From burakaydin at ufl.edu  Mon Jan  2 05:43:55 2017
From: burakaydin at ufl.edu (Aydin,Burak)
Date: Mon, 2 Jan 2017 04:43:55 +0000
Subject: [R-sig-ME] 3 level multivariate multilevel model
In-Reply-To: <MWHPR08MB24302FEFD668CBF28510E57ECB6F0@MWHPR08MB2430.namprd08.prod.outlook.com>
References: <MWHPR08MB24302FEFD668CBF28510E57ECB6F0@MWHPR08MB2430.namprd08.prod.outlook.com>
Message-ID: <MWHPR08MB2430FC2750EAB6CCCA6D24E5CB6F0@MWHPR08MB2430.namprd08.prod.outlook.com>

Hello all,

This is my first post.

I am trying to extract covariance matrices.

I can do it with lme (the model is given by Snijders), please see below;

However, the way I do it is just ugly and inefficient. BTW It is a lot easier with mplus.



Can you help me to get the same covariance matrices using lmer?

Best


# 3 level multivariate empty model
## Attempts to extract the covariance matrices

## load Rdata from an online repository
urlfile2='https://github.com/burakaydin/materyaller/blob/gh-pages/EGEintRo/tempdata.Rdata?raw=true'
load(url(urlfile2))
rm(urlfile2)

head(tempdat)

##reshape data
library(tidyr)
longeb = gather(tempdat, which, response, x:x2,factor_key=TRUE)
head(longeb)
longeb <-
  longeb[order(longeb$schid,
               longeb$cid2,
               longeb$id),]

## run multivariate multilevel model from Snijder's website
library(nlme)
fit <- lme(response ~ - 1 + which, random = ~ -1 + which|schid/cid2,
           weights=varIdent(form=~1|which),
           corr=corSymm(form=~as.numeric(which)|schid/cid2/id),
           data=longeb, method="REML",
           control = list(maxIter=500, msMaxIter=500, tolerance=1e-8,
                          niterEM=250))

##extract covariance matrices

###level3

l3x1var=as.numeric(VarCorr(fit)[[2,1]])
l3x2var=as.numeric(VarCorr(fit)[[3,1]])
l3cor=as.numeric(VarCorr(fit)[[3,3]])
l3cov=l3cor*sqrt(l3x1var)*sqrt(l3x2var)

####level 3 cov matrix
sigma33=matrix(c(l3x1var,l3cov,l3cov,l3x2var),ncol=2)
sigma33

###level 2
l2x1var=as.numeric(VarCorr(fit)[[5,1]])
l2x2var=as.numeric(VarCorr(fit)[[6,1]])
l2cor=as.numeric(VarCorr(fit)[[6,3]])
l2cov=l2cor*sqrt(l2x1var)*sqrt(l2x2var)

#### level 2 matrix
sigma22=matrix(c(l2x1var,l2cov,l2cov,l2x2var),ncol=2)
sigma22

### Level-1 (shame)

l1x1var=as.numeric(VarCorr(fit)[[7,1]])
l1x2var=l1x1var
capture.output( summary(fit) , file='fit.txt')
mystring <- read.table("fit.txt",sep="\n")
l1cor=factor(mystring[22,1])
l1cor=levels(l1cor)
l1cor=strsplit(l1cor," ")
l1cor=as.numeric(l1cor[[1]][2])
l1cov=l1cor*sqrt(l1x1var)*sqrt(l1x2var)

#### level 1 covariance matrix
sigma11=matrix(c(l1x1var,l1cov,l1cov,l1x2var),ncol=2)
sigma11



	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jan  2 22:19:41 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 2 Jan 2017 22:19:41 +0100
Subject: [R-sig-ME] 3 level multivariate multilevel model
In-Reply-To: <MWHPR08MB2430FC2750EAB6CCCA6D24E5CB6F0@MWHPR08MB2430.namprd08.prod.outlook.com>
References: <MWHPR08MB24302FEFD668CBF28510E57ECB6F0@MWHPR08MB2430.namprd08.prod.outlook.com>
	<MWHPR08MB2430FC2750EAB6CCCA6D24E5CB6F0@MWHPR08MB2430.namprd08.prod.outlook.com>
Message-ID: <CAJuCY5wy+eLh8cObHs9NpJkLRnby2gv77inY5oYr2Ewc=ZiUeA@mail.gmail.com>

Dear Aydin,

The lme4 package has no infrastructure to fit variance and correlation
structures. You need nlme for those.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-02 5:43 GMT+01:00 Aydin,Burak <burakaydin at ufl.edu>:

> Hello all,
>
> This is my first post.
>
> I am trying to extract covariance matrices.
>
> I can do it with lme (the model is given by Snijders), please see below;
>
> However, the way I do it is just ugly and inefficient. BTW It is a lot
> easier with mplus.
>
>
>
> Can you help me to get the same covariance matrices using lmer?
>
> Best
>
>
> # 3 level multivariate empty model
> ## Attempts to extract the covariance matrices
>
> ## load Rdata from an online repository
> urlfile2='https://github.com/burakaydin/materyaller/blob/
> gh-pages/EGEintRo/tempdata.Rdata?raw=true'
> load(url(urlfile2))
> rm(urlfile2)
>
> head(tempdat)
>
> ##reshape data
> library(tidyr)
> longeb = gather(tempdat, which, response, x:x2,factor_key=TRUE)
> head(longeb)
> longeb <-
>   longeb[order(longeb$schid,
>                longeb$cid2,
>                longeb$id),]
>
> ## run multivariate multilevel model from Snijder's website
> library(nlme)
> fit <- lme(response ~ - 1 + which, random = ~ -1 + which|schid/cid2,
>            weights=varIdent(form=~1|which),
>            corr=corSymm(form=~as.numeric(which)|schid/cid2/id),
>            data=longeb, method="REML",
>            control = list(maxIter=500, msMaxIter=500, tolerance=1e-8,
>                           niterEM=250))
>
> ##extract covariance matrices
>
> ###level3
>
> l3x1var=as.numeric(VarCorr(fit)[[2,1]])
> l3x2var=as.numeric(VarCorr(fit)[[3,1]])
> l3cor=as.numeric(VarCorr(fit)[[3,3]])
> l3cov=l3cor*sqrt(l3x1var)*sqrt(l3x2var)
>
> ####level 3 cov matrix
> sigma33=matrix(c(l3x1var,l3cov,l3cov,l3x2var),ncol=2)
> sigma33
>
> ###level 2
> l2x1var=as.numeric(VarCorr(fit)[[5,1]])
> l2x2var=as.numeric(VarCorr(fit)[[6,1]])
> l2cor=as.numeric(VarCorr(fit)[[6,3]])
> l2cov=l2cor*sqrt(l2x1var)*sqrt(l2x2var)
>
> #### level 2 matrix
> sigma22=matrix(c(l2x1var,l2cov,l2cov,l2x2var),ncol=2)
> sigma22
>
> ### Level-1 (shame)
>
> l1x1var=as.numeric(VarCorr(fit)[[7,1]])
> l1x2var=l1x1var
> capture.output( summary(fit) , file='fit.txt')
> mystring <- read.table("fit.txt",sep="\n")
> l1cor=factor(mystring[22,1])
> l1cor=levels(l1cor)
> l1cor=strsplit(l1cor," ")
> l1cor=as.numeric(l1cor[[1]][2])
> l1cov=l1cor*sqrt(l1x1var)*sqrt(l1x2var)
>
> #### level 1 covariance matrix
> sigma11=matrix(c(l1x1var,l1cov,l1cov,l1x2var),ncol=2)
> sigma11
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From huangrenhuai at gmail.com  Wed Jan  4 05:57:26 2017
From: huangrenhuai at gmail.com (Ren-Huai Huang)
Date: Tue, 3 Jan 2017 22:57:26 -0600
Subject: [R-sig-ME] random effect latent variable model,
Message-ID: <CAAd=uj4MoYy5huF=8z6EPjWheGpXx_N=ThAy_03shHG1GKtSOA@mail.gmail.com>

Happy new year,

My question is how to replicate the following sas code in R, Julia or
other open source languages? Thanks in advance!

proc nlmixed data=input tech=dbldog qpoints=30 noad;
        ...
    model   id ~ general(loglik);
    random  latent_var ~ normal(0, 1) subject= id;
       ...
run;

Regards,

Renhuai


On Fri, Dec 30, 2016 at 4:24 PM, Ren-Huai Huang <huangrenhuai at gmail.com>
wrote:

> Re: Random Effect Latent Variable Model
>
>
>
> Dear mixed model members,
>
>
> I am trying to do a weighted latent variable modeling with random effects
> in R, which is similar to sas nlmixed general log likelihood over a random
> effect (sas code attached here
> <https://huangrh.github.io/relvm/vignettes/sascode.html>). The purpose is
> to calculate a latent variable from 7 observed variables x1, x2, ? , x7
> with weightings w1, w2, ? , w7 to the corresponding likelihood of the
> variables (the dataset is attached here
> <https://github.com/huangrh/relvm/blob/master/inst/extdata/dat244.csv>).
>
>
> Both equations of the weighted log likelihood and the random effect log
> likelihood are linked here
> <https://huangrh.github.io/relvm/vignettes/formula.html> (equations 2 and
> 3). I was wondering if the subjective function should be the joint
> probability of both equations 2 and 3, as shown in equation 4. How to join
> the equation 2 with the random effect?
>
>
> I tried to optimize the function (link to the R code, lines 36-37
> <https://github.com/huangrh/relvm/blob/master/R/nll.R>) using optim in R (link
> to vignette
> <https://huangrh.github.io/relvm/vignettes/Random_Effect_Latent_Variable_Model.html>).
> But the result is very different from the sas nlmixed mentioned above
> <https://huangrh.github.io/relvm/vignettes/sascode.html>.
>
>
> Any suggestions are very welcome to help me to do this right in R. Thank
> you very much in advance.
>
>
>
> Sincerely,
>
> Ren-Huai Huang
>

	[[alternative HTML version deleted]]


From jbaldwin at fs.fed.us  Wed Jan  4 18:06:17 2017
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Wed, 4 Jan 2017 17:06:17 +0000
Subject: [R-sig-ME] random effect latent variable model,
In-Reply-To: <CAAd=uj4MoYy5huF=8z6EPjWheGpXx_N=ThAy_03shHG1GKtSOA@mail.gmail.com>
References: <CAAd=uj4MoYy5huF=8z6EPjWheGpXx_N=ThAy_03shHG1GKtSOA@mail.gmail.com>
Message-ID: <f2135d2e8f9d496aa4e642e476811720@CY1PR0204MB0101.001f.mgd2.msft.net>

I  think you'd get a better response if you gave a complete (but maybe minimal) working example.  Also, I suspect you'd be better off if your example used PROC GLIMMIX in SAS rather than PROC NLMIXED.  And maybe showing what you've tried so far would also create more interest to help.

Jim


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ren-Huai Huang
Sent: Tuesday, January 03, 2017 8:57 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] random effect latent variable model,

Happy new year,

My question is how to replicate the following sas code in R, Julia or other open source languages? Thanks in advance!

proc nlmixed data=input tech=dbldog qpoints=30 noad;
        ...
    model   id ~ general(loglik);
    random  latent_var ~ normal(0, 1) subject= id;
       ...
run;

Regards,

Renhuai


On Fri, Dec 30, 2016 at 4:24 PM, Ren-Huai Huang <huangrenhuai at gmail.com>
wrote:

> Re: Random Effect Latent Variable Model
>
>
>
> Dear mixed model members,
>
>
> I am trying to do a weighted latent variable modeling with random
> effects in R, which is similar to sas nlmixed general log likelihood
> over a random effect (sas code attached here
> <https://huangrh.github.io/relvm/vignettes/sascode.html>). The purpose
> is to calculate a latent variable from 7 observed variables x1, x2, ?
> , x7 with weightings w1, w2, ? , w7 to the corresponding likelihood of
> the variables (the dataset is attached here
> <https://github.com/huangrh/relvm/blob/master/inst/extdata/dat244.csv>).
>
>
> Both equations of the weighted log likelihood and the random effect
> log likelihood are linked here
> <https://huangrh.github.io/relvm/vignettes/formula.html> (equations 2
> and 3). I was wondering if the subjective function should be the joint
> probability of both equations 2 and 3, as shown in equation 4. How to
> join the equation 2 with the random effect?
>
>
> I tried to optimize the function (link to the R code, lines 36-37
> <https://github.com/huangrh/relvm/blob/master/R/nll.R>) using optim in
> R (link to vignette
> <https://huangrh.github.io/relvm/vignettes/Random_Effect_Latent_Variable_Model.html>).
> But the result is very different from the sas nlmixed mentioned above
> <https://huangrh.github.io/relvm/vignettes/sascode.html>.
>
>
> Any suggestions are very welcome to help me to do this right in R.
> Thank you very much in advance.
>
>
>
> Sincerely,
>
> Ren-Huai Huang
>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.

From huangrenhuai at gmail.com  Wed Jan  4 20:02:28 2017
From: huangrenhuai at gmail.com (Ren-Huai Huang)
Date: Wed, 4 Jan 2017 13:02:28 -0600
Subject: [R-sig-ME] random effect latent variable model,
Message-ID: <CAAd=uj7hsQOfR26QDiwX85FoOtVqu4+X0gmBN5EHmEMVzj3+xA@mail.gmail.com>

Thank you Jim.

I will look at PROC GLIMMIX in SAS. I choose PROC NLMIXED is because using
general(ll)  in the model statement can specifiesa general log likelihood
function.

Attached below is the objective function I have tried in R . What I am not
sure is to join the log likelihood with the random effect as I did in the
last four lines. Let me know if I am wrong
see https://github.com/huangrh/relvm for more details.

Thanks again!

Regards,

Renhuai

# -------------------------------------------------------------------
# negative log likelihood: How to join Likelihood with random effect
nll <- function(par, data = data_tbl, w = weight_tbl) { # Reconstruction of
the parameters from the vector mu <- par[grep("mu",names(par))] # fl <-
par[grep("fl", names(par))] # factor loading lv <-
par[grep("lv",names(par))] # factor variable err <- par[grep("err",
names(par))] # # # Convert to matrix d <- dim(data); nr <- d[1]; nc <- d[2]
data<- as.matrix(data); w <- as.matrix(w) mu <- matrix(mu, nrow = nr, ncol
= nc, byrow = TRUE) fl <- matrix(fl, nrow = nr, ncol = nc, byrow = TRUE) lv
<- matrix(lv, nrow = nr, ncol = nc, byrow = FALSE) err <- matrix(err,nrow =
nr, ncol = nc, byrow = TRUE) # negtive log likelyhood means <- mu + fl * lv
out <- sum(( w * (dnorm(data, mean=means, sd = err, log=TRUE))),na.rm=TRUE)
out <- out + sum(dnorm(lv[,1], mean = 0, sd = 1, log=TRUE), na.rm=TRUE)
(-out) }
#------------------------------------------------------------------------------------
# optimize the nll function set.seed(100)
#
# the data set is available in the Github # <
https://github.com/huangrh/relvm/blob/master/inst/extdata/dat244.csv>  file
<- system.file("/extdata/dat4557.csv", package="relvm") dat <-
read.csv(file, na.strings=".") # subset score_tbl <- subset(dat,
select=c(paste0("x",1:7))) weight_tbl<- subset(dat,
select=c(paste0("w",1:7)))
# Init parameters d <- dim(score_tbl); init <- unlist(list(mu = rep(0,
d[2]), fl = rep(1, d[2]), # factor loading lv = rep(1, d[1]), # latent
variable err = rep(1, d[2]))) # fit the function fit <- optim(par = init,
fn = relvm:::nll, gr = NULL, method = "BFGS", control= list(maxit=5200),
data = score_tbl, w = weight_tbl)



On Wed, Jan 4, 2017 at 11:06 AM, Baldwin, Jim -FS <jbaldwin at fs.fed.us>
wrote:

> I  think you'd get a better response if you gave a complete (but maybe
> minimal) working example.  Also, I suspect you'd be better off if your
> example used PROC GLIMMIX in SAS rather than PROC NLMIXED.  And maybe
> showing what you've tried so far would also create more interest to help.
>
> Jim
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ren-Huai Huang
> Sent: Tuesday, January 03, 2017 8:57 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] random effect latent variable model,
>
> Happy new year,
>
> My question is how to replicate the following sas code in R, Julia or
> other open source languages? Thanks in advance!
>
> proc nlmixed data=input tech=dbldog qpoints=30 noad;
>         ...
>     model   id ~ general(loglik);
>     random  latent_var ~ normal(0, 1) subject= id;
>        ...
> run;
>
> Regards,
>
> Renhuai
>
>
> On Fri, Dec 30, 2016 at 4:24 PM, Ren-Huai Huang <huangrenhuai at gmail.com>
> wrote:
>
> > Re: Random Effect Latent Variable Model
> >
> >
> >
> > Dear mixed model members,
> >
> >
> > I am trying to do a weighted latent variable modeling with random
> > effects in R, which is similar to sas nlmixed general log likelihood
> > over a random effect (sas code attached here
> > <https://huangrh.github.io/relvm/vignettes/sascode.html>). The purpose
> > is to calculate a latent variable from 7 observed variables x1, x2, ?
> > , x7 with weightings w1, w2, ? , w7 to the corresponding likelihood of
> > the variables (the dataset is attached here
> > <https://github.com/huangrh/relvm/blob/master/inst/extdata/dat244.csv>).
> >
> >
> > Both equations of the weighted log likelihood and the random effect
> > log likelihood are linked here
> > <https://huangrh.github.io/relvm/vignettes/formula.html> (equations 2
> > and 3). I was wondering if the subjective function should be the joint
> > probability of both equations 2 and 3, as shown in equation 4. How to
> > join the equation 2 with the random effect?
> >
> >
> > I tried to optimize the function (link to the R code, lines 36-37
> > <https://github.com/huangrh/relvm/blob/master/R/nll.R>) using optim in
> > R (link to vignette
> > <https://huangrh.github.io/relvm/vignettes/Random_Effect_
> Latent_Variable_Model.html>).
> > But the result is very different from the sas nlmixed mentioned above
> > <https://huangrh.github.io/relvm/vignettes/sascode.html>.
> >
> >
> > Any suggestions are very welcome to help me to do this right in R.
> > Thank you very much in advance.
> >
> >
> >
> > Sincerely,
> >
> > Ren-Huai Huang
> >
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> This electronic message contains information generated by the USDA solely
> for the intended recipients. Any unauthorized interception of this message
> or the use or disclosure of the information it contains may violate the law
> and subject the violator to civil or criminal penalties. If you believe you
> have received this message in error, please notify the sender and delete
> the email immediately.
>

	[[alternative HTML version deleted]]


From gangchen at mail.nih.gov  Thu Jan  5 17:28:15 2017
From: gangchen at mail.nih.gov (Chen, Gang (NIH/NIMH) [C])
Date: Thu, 5 Jan 2017 16:28:15 +0000
Subject: [R-sig-ME] Understanding variance components
Message-ID: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>

Suppose that I have the following dataset in R:

library(lme4)
data(Machines,package="nlme")
mydata <- Machines[Machines$Machine!='C?,]

With the following model:

print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata), ranef.comp="Var")

I have the variance components as shown below:

Random effects:
 Groups         Name        Variance
 Machine:Worker (Intercept) 46.00   
 Worker         (Intercept) 13.84   
 Residual                    1.16   

I have trouble understanding exactly what the first two components are: Machine:Worker and Worker? Specifically,

1) What is the variance for Worker: corresponding to the base (or reference) level of the factor Machine? If so, what is the base level: the first level in the dataset or alphabetically the first level (it happens to be the same in this particular dataset)?

2) What is the variance for Machine:Worker? Is it the variance for the second level of the factor Machine, or the extra variance relative to the variance for Worker?

Furthermore, for the model:

print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines), ranef.comp="Var")

what is the variance for Machine:Worker in the following result since there are 3 levels involved in the factor Machine?

Random effects:
 Groups         Name        Variance
 Machine:Worker (Intercept) 60.2972 
 Worker         (Intercept)  7.3959 
 Residual                    0.9246 

Thanks,
Gang

From abfine at gmail.com  Thu Jan  5 17:28:40 2017
From: abfine at gmail.com (Alex Fine)
Date: Thu, 5 Jan 2017 11:28:40 -0500
Subject: [R-sig-ME] random effect latent variable model,
In-Reply-To: <CAAd=uj7hsQOfR26QDiwX85FoOtVqu4+X0gmBN5EHmEMVzj3+xA@mail.gmail.com>
References: <CAAd=uj7hsQOfR26QDiwX85FoOtVqu4+X0gmBN5EHmEMVzj3+xA@mail.gmail.com>
Message-ID: <CAJ6ui+PGJTJ84arPv-R=0-ACYdj=XaHVVYVfp3auJfC_XRVDVA@mail.gmail.com>

Following up on what Jim wrote, I actually think it'd be easier to help if
you just describe the model in terms independent of a programming
language.  For example, "a linear mixed effects regression with a random
intercept for X and a by-X random slope for Z" or something.  That way
people who use R but do not use SAS (like me) can still help you.

On Wed, Jan 4, 2017 at 2:02 PM, Ren-Huai Huang <huangrenhuai at gmail.com>
wrote:

> Thank you Jim.
>
> I will look at PROC GLIMMIX in SAS. I choose PROC NLMIXED is because using
> general(ll)  in the model statement can specifiesa general log likelihood
> function.
>
> Attached below is the objective function I have tried in R . What I am not
> sure is to join the log likelihood with the random effect as I did in the
> last four lines. Let me know if I am wrong
> see https://github.com/huangrh/relvm for more details.
>
> Thanks again!
>
> Regards,
>
> Renhuai
>
> # -------------------------------------------------------------------
> # negative log likelihood: How to join Likelihood with random effect
> nll <- function(par, data = data_tbl, w = weight_tbl) { # Reconstruction of
> the parameters from the vector mu <- par[grep("mu",names(par))] # fl <-
> par[grep("fl", names(par))] # factor loading lv <-
> par[grep("lv",names(par))] # factor variable err <- par[grep("err",
> names(par))] # # # Convert to matrix d <- dim(data); nr <- d[1]; nc <- d[2]
> data<- as.matrix(data); w <- as.matrix(w) mu <- matrix(mu, nrow = nr, ncol
> = nc, byrow = TRUE) fl <- matrix(fl, nrow = nr, ncol = nc, byrow = TRUE) lv
> <- matrix(lv, nrow = nr, ncol = nc, byrow = FALSE) err <- matrix(err,nrow =
> nr, ncol = nc, byrow = TRUE) # negtive log likelyhood means <- mu + fl * lv
> out <- sum(( w * (dnorm(data, mean=means, sd = err, log=TRUE))),na.rm=TRUE)
> out <- out + sum(dnorm(lv[,1], mean = 0, sd = 1, log=TRUE), na.rm=TRUE)
> (-out) }
> #-----------------------------------------------------------
> -------------------------
> # optimize the nll function set.seed(100)
> #
> # the data set is available in the Github # <
> https://github.com/huangrh/relvm/blob/master/inst/extdata/dat244.csv>
> file
> <- system.file("/extdata/dat4557.csv", package="relvm") dat <-
> read.csv(file, na.strings=".") # subset score_tbl <- subset(dat,
> select=c(paste0("x",1:7))) weight_tbl<- subset(dat,
> select=c(paste0("w",1:7)))
> # Init parameters d <- dim(score_tbl); init <- unlist(list(mu = rep(0,
> d[2]), fl = rep(1, d[2]), # factor loading lv = rep(1, d[1]), # latent
> variable err = rep(1, d[2]))) # fit the function fit <- optim(par = init,
> fn = relvm:::nll, gr = NULL, method = "BFGS", control= list(maxit=5200),
> data = score_tbl, w = weight_tbl)
>
>
>
> On Wed, Jan 4, 2017 at 11:06 AM, Baldwin, Jim -FS <jbaldwin at fs.fed.us>
> wrote:
>
> > I  think you'd get a better response if you gave a complete (but maybe
> > minimal) working example.  Also, I suspect you'd be better off if your
> > example used PROC GLIMMIX in SAS rather than PROC NLMIXED.  And maybe
> > showing what you've tried so far would also create more interest to help.
> >
> > Jim
> >
> >
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-
> bounces at r-project.org]
> > On Behalf Of Ren-Huai Huang
> > Sent: Tuesday, January 03, 2017 8:57 PM
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] random effect latent variable model,
> >
> > Happy new year,
> >
> > My question is how to replicate the following sas code in R, Julia or
> > other open source languages? Thanks in advance!
> >
> > proc nlmixed data=input tech=dbldog qpoints=30 noad;
> >         ...
> >     model   id ~ general(loglik);
> >     random  latent_var ~ normal(0, 1) subject= id;
> >        ...
> > run;
> >
> > Regards,
> >
> > Renhuai
> >
> >
> > On Fri, Dec 30, 2016 at 4:24 PM, Ren-Huai Huang <huangrenhuai at gmail.com>
> > wrote:
> >
> > > Re: Random Effect Latent Variable Model
> > >
> > >
> > >
> > > Dear mixed model members,
> > >
> > >
> > > I am trying to do a weighted latent variable modeling with random
> > > effects in R, which is similar to sas nlmixed general log likelihood
> > > over a random effect (sas code attached here
> > > <https://huangrh.github.io/relvm/vignettes/sascode.html>). The purpose
> > > is to calculate a latent variable from 7 observed variables x1, x2, ?
> > > , x7 with weightings w1, w2, ? , w7 to the corresponding likelihood of
> > > the variables (the dataset is attached here
> > > <https://github.com/huangrh/relvm/blob/master/inst/extdata/dat244.csv
> >).
> > >
> > >
> > > Both equations of the weighted log likelihood and the random effect
> > > log likelihood are linked here
> > > <https://huangrh.github.io/relvm/vignettes/formula.html> (equations 2
> > > and 3). I was wondering if the subjective function should be the joint
> > > probability of both equations 2 and 3, as shown in equation 4. How to
> > > join the equation 2 with the random effect?
> > >
> > >
> > > I tried to optimize the function (link to the R code, lines 36-37
> > > <https://github.com/huangrh/relvm/blob/master/R/nll.R>) using optim in
> > > R (link to vignette
> > > <https://huangrh.github.io/relvm/vignettes/Random_Effect_
> > Latent_Variable_Model.html>).
> > > But the result is very different from the sas nlmixed mentioned above
> > > <https://huangrh.github.io/relvm/vignettes/sascode.html>.
> > >
> > >
> > > Any suggestions are very welcome to help me to do this right in R.
> > > Thank you very much in advance.
> > >
> > >
> > >
> > > Sincerely,
> > >
> > > Ren-Huai Huang
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> >
> > This electronic message contains information generated by the USDA solely
> > for the intended recipients. Any unauthorized interception of this
> message
> > or the use or disclosure of the information it contains may violate the
> law
> > and subject the violator to civil or criminal penalties. If you believe
> you
> > have received this message in error, please notify the sender and delete
> > the email immediately.
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Alex Fine
Ph. (336) 302-3251
web:  abfine.github.io/

	[[alternative HTML version deleted]]


From jlb53 at st-andrews.ac.uk  Sun Jan  8 15:32:53 2017
From: jlb53 at st-andrews.ac.uk (Jennifer Botting)
Date: Sun, 8 Jan 2017 09:32:53 -0500
Subject: [R-sig-ME] glmmADMB question
Message-ID: <CAMPETpgewdp9jw=RR7bCR2keDNR2bwC=P0POxVokBMu-vU8MvQ@mail.gmail.com>

Hi,

I'm having trouble running a ZIPGLMM in glmmADMB.  I am comparing the
number of behaviours exhibited by 12 individuals over 7 conditions. Each
subject was tested 4 times.

> str(Dat)
'data.frame': 329 obs. of  26 variables:
 $ Subject      : Factor w/ 12 levels "Baraka","Batang",..: 11 11 11 11 11
11 11 11 11 11 ...
 $ Sex          : Factor w/ 2 levels "F","M": 1 1 1 1 1 1 1 1 1 1 ...
 $ History      : Factor w/ 2 levels "HR","MR": 1 1 1 1 1 1 1 1 1 1 ...
 $ Session      : int  1 2 3 4 1 2 3 4 1 2 ...
 $ Order        : int  3 1 1 4 5 5 5 2 1 2 ...
 $ Condition    : Factor w/ 7 levels "A ","B","BE",..: 1 1 1 1 2 2 2 2 3 3
...
 $ Voc: int  0 0 0 0 7 1 5 5 6 3 ...
 $ Non  : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Fac       : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Ges     : int  0 0 0 0 0 0 0 1 0 0 ...
...............................

The data include a very large number of zeros, so I tried the following
formula in glmmADMB, starting with Ges as my outcome variable:

*> m <- glmmadmb(formula = Ges ~ Condition + (1 | Subject), data = Dat,
family = "poisson", zeroInflation = TRUE) *

and got the following error:

Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(formula = Ges~ Condition + (1 | Subject), data = Dat,  :
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
5 -noinit -shess' had status 1

When I ran it with debug=TRUE, I got the following output:

Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
run failed:  Initial statistics: 7 variables; iteration 0; function
evaluation 0; phase 1 Function value  3.7639324e+002; maximum gradient
component mag  1.2938e+001 Var   Value    Gradient   |Var   Value
 Gradient   |Var   Value    Gradient   1  0.00000  1.2938e+001 |  2
 0.00000  9.7086e-001 |  3  0.00000  1.6197e+000   4  0.00000 -2.6734e+000
|  5  0.00000 -5.9309e-002 |  6  0.00000 -2.6798e+000   7  0.00000
-4.9402e-001 |   - final statistics: 7 variables; iteration 7; function
evaluation 10 Function value  3.2460e+002; maximum gradient component mag
-8.0580e-005 Exit code = 1;  converg criter  1.0000e-004 Var   Value
 Gradient   |Var   Value    Gradient   |Var   Value    Gradient   1
-7.41263  1.8275e-006 |  2 -0.58080  3.4938e-005 |  3 -0.99038  1.6835e-005
  4  1.59079  8.0028e-005 |  5  0.06984  3.2566e-005 |  6  1.63706
-8.0580e-005   7  0.32457  7.7648e-005 |  Initial statistics: 8 variables;
iteration 0; function evaluation 0; phase 2 Function value  3.2460159e+002;
maxi... <truncated>
Error in glmmadmb(formula = Ges ~ Condition + (1 | Subject), data = Dat,  :
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
5 -noinit -shess' had status 1
restored working directory to I:/xxxxx
removed temp directory
C:\Users\BO~1\AppData\Local\Temp\1\RtmpiwJxjv\glmmADMB12a03acd7a0c


I tried adding another fixed effect and the model ran, but gave crazy
values for the condition levels:

Call:
glmmadmb(formula = Ges ~ Condition + History + (1 | Subject),
    data = Dat, family = "poisson", zeroInflation = TRUE)

AIC: 257.9

Coefficients:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    -91.28   91007.00    0.00    0.999
ConditionB      89.63   91007.00    0.00    0.999
ConditionBE     88.69   91007.00    0.00    0.999
ConditionEYC    91.28   91007.00    0.00    0.999
ConditionF      90.54   91007.00    0.00    0.999
ConditionFE     91.17   91007.00    0.00    0.999
ConditionHA     89.59   91007.00    0.00    0.999
HistoryMR       -2.48       1.02   -2.43    0.015 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=329, Subject=12
Random effect variance(s):
Group=Subject
            Variance StdDev
(Intercept)    1.837  1.355

Zero-inflation: 0.15369  (std. err.:  0.13609 )

Log-likelihood: -118.968
Warning message:
In .local(x, sigma, ...) :
  'sigma' and 'rdig' arguments are present for compatibility only: ignored



I tried changing some controls that people had suggested online, such as

 *admb.opts=admbControl(shess=FALSE,noinit=FALSE)*

but this didn't work with my model.

Some issues with my data are that for one of the conditions, the count of
Ges was 0 for all subjects. Similarly, for some subjects, the count for Ges
was 0 across all conditions.

I'd be extremely grateful if you had any advice.

Jenny

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Jan  8 16:19:52 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 8 Jan 2017 10:19:52 -0500
Subject: [R-sig-ME] glmmADMB question
In-Reply-To: <CAMPETpgewdp9jw=RR7bCR2keDNR2bwC=P0POxVokBMu-vU8MvQ@mail.gmail.com>
References: <CAMPETpgewdp9jw=RR7bCR2keDNR2bwC=P0POxVokBMu-vU8MvQ@mail.gmail.com>
Message-ID: <23436dab-6b09-4994-f97a-5162c7876662@gmail.com>


  A few suggestions:

- your "crazy" parameters below, and your statement that

Some issues with my data are that for one of the conditions, the count
of Ges was 0 for all subjects. Similarly, for some subjects, the count
for Ges  was 0 across all conditions.

 suggest that you have an issue of complete separation (e.g. see
<http://stats.stackexchange.com/questions/128742/mixed-logistic-model-with-complete-separation>;
however, the solutions listed there don't currently work in glmmADMB or
glmmTMB ... are you sure you need zero-inflation?  Lots of zeros doesn't
necessarily mean zero-inflation (it could just mean a Poisson/NB with a
very low mean)

  The options I know of for handling complete separation in GLMMs in R
include the blme package (can do anything glmer does, but *not* NB
models - although you could approximate that via a logNormal-Poisson
model); MCMCglmm; and brms.  The latter two can handle zero-inflated
models, but take you into the deep (Bayesian) end of the pool ...

On 17-01-08 09:32 AM, Jennifer Botting wrote:
> Hi,
> 
> I'm having trouble running a ZIPGLMM in glmmADMB.  I am comparing the
> number of behaviours exhibited by 12 individuals over 7 conditions. Each
> subject was tested 4 times.
> 
>> str(Dat)
> 'data.frame': 329 obs. of  26 variables:
>  $ Subject      : Factor w/ 12 levels "Baraka","Batang",..: 11 11 11 11 11
> 11 11 11 11 11 ...
>  $ Sex          : Factor w/ 2 levels "F","M": 1 1 1 1 1 1 1 1 1 1 ...
>  $ History      : Factor w/ 2 levels "HR","MR": 1 1 1 1 1 1 1 1 1 1 ...
>  $ Session      : int  1 2 3 4 1 2 3 4 1 2 ...
>  $ Order        : int  3 1 1 4 5 5 5 2 1 2 ...
>  $ Condition    : Factor w/ 7 levels "A ","B","BE",..: 1 1 1 1 2 2 2 2 3 3
> ...
>  $ Voc: int  0 0 0 0 7 1 5 5 6 3 ...
>  $ Non  : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ Fac       : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ Ges     : int  0 0 0 0 0 0 0 1 0 0 ...
> ...............................
> 
> The data include a very large number of zeros, so I tried the following
> formula in glmmADMB, starting with Ges as my outcome variable:
> 
> *> m <- glmmadmb(formula = Ges ~ Condition + (1 | Subject), data = Dat,
> family = "poisson", zeroInflation = TRUE) *
> 
> and got the following error:
> 
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(formula = Ges~ Condition + (1 | Subject), data = Dat,  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
> 5 -noinit -shess' had status 1
> 
> When I ran it with debug=TRUE, I got the following output:
> 
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> run failed:  Initial statistics: 7 variables; iteration 0; function
> evaluation 0; phase 1 Function value  3.7639324e+002; maximum gradient
> component mag  1.2938e+001 Var   Value    Gradient   |Var   Value
>  Gradient   |Var   Value    Gradient   1  0.00000  1.2938e+001 |  2
>  0.00000  9.7086e-001 |  3  0.00000  1.6197e+000   4  0.00000 -2.6734e+000
> |  5  0.00000 -5.9309e-002 |  6  0.00000 -2.6798e+000   7  0.00000
> -4.9402e-001 |   - final statistics: 7 variables; iteration 7; function
> evaluation 10 Function value  3.2460e+002; maximum gradient component mag
> -8.0580e-005 Exit code = 1;  converg criter  1.0000e-004 Var   Value
>  Gradient   |Var   Value    Gradient   |Var   Value    Gradient   1
> -7.41263  1.8275e-006 |  2 -0.58080  3.4938e-005 |  3 -0.99038  1.6835e-005
>   4  1.59079  8.0028e-005 |  5  0.06984  3.2566e-005 |  6  1.63706
> -8.0580e-005   7  0.32457  7.7648e-005 |  Initial statistics: 8 variables;
> iteration 0; function evaluation 0; phase 2 Function value  3.2460159e+002;
> maxi... <truncated>
> Error in glmmadmb(formula = Ges ~ Condition + (1 | Subject), data = Dat,  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
> 5 -noinit -shess' had status 1
> restored working directory to I:/xxxxx
> removed temp directory
> C:\Users\BO~1\AppData\Local\Temp\1\RtmpiwJxjv\glmmADMB12a03acd7a0c
> 
> 
> I tried adding another fixed effect and the model ran, but gave crazy
> values for the condition levels:
> 
> Call:
> glmmadmb(formula = Ges ~ Condition + History + (1 | Subject),
>     data = Dat, family = "poisson", zeroInflation = TRUE)
> 
> AIC: 257.9
> 
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)    -91.28   91007.00    0.00    0.999
> ConditionB      89.63   91007.00    0.00    0.999
> ConditionBE     88.69   91007.00    0.00    0.999
> ConditionEYC    91.28   91007.00    0.00    0.999
> ConditionF      90.54   91007.00    0.00    0.999
> ConditionFE     91.17   91007.00    0.00    0.999
> ConditionHA     89.59   91007.00    0.00    0.999
> HistoryMR       -2.48       1.02   -2.43    0.015 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Number of observations: total=329, Subject=12
> Random effect variance(s):
> Group=Subject
>             Variance StdDev
> (Intercept)    1.837  1.355
> 
> Zero-inflation: 0.15369  (std. err.:  0.13609 )
> 
> Log-likelihood: -118.968
> Warning message:
> In .local(x, sigma, ...) :
>   'sigma' and 'rdig' arguments are present for compatibility only: ignored
> 
> 
> 
> I tried changing some controls that people had suggested online, such as
> 
>  *admb.opts=admbControl(shess=FALSE,noinit=FALSE)*
> 
> but this didn't work with my model.
> 
> Some issues with my data are that for one of the conditions, the count of
> Ges was 0 for all subjects. Similarly, for some subjects, the count for Ges
> was 0 across all conditions.
> 
> I'd be extremely grateful if you had any advice.
> 
> Jenny
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From alexia.jolicoeur-martineau at mail.mcgill.ca  Sat Jan  7 20:29:35 2017
From: alexia.jolicoeur-martineau at mail.mcgill.ca (Alexia Jolicoeur-Martineau)
Date: Sat, 7 Jan 2017 19:29:35 +0000
Subject: [R-sig-ME] force lmer/glmer to use known random effects
Message-ID: <CY4PR03MB2454003D241670019666E56CF8620@CY4PR03MB2454.namprd03.prod.outlook.com>

In SAS, there is an option to use a known covariance matrix for your random effects (See here: https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect033.htm). In lme4 we cannot use covariance matrices but we can use random effects. Is there a way for me to do force lmer/glmer to use known random effects variances?

My algorithm works in two steps. In step 1, I fit a generalized linear mixed model with a known variable "x". In step 2, I fit the generalized linear mixed model but this time I assume "x" to be unknown and every other parameters to be known (using the parameter estimates from step 1). This is what we call alternating optimization. I thus want to be able to fix the random parameters from the model in step 2 to be the estimates of the random effects from step 1. Is this possible to do?


I already implemented my method in SAS but I wish I could also implement in R because 1) SAS macros  are slow and 2) SAS is not free so not everyone could use it.


Alexia

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jan  9 11:40:48 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 9 Jan 2017 11:40:48 +0100
Subject: [R-sig-ME] force lmer/glmer to use known random effects
In-Reply-To: <CY4PR03MB2454003D241670019666E56CF8620@CY4PR03MB2454.namprd03.prod.outlook.com>
References: <CY4PR03MB2454003D241670019666E56CF8620@CY4PR03MB2454.namprd03.prod.outlook.com>
Message-ID: <CAJuCY5y1LgBaPFv-kR1RGeT1abs-=Bf782XOv_jRhV9a5rV3pQ@mail.gmail.com>

Dear Alexia,

IMHO that is not possible with lme4. I think you can do it with INLA which
has a "copy" feature. See
http://www.r-inla.org/models/tools#TOC-Copying-a-model. You will need to
fit both models simultaneous.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-07 20:29 GMT+01:00 Alexia Jolicoeur-Martineau <
alexia.jolicoeur-martineau at mail.mcgill.ca>:

> In SAS, there is an option to use a known covariance matrix for your
> random effects (See here: https://support.sas.com/
> documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect033.htm).
> In lme4 we cannot use covariance matrices but we can use random effects. Is
> there a way for me to do force lmer/glmer to use known random effects
> variances?
>
> My algorithm works in two steps. In step 1, I fit a generalized linear
> mixed model with a known variable "x". In step 2, I fit the generalized
> linear mixed model but this time I assume "x" to be unknown and every other
> parameters to be known (using the parameter estimates from step 1). This is
> what we call alternating optimization. I thus want to be able to fix the
> random parameters from the model in step 2 to be the estimates of the
> random effects from step 1. Is this possible to do?
>
>
> I already implemented my method in SAS but I wish I could also implement
> in R because 1) SAS macros  are slow and 2) SAS is not free so not everyone
> could use it.
>
>
> Alexia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From iwhite at ed.ac.uk  Mon Jan  9 12:18:00 2017
From: iwhite at ed.ac.uk (ian m s white)
Date: Mon, 9 Jan 2017 11:18:00 +0000
Subject: [R-sig-ME] force lmer/glmer to use known random effects
In-Reply-To: <CY4PR03MB2454003D241670019666E56CF8620@CY4PR03MB2454.namprd03.prod.outlook.com>
References: <CY4PR03MB2454003D241670019666E56CF8620@CY4PR03MB2454.namprd03.prod.outlook.com>
Message-ID: <6a1c26d5-5561-a49a-5e79-a76ed1c380bb@ed.ac.uk>


Fitting a random term with known covariance matrix G is equivalent to 
fitting random term Zu where ZZ' = G and cov(u) = I. Eg Z' is the 
Choleski root of G. So is theoretically possible with lmer but may not 
be practicable (depends on size of G).


On 01/07/2017 07:29 PM, Alexia Jolicoeur-Martineau wrote:
> In SAS, there is an option to use a known covariance matrix for your random effects (See here: https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect033.htm). In lme4 we cannot use covariance matrices but we can use random effects. Is there a way for me to do force lmer/glmer to use known random effects variances?
>
> My algorithm works in two steps. In step 1, I fit a generalized linear mixed model with a known variable "x". In step 2, I fit the generalized linear mixed model but this time I assume "x" to be unknown and every other parameters to be known (using the parameter estimates from step 1). This is what we call alternating optimization. I thus want to be able to fix the random parameters from the model in step 2 to be the estimates of the random effects from step 1. Is this possible to do?
>
>
> I already implemented my method in SAS but I wish I could also implement in R because 1) SAS macros  are slow and 2) SAS is not free so not everyone could use it.
>
>
> Alexia
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Mon Jan  9 18:05:35 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Jan 2017 12:05:35 -0500
Subject: [R-sig-ME] force lmer/glmer to use known random effects
In-Reply-To: <CAJuCY5y1LgBaPFv-kR1RGeT1abs-=Bf782XOv_jRhV9a5rV3pQ@mail.gmail.com>
References: <CY4PR03MB2454003D241670019666E56CF8620@CY4PR03MB2454.namprd03.prod.outlook.com>
	<CAJuCY5y1LgBaPFv-kR1RGeT1abs-=Bf782XOv_jRhV9a5rV3pQ@mail.gmail.com>
Message-ID: <8773a216-97b1-9d7b-5dd9-7fe1b74724c5@gmail.com>


  I think you can actually do this if you're willing to hack a little
bit.  Here's an example modifying the one shown in ?modular :

library(lme4)
## 1.  Parse the data and formula:
glmod <- glFormula(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial)
## 2.  Create the deviance function for optimizing over theta:
##     skip initial (nAGQ=0, theta parameters only) step
devfun <- updateGlmerDevfun(do.call(mkGlmerDevfun, c(glmod, list(nAGQ=1))),
                            reTrms=glmod$reTrms)
devfun2 <- function(beta) {
    devfun(c(1,beta))
}
devfun2(c(0,0,0,0))   ## test: evaluate
## deviance with all fixed-effect parameters set to zero
## optimize
opt <- nloptwrap(fn=devfun2,
          par=c(0,0,0,0),
          lower=rep(-Inf,4),
          upper=rep(Inf,4))
opt$par
[1] -1.4570408 -0.9533831 -1.0913854 -1.5366132


On 17-01-09 05:40 AM, Thierry Onkelinx wrote:
> Dear Alexia,
> 
> IMHO that is not possible with lme4. I think you can do it with INLA which
> has a "copy" feature. See
> http://www.r-inla.org/models/tools#TOC-Copying-a-model. You will need to
> fit both models simultaneous.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2017-01-07 20:29 GMT+01:00 Alexia Jolicoeur-Martineau <
> alexia.jolicoeur-martineau at mail.mcgill.ca>:
> 
>> In SAS, there is an option to use a known covariance matrix for your
>> random effects (See here: https://support.sas.com/
>> documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect033.htm).
>> In lme4 we cannot use covariance matrices but we can use random effects. Is
>> there a way for me to do force lmer/glmer to use known random effects
>> variances?
>>
>> My algorithm works in two steps. In step 1, I fit a generalized linear
>> mixed model with a known variable "x". In step 2, I fit the generalized
>> linear mixed model but this time I assume "x" to be unknown and every other
>> parameters to be known (using the parameter estimates from step 1). This is
>> what we call alternating optimization. I thus want to be able to fix the
>> random parameters from the model in step 2 to be the estimates of the
>> random effects from step 1. Is this possible to do?
>>
>>
>> I already implemented my method in SAS but I wish I could also implement
>> in R because 1) SAS macros  are slow and 2) SAS is not free so not everyone
>> could use it.
>>
>>
>> Alexia
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Tue Jan 10 17:59:28 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Jan 2017 11:59:28 -0500
Subject: [R-sig-ME] glmmADMB question
In-Reply-To: <CAMPETpi-n0J3=SV78Z+3Nd1B5M2kWOyfOEpov2S2k3T88-AE7g@mail.gmail.com>
References: <CAMPETpgewdp9jw=RR7bCR2keDNR2bwC=P0POxVokBMu-vU8MvQ@mail.gmail.com>
	<23436dab-6b09-4994-f97a-5162c7876662@gmail.com>
	<CAMPETpi-n0J3=SV78Z+3Nd1B5M2kWOyfOEpov2S2k3T88-AE7g@mail.gmail.com>
Message-ID: <CABghstQWj1P99sZcm8zOQsMmiwrB2TwWvKBHDMbR7pmh8V5Szw@mail.gmail.com>

 (please keep r-sig-mixed-models in Cc: list)

On Tue, Jan 10, 2017 at 9:14 AM, Jennifer Botting
<jlb53 at st-andrews.ac.uk> wrote:
> Thank you for the reply and advice; I tried blme and it worked using the
> following (there are 7 levels to my fixed effect):
>
>
> m <- bglmer(Ges~ Condition+(1|Subject),data=Dat,
>            family=poisson,
>            fixef.prior = normal(cov = diag(9,7)))
>
> However, when I tried to use different outcome variables, some models again
> failed to converge with the following error :
>
> In get("checkConv", lme4Namespace)(attr(opt, "derivs"), opt$par,  :
>   Model failed to converge with max|grad| = 0.73863 (tol = 0.001, component
> 1)
>
> Do you think that this is something that can be fixed by adjusting the
> controls within bglmer?
>
> Thank you very much for the advice,
> Jenny

 Maybe (?) try tightening the priors a little bit?  I think I would
also try out the advice under ?convergence : try substituting a
different optimizer and see whether you get similar-enough results.
If so, don't worry about the convergence warning.

  cheers
    Ben Bolker

>
> On 8 January 2017 at 10:19, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>   A few suggestions:
>>
>> - your "crazy" parameters below, and your statement that
>>
>> Some issues with my data are that for one of the conditions, the count
>> of Ges was 0 for all subjects. Similarly, for some subjects, the count
>> for Ges  was 0 across all conditions.
>>
>>  suggest that you have an issue of complete separation (e.g. see
>>
>> <http://stats.stackexchange.com/questions/128742/mixed-logistic-model-with-complete-separation>;
>> however, the solutions listed there don't currently work in glmmADMB or
>> glmmTMB ... are you sure you need zero-inflation?  Lots of zeros doesn't
>> necessarily mean zero-inflation (it could just mean a Poisson/NB with a
>> very low mean)
>>
>>   The options I know of for handling complete separation in GLMMs in R
>> include the blme package (can do anything glmer does, but *not* NB
>> models - although you could approximate that via a logNormal-Poisson
>> model); MCMCglmm; and brms.  The latter two can handle zero-inflated
>> models, but take you into the deep (Bayesian) end of the pool ...
>>
>> On 17-01-08 09:32 AM, Jennifer Botting wrote:
>> > Hi,
>> >
>> > I'm having trouble running a ZIPGLMM in glmmADMB.  I am comparing the
>> > number of behaviours exhibited by 12 individuals over 7 conditions. Each
>> > subject was tested 4 times.
>> >
>> >> str(Dat)
>> > 'data.frame': 329 obs. of  26 variables:
>> >  $ Subject      : Factor w/ 12 levels "Baraka","Batang",..: 11 11 11 11
>> > 11
>> > 11 11 11 11 11 ...
>> >  $ Sex          : Factor w/ 2 levels "F","M": 1 1 1 1 1 1 1 1 1 1 ...
>> >  $ History      : Factor w/ 2 levels "HR","MR": 1 1 1 1 1 1 1 1 1 1 ...
>> >  $ Session      : int  1 2 3 4 1 2 3 4 1 2 ...
>> >  $ Order        : int  3 1 1 4 5 5 5 2 1 2 ...
>> >  $ Condition    : Factor w/ 7 levels "A ","B","BE",..: 1 1 1 1 2 2 2 2 3
>> > 3
>> > ...
>> >  $ Voc: int  0 0 0 0 7 1 5 5 6 3 ...
>> >  $ Non  : int  0 0 0 0 0 0 0 0 0 0 ...
>> >  $ Fac       : int  0 0 0 0 0 0 0 0 0 0 ...
>> >  $ Ges     : int  0 0 0 0 0 0 0 1 0 0 ...
>> > ...............................
>> >
>> > The data include a very large number of zeros, so I tried the following
>> > formula in glmmADMB, starting with Ges as my outcome variable:
>> >
>> > *> m <- glmmadmb(formula = Ges ~ Condition + (1 | Subject), data = Dat,
>> > family = "poisson", zeroInflation = TRUE) *
>> >
>> > and got the following error:
>> >
>> > Parameters were estimated, but standard errors were not: the most likely
>> > problem is that the curvature at MLE was zero or negative
>> > Error in glmmadmb(formula = Ges~ Condition + (1 | Subject), data = Dat,
>> > :
>> >   The function maximizer failed (couldn't find parameter file)
>> > Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> > output files; (2) change run parameters: see '?admbControl';(3) re-run
>> > with
>> > debug=TRUE for more information on failure mode
>> > In addition: Warning message:
>> > running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500
>> > -maxph
>> > 5 -noinit -shess' had status 1
>> >
>> > When I ran it with debug=TRUE, I got the following output:
>> >
>> > Parameters were estimated, but standard errors were not: the most likely
>> > problem is that the curvature at MLE was zero or negative
>> > run failed:  Initial statistics: 7 variables; iteration 0; function
>> > evaluation 0; phase 1 Function value  3.7639324e+002; maximum gradient
>> > component mag  1.2938e+001 Var   Value    Gradient   |Var   Value
>> >  Gradient   |Var   Value    Gradient   1  0.00000  1.2938e+001 |  2
>> >  0.00000  9.7086e-001 |  3  0.00000  1.6197e+000   4  0.00000
>> > -2.6734e+000
>> > |  5  0.00000 -5.9309e-002 |  6  0.00000 -2.6798e+000   7  0.00000
>> > -4.9402e-001 |   - final statistics: 7 variables; iteration 7; function
>> > evaluation 10 Function value  3.2460e+002; maximum gradient component
>> > mag
>> > -8.0580e-005 Exit code = 1;  converg criter  1.0000e-004 Var   Value
>> >  Gradient   |Var   Value    Gradient   |Var   Value    Gradient   1
>> > -7.41263  1.8275e-006 |  2 -0.58080  3.4938e-005 |  3 -0.99038
>> > 1.6835e-005
>> >   4  1.59079  8.0028e-005 |  5  0.06984  3.2566e-005 |  6  1.63706
>> > -8.0580e-005   7  0.32457  7.7648e-005 |  Initial statistics: 8
>> > variables;
>> > iteration 0; function evaluation 0; phase 2 Function value
>> > 3.2460159e+002;
>> > maxi... <truncated>
>> > Error in glmmadmb(formula = Ges ~ Condition + (1 | Subject), data = Dat,
>> > :
>> >   The function maximizer failed (couldn't find parameter file)
>> > Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> > output files; (2) change run parameters: see '?admbControl';(3) re-run
>> > with
>> > debug=TRUE for more information on failure mode
>> > In addition: Warning message:
>> > running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500
>> > -maxph
>> > 5 -noinit -shess' had status 1
>> > restored working directory to I:/xxxxx
>> > removed temp directory
>> > C:\Users\BO~1\AppData\Local\Temp\1\RtmpiwJxjv\glmmADMB12a03acd7a0c
>> >
>> >
>> > I tried adding another fixed effect and the model ran, but gave crazy
>> > values for the condition levels:
>> >
>> > Call:
>> > glmmadmb(formula = Ges ~ Condition + History + (1 | Subject),
>> >     data = Dat, family = "poisson", zeroInflation = TRUE)
>> >
>> > AIC: 257.9
>> >
>> > Coefficients:
>> >              Estimate Std. Error z value Pr(>|z|)
>> > (Intercept)    -91.28   91007.00    0.00    0.999
>> > ConditionB      89.63   91007.00    0.00    0.999
>> > ConditionBE     88.69   91007.00    0.00    0.999
>> > ConditionEYC    91.28   91007.00    0.00    0.999
>> > ConditionF      90.54   91007.00    0.00    0.999
>> > ConditionFE     91.17   91007.00    0.00    0.999
>> > ConditionHA     89.59   91007.00    0.00    0.999
>> > HistoryMR       -2.48       1.02   -2.43    0.015 *
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Number of observations: total=329, Subject=12
>> > Random effect variance(s):
>> > Group=Subject
>> >             Variance StdDev
>> > (Intercept)    1.837  1.355
>> >
>> > Zero-inflation: 0.15369  (std. err.:  0.13609 )
>> >
>> > Log-likelihood: -118.968
>> > Warning message:
>> > In .local(x, sigma, ...) :
>> >   'sigma' and 'rdig' arguments are present for compatibility only:
>> > ignored
>> >
>> >
>> >
>> > I tried changing some controls that people had suggested online, such as
>> >
>> >  *admb.opts=admbControl(shess=FALSE,noinit=FALSE)*
>> >
>> > but this didn't work with my model.
>> >
>> > Some issues with my data are that for one of the conditions, the count
>> > of
>> > Ges was 0 for all subjects. Similarly, for some subjects, the count for
>> > Ges
>> > was 0 across all conditions.
>> >
>> > I'd be extremely grateful if you had any advice.
>> >
>> > Jenny
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> ________________________________________
>
> Jennifer Botting, PhD Student
> Centre for Social Learning and Cognitive Evolution
> University of St Andrews
> KY16 9JP


From singmann at psychologie.uzh.ch  Fri Jan 13 18:06:59 2017
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Fri, 13 Jan 2017 18:06:59 +0100
Subject: [R-sig-ME] Understanding variance components
In-Reply-To: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
References: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
Message-ID: <7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>

Hi Gang,

Sorry that I so am late to the party, but in case you are still 
interested I will reply (and, of course, for the archive).

The answer is basically given in the old faq:
http://glmm.wikidot.com/faq#toc27

(1|site/block) = (1|site)+(1|site:block)

Which is exactly what is given in your output. A random intercept for 
Worker and a random intercept for each worker:Machine interaction.

To answer your questions. The random intercepts do not have base or 
reference levels. They are increments or decrements to the overall 
intercept for each level of Worker or the Machine:Worker combination. 
The reported variance is the estimated variance of these increments, 
which is most likely unequal to the actual variance you would obtain by 
calculating it from the estimated increments, which are sometimes called 
BLUPs (I wonder if a better term for those exist).

Hope that helps,
Henrik

PS: Belated Happy New Year to everyone.


Am 05.01.2017 um 17:28 schrieb Chen, Gang (NIH/NIMH) [C]:
> Suppose that I have the following dataset in R:
>
> library(lme4)
> data(Machines,package="nlme")
> mydata <- Machines[Machines$Machine!='C?,]
>
> With the following model:
>
> print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata), ranef.comp="Var")
>
> I have the variance components as shown below:
>
> Random effects:
>  Groups         Name        Variance
>  Machine:Worker (Intercept) 46.00
>  Worker         (Intercept) 13.84
>  Residual                    1.16
>
> I have trouble understanding exactly what the first two components are: Machine:Worker and Worker? Specifically,
>
> 1) What is the variance for Worker: corresponding to the base (or reference) level of the factor Machine? If so, what is the base level: the first level in the dataset or alphabetically the first level (it happens to be the same in this particular dataset)?
>
> 2) What is the variance for Machine:Worker? Is it the variance for the second level of the factor Machine, or the extra variance relative to the variance for Worker?
>
> Furthermore, for the model:
>
> print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines), ranef.comp="Var")
>
> what is the variance for Machine:Worker in the following result since there are 3 levels involved in the factor Machine?
>
> Random effects:
>  Groups         Name        Variance
>  Machine:Worker (Intercept) 60.2972
>  Worker         (Intercept)  7.3959
>  Residual                    0.9246
>
> Thanks,
> Gang
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Phillip.Alday at unisa.edu.au  Sat Jan 14 10:49:33 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Sat, 14 Jan 2017 09:49:33 +0000
Subject: [R-sig-ME] Understanding variance components
In-Reply-To: <7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
References: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
	<7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
Message-ID: <1484387373.32176.1.camel@unisa.edu.au>

On Fri, 2017-01-13 at 18:06 +0100, Henrik Singmann wrote:
> Hi Gang,
> 

:snip:
> The reported variance is the estimated variance of these increments,?
> which is most likely unequal to the actual variance you would obtain
> by?
> calculating it from the estimated increments, which are sometimes
> called?
> BLUPs (I wonder if a better term for those exist).
> 

I've seen them called "conditional modes" (in a vaguely Bayesian sense)
at some point by Doug Bates because of course they're not linear for
the GLMM case.

Best,
Phillip

> Hope that helps,
> Henrik
> 
> PS: Belated Happy New Year to everyone.
> 
> 
> Am 05.01.2017 um 17:28 schrieb Chen, Gang (NIH/NIMH) [C]:
> > 
> > Suppose that I have the following dataset in R:
> > 
> > library(lme4)
> > data(Machines,package="nlme")
> > mydata <- Machines[Machines$Machine!='C?,]
> > 
> > With the following model:
> > 
> > print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata),
> > ranef.comp="Var")
> > 
> > I have the variance components as shown below:
> > 
> > Random effects:
> > ?Groups?????????Name????????Variance
> > ?Machine:Worker (Intercept) 46.00
> > ?Worker?????????(Intercept) 13.84
> > ?Residual????????????????????1.16
> > 
> > I have trouble understanding exactly what the first two components
> > are: Machine:Worker and Worker? Specifically,
> > 
> > 1) What is the variance for Worker: corresponding to the base (or
> > reference) level of the factor Machine? If so, what is the base
> > level: the first level in the dataset or alphabetically the first
> > level (it happens to be the same in this particular dataset)?
> > 
> > 2) What is the variance for Machine:Worker? Is it the variance for
> > the second level of the factor Machine, or the extra variance
> > relative to the variance for Worker?
> > 
> > Furthermore, for the model:
> > 
> > print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines),
> > ranef.comp="Var")
> > 
> > what is the variance for Machine:Worker in the following result
> > since there are 3 levels involved in the factor Machine?
> > 
> > Random effects:
> > ?Groups?????????Name????????Variance
> > ?Machine:Worker (Intercept) 60.2972
> > ?Worker?????????(Intercept)??7.3959
> > ?Residual????????????????????0.9246
> > 
> > Thanks,
> > Gang
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From carolefantini at icloud.com  Sun Jan 15 07:31:05 2017
From: carolefantini at icloud.com (caroleperso)
Date: Sun, 15 Jan 2017 07:31:05 +0100
Subject: [R-sig-ME] x axis wrong with effects to plot an interaction based
	on lme4
Message-ID: <etPan.587b172a.61fb400b.6f88@icloud.com>

Hi
I have the following results based on a glmer Analysis :?

Random effects:
?Groups Name ? ? ? ?Variance Std.Dev.
?N ? ? ?(Intercept) 1.1885 ? 1.0902 ?
?STIM ? (Intercept) 0.2347 ? 0.4844 ?
Number of obs: 650, groups: ?N, 65; STIM, 10

Fixed effects:
? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|) ? ?
(Intercept) ?0.02678 ? ?0.22648 ? 0.118 ? 0.9059 ? ?
GDSc ? ? ? ?-0.45738 ? ?0.15979 ?-2.862 ? 0.0042 **?
MMSEc ? ? ? ?0.07461 ? ?0.04863 ? 1.534 ? 0.1250 ? ?
int ? ? ? ? ?0.69647 ? ?0.13217 ? 5.270 1.37e-07 ***
MMSEc:int ? ?0.04365 ? ?0.02043 ? 2.137 ? 0.0326 * ?

I have plot the interaction with the effect package

plot(allEffects(fear), multiline=TRUE)

however the x-axis is false limited to a max value of 2 while the max value is 3.84.
I have tried many things but that do not work at all. I also find curious that the values are integer while all are decimals.
any help?
many thanks
carole



	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sun Jan 15 19:54:21 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 15 Jan 2017 18:54:21 +0000
Subject: [R-sig-ME] x axis wrong with effects to plot an interaction
 based	on lme4
In-Reply-To: <etPan.587b172a.61fb400b.6f88@icloud.com>
References: <etPan.587b172a.61fb400b.6f88@icloud.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365C1165@FHSDB2D11-2.csu.mcmaster.ca>

Dear carole,

Without a reproducible example (your data and the commands you used to produce the results that you mention) it's impossible to answer your question.

Can you supply this information?

John

--------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of caroleperso
> Sent: Sunday, January 15, 2017 1:31 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] x axis wrong with effects to plot an interaction
> based on lme4
> 
> Hi
> I have the following results based on a glmer Analysis :
> 
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?N ? ? ?(Intercept) 1.1885 ? 1.0902
> ?STIM ? (Intercept) 0.2347 ? 0.4844
> Number of obs: 650, groups: ?N, 65; STIM, 10
> 
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ?0.02678 ? ?0.22648 ? 0.118 ? 0.9059 GDSc ? ? ? ?-
> 0.45738 ? ?0.15979 ?-2.862 ? 0.0042 **
> MMSEc ? ? ? ?0.07461 ? ?0.04863 ? 1.534 ? 0.1250
> int ? ? ? ? ?0.69647 ? ?0.13217 ? 5.270 1.37e-07 ***
> MMSEc:int ? ?0.04365 ? ?0.02043 ? 2.137 ? 0.0326 *
> 
> I have plot the interaction with the effect package
> 
> plot(allEffects(fear), multiline=TRUE)
> 
> however the x-axis is false limited to a max value of 2 while the max
> value is 3.84.
> I have tried many things but that do not work at all. I also find
> curious that the values are integer while all are decimals.
> any help?
> many thanks
> carole
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker at gmail.com  Sun Jan 15 20:21:32 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 15 Jan 2017 14:21:32 -0500
Subject: [R-sig-ME] x axis wrong with effects to plot an interaction
 based on lme4
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365C1165@FHSDB2D11-2.csu.mcmaster.ca>
References: <etPan.587b172a.61fb400b.6f88@icloud.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365C1165@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <eca73194-dfa5-59fb-0eaa-abdd738119d9@gmail.com>


  I agree with Prof. Fox that we need a reproducible example, but I'm
guessing that you made one of your variables into a factor at some point
along the way.


On 17-01-15 01:54 PM, Fox, John wrote:
> Dear carole,
> 
> Without a reproducible example (your data and the commands you used
> to produce the results that you mention) it's impossible to answer
> your question.
> 
> Can you supply this information?
> 
> John
> 
> -------------------------------------- John Fox, Professor McMaster
> University Hamilton, Ontario, Canada Web: socserv.mcmaster.ca/jfox
> 
> 
> 
>> -----Original Message----- From: R-sig-mixed-models
>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf Of
>> caroleperso Sent: Sunday, January 15, 2017 1:31 AM To:
>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] x axis wrong
>> with effects to plot an interaction based on lme4
>> 
>> Hi I have the following results based on a glmer Analysis :
>> 
>> Random effects: Groups Name        Variance Std.Dev. N
>> (Intercept) 1.1885   1.0902 STIM   (Intercept) 0.2347   0.4844 
>> Number of obs: 650, groups:  N, 65; STIM, 10
>> 
>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> 0.02678    0.22648   0.118   0.9059 GDSc        - 0.45738
>> 0.15979  -2.862   0.0042 ** MMSEc        0.07461    0.04863   1.534
>> 0.1250 int          0.69647    0.13217   5.270 1.37e-07 *** 
>> MMSEc:int    0.04365    0.02043   2.137   0.0326 *
>> 
>> I have plot the interaction with the effect package
>> 
>> plot(allEffects(fear), multiline=TRUE)
>> 
>> however the x-axis is false limited to a max value of 2 while the
>> max value is 3.84. I have tried many things but that do not work at
>> all. I also find curious that the values are integer while all are
>> decimals. any help? many thanks carole
>> 
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From joaquin.aldabe at gmail.com  Mon Jan 16 20:06:17 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 16 Jan 2017 16:06:17 -0300
Subject: [R-sig-ME] modeling question
Message-ID: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>

Dear all, I'm interested in modeling the effect of invertebrate biomass on
the density of a grassland shorebird (they eat invertebrates). For this, I
picked 8 plots and sampled invertebrates and birds 6 times in each plot for
about 30 days. This is, I went to each plot and did repeated measures of
invertebrates biomass and shorebird density separated in time by four or
five days, as invertebrates biomass may change over time and it is expected
that birds density change accordingly.

So, I'm trying to see a general pattern of the effect of changes in biomass
on the density of this shorebird species at a plot scale. Plot identity is
not important; I consider them as particular events of a random process.

Is this model correct:

lme(Bird.density~Invertebrate biomass, random=~1|Plot_identity, data=)

Thank you very much,

Joaquin.


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jan 16 22:59:52 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 Jan 2017 16:59:52 -0500
Subject: [R-sig-ME] modeling question
In-Reply-To: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
Message-ID: <CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>

That seems perfectly reasonable.  There are a couple of things to
consider, although you may or may not find that your data supports
that much complexity.

(1) The relationship between bird density and invert biomass, as well
as the intercept (i.e., expected bird density at invert_biomass=0, or
better invert_biomass=<some sensible reference quantity>)

lme(Bird.density~Invertebrate biomass,
random=~invert_biomass|Plot_identity, data=)


(2) The relationship might be changing over time?

lme(Bird.density~Invertebrate biomass+sample_time,
random=~invert_biomass|Plot_identity, data=)

(3) In principle you could consider random effects of both time and
invert biomass, but that will almost certainly overwhelm your data.

  Don't forget to do the standard post-fitting checks: are your
residuals *approximately* equal-variance and (even more approximately)
Normally distributed?  Is the relationship between bird density and
invert biomass *approximately* linear?  (See ?plot.lme)


On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
<joaquin.aldabe at gmail.com> wrote:
> Dear all, I'm interested in modeling the effect of invertebrate biomass on
> the density of a grassland shorebird (they eat invertebrates). For this, I
> picked 8 plots and sampled invertebrates and birds 6 times in each plot for
> about 30 days. This is, I went to each plot and did repeated measures of
> invertebrates biomass and shorebird density separated in time by four or
> five days, as invertebrates biomass may change over time and it is expected
> that birds density change accordingly.
>
> So, I'm trying to see a general pattern of the effect of changes in biomass
> on the density of this shorebird species at a plot scale. Plot identity is
> not important; I consider them as particular events of a random process.
>
> Is this model correct:
>
> lme(Bird.density~Invertebrate biomass, random=~1|Plot_identity, data=)
>
> Thank you very much,
>
> Joaquin.
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From joaquin.aldabe at gmail.com  Mon Jan 16 23:44:26 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 16 Jan 2017 19:44:26 -0300
Subject: [R-sig-ME] modeling question
In-Reply-To: <CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
Message-ID: <CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>

Thankyou very much Ben. Can you please suggest a way of fixing some
sensible reference quantity for Invertebrate biomass?
All the best,
Joaqu?n

2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

> That seems perfectly reasonable.  There are a couple of things to
> consider, although you may or may not find that your data supports
> that much complexity.
>
> (1) The relationship between bird density and invert biomass, as well
> as the intercept (i.e., expected bird density at invert_biomass=0, or
> better invert_biomass=<some sensible reference quantity>)
>
> lme(Bird.density~Invertebrate biomass,
> random=~invert_biomass|Plot_identity, data=)
>
>
> (2) The relationship might be changing over time?
>
> lme(Bird.density~Invertebrate biomass+sample_time,
> random=~invert_biomass|Plot_identity, data=)
>
> (3) In principle you could consider random effects of both time and
> invert biomass, but that will almost certainly overwhelm your data.
>
>   Don't forget to do the standard post-fitting checks: are your
> residuals *approximately* equal-variance and (even more approximately)
> Normally distributed?  Is the relationship between bird density and
> invert biomass *approximately* linear?  (See ?plot.lme)
>
>
> On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com> wrote:
> > Dear all, I'm interested in modeling the effect of invertebrate biomass
> on
> > the density of a grassland shorebird (they eat invertebrates). For this,
> I
> > picked 8 plots and sampled invertebrates and birds 6 times in each plot
> for
> > about 30 days. This is, I went to each plot and did repeated measures of
> > invertebrates biomass and shorebird density separated in time by four or
> > five days, as invertebrates biomass may change over time and it is
> expected
> > that birds density change accordingly.
> >
> > So, I'm trying to see a general pattern of the effect of changes in
> biomass
> > on the density of this shorebird species at a plot scale. Plot identity
> is
> > not important; I consider them as particular events of a random process.
> >
> > Is this model correct:
> >
> > lme(Bird.density~Invertebrate biomass, random=~1|Plot_identity, data=)
> >
> > Thank you very much,
> >
> > Joaquin.
> >
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jan 16 23:49:20 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 Jan 2017 17:49:20 -0500
Subject: [R-sig-ME] modeling question
In-Reply-To: <CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
	<CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
Message-ID: <8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>


  Center your biomass variable on this value: either create a

  mydata$invert_biomass_c <- mydata$invert_biomass-ref_value

or include it directly in your formula:

   bird_dens ~ I(invert_biomass-ref_value), ...

On 17-01-16 05:44 PM, Joaqu?n Aldabe wrote:
> Thankyou very much Ben. Can you please suggest a way of fixing some
> sensible reference quantity for Invertebrate biomass?
> All the best,
> Joaqu?n
> 
> 2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>>:
> 
>     That seems perfectly reasonable.  There are a couple of things to
>     consider, although you may or may not find that your data supports
>     that much complexity.
> 
>     (1) The relationship between bird density and invert biomass, as well
>     as the intercept (i.e., expected bird density at invert_biomass=0, or
>     better invert_biomass=<some sensible reference quantity>)
> 
>     lme(Bird.density~Invertebrate biomass,
>     random=~invert_biomass|Plot_identity, data=)
> 
> 
>     (2) The relationship might be changing over time?
> 
>     lme(Bird.density~Invertebrate biomass+sample_time,
>     random=~invert_biomass|Plot_identity, data=)
> 
>     (3) In principle you could consider random effects of both time and
>     invert biomass, but that will almost certainly overwhelm your data.
> 
>       Don't forget to do the standard post-fitting checks: are your
>     residuals *approximately* equal-variance and (even more approximately)
>     Normally distributed?  Is the relationship between bird density and
>     invert biomass *approximately* linear?  (See ?plot.lme)
> 
> 
>     On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
>     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
>     > Dear all, I'm interested in modeling the effect of invertebrate biomass on
>     > the density of a grassland shorebird (they eat invertebrates). For this, I
>     > picked 8 plots and sampled invertebrates and birds 6 times in each plot for
>     > about 30 days. This is, I went to each plot and did repeated measures of
>     > invertebrates biomass and shorebird density separated in time by four or
>     > five days, as invertebrates biomass may change over time and it is expected
>     > that birds density change accordingly.
>     >
>     > So, I'm trying to see a general pattern of the effect of changes in biomass
>     > on the density of this shorebird species at a plot scale. Plot identity is
>     > not important; I consider them as particular events of a random process.
>     >
>     > Is this model correct:
>     >
>     > lme(Bird.density~Invertebrate biomass, random=~1|Plot_identity, data=)
>     >
>     > Thank you very much,
>     >
>     > Joaquin.
>     >
>     >
>     > --
>     > *Joaqu?n Aldabe*
>     >
>     > *Grupo Biodiversidad, Ambiente y Sociedad*
>     > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     >
>     > *Departamento de Conservaci?n*
>     > Aves Uruguay
>     > BirdLife International
>     > Canelones 1164, Montevideo
>     >
>     > https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/joaquin.aldabe>
>     > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> 
> -- 
> *Joaqu?n Aldabe*
> 
> /Grupo Biodiversidad, Ambiente y Sociedad/
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha  
>                                                            
> /Departamento de Conservaci?n/
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
> 
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> 
> 
>


From chung.huey.wu at gmail.com  Wed Jan 18 05:59:39 2017
From: chung.huey.wu at gmail.com (Chung-Huey Wu)
Date: Wed, 18 Jan 2017 04:59:39 +0000
Subject: [R-sig-ME] Random effect 'overlap' with fixed effect
Message-ID: <CAGEiFWzGfhwCk5i1SYG+MhO-x1VivtaVG7by_9TX8ke0i6CJ0g@mail.gmail.com>

Hello all,

This is my first post in r-sig-ME. I have benefited and learned a lot from
the threads here. In this email I would like to ask for comments on the
correct way to specify my random effect term (sampling site), which
'overlap' with the fixed effect of main interest (altitude).

I am now using nlme, lme4, and glmmADMB to analyze altitudinal survey data
of plant traits.

Below is the structure of the data I am now have trouble analyzing:
=======================================
a) Research design: In every Jan, Apr, Jul, Oct from Jul-2012 to Oct-2015,
we visited the 3 sites at low altitude and 3 sites at medium altitude,
haphazardly selected 6 individual plants of the focal species, and measured
traits and # herbivore for each individual.

b) Hypothesis to test:  Does the trait/# herbivore vary across altitude and
month? Are there interactions?

c) Notations:
alt (altitude): L (low) vs. M (medium); a 2-level factor.
m (month): Jan, Apr, Jul, Oct; a 4-level factor.
site (sampling site): 3 at low- and 3 at medium-altitude Taiwan; a 6-level
factor with unique location names.
y (year of survey): 2012-2015; a 4-level factor.
--------
C_count (# chewing herbivore):  discrete (count) response variable. Many
zeros, mostly 1-3, a few large values (10,17,22).
mT (physical leaf toughness): continuous response variable.


d) My model structure and outputs:
mod_T = lme(mT ~ m + alt + m:alt, random = ~ 1|site/y,
                 weights = varIdent(form = ~1|alt),
                 contrasts = c(list(m=contr.sum,alt=contr.sum)),
                 na.action = "na.omit", data = dat))
#### weights model form (1|alt) is AIC-selected to control
for heteroskedasticity.

Linear mixed-effects model fit by REML
 Data: dat
       AIC      BIC    logLik
  3533.131 3591.853 -1752.565

Random effects:
Formula: ~1 | site
             (Intercept)
StdDev:    5.603294

Formula: ~1 | y %in% site
               (Intercept)  Residual
StdDev:    4.142521  9.003203

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | m
 Parameter estimates:
     July       Oct       Jan       Apr
1.0000000 0.7836473 0.7696658 1.0022467

Fixed effects: mT ~ m + alt + m:alt
                  Value     Std.Error  DF    t-value      p-value
(Intercept) 39.38305  3.590926  468 10.967380  0.0000
mApr         7.57426   1.548235  468  4.892190   0.0000
mJuly        8.44167   1.457696  468  5.791103   0.0000
mOct         4.19561   1.300168  468  3.226973   0.0013
altM          -2.72082   5.093589   4   -0.534166   0.6215
mApr:altM   -2.31793  2.224683 468 -1.041916   0.2980
mJuly:altM  -3.14538  2.098787 468 -1.498666   0.1346
mOct:altM   -3.09390  1.880431 468 -1.645314   0.1006
 Correlation:
           (Intr) mApr   mJuly  mOct   altM   mApr:M mJly:M
mApr       -0.160
mJuly      -0.191  0.394
mOct       -0.214  0.442  0.527
altM       -0.705  0.113  0.135  0.151
mApr:altM   0.111 -0.696 -0.274 -0.307 -0.171
mJuly:altM  0.133 -0.274 -0.695 -0.366 -0.201  0.414
mOct:altM   0.148 -0.305 -0.364 -0.691 -0.225  0.462  0.546

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.49626272 -0.70206429 -0.03138199  0.59483874  3.00467177

Number of Observations: 498
Number of Groups:
       site y %in% site
          6          24

------------------------------------------------------------------------------------------
mod_C = glmmadmb(C_count ~ m + alt + m:alt + (1|site/y),
                    family = "nbinom",
                    zeroInflation = TRUE, data= dat)
#### AIC(nbinom model) << AIC(poisson model), so use nbinom

AIC: 686.6

Coefficients:
                   Estimate Std. Error  z value  Pr(>|z|)
(Intercept)  -0.70537    0.47722   -1.48    0.1394
mApr          0.00304    0.63689    0.00    0.9962
mJuly         -1.24819    0.63544   -1.96   0.0495 *
mOct         -0.36723    0.60261   -0.61    0.5423
altM           -1.63873    0.73215   -2.24   0.0252 *
mApr:altM   0.81522    0.94844    0.86    0.3900
mJuly:altM  3.21364    0.88936    3.61    0.0003 ***
MonthOct:AltM   1.21148    0.89989    1.35    0.1782
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=499, Site=6, Site:Year=24
Random effect variance(s):
Group=Site
            Variance StdDev
(Intercept)  0.03713 0.1927
Group=Site:Year
            Variance StdDev
(Intercept)   0.2289 0.4785

Negative binomial dispersion parameter: 0.17887 (std. err.: 0.036541)
Zero-inflation: 1.0132e-06  (std. err.:  0.00013482 )

Log-likelihood: -331.319
Warning message:
In .local(x, sigma, ...) :
  'sigma' and 'rdig' arguments are present for compatibility only: ignored
================================================

My Questions:
1) Is it reasonable to include (1|site/y)? Since site effect is mixed up
with altitude effect (my main focus), I am worried that adding 'site' as
random effect would disturb the estimation of altitude effect (which seems
strong based on plotted data), or even cause estimation problem?  (for
example, in summary(mod_T), the DF of the 'altM' term is so small (4)
compared to models without site random effect (~480, attached below for
your reference)).
2) One step back, are lme() (for controlling heteroskedasticity) and
glmmadmb() (for accounting for zero-inflation) the right choices for this
analysis?


I would appreciate your comments and help.
Thank very much!

Chung-Huey Wu


####################################################
[WITHOUT site random effect]
mod_T = lme(mT ~ m + alt + m:alt, random = ~ 1|y,
                 weights = varIdent(form = ~1|alt),
                 contrasts = c(list(m=contr.sum,alt=contr.sum)),
                 na.action = "na.omit", data = dat))

Linear mixed-effects model fit by REML
 Data: dat
       AIC      BIC   logLik
  3672.361 3726.888 -1823.18

Random effects:
 Formula: ~1 | y
        (Intercept) Residual
StdDev:    3.515026 9.344131

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | m
 Parameter estimates:
     July       Oct       Jan       Apr
1.0000000 1.0896624 0.9214424 1.0804838
Fixed effects: mT ~ m + alt + m:alt
               Value Std.Error  DF   t-value p-value
(Intercept) 39.65193  2.135613 487 18.567007  0.0000
mApr         7.57426  1.805682 487  4.194680  0.0000
mJuly        8.17279  1.638495 487  4.987985  0.0000
mOct         3.92672  1.706423 487  2.301144  0.0218
altM        -3.48711  1.709890 487 -2.039375  0.0420
mApr:altM   -1.32758  2.588246 487 -0.512928  0.6082
mJuly:altM  -2.37910  2.312807 487 -1.028662  0.3041
mOct:altM   -2.32762  2.409046 487 -0.966198  0.3344
 Correlation:
           (Intr) mApr   mJuly  mOct   altM   mApr:M mJly:M
mApr       -0.356
mJuly      -0.421  0.464
mOct       -0.404  0.446  0.526
altM       -0.376  0.445  0.490  0.471
mApr:altM   0.248 -0.698 -0.324 -0.311 -0.661
mJuly:altM  0.278 -0.329 -0.682 -0.348 -0.739  0.488
mOct:altM   0.267 -0.316 -0.348 -0.684 -0.710  0.469  0.525

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-2.2019475 -0.7909630 -0.0548838  0.7254892  3.0912138

Number of Observations: 498
Number of Groups: 4
####################################################

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Jan 18 13:30:10 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 18 Jan 2017 13:30:10 +0100
Subject: [R-sig-ME] Random effect 'overlap' with fixed effect
In-Reply-To: <CAGEiFWzGfhwCk5i1SYG+MhO-x1VivtaVG7by_9TX8ke0i6CJ0g@mail.gmail.com>
References: <CAGEiFWzGfhwCk5i1SYG+MhO-x1VivtaVG7by_9TX8ke0i6CJ0g@mail.gmail.com>
Message-ID: <CAJuCY5x2c3gKOnZ8u0cixLd=FX3dwWL68fL4bzGH96FFFDCoQQ@mail.gmail.com>

Dear Chung-Huey,

You have 6 x 4 observations per site - year combination. That is sufficient
to use 1|site/year as random effect.
Site is an essential part of the design of your study. Therefore it should
be in the model. The site effect will take up information which is not
explained by the altitude. So if the altitude effect is smaller in
comparison to the site effect, then the site-to-site variation is more
important than the altitude effect.

Note that lots of zero's does not imply zero inflation see
https://rpubs.com/INBOstats/zeroinflation

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-18 5:59 GMT+01:00 Chung-Huey Wu <chung.huey.wu at gmail.com>:

> Hello all,
>
> This is my first post in r-sig-ME. I have benefited and learned a lot from
> the threads here. In this email I would like to ask for comments on the
> correct way to specify my random effect term (sampling site), which
> 'overlap' with the fixed effect of main interest (altitude).
>
> I am now using nlme, lme4, and glmmADMB to analyze altitudinal survey data
> of plant traits.
>
> Below is the structure of the data I am now have trouble analyzing:
> =======================================
> a) Research design: In every Jan, Apr, Jul, Oct from Jul-2012 to Oct-2015,
> we visited the 3 sites at low altitude and 3 sites at medium altitude,
> haphazardly selected 6 individual plants of the focal species, and measured
> traits and # herbivore for each individual.
>
> b) Hypothesis to test:  Does the trait/# herbivore vary across altitude and
> month? Are there interactions?
>
> c) Notations:
> alt (altitude): L (low) vs. M (medium); a 2-level factor.
> m (month): Jan, Apr, Jul, Oct; a 4-level factor.
> site (sampling site): 3 at low- and 3 at medium-altitude Taiwan; a 6-level
> factor with unique location names.
> y (year of survey): 2012-2015; a 4-level factor.
> --------
> C_count (# chewing herbivore):  discrete (count) response variable. Many
> zeros, mostly 1-3, a few large values (10,17,22).
> mT (physical leaf toughness): continuous response variable.
>
>
> d) My model structure and outputs:
> mod_T = lme(mT ~ m + alt + m:alt, random = ~ 1|site/y,
>                  weights = varIdent(form = ~1|alt),
>                  contrasts = c(list(m=contr.sum,alt=contr.sum)),
>                  na.action = "na.omit", data = dat))
> #### weights model form (1|alt) is AIC-selected to control
> for heteroskedasticity.
>
> Linear mixed-effects model fit by REML
>  Data: dat
>        AIC      BIC    logLik
>   3533.131 3591.853 -1752.565
>
> Random effects:
> Formula: ~1 | site
>              (Intercept)
> StdDev:    5.603294
>
> Formula: ~1 | y %in% site
>                (Intercept)  Residual
> StdDev:    4.142521  9.003203
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | m
>  Parameter estimates:
>      July       Oct       Jan       Apr
> 1.0000000 0.7836473 0.7696658 1.0022467
>
> Fixed effects: mT ~ m + alt + m:alt
>                   Value     Std.Error  DF    t-value      p-value
> (Intercept) 39.38305  3.590926  468 10.967380  0.0000
> mApr         7.57426   1.548235  468  4.892190   0.0000
> mJuly        8.44167   1.457696  468  5.791103   0.0000
> mOct         4.19561   1.300168  468  3.226973   0.0013
> altM          -2.72082   5.093589   4   -0.534166   0.6215
> mApr:altM   -2.31793  2.224683 468 -1.041916   0.2980
> mJuly:altM  -3.14538  2.098787 468 -1.498666   0.1346
> mOct:altM   -3.09390  1.880431 468 -1.645314   0.1006
>  Correlation:
>            (Intr) mApr   mJuly  mOct   altM   mApr:M mJly:M
> mApr       -0.160
> mJuly      -0.191  0.394
> mOct       -0.214  0.442  0.527
> altM       -0.705  0.113  0.135  0.151
> mApr:altM   0.111 -0.696 -0.274 -0.307 -0.171
> mJuly:altM  0.133 -0.274 -0.695 -0.366 -0.201  0.414
> mOct:altM   0.148 -0.305 -0.364 -0.691 -0.225  0.462  0.546
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.49626272 -0.70206429 -0.03138199  0.59483874  3.00467177
>
> Number of Observations: 498
> Number of Groups:
>        site y %in% site
>           6          24
>
> ------------------------------------------------------------
> ------------------------------
> mod_C = glmmadmb(C_count ~ m + alt + m:alt + (1|site/y),
>                     family = "nbinom",
>                     zeroInflation = TRUE, data= dat)
> #### AIC(nbinom model) << AIC(poisson model), so use nbinom
>
> AIC: 686.6
>
> Coefficients:
>                    Estimate Std. Error  z value  Pr(>|z|)
> (Intercept)  -0.70537    0.47722   -1.48    0.1394
> mApr          0.00304    0.63689    0.00    0.9962
> mJuly         -1.24819    0.63544   -1.96   0.0495 *
> mOct         -0.36723    0.60261   -0.61    0.5423
> altM           -1.63873    0.73215   -2.24   0.0252 *
> mApr:altM   0.81522    0.94844    0.86    0.3900
> mJuly:altM  3.21364    0.88936    3.61    0.0003 ***
> MonthOct:AltM   1.21148    0.89989    1.35    0.1782
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Number of observations: total=499, Site=6, Site:Year=24
> Random effect variance(s):
> Group=Site
>             Variance StdDev
> (Intercept)  0.03713 0.1927
> Group=Site:Year
>             Variance StdDev
> (Intercept)   0.2289 0.4785
>
> Negative binomial dispersion parameter: 0.17887 (std. err.: 0.036541)
> Zero-inflation: 1.0132e-06  (std. err.:  0.00013482 )
>
> Log-likelihood: -331.319
> Warning message:
> In .local(x, sigma, ...) :
>   'sigma' and 'rdig' arguments are present for compatibility only: ignored
> ================================================
>
> My Questions:
> 1) Is it reasonable to include (1|site/y)? Since site effect is mixed up
> with altitude effect (my main focus), I am worried that adding 'site' as
> random effect would disturb the estimation of altitude effect (which seems
> strong based on plotted data), or even cause estimation problem?  (for
> example, in summary(mod_T), the DF of the 'altM' term is so small (4)
> compared to models without site random effect (~480, attached below for
> your reference)).
> 2) One step back, are lme() (for controlling heteroskedasticity) and
> glmmadmb() (for accounting for zero-inflation) the right choices for this
> analysis?
>
>
> I would appreciate your comments and help.
> Thank very much!
>
> Chung-Huey Wu
>
>
> ####################################################
> [WITHOUT site random effect]
> mod_T = lme(mT ~ m + alt + m:alt, random = ~ 1|y,
>                  weights = varIdent(form = ~1|alt),
>                  contrasts = c(list(m=contr.sum,alt=contr.sum)),
>                  na.action = "na.omit", data = dat))
>
> Linear mixed-effects model fit by REML
>  Data: dat
>        AIC      BIC   logLik
>   3672.361 3726.888 -1823.18
>
> Random effects:
>  Formula: ~1 | y
>         (Intercept) Residual
> StdDev:    3.515026 9.344131
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | m
>  Parameter estimates:
>      July       Oct       Jan       Apr
> 1.0000000 1.0896624 0.9214424 1.0804838
> Fixed effects: mT ~ m + alt + m:alt
>                Value Std.Error  DF   t-value p-value
> (Intercept) 39.65193  2.135613 487 18.567007  0.0000
> mApr         7.57426  1.805682 487  4.194680  0.0000
> mJuly        8.17279  1.638495 487  4.987985  0.0000
> mOct         3.92672  1.706423 487  2.301144  0.0218
> altM        -3.48711  1.709890 487 -2.039375  0.0420
> mApr:altM   -1.32758  2.588246 487 -0.512928  0.6082
> mJuly:altM  -2.37910  2.312807 487 -1.028662  0.3041
> mOct:altM   -2.32762  2.409046 487 -0.966198  0.3344
>  Correlation:
>            (Intr) mApr   mJuly  mOct   altM   mApr:M mJly:M
> mApr       -0.356
> mJuly      -0.421  0.464
> mOct       -0.404  0.446  0.526
> altM       -0.376  0.445  0.490  0.471
> mApr:altM   0.248 -0.698 -0.324 -0.311 -0.661
> mJuly:altM  0.278 -0.329 -0.682 -0.348 -0.739  0.488
> mOct:altM   0.267 -0.316 -0.348 -0.684 -0.710  0.469  0.525
>
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -2.2019475 -0.7909630 -0.0548838  0.7254892  3.0912138
>
> Number of Observations: 498
> Number of Groups: 4
> ####################################################
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From eliecer.diaz at helsinki.fi  Wed Jan 18 16:47:58 2017
From: eliecer.diaz at helsinki.fi (Diaz, Eliecer R)
Date: Wed, 18 Jan 2017 15:47:58 +0000
Subject: [R-sig-ME] Mixed additive model question
Message-ID: <DB6PR0701MB228081937286A2996EE91176857F0@DB6PR0701MB2280.eurprd07.prod.outlook.com>

I am an ecologist, and this is my first time in this forum. I have data concerning plant cover (continuous variable ranging from 0-100%); I am trying to explain plant cover in relationship to the following covariables: habitat (factor: two habitats, pools and rocks:), Temperature (air temperature in the days when the plant cover was sampled among patches), patch (Factor: 12 fixed spots per habitat), and finally to 2 continuous covariables: i. elevation of the substratum and the density of grazers (average along time, so it did not change temporally) in each patch.


I found heterogeneity in the residuals versus the covariable Temperature so I try to reduce them using this following model:


M1 <-   gamm(PlantCover ~ factor(Habitat) + Elevation + Grazers + s(Temperature),

                                random =~ 1 | Patch,                                       #Patch is a factor

                                weights = varIdent(form=~ 1 | Habitat),            #Habitat is a factor

                                correlation = corAR1(form=~ 1 | Temperature) #Temp is numeric month temperature

                                method = "REML",

                                data = plants,

 family = "gaussian")


Alternatively, I have this model:


M2  <- gamm(Response ~  grazers + Elevation + s(Temperature) + Hab,

          random = list(Patch=~1),

          weights = varExp(form =~ grazers),

          method = "REML",

          data = Mac,

          correlation = corAR1(form=~ 1 | Temp),

          family = "gaussian")


These were my two best models after check fifteen versions:

Comparing only these two in terms of AIC output:

       AIC

M1: 6956

M2: 6693


Does someone see a error in the specification of the model??

M2, improves the residuals, although not totally, but this is the only I can manage to do by now. If someone has some suggestions you are welcomed!


Thanks,

Elis




	[[alternative HTML version deleted]]


From gangchen at mail.nih.gov  Wed Jan 18 23:18:45 2017
From: gangchen at mail.nih.gov (Chen, Gang (NIH/NIMH) [C])
Date: Wed, 18 Jan 2017 22:18:45 +0000
Subject: [R-sig-ME] Understanding variance components
In-Reply-To: <7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
References: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
	<7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
Message-ID: <6E20B8F6-56C9-496D-AFC0-EA43945DF49E@mail.nih.gov>

Happy New Year, Henrik! Thanks for explaining the details. A couple of days after I posted the question, I realized that my question was silly! Once I laid out the LME model equation, my original confusion was resolved.

Actually I meant to ask a slightly different question. Let me use the dataset embedded in your ?afex? package as an example:

data(obk.long, package = "afex?)

Suppose that my base model is

lmer(value ~ gender*phase+(1|id), data=obk.long)

Is there a way to specify a different variance for each gender in one model?

Thanks,
Gang


> On Jan 13, 2017, at 12:06 PM, Henrik Singmann <singmann at psychologie.uzh.ch> wrote:
> 
> Hi Gang,
> 
> Sorry that I so am late to the party, but in case you are still interested I will reply (and, of course, for the archive).
> 
> The answer is basically given in the old faq:
> http://glmm.wikidot.com/faq#toc27
> 
> (1|site/block) = (1|site)+(1|site:block)
> 
> Which is exactly what is given in your output. A random intercept for Worker and a random intercept for each worker:Machine interaction.
> 
> To answer your questions. The random intercepts do not have base or reference levels. They are increments or decrements to the overall intercept for each level of Worker or the Machine:Worker combination. The reported variance is the estimated variance of these increments, which is most likely unequal to the actual variance you would obtain by calculating it from the estimated increments, which are sometimes called BLUPs (I wonder if a better term for those exist).
> 
> Hope that helps,
> Henrik
> 
> PS: Belated Happy New Year to everyone.
> 
> 
> Am 05.01.2017 um 17:28 schrieb Chen, Gang (NIH/NIMH) [C]:
>> Suppose that I have the following dataset in R:
>> 
>> library(lme4)
>> data(Machines,package="nlme")
>> mydata <- Machines[Machines$Machine!='C?,]
>> 
>> With the following model:
>> 
>> print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata), ranef.comp="Var")
>> 
>> I have the variance components as shown below:
>> 
>> Random effects:
>> Groups         Name        Variance
>> Machine:Worker (Intercept) 46.00
>> Worker         (Intercept) 13.84
>> Residual                    1.16
>> 
>> I have trouble understanding exactly what the first two components are: Machine:Worker and Worker? Specifically,
>> 
>> 1) What is the variance for Worker: corresponding to the base (or reference) level of the factor Machine? If so, what is the base level: the first level in the dataset or alphabetically the first level (it happens to be the same in this particular dataset)?
>> 
>> 2) What is the variance for Machine:Worker? Is it the variance for the second level of the factor Machine, or the extra variance relative to the variance for Worker?
>> 
>> Furthermore, for the model:
>> 
>> print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines), ranef.comp="Var")
>> 
>> what is the variance for Machine:Worker in the following result since there are 3 levels involved in the factor Machine?
>> 
>> Random effects:
>> Groups         Name        Variance
>> Machine:Worker (Intercept) 60.2972
>> Worker         (Intercept)  7.3959
>> Residual                    0.9246
>> 
>> Thanks,
>> Gang
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From rebecca.hooper at evobio.eu  Wed Jan 18 13:14:57 2017
From: rebecca.hooper at evobio.eu (Rebecca Hooper)
Date: Wed, 18 Jan 2017 12:14:57 +0000
Subject: [R-sig-ME] ZIPoisson MCMCglmm: potential non-independence of random
 effect repeat number and response variable
Message-ID: <CABN6br1Snwku=erkwN5Ziy85xga2MYjTqNSpnHPAhuTBj97P6Q@mail.gmail.com>

Dear List,

I am looking at the annual reproductive success of individuals relative to
their dispersal behaviour using ZIPoisson MCMCglmms.
The data is structured in such a way that individuals have one row per year
lived (so if they live to 5yo they have 5 rows).
Annual reproductive success (ARS) is the response variable and is zero
inflated (85% 0s).
Dispersal score per year is the predictor variable, and Individual ID is
the random effect.

ARS may not be independent of longevity, and thus the number of rows
individuals have in the data may not be independent of the response
variable (e.g. individuals that live longer, with more rows in the data,
may have decreased reproductive success per year relative to those that
live less long).

I don't know how this non-independence between the response variable and
the number of repeats of the random effect might effect the model results,
and would be very grateful for some insight into whether this is likely to
cause problems.

Many thanks,

Beki

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Jan 19 10:43:48 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 19 Jan 2017 09:43:48 +0000
Subject: [R-sig-ME] ZIPoisson MCMCglmm: potential non-independence of
 random effect repeat number and response variable
In-Reply-To: <CABN6br1Snwku=erkwN5Ziy85xga2MYjTqNSpnHPAhuTBj97P6Q@mail.gmail.com>
References: <CABN6br1Snwku=erkwN5Ziy85xga2MYjTqNSpnHPAhuTBj97P6Q@mail.gmail.com>
Message-ID: <e701a57c-2f74-b84d-673b-014add43c151@ed.ac.uk>

Hi,

Mixed models deal with unbalanced data so having a variable number of 
observations per animal is not a problem. However, if the number of 
observations is correlated with the outcome you have to remember that 
the model is 'correcting' for this. For example, imagine 20 individuals 
have 2 observations and an expected outcome of 1, and 20 individuals 
have 6 observations with an expected outcome of 2, the intercept will be 
(on average) 1.5 not 1.75 (the average across observations).

Cheers,

Jarrod



On 18/01/2017 12:14, Rebecca Hooper wrote:
> Dear List,
>
> I am looking at the annual reproductive success of individuals relative to
> their dispersal behaviour using ZIPoisson MCMCglmms.
> The data is structured in such a way that individuals have one row per year
> lived (so if they live to 5yo they have 5 rows).
> Annual reproductive success (ARS) is the response variable and is zero
> inflated (85% 0s).
> Dispersal score per year is the predictor variable, and Individual ID is
> the random effect.
>
> ARS may not be independent of longevity, and thus the number of rows
> individuals have in the data may not be independent of the response
> variable (e.g. individuals that live longer, with more rows in the data,
> may have decreased reproductive success per year relative to those that
> live less long).
>
> I don't know how this non-independence between the response variable and
> the number of repeats of the random effect might effect the model results,
> and would be very grateful for some insight into whether this is likely to
> cause problems.
>
> Many thanks,
>
> Beki
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From singmann at psychologie.uzh.ch  Thu Jan 19 12:13:24 2017
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Thu, 19 Jan 2017 12:13:24 +0100
Subject: [R-sig-ME] Understanding variance components
In-Reply-To: <6E20B8F6-56C9-496D-AFC0-EA43945DF49E@mail.nih.gov>
References: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
	<7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
	<6E20B8F6-56C9-496D-AFC0-EA43945DF49E@mail.nih.gov>
Message-ID: <1c407348-14e7-6a87-8f7a-ca9362480e17@psychologie.uzh.ch>

Hi Gang,

I have an idea which is based on the last example given on ?lmer:
## Fit sex-specific variances by constructing numeric dummy variables
...

I am not sure if this is entirely correct, but it looks good to me. If 
not, hopefully someone more knowledgeable will jump in.

## Original model without gender specific variance:
data(obk.long, package = "afex")

m1 <- lmer(value ~ gender*phase+(1|id), data=obk.long)
summary(m1)$varcor
## Groups   Name        Std.Dev.
## id       (Intercept) 1.6018
## Residual             1.4820
REMLcrit(m1)
## [1] 911.1599

## to get gender specific vari8ances, we construct two dummy variables:
obk.long$gender_F <- as.numeric(obk.long$gender == "F")
obk.long$gender_M <- as.numeric(obk.long$gender == "M")
m2 <- lmer(value ~ gender*phase+(0+gender_F|id)+(0+gender_M|id), 
data=obk.long)
summary(m2)$varcor
## Groups   Name     Std.Dev.
## id       gender_F 0.99723
## id.1     gender_M 2.03404
## Residual          1.48196
REMLcrit(m2)
## [1] 908.297

So far, looks reasonably close. Same for the conditional modes (thx 
Phillip). Left two columns is separate, right is joint variance.
cbind(ranef(m2)$id, rep(NA, 16), ranef(m1)$id)
##      gender_F   gender_M rep(NA, 16) (Intercept)
## 1   0.0000000 -3.0986753          NA  -3.0351426
## 2   0.0000000 -2.1328544          NA  -2.0891242
## 3   0.0000000  0.1207276          NA   0.1182523
## 4  -0.9806229  0.0000000          NA  -1.0642708
## 5  -0.3995130  0.0000000          NA  -0.4335918
## 6   0.0000000  2.6962499          NA   2.6409683
## 7   0.0000000  1.4084888          NA   1.3796103
## 8  -0.3995130  0.0000000          NA  -0.4335918
## 9  -0.6900680  0.0000000          NA  -0.7489313
## 10  0.0000000  0.4426679          NA   0.4335918
## 11  0.0000000 -1.1670336          NA  -1.1431057
## 12  0.0000000  1.7304291          NA   1.6949498
## 13  1.3438166  0.0000000          NA   1.4584452
## 14 -0.6900680  0.0000000          NA  -0.7489313
## 15  0.4721518  0.0000000          NA   0.5124267
## 16  1.3438166  0.0000000          NA   1.4584452

And, finally, the same for the fixed effects:
fixef(m1)
##       (Intercept)           genderM         phasepost
##      6.000000e+00      7.500000e-01     -6.250000e-01
##          phasepre genderM:phasepost  genderM:phasepre
##     -2.000000e+00     -1.243450e-15     -1.687539e-15
fixef(m2)
##      (Intercept)           genderM         phasepost
##     6.000000e+00      7.500000e-01     -6.250000e-01
##         phasepre genderM:phasepost  genderM:phasepre
##    -2.000000e+00      1.829648e-14      1.820766e-14

Hope that helps,
Henrik


Am 18.01.2017 um 23:18 schrieb Chen, Gang (NIH/NIMH) [C]:
> Happy New Year, Henrik! Thanks for explaining the details. A couple of days after I posted the question, I realized that my question was silly! Once I laid out the LME model equation, my original confusion was resolved.
>
> Actually I meant to ask a slightly different question. Let me use the dataset embedded in your ?afex? package as an example:
>
> data(obk.long, package = "afex?)
>
> Suppose that my base model is
>
> lmer(value ~ gender*phase+(1|id), data=obk.long)
>
> Is there a way to specify a different variance for each gender in one model?
>
> Thanks,
> Gang
>
>
>> On Jan 13, 2017, at 12:06 PM, Henrik Singmann <singmann at psychologie.uzh.ch> wrote:
>>
>> Hi Gang,
>>
>> Sorry that I so am late to the party, but in case you are still interested I will reply (and, of course, for the archive).
>>
>> The answer is basically given in the old faq:
>> http://glmm.wikidot.com/faq#toc27
>>
>> (1|site/block) = (1|site)+(1|site:block)
>>
>> Which is exactly what is given in your output. A random intercept for Worker and a random intercept for each worker:Machine interaction.
>>
>> To answer your questions. The random intercepts do not have base or reference levels. They are increments or decrements to the overall intercept for each level of Worker or the Machine:Worker combination. The reported variance is the estimated variance of these increments, which is most likely unequal to the actual variance you would obtain by calculating it from the estimated increments, which are sometimes called BLUPs (I wonder if a better term for those exist).
>>
>> Hope that helps,
>> Henrik
>>
>> PS: Belated Happy New Year to everyone.
>>
>>
>> Am 05.01.2017 um 17:28 schrieb Chen, Gang (NIH/NIMH) [C]:
>>> Suppose that I have the following dataset in R:
>>>
>>> library(lme4)
>>> data(Machines,package="nlme")
>>> mydata <- Machines[Machines$Machine!='C?,]
>>>
>>> With the following model:
>>>
>>> print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata), ranef.comp="Var")
>>>
>>> I have the variance components as shown below:
>>>
>>> Random effects:
>>> Groups         Name        Variance
>>> Machine:Worker (Intercept) 46.00
>>> Worker         (Intercept) 13.84
>>> Residual                    1.16
>>>
>>> I have trouble understanding exactly what the first two components are: Machine:Worker and Worker? Specifically,
>>>
>>> 1) What is the variance for Worker: corresponding to the base (or reference) level of the factor Machine? If so, what is the base level: the first level in the dataset or alphabetically the first level (it happens to be the same in this particular dataset)?
>>>
>>> 2) What is the variance for Machine:Worker? Is it the variance for the second level of the factor Machine, or the extra variance relative to the variance for Worker?
>>>
>>> Furthermore, for the model:
>>>
>>> print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines), ranef.comp="Var")
>>>
>>> what is the variance for Machine:Worker in the following result since there are 3 levels involved in the factor Machine?
>>>
>>> Random effects:
>>> Groups         Name        Variance
>>> Machine:Worker (Intercept) 60.2972
>>> Worker         (Intercept)  7.3959
>>> Residual                    0.9246
>>>
>>> Thanks,
>>> Gang
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From gangchen at mail.nih.gov  Thu Jan 19 16:14:26 2017
From: gangchen at mail.nih.gov (Chen, Gang (NIH/NIMH) [C])
Date: Thu, 19 Jan 2017 15:14:26 +0000
Subject: [R-sig-ME] Understanding variance components
In-Reply-To: <6E20B8F6-56C9-496D-AFC0-EA43945DF49E@mail.nih.gov>
References: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
	<7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
	<6E20B8F6-56C9-496D-AFC0-EA43945DF49E@mail.nih.gov>
Message-ID: <4EDB92F4-B2B1-4F32-AF08-6531B2C60AFC@mail.nih.gov>

Nice, Henrik!

One thing we need to resolve, though, is this.

====================
The variances for model m1:

(1) intercept

summary(m1)$varcor$id[1]
[1] 2.565887

(2) residuals

attr(summary(m1)$varcor, "sc")^2
[1] 2.196212

====================
And the variances for model m2:

(1) female

summary(m2)$varcor$id[1]
[1] 0.9944589

(2) male

summary(m2)$varcor$id.1[1]
[1] 4.137316

(3) residuals

attr(summary(m2)$varcor, "sc")^2
[1] 2.196212
====================

It?s great to see that the residual variance matches between the two models m1 and m2. However, the intercept variance in m1, 2.565887, is not equal to the sum of female and male variances, 0.9944589 + 4.137316 = 5.131775. However, if we divide the total variance of female and male by 2, we have (0.9944589 + 4.137316)/2 = 2.565887. Why is that?

If we code the two groups as

obk.long$gender_F <- sqrt(2)*as.numeric(obk.long$gender == "F")
obk.long$gender_M <- sqrt(2)*as.numeric(obk.long$gender == "M?)

then we have the desired result,

m2 <- lmer(value ~ gender*phase+(0+gender_F|id)+(0+gender_M|id), data=obk.long)
summary(m2)$varcor$id[1]+summary(m2)$varcor$id.1[1]
[1] 2.565888

Even though the variance part is reconciled, I cannot come up with a good explanation as to why this coding strategy is required. Any thought?

Thanks,
Gang


On Jan 19, 2017, at 6:13 AM, Henrik Singmann <singmann at psychologie.uzh.ch<mailto:singmann at psychologie.uzh.ch>> wrote:

Hi Gang,

I have an idea which is based on the last example given on ?lmer:
## Fit sex-specific variances by constructing numeric dummy variables
...

I am not sure if this is entirely correct, but it looks good to me. If not, hopefully someone more knowledgeable will jump in.

## Original model without gender specific variance:
data(obk.long, package = "afex")

m1 <- lmer(value ~ gender*phase+(1|id), data=obk.long)
summary(m1)$varcor
## Groups   Name        Std.Dev.
## id       (Intercept) 1.6018
## Residual             1.4820
REMLcrit(m1)
## [1] 911.1599

## to get gender specific vari8ances, we construct two dummy variables:
obk.long$gender_F <- as.numeric(obk.long$gender == "F")
obk.long$gender_M <- as.numeric(obk.long$gender == "M")
m2 <- lmer(value ~ gender*phase+(0+gender_F|id)+(0+gender_M|id), data=obk.long)
summary(m2)$varcor
## Groups   Name     Std.Dev.
## id       gender_F 0.99723
## id.1     gender_M 2.03404
## Residual          1.48196
REMLcrit(m2)
## [1] 908.297

So far, looks reasonably close. Same for the conditional modes (thx Phillip). Left two columns is separate, right is joint variance.
cbind(ranef(m2)$id, rep(NA, 16), ranef(m1)$id)
##      gender_F   gender_M rep(NA, 16) (Intercept)
## 1   0.0000000 -3.0986753          NA  -3.0351426
## 2   0.0000000 -2.1328544          NA  -2.0891242
## 3   0.0000000  0.1207276          NA   0.1182523
## 4  -0.9806229  0.0000000          NA  -1.0642708
## 5  -0.3995130  0.0000000          NA  -0.4335918
## 6   0.0000000  2.6962499          NA   2.6409683
## 7   0.0000000  1.4084888          NA   1.3796103
## 8  -0.3995130  0.0000000          NA  -0.4335918
## 9  -0.6900680  0.0000000          NA  -0.7489313
## 10  0.0000000  0.4426679          NA   0.4335918
## 11  0.0000000 -1.1670336          NA  -1.1431057
## 12  0.0000000  1.7304291          NA   1.6949498
## 13  1.3438166  0.0000000          NA   1.4584452
## 14 -0.6900680  0.0000000          NA  -0.7489313
## 15  0.4721518  0.0000000          NA   0.5124267
## 16  1.3438166  0.0000000          NA   1.4584452

And, finally, the same for the fixed effects:
fixef(m1)
##       (Intercept)           genderM         phasepost
##      6.000000e+00      7.500000e-01     -6.250000e-01
##          phasepre genderM:phasepost  genderM:phasepre
##     -2.000000e+00     -1.243450e-15     -1.687539e-15
fixef(m2)
##      (Intercept)           genderM         phasepost
##     6.000000e+00      7.500000e-01     -6.250000e-01
##         phasepre genderM:phasepost  genderM:phasepre
##    -2.000000e+00      1.829648e-14      1.820766e-14

Hope that helps,
Henrik

On Jan 18, 2017, at 5:18 PM, Chen, Gang (NIH/NIMH) [C] <gangchen at mail.nih.gov<mailto:gangchen at mail.nih.gov>> wrote:

Happy New Year, Henrik! Thanks for explaining the details. A couple of days after I posted the question, I realized that my question was silly! Once I laid out the LME model equation, my original confusion was resolved.

Actually I meant to ask a slightly different question. Let me use the dataset embedded in your ?afex? package as an example:

data(obk.long, package = "afex?)

Suppose that my base model is

lmer(value ~ gender*phase+(1|id), data=obk.long)

Is there a way to specify a different variance for each gender in one model?

Thanks,
Gang


On Jan 13, 2017, at 12:06 PM, Henrik Singmann <singmann at psychologie.uzh.ch<mailto:singmann at psychologie.uzh.ch>> wrote:

Hi Gang,

Sorry that I so am late to the party, but in case you are still interested I will reply (and, of course, for the archive).

The answer is basically given in the old faq:
http://glmm.wikidot.com/faq#toc27

(1|site/block) = (1|site)+(1|site:block)

Which is exactly what is given in your output. A random intercept for Worker and a random intercept for each worker:Machine interaction.

To answer your questions. The random intercepts do not have base or reference levels. They are increments or decrements to the overall intercept for each level of Worker or the Machine:Worker combination. The reported variance is the estimated variance of these increments, which is most likely unequal to the actual variance you would obtain by calculating it from the estimated increments, which are sometimes called BLUPs (I wonder if a better term for those exist).

Hope that helps,
Henrik

PS: Belated Happy New Year to everyone.


Am 05.01.2017 um 17:28 schrieb Chen, Gang (NIH/NIMH) [C]:
Suppose that I have the following dataset in R:

library(lme4)
data(Machines,package="nlme")
mydata <- Machines[Machines$Machine!='C?,]

With the following model:

print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata), ranef.comp="Var")

I have the variance components as shown below:

Random effects:
Groups         Name        Variance
Machine:Worker (Intercept) 46.00
Worker         (Intercept) 13.84
Residual                    1.16

I have trouble understanding exactly what the first two components are: Machine:Worker and Worker? Specifically,

1) What is the variance for Worker: corresponding to the base (or reference) level of the factor Machine? If so, what is the base level: the first level in the dataset or alphabetically the first level (it happens to be the same in this particular dataset)?

2) What is the variance for Machine:Worker? Is it the variance for the second level of the factor Machine, or the extra variance relative to the variance for Worker?

Furthermore, for the model:

print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines), ranef.comp="Var")

what is the variance for Machine:Worker in the following result since there are 3 levels involved in the factor Machine?

Random effects:
Groups         Name        Variance
Machine:Worker (Intercept) 60.2972
Worker         (Intercept)  7.3959
Residual                    0.9246

Thanks,
Gang
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bimonosom at gmail.com  Thu Jan 19 16:55:00 2017
From: bimonosom at gmail.com (=?UTF-8?B?UmVuw6k=?=)
Date: Thu, 19 Jan 2017 16:55:00 +0100
Subject: [R-sig-ME] Understanding variance components
In-Reply-To: <4EDB92F4-B2B1-4F32-AF08-6531B2C60AFC@mail.nih.gov>
References: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
	<7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
	<6E20B8F6-56C9-496D-AFC0-EA43945DF49E@mail.nih.gov>
	<4EDB92F4-B2B1-4F32-AF08-6531B2C60AFC@mail.nih.gov>
Message-ID: <CADcpBHP3c9XAA-N9nRqVFZxeq6kwSktpoib_c62PuHTVnDqzdA@mail.gmail.com>

Hey Gang, hey Henrik (!) :)

very insightful query, hope it is okay that I briefly join it, on the last
question.
Variance is a result of division of squared deviations by sample size. In
the complete sample, this means divided by 240; and in the gender samples
by 120 each.
Have a look on the reversed equations for obtaining the overall variance by
combining gender groups, weighted by sample size:

(120 * 0.9944589   +   4.137316 * 120)/240 = overall variance (should be
equal to)  = (0.9944589 + 4.137316)/2   acording to your equation gang
left hand can be written as:
120 * (0.9944589   +   4.137316) / 240
which is:
(0.9944589   +   4.137316)/2

so nothing to worry, I think :)

Best wishes,
Ren?



2017-01-19 16:14 GMT+01:00 Chen, Gang (NIH/NIMH) [C] <gangchen at mail.nih.gov>
:

> Nice, Henrik!
>
> One thing we need to resolve, though, is this.
>
> ====================
> The variances for model m1:
>
> (1) intercept
>
> summary(m1)$varcor$id[1]
> [1] 2.565887
>
> (2) residuals
>
> attr(summary(m1)$varcor, "sc")^2
> [1] 2.196212
>
> ====================
> And the variances for model m2:
>
> (1) female
>
> summary(m2)$varcor$id[1]
> [1] 0.9944589
>
> (2) male
>
> summary(m2)$varcor$id.1[1]
> [1] 4.137316
>
> (3) residuals
>
> attr(summary(m2)$varcor, "sc")^2
> [1] 2.196212
> ====================
>
> It?s great to see that the residual variance matches between the two
> models m1 and m2. However, the intercept variance in m1, 2.565887, is not
> equal to the sum of female and male variances, 0.9944589 + 4.137316 =
> 5.131775. However, if we divide the total variance of female and male by 2,
> we have (0.9944589 + 4.137316)/2 = 2.565887. Why is that?
>
> If we code the two groups as
>
> obk.long$gender_F <- sqrt(2)*as.numeric(obk.long$gender == "F")
> obk.long$gender_M <- sqrt(2)*as.numeric(obk.long$gender == "M?)
>
> then we have the desired result,
>
> m2 <- lmer(value ~ gender*phase+(0+gender_F|id)+(0+gender_M|id),
> data=obk.long)
> summary(m2)$varcor$id[1]+summary(m2)$varcor$id.1[1]
> [1] 2.565888
>
> Even though the variance part is reconciled, I cannot come up with a good
> explanation as to why this coding strategy is required. Any thought?
>
> Thanks,
> Gang
>
>
> On Jan 19, 2017, at 6:13 AM, Henrik Singmann <singmann at psychologie.uzh.ch<
> mailto:singmann at psychologie.uzh.ch>> wrote:
>
> Hi Gang,
>
> I have an idea which is based on the last example given on ?lmer:
> ## Fit sex-specific variances by constructing numeric dummy variables
> ...
>
> I am not sure if this is entirely correct, but it looks good to me. If
> not, hopefully someone more knowledgeable will jump in.
>
> ## Original model without gender specific variance:
> data(obk.long, package = "afex")
>
> m1 <- lmer(value ~ gender*phase+(1|id), data=obk.long)
> summary(m1)$varcor
> ## Groups   Name        Std.Dev.
> ## id       (Intercept) 1.6018
> ## Residual             1.4820
> REMLcrit(m1)
> ## [1] 911.1599
>
> ## to get gender specific vari8ances, we construct two dummy variables:
> obk.long$gender_F <- as.numeric(obk.long$gender == "F")
> obk.long$gender_M <- as.numeric(obk.long$gender == "M")
> m2 <- lmer(value ~ gender*phase+(0+gender_F|id)+(0+gender_M|id),
> data=obk.long)
> summary(m2)$varcor
> ## Groups   Name     Std.Dev.
> ## id       gender_F 0.99723
> ## id.1     gender_M 2.03404
> ## Residual          1.48196
> REMLcrit(m2)
> ## [1] 908.297
>
> So far, looks reasonably close. Same for the conditional modes (thx
> Phillip). Left two columns is separate, right is joint variance.
> cbind(ranef(m2)$id, rep(NA, 16), ranef(m1)$id)
> ##      gender_F   gender_M rep(NA, 16) (Intercept)
> ## 1   0.0000000 -3.0986753          NA  -3.0351426
> ## 2   0.0000000 -2.1328544          NA  -2.0891242
> ## 3   0.0000000  0.1207276          NA   0.1182523
> ## 4  -0.9806229  0.0000000          NA  -1.0642708
> ## 5  -0.3995130  0.0000000          NA  -0.4335918
> ## 6   0.0000000  2.6962499          NA   2.6409683
> ## 7   0.0000000  1.4084888          NA   1.3796103
> ## 8  -0.3995130  0.0000000          NA  -0.4335918
> ## 9  -0.6900680  0.0000000          NA  -0.7489313
> ## 10  0.0000000  0.4426679          NA   0.4335918
> ## 11  0.0000000 -1.1670336          NA  -1.1431057
> ## 12  0.0000000  1.7304291          NA   1.6949498
> ## 13  1.3438166  0.0000000          NA   1.4584452
> ## 14 -0.6900680  0.0000000          NA  -0.7489313
> ## 15  0.4721518  0.0000000          NA   0.5124267
> ## 16  1.3438166  0.0000000          NA   1.4584452
>
> And, finally, the same for the fixed effects:
> fixef(m1)
> ##       (Intercept)           genderM         phasepost
> ##      6.000000e+00      7.500000e-01     -6.250000e-01
> ##          phasepre genderM:phasepost  genderM:phasepre
> ##     -2.000000e+00     -1.243450e-15     -1.687539e-15
> fixef(m2)
> ##      (Intercept)           genderM         phasepost
> ##     6.000000e+00      7.500000e-01     -6.250000e-01
> ##         phasepre genderM:phasepost  genderM:phasepre
> ##    -2.000000e+00      1.829648e-14      1.820766e-14
>
> Hope that helps,
> Henrik
>
> On Jan 18, 2017, at 5:18 PM, Chen, Gang (NIH/NIMH) [C] <
> gangchen at mail.nih.gov<mailto:gangchen at mail.nih.gov>> wrote:
>
> Happy New Year, Henrik! Thanks for explaining the details. A couple of
> days after I posted the question, I realized that my question was silly!
> Once I laid out the LME model equation, my original confusion was resolved.
>
> Actually I meant to ask a slightly different question. Let me use the
> dataset embedded in your ?afex? package as an example:
>
> data(obk.long, package = "afex?)
>
> Suppose that my base model is
>
> lmer(value ~ gender*phase+(1|id), data=obk.long)
>
> Is there a way to specify a different variance for each gender in one
> model?
>
> Thanks,
> Gang
>
>
> On Jan 13, 2017, at 12:06 PM, Henrik Singmann <singmann at psychologie.uzh.ch
> <mailto:singmann at psychologie.uzh.ch>> wrote:
>
> Hi Gang,
>
> Sorry that I so am late to the party, but in case you are still interested
> I will reply (and, of course, for the archive).
>
> The answer is basically given in the old faq:
> http://glmm.wikidot.com/faq#toc27
>
> (1|site/block) = (1|site)+(1|site:block)
>
> Which is exactly what is given in your output. A random intercept for
> Worker and a random intercept for each worker:Machine interaction.
>
> To answer your questions. The random intercepts do not have base or
> reference levels. They are increments or decrements to the overall
> intercept for each level of Worker or the Machine:Worker combination. The
> reported variance is the estimated variance of these increments, which is
> most likely unequal to the actual variance you would obtain by calculating
> it from the estimated increments, which are sometimes called BLUPs (I
> wonder if a better term for those exist).
>
> Hope that helps,
> Henrik
>
> PS: Belated Happy New Year to everyone.
>
>
> Am 05.01.2017 um 17:28 schrieb Chen, Gang (NIH/NIMH) [C]:
> Suppose that I have the following dataset in R:
>
> library(lme4)
> data(Machines,package="nlme")
> mydata <- Machines[Machines$Machine!='C?,]
>
> With the following model:
>
> print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata), ranef.comp="Var")
>
> I have the variance components as shown below:
>
> Random effects:
> Groups         Name        Variance
> Machine:Worker (Intercept) 46.00
> Worker         (Intercept) 13.84
> Residual                    1.16
>
> I have trouble understanding exactly what the first two components are:
> Machine:Worker and Worker? Specifically,
>
> 1) What is the variance for Worker: corresponding to the base (or
> reference) level of the factor Machine? If so, what is the base level: the
> first level in the dataset or alphabetically the first level (it happens to
> be the same in this particular dataset)?
>
> 2) What is the variance for Machine:Worker? Is it the variance for the
> second level of the factor Machine, or the extra variance relative to the
> variance for Worker?
>
> Furthermore, for the model:
>
> print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines),
> ranef.comp="Var")
>
> what is the variance for Machine:Worker in the following result since
> there are 3 levels involved in the factor Machine?
>
> Random effects:
> Groups         Name        Variance
> Machine:Worker (Intercept) 60.2972
> Worker         (Intercept)  7.3959
> Residual                    0.9246
>
> Thanks,
> Gang
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Thu Jan 19 19:08:51 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 19 Jan 2017 12:08:51 -0600
Subject: [R-sig-ME] nlme vs nlme4
Message-ID: <021cdb$5ke0q4@ironport10.mayo.edu>

I have a fit that works in nlme and fails in nlme4; I'd like to convert to the latter 
since I now need to use case weights and varFixed() + nlme leads to a lot of "wrong 
length" warnings.  (Google search suggests that this has sometimes been asked about but I 
don't find any anwsers).

As always, my first hypothesis is that I have some silly setup mistake.

# nlme code
tfun2 <- function(age, p1, p2,p3,p4, z)
     p1 + p2*(age+z- 60) + .5*(p4-p2)*((age+z-p3) + sqrt((age+z-p3)^2 +20))

dfun2 <- deriv(body(tfun2), c("p1", "p2", "p3", "p4", "z"),
               function.arg=tfun2)
init <- c(p1=1.2, p2=.03, p3=1, p4=1)

nfit1 <- nlme(y ~ dfun(age, p1, p2, p3, p4, z),
               fixed= p1 + p2 + p3 + p4  ~ 1,
               random= z~ 1|clinic, data=mydata, start=init,
               na.action=na.omit)
nfit1
   Fixed: p1 + p2 + p3 + p4 ~ 1
          p1          p2          p3          p4
  1.21516330  0.00237005 73.58059382  0.08424922

Random effects:
  Formula: z ~ 1 | clinic
                z   Residual
StdDev: 9.418258 0.06865345

---------------

# nlmer code
init2 <- c(p1=1.2, p2=.03, p3=1, p4=1, z=0)
mfit1 <- nlmer(y ~ dfun(age, p1, p2, p3, p4, z) ~
               0+ p1 + p2 + p3 + p4 + (0+z | clinic),
                data=mydata, start=init2, verbose=TRUE)
Error in devfun(rho$pp$theta) : Downdated VtV is not positive definite

------------------

I had to add z=0 to the start vector or else it complains that z is not found, apparently 
the derivative component of dfun is not enough to inform.

For those who want to know more:  This is essentially a change point model fit with a 
hyperbola.  The biomarker in question rises slowly with age, but for a substantial subset 
there is a fairly abrupt upward change in the slope sometime between the ages of 60 and 
90.  The trend line is 1.2 + .0024*(age-60), the average age of turn is 73.5, and the new 
slope is .086, and the std of turning age is 9.4.  The constant "20" in the formula is an 
arbitrary value that controls how sharp a turn the hyperbola makes.

I can provide an anonymized data set to someone (if this isn't just a silly error).  There 
are about 3000 data points.

Terry Therneau


From vito.muggeo at unipa.it  Sat Jan 21 20:25:53 2017
From: vito.muggeo at unipa.it (Vito Michele Rosario Muggeo)
Date: Sat, 21 Jan 2017 19:25:53 +0000
Subject: [R-sig-ME] nlme vs nlme4
In-Reply-To: <021cdb$5ke0q4@ironport10.mayo.edu>
Message-ID: <20170121192553.Horde.Z5PfiPZxFXFgqz5xCkmS5vw@webmail.unipa.it>

dear Terry,
I am sorry, but I don't have an answer to your question. However, as  
it could be of interest for you, I would like to point out a paper of  
mine dealing with piecewise (segmented) mixed models (or random  
changepoint) in a likelihood-based framework. The method uses no  
smooth approximation and it also allows random effects in the  
changepoint parameter. I have written some functions to fit such  
models in R. They should be included in the segmented package, but  
currently are available on RG. Here the links

http://journals.sagepub.com/doi/abs/10.1177/1471082X13504721 #paper
https://www.researchgate.net/publication/263222159

https://www.researchgate.net/publication/292629179 #some notes about  
the R functions

https://www.researchgate.net/publication/292986444 #R code with example

The code on RG works for basic examples, but I have an updated  
version. Let me know if you are interested in.
I hope this helps you,
best,
vito



"Therneau, Terry M., Ph.D." <therneau at mayo.edu> ha scritto:

> I have a fit that works in nlme and fails in nlme4; I'd like to  
> convert to the latter since I now need to use case weights and  
> varFixed() + nlme leads to a lot of "wrong length" warnings.   
> (Google search suggests that this has sometimes been asked about but  
> I don't find any anwsers).
>
> As always, my first hypothesis is that I have some silly setup mistake.
>
> # nlme code
> tfun2 <- function(age, p1, p2,p3,p4, z)
>     p1 + p2*(age+z- 60) + .5*(p4-p2)*((age+z-p3) + sqrt((age+z-p3)^2 +20))
>
> dfun2 <- deriv(body(tfun2), c("p1", "p2", "p3", "p4", "z"),
>               function.arg=tfun2)
> init <- c(p1=1.2, p2=.03, p3=1, p4=1)
>
> nfit1 <- nlme(y ~ dfun(age, p1, p2, p3, p4, z),
>               fixed= p1 + p2 + p3 + p4  ~ 1,
>               random= z~ 1|clinic, data=mydata, start=init,
>               na.action=na.omit)
> nfit1
>   Fixed: p1 + p2 + p3 + p4 ~ 1
>          p1          p2          p3          p4
>  1.21516330  0.00237005 73.58059382  0.08424922
>
> Random effects:
>  Formula: z ~ 1 | clinic
>                z   Residual
> StdDev: 9.418258 0.06865345
>
> ---------------
>
> # nlmer code
> init2 <- c(p1=1.2, p2=.03, p3=1, p4=1, z=0)
> mfit1 <- nlmer(y ~ dfun(age, p1, p2, p3, p4, z) ~
>               0+ p1 + p2 + p3 + p4 + (0+z | clinic),
>                data=mydata, start=init2, verbose=TRUE)
> Error in devfun(rho$pp$theta) : Downdated VtV is not positive definite
>
> ------------------
>
> I had to add z=0 to the start vector or else it complains that z is  
> not found, apparently the derivative component of dfun is not enough  
> to inform.
>
> For those who want to know more:  This is essentially a change point  
> model fit with a hyperbola.  The biomarker in question rises slowly  
> with age, but for a substantial subset there is a fairly abrupt  
> upward change in the slope sometime between the ages of 60 and 90.   
> The trend line is 1.2 + .0024*(age-60), the average age of turn is  
> 73.5, and the new slope is .086, and the std of turning age is 9.4.   
> The constant "20" in the formula is an arbitrary value that controls  
> how sharp a turn the hyperbola makes.
>
> I can provide an anonymized data set to someone (if this isn't just  
> a silly error).  There are about 3000 data points.
>
> Terry Therneau
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jasnie111 at gmail.com  Sat Jan 21 22:10:43 2017
From: jasnie111 at gmail.com (jas ni)
Date: Sat, 21 Jan 2017 21:10:43 +0000
Subject: [R-sig-ME] Need an advise on bias and MSE estimation
Message-ID: <CACEyfM-bq-65xXKc6OZ4Pk60ewMm0bFPrxmY5Z7hhuDJ5qmytQ@mail.gmail.com>

Hi guys,

I'm about to implement the comparison in my experimental work for missing
data through EM algorithm using regression.

I want to measure the bias and MSE on the parameters mean, beta1, beta2 and
sigma and my current references are from this papers (page 206):
https://pdfs.semanticscholar.org/2fa3/699c3db05cec276c3c356c921c68723fa80e.pdf
<https://www.researchgate.net/deref/https%3A%2F%2Fpdfs.semanticscholar.org%2F2fa3%2F699c3db05cec276c3c356c921c68723fa80e.pdf>
I do confuse between m and j variables.

I also refer to the attached paper and do confuse between t and j variables.
Both papers presented to measure the bias. But both equations has different
formula.

I could not implement the equation in R code because i do confuse with the
variables for instance, m and j as shown in the equation in paper 1.

I using the EM algorithm which is each iteration would produce the
parameter mean, variance and beta. But the parameter estimation values
would be generated based on the number of iteration but not based on the
number of records or data points.

If you could explain, why in the bias equation we need to sum the parameter
values up to the number of data points. For example, i have the Old
Faithful geyser dataset that contains 272 instances. Does it mean that i
should generate the 272 estimated mean, variances and betas and sum all of
them together?

- J

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Jan 22 00:32:02 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Jan 2017 18:32:02 -0500
Subject: [R-sig-ME] Need an advise on bias and MSE estimation
In-Reply-To: <CACEyfM-bq-65xXKc6OZ4Pk60ewMm0bFPrxmY5Z7hhuDJ5qmytQ@mail.gmail.com>
References: <CACEyfM-bq-65xXKc6OZ4Pk60ewMm0bFPrxmY5Z7hhuDJ5qmytQ@mail.gmail.com>
Message-ID: <a9ae5d37-c7d7-05c5-f213-182bc7fb4503@gmail.com>


  This question isn't really appropriate for this list, for a couple of
reasons: (1) it isn't about *mixed* models (which assume a continuous,
typically, Normal, mixture distribution rather than a discrete mixture
distribution); (2) it's pretty loosely related to R.  While someone
*might* help you here out of the goodness of their heart, I'd say that
the best places to get help would be (1) if you're a student, from your
professor or a senior student/colleague at your institution; (2)
http://stats.stackexchange.com .  If you ask in the latter place, it
would be good to reproduce the equations you're asking about in LaTeX
format within your question itself, to save people the trouble of
looking them up in the linked papers.

  good luck,
   Ben Bolker


On 17-01-21 04:10 PM, jas ni wrote:
> Hi guys,
> 
> I'm about to implement the comparison in my experimental work for missing
> data through EM algorithm using regression.
> 
> I want to measure the bias and MSE on the parameters mean, beta1, beta2 and
> sigma and my current references are from this papers (page 206):
> https://pdfs.semanticscholar.org/2fa3/699c3db05cec276c3c356c921c68723fa80e.pdf
> <https://www.researchgate.net/deref/https%3A%2F%2Fpdfs.semanticscholar.org%2F2fa3%2F699c3db05cec276c3c356c921c68723fa80e.pdf>
> I do confuse between m and j variables.
> 
> I also refer to the attached paper and do confuse between t and j variables.
> Both papers presented to measure the bias. But both equations has different
> formula.
> 
> I could not implement the equation in R code because i do confuse with the
> variables for instance, m and j as shown in the equation in paper 1.
> 
> I using the EM algorithm which is each iteration would produce the
> parameter mean, variance and beta. But the parameter estimation values
> would be generated based on the number of iteration but not based on the
> number of records or data points.
> 
> If you could explain, why in the bias equation we need to sum the parameter
> values up to the number of data points. For example, i have the Old
> Faithful geyser dataset that contains 272 instances. Does it mean that i
> should generate the 272 estimated mean, variances and betas and sum all of
> them together?
> 
> - J
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From stevenlong75x at gmail.com  Sun Jan 22 14:10:32 2017
From: stevenlong75x at gmail.com (Steven Long)
Date: Sun, 22 Jan 2017 14:10:32 +0100
Subject: [R-sig-ME] unreliable DIC vs. how to evaluate complex interactions
	in MCMCglmm
Message-ID: <CAMcBiJHTMrCsunY4v3ii77dMUR4KMeUjYLOUNSCNKCTWgpH_FQ@mail.gmail.com>

Dear List Members,

I have a mixed effects model setup, that would ideally incorporate
pedigree. This is why I started to run the models using MCMCglmm. As I am
unfamiliar with the latter approach I first tried everything using lme4 and
used AIC to compare the models. Then I rerun everything in MCMCglmm.
Neither of the model sets included pedigree at this stage.

My main concern is the very large difference in AIC vs. DIC based model
selection result.

I've attached my dataset. See my code here.






































*library(MCMCglmm)d2 <- read.csv("d2.csv")d2$f1 <- as.factor(d2$f1)d2$f2 <-
as.factor(d2$f2)n=8prior = list(R = list(V = n, fix = 1),              G =
list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> = 0, alpha.V =
1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 + pi^2/3)))m0
<-MCMCglmm(y ~ x1 +f1 +f2, random = ~ R,
data=d2,family='gaussian',             prior=prior,
nitt=101000,burnin=1000,thin=10)n=9prior = list(R = list(V = n, fix = 1),
             G = list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> =
0, alpha.V = 1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 +
pi^2/3)))m1 <-MCMCglmm(y ~ x1 +f1 +f2 +x2, random = ~ R,
data=d2,family='gaussian',             prior=prior,
nitt=101000,burnin=1000,thin=10)n=12prior = list(R = list(V = n, fix = 1),
             G = list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> =
0, alpha.V = 1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 +
pi^2/3)))m2 <-MCMCglmm(y ~ x1 +f1 +f2*x2, random = ~ R,
data=d2,family='gaussian',             prior=prior,
nitt=101000,burnin=1000,thin=10)n=15prior = list(R = list(V = n, fix = 1),
             G = list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> =
0, alpha.V = 1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 +
pi^2/3)))m3 <-MCMCglmm(y ~ x1 +f1*x1 +f2*x2, random = ~ R,
data=d2,family='gaussian',             prior=prior,
nitt=101000,burnin=1000,thin=10)m0$DIC; m1$DIC; m2$DIC; m3$DIC*

*# m0 -684.7527*

*# m1  -741.8908*

*# m2  -880.8456*

*# m3  -987.9276*







*library(lme4)M0 <- lmer(y ~ x1 +f1 +f2 +(1|R),REML=F, d2)M1 <- lmer(y ~ x1
+f1 +f2 +x2 +(1|R),REML=F, d2)M2 <- lmer(y ~ x1 +f1 +f2*x2 +(1|R),REML=F,
d2)M3 <- lmer(y ~ x1 +f1*x2 +f2*x2 +(1|R),REML=F, d2)AIC(M0);AIC(M1);
AIC(M2); AIC(M3)*

*# M0 -122.76*

*# M1 -122.8364*

*# M2 -118.4911*
*# M3 -113.0851*

So in conclusion, lme4 shows that x2 has no effect on y, neither standing
alone nor in interactions. This of course is highly consistent with LR
tests and is sort of what I expect.

In turn the MCMCglmms show that the most complex model is favored, and x2
largely increases model fit in every combination. The more complex the
model, the smaller the DIC.

I read in MCMCglmm course notes that DIC has large sampling variance, so I
tried running the same models using 10million iterations, but the results
are the same.

So basically I have two questions:
1. DIC seems to be very unreliable. It feels that penalisation of extra
parameters estimated is very low, selecting the most complex models at
times. Does this seem right to more experienced MCMCglmm users or did I do
something wrong in the analyses?
2. Other than DIC, how can I evaluate the importance of interaction terms
and decide to keep it in the models or not?

Any advice or help would be much appreciated.

Kind regards,
Steve

From stevenlong75x at gmail.com  Sun Jan 22 14:58:47 2017
From: stevenlong75x at gmail.com (Steven Long)
Date: Sun, 22 Jan 2017 14:58:47 +0100
Subject: [R-sig-ME] unreliable DIC vs. how to evaluate complex
	interactions in MCMCglmm
In-Reply-To: <CAMcBiJHTMrCsunY4v3ii77dMUR4KMeUjYLOUNSCNKCTWgpH_FQ@mail.gmail.com>
References: <CAMcBiJHTMrCsunY4v3ii77dMUR4KMeUjYLOUNSCNKCTWgpH_FQ@mail.gmail.com>
Message-ID: <CAMcBiJE6VRFt1YuwmQzGZo-myj7Pa7=wrk36rWpHsic04SSnMg@mail.gmail.com>

Please disregard my post.
I used priors specific of binomial models. DIC results are highly similar
to the AIC obtained from lme 4 with proper priors.

Please excuse my erroneous tread.

Bests,
Steve

On Sun, Jan 22, 2017 at 2:10 PM, Steven Long <stevenlong75x at gmail.com>
wrote:

> Dear List Members,
>
> I have a mixed effects model setup, that would ideally incorporate
> pedigree. This is why I started to run the models using MCMCglmm. As I am
> unfamiliar with the latter approach I first tried everything using lme4 and
> used AIC to compare the models. Then I rerun everything in MCMCglmm.
> Neither of the model sets included pedigree at this stage.
>
> My main concern is the very large difference in AIC vs. DIC based model
> selection result.
>
> I've attached my dataset. See my code here.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> *library(MCMCglmm)d2 <- read.csv("d2.csv")d2$f1 <- as.factor(d2$f1)d2$f2
> <- as.factor(d2$f2)n=8prior = list(R = list(V = n, fix = 1),              G
> = list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> = 0, alpha.V =
> 1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 + pi^2/3)))m0
> <-MCMCglmm(y ~ x1 +f1 +f2, random = ~ R,
> data=d2,family='gaussian',             prior=prior,
> nitt=101000,burnin=1000,thin=10)n=9prior = list(R = list(V = n, fix = 1),
>              G = list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> =
> 0, alpha.V = 1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 +
> pi^2/3)))m1 <-MCMCglmm(y ~ x1 +f1 +f2 +x2, random = ~ R,
> data=d2,family='gaussian',             prior=prior,
> nitt=101000,burnin=1000,thin=10)n=12prior = list(R = list(V = n, fix = 1),
>              G = list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> =
> 0, alpha.V = 1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 +
> pi^2/3)))m2 <-MCMCglmm(y ~ x1 +f1 +f2*x2, random = ~ R,
> data=d2,family='gaussian',             prior=prior,
> nitt=101000,burnin=1000,thin=10)n=15prior = list(R = list(V = n, fix = 1),
>              G = list(G1 = list(V = 1, nu = 1, alpha.mu <http://alpha.mu> =
> 0, alpha.V = 1000)),        B = list(mu = rep(0,     n), V = diag(n) * (1 +
> pi^2/3)))m3 <-MCMCglmm(y ~ x1 +f1*x1 +f2*x2, random = ~ R,
> data=d2,family='gaussian',             prior=prior,
> nitt=101000,burnin=1000,thin=10)m0$DIC; m1$DIC; m2$DIC; m3$DIC*
>
> *# m0 -684.7527*
>
> *# m1  -741.8908*
>
> *# m2  -880.8456*
>
> *# m3  -987.9276*
>
>
>
>
>
>
>
> *library(lme4)M0 <- lmer(y ~ x1 +f1 +f2 +(1|R),REML=F, d2)M1 <- lmer(y ~
> x1 +f1 +f2 +x2 +(1|R),REML=F, d2)M2 <- lmer(y ~ x1 +f1 +f2*x2
> +(1|R),REML=F, d2)M3 <- lmer(y ~ x1 +f1*x2 +f2*x2 +(1|R),REML=F,
> d2)AIC(M0);AIC(M1); AIC(M2); AIC(M3)*
>
> *# M0 -122.76*
>
> *# M1 -122.8364*
>
> *# M2 -118.4911*
> *# M3 -113.0851*
>
> So in conclusion, lme4 shows that x2 has no effect on y, neither standing
> alone nor in interactions. This of course is highly consistent with LR
> tests and is sort of what I expect.
>
> In turn the MCMCglmms show that the most complex model is favored, and x2
> largely increases model fit in every combination. The more complex the
> model, the smaller the DIC.
>
> I read in MCMCglmm course notes that DIC has large sampling variance, so I
> tried running the same models using 10million iterations, but the results
> are the same.
>
> So basically I have two questions:
> 1. DIC seems to be very unreliable. It feels that penalisation of extra
> parameters estimated is very low, selecting the most complex models at
> times. Does this seem right to more experienced MCMCglmm users or did I do
> something wrong in the analyses?
> 2. Other than DIC, how can I evaluate the importance of interaction terms
> and decide to keep it in the models or not?
>
> Any advice or help would be much appreciated.
>
> Kind regards,
> Steve
>

	[[alternative HTML version deleted]]


From gangchen at mail.nih.gov  Sun Jan 22 22:48:31 2017
From: gangchen at mail.nih.gov (Chen, Gang (NIH/NIMH) [C])
Date: Sun, 22 Jan 2017 21:48:31 +0000
Subject: [R-sig-ME] Understanding variance components
In-Reply-To: <CADcpBHP3c9XAA-N9nRqVFZxeq6kwSktpoib_c62PuHTVnDqzdA@mail.gmail.com>
References: <1270F325-EB40-4625-9AE7-BDFB100496C7@mail.nih.gov>
	<7d59ff26-02c0-2605-56ae-c059f1bf5a26@psychologie.uzh.ch>
	<6E20B8F6-56C9-496D-AFC0-EA43945DF49E@mail.nih.gov>
	<4EDB92F4-B2B1-4F32-AF08-6531B2C60AFC@mail.nih.gov>,
	<CADcpBHP3c9XAA-N9nRqVFZxeq6kwSktpoib_c62PuHTVnDqzdA@mail.gmail.com>
Message-ID: <2DF23039AABC714B865A63F67141C0945A49EB6E@msgb06.nih.gov>

Thanks Ren? for the comment. I'm still puzzled by the fact that the variance decomposition cannot seem to be directly reconciled through the two models themselves, and I hope that someone can offer a better way to interpret this.

Gang
________________________________
From: Ren? [bimonosom at gmail.com]
Sent: Thursday, January 19, 2017 10:55 AM
To: Chen, Gang (NIH/NIMH) [C]
Cc: Henrik Singmann; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Understanding variance components

Hey Gang, hey Henrik (!) :)

very insightful query, hope it is okay that I briefly join it, on the last question.
Variance is a result of division of squared deviations by sample size. In the complete sample, this means divided by 240; and in the gender samples by 120 each.
Have a look on the reversed equations for obtaining the overall variance by combining gender groups, weighted by sample size:

(120 * 0.9944589   +   4.137316 * 120)/240 = overall variance (should be equal to)  = (0.9944589 + 4.137316)/2   acording to your equation gang
left hand can be written as:
120 * (0.9944589   +   4.137316) / 240
which is:
(0.9944589   +   4.137316)/2

so nothing to worry, I think :)

Best wishes,
Ren?



2017-01-19 16:14 GMT+01:00 Chen, Gang (NIH/NIMH) [C] <gangchen at mail.nih.gov<mailto:gangchen at mail.nih.gov>>:
Nice, Henrik!

One thing we need to resolve, though, is this.

====================
The variances for model m1:

(1) intercept

summary(m1)$varcor$id[1]
[1] 2.565887

(2) residuals

attr(summary(m1)$varcor, "sc")^2
[1] 2.196212

====================
And the variances for model m2:

(1) female

summary(m2)$varcor$id[1]
[1] 0.9944589

(2) male

summary(m2)$varcor$id.1[1]
[1] 4.137316

(3) residuals

attr(summary(m2)$varcor, "sc")^2
[1] 2.196212
====================

It?s great to see that the residual variance matches between the two models m1 and m2. However, the intercept variance in m1, 2.565887, is not equal to the sum of female and male variances, 0.9944589 + 4.137316 = 5.131775. However, if we divide the total variance of female and male by 2, we have (0.9944589 + 4.137316)/2 = 2.565887. Why is that?

If we code the two groups as

obk.long$gender_F <- sqrt(2)*as.numeric(obk.long$gender == "F")
obk.long$gender_M <- sqrt(2)*as.numeric(obk.long$gender == "M?)

then we have the desired result,

m2 <- lmer(value ~ gender*phase+(0+gender_F|id)+(0+gender_M|id), data=obk.long)
summary(m2)$varcor$id[1]+summary(m2)$varcor$id.1[1]
[1] 2.565888

Even though the variance part is reconciled, I cannot come up with a good explanation as to why this coding strategy is required. Any thought?

Thanks,
Gang


On Jan 19, 2017, at 6:13 AM, Henrik Singmann <singmann at psychologie.uzh.ch<mailto:singmann at psychologie.uzh.ch><mailto:singmann at psychologie.uzh.ch<mailto:singmann at psychologie.uzh.ch>>> wrote:

Hi Gang,

I have an idea which is based on the last example given on ?lmer:
## Fit sex-specific variances by constructing numeric dummy variables
...

I am not sure if this is entirely correct, but it looks good to me. If not, hopefully someone more knowledgeable will jump in.

## Original model without gender specific variance:
data(obk.long, package = "afex")

m1 <- lmer(value ~ gender*phase+(1|id), data=obk.long)
summary(m1)$varcor
## Groups   Name        Std.Dev.
## id       (Intercept) 1.6018
## Residual             1.4820
REMLcrit(m1)
## [1] 911.1599

## to get gender specific vari8ances, we construct two dummy variables:
obk.long$gender_F <- as.numeric(obk.long$gender == "F")
obk.long$gender_M <- as.numeric(obk.long$gender == "M")
m2 <- lmer(value ~ gender*phase+(0+gender_F|id)+(0+gender_M|id), data=obk.long)
summary(m2)$varcor
## Groups   Name     Std.Dev.
## id       gender_F 0.99723
## id.1     gender_M 2.03404
## Residual          1.48196
REMLcrit(m2)
## [1] 908.297

So far, looks reasonably close. Same for the conditional modes (thx Phillip). Left two columns is separate, right is joint variance.
cbind(ranef(m2)$id, rep(NA, 16), ranef(m1)$id)
##      gender_F   gender_M rep(NA, 16) (Intercept)
## 1   0.0000000 -3.0986753          NA  -3.0351426
## 2   0.0000000 -2.1328544          NA  -2.0891242
## 3   0.0000000  0.1207276          NA   0.1182523
## 4  -0.9806229  0.0000000          NA  -1.0642708
## 5  -0.3995130  0.0000000          NA  -0.4335918
## 6   0.0000000  2.6962499          NA   2.6409683
## 7   0.0000000  1.4084888          NA   1.3796103
## 8  -0.3995130  0.0000000          NA  -0.4335918
## 9  -0.6900680  0.0000000          NA  -0.7489313
## 10  0.0000000  0.4426679          NA   0.4335918
## 11  0.0000000 -1.1670336          NA  -1.1431057
## 12  0.0000000  1.7304291          NA   1.6949498
## 13  1.3438166  0.0000000          NA   1.4584452
## 14 -0.6900680  0.0000000          NA  -0.7489313
## 15  0.4721518  0.0000000          NA   0.5124267
## 16  1.3438166  0.0000000          NA   1.4584452

And, finally, the same for the fixed effects:
fixef(m1)
##       (Intercept)           genderM         phasepost
##      6.000000e+00      7.500000e-01     -6.250000e-01
##          phasepre genderM:phasepost  genderM:phasepre
##     -2.000000e+00     -1.243450e-15     -1.687539e-15
fixef(m2)
##      (Intercept)           genderM         phasepost
##     6.000000e+00      7.500000e-01     -6.250000e-01
##         phasepre genderM:phasepost  genderM:phasepre
##    -2.000000e+00      1.829648e-14      1.820766e-14

Hope that helps,
Henrik

On Jan 18, 2017, at 5:18 PM, Chen, Gang (NIH/NIMH) [C] <gangchen at mail.nih.gov<mailto:gangchen at mail.nih.gov><mailto:gangchen at mail.nih.gov<mailto:gangchen at mail.nih.gov>>> wrote:

Happy New Year, Henrik! Thanks for explaining the details. A couple of days after I posted the question, I realized that my question was silly! Once I laid out the LME model equation, my original confusion was resolved.

Actually I meant to ask a slightly different question. Let me use the dataset embedded in your ?afex? package as an example:

data(obk.long, package = "afex?)

Suppose that my base model is

lmer(value ~ gender*phase+(1|id), data=obk.long)

Is there a way to specify a different variance for each gender in one model?

Thanks,
Gang


On Jan 13, 2017, at 12:06 PM, Henrik Singmann <singmann at psychologie.uzh.ch<mailto:singmann at psychologie.uzh.ch><mailto:singmann at psychologie.uzh.ch<mailto:singmann at psychologie.uzh.ch>>> wrote:

Hi Gang,

Sorry that I so am late to the party, but in case you are still interested I will reply (and, of course, for the archive).

The answer is basically given in the old faq:
http://glmm.wikidot.com/faq#toc27

(1|site/block) = (1|site)+(1|site:block)

Which is exactly what is given in your output. A random intercept for Worker and a random intercept for each worker:Machine interaction.

To answer your questions. The random intercepts do not have base or reference levels. They are increments or decrements to the overall intercept for each level of Worker or the Machine:Worker combination. The reported variance is the estimated variance of these increments, which is most likely unequal to the actual variance you would obtain by calculating it from the estimated increments, which are sometimes called BLUPs (I wonder if a better term for those exist).

Hope that helps,
Henrik

PS: Belated Happy New Year to everyone.


Am 05.01.2017 um 17:28 schrieb Chen, Gang (NIH/NIMH) [C]:
Suppose that I have the following dataset in R:

library(lme4)
data(Machines,package="nlme")
mydata <- Machines[Machines$Machine!='C?,]

With the following model:

print(lmer(score ~ 1 + (1|Worker/Machine), data=mydata), ranef.comp="Var")

I have the variance components as shown below:

Random effects:
Groups         Name        Variance
Machine:Worker (Intercept) 46.00
Worker         (Intercept) 13.84
Residual                    1.16

I have trouble understanding exactly what the first two components are: Machine:Worker and Worker? Specifically,

1) What is the variance for Worker: corresponding to the base (or reference) level of the factor Machine? If so, what is the base level: the first level in the dataset or alphabetically the first level (it happens to be the same in this particular dataset)?

2) What is the variance for Machine:Worker? Is it the variance for the second level of the factor Machine, or the extra variance relative to the variance for Worker?

Furthermore, for the model:

print(lmer(score ~ 1 + (1|Worker/Machine), data=Machines), ranef.comp="Var")

what is the variance for Machine:Worker in the following result since there are 3 levels involved in the factor Machine?

Random effects:
Groups         Name        Variance
Machine:Worker (Intercept) 60.2972
Worker         (Intercept)  7.3959
Residual                    0.9246

Thanks,
Gang
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From joao.santiago at uni-tuebingen.de  Mon Jan 23 08:46:01 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Mon, 23 Jan 2017 08:46:01 +0100
Subject: [R-sig-ME] Modeling truncated counts with glmer
Message-ID: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>

Hi,

In my experiment 20 participants did a word-pairs learning task in two  
conditions (repeated measures):
40 pairs of nouns are presented on a monitor, each for 4s and with an  
interval of 1s. The words of each pair were moderately semantically  
related (e.g., brain, consciousness and solution, problem). Two  
different word lists were used for the subject?s two experimental  
conditions, with the order of word lists balanced across subjects and  
conditions. The subject had unlimited time to recall the appropriate  
response word, and did three trials in succession for each list:

Condition 1, List A > T1, T2, T3
Condition 2, List B > T1, T2, T3

No feedback was given as to whether the remembered word was correct or not.

I've seen some people go at this with anova, others subtract the total  
number of correct pairs in one condition from the other per subject  
and run a t-test. Since this is count data, a generalized linear model  
should be more appropriate, right?

head(data)
   subjectNumber expDay      bmi treatment tones       hour abruf  
correctPair incorrectPair
           <dbl>  <chr>    <dbl>    <fctr> <dbl>     <time> <dbl>       
  <dbl>         <dbl>
1             1     N2 22.53086   Control     0 27900 secs     1        
    26            14
2             1     N2 22.53086   Control     0 27900 secs     2        
    40             0
3             1     N2 22.53086   Control     0 27900 secs     3        
    40             0
4             2     N1 22.53086   Control     0 27900 secs     1        
    22            18
5             2     N1 22.53086   Control     0 27900 secs     2        
    33             7
6             2     N1 22.53086   Control     0 27900 secs     3        
    36             4



I fitted a model with glmer.nb(correctPair ~ I((abruf - 1)^2) *  
treatment + (1|subjectNumber), data=data). The residuals don't look so  
good to me http://imgur.com/a/AJXGq and the model is fitting values  
above 40, which will never happen in real life (not sure if this is  
important).

I'm interested in knowing if there is any difference between  
conditions (are the values at timepoint (abruf) 1 different? do people  
remember less in one one condition than in the other (different number  
of pairs at timepoint 3?)


If the direction I'm taking is completely wrong please let me know.

Best,
Santiago



-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From thierry.onkelinx at inbo.be  Mon Jan 23 09:42:01 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 Jan 2017 09:42:01 +0100
Subject: [R-sig-ME] Modeling truncated counts with glmer
In-Reply-To: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>
References: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>
Message-ID: <CAJuCY5znseEwrASNwkzzN5C8rkpzebZnEAUEA-HDLG5PMe3iVA@mail.gmail.com>

Dear Jo?o,

A binomial distribution seems more relevant to me.

glmer(cbind(correctPair, incorrectPair) ~ I((abruf - 1)^2) * treatment +
(1|subjectNumber), data=data, family = binomial)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-23 8:46 GMT+01:00 Jo?o C P Santiago <joao.santiago at uni-tuebingen.de>
:

> Hi,
>
> In my experiment 20 participants did a word-pairs learning task in two
> conditions (repeated measures):
> 40 pairs of nouns are presented on a monitor, each for 4s and with an
> interval of 1s. The words of each pair were moderately semantically related
> (e.g., brain, consciousness and solution, problem). Two different word
> lists were used for the subject?s two experimental conditions, with the
> order of word lists balanced across subjects and conditions. The subject
> had unlimited time to recall the appropriate response word, and did three
> trials in succession for each list:
>
> Condition 1, List A > T1, T2, T3
> Condition 2, List B > T1, T2, T3
>
> No feedback was given as to whether the remembered word was correct or not.
>
> I've seen some people go at this with anova, others subtract the total
> number of correct pairs in one condition from the other per subject and run
> a t-test. Since this is count data, a generalized linear model should be
> more appropriate, right?
>
> head(data)
>   subjectNumber expDay      bmi treatment tones       hour abruf
> correctPair incorrectPair
>           <dbl>  <chr>    <dbl>    <fctr> <dbl>     <time> <dbl>
>  <dbl>         <dbl>
> 1             1     N2 22.53086   Control     0 27900 secs     1
> 26            14
> 2             1     N2 22.53086   Control     0 27900 secs     2
> 40             0
> 3             1     N2 22.53086   Control     0 27900 secs     3
> 40             0
> 4             2     N1 22.53086   Control     0 27900 secs     1
> 22            18
> 5             2     N1 22.53086   Control     0 27900 secs     2
> 33             7
> 6             2     N1 22.53086   Control     0 27900 secs     3
> 36             4
>
>
>
> I fitted a model with glmer.nb(correctPair ~ I((abruf - 1)^2) * treatment
> + (1|subjectNumber), data=data). The residuals don't look so good to me
> http://imgur.com/a/AJXGq and the model is fitting values above 40, which
> will never happen in real life (not sure if this is important).
>
> I'm interested in knowing if there is any difference between conditions
> (are the values at timepoint (abruf) 1 different? do people remember less
> in one one condition than in the other (different number of pairs at
> timepoint 3?)
>
>
> If the direction I'm taking is completely wrong please let me know.
>
> Best,
> Santiago
>
>
>
> --
> Jo?o C. P. Santiago
> Institute for Medical Psychology & Behavioral Neurobiology
> Center of Integrative Neuroscience
> University of Tuebingen
> Otfried-Mueller-Str. 25
> 72076 Tuebingen, Germany
>
> Phone: +49 7071 29 88981
> Fax: +49 7071 29 25016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jan 23 10:21:58 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 Jan 2017 10:21:58 +0100
Subject: [R-sig-ME] Modeling truncated counts with glmer
In-Reply-To: <20170123100147.Horde.QGfa6_Jsb7QdOvh6vL11Et2@webmail.uni-tuebingen.de>
References: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>
	<CAJuCY5znseEwrASNwkzzN5C8rkpzebZnEAUEA-HDLG5PMe3iVA@mail.gmail.com>
	<20170123100147.Horde.QGfa6_Jsb7QdOvh6vL11Et2@webmail.uni-tuebingen.de>
Message-ID: <CAJuCY5x1B3Kpr-z6xuPYMDFbBqspFr9yp-Mg1k6dGmBL4MWQUQ@mail.gmail.com>

It looks like you participants performed a known number of trials which
resulted in either success or failure. The binomial distribution models
exactly that. The model fit would be the probability of success.

Once you have the relevant distribution, you can set the relevant
covariates. Which and in which form (linear, polynomial, factor) depends on
the hypotheses which are relevant for your experiment.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-23 10:01 GMT+01:00 Jo?o C P Santiago <joao.santiago at uni-tuebingen.de
>:

> Thank you! Could you be a bit more specific as to why? I will most likely
> encounter similar data in the future and I want to know how to think about
> it.
>
> Fitting the model with abruf as a factor resulted in a better fit, but
> that answers a different question right? Namely how different is the
> intercept at a timepoint in comparison with the main level (abruf 0 in my
> code)?
>
> Best
>
>
> Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
> Dear Jo?o,
>>
>> A binomial distribution seems more relevant to me.
>>
>> glmer(cbind(correctPair, incorrectPair) ~ I((abruf - 1)^2) * treatment +
>> (1|subjectNumber), data=data, family = binomial)
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2017-01-23 8:46 GMT+01:00 Jo?o C P Santiago <
>> joao.santiago at uni-tuebingen.de>
>> :
>>
>> Hi,
>>>
>>> In my experiment 20 participants did a word-pairs learning task in two
>>> conditions (repeated measures):
>>> 40 pairs of nouns are presented on a monitor, each for 4s and with an
>>> interval of 1s. The words of each pair were moderately semantically
>>> related
>>> (e.g., brain, consciousness and solution, problem). Two different word
>>> lists were used for the subject?s two experimental conditions, with the
>>> order of word lists balanced across subjects and conditions. The subject
>>> had unlimited time to recall the appropriate response word, and did three
>>> trials in succession for each list:
>>>
>>> Condition 1, List A > T1, T2, T3
>>> Condition 2, List B > T1, T2, T3
>>>
>>> No feedback was given as to whether the remembered word was correct or
>>> not.
>>>
>>> I've seen some people go at this with anova, others subtract the total
>>> number of correct pairs in one condition from the other per subject and
>>> run
>>> a t-test. Since this is count data, a generalized linear model should be
>>> more appropriate, right?
>>>
>>> head(data)
>>>   subjectNumber expDay      bmi treatment tones       hour abruf
>>> correctPair incorrectPair
>>>           <dbl>  <chr>    <dbl>    <fctr> <dbl>     <time> <dbl>
>>>  <dbl>         <dbl>
>>> 1             1     N2 22.53086   Control     0 27900 secs     1
>>> 26            14
>>> 2             1     N2 22.53086   Control     0 27900 secs     2
>>> 40             0
>>> 3             1     N2 22.53086   Control     0 27900 secs     3
>>> 40             0
>>> 4             2     N1 22.53086   Control     0 27900 secs     1
>>> 22            18
>>> 5             2     N1 22.53086   Control     0 27900 secs     2
>>> 33             7
>>> 6             2     N1 22.53086   Control     0 27900 secs     3
>>> 36             4
>>>
>>>
>>>
>>> I fitted a model with glmer.nb(correctPair ~ I((abruf - 1)^2) * treatment
>>> + (1|subjectNumber), data=data). The residuals don't look so good to me
>>> http://imgur.com/a/AJXGq and the model is fitting values above 40, which
>>> will never happen in real life (not sure if this is important).
>>>
>>> I'm interested in knowing if there is any difference between conditions
>>> (are the values at timepoint (abruf) 1 different? do people remember less
>>> in one one condition than in the other (different number of pairs at
>>> timepoint 3?)
>>>
>>>
>>> If the direction I'm taking is completely wrong please let me know.
>>>
>>> Best,
>>> Santiago
>>>
>>>
>>>
>>> --
>>> Jo?o C. P. Santiago
>>> Institute for Medical Psychology & Behavioral Neurobiology
>>> Center of Integrative Neuroscience
>>> University of Tuebingen
>>> Otfried-Mueller-Str. 25
>>> 72076 Tuebingen, Germany
>>>
>>> Phone: +49 7071 29 88981
>>> Fax: +49 7071 29 25016
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
>
> --
> Jo?o C. P. Santiago
> Institute for Medical Psychology & Behavioral Neurobiology
> Center of Integrative Neuroscience
> University of Tuebingen
> Otfried-Mueller-Str. 25
> 72076 Tuebingen, Germany
>
> Phone: +49 7071 29 88981
> Fax: +49 7071 29 25016
>
>

	[[alternative HTML version deleted]]


From tim.cole at ucl.ac.uk  Mon Jan 23 10:46:49 2017
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Mon, 23 Jan 2017 09:46:49 +0000
Subject: [R-sig-ME] nlme vs nlme4
Message-ID: <D4AB7520.52059%tim.cole@ucl.ac.uk>

Terry,

I've also recently reported that same error, at
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q4/025213.html.

BTW where is your function dfun defined? - should it be dfun2?

You say you had to add z to the start vector init2, but you've defined it
as a fixed effect when it's random. Try defining init2 as a list with
components nlpars for the fixed effects p1, p2, p3 and p4, and theta for
var(z), and it might work better (note the error message refers to theta).

Best wishes,
Tim Cole

--- 
Tim.cole at ucl.ac.uk Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population, Policy and Practice Programme
UCL Great Ormond Street Institute of Child Health, London WC1N 1EH, UK





>Date: Thu, 19 Jan 2017 12:08:51 -0600
>From: "Therneau, Terry M., Ph.D." <therneau at mayo.edu>
>To: r-sig-mixed-models at r-project.org
>Subject: [R-sig-ME] nlme vs nlme4
>
>I have a fit that works in nlme and fails in nlme4; I'd like to convert
>to the latter 
>since I now need to use case weights and varFixed() + nlme leads to a lot
>of "wrong 
>length" warnings.  (Google search suggests that this has sometimes been
>asked about but I 
>don't find any anwsers).
>
>As always, my first hypothesis is that I have some silly setup mistake.
>
># nlme code
>tfun2 <- function(age, p1, p2,p3,p4, z)
>     p1 + p2*(age+z- 60) + .5*(p4-p2)*((age+z-p3) + sqrt((age+z-p3)^2
>+20))
>
>dfun2 <- deriv(body(tfun2), c("p1", "p2", "p3", "p4", "z"),
>               function.arg=tfun2)
>init <- c(p1=1.2, p2=.03, p3=1, p4=1)
>
>nfit1 <- nlme(y ~ dfun(age, p1, p2, p3, p4, z),
>               fixed= p1 + p2 + p3 + p4  ~ 1,
>               random= z~ 1|clinic, data=mydata, start=init,
>               na.action=na.omit)
>nfit1
>   Fixed: p1 + p2 + p3 + p4 ~ 1
>          p1          p2          p3          p4
>  1.21516330  0.00237005 73.58059382  0.08424922
>
>Random effects:
>  Formula: z ~ 1 | clinic
>                z   Residual
>StdDev: 9.418258 0.06865345
>
>---------------
>
># nlmer code
>init2 <- c(p1=1.2, p2=.03, p3=1, p4=1, z=0)
>mfit1 <- nlmer(y ~ dfun(age, p1, p2, p3, p4, z) ~
>               0+ p1 + p2 + p3 + p4 + (0+z | clinic),
>                data=mydata, start=init2, verbose=TRUE)
>Error in devfun(rho$pp$theta) : Downdated VtV is not positive definite
>
>------------------
>
>I had to add z=0 to the start vector or else it complains that z is not
>found, apparently 
>the derivative component of dfun is not enough to inform.
>
>For those who want to know more:  This is essentially a change point
>model fit with a 
>hyperbola.  The biomarker in question rises slowly with age, but for a
>substantial subset
>there is a fairly abrupt upward change in the slope sometime between the
>ages of 60 and 
>90.  The trend line is 1.2 + .0024*(age-60), the average age of turn is
>73.5, and the new 
>slope is .086, and the std of turning age is 9.4.  The constant "20" in
>the formula is an 
>arbitrary value that controls how sharp a turn the hyperbola makes.
>
>I can provide an anonymized data set to someone (if this isn't just a
>silly error).  There
>are about 3000 data points.
>
>Terry Therneau
>
>>


From chanratana.pin at gmail.com  Tue Jan 24 10:26:18 2017
From: chanratana.pin at gmail.com (Pin chanratana)
Date: Tue, 24 Jan 2017 16:26:18 +0700
Subject: [R-sig-ME] Mixes effect with polynomial term
Message-ID: <CANW7wbdrryCP=2pJ03yoPuiMij-BpdRu8UpinP1mDwMuPF6Szg@mail.gmail.com>

Hello,

I'm fitting data of Lesser adjutant that were camera-trapped at waterholes
during the dry season.
My final model consist of depth of waterholes and the depth power 2. Can anyone
help me in interpreting the result shown below.

glmmadmb ( LA ~ depth + I(depth^2) + offset(log(trap)) + (1 | obs), data =
ndata4, family = "nbinom")

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -3.0644     0.2397  -12.78  < 2e-16 ***
depth         1.5807     0.2633    6.00  1.9e-09 ***
I(depth^2)   -0.3598     0.0737   -4.89  1.0e-06 ***

Number of observations: total=294, obs=9
Random effect variance(s):
Group=obs
            Variance StdDev
(Intercept)   0.3244 0.5696

Negative binomial dispersion parameter: 0.34381 (std. err.: 0.064328)


Thanks,

Ratana

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jan 24 10:45:26 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 24 Jan 2017 10:45:26 +0100
Subject: [R-sig-ME] Mixes effect with polynomial term
In-Reply-To: <CANW7wbdrryCP=2pJ03yoPuiMij-BpdRu8UpinP1mDwMuPF6Szg@mail.gmail.com>
References: <CANW7wbdrryCP=2pJ03yoPuiMij-BpdRu8UpinP1mDwMuPF6Szg@mail.gmail.com>
Message-ID: <CAJuCY5yt3eYisWx-BBmv_9cWrp4Hs2Cb93Zs65fa0O=zOwz=2A@mail.gmail.com>

Dear Ratana,

Make a plot of the fitted value using only the fixed effect. That will be
easier to interpret that the raw coefficients.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-24 10:26 GMT+01:00 Pin chanratana <chanratana.pin at gmail.com>:

> Hello,
>
> I'm fitting data of Lesser adjutant that were camera-trapped at waterholes
> during the dry season.
> My final model consist of depth of waterholes and the depth power 2. Can
> anyone
> help me in interpreting the result shown below.
>
> glmmadmb ( LA ~ depth + I(depth^2) + offset(log(trap)) + (1 | obs), data =
> ndata4, family = "nbinom")
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -3.0644     0.2397  -12.78  < 2e-16 ***
> depth         1.5807     0.2633    6.00  1.9e-09 ***
> I(depth^2)   -0.3598     0.0737   -4.89  1.0e-06 ***
>
> Number of observations: total=294, obs=9
> Random effect variance(s):
> Group=obs
>             Variance StdDev
> (Intercept)   0.3244 0.5696
>
> Negative binomial dispersion parameter: 0.34381 (std. err.: 0.064328)
>
>
> Thanks,
>
> Ratana
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From roberto.mannu at ise.cnr.it  Wed Jan 25 09:04:59 2017
From: roberto.mannu at ise.cnr.it (Roberto Mannu)
Date: Wed, 25 Jan 2017 09:04:59 +0100
Subject: [R-sig-ME] Mixed models and time series
Message-ID: <6dc94b07-ff16-6d3b-efc3-21d8365e945b@ise.cnr.it>

Dear,

First of all I want to apologize for my not perfect English, I'll try to well explain my issues too. At the moment I'm trying to
analize a dataset of three-years insect counts. Insects were counted
monthly on 4 sampling trees (causally selected) in 12 different
locations. Therefore, I firstly obtained 12 similar dynamics for each
location. My first question is: "Can I evaluate differences in
population among location?". I thought to fit a linear mixed model after
data log-transformation in which "location", "time" (evaluated as the
time from beginning to end of sampling) and its relationship were the
fixed factors and sampling trees (1 to 4 within each location at each
sampling date) were the randoms factors. Can this being considered right?

I'm afraid that there may be temporal autocorrelation between data cause
of regular dynamics within year.

I read different work regarding GLMMs, but I did not understand how to apply
them in R.

Thanks in advance for your reply.

Best regards


Roberto


-- 
Roberto Mannu, PhD
Istituto per lo Studio degli Ecosistemi
Consiglio Nazionale delle Ricerche
Traversa La Crucca 3
07100 Sassari

tel: +390792841410
cell: +393401612546
  
email: r.mannu at ise.cnr.it


From joaquin.aldabe at gmail.com  Thu Jan 26 15:38:10 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 26 Jan 2017 11:38:10 -0300
Subject: [R-sig-ME] modeling question
In-Reply-To: <8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
	<CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
	<8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>
Message-ID: <CAMM93=+YZzVged7we2mhy6A3MZi5o_OFdNAQ6RBAeHS8hn_WqQ@mail.gmail.com>

Dear Ben, it's me again with this subject about invertebrate biomass and
its possible effect on shorebird density. I have a couple of extra doubts
about your recommendations:

You suggested this:

(1) The relationship between bird density and invert biomass, as well
as the intercept (i.e., expected bird density at invert_biomass=0, or
better invert_biomass=<some sensible reference quantity>).

I tried a quantity considering the lowest value of the invertebrate biomass
variable, but the model did not converge. So I wonder if I should pick this
value or a different one?

(2) The relationship might be changing over time?

lme(Bird.density~Invertebrate biomass+sample_time,
random=~invert_biomass|Plot_identity, data=)

How should I treat sample time? Is it a ordered categorical variable?

Thankyou very much.

Joaquin


2017-01-16 19:49 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

>
>   Center your biomass variable on this value: either create a
>
>   mydata$invert_biomass_c <- mydata$invert_biomass-ref_value
>
> or include it directly in your formula:
>
>    bird_dens ~ I(invert_biomass-ref_value), ...
>
> On 17-01-16 05:44 PM, Joaqu?n Aldabe wrote:
> > Thankyou very much Ben. Can you please suggest a way of fixing some
> > sensible reference quantity for Invertebrate biomass?
> > All the best,
> > Joaqu?n
> >
> > 2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>>:
> >
> >     That seems perfectly reasonable.  There are a couple of things to
> >     consider, although you may or may not find that your data supports
> >     that much complexity.
> >
> >     (1) The relationship between bird density and invert biomass, as well
> >     as the intercept (i.e., expected bird density at invert_biomass=0, or
> >     better invert_biomass=<some sensible reference quantity>)
> >
> >     lme(Bird.density~Invertebrate biomass,
> >     random=~invert_biomass|Plot_identity, data=)
> >
> >
> >     (2) The relationship might be changing over time?
> >
> >     lme(Bird.density~Invertebrate biomass+sample_time,
> >     random=~invert_biomass|Plot_identity, data=)
> >
> >     (3) In principle you could consider random effects of both time and
> >     invert biomass, but that will almost certainly overwhelm your data.
> >
> >       Don't forget to do the standard post-fitting checks: are your
> >     residuals *approximately* equal-variance and (even more
> approximately)
> >     Normally distributed?  Is the relationship between bird density and
> >     invert biomass *approximately* linear?  (See ?plot.lme)
> >
> >
> >     On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
> >     > Dear all, I'm interested in modeling the effect of invertebrate
> biomass on
> >     > the density of a grassland shorebird (they eat invertebrates). For
> this, I
> >     > picked 8 plots and sampled invertebrates and birds 6 times in each
> plot for
> >     > about 30 days. This is, I went to each plot and did repeated
> measures of
> >     > invertebrates biomass and shorebird density separated in time by
> four or
> >     > five days, as invertebrates biomass may change over time and it is
> expected
> >     > that birds density change accordingly.
> >     >
> >     > So, I'm trying to see a general pattern of the effect of changes
> in biomass
> >     > on the density of this shorebird species at a plot scale. Plot
> identity is
> >     > not important; I consider them as particular events of a random
> process.
> >     >
> >     > Is this model correct:
> >     >
> >     > lme(Bird.density~Invertebrate biomass, random=~1|Plot_identity,
> data=)
> >     >
> >     > Thank you very much,
> >     >
> >     > Joaquin.
> >     >
> >     >
> >     > --
> >     > *Joaqu?n Aldabe*
> >     >
> >     > *Grupo Biodiversidad, Ambiente y Sociedad*
> >     > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >     >
> >     > *Departamento de Conservaci?n*
> >     > Aves Uruguay
> >     > BirdLife International
> >     > Canelones 1164, Montevideo
> >     >
> >     > https://sites.google.com/site/joaquin.aldabe
> >     <https://sites.google.com/site/joaquin.aldabe>
> >     > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
> >     >
> >     >         [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
> >
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > /Grupo Biodiversidad, Ambiente y Sociedad/
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > /Departamento de Conservaci?n/
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >
> >
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From joao.santiago at uni-tuebingen.de  Mon Jan 23 10:01:47 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Mon, 23 Jan 2017 10:01:47 +0100
Subject: [R-sig-ME] Modeling truncated counts with glmer
In-Reply-To: <CAJuCY5znseEwrASNwkzzN5C8rkpzebZnEAUEA-HDLG5PMe3iVA@mail.gmail.com>
References: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>
	<CAJuCY5znseEwrASNwkzzN5C8rkpzebZnEAUEA-HDLG5PMe3iVA@mail.gmail.com>
Message-ID: <20170123100147.Horde.QGfa6_Jsb7QdOvh6vL11Et2@webmail.uni-tuebingen.de>

Thank you! Could you be a bit more specific as to why? I will most  
likely encounter similar data in the future and I want to know how to  
think about it.

Fitting the model with abruf as a factor resulted in a better fit, but  
that answers a different question right? Namely how different is the  
intercept at a timepoint in comparison with the main level (abruf 0 in  
my code)?

Best

Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Jo?o,
>
> A binomial distribution seems more relevant to me.
>
> glmer(cbind(correctPair, incorrectPair) ~ I((abruf - 1)^2) * treatment +
> (1|subjectNumber), data=data, family = binomial)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-01-23 8:46 GMT+01:00 Jo?o C P Santiago <joao.santiago at uni-tuebingen.de>
> :
>
>> Hi,
>>
>> In my experiment 20 participants did a word-pairs learning task in two
>> conditions (repeated measures):
>> 40 pairs of nouns are presented on a monitor, each for 4s and with an
>> interval of 1s. The words of each pair were moderately semantically related
>> (e.g., brain, consciousness and solution, problem). Two different word
>> lists were used for the subject?s two experimental conditions, with the
>> order of word lists balanced across subjects and conditions. The subject
>> had unlimited time to recall the appropriate response word, and did three
>> trials in succession for each list:
>>
>> Condition 1, List A > T1, T2, T3
>> Condition 2, List B > T1, T2, T3
>>
>> No feedback was given as to whether the remembered word was correct or not.
>>
>> I've seen some people go at this with anova, others subtract the total
>> number of correct pairs in one condition from the other per subject and run
>> a t-test. Since this is count data, a generalized linear model should be
>> more appropriate, right?
>>
>> head(data)
>>   subjectNumber expDay      bmi treatment tones       hour abruf
>> correctPair incorrectPair
>>           <dbl>  <chr>    <dbl>    <fctr> <dbl>     <time> <dbl>
>>  <dbl>         <dbl>
>> 1             1     N2 22.53086   Control     0 27900 secs     1
>> 26            14
>> 2             1     N2 22.53086   Control     0 27900 secs     2
>> 40             0
>> 3             1     N2 22.53086   Control     0 27900 secs     3
>> 40             0
>> 4             2     N1 22.53086   Control     0 27900 secs     1
>> 22            18
>> 5             2     N1 22.53086   Control     0 27900 secs     2
>> 33             7
>> 6             2     N1 22.53086   Control     0 27900 secs     3
>> 36             4
>>
>>
>>
>> I fitted a model with glmer.nb(correctPair ~ I((abruf - 1)^2) * treatment
>> + (1|subjectNumber), data=data). The residuals don't look so good to me
>> http://imgur.com/a/AJXGq and the model is fitting values above 40, which
>> will never happen in real life (not sure if this is important).
>>
>> I'm interested in knowing if there is any difference between conditions
>> (are the values at timepoint (abruf) 1 different? do people remember less
>> in one one condition than in the other (different number of pairs at
>> timepoint 3?)
>>
>>
>> If the direction I'm taking is completely wrong please let me know.
>>
>> Best,
>> Santiago
>>
>>
>>
>> --
>> Jo?o C. P. Santiago
>> Institute for Medical Psychology & Behavioral Neurobiology
>> Center of Integrative Neuroscience
>> University of Tuebingen
>> Otfried-Mueller-Str. 25
>> 72076 Tuebingen, Germany
>>
>> Phone: +49 7071 29 88981
>> Fax: +49 7071 29 25016
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From tom.wenseleers at kuleuven.be  Thu Jan 26 16:11:20 2017
From: tom.wenseleers at kuleuven.be (Tom Wenseleers)
Date: Thu, 26 Jan 2017 15:11:20 +0000
Subject: [R-sig-ME] Correct specification of nested binomial mixed model
 with custom intercept to infer variance components and intraclass
 correlations
In-Reply-To: <558ADB54.3020304@glasgow.ac.uk>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W198183686B973039916732CBA00@phx.gbl>,
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk>,<558ADB54.3020304@glasgow.ac.uk>
Message-ID: <1485443532333.72208@kuleuven.be>

Dear all,
Just to ask a bit of advice about the correct way to specify a nested binomial GLM, in the context of estimating variance components / intraclass correlations to infer heritabilities of a behavioural trait.

The behavioural trait is a binary one (eating an egg or not, 1 or 0), and is performed by known individual honeybees (individually numbered, ?individual_ID?) of a known father line (?patriline?) of a given hive (?colony?). Several subsequent egg eating events could be performed by the same individuals. Of each experiment with each colony several trials were done, and for each trial we have data on how many eggs were eaten in total, so we could analyse as a dependent variable the proportion of those eggs that were eaten by a given individual. In addition, we also genotyped a bunch of bees of each colony, which gave us the patriline distribution within each colony (?expected_proportion_patriline?), i.e. the proportion that each patriline makes up in the colony, which I thought should affect the a priori probability that bees of a given patriline would be observed eating eggs.

My question is what mixed model syntax would make most sense to analyse this data, and allows us to infer variance components and intraclass correlations as a basis for a heritability estimate of this egg eating behaviour?

One model I thought of was to include the expected proportion of each patriline that is present as a custom offset, using
library(afex)
set_sum_contrasts() # use effect coding
data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-1+(1|colony/patriline/ID), offset=baseline, data=data, family=binomial)
but would this model make sense as a basis to estimate the variance components and intraclass correlation?

In another model I worked with the mean eggs eaten by bees of a given patriline and then fitted the model
data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
fit2=glmer(cbind(eggs_eaten_by_patriline, eggs_eaten_in_total_intrial ? eggs_eaten_by_patriline)~-1+(1|colony/patriline), offset=baseline, data=data, family=binomial)

Again though I am not sure if such a model would make sense, and neither of my two models take trial explicitly as a factor. Would anybody have any advice by any chance about the most sensible model given my experimental design (proportion data, with individuals nested in patriline nested in colony, with repeated trials and a priori info on the proportion of eggs that would be expected to be eaten by each patriline based on independent genotyping, which could perhaps be included as a custom intercept or a covariate)?

Best regards,
Tom Wenseleers
Dept of Biology
University of Leuven
Belgium

_____

From bbolker at gmail.com  Thu Jan 26 19:59:52 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 26 Jan 2017 13:59:52 -0500
Subject: [R-sig-ME] modeling question
In-Reply-To: <CAMM93=+YZzVged7we2mhy6A3MZi5o_OFdNAQ6RBAeHS8hn_WqQ@mail.gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
	<CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
	<8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>
	<CAMM93=+YZzVged7we2mhy6A3MZi5o_OFdNAQ6RBAeHS8hn_WqQ@mail.gmail.com>
Message-ID: <CABghstQY+NNoWJxDV33GS7-QsABy+ZRpDtk7uxqApNmTrKeA8A@mail.gmail.com>

On Thu, Jan 26, 2017 at 9:38 AM, Joaqu?n Aldabe
<joaquin.aldabe at gmail.com> wrote:
> Dear Ben, it's me again


(I don't mind if you cc: me, but this is really a question to the
list. Probably better to frame it as "I sent this to the list and Ben
Bolker said ...")

> with this subject about invertebrate biomass and its
> possible effect on shorebird density. I have a couple of extra doubts about
> your recommendations:


>
> You suggested this:
>
> (1) The relationship between bird density and invert biomass, as well
> as the intercept (i.e., expected bird density at invert_biomass=0, or
> better invert_biomass=<some sensible reference quantity>).
>
> I tried a quantity considering the lowest value of the invertebrate biomass
> variable, but the model did not converge. So I wonder if I should pick this
> value or a different one?

Hmm, is this with lme or lmer?  Can you give more detail?  If it's
lmer, it's quite likely a false positive.

>
> (2) The relationship might be changing over time?
>
> lme(Bird.density~Invertebrate biomass+sample_time,
> random=~invert_biomass|Plot_identity, data=)
>
> How should I treat sample time? Is it a ordered categorical variable?

   Depends on a number of things.  Your original message suggested
that you sampled over the course of 30 days (maybe at different times
in different plots?)  If this is the case (e.g. you sampled plot 1 on
days 1, 5, 9, ... and plot 2 on days 2, 6, 10 ...) then it is probably
most sensible to treat time as a numeric variable (i.e., assume a
linear trend over days) and possibly a random effect with days as a
grouping variable (in which case you might have to switch from lme to
lmer).  If you have a small number of distinct sample days then a
categorical variable makes sense. Whether you specify it as ordered or
(default) unordered doesn't affect the overall fit of the model, just
the particular contrasts that get tested with respect to the time
variable.


>
> Thankyou very much.
>
> Joaquin
>
>
> 2017-01-16 19:49 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>>
>>
>>   Center your biomass variable on this value: either create a
>>
>>   mydata$invert_biomass_c <- mydata$invert_biomass-ref_value
>>
>> or include it directly in your formula:
>>
>>    bird_dens ~ I(invert_biomass-ref_value), ...
>>
>> On 17-01-16 05:44 PM, Joaqu?n Aldabe wrote:
>> > Thankyou very much Ben. Can you please suggest a way of fixing some
>> > sensible reference quantity for Invertebrate biomass?
>> > All the best,
>> > Joaqu?n
>> >
>> > 2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
>> > <mailto:bbolker at gmail.com>>:
>> >
>> >     That seems perfectly reasonable.  There are a couple of things to
>> >     consider, although you may or may not find that your data supports
>> >     that much complexity.
>> >
>> >     (1) The relationship between bird density and invert biomass, as
>> > well
>> >     as the intercept (i.e., expected bird density at invert_biomass=0,
>> > or
>> >     better invert_biomass=<some sensible reference quantity>)
>> >
>> >     lme(Bird.density~Invertebrate biomass,
>> >     random=~invert_biomass|Plot_identity, data=)
>> >
>> >
>> >     (2) The relationship might be changing over time?
>> >
>> >     lme(Bird.density~Invertebrate biomass+sample_time,
>> >     random=~invert_biomass|Plot_identity, data=)
>> >
>> >     (3) In principle you could consider random effects of both time and
>> >     invert biomass, but that will almost certainly overwhelm your data.
>> >
>> >       Don't forget to do the standard post-fitting checks: are your
>> >     residuals *approximately* equal-variance and (even more
>> > approximately)
>> >     Normally distributed?  Is the relationship between bird density and
>> >     invert biomass *approximately* linear?  (See ?plot.lme)
>> >
>> >
>> >     On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
>> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
>> >     > Dear all, I'm interested in modeling the effect of invertebrate
>> > biomass on
>> >     > the density of a grassland shorebird (they eat invertebrates). For
>> > this, I
>> >     > picked 8 plots and sampled invertebrates and birds 6 times in each
>> > plot for
>> >     > about 30 days. This is, I went to each plot and did repeated
>> > measures of
>> >     > invertebrates biomass and shorebird density separated in time by
>> > four or
>> >     > five days, as invertebrates biomass may change over time and it is
>> > expected
>> >     > that birds density change accordingly.
>> >     >
>> >     > So, I'm trying to see a general pattern of the effect of changes
>> > in biomass
>> >     > on the density of this shorebird species at a plot scale. Plot
>> > identity is
>> >     > not important; I consider them as particular events of a random
>> > process.
>> >     >
>> >     > Is this model correct:
>> >     >
>> >     > lme(Bird.density~Invertebrate biomass, random=~1|Plot_identity,
>> > data=)
>> >     >
>> >     > Thank you very much,
>> >     >
>> >     > Joaquin.
>> >     >
>> >     >
>> >     > --
>> >     > *Joaqu?n Aldabe*
>> >     >
>> >     > *Grupo Biodiversidad, Ambiente y Sociedad*
>> >     > Centro Universitario de la Regi?n Este, Universidad de la
>> > Rep?blica
>> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >     >
>> >     > *Departamento de Conservaci?n*
>> >     > Aves Uruguay
>> >     > BirdLife International
>> >     > Canelones 1164, Montevideo
>> >     >
>> >     > https://sites.google.com/site/joaquin.aldabe
>> >     <https://sites.google.com/site/joaquin.aldabe>
>> >     > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
>> >     >
>> >     >         [[alternative HTML version deleted]]
>> >     >
>> >     > _______________________________________________
>> >     > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >
>> >
>> >
>> >
>> > --
>> > *Joaqu?n Aldabe*
>> >
>> > /Grupo Biodiversidad, Ambiente y Sociedad/
>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >
>> > /Departamento de Conservaci?n/
>> > Aves Uruguay
>> > BirdLife International
>> > Canelones 1164, Montevideo
>> >
>> > https://sites.google.com/site/joaquin.aldabe
>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> >
>> >
>> >
>
>
>
>
> --
> Joaqu?n Aldabe
>
> Grupo Biodiversidad, Ambiente y Sociedad
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> Departamento de Conservaci?n
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
>
>
>


From joaquin.aldabe at gmail.com  Thu Jan 26 20:11:45 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 26 Jan 2017 16:11:45 -0300
Subject: [R-sig-ME] modeling question
In-Reply-To: <CABghstQY+NNoWJxDV33GS7-QsABy+ZRpDtk7uxqApNmTrKeA8A@mail.gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
	<CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
	<8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>
	<CAMM93=+YZzVged7we2mhy6A3MZi5o_OFdNAQ6RBAeHS8hn_WqQ@mail.gmail.com>
	<CABghstQY+NNoWJxDV33GS7-QsABy+ZRpDtk7uxqApNmTrKeA8A@mail.gmail.com>
Message-ID: <CAMM93=Lc==krj5bOTjoAkW_0gbSrrzaOKs8pAhS9Yi8HD0DHuQ@mail.gmail.com>

Thanks Ben, I sent all emails to the whole list. See below (in caps lock
for differentiating from the other text). Regards, Joaquin

2017-01-26 15:59 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

> On Thu, Jan 26, 2017 at 9:38 AM, Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com> wrote:
> > Dear Ben, it's me again
>
>
> (I don't mind if you cc: me, but this is really a question to the
> list. Probably better to frame it as "I sent this to the list and Ben
> Bolker said ...")
>
> > with this subject about invertebrate biomass and its
> > possible effect on shorebird density. I have a couple of extra doubts
> about
> > your recommendations:
>
>
> >
> > You suggested this:
> >
> > (1) The relationship between bird density and invert biomass, as well
> > as the intercept (i.e., expected bird density at invert_biomass=0, or
> > better invert_biomass=<some sensible reference quantity>).
> >
> > I tried a quantity considering the lowest value of the invertebrate
> biomass
> > variable, but the model did not converge. So I wonder if I should pick
> this
> > value or a different one?
>
> Hmm, is this with lme or lmer?  Can you give more detail?  If it's
> lmer, it's quite likely a false positive. I USED LME. I DON'T REALLY KNOW
> WHAT DO YOU EXACTLY MEAN WITH SENSIBLE REFERENCE QUANTITY. I THOUGHT IT WAS
> THE MINIMUM VALUE OF MY X VARIABLE (AS CERO IS NOT A POSSIBILITY).
>
> >
> > (2) The relationship might be changing over time?
> >
> > lme(Bird.density~Invertebrate biomass+sample_time,
> > random=~invert_biomass|Plot_identity, data=)
> >
> > How should I treat sample time? Is it a ordered categorical variable?
>
>    Depends on a number of things.  Your original message suggested
> that you sampled over the course of 30 days (maybe at different times
> in different plots?)  If this is the case (e.g. you sampled plot 1 on
> days 1, 5, 9, ... and plot 2 on days 2, 6, 10 ...) then it is probably
> most sensible to treat time as a numeric variable (i.e., assume a
> linear trend over days) and possibly a random effect with days as a
> grouping variable (in which case you might have to switch from lme to
> lmer).  If you have a small number of distinct sample days then a
> categorical variable makes sense. Whether you specify it as ordered or
> (default) unordered doesn't affect the overall fit of the model, just
> the particular contrasts that get tested with respect to the time
> variable.
>
>
> >
> > Thankyou very much.
> >
> > Joaquin
> >
> >
> > 2017-01-16 19:49 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
> >>
> >>
> >>   Center your biomass variable on this value: either create a
> >>
> >>   mydata$invert_biomass_c <- mydata$invert_biomass-ref_value
> >>
> >> or include it directly in your formula:
> >>
> >>    bird_dens ~ I(invert_biomass-ref_value), ...
> >>
> >> On 17-01-16 05:44 PM, Joaqu?n Aldabe wrote:
> >> > Thankyou very much Ben. Can you please suggest a way of fixing some
> >> > sensible reference quantity for Invertebrate biomass?
> >> > All the best,
> >> > Joaqu?n
> >> >
> >> > 2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
> >> > <mailto:bbolker at gmail.com>>:
> >> >
> >> >     That seems perfectly reasonable.  There are a couple of things to
> >> >     consider, although you may or may not find that your data supports
> >> >     that much complexity.
> >> >
> >> >     (1) The relationship between bird density and invert biomass, as
> >> > well
> >> >     as the intercept (i.e., expected bird density at invert_biomass=0,
> >> > or
> >> >     better invert_biomass=<some sensible reference quantity>)
> >> >
> >> >     lme(Bird.density~Invertebrate biomass,
> >> >     random=~invert_biomass|Plot_identity, data=)
> >> >
> >> >
> >> >     (2) The relationship might be changing over time?
> >> >
> >> >     lme(Bird.density~Invertebrate biomass+sample_time,
> >> >     random=~invert_biomass|Plot_identity, data=)
> >> >
> >> >     (3) In principle you could consider random effects of both time
> and
> >> >     invert biomass, but that will almost certainly overwhelm your
> data.
> >> >
> >> >       Don't forget to do the standard post-fitting checks: are your
> >> >     residuals *approximately* equal-variance and (even more
> >> > approximately)
> >> >     Normally distributed?  Is the relationship between bird density
> and
> >> >     invert biomass *approximately* linear?  (See ?plot.lme)
> >> >
> >> >
> >> >     On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
> >> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>>
> wrote:
> >> >     > Dear all, I'm interested in modeling the effect of invertebrate
> >> > biomass on
> >> >     > the density of a grassland shorebird (they eat invertebrates).
> For
> >> > this, I
> >> >     > picked 8 plots and sampled invertebrates and birds 6 times in
> each
> >> > plot for
> >> >     > about 30 days. This is, I went to each plot and did repeated
> >> > measures of
> >> >     > invertebrates biomass and shorebird density separated in time by
> >> > four or
> >> >     > five days, as invertebrates biomass may change over time and it
> is
> >> > expected
> >> >     > that birds density change accordingly.
> >> >     >
> >> >     > So, I'm trying to see a general pattern of the effect of changes
> >> > in biomass
> >> >     > on the density of this shorebird species at a plot scale. Plot
> >> > identity is
> >> >     > not important; I consider them as particular events of a random
> >> > process.
> >> >     >
> >> >     > Is this model correct:
> >> >     >
> >> >     > lme(Bird.density~Invertebrate biomass, random=~1|Plot_identity,
> >> > data=)
> >> >     >
> >> >     > Thank you very much,
> >> >     >
> >> >     > Joaquin.
> >> >     >
> >> >     >
> >> >     > --
> >> >     > *Joaqu?n Aldabe*
> >> >     >
> >> >     > *Grupo Biodiversidad, Ambiente y Sociedad*
> >> >     > Centro Universitario de la Regi?n Este, Universidad de la
> >> > Rep?blica
> >> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >> >     >
> >> >     > *Departamento de Conservaci?n*
> >> >     > Aves Uruguay
> >> >     > BirdLife International
> >> >     > Canelones 1164, Montevideo
> >> >     >
> >> >     > https://sites.google.com/site/joaquin.aldabe
> >> >     <https://sites.google.com/site/joaquin.aldabe>
> >> >     > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
> >> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
> >> >     >
> >> >     >         [[alternative HTML version deleted]]
> >> >     >
> >> >     > _______________________________________________
> >> >     > R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > *Joaqu?n Aldabe*
> >> >
> >> > /Grupo Biodiversidad, Ambiente y Sociedad/
> >> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> >> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >> >
> >> > /Departamento de Conservaci?n/
> >> > Aves Uruguay
> >> > BirdLife International
> >> > Canelones 1164, Montevideo
> >> >
> >> > https://sites.google.com/site/joaquin.aldabe
> >> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >> >
> >> >
> >> >
> >
> >
> >
> >
> > --
> > Joaqu?n Aldabe
> >
> > Grupo Biodiversidad, Ambiente y Sociedad
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > Departamento de Conservaci?n
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> >
> >
> >
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan 26 20:17:43 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 26 Jan 2017 14:17:43 -0500
Subject: [R-sig-ME] modeling question
In-Reply-To: <CAMM93=Lc==krj5bOTjoAkW_0gbSrrzaOKs8pAhS9Yi8HD0DHuQ@mail.gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
	<CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
	<8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>
	<CAMM93=+YZzVged7we2mhy6A3MZi5o_OFdNAQ6RBAeHS8hn_WqQ@mail.gmail.com>
	<CABghstQY+NNoWJxDV33GS7-QsABy+ZRpDtk7uxqApNmTrKeA8A@mail.gmail.com>
	<CAMM93=Lc==krj5bOTjoAkW_0gbSrrzaOKs8pAhS9Yi8HD0DHuQ@mail.gmail.com>
Message-ID: <516346fa-f06e-a04d-55e3-4ed19b7866ac@gmail.com>



On 17-01-26 02:11 PM, Joaqu?n Aldabe wrote:
> Thanks Ben, I sent all emails to the whole list. See below (in caps lock
> for differentiating from the other text). Regards, Joaquin
> 
> 2017-01-26 15:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>>:
> 
>     On Thu, Jan 26, 2017 at 9:38 AM, Joaqu?n Aldabe
>     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
>     > Dear Ben, it's me again
> 
> 
>     (I don't mind if you cc: me, but this is really a question to the
>     list. Probably better to frame it as "I sent this to the list and Ben
>     Bolker said ...")
> 
>     > with this subject about invertebrate biomass and its
>     > possible effect on shorebird density. I have a couple of extra doubts about
>     > your recommendations:
> 
> 
>     >
>     > You suggested this:
>     >
>     > (1) The relationship between bird density and invert biomass, as well
>     > as the intercept (i.e., expected bird density at invert_biomass=0, or
>     > better invert_biomass=<some sensible reference quantity>).
>     >
>     > I tried a quantity considering the lowest value of the invertebrate biomass
>     > variable, but the model did not converge. So I wonder if I should pick this
>     > value or a different one?
> 
>     Hmm, is this with lme or lmer?  Can you give more detail?  If it's
>     lmer, it's quite likely a false positive. I USED LME. I DON'T REALLY
>     KNOW WHAT DO YOU EXACTLY MEAN WITH SENSIBLE REFERENCE QUANTITY. I
>     THOUGHT IT WAS THE MINIMUM VALUE OF MY X VARIABLE (AS CERO IS NOT A
>     POSSIBILITY). 
> 

  The minimum value of your x variable is sensible.  The mean or median
would also be sensible.  It will change the interpretation of your
intercept parameter, and might improve convergence, but if the model
does converge then it won't change the overall fit of the model.

  If you're using lme and re-locating your x variable (i.e. using
I(invert_biomass-ref_value)) doesn't help with convergence, then there
might be something else wrong. We need more information (what was the
error message?  What are the general properties of your data?) and
preferably a reproducible example ...

>     >
>     > (2) The relationship might be changing over time?
>     >
>     > lme(Bird.density~Invertebrate biomass+sample_time,
>     > random=~invert_biomass|Plot_identity, data=)
>     >
>     > How should I treat sample time? Is it a ordered categorical variable?
> 
>        Depends on a number of things.  Your original message suggested
>     that you sampled over the course of 30 days (maybe at different times
>     in different plots?)  If this is the case (e.g. you sampled plot 1 on
>     days 1, 5, 9, ... and plot 2 on days 2, 6, 10 ...) then it is probably
>     most sensible to treat time as a numeric variable (i.e., assume a
>     linear trend over days) and possibly a random effect with days as a
>     grouping variable (in which case you might have to switch from lme to
>     lmer).  If you have a small number of distinct sample days then a
>     categorical variable makes sense. Whether you specify it as ordered or
>     (default) unordered doesn't affect the overall fit of the model, just
>     the particular contrasts that get tested with respect to the time
>     variable.
> 
> 
>     >
>     > Thankyou very much.
>     >
>     > Joaquin
>     >
>     >
>     > 2017-01-16 19:49 GMT-03:00 Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>>:
>     >>
>     >>
>     >>   Center your biomass variable on this value: either create a
>     >>
>     >>   mydata$invert_biomass_c <- mydata$invert_biomass-ref_value
>     >>
>     >> or include it directly in your formula:
>     >>
>     >>    bird_dens ~ I(invert_biomass-ref_value), ...
>     >>
>     >> On 17-01-16 05:44 PM, Joaqu?n Aldabe wrote:
>     >> > Thankyou very much Ben. Can you please suggest a way of fixing some
>     >> > sensible reference quantity for Invertebrate biomass?
>     >> > All the best,
>     >> > Joaqu?n
>     >> >
>     >> > 2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>
>     >> > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>>:
>     >> >
>     >> >     That seems perfectly reasonable.  There are a couple of
>     things to
>     >> >     consider, although you may or may not find that your data
>     supports
>     >> >     that much complexity.
>     >> >
>     >> >     (1) The relationship between bird density and invert
>     biomass, as
>     >> > well
>     >> >     as the intercept (i.e., expected bird density at
>     invert_biomass=0,
>     >> > or
>     >> >     better invert_biomass=<some sensible reference quantity>)
>     >> >
>     >> >     lme(Bird.density~Invertebrate biomass,
>     >> >     random=~invert_biomass|Plot_identity, data=)
>     >> >
>     >> >
>     >> >     (2) The relationship might be changing over time?
>     >> >
>     >> >     lme(Bird.density~Invertebrate biomass+sample_time,
>     >> >     random=~invert_biomass|Plot_identity, data=)
>     >> >
>     >> >     (3) In principle you could consider random effects of both
>     time and
>     >> >     invert biomass, but that will almost certainly overwhelm
>     your data.
>     >> >
>     >> >       Don't forget to do the standard post-fitting checks: are your
>     >> >     residuals *approximately* equal-variance and (even more
>     >> > approximately)
>     >> >     Normally distributed?  Is the relationship between bird
>     density and
>     >> >     invert biomass *approximately* linear?  (See ?plot.lme)
>     >> >
>     >> >
>     >> >     On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
>     >> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>
>     <mailto:joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>>>
>     wrote:
>     >> >     > Dear all, I'm interested in modeling the effect of
>     invertebrate
>     >> > biomass on
>     >> >     > the density of a grassland shorebird (they eat
>     invertebrates). For
>     >> > this, I
>     >> >     > picked 8 plots and sampled invertebrates and birds 6
>     times in each
>     >> > plot for
>     >> >     > about 30 days. This is, I went to each plot and did repeated
>     >> > measures of
>     >> >     > invertebrates biomass and shorebird density separated in
>     time by
>     >> > four or
>     >> >     > five days, as invertebrates biomass may change over time
>     and it is
>     >> > expected
>     >> >     > that birds density change accordingly.
>     >> >     >
>     >> >     > So, I'm trying to see a general pattern of the effect of
>     changes
>     >> > in biomass
>     >> >     > on the density of this shorebird species at a plot scale.
>     Plot
>     >> > identity is
>     >> >     > not important; I consider them as particular events of a
>     random
>     >> > process.
>     >> >     >
>     >> >     > Is this model correct:
>     >> >     >
>     >> >     > lme(Bird.density~Invertebrate biomass,
>     random=~1|Plot_identity,
>     >> > data=)
>     >> >     >
>     >> >     > Thank you very much,
>     >> >     >
>     >> >     > Joaquin.
>     >> >     >
>     >> >     >
>     >> >     > --
>     >> >     > *Joaqu?n Aldabe*
>     >> >     >
>     >> >     > *Grupo Biodiversidad, Ambiente y Sociedad*
>     >> >     > Centro Universitario de la Regi?n Este, Universidad de la
>     >> > Rep?blica
>     >> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     >> >     >
>     >> >     > *Departamento de Conservaci?n*
>     >> >     > Aves Uruguay
>     >> >     > BirdLife International
>     >> >     > Canelones 1164, Montevideo
>     >> >     >
>     >> >     > https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/joaquin.aldabe>
>     >> >     <https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/joaquin.aldabe>>
>     >> >     >
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>     >> >   
>      <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>>
>     >> >     >
>     >> >     >         [[alternative HTML version deleted]]
>     >> >     >
>     >> >     > _______________________________________________
>     >> >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >> >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >> >
>     >> >
>     >> >
>     >> >
>     >> > --
>     >> > *Joaqu?n Aldabe*
>     >> >
>     >> > /Grupo Biodiversidad, Ambiente y Sociedad/
>     >> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>     >> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     >> >
>     >> > /Departamento de Conservaci?n/
>     >> > Aves Uruguay
>     >> > BirdLife International
>     >> > Canelones 1164, Montevideo
>     >> >
>     >> > https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/joaquin.aldabe>
>     >> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
>     >> >
>     >> >
>     >> >
>     >
>     >
>     >
>     >
>     > --
>     > Joaqu?n Aldabe
>     >
>     > Grupo Biodiversidad, Ambiente y Sociedad
>     > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     >
>     > Departamento de Conservaci?n
>     > Aves Uruguay
>     > BirdLife International
>     > Canelones 1164, Montevideo
>     >
>     > https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/joaquin.aldabe>
>     >
>     >
>     >
> 
> 
> 
> 
> -- 
> *Joaqu?n Aldabe*
> 
> /Grupo Biodiversidad, Ambiente y Sociedad/
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha  
>                                                            
> /Departamento de Conservaci?n/
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
> 
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> 
> 
>


From joaquin.aldabe at gmail.com  Thu Jan 26 22:24:21 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 26 Jan 2017 18:24:21 -0300
Subject: [R-sig-ME] modeling question
In-Reply-To: <516346fa-f06e-a04d-55e3-4ed19b7866ac@gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
	<CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
	<8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>
	<CAMM93=+YZzVged7we2mhy6A3MZi5o_OFdNAQ6RBAeHS8hn_WqQ@mail.gmail.com>
	<CABghstQY+NNoWJxDV33GS7-QsABy+ZRpDtk7uxqApNmTrKeA8A@mail.gmail.com>
	<CAMM93=Lc==krj5bOTjoAkW_0gbSrrzaOKs8pAhS9Yi8HD0DHuQ@mail.gmail.com>
	<516346fa-f06e-a04d-55e3-4ed19b7866ac@gmail.com>
Message-ID: <CAMM93=+_X4q9g63WckFWXfXX=gYXXWzZjYvidfCgM4RxSJb9Dg@mail.gmail.com>

ok. These are the models I wrote. I'm attaching the data frame. The
variables mean.biom is the biomass in each count, Trysu_dens is the density
of birds in each count and Plot_name is the id of each plot. Let me know if
I'm not explaining myself adequately.

1) model with random intercept:

m2=lme(Trysu_dens~mean.biom, random=~1|Plot_name, data=try.dens.biom)

2) model with random slope and intercept, centering biomass with the mean

try.dens.biom$mean.biom.c=try.dens.biom$mean.biom-152.46
m2.1=lme(Trysu_dens~mean.biom.c, random=~mean.biom.c|Plot_name,
data=try.dens.biom)

2017-01-26 16:17 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

>
>
> On 17-01-26 02:11 PM, Joaqu?n Aldabe wrote:
> > Thanks Ben, I sent all emails to the whole list. See below (in caps lock
> > for differentiating from the other text). Regards, Joaquin
> >
> > 2017-01-26 15:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>>:
> >
> >     On Thu, Jan 26, 2017 at 9:38 AM, Joaqu?n Aldabe
> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
> >     > Dear Ben, it's me again
> >
> >
> >     (I don't mind if you cc: me, but this is really a question to the
> >     list. Probably better to frame it as "I sent this to the list and Ben
> >     Bolker said ...")
> >
> >     > with this subject about invertebrate biomass and its
> >     > possible effect on shorebird density. I have a couple of extra
> doubts about
> >     > your recommendations:
> >
> >
> >     >
> >     > You suggested this:
> >     >
> >     > (1) The relationship between bird density and invert biomass, as
> well
> >     > as the intercept (i.e., expected bird density at invert_biomass=0,
> or
> >     > better invert_biomass=<some sensible reference quantity>).
> >     >
> >     > I tried a quantity considering the lowest value of the
> invertebrate biomass
> >     > variable, but the model did not converge. So I wonder if I should
> pick this
> >     > value or a different one?
> >
> >     Hmm, is this with lme or lmer?  Can you give more detail?  If it's
> >     lmer, it's quite likely a false positive. I USED LME. I DON'T REALLY
> >     KNOW WHAT DO YOU EXACTLY MEAN WITH SENSIBLE REFERENCE QUANTITY. I
> >     THOUGHT IT WAS THE MINIMUM VALUE OF MY X VARIABLE (AS CERO IS NOT A
> >     POSSIBILITY).
> >
>
>   The minimum value of your x variable is sensible.  The mean or median
> would also be sensible.  It will change the interpretation of your
> intercept parameter, and might improve convergence, but if the model
> does converge then it won't change the overall fit of the model.
>
>   If you're using lme and re-locating your x variable (i.e. using
> I(invert_biomass-ref_value)) doesn't help with convergence, then there
> might be something else wrong. We need more information (what was the
> error message?  What are the general properties of your data?) and
> preferably a reproducible example ...
>
> >     >
> >     > (2) The relationship might be changing over time?
> >     >
> >     > lme(Bird.density~Invertebrate biomass+sample_time,
> >     > random=~invert_biomass|Plot_identity, data=)
> >     >
> >     > How should I treat sample time? Is it a ordered categorical
> variable?
> >
> >        Depends on a number of things.  Your original message suggested
> >     that you sampled over the course of 30 days (maybe at different times
> >     in different plots?)  If this is the case (e.g. you sampled plot 1 on
> >     days 1, 5, 9, ... and plot 2 on days 2, 6, 10 ...) then it is
> probably
> >     most sensible to treat time as a numeric variable (i.e., assume a
> >     linear trend over days) and possibly a random effect with days as a
> >     grouping variable (in which case you might have to switch from lme to
> >     lmer).  If you have a small number of distinct sample days then a
> >     categorical variable makes sense. Whether you specify it as ordered
> or
> >     (default) unordered doesn't affect the overall fit of the model, just
> >     the particular contrasts that get tested with respect to the time
> >     variable.
> >
> >
> >     >
> >     > Thankyou very much.
> >     >
> >     > Joaquin
> >     >
> >     >
> >     > 2017-01-16 19:49 GMT-03:00 Ben Bolker <bbolker at gmail.com
> >     <mailto:bbolker at gmail.com>>:
> >     >>
> >     >>
> >     >>   Center your biomass variable on this value: either create a
> >     >>
> >     >>   mydata$invert_biomass_c <- mydata$invert_biomass-ref_value
> >     >>
> >     >> or include it directly in your formula:
> >     >>
> >     >>    bird_dens ~ I(invert_biomass-ref_value), ...
> >     >>
> >     >> On 17-01-16 05:44 PM, Joaqu?n Aldabe wrote:
> >     >> > Thankyou very much Ben. Can you please suggest a way of fixing
> some
> >     >> > sensible reference quantity for Invertebrate biomass?
> >     >> > All the best,
> >     >> > Joaqu?n
> >     >> >
> >     >> > 2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
> >     <mailto:bbolker at gmail.com>
> >     >> > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>>:
> >     >> >
> >     >> >     That seems perfectly reasonable.  There are a couple of
> >     things to
> >     >> >     consider, although you may or may not find that your data
> >     supports
> >     >> >     that much complexity.
> >     >> >
> >     >> >     (1) The relationship between bird density and invert
> >     biomass, as
> >     >> > well
> >     >> >     as the intercept (i.e., expected bird density at
> >     invert_biomass=0,
> >     >> > or
> >     >> >     better invert_biomass=<some sensible reference quantity>)
> >     >> >
> >     >> >     lme(Bird.density~Invertebrate biomass,
> >     >> >     random=~invert_biomass|Plot_identity, data=)
> >     >> >
> >     >> >
> >     >> >     (2) The relationship might be changing over time?
> >     >> >
> >     >> >     lme(Bird.density~Invertebrate biomass+sample_time,
> >     >> >     random=~invert_biomass|Plot_identity, data=)
> >     >> >
> >     >> >     (3) In principle you could consider random effects of both
> >     time and
> >     >> >     invert biomass, but that will almost certainly overwhelm
> >     your data.
> >     >> >
> >     >> >       Don't forget to do the standard post-fitting checks: are
> your
> >     >> >     residuals *approximately* equal-variance and (even more
> >     >> > approximately)
> >     >> >     Normally distributed?  Is the relationship between bird
> >     density and
> >     >> >     invert biomass *approximately* linear?  (See ?plot.lme)
> >     >> >
> >     >> >
> >     >> >     On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
> >     >> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>
> >     <mailto:joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>>>
> >     wrote:
> >     >> >     > Dear all, I'm interested in modeling the effect of
> >     invertebrate
> >     >> > biomass on
> >     >> >     > the density of a grassland shorebird (they eat
> >     invertebrates). For
> >     >> > this, I
> >     >> >     > picked 8 plots and sampled invertebrates and birds 6
> >     times in each
> >     >> > plot for
> >     >> >     > about 30 days. This is, I went to each plot and did
> repeated
> >     >> > measures of
> >     >> >     > invertebrates biomass and shorebird density separated in
> >     time by
> >     >> > four or
> >     >> >     > five days, as invertebrates biomass may change over time
> >     and it is
> >     >> > expected
> >     >> >     > that birds density change accordingly.
> >     >> >     >
> >     >> >     > So, I'm trying to see a general pattern of the effect of
> >     changes
> >     >> > in biomass
> >     >> >     > on the density of this shorebird species at a plot scale.
> >     Plot
> >     >> > identity is
> >     >> >     > not important; I consider them as particular events of a
> >     random
> >     >> > process.
> >     >> >     >
> >     >> >     > Is this model correct:
> >     >> >     >
> >     >> >     > lme(Bird.density~Invertebrate biomass,
> >     random=~1|Plot_identity,
> >     >> > data=)
> >     >> >     >
> >     >> >     > Thank you very much,
> >     >> >     >
> >     >> >     > Joaquin.
> >     >> >     >
> >     >> >     >
> >     >> >     > --
> >     >> >     > *Joaqu?n Aldabe*
> >     >> >     >
> >     >> >     > *Grupo Biodiversidad, Ambiente y Sociedad*
> >     >> >     > Centro Universitario de la Regi?n Este, Universidad de la
> >     >> > Rep?blica
> >     >> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >     >> >     >
> >     >> >     > *Departamento de Conservaci?n*
> >     >> >     > Aves Uruguay
> >     >> >     > BirdLife International
> >     >> >     > Canelones 1164, Montevideo
> >     >> >     >
> >     >> >     > https://sites.google.com/site/joaquin.aldabe
> >     <https://sites.google.com/site/joaquin.aldabe>
> >     >> >     <https://sites.google.com/site/joaquin.aldabe
> >     <https://sites.google.com/site/joaquin.aldabe>>
> >     >> >     >
> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >     >> >
> >      <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>>
> >     >> >     >
> >     >> >     >         [[alternative HTML version deleted]]
> >     >> >     >
> >     >> >     > _______________________________________________
> >     >> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >> >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     >> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >> >
> >     >> >
> >     >> >
> >     >> >
> >     >> > --
> >     >> > *Joaqu?n Aldabe*
> >     >> >
> >     >> > /Grupo Biodiversidad, Ambiente y Sociedad/
> >     >> > Centro Universitario de la Regi?n Este, Universidad de la
> Rep?blica
> >     >> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >     >> >
> >     >> > /Departamento de Conservaci?n/
> >     >> > Aves Uruguay
> >     >> > BirdLife International
> >     >> > Canelones 1164, Montevideo
> >     >> >
> >     >> > https://sites.google.com/site/joaquin.aldabe
> >     <https://sites.google.com/site/joaquin.aldabe>
> >     >> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
> >     >> >
> >     >> >
> >     >> >
> >     >
> >     >
> >     >
> >     >
> >     > --
> >     > Joaqu?n Aldabe
> >     >
> >     > Grupo Biodiversidad, Ambiente y Sociedad
> >     > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >     >
> >     > Departamento de Conservaci?n
> >     > Aves Uruguay
> >     > BirdLife International
> >     > Canelones 1164, Montevideo
> >     >
> >     > https://sites.google.com/site/joaquin.aldabe
> >     <https://sites.google.com/site/joaquin.aldabe>
> >     >
> >     >
> >     >
> >
> >
> >
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > /Grupo Biodiversidad, Ambiente y Sociedad/
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > /Departamento de Conservaci?n/
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >
> >
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

From joaquin.aldabe at gmail.com  Thu Jan 26 22:26:24 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 26 Jan 2017 18:26:24 -0300
Subject: [R-sig-ME] modeling question
In-Reply-To: <CAMM93=+_X4q9g63WckFWXfXX=gYXXWzZjYvidfCgM4RxSJb9Dg@mail.gmail.com>
References: <CAMM93=KtXra+o=50jYj0dz=heQuuA+jrTvCDeqcU9qZOTwutuA@mail.gmail.com>
	<CABghstSa8-n=3ODrw9OvBtHAvPQFhYrTB-aOrPe+nyWC7UXZWQ@mail.gmail.com>
	<CAMM93=Lep3R+1ypgrhCq4XStUahyQ=G+h7bpvVJzzYG1pxfmfA@mail.gmail.com>
	<8e41198c-bc50-d15a-bcae-9e71d32121f4@gmail.com>
	<CAMM93=+YZzVged7we2mhy6A3MZi5o_OFdNAQ6RBAeHS8hn_WqQ@mail.gmail.com>
	<CABghstQY+NNoWJxDV33GS7-QsABy+ZRpDtk7uxqApNmTrKeA8A@mail.gmail.com>
	<CAMM93=Lc==krj5bOTjoAkW_0gbSrrzaOKs8pAhS9Yi8HD0DHuQ@mail.gmail.com>
	<516346fa-f06e-a04d-55e3-4ed19b7866ac@gmail.com>
	<CAMM93=+_X4q9g63WckFWXfXX=gYXXWzZjYvidfCgM4RxSJb9Dg@mail.gmail.com>
Message-ID: <CAMM93=LBGTxnR9XxnjtsMPQgkQjQKsJ8=A7wwQY13r+pk8UMvQ@mail.gmail.com>

I forgot to mentioned that I divided the biomass of each count by the
number of traps (NTrampas) and used this as the predictor, as there were
differences in the number of functional traps per count because of trap
lost.

2017-01-26 18:24 GMT-03:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> ok. These are the models I wrote. I'm attaching the data frame. The
> variables mean.biom is the biomass in each count, Trysu_dens is the density
> of birds in each count and Plot_name is the id of each plot. Let me know if
> I'm not explaining myself adequately.
>
> 1) model with random intercept:
>
> m2=lme(Trysu_dens~mean.biom, random=~1|Plot_name, data=try.dens.biom)
>
> 2) model with random slope and intercept, centering biomass with the mean
>
> try.dens.biom$mean.biom.c=try.dens.biom$mean.biom-152.46
> m2.1=lme(Trysu_dens~mean.biom.c, random=~mean.biom.c|Plot_name,
> data=try.dens.biom)
>
> 2017-01-26 16:17 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>
>>
>>
>> On 17-01-26 02:11 PM, Joaqu?n Aldabe wrote:
>> > Thanks Ben, I sent all emails to the whole list. See below (in caps lock
>> > for differentiating from the other text). Regards, Joaquin
>> >
>> > 2017-01-26 15:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
>> > <mailto:bbolker at gmail.com>>:
>> >
>> >     On Thu, Jan 26, 2017 at 9:38 AM, Joaqu?n Aldabe
>> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
>> >     > Dear Ben, it's me again
>> >
>> >
>> >     (I don't mind if you cc: me, but this is really a question to the
>> >     list. Probably better to frame it as "I sent this to the list and
>> Ben
>> >     Bolker said ...")
>> >
>> >     > with this subject about invertebrate biomass and its
>> >     > possible effect on shorebird density. I have a couple of extra
>> doubts about
>> >     > your recommendations:
>> >
>> >
>> >     >
>> >     > You suggested this:
>> >     >
>> >     > (1) The relationship between bird density and invert biomass, as
>> well
>> >     > as the intercept (i.e., expected bird density at
>> invert_biomass=0, or
>> >     > better invert_biomass=<some sensible reference quantity>).
>> >     >
>> >     > I tried a quantity considering the lowest value of the
>> invertebrate biomass
>> >     > variable, but the model did not converge. So I wonder if I should
>> pick this
>> >     > value or a different one?
>> >
>> >     Hmm, is this with lme or lmer?  Can you give more detail?  If it's
>> >     lmer, it's quite likely a false positive. I USED LME. I DON'T REALLY
>> >     KNOW WHAT DO YOU EXACTLY MEAN WITH SENSIBLE REFERENCE QUANTITY. I
>> >     THOUGHT IT WAS THE MINIMUM VALUE OF MY X VARIABLE (AS CERO IS NOT A
>> >     POSSIBILITY).
>> >
>>
>>   The minimum value of your x variable is sensible.  The mean or median
>> would also be sensible.  It will change the interpretation of your
>> intercept parameter, and might improve convergence, but if the model
>> does converge then it won't change the overall fit of the model.
>>
>>   If you're using lme and re-locating your x variable (i.e. using
>> I(invert_biomass-ref_value)) doesn't help with convergence, then there
>> might be something else wrong. We need more information (what was the
>> error message?  What are the general properties of your data?) and
>> preferably a reproducible example ...
>>
>> >     >
>> >     > (2) The relationship might be changing over time?
>> >     >
>> >     > lme(Bird.density~Invertebrate biomass+sample_time,
>> >     > random=~invert_biomass|Plot_identity, data=)
>> >     >
>> >     > How should I treat sample time? Is it a ordered categorical
>> variable?
>> >
>> >        Depends on a number of things.  Your original message suggested
>> >     that you sampled over the course of 30 days (maybe at different
>> times
>> >     in different plots?)  If this is the case (e.g. you sampled plot 1
>> on
>> >     days 1, 5, 9, ... and plot 2 on days 2, 6, 10 ...) then it is
>> probably
>> >     most sensible to treat time as a numeric variable (i.e., assume a
>> >     linear trend over days) and possibly a random effect with days as a
>> >     grouping variable (in which case you might have to switch from lme
>> to
>> >     lmer).  If you have a small number of distinct sample days then a
>> >     categorical variable makes sense. Whether you specify it as ordered
>> or
>> >     (default) unordered doesn't affect the overall fit of the model,
>> just
>> >     the particular contrasts that get tested with respect to the time
>> >     variable.
>> >
>> >
>> >     >
>> >     > Thankyou very much.
>> >     >
>> >     > Joaquin
>> >     >
>> >     >
>> >     > 2017-01-16 19:49 GMT-03:00 Ben Bolker <bbolker at gmail.com
>> >     <mailto:bbolker at gmail.com>>:
>> >     >>
>> >     >>
>> >     >>   Center your biomass variable on this value: either create a
>> >     >>
>> >     >>   mydata$invert_biomass_c <- mydata$invert_biomass-ref_value
>> >     >>
>> >     >> or include it directly in your formula:
>> >     >>
>> >     >>    bird_dens ~ I(invert_biomass-ref_value), ...
>> >     >>
>> >     >> On 17-01-16 05:44 PM, Joaqu?n Aldabe wrote:
>> >     >> > Thankyou very much Ben. Can you please suggest a way of fixing
>> some
>> >     >> > sensible reference quantity for Invertebrate biomass?
>> >     >> > All the best,
>> >     >> > Joaqu?n
>> >     >> >
>> >     >> > 2017-01-16 18:59 GMT-03:00 Ben Bolker <bbolker at gmail.com
>> >     <mailto:bbolker at gmail.com>
>> >     >> > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>>:
>> >     >> >
>> >     >> >     That seems perfectly reasonable.  There are a couple of
>> >     things to
>> >     >> >     consider, although you may or may not find that your data
>> >     supports
>> >     >> >     that much complexity.
>> >     >> >
>> >     >> >     (1) The relationship between bird density and invert
>> >     biomass, as
>> >     >> > well
>> >     >> >     as the intercept (i.e., expected bird density at
>> >     invert_biomass=0,
>> >     >> > or
>> >     >> >     better invert_biomass=<some sensible reference quantity>)
>> >     >> >
>> >     >> >     lme(Bird.density~Invertebrate biomass,
>> >     >> >     random=~invert_biomass|Plot_identity, data=)
>> >     >> >
>> >     >> >
>> >     >> >     (2) The relationship might be changing over time?
>> >     >> >
>> >     >> >     lme(Bird.density~Invertebrate biomass+sample_time,
>> >     >> >     random=~invert_biomass|Plot_identity, data=)
>> >     >> >
>> >     >> >     (3) In principle you could consider random effects of both
>> >     time and
>> >     >> >     invert biomass, but that will almost certainly overwhelm
>> >     your data.
>> >     >> >
>> >     >> >       Don't forget to do the standard post-fitting checks: are
>> your
>> >     >> >     residuals *approximately* equal-variance and (even more
>> >     >> > approximately)
>> >     >> >     Normally distributed?  Is the relationship between bird
>> >     density and
>> >     >> >     invert biomass *approximately* linear?  (See ?plot.lme)
>> >     >> >
>> >     >> >
>> >     >> >     On Mon, Jan 16, 2017 at 2:06 PM, Joaqu?n Aldabe
>> >     >> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com
>> >
>> >     <mailto:joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com
>> >>>
>> >     wrote:
>> >     >> >     > Dear all, I'm interested in modeling the effect of
>> >     invertebrate
>> >     >> > biomass on
>> >     >> >     > the density of a grassland shorebird (they eat
>> >     invertebrates). For
>> >     >> > this, I
>> >     >> >     > picked 8 plots and sampled invertebrates and birds 6
>> >     times in each
>> >     >> > plot for
>> >     >> >     > about 30 days. This is, I went to each plot and did
>> repeated
>> >     >> > measures of
>> >     >> >     > invertebrates biomass and shorebird density separated in
>> >     time by
>> >     >> > four or
>> >     >> >     > five days, as invertebrates biomass may change over time
>> >     and it is
>> >     >> > expected
>> >     >> >     > that birds density change accordingly.
>> >     >> >     >
>> >     >> >     > So, I'm trying to see a general pattern of the effect of
>> >     changes
>> >     >> > in biomass
>> >     >> >     > on the density of this shorebird species at a plot scale.
>> >     Plot
>> >     >> > identity is
>> >     >> >     > not important; I consider them as particular events of a
>> >     random
>> >     >> > process.
>> >     >> >     >
>> >     >> >     > Is this model correct:
>> >     >> >     >
>> >     >> >     > lme(Bird.density~Invertebrate biomass,
>> >     random=~1|Plot_identity,
>> >     >> > data=)
>> >     >> >     >
>> >     >> >     > Thank you very much,
>> >     >> >     >
>> >     >> >     > Joaquin.
>> >     >> >     >
>> >     >> >     >
>> >     >> >     > --
>> >     >> >     > *Joaqu?n Aldabe*
>> >     >> >     >
>> >     >> >     > *Grupo Biodiversidad, Ambiente y Sociedad*
>> >     >> >     > Centro Universitario de la Regi?n Este, Universidad de la
>> >     >> > Rep?blica
>> >     >> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >     >> >     >
>> >     >> >     > *Departamento de Conservaci?n*
>> >     >> >     > Aves Uruguay
>> >     >> >     > BirdLife International
>> >     >> >     > Canelones 1164, Montevideo
>> >     >> >     >
>> >     >> >     > https://sites.google.com/site/joaquin.aldabe
>> >     <https://sites.google.com/site/joaquin.aldabe>
>> >     >> >     <https://sites.google.com/site/joaquin.aldabe
>> >     <https://sites.google.com/site/joaquin.aldabe>>
>> >     >> >     >
>> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> >     >> >
>> >      <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>>
>> >     >> >     >
>> >     >> >     >         [[alternative HTML version deleted]]
>> >     >> >     >
>> >     >> >     > _______________________________________________
>> >     >> >     > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >> >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>> >     >> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> >     >> >
>> >     >> >
>> >     >> >
>> >     >> >
>> >     >> > --
>> >     >> > *Joaqu?n Aldabe*
>> >     >> >
>> >     >> > /Grupo Biodiversidad, Ambiente y Sociedad/
>> >     >> > Centro Universitario de la Regi?n Este, Universidad de la
>> Rep?blica
>> >     >> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >     >> >
>> >     >> > /Departamento de Conservaci?n/
>> >     >> > Aves Uruguay
>> >     >> > BirdLife International
>> >     >> > Canelones 1164, Montevideo
>> >     >> >
>> >     >> > https://sites.google.com/site/joaquin.aldabe
>> >     <https://sites.google.com/site/joaquin.aldabe>
>> >     >> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
>> >     >> >
>> >     >> >
>> >     >> >
>> >     >
>> >     >
>> >     >
>> >     >
>> >     > --
>> >     > Joaqu?n Aldabe
>> >     >
>> >     > Grupo Biodiversidad, Ambiente y Sociedad
>> >     > Centro Universitario de la Regi?n Este, Universidad de la
>> Rep?blica
>> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >     >
>> >     > Departamento de Conservaci?n
>> >     > Aves Uruguay
>> >     > BirdLife International
>> >     > Canelones 1164, Montevideo
>> >     >
>> >     > https://sites.google.com/site/joaquin.aldabe
>> >     <https://sites.google.com/site/joaquin.aldabe>
>> >     >
>> >     >
>> >     >
>> >
>> >
>> >
>> >
>> > --
>> > *Joaqu?n Aldabe*
>> >
>> > /Grupo Biodiversidad, Ambiente y Sociedad/
>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >
>> > /Departamento de Conservaci?n/
>> > Aves Uruguay
>> > BirdLife International
>> > Canelones 1164, Montevideo
>> >
>> > https://sites.google.com/site/joaquin.aldabe
>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> >
>> >
>> >
>>
>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>
>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri Jan 27 06:37:55 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 27 Jan 2017 05:37:55 +0000
Subject: [R-sig-ME] Correct specification of nested binomial mixed model
 with custom intercept to infer variance components and intraclass
 correlations
In-Reply-To: <1485443532333.72208@kuleuven.be>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W198183686B973039916732CBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk> <558ADB54.3020304@glasgow.ac.uk>
	<1485443532333.72208@kuleuven.be>
Message-ID: <f504e208-c486-9813-f299-a5fcfd23e055@ed.ac.uk>

Hi Tom,

If I understand your experiment/data set up, each row of the data frame 
contains all the data for one trial? If so, having trial as random 
effect is one way of modelling any overdispersion in the data with 
respect to the binomial. If overdispersion exists it is important to 
model this. Other than that the random effect structure seems fine.

Also I don't understand why baseline is fitted, especially as an offset. 
If you are fitting patriline as a random effect presumably you know the 
patriline for each bee? Why then fit the proportion of the colony that 
has the same patriline as the bee, and why fix the associated 
coefficient to one?

Cheers,

Jarrod



On 26/01/2017 15:11, Tom Wenseleers wrote:
> Dear all,
> Just to ask a bit of advice about the correct way to specify a nested binomial GLM, in the context of estimating variance components / intraclass correlations to infer heritabilities of a behavioural trait.
>
> The behavioural trait is a binary one (eating an egg or not, 1 or 0), and is performed by known individual honeybees (individually numbered, ?individual_ID?) of a known father line (?patriline?) of a given hive (?colony?). Several subsequent egg eating events could be performed by the same individuals. Of each experiment with each colony several trials were done, and for each trial we have data on how many eggs were eaten in total, so we could analyse as a dependent variable the proportion of those eggs that were eaten by a given individual. In addition, we also genotyped a bunch of bees of each colony, which gave us the patriline distribution within each colony (?expected_proportion_patriline?), i.e. the proportion that each patriline makes up in the colony, which I thought should affect the a priori probability that bees of a given patriline would be observed eating eggs.
>
> My question is what mixed model syntax would make most sense to analyse this data, and allows us to infer variance components and intraclass correlations as a basis for a heritability estimate of this egg eating behaviour?
>
> One model I thought of was to include the expected proportion of each patriline that is present as a custom offset, using
> library(afex)
> set_sum_contrasts() # use effect coding
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-1+(1|colony/patriline/ID), offset=baseline, data=data, family=binomial)
> but would this model make sense as a basis to estimate the variance components and intraclass correlation?
>
> In another model I worked with the mean eggs eaten by bees of a given patriline and then fitted the model
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit2=glmer(cbind(eggs_eaten_by_patriline, eggs_eaten_in_total_intrial ? eggs_eaten_by_patriline)~-1+(1|colony/patriline), offset=baseline, data=data, family=binomial)
>
> Again though I am not sure if such a model would make sense, and neither of my two models take trial explicitly as a factor. Would anybody have any advice by any chance about the most sensible model given my experimental design (proportion data, with individuals nested in patriline nested in colony, with repeated trials and a priori info on the proportion of eggs that would be expected to be eaten by each patriline based on independent genotyping, which could perhaps be included as a custom intercept or a covariate)?
>
> Best regards,
> Tom Wenseleers
> Dept of Biology
> University of Leuven
> Belgium
>
> _____
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From tom.wenseleers at kuleuven.be  Fri Jan 27 10:12:33 2017
From: tom.wenseleers at kuleuven.be (Tom Wenseleers)
Date: Fri, 27 Jan 2017 09:12:33 +0000
Subject: [R-sig-ME] Correct specification of nested binomial mixed model
 with custom intercept to infer variance components and intraclass
 correlations
In-Reply-To: <f504e208-c486-9813-f299-a5fcfd23e055@ed.ac.uk>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W198183686B973039916732CBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk> <558ADB54.3020304@glasgow.ac.uk>
	<1485443532333.72208@kuleuven.be>,
	<f504e208-c486-9813-f299-a5fcfd23e055@ed.ac.uk>
Message-ID: <1485508405900.26497@kuleuven.be>

Hi Jarrod,
Well the structure of the datafile is such that each row of the datafile contains the proportion of the eggs eaten in each trial by each individual bee (that belongs to a particular patriline, ie there would be several lines per trial corresponding to different individual bees, some of which might also occur again in different trials with the same colony) (this is in fit1 below) or the mean proportion of the eggs eaten in each trial by a patricular patriline (in fit2 below). So I was not entirely sure how I should still incorporate trial as a random effect as well, and how this would look like?
The reason that I thought it would make sense to also include the proportional distribution of the different patrilines in the colony (either as a custom intercept or a covariate, not sure about that) in the model is that these give the a priori probability that eggs would be eaten by bees belonging to different patrilines (as they are heavily skewed), so the heritability of the trait would be expressed mainly in terms of some patrilines making a much greater or much lower contribution to egg eating than expected based on their proportional presence in the colony. But I am not sure how I would correctly do that in my model, hence my question? Makes sense?

cheers,
Tom

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: 27 January 2017 06:37
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Correct specification of nested binomial mixed model with custom intercept to infer variance components and intraclass correlations

Hi Tom,

If I understand your experiment/data set up, each row of the data frame
contains all the data for one trial? If so, having trial as random
effect is one way of modelling any overdispersion in the data with
respect to the binomial. If overdispersion exists it is important to
model this. Other than that the random effect structure seems fine.

Also I don't understand why baseline is fitted, especially as an offset.
If you are fitting patriline as a random effect presumably you know the
patriline for each bee? Why then fit the proportion of the colony that
has the same patriline as the bee, and why fix the associated
coefficient to one?

Cheers,

Jarrod



On 26/01/2017 15:11, Tom Wenseleers wrote:
> Dear all,
> Just to ask a bit of advice about the correct way to specify a nested binomial GLM, in the context of estimating variance components / intraclass correlations to infer heritabilities of a behavioural trait.
>
> The behavioural trait is a binary one (eating an egg or not, 1 or 0), and is performed by known individual honeybees (individually numbered, ?individual_ID?) of a known father line (?patriline?) of a given hive (?colony?). Several subsequent egg eating events could be performed by the same individuals. Of each experiment with each colony several trials were done, and for each trial we have data on how many eggs were eaten in total, so we could analyse as a dependent variable the proportion of those eggs that were eaten by a given individual. In addition, we also genotyped a bunch of bees of each colony, which gave us the patriline distribution within each colony (?expected_proportion_patriline?), i.e. the proportion that each patriline makes up in the colony, which I thought should affect the a priori probability that bees of a given patriline would be observed eating eggs.
>
> My question is what mixed model syntax would make most sense to analyse this data, and allows us to infer variance components and intraclass correlations as a basis for a heritability estimate of this egg eating behaviour?
>
> One model I thought of was to include the expected proportion of each patriline that is present as a custom offset, using
> library(afex)
> set_sum_contrasts() # use effect coding
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-1+(1|colony/patriline/ID), offset=baseline, data=data, family=binomial)
> but would this model make sense as a basis to estimate the variance components and intraclass correlation?
>
> In another model I worked with the mean eggs eaten by bees of a given patriline and then fitted the model
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit2=glmer(cbind(eggs_eaten_by_patriline, eggs_eaten_in_total_intrial ? eggs_eaten_by_patriline)~-1+(1|colony/patriline), offset=baseline, data=data, family=binomial)
>
> Again though I am not sure if such a model would make sense, and neither of my two models take trial explicitly as a factor. Would anybody have any advice by any chance about the most sensible model given my experimental design (proportion data, with individuals nested in patriline nested in colony, with repeated trials and a priori info on the proportion of eggs that would be expected to be eaten by each patriline based on independent genotyping, which could perhaps be included as a custom intercept or a covariate)?
>
> Best regards,
> Tom Wenseleers
> Dept of Biology
> University of Leuven
> Belgium
>
> _____
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tom.wenseleers at kuleuven.be  Fri Jan 27 13:45:12 2017
From: tom.wenseleers at kuleuven.be (Tom Wenseleers)
Date: Fri, 27 Jan 2017 12:45:12 +0000
Subject: [R-sig-ME] Correct specification of nested binomial mixed model
 with custom intercept to infer variance components and intraclass
 correlations
In-Reply-To: <1485508405900.26497@kuleuven.be>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W198183686B973039916732CBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk> <558ADB54.3020304@glasgow.ac.uk>
	<1485443532333.72208@kuleuven.be>,
	<f504e208-c486-9813-f299-a5fcfd23e055@ed.ac.uk>,
	<1485508405900.26497@kuleuven.be>
Message-ID: <1485521165610.87517@kuleuven.be>

Hi Jarrod,
Well the structure of the datafile is such that each row of the datafile contains the proportion of the eggs eaten in each trial by each individual bee (that belongs to a particular patriline, ie there would be several lines per trial corresponding to different individual bees, some of which might also occur again in different trials with the same colony) (this is in fit1 below) or the mean proportion of the eggs eaten in each trial by a patricular patriline (in fit2 below). So I was not entirely sure how I should still incorporate trial as a random effect as well, and how this would look like?
The reason that I thought it would make sense to also include the proportional distribution of the different patrilines in the colony (either as a custom intercept or a covariate, not sure about that) in the model is that these give the a priori probability that eggs would be eaten by bees belonging to different patrilines (as they are heavily skewed), so the heritability of the trait would be expressed mainly in terms of some patrilines making a much greater or much lower contribution to egg eating than expected based on their proportional presence in the colony. But I am not sure how I would correctly do that in my model, hence my question? Makes sense?

cheers,
Tom

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: 27 January 2017 06:37
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Correct specification of nested binomial mixed model with custom intercept to infer variance components and intraclass correlations

Hi Tom,

If I understand your experiment/data set up, each row of the data frame
contains all the data for one trial? If so, having trial as random
effect is one way of modelling any overdispersion in the data with
respect to the binomial. If overdispersion exists it is important to
model this. Other than that the random effect structure seems fine.

Also I don't understand why baseline is fitted, especially as an offset.
If you are fitting patriline as a random effect presumably you know the
patriline for each bee? Why then fit the proportion of the colony that
has the same patriline as the bee, and why fix the associated
coefficient to one?

Cheers,

Jarrod



On 26/01/2017 15:11, Tom Wenseleers wrote:
> Dear all,
> Just to ask a bit of advice about the correct way to specify a nested binomial GLM, in the context of estimating variance components / intraclass correlations to infer heritabilities of a behavioural trait.
>
> The behavioural trait is a binary one (eating an egg or not, 1 or 0), and is performed by known individual honeybees (individually numbered, ?individual_ID?) of a known father line (?patriline?) of a given hive (?colony?). Several subsequent egg eating events could be performed by the same individuals. Of each experiment with each colony several trials were done, and for each trial we have data on how many eggs were eaten in total, so we could analyse as a dependent variable the proportion of those eggs that were eaten by a given individual. In addition, we also genotyped a bunch of bees of each colony, which gave us the patriline distribution within each colony (?expected_proportion_patriline?), i.e. the proportion that each patriline makes up in the colony, which I thought should affect the a priori probability that bees of a given patriline would be observed eating eggs.
>
> My question is what mixed model syntax would make most sense to analyse this data, and allows us to infer variance components and intraclass correlations as a basis for a heritability estimate of this egg eating behaviour?
>
> One model I thought of was to include the expected proportion of each patriline that is present as a custom offset, using
> library(afex)
> set_sum_contrasts() # use effect coding
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-1+(1|colony/patriline/ID), offset=baseline, data=data, family=binomial)
> but would this model make sense as a basis to estimate the variance components and intraclass correlation?
>
> In another model I worked with the mean eggs eaten by bees of a given patriline and then fitted the model
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit2=glmer(cbind(eggs_eaten_by_patriline, eggs_eaten_in_total_intrial ? eggs_eaten_by_patriline)~-1+(1|colony/patriline), offset=baseline, data=data, family=binomial)
>
> Again though I am not sure if such a model would make sense, and neither of my two models take trial explicitly as a factor. Would anybody have any advice by any chance about the most sensible model given my experimental design (proportion data, with individuals nested in patriline nested in colony, with repeated trials and a priori info on the proportion of eggs that would be expected to be eaten by each patriline based on independent genotyping, which could perhaps be included as a custom intercept or a covariate)?
>
> Best regards,
> Tom Wenseleers
> Dept of Biology
> University of Leuven
> Belgium
>
> _____
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tom.wenseleers at kuleuven.be  Fri Jan 27 15:42:55 2017
From: tom.wenseleers at kuleuven.be (Tom Wenseleers)
Date: Fri, 27 Jan 2017 14:42:55 +0000
Subject: [R-sig-ME] Correct specification of nested binomial mixed model
 with custom intercept to infer variance components and intraclass
 correlations
In-Reply-To: <1485521165610.87517@kuleuven.be>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W198183686B973039916732CBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk> <558ADB54.3020304@glasgow.ac.uk>
	<1485443532333.72208@kuleuven.be>,
	<f504e208-c486-9813-f299-a5fcfd23e055@ed.ac.uk>,
	<1485508405900.26497@kuleuven.be>,<1485521165610.87517@kuleuven.be>
Message-ID: <1485528229525.12125@kuleuven.be>

Hi Jarrod,
In the meantime I think I found what I was doing wrong - I should have included all the control bees that we genotyped and which did not eat any eggs as well in the dataset, specifying they ate 0 eggs, and then I should have specified the standard nested mixed model
fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-(1|colony/patriline/ID), data=data, family=binomial)

The only residual query is whether trial should be included as well, perhaps as a crossed random factor +(1|trial) in the model?

best regards,
Tom

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Tom Wenseleers <tom.wenseleers at kuleuven.be>
Sent: 27 January 2017 13:45
To: Jarrod Hadfield; r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Correct specification of nested binomial mixed model with custom intercept to infer variance components and intraclass correlations

Hi Jarrod,
Well the structure of the datafile is such that each row of the datafile contains the proportion of the eggs eaten in each trial by each individual bee (that belongs to a particular patriline, ie there would be several lines per trial corresponding to different individual bees, some of which might also occur again in different trials with the same colony) (this is in fit1 below) or the mean proportion of the eggs eaten in each trial by a patricular patriline (in fit2 below). So I was not entirely sure how I should still incorporate trial as a random effect as well, and how this would look like?
The reason that I thought it would make sense to also include the proportional distribution of the different patrilines in the colony (either as a custom intercept or a covariate, not sure about that) in the model is that these give the a priori probability that eggs would be eaten by bees belonging to different patrilines (as they are heavily skewed), so the heritability of the trait would be expressed mainly in terms of some patrilines making a much greater or much lower contribution to egg eating than expected based on their proportional presence in the colony. But I am not sure how I would correctly do that in my model, hence my question? Makes sense?

cheers,
Tom

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: 27 January 2017 06:37
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Correct specification of nested binomial mixed model with custom intercept to infer variance components and intraclass correlations

Hi Tom,

If I understand your experiment/data set up, each row of the data frame
contains all the data for one trial? If so, having trial as random
effect is one way of modelling any overdispersion in the data with
respect to the binomial. If overdispersion exists it is important to
model this. Other than that the random effect structure seems fine.

Also I don't understand why baseline is fitted, especially as an offset.
If you are fitting patriline as a random effect presumably you know the
patriline for each bee? Why then fit the proportion of the colony that
has the same patriline as the bee, and why fix the associated
coefficient to one?

Cheers,

Jarrod



On 26/01/2017 15:11, Tom Wenseleers wrote:
> Dear all,
> Just to ask a bit of advice about the correct way to specify a nested binomial GLM, in the context of estimating variance components / intraclass correlations to infer heritabilities of a behavioural trait.
>
> The behavioural trait is a binary one (eating an egg or not, 1 or 0), and is performed by known individual honeybees (individually numbered, ?individual_ID?) of a known father line (?patriline?) of a given hive (?colony?). Several subsequent egg eating events could be performed by the same individuals. Of each experiment with each colony several trials were done, and for each trial we have data on how many eggs were eaten in total, so we could analyse as a dependent variable the proportion of those eggs that were eaten by a given individual. In addition, we also genotyped a bunch of bees of each colony, which gave us the patriline distribution within each colony (?expected_proportion_patriline?), i.e. the proportion that each patriline makes up in the colony, which I thought should affect the a priori probability that bees of a given patriline would be observed eating eggs.
>
> My question is what mixed model syntax would make most sense to analyse this data, and allows us to infer variance components and intraclass correlations as a basis for a heritability estimate of this egg eating behaviour?
>
> One model I thought of was to include the expected proportion of each patriline that is present as a custom offset, using
> library(afex)
> set_sum_contrasts() # use effect coding
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-1+(1|colony/patriline/ID), offset=baseline, data=data, family=binomial)
> but would this model make sense as a basis to estimate the variance components and intraclass correlation?
>
> In another model I worked with the mean eggs eaten by bees of a given patriline and then fitted the model
> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
> fit2=glmer(cbind(eggs_eaten_by_patriline, eggs_eaten_in_total_intrial ? eggs_eaten_by_patriline)~-1+(1|colony/patriline), offset=baseline, data=data, family=binomial)
>
> Again though I am not sure if such a model would make sense, and neither of my two models take trial explicitly as a factor. Would anybody have any advice by any chance about the most sensible model given my experimental design (proportion data, with individuals nested in patriline nested in colony, with repeated trials and a priori info on the proportion of eggs that would be expected to be eaten by each patriline based on independent genotyping, which could perhaps be included as a custom intercept or a covariate)?
>
> Best regards,
> Tom Wenseleers
> Dept of Biology
> University of Leuven
> Belgium
>
> _____
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From lupp at uchicago.edu  Fri Jan 27 22:27:22 2017
From: lupp at uchicago.edu (Stuart Luppescu)
Date: Fri, 27 Jan 2017 16:27:22 -0500
Subject: [R-sig-ME] Identify large residuals
Message-ID: <1485552442.17730.62.camel@uchicago.edu>

Hello, I have a dataset of test item response times. The examinees took
the test unsupervised online. We want to identify person-items with
unusually large time residuals indicating that the examinee might have
looked up the answer on Google before responding.?

I am trying to do this in a model with items nested within examinees
like this:

lmer.test1a <- lmer(log(answer_time) ~ qid + (1|examinee/qid), data=test.DF, REML=FALSE)

The results look like this:

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: log(answer_time) ~ qid + (1 | examinee/qid)
   Data: test.DF

     AIC      BIC   logLik deviance df.resid 
  1670.2   1709.8   -826.1   1652.2      597 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.9656 -0.3263  0.1407  0.5539  2.7752 

Random effects:
 Groups       Name        Variance  Std.Dev. 
 qid:examinee (Intercept) 1.275e-15 3.571e-08
 examinee     (Intercept) 1.920e-01 4.382e-01
 Residual                 7.684e-01 8.766e-01
Number of obs: 606, groups:  qid:examinee, 600; examinee, 100

Fixed effects:
            Estimate Std. Error t value
(Intercept)  3.48381    0.09764   35.68
qidItem2    -0.11060    0.12335   -0.90
qidItem3    -0.09798    0.12335   -0.79
qidItem4    -0.02294    0.12335   -0.19
qidItem5     0.13196    0.12335    1.07
qidItem6    -0.01915    0.12335   -0.16

Does this look like a reasonable approach? If so, how would I get the
residuals out of this to identify examinee/qid combinations that seem
unusually large?

Thanks in advance for any help.

The dataset I'm using is pasted below. (I made the qid variable effects
coded by doing contrast(test.DF$qid) <- contr.sum but I'm not sure if
the contrast attribute is included in the dput below. Also, I added one
line at the bottom with dummy data to get it to run.)

?dput(test.DF)
structure(list(examinee = structure(c(3L, 3L, 3L, 3L, 3L, 3L,?
6L, 6L, 6L, 6L, 6L, 6L, 9L, 9L, 9L, 9L, 9L, 9L, 7L, 7L, 7L, 7L,?
7L, 7L, 96L, 96L, 96L, 96L, 96L, 96L, 8L, 8L, 8L, 8L, 8L, 8L,?
4L, 4L, 4L, 4L, 4L, 4L, 12L, 12L, 12L, 12L, 12L, 12L, 16L, 16L,?
16L, 16L, 16L, 16L, 10L, 10L, 10L, 10L, 10L, 10L, 19L, 19L, 19L,?
19L, 19L, 19L, 5L, 5L, 5L, 5L, 5L, 5L, 21L, 21L, 21L, 21L, 21L,?
21L, 18L, 18L, 18L, 18L, 18L, 18L, 99L, 99L, 99L, 99L, 99L, 99L,?
98L, 98L, 98L, 98L, 98L, 98L, 13L, 13L, 13L, 13L, 13L, 13L, 26L,?
26L, 26L, 26L, 26L, 26L, 1L, 1L, 1L, 1L, 1L, 1L, 29L, 29L, 29L,?
29L, 29L, 29L, 30L, 30L, 30L, 30L, 30L, 30L, 31L, 31L, 31L, 31L,?
31L, 31L, 32L, 32L, 32L, 32L, 32L, 32L, 23L, 23L, 23L, 23L, 23L,?
23L, 35L, 35L, 35L, 35L, 35L, 35L, 36L, 36L, 36L, 36L, 36L, 36L,?
37L, 37L, 37L, 37L, 37L, 37L, 38L, 38L, 38L, 38L, 38L, 38L, 100L,?
100L, 100L, 100L, 100L, 100L, 40L, 40L, 40L, 40L, 40L, 40L, 42L,?
42L, 42L, 42L, 42L, 42L, 34L, 34L, 34L, 34L, 34L, 34L, 46L, 46L,?
46L, 46L, 46L, 46L, 47L, 47L, 47L, 47L, 47L, 47L, 44L, 44L, 44L,?
44L, 44L, 44L, 15L, 15L, 15L, 15L, 15L, 15L, 52L, 52L, 52L, 52L,?
52L, 52L, 55L, 55L, 55L, 55L, 55L, 55L, 53L, 53L, 53L, 53L, 53L,?
53L, 39L, 39L, 39L, 39L, 39L, 39L, 51L, 51L, 51L, 51L, 51L, 51L,?
48L, 48L, 48L, 48L, 48L, 48L, 58L, 58L, 58L, 58L, 58L, 58L, 22L,?
22L, 22L, 22L, 22L, 22L, 33L, 33L, 33L, 33L, 33L, 33L, 60L, 60L,?
60L, 60L, 60L, 60L, 95L, 95L, 95L, 95L, 95L, 95L, 59L, 59L, 59L,?
59L, 59L, 59L, 56L, 56L, 56L, 56L, 56L, 56L, 63L, 63L, 63L, 63L,?
63L, 63L, 57L, 57L, 57L, 57L, 57L, 57L, 50L, 50L, 50L, 50L, 50L,?
50L, 62L, 62L, 62L, 62L, 62L, 62L, 25L, 25L, 25L, 25L, 25L, 25L,?
64L, 64L, 64L, 64L, 64L, 64L, 14L, 14L, 14L, 14L, 14L, 14L, 66L,?
66L, 66L, 66L, 66L, 66L, 61L, 61L, 61L, 61L, 61L, 61L, 68L, 68L,?
68L, 68L, 68L, 68L, 49L, 49L, 49L, 49L, 49L, 49L, 69L, 69L, 69L,?
69L, 69L, 69L, 41L, 41L, 41L, 41L, 41L, 41L, 54L, 54L, 54L, 54L,?
54L, 54L, 67L, 67L, 67L, 67L, 67L, 67L, 65L, 65L, 65L, 65L, 65L,?
65L, 70L, 70L, 70L, 70L, 70L, 70L, 43L, 43L, 43L, 43L, 43L, 43L,?
20L, 20L, 20L, 20L, 20L, 20L, 72L, 72L, 72L, 72L, 72L, 72L, 11L,?
11L, 11L, 11L, 11L, 11L, 97L, 97L, 97L, 97L, 97L, 97L, 74L, 74L,?
74L, 74L, 74L, 74L, 75L, 75L, 75L, 75L, 75L, 75L, 77L, 77L, 77L,?
77L, 77L, 77L, 76L, 76L, 76L, 76L, 76L, 76L, 79L, 79L, 79L, 79L,?
79L, 79L, 78L, 78L, 78L, 78L, 78L, 78L, 80L, 80L, 80L, 80L, 80L,?
80L, 81L, 81L, 81L, 81L, 81L, 81L, 71L, 71L, 71L, 71L, 71L, 71L,?
82L, 82L, 82L, 82L, 82L, 82L, 83L, 83L, 83L, 83L, 83L, 83L, 28L,?
28L, 28L, 28L, 28L, 28L, 84L, 84L, 84L, 84L, 84L, 84L, 89L, 89L,?
89L, 89L, 89L, 89L, 87L, 87L, 87L, 87L, 87L, 87L, 86L, 86L, 86L,?
86L, 86L, 86L, 90L, 90L, 90L, 90L, 90L, 90L, 91L, 91L, 91L, 91L,?
91L, 91L, 85L, 85L, 85L, 85L, 85L, 85L, 2L, 2L, 2L, 2L, 2L, 2L,?
92L, 92L, 92L, 92L, 92L, 92L, 17L, 17L, 17L, 17L, 17L, 17L, 24L,?
24L, 24L, 24L, 24L, 24L, 93L, 93L, 93L, 93L, 93L, 93L, 88L, 88L,?
88L, 88L, 88L, 88L, 73L, 73L, 73L, 73L, 73L, 73L, 27L, 27L, 27L,?
27L, 27L, 27L, 45L, 45L, 45L, 45L, 45L, 45L, 94L, 94L, 94L, 94L,?
94L, 94L, 100L, 100L, 100L, 100L, 100L, 100L), .Label = c("1",?
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",?
"14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",?
"25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",?
"36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",?
"47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",?
"58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",?
"69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",?
"80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",?
"91", "92", "93", "94", "95", "96", "97", "98", "99", "100"), class =
"factor"),?
????qid = structure(c(3L, 5L, 1L, 2L, 4L, 6L, 5L, 2L, 4L, 6L,?
????1L, 3L, 6L, 3L, 4L, 2L, 5L, 1L, 6L, 3L, 2L, 5L, 1L, 4L, 4L,?
????3L, 1L, 6L, 5L, 2L, 3L, 2L, 5L, 6L, 4L, 1L, 2L, 1L, 3L, 5L,?
????4L, 6L, 3L, 2L, 6L, 4L, 5L, 1L, 3L, 2L, 5L, 4L, 6L, 1L, 2L,?
????6L, 5L, 1L, 4L, 3L, 3L, 6L, 5L, 4L, 2L, 1L, 4L, 2L, 3L, 5L,?
????6L, 1L, 3L, 5L, 2L, 6L, 4L, 1L, 5L, 6L, 3L, 2L, 1L, 4L, 4L,?
????2L, 3L, 5L, 1L, 6L, 3L, 6L, 2L, 1L, 5L, 4L, 1L, 6L, 5L, 3L,?
????2L, 4L, 6L, 1L, 2L, 3L, 5L, 4L, 2L, 6L, 4L, 3L, 5L, 1L, 1L,?
????4L, 3L, 5L, 6L, 2L, 4L, 2L, 6L, 5L, 3L, 1L, 5L, 2L, 6L, 3L,?
????1L, 4L, 1L, 6L, 4L, 5L, 2L, 3L, 1L, 4L, 3L, 2L, 5L, 6L, 6L,?
????2L, 1L, 3L, 4L, 5L, 1L, 6L, 3L, 4L, 5L, 2L, 6L, 3L, 5L, 1L,?
????4L, 2L, 2L, 4L, 6L, 5L, 3L, 1L, 6L, 1L, 5L, 3L, 4L, 2L, 2L,?
????1L, 3L, 4L, 6L, 5L, 3L, 6L, 1L, 5L, 4L, 2L, 2L, 4L, 5L, 6L,?
????3L, 1L, 2L, 3L, 4L, 1L, 5L, 6L, 6L, 5L, 4L, 1L, 2L, 3L, 5L,?
????4L, 1L, 3L, 2L, 6L, 6L, 1L, 4L, 5L, 3L, 2L, 2L, 6L, 5L, 3L,?
????4L, 1L, 6L, 5L, 3L, 4L, 2L, 1L, 5L, 1L, 3L, 4L, 2L, 6L, 4L,?
????3L, 2L, 6L, 1L, 5L, 2L, 3L, 5L, 1L, 4L, 6L, 6L, 5L, 2L, 3L,?
????4L, 1L, 5L, 4L, 3L, 2L, 1L, 6L, 4L, 3L, 2L, 6L, 1L, 5L, 2L,?
????3L, 5L, 6L, 4L, 1L, 4L, 3L, 1L, 5L, 6L, 2L, 3L, 6L, 2L, 4L,?
????5L, 1L, 6L, 1L, 3L, 4L, 2L, 5L, 5L, 1L, 3L, 2L, 4L, 6L, 1L,?
????6L, 3L, 4L, 2L, 5L, 1L, 6L, 3L, 5L, 2L, 4L, 5L, 4L, 6L, 2L,?
????1L, 3L, 4L, 3L, 5L, 2L, 6L, 1L, 5L, 6L, 4L, 3L, 1L, 2L, 5L,?
????4L, 3L, 2L, 1L, 6L, 3L, 6L, 2L, 5L, 4L, 1L, 3L, 6L, 4L, 5L,?
????2L, 1L, 6L, 1L, 2L, 3L, 5L, 4L, 2L, 1L, 4L, 3L, 5L, 6L, 5L,?
????2L, 4L, 3L, 6L, 1L, 4L, 5L, 3L, 1L, 2L, 6L, 2L, 1L, 4L, 6L,?
????3L, 5L, 6L, 2L, 5L, 4L, 1L, 3L, 4L, 6L, 2L, 1L, 5L, 3L, 4L,?
????6L, 3L, 5L, 1L, 2L, 6L, 3L, 1L, 5L, 2L, 4L, 5L, 6L, 1L, 4L,?
????2L, 3L, 6L, 4L, 5L, 2L, 3L, 1L, 4L, 5L, 1L, 6L, 3L, 2L, 6L,?
????1L, 4L, 2L, 5L, 3L, 3L, 1L, 5L, 4L, 2L, 6L, 4L, 6L, 1L, 2L,?
????3L, 5L, 1L, 4L, 5L, 3L, 2L, 6L, 5L, 2L, 1L, 6L, 3L, 4L, 6L,?
????1L, 2L, 3L, 4L, 5L, 3L, 1L, 5L, 2L, 6L, 4L, 3L, 2L, 1L, 5L,?
????6L, 4L, 5L, 4L, 6L, 1L, 2L, 3L, 4L, 5L, 3L, 2L, 1L, 6L, 4L,?
????3L, 6L, 2L, 1L, 5L, 5L, 4L, 3L, 2L, 6L, 1L, 2L, 6L, 4L, 1L,?
????5L, 3L, 3L, 4L, 6L, 2L, 5L, 1L, 5L, 3L, 4L, 2L, 1L, 6L, 2L,?
????4L, 5L, 6L, 1L, 3L, 6L, 3L, 4L, 5L, 1L, 2L, 1L, 5L, 2L, 4L,?
????6L, 3L, 6L, 5L, 1L, 3L, 4L, 2L, 6L, 3L, 4L, 1L, 2L, 5L, 5L,?
????6L, 4L, 2L, 3L, 1L, 1L, 3L, 4L, 2L, 5L, 6L, 5L, 3L, 2L, 6L,?
????4L, 1L, 1L, 5L, 4L, 2L, 3L, 6L, 2L, 5L, 1L, 4L, 6L, 3L, 4L,?
????1L, 2L, 5L, 6L, 3L, 6L, 5L, 4L, 3L, 2L, 1L, 1L, 4L, 3L, 5L,?
????6L, 2L, 5L, 3L, 1L, 4L, 2L, 6L, 2L, 6L, 4L, 3L, 5L, 1L, 2L,?
????6L, 4L, 5L, 1L, 3L, 1L, 2L, 3L, 4L, 5L, 6L), .Label = c("Item1",?
????"Item2", "Item3", "Item4", "Item5", "Item6"), class = "factor"),?
????answer_time = c(16, 11, 29, 19, 51, 23, 17, 28, 36, 57, 23,?
????20, 26, 29, 90, 13, 43, 41, 40, 90, 63, 56, 54, 54, 1, 27,?
????35, 90, 90, 32, 13, 12, 57, 24, 56, 18, 33, 61, 34, 36, 47,?
????38, 90, 67, 21, 74, 81, 71, 28, 40, 22, 22, 26, 69, 77, 69,?
????35, 76, 55, 24, 90, 42, 44, 16, 22, 39, 1, 32, 72, 90, 28,?
????54, 1, 56, 51, 40, 11, 29, 64, 32, 62, 50, 19, 19, 90, 26,?
????36, 16, 22, 14, 1, 49, 53, 88, 48, 54, 60, 28, 33, 58, 15,?
????22, 44, 47, 10, 71, 75, 60, 39, 28, 31, 17, 61, 42, 1, 56,?
????76, 39, 28, 26, 32, 90, 19, 90, 63, 41, 90, 57, 21, 45, 52,?
????36, 1, 55, 62, 60, 83, 58, 90, 90, 83, 30, 60, 77, 54, 18,?
????42, 66, 26, 69, 15, 41, 27, 12, 34, 18, 61, 56, 49, 56, 43,?
????34, 85, 90, 31, 73, 65, 83, 1, 90, 59, 22, 90, 90, 28, 46,?
????90, 17, 47, 42, 53, 25, 35, 47, 19, 31, 49, 72, 73, 34, 75,?
????63, 43, 30, 10, 14, 41, 32, 90, 90, 56, 68, 32, 10, 90, 69,?
????43, 11, 45, 49, 90, 61, 72, 57, 70, 77, 6, 1, 2, 2, 1, 2,?
????90, 64, 75, 18, 22, 24, 66, 23, 45, 67, 49, 55, 14, 20, 9,?
????11, 9, 17, 1, 25, 21, 34, 90, 32, 90, 71, 38, 34, 18, 36,?
????35, 37, 34, 22, 30, 21, 44, 34, 58, 15, 32, 23, 45, 90, 56,?
????43, 41, 42, 17, 40, 90, 90, 20, 40, 75, 25, 35, 42, 31, 48,?
????28, 51, 29, 31, 12, 90, 21, 43, 16, 63, 35, 23, 23, 25, 16,?
????23, 18, 14, 58, 19, 22, 54, 37, 52, 90, 71, 21, 72, 85, 76,?
????71, 13, 53, 14, 43, 68, 76, 28, 38, 33, 13, 13, 50, 27, 48,?
????21, 36, 28, 1, 32, 10, 68, 12, 21, 90, 22, 77, 34, 35, 39,?
????64, 55, 42, 82, 88, 90, 33, 18, 85, 49, 23, 33, 1, 55, 42,?
????19, 36, 90, 39, 32, 6, 29, 36, 25, 1, 24, 20, 24, 15, 28,?
????90, 24, 13, 35, 19, 13, 82, 56, 43, 30, 74, 74, 90, 77, 12,?
????34, 41, 77, 90, 90, 53, 64, 38, 90, 25, 40, 55, 69, 18, 16,?
????53, 49, 82, 28, 73, 46, 72, 76, 53, 66, 73, 53, 37, 28, 39,?
????90, 48, 21, 90, 75, 77, 65, 61, 18, 90, 26, 29, 22, 51, 76,?
????1, 31, 28, 74, 29, 21, 90, 62, 43, 42, 28, 58, 44, 36, 29,?
????50, 21, 90, 28, 19, 18, 21, 12, 19, 1, 48, 59, 62, 49, 1,?
????26, 32, 27, 18, 16, 15, 37, 48, 24, 27, 30, 42, 68, 38, 35,?
????90, 66, 73, 1, 19, 90, 56, 21, 17, 65, 35, 41, 64, 38, 25,?
????90, 25, 57, 41, 63, 71, 1, 41, 25, 17, 47, 48, 28, 69, 31,?
????31, 22, 59, 86, 25, 21, 52, 19, 32, 51, 43, 22, 33, 90, 31,?
????88, 63, 70, 71, 76, 74, 13, 27, 9, 21, 12, 15, 76, 17, 36,?
????19, 6, 51, 71, 77, 67, 32, 74, 14, 1, 90, 18, 26, 50, 41,?
????69, 58, 22, 62, 10, 40, 15, 8, 14, 7, 16, 5, 1, 54, 90, 25,?
????29, 41, 33, 40, 36, 30, 24, 63, 1, 44, 16, 13, 40, 20, 90,?
????21, 34, 10, 32, 14, 90, 33, 90, 11, 34, 76, 1, 77, 77, 82,?
????32, 90, 1, 1, 1, 1, 1, 1)), row.names = c(NA, 606L), .Names =
c("examinee",?
"qid", "answer_time"), class = "data.frame")
>?

-- 
Stuart Luppescu
Chief Psychometrician (ret.)
UChicago Consortium on School Research
http://consortium.uchicago.edu

lupp at uchicago.edu


From bbolker at gmail.com  Fri Jan 27 22:49:48 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 27 Jan 2017 16:49:48 -0500
Subject: [R-sig-ME] Identify large residuals
In-Reply-To: <1485552442.17730.62.camel@uchicago.edu>
References: <1485552442.17730.62.camel@uchicago.edu>
Message-ID: <aff0d00b-ab86-9e90-69f8-1c486eb54208@gmail.com>

1. you can calculate residuals with different levels of random effects
included via   predict(...,re.form=<something>)-(observed value).  In
your case, though, it seems you just want the raw residuals()
(lowest-level) -- but see point #2.

2. in this sample data set, there is a single response per question for
all but one examinee.  This will make the qid-with-examinee random
effect variance almost impossible to estimate (strongly confounded with
the observation-level residual variance); was that on purpose or is that
an artifact of the example you gave us to look at? (Now that I look
closer, I think this is what you meant by "I added one line at the
bottom with dummy data to get it to run"; otherwise you would get an
error from lmer() that you'd have to override.) What do your real data
look like? If they really have only one observation per examinee:qid
combo, then you should leave out the nested random effect -- it will be
captured entirely by the residual variance term.

3. For what it's worth, it doesn't seem as though log-transforming these
data is worthwhile, but that may be because you made up data that were
already reasonably well distributed?


On 17-01-27 04:27 PM, Stuart Luppescu wrote:
> Hello, I have a dataset of test item response times. The examinees took
> the test unsupervised online. We want to identify person-items with
> unusually large time residuals indicating that the examinee might have
> looked up the answer on Google before responding. 
> 
> I am trying to do this in a model with items nested within examinees
> like this:
> 
> lmer.test1a <- lmer(log(answer_time) ~ qid + (1|examinee/qid), data=test.DF, REML=FALSE)
> 
> The results look like this:
> 
> Linear mixed model fit by maximum likelihood  ['lmerMod']
> Formula: log(answer_time) ~ qid + (1 | examinee/qid)
>    Data: test.DF
> 
>      AIC      BIC   logLik deviance df.resid 
>   1670.2   1709.8   -826.1   1652.2      597 
> 
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -3.9656 -0.3263  0.1407  0.5539  2.7752 
> 
> Random effects:
>  Groups       Name        Variance  Std.Dev. 
>  qid:examinee (Intercept) 1.275e-15 3.571e-08
>  examinee     (Intercept) 1.920e-01 4.382e-01
>  Residual                 7.684e-01 8.766e-01
> Number of obs: 606, groups:  qid:examinee, 600; examinee, 100
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  3.48381    0.09764   35.68
> qidItem2    -0.11060    0.12335   -0.90
> qidItem3    -0.09798    0.12335   -0.79
> qidItem4    -0.02294    0.12335   -0.19
> qidItem5     0.13196    0.12335    1.07
> qidItem6    -0.01915    0.12335   -0.16
> 
> Does this look like a reasonable approach? If so, how would I get the
> residuals out of this to identify examinee/qid combinations that seem
> unusually large?
> 
> Thanks in advance for any help.
> 
> The dataset I'm using is pasted below. (I made the qid variable effects
> coded by doing contrast(test.DF$qid) <- contr.sum but I'm not sure if
> the contrast attribute is included in the dput below. Also, I added one
> line at the bottom with dummy data to get it to run.)
> 
>  dput(test.DF)
> structure(list(examinee = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 
> 6L, 6L, 6L, 6L, 6L, 6L, 9L, 9L, 9L, 9L, 9L, 9L, 7L, 7L, 7L, 7L, 
> 7L, 7L, 96L, 96L, 96L, 96L, 96L, 96L, 8L, 8L, 8L, 8L, 8L, 8L, 
> 4L, 4L, 4L, 4L, 4L, 4L, 12L, 12L, 12L, 12L, 12L, 12L, 16L, 16L, 
> 16L, 16L, 16L, 16L, 10L, 10L, 10L, 10L, 10L, 10L, 19L, 19L, 19L, 
> 19L, 19L, 19L, 5L, 5L, 5L, 5L, 5L, 5L, 21L, 21L, 21L, 21L, 21L, 
> 21L, 18L, 18L, 18L, 18L, 18L, 18L, 99L, 99L, 99L, 99L, 99L, 99L, 
> 98L, 98L, 98L, 98L, 98L, 98L, 13L, 13L, 13L, 13L, 13L, 13L, 26L, 
> 26L, 26L, 26L, 26L, 26L, 1L, 1L, 1L, 1L, 1L, 1L, 29L, 29L, 29L, 
> 29L, 29L, 29L, 30L, 30L, 30L, 30L, 30L, 30L, 31L, 31L, 31L, 31L, 
> 31L, 31L, 32L, 32L, 32L, 32L, 32L, 32L, 23L, 23L, 23L, 23L, 23L, 
> 23L, 35L, 35L, 35L, 35L, 35L, 35L, 36L, 36L, 36L, 36L, 36L, 36L, 
> 37L, 37L, 37L, 37L, 37L, 37L, 38L, 38L, 38L, 38L, 38L, 38L, 100L, 
> 100L, 100L, 100L, 100L, 100L, 40L, 40L, 40L, 40L, 40L, 40L, 42L, 
> 42L, 42L, 42L, 42L, 42L, 34L, 34L, 34L, 34L, 34L, 34L, 46L, 46L, 
> 46L, 46L, 46L, 46L, 47L, 47L, 47L, 47L, 47L, 47L, 44L, 44L, 44L, 
> 44L, 44L, 44L, 15L, 15L, 15L, 15L, 15L, 15L, 52L, 52L, 52L, 52L, 
> 52L, 52L, 55L, 55L, 55L, 55L, 55L, 55L, 53L, 53L, 53L, 53L, 53L, 
> 53L, 39L, 39L, 39L, 39L, 39L, 39L, 51L, 51L, 51L, 51L, 51L, 51L, 
> 48L, 48L, 48L, 48L, 48L, 48L, 58L, 58L, 58L, 58L, 58L, 58L, 22L, 
> 22L, 22L, 22L, 22L, 22L, 33L, 33L, 33L, 33L, 33L, 33L, 60L, 60L, 
> 60L, 60L, 60L, 60L, 95L, 95L, 95L, 95L, 95L, 95L, 59L, 59L, 59L, 
> 59L, 59L, 59L, 56L, 56L, 56L, 56L, 56L, 56L, 63L, 63L, 63L, 63L, 
> 63L, 63L, 57L, 57L, 57L, 57L, 57L, 57L, 50L, 50L, 50L, 50L, 50L, 
> 50L, 62L, 62L, 62L, 62L, 62L, 62L, 25L, 25L, 25L, 25L, 25L, 25L, 
> 64L, 64L, 64L, 64L, 64L, 64L, 14L, 14L, 14L, 14L, 14L, 14L, 66L, 
> 66L, 66L, 66L, 66L, 66L, 61L, 61L, 61L, 61L, 61L, 61L, 68L, 68L, 
> 68L, 68L, 68L, 68L, 49L, 49L, 49L, 49L, 49L, 49L, 69L, 69L, 69L, 
> 69L, 69L, 69L, 41L, 41L, 41L, 41L, 41L, 41L, 54L, 54L, 54L, 54L, 
> 54L, 54L, 67L, 67L, 67L, 67L, 67L, 67L, 65L, 65L, 65L, 65L, 65L, 
> 65L, 70L, 70L, 70L, 70L, 70L, 70L, 43L, 43L, 43L, 43L, 43L, 43L, 
> 20L, 20L, 20L, 20L, 20L, 20L, 72L, 72L, 72L, 72L, 72L, 72L, 11L, 
> 11L, 11L, 11L, 11L, 11L, 97L, 97L, 97L, 97L, 97L, 97L, 74L, 74L, 
> 74L, 74L, 74L, 74L, 75L, 75L, 75L, 75L, 75L, 75L, 77L, 77L, 77L, 
> 77L, 77L, 77L, 76L, 76L, 76L, 76L, 76L, 76L, 79L, 79L, 79L, 79L, 
> 79L, 79L, 78L, 78L, 78L, 78L, 78L, 78L, 80L, 80L, 80L, 80L, 80L, 
> 80L, 81L, 81L, 81L, 81L, 81L, 81L, 71L, 71L, 71L, 71L, 71L, 71L, 
> 82L, 82L, 82L, 82L, 82L, 82L, 83L, 83L, 83L, 83L, 83L, 83L, 28L, 
> 28L, 28L, 28L, 28L, 28L, 84L, 84L, 84L, 84L, 84L, 84L, 89L, 89L, 
> 89L, 89L, 89L, 89L, 87L, 87L, 87L, 87L, 87L, 87L, 86L, 86L, 86L, 
> 86L, 86L, 86L, 90L, 90L, 90L, 90L, 90L, 90L, 91L, 91L, 91L, 91L, 
> 91L, 91L, 85L, 85L, 85L, 85L, 85L, 85L, 2L, 2L, 2L, 2L, 2L, 2L, 
> 92L, 92L, 92L, 92L, 92L, 92L, 17L, 17L, 17L, 17L, 17L, 17L, 24L, 
> 24L, 24L, 24L, 24L, 24L, 93L, 93L, 93L, 93L, 93L, 93L, 88L, 88L, 
> 88L, 88L, 88L, 88L, 73L, 73L, 73L, 73L, 73L, 73L, 27L, 27L, 27L, 
> 27L, 27L, 27L, 45L, 45L, 45L, 45L, 45L, 45L, 94L, 94L, 94L, 94L, 
> 94L, 94L, 100L, 100L, 100L, 100L, 100L, 100L), .Label = c("1", 
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", 
> "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", 
> "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", 
> "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", 
> "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", 
> "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68", 
> "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79", 
> "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90", 
> "91", "92", "93", "94", "95", "96", "97", "98", "99", "100"), class =
> "factor"), 
>     qid = structure(c(3L, 5L, 1L, 2L, 4L, 6L, 5L, 2L, 4L, 6L, 
>     1L, 3L, 6L, 3L, 4L, 2L, 5L, 1L, 6L, 3L, 2L, 5L, 1L, 4L, 4L, 
>     3L, 1L, 6L, 5L, 2L, 3L, 2L, 5L, 6L, 4L, 1L, 2L, 1L, 3L, 5L, 
>     4L, 6L, 3L, 2L, 6L, 4L, 5L, 1L, 3L, 2L, 5L, 4L, 6L, 1L, 2L, 
>     6L, 5L, 1L, 4L, 3L, 3L, 6L, 5L, 4L, 2L, 1L, 4L, 2L, 3L, 5L, 
>     6L, 1L, 3L, 5L, 2L, 6L, 4L, 1L, 5L, 6L, 3L, 2L, 1L, 4L, 4L, 
>     2L, 3L, 5L, 1L, 6L, 3L, 6L, 2L, 1L, 5L, 4L, 1L, 6L, 5L, 3L, 
>     2L, 4L, 6L, 1L, 2L, 3L, 5L, 4L, 2L, 6L, 4L, 3L, 5L, 1L, 1L, 
>     4L, 3L, 5L, 6L, 2L, 4L, 2L, 6L, 5L, 3L, 1L, 5L, 2L, 6L, 3L, 
>     1L, 4L, 1L, 6L, 4L, 5L, 2L, 3L, 1L, 4L, 3L, 2L, 5L, 6L, 6L, 
>     2L, 1L, 3L, 4L, 5L, 1L, 6L, 3L, 4L, 5L, 2L, 6L, 3L, 5L, 1L, 
>     4L, 2L, 2L, 4L, 6L, 5L, 3L, 1L, 6L, 1L, 5L, 3L, 4L, 2L, 2L, 
>     1L, 3L, 4L, 6L, 5L, 3L, 6L, 1L, 5L, 4L, 2L, 2L, 4L, 5L, 6L, 
>     3L, 1L, 2L, 3L, 4L, 1L, 5L, 6L, 6L, 5L, 4L, 1L, 2L, 3L, 5L, 
>     4L, 1L, 3L, 2L, 6L, 6L, 1L, 4L, 5L, 3L, 2L, 2L, 6L, 5L, 3L, 
>     4L, 1L, 6L, 5L, 3L, 4L, 2L, 1L, 5L, 1L, 3L, 4L, 2L, 6L, 4L, 
>     3L, 2L, 6L, 1L, 5L, 2L, 3L, 5L, 1L, 4L, 6L, 6L, 5L, 2L, 3L, 
>     4L, 1L, 5L, 4L, 3L, 2L, 1L, 6L, 4L, 3L, 2L, 6L, 1L, 5L, 2L, 
>     3L, 5L, 6L, 4L, 1L, 4L, 3L, 1L, 5L, 6L, 2L, 3L, 6L, 2L, 4L, 
>     5L, 1L, 6L, 1L, 3L, 4L, 2L, 5L, 5L, 1L, 3L, 2L, 4L, 6L, 1L, 
>     6L, 3L, 4L, 2L, 5L, 1L, 6L, 3L, 5L, 2L, 4L, 5L, 4L, 6L, 2L, 
>     1L, 3L, 4L, 3L, 5L, 2L, 6L, 1L, 5L, 6L, 4L, 3L, 1L, 2L, 5L, 
>     4L, 3L, 2L, 1L, 6L, 3L, 6L, 2L, 5L, 4L, 1L, 3L, 6L, 4L, 5L, 
>     2L, 1L, 6L, 1L, 2L, 3L, 5L, 4L, 2L, 1L, 4L, 3L, 5L, 6L, 5L, 
>     2L, 4L, 3L, 6L, 1L, 4L, 5L, 3L, 1L, 2L, 6L, 2L, 1L, 4L, 6L, 
>     3L, 5L, 6L, 2L, 5L, 4L, 1L, 3L, 4L, 6L, 2L, 1L, 5L, 3L, 4L, 
>     6L, 3L, 5L, 1L, 2L, 6L, 3L, 1L, 5L, 2L, 4L, 5L, 6L, 1L, 4L, 
>     2L, 3L, 6L, 4L, 5L, 2L, 3L, 1L, 4L, 5L, 1L, 6L, 3L, 2L, 6L, 
>     1L, 4L, 2L, 5L, 3L, 3L, 1L, 5L, 4L, 2L, 6L, 4L, 6L, 1L, 2L, 
>     3L, 5L, 1L, 4L, 5L, 3L, 2L, 6L, 5L, 2L, 1L, 6L, 3L, 4L, 6L, 
>     1L, 2L, 3L, 4L, 5L, 3L, 1L, 5L, 2L, 6L, 4L, 3L, 2L, 1L, 5L, 
>     6L, 4L, 5L, 4L, 6L, 1L, 2L, 3L, 4L, 5L, 3L, 2L, 1L, 6L, 4L, 
>     3L, 6L, 2L, 1L, 5L, 5L, 4L, 3L, 2L, 6L, 1L, 2L, 6L, 4L, 1L, 
>     5L, 3L, 3L, 4L, 6L, 2L, 5L, 1L, 5L, 3L, 4L, 2L, 1L, 6L, 2L, 
>     4L, 5L, 6L, 1L, 3L, 6L, 3L, 4L, 5L, 1L, 2L, 1L, 5L, 2L, 4L, 
>     6L, 3L, 6L, 5L, 1L, 3L, 4L, 2L, 6L, 3L, 4L, 1L, 2L, 5L, 5L, 
>     6L, 4L, 2L, 3L, 1L, 1L, 3L, 4L, 2L, 5L, 6L, 5L, 3L, 2L, 6L, 
>     4L, 1L, 1L, 5L, 4L, 2L, 3L, 6L, 2L, 5L, 1L, 4L, 6L, 3L, 4L, 
>     1L, 2L, 5L, 6L, 3L, 6L, 5L, 4L, 3L, 2L, 1L, 1L, 4L, 3L, 5L, 
>     6L, 2L, 5L, 3L, 1L, 4L, 2L, 6L, 2L, 6L, 4L, 3L, 5L, 1L, 2L, 
>     6L, 4L, 5L, 1L, 3L, 1L, 2L, 3L, 4L, 5L, 6L), .Label = c("Item1", 
>     "Item2", "Item3", "Item4", "Item5", "Item6"), class = "factor"), 
>     answer_time = c(16, 11, 29, 19, 51, 23, 17, 28, 36, 57, 23, 
>     20, 26, 29, 90, 13, 43, 41, 40, 90, 63, 56, 54, 54, 1, 27, 
>     35, 90, 90, 32, 13, 12, 57, 24, 56, 18, 33, 61, 34, 36, 47, 
>     38, 90, 67, 21, 74, 81, 71, 28, 40, 22, 22, 26, 69, 77, 69, 
>     35, 76, 55, 24, 90, 42, 44, 16, 22, 39, 1, 32, 72, 90, 28, 
>     54, 1, 56, 51, 40, 11, 29, 64, 32, 62, 50, 19, 19, 90, 26, 
>     36, 16, 22, 14, 1, 49, 53, 88, 48, 54, 60, 28, 33, 58, 15, 
>     22, 44, 47, 10, 71, 75, 60, 39, 28, 31, 17, 61, 42, 1, 56, 
>     76, 39, 28, 26, 32, 90, 19, 90, 63, 41, 90, 57, 21, 45, 52, 
>     36, 1, 55, 62, 60, 83, 58, 90, 90, 83, 30, 60, 77, 54, 18, 
>     42, 66, 26, 69, 15, 41, 27, 12, 34, 18, 61, 56, 49, 56, 43, 
>     34, 85, 90, 31, 73, 65, 83, 1, 90, 59, 22, 90, 90, 28, 46, 
>     90, 17, 47, 42, 53, 25, 35, 47, 19, 31, 49, 72, 73, 34, 75, 
>     63, 43, 30, 10, 14, 41, 32, 90, 90, 56, 68, 32, 10, 90, 69, 
>     43, 11, 45, 49, 90, 61, 72, 57, 70, 77, 6, 1, 2, 2, 1, 2, 
>     90, 64, 75, 18, 22, 24, 66, 23, 45, 67, 49, 55, 14, 20, 9, 
>     11, 9, 17, 1, 25, 21, 34, 90, 32, 90, 71, 38, 34, 18, 36, 
>     35, 37, 34, 22, 30, 21, 44, 34, 58, 15, 32, 23, 45, 90, 56, 
>     43, 41, 42, 17, 40, 90, 90, 20, 40, 75, 25, 35, 42, 31, 48, 
>     28, 51, 29, 31, 12, 90, 21, 43, 16, 63, 35, 23, 23, 25, 16, 
>     23, 18, 14, 58, 19, 22, 54, 37, 52, 90, 71, 21, 72, 85, 76, 
>     71, 13, 53, 14, 43, 68, 76, 28, 38, 33, 13, 13, 50, 27, 48, 
>     21, 36, 28, 1, 32, 10, 68, 12, 21, 90, 22, 77, 34, 35, 39, 
>     64, 55, 42, 82, 88, 90, 33, 18, 85, 49, 23, 33, 1, 55, 42, 
>     19, 36, 90, 39, 32, 6, 29, 36, 25, 1, 24, 20, 24, 15, 28, 
>     90, 24, 13, 35, 19, 13, 82, 56, 43, 30, 74, 74, 90, 77, 12, 
>     34, 41, 77, 90, 90, 53, 64, 38, 90, 25, 40, 55, 69, 18, 16, 
>     53, 49, 82, 28, 73, 46, 72, 76, 53, 66, 73, 53, 37, 28, 39, 
>     90, 48, 21, 90, 75, 77, 65, 61, 18, 90, 26, 29, 22, 51, 76, 
>     1, 31, 28, 74, 29, 21, 90, 62, 43, 42, 28, 58, 44, 36, 29, 
>     50, 21, 90, 28, 19, 18, 21, 12, 19, 1, 48, 59, 62, 49, 1, 
>     26, 32, 27, 18, 16, 15, 37, 48, 24, 27, 30, 42, 68, 38, 35, 
>     90, 66, 73, 1, 19, 90, 56, 21, 17, 65, 35, 41, 64, 38, 25, 
>     90, 25, 57, 41, 63, 71, 1, 41, 25, 17, 47, 48, 28, 69, 31, 
>     31, 22, 59, 86, 25, 21, 52, 19, 32, 51, 43, 22, 33, 90, 31, 
>     88, 63, 70, 71, 76, 74, 13, 27, 9, 21, 12, 15, 76, 17, 36, 
>     19, 6, 51, 71, 77, 67, 32, 74, 14, 1, 90, 18, 26, 50, 41, 
>     69, 58, 22, 62, 10, 40, 15, 8, 14, 7, 16, 5, 1, 54, 90, 25, 
>     29, 41, 33, 40, 36, 30, 24, 63, 1, 44, 16, 13, 40, 20, 90, 
>     21, 34, 10, 32, 14, 90, 33, 90, 11, 34, 76, 1, 77, 77, 82, 
>     32, 90, 1, 1, 1, 1, 1, 1)), row.names = c(NA, 606L), .Names =
> c("examinee", 
> "qid", "answer_time"), class = "data.frame")
>>  
>


From j.hadfield at ed.ac.uk  Sat Jan 28 15:04:26 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 28 Jan 2017 14:04:26 +0000
Subject: [R-sig-ME] Correct specification of nested binomial mixed model
 with custom intercept to infer variance components and intraclass
 correlations
In-Reply-To: <1485528229525.12125@kuleuven.be>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W198183686B973039916732CBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk> <558ADB54.3020304@glasgow.ac.uk>
	<1485443532333.72208@kuleuven.be>
	<f504e208-c486-9813-f299-a5fcfd23e055@ed.ac.uk>
	<1485508405900.26497@kuleuven.be> <1485521165610.87517@kuleuven.be>
	<1485528229525.12125@kuleuven.be>
Message-ID: <eca2c279-b22f-32a0-bc80-0b063cd2eab0@ed.ac.uk>

Hi,

As long as you code each colony, patriline, ID and trial uniquely (for 
example, you don't call the first bees from two different patrilines 
bee1) then you don't need to be explicit about the nesting: 
(1|colony)+(1|patriline)+(1|ID) = (1|colony/patriline/ID). It used to be 
useful for computational reasons to explicitly state that the design was 
nested, but now most software (lmer/asreml/MCMCglmm) use algorithms for 
detecting this structure to determine a good computational strategy.

You can also fit (1|colony)+(1|patriline)+(1|ID)+(1|trial)+(1|obs) where 
obs is a factor with a different level for each row. It accounts for 
overdispersion. How many of these random effect you choose to model is 
your decision.

Are there a fixed number of eggs and multiple bees are trying to eat 
them, or is each bee assayed alone? If the former, the response 
variables might not conform to a binomial but a multinomial.

The patriline variance is accounting for any imbalance in the data, so 
it is estimating the variance had there been no skew. I still don't 
understand why you want to include the proportional distribution of the 
different patrilines in the model, particularly as an offset? Why would 
it influence what a single bee with known patriline does - because it is 
more likely to eat an egg that belongs to a different patriline? If so, 
I understand, but I would just have it in as a standard covariate.

Cheers,

Jarrod






On 27/01/2017 14:42, Tom Wenseleers wrote:
> Hi Jarrod,
> In the meantime I think I found what I was doing wrong - I should have included all the control bees that we genotyped and which did not eat any eggs as well in the dataset, specifying they ate 0 eggs, and then I should have specified the standard nested mixed model
> fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-(1|colony/patriline/ID), data=data, family=binomial)
>
> The only residual query is whether trial should be included as well, perhaps as a crossed random factor +(1|trial) in the model?
>
> best regards,
> Tom
>
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Tom Wenseleers <tom.wenseleers at kuleuven.be>
> Sent: 27 January 2017 13:45
> To: Jarrod Hadfield; r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Correct specification of nested binomial mixed model with custom intercept to infer variance components and intraclass correlations
>
> Hi Jarrod,
> Well the structure of the datafile is such that each row of the datafile contains the proportion of the eggs eaten in each trial by each individual bee (that belongs to a particular patriline, ie there would be several lines per trial corresponding to different individual bees, some of which might also occur again in different trials with the same colony) (this is in fit1 below) or the mean proportion of the eggs eaten in each trial by a patricular patriline (in fit2 below). So I was not entirely sure how I should still incorporate trial as a random effect as well, and how this would look like?
> The reason that I thought it would make sense to also include the proportional distribution of the different patrilines in the colony (either as a custom intercept or a covariate, not sure about that) in the model is that these give the a priori probability that eggs would be eaten by bees belonging to different patrilines (as they are heavily skewed), so the heritability of the trait would be expressed mainly in terms of some patrilines making a much greater or much lower contribution to egg eating than expected based on their proportional presence in the colony. But I am not sure how I would correctly do that in my model, hence my question? Makes sense?
>
> cheers,
> Tom
>
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Sent: 27 January 2017 06:37
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Correct specification of nested binomial mixed model with custom intercept to infer variance components and intraclass correlations
>
> Hi Tom,
>
> If I understand your experiment/data set up, each row of the data frame
> contains all the data for one trial? If so, having trial as random
> effect is one way of modelling any overdispersion in the data with
> respect to the binomial. If overdispersion exists it is important to
> model this. Other than that the random effect structure seems fine.
>
> Also I don't understand why baseline is fitted, especially as an offset.
> If you are fitting patriline as a random effect presumably you know the
> patriline for each bee? Why then fit the proportion of the colony that
> has the same patriline as the bee, and why fix the associated
> coefficient to one?
>
> Cheers,
>
> Jarrod
>
>
>
> On 26/01/2017 15:11, Tom Wenseleers wrote:
>> Dear all,
>> Just to ask a bit of advice about the correct way to specify a nested binomial GLM, in the context of estimating variance components / intraclass correlations to infer heritabilities of a behavioural trait.
>>
>> The behavioural trait is a binary one (eating an egg or not, 1 or 0), and is performed by known individual honeybees (individually numbered, ?individual_ID?) of a known father line (?patriline?) of a given hive (?colony?). Several subsequent egg eating events could be performed by the same individuals. Of each experiment with each colony several trials were done, and for each trial we have data on how many eggs were eaten in total, so we could analyse as a dependent variable the proportion of those eggs that were eaten by a given individual. In addition, we also genotyped a bunch of bees of each colony, which gave us the patriline distribution within each colony (?expected_proportion_patriline?), i.e. the proportion that each patriline makes up in the colony, which I thought should affect the a priori probability that bees of a given patriline would be observed eating eggs.
>>
>> My question is what mixed model syntax would make most sense to analyse this data, and allows us to infer variance components and intraclass correlations as a basis for a heritability estimate of this egg eating behaviour?
>>
>> One model I thought of was to include the expected proportion of each patriline that is present as a custom offset, using
>> library(afex)
>> set_sum_contrasts() # use effect coding
>> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
>> fit1=glmer(cbind(eggs_eaten_by_individual, eggs_eaten_in_total_intrial -eggs_eaten_by_individual)~-1+(1|colony/patriline/ID), offset=baseline, data=data, family=binomial)
>> but would this model make sense as a basis to estimate the variance components and intraclass correlation?
>>
>> In another model I worked with the mean eggs eaten by bees of a given patriline and then fitted the model
>> data$baseline=qlogis(data$expected_proportion_patriline) # custom intercept (qlogis=logit)
>> fit2=glmer(cbind(eggs_eaten_by_patriline, eggs_eaten_in_total_intrial ? eggs_eaten_by_patriline)~-1+(1|colony/patriline), offset=baseline, data=data, family=binomial)
>>
>> Again though I am not sure if such a model would make sense, and neither of my two models take trial explicitly as a factor. Would anybody have any advice by any chance about the most sensible model given my experimental design (proportion data, with individuals nested in patriline nested in colony, with repeated trials and a priori info on the proportion of eggs that would be expected to be eaten by each patriline based on independent genotyping, which could perhaps be included as a custom intercept or a covariate)?
>>
>> Best regards,
>> Tom Wenseleers
>> Dept of Biology
>> University of Leuven
>> Belgium
>>
>> _____
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From oppela at gmail.com  Sat Jan 28 16:43:29 2017
From: oppela at gmail.com (Claudio)
Date: Sat, 28 Jan 2017 16:43:29 +0100
Subject: [R-sig-ME] multivariate mixed nested model
Message-ID: <1485618209.1531.29.camel@gmail.com>

Hi all.
I collected six body features (bf1-bf6)from three populations of a
salamander and from two populations of another sister species of
salamander.
I would evaluate how the species (fixed) and population belonging
(random) affect the body features, by comparing models built with lme4.
For some models, I also want to include bf6 as covariate. Thus, in case
of univariate analyses, some models, for example, could be:
mo1<-lmer(bf1~species+(1|species:population), data, REML=FALSE)
mo2<-lmer(bf1~species+bf6+(1|species:population), data, REML=FALSE)

However, I want to fit multivariate models, and my post is about this.
First, I melted the data:
mdata<-melt(data, id.vars = c("species", "population", "bf6"),
measure.vars = c("bf1", "bf2","bf3","bf4","bf5"), variable.name =
"traits)

Now the question.
1) Are the multivariate versions of the models mo1 and mo2 above
mumo1<-lmer(value~traits -1 + species + (1|species:populations) +
(1|individuals), mdata, REML=FALSE)
mumo1<-lmer(value~traits -1 + species + bf6 + (1|species:populations) +
(1|individuals), mdata, REML=FALSE)

A secondary question, which in case I will move to a new post:
it seemed to me that building multivariate models with MCMCglmm is
easier. However, cbind did not work, even without missing values: to
your knowledge, is there any issue?

thanks in advance
Claudio ?


From ludovicofrate at hotmail.it  Mon Jan 30 07:22:04 2017
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Mon, 30 Jan 2017 06:22:04 +0000
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <1485618209.1531.29.camel@gmail.com>
References: <1485618209.1531.29.camel@gmail.com>
Message-ID: <VI1PR10MB0048DF8F0C2B97B3A57843E0D64B0@VI1PR10MB0048.EURPRD10.PROD.OUTLOOK.COM>

Hi Claudio, for multivariate data see the mvabund package as well as the boral package.
Regards,
Ludovico

Ottieni Outlook per Android<https://aka.ms/ghei36>


Da: Claudio
Inviato: sabato 28 gennaio, 16:45
Oggetto: [R-sig-ME] multivariate mixed nested model
A: r-sig-mixed-models at r-project.org

Hi all. I collected six body features (bf1-bf6)from three populations of a salamander and from two populations of another sister species of salamander. I would evaluate how the species (fixed) and population belonging (random) affect the body features, by comparing models built with lme4. For some models, I also want to include bf6 as covariate. Thus, in case of univariate analyses, some models, for example, could be: mo1

	[[alternative HTML version deleted]]


From oppela at gmail.com  Mon Jan 30 15:49:42 2017
From: oppela at gmail.com (Claudio)
Date: Mon, 30 Jan 2017 15:49:42 +0100
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <VI1PR10MB0048DF8F0C2B97B3A57843E0D64B0@VI1PR10MB0048.EURPRD10.PROD.OUTLOOK.COM>
References: <1485618209.1531.29.camel@gmail.com>
	<VI1PR10MB0048DF8F0C2B97B3A57843E0D64B0@VI1PR10MB0048.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <1485787782.1204.1.camel@gmail.com>

Hi Ludovico,
thanks for your suggestion. However, it seems that they both deal with
abundance data, while I measured body features.
best regards
Claudio

Il giorno lun, 30/01/2017 alle 06.22 +0000, Ludovico Frate ha scritto:
> Hi Claudio, for multivariate data see the mvabund package as well as
> the boral package.
> Regards,
> Ludovico
> 
> Ottieni Outlook per Android
> 
> 
> Da: Claudio
> Inviato: sabato 28 gennaio, 16:45
> Oggetto: [R-sig-ME] multivariate mixed nested model
> A: r-sig-mixed-models at r-project.org
> Hi all. I collected six body features (bf1-bf6)from three populations
> of a salamander and from two populations of another sister species of
> salamander. I would evaluate how the species (fixed) and population
> belonging (random) affect the body features, by comparing models
> built with lme4. For some models, I also want to include bf6 as
> covariate. Thus, in case of univariate analyses, some models, for
> example, could be: mo1
>


From ludovicofrate at hotmail.it  Mon Jan 30 15:57:04 2017
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Mon, 30 Jan 2017 14:57:04 +0000
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <1485787782.1204.1.camel@gmail.com>
References: <1485618209.1531.29.camel@gmail.com>
	<VI1PR10MB0048DF8F0C2B97B3A57843E0D64B0@VI1PR10MB0048.EURPRD10.PROD.OUTLOOK.COM>,
	<1485787782.1204.1.camel@gmail.com>
Message-ID: <VI1PR10MB00484CB6C679DBC90A538D00D64B0@VI1PR10MB0048.EURPRD10.PROD.OUTLOOK.COM>

Hi Claudio,

both packages can deal with different family, i.e. poisson and negative binomial for counts, beta for proportion, normal...

Ragards,

Ludovico



Dott. For. Ludovico Frate, Ph.D.

Environmetrics Lab,
Dipartimento di Bioscienze e Territorio - Universit? degli Studi del Molise.
Contrada Fonte Lappone, 86090 - Pesche (IS) - ITALIA.
Cel: ++39 3333767557|Fax: ++39 (0874) 404123
E-mail: frateludovico at gmail.com<mailto:frateludovico at gmail.com>|ludovicofrate at hotmail.it<mailto:ludovicofrate at hotmail.it>



________________________________
Da: Claudio <oppela at gmail.com>
Inviato: luned? 30 gennaio 2017 15.49
A: Ludovico Frate; r-sig-mixed-models at r-project.org
Oggetto: Re: [R-sig-ME] multivariate mixed nested model

Hi Ludovico,
thanks for your suggestion. However, it seems that they both deal with
abundance data, while I measured body features.
best regards
Claudio

Il giorno lun, 30/01/2017 alle 06.22 +0000, Ludovico Frate ha scritto:
> Hi Claudio, for multivariate data see the mvabund package as well as
> the boral package.
> Regards,
> Ludovico
>
> Ottieni Outlook per Android
>
>
> Da: Claudio
> Inviato: sabato 28 gennaio, 16:45
> Oggetto: [R-sig-ME] multivariate mixed nested model
> A: r-sig-mixed-models at r-project.org
> Hi all. I collected six body features (bf1-bf6)from three populations
> of a salamander and from two populations of another sister species of
> salamander. I would evaluate how the species (fixed) and population
> belonging (random) affect the body features, by comparing models
> built with lme4. For some models, I also want to include bf6 as
> covariate. Thus, in case of univariate analyses, some models, for
> example, could be: mo1
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jan 30 16:02:10 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 30 Jan 2017 16:02:10 +0100
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <1485618209.1531.29.camel@gmail.com>
References: <1485618209.1531.29.camel@gmail.com>
Message-ID: <CAJuCY5w59JT9tCQZWUX1Q0cvp+i3J1RRyCvN7PhG_uAt9WYd0Q@mail.gmail.com>

Dear Claudio,

I this you need to add the interaction with traits to all the fixed and
random effects. Otherwise you assume that these have the same effect for
each trait. Note that 0 + traits is identical to traits - 1.

mumo1 <- lmer(value~0 + traits + traits:species + (0 +
traits|species:populations) + (0 + traits|individuals), mdata, REML=FALSE)

Your second question needs a reproducible example.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-28 16:43 GMT+01:00 Claudio <oppela at gmail.com>:

> Hi all.
> I collected six body features (bf1-bf6)from three populations of a
> salamander and from two populations of another sister species of
> salamander.
> I would evaluate how the species (fixed) and population belonging
> (random) affect the body features, by comparing models built with lme4.
> For some models, I also want to include bf6 as covariate. Thus, in case
> of univariate analyses, some models, for example, could be:
> mo1<-lmer(bf1~species+(1|species:population), data, REML=FALSE)
> mo2<-lmer(bf1~species+bf6+(1|species:population), data, REML=FALSE)
>
> However, I want to fit multivariate models, and my post is about this.
> First, I melted the data:
> mdata<-melt(data, id.vars = c("species", "population", "bf6"),
> measure.vars = c("bf1", "bf2","bf3","bf4","bf5"), variable.name =
> "traits)
>
> Now the question.
> 1) Are the multivariate versions of the models mo1 and mo2 above
> mumo1<-lmer(value~traits -1 + species + (1|species:populations) +
> (1|individuals), mdata, REML=FALSE)
> mumo1<-lmer(value~traits -1 + species + bf6 + (1|species:populations) +
> (1|individuals), mdata, REML=FALSE)
>
> A secondary question, which in case I will move to a new post:
> it seemed to me that building multivariate models with MCMCglmm is
> easier. However, cbind did not work, even without missing values: to
> your knowledge, is there any issue?
>
> thanks in advance
> Claudio
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From lupp at uchicago.edu  Mon Jan 30 16:55:29 2017
From: lupp at uchicago.edu (Stuart Luppescu)
Date: Mon, 30 Jan 2017 10:55:29 -0500
Subject: [R-sig-ME] Identify large residuals
In-Reply-To: <aff0d00b-ab86-9e90-69f8-1c486eb54208@gmail.com>
References: <1485552442.17730.62.camel@uchicago.edu>
	<aff0d00b-ab86-9e90-69f8-1c486eb54208@gmail.com>
Message-ID: <1485791729.12577.68.camel@uchicago.edu>

On Fri, 2017-01-27 at 16:49 -0500, Ben Bolker wrote:
Thanks very much for your as-always helpful response.

> 1. you can calculate residuals with different levels of random
> effects included via?? predict(...,re.form=<something>)-(observed
> value).? In your case, though, it seems you just want the raw
> residuals() (lowest-level) -- but see point #2.

Right, but residuals() seems to put out a single vector of length 600.
I can't figure out how to rearrange these into rows and columns. Is it
row-wise?

> 2. in this sample data set, there is a single response per question
> for all but one examinee.? This will make the qid-with-examinee
> random effect variance almost impossible to estimate (strongly
> confounded with the observation-level residual variance); was that on
> purpose or is that an artifact of the example you gave us to look at?

No, that's on purpose.

> (Now that I look closer, I think this is what you meant by "I added
> one line at the bottom with dummy data to get it to run"; otherwise
> you would get an error from lmer() that you'd have to override.)

You can override this error? I want to do that! How do I do it?

>  What do your real data look like? If they really have only one
> observation per examinee:qid combo, then you should leave out the
> nested random effect -- it will be captured entirely by the residual
> variance term.

My main question is how to set up the model to get what I want. I want
to identify examinee:qid response-time residuals that are unusually
large controlling for the time the examinee takes on all the items, and
the time each item takes over all the examinees. I realize that my
model is overspecified but I'm thinking there should be some way to do
it. I could do it in an IRT model but then I'd have to categorize the
times and lose a lot of information.

> 3. For what it's worth, it doesn't seem as though log-transforming
> these data is worthwhile, but that may be because you made up data
> that were already reasonably well distributed?

In the full dataset the response time is quite positively skewed. I
tried it both ways and anova() showed that the log-transformed time fit
much better. I don't know if it's appropriate to use anova() in this
situation since the models are not strictly nested, but I thought the
log transform probably wouldn't hurt, so what the hell.

-- 
Stuart Luppescu
Chief Psychometrician (ret.)
UChicago Consortium on School Research
http://consortium.uchicago.edu


From mollieebrooks at gmail.com  Tue Jan 31 15:22:53 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Tue, 31 Jan 2017 15:22:53 +0100
Subject: [R-sig-ME] GLMM for underdispersed count data:
	Conway-Maxwell-Poisson and Ordinal
In-Reply-To: <0e9bb1fc-a8ee-c03f-f166-d767b444dd1c@gmail.com>
References: <a354afb2-6835-8457-dcd6-d2ae89ded0b4@ebd.csic.es>
	<9fe6f0cc-eb40-d81e-2915-bdbda1957ba2@ebd.csic.es>
	<cd745e2c-9b7f-a347-6568-ecd79e8ec2a3@gmail.com>
	<37ba41e9-d157-b1de-676e-c7b2030efd9e@ebd.csic.es>
	<A2B13B0A-9650-421F-85B9-17D4B64D412C@gmail.com>
	<d8505369-dc1d-77da-36e8-f4d788d43bf8@ebd.csic.es>
	<0e9bb1fc-a8ee-c03f-f166-d767b444dd1c@gmail.com>
Message-ID: <01CF2FAB-0573-4BA8-B98D-E76787B14564@gmail.com>

I wanted to follow up on this discussion and let you know that glmmTMB recently changed the way that it does Conway-Maxwell-Poisson regression. So if you are using glmmTMB for this, you should probably install the new version from source. It now is parameterized to do regression on the mean rather than the approximate mean, which should improve accuracy and interpretability. It?s part of the master branch now, so the standard installation from source should work as described here https://github.com/glmmTMB/glmmTMB

cheers,
Mollie 

???????????
Mollie E. Brooks, Ph.D.
Postdoctoral Researcher
National Institute of Aquatic Resources
Technical University of Denmark

> On 15Dec 2016, at 1:52, Ben Bolker <bbolker at gmail.com> wrote:
> 
> 
> 
> 
> On 16-12-14 11:05 AM, Simone Santoro wrote:
>> Thank you all so much for it. Really a very useful discussion, hope it
>> may be so to others too.
>> 
>> El 14/12/2016 a las 16:06, Mollie Brooks escribi?:
>>> Hi Simone,
>>> 
>>> For the glmmTMB model with the Conway-Maxwell Poisson distribution,
>>> the left side of the equation should technically by fledges rather
>>> than as.factor(fledges). However, it looks like glmmTMB doesn?t
>>> evaluate the as.factor() command and fits the model with fledges as
>>> the response anyway.
> 
>  I'd be careful with this conclusion.  I think these are *not* the same
> model.  For the fake data set (where all the true effects are zero) the
> results aren't that different, but what happens when you convert an
> integer value to a factor is that the unique values get converted to
> codes 1, 2, ...  This would potentially be disastrous.
> 
>  I got the clmm model to run with Rune's development version; it's a
> little hard to see whether the results are comparable or not since it's
> fitting a qualitatively different model ...
> 
> 
>>> 
>>> If you end up needing zero-inflation also, it can be specified using
>>> the ziformula command. See vignette("glmmTMB") or here
>>> https://github.com/glmmTMB/glmmTMB/blob/master/misc/salamanders.pdf
>>> for an example.
>>> 
>>> cheers,
>>> Mollie
>>> 
>>> ???????????
>>> Mollie E. Brooks, Ph.D.
>>> Postdoctoral Researcher
>>> National Institute of Aquatic Resources
>>> Technical University of Denmark
>>> 
>>>> On 9Dec 2016, at 19:40, Simone Santoro <santoro at ebd.csic.es
>>>> <mailto:santoro at ebd.csic.es>> wrote:
>>>> 
>>>> Hi,
>>>> 
>>>> Thank you all very much your hints. They have been really really
>>>> helpful for me. Below you may find a reproducible code to see how
>>>> three approaches fit a simulated data set (clmm::ordinal,
>>>> glmmTMB::glmmTMB, fitme:spaMM). Results seem to me qualitatively
>>>> similar but with clmm:ordinal I cannot use the three crossed random
>>>> effects because I get an error like this:
>>>> Error: no. random effects (=135) >= no. observations (=100)
>>>> 
>>>> set.seed(1234)
>>>> library(ordinal)
>>>> library(glmmTMB)
>>>> library(spaMM)
>>>> dati<- data.frame(fledges= rpois(100,10), habitatF=
>>>> as.factor(rbinom(100,1,0.5)), areaPatchFath= rnorm(100), poligF01=
>>>> as.factor(rbinom(100,1,0.5)),StdLayingDate= rnorm(100), ageFath1=
>>>> rpois(100,3), ageMoth1= rpois(100,3), year=
>>>> as.factor(rpois(100,200)), ringMoth= as.factor(rpois(100,200)),
>>>> ringFath= as.factor(rpois(100,200)))
>>>> str(dati)
>>>> 
>>>> system.time(Fitclm<- clmm(as.factor(fledges) ~
>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringMoth)+(1|ringFath),data=dati,Hess=T))
>>>> # this way it works...
>>>> system.time(Fitclm1<- clmm(as.factor(fledges) ~
>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringFath),data=dati,Hess=T))
>>>> summary(Fitclm1)
>>>> 
>>>> system.time(FitglmmTMB<- glmmTMB(as.factor(fledges) ~
>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringMoth)+(1|ringFath),data=dati,family=
>>>> "compois"))
>>>> summary(FitglmmTMB)
>>>> 
>>>> system.time(FitglmmTMB<- glmmTMB(as.factor(fledges) ~
>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringMoth)+(1|ringFath),data=dati,family=
>>>> "compois"))
>>>> summary(FitglmmTMB)
>>>> 
>>>> # This lasts much more (3-4')
>>>> system.time(Fitfitme<- fitme(fledges ~
>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringFath)+(1|ringMoth),data=dati,COMPoisson(),method
>>>> = "ML"))
>>>> summary(Fitfitme)
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> El 08/12/2016 a las 4:32, Ben Bolker escribi?:
>>>>>   One reference that uses ordinal regression in a similar situation
>>>>> (litter size of Florida panthers) is
>>>>> http://link.springer.com/article/10.1007/s00442-011-2083-0 ("Does
>>>>> genetic introgression improve female reproductive performance? A test on
>>>>> the endangered Florida panther")
>>>>> 
>>>>>  Not sure about the number-of-random-effects error: a reproducible
>>>>> example would probably be needed (smaller is better!)
>>>>> 
>>>>>  Ben Bolker
>>>>> 
>>>>> 
>>>>> On 16-12-06 08:41 AM, Simone Santoro wrote:
>>>>>> Dear all,
>>>>>> 
>>>>>> I am trying to find an appropriate GLMM (with temporal and individual 
>>>>>> crossed random effects) to model underdispersed count data (clutch 
>>>>>> size). I have found several possible ways of doing that. A good 
>>>>>> distribution for data like this would seem to be the 
>>>>>> Conway-Maxwell-Poisson but I have not found a way of using it within a 
>>>>>> GLMM in R (I have asked here 
>>>>>> <http://stats.stackexchange.com/questions/249738/how-to-define-the-nu-parameter-of-conway-maxwell-poisson-in-spamm-package> 
>>>>>> and here 
>>>>>> <http://stats.stackexchange.com/questions/249798/conway-maxwell-poisson-with-crossed-random-effects-in-r>).
>>>>>> I have seen that Ben Bolker suggested (here 
>>>>>> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021945.html>and 
>>>>>> here 
>>>>>> <http://stats.stackexchange.com/questions/92156/how-to-handle-underdispersion-in-glmm-binomial-outcome-variable>) 
>>>>>> to use an ordinal model in cases like this(e.g. _ordinal:clmm_). I have 
>>>>>> tried this solution and the results I obtain makes (biological) sense to 
>>>>>> me. However, I wonder why but I cannot put all the three crossed random 
>>>>>> effects I have in the clmm model (_Error: no. random effects (=1254) >= 
>>>>>> no. observations (=854)_) whereas it is not a problem for the glmer 
>>>>>> model (the no. of levels of each single random effect does not exceed 854)*.
>>>>>> Beyond that, and that's what I would like to ask you, *I cannot find a 
>>>>>> reference to justify I used the ordinal model* to deal with 
>>>>>> underdispersed count data (referee will ask it for sure).
>>>>>> Best,
>>>>>> 
>>>>>> Simone
>>>>>> 
>>>>>> * FMglmer<- glmer(fledges ~ habitatF * (areaPatchFath + poligF01 + 
>>>>>> StdLayingDate + ageFath1 + ageMoth1) + (1|year) + (1|ringMoth) + 
>>>>>> (1|ringFath), data = datiDRS)
>>>>>>    FMclmm<- glmer(as.factor(fledges)~ habitatF * (areaPatchFath + 
>>>>>> poligF01 + StdLayingDate + ageFath1 + ageMoth1) + (1|year) + 
>>>>>> (1|ringMoth) + (1|ringFath), data = datiDRS)
>>>>>> 
>>>>>> 
>>>>>> 	[[alternative HTML version deleted]]
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> 
>>>> 
>>>> -- 
>>>> Simone Santoro
>>>> PhD
>>>> Department of Ethology and Biodiversity Conservation
>>>> Do?ana Biological Station
>>>> Calle Am?rico Vespucio s/n
>>>> 41092 Seville - Spain
>>>> Phone no. +34 954 466 700 (ext. 1213)
>>>> http://www.researchgate.net/profile/Simone_Santoro
>>>> http://orcid.org/0000-0003-0986-3278
>>> 
>> 
>> -- 
>> Simone Santoro
>> PhD
>> Department of Ethology and Biodiversity Conservation
>> Do?ana Biological Station
>> Calle Am?rico Vespucio s/n
>> 41092 Seville - Spain
>> Phone no. +34 954 466 700 (ext. 1213)
>> http://www.researchgate.net/profile/Simone_Santoro
>> http://orcid.org/0000-0003-0986-3278
>> 


	[[alternative HTML version deleted]]


From thlytras at gmail.com  Wed Feb  1 09:37:44 2017
From: thlytras at gmail.com (Theodore Lytras)
Date: Wed, 01 Feb 2017 10:37:44 +0200
Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
Message-ID: <3197712.2r4pMF0lQW@equinox2>

Hi all,

I have repeated measures on individuals, and I'm fitting two LMMs with random 
intercepts and slopes per participant, on two outcomes (Y1, Y2) as follows:

library(lme4)
m1 <- lmer(Y1 ~ age + X + (age | id), data=dat)
m2 <- lmer(Y2 ~ age + X + (age | id), data=dat)

Fixed covariates for the two outcomes are the same, and id = participant ID.

However, my two continuous outcomes Y1 and Y2 are correlated (highly), thus I 
would like to jointly model them (including estimating their correlation).

What is the appropriate way to do so in this case? Can lme4 do it, or do I 
have to resort to MCMCglmm or JAGS? Could someone point me in the right 
direction (for either lme4, MCMCglmm or JAGS), including any helpful papers, 
guides, etc ??

Thank you,

Theodore Lytras

Epidemiologist, PhD student
Hellenic Centre for Disease Control and Prevention


From thierry.onkelinx at inbo.be  Wed Feb  1 09:49:58 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 1 Feb 2017 09:49:58 +0100
Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
In-Reply-To: <3197712.2r4pMF0lQW@equinox2>
References: <3197712.2r4pMF0lQW@equinox2>
Message-ID: <CAJuCY5we681aPJj9sx9odUFEWT0S3xbdUn0mj5LBbRnwXLuA7w@mail.gmail.com>

Dear Theodore,

You can do this is you convert the dataset into long format.

untested

library(lme4)
library(tidyr)
long <- gather(dat, key = "trait", value = "Y", Y1, Y2)
lmer(Y ~ 0 + trait + trait * (age + X) + (0 + trait | id), data = long)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-02-01 9:37 GMT+01:00 Theodore Lytras <thlytras at gmail.com>:

> Hi all,
>
> I have repeated measures on individuals, and I'm fitting two LMMs with
> random
> intercepts and slopes per participant, on two outcomes (Y1, Y2) as follows:
>
> library(lme4)
> m1 <- lmer(Y1 ~ age + X + (age | id), data=dat)
> m2 <- lmer(Y2 ~ age + X + (age | id), data=dat)
>
> Fixed covariates for the two outcomes are the same, and id = participant
> ID.
>
> However, my two continuous outcomes Y1 and Y2 are correlated (highly),
> thus I
> would like to jointly model them (including estimating their correlation).
>
> What is the appropriate way to do so in this case? Can lme4 do it, or do I
> have to resort to MCMCglmm or JAGS? Could someone point me in the right
> direction (for either lme4, MCMCglmm or JAGS), including any helpful
> papers,
> guides, etc ??
>
> Thank you,
>
> Theodore Lytras
>
> Epidemiologist, PhD student
> Hellenic Centre for Disease Control and Prevention
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thlytras at gmail.com  Wed Feb  1 10:39:58 2017
From: thlytras at gmail.com (Theodore Lytras)
Date: Wed, 01 Feb 2017 11:39:58 +0200
Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
In-Reply-To: <CAJuCY5we681aPJj9sx9odUFEWT0S3xbdUn0mj5LBbRnwXLuA7w@mail.gmail.com>
References: <3197712.2r4pMF0lQW@equinox2>
	<CAJuCY5we681aPJj9sx9odUFEWT0S3xbdUn0mj5LBbRnwXLuA7w@mail.gmail.com>
Message-ID: <4084404.sHxPralzxM@equinox2>

Dear Thierry,

Thank you, this helps indeed. 
However, are you sure that this models the random slopes (age | id) as well? 

I tried it on my data, I indeed get very similar results as with the two 
separate models, both for the fixed and for the random part. 
For the random part, I got:

Random effects:
 Groups   Name    Variance Std.Dev. Corr
 id       traitY1 0.56144  0.7493       
          traitY2 0.93665  0.9678   0.98
 Residual         0.06432  0.2536       

The variances for traitY1 and traitY2 are very close to the random intercept 
variances for the two separate models. But where are the variances for the 
random slopes??

Also, the 0.98 above, is it the correlation between the outcomes? Or should I 
look at the "Correlation of Fixed Effects" part in the summary() output, where 
the correlation between traitY1 and traitY2 is reported as 0.925 ??

A minor detail: the first "trait" in your formula, the one after the 0, isn't 
it redundant? [ Y ~ 0 + trait + trait * (age+X) + (0+trait|id)  ]

Thank you again,

Theodore


???? ???????, 1 ??????????? 2017 9:49:58 ?.?. EET Thierry Onkelinx ??????:
> Dear Theodore,
> 
> You can do this is you convert the dataset into long format.
> 
> untested
> 
> library(lme4)
> library(tidyr)
> long <- gather(dat, key = "trait", value = "Y", Y1, Y2)
> lmer(Y ~ 0 + trait + trait * (age + X) + (0 + trait | id), data = long)
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2017-02-01 9:37 GMT+01:00 Theodore Lytras <thlytras at gmail.com>:
> > Hi all,
> > 
> > I have repeated measures on individuals, and I'm fitting two LMMs with
> > random
> > intercepts and slopes per participant, on two outcomes (Y1, Y2) as
> > follows:
> > 
> > library(lme4)
> > m1 <- lmer(Y1 ~ age + X + (age | id), data=dat)
> > m2 <- lmer(Y2 ~ age + X + (age | id), data=dat)
> > 
> > Fixed covariates for the two outcomes are the same, and id = participant
> > ID.
> > 
> > However, my two continuous outcomes Y1 and Y2 are correlated (highly),
> > thus I
> > would like to jointly model them (including estimating their correlation).
> > 
> > What is the appropriate way to do so in this case? Can lme4 do it, or do I
> > have to resort to MCMCglmm or JAGS? Could someone point me in the right
> > direction (for either lme4, MCMCglmm or JAGS), including any helpful
> > papers,
> > guides, etc ??
> > 
> > Thank you,
> > 
> > Theodore Lytras
> > 
> > Epidemiologist, PhD student
> > Hellenic Centre for Disease Control and Prevention
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Wed Feb  1 10:58:29 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 1 Feb 2017 10:58:29 +0100
Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
In-Reply-To: <4084404.sHxPralzxM@equinox2>
References: <3197712.2r4pMF0lQW@equinox2>
	<CAJuCY5we681aPJj9sx9odUFEWT0S3xbdUn0mj5LBbRnwXLuA7w@mail.gmail.com>
	<4084404.sHxPralzxM@equinox2>
Message-ID: <CAJuCY5zt23GUpw-=V1apWnta5ftE6_XKaiKLFZkCEFFjKsiVJw@mail.gmail.com>

Dear Theodore,

I missing the random slope of age. Use (0 + trait:age | id). The 0.98 is
the correlation between the random intercepts, not the outcomes. Likewise
the 0.925 is the correlation between the fixed intercepts, not the
outcomes. IMHO you should look at the trait:age and trait:X interactions.
These interactions model how strong the slopes of age and X differ between
the traits. Small differences suggest strong correlation. I'm not sure if
you can express that into a single correlation measurement.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-02-01 10:39 GMT+01:00 Theodore Lytras <thlytras at gmail.com>:

> Dear Thierry,
>
> Thank you, this helps indeed.
> However, are you sure that this models the random slopes (age | id) as
> well?
>
> I tried it on my data, I indeed get very similar results as with the two
> separate models, both for the fixed and for the random part.
> For the random part, I got:
>
> Random effects:
>  Groups   Name    Variance Std.Dev. Corr
>  id       traitY1 0.56144  0.7493
>           traitY2 0.93665  0.9678   0.98
>  Residual         0.06432  0.2536
>
> The variances for traitY1 and traitY2 are very close to the random
> intercept
> variances for the two separate models. But where are the variances for the
> random slopes??
>
> Also, the 0.98 above, is it the correlation between the outcomes? Or
> should I
> look at the "Correlation of Fixed Effects" part in the summary() output,
> where
> the correlation between traitY1 and traitY2 is reported as 0.925 ??
>
> A minor detail: the first "trait" in your formula, the one after the 0,
> isn't
> it redundant? [ Y ~ 0 + trait + trait * (age+X) + (0+trait|id)  ]
>
> Thank you again,
>
> Theodore
>
>
> ???? ???????, 1 ??????????? 2017 9:49:58 ?.?. EET Thierry Onkelinx ??????:
> > Dear Theodore,
> >
> > You can do this is you convert the dataset into long format.
> >
> > untested
> >
> > library(lme4)
> > library(tidyr)
> > long <- gather(dat, key = "trait", value = "Y", Y1, Y2)
> > lmer(Y ~ 0 + trait + trait * (age + X) + (0 + trait | id), data = long)
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2017-02-01 9:37 GMT+01:00 Theodore Lytras <thlytras at gmail.com>:
> > > Hi all,
> > >
> > > I have repeated measures on individuals, and I'm fitting two LMMs with
> > > random
> > > intercepts and slopes per participant, on two outcomes (Y1, Y2) as
> > > follows:
> > >
> > > library(lme4)
> > > m1 <- lmer(Y1 ~ age + X + (age | id), data=dat)
> > > m2 <- lmer(Y2 ~ age + X + (age | id), data=dat)
> > >
> > > Fixed covariates for the two outcomes are the same, and id =
> participant
> > > ID.
> > >
> > > However, my two continuous outcomes Y1 and Y2 are correlated (highly),
> > > thus I
> > > would like to jointly model them (including estimating their
> correlation).
> > >
> > > What is the appropriate way to do so in this case? Can lme4 do it, or
> do I
> > > have to resort to MCMCglmm or JAGS? Could someone point me in the right
> > > direction (for either lme4, MCMCglmm or JAGS), including any helpful
> > > papers,
> > > guides, etc ??
> > >
> > > Thank you,
> > >
> > > Theodore Lytras
> > >
> > > Epidemiologist, PhD student
> > > Hellenic Centre for Disease Control and Prevention
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb  1 15:02:26 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 1 Feb 2017 15:02:26 +0100
Subject: [R-sig-ME] Modeling truncated counts with glmer
In-Reply-To: <20170201142256.Horde.7bTr3oe0RCzGJyE9aJfg2iW@webmail.uni-tuebingen.de>
References: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>
	<CAJuCY5znseEwrASNwkzzN5C8rkpzebZnEAUEA-HDLG5PMe3iVA@mail.gmail.com>
	<20170123100147.Horde.QGfa6_Jsb7QdOvh6vL11Et2@webmail.uni-tuebingen.de>
	<CAJuCY5x1B3Kpr-z6xuPYMDFbBqspFr9yp-Mg1k6dGmBL4MWQUQ@mail.gmail.com>
	<20170201142256.Horde.7bTr3oe0RCzGJyE9aJfg2iW@webmail.uni-tuebingen.de>
Message-ID: <CAJuCY5w69rPmE19aWKewA69J_Lzd8ROK=_WUZeGogzTiH8uoLg@mail.gmail.com>

Dear Jo?o,

The intercept is -0.07376 on the **logit** scale. That is 0.48 on the
original scale. Use plogis(-0.07376) to transform from logit to original
scale. Your interpretation of the intercept is correct.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-02-01 14:22 GMT+01:00 Jo?o C P Santiago <joao.santiago at uni-tuebingen.de
>:

> Thank you for your input! Only now did I go back to this model.
>
> I'm having some doubts about the meaning of the intercept from my binomial
> model. Here's the complete output:
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: cbind(correctPair, incorrectPair) ~ I(abruf - 1) * treatment +
>     version + (1 | subjectNumber)
>    Data: .
>
>      AIC      BIC   logLik deviance df.resid
>    691.4    708.4   -339.7    679.4      119
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.2676 -0.7861 -0.0428  0.9417  2.7483
>
> Random effects:
>  Groups        Name        Variance Std.Dev.
>  subjectNumber (Intercept) 0.7135   0.8447
> Number of obs: 125, groups:  subjectNumber, 21
>
> Fixed effects:
>                                   Estimate Std. Error z value Pr(>|z|)
> (Intercept)                       -0.07376    0.20096  -0.367    0.714
> I(abruf - 1)                       1.30891    0.06904  18.958   <2e-16 ***
> treatmentStimulation               0.06116    0.09961   0.614    0.539
> versionB                          -0.08709    0.07222  -1.206    0.228
> I(abruf - 1):treatmentStimulation  0.03342    0.09727   0.344    0.731
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) I(b-1) trtmnS versnB
> I(abruf-1)  -0.235
> trtmntStmlt -0.254  0.482
> versionB    -0.189 -0.029  0.037
> I(-1):trtmS  0.164 -0.681 -0.689  0.030
>
>
>
> abruf has values c(1,2,3) so by -1 it starts at a more meaningful point.
>
> My question is: is the intercept the ratio of success/no success on abruf
> 0, treatment control and version A? If so why is it statistically speaking
> 1 on the log scale? The number of successes increases from abruf 1 to 3 (as
> seen by the estimate of the model and plots).
>
> It's the first time I'm dealing with such complex models. Thank you for
> your patience and time.
>
> Best
> J Santiago
>
>
>
> Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
> It looks like you participants performed a known number of trials which
>> resulted in either success or failure. The binomial distribution models
>> exactly that. The model fit would be the probability of success.
>>
>> Once you have the relevant distribution, you can set the relevant
>> covariates. Which and in which form (linear, polynomial, factor) depends
>> on
>> the hypotheses which are relevant for your experiment.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2017-01-23 10:01 GMT+01:00 Jo?o C P Santiago <
>> joao.santiago at uni-tuebingen.de
>>
>>> :
>>>
>>
>> Thank you! Could you be a bit more specific as to why? I will most likely
>>> encounter similar data in the future and I want to know how to think
>>> about
>>> it.
>>>
>>> Fitting the model with abruf as a factor resulted in a better fit, but
>>> that answers a different question right? Namely how different is the
>>> intercept at a timepoint in comparison with the main level (abruf 0 in my
>>> code)?
>>>
>>> Best
>>>
>>>
>>> Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>>
>>> Dear Jo?o,
>>>
>>>>
>>>> A binomial distribution seems more relevant to me.
>>>>
>>>> glmer(cbind(correctPair, incorrectPair) ~ I((abruf - 1)^2) * treatment +
>>>> (1|subjectNumber), data=data, family = binomial)
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and
>>>> Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to
>>>> say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of
>>>> data.
>>>> ~ John Tukey
>>>>
>>>> 2017-01-23 8:46 GMT+01:00 Jo?o C P Santiago <
>>>> joao.santiago at uni-tuebingen.de>
>>>> :
>>>>
>>>> Hi,
>>>>
>>>>>
>>>>> In my experiment 20 participants did a word-pairs learning task in two
>>>>> conditions (repeated measures):
>>>>> 40 pairs of nouns are presented on a monitor, each for 4s and with an
>>>>> interval of 1s. The words of each pair were moderately semantically
>>>>> related
>>>>> (e.g., brain, consciousness and solution, problem). Two different word
>>>>> lists were used for the subject?s two experimental conditions, with the
>>>>> order of word lists balanced across subjects and conditions. The
>>>>> subject
>>>>> had unlimited time to recall the appropriate response word, and did
>>>>> three
>>>>> trials in succession for each list:
>>>>>
>>>>> Condition 1, List A > T1, T2, T3
>>>>> Condition 2, List B > T1, T2, T3
>>>>>
>>>>> No feedback was given as to whether the remembered word was correct or
>>>>> not.
>>>>>
>>>>> I've seen some people go at this with anova, others subtract the total
>>>>> number of correct pairs in one condition from the other per subject and
>>>>> run
>>>>> a t-test. Since this is count data, a generalized linear model should
>>>>> be
>>>>> more appropriate, right?
>>>>>
>>>>> head(data)
>>>>>   subjectNumber expDay      bmi treatment tones       hour abruf
>>>>> correctPair incorrectPair
>>>>>           <dbl>  <chr>    <dbl>    <fctr> <dbl>     <time> <dbl>
>>>>>  <dbl>         <dbl>
>>>>> 1             1     N2 22.53086   Control     0 27900 secs     1
>>>>> 26            14
>>>>> 2             1     N2 22.53086   Control     0 27900 secs     2
>>>>> 40             0
>>>>> 3             1     N2 22.53086   Control     0 27900 secs     3
>>>>> 40             0
>>>>> 4             2     N1 22.53086   Control     0 27900 secs     1
>>>>> 22            18
>>>>> 5             2     N1 22.53086   Control     0 27900 secs     2
>>>>> 33             7
>>>>> 6             2     N1 22.53086   Control     0 27900 secs     3
>>>>> 36             4
>>>>>
>>>>>
>>>>>
>>>>> I fitted a model with glmer.nb(correctPair ~ I((abruf - 1)^2) *
>>>>> treatment
>>>>> + (1|subjectNumber), data=data). The residuals don't look so good to me
>>>>> http://imgur.com/a/AJXGq and the model is fitting values above 40,
>>>>> which
>>>>> will never happen in real life (not sure if this is important).
>>>>>
>>>>> I'm interested in knowing if there is any difference between conditions
>>>>> (are the values at timepoint (abruf) 1 different? do people remember
>>>>> less
>>>>> in one one condition than in the other (different number of pairs at
>>>>> timepoint 3?)
>>>>>
>>>>>
>>>>> If the direction I'm taking is completely wrong please let me know.
>>>>>
>>>>> Best,
>>>>> Santiago
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Jo?o C. P. Santiago
>>>>> Institute for Medical Psychology & Behavioral Neurobiology
>>>>> Center of Integrative Neuroscience
>>>>> University of Tuebingen
>>>>> Otfried-Mueller-Str. 25
>>>>> 72076 Tuebingen, Germany
>>>>>
>>>>> Phone: +49 7071 29 88981
>>>>> Fax: +49 7071 29 25016
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>
>>> --
>>> Jo?o C. P. Santiago
>>> Institute for Medical Psychology & Behavioral Neurobiology
>>> Center of Integrative Neuroscience
>>> University of Tuebingen
>>> Otfried-Mueller-Str. 25
>>> 72076 Tuebingen, Germany
>>>
>>> Phone: +49 7071 29 88981
>>> Fax: +49 7071 29 25016
>>>
>>>
>>>
>
>
> --
> Jo?o C. P. Santiago
> Institute for Medical Psychology & Behavioral Neurobiology
> Center of Integrative Neuroscience
> University of Tuebingen
> Otfried-Mueller-Str. 25
> 72076 Tuebingen, Germany
>
> Phone: +49 7071 29 88981
> Fax: +49 7071 29 25016
>
>

	[[alternative HTML version deleted]]


From T.Houslay at exeter.ac.uk  Wed Feb  1 16:44:40 2017
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Wed, 1 Feb 2017 15:44:40 +0000
Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
In-Reply-To: <mailman.1890.1485942007.4316.r-sig-mixed-models@r-project.org>
References: <mailman.1890.1485942007.4316.r-sig-mixed-models@r-project.org>
Message-ID: <DB6PR0301MB23117470689224BE1902C112D24D0@DB6PR0301MB2311.eurprd03.prod.outlook.com>

Hi Theodore, just in case it's of interest, there is another option - ASReml (commercial software from VSNi) can fit the type of model you are looking for, with more complex variance structures (and it has an R interface). This thread from the forum might be informative in terms of how to set up such a model:

http://www.vsni.co.uk/forum/viewtopic.php?t=1202

Cheers (and good luck!)

Tom

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Sent: 01 February 2017 09:40
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 122, Issue 1



Date: Wed, 01 Feb 2017 10:37:44 +0200
From: Theodore Lytras <thlytras at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
Message-ID: <3197712.2r4pMF0lQW at equinox2>
Content-Type: text/plain; charset="us-ascii"

Hi all,

I have repeated measures on individuals, and I'm fitting two LMMs with random
intercepts and slopes per participant, on two outcomes (Y1, Y2) as follows:

library(lme4)
m1 <- lmer(Y1 ~ age + X + (age | id), data=dat)
m2 <- lmer(Y2 ~ age + X + (age | id), data=dat)

Fixed covariates for the two outcomes are the same, and id = participant ID.

However, my two continuous outcomes Y1 and Y2 are correlated (highly), thus I
would like to jointly model them (including estimating their correlation).

What is the appropriate way to do so in this case? Can lme4 do it, or do I
have to resort to MCMCglmm or JAGS? Could someone point me in the right
direction (for either lme4, MCMCglmm or JAGS), including any helpful papers,
guides, etc ??

Thank you,

Theodore Lytras

Epidemiologist, PhD student
Hellenic Centre for Disease Control and Prevention




	[[alternative HTML version deleted]]


From oppela at gmail.com  Wed Feb  1 20:01:16 2017
From: oppela at gmail.com (Claudio)
Date: Wed, 01 Feb 2017 20:01:16 +0100
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <CAJuCY5w59JT9tCQZWUX1Q0cvp+i3J1RRyCvN7PhG_uAt9WYd0Q@mail.gmail.com>
References: <1485618209.1531.29.camel@gmail.com>
	<CAJuCY5w59JT9tCQZWUX1Q0cvp+i3J1RRyCvN7PhG_uAt9WYd0Q@mail.gmail.com>
Message-ID: <1485975676.1574.16.camel@gmail.com>

Dear Thierry,
thanks a lot, it is exactly the kind of suggestion I was looking for!
However, when using (0 + traits|individuals) for the random effect of
individuals I got the message:
"Errore: number of observations (=1431) <= number of random effects
(=1431) for term (0 + traits | individuals); the random-effects
parameters and the residual variance (or scale parameter) are probably
unidentifiable"
The models work when I use for the individual part (1|individuals).

A second further question: in order to include in the model a
continuous fixed covariate, am I doing the right thing when scripting:

mumo2 <- lmer(value~0 + traits + traits:species + traits:covariate (0 +
traits|species:populations) + (1|individuals), mdata, REML=FALSE)

About cbind and MCMCglmm, below there is an example which causes the
message:
"Error in `[<-.data.frame`(`*tmp*`, , response.names, value = c(1, 2,
3,??: missing values are not allowed in subscripted assignments of data
frames"

a = c(1, 2, 3, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 5, 5, 4, 5, 7,
8, 9, 4, 1)?
b = c(8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 1, 2, 3, 5, 5, 7, 4, 1, 2, 3, 1,
2, 3, 6, 6)
d = c(8, 9, 4, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 2, 3, 1, 2, 3,
5, 5, 7, 6)??
s = c("m", "m", "f", "f", "m", "m", "m", "f", "m", "f", "f", "f", "m",
"f", "f", "f", "m", "m", "m", "m", "m", "f", "m", "f", "f", "f")?
df = data.frame(a, b, d, s)

y<-cbind(a, b, d)
prior <- list(R = list(V = 1, nu = 0.002))
m <- MCMCglmm(y ~ s, family = "gaussian" , data = df, prior = prior,
verbose = FALSE, pl = TRUE)
summary(m)

all the best (and thanks again)
Claudio

Il giorno lun, 30/01/2017 alle 16.02 +0100, Thierry Onkelinx ha
scritto:
> Dear Claudio,
> 
> I this you need to add the interaction with traits to all the fixed
> and random effects. Otherwise you assume that these have the same
> effect for each trait. Note that 0 + traits is identical to traits -
> 1.
> 
> mumo1 <- lmer(value~0 + traits + traits:species + (0 +
> traits|species:populations) +?(0 + traits|individuals), mdata,
> REML=FALSE)
> 
> Your second question needs a reproducible example.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for
> Nature and Forest?
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance?
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner?
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given
> body of data. ~ John Tukey
> 
> 2017-01-28 16:43 GMT+01:00 Claudio <oppela at gmail.com>:
> > Hi all.
> > I collected six body features (bf1-bf6)from three populations of a
> > salamander and from two populations of another sister species of
> > salamander.
> > I would evaluate how the species (fixed) and population belonging
> > (random) affect the body features, by comparing models built with
> > lme4.
> > For some models, I also want to include bf6 as covariate. Thus, in
> > case
> > of univariate analyses, some models, for example, could be:
> > mo1<-lmer(bf1~species+(1|species:population), data, REML=FALSE)
> > mo2<-lmer(bf1~species+bf6+(1|species:population), data, REML=FALSE)
> > 
> > However, I want to fit multivariate models, and my post is about
> > this.
> > First, I melted the data:
> > mdata<-melt(data, id.vars = c("species", "population", "bf6"),
> > measure.vars = c("bf1", "bf2","bf3","bf4","bf5"), variable.name =
> > "traits)
> > 
> > Now the question.
> > 1) Are the multivariate versions of the models mo1 and mo2 above
> > mumo1<-lmer(value~traits -1 + species + (1|species:populations) +
> > (1|individuals), mdata, REML=FALSE)
> > mumo1<-lmer(value~traits -1 + species + bf6 +
> > (1|species:populations) +
> > (1|individuals), mdata, REML=FALSE)
> > 
> > A secondary question, which in case I will move to a new post:
> > it seemed to me that building multivariate models with MCMCglmm is
> > easier. However, cbind did not work, even without missing values:
> > to
> > your knowledge, is there any issue?
> > 
> > thanks in advance
> > Claudio ?
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From joao.santiago at uni-tuebingen.de  Wed Feb  1 14:22:56 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Wed, 01 Feb 2017 14:22:56 +0100
Subject: [R-sig-ME] Modeling truncated counts with glmer
In-Reply-To: <CAJuCY5x1B3Kpr-z6xuPYMDFbBqspFr9yp-Mg1k6dGmBL4MWQUQ@mail.gmail.com>
References: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>
	<CAJuCY5znseEwrASNwkzzN5C8rkpzebZnEAUEA-HDLG5PMe3iVA@mail.gmail.com>
	<20170123100147.Horde.QGfa6_Jsb7QdOvh6vL11Et2@webmail.uni-tuebingen.de>
	<CAJuCY5x1B3Kpr-z6xuPYMDFbBqspFr9yp-Mg1k6dGmBL4MWQUQ@mail.gmail.com>
Message-ID: <20170201142256.Horde.7bTr3oe0RCzGJyE9aJfg2iW@webmail.uni-tuebingen.de>

Thank you for your input! Only now did I go back to this model.

I'm having some doubts about the meaning of the intercept from my  
binomial model. Here's the complete output:

Generalized linear mixed model fit by maximum likelihood (Laplace  
Approximation) ['glmerMod']
  Family: binomial  ( logit )
Formula: cbind(correctPair, incorrectPair) ~ I(abruf - 1) * treatment +
     version + (1 | subjectNumber)
    Data: .

      AIC      BIC   logLik deviance df.resid
    691.4    708.4   -339.7    679.4      119

Scaled residuals:
     Min      1Q  Median      3Q     Max
-3.2676 -0.7861 -0.0428  0.9417  2.7483

Random effects:
  Groups        Name        Variance Std.Dev.
  subjectNumber (Intercept) 0.7135   0.8447
Number of obs: 125, groups:  subjectNumber, 21

Fixed effects:
                                   Estimate Std. Error z value Pr(>|z|)
(Intercept)                       -0.07376    0.20096  -0.367    0.714
I(abruf - 1)                       1.30891    0.06904  18.958   <2e-16 ***
treatmentStimulation               0.06116    0.09961   0.614    0.539
versionB                          -0.08709    0.07222  -1.206    0.228
I(abruf - 1):treatmentStimulation  0.03342    0.09727   0.344    0.731
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) I(b-1) trtmnS versnB
I(abruf-1)  -0.235
trtmntStmlt -0.254  0.482
versionB    -0.189 -0.029  0.037
I(-1):trtmS  0.164 -0.681 -0.689  0.030



abruf has values c(1,2,3) so by -1 it starts at a more meaningful point.

My question is: is the intercept the ratio of success/no success on  
abruf 0, treatment control and version A? If so why is it  
statistically speaking 1 on the log scale? The number of successes  
increases from abruf 1 to 3 (as seen by the estimate of the model and  
plots).

It's the first time I'm dealing with such complex models. Thank you  
for your patience and time.

Best
J Santiago


Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> It looks like you participants performed a known number of trials which
> resulted in either success or failure. The binomial distribution models
> exactly that. The model fit would be the probability of success.
>
> Once you have the relevant distribution, you can set the relevant
> covariates. Which and in which form (linear, polynomial, factor) depends on
> the hypotheses which are relevant for your experiment.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-01-23 10:01 GMT+01:00 Jo?o C P Santiago <joao.santiago at uni-tuebingen.de
>> :
>
>> Thank you! Could you be a bit more specific as to why? I will most likely
>> encounter similar data in the future and I want to know how to think about
>> it.
>>
>> Fitting the model with abruf as a factor resulted in a better fit, but
>> that answers a different question right? Namely how different is the
>> intercept at a timepoint in comparison with the main level (abruf 0 in my
>> code)?
>>
>> Best
>>
>>
>> Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>> Dear Jo?o,
>>>
>>> A binomial distribution seems more relevant to me.
>>>
>>> glmer(cbind(correctPair, incorrectPair) ~ I((abruf - 1)^2) * treatment +
>>> (1|subjectNumber), data=data, family = binomial)
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> 2017-01-23 8:46 GMT+01:00 Jo?o C P Santiago <
>>> joao.santiago at uni-tuebingen.de>
>>> :
>>>
>>> Hi,
>>>>
>>>> In my experiment 20 participants did a word-pairs learning task in two
>>>> conditions (repeated measures):
>>>> 40 pairs of nouns are presented on a monitor, each for 4s and with an
>>>> interval of 1s. The words of each pair were moderately semantically
>>>> related
>>>> (e.g., brain, consciousness and solution, problem). Two different word
>>>> lists were used for the subject?s two experimental conditions, with the
>>>> order of word lists balanced across subjects and conditions. The subject
>>>> had unlimited time to recall the appropriate response word, and did three
>>>> trials in succession for each list:
>>>>
>>>> Condition 1, List A > T1, T2, T3
>>>> Condition 2, List B > T1, T2, T3
>>>>
>>>> No feedback was given as to whether the remembered word was correct or
>>>> not.
>>>>
>>>> I've seen some people go at this with anova, others subtract the total
>>>> number of correct pairs in one condition from the other per subject and
>>>> run
>>>> a t-test. Since this is count data, a generalized linear model should be
>>>> more appropriate, right?
>>>>
>>>> head(data)
>>>>   subjectNumber expDay      bmi treatment tones       hour abruf
>>>> correctPair incorrectPair
>>>>           <dbl>  <chr>    <dbl>    <fctr> <dbl>     <time> <dbl>
>>>>  <dbl>         <dbl>
>>>> 1             1     N2 22.53086   Control     0 27900 secs     1
>>>> 26            14
>>>> 2             1     N2 22.53086   Control     0 27900 secs     2
>>>> 40             0
>>>> 3             1     N2 22.53086   Control     0 27900 secs     3
>>>> 40             0
>>>> 4             2     N1 22.53086   Control     0 27900 secs     1
>>>> 22            18
>>>> 5             2     N1 22.53086   Control     0 27900 secs     2
>>>> 33             7
>>>> 6             2     N1 22.53086   Control     0 27900 secs     3
>>>> 36             4
>>>>
>>>>
>>>>
>>>> I fitted a model with glmer.nb(correctPair ~ I((abruf - 1)^2) * treatment
>>>> + (1|subjectNumber), data=data). The residuals don't look so good to me
>>>> http://imgur.com/a/AJXGq and the model is fitting values above 40, which
>>>> will never happen in real life (not sure if this is important).
>>>>
>>>> I'm interested in knowing if there is any difference between conditions
>>>> (are the values at timepoint (abruf) 1 different? do people remember less
>>>> in one one condition than in the other (different number of pairs at
>>>> timepoint 3?)
>>>>
>>>>
>>>> If the direction I'm taking is completely wrong please let me know.
>>>>
>>>> Best,
>>>> Santiago
>>>>
>>>>
>>>>
>>>> --
>>>> Jo?o C. P. Santiago
>>>> Institute for Medical Psychology & Behavioral Neurobiology
>>>> Center of Integrative Neuroscience
>>>> University of Tuebingen
>>>> Otfried-Mueller-Str. 25
>>>> 72076 Tuebingen, Germany
>>>>
>>>> Phone: +49 7071 29 88981
>>>> Fax: +49 7071 29 25016
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>>
>> --
>> Jo?o C. P. Santiago
>> Institute for Medical Psychology & Behavioral Neurobiology
>> Center of Integrative Neuroscience
>> University of Tuebingen
>> Otfried-Mueller-Str. 25
>> 72076 Tuebingen, Germany
>>
>> Phone: +49 7071 29 88981
>> Fax: +49 7071 29 25016
>>
>>



-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From santoro at ebd.csic.es  Tue Jan 31 15:25:08 2017
From: santoro at ebd.csic.es (Simone Santoro)
Date: Tue, 31 Jan 2017 15:25:08 +0100
Subject: [R-sig-ME] GLMM for underdispersed count data:
 Conway-Maxwell-Poisson and Ordinal
In-Reply-To: <01CF2FAB-0573-4BA8-B98D-E76787B14564@gmail.com>
References: <a354afb2-6835-8457-dcd6-d2ae89ded0b4@ebd.csic.es>
	<9fe6f0cc-eb40-d81e-2915-bdbda1957ba2@ebd.csic.es>
	<cd745e2c-9b7f-a347-6568-ecd79e8ec2a3@gmail.com>
	<37ba41e9-d157-b1de-676e-c7b2030efd9e@ebd.csic.es>
	<A2B13B0A-9650-421F-85B9-17D4B64D412C@gmail.com>
	<d8505369-dc1d-77da-36e8-f4d788d43bf8@ebd.csic.es>
	<0e9bb1fc-a8ee-c03f-f166-d767b444dd1c@gmail.com>
	<01CF2FAB-0573-4BA8-B98D-E76787B14564@gmail.com>
Message-ID: <f0b4ebfe-a58c-4c90-0b07-ce3d8aeac79c@ebd.csic.es>

Thank you very much Mollie. I am going to take again the analyses in a 
couple of weeks and it will be useful for me knowing that.
Bye,

Simone

El 31/01/2017 a las 15:22, Mollie Brooks escribi?:
> I wanted to follow up on this discussion and let you know that glmmTMB 
> recently changed the way that it does Conway-Maxwell-Poisson 
> regression. So if you are using glmmTMB for this, you should probably 
> install the new version from source. It now is parameterized to do 
> regression on the mean rather than the approximate mean, which should 
> improve accuracy and interpretability. It?s part of the master branch 
> now, so the standard installation from source should work as described 
> here https://github.com/glmmTMB/glmmTMB
>
> cheers,
> Mollie
>
> ???????????
> Mollie E. Brooks, Ph.D.
> Postdoctoral Researcher
> National Institute of Aquatic Resources
> Technical University of Denmark
>
>> On 15Dec 2016, at 1:52, Ben Bolker <bbolker at gmail.com 
>> <mailto:bbolker at gmail.com>> wrote:
>>
>>
>>
>>
>> On 16-12-14 11:05 AM, Simone Santoro wrote:
>>> Thank you all so much for it. Really a very useful discussion, hope it
>>> may be so to others too.
>>>
>>> El 14/12/2016 a las 16:06, Mollie Brooks escribi?:
>>>> Hi Simone,
>>>>
>>>> For the glmmTMB model with the Conway-Maxwell Poisson distribution,
>>>> the left side of the equation should technically by fledges rather
>>>> than as.factor(fledges). However, it looks like glmmTMB doesn?t
>>>> evaluate the as.factor() command and fits the model with fledges as
>>>> the response anyway.
>>
>>  I'd be careful with this conclusion.  I think these are *not* the same
>> model.  For the fake data set (where all the true effects are zero) the
>> results aren't that different, but what happens when you convert an
>> integer value to a factor is that the unique values get converted to
>> codes 1, 2, ...  This would potentially be disastrous.
>>
>>  I got the clmm model to run with Rune's development version; it's a
>> little hard to see whether the results are comparable or not since it's
>> fitting a qualitatively different model ...
>>
>>
>>>>
>>>> If you end up needing zero-inflation also, it can be specified using
>>>> the ziformula command. See vignette("glmmTMB") or here
>>>> https://github.com/glmmTMB/glmmTMB/blob/master/misc/salamanders.pdf
>>>> for an example.
>>>>
>>>> cheers,
>>>> Mollie
>>>>
>>>> ???????????
>>>> Mollie E. Brooks, Ph.D.
>>>> Postdoctoral Researcher
>>>> National Institute of Aquatic Resources
>>>> Technical University of Denmark
>>>>
>>>>> On 9Dec 2016, at 19:40, Simone Santoro <santoro at ebd.csic.es
>>>>> <mailto:santoro at ebd.csic.es>> wrote:
>>>>>
>>>>> Hi,
>>>>>
>>>>> Thank you all very much your hints. They have been really really
>>>>> helpful for me. Below you may find a reproducible code to see how
>>>>> three approaches fit a simulated data set (clmm::ordinal,
>>>>> glmmTMB::glmmTMB, fitme:spaMM). Results seem to me qualitatively
>>>>> similar but with clmm:ordinal I cannot use the three crossed random
>>>>> effects because I get an error like this:
>>>>> Error: no. random effects (=135) >= no. observations (=100)
>>>>>
>>>>> set.seed(1234)
>>>>> library(ordinal)
>>>>> library(glmmTMB)
>>>>> library(spaMM)
>>>>> dati<- data.frame(fledges= rpois(100,10), habitatF=
>>>>> as.factor(rbinom(100,1,0.5)), areaPatchFath= rnorm(100), poligF01=
>>>>> as.factor(rbinom(100,1,0.5)),StdLayingDate= rnorm(100), ageFath1=
>>>>> rpois(100,3), ageMoth1= rpois(100,3), year=
>>>>> as.factor(rpois(100,200)), ringMoth= as.factor(rpois(100,200)),
>>>>> ringFath= as.factor(rpois(100,200)))
>>>>> str(dati)
>>>>>
>>>>> system.time(Fitclm<- clmm(as.factor(fledges) ~
>>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringMoth)+(1|ringFath),data=dati,Hess=T))
>>>>> # this way it works...
>>>>> system.time(Fitclm1<- clmm(as.factor(fledges) ~
>>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringFath),data=dati,Hess=T))
>>>>> summary(Fitclm1)
>>>>>
>>>>> system.time(FitglmmTMB<- glmmTMB(as.factor(fledges) ~
>>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringMoth)+(1|ringFath),data=dati,family=
>>>>> "compois"))
>>>>> summary(FitglmmTMB)
>>>>>
>>>>> system.time(FitglmmTMB<- glmmTMB(as.factor(fledges) ~
>>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringMoth)+(1|ringFath),data=dati,family=
>>>>> "compois"))
>>>>> summary(FitglmmTMB)
>>>>>
>>>>> # This lasts much more (3-4')
>>>>> system.time(Fitfitme<- fitme(fledges ~
>>>>> habitatF*(areaPatchFath+poligF01+StdLayingDate+ageFath1+ageMoth1)+(1|year)+(1|ringFath)+(1|ringMoth),data=dati,COMPoisson(),method
>>>>> = "ML"))
>>>>> summary(Fitfitme)
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> El 08/12/2016 a las 4:32, Ben Bolker escribi?:
>>>>>>   One reference that uses ordinal regression in a similar situation
>>>>>> (litter size of Florida panthers) is
>>>>>> http://link.springer.com/article/10.1007/s00442-011-2083-0 ("Does
>>>>>> genetic introgression improve female reproductive performance? A 
>>>>>> test on
>>>>>> the endangered Florida panther")
>>>>>>
>>>>>>  Not sure about the number-of-random-effects error: a reproducible
>>>>>> example would probably be needed (smaller is better!)
>>>>>>
>>>>>>  Ben Bolker
>>>>>>
>>>>>>
>>>>>> On 16-12-06 08:41 AM, Simone Santoro wrote:
>>>>>>> Dear all,
>>>>>>>
>>>>>>> I am trying to find an appropriate GLMM (with temporal and 
>>>>>>> individual
>>>>>>> crossed random effects) to model underdispersed count data (clutch
>>>>>>> size). I have found several possible ways of doing that. A good
>>>>>>> distribution for data like this would seem to be the
>>>>>>> Conway-Maxwell-Poisson but I have not found a way of using it 
>>>>>>> within a
>>>>>>> GLMM in R (I have asked here
>>>>>>> <http://stats.stackexchange.com/questions/249738/how-to-define-the-nu-parameter-of-conway-maxwell-poisson-in-spamm-package> 
>>>>>>>
>>>>>>> and here
>>>>>>> <http://stats.stackexchange.com/questions/249798/conway-maxwell-poisson-with-crossed-random-effects-in-r>).
>>>>>>> I have seen that Ben Bolker suggested (here
>>>>>>> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021945.html>and 
>>>>>>>
>>>>>>> here
>>>>>>> <http://stats.stackexchange.com/questions/92156/how-to-handle-underdispersion-in-glmm-binomial-outcome-variable>) 
>>>>>>>
>>>>>>> to use an ordinal model in cases like this(e.g. _ordinal:clmm_). 
>>>>>>> I have
>>>>>>> tried this solution and the results I obtain makes (biological) 
>>>>>>> sense to
>>>>>>> me. However, I wonder why but I cannot put all the three crossed 
>>>>>>> random
>>>>>>> effects I have in the clmm model (_Error: no. random effects 
>>>>>>> (=1254) >=
>>>>>>> no. observations (=854)_) whereas it is not a problem for the glmer
>>>>>>> model (the no. of levels of each single random effect does not 
>>>>>>> exceed 854)*.
>>>>>>> Beyond that, and that's what I would like to ask you, *I cannot 
>>>>>>> find a
>>>>>>> reference to justify I used the ordinal model* to deal with
>>>>>>> underdispersed count data (referee will ask it for sure).
>>>>>>> Best,
>>>>>>>
>>>>>>> Simone
>>>>>>>
>>>>>>> * FMglmer<- glmer(fledges ~ habitatF * (areaPatchFath + poligF01 +
>>>>>>> StdLayingDate + ageFath1 + ageMoth1) + (1|year) + (1|ringMoth) +
>>>>>>> (1|ringFath), data = datiDRS)
>>>>>>>    FMclmm<- glmer(as.factor(fledges)~ habitatF * (areaPatchFath +
>>>>>>> poligF01 + StdLayingDate + ageFath1 + ageMoth1) + (1|year) +
>>>>>>> (1|ringMoth) + (1|ringFath), data = datiDRS)
>>>>>>>
>>>>>>>
>>>>>>> [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>
>>>>> -- 
>>>>> Simone Santoro
>>>>> PhD
>>>>> Department of Ethology and Biodiversity Conservation
>>>>> Do?ana Biological Station
>>>>> Calle Am?rico Vespucio s/n
>>>>> 41092 Seville - Spain
>>>>> Phone no. +34 954 466 700 (ext. 1213)
>>>>> http://www.researchgate.net/profile/Simone_Santoro
>>>>> http://orcid.org/0000-0003-0986-3278
>>>>
>>>
>>> -- 
>>> Simone Santoro
>>> PhD
>>> Department of Ethology and Biodiversity Conservation
>>> Do?ana Biological Station
>>> Calle Am?rico Vespucio s/n
>>> 41092 Seville - Spain
>>> Phone no. +34 954 466 700 (ext. 1213)
>>> http://www.researchgate.net/profile/Simone_Santoro
>>> http://orcid.org/0000-0003-0986-3278
>>>
>

-- 
Simone Santoro
PhD
Dept. Molecular Biology and Biochemical Engineering
University Pablo de Olavide, Sevilla, Spain
ssantoro at upo.es
&
Dept. of Ethology and Biodiversity Conservation
Do?ana Biological Station
Calle Am?rico Vespucio s/n
41092 Seville - Spain
Phone no. +34 954 466 700 (ext. 1213)
http://www.researchgate.net/profile/Simone_Santoro
http://orcid.org/0000-0003-0986-3278


	[[alternative HTML version deleted]]


From wstyler at umich.edu  Wed Feb  1 17:20:01 2017
From: wstyler at umich.edu (Will Styler)
Date: Wed, 1 Feb 2017 11:20:01 -0500
Subject: [R-sig-ME] MCMCglmm Predict failing with "NA/NaN/Inf in foreign
 function call" for binary responses
Message-ID: <5E607003-B114-4D63-9F55-E499F7426043@umich.edu>

Hello,

After successfully fitting my models, I've been struggling to get predicted curves for illustration.  I'm working with binary data, with b-splines, and some random effects, and any time that I use the predict function in MCMCglmm 2.24, it returns the below error:

> Error in MCMCglmm(fixed = object$Fixed$formula, random = object$Random$formula, : NA/NaN/Inf in foreign function call (arg 3)

Although my model is rather more complex, here's a toy example returning the same issue during the "predict" call.

Do you have any advice on how to proceed?  Or, if I'm barking up the wrong tree, is there an easier approach to getting the model's predictions for a given set of conditions which I can graph?

Thanks,

Will

-----------------
Will Styler
Post-Doctoral Research Fellow
University of Michigan Department of Linguistics
http://savethevowels.org/will

> library(MCMCglmm)
> 
> set.seed(123)
> 
> dat <- data.frame(x = rnorm(100), y = sample(c(0,1)),z=as.factor(seq(1:2)),r1=as.factor(seq(1:20)))
> 
> prior = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V =1,n = 1)))
> 
> fit <- MCMCglmm(
> 
>     fixed = y ~ bs(x)*z,
>     
>     random =~r1,
> 
>     rcov = ~ units,
> 
>     data = dat,
> 
>     family = "threshold",
> 
>     pr = TRUE, pl = TRUE,
>     
>     prior=prior,
> 
>     saveX = TRUE,  saveZ = TRUE,
> 
>     nitt = 1.3e+4, thin = 10, burnin = 3e+3
> 
> )
> 
> 
> pred_grid <- data.frame(x = seq(-1, 1, length.out = 30),y=0,z=factor(seq(1:2)),r1="1")
> 
> predict(fit, newdata = pred_grid)


From thierry.onkelinx at inbo.be  Thu Feb  2 10:12:57 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 2 Feb 2017 10:12:57 +0100
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <1485975676.1574.16.camel@gmail.com>
References: <1485618209.1531.29.camel@gmail.com>
	<CAJuCY5w59JT9tCQZWUX1Q0cvp+i3J1RRyCvN7PhG_uAt9WYd0Q@mail.gmail.com>
	<1485975676.1574.16.camel@gmail.com>
Message-ID: <CAJuCY5wb+zfqisAe2T6_3OW-n+Ni9X4A_f7xpag=B5MJiBd6_A@mail.gmail.com>

Dear Claudio,

It looks like you have only one observation (of each trait) per individual.
That is not sufficient to fit (0 + trait | individual). Hence the error
message.

Using (1 | individuals) implies that each individual has a effect which is
common for all traits. Whether that is a relevant assumption depends on
your experiment. Tip: write the model as an equation for each trait. Then
see if the random intercept for individual makes sense.

I'm not proficient with MCMCglmm. So I can help you with that.

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-02-01 20:01 GMT+01:00 Claudio <oppela at gmail.com>:

> Dear Thierry,
> thanks a lot, it is exactly the kind of suggestion I was looking for!
> However, when using (0 + traits|individuals) for the random effect of
> individuals I got the message:
> "Errore: number of observations (=1431) <= number of random effects
> (=1431) for term (0 + traits | individuals); the random-effects
> parameters and the residual variance (or scale parameter) are probably
> unidentifiable"
> The models work when I use for the individual part (1|individuals).
>
> A second further question: in order to include in the model a
> continuous fixed covariate, am I doing the right thing when scripting:
>
> mumo2 <- lmer(value~0 + traits + traits:species + traits:covariate (0 +
> traits|species:populations) + (1|individuals), mdata, REML=FALSE)
>
> About cbind and MCMCglmm, below there is an example which causes the
> message:
> "Error in `[<-.data.frame`(`*tmp*`, , response.names, value = c(1, 2,
> 3,  : missing values are not allowed in subscripted assignments of data
> frames"
>
> a = c(1, 2, 3, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 5, 5, 4, 5, 7,
> 8, 9, 4, 1)
> b = c(8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 1, 2, 3, 5, 5, 7, 4, 1, 2, 3, 1,
> 2, 3, 6, 6)
> d = c(8, 9, 4, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 2, 3, 1, 2, 3,
> 5, 5, 7, 6)
> s = c("m", "m", "f", "f", "m", "m", "m", "f", "m", "f", "f", "f", "m",
> "f", "f", "f", "m", "m", "m", "m", "m", "f", "m", "f", "f", "f")
> df = data.frame(a, b, d, s)
>
> y<-cbind(a, b, d)
> prior <- list(R = list(V = 1, nu = 0.002))
> m <- MCMCglmm(y ~ s, family = "gaussian" , data = df, prior = prior,
> verbose = FALSE, pl = TRUE)
> summary(m)
>
> all the best (and thanks again)
> Claudio
>
> Il giorno lun, 30/01/2017 alle 16.02 +0100, Thierry Onkelinx ha
> scritto:
> > Dear Claudio,
> >
> > I this you need to add the interaction with traits to all the fixed
> > and random effects. Otherwise you assume that these have the same
> > effect for each trait. Note that 0 + traits is identical to traits -
> > 1.
> >
> > mumo1 <- lmer(value~0 + traits + traits:species + (0 +
> > traits|species:populations) + (0 + traits|individuals), mdata,
> > REML=FALSE)
> >
> > Your second question needs a reproducible example.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for
> > Nature and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> > Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given
> > body of data. ~ John Tukey
> >
> > 2017-01-28 16:43 GMT+01:00 Claudio <oppela at gmail.com>:
> > > Hi all.
> > > I collected six body features (bf1-bf6)from three populations of a
> > > salamander and from two populations of another sister species of
> > > salamander.
> > > I would evaluate how the species (fixed) and population belonging
> > > (random) affect the body features, by comparing models built with
> > > lme4.
> > > For some models, I also want to include bf6 as covariate. Thus, in
> > > case
> > > of univariate analyses, some models, for example, could be:
> > > mo1<-lmer(bf1~species+(1|species:population), data, REML=FALSE)
> > > mo2<-lmer(bf1~species+bf6+(1|species:population), data, REML=FALSE)
> > >
> > > However, I want to fit multivariate models, and my post is about
> > > this.
> > > First, I melted the data:
> > > mdata<-melt(data, id.vars = c("species", "population", "bf6"),
> > > measure.vars = c("bf1", "bf2","bf3","bf4","bf5"), variable.name =
> > > "traits)
> > >
> > > Now the question.
> > > 1) Are the multivariate versions of the models mo1 and mo2 above
> > > mumo1<-lmer(value~traits -1 + species + (1|species:populations) +
> > > (1|individuals), mdata, REML=FALSE)
> > > mumo1<-lmer(value~traits -1 + species + bf6 +
> > > (1|species:populations) +
> > > (1|individuals), mdata, REML=FALSE)
> > >
> > > A secondary question, which in case I will move to a new post:
> > > it seemed to me that building multivariate models with MCMCglmm is
> > > easier. However, cbind did not work, even without missing values:
> > > to
> > > your knowledge, is there any issue?
> > >
> > > thanks in advance
> > > Claudio
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Thu Feb  2 10:52:00 2017
From: paul.debes at utu.fi (Paul Debes)
Date: Thu, 02 Feb 2017 11:52:00 +0200
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <CAJuCY5wb+zfqisAe2T6_3OW-n+Ni9X4A_f7xpag=B5MJiBd6_A@mail.gmail.com>
References: <1485618209.1531.29.camel@gmail.com>
	<CAJuCY5w59JT9tCQZWUX1Q0cvp+i3J1RRyCvN7PhG_uAt9WYd0Q@mail.gmail.com>
	<1485975676.1574.16.camel@gmail.com>
	<CAJuCY5wb+zfqisAe2T6_3OW-n+Ni9X4A_f7xpag=B5MJiBd6_A@mail.gmail.com>
Message-ID: <op.yu01oyaqsgx3xe@armadillo50>

Hi Claudio

to make the model work in MCMCglmm, you need to explicitly specify the  
interaction for each trait by adding "trait". This specification extends  
to the dimensions of the prior(s) and distribution(s). If you wish to  
specify covariances between traits (here for the residuals), your model  
could be something like:

prior <- list(R = list(V = diag(3), nu = rep(0.002,3)))

m <- MCMCglmm(cbind(a,b,d) ~ -1 + trait*s,
	rcov = ~us(trait):units,
	family = rep("gaussian",3),
	data = df,
	prior = prior,
	verbose = FALSE,
	pl = TRUE)

summary(m)

Best,
Paul



  On Thu, 02 Feb 2017 11:12:57 +0200, Thierry Onkelinx  
<thierry.onkelinx at inbo.be> wrote:

> Dear Claudio,
>
> It looks like you have only one observation (of each trait) per  
> individual.
> That is not sufficient to fit (0 + trait | individual). Hence the error
> message.
>
> Using (1 | individuals) implies that each individual has a effect which  
> is
> common for all traits. Whether that is a relevant assumption depends on
> your experiment. Tip: write the model as an equation for each trait. Then
> see if the random intercept for individual makes sense.
>
> I'm not proficient with MCMCglmm. So I can help you with that.
>
> Best regards,
>
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature  
> and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to  
> say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of  
> data.
> ~ John Tukey
>
> 2017-02-01 20:01 GMT+01:00 Claudio <oppela at gmail.com>:
>
>> Dear Thierry,
>> thanks a lot, it is exactly the kind of suggestion I was looking for!
>> However, when using (0 + traits|individuals) for the random effect of
>> individuals I got the message:
>> "Errore: number of observations (=1431) <= number of random effects
>> (=1431) for term (0 + traits | individuals); the random-effects
>> parameters and the residual variance (or scale parameter) are probably
>> unidentifiable"
>> The models work when I use for the individual part (1|individuals).
>>
>> A second further question: in order to include in the model a
>> continuous fixed covariate, am I doing the right thing when scripting:
>>
>> mumo2 <- lmer(value~0 + traits + traits:species + traits:covariate (0 +
>> traits|species:populations) + (1|individuals), mdata, REML=FALSE)
>>
>> About cbind and MCMCglmm, below there is an example which causes the
>> message:
>> "Error in `[<-.data.frame`(`*tmp*`, , response.names, value = c(1, 2,
>> 3,  : missing values are not allowed in subscripted assignments of data
>> frames"
>>
>> a = c(1, 2, 3, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 5, 5, 4, 5, 7,
>> 8, 9, 4, 1)
>> b = c(8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 1, 2, 3, 5, 5, 7, 4, 1, 2, 3, 1,
>> 2, 3, 6, 6)
>> d = c(8, 9, 4, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 2, 3, 1, 2, 3,
>> 5, 5, 7, 6)
>> s = c("m", "m", "f", "f", "m", "m", "m", "f", "m", "f", "f", "f", "m",
>> "f", "f", "f", "m", "m", "m", "m", "m", "f", "m", "f", "f", "f")
>> df = data.frame(a, b, d, s)
>>
>> y<-cbind(a, b, d)
>> prior <- list(R = list(V = 1, nu = 0.002))
>> m <- MCMCglmm(y ~ s, family = "gaussian" , data = df, prior = prior,
>> verbose = FALSE, pl = TRUE)
>> summary(m)
>>
>> all the best (and thanks again)
>> Claudio
>>
>> Il giorno lun, 30/01/2017 alle 16.02 +0100, Thierry Onkelinx ha
>> scritto:
>> > Dear Claudio,
>> >
>> > I this you need to add the interaction with traits to all the fixed
>> > and random effects. Otherwise you assume that these have the same
>> > effect for each trait. Note that 0 + traits is identical to traits -
>> > 1.
>> >
>> > mumo1 <- lmer(value~0 + traits + traits:species + (0 +
>> > traits|species:populations) + (0 + traits|individuals), mdata,
>> > REML=FALSE)
>> >
>> > Your second question needs a reproducible example.
>> >
>> > Best regards,
>> >
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek / Research Institute for
>> > Nature and Forest
>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>> > Assurance
>> > Kliniekstraat 25
>> > 1070 Anderlecht
>> > Belgium
>> >
>> > To call in the statistician after the experiment is done may be no
>> > more than asking him to perform a post-mortem examination: he may be
>> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > The plural of anecdote is not data. ~ Roger Brinner
>> > The combination of some data and an aching desire for an answer does
>> > not ensure that a reasonable answer can be extracted from a given
>> > body of data. ~ John Tukey
>> >
>> > 2017-01-28 16:43 GMT+01:00 Claudio <oppela at gmail.com>:
>> > > Hi all.
>> > > I collected six body features (bf1-bf6)from three populations of a
>> > > salamander and from two populations of another sister species of
>> > > salamander.
>> > > I would evaluate how the species (fixed) and population belonging
>> > > (random) affect the body features, by comparing models built with
>> > > lme4.
>> > > For some models, I also want to include bf6 as covariate. Thus, in
>> > > case
>> > > of univariate analyses, some models, for example, could be:
>> > > mo1<-lmer(bf1~species+(1|species:population), data, REML=FALSE)
>> > > mo2<-lmer(bf1~species+bf6+(1|species:population), data, REML=FALSE)
>> > >
>> > > However, I want to fit multivariate models, and my post is about
>> > > this.
>> > > First, I melted the data:
>> > > mdata<-melt(data, id.vars = c("species", "population", "bf6"),
>> > > measure.vars = c("bf1", "bf2","bf3","bf4","bf5"), variable.name =
>> > > "traits)
>> > >
>> > > Now the question.
>> > > 1) Are the multivariate versions of the models mo1 and mo2 above
>> > > mumo1<-lmer(value~traits -1 + species + (1|species:populations) +
>> > > (1|individuals), mdata, REML=FALSE)
>> > > mumo1<-lmer(value~traits -1 + species + bf6 +
>> > > (1|species:populations) +
>> > > (1|individuals), mdata, REML=FALSE)
>> > >
>> > > A secondary question, which in case I will move to a new post:
>> > > it seemed to me that building multivariate models with MCMCglmm is
>> > > easier. However, cbind did not work, even without missing values:
>> > > to
>> > > your knowledge, is there any issue?
>> > >
>> > > thanks in advance
>> > > Claudio
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul V. Debes
Postdoctoral researcher

Email: paul.debes at utu.fi
Phone: +358 4659 11055


From kn.journal.news at gmail.com  Thu Feb  2 11:04:40 2017
From: kn.journal.news at gmail.com (Koen Neijenhuijs)
Date: Thu, 2 Feb 2017 11:04:40 +0100
Subject: [R-sig-ME] brms: Multivariate LMEM with systematic missing data
Message-ID: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>

Hello all,

I was wondering what would happen with a multivariate LMEM when there is
systematic missing data. I ran a crude simulation to check this situation:

Group A: Has data on Dependent variable 1 (dep1), 2 (dep2), and 3 (dep3)
Group B: Has data on dep1 and dep3
Group C: Has data on dep2 and dep3

All data is measured three times (I am disregarding the effect of time for
simplicity's sake).

The aim is to compare group A on the data it shares with group B and group
C. I created this data and ran a multivariate brms model on it. I did not
provide priors, as such, uninformative priors will be used. Code:

set.seed(103)
# Data structure:
# id | group (A/B/C) | dep1 (mean(SD), A: 10(5), B: 15(5), C: NA) | dep2
(A: 20(5), B: NA, C: 40(5)), dep3 (A: 30(5), B: 40(5), C: 30(5))

n_indiv <- 999
n_per_indiv <- 3
n_tot <- n_indiv * n_per_indiv
id <- gl(n_indiv, n_per_indiv)  ## generate identifier columns

dat <- data.frame(id=id,
                  group=rep(c("A", "B", "C"),each=n_tot/3),
                  meas=rep(c(1, 2, 3), times=n_tot/n_per_indiv),
                  dep1=c(rnorm(n_tot/3,10,5), rnorm(n_tot/3,15,5),
rep("NA", times=n_tot/3)),
                  dep2=c(rnorm(n_tot/3,20,5), rep("NA", times=n_tot/3),
rnorm(n_tot/3,40,5)),
                  dep3=c(rnorm(n_tot/3,30,5), rnorm(n_tot/3,40,5),
rnorm(n_tot/3,30,5)))

ncores <- detectCores() -1

m1_brms <- brm(cbind(dep1, dep2, dep3) ~ group + (1+meas|id), data=dat,
family="gaussian",
               n.warmup=500, n.iter = 1500, n.chains=5, cores=ncores)

sum_m1_brms <- summary(m1_brms)

Everything converged nicely (trace plots are looking good, Rhat is fine I
believe). The output of the summary:

 Family: gaussian (identity)
Formula: cbind(dep1, dep2, dep3) ~ group + (1 + meas | id)
   Data: dat (Number of observations: 2997)
Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
         total post-warmup samples = 5000
   WAIC: Not computed

Group-Level Effects:
~id (Number of levels: 999)
                              Estimate Est.Error l-95% CI u-95% CI
Eff.Sample Rhat
sd(dep1_Intercept)               45.29     37.05     2.16   145.59
402 1.00
sd(dep1_meas)                    26.92     20.37     1.30    78.80
226 1.03
sd(dep2_Intercept)               32.91     28.47     0.97   111.39
184 1.03
sd(dep2_meas)                    18.89     13.85     0.75    54.06
159 1.02
sd(dep3_Intercept)                0.54      0.50     0.02     2.08
155 1.05
sd(dep3_meas)                     0.25      0.23     0.01     0.95
93 1.05
cor(dep1_Intercept,dep1_meas)    -0.36      0.57    -0.99     0.89
338 1.02
cor(dep2_Intercept,dep2_meas)    -0.40      0.56    -0.98     0.88
241 1.01
cor(dep3_Intercept,dep3_meas)    -0.36      0.59    -0.99     0.92
386 1.01

Population-Level Effects:
               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
dep1_Intercept  1058.94     14.62  1029.65  1087.34       5000 1.00
dep2_Intercept   523.02      8.40   506.45   540.22       2150 1.00
dep3_Intercept    30.25      0.16    29.94    30.56       5000 1.00
dep1_groupB     -118.01     20.82  -160.15   -77.53       5000 1.00
dep1_groupC      940.46     20.83   900.16   982.28       5000 1.00
dep2_groupB     1476.62     12.24  1452.73  1500.95        661 1.01
dep2_groupC      953.48     11.75   930.22   976.84       5000 1.00
dep3_groupB        9.52      0.22     9.08     9.95       5000 1.00
dep3_groupC       -0.29      0.22    -0.73     0.15       5000 1.00

Family Specific Parameters:
                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma(dep1)         465.54      6.59   452.02   478.22        755 1.00
sigma(dep2)         262.63      3.93   254.64   270.00        712 1.01
sigma(dep3)           4.98      0.07     4.84     5.12        699 1.01
rescor(dep1,dep2)    -0.02      0.02    -0.05     0.02       5000 1.00
rescor(dep1,dep3)     0.00      0.02    -0.03     0.04       5000 1.01
rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000 1.00

The effects that are in the data, seem to be estimated, but the directions
and magnitudes of the estimates seem all over the place. In the data, group
A was always smaller or equal (in the case of dep3_groupC). As you can see,
the population estimate for dep1_groupB is in the wrong direction, and the
estimate for dep2_groupC is huge. The only estimates that seem non-inflated
and correct are those for dep3, which had data on all three groups.

Would it be safe to assume that systematic missing data on one group,
inflates the estimates between the remaining groups? I would love to hear
your thoughts!

One further question. I tried to perform the same multivariate analysis
using MCMCglmm, but I find the syntax of the random and rcov parameters
hard to set, and the output even harder to interpret. I would love to get
some feedback on how to perform a similar analysis using the MCMCglmm
function. Code:

m1 <- MCMCglmm(cbind(dep1, dep2, dep3) ~ group-1, random = ~us(1+meas):id,
               rcov = ~us(trait):units, data = dat, family = c("gaussian",
"gaussian", "gaussian"),
                    verbose = FALSE)

summary(m1)

Output:

 Iterations = 3001:12991
 Thinning interval  = 10
 Sample size  = 1000

 DIC: 119465.7

 G-structure:  ~us(1 + meas):id

                           post.mean   l-95% CI u-95% CI eff.samp
(Intercept):(Intercept).id    0.5868  0.0010440  2.54542    6.784
meas:(Intercept).id          -0.3008 -1.2656335  0.01044    6.621
(Intercept):meas.id          -0.3008 -1.2656335  0.01044    6.621
meas:meas.id                  0.1716  0.0004239  0.65286    6.936

 R-structure:  ~us(trait):units

                           post.mean   l-95% CI   u-95% CI eff.samp
traitdep1:traitdep1.units 2132866.20 2027876.02 2239057.50    911.5
traitdep2:traitdep1.units 1703387.51 1615965.82 1803474.41   1000.0
traitdep3:traitdep1.units   -1405.09   -2700.25      60.61    150.3
traitdep1:traitdep2.units 1703387.51 1615965.82 1803474.41   1000.0
traitdep2:traitdep2.units 2129068.98 2023232.02 2239145.62   1283.7
traitdep3:traitdep2.units   -1685.89   -3264.50    -184.62    136.2
traitdep1:traitdep3.units   -1405.09   -2700.25      60.61    150.3
traitdep2:traitdep3.units   -1685.89   -3264.50    -184.62    136.2
traitdep3:traitdep3.units      26.57      23.99      29.55    188.8

 Location effects: cbind(dep1, dep2, dep3) ~ group - 1

       post.mean l-95% CI u-95% CI eff.samp  pMCMC
groupA     30.69    30.13    31.37    226.0 <0.001 ***
groupB     41.29    39.97    42.75    122.0 <0.001 ***
groupC     31.20    29.89    32.50    151.8 <0.001 ***

Thanks in advance!

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Feb  2 12:45:38 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 2 Feb 2017 11:45:38 +0000
Subject: [R-sig-ME] brms: Multivariate LMEM with systematic missing data
In-Reply-To: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>
References: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>
Message-ID: <716ca0f3-03e0-f77c-222e-d826a004e422@ed.ac.uk>

Hi,

I'm just about to board a plane, so briefly, the equivalent MCMCglmm 
code is:

m1 <- MCMCglmm(cbind(dep1, dep2, dep3) ~ trait-1+trait:group, random = ~us(at.level(trait,1):(1+meas)):id+us(at.level(trait,2):(1+meas)):id+us(at.level(trait,3):(1+meas)):id,
                rcov = ~us(trait):units, data = dat, family = c("gaussian",
"gaussian", "gaussian"),
                     verbose = FALSE)
  
Cheers,

Jarrod


On 02/02/2017 10:04, Koen Neijenhuijs wrote:
> m1 <- MCMCglmm(cbind(dep1, dep2, dep3) ~ group-1, random = ~us(1+meas):id,
>                 rcov = ~us(trait):units, data = dat, family = c("gaussian",
> "gaussian", "gaussian"),
>                      verbose = FALSE)


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From paul.buerkner at gmail.com  Thu Feb  2 20:41:51 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Thu, 2 Feb 2017 20:41:51 +0100
Subject: [R-sig-ME] brms: Multivariate LMEM with systematic missing data
In-Reply-To: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>
References: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>
Message-ID: <CAGoSky-tSjgkNOX_ADi0WUrOe-UxEZ2rX5BQDe6YrWn2bZpyhw@mail.gmail.com>

Could it be that this is partly because you did not include "meas" as a
fixed effect but only as a random effect? Without a corresponding fixed
effect, random effects are centered around zero, which may not be what you
want.

2017-02-02 11:04 GMT+01:00 Koen Neijenhuijs <kn.journal.news at gmail.com>:

> Hello all,
>
> I was wondering what would happen with a multivariate LMEM when there is
> systematic missing data. I ran a crude simulation to check this situation:
>
> Group A: Has data on Dependent variable 1 (dep1), 2 (dep2), and 3 (dep3)
> Group B: Has data on dep1 and dep3
> Group C: Has data on dep2 and dep3
>
> All data is measured three times (I am disregarding the effect of time for
> simplicity's sake).
>
> The aim is to compare group A on the data it shares with group B and group
> C. I created this data and ran a multivariate brms model on it. I did not
> provide priors, as such, uninformative priors will be used. Code:
>
> set.seed(103)
> # Data structure:
> # id | group (A/B/C) | dep1 (mean(SD), A: 10(5), B: 15(5), C: NA) | dep2
> (A: 20(5), B: NA, C: 40(5)), dep3 (A: 30(5), B: 40(5), C: 30(5))
>
> n_indiv <- 999
> n_per_indiv <- 3
> n_tot <- n_indiv * n_per_indiv
> id <- gl(n_indiv, n_per_indiv)  ## generate identifier columns
>
> dat <- data.frame(id=id,
>                   group=rep(c("A", "B", "C"),each=n_tot/3),
>                   meas=rep(c(1, 2, 3), times=n_tot/n_per_indiv),
>                   dep1=c(rnorm(n_tot/3,10,5), rnorm(n_tot/3,15,5),
> rep("NA", times=n_tot/3)),
>                   dep2=c(rnorm(n_tot/3,20,5), rep("NA", times=n_tot/3),
> rnorm(n_tot/3,40,5)),
>                   dep3=c(rnorm(n_tot/3,30,5), rnorm(n_tot/3,40,5),
> rnorm(n_tot/3,30,5)))
>
> ncores <- detectCores() -1
>
> m1_brms <- brm(cbind(dep1, dep2, dep3) ~ group + (1+meas|id), data=dat,
> family="gaussian",
>                n.warmup=500, n.iter = 1500, n.chains=5, cores=ncores)
>
> sum_m1_brms <- summary(m1_brms)
>
> Everything converged nicely (trace plots are looking good, Rhat is fine I
> believe). The output of the summary:
>
>  Family: gaussian (identity)
> Formula: cbind(dep1, dep2, dep3) ~ group + (1 + meas | id)
>    Data: dat (Number of observations: 2997)
> Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
>          total post-warmup samples = 5000
>    WAIC: Not computed
>
> Group-Level Effects:
> ~id (Number of levels: 999)
>                               Estimate Est.Error l-95% CI u-95% CI
> Eff.Sample Rhat
> sd(dep1_Intercept)               45.29     37.05     2.16   145.59
> 402 1.00
> sd(dep1_meas)                    26.92     20.37     1.30    78.80
> 226 1.03
> sd(dep2_Intercept)               32.91     28.47     0.97   111.39
> 184 1.03
> sd(dep2_meas)                    18.89     13.85     0.75    54.06
> 159 1.02
> sd(dep3_Intercept)                0.54      0.50     0.02     2.08
> 155 1.05
> sd(dep3_meas)                     0.25      0.23     0.01     0.95
> 93 1.05
> cor(dep1_Intercept,dep1_meas)    -0.36      0.57    -0.99     0.89
> 338 1.02
> cor(dep2_Intercept,dep2_meas)    -0.40      0.56    -0.98     0.88
> 241 1.01
> cor(dep3_Intercept,dep3_meas)    -0.36      0.59    -0.99     0.92
> 386 1.01
>
> Population-Level Effects:
>                Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> dep1_Intercept  1058.94     14.62  1029.65  1087.34       5000 1.00
> dep2_Intercept   523.02      8.40   506.45   540.22       2150 1.00
> dep3_Intercept    30.25      0.16    29.94    30.56       5000 1.00
> dep1_groupB     -118.01     20.82  -160.15   -77.53       5000 1.00
> dep1_groupC      940.46     20.83   900.16   982.28       5000 1.00
> dep2_groupB     1476.62     12.24  1452.73  1500.95        661 1.01
> dep2_groupC      953.48     11.75   930.22   976.84       5000 1.00
> dep3_groupB        9.52      0.22     9.08     9.95       5000 1.00
> dep3_groupC       -0.29      0.22    -0.73     0.15       5000 1.00
>
> Family Specific Parameters:
>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sigma(dep1)         465.54      6.59   452.02   478.22        755 1.00
> sigma(dep2)         262.63      3.93   254.64   270.00        712 1.01
> sigma(dep3)           4.98      0.07     4.84     5.12        699 1.01
> rescor(dep1,dep2)    -0.02      0.02    -0.05     0.02       5000 1.00
> rescor(dep1,dep3)     0.00      0.02    -0.03     0.04       5000 1.01
> rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000 1.00
>
> The effects that are in the data, seem to be estimated, but the directions
> and magnitudes of the estimates seem all over the place. In the data, group
> A was always smaller or equal (in the case of dep3_groupC). As you can see,
> the population estimate for dep1_groupB is in the wrong direction, and the
> estimate for dep2_groupC is huge. The only estimates that seem non-inflated
> and correct are those for dep3, which had data on all three groups.
>
> Would it be safe to assume that systematic missing data on one group,
> inflates the estimates between the remaining groups? I would love to hear
> your thoughts!
>
> One further question. I tried to perform the same multivariate analysis
> using MCMCglmm, but I find the syntax of the random and rcov parameters
> hard to set, and the output even harder to interpret. I would love to get
> some feedback on how to perform a similar analysis using the MCMCglmm
> function. Code:
>
> m1 <- MCMCglmm(cbind(dep1, dep2, dep3) ~ group-1, random = ~us(1+meas):id,
>                rcov = ~us(trait):units, data = dat, family = c("gaussian",
> "gaussian", "gaussian"),
>                     verbose = FALSE)
>
> summary(m1)
>
> Output:
>
>  Iterations = 3001:12991
>  Thinning interval  = 10
>  Sample size  = 1000
>
>  DIC: 119465.7
>
>  G-structure:  ~us(1 + meas):id
>
>                            post.mean   l-95% CI u-95% CI eff.samp
> (Intercept):(Intercept).id    0.5868  0.0010440  2.54542    6.784
> meas:(Intercept).id          -0.3008 -1.2656335  0.01044    6.621
> (Intercept):meas.id          -0.3008 -1.2656335  0.01044    6.621
> meas:meas.id                  0.1716  0.0004239  0.65286    6.936
>
>  R-structure:  ~us(trait):units
>
>                            post.mean   l-95% CI   u-95% CI eff.samp
> traitdep1:traitdep1.units 2132866.20 2027876.02 2239057.50    911.5
> traitdep2:traitdep1.units 1703387.51 1615965.82 1803474.41   1000.0
> traitdep3:traitdep1.units   -1405.09   -2700.25      60.61    150.3
> traitdep1:traitdep2.units 1703387.51 1615965.82 1803474.41   1000.0
> traitdep2:traitdep2.units 2129068.98 2023232.02 2239145.62   1283.7
> traitdep3:traitdep2.units   -1685.89   -3264.50    -184.62    136.2
> traitdep1:traitdep3.units   -1405.09   -2700.25      60.61    150.3
> traitdep2:traitdep3.units   -1685.89   -3264.50    -184.62    136.2
> traitdep3:traitdep3.units      26.57      23.99      29.55    188.8
>
>  Location effects: cbind(dep1, dep2, dep3) ~ group - 1
>
>        post.mean l-95% CI u-95% CI eff.samp  pMCMC
> groupA     30.69    30.13    31.37    226.0 <0.001 ***
> groupB     41.29    39.97    42.75    122.0 <0.001 ***
> groupC     31.20    29.89    32.50    151.8 <0.001 ***
>
> Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From joao.santiago at uni-tuebingen.de  Thu Feb  2 14:10:41 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Thu, 02 Feb 2017 14:10:41 +0100
Subject: [R-sig-ME] Modeling truncated counts with glmer
In-Reply-To: <CAJuCY5w69rPmE19aWKewA69J_Lzd8ROK=_WUZeGogzTiH8uoLg@mail.gmail.com>
References: <20170123084601.Horde.ls0WEicDws5CAvomXoyeSjD@webmail.uni-tuebingen.de>
	<CAJuCY5znseEwrASNwkzzN5C8rkpzebZnEAUEA-HDLG5PMe3iVA@mail.gmail.com>
	<20170123100147.Horde.QGfa6_Jsb7QdOvh6vL11Et2@webmail.uni-tuebingen.de>
	<CAJuCY5x1B3Kpr-z6xuPYMDFbBqspFr9yp-Mg1k6dGmBL4MWQUQ@mail.gmail.com>
	<20170201142256.Horde.7bTr3oe0RCzGJyE9aJfg2iW@webmail.uni-tuebingen.de>
	<CAJuCY5w69rPmE19aWKewA69J_Lzd8ROK=_WUZeGogzTiH8uoLg@mail.gmail.com>
Message-ID: <20170202141041.Horde.xE-q6Up-KrQvoy8j45H87dO@webmail.uni-tuebingen.de>

Dear Thierry,

Thank you, that makes sense now! I have been reading more on this and  
playing with the data to understand it better. Here are some final  
questions:

I've reduced the model to only include the abruf term to simplify things:

              Estimate Std. Error z value Pr(>|z|)
(Intercept)   -0.0865     0.1909 -0.4532   0.6504
I(abruf - 1)   1.3241     0.0505 26.2030   0.0000

the probability of answering correctly is given by the equation  
-0.0865 + 1.3241(abruf).


* When abruf is zero, the result is the probability of an average  
person, on trial 0, answering correctly.

So in this case that means odds of exp(-0.0865)=0.92 and a probability  
of plogis(-0.0865)=0.48 (which means on average 0.48*40= 19 correct  
pairs)


* for each subsequent trial the odds of answering correctly increase  
by exp(1.3241)=3.76 (almost 4x more likely to answer correctly  
relative to trial 0) or plogis(1.3241)= 79% increase.

This means our average joe, for example on the last trial (trial=2),  
will be -0.0865 + 1.3241*2=2.5617 or exp(2.5617)= 13x more likely to  
answer correctly than on trial zero. Which translates to  
plogis(2.5617) = 92% probability of success or 37 correct pairs.


* if I want to predict how well a person will do in this test after a  
first trial, I simply need to change the intercept? Let's imagine  
someone is not very good at this and only gets 25% of the pairs  
correctly on the first go. Her or his intercept is log(0.25/0.75) and  
on trial 2 the predicted correct number of word-pairs is:

log(0.25/0.75) + 1.3241*2 = 82% or 32 correct pairs.



Again thank you so much for your replies. If you ever come to this  
neck of the woods a free beer is in order!

Best,
J Santiago




Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Jo?o,
>
> The intercept is -0.07376 on the **logit** scale. That is 0.48 on the
> original scale. Use plogis(-0.07376) to transform from logit to original
> scale. Your interpretation of the intercept is correct.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-02-01 14:22 GMT+01:00 Jo?o C P Santiago <joao.santiago at uni-tuebingen.de
>> :
>
>> Thank you for your input! Only now did I go back to this model.
>>
>> I'm having some doubts about the meaning of the intercept from my binomial
>> model. Here's the complete output:
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>>  Family: binomial  ( logit )
>> Formula: cbind(correctPair, incorrectPair) ~ I(abruf - 1) * treatment +
>>     version + (1 | subjectNumber)
>>    Data: .
>>
>>      AIC      BIC   logLik deviance df.resid
>>    691.4    708.4   -339.7    679.4      119
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -3.2676 -0.7861 -0.0428  0.9417  2.7483
>>
>> Random effects:
>>  Groups        Name        Variance Std.Dev.
>>  subjectNumber (Intercept) 0.7135   0.8447
>> Number of obs: 125, groups:  subjectNumber, 21
>>
>> Fixed effects:
>>                                   Estimate Std. Error z value Pr(>|z|)
>> (Intercept)                       -0.07376    0.20096  -0.367    0.714
>> I(abruf - 1)                       1.30891    0.06904  18.958   <2e-16 ***
>> treatmentStimulation               0.06116    0.09961   0.614    0.539
>> versionB                          -0.08709    0.07222  -1.206    0.228
>> I(abruf - 1):treatmentStimulation  0.03342    0.09727   0.344    0.731
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>             (Intr) I(b-1) trtmnS versnB
>> I(abruf-1)  -0.235
>> trtmntStmlt -0.254  0.482
>> versionB    -0.189 -0.029  0.037
>> I(-1):trtmS  0.164 -0.681 -0.689  0.030
>>
>>
>>
>> abruf has values c(1,2,3) so by -1 it starts at a more meaningful point.
>>
>> My question is: is the intercept the ratio of success/no success on abruf
>> 0, treatment control and version A? If so why is it statistically speaking
>> 1 on the log scale? The number of successes increases from abruf 1 to 3 (as
>> seen by the estimate of the model and plots).
>>
>> It's the first time I'm dealing with such complex models. Thank you for
>> your patience and time.
>>
>> Best
>> J Santiago
>>
>>
>>
>> Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>> It looks like you participants performed a known number of trials which
>>> resulted in either success or failure. The binomial distribution models
>>> exactly that. The model fit would be the probability of success.
>>>
>>> Once you have the relevant distribution, you can set the relevant
>>> covariates. Which and in which form (linear, polynomial, factor) depends
>>> on
>>> the hypotheses which are relevant for your experiment.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> 2017-01-23 10:01 GMT+01:00 Jo?o C P Santiago <
>>> joao.santiago at uni-tuebingen.de
>>>
>>>> :
>>>>
>>>
>>> Thank you! Could you be a bit more specific as to why? I will most likely
>>>> encounter similar data in the future and I want to know how to think
>>>> about
>>>> it.
>>>>
>>>> Fitting the model with abruf as a factor resulted in a better fit, but
>>>> that answers a different question right? Namely how different is the
>>>> intercept at a timepoint in comparison with the main level (abruf 0 in my
>>>> code)?
>>>>
>>>> Best
>>>>
>>>>
>>>> Quoting Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>>>
>>>> Dear Jo?o,
>>>>
>>>>>
>>>>> A binomial distribution seems more relevant to me.
>>>>>
>>>>> glmer(cbind(correctPair, incorrectPair) ~ I((abruf - 1)^2) * treatment +
>>>>> (1|subjectNumber), data=data, family = binomial)
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>>> and
>>>>> Forest
>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> Kliniekstraat 25
>>>>> 1070 Anderlecht
>>>>> Belgium
>>>>>
>>>>> To call in the statistician after the experiment is done may be no more
>>>>> than asking him to perform a post-mortem examination: he may be able to
>>>>> say
>>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does not
>>>>> ensure that a reasonable answer can be extracted from a given body of
>>>>> data.
>>>>> ~ John Tukey
>>>>>
>>>>> 2017-01-23 8:46 GMT+01:00 Jo?o C P Santiago <
>>>>> joao.santiago at uni-tuebingen.de>
>>>>> :
>>>>>
>>>>> Hi,
>>>>>
>>>>>>
>>>>>> In my experiment 20 participants did a word-pairs learning task in two
>>>>>> conditions (repeated measures):
>>>>>> 40 pairs of nouns are presented on a monitor, each for 4s and with an
>>>>>> interval of 1s. The words of each pair were moderately semantically
>>>>>> related
>>>>>> (e.g., brain, consciousness and solution, problem). Two different word
>>>>>> lists were used for the subject?s two experimental conditions, with the
>>>>>> order of word lists balanced across subjects and conditions. The
>>>>>> subject
>>>>>> had unlimited time to recall the appropriate response word, and did
>>>>>> three
>>>>>> trials in succession for each list:
>>>>>>
>>>>>> Condition 1, List A > T1, T2, T3
>>>>>> Condition 2, List B > T1, T2, T3
>>>>>>
>>>>>> No feedback was given as to whether the remembered word was correct or
>>>>>> not.
>>>>>>
>>>>>> I've seen some people go at this with anova, others subtract the total
>>>>>> number of correct pairs in one condition from the other per subject and
>>>>>> run
>>>>>> a t-test. Since this is count data, a generalized linear model should
>>>>>> be
>>>>>> more appropriate, right?
>>>>>>
>>>>>> head(data)
>>>>>>   subjectNumber expDay      bmi treatment tones       hour abruf
>>>>>> correctPair incorrectPair
>>>>>>           <dbl>  <chr>    <dbl>    <fctr> <dbl>     <time> <dbl>
>>>>>>  <dbl>         <dbl>
>>>>>> 1             1     N2 22.53086   Control     0 27900 secs     1
>>>>>> 26            14
>>>>>> 2             1     N2 22.53086   Control     0 27900 secs     2
>>>>>> 40             0
>>>>>> 3             1     N2 22.53086   Control     0 27900 secs     3
>>>>>> 40             0
>>>>>> 4             2     N1 22.53086   Control     0 27900 secs     1
>>>>>> 22            18
>>>>>> 5             2     N1 22.53086   Control     0 27900 secs     2
>>>>>> 33             7
>>>>>> 6             2     N1 22.53086   Control     0 27900 secs     3
>>>>>> 36             4
>>>>>>
>>>>>>
>>>>>>
>>>>>> I fitted a model with glmer.nb(correctPair ~ I((abruf - 1)^2) *
>>>>>> treatment
>>>>>> + (1|subjectNumber), data=data). The residuals don't look so good to me
>>>>>> http://imgur.com/a/AJXGq and the model is fitting values above 40,
>>>>>> which
>>>>>> will never happen in real life (not sure if this is important).
>>>>>>
>>>>>> I'm interested in knowing if there is any difference between conditions
>>>>>> (are the values at timepoint (abruf) 1 different? do people remember
>>>>>> less
>>>>>> in one one condition than in the other (different number of pairs at
>>>>>> timepoint 3?)
>>>>>>
>>>>>>
>>>>>> If the direction I'm taking is completely wrong please let me know.
>>>>>>
>>>>>> Best,
>>>>>> Santiago
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Jo?o C. P. Santiago
>>>>>> Institute for Medical Psychology & Behavioral Neurobiology
>>>>>> Center of Integrative Neuroscience
>>>>>> University of Tuebingen
>>>>>> Otfried-Mueller-Str. 25
>>>>>> 72076 Tuebingen, Germany
>>>>>>
>>>>>> Phone: +49 7071 29 88981
>>>>>> Fax: +49 7071 29 25016
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>>
>>>>>
>>>>
>>>> --
>>>> Jo?o C. P. Santiago
>>>> Institute for Medical Psychology & Behavioral Neurobiology
>>>> Center of Integrative Neuroscience
>>>> University of Tuebingen
>>>> Otfried-Mueller-Str. 25
>>>> 72076 Tuebingen, Germany
>>>>
>>>> Phone: +49 7071 29 88981
>>>> Fax: +49 7071 29 25016
>>>>
>>>>
>>>>
>>
>>
>> --
>> Jo?o C. P. Santiago
>> Institute for Medical Psychology & Behavioral Neurobiology
>> Center of Integrative Neuroscience
>> University of Tuebingen
>> Otfried-Mueller-Str. 25
>> 72076 Tuebingen, Germany
>>
>> Phone: +49 7071 29 88981
>> Fax: +49 7071 29 25016
>>
>>



-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From kn.journal.news at gmail.com  Fri Feb  3 11:39:24 2017
From: kn.journal.news at gmail.com (Koen Neijenhuijs)
Date: Fri, 3 Feb 2017 11:39:24 +0100
Subject: [R-sig-ME] brms: Multivariate LMEM with systematic missing data
In-Reply-To: <CAGoSky-tSjgkNOX_ADi0WUrOe-UxEZ2rX5BQDe6YrWn2bZpyhw@mail.gmail.com>
References: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>
	<CAGoSky-tSjgkNOX_ADi0WUrOe-UxEZ2rX5BQDe6YrWn2bZpyhw@mail.gmail.com>
Message-ID: <CABL7txQ6UinetcHqWd8H0tt4gsirS2ThbN7FHpOENRvsGBzuug@mail.gmail.com>

Hi Paul and Jarrod,

@Paul: not including "meas" as a fixed effect was an error on my part. I
reran the model with it included (note, meas had no effect size in the
generated data). The output still shows the same kind of inflated
population estimates that I noted before:

 Family: gaussian (identity)
Formula: cbind(dep1, dep2, dep3) ~ group * meas + (1 + meas | id)
   Data: dat (Number of observations: 2997)
Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
         total post-warmup samples = 5000
   WAIC: Not computed

Group-Level Effects:
~id (Number of levels: 999)
                              Estimate Est.Error l-95% CI u-95% CI
Eff.Sample Rhat
sd(dep1_Intercept)               41.25     32.88     1.49   125.28
722 1.01
sd(dep1_meas)                    23.84     17.80     0.95    68.74
195 1.02
sd(dep2_Intercept)               28.35     21.61     0.81    81.16
643 1.00
sd(dep2_meas)                    15.10     10.70     0.78    40.85
280 1.01
sd(dep3_Intercept)                0.45      0.38     0.02     1.45
652 1.00
sd(dep3_meas)                     0.21      0.17     0.01     0.67
386 1.00
cor(dep1_Intercept,dep1_meas)    -0.31      0.56    -0.98     0.89
691 1.01
cor(dep2_Intercept,dep2_meas)    -0.31      0.56    -0.98     0.87
583 1.00
cor(dep3_Intercept,dep3_meas)    -0.33      0.58    -0.99     0.90
905 1.00

Population-Level Effects:
                 Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
dep1_Intercept    1165.57     38.58  1090.30  1243.48       1627 1.00
dep2_Intercept     528.38     22.42   485.62   572.92       1613 1.00
dep3_Intercept      30.07      0.43    29.25    30.91       1145 1.00
dep1_groupB       -185.97     54.52  -292.98   -78.96       1703 1.00
dep1_groupC        833.20     54.37   726.62   942.00       1766 1.00
dep1_meas          -53.49     17.92   -88.61   -17.70       1512 1.00
dep1_groupB:meas    33.89     25.41   -16.60    83.19       1727 1.00
dep1_groupC:meas    53.53     25.13     3.72   102.48       1672 1.00
dep2_groupB       1471.02     31.32  1409.44  1530.53       1711 1.00
dep2_groupC        945.18     31.53   882.38  1006.88       1704 1.00
dep2_meas           -2.86     10.40   -23.08    16.94       1533 1.00
dep2_groupB:meas     2.63     14.58   -24.96    31.52       1551 1.00
dep2_groupC:meas     4.24     14.56   -24.24    32.84       1650 1.00
dep3_groupB          9.49      0.60     8.33    10.69       1466 1.00
dep3_groupC          0.04      0.60    -1.14     1.21       1398 1.01
dep3_meas            0.09      0.20    -0.30     0.47       1056 1.00
dep3_groupB:meas     0.02      0.28    -0.52     0.55       1366 1.00
dep3_groupC:meas    -0.16      0.28    -0.72     0.37       1107 1.01

Family Specific Parameters:
                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma(dep1)         465.19      6.69   452.13   478.19       5000    1
sigma(dep2)         263.12      3.76   255.76   270.45       5000    1
sigma(dep3)           4.98      0.07     4.85     5.12       5000    1
rescor(dep1,dep2)    -0.02      0.02    -0.06     0.02       5000    1
rescor(dep1,dep3)     0.01      0.02    -0.03     0.04       5000    1
rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000    1

@Jarrod: Thanks for the translation, I will delve into it!

I believe it is safe to say that systematic missing values lead to inflated
population estimates. I reran the same type of model about 3 times (with
different seeds), and the same kind of weird things popped up. Of course, I
must confess this is a very crude simulation (my data-generation is far
from sophisticated).

Kind regards,

Koen

2017-02-02 20:41 GMT+01:00 Paul Buerkner <paul.buerkner at gmail.com>:

> Could it be that this is partly because you did not include "meas" as a
> fixed effect but only as a random effect? Without a corresponding fixed
> effect, random effects are centered around zero, which may not be what you
> want.
>
> 2017-02-02 11:04 GMT+01:00 Koen Neijenhuijs <kn.journal.news at gmail.com>:
>
>> Hello all,
>>
>> I was wondering what would happen with a multivariate LMEM when there is
>> systematic missing data. I ran a crude simulation to check this situation:
>>
>> Group A: Has data on Dependent variable 1 (dep1), 2 (dep2), and 3 (dep3)
>> Group B: Has data on dep1 and dep3
>> Group C: Has data on dep2 and dep3
>>
>> All data is measured three times (I am disregarding the effect of time for
>> simplicity's sake).
>>
>> The aim is to compare group A on the data it shares with group B and group
>> C. I created this data and ran a multivariate brms model on it. I did not
>> provide priors, as such, uninformative priors will be used. Code:
>>
>> set.seed(103)
>> # Data structure:
>> # id | group (A/B/C) | dep1 (mean(SD), A: 10(5), B: 15(5), C: NA) | dep2
>> (A: 20(5), B: NA, C: 40(5)), dep3 (A: 30(5), B: 40(5), C: 30(5))
>>
>> n_indiv <- 999
>> n_per_indiv <- 3
>> n_tot <- n_indiv * n_per_indiv
>> id <- gl(n_indiv, n_per_indiv)  ## generate identifier columns
>>
>> dat <- data.frame(id=id,
>>                   group=rep(c("A", "B", "C"),each=n_tot/3),
>>                   meas=rep(c(1, 2, 3), times=n_tot/n_per_indiv),
>>                   dep1=c(rnorm(n_tot/3,10,5), rnorm(n_tot/3,15,5),
>> rep("NA", times=n_tot/3)),
>>                   dep2=c(rnorm(n_tot/3,20,5), rep("NA", times=n_tot/3),
>> rnorm(n_tot/3,40,5)),
>>                   dep3=c(rnorm(n_tot/3,30,5), rnorm(n_tot/3,40,5),
>> rnorm(n_tot/3,30,5)))
>>
>> ncores <- detectCores() -1
>>
>> m1_brms <- brm(cbind(dep1, dep2, dep3) ~ group + (1+meas|id), data=dat,
>> family="gaussian",
>>                n.warmup=500, n.iter = 1500, n.chains=5, cores=ncores)
>>
>> sum_m1_brms <- summary(m1_brms)
>>
>> Everything converged nicely (trace plots are looking good, Rhat is fine I
>> believe). The output of the summary:
>>
>>  Family: gaussian (identity)
>> Formula: cbind(dep1, dep2, dep3) ~ group + (1 + meas | id)
>>    Data: dat (Number of observations: 2997)
>> Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
>>          total post-warmup samples = 5000
>>    WAIC: Not computed
>>
>> Group-Level Effects:
>> ~id (Number of levels: 999)
>>                               Estimate Est.Error l-95% CI u-95% CI
>> Eff.Sample Rhat
>> sd(dep1_Intercept)               45.29     37.05     2.16   145.59
>> 402 1.00
>> sd(dep1_meas)                    26.92     20.37     1.30    78.80
>> 226 1.03
>> sd(dep2_Intercept)               32.91     28.47     0.97   111.39
>> 184 1.03
>> sd(dep2_meas)                    18.89     13.85     0.75    54.06
>> 159 1.02
>> sd(dep3_Intercept)                0.54      0.50     0.02     2.08
>> 155 1.05
>> sd(dep3_meas)                     0.25      0.23     0.01     0.95
>> 93 1.05
>> cor(dep1_Intercept,dep1_meas)    -0.36      0.57    -0.99     0.89
>> 338 1.02
>> cor(dep2_Intercept,dep2_meas)    -0.40      0.56    -0.98     0.88
>> 241 1.01
>> cor(dep3_Intercept,dep3_meas)    -0.36      0.59    -0.99     0.92
>> 386 1.01
>>
>> Population-Level Effects:
>>                Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> dep1_Intercept  1058.94     14.62  1029.65  1087.34       5000 1.00
>> dep2_Intercept   523.02      8.40   506.45   540.22       2150 1.00
>> dep3_Intercept    30.25      0.16    29.94    30.56       5000 1.00
>> dep1_groupB     -118.01     20.82  -160.15   -77.53       5000 1.00
>> dep1_groupC      940.46     20.83   900.16   982.28       5000 1.00
>> dep2_groupB     1476.62     12.24  1452.73  1500.95        661 1.01
>> dep2_groupC      953.48     11.75   930.22   976.84       5000 1.00
>> dep3_groupB        9.52      0.22     9.08     9.95       5000 1.00
>> dep3_groupC       -0.29      0.22    -0.73     0.15       5000 1.00
>>
>> Family Specific Parameters:
>>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sigma(dep1)         465.54      6.59   452.02   478.22        755 1.00
>> sigma(dep2)         262.63      3.93   254.64   270.00        712 1.01
>> sigma(dep3)           4.98      0.07     4.84     5.12        699 1.01
>> rescor(dep1,dep2)    -0.02      0.02    -0.05     0.02       5000 1.00
>> rescor(dep1,dep3)     0.00      0.02    -0.03     0.04       5000 1.01
>> rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000 1.00
>>
>> The effects that are in the data, seem to be estimated, but the directions
>> and magnitudes of the estimates seem all over the place. In the data,
>> group
>> A was always smaller or equal (in the case of dep3_groupC). As you can
>> see,
>> the population estimate for dep1_groupB is in the wrong direction, and the
>> estimate for dep2_groupC is huge. The only estimates that seem
>> non-inflated
>> and correct are those for dep3, which had data on all three groups.
>>
>> Would it be safe to assume that systematic missing data on one group,
>> inflates the estimates between the remaining groups? I would love to hear
>> your thoughts!
>>
>> One further question. I tried to perform the same multivariate analysis
>> using MCMCglmm, but I find the syntax of the random and rcov parameters
>> hard to set, and the output even harder to interpret. I would love to get
>> some feedback on how to perform a similar analysis using the MCMCglmm
>> function. Code:
>>
>> m1 <- MCMCglmm(cbind(dep1, dep2, dep3) ~ group-1, random = ~us(1+meas):id,
>>                rcov = ~us(trait):units, data = dat, family = c("gaussian",
>> "gaussian", "gaussian"),
>>                     verbose = FALSE)
>>
>> summary(m1)
>>
>> Output:
>>
>>  Iterations = 3001:12991
>>  Thinning interval  = 10
>>  Sample size  = 1000
>>
>>  DIC: 119465.7
>>
>>  G-structure:  ~us(1 + meas):id
>>
>>                            post.mean   l-95% CI u-95% CI eff.samp
>> (Intercept):(Intercept).id    0.5868  0.0010440  2.54542    6.784
>> meas:(Intercept).id          -0.3008 -1.2656335  0.01044    6.621
>> (Intercept):meas.id          -0.3008 -1.2656335  0.01044    6.621
>> meas:meas.id                  0.1716  0.0004239  0.65286    6.936
>>
>>  R-structure:  ~us(trait):units
>>
>>                            post.mean   l-95% CI   u-95% CI eff.samp
>> traitdep1:traitdep1.units 2132866.20 2027876.02 2239057.50    911.5
>> traitdep2:traitdep1.units 1703387.51 1615965.82 1803474.41   1000.0
>> traitdep3:traitdep1.units   -1405.09   -2700.25      60.61    150.3
>> traitdep1:traitdep2.units 1703387.51 1615965.82 1803474.41   1000.0
>> traitdep2:traitdep2.units 2129068.98 2023232.02 2239145.62   1283.7
>> traitdep3:traitdep2.units   -1685.89   -3264.50    -184.62    136.2
>> traitdep1:traitdep3.units   -1405.09   -2700.25      60.61    150.3
>> traitdep2:traitdep3.units   -1685.89   -3264.50    -184.62    136.2
>> traitdep3:traitdep3.units      26.57      23.99      29.55    188.8
>>
>>  Location effects: cbind(dep1, dep2, dep3) ~ group - 1
>>
>>        post.mean l-95% CI u-95% CI eff.samp  pMCMC
>> groupA     30.69    30.13    31.37    226.0 <0.001 ***
>> groupB     41.29    39.97    42.75    122.0 <0.001 ***
>> groupC     31.20    29.89    32.50    151.8 <0.001 ***
>>
>> Thanks in advance!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Fri Feb  3 11:52:16 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Fri, 3 Feb 2017 11:52:16 +0100
Subject: [R-sig-ME] brms: Multivariate LMEM with systematic missing data
In-Reply-To: <CABL7txQ6UinetcHqWd8H0tt4gsirS2ThbN7FHpOENRvsGBzuug@mail.gmail.com>
References: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>
	<CAGoSky-tSjgkNOX_ADi0WUrOe-UxEZ2rX5BQDe6YrWn2bZpyhw@mail.gmail.com>
	<CABL7txQ6UinetcHqWd8H0tt4gsirS2ThbN7FHpOENRvsGBzuug@mail.gmail.com>
Message-ID: <CAGoSky9tK6AZ5Ykpu6djEhAOrPkUTeW8B-695u3fCeUq4Zt+nw@mail.gmail.com>

Hi Koen,

now that I am looking at your simulations more closely I am not at all
surprised it leads to bias.

As neither brms nor MCMCglmm (correct me if I am wrong Jarrod) can handle
missing values, rows containing NAs are removed. So, as a result of your
simulations, 2 / 3 of the data will be excluded. In brms, the number of obs
shows 2997 since in counts all responses, so 2997 / 3 * 3 = 2997.

Best,
Paul

2017-02-03 11:39 GMT+01:00 Koen Neijenhuijs <kn.journal.news at gmail.com>:

> Hi Paul and Jarrod,
>
> @Paul: not including "meas" as a fixed effect was an error on my part. I
> reran the model with it included (note, meas had no effect size in the
> generated data). The output still shows the same kind of inflated
> population estimates that I noted before:
>
>  Family: gaussian (identity)
> Formula: cbind(dep1, dep2, dep3) ~ group * meas + (1 + meas | id)
>    Data: dat (Number of observations: 2997)
> Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
>          total post-warmup samples = 5000
>    WAIC: Not computed
>
> Group-Level Effects:
> ~id (Number of levels: 999)
>                               Estimate Est.Error l-95% CI u-95% CI
> Eff.Sample Rhat
> sd(dep1_Intercept)               41.25     32.88     1.49   125.28
> 722 1.01
> sd(dep1_meas)                    23.84     17.80     0.95    68.74
> 195 1.02
> sd(dep2_Intercept)               28.35     21.61     0.81    81.16
> 643 1.00
> sd(dep2_meas)                    15.10     10.70     0.78    40.85
> 280 1.01
> sd(dep3_Intercept)                0.45      0.38     0.02     1.45
> 652 1.00
> sd(dep3_meas)                     0.21      0.17     0.01     0.67
> 386 1.00
> cor(dep1_Intercept,dep1_meas)    -0.31      0.56    -0.98     0.89
> 691 1.01
> cor(dep2_Intercept,dep2_meas)    -0.31      0.56    -0.98     0.87
> 583 1.00
> cor(dep3_Intercept,dep3_meas)    -0.33      0.58    -0.99     0.90
> 905 1.00
>
> Population-Level Effects:
>                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> dep1_Intercept    1165.57     38.58  1090.30  1243.48       1627 1.00
> dep2_Intercept     528.38     22.42   485.62   572.92       1613 1.00
> dep3_Intercept      30.07      0.43    29.25    30.91       1145 1.00
> dep1_groupB       -185.97     54.52  -292.98   -78.96       1703 1.00
> dep1_groupC        833.20     54.37   726.62   942.00       1766 1.00
> dep1_meas          -53.49     17.92   -88.61   -17.70       1512 1.00
> dep1_groupB:meas    33.89     25.41   -16.60    83.19       1727 1.00
> dep1_groupC:meas    53.53     25.13     3.72   102.48       1672 1.00
> dep2_groupB       1471.02     31.32  1409.44  1530.53       1711 1.00
> dep2_groupC        945.18     31.53   882.38  1006.88       1704 1.00
> dep2_meas           -2.86     10.40   -23.08    16.94       1533 1.00
> dep2_groupB:meas     2.63     14.58   -24.96    31.52       1551 1.00
> dep2_groupC:meas     4.24     14.56   -24.24    32.84       1650 1.00
> dep3_groupB          9.49      0.60     8.33    10.69       1466 1.00
> dep3_groupC          0.04      0.60    -1.14     1.21       1398 1.01
> dep3_meas            0.09      0.20    -0.30     0.47       1056 1.00
> dep3_groupB:meas     0.02      0.28    -0.52     0.55       1366 1.00
> dep3_groupC:meas    -0.16      0.28    -0.72     0.37       1107 1.01
>
> Family Specific Parameters:
>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sigma(dep1)         465.19      6.69   452.13   478.19       5000    1
> sigma(dep2)         263.12      3.76   255.76   270.45       5000    1
> sigma(dep3)           4.98      0.07     4.85     5.12       5000    1
> rescor(dep1,dep2)    -0.02      0.02    -0.06     0.02       5000    1
> rescor(dep1,dep3)     0.01      0.02    -0.03     0.04       5000    1
> rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000    1
>
> @Jarrod: Thanks for the translation, I will delve into it!
>
> I believe it is safe to say that systematic missing values lead to
> inflated population estimates. I reran the same type of model about 3 times
> (with different seeds), and the same kind of weird things popped up. Of
> course, I must confess this is a very crude simulation (my data-generation
> is far from sophisticated).
>
> Kind regards,
>
> Koen
>
> 2017-02-02 20:41 GMT+01:00 Paul Buerkner <paul.buerkner at gmail.com>:
>
>> Could it be that this is partly because you did not include "meas" as a
>> fixed effect but only as a random effect? Without a corresponding fixed
>> effect, random effects are centered around zero, which may not be what you
>> want.
>>
>> 2017-02-02 11:04 GMT+01:00 Koen Neijenhuijs <kn.journal.news at gmail.com>:
>>
>>> Hello all,
>>>
>>> I was wondering what would happen with a multivariate LMEM when there is
>>> systematic missing data. I ran a crude simulation to check this
>>> situation:
>>>
>>> Group A: Has data on Dependent variable 1 (dep1), 2 (dep2), and 3 (dep3)
>>> Group B: Has data on dep1 and dep3
>>> Group C: Has data on dep2 and dep3
>>>
>>> All data is measured three times (I am disregarding the effect of time
>>> for
>>> simplicity's sake).
>>>
>>> The aim is to compare group A on the data it shares with group B and
>>> group
>>> C. I created this data and ran a multivariate brms model on it. I did not
>>> provide priors, as such, uninformative priors will be used. Code:
>>>
>>> set.seed(103)
>>> # Data structure:
>>> # id | group (A/B/C) | dep1 (mean(SD), A: 10(5), B: 15(5), C: NA) | dep2
>>> (A: 20(5), B: NA, C: 40(5)), dep3 (A: 30(5), B: 40(5), C: 30(5))
>>>
>>> n_indiv <- 999
>>> n_per_indiv <- 3
>>> n_tot <- n_indiv * n_per_indiv
>>> id <- gl(n_indiv, n_per_indiv)  ## generate identifier columns
>>>
>>> dat <- data.frame(id=id,
>>>                   group=rep(c("A", "B", "C"),each=n_tot/3),
>>>                   meas=rep(c(1, 2, 3), times=n_tot/n_per_indiv),
>>>                   dep1=c(rnorm(n_tot/3,10,5), rnorm(n_tot/3,15,5),
>>> rep("NA", times=n_tot/3)),
>>>                   dep2=c(rnorm(n_tot/3,20,5), rep("NA", times=n_tot/3),
>>> rnorm(n_tot/3,40,5)),
>>>                   dep3=c(rnorm(n_tot/3,30,5), rnorm(n_tot/3,40,5),
>>> rnorm(n_tot/3,30,5)))
>>>
>>> ncores <- detectCores() -1
>>>
>>> m1_brms <- brm(cbind(dep1, dep2, dep3) ~ group + (1+meas|id), data=dat,
>>> family="gaussian",
>>>                n.warmup=500, n.iter = 1500, n.chains=5, cores=ncores)
>>>
>>> sum_m1_brms <- summary(m1_brms)
>>>
>>> Everything converged nicely (trace plots are looking good, Rhat is fine I
>>> believe). The output of the summary:
>>>
>>>  Family: gaussian (identity)
>>> Formula: cbind(dep1, dep2, dep3) ~ group + (1 + meas | id)
>>>    Data: dat (Number of observations: 2997)
>>> Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
>>>          total post-warmup samples = 5000
>>>    WAIC: Not computed
>>>
>>> Group-Level Effects:
>>> ~id (Number of levels: 999)
>>>                               Estimate Est.Error l-95% CI u-95% CI
>>> Eff.Sample Rhat
>>> sd(dep1_Intercept)               45.29     37.05     2.16   145.59
>>> 402 1.00
>>> sd(dep1_meas)                    26.92     20.37     1.30    78.80
>>> 226 1.03
>>> sd(dep2_Intercept)               32.91     28.47     0.97   111.39
>>> 184 1.03
>>> sd(dep2_meas)                    18.89     13.85     0.75    54.06
>>> 159 1.02
>>> sd(dep3_Intercept)                0.54      0.50     0.02     2.08
>>> 155 1.05
>>> sd(dep3_meas)                     0.25      0.23     0.01     0.95
>>> 93 1.05
>>> cor(dep1_Intercept,dep1_meas)    -0.36      0.57    -0.99     0.89
>>> 338 1.02
>>> cor(dep2_Intercept,dep2_meas)    -0.40      0.56    -0.98     0.88
>>> 241 1.01
>>> cor(dep3_Intercept,dep3_meas)    -0.36      0.59    -0.99     0.92
>>> 386 1.01
>>>
>>> Population-Level Effects:
>>>                Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>>> dep1_Intercept  1058.94     14.62  1029.65  1087.34       5000 1.00
>>> dep2_Intercept   523.02      8.40   506.45   540.22       2150 1.00
>>> dep3_Intercept    30.25      0.16    29.94    30.56       5000 1.00
>>> dep1_groupB     -118.01     20.82  -160.15   -77.53       5000 1.00
>>> dep1_groupC      940.46     20.83   900.16   982.28       5000 1.00
>>> dep2_groupB     1476.62     12.24  1452.73  1500.95        661 1.01
>>> dep2_groupC      953.48     11.75   930.22   976.84       5000 1.00
>>> dep3_groupB        9.52      0.22     9.08     9.95       5000 1.00
>>> dep3_groupC       -0.29      0.22    -0.73     0.15       5000 1.00
>>>
>>> Family Specific Parameters:
>>>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>>> sigma(dep1)         465.54      6.59   452.02   478.22        755 1.00
>>> sigma(dep2)         262.63      3.93   254.64   270.00        712 1.01
>>> sigma(dep3)           4.98      0.07     4.84     5.12        699 1.01
>>> rescor(dep1,dep2)    -0.02      0.02    -0.05     0.02       5000 1.00
>>> rescor(dep1,dep3)     0.00      0.02    -0.03     0.04       5000 1.01
>>> rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000 1.00
>>>
>>> The effects that are in the data, seem to be estimated, but the
>>> directions
>>> and magnitudes of the estimates seem all over the place. In the data,
>>> group
>>> A was always smaller or equal (in the case of dep3_groupC). As you can
>>> see,
>>> the population estimate for dep1_groupB is in the wrong direction, and
>>> the
>>> estimate for dep2_groupC is huge. The only estimates that seem
>>> non-inflated
>>> and correct are those for dep3, which had data on all three groups.
>>>
>>> Would it be safe to assume that systematic missing data on one group,
>>> inflates the estimates between the remaining groups? I would love to hear
>>> your thoughts!
>>>
>>> One further question. I tried to perform the same multivariate analysis
>>> using MCMCglmm, but I find the syntax of the random and rcov parameters
>>> hard to set, and the output even harder to interpret. I would love to get
>>> some feedback on how to perform a similar analysis using the MCMCglmm
>>> function. Code:
>>>
>>> m1 <- MCMCglmm(cbind(dep1, dep2, dep3) ~ group-1, random =
>>> ~us(1+meas):id,
>>>                rcov = ~us(trait):units, data = dat, family =
>>> c("gaussian",
>>> "gaussian", "gaussian"),
>>>                     verbose = FALSE)
>>>
>>> summary(m1)
>>>
>>> Output:
>>>
>>>  Iterations = 3001:12991
>>>  Thinning interval  = 10
>>>  Sample size  = 1000
>>>
>>>  DIC: 119465.7
>>>
>>>  G-structure:  ~us(1 + meas):id
>>>
>>>                            post.mean   l-95% CI u-95% CI eff.samp
>>> (Intercept):(Intercept).id    0.5868  0.0010440  2.54542    6.784
>>> meas:(Intercept).id          -0.3008 -1.2656335  0.01044    6.621
>>> (Intercept):meas.id          -0.3008 -1.2656335  0.01044    6.621
>>> meas:meas.id                  0.1716  0.0004239  0.65286    6.936
>>>
>>>  R-structure:  ~us(trait):units
>>>
>>>                            post.mean   l-95% CI   u-95% CI eff.samp
>>> traitdep1:traitdep1.units 2132866.20 2027876.02 2239057.50    911.5
>>> traitdep2:traitdep1.units 1703387.51 1615965.82 1803474.41   1000.0
>>> traitdep3:traitdep1.units   -1405.09   -2700.25      60.61    150.3
>>> traitdep1:traitdep2.units 1703387.51 1615965.82 1803474.41   1000.0
>>> traitdep2:traitdep2.units 2129068.98 2023232.02 2239145.62   1283.7
>>> traitdep3:traitdep2.units   -1685.89   -3264.50    -184.62    136.2
>>> traitdep1:traitdep3.units   -1405.09   -2700.25      60.61    150.3
>>> traitdep2:traitdep3.units   -1685.89   -3264.50    -184.62    136.2
>>> traitdep3:traitdep3.units      26.57      23.99      29.55    188.8
>>>
>>>  Location effects: cbind(dep1, dep2, dep3) ~ group - 1
>>>
>>>        post.mean l-95% CI u-95% CI eff.samp  pMCMC
>>> groupA     30.69    30.13    31.37    226.0 <0.001 ***
>>> groupB     41.29    39.97    42.75    122.0 <0.001 ***
>>> groupC     31.20    29.89    32.50    151.8 <0.001 ***
>>>
>>> Thanks in advance!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From kn.journal.news at gmail.com  Fri Feb  3 14:53:21 2017
From: kn.journal.news at gmail.com (Koen Neijenhuijs)
Date: Fri, 3 Feb 2017 14:53:21 +0100
Subject: [R-sig-ME] brms: Multivariate LMEM with systematic missing data
In-Reply-To: <op.yu25yht5sgx3xe@armadillo50>
References: <CABL7txT+pVWR8292o1YdGJs6zA9Wfdh=oYAHrY1pJik2JUR4mg@mail.gmail.com>
	<CAGoSky-tSjgkNOX_ADi0WUrOe-UxEZ2rX5BQDe6YrWn2bZpyhw@mail.gmail.com>
	<CABL7txQ6UinetcHqWd8H0tt4gsirS2ThbN7FHpOENRvsGBzuug@mail.gmail.com>
	<op.yu25yht5sgx3xe@armadillo50>
Message-ID: <CABL7txTxO1Wtr5ct45K9YB1uwEKy8h9qYwrQELSOZPniaxm3EQ@mail.gmail.com>

Hi,

@Paul Debes: You are absolutely correct, the NA were misspecified. I need
to take better care to my specifications.
@Paul Buerkner: With the above fixed, you are absolutely correct that I
only have 999 valid responses. Funnily, the coefficients only get more
ridiculous:

 Family: gaussian (identity)
Formula: cbind(dep1, dep2, dep3) ~ group * meas + (1 + meas | id)
   Data: dat (Number of observations: 999)
Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
         total post-warmup samples = 5000
   WAIC: Not computed

Group-Level Effects:
~id (Number of levels: 333)
                              Estimate Est.Error l-95% CI u-95% CI
Eff.Sample Rhat
sd(dep1_Intercept)                0.68      0.50     0.03     1.93
1127 1.00
sd(dep1_meas)                     0.30      0.23     0.01     0.88
609 1.01
sd(dep2_Intercept)                0.79      0.74     0.03     3.14
69 1.07
sd(dep2_meas)                     0.37      0.31     0.02     1.27
64 1.07
sd(dep3_Intercept)                0.63      0.55     0.03     2.09
656 1.01
sd(dep3_meas)                     0.26      0.23     0.01     0.90
691 1.01
cor(dep1_Intercept,dep1_meas)    -0.28      0.57    -0.98     0.89
911 1.01
cor(dep2_Intercept,dep2_meas)    -0.28      0.58    -0.98     0.91
385 1.01
cor(dep3_Intercept,dep3_meas)    -0.32      0.58    -0.99     0.89
1020 1.01

Population-Level Effects:
                   Estimate Est.Error   l-95% CI   u-95% CI Eff.Sample Rhat
dep1_Intercept        10.24      0.44       9.38      11.05       5000 1.01
dep2_Intercept        20.02      0.41      19.22      20.81       5000 1.00
dep3_Intercept        29.40      0.42      28.54      30.21       5000 1.00
dep1_groupB       210763.68 526479.52 -157461.18 1583956.49          3 3.56
dep1_groupC         9138.67  70713.21 -121719.20  157643.19          4 1.64
dep1_meas             -0.19      0.20      -0.57       0.20       5000 1.00
dep1_groupB:meas  -23205.11 100734.03 -312577.64  142648.44          4 2.48
dep1_groupC:meas  -71455.38 157002.26 -446894.22  182257.70          5 2.17
dep2_groupB       -20607.61 140109.92 -392849.23  238572.51          5 2.93
dep2_groupC      -148928.00 143151.46 -433430.59   80773.75          8 2.19
dep2_meas             -0.01      0.19      -0.39       0.37       5000 1.00
dep2_groupB:meas -142584.37 265356.46 -843416.71  159443.42          3 3.12
dep2_groupC:meas   43112.00 217047.74 -404953.43  715305.83         11 1.88
dep3_groupB       -50794.17 106310.18 -315974.63  133696.31          5 2.20
dep3_groupC        81455.65 112784.68 -103536.02  385103.89          7 1.90
dep3_meas              0.25      0.19      -0.12       0.64       5000 1.00
dep3_groupB:meas  -86503.76  82586.35 -238653.81  144958.27         19 1.34
dep3_groupC:meas  -54695.42  58965.65 -177878.21   33452.76          4 1.79

Family Specific Parameters:
                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma(dep1)           5.07      0.12     4.83     5.31       5000 1.01
sigma(dep2)           4.88      0.14     4.46     5.13        112 1.04
sigma(dep3)           5.03      0.12     4.81     5.27       5000 1.00
rescor(dep1,dep2)     0.03      0.03    -0.04     0.09       5000 1.00
rescor(dep1,dep3)     0.02      0.03    -0.04     0.09       5000 1.00
rescor(dep2,dep3)     0.01      0.03    -0.06     0.08       5000 1.01

@Paul Debes: I am not familiar with ASreml package. I'm currently looking
at the documentation, and seeing if this package can do what I want it to.

@Jarrod: Still very interested in hearing how MCMCglmm handles missing data
exactly. I found some earlier r-sig mailings surrounding it, however that
seemed to focus on missing data on fixed effects, instead of missing data
on outcome measures.

Thanks everyone so far for the great responses!

2017-02-03 14:19 GMT+01:00 Paul Debes <paul.debes at utu.fi>:

> Hi Koen,
>
> Your conclusion (biased estimates with missing data for specific groups)
> made me very curious if that is the case (I think this is quite important),
> so I just run the model in asreml-R. To exclude sampling error, I generated
> the data with 'mvrnorm' from 'MASS' with 'empirical = TRUE' (don't use this
> option for simulations) rather than with 'rnorm'. It gives estimates that
> agree with the simulated data.
>
> Did you run the models with dep2 and dep3 wrongly formatted as factors by
> specifying "NA" rather than NA?
>
>
> library("MASS")
> Sigma.no.cor = matrix(0,3,3)
> diag(Sigma.no.cor) = sqrt(5)
> Sigma.no.cor
>
> empirical.switch = TRUE # FALSE # set to FALSE for simulations, to TRUE
> for checking
> Sigma = Sigma.no.cor
>
> A.dat.matrix = mvrnorm(n_tot/3, c(10,20,30), Sigma= Sigma, empirical=
> empirical.switch)
> B.dat.matrix = mvrnorm(n_tot/3, c(15, 0,40), Sigma= Sigma, empirical=
> empirical.switch)
> B.dat.matrix[,2] = NA
> C.dat.matrix = mvrnorm(n_tot/3, c( 0,40,30), Sigma= Sigma, empirical=
> empirical.switch)
> C.dat.matrix[,1] = NA
>
> dat <- data.frame(id= id,
>         group =rep(c("A", "B", "C"),each=n_tot/3),
>         meas =rep(c(1, 2, 3), times=n_tot/n_per_indiv),
>         #dep1 =c(rnorm(n_tot/3,10,5), rnorm(n_tot/3,15,5), rep(NA,
> times=n_tot/3)), # I removed your quotes!
>         #dep2 =c(rnorm(n_tot/3,20,5), rep(NA, times=n_tot/3),
> rnorm(n_tot/3,40,5)),
>         #dep3 =c(rnorm(n_tot/3,30,5), rnorm(n_tot/3,40,5),
> rnorm(n_tot/3,30,5)) )
>         dep1 = c(A.dat.matrix[,1],B.dat.matrix[,1],C.dat.matrix[,1]),
>         dep2 = c(A.dat.matrix[,2],B.dat.matrix[,2],C.dat.matrix[,2]),
>         dep3 = c(A.dat.matrix[,3],B.dat.matrix[,3],C.dat.matrix[,3]))
>
> str(dat)
>
> library("asreml")
> m1_asreml = asreml(cbind(dep1, dep2, dep3) ~ -1 + trait:group + trait:meas,
>         random = ~ str(~id/meas ,~us(2):id(id)),
>         rcov = ~ units:us(trait),
>         data = dat,
>         maxiter = 1000)
> m1_asreml = update(m1_asreml)
>
> varcomp.nice(m1_asreml,digits=3)
>                      component std.error z.ratio   V
> id+id:meas!us(2).1:1        NA        NA      NA  V1
> id+id:meas!us(2).2:1    -0.005     0.012   -0.41  V2
> id+id:meas!us(2).2:2     0.006     0.011    0.57  V3
> R!variance               1.000        NA      NA  V4
> R!trait.dep1:dep1        2.228     0.073   30.60  V5
> R!trait.dep2:dep1       -0.009     0.073   -0.12  V6
> R!trait.dep2:dep2        2.228     0.073   30.71  V7
> R!trait.dep3:dep1       -0.010     0.053   -0.19  V8
> R!trait.dep3:dep2       -0.010     0.053   -0.19  V9
> R!trait.dep3:dep3        2.225     0.060   36.88 V10
>
> coef.nice(m1_asreml,digits=3)
>                    solution std.error z.ratio
> trait_dep1:meas      -0.006     0.041   -0.15
> trait_dep2:meas      -0.010     0.041   -0.24
> trait_dep3:meas      -0.033     0.033   -0.99
> trait_dep1:group_A   10.013     0.094  105.96
> trait_dep1:group_B   15.012     0.094  158.87
> trait_dep2:group_A   20.020     0.094  211.88
> trait_dep2:group_C   40.020     0.094  423.55
> trait_dep3:group_A   30.066     0.082  367.50
> trait_dep3:group_B   40.066     0.082  489.73
> trait_dep3:group_C   30.066     0.082  367.50
>
> Best,
> Paul
>
>
>
> On Fri, 03 Feb 2017 12:39:24 +0200, Koen Neijenhuijs <
> kn.journal.news at gmail.com> wrote:
>
> Hi Paul and Jarrod,
>>
>> @Paul: not including "meas" as a fixed effect was an error on my part. I
>> reran the model with it included (note, meas had no effect size in the
>> generated data). The output still shows the same kind of inflated
>> population estimates that I noted before:
>>
>>  Family: gaussian (identity)
>> Formula: cbind(dep1, dep2, dep3) ~ group * meas + (1 + meas | id)
>>    Data: dat (Number of observations: 2997)
>> Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
>>          total post-warmup samples = 5000
>>    WAIC: Not computed
>>
>> Group-Level Effects:
>> ~id (Number of levels: 999)
>>                               Estimate Est.Error l-95% CI u-95% CI
>> Eff.Sample Rhat
>> sd(dep1_Intercept)               41.25     32.88     1.49   125.28
>> 722 1.01
>> sd(dep1_meas)                    23.84     17.80     0.95    68.74
>> 195 1.02
>> sd(dep2_Intercept)               28.35     21.61     0.81    81.16
>> 643 1.00
>> sd(dep2_meas)                    15.10     10.70     0.78    40.85
>> 280 1.01
>> sd(dep3_Intercept)                0.45      0.38     0.02     1.45
>> 652 1.00
>> sd(dep3_meas)                     0.21      0.17     0.01     0.67
>> 386 1.00
>> cor(dep1_Intercept,dep1_meas)    -0.31      0.56    -0.98     0.89
>> 691 1.01
>> cor(dep2_Intercept,dep2_meas)    -0.31      0.56    -0.98     0.87
>> 583 1.00
>> cor(dep3_Intercept,dep3_meas)    -0.33      0.58    -0.99     0.90
>> 905 1.00
>>
>> Population-Level Effects:
>>                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> dep1_Intercept    1165.57     38.58  1090.30  1243.48       1627 1.00
>> dep2_Intercept     528.38     22.42   485.62   572.92       1613 1.00
>> dep3_Intercept      30.07      0.43    29.25    30.91       1145 1.00
>> dep1_groupB       -185.97     54.52  -292.98   -78.96       1703 1.00
>> dep1_groupC        833.20     54.37   726.62   942.00       1766 1.00
>> dep1_meas          -53.49     17.92   -88.61   -17.70       1512 1.00
>> dep1_groupB:meas    33.89     25.41   -16.60    83.19       1727 1.00
>> dep1_groupC:meas    53.53     25.13     3.72   102.48       1672 1.00
>> dep2_groupB       1471.02     31.32  1409.44  1530.53       1711 1.00
>> dep2_groupC        945.18     31.53   882.38  1006.88       1704 1.00
>> dep2_meas           -2.86     10.40   -23.08    16.94       1533 1.00
>> dep2_groupB:meas     2.63     14.58   -24.96    31.52       1551 1.00
>> dep2_groupC:meas     4.24     14.56   -24.24    32.84       1650 1.00
>> dep3_groupB          9.49      0.60     8.33    10.69       1466 1.00
>> dep3_groupC          0.04      0.60    -1.14     1.21       1398 1.01
>> dep3_meas            0.09      0.20    -0.30     0.47       1056 1.00
>> dep3_groupB:meas     0.02      0.28    -0.52     0.55       1366 1.00
>> dep3_groupC:meas    -0.16      0.28    -0.72     0.37       1107 1.01
>>
>> Family Specific Parameters:
>>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sigma(dep1)         465.19      6.69   452.13   478.19       5000    1
>> sigma(dep2)         263.12      3.76   255.76   270.45       5000    1
>> sigma(dep3)           4.98      0.07     4.85     5.12       5000    1
>> rescor(dep1,dep2)    -0.02      0.02    -0.06     0.02       5000    1
>> rescor(dep1,dep3)     0.01      0.02    -0.03     0.04       5000    1
>> rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000    1
>>
>> @Jarrod: Thanks for the translation, I will delve into it!
>>
>> I believe it is safe to say that systematic missing values lead to
>> inflated
>> population estimates. I reran the same type of model about 3 times (with
>> different seeds), and the same kind of weird things popped up. Of course,
>> I
>> must confess this is a very crude simulation (my data-generation is far
>> from sophisticated).
>>
>> Kind regards,
>>
>> Koen
>>
>> 2017-02-02 20:41 GMT+01:00 Paul Buerkner <paul.buerkner at gmail.com>:
>>
>> Could it be that this is partly because you did not include "meas" as a
>>> fixed effect but only as a random effect? Without a corresponding fixed
>>> effect, random effects are centered around zero, which may not be what
>>> you
>>> want.
>>>
>>> 2017-02-02 11:04 GMT+01:00 Koen Neijenhuijs <kn.journal.news at gmail.com>:
>>>
>>> Hello all,
>>>>
>>>> I was wondering what would happen with a multivariate LMEM when there is
>>>> systematic missing data. I ran a crude simulation to check this
>>>> situation:
>>>>
>>>> Group A: Has data on Dependent variable 1 (dep1), 2 (dep2), and 3 (dep3)
>>>> Group B: Has data on dep1 and dep3
>>>> Group C: Has data on dep2 and dep3
>>>>
>>>> All data is measured three times (I am disregarding the effect of time
>>>> for
>>>> simplicity's sake).
>>>>
>>>> The aim is to compare group A on the data it shares with group B and
>>>> group
>>>> C. I created this data and ran a multivariate brms model on it. I did
>>>> not
>>>> provide priors, as such, uninformative priors will be used. Code:
>>>>
>>>> set.seed(103)
>>>> # Data structure:
>>>> # id | group (A/B/C) | dep1 (mean(SD), A: 10(5), B: 15(5), C: NA) | dep2
>>>> (A: 20(5), B: NA, C: 40(5)), dep3 (A: 30(5), B: 40(5), C: 30(5))
>>>>
>>>> n_indiv <- 999
>>>> n_per_indiv <- 3
>>>> n_tot <- n_indiv * n_per_indiv
>>>> id <- gl(n_indiv, n_per_indiv)  ## generate identifier columns
>>>>
>>>> dat <- data.frame(id=id,
>>>>                   group=rep(c("A", "B", "C"),each=n_tot/3),
>>>>                   meas=rep(c(1, 2, 3), times=n_tot/n_per_indiv),
>>>>                   dep1=c(rnorm(n_tot/3,10,5), rnorm(n_tot/3,15,5),
>>>> rep("NA", times=n_tot/3)),
>>>>                   dep2=c(rnorm(n_tot/3,20,5), rep("NA", times=n_tot/3),
>>>> rnorm(n_tot/3,40,5)),
>>>>                   dep3=c(rnorm(n_tot/3,30,5), rnorm(n_tot/3,40,5),
>>>> rnorm(n_tot/3,30,5)))
>>>>
>>>> ncores <- detectCores() -1
>>>>
>>>> m1_brms <- brm(cbind(dep1, dep2, dep3) ~ group + (1+meas|id), data=dat,
>>>> family="gaussian",
>>>>                n.warmup=500, n.iter = 1500, n.chains=5, cores=ncores)
>>>>
>>>> sum_m1_brms <- summary(m1_brms)
>>>>
>>>> Everything converged nicely (trace plots are looking good, Rhat is fine
>>>> I
>>>> believe). The output of the summary:
>>>>
>>>>  Family: gaussian (identity)
>>>> Formula: cbind(dep1, dep2, dep3) ~ group + (1 + meas | id)
>>>>    Data: dat (Number of observations: 2997)
>>>> Samples: 5 chains, each with iter = 1500; warmup = 500; thin = 1;
>>>>          total post-warmup samples = 5000
>>>>    WAIC: Not computed
>>>>
>>>> Group-Level Effects:
>>>> ~id (Number of levels: 999)
>>>>                               Estimate Est.Error l-95% CI u-95% CI
>>>> Eff.Sample Rhat
>>>> sd(dep1_Intercept)               45.29     37.05     2.16   145.59
>>>> 402 1.00
>>>> sd(dep1_meas)                    26.92     20.37     1.30    78.80
>>>> 226 1.03
>>>> sd(dep2_Intercept)               32.91     28.47     0.97   111.39
>>>> 184 1.03
>>>> sd(dep2_meas)                    18.89     13.85     0.75    54.06
>>>> 159 1.02
>>>> sd(dep3_Intercept)                0.54      0.50     0.02     2.08
>>>> 155 1.05
>>>> sd(dep3_meas)                     0.25      0.23     0.01     0.95
>>>> 93 1.05
>>>> cor(dep1_Intercept,dep1_meas)    -0.36      0.57    -0.99     0.89
>>>> 338 1.02
>>>> cor(dep2_Intercept,dep2_meas)    -0.40      0.56    -0.98     0.88
>>>> 241 1.01
>>>> cor(dep3_Intercept,dep3_meas)    -0.36      0.59    -0.99     0.92
>>>> 386 1.01
>>>>
>>>> Population-Level Effects:
>>>>                Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>>>> dep1_Intercept  1058.94     14.62  1029.65  1087.34       5000 1.00
>>>> dep2_Intercept   523.02      8.40   506.45   540.22       2150 1.00
>>>> dep3_Intercept    30.25      0.16    29.94    30.56       5000 1.00
>>>> dep1_groupB     -118.01     20.82  -160.15   -77.53       5000 1.00
>>>> dep1_groupC      940.46     20.83   900.16   982.28       5000 1.00
>>>> dep2_groupB     1476.62     12.24  1452.73  1500.95        661 1.01
>>>> dep2_groupC      953.48     11.75   930.22   976.84       5000 1.00
>>>> dep3_groupB        9.52      0.22     9.08     9.95       5000 1.00
>>>> dep3_groupC       -0.29      0.22    -0.73     0.15       5000 1.00
>>>>
>>>> Family Specific Parameters:
>>>>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>>>> sigma(dep1)         465.54      6.59   452.02   478.22        755 1.00
>>>> sigma(dep2)         262.63      3.93   254.64   270.00        712 1.01
>>>> sigma(dep3)           4.98      0.07     4.84     5.12        699 1.01
>>>> rescor(dep1,dep2)    -0.02      0.02    -0.05     0.02       5000 1.00
>>>> rescor(dep1,dep3)     0.00      0.02    -0.03     0.04       5000 1.01
>>>> rescor(dep2,dep3)    -0.02      0.02    -0.06     0.02       5000 1.00
>>>>
>>>> The effects that are in the data, seem to be estimated, but the
>>>> directions
>>>> and magnitudes of the estimates seem all over the place. In the data,
>>>> group
>>>> A was always smaller or equal (in the case of dep3_groupC). As you can
>>>> see,
>>>> the population estimate for dep1_groupB is in the wrong direction, and
>>>> the
>>>> estimate for dep2_groupC is huge. The only estimates that seem
>>>> non-inflated
>>>> and correct are those for dep3, which had data on all three groups.
>>>>
>>>> Would it be safe to assume that systematic missing data on one group,
>>>> inflates the estimates between the remaining groups? I would love to
>>>> hear
>>>> your thoughts!
>>>>
>>>> One further question. I tried to perform the same multivariate analysis
>>>> using MCMCglmm, but I find the syntax of the random and rcov parameters
>>>> hard to set, and the output even harder to interpret. I would love to
>>>> get
>>>> some feedback on how to perform a similar analysis using the MCMCglmm
>>>> function. Code:
>>>>
>>>> m1 <- MCMCglmm(cbind(dep1, dep2, dep3) ~ group-1, random =
>>>> ~us(1+meas):id,
>>>>                rcov = ~us(trait):units, data = dat, family =
>>>> c("gaussian",
>>>> "gaussian", "gaussian"),
>>>>                     verbose = FALSE)
>>>>
>>>> summary(m1)
>>>>
>>>> Output:
>>>>
>>>>  Iterations = 3001:12991
>>>>  Thinning interval  = 10
>>>>  Sample size  = 1000
>>>>
>>>>  DIC: 119465.7
>>>>
>>>>  G-structure:  ~us(1 + meas):id
>>>>
>>>>                            post.mean   l-95% CI u-95% CI eff.samp
>>>> (Intercept):(Intercept).id    0.5868  0.0010440  2.54542    6.784
>>>> meas:(Intercept).id          -0.3008 -1.2656335  0.01044    6.621
>>>> (Intercept):meas.id          -0.3008 -1.2656335  0.01044    6.621
>>>> meas:meas.id                  0.1716  0.0004239  0.65286    6.936
>>>>
>>>>  R-structure:  ~us(trait):units
>>>>
>>>>                            post.mean   l-95% CI   u-95% CI eff.samp
>>>> traitdep1:traitdep1.units 2132866.20 2027876.02 2239057.50    911.5
>>>> traitdep2:traitdep1.units 1703387.51 1615965.82 1803474.41   1000.0
>>>> traitdep3:traitdep1.units   -1405.09   -2700.25      60.61    150.3
>>>> traitdep1:traitdep2.units 1703387.51 1615965.82 1803474.41   1000.0
>>>> traitdep2:traitdep2.units 2129068.98 2023232.02 2239145.62   1283.7
>>>> traitdep3:traitdep2.units   -1685.89   -3264.50    -184.62    136.2
>>>> traitdep1:traitdep3.units   -1405.09   -2700.25      60.61    150.3
>>>> traitdep2:traitdep3.units   -1685.89   -3264.50    -184.62    136.2
>>>> traitdep3:traitdep3.units      26.57      23.99      29.55    188.8
>>>>
>>>>  Location effects: cbind(dep1, dep2, dep3) ~ group - 1
>>>>
>>>>        post.mean l-95% CI u-95% CI eff.samp  pMCMC
>>>> groupA     30.69    30.13    31.37    226.0 <0.001 ***
>>>> groupB     41.29    39.97    42.75    122.0 <0.001 ***
>>>> groupC     31.20    29.89    32.50    151.8 <0.001 ***
>>>>
>>>> Thanks in advance!
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From oppela at gmail.com  Fri Feb  3 16:22:28 2017
From: oppela at gmail.com (Claudio)
Date: Fri, 03 Feb 2017 16:22:28 +0100
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <CAJuCY5wb+zfqisAe2T6_3OW-n+Ni9X4A_f7xpag=B5MJiBd6_A@mail.gmail.com>
References: <1485618209.1531.29.camel@gmail.com>
	<CAJuCY5w59JT9tCQZWUX1Q0cvp+i3J1RRyCvN7PhG_uAt9WYd0Q@mail.gmail.com>
	<1485975676.1574.16.camel@gmail.com>
	<CAJuCY5wb+zfqisAe2T6_3OW-n+Ni9X4A_f7xpag=B5MJiBd6_A@mail.gmail.com>
Message-ID: <1486135348.2351.10.camel@gmail.com>

Dear Thierry,
yes, I recorded only once each trait for each individual (i.e., it was
not a longitudinal study).
And, yes, the idea is that each individual has a different effect.
thanks again
Claudio


Il giorno gio, 02/02/2017 alle 10.12 +0100, Thierry Onkelinx ha
scritto:
> Dear Claudio,
> 
> It looks like you have only one observation (of each trait) per
> individual. That is not sufficient to fit (0 + trait | individual).
> Hence the error message.
> 
> Using (1 | individuals) implies that each individual has a effect
> which is common for all traits. Whether that is a relevant assumption
> depends on your experiment. Tip: write the model as an equation for
> each trait. Then see if the random intercept for individual makes
> sense.
> 
> I'm not proficient with MCMCglmm. So I can help you with that.
> 
> Best regards,
> 
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for
> Nature and Forest?
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance?
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner?
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given
> body of data. ~ John Tukey
> 
> 2017-02-01 20:01 GMT+01:00 Claudio <oppela at gmail.com>:
> > Dear Thierry,
> > thanks a lot, it is exactly the kind of suggestion I was looking
> > for!
> > However, when using (0 + traits|individuals) for the random effect
> > of
> > individuals I got the message:
> > "Errore: number of observations (=1431) <= number of random effects
> > (=1431) for term (0 + traits | individuals); the random-effects
> > parameters and the residual variance (or scale parameter) are
> > probably
> > unidentifiable"
> > The models work when I use for the individual part (1|individuals).
> > 
> > A second further question: in order to include in the model a
> > continuous fixed covariate, am I doing the right thing when
> > scripting:
> > 
> > mumo2 <- lmer(value~0 + traits + traits:species + traits:covariate
> > (0 +
> > traits|species:populations) + (1|individuals), mdata, REML=FALSE)
> > 
> > About cbind and MCMCglmm, below there is an example which causes
> > the
> > message:
> > "Error in `[<-.data.frame`(`*tmp*`, , response.names, value = c(1,
> > 2,
> > 3,??: missing values are not allowed in subscripted assignments of
> > data
> > frames"
> > 
> > a = c(1, 2, 3, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 5, 5, 4,
> > 5, 7,
> > 8, 9, 4, 1)?
> > b = c(8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 1, 2, 3, 5, 5, 7, 4, 1, 2,
> > 3, 1,
> > 2, 3, 6, 6)
> > d = c(8, 9, 4, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 2, 3, 1,
> > 2, 3,
> > 5, 5, 7, 6)??
> > s = c("m", "m", "f", "f", "m", "m", "m", "f", "m", "f", "f", "f",
> > "m",
> > "f", "f", "f", "m", "m", "m", "m", "m", "f", "m", "f", "f", "f")?
> > df = data.frame(a, b, d, s)
> > 
> > y<-cbind(a, b, d)
> > prior <- list(R = list(V = 1, nu = 0.002))
> > m <- MCMCglmm(y ~ s, family = "gaussian" , data = df, prior =
> > prior,
> > verbose = FALSE, pl = TRUE)
> > summary(m)
> > 
> > all the best (and thanks again)
> > Claudio
> > 
> > Il giorno lun, 30/01/2017 alle 16.02 +0100, Thierry Onkelinx ha
> > scritto:
> > > Dear Claudio,
> > >
> > > I this you need to add the interaction with traits to all the
> > fixed
> > > and random effects. Otherwise you assume that these have the same
> > > effect for each trait. Note that 0 + traits is identical to
> > traits -
> > > 1.
> > >
> > > mumo1 <- lmer(value~0 + traits + traits:species + (0 +
> > > traits|species:populations) +?(0 + traits|individuals), mdata,
> > > REML=FALSE)
> > >
> > > Your second question needs a reproducible example.
> > >
> > > Best regards,
> > >
> > > ir. Thierry Onkelinx
> > > Instituut voor natuur- en bosonderzoek / Research Institute for
> > > Nature and Forest?
> > > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> > > Assurance?
> > > Kliniekstraat 25
> > > 1070 Anderlecht
> > > Belgium
> > >
> > > To call in the statistician after the experiment is done may be
> > no
> > > more than asking him to perform a post-mortem examination: he may
> > be
> > > able to say what the experiment died of. ~ Sir Ronald Aylmer
> > Fisher
> > > The plural of anecdote is not data. ~ Roger Brinner?
> > > The combination of some data and an aching desire for an answer
> > does
> > > not ensure that a reasonable answer can be extracted from a given
> > > body of data. ~ John Tukey
> > >
> > > 2017-01-28 16:43 GMT+01:00 Claudio <oppela at gmail.com>:
> > > > Hi all.
> > > > I collected six body features (bf1-bf6)from three populations
> > of a
> > > > salamander and from two populations of another sister species
> > of
> > > > salamander.
> > > > I would evaluate how the species (fixed) and population
> > belonging
> > > > (random) affect the body features, by comparing models built
> > with
> > > > lme4.
> > > > For some models, I also want to include bf6 as covariate. Thus,
> > in
> > > > case
> > > > of univariate analyses, some models, for example, could be:
> > > > mo1<-lmer(bf1~species+(1|species:population), data, REML=FALSE)
> > > > mo2<-lmer(bf1~species+bf6+(1|species:population), data,
> > REML=FALSE)
> > > >
> > > > However, I want to fit multivariate models, and my post is
> > about
> > > > this.
> > > > First, I melted the data:
> > > > mdata<-melt(data, id.vars = c("species", "population", "bf6"),
> > > > measure.vars = c("bf1", "bf2","bf3","bf4","bf5"), variable.name
> > =
> > > > "traits)
> > > >
> > > > Now the question.
> > > > 1) Are the multivariate versions of the models mo1 and mo2
> > above
> > > > mumo1<-lmer(value~traits -1 + species + (1|species:populations)
> > +
> > > > (1|individuals), mdata, REML=FALSE)
> > > > mumo1<-lmer(value~traits -1 + species + bf6 +
> > > > (1|species:populations) +
> > > > (1|individuals), mdata, REML=FALSE)
> > > >
> > > > A secondary question, which in case I will move to a new post:
> > > > it seemed to me that building multivariate models with MCMCglmm
> > is
> > > > easier. However, cbind did not work, even without missing
> > values:
> > > > to
> > > > your knowledge, is there any issue?
> > > >
> > > > thanks in advance
> > > > Claudio ?
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >


From wstyler at umich.edu  Fri Feb  3 17:24:44 2017
From: wstyler at umich.edu (Will Styler)
Date: Fri, 3 Feb 2017 11:24:44 -0500
Subject: [R-sig-ME] MCMCglmm Predict failing with "NA/NaN/Inf in foreign
 function call" for binary responses
Message-ID: <CAMCd=SRyoSoPcLCfPmMgt65hBEvrQ2af-jFC76x6hHnnrkL2GQ@mail.gmail.com>

Hello,

After successfully fitting my models, I've been struggling to get predicted
curves for illustration.  I'm working with binary data, with b-splines (to
model change over time), and some random effects, and any time that I use
the predict function in MCMCglmm 2.24, it returns the below error:

> Error in MCMCglmm(fixed = object$Fixed$formula, random =
object$Random$formula, : NA/NaN/Inf in foreign function call (arg 3)

Although my model is rather more complex, here's a toy example returning
the same issue during the "predict" call.

Do you have any advice on how to proceed?  Or, if I'm barking up the wrong
tree, is there an easier approach to getting the model's predictions for a
given set of conditions which I can graph?

Thanks,

Will

-----------------
Will Styler
Post-Doctoral Research Fellow
University of Michigan Department of Linguistics
http://savethevowels.org/will

> library(MCMCglmm)
>
> set.seed(123)
>
> dat <- data.frame(x = rnorm(100), y = sample(c(0,1)),z=as.factor(
seq(1:2)),r1=as.factor(seq(1:20)))
>
> prior = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V =1,n =
1)))
>
> fit <- MCMCglmm(
>
>     fixed = y ~ bs(x)*z,
>
>     random =~r1,
>
>     rcov = ~ units,
>
>     data = dat,
>
>     family = "threshold",
>
>     pr = TRUE, pl = TRUE,
>
>     prior=prior,
>
>     saveX = TRUE,  saveZ = TRUE,
>
>     nitt = 1.3e+4, thin = 10, burnin = 3e+3
>
> )
>
>
> pred_grid <- data.frame(x = seq(-1, 1, length.out =
30),y=0,z=factor(seq(1:2)),r1="1")
>
> predict(fit, newdata = pred_grid)

	[[alternative HTML version deleted]]


From oppela at gmail.com  Sat Feb  4 09:00:33 2017
From: oppela at gmail.com (Claudio)
Date: Sat, 04 Feb 2017 09:00:33 +0100
Subject: [R-sig-ME] multivariate mixed nested model
In-Reply-To: <op.yu01oyaqsgx3xe@armadillo50>
References: <1485618209.1531.29.camel@gmail.com>
	<CAJuCY5w59JT9tCQZWUX1Q0cvp+i3J1RRyCvN7PhG_uAt9WYd0Q@mail.gmail.com>
	<1485975676.1574.16.camel@gmail.com>
	<CAJuCY5wb+zfqisAe2T6_3OW-n+Ni9X4A_f7xpag=B5MJiBd6_A@mail.gmail.com>
	<op.yu01oyaqsgx3xe@armadillo50>
Message-ID: <1486195233.1625.1.camel@gmail.com>

Thanks Paul,
I will try.
all the best
Claudio

Il giorno gio, 02/02/2017 alle 11.52 +0200, Paul Debes ha scritto:
> Hi Claudio
> 
> to make the model work in MCMCglmm, you need to explicitly specify
> the??
> interaction for each trait by adding "trait". This specification
> extends??
> to the dimensions of the prior(s) and distribution(s). If you wish
> to??
> specify covariances between traits (here for the residuals), your
> model??
> could be something like:
> 
> prior <- list(R = list(V = diag(3), nu = rep(0.002,3)))
> 
> m <- MCMCglmm(cbind(a,b,d) ~ -1 + trait*s,
> 	rcov = ~us(trait):units,
> 	family = rep("gaussian",3),
> 	data = df,
> 	prior = prior,
> 	verbose = FALSE,
> 	pl = TRUE)
> 
> summary(m)
> 
> Best,
> Paul
> 
> 
> 
> ? On Thu, 02 Feb 2017 11:12:57 +0200, Thierry Onkelinx??
> <thierry.onkelinx at inbo.be> wrote:
> 
> > 
> > Dear Claudio,
> > 
> > It looks like you have only one observation (of each trait) per??
> > individual.
> > That is not sufficient to fit (0 + trait | individual). Hence the
> > error
> > message.
> > 
> > Using (1 | individuals) implies that each individual has a effect
> > which??
> > is
> > common for all traits. Whether that is a relevant assumption
> > depends on
> > your experiment. Tip: write the model as an equation for each
> > trait. Then
> > see if the random intercept for individual makes sense.
> > 
> > I'm not proficient with MCMCglmm. So I can help you with that.
> > 
> > Best regards,
> > 
> > 
> > 
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for
> > Nature??
> > and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> > Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> > 
> > To call in the statistician after the experiment is done may be no
> > more
> > than asking him to perform a post-mortem examination: he may be
> > able to??
> > say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer
> > does not
> > ensure that a reasonable answer can be extracted from a given body
> > of??
> > data.
> > ~ John Tukey
> > 
> > 2017-02-01 20:01 GMT+01:00 Claudio <oppela at gmail.com>:
> > 
> > > 
> > > Dear Thierry,
> > > thanks a lot, it is exactly the kind of suggestion I was looking
> > > for!
> > > However, when using (0 + traits|individuals) for the random
> > > effect of
> > > individuals I got the message:
> > > "Errore: number of observations (=1431) <= number of random
> > > effects
> > > (=1431) for term (0 + traits | individuals); the random-effects
> > > parameters and the residual variance (or scale parameter) are
> > > probably
> > > unidentifiable"
> > > The models work when I use for the individual part
> > > (1|individuals).
> > > 
> > > A second further question: in order to include in the model a
> > > continuous fixed covariate, am I doing the right thing when
> > > scripting:
> > > 
> > > mumo2 <- lmer(value~0 + traits + traits:species +
> > > traits:covariate (0 +
> > > traits|species:populations) + (1|individuals), mdata, REML=FALSE)
> > > 
> > > About cbind and MCMCglmm, below there is an example which causes
> > > the
> > > message:
> > > "Error in `[<-.data.frame`(`*tmp*`, , response.names, value =
> > > c(1, 2,
> > > 3,??: missing values are not allowed in subscripted assignments
> > > of data
> > > frames"
> > > 
> > > a = c(1, 2, 3, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 5, 5, 4,
> > > 5, 7,
> > > 8, 9, 4, 1)
> > > b = c(8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 1, 2, 3, 5, 5, 7, 4, 1, 2,
> > > 3, 1,
> > > 2, 3, 6, 6)
> > > d = c(8, 9, 4, 5, 5, 7, 8, 9, 4, 5, 7, 8, 9, 4, 1, 2, 3, 2, 3, 1,
> > > 2, 3,
> > > 5, 5, 7, 6)
> > > s = c("m", "m", "f", "f", "m", "m", "m", "f", "m", "f", "f", "f",
> > > "m",
> > > "f", "f", "f", "m", "m", "m", "m", "m", "f", "m", "f", "f", "f")
> > > df = data.frame(a, b, d, s)
> > > 
> > > y<-cbind(a, b, d)
> > > prior <- list(R = list(V = 1, nu = 0.002))
> > > m <- MCMCglmm(y ~ s, family = "gaussian" , data = df, prior =
> > > prior,
> > > verbose = FALSE, pl = TRUE)
> > > summary(m)
> > > 
> > > all the best (and thanks again)
> > > Claudio
> > > 
> > > Il giorno lun, 30/01/2017 alle 16.02 +0100, Thierry Onkelinx ha
> > > scritto:
> > > > 
> > > > Dear Claudio,
> > > > 
> > > > I this you need to add the interaction with traits to all the
> > > > fixed
> > > > and random effects. Otherwise you assume that these have the
> > > > same
> > > > effect for each trait. Note that 0 + traits is identical to
> > > > traits -
> > > > 1.
> > > > 
> > > > mumo1 <- lmer(value~0 + traits + traits:species + (0 +
> > > > traits|species:populations) + (0 + traits|individuals), mdata,
> > > > REML=FALSE)
> > > > 
> > > > Your second question needs a reproducible example.
> > > > 
> > > > Best regards,
> > > > 
> > > > ir. Thierry Onkelinx
> > > > Instituut voor natuur- en bosonderzoek / Research Institute for
> > > > Nature and Forest
> > > > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> > > > Assurance
> > > > Kliniekstraat 25
> > > > 1070 Anderlecht
> > > > Belgium
> > > > 
> > > > To call in the statistician after the experiment is done may be
> > > > no
> > > > more than asking him to perform a post-mortem examination: he
> > > > may be
> > > > able to say what the experiment died of. ~ Sir Ronald Aylmer
> > > > Fisher
> > > > The plural of anecdote is not data. ~ Roger Brinner
> > > > The combination of some data and an aching desire for an answer
> > > > does
> > > > not ensure that a reasonable answer can be extracted from a
> > > > given
> > > > body of data. ~ John Tukey
> > > > 
> > > > 2017-01-28 16:43 GMT+01:00 Claudio <oppela at gmail.com>:
> > > > > 
> > > > > Hi all.
> > > > > I collected six body features (bf1-bf6)from three populations
> > > > > of a
> > > > > salamander and from two populations of another sister species
> > > > > of
> > > > > salamander.
> > > > > I would evaluate how the species (fixed) and population
> > > > > belonging
> > > > > (random) affect the body features, by comparing models built
> > > > > with
> > > > > lme4.
> > > > > For some models, I also want to include bf6 as covariate.
> > > > > Thus, in
> > > > > case
> > > > > of univariate analyses, some models, for example, could be:
> > > > > mo1<-lmer(bf1~species+(1|species:population), data,
> > > > > REML=FALSE)
> > > > > mo2<-lmer(bf1~species+bf6+(1|species:population), data,
> > > > > REML=FALSE)
> > > > > 
> > > > > However, I want to fit multivariate models, and my post is
> > > > > about
> > > > > this.
> > > > > First, I melted the data:
> > > > > mdata<-melt(data, id.vars = c("species", "population",
> > > > > "bf6"),
> > > > > measure.vars = c("bf1", "bf2","bf3","bf4","bf5"),
> > > > > variable.name =
> > > > > "traits)
> > > > > 
> > > > > Now the question.
> > > > > 1) Are the multivariate versions of the models mo1 and mo2
> > > > > above
> > > > > mumo1<-lmer(value~traits -1 + species +
> > > > > (1|species:populations) +
> > > > > (1|individuals), mdata, REML=FALSE)
> > > > > mumo1<-lmer(value~traits -1 + species + bf6 +
> > > > > (1|species:populations) +
> > > > > (1|individuals), mdata, REML=FALSE)
> > > > > 
> > > > > A secondary question, which in case I will move to a new
> > > > > post:
> > > > > it seemed to me that building multivariate models with
> > > > > MCMCglmm is
> > > > > easier. However, cbind did not work, even without missing
> > > > > values:
> > > > > to
> > > > > your knowledge, is there any issue?
> > > > > 
> > > > > thanks in advance
> > > > > Claudio
> > > > > 
> > > > > _______________________________________________
> > > > > R-sig-mixed-models at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From tibor at linguistics.rub.de  Sat Feb  4 16:38:07 2017
From: tibor at linguistics.rub.de (Tibor Kiss)
Date: Sat, 4 Feb 2017 16:38:07 +0100
Subject: [R-sig-ME] Question concerning the reduction of random effects
Message-ID: <9AD31612-DBA0-4B40-80EF-1A05D1594492@linguistics.rub.de>

Hello everybody,

I have a question that might perhaps sound weird, but I haven't found anything on this yet, so maybe someone can enlighten me here.

I am working with a BGLMM (random intercept) that contains the random effect "noun" (basically, a noun occurring in a natural language sentence from a sample) with 1.302 levels. The high number of levels is due to the fact that the sample contains this many different nouns in the relevant position of the clause. 

After determining the variances of the individual 1.302 nouns, there are only 54 nouns left which do not contain 0 in the 95 % confidence interval. So, these are nouns that are actually interesting. I have a hunch now that this reduced number of nouns also influences some of the slopes, but I cannot test this. The dataset contains only 2.284 observations. Thus, the total number of random effects is larger than the number of observations when tested against a binary feature. 

I would like to find a way to reduce the random effects to the ones which have shown relevant in the random intercept model, and would like to use the reduced set for a random slope model. It strikes me that this is tampering with the data, unless there is a principled way of selecting a subset from the set of random effects. So, if there is a principled way, I would appreciate learning about it. 



With kind regards 

Tibor

 


From jdpo223 at g.uky.edu  Sat Feb  4 17:10:17 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Sat, 4 Feb 2017 11:10:17 -0500
Subject: [R-sig-ME] Question concerning the reduction of random effects
In-Reply-To: <9AD31612-DBA0-4B40-80EF-1A05D1594492@linguistics.rub.de>
References: <9AD31612-DBA0-4B40-80EF-1A05D1594492@linguistics.rub.de>
Message-ID: <CAFW8Byrb6S__v3WttLHfqsz82B2oNU6t4cu7DFvOqpbaBqSf0A@mail.gmail.com>

Tibor,

If I understand you correctly you've included each group as a fixed effect
to get the confidence intervals and done a an enormous number of hypotheses
tests. If that's the case you really can't trust the results.  That many
categorical fixed effects for a nonlinear outcome will produce biased
coefficients and standard errors. Even with as few as ten groups you start
to see bias. So just because something has zero in the CI on a group fixed
effect doesn't mean that the group does not, in reality,  have a
significant mean difference from the population average.

On Feb 4, 2017 10:38 AM, "Tibor Kiss" <tibor at linguistics.rub.de> wrote:

> Hello everybody,
>
> I have a question that might perhaps sound weird, but I haven't found
> anything on this yet, so maybe someone can enlighten me here.
>
> I am working with a BGLMM (random intercept) that contains the random
> effect "noun" (basically, a noun occurring in a natural language sentence
> from a sample) with 1.302 levels. The high number of levels is due to the
> fact that the sample contains this many different nouns in the relevant
> position of the clause.
>
> After determining the variances of the individual 1.302 nouns, there are
> only 54 nouns left which do not contain 0 in the 95 % confidence interval.
> So, these are nouns that are actually interesting. I have a hunch now that
> this reduced number of nouns also influences some of the slopes, but I
> cannot test this. The dataset contains only 2.284 observations. Thus, the
> total number of random effects is larger than the number of observations
> when tested against a binary feature.
>
> I would like to find a way to reduce the random effects to the ones which
> have shown relevant in the random intercept model, and would like to use
> the reduced set for a random slope model. It strikes me that this is
> tampering with the data, unless there is a principled way of selecting a
> subset from the set of random effects. So, if there is a principled way, I
> would appreciate learning about it.
>
>
>
> With kind regards
>
> Tibor
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From tibor at linguistics.rub.de  Sat Feb  4 17:22:07 2017
From: tibor at linguistics.rub.de (Tibor Kiss)
Date: Sat, 4 Feb 2017 17:22:07 +0100
Subject: [R-sig-ME] Question concerning the reduction of random effects
In-Reply-To: <CAFW8Byrb6S__v3WttLHfqsz82B2oNU6t4cu7DFvOqpbaBqSf0A@mail.gmail.com>
References: <9AD31612-DBA0-4B40-80EF-1A05D1594492@linguistics.rub.de>
	<CAFW8Byrb6S__v3WttLHfqsz82B2oNU6t4cu7DFvOqpbaBqSf0A@mail.gmail.com>
Message-ID: <9D17A39D-59CF-4D66-B633-F8EDA80B710F@linguistics.rub.de>

Hi John,

no, I have extracted the conditional variances with ranef(MODEL, condVar = T) as well as attr(MODEL.randoms[[1]], "postVar"), determined the sqrt(variances)*1,96 and calculated whether abs(intercept) - sqrt(variance)*1,96 > 0. 

I treat nouns only as random effects, since they are sampled from an infinite population.

With kind regards

Tibor



 

Am 04.02.2017 um 17:10 schrieb Poe, John <jdpo223 at g.uky.edu>:

> Tibor, 
> 
> If I understand you correctly you've included each group as a fixed effect to get the confidence intervals and done a an enormous number of hypotheses tests. If that's the case you really can't trust the results.  That many categorical fixed effects for a nonlinear outcome will produce biased coefficients and standard errors. Even with as few as ten groups you start to see bias. So just because something has zero in the CI on a group fixed effect doesn't mean that the group does not, in reality,  have a significant mean difference from the population average.   
> 
> On Feb 4, 2017 10:38 AM, "Tibor Kiss" <tibor at linguistics.rub.de> wrote:
> Hello everybody,
> 
> I have a question that might perhaps sound weird, but I haven't found anything on this yet, so maybe someone can enlighten me here.
> 
> I am working with a BGLMM (random intercept) that contains the random effect "noun" (basically, a noun occurring in a natural language sentence from a sample) with 1.302 levels. The high number of levels is due to the fact that the sample contains this many different nouns in the relevant position of the clause.
> 
> After determining the variances of the individual 1.302 nouns, there are only 54 nouns left which do not contain 0 in the 95 % confidence interval. So, these are nouns that are actually interesting. I have a hunch now that this reduced number of nouns also influences some of the slopes, but I cannot test this. The dataset contains only 2.284 observations. Thus, the total number of random effects is larger than the number of observations when tested against a binary feature.
> 
> I would like to find a way to reduce the random effects to the ones which have shown relevant in the random intercept model, and would like to use the reduced set for a random slope model. It strikes me that this is tampering with the data, unless there is a principled way of selecting a subset from the set of random effects. So, if there is a principled way, I would appreciate learning about it.
> 
> 
> 
> With kind regards
> 
> Tibor
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From tibor at linguistics.rub.de  Sat Feb  4 17:33:30 2017
From: tibor at linguistics.rub.de (Tibor Kiss)
Date: Sat, 4 Feb 2017 17:33:30 +0100
Subject: [R-sig-ME] Question concerning the reduction of random effects
In-Reply-To: <9D17A39D-59CF-4D66-B633-F8EDA80B710F@linguistics.rub.de>
References: <9AD31612-DBA0-4B40-80EF-1A05D1594492@linguistics.rub.de>
	<CAFW8Byrb6S__v3WttLHfqsz82B2oNU6t4cu7DFvOqpbaBqSf0A@mail.gmail.com>
	<9D17A39D-59CF-4D66-B633-F8EDA80B710F@linguistics.rub.de>
Message-ID: <CDD7CA86-9CD6-42DF-9300-51B8EE0D2776@linguistics.rub.de>

Hi,

perhaps I should add for greater clarity that I have calculated the values below for each level of the random effect "noun". Altogether, the random effect has a standard deviation of 3.85 on an intercept of 6.95. 

I have assumed that a level of the random effect does not have an effect if sqrt(level)*1,96 includes 0 (because then in a binary model, it can have a positive as well as a negative effect on the intercept). I am only interested in those levels that show a unique negative influence. Thus the level with the highest negative value (-7.93) may reduce the likelihood of a positive outcome from 99.9 to a mere 27.3 %.

With kind regards

Tibor
  


 

Am 04.02.2017 um 17:22 schrieb Tibor Kiss <tibor at linguistics.rub.de>:

> Hi John,
> 
> no, I have extracted the conditional variances with ranef(MODEL, condVar = T) as well as attr(MODEL.randoms[[1]], "postVar"), determined the sqrt(variances)*1,96 and calculated whether abs(intercept) - sqrt(variance)*1,96 > 0. 
> 
> I treat nouns only as random effects, since they are sampled from an infinite population.
> 
> With kind regards
> 
> Tibor
> 
> 
> 
>  
> 
> Am 04.02.2017 um 17:10 schrieb Poe, John <jdpo223 at g.uky.edu>:
> 
>> Tibor, 
>> 
>> If I understand you correctly you've included each group as a fixed effect to get the confidence intervals and done a an enormous number of hypotheses tests. If that's the case you really can't trust the results.  That many categorical fixed effects for a nonlinear outcome will produce biased coefficients and standard errors. Even with as few as ten groups you start to see bias. So just because something has zero in the CI on a group fixed effect doesn't mean that the group does not, in reality,  have a significant mean difference from the population average.   
>> 
>> On Feb 4, 2017 10:38 AM, "Tibor Kiss" <tibor at linguistics.rub.de> wrote:
>> Hello everybody,
>> 
>> I have a question that might perhaps sound weird, but I haven't found anything on this yet, so maybe someone can enlighten me here.
>> 
>> I am working with a BGLMM (random intercept) that contains the random effect "noun" (basically, a noun occurring in a natural language sentence from a sample) with 1.302 levels. The high number of levels is due to the fact that the sample contains this many different nouns in the relevant position of the clause.
>> 
>> After determining the variances of the individual 1.302 nouns, there are only 54 nouns left which do not contain 0 in the 95 % confidence interval. So, these are nouns that are actually interesting. I have a hunch now that this reduced number of nouns also influences some of the slopes, but I cannot test this. The dataset contains only 2.284 observations. Thus, the total number of random effects is larger than the number of observations when tested against a binary feature.
>> 
>> I would like to find a way to reduce the random effects to the ones which have shown relevant in the random intercept model, and would like to use the reduced set for a random slope model. It strikes me that this is tampering with the data, unless there is a principled way of selecting a subset from the set of random effects. So, if there is a principled way, I would appreciate learning about it.
>> 
>> 
>> 
>> With kind regards
>> 
>> Tibor
>> 
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Sat Feb  4 19:23:57 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Sat, 4 Feb 2017 13:23:57 -0500
Subject: [R-sig-ME] Question concerning the reduction of random effects
In-Reply-To: <CDD7CA86-9CD6-42DF-9300-51B8EE0D2776@linguistics.rub.de>
References: <9AD31612-DBA0-4B40-80EF-1A05D1594492@linguistics.rub.de>
	<CAFW8Byrb6S__v3WttLHfqsz82B2oNU6t4cu7DFvOqpbaBqSf0A@mail.gmail.com>
	<9D17A39D-59CF-4D66-B633-F8EDA80B710F@linguistics.rub.de>
	<CDD7CA86-9CD6-42DF-9300-51B8EE0D2776@linguistics.rub.de>
Message-ID: <CAFW8ByorNDkPU4=Fr3GFKFnAdFaXnGyGuW6Qj8spATdyz9KBCg@mail.gmail.com>

Wow, that's a lot of random effects parameters to deal with.

You could use likelihood ratio tests to decide which nouns aren't having an
impact on model fit but with cross classified levels the order in which you
do the tests can matter if the nouns are correlated.

There are three basic ways to go about it when you have a lot of parameters.

 1) You can add a random effect and use an LR test against a model without
any other random intercepts and cycle your way through all of the groups.
This is a problem if groups are correlated because two random effects might
essentially be collinear so the test can be too generous with cross
classified random effects tested one at a time. It will provide you a
decent way to thin your initial list because it's the most conservative way
you can test impact on model fit of these three approaches. A random effect
shouldn't be rejected from this version of the test and show an impact on
the next version unless something is seriously wrong with your data, model,
or estimator.

2) you can use a leave one out approach where you fit every random
intercept except one and compare it to a full model with all random
intercepts using an LR test. Then cycle through the list like a jackknife.
My guess is you'll have problems with this because of the number of
parameters you have.  Try version 1 first to toss out random effects that
dont matter and then use this approach to test the remainders. Maybe you
can do some version of factor analysis to reduce the number of dimensions
in the model if you still have too many.  If nouns are correlated then just
combine them into factor loadings and do random effects with those
aggregations.

3) you can cycle through all possible combinations of random effects and do
bayesian model averaging to figure out what percentage of the possible
models a noun matters according to some model fit statistic. You can also
combine this version with version 1 or with factor analysis to do an
initial reduction in parameters and make estimation more manageable.

As a general caution you should be very certain that your random effects
approximations are accurate in this case. I'm guessing you're using some
variant of MCMC because gauss quadrature would fail miserably if it had to
estimate that many random effects. If you're trying to use PQL or a Laplace
approximation here then you are very likely to have problems with accuracy
which will bias the LR tests toward no effect. This will be more likely to
happen if your nouns are correlated because the omitted levels in version 1
will cause distortions from normality in the shape of the random effects
parameters you leave in the model.

Hope that makes sense.  I'm typing it out on my phone.

On Feb 4, 2017 12:30 PM, "Tibor Kiss" <tibor at linguistics.rub.de> wrote:

> Hi,
>
> perhaps I should add for greater clarity that I have calculated the values
> below for each level of the random effect "noun". Altogether, the random
> effect has a standard deviation of 3.85 on an intercept of 6.95.
>
> I have assumed that a level of the random effect does not have an effect
> if sqrt(level)*1,96 includes 0 (because then in a binary model, it can have
> a positive as well as a negative effect on the intercept). I am only
> interested in those levels that show a unique negative influence. Thus the
> level with the highest negative value (-7.93) may reduce the likelihood of
> a positive outcome from 99.9 to a mere 27.3 %.
>
> With kind regards
>
> Tibor
>
>
>
>
>
> Am 04.02.2017 um 17:22 schrieb Tibor Kiss <tibor at linguistics.rub.de>:
>
> > Hi John,
> >
> > no, I have extracted the conditional variances with ranef(MODEL, condVar
> = T) as well as attr(MODEL.randoms[[1]], "postVar"), determined the
> sqrt(variances)*1,96 and calculated whether abs(intercept) -
> sqrt(variance)*1,96 > 0.
> >
> > I treat nouns only as random effects, since they are sampled from an
> infinite population.
> >
> > With kind regards
> >
> > Tibor
> >
> >
> >
> >
> >
> > Am 04.02.2017 um 17:10 schrieb Poe, John <jdpo223 at g.uky.edu>:
> >
> >> Tibor,
> >>
> >> If I understand you correctly you've included each group as a fixed
> effect to get the confidence intervals and done a an enormous number of
> hypotheses tests. If that's the case you really can't trust the results.
> That many categorical fixed effects for a nonlinear outcome will produce
> biased coefficients and standard errors. Even with as few as ten groups you
> start to see bias. So just because something has zero in the CI on a group
> fixed effect doesn't mean that the group does not, in reality,  have a
> significant mean difference from the population average.
> >>
> >> On Feb 4, 2017 10:38 AM, "Tibor Kiss" <tibor at linguistics.rub.de> wrote:
> >> Hello everybody,
> >>
> >> I have a question that might perhaps sound weird, but I haven't found
> anything on this yet, so maybe someone can enlighten me here.
> >>
> >> I am working with a BGLMM (random intercept) that contains the random
> effect "noun" (basically, a noun occurring in a natural language sentence
> from a sample) with 1.302 levels. The high number of levels is due to the
> fact that the sample contains this many different nouns in the relevant
> position of the clause.
> >>
> >> After determining the variances of the individual 1.302 nouns, there
> are only 54 nouns left which do not contain 0 in the 95 % confidence
> interval. So, these are nouns that are actually interesting. I have a hunch
> now that this reduced number of nouns also influences some of the slopes,
> but I cannot test this. The dataset contains only 2.284 observations. Thus,
> the total number of random effects is larger than the number of
> observations when tested against a binary feature.
> >>
> >> I would like to find a way to reduce the random effects to the ones
> which have shown relevant in the random intercept model, and would like to
> use the reduced set for a random slope model. It strikes me that this is
> tampering with the data, unless there is a principled way of selecting a
> subset from the set of random effects. So, if there is a principled way, I
> would appreciate learning about it.
> >>
> >>
> >>
> >> With kind regards
> >>
> >> Tibor
> >>
> >>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From rdiaz02 at gmail.com  Mon Feb  6 10:39:36 2017
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Mon, 06 Feb 2017 10:39:36 +0100
Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
In-Reply-To: <DB6PR0301MB23117470689224BE1902C112D24D0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
References: <mailman.1890.1485942007.4316.r-sig-mixed-models@r-project.org>
	<DB6PR0301MB23117470689224BE1902C112D24D0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
Message-ID: <874m078xpj.fsf@gmail.com>


Hi Theodore,

If you want a reference for an example with lmer, Faraway's book,
"Extending the Linear Model with R: Generalized Linear, Mixed Effects and
Nonparametric Regression Models, 2nd ed.", on section 11.3 contains an
example on using lmer with multiple responses. But this is basically the
answer that Thierry gave you (and Thierry's answer is adapted to your own
problem).

Best,


R.



On Wed, 01-02-2017, at 15:44, Houslay, Tom <T.Houslay at exeter.ac.uk> wrote:
> Hi Theodore, just in case it's of interest, there is another option - ASReml (commercial software from VSNi) can fit the type of model you are looking for, with more complex variance structures (and it has an R interface). This thread from the forum might be informative in terms of how to set up such a model:
>
> http://www.vsni.co.uk/forum/viewtopic.php?t=1202
>
> Cheers (and good luck!)
>
> Tom
>
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Sent: 01 February 2017 09:40
> To: r-sig-mixed-models at r-project.org
> Subject: R-sig-mixed-models Digest, Vol 122, Issue 1
>
>
>
> Date: Wed, 01 Feb 2017 10:37:44 +0200
> From: Theodore Lytras <thlytras at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Random intercept/slopes on two correlated outcomes
> Message-ID: <3197712.2r4pMF0lQW at equinox2>
> Content-Type: text/plain; charset="us-ascii"
>
> Hi all,
>
> I have repeated measures on individuals, and I'm fitting two LMMs with random
> intercepts and slopes per participant, on two outcomes (Y1, Y2) as follows:
>
> library(lme4)
> m1 <- lmer(Y1 ~ age + X + (age | id), data=dat)
> m2 <- lmer(Y2 ~ age + X + (age | id), data=dat)
>
> Fixed covariates for the two outcomes are the same, and id = participant ID.
>
> However, my two continuous outcomes Y1 and Y2 are correlated (highly), thus I
> would like to jointly model them (including estimating their correlation).
>
> What is the appropriate way to do so in this case? Can lme4 do it, or do I
> have to resort to MCMCglmm or JAGS? Could someone point me in the right
> direction (for either lme4, MCMCglmm or JAGS), including any helpful papers,
> guides, etc ??
>
> Thank you,
>
> Theodore Lytras
>
> Epidemiologist, PhD student
> Hellenic Centre for Disease Control and Prevention
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From rdiaz02 at gmail.com  Tue Feb  7 18:07:21 2017
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Tue, 07 Feb 2017 18:07:21 +0100
Subject: [R-sig-ME] random slope by treatment interaction: specification
Message-ID: <87lgtihquu.fsf@gmail.com>


Dear All,

I want to fit a model with a specification not unlike that given in Ben Bolker's
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification
the entry that says

x*site + (x | site:block)

"fixed effect variation of slope and intercept varying among sites and
random variation of slope and intercept among blocks within sites".


In my case, however, I have a fixed-effects treatment, not a
(random-effect) site and blocks are not nested within treatment (they are
crossed). And I am not sure what is the way to model this.


I think a model like

x*trt + (x | trt:block)

is not really what I want: here, all the random slopes (intercepts) are
modelled as coming from the same distribution, regardless of treatment.


I think a specification like

x*trt + (x*trt | block)

is closer to what I want: for each block (not trt by block combination) I
get distributions of slopes (intercepts) that might have a different
variance for each trt.

In addition, it seems (to me) to make some sort of sense to specify the
same interaction in the fixed and random effects part (yes, a fixed by
random interaction ought to be a random effect, but I care about the
interactions between the fixed treatment and the x continuous covariate).


Is the second specification sensible?


Thanks,


R.


P.S. The actual models, with both specifications, sometimes run into
convergence problems and I might be overfitting the data (e.g., huge
correlations in the random effects estimates). But I think that is
something I'd need to deal with once I really figure out the model to use.



--
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From bbolker at gmail.com  Tue Feb  7 19:35:54 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Feb 2017 13:35:54 -0500
Subject: [R-sig-ME] random slope by treatment interaction: specification
In-Reply-To: <87lgtihquu.fsf@gmail.com>
References: <87lgtihquu.fsf@gmail.com>
Message-ID: <CABghstSoLe1xQDFj-Y3-7wbFBYqp+MTY=0kJ_GkChmVp85eZqg@mail.gmail.com>

On Tue, Feb 7, 2017 at 12:07 PM, Ramon Diaz-Uriarte <rdiaz02 at gmail.com> wrote:
>
> Dear All,
>
> I want to fit a model with a specification not unlike that given in Ben Bolker's
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification
> the entry that says
>
> x*site + (x | site:block)
>
> "fixed effect variation of slope and intercept varying among sites and
> random variation of slope and intercept among blocks within sites".
>
>
> In my case, however, I have a fixed-effects treatment, not a
> (random-effect) site and blocks are not nested within treatment (they are
> crossed). And I am not sure what is the way to model this.
>
>
> I think a model like
>
> x*trt + (x | trt:block)
>
> is not really what I want: here, all the random slopes (intercepts) are
> modelled as coming from the same distribution, regardless of treatment.
>
>
> I think a specification like
>
> x*trt + (x*trt | block)
>
> is closer to what I want: for each block (not trt by block combination) I
> get distributions of slopes (intercepts) that might have a different
> variance for each trt.
>
> In addition, it seems (to me) to make some sort of sense to specify the
> same interaction in the fixed and random effects part (yes, a fixed by
> random interaction ought to be a random effect, but I care about the
> interactions between the fixed treatment and the x continuous covariate).
>
>
> Is the second specification sensible?
>

  Yes, if you could in principle estimate x*trt for every block (or
most blocks), i.e. there are measurements for multiple combinations of
x and trt in every block, then ~ x*trt + (x*trt|block) is sensible
[again, *in principle*].  But your PS is relevant - it may well not
make practical statistical sense to do so.

  You might be interested in https://github.com/dmbates/RePsychLing ...


> P.S. The actual models, with both specifications, sometimes run into
> convergence problems and I might be overfitting the data (e.g., huge
> correlations in the random effects estimates). But I think that is
> something I'd need to deal with once I really figure out the model to use.
> Spain


From rdiaz02 at gmail.com  Tue Feb  7 22:28:38 2017
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Tue, 07 Feb 2017 22:28:38 +0100
Subject: [R-sig-ME] random slope by treatment interaction: specification
In-Reply-To: <CABghstSoLe1xQDFj-Y3-7wbFBYqp+MTY=0kJ_GkChmVp85eZqg@mail.gmail.com>
References: <87lgtihquu.fsf@gmail.com>
	<CABghstSoLe1xQDFj-Y3-7wbFBYqp+MTY=0kJ_GkChmVp85eZqg@mail.gmail.com>
Message-ID: <87k291itbt.fsf@gmail.com>

Dear Ben,


On Tue, 07-02-2017, at 18:35, Ben Bolker <bbolker at gmail.com> wrote:
> On Tue, Feb 7, 2017 at 12:07 PM, Ramon Diaz-Uriarte <rdiaz02 at gmail.com> wrote:
>>
>> Dear All,
>>
>> I want to fit a model with a specification not unlike that given in Ben Bolker's
>> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification
>> the entry that says
>>
>> x*site + (x | site:block)
>>
>> "fixed effect variation of slope and intercept varying among sites and
>> random variation of slope and intercept among blocks within sites".
>>
>>
>> In my case, however, I have a fixed-effects treatment, not a
>> (random-effect) site and blocks are not nested within treatment (they are
>> crossed). And I am not sure what is the way to model this.
>>
>>
>> I think a model like
>>
>> x*trt + (x | trt:block)
>>
>> is not really what I want: here, all the random slopes (intercepts) are
>> modelled as coming from the same distribution, regardless of treatment.
>>
>>
>> I think a specification like
>>
>> x*trt + (x*trt | block)
>>
>> is closer to what I want: for each block (not trt by block combination) I
>> get distributions of slopes (intercepts) that might have a different
>> variance for each trt.
>>
>> In addition, it seems (to me) to make some sort of sense to specify the
>> same interaction in the fixed and random effects part (yes, a fixed by
>> random interaction ought to be a random effect, but I care about the
>> interactions between the fixed treatment and the x continuous covariate).
>>
>>
>> Is the second specification sensible?
>>
>
>   Yes, if you could in principle estimate x*trt for every block (or
> most blocks), i.e. there are measurements for multiple combinations of
> x and trt in every block, then ~ x*trt + (x*trt|block) is sensible


Yes, I do: I have about 190 (never less than 180) measures for each
block, with values of x that span the range of x's considered.

> [again, *in principle*].  But your PS is relevant - it may well not
> make practical statistical sense to do so.
>

But the convergence problems are also happening in the

x*trt + (x | trt:block)

specification, so I think it might be something else.

Actually, the full design is slightly more complex, and contains a "unit"
random effect, crossed with the block effect. This is a balanced design,
with 190 units measured under all the combinations of two treatments by 16
blocks (i.e., 32 measures per unit so a total of 6080 measures, except for
a few NAs ---24 total). Each unit is also characterized by an x.

I am modeling (at the moment) binomial data, and there could be
overdispersion, and the relationship between the binomial response and the
x seems either week or widely variable between blocks and treatment
combinations. And the convergence problems tend to be somewhat ameliorated
if I use uncorrelated random slopes and intercepts.


>   You might be interested in https://github.com/dmbates/RePsychLing ...
>

Thanks! The paper seems most pertinet; reading for the morning commute. 


Best,

R.

>
>> P.S. The actual models, with both specifications, sometimes run into
>> convergence problems and I might be overfitting the data (e.g., huge
>> correlations in the random effects estimates). But I think that is
>> something I'd need to deal with once I really figure out the model to use.
>> Spain


--
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From RobyJoehanes at hsl.harvard.edu  Wed Feb  8 19:51:39 2017
From: RobyJoehanes at hsl.harvard.edu (Roby Joehanes)
Date: Wed, 8 Feb 2017 18:51:39 +0000
Subject: [R-sig-ME] Patch for pedigreemm 0.3-3 plus questions
Message-ID: <05B4E90C30995F45B8E8D5506ADB2775649E6297@EXCH-MAILBOX01.hebrewseniorlife.local>

Dear all:

Attached please find the patch for pedigreemm 0.3-3, with the following changes:
1. Control options are now passed through to the optimizeLmer / optimizeGlmer, including optimizer, calc.derivs, etc. This saves about 15% of time.
2. Allowing direct matrix specification on pedigree. This will allow broader application in genetics, such as allowing cryptic relatedness to stand in as pedigree matrix.

A few questions from me. I think pedigreemm tries to call lmer / glmer once to get @pp (for Zt, primarily, but also X, Lambdat, and Lind), @resp (only for REML), @flist and @Gp, then followed up with optimizeLmer or optimizeGlmer. I think it is a big waste of time since most of these can be constructed offline (i.e., without actually computing the results), like in pedigreemm version 1.1 or so. Is there a way in lme4 package to do that instead of calling lmer / glmer? Is lme4::lFormula / lme4::glFormula the right way? Did I overlook something?

Thank you!

Sincerely,
Roby



----------------------------------------------------------------------
CONFIDENTIAL NOTICE:

This electronic mail transmission contains confidential information 
including Protected Health Information (PHI) that is legally privileged. 
If you are not the intended recipient, or designee, you are hereby 
notified that any disclosure, copying, distribution or use of any and
all attachments to this transmission is STRICTLY PROHIBITED. If you 
have received this transmission in error, please notify the sender 
immediately to arrange for return or destruction of these documents.

From RobyJoehanes at hsl.harvard.edu  Wed Feb  8 20:20:38 2017
From: RobyJoehanes at hsl.harvard.edu (Roby Joehanes)
Date: Wed, 8 Feb 2017 19:20:38 +0000
Subject: [R-sig-ME] Patch for pedigreemm 0.3-3 plus questions
In-Reply-To: <05B4E90C30995F45B8E8D5506ADB2775649E6297@EXCH-MAILBOX01.hebrewseniorlife.local>
References: <05B4E90C30995F45B8E8D5506ADB2775649E6297@EXCH-MAILBOX01.hebrewseniorlife.local>
Message-ID: <05B4E90C30995F45B8E8D5506ADB2775649E6341@EXCH-MAILBOX01.hebrewseniorlife.local>

Dear all:

It looks like lme4::lFormula or lme4::glFormula works. The time savings is about 40% now. Here is the code. If this code gets the blessings of the maintainers, I wonder if this code could be incorporated into the official pedigreemm.

Sincerely,
Roby

# Modified pedigreemm source
# Based on pedigreemm 0.3-3
# By Roby Joehanes

# What is modified:
# 1. Allowing optimizer options to pass through
# 2. Allow direct specification of pedigree matrix
# 3. Shortcut to reconstruct necessary matrices instead of calling lmer/glmer

pedigreemm <-
		function(formula, data, family = NULL, REML = TRUE, pedigree = list(),
				control = list(), start = NULL, verbose = FALSE, 
				subset, weights, na.action, offset, contrasts = NULL,
				model = TRUE, x = TRUE, ...)
{
	gaus <- FALSE
	if (is.null(family)) {
		gaus <- TRUE
	} else {
		## copied from glm()
		if (is.character(family)) 
			family <- get(family, mode = "function", envir = parent.frame())
		if (is.function(family)) 
			family <- family()
		if (!inherits(family, "family")) stop("unknown family type")
		gaus <- family$family == "gaussian" && family$link == "identity"
	}
	mc <- match.call()
	lmerc <- mc                         # create a call to lmer
	lmerc[[1]] <- if (gaus) as.name("lmer") else as.name("glmer")
	lmerc$pedigree <- NULL
	if (!gaus) lmerc$REML <- NULL
	
	if (!length(pedigree))              # call [g]lmer instead
		return(eval.parent(lmerc))
	
	stopifnot(is.list(pedigree),        # check the pedigree argument
			length(names(pedigree)) == length(pedigree),
			all(sapply(pedigree, function(x) is(x, "pedigree") | is(x, "matrix")))) # RJ modification
	
	lmerc[[1]] <- if (gaus) quote(lme4::lFormula) else quote(lme4::glFormula) # RJ modification
	lmf <- eval(lmerc, parent.frame())
	
	
	relfac <- pedigree          # copy the pedigree list for relfactor
	pnms <- names(pedigree)
	#pp <- lmf at pp # RJ modification
	#resp <- lmf at resp # RJ modification
	fl <- lmf$reTrms$flist # RJ modification
	stopifnot(all(pnms %in% names(fl)))
	asgn <- attr(fl, "assign")
	#Zt <- pp$Zt # RJ modification
	for (i in seq_along(pedigree)) {
		tn <- which(match(pnms[i], names(fl)) == asgn)
		if (length(tn) > 1)
			stop("a pedigree factor must be associated with only one r.e. term")
		ind <- (lmf$reTrms$Gp)[tn:(tn+1L)] # RJ modification
		rowsi <- (ind[1]+1L):ind[2]
		if (is(relfac[[i]], "pedigree")) relfac[[i]] <- relfactor(pedigree[[i]], rownames(lmf$reTrms$Zt)[rowsi]) # RJ modification
		lmf$reTrms$Zt[rowsi,] <- relfac[[i]] %*% lmf$reTrms$Zt[rowsi,] # RJ modification
	}
	#reTrms <- list(Zt=Zt,theta=lmf at theta,Lambdat=pp$Lambdat,Lind=pp$Lind,  # RJ modification starts
	#		lower=lmf at lower,flist=lmf at flist,cnms=lmf at cnms, Gp=lmf at Gp)
	dfl <- list(fr=lmf$fr, X=lmf$X, reTrms=lmf$reTrms, start=lmf$reTrms$theta)
	optimizer_opt <- ifelse(gaus, control$optimizer, control$optimizer[[2]]);
	if (is.null(optimizer_opt)) optimizer_opt <- "Nelder_Mead"; # RJ modification ends
	if (gaus) {
		dfl$REML = lmf$REML > 0L # RJ modification
		devfun <- do.call(mkLmerDevfun,dfl)
		opt <- optimizeLmer(devfun, optimizer=optimizer_opt,  # RJ modification starts
			restart_edge = control$restart_edge,
			boundary.tol = control$boundary.tol,
			control = control$optCtrl,
			calc.derivs=control$calc.derivs,
			use.last.params=control$use.last.params,...) # RJ modification ends
	} else {
		dfl$family <- family
		devfun <- do.call(mkGlmerDevfun,dfl)
		opt <- optimizeGlmer(devfun, optimizer=optimizer_opt, # RJ modification starts
			restart_edge=control$restart_edge,
			boundary.tol=control$boundary.tol,
			control = control$optCtrl,
			stage=2,
			calc.derivs=control$calc.derivs,
			use.last.params=control$use.last.params,...) # RJ modification ends
	}
	mm <- mkMerMod(environment(devfun), opt, lmf$reTrms, lmf$fr, mc)  # RJ modification
	cls <- if (gaus) "lmerpedigreemm" else "glmerpedigreemm"
	ans <- do.call(new, list(Class=cls, relfac=relfac,
					frame=mm at frame, flist=mm at flist, cnms=mm at cnms, Gp=mm at Gp,
					theta=mm at theta, beta=mm at beta,u=mm at u,lower=mm at lower,
					devcomp=mm at devcomp, pp=mm at pp,resp=mm at resp,optinfo=mm at optinfo))
	ans at call <- evalq(mc)
	ans
}



-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Roby Joehanes
Sent: Wednesday, February 8, 2017 1:52 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Patch for pedigreemm 0.3-3 plus questions

Dear all:

Attached please find the patch for pedigreemm 0.3-3, with the following changes:
1. Control options are now passed through to the optimizeLmer / optimizeGlmer, including optimizer, calc.derivs, etc. This saves about 15% of time.
2. Allowing direct matrix specification on pedigree. This will allow broader application in genetics, such as allowing cryptic relatedness to stand in as pedigree matrix.

A few questions from me. I think pedigreemm tries to call lmer / glmer once to get @pp (for Zt, primarily, but also X, Lambdat, and Lind), @resp (only for REML), @flist and @Gp, then followed up with optimizeLmer or optimizeGlmer. I think it is a big waste of time since most of these can be constructed offline (i.e., without actually computing the results), like in pedigreemm version 1.1 or so. Is there a way in lme4 package to do that instead of calling lmer / glmer? Is lme4::lFormula / lme4::glFormula the right way? Did I overlook something?

Thank you!

Sincerely,
Roby



----------------------------------------------------------------------
CONFIDENTIAL NOTICE:

This electronic mail transmission contains confidential information including Protected Health Information (PHI) that is legally privileged. 
If you are not the intended recipient, or designee, you are hereby notified that any disclosure, copying, distribution or use of any and all attachments to this transmission is STRICTLY PROHIBITED. If you have received this transmission in error, please notify the sender immediately to arrange for return or destruction of these documents.
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

----------------------------------------------------------------------
CONFIDENTIAL NOTICE:

This electronic mail transmission contains confidential information 
including Protected Health Information (PHI) that is legally privileged. 
If you are not the intended recipient, or designee, you are hereby 
notified that any disclosure, copying, distribution or use of any and
all attachments to this transmission is STRICTLY PROHIBITED. If you 
have received this transmission in error, please notify the sender 
immediately to arrange for return or destruction of these documents.


From bbolker at gmail.com  Wed Feb  8 22:24:17 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 8 Feb 2017 16:24:17 -0500
Subject: [R-sig-ME] Patch for pedigreemm 0.3-3 plus questions
In-Reply-To: <05B4E90C30995F45B8E8D5506ADB2775649E6341@EXCH-MAILBOX01.hebrewseniorlife.local>
References: <05B4E90C30995F45B8E8D5506ADB2775649E6297@EXCH-MAILBOX01.hebrewseniorlife.local>
	<05B4E90C30995F45B8E8D5506ADB2775649E6341@EXCH-MAILBOX01.hebrewseniorlife.local>
Message-ID: <bedf5636-c509-2a65-cd24-4ab553533406@gmail.com>


  This is great -- thank you! -- but it would be better to e-mail the
maintainer (try maintainer("pedigreemm")) directly -- they may or may
not actually read this mailing list ...

On 17-02-08 02:20 PM, Roby Joehanes wrote:
> Dear all:
> 
> It looks like lme4::lFormula or lme4::glFormula works. The time
> savings is about 40% now. Here is the code. If this code gets the
> blessings of the maintainers, I wonder if this code could be
> incorporated into the official pedigreemm.
> 
> Sincerely, Roby
> 
> # Modified pedigreemm source # Based on pedigreemm 0.3-3 # By Roby
> Joehanes
> 
> # What is modified: # 1. Allowing optimizer options to pass through #
> 2. Allow direct specification of pedigree matrix # 3. Shortcut to
> reconstruct necessary matrices instead of calling lmer/glmer
> 
> pedigreemm <- function(formula, data, family = NULL, REML = TRUE,
> pedigree = list(), control = list(), start = NULL, verbose = FALSE, 
> subset, weights, na.action, offset, contrasts = NULL, model = TRUE, x
> = TRUE, ...) { gaus <- FALSE if (is.null(family)) { gaus <- TRUE }
> else { ## copied from glm() if (is.character(family)) family <-
> get(family, mode = "function", envir = parent.frame()) if
> (is.function(family)) family <- family() if (!inherits(family,
> "family")) stop("unknown family type") gaus <- family$family ==
> "gaussian" && family$link == "identity" } mc <- match.call() lmerc <-
> mc                         # create a call to lmer lmerc[[1]] <- if
> (gaus) as.name("lmer") else as.name("glmer") lmerc$pedigree <- NULL 
> if (!gaus) lmerc$REML <- NULL  if (!length(pedigree))              #
> call [g]lmer instead return(eval.parent(lmerc))  
> stopifnot(is.list(pedigree),        # check the pedigree argument 
> length(names(pedigree)) == length(pedigree), all(sapply(pedigree,
> function(x) is(x, "pedigree") | is(x, "matrix")))) # RJ modification 
> 

> lmerc[[1]] <- if (gaus) quote(lme4::lFormula) else
> quote(lme4::glFormula) # RJ modification lmf <- eval(lmerc,
> parent.frame())   relfac <- pedigree          # copy the pedigree
> list for relfactor pnms <- names(pedigree) #pp <- lmf at pp # RJ
> modification #resp <- lmf at resp # RJ modification fl <-
> lmf$reTrms$flist # RJ modification stopifnot(all(pnms %in%
> names(fl))) asgn <- attr(fl, "assign") #Zt <- pp$Zt # RJ
> modification for (i in seq_along(pedigree)) { tn <-
> which(match(pnms[i], names(fl)) == asgn) if (length(tn) > 1) stop("a
> pedigree factor must be associated with only one r.e. term") ind <-
> (lmf$reTrms$Gp)[tn:(tn+1L)] # RJ modification rowsi <-
> (ind[1]+1L):ind[2] if (is(relfac[[i]], "pedigree")) relfac[[i]] <-
> relfactor(pedigree[[i]], rownames(lmf$reTrms$Zt)[rowsi]) # RJ
> modification lmf$reTrms$Zt[rowsi,] <- relfac[[i]] %*%
> lmf$reTrms$Zt[rowsi,] # RJ modification } #reTrms <-
> list(Zt=Zt,theta=lmf at theta,Lambdat=pp$Lambdat,Lind=pp$Lind,  # RJ
> modification starts #		lower=lmf at lower,flist=lmf at flist,cnms=lmf at cnms,
> Gp=lmf at Gp) dfl <- list(fr=lmf$fr, X=lmf$X, reTrms=lmf$reTrms,
> start=lmf$reTrms$theta) optimizer_opt <- ifelse(gaus,
> control$optimizer, control$optimizer[[2]]); if
> (is.null(optimizer_opt)) optimizer_opt <- "Nelder_Mead"; # RJ
> modification ends if (gaus) { dfl$REML = lmf$REML > 0L # RJ
> modification devfun <- do.call(mkLmerDevfun,dfl) opt <-
> optimizeLmer(devfun, optimizer=optimizer_opt,  # RJ modification
> starts restart_edge = control$restart_edge, boundary.tol =
> control$boundary.tol, control = control$optCtrl, 
> calc.derivs=control$calc.derivs, 
> use.last.params=control$use.last.params,...) # RJ modification ends }
> else { dfl$family <- family devfun <- do.call(mkGlmerDevfun,dfl) opt
> <- optimizeGlmer(devfun, optimizer=optimizer_opt, # RJ modification
> starts restart_edge=control$restart_edge, 
> boundary.tol=control$boundary.tol, control = control$optCtrl, 
> stage=2, calc.derivs=control$calc.derivs, 
> use.last.params=control$use.last.params,...) # RJ modification ends 
> } mm <- mkMerMod(environment(devfun), opt, lmf$reTrms, lmf$fr, mc)  #
> RJ modification cls <- if (gaus) "lmerpedigreemm" else
> "glmerpedigreemm" ans <- do.call(new, list(Class=cls, relfac=relfac, 
> frame=mm at frame, flist=mm at flist, cnms=mm at cnms, Gp=mm at Gp, 
> theta=mm at theta, beta=mm at beta,u=mm at u,lower=mm at lower, 
> devcomp=mm at devcomp, pp=mm at pp,resp=mm at resp,optinfo=mm at optinfo)) 
> ans at call <- evalq(mc) ans }
> 
> 
> 
> -----Original Message----- From: R-sig-mixed-models
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Roby
> Joehanes Sent: Wednesday, February 8, 2017 1:52 PM To:
> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Patch for
> pedigreemm 0.3-3 plus questions
> 
> Dear all:
> 
> Attached please find the patch for pedigreemm 0.3-3, with the
> following changes: 1. Control options are now passed through to the
> optimizeLmer / optimizeGlmer, including optimizer, calc.derivs, etc.
> This saves about 15% of time. 2. Allowing direct matrix specification
> on pedigree. This will allow broader application in genetics, such as
> allowing cryptic relatedness to stand in as pedigree matrix.
> 
> A few questions from me. I think pedigreemm tries to call lmer /
> glmer once to get @pp (for Zt, primarily, but also X, Lambdat, and
> Lind), @resp (only for REML), @flist and @Gp, then followed up with
> optimizeLmer or optimizeGlmer. I think it is a big waste of time
> since most of these can be constructed offline (i.e., without
> actually computing the results), like in pedigreemm version 1.1 or
> so. Is there a way in lme4 package to do that instead of calling lmer
> / glmer? Is lme4::lFormula / lme4::glFormula the right way? Did I
> overlook something?
> 
> Thank you!
> 
> Sincerely, Roby
> 
> 
> 
> ----------------------------------------------------------------------
>
> 
CONFIDENTIAL NOTICE:
> 
> This electronic mail transmission contains confidential information
> including Protected Health Information (PHI) that is legally
> privileged. If you are not the intended recipient, or designee, you
> are hereby notified that any disclosure, copying, distribution or use
> of any and all attachments to this transmission is STRICTLY
> PROHIBITED. If you have received this transmission in error, please
> notify the sender immediately to arrange for return or destruction of
> these documents. _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> ----------------------------------------------------------------------
>
> 
CONFIDENTIAL NOTICE:
> 
> This electronic mail transmission contains confidential information 
> including Protected Health Information (PHI) that is legally
> privileged. If you are not the intended recipient, or designee, you
> are hereby notified that any disclosure, copying, distribution or use
> of any and all attachments to this transmission is STRICTLY
> PROHIBITED. If you have received this transmission in error, please
> notify the sender immediately to arrange for return or destruction of
> these documents.
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From joao.santiago at uni-tuebingen.de  Thu Feb  9 13:46:31 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Thu, 09 Feb 2017 13:46:31 +0100
Subject: [R-sig-ME] How to pairwise comparisons with lsmeansLT
Message-ID: <20170209134631.Horde.DnanEC4xDkyQa7A8g5pMG6F@webmail.uni-tuebingen.de>

Hello everyone,

Last I used lsmeans from the lmerTest package one could simply

lsmeans(mod, pairwise ~ a | b)

and get a nice output with pairwise comparisons and adjusted p-values.

now it seems lsmeans is deprecated, replaced by lsmeansLT.

lsmeansLT(mod, test.effs = "a:b")

does not have the same output. Here my own output

> lsmeansLT(fit_linN, test.effs = "stageGroup:treatment")
Least Squares Means table:
                                         stageGroup treatment Estimate  
Standard Error   DF t-value Lower CI Upper CI p-value
stageGroup:treatment  Awake Control            1.0       1.0    44.75   
         10.00 27.7    4.48     24.3     65.2   1e-04 ***
stageGroup:treatment  REM Control              2.0       1.0    90.92   
          6.25 72.1   14.56     78.5    103.4  <2e-16 ***
stageGroup:treatment  S1/S2 Control            3.0       1.0   272.32   
          8.79 31.5   30.97    254.4    290.2  <2e-16 ***
stageGroup:treatment  SWS Control              4.0       1.0    86.62   
          8.44 33.2   10.27     69.5    103.8  <2e-16 ***
stageGroup:treatment  Awake Stimulation        1.0       2.0    52.15   
         10.00 27.7    5.22     31.7     72.6  <2e-16 ***
stageGroup:treatment  REM Stimulation          2.0       2.0    89.85   
          6.25 72.1   14.39     77.4    102.3  <2e-16 ***
stageGroup:treatment  S1/S2 Stimulation        3.0       2.0   265.82   
          8.79 31.5   30.24    247.9    283.7  <2e-16 ***
stageGroup:treatment  SWS Stimulation          4.0       2.0    86.40   
          8.44 33.2   10.24     69.2    103.6  <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

the interaction stageGroup:treatment is NOT significant, the plots  
show no signs of interaction. I think what is being tested here is  
wrong anyway. what I want is to test the differences in means between  
treatments in each stageGroup.
the former version of lsmeans would do this. for example lsmeans(mod,  
"treatment") would only tests the difference between treatments after  
adjusting for the other covariates.

Am I doing something wrong here?

Additionally: if this is not the way to go to obtain p-values from  
multiple comparisons (my peers want those values), is it "allowed" to  
perform multiple t-tests on the normal means? It's not the same  
though, no adjusment for the other covariates.

Best,
Santiago

-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From russell-lenth at uiowa.edu  Fri Feb 10 15:24:29 2017
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Fri, 10 Feb 2017 14:24:29 +0000
Subject: [R-sig-ME] How to pairwise comparisons with lsmeansLT
Message-ID: <CO2PR04MB2200F1F73BC4757701123CECF1440@CO2PR04MB2200.namprd04.prod.outlook.com>

The interface style you mention is for the 'lsmeans' function in the *lsmeans* package. The developers of the *lmerTest* package renamed their 'lsmeans' function 'lsmeansLT' to help avoid confusion.

Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



Message: 1
Date: Thu, 09 Feb 2017 13:46:31 +0100
From: Jo?o C P Santiago <joao.santiago at uni-tuebingen.de>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] How to pairwise comparisons with lsmeansLT
Message-ID:
	<20170209134631.Horde.DnanEC4xDkyQa7A8g5pMG6F at webmail.uni-tuebingen.de>
	
Content-Type: text/plain; charset=utf-8; format=flowed; DelSp=Yes

Hello everyone,

Last I used lsmeans from the lmerTest package one could simply

lsmeans(mod, pairwise ~ a | b)

and get a nice output with pairwise comparisons and adjusted p-values.

now it seems lsmeans is deprecated, replaced by lsmeansLT.

lsmeansLT(mod, test.effs = "a:b")

does not have the same output. Here my own output

> lsmeansLT(fit_linN, test.effs = "stageGroup:treatment")
Least Squares Means table:
                                         stageGroup treatment Estimate  
Standard Error   DF t-value Lower CI Upper CI p-value
stageGroup:treatment  Awake Control            1.0       1.0    44.75   
         10.00 27.7    4.48     24.3     65.2   1e-04 ***
stageGroup:treatment  REM Control              2.0       1.0    90.92   
          6.25 72.1   14.56     78.5    103.4  <2e-16 ***
stageGroup:treatment  S1/S2 Control            3.0       1.0   272.32   
          8.79 31.5   30.97    254.4    290.2  <2e-16 ***
stageGroup:treatment  SWS Control              4.0       1.0    86.62   
          8.44 33.2   10.27     69.5    103.8  <2e-16 ***
stageGroup:treatment  Awake Stimulation        1.0       2.0    52.15   
         10.00 27.7    5.22     31.7     72.6  <2e-16 ***
stageGroup:treatment  REM Stimulation          2.0       2.0    89.85   
          6.25 72.1   14.39     77.4    102.3  <2e-16 ***
stageGroup:treatment  S1/S2 Stimulation        3.0       2.0   265.82   
          8.79 31.5   30.24    247.9    283.7  <2e-16 ***
stageGroup:treatment  SWS Stimulation          4.0       2.0    86.40   
          8.44 33.2   10.24     69.2    103.6  <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

the interaction stageGroup:treatment is NOT significant, the plots show no signs of interaction. I think what is being tested here is wrong anyway. what I want is to test the differences in means between treatments in each stageGroup.
the former version of lsmeans would do this. for example lsmeans(mod,
"treatment") would only tests the difference between treatments after adjusting for the other covariates.

Am I doing something wrong here?

Additionally: if this is not the way to go to obtain p-values from multiple comparisons (my peers want those values), is it "allowed" to perform multiple t-tests on the normal means? It's not the same though, no adjusment for the other covariates.

Best,
Santiago

-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From joao.santiago at uni-tuebingen.de  Fri Feb 10 16:17:40 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Fri, 10 Feb 2017 16:17:40 +0100
Subject: [R-sig-ME] How to pairwise comparisons with lsmeansLT
In-Reply-To: <CO2PR04MB2200F1F73BC4757701123CECF1440@CO2PR04MB2200.namprd04.prod.outlook.com>
Message-ID: <20170210161740.Horde.D1SoX47IY6PgY8BPogx3rX5@webmail.uni-tuebingen.de>

d'oh.. thank you Russel! now it works. I guess then the lmerTest  
simply does not do pairwise comparisons and I'm not doing anything  
wrong?


Thanks
Santiago

Quoting "Lenth, Russell V" <russell-lenth at uiowa.edu>:

> The interface style you mention is for the 'lsmeans' function in the  
> *lsmeans* package. The developers of the *lmerTest* package renamed  
> their 'lsmeans' function 'lsmeansLT' to help avoid confusion.
>
> Russ
>
> Russell V. Lenth? -? Professor Emeritus
> Department of Statistics and Actuarial Science??
> The University of Iowa ?-? Iowa City, IA 52242? USA??
> Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017
>
>
>
> Message: 1
> Date: Thu, 09 Feb 2017 13:46:31 +0100
> From: Jo?o C P Santiago <joao.santiago at uni-tuebingen.de>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] How to pairwise comparisons with lsmeansLT
> Message-ID:
> 	<20170209134631.Horde.DnanEC4xDkyQa7A8g5pMG6F at webmail.uni-tuebingen.de>
>
> Content-Type: text/plain; charset=utf-8; format=flowed; DelSp=Yes
>
> Hello everyone,
>
> Last I used lsmeans from the lmerTest package one could simply
>
> lsmeans(mod, pairwise ~ a | b)
>
> and get a nice output with pairwise comparisons and adjusted p-values.
>
> now it seems lsmeans is deprecated, replaced by lsmeansLT.
>
> lsmeansLT(mod, test.effs = "a:b")
>
> does not have the same output. Here my own output
>
>> lsmeansLT(fit_linN, test.effs = "stageGroup:treatment")
> Least Squares Means table:
>                                          stageGroup treatment Estimate
> Standard Error   DF t-value Lower CI Upper CI p-value
> stageGroup:treatment  Awake Control            1.0       1.0    44.75
>          10.00 27.7    4.48     24.3     65.2   1e-04 ***
> stageGroup:treatment  REM Control              2.0       1.0    90.92
>           6.25 72.1   14.56     78.5    103.4  <2e-16 ***
> stageGroup:treatment  S1/S2 Control            3.0       1.0   272.32
>           8.79 31.5   30.97    254.4    290.2  <2e-16 ***
> stageGroup:treatment  SWS Control              4.0       1.0    86.62
>           8.44 33.2   10.27     69.5    103.8  <2e-16 ***
> stageGroup:treatment  Awake Stimulation        1.0       2.0    52.15
>          10.00 27.7    5.22     31.7     72.6  <2e-16 ***
> stageGroup:treatment  REM Stimulation          2.0       2.0    89.85
>           6.25 72.1   14.39     77.4    102.3  <2e-16 ***
> stageGroup:treatment  S1/S2 Stimulation        3.0       2.0   265.82
>           8.79 31.5   30.24    247.9    283.7  <2e-16 ***
> stageGroup:treatment  SWS Stimulation          4.0       2.0    86.40
>           8.44 33.2   10.24     69.2    103.6  <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> the interaction stageGroup:treatment is NOT significant, the plots  
> show no signs of interaction. I think what is being tested here is  
> wrong anyway. what I want is to test the differences in means  
> between treatments in each stageGroup.
> the former version of lsmeans would do this. for example lsmeans(mod,
> "treatment") would only tests the difference between treatments  
> after adjusting for the other covariates.
>
> Am I doing something wrong here?
>
> Additionally: if this is not the way to go to obtain p-values from  
> multiple comparisons (my peers want those values), is it "allowed"  
> to perform multiple t-tests on the normal means? It's not the same  
> though, no adjusment for the other covariates.
>
> Best,
> Santiago
>
> --
> Jo?o C. P. Santiago
> Institute for Medical Psychology & Behavioral Neurobiology
> Center of Integrative Neuroscience
> University of Tuebingen
> Otfried-Mueller-Str. 25
> 72076 Tuebingen, Germany
>
> Phone: +49 7071 29 88981
> Fax: +49 7071 29 25016



-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From belinda.pletzer at gmail.com  Tue Feb 14 15:24:48 2017
From: belinda.pletzer at gmail.com (Belinda Pletzer)
Date: Tue, 14 Feb 2017 15:24:48 +0100
Subject: [R-sig-ME] question on lme4
Message-ID: <CAM6hLDkcwX8JTfMEitXv77DhU8Ma748X_cCM3NqF8kPz7Q6wWA@mail.gmail.com>

Dear Dr. Bolker,

I am writing to you with a question regarding linear mixed effects models
in R, since you are listed as the maintainer for the lme4 package. I've
been using both nlme and the lme4 package for my models and have now for
the second time encountered a reviewer who insisted on the calculation of
standardized effect sizes like d, r or beta for the fixed effects in my
model.

I've already spent hours on the internet trying to figure out a way to do
so, but all I found were some approximations to calculate R?-like measures
for the whole model, but not for each effect separately and as far as I
understood all the literature I've found, it is not advisable to attemt the
calculation of standardized effect sizes in lme's, but I might be mistaken.

Do you know of any way to do something like that with your package, or
could you otherwise point me towards someone who knows an other way or
towards some literature that might help in responding to this reviewer?

Thanks a lot in advance!

Best regards,
Belinda Pletzer

	[[alternative HTML version deleted]]


From bio.jjmartinez at gmail.com  Tue Feb 14 20:16:09 2017
From: bio.jjmartinez at gmail.com (Juan Jose Martinez)
Date: Tue, 14 Feb 2017 16:16:09 -0300
Subject: [R-sig-ME] problems to run MCMCglmm to estimate heritability
Message-ID: <CAM7qEV1Nuz2kroogdBWWBJUA0RAdBxat_+xZwhR_DeJPDWmEGQ@mail.gmail.com>

Dear folks



I am assessing the heritability of morphological traits in a wild
population of a parakeet and I am trying to apply animal models with
the MCMCglmm package. My main problem is to run the function MCMCglmm
due to an error message:

?Error in MCMCglmm(PESO ~ 1, random = ~animal, pedigree = fixordped,
data = cotorras_traits,  :

  some levels of animal do not have a row entry in ginverse?



What I am doing wrong?

I checked the pedigree with pedantics but I did not see any error with it.


Thanks in advance for your help.


Best,


Juan Jose Martinez
Investigador Asistente CONICET
Instituto de Ecorregiones Andinas (INECOA, CONICET-UNJu)

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Wed Feb 15 08:02:47 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Wed, 15 Feb 2017 07:02:47 +0000
Subject: [R-sig-ME] question on lme4
In-Reply-To: <CAM6hLDkcwX8JTfMEitXv77DhU8Ma748X_cCM3NqF8kPz7Q6wWA@mail.gmail.com>
References: <CAM6hLDkcwX8JTfMEitXv77DhU8Ma748X_cCM3NqF8kPz7Q6wWA@mail.gmail.com>
Message-ID: <CE972BD7-907B-4E8E-B652-6FCE2D99816F@unisa.edu.au>

Dear Belinda,

(Partial) R^2 is a rather challenging concept for mixed models. Intuitively, correlation (r) is difficult for multilevel models -- do you want the average of all within-group correlations, the overall correlation or something else entirely?  Neither one is "right" or "wrong" but rather answer subtly different questions.This only gets harder when we consider things like Simpson's paradox or models with crossed (whether partially or fully) or nested groups. 

This is discussed a bit on the FAQ:

https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms

The betas (coefficients) are themselves effect sizes -- after all they describe how big a change in the dependent/response variable (i.e. effect) you can expect per unit change in the predictor. If you want them to standardised effect sizes, then you can simply standardise your predictors (which is often recommended practice anyway because it puts all your predictors on the same scale and makes some aspects of model fitting easier) and you'll have an effect size in terms of standard deviations, i.e. similar to Cohen's d. The confidence intervals on the coefficients are then also confidence intervals on your effect size. 

This is easy to do in R by the way: simply change

y ~ x1 * x2 

to

y ~ scale(x1) * scale(x2) 

(And make sure to do the same thing for the relevant parts of your random-effect structure.)

Best,
Phillip

PS: Ben Bolker is one of the maintainers of lme4, but this mailing list thankfully -- for his sake -- isn't a hotline to him. It's just a collection of people interested in mixed models, especially in R.


> On 15 Feb 2017, at 00:54, Belinda Pletzer <belinda.pletzer at gmail.com> wrote:
> 
> Dear Dr. Bolker,
> 
> I am writing to you with a question regarding linear mixed effects models
> in R, since you are listed as the maintainer for the lme4 package. I've
> been using both nlme and the lme4 package for my models and have now for
> the second time encountered a reviewer who insisted on the calculation of
> standardized effect sizes like d, r or beta for the fixed effects in my
> model.
> 
> I've already spent hours on the internet trying to figure out a way to do
> so, but all I found were some approximations to calculate R?-like measures
> for the whole model, but not for each effect separately and as far as I
> understood all the literature I've found, it is not advisable to attemt the
> calculation of standardized effect sizes in lme's, but I might be mistaken.
> 
> Do you know of any way to do something like that with your package, or
> could you otherwise point me towards someone who knows an other way or
> towards some literature that might help in responding to this reviewer?
> 
> Thanks a lot in advance!
> 
> Best regards,
> Belinda Pletzer
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From vincenzoaellis at gmail.com  Wed Feb 15 17:47:54 2017
From: vincenzoaellis at gmail.com (Vincenzo Ellis)
Date: Wed, 15 Feb 2017 14:47:54 -0200
Subject: [R-sig-ME] variance estimates differ glmer vs lme
Message-ID: <CAGekO=3ec57WNBj5yMWsdN0CY=c2xQsaXW=nd_PWQXuyu8Of8Q@mail.gmail.com>

Dear mixed effects modelers,

I'm interested in doing variance partitioning of parasite prevalence (a
proportion calculated as the number of infected host individuals divided by
the total number of host individuals sampled) among different host
taxonomic levels.

I've run the analysis in lme4 using the glmer function and I've also
arcsine square-root transformed the response variable (prevalence) and run
that in the nlme package using the lme function (with weights set to the
square root of sample size).

These two approaches give different answers. I assumed they would differ a
bit, but I expected them to be more similar than they are. The glmer
approach puts 66% of the variance in prevalence at the species within
genera level, while the lme approach puts 92% of the variance at the
species within genera level.

*Question:* Am I wrong to think that these two approaches should have given
more similar results? And is one of these approaches clearly correct or
incorrect?

Thanks for any insights!

Vincenzo

Reproducible example:

#### Compare hierarchical variance partitioning results between glmer() and
lme()

## install packages if necessary
install.packages(c("gsheet", "lme4", "nlme"))

## load data
library(gsheet)
dat <- gsheet2tbl('
https://docs.google.com/spreadsheets/d/1EhkrHG19pESBCTQ1mMa8od4lbyF-N484RchskCrPUqo/edit?usp=sharing
')


## glmer variance partitioning (takes about 30s to run on my computer)
library(lme4)
mod.glmm <- glmer(cbind(Infected, Sample_Size-Infected) ~ 1 +
(1|Family/Genus/Species),
                  data = dat, family = binomial)

## variance estimates
print(VarCorr(mod.glmm), comp=c("Variance"))

## proportional variance
mod.glmm.var <- c(VarCorr(mod.glmm)[[1]][1,1], VarCorr(mod.glmm)[[2]][1,1],
                  VarCorr(mod.glmm)[[3]][1,1])
round(mod.glmm.var/sum(mod.glmm.var), 3)


## lme variance partitioning
library(nlme)
prev <- with(dat, Infected/Sample_Size)
mod.lmm <- lme(asin(sqrt(prev)) ~ 1, random = ~ 1|Family/Genus,
               data = dat, weights = ~ 1/sqrt(Sample_Size))

## variance estimates
VarCorr(mod.lmm)

## proportional variance
mod.lmm.var <- as.numeric(VarCorr(mod.lmm)[c(5,4,2),1])
round(mod.lmm.var/sum(mod.lmm.var), 3)

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Feb 16 10:18:28 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 16 Feb 2017 10:18:28 +0100
Subject: [R-sig-ME] variance estimates differ glmer vs lme
In-Reply-To: <CAGekO=3ec57WNBj5yMWsdN0CY=c2xQsaXW=nd_PWQXuyu8Of8Q@mail.gmail.com>
References: <CAGekO=3ec57WNBj5yMWsdN0CY=c2xQsaXW=nd_PWQXuyu8Of8Q@mail.gmail.com>
Message-ID: <CAJuCY5xhoQB9KubwUMpOYiPB88Pzq61EHeMW67Ym7QBzRpi7vA@mail.gmail.com>

Dear Vincenzo,

You can't compare those models at all. Write down the equations and you'll
see that they are very different.

In this case you should use the glmer version.

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-02-15 17:47 GMT+01:00 Vincenzo Ellis <vincenzoaellis at gmail.com>:

> Dear mixed effects modelers,
>
> I'm interested in doing variance partitioning of parasite prevalence (a
> proportion calculated as the number of infected host individuals divided by
> the total number of host individuals sampled) among different host
> taxonomic levels.
>
> I've run the analysis in lme4 using the glmer function and I've also
> arcsine square-root transformed the response variable (prevalence) and run
> that in the nlme package using the lme function (with weights set to the
> square root of sample size).
>
> These two approaches give different answers. I assumed they would differ a
> bit, but I expected them to be more similar than they are. The glmer
> approach puts 66% of the variance in prevalence at the species within
> genera level, while the lme approach puts 92% of the variance at the
> species within genera level.
>
> *Question:* Am I wrong to think that these two approaches should have given
> more similar results? And is one of these approaches clearly correct or
> incorrect?
>
> Thanks for any insights!
>
> Vincenzo
>
> Reproducible example:
>
> #### Compare hierarchical variance partitioning results between glmer() and
> lme()
>
> ## install packages if necessary
> install.packages(c("gsheet", "lme4", "nlme"))
>
> ## load data
> library(gsheet)
> dat <- gsheet2tbl('
> https://docs.google.com/spreadsheets/d/1EhkrHG19pESBCTQ1mMa8od4lbyF-
> N484RchskCrPUqo/edit?usp=sharing
> ')
>
>
> ## glmer variance partitioning (takes about 30s to run on my computer)
> library(lme4)
> mod.glmm <- glmer(cbind(Infected, Sample_Size-Infected) ~ 1 +
> (1|Family/Genus/Species),
>                   data = dat, family = binomial)
>
> ## variance estimates
> print(VarCorr(mod.glmm), comp=c("Variance"))
>
> ## proportional variance
> mod.glmm.var <- c(VarCorr(mod.glmm)[[1]][1,1], VarCorr(mod.glmm)[[2]][1,1],
>                   VarCorr(mod.glmm)[[3]][1,1])
> round(mod.glmm.var/sum(mod.glmm.var), 3)
>
>
> ## lme variance partitioning
> library(nlme)
> prev <- with(dat, Infected/Sample_Size)
> mod.lmm <- lme(asin(sqrt(prev)) ~ 1, random = ~ 1|Family/Genus,
>                data = dat, weights = ~ 1/sqrt(Sample_Size))
>
> ## variance estimates
> VarCorr(mod.lmm)
>
> ## proportional variance
> mod.lmm.var <- as.numeric(VarCorr(mod.lmm)[c(5,4,2),1])
> round(mod.lmm.var/sum(mod.lmm.var), 3)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pierre.de.villemereuil at mailoo.org  Thu Feb 16 10:40:32 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Thu, 16 Feb 2017 22:40:32 +1300
Subject: [R-sig-ME] problems to run MCMCglmm to estimate heritability
In-Reply-To: <CAM7qEV1Nuz2kroogdBWWBJUA0RAdBxat_+xZwhR_DeJPDWmEGQ@mail.gmail.com>
References: <CAM7qEV1Nuz2kroogdBWWBJUA0RAdBxat_+xZwhR_DeJPDWmEGQ@mail.gmail.com>
Message-ID: <3321898.xZORjFQb76@flyosflip>

Hi,

Usually, I think this message is thrown when individuals in your dataset are missing from the pedigree (or from a custom ginverse you might have provided).

It's hard to tell without even the code.

Cheers,
Pierre.

Le mercredi 15 f?vrier 2017, 08:16:09 NZDT Juan Jose Martinez a ?crit :
> Dear folks
> 
> 
> 
> I am assessing the heritability of morphological traits in a wild
> population of a parakeet and I am trying to apply animal models with
> the MCMCglmm package. My main problem is to run the function MCMCglmm
> due to an error message:
> 
> ?Error in MCMCglmm(PESO ~ 1, random = ~animal, pedigree = fixordped,
> data = cotorras_traits,  :
> 
>   some levels of animal do not have a row entry in ginverse?
> 
> 
> 
> What I am doing wrong?
> 
> I checked the pedigree with pedantics but I did not see any error with it.
> 
> 
> Thanks in advance for your help.
> 
> 
> Best,
> 
> 
> Juan Jose Martinez
> Investigador Asistente CONICET
> Instituto de Ecorregiones Andinas (INECOA, CONICET-UNJu)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From torsten.hauffe at gmail.com  Fri Feb 17 14:25:00 2017
From: torsten.hauffe at gmail.com (Torsten Hauffe)
Date: Fri, 17 Feb 2017 14:25:00 +0100
Subject: [R-sig-ME] multivariate glmm
Message-ID: <CAGCrCxZQVBSC1FtmrgPNkvccb4RsW0Q2k7qxson7y0dU6Y_8CQ@mail.gmail.com>

Dear list members,

I' m fitting a multivariate time series using mgcv:::gamm. I cannot run a
summary on my fitted object and no gam.check(). Any idea how I can assess
the model fit and diagnostic plots?

Because I'm interested in the general trend of all dependent variables (dv)
over time, I use a manova-like style and not the mgcv:::mvn function. The
latter function seems to estimate individual coefficients for all dv and
not the general temporal trend of all dv together. I use a gamm because of
allows to include temporal autocorrelation, which is not part of the
minimal example below.

library(mgcv)
data(iris)
set.seed(1)

iris$x <- rnorm(n = nrow(iris) # Create independent variable
# Regular manova
Manova <- lm(cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~
x, data = iris)
summary(Manova)
plot(Manova) # Does not work
# Now the gamm
Gamm <- gamm(cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~
s(x), data = iris)
summary(Gamm$lme) # Works
summary(Gamm$gam) # Does not work
gam.check(Gamm$gam) # Does not work

Thank you for any suggestion,
Torsten

	[[alternative HTML version deleted]]


From daniel.gregory3 at gmail.com  Mon Feb 20 18:41:14 2017
From: daniel.gregory3 at gmail.com (=?UTF-8?Q?Gr=c3=a9gory_DANIEL?=)
Date: Mon, 20 Feb 2017 18:41:14 +0100
Subject: [R-sig-ME] Prior for a bivariate model
Message-ID: <8960d3bb-9c0c-50e4-38ed-e7763469d76b@gmail.com>

Dear list members,

I am working with MCMCglmm package on a bivariate model to estimate the 
genetic covariance between my two traits that are my response variables. 
One is binary and the other is gaussian.  I have about 700 individuals, 
one measure per trait for each individual.

The model is simple : sex as fixed effect, and animal as random effect. 
But I have been struggling for several weeks to find a proper prior for 
which the model converge concerning the "animal" variance of my binary 
variable, and to do not have a big auto-correlation between iterations 
for the same variance.

Concerning the residual variance, I have no problem, only with the prior 
for the additive genetic variance of my binary response variable. I 
think we cannot specify two priors for a same variable...

I hope I was clear enough... Does anyone could help me to find a 
solution please  ?

Thanks a lot,

Gr?gory DANIEL - Ph.D. in evolutionary ecology
mail : daniel.gregory3 at gmail.com


---
L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par le logiciel antivirus Avast.
https://www.avast.com/antivirus


From jl.verissimo at gmail.com  Tue Feb 21 00:09:19 2017
From: jl.verissimo at gmail.com (=?ISO-8859-1?Q?Jo=E3o_Ver=EDssimo?=)
Date: Tue, 21 Feb 2017 00:09:19 +0100
Subject: [R-sig-ME] GLMM inverse gaussian and treatment contrasts (response
	times)
Message-ID: <1487632159.1569.12.camel@gmail.com>

Dear all,	

I've been trying to analyse a dataset of response times following Lo &
Andrews' (2015) proposal here: https://doi.org/10.3389/fpsyg.2015.01171
Specifically, they propose analysing raw (untransformed) RTs using a
GLMM that assumes a Gamma or inverse Gaussian distribution (with an
identity link function). For example:

glmer(rt.cut ~ (1|subject) + (1|targetnumber) + primetype * form * group
+ scale(order) + scale(rt.previous), exp,
family=inverse.gaussian(link="identity"),
control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=20000))))

(I could only get this to converge by using bobyqa, increasing maxfun,
and eliminating random slopes)

I am concerned about the interpretation of coefficients when using
treatment contrasts. In particular, I get different t-values for
interactions, depending on the reference level of one of the factors.

For example, these are the 3-way interactions when using one of the
levels of "form" as the reference:
primeType2:formInf:groupL2  -39.094     15.266   -2.56  0.01044 *
primeType3:formInf:groupL2  -37.020     15.495   -2.39  0.01689 *

And these are the same interactions when using the other level of "form"
as the reference:
primeType2:formFinite:groupL2  39.0939    17.5759   2.224   0.0261 *  
primeType3:formFinite:groupL2  37.0203    18.0101   2.056   0.0398 *

The estimates are exactly the same (as expected), but the SEs are larger
in the second case.

Why does this arise and why should I choose one or the other treatment
coding?

Thank you!
Jo?o


From M.Fairbrother at bristol.ac.uk  Tue Feb 21 12:06:22 2017
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 21 Feb 2017 11:06:22 +0000
Subject: [R-sig-ME] Prior for a bivariate model
Message-ID: <CAAH-yP8KiYAzjVB01dMv-Q-WQxmNmCs1hvh5ssqnzgHoaLVJQw@mail.gmail.com>

Hi Gregory,

I can't answer your question, but it sounds likely that someone on the list
will be able to. However, you'll increase the chances if you can send a
snippet of your R code thus far...

What call to MCMCglmm and what specification of your prior are you using
for a univariate model for each outcome separately, for example? If you can
show people something of what you've been able to do so far, you'll likely
get a response about how to go further.

Best wishes,
Malcolm





> Date: Mon, 20 Feb 2017 18:41:14 +0100
> From: Gr?gory DANIEL <daniel.gregory3 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Prior for a bivariate model
> Message-ID: <8960d3bb-9c0c-50e4-38ed-e7763469d76b at gmail.com>
> Content-Type: text/plain; charset=utf-8; format=flowed
>
> Dear list members,
>
> I am working with MCMCglmm package on a bivariate model to estimate the
> genetic covariance between my two traits that are my response variables.
> One is binary and the other is gaussian.  I have about 700 individuals,
> one measure per trait for each individual.
>
> The model is simple : sex as fixed effect, and animal as random effect.
> But I have been struggling for several weeks to find a proper prior for
> which the model converge concerning the "animal" variance of my binary
> variable, and to do not have a big auto-correlation between iterations
> for the same variance.
>
> Concerning the residual variance, I have no problem, only with the prior
> for the additive genetic variance of my binary response variable. I
> think we cannot specify two priors for a same variable...
>
> I hope I was clear enough... Does anyone could help me to find a
> solution please  ?
>
> Thanks a lot,
>
> Gr?gory DANIEL - Ph.D. in evolutionary ecology
> mail : daniel.gregory3 at gmail.com
>

	[[alternative HTML version deleted]]


From ilgim.hepdarcan at izmirekonomi.edu.tr  Mon Feb 27 23:36:05 2017
From: ilgim.hepdarcan at izmirekonomi.edu.tr (Ilgim Hepdarcan)
Date: Tue, 28 Feb 2017 00:36:05 +0200 (EET)
Subject: [R-sig-ME] How to model multilevel data of repeated measures using
 nlme function in R? and Is it okay to include categorical variable to
 random slopes model?
In-Reply-To: <221514687.11232043.1488234554120.JavaMail.zimbra@izmirekonomi.edu.tr>
Message-ID: <2014245323.11232184.1488234965412.JavaMail.zimbra@izmirekonomi.edu.tr>

Hi! 

My study consists of 3 trials and each trial includes four different n-back types, 0-,1-,2-,3-back. Each participant had 12 n-back conditions, in a different order. Therefore, my design is within-subject design. Participants are between factors and gender of the participant is the covariate of that between factor. 



While participants were performing n-back task, I have measured their dorsolateral prefrontal cortex activation via 16-channeled fNIR and obtained oxygenated hemoglobin measures from each of the 16 channels and I'm trying to conduct multilevel analysis by using R. My fixed variable is gender and my random variable is Nback Types (which has 4 levels, 0-, 1-, 2-, and 3-back) which is categorical. In my model, participants are nested within nback types. 




Because NbackType is categorical, I've wondered whether it is okay to test random slopes as in my model 1. 




Last but not least, would you share your opinions about how to interpret this random slopes model? 




#Random slopes model (model 1) 

library(lme4) 

library(lmerTest) 

model1.nbackOpt1 = lmer (Optode1 ~ NbackType * gender + 

(NbackType|participant), 

na.action = na.exclude, 

data=oxyHbConditionCellbyCell 

REML=FALSE) 

summary(model1.nbackOpt1) 


#Random intercepts model (model 2) 

library(lme4) 

library(lmerTest 

model2.nbackOpt1 = lmer (Optode1 ~ NbackType * gender + 

(1|participant:NbackType), 

na.action = na.exclude, 

data=oxyHbConditionCellbyCell, 

REML=FALSE) 
summary(model2.nbackOpt1) 


Ilg?m Hepdarcan 
Izmir University of Economics 
Experimental Psychology MD 


	[[alternative HTML version deleted]]


From mdevoto at agro.uba.ar  Fri Mar  3 15:51:23 2017
From: mdevoto at agro.uba.ar (Mariano Devoto)
Date: Fri, 3 Mar 2017 11:51:23 -0300
Subject: [R-sig-ME] glmm on paired data with repeated measures
Message-ID: <CAJRWjBYjEATg_bVYPycNoRzOfa88YAvehOYwMd4CVK3KBpVHeQ@mail.gmail.com>

Hi everyone. I'd really appreciate help with the following analysis.
Apologies for such a basic question; I looked for previous queries on
similar data, but none seem to quite fit what I am after.

I have a field experiment aimed at understanding how the presence of
"bodyguard" ants regulates the abundance of butterfly eggs and larvae (and
the damage the latter cause) on a focal plant species.
For this, I set up fourteen pairs of plants in a nature reserve and then
assigned each plant in each pair to one of two treatments, either "with
ants" or "without ants", by applying a physical barrier at the base of the
plant.
In the following nine weeks I measured four response variables once a week
on a subsample of ten randomly chosen leaves of each plant. I thus have
nine repeated measures on each plant.

My response variables are:
ants: number of ants (this was measured just to check the physical barrier
had worked OK)
eggs: number of butterfly eggs
larvae: number of butterfly larvae
dam: percent leaf damage (percentage eaten by larvae)

My explanatory variables are:
treat: treatment (two levels: "con" and "sin" mean with and without ants,
respectively)
pair: plant pair
date

For each response variable I would like to build a model that accounts for
the lack of independence of data within each pair, and that considers the
fact that data come from repeated measures (so, for instance, leaf damage
tends to accumulate).
My specific question is if including the random term "pair" in the model
accomplishes both things. I guess it probably doesn't, so I'd appreciate
any suggestions.
The results indicate plants without ants have a higher number of eggs
(which is what we expected, yeaeee), but without proper control of the
autocorrelations I mentioned I am not convinced.
I provide a workable example below.

#read data from Google drive
#each line represents the variables measured on a single leaf of a single
plant on a single date.

id <- "0Bzd8I1jr8z_iU0h6R0hxaElseDA" # google file ID
gaston <- read.table(sprintf("
https://docs.google.com/uc?id=%s&export=download", id), head=T)

#GLMM
require(lme4); require(effects)
M1 <- glmer(eggs ~ treat + (1|pair), data=gaston, family=poisson)

#check if there are any significant effects of treatment
summary(M1)
allEffects(M1)

Thanks in advance for your help.

Best,

Mariano


*Dr. Mariano Devoto*

Profesor Adjunto - C?tedra de Bot?nica General, Facultad de Agronom?a de la
UBA
Investigador Adjunto del CONICET

Av. San Mart?n 4453 - C1417DSE - C. A. de Buenos Aires - Argentina
+5411 4524-8069
http://www.agro.uba.ar/users/mdevoto/

	[[alternative HTML version deleted]]


From roserosei2030 at gmail.com  Sat Mar  4 21:02:49 2017
From: roserosei2030 at gmail.com (Rose Rosei)
Date: Sat, 4 Mar 2017 20:02:49 +0000
Subject: [R-sig-ME] Help
Message-ID: <CAEO-xr3axZ+Go5gbu-XZL3VRT+JxUuE_LLjRC+xs_RCvAT7+jg@mail.gmail.com>

Dear Professor Bolker

I have 100 applicants (A). They are nested in Streams (S). Applicants are
nested in days (D). Applicants nested in sessions (S) and Applicants
crossed in Question (Q), the dependent variable is a score.  All
independent variables are random

Would you please advise me how to address the codes in lme4.

Many thanks and very much appreciated.

Best,
Rose

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Mar  7 15:41:32 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Mar 2017 09:41:32 -0500
Subject: [R-sig-ME] Help
In-Reply-To: <CAEO-xr3axZ+Go5gbu-XZL3VRT+JxUuE_LLjRC+xs_RCvAT7+jg@mail.gmail.com>
References: <CAEO-xr3axZ+Go5gbu-XZL3VRT+JxUuE_LLjRC+xs_RCvAT7+jg@mail.gmail.com>
Message-ID: <45b3f451-4aac-c2cb-3f0d-5d27a91dade3@gmail.com>


 * this is a general mailing list (I asked you to redirect an off-line
query to r-sig-mixed-models, but I think I suggested that you change the
salutation ...).

 * a more informative subject would help (everyone who writes to the
list wants "Help" ...)

  Are you sure you want all independent variables to be random effects?
That would suggest that you don't care about the effects of any
particular variables (e.g. streams), only about decomposing variance,
which I would find surprising.  Also, for practical mixed modeling you
need to have a reasonable of levels (e.g. >5); do you have more than 5
Streams?

  I'm going to take a guess that you really want to assess effects of
Streams.

A reasonable model for this would be

  score ~ S + (1|A) + (1|Q) + (1|D)

This assumes that each applicant has a unique ID number (e.g. there is
not an applicant #24 in Stream 1 and in Stream 2, but these applicants
would be coded as 24-1 and 24-2).  Also assumes S is a factor.

  This is not a maximal model in the sense of Barr et al 2013: in
principle you could estimate among-applicant variability in Q, but that
would generally take a great deal of data.

  For future reference it would help to know more about your design; how
many Streams, how many Days, how many Questions, how many total
observations?  It would also help to know what your actual subject-area
question is: what are you trying to find out from this analysis?

 You might also want to read the "nested or crossed?" section in
bbolker.github.io/mixedmodels-misc/glmmFAQ.html



On 17-03-04 03:02 PM, Rose Rosei wrote:
> Dear Professor Bolker
> 
> I have 100 applicants (A). They are nested in Streams (S). Applicants are
> nested in days (D). Applicants nested in sessions (S) and Applicants
> crossed in Question (Q), the dependent variable is a score.  All
> independent variables are random
> 
> Would you please advise me how to address the codes in lme4.
> 
> Many thanks and very much appreciated.
> 
> Best,
> Rose
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From thierry.onkelinx at inbo.be  Tue Mar  7 15:41:40 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 7 Mar 2017 15:41:40 +0100
Subject: [R-sig-ME] Help
In-Reply-To: <CAEO-xr3axZ+Go5gbu-XZL3VRT+JxUuE_LLjRC+xs_RCvAT7+jg@mail.gmail.com>
References: <CAEO-xr3axZ+Go5gbu-XZL3VRT+JxUuE_LLjRC+xs_RCvAT7+jg@mail.gmail.com>
Message-ID: <CAJuCY5zd21c8obP7HqNC+hi+BzvrucpxLRgBgNMWRkjvf3ga1g@mail.gmail.com>

Dear Rose,

Let's clear two misunderstandings on your side. 1) This the
r-sig-mixed-models mailing list, not prof. Bolker's private address. 2) The
goal of this mailing list is to help each other. Most people are more
likely to respond when they only need to confirm or correct your code. They
are unwilling to do all the work for you. So some minimal effort on your
side (attempt to code + dataset with design) is highly recommended. Have a
look at https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q1/025478.html

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-03-04 21:02 GMT+01:00 Rose Rosei <roserosei2030 at gmail.com>:

> Dear Professor Bolker
>
> I have 100 applicants (A). They are nested in Streams (S). Applicants are
> nested in days (D). Applicants nested in sessions (S) and Applicants
> crossed in Question (Q), the dependent variable is a score.  All
> independent variables are random
>
> Would you please advise me how to address the codes in lme4.
>
> Many thanks and very much appreciated.
>
> Best,
> Rose
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From roserosei2030 at gmail.com  Wed Mar  8 20:01:48 2017
From: roserosei2030 at gmail.com (Rose Rosei)
Date: Wed, 8 Mar 2017 19:01:48 +0000
Subject: [R-sig-ME] Advice on Mixed Models
Message-ID: <CAEO-xr3M641NWySp9qYeCPx4wAUJ3Gws6XP1TtukB-0=eBroCw@mail.gmail.com>

Dear Advisors

Would you please advise me. I would like to fit my model, but I struggled
to do it


  A= Applicant = 10 persons
  S= Stream ( four levels, 1, 2)
  D= Day   (1,2)
 S1= Session ( 1,2)
 Q = Qestion ( 1-to 8)
 Applicants are crossed in Questions, but Applicants nested in Stream,
  nested in Day, nested in session (S1). All variables are a a random factor

   I want to calculate SD for A, S, D, S1 and Q, and their interaction
.score=dependent variable

 I have used the following codes, but it seems they are wrong.

 lmer(score~ (1|A)+(1|S)+(1+D)+(1|S1)+(1|Q)+(1|A/S)+1|S/D)+(1|D/S1)+(1|S1/Q),
R)

Linear mixed model fit by REML ['lmerMod']
Formula: score ~ (1 | A) + (1 | S) + (1 + D) + (1 | S1) + (1 | Q) + (1 |
    A/S) + (1 | S/D) + (1 | D/S1) + (1 | S1/Q)
   Data: R
REML criterion at convergence: 192.4591
Random effects:
 Groups   Name        Std.Dev.
 Q.S1     (Intercept) 0.000e+00
 A        (Intercept) 2.383e-01
 S.A      (Intercept) 7.692e-01
 A.1      (Intercept) 8.399e-01
 Q        (Intercept) 0.000e+00
 S1.D     (Intercept) 1.386e-08
 D.S      (Intercept) 0.000e+00
 S1       (Intercept) 0.000e+00
 D        (Intercept) 9.498e-01
 S        (Intercept) 0.000e+00
 S1.1     (Intercept) 0.000e+00
 S.1      (Intercept) 0.000e+00
 Residual             6.722e-01
Number of obs: 80, groups:
Q:S1, 16; A, 10; S:A, 10; Q, 8; S1:D, 4; D:S, 4; S1, 2; D, 2; S, 2
Fixed Effects:
(Intercept)            D
    1.61458     -0.07292
convergence code 0; 2 optimizer warnings; 0 lme4 warnings

   Very much appreciated for your help.
looking forward to hearing from you.
   Rose

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Mar 11 00:59:52 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Mar 2017 18:59:52 -0500
Subject: [R-sig-ME] Advice on Mixed Models
In-Reply-To: <CAEO-xr3M641NWySp9qYeCPx4wAUJ3Gws6XP1TtukB-0=eBroCw@mail.gmail.com>
References: <CAEO-xr3M641NWySp9qYeCPx4wAUJ3Gws6XP1TtukB-0=eBroCw@mail.gmail.com>
Message-ID: <457e23eb-8c81-a97e-478e-a2a43c73ed73@gmail.com>



On 17-03-08 02:01 PM, Rose Rosei wrote:
> Dear Advisors
> 
> Would you please advise me. I would like to fit my model, but I struggled
> to do it
> 
> 
>   A= Applicant = 10 persons
>   S= Stream ( four levels, 1, 2)

  Not sure what "four levels, 1, 2" means here.  Do you mean "four
levels, 1-4" ... ?

>   D= Day   (1,2)
>  S1= Session ( 1,2)
>  Q = Qestion ( 1-to 8)
>  Applicants are crossed in Questions, but Applicants nested in Stream,
>   nested in Day, nested in session (S1). All variables are a a random factor

  You need to know that **with modern mixed-model machinery (e.g. nlme,
lme4 as opposed to aov() in R) it is not in general practical to
estimate random-effects terms for variables with fewer than 5 or 6 levels**.
See e.g. http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#singular-fit

> 
>    I want to calculate SD for A, S, D, S1 and Q, and their interaction
> .score=dependent variable
> 
>  I have used the following codes, but it seems they are wrong.
> 
>  lmer(score~ (1|A)+(1|S)+(1+D)+(1|S1)+(1|Q)+(1|A/S)+1|S/D)+(1|D/S1)+(1|S1/Q),
> R)

  (1|S1/D/S/A) gives "Applicants nested in Stream, nested in Day, nested
in session (S1)".  As I said above, it would be wiser if possible to use
S1+ (1|S1:D/S/A) (i.e. treat session as a fixed effect).
I would probably handle questions via (1|Q); if each applicant receives
each question no more than once within a session/day/stream combination,
then the S1:D:S:A:Q interaction will be handled by the residual variance
term.

In addition to the problems stated above, many of these terms are
redundant.  The nesting syntax (1|A/S) expands to (1|A) + (1|A:S) (i.e.
variability among levels of A, and variability among the interacting
levels of A and S). Fitting a crossed term as compactly as possible
would use (1|A*S), but I think this doesn't actually work: (1|A) + (1|S)
or (1|A:S) or (1|A/S)+(1|S) both describe crossed random effects of A
and S.  You may also have the nesting order backwards: (1|A/S) means
"Stream nested within Applicants", not "Applicants nested within Stream".


> 
> Linear mixed model fit by REML ['lmerMod']
> Formula: score ~ (1 | A) + (1 | S) + (1 + D) + (1 | S1) + (1 | Q) + (1 |
>     A/S) + (1 | S/D) + (1 | D/S1) + (1 | S1/Q)
>    Data: R
> REML criterion at convergence: 192.4591
> Random effects:
>  Groups   Name        Std.Dev.
>  Q.S1     (Intercept) 0.000e+00
>  A        (Intercept) 2.383e-01
>  S.A      (Intercept) 7.692e-01
>  A.1      (Intercept) 8.399e-01
>  Q        (Intercept) 0.000e+00
>  S1.D     (Intercept) 1.386e-08
>  D.S      (Intercept) 0.000e+00
>  S1       (Intercept) 0.000e+00
>  D        (Intercept) 9.498e-01
>  S        (Intercept) 0.000e+00
>  S1.1     (Intercept) 0.000e+00
>  S.1      (Intercept) 0.000e+00
>  Residual             6.722e-01
> Number of obs: 80, groups:
> Q:S1, 16; A, 10; S:A, 10; Q, 8; S1:D, 4; D:S, 4; S1, 2; D, 2; S, 2
> Fixed Effects:
> (Intercept)            D
>     1.61458     -0.07292
> convergence code 0; 2 optimizer warnings; 0 lme4 warnings
> 
>    Very much appreciated for your help.
> looking forward to hearing from you.
>    Rose
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From roserosei2030 at gmail.com  Sat Mar 11 14:17:59 2017
From: roserosei2030 at gmail.com (Rose Rosei)
Date: Sat, 11 Mar 2017 13:17:59 +0000
Subject: [R-sig-ME] Fwd:  Advice on Mixed Models
In-Reply-To: <CAEO-xr2AskbQPGyudeN3qhNfe1xZYCT_B06GXxnkN_yVKQO_4Q@mail.gmail.com>
References: <CAEO-xr3M641NWySp9qYeCPx4wAUJ3Gws6XP1TtukB-0=eBroCw@mail.gmail.com>
	<457e23eb-8c81-a97e-478e-a2a43c73ed73@gmail.com>
	<CAEO-xr2AskbQPGyudeN3qhNfe1xZYCT_B06GXxnkN_yVKQO_4Q@mail.gmail.com>
Message-ID: <CAEO-xr3vW=sRiivC9=_XdCSDkAATw304oYzJcubzk0=dwz92sQ@mail.gmail.com>

Many thanks, Professor Bolker- Very Much appriciated

When I use this model:

lmer(mark~ (1|A)+(1+D)+(1|S)+(1|Q)+ S1+ (1|S1/D/S/A), R) # session as a
fiexed effect

I got the following results, which are not consistent with the SPSS Output
( Variance Components)

Linear mixed model fit by REML ['lmerMod']
Formula: mark ~ (1 | A) + (1 + D) + (1 | S) + (1 | Q) + S1 + (1 | S1/D/S/A)
   Data: R
REML criterion at convergence: 190.5212
Random effects:
 Groups       Name        Std.Dev.
 A:(S:(D:S1)) (Intercept) 0.9581
 A            (Intercept) 0.7198
 Q            (Intercept) 0.0000
 S:(D:S1)     (Intercept) 0.0000
 D:S1         (Intercept) 0.0000
 S1           (Intercept) 1.1411
 S            (Intercept) 0.0000
 Residual                 0.6722
Number of obs: 80, groups:  A:(S:(D:S1)), 10; A, 10; Q, 8; S:(D:S1), 7;
D:S1, 4; S1, 2; S, 2
Fixed Effects:
(Intercept)            D           S1
    2.31250      0.02679     -0.59821
convergence code 0; 2 optimizer warnings; 0 lme4 warnings

SPSS output

*Variance Estimates*

Component

Estimate

Var(A)

2.443

Var(D)

-.302a

Var(S1)

-.348a

Var(O)

.093

Var(A * D)

.000b

Var(A * S1)

.000b

Var(A * O)

.548

Var(A * S)

.000b

Var(D * S1)

.139

Var(D * O)

-.074a

Var(D * S)

.554

Var(S1 * O)

-.210a

Var(S1 * S)

.644

Var(O * S)

-.124a

Var(A * D * S1)

.000b

Var(A * D * O)

.000b

Var(A * D * S)

.000b

Var(A * S1 * O)

.000b

Var(A * S1 * S)

.000b

Var(A * O * S)

.000b

Var(D * S1 * O)

.090

Var(D * S1 * S)

-1.834a

Var(D * O * S)

.070

Var(S1 * O * S)

.338

Var(A * D * S1 * O)

.000b

Var(A * D * S1 * S)

.000b

Var(A * D * O * S)

.000b

Var(A * S1 * O * S)

.000b

Var(D * S1 * O * S)

-.276a

Var(A * D * S1 * O * S)

.000b

Var(Error)

.000b

Dependent Variable: mark

 Method: Minimum Norm Quadratic Unbiased Estimation (Weight = 1 for Random
Effects and Residual)

a. For the ANOVA and MINQUE methods, negative variance component estimates
may occur. Some possible reasons for their occurrence are: (a) the
specified model is not the correct model, or (b) the true value of the
variance equals zero.

b. This estimate is set to zero because it is redundant.

When I use this model:
lmer(mark~ (1|A)+(1+D)+(1|S)+(1|Q)+ S1+ (1|S1:D/S/A), R)

I got the follwowig error

Error: couldn't evaluate grouping factor A:(S:(S1:`:`)) within model frame:
try adding grouping factor to data frame explicitly if possible
In addition: Warning message:
In S1:`:` : numerical expression has 80 elements: only the first used;

Would you advise me what went wrong with the model.

Many thanks,
Rose

On Fri, Mar 10, 2017 at 11:59 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On 17-03-08 02:01 PM, Rose Rosei wrote:
> > Dear Advisors
> >
> > Would you please advise me. I would like to fit my model, but I struggled
> > to do it
> >
> >
> >   A= Applicant = 10 persons
> >   S= Stream ( four levels, 1, 2)
>
>   Not sure what "four levels, 1, 2" means here.  Do you mean "four
> levels, 1-4" ... ?
>
> >   D= Day   (1,2)
> >  S1= Session ( 1,2)
> >  Q = Qestion ( 1-to 8)
> >  Applicants are crossed in Questions, but Applicants nested in Stream,
> >   nested in Day, nested in session (S1). All variables are a a random
> factor
>
>   You need to know that **with modern mixed-model machinery (e.g. nlme,
> lme4 as opposed to aov() in R) it is not in general practical to
> estimate random-effects terms for variables with fewer than 5 or 6
> levels**.
> See e.g. http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#singu
> lar-fit
>
> >
> >    I want to calculate SD for A, S, D, S1 and Q, and their interaction
> > .score=dependent variable
> >
> >  I have used the following codes, but it seems they are wrong.
> >
> >  lmer(score~ (1|A)+(1|S)+(1+D)+(1|S1)+(1|Q)
> +(1|A/S)+1|S/D)+(1|D/S1)+(1|S1/Q),
> > R)
>
>   (1|S1/D/S/A) gives "Applicants nested in Stream, nested in Day, nested
> in session (S1)".  As I said above, it would be wiser if possible to use
> S1+ (1|S1:D/S/A) (i.e. treat session as a fixed effect).
> I would probably handle questions via (1|Q); if each applicant receives
> each question no more than once within a session/day/stream combination,
> then the S1:D:S:A:Q interaction will be handled by the residual variance
> term.
>
> In addition to the problems stated above, many of these terms are
> redundant.  The nesting syntax (1|A/S) expands to (1|A) + (1|A:S) (i.e.
> variability among levels of A, and variability among the interacting
> levels of A and S). Fitting a crossed term as compactly as possible
> would use (1|A*S), but I think this doesn't actually work: (1|A) + (1|S)
> or (1|A:S) or (1|A/S)+(1|S) both describe crossed random effects of A
> and S.  You may also have the nesting order backwards: (1|A/S) means
> "Stream nested within Applicants", not "Applicants nested within Stream".
>
>
> >
> > Linear mixed model fit by REML ['lmerMod']
> > Formula: score ~ (1 | A) + (1 | S) + (1 + D) + (1 | S1) + (1 | Q) + (1 |
> >     A/S) + (1 | S/D) + (1 | D/S1) + (1 | S1/Q)
> >    Data: R
> > REML criterion at convergence: 192.4591
> > Random effects:
> >  Groups   Name        Std.Dev.
> >  Q.S1     (Intercept) 0.000e+00
> >  A        (Intercept) 2.383e-01
> >  S.A      (Intercept) 7.692e-01
> >  A.1      (Intercept) 8.399e-01
> >  Q        (Intercept) 0.000e+00
> >  S1.D     (Intercept) 1.386e-08
> >  D.S      (Intercept) 0.000e+00
> >  S1       (Intercept) 0.000e+00
> >  D        (Intercept) 9.498e-01
> >  S        (Intercept) 0.000e+00
> >  S1.1     (Intercept) 0.000e+00
> >  S.1      (Intercept) 0.000e+00
> >  Residual             6.722e-01
> > Number of obs: 80, groups:
> > Q:S1, 16; A, 10; S:A, 10; Q, 8; S1:D, 4; D:S, 4; S1, 2; D, 2; S, 2
> > Fixed Effects:
> > (Intercept)            D
> >     1.61458     -0.07292
> > convergence code 0; 2 optimizer warnings; 0 lme4 warnings
> >
> >    Very much appreciated for your help.
> > looking forward to hearing from you.
> >    Rose
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thlytras at gmail.com  Tue Mar 14 11:02:53 2017
From: thlytras at gmail.com (Theodore Lytras)
Date: Tue, 14 Mar 2017 12:02:53 +0200
Subject: [R-sig-ME] Prediction interval for the difference of a pair of
	outcomes
Message-ID: <3311774.7jcL3GKvV6@equinox2>

Dear all,

I'll try to keep this as brief as possible. Some time ago I asked about joint 
(linear mixed-effects) modelling of two correlated outcomes, of the form:

m1 <- lmer(Y1 ~ age + X + (age | id), data=dat)
m2 <- lmer(Y2 ~ age + X + (age | id), data=dat)

Thierry Onkelinx very helpfully suggested the following:

library(tidyr)
long <- gather(dat, key = "trait", value = "Y", Y1, Y2)
lmer(Y ~ 0 + trait + trait * (age + X) + (0 + trait:age | id), data = long)

which was perfect and indeed worked as expected.

Now, I am trying to draw predictions (+prediction intervals) from this model. 
I've read (among other stuff) the instructions on glmm.wikidot.com/faq, and 
also this past message:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020809.html

Thus I have two questions:

(1) If my interest is in predicting the response of a single unobserved 
individual, accounting for all the random effects (=marginalizing over the 
random effects, I think), which variances should I add together to construct 
my prediction interval? 

My understanding is that I would have to add (a) the variance due to the fixed 
coefficients (betas), (b) the variance due to the random effects, AND (c) the 
residual variance. Is this correct????

I've become rather confused because among the examples provided on the  
glmm.wikidot.com/faq page, I see the lme and glmmADMB examples add (a) + (c), 
ignoring the (b), while the lme4 example adds (a) + (b), ignoring the (c). 
Maybe some extra detail would help a lot.


(2) Assuming that I do indeed need (a) + (b) + (c) to calculate prediction 
intervals from my above described model, for one outcome (trait) only. 
What if I want to calculate prediction intervals for the **difference** 
between my two modelled outcomes, for a single unobserved individual? 
Which variances and covariances should I account for??

Given that: Var(a*A + b*B) = a^2*Var(A) + b^2*Var(B) + 2*a*b*cov(A,B) ,
I can calculate (b), i.e. the variance due to the random effects, using the 
correlations between the random effects. 
Also I think I'll need to add **twice** the residual variance (c); is this 
correct??
What I'm more in doubt about is the (a), i.e. the variance due to the fixed 
effects. Don't I somehow have to account for the correlations between my fixed 
effects terms, and if so, how should I go about doing that?? 


An extension of this latest question: say I move away from lme4 and run this 
particular model in JAGS (in fact I did this already as an experiment), 
calculating (b) and (c), and thus the limits of my 95% PI (for the difference 
between the two outcomes), over the whole MCMC chain.

Since integrating over the MCMC chain automatically estimates the uncertainty 
over any derived parameter (in this case, the difference between the 
outcomes), shouldn't this account for any correlation between my fixed effects 
terms as well? Thus problem solved??

Any help is greatly appreciated!

Thanks in advance,

Theodore Lytras

Epidemiologist, PhD student
Hellenic Centre for Disease Control and Prevention


From highstat at highstat.com  Wed Mar 15 10:14:30 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 15 Mar 2017 11:14:30 +0200
Subject: [R-sig-ME] Crete stats course
Message-ID: <6a7383ed-33c6-4d1d-cd92-be15643fff03@highstat.com>

There are a few remaining seats on the following course:



Course: Data exploration, regression, GLM & GAM with R

Where:  HCMR, Crete, Greece

When:   24-28 April 2017

Course website: http://www.highstat.com/statscourse.htm

Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf


Kind regards,

Alain Zuur


Other open courses in 2017:

Introduction to Regression Models with Spatial and Temporal Correlation. 
8-12 May 2017. Genoa, Italy.
Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian 
approaches. 9-13 October 2017. Trondheim, Norway.
Introduction to Regression Models with Spatial and Temporal Correlation. 
23-27 October 2017. Southampton, UK
Data exploration, regression, GLM & GAM with introduction to R. 18-22 
September 2017. Edmonton, Canada.
Introduction to Regression Models with Spatial and Temporal Correlation. 
4-8 December 2017. Banff, Canada.







-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From f_fran03 at uni-muenster.de  Wed Mar 15 10:46:02 2017
From: f_fran03 at uni-muenster.de (f_fran03 at uni-muenster.de)
Date: Wed, 15 Mar 2017 10:46:02 +0100 (CET)
Subject: [R-sig-ME] Quadratic term in linear model and model
	over-parameterization
Message-ID: <permail-201703150946028218e1ae00007d18-f_fran03@message-id.uni-muenster.de>

Dear all,

I?m new to this mailing list and really hope that somebody here can help me with the following issue:

I calculated the following linear models on a BoxCox transformed response variable with 382 data points:
Model 1: Y~x+a+b+c+d+e+(a*b)+(a*c)+ (a*d)+?+(a*b*c)+(a*b*d)+(a*b*e)+?
a: 'Experimental Temperature' (Temp1, Temp2)
b: 'Host Population' (PopX, PopY)
c: 'Parasite Population' (PopX, PopY)
d: 'Host Gender' (male, female)
Additionally, I included the continuous predictor variable 'Parasite Weight' (e) and all possible 2-way (10 interactions) and 3-way (10 interactions) interactions into the model.

In model 2 I replaced the two main effects 'Host Population' and 'Parasite Population' with one variable ('Sympatry/Allopatry') that combines the two effects. Apart from this, model 2 (six 2-way interactions and four 3-way interactions) was identical to model 1.

I am interested now in all interactions that include the continuous predictor variable 'Parasite Weight'. I got such a significant interaction ('Experimental Temperature x Parasite Population x Parasite Weight', p = 0.010) from model 1.

We sent a manuscript containing these two models to a journal for review and got it back now with a comment from a reviewer who suggested that we look for non-linear relationships involving 'Parasite Weight'.

Thus, I calculated model 1.2 which corresponds to model 1 but additionally added the quadratic term of 'Parasite Weight' ('Parasite Weight^2') and the respective interactions (in total 14 x 2-way interactions and 16 x 3-way interactions). I did the same for model 2, which resulted in model 2.2 with nine 2-way interactions and seven 3-way interactions.

The significant interaction I found with model 1 was not significant anymore with model 1.2 and in model 2.2 two interactions became significant ('Host Gender x Sympatry/Allopatry x Parasite Weight', p = 0.038 and 'Host Gender x Sympatry/Allopatry x Parasite Weight^2', p = 0.044) that were not significant in model 2.

Here are my questions:
1. Why is it that including the quadratic term removes some significant effects while adding others?
2. What does it mean when both an interaction including the linear term and the same interaction including the quadratic term become significant? Does this suggest a non-linear relationship or both a linear and a non-linear relationship?
3. Could it be that the disappearance of the interaction that was significant in model 1, is caused by an over-parameterization of model 1.2 and how can I prove this (with all the models we have the potential problem of many interactions and main effects)?
4. Are there any general arguments for when to include a quadratic term into a model and when quadratic terms should be avoided?
5. Which model can I trust?

Thank you very much in advance for any advice you can give me,

Fred.


From thierry.onkelinx at inbo.be  Wed Mar 15 10:56:23 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 15 Mar 2017 10:56:23 +0100
Subject: [R-sig-ME] Quadratic term in linear model and model
	over-parameterization
In-Reply-To: <permail-201703150946028218e1ae00007d18-f_fran03@message-id.uni-muenster.de>
References: <permail-201703150946028218e1ae00007d18-f_fran03@message-id.uni-muenster.de>
Message-ID: <CAJuCY5x-_N3+1kGkoEVPBFNYKQJY3jFouoP0VcBMDgvaNhzi3w@mail.gmail.com>

Dear Fred,

This looks like a linear model and not a linear mixed model. This
mailing list is dedicated to mixed models.

I strongly recommend to find a local statistician. All your models
seem way to complex given the data. As a rule of thumb you need at
least 10 observations for each parameter in your model. Adding the
quadratic terms increases the number of parameters and only make the
problem worse.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-15 10:46 GMT+01:00  <f_fran03 at uni-muenster.de>:
> Dear all,
>
> I?m new to this mailing list and really hope that somebody here can help me with the following issue:
>
> I calculated the following linear models on a BoxCox transformed response variable with 382 data points:
> Model 1: Y~x+a+b+c+d+e+(a*b)+(a*c)+ (a*d)+?+(a*b*c)+(a*b*d)+(a*b*e)+?
> a: 'Experimental Temperature' (Temp1, Temp2)
> b: 'Host Population' (PopX, PopY)
> c: 'Parasite Population' (PopX, PopY)
> d: 'Host Gender' (male, female)
> Additionally, I included the continuous predictor variable 'Parasite Weight' (e) and all possible 2-way (10 interactions) and 3-way (10 interactions) interactions into the model.
>
> In model 2 I replaced the two main effects 'Host Population' and 'Parasite Population' with one variable ('Sympatry/Allopatry') that combines the two effects. Apart from this, model 2 (six 2-way interactions and four 3-way interactions) was identical to model 1.
>
> I am interested now in all interactions that include the continuous predictor variable 'Parasite Weight'. I got such a significant interaction ('Experimental Temperature x Parasite Population x Parasite Weight', p = 0.010) from model 1.
>
> We sent a manuscript containing these two models to a journal for review and got it back now with a comment from a reviewer who suggested that we look for non-linear relationships involving 'Parasite Weight'.
>
> Thus, I calculated model 1.2 which corresponds to model 1 but additionally added the quadratic term of 'Parasite Weight' ('Parasite Weight^2') and the respective interactions (in total 14 x 2-way interactions and 16 x 3-way interactions). I did the same for model 2, which resulted in model 2.2 with nine 2-way interactions and seven 3-way interactions.
>
> The significant interaction I found with model 1 was not significant anymore with model 1.2 and in model 2.2 two interactions became significant ('Host Gender x Sympatry/Allopatry x Parasite Weight', p = 0.038 and 'Host Gender x Sympatry/Allopatry x Parasite Weight^2', p = 0.044) that were not significant in model 2.
>
> Here are my questions:
> 1. Why is it that including the quadratic term removes some significant effects while adding others?
> 2. What does it mean when both an interaction including the linear term and the same interaction including the quadratic term become significant? Does this suggest a non-linear relationship or both a linear and a non-linear relationship?
> 3. Could it be that the disappearance of the interaction that was significant in model 1, is caused by an over-parameterization of model 1.2 and how can I prove this (with all the models we have the potential problem of many interactions and main effects)?
> 4. Are there any general arguments for when to include a quadratic term into a model and when quadratic terms should be avoided?
> 5. Which model can I trust?
>
> Thank you very much in advance for any advice you can give me,
>
> Fred.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ukoether at uke.de  Wed Mar 15 11:13:34 2017
From: ukoether at uke.de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Wed, 15 Mar 2017 11:13:34 +0100
Subject: [R-sig-ME] Quadratic term in linear model and model
 over-parameterization
In-Reply-To: <permail-201703150946028218e1ae00007d18-f_fran03@message-id.uni-muenster.de>
References: <permail-201703150946028218e1ae00007d18-f_fran03@message-id.uni-muenster.de>
Message-ID: <27c6d1a9-db78-f8f1-f9df-e3f8ea48621f@uke.de>

Dear Fred,

I have to say... wow! Really, you got *only* the comment about adding a
quadratic effect to the model?!? The review process itself seems to be
much more ill-conditioned these days than I thought...

First, this is the mailing list for mixed effects models, i.e.,
multilevel models. Your question seems to be on "normal" linear models
(which are a special case of the former without any random effects) and
you offered no hint on any pseudoreplication in your data, i.e., no
random effects that you fitted. Are all of your data points really
independent? If so, this might not be the right mailing list to ask your
question.

Second, to give you some hints about where to start your modelling
endeavour:

You need about 10-15 data points (rule of thumb) to reliably estimate
one parameter, so you have about 382 / 15 = 25 possible parameters you
can estimate. Your models are overfitted! And the p-values you are
getting are totally nonsensical in my opinion (besides the discussion
about the sense of p-values at all).

So, regarding your question 5: NONE!

You should start at reading Frank Harrell's 2015 book "Regression
Modeling Strategies (2nd-Ed)" to give yourself a better foundation about
linear models. You really have to begin with the basics of what you are
doing...
And in that book you'll also find answers to all the other question you
asked.

Sorry for being a bit harsh here, but I do not know another way of
telling you this.

Good luck!




Am 15.03.2017 um 10:46 schrieb f_fran03 at uni-muenster.de:
> Dear all,
> 
> I?m new to this mailing list and really hope that somebody here can help me with the following issue:
> 
> I calculated the following linear models on a BoxCox transformed response variable with 382 data points:
> Model 1: Y~x+a+b+c+d+e+(a*b)+(a*c)+ (a*d)+?+(a*b*c)+(a*b*d)+(a*b*e)+?
> a: 'Experimental Temperature' (Temp1, Temp2)
> b: 'Host Population' (PopX, PopY)
> c: 'Parasite Population' (PopX, PopY)
> d: 'Host Gender' (male, female)
> Additionally, I included the continuous predictor variable 'Parasite Weight' (e) and all possible 2-way (10 interactions) and 3-way (10 interactions) interactions into the model.
> 
> In model 2 I replaced the two main effects 'Host Population' and 'Parasite Population' with one variable ('Sympatry/Allopatry') that combines the two effects. Apart from this, model 2 (six 2-way interactions and four 3-way interactions) was identical to model 1.
> 
> I am interested now in all interactions that include the continuous predictor variable 'Parasite Weight'. I got such a significant interaction ('Experimental Temperature x Parasite Population x Parasite Weight', p = 0.010) from model 1.
> 
> We sent a manuscript containing these two models to a journal for review and got it back now with a comment from a reviewer who suggested that we look for non-linear relationships involving 'Parasite Weight'.
> 
> Thus, I calculated model 1.2 which corresponds to model 1 but additionally added the quadratic term of 'Parasite Weight' ('Parasite Weight^2') and the respective interactions (in total 14 x 2-way interactions and 16 x 3-way interactions). I did the same for model 2, which resulted in model 2.2 with nine 2-way interactions and seven 3-way interactions.
> 
> The significant interaction I found with model 1 was not significant anymore with model 1.2 and in model 2.2 two interactions became significant ('Host Gender x Sympatry/Allopatry x Parasite Weight', p = 0.038 and 'Host Gender x Sympatry/Allopatry x Parasite Weight^2', p = 0.044) that were not significant in model 2.
> 
> Here are my questions:
> 1. Why is it that including the quadratic term removes some significant effects while adding others?
> 2. What does it mean when both an interaction including the linear term and the same interaction including the quadratic term become significant? Does this suggest a non-linear relationship or both a linear and a non-linear relationship?
> 3. Could it be that the disappearance of the interaction that was significant in model 1, is caused by an over-parameterization of model 1.2 and how can I prove this (with all the models we have the potential problem of many interactions and main effects)?
> 4. Are there any general arguments for when to include a quadratic term into a model and when quadratic terms should be avoided?
> 5. Which model can I trust?
> 
> Thank you very much in advance for any advice you can give me,
> 
> Fred.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From mmonasterolo at agro.uba.ar  Thu Mar 16 22:15:11 2017
From: mmonasterolo at agro.uba.ar (Marcos Monasterolo)
Date: Thu, 16 Mar 2017 18:15:11 -0300
Subject: [R-sig-ME] GLMM - selection of models
Message-ID: <CAJ-MGDTqJV+i22CwXCy5JJJskbO3+qhhi0NijPANimtzYfyQHQ@mail.gmail.com>

Dear all. I am working with a GLMM in the lme4 package using 6 fixed
factors and 1 random factor (plot). The syntax of my model is as follows:

 M1 <- glmer(riquinsec~  adjacent field+ exph200+db500+exph500+db200+width+
(1|plot), data = comuni1, family = poisson)

I need to make a selection of models to get rid of non relevant variables,
but the "step" function in lme4 is not appropriate for GLMM models.
Which function can I use for a selection of models in GLMM?

Thanks in advance for you kind help.

----
Bi?l. Marcos Monasterolo
Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a, UBA

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Mar 16 22:31:41 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 16 Mar 2017 17:31:41 -0400
Subject: [R-sig-ME] GLMM - selection of models
In-Reply-To: <CAJ-MGDTqJV+i22CwXCy5JJJskbO3+qhhi0NijPANimtzYfyQHQ@mail.gmail.com>
References: <CAJ-MGDTqJV+i22CwXCy5JJJskbO3+qhhi0NijPANimtzYfyQHQ@mail.gmail.com>
Message-ID: <CABghstT7pVrvuUG8popHkhijQuYgkNGLaDebyaVSEV2xUF7xfg@mail.gmail.com>

There are strong theoretical arguments for **not** doing stepwise
selection on models (any kind, at all), e.g.
http://www.stata.com/support/faqs/statistics/stepwise-regression-problems/.
If you must, you can use `drop1()` to semi-automate the process, or
you can use MuMIn::dredge to do all-subsets fitting.

On Thu, Mar 16, 2017 at 5:15 PM, Marcos Monasterolo
<mmonasterolo at agro.uba.ar> wrote:
> Dear all. I am working with a GLMM in the lme4 package using 6 fixed
> factors and 1 random factor (plot). The syntax of my model is as follows:
>
>  M1 <- glmer(riquinsec~  adjacent field+ exph200+db500+exph500+db200+width+
> (1|plot), data = comuni1, family = poisson)
>
> I need to make a selection of models to get rid of non relevant variables,
> but the "step" function in lme4 is not appropriate for GLMM models.
> Which function can I use for a selection of models in GLMM?
>
> Thanks in advance for you kind help.
>
> ----
> Bi?l. Marcos Monasterolo
> Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a, UBA
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tom_philippi at nps.gov  Thu Mar 16 23:19:03 2017
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Thu, 16 Mar 2017 15:19:03 -0700
Subject: [R-sig-ME] GLMM - selection of models
In-Reply-To: <CABghstT7pVrvuUG8popHkhijQuYgkNGLaDebyaVSEV2xUF7xfg@mail.gmail.com>
References: <CAJ-MGDTqJV+i22CwXCy5JJJskbO3+qhhi0NijPANimtzYfyQHQ@mail.gmail.com>
	<CABghstT7pVrvuUG8popHkhijQuYgkNGLaDebyaVSEV2xUF7xfg@mail.gmail.com>
Message-ID: <CAM9kYqjyFhBptn0_wS1nd+_+q6cY3mGoqfoUqAF55amJ2tPFow@mail.gmail.com>

In addition to what Dr. Bolker wrote, note that for family=poisson, as you
add or drop fixed effects, there will be different amounts of
overdispersion among the models fits.  This can be an issue that affects
both the mechanics and interpretation of any form of model selection or
averaging.  May you be luckier with your data and overdispersion than I
tend to be with mine.

Tom 2


On Thu, Mar 16, 2017 at 2:31 PM, Ben Bolker <bbolker at gmail.com> wrote:

> There are strong theoretical arguments for **not** doing stepwise
> selection on models (any kind, at all), e.g.
> http://www.stata.com/support/faqs/statistics/stepwise-regression-problems/
> .
> If you must, you can use `drop1()` to semi-automate the process, or
> you can use MuMIn::dredge to do all-subsets fitting.
>
> On Thu, Mar 16, 2017 at 5:15 PM, Marcos Monasterolo
> <mmonasterolo at agro.uba.ar> wrote:
> > Dear all. I am working with a GLMM in the lme4 package using 6 fixed
> > factors and 1 random factor (plot). The syntax of my model is as follows:
> >
> >  M1 <- glmer(riquinsec~  adjacent field+ exph200+db500+exph500+db200+
> width+
> > (1|plot), data = comuni1, family = poisson)
> >
> > I need to make a selection of models to get rid of non relevant
> variables,
> > but the "step" function in lme4 is not appropriate for GLMM models.
> > Which function can I use for a selection of models in GLMM?
> >
> > Thanks in advance for you kind help.
> >
> > ----
> > Bi?l. Marcos Monasterolo
> > Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a,
> UBA
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From sophia.kyriakou17 at gmail.com  Thu Mar 16 23:34:31 2017
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Fri, 17 Mar 2017 00:34:31 +0200
Subject: [R-sig-ME] glmmTMB and foreach parallel adaptor
Message-ID: <CAO4gA+og=a8u4EB9Ry8cWwQL6arpcV+dXZu+qrkLx9pLx+b-XQ@mail.gmail.com>

Dear members,

I am trying to set some code running on Windows, which calculates and
returns the Laplace-based maximum likelihood estimates of a generalized
linear mixed model.
Both glmer and glmmTMB functions work on R 3.3.3 when the code is executed
sequentially.
However, when I use the parallel algorithm, then glmer still works, but
glmmTMB does not.
The error I get is Error in { : task 1 failed - "object 'dat' not found" ,
where dat is the simulated dataset in each replication.

Any ideas on how to tackle this error? I am interested in using glmmTMB
instead of lme4, because I need some of glmmTMB output components.

Below is a sample code that illustrates the above:


library(doParallel)
library(glmmTMB)
library(lme4)

simSamples <- matrix(sample(0:6,300,replace=TRUE),30,10)

## Sequential version
LA <- LA2 <- matrix(NA,3,10)
for (i in 1:10){
dat <-
data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),y=simSamples[,i],yprop=simSamples[,i]/6)
fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,weights=m,data=dat)
LA[,i] <- fitLA$fit$par
fitLA2 <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
LA2[,i] <- c(fixef(fitLA2),sqrt(unlist(VarCorr(fitLA2))))
}


## Parallel version
cl <- makeCluster(3)
registerDoParallel(cl)
TMBfit <- foreach(i=1:10, .combine= cbind, .packages=c("glmmTMB")) %dopar% {
dat <-
data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),yprop=simSamples[,i]/6)
fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,weights=m,data=dat)
fitLA$fit$par
}
stopCluster(cl)


cl <- makeCluster(3)
registerDoParallel(cl)
LME4fit <- foreach(i=1:10, .combine= cbind, .packages=c("lme4")) %dopar% {
dat <-
data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),y=simSamples[,i])
fitLA <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
c(fixef(fitLA),sqrt(unlist(VarCorr(fitLA))))
}
stopCluster(cl)

Any help is much appreciated.
Thanks in advance!
Sophia

	[[alternative HTML version deleted]]


From jl.verissimo at gmail.com  Fri Mar 17 00:09:52 2017
From: jl.verissimo at gmail.com (=?ISO-8859-1?Q?Jo=E3o_Ver=EDssimo?=)
Date: Fri, 17 Mar 2017 00:09:52 +0100
Subject: [R-sig-ME] glmmTMB and foreach parallel adaptor
In-Reply-To: <CAO4gA+og=a8u4EB9Ry8cWwQL6arpcV+dXZu+qrkLx9pLx+b-XQ@mail.gmail.com>
References: <CAO4gA+og=a8u4EB9Ry8cWwQL6arpcV+dXZu+qrkLx9pLx+b-XQ@mail.gmail.com>
Message-ID: <1489705792.3479.3.camel@gmail.com>

Hi Sophia,

Not sure why this happens, but using <<- assignment seems to work.
(i.e., dat <<- ..., rather than dat <- ...)

Jo?o

On Fri, 2017-03-17 at 00:34 +0200, Sophia Kyriakou wrote:
> Dear members,
> 
> I am trying to set some code running on Windows, which calculates and
> returns the Laplace-based maximum likelihood estimates of a generalized
> linear mixed model.
> Both glmer and glmmTMB functions work on R 3.3.3 when the code is executed
> sequentially.
> However, when I use the parallel algorithm, then glmer still works, but
> glmmTMB does not.
> The error I get is Error in { : task 1 failed - "object 'dat' not found" ,
> where dat is the simulated dataset in each replication.
> 
> Any ideas on how to tackle this error? I am interested in using glmmTMB
> instead of lme4, because I need some of glmmTMB output components.
> 
> Below is a sample code that illustrates the above:
> 
> 
> library(doParallel)
> library(glmmTMB)
> library(lme4)
> 
> simSamples <- matrix(sample(0:6,300,replace=TRUE),30,10)
> 
> ## Sequential version
> LA <- LA2 <- matrix(NA,3,10)
> for (i in 1:10){
> dat <-
> data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),y=simSamples[,i],yprop=simSamples[,i]/6)
> fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,weights=m,data=dat)
> LA[,i] <- fitLA$fit$par
> fitLA2 <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
> LA2[,i] <- c(fixef(fitLA2),sqrt(unlist(VarCorr(fitLA2))))
> }
> 
> 
> ## Parallel version
> cl <- makeCluster(3)
> registerDoParallel(cl)
> TMBfit <- foreach(i=1:10, .combine= cbind, .packages=c("glmmTMB")) %dopar% {
> dat <-
> data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),yprop=simSamples[,i]/6)
> fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,weights=m,data=dat)
> fitLA$fit$par
> }
> stopCluster(cl)
> 
> 
> cl <- makeCluster(3)
> registerDoParallel(cl)
> LME4fit <- foreach(i=1:10, .combine= cbind, .packages=c("lme4")) %dopar% {
> dat <-
> data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),y=simSamples[,i])
> fitLA <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
> c(fixef(fitLA),sqrt(unlist(VarCorr(fitLA))))
> }
> stopCluster(cl)
> 
> Any help is much appreciated.
> Thanks in advance!
> Sophia
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From sophia.kyriakou17 at gmail.com  Fri Mar 17 00:51:08 2017
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Fri, 17 Mar 2017 01:51:08 +0200
Subject: [R-sig-ME] glmmTMB and foreach parallel adaptor
In-Reply-To: <1489705792.3479.3.camel@gmail.com>
References: <CAO4gA+og=a8u4EB9Ry8cWwQL6arpcV+dXZu+qrkLx9pLx+b-XQ@mail.gmail.com>
	<1489705792.3479.3.camel@gmail.com>
Message-ID: <CAO4gA+qsECgv-pkJEGT6gVOF-63Rwj_vsskP-da0MOyPD6=-Ag@mail.gmail.com>

Thanks Jo?o, indeed the scoping assignment works.
All the best,
Sophia

On Fri, Mar 17, 2017 at 1:09 AM, Jo?o Ver?ssimo <jl.verissimo at gmail.com>
wrote:

> Hi Sophia,
>
> Not sure why this happens, but using <<- assignment seems to work.
> (i.e., dat <<- ..., rather than dat <- ...)
>
> Jo?o
>
> On Fri, 2017-03-17 at 00:34 +0200, Sophia Kyriakou wrote:
> > Dear members,
> >
> > I am trying to set some code running on Windows, which calculates and
> > returns the Laplace-based maximum likelihood estimates of a generalized
> > linear mixed model.
> > Both glmer and glmmTMB functions work on R 3.3.3 when the code is
> executed
> > sequentially.
> > However, when I use the parallel algorithm, then glmer still works, but
> > glmmTMB does not.
> > The error I get is Error in { : task 1 failed - "object 'dat' not found"
> ,
> > where dat is the simulated dataset in each replication.
> >
> > Any ideas on how to tackle this error? I am interested in using glmmTMB
> > instead of lme4, because I need some of glmmTMB output components.
> >
> > Below is a sample code that illustrates the above:
> >
> >
> > library(doParallel)
> > library(glmmTMB)
> > library(lme4)
> >
> > simSamples <- matrix(sample(0:6,300,replace=TRUE),30,10)
> >
> > ## Sequential version
> > LA <- LA2 <- matrix(NA,3,10)
> > for (i in 1:10){
> > dat <-
> > data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
> y=simSamples[,i],yprop=simSamples[,i]/6)
> > fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
> weights=m,data=dat)
> > LA[,i] <- fitLA$fit$par
> > fitLA2 <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
> > LA2[,i] <- c(fixef(fitLA2),sqrt(unlist(VarCorr(fitLA2))))
> > }
> >
> >
> > ## Parallel version
> > cl <- makeCluster(3)
> > registerDoParallel(cl)
> > TMBfit <- foreach(i=1:10, .combine= cbind, .packages=c("glmmTMB"))
> %dopar% {
> > dat <-
> > data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
> yprop=simSamples[,i]/6)
> > fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
> weights=m,data=dat)
> > fitLA$fit$par
> > }
> > stopCluster(cl)
> >
> >
> > cl <- makeCluster(3)
> > registerDoParallel(cl)
> > LME4fit <- foreach(i=1:10, .combine= cbind, .packages=c("lme4")) %dopar%
> {
> > dat <-
> > data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
> y=simSamples[,i])
> > fitLA <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
> > c(fixef(fitLA),sqrt(unlist(VarCorr(fitLA))))
> > }
> > stopCluster(cl)
> >
> > Any help is much appreciated.
> > Thanks in advance!
> > Sophia
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From tom_philippi at nps.gov  Fri Mar 17 01:10:08 2017
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Thu, 16 Mar 2017 17:10:08 -0700
Subject: [R-sig-ME] glmmTMB and foreach parallel adaptor
In-Reply-To: <CAO4gA+qsECgv-pkJEGT6gVOF-63Rwj_vsskP-da0MOyPD6=-Ag@mail.gmail.com>
References: <CAO4gA+og=a8u4EB9Ry8cWwQL6arpcV+dXZu+qrkLx9pLx+b-XQ@mail.gmail.com>
	<1489705792.3479.3.camel@gmail.com>
	<CAO4gA+qsECgv-pkJEGT6gVOF-63Rwj_vsskP-da0MOyPD6=-Ag@mail.gmail.com>
Message-ID: <CAM9kYqjO69W48OKamDdYYf8MF6i9Jn93fnGHFjApwODcUAqNUw@mail.gmail.com>

I try to avoid variable scoping (environment) confusion by wrapping my
inner stuff as a simple function:

cl <- makeCluster(3)
registerDoParallel(cl)

fn <- function(i) {
  dat <- data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
yprop=simSamples[,i]/6)
  fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
weights=m,data=dat)
  return(fitLA$fit$par)
}

TMBfit <- foreach(i=1:10, .combine= cbind, .inorder=FALSE,
.packages=c("glmmTMB")) %dopar% fn(i)
stopCluster(cl)

With .inorder=FALSE you may or may not need to return a list with i as well:
return(list(i=i,par=fitLA$fit$par))

Tom 2





On Thu, Mar 16, 2017 at 4:51 PM, Sophia Kyriakou <
sophia.kyriakou17 at gmail.com> wrote:

> Thanks Jo?o, indeed the scoping assignment works.
> All the best,
> Sophia
>
> On Fri, Mar 17, 2017 at 1:09 AM, Jo?o Ver?ssimo <jl.verissimo at gmail.com>
> wrote:
>
> > Hi Sophia,
> >
> > Not sure why this happens, but using <<- assignment seems to work.
> > (i.e., dat <<- ..., rather than dat <- ...)
> >
> > Jo?o
> >
> > On Fri, 2017-03-17 at 00:34 +0200, Sophia Kyriakou wrote:
> > > Dear members,
> > >
> > > I am trying to set some code running on Windows, which calculates and
> > > returns the Laplace-based maximum likelihood estimates of a generalized
> > > linear mixed model.
> > > Both glmer and glmmTMB functions work on R 3.3.3 when the code is
> > executed
> > > sequentially.
> > > However, when I use the parallel algorithm, then glmer still works, but
> > > glmmTMB does not.
> > > The error I get is Error in { : task 1 failed - "object 'dat' not
> found"
> > ,
> > > where dat is the simulated dataset in each replication.
> > >
> > > Any ideas on how to tackle this error? I am interested in using glmmTMB
> > > instead of lme4, because I need some of glmmTMB output components.
> > >
> > > Below is a sample code that illustrates the above:
> > >
> > >
> > > library(doParallel)
> > > library(glmmTMB)
> > > library(lme4)
> > >
> > > simSamples <- matrix(sample(0:6,300,replace=TRUE),30,10)
> > >
> > > ## Sequential version
> > > LA <- LA2 <- matrix(NA,3,10)
> > > for (i in 1:10){
> > > dat <-
> > > data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
> > y=simSamples[,i],yprop=simSamples[,i]/6)
> > > fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
> > weights=m,data=dat)
> > > LA[,i] <- fitLA$fit$par
> > > fitLA2 <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,
> data=dat)
> > > LA2[,i] <- c(fixef(fitLA2),sqrt(unlist(VarCorr(fitLA2))))
> > > }
> > >
> > >
> > > ## Parallel version
> > > cl <- makeCluster(3)
> > > registerDoParallel(cl)
> > > TMBfit <- foreach(i=1:10, .combine= cbind, .packages=c("glmmTMB"))
> > %dopar% {
> > > dat <-
> > > data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
> > yprop=simSamples[,i]/6)
> > > fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
> > weights=m,data=dat)
> > > fitLA$fit$par
> > > }
> > > stopCluster(cl)
> > >
> > >
> > > cl <- makeCluster(3)
> > > registerDoParallel(cl)
> > > LME4fit <- foreach(i=1:10, .combine= cbind, .packages=c("lme4"))
> %dopar%
> > {
> > > dat <-
> > > data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
> > y=simSamples[,i])
> > > fitLA <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
> > > c(fixef(fitLA),sqrt(unlist(VarCorr(fitLA))))
> > > }
> > > stopCluster(cl)
> > >
> > > Any help is much appreciated.
> > > Thanks in advance!
> > > Sophia
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From david.tn.jones at gmail.com  Fri Mar 17 02:39:53 2017
From: david.tn.jones at gmail.com (David Jones)
Date: Thu, 16 Mar 2017 20:39:53 -0500
Subject: [R-sig-ME] How to Model U-Shaped Distribution in LME4
Message-ID: <CAJgUsw+tGyHxSSKRTd6F+p7_pQ1JxsRfNiHdtULn4mPKwwUFJg@mail.gmail.com>

I am looking at medication adherence as a DV. I am having difficulty
considering how to model adherence in LME4, as the distribution is very
u-shaped.

In particular, the distribution is bimodal - participants usually
didn't adhere at all, or adhered completely (30% of responses did not
adhere at all, while 55% of responses had full adherence, despite it
being measured on a ratio scale). Q-Q and P-P plots also reflect
problems with modeling adherence as Gaussian.

I was wondering what thoughts would be regarding the best distribution
to apply to this variable - beta binomial has been mentioned, and I
was wondering if other options come to mind that are available in
LME4.

Of note, as it has turned out there have only been 8 response
categories despite adherence being a continuous measure (the measures
asked people how many pills they missed weekly; many people were
prescribed only 1 pill/day, thus there were only 8 options).

Many thanks!


From jdpo223 at g.uky.edu  Fri Mar 17 04:36:57 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Thu, 16 Mar 2017 23:36:57 -0400
Subject: [R-sig-ME] How to Model U-Shaped Distribution in LME4
In-Reply-To: <CAJgUsw+tGyHxSSKRTd6F+p7_pQ1JxsRfNiHdtULn4mPKwwUFJg@mail.gmail.com>
References: <CAJgUsw+tGyHxSSKRTd6F+p7_pQ1JxsRfNiHdtULn4mPKwwUFJg@mail.gmail.com>
Message-ID: <CAFW8ByoiU1H=f-2PK7ya-joL4XeY4TYPVJ74F1BPikQfHs6Svg@mail.gmail.com>

Given that you've only got 8 response options and the data are multimodal
it's arguable that you're best off going with a discrete choice model like
multinomial or mixed logit. You can collapse adherence, partial adherence,
and no adherence into three or four categories and then model them that
way.


On Mar 16, 2017 8:41 PM, "David Jones" <david.tn.jones at gmail.com> wrote:

I am looking at medication adherence as a DV. I am having difficulty
considering how to model adherence in LME4, as the distribution is very
u-shaped.

In particular, the distribution is bimodal - participants usually
didn't adhere at all, or adhered completely (30% of responses did not
adhere at all, while 55% of responses had full adherence, despite it
being measured on a ratio scale). Q-Q and P-P plots also reflect
problems with modeling adherence as Gaussian.

I was wondering what thoughts would be regarding the best distribution
to apply to this variable - beta binomial has been mentioned, and I
was wondering if other options come to mind that are available in
LME4.

Of note, as it has turned out there have only been 8 response
categories despite adherence being a continuous measure (the measures
asked people how many pills they missed weekly; many people were
prescribed only 1 pill/day, thus there were only 8 options).

Many thanks!

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Fri Mar 17 07:21:33 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Fri, 17 Mar 2017 07:21:33 +0100
Subject: [R-sig-ME] glmmTMB and foreach parallel adaptor
In-Reply-To: <CAM9kYqjO69W48OKamDdYYf8MF6i9Jn93fnGHFjApwODcUAqNUw@mail.gmail.com>
References: <CAO4gA+og=a8u4EB9Ry8cWwQL6arpcV+dXZu+qrkLx9pLx+b-XQ@mail.gmail.com>
	<1489705792.3479.3.camel@gmail.com>
	<CAO4gA+qsECgv-pkJEGT6gVOF-63Rwj_vsskP-da0MOyPD6=-Ag@mail.gmail.com>
	<CAM9kYqjO69W48OKamDdYYf8MF6i9Jn93fnGHFjApwODcUAqNUw@mail.gmail.com>
Message-ID: <55E64F73-E5E5-4FBC-93EA-FC1B6697F33F@gmail.com>

Hi Sophia,

I think we fixed this bug https://github.com/glmmTMB/glmmTMB/issues/209 <https://github.com/glmmTMB/glmmTMB/issues/209>

Have you installed from GitHub  in the past 2 weeks? I think this should also be fixed in the CRAN version.

If updating from GitHub doesn?t fix the problem, please file an issue or let me know and I will.

cheers,
Mollie

???????????
Mollie E. Brooks, Ph.D.
Postdoctoral Researcher
National Institute of Aquatic Resources
Technical University of Denmark

> On 17Mar 2017, at 1:10, Philippi, Tom <tom_philippi at nps.gov> wrote:
> 
> I try to avoid variable scoping (environment) confusion by wrapping my
> inner stuff as a simple function:
> 
> cl <- makeCluster(3)
> registerDoParallel(cl)
> 
> fn <- function(i) {
>  dat <- data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
> yprop=simSamples[,i]/6)
>  fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
> weights=m,data=dat)
>  return(fitLA$fit$par)
> }
> 
> TMBfit <- foreach(i=1:10, .combine= cbind, .inorder=FALSE,
> .packages=c("glmmTMB")) %dopar% fn(i)
> stopCluster(cl)
> 
> With .inorder=FALSE you may or may not need to return a list with i as well:
> return(list(i=i,par=fitLA$fit$par))
> 
> Tom 2
> 
> 
> 
> 
> 
> On Thu, Mar 16, 2017 at 4:51 PM, Sophia Kyriakou <
> sophia.kyriakou17 at gmail.com> wrote:
> 
>> Thanks Jo?o, indeed the scoping assignment works.
>> All the best,
>> Sophia
>> 
>> On Fri, Mar 17, 2017 at 1:09 AM, Jo?o Ver?ssimo <jl.verissimo at gmail.com>
>> wrote:
>> 
>>> Hi Sophia,
>>> 
>>> Not sure why this happens, but using <<- assignment seems to work.
>>> (i.e., dat <<- ..., rather than dat <- ...)
>>> 
>>> Jo?o
>>> 
>>> On Fri, 2017-03-17 at 00:34 +0200, Sophia Kyriakou wrote:
>>>> Dear members,
>>>> 
>>>> I am trying to set some code running on Windows, which calculates and
>>>> returns the Laplace-based maximum likelihood estimates of a generalized
>>>> linear mixed model.
>>>> Both glmer and glmmTMB functions work on R 3.3.3 when the code is
>>> executed
>>>> sequentially.
>>>> However, when I use the parallel algorithm, then glmer still works, but
>>>> glmmTMB does not.
>>>> The error I get is Error in { : task 1 failed - "object 'dat' not
>> found"
>>> ,
>>>> where dat is the simulated dataset in each replication.
>>>> 
>>>> Any ideas on how to tackle this error? I am interested in using glmmTMB
>>>> instead of lme4, because I need some of glmmTMB output components.
>>>> 
>>>> Below is a sample code that illustrates the above:
>>>> 
>>>> 
>>>> library(doParallel)
>>>> library(glmmTMB)
>>>> library(lme4)
>>>> 
>>>> simSamples <- matrix(sample(0:6,300,replace=TRUE),30,10)
>>>> 
>>>> ## Sequential version
>>>> LA <- LA2 <- matrix(NA,3,10)
>>>> for (i in 1:10){
>>>> dat <-
>>>> data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
>>> y=simSamples[,i],yprop=simSamples[,i]/6)
>>>> fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
>>> weights=m,data=dat)
>>>> LA[,i] <- fitLA$fit$par
>>>> fitLA2 <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,
>> data=dat)
>>>> LA2[,i] <- c(fixef(fitLA2),sqrt(unlist(VarCorr(fitLA2))))
>>>> }
>>>> 
>>>> 
>>>> ## Parallel version
>>>> cl <- makeCluster(3)
>>>> registerDoParallel(cl)
>>>> TMBfit <- foreach(i=1:10, .combine= cbind, .packages=c("glmmTMB"))
>>> %dopar% {
>>>> dat <-
>>>> data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
>>> yprop=simSamples[,i]/6)
>>>> fitLA <- glmmTMB(yprop ~ x +(1|subject),family=binomial,
>>> weights=m,data=dat)
>>>> fitLA$fit$par
>>>> }
>>>> stopCluster(cl)
>>>> 
>>>> 
>>>> cl <- makeCluster(3)
>>>> registerDoParallel(cl)
>>>> LME4fit <- foreach(i=1:10, .combine= cbind, .packages=c("lme4"))
>> %dopar%
>>> {
>>>> dat <-
>>>> data.frame(subject=rep(1:15,each=2),x=-14:15,m=rep(6,30),
>>> y=simSamples[,i])
>>>> fitLA <- glmer(cbind(y,6-y) ~ x +(1|subject),family=binomial,data=dat)
>>>> c(fixef(fitLA),sqrt(unlist(VarCorr(fitLA))))
>>>> }
>>>> stopCluster(cl)
>>>> 
>>>> Any help is much appreciated.
>>>> Thanks in advance!
>>>> Sophia
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From ilgim.hepdarcan at izmirekonomi.edu.tr  Thu Mar 16 22:55:11 2017
From: ilgim.hepdarcan at izmirekonomi.edu.tr (Ilgim Hepdarcan)
Date: Thu, 16 Mar 2017 23:55:11 +0200 (EET)
Subject: [R-sig-ME] Multilevel Model in R
In-Reply-To: <730754761.13398048.1489701160041.JavaMail.zimbra@izmirekonomi.edu.tr>
Message-ID: <476743736.13398088.1489701311792.JavaMail.zimbra@izmirekonomi.edu.tr>

Dear all! 
My study consists of 3 trials and each trial includes four different n-back types, 0-,1-,2-,3-back. Each participant had 12 n-back conditions, in a different order. Therefore, my design is within-subject design. Participants are between factors and gender of the participant is the covariate of that between factor. 


While participants were performing n-back task, I have measured their dorsolateral prefrontal cortex activation via 16-channeled fNIR and obtained oxygenated hemoglobin measures from each of the 16 channels and I'm trying to conduct multilevel analysis by using R. My fixed variable is gender and my random variable is Nback Types (which has 4 levels, 0-, 1-, 2-, and 3-back) which is categorical. In my model, participants are nested within nback types. 




Because NbackType is categorical, I've wondered whether it is okay to test random slopes. 




Last but not least, would you share your opinions about how to interpret this random slopes model? 





#Null model 
#Optode1 
library(lme4) 
library(lmerTest) 
Optode1.m1 = lmer (Optode1 ~ 1 + 
(1|participant), 
na.action = na.exclude, 
data=oxyHbConditionCellbyCell, 
REML=FALSE) 
summary(Optode1.m1) 


##Nback model Random intercept 
#Optode1 
library(lme4) 
library(lmerTest) 
Optode1.m2 = lmer (Optode1 ~ NbackType + 
(1|participant:NbackType), 
na.action = na.exclude, 
data=oxyHbConditionCellbyCell, 
REML=FALSE) 
summary(Optode1.m2) 

##Nback model Random slope 
#Optode1 
library(lme4) 
library(lmerTest) 
Optode1.m3 = lmer (Optode1 ~ NbackType + 
(NbackType|participant), 
na.action = na.exclude, 
data=oxyHbConditionCellbyCell, 
REML=FALSE) 
summary(Optode1.m3) 




##Nback gender model Random intercept 
#Optode1 
library(lme4) 
library(lmerTest) 
Optode1.m4 = lmer (Optode1 ~ NbackType + gender + 
(1|participant:NbackType), 
na.action = na.exclude, 
data=oxyHbConditionCellbyCell, 
REML=FALSE) 
summary(Optode1.m4) 




##Nback gender model Random intercept 
#Optode1 
library(lme4) 
library(lmerTest) 
Optode1.m5 = lmer (Optode1 ~ NbackType + gender + 
(NbackType|participant), 
na.action = na.exclude, 
data=oxyHbConditionCellbyCell, 
REML=FALSE) 
summary(Optode1.m5) 




##Nback gender model Random intercept 
#Optode1 
library(lme4) 
library(lmerTest) 
Optode1.m6 = lmer (Optode1 ~ NbackType * gender + 
(1|participant:NbackType), 
na.action = na.exclude, 
data=oxyHbConditionCellbyCell, 
REML=FALSE) 
summary(Optode1.m6) 




##Nback gender interaction model Random slope 
#Optode1 
library(lme4) 
library(lmerTest) 
Optode1.m7 = lmer (Optode1 ~ NbackType * gender + 
(NbackType|participant), 
na.action = na.exclude, 
data=oxyHbConditionCellbyCell, 
REML=FALSE) 
summary(Optode1.m7) 




anova(Optode1.m1,Optode1.m2,Optode1.m3,Optode1.m4,Optode1.m5,Optode1.m6,Optode1.m7) 


Ilg?m Hepdarcan 
Izmir University of Economics 
Experimental Psychology MD 


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Mar 19 20:55:22 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 19 Mar 2017 15:55:22 -0400
Subject: [R-sig-ME] How the interpret non-significant Intercept value in
 Fixed Effects Table?
In-Reply-To: <843054155.13602331.1489951181822.JavaMail.zimbra@izmirekonomi.edu.tr>
References: <1417728076.13602003.1489951075478.JavaMail.zimbra@izmirekonomi.edu.tr>
	<843054155.13602331.1489951181822.JavaMail.zimbra@izmirekonomi.edu.tr>
Message-ID: <CABghstQZ=BowePv9vGaMWp2p9amjoaE6eOEJk1z4v8pKs+9f1A@mail.gmail.com>

On Sun, Mar 19, 2017 at 3:19 PM, Ilgim Hepdarcan
<ilgim.hepdarcan at izmirekonomi.edu.tr> wrote:
>  Dear all,
>>
>> I'm conducting multilevel linear mixed effects model analysis for my MD
>> Thesis, but I've got confused about the models and the results of the
>> models that I've tested.
>>
>> So, my study consists of 3 trials and each trial includes four different
>> n-back types, 0-,1-,2-,3-back. Each participant had 12 n-back
>> conditions, in a different order. Therefore, my design is within-subject
>> design. Participants are between factors and gender of the participant
>> is the covariate of that between factor.
>>
>> While participants were performing n-back task, I have measured their
>> dorsolateral prefrontal cortex activation via 16-channeled fNIR and
>> obtained oxygenated hemoglobin measures from each of the 16 channels and
>> I'm trying to conduct multilevel analysis by using R. My fixed variable
>> is gender and my random variable is Nback Types (which has 4 levels, 0-,
>> 1-, 2-, and 3-back) which is categorical. In my model, participants are
>> nested within Nback types.

These statements seem a little surprising and inconsistent with what I
understand about your
design.  "participants are nested within Nback types" would suggest
that each participant
gets only a single Nback type (and that there are multiple patients
per Nback type),
which seems inconsistent with your statement "each participant had 12
n-back conditions".
(Does each participant get each of the 4 n-back conditions exactly 3
times?  That isn't
necessary but would probably maximize statistical power.) Also, you
say "my random variable
is Nback types", which seems surprising and is inconsistent with the
formulas you give
below (which include Nback type as a fixed effect)

>> Because NbackType is categorical, I've wondered whether it is okay to
>> test random slopes.

 Yes: "random slopes" for categorical predictors equates to
"among-individual variation in effects".

>>
>> #Null model
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m1 = lmer (Optode1 ~ 1 +
>> (1|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m1)
>>
>> ##Nback model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m2 = lmer (Optode1 ~ NbackType +
>> (1|participant:NbackType),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m2)
>> ##Nback model Random slope
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m3 = lmer (Optode1 ~ NbackType +
>> (NbackType|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m3)
>>
>> ##Nback gender model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m4 = lmer (Optode1 ~ NbackType + gender +
>> (1|participant:NbackType),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m4)
>>
>> ##Nback gender model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m5 = lmer (Optode1 ~ NbackType + gender +
>> (NbackType|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m5)
>>
>> ##Nback gender model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m6 = lmer (Optode1 ~ NbackType * gender +
>> (1|participant:NbackType),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m6)
>>
>> ##Nback gender interaction model Random slope
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m7 = lmer (Optode1 ~ NbackType * gender +
>> (NbackType|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m7)
>>
>>
>> anova(Optode1.m1,Optode1.m2,Optode1.m3,Optode1.m4,Optode1.m5,Optode1.m6,Optode1.m7)
>>
>> Result of the ANOVA
>>
>>>
>>> anova(Optode1.m1,Optode1.m2,Optode1.m3,Optode1.m4,Optode1.m5,Optode1.m6,Optode1.m7)
>> Data: oxyHbConditionCellbyCell
>> Models:
>> object: Optode1 ~ 1 + (1 | participant)
>> ..1: Optode1 ~ NbackType + (1 | participant:NbackType)
>> ..3: Optode1 ~ NbackType + gender + (1 | participant:NbackType)
>> ..5: Optode1 ~ NbackType * gender + (1 | participant:NbackType)
>> ..2: Optode1 ~ NbackType + (NbackType | participant)
>> ..4: Optode1 ~ NbackType + gender + (NbackType | participant)
>> ..6: Optode1 ~ NbackType * gender + (NbackType | participant)
>> Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq)
>> object 3 34885 34910 -17439.6 34879
>> ..1 6 16010 16059 -7999.0 15998 18881.1967 3 < 2e-16 ***
>> ..3 7 16012 16069 -7999.0 15998 0.0471 1 0.82819
>> ..5 10 16011 16093 -7995.6 15991 6.8243 3 0.07771 .
>> ..2 15 16013 16136 -7991.6 15983 8.0654 5 0.15267
>> ..4 16 16015 16146 -7991.4 15983 0.4057 1 0.52416
>> ..6 19 16014 16170 -7988.1 15976 6.4941 3 0.08990 .
>> ---
>> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


You might want to make your null model

 ~ 1 + (1 | participant/NbackType)

and your subsequent (non-random-slope) models should probably use the
same random effect term. This makes participants *crossed* with NbackType (there
is a random effect of participant, potentially a fixed effect of NbackType, and
a random effect of the interaction between NbackType and participant).

  Your anova above suggests that the *combination* of NbackType and variation
of NbackType within participant is significant.

While it's not impossible for the overall anova result to be
significant while the individual
levels aren't, in this case I think the mismatch comes from the
mismatch in the random
effects term between the full and null models.

>>
>> As the ANOVA results indicated the significant model states at the below.
>>
>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite
>> approximations to degrees of freedom [lmerMod]
>> Formula: Optode1 ~ NbackType + (1 | participant:NbackType)
>> Data: oxyHbConditionCellbyCell
>>
>> AIC BIC logLik deviance df.resid
>> 16010.1 16059.2 -7999.0 15998.1 26369
>>
>> Scaled residuals:
>> Min 1Q Median 3Q Max
>> -4.7604 -0.4671 -0.0612 0.4037 7.3160
>>
>> Random effects:
>> Groups Name Variance Std.Dev.
>> participant:NbackType (Intercept) 0.1653 0.4065
>>  Residual 0.1036 0.3219
>> Number of obs: 26375, groups: participant:NbackType, 172
>>
>> Fixed effects:
>> Estimate Std. Error df t value Pr(>|t|)
>> (Intercept) -0.05137 0.06212 172.02000 -0.827 0.409
>> NbackTypeoneback 0.01459 0.08785 172.02000 0.166 0.868
>> NbackTypetwoback 0.01540 0.08785 172.02000 0.175 0.861
>> NbackTypethreeback -0.05264 0.08785 172.02000 -0.599 0.550
>>
>> But, none of them is significant even my Intercept. How should I
>> interpret this result?
>>
>> Your answer is extremely important for me.
>>
>> Thank you in advance.
>>
>> Ilg?m Hepdarcan
>> Experimental Psychology, MD


From ilgim.hepdarcan at izmirekonomi.edu.tr  Sun Mar 19 21:05:07 2017
From: ilgim.hepdarcan at izmirekonomi.edu.tr (Ilgim Hepdarcan)
Date: Sun, 19 Mar 2017 22:05:07 +0200 (EET)
Subject: [R-sig-ME] How the interpret non-significant Intercept value in
 Fixed Effects Table?
In-Reply-To: <CABghstQZ=BowePv9vGaMWp2p9amjoaE6eOEJk1z4v8pKs+9f1A@mail.gmail.com>
References: <1417728076.13602003.1489951075478.JavaMail.zimbra@izmirekonomi.edu.tr>
	<843054155.13602331.1489951181822.JavaMail.zimbra@izmirekonomi.edu.tr>
	<CABghstQZ=BowePv9vGaMWp2p9amjoaE6eOEJk1z4v8pKs+9f1A@mail.gmail.com>
Message-ID: <1983614681.13604253.1489953907732.JavaMail.zimbra@izmirekonomi.edu.tr>

Sorry for the inconsistency,

I would say repeated measures are nested within participants. Each of the participants completed 4 NbackTypes for 3 times which is my independent variable (random effect). Gender of the participant (fixed effect) is also my other independent variable. My dependent variables are oxygenated hemoglobin from 16 channels.

So, I understand that I can use random slope model.

But, how about the none-significance of Intercept. 

Thank you for your quick answer Mr. Bolker.

Ilg?m 


----- Original Message -----
From: "Ben Bolker" <bbolker at gmail.com>
To: "Ilgim Hepdarcan" <ilgim.hepdarcan at izmirekonomi.edu.tr>
Cc: r-sig-mixed-models at r-project.org
Sent: Sunday, March 19, 2017 10:55:22 PM
Subject: Re: How the interpret non-significant Intercept value in Fixed Effects Table?

On Sun, Mar 19, 2017 at 3:19 PM, Ilgim Hepdarcan
<ilgim.hepdarcan at izmirekonomi.edu.tr> wrote:
>  Dear all,
>>
>> I'm conducting multilevel linear mixed effects model analysis for my MD
>> Thesis, but I've got confused about the models and the results of the
>> models that I've tested.
>>
>> So, my study consists of 3 trials and each trial includes four different
>> n-back types, 0-,1-,2-,3-back. Each participant had 12 n-back
>> conditions, in a different order. Therefore, my design is within-subject
>> design. Participants are between factors and gender of the participant
>> is the covariate of that between factor.
>>
>> While participants were performing n-back task, I have measured their
>> dorsolateral prefrontal cortex activation via 16-channeled fNIR and
>> obtained oxygenated hemoglobin measures from each of the 16 channels and
>> I'm trying to conduct multilevel analysis by using R. My fixed variable
>> is gender and my random variable is Nback Types (which has 4 levels, 0-,
>> 1-, 2-, and 3-back) which is categorical. In my model, participants are
>> nested within Nback types.

These statements seem a little surprising and inconsistent with what I
understand about your
design.  "participants are nested within Nback types" would suggest
that each participant
gets only a single Nback type (and that there are multiple patients
per Nback type),
which seems inconsistent with your statement "each participant had 12
n-back conditions".
(Does each participant get each of the 4 n-back conditions exactly 3
times?  That isn't
necessary but would probably maximize statistical power.) Also, you
say "my random variable
is Nback types", which seems surprising and is inconsistent with the
formulas you give
below (which include Nback type as a fixed effect)

>> Because NbackType is categorical, I've wondered whether it is okay to
>> test random slopes.

 Yes: "random slopes" for categorical predictors equates to
"among-individual variation in effects".

>>
>> #Null model
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m1 = lmer (Optode1 ~ 1 +
>> (1|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m1)
>>
>> ##Nback model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m2 = lmer (Optode1 ~ NbackType +
>> (1|participant:NbackType),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m2)
>> ##Nback model Random slope
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m3 = lmer (Optode1 ~ NbackType +
>> (NbackType|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m3)
>>
>> ##Nback gender model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m4 = lmer (Optode1 ~ NbackType + gender +
>> (1|participant:NbackType),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m4)
>>
>> ##Nback gender model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m5 = lmer (Optode1 ~ NbackType + gender +
>> (NbackType|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m5)
>>
>> ##Nback gender model Random intercept
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m6 = lmer (Optode1 ~ NbackType * gender +
>> (1|participant:NbackType),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m6)
>>
>> ##Nback gender interaction model Random slope
>> #Optode1
>> library(lme4)
>> library(lmerTest)
>> Optode1.m7 = lmer (Optode1 ~ NbackType * gender +
>> (NbackType|participant),
>> na.action = na.exclude,
>> data=oxyHbConditionCellbyCell,
>> REML=FALSE)
>> summary(Optode1.m7)
>>
>>
>> anova(Optode1.m1,Optode1.m2,Optode1.m3,Optode1.m4,Optode1.m5,Optode1.m6,Optode1.m7)
>>
>> Result of the ANOVA
>>
>>>
>>> anova(Optode1.m1,Optode1.m2,Optode1.m3,Optode1.m4,Optode1.m5,Optode1.m6,Optode1.m7)
>> Data: oxyHbConditionCellbyCell
>> Models:
>> object: Optode1 ~ 1 + (1 | participant)
>> ..1: Optode1 ~ NbackType + (1 | participant:NbackType)
>> ..3: Optode1 ~ NbackType + gender + (1 | participant:NbackType)
>> ..5: Optode1 ~ NbackType * gender + (1 | participant:NbackType)
>> ..2: Optode1 ~ NbackType + (NbackType | participant)
>> ..4: Optode1 ~ NbackType + gender + (NbackType | participant)
>> ..6: Optode1 ~ NbackType * gender + (NbackType | participant)
>> Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq)
>> object 3 34885 34910 -17439.6 34879
>> ..1 6 16010 16059 -7999.0 15998 18881.1967 3 < 2e-16 ***
>> ..3 7 16012 16069 -7999.0 15998 0.0471 1 0.82819
>> ..5 10 16011 16093 -7995.6 15991 6.8243 3 0.07771 .
>> ..2 15 16013 16136 -7991.6 15983 8.0654 5 0.15267
>> ..4 16 16015 16146 -7991.4 15983 0.4057 1 0.52416
>> ..6 19 16014 16170 -7988.1 15976 6.4941 3 0.08990 .
>> ---
>> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


You might want to make your null model

 ~ 1 + (1 | participant/NbackType)

and your subsequent (non-random-slope) models should probably use the
same random effect term. This makes participants *crossed* with NbackType (there
is a random effect of participant, potentially a fixed effect of NbackType, and
a random effect of the interaction between NbackType and participant).

  Your anova above suggests that the *combination* of NbackType and variation
of NbackType within participant is significant.

While it's not impossible for the overall anova result to be
significant while the individual
levels aren't, in this case I think the mismatch comes from the
mismatch in the random
effects term between the full and null models.

>>
>> As the ANOVA results indicated the significant model states at the below.
>>
>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite
>> approximations to degrees of freedom [lmerMod]
>> Formula: Optode1 ~ NbackType + (1 | participant:NbackType)
>> Data: oxyHbConditionCellbyCell
>>
>> AIC BIC logLik deviance df.resid
>> 16010.1 16059.2 -7999.0 15998.1 26369
>>
>> Scaled residuals:
>> Min 1Q Median 3Q Max
>> -4.7604 -0.4671 -0.0612 0.4037 7.3160
>>
>> Random effects:
>> Groups Name Variance Std.Dev.
>> participant:NbackType (Intercept) 0.1653 0.4065
>>  Residual 0.1036 0.3219
>> Number of obs: 26375, groups: participant:NbackType, 172
>>
>> Fixed effects:
>> Estimate Std. Error df t value Pr(>|t|)
>> (Intercept) -0.05137 0.06212 172.02000 -0.827 0.409
>> NbackTypeoneback 0.01459 0.08785 172.02000 0.166 0.868
>> NbackTypetwoback 0.01540 0.08785 172.02000 0.175 0.861
>> NbackTypethreeback -0.05264 0.08785 172.02000 -0.599 0.550
>>
>> But, none of them is significant even my Intercept. How should I
>> interpret this result?
>>
>> Your answer is extremely important for me.
>>
>> Thank you in advance.
>>
>> Ilg?m Hepdarcan
>> Experimental Psychology, MD


From sahai.abhimanyu at gmail.com  Mon Mar 20 21:54:01 2017
From: sahai.abhimanyu at gmail.com (Abhimanyu Sahai)
Date: Mon, 20 Mar 2017 21:54:01 +0100
Subject: [R-sig-ME] Appropriate formula for my mixed-effects model
Message-ID: <CAN2pq_yhs4wg57YQOo=VSDxwiHJ+JHerT=vRR+frBnoNQL9Qpw@mail.gmail.com>

Hi,

This question is regarding choice of R formula for my mixed-effects model.
My response variable is a 3-level discrete variable. The independent
variables comprise of both continuous and categorical variables.
Furthermore, one of the categorical variables qualifies as a random effect.
I am modeling it as a generalized linear model. Which formula in R would be
appropriate in this case? I would have used *glmer*, but as far as I could
figure out, there is no appropriate option in '*family' *to model a 3-level
response variable.

Thanks,
Abhimanyu

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Mar 20 22:40:48 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 20 Mar 2017 17:40:48 -0400
Subject: [R-sig-ME] Appropriate formula for my mixed-effects model
In-Reply-To: <CAN2pq_yhs4wg57YQOo=VSDxwiHJ+JHerT=vRR+frBnoNQL9Qpw@mail.gmail.com>
References: <CAN2pq_yhs4wg57YQOo=VSDxwiHJ+JHerT=vRR+frBnoNQL9Qpw@mail.gmail.com>
Message-ID: <556405f8-de8e-d527-185c-04c328f6a7c6@gmail.com>


  Are your three levels ordered or unordered?
  If they are ordered, you can use clmm from the ordinal package.
  If they're unordered, you can use the MCMCglmm package.

  It is also possible (with considerably more work) to construct
multinomial responses by appropriately combining binomial fits (e.g.
taking your three levels and coding two separate responses e.g. ["level
1" vs "not level 1"] and ["level 2" vs "not level 2"] , e.g. see chapter
9.4 of Dobson and Barnett "introduction to Generalized Linear Models".

There may be other options but I can't think of them off the top of my head.

On 17-03-20 04:54 PM, Abhimanyu Sahai wrote:
> Hi,
> 
> This question is regarding choice of R formula for my mixed-effects model.
> My response variable is a 3-level discrete variable. The independent
> variables comprise of both continuous and categorical variables.
> Furthermore, one of the categorical variables qualifies as a random effect.
> I am modeling it as a generalized linear model. Which formula in R would be
> appropriate in this case? I would have used *glmer*, but as far as I could
> figure out, there is no appropriate option in '*family' *to model a 3-level
> response variable.
> 
> Thanks,
> Abhimanyu
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mhyland at u.northwestern.edu  Tue Mar 21 22:08:20 2017
From: mhyland at u.northwestern.edu (Michael Hyland)
Date: Tue, 21 Mar 2017 16:08:20 -0500
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
	Outside-Group Spatial Correlation
Message-ID: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>

Hi,

I'm new to the listserv.

A shortened version of my dataset is below. I am developing a model to
forecast monthly ridership at Bikeshare stations. I want to predict 'Cnts'
as a function of 'Population' - 'Temperature'. The dataset is unbalanced
(unequal number of observations for each station) and most of covariates do
not vary over time, but a few do.

I have successfully used lmer() and lme() in R to capture the dependency
between the error terms for repeated observations from a given station
('id').

model_spatial = lme(log(counts) ~ log(Population)
                 +Drive +Med_Income + Buff2 +Rain + Temperature
                 , data = Data, random = ~1|id, method = "ML" )

model_All = lmer(log(counts) ~ log(Population)
                 +Drive +Med_Income + Buff2 +Rain + Temperature
                 + (1|id)
                  , data = Data )

However, a Moran's I test of the residuals suggests that the residuals are
spatially correlated.
station.dists <- as.matrix(dist(cbind(Data$longitude, Data$latitude)))
station.dists.inv <- 1/station.dists
station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance value is
inf for repeated observations from the same station
Data$resid_all = resid(model_spatial)
Moran.I(Data$resid_all, station.dists.inv)


Hence, I need to develop a model in R that accounts for spatial correlation
across stations, while simultaneously capturing correlations between
observations from a single station.  I've tried the following updates to
the lme() model, but have been unsuccessful.
model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
latitude +longitude ), method = "ML")
model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
latitude +longitude| id ), method = "ML")

Is there a way to formulate the correlation matrix in lme() or lmer() such
that the correlation between repeated obvservations of a given station *and*
the spatial autocorrelation between stations is accounted for?


year month id Cnts latitude longitude Population Drive Med_Income Buff2 Rain
Temperature
2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7


Thanks,
Mike Hyland

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Mar 21 22:12:37 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Mar 2017 17:12:37 -0400
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
 Outside-Group Spatial Correlation
In-Reply-To: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
References: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
Message-ID: <CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>

Your approach seems about right.

- What precisely does "unsuccessful" mean?  warnings, errors,
ridiculous answers?
- Is this your whole data set or a subset?
- centering and scaling predictors is always worth a shot to fix
numeric problems
- INLA is more powerful than lme for fitting spatial correlations,
although it's a *steep* learning curve ...


On Tue, Mar 21, 2017 at 5:08 PM, Michael Hyland
<mhyland at u.northwestern.edu> wrote:
> Hi,
>
> I'm new to the listserv.
>
> A shortened version of my dataset is below. I am developing a model to
> forecast monthly ridership at Bikeshare stations. I want to predict 'Cnts'
> as a function of 'Population' - 'Temperature'. The dataset is unbalanced
> (unequal number of observations for each station) and most of covariates do
> not vary over time, but a few do.
>
> I have successfully used lmer() and lme() in R to capture the dependency
> between the error terms for repeated observations from a given station
> ('id').
>
> model_spatial = lme(log(counts) ~ log(Population)
>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>                  , data = Data, random = ~1|id, method = "ML" )
>
> model_All = lmer(log(counts) ~ log(Population)
>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>                  + (1|id)
>                   , data = Data )
>
> However, a Moran's I test of the residuals suggests that the residuals are
> spatially correlated.
> station.dists <- as.matrix(dist(cbind(Data$longitude, Data$latitude)))
> station.dists.inv <- 1/station.dists
> station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance value is
> inf for repeated observations from the same station
> Data$resid_all = resid(model_spatial)
> Moran.I(Data$resid_all, station.dists.inv)
>
>
> Hence, I need to develop a model in R that accounts for spatial correlation
> across stations, while simultaneously capturing correlations between
> observations from a single station.  I've tried the following updates to
> the lme() model, but have been unsuccessful.
> model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> latitude +longitude ), method = "ML")
> model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> latitude +longitude| id ), method = "ML")
>
> Is there a way to formulate the correlation matrix in lme() or lmer() such
> that the correlation between repeated obvservations of a given station *and*
> the spatial autocorrelation between stations is accounted for?
>
>
> year month id Cnts latitude longitude Population Drive Med_Income Buff2 Rain
> Temperature
> 2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
> 2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
> 2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
> 2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
> 2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
> 2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
> 2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
> 2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
> 2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
> 2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
> 2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
> 2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
> 2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
> 2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
> 2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
> 2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
> 2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
> 2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
> 2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
> 2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
> 2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7
>
>
> Thanks,
> Mike Hyland
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mhyland at u.northwestern.edu  Tue Mar 21 22:19:05 2017
From: mhyland at u.northwestern.edu (Michael Hyland)
Date: Tue, 21 Mar 2017 16:19:05 -0500
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
 Outside-Group Spatial Correlation
In-Reply-To: <CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>
References: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
	<CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>
Message-ID: <CAMhFbwpuCEe1kTuVg=64F4Fwo7JbFwewEF6M8OH8PgGEWiZ+XQ@mail.gmail.com>

Thanks for the quick response.

This is a subset. Full dataset is 12,266 observations across 530 groups (or
Bikeshare stations).

for
model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
latitude +longitude ), method = "ML")
and
model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
latitude +longitude| id ), method = "ML")
the error is "cannot have zero distances in "corSpatial" which I assume is
due to the repeated observations having the same exact lat and lon;
therefore zero distance

Moreover, when I do anything with '| id' I think the model only accounts
for 'within-group' correlations, not across stations


On Tue, Mar 21, 2017 at 4:12 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Your approach seems about right.
>
> - What precisely does "unsuccessful" mean?  warnings, errors,
> ridiculous answers?
> - Is this your whole data set or a subset?
> - centering and scaling predictors is always worth a shot to fix
> numeric problems
> - INLA is more powerful than lme for fitting spatial correlations,
> although it's a *steep* learning curve ...
>
>
> On Tue, Mar 21, 2017 at 5:08 PM, Michael Hyland
> <mhyland at u.northwestern.edu> wrote:
> > Hi,
> >
> > I'm new to the listserv.
> >
> > A shortened version of my dataset is below. I am developing a model to
> > forecast monthly ridership at Bikeshare stations. I want to predict
> 'Cnts'
> > as a function of 'Population' - 'Temperature'. The dataset is unbalanced
> > (unequal number of observations for each station) and most of covariates
> do
> > not vary over time, but a few do.
> >
> > I have successfully used lmer() and lme() in R to capture the dependency
> > between the error terms for repeated observations from a given station
> > ('id').
> >
> > model_spatial = lme(log(counts) ~ log(Population)
> >                  +Drive +Med_Income + Buff2 +Rain + Temperature
> >                  , data = Data, random = ~1|id, method = "ML" )
> >
> > model_All = lmer(log(counts) ~ log(Population)
> >                  +Drive +Med_Income + Buff2 +Rain + Temperature
> >                  + (1|id)
> >                   , data = Data )
> >
> > However, a Moran's I test of the residuals suggests that the residuals
> are
> > spatially correlated.
> > station.dists <- as.matrix(dist(cbind(Data$longitude, Data$latitude)))
> > station.dists.inv <- 1/station.dists
> > station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance
> value is
> > inf for repeated observations from the same station
> > Data$resid_all = resid(model_spatial)
> > Moran.I(Data$resid_all, station.dists.inv)
> >
> >
> > Hence, I need to develop a model in R that accounts for spatial
> correlation
> > across stations, while simultaneously capturing correlations between
> > observations from a single station.  I've tried the following updates to
> > the lme() model, but have been unsuccessful.
> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> > latitude +longitude ), method = "ML")
> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> > latitude +longitude| id ), method = "ML")
> >
> > Is there a way to formulate the correlation matrix in lme() or lmer()
> such
> > that the correlation between repeated obvservations of a given station
> *and*
> > the spatial autocorrelation between stations is accounted for?
> >
> >
> > year month id Cnts latitude longitude Population Drive Med_Income Buff2
> Rain
> > Temperature
> > 2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
> > 2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
> > 2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
> > 2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
> > 2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
> > 2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
> > 2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
> > 2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
> > 2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
> > 2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
> > 2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
> > 2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
> > 2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
> > 2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
> > 2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
> > 2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
> > 2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
> > 2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
> > 2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
> > 2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
> > 2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7
> >
> >
> > Thanks,
> > Mike Hyland
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Mar 22 10:07:11 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 22 Mar 2017 10:07:11 +0100
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
 Outside-Group Spatial Correlation
In-Reply-To: <CAMhFbwpuCEe1kTuVg=64F4Fwo7JbFwewEF6M8OH8PgGEWiZ+XQ@mail.gmail.com>
References: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
	<CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>
	<CAMhFbwpuCEe1kTuVg=64F4Fwo7JbFwewEF6M8OH8PgGEWiZ+XQ@mail.gmail.com>
Message-ID: <CAJuCY5yfe4OFAwQOgC_J2tN106tBX8ME-E_8F9o9tnHQogNCUA@mail.gmail.com>

Dear Michael,

The correlation structures in nlme assume correlation among the
residuals **within** the most detail level of the random effects.
Residuals of observations originating from different levels of the
random effects are assumed to be uncorrelated. So nlme can do what you
would like to do.

As Ben already mentioned, INLA is useful as it allows for spatially
correlated random effects. You can find information on the INLA
website (www.r-inla.org) and in a few books. e.g.
- Blangiardo & Cameletti (2015) Spatial and Spatio-temporal Bayesian
Model with R - INLA
- Zuur et al (in press) Beginner's Guide to Spatial, Temporal and
Spatial-Temporal Ecological Data Analysis with R-INLA: Using GLM and
GLMM

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-21 22:19 GMT+01:00 Michael Hyland <mhyland at u.northwestern.edu>:
> Thanks for the quick response.
>
> This is a subset. Full dataset is 12,266 observations across 530 groups (or
> Bikeshare stations).
>
> for
> model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> latitude +longitude ), method = "ML")
> and
> model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> latitude +longitude| id ), method = "ML")
> the error is "cannot have zero distances in "corSpatial" which I assume is
> due to the repeated observations having the same exact lat and lon;
> therefore zero distance
>
> Moreover, when I do anything with '| id' I think the model only accounts
> for 'within-group' correlations, not across stations
>
>
> On Tue, Mar 21, 2017 at 4:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> Your approach seems about right.
>>
>> - What precisely does "unsuccessful" mean?  warnings, errors,
>> ridiculous answers?
>> - Is this your whole data set or a subset?
>> - centering and scaling predictors is always worth a shot to fix
>> numeric problems
>> - INLA is more powerful than lme for fitting spatial correlations,
>> although it's a *steep* learning curve ...
>>
>>
>> On Tue, Mar 21, 2017 at 5:08 PM, Michael Hyland
>> <mhyland at u.northwestern.edu> wrote:
>> > Hi,
>> >
>> > I'm new to the listserv.
>> >
>> > A shortened version of my dataset is below. I am developing a model to
>> > forecast monthly ridership at Bikeshare stations. I want to predict
>> 'Cnts'
>> > as a function of 'Population' - 'Temperature'. The dataset is unbalanced
>> > (unequal number of observations for each station) and most of covariates
>> do
>> > not vary over time, but a few do.
>> >
>> > I have successfully used lmer() and lme() in R to capture the dependency
>> > between the error terms for repeated observations from a given station
>> > ('id').
>> >
>> > model_spatial = lme(log(counts) ~ log(Population)
>> >                  +Drive +Med_Income + Buff2 +Rain + Temperature
>> >                  , data = Data, random = ~1|id, method = "ML" )
>> >
>> > model_All = lmer(log(counts) ~ log(Population)
>> >                  +Drive +Med_Income + Buff2 +Rain + Temperature
>> >                  + (1|id)
>> >                   , data = Data )
>> >
>> > However, a Moran's I test of the residuals suggests that the residuals
>> are
>> > spatially correlated.
>> > station.dists <- as.matrix(dist(cbind(Data$longitude, Data$latitude)))
>> > station.dists.inv <- 1/station.dists
>> > station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance
>> value is
>> > inf for repeated observations from the same station
>> > Data$resid_all = resid(model_spatial)
>> > Moran.I(Data$resid_all, station.dists.inv)
>> >
>> >
>> > Hence, I need to develop a model in R that accounts for spatial
>> correlation
>> > across stations, while simultaneously capturing correlations between
>> > observations from a single station.  I've tried the following updates to
>> > the lme() model, but have been unsuccessful.
>> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
>> > latitude +longitude ), method = "ML")
>> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
>> > latitude +longitude| id ), method = "ML")
>> >
>> > Is there a way to formulate the correlation matrix in lme() or lmer()
>> such
>> > that the correlation between repeated obvservations of a given station
>> *and*
>> > the spatial autocorrelation between stations is accounted for?
>> >
>> >
>> > year month id Cnts latitude longitude Population Drive Med_Income Buff2
>> Rain
>> > Temperature
>> > 2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
>> > 2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
>> > 2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
>> > 2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
>> > 2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
>> > 2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
>> > 2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
>> > 2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
>> > 2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
>> > 2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
>> > 2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
>> > 2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
>> > 2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
>> > 2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
>> > 2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
>> > 2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
>> > 2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
>> > 2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
>> > 2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
>> > 2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
>> > 2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7
>> >
>> >
>> > Thanks,
>> > Mike Hyland
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dexter.locke at gmail.com  Wed Mar 22 15:46:51 2017
From: dexter.locke at gmail.com (Dexter Locke)
Date: Wed, 22 Mar 2017 10:46:51 -0400
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
 Outside-Group Spatial Correlation
In-Reply-To: <CAJuCY5yfe4OFAwQOgC_J2tN106tBX8ME-E_8F9o9tnHQogNCUA@mail.gmail.com>
References: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
	<CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>
	<CAMhFbwpuCEe1kTuVg=64F4Fwo7JbFwewEF6M8OH8PgGEWiZ+XQ@mail.gmail.com>
	<CAJuCY5yfe4OFAwQOgC_J2tN106tBX8ME-E_8F9o9tnHQogNCUA@mail.gmail.com>
Message-ID: <CAA=SVwEOoFkcY+uHeCYgnHFnDZwpjoQF85Hf6r+TiFgXnpFRaw@mail.gmail.com>

Dear list,

You may consider also the citations below and HSAR package:
https://cran.r-project.org/web/packages/HSAR/vignettes/hsar.html

Dear Michael,

Do you have comparable code for extracting the residuals of the model and
testing for spatial autocorrelation that works with your second model
"model_All" created with lme4::lmer ?  What package contains the "Moran.I"
function?

- Dexter

Dong, G., & Harris, R. (2014). Spatial Autoregressive Models for
Geographically Hierarchical Data Structures. *Geographical Analysis*,
n/a-n/a. http://doi.org/10.1111/gean.12049

Dong, G., Harris, R., Jones, K., & Yu, J. (2015). Multilevel Modelling with
Spatial Interaction Effects with Application to an Emerging Land Market in
Beijing, China. *PloS One*, *10*(6), e0130761.
http://doi.org/10.1371/journal.pone.0130761

Dong, G., Ma, J., Harris, R., & Pryce, G. (2016). Spatial Random Slope
Multilevel Modeling Using Multivariate Conditional Autoregressive Models: A
Case Study of Subjective Travel Satisfaction in Beijing. *Annals of the
American Association of Geographers*, *106*(1), 19?35.
http://doi.org/10.1080/00045608.2015.1094388

On Wed, Mar 22, 2017 at 5:07 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Michael,
>
> The correlation structures in nlme assume correlation among the
> residuals **within** the most detail level of the random effects.
> Residuals of observations originating from different levels of the
> random effects are assumed to be uncorrelated. So nlme can do what you
> would like to do.
>
> As Ben already mentioned, INLA is useful as it allows for spatially
> correlated random effects. You can find information on the INLA
> website (www.r-inla.org) and in a few books. e.g.
> - Blangiardo & Cameletti (2015) Spatial and Spatio-temporal Bayesian
> Model with R - INLA
> - Zuur et al (in press) Beginner's Guide to Spatial, Temporal and
> Spatial-Temporal Ecological Data Analysis with R-INLA: Using GLM and
> GLMM
>
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2017-03-21 22:19 GMT+01:00 Michael Hyland <mhyland at u.northwestern.edu>:
> > Thanks for the quick response.
> >
> > This is a subset. Full dataset is 12,266 observations across 530 groups
> (or
> > Bikeshare stations).
> >
> > for
> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> > latitude +longitude ), method = "ML")
> > and
> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
> > latitude +longitude| id ), method = "ML")
> > the error is "cannot have zero distances in "corSpatial" which I assume
> is
> > due to the repeated observations having the same exact lat and lon;
> > therefore zero distance
> >
> > Moreover, when I do anything with '| id' I think the model only accounts
> > for 'within-group' correlations, not across stations
> >
> >
> > On Tue, Mar 21, 2017 at 4:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >
> >> Your approach seems about right.
> >>
> >> - What precisely does "unsuccessful" mean?  warnings, errors,
> >> ridiculous answers?
> >> - Is this your whole data set or a subset?
> >> - centering and scaling predictors is always worth a shot to fix
> >> numeric problems
> >> - INLA is more powerful than lme for fitting spatial correlations,
> >> although it's a *steep* learning curve ...
> >>
> >>
> >> On Tue, Mar 21, 2017 at 5:08 PM, Michael Hyland
> >> <mhyland at u.northwestern.edu> wrote:
> >> > Hi,
> >> >
> >> > I'm new to the listserv.
> >> >
> >> > A shortened version of my dataset is below. I am developing a model to
> >> > forecast monthly ridership at Bikeshare stations. I want to predict
> >> 'Cnts'
> >> > as a function of 'Population' - 'Temperature'. The dataset is
> unbalanced
> >> > (unequal number of observations for each station) and most of
> covariates
> >> do
> >> > not vary over time, but a few do.
> >> >
> >> > I have successfully used lmer() and lme() in R to capture the
> dependency
> >> > between the error terms for repeated observations from a given station
> >> > ('id').
> >> >
> >> > model_spatial = lme(log(counts) ~ log(Population)
> >> >                  +Drive +Med_Income + Buff2 +Rain + Temperature
> >> >                  , data = Data, random = ~1|id, method = "ML" )
> >> >
> >> > model_All = lmer(log(counts) ~ log(Population)
> >> >                  +Drive +Med_Income + Buff2 +Rain + Temperature
> >> >                  + (1|id)
> >> >                   , data = Data )
> >> >
> >> > However, a Moran's I test of the residuals suggests that the residuals
> >> are
> >> > spatially correlated.
> >> > station.dists <- as.matrix(dist(cbind(Data$longitude,
> Data$latitude)))
> >> > station.dists.inv <- 1/station.dists
> >> > station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance
> >> value is
> >> > inf for repeated observations from the same station
> >> > Data$resid_all = resid(model_spatial)
> >> > Moran.I(Data$resid_all, station.dists.inv)
> >> >
> >> >
> >> > Hence, I need to develop a model in R that accounts for spatial
> >> correlation
> >> > across stations, while simultaneously capturing correlations between
> >> > observations from a single station.  I've tried the following updates
> to
> >> > the lme() model, but have been unsuccessful.
> >> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form
> = ~
> >> > latitude +longitude ), method = "ML")
> >> > model_spatial.gau <- update(model_spatial, correlation = corGaus(form
> = ~
> >> > latitude +longitude| id ), method = "ML")
> >> >
> >> > Is there a way to formulate the correlation matrix in lme() or lmer()
> >> such
> >> > that the correlation between repeated obvservations of a given station
> >> *and*
> >> > the spatial autocorrelation between stations is accounted for?
> >> >
> >> >
> >> > year month id Cnts latitude longitude Population Drive Med_Income
> Buff2
> >> Rain
> >> > Temperature
> >> > 2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
> >> > 2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
> >> > 2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
> >> > 2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
> >> > 2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
> >> > 2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
> >> > 2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
> >> > 2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
> >> > 2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
> >> > 2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
> >> > 2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
> >> > 2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
> >> > 2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
> >> > 2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
> >> > 2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
> >> > 2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
> >> > 2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
> >> > 2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
> >> > 2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
> >> > 2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
> >> > 2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7
> >> >
> >> >
> >> > Thanks,
> >> > Mike Hyland
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Mar 22 17:02:58 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Mar 2017 12:02:58 -0400
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
 Outside-Group Spatial Correlation
In-Reply-To: <CAA=SVwEOoFkcY+uHeCYgnHFnDZwpjoQF85Hf6r+TiFgXnpFRaw@mail.gmail.com>
References: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
	<CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>
	<CAMhFbwpuCEe1kTuVg=64F4Fwo7JbFwewEF6M8OH8PgGEWiZ+XQ@mail.gmail.com>
	<CAJuCY5yfe4OFAwQOgC_J2tN106tBX8ME-E_8F9o9tnHQogNCUA@mail.gmail.com>
	<CAA=SVwEOoFkcY+uHeCYgnHFnDZwpjoQF85Hf6r+TiFgXnpFRaw@mail.gmail.com>
Message-ID: <c457bb4e-f431-9fe9-322e-a7cd4f093bf5@gmail.com>


  The spaMM package is also worth a try.

  A hack suggested a while ago by Dormann et al. is to make a single
group that includes all observations, but (1) it's pretty inefficient
and (2) I don't think you can have that *and* another, non-trivial
grouping factor.

On 17-03-22 10:46 AM, Dexter Locke wrote:
> Dear list,
> 
> You may consider also the citations below and HSAR package:
> https://cran.r-project.org/web/packages/HSAR/vignettes/hsar.html
> 
> Dear Michael,
> 
> Do you have comparable code for extracting the residuals of the model and
> testing for spatial autocorrelation that works with your second model
> "model_All" created with lme4::lmer ?  What package contains the "Moran.I"
> function?
> 
> - Dexter
> 
> Dong, G., & Harris, R. (2014). Spatial Autoregressive Models for
> Geographically Hierarchical Data Structures. *Geographical Analysis*,
> n/a-n/a. http://doi.org/10.1111/gean.12049
> 
> Dong, G., Harris, R., Jones, K., & Yu, J. (2015). Multilevel Modelling with
> Spatial Interaction Effects with Application to an Emerging Land Market in
> Beijing, China. *PloS One*, *10*(6), e0130761.
> http://doi.org/10.1371/journal.pone.0130761
> 
> Dong, G., Ma, J., Harris, R., & Pryce, G. (2016). Spatial Random Slope
> Multilevel Modeling Using Multivariate Conditional Autoregressive Models: A
> Case Study of Subjective Travel Satisfaction in Beijing. *Annals of the
> American Association of Geographers*, *106*(1), 19?35.
> http://doi.org/10.1080/00045608.2015.1094388
> 
> On Wed, Mar 22, 2017 at 5:07 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
> 
>> Dear Michael,
>>
>> The correlation structures in nlme assume correlation among the
>> residuals **within** the most detail level of the random effects.
>> Residuals of observations originating from different levels of the
>> random effects are assumed to be uncorrelated. So nlme can do what you
>> would like to do.
>>
>> As Ben already mentioned, INLA is useful as it allows for spatially
>> correlated random effects. You can find information on the INLA
>> website (www.r-inla.org) and in a few books. e.g.
>> - Blangiardo & Cameletti (2015) Spatial and Spatio-temporal Bayesian
>> Model with R - INLA
>> - Zuur et al (in press) Beginner's Guide to Spatial, Temporal and
>> Spatial-Temporal Ecological Data Analysis with R-INLA: Using GLM and
>> GLMM
>>
>> Best regards,
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2017-03-21 22:19 GMT+01:00 Michael Hyland <mhyland at u.northwestern.edu>:
>>> Thanks for the quick response.
>>>
>>> This is a subset. Full dataset is 12,266 observations across 530 groups
>> (or
>>> Bikeshare stations).
>>>
>>> for
>>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
>>> latitude +longitude ), method = "ML")
>>> and
>>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form = ~
>>> latitude +longitude| id ), method = "ML")
>>> the error is "cannot have zero distances in "corSpatial" which I assume
>> is
>>> due to the repeated observations having the same exact lat and lon;
>>> therefore zero distance
>>>
>>> Moreover, when I do anything with '| id' I think the model only accounts
>>> for 'within-group' correlations, not across stations
>>>
>>>
>>> On Tue, Mar 21, 2017 at 4:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>> Your approach seems about right.
>>>>
>>>> - What precisely does "unsuccessful" mean?  warnings, errors,
>>>> ridiculous answers?
>>>> - Is this your whole data set or a subset?
>>>> - centering and scaling predictors is always worth a shot to fix
>>>> numeric problems
>>>> - INLA is more powerful than lme for fitting spatial correlations,
>>>> although it's a *steep* learning curve ...
>>>>
>>>>
>>>> On Tue, Mar 21, 2017 at 5:08 PM, Michael Hyland
>>>> <mhyland at u.northwestern.edu> wrote:
>>>>> Hi,
>>>>>
>>>>> I'm new to the listserv.
>>>>>
>>>>> A shortened version of my dataset is below. I am developing a model to
>>>>> forecast monthly ridership at Bikeshare stations. I want to predict
>>>> 'Cnts'
>>>>> as a function of 'Population' - 'Temperature'. The dataset is
>> unbalanced
>>>>> (unequal number of observations for each station) and most of
>> covariates
>>>> do
>>>>> not vary over time, but a few do.
>>>>>
>>>>> I have successfully used lmer() and lme() in R to capture the
>> dependency
>>>>> between the error terms for repeated observations from a given station
>>>>> ('id').
>>>>>
>>>>> model_spatial = lme(log(counts) ~ log(Population)
>>>>>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>>>>>                  , data = Data, random = ~1|id, method = "ML" )
>>>>>
>>>>> model_All = lmer(log(counts) ~ log(Population)
>>>>>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>>>>>                  + (1|id)
>>>>>                   , data = Data )
>>>>>
>>>>> However, a Moran's I test of the residuals suggests that the residuals
>>>> are
>>>>> spatially correlated.
>>>>> station.dists <- as.matrix(dist(cbind(Data$longitude,
>> Data$latitude)))
>>>>> station.dists.inv <- 1/station.dists
>>>>> station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance
>>>> value is
>>>>> inf for repeated observations from the same station
>>>>> Data$resid_all = resid(model_spatial)
>>>>> Moran.I(Data$resid_all, station.dists.inv)
>>>>>
>>>>>
>>>>> Hence, I need to develop a model in R that accounts for spatial
>>>> correlation
>>>>> across stations, while simultaneously capturing correlations between
>>>>> observations from a single station.  I've tried the following updates
>> to
>>>>> the lme() model, but have been unsuccessful.
>>>>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
>> = ~
>>>>> latitude +longitude ), method = "ML")
>>>>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
>> = ~
>>>>> latitude +longitude| id ), method = "ML")
>>>>>
>>>>> Is there a way to formulate the correlation matrix in lme() or lmer()
>>>> such
>>>>> that the correlation between repeated obvservations of a given station
>>>> *and*
>>>>> the spatial autocorrelation between stations is accounted for?
>>>>>
>>>>>
>>>>> year month id Cnts latitude longitude Population Drive Med_Income
>> Buff2
>>>> Rain
>>>>> Temperature
>>>>> 2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
>>>>> 2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
>>>>> 2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
>>>>> 2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
>>>>> 2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
>>>>> 2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
>>>>> 2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
>>>>> 2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
>>>>> 2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
>>>>> 2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
>>>>> 2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
>>>>> 2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
>>>>> 2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
>>>>> 2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
>>>>> 2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
>>>>> 2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
>>>>> 2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
>>>>> 2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
>>>>> 2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
>>>>> 2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
>>>>> 2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7
>>>>>
>>>>>
>>>>> Thanks,
>>>>> Mike Hyland
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mhyland at u.northwestern.edu  Wed Mar 22 17:51:09 2017
From: mhyland at u.northwestern.edu (Michael Hyland)
Date: Wed, 22 Mar 2017 11:51:09 -0500
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
 Outside-Group Spatial Correlation
In-Reply-To: <c457bb4e-f431-9fe9-322e-a7cd4f093bf5@gmail.com>
References: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
	<CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>
	<CAMhFbwpuCEe1kTuVg=64F4Fwo7JbFwewEF6M8OH8PgGEWiZ+XQ@mail.gmail.com>
	<CAJuCY5yfe4OFAwQOgC_J2tN106tBX8ME-E_8F9o9tnHQogNCUA@mail.gmail.com>
	<CAA=SVwEOoFkcY+uHeCYgnHFnDZwpjoQF85Hf6r+TiFgXnpFRaw@mail.gmail.com>
	<c457bb4e-f431-9fe9-322e-a7cd4f093bf5@gmail.com>
Message-ID: <CAMhFbwo_ruFdG6FE=F63A=d2B1U_GJD15RRZavxh6pdHu620yQ@mail.gmail.com>

Thanks for the responses everyone.

David and Ben - I am in the midst of trying the hack right now. I created a
single 'group' with all observations. Then I constructed the correlation
distance matrix using three variables latitude, longitude, and *time*. This
way I can capture the correlations from repeated observations (they have
the same latitude and longitude) as a function of their temporal distance
(time) and the correlations across stations as a function of their spatial
and temporal distance. I think this structure is actually better and more
flexible. I am still trying to figure out how to determine the tradeoff
between spatial distance and temporal distance that I want. Also, as Ben
suggested this method appears to be quite inefficient. The model has been
running for 11 hours and is using around 12gb of RAM. I think I might
create groups by clustering the stations geographically to reduce the
computational burden of what is now 12,271x12,271 correlation matrix.

Dexter -  lm::lm(), nlme::lme(), and lme4::lmer() all have the function
resid(model) that provides the residual for each observation in the model.
I used the package "ape" to calculate the Moran I.

model_spatial = lme(log(counts) ~ log(Population)
                 +Drive +Med_Income + Buff2 +Rain + Temperature
                 , data = Data, random = ~1|id, method = "ML" )

model_All = lmer(log(counts) ~ log(Population)
                 +Drive +Med_Income + Buff2 +Rain + Temperature
                 + (1|id)
                  , data = Data )
Data$resid_spat = resid(model_spatial )
Data$resid_all = resid(model_All )

Thierry - I assume you meant "nlme *cant *do what you would like to do"?

I will check out the INLA, spaMM, and HSAR packages if the nlme workaround
does not actually work.



On Wed, Mar 22, 2017 at 11:02 AM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   The spaMM package is also worth a try.
>
>   A hack suggested a while ago by Dormann et al. is to make a single
> group that includes all observations, but (1) it's pretty inefficient
> and (2) I don't think you can have that *and* another, non-trivial
> grouping factor.
>
> On 17-03-22 10:46 AM, Dexter Locke wrote:
> > Dear list,
> >
> > You may consider also the citations below and HSAR package:
> > https://cran.r-project.org/web/packages/HSAR/vignettes/hsar.html
> >
> > Dear Michael,
> >
> > Do you have comparable code for extracting the residuals of the model and
> > testing for spatial autocorrelation that works with your second model
> > "model_All" created with lme4::lmer ?  What package contains the
> "Moran.I"
> > function?
> >
> > - Dexter
> >
> > Dong, G., & Harris, R. (2014). Spatial Autoregressive Models for
> > Geographically Hierarchical Data Structures. *Geographical Analysis*,
> > n/a-n/a. http://doi.org/10.1111/gean.12049
> >
> > Dong, G., Harris, R., Jones, K., & Yu, J. (2015). Multilevel Modelling
> with
> > Spatial Interaction Effects with Application to an Emerging Land Market
> in
> > Beijing, China. *PloS One*, *10*(6), e0130761.
> > http://doi.org/10.1371/journal.pone.0130761
> >
> > Dong, G., Ma, J., Harris, R., & Pryce, G. (2016). Spatial Random Slope
> > Multilevel Modeling Using Multivariate Conditional Autoregressive
> Models: A
> > Case Study of Subjective Travel Satisfaction in Beijing. *Annals of the
> > American Association of Geographers*, *106*(1), 19?35.
> > http://doi.org/10.1080/00045608.2015.1094388
> >
> > On Wed, Mar 22, 2017 at 5:07 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
> > wrote:
> >
> >> Dear Michael,
> >>
> >> The correlation structures in nlme assume correlation among the
> >> residuals **within** the most detail level of the random effects.
> >> Residuals of observations originating from different levels of the
> >> random effects are assumed to be uncorrelated. So nlme can do what you
> >> would like to do.
> >>
> >> As Ben already mentioned, INLA is useful as it allows for spatially
> >> correlated random effects. You can find information on the INLA
> >> website (www.r-inla.org) and in a few books. e.g.
> >> - Blangiardo & Cameletti (2015) Spatial and Spatio-temporal Bayesian
> >> Model with R - INLA
> >> - Zuur et al (in press) Beginner's Guide to Spatial, Temporal and
> >> Spatial-Temporal Ecological Data Analysis with R-INLA: Using GLM and
> >> GLMM
> >>
> >> Best regards,
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> >> and Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no
> >> more than asking him to perform a post-mortem examination: he may be
> >> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does
> >> not ensure that a reasonable answer can be extracted from a given body
> >> of data. ~ John Tukey
> >>
> >>
> >> 2017-03-21 22:19 GMT+01:00 Michael Hyland <mhyland at u.northwestern.edu>:
> >>> Thanks for the quick response.
> >>>
> >>> This is a subset. Full dataset is 12,266 observations across 530 groups
> >> (or
> >>> Bikeshare stations).
> >>>
> >>> for
> >>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
> = ~
> >>> latitude +longitude ), method = "ML")
> >>> and
> >>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
> = ~
> >>> latitude +longitude| id ), method = "ML")
> >>> the error is "cannot have zero distances in "corSpatial" which I assume
> >> is
> >>> due to the repeated observations having the same exact lat and lon;
> >>> therefore zero distance
> >>>
> >>> Moreover, when I do anything with '| id' I think the model only
> accounts
> >>> for 'within-group' correlations, not across stations
> >>>
> >>>
> >>> On Tue, Mar 21, 2017 at 4:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>>
> >>>> Your approach seems about right.
> >>>>
> >>>> - What precisely does "unsuccessful" mean?  warnings, errors,
> >>>> ridiculous answers?
> >>>> - Is this your whole data set or a subset?
> >>>> - centering and scaling predictors is always worth a shot to fix
> >>>> numeric problems
> >>>> - INLA is more powerful than lme for fitting spatial correlations,
> >>>> although it's a *steep* learning curve ...
> >>>>
> >>>>
> >>>> On Tue, Mar 21, 2017 at 5:08 PM, Michael Hyland
> >>>> <mhyland at u.northwestern.edu> wrote:
> >>>>> Hi,
> >>>>>
> >>>>> I'm new to the listserv.
> >>>>>
> >>>>> A shortened version of my dataset is below. I am developing a model
> to
> >>>>> forecast monthly ridership at Bikeshare stations. I want to predict
> >>>> 'Cnts'
> >>>>> as a function of 'Population' - 'Temperature'. The dataset is
> >> unbalanced
> >>>>> (unequal number of observations for each station) and most of
> >> covariates
> >>>> do
> >>>>> not vary over time, but a few do.
> >>>>>
> >>>>> I have successfully used lmer() and lme() in R to capture the
> >> dependency
> >>>>> between the error terms for repeated observations from a given
> station
> >>>>> ('id').
> >>>>>
> >>>>> model_spatial = lme(log(counts) ~ log(Population)
> >>>>>                  +Drive +Med_Income + Buff2 +Rain + Temperature
> >>>>>                  , data = Data, random = ~1|id, method = "ML" )
> >>>>>
> >>>>> model_All = lmer(log(counts) ~ log(Population)
> >>>>>                  +Drive +Med_Income + Buff2 +Rain + Temperature
> >>>>>                  + (1|id)
> >>>>>                   , data = Data )
> >>>>>
> >>>>> However, a Moran's I test of the residuals suggests that the
> residuals
> >>>> are
> >>>>> spatially correlated.
> >>>>> station.dists <- as.matrix(dist(cbind(Data$longitude,
> >> Data$latitude)))
> >>>>> station.dists.inv <- 1/station.dists
> >>>>> station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance
> >>>> value is
> >>>>> inf for repeated observations from the same station
> >>>>> Data$resid_all = resid(model_spatial)
> >>>>> Moran.I(Data$resid_all, station.dists.inv)
> >>>>>
> >>>>>
> >>>>> Hence, I need to develop a model in R that accounts for spatial
> >>>> correlation
> >>>>> across stations, while simultaneously capturing correlations between
> >>>>> observations from a single station.  I've tried the following updates
> >> to
> >>>>> the lme() model, but have been unsuccessful.
> >>>>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
> >> = ~
> >>>>> latitude +longitude ), method = "ML")
> >>>>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
> >> = ~
> >>>>> latitude +longitude| id ), method = "ML")
> >>>>>
> >>>>> Is there a way to formulate the correlation matrix in lme() or lmer()
> >>>> such
> >>>>> that the correlation between repeated obvservations of a given
> station
> >>>> *and*
> >>>>> the spatial autocorrelation between stations is accounted for?
> >>>>>
> >>>>>
> >>>>> year month id Cnts latitude longitude Population Drive Med_Income
> >> Buff2
> >>>> Rain
> >>>>> Temperature
> >>>>> 2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
> >>>>> 2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
> >>>>> 2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
> >>>>> 2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
> >>>>> 2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
> >>>>> 2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
> >>>>> 2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
> >>>>> 2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
> >>>>> 2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
> >>>>> 2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
> >>>>> 2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
> >>>>> 2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
> >>>>> 2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
> >>>>> 2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
> >>>>> 2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
> >>>>> 2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
> >>>>> 2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
> >>>>> 2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
> >>>>> 2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
> >>>>> 2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
> >>>>> 2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7
> >>>>>
> >>>>>
> >>>>> Thanks,
> >>>>> Mike Hyland
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mmonasterolo at agro.uba.ar  Wed Mar 22 22:44:34 2017
From: mmonasterolo at agro.uba.ar (Marcos Monasterolo)
Date: Wed, 22 Mar 2017 18:44:34 -0300
Subject: [R-sig-ME] GLMM - R squared
Message-ID: <CAJ-MGDRd4M49uoLh0NnNBsV4DeBzwM7ONidW-fEFC_8e7gicnQ@mail.gmail.com>

Dear all. I am working with a GLMM in the lme4 package using 4 fixed
factors and 1 random factor (plot). An unexpected result comes up when I
calculate the model's conditional and marginal R-squared using the
r.squaredGLMM funtion in the MuMIn package. Both values are the same. Does
this mean the random term does not add any explanatory power to the model
(and could thus be dropped)? I provide a working code below. Thanks in
advance for your help.
Marcos

id <- "0Bzd8I1jr8z_iRm1aRWhqdHJHcmc" # google file ID
comuni <- read.table(sprintf("https://docs.google.com/uc?id=%s&
export=download", id), head=T, sep="")
comuni1<-comuni[-c(3,6,7,8),] #these data points I don't need
library(lme4)
MM1A <- glmer(riquplanta ~width+lot+exph200+db500+(1|plot), data = comuni1,
family=poisson, control=glmerControl(optimizer="bobyqa",
optCtrl=list(maxfun=2e5)))
summary(MM1A)
library(MuMIn)
r.squaredGLMM(MM1A) #what's going on here?


----
Bi?l. Marcos Monasterolo
Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a, UBA

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Mar 22 23:19:56 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Mar 2017 18:19:56 -0400
Subject: [R-sig-ME] GLMM - R squared
In-Reply-To: <CAJ-MGDRd4M49uoLh0NnNBsV4DeBzwM7ONidW-fEFC_8e7gicnQ@mail.gmail.com>
References: <CAJ-MGDRd4M49uoLh0NnNBsV4DeBzwM7ONidW-fEFC_8e7gicnQ@mail.gmail.com>
Message-ID: <CABghstQEs+kwHWHFw+aZyz45g0Pf540JKErHhYX7cw=CEKS9aw@mail.gmail.com>

You have the same number of random effects grouping levels (plots, 16)
as total observations (16).  The way that the conditional and marginal
R-squareds differ is by adding an observation-level random effect to
the model; since you already have an observation-level random effect
in your model, adding another observation-level random effect doesn't
make a difference.

While we're at it, I would be *very* careful fitting a model with 4-6
parameters (depending on whether you count the intercept and/or the
random effects variance) to a data set with 16 points; a general rule
of thumb (Harrell, *Regression Modeling Strategies*) is that you need
*at least* 10-20 data points per parameter ...

Possibly of interest:


library(dplyr)
ss <- arm::rescale ## avoid Error: Unsupported type CLOSXP for column "width"
comuni1sc <- comuni1 %>%
  mutate_each(funs(ss),-c(riquplanta,plot,lot))
MM1B <- update(MM1A,data=comuni1sc)
library(ggplot2)
dotwhisker::dwplot(MM1B)+geom_vline(xintercept=0,lty=2)



On Wed, Mar 22, 2017 at 5:44 PM, Marcos Monasterolo
<mmonasterolo at agro.uba.ar> wrote:
> Dear all. I am working with a GLMM in the lme4 package using 4 fixed
> factors and 1 random factor (plot). An unexpected result comes up when I
> calculate the model's conditional and marginal R-squared using the
> r.squaredGLMM funtion in the MuMIn package. Both values are the same. Does
> this mean the random term does not add any explanatory power to the model
> (and could thus be dropped)? I provide a working code below. Thanks in
> advance for your help.
> Marcos
>
> id <- "0Bzd8I1jr8z_iRm1aRWhqdHJHcmc" # google file ID
> comuni <- read.table(sprintf("https://docs.google.com/uc?id=%s&
> export=download", id), head=T, sep="")
> comuni1<-comuni[-c(3,6,7,8),] #these data points I don't need
> library(lme4)
> MM1A <- glmer(riquplanta ~width+lot+exph200+db500+(1|plot), data = comuni1,
> family=poisson, control=glmerControl(optimizer="bobyqa",
> optCtrl=list(maxfun=2e5)))
> summary(MM1A)
> library(MuMIn)
> r.squaredGLMM(MM1A) #what's going on here?
>
>
> ----
> Bi?l. Marcos Monasterolo
> Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a, UBA
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Mar 22 23:55:26 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Mar 2017 18:55:26 -0400
Subject: [R-sig-ME] Repeated Observations Linear Mixed Model with
 Outside-Group Spatial Correlation
In-Reply-To: <CAMhFbwo_ruFdG6FE=F63A=d2B1U_GJD15RRZavxh6pdHu620yQ@mail.gmail.com>
References: <CAMhFbwp2L0WB+F6jPy2cg9zYoYfpdtX+Ozw6G_Vb0SvRgOU-Fw@mail.gmail.com>
	<CABghstQbHy+g8O-WBSKZeAD9ZXs0pqbTvLDNOzRNTiBsyFj2xA@mail.gmail.com>
	<CAMhFbwpuCEe1kTuVg=64F4Fwo7JbFwewEF6M8OH8PgGEWiZ+XQ@mail.gmail.com>
	<CAJuCY5yfe4OFAwQOgC_J2tN106tBX8ME-E_8F9o9tnHQogNCUA@mail.gmail.com>
	<CAA=SVwEOoFkcY+uHeCYgnHFnDZwpjoQF85Hf6r+TiFgXnpFRaw@mail.gmail.com>
	<c457bb4e-f431-9fe9-322e-a7cd4f093bf5@gmail.com>
	<CAMhFbwo_ruFdG6FE=F63A=d2B1U_GJD15RRZavxh6pdHu620yQ@mail.gmail.com>
Message-ID: <CABghstSaZvusJR4xJennit_LuU=NDTZnUzw==RGh07KThC51_w@mail.gmail.com>

Last comment:  for a large data set, INLA or something that handles
the pairwise interactions in a smart way (e.g. SAR/CAR models from
geography) are probably going to be necessary.  In contrast,
approaches that rely on repeated, brute-force Cholesky decompositions
of large matrices (e.g., nlme) are probably going to crap out.

Another approach is to use an additive model to fit the relatively
high-frequency (but still smooth) spatial variation, i.e. see
mgcv/gamm4 packages (and Simon Wood's 2006 book).



On Wed, Mar 22, 2017 at 12:51 PM, Michael Hyland
<mhyland at u.northwestern.edu> wrote:
> Thanks for the responses everyone.
>
> David and Ben - I am in the midst of trying the hack right now. I created a
> single 'group' with all observations. Then I constructed the correlation
> distance matrix using three variables latitude, longitude, and time. This
> way I can capture the correlations from repeated observations (they have the
> same latitude and longitude) as a function of their temporal distance (time)
> and the correlations across stations as a function of their spatial and
> temporal distance. I think this structure is actually better and more
> flexible. I am still trying to figure out how to determine the tradeoff
> between spatial distance and temporal distance that I want. Also, as Ben
> suggested this method appears to be quite inefficient. The model has been
> running for 11 hours and is using around 12gb of RAM. I think I might create
> groups by clustering the stations geographically to reduce the computational
> burden of what is now 12,271x12,271 correlation matrix.
>
> Dexter -  lm::lm(), nlme::lme(), and lme4::lmer() all have the function
> resid(model) that provides the residual for each observation in the model. I
> used the package "ape" to calculate the Moran I.
>
> model_spatial = lme(log(counts) ~ log(Population)
>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>                  , data = Data, random = ~1|id, method = "ML" )
>
> model_All = lmer(log(counts) ~ log(Population)
>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>                  + (1|id)
>                   , data = Data )
> Data$resid_spat = resid(model_spatial )
> Data$resid_all = resid(model_All )
>
> Thierry - I assume you meant "nlme cant do what you would like to do"?
>
> I will check out the INLA, spaMM, and HSAR packages if the nlme workaround
> does not actually work.
>
>
>
> On Wed, Mar 22, 2017 at 11:02 AM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>   The spaMM package is also worth a try.
>>
>>   A hack suggested a while ago by Dormann et al. is to make a single
>> group that includes all observations, but (1) it's pretty inefficient
>> and (2) I don't think you can have that *and* another, non-trivial
>> grouping factor.
>>
>> On 17-03-22 10:46 AM, Dexter Locke wrote:
>> > Dear list,
>> >
>> > You may consider also the citations below and HSAR package:
>> > https://cran.r-project.org/web/packages/HSAR/vignettes/hsar.html
>> >
>> > Dear Michael,
>> >
>> > Do you have comparable code for extracting the residuals of the model
>> > and
>> > testing for spatial autocorrelation that works with your second model
>> > "model_All" created with lme4::lmer ?  What package contains the
>> > "Moran.I"
>> > function?
>> >
>> > - Dexter
>> >
>> > Dong, G., & Harris, R. (2014). Spatial Autoregressive Models for
>> > Geographically Hierarchical Data Structures. *Geographical Analysis*,
>> > n/a-n/a. http://doi.org/10.1111/gean.12049
>> >
>> > Dong, G., Harris, R., Jones, K., & Yu, J. (2015). Multilevel Modelling
>> > with
>> > Spatial Interaction Effects with Application to an Emerging Land Market
>> > in
>> > Beijing, China. *PloS One*, *10*(6), e0130761.
>> > http://doi.org/10.1371/journal.pone.0130761
>> >
>> > Dong, G., Ma, J., Harris, R., & Pryce, G. (2016). Spatial Random Slope
>> > Multilevel Modeling Using Multivariate Conditional Autoregressive
>> > Models: A
>> > Case Study of Subjective Travel Satisfaction in Beijing. *Annals of the
>> > American Association of Geographers*, *106*(1), 19?35.
>> > http://doi.org/10.1080/00045608.2015.1094388
>> >
>> > On Wed, Mar 22, 2017 at 5:07 AM, Thierry Onkelinx
>> > <thierry.onkelinx at inbo.be>
>> > wrote:
>> >
>> >> Dear Michael,
>> >>
>> >> The correlation structures in nlme assume correlation among the
>> >> residuals **within** the most detail level of the random effects.
>> >> Residuals of observations originating from different levels of the
>> >> random effects are assumed to be uncorrelated. So nlme can do what you
>> >> would like to do.
>> >>
>> >> As Ben already mentioned, INLA is useful as it allows for spatially
>> >> correlated random effects. You can find information on the INLA
>> >> website (www.r-inla.org) and in a few books. e.g.
>> >> - Blangiardo & Cameletti (2015) Spatial and Spatio-temporal Bayesian
>> >> Model with R - INLA
>> >> - Zuur et al (in press) Beginner's Guide to Spatial, Temporal and
>> >> Spatial-Temporal Ecological Data Analysis with R-INLA: Using GLM and
>> >> GLMM
>> >>
>> >> Best regards,
>> >> ir. Thierry Onkelinx
>> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> >> and Forest
>> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> >> Kliniekstraat 25
>> >> 1070 Anderlecht
>> >> Belgium
>> >>
>> >> To call in the statistician after the experiment is done may be no
>> >> more than asking him to perform a post-mortem examination: he may be
>> >> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> The combination of some data and an aching desire for an answer does
>> >> not ensure that a reasonable answer can be extracted from a given body
>> >> of data. ~ John Tukey
>> >>
>> >>
>> >> 2017-03-21 22:19 GMT+01:00 Michael Hyland <mhyland at u.northwestern.edu>:
>> >>> Thanks for the quick response.
>> >>>
>> >>> This is a subset. Full dataset is 12,266 observations across 530
>> >>> groups
>> >> (or
>> >>> Bikeshare stations).
>> >>>
>> >>> for
>> >>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
>> >>> = ~
>> >>> latitude +longitude ), method = "ML")
>> >>> and
>> >>> model_spatial.gau <- update(model_spatial, correlation = corGaus(form
>> >>> = ~
>> >>> latitude +longitude| id ), method = "ML")
>> >>> the error is "cannot have zero distances in "corSpatial" which I
>> >>> assume
>> >> is
>> >>> due to the repeated observations having the same exact lat and lon;
>> >>> therefore zero distance
>> >>>
>> >>> Moreover, when I do anything with '| id' I think the model only
>> >>> accounts
>> >>> for 'within-group' correlations, not across stations
>> >>>
>> >>>
>> >>> On Tue, Mar 21, 2017 at 4:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> >>>
>> >>>> Your approach seems about right.
>> >>>>
>> >>>> - What precisely does "unsuccessful" mean?  warnings, errors,
>> >>>> ridiculous answers?
>> >>>> - Is this your whole data set or a subset?
>> >>>> - centering and scaling predictors is always worth a shot to fix
>> >>>> numeric problems
>> >>>> - INLA is more powerful than lme for fitting spatial correlations,
>> >>>> although it's a *steep* learning curve ...
>> >>>>
>> >>>>
>> >>>> On Tue, Mar 21, 2017 at 5:08 PM, Michael Hyland
>> >>>> <mhyland at u.northwestern.edu> wrote:
>> >>>>> Hi,
>> >>>>>
>> >>>>> I'm new to the listserv.
>> >>>>>
>> >>>>> A shortened version of my dataset is below. I am developing a model
>> >>>>> to
>> >>>>> forecast monthly ridership at Bikeshare stations. I want to predict
>> >>>> 'Cnts'
>> >>>>> as a function of 'Population' - 'Temperature'. The dataset is
>> >> unbalanced
>> >>>>> (unequal number of observations for each station) and most of
>> >> covariates
>> >>>> do
>> >>>>> not vary over time, but a few do.
>> >>>>>
>> >>>>> I have successfully used lmer() and lme() in R to capture the
>> >> dependency
>> >>>>> between the error terms for repeated observations from a given
>> >>>>> station
>> >>>>> ('id').
>> >>>>>
>> >>>>> model_spatial = lme(log(counts) ~ log(Population)
>> >>>>>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>> >>>>>                  , data = Data, random = ~1|id, method = "ML" )
>> >>>>>
>> >>>>> model_All = lmer(log(counts) ~ log(Population)
>> >>>>>                  +Drive +Med_Income + Buff2 +Rain + Temperature
>> >>>>>                  + (1|id)
>> >>>>>                   , data = Data )
>> >>>>>
>> >>>>> However, a Moran's I test of the residuals suggests that the
>> >>>>> residuals
>> >>>> are
>> >>>>> spatially correlated.
>> >>>>> station.dists <- as.matrix(dist(cbind(Data$longitude,
>> >> Data$latitude)))
>> >>>>> station.dists.inv <- 1/station.dists
>> >>>>> station.dists.inv[is.infinite(station.dists.inv)] <- 0   #Distance
>> >>>> value is
>> >>>>> inf for repeated observations from the same station
>> >>>>> Data$resid_all = resid(model_spatial)
>> >>>>> Moran.I(Data$resid_all, station.dists.inv)
>> >>>>>
>> >>>>>
>> >>>>> Hence, I need to develop a model in R that accounts for spatial
>> >>>> correlation
>> >>>>> across stations, while simultaneously capturing correlations between
>> >>>>> observations from a single station.  I've tried the following
>> >>>>> updates
>> >> to
>> >>>>> the lme() model, but have been unsuccessful.
>> >>>>> model_spatial.gau <- update(model_spatial, correlation =
>> >>>>> corGaus(form
>> >> = ~
>> >>>>> latitude +longitude ), method = "ML")
>> >>>>> model_spatial.gau <- update(model_spatial, correlation =
>> >>>>> corGaus(form
>> >> = ~
>> >>>>> latitude +longitude| id ), method = "ML")
>> >>>>>
>> >>>>> Is there a way to formulate the correlation matrix in lme() or
>> >>>>> lmer()
>> >>>> such
>> >>>>> that the correlation between repeated obvservations of a given
>> >>>>> station
>> >>>> *and*
>> >>>>> the spatial autocorrelation between stations is accounted for?
>> >>>>>
>> >>>>>
>> >>>>> year month id Cnts latitude longitude Population Drive Med_Income
>> >> Buff2
>> >>>> Rain
>> >>>>> Temperature
>> >>>>> 2015 8 2 2597 41.87264 -87.62398 4256 0.3418054 76857 127 0.07 71.8
>> >>>>> 2015 9 2 2772 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 69
>> >>>>> 2015 10 2 684 41.87264 -87.62398 4256 0.3418054 76857 128 0.07 54.7
>> >>>>> 2015 11 2 394 41.87264 -87.62398 4256 0.3418054 76857 128 0.15 44.6
>> >>>>> 2015 12 2 148 41.87264 -87.62398 4256 0.3418054 76857 129 0.16 39
>> >>>>> 2016 1 2 44 41.87264 -87.62398 4256 0.3418054 76857 129 0.03 24.7
>> >>>>> 2015 5 3 2303 41.86723 -87.61536 16735 0.4312349 75227 90 0.15 60.4
>> >>>>> 2015 6 3 3323 41.86723 -87.61536 16735 0.4312349 75227 98 0.24 67.4
>> >>>>> 2015 7 3 5920 41.86723 -87.61536 16735 0.4312349 75227 98 0.09 72.3
>> >>>>> 2015 8 3 4405 41.86723 -87.61536 16735 0.4312349 75227 98 0.07 71.8
>> >>>>> 2015 9 3 3638 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 69
>> >>>>> 2015 10 3 2061 41.86723 -87.61536 16735 0.4312349 75227 99 0.07 54.7
>> >>>>> 2015 11 3 1074 41.86723 -87.61536 16735 0.4312349 75227 99 0.15 44.6
>> >>>>> 2015 12 3 374 41.86723 -87.61536 16735 0.4312349 75227 100 0.16 39
>> >>>>> 2016 1 3 188 41.86723 -87.61536 16735 0.4312349 75227 100 0.03 24.7
>> >>>>> 2016 2 3 474 41.86723 -87.61536 16735 0.4312349 75227 100 0.04 30.4
>> >>>>> 2015 6 4 2968 41.85627 -87.61335 16735 0.4312349 75227 68 0.24 67.4
>> >>>>> 2015 7 4 4266 41.85627 -87.61335 16735 0.4312349 75227 68 0.09 72.3
>> >>>>> 2015 8 4 3442 41.85627 -87.61335 16735 0.4312349 75227 68 0.07 71.8
>> >>>>> 2015 9 4 2552 41.85627 -87.61335 16735 0.4312349 75227 69 0.15 69
>> >>>>> 2015 10 4 1301 41.85627 -87.61335 16735 0.4312349 75227 69 0.07 54.7
>> >>>>>
>> >>>>>
>> >>>>> Thanks,
>> >>>>> Mike Hyland
>> >>>>>
>> >>>>>         [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> _______________________________________________
>> >>>>> R-sig-mixed-models at r-project.org mailing list
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From victoriastimple at gmail.com  Thu Mar 23 01:19:13 2017
From: victoriastimple at gmail.com (Victoria Stimple)
Date: Wed, 22 Mar 2017 20:19:13 -0400
Subject: [R-sig-ME] Linear mixed effects
Message-ID: <CAB72_tCdu5hT-91cuJ0q9mX1g-uEEoNH8LK4qQ-Lve4L9Q3MYQ@mail.gmail.com>

Hi all, I am writing to receive some help on the following issue:

I want to estimate different slopes and intercepts for the three groups.
For example: group A is subjects whose father's were blue-collar; group B
is subjects whose father's were white-collar; group C is subjects whose
father's were other types of workers. I have repeated measures for 10
annual surveys and subjects reported how much of their income they saved. I
want to see if the intercept and trajectory differs for the three groups.

This is what I come up with but I am not sure if this gets at the
appropriate verbal explanation. Thank you very much for your time. I truly
appreciate it. Thank you!

m1 <- lmer(savings~ time + (time|subjects))
m1 looks at the impact of time on savings and estimates intercepts and
slopes for each subject.

m2 <- lmer(savings~time*fathers_occupation + (time|subjects))

Does m2 examine the differences in the intercept and slope for the two
groups?

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Mar 23 18:40:10 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 23 Mar 2017 18:40:10 +0100
Subject: [R-sig-ME] Linear mixed effects
In-Reply-To: <CAB72_tCdu5hT-91cuJ0q9mX1g-uEEoNH8LK4qQ-Lve4L9Q3MYQ@mail.gmail.com>
References: <CAB72_tCdu5hT-91cuJ0q9mX1g-uEEoNH8LK4qQ-Lve4L9Q3MYQ@mail.gmail.com>
Message-ID: <CAJuCY5zxWdDPTh2F0SVXnKnsEoFYg6pYH1-vo0itGkoqEfnvsw@mail.gmail.com>

Dear Victoria,

It does gives the difference in intercept and slope due to the occupation
of the father.

Best regards,

Thierry

Op 23-mrt.-2017 18:14 schreef "Victoria Stimple" <victoriastimple at gmail.com
>:

Hi all, I am writing to receive some help on the following issue:

I want to estimate different slopes and intercepts for the three groups.
For example: group A is subjects whose father's were blue-collar; group B
is subjects whose father's were white-collar; group C is subjects whose
father's were other types of workers. I have repeated measures for 10
annual surveys and subjects reported how much of their income they saved. I
want to see if the intercept and trajectory differs for the three groups.

This is what I come up with but I am not sure if this gets at the
appropriate verbal explanation. Thank you very much for your time. I truly
appreciate it. Thank you!

m1 <- lmer(savings~ time + (time|subjects))
m1 looks at the impact of time on savings and estimates intercepts and
slopes for each subject.

m2 <- lmer(savings~time*fathers_occupation + (time|subjects))

Does m2 examine the differences in the intercept and slope for the two
groups?

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From Steve.Pierce at cstat.msu.edu  Fri Mar 24 13:35:00 2017
From: Steve.Pierce at cstat.msu.edu (Steve Pierce)
Date: Fri, 24 Mar 2017 12:35:00 +0000
Subject: [R-sig-ME] Linear mixed effects
In-Reply-To: <CAB72_tCdu5hT-91cuJ0q9mX1g-uEEoNH8LK4qQ-Lve4L9Q3MYQ@mail.gmail.com>
References: <CAB72_tCdu5hT-91cuJ0q9mX1g-uEEoNH8LK4qQ-Lve4L9Q3MYQ@mail.gmail.com>
Message-ID: <a6880bbfe7e9417fa63659e8c11df0bc@CSTATWINEX1.cstatwin.msu.edu>

Victoria,

The sort of model you're fitting is often called a growth curve model. The first half of following book is an excellent source on these sorts of models. It gives great descriptions of how to specify & interpret such models. They use lots of graphs to help visualize different model specifications and results. Example code for the text book is available online at http://stats.idre.ucla.edu/other/examples/alda/ as well.  

Singer, J. D., & Willett, J. B. (2003). Applied longitudinal data analysis: Modeling change and event occurrence. New York, NY: Oxford University Press.


Steven J. Pierce, Ph.D.
Acting Director; Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
E-mail: Steve.Pierce at cstat.msu.edu
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Victoria Stimple [mailto:victoriastimple at gmail.com] 
Sent: Wednesday, March 22, 2017 8:19 PM
To: R-SIG-Mixed-Models at R-project.org
Subject: [R-sig-ME] Linear mixed effects

Hi all, I am writing to receive some help on the following issue:

I want to estimate different slopes and intercepts for the three groups.
For example: group A is subjects whose father's were blue-collar; group B
is subjects whose father's were white-collar; group C is subjects whose
father's were other types of workers. I have repeated measures for 10
annual surveys and subjects reported how much of their income they saved. I
want to see if the intercept and trajectory differs for the three groups.

This is what I come up with but I am not sure if this gets at the
appropriate verbal explanation. Thank you very much for your time. I truly
appreciate it. Thank you!

m1 <- lmer(savings~ time + (time|subjects))
m1 looks at the impact of time on savings and estimates intercepts and
slopes for each subject.

m2 <- lmer(savings~time*fathers_occupation + (time|subjects))

Does m2 examine the differences in the intercept and slope for the two
groups?

	[[alternative HTML version deleted]]



From aqmalsaepul at gmail.com  Sun Mar 26 13:00:56 2017
From: aqmalsaepul at gmail.com (Euis Aqmaliyah)
Date: Sun, 26 Mar 2017 18:00:56 +0700
Subject: [R-sig-ME] Specification Noninformative Prior with Jeffrey's Method
	in MCMCglmm function
In-Reply-To: <CAPFbjCZG26fVn4kQRJXjxX9-ba5SCWwhA4isCzMZrBtKb1hizw@mail.gmail.com>
References: <CAPFbjCb6p7Va_bXbJSyxnU80TU+J14GcNb1AFND2cRdSZCS2bw@mail.gmail.com>
	<CAPFbjCbQMKZJGbw5+VW8x1uJS863f-Nf3xgF4VEPF=Tdbdwdhw@mail.gmail.com>
	<CAPFbjCZhocekEyqovQD8oLA0QGuZY+xRezb0a4v=gm5y31vT2A@mail.gmail.com>
	<CAPFbjCYNXVJ6KiAkXD-NyrT43WXhwZoZd0pPOKX_gtU-C7R27w@mail.gmail.com>
	<CAPFbjCYKyEZJjBs5P4GvKfSCBpe7dxtpVnoMMMVJVUHkSEuVNw@mail.gmail.com>
	<CAPFbjCbUOvm4yNROr2aaYjaZVS8dmMmJ+g=xT9n+fFkiwN4P9Q@mail.gmail.com>
	<CAPFbjCa5ZCUjTYw+useSsdLBvkb73nBSazuJe5bR3nCCHDfqOA@mail.gmail.com>
	<CAPFbjCaVMod58u3HXsqWQcA0Nx5DbH-m_b1MHs9mg0mOTaEijA@mail.gmail.com>
	<CAPFbjCYQ-XdsJx47px9scr6iixdtte-HRVxWy4xnX6ga=oBnxw@mail.gmail.com>
	<CAPFbjCZVEi--SXLQdzCLbnWVAOSroFjZSvF7=k60_mDU0WKCrA@mail.gmail.com>
	<CAPFbjCZG26fVn4kQRJXjxX9-ba5SCWwhA4isCzMZrBtKb1hizw@mail.gmail.com>
Message-ID: <CAPFbjCYP=UuPhQbSABORhtr01uKZDpdoKN1pFV7LhWX8JQXVEw@mail.gmail.com>

Hello.
Now, i'm writting thesis with the topic Small Area Estimation using
Bayesian Approach.
Models that i use in estimation are Linear Mixed Model (LMM) and
Generalized Linear Mixed Model (GLMM) because my response variable is
Zero-Inflated Data.
But, i have problem when i fit a linear mixed model. I want specification
prior for residual variance parameter (sigma^2) is 1/sigma^2 that i get
using Jeffrey's Method from Normal distribution.
So, how to specification that prior in MCMCglmm function?
I hope you can help me.
Thank you.

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sun Mar 26 19:30:31 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 26 Mar 2017 18:30:31 +0100
Subject: [R-sig-ME] Specification Noninformative Prior with Jeffrey's
 Method in MCMCglmm function
In-Reply-To: <CAPFbjCYP=UuPhQbSABORhtr01uKZDpdoKN1pFV7LhWX8JQXVEw@mail.gmail.com>
References: <CAPFbjCb6p7Va_bXbJSyxnU80TU+J14GcNb1AFND2cRdSZCS2bw@mail.gmail.com>
	<CAPFbjCbQMKZJGbw5+VW8x1uJS863f-Nf3xgF4VEPF=Tdbdwdhw@mail.gmail.com>
	<CAPFbjCZhocekEyqovQD8oLA0QGuZY+xRezb0a4v=gm5y31vT2A@mail.gmail.com>
	<CAPFbjCYNXVJ6KiAkXD-NyrT43WXhwZoZd0pPOKX_gtU-C7R27w@mail.gmail.com>
	<CAPFbjCYKyEZJjBs5P4GvKfSCBpe7dxtpVnoMMMVJVUHkSEuVNw@mail.gmail.com>
	<CAPFbjCbUOvm4yNROr2aaYjaZVS8dmMmJ+g=xT9n+fFkiwN4P9Q@mail.gmail.com>
	<CAPFbjCa5ZCUjTYw+useSsdLBvkb73nBSazuJe5bR3nCCHDfqOA@mail.gmail.com>
	<CAPFbjCaVMod58u3HXsqWQcA0Nx5DbH-m_b1MHs9mg0mOTaEijA@mail.gmail.com>
	<CAPFbjCYQ-XdsJx47px9scr6iixdtte-HRVxWy4xnX6ga=oBnxw@mail.gmail.com>
	<CAPFbjCZVEi--SXLQdzCLbnWVAOSroFjZSvF7=k60_mDU0WKCrA@mail.gmail.com>
	<CAPFbjCZG26fVn4kQRJXjxX9-ba5SCWwhA4isCzMZrBtKb1hizw@mail.gmail.com>
	<CAPFbjCYP=UuPhQbSABORhtr01uKZDpdoKN1pFV7LhWX8JQXVEw@mail.gmail.com>
Message-ID: <b670a03b-e412-831c-3206-a9d823510936@ed.ac.uk>

Hi,

I think p(sigma^2) = 1/sigma^2 is the limit of the inverse-chisquare 
distribution as nu goes to zero.  This is the default in MCMCglmm.

Cheers,

Jarrod


On 26/03/2017 12:00, Euis Aqmaliyah wrote:
> Hello.
> Now, i'm writting thesis with the topic Small Area Estimation using
> Bayesian Approach.
> Models that i use in estimation are Linear Mixed Model (LMM) and
> Generalized Linear Mixed Model (GLMM) because my response variable is
> Zero-Inflated Data.
> But, i have problem when i fit a linear mixed model. I want specification
> prior for residual variance parameter (sigma^2) is 1/sigma^2 that i get
> using Jeffrey's Method from Normal distribution.
> So, how to specification that prior in MCMCglmm function?
> I hope you can help me.
> Thank you.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From cdemars at ualberta.ca  Sun Mar 26 22:15:16 2017
From: cdemars at ualberta.ca (Craig DeMars)
Date: Sun, 26 Mar 2017 14:15:16 -0600
Subject: [R-sig-ME] Advice on comparing non-nested random slope models
Message-ID: <CAM1YihA=ej7EU+XpXFQjQT3yPoRLKuaUKz3SaMvR12nvXAsH=A@mail.gmail.com>

Hello,

This is a bit of a follow-up to a question last week on selecting among
GLMM models. Is there a recommended strategy for comparing non-nested,
random slope models? I have seen a similar question posted here
http://stats.stackexchange.com/questions/116935/comparing-non-nested-
models-with-aic but it doesn't seem to answer the problem - and maybe there
is no "answer".  Zuur et al. (2010) discuss model selection but only in a
nested framework. Bolker et al. (2009) suggest AIC can be used in GLMMs but
caution against boundary issues and don't specifically mention any issues
with comparing different random effects structures (as Zuur does).

The context of my question comes from an analysis where we have 5 *a priori*
hypotheses describing different climate effects on juvenile recruitment in
an ungulate species.  The data set has 21 populations (or herds) with
repeated annual measurements of recruitment and the climate variables
measured at the herd scale. To generate SE's that reflect herd as the
sampling unit, explanatory variables are specified as random slopes within
herd (as recommended by Schielzeth & Forstmeier 2009; Year is also
specified as a random intercept).  Because there are only 21 herds, models
are fairly simple with only 2-3 explanatory variables (3 may by pushing
it...????). I can't post the data but it isn't really relevant to the
question (I think).

Initially, we looked at AIC to compare models.  At the bottom of this
email, I have pasted the output from two models, each representing separate
hypotheses, to illustrate "the problem".  The first model yields an AIC
value of 2210.7. The second model yields an AIC of 2479.5. Using AIC, Model
1 would be the "best" model. However, examining the parameter estimates
within each model makes me think twice about declaring  Model 1 (or the
hypothesis it represents) as the most parsimonious explanation for the
data. In Model 1, two of the thee fixed effects estimates have small effect
sizes and all estimates are "non-significant" (if one considers
p-values....). In Model 2, two of the three fixed effect estimates have
larger effect sizes are would be considered "significant.  Is this an
example of the difficulty in using AIC to compare non-nested mixed
models.....or am I missing something in my interpretation? I haven't come
across this type of result when model selecting among GLMs.

Any suggestions on how best to compare competing hypotheses represented by
non-nested GLMMs? Should one just compare relative effect sizes of
parameter estimates among models?
Any help would be appreciated.

Thanks,
Craig

*Model 1:*
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: (Calves/Cows) ~ spr.indvi.ab + green.rate.ab + trend + (1 | Year)
+      (spr.indvi.ab + green.rate.ab + trend | Herd)
   Data: bou.dat
Weights: Cows

     *AIC  *    BIC   logLik deviance df.resid
  *2210.7*   2265.0  -1090.3   2180.7      262

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.8700 -1.0800 -0.1057  1.0405  6.8353

Random effects:
 Groups Name          Variance Std.Dev. Corr
 Year   (Intercept)   0.10517  0.3243
 Herd   (Intercept)   0.29832  0.5462
        spr.indvi.ab  0.04331  0.2081    0.38
        green.rate.ab 0.03741  0.1934    0.68  0.62
        trend         0.62661  0.7916   -0.59  0.20 -0.46
Number of obs: 277, groups:  Year, 22; Herd, 21

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)   -1.62160    0.15798 -10.265   <2e-16 ***
spr.indvi.ab   0.04019    0.09793   0.410    0.682
green.rate.ab  0.04704    0.05555   0.847    0.397
trend         -0.29676    0.23092  -1.285    0.199
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) spr.n. grn.r.
spr.indvi.b -0.113
green.rat.b  0.347  0.438
trend       -0.606  0.349 -0.200

*Model 2:*
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: (Calves/Cows) ~ win.bb + tot.sn.ybb + trend + (1 | Year) + (win.bb
+      tot.sn.ybb | Herd)
   Data: bou.dat
Weights: Cows

    * AIC*      BIC   logLik deviance df.resid
  *2479.5 *  2519.4  -1228.8   2457.5      266

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.5720 -1.1801 -0.1364  1.3704  8.3271

Random effects:
 Groups Name        Variance Std.Dev. Corr
 Year   (Intercept) 0.10694  0.3270
 Herd   (Intercept) 0.13496  0.3674
        win.bb      0.05351  0.2313   -0.13
        tot.sn.ybb  0.06200  0.2490    0.23  0.34
Number of obs: 277, groups:  Year, 22; Herd, 21

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -1.851656   0.127702 -14.500  < 2e-16 ***
win.bb      -0.364019   0.101386  -3.590  0.00033 ***
tot.sn.ybb   0.275271   0.118111   2.331  0.01977 *
trend       -0.007568   0.115706  -0.065  0.94785
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr) win.bb tt.sn.
win.bb      0.048
tot.sn.ybb  0.269  0.083
trend      -0.242 -0.269 -0.131
-- 
Craig DeMars, Ph.D.
Postdoctoral Fellow
Department of Biological Sciences
University of Alberta
Phone: 780-221-3971 <(780)%20221-3971>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Mon Mar 27 02:30:05 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Mon, 27 Mar 2017 02:30:05 +0200
Subject: [R-sig-ME] Advice on comparing non-nested random slope models
In-Reply-To: <CAM1YihA=ej7EU+XpXFQjQT3yPoRLKuaUKz3SaMvR12nvXAsH=A@mail.gmail.com>
References: <CAM1YihA=ej7EU+XpXFQjQT3yPoRLKuaUKz3SaMvR12nvXAsH=A@mail.gmail.com>
Message-ID: <CAGoSky-Qojdc8rAi0qp59Z3D4cDhkS3L+_eD5RevZLkyw5u1Lw@mail.gmail.com>

Hi Craig,

in short, significance does not tell you anything about model fit. You may
find models to have the best fit without any particular predictor being
significant for this model. Similarily average "effect sizes" are not a
good indicator of model fit.

Information criteria are, in my opinion, the right way to go. For an
improved version of the AIC, I recommend going Bayesian and computing the
so called LOO (leave-one-out cross validation) or the WAIC (widely
applicable information criterion) as implemented in the R package loo. For
the bayesian GLMM model fitting (and convenient LOO computation), you could
use the R packages brms or rstanarm.

Best,
Paul

2017-03-26 22:15 GMT+02:00 Craig DeMars <cdemars at ualberta.ca>:

> Hello,
>
> This is a bit of a follow-up to a question last week on selecting among
> GLMM models. Is there a recommended strategy for comparing non-nested,
> random slope models? I have seen a similar question posted here
> http://stats.stackexchange.com/questions/116935/comparing-non-nested-
> models-with-aic but it doesn't seem to answer the problem - and maybe
> there
> is no "answer".  Zuur et al. (2010) discuss model selection but only in a
> nested framework. Bolker et al. (2009) suggest AIC can be used in GLMMs but
> caution against boundary issues and don't specifically mention any issues
> with comparing different random effects structures (as Zuur does).
>
> The context of my question comes from an analysis where we have 5 *a
> priori*
> hypotheses describing different climate effects on juvenile recruitment in
> an ungulate species.  The data set has 21 populations (or herds) with
> repeated annual measurements of recruitment and the climate variables
> measured at the herd scale. To generate SE's that reflect herd as the
> sampling unit, explanatory variables are specified as random slopes within
> herd (as recommended by Schielzeth & Forstmeier 2009; Year is also
> specified as a random intercept).  Because there are only 21 herds, models
> are fairly simple with only 2-3 explanatory variables (3 may by pushing
> it...????). I can't post the data but it isn't really relevant to the
> question (I think).
>
> Initially, we looked at AIC to compare models.  At the bottom of this
> email, I have pasted the output from two models, each representing separate
> hypotheses, to illustrate "the problem".  The first model yields an AIC
> value of 2210.7. The second model yields an AIC of 2479.5. Using AIC, Model
> 1 would be the "best" model. However, examining the parameter estimates
> within each model makes me think twice about declaring  Model 1 (or the
> hypothesis it represents) as the most parsimonious explanation for the
> data. In Model 1, two of the thee fixed effects estimates have small effect
> sizes and all estimates are "non-significant" (if one considers
> p-values....). In Model 2, two of the three fixed effect estimates have
> larger effect sizes are would be considered "significant.  Is this an
> example of the difficulty in using AIC to compare non-nested mixed
> models.....or am I missing something in my interpretation? I haven't come
> across this type of result when model selecting among GLMs.
>
> Any suggestions on how best to compare competing hypotheses represented by
> non-nested GLMMs? Should one just compare relative effect sizes of
> parameter estimates among models?
> Any help would be appreciated.
>
> Thanks,
> Craig
>
> *Model 1:*
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: (Calves/Cows) ~ spr.indvi.ab + green.rate.ab + trend + (1 | Year)
> +      (spr.indvi.ab + green.rate.ab + trend | Herd)
>    Data: bou.dat
> Weights: Cows
>
>      *AIC  *    BIC   logLik deviance df.resid
>   *2210.7*   2265.0  -1090.3   2180.7      262
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.8700 -1.0800 -0.1057  1.0405  6.8353
>
> Random effects:
>  Groups Name          Variance Std.Dev. Corr
>  Year   (Intercept)   0.10517  0.3243
>  Herd   (Intercept)   0.29832  0.5462
>         spr.indvi.ab  0.04331  0.2081    0.38
>         green.rate.ab 0.03741  0.1934    0.68  0.62
>         trend         0.62661  0.7916   -0.59  0.20 -0.46
> Number of obs: 277, groups:  Year, 22; Herd, 21
>
> Fixed effects:
>               Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -1.62160    0.15798 -10.265   <2e-16 ***
> spr.indvi.ab   0.04019    0.09793   0.410    0.682
> green.rate.ab  0.04704    0.05555   0.847    0.397
> trend         -0.29676    0.23092  -1.285    0.199
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) spr.n. grn.r.
> spr.indvi.b -0.113
> green.rat.b  0.347  0.438
> trend       -0.606  0.349 -0.200
>
> *Model 2:*
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: (Calves/Cows) ~ win.bb + tot.sn.ybb + trend + (1 | Year) + (
> win.bb
> +      tot.sn.ybb | Herd)
>    Data: bou.dat
> Weights: Cows
>
>     * AIC*      BIC   logLik deviance df.resid
>   *2479.5 *  2519.4  -1228.8   2457.5      266
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -4.5720 -1.1801 -0.1364  1.3704  8.3271
>
> Random effects:
>  Groups Name        Variance Std.Dev. Corr
>  Year   (Intercept) 0.10694  0.3270
>  Herd   (Intercept) 0.13496  0.3674
>         win.bb      0.05351  0.2313   -0.13
>         tot.sn.ybb  0.06200  0.2490    0.23  0.34
> Number of obs: 277, groups:  Year, 22; Herd, 21
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.851656   0.127702 -14.500  < 2e-16 ***
> win.bb      -0.364019   0.101386  -3.590  0.00033 ***
> tot.sn.ybb   0.275271   0.118111   2.331  0.01977 *
> trend       -0.007568   0.115706  -0.065  0.94785
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>            (Intr) win.bb tt.sn.
> win.bb      0.048
> tot.sn.ybb  0.269  0.083
> trend      -0.242 -0.269 -0.131
> --
> Craig DeMars, Ph.D.
> Postdoctoral Fellow
> Department of Biological Sciences
> University of Alberta
> Phone: 780-221-3971 <(780)%20221-3971>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From jacob.berson at research.uwa.edu.au  Mon Mar 27 06:18:27 2017
From: jacob.berson at research.uwa.edu.au (Jacob Berson)
Date: Mon, 27 Mar 2017 12:18:27 +0800
Subject: [R-sig-ME] Binary response animal models in MCMCglmm
Message-ID: <00bb01d2a6b1$3104dc30$930e9490$@research.uwa.edu.au>

Hi All

 

I have attempted to estimate the heritability of several binary traits, and
test for genetic correlations both between two binary traits, as well as
between a binary and a Gaussian trait, using the animal model in MCMCglmm.

 

Several issues have come up in my analysis that I'm hoping to get some help
with.

 

For some traits the posterior distribution of my heritability estimate is
very close to zero, resulting in a non-symmetric density plot (the left tail
is essentially cut by the y-axis). With these distributions I get very
different point estimates of heritability depending on if I use the
posterior mean or posterior mode.

 

1)      I've seen both the mean and mode used in the literature, does anyone
have a view on which is the most appropriate in the above circumstance?

 

The abovementioned distributions suggest to me that there is little, if any,
additive genetic variance present. However, for some traits the DIC value of
a model with "animal" as a random effect is lower than the null model
(though after reading
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html and
switching from using family="ordinal" to family="threshold" the difference
in DIC values was greatly reduced).

 

2)      Are differences in DIC values an appropriate tool for testing model
fit when the response is binary? If so, what level of difference is
sufficient to reject the null model (I've seen both >5 and >10)?

 

I am getting a posterior distribution centred on zero when testing for
intersexual genetic correlations between two binary traits. However, when I
look at the data (for example using sire means) it seems to me that there is
in fact a strong correlation and that my MCMCglmm results are not correct.

 

3)      Am I trying to do the impossible, i.e., is it still recommended (as
was the case a few years ago
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html) not to
fit bivariate binary models in MCMCglmm, even when using family="threshold"?

 

Finally, as I understand it, it is not appropriate to report the estimates
of the additive genetic variance from binary models because it depends on
the residual variance (which I have fixed to 1).

 

4)      Can anyone help a novice like me understand why heritability is more
appropriate to report, even though it also incorporates the fixed residual
variance?

 

Apologies for the length of this post - after much searching and reading I
haven't been able to find solutions to these questions. Any advice on the
above and/or feedback on my code below would be very much appreciated.

 

Jacob

 

 

My code:

 

#Univariate models for binary traits

 

Prior0 <- list(R = list(V = 1, fix = 1))

 

Prior1 <- list(R = list(V = 1, fix = 1), 

               G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0, alpha.V =
1)))

 

Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold", pedigree =
Ped,

                prior = Prior0, data = Data, nitt = 1050000, burnin = 50000,
thin = 500, verbose = FALSE)

 

Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family =
"threshold", pedigree = Ped, 

prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin = 500,
verbose = FALSE)

 

heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va [["VCV"]]) 

 

 

#Genetic correlation between two binary traits (bin1 and bin2)

 

Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),

                 G = list(G1 = list(V = diag(2), nu = 10001, alpha.mu =
c(0,0), alpha.V = diag(2))))

 

Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random =
~us(trait):animal, 

     rcov = ~corg(trait):units, family = c("threshold", "threshold"),
pedigree = Ped, prior = Prior1rG,    

     data = Data, nitt = 4050000, burnin = 50000, thin = 2000, verbose =
FALSE)

 

Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] /
sqrt(Bin.Bin.corr$VCV[, 

"traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
"traitbin2:traitbin2.animal"])

 

 

#Genetic correlations between a Gaussian (gau1) and a binary (bin2) trait

 

Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2), 

                 G = list(G1 = list(V = diag(2), nu = 2, alpha.mu = c(0,0),
alpha.V = diag(2)*1000)))

 

Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random =
~us(trait):animal, rcov = 

~us(trait):units, family = c("gaussian", "threshold"), pedigree = Ped,


prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin = 500, 

verbose = FALSE)

 

Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] /
sqrt(Gau.Bin.corr $VCV[, "trait 

gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
"traitbin2:traitbin2.animal"])

 

 

 

Jacob Berson BSc (Hons), PhD Candidate

Centre for Evolutionary Biology

 

School of Animal Biology (M092)

University of Western Australia

35 Stirling Highway

Crawley, WA, 6009

 

Tel: (+61 8) 6488 3425

 


	[[alternative HTML version deleted]]


From aqmalsaepul at gmail.com  Mon Mar 27 11:16:56 2017
From: aqmalsaepul at gmail.com (Euis Aqmaliyah)
Date: Mon, 27 Mar 2017 16:16:56 +0700
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
Message-ID: <CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>

Hi,

I stil try fit linear mixed model. I use Potencial Scale Reduction (PSR) to
check convergence. But, it still dosn't convergence. Is there any function
that can i use to determine length of chains, length of burn-in, or
thinning interval?

Thank you.

	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Mon Mar 27 12:36:05 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Mon, 27 Mar 2017 06:36:05 -0400
Subject: [R-sig-ME] Advice on comparing non-nested random slope models
In-Reply-To: <CAGoSky-Qojdc8rAi0qp59Z3D4cDhkS3L+_eD5RevZLkyw5u1Lw@mail.gmail.com>
References: <CAM1YihA=ej7EU+XpXFQjQT3yPoRLKuaUKz3SaMvR12nvXAsH=A@mail.gmail.com>
	<CAGoSky-Qojdc8rAi0qp59Z3D4cDhkS3L+_eD5RevZLkyw5u1Lw@mail.gmail.com>
Message-ID: <CAFW8Byp0Dfsn8a+gdeu0Gi5a=y3tuNZdAXrocBuQEdVMSogU3A@mail.gmail.com>

You might try a Vuong test. It's a likelihood ratio test that allows for
nonnested models.

On Mar 26, 2017 8:30 PM, "Paul Buerkner" <paul.buerkner at gmail.com> wrote:

Hi Craig,

in short, significance does not tell you anything about model fit. You may
find models to have the best fit without any particular predictor being
significant for this model. Similarily average "effect sizes" are not a
good indicator of model fit.

Information criteria are, in my opinion, the right way to go. For an
improved version of the AIC, I recommend going Bayesian and computing the
so called LOO (leave-one-out cross validation) or the WAIC (widely
applicable information criterion) as implemented in the R package loo. For
the bayesian GLMM model fitting (and convenient LOO computation), you could
use the R packages brms or rstanarm.

Best,
Paul

2017-03-26 22:15 GMT+02:00 Craig DeMars <cdemars at ualberta.ca>:

> Hello,
>
> This is a bit of a follow-up to a question last week on selecting among
> GLMM models. Is there a recommended strategy for comparing non-nested,
> random slope models? I have seen a similar question posted here
> http://stats.stackexchange.com/questions/116935/comparing-non-nested-
> models-with-aic but it doesn't seem to answer the problem - and maybe
> there
> is no "answer".  Zuur et al. (2010) discuss model selection but only in a
> nested framework. Bolker et al. (2009) suggest AIC can be used in GLMMs
but
> caution against boundary issues and don't specifically mention any issues
> with comparing different random effects structures (as Zuur does).
>
> The context of my question comes from an analysis where we have 5 *a
> priori*
> hypotheses describing different climate effects on juvenile recruitment in
> an ungulate species.  The data set has 21 populations (or herds) with
> repeated annual measurements of recruitment and the climate variables
> measured at the herd scale. To generate SE's that reflect herd as the
> sampling unit, explanatory variables are specified as random slopes within
> herd (as recommended by Schielzeth & Forstmeier 2009; Year is also
> specified as a random intercept).  Because there are only 21 herds, models
> are fairly simple with only 2-3 explanatory variables (3 may by pushing
> it...????). I can't post the data but it isn't really relevant to the
> question (I think).
>
> Initially, we looked at AIC to compare models.  At the bottom of this
> email, I have pasted the output from two models, each representing
separate
> hypotheses, to illustrate "the problem".  The first model yields an AIC
> value of 2210.7. The second model yields an AIC of 2479.5. Using AIC,
Model
> 1 would be the "best" model. However, examining the parameter estimates
> within each model makes me think twice about declaring  Model 1 (or the
> hypothesis it represents) as the most parsimonious explanation for the
> data. In Model 1, two of the thee fixed effects estimates have small
effect
> sizes and all estimates are "non-significant" (if one considers
> p-values....). In Model 2, two of the three fixed effect estimates have
> larger effect sizes are would be considered "significant.  Is this an
> example of the difficulty in using AIC to compare non-nested mixed
> models.....or am I missing something in my interpretation? I haven't come
> across this type of result when model selecting among GLMs.
>
> Any suggestions on how best to compare competing hypotheses represented by
> non-nested GLMMs? Should one just compare relative effect sizes of
> parameter estimates among models?
> Any help would be appreciated.
>
> Thanks,
> Craig
>
> *Model 1:*
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: (Calves/Cows) ~ spr.indvi.ab + green.rate.ab + trend + (1 | Year)
> +      (spr.indvi.ab + green.rate.ab + trend | Herd)
>    Data: bou.dat
> Weights: Cows
>
>      *AIC  *    BIC   logLik deviance df.resid
>   *2210.7*   2265.0  -1090.3   2180.7      262
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.8700 -1.0800 -0.1057  1.0405  6.8353
>
> Random effects:
>  Groups Name          Variance Std.Dev. Corr
>  Year   (Intercept)   0.10517  0.3243
>  Herd   (Intercept)   0.29832  0.5462
>         spr.indvi.ab  0.04331  0.2081    0.38
>         green.rate.ab 0.03741  0.1934    0.68  0.62
>         trend         0.62661  0.7916   -0.59  0.20 -0.46
> Number of obs: 277, groups:  Year, 22; Herd, 21
>
> Fixed effects:
>               Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -1.62160    0.15798 -10.265   <2e-16 ***
> spr.indvi.ab   0.04019    0.09793   0.410    0.682
> green.rate.ab  0.04704    0.05555   0.847    0.397
> trend         -0.29676    0.23092  -1.285    0.199
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) spr.n. grn.r.
> spr.indvi.b -0.113
> green.rat.b  0.347  0.438
> trend       -0.606  0.349 -0.200
>
> *Model 2:*
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: (Calves/Cows) ~ win.bb + tot.sn.ybb + trend + (1 | Year) + (
> win.bb
> +      tot.sn.ybb | Herd)
>    Data: bou.dat
> Weights: Cows
>
>     * AIC*      BIC   logLik deviance df.resid
>   *2479.5 *  2519.4  -1228.8   2457.5      266
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -4.5720 -1.1801 -0.1364  1.3704  8.3271
>
> Random effects:
>  Groups Name        Variance Std.Dev. Corr
>  Year   (Intercept) 0.10694  0.3270
>  Herd   (Intercept) 0.13496  0.3674
>         win.bb      0.05351  0.2313   -0.13
>         tot.sn.ybb  0.06200  0.2490    0.23  0.34
> Number of obs: 277, groups:  Year, 22; Herd, 21
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.851656   0.127702 -14.500  < 2e-16 ***
> win.bb      -0.364019   0.101386  -3.590  0.00033 ***
> tot.sn.ybb   0.275271   0.118111   2.331  0.01977 *
> trend       -0.007568   0.115706  -0.065  0.94785
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>            (Intr) win.bb tt.sn.
> win.bb      0.048
> tot.sn.ybb  0.269  0.083
> trend      -0.242 -0.269 -0.131
> --
> Craig DeMars, Ph.D.
> Postdoctoral Fellow
> Department of Biological Sciences
> University of Alberta
> Phone: 780-221-3971 <(780)%20221-3971>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Mar 27 16:16:03 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 27 Mar 2017 10:16:03 -0400
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
Message-ID: <CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>

  We would probably need more information to help you.
  Some quick thoughts:

- MCMCglmm usually burns in very quickly.   I would guess that either
(1) your problem/data are really pathological; (2) you're confusing
"burn-in" with "mixing"; if your chain reaches the stationary state
quickly but samples it slowly, then you're having a burn-in rather
than a mixing problem.  In general PRSF is meant to diagnose
convergence, not just burn-in. (Although now that I read your
question, it sounds like it's only the title that's specific to
burn-in ...)

- I think what most people do is brute-force (increase length of
chain, increasing thinning at the same time so that the number of
samples remains constant, until traceplots look OK/PRSF looks OK).
- setting more informative priors may be helpful/necessary
- the coda package has other diagnostics, in particular the
Raftery-Lewis (raftery.diag()), which is supposed to estimate the
chain length required for convergence.  You should be able to apply it
to the components of an MCMCglmm fit ($Sol, $VCV, etc.), which are
mcmc objects



On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah <aqmalsaepul at gmail.com> wrote:
> Hi,
>
> I stil try fit linear mixed model. I use Potencial Scale Reduction (PSR) to
> check convergence. But, it still dosn't convergence. Is there any function
> that can i use to determine length of chains, length of burn-in, or
> thinning interval?
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cdemars at ualberta.ca  Mon Mar 27 16:16:24 2017
From: cdemars at ualberta.ca (Craig DeMars)
Date: Mon, 27 Mar 2017 08:16:24 -0600
Subject: [R-sig-ME] Advice on comparing non-nested random slope models
In-Reply-To: <CAFW8Byp0Dfsn8a+gdeu0Gi5a=y3tuNZdAXrocBuQEdVMSogU3A@mail.gmail.com>
References: <CAM1YihA=ej7EU+XpXFQjQT3yPoRLKuaUKz3SaMvR12nvXAsH=A@mail.gmail.com>
	<CAGoSky-Qojdc8rAi0qp59Z3D4cDhkS3L+_eD5RevZLkyw5u1Lw@mail.gmail.com>
	<CAFW8Byp0Dfsn8a+gdeu0Gi5a=y3tuNZdAXrocBuQEdVMSogU3A@mail.gmail.com>
Message-ID: <CAM1YihBUvY=tipbPRkPDyZ0gN=0Ai9adNVHiNKn5tzG8y1fnNQ@mail.gmail.com>

Thanks. Unfortunately, it doesn't look like the Vuong test has been
implemented for mixed models yet, at least not in R.....

On Mon, Mar 27, 2017 at 4:36 AM, Poe, John <jdpo223 at g.uky.edu> wrote:

> You might try a Vuong test. It's a likelihood ratio test that allows for
> nonnested models.
>
>
> On Mar 26, 2017 8:30 PM, "Paul Buerkner" <paul.buerkner at gmail.com> wrote:
>
> Hi Craig,
>
> in short, significance does not tell you anything about model fit. You may
> find models to have the best fit without any particular predictor being
> significant for this model. Similarily average "effect sizes" are not a
> good indicator of model fit.
>
> Information criteria are, in my opinion, the right way to go. For an
> improved version of the AIC, I recommend going Bayesian and computing the
> so called LOO (leave-one-out cross validation) or the WAIC (widely
> applicable information criterion) as implemented in the R package loo. For
> the bayesian GLMM model fitting (and convenient LOO computation), you could
> use the R packages brms or rstanarm.
>
> Best,
> Paul
>
> 2017-03-26 22:15 GMT+02:00 Craig DeMars <cdemars at ualberta.ca>:
>
> > Hello,
> >
> > This is a bit of a follow-up to a question last week on selecting among
> > GLMM models. Is there a recommended strategy for comparing non-nested,
> > random slope models? I have seen a similar question posted here
> > http://stats.stackexchange.com/questions/116935/comparing-non-nested-
> > models-with-aic but it doesn't seem to answer the problem - and maybe
> > there
> > is no "answer".  Zuur et al. (2010) discuss model selection but only in a
> > nested framework. Bolker et al. (2009) suggest AIC can be used in GLMMs
> but
> > caution against boundary issues and don't specifically mention any issues
> > with comparing different random effects structures (as Zuur does).
> >
> > The context of my question comes from an analysis where we have 5 *a
> > priori*
> > hypotheses describing different climate effects on juvenile recruitment
> in
> > an ungulate species.  The data set has 21 populations (or herds) with
> > repeated annual measurements of recruitment and the climate variables
> > measured at the herd scale. To generate SE's that reflect herd as the
> > sampling unit, explanatory variables are specified as random slopes
> within
> > herd (as recommended by Schielzeth & Forstmeier 2009; Year is also
> > specified as a random intercept).  Because there are only 21 herds,
> models
> > are fairly simple with only 2-3 explanatory variables (3 may by pushing
> > it...????). I can't post the data but it isn't really relevant to the
> > question (I think).
> >
> > Initially, we looked at AIC to compare models.  At the bottom of this
> > email, I have pasted the output from two models, each representing
> separate
> > hypotheses, to illustrate "the problem".  The first model yields an AIC
> > value of 2210.7. The second model yields an AIC of 2479.5. Using AIC,
> Model
> > 1 would be the "best" model. However, examining the parameter estimates
> > within each model makes me think twice about declaring  Model 1 (or the
> > hypothesis it represents) as the most parsimonious explanation for the
> > data. In Model 1, two of the thee fixed effects estimates have small
> effect
> > sizes and all estimates are "non-significant" (if one considers
> > p-values....). In Model 2, two of the three fixed effect estimates have
> > larger effect sizes are would be considered "significant.  Is this an
> > example of the difficulty in using AIC to compare non-nested mixed
> > models.....or am I missing something in my interpretation? I haven't come
> > across this type of result when model selecting among GLMs.
> >
> > Any suggestions on how best to compare competing hypotheses represented
> by
> > non-nested GLMMs? Should one just compare relative effect sizes of
> > parameter estimates among models?
> > Any help would be appreciated.
> >
> > Thanks,
> > Craig
> >
> > *Model 1:*
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['glmerMod']
> >  Family: binomial  ( logit )
> > Formula: (Calves/Cows) ~ spr.indvi.ab + green.rate.ab + trend + (1 |
> Year)
> > +      (spr.indvi.ab + green.rate.ab + trend | Herd)
> >    Data: bou.dat
> > Weights: Cows
> >
> >      *AIC  *    BIC   logLik deviance df.resid
> >   *2210.7*   2265.0  -1090.3   2180.7      262
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -3.8700 -1.0800 -0.1057  1.0405  6.8353
> >
> > Random effects:
> >  Groups Name          Variance Std.Dev. Corr
> >  Year   (Intercept)   0.10517  0.3243
> >  Herd   (Intercept)   0.29832  0.5462
> >         spr.indvi.ab  0.04331  0.2081    0.38
> >         green.rate.ab 0.03741  0.1934    0.68  0.62
> >         trend         0.62661  0.7916   -0.59  0.20 -0.46
> > Number of obs: 277, groups:  Year, 22; Herd, 21
> >
> > Fixed effects:
> >               Estimate Std. Error z value Pr(>|z|)
> > (Intercept)   -1.62160    0.15798 -10.265   <2e-16 ***
> > spr.indvi.ab   0.04019    0.09793   0.410    0.682
> > green.rate.ab  0.04704    0.05555   0.847    0.397
> > trend         -0.29676    0.23092  -1.285    0.199
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >             (Intr) spr.n. grn.r.
> > spr.indvi.b -0.113
> > green.rat.b  0.347  0.438
> > trend       -0.606  0.349 -0.200
> >
> > *Model 2:*
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['glmerMod']
> >  Family: binomial  ( logit )
> > Formula: (Calves/Cows) ~ win.bb + tot.sn.ybb + trend + (1 | Year) + (
> > win.bb
> > +      tot.sn.ybb | Herd)
> >    Data: bou.dat
> > Weights: Cows
> >
> >     * AIC*      BIC   logLik deviance df.resid
> >   *2479.5 *  2519.4  -1228.8   2457.5      266
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -4.5720 -1.1801 -0.1364  1.3704  8.3271
> >
> > Random effects:
> >  Groups Name        Variance Std.Dev. Corr
> >  Year   (Intercept) 0.10694  0.3270
> >  Herd   (Intercept) 0.13496  0.3674
> >         win.bb      0.05351  0.2313   -0.13
> >         tot.sn.ybb  0.06200  0.2490    0.23  0.34
> > Number of obs: 277, groups:  Year, 22; Herd, 21
> >
> > Fixed effects:
> >              Estimate Std. Error z value Pr(>|z|)
> > (Intercept) -1.851656   0.127702 -14.500  < 2e-16 ***
> > win.bb      -0.364019   0.101386  -3.590  0.00033 ***
> > tot.sn.ybb   0.275271   0.118111   2.331  0.01977 *
> > trend       -0.007568   0.115706  -0.065  0.94785
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >            (Intr) win.bb tt.sn.
> > win.bb      0.048
> > tot.sn.ybb  0.269  0.083
> > trend      -0.242 -0.269 -0.131
> > --
> > Craig DeMars, Ph.D.
> > Postdoctoral Fellow
> > Department of Biological Sciences
> > University of Alberta
> > Phone: 780-221-3971 <(780)%20221-3971> <(780)%20221-3971>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
Craig DeMars, Ph.D.
Postdoctoral Fellow
Department of Biological Sciences
University of Alberta
Phone: 780-221-3971

	[[alternative HTML version deleted]]


From ljrhurley at gmail.com  Mon Mar 27 16:36:35 2017
From: ljrhurley at gmail.com (landon hurley)
Date: Mon, 27 Mar 2017 10:36:35 -0400
Subject: [R-sig-ME] Advice on comparing non-nested random slope models
In-Reply-To: <CAM1YihBUvY=tipbPRkPDyZ0gN=0Ai9adNVHiNKn5tzG8y1fnNQ@mail.gmail.com>
References: <CAM1YihA=ej7EU+XpXFQjQT3yPoRLKuaUKz3SaMvR12nvXAsH=A@mail.gmail.com>
	<CAGoSky-Qojdc8rAi0qp59Z3D4cDhkS3L+_eD5RevZLkyw5u1Lw@mail.gmail.com>
	<CAFW8Byp0Dfsn8a+gdeu0Gi5a=y3tuNZdAXrocBuQEdVMSogU3A@mail.gmail.com>
	<CAM1YihBUvY=tipbPRkPDyZ0gN=0Ai9adNVHiNKn5tzG8y1fnNQ@mail.gmail.com>
Message-ID: <f338c3c1-8183-e350-e159-f26aba867e44@gmail.com>

On 3/27/17 10:16 AM, Craig DeMars wrote:
> Thanks. Unfortunately, it doesn't look like the Vuong test has been
> implemented for mixed models yet, at least not in R.....
> 

Craig, you might want to follow up with [0] to see if there was any
advancement if you haven't already.

[0] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024104.html



> On Mon, Mar 27, 2017 at 4:36 AM, Poe, John <jdpo223 at g.uky.edu> wrote:
> 
>> You might try a Vuong test. It's a likelihood ratio test that allows for
>> nonnested models.
>>
>>
>> On Mar 26, 2017 8:30 PM, "Paul Buerkner" <paul.buerkner at gmail.com> wrote:
>>
>> Hi Craig,
>>
>> in short, significance does not tell you anything about model fit. You may
>> find models to have the best fit without any particular predictor being
>> significant for this model. Similarily average "effect sizes" are not a
>> good indicator of model fit.
>>
>> Information criteria are, in my opinion, the right way to go. For an
>> improved version of the AIC, I recommend going Bayesian and computing the
>> so called LOO (leave-one-out cross validation) or the WAIC (widely
>> applicable information criterion) as implemented in the R package loo. For
>> the bayesian GLMM model fitting (and convenient LOO computation), you could
>> use the R packages brms or rstanarm.
>>
>> Best,
>> Paul
>>
>> 2017-03-26 22:15 GMT+02:00 Craig DeMars <cdemars at ualberta.ca>:
>>
>>> Hello,
>>>
>>> This is a bit of a follow-up to a question last week on selecting among
>>> GLMM models. Is there a recommended strategy for comparing non-nested,
>>> random slope models? I have seen a similar question posted here
>>> http://stats.stackexchange.com/questions/116935/comparing-non-nested-
>>> models-with-aic but it doesn't seem to answer the problem - and maybe
>>> there
>>> is no "answer".  Zuur et al. (2010) discuss model selection but only in a
>>> nested framework. Bolker et al. (2009) suggest AIC can be used in GLMMs
>> but
>>> caution against boundary issues and don't specifically mention any issues
>>> with comparing different random effects structures (as Zuur does).
>>>
>>> The context of my question comes from an analysis where we have 5 *a
>>> priori*
>>> hypotheses describing different climate effects on juvenile recruitment
>> in
>>> an ungulate species.  The data set has 21 populations (or herds) with
>>> repeated annual measurements of recruitment and the climate variables
>>> measured at the herd scale. To generate SE's that reflect herd as the
>>> sampling unit, explanatory variables are specified as random slopes
>> within
>>> herd (as recommended by Schielzeth & Forstmeier 2009; Year is also
>>> specified as a random intercept).  Because there are only 21 herds,
>> models
>>> are fairly simple with only 2-3 explanatory variables (3 may by pushing
>>> it...????). I can't post the data but it isn't really relevant to the
>>> question (I think).
>>>
>>> Initially, we looked at AIC to compare models.  At the bottom of this
>>> email, I have pasted the output from two models, each representing
>> separate
>>> hypotheses, to illustrate "the problem".  The first model yields an AIC
>>> value of 2210.7. The second model yields an AIC of 2479.5. Using AIC,
>> Model
>>> 1 would be the "best" model. However, examining the parameter estimates
>>> within each model makes me think twice about declaring  Model 1 (or the
>>> hypothesis it represents) as the most parsimonious explanation for the
>>> data. In Model 1, two of the thee fixed effects estimates have small
>> effect
>>> sizes and all estimates are "non-significant" (if one considers
>>> p-values....). In Model 2, two of the three fixed effect estimates have
>>> larger effect sizes are would be considered "significant.  Is this an
>>> example of the difficulty in using AIC to compare non-nested mixed
>>> models.....or am I missing something in my interpretation? I haven't come
>>> across this type of result when model selecting among GLMs.
>>>
>>> Any suggestions on how best to compare competing hypotheses represented
>> by
>>> non-nested GLMMs? Should one just compare relative effect sizes of
>>> parameter estimates among models?
>>> Any help would be appreciated.
>>>
>>> Thanks,
>>> Craig
>>>
>>> *Model 1:*
>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>> Approximation) ['glmerMod']
>>>  Family: binomial  ( logit )
>>> Formula: (Calves/Cows) ~ spr.indvi.ab + green.rate.ab + trend + (1 |
>> Year)
>>> +      (spr.indvi.ab + green.rate.ab + trend | Herd)
>>>    Data: bou.dat
>>> Weights: Cows
>>>
>>>      *AIC  *    BIC   logLik deviance df.resid
>>>   *2210.7*   2265.0  -1090.3   2180.7      262
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -3.8700 -1.0800 -0.1057  1.0405  6.8353
>>>
>>> Random effects:
>>>  Groups Name          Variance Std.Dev. Corr
>>>  Year   (Intercept)   0.10517  0.3243
>>>  Herd   (Intercept)   0.29832  0.5462
>>>         spr.indvi.ab  0.04331  0.2081    0.38
>>>         green.rate.ab 0.03741  0.1934    0.68  0.62
>>>         trend         0.62661  0.7916   -0.59  0.20 -0.46
>>> Number of obs: 277, groups:  Year, 22; Herd, 21
>>>
>>> Fixed effects:
>>>               Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)   -1.62160    0.15798 -10.265   <2e-16 ***
>>> spr.indvi.ab   0.04019    0.09793   0.410    0.682
>>> green.rate.ab  0.04704    0.05555   0.847    0.397
>>> trend         -0.29676    0.23092  -1.285    0.199
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>             (Intr) spr.n. grn.r.
>>> spr.indvi.b -0.113
>>> green.rat.b  0.347  0.438
>>> trend       -0.606  0.349 -0.200
>>>
>>> *Model 2:*
>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>> Approximation) ['glmerMod']
>>>  Family: binomial  ( logit )
>>> Formula: (Calves/Cows) ~ win.bb + tot.sn.ybb + trend + (1 | Year) + (
>>> win.bb
>>> +      tot.sn.ybb | Herd)
>>>    Data: bou.dat
>>> Weights: Cows
>>>
>>>     * AIC*      BIC   logLik deviance df.resid
>>>   *2479.5 *  2519.4  -1228.8   2457.5      266
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -4.5720 -1.1801 -0.1364  1.3704  8.3271
>>>
>>> Random effects:
>>>  Groups Name        Variance Std.Dev. Corr
>>>  Year   (Intercept) 0.10694  0.3270
>>>  Herd   (Intercept) 0.13496  0.3674
>>>         win.bb      0.05351  0.2313   -0.13
>>>         tot.sn.ybb  0.06200  0.2490    0.23  0.34
>>> Number of obs: 277, groups:  Year, 22; Herd, 21
>>>
>>> Fixed effects:
>>>              Estimate Std. Error z value Pr(>|z|)
>>> (Intercept) -1.851656   0.127702 -14.500  < 2e-16 ***
>>> win.bb      -0.364019   0.101386  -3.590  0.00033 ***
>>> tot.sn.ybb   0.275271   0.118111   2.331  0.01977 *
>>> trend       -0.007568   0.115706  -0.065  0.94785
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>            (Intr) win.bb tt.sn.
>>> win.bb      0.048
>>> tot.sn.ybb  0.269  0.083
>>> trend      -0.242 -0.269 -0.131
>>> --
>>> Craig DeMars, Ph.D.
>>> Postdoctoral Fellow
>>> Department of Biological Sciences
>>> University of Alberta
>>> Phone: 780-221-3971 <(780)%20221-3971> <(780)%20221-3971>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
> 
> 


-- 
Violence is the last refuge of the incompetent.


From bbolker at gmail.com  Mon Mar 27 19:40:43 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 27 Mar 2017 13:40:43 -0400
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
Message-ID: <cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>


 [please keep r-sig-mixed in Cc:]

  To repeat what I said below, the general brute-force strategy would be

N=2 (or 10 or something)
run MCMCglmm with some reasonably optimistic default settings such that
the final sample size (nitt-nburn)/thin is 1000
while (convergence not satisfactory)
    nitt = N*nitt
    thin = N* thin
    re-try MCMCglmm

This brute force strategy will fail if something is wrong with your
model (e.g. underdetermined).  Strengthening priors may help.  Other
than that, without more information, we really can't help you more.

On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
> Thank you for your reply.
> 
> I'm sorry if my subject mail or my question is not clear.
> Actually, i have understood that diagnostic convergence can use
> potential scale reduction, potential scale reduction factor, or use
> trace plot or another graphic  (i use potential scale reduction and
> trace plot). But, in MCMCglmm Tutorial that i read, if convergence
> hasn't reached, we can increase length of chain, or length of burn-in,
> or thinning interval. So, it is that i ask.
> Oh yes, i also have apply raftery.diag(). The output show sample size
> that i need. So, i combine chain length, burn-in length, and thinning
> interval so that yield sample size like in that output. But, it is still
> doesn't convergence.
> 
> Regards
> 
> Pada tanggal 27 Mar 2017 21.16, "Ben Bolker" <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> menulis:
> 
>       We would probably need more information to help you.
>       Some quick thoughts:
> 
>     - MCMCglmm usually burns in very quickly.   I would guess that either
>     (1) your problem/data are really pathological; (2) you're confusing
>     "burn-in" with "mixing"; if your chain reaches the stationary state
>     quickly but samples it slowly, then you're having a burn-in rather
>     than a mixing problem.  In general PRSF is meant to diagnose
>     convergence, not just burn-in. (Although now that I read your
>     question, it sounds like it's only the title that's specific to
>     burn-in ...)
> 
>     - I think what most people do is brute-force (increase length of
>     chain, increasing thinning at the same time so that the number of
>     samples remains constant, until traceplots look OK/PRSF looks OK).
>     - setting more informative priors may be helpful/necessary
>     - the coda package has other diagnostics, in particular the
>     Raftery-Lewis (raftery.diag()), which is supposed to estimate the
>     chain length required for convergence.  You should be able to apply it
>     to the components of an MCMCglmm fit ($Sol, $VCV, etc.), which are
>     mcmc objects
> 
> 
> 
>     On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>     <aqmalsaepul at gmail.com <mailto:aqmalsaepul at gmail.com>> wrote:
>     > Hi,
>     >
>     > I stil try fit linear mixed model. I use Potencial Scale Reduction
>     (PSR) to
>     > check convergence. But, it still dosn't convergence. Is there any
>     function
>     > that can i use to determine length of chains, length of burn-in, or
>     > thinning interval?
>     >
>     > Thank you.
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>


From j.hadfield at ed.ac.uk  Mon Mar 27 20:18:38 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 27 Mar 2017 19:18:38 +0100
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
	<cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
Message-ID: <bd0a2cfc-f301-5218-4dc9-67ad5f01cb2d@ed.ac.uk>

Hi Euis,

In an earlier post you said you were fitting zero-inflated models 
(zipoisson)? Is it possible you

a) forgot to fix the non-identifiable residual variance for the 
zero-inflation process at some value (e.g. 1)?

b) that the data are not zero-inflated but just over-dispersed so the  
zero-inflation parameters are heading off towards -Infinity?

Cheers,

Jarrod



On 27/03/2017 18:40, Ben Bolker wrote:
>   [please keep r-sig-mixed in Cc:]
>
>    To repeat what I said below, the general brute-force strategy would be
>
> N=2 (or 10 or something)
> run MCMCglmm with some reasonably optimistic default settings such that
> the final sample size (nitt-nburn)/thin is 1000
> while (convergence not satisfactory)
>      nitt = N*nitt
>      thin = N* thin
>      re-try MCMCglmm
>
> This brute force strategy will fail if something is wrong with your
> model (e.g. underdetermined).  Strengthening priors may help.  Other
> than that, without more information, we really can't help you more.
>
> On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
>> Thank you for your reply.
>>
>> I'm sorry if my subject mail or my question is not clear.
>> Actually, i have understood that diagnostic convergence can use
>> potential scale reduction, potential scale reduction factor, or use
>> trace plot or another graphic  (i use potential scale reduction and
>> trace plot). But, in MCMCglmm Tutorial that i read, if convergence
>> hasn't reached, we can increase length of chain, or length of burn-in,
>> or thinning interval. So, it is that i ask.
>> Oh yes, i also have apply raftery.diag(). The output show sample size
>> that i need. So, i combine chain length, burn-in length, and thinning
>> interval so that yield sample size like in that output. But, it is still
>> doesn't convergence.
>>
>> Regards
>>
>> Pada tanggal 27 Mar 2017 21.16, "Ben Bolker" <bbolker at gmail.com
>> <mailto:bbolker at gmail.com>> menulis:
>>
>>        We would probably need more information to help you.
>>        Some quick thoughts:
>>
>>      - MCMCglmm usually burns in very quickly.   I would guess that either
>>      (1) your problem/data are really pathological; (2) you're confusing
>>      "burn-in" with "mixing"; if your chain reaches the stationary state
>>      quickly but samples it slowly, then you're having a burn-in rather
>>      than a mixing problem.  In general PRSF is meant to diagnose
>>      convergence, not just burn-in. (Although now that I read your
>>      question, it sounds like it's only the title that's specific to
>>      burn-in ...)
>>
>>      - I think what most people do is brute-force (increase length of
>>      chain, increasing thinning at the same time so that the number of
>>      samples remains constant, until traceplots look OK/PRSF looks OK).
>>      - setting more informative priors may be helpful/necessary
>>      - the coda package has other diagnostics, in particular the
>>      Raftery-Lewis (raftery.diag()), which is supposed to estimate the
>>      chain length required for convergence.  You should be able to apply it
>>      to the components of an MCMCglmm fit ($Sol, $VCV, etc.), which are
>>      mcmc objects
>>
>>
>>
>>      On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>>      <aqmalsaepul at gmail.com <mailto:aqmalsaepul at gmail.com>> wrote:
>>      > Hi,
>>      >
>>      > I stil try fit linear mixed model. I use Potencial Scale Reduction
>>      (PSR) to
>>      > check convergence. But, it still dosn't convergence. Is there any
>>      function
>>      > that can i use to determine length of chains, length of burn-in, or
>>      > thinning interval?
>>      >
>>      > Thank you.
>>      >
>>      >         [[alternative HTML version deleted]]
>>      >
>>      > _______________________________________________
>>      > R-sig-mixed-models at r-project.org
>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Mar 27 21:49:39 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 27 Mar 2017 20:49:39 +0100
Subject: [R-sig-ME] Binary response animal models in MCMCglmm
In-Reply-To: <00bb01d2a6b1$3104dc30$930e9490$@research.uwa.edu.au>
References: <00bb01d2a6b1$3104dc30$930e9490$@research.uwa.edu.au>
Message-ID: <1a92dddf-5c0d-a935-ae22-6ab972ab019a@ed.ac.uk>

Hi Jacob,

1/ I usually go for the posterior mode for variances in which the 
posteriors are strongly skewed.

2/ Compared to family="ordinal", the DIC in threshold models is a level 
closer to what most people are after. But its still a level to high - it 
is asking how well could we predict new observations associated with the 
particular random effects (breeding values in this case) we've happened 
to sample. I don't use DIC.

3/ Because you have V=diag(2) *and* fix=1 you are fixing the residual 
covariance matrix to an identity matrix. This might be OK if your two 
responses are a male and female trait and so each row only has one value 
and one NA? Even then this makes the algorithm pretty inefficient: 
better to have a single trait indexed by sex. The intersexual genetic 
correlation is then estimated using us(sex):animal.

If this isn't the case then fixing the residual covariance to zero will 
force some of the residual correlation into the genetic term. It is 
possible then to obtain an *estimate* of zero for the genetic 
correlation if the *true* genetic correlation is positive and the 
residual covariance negative.

Much more likely though is that the prior you use is strongly 
constraining the genetic correlation to zero. I guess your motivation 
for using it is that the marginal priors for each variance have nu=1000, 
and this is what Pierre de Villemereuil suggests for probit models in 
his MEE paper (i.e. tending towards a chi-square with 1df)? However, for 
bivariate models the marginal prior for the correlation is flat when 
nu=3 (and pushed outwards towards -1/1 when nu=2). With nu=1000 it is 
pushed inwards towards zero by quite  a bit.

4/ The scale in binary models is not identifiable and so absolute values 
of the genetic variance do not have a meaning outside of the context of 
the residual variance. I've tried to explain this in pictures in the 
supp materials to this paper:

http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12354/abstract

but not sure if it helps. The other way I try and explain it is that the 
residual variance is not identifiable (Section 2.6 of the course notes). 
If there are better ways of explaining it, it would be good to know!

Cheers,

Jarrod


On 27/03/2017 05:18, Jacob Berson wrote:
> Hi All
>
>   
>
> I have attempted to estimate the heritability of several binary traits, and
> test for genetic correlations both between two binary traits, as well as
> between a binary and a Gaussian trait, using the animal model in MCMCglmm.
>
>   
>
> Several issues have come up in my analysis that I'm hoping to get some help
> with.
>
>   
>
> For some traits the posterior distribution of my heritability estimate is
> very close to zero, resulting in a non-symmetric density plot (the left tail
> is essentially cut by the y-axis). With these distributions I get very
> different point estimates of heritability depending on if I use the
> posterior mean or posterior mode.
>
>   
>
> 1)      I've seen both the mean and mode used in the literature, does anyone
> have a view on which is the most appropriate in the above circumstance?
>
>   
>
> The abovementioned distributions suggest to me that there is little, if any,
> additive genetic variance present. However, for some traits the DIC value of
> a model with "animal" as a random effect is lower than the null model
> (though after reading
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html and
> switching from using family="ordinal" to family="threshold" the difference
> in DIC values was greatly reduced).
>
>   
>
> 2)      Are differences in DIC values an appropriate tool for testing model
> fit when the response is binary? If so, what level of difference is
> sufficient to reject the null model (I've seen both >5 and >10)?
>
>   
>
> I am getting a posterior distribution centred on zero when testing for
> intersexual genetic correlations between two binary traits. However, when I
> look at the data (for example using sire means) it seems to me that there is
> in fact a strong correlation and that my MCMCglmm results are not correct.
>
>   
>
> 3)      Am I trying to do the impossible, i.e., is it still recommended (as
> was the case a few years ago
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html) not to
> fit bivariate binary models in MCMCglmm, even when using family="threshold"?
>
>   
>
> Finally, as I understand it, it is not appropriate to report the estimates
> of the additive genetic variance from binary models because it depends on
> the residual variance (which I have fixed to 1).
>
>   
>
> 4)      Can anyone help a novice like me understand why heritability is more
> appropriate to report, even though it also incorporates the fixed residual
> variance?
>
>   
>
> Apologies for the length of this post - after much searching and reading I
> haven't been able to find solutions to these questions. Any advice on the
> above and/or feedback on my code below would be very much appreciated.
>
>   
>
> Jacob
>
>   
>
>   
>
> My code:
>
>   
>
> #Univariate models for binary traits
>
>   
>
> Prior0 <- list(R = list(V = 1, fix = 1))
>
>   
>
> Prior1 <- list(R = list(V = 1, fix = 1),
>
>                 G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0, alpha.V =
> 1)))
>
>   
>
> Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold", pedigree =
> Ped,
>
>                  prior = Prior0, data = Data, nitt = 1050000, burnin = 50000,
> thin = 500, verbose = FALSE)
>
>   
>
> Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family =
> "threshold", pedigree = Ped,
>
> prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin = 500,
> verbose = FALSE)
>
>   
>
> heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va [["VCV"]])
>
>   
>
>   
>
> #Genetic correlation between two binary traits (bin1 and bin2)
>
>   
>
> Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),
>
>                   G = list(G1 = list(V = diag(2), nu = 10001, alpha.mu =
> c(0,0), alpha.V = diag(2))))
>
>   
>
> Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random =
> ~us(trait):animal,
>
>       rcov = ~corg(trait):units, family = c("threshold", "threshold"),
> pedigree = Ped, prior = Prior1rG,
>
>       data = Data, nitt = 4050000, burnin = 50000, thin = 2000, verbose =
> FALSE)
>
>   
>
> Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] /
> sqrt(Bin.Bin.corr$VCV[,
>
> "traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
> "traitbin2:traitbin2.animal"])
>
>   
>
>   
>
> #Genetic correlations between a Gaussian (gau1) and a binary (bin2) trait
>
>   
>
> Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2),
>
>                   G = list(G1 = list(V = diag(2), nu = 2, alpha.mu = c(0,0),
> alpha.V = diag(2)*1000)))
>
>   
>
> Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random =
> ~us(trait):animal, rcov =
>
> ~us(trait):units, family = c("gaussian", "threshold"), pedigree = Ped,
>
>
> prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin = 500,
>
> verbose = FALSE)
>
>   
>
> Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] /
> sqrt(Gau.Bin.corr $VCV[, "trait
>
> gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
> "traitbin2:traitbin2.animal"])
>
>   
>
>   
>
>   
>
> Jacob Berson BSc (Hons), PhD Candidate
>
> Centre for Evolutionary Biology
>
>   
>
> School of Animal Biology (M092)
>
> University of Western Australia
>
> 35 Stirling Highway
>
> Crawley, WA, 6009
>
>   
>
> Tel: (+61 8) 6488 3425
>
>   
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From pierre.de.villemereuil at mailoo.org  Mon Mar 27 22:54:23 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Tue, 28 Mar 2017 09:54:23 +1300
Subject: [R-sig-ME] Binary response animal models in MCMCglmm
In-Reply-To: <1a92dddf-5c0d-a935-ae22-6ab972ab019a@ed.ac.uk>
References: <00bb01d2a6b1$3104dc30$930e9490$@research.uwa.edu.au>
	<1a92dddf-5c0d-a935-ae22-6ab972ab019a@ed.ac.uk>
Message-ID: <2128458.8BLEj2G8xN@vercors>

Hi Jacob, hi Jarrod,

A bit ago, I wrote a script for a friend to view the priors for multi-response models when one response is binary (hence with fixed residual variance). I decided to share it on GitHub, see here:
https://github.com/devillemereuil/prior-MCMCglmm

It will help you Jacob to see what Jarrod is meaning about priors I think. It might be useful to even more people.

Cheers,
Pierre.

On Monday, 27 March 2017 20:49:39 NZDT Jarrod Hadfield wrote:
> Hi Jacob,
> 
> 1/ I usually go for the posterior mode for variances in which the 
> posteriors are strongly skewed.
> 
> 2/ Compared to family="ordinal", the DIC in threshold models is a level 
> closer to what most people are after. But its still a level to high - it 
> is asking how well could we predict new observations associated with the 
> particular random effects (breeding values in this case) we've happened 
> to sample. I don't use DIC.
> 
> 3/ Because you have V=diag(2) *and* fix=1 you are fixing the residual 
> covariance matrix to an identity matrix. This might be OK if your two 
> responses are a male and female trait and so each row only has one value 
> and one NA? Even then this makes the algorithm pretty inefficient: 
> better to have a single trait indexed by sex. The intersexual genetic 
> correlation is then estimated using us(sex):animal.
> 
> If this isn't the case then fixing the residual covariance to zero will 
> force some of the residual correlation into the genetic term. It is 
> possible then to obtain an *estimate* of zero for the genetic 
> correlation if the *true* genetic correlation is positive and the 
> residual covariance negative.
> 
> Much more likely though is that the prior you use is strongly 
> constraining the genetic correlation to zero. I guess your motivation 
> for using it is that the marginal priors for each variance have nu=1000, 
> and this is what Pierre de Villemereuil suggests for probit models in 
> his MEE paper (i.e. tending towards a chi-square with 1df)? However, for 
> bivariate models the marginal prior for the correlation is flat when 
> nu=3 (and pushed outwards towards -1/1 when nu=2). With nu=1000 it is 
> pushed inwards towards zero by quite  a bit.
> 
> 4/ The scale in binary models is not identifiable and so absolute values 
> of the genetic variance do not have a meaning outside of the context of 
> the residual variance. I've tried to explain this in pictures in the 
> supp materials to this paper:
> 
> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12354/abstract
> 
> but not sure if it helps. The other way I try and explain it is that the 
> residual variance is not identifiable (Section 2.6 of the course notes). 
> If there are better ways of explaining it, it would be good to know!
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 27/03/2017 05:18, Jacob Berson wrote:
> > Hi All
> >
> >   
> >
> > I have attempted to estimate the heritability of several binary traits, and
> > test for genetic correlations both between two binary traits, as well as
> > between a binary and a Gaussian trait, using the animal model in MCMCglmm.
> >
> >   
> >
> > Several issues have come up in my analysis that I'm hoping to get some help
> > with.
> >
> >   
> >
> > For some traits the posterior distribution of my heritability estimate is
> > very close to zero, resulting in a non-symmetric density plot (the left tail
> > is essentially cut by the y-axis). With these distributions I get very
> > different point estimates of heritability depending on if I use the
> > posterior mean or posterior mode.
> >
> >   
> >
> > 1)      I've seen both the mean and mode used in the literature, does anyone
> > have a view on which is the most appropriate in the above circumstance?
> >
> >   
> >
> > The abovementioned distributions suggest to me that there is little, if any,
> > additive genetic variance present. However, for some traits the DIC value of
> > a model with "animal" as a random effect is lower than the null model
> > (though after reading
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html and
> > switching from using family="ordinal" to family="threshold" the difference
> > in DIC values was greatly reduced).
> >
> >   
> >
> > 2)      Are differences in DIC values an appropriate tool for testing model
> > fit when the response is binary? If so, what level of difference is
> > sufficient to reject the null model (I've seen both >5 and >10)?
> >
> >   
> >
> > I am getting a posterior distribution centred on zero when testing for
> > intersexual genetic correlations between two binary traits. However, when I
> > look at the data (for example using sire means) it seems to me that there is
> > in fact a strong correlation and that my MCMCglmm results are not correct.
> >
> >   
> >
> > 3)      Am I trying to do the impossible, i.e., is it still recommended (as
> > was the case a few years ago
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html) not to
> > fit bivariate binary models in MCMCglmm, even when using family="threshold"?
> >
> >   
> >
> > Finally, as I understand it, it is not appropriate to report the estimates
> > of the additive genetic variance from binary models because it depends on
> > the residual variance (which I have fixed to 1).
> >
> >   
> >
> > 4)      Can anyone help a novice like me understand why heritability is more
> > appropriate to report, even though it also incorporates the fixed residual
> > variance?
> >
> >   
> >
> > Apologies for the length of this post - after much searching and reading I
> > haven't been able to find solutions to these questions. Any advice on the
> > above and/or feedback on my code below would be very much appreciated.
> >
> >   
> >
> > Jacob
> >
> >   
> >
> >   
> >
> > My code:
> >
> >   
> >
> > #Univariate models for binary traits
> >
> >   
> >
> > Prior0 <- list(R = list(V = 1, fix = 1))
> >
> >   
> >
> > Prior1 <- list(R = list(V = 1, fix = 1),
> >
> >                 G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0, alpha.V =
> > 1)))
> >
> >   
> >
> > Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold", pedigree =
> > Ped,
> >
> >                  prior = Prior0, data = Data, nitt = 1050000, burnin = 50000,
> > thin = 500, verbose = FALSE)
> >
> >   
> >
> > Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family =
> > "threshold", pedigree = Ped,
> >
> > prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin = 500,
> > verbose = FALSE)
> >
> >   
> >
> > heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va [["VCV"]])
> >
> >   
> >
> >   
> >
> > #Genetic correlation between two binary traits (bin1 and bin2)
> >
> >   
> >
> > Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 10001, alpha.mu =
> > c(0,0), alpha.V = diag(2))))
> >
> >   
> >
> > Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random =
> > ~us(trait):animal,
> >
> >       rcov = ~corg(trait):units, family = c("threshold", "threshold"),
> > pedigree = Ped, prior = Prior1rG,
> >
> >       data = Data, nitt = 4050000, burnin = 50000, thin = 2000, verbose =
> > FALSE)
> >
> >   
> >
> > Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] /
> > sqrt(Bin.Bin.corr$VCV[,
> >
> > "traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >   
> >
> >   
> >
> > #Genetic correlations between a Gaussian (gau1) and a binary (bin2) trait
> >
> >   
> >
> > Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 2, alpha.mu = c(0,0),
> > alpha.V = diag(2)*1000)))
> >
> >   
> >
> > Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random =
> > ~us(trait):animal, rcov =
> >
> > ~us(trait):units, family = c("gaussian", "threshold"), pedigree = Ped,
> >
> >
> > prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin = 500,
> >
> > verbose = FALSE)
> >
> >   
> >
> > Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] /
> > sqrt(Gau.Bin.corr $VCV[, "trait
> >
> > gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >   
> >
> >   
> >
> >   
> >
> > Jacob Berson BSc (Hons), PhD Candidate
> >
> > Centre for Evolutionary Biology
> >
> >   
> >
> > School of Animal Biology (M092)
> >
> > University of Western Australia
> >
> > 35 Stirling Highway
> >
> > Crawley, WA, 6009
> >
> >   
> >
> > Tel: (+61 8) 6488 3425
> >
> >   
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From jacob.berson at research.uwa.edu.au  Tue Mar 28 10:24:07 2017
From: jacob.berson at research.uwa.edu.au (Jacob Berson)
Date: Tue, 28 Mar 2017 16:24:07 +0800
Subject: [R-sig-ME] Binary response animal models in MCMCglmm
In-Reply-To: <2128458.8BLEj2G8xN@vercors>
References: <00bb01d2a6b1$3104dc30$930e9490$@research.uwa.edu.au>
	<1a92dddf-5c0d-a935-ae22-6ab972ab019a@ed.ac.uk>
	<2128458.8BLEj2G8xN@vercors>
Message-ID: <003b01d2a79c$ad6d3d80$0847b880$@research.uwa.edu.au>

Hi Jarrod and Pierre

Thank you both very much for your responses.

Pierre, that script is really useful - thanks for making it available.

Jarrod, your answers have been a great help. In regards to 3/, yes you are
correct that my two responses were male and female traits so each row only
had one value and one NA. And yes, my motivation for using that prior for
this model was an attempt at a bivariate form of the prior suggested in de
Villemereuil et al 2013. Both running the model with nu=3, and a different
model using us(sex):animal, have given me similar estimates which are much
closer to what I would expect.

As a follow up...

In the case of a genetic correlation between two binary traits where both
traits have been measured on the same individual (i.e. each row has a value
for both responses), is there a way of fixing both of the residual variances
but estimating the residual correlation? Am I right in my understanding of
below that using V=diag(2) and fix=1 should always be avoided in this
circumstance as it will bias the genetic correlation estimate in the
direction of the residual correlation?

Thanks again for the help, I really appreciate it.

Jacob

-----Original Message-----
From: Pierre de Villemereuil [mailto:pierre.de.villemereuil at mailoo.org] 
Sent: Tuesday, 28 March 2017 4:54 AM
To: r-sig-mixed-models at r-project.org; Jacob Berson
<jacob.berson at research.uwa.edu.au>
Subject: Re: [R-sig-ME] Binary response animal models in MCMCglmm

Hi Jacob, hi Jarrod,

A bit ago, I wrote a script for a friend to view the priors for
multi-response models when one response is binary (hence with fixed residual
variance). I decided to share it on GitHub, see here:
https://github.com/devillemereuil/prior-MCMCglmm

It will help you Jacob to see what Jarrod is meaning about priors I think.
It might be useful to even more people.

Cheers,
Pierre.

On Monday, 27 March 2017 20:49:39 NZDT Jarrod Hadfield wrote:
> Hi Jacob,
> 
> 1/ I usually go for the posterior mode for variances in which the 
> posteriors are strongly skewed.
> 
> 2/ Compared to family="ordinal", the DIC in threshold models is a 
> level closer to what most people are after. But its still a level to 
> high - it is asking how well could we predict new observations 
> associated with the particular random effects (breeding values in this 
> case) we've happened to sample. I don't use DIC.
> 
> 3/ Because you have V=diag(2) *and* fix=1 you are fixing the residual 
> covariance matrix to an identity matrix. This might be OK if your two 
> responses are a male and female trait and so each row only has one 
> value and one NA? Even then this makes the algorithm pretty inefficient:
> better to have a single trait indexed by sex. The intersexual genetic 
> correlation is then estimated using us(sex):animal.
> 
> If this isn't the case then fixing the residual covariance to zero 
> will force some of the residual correlation into the genetic term. It 
> is possible then to obtain an *estimate* of zero for the genetic 
> correlation if the *true* genetic correlation is positive and the 
> residual covariance negative.
> 
> Much more likely though is that the prior you use is strongly 
> constraining the genetic correlation to zero. I guess your motivation 
> for using it is that the marginal priors for each variance have 
> nu=1000, and this is what Pierre de Villemereuil suggests for probit 
> models in his MEE paper (i.e. tending towards a chi-square with 1df)? 
> However, for bivariate models the marginal prior for the correlation 
> is flat when
> nu=3 (and pushed outwards towards -1/1 when nu=2). With nu=1000 it is 
> pushed inwards towards zero by quite  a bit.
> 
> 4/ The scale in binary models is not identifiable and so absolute 
> values of the genetic variance do not have a meaning outside of the 
> context of the residual variance. I've tried to explain this in 
> pictures in the supp materials to this paper:
> 
> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12354/abstract
> 
> but not sure if it helps. The other way I try and explain it is that 
> the residual variance is not identifiable (Section 2.6 of the course
notes).
> If there are better ways of explaining it, it would be good to know!
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 27/03/2017 05:18, Jacob Berson wrote:
> > Hi All
> >
> >   
> >
> > I have attempted to estimate the heritability of several binary 
> > traits, and test for genetic correlations both between two binary 
> > traits, as well as between a binary and a Gaussian trait, using the
animal model in MCMCglmm.
> >
> >   
> >
> > Several issues have come up in my analysis that I'm hoping to get 
> > some help with.
> >
> >   
> >
> > For some traits the posterior distribution of my heritability 
> > estimate is very close to zero, resulting in a non-symmetric density 
> > plot (the left tail is essentially cut by the y-axis). With these 
> > distributions I get very different point estimates of heritability 
> > depending on if I use the posterior mean or posterior mode.
> >
> >   
> >
> > 1)      I've seen both the mean and mode used in the literature, does
anyone
> > have a view on which is the most appropriate in the above circumstance?
> >
> >   
> >
> > The abovementioned distributions suggest to me that there is little, 
> > if any, additive genetic variance present. However, for some traits 
> > the DIC value of a model with "animal" as a random effect is lower 
> > than the null model (though after reading 
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html 
> > and switching from using family="ordinal" to family="threshold" the 
> > difference in DIC values was greatly reduced).
> >
> >   
> >
> > 2)      Are differences in DIC values an appropriate tool for testing
model
> > fit when the response is binary? If so, what level of difference is 
> > sufficient to reject the null model (I've seen both >5 and >10)?
> >
> >   
> >
> > I am getting a posterior distribution centred on zero when testing 
> > for intersexual genetic correlations between two binary traits. 
> > However, when I look at the data (for example using sire means) it 
> > seems to me that there is in fact a strong correlation and that my
MCMCglmm results are not correct.
> >
> >   
> >
> > 3)      Am I trying to do the impossible, i.e., is it still recommended
(as
> > was the case a few years ago
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html
> > ) not to fit bivariate binary models in MCMCglmm, even when using
family="threshold"?
> >
> >   
> >
> > Finally, as I understand it, it is not appropriate to report the 
> > estimates of the additive genetic variance from binary models 
> > because it depends on the residual variance (which I have fixed to 1).
> >
> >   
> >
> > 4)      Can anyone help a novice like me understand why heritability is
more
> > appropriate to report, even though it also incorporates the fixed 
> > residual variance?
> >
> >   
> >
> > Apologies for the length of this post - after much searching and 
> > reading I haven't been able to find solutions to these questions. 
> > Any advice on the above and/or feedback on my code below would be very
much appreciated.
> >
> >   
> >
> > Jacob
> >
> >   
> >
> >   
> >
> > My code:
> >
> >   
> >
> > #Univariate models for binary traits
> >
> >   
> >
> > Prior0 <- list(R = list(V = 1, fix = 1))
> >
> >   
> >
> > Prior1 <- list(R = list(V = 1, fix = 1),
> >
> >                 G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0, 
> > alpha.V =
> > 1)))
> >
> >   
> >
> > Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold", 
> > pedigree = Ped,
> >
> >                  prior = Prior0, data = Data, nitt = 1050000, burnin 
> > = 50000, thin = 500, verbose = FALSE)
> >
> >   
> >
> > Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family = 
> > "threshold", pedigree = Ped,
> >
> > prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin = 
> > 500, verbose = FALSE)
> >
> >   
> >
> > heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va 
> > [["VCV"]])
> >
> >   
> >
> >   
> >
> > #Genetic correlation between two binary traits (bin1 and bin2)
> >
> >   
> >
> > Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 10001, 
> > alpha.mu = c(0,0), alpha.V = diag(2))))
> >
> >   
> >
> > Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random = 
> > ~us(trait):animal,
> >
> >       rcov = ~corg(trait):units, family = c("threshold", 
> > "threshold"), pedigree = Ped, prior = Prior1rG,
> >
> >       data = Data, nitt = 4050000, burnin = 50000, thin = 2000, 
> > verbose =
> > FALSE)
> >
> >   
> >
> > Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] / 
> > sqrt(Bin.Bin.corr$VCV[,
> >
> > "traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >   
> >
> >   
> >
> > #Genetic correlations between a Gaussian (gau1) and a binary (bin2) 
> > trait
> >
> >   
> >
> > Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 2, alpha.mu = 
> > c(0,0), alpha.V = diag(2)*1000)))
> >
> >   
> >
> > Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random = 
> > ~us(trait):animal, rcov =
> >
> > ~us(trait):units, family = c("gaussian", "threshold"), pedigree = 
> > Ped,
> >
> >
> > prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin 
> > = 500,
> >
> > verbose = FALSE)
> >
> >   
> >
> > Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] / 
> > sqrt(Gau.Bin.corr $VCV[, "trait
> >
> > gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >   
> >
> >   
> >
> >   
> >
> > Jacob Berson BSc (Hons), PhD Candidate
> >
> > Centre for Evolutionary Biology
> >
> >   
> >
> > School of Animal Biology (M092)
> >
> > University of Western Australia
> >
> > 35 Stirling Highway
> >
> > Crawley, WA, 6009
> >
> >   
> >
> > Tel: (+61 8) 6488 3425
> >
> >   
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From j.hadfield at ed.ac.uk  Tue Mar 28 10:30:43 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 28 Mar 2017 09:30:43 +0100
Subject: [R-sig-ME] Binary response animal models in MCMCglmm
In-Reply-To: <003b01d2a79c$ad6d3d80$0847b880$@research.uwa.edu.au>
References: <00bb01d2a6b1$3104dc30$930e9490$@research.uwa.edu.au>
	<1a92dddf-5c0d-a935-ae22-6ab972ab019a@ed.ac.uk>
	<2128458.8BLEj2G8xN@vercors>
	<003b01d2a79c$ad6d3d80$0847b880$@research.uwa.edu.au>
Message-ID: <37836e79-59d9-9f86-379b-7f0b0e2d1cd0@ed.ac.uk>

Hi Jacob,

Using rcov=~corg(trait):units constrains the residual variances to one 
but estimates the residual correlation. However, you shouldn't use fix 
in the prior.

Cheers,

Jarrod


On 28/03/2017 09:24, Jacob Berson wrote:
> Hi Jarrod and Pierre
>
> Thank you both very much for your responses.
>
> Pierre, that script is really useful - thanks for making it available.
>
> Jarrod, your answers have been a great help. In regards to 3/, yes you are
> correct that my two responses were male and female traits so each row only
> had one value and one NA. And yes, my motivation for using that prior for
> this model was an attempt at a bivariate form of the prior suggested in de
> Villemereuil et al 2013. Both running the model with nu=3, and a different
> model using us(sex):animal, have given me similar estimates which are much
> closer to what I would expect.
>
> As a follow up...
>
> In the case of a genetic correlation between two binary traits where both
> traits have been measured on the same individual (i.e. each row has a value
> for both responses), is there a way of fixing both of the residual variances
> but estimating the residual correlation? Am I right in my understanding of
> below that using V=diag(2) and fix=1 should always be avoided in this
> circumstance as it will bias the genetic correlation estimate in the
> direction of the residual correlation?
>
> Thanks again for the help, I really appreciate it.
>
> Jacob
>
> -----Original Message-----
> From: Pierre de Villemereuil [mailto:pierre.de.villemereuil at mailoo.org]
> Sent: Tuesday, 28 March 2017 4:54 AM
> To: r-sig-mixed-models at r-project.org; Jacob Berson
> <jacob.berson at research.uwa.edu.au>
> Subject: Re: [R-sig-ME] Binary response animal models in MCMCglmm
>
> Hi Jacob, hi Jarrod,
>
> A bit ago, I wrote a script for a friend to view the priors for
> multi-response models when one response is binary (hence with fixed residual
> variance). I decided to share it on GitHub, see here:
> https://github.com/devillemereuil/prior-MCMCglmm
>
> It will help you Jacob to see what Jarrod is meaning about priors I think.
> It might be useful to even more people.
>
> Cheers,
> Pierre.
>
> On Monday, 27 March 2017 20:49:39 NZDT Jarrod Hadfield wrote:
>> Hi Jacob,
>>
>> 1/ I usually go for the posterior mode for variances in which the
>> posteriors are strongly skewed.
>>
>> 2/ Compared to family="ordinal", the DIC in threshold models is a
>> level closer to what most people are after. But its still a level to
>> high - it is asking how well could we predict new observations
>> associated with the particular random effects (breeding values in this
>> case) we've happened to sample. I don't use DIC.
>>
>> 3/ Because you have V=diag(2) *and* fix=1 you are fixing the residual
>> covariance matrix to an identity matrix. This might be OK if your two
>> responses are a male and female trait and so each row only has one
>> value and one NA? Even then this makes the algorithm pretty inefficient:
>> better to have a single trait indexed by sex. The intersexual genetic
>> correlation is then estimated using us(sex):animal.
>>
>> If this isn't the case then fixing the residual covariance to zero
>> will force some of the residual correlation into the genetic term. It
>> is possible then to obtain an *estimate* of zero for the genetic
>> correlation if the *true* genetic correlation is positive and the
>> residual covariance negative.
>>
>> Much more likely though is that the prior you use is strongly
>> constraining the genetic correlation to zero. I guess your motivation
>> for using it is that the marginal priors for each variance have
>> nu=1000, and this is what Pierre de Villemereuil suggests for probit
>> models in his MEE paper (i.e. tending towards a chi-square with 1df)?
>> However, for bivariate models the marginal prior for the correlation
>> is flat when
>> nu=3 (and pushed outwards towards -1/1 when nu=2). With nu=1000 it is
>> pushed inwards towards zero by quite  a bit.
>>
>> 4/ The scale in binary models is not identifiable and so absolute
>> values of the genetic variance do not have a meaning outside of the
>> context of the residual variance. I've tried to explain this in
>> pictures in the supp materials to this paper:
>>
>> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12354/abstract
>>
>> but not sure if it helps. The other way I try and explain it is that
>> the residual variance is not identifiable (Section 2.6 of the course
> notes).
>> If there are better ways of explaining it, it would be good to know!
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> On 27/03/2017 05:18, Jacob Berson wrote:
>>> Hi All
>>>
>>>    
>>>
>>> I have attempted to estimate the heritability of several binary
>>> traits, and test for genetic correlations both between two binary
>>> traits, as well as between a binary and a Gaussian trait, using the
> animal model in MCMCglmm.
>>>    
>>>
>>> Several issues have come up in my analysis that I'm hoping to get
>>> some help with.
>>>
>>>    
>>>
>>> For some traits the posterior distribution of my heritability
>>> estimate is very close to zero, resulting in a non-symmetric density
>>> plot (the left tail is essentially cut by the y-axis). With these
>>> distributions I get very different point estimates of heritability
>>> depending on if I use the posterior mean or posterior mode.
>>>
>>>    
>>>
>>> 1)      I've seen both the mean and mode used in the literature, does
> anyone
>>> have a view on which is the most appropriate in the above circumstance?
>>>
>>>    
>>>
>>> The abovementioned distributions suggest to me that there is little,
>>> if any, additive genetic variance present. However, for some traits
>>> the DIC value of a model with "animal" as a random effect is lower
>>> than the null model (though after reading
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html
>>> and switching from using family="ordinal" to family="threshold" the
>>> difference in DIC values was greatly reduced).
>>>
>>>    
>>>
>>> 2)      Are differences in DIC values an appropriate tool for testing
> model
>>> fit when the response is binary? If so, what level of difference is
>>> sufficient to reject the null model (I've seen both >5 and >10)?
>>>
>>>    
>>>
>>> I am getting a posterior distribution centred on zero when testing
>>> for intersexual genetic correlations between two binary traits.
>>> However, when I look at the data (for example using sire means) it
>>> seems to me that there is in fact a strong correlation and that my
> MCMCglmm results are not correct.
>>>    
>>>
>>> 3)      Am I trying to do the impossible, i.e., is it still recommended
> (as
>>> was the case a few years ago
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html
>>> ) not to fit bivariate binary models in MCMCglmm, even when using
> family="threshold"?
>>>    
>>>
>>> Finally, as I understand it, it is not appropriate to report the
>>> estimates of the additive genetic variance from binary models
>>> because it depends on the residual variance (which I have fixed to 1).
>>>
>>>    
>>>
>>> 4)      Can anyone help a novice like me understand why heritability is
> more
>>> appropriate to report, even though it also incorporates the fixed
>>> residual variance?
>>>
>>>    
>>>
>>> Apologies for the length of this post - after much searching and
>>> reading I haven't been able to find solutions to these questions.
>>> Any advice on the above and/or feedback on my code below would be very
> much appreciated.
>>>    
>>>
>>> Jacob
>>>
>>>    
>>>
>>>    
>>>
>>> My code:
>>>
>>>    
>>>
>>> #Univariate models for binary traits
>>>
>>>    
>>>
>>> Prior0 <- list(R = list(V = 1, fix = 1))
>>>
>>>    
>>>
>>> Prior1 <- list(R = list(V = 1, fix = 1),
>>>
>>>                  G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0,
>>> alpha.V =
>>> 1)))
>>>
>>>    
>>>
>>> Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold",
>>> pedigree = Ped,
>>>
>>>                   prior = Prior0, data = Data, nitt = 1050000, burnin
>>> = 50000, thin = 500, verbose = FALSE)
>>>
>>>    
>>>
>>> Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family =
>>> "threshold", pedigree = Ped,
>>>
>>> prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin =
>>> 500, verbose = FALSE)
>>>
>>>    
>>>
>>> heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va
>>> [["VCV"]])
>>>
>>>    
>>>
>>>    
>>>
>>> #Genetic correlation between two binary traits (bin1 and bin2)
>>>
>>>    
>>>
>>> Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),
>>>
>>>                    G = list(G1 = list(V = diag(2), nu = 10001,
>>> alpha.mu = c(0,0), alpha.V = diag(2))))
>>>
>>>    
>>>
>>> Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random =
>>> ~us(trait):animal,
>>>
>>>        rcov = ~corg(trait):units, family = c("threshold",
>>> "threshold"), pedigree = Ped, prior = Prior1rG,
>>>
>>>        data = Data, nitt = 4050000, burnin = 50000, thin = 2000,
>>> verbose =
>>> FALSE)
>>>
>>>    
>>>
>>> Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] /
>>> sqrt(Bin.Bin.corr$VCV[,
>>>
>>> "traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
>>> "traitbin2:traitbin2.animal"])
>>>
>>>    
>>>
>>>    
>>>
>>> #Genetic correlations between a Gaussian (gau1) and a binary (bin2)
>>> trait
>>>
>>>    
>>>
>>> Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2),
>>>
>>>                    G = list(G1 = list(V = diag(2), nu = 2, alpha.mu =
>>> c(0,0), alpha.V = diag(2)*1000)))
>>>
>>>    
>>>
>>> Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random =
>>> ~us(trait):animal, rcov =
>>>
>>> ~us(trait):units, family = c("gaussian", "threshold"), pedigree =
>>> Ped,
>>>
>>>
>>> prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin
>>> = 500,
>>>
>>> verbose = FALSE)
>>>
>>>    
>>>
>>> Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] /
>>> sqrt(Gau.Bin.corr $VCV[, "trait
>>>
>>> gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
>>> "traitbin2:traitbin2.animal"])
>>>
>>>    
>>>
>>>    
>>>
>>>    
>>>
>>> Jacob Berson BSc (Hons), PhD Candidate
>>>
>>> Centre for Evolutionary Biology
>>>
>>>    
>>>
>>> School of Animal Biology (M092)
>>>
>>> University of Western Australia
>>>
>>> 35 Stirling Highway
>>>
>>> Crawley, WA, 6009
>>>
>>>    
>>>
>>> Tel: (+61 8) 6488 3425
>>>
>>>    
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From d.hartgerink at student.ru.nl  Tue Mar 28 10:51:04 2017
From: d.hartgerink at student.ru.nl (Hartgerink, D.M. (Marjolein))
Date: Tue, 28 Mar 2017 08:51:04 +0000
Subject: [R-sig-ME] Unsubscribe mailinglist
Message-ID: <6F5DD03F08766B4EADAE4A6DFC2DCA913D46B34B@exprd03.hosting.ru.nl>

Dear sir/madam,

I would like to be unsubscribed from this mailing list. 

Thank you in advance,

Marjolein Hartgerink
________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens r-sig-mixed-models-request at r-project.org [r-sig-mixed-models-request at r-project.org]
Verzonden: dinsdag 28 maart 2017 10:31
Aan: r-sig-mixed-models at r-project.org
Onderwerp: R-sig-mixed-models Digest, Vol 123, Issue 23

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: Binary response animal models in MCMCglmm
      (Pierre de Villemereuil)
   2. Re: Binary response animal models in MCMCglmm (Jacob Berson)
   3. Re: Binary response animal models in MCMCglmm (Jarrod Hadfield)


----------------------------------------------------------------------

Message: 1
Date: Tue, 28 Mar 2017 09:54:23 +1300
From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
To: r-sig-mixed-models at r-project.org,   Jacob Berson
        <jacob.berson at research.uwa.edu.au>
Subject: Re: [R-sig-ME] Binary response animal models in MCMCglmm
Message-ID: <2128458.8BLEj2G8xN at vercors>
Content-Type: text/plain; charset="us-ascii"

Hi Jacob, hi Jarrod,

A bit ago, I wrote a script for a friend to view the priors for multi-response models when one response is binary (hence with fixed residual variance). I decided to share it on GitHub, see here:
https://github.com/devillemereuil/prior-MCMCglmm

It will help you Jacob to see what Jarrod is meaning about priors I think. It might be useful to even more people.

Cheers,
Pierre.

On Monday, 27 March 2017 20:49:39 NZDT Jarrod Hadfield wrote:
> Hi Jacob,
>
> 1/ I usually go for the posterior mode for variances in which the
> posteriors are strongly skewed.
>
> 2/ Compared to family="ordinal", the DIC in threshold models is a level
> closer to what most people are after. But its still a level to high - it
> is asking how well could we predict new observations associated with the
> particular random effects (breeding values in this case) we've happened
> to sample. I don't use DIC.
>
> 3/ Because you have V=diag(2) *and* fix=1 you are fixing the residual
> covariance matrix to an identity matrix. This might be OK if your two
> responses are a male and female trait and so each row only has one value
> and one NA? Even then this makes the algorithm pretty inefficient:
> better to have a single trait indexed by sex. The intersexual genetic
> correlation is then estimated using us(sex):animal.
>
> If this isn't the case then fixing the residual covariance to zero will
> force some of the residual correlation into the genetic term. It is
> possible then to obtain an *estimate* of zero for the genetic
> correlation if the *true* genetic correlation is positive and the
> residual covariance negative.
>
> Much more likely though is that the prior you use is strongly
> constraining the genetic correlation to zero. I guess your motivation
> for using it is that the marginal priors for each variance have nu=1000,
> and this is what Pierre de Villemereuil suggests for probit models in
> his MEE paper (i.e. tending towards a chi-square with 1df)? However, for
> bivariate models the marginal prior for the correlation is flat when
> nu=3 (and pushed outwards towards -1/1 when nu=2). With nu=1000 it is
> pushed inwards towards zero by quite  a bit.
>
> 4/ The scale in binary models is not identifiable and so absolute values
> of the genetic variance do not have a meaning outside of the context of
> the residual variance. I've tried to explain this in pictures in the
> supp materials to this paper:
>
> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12354/abstract
>
> but not sure if it helps. The other way I try and explain it is that the
> residual variance is not identifiable (Section 2.6 of the course notes).
> If there are better ways of explaining it, it would be good to know!
>
> Cheers,
>
> Jarrod
>
>
> On 27/03/2017 05:18, Jacob Berson wrote:
> > Hi All
> >
> >
> >
> > I have attempted to estimate the heritability of several binary traits, and
> > test for genetic correlations both between two binary traits, as well as
> > between a binary and a Gaussian trait, using the animal model in MCMCglmm.
> >
> >
> >
> > Several issues have come up in my analysis that I'm hoping to get some help
> > with.
> >
> >
> >
> > For some traits the posterior distribution of my heritability estimate is
> > very close to zero, resulting in a non-symmetric density plot (the left tail
> > is essentially cut by the y-axis). With these distributions I get very
> > different point estimates of heritability depending on if I use the
> > posterior mean or posterior mode.
> >
> >
> >
> > 1)      I've seen both the mean and mode used in the literature, does anyone
> > have a view on which is the most appropriate in the above circumstance?
> >
> >
> >
> > The abovementioned distributions suggest to me that there is little, if any,
> > additive genetic variance present. However, for some traits the DIC value of
> > a model with "animal" as a random effect is lower than the null model
> > (though after reading
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html and
> > switching from using family="ordinal" to family="threshold" the difference
> > in DIC values was greatly reduced).
> >
> >
> >
> > 2)      Are differences in DIC values an appropriate tool for testing model
> > fit when the response is binary? If so, what level of difference is
> > sufficient to reject the null model (I've seen both >5 and >10)?
> >
> >
> >
> > I am getting a posterior distribution centred on zero when testing for
> > intersexual genetic correlations between two binary traits. However, when I
> > look at the data (for example using sire means) it seems to me that there is
> > in fact a strong correlation and that my MCMCglmm results are not correct.
> >
> >
> >
> > 3)      Am I trying to do the impossible, i.e., is it still recommended (as
> > was the case a few years ago
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html) not to
> > fit bivariate binary models in MCMCglmm, even when using family="threshold"?
> >
> >
> >
> > Finally, as I understand it, it is not appropriate to report the estimates
> > of the additive genetic variance from binary models because it depends on
> > the residual variance (which I have fixed to 1).
> >
> >
> >
> > 4)      Can anyone help a novice like me understand why heritability is more
> > appropriate to report, even though it also incorporates the fixed residual
> > variance?
> >
> >
> >
> > Apologies for the length of this post - after much searching and reading I
> > haven't been able to find solutions to these questions. Any advice on the
> > above and/or feedback on my code below would be very much appreciated.
> >
> >
> >
> > Jacob
> >
> >
> >
> >
> >
> > My code:
> >
> >
> >
> > #Univariate models for binary traits
> >
> >
> >
> > Prior0 <- list(R = list(V = 1, fix = 1))
> >
> >
> >
> > Prior1 <- list(R = list(V = 1, fix = 1),
> >
> >                 G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0, alpha.V =
> > 1)))
> >
> >
> >
> > Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold", pedigree =
> > Ped,
> >
> >                  prior = Prior0, data = Data, nitt = 1050000, burnin = 50000,
> > thin = 500, verbose = FALSE)
> >
> >
> >
> > Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family =
> > "threshold", pedigree = Ped,
> >
> > prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin = 500,
> > verbose = FALSE)
> >
> >
> >
> > heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va [["VCV"]])
> >
> >
> >
> >
> >
> > #Genetic correlation between two binary traits (bin1 and bin2)
> >
> >
> >
> > Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 10001, alpha.mu =
> > c(0,0), alpha.V = diag(2))))
> >
> >
> >
> > Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random =
> > ~us(trait):animal,
> >
> >       rcov = ~corg(trait):units, family = c("threshold", "threshold"),
> > pedigree = Ped, prior = Prior1rG,
> >
> >       data = Data, nitt = 4050000, burnin = 50000, thin = 2000, verbose =
> > FALSE)
> >
> >
> >
> > Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] /
> > sqrt(Bin.Bin.corr$VCV[,
> >
> > "traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >
> >
> >
> >
> > #Genetic correlations between a Gaussian (gau1) and a binary (bin2) trait
> >
> >
> >
> > Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 2, alpha.mu = c(0,0),
> > alpha.V = diag(2)*1000)))
> >
> >
> >
> > Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random =
> > ~us(trait):animal, rcov =
> >
> > ~us(trait):units, family = c("gaussian", "threshold"), pedigree = Ped,
> >
> >
> > prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin = 500,
> >
> > verbose = FALSE)
> >
> >
> >
> > Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] /
> > sqrt(Gau.Bin.corr $VCV[, "trait
> >
> > gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >
> >
> >
> >
> >
> >
> > Jacob Berson BSc (Hons), PhD Candidate
> >
> > Centre for Evolutionary Biology
> >
> >
> >
> > School of Animal Biology (M092)
> >
> > University of Western Australia
> >
> > 35 Stirling Highway
> >
> > Crawley, WA, 6009
> >
> >
> >
> > Tel: (+61 8) 6488 3425
> >
> >
> >
> >
> >     [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



------------------------------

Message: 2
Date: Tue, 28 Mar 2017 16:24:07 +0800
From: "Jacob Berson" <jacob.berson at research.uwa.edu.au>
To: "'Jarrod Hadfield'" <j.hadfield at ed.ac.uk>,  "'Pierre de
        Villemereuil'" <pierre.de.villemereuil at mailoo.org>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Binary response animal models in MCMCglmm
Message-ID: <003b01d2a79c$ad6d3d80$0847b880$@research.uwa.edu.au>
Content-Type: text/plain;       charset="us-ascii"

Hi Jarrod and Pierre

Thank you both very much for your responses.

Pierre, that script is really useful - thanks for making it available.

Jarrod, your answers have been a great help. In regards to 3/, yes you are
correct that my two responses were male and female traits so each row only
had one value and one NA. And yes, my motivation for using that prior for
this model was an attempt at a bivariate form of the prior suggested in de
Villemereuil et al 2013. Both running the model with nu=3, and a different
model using us(sex):animal, have given me similar estimates which are much
closer to what I would expect.

As a follow up...

In the case of a genetic correlation between two binary traits where both
traits have been measured on the same individual (i.e. each row has a value
for both responses), is there a way of fixing both of the residual variances
but estimating the residual correlation? Am I right in my understanding of
below that using V=diag(2) and fix=1 should always be avoided in this
circumstance as it will bias the genetic correlation estimate in the
direction of the residual correlation?

Thanks again for the help, I really appreciate it.

Jacob

-----Original Message-----
From: Pierre de Villemereuil [mailto:pierre.de.villemereuil at mailoo.org]
Sent: Tuesday, 28 March 2017 4:54 AM
To: r-sig-mixed-models at r-project.org; Jacob Berson
<jacob.berson at research.uwa.edu.au>
Subject: Re: [R-sig-ME] Binary response animal models in MCMCglmm

Hi Jacob, hi Jarrod,

A bit ago, I wrote a script for a friend to view the priors for
multi-response models when one response is binary (hence with fixed residual
variance). I decided to share it on GitHub, see here:
https://github.com/devillemereuil/prior-MCMCglmm

It will help you Jacob to see what Jarrod is meaning about priors I think.
It might be useful to even more people.

Cheers,
Pierre.

On Monday, 27 March 2017 20:49:39 NZDT Jarrod Hadfield wrote:
> Hi Jacob,
>
> 1/ I usually go for the posterior mode for variances in which the
> posteriors are strongly skewed.
>
> 2/ Compared to family="ordinal", the DIC in threshold models is a
> level closer to what most people are after. But its still a level to
> high - it is asking how well could we predict new observations
> associated with the particular random effects (breeding values in this
> case) we've happened to sample. I don't use DIC.
>
> 3/ Because you have V=diag(2) *and* fix=1 you are fixing the residual
> covariance matrix to an identity matrix. This might be OK if your two
> responses are a male and female trait and so each row only has one
> value and one NA? Even then this makes the algorithm pretty inefficient:
> better to have a single trait indexed by sex. The intersexual genetic
> correlation is then estimated using us(sex):animal.
>
> If this isn't the case then fixing the residual covariance to zero
> will force some of the residual correlation into the genetic term. It
> is possible then to obtain an *estimate* of zero for the genetic
> correlation if the *true* genetic correlation is positive and the
> residual covariance negative.
>
> Much more likely though is that the prior you use is strongly
> constraining the genetic correlation to zero. I guess your motivation
> for using it is that the marginal priors for each variance have
> nu=1000, and this is what Pierre de Villemereuil suggests for probit
> models in his MEE paper (i.e. tending towards a chi-square with 1df)?
> However, for bivariate models the marginal prior for the correlation
> is flat when
> nu=3 (and pushed outwards towards -1/1 when nu=2). With nu=1000 it is
> pushed inwards towards zero by quite  a bit.
>
> 4/ The scale in binary models is not identifiable and so absolute
> values of the genetic variance do not have a meaning outside of the
> context of the residual variance. I've tried to explain this in
> pictures in the supp materials to this paper:
>
> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12354/abstract
>
> but not sure if it helps. The other way I try and explain it is that
> the residual variance is not identifiable (Section 2.6 of the course
notes).
> If there are better ways of explaining it, it would be good to know!
>
> Cheers,
>
> Jarrod
>
>
> On 27/03/2017 05:18, Jacob Berson wrote:
> > Hi All
> >
> >
> >
> > I have attempted to estimate the heritability of several binary
> > traits, and test for genetic correlations both between two binary
> > traits, as well as between a binary and a Gaussian trait, using the
animal model in MCMCglmm.
> >
> >
> >
> > Several issues have come up in my analysis that I'm hoping to get
> > some help with.
> >
> >
> >
> > For some traits the posterior distribution of my heritability
> > estimate is very close to zero, resulting in a non-symmetric density
> > plot (the left tail is essentially cut by the y-axis). With these
> > distributions I get very different point estimates of heritability
> > depending on if I use the posterior mean or posterior mode.
> >
> >
> >
> > 1)      I've seen both the mean and mode used in the literature, does
anyone
> > have a view on which is the most appropriate in the above circumstance?
> >
> >
> >
> > The abovementioned distributions suggest to me that there is little,
> > if any, additive genetic variance present. However, for some traits
> > the DIC value of a model with "animal" as a random effect is lower
> > than the null model (though after reading
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html
> > and switching from using family="ordinal" to family="threshold" the
> > difference in DIC values was greatly reduced).
> >
> >
> >
> > 2)      Are differences in DIC values an appropriate tool for testing
model
> > fit when the response is binary? If so, what level of difference is
> > sufficient to reject the null model (I've seen both >5 and >10)?
> >
> >
> >
> > I am getting a posterior distribution centred on zero when testing
> > for intersexual genetic correlations between two binary traits.
> > However, when I look at the data (for example using sire means) it
> > seems to me that there is in fact a strong correlation and that my
MCMCglmm results are not correct.
> >
> >
> >
> > 3)      Am I trying to do the impossible, i.e., is it still recommended
(as
> > was the case a few years ago
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html
> > ) not to fit bivariate binary models in MCMCglmm, even when using
family="threshold"?
> >
> >
> >
> > Finally, as I understand it, it is not appropriate to report the
> > estimates of the additive genetic variance from binary models
> > because it depends on the residual variance (which I have fixed to 1).
> >
> >
> >
> > 4)      Can anyone help a novice like me understand why heritability is
more
> > appropriate to report, even though it also incorporates the fixed
> > residual variance?
> >
> >
> >
> > Apologies for the length of this post - after much searching and
> > reading I haven't been able to find solutions to these questions.
> > Any advice on the above and/or feedback on my code below would be very
much appreciated.
> >
> >
> >
> > Jacob
> >
> >
> >
> >
> >
> > My code:
> >
> >
> >
> > #Univariate models for binary traits
> >
> >
> >
> > Prior0 <- list(R = list(V = 1, fix = 1))
> >
> >
> >
> > Prior1 <- list(R = list(V = 1, fix = 1),
> >
> >                 G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0,
> > alpha.V =
> > 1)))
> >
> >
> >
> > Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold",
> > pedigree = Ped,
> >
> >                  prior = Prior0, data = Data, nitt = 1050000, burnin
> > = 50000, thin = 500, verbose = FALSE)
> >
> >
> >
> > Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family =
> > "threshold", pedigree = Ped,
> >
> > prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin =
> > 500, verbose = FALSE)
> >
> >
> >
> > heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va
> > [["VCV"]])
> >
> >
> >
> >
> >
> > #Genetic correlation between two binary traits (bin1 and bin2)
> >
> >
> >
> > Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 10001,
> > alpha.mu = c(0,0), alpha.V = diag(2))))
> >
> >
> >
> > Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random =
> > ~us(trait):animal,
> >
> >       rcov = ~corg(trait):units, family = c("threshold",
> > "threshold"), pedigree = Ped, prior = Prior1rG,
> >
> >       data = Data, nitt = 4050000, burnin = 50000, thin = 2000,
> > verbose =
> > FALSE)
> >
> >
> >
> > Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] /
> > sqrt(Bin.Bin.corr$VCV[,
> >
> > "traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >
> >
> >
> >
> > #Genetic correlations between a Gaussian (gau1) and a binary (bin2)
> > trait
> >
> >
> >
> > Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2),
> >
> >                   G = list(G1 = list(V = diag(2), nu = 2, alpha.mu =
> > c(0,0), alpha.V = diag(2)*1000)))
> >
> >
> >
> > Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random =
> > ~us(trait):animal, rcov =
> >
> > ~us(trait):units, family = c("gaussian", "threshold"), pedigree =
> > Ped,
> >
> >
> > prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin
> > = 500,
> >
> > verbose = FALSE)
> >
> >
> >
> > Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] /
> > sqrt(Gau.Bin.corr $VCV[, "trait
> >
> > gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
> > "traitbin2:traitbin2.animal"])
> >
> >
> >
> >
> >
> >
> >
> > Jacob Berson BSc (Hons), PhD Candidate
> >
> > Centre for Evolutionary Biology
> >
> >
> >
> > School of Animal Biology (M092)
> >
> > University of Western Australia
> >
> > 35 Stirling Highway
> >
> > Crawley, WA, 6009
> >
> >
> >
> > Tel: (+61 8) 6488 3425
> >
> >
> >
> >
> >     [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



------------------------------

Message: 3
Date: Tue, 28 Mar 2017 09:30:43 +0100
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
To: Jacob Berson <jacob.berson at research.uwa.edu.au>, "'Pierre de
        Villemereuil'"  <pierre.de.villemereuil at mailoo.org>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Binary response animal models in MCMCglmm
Message-ID: <37836e79-59d9-9f86-379b-7f0b0e2d1cd0 at ed.ac.uk>
Content-Type: text/plain; charset="windows-1252"; format=flowed

Hi Jacob,

Using rcov=~corg(trait):units constrains the residual variances to one
but estimates the residual correlation. However, you shouldn't use fix
in the prior.

Cheers,

Jarrod


On 28/03/2017 09:24, Jacob Berson wrote:
> Hi Jarrod and Pierre
>
> Thank you both very much for your responses.
>
> Pierre, that script is really useful - thanks for making it available.
>
> Jarrod, your answers have been a great help. In regards to 3/, yes you are
> correct that my two responses were male and female traits so each row only
> had one value and one NA. And yes, my motivation for using that prior for
> this model was an attempt at a bivariate form of the prior suggested in de
> Villemereuil et al 2013. Both running the model with nu=3, and a different
> model using us(sex):animal, have given me similar estimates which are much
> closer to what I would expect.
>
> As a follow up...
>
> In the case of a genetic correlation between two binary traits where both
> traits have been measured on the same individual (i.e. each row has a value
> for both responses), is there a way of fixing both of the residual variances
> but estimating the residual correlation? Am I right in my understanding of
> below that using V=diag(2) and fix=1 should always be avoided in this
> circumstance as it will bias the genetic correlation estimate in the
> direction of the residual correlation?
>
> Thanks again for the help, I really appreciate it.
>
> Jacob
>
> -----Original Message-----
> From: Pierre de Villemereuil [mailto:pierre.de.villemereuil at mailoo.org]
> Sent: Tuesday, 28 March 2017 4:54 AM
> To: r-sig-mixed-models at r-project.org; Jacob Berson
> <jacob.berson at research.uwa.edu.au>
> Subject: Re: [R-sig-ME] Binary response animal models in MCMCglmm
>
> Hi Jacob, hi Jarrod,
>
> A bit ago, I wrote a script for a friend to view the priors for
> multi-response models when one response is binary (hence with fixed residual
> variance). I decided to share it on GitHub, see here:
> https://github.com/devillemereuil/prior-MCMCglmm
>
> It will help you Jacob to see what Jarrod is meaning about priors I think.
> It might be useful to even more people.
>
> Cheers,
> Pierre.
>
> On Monday, 27 March 2017 20:49:39 NZDT Jarrod Hadfield wrote:
>> Hi Jacob,
>>
>> 1/ I usually go for the posterior mode for variances in which the
>> posteriors are strongly skewed.
>>
>> 2/ Compared to family="ordinal", the DIC in threshold models is a
>> level closer to what most people are after. But its still a level to
>> high - it is asking how well could we predict new observations
>> associated with the particular random effects (breeding values in this
>> case) we've happened to sample. I don't use DIC.
>>
>> 3/ Because you have V=diag(2) *and* fix=1 you are fixing the residual
>> covariance matrix to an identity matrix. This might be OK if your two
>> responses are a male and female trait and so each row only has one
>> value and one NA? Even then this makes the algorithm pretty inefficient:
>> better to have a single trait indexed by sex. The intersexual genetic
>> correlation is then estimated using us(sex):animal.
>>
>> If this isn't the case then fixing the residual covariance to zero
>> will force some of the residual correlation into the genetic term. It
>> is possible then to obtain an *estimate* of zero for the genetic
>> correlation if the *true* genetic correlation is positive and the
>> residual covariance negative.
>>
>> Much more likely though is that the prior you use is strongly
>> constraining the genetic correlation to zero. I guess your motivation
>> for using it is that the marginal priors for each variance have
>> nu=1000, and this is what Pierre de Villemereuil suggests for probit
>> models in his MEE paper (i.e. tending towards a chi-square with 1df)?
>> However, for bivariate models the marginal prior for the correlation
>> is flat when
>> nu=3 (and pushed outwards towards -1/1 when nu=2). With nu=1000 it is
>> pushed inwards towards zero by quite  a bit.
>>
>> 4/ The scale in binary models is not identifiable and so absolute
>> values of the genetic variance do not have a meaning outside of the
>> context of the residual variance. I've tried to explain this in
>> pictures in the supp materials to this paper:
>>
>> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12354/abstract
>>
>> but not sure if it helps. The other way I try and explain it is that
>> the residual variance is not identifiable (Section 2.6 of the course
> notes).
>> If there are better ways of explaining it, it would be good to know!
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> On 27/03/2017 05:18, Jacob Berson wrote:
>>> Hi All
>>>
>>>
>>>
>>> I have attempted to estimate the heritability of several binary
>>> traits, and test for genetic correlations both between two binary
>>> traits, as well as between a binary and a Gaussian trait, using the
> animal model in MCMCglmm.
>>>
>>>
>>> Several issues have come up in my analysis that I'm hoping to get
>>> some help with.
>>>
>>>
>>>
>>> For some traits the posterior distribution of my heritability
>>> estimate is very close to zero, resulting in a non-symmetric density
>>> plot (the left tail is essentially cut by the y-axis). With these
>>> distributions I get very different point estimates of heritability
>>> depending on if I use the posterior mean or posterior mode.
>>>
>>>
>>>
>>> 1)      I've seen both the mean and mode used in the literature, does
> anyone
>>> have a view on which is the most appropriate in the above circumstance?
>>>
>>>
>>>
>>> The abovementioned distributions suggest to me that there is little,
>>> if any, additive genetic variance present. However, for some traits
>>> the DIC value of a model with "animal" as a random effect is lower
>>> than the null model (though after reading
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html
>>> and switching from using family="ordinal" to family="threshold" the
>>> difference in DIC values was greatly reduced).
>>>
>>>
>>>
>>> 2)      Are differences in DIC values an appropriate tool for testing
> model
>>> fit when the response is binary? If so, what level of difference is
>>> sufficient to reject the null model (I've seen both >5 and >10)?
>>>
>>>
>>>
>>> I am getting a posterior distribution centred on zero when testing
>>> for intersexual genetic correlations between two binary traits.
>>> However, when I look at the data (for example using sire means) it
>>> seems to me that there is in fact a strong correlation and that my
> MCMCglmm results are not correct.
>>>
>>>
>>> 3)      Am I trying to do the impossible, i.e., is it still recommended
> (as
>>> was the case a few years ago
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002637.html
>>> ) not to fit bivariate binary models in MCMCglmm, even when using
> family="threshold"?
>>>
>>>
>>> Finally, as I understand it, it is not appropriate to report the
>>> estimates of the additive genetic variance from binary models
>>> because it depends on the residual variance (which I have fixed to 1).
>>>
>>>
>>>
>>> 4)      Can anyone help a novice like me understand why heritability is
> more
>>> appropriate to report, even though it also incorporates the fixed
>>> residual variance?
>>>
>>>
>>>
>>> Apologies for the length of this post - after much searching and
>>> reading I haven't been able to find solutions to these questions.
>>> Any advice on the above and/or feedback on my code below would be very
> much appreciated.
>>>
>>>
>>> Jacob
>>>
>>>
>>>
>>>
>>>
>>> My code:
>>>
>>>
>>>
>>> #Univariate models for binary traits
>>>
>>>
>>>
>>> Prior0 <- list(R = list(V = 1, fix = 1))
>>>
>>>
>>>
>>> Prior1 <- list(R = list(V = 1, fix = 1),
>>>
>>>                  G = list(G1 = list(V = 1, nu = 1000, alpha.mu = 0,
>>> alpha.V =
>>> 1)))
>>>
>>>
>>>
>>> Binary.Null <- MCMCglmm(bin.response ~ 1, family = "threshold",
>>> pedigree = Ped,
>>>
>>>                   prior = Prior0, data = Data, nitt = 1050000, burnin
>>> = 50000, thin = 500, verbose = FALSE)
>>>
>>>
>>>
>>> Binary.Va <- MCMCglmm(bin.response ~ 1, random = ~animal, family =
>>> "threshold", pedigree = Ped,
>>>
>>> prior = Prior1, data = Data, nitt = 1050000, burnin = 50000, thin =
>>> 500, verbose = FALSE)
>>>
>>>
>>>
>>> heritability <- Binary.Va $VCV[,"animal"] / rowSums(Binary.Va
>>> [["VCV"]])
>>>
>>>
>>>
>>>
>>>
>>> #Genetic correlation between two binary traits (bin1 and bin2)
>>>
>>>
>>>
>>> Prior1rG <- list(R = list(V = diag(2), nu = 0, fix = 1),
>>>
>>>                    G = list(G1 = list(V = diag(2), nu = 10001,
>>> alpha.mu = c(0,0), alpha.V = diag(2))))
>>>
>>>
>>>
>>> Bin.Bin.corr <- MCMCglmm(cbind(bin1, bin2) ~ trait - 1, random =
>>> ~us(trait):animal,
>>>
>>>        rcov = ~corg(trait):units, family = c("threshold",
>>> "threshold"), pedigree = Ped, prior = Prior1rG,
>>>
>>>        data = Data, nitt = 4050000, burnin = 50000, thin = 2000,
>>> verbose =
>>> FALSE)
>>>
>>>
>>>
>>> Genetic_correlation1 <- Bin.Bin.corr $VCV[, "traitbin1:traitbin2"] /
>>> sqrt(Bin.Bin.corr$VCV[,
>>>
>>> "traitbin1:trait bin1.animal"] * Bin.Bin.corr $VCV[,
>>> "traitbin2:traitbin2.animal"])
>>>
>>>
>>>
>>>
>>>
>>> #Genetic correlations between a Gaussian (gau1) and a binary (bin2)
>>> trait
>>>
>>>
>>>
>>> Prior2rG <- list(R = list(V = diag(2), nu = 0, fix = 2),
>>>
>>>                    G = list(G1 = list(V = diag(2), nu = 2, alpha.mu =
>>> c(0,0), alpha.V = diag(2)*1000)))
>>>
>>>
>>>
>>> Gau.Bin.corr <- MCMCglmm(cbind(gau1, bin2) ~ trait - 1, random =
>>> ~us(trait):animal, rcov =
>>>
>>> ~us(trait):units, family = c("gaussian", "threshold"), pedigree =
>>> Ped,
>>>
>>>
>>> prior = Prior2rG, data = Data, nitt = 1050000, burnin = 50000, thin
>>> = 500,
>>>
>>> verbose = FALSE)
>>>
>>>
>>>
>>> Genetic_correlation2 <- Gau.Bin.corr$VCV[, "traitgau1:traitbin2"] /
>>> sqrt(Gau.Bin.corr $VCV[, "trait
>>>
>>> gau1:trait gau1.animal"] * Gau.Bin.corr $VCV[,
>>> "traitbin2:traitbin2.animal"])
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Jacob Berson BSc (Hons), PhD Candidate
>>>
>>> Centre for Evolutionary Biology
>>>
>>>
>>>
>>> School of Animal Biology (M092)
>>>
>>> University of Western Australia
>>>
>>> 35 Stirling Highway
>>>
>>> Crawley, WA, 6009
>>>
>>>
>>>
>>> Tel: (+61 8) 6488 3425
>>>
>>>
>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

------------------------------

End of R-sig-mixed-models Digest, Vol 123, Issue 23
***************************************************


From aqmalsaepul at gmail.com  Tue Mar 28 14:05:59 2017
From: aqmalsaepul at gmail.com (Euis Aqmaliyah)
Date: Tue, 28 Mar 2017 19:05:59 +0700
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <CAPFbjCaYKAE7-+QXpoestsV8k73OGsw=kVEuMq2qmZ-Ej3H7wg@mail.gmail.com>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
	<cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
	<CAPFbjCa-GHbxueSLy9+CriDQytJuHkMsDfORMvV4gAXqJkuPow@mail.gmail.com>
	<CAPFbjCaYKAE7-+QXpoestsV8k73OGsw=kVEuMq2qmZ-Ej3H7wg@mail.gmail.com>
Message-ID: <CAPFbjCZqyYFvrJA4+FdaiTsLPMpOSdpVUYvHYpk+DnNLi0Nd6A@mail.gmail.com>

Hi Ben,

Thank you for your advise.
I try to re-set specification prior that i use.

Pada tanggal 28 Mar 2017 00.40, "Ben Bolker" <bbolker at gmail.com> menulis:


 [please keep r-sig-mixed in Cc:]

  To repeat what I said below, the general brute-force strategy would be

N=2 (or 10 or something)
run MCMCglmm with some reasonably optimistic default settings such that
the final sample size (nitt-nburn)/thin is 1000
while (convergence not satisfactory)
    nitt = N*nitt
    thin = N* thin
    re-try MCMCglmm

This brute force strategy will fail if something is wrong with your
model (e.g. underdetermined).  Strengthening priors may help.  Other
than that, without more information, we really can't help you more.

On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
> Thank you for your reply.
>
> I'm sorry if my subject mail or my question is not clear.
> Actually, i have understood that diagnostic convergence can use
> potential scale reduction, potential scale reduction factor, or use
> trace plot or another graphic  (i use potential scale reduction and
> trace plot). But, in MCMCglmm Tutorial that i read, if convergence
> hasn't reached, we can increase length of chain, or length of burn-in,
> or thinning interval. So, it is that i ask.
> Oh yes, i also have apply raftery.diag(). The output show sample size
> that i need. So, i combine chain length, burn-in length, and thinning
> interval so that yield sample size like in that output. But, it is still
> doesn't convergence.
>
> Regards
>
> Pada tanggal 27 Mar 2017 21.16, "Ben Bolker" <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> menulis:
>
>       We would probably need more information to help you.
>       Some quick thoughts:
>
>     - MCMCglmm usually burns in very quickly.   I would guess that either
>     (1) your problem/data are really pathological; (2) you're confusing
>     "burn-in" with "mixing"; if your chain reaches the stationary state
>     quickly but samples it slowly, then you're having a burn-in rather
>     than a mixing problem.  In general PRSF is meant to diagnose
>     convergence, not just burn-in. (Although now that I read your
>     question, it sounds like it's only the title that's specific to
>     burn-in ...)
>
>     - I think what most people do is brute-force (increase length of
>     chain, increasing thinning at the same time so that the number of
>     samples remains constant, until traceplots look OK/PRSF looks OK).
>     - setting more informative priors may be helpful/necessary
>     - the coda package has other diagnostics, in particular the
>     Raftery-Lewis (raftery.diag()), which is supposed to estimate the
>     chain length required for convergence.  You should be able to apply it
>     to the components of an MCMCglmm fit ($Sol, $VCV, etc.), which are
>     mcmc objects
>
>
>
>     On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>     <aqmalsaepul at gmail.com <mailto:aqmalsaepul at gmail.com>> wrote:
>     > Hi,
>     >
>     > I stil try fit linear mixed model. I use Potencial Scale Reduction
>     (PSR) to
>     > check convergence. But, it still dosn't convergence. Is there any
>     function
>     > that can i use to determine length of chains, length of burn-in, or
>     > thinning interval?
>     >
>     > Thank you.
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>

	[[alternative HTML version deleted]]


From aqmalsaepul at gmail.com  Tue Mar 28 14:16:42 2017
From: aqmalsaepul at gmail.com (Euis Aqmaliyah)
Date: Tue, 28 Mar 2017 19:16:42 +0700
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <bd0a2cfc-f301-5218-4dc9-67ad5f01cb2d@ed.ac.uk>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
	<cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
	<bd0a2cfc-f301-5218-4dc9-67ad5f01cb2d@ed.ac.uk>
Message-ID: <CAPFbjCbQJ3rg2XYo5vzFdq2or9pfDnqQAzt+m64bcXN8PNOaAA@mail.gmail.com>

Hi Jarrod,

Zero-Inflated that i meant is not Zero-Inflated Poisson. It is follow a
semicontinuous distribution with a mixture
of zeros and continuously distributed positive values.
But, i have tried to set fix residual variance and the convergence has
reached in two model that i use.
Thank you for your advice.

Regards

Pada tanggal 28 Mar 2017 01.18, "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
menulis:

> Hi Euis,
>
> In an earlier post you said you were fitting zero-inflated models
> (zipoisson)? Is it possible you
>
> a) forgot to fix the non-identifiable residual variance for the
> zero-inflation process at some value (e.g. 1)?
>
> b) that the data are not zero-inflated but just over-dispersed so the
> zero-inflation parameters are heading off towards -Infinity?
>
> Cheers,
>
> Jarrod
>
>
>
> On 27/03/2017 18:40, Ben Bolker wrote:
>
>>   [please keep r-sig-mixed in Cc:]
>>
>>    To repeat what I said below, the general brute-force strategy would be
>>
>> N=2 (or 10 or something)
>> run MCMCglmm with some reasonably optimistic default settings such that
>> the final sample size (nitt-nburn)/thin is 1000
>> while (convergence not satisfactory)
>>      nitt = N*nitt
>>      thin = N* thin
>>      re-try MCMCglmm
>>
>> This brute force strategy will fail if something is wrong with your
>> model (e.g. underdetermined).  Strengthening priors may help.  Other
>> than that, without more information, we really can't help you more.
>>
>> On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
>>
>>> Thank you for your reply.
>>>
>>> I'm sorry if my subject mail or my question is not clear.
>>> Actually, i have understood that diagnostic convergence can use
>>> potential scale reduction, potential scale reduction factor, or use
>>> trace plot or another graphic  (i use potential scale reduction and
>>> trace plot). But, in MCMCglmm Tutorial that i read, if convergence
>>> hasn't reached, we can increase length of chain, or length of burn-in,
>>> or thinning interval. So, it is that i ask.
>>> Oh yes, i also have apply raftery.diag(). The output show sample size
>>> that i need. So, i combine chain length, burn-in length, and thinning
>>> interval so that yield sample size like in that output. But, it is still
>>> doesn't convergence.
>>>
>>> Regards
>>>
>>> Pada tanggal 27 Mar 2017 21.16, "Ben Bolker" <bbolker at gmail.com
>>> <mailto:bbolker at gmail.com>> menulis:
>>>
>>>        We would probably need more information to help you.
>>>        Some quick thoughts:
>>>
>>>      - MCMCglmm usually burns in very quickly.   I would guess that
>>> either
>>>      (1) your problem/data are really pathological; (2) you're confusing
>>>      "burn-in" with "mixing"; if your chain reaches the stationary state
>>>      quickly but samples it slowly, then you're having a burn-in rather
>>>      than a mixing problem.  In general PRSF is meant to diagnose
>>>      convergence, not just burn-in. (Although now that I read your
>>>      question, it sounds like it's only the title that's specific to
>>>      burn-in ...)
>>>
>>>      - I think what most people do is brute-force (increase length of
>>>      chain, increasing thinning at the same time so that the number of
>>>      samples remains constant, until traceplots look OK/PRSF looks OK).
>>>      - setting more informative priors may be helpful/necessary
>>>      - the coda package has other diagnostics, in particular the
>>>      Raftery-Lewis (raftery.diag()), which is supposed to estimate the
>>>      chain length required for convergence.  You should be able to apply
>>> it
>>>      to the components of an MCMCglmm fit ($Sol, $VCV, etc.), which are
>>>      mcmc objects
>>>
>>>
>>>
>>>      On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>>>      <aqmalsaepul at gmail.com <mailto:aqmalsaepul at gmail.com>> wrote:
>>>      > Hi,
>>>      >
>>>      > I stil try fit linear mixed model. I use Potencial Scale Reduction
>>>      (PSR) to
>>>      > check convergence. But, it still dosn't convergence. Is there any
>>>      function
>>>      > that can i use to determine length of chains, length of burn-in,
>>> or
>>>      > thinning interval?
>>>      >
>>>      > Thank you.
>>>      >
>>>      >         [[alternative HTML version deleted]]
>>>      >
>>>      > _______________________________________________
>>>      > R-sig-mixed-models at r-project.org
>>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Mar 28 14:20:53 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 28 Mar 2017 13:20:53 +0100
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <CAPFbjCbQJ3rg2XYo5vzFdq2or9pfDnqQAzt+m64bcXN8PNOaAA@mail.gmail.com>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
	<cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
	<bd0a2cfc-f301-5218-4dc9-67ad5f01cb2d@ed.ac.uk>
	<CAPFbjCbQJ3rg2XYo5vzFdq2or9pfDnqQAzt+m64bcXN8PNOaAA@mail.gmail.com>
Message-ID: <13e068bf-29f1-0a07-86e0-bba5dc1e623b@ed.ac.uk>

Hi,

If you are not explicitly fitting a zero-inflated model then my 
suggestions are not relevant, and you should not fix the residual 
variance. A description of your data and a post of your model syntax 
would help us diagnose the problem.

Cheers,

Jarrod



On 28/03/2017 13:16, Euis Aqmaliyah wrote:
> Hi Jarrod,
>
> Zero-Inflated that i meant is not Zero-Inflated Poisson. It is follow 
> a semicontinuous distribution with a mixture
> of zeros and continuously distributed positive values.
> But, i have tried to set fix residual variance and the convergence has 
> reached in two model that i use.
> Thank you for your advice.
>
> Regards
>
> Pada tanggal 28 Mar 2017 01.18, "Jarrod Hadfield" <j.hadfield at ed.ac.uk 
> <mailto:j.hadfield at ed.ac.uk>> menulis:
>
>     Hi Euis,
>
>     In an earlier post you said you were fitting zero-inflated models
>     (zipoisson)? Is it possible you
>
>     a) forgot to fix the non-identifiable residual variance for the
>     zero-inflation process at some value (e.g. 1)?
>
>     b) that the data are not zero-inflated but just over-dispersed so
>     the  zero-inflation parameters are heading off towards -Infinity?
>
>     Cheers,
>
>     Jarrod
>
>
>
>     On 27/03/2017 18:40, Ben Bolker wrote:
>
>           [please keep r-sig-mixed in Cc:]
>
>            To repeat what I said below, the general brute-force
>         strategy would be
>
>         N=2 (or 10 or something)
>         run MCMCglmm with some reasonably optimistic default settings
>         such that
>         the final sample size (nitt-nburn)/thin is 1000
>         while (convergence not satisfactory)
>              nitt = N*nitt
>              thin = N* thin
>              re-try MCMCglmm
>
>         This brute force strategy will fail if something is wrong with
>         your
>         model (e.g. underdetermined).  Strengthening priors may help. 
>         Other
>         than that, without more information, we really can't help you
>         more.
>
>         On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
>
>             Thank you for your reply.
>
>             I'm sorry if my subject mail or my question is not clear.
>             Actually, i have understood that diagnostic convergence
>             can use
>             potential scale reduction, potential scale reduction
>             factor, or use
>             trace plot or another graphic  (i use potential scale
>             reduction and
>             trace plot). But, in MCMCglmm Tutorial that i read, if
>             convergence
>             hasn't reached, we can increase length of chain, or length
>             of burn-in,
>             or thinning interval. So, it is that i ask.
>             Oh yes, i also have apply raftery.diag(). The output show
>             sample size
>             that i need. So, i combine chain length, burn-in length,
>             and thinning
>             interval so that yield sample size like in that output.
>             But, it is still
>             doesn't convergence.
>
>             Regards
>
>             Pada tanggal 27 Mar 2017 21.16, "Ben Bolker"
>             <bbolker at gmail.com <mailto:bbolker at gmail.com>
>             <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>>
>             menulis:
>
>                    We would probably need more information to help you.
>                    Some quick thoughts:
>
>                  - MCMCglmm usually burns in very quickly.   I would
>             guess that either
>                  (1) your problem/data are really pathological; (2)
>             you're confusing
>                  "burn-in" with "mixing"; if your chain reaches the
>             stationary state
>                  quickly but samples it slowly, then you're having a
>             burn-in rather
>                  than a mixing problem.  In general PRSF is meant to
>             diagnose
>                  convergence, not just burn-in. (Although now that I
>             read your
>                  question, it sounds like it's only the title that's
>             specific to
>                  burn-in ...)
>
>                  - I think what most people do is brute-force
>             (increase length of
>                  chain, increasing thinning at the same time so that
>             the number of
>                  samples remains constant, until traceplots look
>             OK/PRSF looks OK).
>                  - setting more informative priors may be
>             helpful/necessary
>                  - the coda package has other diagnostics, in
>             particular the
>                  Raftery-Lewis (raftery.diag()), which is supposed to
>             estimate the
>                  chain length required for convergence.  You should be
>             able to apply it
>                  to the components of an MCMCglmm fit ($Sol, $VCV,
>             etc.), which are
>                  mcmc objects
>
>
>
>                  On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>                  <aqmalsaepul at gmail.com <mailto:aqmalsaepul at gmail.com>
>             <mailto:aqmalsaepul at gmail.com
>             <mailto:aqmalsaepul at gmail.com>>> wrote:
>                  > Hi,
>                  >
>                  > I stil try fit linear mixed model. I use Potencial
>             Scale Reduction
>                  (PSR) to
>                  > check convergence. But, it still dosn't
>             convergence. Is there any
>                  function
>                  > that can i use to determine length of chains,
>             length of burn-in, or
>                  > thinning interval?
>                  >
>                  > Thank you.
>                  >
>                  >         [[alternative HTML version deleted]]
>                  >
>                  > _______________________________________________
>                  > R-sig-mixed-models at r-project.org
>             <mailto:R-sig-mixed-models at r-project.org>
>                  <mailto:R-sig-mixed-models at r-project.org
>             <mailto:R-sig-mixed-models at r-project.org>> mailing list
>                  >
>             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>             <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>                
>              <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>             <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>
>
>     -- 
>     The University of Edinburgh is a charitable body, registered in
>     Scotland, with registration number SC005336.
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170328/5372949d/attachment-0001.pl>

From aqmalsaepul at gmail.com  Tue Mar 28 14:34:18 2017
From: aqmalsaepul at gmail.com (Euis Aqmaliyah)
Date: Tue, 28 Mar 2017 19:34:18 +0700
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <13e068bf-29f1-0a07-86e0-bba5dc1e623b@ed.ac.uk>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
	<cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
	<bd0a2cfc-f301-5218-4dc9-67ad5f01cb2d@ed.ac.uk>
	<CAPFbjCbQJ3rg2XYo5vzFdq2or9pfDnqQAzt+m64bcXN8PNOaAA@mail.gmail.com>
	<13e068bf-29f1-0a07-86e0-bba5dc1e623b@ed.ac.uk>
Message-ID: <CAPFbjCYs5qHM2E2B=+oHcYfBJbkYnxhca8DUHfO+4-1MdNMs1Q@mail.gmail.com>

Dear Jarrod,

So, because my zero-inflated data is a mixture of zeros and continuosly
diatributed positive values, i use two models, there are linear mixed model
(LMM) for positive values and generalized linear mixed model (GLMM) with
logit as link function for probability of positive values.
In LMM, prior for residual variance that i set is R=list(V=1, nu=0) like
you said in my post a few days ago.
And then, in GLMM, i set fix residual variance.
Is it true?

Regards

Pada tanggal 28 Mar 2017 19.20, "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
menulis:

> Hi,
>
> If you are not explicitly fitting a zero-inflated model then my
> suggestions are not relevant, and you should not fix the residual variance.
> A description of your data and a post of your model syntax would help us
> diagnose the problem.
>
> Cheers,
>
> Jarrod
>
>
>
> On 28/03/2017 13:16, Euis Aqmaliyah wrote:
>
> Hi Jarrod,
>
> Zero-Inflated that i meant is not Zero-Inflated Poisson. It is follow a
> semicontinuous distribution with a mixture
> of zeros and continuously distributed positive values.
> But, i have tried to set fix residual variance and the convergence has
> reached in two model that i use.
> Thank you for your advice.
>
> Regards
>
> Pada tanggal 28 Mar 2017 01.18, "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
> menulis:
>
>> Hi Euis,
>>
>> In an earlier post you said you were fitting zero-inflated models
>> (zipoisson)? Is it possible you
>>
>> a) forgot to fix the non-identifiable residual variance for the
>> zero-inflation process at some value (e.g. 1)?
>>
>> b) that the data are not zero-inflated but just over-dispersed so the
>> zero-inflation parameters are heading off towards -Infinity?
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> On 27/03/2017 18:40, Ben Bolker wrote:
>>
>>>   [please keep r-sig-mixed in Cc:]
>>>
>>>    To repeat what I said below, the general brute-force strategy would be
>>>
>>> N=2 (or 10 or something)
>>> run MCMCglmm with some reasonably optimistic default settings such that
>>> the final sample size (nitt-nburn)/thin is 1000
>>> while (convergence not satisfactory)
>>>      nitt = N*nitt
>>>      thin = N* thin
>>>      re-try MCMCglmm
>>>
>>> This brute force strategy will fail if something is wrong with your
>>> model (e.g. underdetermined).  Strengthening priors may help.  Other
>>> than that, without more information, we really can't help you more.
>>>
>>> On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
>>>
>>>> Thank you for your reply.
>>>>
>>>> I'm sorry if my subject mail or my question is not clear.
>>>> Actually, i have understood that diagnostic convergence can use
>>>> potential scale reduction, potential scale reduction factor, or use
>>>> trace plot or another graphic  (i use potential scale reduction and
>>>> trace plot). But, in MCMCglmm Tutorial that i read, if convergence
>>>> hasn't reached, we can increase length of chain, or length of burn-in,
>>>> or thinning interval. So, it is that i ask.
>>>> Oh yes, i also have apply raftery.diag(). The output show sample size
>>>> that i need. So, i combine chain length, burn-in length, and thinning
>>>> interval so that yield sample size like in that output. But, it is still
>>>> doesn't convergence.
>>>>
>>>> Regards
>>>>
>>>> Pada tanggal 27 Mar 2017 21.16, "Ben Bolker" <bbolker at gmail.com
>>>> <mailto:bbolker at gmail.com>> menulis:
>>>>
>>>>        We would probably need more information to help you.
>>>>        Some quick thoughts:
>>>>
>>>>      - MCMCglmm usually burns in very quickly.   I would guess that
>>>> either
>>>>      (1) your problem/data are really pathological; (2) you're confusing
>>>>      "burn-in" with "mixing"; if your chain reaches the stationary state
>>>>      quickly but samples it slowly, then you're having a burn-in rather
>>>>      than a mixing problem.  In general PRSF is meant to diagnose
>>>>      convergence, not just burn-in. (Although now that I read your
>>>>      question, it sounds like it's only the title that's specific to
>>>>      burn-in ...)
>>>>
>>>>      - I think what most people do is brute-force (increase length of
>>>>      chain, increasing thinning at the same time so that the number of
>>>>      samples remains constant, until traceplots look OK/PRSF looks OK).
>>>>      - setting more informative priors may be helpful/necessary
>>>>      - the coda package has other diagnostics, in particular the
>>>>      Raftery-Lewis (raftery.diag()), which is supposed to estimate the
>>>>      chain length required for convergence.  You should be able to
>>>> apply it
>>>>      to the components of an MCMCglmm fit ($Sol, $VCV, etc.), which are
>>>>      mcmc objects
>>>>
>>>>
>>>>
>>>>      On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>>>>      <aqmalsaepul at gmail.com <mailto:aqmalsaepul at gmail.com>> wrote:
>>>>      > Hi,
>>>>      >
>>>>      > I stil try fit linear mixed model. I use Potencial Scale
>>>> Reduction
>>>>      (PSR) to
>>>>      > check convergence. But, it still dosn't convergence. Is there any
>>>>      function
>>>>      > that can i use to determine length of chains, length of burn-in,
>>>> or
>>>>      > thinning interval?
>>>>      >
>>>>      > Thank you.
>>>>      >
>>>>      >         [[alternative HTML version deleted]]
>>>>      >
>>>>      > _______________________________________________
>>>>      > R-sig-mixed-models at r-project.org
>>>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>
>>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Mar 28 14:38:51 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 28 Mar 2017 13:38:51 +0100
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <CAPFbjCYs5qHM2E2B=+oHcYfBJbkYnxhca8DUHfO+4-1MdNMs1Q@mail.gmail.com>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
	<cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
	<bd0a2cfc-f301-5218-4dc9-67ad5f01cb2d@ed.ac.uk>
	<CAPFbjCbQJ3rg2XYo5vzFdq2or9pfDnqQAzt+m64bcXN8PNOaAA@mail.gmail.com>
	<13e068bf-29f1-0a07-86e0-bba5dc1e623b@ed.ac.uk>
	<CAPFbjCYs5qHM2E2B=+oHcYfBJbkYnxhca8DUHfO+4-1MdNMs1Q@mail.gmail.com>
Message-ID: <4f9e5793-ce90-44c4-98c0-7ed0f60a622b@ed.ac.uk>

Hi,

Yes - for the binary model you should fix the residual variance.

Cheers,

Jarrod


On 28/03/2017 13:34, Euis Aqmaliyah wrote:
> Dear Jarrod,
>
> So, because my zero-inflated data is a mixture of zeros and 
> continuosly diatributed positive values, i use two models, there are 
> linear mixed model (LMM) for positive values and generalized linear 
> mixed model (GLMM) with logit as link function for probability of 
> positive values.
> In LMM, prior for residual variance that i set is R=list(V=1, nu=0) 
> like you said in my post a few days ago.
> And then, in GLMM, i set fix residual variance.
> Is it true?
>
> Regards
>
> Pada tanggal 28 Mar 2017 19.20, "Jarrod Hadfield" <j.hadfield at ed.ac.uk 
> <mailto:j.hadfield at ed.ac.uk>> menulis:
>
>     Hi,
>
>     If you are not explicitly fitting a zero-inflated model then my
>     suggestions are not relevant, and you should not fix the residual
>     variance. A description of your data and a post of your model
>     syntax would help us diagnose the problem.
>
>     Cheers,
>
>     Jarrod
>
>
>
>     On 28/03/2017 13:16, Euis Aqmaliyah wrote:
>>     Hi Jarrod,
>>
>>     Zero-Inflated that i meant is not Zero-Inflated Poisson. It is
>>     follow a semicontinuous distribution with a mixture
>>     of zeros and continuously distributed positive values.
>>     But, i have tried to set fix residual variance and the
>>     convergence has reached in two model that i use.
>>     Thank you for your advice.
>>
>>     Regards
>>
>>     Pada tanggal 28 Mar 2017 01.18, "Jarrod Hadfield"
>>     <j.hadfield at ed.ac.uk <mailto:j.hadfield at ed.ac.uk>> menulis:
>>
>>         Hi Euis,
>>
>>         In an earlier post you said you were fitting zero-inflated
>>         models (zipoisson)? Is it possible you
>>
>>         a) forgot to fix the non-identifiable residual variance for
>>         the zero-inflation process at some value (e.g. 1)?
>>
>>         b) that the data are not zero-inflated but just
>>         over-dispersed so the  zero-inflation parameters are heading
>>         off towards -Infinity?
>>
>>         Cheers,
>>
>>         Jarrod
>>
>>
>>
>>         On 27/03/2017 18:40, Ben Bolker wrote:
>>
>>               [please keep r-sig-mixed in Cc:]
>>
>>                To repeat what I said below, the general brute-force
>>             strategy would be
>>
>>             N=2 (or 10 or something)
>>             run MCMCglmm with some reasonably optimistic default
>>             settings such that
>>             the final sample size (nitt-nburn)/thin is 1000
>>             while (convergence not satisfactory)
>>                  nitt = N*nitt
>>                  thin = N* thin
>>                  re-try MCMCglmm
>>
>>             This brute force strategy will fail if something is wrong
>>             with your
>>             model (e.g. underdetermined).  Strengthening priors may
>>             help.  Other
>>             than that, without more information, we really can't help
>>             you more.
>>
>>             On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
>>
>>                 Thank you for your reply.
>>
>>                 I'm sorry if my subject mail or my question is not clear.
>>                 Actually, i have understood that diagnostic
>>                 convergence can use
>>                 potential scale reduction, potential scale reduction
>>                 factor, or use
>>                 trace plot or another graphic  (i use potential scale
>>                 reduction and
>>                 trace plot). But, in MCMCglmm Tutorial that i read,
>>                 if convergence
>>                 hasn't reached, we can increase length of chain, or
>>                 length of burn-in,
>>                 or thinning interval. So, it is that i ask.
>>                 Oh yes, i also have apply raftery.diag(). The output
>>                 show sample size
>>                 that i need. So, i combine chain length, burn-in
>>                 length, and thinning
>>                 interval so that yield sample size like in that
>>                 output. But, it is still
>>                 doesn't convergence.
>>
>>                 Regards
>>
>>                 Pada tanggal 27 Mar 2017 21.16, "Ben Bolker"
>>                 <bbolker at gmail.com <mailto:bbolker at gmail.com>
>>                 <mailto:bbolker at gmail.com
>>                 <mailto:bbolker at gmail.com>>> menulis:
>>
>>                        We would probably need more information to
>>                 help you.
>>                        Some quick thoughts:
>>
>>                      - MCMCglmm usually burns in very quickly.   I
>>                 would guess that either
>>                      (1) your problem/data are really pathological;
>>                 (2) you're confusing
>>                      "burn-in" with "mixing"; if your chain reaches
>>                 the stationary state
>>                      quickly but samples it slowly, then you're
>>                 having a burn-in rather
>>                      than a mixing problem.  In general PRSF is meant
>>                 to diagnose
>>                      convergence, not just burn-in. (Although now
>>                 that I read your
>>                      question, it sounds like it's only the title
>>                 that's specific to
>>                      burn-in ...)
>>
>>                      - I think what most people do is brute-force
>>                 (increase length of
>>                      chain, increasing thinning at the same time so
>>                 that the number of
>>                      samples remains constant, until traceplots look
>>                 OK/PRSF looks OK).
>>                      - setting more informative priors may be
>>                 helpful/necessary
>>                      - the coda package has other diagnostics, in
>>                 particular the
>>                      Raftery-Lewis (raftery.diag()), which is
>>                 supposed to estimate the
>>                      chain length required for convergence. You
>>                 should be able to apply it
>>                      to the components of an MCMCglmm fit ($Sol,
>>                 $VCV, etc.), which are
>>                      mcmc objects
>>
>>
>>
>>                      On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>>                      <aqmalsaepul at gmail.com
>>                 <mailto:aqmalsaepul at gmail.com>
>>                 <mailto:aqmalsaepul at gmail.com
>>                 <mailto:aqmalsaepul at gmail.com>>> wrote:
>>                      > Hi,
>>                      >
>>                      > I stil try fit linear mixed model. I use
>>                 Potencial Scale Reduction
>>                      (PSR) to
>>                      > check convergence. But, it still dosn't
>>                 convergence. Is there any
>>                      function
>>                      > that can i use to determine length of chains,
>>                 length of burn-in, or
>>                      > thinning interval?
>>                      >
>>                      > Thank you.
>>                      >
>>                      >         [[alternative HTML version deleted]]
>>                      >
>>                      > _______________________________________________
>>                      > R-sig-mixed-models at r-project.org
>>                 <mailto:R-sig-mixed-models at r-project.org>
>>                      <mailto:R-sig-mixed-models at r-project.org
>>                 <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>                      >
>>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>                    
>>                  <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>
>>             _______________________________________________
>>             R-sig-mixed-models at r-project.org
>>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>>             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>             <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>>
>>         -- 
>>         The University of Edinburgh is a charitable body, registered in
>>         Scotland, with registration number SC005336.
>>
>
>
>     The University of Edinburgh is a charitable body, registered in
>     Scotland, with registration number SC005336.
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170328/98beeb70/attachment-0001.pl>

From aqmalsaepul at gmail.com  Tue Mar 28 14:45:20 2017
From: aqmalsaepul at gmail.com (Euis Aqmaliyah)
Date: Tue, 28 Mar 2017 19:45:20 +0700
Subject: [R-sig-ME] How to determine the length of the required burn-in
 until convergence in MCMCglmm package or another package
In-Reply-To: <4f9e5793-ce90-44c4-98c0-7ed0f60a622b@ed.ac.uk>
References: <CAPFbjCYcACAfmbsWASvdUf1sjO-DgnxP6t27CFVaNky6fHSbaw@mail.gmail.com>
	<CAPFbjCYeBL+JdjvXJZrwE6+=L0pcUXMwXJ5gKZfTmS3opjBmoA@mail.gmail.com>
	<CAPFbjCY=ii13C4zcom1kW4RqbK+NJKKDeUJktRMcB5Xz0OECYw@mail.gmail.com>
	<CAPFbjCY_4eXKuo64YXyZL+DSNHYEv1=oYi=+EKF7LWoqVEJh_Q@mail.gmail.com>
	<CAPFbjCYt=_pjs2hN_xeyO2fU9ANefmnfeaSrk5+VQvLSJm6T5w@mail.gmail.com>
	<CAPFbjCby-rX4jeebYD4hiupkLJ6ckewzyUVyOM4BoFCn2ggy0w@mail.gmail.com>
	<CAPFbjCYwbk3o9P27dapomtFODuAvUnd7MoEzxZfZJgwzY-eY_Q@mail.gmail.com>
	<CABghstSdK9ak41Fk8W8EUH=zgOX60dtHr7_vMBk8w6YvqC6vVg@mail.gmail.com>
	<CAPFbjCZAcrtiZp-FpgfR9j7fiqvN7K7FeiQM-Y+uXnCb=ZLw6g@mail.gmail.com>
	<cedb2ebd-23ff-f5df-10c6-44e5a938bf01@gmail.com>
	<bd0a2cfc-f301-5218-4dc9-67ad5f01cb2d@ed.ac.uk>
	<CAPFbjCbQJ3rg2XYo5vzFdq2or9pfDnqQAzt+m64bcXN8PNOaAA@mail.gmail.com>
	<13e068bf-29f1-0a07-86e0-bba5dc1e623b@ed.ac.uk>
	<CAPFbjCYs5qHM2E2B=+oHcYfBJbkYnxhca8DUHfO+4-1MdNMs1Q@mail.gmail.com>
	<4f9e5793-ce90-44c4-98c0-7ed0f60a622b@ed.ac.uk>
Message-ID: <CAPFbjCacqRL_yktrLzHP1uEHCRvYixg+UOrXFbTfi=5unYtnjg@mail.gmail.com>

Okay.
Thank you Jarrod for your help.

Regards

Pada tanggal 28 Mar 2017 19.39, "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
menulis:

> Hi,
>
> Yes - for the binary model you should fix the residual variance.
>
> Cheers,
>
> Jarrod
>
> On 28/03/2017 13:34, Euis Aqmaliyah wrote:
>
> Dear Jarrod,
>
> So, because my zero-inflated data is a mixture of zeros and continuosly
> diatributed positive values, i use two models, there are linear mixed model
> (LMM) for positive values and generalized linear mixed model (GLMM) with
> logit as link function for probability of positive values.
> In LMM, prior for residual variance that i set is R=list(V=1, nu=0) like
> you said in my post a few days ago.
> And then, in GLMM, i set fix residual variance.
> Is it true?
>
> Regards
>
> Pada tanggal 28 Mar 2017 19.20, "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
> menulis:
>
>> Hi,
>>
>> If you are not explicitly fitting a zero-inflated model then my
>> suggestions are not relevant, and you should not fix the residual variance.
>> A description of your data and a post of your model syntax would help us
>> diagnose the problem.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> On 28/03/2017 13:16, Euis Aqmaliyah wrote:
>>
>> Hi Jarrod,
>>
>> Zero-Inflated that i meant is not Zero-Inflated Poisson. It is follow a
>> semicontinuous distribution with a mixture
>> of zeros and continuously distributed positive values.
>> But, i have tried to set fix residual variance and the convergence has
>> reached in two model that i use.
>> Thank you for your advice.
>>
>> Regards
>>
>> Pada tanggal 28 Mar 2017 01.18, "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
>> menulis:
>>
>>> Hi Euis,
>>>
>>> In an earlier post you said you were fitting zero-inflated models
>>> (zipoisson)? Is it possible you
>>>
>>> a) forgot to fix the non-identifiable residual variance for the
>>> zero-inflation process at some value (e.g. 1)?
>>>
>>> b) that the data are not zero-inflated but just over-dispersed so the
>>> zero-inflation parameters are heading off towards -Infinity?
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>> On 27/03/2017 18:40, Ben Bolker wrote:
>>>
>>>>   [please keep r-sig-mixed in Cc:]
>>>>
>>>>    To repeat what I said below, the general brute-force strategy would
>>>> be
>>>>
>>>> N=2 (or 10 or something)
>>>> run MCMCglmm with some reasonably optimistic default settings such that
>>>> the final sample size (nitt-nburn)/thin is 1000
>>>> while (convergence not satisfactory)
>>>>      nitt = N*nitt
>>>>      thin = N* thin
>>>>      re-try MCMCglmm
>>>>
>>>> This brute force strategy will fail if something is wrong with your
>>>> model (e.g. underdetermined).  Strengthening priors may help.  Other
>>>> than that, without more information, we really can't help you more.
>>>>
>>>> On 17-03-27 11:19 AM, Euis Aqmaliyah wrote:
>>>>
>>>>> Thank you for your reply.
>>>>>
>>>>> I'm sorry if my subject mail or my question is not clear.
>>>>> Actually, i have understood that diagnostic convergence can use
>>>>> potential scale reduction, potential scale reduction factor, or use
>>>>> trace plot or another graphic  (i use potential scale reduction and
>>>>> trace plot). But, in MCMCglmm Tutorial that i read, if convergence
>>>>> hasn't reached, we can increase length of chain, or length of burn-in,
>>>>> or thinning interval. So, it is that i ask.
>>>>> Oh yes, i also have apply raftery.diag(). The output show sample size
>>>>> that i need. So, i combine chain length, burn-in length, and thinning
>>>>> interval so that yield sample size like in that output. But, it is
>>>>> still
>>>>> doesn't convergence.
>>>>>
>>>>> Regards
>>>>>
>>>>> Pada tanggal 27 Mar 2017 21.16, "Ben Bolker" <bbolker at gmail.com
>>>>> <mailto:bbolker at gmail.com>> menulis:
>>>>>
>>>>>        We would probably need more information to help you.
>>>>>        Some quick thoughts:
>>>>>
>>>>>      - MCMCglmm usually burns in very quickly.   I would guess that
>>>>> either
>>>>>      (1) your problem/data are really pathological; (2) you're
>>>>> confusing
>>>>>      "burn-in" with "mixing"; if your chain reaches the stationary
>>>>> state
>>>>>      quickly but samples it slowly, then you're having a burn-in rather
>>>>>      than a mixing problem.  In general PRSF is meant to diagnose
>>>>>      convergence, not just burn-in. (Although now that I read your
>>>>>      question, it sounds like it's only the title that's specific to
>>>>>      burn-in ...)
>>>>>
>>>>>      - I think what most people do is brute-force (increase length of
>>>>>      chain, increasing thinning at the same time so that the number of
>>>>>      samples remains constant, until traceplots look OK/PRSF looks OK).
>>>>>      - setting more informative priors may be helpful/necessary
>>>>>      - the coda package has other diagnostics, in particular the
>>>>>      Raftery-Lewis (raftery.diag()), which is supposed to estimate the
>>>>>      chain length required for convergence.  You should be able to
>>>>> apply it
>>>>>      to the components of an MCMCglmm fit ($Sol, $VCV, etc.), which are
>>>>>      mcmc objects
>>>>>
>>>>>
>>>>>
>>>>>      On Mon, Mar 27, 2017 at 5:16 AM, Euis Aqmaliyah
>>>>>      <aqmalsaepul at gmail.com <mailto:aqmalsaepul at gmail.com>> wrote:
>>>>>      > Hi,
>>>>>      >
>>>>>      > I stil try fit linear mixed model. I use Potencial Scale
>>>>> Reduction
>>>>>      (PSR) to
>>>>>      > check convergence. But, it still dosn't convergence. Is there
>>>>> any
>>>>>      function
>>>>>      > that can i use to determine length of chains, length of
>>>>> burn-in, or
>>>>>      > thinning interval?
>>>>>      >
>>>>>      > Thank you.
>>>>>      >
>>>>>      >         [[alternative HTML version deleted]]
>>>>>      >
>>>>>      > _______________________________________________
>>>>>      > R-sig-mixed-models at r-project.org
>>>>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>
>>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>

	[[alternative HTML version deleted]]


From suzanne.lommen at unifr.ch  Tue Mar 28 16:39:56 2017
From: suzanne.lommen at unifr.ch (LOMMEN Suzanne)
Date: Tue, 28 Mar 2017 14:39:56 +0000
Subject: [R-sig-ME] How to vary residual variance with covariate and per
 factor in mcmcGLMM
Message-ID: <1490711997892.7364@unifr.ch>

Dear all,


I am grateful to the active community on this mailing list! Reading the posts already helped me solving many pRoblems.


I am quite new to mcmcGLMM and haven't managed to find out how to specify that the residual variance varies with explanatory factors AND a continuous covariate. I hope someone could advice me on the case below. My apologies for the long explanation.


I investigate how a herbivore treatment throughout the growing season ("treatment") affects individual plant size at the end of the season (log size2). The treatment was applied at 4 sites, and data were collected from ca 10 plants in each of ca 12 permanent subplots per site, in each of 3 years. The plant is an annual, so plants are only measured in 1 single year.

Because not all plants survived , the total number of datapoints is 843.



Other explanatory factors I included in my model are  "year" (3 levels), the continuous covariate plant size at the start of the season ("log size1"), the continuous covariate "baresoil" (as the fraction of soil not covered by vegetation in the subplot), and their interactions.

I also include the random factors "subplot" nested within "site" (although in mcmcGLMM it is not really nested, as I read in other posts).

(Note: I included "year" as a fixed effect and not as a random effect because plant growth and the treatment effect varied dramatically from year to year, and this is what I want to capture in my analysis.)


I am interested in the effect on mean plant size AND in the variance, because I will use these two parameters to model a probability density function of logsize2 given logsize1 for each of all treatment*year combinations (2 treatments * 3 years = 6 combinations).


I noticed that variance varies per treatment*year combination, and in some of these combinations it also decreases with an increase in the covariate logsize1. Therefore, I would like to specify the residual variance per treatment*year combination as a function of logsize1.


So far, I have specified the variance as a constant for each of the treamnet*year combinations:

rcov= ~idh(treatment*year):units,

and adjusted the prior accordingly:

R = list(V = diag(6), n = 0.002).


The complete model looks like this:
priorY1q1 = list(R = list(V = diag(6), n = 0.002),
                 G = list(G1 = list(V = 1, n = 0.002), G2 = list(V = 1, n = 0.002)))
modelY0bq1 <- MCMCglmm(logsize2 ~  logsize1 + treatment + baresoil + year +
                       treatment:logsize1 +  baresoil:logsize1+
                       year:treatment + year:logsize1 + year:baresoil +
                       year:treatment:logsize1 + year:baresoil:logsize1 ,
                     random = ~ site + subplot, family = "gaussian",
                     rcov= ~idh(treatment*year):units,
                     data =pd_grow, prior = priorY1q1, burnin = 5000, nitt = 805000, thin=200)


I would be very glad to get comments on

1. if this is correctly specified so far (the results seem to make sense)

2. how to specify that the variance ALSO varies with logsize1, but possibly in a different way for each treatment*year combination?

3. If there is  a risk to over-specify the variance this way?


Many thanks,


Kind regards,

Suzanne Lommen

PostDoc<http://www.unifr.ch/ecology/groupmueller/group/post-doctoral-associates/suzanne-lommen> in the Plant Population Biology group of Prof. Dr. Heinz M?ller-Sch?rer

Co-management of the EU-COST Action 'SMARTER<http://www.ragweed.eu/>': Sustainable management of Ambrosia artemisiifolia in Europe
Coordination of the SMARTER Task Force Population Dynamics <http://ragweed.eu/task-force-population-dynamics/>

Department of Biology/Ecology & Evolution
University of Fribourg/P?rolles
Chemin du Mus?e 10
CH-1700 Fribourg, SWITZERLAND
Tel: + (41) (0) 26-300 88 48 direct
Tel: + (41) (0) 26-300 88 50 secr.
Fax: + (41) (0) 26-300 9741




	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Mar 28 17:59:43 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 28 Mar 2017 16:59:43 +0100
Subject: [R-sig-ME] How to vary residual variance with covariate and per
 factor in mcmcGLMM
In-Reply-To: <1490711997892.7364@unifr.ch>
References: <1490711997892.7364@unifr.ch>
Message-ID: <4567f7ec-a829-9322-82fb-dcf93070b0fd@ed.ac.uk>

Hi,

1/ This is correct

2/ add idh(logsize1:treatment:year):units to the random effects. This 
gives 6 variances which we will call Vs1 ... Vs6 (s stands for slope) 
and these complement your 6 variances specified in rcov. We'll call 
these Vi1 ... Vi6 (s stands for intercept). The residual variance for 
the first treatment/year category (for example) at a specific value of 
logsize1 is then Vi1+Vs1*logsize1^2.

3/ You will find it hard to get precise estimates of these variance 
functions, and so if you can safely simplify it I would.

Cheers,

Jarrod



On 28/03/2017 15:39, LOMMEN Suzanne via R-sig-mixed-models wrote:
> Dear all,
>
>
> I am grateful to the active community on this mailing list! Reading the posts already helped me solving many pRoblems.
>
>
> I am quite new to mcmcGLMM and haven't managed to find out how to specify that the residual variance varies with explanatory factors AND a continuous covariate. I hope someone could advice me on the case below. My apologies for the long explanation.
>
>
> I investigate how a herbivore treatment throughout the growing season ("treatment") affects individual plant size at the end of the season (log size2). The treatment was applied at 4 sites, and data were collected from ca 10 plants in each of ca 12 permanent subplots per site, in each of 3 years. The plant is an annual, so plants are only measured in 1 single year.
>
> Because not all plants survived , the total number of datapoints is 843.
>
>
>
> Other explanatory factors I included in my model are  "year" (3 levels), the continuous covariate plant size at the start of the season ("log size1"), the continuous covariate "baresoil" (as the fraction of soil not covered by vegetation in the subplot), and their interactions.
>
> I also include the random factors "subplot" nested within "site" (although in mcmcGLMM it is not really nested, as I read in other posts).
>
> (Note: I included "year" as a fixed effect and not as a random effect because plant growth and the treatment effect varied dramatically from year to year, and this is what I want to capture in my analysis.)
>
>
> I am interested in the effect on mean plant size AND in the variance, because I will use these two parameters to model a probability density function of logsize2 given logsize1 for each of all treatment*year combinations (2 treatments * 3 years = 6 combinations).
>
>
> I noticed that variance varies per treatment*year combination, and in some of these combinations it also decreases with an increase in the covariate logsize1. Therefore, I would like to specify the residual variance per treatment*year combination as a function of logsize1.
>
>
> So far, I have specified the variance as a constant for each of the treamnet*year combinations:
>
> rcov= ~idh(treatment*year):units,
>
> and adjusted the prior accordingly:
>
> R = list(V = diag(6), n = 0.002).
>
>
> The complete model looks like this:
> priorY1q1 = list(R = list(V = diag(6), n = 0.002),
>                   G = list(G1 = list(V = 1, n = 0.002), G2 = list(V = 1, n = 0.002)))
> modelY0bq1 <- MCMCglmm(logsize2 ~  logsize1 + treatment + baresoil + year +
>                         treatment:logsize1 +  baresoil:logsize1+
>                         year:treatment + year:logsize1 + year:baresoil +
>                         year:treatment:logsize1 + year:baresoil:logsize1 ,
>                       random = ~ site + subplot, family = "gaussian",
>                       rcov= ~idh(treatment*year):units,
>                       data =pd_grow, prior = priorY1q1, burnin = 5000, nitt = 805000, thin=200)
>
>
> I would be very glad to get comments on
>
> 1. if this is correctly specified so far (the results seem to make sense)
>
> 2. how to specify that the variance ALSO varies with logsize1, but possibly in a different way for each treatment*year combination?
>
> 3. If there is  a risk to over-specify the variance this way?
>
>
> Many thanks,
>
>
> Kind regards,
>
> Suzanne Lommen
>
> PostDoc<http://www.unifr.ch/ecology/groupmueller/group/post-doctoral-associates/suzanne-lommen> in the Plant Population Biology group of Prof. Dr. Heinz M?ller-Sch?rer
>
> Co-management of the EU-COST Action 'SMARTER<http://www.ragweed.eu/>': Sustainable management of Ambrosia artemisiifolia in Europe
> Coordination of the SMARTER Task Force Population Dynamics <http://ragweed.eu/task-force-population-dynamics/>
>
> Department of Biology/Ecology & Evolution
> University of Fribourg/P?rolles
> Chemin du Mus?e 10
> CH-1700 Fribourg, SWITZERLAND
> Tel: + (41) (0) 26-300 88 48 direct
> Tel: + (41) (0) 26-300 88 50 secr.
> Fax: + (41) (0) 26-300 9741
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170328/53cb110d/attachment-0001.pl>

From asher.strauss at gmail.com  Wed Mar 29 10:39:46 2017
From: asher.strauss at gmail.com (Asher Strauss)
Date: Wed, 29 Mar 2017 11:39:46 +0300
Subject: [R-sig-ME] fixing the value of some parameters in an lme or lmer
	model
Message-ID: <CAJoaH8mohLwF7p+kc=O8eeom0OKM+pHZEkObUz9ria_fjkDW7Q@mail.gmail.com>

Dear list,

I am trying to fit a two level hierarchical model using the lme/lmer
function.
I have two levels in my data: 3 time points (codded: week 0, week 4, week
8) nested within subjects (ID). I would like to set the intercept of each
patient to the value of the outcome at week 0 (the first observation), or
in other words force the model fit for each subject to pass through the
subject's baseline score on the outcome variable.

Here are the formulas (in informal notation):

Level 1: (time)
outcome=b0+b1*week+error

Level 2: (subjects)
b0=*0*+*1**"outcome-at-time-0"
b1="grand-slope"+error

I underlined and made bold the values I would like to force.

Can this be done in nlme or lme4 packages?

Thank you very much!!!

Asher Strauss

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Mar 29 11:00:40 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 29 Mar 2017 11:00:40 +0200
Subject: [R-sig-ME] fixing the value of some parameters in an lme or
	lmer model
In-Reply-To: <CAJoaH8mohLwF7p+kc=O8eeom0OKM+pHZEkObUz9ria_fjkDW7Q@mail.gmail.com>
References: <CAJoaH8mohLwF7p+kc=O8eeom0OKM+pHZEkObUz9ria_fjkDW7Q@mail.gmail.com>
Message-ID: <CAJuCY5wJW5HR1XgURZTsdUCCH-1xMNq-OJ1jP13XwfZ5S=KtgA@mail.gmail.com>

Dear Asher,

You start from a model with this equation $y = \beta_0 + \beta_1 week
+ b_{i0} + b_{i1} week$
The fit of the baseline of each patient is $baseline_i = \beta_0 +
b_{i0}$ but you want $baseline_i = b_{i0}$ hence $\beta_0 = 0$
Forcing a parameter to be 1 can be done with offset(): $y = 0 +
\beta_1 week + offset(baseline_i) + b_{i1} week$

The lmer formula becomes y ~ offset(baseline) + week + (0 + week |
subject), assuming that the baseline has week = 0 and week is
continuous

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-29 10:39 GMT+02:00 Asher Strauss <asher.strauss at gmail.com>:
> Dear list,
>
> I am trying to fit a two level hierarchical model using the lme/lmer
> function.
> I have two levels in my data: 3 time points (codded: week 0, week 4, week
> 8) nested within subjects (ID). I would like to set the intercept of each
> patient to the value of the outcome at week 0 (the first observation), or
> in other words force the model fit for each subject to pass through the
> subject's baseline score on the outcome variable.
>
> Here are the formulas (in informal notation):
>
> Level 1: (time)
> outcome=b0+b1*week+error
>
> Level 2: (subjects)
> b0=*0*+*1**"outcome-at-time-0"
> b1="grand-slope"+error
>
> I underlined and made bold the values I would like to force.
>
> Can this be done in nlme or lme4 packages?
>
> Thank you very much!!!
>
> Asher Strauss
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Thu Mar 30 07:43:33 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 30 Mar 2017 06:43:33 +0100
Subject: [R-sig-ME] How to vary residual variance with covariate and per
 factor in mcmcGLMM
In-Reply-To: <1490818409566.78743@unifr.ch>
References: <1490711997892.7364@unifr.ch>
	<4567f7ec-a829-9322-82fb-dcf93070b0fd@ed.ac.uk>
	<1490818409566.78743@unifr.ch>
Message-ID: <280a6614-9a5b-577b-cc72-584e2971ce07@ed.ac.uk>

cc-ed back to the list...


DIC isn't meaningful in this context - I would ignore it.


My suggestion assumes that the variance increases to the square of the 
covariate. Sometimes people square-root the covariate (if it is 
positive) if they want a positive linear relationship. A negative 
relationship is more tricky. You could have 1/logsize1 but this is going 
to behave badly at values close to zero, or perhaps 1/size1 or 
1/sqrt(size1).


Cheers,


Jarrod


On 29/03/2017 21:13, LOMMEN Suzanne wrote:
>
>
> Dear Jarrod,
>
>
> Many thanks for the swift and helpful answer!
>
>
> Implementing your suggestions works but indeed gives very awkward 
> values and even a negative DIC (which I never experienced before).
>
>
> Defining instead only the random factors (random = ~ site + subplot + 
> idh(logsize1:treatment:year):units) and no rcov gives much better 
> results, but in both cases the estimates of the variances increase 
> with the covariate  logsize1, while the data suggests it should 
> decrease at high values. I assume this increase with higher covariate 
> values is not a build-in assumption, but rather based on fitting my 
> data? (in which case the fit is not good)?
>
>
> The DIC values of the more reasonable alternative described above is 
> 2980, while the DIC of my model previously defined (variance invarient 
> for the covariate, but differing in value for each treatment*year 
> combination defined in rcov) gives a DIC of ca 4900. I know I cannot 
> compare these at all since the R- and G-structure are different, but 
> is it worrying to get values that differ so extremely from each other 
> while fixed effects are the same?
>
>
> Cheers,
>
> Suzanne
>
>
>
>
> ------------------------------------------------------------------------
> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
> *Sent:* 28 March 2017 17:59:43
> *To:* LOMMEN Suzanne; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] How to vary residual variance with covariate 
> and per factor in mcmcGLMM
>
> Hi,
>
> 1/ This is correct
>
> 2/ add idh(logsize1:treatment:year):units to the random effects. This 
> gives 6 variances which we will call Vs1 ... Vs6 (s stands for slope) 
> and these complement your 6 variances specified in rcov. We'll call 
> these Vi1 ... Vi6 (s stands for intercept). The residual variance for 
> the first treatment/year category (for example) at a specific value of 
> logsize1 is then Vi1+Vs1*logsize1^2.
>
> 3/ You will find it hard to get precise estimates of these variance 
> functions, and so if you can safely simplify it I would.
>
> Cheers,
>
> Jarrod
>
>
>
> On 28/03/2017 15:39, LOMMEN Suzanne via R-sig-mixed-models wrote:
>> Dear all,
>>
>>
>> I am grateful to the active community on this mailing list! Reading the posts already helped me solving many pRoblems.
>>
>>
>> I am quite new to mcmcGLMM and haven't managed to find out how to specify that the residual variance varies with explanatory factors AND a continuous covariate. I hope someone could advice me on the case below. My apologies for the long explanation.
>>
>>
>> I investigate how a herbivore treatment throughout the growing season ("treatment") affects individual plant size at the end of the season (log size2). The treatment was applied at 4 sites, and data were collected from ca 10 plants in each of ca 12 permanent subplots per site, in each of 3 years. The plant is an annual, so plants are only measured in 1 single year.
>>
>> Because not all plants survived , the total number of datapoints is 843.
>>
>>
>>
>> Other explanatory factors I included in my model are  "year" (3 levels), the continuous covariate plant size at the start of the season ("log size1"), the continuous covariate "baresoil" (as the fraction of soil not covered by vegetation in the subplot), and their interactions.
>>
>> I also include the random factors "subplot" nested within "site" (although in mcmcGLMM it is not really nested, as I read in other posts).
>>
>> (Note: I included "year" as a fixed effect and not as a random effect because plant growth and the treatment effect varied dramatically from year to year, and this is what I want to capture in my analysis.)
>>
>>
>> I am interested in the effect on mean plant size AND in the variance, because I will use these two parameters to model a probability density function of logsize2 given logsize1 for each of all treatment*year combinations (2 treatments * 3 years = 6 combinations).
>>
>>
>> I noticed that variance varies per treatment*year combination, and in some of these combinations it also decreases with an increase in the covariate logsize1. Therefore, I would like to specify the residual variance per treatment*year combination as a function of logsize1.
>>
>>
>> So far, I have specified the variance as a constant for each of the treamnet*year combinations:
>>
>> rcov= ~idh(treatment*year):units,
>>
>> and adjusted the prior accordingly:
>>
>> R = list(V = diag(6), n = 0.002).
>>
>>
>> The complete model looks like this:
>> priorY1q1 = list(R = list(V = diag(6), n = 0.002),
>>                   G = list(G1 = list(V = 1, n = 0.002), G2 = list(V = 1, n = 0.002)))
>> modelY0bq1 <- MCMCglmm(logsize2 ~  logsize1 + treatment + baresoil + year +
>>                         treatment:logsize1 +  baresoil:logsize1+
>>                         year:treatment + year:logsize1 + year:baresoil +
>>                         year:treatment:logsize1 + year:baresoil:logsize1 ,
>>                       random = ~ site + subplot, family = "gaussian",
>>                       rcov= ~idh(treatment*year):units,
>>                       data =pd_grow, prior = priorY1q1, burnin = 5000, nitt = 805000, thin=200)
>>
>>
>> I would be very glad to get comments on
>>
>> 1. if this is correctly specified so far (the results seem to make sense)
>>
>> 2. how to specify that the variance ALSO varies with logsize1, but possibly in a different way for each treatment*year combination?
>>
>> 3. If there is  a risk to over-specify the variance this way?
>>
>>
>> Many thanks,
>>
>>
>> Kind regards,
>>
>> Suzanne Lommen
>>
>> PostDoc<http://www.unifr.ch/ecology/groupmueller/group/post-doctoral-associates/suzanne-lommen>  in the Plant Population Biology group of Prof. Dr. Heinz M?ller-Sch?rer
>>
>> Co-management of the EU-COST Action 'SMARTER<http://www.ragweed.eu/>': Sustainable management of Ambrosia artemisiifolia in Europe
>> Coordination of the SMARTER Task Force Population Dynamics<http://ragweed.eu/task-force-population-dynamics/>
>>
>> Department of Biology/Ecology & Evolution
>> University of Fribourg/P?rolles
>> Chemin du Mus?e 10
>> CH-1700 Fribourg, SWITZERLAND
>> Tel: + (41) (0) 26-300 88 48 direct
>> Tel: + (41) (0) 26-300 88 50 secr.
>> Fax: + (41) (0) 26-300 9741
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170330/a8ae77e3/attachment.pl>

From A.De-Palma at nhm.ac.uk  Thu Mar 30 11:41:17 2017
From: A.De-Palma at nhm.ac.uk (Adriana De Palma)
Date: Thu, 30 Mar 2017 09:41:17 +0000
Subject: [R-sig-ME] Modelling proportion data in lme4
Message-ID: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>

Dear all,

I'd be really grateful if someone could advise on the following issue I've come across.

I have proportion data (non-integer, bounded between 0 and 1) as my response variable, in a model that requires nested random effects and weights, which makes lme4 the ideal choice. Using lme4 with a binomial error structure and logit link seems to produce reasonable (and realistic looking) results, and the residual plots look good. However, it warns me that the error structure expects integer data, and I don't know whether this approach is doing what I think (and hope) that it is doing. I have tried to validate the lme4 results in the following ways:


1.       Running the same method (binomial error structure and logit link with the proportions as the response variable) with glmmADMB. This produces very different results (they are completely unrealistic, e.g. predicted proportion of 2.16e-34).

2.       Using beta regression with glmmADMB. This seems to work and produce results that are on the same scale, but not that close to those of lme4.

3.       Running an lme4 model with normal errors (lmer), after logit-transforming the response variable. This again gives quite different results to the lme4 model with binomial error structure and logit link (and the behaviour of the residuals is not ideal).

Since these all give different results, it's hard to tell whether the lme4 method I've used is giving the 'right' answer. I would be really grateful for any advice. Is lme4 correctly analysing the proportion data when a binomial error structure and logit link are specified?

Additional note: the proportion data are compositional similarity measurements (Jaccard assymetric abundance-based compositional similarity), so technically there is a numerator and denominator (numerator = abundance of species in Site 1 that are also present in Site 2; denominator = abundance of all species in Site 1). I've been exploring different weights options, but they generally include the denominator.

Many thanks in advance,

Adriana


_____

Adriana De Palma
PREDICTS Postdoctoral Research Assistant
Natural History Museum
South Kensington

Web: The Purvis Lab<http://www.bio.ic.ac.uk/research/apurvis/ajpurvis.htm> | PREDICTS<predicts.org.uk>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Mar 30 16:36:58 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 30 Mar 2017 16:36:58 +0200
Subject: [R-sig-ME] Modelling proportion data in lme4
In-Reply-To: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>
References: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>
Message-ID: <CAJuCY5wqz-TU4BZqGo-x69POJ3eVtbHdRjKpDjkrLJxEdOmi6w@mail.gmail.com>

Dear Adriana,

Use binomial only when the raw proportion stem from n Bernouilli
trials. E.g. 25% of 20 trails (or 5/20). In your case that could be
the abundances of all species at each site. Use that as the weights.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-03-30 11:41 GMT+02:00 Adriana De Palma <A.De-Palma at nhm.ac.uk>:
> Dear all,
>
> I'd be really grateful if someone could advise on the following issue I've come across.
>
> I have proportion data (non-integer, bounded between 0 and 1) as my response variable, in a model that requires nested random effects and weights, which makes lme4 the ideal choice. Using lme4 with a binomial error structure and logit link seems to produce reasonable (and realistic looking) results, and the residual plots look good. However, it warns me that the error structure expects integer data, and I don't know whether this approach is doing what I think (and hope) that it is doing. I have tried to validate the lme4 results in the following ways:
>
>
> 1.       Running the same method (binomial error structure and logit link with the proportions as the response variable) with glmmADMB. This produces very different results (they are completely unrealistic, e.g. predicted proportion of 2.16e-34).
>
> 2.       Using beta regression with glmmADMB. This seems to work and produce results that are on the same scale, but not that close to those of lme4.
>
> 3.       Running an lme4 model with normal errors (lmer), after logit-transforming the response variable. This again gives quite different results to the lme4 model with binomial error structure and logit link (and the behaviour of the residuals is not ideal).
>
> Since these all give different results, it's hard to tell whether the lme4 method I've used is giving the 'right' answer. I would be really grateful for any advice. Is lme4 correctly analysing the proportion data when a binomial error structure and logit link are specified?
>
> Additional note: the proportion data are compositional similarity measurements (Jaccard assymetric abundance-based compositional similarity), so technically there is a numerator and denominator (numerator = abundance of species in Site 1 that are also present in Site 2; denominator = abundance of all species in Site 1). I've been exploring different weights options, but they generally include the denominator.
>
> Many thanks in advance,
>
> Adriana
>
>
> _____
>
> Adriana De Palma
> PREDICTS Postdoctoral Research Assistant
> Natural History Museum
> South Kensington
>
> Web: The Purvis Lab<http://www.bio.ic.ac.uk/research/apurvis/ajpurvis.htm> | PREDICTS<predicts.org.uk>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From suzanne.lommen at unifr.ch  Fri Mar 31 11:15:44 2017
From: suzanne.lommen at unifr.ch (LOMMEN Suzanne)
Date: Fri, 31 Mar 2017 09:15:44 +0000
Subject: [R-sig-ME] How to vary residual variance with covariate and per
 factor in mcmcGLMM
In-Reply-To: <280a6614-9a5b-577b-cc72-584e2971ce07@ed.ac.uk>
References: <1490711997892.7364@unifr.ch>
	<4567f7ec-a829-9322-82fb-dcf93070b0fd@ed.ac.uk>
	<1490818409566.78743@unifr.ch>
	<280a6614-9a5b-577b-cc72-584e2971ce07@ed.ac.uk>
Message-ID: <0434f4f4394c4e15b7bf9ba1de4d6d5e@svw-exmb2.unifr.ch>

Many thanks!
Suzanne

From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
Sent: 30 March 2017 07:44
To: LOMMEN Suzanne; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] How to vary residual variance with covariate and per factor in mcmcGLMM


cc-ed back to the list...



DIC isn't meaningful in this context - I would ignore it.



My suggestion assumes that the variance increases to the square of the covariate. Sometimes people square-root the covariate (if it is positive) if they want a positive linear relationship. A negative relationship is more tricky. You could have 1/logsize1 but this is going to behave badly at values close to zero, or perhaps 1/size1 or 1/sqrt(size1).



Cheers,



Jarrod

On 29/03/2017 21:13, LOMMEN Suzanne wrote:



Dear Jarrod,



Many thanks for the swift and helpful answer!



Implementing your suggestions works but indeed gives very awkward values and even a negative DIC (which I never experienced before).



Defining instead only the random factors (random = ~ site + subplot + idh(logsize1:treatment:year):units) and no rcov gives much better results, but in both cases the estimates of the variances increase with the covariate  logsize1, while the data suggests it should decrease at high values. I assume this increase with higher covariate values is not a build-in assumption, but rather based on fitting my data? (in which case the fit is not good)?



The DIC values of the more reasonable alternative described above is 2980, while the DIC of my model previously defined (variance invarient for the covariate, but differing in value for each treatment*year combination defined in rcov) gives a DIC of ca 4900. I know I cannot compare these at all since the R- and G-structure are different, but is it worrying to get values that differ so extremely from each other while fixed effects are the same?



Cheers,

Suzanne







________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: 28 March 2017 17:59:43
To: LOMMEN Suzanne; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] How to vary residual variance with covariate and per factor in mcmcGLMM


Hi,

1/ This is correct

2/ add idh(logsize1:treatment:year):units to the random effects. This gives 6 variances which we will call Vs1 ... Vs6 (s stands for slope) and these complement your 6 variances specified in rcov. We'll call these Vi1 ... Vi6 (s stands for intercept). The residual variance for the first treatment/year category (for example) at a specific value of logsize1 is then Vi1+Vs1*logsize1^2.

3/ You will find it hard to get precise estimates of these variance functions, and so if you can safely simplify it I would.

Cheers,

Jarrod



On 28/03/2017 15:39, LOMMEN Suzanne via R-sig-mixed-models wrote:

Dear all,





I am grateful to the active community on this mailing list! Reading the posts already helped me solving many pRoblems.





I am quite new to mcmcGLMM and haven't managed to find out how to specify that the residual variance varies with explanatory factors AND a continuous covariate. I hope someone could advice me on the case below. My apologies for the long explanation.





I investigate how a herbivore treatment throughout the growing season ("treatment") affects individual plant size at the end of the season (log size2). The treatment was applied at 4 sites, and data were collected from ca 10 plants in each of ca 12 permanent subplots per site, in each of 3 years. The plant is an annual, so plants are only measured in 1 single year.



Because not all plants survived , the total number of datapoints is 843.







Other explanatory factors I included in my model are  "year" (3 levels), the continuous covariate plant size at the start of the season ("log size1"), the continuous covariate "baresoil" (as the fraction of soil not covered by vegetation in the subplot), and their interactions.



I also include the random factors "subplot" nested within "site" (although in mcmcGLMM it is not really nested, as I read in other posts).



(Note: I included "year" as a fixed effect and not as a random effect because plant growth and the treatment effect varied dramatically from year to year, and this is what I want to capture in my analysis.)





I am interested in the effect on mean plant size AND in the variance, because I will use these two parameters to model a probability density function of logsize2 given logsize1 for each of all treatment*year combinations (2 treatments * 3 years = 6 combinations).





I noticed that variance varies per treatment*year combination, and in some of these combinations it also decreases with an increase in the covariate logsize1. Therefore, I would like to specify the residual variance per treatment*year combination as a function of logsize1.





So far, I have specified the variance as a constant for each of the treamnet*year combinations:



rcov= ~idh(treatment*year):units,



and adjusted the prior accordingly:



R = list(V = diag(6), n = 0.002).





The complete model looks like this:

priorY1q1 = list(R = list(V = diag(6), n = 0.002),

                 G = list(G1 = list(V = 1, n = 0.002), G2 = list(V = 1, n = 0.002)))

modelY0bq1 <- MCMCglmm(logsize2 ~  logsize1 + treatment + baresoil + year +

                       treatment:logsize1 +  baresoil:logsize1+

                       year:treatment + year:logsize1 + year:baresoil +

                       year:treatment:logsize1 + year:baresoil:logsize1 ,

                     random = ~ site + subplot, family = "gaussian",

                     rcov= ~idh(treatment*year):units,

                     data =pd_grow, prior = priorY1q1, burnin = 5000, nitt = 805000, thin=200)





I would be very glad to get comments on



1. if this is correctly specified so far (the results seem to make sense)



2. how to specify that the variance ALSO varies with logsize1, but possibly in a different way for each treatment*year combination?



3. If there is  a risk to over-specify the variance this way?





Many thanks,





Kind regards,



Suzanne Lommen



PostDoc<http://www.unifr.ch/ecology/groupmueller/group/post-doctoral-associates/suzanne-lommen><http://www.unifr.ch/ecology/groupmueller/group/post-doctoral-associates/suzanne-lommen> in the Plant Population Biology group of Prof. Dr. Heinz M?ller-Sch?rer



Co-management of the EU-COST Action 'SMARTER<http://www.ragweed.eu/><http://www.ragweed.eu/>': Sustainable management of Ambrosia artemisiifolia in Europe

Coordination of the SMARTER Task Force Population Dynamics <http://ragweed.eu/task-force-population-dynamics/><http://ragweed.eu/task-force-population-dynamics/>



Department of Biology/Ecology & Evolution

University of Fribourg/P?rolles

Chemin du Mus?e 10

CH-1700 Fribourg, SWITZERLAND

Tel: + (41) (0) 26-300 88 48 direct

Tel: + (41) (0) 26-300 88 50 secr.

Fax: + (41) (0) 26-300 9741









   [[alternative HTML version deleted]]





_______________________________________________

R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From stephanie.kalberer at uni-bielefeld.de  Fri Mar 31 14:41:48 2017
From: stephanie.kalberer at uni-bielefeld.de (Stephanie Kalberer)
Date: Fri, 31 Mar 2017 14:41:48 +0200
Subject: [R-sig-ME] marginal R square calculation in zero truncated poisson
	model
Message-ID: <7330bb44d56.58de6aac@uni-bielefeld.de>

Dear Professor Bolker,
I am looking into life history data of sea lions at the moment and would like to test what influences the length of the inter-birth interval. My response variable shows a clear poisson distribution but as I don't have any zeros in my inter-birth interval, I use a zero truncated model. The full model:
glmmadmb(IBI..years.~ sex.first.offspring + SST.Jan.May. + IBI.of.previous.pup + birthyear_mother.num + birthyear_pup.num + first.offspring.of.interval.died.within.1st.year + (1|AnimalID), 
 family="truncpoiss", data=IBI_successive_pups_sexmat_OF_sex)
I couldn't find any information though how to calculate the marginal R square in that case, could you point me towards a document or solution for it?
Thanks a lot and best,
Stephanie Kalberer
-- 
___________________________

Stephanie Kalberer
PhD Candidate
Galapagos Sea Lion Project
Department of Animal Behaviour
Bielefeld University
Germany

	[[alternative HTML version deleted]]


