From mollieebrooks at gmail.com  Mon Oct  2 15:33:53 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Mon, 2 Oct 2017 15:33:53 +0200
Subject: [R-sig-ME] How to specify user-defined matrix Z?
In-Reply-To: <CALKSUOkcsaMGx2Xc0A08M3THg-f+CHqxxLDO050CN7gwwYic_Q@mail.gmail.com>
References: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>
 <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>
 <8ef01ac9-639a-e003-b668-214e986902f6@control.lth.se>
 <1506714713397.37325@UTSouthwestern.edu>
 <CALKSUOkcsaMGx2Xc0A08M3THg-f+CHqxxLDO050CN7gwwYic_Q@mail.gmail.com>
Message-ID: <CAMu=eMDAjMixepPvu265BQm2g-57FyyNXqfuHVtkXoeO46FrQw@mail.gmail.com>

This example, from Bolker and wzmli, showing how to use lme4 and glmmTMB
seems relevant. It's a long-term goal to make these analyses easier in
glmmTMB.

https://github.com/bbolker/mixedmodels-misc/blob/master/notes/phylog.rmd

cheers,
Mollie

On Sat, Sep 30, 2017 at 6:27 PM, Diogo Melo <diogro at gmail.com> wrote:

> I'm pretty sure lme4qtl can handle this:
>
> https://www.biorxiv.org/content/early/2017/05/18/139816.1
> https://github.com/variani/lme4qtl
>
> Cheers,
> Diogo
>
> On Fri, Sep 29, 2017 at 4:51 PM, Zhengyang Zhou <
> Zhengyang.Zhou at utsouthwestern.edu> wrote:
>
> > Hi Jacob,
> >
> > Thank you for your reply. I need to use lme4 because I want to test for
> > the fixed effects (ie., beta), and the packages which can do it (eg,
> > pbkrtest) is based on lme4.
> >
> > Sincerely,
> > Zhengyang
> > ________________________________________
> > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> > behalf of Jacob Bergstedt <jacoba at control.lth.se>
> > Sent: Friday, September 29, 2017 6:39 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] How to specify user-defined matrix Z?
> >
> > Hi,
> >
> > You can use the lmekin function in the coxme package.
> >
> > Best regards,
> >
> > Jacob
> >
> >
> > On 2017-09-29 12:28, Crump, Ron wrote:
> > > Hi Zhengyang,
> > >
> > >> In genetic studies, we sometimes include the genetic relatedness
> matrix
> > as a variance component, so we have this following model:
> > >> Y~Xbeta+Zb+error,
> > >>
> > >> where beta are the fixed effects, b~N(0,sigma^2*I) are the random
> > effects, error are the random error, Z is the cholesky decomposition of
> the
> > known genetic relatedness matrix. So how to use lme4 to fit this model if
> > we know X and Z beforehand? I can use the package "nlme" to do it using
> the
> > code like
> > >>
> > >> lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
> > >> but how to do it using lme4?
> > > I think, assuming you are using I to indicate an identity matrix, that
> > > in neither case are you specifying a genetic relationship matrix,
> unless
> > > you are somehow incorporating it into Z (in which case I'd like to see
> > how).
> > >
> > > I don't believe that either lme4 or nlme will allow you to do what you
> > > want. (Somebody might correct me on this).
> > >
> > > Within R you could certainly use MCMCglmm or INLA to do analysis of
> > > quantitative genetics data to obtain genetic parameters (or the asremlr
> > > interface to ASREML). I've not used it, but the pedigreemm package also
> > > looks like it would help you and there may be others. Outside of R,
> > > Karin Meyer's wombat program will also do the job.
> > >
> > >
> > > Regards,
> > > Ron.
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > ________________________________
> >
> > UT Southwestern
> >
> >
> > Medical Center
> >
> >
> >
> > The future of medicine, today.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Mon Oct  2 15:36:45 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Mon, 2 Oct 2017 15:36:45 +0200
Subject: [R-sig-ME] How to specify user-defined matrix Z?
In-Reply-To: <CAMu=eMDAjMixepPvu265BQm2g-57FyyNXqfuHVtkXoeO46FrQw@mail.gmail.com>
References: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>
 <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>
 <8ef01ac9-639a-e003-b668-214e986902f6@control.lth.se>
 <1506714713397.37325@UTSouthwestern.edu>
 <CALKSUOkcsaMGx2Xc0A08M3THg-f+CHqxxLDO050CN7gwwYic_Q@mail.gmail.com>
 <CAMu=eMDAjMixepPvu265BQm2g-57FyyNXqfuHVtkXoeO46FrQw@mail.gmail.com>
Message-ID: <CAMu=eMDoRfFy-fJpSMkNBQYJShQ9m6SYz36UVbwcrrb0THybFg@mail.gmail.com>

Sorry, I just found this formatted version.
 https://bbolker.github.io/mixedmodels-misc/notes/phylog.html

On Mon, Oct 2, 2017 at 3:33 PM, Mollie Brooks <mollieebrooks at gmail.com>
wrote:

> This example, from Bolker and wzmli, showing how to use lme4 and glmmTMB
> seems relevant. It's a long-term goal to make these analyses easier in
> glmmTMB.
>
> https://github.com/bbolker/mixedmodels-misc/blob/master/notes/phylog.rmd
>
> cheers,
> Mollie
>
> On Sat, Sep 30, 2017 at 6:27 PM, Diogo Melo <diogro at gmail.com> wrote:
>
>> I'm pretty sure lme4qtl can handle this:
>>
>> https://www.biorxiv.org/content/early/2017/05/18/139816.1
>> https://github.com/variani/lme4qtl
>>
>> Cheers,
>> Diogo
>>
>> On Fri, Sep 29, 2017 at 4:51 PM, Zhengyang Zhou <
>> Zhengyang.Zhou at utsouthwestern.edu> wrote:
>>
>> > Hi Jacob,
>> >
>> > Thank you for your reply. I need to use lme4 because I want to test for
>> > the fixed effects (ie., beta), and the packages which can do it (eg,
>> > pbkrtest) is based on lme4.
>> >
>> > Sincerely,
>> > Zhengyang
>> > ________________________________________
>> > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
>> > behalf of Jacob Bergstedt <jacoba at control.lth.se>
>> > Sent: Friday, September 29, 2017 6:39 AM
>> > To: r-sig-mixed-models at r-project.org
>> > Subject: Re: [R-sig-ME] How to specify user-defined matrix Z?
>> >
>> > Hi,
>> >
>> > You can use the lmekin function in the coxme package.
>> >
>> > Best regards,
>> >
>> > Jacob
>> >
>> >
>> > On 2017-09-29 12:28, Crump, Ron wrote:
>> > > Hi Zhengyang,
>> > >
>> > >> In genetic studies, we sometimes include the genetic relatedness
>> matrix
>> > as a variance component, so we have this following model:
>> > >> Y~Xbeta+Zb+error,
>> > >>
>> > >> where beta are the fixed effects, b~N(0,sigma^2*I) are the random
>> > effects, error are the random error, Z is the cholesky decomposition of
>> the
>> > known genetic relatedness matrix. So how to use lme4 to fit this model
>> if
>> > we know X and Z beforehand? I can use the package "nlme" to do it using
>> the
>> > code like
>> > >>
>> > >> lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
>> > >> but how to do it using lme4?
>> > > I think, assuming you are using I to indicate an identity matrix, that
>> > > in neither case are you specifying a genetic relationship matrix,
>> unless
>> > > you are somehow incorporating it into Z (in which case I'd like to see
>> > how).
>> > >
>> > > I don't believe that either lme4 or nlme will allow you to do what you
>> > > want. (Somebody might correct me on this).
>> > >
>> > > Within R you could certainly use MCMCglmm or INLA to do analysis of
>> > > quantitative genetics data to obtain genetic parameters (or the
>> asremlr
>> > > interface to ASREML). I've not used it, but the pedigreemm package
>> also
>> > > looks like it would help you and there may be others. Outside of R,
>> > > Karin Meyer's wombat program will also do the job.
>> > >
>> > >
>> > > Regards,
>> > > Ron.
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> > ________________________________
>> >
>> > UT Southwestern
>> >
>> >
>> > Medical Center
>> >
>> >
>> >
>> > The future of medicine, today.
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From dmichl at uni-potsdam.de  Tue Oct  3 17:14:37 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Tue, 3 Oct 2017 17:14:37 +0200
Subject: [R-sig-ME] Linear mixed model in lme4
In-Reply-To: <DM5PR11MB156300A4B73E77FB13A1A246A47E0@DM5PR11MB1563.namprd11.prod.outlook.com>
References: <DM5PR11MB156300A4B73E77FB13A1A246A47E0@DM5PR11MB1563.namprd11.prod.outlook.com>
Message-ID: <a59fc0ce-1391-7804-bb73-74103bdf53dc@uni-potsdam.de>

Hi Ricardo,

if you have fixed and random effects, then lme4 can definitely do this 
analysis. But your formula would have to look quite different. I also 
don't get your data overview - if you have it in a table, rather send 
that than a single column. While I still wouldn't know what FA7, FV7, 
and your other letter-number combinations refer to, which might make a 
difference to your model.

You're aware that you wouldn't write your equation in lme4 as you did 
here, right? You would not write mu+ and +e, but Y ~ variable1 + 
variable2 + random effect.

1. What is your Y? Is Y the specific tree clone you're trying to predict?
2. Your Female+Male is most likely one variable with 2 levels (Female 
and Male), not two. So in your formula, it would be "sex" instead or 
however you want to call it.
3. I don't know what FemxMale refers to.
4. What does Clone refer to?
5. What would your random effect(s) be? If you don't have any, lme4 is 
not right for you.

 From what you're writing, I don't think your formula is correct. From 
the data you've sent, I can't get the proper info.
So we would really need more info on what you're trying to find out and 
model.

Diana


Am 29.09.2017 um 18:52 schrieb Ricardo Francisco Duran Reyes:
> Dear all,
> I am a forestry researcher from Chile and I want to use the Lme4 packages for fitting a linear mixed model according this equation:
>   Y=mu+Female+Male+FemxMale+Clone+e
>   Where some trees are clones with know family and other are clones with unknow parents, others are family data with both parents know and other are family data with just one parent know.
>   Is lme4 capable for doing this analysis?
>   An example of how data looks is here:
>   Family
>
> Female
>
> Male
>
> Clone
>
> Type of data
>
> AH
>
> FA7
>
> FV7
>
> AH714
>
> Clonal data
>
> AH
>
> FA7
>
> FV7
>
>
>
> Full sib progeny
>
> LB
>
> FA7
>
> Unknown
>
> LB315
>
> Clonal data (one parent known)
>
> Unknown
>
> Unknown
>
> Unknown
>
> BA465
>
> Clonal data (unknown family)
>
> BT
>
> FA21
>
> FV50
>
>
>
> Full sib progeny
>
> BA
>
> G184
>
> Unknown
>
>
>
> OP progeny
>
>
> I would appreciate any help
>
> Best regards,
>
> Ricardo Dur?n
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Diana Michl, M.A.
PhD candidate
International Experimental
and Clinical Linguistics
Universit?t Potsdam
www.ling.uni-potsdam.de/staff/dmichl
www.duoinfernale.eu


	[[alternative HTML version deleted]]


From udube at wustl.edu  Tue Oct  3 22:50:29 2017
From: udube at wustl.edu (Dube, Umber)
Date: Tue, 3 Oct 2017 20:50:29 +0000
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>,
 <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
Message-ID: <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>

Thanks for your responses.

Thierry,

The first case is correct. For example, the skin is an organ and the different layers of the skin (epidermis, dermis, and hypodermis) can be considered tissues. So in my experiment I have collected the same tissues originating from different organs which are either healthy or diseased.

Good call on the species effect. I've dropped one of the species for whom I had only healthy data. This has resulted in fewer convergence warnings as I perform the glmer with each gene. I've also noticed that even those genes for which I do produce convergence warnings will converge if I try using other optimizers. I understand this provides additional evidence to support the warnings being false positives.

---

David,

I hadn't considered that. If I'm understanding correctly, you would recommend including species:tissue in my model?

---

All,

Is it appropriate to model batch as a random effect, or should I include it as a fixed effect?


Thanks,

Umber


________________________________
From: Farrar, David <Farrar.David at epa.gov>
Sent: Monday, October 2, 2017 1:21:45 PM
To: Dube, Umber
Subject: RE: [R-sig-ME] Questions about design and convergence warnings

Dear Umber,
It seems your model would not support a conclusion that the effect on a certain tissue would depend on the species, an interaction.
Is that intentional?
David

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thierry Onkelinx
Sent: Friday, September 29, 2017 7:35 AM
To: Dube, Umber <udube at wustl.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Questions about design and convergence warnings

Dear Umber,

Can you clarify what a tissue is? Distinct parts of an organ (tissue 1 for organ 1 refers to the same part as tissue 1 for organ 2)? Or merely different samples for the same organ (no link between tissue 1 between organs). Tissue as random effect is only relevant in the first case. In the latter case is depends on the number of replicates per tissue:organ. In case of one replication go for (1|Organ), in case of multiple replications go for (1|Organ/Tissue).

It looks like you have very strong species effects. That is an indication for quasi-complete separation, which can trigger convergence warnings.

Best regards,

ir. Thierry Onkelinx
Statisticus/ Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Kliniekstraat 25, B-1070 Brussel www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu>:
> Thanks for your continued development of lme4 and all the support you've provided.
>
> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
>
> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
>
> I have been modelling the following as fixed effects:
> RNA Integrity Number (RIN) - quality of the total RNA extracted from
> each tissues (continuous) Post-mortem Interval (PMI) - how much time
> elapsed following death until the tissue was frozen (continuous) Sex -
> genetic sex of the organ (categorical) Age at death (AOD) - age of
> organ at death (continuous) Species - species of organ (categorical)
> Gene -  normalized count data of gene expression (continuous)
>
> I have been modelling the following as random effects:
> Batch (categorical)
>
> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
>
> Altogether, my model is:
>
> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue +
> (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(),
> control=glmerControl(optCtrl=list(maxfun=1e9) ) )
>
> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
>
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   unable to evaluate scaled gradient
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative
> eigenvalues
>
> To address this:
>
> 1) I've centered and scaled my continous predictors
>
> 2) I've checked for singularity #False
>
> 3) I've printed and compared with internal calculations
>
> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
>
>
>> ss$ fixef ## extract fixed effects
>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>
>
>> ss$ llik ## log-likelihoods
>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
>
>> ss$ sdcor ## SDs and correlations
>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>         bobyqa  3.68E-05        0.520826
>         Nelder_Mead     5.56E-03        0.52084
>         nlminbw 3.10E-08        0.520826
>         optimx.L-BFGS-B 0.00E+00        0.52084
>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>
>
>
>> ss$ theta ## Cholesky factors
>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>         bobyqa  3.68E-05        0.520826
>         Nelder_Mead     5.56E-03        0.52084
>         nlminbw 3.10E-08        0.520826
>         optimx.L-BFGS-B 0.00E+00        0.52084
>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>
>
>> ss$ which.OK ## which fits worked
>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
>
>
> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
>
> Thanks,
>
> Umber
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Oct  3 23:34:12 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Oct 2017 17:34:12 -0400
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>
 <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>
Message-ID: <CABghstQ0P59Yh+9im0LY4g4rk82t0UAxPdUt=0BohuOBveAmCw@mail.gmail.com>

On Tue, Oct 3, 2017 at 4:50 PM, Dube, Umber <udube at wustl.edu> wrote:
> Thanks for your responses.
>
> Thierry,
>
> The first case is correct. For example, the skin is an organ and the different layers of the skin (epidermis, dermis, and hypodermis) can be considered tissues. So in my experiment I have collected the same tissues originating from different organs which are either healthy or diseased.
>
> Good call on the species effect. I've dropped one of the species for whom I had only healthy data. This has resulted in fewer convergence warnings as I perform the glmer with each gene. I've also noticed that even those genes for which I do produce convergence warnings will converge if I try using other optimizers. I understand this provides additional evidence to support the warnings being false positives.
>
> ---
>
> David,
>
> I hadn't considered that. If I'm understanding correctly, you would recommend including species:tissue in my model?
>
> ---
>
> All,
>
> Is it appropriate to model batch as a random effect, or should I include it as a fixed effect?


  Haven't followed the thread carefully, but: typically an
exchangeable factor such as batch (i.e., relabeling the batches
wouldn't change anything about their meaning) is _philosophically_ a
random effect, but if you have too few levels (batches) to reliably
estimate among-batch variance (e.g. <5) you might choose to treat it
as a fixed effect instead (or use a Bayesian method that allows you to
specify a prior on the among-batch variance ...)

>
>
> Thanks,
>
> Umber
>
>
> ________________________________
> From: Farrar, David <Farrar.David at epa.gov>
> Sent: Monday, October 2, 2017 1:21:45 PM
> To: Dube, Umber
> Subject: RE: [R-sig-ME] Questions about design and convergence warnings
>
> Dear Umber,
> It seems your model would not support a conclusion that the effect on a certain tissue would depend on the species, an interaction.
> Is that intentional?
> David
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thierry Onkelinx
> Sent: Friday, September 29, 2017 7:35 AM
> To: Dube, Umber <udube at wustl.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Questions about design and convergence warnings
>
> Dear Umber,
>
> Can you clarify what a tissue is? Distinct parts of an organ (tissue 1 for organ 1 refers to the same part as tissue 1 for organ 2)? Or merely different samples for the same organ (no link between tissue 1 between organs). Tissue as random effect is only relevant in the first case. In the latter case is depends on the number of replicates per tissue:organ. In case of one replication go for (1|Organ), in case of multiple replications go for (1|Organ/Tissue).
>
> It looks like you have very strong species effects. That is an indication for quasi-complete separation, which can trigger convergence warnings.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus/ Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Kliniekstraat 25, B-1070 Brussel www.inbo.be<http://www.inbo.be>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
> 2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu>:
>> Thanks for your continued development of lme4 and all the support you've provided.
>>
>> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
>>
>> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
>>
>> I have been modelling the following as fixed effects:
>> RNA Integrity Number (RIN) - quality of the total RNA extracted from
>> each tissues (continuous) Post-mortem Interval (PMI) - how much time
>> elapsed following death until the tissue was frozen (continuous) Sex -
>> genetic sex of the organ (categorical) Age at death (AOD) - age of
>> organ at death (continuous) Species - species of organ (categorical)
>> Gene -  normalized count data of gene expression (continuous)
>>
>> I have been modelling the following as random effects:
>> Batch (categorical)
>>
>> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
>>
>> Altogether, my model is:
>>
>> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue +
>> (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(),
>> control=glmerControl(optCtrl=list(maxfun=1e9) ) )
>>
>> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
>>
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   unable to evaluate scaled gradient
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge: degenerate  Hessian with 1 negative
>> eigenvalues
>>
>> To address this:
>>
>> 1) I've centered and scaled my continous predictors
>>
>> 2) I've checked for singularity #False
>>
>> 3) I've printed and compared with internal calculations
>>
>> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
>>
>>
>>> ss$ fixef ## extract fixed effects
>>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
>> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
>> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
>> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
>> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
>> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>>
>>
>>> ss$ llik ## log-likelihoods
>>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
>>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
>>
>>> ss$ sdcor ## SDs and correlations
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>
>>> ss$ theta ## Cholesky factors
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>> ss$ which.OK ## which fits worked
>>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
>>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
>>
>>
>> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
>>
>> Thanks,
>>
>> Umber
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From vito.muggeo at unipa.it  Tue Oct  3 23:39:31 2017
From: vito.muggeo at unipa.it (Vito Michele Rosario Muggeo)
Date: Tue, 03 Oct 2017 23:39:31 +0200
Subject: [R-sig-ME] adding objects into "glmerMod" fits
Message-ID: <20171003233931.Horde.SAdazIRk4QhdKERT1z5vjWV@webmail.unipa.it>

dear all,
for some reasons I would like to add some new components (vectors,  
matrices) to a "glmerMod" fit. I am not familiar with S4, so borrowing  
from S3 classes my first tentative was

o <- glmer(y ~ ..)
o at new<-1:3

But it clearly does not work. Is there any solution?
thanks in advance for your time,
best,
vito


From Farrar.David at epa.gov  Wed Oct  4 00:04:42 2017
From: Farrar.David at epa.gov (Farrar, David)
Date: Tue, 3 Oct 2017 22:04:42 +0000
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <CABghstQ0P59Yh+9im0LY4g4rk82t0UAxPdUt=0BohuOBveAmCw@mail.gmail.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>
 <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CABghstQ0P59Yh+9im0LY4g4rk82t0UAxPdUt=0BohuOBveAmCw@mail.gmail.com>
Message-ID: <BY1PR09MB05338F5ECB0E060575CFE3219A720@BY1PR09MB0533.namprd09.prod.outlook.com>

Hi,
I would like to check my intuition on the number of levels needed for a random effect.  I think of this basically in terms of the split plot design, with fixed effects that vary either within whole plots or among whole plots.  In the real world, I wouldn't expect that clean a breakdown.  You need a bunch of levels if the variance is inherently interesting.   If you are trying to evaluate some fixed effect, it seems like you are concerned with whether that effect varies primarily among levels of the random effect, or primarily within levels.  In the 2nd case, it seems to me that you wouldn't need many levels for the random effect.   This is just my intuition.   I am interested in how good it is and whether it can be related to mathematical results.  
Regards,
David 


-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Tuesday, October 03, 2017 5:34 PM
To: Dube, Umber <udube at wustl.edu>
Cc: Farrar, David <Farrar.David at epa.gov>; r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
Subject: Re: [R-sig-ME] Questions about design and convergence warnings

On Tue, Oct 3, 2017 at 4:50 PM, Dube, Umber <udube at wustl.edu> wrote:
> Thanks for your responses.
>
> Thierry,
>
> The first case is correct. For example, the skin is an organ and the different layers of the skin (epidermis, dermis, and hypodermis) can be considered tissues. So in my experiment I have collected the same tissues originating from different organs which are either healthy or diseased.
>
> Good call on the species effect. I've dropped one of the species for whom I had only healthy data. This has resulted in fewer convergence warnings as I perform the glmer with each gene. I've also noticed that even those genes for which I do produce convergence warnings will converge if I try using other optimizers. I understand this provides additional evidence to support the warnings being false positives.
>
> ---
>
> David,
>
> I hadn't considered that. If I'm understanding correctly, you would recommend including species:tissue in my model?
>
> ---
>
> All,
>
> Is it appropriate to model batch as a random effect, or should I include it as a fixed effect?


  Haven't followed the thread carefully, but: typically an exchangeable factor such as batch (i.e., relabeling the batches wouldn't change anything about their meaning) is _philosophically_ a random effect, but if you have too few levels (batches) to reliably estimate among-batch variance (e.g. <5) you might choose to treat it as a fixed effect instead (or use a Bayesian method that allows you to specify a prior on the among-batch variance ...)

>
>
> Thanks,
>
> Umber
>
>
> ________________________________
> From: Farrar, David <Farrar.David at epa.gov>
> Sent: Monday, October 2, 2017 1:21:45 PM
> To: Dube, Umber
> Subject: RE: [R-sig-ME] Questions about design and convergence 
> warnings
>
> Dear Umber,
> It seems your model would not support a conclusion that the effect on a certain tissue would depend on the species, an interaction.
> Is that intentional?
> David
>
> -----Original Message-----
> From: R-sig-mixed-models 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thierry 
> Onkelinx
> Sent: Friday, September 29, 2017 7:35 AM
> To: Dube, Umber <udube at wustl.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Questions about design and convergence 
> warnings
>
> Dear Umber,
>
> Can you clarify what a tissue is? Distinct parts of an organ (tissue 1 for organ 1 refers to the same part as tissue 1 for organ 2)? Or merely different samples for the same organ (no link between tissue 1 between organs). Tissue as random effect is only relevant in the first case. In the latter case is depends on the number of replicates per tissue:organ. In case of one replication go for (1|Organ), in case of multiple replications go for (1|Organ/Tissue).
>
> It looks like you have very strong species effects. That is an indication for quasi-complete separation, which can trigger convergence warnings.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus/ Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN 
> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie 
> & Kwaliteitszorg / Team Biometrics & Quality Assurance 
> thierry.onkelinx at inbo.be Kliniekstraat 25, B-1070 Brussel 
> www.inbo.be<http://www.inbo.be>
>
> //////////////////////////////////////////////////////////////////////
> ///////////////////// To call in the statistician after the experiment 
> is done may be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of. ~ Sir 
> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger 
> Brinner The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be extracted from 
> a given body of data. ~ John Tukey 
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
>
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
>
> 2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu>:
>> Thanks for your continued development of lme4 and all the support you've provided.
>>
>> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
>>
>> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
>>
>> I have been modelling the following as fixed effects:
>> RNA Integrity Number (RIN) - quality of the total RNA extracted from 
>> each tissues (continuous) Post-mortem Interval (PMI) - how much time 
>> elapsed following death until the tissue was frozen (continuous) Sex 
>> - genetic sex of the organ (categorical) Age at death (AOD) - age of 
>> organ at death (continuous) Species - species of organ (categorical) 
>> Gene -  normalized count data of gene expression (continuous)
>>
>> I have been modelling the following as random effects:
>> Batch (categorical)
>>
>> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
>>
>> Altogether, my model is:
>>
>> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue 
>> +
>> (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(),
>> control=glmerControl(optCtrl=list(maxfun=1e9) ) )
>>
>> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
>>
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   unable to evaluate scaled gradient
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge: degenerate  Hessian with 1 negative 
>> eigenvalues
>>
>> To address this:
>>
>> 1) I've centered and scaled my continous predictors
>>
>> 2) I've checked for singularity #False
>>
>> 3) I've printed and compared with internal calculations
>>
>> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
>>
>>
>>> ss$ fixef ## extract fixed effects
>>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
>> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
>> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
>> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
>> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
>> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>>
>>
>>> ss$ llik ## log-likelihoods
>>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
>>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
>>
>>> ss$ sdcor ## SDs and correlations
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>
>>> ss$ theta ## Cholesky factors
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>> ss$ which.OK ## which fits worked
>>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
>>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
>>
>>
>> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
>>
>> Thanks,
>>
>> Umber
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker at gmail.com  Wed Oct  4 00:41:04 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Oct 2017 18:41:04 -0400
Subject: [R-sig-ME] adding objects into "glmerMod" fits
In-Reply-To: <20171003233931.Horde.SAdazIRk4QhdKERT1z5vjWV@webmail.unipa.it>
References: <20171003233931.Horde.SAdazIRk4QhdKERT1z5vjWV@webmail.unipa.it>
Message-ID: <CABghstSDRjUj+m7_rGyDvT9udj24WdFvO=8qhO-iD4O44HJY6Q@mail.gmail.com>

  Unfortunately for you, S4 classes are much fussier than S3 classes
about their composition.  Your only choices, I think, are

(1) modify the definition of a glmerMod (by copying the entire code of
the package, or forking it on Github)
(2) construct a class that extends the glmerMod  (i.e with
setClass("myGlmerMod", contains="glmerMod"))

e.g.

 setClass("myGlmerMod",contains="glmerMod",representation(new="data.frame"))

seems to work - at least it doesn't complain.

(3) add the additional information as one or more attributes

On Tue, Oct 3, 2017 at 5:39 PM, Vito Michele Rosario Muggeo
<vito.muggeo at unipa.it> wrote:
> dear all,
> for some reasons I would like to add some new components (vectors, matrices)
> to a "glmerMod" fit. I am not familiar with S4, so borrowing from S3 classes
> my first tentative was
>
> o <- glmer(y ~ ..)
> o at new<-1:3
>
> But it clearly does not work. Is there any solution?
> thanks in advance for your time,
> best,
> vito
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From singmann at psychologie.uzh.ch  Wed Oct  4 12:34:01 2017
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Wed, 4 Oct 2017 12:34:01 +0200
Subject: [R-sig-ME] adding objects into "glmerMod" fits
In-Reply-To: <CABghstSDRjUj+m7_rGyDvT9udj24WdFvO=8qhO-iD4O44HJY6Q@mail.gmail.com>
References: <20171003233931.Horde.SAdazIRk4QhdKERT1z5vjWV@webmail.unipa.it>
 <CABghstSDRjUj+m7_rGyDvT9udj24WdFvO=8qhO-iD4O44HJY6Q@mail.gmail.com>
Message-ID: <866096bc-17c4-4917-99eb-d7856b631572@psychologie.uzh.ch>

FWIW, the approach of extending the class via setClass is also the one 
taken by lmerTest. And lmerTest works quite well. See:
https://github.com/cran/lmerTest/blob/master/R/classes.R

Best,
Henrik


Am 04.10.2017 um 00:41 schrieb Ben Bolker:
>    Unfortunately for you, S4 classes are much fussier than S3 classes
> about their composition.  Your only choices, I think, are
> 
> (1) modify the definition of a glmerMod (by copying the entire code of
> the package, or forking it on Github)
> (2) construct a class that extends the glmerMod  (i.e with
> setClass("myGlmerMod", contains="glmerMod"))
> 
> e.g.
> 
>   setClass("myGlmerMod",contains="glmerMod",representation(new="data.frame"))
> 
> seems to work - at least it doesn't complain.
> 
> (3) add the additional information as one or more attributes
> 
> On Tue, Oct 3, 2017 at 5:39 PM, Vito Michele Rosario Muggeo
> <vito.muggeo at unipa.it> wrote:
>> dear all,
>> for some reasons I would like to add some new components (vectors, matrices)
>> to a "glmerMod" fit. I am not familiar with S4, so borrowing from S3 classes
>> my first tentative was
>>
>> o <- glmer(y ~ ..)
>> o at new<-1:3
>>
>> But it clearly does not work. Is there any solution?
>> thanks in advance for your time,
>> best,
>> vito
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Mon Oct  2 02:25:58 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 1 Oct 2017 20:25:58 -0400
Subject: [R-sig-ME] specifying crossed random effects for glmmPQL / lme
In-Reply-To: <CAOQn1wW27+DymtS=aNJ16GjYJ0AdMERhWNXAzvNDY-0FYvFevA@mail.gmail.com>
References: <CAOQn1wW27+DymtS=aNJ16GjYJ0AdMERhWNXAzvNDY-0FYvFevA@mail.gmail.com>
Message-ID: <7da5e74a-4019-55d3-0d48-e39129cbc8ac@gmail.com>


  There are a few issues here: see comments inline.

On 17-09-26 05:03 PM, Van Rynald Liceralde wrote:
> Hello,
> 
> I'm trying to fit a GLMM on simulated response time data (continuous,
> positively skewed) obtained from hypothetical participants (Subject)
> responding to the same set of hypothetical items (Item), so it's a
> fully-crossed design. I intend to include several crossed-random effects
> for Subject and Item, so in lme4 language, it would look like the following:
> 
> glmer(y ~ x1*x2*z1 + (1+x1+x2|Subject) + (1|Item),
> family=Gamma("identity"), data=foo)

   I've seen the arguments that say that one should use a Gamma with
identity link for response time data; I didn't find them 100%
convincing, but whatever (can someone remind me of the reference?)
Nevertheless, be aware that fitting models where the link function
doesn't constrain the predicted value to to the domain of the specified
probability distribution (e.g. Gamma/inverse, Gamma/identity,
binomial/identity ...) is much more likely to be computationally
problematic.

> However, as I read from Ben Bolker's GLMM FAQ (
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#fn1), the
> estimation procedure used by glmer (adaptive Gauss-Hermite quadrature) can
> only handle up to 2-3 random effects. Indeed, running glmer on my simulated
> data not only results in inevitable non-convergence but also takes such a
> long time to run.

  AGHQ is not glmer's default; Laplace (equivalently, AGHQ with a single
quadrature point) is.
> Someone recommended to me to use MASS::glmmPQL instead because the cases in
> which penalized quasi-likelihood (PQL) would perform poorly (count/binomial
> DV, mean DV < 5) doesn't apply to my data (continuous DV, identity link,
> many items, and many subjects). Moreover, PQL could handle more random
> effects than GHQ; it could also allow for correlations of random effects to
> be estimated; and it estimates the model faster than GHQ. (I don't actually
> know about any of those being accurate characterizations of PQL and GHQ;
> would be happy to be corrected and pointed to the right direction.)

  The underlying characteristic for whether glmmPQL works well is how
close the sampling distributions of the conditional modes are to being
Gaussian. This generally fails badly in settings where there is little
information on each cluster, which is true for low-count data; I'm not
quite sure how "information per observation" maps onto the Gamma
distribution, although very small shape parameters/skewed distributions
would probably be worse than approximately Normal responses. If you have
many items per subject you're probably OK.

 It is certainly true that where it is sufficiently accurate, PQL is
faster than Laplace or AGHQ.  I'm not sure what you mean by "also allow
for correlations of random effects to be estimated" ...


> 
> The solution suggested online on CrossValidated is as follows:
> 
>> bar <- glmmPQL(y ~ x1*x2*z1, random=list(Subject=~1+x1+x2, Item=~1),
>                  family=Gamma("identity"),data=foo)
> 
> but this way of doing it seems to model the random effect for Item as if it
> was nested under Subject, but I want them to be identified as crossed. I
> was wondering if someone can point me to how I'd be able to specify my
> model using glmmPQL such that the effects of Subject and Item are truly
> crossed. Thank you so much!

   Unfortunately crossed effects are rather challenging to implement in
nlme (the platform underlying glmmPQL). There is one example in one of
the later chapters of Pinheiro and Bates (2000), but I'm not in a
position to look it up right now ...

> 
> Sincerely,
> Van Liceralde
>


From jmichaelrosenberg at gmail.com  Wed Oct  4 17:37:44 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Wed, 4 Oct 2017 11:37:44 -0400
Subject: [R-sig-ME]
	https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
Message-ID: <CANYHYTTdKauDXjgzA-Ghy=dnEUfgJG+UPWMMM4UqtLXxR13k7g@mail.gmail.com>

Hi R-Sig-mixed-models,

My question is about the use of predictions of effects for specific units
(such as an individual in the case of repeated measures data) in other
models. I'm especially interested in whether the group thinks this is a
good / useful approach for using repeated measures data to predict a
longer-term outcome. I am also interested in whether the group has any
suggestions for betters way to do this (or to combine what now requires two
models).

For example, were individual-level predicted effects to be obtained from a
mixed effects model (through a null model, i.e. there is random intercept
for individuals and no fixed effect), could they be used to predict an
individual-level outcome?

I am thinking about this specifically in the context of repeated measures
data (collected using Experience Sampling Method, or ESM, whereby students
are asked every so often to respond to questions about their interest and
engagement) and pre- and post-survey measures, representing a longer-term
outcome, students' self-reported interest in a STEM career.

Here is how I am thinking about this, using lmer() and lm() to specify the
models:

m1 <- lmer(repeated_measures_outcome ~ 1 + (1 | participant), data)


Process the data to obtain the predicted intercept for each participant.

m2 <- lm(longer_term_outcome ~ prior_level_of_longer_term_outcome +
predicted_intercept_for_participant)


When I have shared this idea with others (i.e., in this Stack Overflow
question) I have received feedback that a) yes, you can do this and b) you
could / should combine the two models (m1 and m2 in this example) into one
model. This would (obviously?) require using a different approach - but I
do not have a clear idea of what this would require (MCMCglmm? brms?).

Any general or specific advice is welcomed. Thank you for your
consideration of this. If I can or need to provide more detail or
background, then please do not hesitate to tell me so!

Josh

-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
&
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From udube at wustl.edu  Wed Oct  4 19:12:06 2017
From: udube at wustl.edu (Dube, Umber)
Date: Wed, 4 Oct 2017 17:12:06 +0000
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <BY1PR09MB05338F5ECB0E060575CFE3219A720@BY1PR09MB0533.namprd09.prod.outlook.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>
 <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CABghstQ0P59Yh+9im0LY4g4rk82t0UAxPdUt=0BohuOBveAmCw@mail.gmail.com>,
 <BY1PR09MB05338F5ECB0E060575CFE3219A720@BY1PR09MB0533.namprd09.prod.outlook.com>
Message-ID: <MWHPR0201MB3513C53EE4CFB27C8252BA37AA730@MWHPR0201MB3513.namprd02.prod.outlook.com>

Thanks.


---


David,


I only have 3 species after dropping the one for which I had incomplete data. Adding the term species:tissue doesn't seem to impact my results .



Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +
    (1 | batch) + (1 | Tissue:Organ) + Gene_scale
   Data: regress_MSBB
Control: glmerControl(optCtrl = list(maxfun = 1e+09))

     AIC      BIC   logLik deviance df.resid
   741.9    800.4   -357.9    715.9      653

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.2476 -0.7030  0.3109  0.6412  3.5852

Random effects:
 Groups                            Name        Variance  Std.Dev.
 Tissue:Organ (Intercept) 0.0001335 0.01155
 batch                             (Intercept) 0.3555065 0.59624
Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28

Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)
(Intercept)        0.3087     0.3000   1.029  0.30348
RIN_scale         -0.3812     0.1290  -2.956  0.00312 **
SEXF               0.4868     0.2030   2.398  0.01650 *
AOD_scale         -0.1094     0.1039  -1.053  0.29217
PMI_scale         -0.5463     0.1081  -5.055 4.31e-07 ***
Species1             -0.1406     0.2891  -0.486  0.62680
Species2             -1.5740     0.3873  -4.064 4.83e-05 ***
Tissue1  -0.2696     0.3788  -0.712  0.47660
Tissue2  -0.1634     0.3661  -0.446  0.65528
Tissue3   0.6631     0.4109   1.614  0.10661
Gene_scale      -0.8184     0.1250  -6.548 5.85e-11 ***




Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +
    (1 | batch) + (1 | Tissue:Organ) + Species:Tissue +      Gene_scale
   Data: regress_MSBB
Control: glmerControl(optCtrl = list(maxfun = 1e+09))

     AIC      BIC   logLik deviance df.resid
   751.7    837.2   -356.8    713.7      647

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.2554 -0.7252  0.3088  0.6355  3.6163

Random effects:
 Groups                            Name        Variance  Std.Dev.
 Tissue:Organ (Intercept) 0.0005321 0.02307
 batch                             (Intercept) 0.3613201 0.60110
Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28

Fixed effects:
                       Estimate Std. Error z value Pr(>|z|)
(Intercept)             0.29375    0.31057   0.946  0.34423
RIN_scale              -0.38955    0.13092  -2.975  0.00293 **
SEXF                    0.48576    0.20366   2.385  0.01707 *
AOD_scale              -0.10533    0.10418  -1.011  0.31199
PMI_scale              -0.54720    0.10877  -5.031 4.88e-07 ***
Species1                  -0.09427    0.55332  -0.170  0.86472
Species2                  -1.35744    0.68746  -1.975  0.04832 *
Tissue1       -0.32254    0.40243  -0.801  0.42286
Tissue2       -0.14617    0.39294  -0.372  0.70989
Tissue3        0.76621    0.43232   1.772  0.07634 .
Gene_scale           -0.81542    0.12527  -6.509 7.56e-11 ***
Species1:Tissue1  0.17224    0.80081   0.215  0.82971
Species2:Tissue1  0.42202    1.00304   0.421  0.67395
Species1:Tissue2  0.02979    0.78221   0.038  0.96962
Species2:Tissue2 -0.49815    1.08503  -0.459  0.64616
Species1:Tissue3 -0.39867    0.80706  -0.494  0.62132
Species2:Tissue3 -1.03753    1.16070  -0.894  0.37139



---


All,


1) I have been trying to use a very similar model in a lmer for a continuous variable, weight of the organ as a proxy for disease. However, I get an error when I try and run the following model:
lmer(Weight ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species+ Tissue + (1|batch) + (1|Tissue:Organ) + Gene_scale, data=regress_MSBB, family=gaussian(), control=lmerControl(optCtrl=list(maxfun=1e9) ) )


Error: number of levels of each grouping factor must be < number of observations


This error goes away when I drop the (1|Tissue:Organ) term, but I'm concerned that I am no longer faithfully modeling the random effects in doing so.


Does anyone have advice with how to deal with this error?


2) Should I be including Gene expression in front of the | in my random effect terms if I believe that the change in gene expression between disease and healthy are different in the different tissues? If so, should I be including a term for (GeneExpression|Tissue) in addition to Tissue + (1|Tissue:Organ)? I know I can't use (GeneExpression|Tissue:Organ) as this produces the following error: Error: number of observations (=666) < number of random effects (=1332).



Thanks,


Umber

________________________________
From: Farrar, David <Farrar.David at epa.gov>
Sent: Tuesday, October 3, 2017 5:04:42 PM
To: Ben Bolker; Dube, Umber
Cc: r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
Subject: RE: [R-sig-ME] Questions about design and convergence warnings

Hi,
I would like to check my intuition on the number of levels needed for a random effect.  I think of this basically in terms of the split plot design, with fixed effects that vary either within whole plots or among whole plots.  In the real world, I wouldn't expect that clean a breakdown.  You need a bunch of levels if the variance is inherently interesting.   If you are trying to evaluate some fixed effect, it seems like you are concerned with whether that effect varies primarily among levels of the random effect, or primarily within levels.  In the 2nd case, it seems to me that you wouldn't need many levels for the random effect.   This is just my intuition.   I am interested in how good it is and whether it can be related to mathematical results.
Regards,
David


-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com]
Sent: Tuesday, October 03, 2017 5:34 PM
To: Dube, Umber <udube at wustl.edu>
Cc: Farrar, David <Farrar.David at epa.gov>; r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
Subject: Re: [R-sig-ME] Questions about design and convergence warnings

On Tue, Oct 3, 2017 at 4:50 PM, Dube, Umber <udube at wustl.edu> wrote:
> Thanks for your responses.
>
> Thierry,
>
> The first case is correct. For example, the skin is an organ and the different layers of the skin (epidermis, dermis, and hypodermis) can be considered tissues. So in my experiment I have collected the same tissues originating from different organs which are either healthy or diseased.
>
> Good call on the species effect. I've dropped one of the species for whom I had only healthy data. This has resulted in fewer convergence warnings as I perform the glmer with each gene. I've also noticed that even those genes for which I do produce convergence warnings will converge if I try using other optimizers. I understand this provides additional evidence to support the warnings being false positives.
>
> ---
>
> David,
>
> I hadn't considered that. If I'm understanding correctly, you would recommend including species:tissue in my model?
>
> ---
>
> All,
>
> Is it appropriate to model batch as a random effect, or should I include it as a fixed effect?


  Haven't followed the thread carefully, but: typically an exchangeable factor such as batch (i.e., relabeling the batches wouldn't change anything about their meaning) is _philosophically_ a random effect, but if you have too few levels (batches) to reliably estimate among-batch variance (e.g. <5) you might choose to treat it as a fixed effect instead (or use a Bayesian method that allows you to specify a prior on the among-batch variance ...)

>
>
> Thanks,
>
> Umber
>
>
> ________________________________
> From: Farrar, David <Farrar.David at epa.gov>
> Sent: Monday, October 2, 2017 1:21:45 PM
> To: Dube, Umber
> Subject: RE: [R-sig-ME] Questions about design and convergence
> warnings
>
> Dear Umber,
> It seems your model would not support a conclusion that the effect on a certain tissue would depend on the species, an interaction.
> Is that intentional?
> David
>
> -----Original Message-----
> From: R-sig-mixed-models
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thierry
> Onkelinx
> Sent: Friday, September 29, 2017 7:35 AM
> To: Dube, Umber <udube at wustl.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Questions about design and convergence
> warnings
>
> Dear Umber,
>
> Can you clarify what a tissue is? Distinct parts of an organ (tissue 1 for organ 1 refers to the same part as tissue 1 for organ 2)? Or merely different samples for the same organ (no link between tissue 1 between organs). Tissue as random effect is only relevant in the first case. In the latter case is depends on the number of replicates per tissue:organ. In case of one replication go for (1|Organ), in case of multiple replications go for (1|Organ/Tissue).
>
> It looks like you have very strong species effects. That is an indication for quasi-complete separation, which can trigger convergence warnings.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus/ Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
> & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be Kliniekstraat 25, B-1070 Brussel
> www.inbo.be<http://www.inbo.be>
>
> //////////////////////////////////////////////////////////////////////
> ///////////////////// To call in the statistician after the experiment
> is done may be no more than asking him to perform a post-mortem
> examination: he may be able to say what the experiment died of. ~ Sir
> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
> Brinner The combination of some data and an aching desire for an
> answer does not ensure that a reasonable answer can be extracted from
> a given body of data. ~ John Tukey
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
>
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
>
> 2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu>:
>> Thanks for your continued development of lme4 and all the support you've provided.
>>
>> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
>>
>> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
>>
>> I have been modelling the following as fixed effects:
>> RNA Integrity Number (RIN) - quality of the total RNA extracted from
>> each tissues (continuous) Post-mortem Interval (PMI) - how much time
>> elapsed following death until the tissue was frozen (continuous) Sex
>> - genetic sex of the organ (categorical) Age at death (AOD) - age of
>> organ at death (continuous) Species - species of organ (categorical)
>> Gene -  normalized count data of gene expression (continuous)
>>
>> I have been modelling the following as random effects:
>> Batch (categorical)
>>
>> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
>>
>> Altogether, my model is:
>>
>> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue
>> +
>> (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(),
>> control=glmerControl(optCtrl=list(maxfun=1e9) ) )
>>
>> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
>>
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   unable to evaluate scaled gradient
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge: degenerate  Hessian with 1 negative
>> eigenvalues
>>
>> To address this:
>>
>> 1) I've centered and scaled my continous predictors
>>
>> 2) I've checked for singularity #False
>>
>> 3) I've printed and compared with internal calculations
>>
>> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
>>
>>
>>> ss$ fixef ## extract fixed effects
>>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
>> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
>> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
>> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
>> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
>> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>>
>>
>>> ss$ llik ## log-likelihoods
>>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
>>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
>>
>>> ss$ sdcor ## SDs and correlations
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>
>>> ss$ theta ## Cholesky factors
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>> ss$ which.OK ## which fits worked
>>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
>>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
>>
>>
>> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
>>
>> Thanks,
>>
>> Umber
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From T.Houslay at exeter.ac.uk  Wed Oct  4 19:45:20 2017
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Wed, 4 Oct 2017 17:45:20 +0000
Subject: [R-sig-ME]
 https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
In-Reply-To: <mailman.720.1507137139.1577.r-sig-mixed-models@r-project.org>
References: <mailman.720.1507137139.1577.r-sig-mixed-models@r-project.org>
Message-ID: <AM0PR0302MB33631B144E703C6A42EDB2E9D2730@AM0PR0302MB3363.eurprd03.prod.outlook.com>

Hi Josh,


It sounds like you would be better off using a bivariate model (I'm assuming this was where you were headed with 'combining' the models?), where your response variables are something like 'ESM' and 'Outcome'. You could have these grouped by individual ID, and (having controlled for any fixed effects on either response) calculate the among-individual variation in each response and the covariance between them (which can be scaled to a correlation). As you're effectively modelling the relationship between two response variables then I think this makes sense, and avoids discarding the error associated with predictions from a previous model.


If you have repeated measures for both ESM and Outcome, but these were not measured at the same time, you might have data something like the following:


ID --- Repeat --- ESM --- Outcome

A --- 1 --- 12 --- NA

A --- 2 --- 19 --- NA

A --- 3 --- 14 --- NA

A --- 1 --- NA --- 15

A --- 2 --- NA --- 9

B ...


etc


In which case you could calculate both among-individual and residual variation for both traits, but only the among-individual covariance (as you don't have observations of both responses at the same time to estimate the residual/'within-individual' covariance).


Note that if you only had a single observation for 'Outcome', you would simply constrain the residual variation for this trait to be 0 (such that all variation is modelled as 'among-individual').


In case they're useful, we have a brief paper related to this topic in Behavioural Ecology here:

https://doi.org/10.1093/beheco/arx023


...and some tutorials for these kinds of models in MCMCglmm / ASreml-R here:

https://tomhouslay.com/tutorials/


This paper on comparing behaviours measured repeatedly in both short- and long-term sampling regimes might also be of interest:

https://link.springer.com/article/10.1007/s00265-014-1692-0


Good luck!


Tom



Date: Wed, 4 Oct 2017 11:37:44 -0400
From: Joshua Rosenberg <jmichaelrosenberg at gmail.com>
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME]
        https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763

Message-ID:
        <CANYHYTTdKauDXjgzA-Ghy=dnEUfgJG+UPWMMM4UqtLXxR13k7g at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hi R-Sig-mixed-models,

My question is about the use of predictions of effects for specific units
(such as an individual in the case of repeated measures data) in other
models. I'm especially interested in whether the group thinks this is a
good / useful approach for using repeated measures data to predict a
longer-term outcome. I am also interested in whether the group has any
suggestions for betters way to do this (or to combine what now requires two
models).

For example, were individual-level predicted effects to be obtained from a
mixed effects model (through a null model, i.e. there is random intercept
for individuals and no fixed effect), could they be used to predict an
individual-level outcome?

I am thinking about this specifically in the context of repeated measures
data (collected using Experience Sampling Method, or ESM, whereby students
are asked every so often to respond to questions about their interest and
engagement) and pre- and post-survey measures, representing a longer-term
outcome, students' self-reported interest in a STEM career.

Here is how I am thinking about this, using lmer() and lm() to specify the
models:

m1 <- lmer(repeated_measures_outcome ~ 1 + (1 | participant), data)


Process the data to obtain the predicted intercept for each participant.

m2 <- lm(longer_term_outcome ~ prior_level_of_longer_term_outcome +
predicted_intercept_for_participant)


When I have shared this idea with others (i.e., in this Stack Overflow
question) I have received feedback that a) yes, you can do this and b) you
could / should combine the two models (m1 and m2 in this example) into one
model. This would (obviously?) require using a different approach - but I
do not have a clear idea of what this would require (MCMCglmm? brms?).

Any general or specific advice is welcomed. Thank you for your
consideration of this. If I can or need to provide more detail or
background, then please do not hesitate to tell me so!

Josh

--
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
&
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

        [[alternative HTML version deleted]]




	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Wed Oct  4 20:16:27 2017
From: Farrar.David at epa.gov (Farrar, David)
Date: Wed, 4 Oct 2017 18:16:27 +0000
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <MWHPR0201MB3513C53EE4CFB27C8252BA37AA730@MWHPR0201MB3513.namprd02.prod.outlook.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>
 <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CABghstQ0P59Yh+9im0LY4g4rk82t0UAxPdUt=0BohuOBveAmCw@mail.gmail.com>,
 <BY1PR09MB05338F5ECB0E060575CFE3219A720@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB3513C53EE4CFB27C8252BA37AA730@MWHPR0201MB3513.namprd02.prod.outlook.com>
Message-ID: <BY1PR09MB053321C4B18525623418FA269A730@BY1PR09MB0533.namprd09.prod.outlook.com>


Although I don't know your situation scientifically, tissues and organs or combinations thereof don't strike me as reasonable random effects.
It might be helpful if you would state one or more biological hypothesis, which would then as a rule involve fixed effects.  I like an old rule that goes like this.   Imagine telling someone how to repeat your study.   Would you tell them which organs and tissues should be involved?  (Then probably fixed.)  Or could you just say "it doesn't really matter - just get a respectable number of tissues (etc.)."   (Then perhaps random.)

From: Dube, Umber [mailto:udube at wustl.edu]
Sent: Wednesday, October 04, 2017 1:12 PM
To: Farrar, David <Farrar.David at epa.gov>; Ben Bolker <bbolker at gmail.com>
Cc: r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
Subject: Re: [R-sig-ME] Questions about design and convergence warnings


Thanks.



---



David,



I only have 3 species after dropping the one for which I had incomplete data. Adding the term species:tissue doesn't seem to impact my results .





Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']

 Family: binomial  ( logit )

Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +

    (1 | batch) + (1 | Tissue:Organ) + Gene_scale

   Data: regress_MSBB

Control: glmerControl(optCtrl = list(maxfun = 1e+09))



     AIC      BIC   logLik deviance df.resid

   741.9    800.4   -357.9    715.9      653



Scaled residuals:

    Min      1Q  Median      3Q     Max

-3.2476 -0.7030  0.3109  0.6412  3.5852



Random effects:

 Groups                            Name        Variance  Std.Dev.

 Tissue:Organ (Intercept) 0.0001335 0.01155

 batch                             (Intercept) 0.3555065 0.59624

Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28



Fixed effects:

                 Estimate Std. Error z value Pr(>|z|)

(Intercept)        0.3087     0.3000   1.029  0.30348

RIN_scale         -0.3812     0.1290  -2.956  0.00312 **

SEXF               0.4868     0.2030   2.398  0.01650 *

AOD_scale         -0.1094     0.1039  -1.053  0.29217

PMI_scale         -0.5463     0.1081  -5.055 4.31e-07 ***

Species1             -0.1406     0.2891  -0.486  0.62680

Species2             -1.5740     0.3873  -4.064 4.83e-05 ***

Tissue1  -0.2696     0.3788  -0.712  0.47660

Tissue2  -0.1634     0.3661  -0.446  0.65528

Tissue3   0.6631     0.4109   1.614  0.10661

Gene_scale      -0.8184     0.1250  -6.548 5.85e-11 ***









Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']

 Family: binomial  ( logit )

Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +

    (1 | batch) + (1 | Tissue:Organ) + Species:Tissue +      Gene_scale

   Data: regress_MSBB

Control: glmerControl(optCtrl = list(maxfun = 1e+09))



     AIC      BIC   logLik deviance df.resid

   751.7    837.2   -356.8    713.7      647



Scaled residuals:

    Min      1Q  Median      3Q     Max

-3.2554 -0.7252  0.3088  0.6355  3.6163



Random effects:

 Groups                            Name        Variance  Std.Dev.

 Tissue:Organ (Intercept) 0.0005321 0.02307

 batch                             (Intercept) 0.3613201 0.60110

Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28



Fixed effects:

                       Estimate Std. Error z value Pr(>|z|)

(Intercept)             0.29375    0.31057   0.946  0.34423

RIN_scale              -0.38955    0.13092  -2.975  0.00293 **

SEXF                    0.48576    0.20366   2.385  0.01707 *

AOD_scale              -0.10533    0.10418  -1.011  0.31199

PMI_scale              -0.54720    0.10877  -5.031 4.88e-07 ***

Species1                  -0.09427    0.55332  -0.170  0.86472

Species2                  -1.35744    0.68746  -1.975  0.04832 *

Tissue1       -0.32254    0.40243  -0.801  0.42286

Tissue2       -0.14617    0.39294  -0.372  0.70989

Tissue3        0.76621    0.43232   1.772  0.07634 .

Gene_scale           -0.81542    0.12527  -6.509 7.56e-11 ***

Species1:Tissue1  0.17224    0.80081   0.215  0.82971

Species2:Tissue1  0.42202    1.00304   0.421  0.67395

Species1:Tissue2  0.02979    0.78221   0.038  0.96962

Species2:Tissue2 -0.49815    1.08503  -0.459  0.64616

Species1:Tissue3 -0.39867    0.80706  -0.494  0.62132

Species2:Tissue3 -1.03753    1.16070  -0.894  0.37139





---



All,



1) I have been trying to use a very similar model in a lmer for a continuous variable, weight of the organ as a proxy for disease. However, I get an error when I try and run the following model:
lmer(Weight ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species+ Tissue + (1|batch) + (1|Tissue:Organ) + Gene_scale, data=regress_MSBB, family=gaussian(), control=lmerControl(optCtrl=list(maxfun=1e9) ) )



Error: number of levels of each grouping factor must be < number of observations



This error goes away when I drop the (1|Tissue:Organ) term, but I'm concerned that I am no longer faithfully modeling the random effects in doing so.



Does anyone have advice with how to deal with this error?



2) Should I be including Gene expression in front of the | in my random effect terms if I believe that the change in gene expression between disease and healthy are different in the different tissues? If so, should I be including a term for (GeneExpression|Tissue) in addition to Tissue + (1|Tissue:Organ)? I know I can't use (GeneExpression|Tissue:Organ) as this produces the following error: Error: number of observations (=666) < number of random effects (=1332).





Thanks,



Umber

________________________________
From: Farrar, David <Farrar.David at epa.gov<mailto:Farrar.David at epa.gov>>
Sent: Tuesday, October 3, 2017 5:04:42 PM
To: Ben Bolker; Dube, Umber
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>; thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Subject: RE: [R-sig-ME] Questions about design and convergence warnings

Hi,
I would like to check my intuition on the number of levels needed for a random effect.  I think of this basically in terms of the split plot design, with fixed effects that vary either within whole plots or among whole plots.  In the real world, I wouldn't expect that clean a breakdown.  You need a bunch of levels if the variance is inherently interesting.   If you are trying to evaluate some fixed effect, it seems like you are concerned with whether that effect varies primarily among levels of the random effect, or primarily within levels.  In the 2nd case, it seems to me that you wouldn't need many levels for the random effect.   This is just my intuition.   I am interested in how good it is and whether it can be related to mathematical results.
Regards,
David


-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com]
Sent: Tuesday, October 03, 2017 5:34 PM
To: Dube, Umber <udube at wustl.edu<mailto:udube at wustl.edu>>
Cc: Farrar, David <Farrar.David at epa.gov<mailto:Farrar.David at epa.gov>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>; thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Subject: Re: [R-sig-ME] Questions about design and convergence warnings

On Tue, Oct 3, 2017 at 4:50 PM, Dube, Umber <udube at wustl.edu<mailto:udube at wustl.edu>> wrote:
> Thanks for your responses.
>
> Thierry,
>
> The first case is correct. For example, the skin is an organ and the different layers of the skin (epidermis, dermis, and hypodermis) can be considered tissues. So in my experiment I have collected the same tissues originating from different organs which are either healthy or diseased.
>
> Good call on the species effect. I've dropped one of the species for whom I had only healthy data. This has resulted in fewer convergence warnings as I perform the glmer with each gene. I've also noticed that even those genes for which I do produce convergence warnings will converge if I try using other optimizers. I understand this provides additional evidence to support the warnings being false positives.
>
> ---
>
> David,
>
> I hadn't considered that. If I'm understanding correctly, you would recommend including species:tissue in my model?
>
> ---
>
> All,
>
> Is it appropriate to model batch as a random effect, or should I include it as a fixed effect?


  Haven't followed the thread carefully, but: typically an exchangeable factor such as batch (i.e., relabeling the batches wouldn't change anything about their meaning) is _philosophically_ a random effect, but if you have too few levels (batches) to reliably estimate among-batch variance (e.g. <5) you might choose to treat it as a fixed effect instead (or use a Bayesian method that allows you to specify a prior on the among-batch variance ...)

>
>
> Thanks,
>
> Umber
>
>
> ________________________________
> From: Farrar, David <Farrar.David at epa.gov<mailto:Farrar.David at epa.gov>>
> Sent: Monday, October 2, 2017 1:21:45 PM
> To: Dube, Umber
> Subject: RE: [R-sig-ME] Questions about design and convergence
> warnings
>
> Dear Umber,
> It seems your model would not support a conclusion that the effect on a certain tissue would depend on the species, an interaction.
> Is that intentional?
> David
>
> -----Original Message-----
> From: R-sig-mixed-models
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thierry
> Onkelinx
> Sent: Friday, September 29, 2017 7:35 AM
> To: Dube, Umber <udube at wustl.edu<mailto:udube at wustl.edu>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Questions about design and convergence
> warnings
>
> Dear Umber,
>
> Can you clarify what a tissue is? Distinct parts of an organ (tissue 1 for organ 1 refers to the same part as tissue 1 for organ 2)? Or merely different samples for the same organ (no link between tissue 1 between organs). Tissue as random effect is only relevant in the first case. In the latter case is depends on the number of replicates per tissue:organ. In case of one replication go for (1|Organ), in case of multiple replications go for (1|Organ/Tissue).
>
> It looks like you have very strong species effects. That is an indication for quasi-complete separation, which can trigger convergence warnings.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus/ Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
> & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be> Kliniekstraat 25, B-1070 Brussel
> www.inbo.be<http://www.inbo.be>
>
> //////////////////////////////////////////////////////////////////////
> ///////////////////// To call in the statistician after the experiment
> is done may be no more than asking him to perform a post-mortem
> examination: he may be able to say what the experiment died of. ~ Sir
> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
> Brinner The combination of some data and an aching desire for an
> answer does not ensure that a reasonable answer can be extracted from
> a given body of data. ~ John Tukey
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
>
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
>
> 2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu<mailto:udube at wustl.edu>>:
>> Thanks for your continued development of lme4 and all the support you've provided.
>>
>> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
>>
>> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
>>
>> I have been modelling the following as fixed effects:
>> RNA Integrity Number (RIN) - quality of the total RNA extracted from
>> each tissues (continuous) Post-mortem Interval (PMI) - how much time
>> elapsed following death until the tissue was frozen (continuous) Sex
>> - genetic sex of the organ (categorical) Age at death (AOD) - age of
>> organ at death (continuous) Species - species of organ (categorical)
>> Gene -  normalized count data of gene expression (continuous)
>>
>> I have been modelling the following as random effects:
>> Batch (categorical)
>>
>> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
>>
>> Altogether, my model is:
>>
>> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue
>> +
>> (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(),
>> control=glmerControl(optCtrl=list(maxfun=1e9) ) )
>>
>> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
>>
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   unable to evaluate scaled gradient
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge: degenerate  Hessian with 1 negative
>> eigenvalues
>>
>> To address this:
>>
>> 1) I've centered and scaled my continous predictors
>>
>> 2) I've checked for singularity #False
>>
>> 3) I've printed and compared with internal calculations
>>
>> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
>>
>>
>>> ss$ fixef ## extract fixed effects
>>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
>> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
>> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
>> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
>> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
>> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>>
>>
>>> ss$ llik ## log-likelihoods
>>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
>>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
>>
>>> ss$ sdcor ## SDs and correlations
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>
>>> ss$ theta ## Cholesky factors
>>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>>         bobyqa  3.68E-05        0.520826
>>         Nelder_Mead     5.56E-03        0.52084
>>         nlminbw 3.10E-08        0.520826
>>         optimx.L-BFGS-B 0.00E+00        0.52084
>>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
>>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>>
>>
>>> ss$ which.OK ## which fits worked
>>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
>>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
>>
>>
>> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
>>
>> Thanks,
>>
>> Umber
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Oct  4 21:10:27 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 4 Oct 2017 21:10:27 +0200
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <MWHPR0201MB3513C53EE4CFB27C8252BA37AA730@MWHPR0201MB3513.namprd02.prod.outlook.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>
 <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CABghstQ0P59Yh+9im0LY4g4rk82t0UAxPdUt=0BohuOBveAmCw@mail.gmail.com>
 <BY1PR09MB05338F5ECB0E060575CFE3219A720@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB3513C53EE4CFB27C8252BA37AA730@MWHPR0201MB3513.namprd02.prod.outlook.com>
Message-ID: <CAJuCY5zfc+9OfM+NQfuG9QkiM+rme0oUs6uuHFUPnucVTbcWog@mail.gmail.com>

Dear Umber,

You have a so called observation level random effect (OLRE) because
each combination of tissue and organ has only one level. An OLRE is
only relevant for generalised linear mixed models when you want to use
it to model overdispersion. Often in combination with the Poisson
distribution. Only use an OLRE when you know what you are doing. And
your convergence warnings are a good indicator that an ORLE is not
relevant for your data. Use (1|Organ) as I already recommended you to
do.

I'd go for GeneExpression*Tissue. You don't have enough data to
support (GeneExpression|Organ)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////


2017-10-04 19:12 GMT+02:00 Dube, Umber <udube at wustl.edu>:
>
> Thanks.
>
>
> ---
>
>
> David,
>
>
> I only have 3 species after dropping the one for which I had incomplete data. Adding the term species:tissue doesn't seem to impact my results .
>
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +
>     (1 | batch) + (1 | Tissue:Organ) + Gene_scale
>    Data: regress_MSBB
> Control: glmerControl(optCtrl = list(maxfun = 1e+09))
>
>      AIC      BIC   logLik deviance df.resid
>    741.9    800.4   -357.9    715.9      653
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.2476 -0.7030  0.3109  0.6412  3.5852
>
> Random effects:
>  Groups                            Name        Variance  Std.Dev.
>  Tissue:Organ (Intercept) 0.0001335 0.01155
>  batch                             (Intercept) 0.3555065 0.59624
> Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28
>
> Fixed effects:
>                  Estimate Std. Error z value Pr(>|z|)
> (Intercept)        0.3087     0.3000   1.029  0.30348
> RIN_scale         -0.3812     0.1290  -2.956  0.00312 **
> SEXF               0.4868     0.2030   2.398  0.01650 *
> AOD_scale         -0.1094     0.1039  -1.053  0.29217
> PMI_scale         -0.5463     0.1081  -5.055 4.31e-07 ***
> Species1             -0.1406     0.2891  -0.486  0.62680
> Species2             -1.5740     0.3873  -4.064 4.83e-05 ***
> Tissue1  -0.2696     0.3788  -0.712  0.47660
> Tissue2  -0.1634     0.3661  -0.446  0.65528
> Tissue3   0.6631     0.4109   1.614  0.10661
> Gene_scale      -0.8184     0.1250  -6.548 5.85e-11 ***
>
>
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +
>     (1 | batch) + (1 | Tissue:Organ) + Species:Tissue +      Gene_scale
>    Data: regress_MSBB
> Control: glmerControl(optCtrl = list(maxfun = 1e+09))
>
>      AIC      BIC   logLik deviance df.resid
>    751.7    837.2   -356.8    713.7      647
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.2554 -0.7252  0.3088  0.6355  3.6163
>
> Random effects:
>  Groups                            Name        Variance  Std.Dev.
>  Tissue:Organ (Intercept) 0.0005321 0.02307
>  batch                             (Intercept) 0.3613201 0.60110
> Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28
>
> Fixed effects:
>                        Estimate Std. Error z value Pr(>|z|)
> (Intercept)             0.29375    0.31057   0.946  0.34423
> RIN_scale              -0.38955    0.13092  -2.975  0.00293 **
> SEXF                    0.48576    0.20366   2.385  0.01707 *
> AOD_scale              -0.10533    0.10418  -1.011  0.31199
> PMI_scale              -0.54720    0.10877  -5.031 4.88e-07 ***
> Species1                  -0.09427    0.55332  -0.170  0.86472
> Species2                  -1.35744    0.68746  -1.975  0.04832 *
> Tissue1       -0.32254    0.40243  -0.801  0.42286
> Tissue2       -0.14617    0.39294  -0.372  0.70989
> Tissue3        0.76621    0.43232   1.772  0.07634 .
> Gene_scale           -0.81542    0.12527  -6.509 7.56e-11 ***
> Species1:Tissue1  0.17224    0.80081   0.215  0.82971
> Species2:Tissue1  0.42202    1.00304   0.421  0.67395
> Species1:Tissue2  0.02979    0.78221   0.038  0.96962
> Species2:Tissue2 -0.49815    1.08503  -0.459  0.64616
> Species1:Tissue3 -0.39867    0.80706  -0.494  0.62132
> Species2:Tissue3 -1.03753    1.16070  -0.894  0.37139
>
>
> ---
>
>
> All,
>
>
> 1) I have been trying to use a very similar model in a lmer for a continuous variable, weight of the organ as a proxy for disease. However, I get an error when I try and run the following model:
> lmer(Weight ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species+ Tissue + (1|batch) + (1|Tissue:Organ) + Gene_scale, data=regress_MSBB, family=gaussian(), control=lmerControl(optCtrl=list(maxfun=1e9) ) )
>
>
> Error: number of levels of each grouping factor must be < number of observations
>
>
> This error goes away when I drop the (1|Tissue:Organ) term, but I'm concerned that I am no longer faithfully modeling the random effects in doing so.
>
>
> Does anyone have advice with how to deal with this error?
>
>
> 2) Should I be including Gene expression in front of the | in my random effect terms if I believe that the change in gene expression between disease and healthy are different in the different tissues? If so, should I be including a term for (GeneExpression|Tissue) in addition to Tissue + (1|Tissue:Organ)? I know I can't use (GeneExpression|Tissue:Organ) as this produces the following error: Error: number of observations (=666) < number of random effects (=1332).
>
>
>
> Thanks,
>
>
> Umber
>
> ________________________________
> From: Farrar, David <Farrar.David at epa.gov>
> Sent: Tuesday, October 3, 2017 5:04:42 PM
> To: Ben Bolker; Dube, Umber
> Cc: r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
>
> Subject: RE: [R-sig-ME] Questions about design and convergence warnings
>
> Hi,
> I would like to check my intuition on the number of levels needed for a random effect.  I think of this basically in terms of the split plot design, with fixed effects that vary either within whole plots or among whole plots.  In the real world, I wouldn't expect that clean a breakdown.  You need a bunch of levels if the variance is inherently interesting.   If you are trying to evaluate some fixed effect, it seems like you are concerned with whether that effect varies primarily among levels of the random effect, or primarily within levels.  In the 2nd case, it seems to me that you wouldn't need many levels for the random effect.   This is just my intuition.   I am interested in how good it is and whether it can be related to mathematical results.
> Regards,
> David
>
>
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Tuesday, October 03, 2017 5:34 PM
> To: Dube, Umber <udube at wustl.edu>
> Cc: Farrar, David <Farrar.David at epa.gov>; r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
> Subject: Re: [R-sig-ME] Questions about design and convergence warnings
>
> On Tue, Oct 3, 2017 at 4:50 PM, Dube, Umber <udube at wustl.edu> wrote:
> > Thanks for your responses.
> >
> > Thierry,
> >
> > The first case is correct. For example, the skin is an organ and the different layers of the skin (epidermis, dermis, and hypodermis) can be considered tissues. So in my experiment I have collected the same tissues originating from different organs which are either healthy or diseased.
> >
> > Good call on the species effect. I've dropped one of the species for whom I had only healthy data. This has resulted in fewer convergence warnings as I perform the glmer with each gene. I've also noticed that even those genes for which I do produce convergence warnings will converge if I try using other optimizers. I understand this provides additional evidence to support the warnings being false positives.
> >
> > ---
> >
> > David,
> >
> > I hadn't considered that. If I'm understanding correctly, you would recommend including species:tissue in my model?
> >
> > ---
> >
> > All,
> >
> > Is it appropriate to model batch as a random effect, or should I include it as a fixed effect?
>
>
>   Haven't followed the thread carefully, but: typically an exchangeable factor such as batch (i.e., relabeling the batches wouldn't change anything about their meaning) is _philosophically_ a random effect, but if you have too few levels (batches) to reliably estimate among-batch variance (e.g. <5) you might choose to treat it as a fixed effect instead (or use a Bayesian method that allows you to specify a prior on the among-batch variance ...)
>
> >
> >
> > Thanks,
> >
> > Umber
> >
> >
> > ________________________________
> > From: Farrar, David <Farrar.David at epa.gov>
> > Sent: Monday, October 2, 2017 1:21:45 PM
> > To: Dube, Umber
> > Subject: RE: [R-sig-ME] Questions about design and convergence
> > warnings
> >
> > Dear Umber,
> > It seems your model would not support a conclusion that the effect on a certain tissue would depend on the species, an interaction.
> > Is that intentional?
> > David
> >
> > -----Original Message-----
> > From: R-sig-mixed-models
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thierry
> > Onkelinx
> > Sent: Friday, September 29, 2017 7:35 AM
> > To: Dube, Umber <udube at wustl.edu>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Questions about design and convergence
> > warnings
> >
> > Dear Umber,
> >
> > Can you clarify what a tissue is? Distinct parts of an organ (tissue 1 for organ 1 refers to the same part as tissue 1 for organ 2)? Or merely different samples for the same organ (no link between tissue 1 between organs). Tissue as random effect is only relevant in the first case. In the latter case is depends on the number of replicates per tissue:organ. In case of one replication go for (1|Organ), in case of multiple replications go for (1|Organ/Tissue).
> >
> > It looks like you have very strong species effects. That is an indication for quasi-complete separation, which can trigger convergence warnings.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus/ Statistician
> >
> > Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
> > BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
> > & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be Kliniekstraat 25, B-1070 Brussel
> > www.inbo.be<http://www.inbo.be>
> >
> > //////////////////////////////////////////////////////////////////////
> > ///////////////////// To call in the statistician after the experiment
> > is done may be no more than asking him to perform a post-mortem
> > examination: he may be able to say what the experiment died of. ~ Sir
> > Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
> > Brinner The combination of some data and an aching desire for an
> > answer does not ensure that a reasonable answer can be extracted from
> > a given body of data. ~ John Tukey
> > //////////////////////////////////////////////////////////////////////
> > /////////////////////
> >
> >
> > Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> > Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
> >
> > //////////////////////////////////////////////////////////////////////
> > /////////////////////
> >
> >
> >
> > 2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu>:
> >> Thanks for your continued development of lme4 and all the support you've provided.
> >>
> >> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
> >>
> >> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
> >>
> >> I have been modelling the following as fixed effects:
> >> RNA Integrity Number (RIN) - quality of the total RNA extracted from
> >> each tissues (continuous) Post-mortem Interval (PMI) - how much time
> >> elapsed following death until the tissue was frozen (continuous) Sex
> >> - genetic sex of the organ (categorical) Age at death (AOD) - age of
> >> organ at death (continuous) Species - species of organ (categorical)
> >> Gene -  normalized count data of gene expression (continuous)
> >>
> >> I have been modelling the following as random effects:
> >> Batch (categorical)
> >>
> >> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
> >>
> >> Altogether, my model is:
> >>
> >> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue
> >> +
> >> (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(),
> >> control=glmerControl(optCtrl=list(maxfun=1e9) ) )
> >>
> >> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
> >>
> >> Warning messages:
> >> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >>   unable to evaluate scaled gradient
> >> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >>   Model failed to converge: degenerate  Hessian with 1 negative
> >> eigenvalues
> >>
> >> To address this:
> >>
> >> 1) I've centered and scaled my continous predictors
> >>
> >> 2) I've checked for singularity #False
> >>
> >> 3) I've printed and compared with internal calculations
> >>
> >> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
> >>
> >>
> >>> ss$ fixef ## extract fixed effects
> >>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
> >> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
> >> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
> >> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
> >> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
> >> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
> >> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
> >>
> >>
> >>> ss$ llik ## log-likelihoods
> >>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
> >>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
> >>
> >>> ss$ sdcor ## SDs and correlations
> >>                 Organ:Tissue.(Intercept)        batch.(Intercept)
> >>         bobyqa  3.68E-05        0.520826
> >>         Nelder_Mead     5.56E-03        0.52084
> >>         nlminbw 3.10E-08        0.520826
> >>         optimx.L-BFGS-B 0.00E+00        0.52084
> >>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
> >>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
> >>
> >>
> >>
> >>> ss$ theta ## Cholesky factors
> >>                 Organ:Tissue.(Intercept)        batch.(Intercept)
> >>         bobyqa  3.68E-05        0.520826
> >>         Nelder_Mead     5.56E-03        0.52084
> >>         nlminbw 3.10E-08        0.520826
> >>         optimx.L-BFGS-B 0.00E+00        0.52084
> >>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
> >>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
> >>
> >>
> >>> ss$ which.OK ## which fits worked
> >>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
> >>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
> >>
> >>
> >> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
> >>
> >> Thanks,
> >>
> >> Umber
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From udube at wustl.edu  Wed Oct  4 21:54:02 2017
From: udube at wustl.edu (Dube, Umber)
Date: Wed, 4 Oct 2017 19:54:02 +0000
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <CAJuCY5zfc+9OfM+NQfuG9QkiM+rme0oUs6uuHFUPnucVTbcWog@mail.gmail.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>
 <BY1PR09MB0533E08438A4AFD564B98CBB9A7D0@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB35132BF65E750D46B6B5158CAA720@MWHPR0201MB3513.namprd02.prod.outlook.com>
 <CABghstQ0P59Yh+9im0LY4g4rk82t0UAxPdUt=0BohuOBveAmCw@mail.gmail.com>
 <BY1PR09MB05338F5ECB0E060575CFE3219A720@BY1PR09MB0533.namprd09.prod.outlook.com>
 <MWHPR0201MB3513C53EE4CFB27C8252BA37AA730@MWHPR0201MB3513.namprd02.prod.outlook.com>,
 <CAJuCY5zfc+9OfM+NQfuG9QkiM+rme0oUs6uuHFUPnucVTbcWog@mail.gmail.com>
Message-ID: <MWHPR0201MB35138223E721EC47CFB41D37AA730@MWHPR0201MB3513.namprd02.prod.outlook.com>

Thanks.


---


David,


I agree with your point. I think one thing to clarify is that I'm using a single organ from which I have the gene expression in multiple tissues. This non-independence in these multiple tissues is what motivated me to take a mixed model approach. Given that I'm only looking at a single organ, we can simplify organ to individual. So altogether,  I am hoping that Tissue + (1|Tissue:Individual) allows me to account for the fact that my expression in each tissue may be related to individual level differences. This is also what motivated questions 2 in my last email, as I am wondering whether or not it's important to include gene expression in front of the |.


---


Thierry,


Thanks for your suggestions. I've attempted to run the model you are suggesting. Unfortunately, gene expression is no longer significant. Given that it's significant using a glm in all of the tissues individually, this is not the result I would have expected. Am I mistaken in this expectation?



Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: Disease ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +
    (1 | batch) + (1 | Organ) + Gene_scale * Tissue + Gene_scale
   Data: regress_MSBB
Control: glmerControl(optCtrl = list(maxfun = 1e+09))

     AIC      BIC   logLik deviance df.resid
   309.6    381.6   -138.8    277.6      650

Scaled residuals:
     Min       1Q   Median       3Q      Max
-0.35347 -0.07869  0.00811  0.03399  0.31761

Random effects:
 Groups               Name        Variance  Std.Dev.
 Organ (Intercept) 91.669528 9.57442
 batch                (Intercept)  0.003062 0.05533
Number of obs: 666, groups:  Organ, 218; batch, 28

Fixed effects:
                               Estimate Std. Error z value Pr(>|z|)
(Intercept)                     4.84389    1.26547   3.828 0.000129 ***
RIN_scale                      -0.84579    0.44969  -1.881 0.059997 .
SEXF                            0.67658    1.34124   0.504 0.613947
AOD_scale                      -0.03113    0.64106  -0.049 0.961272
PMI_scale                      -4.03811    0.87860  -4.596 4.31e-06 ***
Species1                          -2.55531    2.58021  -0.990 0.322004
Species2                         -13.82624    2.68223  -5.155 2.54e-07 ***
Tissue1               -0.83999    0.79930  -1.051 0.293300
Tissue2               -0.78717    0.84132  -0.936 0.349465
Tissue3                1.00279    0.99135   1.012 0.311755
Gene_scale                   -1.30241    0.79605  -1.636 0.101820
Tissue1:Gene_scale  -0.08704    0.93673  -0.093 0.925966
Tissue2:Gene_scale  -0.34300    1.13281  -0.303 0.762053
Tissue3:Gene_scale  -0.09186    1.13147  -0.081 0.935293
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation matrix not shown by default, as p = 14 > 12.
Use print(x, correlation=TRUE)  or
vcov(x) if you need it

convergence code: 0
Model failed to converge with max|grad| = 3.92954 (tol = 0.001, component 1)







________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: Wednesday, October 4, 2017 2:10:27 PM
To: Dube, Umber
Cc: Farrar, David; Ben Bolker; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Questions about design and convergence warnings

Dear Umber,

You have a so called observation level random effect (OLRE) because
each combination of tissue and organ has only one level. An OLRE is
only relevant for generalised linear mixed models when you want to use
it to model overdispersion. Often in combination with the Poisson
distribution. Only use an OLRE when you know what you are doing. And
your convergence warnings are a good indicator that an ORLE is not
relevant for your data. Use (1|Organ) as I already recommended you to
do.

I'd go for GeneExpression*Tissue. You don't have enough data to
support (GeneExpression|Organ)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be<http://www.inbo.be>
Home | Instituut voor Natuur- en Bosonderzoek<http://www.inbo.be/>
www.inbo.be
Kenniscentrum dat rapporteert over de toestand van de natuur en het Vlaams beleid hierrond. Met hun publicaties en de databanken waaraan ze weewerken.




///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////


2017-10-04 19:12 GMT+02:00 Dube, Umber <udube at wustl.edu>:
>
> Thanks.
>
>
> ---
>
>
> David,
>
>
> I only have 3 species after dropping the one for which I had incomplete data. Adding the term species:tissue doesn't seem to impact my results .
>
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +
>     (1 | batch) + (1 | Tissue:Organ) + Gene_scale
>    Data: regress_MSBB
> Control: glmerControl(optCtrl = list(maxfun = 1e+09))
>
>      AIC      BIC   logLik deviance df.resid
>    741.9    800.4   -357.9    715.9      653
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.2476 -0.7030  0.3109  0.6412  3.5852
>
> Random effects:
>  Groups                            Name        Variance  Std.Dev.
>  Tissue:Organ (Intercept) 0.0001335 0.01155
>  batch                             (Intercept) 0.3555065 0.59624
> Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28
>
> Fixed effects:
>                  Estimate Std. Error z value Pr(>|z|)
> (Intercept)        0.3087     0.3000   1.029  0.30348
> RIN_scale         -0.3812     0.1290  -2.956  0.00312 **
> SEXF               0.4868     0.2030   2.398  0.01650 *
> AOD_scale         -0.1094     0.1039  -1.053  0.29217
> PMI_scale         -0.5463     0.1081  -5.055 4.31e-07 ***
> Species1             -0.1406     0.2891  -0.486  0.62680
> Species2             -1.5740     0.3873  -4.064 4.83e-05 ***
> Tissue1  -0.2696     0.3788  -0.712  0.47660
> Tissue2  -0.1634     0.3661  -0.446  0.65528
> Tissue3   0.6631     0.4109   1.614  0.10661
> Gene_scale      -0.8184     0.1250  -6.548 5.85e-11 ***
>
>
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: NP.1 ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species + Tissue +
>     (1 | batch) + (1 | Tissue:Organ) + Species:Tissue +      Gene_scale
>    Data: regress_MSBB
> Control: glmerControl(optCtrl = list(maxfun = 1e+09))
>
>      AIC      BIC   logLik deviance df.resid
>    751.7    837.2   -356.8    713.7      647
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.2554 -0.7252  0.3088  0.6355  3.6163
>
> Random effects:
>  Groups                            Name        Variance  Std.Dev.
>  Tissue:Organ (Intercept) 0.0005321 0.02307
>  batch                             (Intercept) 0.3613201 0.60110
> Number of obs: 666, groups:  Tissue:Organ, 666; batch, 28
>
> Fixed effects:
>                        Estimate Std. Error z value Pr(>|z|)
> (Intercept)             0.29375    0.31057   0.946  0.34423
> RIN_scale              -0.38955    0.13092  -2.975  0.00293 **
> SEXF                    0.48576    0.20366   2.385  0.01707 *
> AOD_scale              -0.10533    0.10418  -1.011  0.31199
> PMI_scale              -0.54720    0.10877  -5.031 4.88e-07 ***
> Species1                  -0.09427    0.55332  -0.170  0.86472
> Species2                  -1.35744    0.68746  -1.975  0.04832 *
> Tissue1       -0.32254    0.40243  -0.801  0.42286
> Tissue2       -0.14617    0.39294  -0.372  0.70989
> Tissue3        0.76621    0.43232   1.772  0.07634 .
> Gene_scale           -0.81542    0.12527  -6.509 7.56e-11 ***
> Species1:Tissue1  0.17224    0.80081   0.215  0.82971
> Species2:Tissue1  0.42202    1.00304   0.421  0.67395
> Species1:Tissue2  0.02979    0.78221   0.038  0.96962
> Species2:Tissue2 -0.49815    1.08503  -0.459  0.64616
> Species1:Tissue3 -0.39867    0.80706  -0.494  0.62132
> Species2:Tissue3 -1.03753    1.16070  -0.894  0.37139
>
>
> ---
>
>
> All,
>
>
> 1) I have been trying to use a very similar model in a lmer for a continuous variable, weight of the organ as a proxy for disease. However, I get an error when I try and run the following model:
> lmer(Weight ~ RIN_scale + SEX + AOD_scale + PMI_scale + Species+ Tissue + (1|batch) + (1|Tissue:Organ) + Gene_scale, data=regress_MSBB, family=gaussian(), control=lmerControl(optCtrl=list(maxfun=1e9) ) )
>
>
> Error: number of levels of each grouping factor must be < number of observations
>
>
> This error goes away when I drop the (1|Tissue:Organ) term, but I'm concerned that I am no longer faithfully modeling the random effects in doing so.
>
>
> Does anyone have advice with how to deal with this error?
>
>
> 2) Should I be including Gene expression in front of the | in my random effect terms if I believe that the change in gene expression between disease and healthy are different in the different tissues? If so, should I be including a term for (GeneExpression|Tissue) in addition to Tissue + (1|Tissue:Organ)? I know I can't use (GeneExpression|Tissue:Organ) as this produces the following error: Error: number of observations (=666) < number of random effects (=1332).
>
>
>
> Thanks,
>
>
> Umber
>
> ________________________________
> From: Farrar, David <Farrar.David at epa.gov>
> Sent: Tuesday, October 3, 2017 5:04:42 PM
> To: Ben Bolker; Dube, Umber
> Cc: r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
>
> Subject: RE: [R-sig-ME] Questions about design and convergence warnings
>
> Hi,
> I would like to check my intuition on the number of levels needed for a random effect.  I think of this basically in terms of the split plot design, with fixed effects that vary either within whole plots or among whole plots.  In the real world, I wouldn't expect that clean a breakdown.  You need a bunch of levels if the variance is inherently interesting.   If you are trying to evaluate some fixed effect, it seems like you are concerned with whether that effect varies primarily among levels of the random effect, or primarily within levels.  In the 2nd case, it seems to me that you wouldn't need many levels for the random effect.   This is just my intuition.   I am interested in how good it is and whether it can be related to mathematical results.
> Regards,
> David
>
>
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Tuesday, October 03, 2017 5:34 PM
> To: Dube, Umber <udube at wustl.edu>
> Cc: Farrar, David <Farrar.David at epa.gov>; r-sig-mixed-models at r-project.org; thierry.onkelinx at inbo.be
> Subject: Re: [R-sig-ME] Questions about design and convergence warnings
>
> On Tue, Oct 3, 2017 at 4:50 PM, Dube, Umber <udube at wustl.edu> wrote:
> > Thanks for your responses.
> >
> > Thierry,
> >
> > The first case is correct. For example, the skin is an organ and the different layers of the skin (epidermis, dermis, and hypodermis) can be considered tissues. So in my experiment I have collected the same tissues originating from different organs which are either healthy or diseased.
> >
> > Good call on the species effect. I've dropped one of the species for whom I had only healthy data. This has resulted in fewer convergence warnings as I perform the glmer with each gene. I've also noticed that even those genes for which I do produce convergence warnings will converge if I try using other optimizers. I understand this provides additional evidence to support the warnings being false positives.
> >
> > ---
> >
> > David,
> >
> > I hadn't considered that. If I'm understanding correctly, you would recommend including species:tissue in my model?
> >
> > ---
> >
> > All,
> >
> > Is it appropriate to model batch as a random effect, or should I include it as a fixed effect?
>
>
>   Haven't followed the thread carefully, but: typically an exchangeable factor such as batch (i.e., relabeling the batches wouldn't change anything about their meaning) is _philosophically_ a random effect, but if you have too few levels (batches) to reliably estimate among-batch variance (e.g. <5) you might choose to treat it as a fixed effect instead (or use a Bayesian method that allows you to specify a prior on the among-batch variance ...)
>
> >
> >
> > Thanks,
> >
> > Umber
> >
> >
> > ________________________________
> > From: Farrar, David <Farrar.David at epa.gov>
> > Sent: Monday, October 2, 2017 1:21:45 PM
> > To: Dube, Umber
> > Subject: RE: [R-sig-ME] Questions about design and convergence
> > warnings
> >
> > Dear Umber,
> > It seems your model would not support a conclusion that the effect on a certain tissue would depend on the species, an interaction.
> > Is that intentional?
> > David
> >
> > -----Original Message-----
> > From: R-sig-mixed-models
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thierry
> > Onkelinx
> > Sent: Friday, September 29, 2017 7:35 AM
> > To: Dube, Umber <udube at wustl.edu>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Questions about design and convergence
> > warnings
> >
> > Dear Umber,
> >
> > Can you clarify what a tissue is? Distinct parts of an organ (tissue 1 for organ 1 refers to the same part as tissue 1 for organ 2)? Or merely different samples for the same organ (no link between tissue 1 between organs). Tissue as random effect is only relevant in the first case. In the latter case is depends on the number of replicates per tissue:organ. In case of one replication go for (1|Organ), in case of multiple replications go for (1|Organ/Tissue).
> >
> > It looks like you have very strong species effects. That is an indication for quasi-complete separation, which can trigger convergence warnings.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus/ Statistician
> >
> > Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
> > BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
> > & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be Kliniekstraat 25, B-1070 Brussel
> > www.inbo.be<http://www.inbo.be>
> >
> > //////////////////////////////////////////////////////////////////////
> > ///////////////////// To call in the statistician after the experiment
> > is done may be no more than asking him to perform a post-mortem
> > examination: he may be able to say what the experiment died of. ~ Sir
> > Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
> > Brinner The combination of some data and an aching desire for an
> > answer does not ensure that a reasonable answer can be extracted from
> > a given body of data. ~ John Tukey
> > //////////////////////////////////////////////////////////////////////
> > /////////////////////
> >
> >
> > Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> > Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
> >
> > //////////////////////////////////////////////////////////////////////
> > /////////////////////
> >
> >
> >
> > 2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu>:
> >> Thanks for your continued development of lme4 and all the support you've provided.
> >>
> >> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
> >>
> >> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
> >>
> >> I have been modelling the following as fixed effects:
> >> RNA Integrity Number (RIN) - quality of the total RNA extracted from
> >> each tissues (continuous) Post-mortem Interval (PMI) - how much time
> >> elapsed following death until the tissue was frozen (continuous) Sex
> >> - genetic sex of the organ (categorical) Age at death (AOD) - age of
> >> organ at death (continuous) Species - species of organ (categorical)
> >> Gene -  normalized count data of gene expression (continuous)
> >>
> >> I have been modelling the following as random effects:
> >> Batch (categorical)
> >>
> >> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
> >>
> >> Altogether, my model is:
> >>
> >> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue
> >> +
> >> (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(),
> >> control=glmerControl(optCtrl=list(maxfun=1e9) ) )
> >>
> >> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
> >>
> >> Warning messages:
> >> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >>   unable to evaluate scaled gradient
> >> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >>   Model failed to converge: degenerate  Hessian with 1 negative
> >> eigenvalues
> >>
> >> To address this:
> >>
> >> 1) I've centered and scaled my continous predictors
> >>
> >> 2) I've checked for singularity #False
> >>
> >> 3) I've printed and compared with internal calculations
> >>
> >> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
> >>
> >>
> >>> ss$ fixef ## extract fixed effects
> >>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
> >> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
> >> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
> >> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
> >> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
> >> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
> >> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
> >>
> >>
> >>> ss$ llik ## log-likelihoods
> >>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
> >>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
> >>
> >>> ss$ sdcor ## SDs and correlations
> >>                 Organ:Tissue.(Intercept)        batch.(Intercept)
> >>         bobyqa  3.68E-05        0.520826
> >>         Nelder_Mead     5.56E-03        0.52084
> >>         nlminbw 3.10E-08        0.520826
> >>         optimx.L-BFGS-B 0.00E+00        0.52084
> >>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
> >>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
> >>
> >>
> >>
> >>> ss$ theta ## Cholesky factors
> >>                 Organ:Tissue.(Intercept)        batch.(Intercept)
> >>         bobyqa  3.68E-05        0.520826
> >>         Nelder_Mead     5.56E-03        0.52084
> >>         nlminbw 3.10E-08        0.520826
> >>         optimx.L-BFGS-B 0.00E+00        0.52084
> >>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
> >>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
> >>
> >>
> >>> ss$ which.OK ## which fits worked
> >>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
> >>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
> >>
> >>
> >> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
> >>
> >> Thanks,
> >>
> >> Umber
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From van.liceralde at gmail.com  Wed Oct  4 21:55:39 2017
From: van.liceralde at gmail.com (Van Rynald Liceralde)
Date: Wed, 4 Oct 2017 15:55:39 -0400
Subject: [R-sig-ME] specifying crossed random effects for glmmPQL / lme
Message-ID: <CAOQn1wVhOm5TGr5M6GfAcNahMS8yQ8YbPN92sqWobNPUh7snhQ@mail.gmail.com>

Thanks for your response, Ben! The paper that argued the use of the
identity link with Gamma for response time data is Lo & Andrews (2015) (doi:
10.3389/fpsyg.2015.01171 <https://dx.doi.org/10.3389%2Ffpsyg.2015.01171>).
Would such a model still be computationally problematic if the observed
values fall very much within the domain of the specified probability
distribution (i.e., valid response times are always above 200 ms)?

Re: "allow for correlations of random effects to be estimated", I've been
told that it's more tractable to estimate covariances between the random
slopes and intercepts (as I want with my model) using PQL than
Laplace/AGHQ. In fact, Lo & Andrews' demonstration using glmer explicitly
specified the covariances between the slopes and the intercepts to be 0 due
to the computational rigor of specifying a model with random
intercept-slope covariances in glmer and due to theoretical reasons.

And thanks for pointing out the Pinheiro & Bates (2000) reference to
specifying crossed effects!

Sincerely,
Van Liceralde

-- 
Van Rynald T. Liceralde, BS, BA
Graduate Student, Cognitive Psychology
University of North Carolina at Chapel Hill

	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Thu Oct  5 00:12:21 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Wed, 04 Oct 2017 22:12:21 +0000
Subject: [R-sig-ME]
	https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
In-Reply-To: <AM0PR0302MB33631B144E703C6A42EDB2E9D2730@AM0PR0302MB3363.eurprd03.prod.outlook.com>
References: <mailman.720.1507137139.1577.r-sig-mixed-models@r-project.org>
 <AM0PR0302MB33631B144E703C6A42EDB2E9D2730@AM0PR0302MB3363.eurprd03.prod.outlook.com>
Message-ID: <CANYHYTRsoVJBmnoczvBHJrbbw3vMNZg1hGfbx=_VUm1ti-BChg@mail.gmail.com>

Tom, thank you so much, this is exactly the direction (I didn't know enough
in this case to call it a bivariate model) I was searching for. The
tutorials linked in your response are excellent and I've already started to
use one.

As an aside, I'm sorry for the subject of this post - I meant to insert the
link in the content of my message and have the subject of this message be
"Using random effect predictions in other models."

Josh

On Wed, Oct 4, 2017 at 1:45 PM Houslay, Tom <T.Houslay at exeter.ac.uk> wrote:

> Hi Josh,
>
>
> It sounds like you would be better off using a bivariate model (I'm
> assuming this was where you were headed with 'combining' the models?),
> where your response variables are something like 'ESM' and 'Outcome'. You
> could have these grouped by individual ID, and (having controlled for any
> fixed effects on either response) calculate the among-individual variation
> in each response and the covariance between them (which can be scaled to a
> correlation). As you're effectively modelling the relationship between two
> response variables then I think this makes sense, and avoids discarding the
> error associated with predictions from a previous model.
>
>
> If you have repeated measures for both ESM and Outcome, but these were not
> measured at the same time, you might have data something like the following:
>
>
> ID --- Repeat --- ESM --- Outcome
>
> A --- 1 --- 12 --- NA
>
> A --- 2 --- 19 --- NA
>
> A --- 3 --- 14 --- NA
>
> A --- 1 --- NA --- 15
>
> A --- 2 --- NA --- 9
>
> B ...
>
>
> etc
>
>
> In which case you could calculate both among-individual and residual
> variation for both traits, but only the among-individual covariance (as you
> don't have observations of both responses at the same time to estimate the
> residual/'within-individual' covariance).
>
>
> Note that if you only had a single observation for 'Outcome', you would
> simply constrain the residual variation for this trait to be 0 (such that
> all variation is modelled as 'among-individual').
>
>
> In case they're useful, we have a brief paper related to this topic in
> Behavioural Ecology here:
>
> https://doi.org/10.1093/beheco/arx023
>
>
> ...and some tutorials for these kinds of models in MCMCglmm / ASreml-R
> here:
>
> https://tomhouslay.com/tutorials/
>
>
> This paper on comparing behaviours measured repeatedly in both short- and
> long-term sampling regimes might also be of interest:
>
> https://link.springer.com/article/10.1007/s00265-014-1692-0
>
>
> Good luck!
>
>
> Tom
>
>
>
> Date: Wed, 4 Oct 2017 11:37:44 -0400
> From: Joshua Rosenberg <jmichaelrosenberg at gmail.com>
> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME]
>
> https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
>
> Message-ID:
>         <CANYHYTTdKauDXjgzA-Ghy=
> dnEUfgJG+UPWMMM4UqtLXxR13k7g at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
>
> Hi R-Sig-mixed-models,
>
> My question is about the use of predictions of effects for specific units
> (such as an individual in the case of repeated measures data) in other
> models. I'm especially interested in whether the group thinks this is a
> good / useful approach for using repeated measures data to predict a
> longer-term outcome. I am also interested in whether the group has any
> suggestions for betters way to do this (or to combine what now requires two
> models).
>
> For example, were individual-level predicted effects to be obtained from a
> mixed effects model (through a null model, i.e. there is random intercept
> for individuals and no fixed effect), could they be used to predict an
> individual-level outcome?
>
> I am thinking about this specifically in the context of repeated measures
> data (collected using Experience Sampling Method, or ESM, whereby students
> are asked every so often to respond to questions about their interest and
> engagement) and pre- and post-survey measures, representing a longer-term
> outcome, students' self-reported interest in a STEM career.
>
> Here is how I am thinking about this, using lmer() and lm() to specify the
> models:
>
> m1 <- lmer(repeated_measures_outcome ~ 1 + (1 | participant), data)
>
>
> Process the data to obtain the predicted intercept for each participant.
>
> m2 <- lm(longer_term_outcome ~ prior_level_of_longer_term_outcome +
> predicted_intercept_for_participant)
>
>
> When I have shared this idea with others (i.e., in this Stack Overflow
> question) I have received feedback that a) yes, you can do this and b) you
> could / should combine the two models (m1 and m2 in this example) into one
> model. This would (obviously?) require using a different approach - but I
> do not have a clear idea of what this would require (MCMCglmm? brms?).
>
> Any general or specific advice is welcomed. Thank you for your
> consideration of this. If I can or need to provide more detail or
> background, then please do not hesitate to tell me so!
>
> Josh
>
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology
> &
>  Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
>         [[alternative HTML version deleted]]
>
>
>
> --
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Oct  5 07:01:41 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 5 Oct 2017 06:01:41 +0100
Subject: [R-sig-ME]
 https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
In-Reply-To: <CANYHYTRsoVJBmnoczvBHJrbbw3vMNZg1hGfbx=_VUm1ti-BChg@mail.gmail.com>
References: <mailman.720.1507137139.1577.r-sig-mixed-models@r-project.org>
 <AM0PR0302MB33631B144E703C6A42EDB2E9D2730@AM0PR0302MB3363.eurprd03.prod.outlook.com>
 <CANYHYTRsoVJBmnoczvBHJrbbw3vMNZg1hGfbx=_VUm1ti-BChg@mail.gmail.com>
Message-ID: <9e31dd76-fdc0-6b39-a666-8eac7d739f7e@ed.ac.uk>

Hi Josh,

It sounds like one of your responses is repeat measure and the other 
not. With a bivariate model this means you want to model the covariance 
between the ID random effect for the repeat-measure trait and the 
residual for the single-measure trait (an ID term and  a residual would 
be non-identifiable for the latter). In MCMCglmm you can do this using 
the covu argument in the prior. An example is below.

Cheers,

Jarrod

   N<-500
    # 500 individuals

   V<-matrix(c(1,0.5, 0.5, 1),2,2)
    # 2x2 random/residual-effect covariance matrix

   Vr<-matrix(1,1,1)
    # residual variance for repeat measure trait

   u<-MASS::mvrnorm(N, rep(0, 2), V)
     # random effect for repeat measure trait followed by
     # residuals for the single measured trait.

   e<-rnorm(2*N,0,sqrt(Vr))
    # residuals for the repeat trait

   ysingle<-1+u[,2]
     # single measure traits has intercept of 1

   individual<-as.factor(rep(1:N, 3))
     # individuals are ordered within each trait/time combination

   type<-as.factor(c(rep("s", N), rep("r",2*N)))
     # designate which observations are single measures (s)
     # or repeat measures (r)

   yrep<--1+u[rep(1:N, 2),1]+e
     # the repeat measure trait has an intercept of -1

   dat1<-data.frame(y=c(ysingle,yrep), type=type,
   individual=individual)

   prior1<-list(R=list(R1=list(V=V, nu=0, covu=TRUE),
      R2=list(V=Vr, nu=0)))
     # use flat priors, but use covu=TRUE to mdoel covariances
     # between R1 effects and the random effects
     # (G is not needed because random effect prior is
     #  specified in R1)


   m.test1<-MCMCglmm(y~type-1,
     random=~us(at.level(type,"r")):individual,
     rcov=~us(at.level(type, "s")):individual+us(at.level(type, "r")):units,
     data=dat1,
     prior=prior1,
     verbose=FALSE)
     # Have to fit repeat measure residuals in the
     # second residual term.


On 04/10/2017 23:12, Joshua Rosenberg wrote:
> Tom, thank you so much, this is exactly the direction (I didn't know enough
> in this case to call it a bivariate model) I was searching for. The
> tutorials linked in your response are excellent and I've already started to
> use one.
>
> As an aside, I'm sorry for the subject of this post - I meant to insert the
> link in the content of my message and have the subject of this message be
> "Using random effect predictions in other models."
>
> Josh
>
> On Wed, Oct 4, 2017 at 1:45 PM Houslay, Tom <T.Houslay at exeter.ac.uk> wrote:
>
>> Hi Josh,
>>
>>
>> It sounds like you would be better off using a bivariate model (I'm
>> assuming this was where you were headed with 'combining' the models?),
>> where your response variables are something like 'ESM' and 'Outcome'. You
>> could have these grouped by individual ID, and (having controlled for any
>> fixed effects on either response) calculate the among-individual variation
>> in each response and the covariance between them (which can be scaled to a
>> correlation). As you're effectively modelling the relationship between two
>> response variables then I think this makes sense, and avoids discarding the
>> error associated with predictions from a previous model.
>>
>>
>> If you have repeated measures for both ESM and Outcome, but these were not
>> measured at the same time, you might have data something like the following:
>>
>>
>> ID --- Repeat --- ESM --- Outcome
>>
>> A --- 1 --- 12 --- NA
>>
>> A --- 2 --- 19 --- NA
>>
>> A --- 3 --- 14 --- NA
>>
>> A --- 1 --- NA --- 15
>>
>> A --- 2 --- NA --- 9
>>
>> B ...
>>
>>
>> etc
>>
>>
>> In which case you could calculate both among-individual and residual
>> variation for both traits, but only the among-individual covariance (as you
>> don't have observations of both responses at the same time to estimate the
>> residual/'within-individual' covariance).
>>
>>
>> Note that if you only had a single observation for 'Outcome', you would
>> simply constrain the residual variation for this trait to be 0 (such that
>> all variation is modelled as 'among-individual').
>>
>>
>> In case they're useful, we have a brief paper related to this topic in
>> Behavioural Ecology here:
>>
>> https://doi.org/10.1093/beheco/arx023
>>
>>
>> ...and some tutorials for these kinds of models in MCMCglmm / ASreml-R
>> here:
>>
>> https://tomhouslay.com/tutorials/
>>
>>
>> This paper on comparing behaviours measured repeatedly in both short- and
>> long-term sampling regimes might also be of interest:
>>
>> https://link.springer.com/article/10.1007/s00265-014-1692-0
>>
>>
>> Good luck!
>>
>>
>> Tom
>>
>>
>>
>> Date: Wed, 4 Oct 2017 11:37:44 -0400
>> From: Joshua Rosenberg <jmichaelrosenberg at gmail.com>
>> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME]
>>
>> https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
>>
>> Message-ID:
>>          <CANYHYTTdKauDXjgzA-Ghy=
>> dnEUfgJG+UPWMMM4UqtLXxR13k7g at mail.gmail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>>
>> Hi R-Sig-mixed-models,
>>
>> My question is about the use of predictions of effects for specific units
>> (such as an individual in the case of repeated measures data) in other
>> models. I'm especially interested in whether the group thinks this is a
>> good / useful approach for using repeated measures data to predict a
>> longer-term outcome. I am also interested in whether the group has any
>> suggestions for betters way to do this (or to combine what now requires two
>> models).
>>
>> For example, were individual-level predicted effects to be obtained from a
>> mixed effects model (through a null model, i.e. there is random intercept
>> for individuals and no fixed effect), could they be used to predict an
>> individual-level outcome?
>>
>> I am thinking about this specifically in the context of repeated measures
>> data (collected using Experience Sampling Method, or ESM, whereby students
>> are asked every so often to respond to questions about their interest and
>> engagement) and pre- and post-survey measures, representing a longer-term
>> outcome, students' self-reported interest in a STEM career.
>>
>> Here is how I am thinking about this, using lmer() and lm() to specify the
>> models:
>>
>> m1 <- lmer(repeated_measures_outcome ~ 1 + (1 | participant), data)
>>
>>
>> Process the data to obtain the predicted intercept for each participant.
>>
>> m2 <- lm(longer_term_outcome ~ prior_level_of_longer_term_outcome +
>> predicted_intercept_for_participant)
>>
>>
>> When I have shared this idea with others (i.e., in this Stack Overflow
>> question) I have received feedback that a) yes, you can do this and b) you
>> could / should combine the two models (m1 and m2 in this example) into one
>> model. This would (obviously?) require using a different approach - but I
>> do not have a clear idea of what this would require (MCMCglmm? brms?).
>>
>> Any general or specific advice is welcomed. Thank you for your
>> consideration of this. If I can or need to provide more detail or
>> background, then please do not hesitate to tell me so!
>>
>> Josh
>>
>> --
>> Joshua Rosenberg, Ph.D. Candidate
>> Educational Psychology
>> &
>>   Educational Technology
>> Michigan State University
>> http://jmichaelrosenberg.com
>>
>>          [[alternative HTML version deleted]]
>>
>>
>>
>> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology ?&? Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From T.Houslay at exeter.ac.uk  Thu Oct  5 13:11:54 2017
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Thu, 5 Oct 2017 11:11:54 +0000
Subject: [R-sig-ME]
 https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
In-Reply-To: <9e31dd76-fdc0-6b39-a666-8eac7d739f7e@ed.ac.uk>
References: <mailman.720.1507137139.1577.r-sig-mixed-models@r-project.org>
 <AM0PR0302MB33631B144E703C6A42EDB2E9D2730@AM0PR0302MB3363.eurprd03.prod.outlook.com>
 <CANYHYTRsoVJBmnoczvBHJrbbw3vMNZg1hGfbx=_VUm1ti-BChg@mail.gmail.com>,
 <9e31dd76-fdc0-6b39-a666-8eac7d739f7e@ed.ac.uk>
Message-ID: <AM0PR0302MB33638DC774D86D69E49930DED2700@AM0PR0302MB3363.eurprd03.prod.outlook.com>

Thanks for this Jarrod, I didn't know about this method (which seems more elegant than fixing variances in the priors) - I'll investigate and hopefully get to updating those tutorials in due course...

________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: 05 October 2017 06:01:41
To: Joshua Rosenberg; Houslay, Tom; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763

Hi Josh,

It sounds like one of your responses is repeat measure and the other
not. With a bivariate model this means you want to model the covariance
between the ID random effect for the repeat-measure trait and the
residual for the single-measure trait (an ID term and  a residual would
be non-identifiable for the latter). In MCMCglmm you can do this using
the covu argument in the prior. An example is below.

Cheers,

Jarrod

   N<-500
    # 500 individuals

   V<-matrix(c(1,0.5, 0.5, 1),2,2)
    # 2x2 random/residual-effect covariance matrix

   Vr<-matrix(1,1,1)
    # residual variance for repeat measure trait

   u<-MASS::mvrnorm(N, rep(0, 2), V)
     # random effect for repeat measure trait followed by
     # residuals for the single measured trait.

   e<-rnorm(2*N,0,sqrt(Vr))
    # residuals for the repeat trait

   ysingle<-1+u[,2]
     # single measure traits has intercept of 1

   individual<-as.factor(rep(1:N, 3))
     # individuals are ordered within each trait/time combination

   type<-as.factor(c(rep("s", N), rep("r",2*N)))
     # designate which observations are single measures (s)
     # or repeat measures (r)

   yrep<--1+u[rep(1:N, 2),1]+e
     # the repeat measure trait has an intercept of -1

   dat1<-data.frame(y=c(ysingle,yrep), type=type,
   individual=individual)

   prior1<-list(R=list(R1=list(V=V, nu=0, covu=TRUE),
      R2=list(V=Vr, nu=0)))
     # use flat priors, but use covu=TRUE to mdoel covariances
     # between R1 effects and the random effects
     # (G is not needed because random effect prior is
     #  specified in R1)


   m.test1<-MCMCglmm(y~type-1,
     random=~us(at.level(type,"r")):individual,
     rcov=~us(at.level(type, "s")):individual+us(at.level(type, "r")):units,
     data=dat1,
     prior=prior1,
     verbose=FALSE)
     # Have to fit repeat measure residuals in the
     # second residual term.


On 04/10/2017 23:12, Joshua Rosenberg wrote:
> Tom, thank you so much, this is exactly the direction (I didn't know enough
> in this case to call it a bivariate model) I was searching for. The
> tutorials linked in your response are excellent and I've already started to
> use one.
>
> As an aside, I'm sorry for the subject of this post - I meant to insert the
> link in the content of my message and have the subject of this message be
> "Using random effect predictions in other models."
>
> Josh
>
> On Wed, Oct 4, 2017 at 1:45 PM Houslay, Tom <T.Houslay at exeter.ac.uk> wrote:
>
>> Hi Josh,
>>
>>
>> It sounds like you would be better off using a bivariate model (I'm
>> assuming this was where you were headed with 'combining' the models?),
>> where your response variables are something like 'ESM' and 'Outcome'. You
>> could have these grouped by individual ID, and (having controlled for any
>> fixed effects on either response) calculate the among-individual variation
>> in each response and the covariance between them (which can be scaled to a
>> correlation). As you're effectively modelling the relationship between two
>> response variables then I think this makes sense, and avoids discarding the
>> error associated with predictions from a previous model.
>>
>>
>> If you have repeated measures for both ESM and Outcome, but these were not
>> measured at the same time, you might have data something like the following:
>>
>>
>> ID --- Repeat --- ESM --- Outcome
>>
>> A --- 1 --- 12 --- NA
>>
>> A --- 2 --- 19 --- NA
>>
>> A --- 3 --- 14 --- NA
>>
>> A --- 1 --- NA --- 15
>>
>> A --- 2 --- NA --- 9
>>
>> B ...
>>
>>
>> etc
>>
>>
>> In which case you could calculate both among-individual and residual
>> variation for both traits, but only the among-individual covariance (as you
>> don't have observations of both responses at the same time to estimate the
>> residual/'within-individual' covariance).
>>
>>
>> Note that if you only had a single observation for 'Outcome', you would
>> simply constrain the residual variation for this trait to be 0 (such that
>> all variation is modelled as 'among-individual').
>>
>>
>> In case they're useful, we have a brief paper related to this topic in
>> Behavioural Ecology here:
>>
>> https://doi.org/10.1093/beheco/arx023
>>
>>
>> ...and some tutorials for these kinds of models in MCMCglmm / ASreml-R
>> here:
>>
>> https://tomhouslay.com/tutorials/
>>
>>
>> This paper on comparing behaviours measured repeatedly in both short- and
>> long-term sampling regimes might also be of interest:
>>
>> https://link.springer.com/article/10.1007/s00265-014-1692-0
>>
>>
>> Good luck!
>>
>>
>> Tom
>>
>>
>>
>> Date: Wed, 4 Oct 2017 11:37:44 -0400
>> From: Joshua Rosenberg <jmichaelrosenberg at gmail.com>
>> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME]
>>
>> https://stats.stackexchange.com/questions/301763/using-random-effect-predictions-in-other-models?noredirect=1#comment573574_301763
>>
>> Message-ID:
>>          <CANYHYTTdKauDXjgzA-Ghy=
>> dnEUfgJG+UPWMMM4UqtLXxR13k7g at mail.gmail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>>
>> Hi R-Sig-mixed-models,
>>
>> My question is about the use of predictions of effects for specific units
>> (such as an individual in the case of repeated measures data) in other
>> models. I'm especially interested in whether the group thinks this is a
>> good / useful approach for using repeated measures data to predict a
>> longer-term outcome. I am also interested in whether the group has any
>> suggestions for betters way to do this (or to combine what now requires two
>> models).
>>
>> For example, were individual-level predicted effects to be obtained from a
>> mixed effects model (through a null model, i.e. there is random intercept
>> for individuals and no fixed effect), could they be used to predict an
>> individual-level outcome?
>>
>> I am thinking about this specifically in the context of repeated measures
>> data (collected using Experience Sampling Method, or ESM, whereby students
>> are asked every so often to respond to questions about their interest and
>> engagement) and pre- and post-survey measures, representing a longer-term
>> outcome, students' self-reported interest in a STEM career.
>>
>> Here is how I am thinking about this, using lmer() and lm() to specify the
>> models:
>>
>> m1 <- lmer(repeated_measures_outcome ~ 1 + (1 | participant), data)
>>
>>
>> Process the data to obtain the predicted intercept for each participant.
>>
>> m2 <- lm(longer_term_outcome ~ prior_level_of_longer_term_outcome +
>> predicted_intercept_for_participant)
>>
>>
>> When I have shared this idea with others (i.e., in this Stack Overflow
>> question) I have received feedback that a) yes, you can do this and b) you
>> could / should combine the two models (m1 and m2 in this example) into one
>> model. This would (obviously?) require using a different approach - but I
>> do not have a clear idea of what this would require (MCMCglmm? brms?).
>>
>> Any general or specific advice is welcomed. Thank you for your
>> consideration of this. If I can or need to provide more detail or
>> background, then please do not hesitate to tell me so!
>>
>> Josh
>>
>> --
>> Joshua Rosenberg, Ph.D. Candidate
>> Educational Psychology
>> &
>>   Educational Technology
>> Michigan State University
>> http://jmichaelrosenberg.com
>>
>>          [[alternative HTML version deleted]]
>>
>>
>>
>> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology ?&? Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


	[[alternative HTML version deleted]]


From yliu at psych.udel.edu  Thu Oct  5 23:59:30 2017
From: yliu at psych.udel.edu (Yuqi Liu)
Date: Thu, 5 Oct 2017 21:59:30 +0000
Subject: [R-sig-ME] degree of freedom is non-integer from lmerTest
Message-ID: <0005b50d2bd944cb8abc6893436cae3e@Mercury.psych.udel.edu>

Dear R-experts,

  I am using lmerTest to do mixed model analysis on one of my experiments. There are two factors, each with 2 levels, resulting in 4 experiment conditions.  It was repeated measures design, and each experiment condition was conducted once for each individual. The model is thus very simple, with each factor as a fixed effect and subjects as a random effect: model <- lmerTest (DV~IV1*IV2+(1|subject),data).

 When I looked at the result using summary(model), the Dfs are non-integers, is it because we had to exclude some of the trials, so that some participants had missing data? In general, I am wondering how t-tests are performed in lmerTest, and how degree of freedom was calculated.

Thank you for your help!
Yuqi

	[[alternative HTML version deleted]]


From jake.a.westfall at gmail.com  Fri Oct  6 00:04:17 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Thu, 5 Oct 2017 17:04:17 -0500
Subject: [R-sig-ME] degree of freedom is non-integer from lmerTest
In-Reply-To: <0005b50d2bd944cb8abc6893436cae3e@Mercury.psych.udel.edu>
References: <0005b50d2bd944cb8abc6893436cae3e@Mercury.psych.udel.edu>
Message-ID: <CAE9_Wg7kjmtvbNQt6vda5fqMUSrP2L70B+k=GRfDXV9JDacKyw@mail.gmail.com>

Yuqi,

By default, the DFs in lmerTest are based on the Satterthwaite
approximation:
https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation

Also see ?lmerTest::summary.merModLmerTest

Jake

On Thu, Oct 5, 2017 at 4:59 PM, Yuqi Liu <yliu at psych.udel.edu> wrote:

> Dear R-experts,
>
>   I am using lmerTest to do mixed model analysis on one of my experiments.
> There are two factors, each with 2 levels, resulting in 4 experiment
> conditions.  It was repeated measures design, and each experiment condition
> was conducted once for each individual. The model is thus very simple, with
> each factor as a fixed effect and subjects as a random effect: model <-
> lmerTest (DV~IV1*IV2+(1|subject),data).
>
>  When I looked at the result using summary(model), the Dfs are
> non-integers, is it because we had to exclude some of the trials, so that
> some participants had missing data? In general, I am wondering how t-tests
> are performed in lmerTest, and how degree of freedom was calculated.
>
> Thank you for your help!
> Yuqi
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Fri Oct  6 11:20:46 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Fri, 6 Oct 2017 11:20:46 +0200
Subject: [R-sig-ME] specifying crossed random effects for glmmPQL / lme
In-Reply-To: <CAOQn1wVhOm5TGr5M6GfAcNahMS8yQ8YbPN92sqWobNPUh7snhQ@mail.gmail.com>
References: <CAOQn1wVhOm5TGr5M6GfAcNahMS8yQ8YbPN92sqWobNPUh7snhQ@mail.gmail.com>
Message-ID: <59D74AEE.2070003@mpi.nl>

As an oblique not-quite-an answer ....

brms has an exponential Gaussian (exgaussian) option for the error
distribution / family, which as the documentation notes is "especially
suited to model reaction times". You have to go Bayesian, but you can
estimate crossed random effects and their associated correlations
without any special tricks.

Phillip

On 10/04/2017 09:55 PM, Van Rynald Liceralde wrote:
> Thanks for your response, Ben! The paper that argued the use of the
> identity link with Gamma for response time data is Lo & Andrews (2015) (doi:
> 10.3389/fpsyg.2015.01171 <https://dx.doi.org/10.3389%2Ffpsyg.2015.01171>).
> Would such a model still be computationally problematic if the observed
> values fall very much within the domain of the specified probability
> distribution (i.e., valid response times are always above 200 ms)?
> 
> Re: "allow for correlations of random effects to be estimated", I've been
> told that it's more tractable to estimate covariances between the random
> slopes and intercepts (as I want with my model) using PQL than
> Laplace/AGHQ. In fact, Lo & Andrews' demonstration using glmer explicitly
> specified the covariances between the slopes and the intercepts to be 0 due
> to the computational rigor of specifying a model with random
> intercept-slope covariances in glmer and due to theoretical reasons.
> 
> And thanks for pointing out the Pinheiro & Bates (2000) reference to
> specifying crossed effects!
> 
> Sincerely,
> Van Liceralde
>


From luca.corlatti at boku.ac.at  Sun Oct  8 18:58:50 2017
From: luca.corlatti at boku.ac.at (Luca Corlatti)
Date: Sun, 8 Oct 2017 18:58:50 +0200
Subject: [R-sig-ME] Binomial glmer with time dependency
Message-ID: <BAB54EC5-8D16-434C-BB2B-96862037BEDE@boku.ac.at>

Dear list member, 
suppose I want to investigate how the success in DNA extraction (binary response 1/0) from, e.g., scats, is affected by the method of sample storage (4 levels: ?ethanol?, ?silica?, ?DMSO? and ?lysis?) and the time elapsed from scat deposition (3 levels: ?<48h?, "week1?, "week2?). If I collect scats from, e.g, 10 individuals, my dataset will look like:

ID_individual	method	time		DNA_extraction
1			ethanol	<48h	1
1			ethanol	week1	1
1			ethanol	week2	0
1			silica	<48h	1
1			silica	week1	0
1			silica	week2	0
1			DMSO	<48h	1
1			DMSO	week1	1
1			DMSO	week2	1
1			lysis		<48h	1
1			lysis		week1	1
1			lysis		week2	0
2			ethanol	<48h	1
2			ethanol	week1	1
2			ethanol	week2	0
?
10			lysis		<48h	1
10			lysis		week1	1
10			lysis		week2	1

for an overall of 120 records.

A simple model could be:

mod <- glmer(DNA_extraction ~ method*time + (1|ID_individual), family=binomial)

This model should account for pseudoreplication between methods, while different time decays should be corrected for by the ?method? variable. 
However, the success in DNA extraction is not independent between 48h, week1 and week2 (e.g. if i fail in 48h, I am likely to fail also in week1 and week 2), and I am not sure how to account for this time dependency.
Any suggestion?
Thanks a lot in advance!
Luca


From adomalik at sfu.ca  Mon Oct  9 15:22:12 2017
From: adomalik at sfu.ca (Alice Domalik)
Date: Mon, 9 Oct 2017 06:22:12 -0700 (PDT)
Subject: [R-sig-ME] spatial covariance structure in glmmTMB
Message-ID: <845771341.62814150.1507555332287.JavaMail.zimbra@sfu.ca>

Dear list, 

I am fitting mixed effects models using the package glmmTMB to investigate habitat use. 
My current model has the form m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) 
I would like to add a spatial covariance structure based on geographic coordinates (mydata$x and mydata$y). 
However, I do not know how to modify my model formula to include a spatial covariance structure. Does anyone have example code to show how this is done? 

Any help would be much appreciated! 



	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Mon Oct  9 15:42:48 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Mon, 9 Oct 2017 15:42:48 +0200
Subject: [R-sig-ME] spatial covariance structure in glmmTMB
In-Reply-To: <845771341.62814150.1507555332287.JavaMail.zimbra@sfu.ca>
References: <845771341.62814150.1507555332287.JavaMail.zimbra@sfu.ca>
Message-ID: <CAMu=eMBXb2OWFw2xNmq+0XSwFU1=m2bN5tCqjXT9U40EpLFV7g@mail.gmail.com>

Hi Alice,

Have you looked at the vignette on covariance structures? There's a section
on spatial correlations.

https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

cheers,
Mollie

On Mon, Oct 9, 2017 at 3:22 PM, Alice Domalik <adomalik at sfu.ca> wrote:

> Dear list,
>
> I am fitting mixed effects models using the package glmmTMB to investigate
> habitat use.
> My current model has the form m1<-glmmTMB(count~waterdepth + temperature +
> chl.conc + (1|individual), family=list(family="truncated_nbinom1",
> link="log"), data=mydata)
> I would like to add a spatial covariance structure based on geographic
> coordinates (mydata$x and mydata$y).
> However, I do not know how to modify my model formula to include a spatial
> covariance structure. Does anyone have example code to show how this is
> done?
>
> Any help would be much appreciated!
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From yliu at psych.udel.edu  Mon Oct  9 16:20:32 2017
From: yliu at psych.udel.edu (Yuqi Liu)
Date: Mon, 9 Oct 2017 14:20:32 +0000
Subject: [R-sig-ME] mixed-effects model with partially nested fixed effects
Message-ID: <90e7574a32c74d7686ba198e9986ae5d@Mercury.psych.udel.edu>

Hi R-experts,

  I am analyzing data from 3 experiments using linear mixed model. Each experiment had 2 fixed effects, movement type and motor effort. Movement type is shared by all experiments, motor effort varied but partially shared across experiments. The data looks like this:


  Subject              experiment        movement_type              motor_effort     DV

  1                           1                              synchronous                      normal
  2                           1                              asynchronous                    normal
   .
   .
   .

  101                       2                              synchronous                      normal
  102                       2                              asynchronous                    normal
  103                       2                              synchronous                      medium
  104                       2                              asynchronous                    medium
   .
   .
   .
  201                       3                              synchronous                      normal
  202                       3                              asynchronous                    normal
  203                       3                              synchronous                      hard
  204                       3                              asynchronous                    hard
   .
   .
   .
  I want to test if the effect of movement type differed across experiments and motor effort, but I am a little confused of how the model should be constructed in this case.

  My current model is :   model <- lmer(DV ~ movement_type * experiment/motor_effort + (1|subject), data). Is that correct in terms of my purpose?

  I am also wondering how to center independent variables in this case. For movement_type, I could code "synchronous" as "0.5" and "asynchronous" as "-0.5". For motor_effort, should I center them for each experiment separately, or across all experiment?

Thank you for your help!
Yuqi


	[[alternative HTML version deleted]]


From jake.a.westfall at gmail.com  Mon Oct  9 16:54:24 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Mon, 9 Oct 2017 09:54:24 -0500
Subject: [R-sig-ME] mixed-effects model with partially nested fixed
	effects
In-Reply-To: <90e7574a32c74d7686ba198e9986ae5d@Mercury.psych.udel.edu>
References: <90e7574a32c74d7686ba198e9986ae5d@Mercury.psych.udel.edu>
Message-ID: <CAE9_Wg6QGPVqWnQEmZkw8pYMvP2VP8f6uNgh1MLCkiVMjxzMpQ@mail.gmail.com>

Hi Yuqi,

Because each subject has only a single row, you don't need random effects
for subjects. You do have observations nested in experiments, so you
probably want some sort of experiment effects. Right now you have fixed
experiment effects, but random effects probably make more sense.

The maximal model
<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.703.657&rep=rep1&type=pdf>
w/
random experiment effects would be like:
lmer(DV ~ movement_type*motor_effort + (movement_type*motor_effort|
experiment))

In case of convergence problems, you can probably drop the random
movement_type*motor_effort
interaction, but usually it's best to decide what to drop by eyeballing the
nonconverged results to see which random effects seem extraneous (due to
either 0 estimated variance or perfect estimated correlations with other
random effects).

As for how to center, it depends on what you're interested in. A good
reference here is Enders & Tofighi
<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.928.9848&rep=rep1&type=pdf>
.

Jake


On Mon, Oct 9, 2017 at 9:20 AM, Yuqi Liu <yliu at psych.udel.edu> wrote:

> Hi R-experts,
>
>   I am analyzing data from 3 experiments using linear mixed model. Each
> experiment had 2 fixed effects, movement type and motor effort. Movement
> type is shared by all experiments, motor effort varied but partially shared
> across experiments. The data looks like this:
>
>
>   Subject              experiment        movement_type
> motor_effort     DV
>
>   1                           1                              synchronous
>                     normal
>   2                           1                              asynchronous
>                   normal
>    .
>    .
>    .
>
>   101                       2                              synchronous
>                   normal
>   102                       2                              asynchronous
>                 normal
>   103                       2                              synchronous
>                   medium
>   104                       2                              asynchronous
>                 medium
>    .
>    .
>    .
>   201                       3                              synchronous
>                   normal
>   202                       3                              asynchronous
>                 normal
>   203                       3                              synchronous
>                   hard
>   204                       3                              asynchronous
>                 hard
>    .
>    .
>    .
>   I want to test if the effect of movement type differed across
> experiments and motor effort, but I am a little confused of how the model
> should be constructed in this case.
>
>   My current model is :   model <- lmer(DV ~ movement_type *
> experiment/motor_effort + (1|subject), data). Is that correct in terms of
> my purpose?
>
>   I am also wondering how to center independent variables in this case.
> For movement_type, I could code "synchronous" as "0.5" and "asynchronous"
> as "-0.5". For motor_effort, should I center them for each experiment
> separately, or across all experiment?
>
> Thank you for your help!
> Yuqi
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From adomalik at sfu.ca  Mon Oct  9 18:05:59 2017
From: adomalik at sfu.ca (Alice Domalik)
Date: Mon, 9 Oct 2017 09:05:59 -0700 (PDT)
Subject: [R-sig-ME] spatial covariance structure in glmmTMB
In-Reply-To: <CAMu=eMBXb2OWFw2xNmq+0XSwFU1=m2bN5tCqjXT9U40EpLFV7g@mail.gmail.com>
References: <845771341.62814150.1507555332287.JavaMail.zimbra@sfu.ca>
 <CAMu=eMBXb2OWFw2xNmq+0XSwFU1=m2bN5tCqjXT9U40EpLFV7g@mail.gmail.com>
Message-ID: <1841227664.62914605.1507565159002.JavaMail.zimbra@sfu.ca>

I did look at the vignette, and the notation wasn't clear to me. 
If, for example, I wanted to add a spatial gaussian, would I write my model as: 

m1<-glmmTMB(count~gau(coordinates) + waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) ? 

It also isn't clear to me if spatial coordinates need to be in a particular format. 


From: "Mollie Brooks" <mollieebrooks at gmail.com> 
To: "Alice Domalik" <adomalik at sfu.ca> 
Cc: r-sig-mixed-models at r-project.org, "Kasper Kristensen" <kaskr at dtu.dk> 
Sent: Monday, October 9, 2017 6:42:48 AM 
Subject: Re: [R-sig-ME] spatial covariance structure in glmmTMB 

Hi Alice, 
Have you looked at the vignette on covariance structures? There's a section on spatial correlations. 

[ https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html | https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html ] 

cheers, 
Mollie 

On Mon, Oct 9, 2017 at 3:22 PM, Alice Domalik < [ mailto:adomalik at sfu.ca | adomalik at sfu.ca ] > wrote: 


Dear list, 

I am fitting mixed effects models using the package glmmTMB to investigate habitat use. 
My current model has the form m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) 
I would like to add a spatial covariance structure based on geographic coordinates (mydata$x and mydata$y). 
However, I do not know how to modify my model formula to include a spatial covariance structure. Does anyone have example code to show how this is done? 

Any help would be much appreciated! 



[[alternative HTML version deleted]] 

_______________________________________________ 
[ mailto:R-sig-mixed-models at r-project.org | R-sig-mixed-models at r-project.org ] mailing list 
[ https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models | https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models ] 





	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct  9 19:07:24 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Oct 2017 13:07:24 -0400
Subject: [R-sig-ME] ZINB model validation and interpretation
In-Reply-To: <91b4b6059620683ce3b36ce5805146c5.squirrel@webmail.unavarra.es>
References: <7a1fb2d51795472cc3954f92ce9b10c5.squirrel@webmail.unavarra.es>
 <CABghstTKAzCgwurDse4tEGSh68kwioz=tdttsmKtx0qzkLS1qA@mail.gmail.com>
 <91b4b6059620683ce3b36ce5805146c5.squirrel@webmail.unavarra.es>
Message-ID: <CABghstSk+9wSXSMnS7hTeSmDdvVPQSgeUJD4jWps4Up8vxVjaQ@mail.gmail.com>

 Please keep r-sig-mixed-models in the Cc: (this is borderline since
the questions are a bit off topic, but the more important [to me]
point is that I don't want to engage in off-list conversations about
stats help outside of direct collaborations ...)

On Fri, Oct 6, 2017 at 4:11 PM,  <miriam.alzate at unavarra.es> wrote:
> Hi Ben,
>
> Many thanks for the answer and sorry for the delay.
>
> The first part is ok. Would you compute the BIC test as well? The point is
> that I am getting a N/A when I run the BIC test in R for my ZINB and ZIP
> models, it works right for the P and NB. AIC, VUONG and likelihood ratio
> test are Ok.

  BIC, AIC, likelihood, and Vuong are all reasonable approaches to
model testing. They all answer slightly different questions, and you
should be aware of the differences, e.g. see
http://emdbolker.wikidot.com/blog:aic-vs-bic . I don't know why you
get NA values; a reproducible example would be helpful (you should
probably post it to the glmmTMB issues list
<https://github.com/glmmTMB/glmmTMB/issues>

>
> The second part is quite unfamiliar for me. Could you let me know the
> package or what kind of code should I use for it? I have read something
> about bootstrapping.

  You can use the simulate() function for a sort of posterior
predictive simulation (although not one that takes uncertainty in the
parameter estimates into account ...) see e.g. Gelman and Hill 2007.
>
> Thanks a lot
>
> Miriam
>
> El Mie, 20 de Septiembre de 2017, 20:24, Ben Bolker escribi?:
>> This isn't actually a mixed-model question as far as I can tell, but
>> I'll take a stab at it.  (https://stats.stackexchange.com is probably
>> the best option for follow-ups, as R-help isn't for general statistics
>> questions.)
>>
>> Your approach seems not-crazy to me, although I would probably be
>> lazier/slopper and compare all four cases (P, NB, ZIP, ZINB) in a
>> single AIC(c) table. In any case, there are very basic issues with
>> either P vs NB or ZIP vs ZINB tests based on any of the standard
>> approaches (Vuong, *IC, likelihood ratio test) that come from the fact
>> that one of the pair of models is on the boundary of the feasible
>> space, see e.g.
>> https://stats.stackexchange.com/questions/182020/zero-inflated-poisson-regression-vuong-test-raw-aic-or-bic-corrected-results/217869
>>
>> For validity and robustness, I would suggest more "impressionistic"
>> diagnostics (inspect residuals for independence of predictors, lack of
>> heteroscedasticity; look for influential/outlier residuals; compare
>> patterns of predictions with patterns in raw data for evidence of
>> unexpected patterns). If you want more formal tests, try generating
>> posterior predictive simulations of quantities that are important to
>> you and see if they match the observed values of those quantities.
>>
>> On Mon, Sep 18, 2017 at 6:25 PM,  <miriam.alzate at unavarra.es> wrote:
>>> Hello,
>>> I am working with a ZINB model in R. To validate it, I first did a VUONG
>>> test to compare it with a standard NB model. The result is that the ZINB
>>> is better than the NB. Then, I compared the ZINB to a ZIP model,
>>> comparing
>>> the AIC index and the log-likelihood and I also get that the ZINB fits
>>> better than the ZIP.
>>>
>>> However, I would like to know if I should take other tests into
>>> consideration to show the validity and robustness of my model.
>>>
>>> On the other hand, I would like to know if I can interpret the
>>> coefficients directly from the model result or I should compute the Odds
>>> ratios.
>>>
>>> Thanks a lot,
>>>
>>> Miriam
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


From bbolker at gmail.com  Tue Oct 10 00:05:19 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Oct 2017 18:05:19 -0400
Subject: [R-sig-ME] spatial covariance structure in glmmTMB
In-Reply-To: <1841227664.62914605.1507565159002.JavaMail.zimbra@sfu.ca>
References: <845771341.62814150.1507555332287.JavaMail.zimbra@sfu.ca>
 <CAMu=eMBXb2OWFw2xNmq+0XSwFU1=m2bN5tCqjXT9U40EpLFV7g@mail.gmail.com>
 <1841227664.62914605.1507565159002.JavaMail.zimbra@sfu.ca>
Message-ID: <CABghstTYQFQMYOj-AP2MdjqTDNXDcOp_Kdka6rs+QDq0Zq7A4Q@mail.gmail.com>

Did you see the part of the document (sub)titled "Adding coordinate
information" ?  (The example given in the vignette only does a 1-D
example, but it gives instructions that should in principle work for
2-D ...)

On Mon, Oct 9, 2017 at 12:05 PM, Alice Domalik <adomalik at sfu.ca> wrote:
> I did look at the vignette, and the notation wasn't clear to me.
> If, for example, I wanted to add a spatial gaussian, would I write my model as:
>
> m1<-glmmTMB(count~gau(coordinates) + waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) ?
>
> It also isn't clear to me if spatial coordinates need to be in a particular format.
>
>
> From: "Mollie Brooks" <mollieebrooks at gmail.com>
> To: "Alice Domalik" <adomalik at sfu.ca>
> Cc: r-sig-mixed-models at r-project.org, "Kasper Kristensen" <kaskr at dtu.dk>
> Sent: Monday, October 9, 2017 6:42:48 AM
> Subject: Re: [R-sig-ME] spatial covariance structure in glmmTMB
>
> Hi Alice,
> Have you looked at the vignette on covariance structures? There's a section on spatial correlations.
>
> [ https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html | https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html ]
>
> cheers,
> Mollie
>
> On Mon, Oct 9, 2017 at 3:22 PM, Alice Domalik < [ mailto:adomalik at sfu.ca | adomalik at sfu.ca ] > wrote:
>
>
> Dear list,
>
> I am fitting mixed effects models using the package glmmTMB to investigate habitat use.
> My current model has the form m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata)
> I would like to add a spatial covariance structure based on geographic coordinates (mydata$x and mydata$y).
> However, I do not know how to modify my model formula to include a spatial covariance structure. Does anyone have example code to show how this is done?
>
> Any help would be much appreciated!
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> [ mailto:R-sig-mixed-models at r-project.org | R-sig-mixed-models at r-project.org ] mailing list
> [ https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models | https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models ]
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From orchidn at live.com  Tue Oct 10 19:44:37 2017
From: orchidn at live.com (dani)
Date: Tue, 10 Oct 2017 17:44:37 +0000
Subject: [R-sig-ME] effective sample size in MCMCglmm
Message-ID: <MWHPR1201MB00295645C763B6FFBC90A0F0D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,


My question is:

do the effective samples I obtain in my MCMCglmm output (attached below) make sense?


I understand that the rule of thumb is to get effective samples of at least 100-1000. How should I tweak the thin, burnin, and the nitt specifications? My computer reaches its memory limit fast and I have barely been able to run the model below.


I have the following model:

k<-12 # number of fixed effects

prior2<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
             R=list(V=1, nu=0),
             G=list(G1=list(V=1, nu=0),
                    G2=list(V=1, nu=0),
                    G3=list(V=1, nu=0)))

prior2$B$mu[k]<-1
prior2$B$V[k,k]<-1e-4

m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
                  random =~ studyid+class+idv(l_lfvcspn),
                  data   = wo1,
                  family = "poisson", prior=prior2,
                  verbose=FALSE,
                  thin   = 10,
                  burnin = 2000,
                  nitt   = 200000,
                  saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)


Iterations = 2001:199991
Thinning interval  = 10
Sample size  = 19800
DIC: 2930.006

G-structure:
~studyid
           post.mean  l-95% CI u-95% CI eff.samp
studyid    0.1053 1.814e-11   0.5757    81.12
~class
          post.mean l-95% CI u-95% CI eff.samp
class    0.7008  0.07577    1.207    382.1

~idv(l_lfvcspn)
                 post.mean l-95% CI u-95% CI eff.samp
l_lfvcspn.     705.7    37.33     2044    11852

R-structure:
~units
           post.mean l-95% CI u-95% CI eff.samp
units     2.516    1.809     3.23    336.6

Location effects: y ~ f_newage_c + x2n + x8n + x9n + x5n + l_lfvcspo + x3n + x4n + x6n + x7n + offset
                       post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
(Intercept) -7.0395427 -7.5590206 -6.5187847    865.6 <5e-05 ***
f_newage_c   0.0099703 -0.0222981  0.0448880   3324.7 0.5615
x2nM        -0.1068377 -0.3782251  0.1678528   3760.2 0.4462
x8n1         0.4103047  0.0920875  0.7179638   3884.3 0.0099 **
x9n1        -0.2784715 -0.5975232  0.0495615   3337.9 0.0901 .
x5n         -0.0009378 -0.0064175  0.0044266   3528.4 0.7283
l_lfvcspo    0.4018810 -0.8271349  1.4468375  14536.6 0.4080
x3n          0.0789652 -0.0018683  0.1523108   3726.0 0.0438 *
x4n          0.0602655 -0.0643903  0.1859443   2711.9 0.3356
x6n         -0.0137132 -0.0728385  0.0449804   3489.7 0.6453

Thank you all so much,
Dani


<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From orchidn at live.com  Tue Oct 10 19:52:26 2017
From: orchidn at live.com (dani)
Date: Tue, 10 Oct 2017 17:52:26 +0000
Subject: [R-sig-ME] tracePlot for a huge MCMCglmm model
Message-ID: <MWHPR1201MB00292AC8D0B78C36EDFC0F99D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,


I obtained a very large MCMCglmm object and I tried to plot it. I have about 7000 observations nested into two groups of about 1500 each. Just to give you an idea, if I attempt to save the model as a rds, I succeed, but I cannot read it afterwards because of memory allocation issues. My issue is that I cannot plot it nor perform a diagnostic because of its size.


My questions are:

Should I conduct my analysis on a smaller random dataset (20% of the data or 50% of the data) and present those results graphically and conduct a diagnostic test for those? Is it ok to report those results and make comments about the potential convergence of the model based on the full dataset? My instinct tells me it is probably not ok to do this, but I thought I should ask about this:)


Thank you very much!

Best,

Dani

	[[alternative HTML version deleted]]


From mew0099 at auburn.edu  Tue Oct 10 20:17:20 2017
From: mew0099 at auburn.edu (Matthew)
Date: Tue, 10 Oct 2017 13:17:20 -0500
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <MWHPR1201MB00295645C763B6FFBC90A0F0D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00295645C763B6FFBC90A0F0D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <79f19d69-16dc-df4e-6484-5f3cb0ed21d5@auburn.edu>

Hi Dani,

You might want to have a good read through the extensive Course Notes 
that Jarrod Hadfield has written to accompany the MCMCglmm package. 
Particularly (but not exclusively), Sections 1.3.1 and all of 1.4 
pertain to these issues.

Your specifications of `nitt`, `thin`, and `burnin` are such that you 
have retained almost 20,000 samples so it is not surprising your 
computer is having issues. However, the effective sample sizes being so 
low means that the almost 20,000 samples you have retained are not 
independent.

What you really need to change is the thinning interval. Given how bad 
your effective sample sizes are compared to the total number of samples 
retained, I would start with `thin=100` and see if that reduces the 
autocorrelation between successive samples. You can check the 
autocorrelation with `autocorr.diag(m3.new$Sol[, 1:k])` and 
`autocorr.diag(m3.new$VCV)`, for the location effects and variance 
components, respectively.

You will need to figure out the best `burnin`, but start with 
`burnin=3000` and increase if the traceplots show a pattern at the 
beginning of the trace.

Remember to adjust `nitt` to run the MCMC long enough to get the desired 
number of samples, but not excessively longer. So nitt = burnin + 
thin*(number of samples to keep). All of this will result in a suggested 
model specification like the following, but this will likely need to be 
changed once you diagnose the performance with your actual data:

nsamp <- 1000
THIN <- 100
BURNIN <- 3000
NITT <- BURNIN + THIN*nsamp
m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
                   random =~ studyid+class+idv(l_lfvcspn),
                   data   = wo1,
                   family = "poisson", prior=prior2,
                   verbose=FALSE,
                   thin   = THIN,     #<-- CHANGED
                   burnin = BURNIN,   #<-- CHANGED
                   nitt   = NITT,     #<-- CHANGED
                   saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
autocorr.diag(m3new$Sol[, 1:k])
autocorr.diag(m3new$VCV)

With regards to your other message concerning the trace plots, this is 
likely because you have so many samples (almost 20,000). Once you have 
changed the `nitt` to reflect the `thin` and `burnin` required to give 
you the least autocorrelation and effective samples close to the number 
of samples you want, then you should be able to save the model and run 
the MCMC diagnostics much more easily.

Sincerely,
Matthew



On 10/10/2017 12:44 PM, dani wrote:
> Hello everyone,
>
>
> My question is:
>
> do the effective samples I obtain in my MCMCglmm output (attached below) make sense?
>
>
> I understand that the rule of thumb is to get effective samples of at least 100-1000. How should I tweak the thin, burnin, and the nitt specifications? My computer reaches its memory limit fast and I have barely been able to run the model below.
>
>
> I have the following model:
>
> k<-12 # number of fixed effects
>
> prior2<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>               R=list(V=1, nu=0),
>               G=list(G1=list(V=1, nu=0),
>                      G2=list(V=1, nu=0),
>                      G3=list(V=1, nu=0)))
>
> prior2$B$mu[k]<-1
> prior2$B$V[k,k]<-1e-4
>
> m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
>                    random =~ studyid+class+idv(l_lfvcspn),
>                    data   = wo1,
>                    family = "poisson", prior=prior2,
>                    verbose=FALSE,
>                    thin   = 10,
>                    burnin = 2000,
>                    nitt   = 200000,
>                    saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>
>
> Iterations = 2001:199991
> Thinning interval  = 10
> Sample size  = 19800
> DIC: 2930.006
>
> G-structure:
> ~studyid
>             post.mean  l-95% CI u-95% CI eff.samp
> studyid    0.1053 1.814e-11   0.5757    81.12
> ~class
>            post.mean l-95% CI u-95% CI eff.samp
> class    0.7008  0.07577    1.207    382.1
>
> ~idv(l_lfvcspn)
>                   post.mean l-95% CI u-95% CI eff.samp
> l_lfvcspn.     705.7    37.33     2044    11852
>
> R-structure:
> ~units
>             post.mean l-95% CI u-95% CI eff.samp
> units     2.516    1.809     3.23    336.6
>
> Location effects: y ~ f_newage_c + x2n + x8n + x9n + x5n + l_lfvcspo + x3n + x4n + x6n + x7n + offset
>                         post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> (Intercept) -7.0395427 -7.5590206 -6.5187847    865.6 <5e-05 ***
> f_newage_c   0.0099703 -0.0222981  0.0448880   3324.7 0.5615
> x2nM        -0.1068377 -0.3782251  0.1678528   3760.2 0.4462
> x8n1         0.4103047  0.0920875  0.7179638   3884.3 0.0099 **
> x9n1        -0.2784715 -0.5975232  0.0495615   3337.9 0.0901 .
> x5n         -0.0009378 -0.0064175  0.0044266   3528.4 0.7283
> l_lfvcspo    0.4018810 -0.8271349  1.4468375  14536.6 0.4080
> x3n          0.0789652 -0.0018683  0.1523108   3726.0 0.0438 *
> x4n          0.0602655 -0.0643903  0.1859443   2711.9 0.3356
> x6n         -0.0137132 -0.0728385  0.0449804   3489.7 0.6453
>
> Thank you all so much,
> Dani
>
>
> <http://aka.ms/weboutlook>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 


****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu
Tel: 334-844-9242


From orchidn at live.com  Tue Oct 10 20:21:30 2017
From: orchidn at live.com (dani)
Date: Tue, 10 Oct 2017 18:21:30 +0000
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <79f19d69-16dc-df4e-6484-5f3cb0ed21d5@auburn.edu>
References: <MWHPR1201MB00295645C763B6FFBC90A0F0D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <79f19d69-16dc-df4e-6484-5f3cb0ed21d5@auburn.edu>
Message-ID: <MWHPR1201MB00292202878522A5216E2F2ED6750@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Matthew,


Thank you so much for such a thorough answer! This is so helpful! I truly appreciate it!

Best regards,

D

________________________________
From: Matthew <mew0099 at auburn.edu>
Sent: Tuesday, October 10, 2017 11:17 AM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] effective sample size in MCMCglmm

Hi Dani,

You might want to have a good read through the extensive Course Notes
that Jarrod Hadfield has written to accompany the MCMCglmm package.
Particularly (but not exclusively), Sections 1.3.1 and all of 1.4
pertain to these issues.

Your specifications of `nitt`, `thin`, and `burnin` are such that you
have retained almost 20,000 samples so it is not surprising your
computer is having issues. However, the effective sample sizes being so
low means that the almost 20,000 samples you have retained are not
independent.

What you really need to change is the thinning interval. Given how bad
your effective sample sizes are compared to the total number of samples
retained, I would start with `thin=100` and see if that reduces the
autocorrelation between successive samples. You can check the
autocorrelation with `autocorr.diag(m3.new$Sol[, 1:k])` and
`autocorr.diag(m3.new$VCV)`, for the location effects and variance
components, respectively.

You will need to figure out the best `burnin`, but start with
`burnin=3000` and increase if the traceplots show a pattern at the
beginning of the trace.

Remember to adjust `nitt` to run the MCMC long enough to get the desired
number of samples, but not excessively longer. So nitt = burnin +
thin*(number of samples to keep). All of this will result in a suggested
model specification like the following, but this will likely need to be
changed once you diagnose the performance with your actual data:

nsamp <- 1000
THIN <- 100
BURNIN <- 3000
NITT <- BURNIN + THIN*nsamp
m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
                   random =~ studyid+class+idv(l_lfvcspn),
                   data   = wo1,
                   family = "poisson", prior=prior2,
                   verbose=FALSE,
                   thin   = THIN,     #<-- CHANGED
                   burnin = BURNIN,   #<-- CHANGED
                   nitt   = NITT,     #<-- CHANGED
                   saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
autocorr.diag(m3new$Sol[, 1:k])
autocorr.diag(m3new$VCV)

With regards to your other message concerning the trace plots, this is
likely because you have so many samples (almost 20,000). Once you have
changed the `nitt` to reflect the `thin` and `burnin` required to give
you the least autocorrelation and effective samples close to the number
of samples you want, then you should be able to save the model and run
the MCMC diagnostics much more easily.

Sincerely,
Matthew



On 10/10/2017 12:44 PM, dani wrote:
> Hello everyone,
>
>
> My question is:
>
> do the effective samples I obtain in my MCMCglmm output (attached below) make sense?
>
>
> I understand that the rule of thumb is to get effective samples of at least 100-1000. How should I tweak the thin, burnin, and the nitt specifications? My computer reaches its memory limit fast and I have barely been able to run the model below.
>
>
> I have the following model:
>
> k<-12 # number of fixed effects
>
> prior2<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>               R=list(V=1, nu=0),
>               G=list(G1=list(V=1, nu=0),
>                      G2=list(V=1, nu=0),
>                      G3=list(V=1, nu=0)))
>
> prior2$B$mu[k]<-1
> prior2$B$V[k,k]<-1e-4
>
> m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
>                    random =~ studyid+class+idv(l_lfvcspn),
>                    data   = wo1,
>                    family = "poisson", prior=prior2,
>                    verbose=FALSE,
>                    thin   = 10,
>                    burnin = 2000,
>                    nitt   = 200000,
>                    saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>
>
> Iterations = 2001:199991
> Thinning interval  = 10
> Sample size  = 19800
> DIC: 2930.006
>
> G-structure:
> ~studyid
>             post.mean  l-95% CI u-95% CI eff.samp
> studyid    0.1053 1.814e-11   0.5757    81.12
> ~class
>            post.mean l-95% CI u-95% CI eff.samp
> class    0.7008  0.07577    1.207    382.1
>
> ~idv(l_lfvcspn)
>                   post.mean l-95% CI u-95% CI eff.samp
> l_lfvcspn.     705.7    37.33     2044    11852
>
> R-structure:
> ~units
>             post.mean l-95% CI u-95% CI eff.samp
> units     2.516    1.809     3.23    336.6
>
> Location effects: y ~ f_newage_c + x2n + x8n + x9n + x5n + l_lfvcspo + x3n + x4n + x6n + x7n + offset
>                         post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> (Intercept) -7.0395427 -7.5590206 -6.5187847    865.6 <5e-05 ***
> f_newage_c   0.0099703 -0.0222981  0.0448880   3324.7 0.5615
> x2nM        -0.1068377 -0.3782251  0.1678528   3760.2 0.4462
> x8n1         0.4103047  0.0920875  0.7179638   3884.3 0.0099 **
> x9n1        -0.2784715 -0.5975232  0.0495615   3337.9 0.0901 .
> x5n         -0.0009378 -0.0064175  0.0044266   3528.4 0.7283
> l_lfvcspo    0.4018810 -0.8271349  1.4468375  14536.6 0.4080
> x3n          0.0789652 -0.0018683  0.1523108   3726.0 0.0438 *
> x4n          0.0602655 -0.0643903  0.1859443   2711.9 0.3356
> x6n         -0.0137132 -0.0728385  0.0449804   3489.7 0.6453
>
> Thank you all so much,
> Dani
>
>
> <http://aka.ms/weboutlook>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...




--


****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu
Tel: 334-844-9242


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Oct 10 21:29:25 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 10 Oct 2017 20:29:25 +0100
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <MWHPR1201MB00292202878522A5216E2F2ED6750@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00295645C763B6FFBC90A0F0D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <79f19d69-16dc-df4e-6484-5f3cb0ed21d5@auburn.edu>
 <MWHPR1201MB00292202878522A5216E2F2ED6750@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <16a88b01-0ba2-02a8-cbc8-187a7551c062@ed.ac.uk>

Hi,

You probably want to have pl=FALSE too, unless you have a special reason 
to save the latent variables? Currently this saves 20,000*7,000 = 
140,000,000 numbers, which will take about 1GB of memory.

Cheers,

Jarrod



On 10/10/2017 19:21, dani wrote:
> Hello Matthew,
>
>
> Thank you so much for such a thorough answer! This is so helpful! I truly appreciate it!
>
> Best regards,
>
> D
>
> ________________________________
> From: Matthew <mew0099 at auburn.edu>
> Sent: Tuesday, October 10, 2017 11:17 AM
> To: dani; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] effective sample size in MCMCglmm
>
> Hi Dani,
>
> You might want to have a good read through the extensive Course Notes
> that Jarrod Hadfield has written to accompany the MCMCglmm package.
> Particularly (but not exclusively), Sections 1.3.1 and all of 1.4
> pertain to these issues.
>
> Your specifications of `nitt`, `thin`, and `burnin` are such that you
> have retained almost 20,000 samples so it is not surprising your
> computer is having issues. However, the effective sample sizes being so
> low means that the almost 20,000 samples you have retained are not
> independent.
>
> What you really need to change is the thinning interval. Given how bad
> your effective sample sizes are compared to the total number of samples
> retained, I would start with `thin=100` and see if that reduces the
> autocorrelation between successive samples. You can check the
> autocorrelation with `autocorr.diag(m3.new$Sol[, 1:k])` and
> `autocorr.diag(m3.new$VCV)`, for the location effects and variance
> components, respectively.
>
> You will need to figure out the best `burnin`, but start with
> `burnin=3000` and increase if the traceplots show a pattern at the
> beginning of the trace.
>
> Remember to adjust `nitt` to run the MCMC long enough to get the desired
> number of samples, but not excessively longer. So nitt = burnin +
> thin*(number of samples to keep). All of this will result in a suggested
> model specification like the following, but this will likely need to be
> changed once you diagnose the performance with your actual data:
>
> nsamp <- 1000
> THIN <- 100
> BURNIN <- 3000
> NITT <- BURNIN + THIN*nsamp
> m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
>                     random =~ studyid+class+idv(l_lfvcspn),
>                     data   = wo1,
>                     family = "poisson", prior=prior2,
>                     verbose=FALSE,
>                     thin   = THIN,     #<-- CHANGED
>                     burnin = BURNIN,   #<-- CHANGED
>                     nitt   = NITT,     #<-- CHANGED
>                     saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
> autocorr.diag(m3new$Sol[, 1:k])
> autocorr.diag(m3new$VCV)
>
> With regards to your other message concerning the trace plots, this is
> likely because you have so many samples (almost 20,000). Once you have
> changed the `nitt` to reflect the `thin` and `burnin` required to give
> you the least autocorrelation and effective samples close to the number
> of samples you want, then you should be able to save the model and run
> the MCMC diagnostics much more easily.
>
> Sincerely,
> Matthew
>
>
>
> On 10/10/2017 12:44 PM, dani wrote:
>> Hello everyone,
>>
>>
>> My question is:
>>
>> do the effective samples I obtain in my MCMCglmm output (attached below) make sense?
>>
>>
>> I understand that the rule of thumb is to get effective samples of at least 100-1000. How should I tweak the thin, burnin, and the nitt specifications? My computer reaches its memory limit fast and I have barely been able to run the model below.
>>
>>
>> I have the following model:
>>
>> k<-12 # number of fixed effects
>>
>> prior2<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>>                R=list(V=1, nu=0),
>>                G=list(G1=list(V=1, nu=0),
>>                       G2=list(V=1, nu=0),
>>                       G3=list(V=1, nu=0)))
>>
>> prior2$B$mu[k]<-1
>> prior2$B$V[k,k]<-1e-4
>>
>> m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
>>                     random =~ studyid+class+idv(l_lfvcspn),
>>                     data   = wo1,
>>                     family = "poisson", prior=prior2,
>>                     verbose=FALSE,
>>                     thin   = 10,
>>                     burnin = 2000,
>>                     nitt   = 200000,
>>                     saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>>
>>
>> Iterations = 2001:199991
>> Thinning interval  = 10
>> Sample size  = 19800
>> DIC: 2930.006
>>
>> G-structure:
>> ~studyid
>>              post.mean  l-95% CI u-95% CI eff.samp
>> studyid    0.1053 1.814e-11   0.5757    81.12
>> ~class
>>             post.mean l-95% CI u-95% CI eff.samp
>> class    0.7008  0.07577    1.207    382.1
>>
>> ~idv(l_lfvcspn)
>>                    post.mean l-95% CI u-95% CI eff.samp
>> l_lfvcspn.     705.7    37.33     2044    11852
>>
>> R-structure:
>> ~units
>>              post.mean l-95% CI u-95% CI eff.samp
>> units     2.516    1.809     3.23    336.6
>>
>> Location effects: y ~ f_newage_c + x2n + x8n + x9n + x5n + l_lfvcspo + x3n + x4n + x6n + x7n + offset
>>                          post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>> (Intercept) -7.0395427 -7.5590206 -6.5187847    865.6 <5e-05 ***
>> f_newage_c   0.0099703 -0.0222981  0.0448880   3324.7 0.5615
>> x2nM        -0.1068377 -0.3782251  0.1678528   3760.2 0.4462
>> x8n1         0.4103047  0.0920875  0.7179638   3884.3 0.0099 **
>> x9n1        -0.2784715 -0.5975232  0.0495615   3337.9 0.0901 .
>> x5n         -0.0009378 -0.0064175  0.0044266   3528.4 0.7283
>> l_lfvcspo    0.4018810 -0.8271349  1.4468375  14536.6 0.4080
>> x3n          0.0789652 -0.0018683  0.1523108   3726.0 0.0438 *
>> x4n          0.0602655 -0.0643903  0.1859443   2711.9 0.3356
>> x6n         -0.0137132 -0.0728385  0.0449804   3489.7 0.6453
>>
>> Thank you all so much,
>> Dani
>>
>>
>> <http://aka.ms/weboutlook>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>
> --
>
>
> ****************************************************
> Matthew E. Wolak, Ph.D.
> Assistant Professor
> Department of Biological Sciences
> Auburn University
> 306 Funchess Hall
> Auburn, AL 36849, USA
> Email: matthew.wolak at auburn.edu
> Tel: 334-844-9242
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From orchidn at live.com  Tue Oct 10 21:41:35 2017
From: orchidn at live.com (dani)
Date: Tue, 10 Oct 2017 19:41:35 +0000
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <16a88b01-0ba2-02a8-cbc8-187a7551c062@ed.ac.uk>
References: <MWHPR1201MB00295645C763B6FFBC90A0F0D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <79f19d69-16dc-df4e-6484-5f3cb0ed21d5@auburn.edu>
 <MWHPR1201MB00292202878522A5216E2F2ED6750@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <16a88b01-0ba2-02a8-cbc8-187a7551c062@ed.ac.uk>
Message-ID: <MWHPR1201MB00297A8C3E171939E7B55825D6750@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


Thank you so much, I will change the code and specify pl=FALSE!

I ran the model based on Matthew's suggestion and I got the output below. What effective sample should I aim for in regards to the  G structure (studyid) - should I try again tweaking the specifications based on higher burnins until I reach an effective sample of 100 for studyid?


On a separate note, I managed to plot the model, but it looks illegible, the graphs are so small given the large number of groups. Should I plot just a random subsample then?


Thank you all so much,

D

Iterations = 3001:102901
Thinning interval  = 100
Sample size  = 1000

DIC: 2928.214

 G-structure:  ~studyid

           post.mean  l-95% CI u-95% CI eff.samp
studyid   0.06139 5.424e-16   0.4621    21.16

               ~class

      post.mean l-95% CI u-95% CI eff.samp
class    0.7278    0.132    1.232    154.9

               ~idv(l_lfvcspn)

           post.mean l-95% CI u-95% CI eff.samp
l_lfvcspn.     752.6    50.16     2352     1000

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units     2.533    1.907    3.204    186.5

 Location effects: y ~ f_newage_c + x2n + x8n + x9n + x5n + l_lfvcspo + x3n + x4n + x6n + x7n + offset

            post.mean  l-95% CI  u-95% CI eff.samp  pMCMC
(Intercept) -7.033381 -7.535696 -6.524339    487.7 <0.001 ***
f_newage_c   0.009066 -0.025116  0.041159    909.3  0.596
x2nM        -0.107655 -0.403837  0.165664   1000.0  0.440
x8n1         0.413878  0.119578  0.745171    891.1  0.002 **
x9n1        -0.287382 -0.600003  0.016531    892.7  0.070 .
x5n         -0.001037 -0.006182  0.004417    864.8  0.670
l_lfvcspo    0.397952 -0.941309  1.455719   1000.0  0.426
x3n          0.079109 -0.001274  0.150664    914.1  0.042 *
x4n          0.058303 -0.067089  0.174404   1000.0  0.344
x6n         -0.013916 -0.067176  0.049719   1000.0  0.610
x7n         -0.014880 -0.081243  0.057582    710.6  0.654
offset       0.999452  0.977609  1.018083   1000.0 <0.001 ***


<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Tuesday, October 10, 2017 12:29 PM
To: dani; Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] effective sample size in MCMCglmm

Hi,

You probably want to have pl=FALSE too, unless you have a special reason
to save the latent variables? Currently this saves 20,000*7,000 =
140,000,000 numbers, which will take about 1GB of memory.

Cheers,

Jarrod



On 10/10/2017 19:21, dani wrote:
> Hello Matthew,
>
>
> Thank you so much for such a thorough answer! This is so helpful! I truly appreciate it!
>
> Best regards,
>
> D
>
> ________________________________
> From: Matthew <mew0099 at auburn.edu>
> Sent: Tuesday, October 10, 2017 11:17 AM
> To: dani; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] effective sample size in MCMCglmm
>
> Hi Dani,
>
> You might want to have a good read through the extensive Course Notes
> that Jarrod Hadfield has written to accompany the MCMCglmm package.
> Particularly (but not exclusively), Sections 1.3.1 and all of 1.4
> pertain to these issues.
>
> Your specifications of `nitt`, `thin`, and `burnin` are such that you
> have retained almost 20,000 samples so it is not surprising your
> computer is having issues. However, the effective sample sizes being so
> low means that the almost 20,000 samples you have retained are not
> independent.
>
> What you really need to change is the thinning interval. Given how bad
> your effective sample sizes are compared to the total number of samples
> retained, I would start with `thin=100` and see if that reduces the
> autocorrelation between successive samples. You can check the
> autocorrelation with `autocorr.diag(m3.new$Sol[, 1:k])` and
> `autocorr.diag(m3.new$VCV)`, for the location effects and variance
> components, respectively.
>
> You will need to figure out the best `burnin`, but start with
> `burnin=3000` and increase if the traceplots show a pattern at the
> beginning of the trace.
>
> Remember to adjust `nitt` to run the MCMC long enough to get the desired
> number of samples, but not excessively longer. So nitt = burnin +
> thin*(number of samples to keep). All of this will result in a suggested
> model specification like the following, but this will likely need to be
> changed once you diagnose the performance with your actual data:
>
> nsamp <- 1000
> THIN <- 100
> BURNIN <- 3000
> NITT <- BURNIN + THIN*nsamp
> m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
>                     random =~ studyid+class+idv(l_lfvcspn),
>                     data   = wo1,
>                     family = "poisson", prior=prior2,
>                     verbose=FALSE,
>                     thin   = THIN,     #<-- CHANGED
>                     burnin = BURNIN,   #<-- CHANGED
>                     nitt   = NITT,     #<-- CHANGED
>                     saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
> autocorr.diag(m3new$Sol[, 1:k])
> autocorr.diag(m3new$VCV)
>
> With regards to your other message concerning the trace plots, this is
> likely because you have so many samples (almost 20,000). Once you have
> changed the `nitt` to reflect the `thin` and `burnin` required to give
> you the least autocorrelation and effective samples close to the number
> of samples you want, then you should be able to save the model and run
> the MCMC diagnostics much more easily.
>
> Sincerely,
> Matthew
>
>
>
> On 10/10/2017 12:44 PM, dani wrote:
>> Hello everyone,
>>
>>
>> My question is:
>>
>> do the effective samples I obtain in my MCMCglmm output (attached below) make sense?
>>
>>
>> I understand that the rule of thumb is to get effective samples of at least 100-1000. How should I tweak the thin, burnin, and the nitt specifications? My computer reaches its memory limit fast and I have barely been able to run the model below.
>>
>>
>> I have the following model:
>>
>> k<-12 # number of fixed effects
>>
>> prior2<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>>                R=list(V=1, nu=0),
>>                G=list(G1=list(V=1, nu=0),
>>                       G2=list(V=1, nu=0),
>>                       G3=list(V=1, nu=0)))
>>
>> prior2$B$mu[k]<-1
>> prior2$B$V[k,k]<-1e-4
>>
>> m3new <- MCMCglmm(y ~ f_newage_c+x2n+x8n+x9n+x5n+l_lfvcspo+x3n+x4n+x6n+x7n+offset,
>>                     random =~ studyid+class+idv(l_lfvcspn),
>>                     data   = wo1,
>>                     family = "poisson", prior=prior2,
>>                     verbose=FALSE,
>>                     thin   = 10,
>>                     burnin = 2000,
>>                     nitt   = 200000,
>>                     saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>>
>>
>> Iterations = 2001:199991
>> Thinning interval  = 10
>> Sample size  = 19800
>> DIC: 2930.006
>>
>> G-structure:
>> ~studyid
>>              post.mean  l-95% CI u-95% CI eff.samp
>> studyid    0.1053 1.814e-11   0.5757    81.12
>> ~class
>>             post.mean l-95% CI u-95% CI eff.samp
>> class    0.7008  0.07577    1.207    382.1
>>
>> ~idv(l_lfvcspn)
>>                    post.mean l-95% CI u-95% CI eff.samp
>> l_lfvcspn.     705.7    37.33     2044    11852
>>
>> R-structure:
>> ~units
>>              post.mean l-95% CI u-95% CI eff.samp
>> units     2.516    1.809     3.23    336.6
>>
>> Location effects: y ~ f_newage_c + x2n + x8n + x9n + x5n + l_lfvcspo + x3n + x4n + x6n + x7n + offset
>>                          post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>> (Intercept) -7.0395427 -7.5590206 -6.5187847    865.6 <5e-05 ***
>> f_newage_c   0.0099703 -0.0222981  0.0448880   3324.7 0.5615
>> x2nM        -0.1068377 -0.3782251  0.1678528   3760.2 0.4462
>> x8n1         0.4103047  0.0920875  0.7179638   3884.3 0.0099 **
>> x9n1        -0.2784715 -0.5975232  0.0495615   3337.9 0.0901 .
>> x5n         -0.0009378 -0.0064175  0.0044266   3528.4 0.7283
>> l_lfvcspo    0.4018810 -0.8271349  1.4468375  14536.6 0.4080
>> x3n          0.0789652 -0.0018683  0.1523108   3726.0 0.0438 *
>> x4n          0.0602655 -0.0643903  0.1859443   2711.9 0.3356
>> x6n         -0.0137132 -0.0728385  0.0449804   3489.7 0.6453
>>
>> Thank you all so much,
>> Dani
>>
>>
>> <http://aka.ms/weboutlook>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>
> --
>
>
> ****************************************************
> Matthew E. Wolak, Ph.D.
> Assistant Professor
> Department of Biological Sciences
> Auburn University
> 306 Funchess Hall
> Auburn, AL 36849, USA
> Email: matthew.wolak at auburn.edu
> Tel: 334-844-9242
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


	[[alternative HTML version deleted]]


From walidmawass10 at gmail.com  Wed Oct 11 20:06:39 2017
From: walidmawass10 at gmail.com (Walid Mawass)
Date: Wed, 11 Oct 2017 14:06:39 -0400
Subject: [R-sig-ME] MCMCglmm binary data
Message-ID: <95b02759-ce9d-8f41-4e17-bda4c151e03d@gmail.com>

Hello everyone,

I am running an 'animal model' for a binary trait (0 or 1 value) using 
MCMCglmm. After reading Hadfield's course notes, i fixed the residual 
variance to 1 and used an inverse gamma distribution for the additive 
variance in my prior, and chose the family as "categorical" (link = 
logit)? since there is no order here. h2 would equal Va/Va+1+??/3, right?

Also, a different study was suggesting to use a ?? distribution (V=1, 
nu=1000, alpha.mu=0, alpha.V=1) as the prior distribution for binary 
traits (and only binary traits) when the sample is big enough (in my 
case N = ~5000). I wanted to know your opinion on this and if I should 
opt for it.

Thank you

-- 
Walid Mawass

M.Sc. of Cellular and Molecular Biology

Population Genetics Laboratory

University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


	[[alternative HTML version deleted]]


From adomalik at sfu.ca  Wed Oct 11 20:37:35 2017
From: adomalik at sfu.ca (Alice Domalik)
Date: Wed, 11 Oct 2017 11:37:35 -0700 (PDT)
Subject: [R-sig-ME] spatial covariance structure in glmmTMB
In-Reply-To: <CABghstTYQFQMYOj-AP2MdjqTDNXDcOp_Kdka6rs+QDq0Zq7A4Q@mail.gmail.com>
References: <845771341.62814150.1507555332287.JavaMail.zimbra@sfu.ca>
 <CAMu=eMBXb2OWFw2xNmq+0XSwFU1=m2bN5tCqjXT9U40EpLFV7g@mail.gmail.com>
 <1841227664.62914605.1507565159002.JavaMail.zimbra@sfu.ca>
 <CABghstTYQFQMYOj-AP2MdjqTDNXDcOp_Kdka6rs+QDq0Zq7A4Q@mail.gmail.com>
Message-ID: <1776635358.67364670.1507747055129.JavaMail.zimbra@sfu.ca>

In the end, I was able to run the following model: 

m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual) + gau(coord + 0| group), family=list(family="truncated_nbinom1", link="log"), data=mydata) 

Where 'coord' are the spatial coordinates (UTM) represented as a factor, and 'group' is a single level. 

group<-factor(rep(1,n)) 

However, I get the error: 

Warning message: 
In glmmTMB(count ~ waterdepth + temperature + : 
Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting') 

I didn't have this error when I initially ran my model without a covariance structure. 
Any advice on how I should move forward? 

Thanks!!! Alice 


From: "Ben Bolker" <bbolker at gmail.com> 
To: "Alice Domalik" <adomalik at sfu.ca> 
Cc: "Mollie Brooks" <mollieebrooks at gmail.com>, r-sig-mixed-models at r-project.org, "Kasper Kristensen" <kaskr at dtu.dk> 
Sent: Monday, October 9, 2017 3:05:19 PM 
Subject: Re: [R-sig-ME] spatial covariance structure in glmmTMB 

Did you see the part of the document (sub)titled "Adding coordinate 
information" ? (The example given in the vignette only does a 1-D 
example, but it gives instructions that should in principle work for 
2-D ...) 

On Mon, Oct 9, 2017 at 12:05 PM, Alice Domalik <adomalik at sfu.ca> wrote: 
> I did look at the vignette, and the notation wasn't clear to me. 
> If, for example, I wanted to add a spatial gaussian, would I write my model as: 
> 
> m1<-glmmTMB(count~gau(coordinates) + waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) ? 
> 
> It also isn't clear to me if spatial coordinates need to be in a particular format. 
> 
> 
> From: "Mollie Brooks" <mollieebrooks at gmail.com> 
> To: "Alice Domalik" <adomalik at sfu.ca> 
> Cc: r-sig-mixed-models at r-project.org, "Kasper Kristensen" <kaskr at dtu.dk> 
> Sent: Monday, October 9, 2017 6:42:48 AM 
> Subject: Re: [R-sig-ME] spatial covariance structure in glmmTMB 
> 
> Hi Alice, 
> Have you looked at the vignette on covariance structures? There's a section on spatial correlations. 
> 
> [ https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html | https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html ] 
> 
> cheers, 
> Mollie 
> 
> On Mon, Oct 9, 2017 at 3:22 PM, Alice Domalik < [ mailto:adomalik at sfu.ca | adomalik at sfu.ca ] > wrote: 
> 
> 
> Dear list, 
> 
> I am fitting mixed effects models using the package glmmTMB to investigate habitat use. 
> My current model has the form m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) 
> I would like to add a spatial covariance structure based on geographic coordinates (mydata$x and mydata$y). 
> However, I do not know how to modify my model formula to include a spatial covariance structure. Does anyone have example code to show how this is done? 
> 
> Any help would be much appreciated! 
> 
> 
> 
> [[alternative HTML version deleted]] 
> 
> _______________________________________________ 
> [ mailto:R-sig-mixed-models at r-project.org | R-sig-mixed-models at r-project.org ] mailing list 
> [ https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models | https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models ] 
> 
> 
> 
> 
> 
> [[alternative HTML version deleted]] 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 

	[[alternative HTML version deleted]]


From pierre.de.villemereuil at mailoo.org  Wed Oct 11 23:04:15 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Thu, 12 Oct 2017 10:04:15 +1300
Subject: [R-sig-ME] MCMCglmm binary data
In-Reply-To: <95b02759-ce9d-8f41-4e17-bda4c151e03d@gmail.com>
References: <95b02759-ce9d-8f41-4e17-bda4c151e03d@gmail.com>
Message-ID: <1526356.r4l39gF7jC@flyosflip>

Hi,

> I am running an 'animal model' for a binary trait (0 or 1 value) using 
> MCMCglmm. After reading Hadfield's course notes, i fixed the residual 
> variance to 1 and used an inverse gamma distribution for the additive 
> variance in my prior, and chose the family as "categorical" (link = 
> logit)  since there is no order here. h2 would equal Va/Va+1+??/3, right?

It depends on which kind of scale you wish to compute h?. Here you get an estimate that can be related to a "threshold model". It might be sensible or not, depending on your biological question. You can also get an estimate on the data scale through the QGglmm package. You might want to have a read at the following:
http://www.genetics.org/content/204/3/1281

Also, I would recommend using "ordinal" rather than "categorical", as the probit link bears connection with the classical threshold model and might make more biological sense. There is no question of ordering for binary data (as it is a "degenerate" case in that regard). You might have specific reasons for using "categorical" of course.

> Also, a different study was suggesting to use a ?? distribution (V=1, 
> nu=1000, alpha.mu=0, alpha.V=1) as the prior distribution for binary 
> traits (and only binary traits) when the sample is big enough (in my 
> case N = ~5000). I wanted to know your opinion on this and if I should 
> opt for it.

Yes, this prior has usually better properties for binary data. It resulted in a much better precision and better accuracy in simulations. See Appendix B of the following (sorry for the auto-promotion...):
http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12011/full

Hope this helps,
Pierre.


From Maarten.Jung at mailbox.tu-dresden.de  Thu Oct 12 02:09:42 2017
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 12 Oct 2017 02:09:42 +0200
Subject: [R-sig-ME] Using LRT with alpha = .2 in model reduction guided by
	PCA
Message-ID: <CAHr4Dyc7trHw=kGEnjpsL0N8RAMc01d-YoPZZv52brSELhEfHQ@mail.gmail.com>

Hi all,

Bates et al. (2015) [1] suggest an iterative reduction of degenerate
maximal models. First they use PCA to obtain the appropriate dimensionality
of the variance-covariance matrix of the random-effect structure. Given
this reference point, they suggest to drop all non-signi cant variance
components and correlation parameters from the model. But each reduction
can lead to a signi cant loss in goodness of fi t indicated by LRTs - in
which case the parameter should stay in the model.

Is it, in this PCA context, a good idea to choose an alpha level of 0.2 as
model-selection criterion as suggested by Matuschek et al. (2017) [2] to
balance the Type I error rate and power?

[1] https://arxiv.org/abs/1506.04967
[2] https://arxiv.org/abs/1511.01864


Best,
Maarten

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Oct 12 08:57:03 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 12 Oct 2017 07:57:03 +0100
Subject: [R-sig-ME] MCMCglmm binary data
In-Reply-To: <1526356.r4l39gF7jC@flyosflip>
References: <95b02759-ce9d-8f41-4e17-bda4c151e03d@gmail.com>
 <1526356.r4l39gF7jC@flyosflip>
Message-ID: <22ecbe33-8687-8434-9f04-c282a7c317f3@ed.ac.uk>

Hi,

If you want to fit a probit model I would use family="threshold". It 
omits the additional overdispersion term and so you can simply calculate 
the link-scale h2 as Va/(Va+1) if you fixed the residual variance to 
one. This is the 'standard' probit model. For family="ordinal"? the 
link-scale h2 is Va/(Va+1+1) if you fixed the residual variance to one. 
Additionally, using family="threshold" mixes better. In both cases there 
is now the option (v2.25 and above) to specify trunc=TRUE in the call to 
MCMCglmm. This stops the latent variable going in to extreme probability 
regions resulting in numerical errors which can be an issue with binary 
models.

Cheers,

Jarrod


On 11/10/2017 22:04, Pierre de Villemereuil wrote:
> Hi,
>
>> I am running an 'animal model' for a binary trait (0 or 1 value) using
>> MCMCglmm. After reading Hadfield's course notes, i fixed the residual
>> variance to 1 and used an inverse gamma distribution for the additive
>> variance in my prior, and chose the family as "categorical" (link =
>> logit)  since there is no order here. h2 would equal Va/Va+1+??/3, right?
> It depends on which kind of scale you wish to compute h?. Here you get an estimate that can be related to a "threshold model". It might be sensible or not, depending on your biological question. You can also get an estimate on the data scale through the QGglmm package. You might want to have a read at the following:
> http://www.genetics.org/content/204/3/1281
>
> Also, I would recommend using "ordinal" rather than "categorical", as the probit link bears connection with the classical threshold model and might make more biological sense. There is no question of ordering for binary data (as it is a "degenerate" case in that regard). You might have specific reasons for using "categorical" of course.
>
>> Also, a different study was suggesting to use a ?? distribution (V=1,
>> nu=1000, alpha.mu=0, alpha.V=1) as the prior distribution for binary
>> traits (and only binary traits) when the sample is big enough (in my
>> case N = ~5000). I wanted to know your opinion on this and if I should
>> opt for it.
> Yes, this prior has usually better properties for binary data. It resulted in a much better precision and better accuracy in simulations. See Appendix B of the following (sorry for the auto-promotion...):
> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12011/full
>
> Hope this helps,
> Pierre.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From pgreenw1 at gmu.edu  Thu Oct 12 16:03:14 2017
From: pgreenw1 at gmu.edu (P Greenwood)
Date: Thu, 12 Oct 2017 10:03:14 -0400
Subject: [R-sig-ME] subjects assigned to treatment groups,
	multiple repeated measures over time
Message-ID: <C0DF4576-08CE-4D5B-ADF2-D4D275737850@gmu.edu>

Hello

I am a new user of lme4 and cannot find a clear answer to how to handle subjects randomly assigned to condition (treatment)  groups. The subject to subject variability  is likely to differ between groups on my measures in a way that varies over time. Time is broken into to 5 ?drives? which occur in order (drive 1 is first, drive 2 is second, etc). Each drive has 10 trials on which various measures are obtained - heart rate, alpha band power at Pz, eye gaze, etc..
 
Initially, I want to predict reaction time (RT) as a function of condition, alpha band power (PzAlpha), and drive.  

This model runs, but I?m not sure whether I am handling subjects within group correctly.
I plan to use Anova to compare a null model with a simpler model, once I understand how to handle subjects within groups.

Here is my model and output as a screen shot. Thanks so very much...

sumModelInteraction20 <- lmer(RT ~ 1 + Condition + PzAlpha + Drive + Condition*PzAlpha*Drive + (1 | Subject) + (1 | Trial), data = INFAST_Behavioral)


P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1


From bbolker at gmail.com  Fri Oct 13 15:43:13 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Oct 2017 09:43:13 -0400
Subject: [R-sig-ME] subjects assigned to treatment groups,
 multiple repeated measures over time
In-Reply-To: <C0DF4576-08CE-4D5B-ADF2-D4D275737850@gmu.edu>
References: <C0DF4576-08CE-4D5B-ADF2-D4D275737850@gmu.edu>
Message-ID: <CABghstQv6a5Nd8uyG4qi=ocmjL7X887O67X=C7UmJQkw6_87CQ@mail.gmail.com>

On Thu, Oct 12, 2017 at 10:03 AM, P Greenwood <pgreenw1 at gmu.edu> wrote:
> Hello
>
> I am a new user of lme4 and cannot find a clear answer to how to handle subjects randomly assigned to condition (treatment)  groups. The subject to subject variability  is likely to differ between groups on my measures in a way that varies over time. Time is broken into to 5 ?drives? which occur in order (drive 1 is first, drive 2 is second, etc). Each drive has 10 trials on which various measures are obtained - heart rate, alpha band power at Pz, eye gaze, etc..
>

  How much data do you have?  Is the total 5 drives x 10 trials x ??
treatments ?? subjects?  How many treatments? In principle, variation
in among-subject variance across groups over time is a sensible thing
to want to model, but it's not easy in any of the canned frameworks I
know of within R.  Varying among-subject variation can roughly done
via the example in ?dummy:

lmer(distance ~ age + (age|Subject) +
          (0+dummy(Sex, "Female")|Subject), data = Orthodont)

which effectively allows different among-subject variation for males
and females (the big caveat here is that it can only *add* variance
for the dummy group, so variance(male) must be < variance(female) for
this to work ...

  Otherwise, you will need to use one of the "build-your-own" tools
(Stan, rethinking, TMB, JAGS, ...)

> Initially, I want to predict reaction time (RT) as a function of condition, alpha band power (PzAlpha), and drive.
>
> This model runs, but I?m not sure whether I am handling subjects within group correctly.
> I plan to use Anova to compare a null model with a simpler model, once I understand how to handle subjects within groups.
>
> Here is my model and output as a screen shot. Thanks so very much...

  Screenshots get stripped from mailing list posts. Can you
cut-and-paste as text?

>
> sumModelInteraction20 <- lmer(RT ~ 1 + Condition + PzAlpha + Drive + Condition*PzAlpha*Drive +
    (1 | Subject) + (1 | Trial), data = INFAST_Behavioral)

  Crudely speaking, this should allow for among-subject variation in
the response variable (although not for random slopes
such as varying effect of pzalpha or drive among subjects).
Condition*PzAlpha*Drive includes all of the main effects as
well as all two-way interactions and the three-way interactions, so
the intercept and main effect terms in the formula are redundant (but
harmless).

>
>


From pgreenw1 at gmu.edu  Fri Oct 13 17:32:39 2017
From: pgreenw1 at gmu.edu (P Greenwood)
Date: Fri, 13 Oct 2017 11:32:39 -0400
Subject: [R-sig-ME] subjects assigned to treatment groups,
	multiple repeated measures over time
In-Reply-To: <CABghstQv6a5Nd8uyG4qi=ocmjL7X887O67X=C7UmJQkw6_87CQ@mail.gmail.com>
References: <C0DF4576-08CE-4D5B-ADF2-D4D275737850@gmu.edu>
 <CABghstQv6a5Nd8uyG4qi=ocmjL7X887O67X=C7UmJQkw6_87CQ@mail.gmail.com>
Message-ID: <2442C254-3354-446D-A706-911349AE08AB@gmu.edu>

Thank you so much.  I did apply for membership, but have not had a response.

To answer your questions:

1. I have currently an n of 26, with 12 subjects in one group, 14 in the other.  So 5 drives x 10 trials x 12  (group 1) or 14 (group 2) subjects
2. There are 2 treatments.
3.  I am pasting in the output below.
4.  I don?t currently have a main effect of Condition, p = 0.059.  If I did, would I be justified in running a separate model on each Condition? (I want to plan for future studies of this sort)

Thanks for the suggestions re: ?build your own? tools.  Let me know if you have other thoughts after seeing the output.

Pam

sumModelInteraction21 <- lmer(RT ~ 1 + Condition + PzAlpha + Drive + Condition:PzAlpha + (1 | Subject) + (1 | Trial), data = INFAST_Behavioral)
> summary(sumModelInteraction21)
Linear mixed model fit by REML 
t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
Formula: RT ~ 1 + Condition + PzAlpha + Drive + Condition:PzAlpha + (1 |      Subject) + (1 | Trial)
   Data: INFAST_Behavioral

REML criterion at convergence: 2619.9

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.2633 -0.5041 -0.1428  0.2929  7.9158 

Random effects:
 Groups   Name        	Variance Std.Dev.
 Subject  (Intercept) 	0.572680 0.75676 
 Trial    (Intercept) 		0.004865 0.06975 
 Residual             		0.442561 0.66525 
Number of obs: 1231, groups:  Subject, 26; Trial, 10

Fixed effects:
                                   			Estimate 		Std. Error         df 			t value Pr(>|t|)  
(Intercept)                     			 -3.469e-01 	 2.249e-01  	2.600e+01  	-1.543   0.1350  
ConditionMachineLanguage          	5.214e-01  	3.002e-01  	2.390e+01   	1.737   0.0952 .
PzAlpha                          			 1.291e-02 	 2.970e-02 	 1.198e+03  	 0.435   0.6638  
Drive                            			 3.098e-02  	1.331e-02  	1.193e+03   	2.327   0.0201 *
ConditionMachineLanguage:PzAlpha -2.073e-04  4.053e-02 	 1.198e+03  	-0.005   0.9959  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) CndtML PzAlph Drive 
CndtnMchnLn -0.719                     
PzAlpha     -0.009  0.011              
Drive       -0.177  0.001 -0.034       
CndtnMcL:PA  0.007 -0.002 -0.732  0.020
> sumModelInteraction20 <- lmer(RT ~ 1 + Condition + PzAlpha + Drive + Condition*PzAlpha*PzDelta*Drive + (1 | Subject) + (1 | Trial), data = INFAST_Behavioral)
> summary(sumModelInteraction20)
Linear mixed model fit by REML 
t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
Formula: RT ~ 1 + Condition + PzAlpha + Drive + Condition * PzAlpha *      PzDelta * Drive + (1 | Subject) + (1 | Trial)
   Data: INFAST_Behavioral

REML criterion at convergence: 2676.2

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.3382 -0.4999 -0.1433  0.3075  7.8310 

Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 0.573459 0.75727 
 Trial    (Intercept) 0.004913 0.07009 
 Residual             0.444402 0.66664 
Number of obs: 1231, groups:  Subject, 26; Trial, 10

Fixed effects:
                                                 Estimate Std. Error         df t value Pr(>|t|)  
(Intercept)                                    -3.966e-01  2.292e-01  2.790e+01  -1.730   0.0946 .
ConditionMachineLanguage                        6.269e-01  3.111e-01  2.750e+01   2.015   0.0538 .
PzAlpha                                         4.245e-02  7.310e-02  1.188e+03   0.581   0.5616  
Drive                                           4.701e-02  1.975e-02  1.182e+03   2.381   0.0174 *
PzDelta                                         4.598e-02  6.787e-02  1.187e+03   0.677   0.4983  
ConditionMachineLanguage:PzAlpha               -3.520e-02  9.433e-02  1.188e+03  -0.373   0.7091  
ConditionMachineLanguage:PzDelta               -4.527e-02  9.377e-02  1.187e+03  -0.483   0.6294  
PzAlpha:PzDelta                                -3.334e-02  7.168e-02  1.187e+03  -0.465   0.6420  
ConditionMachineLanguage:Drive                 -3.403e-02  2.715e-02  1.183e+03  -1.253   0.2104  
PzAlpha:Drive                                  -9.227e-03  2.172e-02  1.190e+03  -0.425   0.6710  
Drive:PzDelta                                  -2.117e-02  2.103e-02  1.187e+03  -1.007   0.3143  
ConditionMachineLanguage:PzAlpha:PzDelta       -6.171e-02  9.652e-02  1.188e+03  -0.639   0.5227  
ConditionMachineLanguage:PzAlpha:Drive          1.088e-02  2.856e-02  1.189e+03   0.381   0.7032  
ConditionMachineLanguage:Drive:PzDelta          2.344e-02  2.891e-02  1.187e+03   0.811   0.4176  
PzAlpha:Drive:PzDelta                           1.553e-02  2.183e-02  1.189e+03   0.711   0.4770  
ConditionMachineLanguage:PzAlpha:Drive:PzDelta  1.753e-02  3.041e-02  1.188e+03   0.576   0.5645  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1

> On Oct 13, 2017, at 9:43 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> On Thu, Oct 12, 2017 at 10:03 AM, P Greenwood <pgreenw1 at gmu.edu> wrote:
>> Hello
>> 
>> I am a new user of lme4 and cannot find a clear answer to how to handle subjects randomly assigned to condition (treatment)  groups. The subject to subject variability  is likely to differ between groups on my measures in a way that varies over time. Time is broken into to 5 ?drives? which occur in order (drive 1 is first, drive 2 is second, etc). Each drive has 10 trials on which various measures are obtained - heart rate, alpha band power at Pz, eye gaze, etc..
>> 
> 
>  How much data do you have?  Is the total 5 drives x 10 trials x ??
> treatments ?? subjects?  How many treatments? In principle, variation
> in among-subject variance across groups over time is a sensible thing
> to want to model, but it's not easy in any of the canned frameworks I
> know of within R.  Varying among-subject variation can roughly done
> via the example in ?dummy:
> 
> lmer(distance ~ age + (age|Subject) +
>          (0+dummy(Sex, "Female")|Subject), data = Orthodont)
> 
> which effectively allows different among-subject variation for males
> and females (the big caveat here is that it can only *add* variance
> for the dummy group, so variance(male) must be < variance(female) for
> this to work ...
> 
>  Otherwise, you will need to use one of the "build-your-own" tools
> (Stan, rethinking, TMB, JAGS, ...)
> 
>> Initially, I want to predict reaction time (RT) as a function of condition, alpha band power (PzAlpha), and drive.
>> 
>> This model runs, but I?m not sure whether I am handling subjects within group correctly.
>> I plan to use Anova to compare a null model with a simpler model, once I understand how to handle subjects within groups.
>> 
>> Here is my model and output as a screen shot. Thanks so very much...
> 
>  Screenshots get stripped from mailing list posts. Can you
> cut-and-paste as text?
> 
>> 
>> sumModelInteraction20 <- lmer(RT ~ 1 + Condition + PzAlpha + Drive + Condition*PzAlpha*Drive +
>    (1 | Subject) + (1 | Trial), data = INFAST_Behavioral)
> 
>  Crudely speaking, this should allow for among-subject variation in
> the response variable (although not for random slopes
> such as varying effect of pzalpha or drive among subjects).
> Condition*PzAlpha*Drive includes all of the main effects as
> well as all two-way interactions and the three-way interactions, so
> the intercept and main effect terms in the formula are redundant (but
> harmless).
> 
>> 
>> 


	[[alternative HTML version deleted]]


From lauranynkevanderlaan at hotmail.com  Fri Oct 13 21:49:51 2017
From: lauranynkevanderlaan at hotmail.com (Nynke l)
Date: Fri, 13 Oct 2017 19:49:51 +0000
Subject: [R-sig-ME] Model within subjects treatment variable and multiple
 measurements per treatment: is this the correct model?
Message-ID: <SN1PR10MB1007EB41FB504A0A413457A4DB480@SN1PR10MB1007.namprd10.prod.outlook.com>

Hello all,

I have a question regarding my analysis and how to correctly model this in r syntax.
I have a dataset from an experiment in which each subject received 3 treatments (HealthPrime, HedPrime and NonfPrime; within subjects factor). In each of these treatments, 40 measurements have been done of my DV (choice_topbottom, contineous variable) and two other predictor variables (tastiness_dif_topminbottom and healthiness_dif_topminbottom). In addition, I have a subject level variable (DEBQ_restraint) for which I would like to know if there is an interaction with treatment or the predictor variables.

What I basically want to know is if there is a difference between the treatments in how tastiness_dif_topminbottom and healthiness_dif_topminbottom relate to choice_topbottom. And I would like to know whether this is influenced by DEBQ_restraint.

Is the model below correct to take into account the fact that the treatment is a within subjects factor and that there are multiple measurements per treatment?

fit <- lmer(choice_topbottom ~ tastiness_dif_topminbottom + healthiness_dif_topminbottom + HealthPrime*tastiness_dif_topminbottom + HedPrime*healthiness_dif_topminbottom + HedPrime*tastiness_dif_topminbottom + HealthPrime*healthiness_dif_topminbottom + (1 | pp_code) + DEBQ_restraint + tastiness_dif_topminbottom*DEBQ_restraint + healthiness_dif_topminbottom*DEBQ_restraint + HealthPrime*tastiness_dif_topminbottom*DEBQ_restraint + HedPrime*healthiness_dif_topminbottom*DEBQ_restraint + HedPrime*tastiness_dif_topminbottom*DEBQ_restraint + HealthPrime*healthiness_dif_topminbottom*DEBQ_restraint, data = data)

I hope someone with more experience in these kind of models can let me know whether this is correct.

Many thanks in advance!

Best,
Nynke


	[[alternative HTML version deleted]]


From celiasofiamoreira at gmail.com  Mon Oct 16 14:38:34 2017
From: celiasofiamoreira at gmail.com (=?UTF-8?Q?C=C3=A9lia_Sofia_Moreira?=)
Date: Mon, 16 Oct 2017 13:38:34 +0100
Subject: [R-sig-ME] Normal data vs normal residuals
Message-ID: <CAJhU6eHARyQqWTDmSRo4Cd-xs38qHw_9YJCs0ue2YbZqxFF-5A@mail.gmail.com>

I have the following two questions:

1) one of my variables, say y, is normally distributed (shapiro/lilliefors
tests). However, the residuals of
lmer(y ~ x + (1|Subject))
are not normally distributed. Thus, as far as I understand, I can not use
lmer results. I was thinking about replacing lmer by (robust) rlmer. Do you
agree? Is there a better recommended approach?

2) another variable, say z, is not normally distributed but the residuals of
lmer (z ~ x + (1|Subject))
pass the normality tests. May I accept the results of lmer?

Kind regards,
CSM

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Oct 16 17:09:29 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 Oct 2017 11:09:29 -0400
Subject: [R-sig-ME] Normal data vs normal residuals
In-Reply-To: <CAJhU6eHARyQqWTDmSRo4Cd-xs38qHw_9YJCs0ue2YbZqxFF-5A@mail.gmail.com>
References: <CAJhU6eHARyQqWTDmSRo4Cd-xs38qHw_9YJCs0ue2YbZqxFF-5A@mail.gmail.com>
Message-ID: <b75cc920-9e78-7e5d-d859-2c5d0cdafe65@gmail.com>



On 17-10-16 08:38 AM, C?lia Sofia Moreira wrote:
> I have the following two questions:
> 
> 1) one of my variables, say y, is normally distributed (shapiro/lilliefors
> tests). However, the residuals of
> lmer(y ~ x + (1|Subject))
> are not normally distributed. Thus, as far as I understand, I can not use
> lmer results. I was thinking about replacing lmer by (robust) rlmer. Do you
> agree? Is there a better recommended approach?


> 
> 2) another variable, say z, is not normally distributed but the residuals of
> lmer (z ~ x + (1|Subject))
> pass the normality tests. May I accept the results of lmer?
> 

The marginal distribution (unconditional distribution of y in the first
case or z in the second case) is not really relevant at all.

Many statisticians think that statistical testing of residuals for
Normality is a waste of time (because such tests will almost always fail
to reject the null hypothesis for small samples and will almost always
succeed in rejecting for large samples, even when the level of
non-Normality is not a practical problem for estimation or inference:
e.g. see
https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless

If you still conclude that the level of non-Normality is a problem, then
transformation of the response variable or robust estimation via rlmer
are both reasonable strategies. Alternatively you could look for a
statistical framework that allows fat-tailed distributions such as
Student t (e.g. brms).



> Kind regards,
> CSM
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From gaughra at tcd.ie  Tue Oct 17 15:54:45 2017
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Tue, 17 Oct 2017 14:54:45 +0100
Subject: [R-sig-ME] Extracting standardized residuals from a gamma(log)
	glmmTMB
Message-ID: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>

Hi all,

I have run a glmmTMB with (family="Gamma",link="log") and now want to
validate the model, but am unable to extract the standardised residuals
with sresid <- resid(mod1tmb, "pearson").  It produces the following error
message:

Error in residuals.glmmTMB(mod1tmb, "pearson") :
variance function undefined for family ?Gamma?; cannot compute Pearson residuals


Would anyone be able to assist me with this?

Many thanks,

-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Oct 17 17:33:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 17 Oct 2017 08:33:18 -0700
Subject: [R-sig-ME] Extracting standardized residuals from a
	gamma(log)	glmmTMB
In-Reply-To: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>
References: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>
Message-ID: <7B30E7DA-3176-4AC6-9312-8A1F00EC90E0@dcn.davis.ca.us>

Google is your friend...

https://stats.stackexchange.com/questions/295340/what-to-do-with-glm-gamma-when-residuals-are-not-normally-distributed
-- 
Sent from my phone. Please excuse my brevity.

On October 17, 2017 6:54:45 AM PDT, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>Hi all,
>
>I have run a glmmTMB with (family="Gamma",link="log") and now want to
>validate the model, but am unable to extract the standardised residuals
>with sresid <- resid(mod1tmb, "pearson").  It produces the following
>error
>message:
>
>Error in residuals.glmmTMB(mod1tmb, "pearson") :
>variance function undefined for family ?Gamma?; cannot compute Pearson
>residuals
>
>
>Would anyone be able to assist me with this?
>
>Many thanks,
>
>-- 
>Aoibheann Gaughran
>
>Behavioural and Evolutionary Ecology Research Group
>Zoology Building
>School of Natural Sciences
>Trinity College Dublin
>Dublin 2
>Ireland
>Phone: +353 (86) 3812615
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mollieebrooks at gmail.com  Tue Oct 17 17:33:48 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Tue, 17 Oct 2017 17:33:48 +0200
Subject: [R-sig-ME] Extracting standardized residuals from a gamma(log)
	glmmTMB
In-Reply-To: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>
References: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>
Message-ID: <CAMu=eMCHw4wzEqadtH7rpjDsof1UrM1kFVZQGP7equ21WRkfQA@mail.gmail.com>

Hi Aoibheann,

That seems to be a bug in glmmTMB since the Gamma family does include a
variance function.

I think we need to change this line of code https://github.com/
glmmTMB/glmmTMB/blob/f9388401f2173b774b16d63d31fff9
a1dbc3c48f/glmmTMB/R/methods.R#L483


Can you add an issue on GitHub (https://github.com/glmmTMB/glmmTMB/issues)?
If not, I could do it.

cheers,
Mollie


On Tue, Oct 17, 2017 at 3:54 PM, Aoibheann Gaughran <gaughra at tcd.ie> wrote:

> Hi all,
>
> I have run a glmmTMB with (family="Gamma",link="log") and now want to
> validate the model, but am unable to extract the standardised residuals
> with sresid <- resid(mod1tmb, "pearson").  It produces the following error
> message:
>
> Error in residuals.glmmTMB(mod1tmb, "pearson") :
> variance function undefined for family ?Gamma?; cannot compute Pearson
> residuals
>
>
> Would anyone be able to assist me with this?
>
> Many thanks,
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Oct 17 17:36:36 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Oct 2017 11:36:36 -0400
Subject: [R-sig-ME] Extracting standardized residuals from a gamma(log)
 glmmTMB
In-Reply-To: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>
References: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>
Message-ID: <5174ae0c-14b0-b980-fb18-277d0c7e12db@gmail.com>


  If you specify your model with the built-in Gamma() family-generator,
this should work, e.g.:

> library(glmmTMB)
> dd <- data.frame(g=rgamma(100,shape=4,scale=1))
> g1 <- glmmTMB(g~1,family=Gamma(link="log"),data=dd)
> resid(g1,"pearson")

  The reason for this is that Gamma() produces a list with additional
information:

Gamma(link="log")$variance
function (mu)
mu^2

If you wanted to specify a family that base R didn't know about you
could do it by adding your own variance function to the list.


On 17-10-17 09:54 AM, Aoibheann Gaughran wrote:
> Hi all,
> 
> I have run a glmmTMB with (family="Gamma",link="log") and now want to
> validate the model, but am unable to extract the standardised residuals
> with sresid <- resid(mod1tmb, "pearson").  It produces the following error
> message:
> 
> Error in residuals.glmmTMB(mod1tmb, "pearson") :
> variance function undefined for family ?Gamma?; cannot compute Pearson residuals
> 
> 
> Would anyone be able to assist me with this?
> 
> Many thanks,
>


From dorothea.dumuid at mymail.unisa.edu.au  Sat Oct 14 10:05:58 2017
From: dorothea.dumuid at mymail.unisa.edu.au (Dumuid, Dorothea - tridy002)
Date: Sat, 14 Oct 2017 08:05:58 +0000
Subject: [R-sig-ME] r-sig-mixed-models@r-project.org: multiple dependent
 variables in lmer()
Message-ID: <MEXPR01MB091825037B89E12D291F1D3DED490@MEXPR01MB0918.ausprd01.prod.outlook.com>

We are analysing data from a randomised controlled trial for an exercise intervention.

We have 106 participants, in three groups:
(1) control (n=34)
(2) moderate exercise (n=36)
(2) intensive exercise (n= 36)

We want to know if participants' use of time changed differently depending on which group they were in.

Our outcome measure is participants' 24-hour time-use composition (minutes/day spent in 4 domains: sleep, sitting, standing and physical activity).

Time use is measured at 3 time points:
(1) baseline
(2) post-intervention
(3) 12-month follow-up

Time in all four domains always adds to 24 hours, therefore if all components are included in the model there would be perfect multicollinearity. So we have expressed the time-use compositions as sets of three isometric log-ratio (ilr) coordinates created using an orthonormal basis. These ilr coordinates contain all relative information regarding the time-use compositions and can be used to represent the compositions in multivariate statistical models.

So, the variables for our model look like this:
ID = participant ID
gp = a factor variable ("I", "M, "C"), for intense, moderate or control group
time = a factor variable (1, 2, 3) for time point of measurement
ilr1, ilr2 and ilr3 = three isometric log ratios (the dependent variables).

We would like to run a model like this:

fit=lmer(cbind(ilr1, ilr2, ilr3) ~gp * time + (1|ID)),
car::Anova(fit)  # this does a Type II MANOVA Test (Pillai)

(ignoring for the moment that participants may have random slopes).

But the lme4 regression command (lmer) does not allow more than one dependent variable. It's possible to run a separate lmer() for each log-ratio coordinate, and then predict a new log-ratio coordinate for each time point, for each group. Because the log-ratio coordinates are orthornormal, we can simply put the predicted log-ratios back together, find their inverse, and then we can compare the predicted time-use composition for each group, for each time point. So we can see from this how time in the four domains is predicted to change over the time points, for both groups.

However, we cannot work out how to compute a statistic for the interaction effect between group and time point for all the log ratios together (i.e., the set of log ratios). Is it possible to run a MANOVA of the complete set of models?

Thanks in advance!
Dot


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Oct 17 17:50:31 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Oct 2017 11:50:31 -0400
Subject: [R-sig-ME] Extracting standardized residuals from a gamma(log)
 glmmTMB
In-Reply-To: <CAMu=eMCHw4wzEqadtH7rpjDsof1UrM1kFVZQGP7equ21WRkfQA@mail.gmail.com>
References: <CAN=0SEkQgUD_w_zuhPtNd4dA74zG=fRsVw=Dvd4RsYi0k0xMhQ@mail.gmail.com>
 <CAMu=eMCHw4wzEqadtH7rpjDsof1UrM1kFVZQGP7equ21WRkfQA@mail.gmail.com>
Message-ID: <7eee8b53-101c-1528-ef80-612db63c44c4@gmail.com>


  I don't think it's a bug, except possibly a documentation bug. I.e.,
we should add details to ?glmmTMB or ?family_glmmTMB (which should
possibly be aliased to family.glmmTMB as well even though family is not
an S3 generic function, because people might look there.

 cheers
  Ben Bolker


On 17-10-17 11:33 AM, Mollie Brooks wrote:
> Hi Aoibheann,
> 
> That seems to be a bug in glmmTMB since the Gamma family does include a
> variance function.
> 
> I think we need to change this line of code https://github.com/
> glmmTMB/glmmTMB/blob/f9388401f2173b774b16d63d31fff9a1dbc3c48f/glmmTMB/R/methods.R#L483
> 
> 
> Can you add an issue on GitHub (https://github.com/glmmTMB/glmmTMB/issues)?
> If not, I could do it.
> 
> cheers,
> Mollie
> 
> 
> On Tue, Oct 17, 2017 at 3:54 PM, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
> 
>> Hi all,
>>
>> I have run a glmmTMB with (family="Gamma",link="log") and now want to
>> validate the model, but am unable to extract the standardised residuals
>> with sresid <- resid(mod1tmb, "pearson").  It produces the following error
>> message:
>>
>> Error in residuals.glmmTMB(mod1tmb, "pearson") :
>> variance function undefined for family ?Gamma?; cannot compute Pearson
>> residuals
>>
>>
>> Would anyone be able to assist me with this?
>>
>> Many thanks,
>>
>> --
>> Aoibheann Gaughran
>>
>> Behavioural and Evolutionary Ecology Research Group
>> Zoology Building
>> School of Natural Sciences
>> Trinity College Dublin
>> Dublin 2
>> Ireland
>> Phone: +353 (86) 3812615
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From c.c.voeten at hum.leidenuniv.nl  Wed Oct 18 10:05:47 2017
From: c.c.voeten at hum.leidenuniv.nl (Voeten, C.C.)
Date: Wed, 18 Oct 2017 08:05:47 +0000
Subject: [R-sig-ME] Model within subjects treatment variable and
 multiple measurements per treatment: is this the correct model?
In-Reply-To: <SN1PR10MB1007EB41FB504A0A413457A4DB480@SN1PR10MB1007.namprd10.prod.outlook.com>
References: <SN1PR10MB1007EB41FB504A0A413457A4DB480@SN1PR10MB1007.namprd10.prod.outlook.com>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F799464@SPMXM08.VUW.leidenuniv.nl>

Hi Nynke,

Can you paste the first few rows of your dataset so that we can take a look at the way you coded your variables? The way I would do it is to create a single factor variable "treatment" with three levels "HealthPrime", "HedPrime", and "NonfPrime". It seems like you coded them as separate variables, which is fine, but makes the model syntax somewhat cluttered.

If you code them as a single variable, the way I would do it would be:

fit <- lmer(choice_topbottom ~ treatment * (tastiness_dif_topminbottom + healthiness_dif_topminbottom) * DEBQ_restraint) + (1|pp_code),data=data)

If you want to keep your predictors coded as separate columns, replace 'treatment' by your three treatments separated by a plus. In that case, your formula is probably correct (though it's also a bit challenging to read so I didn't look at it in too much detail!). Note that the * operator for interactions automatically includes any lower-order interactions and the main effects, so there is no need to state those explicitly (but also no harm).

Note that, in any case, you may also want to consider by-participant random slopes for your predictors.

Best,
Cesko

> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] Namens Nynke l
> Verzonden: vrijdag 13 oktober 2017 21:50
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Model within subjects treatment variable and
> multiple measurements per treatment: is this the correct model?
> 
> Hello all,
> 
> I have a question regarding my analysis and how to correctly model this in r
> syntax.
> I have a dataset from an experiment in which each subject received 3
> treatments (HealthPrime, HedPrime and NonfPrime; within subjects factor).
> In each of these treatments, 40 measurements have been done of my DV
> (choice_topbottom, contineous variable) and two other predictor variables
> (tastiness_dif_topminbottom and healthiness_dif_topminbottom). In
> addition, I have a subject level variable (DEBQ_restraint) for which I would
> like to know if there is an interaction with treatment or the predictor
> variables.
> 
> What I basically want to know is if there is a difference between the
> treatments in how tastiness_dif_topminbottom and
> healthiness_dif_topminbottom relate to choice_topbottom. And I would like
> to know whether this is influenced by DEBQ_restraint.
> 
> Is the model below correct to take into account the fact that the treatment is
> a within subjects factor and that there are multiple measurements per
> treatment?
> 
> fit <- lmer(choice_topbottom ~ tastiness_dif_topminbottom +
> healthiness_dif_topminbottom + HealthPrime*tastiness_dif_topminbottom
> + HedPrime*healthiness_dif_topminbottom +
> HedPrime*tastiness_dif_topminbottom +
> HealthPrime*healthiness_dif_topminbottom + (1 | pp_code) +
> DEBQ_restraint + tastiness_dif_topminbottom*DEBQ_restraint +
> healthiness_dif_topminbottom*DEBQ_restraint +
> HealthPrime*tastiness_dif_topminbottom*DEBQ_restraint +
> HedPrime*healthiness_dif_topminbottom*DEBQ_restraint +
> HedPrime*tastiness_dif_topminbottom*DEBQ_restraint +
> HealthPrime*healthiness_dif_topminbottom*DEBQ_restraint, data = data)
> 
> I hope someone with more experience in these kind of models can let me
> know whether this is correct.
> 
> Many thanks in advance!
> 
> Best,
> Nynke
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From andreu.blanco at gmail.com  Thu Oct 19 14:03:05 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Thu, 19 Oct 2017 14:03:05 +0200
Subject: [R-sig-ME] glmmADMB errors
Message-ID: <CAOy7hbA9UxVShG=LRePEZDE7CimQa=WBNjs=qToRPersimjsSg@mail.gmail.com>

 Dear list members, I am starting with generalized mixed models and I am
having some trouble I hope someone could help me with.

We are trying to understand the invasiveness of algae inside and outside
MPA, to do so our sampling was set with a nested desing:

Protected vs nonProtected
4 Locations (protected) vs 4 Locations (nonProtected)
Exposed vs Semiexposed at each location
1 transect per sampling point (total 16)
5 quadrants per transect

str(dataGLMMADMB)
'data.frame':   80 obs. of  4 variables:
 $ Location: Factor w/ 4 levels "Cies1","Cies2",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Protection: Factor w/ 2 levels "Control","Protected": 1 1 1 1 1 2 2 2 2
2 ...
 $ Exposure: Factor w/ 2 levels "Exposed","Semiexposed": 1 1 1 1 1 1 1 1 1
1 ...
 $ Biomass: num  124.8 104.8 139.2 102.6 62.9 ...


First I ran it as a Poission distribution (after round the Biomass values)
to be able to fit a zeroInflation model:
> Model_ADMB_P<-glmmadmb(Biomass~Protection+Exposure+Protection:Exposure+(1|
Protection/Location),data=GLMMADMB_P, zeroInflation=TRUE, family="Poisson")
Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
:
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
Adem?s: Warning message:
comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
-maxph 5 -noinit -shess' tiene estatus 1

Then I though that since my data is continuous I'd better run the model
with a gamma family, however, when I do run it with gamma I got the
following error:
> Model_ADMB_G<-glmmadmb(Biomass~Protection+Exposure+Protection:Exposure+(1|
Protection/Location),data=GLMMADMB_P, family="gamma")

Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
:
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
Adem?s: Warning message:
comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
-maxph 5 -noinit -shess' tiene estatus 1

However, when I run it as a Poisson distribution with zeroInflated values
but with no nested design and Location effect either, it ran ok
> Model_ADMB_P1<-glmmadmb(Biomass~Protection*Exposure,data=GLMMADMB_P,
zeroInflation=TRUE, family="Poisson")
> summary(Model_ADMB_P1)

Call:
glmmadmb(formula = Biomass ~ Protection * Exposure, data = GLMMADMB_P,
    family = "Poisson", zeroInflation = TRUE)

AIC: 1570.7

Coefficients:
                                         Estimate Std. Error z value
Pr(>|z|)
(Intercept)                              4.71e+00   3.18e-02   148.0
 <2e-16
ProtectionProtected                     -5.53e-01   5.00e-02   -11.1
 <2e-16
ExposureSemiexposed                     -3.83e+01   2.22e+05     0.0
1
ProtectionProtected:ExposureSemiexposed  3.64e+01   2.22e+05     0.0
1

(Intercept)                             ***
ProtectionProtected                     ***
ExposureSemiexposed
ProtectionProtected:ExposureSemiexposed
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=80
Zero-inflation: 0.30908  (std. err.:  0.071433 )

Log-likelihood: -780.37
>


I can not understat the solutions to these errors, can anyone please help
me out?
I really appreciate it!

Thanks in advance,

-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Oct 19 14:40:31 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 19 Oct 2017 13:40:31 +0100
Subject: [R-sig-ME] Course: Introduction to regression models with spatial
 and temporal correlation using R-INLA
Message-ID: <a7844e63-79f2-4d85-1560-c3b2a6dd6b21@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Regression Models with Spatial and Temporal 
Correlation using R-INLA
Where:? Banff, Cananda (easily accessible from Calgary airport)
When:?? 4-8 December 2017

Course website: http://highstat.com/index.php/courses
Course flyer: 
http://highstat.com/Courses/Flyers/2017/Flyer2017_12Banff_SpatTemp.pdf

Kind regards,

Alain Zuur


Other courses in Canada:

Halifax, January 2018: Introduction to Linear Mixed Effects Models and 
GLMM with R; Frequentist and Bayesian approaches

Edmonton, January 2018: Introduction to Linear Mixed Effects Models and 
GLMM with R; Frequentist and Bayesian approaches


-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From dorothea.dumuid at mymail.unisa.edu.au  Thu Oct 19 14:46:47 2017
From: dorothea.dumuid at mymail.unisa.edu.au (Dumuid, Dorothea - tridy002)
Date: Thu, 19 Oct 2017 12:46:47 +0000
Subject: [R-sig-ME] Mixed model with dependent compositional data
Message-ID: <MEXPR01MB0918EAA9166DEA705AC2A4CDED420@MEXPR01MB0918.ausprd01.prod.outlook.com>

We are analysing data from a randomised controlled trial for an exercise intervention.

We have 106 participants, in three groups:
(1) control (n=34)
(2) moderate exercise (n=36)
(2) intensive exercise (n= 36)

We want to know if participants' use of time changed differently depending on which group they were in.

Our outcome measure is participants' 24-hour time-use composition (minutes/day spent in 4 domains: sleep, sitting, standing and physical activity).

Time use is measured at 3 time points:
(1) baseline
(2) post-intervention
(3) 12-month follow-up

Time in all four domains always adds to 24 hours, therefore if all components are included in the model there would be perfect multicollinearity. So we have expressed the time-use compositions as sets of three isometric log-ratio (ilr) coordinates created using an orthonormal basis. These ilr coordinates contain all relative information regarding the time-use compositions and can be used to represent the compositions in multivariate statistical models.

So, the variables for our model look like this:
ID = participant ID
gp = a factor variable ("I", "M, "C"), for intense, moderate or control group
time = a factor variable (1, 2, 3) for time point of measurement
ilr1, ilr2 and ilr3 = three isometric log ratios (the dependent variables).

We would like to run a model like this:

fit=lmer(cbind(ilr1, ilr2, ilr3) ~gp * time + (1|ID)),
car::Anova(fit)  # this does a Type II MANOVA Test (Pillai)

(ignoring for the moment that participants may have random slopes).

But the lme4 regression command (lmer) does not allow more than one dependent variable. We cannot work out how to compute a statistic for the interaction effect between group and time point for all the log ratios together (i.e., the set of log ratios).

Thanks in advance!
Dot

	[[alternative HTML version deleted]]


From dorothea.dumuid at mymail.unisa.edu.au  Thu Oct 19 14:53:38 2017
From: dorothea.dumuid at mymail.unisa.edu.au (Dumuid, Dorothea - tridy002)
Date: Thu, 19 Oct 2017 12:53:38 +0000
Subject: [R-sig-ME] Mixed model with dependent compositional data
Message-ID: <MEXPR01MB0918C8CCAA592336550D1815ED420@MEXPR01MB0918.ausprd01.prod.outlook.com>

We are analysing data from a randomised controlled trial for an exercise intervention.

We have 106 participants, in three groups:
(1) control (n=34)
(2) moderate exercise (n=36)
(2) intensive exercise (n= 36)

We want to know if participants' use of time changed differently depending on which group they were in.

Our outcome measure is participants' 24-hour time-use composition (minutes/day spent in 4 domains: sleep, sitting, standing and physical activity).

Time use is measured at 3 time points:
(1) baseline
(2) post-intervention
(3) 12-month follow-up

Time in all four domains always adds to 24 hours, therefore if all components are included in the model there would be perfect multicollinearity. So we have expressed the time-use compositions as sets of three isometric log-ratio (ilr) coordinates created using an orthonormal basis. These ilr coordinates contain all relative information regarding the time-use compositions and can be used to represent the compositions in multivariate statistical models.

So, the variables for our model look like this:
ID = participant ID
gp = a factor variable ("I", "M, "C"), for intense, moderate or control group
time = a factor variable (1, 2, 3) for time point of measurement
ilr1, ilr2 and ilr3 = three isometric log ratios (the dependent variables).

We would like to run a model like this:

fit=lmer(cbind(ilr1, ilr2, ilr3) ~gp * time + (1|ID)),
car::Anova(fit)  # this does a Type II MANOVA Test (Pillai)

(ignoring for the moment that participants may have random slopes).

But the lme4 regression command (lmer) does not allow more than one dependent variable. We cannot work out how to compute a statistic for the interaction effect between group and time point for all the log ratios together (i.e., the set of log ratios).

Thanks in advance!
Dot

	[[alternative HTML version deleted]]


From haveaballphysio at gmail.com  Thu Oct 19 15:12:24 2017
From: haveaballphysio at gmail.com (Dot Dumuid)
Date: Thu, 19 Oct 2017 23:42:24 +1030
Subject: [R-sig-ME] Mixed models with dependent compositional data
Message-ID: <CA+GPHvO-xt9Y0p-FMZRdRiqd3m_nQqNxG+Qa2uAPKon7T3bHsg@mail.gmail.com>

We are analysing data from a randomised controlled trial for an exercise
intervention.

We have 106 participants, in three groups:
(1) control (n=34)
(2) moderate exercise (n=36)
(2) intensive exercise (n= 36)

We want to know if participants' use of time changed differently depending
on which group they were in.

Our outcome measure is participants' 24-hour time-use composition
(minutes/day spent in 4 domains: sleep, sitting, standing and physical
activity).

Time use is measured at 3 time points:
(1) baseline
(2) post-intervention
(3) 12-month follow-up

Time in all four domains always adds to 24 hours, therefore if all
components are included in the model there would be perfect
multicollinearity. So we have expressed the time-use compositions as sets
of three isometric log-ratio (ilr) coordinates created using an orthonormal
basis. These ilr coordinates contain all relative information regarding the
time-use compositions and can be used to represent the compositions in
multivariate statistical models.

So, the variables for our model look like this:
ID = participant ID
gp = a factor variable ("I", "M, "C"), for intense, moderate or control
group
time = a factor variable (1, 2, 3) for time point of measurement
ilr1, ilr2 and ilr3 = three isometric log ratios (the dependent variables).

We would like to run a model like this:

fit=lmer(cbind(ilr1, ilr2, ilr3) ~gp * time + (1|ID)),
car::Anova(fit)  # this does a Type II MANOVA Test (Pillai)

(ignoring for the moment that participants may have random slopes).

But the lme4 regression command (lmer) does not allow more than one
dependent variable. We cannot work out how to compute a statistic for the
interaction effect between group and time point for all the log ratios
together (i.e., the set of log ratios).

Thanks in advance!
Dot

	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Thu Oct 19 19:07:44 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Thu, 19 Oct 2017 19:07:44 +0200
Subject: [R-sig-ME] random slope and intercept in gamlss
Message-ID: <CAMu=eMCe7owjKs1VmS1z5Z8C2TRFV6bt0Y1v0aOMvbFsbXe70Q@mail.gmail.com>

Hi mixed modellers,

I've been struggling to figure out how to fit a model in gamlss with
correlated random effects of slope and intercept. I can fit one model that
might be right, but I can't find the random effect estimates to check.

Can anyone tell me if m1 or m2 below is the right code for a correlated
random slope and intercept as simulated below?

Thanks,
Mollie

library(MASS)
library(gamlss)

ni=50 #num groups in RE
nrep=10 #num reps per group
sdi=1
sdii=.1
rho = .5
slope=.8

dat=expand.grid(i=1:ni, rep=1:nrep, x=c(0, .1, .2, .4))
RE =mvrnorm(n=ni, mu =c(0,0), Sigma = matrix(c(sdi*sdi, rho*sdi*sdii,
rho*sdi*sdii, sdii*sdii),2,2))
dat=transform(dat, obs=rpois(n=nrow(dat), lambda =
exp(RE[i,1]+x*(slope+RE[i,2]))))

m0= gamlss(obs~x+re(random=~1|i), family=PO, data = dat)
m1= gamlss(obs~x+re(random=~1+x|i, correlation=corSymm()), family=PO, data
= dat, start.from=m0)
m2= gamlss(obs~x+re(random=~1+x|i), family=PO, data = dat, start.from=m0)

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Oct 19 21:03:35 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Thu, 19 Oct 2017 19:03:35 +0000
Subject: [R-sig-ME] r-sig-mixed-models@r-project.org: multiple dependent
 variables in lmer()
In-Reply-To: <MEXPR01MB091825037B89E12D291F1D3DED490@MEXPR01MB0918.ausprd01.prod.outlook.com>
References: <MEXPR01MB091825037B89E12D291F1D3DED490@MEXPR01MB0918.ausprd01.prod.outlook.com>
Message-ID: <c4ad35462ba54dea84fb75f388aa025c@UM-MAIL3216.unimaas.nl>

Hi Dot,

Restructure your data into a 'very long' format, that is:

ID gp time ilr   y
1  I  1    ilr1  .
1  I  2    ilr2  .
1  I  3    ilr3  .
1  I  1    ilr1  .
1  I  2    ilr2  .
1  I  3    ilr3  .
1  I  1    ilr1  .
1  I  2    ilr2  .
1  I  3    ilr3  .
...

where 'y' is the actual ilr value for that person in that group at that time point for that domain. Then you can fit a multivariate model to these data. For example, a MANOVA-type model would be:

library(nlme)
dat$cond <- 1:9
res <- gls(y ~ factor(gp)*factor(time)*factor(ilr), correlation = corSymm(form = ~ 1 | id), weights = varIdent(form = ~ 1 | cond), data=dat)
anova(res)

But this will estimate 9 variances and 36 covariances (plus the fixed effects), which might be pushing things. So you might want to consider a more parsimonious model. The other extreme would be:

lmer(y ~ factor(gp)*factor(time)*factor(ilr) + (1 | ID), data=dat)

or equivalently

lme(y ~ factor(gp)*factor(time)*factor(ilr), random = ~ 1 | ID, data=dat)

but this probably way too parsimonious. 

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Dumuid, Dorothea - tridy002
Sent: Saturday, 14 October, 2017 10:06
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] r-sig-mixed-models at r-project.org: multiple dependent variables in lmer()

We are analysing data from a randomised controlled trial for an exercise intervention.

We have 106 participants, in three groups:
(1) control (n=34)
(2) moderate exercise (n=36)
(2) intensive exercise (n= 36)

We want to know if participants' use of time changed differently depending on which group they were in.

Our outcome measure is participants' 24-hour time-use composition (minutes/day spent in 4 domains: sleep, sitting, standing and physical activity).

Time use is measured at 3 time points:
(1) baseline
(2) post-intervention
(3) 12-month follow-up

Time in all four domains always adds to 24 hours, therefore if all components are included in the model there would be perfect multicollinearity. So we have expressed the time-use compositions as sets of three isometric log-ratio (ilr) coordinates created using an orthonormal basis. These ilr coordinates contain all relative information regarding the time-use compositions and can be used to represent the compositions in multivariate statistical models.

So, the variables for our model look like this:
ID = participant ID
gp = a factor variable ("I", "M, "C"), for intense, moderate or control group
time = a factor variable (1, 2, 3) for time point of measurement
ilr1, ilr2 and ilr3 = three isometric log ratios (the dependent variables).

We would like to run a model like this:

fit=lmer(cbind(ilr1, ilr2, ilr3) ~gp * time + (1|ID)),
car::Anova(fit)  # this does a Type II MANOVA Test (Pillai)

(ignoring for the moment that participants may have random slopes).

But the lme4 regression command (lmer) does not allow more than one dependent variable. It's possible to run a separate lmer() for each log-ratio coordinate, and then predict a new log-ratio coordinate for each time point, for each group. Because the log-ratio coordinates are orthornormal, we can simply put the predicted log-ratios back together, find their inverse, and then we can compare the predicted time-use composition for each group, for each time point. So we can see from this how time in the four domains is predicted to change over the time points, for both groups.

However, we cannot work out how to compute a statistic for the interaction effect between group and time point for all the log ratios together (i.e., the set of log ratios). Is it possible to run a MANOVA of the complete set of models?

Thanks in advance!
Dot


From mollieebrooks at gmail.com  Fri Oct 20 13:51:24 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Fri, 20 Oct 2017 13:51:24 +0200
Subject: [R-sig-ME] glmmADMB errors
In-Reply-To: <CAOy7hbA9UxVShG=LRePEZDE7CimQa=WBNjs=qToRPersimjsSg@mail.gmail.com>
References: <CAOy7hbA9UxVShG=LRePEZDE7CimQa=WBNjs=qToRPersimjsSg@mail.gmail.com>
Message-ID: <CAMu=eMANfcoeOn3a_ufedhp6YHJDaeg91_RUa9EYWzG-andrNA@mail.gmail.com>

Hi Andreu,

A zero-inflated Poisson distribution is not appropriate because biomass is
not count data. I would recommend checking what distribution other
researchers in your field are using. Maybe you want to first model zero vs
non-zero and then model the non-zero biomasses separately. The log of
non-zero biomasses could be modeled with a normal distribution. Or on the
natural scale, they could be Gamma or Tweedie. Or maybe a zero-inflated
continuous positive distribution (e.g. Gamma or Tweedie) makes sense for
all of the biomasses. These zero-inflated models could be fit in glmmTMB.

cheers,
Mollie

On Thu, Oct 19, 2017 at 2:03 PM, andreu blanco <andreu.blanco at gmail.com>
wrote:

>  Dear list members, I am starting with generalized mixed models and I am
> having some trouble I hope someone could help me with.
>
> We are trying to understand the invasiveness of algae inside and outside
> MPA, to do so our sampling was set with a nested desing:
>
> Protected vs nonProtected
> 4 Locations (protected) vs 4 Locations (nonProtected)
> Exposed vs Semiexposed at each location
> 1 transect per sampling point (total 16)
> 5 quadrants per transect
>
> str(dataGLMMADMB)
> 'data.frame':   80 obs. of  4 variables:
>  $ Location: Factor w/ 4 levels "Cies1","Cies2",..: 1 1 1 1 1 1 1 1 1 1 ...
>  $ Protection: Factor w/ 2 levels "Control","Protected": 1 1 1 1 1 2 2 2 2
> 2 ...
>  $ Exposure: Factor w/ 2 levels "Exposed","Semiexposed": 1 1 1 1 1 1 1 1 1
> 1 ...
>  $ Biomass: num  124.8 104.8 139.2 102.6 62.9 ...
>
>
> First I ran it as a Poission distribution (after round the Biomass values)
> to be able to fit a zeroInflation model:
> > Model_ADMB_P<-glmmadmb(Biomass~Protection+Exposure+
> Protection:Exposure+(1|
> Protection/Location),data=GLMMADMB_P, zeroInflation=TRUE,
> family="Poisson")
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
> :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> Adem?s: Warning message:
> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
> -maxph 5 -noinit -shess' tiene estatus 1
>
> Then I though that since my data is continuous I'd better run the model
> with a gamma family, however, when I do run it with gamma I got the
> following error:
> > Model_ADMB_G<-glmmadmb(Biomass~Protection+Exposure+
> Protection:Exposure+(1|
> Protection/Location),data=GLMMADMB_P, family="gamma")
>
> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
> :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> Adem?s: Warning message:
> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
> -maxph 5 -noinit -shess' tiene estatus 1
>
> However, when I run it as a Poisson distribution with zeroInflated values
> but with no nested design and Location effect either, it ran ok
> > Model_ADMB_P1<-glmmadmb(Biomass~Protection*Exposure,data=GLMMADMB_P,
> zeroInflation=TRUE, family="Poisson")
> > summary(Model_ADMB_P1)
>
> Call:
> glmmadmb(formula = Biomass ~ Protection * Exposure, data = GLMMADMB_P,
>     family = "Poisson", zeroInflation = TRUE)
>
> AIC: 1570.7
>
> Coefficients:
>                                          Estimate Std. Error z value
> Pr(>|z|)
> (Intercept)                              4.71e+00   3.18e-02   148.0
>  <2e-16
> ProtectionProtected                     -5.53e-01   5.00e-02   -11.1
>  <2e-16
> ExposureSemiexposed                     -3.83e+01   2.22e+05     0.0
> 1
> ProtectionProtected:ExposureSemiexposed  3.64e+01   2.22e+05     0.0
> 1
>
> (Intercept)                             ***
> ProtectionProtected                     ***
> ExposureSemiexposed
> ProtectionProtected:ExposureSemiexposed
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Number of observations: total=80
> Zero-inflation: 0.30908  (std. err.:  0.071433 )
>
> Log-likelihood: -780.37
> >
>
>
> I can not understat the solutions to these errors, can anyone please help
> me out?
> I really appreciate it!
>
> Thanks in advance,
>
> --
> Andreu Blanco Cartagena
>
>
>
> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
> ajuda a protegir el medi ambient.
>
> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
> proteger el medio ambiente.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From andreu.blanco at gmail.com  Fri Oct 20 14:08:02 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Fri, 20 Oct 2017 14:08:02 +0200
Subject: [R-sig-ME] glmmADMB errors
In-Reply-To: <CAMu=eMANfcoeOn3a_ufedhp6YHJDaeg91_RUa9EYWzG-andrNA@mail.gmail.com>
References: <CAOy7hbA9UxVShG=LRePEZDE7CimQa=WBNjs=qToRPersimjsSg@mail.gmail.com>
 <CAMu=eMANfcoeOn3a_ufedhp6YHJDaeg91_RUa9EYWzG-andrNA@mail.gmail.com>
Message-ID: <CAOy7hbCW+dc7E-X31kkndzchvZ-hahugoxGzCJKH+B5SkqAR-w@mail.gmail.com>

Thanks Mollie,
In fact, I am following instructions from the Zuur's book Beginner's guide
to zero inflated models and he suggests something similar to what you have
proposed. Hurdle models:
First modelling with a binomial distribution when biomass is present or not
and second, once is present with Gamma see which variables are affecting
the present biomass, plus glueing both models together in a ZAG. However I
am having some further problems since one of my varibles is random and
nested, which I think the model doesn't like that much, although it allows
to use glmer in such cases.
However, using glmmADMB with the gamma family still returns errors:
> Model_ADMB_G<-glmmadmb(Biomass~Protection*Exposure+(1|Protection/Location),data=GLMMADMB_P,
family="gamma")

Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
:
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
Adem?s: Warning message:
comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
-maxph 5 -noinit -shess' tiene estatus 1

I hope someone can see what I am doing wrong. Thanks in advance



On 20 October 2017 at 13:51, Mollie Brooks <mollieebrooks at gmail.com> wrote:

> Hi Andreu,
>
> A zero-inflated Poisson distribution is not appropriate because biomass is
> not count data. I would recommend checking what distribution other
> researchers in your field are using. Maybe you want to first model zero vs
> non-zero and then model the non-zero biomasses separately. The log of
> non-zero biomasses could be modeled with a normal distribution. Or on the
> natural scale, they could be Gamma or Tweedie. Or maybe a zero-inflated
> continuous positive distribution (e.g. Gamma or Tweedie) makes sense for
> all of the biomasses. These zero-inflated models could be fit in glmmTMB.
>
> cheers,
> Mollie
>
> On Thu, Oct 19, 2017 at 2:03 PM, andreu blanco <andreu.blanco at gmail.com>
> wrote:
>
>>  Dear list members, I am starting with generalized mixed models and I am
>> having some trouble I hope someone could help me with.
>>
>> We are trying to understand the invasiveness of algae inside and outside
>> MPA, to do so our sampling was set with a nested desing:
>>
>> Protected vs nonProtected
>> 4 Locations (protected) vs 4 Locations (nonProtected)
>> Exposed vs Semiexposed at each location
>> 1 transect per sampling point (total 16)
>> 5 quadrants per transect
>>
>> str(dataGLMMADMB)
>> 'data.frame':   80 obs. of  4 variables:
>>  $ Location: Factor w/ 4 levels "Cies1","Cies2",..: 1 1 1 1 1 1 1 1 1 1
>> ...
>>  $ Protection: Factor w/ 2 levels "Control","Protected": 1 1 1 1 1 2 2 2 2
>> 2 ...
>>  $ Exposure: Factor w/ 2 levels "Exposed","Semiexposed": 1 1 1 1 1 1 1 1 1
>> 1 ...
>>  $ Biomass: num  124.8 104.8 139.2 102.6 62.9 ...
>>
>>
>> First I ran it as a Poission distribution (after round the Biomass values)
>> to be able to fit a zeroInflation model:
>> > Model_ADMB_P<-glmmadmb(Biomass~Protection+Exposure+Protectio
>> n:Exposure+(1|
>> Protection/Location),data=GLMMADMB_P, zeroInflation=TRUE,
>> family="Poisson")
>> Parameters were estimated, but standard errors were not: the most likely
>> problem is that the curvature at MLE was zero or negative
>> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
>> :
>>   The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>> with
>> debug=TRUE for more information on failure mode
>> Adem?s: Warning message:
>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
>> -maxph 5 -noinit -shess' tiene estatus 1
>>
>> Then I though that since my data is continuous I'd better run the model
>> with a gamma family, however, when I do run it with gamma I got the
>> following error:
>> > Model_ADMB_G<-glmmadmb(Biomass~Protection+Exposure+Protectio
>> n:Exposure+(1|
>> Protection/Location),data=GLMMADMB_P, family="gamma")
>>
>> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
>> :
>>   The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>> with
>> debug=TRUE for more information on failure mode
>> Adem?s: Warning message:
>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
>> -maxph 5 -noinit -shess' tiene estatus 1
>>
>> However, when I run it as a Poisson distribution with zeroInflated values
>> but with no nested design and Location effect either, it ran ok
>> > Model_ADMB_P1<-glmmadmb(Biomass~Protection*Exposure,data=GLMMADMB_P,
>> zeroInflation=TRUE, family="Poisson")
>> > summary(Model_ADMB_P1)
>>
>> Call:
>> glmmadmb(formula = Biomass ~ Protection * Exposure, data = GLMMADMB_P,
>>     family = "Poisson", zeroInflation = TRUE)
>>
>> AIC: 1570.7
>>
>> Coefficients:
>>                                          Estimate Std. Error z value
>> Pr(>|z|)
>> (Intercept)                              4.71e+00   3.18e-02   148.0
>>  <2e-16
>> ProtectionProtected                     -5.53e-01   5.00e-02   -11.1
>>  <2e-16
>> ExposureSemiexposed                     -3.83e+01   2.22e+05     0.0
>> 1
>> ProtectionProtected:ExposureSemiexposed  3.64e+01   2.22e+05     0.0
>> 1
>>
>> (Intercept)                             ***
>> ProtectionProtected                     ***
>> ExposureSemiexposed
>> ProtectionProtected:ExposureSemiexposed
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Number of observations: total=80
>> Zero-inflation: 0.30908  (std. err.:  0.071433 )
>>
>> Log-likelihood: -780.37
>> >
>>
>>
>> I can not understat the solutions to these errors, can anyone please help
>> me out?
>> I really appreciate it!
>>
>> Thanks in advance,
>>
>> --
>> Andreu Blanco Cartagena
>>
>>
>>
>> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
>> ajuda a protegir el medi ambient.
>>
>> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
>> proteger el medio ambiente.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Fri Oct 20 14:10:19 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Fri, 20 Oct 2017 14:10:19 +0200
Subject: [R-sig-ME] glmmADMB errors
In-Reply-To: <CAMu=eMANfcoeOn3a_ufedhp6YHJDaeg91_RUa9EYWzG-andrNA@mail.gmail.com>
References: <CAOy7hbA9UxVShG=LRePEZDE7CimQa=WBNjs=qToRPersimjsSg@mail.gmail.com>
 <CAMu=eMANfcoeOn3a_ufedhp6YHJDaeg91_RUa9EYWzG-andrNA@mail.gmail.com>
Message-ID: <CAMu=eMCcjK0SHy+wcQsKCivHqyHfmtW8ejR6AD3-YwuXskU1vA@mail.gmail.com>

Sorry, I didn't see in your email that you had tried the Gamma distribution
in glmmADMB.

The cause of the error may have been the nesting of the random effect. In
my opinion, the nesting notation causes confusion quite often and it's best
to just give each of the 8 locations (i.e. RE levels) a unique name. If, on
the other hand, there are only 4 unique locations and both treatments are
in the same location, then location should be a fixed effect because 4
levels is too few for a random effect.

If you're fitting a zero-inflated model, you might have better luck with
convergence if you allow the zero-inflation to vary with parameters.

I would try these models if there are 8 uniquely coded locations
m1 <- glmmTMB(Biomass ~ Protection * Exposure +(1|Location),
data=dataGLMMADMB, family=Gamma(link="log"))

m2 <- glmmTMB(Biomass ~ Protection * Exposure +(1|Location),
zi =~ Protection * Exposure,
data=dataGLMMADMB, family=Gamma(link="log"))

On Fri, Oct 20, 2017 at 1:51 PM, Mollie Brooks <mollieebrooks at gmail.com>
wrote:

> Hi Andreu,
>
> A zero-inflated Poisson distribution is not appropriate because biomass is
> not count data. I would recommend checking what distribution other
> researchers in your field are using. Maybe you want to first model zero vs
> non-zero and then model the non-zero biomasses separately. The log of
> non-zero biomasses could be modeled with a normal distribution. Or on the
> natural scale, they could be Gamma or Tweedie. Or maybe a zero-inflated
> continuous positive distribution (e.g. Gamma or Tweedie) makes sense for
> all of the biomasses. These zero-inflated models could be fit in glmmTMB.
>
> cheers,
> Mollie
>
> On Thu, Oct 19, 2017 at 2:03 PM, andreu blanco <andreu.blanco at gmail.com>
> wrote:
>
>>  Dear list members, I am starting with generalized mixed models and I am
>> having some trouble I hope someone could help me with.
>>
>> We are trying to understand the invasiveness of algae inside and outside
>> MPA, to do so our sampling was set with a nested desing:
>>
>> Protected vs nonProtected
>> 4 Locations (protected) vs 4 Locations (nonProtected)
>> Exposed vs Semiexposed at each location
>> 1 transect per sampling point (total 16)
>> 5 quadrants per transect
>>
>> str(dataGLMMADMB)
>> 'data.frame':   80 obs. of  4 variables:
>>  $ Location: Factor w/ 4 levels "Cies1","Cies2",..: 1 1 1 1 1 1 1 1 1 1
>> ...
>>  $ Protection: Factor w/ 2 levels "Control","Protected": 1 1 1 1 1 2 2 2 2
>> 2 ...
>>  $ Exposure: Factor w/ 2 levels "Exposed","Semiexposed": 1 1 1 1 1 1 1 1 1
>> 1 ...
>>  $ Biomass: num  124.8 104.8 139.2 102.6 62.9 ...
>>
>>
>> First I ran it as a Poission distribution (after round the Biomass values)
>> to be able to fit a zeroInflation model:
>> > Model_ADMB_P<-glmmadmb(Biomass~Protection+Exposure+Protectio
>> n:Exposure+(1|
>> Protection/Location),data=GLMMADMB_P, zeroInflation=TRUE,
>> family="Poisson")
>> Parameters were estimated, but standard errors were not: the most likely
>> problem is that the curvature at MLE was zero or negative
>> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
>> :
>>   The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>> with
>> debug=TRUE for more information on failure mode
>> Adem?s: Warning message:
>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
>> -maxph 5 -noinit -shess' tiene estatus 1
>>
>> Then I though that since my data is continuous I'd better run the model
>> with a gamma family, however, when I do run it with gamma I got the
>> following error:
>> > Model_ADMB_G<-glmmadmb(Biomass~Protection+Exposure+Protectio
>> n:Exposure+(1|
>> Protection/Location),data=GLMMADMB_P, family="gamma")
>>
>> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
>> :
>>   The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>> with
>> debug=TRUE for more information on failure mode
>> Adem?s: Warning message:
>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
>> -maxph 5 -noinit -shess' tiene estatus 1
>>
>> However, when I run it as a Poisson distribution with zeroInflated values
>> but with no nested design and Location effect either, it ran ok
>> > Model_ADMB_P1<-glmmadmb(Biomass~Protection*Exposure,data=GLMMADMB_P,
>> zeroInflation=TRUE, family="Poisson")
>> > summary(Model_ADMB_P1)
>>
>> Call:
>> glmmadmb(formula = Biomass ~ Protection * Exposure, data = GLMMADMB_P,
>>     family = "Poisson", zeroInflation = TRUE)
>>
>> AIC: 1570.7
>>
>> Coefficients:
>>                                          Estimate Std. Error z value
>> Pr(>|z|)
>> (Intercept)                              4.71e+00   3.18e-02   148.0
>>  <2e-16
>> ProtectionProtected                     -5.53e-01   5.00e-02   -11.1
>>  <2e-16
>> ExposureSemiexposed                     -3.83e+01   2.22e+05     0.0
>> 1
>> ProtectionProtected:ExposureSemiexposed  3.64e+01   2.22e+05     0.0
>> 1
>>
>> (Intercept)                             ***
>> ProtectionProtected                     ***
>> ExposureSemiexposed
>> ProtectionProtected:ExposureSemiexposed
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Number of observations: total=80
>> Zero-inflation: 0.30908  (std. err.:  0.071433 )
>>
>> Log-likelihood: -780.37
>> >
>>
>>
>> I can not understat the solutions to these errors, can anyone please help
>> me out?
>> I really appreciate it!
>>
>> Thanks in advance,
>>
>> --
>> Andreu Blanco Cartagena
>>
>>
>>
>> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
>> ajuda a protegir el medi ambient.
>>
>> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
>> proteger el medio ambiente.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Oct 20 17:49:42 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 20 Oct 2017 11:49:42 -0400
Subject: [R-sig-ME] glmmADMB errors
In-Reply-To: <CAMu=eMCcjK0SHy+wcQsKCivHqyHfmtW8ejR6AD3-YwuXskU1vA@mail.gmail.com>
References: <CAOy7hbA9UxVShG=LRePEZDE7CimQa=WBNjs=qToRPersimjsSg@mail.gmail.com>
 <CAMu=eMANfcoeOn3a_ufedhp6YHJDaeg91_RUa9EYWzG-andrNA@mail.gmail.com>
 <CAMu=eMCcjK0SHy+wcQsKCivHqyHfmtW8ejR6AD3-YwuXskU1vA@mail.gmail.com>
Message-ID: <CABghstS7_6jCV6CvFRq6j+G4vL2kOKU2O-uuu4L37EQzxHSZxA@mail.gmail.com>

Following up on this: the proximal problem is that you have specified
Protection as both a random and a fixed effect, because the nesting
syntax (1|Protection/Location) expands to
(1|Protection)+(1|Protection:Location). I agree with Mollie that it's
generally less confusing to give unique values to the Location
variable, but if not then I would expect

Biomass~Protection+Exposure+Protection:Exposure+
  (1|Protection:Location)

to work better.


On Fri, Oct 20, 2017 at 8:10 AM, Mollie Brooks <mollieebrooks at gmail.com> wrote:
> Sorry, I didn't see in your email that you had tried the Gamma distribution
> in glmmADMB.
>
> The cause of the error may have been the nesting of the random effect. In
> my opinion, the nesting notation causes confusion quite often and it's best
> to just give each of the 8 locations (i.e. RE levels) a unique name. If, on
> the other hand, there are only 4 unique locations and both treatments are
> in the same location, then location should be a fixed effect because 4
> levels is too few for a random effect.
>
> If you're fitting a zero-inflated model, you might have better luck with
> convergence if you allow the zero-inflation to vary with parameters.
>
> I would try these models if there are 8 uniquely coded locations
> m1 <- glmmTMB(Biomass ~ Protection * Exposure +(1|Location),
> data=dataGLMMADMB, family=Gamma(link="log"))
>
> m2 <- glmmTMB(Biomass ~ Protection * Exposure +(1|Location),
> zi =~ Protection * Exposure,
> data=dataGLMMADMB, family=Gamma(link="log"))
>
> On Fri, Oct 20, 2017 at 1:51 PM, Mollie Brooks <mollieebrooks at gmail.com>
> wrote:
>
>> Hi Andreu,
>>
>> A zero-inflated Poisson distribution is not appropriate because biomass is
>> not count data. I would recommend checking what distribution other
>> researchers in your field are using. Maybe you want to first model zero vs
>> non-zero and then model the non-zero biomasses separately. The log of
>> non-zero biomasses could be modeled with a normal distribution. Or on the
>> natural scale, they could be Gamma or Tweedie. Or maybe a zero-inflated
>> continuous positive distribution (e.g. Gamma or Tweedie) makes sense for
>> all of the biomasses. These zero-inflated models could be fit in glmmTMB.
>>
>> cheers,
>> Mollie
>>
>> On Thu, Oct 19, 2017 at 2:03 PM, andreu blanco <andreu.blanco at gmail.com>
>> wrote:
>>
>>>  Dear list members, I am starting with generalized mixed models and I am
>>> having some trouble I hope someone could help me with.
>>>
>>> We are trying to understand the invasiveness of algae inside and outside
>>> MPA, to do so our sampling was set with a nested desing:
>>>
>>> Protected vs nonProtected
>>> 4 Locations (protected) vs 4 Locations (nonProtected)
>>> Exposed vs Semiexposed at each location
>>> 1 transect per sampling point (total 16)
>>> 5 quadrants per transect
>>>
>>> str(dataGLMMADMB)
>>> 'data.frame':   80 obs. of  4 variables:
>>>  $ Location: Factor w/ 4 levels "Cies1","Cies2",..: 1 1 1 1 1 1 1 1 1 1
>>> ...
>>>  $ Protection: Factor w/ 2 levels "Control","Protected": 1 1 1 1 1 2 2 2 2
>>> 2 ...
>>>  $ Exposure: Factor w/ 2 levels "Exposed","Semiexposed": 1 1 1 1 1 1 1 1 1
>>> 1 ...
>>>  $ Biomass: num  124.8 104.8 139.2 102.6 62.9 ...
>>>
>>>
>>> First I ran it as a Poission distribution (after round the Biomass values)
>>> to be able to fit a zeroInflation model:
>>> > Model_ADMB_P<-glmmadmb(Biomass~Protection+Exposure+Protectio
>>> n:Exposure+(1|
>>> Protection/Location),data=GLMMADMB_P, zeroInflation=TRUE,
>>> family="Poisson")
>>> Parameters were estimated, but standard errors were not: the most likely
>>> problem is that the curvature at MLE was zero or negative
>>> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
>>> :
>>>   The function maximizer failed (couldn't find parameter file)
>>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>>> with
>>> debug=TRUE for more information on failure mode
>>> Adem?s: Warning message:
>>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
>>> -maxph 5 -noinit -shess' tiene estatus 1
>>>
>>> Then I though that since my data is continuous I'd better run the model
>>> with a gamma family, however, when I do run it with gamma I got the
>>> following error:
>>> > Model_ADMB_G<-glmmadmb(Biomass~Protection+Exposure+Protectio
>>> n:Exposure+(1|
>>> Protection/Location),data=GLMMADMB_P, family="gamma")
>>>
>>> Error in glmmadmb(Biomass ~ Protection + Exposure + Protection:Exposure +
>>> :
>>>   The function maximizer failed (couldn't find parameter file)
>>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>>> with
>>> debug=TRUE for more information on failure mode
>>> Adem?s: Warning message:
>>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
>>> -maxph 5 -noinit -shess' tiene estatus 1
>>>
>>> However, when I run it as a Poisson distribution with zeroInflated values
>>> but with no nested design and Location effect either, it ran ok
>>> > Model_ADMB_P1<-glmmadmb(Biomass~Protection*Exposure,data=GLMMADMB_P,
>>> zeroInflation=TRUE, family="Poisson")
>>> > summary(Model_ADMB_P1)
>>>
>>> Call:
>>> glmmadmb(formula = Biomass ~ Protection * Exposure, data = GLMMADMB_P,
>>>     family = "Poisson", zeroInflation = TRUE)
>>>
>>> AIC: 1570.7
>>>
>>> Coefficients:
>>>                                          Estimate Std. Error z value
>>> Pr(>|z|)
>>> (Intercept)                              4.71e+00   3.18e-02   148.0
>>>  <2e-16
>>> ProtectionProtected                     -5.53e-01   5.00e-02   -11.1
>>>  <2e-16
>>> ExposureSemiexposed                     -3.83e+01   2.22e+05     0.0
>>> 1
>>> ProtectionProtected:ExposureSemiexposed  3.64e+01   2.22e+05     0.0
>>> 1
>>>
>>> (Intercept)                             ***
>>> ProtectionProtected                     ***
>>> ExposureSemiexposed
>>> ProtectionProtected:ExposureSemiexposed
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Number of observations: total=80
>>> Zero-inflation: 0.30908  (std. err.:  0.071433 )
>>>
>>> Log-likelihood: -780.37
>>> >
>>>
>>>
>>> I can not understat the solutions to these errors, can anyone please help
>>> me out?
>>> I really appreciate it!
>>>
>>> Thanks in advance,
>>>
>>> --
>>> Andreu Blanco Cartagena
>>>
>>>
>>>
>>> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
>>> ajuda a protegir el medi ambient.
>>>
>>> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
>>> proteger el medio ambiente.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From orchidn at live.com  Sat Oct 21 23:28:42 2017
From: orchidn at live.com (dani)
Date: Sat, 21 Oct 2017 21:28:42 +0000
Subject: [R-sig-ME] coefplot2 in conjunction with glmmTMB and glmer
Message-ID: <DM5PR1201MB00272D4AC593D8EFC57EAE36D6400@DM5PR1201MB0027.namprd12.prod.outlook.com>

Hello everyone,

<http://aka.ms/weboutlook>

I am learning how to use glmmTMB and I encountered the following issue:

I cannot get coefplot2 to work with my glmmTMB model. None of the options work (e.g coeftab). When I apply coefplot2 to the simple glmer model coeftab returns the following error:
Error in UseMethod("coeftab", object) :
  no applicable method for 'coeftab' applied to an object of class "c('glmerMod', 'merMod')"

I am not sure what to do as I would like to be able to get a plot of the regression estimates for the these two models. So far, even though coeftab  is not working, I can only plot the estimates for the glmer model.

I suspect it is because both glmerMod and glmmTMb are S4 objects.

Thank you all very much!
Best,
Dani N-M



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Oct 21 23:36:46 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Oct 2017 17:36:46 -0400
Subject: [R-sig-ME] coefplot2 in conjunction with glmmTMB and glmer
In-Reply-To: <DM5PR1201MB00272D4AC593D8EFC57EAE36D6400@DM5PR1201MB0027.namprd12.prod.outlook.com>
References: <DM5PR1201MB00272D4AC593D8EFC57EAE36D6400@DM5PR1201MB0027.namprd12.prod.outlook.com>
Message-ID: <9d227a19-908b-f5b6-710a-c523dfac7744@gmail.com>


  coefplot2 is pretty well deprecated now, in favor of the "broom"
package.  In order to get nice coefficient plots/tables for glmmTMB
objects, I would suggest

1. install my fork of broom, which knows how to deal with those objects:
  devtools::install_github("bbolker/broom")

2a. use tidy() to extract the coefficient table and ggplot to plot the
coefficient plots (geom_pointrange is useful), or

2b. install the dotwhisker package, which should (in conjunction with
broom) do this automatically

 e.g.

library(glmmTMB)
example(glmmTMB)
library(dotwhisker)
dwplot(m3)  ## hmm, RE standard dev disappears
dwplot(m3,effects="fixed")  ## maybe we didn't want it anyway



On 17-10-21 05:28 PM, dani wrote:
> Hello everyone,
> 
> <http://aka.ms/weboutlook>
> 
> I am learning how to use glmmTMB and I encountered the following issue:
> 
> I cannot get coefplot2 to work with my glmmTMB model. None of the options work (e.g coeftab). When I apply coefplot2 to the simple glmer model coeftab returns the following error:
> Error in UseMethod("coeftab", object) :
>   no applicable method for 'coeftab' applied to an object of class "c('glmerMod', 'merMod')"
> 
> I am not sure what to do as I would like to be able to get a plot of the regression estimates for the these two models. So far, even though coeftab  is not working, I can only plot the estimates for the glmer model.
> 
> I suspect it is because both glmerMod and glmmTMb are S4 objects.
> 
> Thank you all very much!
> Best,
> Dani N-M
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From orchidn at live.com  Sat Oct 21 23:43:53 2017
From: orchidn at live.com (dani)
Date: Sat, 21 Oct 2017 21:43:53 +0000
Subject: [R-sig-ME] coefplot2 in conjunction with glmmTMB and glmer
In-Reply-To: <9d227a19-908b-f5b6-710a-c523dfac7744@gmail.com>
References: <DM5PR1201MB00272D4AC593D8EFC57EAE36D6400@DM5PR1201MB0027.namprd12.prod.outlook.com>,
 <9d227a19-908b-f5b6-710a-c523dfac7744@gmail.com>
Message-ID: <MWHPR1201MB002959B7FE4F965249EFCC0ED6400@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Ben,


Thank you so much for your prompt response!

Much appreciated!

Best regards!

Dani

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Saturday, October 21, 2017 2:36 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] coefplot2 in conjunction with glmmTMB and glmer


  coefplot2 is pretty well deprecated now, in favor of the "broom"
package.  In order to get nice coefficient plots/tables for glmmTMB
objects, I would suggest

1. install my fork of broom, which knows how to deal with those objects:
  devtools::install_github("bbolker/broom")

2a. use tidy() to extract the coefficient table and ggplot to plot the
coefficient plots (geom_pointrange is useful), or

2b. install the dotwhisker package, which should (in conjunction with
broom) do this automatically

 e.g.

library(glmmTMB)
example(glmmTMB)
library(dotwhisker)
dwplot(m3)  ## hmm, RE standard dev disappears
dwplot(m3,effects="fixed")  ## maybe we didn't want it anyway



On 17-10-21 05:28 PM, dani wrote:
> Hello everyone,
>
> <http://aka.ms/weboutlook>
>
> I am learning how to use glmmTMB and I encountered the following issue:
>
> I cannot get coefplot2 to work with my glmmTMB model. None of the options work (e.g coeftab). When I apply coefplot2 to the simple glmer model coeftab returns the following error:
> Error in UseMethod("coeftab", object) :
>   no applicable method for 'coeftab' applied to an object of class "c('glmerMod', 'merMod')"
>
> I am not sure what to do as I would like to be able to get a plot of the regression estimates for the these two models. So far, even though coeftab  is not working, I can only plot the estimates for the glmer model.
>
> I suspect it is because both glmerMod and glmmTMb are S4 objects.
>
> Thank you all very much!
> Best,
> Dani N-M
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...




	[[alternative HTML version deleted]]


From andreu.blanco at gmail.com  Mon Oct 23 09:12:51 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Mon, 23 Oct 2017 09:12:51 +0200
Subject: [R-sig-ME] glmmADMB errors
In-Reply-To: <CABghstS7_6jCV6CvFRq6j+G4vL2kOKU2O-uuu4L37EQzxHSZxA@mail.gmail.com>
References: <CAOy7hbA9UxVShG=LRePEZDE7CimQa=WBNjs=qToRPersimjsSg@mail.gmail.com>
 <CAMu=eMANfcoeOn3a_ufedhp6YHJDaeg91_RUa9EYWzG-andrNA@mail.gmail.com>
 <CAMu=eMCcjK0SHy+wcQsKCivHqyHfmtW8ejR6AD3-YwuXskU1vA@mail.gmail.com>
 <CABghstS7_6jCV6CvFRq6j+G4vL2kOKU2O-uuu4L37EQzxHSZxA@mail.gmail.com>
Message-ID: <CAOy7hbC2dj_0-_eCJpWVHOoYDFG-jWkMu4qUwL7AeyD4A9hCxg@mail.gmail.com>

Thank you both very much.

I hope this will work.

On 20 October 2017 at 17:49, Ben Bolker <bbolker at gmail.com> wrote:

> Following up on this: the proximal problem is that you have specified
> Protection as both a random and a fixed effect, because the nesting
> syntax (1|Protection/Location) expands to
> (1|Protection)+(1|Protection:Location). I agree with Mollie that it's
> generally less confusing to give unique values to the Location
> variable, but if not then I would expect
>
> Biomass~Protection+Exposure+Protection:Exposure+
>   (1|Protection:Location)
>
> to work better.
>
>
> On Fri, Oct 20, 2017 at 8:10 AM, Mollie Brooks <mollieebrooks at gmail.com>
> wrote:
> > Sorry, I didn't see in your email that you had tried the Gamma
> distribution
> > in glmmADMB.
> >
> > The cause of the error may have been the nesting of the random effect. In
> > my opinion, the nesting notation causes confusion quite often and it's
> best
> > to just give each of the 8 locations (i.e. RE levels) a unique name. If,
> on
> > the other hand, there are only 4 unique locations and both treatments are
> > in the same location, then location should be a fixed effect because 4
> > levels is too few for a random effect.
> >
> > If you're fitting a zero-inflated model, you might have better luck with
> > convergence if you allow the zero-inflation to vary with parameters.
> >
> > I would try these models if there are 8 uniquely coded locations
> > m1 <- glmmTMB(Biomass ~ Protection * Exposure +(1|Location),
> > data=dataGLMMADMB, family=Gamma(link="log"))
> >
> > m2 <- glmmTMB(Biomass ~ Protection * Exposure +(1|Location),
> > zi =~ Protection * Exposure,
> > data=dataGLMMADMB, family=Gamma(link="log"))
> >
> > On Fri, Oct 20, 2017 at 1:51 PM, Mollie Brooks <mollieebrooks at gmail.com>
> > wrote:
> >
> >> Hi Andreu,
> >>
> >> A zero-inflated Poisson distribution is not appropriate because biomass
> is
> >> not count data. I would recommend checking what distribution other
> >> researchers in your field are using. Maybe you want to first model zero
> vs
> >> non-zero and then model the non-zero biomasses separately. The log of
> >> non-zero biomasses could be modeled with a normal distribution. Or on
> the
> >> natural scale, they could be Gamma or Tweedie. Or maybe a zero-inflated
> >> continuous positive distribution (e.g. Gamma or Tweedie) makes sense for
> >> all of the biomasses. These zero-inflated models could be fit in
> glmmTMB.
> >>
> >> cheers,
> >> Mollie
> >>
> >> On Thu, Oct 19, 2017 at 2:03 PM, andreu blanco <andreu.blanco at gmail.com
> >
> >> wrote:
> >>
> >>>  Dear list members, I am starting with generalized mixed models and I
> am
> >>> having some trouble I hope someone could help me with.
> >>>
> >>> We are trying to understand the invasiveness of algae inside and
> outside
> >>> MPA, to do so our sampling was set with a nested desing:
> >>>
> >>> Protected vs nonProtected
> >>> 4 Locations (protected) vs 4 Locations (nonProtected)
> >>> Exposed vs Semiexposed at each location
> >>> 1 transect per sampling point (total 16)
> >>> 5 quadrants per transect
> >>>
> >>> str(dataGLMMADMB)
> >>> 'data.frame':   80 obs. of  4 variables:
> >>>  $ Location: Factor w/ 4 levels "Cies1","Cies2",..: 1 1 1 1 1 1 1 1 1 1
> >>> ...
> >>>  $ Protection: Factor w/ 2 levels "Control","Protected": 1 1 1 1 1 2 2
> 2 2
> >>> 2 ...
> >>>  $ Exposure: Factor w/ 2 levels "Exposed","Semiexposed": 1 1 1 1 1 1 1
> 1 1
> >>> 1 ...
> >>>  $ Biomass: num  124.8 104.8 139.2 102.6 62.9 ...
> >>>
> >>>
> >>> First I ran it as a Poission distribution (after round the Biomass
> values)
> >>> to be able to fit a zeroInflation model:
> >>> > Model_ADMB_P<-glmmadmb(Biomass~Protection+Exposure+Protectio
> >>> n:Exposure+(1|
> >>> Protection/Location),data=GLMMADMB_P, zeroInflation=TRUE,
> >>> family="Poisson")
> >>> Parameters were estimated, but standard errors were not: the most
> likely
> >>> problem is that the curvature at MLE was zero or negative
> >>> Error in glmmadmb(Biomass ~ Protection + Exposure +
> Protection:Exposure +
> >>> :
> >>>   The function maximizer failed (couldn't find parameter file)
> >>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> >>> output files; (2) change run parameters: see '?admbControl';(3) re-run
> >>> with
> >>> debug=TRUE for more information on failure mode
> >>> Adem?s: Warning message:
> >>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
> >>> -maxph 5 -noinit -shess' tiene estatus 1
> >>>
> >>> Then I though that since my data is continuous I'd better run the model
> >>> with a gamma family, however, when I do run it with gamma I got the
> >>> following error:
> >>> > Model_ADMB_G<-glmmadmb(Biomass~Protection+Exposure+Protectio
> >>> n:Exposure+(1|
> >>> Protection/Location),data=GLMMADMB_P, family="gamma")
> >>>
> >>> Error in glmmadmb(Biomass ~ Protection + Exposure +
> Protection:Exposure +
> >>> :
> >>>   The function maximizer failed (couldn't find parameter file)
> >>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> >>> output files; (2) change run parameters: see '?admbControl';(3) re-run
> >>> with
> >>> debug=TRUE for more information on failure mode
> >>> Adem?s: Warning message:
> >>> comando ejecutado 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
> >>> -maxph 5 -noinit -shess' tiene estatus 1
> >>>
> >>> However, when I run it as a Poisson distribution with zeroInflated
> values
> >>> but with no nested design and Location effect either, it ran ok
> >>> > Model_ADMB_P1<-glmmadmb(Biomass~Protection*Exposure,data=GLMMADMB_P,
> >>> zeroInflation=TRUE, family="Poisson")
> >>> > summary(Model_ADMB_P1)
> >>>
> >>> Call:
> >>> glmmadmb(formula = Biomass ~ Protection * Exposure, data = GLMMADMB_P,
> >>>     family = "Poisson", zeroInflation = TRUE)
> >>>
> >>> AIC: 1570.7
> >>>
> >>> Coefficients:
> >>>                                          Estimate Std. Error z value
> >>> Pr(>|z|)
> >>> (Intercept)                              4.71e+00   3.18e-02   148.0
> >>>  <2e-16
> >>> ProtectionProtected                     -5.53e-01   5.00e-02   -11.1
> >>>  <2e-16
> >>> ExposureSemiexposed                     -3.83e+01   2.22e+05     0.0
> >>> 1
> >>> ProtectionProtected:ExposureSemiexposed  3.64e+01   2.22e+05     0.0
> >>> 1
> >>>
> >>> (Intercept)                             ***
> >>> ProtectionProtected                     ***
> >>> ExposureSemiexposed
> >>> ProtectionProtected:ExposureSemiexposed
> >>> ---
> >>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>
> >>> Number of observations: total=80
> >>> Zero-inflation: 0.30908  (std. err.:  0.071433 )
> >>>
> >>> Log-likelihood: -780.37
> >>> >
> >>>
> >>>
> >>> I can not understat the solutions to these errors, can anyone please
> help
> >>> me out?
> >>> I really appreciate it!
> >>>
> >>> Thanks in advance,
> >>>
> >>> --
> >>> Andreu Blanco Cartagena
> >>>
> >>>
> >>>
> >>> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
> >>> ajuda a protegir el medi ambient.
> >>>
> >>> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
> >>> proteger el medio ambiente.
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From orchidn at live.com  Mon Oct 23 10:28:48 2017
From: orchidn at live.com (dani)
Date: Mon, 23 Oct 2017 08:28:48 +0000
Subject: [R-sig-ME] fitting a MCMCglmm zero-inflated model
Message-ID: <MWHPR1201MB00298E02C87820026E0AC61DD6460@MWHPR1201MB0029.namprd12.prod.outlook.com>

Dear list members,


I need some advice regarding fitting a MCMCglmm zero-inflated model.


I fitted a zero-inflated Poisson model with a single zero inflation parameter for all observations (ziformula~1) in glmmTMB. I would now like to run a similar model based on MCMCglmm.<http://aka.ms/weboutlook>

I must confess I am not sure I understood how to use the at.level term to model interactions with covariates at level 1 in my model. It is not clear to me how to specify the prior.

My model has an offset term and two cross-classified random groups, as well as the following variables:
 - Level 1 variables:                   x1, x2, and x3
 - Level 2 (group 1) variable:   x4
 - Level 2 (group 2) variables: x5, x6, and x7

Here is the code:

priori <- list(R=list(V=diag(2), n=2,fix=2),
               G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))

model <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):offset +
                  at.level(trait,1):x1 +
                  at.level(trait,1):x2 +
                  at.level(trait,1):x3 +
                  x4+ x5 + x6+x7 ,
                  random = ~idh(trait):group1 + idh(trait):group2
                 family = "zipoisson",
                 prior = priori,
                 rcov = ~idh(trait):units,
                 data = mydata)

I am getting the following message:
Error in cbind_all(x) : Argument 2 must have names

As I am pretty sure that my prior and my at.level terms specification are all kinds of wrong:) , I am not worried at this point about the error message, but I would like to ask advice as to how to properly specify this model.

Thank you all for your constant help, this list is amazing!
Best regards, everyone,
Dani NM


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Oct 23 10:50:04 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 23 Oct 2017 09:50:04 +0100
Subject: [R-sig-ME] fitting a MCMCglmm zero-inflated model
In-Reply-To: <MWHPR1201MB00298E02C87820026E0AC61DD6460@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00298E02C87820026E0AC61DD6460@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <3f610868-fbd1-a203-ce94-8de5225a6cfd@ed.ac.uk>

Hi,

You've missed a comma after the random argument.

At the moment you are fitting a single effect of x4, x5,x6 and x7 for 
both the zi and the Possion processes. Presumably you only intend to fit 
effects for these terms for the Poisson part? I would use the formula:

y ~ trait - 1 + at.level(trait,1):(offset+x1+x2+x3+x4+x5+x6+x7)

Your priors are strong too - I would use nu=0.002 rather than nu=2.

Cheers,

Jarrod


On 23/10/2017 09:28, dani wrote:
> Dear list members,
>
>
> I need some advice regarding fitting a MCMCglmm zero-inflated model.
>
>
> I fitted a zero-inflated Poisson model with a single zero inflation parameter for all observations (ziformula~1) in glmmTMB. I would now like to run a similar model based on MCMCglmm.<http://aka.ms/weboutlook>
>
> I must confess I am not sure I understood how to use the at.level term to model interactions with covariates at level 1 in my model. It is not clear to me how to specify the prior.
>
> My model has an offset term and two cross-classified random groups, as well as the following variables:
>   - Level 1 variables:                   x1, x2, and x3
>   - Level 2 (group 1) variable:   x4
>   - Level 2 (group 2) variables: x5, x6, and x7
>
> Here is the code:
>
> priori <- list(R=list(V=diag(2), n=2,fix=2),
>                 G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>
> model <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):offset +
>                    at.level(trait,1):x1 +
>                    at.level(trait,1):x2 +
>                    at.level(trait,1):x3 +
>                    x4+ x5 + x6+x7 ,
>                    random = ~idh(trait):group1 + idh(trait):group2
>                   family = "zipoisson",
>                   prior = priori,
>                   rcov = ~idh(trait):units,
>                   data = mydata)
>
> I am getting the following message:
> Error in cbind_all(x) : Argument 2 must have names
>
> As I am pretty sure that my prior and my at.level terms specification are all kinds of wrong:) , I am not worried at this point about the error message, but I would like to ask advice as to how to properly specify this model.
>
> Thank you all for your constant help, this list is amazing!
> Best regards, everyone,
> Dani NM
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From orchidn at live.com  Mon Oct 23 10:55:39 2017
From: orchidn at live.com (dani)
Date: Mon, 23 Oct 2017 08:55:39 +0000
Subject: [R-sig-ME] fitting a MCMCglmm zero-inflated model
In-Reply-To: <3f610868-fbd1-a203-ce94-8de5225a6cfd@ed.ac.uk>
References: <MWHPR1201MB00298E02C87820026E0AC61DD6460@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <3f610868-fbd1-a203-ce94-8de5225a6cfd@ed.ac.uk>
Message-ID: <MWHPR1201MB0029B14081ED9B3855ED3FBAD6460@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Jarrod,


Thank you so much for your prompt response. Yes, that sounds right, I will make the correction. Interestingly, after I posted my message, I restarted R and the model magically worked. SInce I used implicit specifications (13000 iterations), my effective samples were ridiculous; for example:


R-structure:  ~idh(trait):units
#
#                             post.mean l-95% CI u-95% CI eff.samp
# traity.units       0.1155  0.07864   0.1696    7.503
# traitzi_y.units    1.0000  1.00000   1.0000    0.000


Thank you so much and have a nice day everyone!

Best, DNM


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Monday, October 23, 2017 1:50 AM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] fitting a MCglmm zero-inflated model

Hi,

You've missed a comma after the random argument.

At the moment you are fitting a single effect of x4, x5,x6 and x7 for
both the zi and the Possion processes. Presumably you only intend to fit
effects for these terms for the Poisson part? I would use the formula:

y ~ trait - 1 + at.level(trait,1):(offset+x1+x2+x3+x4+x5+x6+x7)

Your priors are strong too - I would use nu=0.002 rather than nu=2.

Cheers,

Jarrod


On 23/10/2017 09:28, dani wrote:
> Dear list members,
>
>
> I need some advice regarding fitting a MCMCglmm zero-inflated model.
>
>
> I fitted a zero-inflated Poisson model with a single zero inflation parameter for all observations (ziformula~1) in glmmTMB. I would now like to run a similar model based on MCMCglmm.<http://aka.ms/weboutlook>
>
> I must confess I am not sure I understood how to use the at.level term to model interactions with covariates at level 1 in my model. It is not clear to me how to specify the prior.
>
> My model has an offset term and two cross-classified random groups, as well as the following variables:
>   - Level 1 variables:                   x1, x2, and x3
>   - Level 2 (group 1) variable:   x4
>   - Level 2 (group 2) variables: x5, x6, and x7
>
> Here is the code:
>
> priori <- list(R=list(V=diag(2), n=2,fix=2),
>                 G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>
> model <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):offset +
>                    at.level(trait,1):x1 +
>                    at.level(trait,1):x2 +
>                    at.level(trait,1):x3 +
>                    x4+ x5 + x6+x7 ,
>                    random = ~idh(trait):group1 + idh(trait):group2
>                   family = "zipoisson",
>                   prior = priori,
>                   rcov = ~idh(trait):units,
>                   data = mydata)
>
> I am getting the following message:
> Error in cbind_all(x) : Argument 2 must have names
>
> As I am pretty sure that my prior and my at.level terms specification are all kinds of wrong:) , I am not worried at this point about the error message, but I would like to ask advice as to how to properly specify this model.
>
> Thank you all for your constant help, this list is amazing!
> Best regards, everyone,
> Dani NM
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


	[[alternative HTML version deleted]]


From dorothea.dumuid at mymail.unisa.edu.au  Mon Oct 23 06:31:56 2017
From: dorothea.dumuid at mymail.unisa.edu.au (Dumuid, Dorothea - tridy002)
Date: Mon, 23 Oct 2017 04:31:56 +0000
Subject: [R-sig-ME] r-sig-mixed-models@r-project.org: multiple dependent
 variables in lmer()
In-Reply-To: <c4ad35462ba54dea84fb75f388aa025c@UM-MAIL3216.unimaas.nl>
References: <MEXPR01MB091825037B89E12D291F1D3DED490@MEXPR01MB0918.ausprd01.prod.outlook.com>,
 <c4ad35462ba54dea84fb75f388aa025c@UM-MAIL3216.unimaas.nl>
Message-ID: <MEXPR01MB091899ECEF5723C40F2F2F06ED460@MEXPR01MB0918.ausprd01.prod.outlook.com>

Thank you so much for your very quick response. It is very helpful.

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Viechtbauer Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl>
Sent: Friday, October 20, 2017 5:33:35 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] r-sig-mixed-models at r-project.org: multiple dependent variables in lmer()

Hi Dot,

Restructure your data into a 'very long' format, that is:

ID gp time ilr   y
1  I  1    ilr1  .
1  I  2    ilr2  .
1  I  3    ilr3  .
1  I  1    ilr1  .
1  I  2    ilr2  .
1  I  3    ilr3  .
1  I  1    ilr1  .
1  I  2    ilr2  .
1  I  3    ilr3  .
...

where 'y' is the actual ilr value for that person in that group at that time point for that domain. Then you can fit a multivariate model to these data. For example, a MANOVA-type model would be:

library(nlme)
dat$cond <- 1:9
res <- gls(y ~ factor(gp)*factor(time)*factor(ilr), correlation = corSymm(form = ~ 1 | id), weights = varIdent(form = ~ 1 | cond), data=dat)
anova(res)

But this will estimate 9 variances and 36 covariances (plus the fixed effects), which might be pushing things. So you might want to consider a more parsimonious model. The other extreme would be:

lmer(y ~ factor(gp)*factor(time)*factor(ilr) + (1 | ID), data=dat)

or equivalently

lme(y ~ factor(gp)*factor(time)*factor(ilr), random = ~ 1 | ID, data=dat)

but this probably way too parsimonious.

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Dumuid, Dorothea - tridy002
Sent: Saturday, 14 October, 2017 10:06
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] r-sig-mixed-models at r-project.org: multiple dependent variables in lmer()

We are analysing data from a randomised controlled trial for an exercise intervention.

We have 106 participants, in three groups:
(1) control (n=34)
(2) moderate exercise (n=36)
(2) intensive exercise (n= 36)

We want to know if participants' use of time changed differently depending on which group they were in.

Our outcome measure is participants' 24-hour time-use composition (minutes/day spent in 4 domains: sleep, sitting, standing and physical activity).

Time use is measured at 3 time points:
(1) baseline
(2) post-intervention
(3) 12-month follow-up

Time in all four domains always adds to 24 hours, therefore if all components are included in the model there would be perfect multicollinearity. So we have expressed the time-use compositions as sets of three isometric log-ratio (ilr) coordinates created using an orthonormal basis. These ilr coordinates contain all relative information regarding the time-use compositions and can be used to represent the compositions in multivariate statistical models.

So, the variables for our model look like this:
ID = participant ID
gp = a factor variable ("I", "M, "C"), for intense, moderate or control group
time = a factor variable (1, 2, 3) for time point of measurement
ilr1, ilr2 and ilr3 = three isometric log ratios (the dependent variables).

We would like to run a model like this:

fit=lmer(cbind(ilr1, ilr2, ilr3) ~gp * time + (1|ID)),
car::Anova(fit)  # this does a Type II MANOVA Test (Pillai)

(ignoring for the moment that participants may have random slopes).

But the lme4 regression command (lmer) does not allow more than one dependent variable. It's possible to run a separate lmer() for each log-ratio coordinate, and then predict a new log-ratio coordinate for each time point, for each group. Because the log-ratio coordinates are orthornormal, we can simply put the predicted log-ratios back together, find their inverse, and then we can compare the predicted time-use composition for each group, for each time point. So we can see from this how time in the four domains is predicted to change over the time points, for both groups.

However, we cannot work out how to compute a statistic for the interaction effect between group and time point for all the log ratios together (i.e., the set of log ratios). Is it possible to run a MANOVA of the complete set of models?

Thanks in advance!
Dot

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From andreu.blanco at gmail.com  Tue Oct 24 11:30:14 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Tue, 24 Oct 2017 11:30:14 +0200
Subject: [R-sig-ME] Gamma-shape parameter extraction
Message-ID: <CAOy7hbCh40yoH=D_pw+6BR4NoFdn8szDdnn=y1Zoe5S5xLmpbA@mail.gmail.com>

Hi,

I am dealing with hurdle models for which I need to extract the dispersion
parameter of my gamma model, which I did with glmmadmb. However I am not
able to extract that value from the summary. Of course I can copy paste,
but I rather want to know how to do it. Thanks!
That's my summary:

>summary(zag1)

Call:
glmmadmb(formula = Biomass ~ Protection + Exposure + Protection:Exposure +
    (1 | Protection:Location), data = Aarmata.pos, family = "Gamma",
    link = "log")

AIC: 644.9

Coefficients:
                                        Estimate Std. Error z value
Pr(>|z|)
(Intercept)                                4.184      0.452    9.25
 <2e-16 ***
ProtectionProtected                        0.201      0.647    0.31
0.756
ExposureSemiexposed                       -0.609      0.349   -1.75
0.081 .
ProtectionProtected:ExposureSemiexposed   -0.674      0.575   -1.17
0.241
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=61, Protection:Location=8
Random effect variance(s):
Group=Protection:Location
            Variance StdDev
(Intercept)   0.6592 0.8119

Gamma shape parameter: 1.4473 (std. err.: 0.25759)

Log-likelihood: -316.472

-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Tue Oct 24 15:16:26 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Tue, 24 Oct 2017 11:16:26 -0200
Subject: [R-sig-ME] reporting model estimates values
Message-ID: <CAF5W3aRBq_zQ-a8DzzMR_d_-4qpqi-NAYbEouvSv7RJ4-ybYXQ@mail.gmail.com>

Dear glmmTMB authors & list members ,

For glmer models I use "lsmeans" or "effects" package to report the
coefficient estimated values, but any of them works with glmmTMB
objetcs:

lsmeans::lsmeans(mod, ~ factor, type = "response"); or

effects::allEffects(mod)

How would you suggest me to do that with an glmmTMB model?

Here is a short example (with only two factor levels):

library(glmmTMB)
m1 <- glmmTMB(count~ mined + (1|site),
               zi=~0,
               family=poisson, data=Salamanders)
summary(m1)

m2 <- glmer(count ~ mined + (1|site), family=poisson, data=Salamanders)
summary(m2)

library(lsmeans)
lsmeans(m2, ~ mined, type = "response")

library(effects)
eff.m2 <- allEffects(m2); as.data.frame(eff.m2[[1]])

lsmeans(m1, ~ mined, type = "response")
eff.m2 <- allEffects(m1); as.data.frame(eff.m1[[1]])

Thanks in advance,

Juan Edwards

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Oct 24 17:12:46 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Oct 2017 11:12:46 -0400
Subject: [R-sig-ME] reporting model estimates values
In-Reply-To: <CAF5W3aRBq_zQ-a8DzzMR_d_-4qpqi-NAYbEouvSv7RJ4-ybYXQ@mail.gmail.com>
References: <CAF5W3aRBq_zQ-a8DzzMR_d_-4qpqi-NAYbEouvSv7RJ4-ybYXQ@mail.gmail.com>
Message-ID: <cbe35101-2e29-5813-f3e5-929cd448af2f@gmail.com>



 Depends what you mean by estimated coefficient values.  You already
have the summaries; I assume you mean you want predicted values with
standard errors for each factor level?

  You could do it like this: (this brute-force method will work for any
model where you can extract the formula, fixed-effect parameters,
variance-covariance matrix of fixed-effect parameters)

## set up prediction frame
pframe <- with(Salamanders,
               data.frame(mined=levels(mined)))
## get formula and keep only fixed effects
fform <- lme4::nobars(formula(m1))
## drop LHS from formula
fform_noresp <- fform[-2]
## model matrix for new predictions
X <- model.matrix(fform_noresp,data=pframe)
## fixed-effect parameters
beta <- fixef(m1)[["cond"]]
## predictions (linear predictor scale)
pred0 <- X %*% beta
## predictions (back-transformed)
pred <- exp(pred0)
## standard errors of predictions (log scale)
pse <- sqrt(diag(X %*% crossprod(X,vcov(m1)[["cond"]])))
## back-transformed confidence intervals
exp(qnorm(c(0.025,0.975),mean=pred0[1],sd=pse[1]))
exp(qnorm(c(0.025,0.975),mean=pred0[2],sd=pse[2]))

Alternatively, you can use an experimental version that has the glue
needed for the effects package.

devtools::install_github("glmmTMB/glmmTMB/glmmTMB",ref="effects")
library(glmmTMB)
source(system.file("other_methods","effectsglmmTMB.R",package="glmmTMB"))
allEffects(m1)


  Caveats:

   - this will only work at present for families known to base-R
(poisson, gaussian, binomial, Gamma, etc.) - not for nbinom2 etc.
   - it makes lots of assumptions. In particular, for zero-inflated
models it ignores the zero-inflation part completely and gives
predictions etc etc only for the conditional model




On 17-10-24 09:16 AM, Juan Pablo Edwards Molina wrote:
> Dear glmmTMB authors & list members ,
> 
> For glmer models I use "lsmeans" or "effects" package to report the
> coefficient estimated values, but any of them works with glmmTMB
> objetcs:
> 
> lsmeans::lsmeans(mod, ~ factor, type = "response"); or
> 
> effects::allEffects(mod)
> 
> How would you suggest me to do that with an glmmTMB model?
> 
> Here is a short example (with only two factor levels):
> 
> library(glmmTMB)
> m1 <- glmmTMB(count~ mined + (1|site),
>                zi=~0,
>                family=poisson, data=Salamanders)
> summary(m1)
> 
> m2 <- glmer(count ~ mined + (1|site), family=poisson, data=Salamanders)
> summary(m2)
> 
> library(lsmeans)
> lsmeans(m2, ~ mined, type = "response")
> 
> library(effects)
> eff.m2 <- allEffects(m2); as.data.frame(eff.m2[[1]])
> 
> lsmeans(m1, ~ mined, type = "response")
> eff.m2 <- allEffects(m1); as.data.frame(eff.m1[[1]])
> 
> Thanks in advance,
> 
> Juan Edwards
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Tue Oct 24 20:51:45 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Oct 2017 14:51:45 -0400
Subject: [R-sig-ME] reporting model estimates values
In-Reply-To: <CAF5W3aT8ECk+09JdtJhS=Fbmv5-0vnSfGUpPX_a--SKkLBu7nw@mail.gmail.com>
References: <CAF5W3aRBq_zQ-a8DzzMR_d_-4qpqi-NAYbEouvSv7RJ4-ybYXQ@mail.gmail.com>
 <cbe35101-2e29-5813-f3e5-929cd448af2f@gmail.com>
 <CAF5W3aT8ECk+09JdtJhS=Fbmv5-0vnSfGUpPX_a--SKkLBu7nw@mail.gmail.com>
Message-ID: <5c799216-a9d0-7da8-fcee-ef4474e3eea5@gmail.com>



 (please keep r-sig-mixed-models in cc:)

  Without investigating too closely I'm not sure what drives the
difference.  effects could be using CIs based on t rather than Normal,
but with 641 residual df (df.residual(m1)) that wouldn't make that big a
difference.

  Ben Bolker


On 17-10-24 02:26 PM, Juan Pablo Edwards Molina wrote:
> Thanks for your quick reply prof. Bolker and sorry for the misunderstanding.
> 
>  Yes, I meant the predicted values with standard errors for each factor level.
> 
> I tried both methods: predicted values and SE they present slight
> differences in the CI values. I suppose it?s not a big deal...
> 
> # Extended method
>> pred
>        [,1]
> 1 2.1363277
> 2 0.2219451
> 
>> pse
> [1] 0.2233638 0.1701403
> 
>> exp(qnorm(c(0.025,0.975), mean=pred0[1],sd=pse[1]))
> [1] 1.378924 3.309752
> 
>> exp(qnorm(c(0.025,0.975), mean=pred0[2],sd=pse[2]))
> [1] 0.1590091 0.3097914
> 
> # Experimental version of effect package:
> 
>> as.data.frame(allEffects(m1)[[1]])
>     mined       fit             se     lower     upper
> 1   yes 0.2219451 0.2230325 0.1433508 0.3436301
> 2    no 2.1363277 0.1705744 1.5292366 2.9844276
> 
> Thanks!
> 
> Juan
> 
> 
> On Tue, Oct 24, 2017 at 1:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>  Depends what you mean by estimated coefficient values.  You already
>> have the summaries; I assume you mean you want predicted values with
>> standard errors for each factor level?
>>
>>   You could do it like this: (this brute-force method will work for any
>> model where you can extract the formula, fixed-effect parameters,
>> variance-covariance matrix of fixed-effect parameters)
>>
>> ## set up prediction frame
>> pframe <- with(Salamanders,
>>                data.frame(mined=levels(mined)))
>> ## get formula and keep only fixed effects
>> fform <- lme4::nobars(formula(m1))
>> ## drop LHS from formula
>> fform_noresp <- fform[-2]
>> ## model matrix for new predictions
>> X <- model.matrix(fform_noresp,data=pframe)
>> ## fixed-effect parameters
>> beta <- fixef(m1)[["cond"]]
>> ## predictions (linear predictor scale)
>> pred0 <- X %*% beta
>> ## predictions (back-transformed)
>> pred <- exp(pred0)
>> ## standard errors of predictions (log scale)
>> pse <- sqrt(diag(X %*% crossprod(X,vcov(m1)[["cond"]])))
>> ## back-transformed confidence intervals
>> exp(qnorm(c(0.025,0.975),mean=pred0[1],sd=pse[1]))
>> exp(qnorm(c(0.025,0.975),mean=pred0[2],sd=pse[2]))
>>
>> Alternatively, you can use an experimental version that has the glue
>> needed for the effects package.
>>
>> devtools::install_github("glmmTMB/glmmTMB/glmmTMB",ref="effects")
>> library(glmmTMB)
>> source(system.file("other_methods","effectsglmmTMB.R",package="glmmTMB"))
>> allEffects(m1)
>>
>>
>>   Caveats:
>>
>>    - this will only work at present for families known to base-R
>> (poisson, gaussian, binomial, Gamma, etc.) - not for nbinom2 etc.
>>    - it makes lots of assumptions. In particular, for zero-inflated
>> models it ignores the zero-inflation part completely and gives
>> predictions etc etc only for the conditional model
>>
>>
>>
>>
>> On 17-10-24 09:16 AM, Juan Pablo Edwards Molina wrote:
>>> Dear glmmTMB authors & list members ,
>>>
>>> For glmer models I use "lsmeans" or "effects" package to report the
>>> coefficient estimated values, but any of them works with glmmTMB
>>> objetcs:
>>>
>>> lsmeans::lsmeans(mod, ~ factor, type = "response"); or
>>>
>>> effects::allEffects(mod)
>>>
>>> How would you suggest me to do that with an glmmTMB model?
>>>
>>> Here is a short example (with only two factor levels):
>>>
>>> library(glmmTMB)
>>> m1 <- glmmTMB(count~ mined + (1|site),
>>>                zi=~0,
>>>                family=poisson, data=Salamanders)
>>> summary(m1)
>>>
>>> m2 <- glmer(count ~ mined + (1|site), family=poisson, data=Salamanders)
>>> summary(m2)
>>>
>>> library(lsmeans)
>>> lsmeans(m2, ~ mined, type = "response")
>>>
>>> library(effects)
>>> eff.m2 <- allEffects(m2); as.data.frame(eff.m2[[1]])
>>>
>>> lsmeans(m1, ~ mined, type = "response")
>>> eff.m2 <- allEffects(m1); as.data.frame(eff.m1[[1]])
>>>
>>> Thanks in advance,
>>>
>>> Juan Edwards
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From edwardsmolina at gmail.com  Tue Oct 24 21:17:56 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Tue, 24 Oct 2017 17:17:56 -0200
Subject: [R-sig-ME] reporting model estimates values
In-Reply-To: <5c799216-a9d0-7da8-fcee-ef4474e3eea5@gmail.com>
References: <CAF5W3aRBq_zQ-a8DzzMR_d_-4qpqi-NAYbEouvSv7RJ4-ybYXQ@mail.gmail.com>
 <cbe35101-2e29-5813-f3e5-929cd448af2f@gmail.com>
 <CAF5W3aT8ECk+09JdtJhS=Fbmv5-0vnSfGUpPX_a--SKkLBu7nw@mail.gmail.com>
 <5c799216-a9d0-7da8-fcee-ef4474e3eea5@gmail.com>
Message-ID: <CAF5W3aS6pd--N4dXy3QvXOK0Bw+6TmwJFU=Jj=nmwOs21V+4yA@mail.gmail.com>

Thanks for your help prof. Bolker.
Best wishes,
Juan Edwards
Juan


On Tue, Oct 24, 2017 at 4:51 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>
>  (please keep r-sig-mixed-models in cc:)
>
>   Without investigating too closely I'm not sure what drives the
> difference.  effects could be using CIs based on t rather than Normal,
> but with 641 residual df (df.residual(m1)) that wouldn't make that big a
> difference.
>
>   Ben Bolker
>
>
> On 17-10-24 02:26 PM, Juan Pablo Edwards Molina wrote:
>> Thanks for your quick reply prof. Bolker and sorry for the misunderstanding.
>>
>>  Yes, I meant the predicted values with standard errors for each factor level.
>>
>> I tried both methods: predicted values and SE they present slight
>> differences in the CI values. I suppose it?s not a big deal...
>>
>> # Extended method
>>> pred
>>        [,1]
>> 1 2.1363277
>> 2 0.2219451
>>
>>> pse
>> [1] 0.2233638 0.1701403
>>
>>> exp(qnorm(c(0.025,0.975), mean=pred0[1],sd=pse[1]))
>> [1] 1.378924 3.309752
>>
>>> exp(qnorm(c(0.025,0.975), mean=pred0[2],sd=pse[2]))
>> [1] 0.1590091 0.3097914
>>
>> # Experimental version of effect package:
>>
>>> as.data.frame(allEffects(m1)[[1]])
>>     mined       fit             se     lower     upper
>> 1   yes 0.2219451 0.2230325 0.1433508 0.3436301
>> 2    no 2.1363277 0.1705744 1.5292366 2.9844276
>>
>> Thanks!
>>
>> Juan
>>
>>
>> On Tue, Oct 24, 2017 at 1:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>
>>>  Depends what you mean by estimated coefficient values.  You already
>>> have the summaries; I assume you mean you want predicted values with
>>> standard errors for each factor level?
>>>
>>>   You could do it like this: (this brute-force method will work for any
>>> model where you can extract the formula, fixed-effect parameters,
>>> variance-covariance matrix of fixed-effect parameters)
>>>
>>> ## set up prediction frame
>>> pframe <- with(Salamanders,
>>>                data.frame(mined=levels(mined)))
>>> ## get formula and keep only fixed effects
>>> fform <- lme4::nobars(formula(m1))
>>> ## drop LHS from formula
>>> fform_noresp <- fform[-2]
>>> ## model matrix for new predictions
>>> X <- model.matrix(fform_noresp,data=pframe)
>>> ## fixed-effect parameters
>>> beta <- fixef(m1)[["cond"]]
>>> ## predictions (linear predictor scale)
>>> pred0 <- X %*% beta
>>> ## predictions (back-transformed)
>>> pred <- exp(pred0)
>>> ## standard errors of predictions (log scale)
>>> pse <- sqrt(diag(X %*% crossprod(X,vcov(m1)[["cond"]])))
>>> ## back-transformed confidence intervals
>>> exp(qnorm(c(0.025,0.975),mean=pred0[1],sd=pse[1]))
>>> exp(qnorm(c(0.025,0.975),mean=pred0[2],sd=pse[2]))
>>>
>>> Alternatively, you can use an experimental version that has the glue
>>> needed for the effects package.
>>>
>>> devtools::install_github("glmmTMB/glmmTMB/glmmTMB",ref="effects")
>>> library(glmmTMB)
>>> source(system.file("other_methods","effectsglmmTMB.R",package="glmmTMB"))
>>> allEffects(m1)
>>>
>>>
>>>   Caveats:
>>>
>>>    - this will only work at present for families known to base-R
>>> (poisson, gaussian, binomial, Gamma, etc.) - not for nbinom2 etc.
>>>    - it makes lots of assumptions. In particular, for zero-inflated
>>> models it ignores the zero-inflation part completely and gives
>>> predictions etc etc only for the conditional model
>>>
>>>
>>>
>>>
>>> On 17-10-24 09:16 AM, Juan Pablo Edwards Molina wrote:
>>>> Dear glmmTMB authors & list members ,
>>>>
>>>> For glmer models I use "lsmeans" or "effects" package to report the
>>>> coefficient estimated values, but any of them works with glmmTMB
>>>> objetcs:
>>>>
>>>> lsmeans::lsmeans(mod, ~ factor, type = "response"); or
>>>>
>>>> effects::allEffects(mod)
>>>>
>>>> How would you suggest me to do that with an glmmTMB model?
>>>>
>>>> Here is a short example (with only two factor levels):
>>>>
>>>> library(glmmTMB)
>>>> m1 <- glmmTMB(count~ mined + (1|site),
>>>>                zi=~0,
>>>>                family=poisson, data=Salamanders)
>>>> summary(m1)
>>>>
>>>> m2 <- glmer(count ~ mined + (1|site), family=poisson, data=Salamanders)
>>>> summary(m2)
>>>>
>>>> library(lsmeans)
>>>> lsmeans(m2, ~ mined, type = "response")
>>>>
>>>> library(effects)
>>>> eff.m2 <- allEffects(m2); as.data.frame(eff.m2[[1]])
>>>>
>>>> lsmeans(m1, ~ mined, type = "response")
>>>> eff.m2 <- allEffects(m1); as.data.frame(eff.m1[[1]])
>>>>
>>>> Thanks in advance,
>>>>
>>>> Juan Edwards
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From orchidn at live.com  Tue Oct 24 21:49:50 2017
From: orchidn at live.com (dani)
Date: Tue, 24 Oct 2017 19:49:50 +0000
Subject: [R-sig-ME] compare two GAMM4 models using AICs
Message-ID: <MWHPR1201MB0029CE3D9C5EC1956640DB70D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,


I am fitting two gamm4 models because I would like to see whether there is justification for including a spline term for x1. Can this be done by comparing the AICs for the underlying mixed models (i.e., the "mer" part) of the two models?


b1 <- gamm4(y~x1+offset(e),data=dat,random=~(1|fac))

b2 <- gamm4(y~x1+s(x1)+offset(e),data=dat,random=~(1|fac))


summary(b1$gam)

summary(b1$mer)


summary(b2$gam)

summary(b2$mer)


AIC(b1$mer)

AIC(b2$mer)


Thank you very much!

Best,

DaniNM

<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Oct 24 22:10:01 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 24 Oct 2017 20:10:01 +0000
Subject: [R-sig-ME] reporting model estimates values
In-Reply-To: <6399_1508871136_v9OIqGPh017567_5c799216-a9d0-7da8-fcee-ef4474e3eea5@gmail.com>
References: <CAF5W3aRBq_zQ-a8DzzMR_d_-4qpqi-NAYbEouvSv7RJ4-ybYXQ@mail.gmail.com>
 <cbe35101-2e29-5813-f3e5-929cd448af2f@gmail.com>
 <CAF5W3aT8ECk+09JdtJhS=Fbmv5-0vnSfGUpPX_a--SKkLBu7nw@mail.gmail.com>
 <6399_1508871136_v9OIqGPh017567_5c799216-a9d0-7da8-fcee-ef4474e3eea5@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366ED7A7@FHSDB4H16-2.csu.mcmaster.ca>

Dear Ben and Juan,

Sorry to chime in late -- I was traveling when this thread started.

I'm not sure what Effect() method (the function in the effects package that does the computations) is getting invoked here -- probably the default method -- but in any event for a Poisson model it will use qnorm() not qt() to get confidence limits. I noticed that the effect estimates are identical (to the precision shown) but the standard errors of the effects are slightly different. I believe that's because Ben's computation of the SEs has removed the fixed-effect intercept, which is also subject to sampling variability and thus should figure in the SE of the "predicted" values.

Best,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Tuesday, October 24, 2017 2:52 PM
> To: Juan Pablo Edwards Molina <edwardsmolina at gmail.com>; r-sig-mixed-
> models at r-project.org
> Subject: Re: [R-sig-ME] reporting model estimates values
> 
> 
> 
>  (please keep r-sig-mixed-models in cc:)
> 
>   Without investigating too closely I'm not sure what drives the difference.
> effects could be using CIs based on t rather than Normal, but with 641 residual
> df (df.residual(m1)) that wouldn't make that big a difference.
> 
>   Ben Bolker
> 
> 
> On 17-10-24 02:26 PM, Juan Pablo Edwards Molina wrote:
> > Thanks for your quick reply prof. Bolker and sorry for the misunderstanding.
> >
> >  Yes, I meant the predicted values with standard errors for each factor level.
> >
> > I tried both methods: predicted values and SE they present slight
> > differences in the CI values. I suppose it?s not a big deal...
> >
> > # Extended method
> >> pred
> >        [,1]
> > 1 2.1363277
> > 2 0.2219451
> >
> >> pse
> > [1] 0.2233638 0.1701403
> >
> >> exp(qnorm(c(0.025,0.975), mean=pred0[1],sd=pse[1]))
> > [1] 1.378924 3.309752
> >
> >> exp(qnorm(c(0.025,0.975), mean=pred0[2],sd=pse[2]))
> > [1] 0.1590091 0.3097914
> >
> > # Experimental version of effect package:
> >
> >> as.data.frame(allEffects(m1)[[1]])
> >     mined       fit             se     lower     upper
> > 1   yes 0.2219451 0.2230325 0.1433508 0.3436301
> > 2    no 2.1363277 0.1705744 1.5292366 2.9844276
> >
> > Thanks!
> >
> > Juan
> >
> >
> > On Tue, Oct 24, 2017 at 1:12 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>
> >>  Depends what you mean by estimated coefficient values.  You already
> >> have the summaries; I assume you mean you want predicted values with
> >> standard errors for each factor level?
> >>
> >>   You could do it like this: (this brute-force method will work for
> >> any model where you can extract the formula, fixed-effect parameters,
> >> variance-covariance matrix of fixed-effect parameters)
> >>
> >> ## set up prediction frame
> >> pframe <- with(Salamanders,
> >>                data.frame(mined=levels(mined))) ## get formula and
> >> keep only fixed effects fform <- lme4::nobars(formula(m1)) ## drop
> >> LHS from formula fform_noresp <- fform[-2] ## model matrix for new
> >> predictions X <- model.matrix(fform_noresp,data=pframe)
> >> ## fixed-effect parameters
> >> beta <- fixef(m1)[["cond"]]
> >> ## predictions (linear predictor scale)
> >> pred0 <- X %*% beta
> >> ## predictions (back-transformed)
> >> pred <- exp(pred0)
> >> ## standard errors of predictions (log scale) pse <- sqrt(diag(X %*%
> >> crossprod(X,vcov(m1)[["cond"]]))) ## back-transformed confidence
> >> intervals
> >> exp(qnorm(c(0.025,0.975),mean=pred0[1],sd=pse[1]))
> >> exp(qnorm(c(0.025,0.975),mean=pred0[2],sd=pse[2]))
> >>
> >> Alternatively, you can use an experimental version that has the glue
> >> needed for the effects package.
> >>
> >> devtools::install_github("glmmTMB/glmmTMB/glmmTMB",ref="effects")
> >> library(glmmTMB)
> >>
> source(system.file("other_methods","effectsglmmTMB.R",package="glmmTM
> >> B"))
> >> allEffects(m1)
> >>
> >>
> >>   Caveats:
> >>
> >>    - this will only work at present for families known to base-R
> >> (poisson, gaussian, binomial, Gamma, etc.) - not for nbinom2 etc.
> >>    - it makes lots of assumptions. In particular, for zero-inflated
> >> models it ignores the zero-inflation part completely and gives
> >> predictions etc etc only for the conditional model
> >>
> >>
> >>
> >>
> >> On 17-10-24 09:16 AM, Juan Pablo Edwards Molina wrote:
> >>> Dear glmmTMB authors & list members ,
> >>>
> >>> For glmer models I use "lsmeans" or "effects" package to report the
> >>> coefficient estimated values, but any of them works with glmmTMB
> >>> objetcs:
> >>>
> >>> lsmeans::lsmeans(mod, ~ factor, type = "response"); or
> >>>
> >>> effects::allEffects(mod)
> >>>
> >>> How would you suggest me to do that with an glmmTMB model?
> >>>
> >>> Here is a short example (with only two factor levels):
> >>>
> >>> library(glmmTMB)
> >>> m1 <- glmmTMB(count~ mined + (1|site),
> >>>                zi=~0,
> >>>                family=poisson, data=Salamanders)
> >>> summary(m1)
> >>>
> >>> m2 <- glmer(count ~ mined + (1|site), family=poisson,
> >>> data=Salamanders)
> >>> summary(m2)
> >>>
> >>> library(lsmeans)
> >>> lsmeans(m2, ~ mined, type = "response")
> >>>
> >>> library(effects)
> >>> eff.m2 <- allEffects(m2); as.data.frame(eff.m2[[1]])
> >>>
> >>> lsmeans(m1, ~ mined, type = "response")
> >>> eff.m2 <- allEffects(m1); as.data.frame(eff.m1[[1]])
> >>>
> >>> Thanks in advance,
> >>>
> >>> Juan Edwards
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From orchidn at live.com  Tue Oct 24 22:13:53 2017
From: orchidn at live.com (dani)
Date: Tue, 24 Oct 2017 20:13:53 +0000
Subject: [R-sig-ME] broom package and MCMCglmm estimates
Message-ID: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi everyone,


I would like to visualize the estimates from a MCMC glmm model and I tried using broom but I received the following message:

Error in as.data.frame.default(mj) :
  cannot coerce class ""MCMCglmm"" to a data.frame
I was wondering what should I do about this?
Thank you in advance for all your help!
Best,
DaniNM

	[[alternative HTML version deleted]]


From pierre.de.villemereuil at mailoo.org  Tue Oct 24 22:47:13 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Wed, 25 Oct 2017 09:47:13 +1300
Subject: [R-sig-ME] broom package and MCMCglmm estimates
In-Reply-To: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <1916127.vipybtBhR9@vercors>

Hi,

As far as I can see, there is no method to tidy up MCMCglmm output in broom. You can see that by looking at the "tidiers" functions in broom using:
library(help = broom) #No MCMCglmm

However, MCMCglmm output contains "mcmc" class objects that can be tidied up using tidyMCMC():
- fixed effects: tidyMCMC(model$Sol)
- random effects: tidyMCMC(model$VCV)

Look up ?tidyMCMC for more options. I'm afraid it's difficult to get the pMCMC back though. You can get 95% credible intervals are a replacement for those (set conf.int = TRUE).

I have also seen that Ben Bolker is working on a fork/split of broom for mixed models especially, maybe he plans on having a specific tidier for MCMCglmm?

Best,
Pierre.


On Tuesday, 24 October 2017 20:13:53 NZDT dani wrote:
> Hi everyone,
> 
> 
> I would like to visualize the estimates from a MCMC glmm model and I tried using broom but I received the following message:
> 
> Error in as.data.frame.default(mj) :
>   cannot coerce class ""MCMCglmm"" to a data.frame
> I was wondering what should I do about this?
> Thank you in advance for all your help!
> Best,
> DaniNM
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From highstat at highstat.com  Tue Oct 24 23:00:15 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 24 Oct 2017 22:00:15 +0100
Subject: [R-sig-ME] compare two GAMM4 models using AICs
In-Reply-To: <8e21daf5-3027-1ecb-8b45-a55dea075874@highstat.com>
References: <mailman.3511.1508878054.1577.r-sig-mixed-models@r-project.org>
 <8e21daf5-3027-1ecb-8b45-a55dea075874@highstat.com>
Message-ID: <af638172-1da9-52b5-46f2-7d5bdaefaf41@highstat.com>



>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Tue, 24 Oct 2017 19:49:50 +0000
>> From: dani <orchidn at live.com>
>> To: "r-sig-mixed-models at r-project.org"
>> ????<r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] compare two GAMM4 models using AICs
>> Message-ID:
>> ????<MWHPR1201MB0029CE3D9C5EC1956640DB70D6470 at MWHPR1201MB0029.namprd12.prod.outlook.com> 
>>
>>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Hello everyone,
>>
>>
>> I am fitting two gamm4 models because I would like to see whether 
>> there is justification for including a spline term for x1. Can this 
>> be done by comparing the AICs for the underlying mixed models (i.e., 
>> the "mer" part) of the two models?
>
>

Technically it won't crash..."so it can be done"..but I am not sure 
whether you want to do this. Internally, the smoother is written as a 
mixed model (X * b + Z * u)....and those random effects (which is part 
of the smoother) don't count towards the number of parameters.

>> b1 <- gamm4(y~x1+offset(e),data=dat,random=~(1|fac))
>
>> b2 <- gamm4(y~x1+s(x1)+offset(e),data=dat,random=~(1|fac))
>
>
>


I am confused about your use of an offset in a Gaussian model, and I am 
confused why you would use x1 and s(x1) in the same model. The s(x1) 
already contains the linear part of the smoother.

Why not fit the first model and inspect residuals for any patterns? If 
there are, then using a smoother is an option.

Kind regards,

Alain Zuur


>
>>
>> summary(b1$gam)
>>
>> summary(b1$mer)
>>
>>
>> summary(b2$gam)
>>
>> summary(b2$mer)
>>
>>
>> AIC(b1$mer)
>>
>> AIC(b2$mer)
>>
>>
>> Thank you very much!
>>
>> Best,
>>
>> DaniNM
>>
>> <http://aka.ms/weboutlook>
>>
>> ????[[alternative HTML version deleted]]
>>
>>
>

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From orchidn at live.com  Tue Oct 24 23:54:28 2017
From: orchidn at live.com (dani)
Date: Tue, 24 Oct 2017 21:54:28 +0000
Subject: [R-sig-ME] compare two GAMM4 models using AICs
In-Reply-To: <af638172-1da9-52b5-46f2-7d5bdaefaf41@highstat.com>
References: <mailman.3511.1508878054.1577.r-sig-mixed-models@r-project.org>
 <8e21daf5-3027-1ecb-8b45-a55dea075874@highstat.com>,
 <af638172-1da9-52b5-46f2-7d5bdaefaf41@highstat.com>
Message-ID: <MWHPR1201MB00297C3CD019542A15A9EFCAD6470@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,


Dr Zuur, thank you so much for your answer.

First, I made a mistake and I forgot to specify that it was a Poisson model with an offset term.


I asked my question because I saw this: http://qcbs.ca/wiki/r_workshop8:


"How do we test whether the non-linear model offers a significant improvement over the linear model? We can use the gam() and anova() commands to formally test whether an assumption of linearity is justified. To do, we must simply set our smoothed model so that it is nested in our linear model; that is, we create model object that includes both x (linear) and s(x) (non-linear) and we ask whether adding s(x) to the model with only x as a covariate is supported by the data."

|" Test for linearity<http://qcbs.ca/wiki/_export/code/r_workshop8?codeblock=4>

linear_model = gam(y_obs~x)
nested_gam_model = gam(y_obs~s(x)+x)
print<http://stat.ethz.ch/R-manual/R-devel/library/base/html/print.html>(anova<http://stat.ethz.ch/R-manual/R-devel/library/stats/html/anova.html>(linear_model, nested_gam_model, test="Chisq"))"

Given that in their case it was a GAM model, I was not sure how to do something similar in a gamm4 context. I searched online but I could not find an answer.


My model looks like this:

mg = gamm4(y ~ s(age)+offset(expy), random=~(1|g)+(1|s), data=s25h, family= poisson)


summary(mg$gam)

Family: poisson
Link function: log

Formula:
y ~ s(age) + offset(expy)

Parametric coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -7.3922     0.1065  -69.41   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
            edf Ref.df    Chi.sq p-value
s(age)   1      1         0.13   0.719

R-sq.(adj) =  -8.44e-05
glmer.ML = 2075.4  Scale est. = 1         n = 10523

summary(mg$mer)

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: poisson  ( log )

     AIC      BIC   logLik deviance df.resid
  5294.9   5331.2  -2642.4   5284.9    10518

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8449 -0.0806 -0.0786 -0.0775  4.9384

Random effects:
 Groups  Name        Variance Std.Dev.
 g  (Intercept) 2.868    1.694
 s (Intercept) 3.820    1.954
 Xr      s(age) 0.000    0.000
Number of obs: 10523, groups:  g, 1785; s, 1768; Xr, 8

Fixed effects:
                Estimate Std. Error z value Pr(>|z|)
X(Intercept)    -7.39218    0.19834  -37.27   <2e-16 ***
Xs(age)Fx1  0.03669    0.08418    0.44    0.663
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            X(Int)
Xs(age)F1 0.024


Is this the right way to interpret it:

1) from the gam part I would conclude that the spline for the variable age has an estimated degree of freedom of 1, indicating that I might not need a spline. However, I understood that one can have a edf of 1 and there might still be a need for including a spline in the model (this part is very ambiguous for me, as I would think this alone should be indicative of a linear association). Either way, the spline term is not significantly associated with my outcome.

2) from the mer part I would conclude that the linear part of the variable age is not associated with my outcome, either.

Based on this model, I can safely assume that age can be included in my regression model as a linear term, given there is nothing to suggest the association with my outcome is non-parametrical.

I would then check the residuals, as you suggested, and if there is not any pattern, I should be ok without including a spline then.

Does this sound like a reasonable explanation for not including a spline term in my regression model?

Thank you so much. I apologize for these silly questions. I am just trying to assimilate way too much at once and I second guess everything I do since these are all difficult concepts to grasp for a beginner.

Best,
DaniNM



________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Highland Statistics Ltd <highstat at highstat.com>
Sent: Tuesday, October 24, 2017 2:00 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] compare two GAMM4 models using AICs



>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Tue, 24 Oct 2017 19:49:50 +0000
>> From: dani <orchidn at live.com>
>> To: "r-sig-mixed-models at r-project.org"
>>     <r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] compare two GAMM4 models using AICs
>> Message-ID:
>>     <MWHPR1201MB0029CE3D9C5EC1956640DB70D6470 at MWHPR1201MB0029.namprd12.prod.outlook.com>
>>
>>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Hello everyone,
>>
>>
>> I am fitting two gamm4 models because I would like to see whether
>> there is justification for including a spline term for x1. Can this
>> be done by comparing the AICs for the underlying mixed models (i.e.,
>> the "mer" part) of the two models?
>
>

Technically it won't crash..."so it can be done"..but I am not sure
whether you want to do this. Internally, the smoother is written as a
mixed model (X * b + Z * u)....and those random effects (which is part
of the smoother) don't count towards the number of parameters.

>> b1 <- gamm4(y~x1+offset(e),data=dat,random=~(1|fac))
>
>> b2 <- gamm4(y~x1+s(x1)+offset(e),data=dat,random=~(1|fac))
>
>
>


I am confused about your use of an offset in a Gaussian model, and I am
confused why you would use x1 and s(x1) in the same model. The s(x1)
already contains the linear part of the smoother.

Why not fit the first model and inspect residuals for any patterns? If
there are, then using a smoother is an option.

Kind regards,

Alain Zuur


>
>>
>> summary(b1$gam)
>>
>> summary(b1$mer)
>>
>>
>> summary(b2$gam)
>>
>> summary(b2$mer)
>>
>>
>> AIC(b1$mer)
>>
>> AIC(b2$mer)
>>
>>
>> Thank you very much!
>>
>> Best,
>>
>> DaniNM
>>
>> <http://aka.ms/weboutlook>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>

--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com<http://www.highstat.com>
Highland Statistics Ltd.<http://www.highstat.com/>
www.highstat.com
Statistical consultancy, data analysis and software development. Specialized in time series analysis. Located in Scotland.




And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



	[[alternative HTML version deleted]]


From orchidn at live.com  Tue Oct 24 23:56:49 2017
From: orchidn at live.com (dani)
Date: Tue, 24 Oct 2017 21:56:49 +0000
Subject: [R-sig-ME] broom package and MCMCglmm estimates
In-Reply-To: <1916127.vipybtBhR9@vercors>
References: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <1916127.vipybtBhR9@vercors>
Message-ID: <MWHPR1201MB0029966B0FF097AE0BE3FA73D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Pierre,


Thank you so much for your prompt response, I will follow your advice and report back.


best,

daniNm

________________________________
From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
Sent: Tuesday, October 24, 2017 1:47 PM
To: r-sig-mixed-models at r-project.org
Cc: dani
Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates

Hi,

As far as I can see, there is no method to tidy up MCMCglmm output in broom. You can see that by looking at the "tidiers" functions in broom using:
library(help = broom) #No MCMCglmm

However, MCMCglmm output contains "mcmc" class objects that can be tidied up using tidyMCMC():
- fixed effects: tidyMCMC(model$Sol)
- random effects: tidyMCMC(model$VCV)

Look up ?tidyMCMC for more options. I'm afraid it's difficult to get the pMCMC back though. You can get 95% credible intervals are a replacement for those (set conf.int = TRUE).

I have also seen that Ben Bolker is working on a fork/split of broom for mixed models especially, maybe he plans on having a specific tidier for MCMCglmm?

Best,
Pierre.


On Tuesday, 24 October 2017 20:13:53 NZDT dani wrote:
> Hi everyone,
>
>
> I would like to visualize the estimates from a MCMC glmm model and I tried using broom but I received the following message:
>
> Error in as.data.frame.default(mj) :
>   cannot coerce class ""MCMCglmm"" to a data.frame
> I was wondering what should I do about this?
> Thank you in advance for all your help!
> Best,
> DaniNM
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Oct 25 00:04:54 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Oct 2017 18:04:54 -0400
Subject: [R-sig-ME] broom package and MCMCglmm estimates
In-Reply-To: <MWHPR1201MB0029966B0FF097AE0BE3FA73D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1916127.vipybtBhR9@vercors>
 <MWHPR1201MB0029966B0FF097AE0BE3FA73D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <3feed415-5bc9-000a-e090-6e72c4bd6678@gmail.com>


  There is an MCMCglmm method in my fork of broom :

devtools::install_github("bbolker/broom")
library(broom)
library(MCMCglmm)
data(PlodiaPO)
model1 <- MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO,
  verbose=FALSE,  nitt=1300, burnin=300, thin=1)
tidy(model1)
##   effect        term estimate  std.error
## 1  fixed (Intercept) 1.162818 0.01656339

  I make no claims as to its completeness, but am happy to accept issues
or pull requests.  Eventually the stuff in my fork will get migrated to
a separate "broom.mixed" (or some such) package.



On 17-10-24 05:56 PM, dani wrote:
> Hello Pierre,
> 
> 
> Thank you so much for your prompt response, I will follow your advice and report back.
> 
> 
> best,
> 
> daniNm
> 
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Tuesday, October 24, 2017 1:47 PM
> To: r-sig-mixed-models at r-project.org
> Cc: dani
> Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates
> 
> Hi,
> 
> As far as I can see, there is no method to tidy up MCMCglmm output in broom. You can see that by looking at the "tidiers" functions in broom using:
> library(help = broom) #No MCMCglmm
> 
> However, MCMCglmm output contains "mcmc" class objects that can be tidied up using tidyMCMC():
> - fixed effects: tidyMCMC(model$Sol)
> - random effects: tidyMCMC(model$VCV)
> 
> Look up ?tidyMCMC for more options. I'm afraid it's difficult to get the pMCMC back though. You can get 95% credible intervals are a replacement for those (set conf.int = TRUE).
> 
> I have also seen that Ben Bolker is working on a fork/split of broom for mixed models especially, maybe he plans on having a specific tidier for MCMCglmm?
> 
> Best,
> Pierre.
> 
> 
> On Tuesday, 24 October 2017 20:13:53 NZDT dani wrote:
>> Hi everyone,
>>
>>
>> I would like to visualize the estimates from a MCMC glmm model and I tried using broom but I received the following message:
>>
>> Error in as.data.frame.default(mj) :
>>   cannot coerce class ""MCMCglmm"" to a data.frame
>> I was wondering what should I do about this?
>> Thank you in advance for all your help!
>> Best,
>> DaniNM
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
> 
> 
> 
>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From orchidn at live.com  Wed Oct 25 00:42:31 2017
From: orchidn at live.com (dani)
Date: Tue, 24 Oct 2017 22:42:31 +0000
Subject: [R-sig-ME] broom package and MCMCglmm estimates
In-Reply-To: <3feed415-5bc9-000a-e090-6e72c4bd6678@gmail.com>
References: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1916127.vipybtBhR9@vercors>
 <MWHPR1201MB0029966B0FF097AE0BE3FA73D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <3feed415-5bc9-000a-e090-6e72c4bd6678@gmail.com>
Message-ID: <MWHPR1201MB0029899432C8EE0A6DEDF815D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


That is fantastic, thank you so much, Dr Bolker!

I had tried earlier today and I got the same error message several times. I tried again after I received your message and I got several other error messages - one of them saying that the broom.rdb was corrupt, so I guess I might have messed up somehow because I was trying different things and I installing many packages. I removed them all and re- installed "broom" as you suggested and it worked nicely for a glmmTMB model as well as for a MCMC model. Now I hope everything goes nicely to visualize them.


I appreciate all your help and all your work in the field and in making everything easier to understand!

This is truly wonderful and I cannot emphasize more how great this mailing list is for me!

Best regards everyone!

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Tuesday, October 24, 2017 3:04 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates


  There is an MCMCglmm method in my fork of broom :

devtools::install_github("bbolker/broom")
library(broom)
library(MCMCglmm)
data(PlodiaPO)
model1 <- MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO,
  verbose=FALSE,  nitt=1300, burnin=300, thin=1)
tidy(model1)
##   effect        term estimate  std.error
## 1  fixed (Intercept) 1.162818 0.01656339

  I make no claims as to its completeness, but am happy to accept issues
or pull requests.  Eventually the stuff in my fork will get migrated to
a separate "broom.mixed" (or some such) package.



On 17-10-24 05:56 PM, dani wrote:
> Hello Pierre,
>
>
> Thank you so much for your prompt response, I will follow your advice and report back.
>
>
> best,
>
> daniNm
>
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Tuesday, October 24, 2017 1:47 PM
> To: r-sig-mixed-models at r-project.org
> Cc: dani
> Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates
>
> Hi,
>
> As far as I can see, there is no method to tidy up MCMCglmm output in broom. You can see that by looking at the "tidiers" functions in broom using:
> library(help = broom) #No MCMCglmm
>
> However, MCMCglmm output contains "mcmc" class objects that can be tidied up using tidyMCMC():
> - fixed effects: tidyMCMC(model$Sol)
> - random effects: tidyMCMC(model$VCV)
>
> Look up ?tidyMCMC for more options. I'm afraid it's difficult to get the pMCMC back though. You can get 95% credible intervals are a replacement for those (set conf.int = TRUE).
>
> I have also seen that Ben Bolker is working on a fork/split of broom for mixed models especially, maybe he plans on having a specific tidier for MCMCglmm?
>
> Best,
> Pierre.
>
>
> On Tuesday, 24 October 2017 20:13:53 NZDT dani wrote:
>> Hi everyone,
>>
>>
>> I would like to visualize the estimates from a MCMC glmm model and I tried using broom but I received the following message:
>>
>> Error in as.data.frame.default(mj) :
>>   cannot coerce class ""MCMCglmm"" to a data.frame
>> I was wondering what should I do about this?
>> Thank you in advance for all your help!
>> Best,
>> DaniNM
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From andreu.blanco at gmail.com  Wed Oct 25 16:31:37 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Wed, 25 Oct 2017 16:31:37 +0200
Subject: [R-sig-ME] Residual Variance or Dispersion of Gamma GLMER
Message-ID: <CAOy7hbDCNH2WPezF98nhpGs_nnHDs5qnSXHTvak7qTV7h5LiTw@mail.gmail.com>

Hi,
I am trying to fit a Hurdle model using glmer, however in order to
calculate the variance of the Hurdle model I need to know the dispersion of
the gamma ZAG, which I cannot find from the summary of my model:
> summary(H1)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: Gamma  ( log )
Formula: Biomass ~ Protection * Exposure + (1 | Location)
   Data: Aarmata.pos

     AIC      BIC   logLik deviance df.resid
   644.9    657.5   -316.4    632.9       55

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.2278 -0.7188 -0.1149  0.3721  3.4934

Random effects:
 Groups   Name        Variance Std.Dev.
 Location (Intercept) 0.5489   0.7409
 Residual             0.6531   0.8082
Number of obs: 61, groups:  Location, 8

Fixed effects:
                                        Estimate Std. Error t value
Pr(>|z|)
(Intercept)                               4.1195     0.4866   8.466
 <2e-16 ***
ProtectionProtected                       0.2202     0.6940   0.317
 0.7510
ExposureSemiexposed                      -0.6357     0.3319  -1.915
 0.0555 .
ProtectionProtected:ExposureSemiexposed  -0.7128     0.5492  -1.298
 0.1944
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) PrtctP ExpsrS
PrtctnPrtct -0.701
ExpsrSmxpsd -0.212  0.143
PrtctnPr:ES  0.131 -0.242 -0.562

-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From orchidn at live.com  Wed Oct 25 18:16:29 2017
From: orchidn at live.com (dani)
Date: Wed, 25 Oct 2017 16:16:29 +0000
Subject: [R-sig-ME] broom package and MCMCglmm estimates
In-Reply-To: <B01AC742-2924-4C95-BA82-950748F447BA@sms.ed.ac.uk>
References: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1916127.vipybtBhR9@vercors>
 <MWHPR1201MB0029966B0FF097AE0BE3FA73D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <3feed415-5bc9-000a-e090-6e72c4bd6678@gmail.com>
 <MWHPR1201MB0029899432C8EE0A6DEDF815D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <B01AC742-2924-4C95-BA82-950748F447BA@sms.ed.ac.uk>
Message-ID: <MWHPR1201MB0029693AE3F44CDC8AFBE9EDD6440@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi Gabriela,

Thank you so much, this is very helpful!

Broom works wonderfully, but I will give your function a try, it looks very interesting!

Best,

Dani

________________________________
From: HAJDUK Gabriela <G.K.Hajduk at ed.ac.uk>
Sent: Wednesday, October 25, 2017 5:27 AM
To: dani
Cc: Ben Bolker; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates

Hello Dani,

Looks like Ben?s version of broom solves your problem (I haven?t used it, but looks like it does the trick beautifully!), but in case it?s any use (e.g. if you wanted to tweak anything for yourself to adjust the output) I?ve popped a function that I?ve wrote ages ago to pull out information from multiple MCMCglmm model objects for summary/plotting purposes.

You can find the code here:
https://gkhajduk.github.io/2017-10-25-cleanMCMCglmm/
Cleaning MCMCglmm model outputs<https://gkhajduk.github.io/2017-10-25-cleanMCMCglmm/>
gkhajduk.github.io



Cheers,
Gabriela


On 24 Oct 2017, at 23:42, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:

Hello again,


That is fantastic, thank you so much, Dr Bolker!

I had tried earlier today and I got the same error message several times. I tried again after I received your message and I got several other error messages - one of them saying that the broom.rdb was corrupt, so I guess I might have messed up somehow because I was trying different things and I installing many packages. I removed them all and re- installed "broom" as you suggested and it worked nicely for a glmmTMB model as well as for a MCMC model. Now I hope everything goes nicely to visualize them.


I appreciate all your help and all your work in the field and in making everything easier to understand!

This is truly wonderful and I cannot emphasize more how great this mailing list is for me!

Best regards everyone!

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Sent: Tuesday, October 24, 2017 3:04 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates


 There is an MCMCglmm method in my fork of broom :

devtools::install_github("bbolker/broom")
library(broom)
library(MCMCglmm)
data(PlodiaPO)
model1 <- MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO,
 verbose=FALSE,  nitt=1300, burnin=300, thin=1)
tidy(model1)
##   effect        term estimate  std.error
## 1  fixed (Intercept) 1.162818 0.01656339

 I make no claims as to its completeness, but am happy to accept issues
or pull requests.  Eventually the stuff in my fork will get migrated to
a separate "broom.mixed" (or some such) package.



On 17-10-24 05:56 PM, dani wrote:
Hello Pierre,


Thank you so much for your prompt response, I will follow your advice and report back.


best,

daniNm

________________________________
From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org<mailto:pierre.de.villemereuil at mailoo.org>>
Sent: Tuesday, October 24, 2017 1:47 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Cc: dani
Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates

Hi,

As far as I can see, there is no method to tidy up MCMCglmm output in broom. You can see that by looking at the "tidiers" functions in broom using:
library(help = broom) #No MCMCglmm

However, MCMCglmm output contains "mcmc" class objects that can be tidied up using tidyMCMC():
- fixed effects: tidyMCMC(model$Sol)
- random effects: tidyMCMC(model$VCV)

Look up ?tidyMCMC for more options. I'm afraid it's difficult to get the pMCMC back though. You can get 95% credible intervals are a replacement for those (set conf.int = TRUE).

I have also seen that Ben Bolker is working on a fork/split of broom for mixed models especially, maybe he plans on having a specific tidier for MCMCglmm?

Best,
Pierre.


On Tuesday, 24 October 2017 20:13:53 NZDT dani wrote:
Hi everyone,


I would like to visualize the estimates from a MCMC glmm model and I tried using broom but I received the following message:

Error in as.data.frame.default(mj) :
 cannot coerce class ""MCMCglmm"" to a data.frame
I was wondering what should I do about this?
Thank you in advance for all your help!
Best,
DaniNM

      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<http://stat.ethz.ch><https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch<http://stat.ethz.ch>
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...






      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Oct 25 18:18:05 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 25 Oct 2017 17:18:05 +0100
Subject: [R-sig-ME] Residual Variance or Dispersion of Gamma GLMER
Message-ID: <bb266f5a-c25d-adb3-5b29-d45415268257@highstat.com>


Using glmmTMB, it is:

r? <- 1 / (summary(M1)$sigma^2)

I guess it is the same in lme4. Note that this is the r as in:

var(Y) = mu^2 / r


Alain



-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From highstat at highstat.com  Wed Oct 25 19:59:21 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 25 Oct 2017 18:59:21 +0100
Subject: [R-sig-ME] compare two GAMM4 models using AICs
In-Reply-To: <MWHPR1201MB00297C3CD019542A15A9EFCAD6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <mailman.3511.1508878054.1577.r-sig-mixed-models@r-project.org>
 <8e21daf5-3027-1ecb-8b45-a55dea075874@highstat.com>
 <af638172-1da9-52b5-46f2-7d5bdaefaf41@highstat.com>
 <MWHPR1201MB00297C3CD019542A15A9EFCAD6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <1372d182-7dc7-5f24-c0b6-a22e075ca48e@highstat.com>

**
>
> Family: poisson
> Link function: log
>
> Formula:
> y ~ s(age) + offset(expy)
>
> Parametric coefficients:
> ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept)? -7.3922? ? ?0.1065? -69.41 ?<2e-16 ***
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
> ? ? ? ? ? ? edf Ref.df? ? Chi.sq p-value
> s(age)? ?1? ? ? 1? ? ? ? ?0.13? ?0.719
>
> R-sq.(adj) =? -8.44e-05
> glmer.ML = 2075.4? Scale est. = 1? ? ? ? ?n = 10523
>
> *summary(mg$mer)*
>
> Generalized linear mixed model fit by maximum likelihood (Laplace 
> Approximation) ['glmerMod']
> ?Family: poisson? ( log )
>
> ? ? ?AIC? ? ? BIC? ?logLik deviance df.resid
> ? 5294.9? ?5331.2? -2642.4? ?5284.9? ? 10518
>
> Scaled residuals:
> ? ? Min? ? ? 1Q? Median? ? ? 3Q? ? ?Max
> -1.8449 -0.0806 -0.0786 -0.0775? 4.9384
>
> Random effects:
> ?Groups? Name? ? ? ? Variance Std.Dev.
> ?g? (Intercept) 2.868? ? 1.694
> ?s (Intercept) 3.820? ? 1.954
> ?Xr? ? ? s(age) 0.000? ? 0.000
> Number of obs: 10523, groups:? g, 1785; s, 1768; Xr, 8
>
> Fixed effects:
> ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> X(Intercept)? ? -7.39218? ? 0.19834? -37.27 ?<2e-16 ***
> Xs(age)Fx1? 0.03669? ? 0.08418? ? 0.44? ? 0.663
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ? X(Int)
> Xs(age)F1 0.024
>
> *
> *
> *Is this the right way to interpret it:*
> *
> *
> *1) from the gam part *I would conclude that the spline for the 
> variable age has an estimated degree of freedom of 1, indicating that 
> I might not need a spline.
Indeed. And you won't need the covariate Age as a parametric term neither.


> *
> *
> *2) from the mer part *I would conclude that the linear part of 
> the?variable age is not associated with my outcome, either.
There is no need to look at the smoother info in the mer part.
>
> Based on this model, I can safely assume that age can be included in 
> my regression model as a linear term, given there is nothing to 
> suggest the association with my?outcome is non-parametrical.

Keep in mind that you are using a log link function, which means that 
the effect of age on your response variable is actually exponential 
(would it have been significant).


Alain

>
> I would then check the residuals, as you suggested, and if there is 
> not any pattern, I should be ok without including a spline then.
>
> Does this sound like a reasonable explanation for not including a 
> spline term in my regression model?
>
> Thank you so much. I apologize for these silly questions. I am just 
> trying to assimilate way too much at once and I second guess 
> everything I do since these are all difficult concepts to grasp for a 
> beginner.
>
> Best,
> DaniNM
>
> _
>
> _
> _
> ------------------------------------------------------------------------
> _
> _*From:* R-sig-mixed-models 
> <r-si_g-mixed-models-bounces at r-project.org> on behalf of Highland 
> Statistics Ltd <highstat at highstat.com>
> *Sent:* Tuesday, October 24, 2017 2:00 PM
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] compare two GAMM4 models using AICs
>
>
> >> ----------------------------------------------------------------------
> >>
> >> Message: 1
> >> Date: Tue, 24 Oct 2017 19:49:50 +0000
> >> From: dani <orchidn at live.com>
> >> To: "r-sig-mixed-models at r-project.org"
> >> ????<r-sig-mixed-models at r-project.org>
> >> Subject: [R-sig-ME] compare two GAMM4 models using AICs
> >> Message-ID:
> >> 
> ????<MWHPR1201MB0029CE3D9C5EC1956640DB70D6470 at MWHPR1201MB0029.namprd12.prod.outlook.com>
> >>
> >>
> >> Content-Type: text/plain; charset="UTF-8"
> >>
> >> Hello everyone,
> >>
> >>
> >> I am fitting two gamm4 models because I would like to see whether
> >> there is justification for including a spline term for x1. Can this
> >> be done by comparing the AICs for the underlying mixed models (i.e.,
> >> the "mer" part) of the two models?
> >
> >
>
> Technically it won't crash..."so it can be done"..but I am not sure
> whether you want to do this. Internally, the smoother is written as a
> mixed model (X * b + Z * u)....and those random effects (which is part
> of the smoother) don't count towards the number of parameters.
>
> >> b1 <- gamm4(y~x1+offset(e),data=dat,random=~(1|fac))
> >
> >> b2 <- gamm4(y~x1+s(x1)+offset(e),data=dat,random=~(1|fac))
> >
> >
> >
>
>
> I am confused about your use of an offset in a Gaussian model, and I am
> confused why you would use x1 and s(x1) in the same model. The s(x1)
> already contains the linear part of the smoother.
>
> Why not fit the first model and inspect residuals for any patterns? If
> there are, then using a smoother is an option.
>
> Kind regards,
>
> Alain Zuur
>
>
> >
> >>
> >> summary(b1$gam)
> >>
> >> summary(b1$mer)
> >>
> >>
> >> summary(b2$gam)
> >>
> >> summary(b2$mer)
> >>
> >>
> >> AIC(b1$mer)
> >>
> >> AIC(b2$mer)
> >>
> >>
> >> Thank you very much!
> >>
> >> Best,
> >>
> >> DaniNM
> >>
> >> <http://aka.ms/weboutlook>
> >>
> >> ????[[alternative HTML version deleted]]
> >>
> >>
> >
>
> -- 
>
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email: highstat at highstat.com
> URL: www.highstat.com <http://www.highstat.com>
> Highland Statistics Ltd. <http://www.highstat.com/>
> www.highstat.com
> Statistical consultancy, data analysis and software development. 
> Specialized in time series analysis. Located in Scotland.
>
>
>
>
> And:
> NIOZ Royal Netherlands Institute for Sea Research,
> Department of Coastal Systems, and Utrecht University,
> P.O. Box 59, 1790 AB Den Burg,
> Texel, The Netherlands
>
>
>
> Author of:
> 1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal 
> Ecological Data Analysis with R-INLA. (2017).
> 2. Beginner's Guide to Zero-Inflated Models with R (2016).
> 3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
> 4. Beginner's Guide to GAMM with R (2014).
> 5. Beginner's Guide to GLM and GLMM with R (2013).
> 6. Beginner's Guide to GAM with R (2012).
> 7. Zero Inflated Models and GLMM with R (2012).
> 8. A Beginner's Guide to R (2009).
> 9. Mixed effects models and extensions in ecology with R (2009).
> 10. Analysing Ecological Data (2007).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
>
>

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


	[[alternative HTML version deleted]]


From orchidn at live.com  Wed Oct 25 20:10:53 2017
From: orchidn at live.com (dani)
Date: Wed, 25 Oct 2017 18:10:53 +0000
Subject: [R-sig-ME] compare two GAMM4 models using AICs
In-Reply-To: <1372d182-7dc7-5f24-c0b6-a22e075ca48e@highstat.com>
References: <mailman.3511.1508878054.1577.r-sig-mixed-models@r-project.org>
 <8e21daf5-3027-1ecb-8b45-a55dea075874@highstat.com>
 <af638172-1da9-52b5-46f2-7d5bdaefaf41@highstat.com>
 <MWHPR1201MB00297C3CD019542A15A9EFCAD6470@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <1372d182-7dc7-5f24-c0b6-a22e075ca48e@highstat.com>
Message-ID: <MWHPR1201MB0029F3EA43178F45DE3E8A36D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Dr. Zuur,

Thank you so much, this is so helpful!

Best,

Dani NM

________________________________
From: Highland Statistics Ltd <highstat at highstat.com>
Sent: Wednesday, October 25, 2017 10:59 AM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] compare two GAMM4 models using AICs


Family: poisson
Link function: log

Formula:
y ~ s(age) + offset(expy)

Parametric coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -7.3922     0.1065  -69.41   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
            edf Ref.df    Chi.sq p-value
s(age)   1      1         0.13   0.719

R-sq.(adj) =  -8.44e-05
glmer.ML = 2075.4  Scale est. = 1         n = 10523

summary(mg$mer)

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: poisson  ( log )

     AIC      BIC   logLik deviance df.resid
  5294.9   5331.2  -2642.4   5284.9    10518

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8449 -0.0806 -0.0786 -0.0775  4.9384

Random effects:
 Groups  Name        Variance Std.Dev.
 g  (Intercept) 2.868    1.694
 s (Intercept) 3.820    1.954
 Xr      s(age) 0.000    0.000
Number of obs: 10523, groups:  g, 1785; s, 1768; Xr, 8

Fixed effects:
                Estimate Std. Error z value Pr(>|z|)
X(Intercept)    -7.39218    0.19834  -37.27   <2e-16 ***
Xs(age)Fx1  0.03669    0.08418    0.44    0.663
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            X(Int)
Xs(age)F1 0.024


Is this the right way to interpret it:

1) from the gam part I would conclude that the spline for the variable age has an estimated degree of freedom of 1, indicating that I might not need a spline.
Indeed. And you won't need the covariate Age as a parametric term neither.



2) from the mer part I would conclude that the linear part of the variable age is not associated with my outcome, either.
There is no need to look at the smoother info in the mer part.

Based on this model, I can safely assume that age can be included in my regression model as a linear term, given there is nothing to suggest the association with my outcome is non-parametrical.

Keep in mind that you are using a log link function, which means that the effect of age on your response variable is actually exponential (would it have been significant).


Alain


I would then check the residuals, as you suggested, and if there is not any pattern, I should be ok without including a spline then.

Does this sound like a reasonable explanation for not including a spline term in my regression model?

Thank you so much. I apologize for these silly questions. I am just trying to assimilate way too much at once and I second guess everything I do since these are all difficult concepts to grasp for a beginner.

Best,
DaniNM



________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:g-mixed-models-bounces at r-project.org>> on behalf of Highland Statistics Ltd <highstat at highstat.com><mailto:highstat at highstat.com>
Sent: Tuesday, October 24, 2017 2:00 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] compare two GAMM4 models using AICs



>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Tue, 24 Oct 2017 19:49:50 +0000
>> From: dani <orchidn at live.com><mailto:orchidn at live.com>
>> To: "r-sig-mixed-models at r-project.org"<mailto:r-sig-mixed-models at r-project.org>
>>     <r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] compare two GAMM4 models using AICs
>> Message-ID:
>>     <MWHPR1201MB0029CE3D9C5EC1956640DB70D6470 at MWHPR1201MB0029.namprd12.prod.outlook.com><mailto:MWHPR1201MB0029CE3D9C5EC1956640DB70D6470 at MWHPR1201MB0029.namprd12.prod.outlook.com>
>>
>>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Hello everyone,
>>
>>
>> I am fitting two gamm4 models because I would like to see whether
>> there is justification for including a spline term for x1. Can this
>> be done by comparing the AICs for the underlying mixed models (i.e.,
>> the "mer" part) of the two models?
>
>

Technically it won't crash..."so it can be done"..but I am not sure
whether you want to do this. Internally, the smoother is written as a
mixed model (X * b + Z * u)....and those random effects (which is part
of the smoother) don't count towards the number of parameters.

>> b1 <- gamm4(y~x1+offset(e),data=dat,random=~(1|fac))
>
>> b2 <- gamm4(y~x1+s(x1)+offset(e),data=dat,random=~(1|fac))
>
>
>


I am confused about your use of an offset in a Gaussian model, and I am
confused why you would use x1 and s(x1) in the same model. The s(x1)
already contains the linear part of the smoother.

Why not fit the first model and inspect residuals for any patterns? If
there are, then using a smoother is an option.

Kind regards,

Alain Zuur


>
>>
>> summary(b1$gam)
>>
>> summary(b1$mer)
>>
>>
>> summary(b2$gam)
>>
>> summary(b2$mer)
>>
>>
>> AIC(b1$mer)
>>
>> AIC(b2$mer)
>>
>>
>> Thank you very much!
>>
>> Best,
>>
>> DaniNM
>>
>> <http://aka.ms/weboutlook>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>

--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com<mailto:highstat at highstat.com>
URL:   www.highstat.com<http://www.highstat.com>
Highland Statistics Ltd.<http://www.highstat.com/>
www.highstat.com<http://www.highstat.com>
Statistical consultancy, data analysis and software development. Specialized in time series analysis. Located in Scotland.




And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...




--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com<mailto:highstat at highstat.com>
URL:   www.highstat.com<http://www.highstat.com>

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).



	[[alternative HTML version deleted]]


From orchidn at live.com  Wed Oct 25 20:45:46 2017
From: orchidn at live.com (dani)
Date: Wed, 25 Oct 2017 18:45:46 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
Message-ID: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>

Dear list members,

I need some advice regarding this ZIP MCMCglmm model:

library(MCMCglmm)

priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
               G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))

mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
                  random = ~idh(trait):group1 + idh(trait):group2,
                  family = "zipoisson",
                  prior = priori,
                  rcov = ~idh(trait):units,
               verbose=FALSE,
               thin   = 100,
               burnin = 3000,
               nitt   = 103000,
               saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
               data = s25h)

summary(mj)

# Iterations = 3001:102901
# Thinning interval  = 100
# Sample size  = 1000
#
# DIC: 4811.791
#
# G-structure:  ~idh(trait):group1
#
#                                post.mean l-95% CI u-95% CI eff.samp
# traity.group1       0.4307   0.1351   0.9281    10.17
# traitzi_y. group1  4.3196   2.1216   7.4310    31.26
#
# ~idh(trait):group2
#
#                              post.mean l-95% CI u-95% CI eff.samp
# traity. group2       0.4233   0.2341   0.6781    30.81
# traitzi_y. group2    3.5497   1.2365   6.1525    26.39
#
# R-structure:  ~idh(trait):units
#
#                            post.mean l-95% CI u-95% CI eff.samp
# traity.units      0.02393 0.002833  0.06621    10.58
# traitzi_y.units   1.00000 1.000000  1.00000     0.00
#
# Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
#
#                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
# traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
# traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
# at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
# at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
# at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
# at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
# at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
# at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
# at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
# at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
#   ---
#   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?

Thanks in advance!
DNM
<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Oct 25 21:58:03 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Oct 2017 15:58:03 -0400
Subject: [R-sig-ME] Residual Variance or Dispersion of Gamma GLMER
In-Reply-To: <CAOy7hbDCNH2WPezF98nhpGs_nnHDs5qnSXHTvak7qTV7h5LiTw@mail.gmail.com>
References: <CAOy7hbDCNH2WPezF98nhpGs_nnHDs5qnSXHTvak7qTV7h5LiTw@mail.gmail.com>
Message-ID: <f501ce74-b57d-fb88-8a10-7a0d38d50078@gmail.com>


  Depending on what exactly you mean by for "dispersion" (there are lots
of different definitions depending on context): sigma() gives you
1/sqrt(shape) (i.e. the scaled standard deviation or coefficient of
variation: mean=shape*scale, variance=shape*scale^2, so sd/mean =
sqrt(shape)*scale/(shape*scale) = 1/sqrt(shape).

In the classic GLM sense phi=sigma^2=1/shape is the dispersion
parameter, because we define variance= V(mu)/phi,  V=mu^2
((shape*scale)^2/shape = shape*scale^2 - variance).

sigma() is the same value as the one reported in the Residual Std.Dev.
column.

 For what it's worth I wouldn't call the conditional (Gamma) model
"zero-altered" in this case, as the Gamma has a zero (or infinite)
probability density for x=0 anyway.


On 17-10-25 10:31 AM, andreu blanco wrote:
> Hi,
> I am trying to fit a Hurdle model using glmer, however in order to
> calculate the variance of the Hurdle model I need to know the dispersion of
> the gamma ZAG, which I cannot find from the summary of my model:
>> summary(H1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: Gamma  ( log )
> Formula: Biomass ~ Protection * Exposure + (1 | Location)
>    Data: Aarmata.pos
> 
>      AIC      BIC   logLik deviance df.resid
>    644.9    657.5   -316.4    632.9       55
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.2278 -0.7188 -0.1149  0.3721  3.4934
> 
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Location (Intercept) 0.5489   0.7409
>  Residual             0.6531   0.8082
> Number of obs: 61, groups:  Location, 8
> 
> Fixed effects:
>                                         Estimate Std. Error t value
> Pr(>|z|)
> (Intercept)                               4.1195     0.4866   8.466
>  <2e-16 ***
> ProtectionProtected                       0.2202     0.6940   0.317
>  0.7510
> ExposureSemiexposed                      -0.6357     0.3319  -1.915
>  0.0555 .
> ProtectionProtected:ExposureSemiexposed  -0.7128     0.5492  -1.298
>  0.1944
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>             (Intr) PrtctP ExpsrS
> PrtctnPrtct -0.701
> ExpsrSmxpsd -0.212  0.143
> PrtctnPr:ES  0.131 -0.242 -0.562
>


From andreu.blanco at gmail.com  Thu Oct 26 09:07:33 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Thu, 26 Oct 2017 09:07:33 +0200
Subject: [R-sig-ME] Residual Variance or Dispersion of Gamma GLMER
In-Reply-To: <CAOy7hbDCNH2WPezF98nhpGs_nnHDs5qnSXHTvak7qTV7h5LiTw@mail.gmail.com>
References: <CAOy7hbDCNH2WPezF98nhpGs_nnHDs5qnSXHTvak7qTV7h5LiTw@mail.gmail.com>
Message-ID: <CAOy7hbD98PTodkd51M4Y_7hskh8_FrMY+F+8CwLtpWhteu8YnQ@mail.gmail.com>

Thank you both very much.

On 25 October 2017 at 16:31, andreu blanco <andreu.blanco at gmail.com> wrote:

> Hi,
> I am trying to fit a Hurdle model using glmer, however in order to
> calculate the variance of the Hurdle model I need to know the dispersion of
> the gamma ZAG, which I cannot find from the summary of my model:
> > summary(H1)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: Gamma  ( log )
> Formula: Biomass ~ Protection * Exposure + (1 | Location)
>    Data: Aarmata.pos
>
>      AIC      BIC   logLik deviance df.resid
>    644.9    657.5   -316.4    632.9       55
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.2278 -0.7188 -0.1149  0.3721  3.4934
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Location (Intercept) 0.5489   0.7409
>  Residual             0.6531   0.8082
> Number of obs: 61, groups:  Location, 8
>
> Fixed effects:
>                                         Estimate Std. Error t value
> Pr(>|z|)
> (Intercept)                               4.1195     0.4866   8.466
>  <2e-16 ***
> ProtectionProtected                       0.2202     0.6940   0.317
>  0.7510
> ExposureSemiexposed                      -0.6357     0.3319  -1.915
>  0.0555 .
> ProtectionProtected:ExposureSemiexposed  -0.7128     0.5492  -1.298
>  0.1944
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) PrtctP ExpsrS
> PrtctnPrtct -0.701
> ExpsrSmxpsd -0.212  0.143
> PrtctnPr:ES  0.131 -0.242 -0.562
>
> --
> Andreu Blanco Cartagena
>
>
>
> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
> ajuda a protegir el medi ambient.
>
> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
> proteger el medio ambiente.
>



-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From walidmawass10 at gmail.com  Thu Oct 26 21:13:51 2017
From: walidmawass10 at gmail.com (Walid Mawass)
Date: Thu, 26 Oct 2017 15:13:51 -0400
Subject: [R-sig-ME] prior specification for bivariate MCMCglmm model
Message-ID: <f6448ba0-923f-1637-3573-fc74042c25e7@gmail.com>

Hello everyone,

I am working with a bivariate model which includes gaussian and poisson 
distributions. I am trying to figure out the proper prior specification 
specifically for the (co)variance matrices. This is what I have used so far:

prior <- list(R = list(V=diag(2), nu =3), G=list(G1 = list(V=diag(2), nu 
=3)))

Thank you for any feedback

-- 
Walid Mawass

M.Sc. of Cellular and Molecular Biology

Population Genetics Laboratory

University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


From jl.verissimo at gmail.com  Mon Oct 30 13:35:17 2017
From: jl.verissimo at gmail.com (=?ISO-8859-1?Q?Jo=E3o_Ver=EDssimo?=)
Date: Mon, 30 Oct 2017 13:35:17 +0100
Subject: [R-sig-ME] constrain random effect in lmer (fitting reduced model
 for calculation of Cohen's f2)
Message-ID: <1509366917.7899.4.camel@gmail.com>

Dear all,

I am attempting to calculate Cohen's f2 as a measure of "local" effect
size in a mixed-effects regression model (Selya et al., 2012, https://d
oi.org/10.3389/fpsyg.2012.00111 ).

The procedure involves comparing 3 models in order to calculate the
reduction in residual variance that can be attributed to the fixed
effect of interest (the 3 models are a "full" model with all
predictors, a reduced model without the fixed effect of interest, and a
"null" model with no fixed effects; for specifics, see Eqs. 2 and 3 in
Selya et al., 2012).

Importantly, it is necessary to obtain the variance of random effects
from the "full" model and hold this constant (the random effect
variance) when fitting the reduced models.

1. Is there a way to achieve this in lmer(), i.e., to prespecify the
variance of a random effect?

2. If not: as a proxy for "holding the random effect constant" I've
assumed that the increased random effect variance in the reduced models
could be added to the residual variance.

For example, the random effect part of the "full" model shows Subject
(Intercept)=0.264;Residual=0.532. Taking one predictor out, for which I
want to calculate Cohen's f2, I get Subject (Intercept)=0.320;
Residual=0.534. I have taken the residual variance of the reduced model
to be 0.534+0.056 (which is the difference in the Subject effect when
said predictor is left out).

Are there objections to this? It seemed reasonable to me, but I'm not
sure at all.

Thank you!
Jo?o


From highstat at highstat.com  Tue Oct 31 12:41:39 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 31 Oct 2017 11:41:39 +0000
Subject: [R-sig-ME] Course in Lisbon: Introduction to Linear Mixed Effects
 Models and GLMM with R
Message-ID: <7a276e7c-05cb-0794-5ff6-70d61cff3437@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Linear Mixed Effects Models and GLMM with R
Where:? Lisbon, Portugal
When:?? 19-23 February 2018

Course website: http://highstat.com/index.php/courses
Course flyer: 
http://highstat.com/Courses/Flyers/2018/Flyer2018_02LisbonV2.pdf


Kind regards,

Alain Zuur



-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From G.K.Hajduk at ed.ac.uk  Wed Oct 25 14:27:26 2017
From: G.K.Hajduk at ed.ac.uk (HAJDUK Gabriela)
Date: Wed, 25 Oct 2017 12:27:26 +0000
Subject: [R-sig-ME] broom package and MCMCglmm estimates
In-Reply-To: <MWHPR1201MB0029899432C8EE0A6DEDF815D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029B09ACB61822603738593D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1916127.vipybtBhR9@vercors>
 <MWHPR1201MB0029966B0FF097AE0BE3FA73D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <3feed415-5bc9-000a-e090-6e72c4bd6678@gmail.com>
 <MWHPR1201MB0029899432C8EE0A6DEDF815D6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <B01AC742-2924-4C95-BA82-950748F447BA@sms.ed.ac.uk>

Hello Dani,

Looks like Ben?s version of broom solves your problem (I haven?t used it, but looks like it does the trick beautifully!), but in case it?s any use (e.g. if you wanted to tweak anything for yourself to adjust the output) I?ve popped a function that I?ve wrote ages ago to pull out information from multiple MCMCglmm model objects for summary/plotting purposes.

You can find the code here:
https://gkhajduk.github.io/2017-10-25-cleanMCMCglmm/

Cheers,
Gabriela


On 24 Oct 2017, at 23:42, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:

Hello again,


That is fantastic, thank you so much, Dr Bolker!

I had tried earlier today and I got the same error message several times. I tried again after I received your message and I got several other error messages - one of them saying that the broom.rdb was corrupt, so I guess I might have messed up somehow because I was trying different things and I installing many packages. I removed them all and re- installed "broom" as you suggested and it worked nicely for a glmmTMB model as well as for a MCMC model. Now I hope everything goes nicely to visualize them.


I appreciate all your help and all your work in the field and in making everything easier to understand!

This is truly wonderful and I cannot emphasize more how great this mailing list is for me!

Best regards everyone!

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Sent: Tuesday, October 24, 2017 3:04 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates


 There is an MCMCglmm method in my fork of broom :

devtools::install_github("bbolker/broom")
library(broom)
library(MCMCglmm)
data(PlodiaPO)
model1 <- MCMCglmm(PO~1, random=~FSfamily, data=PlodiaPO,
 verbose=FALSE,  nitt=1300, burnin=300, thin=1)
tidy(model1)
##   effect        term estimate  std.error
## 1  fixed (Intercept) 1.162818 0.01656339

 I make no claims as to its completeness, but am happy to accept issues
or pull requests.  Eventually the stuff in my fork will get migrated to
a separate "broom.mixed" (or some such) package.



On 17-10-24 05:56 PM, dani wrote:
Hello Pierre,


Thank you so much for your prompt response, I will follow your advice and report back.


best,

daniNm

________________________________
From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org<mailto:pierre.de.villemereuil at mailoo.org>>
Sent: Tuesday, October 24, 2017 1:47 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Cc: dani
Subject: Re: [R-sig-ME] broom package and MCMCglmm estimates

Hi,

As far as I can see, there is no method to tidy up MCMCglmm output in broom. You can see that by looking at the "tidiers" functions in broom using:
library(help = broom) #No MCMCglmm

However, MCMCglmm output contains "mcmc" class objects that can be tidied up using tidyMCMC():
- fixed effects: tidyMCMC(model$Sol)
- random effects: tidyMCMC(model$VCV)

Look up ?tidyMCMC for more options. I'm afraid it's difficult to get the pMCMC back though. You can get 95% credible intervals are a replacement for those (set conf.int = TRUE).

I have also seen that Ben Bolker is working on a fork/split of broom for mixed models especially, maybe he plans on having a specific tidier for MCMCglmm?

Best,
Pierre.


On Tuesday, 24 October 2017 20:13:53 NZDT dani wrote:
Hi everyone,


I would like to visualize the estimates from a MCMC glmm model and I tried using broom but I received the following message:

Error in as.data.frame.default(mj) :
 cannot coerce class ""MCMCglmm"" to a data.frame
I was wondering what should I do about this?
Thank you in advance for all your help!
Best,
DaniNM

      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<http://stat.ethz.ch><https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch<http://stat.ethz.ch>
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...






      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20171025/9e9762fe/attachment.ksh>

From pierre.de.villemereuil at mailoo.org  Tue Oct 31 22:08:44 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Wed, 01 Nov 2017 10:08:44 +1300
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <2031614.qUIID80tlY@vercors>

Hi,

There are about three way to increase effective sample size:
- increase the number of iterations
- use a prior with better properties
- change your model somehow (you might not always want to use that one...)

In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:

priori <- list(R=list(V=diag(2), nu=1, fix=2),
               G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
						 G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))

Hope this helps,
Pierre.

On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> Dear list members,
> 
> I need some advice regarding this ZIP MCMCglmm model:
> 
> library(MCMCglmm)
> 
> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>                G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
> 
> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>                   random = ~idh(trait):group1 + idh(trait):group2,
>                   family = "zipoisson",
>                   prior = priori,
>                   rcov = ~idh(trait):units,
>                verbose=FALSE,
>                thin   = 100,
>                burnin = 3000,
>                nitt   = 103000,
>                saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>                data = s25h)
> 
> summary(mj)
> 
> # Iterations = 3001:102901
> # Thinning interval  = 100
> # Sample size  = 1000
> #
> # DIC: 4811.791
> #
> # G-structure:  ~idh(trait):group1
> #
> #                                post.mean l-95% CI u-95% CI eff.samp
> # traity.group1       0.4307   0.1351   0.9281    10.17
> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
> #
> # ~idh(trait):group2
> #
> #                              post.mean l-95% CI u-95% CI eff.samp
> # traity. group2       0.4233   0.2341   0.6781    30.81
> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
> #
> # R-structure:  ~idh(trait):units
> #
> #                            post.mean l-95% CI u-95% CI eff.samp
> # traity.units      0.02393 0.002833  0.06621    10.58
> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
> #
> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
> #
> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
> #   ---
> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
> 
> Thanks in advance!
> DNM
> <http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 


From orchidn at live.com  Wed Nov  1 01:39:16 2017
From: orchidn at live.com (dani)
Date: Wed, 1 Nov 2017 00:39:16 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <2031614.qUIID80tlY@vercors>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <2031614.qUIID80tlY@vercors>
Message-ID: <MWHPR1201MB0029EC2036557477181F429FD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Pierre,


Thank you so much for your message! I truly appreciate your help with the prior, I have exhausted all the other options and I was going to give up using MCMCglmm. I will give it a try and hopefully it works out!


Cheers,

Dani

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
Sent: Tuesday, October 31, 2017 2:08 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

Hi,

There are about three way to increase effective sample size:
- increase the number of iterations
- use a prior with better properties
- change your model somehow (you might not always want to use that one...)

In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:

priori <- list(R=list(V=diag(2), nu=1, fix=2),
               G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
                                                 G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))

Hope this helps,
Pierre.

On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> Dear list members,
>
> I need some advice regarding this ZIP MCMCglmm model:
>
> library(MCMCglmm)
>
> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>                G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>
> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>                   random = ~idh(trait):group1 + idh(trait):group2,
>                   family = "zipoisson",
>                   prior = priori,
>                   rcov = ~idh(trait):units,
>                verbose=FALSE,
>                thin   = 100,
>                burnin = 3000,
>                nitt   = 103000,
>                saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>                data = s25h)
>
> summary(mj)
>
> # Iterations = 3001:102901
> # Thinning interval  = 100
> # Sample size  = 1000
> #
> # DIC: 4811.791
> #
> # G-structure:  ~idh(trait):group1
> #
> #                                post.mean l-95% CI u-95% CI eff.samp
> # traity.group1       0.4307   0.1351   0.9281    10.17
> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
> #
> # ~idh(trait):group2
> #
> #                              post.mean l-95% CI u-95% CI eff.samp
> # traity. group2       0.4233   0.2341   0.6781    30.81
> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
> #
> # R-structure:  ~idh(trait):units
> #
> #                            post.mean l-95% CI u-95% CI eff.samp
> # traity.units      0.02393 0.002833  0.06621    10.58
> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
> #
> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
> #
> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
> #   ---
> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
>
> Thanks in advance!
> DNM
> <http://aka.ms/weboutlook>
>
>        [[alternative HTML version deleted]]
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



	[[alternative HTML version deleted]]


From orchidn at live.com  Wed Nov  1 05:18:05 2017
From: orchidn at live.com (dani)
Date: Wed, 1 Nov 2017 04:18:05 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <2031614.qUIID80tlY@vercors>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <2031614.qUIID80tlY@vercors>
Message-ID: <MWHPR1201MB0029A7F7F44DDF2B63B35309D65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi Pierre,

I tried using the new prior you suggested and I got this error:

Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
  prior list should contain elements R, G, and/or B only

I am not sure what to do about this:)
Any advice would be very much appreciated.

Thanks,
DaniNM
<http://aka.ms/weboutlook>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
Sent: Tuesday, October 31, 2017 2:08 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

Hi,

There are about three way to increase effective sample size:
- increase the number of iterations
- use a prior with better properties
- change your model somehow (you might not always want to use that one...)

In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:

priori <- list(R=list(V=diag(2), nu=1, fix=2),
               G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
                                                 G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))

Hope this helps,
Pierre.

On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> Dear list members,
>
> I need some advice regarding this ZIP MCMCglmm model:
>
> library(MCMCglmm)
>
> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>                G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>
> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>                   random = ~idh(trait):group1 + idh(trait):group2,
>                   family = "zipoisson",
>                   prior = priori,
>                   rcov = ~idh(trait):units,
>                verbose=FALSE,
>                thin   = 100,
>                burnin = 3000,
>                nitt   = 103000,
>                saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>                data = s25h)
>
> summary(mj)
>
> # Iterations = 3001:102901
> # Thinning interval  = 100
> # Sample size  = 1000
> #
> # DIC: 4811.791
> #
> # G-structure:  ~idh(trait):group1
> #
> #                                post.mean l-95% CI u-95% CI eff.samp
> # traity.group1       0.4307   0.1351   0.9281    10.17
> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
> #
> # ~idh(trait):group2
> #
> #                              post.mean l-95% CI u-95% CI eff.samp
> # traity. group2       0.4233   0.2341   0.6781    30.81
> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
> #
> # R-structure:  ~idh(trait):units
> #
> #                            post.mean l-95% CI u-95% CI eff.samp
> # traity.units      0.02393 0.002833  0.06621    10.58
> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
> #
> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
> #
> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
> #   ---
> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
>
> Thanks in advance!
> DNM
> <http://aka.ms/weboutlook>
>
>        [[alternative HTML version deleted]]
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From pierre.de.villemereuil at mailoo.org  Wed Nov  1 06:11:57 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Wed, 01 Nov 2017 18:11:57 +1300
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <MWHPR1201MB0029A7F7F44DDF2B63B35309D65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2031614.qUIID80tlY@vercors>
 <MWHPR1201MB0029A7F7F44DDF2B63B35309D65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <2693603.WQtUsETXuI@flyosflip>

Just some parentheses issue:
priori <- list(R=list(V=diag(2), nu=1, fix=2),
               G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
                      G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))

Cheers,
Pierre

Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
> Hi Pierre,
> 
> I tried using the new prior you suggested and I got this error:
> 
> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
>   prior list should contain elements R, G, and/or B only
> 
> I am not sure what to do about this:)
> Any advice would be very much appreciated.
> 
> Thanks,
> DaniNM
> <http://aka.ms/weboutlook>
> 
> 
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Tuesday, October 31, 2017 2:08 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
> 
> Hi,
> 
> There are about three way to increase effective sample size:
> - increase the number of iterations
> - use a prior with better properties
> - change your model somehow (you might not always want to use that one...)
> 
> In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
> 
> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>                G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
>                                                  G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
> 
> Hope this helps,
> Pierre.
> 
> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> > Dear list members,
> >
> > I need some advice regarding this ZIP MCMCglmm model:
> >
> > library(MCMCglmm)
> >
> > priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
> >                G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
> >
> > mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
> >                   random = ~idh(trait):group1 + idh(trait):group2,
> >                   family = "zipoisson",
> >                   prior = priori,
> >                   rcov = ~idh(trait):units,
> >                verbose=FALSE,
> >                thin   = 100,
> >                burnin = 3000,
> >                nitt   = 103000,
> >                saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
> >                data = s25h)
> >
> > summary(mj)
> >
> > # Iterations = 3001:102901
> > # Thinning interval  = 100
> > # Sample size  = 1000
> > #
> > # DIC: 4811.791
> > #
> > # G-structure:  ~idh(trait):group1
> > #
> > #                                post.mean l-95% CI u-95% CI eff.samp
> > # traity.group1       0.4307   0.1351   0.9281    10.17
> > # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
> > #
> > # ~idh(trait):group2
> > #
> > #                              post.mean l-95% CI u-95% CI eff.samp
> > # traity. group2       0.4233   0.2341   0.6781    30.81
> > # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
> > #
> > # R-structure:  ~idh(trait):units
> > #
> > #                            post.mean l-95% CI u-95% CI eff.samp
> > # traity.units      0.02393 0.002833  0.06621    10.58
> > # traitzi_y.units   1.00000 1.000000  1.00000     0.00
> > #
> > # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
> > #
> > #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> > # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
> > # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
> > # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
> > # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
> > # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
> > # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
> > # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
> > # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
> > # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
> > # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
> > #   ---
> > #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
> >
> > Thanks in advance!
> > DNM
> > <http://aka.ms/weboutlook>
> >
> >        [[alternative HTML version deleted]]
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From orchidn at live.com  Wed Nov  1 21:14:15 2017
From: orchidn at live.com (dani)
Date: Wed, 1 Nov 2017 20:14:15 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <2693603.WQtUsETXuI@flyosflip>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2031614.qUIID80tlY@vercors>
 <MWHPR1201MB0029A7F7F44DDF2B63B35309D65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <2693603.WQtUsETXuI@flyosflip>
Message-ID: <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Pierre and list members,


Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.


Best regards, everyone!

DNM


________________________________
From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
Sent: Tuesday, October 31, 2017 10:11 PM
To: dani
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

Just some parentheses issue:
priori <- list(R=list(V=diag(2), nu=1, fix=2),
               G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
                      G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))

Cheers,
Pierre

Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
> Hi Pierre,
>
> I tried using the new prior you suggested and I got this error:
>
> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
>   prior list should contain elements R, G, and/or B only
>
> I am not sure what to do about this:)
> Any advice would be very much appreciated.
>
> Thanks,
> DaniNM
> <http://aka.ms/weboutlook>
>
>
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Tuesday, October 31, 2017 2:08 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>
> Hi,
>
> There are about three way to increase effective sample size:
> - increase the number of iterations
> - use a prior with better properties
> - change your model somehow (you might not always want to use that one...)
>
> In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
>
> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>                G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
>                                                  G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
>
> Hope this helps,
> Pierre.
>
> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> > Dear list members,
> >
> > I need some advice regarding this ZIP MCMCglmm model:
> >
> > library(MCMCglmm)
> >
> > priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
> >                G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
> >
> > mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
> >                   random = ~idh(trait):group1 + idh(trait):group2,
> >                   family = "zipoisson",
> >                   prior = priori,
> >                   rcov = ~idh(trait):units,
> >                verbose=FALSE,
> >                thin   = 100,
> >                burnin = 3000,
> >                nitt   = 103000,
> >                saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
> >                data = s25h)
> >
> > summary(mj)
> >
> > # Iterations = 3001:102901
> > # Thinning interval  = 100
> > # Sample size  = 1000
> > #
> > # DIC: 4811.791
> > #
> > # G-structure:  ~idh(trait):group1
> > #
> > #                                post.mean l-95% CI u-95% CI eff.samp
> > # traity.group1       0.4307   0.1351   0.9281    10.17
> > # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
> > #
> > # ~idh(trait):group2
> > #
> > #                              post.mean l-95% CI u-95% CI eff.samp
> > # traity. group2       0.4233   0.2341   0.6781    30.81
> > # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
> > #
> > # R-structure:  ~idh(trait):units
> > #
> > #                            post.mean l-95% CI u-95% CI eff.samp
> > # traity.units      0.02393 0.002833  0.06621    10.58
> > # traitzi_y.units   1.00000 1.000000  1.00000     0.00
> > #
> > # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
> > #
> > #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> > # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
> > # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
> > # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
> > # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
> > # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
> > # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
> > # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
> > # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
> > # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
> > # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
> > #   ---
> > #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
> >
> > Thanks in advance!
> > DNM
> > <http://aka.ms/weboutlook>
> >
> >        [[alternative HTML version deleted]]
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>

	[[alternative HTML version deleted]]


From pierre.de.villemereuil at mailoo.org  Wed Nov  1 21:25:57 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Thu, 02 Nov 2017 09:25:57 +1300
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <1813389.GnyUOU5luO@vercors>

You can look at the auto-correlation to guess how many more iterations are needed to increase your sample size. Something like:

library(coda)
autocorr.diag(mj$Sol)
autocorr.diag(mj$VCV)

Cheers,
Pierre

On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
> Hello Pierre and list members,
> 
> 
> Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.
> 
> 
> Best regards, everyone!
> 
> DNM
> 
> 
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Tuesday, October 31, 2017 10:11 PM
> To: dani
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
> 
> Just some parentheses issue:
> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>                G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
>                       G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
> 
> Cheers,
> Pierre
> 
> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
> > Hi Pierre,
> >
> > I tried using the new prior you suggested and I got this error:
> >
> > Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
> >   prior list should contain elements R, G, and/or B only
> >
> > I am not sure what to do about this:)
> > Any advice would be very much appreciated.
> >
> > Thanks,
> > DaniNM
> > <http://aka.ms/weboutlook>
> >
> >
> > ________________________________
> > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> > Sent: Tuesday, October 31, 2017 2:08 PM
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
> >
> > Hi,
> >
> > There are about three way to increase effective sample size:
> > - increase the number of iterations
> > - use a prior with better properties
> > - change your model somehow (you might not always want to use that one...)
> >
> > In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
> >
> > priori <- list(R=list(V=diag(2), nu=1, fix=2),
> >                G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
> >                                                  G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
> >
> > Hope this helps,
> > Pierre.
> >
> > On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> > > Dear list members,
> > >
> > > I need some advice regarding this ZIP MCMCglmm model:
> > >
> > > library(MCMCglmm)
> > >
> > > priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
> > >                G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
> > >
> > > mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
> > >                   random = ~idh(trait):group1 + idh(trait):group2,
> > >                   family = "zipoisson",
> > >                   prior = priori,
> > >                   rcov = ~idh(trait):units,
> > >                verbose=FALSE,
> > >                thin   = 100,
> > >                burnin = 3000,
> > >                nitt   = 103000,
> > >                saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
> > >                data = s25h)
> > >
> > > summary(mj)
> > >
> > > # Iterations = 3001:102901
> > > # Thinning interval  = 100
> > > # Sample size  = 1000
> > > #
> > > # DIC: 4811.791
> > > #
> > > # G-structure:  ~idh(trait):group1
> > > #
> > > #                                post.mean l-95% CI u-95% CI eff.samp
> > > # traity.group1       0.4307   0.1351   0.9281    10.17
> > > # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
> > > #
> > > # ~idh(trait):group2
> > > #
> > > #                              post.mean l-95% CI u-95% CI eff.samp
> > > # traity. group2       0.4233   0.2341   0.6781    30.81
> > > # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
> > > #
> > > # R-structure:  ~idh(trait):units
> > > #
> > > #                            post.mean l-95% CI u-95% CI eff.samp
> > > # traity.units      0.02393 0.002833  0.06621    10.58
> > > # traitzi_y.units   1.00000 1.000000  1.00000     0.00
> > > #
> > > # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
> > > #
> > > #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> > > # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
> > > # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
> > > # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
> > > # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
> > > # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
> > > # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
> > > # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
> > > # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
> > > # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
> > > # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
> > > #   ---
> > > #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > > I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
> > >
> > > Thanks in advance!
> > > DNM
> > > <http://aka.ms/weboutlook>
> > >
> > >        [[alternative HTML version deleted]]
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
> 
> 
> 
> >
> 


From orchidn at live.com  Wed Nov  1 21:31:59 2017
From: orchidn at live.com (dani)
Date: Wed, 1 Nov 2017 20:31:59 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <1813389.GnyUOU5luO@vercors>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <1813389.GnyUOU5luO@vercors>
Message-ID: <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Thanks, Pierre! Will do that, too!

Best,
DNM

________________________________
From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
Sent: Wednesday, November 1, 2017 1:25 PM
To: dani
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

You can look at the auto-correlation to guess how many more iterations are needed to increase your sample size. Something like:

library(coda)
autocorr.diag(mj$Sol)
autocorr.diag(mj$VCV)

Cheers,
Pierre

On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
> Hello Pierre and list members,
>
>
> Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.
>
>
> Best regards, everyone!
>
> DNM
>
>
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Tuesday, October 31, 2017 10:11 PM
> To: dani
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>
> Just some parentheses issue:
> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>                G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
>                       G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>
> Cheers,
> Pierre
>
> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
> > Hi Pierre,
> >
> > I tried using the new prior you suggested and I got this error:
> >
> > Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
> >   prior list should contain elements R, G, and/or B only
> >
> > I am not sure what to do about this:)
> > Any advice would be very much appreciated.
> >
> > Thanks,
> > DaniNM
> > <http://aka.ms/weboutlook>
> >
> >
> > ________________________________
> > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> > Sent: Tuesday, October 31, 2017 2:08 PM
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
> >
> > Hi,
> >
> > There are about three way to increase effective sample size:
> > - increase the number of iterations
> > - use a prior with better properties
> > - change your model somehow (you might not always want to use that one...)
> >
> > In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
> >
> > priori <- list(R=list(V=diag(2), nu=1, fix=2),
> >                G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
> >                                                  G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
> >
> > Hope this helps,
> > Pierre.
> >
> > On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> > > Dear list members,
> > >
> > > I need some advice regarding this ZIP MCMCglmm model:
> > >
> > > library(MCMCglmm)
> > >
> > > priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
> > >                G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
> > >
> > > mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
> > >                   random = ~idh(trait):group1 + idh(trait):group2,
> > >                   family = "zipoisson",
> > >                   prior = priori,
> > >                   rcov = ~idh(trait):units,
> > >                verbose=FALSE,
> > >                thin   = 100,
> > >                burnin = 3000,
> > >                nitt   = 103000,
> > >                saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
> > >                data = s25h)
> > >
> > > summary(mj)
> > >
> > > # Iterations = 3001:102901
> > > # Thinning interval  = 100
> > > # Sample size  = 1000
> > > #
> > > # DIC: 4811.791
> > > #
> > > # G-structure:  ~idh(trait):group1
> > > #
> > > #                                post.mean l-95% CI u-95% CI eff.samp
> > > # traity.group1       0.4307   0.1351   0.9281    10.17
> > > # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
> > > #
> > > # ~idh(trait):group2
> > > #
> > > #                              post.mean l-95% CI u-95% CI eff.samp
> > > # traity. group2       0.4233   0.2341   0.6781    30.81
> > > # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
> > > #
> > > # R-structure:  ~idh(trait):units
> > > #
> > > #                            post.mean l-95% CI u-95% CI eff.samp
> > > # traity.units      0.02393 0.002833  0.06621    10.58
> > > # traitzi_y.units   1.00000 1.000000  1.00000     0.00
> > > #
> > > # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
> > > #
> > > #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
> > > # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
> > > # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
> > > # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
> > > # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
> > > # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
> > > # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
> > > # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
> > > # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
> > > # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
> > > # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
> > > #   ---
> > > #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > > I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
> > >
> > > Thanks in advance!
> > > DNM
> > > <http://aka.ms/weboutlook>
> > >
> > >        [[alternative HTML version deleted]]
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
> >
>


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Nov  1 21:42:52 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 1 Nov 2017 20:42:52 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1813389.GnyUOU5luO@vercors>
 <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <ea1d4727-a03b-fd68-4d60-87d4c9bdf96e@ed.ac.uk>

Hi,

I would try and diagnose why the mixing is bad first.

1) How many observations are there, what is their mean and how many are 
zero?
2) How many levels are there to group1 and group2?
3) What is the range of the latent variable for the zero inflation? 
Include pl=TRUE in the call to MCMCglmm and plot a histogram of

model$Liab[,(ncol(model$Liab)/2+1):ncol(model$Liab)])

4) why do you have random effects for zero-inflation but choose to 
ignore it in the fixed effects?

Cheers,

Jarrod

On 01/11/2017 20:31, dani wrote:
> Thanks, Pierre! Will do that, too!
>
> Best,
> DNM
>
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Wednesday, November 1, 2017 1:25 PM
> To: dani
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>
> You can look at the auto-correlation to guess how many more iterations are needed to increase your sample size. Something like:
>
> library(coda)
> autocorr.diag(mj$Sol)
> autocorr.diag(mj$VCV)
>
> Cheers,
> Pierre
>
> On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
>> Hello Pierre and list members,
>>
>>
>> Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.
>>
>>
>> Best regards, everyone!
>>
>> DNM
>>
>>
>> ________________________________
>> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
>> Sent: Tuesday, October 31, 2017 10:11 PM
>> To: dani
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>
>> Just some parentheses issue:
>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
>>                        G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>
>> Cheers,
>> Pierre
>>
>> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
>>> Hi Pierre,
>>>
>>> I tried using the new prior you suggested and I got this error:
>>>
>>> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
>>>    prior list should contain elements R, G, and/or B only
>>>
>>> I am not sure what to do about this:)
>>> Any advice would be very much appreciated.
>>>
>>> Thanks,
>>> DaniNM
>>> <http://aka.ms/weboutlook>
>>>
>>>
>>> ________________________________
>>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
>>> Sent: Tuesday, October 31, 2017 2:08 PM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>>
>>> Hi,
>>>
>>> There are about three way to increase effective sample size:
>>> - increase the number of iterations
>>> - use a prior with better properties
>>> - change your model somehow (you might not always want to use that one...)
>>>
>>> In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
>>>
>>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
>>>                                                   G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
>>>
>>> Hope this helps,
>>> Pierre.
>>>
>>> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
>>>> Dear list members,
>>>>
>>>> I need some advice regarding this ZIP MCMCglmm model:
>>>>
>>>> library(MCMCglmm)
>>>>
>>>> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>>>>                 G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>>>>
>>>> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>>>>                    random = ~idh(trait):group1 + idh(trait):group2,
>>>>                    family = "zipoisson",
>>>>                    prior = priori,
>>>>                    rcov = ~idh(trait):units,
>>>>                 verbose=FALSE,
>>>>                 thin   = 100,
>>>>                 burnin = 3000,
>>>>                 nitt   = 103000,
>>>>                 saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>>>>                 data = s25h)
>>>>
>>>> summary(mj)
>>>>
>>>> # Iterations = 3001:102901
>>>> # Thinning interval  = 100
>>>> # Sample size  = 1000
>>>> #
>>>> # DIC: 4811.791
>>>> #
>>>> # G-structure:  ~idh(trait):group1
>>>> #
>>>> #                                post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.group1       0.4307   0.1351   0.9281    10.17
>>>> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
>>>> #
>>>> # ~idh(trait):group2
>>>> #
>>>> #                              post.mean l-95% CI u-95% CI eff.samp
>>>> # traity. group2       0.4233   0.2341   0.6781    30.81
>>>> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
>>>> #
>>>> # R-structure:  ~idh(trait):units
>>>> #
>>>> #                            post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.units      0.02393 0.002833  0.06621    10.58
>>>> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
>>>> #
>>>> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
>>>> #
>>>> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>>>> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
>>>> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
>>>> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
>>>> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
>>>> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
>>>> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
>>>> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
>>>> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
>>>> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
>>>> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
>>>> #   ---
>>>> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
>>>>
>>>> Thanks in advance!
>>>> DNM
>>>> <http://aka.ms/weboutlook>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> stat.ethz.ch
>> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ucfagls at gmail.com  Thu Nov  2 01:56:34 2017
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 1 Nov 2017 18:56:34 -0600
Subject: [R-sig-ME] compare two GAMM4 models using AICs
In-Reply-To: <MWHPR1201MB00297C3CD019542A15A9EFCAD6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <mailman.3511.1508878054.1577.r-sig-mixed-models@r-project.org>
 <8e21daf5-3027-1ecb-8b45-a55dea075874@highstat.com>
 <af638172-1da9-52b5-46f2-7d5bdaefaf41@highstat.com>
 <MWHPR1201MB00297C3CD019542A15A9EFCAD6470@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <CAAHES9zEgPinY91p=2wyqpvSco-Rx-XCsRv-RvfKPc7HVskDgg@mail.gmail.com>

That isn't the recommended test for a parametric term vesus and smooth
alternative. A few weeks ago I emailed the authors, of the script you
link to, to point out the issue and provided a correction.

The alternative model should be

y ~ x + s(x, bs = 'tp', m = c(2,0))

As Alain mentioned, s(x) contains a basis function the corresponds to
a linear effect of x. What the version I show above does is as for a
second-order thin plate spline (so far so default) but without a null
space (the 0 in `m`). The null space of the spline is the part of the
basis that includes all the perfectly smooth basis functions; the
constant basis function and the linear basis function -- IIRC the
constant term will have been removed by the identifiability
constraints for the model intercept.

The above was cribbed from section 6.12.3 of the Second Edition of
Simon Wood's GAM book. Hopefully the tutorial script you linked to
will be updated soon.

If you want to double check some of the GAMM fits, you can fit your
model as a simple GAM with "random effect" splines:

gam(y ~ s(age) + s(g, bs='re') + s(s, bs = 're') + offset(expy), family=poisson)

which fits random intercepts in levels of g and levels of s. (I can't
recall what that lme4 notation actually produces in terms of random
effects - the gam() version I show will be uncorrelated.) You also
have a few more choices for conditional distribution of the response
via family = nb for Neg Bin, plus there are some zero-inflated Poisson
options if needed.

HTH

Gavin

On 24 October 2017 at 15:54, dani <orchidn at live.com> wrote:
> Hello everyone,
>
>
> Dr Zuur, thank you so much for your answer.
>
> First, I made a mistake and I forgot to specify that it was a Poisson model with an offset term.
>
>
> I asked my question because I saw this: http://qcbs.ca/wiki/r_workshop8:
>
>
> "How do we test whether the non-linear model offers a significant improvement over the linear model? We can use the gam() and anova() commands to formally test whether an assumption of linearity is justified. To do, we must simply set our smoothed model so that it is nested in our linear model; that is, we create model object that includes both x (linear) and s(x) (non-linear) and we ask whether adding s(x) to the model with only x as a covariate is supported by the data."
>
> |" Test for linearity<http://qcbs.ca/wiki/_export/code/r_workshop8?codeblock=4>
>
> linear_model = gam(y_obs~x)
> nested_gam_model = gam(y_obs~s(x)+x)
> print<http://stat.ethz.ch/R-manual/R-devel/library/base/html/print.html>(anova<http://stat.ethz.ch/R-manual/R-devel/library/stats/html/anova.html>(linear_model, nested_gam_model, test="Chisq"))"
>
> Given that in their case it was a GAM model, I was not sure how to do something similar in a gamm4 context. I searched online but I could not find an answer.
>
>
> My model looks like this:
>
> mg = gamm4(y ~ s(age)+offset(expy), random=~(1|g)+(1|s), data=s25h, family= poisson)
>
>
> summary(mg$gam)
>
> Family: poisson
> Link function: log
>
> Formula:
> y ~ s(age) + offset(expy)
>
> Parametric coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -7.3922     0.1065  -69.41   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
>             edf Ref.df    Chi.sq p-value
> s(age)   1      1         0.13   0.719
>
> R-sq.(adj) =  -8.44e-05
> glmer.ML = 2075.4  Scale est. = 1         n = 10523
>
> summary(mg$mer)
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: poisson  ( log )
>
>      AIC      BIC   logLik deviance df.resid
>   5294.9   5331.2  -2642.4   5284.9    10518
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.8449 -0.0806 -0.0786 -0.0775  4.9384
>
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  g  (Intercept) 2.868    1.694
>  s (Intercept) 3.820    1.954
>  Xr      s(age) 0.000    0.000
> Number of obs: 10523, groups:  g, 1785; s, 1768; Xr, 8
>
> Fixed effects:
>                 Estimate Std. Error z value Pr(>|z|)
> X(Intercept)    -7.39218    0.19834  -37.27   <2e-16 ***
> Xs(age)Fx1  0.03669    0.08418    0.44    0.663
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             X(Int)
> Xs(age)F1 0.024
>
>
> Is this the right way to interpret it:
>
> 1) from the gam part I would conclude that the spline for the variable age has an estimated degree of freedom of 1, indicating that I might not need a spline. However, I understood that one can have a edf of 1 and there might still be a need for including a spline in the model (this part is very ambiguous for me, as I would think this alone should be indicative of a linear association). Either way, the spline term is not significantly associated with my outcome.
>
> 2) from the mer part I would conclude that the linear part of the variable age is not associated with my outcome, either.
>
> Based on this model, I can safely assume that age can be included in my regression model as a linear term, given there is nothing to suggest the association with my outcome is non-parametrical.
>
> I would then check the residuals, as you suggested, and if there is not any pattern, I should be ok without including a spline then.
>
> Does this sound like a reasonable explanation for not including a spline term in my regression model?
>
> Thank you so much. I apologize for these silly questions. I am just trying to assimilate way too much at once and I second guess everything I do since these are all difficult concepts to grasp for a beginner.
>
> Best,
> DaniNM
>
>
>
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Highland Statistics Ltd <highstat at highstat.com>
> Sent: Tuesday, October 24, 2017 2:00 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] compare two GAMM4 models using AICs
>
>
>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Tue, 24 Oct 2017 19:49:50 +0000
>>> From: dani <orchidn at live.com>
>>> To: "r-sig-mixed-models at r-project.org"
>>>     <r-sig-mixed-models at r-project.org>
>>> Subject: [R-sig-ME] compare two GAMM4 models using AICs
>>> Message-ID:
>>>     <MWHPR1201MB0029CE3D9C5EC1956640DB70D6470 at MWHPR1201MB0029.namprd12.prod.outlook.com>
>>>
>>>
>>> Content-Type: text/plain; charset="UTF-8"
>>>
>>> Hello everyone,
>>>
>>>
>>> I am fitting two gamm4 models because I would like to see whether
>>> there is justification for including a spline term for x1. Can this
>>> be done by comparing the AICs for the underlying mixed models (i.e.,
>>> the "mer" part) of the two models?
>>
>>
>
> Technically it won't crash..."so it can be done"..but I am not sure
> whether you want to do this. Internally, the smoother is written as a
> mixed model (X * b + Z * u)....and those random effects (which is part
> of the smoother) don't count towards the number of parameters.
>
>>> b1 <- gamm4(y~x1+offset(e),data=dat,random=~(1|fac))
>>
>>> b2 <- gamm4(y~x1+s(x1)+offset(e),data=dat,random=~(1|fac))
>>
>>
>>
>
>
> I am confused about your use of an offset in a Gaussian model, and I am
> confused why you would use x1 and s(x1) in the same model. The s(x1)
> already contains the linear part of the smoother.
>
> Why not fit the first model and inspect residuals for any patterns? If
> there are, then using a smoother is an option.
>
> Kind regards,
>
> Alain Zuur
>
>
>>
>>>
>>> summary(b1$gam)
>>>
>>> summary(b1$mer)
>>>
>>>
>>> summary(b2$gam)
>>>
>>> summary(b2$mer)
>>>
>>>
>>> AIC(b1$mer)
>>>
>>> AIC(b2$mer)
>>>
>>>
>>> Thank you very much!
>>>
>>> Best,
>>>
>>> DaniNM
>>>
>>> <http://aka.ms/weboutlook>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>>
>>
>
> --
>
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email: highstat at highstat.com
> URL:   www.highstat.com<http://www.highstat.com>
> Highland Statistics Ltd.<http://www.highstat.com/>
> www.highstat.com
> Statistical consultancy, data analysis and software development. Specialized in time series analysis. Located in Scotland.
>
>
>
>
> And:
> NIOZ Royal Netherlands Institute for Sea Research,
> Department of Coastal Systems, and Utrecht University,
> P.O. Box 59, 1790 AB Den Burg,
> Texel, The Netherlands
>
>
>
> Author of:
> 1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
> 2. Beginner's Guide to Zero-Inflated Models with R (2016).
> 3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
> 4. Beginner's Guide to GAMM with R (2014).
> 5. Beginner's Guide to GLM and GLMM with R (2013).
> 6. Beginner's Guide to GAM with R (2012).
> 7. Zero Inflated Models and GLMM with R (2012).
> 8. A Beginner's Guide to R (2009).
> 9. Mixed effects models and extensions in ecology with R (2009).
> 10. Analysing Ecological Data (2007).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Gavin Simpson, PhD


From andreu.blanco at gmail.com  Thu Nov  2 14:52:29 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Thu, 2 Nov 2017 14:52:29 +0100
Subject: [R-sig-ME] ggplot of Hurdle model
Message-ID: <CAOy7hbCs_niPqWPN-u+zDrgSczfi9J1pHFbPhTc6L_WunY35DQ@mail.gmail.com>

According to the information in the Zuur's book "Begginers guide to
Zero-inflated models with R", I see they suggest a graph to add to the
research paper. However I don't know how to sketch the model fit to my
results.

My data structure is:

> str(Aarmata)
'data.frame': 80 obs. of  6 variables:
 $ Location  : Factor w/ 8 levels "C1","C2","O",..: 1 1 1 1 1 5 5 5 5 5 ...
 $ Protection: Factor w/ 2 levels "C","P": 1 1 1 1 1 2 2 2 2 2 ...
 $ Exposure  : Factor w/ 2 levels "E","S": 1 1 1 1 1 1 1 1 1 1 ...
 $ replicates: int  1 2 3 4 5 1 2 3 4 5 ...
 $ Biomass   : num  124.8 104.8 139.2 102.6 62.9 ...

Any suggestion would be highly appreciated.

Andreu
-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Thu Nov  2 15:11:26 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Thu, 2 Nov 2017 15:11:26 +0100
Subject: [R-sig-ME] ggplot of Hurdle model
In-Reply-To: <CAOy7hbCs_niPqWPN-u+zDrgSczfi9J1pHFbPhTc6L_WunY35DQ@mail.gmail.com>
References: <CAOy7hbCs_niPqWPN-u+zDrgSczfi9J1pHFbPhTc6L_WunY35DQ@mail.gmail.com>
Message-ID: <243CE7FD-A5E5-4935-A737-70181011B1FE@gmail.com>

Hi Andreu,

We don?t really have enough information to answer your question. I don?t have access to that book and I imagine many people on this list don't either. 

If you are using glmmTMB and trying to plot predictions, there is an example on pages 8-9 of this appendix
https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>

cheers,
Mollie

> On 2Nov 2017, at 14:52, andreu blanco <andreu.blanco at gmail.com> wrote:
> 
> According to the information in the Zuur's book "Begginers guide to
> Zero-inflated models with R", I see they suggest a graph to add to the
> research paper. However I don't know how to sketch the model fit to my
> results.
> 
> My data structure is:
> 
>> str(Aarmata)
> 'data.frame': 80 obs. of  6 variables:
> $ Location  : Factor w/ 8 levels "C1","C2","O",..: 1 1 1 1 1 5 5 5 5 5 ...
> $ Protection: Factor w/ 2 levels "C","P": 1 1 1 1 1 2 2 2 2 2 ...
> $ Exposure  : Factor w/ 2 levels "E","S": 1 1 1 1 1 1 1 1 1 1 ...
> $ replicates: int  1 2 3 4 5 1 2 3 4 5 ...
> $ Biomass   : num  124.8 104.8 139.2 102.6 62.9 ...
> 
> Any suggestion would be highly appreciated.
> 
> Andreu
> -- 
> Andreu Blanco Cartagena
> 
> 
> 
> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
> ajuda a protegir el medi ambient.
> 
> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
> proteger el medio ambiente.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From andreu.blanco at gmail.com  Thu Nov  2 15:41:01 2017
From: andreu.blanco at gmail.com (andreu blanco)
Date: Thu, 2 Nov 2017 15:41:01 +0100
Subject: [R-sig-ME] ggplot of Hurdle model
In-Reply-To: <243CE7FD-A5E5-4935-A737-70181011B1FE@gmail.com>
References: <CAOy7hbCs_niPqWPN-u+zDrgSczfi9J1pHFbPhTc6L_WunY35DQ@mail.gmail.com>
 <243CE7FD-A5E5-4935-A737-70181011B1FE@gmail.com>
Message-ID: <CAOy7hbDvsMm3n7E1cYJmajKwPQw3MVEXUrFirZNGAu0jOyVkGg@mail.gmail.com>

Thank you Mollie, I understand what you mean but this is the reference I
have and that's why I am referring to it. Of course I understand every data
will need its own graph and that why I am asking for help. I will check the
info you sent and try to figure out if it is useful for my data.

Yes, I am trying to fil the model predictions, I used a glmer for the
Hurdle model and it perform smoothly. However I want to understand how to
graph the predicted values of the model to get a fancy figure for my paper.
Unfortunately I am quite new to R and doing betiful graphs I think is quite
difficult, at least as far as I tried. I hope to get some help on how to do
a good graph for my predicted values.

On 2 November 2017 at 15:11, Mollie Brooks <mollieebrooks at gmail.com> wrote:

> Hi Andreu,
>
> We don?t really have enough information to answer your question. I don?t
> have access to that book and I imagine many people on this list don't
> either.
>
> If you are using glmmTMB and trying to plot predictions, there is an
> example on pages 8-9 of this appendix
> https://www.biorxiv.org/content/biorxiv/suppl/2017/05/
> 01/132753.DC1/132753-2.pdf
>
> cheers,
> Mollie
>
> On 2Nov 2017, at 14:52, andreu blanco <andreu.blanco at gmail.com> wrote:
>
> According to the information in the Zuur's book "Begginers guide to
> Zero-inflated models with R", I see they suggest a graph to add to the
> research paper. However I don't know how to sketch the model fit to my
> results.
>
> My data structure is:
>
> str(Aarmata)
>
> 'data.frame': 80 obs. of  6 variables:
> $ Location  : Factor w/ 8 levels "C1","C2","O",..: 1 1 1 1 1 5 5 5 5 5 ...
> $ Protection: Factor w/ 2 levels "C","P": 1 1 1 1 1 2 2 2 2 2 ...
> $ Exposure  : Factor w/ 2 levels "E","S": 1 1 1 1 1 1 1 1 1 1 ...
> $ replicates: int  1 2 3 4 5 1 2 3 4 5 ...
> $ Biomass   : num  124.8 104.8 139.2 102.6 62.9 ...
>
> Any suggestion would be highly appreciated.
>
> Andreu
> --
> Andreu Blanco Cartagena
>
>
>
> Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
> ajuda a protegir el medi ambient.
>
> Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
> proteger el medio ambiente.
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
Andreu Blanco Cartagena



Si no ?s imprescindible, no imprimeixis aquest e-mail. Estalviar paper
ajuda a protegir el medi ambient.

Si no es imprescindible, no imprimas este e-mail. Ahorrar papel ayuda a
proteger el medio ambiente.

	[[alternative HTML version deleted]]


From orchidn at live.com  Thu Nov  2 16:28:33 2017
From: orchidn at live.com (dani)
Date: Thu, 2 Nov 2017 15:28:33 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <ea1d4727-a03b-fd68-4d60-87d4c9bdf96e@ed.ac.uk>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1813389.GnyUOU5luO@vercors>
 <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <ea1d4727-a03b-fd68-4d60-87d4c9bdf96e@ed.ac.uk>
Message-ID: <MWHPR1201MB00291AE038C5166E63406142D65C0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi Jarrod,


Thank you very much for your message!

I think one of the main issues is the high degree of autocorrelation. I tried to check for autocorrelation as Pierre suggested, but my computer ran out of memory.

Here are my answers to your questions:

1). There are 10523 observations  with a mean of 0.09; 95% of observations are zero.

value  N    raw %     valid % cumulative %
0 9946       94.52       94.52 94.52
1 372   3.54  3.54         98.05
2 112    1.06         1.06         99.12
3 58     0.55  0.55        99.67
4 22         0.21  0.21        99.88
5 7         0.07         0.07        99.94
6 4         0.04         0.04   99.98
7 1         0.01         0.01   99.99
8 1         0.01   0.01  100.00

missing 0 0.00

total N=10523 ? valid N=10523 ? x?=0.09 ? ?=0.44


2) group 1:  1768 level

    group 2:  1857  levels


3) I attached the histogram of the latent variable.


4) I would like a model with two random intercepts (group 1 and 2) and I am not sure how to do that with a zero inflation term.


Thank you so much for taking the time to help me with this.

Best regards,

DNM

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Wednesday, November 1, 2017 1:42 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

Hi,

I would try and diagnose why the mixing is bad first.

1) How many observations are there, what is their mean and how many are
zero?
2) How many levels are there to group1 and group2?
3) What is the range of the latent variable for the zero inflation?
Include pl=TRUE in the call to MCMCglmm and plot a histogram of

model$Liab[,(ncol(model$Liab)/2+1):ncol(model$Liab)])

4) why do you have random effects for zero-inflation but choose to
ignore it in the fixed effects?

Cheers,

Jarrod

On 01/11/2017 20:31, dani wrote:
> Thanks, Pierre! Will do that, too!
>
> Best,
> DNM
>
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> Sent: Wednesday, November 1, 2017 1:25 PM
> To: dani
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>
> You can look at the auto-correlation to guess how many more iterations are needed to increase your sample size. Something like:
>
> library(coda)
> autocorr.diag(mj$Sol)
> autocorr.diag(mj$VCV)
>
> Cheers,
> Pierre
>
> On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
>> Hello Pierre and list members,
>>
>>
>> Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.
>>
>>
>> Best regards, everyone!
>>
>> DNM
>>
>>
>> ________________________________
>> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
>> Sent: Tuesday, October 31, 2017 10:11 PM
>> To: dani
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>
>> Just some parentheses issue:
>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
>>                        G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>
>> Cheers,
>> Pierre
>>
>> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
>>> Hi Pierre,
>>>
>>> I tried using the new prior you suggested and I got this error:
>>>
>>> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
>>>    prior list should contain elements R, G, and/or B only
>>>
>>> I am not sure what to do about this:)
>>> Any advice would be very much appreciated.
>>>
>>> Thanks,
>>> DaniNM
>>> <http://aka.ms/weboutlook>
>>>
>>>
>>> ________________________________
>>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
>>> Sent: Tuesday, October 31, 2017 2:08 PM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>>
>>> Hi,
>>>
>>> There are about three way to increase effective sample size:
>>> - increase the number of iterations
>>> - use a prior with better properties
>>> - change your model somehow (you might not always want to use that one...)
>>>
>>> In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
>>>
>>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
>>>                                                   G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
>>>
>>> Hope this helps,
>>> Pierre.
>>>
>>> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
>>>> Dear list members,
>>>>
>>>> I need some advice regarding this ZIP MCMCglmm model:
>>>>
>>>> library(MCMCglmm)
>>>>
>>>> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>>>>                 G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>>>>
>>>> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>>>>                    random = ~idh(trait):group1 + idh(trait):group2,
>>>>                    family = "zipoisson",
>>>>                    prior = priori,
>>>>                    rcov = ~idh(trait):units,
>>>>                 verbose=FALSE,
>>>>                 thin   = 100,
>>>>                 burnin = 3000,
>>>>                 nitt   = 103000,
>>>>                 saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>>>>                 data = s25h)
>>>>
>>>> summary(mj)
>>>>
>>>> # Iterations = 3001:102901
>>>> # Thinning interval  = 100
>>>> # Sample size  = 1000
>>>> #
>>>> # DIC: 4811.791
>>>> #
>>>> # G-structure:  ~idh(trait):group1
>>>> #
>>>> #                                post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.group1       0.4307   0.1351   0.9281    10.17
>>>> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
>>>> #
>>>> # ~idh(trait):group2
>>>> #
>>>> #                              post.mean l-95% CI u-95% CI eff.samp
>>>> # traity. group2       0.4233   0.2341   0.6781    30.81
>>>> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
>>>> #
>>>> # R-structure:  ~idh(trait):units
>>>> #
>>>> #                            post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.units      0.02393 0.002833  0.06621    10.58
>>>> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
>>>> #
>>>> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
>>>> #
>>>> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>>>> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
>>>> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
>>>> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
>>>> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
>>>> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
>>>> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
>>>> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
>>>> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
>>>> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
>>>> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
>>>> #   ---
>>>> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
>>>>
>>>> Thanks in advance!
>>>> DNM
>>>> <http://aka.ms/weboutlook>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>> stat.ethz.ch
>> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>>
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...


-------------- next part --------------
A non-text attachment was scrubbed...
Name: HistogtamLambda.png
Type: image/png
Size: 3205 bytes
Desc: HistogtamLambda.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20171102/23ce076b/attachment-0001.png>

From orchidn at live.com  Thu Nov  2 16:31:13 2017
From: orchidn at live.com (dani)
Date: Thu, 2 Nov 2017 15:31:13 +0000
Subject: [R-sig-ME] compare two GAMM4 models using AICs
In-Reply-To: <CAAHES9zEgPinY91p=2wyqpvSco-Rx-XCsRv-RvfKPc7HVskDgg@mail.gmail.com>
References: <mailman.3511.1508878054.1577.r-sig-mixed-models@r-project.org>
 <8e21daf5-3027-1ecb-8b45-a55dea075874@highstat.com>
 <af638172-1da9-52b5-46f2-7d5bdaefaf41@highstat.com>
 <MWHPR1201MB00297C3CD019542A15A9EFCAD6470@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <CAAHES9zEgPinY91p=2wyqpvSco-Rx-XCsRv-RvfKPc7HVskDgg@mail.gmail.com>
Message-ID: <MWHPR1201MB0029520AB91ACEE68FB2DB26D65C0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Gavin,


Thank you so much for your detailed explanation, that is very helpful!

Very much appreciated!


Best regards,

Dani

________________________________
From: Gavin Simpson <ucfagls at gmail.com>
Sent: Wednesday, November 1, 2017 5:56 PM
To: dani
Cc: Highland Statistics Ltd; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] compare two GAMM4 models using AICs

That isn't the recommended test for a parametric term vesus and smooth
alternative. A few weeks ago I emailed the authors, of the script you
link to, to point out the issue and provided a correction.

The alternative model should be

y ~ x + s(x, bs = 'tp', m = c(2,0))

As Alain mentioned, s(x) contains a basis function the corresponds to
a linear effect of x. What the version I show above does is as for a
second-order thin plate spline (so far so default) but without a null
space (the 0 in `m`). The null space of the spline is the part of the
basis that includes all the perfectly smooth basis functions; the
constant basis function and the linear basis function -- IIRC the
constant term will have been removed by the identifiability
constraints for the model intercept.

The above was cribbed from section 6.12.3 of the Second Edition of
Simon Wood's GAM book. Hopefully the tutorial script you linked to
will be updated soon.

If you want to double check some of the GAMM fits, you can fit your
model as a simple GAM with "random effect" splines:

gam(y ~ s(age) + s(g, bs='re') + s(s, bs = 're') + offset(expy), family=poisson)

which fits random intercepts in levels of g and levels of s. (I can't
recall what that lme4 notation actually produces in terms of random
effects - the gam() version I show will be uncorrelated.) You also
have a few more choices for conditional distribution of the response
via family = nb for Neg Bin, plus there are some zero-inflated Poisson
options if needed.

HTH

Gavin

On 24 October 2017 at 15:54, dani <orchidn at live.com> wrote:
> Hello everyone,
>
>
> Dr Zuur, thank you so much for your answer.
>
> First, I made a mistake and I forgot to specify that it was a Poisson model with an offset term.
>
>
> I asked my question because I saw this: http://qcbs.ca/wiki/r_workshop8:
>
>
> "How do we test whether the non-linear model offers a significant improvement over the linear model? We can use the gam() and anova() commands to formally test whether an assumption of linearity is justified. To do, we must simply set our smoothed model so that it is nested in our linear model; that is, we create model object that includes both x (linear) and s(x) (non-linear) and we ask whether adding s(x) to the model with only x as a covariate is supported by the data."
>
> |" Test for linearity<http://qcbs.ca/wiki/_export/code/r_workshop8?codeblock=4>
>
> linear_model = gam(y_obs~x)
> nested_gam_model = gam(y_obs~s(x)+x)
> print<http://stat.ethz.ch/R-manual/R-devel/library/base/html/print.html>(anova<http://stat.ethz.ch/R-manual/R-devel/library/stats/html/anova.html>(linear_model, nested_gam_model, test="Chisq"))"
>
> Given that in their case it was a GAM model, I was not sure how to do something similar in a gamm4 context. I searched online but I could not find an answer.
>
>
> My model looks like this:
>
> mg = gamm4(y ~ s(age)+offset(expy), random=~(1|g)+(1|s), data=s25h, family= poisson)
>
>
> summary(mg$gam)
>
> Family: poisson
> Link function: log
>
> Formula:
> y ~ s(age) + offset(expy)
>
> Parametric coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -7.3922     0.1065  -69.41   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
>             edf Ref.df    Chi.sq p-value
> s(age)   1      1         0.13   0.719
>
> R-sq.(adj) =  -8.44e-05
> glmer.ML = 2075.4  Scale est. = 1         n = 10523
>
> summary(mg$mer)
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: poisson  ( log )
>
>      AIC      BIC   logLik deviance df.resid
>   5294.9   5331.2  -2642.4   5284.9    10518
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.8449 -0.0806 -0.0786 -0.0775  4.9384
>
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  g  (Intercept) 2.868    1.694
>  s (Intercept) 3.820    1.954
>  Xr      s(age) 0.000    0.000
> Number of obs: 10523, groups:  g, 1785; s, 1768; Xr, 8
>
> Fixed effects:
>                 Estimate Std. Error z value Pr(>|z|)
> X(Intercept)    -7.39218    0.19834  -37.27   <2e-16 ***
> Xs(age)Fx1  0.03669    0.08418    0.44    0.663
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             X(Int)
> Xs(age)F1 0.024
>
>
> Is this the right way to interpret it:
>
> 1) from the gam part I would conclude that the spline for the variable age has an estimated degree of freedom of 1, indicating that I might not need a spline. However, I understood that one can have a edf of 1 and there might still be a need for including a spline in the model (this part is very ambiguous for me, as I would think this alone should be indicative of a linear association). Either way, the spline term is not significantly associated with my outcome.
>
> 2) from the mer part I would conclude that the linear part of the variable age is not associated with my outcome, either.
>
> Based on this model, I can safely assume that age can be included in my regression model as a linear term, given there is nothing to suggest the association with my outcome is non-parametrical.
>
> I would then check the residuals, as you suggested, and if there is not any pattern, I should be ok without including a spline then.
>
> Does this sound like a reasonable explanation for not including a spline term in my regression model?
>
> Thank you so much. I apologize for these silly questions. I am just trying to assimilate way too much at once and I second guess everything I do since these are all difficult concepts to grasp for a beginner.
>
> Best,
> DaniNM
>
>
>
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Highland Statistics Ltd <highstat at highstat.com>
> Sent: Tuesday, October 24, 2017 2:00 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] compare two GAMM4 models using AICs
>
>
>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Tue, 24 Oct 2017 19:49:50 +0000
>>> From: dani <orchidn at live.com>
>>> To: "r-sig-mixed-models at r-project.org"
>>>     <r-sig-mixed-models at r-project.org>
>>> Subject: [R-sig-ME] compare two GAMM4 models using AICs
>>> Message-ID:
>>>     <MWHPR1201MB0029CE3D9C5EC1956640DB70D6470 at MWHPR1201MB0029.namprd12.prod.outlook.com>
>>>
>>>
>>> Content-Type: text/plain; charset="UTF-8"
>>>
>>> Hello everyone,
>>>
>>>
>>> I am fitting two gamm4 models because I would like to see whether
>>> there is justification for including a spline term for x1. Can this
>>> be done by comparing the AICs for the underlying mixed models (i.e.,
>>> the "mer" part) of the two models?
>>
>>
>
> Technically it won't crash..."so it can be done"..but I am not sure
> whether you want to do this. Internally, the smoother is written as a
> mixed model (X * b + Z * u)....and those random effects (which is part
> of the smoother) don't count towards the number of parameters.
>
>>> b1 <- gamm4(y~x1+offset(e),data=dat,random=~(1|fac))
>>
>>> b2 <- gamm4(y~x1+s(x1)+offset(e),data=dat,random=~(1|fac))
>>
>>
>>
>
>
> I am confused about your use of an offset in a Gaussian model, and I am
> confused why you would use x1 and s(x1) in the same model. The s(x1)
> already contains the linear part of the smoother.
>
> Why not fit the first model and inspect residuals for any patterns? If
> there are, then using a smoother is an option.
>
> Kind regards,
>
> Alain Zuur
>
>
>>
>>>
>>> summary(b1$gam)
>>>
>>> summary(b1$mer)
>>>
>>>
>>> summary(b2$gam)
>>>
>>> summary(b2$mer)
>>>
>>>
>>> AIC(b1$mer)
>>>
>>> AIC(b2$mer)
>>>
>>>
>>> Thank you very much!
>>>
>>> Best,
>>>
>>> DaniNM
>>>
>>> <http://aka.ms/weboutlook>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>>
>>
>
> --
>
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email: highstat at highstat.com
> URL:   www.highstat.com<http://www.highstat.com>
> Highland Statistics Ltd.<http://www.highstat.com/>
> www.highstat.com<http://www.highstat.com>
> Statistical consultancy, data analysis and software development. Specialized in time series analysis. Located in Scotland.
>
>
>
>
> And:
> NIOZ Royal Netherlands Institute for Sea Research,
> Department of Coastal Systems, and Utrecht University,
> P.O. Box 59, 1790 AB Den Burg,
> Texel, The Netherlands
>
>
>
> Author of:
> 1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
> 2. Beginner's Guide to Zero-Inflated Models with R (2016).
> 3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
> 4. Beginner's Guide to GAMM with R (2014).
> 5. Beginner's Guide to GLM and GLMM with R (2013).
> 6. Beginner's Guide to GAM with R (2012).
> 7. Zero Inflated Models and GLMM with R (2012).
> 8. A Beginner's Guide to R (2009).
> 9. Mixed effects models and extensions in ecology with R (2009).
> 10. Analysing Ecological Data (2007).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Nov  2 16:46:40 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 2 Nov 2017 15:46:40 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <MWHPR1201MB00291AE038C5166E63406142D65C0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1813389.GnyUOU5luO@vercors>
 <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ea1d4727-a03b-fd68-4d60-87d4c9bdf96e@ed.ac.uk>
 <MWHPR1201MB00291AE038C5166E63406142D65C0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <1fcd55c5-546f-650d-df80-ac114398b671@ed.ac.uk>

Hi Dani,


Its hard to tell without seeing the data, but my guess is that the poor 
mixing is due to there being no zero-inflation (and so the zi latent 
variables are heading to -infinity). exp(-0.09)=0.91 gives the 
probability of a zero from a standard Poission which is pretty close to 
your observed 95%. Also the variance is about double the mean suggesting 
over-dispersion. Add an over-dispersion parameter to the Poisson process 
(which MCMCglmm does automatically) and you would have even more zeros, 
quite possibly close to 95%. As I said its hard to know without seeing 
the data. You could run a standard Poisson and use posterior predictive 
tests to obtain a) the number of expected zeros and b) the 95% upper 
quantile of the observations and see if they are compatible with your data.


You can now do posterior predictive checks more easily now in MCMCglmm.


sim<-simulate(poisson_model, nsim=1000)


nzeros<-apply(sim, 2, function(x){sum(x==0)})

uq<-apply(sim, 2, function(x){quantile(x, 0.95)})


hist(nzeros)

abline(v=sum(s25h$y==0))


if the statistics calculated from the data are in the body of the 
histograms then an over-dispersed Poisson is probably accurate.


Cheers,


Jarrod


On 02/11/2017 15:28, dani wrote:
>
> Hi Jarrod,
>
>
> Thank you very much for your message!
>
> I think one of the main issues is the high degree of autocorrelation. 
> I tried to check for autocorrelation as Pierre suggested, but my 
> computer ran out of memory.
>
> Here are my answers to your questions:
>
> 1). There are 10523 observations? with a mean of 0.09; 95% of 
> observations are zero.
>
>
> value??N? ?raw %? ??valid %cumulative %
> 09946 ?94.52? ? ? ?94.5294.52
> 1372 3.54 3.54? ? ? ??98.05
> 2112 1.06? ? ? ? 1.06? ? ? ? 99.12
> 358 0.55 0.55? ? ? ?99.67
> 422? ? ? ??0.21 0.21? ? ? ?99.88
> 57? ? ? ??0.07??0.07? ? ? ?99.94
> 64? ? ? ??0.040.04 99.98
> 71? ? ? ??0.010.01 99.99
> 81? ? ? ??0.01 0.01 100.00
>
> missing00.00
>
> total N=10523 ? valid N=10523 ? x?=0.09 ? ?=0.44
>
> 2)?group 1:??1768 level
>
> ? ? group 2:??1857? levels
>
>
> 3) I attached the histogram of the latent variable.
>
>
> 4) I would like a model with two random intercepts (group 1 and 2) and 
> I am not sure how to do that with a zero inflation term.
>
>
> Thank you so much for taking the time to help me with this.
>
> Best regards,
>
> DNM
>
>
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> 
> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk>
> *Sent:* Wednesday, November 1, 2017 1:42 PM
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective 
> sample size?
> Hi,
>
> I would try and diagnose why the mixing is bad first.
>
> 1) How many observations are there, what is their mean and how many are
> zero?
> 2) How many levels are there to group1 and group2?
> 3) What is the range of the latent variable for the zero inflation?
> Include pl=TRUE in the call to MCMCglmm and plot a histogram of
>
> model$Liab[,(ncol(model$Liab)/2+1):ncol(model$Liab)])
>
> 4) why do you have random effects for zero-inflation but choose to
> ignore it in the fixed effects?
>
> Cheers,
>
> Jarrod
>
> On 01/11/2017 20:31, dani wrote:
> > Thanks, Pierre! Will do that, too!
> >
> > Best,
> > DNM
> >
> > ________________________________
> > From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> > Sent: Wednesday, November 1, 2017 1:25 PM
> > To: dani
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective 
> sample size?
> >
> > You can look at the auto-correlation to guess how many more 
> iterations are needed to increase your sample size. Something like:
> >
> > library(coda)
> > autocorr.diag(mj$Sol)
> > autocorr.diag(mj$VCV)
> >
> > Cheers,
> > Pierre
> >
> > On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
> >> Hello Pierre and list members,
> >>
> >>
> >> Thank you so much! The analysis with the new prior worked:) 
> However, the effective samples are still small, so I am trying again 
> the new prior with more iterations - will report back how my effective 
> samples change.
> >>
> >>
> >> Best regards, everyone!
> >>
> >> DNM
> >>
> >>
> >> ________________________________
> >> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
> >> Sent: Tuesday, October 31, 2017 10:11 PM
> >> To: dani
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective 
> sample size?
> >>
> >> Just some parentheses issue:
> >> priori <- list(R=list(V=diag(2), nu=1, fix=2),
> >>???????????????? G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), 
> alpha.V=diag(2)*1000),
> >>??????????????????????? G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), 
> alpha.V=diag(2)*1000)))
> >>
> >> Cheers,
> >> Pierre
> >>
> >> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
> >>> Hi Pierre,
> >>>
> >>> I tried using the new prior you suggested and I got this error:
> >>>
> >>> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
> >>>??? prior list should contain elements R, G, and/or B only
> >>>
> >>> I am not sure what to do about this:)
> >>> Any advice would be very much appreciated.
> >>>
> >>> Thanks,
> >>> DaniNM
> >>> <http://aka.ms/weboutlook>
> >>>
> >>>
> >>> ________________________________
> >>> From: R-sig-mixed-models 
> <r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de 
> Villemereuil <pierre.de.villemereuil at mailoo.org>
> >>> Sent: Tuesday, October 31, 2017 2:08 PM
> >>> To: r-sig-mixed-models at r-project.org
> >>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective 
> sample size?
> >>>
> >>> Hi,
> >>>
> >>> There are about three way to increase effective sample size:
> >>> - increase the number of iterations
> >>> - use a prior with better properties
> >>> - change your model somehow (you might not always want to use that 
> one...)
> >>>
> >>> In your case, using a slightly more informative prior and the 
> extended parameters prior might help? Something like:
> >>>
> >>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
> >>>???????????????? G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), 
> alpha.V=diag(2)*1000)),
> >>>                                                  G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
> >>>
> >>> Hope this helps,
> >>> Pierre.
> >>>
> >>> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
> >>>> Dear list members,
> >>>>
> >>>> I need some advice regarding this ZIP MCMCglmm model:
> >>>>
> >>>> library(MCMCglmm)
> >>>>
> >>>> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
> >>>> G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
> >>>>
> >>>> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 
> +x6+x7+ offset),
> >>>>??????????????????? random = ~idh(trait):group1 + idh(trait):group2,
> >>>>??????????????????? family = "zipoisson",
> >>>>??????????????????? prior = priori,
> >>>>??????????????????? rcov = ~idh(trait):units,
> >>>>???????????????? verbose=FALSE,
> >>>>???????????????? thin?? = 100,
> >>>>???????????????? burnin = 3000,
> >>>>???????????????? nitt?? = 103000,
> >>>>???????????????? saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, 
> pl=FALSE,
> >>>>???????????????? data = s25h)
> >>>>
> >>>> summary(mj)
> >>>>
> >>>> # Iterations = 3001:102901
> >>>> # Thinning interval? = 100
> >>>> # Sample size? = 1000
> >>>> #
> >>>> # DIC: 4811.791
> >>>> #
> >>>> # G-structure:? ~idh(trait):group1
> >>>> #
> >>>> # post.mean l-95% CI u-95% CI eff.samp
> >>>> # traity.group1?????? 0.4307?? 0.1351 0.9281??? 10.17
> >>>> # traitzi_y. group1? 4.3196?? 2.1216 7.4310??? 31.26
> >>>> #
> >>>> # ~idh(trait):group2
> >>>> #
> >>>> # post.mean l-95% CI u-95% CI eff.samp
> >>>> # traity. group2?????? 0.4233 0.2341?? 0.6781??? 30.81
> >>>> # traitzi_y. group2??? 3.5497 1.2365?? 6.1525??? 26.39
> >>>> #
> >>>> # R-structure:? ~idh(trait):units
> >>>> #
> >>>> #??????????????????????????? post.mean l-95% CI u-95% CI eff.samp
> >>>> # traity.units????? 0.02393 0.002833 0.06621??? 10.58
> >>>> # traitzi_y.units?? 1.00000 1.000000 1.00000???? 0.00
> >>>> #
> >>>> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + 
> x3 + x4 + x5 + x6 + x7 + offset)
> >>>> #
> >>>> # post.mean?? l-95% CI?? u-95% CI eff.samp? pMCMC
> >>>> # traity -4.3823820 -6.1496186 -2.6424402?? 23.592 <0.001 ***
> >>>> # traitzi_y 3.4696204? 2.6430476? 4.1392235??? 1.922 <0.001 ***
> >>>> # at.level(trait, 1):x1???????????????????????? -0.0498043 
> -0.2192051 0.1097667?? 16.979? 0.522
> >>>> # at.level(trait, 1):x2M???????????????????? -0.2088408 
> -0.4535085 0.0440055??? 8.727? 0.088 .
> >>>> # at.level(trait, 1):x31?????????????????????? 0.1422342 
> -0.1473884 0.4199985?? 11.521? 0.288
> >>>> # at.level(trait, 1):x4???????????????????????? 0.0007054 
> -0.0030953 0.0043456?? 24.299? 0.680
> >>>> # at.level(trait, 1):x5???????????????????????? 0.1131704? 
> 0.0647184 0.1676469?? 26.621 <0.001 ***
> >>>> # at.level(trait, 1):x6??????????????????????? -0.0128734 
> -0.0483344 0.0306350?? 13.599? 0.588
> >>>> # at.level(trait, 1):x7???????????????????????? 0.0102356 
> -0.0276141 0.0540893?? 40.746? 0.680
> >>>> # at.level(trait, 1):offset?????????????????? 1.3511873? 
> 0.6963525 2.1299075?? 13.216 <0.001 ***
> >>>> #?? ---
> >>>> #?? Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>>
> >>>> I would like to increase my effective samples, but I am not sure 
> which way to go. I tried increasing the NITT to 503000, but the 
> effective samples actually got worse. Is there anything else I could 
> do? I plan on dropping some variables from the model, but if I were to 
> proceed with the model above, what could I have done better?
> >>>>
> >>>> Thanks in advance!
> >>>> DNM
> >>>> <http://aka.ms/weboutlook>
> >>>>
> >>>>???????? [[alternative HTML version deleted]]
> >>>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
>
>
>
> > R-sig-mixed-models Info Page - 
> stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> R-sig-mixed-models Info Page - stat.ethz.ch 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
>
>
>
> > stat.ethz.ch
> > Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
> >
> >
> >
> >> R-sig-mixed-models Info Page - 
> stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> R-sig-mixed-models Info Page - stat.ethz.ch 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
>
>
>
> >> stat.ethz.ch
> >> Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
> >>
> >>
> >>
> >
> >??????? [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
>
>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> R-sig-mixed-models Info Page - stat.ethz.ch 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy 
> password below. This provides only mild security, but should prevent 
> others from messing ...
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20171102/d6b128c2/attachment-0001.ksh>

From highstat at highstat.com  Thu Nov  2 20:17:23 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 2 Nov 2017 19:17:23 +0000
Subject: [R-sig-ME] ggplot of Hurdle model
Message-ID: <ffd9112d-9803-60d4-4b1d-cfb0b0a3b529@highstat.com>


> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 2 Nov 2017 14:52:29 +0100
> From: andreu blanco <andreu.blanco at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] ggplot of Hurdle model
> Message-ID:
> <CAOy7hbCs_niPqWPN-u+zDrgSczfi9J1pHFbPhTc6L_WunY35DQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> According to the information in the Zuur's book "Begginers guide to
> Zero-inflated models with R", I see they suggest a graph to add to the
> research paper. However I don't know how to sketch the model fit to my
> results.
That book contains fully worked out ggplot2 code to sketch the two 
individual components of a hurdle model, and also the expected values of 
the actual hurdle model. Based on your str output below I see you have 
only factors and biomass. So..you can visualise the Bernoulli GLM, and 
you can also visualise the Gamma GLM. Just use geom_errorbar instead of 
geom_ribbon when plotting the results (because you only have factors). 
Being a PhD student means that you should be able to figure this out.

Note that 80 observations is rather small for the things that you are 
(probably) doing. I hope there are no random effects involved.....though 
given the fact that you use glmer it seems that you do.

Kind regards,

Alain

>
> My data structure is:
>
>> str(Aarmata)
> 'data.frame': 80 obs. of? 6 variables:
> ? $ Location? : Factor w/ 8 levels "C1","C2","O",..: 1 1 1 1 1 5 5 5 5 
> 5 ...
> ? $ Protection: Factor w/ 2 levels "C","P": 1 1 1 1 1 2 2 2 2 2 ...
> ? $ Exposure? : Factor w/ 2 levels "E","S": 1 1 1 1 1 1 1 1 1 1 ...
> ? $ replicates: int? 1 2 3 4 5 1 2 3 4 5 ...
> ? $ Biomass?? : num? 124.8 104.8 139.2 102.6 62.9 ...
>
> Any suggestion would be highly appreciated.
>
> Andreu

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL: www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological 
Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


	[[alternative HTML version deleted]]


From orchidn at live.com  Fri Nov  3 15:56:33 2017
From: orchidn at live.com (dani)
Date: Fri, 3 Nov 2017 14:56:33 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <1fcd55c5-546f-650d-df80-ac114398b671@ed.ac.uk>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1813389.GnyUOU5luO@vercors>
 <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ea1d4727-a03b-fd68-4d60-87d4c9bdf96e@ed.ac.uk>
 <MWHPR1201MB00291AE038C5166E63406142D65C0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <1fcd55c5-546f-650d-df80-ac114398b671@ed.ac.uk>
Message-ID: <MWHPR1201MB00295895A1C60E5C0C35DB8AD65D0@MWHPR1201MB0029.namprd12.prod.outlook.com>


Hi Jarrod,


Thank you so much for your detailed and extremely helpful message!


I tried to post the message below plus some images showing the histograms, but the message was too large, so I am only sending the text here. I will send the images separately.


_______________________________________________________________


Yes, I was a bit puzzled about zero-inflation and overdispersion, because I ran a GLMER - Poisson and  a GLMER - negative binomial as well as two glmmTMB (Poisson and negative binomial) models before getting a little bit more familiar with MCMCglmm.


I ran the glmmTMB models for both cases: for no zero inflation and for zero inflation. The tests for zero-inflation and overdispersion indicated the data presented zero-inflation and overdispersion, yet the AICs of the models were better for the no zero inflation models. I attached the histograms of the expected zeros for the two GLMER. I also ran all null models, including null models with only one random intercept or none, to be able to calculate ICCs and test the significance of the cross-classified random effects.


I attached a table showing the AICs and DICs for some of the models I ran. In the case of the models with zero inflation, some of the null models (with either one of the two random effects) did not converge, so I believe the zero-inflation models perform worse than the models that do not account for zero inflation.


In the case of the MCMCglmm models, again, as you suggested - the results seem better for the models without zero-inflation. The sample sizes are ok-ish (around 200 or so). I attached the histogram I obtained using the script you suggested.


It seems that MCMCglmm does not accommodate negative binomial distributions, is that right? In that case,


I would like to compare the three types of models (GLMER, glmmTMB, and MCMCglmm) for Poisson distributions and it looks like I should only include the models without zero inflation. I am not sure, though, if I need to further account for overdispersion in the case of the GLMER or glmmTMB models.

Thank you so much for all your help with this!
Greetings to all list members!
Best,
DNM
<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Thursday, November 2, 2017 8:46 AM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?


Hi Dani,


Its hard to tell without seeing the data, but my guess is that the poor mixing is due to there being no zero-inflation (and so the zi latent variables are heading to -infinity). exp(-0.09)=0.91 gives the probability of a zero from a standard Poission which is pretty close to your observed 95%. Also the variance is about double the mean suggesting over-dispersion. Add an over-dispersion parameter to the Poisson process (which MCMCglmm does automatically) and you would have even more zeros, quite possibly close to 95%. As I said its hard to know without seeing the data. You could run a standard Poisson and use posterior predictive tests to obtain a) the number of expected zeros and b) the 95% upper quantile of the observations and see if they are compatible with your data.


You can now do posterior predictive checks more easily now in MCMCglmm.


sim<-simulate(poisson_model, nsim=1000)


nzeros<-apply(sim, 2, function(x){sum(x==0)})

uq<-apply(sim, 2, function(x){quantile(x, 0.95)})


hist(nzeros)

abline(v=sum(s25h$y==0))


if the statistics calculated from the data are in the body of the histograms then an over-dispersed Poisson is probably accurate.


Cheers,


Jarrod

On 02/11/2017 15:28, dani wrote:

Hi Jarrod,


Thank you very much for your message!

I think one of the main issues is the high degree of autocorrelation. I tried to check for autocorrelation as Pierre suggested, but my computer ran out of memory.

Here are my answers to your questions:

1). There are 10523 observations  with a mean of 0.09; 95% of observations are zero.

value  N    raw %     valid % cumulative %
0 9946       94.52       94.52 94.52
1 372   3.54  3.54         98.05
2 112    1.06         1.06         99.12
3 58     0.55  0.55        99.67
4 22         0.21  0.21        99.88
5 7         0.07         0.07        99.94
6 4         0.04         0.04   99.98
7 1         0.01         0.01   99.99
8 1         0.01   0.01  100.00

missing 0 0.00

total N=10523 ? valid N=10523 ? x?=0.09 ? ?=0.44


2) group 1:  1768 level

    group 2:  1857  levels


3) I attached the histogram of the latent variable.


4) I would like a model with two random intercepts (group 1 and 2) and I am not sure how to do that with a zero inflation term.


Thank you so much for taking the time to help me with this.

Best regards,

DNM

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, November 1, 2017 1:42 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

Hi,

I would try and diagnose why the mixing is bad first.

1) How many observations are there, what is their mean and how many are
zero?
2) How many levels are there to group1 and group2?
3) What is the range of the latent variable for the zero inflation?
Include pl=TRUE in the call to MCMCglmm and plot a histogram of

model$Liab[,(ncol(model$Liab)/2+1):ncol(model$Liab)])

4) why do you have random effects for zero-inflation but choose to
ignore it in the fixed effects?

Cheers,

Jarrod

On 01/11/2017 20:31, dani wrote:
> Thanks, Pierre! Will do that, too!
>
> Best,
> DNM
>
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
> Sent: Wednesday, November 1, 2017 1:25 PM
> To: dani
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>
> You can look at the auto-correlation to guess how many more iterations are needed to increase your sample size. Something like:
>
> library(coda)
> autocorr.diag(mj$Sol)
> autocorr.diag(mj$VCV)
>
> Cheers,
> Pierre
>
> On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
>> Hello Pierre and list members,
>>
>>
>> Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.
>>
>>
>> Best regards, everyone!
>>
>> DNM
>>
>>
>> ________________________________
>> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
>> Sent: Tuesday, October 31, 2017 10:11 PM
>> To: dani
>> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>
>> Just some parentheses issue:
>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
>>                        G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>
>> Cheers,
>> Pierre
>>
>> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
>>> Hi Pierre,
>>>
>>> I tried using the new prior you suggested and I got this error:
>>>
>>> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
>>>    prior list should contain elements R, G, and/or B only
>>>
>>> I am not sure what to do about this:)
>>> Any advice would be very much appreciated.
>>>
>>> Thanks,
>>> DaniNM
>>> <http://aka.ms/weboutlook>
>>>
>>>
>>> ________________________________
>>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
>>> Sent: Tuesday, October 31, 2017 2:08 PM
>>> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>>
>>> Hi,
>>>
>>> There are about three way to increase effective sample size:
>>> - increase the number of iterations
>>> - use a prior with better properties
>>> - change your model somehow (you might not always want to use that one...)
>>>
>>> In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
>>>
>>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
>>>                                                   G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
>>>
>>> Hope this helps,
>>> Pierre.
>>>
>>> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
>>>> Dear list members,
>>>>
>>>> I need some advice regarding this ZIP MCMCglmm model:
>>>>
>>>> library(MCMCglmm)
>>>>
>>>> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>>>>                 G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>>>>
>>>> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>>>>                    random = ~idh(trait):group1 + idh(trait):group2,
>>>>                    family = "zipoisson",
>>>>                    prior = priori,
>>>>                    rcov = ~idh(trait):units,
>>>>                 verbose=FALSE,
>>>>                 thin   = 100,
>>>>                 burnin = 3000,
>>>>                 nitt   = 103000,
>>>>                 saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>>>>                 data = s25h)
>>>>
>>>> summary(mj)
>>>>
>>>> # Iterations = 3001:102901
>>>> # Thinning interval  = 100
>>>> # Sample size  = 1000
>>>> #
>>>> # DIC: 4811.791
>>>> #
>>>> # G-structure:  ~idh(trait):group1
>>>> #
>>>> #                                post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.group1       0.4307   0.1351   0.9281    10.17
>>>> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
>>>> #
>>>> # ~idh(trait):group2
>>>> #
>>>> #                              post.mean l-95% CI u-95% CI eff.samp
>>>> # traity. group2       0.4233   0.2341   0.6781    30.81
>>>> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
>>>> #
>>>> # R-structure:  ~idh(trait):units
>>>> #
>>>> #                            post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.units      0.02393 0.002833  0.06621    10.58
>>>> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
>>>> #
>>>> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
>>>> #
>>>> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>>>> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
>>>> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
>>>> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
>>>> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
>>>> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
>>>> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
>>>> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
>>>> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
>>>> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
>>>> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
>>>> #   ---
>>>> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
>>>>
>>>> Thanks in advance!
>>>> DNM
>>>> <http://aka.ms/weboutlook>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>> stat.ethz.ch
>> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>>
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...




	[[alternative HTML version deleted]]


From orchidn at live.com  Fri Nov  3 16:07:49 2017
From: orchidn at live.com (dani)
Date: Fri, 3 Nov 2017 15:07:49 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <1fcd55c5-546f-650d-df80-ac114398b671@ed.ac.uk>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1813389.GnyUOU5luO@vercors>
 <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ea1d4727-a03b-fd68-4d60-87d4c9bdf96e@ed.ac.uk>
 <MWHPR1201MB00291AE038C5166E63406142D65C0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <1fcd55c5-546f-650d-df80-ac114398b671@ed.ac.uk>
Message-ID: <MWHPR1201MB0029E64942E3D81662976726D65D0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


Please find attached the images for my previous message.

Thanks,

DNM

________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Thursday, November 2, 2017 8:46 AM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?


Hi Dani,


Its hard to tell without seeing the data, but my guess is that the poor mixing is due to there being no zero-inflation (and so the zi latent variables are heading to -infinity). exp(-0.09)=0.91 gives the probability of a zero from a standard Poission which is pretty close to your observed 95%. Also the variance is about double the mean suggesting over-dispersion. Add an over-dispersion parameter to the Poisson process (which MCMCglmm does automatically) and you would have even more zeros, quite possibly close to 95%. As I said its hard to know without seeing the data. You could run a standard Poisson and use posterior predictive tests to obtain a) the number of expected zeros and b) the 95% upper quantile of the observations and see if they are compatible with your data.


You can now do posterior predictive checks more easily now in MCMCglmm.


sim<-simulate(poisson_model, nsim=1000)


nzeros<-apply(sim, 2, function(x){sum(x==0)})

uq<-apply(sim, 2, function(x){quantile(x, 0.95)})


hist(nzeros)

abline(v=sum(s25h$y==0))


if the statistics calculated from the data are in the body of the histograms then an over-dispersed Poisson is probably accurate.


Cheers,


Jarrod

On 02/11/2017 15:28, dani wrote:

Hi Jarrod,


Thank you very much for your message!

I think one of the main issues is the high degree of autocorrelation. I tried to check for autocorrelation as Pierre suggested, but my computer ran out of memory.

Here are my answers to your questions:

1). There are 10523 observations  with a mean of 0.09; 95% of observations are zero.

value  N    raw %     valid % cumulative %
0 9946       94.52       94.52 94.52
1 372   3.54  3.54         98.05
2 112    1.06         1.06         99.12
3 58     0.55  0.55        99.67
4 22         0.21  0.21        99.88
5 7         0.07         0.07        99.94
6 4         0.04         0.04   99.98
7 1         0.01         0.01   99.99
8 1         0.01   0.01  100.00

missing 0 0.00

total N=10523 ? valid N=10523 ? x?=0.09 ? ?=0.44


2) group 1:  1768 level

    group 2:  1857  levels


3) I attached the histogram of the latent variable.


4) I would like a model with two random intercepts (group 1 and 2) and I am not sure how to do that with a zero inflation term.


Thank you so much for taking the time to help me with this.

Best regards,

DNM

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, November 1, 2017 1:42 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

Hi,

I would try and diagnose why the mixing is bad first.

1) How many observations are there, what is their mean and how many are
zero?
2) How many levels are there to group1 and group2?
3) What is the range of the latent variable for the zero inflation?
Include pl=TRUE in the call to MCMCglmm and plot a histogram of

model$Liab[,(ncol(model$Liab)/2+1):ncol(model$Liab)])

4) why do you have random effects for zero-inflation but choose to
ignore it in the fixed effects?

Cheers,

Jarrod

On 01/11/2017 20:31, dani wrote:
> Thanks, Pierre! Will do that, too!
>
> Best,
> DNM
>
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
> Sent: Wednesday, November 1, 2017 1:25 PM
> To: dani
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>
> You can look at the auto-correlation to guess how many more iterations are needed to increase your sample size. Something like:
>
> library(coda)
> autocorr.diag(mj$Sol)
> autocorr.diag(mj$VCV)
>
> Cheers,
> Pierre
>
> On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
>> Hello Pierre and list members,
>>
>>
>> Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.
>>
>>
>> Best regards, everyone!
>>
>> DNM
>>
>>
>> ________________________________
>> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
>> Sent: Tuesday, October 31, 2017 10:11 PM
>> To: dani
>> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>
>> Just some parentheses issue:
>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
>>                        G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>
>> Cheers,
>> Pierre
>>
>> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
>>> Hi Pierre,
>>>
>>> I tried using the new prior you suggested and I got this error:
>>>
>>> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
>>>    prior list should contain elements R, G, and/or B only
>>>
>>> I am not sure what to do about this:)
>>> Any advice would be very much appreciated.
>>>
>>> Thanks,
>>> DaniNM
>>> <http://aka.ms/weboutlook>
>>>
>>>
>>> ________________________________
>>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
>>> Sent: Tuesday, October 31, 2017 2:08 PM
>>> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>>
>>> Hi,
>>>
>>> There are about three way to increase effective sample size:
>>> - increase the number of iterations
>>> - use a prior with better properties
>>> - change your model somehow (you might not always want to use that one...)
>>>
>>> In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
>>>
>>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
>>>                                                   G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
>>>
>>> Hope this helps,
>>> Pierre.
>>>
>>> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
>>>> Dear list members,
>>>>
>>>> I need some advice regarding this ZIP MCMCglmm model:
>>>>
>>>> library(MCMCglmm)
>>>>
>>>> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>>>>                 G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>>>>
>>>> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>>>>                    random = ~idh(trait):group1 + idh(trait):group2,
>>>>                    family = "zipoisson",
>>>>                    prior = priori,
>>>>                    rcov = ~idh(trait):units,
>>>>                 verbose=FALSE,
>>>>                 thin   = 100,
>>>>                 burnin = 3000,
>>>>                 nitt   = 103000,
>>>>                 saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>>>>                 data = s25h)
>>>>
>>>> summary(mj)
>>>>
>>>> # Iterations = 3001:102901
>>>> # Thinning interval  = 100
>>>> # Sample size  = 1000
>>>> #
>>>> # DIC: 4811.791
>>>> #
>>>> # G-structure:  ~idh(trait):group1
>>>> #
>>>> #                                post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.group1       0.4307   0.1351   0.9281    10.17
>>>> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
>>>> #
>>>> # ~idh(trait):group2
>>>> #
>>>> #                              post.mean l-95% CI u-95% CI eff.samp
>>>> # traity. group2       0.4233   0.2341   0.6781    30.81
>>>> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
>>>> #
>>>> # R-structure:  ~idh(trait):units
>>>> #
>>>> #                            post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.units      0.02393 0.002833  0.06621    10.58
>>>> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
>>>> #
>>>> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
>>>> #
>>>> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>>>> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
>>>> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
>>>> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
>>>> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
>>>> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
>>>> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
>>>> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
>>>> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
>>>> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
>>>> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
>>>> #   ---
>>>> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
>>>>
>>>> Thanks in advance!
>>>> DNM
>>>> <http://aka.ms/weboutlook>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>> stat.ethz.ch
>> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>>
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...




From orchidn at live.com  Fri Nov  3 16:40:54 2017
From: orchidn at live.com (dani)
Date: Fri, 3 Nov 2017 15:40:54 +0000
Subject: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
In-Reply-To: <MWHPR1201MB00295895A1C60E5C0C35DB8AD65D0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00296037AF64064FFF25B2F2D6440@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <2693603.WQtUsETXuI@flyosflip>
 <MWHPR1201MB002937154B1A6E83B6A50D9BD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <1813389.GnyUOU5luO@vercors>
 <MWHPR1201MB00297CDD81088332C252D01CD65F0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ea1d4727-a03b-fd68-4d60-87d4c9bdf96e@ed.ac.uk>
 <MWHPR1201MB00291AE038C5166E63406142D65C0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <1fcd55c5-546f-650d-df80-ac114398b671@ed.ac.uk>,
 <MWHPR1201MB00295895A1C60E5C0C35DB8AD65D0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <MWHPR1201MB0029FEB70E5110C1FCA2111BD65D0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


Sorry for sending so many messages, my messages cannot be sent given their size. I re-attached the images.

DNM


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of dani <orchidn at live.com>
Sent: Friday, November 3, 2017 7:56 AM
To: Jarrod Hadfield; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?


Hi Jarrod,


Thank you so much for your detailed and extremely helpful message!


I tried to post the message below plus some images showing the histograms, but the message was too large, so I am only sending the text here. I will send the images separately.


_______________________________________________________________


Yes, I was a bit puzzled about zero-inflation and overdispersion, because I ran a GLMER - Poisson and  a GLMER - negative binomial as well as two glmmTMB (Poisson and negative binomial) models before getting a little bit more familiar with MCMCglmm.


I ran the glmmTMB models for both cases: for no zero inflation and for zero inflation. The tests for zero-inflation and overdispersion indicated the data presented zero-inflation and overdispersion, yet the AICs of the models were better for the no zero inflation models. I attached the histograms of the expected zeros for the two GLMER. I also ran all null models, including null models with only one random intercept or none, to be able to calculate ICCs and test the significance of the cross-classified random effects.


I attached a table showing the AICs and DICs for some of the models I ran. In the case of the models with zero inflation, some of the null models (with either one of the two random effects) did not converge, so I believe the zero-inflation models perform worse than the models that do not account for zero inflation.


In the case of the MCMCglmm models, again, as you suggested - the results seem better for the models without zero-inflation. The sample sizes are ok-ish (around 200 or so). I attached the histogram I obtained using the script you suggested.


It seems that MCMCglmm does not accommodate negative binomial distributions, is that right? In that case,


I would like to compare the three types of models (GLMER, glmmTMB, and MCMCglmm) for Poisson distributions and it looks like I should only include the models without zero inflation. I am not sure, though, if I need to further account for overdispersion in the case of the GLMER or glmmTMB models.

Thank you so much for all your help with this!
Greetings to all list members!
Best,
DNM
<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Thursday, November 2, 2017 8:46 AM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?


Hi Dani,


Its hard to tell without seeing the data, but my guess is that the poor mixing is due to there being no zero-inflation (and so the zi latent variables are heading to -infinity). exp(-0.09)=0.91 gives the probability of a zero from a standard Poission which is pretty close to your observed 95%. Also the variance is about double the mean suggesting over-dispersion. Add an over-dispersion parameter to the Poisson process (which MCMCglmm does automatically) and you would have even more zeros, quite possibly close to 95%. As I said its hard to know without seeing the data. You could run a standard Poisson and use posterior predictive tests to obtain a) the number of expected zeros and b) the 95% upper quantile of the observations and see if they are compatible with your data.


You can now do posterior predictive checks more easily now in MCMCglmm.


sim<-simulate(poisson_model, nsim=1000)


nzeros<-apply(sim, 2, function(x){sum(x==0)})

uq<-apply(sim, 2, function(x){quantile(x, 0.95)})


hist(nzeros)

abline(v=sum(s25h$y==0))


if the statistics calculated from the data are in the body of the histograms then an over-dispersed Poisson is probably accurate.


Cheers,


Jarrod

On 02/11/2017 15:28, dani wrote:

Hi Jarrod,


Thank you very much for your message!

I think one of the main issues is the high degree of autocorrelation. I tried to check for autocorrelation as Pierre suggested, but my computer ran out of memory.

Here are my answers to your questions:

1). There are 10523 observations  with a mean of 0.09; 95% of observations are zero.

value  N    raw %     valid % cumulative %
0 9946       94.52       94.52 94.52
1 372   3.54  3.54         98.05
2 112    1.06         1.06         99.12
3 58     0.55  0.55        99.67
4 22         0.21  0.21        99.88
5 7         0.07         0.07        99.94
6 4         0.04         0.04   99.98
7 1         0.01         0.01   99.99
8 1         0.01   0.01  100.00

missing 0 0.00

total N=10523 ? valid N=10523 ? x?=0.09 ? ?=0.44


2) group 1:  1768 level

    group 2:  1857  levels


3) I attached the histogram of the latent variable.


4) I would like a model with two random intercepts (group 1 and 2) and I am not sure how to do that with a zero inflation term.


Thank you so much for taking the time to help me with this.

Best regards,

DNM

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, November 1, 2017 1:42 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?

Hi,

I would try and diagnose why the mixing is bad first.

1) How many observations are there, what is their mean and how many are
zero?
2) How many levels are there to group1 and group2?
3) What is the range of the latent variable for the zero inflation?
Include pl=TRUE in the call to MCMCglmm and plot a histogram of

model$Liab[,(ncol(model$Liab)/2+1):ncol(model$Liab)])

4) why do you have random effects for zero-inflation but choose to
ignore it in the fixed effects?

Cheers,

Jarrod

On 01/11/2017 20:31, dani wrote:
> Thanks, Pierre! Will do that, too!
>
> Best,
> DNM
>
> ________________________________
> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
> Sent: Wednesday, November 1, 2017 1:25 PM
> To: dani
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>
> You can look at the auto-correlation to guess how many more iterations are needed to increase your sample size. Something like:
>
> library(coda)
> autocorr.diag(mj$Sol)
> autocorr.diag(mj$VCV)
>
> Cheers,
> Pierre
>
> On Wednesday, 1 November 2017 20:14:15 NZDT dani wrote:
>> Hello Pierre and list members,
>>
>>
>> Thank you so much! The analysis with the new prior worked:) However, the effective samples are still small, so I am trying again the new prior with more iterations - will report back how my effective samples change.
>>
>>
>> Best regards, everyone!
>>
>> DNM
>>
>>
>> ________________________________
>> From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
>> Sent: Tuesday, October 31, 2017 10:11 PM
>> To: dani
>> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>
>> Just some parentheses issue:
>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),
>>                        G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>
>> Cheers,
>> Pierre
>>
>> Le mercredi 1 novembre 2017, 17:18:05 NZDT dani a ?crit :
>>> Hi Pierre,
>>>
>>> I tried using the new prior you suggested and I got this error:
>>>
>>> Error in MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+:
>>>    prior list should contain elements R, G, and/or B only
>>>
>>> I am not sure what to do about this:)
>>> Any advice would be very much appreciated.
>>>
>>> Thanks,
>>> DaniNM
>>> <http://aka.ms/weboutlook>
>>>
>>>
>>> ________________________________
>>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org><mailto:pierre.de.villemereuil at mailoo.org>
>>> Sent: Tuesday, October 31, 2017 2:08 PM
>>> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>>> Subject: Re: [R-sig-ME] ZIP MCMCglmm - how to increase effective sample size?
>>>
>>> Hi,
>>>
>>> There are about three way to increase effective sample size:
>>> - increase the number of iterations
>>> - use a prior with better properties
>>> - change your model somehow (you might not always want to use that one...)
>>>
>>> In your case, using a slightly more informative prior and the extended parameters prior might help? Something like:
>>>
>>> priori <- list(R=list(V=diag(2), nu=1, fix=2),
>>>                 G=list(G1=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)),
>>>                                                   G2=list(V=diag(2)/2, nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000))))
>>>
>>> Hope this helps,
>>> Pierre.
>>>
>>> On Wednesday, 25 October 2017 18:45:46 NZDT dani wrote:
>>>> Dear list members,
>>>>
>>>> I need some advice regarding this ZIP MCMCglmm model:
>>>>
>>>> library(MCMCglmm)
>>>>
>>>> priori <- list(R=list(V=diag(2), nu=0.002,fix=2),
>>>>                 G=list(G1=list(V=diag(2), n=2),G2=list(V=diag(2), n=2)))
>>>>
>>>> mj <- MCMCglmm(y ~ trait - 1 + at.level(trait,1):(x1+x2+x3+x4+ x5 +x6+x7+ offset),
>>>>                    random = ~idh(trait):group1 + idh(trait):group2,
>>>>                    family = "zipoisson",
>>>>                    prior = priori,
>>>>                    rcov = ~idh(trait):units,
>>>>                 verbose=FALSE,
>>>>                 thin   = 100,
>>>>                 burnin = 3000,
>>>>                 nitt   = 103000,
>>>>                 saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=FALSE,
>>>>                 data = s25h)
>>>>
>>>> summary(mj)
>>>>
>>>> # Iterations = 3001:102901
>>>> # Thinning interval  = 100
>>>> # Sample size  = 1000
>>>> #
>>>> # DIC: 4811.791
>>>> #
>>>> # G-structure:  ~idh(trait):group1
>>>> #
>>>> #                                post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.group1       0.4307   0.1351   0.9281    10.17
>>>> # traitzi_y. group1  4.3196   2.1216   7.4310    31.26
>>>> #
>>>> # ~idh(trait):group2
>>>> #
>>>> #                              post.mean l-95% CI u-95% CI eff.samp
>>>> # traity. group2       0.4233   0.2341   0.6781    30.81
>>>> # traitzi_y. group2    3.5497   1.2365   6.1525    26.39
>>>> #
>>>> # R-structure:  ~idh(trait):units
>>>> #
>>>> #                            post.mean l-95% CI u-95% CI eff.samp
>>>> # traity.units      0.02393 0.002833  0.06621    10.58
>>>> # traitzi_y.units   1.00000 1.000000  1.00000     0.00
>>>> #
>>>> # Location effects: y ~ trait - 1 + at.level(trait, 1):(x1 + x2 + x3 + x4 + x5 + x6 + x7 + offset)
>>>> #
>>>> #                                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>>>> # traity                                               -4.3823820 -6.1496186 -2.6424402   23.592 <0.001 ***
>>>> # traitzi_y                                           3.4696204  2.6430476  4.1392235    1.922 <0.001 ***
>>>> # at.level(trait, 1):x1                         -0.0498043 -0.2192051  0.1097667   16.979  0.522
>>>> # at.level(trait, 1):x2M                     -0.2088408 -0.4535085  0.0440055    8.727  0.088 .
>>>> # at.level(trait, 1):x31                       0.1422342 -0.1473884  0.4199985   11.521  0.288
>>>> # at.level(trait, 1):x4                         0.0007054 -0.0030953  0.0043456   24.299  0.680
>>>> # at.level(trait, 1):x5                         0.1131704  0.0647184  0.1676469   26.621 <0.001 ***
>>>> # at.level(trait, 1):x6                        -0.0128734 -0.0483344  0.0306350   13.599  0.588
>>>> # at.level(trait, 1):x7                         0.0102356 -0.0276141  0.0540893   40.746  0.680
>>>> # at.level(trait, 1):offset                   1.3511873  0.6963525  2.1299075   13.216 <0.001 ***
>>>> #   ---
>>>> #   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> I would like to increase my effective samples, but I am not sure which way to go. I tried increasing the NITT to 503000, but the effective samples actually got worse. Is there anything else I could do? I plan on dropping some variables from the model, but if I were to proceed with the model above, what could I have done better?
>>>>
>>>> Thanks in advance!
>>>> DNM
>>>> <http://aka.ms/weboutlook>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



> stat.ethz.ch
> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>
>
>
>> R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>> stat.ethz.ch
>> Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...
>>
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
R-sig-mixed-models Info Page - stat.ethz.ch<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...




        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From adomalik at sfu.ca  Fri Nov  3 22:07:44 2017
From: adomalik at sfu.ca (Alice Domalik)
Date: Fri, 3 Nov 2017 14:07:44 -0700 (PDT)
Subject: [R-sig-ME] zero-truncated negative binomial distribution
Message-ID: <1892971061.119263603.1509743264308.JavaMail.zimbra@sfu.ca>

Hi all, 

I am fitting mixed effects models using the package glmmTMB to investigate habitat use. 
My data does not contain any zeros, so I have considered the zero-truncated poisson and the zero-truncated negative binomial. 
Of these two distributions, the zt negative binomial was better, so I tried fitting my model: 

m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) 

However, it is clear that the model is having a hard time fitting my very high response values (the distribution of my response variable has a very long tail). 
The QQplot also shows the high 'count' values being above the QQline. 

What are my options for improving model fit? Are there any distributions that might be better? Is it permissible to transform my response variable (eg. sqrt or log)? 

Any suggestions are greatly appreciated. 

-Ally 


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Nov  3 23:04:36 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 3 Nov 2017 18:04:36 -0400
Subject: [R-sig-ME] zero-truncated negative binomial distribution
In-Reply-To: <1892971061.119263603.1509743264308.JavaMail.zimbra@sfu.ca>
References: <1892971061.119263603.1509743264308.JavaMail.zimbra@sfu.ca>
Message-ID: <f04d125a-1000-7446-3d80-5dd959204a55@gmail.com>


   I assume you have multiple observations per individual (an
observation-level random effect wouldn't make sense with a model like
the [truncated] negative binomial, which includes an estimated
dispersion parameter)?

  How big is your data set overall? What is summary(count) for your data
(e.g. min/max, 10% and 90% quantiles, mean, std dev) ?  (The marginal
distribution is less important than the conditional distribution, but
getting information about the conditional distribution is more difficult.)

   Transforming data and fitting with a linear model is always a
reasonable alternative if you can find a distribution that makes the
(conditional) distributions approximately normal (and homoscedastic).

  What is your evidence of "a hard time"?  Warning/error messages?

  How important is the zero-truncation?  Do you have a lot of small
counts (1,2,3) in addition to your extremely large values?

  Other more heavy-tailed distributions do exist (e.g.
https://en.wikipedia.org/wiki/Beta_negative_binomial_distribution ) but
not yet implemented in glmmTMB (and we'd have to implement both the BNB
and its zero-truncated version).  I think they'd likely be overkill.

On 17-11-03 05:07 PM, Alice Domalik wrote:
> Hi all, 
> 
> I am fitting mixed effects models using the package glmmTMB to investigate habitat use. 
> My data does not contain any zeros, so I have considered the zero-truncated poisson and the zero-truncated negative binomial. 
> Of these two distributions, the zt negative binomial was better, so I tried fitting my model: 
> 
> m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) 
> 
> However, it is clear that the model is having a hard time fitting my very high response values (the distribution of my response variable has a very long tail). 
> The QQplot also shows the high 'count' values being above the QQline. 
> 
> What are my options for improving model fit? Are there any distributions that might be better? Is it permissible to transform my response variable (eg. sqrt or log)? 
> 
> Any suggestions are greatly appreciated. 
> 
> -Ally 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From adomalik at sfu.ca  Fri Nov  3 23:21:21 2017
From: adomalik at sfu.ca (Alice Domalik)
Date: Fri, 3 Nov 2017 15:21:21 -0700 (PDT)
Subject: [R-sig-ME] zero-truncated negative binomial distribution
In-Reply-To: <f04d125a-1000-7446-3d80-5dd959204a55@gmail.com>
References: <1892971061.119263603.1509743264308.JavaMail.zimbra@sfu.ca>
 <f04d125a-1000-7446-3d80-5dd959204a55@gmail.com>
Message-ID: <441650509.119490750.1509747681021.JavaMail.zimbra@sfu.ca>

Thank you very much for your reply! 

I have ~1200 observations (and 24 individuals), and summary(count) looks like the following: 

min:1 
max: 351 
mean: 20 
10% quantile: 2 
90% quantile: 44 
std dev: 37.5 

Most of my values are extremely small (1's, 2's). The distribution of my response variable essentially looks like an exponential decay. 

The models run without errors, but the QQ plot suggests that the model is doing a poor job fitting the heavy tail. The high values fall well above the QQ line. 


Thanks again, Alice 

From: "Ben Bolker" <bbolker at gmail.com> 
To: r-sig-mixed-models at r-project.org 
Sent: Friday, November 3, 2017 3:04:36 PM 
Subject: Re: [R-sig-ME] zero-truncated negative binomial distribution 

I assume you have multiple observations per individual (an 
observation-level random effect wouldn't make sense with a model like 
the [truncated] negative binomial, which includes an estimated 
dispersion parameter)? 

How big is your data set overall? What is summary(count) for your data 
(e.g. min/max, 10% and 90% quantiles, mean, std dev) ? (The marginal 
distribution is less important than the conditional distribution, but 
getting information about the conditional distribution is more difficult.) 

Transforming data and fitting with a linear model is always a 
reasonable alternative if you can find a distribution that makes the 
(conditional) distributions approximately normal (and homoscedastic). 

What is your evidence of "a hard time"? Warning/error messages? 

How important is the zero-truncation? Do you have a lot of small 
counts (1,2,3) in addition to your extremely large values? 

Other more heavy-tailed distributions do exist (e.g. 
https://en.wikipedia.org/wiki/Beta_negative_binomial_distribution ) but 
not yet implemented in glmmTMB (and we'd have to implement both the BNB 
and its zero-truncated version). I think they'd likely be overkill. 

On 17-11-03 05:07 PM, Alice Domalik wrote: 
> Hi all, 
> 
> I am fitting mixed effects models using the package glmmTMB to investigate habitat use. 
> My data does not contain any zeros, so I have considered the zero-truncated poisson and the zero-truncated negative binomial. 
> Of these two distributions, the zt negative binomial was better, so I tried fitting my model: 
> 
> m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) 
> 
> However, it is clear that the model is having a hard time fitting my very high response values (the distribution of my response variable has a very long tail). 
> The QQplot also shows the high 'count' values being above the QQline. 
> 
> What are my options for improving model fit? Are there any distributions that might be better? Is it permissible to transform my response variable (eg. sqrt or log)? 
> 
> Any suggestions are greatly appreciated. 
> 
> -Ally 
> 
> 
> [[alternative HTML version deleted]] 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
> 

_______________________________________________ 
R-sig-mixed-models at r-project.org mailing list 
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 

	[[alternative HTML version deleted]]


From highstat at highstat.com  Sat Nov  4 10:09:14 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sat, 4 Nov 2017 09:09:14 +0000
Subject: [R-sig-ME] zero-truncated negative binomial distribution
Message-ID: <ef7d01da-394e-be57-80ab-114507784b5f@highstat.com>


Ally,

Did you not count zeros...or is it not possible to observe zeros for 
your data? If theoretically you can observe zeros, but by chance you 
didn't observe them then you better stick to an ordinary distribution.

If theoretically you cannot get them (e.g. numbers of eggs in a birds 
nest...it is always >0), then a zero-truncated distribution is a better 
option. But if your data is relative far away from 0 then you could 
decide to stick to an ordinary (e.g. NB) distribution.

If you have very high values for your response variable....and if a 
covariate cannot explain that, then you could also consider NB-p models. 
In such a model you use:

E(Y) = mu

var(Y) = mu + mu^p / theta

and p is estimated. (In an ordinary NB p = 2).

Apologies for self-citing here....but we apply them in Chapter 5 of our 
Beginner's Guide to GAMM with R (2014). Unfortunately, this does mean 
that you have to use MCMC.

Instead of looking at QQ-plots I suggest that you also simulate data 
from your model and see whether it produces similar values (especially 
the large values) as your observed data.

Kind regards,

Alain



Hi all,

I am fitting mixed effects models using the package glmmTMB to 
investigate habitat use.
My data does not contain any zeros, so I have considered the 
zero-truncated poisson and the zero-truncated negative binomial.
Of these two distributions, the zt negative binomial was better, so I 
tried fitting my model:

m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), 
family=list(family="truncated_nbinom1", link="log"), data=mydata)

However, it is clear that the model is having a hard time fitting my 
very high response values (the distribution of my response variable has 
a very long tail).
The QQplot also shows the high 'count' values being above the QQline.

What are my options for improving model fit? Are there any distributions 
that might be better? Is it permissible to transform my response 
variable (eg. sqrt or log)?

Any suggestions are greatly appreciated.

-Ally


-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From oliverhooker at prstatistics.com  Mon Nov  6 13:04:28 2017
From: oliverhooker at prstatistics.com (Oliver Hooker)
Date: Mon, 06 Nov 2017 12:04:28 +0000
Subject: [R-sig-ME] Course "Introduction to Mixed (Hierarchical) models for
 biologists using R"
Message-ID: <023e32e0f825475dad00eb230bd79439@prstatistics.com>

Introduction to Mixed (Hierarchical) models for biologists using R 
(IMBR01)

https://www.prstatistics.com/course/introduction-to-mixed-hierarchical-models-for-biologists-using-r-imbr01/

14th May 2018 - 18th May 2018

Prof. Subhash Lele

Course overview:
Mixed models, also known as hierarchical models and multilevel models, 
is a useful class of models for many applied sciences, including 
biology, ecology and evolution. The goal of this course is to give a 
thorough introduction to the logic, theory and most importantly 
implementation of these models to solve practical problems in ecology. 
Participants are not expected to know mathematics beyond the basic 
algebra and calculus. Participants are expected to know some R 
programming and to be familiar with the linear and generalized linear 
regression. We will be using JAGS (Just Another Gibbs Sampler) for 
Markov Chain Monte Carlo (MCMC) simulations for analyzing mixed models. 
The course will be conducted so that participants have substantial 
hands-on experience.

Monday 14th
Linear and Generalized linear models
To understand mixed models, the most important ?rst step is to 
thoroughly understand the linear and generalized linear models. Also, 
when conducting the data analysis, it is useful to ?t a simpler ?xed 
e?ects model before trying to ?t a more complex mixed e?ects 
model. Hence, we will start with a very detailed review of these models. 
We are assuming that the participants are familiar with these models and 
hence we will emphasize some important, but not commonly covered, 
topics. This will also give us an opportunity to unify the notation, 
review the basic R commands and ?ll out any gaps in knowledge and 
understanding of these topics.
1. We will show the use of non-parametric exploratory techniques such as 
classi?cation and regression trees (CART) for learning about important 
covariates and possible non-linearities in the relationships.
2. We will emphasize graphical and simulation based methods (e.g. Gelman 
and Hill, 2006) to understand and explore the implications of the 
?tted model.
3. We will discuss graphical tools such as marginal and conditional 
plots that are useful for conveying the results of a multiple regression 
model to a lay person.
4. We will emphasize the use of graphical tools to conduct regression 
diagnostics and appropriateness of the model.
5. We will discuss the important concepts of confounding, e?ect 
modi?cation and interaction. These are particularly important to 
conduct causal, not just correlational, inference using observational 
studies.

Tuesday 15th
Computational inference
Many of the topics that will be covered involve the use of matrix 
algebra and calculus. While these mathematical techniques are essential 
tools for a mathematical statistician who is trying to understand the 
theory behind the methods, they can be avoided in practice by using 
simulation based techniques. The built-in functions such as the ?lm? 
and ?glm? to ?t the regression models use the method of maximum 
likelihood to estimate the parameters and conduct statistical inference. 
We will discuss the use of JAGS (Just Another Gibbs Sampler) and the R 
package ?dclone? to ?t the same models. We will use a di?erent 
statistical philosophy, namely the Bayesian inference, to ?t these 
models. We will show how the Bayesian approach can be tricked into 
giving frequentist answers using data cloning (Lele et al. 2007, Ecology 
Letters). We will also discuss the rudiments of frequentist and Bayesian 
inference although we will not go into the pros and cons of them at this 
time. That will be covered during sessions 3 and 4 of the ?fth day 
(and, over beer afterwards).
1. What makes an inference statistical inference?
2. What do we mean by probability of an event?
3. How do we quantify uncertainty in an inferential statement in the 
frequentist framework?
4. How do we quantify uncertainty in an inferential statement in the 
Bayesian framework?
We will then discuss the simulation based methods to quantify 
uncertainty.
1. Parametric bootstrap to quantify frequentist uncertainty
2. Markov Chain Monte Carlo to quantify Bayesian uncertainty
3. Fitting LM and GLM using JAGS and Bayesian approach

Wednesday 16th
Linear Mixed Models
Historically, linear mixed models arose in the study of quantitative 
genetics and heritability issues. They were successfully applied in 
animal breeding and led to the ?white? revolution with abundance of 
milk supply for the developing world. They were, also, used in horse 
racing and other such fun areas. The other situation where linear mixed 
e?ects models were developed were in the context of growth curves. We 
will follow this historical trajectory of mixed models, paying tribute 
to the great statisticians R. A. Fisher, C. R. Rao and Jerzy Neyman, and 
study linear mixed models ?rst. The questions they tried to solve 
were: Deciding the genetic value of a sire and/or a dam, studying 
heritability of traits, studying co-evolution of traits etc. These can 
be answered provided we assume that the sires and dams in our experiment 
or sample are merely a sample from a super-population of sires and dams. 
In growth curve analysis, we need to take into account that each 
individual is unique in its own way but is also a part of a population. 
How do we discuss both individual level and population inferences? In 
modern times, linear mixed e?ects models have arisen in the context of 
small area estimation in survey sampling where one is interested in 
inferring about a census tract based on county or state level data. 
These models arise also in the context of combining remote sensed data 
from di?erent resolutions and types. The main issues that we will be 
discussing are:
1. What is a random e?ect? What is a ?xed e?ect? How do we decide 
if an e?ect is random or ?xed?
2. How do we modify a linear regression model to accommodate random 
e?ects?
3. Why bother ?tting a mixed e?ects models? What do we gain?
4. How to modify the JAGS linear models program to ?t a linear mixed 
e?ects model using JAGS?
5. What is the di?erence between a Bayesian and a frequentist 
inference?
6. What is a prior? What is a non-informative prior?
7. How do we interpret the results of a linear mixed e?ects model 
?t? Graphical and simulation based methods
8. How do we do model selection with mixed e?ects models?
9. How do we do model diagnostics in mixed e?ects models?
10. Parameter identi?abilty issues in linear mixed models
As we discuss these applications, we will discuss some subtle 
computational issues involved in using MCMC. In my recollection (which 
may be biased as it has been about 25 years since the quote), Daryl 
Pregibon said: MCMC is the crack cocaine of modern statistics; it is 
addictive, seductive and destructive. Hence, it is important for a 
practitioner to understand these issues in order not to misuse the MCMC 
technique.
1. What is a Markov Chain Monte Carlo method? Why is it necessary for 
mixed models?
2. What are the subtleties in implementing MCMC?: Convergence of the 
algorithm, Mixing of the chains.
3. Pros and cons of using MCMC

Thursday 17th
Generalised Linear Mixed Models
We will again start the discussion of GLMM in its historical context. 
One of the initial uses of mixed models were in the context of over 
dispersion in count data. Zero in?ated count data was another 
important example. The example that drove the current revolution in the 
use of GLMM was in the context of spatial epidemiology. Clayton and 
Caldor (1989, Biometrics) showed that one can use spatial correlation to 
improve the prediction in mapping disease rates. This was also an 
example of the application of Empirical Bayes methods that allow one to 
pool information from di?erent spatial areas (or, studies, or, scales, 
and so on).
1. Zero in?ated data In many practical situations, we observe that 
there are many locations where there are zero counts, far in excess of 
what would be expected under the Poisson regression model. This can be 
e?ectively modelled using a mixed model framework. The mixed models 
framework allows us to use much more complex and realistic models.
2. Over dispersion in GLM, Spatial GLM, Spatio-temporal GLM The Poisson 
regression model assumes that the mean and variance are equal. This is, 
often, not true in practice. Generally the variance in the data exceeds 
the mean. One can show that such over-dispersion can be modelled using a 
mixed e?ects model. These models also arise in the context of 
capturerecapture sampling where capture probabilities vary across space 
or time or individuals.
3. Longitudinal or panel data with discrete response variable Many times 
we have data on di?erent individuals where within the individual there 
is temporal dependence but individuals are independent of each other. 
Cluster sampling is another situation where we have dependence within a 
cluster but independence between clusters. Such data needs to take into 
account the innate variation between individuals before one can discuss 
the e?ect of interesting covariates or risk factors. Such data are 
e?ectively modelled as GLMM.
4. Measurement error, missing data Missing data and measurement error 
are ubiquitous in ecological studies. Mixed models provide a convenient 
way to take into account these di?culties and infer about the 
underlying processes of interest. We will discuss these issues in the 
context of Population Viability Analysis, Spatial population dynamics 
and source-sink analysis, Occupancy and abundance surveys. These also 
arise while doing usual linear and generalized linear models if the 
covariates are measured with error.
5. Additional topics depending on the interest of the participants. 
These may include, for example, discussion of Species Distribution 
Models, Resource Selection Functions and Animal movement models.
6 Computational issues: Advanced topics

Friday 18th
Mixed Models in a Bayesian Framework
MCMC is not the only approach to analyse mixed models. We will brie?y 
discuss Laplace approximation based techniques (INLA, in particular) 
along with approximate techniques such as Composite likelihood and 
Approximate Bayesian Computation. Because of the mathematical nature, 
this discussion will be somewhat limited, only giving the basics and 
hinting at the important issues.
7 Philosophical issues: Sophie?s choice
1. What are the philosophical problems with using the frequentist 
quanti?cation of uncertainty?
2. What are the philosophical problems with using the Bayesian 
quanti?cation of uncertainty?
3. Sophie?s choice?

Other upcoming courses

1.	November 6th ? 10th 2017
LANDSCAPE GENETIC DATA ANALYSIS USING R #LNDG
Margam Discovery Centre, Wales, Prof. Rodney Dyer
http://www.prstatistics.com/course/landscape-genetic-data-analysis-using-r-lndg02/

2.	November 20th - 25th 2017
APPLIED BAYESIAN MODELLING FOR ECOLOGISTS AND EPIDEMIOLOGISTS #ABME
SCENE, Scotland, Dr. Matt Denwood
http://www.prstatistics.com/course/applied-bayesian-modelling-ecologists-epidemiologists-abme03/

3.	November 27th ? December 1st 2017
INTRODUCTION TO PYTHON FOR BIOLOGISTS #IPYB
Margam Discovery Centre, Wales, Dr. Martin Jones
http://www.prinformatics.com/course/introduction-to-python-for-biologists-ipyb04/
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
4.	December 4th - 8th 2017
ADVANCING IN STATISTICAL MODELLING USING R #ADVR
Margam Discovery Centre, Wales, Dr. Luc Bussiere, Dr. Tom Houslay, Dr. 
Ane Timenes Laugen,
http://www.prstatistics.com/course/advancing-statistical-modelling-using-r-advr07/
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
5.	January 29t ? February 2nd 2018
INTRODUCTION TO BAYESIAN HIERARCHICAL MODELLING #IBHM
SCENE, Scotland, Dr. Andrew Parnell
http://www.prstatistics.com/course/introduction-to-bayesian-hierarchical-modelling-using-r-ibhm02/

6.	January 29th ? February 2nd 2018
PHYLOGENETIC DATA ANALYSIS USING R #PHYL
SCENE, Scotland, Dr. Emmanuel Paradis
https://www.prstatistics.com/course/introduction-to-phylogenetic-analysis-with-r-phyg-phyl02/
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
7.	February 19th ? 23rd 2018
MOVEMENT ECOLOGY #MOVE
Margam Discovery Centre, Wales, Dr Luca Borger, Dr Ronny Wilson, Dr 
Jonathan Potts
https://www.prstatistics.com/course/movement-ecology-move01/

8.	February 19th ? 23rd 2018
GEOMETRIC MORPHOMETRICS USING R #GMMR
Margam Discovery Centre, Wales, Prof. Dean Adams, Prof. Michael Collyer, 
Dr. Antigoni Kaliontzopoulou
http://www.prstatistics.com/course/geometric-morphometrics-using-r-gmmr01/
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
9.	March 5th - 9th 2018
SPATIAL PRIORITIZATION USING MARXAN #MRXN
Margam Discovery Centre, Wales, Jennifer McGowan
https://www.prstatistics.com/course/introduction-to-marxan-mrxn01/

10.	March 12th - 16th 2018
ECOLOGICAL NICHE MODELLING USING R #ENMR
Glasgow, Scotland, Dr. Neftali Sillero
http://www.prstatistics.com/course/ecological-niche-modelling-using-r-enmr02/

11.	March 19th ? 23rd 2018
BEHAVIOURAL DATA ANALYSIS USING MAXIMUM LIKLIHOOD IN R #BDML
Glasgow, Scotland, Dr William Hoppitt
http://www.psstatistics.com/course/behavioural-data-analysis-using-maximum-likelihood-bdml01/
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
12.	April 9th ? 13th 2018
NETWORK ANAYLSIS FOR ECOLOGISTS USING R #NTWA
Glasgow, Scotland, Dr. Marco Scotti
https://www.prstatistics.com/course/network-analysis-ecologists-ntwa02/

13.	April 16th ? 20th 2018
INTRODUCTION TO STATISTICAL MODELLING FOR PSYCHOLOGISTS USING R #IPSY
Glasgow, Scotland, Dr. Dale Barr, Dr Luc Bussierre
http://www.psstatistics.com/course/introduction-to-statistics-using-r-for-psychologists-ipsy01/

14.	April 23rd ? 27th 2018
MULTIVARIATE ANALYSIS OF ECOLOGICAL COMMUNITIES USING THE VEGAN PACKAGE 
#VGNR
Glasgow, Scotland, Dr. Peter Solymos, Dr. Guillaume Blanchet
https://www.prstatistics.com/course/multivariate-analysis-of-ecological-communities-in-r-with-the-vegan-package-vgnr01/

15.	April 30th ? 4th May 2018
QUANTITATIVE GEOGRAPHIC ECOLOGY: MODELING GENOMES, NICHES, AND 
COMMUNITIES #QGER
Glasgow, Scotland, Dr. Dan Warren, Dr. Matt Fitzpatrick
https://www.prstatistics.com/course/quantitative-geographic-ecology-using-r-modelling-genomes-niches-and-communities-qger01/
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
16.	May 7th ? 11th 2018 ADVANCES IN MULTIVARIATE ANALYSIS OF SPATIAL 
ECOLOGICAL DATA USING R #MVSP
CANADA (QUEBEC), Prof. Pierre Legendre, Dr. Guillaume Blanchet
https://www.prstatistics.com/course/advances-in-spatial-analysis-of-multivariate-ecological-data-theory-and-practice-mvsp03/

17.	May 14th - 18th 2018
INTRODUCTION TO MIXED (HIERARCHICAL) MODELS FOR BIOLOGISTS #IMBR
CANADA (QUEBEC), Prof Subhash Lele
https://www.prstatistics.com/course/introduction-to-mixed-hierarchical-models-for-biologists-using-r-imbr01/

18.	May 21st - 25th 2018
INTRODUCTION TO PYTHON FOR BIOLOGISTS #IPYB
SCENE, Scotland, Dr. Martin Jones
http://www.prinformatics.com/course/introduction-to-python-for-biologists-ipyb05/

19.	May 21st - 25th 2018
INTRODUCTION TO REMOTE SENISNG AND GIS FOR ECOLOGICAL APPLICATIONS
Glasgow, Scotland, Prof. Duccio Rocchini, Dr. Luca Delucchi
https://www.prinformatics.com/course/introduction-to-remote-sensing-and-gis-for-ecological-applications-irms01/

20.	May 28th ? 31st 2018
STABLE ISOTOPE MIXING MODELS USING SIAR, SIBER AND MIXSIAR #SIMM
CANADA (QUEBEC) Dr. Andrew Parnell, Dr. Andrew Jackson
https://www.prstatistics.com/course/stable-isotope-mixing-models-using-r-simm04/

21.	May 28th ? June 1st 2018
ADVANCED PYTHON FOR BIOLOGISTS #APYB
SCENE, Scotland, Dr. Martin Jones
https://www.prinformatics.com/course/advanced-python-biologists-apyb02/
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
22.	June 12th -0 15th 2018
SPECIES DISTRIBUTION MODELLING #DBMR
Myuna Bay sport and recreation, Australia, TBC
COMING SOON  www.PRstatistics.com

23.	June 12th ? 15th 2018
MARK RECAPTURE METHODS IN ECOLOGY #MKRC
Myuna Bay sport and recreation, Australia, TBC
COMING SOON  www.PRstatistics.com

24.	June 18th ? 22nd 2018
STRUCTURAL EQUATION MODELLING FOR ECOLOGISTS AND EVOLUTIONARY BIOLOGISTS 
USING R #SEMR
Myuna Bay sport and recreation, Australia, TBC
COMING SOON  www.PRstatistics.com
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
25.	July 2nd - 5th 2018
SOCIAL NETWORK ANALYSIS FOR BEHAVIOURAL SCIENTISTS USING R #SNAR
Glasgow, Scotland, Prof James Curley
http://www.psstatistics.com/course/social-network-analysis-for-behavioral-scientists-snar01/

26.	July 8th ? 12th 2018
MODEL BASE MULTIVARIATE ANALYSIS OF ABUNDANCE DATA USING R #MBMV
Glasgow, Scotland, Prof David Warton
https://www.prstatistics.com/course/model-base-multivariate-analysis-of-abundance-data-using-r-mbmv02/

27.	July 16th ? 20th 2018
PRECISION MEDICINE BIOINFORMATICS: FROM RAW GENOME AND TRANSCRIPTOME 
DATA TO CLINICAL INTERPRETATION #PMBI
Glasgow, Scotland, Dr Malachi Griffith, Dr. Obi Griffith
COMING SOON www.prinformatics.com

28.	July 23rd ? 27th 2018
EUKARYOTIC METABARCODING
Glasgow, Scotland, Dr. Owen Wangensteen
http://www.prinformatics.com/course/eukaryotic-metabarcoding-eukb01/


-- 
Oliver Hooker PhD.
PR statistics

2017 publications -

Ecosystem size predicts eco-morphological variability in post-glacial 
diversification. Ecology and Evolution. In press.

The physiological costs of prey switching reinforce foraging 
specialization. Journal of animal ecology.

prstatistics.com
facebook.com/prstatistics/
twitter.com/PRstatistics
groups.google.com/d/forum/pr-statistics-post-course-forum
prstatistics.com/organiser/oliver-hooker/

6 Hope Park Crescent
Edinburgh
EH8 9NA

+44 (0) 7966500340


From mollieebrooks at gmail.com  Wed Nov  8 11:49:20 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Wed, 8 Nov 2017 11:49:20 +0100
Subject: [R-sig-ME] spatial covariance structure in glmmTMB
In-Reply-To: <1776635358.67364670.1507747055129.JavaMail.zimbra@sfu.ca>
References: <845771341.62814150.1507555332287.JavaMail.zimbra@sfu.ca>
 <CAMu=eMBXb2OWFw2xNmq+0XSwFU1=m2bN5tCqjXT9U40EpLFV7g@mail.gmail.com>
 <1841227664.62914605.1507565159002.JavaMail.zimbra@sfu.ca>
 <CABghstTYQFQMYOj-AP2MdjqTDNXDcOp_Kdka6rs+QDq0Zq7A4Q@mail.gmail.com>
 <1776635358.67364670.1507747055129.JavaMail.zimbra@sfu.ca>
Message-ID: <EFFDCE19-58EE-44FD-8F3B-D52F46265955@gmail.com>

Hi Alice,

Kasper recently added a spatial example to vignette("covstruct"). Hopefully, that will solve your problem. To get the vignette, you?ll have to install from github following the instructions here

https://github.com/glmmTMB/glmmTMB <https://github.com/glmmTMB/glmmTMB>

cheers,
Mollie 

> On 11Oct 2017, at 20:37, Alice Domalik <adomalik at sfu.ca> wrote:
> 
> In the end, I was able to run the following model:
> 
> m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual) + gau(coord + 0| group), family=list(family="truncated_nbinom1", link="log"), data=mydata)
> 
> Where 'coord' are the spatial coordinates (UTM) represented as a factor, and 'group' is a single level.
> 
> group<-factor(rep(1,n))
> 
> However, I get the error:
> 
> Warning message:
> In glmmTMB(count ~ waterdepth + temperature +  :
>   Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')
> 
> I didn't have this error when I initially ran my model without a covariance structure.
> Any advice on how I should move forward?
> 
> Thanks!!! Alice
> 
> From: "Ben Bolker" <bbolker at gmail.com>
> To: "Alice Domalik" <adomalik at sfu.ca>
> Cc: "Mollie Brooks" <mollieebrooks at gmail.com>, r-sig-mixed-models at r-project.org, "Kasper Kristensen" <kaskr at dtu.dk>
> Sent: Monday, October 9, 2017 3:05:19 PM
> Subject: Re: [R-sig-ME] spatial covariance structure in glmmTMB
> 
> Did you see the part of the document (sub)titled "Adding coordinate
> information" ?  (The example given in the vignette only does a 1-D
> example, but it gives instructions that should in principle work for
> 2-D ...)
> 
> On Mon, Oct 9, 2017 at 12:05 PM, Alice Domalik <adomalik at sfu.ca> wrote:
> > I did look at the vignette, and the notation wasn't clear to me.
> > If, for example, I wanted to add a spatial gaussian, would I write my model as:
> >
> > m1<-glmmTMB(count~gau(coordinates) + waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata) ?
> >
> > It also isn't clear to me if spatial coordinates need to be in a particular format.
> >
> >
> > From: "Mollie Brooks" <mollieebrooks at gmail.com>
> > To: "Alice Domalik" <adomalik at sfu.ca>
> > Cc: r-sig-mixed-models at r-project.org, "Kasper Kristensen" <kaskr at dtu.dk>
> > Sent: Monday, October 9, 2017 6:42:48 AM
> > Subject: Re: [R-sig-ME] spatial covariance structure in glmmTMB
> >
> > Hi Alice,
> > Have you looked at the vignette on covariance structures? There's a section on spatial correlations.
> >
> > [ https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html | https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html ]
> >
> > cheers,
> > Mollie
> >
> > On Mon, Oct 9, 2017 at 3:22 PM, Alice Domalik < [ mailto:adomalik at sfu.ca | adomalik at sfu.ca ] > wrote:
> >
> >
> > Dear list,
> >
> > I am fitting mixed effects models using the package glmmTMB to investigate habitat use.
> > My current model has the form m1<-glmmTMB(count~waterdepth + temperature + chl.conc + (1|individual), family=list(family="truncated_nbinom1", link="log"), data=mydata)
> > I would like to add a spatial covariance structure based on geographic coordinates (mydata$x and mydata$y).
> > However, I do not know how to modify my model formula to include a spatial covariance structure. Does anyone have example code to show how this is done?
> >
> > Any help would be much appreciated!
> >
> >
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > [ mailto:R-sig-mixed-models at r-project.org | R-sig-mixed-models at r-project.org ] mailing list
> > [ https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models | https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models ]
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From oliverhooker at prstatistics.com  Fri Nov 10 14:46:09 2017
From: oliverhooker at prstatistics.com (Oliver Hooker)
Date: Fri, 10 Nov 2017 13:46:09 +0000
Subject: [R-sig-ME] Intro to Bayesian mixed (hierarchical) modelling
Message-ID: <527ca4e4f7e2298e9190434b992dd539@prstatistics.com>

Introduction to Bayesian hierarchical modelling using R (IBHM02)

https://www.prstatistics.com/course/introduction-to-bayesian-hierarchical-modelling-using-r-ibhm02/

29th January 2018 - 2nd February 2018

Course Overview:
This course will cover introductory hierarchical modelling for 
real-world data sets from a Bayesian perspective. These methods lie at 
the forefront of statistics research and are a vital tool in the 
scientist?s toolbox. The course focuses on introducing concepts and 
demonstrating good practice in hierarchical models. All methods are 
demonstrated with data sets which participants can run themselves. 
Participants will be taught how to fit hierarchical models using the 
Bayesian modelling software Jags and Stan through the R software 
interface. The course covers the full gamut from simple regression 
models through to full generalised multivariate hierarchical structures. 
A Bayesian approach is taken throughout, meaning that participants can 
include all available information in their models and estimates all 
unknown quantities with uncertainty.?Participants are encouraged to 
bring their own data sets for discussion with the course tutors.

Monday 29th ? Classes from 09:00 to 17:00
Module 1: Introduction to Bayesian Statistics
Module 2: Linear and generalised linear models (GLMs)
Practical: Using R, Jags and Stan for fitting GLMs
Round table discussion: Understanding Bayesian models

Tuesday 30th ? Classes from 09:00 to 17:00
Module 3: Simple hierarchical regression models
Module 4: Hierarchical models for non-Gaussian data
Practical: Fitting hierarchical models
Round table discussion: Interpreting hierarchical model output

Wednesday 31st ? Classes from 09:00 to 17:00
Module 5: Hierarchical models vs mixed effects models
Module 6: ?Multivariate and multi-layer hierarchical models
Practical: Advanced examples of hierarchical models
Round table discussion: Issues of continuous vs discrete time

Thursday 1st ? Classes from 09:00 to 16:00
Module 7: Shrinkage and variable selection
Module 8: Hierarchical models and partial pooling
Practical: Shrinkage modelling
Round table discussion?Bring your own data set

Friday 2nd ? Classes from 09:00 to 16:00
Final day for recap session, catch up time and bring your own data set

-- 
Oliver Hooker PhD.
PR statistics

2017 publications -

Ecosystem size predicts eco-morphological variability in post-glacial 
diversification. Ecology and Evolution. In press.

The physiological costs of prey switching reinforce foraging 
specialization. Journal of animal ecology.

prstatistics.com
facebook.com/prstatistics/
twitter.com/PRstatistics
groups.google.com/d/forum/pr-statistics-post-course-forum
prstatistics.com/organiser/oliver-hooker/

6 Hope Park Crescent
Edinburgh
EH8 9NA

+44 (0) 7966500340


From selebatsom at yahoo.co.uk  Sun Nov 12 16:50:14 2017
From: selebatsom at yahoo.co.uk (moses selebatso)
Date: Sun, 12 Nov 2017 15:50:14 +0000 (UTC)
Subject: [R-sig-ME] Negative and zero value on mixed models
References: <435089419.992213.1510501814061.ref@mail.yahoo.com>
Message-ID: <435089419.992213.1510501814061@mail.yahoo.com>

Good day
I am trying?to run mixed models on my dataset.?Values range from 1 to?-1,?including zero. I tried to search and?find out if there is any particular way I should handle this data when running mixed models. 
Moses?


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Nov 13 10:22:08 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 13 Nov 2017 10:22:08 +0100
Subject: [R-sig-ME] Negative and zero value on mixed models
In-Reply-To: <435089419.992213.1510501814061@mail.yahoo.com>
References: <435089419.992213.1510501814061.ref@mail.yahoo.com>
 <435089419.992213.1510501814061@mail.yahoo.com>
Message-ID: <CAJuCY5xyQdMRAoYyMDfjBPFrTjBUdY_uzNn-We6ykOFx4KceGg@mail.gmail.com>

Dear Moses,

Given your question, I highly recommend that you first do some
(self-)study on mixed models.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-11-12 16:50 GMT+01:00 moses selebatso via R-sig-mixed-models
<r-sig-mixed-models at r-project.org>:
> Good day
> I am trying to run mixed models on my dataset. Values range from 1 to -1, including zero. I tried to search and find out if there is any particular way I should handle this data when running mixed models.
> Moses
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Mon Nov 13 14:15:37 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 13 Nov 2017 15:15:37 +0200
Subject: [R-sig-ME] Negative and zero value on mixed models (moses
	selebatso)
In-Reply-To: <mailman.9.1510570801.20537.r-sig-mixed-models@r-project.org>
References: <mailman.9.1510570801.20537.r-sig-mixed-models@r-project.org>
Message-ID: <9eef81c4-f4ad-3bc3-9785-c59d0d9870dd@highstat.com>


> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 12 Nov 2017 15:50:14 +0000 (UTC)
> From: moses selebatso <selebatsom at yahoo.co.uk>
> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Negative and zero value on mixed models
> Message-ID: <435089419.992213.1510501814061 at mail.yahoo.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Good day
> I am trying?to run mixed models on my dataset.?Values range from 1 to?-1,?including zero. I tried to search and?find out if there is any particular way I should handle this data when running mixed models.
> Moses?
>
>
> 	[[alternative HTML version deleted]]
>
Have a look at the pdf file that comes with the betareg package, and see 
whether the beta distribution (after converting it to the 0 - 1 range) 
is something that would work for you. If so, then use glmmTMB to fit a 
beta model with random effects.

https://cran.r-project.org/web/packages/betareg/vignettes/betareg.pdf

Such an approach assumes that you *cannot* sample a value larger than 1, 
or smaller than -1.
Alain


-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From n.l.pace at utah.edu  Tue Nov 14 07:04:24 2017
From: n.l.pace at utah.edu (Nathan Pace)
Date: Tue, 14 Nov 2017 06:04:24 +0000
Subject: [R-sig-ME] diagnostic test meta analysis using glmer
Message-ID: <3E5B8362-2264-4B34-87CC-EC4E5FCFB3FE@utah.edu>

Hi,

I am modeling the sensitivity and specificity of 7 diagnostic tests in a bivariate binomial model using glmer.

glmer(formula = cbind(true, n - true) ~ 0 + seM + spM + seMM + spMM + seMouth + spMouth +
                          seSM + spSM + seTM + spTM + seULBT + spULBT + seW + spW +
                          (0 + sens + spec | studyName), data = Compare_DL.df, family = binomial, nAGQ = 1)

The model without separating diagnostic tests is 

glmer(formula = cbind(true, n - true) ~  0 + sens + spec + (0 + sens + spec | studyName),
                      data = Compare_DL.df, family = binomial, nAGQ = 1)

The 7 test model assumes equal variances across tests.

The dataset includes sens, spec, seM, spM, etc as dummy index variables.
Both models can run and converge.

ANOVA shows improved fit:

                          Df   AIC      BIC        logLik     deviance  Chisq Chi Df 	Pr(>Chisq)
Simple model    5 8987.8 9007.6 -4488.9   8977.8                             
Separate tests 17 6878.5 6945.8 -3422.3   6844.5      2133.3     12  	< 2.2e-16 ***

I need to identify any separation of sensitivity and specificity properties among the 7 tests.

One possibility would be to jointly contrast seTesti ? seTestj  = 0 and spTesti ? spTestj = 0 for all pairwise comparisons of the 7 tests (with multiplicity adjustment).

However, I am unable to construct such tests in lme4. Is this possible in lme4? If so, what is the code?

I have looked at other packages (multcomp) without success.

As usual, all help will be appreciated.

Nathan Pace, MD, MStat
University of Utah
Salt Lake City, UT
n.l.pace at utah.edu



---


_________
____________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Tue Nov 14 09:28:41 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 14 Nov 2017 09:28:41 +0100
Subject: [R-sig-ME] diagnostic test meta analysis using glmer
In-Reply-To: <3E5B8362-2264-4B34-87CC-EC4E5FCFB3FE@utah.edu>
References: <3E5B8362-2264-4B34-87CC-EC4E5FCFB3FE@utah.edu>
Message-ID: <CAJuCY5xXsv69Hy1qEWKU0sgmZTioiuRP+BGF7CzkWksF5v_dtw@mail.gmail.com>

Dear Nathan,

You can use the glht() function from the multcomp package to do post-hoc
tests on contrasts. You should create a custom K matrix. See
https://thebiobucket.blogspot.be/2011/06/glmm-with-custom-multiple-comparisons.html#more

Best regards,

Thierry


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[image: Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging
in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis. Vanaf
dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.]
<https://overheid.vlaanderen.be/mobiliteitsplan-herman-teirlinckgebouw>
Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
Brussel.

///////////////////////////////////////////////////////////////////////////////////////////
<https://www.inbo.be>

2017-11-14 7:04 GMT+01:00 Nathan Pace <n.l.pace at utah.edu>:

> Hi,
>
> I am modeling the sensitivity and specificity of 7 diagnostic tests in a
> bivariate binomial model using glmer.
>
> glmer(formula = cbind(true, n - true) ~ 0 + seM + spM + seMM + spMM +
> seMouth + spMouth +
>                           seSM + spSM + seTM + spTM + seULBT + spULBT +
> seW + spW +
>                           (0 + sens + spec | studyName), data =
> Compare_DL.df, family = binomial, nAGQ = 1)
>
> The model without separating diagnostic tests is
>
> glmer(formula = cbind(true, n - true) ~  0 + sens + spec + (0 + sens +
> spec | studyName),
>                       data = Compare_DL.df, family = binomial, nAGQ = 1)
>
> The 7 test model assumes equal variances across tests.
>
> The dataset includes sens, spec, seM, spM, etc as dummy index variables.
> Both models can run and converge.
>
> ANOVA shows improved fit:
>
>                           Df   AIC      BIC        logLik     deviance
> Chisq Chi Df    Pr(>Chisq)
> Simple model    5 8987.8 9007.6 -4488.9   8977.8
> Separate tests 17 6878.5 6945.8 -3422.3   6844.5      2133.3     12     <
> 2.2e-16 ***
>
> I need to identify any separation of sensitivity and specificity
> properties among the 7 tests.
>
> One possibility would be to jointly contrast seTesti ? seTestj  = 0 and
> spTesti ? spTestj = 0 for all pairwise comparisons of the 7 tests (with
> multiplicity adjustment).
>
> However, I am unable to construct such tests in lme4. Is this possible in
> lme4? If so, what is the code?
>
> I have looked at other packages (multcomp) without success.
>
> As usual, all help will be appreciated.
>
> Nathan Pace, MD, MStat
> University of Utah
> Salt Lake City, UT
> n.l.pace at utah.edu
>
>
>
> ---
>
>
> _________
> ____________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From n.l.pace at utah.edu  Tue Nov 14 22:36:53 2017
From: n.l.pace at utah.edu (Nathan Pace)
Date: Tue, 14 Nov 2017 21:36:53 +0000
Subject: [R-sig-ME] diagnostic test meta analysis using glmer
In-Reply-To: <CAJuCY5xXsv69Hy1qEWKU0sgmZTioiuRP+BGF7CzkWksF5v_dtw@mail.gmail.com>
References: <3E5B8362-2264-4B34-87CC-EC4E5FCFB3FE@utah.edu>
 <CAJuCY5xXsv69Hy1qEWKU0sgmZTioiuRP+BGF7CzkWksF5v_dtw@mail.gmail.com>
Message-ID: <0303BC88-CABE-453C-9414-27E491EDAF25@utah.edu>

Hi Thierry,

Your link to the description of multiple comparisons in glht with custom K matrices for GLMM was much appreciated.

It helped me think clearly about my contrast vectors.

Thanks again,

Nathan

From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Date: Tuesday, November 14, 2017 at 01:29
To: Nathan L Pace <n.l.pace at utah.edu>
Cc: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] diagnostic test meta analysis using glmer

Dear Nathan,

You can use the glht() function from the multcomp package to do post-hoc tests on contrasts. You should create a custom K matrix. See https://thebiobucket.blogspot.be/2011/06/glmm-with-custom-multiple-comparisons.html#more

Best regards,

Thierry


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Kliniekstraat 25, B-1070 Brussel
www.inbo.be<http://www.inbo.be>
///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[Van 14 tot en met 19 december 20]<https://overheid.vlaanderen.be/mobiliteitsplan-herman-teirlinckgebouw>
Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////
[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be>

2017-11-14 7:04 GMT+01:00 Nathan Pace <n.l.pace at utah.edu<mailto:n.l.pace at utah.edu>>:
Hi,

I am modeling the sensitivity and specificity of 7 diagnostic tests in a bivariate binomial model using glmer.

glmer(formula = cbind(true, n - true) ~ 0 + seM + spM + seMM + spMM + seMouth + spMouth +
                          seSM + spSM + seTM + spTM + seULBT + spULBT + seW + spW +
                          (0 + sens + spec | studyName), data = Compare_DL.df, family = binomial, nAGQ = 1)

The model without separating diagnostic tests is

glmer(formula = cbind(true, n - true) ~  0 + sens + spec + (0 + sens + spec | studyName),
                      data = Compare_DL.df, family = binomial, nAGQ = 1)

The 7 test model assumes equal variances across tests.

The dataset includes sens, spec, seM, spM, etc as dummy index variables.
Both models can run and converge.

ANOVA shows improved fit:

                          Df   AIC      BIC        logLik     deviance  Chisq Chi Df    Pr(>Chisq)
Simple model    5 8987.8 9007.6 -4488.9   8977.8
Separate tests 17 6878.5 6945.8 -3422.3   6844.5      2133.3     12     < 2.2e-16 ***

I need to identify any separation of sensitivity and specificity properties among the 7 tests.

One possibility would be to jointly contrast seTesti ? seTestj  = 0 and spTesti ? spTestj = 0 for all pairwise comparisons of the 7 tests (with multiplicity adjustment).

However, I am unable to construct such tests in lme4. Is this possible in lme4? If so, what is the code?

I have looked at other packages (multcomp) without success.

As usual, all help will be appreciated.

Nathan Pace, MD, MStat
University of Utah
Salt Lake City, UT
n.l.pace at utah.edu<mailto:n.l.pace at utah.edu>



---


_________
____________________________________
    R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From n.l.pace at utah.edu  Sat Nov 18 01:02:11 2017
From: n.l.pace at utah.edu (Nathan Pace)
Date: Sat, 18 Nov 2017 00:02:11 +0000
Subject: [R-sig-ME] lme4 merMod model object
Message-ID: <CF5D22F7-0847-4283-B3DE-4D0B5FB975B8@utah.edu>

Hi mixed model experts,

I have a GLMM (binomial) model estimated in lme4 using glmer.

There are many linear coefficients such as coef1, coef2, coef3, coef4, ?

I have used glht from multcomp to test coefficient contrasts such as coef1 ? coef2 = 0.

Now I desire to test sets of linear contrasts in the model jointly such as coef1 ? coef2 = 0 & coef3 ? coef4 = 0.

By my reading, this should be possible in the linearHypothesis function of the car package.

If someone has already used sets of contrast vectors for that purpose, I would appreciate learning of the format.

Thanks,

vd
Nathan Pace
University of Utah


___________________________________
? ? R-sig-mixed-models at r-project.org mailing list
? ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
?



From jfox at mcmaster.ca  Sat Nov 18 15:45:49 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 18 Nov 2017 14:45:49 +0000
Subject: [R-sig-ME] lme4 merMod model object
In-Reply-To: <17507_1510963345_vAI02O7C001810_CF5D22F7-0847-4283-B3DE-4D0B5FB975B8@utah.edu>
References: <17507_1510963345_vAI02O7C001810_CF5D22F7-0847-4283-B3DE-4D0B5FB975B8@utah.edu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83672133C@FHSDB4H16-2.csu.mcmaster.ca>

Dear Nathan,

Yes, you should be able to use linearHypothesis() in the car package. The command would be something like

linearHypothesis(your.model, c("coef1 - coef2 = 0",  "coef3 - coef4 = 0"))

You could equivalently specify the hypothesis as c("coef1 - coef2",  "coef3 - coef4"), with the 0s implied, or as c("coef1 = coef2",  "coef3 = coef4 ").

I'm curious why that wasn't clear from ?linearHypothesis.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Nathan Pace
> Sent: Friday, November 17, 2017 7:02 PM
> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] lme4 merMod model object
> 
> Hi mixed model experts,
> 
> I have a GLMM (binomial) model estimated in lme4 using glmer.
> 
> There are many linear coefficients such as coef1, coef2, coef3, coef4, ?
> 
> I have used glht from multcomp to test coefficient contrasts such as coef1 ?
> coef2 = 0.
> 
> Now I desire to test sets of linear contrasts in the model jointly such as coef1 ?
> coef2 = 0 & coef3 ? coef4 = 0.
> 
> By my reading, this should be possible in the linearHypothesis function of the
> car package.
> 
> If someone has already used sets of contrast vectors for that purpose, I would
> appreciate learning of the format.
> 
> Thanks,
> 
> vd
> Nathan Pace
> University of Utah
> 
> 
> ___________________________________
> ? ? R-sig-mixed-models at r-project.org mailing list
> ? ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From n.l.pace at utah.edu  Mon Nov 20 06:06:08 2017
From: n.l.pace at utah.edu (Nathan Pace)
Date: Mon, 20 Nov 2017 05:06:08 +0000
Subject: [R-sig-ME] lme4 merMod model object
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83672133C@FHSDB4H16-2.csu.mcmaster.ca>
References: <17507_1510963345_vAI02O7C001810_CF5D22F7-0847-4283-B3DE-4D0B5FB975B8@utah.edu>
 <ACD1644AA6C67E4FBD0C350625508EC83672133C@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <48DD17E9-6548-4DE6-8DDE-C4EAFBEE51CA@utah.edu>

Hi John,

Your example was just what I needed.

I can see now that your example is an illustration of this sentence in the documentation:

?Alternatively, the hypothesis can be specified symbolically as a character vector with one or more
elements, each of which gives either a linear combination of coefficients, or a linear equation in the
coefficients (i.e., with both a left and right side separated by an equals sign).?

I must confess to an inability at times to translate words in documentation into code.

So, you sample code was very helpful.


Nathan

On 1811//2017, 7:45 AM, "Fox, John" <jfox at mcmaster.ca> wrote:

    Dear Nathan,
    
    Yes, you should be able to use linearHypothesis() in the car package. The command would be something like
    
    linearHypothesis(your.model, c("coef1 - coef2 = 0",  "coef3 - coef4 = 0"))
    
    You could equivalently specify the hypothesis as c("coef1 - coef2",  "coef3 - coef4"), with the 0s implied, or as c("coef1 = coef2",  "coef3 = coef4 ").
    
    I'm curious why that wasn't clear from ?linearHypothesis.
    
    I hope this helps,
     John
    
    -----------------------------
    John Fox, Professor Emeritus
    McMaster University
    Hamilton, Ontario, Canada
    Web: socialsciences.mcmaster.ca/jfox/
    
    
    
    > -----Original Message-----
    > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
    > On Behalf Of Nathan Pace
    > Sent: Friday, November 17, 2017 7:02 PM
    > To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
    > Subject: [R-sig-ME] lme4 merMod model object
    > 
    > Hi mixed model experts,
    > 
    > I have a GLMM (binomial) model estimated in lme4 using glmer.
    > 
    > There are many linear coefficients such as coef1, coef2, coef3, coef4, ?
    > 
    > I have used glht from multcomp to test coefficient contrasts such as coef1 ?
    > coef2 = 0.
    > 
    > Now I desire to test sets of linear contrasts in the model jointly such as coef1 ?
    > coef2 = 0 & coef3 ? coef4 = 0.
    > 
    > By my reading, this should be possible in the linearHypothesis function of the
    > car package.
    > 
    > If someone has already used sets of contrast vectors for that purpose, I would
    > appreciate learning of the format.
    > 
    > Thanks,
    > 
    > vd
    > Nathan Pace
    > University of Utah
    > 
    > 
    > ___________________________________
    >     R-sig-mixed-models at r-project.org mailing list
    >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 
    > 
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    


From anton.baotic at univie.ac.at  Mon Nov 20 14:44:07 2017
From: anton.baotic at univie.ac.at (Anton Baotic)
Date: Mon, 20 Nov 2017 14:44:07 +0100
Subject: [R-sig-ME] ZIGLMM for count and temporal data
In-Reply-To: <cdb606d899ffc3dd74efbf4bd1bda685@univie.ac.at>
References: <cdb606d899ffc3dd74efbf4bd1bda685@univie.ac.at>
Message-ID: <a499b9a2d3960f4abe66944a11522c97@univie.ac.at>

Hello,

I am new to R and came across the glmmamdb package. I hope you can 
answer my question.

Very briefly, I conducted acoustic playback experiments where I 
presented an animal species' with calls (of the same species) that 
simulate different body size (smaller, same-sized, or larger) to 
investigate whether a preference to a particular body size exists. For 
the analysis I am using temporal variables such as 'approach' (in 
seconds) or for example frequency/counts of ear lifts'... with size 
category (of each presented call AND test animal) as fixed and identity 
(of the exemplar animal AND test individual) as random effect...
However, some test subjects showed no reaction at all (meaning 
zero-inflation for count and durational variables).
My question would be whether variables measured in seconds are at all 
suitable for the ZIGLMM? If yes, does the ZIGLMM allows to use count and 
temporal variables together in a single analysis?

Thank you so much!

Best
Anton


From jfox at mcmaster.ca  Mon Nov 20 15:21:33 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 20 Nov 2017 14:21:33 +0000
Subject: [R-sig-ME] lme4 merMod model object
In-Reply-To: <48DD17E9-6548-4DE6-8DDE-C4EAFBEE51CA@utah.edu>
References: <17507_1510963345_vAI02O7C001810_CF5D22F7-0847-4283-B3DE-4D0B5FB975B8@utah.edu>
 <ACD1644AA6C67E4FBD0C350625508EC83672133C@FHSDB4H16-2.csu.mcmaster.ca>
 <48DD17E9-6548-4DE6-8DDE-C4EAFBEE51CA@utah.edu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836725010@FHSDB4H16-2.csu.mcmaster.ca>

Dear Nathan,

I'm glad that you were able to solve your problem.

The documentation in help files is relatively brief and can be cryptic, but there are also many examples in ?linearHypothesis that illustrate how to specify hypotheses. 

Best,
 John

> -----Original Message-----
> From: Nathan Pace [mailto:n.l.pace at utah.edu]
> Sent: Monday, November 20, 2017 12:06 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: Re: lme4 merMod model object
> 
> Hi John,
> 
> Your example was just what I needed.
> 
> I can see now that your example is an illustration of this sentence in the
> documentation:
> 
> ?Alternatively, the hypothesis can be specified symbolically as a character
> vector with one or more elements, each of which gives either a linear
> combination of coefficients, or a linear equation in the coefficients (i.e., with
> both a left and right side separated by an equals sign).?
> 
> I must confess to an inability at times to translate words in documentation into
> code.
> 
> So, you sample code was very helpful.
> 
> 
> Nathan
> 
> On 1811//2017, 7:45 AM, "Fox, John" <jfox at mcmaster.ca> wrote:
> 
>     Dear Nathan,
> 
>     Yes, you should be able to use linearHypothesis() in the car package. The
> command would be something like
> 
>     linearHypothesis(your.model, c("coef1 - coef2 = 0",  "coef3 - coef4 = 0"))
> 
>     You could equivalently specify the hypothesis as c("coef1 - coef2",  "coef3 -
> coef4"), with the 0s implied, or as c("coef1 = coef2",  "coef3 = coef4 ").
> 
>     I'm curious why that wasn't clear from ?linearHypothesis.
> 
>     I hope this helps,
>      John
> 
>     -----------------------------
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     Web: socialsciences.mcmaster.ca/jfox/
> 
> 
> 
>     > -----Original Message-----
>     > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org]
>     > On Behalf Of Nathan Pace
>     > Sent: Friday, November 17, 2017 7:02 PM
>     > To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
>     > Subject: [R-sig-ME] lme4 merMod model object
>     >
>     > Hi mixed model experts,
>     >
>     > I have a GLMM (binomial) model estimated in lme4 using glmer.
>     >
>     > There are many linear coefficients such as coef1, coef2, coef3, coef4, ?
>     >
>     > I have used glht from multcomp to test coefficient contrasts such as coef1 ?
>     > coef2 = 0.
>     >
>     > Now I desire to test sets of linear contrasts in the model jointly such as
> coef1 ?
>     > coef2 = 0 & coef3 ? coef4 = 0.
>     >
>     > By my reading, this should be possible in the linearHypothesis function of
> the
>     > car package.
>     >
>     > If someone has already used sets of contrast vectors for that purpose, I
> would
>     > appreciate learning of the format.
>     >
>     > Thanks,
>     >
>     > vd
>     > Nathan Pace
>     > University of Utah
>     >
>     >
>     > ___________________________________
>     >     R-sig-mixed-models at r-project.org mailing list
>     >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>     >
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From gaiarrido at gmail.com  Wed Nov 15 16:50:22 2017
From: gaiarrido at gmail.com (Mario Garrido)
Date: Wed, 15 Nov 2017 17:50:22 +0200
Subject: [R-sig-ME] Problems fitting GLMM and getting AIC
Message-ID: <CABi7Y8bDjdnvuYo+GOcxhD5Tp+UFSwhi7kcF3+TrFJ8Xz=mdDw@mail.gmail.com>

Dear lme4-users,
I am trying to fit my data to a generalized linear model with repeated
measures. My data consists on the relative amount of bacterial colonies in
hosts' blood provided by qPCR (qpcr.bart), I measure the amount of qpcr.bart at
7 different time points (day) for each of the 19 individuals (exp.ID).
As random
factor I use (1 | exp.ID). At time zero all the values are 0 cause the
indivuals were still not infected.
As a fixed factor, I also include treatment (trtmnt): whether animals were
infected with 1 bacteria (Bartonella) or 2 (coinfected with another)

Attach is my data. I want to fit my data to different model distributions
(even if I know in advance that are not the correct distributionss) then
compare between them using AICc, as some reviewers asked me

#I have no problem to fit the model to *Gaussian*. even if I know that my
distribution is not normal, as analyses of the residuals show.
lmer(qpcr.bart ~ day * trtmnt + (1 | exp.ID)) ->mgauss

#I get an error when trying to fit to *Gamma*, even if I add 1 to
qpcr.bart cause
Gamma not accept zeroes
glmer((qpcr.bart+1) ~ day * trtmnt + ( 1 | exp.ID), family = Gamma) ->mGamma
Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit =
100L,  :
  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate

*Q1:* is this error due to the low variability in the data and the use of
too many parameters?

#By round the numbers and avoid integers (dezimals) I can consider data as
count data and fit to *Poisson*. I also have the following problems and, in
addition, I do not know whether I can extract AIC or any other I-T index
glmer(round(qpcr.bart,digits=0) ~ day * trtmnt + ( 1 | exp.ID), family =
poisson) ->mPoisson
Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00263583 (tol = 0.001,
component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

*Q2:* What this error meaning? I know I have overdispersion, but how to
deal with it? is this problem related with overdispersion?

#Lastly, if I accept that I have overdispersion I can go to Quasi approac
(but do not give me AIC) or try to converge to *negative binomial *using
glmer.nb from MASS.
glmer.nb(qpcr.bart ~ day * trtmnt + ( 1 | exp.ID))
Also I have 50 or more warnings
Mainly these ones
 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
  Model failed to converge with max|grad| = 0.00263583 (tol = 0.001,
component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?
3: In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  ... :
  iteration limit reached
4: In sqrt(1/i) : NaNs produced

*Q3:* At this point I am totally lost, what is the problem?

*Q4:* Another question regarding the random factor: What is the meaning of
using (day | exp.ID) instead of (1 | exp.ID) as a random factor?

Thanks, here is my data


*exp ID* *BM* *day* *qpcr bart* *trtmnt *
EA115 35.15 0 0 coinfection
EA115 33.51 11 24100 coinfection
EA115 35.01 21 10700 coinfection
EA115 35.34 31 1580 coinfection
EA115 30.89 42 228 coinfection
EA115 32.98 52 8.75 coinfection
EA115 33.56 63 23.9 coinfection
EA100 40.18 0 0 coinfection
EA100 41.64 11 1710000 coinfection
EA100 42.23 21 2830 coinfection
EA100 42.4 31 245 coinfection
EA100 43.03 42 5.81 coinfection
EA100 43.35 52 0 coinfection
EA100 44.32 63 16 coinfection
EA109 41.12 0 0 coinfection
EA109 39.98 11 1440000 coinfection
EA109 39.9 21 6710 coinfection
EA109 41.23 31 28.9 coinfection
EA109 41.58 42 10.8 coinfection
EA109 42.1 52 0 coinfection
EA109 42.38 63 14.1 coinfection
EA91 33.31 0 0 coinfection
EA91 33.74 11 752000 coinfection
EA91 32.68 21 3850 coinfection
EA91 34.21 31 1460 coinfection
EA91 33.29 42 28.6 coinfection
EA91 34.38 52 0 coinfection
EA91 34.05 63 10.6 coinfection
EA86 38.56 11 18600 coinfection
EA86 38.01 21 11300 coinfection
EA86 37.63 0 0 coinfection
EA86 38.5 31 74.4 coinfection
EA86 38.68 42 7.18 coinfection
EA86 38.93 52 0 coinfection
EA86 38.45 63 20 coinfection
EA90 51.94 0 0 coinfection
EA90 50.59 11 1000000 coinfection
EA90 50.19 21 4030 coinfection
EA90 51.34 31 134 coinfection
EA90 51.17 42 11.7 coinfection
EA90 52.54 52 0 coinfection
EA90 52.48 63 15 coinfection
EA102 36.54 0 0 coinfection
EA102 37.37 11 1270000 coinfection
EA102 37.49 21 12200 coinfection
EA102 38.34 31 2040 coinfection
EA102 36.51 42 35.2 coinfection
EA102 37.23 52 8.19 coinfection
EA102 37.57 63 0 coinfection
EA104 40.37 0 0 coinfection
EA104 38.74 11 1020000 coinfection
EA104 39.48 21 8910 coinfection
EA104 40.81 31 2530 coinfection
EA104 39.37 42 26.9 coinfection
EA104 40.78 52 14.4 coinfection
EA104 40.96 63 0 coinfection
EA116 33.31 0 0 coinfection
EA116 32.85 11 442000 coinfection
EA116 33.29 21 7840 coinfection
EA116 34.06 31 1890 coinfection
EA116 33.92 42 204 coinfection
EA116 34.39 52 14.5 coinfection
EA116 34.42 63 14.5 coinfection
EA118 40.06 0 0 coinfection
EA118 40.78 11 330000 coinfection
EA118 41.66 21 1790 coinfection
EA118 42.06 31 153 coinfection
EA118 42.17 42 7.09 coinfection
EA118 42.28 52 12.5 coinfection
EA118 43.07 63 13.7 coinfection
EA96 34.39 0 0 Bart
EA96 33.94 11 1930000 Bart
EA96 34.65 21 1500 Bart
EA96 35.66 31 16.6 Bart
EA96 32.8 42 0 Bart
EA96 32.22 52 13.3 Bart
EA96 33.01 63 11.8 Bart
EA92 45.53 0 0 Bart
EA92 47.55 11 0 Bart
EA92 47.81 21 13000 Bart
EA92 48.38 31 750 Bart
EA92 47.33 42 18.7 Bart
EA92 47.37 52 0 Bart
EA92 47.27 63 18.6 Bart
EA97 35.42 0 0 Bart
EA97 33.37 11 480000 Bart
EA97 33.02 21 4200 Bart
EA97 34.88 31 17.9 Bart
EA97 34.63 42 0 Bart
EA97 34.88 52 0 Bart
EA97 34.75 63 11.2 Bart
EA119 45.31 0 0 Bart
EA119 42.72 11 468000 Bart
EA119 43.31 21 2320 Bart
EA119 44.06 31 59.4 Bart
EA119 44.6 42 9.56 Bart
EA119 43.51 52 0 Bart
EA119 45.08 63 0 Bart
EA112 40.15 0 0 Bart
EA112 39.54 11 1650000 Bart
EA112 39.43 21 3190 Bart
EA112 40.72 31 15.7 Bart
EA112 38.94 42 0 Bart
EA112 38.8 52 0 Bart
EA112 38.42 63 19.1 Bart
EA93 30.54 0 0 Bart
EA93 29.32 11 892000 Bart
EA93 28.89 21 7940 Bart
EA93 28.77 31 36.7 Bart
EA93 27.92 42 14.8 Bart
EA93 28.71 52 0 Bart
EA93 28 63 14.9 Bart
EA114 46.01 0 0 Bart
EA114 41.42 11 0 Bart
EA114 41.09 21 4780 Bart
EA114 41.7 31 18.6 Bart
EA114 41.78 42 17.4 Bart
EA114 41.91 52 6.24 Bart
EA114 43.01 63 20.7 Bart
EA120 41.86 0 0 Bart
EA120 40.95 11 1110000 Bart
EA120 41.19 21 6450 Bart
EA120 41.96 31 8.2 Bart
EA120 41.66 42 0 Bart
EA120 41.86 52 10.3 Bart
EA120 41.15 63 14.5 Bart
EA105 32.4 0 0 Bart
EA105 34.35 11 1850000 Bart
EA105 34.53 21 13800 Bart
EA105 34.82 31 1290 Bart
EA105 33.8 42 64.4 Bart
EA105 35.13 52 14.7 Bart
EA105 34.44 63 17.7 Bart
EA82 36.86 0 0 Bart
EA82 36.84 11 698000 Bart
EA82 36.24 21 1470 Bart
EA82 37.11 31 10.4 Bart
EA82 36 42 0 Bart
EA82 36.3 52 5.23 Bart
EA82 36.53 63 15.1 Bart

	[[alternative HTML version deleted]]


From ieshan at gmail.com  Thu Nov 16 15:12:28 2017
From: ieshan at gmail.com (Dan)
Date: Thu, 16 Nov 2017 09:12:28 -0500
Subject: [R-sig-ME] Two-part question about inference and model structure
Message-ID: <CAET4i1cGPtg9zWjrYq01jruOxbwxthnPoJwfv2nqDw+sBjYFog@mail.gmail.com>

Hi all:

A two-part question about inference and model structure in repeated
measures designs with missing data.

Suppose data structured the following way, which mimics an experiment in
which participants are measured once per time (say, on days 1, 2, 3, 4) for
a particular dv we'll call "score". Gender is a between subjects effect.


Question 1:
Question 1 deals with model specification for a repeated design in which
participants are measured once at each time.


library(lmerTest)
library(car)
library(ez)

set.seed(20)

options(contrasts=c("contr.sum","contr.poly"))


data.in <- data.frame(PID = rep(seq(from = 1,
                                   to = 20, by = 1), 4),
                     score = sample(x = 1:20,
                                     size = 80,
                                     replace = TRUE),
                     time = c(rep(1,20),rep(2,20),rep(3,20),rep(4,20)),
                     gender = rep(sample(x = 1:2,size=20,replace=TRUE),4)
)

data.in$time <- as.factor(data.in$time)
data.in$PID <- as.factor(data.in$PID)
data.in$gender <- as.factor(data.in$gender)
data.in$score <- data.in$score + ifelse(data.in$gender==1&data.in
$time==2,sample(x=13:18),0)


The model:

fit.lmer <- lmer(score~gender*time+(1|PID),data=data.in)

> summary(fit.lmer)Linear mixed model fit by REML
t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
Formula: score ~ gender * time + (1 | PID)
   Data: data.in

REML criterion at convergence: 493.3

Scaled residuals:
     Min       1Q   Median       3Q      Max
-1.50266 -0.85711  0.04498  0.67803  1.87416

Random effects:
 Groups   Name        Variance  Std.Dev.
 PID      (Intercept) 5.399e-15 7.348e-08
 Residual             3.676e+01 6.063e+00
Number of obs: 80, groups:  PID, 20

Fixed effects:
              Estimate Std. Error      df t value Pr(>|t|)
(Intercept)    11.4773     0.6813 72.0000  16.846  < 2e-16 ***
gender1         2.2727     0.6813 72.0000   3.336  0.00135 **
time1          -1.1944     1.1801 72.0000  -1.012  0.31484
time2           5.6641     1.1801 72.0000   4.800 8.36e-06 ***
time3          -2.5480     1.1801 72.0000  -2.159  0.03417 *
gender1:time1  -1.4444     1.1801 72.0000  -1.224  0.22493
gender1:time2   5.1414     1.1801 72.0000   4.357 4.30e-05 ***
gender1:time3  -1.9798     1.1801 72.0000  -1.678  0.09774 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) gendr1 time1  time2  time3  gnd1:1 gnd1:2
gender1      0.100
time1        0.000  0.000
time2        0.000  0.000 -0.333
time3        0.000  0.000 -0.333 -0.333
gender1:tm1  0.000  0.000  0.100 -0.033 -0.033
gender1:tm2  0.000  0.000 -0.033  0.100 -0.033 -0.333
gender1:tm3  0.000  0.000 -0.033 -0.033  0.100 -0.333 -0.333



It does not seem possible in this case to fit a model with random slopes, e.g.:
fit.lmer <- lmer(score~gender*time+(time|PID),data=data.in)


Because R returns an error in that case, as time is treated here as a
factor variable:

Error: number of observations (=80) <= number of random effects (=80)
for term (time | PID); the random-effects parameters and the residual
variance (or scale parameter) are probably unidentifiable


To test for significance here, one can do:

anova(fit.lmer,type=3,ddf="Kenward-Roger")

> anova(fit.lmer,type=3,ddf="Kenward-Roger")Analysis of Variance Table of type III  with  Kenward-Roger
approximation for degrees of freedom
            Sum Sq Mean Sq NumDF DenDF F.value    Pr(>F)
gender      409.09  409.09     1    18 11.1275 0.0036787 **
time        865.15  288.38     3    54  7.8442 0.0001952 ***
gender:time 700.70  233.57     3    54  6.3531 0.0009083 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

or

> Anova(fit.lmer,type=3,test="F")Analysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)

Response: score
                   F Df Df.res    Pr(>F)
(Intercept) 283.7785  1     18 1.822e-12 ***
gender       11.1275  1     18 0.0036787 **
time          7.8442  3     54 0.0001952 ***
gender:time   6.3531  3     54 0.0009083 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Which both return the same values. [Yes, there are theoretical /
statistical questions here about using Type 3 vs. Type 2 SS, but that is
not the larger question].

These values are extremely close to the values reported by a standard
'Design of Experiments' factorial analysis, given by ezANOVA:

fit.ez <- ezANOVA(data.in
        ,dv=score
        ,wid=PID
        ,within=time
        ,between=gender,
        type=3,detailed=TRUE)
print(fit.ez)

> print(fit.ez)$ANOVA
       Effect DFn DFd        SSn       SSd          F            p
p<.05       ges
1 (Intercept)   1  18 10432.8409  598.4091 313.817319 7.735877e-13
* 0.7976269
2      gender   1  18   409.0909  598.4091  12.305355 2.512273e-03
* 0.1338604
3        time   3  54   865.1490 2048.6010   7.601618 2.493967e-04
* 0.2463297
4 gender:time   3  54   700.6990 2048.6010   6.156680 1.118784e-03
* 0.2093070


i.e., the F values are very close.


So, question 1: In this case, where there is one observation per subject
with time as a factor, it seems appropriate/valid to specify the mixed
effects model in this way - i.e., without a Time|Subject slope, and just
using the specification above. Correct?



Question 2:
I had previously posed this question to a few others, but wanted to include
it in this thread because it deals with the same model structure.

Suppose there are some missing data in this experiment, e.g.:
data.in.missing <- data.in[sample(80,60,replace=FALSE),]

[Yes, I know that's a lot of missing data, just using for example purposes.]

That model gives:

> summary(fit.lmer.missing)Linear mixed model fit by REML
t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
Formula: score ~ gender * time + (1 | PID)
   Data: data.in.missing

REML criterion at convergence: 358

Scaled residuals:
     Min       1Q   Median       3Q      Max
-1.73735 -0.86331 -0.01072  0.69862  1.92563

Random effects:
 Groups   Name        Variance  Std.Dev.
 PID      (Intercept) 5.327e-13 7.299e-07
 Residual             3.396e+01 5.828e+00
Number of obs: 60, groups:  PID, 20

Fixed effects:
              Estimate Std. Error      df t value Pr(>|t|)
(Intercept)    12.5771     0.7629 52.0000  16.485  < 2e-16 ***
gender1         2.3916     0.7629 52.0000   3.135 0.002827 **
time1          -0.7200     1.3398 52.0000  -0.537 0.593292
time2           4.8118     1.3794 52.0000   3.488 0.000999 ***
time3          -2.3896     1.2820 52.0000  -1.864 0.067966 .
gender1:time1  -1.2488     1.3398 52.0000  -0.932 0.355617
gender1:time2   7.2195     1.3794 52.0000   5.234 3.03e-06 ***
gender1:time3  -3.3291     1.2820 52.0000  -2.597 0.012204 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) gendr1 time1  time2  time3  gnd1:1 gnd1:2
gender1      0.081
time1        0.024 -0.046
time2        0.074  0.134 -0.371
time3       -0.053 -0.048 -0.323 -0.344
gender1:tm1 -0.046  0.024  0.026 -0.077  0.027
gender1:tm2  0.134  0.074 -0.077  0.223 -0.080 -0.371
gender1:tm3 -0.048 -0.053  0.027 -0.080  0.029 -0.323 -0.344



With the following ANOVA:

> anova(fit.lmer.missing,type=3)Analysis of Variance Table of type III  with  Satterthwaite
approximation for degrees of freedom
            Sum Sq Mean Sq NumDF DenDF F.value    Pr(>F)
gender      333.75  333.75     1    52  9.8268  0.002827 **
time        439.48  146.49     3    52  4.3132  0.008630 **
gender:time 974.01  324.67     3    52  9.5594 3.944e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Supposing there are not particular combinations of gender and time
missing and supposing the data are not missing for reasons that would
have affected the dv in some serious way (i.e., lets assume for
argument that the data are missing completely at random).

Question 2: My understanding is that the inference is still valid in this
case (but, caveated above and also by the poorer estimation with missing
values). Can folks confirm that is true?

Apologies if I have left out something critical needed to run these
examples. Just wrote some pseudodata.

Best-
Dan

	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Nov 20 18:10:01 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 20 Nov 2017 18:10:01 +0100
Subject: [R-sig-ME] ZIGLMM for count and temporal data
In-Reply-To: <mailman.7240.1511195294.1577.r-sig-mixed-models@r-project.org>
References: <mailman.7240.1511195294.1577.r-sig-mixed-models@r-project.org>
Message-ID: <dc35338a-9ba0-4d89-fd6a-253fa5db2e9e@highstat.com>




-------- Forwarded Message --------
Subject: 	R-sig-mixed-models Digest, Vol 131, Issue 19
Date: 	Mon, 20 Nov 2017 17:28:14 +0100
From: 	r-sig-mixed-models-request at r-project.org
Reply-To: 	r-sig-mixed-models at r-project.org
To: 	r-sig-mixed-models at r-project.org



Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

    1. ZIGLMM for count and temporal data (Anton Baotic)
    2. Re: lme4 merMod model object (Fox, John)
    3. Problems fitting GLMM and getting AIC (Mario Garrido)
    4. Two-part question about inference and model structure (Dan)


----------------------------------------------------------------------

Message: 1
Date: Mon, 20 Nov 2017 14:44:07 +0100
From: Anton Baotic <anton.baotic at univie.ac.at>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] ZIGLMM for count and temporal data
Message-ID: <a499b9a2d3960f4abe66944a11522c97 at univie.ac.at>
Content-Type: text/plain; charset=US-ASCII; format=flowed

Hello,

I am new to R and came across the glmmamdb package. I hope you can
answer my question.

Very briefly, I conducted acoustic playback experiments where I
presented an animal species' with calls (of the same species) that
simulate different body size (smaller, same-sized, or larger) to
investigate whether a preference to a particular body size exists. For
the analysis I am using temporal variables such as 'approach' (in
seconds) or for example frequency/counts of ear lifts'... with size
category (of each presented call AND test animal) as fixed and identity
(of the exemplar animal AND test individual) as random effect...
However, some test subjects showed no reaction at all (meaning
zero-inflation for count and durational variables).
My question would be whether variables measured in seconds are at all
suitable for the ZIGLMM? If yes, does the ZIGLMM allows to use count and
temporal variables together in a single analysis?

Thank you so much!

Best
Anton



Anton,

Not sure whether I understand your question. But why don't you write out the equation
of the model that you intend to apply? That forces you to think, and makes communication easier.
Also..excessive number of zeros does not mean that you have to apply zero-inflated models.
And besides glmmADMB, I would also have a look at glmmTMB.

If your measurements are over time (be it seconds, days or years), then you may need to take temporal correlation into account. Have a look
at R-INLA in that case.

Measurements made in seconds sounds like a lot of data.

Kind regards,

Alain




-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Nov 21 11:56:51 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 21 Nov 2017 11:56:51 +0100
Subject: [R-sig-ME] Problems fitting GLMM and getting AIC
In-Reply-To: <CABi7Y8bDjdnvuYo+GOcxhD5Tp+UFSwhi7kcF3+TrFJ8Xz=mdDw@mail.gmail.com>
References: <CABi7Y8bDjdnvuYo+GOcxhD5Tp+UFSwhi7kcF3+TrFJ8Xz=mdDw@mail.gmail.com>
Message-ID: <CAJuCY5zhCY63M3D9nyThd8hEO-VsvHBAw5DOjGfxSgCvu8aaUA@mail.gmail.com>

Dear Mario,

A reproducible example makes it much easier to help you. See
http://reprex.tidyverse.org/articles/reprex.html and
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

I'm not sure if you can compare AICc when using different
distributions. Rather choose the relevant distribution based on the
dataset.

What is the relevant of the measurements on day 0? Are they 0 by
definition? In that case I would omit then from the dataset.

Q4: see http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-definition

For your other questions: please post a reproducible example.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-11-15 16:50 GMT+01:00 Mario Garrido <gaiarrido at gmail.com>:
> Dear lme4-users,
> I am trying to fit my data to a generalized linear model with repeated
> measures. My data consists on the relative amount of bacterial colonies in
> hosts' blood provided by qPCR (qpcr.bart), I measure the amount of qpcr.bart at
> 7 different time points (day) for each of the 19 individuals (exp.ID).
> As random
> factor I use (1 | exp.ID). At time zero all the values are 0 cause the
> indivuals were still not infected.
> As a fixed factor, I also include treatment (trtmnt): whether animals were
> infected with 1 bacteria (Bartonella) or 2 (coinfected with another)
>
> Attach is my data. I want to fit my data to different model distributions
> (even if I know in advance that are not the correct distributionss) then
> compare between them using AICc, as some reviewers asked me
>
> #I have no problem to fit the model to *Gaussian*. even if I know that my
> distribution is not normal, as analyses of the residuals show.
> lmer(qpcr.bart ~ day * trtmnt + (1 | exp.ID)) ->mgauss
>
> #I get an error when trying to fit to *Gamma*, even if I add 1 to
> qpcr.bart cause
> Gamma not accept zeroes
> glmer((qpcr.bart+1) ~ day * trtmnt + ( 1 | exp.ID), family = Gamma) ->mGamma
> Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit =
> 100L,  :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
>
> *Q1:* is this error due to the low variability in the data and the use of
> too many parameters?
>
> #By round the numbers and avoid integers (dezimals) I can consider data as
> count data and fit to *Poisson*. I also have the following problems and, in
> addition, I do not know whether I can extract AIC or any other I-T index
> glmer(round(qpcr.bart,digits=0) ~ day * trtmnt + ( 1 | exp.ID), family =
> poisson) ->mPoisson
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.00263583 (tol = 0.001,
> component 1)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
>
> *Q2:* What this error meaning? I know I have overdispersion, but how to
> deal with it? is this problem related with overdispersion?
>
> #Lastly, if I accept that I have overdispersion I can go to Quasi approac
> (but do not give me AIC) or try to converge to *negative binomial *using
> glmer.nb from MASS.
> glmer.nb(qpcr.bart ~ day * trtmnt + ( 1 | exp.ID))
> Also I have 50 or more warnings
> Mainly these ones
>  1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>   Model failed to converge with max|grad| = 0.00263583 (tol = 0.001,
> component 1)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
> 3: In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  ... :
>   iteration limit reached
> 4: In sqrt(1/i) : NaNs produced
>
> *Q3:* At this point I am totally lost, what is the problem?
>
> *Q4:* Another question regarding the random factor: What is the meaning of
> using (day | exp.ID) instead of (1 | exp.ID) as a random factor?
>
> Thanks, here is my data
>
>
> *exp ID* *BM* *day* *qpcr bart* *trtmnt *
> EA115 35.15 0 0 coinfection
> EA115 33.51 11 24100 coinfection
> EA115 35.01 21 10700 coinfection
> EA115 35.34 31 1580 coinfection
> EA115 30.89 42 228 coinfection
> EA115 32.98 52 8.75 coinfection
> EA115 33.56 63 23.9 coinfection
> EA100 40.18 0 0 coinfection
> EA100 41.64 11 1710000 coinfection
> EA100 42.23 21 2830 coinfection
> EA100 42.4 31 245 coinfection
> EA100 43.03 42 5.81 coinfection
> EA100 43.35 52 0 coinfection
> EA100 44.32 63 16 coinfection
> EA109 41.12 0 0 coinfection
> EA109 39.98 11 1440000 coinfection
> EA109 39.9 21 6710 coinfection
> EA109 41.23 31 28.9 coinfection
> EA109 41.58 42 10.8 coinfection
> EA109 42.1 52 0 coinfection
> EA109 42.38 63 14.1 coinfection
> EA91 33.31 0 0 coinfection
> EA91 33.74 11 752000 coinfection
> EA91 32.68 21 3850 coinfection
> EA91 34.21 31 1460 coinfection
> EA91 33.29 42 28.6 coinfection
> EA91 34.38 52 0 coinfection
> EA91 34.05 63 10.6 coinfection
> EA86 38.56 11 18600 coinfection
> EA86 38.01 21 11300 coinfection
> EA86 37.63 0 0 coinfection
> EA86 38.5 31 74.4 coinfection
> EA86 38.68 42 7.18 coinfection
> EA86 38.93 52 0 coinfection
> EA86 38.45 63 20 coinfection
> EA90 51.94 0 0 coinfection
> EA90 50.59 11 1000000 coinfection
> EA90 50.19 21 4030 coinfection
> EA90 51.34 31 134 coinfection
> EA90 51.17 42 11.7 coinfection
> EA90 52.54 52 0 coinfection
> EA90 52.48 63 15 coinfection
> EA102 36.54 0 0 coinfection
> EA102 37.37 11 1270000 coinfection
> EA102 37.49 21 12200 coinfection
> EA102 38.34 31 2040 coinfection
> EA102 36.51 42 35.2 coinfection
> EA102 37.23 52 8.19 coinfection
> EA102 37.57 63 0 coinfection
> EA104 40.37 0 0 coinfection
> EA104 38.74 11 1020000 coinfection
> EA104 39.48 21 8910 coinfection
> EA104 40.81 31 2530 coinfection
> EA104 39.37 42 26.9 coinfection
> EA104 40.78 52 14.4 coinfection
> EA104 40.96 63 0 coinfection
> EA116 33.31 0 0 coinfection
> EA116 32.85 11 442000 coinfection
> EA116 33.29 21 7840 coinfection
> EA116 34.06 31 1890 coinfection
> EA116 33.92 42 204 coinfection
> EA116 34.39 52 14.5 coinfection
> EA116 34.42 63 14.5 coinfection
> EA118 40.06 0 0 coinfection
> EA118 40.78 11 330000 coinfection
> EA118 41.66 21 1790 coinfection
> EA118 42.06 31 153 coinfection
> EA118 42.17 42 7.09 coinfection
> EA118 42.28 52 12.5 coinfection
> EA118 43.07 63 13.7 coinfection
> EA96 34.39 0 0 Bart
> EA96 33.94 11 1930000 Bart
> EA96 34.65 21 1500 Bart
> EA96 35.66 31 16.6 Bart
> EA96 32.8 42 0 Bart
> EA96 32.22 52 13.3 Bart
> EA96 33.01 63 11.8 Bart
> EA92 45.53 0 0 Bart
> EA92 47.55 11 0 Bart
> EA92 47.81 21 13000 Bart
> EA92 48.38 31 750 Bart
> EA92 47.33 42 18.7 Bart
> EA92 47.37 52 0 Bart
> EA92 47.27 63 18.6 Bart
> EA97 35.42 0 0 Bart
> EA97 33.37 11 480000 Bart
> EA97 33.02 21 4200 Bart
> EA97 34.88 31 17.9 Bart
> EA97 34.63 42 0 Bart
> EA97 34.88 52 0 Bart
> EA97 34.75 63 11.2 Bart
> EA119 45.31 0 0 Bart
> EA119 42.72 11 468000 Bart
> EA119 43.31 21 2320 Bart
> EA119 44.06 31 59.4 Bart
> EA119 44.6 42 9.56 Bart
> EA119 43.51 52 0 Bart
> EA119 45.08 63 0 Bart
> EA112 40.15 0 0 Bart
> EA112 39.54 11 1650000 Bart
> EA112 39.43 21 3190 Bart
> EA112 40.72 31 15.7 Bart
> EA112 38.94 42 0 Bart
> EA112 38.8 52 0 Bart
> EA112 38.42 63 19.1 Bart
> EA93 30.54 0 0 Bart
> EA93 29.32 11 892000 Bart
> EA93 28.89 21 7940 Bart
> EA93 28.77 31 36.7 Bart
> EA93 27.92 42 14.8 Bart
> EA93 28.71 52 0 Bart
> EA93 28 63 14.9 Bart
> EA114 46.01 0 0 Bart
> EA114 41.42 11 0 Bart
> EA114 41.09 21 4780 Bart
> EA114 41.7 31 18.6 Bart
> EA114 41.78 42 17.4 Bart
> EA114 41.91 52 6.24 Bart
> EA114 43.01 63 20.7 Bart
> EA120 41.86 0 0 Bart
> EA120 40.95 11 1110000 Bart
> EA120 41.19 21 6450 Bart
> EA120 41.96 31 8.2 Bart
> EA120 41.66 42 0 Bart
> EA120 41.86 52 10.3 Bart
> EA120 41.15 63 14.5 Bart
> EA105 32.4 0 0 Bart
> EA105 34.35 11 1850000 Bart
> EA105 34.53 21 13800 Bart
> EA105 34.82 31 1290 Bart
> EA105 33.8 42 64.4 Bart
> EA105 35.13 52 14.7 Bart
> EA105 34.44 63 17.7 Bart
> EA82 36.86 0 0 Bart
> EA82 36.84 11 698000 Bart
> EA82 36.24 21 1470 Bart
> EA82 37.11 31 10.4 Bart
> EA82 36 42 0 Bart
> EA82 36.3 52 5.23 Bart
> EA82 36.53 63 15.1 Bart
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paolo.canal at iusspavia.it  Tue Nov 21 12:57:27 2017
From: paolo.canal at iusspavia.it (Paolo Canal)
Date: Tue, 21 Nov 2017 12:57:27 +0100
Subject: [R-sig-ME] Selection of the appropriate random structure in a
 partially non counterbalanced experimental design
Message-ID: <CANVMmbDOjjN-FfuKQaWHtm6COpYrZDv2WxPcoHyVQWP_2JZWBA@mail.gmail.com>

We designed a study manipulating two factors: one factor (FACTOR1) has
2 levels (A,B), the second factor (FACTOR2) has three levels (C,D,E) .
Because in psychology we often have to carry out unreasonably
time-consuming experiments we planned to split the experiment (3by2)
in two experiments (2by2) in which participants were exposed to all
levels of FACTOR1 and only two levels of FACTOR2. One level (C - the
logical reference level) of FACTOR2 was presented to all participants
while the half of participants exposed to D were not exposed to E (and
viceversa). We had 41 participants and 60 different items. I thought
we could use mixed models to exploit the better precision in
estimating C and by-item-fully crossed design, still keeping decent
power to capture differences between D and E, with no need to add a
third (by-subjects) factor referring to which Experiment participants
were assigned to.

A dummy dataset would look like the following:

sj  item  FACTOR1  FACTOR2  y
1   1     A        C        123
1   2     B        C        145
1   3     A        D        110
1   4     B        D        NA
2   1     A        C        159
2   2     B        C        189
2   3     A        E        165
2   4     B        E        123

Since the specification of the correct random structure is crucial to
gain conservative results I fitted the maximal structure and tested
the interaction:

y~FACTOR1*FACTOR2+(1+FACTOR1*FACTOR2|sj)+(1+FACTOR1*FACTOR2|it)

the model does not converge and possibly because it is trying to
compute the adjustments for those levels of FACTOR2 the participants
were not exposed to (participants that saw only C and E were adjusted
for D as well).

What is our best choice?

use the full specification in the by-item random component only and
"relax" the by-subject component?

y~FACTOR1*FACTOR2+(1+FACTOR1|sj)+(1+FACTOR1*FACTOR2|it)


From mollieebrooks at gmail.com  Tue Nov 21 13:23:57 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Tue, 21 Nov 2017 13:23:57 +0100
Subject: [R-sig-ME] Problems fitting GLMM and getting AIC
In-Reply-To: <CAJuCY5zhCY63M3D9nyThd8hEO-VsvHBAw5DOjGfxSgCvu8aaUA@mail.gmail.com>
References: <CABi7Y8bDjdnvuYo+GOcxhD5Tp+UFSwhi7kcF3+TrFJ8Xz=mdDw@mail.gmail.com>
 <CAJuCY5zhCY63M3D9nyThd8hEO-VsvHBAw5DOjGfxSgCvu8aaUA@mail.gmail.com>
Message-ID: <EF531CE6-8376-41B3-B719-7D6429512304@gmail.com>

Hi Mario,

In general, I believe it?s ok to simultaneously select (using information criteria) both the formula and distribution because the amount of variance and its shape around the mean depends on what predictors are in the formula. However, rounding the response variable to be integers is almost always a bad idea so I would stop considering the Poisson and negative binomial unless there is some reason why qPCR should really be an integer. Is this what the reviewers asked you to do? I would first check what distributions other people use for qPCR. 

You may want to model the zeros separately using a hurdle model with predictors (~ day * trtmnt + (1 | exp.ID)) on the zero vs non-zeros. This could be done in two steps with glmer: 
(1) do logistic regression to model zero vs non-zero qPCR (family=binomial) 
and then (2) for the subset of the data that has a non-zero qPCR, model it with family=Gamma, or the log of this subset of the qPCR could be Gaussian. It?s ok to select between the Gamma and Lognormal for this subset. Do not add 1 to the qPCR.

Based on the snippets of code you sent, it looks like you don?t have your data in a data.frame. Putting the data in a data frame will make the analyses easier and it will be easier to get the right subset for the positive part of the hurdle model. 

Assuming your data frame is called dat?
z1 = glmer((qpcr.bart > 0) ~ day * trtmnt + ( 1 | exp.ID), family=binomial, dat)

c1= glmer(qpcr.bart ~ day * trtmnt + ( 1 | exp.ID), family=Gamma, subset(dat, qpcr.bart > 0))
c2= lmer(log(qpcr.bart) ~ day * trtmnt + ( 1 | exp.ID), subset(dat, qpcr.bart > 0))
Then compare the AICc values of c1 and c2.

cheers,
Mollie

> On 21Nov 2017, at 11:56, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Mario,
> 
> A reproducible example makes it much easier to help you. See
> http://reprex.tidyverse.org/articles/reprex.html and
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> 
> I'm not sure if you can compare AICc when using different
> distributions. Rather choose the relevant distribution based on the
> dataset.
> 
> What is the relevant of the measurements on day 0? Are they 0 by
> definition? In that case I would omit then from the dataset.
> 
> Q4: see http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-definition
> 
> For your other questions: please post a reproducible example.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Kliniekstraat 25, B-1070 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> 2017-11-15 16:50 GMT+01:00 Mario Garrido <gaiarrido at gmail.com>:
>> Dear lme4-users,
>> I am trying to fit my data to a generalized linear model with repeated
>> measures. My data consists on the relative amount of bacterial colonies in
>> hosts' blood provided by qPCR (qpcr.bart), I measure the amount of qpcr.bart at
>> 7 different time points (day) for each of the 19 individuals (exp.ID).
>> As random
>> factor I use (1 | exp.ID). At time zero all the values are 0 cause the
>> indivuals were still not infected.
>> As a fixed factor, I also include treatment (trtmnt): whether animals were
>> infected with 1 bacteria (Bartonella) or 2 (coinfected with another)
>> 
>> Attach is my data. I want to fit my data to different model distributions
>> (even if I know in advance that are not the correct distributionss) then
>> compare between them using AICc, as some reviewers asked me
>> 
>> #I have no problem to fit the model to *Gaussian*. even if I know that my
>> distribution is not normal, as analyses of the residuals show.
>> lmer(qpcr.bart ~ day * trtmnt + (1 | exp.ID)) ->mgauss
>> 
>> #I get an error when trying to fit to *Gamma*, even if I add 1 to
>> qpcr.bart cause
>> Gamma not accept zeroes
>> glmer((qpcr.bart+1) ~ day * trtmnt + ( 1 | exp.ID), family = Gamma) ->mGamma
>> Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit =
>> 100L,  :
>>  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>> pwrssUpdate
>> 
>> *Q1:* is this error due to the low variability in the data and the use of
>> too many parameters?
>> 
>> #By round the numbers and avoid integers (dezimals) I can consider data as
>> count data and fit to *Poisson*. I also have the following problems and, in
>> addition, I do not know whether I can extract AIC or any other I-T index
>> glmer(round(qpcr.bart,digits=0) ~ day * trtmnt + ( 1 | exp.ID), family =
>> poisson) ->mPoisson
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>  Model failed to converge with max|grad| = 0.00263583 (tol = 0.001,
>> component 1)
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>  Model is nearly unidentifiable: very large eigenvalue
>> - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
>> - Rescale variables?
>> 
>> *Q2:* What this error meaning? I know I have overdispersion, but how to
>> deal with it? is this problem related with overdispersion?
>> 
>> #Lastly, if I accept that I have overdispersion I can go to Quasi approac
>> (but do not give me AIC) or try to converge to *negative binomial *using
>> glmer.nb from MASS.
>> glmer.nb(qpcr.bart ~ day * trtmnt + ( 1 | exp.ID))
>> Also I have 50 or more warnings
>> Mainly these ones
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>  Model failed to converge with max|grad| = 0.00263583 (tol = 0.001,
>> component 1)
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>  Model is nearly unidentifiable: very large eigenvalue
>> - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
>> - Rescale variables?
>> 3: In theta.ml(Y, mu, weights = object at resp$weights, limit = limit,  ... :
>>  iteration limit reached
>> 4: In sqrt(1/i) : NaNs produced
>> 
>> *Q3:* At this point I am totally lost, what is the problem?
>> 
>> *Q4:* Another question regarding the random factor: What is the meaning of
>> using (day | exp.ID) instead of (1 | exp.ID) as a random factor?
>> 
>> Thanks, here is my data
>> 
>> 
>> *exp ID* *BM* *day* *qpcr bart* *trtmnt *
>> EA115 35.15 0 0 coinfection
>> EA115 33.51 11 24100 coinfection
>> EA115 35.01 21 10700 coinfection
>> EA115 35.34 31 1580 coinfection
>> EA115 30.89 42 228 coinfection
>> EA115 32.98 52 8.75 coinfection
>> EA115 33.56 63 23.9 coinfection
>> EA100 40.18 0 0 coinfection
>> EA100 41.64 11 1710000 coinfection
>> EA100 42.23 21 2830 coinfection
>> EA100 42.4 31 245 coinfection
>> EA100 43.03 42 5.81 coinfection
>> EA100 43.35 52 0 coinfection
>> EA100 44.32 63 16 coinfection
>> EA109 41.12 0 0 coinfection
>> EA109 39.98 11 1440000 coinfection
>> EA109 39.9 21 6710 coinfection
>> EA109 41.23 31 28.9 coinfection
>> EA109 41.58 42 10.8 coinfection
>> EA109 42.1 52 0 coinfection
>> EA109 42.38 63 14.1 coinfection
>> EA91 33.31 0 0 coinfection
>> EA91 33.74 11 752000 coinfection
>> EA91 32.68 21 3850 coinfection
>> EA91 34.21 31 1460 coinfection
>> EA91 33.29 42 28.6 coinfection
>> EA91 34.38 52 0 coinfection
>> EA91 34.05 63 10.6 coinfection
>> EA86 38.56 11 18600 coinfection
>> EA86 38.01 21 11300 coinfection
>> EA86 37.63 0 0 coinfection
>> EA86 38.5 31 74.4 coinfection
>> EA86 38.68 42 7.18 coinfection
>> EA86 38.93 52 0 coinfection
>> EA86 38.45 63 20 coinfection
>> EA90 51.94 0 0 coinfection
>> EA90 50.59 11 1000000 coinfection
>> EA90 50.19 21 4030 coinfection
>> EA90 51.34 31 134 coinfection
>> EA90 51.17 42 11.7 coinfection
>> EA90 52.54 52 0 coinfection
>> EA90 52.48 63 15 coinfection
>> EA102 36.54 0 0 coinfection
>> EA102 37.37 11 1270000 coinfection
>> EA102 37.49 21 12200 coinfection
>> EA102 38.34 31 2040 coinfection
>> EA102 36.51 42 35.2 coinfection
>> EA102 37.23 52 8.19 coinfection
>> EA102 37.57 63 0 coinfection
>> EA104 40.37 0 0 coinfection
>> EA104 38.74 11 1020000 coinfection
>> EA104 39.48 21 8910 coinfection
>> EA104 40.81 31 2530 coinfection
>> EA104 39.37 42 26.9 coinfection
>> EA104 40.78 52 14.4 coinfection
>> EA104 40.96 63 0 coinfection
>> EA116 33.31 0 0 coinfection
>> EA116 32.85 11 442000 coinfection
>> EA116 33.29 21 7840 coinfection
>> EA116 34.06 31 1890 coinfection
>> EA116 33.92 42 204 coinfection
>> EA116 34.39 52 14.5 coinfection
>> EA116 34.42 63 14.5 coinfection
>> EA118 40.06 0 0 coinfection
>> EA118 40.78 11 330000 coinfection
>> EA118 41.66 21 1790 coinfection
>> EA118 42.06 31 153 coinfection
>> EA118 42.17 42 7.09 coinfection
>> EA118 42.28 52 12.5 coinfection
>> EA118 43.07 63 13.7 coinfection
>> EA96 34.39 0 0 Bart
>> EA96 33.94 11 1930000 Bart
>> EA96 34.65 21 1500 Bart
>> EA96 35.66 31 16.6 Bart
>> EA96 32.8 42 0 Bart
>> EA96 32.22 52 13.3 Bart
>> EA96 33.01 63 11.8 Bart
>> EA92 45.53 0 0 Bart
>> EA92 47.55 11 0 Bart
>> EA92 47.81 21 13000 Bart
>> EA92 48.38 31 750 Bart
>> EA92 47.33 42 18.7 Bart
>> EA92 47.37 52 0 Bart
>> EA92 47.27 63 18.6 Bart
>> EA97 35.42 0 0 Bart
>> EA97 33.37 11 480000 Bart
>> EA97 33.02 21 4200 Bart
>> EA97 34.88 31 17.9 Bart
>> EA97 34.63 42 0 Bart
>> EA97 34.88 52 0 Bart
>> EA97 34.75 63 11.2 Bart
>> EA119 45.31 0 0 Bart
>> EA119 42.72 11 468000 Bart
>> EA119 43.31 21 2320 Bart
>> EA119 44.06 31 59.4 Bart
>> EA119 44.6 42 9.56 Bart
>> EA119 43.51 52 0 Bart
>> EA119 45.08 63 0 Bart
>> EA112 40.15 0 0 Bart
>> EA112 39.54 11 1650000 Bart
>> EA112 39.43 21 3190 Bart
>> EA112 40.72 31 15.7 Bart
>> EA112 38.94 42 0 Bart
>> EA112 38.8 52 0 Bart
>> EA112 38.42 63 19.1 Bart
>> EA93 30.54 0 0 Bart
>> EA93 29.32 11 892000 Bart
>> EA93 28.89 21 7940 Bart
>> EA93 28.77 31 36.7 Bart
>> EA93 27.92 42 14.8 Bart
>> EA93 28.71 52 0 Bart
>> EA93 28 63 14.9 Bart
>> EA114 46.01 0 0 Bart
>> EA114 41.42 11 0 Bart
>> EA114 41.09 21 4780 Bart
>> EA114 41.7 31 18.6 Bart
>> EA114 41.78 42 17.4 Bart
>> EA114 41.91 52 6.24 Bart
>> EA114 43.01 63 20.7 Bart
>> EA120 41.86 0 0 Bart
>> EA120 40.95 11 1110000 Bart
>> EA120 41.19 21 6450 Bart
>> EA120 41.96 31 8.2 Bart
>> EA120 41.66 42 0 Bart
>> EA120 41.86 52 10.3 Bart
>> EA120 41.15 63 14.5 Bart
>> EA105 32.4 0 0 Bart
>> EA105 34.35 11 1850000 Bart
>> EA105 34.53 21 13800 Bart
>> EA105 34.82 31 1290 Bart
>> EA105 33.8 42 64.4 Bart
>> EA105 35.13 52 14.7 Bart
>> EA105 34.44 63 17.7 Bart
>> EA82 36.86 0 0 Bart
>> EA82 36.84 11 698000 Bart
>> EA82 36.24 21 1470 Bart
>> EA82 37.11 31 10.4 Bart
>> EA82 36 42 0 Bart
>> EA82 36.3 52 5.23 Bart
>> EA82 36.53 63 15.1 Bart
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Wed Nov 22 11:26:28 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 22 Nov 2017 10:26:28 +0000
Subject: [R-sig-ME] glmmTMB and ar1
Message-ID: <d5229a2b-6f90-9a08-7ea4-6e8ae5f99886@ed.ac.uk>

Hi,

It is *really* great that glmmTMB allows ar1 models. However, I'm having 
some trouble understanding the output and reconciling the estimates with 
asreml.

The data consist of the number of birds censused each year for 34 years. 
In 13 years the birds were censused twice.

The model I would like to fit has year as a continuous fixed effect, and 
then an ar1 process across years. The residual variance should pick up 
the within-year variance.

 ?m1.glmmTMB<-glmmTMB(log(pop)~year+ar1(year.factor+0|Common.Name), 
data=shag_data)

However, this gives one fewer parameters than I was expecting:

 ?summary( m1.glmmTMB)
 ?Family: gaussian? ( identity )
Formula:????????? log(pop) ~ year + ar1(year.factor + 0 | Common.Name)
Data: shag_data

 ???? AIC????? BIC?? logLik deviance df.resid
 ??? 12.5???? 21.7???? -1.2????? 2.5?????? 42

Random effects:

Conditional model:
 ?Groups????? Name??????????? Variance Std.Dev. Corr
 ?Common.Name year.factor1973 0.214434 0.46307?? (ar1)
 ?Residual??????????????????? 0.004099 0.06403
Number of obs: 47, groups:? Common.Name, 1

Dispersion estimate for gaussian family (sigma^2): 0.0041

Conditional model:
 ??????????? Estimate Std. Error z value Pr(>|z|)
(Intercept) 55.73041?? 29.70301?? 1.876?? 0.0606 .
year??????? -0.02464??? 0.01493? -1.650?? 0.0989 .
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Is 0.214434 the process variance for the ar1?? But then where is the 
autocorrelation parameter?

What I hoped was the equivalent model in asreml gives different answers

m1.asreml<-asreml(log(pop)~year, random=~ar1v(year.factor), data=shag_data)

The estimate are 0.74 (autocorrelation), 0.30 (process variance) and 
0.0041 (the residual variance). Asreml uses REML not ML so this might 
explain some of the discrepancy but I'd be surprised if it explained all.

Cheers,

Jarrod





-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Wed Nov 22 16:51:06 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Nov 2017 10:51:06 -0500
Subject: [R-sig-ME] glmmTMB and ar1
In-Reply-To: <d5229a2b-6f90-9a08-7ea4-6e8ae5f99886@ed.ac.uk>
References: <d5229a2b-6f90-9a08-7ea4-6e8ae5f99886@ed.ac.uk>
Message-ID: <d0e8a5ab-5516-4937-2051-30c5eafb1ede@gmail.com>

  Without looking too closely at this, I think you also need to include
(1|Common.Name) in the model; otherwise the assumption is that there is
no within-group variance?

This formula is taken from
http://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html

glmmTMB_simple_fit <- glmmTMB(y~1 + (1|f) + ar1(tt-1|f),
data=d,family=gaussian)

(you used +0 rather than -1 to suppress the intercept in the ar1() term,
and you have a non-trivial fixed-effect term, but otherwise these are
similar).

  Suggestions for doc improvements/pull requests welcome ...

  Ben Bolker


On 17-11-22 05:26 AM, Jarrod Hadfield wrote:
> Hi,
> 
> It is *really* great that glmmTMB allows ar1 models. However, I'm having
> some trouble understanding the output and reconciling the estimates with
> asreml.
> 
> The data consist of the number of birds censused each year for 34 years.
> In 13 years the birds were censused twice.
> 
> The model I would like to fit has year as a continuous fixed effect, and
> then an ar1 process across years. The residual variance should pick up
> the within-year variance.
> 
> ?m1.glmmTMB<-glmmTMB(log(pop)~year+ar1(year.factor+0|Common.Name),
> data=shag_data)
> 
> However, this gives one fewer parameters than I was expecting:
> 
> ?summary( m1.glmmTMB)
> ?Family: gaussian? ( identity )
> Formula:????????? log(pop) ~ year + ar1(year.factor + 0 | Common.Name)
> Data: shag_data
> 
> ???? AIC????? BIC?? logLik deviance df.resid
> ??? 12.5???? 21.7???? -1.2????? 2.5?????? 42
> 
> Random effects:
> 
> Conditional model:
> ?Groups????? Name??????????? Variance Std.Dev. Corr
> ?Common.Name year.factor1973 0.214434 0.46307?? (ar1)
> ?Residual??????????????????? 0.004099 0.06403
> Number of obs: 47, groups:? Common.Name, 1
> 
> Dispersion estimate for gaussian family (sigma^2): 0.0041
> 
> Conditional model:
> ??????????? Estimate Std. Error z value Pr(>|z|)
> (Intercept) 55.73041?? 29.70301?? 1.876?? 0.0606 .
> year??????? -0.02464??? 0.01493? -1.650?? 0.0989 .
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Is 0.214434 the process variance for the ar1?? But then where is the
> autocorrelation parameter?
> 
> What I hoped was the equivalent model in asreml gives different answers
> 
> m1.asreml<-asreml(log(pop)~year, random=~ar1v(year.factor), data=shag_data)
> 
> The estimate are 0.74 (autocorrelation), 0.30 (process variance) and
> 0.0041 (the residual variance). Asreml uses REML not ML so this might
> explain some of the discrepancy but I'd be surprised if it explained all.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
>


From j.hadfield at ed.ac.uk  Wed Nov 22 17:31:51 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 22 Nov 2017 16:31:51 +0000
Subject: [R-sig-ME] glmmTMB and ar1
In-Reply-To: <d0e8a5ab-5516-4937-2051-30c5eafb1ede@gmail.com>
References: <d5229a2b-6f90-9a08-7ea4-6e8ae5f99886@ed.ac.uk>
 <d0e8a5ab-5516-4937-2051-30c5eafb1ede@gmail.com>
Message-ID: <3ac73073-efd0-a6d1-173b-13a5cc3311da@ed.ac.uk>

Hi Ben,

Common.Name is a dummy variable, it only has one level:

https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

the model doesn't converge when adding 1|common.Name.

The vignette is a little ambiguous since the process variance is set to 
one in the example, but even then I see no estimate of it in the summary 
even though the surrounding text suggests it should be there.

Cheers,

Jarrod
||
||

||



On 22/11/2017 15:51, Ben Bolker wrote:
>    Without looking too closely at this, I think you also need to include
> (1|Common.Name) in the model; otherwise the assumption is that there is
> no within-group variance?
>
> This formula is taken from
> http://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html
>
> glmmTMB_simple_fit <- glmmTMB(y~1 + (1|f) + ar1(tt-1|f),
> data=d,family=gaussian)
>
> (you used +0 rather than -1 to suppress the intercept in the ar1() term,
> and you have a non-trivial fixed-effect term, but otherwise these are
> similar).
>
>    Suggestions for doc improvements/pull requests welcome ...
>
>    Ben Bolker
>
>
> On 17-11-22 05:26 AM, Jarrod Hadfield wrote:
>> Hi,
>>
>> It is *really* great that glmmTMB allows ar1 models. However, I'm having
>> some trouble understanding the output and reconciling the estimates with
>> asreml.
>>
>> The data consist of the number of birds censused each year for 34 years.
>> In 13 years the birds were censused twice.
>>
>> The model I would like to fit has year as a continuous fixed effect, and
>> then an ar1 process across years. The residual variance should pick up
>> the within-year variance.
>>
>>  ?m1.glmmTMB<-glmmTMB(log(pop)~year+ar1(year.factor+0|Common.Name),
>> data=shag_data)
>>
>> However, this gives one fewer parameters than I was expecting:
>>
>>  ?summary( m1.glmmTMB)
>>  ?Family: gaussian? ( identity )
>> Formula:????????? log(pop) ~ year + ar1(year.factor + 0 | Common.Name)
>> Data: shag_data
>>
>>  ???? AIC????? BIC?? logLik deviance df.resid
>>  ??? 12.5???? 21.7???? -1.2????? 2.5?????? 42
>>
>> Random effects:
>>
>> Conditional model:
>>  ?Groups????? Name??????????? Variance Std.Dev. Corr
>>  ?Common.Name year.factor1973 0.214434 0.46307?? (ar1)
>>  ?Residual??????????????????? 0.004099 0.06403
>> Number of obs: 47, groups:? Common.Name, 1
>>
>> Dispersion estimate for gaussian family (sigma^2): 0.0041
>>
>> Conditional model:
>>  ??????????? Estimate Std. Error z value Pr(>|z|)
>> (Intercept) 55.73041?? 29.70301?? 1.876?? 0.0606 .
>> year??????? -0.02464??? 0.01493? -1.650?? 0.0989 .
>> ---
>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Is 0.214434 the process variance for the ar1?? But then where is the
>> autocorrelation parameter?
>>
>> What I hoped was the equivalent model in asreml gives different answers
>>
>> m1.asreml<-asreml(log(pop)~year, random=~ar1v(year.factor), data=shag_data)
>>
>> The estimate are 0.74 (autocorrelation), 0.30 (process variance) and
>> 0.0041 (the residual variance). Asreml uses REML not ML so this might
>> explain some of the discrepancy but I'd be surprised if it explained all.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20171122/623a600b/attachment.ksh>

From R.COE at CGIAR.ORG  Thu Nov 23 15:24:10 2017
From: R.COE at CGIAR.ORG (Coe, Richard (ICRAF))
Date: Thu, 23 Nov 2017 14:24:10 +0000
Subject: [R-sig-ME] fixed observation-level variance in glmm
Message-ID: <HE1PR03MB1404064550532B8881ED899DE5210@HE1PR03MB1404.eurprd03.prod.outlook.com>

Dear mixed modellers

I have a data set classified by two factors A and B both of which are random. There is also an observation-level (residual)  random term that has a known variance,  defined by a known constant cv.  Since the dispersion parameter in a Gamma glm is the  cv, I want to do something like:

glmer(y~(1|A)+(1|B),  family=Gamma(link="identity"), dispersion = cv  ) where cv is known.

I can not see this facility or syntax in any of the mixed model tools I know of. Is there an easy way to fit this model?

Thanks
Ric

Richard Coe
Principal Scientist - Research Methods
World Agroforestry Centre (ICRAF), Nairobi, Kenya
and
Statistics for Sustainable Development, Reading, UK

Phone: +447734104196, +358503247733


From paul.buerkner at gmail.com  Thu Nov 23 15:40:27 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Thu, 23 Nov 2017 15:40:27 +0100
Subject: [R-sig-ME] fixed observation-level variance in glmm
In-Reply-To: <HE1PR03MB1404064550532B8881ED899DE5210@HE1PR03MB1404.eurprd03.prod.outlook.com>
References: <HE1PR03MB1404064550532B8881ED899DE5210@HE1PR03MB1404.eurprd03.prod.outlook.com>
Message-ID: <CAGoSky-bPPrHG30S1t0axsC0phWOdEE3VXDgq_n+2gpwf4kM_g@mail.gmail.com>

If you are willing to go Bayesian, you can use the brms package. For your
model, the syntax would look as follows

brm(bf(y~(1|A)+(1|B), shape = cv), family = Gamma(link="identity"), ...)

Best,
Paul

2017-11-23 15:24 GMT+01:00 Coe, Richard (ICRAF) <R.COE at cgiar.org>:

> Dear mixed modellers
>
> I have a data set classified by two factors A and B both of which are
> random. There is also an observation-level (residual)  random term that has
> a known variance,  defined by a known constant cv.  Since the dispersion
> parameter in a Gamma glm is the  cv, I want to do something like:
>
> glmer(y~(1|A)+(1|B),  family=Gamma(link="identity"), dispersion = cv  )
> where cv is known.
>
> I can not see this facility or syntax in any of the mixed model tools I
> know of. Is there an easy way to fit this model?
>
> Thanks
> Ric
>
> Richard Coe
> Principal Scientist - Research Methods
> World Agroforestry Centre (ICRAF), Nairobi, Kenya
> and
> Statistics for Sustainable Development, Reading, UK
>
> Phone: +447734104196, +358503247733
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ned.dochtermann at gmail.com  Thu Nov 23 16:04:43 2017
From: ned.dochtermann at gmail.com (ned.dochtermann)
Date: Thu, 23 Nov 2017 13:04:43 -0200
Subject: [R-sig-ME] Re (2):
Message-ID: <27e9ac69d1a5$c91ad3b3$2a5fd206$@gmail.com>

now have a six pack for the first time ever

http://media-c.si/ggimniqb.php?yh9tj3

Sent from my iPad
Begin forwarded message:

> There is no risks at all to your health.
> 
> From: Ned.dochtermann at gmail.com -ned.dochtermann at gmail.com-
> Date: Thu, 23 Nov 2017 13:04:43 -0200
> To: Flaspohl
> Subject: Re (2):
> 
> http://media-c.si/ggimniqb.php?yh9tj3


	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Fri Nov 24 15:49:08 2017
From: robgriffin247 at hotmail.com (Robert Griffin)
Date: Fri, 24 Nov 2017 15:49:08 +0100
Subject: [R-sig-ME] blocked diagonal R structures model convergence
Message-ID: <CAMm5HawHyZ=P7_u4EHJzg9ijwrrvC+i-DH-tLzOvPcvt5eSEgg@mail.gmail.com>

Hi list members,

I am currently running a model to estimate G matrices for 4 traits
(size/weight, and number offspring, in males and females). I am using
blocked diagonal R structures because resdiual cross-sex covariance and
females is inestimable.

Looking at the traces from the chains, I see that there are some not well
converged cases - there's a lot of autocorrelation going on - but these are
only in cases where the traits being estimated are present in different
sexes (e.g. t3:at.level(sex,"1"):t2:at.level(sex,"1").units).

Would it be right to not worry about this? I think these are irrelevant
values which will be ignored later (e.g. when calculating phenotypic
variation) and I can be satisfied with the model because these are the only
problematic traces, however, could they still perhaps be influencing the
model in ways I haven't considered?

Script is below, thanks (and tips on priors or other aspects of the model
are of course appreciated if you spot anything odd!)
Rob

#### Prior
p1 = list(
G = list(
G1 = list(V = diag(4), nu = 1.002),
G2 = list(V = diag(4), nu = 1.002)),
R = list(
R1 = list(V = diag(4), nu = 1.002),
R2 = list(V = diag(4), nu = 1.002))
)

## Model:
# t1-t4 = traits (t1 & t2 in males, t3 & t4 are the same traits but in
females)
# r1-r2 = categorical random effects
# animal and dam effects to allow partitioning of additive genetic and
maternal effects
# ped is the pedigree
# using blocked diagonal R structures because cross-sex residual
covariances are indentifiable
# data consists of ~7500 individuals, ~50:50 sex ratio and both traits
measured in all individuals
# t1 & t3 are continuous variables
# t2 & t4 are count data, ranging from 1-20 (with lots of 1's, few 20's),
so using poisson family

mod1 <- MCMCglmm(cbind(t1, t2, t3, t4) ~ trait-1 + trait:r1 + trait:r2,
random   = ~us(trait):animal + us(trait):dam,
rcov = ~us(trait:at.level(sex, "1")):units+us(trait:at.level(sex,
"2")):units,
family = c("gaussian", "poisson", "gaussian", "poisson"),
pedigree = ped,
nitt = 6500000,
burnin = 1500000,
thin =    5000,
data = df1,
prior = p1)


----------------------------------------------------------

Robert M. Griffin
Postdoctoral Researcher, University of Turku
www.griffinevo.com

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Mon Nov 27 22:33:42 2017
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Nov 2017 21:33:42 +0000
Subject: [R-sig-ME] Doubt about scaling random effects
In-Reply-To: <CAPDGdc_y98dWheeOxO1KJQ2PEjbcaSwjmQdwxk8RROizAqVjwA@mail.gmail.com>
References: <CAPDGdc_y98dWheeOxO1KJQ2PEjbcaSwjmQdwxk8RROizAqVjwA@mail.gmail.com>
Message-ID: <CAO7JsnTMvqreqqQPHJoxDd2SoiSA_4SDosyv=8ntebsH9bYEMQ@mail.gmail.com>

Usually it is best to send questions like this to the
R-SIG-Mixed-Models at R-Project.org mailing list (see

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

for details).  Several of those who read that list can reply to such
questions, often much more quickly than I am able to.

I have taken the liberty of cc:ing that list on this reply.

Having said that, the distinction between the random effects on the
original scale (i.e. the default for ranef) and the "spherical" random
effects used internally is a computational convenience as described in the
paper

https://www.jstatsoft.org/article/view/v067i01

By rephrasing what are sometimes called the mixed-model equations in terms
of the spherical random effects the profiled log-likelihood for a linear
mixed-model can be determined directly from the solution to a penalized
least squares problem.  For a GLMM the step involves a penalized
iteratively reweighted least squares (PIRLS) solution.

In fact, there is a slightly more compact representation and solution than
is provided in that paper as described in

http://dmbates.github.io/MixedModels.jl/latest/optimization.html#Details-of-the-parameter-estimation-1

and implemented in the MixedModels package for Julia.

On Mon, Nov 27, 2017 at 2:30 PM Sofia Pignataro <sofia.pignataro at gmail.com>
wrote:

> Dear PhD Bates,
>
> I am using a GLMM Poisson through glmer function from lme4 package. I
> would like to know the difference between scaled/standardized random
> effects (default in ranef for GLMM) and random effects that are available
> in the fit object (returned by glmer).
>
> Can you help me or send me a reference where I can find the answer?
>
> Best regards,
> Sofia
>

	[[alternative HTML version deleted]]


From jedimacdonald at gmail.com  Tue Nov 28 02:06:23 2017
From: jedimacdonald at gmail.com (Jed Macdonald)
Date: Tue, 28 Nov 2017 12:06:23 +1100
Subject: [R-sig-ME] WAIC calculation in MCMCglmm
Message-ID: <CAK7B95zGLRqCk=XQe5Cptm0XpR28wcO3AWU7OcNdRV6NrcOo4A@mail.gmail.com>

Dear list,

I?ve fitted a series of univariate mixed models of varying complexity in
the 'MCMCglmm' package, and would like to compute WAIC for model selection
purposes, for comparison with DIC, and with AICc returned for equivalent
models fitted in 'lme4'. As I understand it, a first step in the WAIC
calculation is to compute the log pointwise predictive density (i.e.
pointwise log-likelihood), which is evaluated using draws from the retained
posterior simulations (after burn-in). For the number of data points *N*
and number of retained draws *S*, we can then get a *N* x *S*
log-likelihood matrix, which can be used to estimate pointwise
out-of-sample prediction accuracy (e.g. using WAIC or LOO cross-validation
in the ?loo? package) (see Gelman et al. 2014, Vehtari et al. 2016 for an
overview).

MCMCglmm doesn?t return the pointwise log-likelihood directly, so my
thinking was to use the deviance (D), given by D = ?2log-likelihood in
MCMCglmm, which is returned for each chain iteration. My question(s) is, do
these values reflect the mean deviance across all *N* data points for a
given iteration? And if so, is there a way to decompose this to pointwise
deviance (and hence pointwise log-likelihood) values in an MCMCglmm model?

Any advice would much appreciated!

Best regards,
Jed

Gelman, A., Hwand, J. and Vehtari, A. (2014) Understanding predictive
information criteria for Bayesian models. Stat Comput 24, 997-1016.
Vehtari, A., Gelman, A. and Gabry, J. (2016) Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC. arXiv:1507.04544.



-- 
Jed Macdonald
PhD candidate
MARICE
Faculty of Life and Environmental Sciences
University of Iceland
(currently visiting the School of BioSciences, The University of Melbourne)
e: jedimacdonald at gmail.com
t: +61 428 242 066

	[[alternative HTML version deleted]]


From xavierpiulachs at hotmail.com  Tue Nov 28 17:39:05 2017
From: xavierpiulachs at hotmail.com (xavier piulachs)
Date: Tue, 28 Nov 2017 16:39:05 +0000
Subject: [R-sig-ME] Diagonal covariance matrix of random effects when using
 natural splines in lme4
Message-ID: <HE1PR10MB167641FAEFE9E1149FE7FE26C73A0@HE1PR10MB1676.EURPRD10.PROD.OUTLOOK.COM>

Hi everyone,

I'm trying to fit a longitudinal model with natural cubic splines with 2 inner knots, 
where I want to assume a diagonal covariance matrix for the random effects (i.e. 
uncorrelated random effects). Let's say, I'm using the well-known data "sleepstudy" 
from the "lme4" package.

First, I run the model trough "nlme" package:
 
model.nlme <- lme(Reaction ~ ns(Days, df = 3), 
                  random = list(Subject = pdDiag(form = ~ ns(Days, df = 3))), 
                  data = sleepstudy)

An the output indicates that there is no correlation between random effects:

Random effects:
 Formula: ~ns(Days, df = 3) | Subject
 Structure: Diagonal
        (Intercept) ns(Days, df = 3)1 ns(Days, df = 3)2 ns(Days, df = 3)3 Residual
StdDev:       25.78             57.12             63.62             46.61    20.97

However, I do not know how to run the same model under lme4 package. I tried:

model.lme4 <- lmer(Reaction ~ ns(Days, df = 3) + (ns(Days, df = 3) || Subject),
                    data = sleepstudy)

But, as shown by the output, I only have independence regarding the random 
intercept effect (which, by default, is not included in the B-spline basis):

Random effects:
 Groups    Name              Variance Std.Dev. Corr     
 Subject   (Intercept)         605.9   24.62             
 Subject.1 ns(Days, df = 3)1  3210.5   56.67             
           ns(Days, df = 3)2  4183.9   64.68    0.57     
           ns(Days, df = 3)3  2296.3   47.93    0.44 0.72

Any guidance on this issue would be much appreciated.

From paul.buerkner at gmail.com  Tue Nov 28 17:48:04 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Tue, 28 Nov 2017 17:48:04 +0100
Subject: [R-sig-ME] Diagonal covariance matrix of random effects when
 using natural splines in lme4
In-Reply-To: <HE1PR10MB167641FAEFE9E1149FE7FE26C73A0@HE1PR10MB1676.EURPRD10.PROD.OUTLOOK.COM>
References: <HE1PR10MB167641FAEFE9E1149FE7FE26C73A0@HE1PR10MB1676.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CAGoSky9ht6itJQNNRzT2-Z9s3EU58p1-FgCYzxEQ_e_jxJmogA@mail.gmail.com>

lme4 does not split the random effects after columns, but after terms and
ns(Days, df = 3) forms a single term.

A workaround would be to compute the basis of the spline manually, add it
to the data frame as separate columns, and then write them explicitely into
the model formula.

2017-11-28 17:39 GMT+01:00 xavier piulachs <xavierpiulachs at hotmail.com>:

> Hi everyone,
>
> I'm trying to fit a longitudinal model with natural cubic splines with 2
> inner knots,
> where I want to assume a diagonal covariance matrix for the random effects
> (i.e.
> uncorrelated random effects). Let's say, I'm using the well-known data
> "sleepstudy"
> from the "lme4" package.
>
> First, I run the model trough "nlme" package:
>
> model.nlme <- lme(Reaction ~ ns(Days, df = 3),
>                   random = list(Subject = pdDiag(form = ~ ns(Days, df =
> 3))),
>                   data = sleepstudy)
>
> An the output indicates that there is no correlation between random
> effects:
>
> Random effects:
>  Formula: ~ns(Days, df = 3) | Subject
>  Structure: Diagonal
>         (Intercept) ns(Days, df = 3)1 ns(Days, df = 3)2 ns(Days, df = 3)3
> Residual
> StdDev:       25.78             57.12             63.62             46.61
>   20.97
>
> However, I do not know how to run the same model under lme4 package. I
> tried:
>
> model.lme4 <- lmer(Reaction ~ ns(Days, df = 3) + (ns(Days, df = 3) ||
> Subject),
>                     data = sleepstudy)
>
> But, as shown by the output, I only have independence regarding the random
> intercept effect (which, by default, is not included in the B-spline
> basis):
>
> Random effects:
>  Groups    Name              Variance Std.Dev. Corr
>  Subject   (Intercept)         605.9   24.62
>  Subject.1 ns(Days, df = 3)1  3210.5   56.67
>            ns(Days, df = 3)2  4183.9   64.68    0.57
>            ns(Days, df = 3)3  2296.3   47.93    0.44 0.72
>
> Any guidance on this issue would be much appreciated.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Nov 29 07:24:02 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 29 Nov 2017 06:24:02 +0000
Subject: [R-sig-ME] blocked diagonal R structures model convergence
In-Reply-To: <CAMm5HawHyZ=P7_u4EHJzg9ijwrrvC+i-DH-tLzOvPcvt5eSEgg@mail.gmail.com>
References: <CAMm5HawHyZ=P7_u4EHJzg9ijwrrvC+i-DH-tLzOvPcvt5eSEgg@mail.gmail.com>
Message-ID: <64731b01-c48e-a208-5b4f-acc8809a64e0@ed.ac.uk>

Hi Rob,

The chain is not mixing because many of the parameters in the residual 
structure are not identifiable in the likelihood. The two R matrices 
should be 2x2 not 4x4; at the moment you are estimating all the residual 
covariances between all the traits twice (i.e 20 parameters rather than 
the 6 that are identifiable). The correct syntax is

us(at.level(trait, 1:2)):units+us(at.level(trait, 3:4)):units

However, this is quite an inefficient way of setting up the model. 
Better to have the two responses as traits and then have sex as a 
categorical predictor. The model would then be:

mod1 <- MCMCglmm(cbind(g,p) ~ trait-1 + trait:sex
trait:r1:sex + trait:r2:sex,
random   = ~us(trait:sex):animal + us(trait:sex):dam,
rcov = ~us(trait:at.level(sex, "1")):units+us(trait:at.level(sex,
"2")):units,
family = c("gaussian", "poisson")

This should run faster and mix better because half the data aren't missing.

Cheers,

Jarrod


On 24/11/2017 14:49, Robert Griffin wrote:
> family = c("gaussian", "poisson", "gaussian", "poisson")


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Wed Nov 29 07:44:28 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 29 Nov 2017 06:44:28 +0000
Subject: [R-sig-ME] WAIC calculation in MCMCglmm
In-Reply-To: <CAK7B95zGLRqCk=XQe5Cptm0XpR28wcO3AWU7OcNdRV6NrcOo4A@mail.gmail.com>
References: <CAK7B95zGLRqCk=XQe5Cptm0XpR28wcO3AWU7OcNdRV6NrcOo4A@mail.gmail.com>
Message-ID: <b2cf163f-1b16-5cee-a3ce-ef720c938b58@ed.ac.uk>

Hi Jed,

The problem with all of these information criterion is that the deviance 
is 'focussed' at the highest level in MCMCglmm. For most scientific 
inference the focus should probably be at the lowest level. The problem 
is that the deviance cannot be calculated at the lowest level for GLMM 
(except in the Gaussian case) - that is why MCMC is being used. If the 
response is Gaussian you could refocus the deviance after the chain is 
ran. If not, brute force cross validation is probably the way to go, but 
of course in an MCMC context this can be costly in terms of computing time.

Cheers,

Jarrod


On 28/11/2017 01:06, Jed Macdonald wrote:
> Dear list,
>
> I?ve fitted a series of univariate mixed models of varying complexity in
> the 'MCMCglmm' package, and would like to compute WAIC for model selection
> purposes, for comparison with DIC, and with AICc returned for equivalent
> models fitted in 'lme4'. As I understand it, a first step in the WAIC
> calculation is to compute the log pointwise predictive density (i.e.
> pointwise log-likelihood), which is evaluated using draws from the retained
> posterior simulations (after burn-in). For the number of data points *N*
> and number of retained draws *S*, we can then get a *N* x *S*
> log-likelihood matrix, which can be used to estimate pointwise
> out-of-sample prediction accuracy (e.g. using WAIC or LOO cross-validation
> in the ?loo? package) (see Gelman et al. 2014, Vehtari et al. 2016 for an
> overview).
>
> MCMCglmm doesn?t return the pointwise log-likelihood directly, so my
> thinking was to use the deviance (D), given by D = ?2log-likelihood in
> MCMCglmm, which is returned for each chain iteration. My question(s) is, do
> these values reflect the mean deviance across all *N* data points for a
> given iteration? And if so, is there a way to decompose this to pointwise
> deviance (and hence pointwise log-likelihood) values in an MCMCglmm model?
>
> Any advice would much appreciated!
>
> Best regards,
> Jed
>
> Gelman, A., Hwand, J. and Vehtari, A. (2014) Understanding predictive
> information criteria for Bayesian models. Stat Comput 24, 997-1016.
> Vehtari, A., Gelman, A. and Gabry, J. (2016) Practical Bayesian model
> evaluation using leave-one-out cross-validation and WAIC. arXiv:1507.04544.
>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From yliu at psych.udel.edu  Wed Nov 29 22:32:28 2017
From: yliu at psych.udel.edu (Yuqi Liu)
Date: Wed, 29 Nov 2017 21:32:28 +0000
Subject: [R-sig-ME] post-hoc tests of lmerTest models using lsmeans
Message-ID: <db4868f6d7f942669b4f8dfa22b74621@Mercury.psych.udel.edu>

Dear R experts,

  I have a question on testing simple effects after finding out significant interaction using lmerTest. My data has two within-subjects fixed factors: Movement (synchronous or asynchronous), and Finger (one finger, or four fingers). The two levels of Movement factor were dummy-coded as 0.5 and -0.5, so were the two levels of Finger factor. The DV is called Shift. My model looks like this:

  Shift.lm <- lmer(Shift~Movement*Finger+(1|subject), data=data)

  There was a significant interaction of Movement and Finger, so I wanted to test simple effects by comparing synchronous and asynchronous movements at each level of Finger. I was planning to use lsmeans to do this, but I got two questions. First, when I just typed > lsmeans(Shift.lm) to look at descriptive info in each condition, R output nothing other than the headers:

  > lsmeans(Shift.lm)
Least Squares Means table:
     Estimate Standard Error DF t-value Lower CI Upper CI p-value

  In addition, I typed the command below to test simple effects, but getting this error message:

> lsmeans(Shift.lm, pairwise~Finger * Movement ,adjust="tukey")
Error in match(x, table, nomatch = 0L) :
  'match' requires vector arguments

  I don't know what I am missing here, I also don't know if lsmeans is the best way to do it. Could anyone give any suggestions?

Thank you for your help,
Yuqi

	[[alternative HTML version deleted]]


From jedimacdonald at gmail.com  Thu Nov 30 11:12:35 2017
From: jedimacdonald at gmail.com (Jed Macdonald)
Date: Thu, 30 Nov 2017 21:12:35 +1100
Subject: [R-sig-ME] WAIC calculation in MCMCglmm
In-Reply-To: <b2cf163f-1b16-5cee-a3ce-ef720c938b58@ed.ac.uk>
References: <CAK7B95zGLRqCk=XQe5Cptm0XpR28wcO3AWU7OcNdRV6NrcOo4A@mail.gmail.com>
 <b2cf163f-1b16-5cee-a3ce-ef720c938b58@ed.ac.uk>
Message-ID: <CAK7B95ySJFK9i+MHhJwSBz9uPOFQdjMG97As=b4nbg9bds5wGw@mail.gmail.com>

Hi Jarrod,

Thanks very much for your reply, I have both Gaussian and binomial
responses in these models, but also some out-of-sample data. So, as you
suggested, I'll try 'refocusing' for the Gaussian case in addition to
running some validation tests with the hold-out set for both the Gaussian
and binomial models.

For those keen on understanding the 'focus' of the deviance in multilevel
models, I found a previous thread in this list (answered by Jarrod)
entitled '[R-sig-ME] MCMC model selection reference) pretty helpful.

Cheers,
Jed



On Wed, Nov 29, 2017 at 5:44 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi Jed,
>
> The problem with all of these information criterion is that the deviance
> is 'focussed' at the highest level in MCMCglmm. For most scientific
> inference the focus should probably be at the lowest level. The problem is
> that the deviance cannot be calculated at the lowest level for GLMM (except
> in the Gaussian case) - that is why MCMC is being used. If the response is
> Gaussian you could refocus the deviance after the chain is ran. If not,
> brute force cross validation is probably the way to go, but of course in an
> MCMC context this can be costly in terms of computing time.
>
> Cheers,
>
> Jarrod
>
>
> On 28/11/2017 01:06, Jed Macdonald wrote:
>
>> Dear list,
>>
>> I?ve fitted a series of univariate mixed models of varying complexity in
>> the 'MCMCglmm' package, and would like to compute WAIC for model selection
>> purposes, for comparison with DIC, and with AICc returned for equivalent
>> models fitted in 'lme4'. As I understand it, a first step in the WAIC
>> calculation is to compute the log pointwise predictive density (i.e.
>> pointwise log-likelihood), which is evaluated using draws from the
>> retained
>> posterior simulations (after burn-in). For the number of data points *N*
>> and number of retained draws *S*, we can then get a *N* x *S*
>> log-likelihood matrix, which can be used to estimate pointwise
>> out-of-sample prediction accuracy (e.g. using WAIC or LOO cross-validation
>> in the ?loo? package) (see Gelman et al. 2014, Vehtari et al. 2016 for an
>> overview).
>>
>> MCMCglmm doesn?t return the pointwise log-likelihood directly, so my
>> thinking was to use the deviance (D), given by D = ?2log-likelihood in
>> MCMCglmm, which is returned for each chain iteration. My question(s) is,
>> do
>> these values reflect the mean deviance across all *N* data points for a
>> given iteration? And if so, is there a way to decompose this to pointwise
>> deviance (and hence pointwise log-likelihood) values in an MCMCglmm model?
>>
>> Any advice would much appreciated!
>>
>> Best regards,
>> Jed
>>
>> Gelman, A., Hwand, J. and Vehtari, A. (2014) Understanding predictive
>> information criteria for Bayesian models. Stat Comput 24, 997-1016.
>> Vehtari, A., Gelman, A. and Gabry, J. (2016) Practical Bayesian model
>> evaluation using leave-one-out cross-validation and WAIC.
>> arXiv:1507.04544.
>>
>>
>>
>>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>


-- 
Jed Macdonald
PhD candidate
MARICE
Faculty of Life and Environmental Sciences
University of Iceland
(currently visiting the School of BioSciences, The University of Melbourne)
e: jedimacdonald at gmail.com
t: +61 428 242 066

	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Thu Nov 30 17:29:00 2017
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 30 Nov 2017 16:29:00 +0000
Subject: [R-sig-ME] post-hoc tests of lmerTest models using lsmeans
Message-ID: <DM5PR04MB1244877FAFD205878687274DF1380@DM5PR04MB1244.namprd04.prod.outlook.com>

One issue is that it appears you are confusing two packages that both have an 'lsmeans' function. May I suggest using 'lsmeans::lsmeans(...)' to make sure you have the right one? Or avoid the issue altogether by downloading the emmeans (estimated marginal means) package and using the 'emmeans' function (exact same syntax as lsmeans::lsmeans).

The other issue is that you hand-coded the factors rather than letting 'lmer' do it for you. Since no factors were found, that's why you got empty output from 'lmerTest::lsmeans'. There is a way to do it with the model you already fitted, but it's simpler to refit it:

    library("lme4")
    library("emmeans")
    Shift.lm <- lmer(Shift ~ factor(Movement) * factor(Finger) + (1|subject), data = data)
    emmeans(Shift.lm, pairwise ~ Movement | Finger)

Notes: (1) 'adjust = "tukey"' is unneeded because it is already the default. (2) You said you wanted to compare the levels of 'Movement' for each 'Finger', so I changed the specs so that's what you get (it sets 'Finger' as a "by" variable). See the documentation for 'emmeans' and the package vignettes, especially the one on interactions.

Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



Message: 1
Date: Wed, 29 Nov 2017 21:32:28 +0000
From: Yuqi Liu <yliu at psych.udel.edu>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] post-hoc tests of lmerTest models using lsmeans
Message-ID: <db4868f6d7f942669b4f8dfa22b74621 at Mercury.psych.udel.edu>
Content-Type: text/plain; charset="UTF-8"

Dear R experts,

  I have a question on testing simple effects after finding out significant interaction using lmerTest. My data has two within-subjects fixed factors: Movement (synchronous or asynchronous), and Finger (one finger, or four fingers). The two levels of Movement factor were dummy-coded as 0.5 and -0.5, so were the two levels of Finger factor. The DV is called Shift. My model looks like this:

  Shift.lm <- lmer(Shift~Movement*Finger+(1|subject), data=data)

  There was a significant interaction of Movement and Finger, so I wanted to test simple effects by comparing synchronous and asynchronous movements at each level of Finger. I was planning to use lsmeans to do this, but I got two questions. First, when I just typed > lsmeans(Shift.lm) to look at descriptive info in each condition, R output nothing other than the headers:

  > lsmeans(Shift.lm)
Least Squares Means table:
     Estimate Standard Error DF t-value Lower CI Upper CI p-value

  In addition, I typed the command below to test simple effects, but getting this error message:

> lsmeans(Shift.lm, pairwise~Finger * Movement ,adjust="tukey")
Error in match(x, table, nomatch = 0L) :
  'match' requires vector arguments

  I don't know what I am missing here, I also don't know if lsmeans is the best way to do it. Could anyone give any suggestions?

Thank you for your help,
Yuqi


From clelandcm at gmail.com  Thu Nov 30 10:17:29 2017
From: clelandcm at gmail.com (Chuck Cleland)
Date: Thu, 30 Nov 2017 04:17:29 -0500
Subject: [R-sig-ME] post-hoc tests of lmerTest models using lsmeans
In-Reply-To: <db4868f6d7f942669b4f8dfa22b74621@Mercury.psych.udel.edu>
References: <db4868f6d7f942669b4f8dfa22b74621@Mercury.psych.udel.edu>
Message-ID: <CAPHuU1qaBLwFCn6yu+hTXQC2X=9cx29aJuFCYAatmDNmw3JgPA@mail.gmail.com>

Try detaching the lmerTest package before using lsmeans.

This is what worked for me on a similar problem:

detach(package:lmerTest)

my_lsm <- lsmeans(Dp.reduced.fm, ~ Emotion|Go_NoGo)

pairs(my_lsm)

That gives pairwise comparisons of emotions at each level of Go_NoGo, with
the Tukey p value adjustment.

Hope this helps.

Regards,

Chuck


On Wed, Nov 29, 2017 at 4:32 PM, Yuqi Liu <yliu at psych.udel.edu> wrote:

> Dear R experts,
>
>   I have a question on testing simple effects after finding out
> significant interaction using lmerTest. My data has two within-subjects
> fixed factors: Movement (synchronous or asynchronous), and Finger (one
> finger, or four fingers). The two levels of Movement factor were
> dummy-coded as 0.5 and -0.5, so were the two levels of Finger factor. The
> DV is called Shift. My model looks like this:
>
>   Shift.lm <- lmer(Shift~Movement*Finger+(1|subject), data=data)
>
>   There was a significant interaction of Movement and Finger, so I wanted
> to test simple effects by comparing synchronous and asynchronous movements
> at each level of Finger. I was planning to use lsmeans to do this, but I
> got two questions. First, when I just typed > lsmeans(Shift.lm) to look at
> descriptive info in each condition, R output nothing other than the headers:
>
>   > lsmeans(Shift.lm)
> Least Squares Means table:
>      Estimate Standard Error DF t-value Lower CI Upper CI p-value
>
>   In addition, I typed the command below to test simple effects, but
> getting this error message:
>
> > lsmeans(Shift.lm, pairwise~Finger * Movement ,adjust="tukey")
> Error in match(x, table, nomatch = 0L) :
>   'match' requires vector arguments
>
>   I don't know what I am missing here, I also don't know if lsmeans is the
> best way to do it. Could anyone give any suggestions?
>
> Thank you for your help,
> Yuqi
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Chuck Cleland, Ph.D.
Senior Research Scientist
NYU Rory Meyers College of Nursing
433 First Avenue, 7th floor
New York, NY 10010
tel: (212) 992-9417 (Tu, W, Th)
tel: (732) 512-0171 (M, F)

	[[alternative HTML version deleted]]


From silvia.matesanzgarcia at gmail.com  Thu Nov 30 20:07:55 2017
From: silvia.matesanzgarcia at gmail.com (silvia.matesanzgarcia at gmail.com)
Date: Thu, 30 Nov 2017 20:07:55 +0100
Subject: [R-sig-ME] model specification in lmer
Message-ID: <129601d36a0e$87ec8ef0$97c5acd0$@gmail.com>

Hello all

I am attempting to fit a mixed model in lmer. I have an experimental design
with families nested within populations in two different treatments, and I
want to test the effects of Pop, Trt, and Pop:Trt as fixed factors, and
Family and Family*Trt as random factors.

 

My full model would be:

model1=lmer(Trait~Pop*Trt + (Trt|Family)

I can then use:

model2=lmer(Trait~Pop*Trt + (1|Family)

and

anova(model1, model2) would provide signification for the interaction term.

 

I would need a third model with only the interaction term, so that I can
compare it to the full model and obtain significance for the family term.
But I can't figure out how to do this last part.

 

Can I just compare model2 to a model with no random part?

 

Thank you so much for your help in advance.

 


	[[alternative HTML version deleted]]


From silvia.matesanzgarcia at gmail.com  Thu Nov 30 19:55:53 2017
From: silvia.matesanzgarcia at gmail.com (silvia.matesanzgarcia at gmail.com)
Date: Thu, 30 Nov 2017 19:55:53 +0100
Subject: [R-sig-ME] model specification in lmer
Message-ID: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>

Hello all

I am attempting to fit a mixed model in lmer. I have an experimental design
with families nested within populations in two different treatments, and I
want to test the effects of Pop, Trt, and Pop:Trt as fixed factors, and
Family and Family*Trt as random factors. 

 

My full model would be: 

model1=lmer(Trait~Pop*Trt + (Trt|Family)

I can then use: 

model2=lmer(Trait~Pop*Trt + (1|Family)

and

anova(model1, model2) would provide signification for the interaction term.

 

I would need a third model with only the interaction term, so that I can
compare it to the full model and obtain significance for the family term.
But I can't figure out how to do this last part. 

 

Can I just compare model2 to a model with no random part? 

 

Thank you so much for your help in advance.

 


	[[alternative HTML version deleted]]


From c.c.voeten at hum.leidenuniv.nl  Thu Nov 30 21:26:59 2017
From: c.c.voeten at hum.leidenuniv.nl (Voeten, C.C.)
Date: Thu, 30 Nov 2017 20:26:59 +0000
Subject: [R-sig-ME] model specification in lmer
In-Reply-To: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>
References: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F7D04F0@SPMXM08.VUW.leidenuniv.nl>

There are various ways to do this. The most important thing to make sure of is that the models you're comparing are both fitted either with or without REML; you can't mix ML and REML fits (that will heavily bias your LRT in favor of the ML model). You can fit the no-random-intercept model using lm(), and use anova() to compare it with a random-intercept lmer model fitted with REML=F. A (perhaps slightly better) alternative is to use gls() from nlme to fit the no-random-intercept model using REML. You can then manually calculate chi-square values like so:

> library(nlme)
> library(lme4)
Loading required package: Matrix

Attaching package: ?lme4?

The following object is masked from ?package:nlme?:

    lmList

> model1 <- gls(Reaction~Days,sleepstudy)
> model2 <- lmer(Reaction~Days + (1|Subject),sleepstudy)
> ( neg2ll1 <- -2*logLik(model1) )
'log Lik.' 1893.664 (df=3)
> ( neg2ll2 <- -2*logLik(model2) )
'log Lik.' 1786.465 (df=4)
> ( difference <- as.numeric(neg2ll2-neg2ll1) )
[1] -107.1986
> pchisq(difference,1)
[1] 0

Good luck!
________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens silvia.matesanzgarcia at gmail.com [silvia.matesanzgarcia at gmail.com]
Verzonden: donderdag 30 november 2017 19:55
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] model specification in lmer

Hello all

I am attempting to fit a mixed model in lmer. I have an experimental design
with families nested within populations in two different treatments, and I
want to test the effects of Pop, Trt, and Pop:Trt as fixed factors, and
Family and Family*Trt as random factors.



My full model would be:

model1=lmer(Trait~Pop*Trt + (Trt|Family)

I can then use:

model2=lmer(Trait~Pop*Trt + (1|Family)

and

anova(model1, model2) would provide signification for the interaction term.



I would need a third model with only the interaction term, so that I can
compare it to the full model and obtain significance for the family term.
But I can't figure out how to do this last part.



Can I just compare model2 to a model with no random part?



Thank you so much for your help in advance.




        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From silvia.matesanzgarcia at gmail.com  Thu Nov 30 21:57:22 2017
From: silvia.matesanzgarcia at gmail.com (silvia.matesanzgarcia at gmail.com)
Date: Thu, 30 Nov 2017 21:57:22 +0100
Subject: [R-sig-ME] model specification in lmer
In-Reply-To: <D14049CE02C4F54D95360EEC06CE45C50F7D04F0@SPMXM08.VUW.leidenuniv.nl>
References: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50F7D04F0@SPMXM08.VUW.leidenuniv.nl>
Message-ID: <d31901d36a1d$d21406c0$763c1440$@gmail.com>

Thank you so much for your answer.

So, just to make sure I get this right, I could follow the next approach: 

model1=lmer(Trait~Pop*Trt + (Trt|Family), data=data)
model2=lmer(Trait~Pop*Trt + (1|Family), data=data)
model3=lme(Trait~Pop*Trt , data=data)

anova(model1,model2) would provide significance for the interaction between
Family and Treatment.
anova(model2, model3) would provide significance for the Family term.

Is this correct?


Thank you so much again!!





-----Mensaje original-----
De: Voeten, C.C. [mailto:c.c.voeten at hum.leidenuniv.nl] 
Enviado el: jueves, 30 de noviembre de 2017 21:27
Para: silvia.matesanzgarcia at gmail.com; r-sig-mixed-models at r-project.org
Asunto: RE: [R-sig-ME] model specification in lmer

There are various ways to do this. The most important thing to make sure of
is that the models you're comparing are both fitted either with or without
REML; you can't mix ML and REML fits (that will heavily bias your LRT in
favor of the ML model). You can fit the no-random-intercept model using
lm(), and use anova() to compare it with a random-intercept lmer model
fitted with REML=F. A (perhaps slightly better) alternative is to use gls()
from nlme to fit the no-random-intercept model using REML. You can then
manually calculate chi-square values like so:

> library(nlme)
> library(lme4)
Loading required package: Matrix

Attaching package: 'lme4'

The following object is masked from 'package:nlme':

    lmList

> model1 <- gls(Reaction~Days,sleepstudy)
> model2 <- lmer(Reaction~Days + (1|Subject),sleepstudy) ( neg2ll1 <- 
> -2*logLik(model1) )
'log Lik.' 1893.664 (df=3)
> ( neg2ll2 <- -2*logLik(model2) )
'log Lik.' 1786.465 (df=4)
> ( difference <- as.numeric(neg2ll2-neg2ll1) )
[1] -107.1986
> pchisq(difference,1)
[1] 0

Good luck!
________________________________________
Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens
silvia.matesanzgarcia at gmail.com [silvia.matesanzgarcia at gmail.com]
Verzonden: donderdag 30 november 2017 19:55
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] model specification in lmer

Hello all

I am attempting to fit a mixed model in lmer. I have an experimental design
with families nested within populations in two different treatments, and I
want to test the effects of Pop, Trt, and Pop:Trt as fixed factors, and
Family and Family*Trt as random factors.



My full model would be:

model1=lmer(Trait~Pop*Trt + (Trt|Family)

I can then use:

model2=lmer(Trait~Pop*Trt + (1|Family)

and

anova(model1, model2) would provide signification for the interaction term.



I would need a third model with only the interaction term, so that I can
compare it to the full model and obtain significance for the family term.
But I can't figure out how to do this last part.



Can I just compare model2 to a model with no random part?



Thank you so much for your help in advance.




        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.johnson at glasgow.ac.uk  Fri Dec  1 02:58:23 2017
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Fri, 1 Dec 2017 01:58:23 +0000
Subject: [R-sig-ME] model specification in lmer
In-Reply-To: <d31901d36a1d$d21406c0$763c1440$@gmail.com>
References: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50F7D04F0@SPMXM08.VUW.leidenuniv.nl>
 <d31901d36a1d$d21406c0$763c1440$@gmail.com>
Message-ID: <4C12812E-AA48-4E6E-A3D3-35821CCB6EB1@glasgow.ac.uk>

Hi Silvia & CC,

> model3=lme(Trait~Pop*Trt , data=data)

should be 

> model3=lm(Trait~Pop*Trt , data=data)

I didn?t know you could test a random effect with anova(lmer(?, REML = FALSE), lm(?)). Is that valid when fitted with ML? 

I recommend reading http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html :

"With recent versions of lme4, goodness-of-fit (deviance) can be compared between (g)lmer and (g)lm models, although anova() must be called with the mixed ((g)lmer) model listed first. Keep in mind that LRT-based null hypothesis tests are conservative when the null value (such as ?2=0) is on the boundary of the feasible space; in the simplest case (single random effect variance), the p-value is approximately twice as large as it should be (Pinheiro and Bates 2000).
	? Consider not testing the significance of random effects. If the random effect is part of the experimental design, this procedure may be considered ?sacrificial pseudoreplication? (Hurlbert 1984). Using stepwise approaches to eliminate non-significant terms in order to squeeze more significance out of the remaining terms is dangerous in any case.
	? consider using the RLRsim package, which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests. (However, it only applies to lmer models, and is a bit tricky to use for more complex models.)"

> model1=lmer(Trait~Pop*Trt + (Trt|Family), data=data)
> model2=lmer(Trait~Pop*Trt + (1|Family), data=data)
> model3=lme(Trait~Pop*Trt , data=data)
> 
> anova(model1,model2) would provide significance for the interaction between
> Family and Treatment.

To avoid confusion between random and fixed effects, it?s better not to call ?(Trt|Family)" an interaction (even though it has a lot in common with an interaction). Pop:Trt is an interaction. The difference between (1|Family) and (Trt|Family) is that in the former only the intercept varies randomly between families, while in the latter the main effect of Trt also varies randomly between families. The null hypothesis being tested is that both the variance of the Trt effect and its covariance with the random intercept are zero.

Another simple way to test for a random effect in a lmer fit (if you still want to despite the advice quoted above) would be to use confint(fit) and see if the 95% CI for the family variance includes zero. I did a very quick-and-dirty permutation-based simulation to compare confint(?, method = "profile") with the anova(lmer, lm) test:

library(lme4)
library(nlme)
sim.res <- 
  replicate(1000, {
    Orthodont$Subject <- sample(Orthodont$Subject)
    fm1 <- lmer(distance ~ age + (1 | Subject), data = Orthodont, REML = FALSE)
    fm1.lm <- lm(distance ~ age, data = Orthodont)
    c(LRT = anova(fm1, fm1.lm)[2, "Pr(>Chisq)"] < 0.05, 
      CI = confint(fm1, 1)[1] > 0)
  })
table(sim.res["LRT", ], sim.res["CI", ])

The results were conservative (false positive rate of ~2%), which I expected for the LRT, but not for the CI, and completely concordant, presumably because both use the likelihood:
       
        FALSE TRUE
  FALSE   982    0
  TRUE      0   18

I ran it a few more times and it was very consistent, ~2% false positives and 100% concordance.

Best wishes,
Paul



> anova(model2, model3) would provide significance for the Family term.
> 
> Is this correct?
> 
> 
> Thank you so much again!!
> 
> 
> 
> 
> 
> -----Mensaje original-----
> De: Voeten, C.C. [mailto:c.c.voeten at hum.leidenuniv.nl] 
> Enviado el: jueves, 30 de noviembre de 2017 21:27
> Para: silvia.matesanzgarcia at gmail.com; r-sig-mixed-models at r-project.org
> Asunto: RE: [R-sig-ME] model specification in lmer
> 
> There are various ways to do this. The most important thing to make sure of
> is that the models you're comparing are both fitted either with or without
> REML; you can't mix ML and REML fits (that will heavily bias your LRT in
> favor of the ML model). You can fit the no-random-intercept model using
> lm(), and use anova() to compare it with a random-intercept lmer model
> fitted with REML=F. A (perhaps slightly better) alternative is to use gls()
> from nlme to fit the no-random-intercept model using REML. You can then
> manually calculate chi-square values like so:
> 
>> library(nlme)
>> library(lme4)
> Loading required package: Matrix
> 
> Attaching package: 'lme4'
> 
> The following object is masked from 'package:nlme':
> 
>    lmList
> 
>> model1 <- gls(Reaction~Days,sleepstudy)
>> model2 <- lmer(Reaction~Days + (1|Subject),sleepstudy) ( neg2ll1 <- 
>> -2*logLik(model1) )
> 'log Lik.' 1893.664 (df=3)
>> ( neg2ll2 <- -2*logLik(model2) )
> 'log Lik.' 1786.465 (df=4)
>> ( difference <- as.numeric(neg2ll2-neg2ll1) )
> [1] -107.1986
>> pchisq(difference,1)
> [1] 0
> 
> Good luck!
> ________________________________________
> Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens
> silvia.matesanzgarcia at gmail.com [silvia.matesanzgarcia at gmail.com]
> Verzonden: donderdag 30 november 2017 19:55
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] model specification in lmer
> 
> Hello all
> 
> I am attempting to fit a mixed model in lmer. I have an experimental design
> with families nested within populations in two different treatments, and I
> want to test the effects of Pop, Trt, and Pop:Trt as fixed factors, and
> Family and Family*Trt as random factors.
> 
> 
> 
> My full model would be:
> 
> model1=lmer(Trait~Pop*Trt + (Trt|Family)
> 
> I can then use:
> 
> model2=lmer(Trait~Pop*Trt + (1|Family)
> 
> and
> 
> anova(model1, model2) would provide signification for the interaction term.
> 
> 
> 
> I would need a third model with only the interaction term, so that I can
> compare it to the full model and obtain significance for the family term.
> But I can't figure out how to do this last part.
> 
> 
> 
> Can I just compare model2 to a model with no random part?
> 
> 
> 
> Thank you so much for your help in advance.
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.johnson at glasgow.ac.uk  Fri Dec  1 12:01:47 2017
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Fri, 1 Dec 2017 11:01:47 +0000
Subject: [R-sig-ME] model specification in lmer
In-Reply-To: <4C12812E-AA48-4E6E-A3D3-35821CCB6EB1@glasgow.ac.uk>
References: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50F7D04F0@SPMXM08.VUW.leidenuniv.nl>
 <d31901d36a1d$d21406c0$763c1440$@gmail.com>
 <4C12812E-AA48-4E6E-A3D3-35821CCB6EB1@glasgow.ac.uk>
Message-ID: <0C0C6856-D4B7-45C9-9D3E-37C572950F27@glasgow.ac.uk>

> The results were conservative (false positive rate of ~2%), which I expected for the LRT, but not for the CI, and completely concordant, presumably because both use the likelihood:

On second thoughts, it does makes sense that the CI method is also conservative, because the null value is on the boundary so the 95% CI can only miss on one side. For a more formal explanation of this see Box 3 of Bolker et al. 2009 http://www.ncbi.nlm.nih.gov/pubmed/19185386 .



> On 1 Dec 2017, at 01:58, Paul Johnson <paul.johnson at glasgow.ac.uk> wrote:
> 
> Hi Silvia & CC,
> 
>> model3=lme(Trait~Pop*Trt , data=data)
> 
> should be 
> 
>> model3=lm(Trait~Pop*Trt , data=data)
> 
> I didn?t know you could test a random effect with anova(lmer(?, REML = FALSE), lm(?)). Is that valid when fitted with ML? 
> 
> I recommend reading http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html :
> 
> "With recent versions of lme4, goodness-of-fit (deviance) can be compared between (g)lmer and (g)lm models, although anova() must be called with the mixed ((g)lmer) model listed first. Keep in mind that LRT-based null hypothesis tests are conservative when the null value (such as ?2=0) is on the boundary of the feasible space; in the simplest case (single random effect variance), the p-value is approximately twice as large as it should be (Pinheiro and Bates 2000).
> 	? Consider not testing the significance of random effects. If the random effect is part of the experimental design, this procedure may be considered ?sacrificial pseudoreplication? (Hurlbert 1984). Using stepwise approaches to eliminate non-significant terms in order to squeeze more significance out of the remaining terms is dangerous in any case.
> 	? consider using the RLRsim package, which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests. (However, it only applies to lmer models, and is a bit tricky to use for more complex models.)"
> 
>> model1=lmer(Trait~Pop*Trt + (Trt|Family), data=data)
>> model2=lmer(Trait~Pop*Trt + (1|Family), data=data)
>> model3=lme(Trait~Pop*Trt , data=data)
>> 
>> anova(model1,model2) would provide significance for the interaction between
>> Family and Treatment.
> 
> To avoid confusion between random and fixed effects, it?s better not to call ?(Trt|Family)" an interaction (even though it has a lot in common with an interaction). Pop:Trt is an interaction. The difference between (1|Family) and (Trt|Family) is that in the former only the intercept varies randomly between families, while in the latter the main effect of Trt also varies randomly between families. The null hypothesis being tested is that both the variance of the Trt effect and its covariance with the random intercept are zero.
> 
> Another simple way to test for a random effect in a lmer fit (if you still want to despite the advice quoted above) would be to use confint(fit) and see if the 95% CI for the family variance includes zero. I did a very quick-and-dirty permutation-based simulation to compare confint(?, method = "profile") with the anova(lmer, lm) test:
> 
> library(lme4)
> library(nlme)
> sim.res <- 
>  replicate(1000, {
>    Orthodont$Subject <- sample(Orthodont$Subject)
>    fm1 <- lmer(distance ~ age + (1 | Subject), data = Orthodont, REML = FALSE)
>    fm1.lm <- lm(distance ~ age, data = Orthodont)
>    c(LRT = anova(fm1, fm1.lm)[2, "Pr(>Chisq)"] < 0.05, 
>      CI = confint(fm1, 1)[1] > 0)
>  })
> table(sim.res["LRT", ], sim.res["CI", ])
> 
> The results were conservative (false positive rate of ~2%), which I expected for the LRT, but not for the CI, and completely concordant, presumably because both use the likelihood:
> 
>        FALSE TRUE
>  FALSE   982    0
>  TRUE      0   18
> 
> I ran it a few more times and it was very consistent, ~2% false positives and 100% concordance.
> 
> Best wishes,
> Paul
> 
> 
> 
>> anova(model2, model3) would provide significance for the Family term.
>> 
>> Is this correct?
>> 
>> 
>> Thank you so much again!!
>> 
>> 
>> 
>> 
>> 
>> -----Mensaje original-----
>> De: Voeten, C.C. [mailto:c.c.voeten at hum.leidenuniv.nl] 
>> Enviado el: jueves, 30 de noviembre de 2017 21:27
>> Para: silvia.matesanzgarcia at gmail.com; r-sig-mixed-models at r-project.org
>> Asunto: RE: [R-sig-ME] model specification in lmer
>> 
>> There are various ways to do this. The most important thing to make sure of
>> is that the models you're comparing are both fitted either with or without
>> REML; you can't mix ML and REML fits (that will heavily bias your LRT in
>> favor of the ML model). You can fit the no-random-intercept model using
>> lm(), and use anova() to compare it with a random-intercept lmer model
>> fitted with REML=F. A (perhaps slightly better) alternative is to use gls()
>> from nlme to fit the no-random-intercept model using REML. You can then
>> manually calculate chi-square values like so:
>> 
>>> library(nlme)
>>> library(lme4)
>> Loading required package: Matrix
>> 
>> Attaching package: 'lme4'
>> 
>> The following object is masked from 'package:nlme':
>> 
>>   lmList
>> 
>>> model1 <- gls(Reaction~Days,sleepstudy)
>>> model2 <- lmer(Reaction~Days + (1|Subject),sleepstudy) ( neg2ll1 <- 
>>> -2*logLik(model1) )
>> 'log Lik.' 1893.664 (df=3)
>>> ( neg2ll2 <- -2*logLik(model2) )
>> 'log Lik.' 1786.465 (df=4)
>>> ( difference <- as.numeric(neg2ll2-neg2ll1) )
>> [1] -107.1986
>>> pchisq(difference,1)
>> [1] 0
>> 
>> Good luck!
>> ________________________________________
>> Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] namens
>> silvia.matesanzgarcia at gmail.com [silvia.matesanzgarcia at gmail.com]
>> Verzonden: donderdag 30 november 2017 19:55
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] model specification in lmer
>> 
>> Hello all
>> 
>> I am attempting to fit a mixed model in lmer. I have an experimental design
>> with families nested within populations in two different treatments, and I
>> want to test the effects of Pop, Trt, and Pop:Trt as fixed factors, and
>> Family and Family*Trt as random factors.
>> 
>> 
>> 
>> My full model would be:
>> 
>> model1=lmer(Trait~Pop*Trt + (Trt|Family)
>> 
>> I can then use:
>> 
>> model2=lmer(Trait~Pop*Trt + (1|Family)
>> 
>> and
>> 
>> anova(model1, model2) would provide signification for the interaction term.
>> 
>> 
>> 
>> I would need a third model with only the interaction term, so that I can
>> compare it to the full model and obtain significance for the family term.
>> But I can't figure out how to do this last part.
>> 
>> 
>> 
>> Can I just compare model2 to a model with no random part?
>> 
>> 
>> 
>> Thank you so much for your help in advance.
>> 
>> 
>> 
>> 
>>       [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From silvia.matesanzgarcia at gmail.com  Fri Dec  1 13:09:57 2017
From: silvia.matesanzgarcia at gmail.com (silvia.matesanzgarcia at gmail.com)
Date: Fri, 1 Dec 2017 13:09:57 +0100
Subject: [R-sig-ME] model specification in lmer
In-Reply-To: <4C12812E-AA48-4E6E-A3D3-35821CCB6EB1@glasgow.ac.uk>
References: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50F7D04F0@SPMXM08.VUW.leidenuniv.nl>
 <d31901d36a1d$d21406c0$763c1440$@gmail.com>
 <4C12812E-AA48-4E6E-A3D3-35821CCB6EB1@glasgow.ac.uk>
Message-ID: <607e01d36a9d$4e31e9a0$ea95bce0$@gmail.com>

Thank you so much Paul for your detailed and helpful response.

Yes, sorry, there was a typo in the specification of model3. It should be lm instead of lme. I'm also aware of the conservatism of the LRT when comparing lmer and lm objects. 

Could you please provide clarification for this sentence? "The null hypothesis being tested is that both the variance of the Trt effect and its covariance with the random intercept are zero."

Do you mean the variance of the random slope of treatment? The main effect of Treatment is a fixed factor.


Thank you again.

Silvia 

-----Mensaje original-----
De: Paul Johnson [mailto:paul.johnson at glasgow.ac.uk] 
Enviado el: viernes, 1 de diciembre de 2017 2:58
Para: silvia.matesanzgarcia at gmail.com
CC: Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>; r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] model specification in lmer

Hi Silvia & CC,

> model3=lme(Trait~Pop*Trt , data=data)

should be 

> model3=lm(Trait~Pop*Trt , data=data)

I didn?t know you could test a random effect with anova(lmer(?, REML = FALSE), lm(?)). Is that valid when fitted with ML? 

I recommend reading http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html :

"With recent versions of lme4, goodness-of-fit (deviance) can be compared between (g)lmer and (g)lm models, although anova() must be called with the mixed ((g)lmer) model listed first. Keep in mind that LRT-based null hypothesis tests are conservative when the null value (such as ?2=0) is on the boundary of the feasible space; in the simplest case (single random effect variance), the p-value is approximately twice as large as it should be (Pinheiro and Bates 2000).
	? Consider not testing the significance of random effects. If the random effect is part of the experimental design, this procedure may be considered ?sacrificial pseudoreplication? (Hurlbert 1984). Using stepwise approaches to eliminate non-significant terms in order to squeeze more significance out of the remaining terms is dangerous in any case.
	? consider using the RLRsim package, which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests. (However, it only applies to lmer models, and is a bit tricky to use for more complex models.)"

> model1=lmer(Trait~Pop*Trt + (Trt|Family), data=data) 
> model2=lmer(Trait~Pop*Trt + (1|Family), data=data) 
> model3=lme(Trait~Pop*Trt , data=data)
> 
> anova(model1,model2) would provide significance for the interaction 
> between Family and Treatment.

To avoid confusion between random and fixed effects, it?s better not to call ?(Trt|Family)" an interaction (even though it has a lot in common with an interaction). Pop:Trt is an interaction. The difference between (1|Family) and (Trt|Family) is that in the former only the intercept varies randomly between families, while in the latter the main effect of Trt also varies randomly between families. The null hypothesis being tested is that both the variance of the Trt effect and its covariance with the random intercept are zero.

Another simple way to test for a random effect in a lmer fit (if you still want to despite the advice quoted above) would be to use confint(fit) and see if the 95% CI for the family variance includes zero. I did a very quick-and-dirty permutation-based simulation to compare confint(?, method = "profile") with the anova(lmer, lm) test:

library(lme4)
library(nlme)
sim.res <-
  replicate(1000, {
    Orthodont$Subject <- sample(Orthodont$Subject)
    fm1 <- lmer(distance ~ age + (1 | Subject), data = Orthodont, REML = FALSE)
    fm1.lm <- lm(distance ~ age, data = Orthodont)
    c(LRT = anova(fm1, fm1.lm)[2, "Pr(>Chisq)"] < 0.05, 
      CI = confint(fm1, 1)[1] > 0)
  })
table(sim.res["LRT", ], sim.res["CI", ])

The results were conservative (false positive rate of ~2%), which I expected for the LRT, but not for the CI, and completely concordant, presumably because both use the likelihood:
       
        FALSE TRUE
  FALSE   982    0
  TRUE      0   18

I ran it a few more times and it was very consistent, ~2% false positives and 100% concordance.

Best wishes,
Paul



> anova(model2, model3) would provide significance for the Family term.
> 
> Is this correct?
> 
> 
> Thank you so much again!!
> 
> 
> 
> 
> 
> -----Mensaje original-----
> De: Voeten, C.C. [mailto:c.c.voeten at hum.leidenuniv.nl]
> Enviado el: jueves, 30 de noviembre de 2017 21:27
> Para: silvia.matesanzgarcia at gmail.com; 
> r-sig-mixed-models at r-project.org
> Asunto: RE: [R-sig-ME] model specification in lmer
> 
> There are various ways to do this. The most important thing to make 
> sure of is that the models you're comparing are both fitted either 
> with or without REML; you can't mix ML and REML fits (that will 
> heavily bias your LRT in favor of the ML model). You can fit the 
> no-random-intercept model using lm(), and use anova() to compare it 
> with a random-intercept lmer model fitted with REML=F. A (perhaps 
> slightly better) alternative is to use gls() from nlme to fit the 
> no-random-intercept model using REML. You can then manually calculate chi-square values like so:
> 
>> library(nlme)
>> library(lme4)
> Loading required package: Matrix
> 
> Attaching package: 'lme4'
> 
> The following object is masked from 'package:nlme':
> 
>    lmList
> 
>> model1 <- gls(Reaction~Days,sleepstudy)
>> model2 <- lmer(Reaction~Days + (1|Subject),sleepstudy) ( neg2ll1 <-
>> -2*logLik(model1) )
> 'log Lik.' 1893.664 (df=3)
>> ( neg2ll2 <- -2*logLik(model2) )
> 'log Lik.' 1786.465 (df=4)
>> ( difference <- as.numeric(neg2ll2-neg2ll1) )
> [1] -107.1986
>> pchisq(difference,1)
> [1] 0
> 
> Good luck!
> ________________________________________
> Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] 
> namens silvia.matesanzgarcia at gmail.com 
> [silvia.matesanzgarcia at gmail.com]
> Verzonden: donderdag 30 november 2017 19:55
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] model specification in lmer
> 
> Hello all
> 
> I am attempting to fit a mixed model in lmer. I have an experimental 
> design with families nested within populations in two different 
> treatments, and I want to test the effects of Pop, Trt, and Pop:Trt as 
> fixed factors, and Family and Family*Trt as random factors.
> 
> 
> 
> My full model would be:
> 
> model1=lmer(Trait~Pop*Trt + (Trt|Family)
> 
> I can then use:
> 
> model2=lmer(Trait~Pop*Trt + (1|Family)
> 
> and
> 
> anova(model1, model2) would provide signification for the interaction term.
> 
> 
> 
> I would need a third model with only the interaction term, so that I 
> can compare it to the full model and obtain significance for the family term.
> But I can't figure out how to do this last part.
> 
> 
> 
> Can I just compare model2 to a model with no random part?
> 
> 
> 
> Thank you so much for your help in advance.
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.johnson at glasgow.ac.uk  Fri Dec  1 14:34:41 2017
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Fri, 1 Dec 2017 13:34:41 +0000
Subject: [R-sig-ME] model specification in lmer
In-Reply-To: <607e01d36a9d$4e31e9a0$ea95bce0$@gmail.com>
References: <243401d36a0c$d9703e40$8c50bac0$@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50F7D04F0@SPMXM08.VUW.leidenuniv.nl>
 <d31901d36a1d$d21406c0$763c1440$@gmail.com>
 <4C12812E-AA48-4E6E-A3D3-35821CCB6EB1@glasgow.ac.uk>
 <607e01d36a9d$4e31e9a0$ea95bce0$@gmail.com>
Message-ID: <714944A2-BDB9-4433-BD43-75245BF4F70E@glasgow.ac.uk>

Hi Silvia,

> Could you please provide clarification for this sentence? "The null hypothesis being tested is that both the variance of the Trt effect and its covariance with the random intercept are zero."
> 
> Do you mean the variance of the random slope of treatment? The main effect of Treatment is a fixed factor.


Yes, I meant the variance of the random slope. In the random slopes model, each family has its own treatment effect (slope), which is the sum of main effect of treatment (the mean Treatment slope across all families) and the family-specific random deviation from that mean slope. These deviations are drawn from a normal distribution with mean zero and a free variance parameter, which in the null random-intercept-only model is assumed to be zero. In the random slopes model, there is also a covariance between the random slope deviations and the random intercept deviations, which is zero in the null model.

Best wishes,
Paul



> On 1 Dec 2017, at 12:09, silvia.matesanzgarcia at gmail.com wrote:
> 
> Thank you so much Paul for your detailed and helpful response.
> 
> Yes, sorry, there was a typo in the specification of model3. It should be lm instead of lme. I'm also aware of the conservatism of the LRT when comparing lmer and lm objects. 
> 
> Could you please provide clarification for this sentence? "The null hypothesis being tested is that both the variance of the Trt effect and its covariance with the random intercept are zero."
> 
> Do you mean the variance of the random slope of treatment? The main effect of Treatment is a fixed factor.
> 
> 
> Thank you again.
> 
> Silvia 
> 
> -----Mensaje original-----
> De: Paul Johnson [mailto:paul.johnson at glasgow.ac.uk] 
> Enviado el: viernes, 1 de diciembre de 2017 2:58
> Para: silvia.matesanzgarcia at gmail.com
> CC: Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>; r-sig-mixed-models at r-project.org
> Asunto: Re: [R-sig-ME] model specification in lmer
> 
> Hi Silvia & CC,
> 
>> model3=lme(Trait~Pop*Trt , data=data)
> 
> should be 
> 
>> model3=lm(Trait~Pop*Trt , data=data)
> 
> I didn?t know you could test a random effect with anova(lmer(?, REML = FALSE), lm(?)). Is that valid when fitted with ML? 
> 
> I recommend reading http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html :
> 
> "With recent versions of lme4, goodness-of-fit (deviance) can be compared between (g)lmer and (g)lm models, although anova() must be called with the mixed ((g)lmer) model listed first. Keep in mind that LRT-based null hypothesis tests are conservative when the null value (such as ?2=0) is on the boundary of the feasible space; in the simplest case (single random effect variance), the p-value is approximately twice as large as it should be (Pinheiro and Bates 2000).
> 	? Consider not testing the significance of random effects. If the random effect is part of the experimental design, this procedure may be considered ?sacrificial pseudoreplication? (Hurlbert 1984). Using stepwise approaches to eliminate non-significant terms in order to squeeze more significance out of the remaining terms is dangerous in any case.
> 	? consider using the RLRsim package, which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests. (However, it only applies to lmer models, and is a bit tricky to use for more complex models.)"
> 
>> model1=lmer(Trait~Pop*Trt + (Trt|Family), data=data) 
>> model2=lmer(Trait~Pop*Trt + (1|Family), data=data) 
>> model3=lme(Trait~Pop*Trt , data=data)
>> 
>> anova(model1,model2) would provide significance for the interaction 
>> between Family and Treatment.
> 
> To avoid confusion between random and fixed effects, it?s better not to call ?(Trt|Family)" an interaction (even though it has a lot in common with an interaction). Pop:Trt is an interaction. The difference between (1|Family) and (Trt|Family) is that in the former only the intercept varies randomly between families, while in the latter the main effect of Trt also varies randomly between families. The null hypothesis being tested is that both the variance of the Trt effect and its covariance with the random intercept are zero.
> 
> Another simple way to test for a random effect in a lmer fit (if you still want to despite the advice quoted above) would be to use confint(fit) and see if the 95% CI for the family variance includes zero. I did a very quick-and-dirty permutation-based simulation to compare confint(?, method = "profile") with the anova(lmer, lm) test:
> 
> library(lme4)
> library(nlme)
> sim.res <-
>  replicate(1000, {
>    Orthodont$Subject <- sample(Orthodont$Subject)
>    fm1 <- lmer(distance ~ age + (1 | Subject), data = Orthodont, REML = FALSE)
>    fm1.lm <- lm(distance ~ age, data = Orthodont)
>    c(LRT = anova(fm1, fm1.lm)[2, "Pr(>Chisq)"] < 0.05, 
>      CI = confint(fm1, 1)[1] > 0)
>  })
> table(sim.res["LRT", ], sim.res["CI", ])
> 
> The results were conservative (false positive rate of ~2%), which I expected for the LRT, but not for the CI, and completely concordant, presumably because both use the likelihood:
> 
>        FALSE TRUE
>  FALSE   982    0
>  TRUE      0   18
> 
> I ran it a few more times and it was very consistent, ~2% false positives and 100% concordance.
> 
> Best wishes,
> Paul
> 
> 
> 
>> anova(model2, model3) would provide significance for the Family term.
>> 
>> Is this correct?
>> 
>> 
>> Thank you so much again!!
>> 
>> 
>> 
>> 
>> 
>> -----Mensaje original-----
>> De: Voeten, C.C. [mailto:c.c.voeten at hum.leidenuniv.nl]
>> Enviado el: jueves, 30 de noviembre de 2017 21:27
>> Para: silvia.matesanzgarcia at gmail.com; 
>> r-sig-mixed-models at r-project.org
>> Asunto: RE: [R-sig-ME] model specification in lmer
>> 
>> There are various ways to do this. The most important thing to make 
>> sure of is that the models you're comparing are both fitted either 
>> with or without REML; you can't mix ML and REML fits (that will 
>> heavily bias your LRT in favor of the ML model). You can fit the 
>> no-random-intercept model using lm(), and use anova() to compare it 
>> with a random-intercept lmer model fitted with REML=F. A (perhaps 
>> slightly better) alternative is to use gls() from nlme to fit the 
>> no-random-intercept model using REML. You can then manually calculate chi-square values like so:
>> 
>>> library(nlme)
>>> library(lme4)
>> Loading required package: Matrix
>> 
>> Attaching package: 'lme4'
>> 
>> The following object is masked from 'package:nlme':
>> 
>>   lmList
>> 
>>> model1 <- gls(Reaction~Days,sleepstudy)
>>> model2 <- lmer(Reaction~Days + (1|Subject),sleepstudy) ( neg2ll1 <-
>>> -2*logLik(model1) )
>> 'log Lik.' 1893.664 (df=3)
>>> ( neg2ll2 <- -2*logLik(model2) )
>> 'log Lik.' 1786.465 (df=4)
>>> ( difference <- as.numeric(neg2ll2-neg2ll1) )
>> [1] -107.1986
>>> pchisq(difference,1)
>> [1] 0
>> 
>> Good luck!
>> ________________________________________
>> Van: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] 
>> namens silvia.matesanzgarcia at gmail.com 
>> [silvia.matesanzgarcia at gmail.com]
>> Verzonden: donderdag 30 november 2017 19:55
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] model specification in lmer
>> 
>> Hello all
>> 
>> I am attempting to fit a mixed model in lmer. I have an experimental 
>> design with families nested within populations in two different 
>> treatments, and I want to test the effects of Pop, Trt, and Pop:Trt as 
>> fixed factors, and Family and Family*Trt as random factors.
>> 
>> 
>> 
>> My full model would be:
>> 
>> model1=lmer(Trait~Pop*Trt + (Trt|Family)
>> 
>> I can then use:
>> 
>> model2=lmer(Trait~Pop*Trt + (1|Family)
>> 
>> and
>> 
>> anova(model1, model2) would provide signification for the interaction term.
>> 
>> 
>> 
>> I would need a third model with only the interaction term, so that I 
>> can compare it to the full model and obtain significance for the family term.
>> But I can't figure out how to do this last part.
>> 
>> 
>> 
>> Can I just compare model2 to a model with no random part?
>> 
>> 
>> 
>> Thank you so much for your help in advance.
>> 
>> 
>> 
>> 
>>       [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


From dorothyborowy at me.com  Sat Dec  2 03:28:02 2017
From: dorothyborowy at me.com (dorothy borowy)
Date: Fri, 01 Dec 2017 21:28:02 -0500
Subject: [R-sig-ME] GLM question
Message-ID: <13D122FD-377D-4BFA-9109-3158DC251951@me.com>

Hello,

I have a question about GLMMs and it was recommended to me that I send my question to this group.  My question is below.  I appreciate your input. 

> I designed an experimental greenhouse study whereby I grew 67 plant
> species from seeds collected from urban vacant land habitats in 2 soil
> types (urban vacant lot and topsoil).  Each species was replicated 10
> times (10 pots each w/ an individual plant) in each soil type. I
> measured a suite of continuous traits (i.e. height at maturity,
> % germination success, aboveground biomass, belowground biomass and
> specific leaf area) on each individual for each species over the duration
> of the study.  /
> /
> /
> /My study question is based on understanding functional trait responses
> of a pool of urban plant species to different soil environments. Because
> trait responses can include both differences in mean values and/or
> differences in the variances, and because these represent different
> potential strategies for surviving in urban habitats, I would like to
> test two types of models: the first is a model that tests the mean
> differences between soil groups for each species (species is the unit of
> replication) and the other testing differences in variance as response
> variables.  I am unsure, however, how to structure the model and I
> cannot find any studies that have done anything comparable--not to say
> they do not exist. /
> /
> /
> /I am considering designing 2 generalized linear models that have soil
> and functional group (a separate factor that I have not described in
> this email) as explanatory variables and mean difference and difference
> in variance/SD for each species as the response variables.  My question is
> as follows: /
> /
> /
> /1) Is this possible and how would I structure each model? Specifically,
> how do I represent mean differences and differences in variance,
> separately?  As I mentioned, I am interested in capturing general trends
> in mean and variance across all species.  Therefore, do I simply calculate and
> compare effect size to capture mean differences (model 1) and F values
> for a Levene?s test (or something comparable) (model 2)?  Or, because sp.
> is the unit of rep., would I have the mean and variance/SD for each sp. as
> the response for each model and include sp. as a nested random effect? 

> For example-
> lmer ( trait_mean ~ functional_group + soil + (1|species))
> lmer ( trait_var ~ ?)

Kind Regards,



Dorothy Borowy 
PhD Candidate
Department of Geography and Environmental Systems
University of Maryland Baltimore County 
http://ges.umbc.edu <http://ges.umbc.edu/>
www.researchgate.net/Dorothy_Borowy <http://www.researchgate.net/profile/Dorothy_Borowy>






	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Tue Dec  5 16:58:00 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Tue, 5 Dec 2017 12:58:00 -0300
Subject: [R-sig-ME] glm model with all zeros for one of the factor level
Message-ID: <CAF5W3aT5fLfG4A6psA+y5RLsaucFaTDtyO3XNoBB_-pGpfkq7Q@mail.gmail.com>

Dear List members:

I performed two independent experiments (CRD) to test if a whitefly
has preference to infect with a virus: potatos, tomatos or peppers
(target hosts, TH), wether if the virus was obtained from potato or
tomato (source hosts, SH). So I released 100 white flyes (previously
infected with the virus from one or other SH) inside cages containing
10 plants of each TH (30 total). This is how the data looks like:

exp  SH    TH    cage    tot  posit

1     tom    tom     1       10     4
1     tom    bat      1       10     3
1     tom    pep     1       10     0
1     bat    tom      2       10     1
1     bat    bat       2       10     2
1     bat    pep      2       10     0

2     tom    tom     3       10     6
2     tom    bat      3       10     4
2     tom    pep     3       10     0
2     bat    tom      4       10     4
2     bat    bat       4       10     0
2     bat    pep      4       10     0

The issue I found here  is that pepper was not infected at all,
however it was infected in another experiment without chance of TH
choice: i.e. I released infectious whiteflies inside cages containing
the same pepper genotyope and they present the typical virus disease
symptoms.

So, how should I consider modeling this data?
Zero-inflated negative binomial using the total plants as offset? Hurdle-model?
Should I remove the pepper level for the model?

Any help would be really helpful.

Juan Edwards


From carbrae at gmail.com  Tue Dec  5 17:50:01 2017
From: carbrae at gmail.com (Bradley Carlson)
Date: Tue, 5 Dec 2017 11:50:01 -0500
Subject: [R-sig-ME] Choosing best approach for a crossover experiment
Message-ID: <CAF37_Nft=r0f7yjW2kGrdW-iemrGKeSY-n5GKME7jknpaYxObw@mail.gmail.com>

Hello all,


I have data from a repeated measures, crossover experiment that goes a bit
beyond my experience. I wanted to be sure I was approaching the data in the
right way. The sample size is small as this is an independent study project
with an undergraduate student, but we see some interesting patterns and I
hope it holds up to a proper analysis. Pardon the length of the
explanation: I want to be clear about what the problems are.


I'm trying to test whether snakes respond differently to certain odor cues.
We have 5 individual snakes. The first week, each snake was tested in 3
sets of tests, with each set of tests on a different day. In each set, they
were exposed to all 4 cues in a randomized order (C B A D on day 1, then A
B D C on day 2, etc.) Don't worry about order effects - that's not where
I'm going with this. I expect the same snakes' behavior to be correlated
both across days (some snakes exhibit stronger responses reliably), and I
expect their behavior in response to the 4 different cues to be correlated
within days (e.g., if they happen to be warmer on Monday, they might have a
stronger response to all 4 cues). I don't necessarily expect this
day-to-day variation to be correlated among individuals (I doubt Monday
would be a high response day for all snakes). What I care about are the
within-subjects, within-date differences between the cues (do they reliably
respond more strongly to cue A than the other cues tested on the same day?)


***My first question is what would be the proper formatting for a repeated
measures analysis of this in lmer**.* I was torn between a few different
options:


Behavior ~ Cue + (1|Subject) + (1|Date)   <--- Seems to assume that date
effects are similar for all individuals

Behavior ~ Cue + (1|Subject/Date)

Behavior ~ Cue + (1|Subject:Date)


Any advice on which of these are more appropriate for the structure of my
data?


The second issue is that I retested these same snakes in a second battery
of tests. The structure is identical, except instead of the first 4 cues (A
B C D), two cues were switched out for new ones (A B E F). I could perform
a separate analysis of the data from this battery of tests, using the best
format from the above data. However, since it is the same individual
animals, and since the A vs. B contrast is present in both batteries of
tests, it would be nice to put all the data into a single analysis. This
would strengthen the A vs. B comparisons and seems more elegant than two
separate analyses. ***Are there any reasons I couldn't do this?*** The only
thing I could think of would be that some pairwise comparisons would have
never actually been performed on the same day (e.g., C was part of the
first battery of tests, and E was part of the second), but accounting for
date effects should control for this, I think.


Finally, I was considering bootstrap analysis to generate CIs for testing
null hypotheses, as my data are hard to normalize with
transformations. ***Would
that eliminate the ability to do pairwise, post-hoc comparisons
(using lsmeans or multcomp)?*** I'd like to know which cues are different
from which. I could do this by re-running the analysis with each cue type
as the reference level - then the effects reported would be pairwise with
respect to the reference cue, but this doesn't account for multiple
comparisons.


Thank you so much in advance for taking the time to wade through this and
offer me any thoughts. I'd also be happy to send the data and have someone
put together a script that seems reasonable to them, so I can learn the
nuances of LMM a little better.


Best,

Brad


Assistant Professor of Biology

Wabash College

Crawfordsville, IN

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Wed Dec  6 15:36:37 2017
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 6 Dec 2017 14:36:37 +0000
Subject: [R-sig-ME] glm model with all zeros for one of the factor level
In-Reply-To: <CAF5W3aT5fLfG4A6psA+y5RLsaucFaTDtyO3XNoBB_-pGpfkq7Q@mail.gmail.com>
References: <CAF5W3aT5fLfG4A6psA+y5RLsaucFaTDtyO3XNoBB_-pGpfkq7Q@mail.gmail.com>
Message-ID: <0b7ec366-1116-4ad9-9ddf-83dcf37c601c@glasgow.ac.uk>

(This question is about GLMs rather than mixed models in R.)

I recommend reading up on separation in logistic regression, where the proportion in any of the categories formed by the fixed effects is exactly 1 or 0, so that a maximum likelihood estimate of the log odds doesn't exists. The logistf package is the simplest way of dealing with this in R.

Good luck,
Paul


Sent from BlueMail<http://www.bluemail.me/r?b=11327>
On 5 Dec 2017, at 16:00, Juan Pablo Edwards Molina <edwardsmolina at gmail.com<mailto:edwardsmolina at gmail.com>> wrote:

Dear List members:

I performed two independent experiments (CRD) to test if a whitefly
has preference to infect with a virus: potatos, tomatos or peppers
(target hosts, TH), wether if the virus was obtained from potato or
tomato (source hosts, SH). So I released 100 white flyes (previously
infected with the virus from one or other SH) inside cages containing
10 plants of each TH (30 total). This is how the data looks like:

exp  SH    TH    cage    tot  posit

1     tom    tom     1       10     4
1     tom    bat      1       10     3
1     tom    pep     1       10     0
1     bat    tom      2       10     1
1     bat    bat       2       10     2
1     bat    pep      2       10     0

2     tom    tom     3       10     6
2     tom    bat      3       10     4
2     tom    pep     3       10     0
2     bat    tom      4       10     4
2     bat    bat       4       10     0
2     bat    pep      4       10     0

The issue I found here  is that pepper was not infected at all,
however it was infected in another experiment without chance of TH
choice: i.e. I released infectious whiteflies inside cages containing
the same pepper genotyope and they present the typical virus disease
symptoms.

So, how should I consider modeling this data?
Zero-inflated negative binomial using the total plants as offset? Hurdle-model?
Should I remove the pepper level for the model?

Any help would be really helpful.

Juan Edwards

________________________________

R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Dec  6 15:53:36 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Dec 2017 09:53:36 -0500
Subject: [R-sig-ME] glm model with all zeros for one of the factor level
In-Reply-To: <0b7ec366-1116-4ad9-9ddf-83dcf37c601c@glasgow.ac.uk>
References: <CAF5W3aT5fLfG4A6psA+y5RLsaucFaTDtyO3XNoBB_-pGpfkq7Q@mail.gmail.com>
 <0b7ec366-1116-4ad9-9ddf-83dcf37c601c@glasgow.ac.uk>
Message-ID: <ec7f1cc7-7db3-dffd-c34a-843bd899b3f3@gmail.com>


  Agreed. I added a section to the glmm FAQ giving guidance on how to to
this in the GLMM case:
http://bbolker.github.io/mixedmodels-misc/ecostats_chap.html#digression-complete-separation


On 17-12-06 09:36 AM, Paul Johnson wrote:
> (This question is about GLMs rather than mixed models in R.)
> 
> I recommend reading up on separation in logistic regression, where
> the proportion in any of the categories formed by the fixed effects
> is exactly 1 or 0, so that a maximum likelihood estimate of the log
> odds doesn't exists. The logistf package is the simplest way of
> dealing with this in R.
> 
> Good luck, Paul
> 
> 
> Sent from BlueMail<http://www.bluemail.me/r?b=11327> On 5 Dec 2017,
> at 16:00, Juan Pablo Edwards Molina
> <edwardsmolina at gmail.com<mailto:edwardsmolina at gmail.com>> wrote:
> 
> Dear List members:
> 
> I performed two independent experiments (CRD) to test if a whitefly 
> has preference to infect with a virus: potatos, tomatos or peppers 
> (target hosts, TH), wether if the virus was obtained from potato or 
> tomato (source hosts, SH). So I released 100 white flyes (previously 
> infected with the virus from one or other SH) inside cages
> containing 10 plants of each TH (30 total). This is how the data
> looks like:
> 
> exp  SH    TH    cage    tot  posit
> 
> 1     tom    tom     1       10     4 1     tom    bat      1
> 10     3 1     tom    pep     1       10     0 1     bat    tom
> 2       10     1 1     bat    bat       2       10     2 1     bat
> pep      2       10     0
> 
> 2     tom    tom     3       10     6 2     tom    bat      3
> 10     4 2     tom    pep     3       10     0 2     bat    tom
> 4       10     4 2     bat    bat       4       10     0 2     bat
> pep      4       10     0
> 
> The issue I found here  is that pepper was not infected at all, 
> however it was infected in another experiment without chance of TH 
> choice: i.e. I released infectious whiteflies inside cages
> containing the same pepper genotyope and they present the typical
> virus disease symptoms.
> 
> So, how should I consider modeling this data? Zero-inflated negative
> binomial using the total plants as offset? Hurdle-model? Should I
> remove the pepper level for the model?
> 
> Any help would be really helpful.
> 
> Juan Edwards
> 
> ________________________________
> 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From edwardsmolina at gmail.com  Wed Dec  6 17:02:57 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Wed, 6 Dec 2017 13:02:57 -0300
Subject: [R-sig-ME] glm model with all zeros for one of the factor level
In-Reply-To: <ec7f1cc7-7db3-dffd-c34a-843bd899b3f3@gmail.com>
References: <CAF5W3aT5fLfG4A6psA+y5RLsaucFaTDtyO3XNoBB_-pGpfkq7Q@mail.gmail.com>
 <0b7ec366-1116-4ad9-9ddf-83dcf37c601c@glasgow.ac.uk>
 <ec7f1cc7-7db3-dffd-c34a-843bd899b3f3@gmail.com>
Message-ID: <CAF5W3aRGZGWQdEv-9x-jNuB26qBysZLD9bCoCHt++vA6eV2OGw@mail.gmail.com>

Thanks Ben and Paul... By the way, that was what actually happened
after fitting the glm:
...huge Wald confidence intervals...(from glm FAQ).
I will take a look on that section of glm FAQ.
best,
Juan Edwards
Juan


On Wed, Dec 6, 2017 at 11:53 AM, Ben Bolker <bbolker at gmail.com> wrote:
>
>   Agreed. I added a section to the glmm FAQ giving guidance on how to to
> this in the GLMM case:
> http://bbolker.github.io/mixedmodels-misc/ecostats_chap.html#digression-complete-separation
>
>
> On 17-12-06 09:36 AM, Paul Johnson wrote:
>> (This question is about GLMs rather than mixed models in R.)
>>
>> I recommend reading up on separation in logistic regression, where
>> the proportion in any of the categories formed by the fixed effects
>> is exactly 1 or 0, so that a maximum likelihood estimate of the log
>> odds doesn't exists. The logistf package is the simplest way of
>> dealing with this in R.
>>
>> Good luck, Paul
>>
>>
>> Sent from BlueMail<http://www.bluemail.me/r?b=11327> On 5 Dec 2017,
>> at 16:00, Juan Pablo Edwards Molina
>> <edwardsmolina at gmail.com<mailto:edwardsmolina at gmail.com>> wrote:
>>
>> Dear List members:
>>
>> I performed two independent experiments (CRD) to test if a whitefly
>> has preference to infect with a virus: potatos, tomatos or peppers
>> (target hosts, TH), wether if the virus was obtained from potato or
>> tomato (source hosts, SH). So I released 100 white flyes (previously
>> infected with the virus from one or other SH) inside cages
>> containing 10 plants of each TH (30 total). This is how the data
>> looks like:
>>
>> exp  SH    TH    cage    tot  posit
>>
>> 1     tom    tom     1       10     4 1     tom    bat      1
>> 10     3 1     tom    pep     1       10     0 1     bat    tom
>> 2       10     1 1     bat    bat       2       10     2 1     bat
>> pep      2       10     0
>>
>> 2     tom    tom     3       10     6 2     tom    bat      3
>> 10     4 2     tom    pep     3       10     0 2     bat    tom
>> 4       10     4 2     bat    bat       4       10     0 2     bat
>> pep      4       10     0
>>
>> The issue I found here  is that pepper was not infected at all,
>> however it was infected in another experiment without chance of TH
>> choice: i.e. I released infectious whiteflies inside cages
>> containing the same pepper genotyope and they present the typical
>> virus disease symptoms.
>>
>> So, how should I consider modeling this data? Zero-inflated negative
>> binomial using the total plants as offset? Hurdle-model? Should I
>> remove the pepper level for the model?
>>
>> Any help would be really helpful.
>>
>> Juan Edwards
>>
>> ________________________________
>>
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jmoore25 at wsu.edu  Fri Dec  8 00:34:48 2017
From: jmoore25 at wsu.edu (Moore, James Roy)
Date: Thu, 7 Dec 2017 23:34:48 +0000
Subject: [R-sig-ME] repeated measures and random effects question
In-Reply-To: <CY4PR01MB280539757B91848B7ECAE33AC6330@CY4PR01MB2805.prod.exchangelabs.com>
References: <CY4PR01MB2805D6E6CCCAF6B8B26EC344C6330@CY4PR01MB2805.prod.exchangelabs.com>
 <6bf66c89-784a-f39e-0224-4b85f14ac4f8@mcmaster.ca>
 <CY4PR01MB280539757B91848B7ECAE33AC6330@CY4PR01MB2805.prod.exchangelabs.com>
Message-ID: <CY4PR01MB2805596B5AD26BF133449AF2C6330@CY4PR01MB2805.prod.exchangelabs.com>

Hello list, 

Not sure how to address a list, so let me know if I'm doing something wrong.  

I'm having a difficult time wrapping my mind around how to account for repeated measures and random effects and was directed here.

My experimental design is:
4 sites
2 plots per site (control and treatment, 10m x 10m)
8 subplots per plot (1m x 1m) 
3 years (each subplot sampled once per year every year)

Response variable: proportional plant cover
Potential covariates/predictors: other proportional plant cover, herbivore damage
The treatment is herbivore removal so instead of using the factor treatment in the model I'm using proportional herbivore damage. 

I have to use a package specific for beta distribution with 0's but we can talk about this in the context of a glmm using lme4 since that is the syntax I'm most familiar with.  My limited understanding leads me to:
Plant cover ~ herbivore damage + some covariates +(1|site)+(year|site/plot/subplot)
	Random variation between sites and, to account for repeated measures, subplots nested within plot nested within site sampled at a yearly interval for 	3 years.

As an additional curiosity, is there any problem with excluding the treatment factor and using proportional herbivore damage instead? Also, since site is included in the second random term, is the first term still necessary.  There is definitely variation between sites.  

Thank you for any assistance you're able to provide,
James 


From thierry.onkelinx at inbo.be  Mon Dec 11 11:42:08 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 11 Dec 2017 11:42:08 +0100
Subject: [R-sig-ME] repeated measures and random effects question
In-Reply-To: <CY4PR01MB2805596B5AD26BF133449AF2C6330@CY4PR01MB2805.prod.exchangelabs.com>
References: <CY4PR01MB2805D6E6CCCAF6B8B26EC344C6330@CY4PR01MB2805.prod.exchangelabs.com>
 <6bf66c89-784a-f39e-0224-4b85f14ac4f8@mcmaster.ca>
 <CY4PR01MB280539757B91848B7ECAE33AC6330@CY4PR01MB2805.prod.exchangelabs.com>
 <CY4PR01MB2805596B5AD26BF133449AF2C6330@CY4PR01MB2805.prod.exchangelabs.com>
Message-ID: <CAJuCY5y6o52DtA1A+5c0GcZqRtPY9Ku7ohHpBFifq1Ov9O8poQ@mail.gmail.com>

Dear James,

Your models is too complex given the available data. The random part can be
expanded to (1 + year|site) + (1 + year|site:plot) + (1 +
year|site:plot:subplot). The number of data points for each level of the
random effect groups are respectively 48, 24 and 3. I'm not comfortable
fitting a linear trend through only 3 data points... Also consider
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random,
especially the last paragraph.

I would strongly recommend that you consult a local statistician.

Best regards,



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[image: Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging
in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis. Vanaf
dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.]
<https://overheid.vlaanderen.be/mobiliteitsplan-herman-teirlinckgebouw>
Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
Brussel.

///////////////////////////////////////////////////////////////////////////////////////////
<https://www.inbo.be>

2017-12-08 0:34 GMT+01:00 Moore, James Roy <jmoore25 at wsu.edu>:

> Hello list,
>
> Not sure how to address a list, so let me know if I'm doing something
> wrong.
>
> I'm having a difficult time wrapping my mind around how to account for
> repeated measures and random effects and was directed here.
>
> My experimental design is:
> 4 sites
> 2 plots per site (control and treatment, 10m x 10m)
> 8 subplots per plot (1m x 1m)
> 3 years (each subplot sampled once per year every year)
>
> Response variable: proportional plant cover
> Potential covariates/predictors: other proportional plant cover, herbivore
> damage
> The treatment is herbivore removal so instead of using the factor
> treatment in the model I'm using proportional herbivore damage.
>
> I have to use a package specific for beta distribution with 0's but we can
> talk about this in the context of a glmm using lme4 since that is the
> syntax I'm most familiar with.  My limited understanding leads me to:
> Plant cover ~ herbivore damage + some covariates +(1|site)+(year|site/plot/
> subplot)
>         Random variation between sites and, to account for repeated
> measures, subplots nested within plot nested within site sampled at a
> yearly interval for   3 years.
>
> As an additional curiosity, is there any problem with excluding the
> treatment factor and using proportional herbivore damage instead? Also,
> since site is included in the second random term, is the first term still
> necessary.  There is definitely variation between sites.
>
> Thank you for any assistance you're able to provide,
> James
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Dec 12 09:11:34 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 12 Dec 2017 09:11:34 +0100
Subject: [R-sig-ME] Choosing best approach for a crossover experiment
In-Reply-To: <CAF37_Nft=r0f7yjW2kGrdW-iemrGKeSY-n5GKME7jknpaYxObw@mail.gmail.com>
References: <CAF37_Nft=r0f7yjW2kGrdW-iemrGKeSY-n5GKME7jknpaYxObw@mail.gmail.com>
Message-ID: <CAJuCY5xEtYeTW=kkCXWJ1DGrwR2eLwrYpvs-Kuurfj3scs7Miw@mail.gmail.com>

Dear Bradley,

For your first question you could consider the combination of crossed
and interaction random effects. (1|Subject) + (1|Date) +
(1|Subject:Date) That might be overkill given that you have only 4
observations for each level of Subject:Date. Therefore I'd rather go
for (1|Subject) + (1|Date).

For the second one: though not the most efficient design to test 6
treatment, it seems reasonable to me to analyse them with a single
model.

For the last question: What is hard to normalise? The response or the
residuals? Note that only the residuals are assumed to be normal.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-12-05 17:50 GMT+01:00 Bradley Carlson <carbrae at gmail.com>:
> Hello all,
>
>
> I have data from a repeated measures, crossover experiment that goes a bit
> beyond my experience. I wanted to be sure I was approaching the data in the
> right way. The sample size is small as this is an independent study project
> with an undergraduate student, but we see some interesting patterns and I
> hope it holds up to a proper analysis. Pardon the length of the
> explanation: I want to be clear about what the problems are.
>
>
> I'm trying to test whether snakes respond differently to certain odor cues.
> We have 5 individual snakes. The first week, each snake was tested in 3
> sets of tests, with each set of tests on a different day. In each set, they
> were exposed to all 4 cues in a randomized order (C B A D on day 1, then A
> B D C on day 2, etc.) Don't worry about order effects - that's not where
> I'm going with this. I expect the same snakes' behavior to be correlated
> both across days (some snakes exhibit stronger responses reliably), and I
> expect their behavior in response to the 4 different cues to be correlated
> within days (e.g., if they happen to be warmer on Monday, they might have a
> stronger response to all 4 cues). I don't necessarily expect this
> day-to-day variation to be correlated among individuals (I doubt Monday
> would be a high response day for all snakes). What I care about are the
> within-subjects, within-date differences between the cues (do they reliably
> respond more strongly to cue A than the other cues tested on the same day?)
>
>
> ***My first question is what would be the proper formatting for a repeated
> measures analysis of this in lmer**.* I was torn between a few different
> options:
>
>
> Behavior ~ Cue + (1|Subject) + (1|Date)   <--- Seems to assume that date
> effects are similar for all individuals
>
> Behavior ~ Cue + (1|Subject/Date)
>
> Behavior ~ Cue + (1|Subject:Date)
>
>
> Any advice on which of these are more appropriate for the structure of my
> data?
>
>
> The second issue is that I retested these same snakes in a second battery
> of tests. The structure is identical, except instead of the first 4 cues (A
> B C D), two cues were switched out for new ones (A B E F). I could perform
> a separate analysis of the data from this battery of tests, using the best
> format from the above data. However, since it is the same individual
> animals, and since the A vs. B contrast is present in both batteries of
> tests, it would be nice to put all the data into a single analysis. This
> would strengthen the A vs. B comparisons and seems more elegant than two
> separate analyses. ***Are there any reasons I couldn't do this?*** The only
> thing I could think of would be that some pairwise comparisons would have
> never actually been performed on the same day (e.g., C was part of the
> first battery of tests, and E was part of the second), but accounting for
> date effects should control for this, I think.
>
>
> Finally, I was considering bootstrap analysis to generate CIs for testing
> null hypotheses, as my data are hard to normalize with
> transformations. ***Would
> that eliminate the ability to do pairwise, post-hoc comparisons
> (using lsmeans or multcomp)?*** I'd like to know which cues are different
> from which. I could do this by re-running the analysis with each cue type
> as the reference level - then the effects reported would be pairwise with
> respect to the reference cue, but this doesn't account for multiple
> comparisons.
>
>
> Thank you so much in advance for taking the time to wade through this and
> offer me any thoughts. I'd also be happy to send the data and have someone
> put together a script that seems reasonable to them, so I can learn the
> nuances of LMM a little better.
>
>
> Best,
>
> Brad
>
>
> Assistant Professor of Biology
>
> Wabash College
>
> Crawfordsville, IN
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From sivakoff.3 at osu.edu  Tue Dec 12 20:19:55 2017
From: sivakoff.3 at osu.edu (Sivakoff, Frances)
Date: Tue, 12 Dec 2017 19:19:55 +0000
Subject: [R-sig-ME] Plotting partial residuals from a glmmADMB model
Message-ID: <DAB16A0903A9474491F9134DDC566BC873E5E245@CIO-TNC-D2MBX06.osuad.osu.edu>

I would like to use ggplot2 to plot the partial residuals of an indicator (0 or 1) independent variable in a generalized linear mixed model fit with a "nbinom1" family using glmmadmb. My model has a response variable that is a count, 3 explanatory variables that are continuous, and 7 indicator variables that are 0 when a particular heavy metal is not detected and 1 when it is detected above a threshold value. I'd like to plot the partial residuals of the various independent variables. I think that the model below using the Owl data would be a good example data set for how to do this. The model below has a response variable that is a count, an explanatory variables that is continuous (arrivalTime), two categorical variables (FoodTreatment and SexParent), a random effect of Nest, and uses a "nbinom1" family.

##Using the Owl Data
om <- glmmadmb(SiblingNegotiation~FoodTreatment+ArrivalTime+SexParent+
                 (1|Nest),family="nbinom1",data=Owls)

Could you please suggest a method for plotting the partial residuals of the explanatory variables.

Thank you,
Frances


	[[alternative HTML version deleted]]


From juliachacon at gmail.com  Thu Dec 14 20:25:44 2017
From: juliachacon at gmail.com (Julia Chacon Labella)
Date: Thu, 14 Dec 2017 20:25:44 +0100
Subject: [R-sig-ME] testing significance of fixed factors in a mixed model
Message-ID: <CAPsE2jzpTq5d0MUDHvmAwbUuWC7P6ygBsh=J5nvXY4sbb03u9Q@mail.gmail.com>

I am sorry if I am asking a na?ve question or if that has been already
asked many times. I am not an expert in mixed models at all, but want to
understand and be confident about what I am doing.

Actually, I am analysing a data set of a experiment. I have several
treatments, a balance design, randomized by blocks, etc., and generally
following the recommendations of the FAQs by Bolker, what are really
usefull (Thanks!). http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html

But, I am pretty confused about how to test the significance of fixed
factors in a mixed model.
I find huge differences in the significance output when computing 1) Anova
from the car package or 2) anova from lmerTest with KR or satterthwaite
approaches (both, KR or Satterthwaite have similar results), or 3) a LRT
via anova. The biggest differences are found for car::Anova!

* First, I am not sure if I should employ a LRT or a conditional F-test
(lmerTest::anova, KR or satterthwaite approaches). Both results are pretty
similar in my case, but conditional F-test seem to slightly be more
conservative in my case. Can the F-test be somehow problematic in terms of
statistical power?

* Second, in case of using lmerTest::anova, I am not completely sure if I
should used a type I or type III anova.  There is any reason for using type
I anova in balanced designs?

Thanks in advance,
Julia

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Dec 15 03:51:34 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Dec 2017 21:51:34 -0500
Subject: [R-sig-ME] testing significance of fixed factors in a mixed
	model
In-Reply-To: <CAPsE2jzpTq5d0MUDHvmAwbUuWC7P6ygBsh=J5nvXY4sbb03u9Q@mail.gmail.com>
References: <CAPsE2jzpTq5d0MUDHvmAwbUuWC7P6ygBsh=J5nvXY4sbb03u9Q@mail.gmail.com>
Message-ID: <CABghstSC-oaqKeNH=XeS1Jys1av+zaY42b8WJ2gF3imZX5rH+w@mail.gmail.com>

Can you show us some of your output?

In general, an F-test will be more accurate than an LRT in cases where
you can figure out how to do it, because an LRT doesn't make any
finite-size corrections (what df values are you getting from
KR/Satterthwaite)?

The thing you will have to think hardest about is which variables are
conditioned on when testing, especially when you have interactions in
your model and are considering testing main effects.

On Thu, Dec 14, 2017 at 2:25 PM, Julia Chacon Labella
<juliachacon at gmail.com> wrote:
> I am sorry if I am asking a na?ve question or if that has been already
> asked many times. I am not an expert in mixed models at all, but want to
> understand and be confident about what I am doing.
>
> Actually, I am analysing a data set of a experiment. I have several
> treatments, a balance design, randomized by blocks, etc., and generally
> following the recommendations of the FAQs by Bolker, what are really
> usefull (Thanks!). http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html
>
> But, I am pretty confused about how to test the significance of fixed
> factors in a mixed model.
> I find huge differences in the significance output when computing 1) Anova
> from the car package or 2) anova from lmerTest with KR or satterthwaite
> approaches (both, KR or Satterthwaite have similar results), or 3) a LRT
> via anova. The biggest differences are found for car::Anova!
>
> * First, I am not sure if I should employ a LRT or a conditional F-test
> (lmerTest::anova, KR or satterthwaite approaches). Both results are pretty
> similar in my case, but conditional F-test seem to slightly be more
> conservative in my case. Can the F-test be somehow problematic in terms of
> statistical power?
>
> * Second, in case of using lmerTest::anova, I am not completely sure if I
> should used a type I or type III anova.  There is any reason for using type
> I anova in balanced designs?
>
> Thanks in advance,
> Julia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Dec 15 03:53:54 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Dec 2017 21:53:54 -0500
Subject: [R-sig-ME] Plotting partial residuals from a glmmADMB model
In-Reply-To: <DAB16A0903A9474491F9134DDC566BC873E5E245@CIO-TNC-D2MBX06.osuad.osu.edu>
References: <DAB16A0903A9474491F9134DDC566BC873E5E245@CIO-TNC-D2MBX06.osuad.osu.edu>
Message-ID: <CABghstRC62tAe7bRVMAGt05Piy6kUXweqKSAKkMsJje9fFvaNw@mail.gmail.com>

You'll have to find a way to make "partial predictions". I don't think
there's anything built in for this.  *Very* briefly, considering
only fixed effects, if you retrieve the X matrix
(getME(fitted_model,"X")) and the fixed-effect parameters
(fixef(fitted_model)),
you can drop any columns/parameters you want and do exp(X %*% beta)
with the remaining columns/parameters to get a prediction
that includes some but not all of the predictors. Subtracting the
observed value should get you the partial residuals ...


On Tue, Dec 12, 2017 at 2:19 PM, Sivakoff, Frances <sivakoff.3 at osu.edu> wrote:
> I would like to use ggplot2 to plot the partial residuals of an indicator (0 or 1) independent variable in a generalized linear mixed model fit with a "nbinom1" family using glmmadmb. My model has a response variable that is a count, 3 explanatory variables that are continuous, and 7 indicator variables that are 0 when a particular heavy metal is not detected and 1 when it is detected above a threshold value. I'd like to plot the partial residuals of the various independent variables. I think that the model below using the Owl data would be a good example data set for how to do this. The model below has a response variable that is a count, an explanatory variables that is continuous (arrivalTime), two categorical variables (FoodTreatment and SexParent), a random effect of Nest, and uses a "nbinom1" family.
>
> ##Using the Owl Data
> om <- glmmadmb(SiblingNegotiation~FoodTreatment+ArrivalTime+SexParent+
>                  (1|Nest),family="nbinom1",data=Owls)
>
> Could you please suggest a method for plotting the partial residuals of the explanatory variables.
>
> Thank you,
> Frances
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From caterinaww at gmail.com  Sat Dec 16 14:31:22 2017
From: caterinaww at gmail.com (Cate Ferrari)
Date: Sat, 16 Dec 2017 14:31:22 +0100
Subject: [R-sig-ME] multinomial model with MCMCglmm
Message-ID: <CA+kOGs-j+Bo5gbxOoY1NF062=rKtjTrExxAvU+66F9gVMdkCYQ@mail.gmail.com>

Dear members of the list
 I am writing you about a multinomial model I am currently trying to run
using  MCMCglmm.
 My data are about time budget behaviors, so I have different behaviors on
different individuals collected during a scan. In my model I added some
fxed effects as age, season, area, and Id of the animal as random term.
The model run but when I have the summary I see that instead of having the
6 behaviors that I have in the dataset, I have 5; so I guess the first (in
alphabetic order) is retained as reference. But I don't want this to
happen, where am I wrong?

Also I would need to back transform the estimates for each behavior given
in the summary , but I don't know how to do it.

Can anyone give me some advices?
Thanks a lot in advance!
Caterina


Behaviors in the model:
Agonistic, affiliative, others, foraging, looking, moving


Model

MarmotTB3.mcmc<-MCMCglmm(ATTIVITA2~trait-1+trait:ETA+trait:ZONA+trait:
PERIODO,random=~us(trait)

                         :MARMOTTA,rcov = ~ us(trait):units, family=
"categorical",

                         prior=prior, data=alta.dat,verbose=TRUE,nitt=130000,
thin=100, burnin=30000)


Iterations = 30001:129901

Thinning interval = 100

Number of chains = 1

Sample size per chain = 1000


1. Empirical mean and standard deviation for each variable,

plus standard error of the mean:



  Mean     SD Naive SE Time-series SE

traitATTIVITA2.AGONISTICO           -5.1953780 0.9464 0.029928
0.23713

traitATTIVITA2.ALTRO                -6.2860308 0.8939 0.028268
0.19988

traitATTIVITA2.FORAGING              0.9998039 0.3022 0.009555
0.03373

traitATTIVITA2.LOOKING               0.7450175 0.3297 0.010425
0.03146

traitATTIVITA2.MOVING               -0.9486360 0.3775 0.011938
0.04533


traitATTIVITA2.AGONISTICO:ETA1       1.4235583 1.0277 0.032499
0.27793

traitATTIVITA2.ALTRO:ETA1            0.3434346 0.8574 0.027113
0.21602

traitATTIVITA2.FORAGING:ETA1        -0.2241162 0.2880 0.009107
0.02506

traitATTIVITA2.LOOKING :ETA1        -0.6997858 0.3096 0.009792
0.02601

traitATTIVITA2.MOVING:ETA1          -0.7655606 0.3917 0.012388
0.05077

traitATTIVITA2.AGONISTICO:ETA2+      3.9285262 0.9196 0.029080
0.24008

traitATTIVITA2.ALTRO:ETA2+           1.8530251 0.9014 0.028504
0.23861

traitATTIVITA2.FORAGING:ETA2+        0.4938721 0.2772 0.008766
0.02789

traitATTIVITA2.LOOKING :ETA2+        0.3984561 0.3102 0.009808
0.02788

traitATTIVITA2.MOVING:ETA2+          0.5437561 0.3356 0.010612
0.03101

traitATTIVITA2.AGONISTICO:ZONABASSA -0.7366481 0.6147 0.019437
0.11113

traitATTIVITA2.ALTRO:ZONABASSA       1.5733998 0.5394 0.017056
0.12034

traitATTIVITA2.FORAGING:ZONABASSA    0.1929651 0.2218 0.007013
0.01844

traitATTIVITA2.LOOKING :ZONABASSA    0.2431249 0.2522 0.007975
0.02239

traitATTIVITA2.MOVING:ZONABASSA      0.2652439 0.3282 0.010380
0.05740

traitATTIVITA2.AGONISTICO:PERIODOB   0.8002443 0.3524 0.011143
0.04702

traitATTIVITA2.ALTRO:PERIODOB        1.4053954 0.5840 0.018467
0.14606

traitATTIVITA2.FORAGING:PERIODOB     0.4976160 0.1958 0.006192
0.03157

traitATTIVITA2.LOOKING :PERIODOB     0.6249756 0.2100 0.006640
0.02844

traitATTIVITA2.MOVING:PERIODOB       0.3089387 0.2710 0.008570
0.04932

traitATTIVITA2.AGONISTICO:PERIODOC   0.7986439 0.4134 0.013073
0.06651

traitATTIVITA2.ALTRO:PERIODOC        1.2147869 0.7173 0.022683
0.20310

traitATTIVITA2.FORAGING:PERIODOC     1.5504290 0.1906 0.006029
0.02575

traitATTIVITA2.LOOKING :PERIODOC     0.9520809 0.2049 0.006478
0.02630

traitATTIVITA2.MOVING:PERIODOC      -0.0004336 0.2828 0.008943
0.05482

	[[alternative HTML version deleted]]


From juliachacon at gmail.com  Sat Dec 16 19:05:31 2017
From: juliachacon at gmail.com (Julia Chacon Labella)
Date: Sat, 16 Dec 2017 19:05:31 +0100
Subject: [R-sig-ME] testing significance of fixed factors in a mixed
	model
In-Reply-To: <CABghstSC-oaqKeNH=XeS1Jys1av+zaY42b8WJ2gF3imZX5rH+w@mail.gmail.com>
References: <CAPsE2jzpTq5d0MUDHvmAwbUuWC7P6ygBsh=J5nvXY4sbb03u9Q@mail.gmail.com>
 <CABghstSC-oaqKeNH=XeS1Jys1av+zaY42b8WJ2gF3imZX5rH+w@mail.gmail.com>
Message-ID: <CAPsE2jzAJQmsoTM7-1iO8YZtMGTpzAPpu0tpn+S6cy0fL99VRA@mail.gmail.com>

Thank you very much for your quick answer. Here is the coding of the model:

m1_y <- lmer(log(total_yield) ~ bench +  dom + MoMix + Divalias + fgalias +
               dom:MoMix + dom:Divalias + dom:fgalias+
         fgcomb + dom:fgcomb + MoMix:fgcomb + Divalias:fgcomb +
fgalias:fgcomb+
         dom:MoMix:fgcomb + dom:Divalias:fgcomb + dom:fgalias:fgcomb+
              (1|spcomb),
            data=data_wo_s)

bench: three levels (a,b,c)
dom: has two levels (c and w)
Now I have the treatments. This is like a tree, where I test three
variables that are included in the previous one.
MoMix: has two levels (mono and mix)
    Divalias: has two levels (2 and 4). This two levels are available
within Mix
       Fgalias: has two levels (1 and 2). This two are only and are
included within level 2 in Divalias
So these three are not orthogonal.
fgcomb has 9 levels.
In the random part I have spcomb that are species combinations and have
many levels.
I copied the summary of the model at the end of the email.

NOW, the anovas!
> anova(m1_y, ddf="Kenward-Roger", type=1)

Analysis of Variance Table of type I  with  Kenward-Roger
approximation for degrees of freedom
                  Sum Sq  Mean Sq NumDF   DenDF F.value    Pr(>F)
bench            0.00037 0.000187     2 143.957  0.0043    0.9957
dom              0.02235 0.022345     1 297.576  0.5147    0.4737
MoMix            0.09241 0.092411     1  32.982  2.1288    0.1540
Divalias         0.01255 0.012553     1  37.111  0.2892    0.5940
fgalias          0.00956 0.009564     1  32.410  0.2203    0.6419
fgcomb           2.15832 0.269790     8  34.559  6.2148 5.608e-05 ***
dom:MoMix        0.11248 0.112478     1 298.040  2.5910    0.1085
dom:Divalias     0.00017 0.000174     1 297.846  0.0040    0.9495
dom:fgalias      0.09687 0.096866     1 298.607  2.2314    0.1363
dom:fgcomb       0.58166 0.072707     8 294.133  1.6749    0.1040
MoMix:fgcomb     0.02578 0.008592     3  32.124  0.1979    0.8970
dom:MoMix:fgcomb 0.21952 0.073172     3 292.107  1.6856    0.1702
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

This is the output when I do a type I anova in lmerTest. I was doing a type
I anova, because I wanted to "eliminate" or control the effect of bench.
So, the other factors are tested after and there is less variance to be
explained, that is less from the benches of the greenhouse. But, now I am
not sure if this is the best way to proceed.
Because Type I test the terms in the order of appearance and the way it
calculates the sum of squares, you only get the combined effect of the
factor and the below ones. So...with a Type I anova I am not going to see
the effect of each single factor (isn't it?).
Now I think I should go for a type II. But, not completely sure about that
and as you will see the output is completely different.

Here the type 2.

> anova(m1_y, ddf="Kenward-Roger", type=2)
Analysis of Variance Table of type II  with  Kenward-Roger
approximation for degrees of freedom
                  Sum Sq Mean Sq NumDF   DenDF F.value    Pr(>F)
bench            0.14694 0.07347     2 299.947  1.6924  0.185832
dom              0.01050 0.01050     1 292.202  0.2419  0.623175
MoMix            0.01389 0.01389     1  32.110  0.3199  0.575592
Divalias         0.31910 0.31910     1  32.219  7.3508  0.010660 *
fgalias          0.52884 0.52884     1  32.650 12.1823  0.001405 **
fgcomb           2.16056 0.27007     8  34.559  6.2213 5.556e-05 ***
dom:MoMix        0.00350 0.00350     1 292.154  0.0806  0.776621
dom:Divalias     0.24601 0.24601     1 292.329  5.6670  0.017928 *
dom:fgalias      0.26688 0.26688     1 292.277  6.1477  0.013722 *
dom:fgcomb       0.58182 0.07273     8 292.227  1.6753  0.103916
MoMix:fgcomb     0.02578 0.00859     3  32.124  0.1979  0.897033
dom:MoMix:fgcomb 0.21952 0.07317     3 292.107  1.6856  0.170192
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


I am interested in the main effects but also in the interactions, of
course. So, should I test this with a type II or type I anova?
I was also wondering if there is any way of escaping from this, hahaha, was
wondering if going to a Confidence interval approach is a much more elegant
way of solving this...

Thanks so much. I am so sorry for the long email.
Julia

---------------------------------------------------------------------------------------
summary(m1_y)

REML criterion at convergence: 66.4

Scaled residuals:
     Min       1Q   Median       3Q      Max
-2.72351 -0.57177  0.07539  0.58399  2.81317

Random effects:
 Groups   Name        Variance Std.Dev.
 spcomb   (Intercept) 0.07007  0.2647
 Residual             0.04341  0.2084
Number of obs: 361, groups:  spcomb, 52

Fixed effects:
                        Estimate Std. Error        df t value Pr(>|t|)
(Intercept)              2.58512    0.27555  35.22000   9.382 4.12e-11 ***
benchb                   0.05650    0.03070 301.72000   1.840  0.06669 .
benchc                   0.03420    0.03058 301.94000   1.118  0.26441
domw                    -0.25077    0.10469 292.80000  -2.395  0.01723 *
MoMixMon                -0.11301    0.33789  35.40000  -0.334  0.74001
Divalias4                0.61797    0.28504  35.74000   2.168  0.03690 *
fgalias2                 0.88760    0.31157  36.85000   2.849  0.00714 **
fgcombc4                 1.11869    0.38961  35.20000   2.871  0.00688 **
fgcombfb                 0.36312    0.38871  34.88000   0.934  0.35663
fgcomblg                 0.73868    0.38870  34.87000   1.900  0.06567 .
fgcombc4c3              -0.22859    0.20748  45.19000  -1.102  0.27639
fgcombfbc3              -0.55140    0.20666  44.50000  -2.668  0.01060 *
fgcombfbc4              -0.17922    0.20698  44.78000  -0.866  0.39117
fgcombfblg              -0.30621    0.20665  44.50000  -1.482  0.14544
fgcomblgc3              -0.63072    0.20743  45.15000  -3.041  0.00392 **
domw:MoMixMon            0.05878    0.13489 292.76000   0.436  0.66331
domw:Divalias4           0.27973    0.11750 292.99000   2.381  0.01792 *
domw:fgalias2            0.33864    0.13657 292.94000   2.480  0.01372 *
domw:fgcombc4            0.16957    0.14999 292.71000   1.131  0.25917
domw:fgcombfb            0.33597    0.14769 292.75000   2.275  0.02364 *
domw:fgcomblg            0.36547    0.14753 292.73000   2.477  0.01380 *
domw:fgcombc4c3          0.06844    0.12378 293.12000   0.553  0.58072
domw:fgcombfbc3         -0.04844    0.12231 292.95000  -0.396  0.69237
domw:fgcombfbc4          0.04190    0.12282 293.02000   0.341  0.73323
domw:fgcombfblg         -0.07774    0.12201 292.92000  -0.637  0.52449
domw:fgcomblgc3         -0.13964    0.12339 293.12000  -1.132  0.25871
MoMixMon:fgcombc4       -0.02594    0.47926  35.82000  -0.054  0.95713
MoMixMon:fgcombfb        0.23764    0.47830  35.53000   0.497  0.62236
MoMixMon:fgcomblg       -0.10096    0.47803  35.45000  -0.211  0.83395
domw:MoMixMon:fgcombc4   0.14393    0.19339 292.73000   0.744  0.45732
domw:MoMixMon:fgcombfb  -0.21472    0.19170 292.77000  -1.120  0.26360
domw:MoMixMon:fgcomblg  -0.22705    0.19048 292.72000  -1.192  0.23424



2017-12-15 3:51 GMT+01:00 Ben Bolker <bbolker at gmail.com>:

> Can you show us some of your output?
>
> In general, an F-test will be more accurate than an LRT in cases where
> you can figure out how to do it, because an LRT doesn't make any
> finite-size corrections (what df values are you getting from
> KR/Satterthwaite)?
>
> The thing you will have to think hardest about is which variables are
> conditioned on when testing, especially when you have interactions in
> your model and are considering testing main effects.
>
> On Thu, Dec 14, 2017 at 2:25 PM, Julia Chacon Labella
> <juliachacon at gmail.com> wrote:
> > I am sorry if I am asking a na?ve question or if that has been already
> > asked many times. I am not an expert in mixed models at all, but want to
> > understand and be confident about what I am doing.
> >
> > Actually, I am analysing a data set of a experiment. I have several
> > treatments, a balance design, randomized by blocks, etc., and generally
> > following the recommendations of the FAQs by Bolker, what are really
> > usefull (Thanks!). http://bbolker.github.io/
> mixedmodels-misc/glmmFAQ.html
> >
> > But, I am pretty confused about how to test the significance of fixed
> > factors in a mixed model.
> > I find huge differences in the significance output when computing 1)
> Anova
> > from the car package or 2) anova from lmerTest with KR or satterthwaite
> > approaches (both, KR or Satterthwaite have similar results), or 3) a LRT
> > via anova. The biggest differences are found for car::Anova!
> >
> > * First, I am not sure if I should employ a LRT or a conditional F-test
> > (lmerTest::anova, KR or satterthwaite approaches). Both results are
> pretty
> > similar in my case, but conditional F-test seem to slightly be more
> > conservative in my case. Can the F-test be somehow problematic in terms
> of
> > statistical power?
> >
> > * Second, in case of using lmerTest::anova, I am not completely sure if I
> > should used a type I or type III anova.  There is any reason for using
> type
> > I anova in balanced designs?
> >
> > Thanks in advance,
> > Julia
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Julia

	[[alternative HTML version deleted]]


From m.westinbrook at gmail.com  Sun Dec 17 22:01:12 2017
From: m.westinbrook at gmail.com (M West)
Date: Sun, 17 Dec 2017 15:01:12 -0600
Subject: [R-sig-ME] Mixed effects model with unbalanced repeated measures
	across blocks
Message-ID: <CAKHcBHqvpXU7ApdBoPLeedhJ3EV40BDKpTUFLEGXu95tM3X2gA@mail.gmail.com>

Hello,

I would like to double check that my model is 'OK'.
I am analyzing whether the density of nests differed across four different
forests. Design: I repeatedly sampled transects in the same four forests
throughout the breeding season (May - September). The question here is not
whether the density of nests differed each month (which is what most
examples I've found tend to ask), but I need to make sure to account for
the autocorrelation from repeatedly sampling each forest (i.e., each
transect at each forest).

This design is unbalanced: some sites were only sampled for 2 months,
others were sampled all 5 months and some sites have more transects
compared to others (to account for differences in the length of edges of
the forest). I don't know how to account for this unbalanced design.

The output is included.

Many thanks in advance
~M


model <- with(data, glmer(Number_of_Nests ~ Forest + Week +
(1|Forest:TransectID), family = poisson, data=data))
summary(model)
anova(model, Type = 'II')


Here is the output:


Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: poisson  ( log )
Formula: Number_of_Nests ~ Forest+ Month + (1 | Forest:TransectID)
 Data: data

     AIC      BIC   logLik deviance df.resid
   555.1    577.1   -267.5    535.1       57

Scaled residuals:
    Min      1Q  Median      3Q     Max
-5.8501 -1.3650 -0.0699  0.9217  4.9935

Random effects:
 Groups          Name        Variance Std.Dev.
Forest:TransectID (Intercept) 0.5939   0.7707
Number of obs: 67, groups:  Forest:TransectID, 19

Fixed effects:
               Estimate Std. Error z value Pr(>|z|)
(Intercept)     1.64503    0.54558   3.015 0.002568 **
ForestA     1.03360    0.60045   1.721 0.085182 .
ForestB         -0.44092    0.72516  -0.608 0.543171
ForestC          1.90743    0.78368   2.434 0.014935 *
MonthMay       0.30640    0.08737   3.507 0.000453 ***
MonthJune      -1.11313    0.13132  -8.477  < 2e-16 ***
MonthJuly  -2.63123    0.25254 -10.419  < 2e-16 ***
MonthAugust   -1.34959    0.17249  -7.824 5.11e-15 ***
MonthSeptember -1.34612    0.72723  -1.851 0.064168 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Mon Dec 18 16:55:22 2017
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Mon, 18 Dec 2017 16:55:22 +0100
Subject: [R-sig-ME] Mixed Models in a very basic replication design
Message-ID: <0bcbdfe0-5206-67c5-c6a9-bd65ee765b32@uni-bremen.de>

Dear Group,

i am to plan a very basic factorial greenhouse experiment, and this time 
i will first ask for statistical advise before execution :).

It will encompass two treatment types with two levels each, two sampling 
dates with five replicates each, resulting in 2 x 2 x 2 x 5 = 40 samples.

I guess, this is a basic three way ANOVA (~ Treatment A * Treatment B * 
Time). However, the arrangement of the replicates in the greenhouse will 
be randomized. I have only a limited understanding of mixed models, 
obviously, but does the randomized location of the plant also requires 
the introduction of a random effect (~ Treatment A * Treatment B * Time 
+ (1|Location)?. How do i best code location in this case?

Thank you!

-- 
Tim Richter-Heitmann

University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From dakotajudo at mac.com  Mon Dec 18 18:31:26 2017
From: dakotajudo at mac.com (Peter Claussen)
Date: Mon, 18 Dec 2017 11:31:26 -0600
Subject: [R-sig-ME] Mixed Models in a very basic replication design
In-Reply-To: <0bcbdfe0-5206-67c5-c6a9-bd65ee765b32@uni-bremen.de>
References: <0bcbdfe0-5206-67c5-c6a9-bd65ee765b32@uni-bremen.de>
Message-ID: <7939CDA2-60B1-4C33-829C-CD995FE45719@mac.com>

Tim,

This is more a question of experimental design, but I can answer a bit relevant to mixed models.

In a greenhouse, environmental variation should be negligible and can typically be ignored. In some cases, the variance is so small that it results in a negative estimate from ANOVA. This is most apparent when you have a Location F-ratio less than 1. Briefly, the F-ratio is calculated with an error variance in the denominator, and that same variance plus another source of variance in the numerator, i.e. (EMS + t*Location MS)/EMS. If the ratio is less than 1, then Location MS must be negative.

If this occurs, and you fit the model using lmer and formula  = ~ Treatment A * Treatment B * Time + (1|Location) , you would expect the estimate of Location to be 0, since it would be constrained to be non-negative. If that happens, you can drop location from the model an fit as a CRD using the three-way ANOVA.

However, you also include time in the model. Is this a repeated measures design? If so, then you might want to fit to a mixed model with Pot (or equivalent) as a random effect.

Cheers,

Peter Claussen
Biometrician
Gylling Data Management, Inc.
Brookings, SD 57006-4605 USA
Tel. No.: +1 605 692-4021
Website: www.gdmdata.com <http://www.gdmdata.com/>

> On Dec 18, 2017, at 9:55 AM, Tim Richter-Heitmann <trichter at uni-bremen.de> wrote:
> 
> Dear Group,
> 
> i am to plan a very basic factorial greenhouse experiment, and this time i will first ask for statistical advise before execution :).
> 
> It will encompass two treatment types with two levels each, two sampling dates with five replicates each, resulting in 2 x 2 x 2 x 5 = 40 samples.
> 
> I guess, this is a basic three way ANOVA (~ Treatment A * Treatment B * Time). However, the arrangement of the replicates in the greenhouse will be randomized. I have only a limited understanding of mixed models, obviously, but does the randomized location of the plant also requires the introduction of a random effect (~ Treatment A * Treatment B * Time + (1|Location)?. How do i best code location in this case?
> 
> Thank you!
> 
> -- 
> Tim Richter-Heitmann
> 
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From rodrigo.corder at usp.br  Sun Dec 17 23:53:24 2017
From: rodrigo.corder at usp.br (Rodrigo Malavazi Corder)
Date: Sun, 17 Dec 2017 20:53:24 -0200
Subject: [R-sig-ME] Package glmmADMB
Message-ID: <CA+i+nCr4=PiTq9KWDmWkwJPQ7acreY65O9M0J=dLQwyX=3UZwg@mail.gmail.com>

Dear,

I am not able to install glmmADMB package. I have already tried different
options, but none of them have worked. Please, find below the error message
from R after trying to install it. May you please help me?

Thank you in advance.

Greetings,
Rodrigo Corder


> install.packages("R2admb")
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
'Couldn't connect to server'
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
'Couldn't connect to server'
Warning in install.packages :
  unable to access index for repository
https://vps.fmvz.usp.br/CRAN/src/contrib:
  cannot download all files
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
'Couldn't connect to server'
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
'Couldn't connect to server'
Warning in install.packages :
  unable to access index for repository
https://vps.fmvz.usp.br/CRAN/src/contrib:
  cannot download all files
Warning in install.packages :
  package ?R2admb? is not available (for R version 3.3.2)
Warning in install.packages :
  URL '
https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES.gz':
status was 'Couldn't connect to server'
Warning in install.packages :
  URL '
https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES':
status was 'Couldn't connect to server'
Warning in install.packages :
  unable to access index for repository
https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3:
  cannot download all files
> install.packages("glmmADMB",
+                  repos=c("http://glmmadmb.r-forge.r-project.org/repos",
+                          getOption("repos")),
+                  type="source")
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
'Couldn't connect to server'
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
'Couldn't connect to server'
Warning in install.packages :
  unable to access index for repository
https://vps.fmvz.usp.br/CRAN/src/contrib:
  cannot download all files
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
'Couldn't connect to server'
Warning in install.packages :
  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
'Couldn't connect to server'
Warning in install.packages :
  unable to access index for repository
https://vps.fmvz.usp.br/CRAN/src/contrib:
  cannot download all files
Warning in install.packages :
  dependency ?R2admb? is not available
trying URL '
http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz
'
Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
==================================================
downloaded 9.0 MB

ERROR: dependency ?R2admb? is not available for package ?glmmADMB?
* removing
?/Library/Frameworks/R.framework/Versions/3.3/Resources/library/glmmADMB?
Warning in install.packages :
  installation of package ?glmmADMB? had non-zero exit status

The downloaded source packages are in

?/private/var/folders/7z/jc6r58_d49l5bgq1xf3k7smw0000gn/T/RtmpkTptDB/downloaded_packages?
> library(glmmADMB)
Error in library(glmmADMB) : there is no package called ?glmmADMB?

	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Mon Dec 18 19:13:39 2017
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Mon, 18 Dec 2017 19:13:39 +0100
Subject: [R-sig-ME] Mixed Models in a very basic replication design
In-Reply-To: <7939CDA2-60B1-4C33-829C-CD995FE45719@mac.com>
References: <0bcbdfe0-5206-67c5-c6a9-bd65ee765b32@uni-bremen.de>
 <7939CDA2-60B1-4C33-829C-CD995FE45719@mac.com>
Message-ID: <e5ac286a-4351-ecfb-3fa0-7dc103b15c76@uni-bremen.de>

Peter,

thank you very much. That was a very elucidating answer.
If i may elaborate on the issue of time a bit more, because i am also a 
bit clueless here.
Will the selection of appropriate modelling approaches be a matter of if 
we disrupt the plants (e.g. harvesting soil) or not (e.g. measuring 
height or surface areas)? Or is it just to account for possibly 
individual intercepts for individual plants?
The plants will be grown from surface-sterilized seeds in homogenized 
starting soils.

Also, how would i encode the factor "Pot"? Just in as many levels as i 
have pots?

Thank you again very much, Tim


On 18.12.2017 18:31, Peter Claussen wrote:
> Tim,
>
> This is more a question of experimental design, but I can answer a bit 
> relevant to mixed models.
>
> In a greenhouse, environmental variation should be negligible and can 
> typically be ignored. In some cases, the variance is so small that it 
> results in a negative estimate from ANOVA. This is most apparent when 
> you have a Location F-ratio less than 1. Briefly, the F-ratio is 
> calculated with an error variance in the denominator, and that same 
> variance plus another source of variance in the numerator, i.e. (EMS + 
> t*Location MS)/EMS. If the ratio is less than 1, then Location MS must 
> be negative.
>
> If this occurs, and you fit the model using lmer and formula ?= ~ 
> Treatment A * Treatment B * Time + (1|Location) , you would expect the 
> estimate of Location to be 0, since it would be constrained to be 
> non-negative. If that happens, you can drop location from the model an 
> fit as a CRD using the three-way ANOVA.
>
> However, you also include time in the model. Is this a repeated 
> measures design? If so, then you might want to fit to a mixed model 
> with Pot (or equivalent) as a random effect.
>
> Cheers,
>
> Peter Claussen
> Biometrician
> Gylling Data Management, Inc.
> Brookings, SD 57006-4605 USA
> Tel. No.: +1 605 692-4021
> Website:www.gdmdata.com <http://www.gdmdata.com/>
>
> 	
>
>> On Dec 18, 2017, at 9:55 AM, Tim Richter-Heitmann 
>> <trichter at uni-bremen.de <mailto:trichter at uni-bremen.de>> wrote:
>>
>> Dear Group,
>>
>> i am to plan a very basic factorial greenhouse experiment, and this 
>> time i will first ask for statistical advise before execution :).
>>
>> It will encompass two treatment types with two levels each, two 
>> sampling dates with five replicates each, resulting in 2 x 2 x 2 x 5 
>> = 40 samples.
>>
>> I guess, this is a basic three way ANOVA (~ Treatment A * Treatment B 
>> * Time). However, the arrangement of the replicates in the greenhouse 
>> will be randomized. I have only a limited understanding of mixed 
>> models, obviously, but does the randomized location of the plant also 
>> requires the introduction of a random effect (~ Treatment A * 
>> Treatment B * Time + (1|Location)?. How do i best code location in 
>> this case?
>>
>> Thank you!
>>
>> -- 
>> Tim Richter-Heitmann
>>
>> University of Bremen
>> Microbial Ecophysiology Group (AG Friedrich)
>> FB02 - Biologie/Chemie
>> Leobener Stra?e (NW2 A2130)
>> D-28359 Bremen
>> Tel.: 0049(0)421 218-63062
>> Fax: 0049(0)421 218-63069
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org 
>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dr. Tim Richter-Heitmann

University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From dakotajudo at mac.com  Mon Dec 18 21:06:54 2017
From: dakotajudo at mac.com (Peter Claussen)
Date: Mon, 18 Dec 2017 14:06:54 -0600
Subject: [R-sig-ME] Mixed Models in a very basic replication design
In-Reply-To: <e5ac286a-4351-ecfb-3fa0-7dc103b15c76@uni-bremen.de>
References: <0bcbdfe0-5206-67c5-c6a9-bd65ee765b32@uni-bremen.de>
 <7939CDA2-60B1-4C33-829C-CD995FE45719@mac.com>
 <e5ac286a-4351-ecfb-3fa0-7dc103b15c76@uni-bremen.de>
Message-ID: <A5663A16-C837-4EDB-A069-BD2B65142B0F@mac.com>

Tim,

There may be many reasons that different pots would respond to treatment uniquely. 

If you plant a number of seeds, will you have 100% germination in each pot? Could differences in percent germination (say, root density) affect soil responses - both in initial measurements (independent intercept) or response over time (independent slope)?

If you have one plant per plot, can you be sure all plants are genetically or physiologically identically, and respond the same to treatments over time? Or do you need to account for the fact that you?re drawing seed from a random population? I had a problem like this years ago, doing a field trial with a soybean variety that was still a segregating population.

How you code ?Pot? depends on how you execute the experiment. If you have 2 levels of A and 2 levels of B, replicated 5 times, then you should have 2*2*5=20  pots, assume the 2 time measurements are take twice from the same pot. Then you could write an ANOVA model of the form

aov( ~  Treatment A * Treatment B * Time + Replicate + Error(Treatment A : Treatment B : Replicate))

 since the combination of A,B and Rep uniquely identify Pot. Otherwise, you could assign a id to each pot. 

Myself, I would run something like

aov( ~  Treatment A * Treatment B * Time + Replicate +  Replicate:Treatment + A:Treatment B)

If (Treatment A * Treatment B * Replicate) not significant, relative to EMS, then I would recalculate using 

aov( ~  Treatment A * Treatment B * Time)

It?s not unreasonable for Replicate effects to be 0, and this analysis would give you a bit more error df and a non-significant test suggests that Treatment A:Treatment B:Replicate MS == EMS, so there is only one error term needed for treatment comparisons.

If (Treatment A * Treatment B * Replicate) is significant, you can?t compare two pairs of comparisons taken from different pots (say, A1B1 at time 2 vs A1B2 at time 2) with the same error term that you use for two pairs of comparisons take from the same pot (A1B1 at time 1 vs A1B1 at time 2). That error is easier to get correct using lme or lmer and (1 | Replicate / Pot). I would run

aov( ~  Treatment A * Treatment B * Time + Replicate + Error(Treatment A : Treatment B : Replicate))

just to get a convenient set of F-test for A and B effects.

If (Treatment A : Treatment B : Time) interaction is significant, then you might consider comparing (1 | Replicate / Pot) vs (Time | Replicate / Pot). You could just code (Time | Pot) from the start, but I tend to be conservative when moving beyond a simple AOV. On the face of it, this appears to be a standard repeated-measures-as-split-plot design, so I would plan for an ANOVA, but allow for a mixed-model approach if the data warrant.

Working on a similar problem, I?m using something like

lme(assessment1 ~ Treatment A * Treatment B * Time, random= ~ 1 | Replicate / Pot)

as the default mixed model repeated-measure-as-split-plot analysis, then comparing to different correlated error models (i.e. correlation=corAR1()). With only 2 time points, you won?t need to worry about correlated errors, but it might be useful if you end up taking more measurements.

One caveat. If you end up with missing pots. then you should most certainly skip the AOV calculations and start with a mixed model.

Cheers,

Peter

> On Dec 18, 2017, at 12:13 PM, Tim Richter-Heitmann <trichter at uni-bremen.de> wrote:
> 
> Peter,
> 
> thank you very much. That was a very elucidating answer.
> If i may elaborate on the issue of time a bit more, because i am also a bit clueless here.
> Will the selection of appropriate modelling approaches be a matter of if we disrupt the plants (e.g. harvesting soil) or not (e.g. measuring height or surface areas)? Or is it just to account for possibly individual intercepts for individual plants?
> The plants will be grown from surface-sterilized seeds in homogenized starting soils.
> 
> Also, how would i encode the factor "Pot"? Just in as many levels as i have pots?
> 
> Thank you again very much, Tim
> 
> 
> On 18.12.2017 18:31, Peter Claussen wrote:
>> Tim,
>> 
>> This is more a question of experimental design, but I can answer a bit relevant to mixed models.
>> 
>> In a greenhouse, environmental variation should be negligible and can typically be ignored. In some cases, the variance is so small that it results in a negative estimate from ANOVA. This is most apparent when you have a Location F-ratio less than 1. Briefly, the F-ratio is calculated with an error variance in the denominator, and that same variance plus another source of variance in the numerator, i.e. (EMS + t*Location MS)/EMS. If the ratio is less than 1, then Location MS must be negative.
>> 
>> If this occurs, and you fit the model using lmer and formula  = ~ Treatment A * Treatment B * Time + (1|Location) , you would expect the estimate of Location to be 0, since it would be constrained to be non-negative. If that happens, you can drop location from the model an fit as a CRD using the three-way ANOVA.
>> 
>> However, you also include time in the model. Is this a repeated measures design? If so, then you might want to fit to a mixed model with Pot (or equivalent) as a random effect.
>> 
>> Cheers,
>> 
>> Peter Claussen
>> Biometrician
>> Gylling Data Management, Inc.
>> Brookings, SD 57006-4605 USA
>> Tel. No.: +1 605 692-4021
>> Website:www.gdmdata.com <http://www.gdmdata.com/> <http://www.gdmdata.com/ <http://www.gdmdata.com/>>
>> 
>> 	
>> 
>>> On Dec 18, 2017, at 9:55 AM, Tim Richter-Heitmann <trichter at uni-bremen.de <mailto:trichter at uni-bremen.de> <mailto:trichter at uni-bremen.de <mailto:trichter at uni-bremen.de>>> wrote:
>>> 
>>> Dear Group,
>>> 
>>> i am to plan a very basic factorial greenhouse experiment, and this time i will first ask for statistical advise before execution :).
>>> 
>>> It will encompass two treatment types with two levels each, two sampling dates with five replicates each, resulting in 2 x 2 x 2 x 5 = 40 samples.
>>> 
>>> I guess, this is a basic three way ANOVA (~ Treatment A * Treatment B * Time). However, the arrangement of the replicates in the greenhouse will be randomized. I have only a limited understanding of mixed models, obviously, but does the randomized location of the plant also requires the introduction of a random effect (~ Treatment A * Treatment B * Time + (1|Location)?. How do i best code location in this case?
>>> 
>>> Thank you!
>>> 
>>> -- 
>>> Tim Richter-Heitmann
>>> 
>>> University of Bremen
>>> Microbial Ecophysiology Group (AG Friedrich)
>>> FB02 - Biologie/Chemie
>>> Leobener Stra?e (NW2 A2130)
>>> D-28359 Bremen
>>> Tel.: 0049(0)421 218-63062
>>> Fax: 0049(0)421 218-63069
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> 
> 
> -- 
> Dr. Tim Richter-Heitmann
> 
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069


	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Tue Dec 19 13:47:52 2017
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 19 Dec 2017 12:47:52 +0000
Subject: [R-sig-ME] Package glmmADMB
In-Reply-To: <CA+i+nCr4=PiTq9KWDmWkwJPQ7acreY65O9M0J=dLQwyX=3UZwg@mail.gmail.com>
References: <CA+i+nCr4=PiTq9KWDmWkwJPQ7acreY65O9M0J=dLQwyX=3UZwg@mail.gmail.com>
Message-ID: <24D12F7F-847C-49B1-8194-0036A7895340@glasgow.ac.uk>

Have you tried the glmmTMB package? I understand that Ben Bolker et al. are developing it as a replacement for glmmADMB. I?ve found it to be flexible*, robust, and very fast, much faster than glmmADMB (which I found unusable on large data sets), but sometimes even faster than glmer**. I?ve never had reason to use glmmADMB since finding glmmTMB. However watch out for differences between glmmTMB and glmer etc ? read the Details of the glmmTMB help. There are occasional issues as expected in a new-ish package, but the developers are very active and these tend to be dealt with quickly. On the whole this is already an extremely really useful package, mainly because it can quickly fit complex (= beyond glmer) GLMMs to large data sets where glmmADMB would fail or at best take hours (a huge thank you to the developers).

*https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf
"--Poisson, binomial, negative binomial (NB1 and NB2 parameterizations), Gamma, Beta, Gaussian; truncated Poisson and negative binomial
--zero-inflation with fixed and random-effects components; hurdle models via truncated Poisson/NB
--diagonal, compound-symmetric, or unstructured random effects variance-covariance matrices; first-order autoregressive (AR1) variance structures"

**E.g. binomial GLMM fitted to ~70K binary obs (of which ~700 are 1s) with 25 fixed effects and 2 crossed random effects (on an old Mac with 2.7 GHz Intel Core i7):
glmmTMB: 2.9 min
glmer: 29.4 min, but still didn?t *quite* converge (even with 'optimizer = "bobyqa"', which often helps). Log-likelihood 0.1 units below glmmTMB, so very close, and the estimates were very similar. Also I find that convergence warnings in glmer and glmer.nb are more sensitive than in glmmTMB.


> On 17 Dec 2017, at 22:53, Rodrigo Malavazi Corder <rodrigo.corder at usp.br> wrote:
> 
> Dear,
> 
> I am not able to install glmmADMB package. I have already tried different
> options, but none of them have worked. Please, find below the error message
> from R after trying to install it. May you please help me?
> 
> Thank you in advance.
> 
> Greetings,
> Rodrigo Corder
> 
> 
>> install.packages("R2admb")
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  unable to access index for repository
> https://vps.fmvz.usp.br/CRAN/src/contrib:
>  cannot download all files
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  unable to access index for repository
> https://vps.fmvz.usp.br/CRAN/src/contrib:
>  cannot download all files
> Warning in install.packages :
>  package ?R2admb? is not available (for R version 3.3.2)
> Warning in install.packages :
>  URL '
> https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES.gz':
> status was 'Couldn't connect to server'
> Warning in install.packages :
>  URL '
> https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES':
> status was 'Couldn't connect to server'
> Warning in install.packages :
>  unable to access index for repository
> https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3:
>  cannot download all files
>> install.packages("glmmADMB",
> +                  repos=c("http://glmmadmb.r-forge.r-project.org/repos",
> +                          getOption("repos")),
> +                  type="source")
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  unable to access index for repository
> https://vps.fmvz.usp.br/CRAN/src/contrib:
>  cannot download all files
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES.gz': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  URL 'https://vps.fmvz.usp.br/CRAN/src/contrib/PACKAGES': status was
> 'Couldn't connect to server'
> Warning in install.packages :
>  unable to access index for repository
> https://vps.fmvz.usp.br/CRAN/src/contrib:
>  cannot download all files
> Warning in install.packages :
>  dependency ?R2admb? is not available
> trying URL '
> http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz
> '
> Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
> ==================================================
> downloaded 9.0 MB
> 
> ERROR: dependency ?R2admb? is not available for package ?glmmADMB?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.3/Resources/library/glmmADMB?
> Warning in install.packages :
>  installation of package ?glmmADMB? had non-zero exit status
> 
> The downloaded source packages are in
> 
> ?/private/var/folders/7z/jc6r58_d49l5bgq1xf3k7smw0000gn/T/RtmpkTptDB/downloaded_packages?
>> library(glmmADMB)
> Error in library(glmmADMB) : there is no package called ?glmmADMB?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From walidmawass10 at gmail.com  Tue Dec 19 17:26:41 2017
From: walidmawass10 at gmail.com (Walid Mawass)
Date: Tue, 19 Dec 2017 11:26:41 -0500
Subject: [R-sig-ME] indirect maternal genetic effects
Message-ID: <de994891-577f-4aec-1994-e89b8279d17e@gmail.com>

Hello everyone,

I am trying to model direct genetic effects and indirect maternal 
genetic effects on infant survival, using MCMCglmm. From what I know and 
understood from the ASReml code on how to model this, I should include 
the identity of my focal individual ("animal") to estimate the direct 
genetic effect, include the identity of his mother ("dam") to estimate 
the maternal environment effect and then add another variable which 
should represent the genetic effect of the mother on the focal 
individual. I assumed that I should add the same "dam" variable but give 
it its own incidence matrix through ginverse(), but I am not sure about 
this. I would appreciate some help on how to code this relationship.

Thank you

-- 
Walid Mawass

M.Sc. of Cellular and Molecular Biology

Population Genetics Laboratory

University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


From silvia.matesanzgarcia at gmail.com  Wed Dec 20 11:06:26 2017
From: silvia.matesanzgarcia at gmail.com (=?iso-8859-1?Q?Silvia_Matesanz_Garc=EDa?=)
Date: Wed, 20 Dec 2017 11:06:26 +0100
Subject: [R-sig-ME] Significance of fixed factors using glmer
Message-ID: <003301d3797a$33014a90$9903dfb0$@gmail.com>

Hi all

I?m fitting a model where the response variable is Flowering (0, the plant
didn?t flower; 1, the plant did flower). I?m using glmer with a binomial
distribution. I?m trying to obtain the significance of fixed factors. I?ve
tried lmerTest:anova and car:Anova but neither seem to provide p-values. 

Is there a way to do this? 

 

Thanks!

 

----------------------------------------------------------------------------
-------

Dra. Silvia Matesanz 

Investigadora Ram?n y Cajal. 

?rea de Biodiversidad y Conservaci?n. 

Universidad Rey Juan Carlos

 <http://silviamatesanzgarc.wix.com/silviamatesanz>
http://silviamatesanzgarc.wix.com/silviamatesanz

 <https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es>
https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es 




	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Dec 20 15:43:40 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 20 Dec 2017 14:43:40 +0000
Subject: [R-sig-ME] Significance of fixed factors using glmer
In-Reply-To: <9191_1513780495_vBKEYtCT023959_003301d3797a$33014a90$9903dfb0$@gmail.com>
References: <9191_1513780495_vBKEYtCT023959_003301d3797a$33014a90$9903dfb0$@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836739AD9@FHSDB4H16-2.csu.mcmaster.ca>

Dear Silvia,

Both lmerTest::anova() and car::Anova() print p-values, so you'll have to provide more information -- ideally a reproducible example demonstrating the problem, or at least the problematic output with p-values absent.

Best,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Silvia Matesanz Garc?a
> Sent: Wednesday, December 20, 2017 5:06 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Significance of fixed factors using glmer
> 
> Hi all
> 
> I m fitting a model where the response variable is Flowering (0, the plant didn t
> flower; 1, the plant did flower). I m using glmer with a binomial distribution. I
> m trying to obtain the significance of fixed factors. I ve tried lmerTest:anova
> and car:Anova but neither seem to provide p-values.
> 
> Is there a way to do this?
> 
> 
> 
> Thanks!
> 
> 
> 
> ----------------------------------------------------------------------------
> -------
> 
> Dra. Silvia Matesanz
> 
> Investigadora Ram n y Cajal.
> 
>  rea de Biodiversidad y Conservaci n.
> 
> Universidad Rey Juan Carlos
> 
>  <http://silviamatesanzgarc.wix.com/silviamatesanz>
> http://silviamatesanzgarc.wix.com/silviamatesanz
> 
>  <https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es>
> https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]


From stw at ipipan.waw.pl  Wed Dec 20 22:05:45 2017
From: stw at ipipan.waw.pl (Slawomir Wierzchon)
Date: Wed, 20 Dec 2017 22:05:45 +0100
Subject: [R-sig-ME] repeated measurements of continuous predictors and
 continuous response variable
Message-ID: <CAMMrp0Xzwa5h5TRZw8_f-hQf1Fq0rry1r9d2U1=hMGJMKqtBEQ@mail.gmail.com>

Dear all,

I would greatly appreciate receiving serious and exhaustive answer to the
next question:

My data consist of one response variable and three predictors, say

Id           y                     x1              x2           x3
1    2,29757646    1,522746484    6,1504    1,81651712
1    2,460906175    2,072253268    7,0467    1,952559422
1    2,561146752    1,69296991    4,8555    1,580112083
2    2,542671567    1,419124506    11,5181    2,443919711
2    2,47840973    1,254903533    10,2239    2,324728117
3    2,409638554    2,168676486    14,7873    2,693768704
4    2,577905082    2,290613721    22,1847    3,099402862
4    2,771908643    1,98419636    18,5161    2,918640624
5    2,137096774    1,166644699    5,1028    1,629789409

Thus there are repeated measurements, and each item (Id) has been subjected
to a diverse number of measurements. I?m interested in finding linear
relationship y = a0 + a1*x1 + a2*x2 + a3*x3.

My questions are:

(a) Can I use complete pooling to solve my problem, i.e. simply can I use
lm(y ~x1+x2+x3)? Or should I use lmer routine? If so, is it sufficient to
call it as lmer(y ~ x1+x2+x3 + (1|Id)?

(b)  How can I apply Friedman's ?Multivariate Adaptive Regression Splines?
to such problems? That is I'm looking for an R package solving such
problems.

Best regards,
Slawomir

	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Thu Dec 21 03:28:15 2017
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Thu, 21 Dec 2017 02:28:15 +0000
Subject: [R-sig-ME] repeated measurements of continuous predictors and
 continuous response variable
In-Reply-To: <CAMMrp0Xzwa5h5TRZw8_f-hQf1Fq0rry1r9d2U1=hMGJMKqtBEQ@mail.gmail.com>
References: <CAMMrp0Xzwa5h5TRZw8_f-hQf1Fq0rry1r9d2U1=hMGJMKqtBEQ@mail.gmail.com>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D49FEDC2CC@EXCH06S.adqimr.ad.lan>


> (a) should I use lmer routine? 
Yes
> If so, is it sufficient to call it as lmer(y ~ x1+x2+x3 + (1|Id)?
As a start
> (b)  How can I apply Friedman's ?Multivariate Adaptive Regression Splines?
> to such problems? That is I'm looking for an R package solving such
> problems.
Consider GAMMs eg
library(mgcv)
gamm( y ~ te(x1,x2,x3), list(Id=~1))

From stw at ipipan.waw.pl  Thu Dec 21 07:05:44 2017
From: stw at ipipan.waw.pl (Slawomir Wierzchon)
Date: Thu, 21 Dec 2017 07:05:44 +0100
Subject: [R-sig-ME] repeated measurements of continuous predictors and
 continuous response variable
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D49FEDC2CC@EXCH06S.adqimr.ad.lan>
References: <CAMMrp0Xzwa5h5TRZw8_f-hQf1Fq0rry1r9d2U1=hMGJMKqtBEQ@mail.gmail.com>
 <4737E17E7C8C3C4A8B5C1CE5346371D49FEDC2CC@EXCH06S.adqimr.ad.lan>
Message-ID: <CAMMrp0Xnzk-QBvpASToa4CrTAd0_tv24XpwutHcjogMS-Vecbg@mail.gmail.com>

Thanks!

21 gru 2017 03:28 "David Duffy" <David.Duffy at qimrberghofer.edu.au>
napisa?(a):

>
> > (a) should I use lmer routine?
> Yes
> > If so, is it sufficient to call it as lmer(y ~ x1+x2+x3 + (1|Id)?
> As a start
> > (b)  How can I apply Friedman's ?Multivariate Adaptive Regression
> Splines?
> > to such problems? That is I'm looking for an R package solving such
> > problems.
> Consider GAMMs eg
> library(mgcv)
> gamm( y ~ te(x1,x2,x3), list(Id=~1))

	[[alternative HTML version deleted]]


From juliachacon at gmail.com  Thu Dec 21 11:03:20 2017
From: juliachacon at gmail.com (Julia Chacon Labella)
Date: Thu, 21 Dec 2017 11:03:20 +0100
Subject: [R-sig-ME] Significance of fixed factors using glmer
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836739AD9@FHSDB4H16-2.csu.mcmaster.ca>
References: <9191_1513780495_vBKEYtCT023959_003301d3797a$33014a90$9903dfb0$@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836739AD9@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <CAPsE2jyWoc+58g0ubc7+vewbDVXpcNNMk7rZXQ580iK7gnbAQA@mail.gmail.com>

Hi Silvia,

If you have previously loaded other packages like afex package, then
lmerTest cannot work properly and does not give you the p-values.
Try to detach the other packages if it is the case, and let see if it works
now.

Example: detach("package:afex", unload=TRUE)

Or...you can restart your R session and load only the packages you need.
But I would try detach first.

Hope it works!
Julia


2017-12-20 15:43 GMT+01:00 Fox, John <jfox at mcmaster.ca>:

> Dear Silvia,
>
> Both lmerTest::anova() and car::Anova() print p-values, so you'll have to
> provide more information -- ideally a reproducible example demonstrating
> the problem, or at least the problematic output with p-values absent.
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
>
>
>
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-
> bounces at r-project.org]
> > On Behalf Of Silvia Matesanz Garc?a
> > Sent: Wednesday, December 20, 2017 5:06 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Significance of fixed factors using glmer
> >
> > Hi all
> >
> > I m fitting a model where the response variable is Flowering (0, the
> plant didn t
> > flower; 1, the plant did flower). I m using glmer with a binomial
> distribution. I
> > m trying to obtain the significance of fixed factors. I ve tried
> lmerTest:anova
> > and car:Anova but neither seem to provide p-values.
> >
> > Is there a way to do this?
> >
> >
> >
> > Thanks!
> >
> >
> >
> > ------------------------------------------------------------
> ----------------
> > -------
> >
> > Dra. Silvia Matesanz
> >
> > Investigadora Ram n y Cajal.
> >
> >  rea de Biodiversidad y Conservaci n.
> >
> > Universidad Rey Juan Carlos
> >
> >  <http://silviamatesanzgarc.wix.com/silviamatesanz>
> > http://silviamatesanzgarc.wix.com/silviamatesanz
> >
> >  <https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es>
> > https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
Julia

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Dec 21 14:28:56 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 21 Dec 2017 13:28:56 +0000
Subject: [R-sig-ME] indirect maternal genetic effects
In-Reply-To: <de994891-577f-4aec-1994-e89b8279d17e@gmail.com>
References: <de994891-577f-4aec-1994-e89b8279d17e@gmail.com>
Message-ID: <27ccc648-569f-d88b-7cd0-db81d88572c9@ed.ac.uk>

Hi,

You are correct. You are need to associate the inverse with both terms:

invA<-inverseA(ped)$Ainv


m1<-MCMCglmm(..., random=~dam+animal, ginverse=list(animal=invA, dam=invA),  ...)

if you want to estimate the direct-maternal genetic covariance you need:


m2<-MCMCglmm(..., random=~str(dam+animal), ginverse=list(animal=invA, dam=invA),  ...)

Cheers,

Jarrod
  


On 19/12/2017 16:26, Walid Mawass wrote:
> Hello everyone,
>
> I am trying to model direct genetic effects and indirect maternal 
> genetic effects on infant survival, using MCMCglmm. From what I know 
> and understood from the ASReml code on how to model this, I should 
> include the identity of my focal individual ("animal") to estimate the 
> direct genetic effect, include the identity of his mother ("dam") to 
> estimate the maternal environment effect and then add another variable 
> which should represent the genetic effect of the mother on the focal 
> individual. I assumed that I should add the same "dam" variable but 
> give it its own incidence matrix through ginverse(), but I am not sure 
> about this. I would appreciate some help on how to code this 
> relationship.
>
> Thank you
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20171221/8d35b1bc/attachment.ksh>

From jmichaelrosenberg at gmail.com  Thu Dec 21 15:51:43 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Thu, 21 Dec 2017 09:51:43 -0500
Subject: [R-sig-ME] Use of pbkrtest to calculate Kenward-Roger approximated
	degrees of freedom
Message-ID: <CANYHYTSYWoRidNFc+OzCFeHtKdZpWJmMPzg7b5O4SjQbxbKY5Q@mail.gmail.com>

Hi everyone,

I'm trying to use the pbkrtest package to calculate Kenward-Roger
approximation degrees of freedom for fixed effects coefficients estimated
using the lmer() function from the lme4 package.

I've been able to use, for example, the function pbkrtest::get_Lb_ddf().
Here is how I am using it:

library(lme4)
library(pbkrtest)
fm1 <- lmer(Reaction ~ Days + (Days| Subject), sleepstudy)
get_Lb_ddf(fm1, lme4::fixef(fm1))


My understanding is that this function returns the "denominator degrees of
freedom," which, if I understand correctly, apply to the *overall model*,
rather to specific coefficients, in part because get_Lb_ddf() returns a
single value whether there are coefficients associated with zero, one, or
more than one predictors. I

'm sorry if this is a novice question with respect to calculating degrees
of freedom in general (and calculating them with this, Kenward-Roger,
approach)! Thanks for any thoughts or suggestions for how to think about
calculating degrees of freedom using this - or another, better - approach.

Josh


-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
&
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Dec 21 15:01:39 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Dec 2017 09:01:39 -0500
Subject: [R-sig-ME] Significance of fixed factors using glmer
In-Reply-To: <CAPsE2jyWoc+58g0ubc7+vewbDVXpcNNMk7rZXQ580iK7gnbAQA@mail.gmail.com>
References: <9191_1513780495_vBKEYtCT023959_003301d3797a$33014a90$9903dfb0$@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836739AD9@FHSDB4H16-2.csu.mcmaster.ca>
 <CAPsE2jyWoc+58g0ubc7+vewbDVXpcNNMk7rZXQ580iK7gnbAQA@mail.gmail.com>
Message-ID: <CABghstTeWV+9DcsKPKhPcM=kM7s0j=qs85PXLG52Fog=Kp5upg@mail.gmail.com>

Julia: that's interesting, but can you be more specific? I *never* get
p-values with a single-argument anova(),
but I do get p-values with car::Anova or other methods suggested below:

[1] lmerTest_2.0-36 afex_0.18-0     lsmeans_2.27-61 lme4_1.1-15
[5] Matrix_1.2-12

  Suggestions for improving the text in ?lme4::pvalues will be warmly
appreciated.

  cheers
   Ben Bolker




library(afex)
library(lmerTest)
library(car)
data("cbpp",package="lme4")
g1 <- glmer(cbind(incidence, size-incidence) ~ period + (1|herd),
    family=binomial,data=cbpp)
lme4:::anova.merMod(g1) ## no p-values
anova(g1)  ## from lmerTest: no p-values
find("anova")
## [1] "package:lmerTest" "package:stats"
summary(g1) ## Wald p-values
Anova(g1)  ## Wald (type II) p-values
drop1(g1,test="Chisq")
mixed(cbind(incidence, size-incidence) ~ period + (1|herd),
      family=binomial,data=cbpp, method="LRT")
sessionInfo()




On Thu, Dec 21, 2017 at 5:03 AM, Julia Chacon Labella
<juliachacon at gmail.com> wrote:
> Hi Silvia,
>
> If you have previously loaded other packages like afex package, then
> lmerTest cannot work properly and does not give you the p-values.
> Try to detach the other packages if it is the case, and let see if it works
> now.
>
> Example: detach("package:afex", unload=TRUE)
>
> Or...you can restart your R session and load only the packages you need.
> But I would try detach first.
>
> Hope it works!
> Julia
>
>
> 2017-12-20 15:43 GMT+01:00 Fox, John <jfox at mcmaster.ca>:
>
>> Dear Silvia,
>>
>> Both lmerTest::anova() and car::Anova() print p-values, so you'll have to
>> provide more information -- ideally a reproducible example demonstrating
>> the problem, or at least the problematic output with p-values absent.
>>
>> Best,
>>  John
>>
>> -----------------------------
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: socialsciences.mcmaster.ca/jfox/
>>
>>
>>
>> > -----Original Message-----
>> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-
>> bounces at r-project.org]
>> > On Behalf Of Silvia Matesanz Garc?a
>> > Sent: Wednesday, December 20, 2017 5:06 AM
>> > To: r-sig-mixed-models at r-project.org
>> > Subject: [R-sig-ME] Significance of fixed factors using glmer
>> >
>> > Hi all
>> >
>> > I m fitting a model where the response variable is Flowering (0, the
>> plant didn t
>> > flower; 1, the plant did flower). I m using glmer with a binomial
>> distribution. I
>> > m trying to obtain the significance of fixed factors. I ve tried
>> lmerTest:anova
>> > and car:Anova but neither seem to provide p-values.
>> >
>> > Is there a way to do this?
>> >
>> >
>> >
>> > Thanks!
>> >
>> >
>> >
>> > ------------------------------------------------------------
>> ----------------
>> > -------
>> >
>> > Dra. Silvia Matesanz
>> >
>> > Investigadora Ram n y Cajal.
>> >
>> >  rea de Biodiversidad y Conservaci n.
>> >
>> > Universidad Rey Juan Carlos
>> >
>> >  <http://silviamatesanzgarc.wix.com/silviamatesanz>
>> > http://silviamatesanzgarc.wix.com/silviamatesanz
>> >
>> >  <https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es>
>> > https://scholar.google.es/citations?user=6xRDyPAAAAAJ&hl=es
>> >
>> >
>> >
>> >
>> >       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> Julia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From s.wierzchon at gmail.com  Tue Dec 19 19:35:47 2017
From: s.wierzchon at gmail.com (Slawomir Wierzchon)
Date: Tue, 19 Dec 2017 19:35:47 +0100
Subject: [R-sig-ME] repeated measurements of continuous predictors and
 continuous response variable
Message-ID: <CAMMrp0XVYORjTzU9dNhq6rsahYxn0nn0X6_AwS2AAs699tjqhg@mail.gmail.com>

Dear all,

I would greatly appreciate receiving exhaustive answer to the next question:

My data consist of one response variable and three predictors, say

Id           y                     x1              x2           x3
1    2,29757646    1,522746484    6,1504    1,81651712
1    2,460906175    2,072253268    7,0467    1,952559422
1    2,561146752    1,69296991    4,8555    1,580112083
2    2,542671567    1,419124506    11,5181    2,443919711
2    2,47840973    1,254903533    10,2239    2,324728117
3    2,409638554    2,168676486    14,7873    2,693768704
4    2,577905082    2,290613721    22,1847    3,099402862
4    2,771908643    1,98419636    18,5161    2,918640624
5    2,137096774    1,166644699    5,1028    1,629789409

Thus there are repeated measurements, and each item (Id) has been subjected
to a diverse number of measurements. I?m interested in finding linear
relationship y = a0 + a1*x1 + a2*x2 + a3*x3.

My questions are:

(a) Can I use complete pooling (i.e. ignore Id?s) to solve my problem? Or
should I use lmer routine? If so, is it sufficient to call it as lmer(y ~
x1+x2+x3 + (1|Id)?

(b)  How can I apply Friedman's ?Multivariate Adaptive Regression Splines?
to such problems? That is I'm looking for an R package solving such
problems.

Best regards,

Slawomir

	[[alternative HTML version deleted]]


From sivakoff.3 at osu.edu  Tue Dec 19 21:42:22 2017
From: sivakoff.3 at osu.edu (Sivakoff, Frances)
Date: Tue, 19 Dec 2017 20:42:22 +0000
Subject: [R-sig-ME] Plotting partial residuals from a glmmADMB model
In-Reply-To: <CABghstRC62tAe7bRVMAGt05Piy6kUXweqKSAKkMsJje9fFvaNw@mail.gmail.com>
References: <DAB16A0903A9474491F9134DDC566BC873E5E245@CIO-TNC-D2MBX06.osuad.osu.edu>
 <CABghstRC62tAe7bRVMAGt05Piy6kUXweqKSAKkMsJje9fFvaNw@mail.gmail.com>
Message-ID: <DAB16A0903A9474491F9134DDC566BC873E63F47@CIO-TNC-D2MBX06.osuad.osu.edu>

Dear Dr. Bolker,
 Thank you very much for your response. After trying to implement your suggestion, I'm unfortunately stuck. It appears that the getME function does not work with glmmADMB. I get the following error message:

Error in UseMethod("getME") : 
  no applicable method for 'getME' applied to an object of class "glmmadmb"

A potential work around to this may be to use the "predict" function, which can generate the components, but I'm not sure if this is equivalent. Also, I'm having trouble following the steps that you outlined in your email to generate the partial residuals. Would you be willing to work through how to generate the partial residuals for the fixed effect "FoodTreatment" in the model below that uses the Owl data set?

 ##Using the Owl Data
om <- glmmadmb(SiblingNegotiation~FoodTreatment+ArrivalTime+SexParent+ (1|Nest),family="nbinom1",data=Owls)

Thank you,
Frances

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Thursday, December 14, 2017 9:54 PM
To: Sivakoff, Frances <sivakoff.3 at osu.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Plotting partial residuals from a glmmADMB model

You'll have to find a way to make "partial predictions". I don't think there's anything built in for this.  *Very* briefly, considering only fixed effects, if you retrieve the X matrix
(getME(fitted_model,"X")) and the fixed-effect parameters (fixef(fitted_model)), you can drop any columns/parameters you want and do exp(X %*% beta) with the remaining columns/parameters to get a prediction that includes some but not all of the predictors. Subtracting the observed value should get you the partial residuals ...


On Tue, Dec 12, 2017 at 2:19 PM, Sivakoff, Frances <sivakoff.3 at osu.edu> wrote:
> I would like to use ggplot2 to plot the partial residuals of an indicator (0 or 1) independent variable in a generalized linear mixed model fit with a "nbinom1" family using glmmadmb. My model has a response variable that is a count, 3 explanatory variables that are continuous, and 7 indicator variables that are 0 when a particular heavy metal is not detected and 1 when it is detected above a threshold value. I'd like to plot the partial residuals of the various independent variables. I think that the model below using the Owl data would be a good example data set for how to do this. The model below has a response variable that is a count, an explanatory variables that is continuous (arrivalTime), two categorical variables (FoodTreatment and SexParent), a random effect of Nest, and uses a "nbinom1" family.
>
> ##Using the Owl Data
> om <- glmmadmb(SiblingNegotiation~FoodTreatment+ArrivalTime+SexParent+
>                  (1|Nest),family="nbinom1",data=Owls)
>
> Could you please suggest a method for plotting the partial residuals of the explanatory variables.
>
> Thank you,
> Frances
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From jrosen at msu.edu  Wed Dec 20 23:10:11 2017
From: jrosen at msu.edu (Joshua Rosenberg)
Date: Wed, 20 Dec 2017 17:10:11 -0500
Subject: [R-sig-ME] Use of pbkrtest to calculate Kenward-Roger approximation
	degrees of freedom
Message-ID: <CANYHYTRYFuMDv=xTt7pPOnqGZR5vpfdXW-jouhrHfuWo4xwj9Q@mail.gmail.com>

Hi R-sig-mixed-models,

I'm trying to use the pbkrtest package to calculate Kenward-Roger
approximation degrees of freedom for fixed effects coefficients estimated
using the lmer() function from the lme4 package.

I've been able to use, for example, the function pbkrtest::get_Lb_ddf().
Here is how I am using it:

library(lme4)
library(pbkrtest)
fm1 <- lmer(Reaction ~ Days + (Days| Subject), sleepstudy)
get_Lb_ddf(fm1, lme4::fixef(fm1))

My understanding is that this function returns the "
denominator degrees of freedom
," which, if I understand correctly, apply to the *overall model*, rather
to specific coefficients, in part because get_Lb_ddf() returns a single
value whether there are coefficients associated with zero, one, or more
than one predictors. I'm sorry if this is a novice question with respect to
calculating degrees of freedom in general (and calculating them with this,
Kenward-Roger, approach).

Any advice pointing me in the right direction is much appreciated.

Josh

-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology & Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Tue Dec 26 17:38:05 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Tue, 26 Dec 2017 16:38:05 +0000
Subject: [R-sig-ME] Use of pbkrtest to calculate Kenward-Roger
 approximated degrees of freedom
In-Reply-To: <CANYHYTSYWoRidNFc+OzCFeHtKdZpWJmMPzg7b5O4SjQbxbKY5Q@mail.gmail.com>
References: <CANYHYTSYWoRidNFc+OzCFeHtKdZpWJmMPzg7b5O4SjQbxbKY5Q@mail.gmail.com>
Message-ID: <CANYHYTQUygGRXws+o=EStzZLj99f9VNTpNdK9srbVJwNOatJng@mail.gmail.com>

Hi all, in case any others find this useful, here's the approach I've
pursued, borrowing from the source code for the summary() method function
in lmerTest:

library(purrr)
library(lme4)
library(pbkrtest)

fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)

get_kr_df <- function(model_object) {
    L <- diag(rep(1, length(fixef(model_object))))
    L <- as.data.frame(L)
    out <- purrr::map_dbl(L, pbkrtest::get_Lb_ddf, object = model_object)
    names(out) <- names(fixef(model_object))
    out
}

get_kr_df(m1)

On Thu, Dec 21, 2017 at 9:51 AM Joshua Rosenberg <
jmichaelrosenberg at gmail.com> wrote:

> Hi everyone,
>
> I'm trying to use the pbkrtest package to calculate Kenward-Roger
> approximation degrees of freedom for fixed effects coefficients estimated
> using the lmer() function from the lme4 package.
>
> I've been able to use, for example, the function pbkrtest::get_Lb_ddf().
> Here is how I am using it:
>
> library(lme4)
> library(pbkrtest)
> fm1 <- lmer(Reaction ~ Days + (Days| Subject), sleepstudy)
> get_Lb_ddf(fm1, lme4::fixef(fm1))
>
>
> My understanding is that this function returns the "denominator degrees of
> freedom," which, if I understand correctly, apply to the *overall model*,
> rather to specific coefficients, in part because get_Lb_ddf() returns a
> single value whether there are coefficients associated with zero, one, or
> more than one predictors. I
>
> 'm sorry if this is a novice question with respect to calculating degrees
> of freedom in general (and calculating them with this, Kenward-Roger,
> approach)! Thanks for any thoughts or suggestions for how to think about
> calculating degrees of freedom using this - or another, better - approach.
>
> Josh
>
>
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology
> &
>  Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


