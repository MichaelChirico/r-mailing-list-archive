From bbo|ker @end|ng |rom gm@||@com  Tue Apr  4 15:47:18 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 4 Apr 2023 09:47:18 -0400
Subject: [R-sig-ME] 
 Mixed models with a dichotomous outcome, random slopes,
 and accounting for autocorrelation
In-Reply-To: <CABDmvJ9xQgV+zr31OZE9WcRdXnRTWeKRfvccuLUQhipErxr0CQ@mail.gmail.com>
References: <CABDmvJ9xQgV+zr31OZE9WcRdXnRTWeKRfvccuLUQhipErxr0CQ@mail.gmail.com>
Message-ID: <4822b960-ba6f-b8ff-d8b9-5ccd6db46e51@gmail.com>

  This seems to have slipped through the cracks, sorry about that.

  lme4 doesn't do correlation structures, but glmmTMB does. The closest 
analogue would be something like

## this should be observation number within group
dat$times <- numFactor(dat$times)

model2 <- glmmTMB(continuous_outcome ~ 1 + Predictor_X + Day +
    (1 + Day | Team / Year) + ar1(times + 0 | Team:Year)

  (your random effect has two | in it; was the second meant to be a / ?)

See https://glmmtmb.github.io/glmmTMB/articles/covstruct.html

On 2023-01-25 5:13 p.m., Adam Roebuck wrote:
> Hello,
> 
> I am attempting to set up a multilevel model with two grouping variables
> (team and year), random slopes for day of the year, and accounting for
> autocorrelation. I have a number of different outcome variables I can use.
> When the outcome variable is continuous, I can set up a simple growth model
> using the nlme package that looks something like the following:
> 
> model1 <- lme(continuous_outcome ~ 1 + Predictor_X + Day,
> 
> random = ~1 + Day | Team | Year, data = dat, method = "REML",
> 
> control=list(opt="optim"), correlation = corAR1()
> 
> However, I now want to build a model with a dichotomous outcome variable.
> As far as I know, nlme cannot account for all of the above and a
> dichotomous outcome. I have, however, seen a few references to glmer (in
> the lme4 package) and glmmTMB being capable of such. I've gone back through
> the archives, though, and am not seeing any clear explanations on how to
> set up such a model.
> 
> Using the parameters above and the variables I specified, could someone
> please help specify what that model might look like in R or at least point
> me in the right direction?
> 
> Thanks,
> Adam
> 




-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From bbo|ker @end|ng |rom gm@||@com  Tue Apr  4 20:06:08 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 4 Apr 2023 14:06:08 -0400
Subject: [R-sig-ME] 
 Mixed models with a dichotomous outcome, random slopes,
 and accounting for autocorrelation
In-Reply-To: <CABDmvJ_xzwmCrpX66aR6XDVFuwp1oT3zB1W6-vdsyhjE=R1YyA@mail.gmail.com>
References: <CABDmvJ9xQgV+zr31OZE9WcRdXnRTWeKRfvccuLUQhipErxr0CQ@mail.gmail.com>
 <4822b960-ba6f-b8ff-d8b9-5ccd6db46e51@gmail.com>
 <CABDmvJ_xzwmCrpX66aR6XDVFuwp1oT3zB1W6-vdsyhjE=R1YyA@mail.gmail.com>
Message-ID: <38916073-81ea-b12b-db7c-a6098428b27d@gmail.com>

   [adding r-sig-mixed back to the cc: list]

   This looks mostly right. The only thing you have to watch out for is 
that you want `linear_time` to be *numeric* for the fixed-effect model 
but numFactor()-ized for the ar1() term.  So

dat$linear_time_f <- numFactor(dat$linear_time)

so as not to mess up the original variable, then use linear_time_f 
within ar1().

On 2023-04-04 1:59 p.m., Adam Roebuck wrote:
> Hi again Professor Bolker,
> 
> Thank you kindly for taking the time to respond and even follow up on my 
> original question.
> 
> My original?post to the listserv was actually asking about a different 
> project where I had three levels ? day, team, and year ? without 
> cross-classification. However, my curiosity?about handling 
> auto-correlation applies to that project and this new one with 
> cross-classification.
> 
> The new project has a cross-classification of (a) ego and (b) alter 
> nested within a higher level team. Ratings of ego and alter are captured 
> over time, hence the desire to account for auto-correlation. 
> Extrapolating from your email, then, I am guessing the base model would 
> look something like the following:
> 
> dat$linear_time <- numFactor(dat$linear_time)
> 
> mod <- glmmTMB(continuous_outcome ~ 1 + linear_time + Predictor_X +
>  ? ? (1|ego) + (1|alter) + (1|team) +?ar1(linear_time + 0 | ego:alter)
> 
> Does that seem to track?
> 
> Any additional information would be above and beyond, though highly 
> appreciated.
> 
> Thanks again for the reply and for all you have done for mixed-level 
> modeling.
> 
> My best,
> Adam
> 
> On Tue, Apr 4, 2023 at 9:47?AM Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>> wrote:
> 
>     *Message sent from a system outside of UConn.*
> 
> 
>      ? This seems to have slipped through the cracks, sorry about that.
> 
>      ? lme4 doesn't do correlation structures, but glmmTMB does. The closest
>     analogue would be something like
> 
>     ## this should be observation number within group
>     dat$times <- numFactor(dat$times)
> 
>     model2 <- glmmTMB(continuous_outcome ~ 1 + Predictor_X + Day +
>      ? ? (1 + Day | Team / Year) + ar1(times + 0 | Team:Year)
> 
>      ? (your random effect has two | in it; was the second meant to be a
>     / ?)
> 
>     See https://glmmtmb.github.io/glmmTMB/articles/covstruct.html
>     <https://glmmtmb.github.io/glmmTMB/articles/covstruct.html>
> 
>     On 2023-01-25 5:13 p.m., Adam Roebuck wrote:
>      > Hello,
>      >
>      > I am attempting to set up a multilevel model with two grouping
>     variables
>      > (team and year), random slopes for day of the year, and
>     accounting for
>      > autocorrelation. I have a number of different outcome variables I
>     can use.
>      > When the outcome variable is continuous, I can set up a simple
>     growth model
>      > using the nlme package that looks something like the following:
>      >
>      > model1 <- lme(continuous_outcome ~ 1 + Predictor_X + Day,
>      >
>      > random = ~1 + Day | Team | Year, data = dat, method = "REML",
>      >
>      > control=list(opt="optim"), correlation = corAR1()
>      >
>      > However, I now want to build a model with a dichotomous outcome
>     variable.
>      > As far as I know, nlme cannot account for all of the above and a
>      > dichotomous outcome. I have, however, seen a few references to
>     glmer (in
>      > the lme4 package) and glmmTMB being capable of such. I've gone
>     back through
>      > the archives, though, and am not seeing any clear explanations on
>     how to
>      > set up such a model.
>      >
>      > Using the parameters above and the variables I specified, could
>     someone
>      > please help specify what that model might look like in R or at
>     least point
>      > me in the right direction?
>      >
>      > Thanks,
>      > Adam
>      >
> 
> 
> 
> 
>     --
>     Dr. Benjamin Bolker
>     Professor, Mathematics & Statistics and Biology, McMaster University
>     Director, School of Computational Science and Engineering
>     (Acting) Graduate chair, Mathematics & Statistics
>      ?> E-mail is sent at my convenience; I don't expect replies outside of
>     working hours.
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> -- 
> *Adam Roebuck*
> University of Connecticut | School of Business
> Doctoral Candidate | Management
> 2100 Hillside Rd., Unit 1041
> Storrs, CT 06269
> (248) 613-9609

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @kye@bruce @end|ng |rom w|@c@edu  Sat Apr 15 21:13:47 2023
From: @kye@bruce @end|ng |rom w|@c@edu (Skye Bruce)
Date: Sat, 15 Apr 2023 19:13:47 +0000
Subject: [R-sig-ME] Calculating R2 for a GLMM with small response
 values/Tweedie family
Message-ID: <CY4PR06MB3253AB52E8AF6A528CC5494DE79E9@CY4PR06MB3253.namprd06.prod.outlook.com>

Greetings,

I am emailing to ask about calculating R2 for a GLMM using Tweedie family of distributions in the glmmTMB + performance packages in R. My response variable contains many zeroes and very small values, and performance is having trouble calculating my model's distribution-specific variance, making the resulting R2 unreliable. Is there a more reliable way to calculate R2 for this GLMM?

I have measured my response variable, monarch butterfly eggs and larvae per m2, on grazed lands that vary in (predictors) grazing management category, floral richness, milkweed density (stems/m2) over two years, with three visits per year to each site.

Data .csv file attached.

Input:
mod1.egglarv1m.twe <- glmmTMB(egglarva1m ~ category + florarich + submilk1m + visit + year + category:year + (1|site),
                              data = egglarv1m.scale,
                              family = tweedie)
performance::r2(mod1.egglarv1m.twe)

Output:
# R2 for Mixed Models

  Conditional R2: 1.000
     Marginal R2: 0.724
Warning messages:
1: mu of 0.0 is too close to zero, estimate of random effect variances may be unreliable.
2: Can't calculate model's distribution-specific variance. Results are not reliable.

Thank you for your assistance,

Skye Bruce

PhD Student
University of Wisconsin?Madison | Entomology


From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Sun Apr 16 02:16:37 2023
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Sun, 16 Apr 2023 00:16:37 +0000
Subject: [R-sig-ME] Trying to align lmer output with Robinson's BLUP is a
 good thing
Message-ID: <SJ0PR01MB6400B37409159ABC26BD1E23F29F9@SJ0PR01MB6400.prod.exchangelabs.com>

Hi,

I am trying to understand the model fitting of lmer() with the aid of GK Robinson's 1991 paper "BLUP is a good thing."  I am trying to align the lmer() output with Robinson's notation.

I have a few questions in this regard.

  1.  How can I get matrices X and Z from lmer?
  2.  How do I obtain the variances G and R?
  3.  For a new subject (x*, z*), is it possible to obtain BLUP predictions of x*\beta + z*u as shown in Robinson's paper? When I try to do this using predict.merMod, it complains that new levels are not allowed for conditional prediction.

Thank you,
Ravi


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Apr 16 02:35:09 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 15 Apr 2023 20:35:09 -0400
Subject: [R-sig-ME] 
 Trying to align lmer output with Robinson's BLUP is a good thing
In-Reply-To: <SJ0PR01MB6400B37409159ABC26BD1E23F29F9@SJ0PR01MB6400.prod.exchangelabs.com>
References: <SJ0PR01MB6400B37409159ABC26BD1E23F29F9@SJ0PR01MB6400.prod.exchangelabs.com>
Message-ID: <4241508d-db30-9db2-cd99-6b5ec189b8d9@gmail.com>

 ?? You can get most of the answers to these questions from the JSS 
paper (vignette("lmer", package = "lme4")).

 ? X: getME(fitted_model, "X")

 ? Z: t(getME(fitted_model, "Zt"))

 ? I believe G is

Lambda <- t(getME(fitted_model, "Lambdat"))

G <- crossprod(Lambda) ## or maybe tcrossprod()?

R <- diag(nobs(fitted_model))

 ? (but you should double/cross-check with the JSS vignette, I didn't 
look at the definitions in the Robinson paper super-carefully)

 ? At present lme4 only allows predictions that are either completely 
unconditional (re.form = NA) or conditional on the b values (re.form = 
NULL), not conditional on the y-values from the new level and the 
top-level estimates (sigma^2, theta -> G). You can follow the machinery 
in Robinson's paper or (as you pointed out in another e-mail) follow the 
machinery here: 
https://github.com/drizopoulos/JMbayes/blob/master/R/dynPred_lme.R but 
adapted for lme4

 ? This would be a good idea to include in lme4, if anyone wants to 
implement and make a pull request :-)

On 2023-04-15 8:16 p.m., Ravi Varadhan via R-sig-mixed-models wrote:
> Hi,
>
> I am trying to understand the model fitting of lmer() with the aid of GK Robinson's 1991 paper "BLUP is a good thing."  I am trying to align the lmer() output with Robinson's notation.
>
> I have a few questions in this regard.
>
>    1.  How can I get matrices X and Z from lmer?
>    2.  How do I obtain the variances G and R?
>    3.  For a new subject (x*, z*), is it possible to obtain BLUP predictions of x*\beta + z*u as shown in Robinson's paper? When I try to do this using predict.merMod, it complains that new levels are not allowed for conditional prediction.
>
> Thank you,
> Ravi
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @r|ve@ @end|ng |rom w|@c@edu  Sun Apr 16 13:40:17 2023
From: @r|ve@ @end|ng |rom w|@c@edu (Anthony R. Ives)
Date: Sun, 16 Apr 2023 11:40:17 +0000
Subject: [R-sig-ME] Calculating R2 for a GLMM with small response
 values/Tweedie family
In-Reply-To: <CY4PR06MB3253AB52E8AF6A528CC5494DE79E9@CY4PR06MB3253.namprd06.prod.outlook.com>
References: <CY4PR06MB3253AB52E8AF6A528CC5494DE79E9@CY4PR06MB3253.namprd06.prod.outlook.com>
Message-ID: <SN4PR0601MB8645D70A7EEA1FD0C1EC6CDCB49F9@SN4PR0601MB8645.namprd06.prod.outlook.com>

Skye,

I?d use a partial R2. I know that people like marginal and conditional R2?s, but I don?t understand how they can be interpreted as ?amount of variation explained by?? A partial R2 explicitly asks how much loss-of-fit occurs with removal of a component (fixed or random) of a model. A (the) main problem solved by mixed models is violation of the exogeneity assumption of OLS, and marginal/conditional R2?s are insensitive to this problem.


You can calculate a partial R2 from likelihoods (from models fit with ML): see equation 17 in Ives, A.R. (2019. Rs for Correlated Data: Phylogenetic Models, LMMs, and GLMMs. Systematic Biology, 68, 234-251). You could grab the code from the package rr2, but I don?t think it can be used directly because it won?t recognize the class for glmmTMB. If you need a hand, just shoot me a private email.



Cheers, Tony


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Skye Bruce via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Date: Saturday, April 15, 2023 at 4:13 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Calculating R2 for a GLMM with small response values/Tweedie family
Greetings,

I am emailing to ask about calculating R2 for a GLMM using Tweedie family of distributions in the glmmTMB + performance packages in R. My response variable contains many zeroes and very small values, and performance is having trouble calculating my model's distribution-specific variance, making the resulting R2 unreliable. Is there a more reliable way to calculate R2 for this GLMM?

I have measured my response variable, monarch butterfly eggs and larvae per m2, on grazed lands that vary in (predictors) grazing management category, floral richness, milkweed density (stems/m2) over two years, with three visits per year to each site.

Data .csv file attached.

Input:
mod1.egglarv1m.twe <- glmmTMB(egglarva1m ~ category + florarich + submilk1m + visit + year + category:year + (1|site),
                              data = egglarv1m.scale,
                              family = tweedie)
performance::r2(mod1.egglarv1m.twe)

Output:
# R2 for Mixed Models

  Conditional R2: 1.000
     Marginal R2: 0.724
Warning messages:
1: mu of 0.0 is too close to zero, estimate of random effect variances may be unreliable.
2: Can't calculate model's distribution-specific variance. Results are not reliable.

Thank you for your assistance,

Skye Bruce

PhD Student
University of Wisconsin?Madison | Entomology

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Apr 16 15:31:36 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 16 Apr 2023 09:31:36 -0400
Subject: [R-sig-ME] Calculating R2 for a GLMM with small response
 values/Tweedie family
In-Reply-To: <SN4PR0601MB8645D70A7EEA1FD0C1EC6CDCB49F9@SN4PR0601MB8645.namprd06.prod.outlook.com>
References: <CY4PR06MB3253AB52E8AF6A528CC5494DE79E9@CY4PR06MB3253.namprd06.prod.outlook.com>
 <SN4PR0601MB8645D70A7EEA1FD0C1EC6CDCB49F9@SN4PR0601MB8645.namprd06.prod.outlook.com>
Message-ID: <89fb9642-0235-bf64-5406-6fbaff71aea3@gmail.com>

 ??? Hmm.

 ? Based on the code it looks like something like

## mod is the original fitted model

mod.r <- update(mod, . ~ 1)

n <- nobs(mod)

(1 - exp(-2/n * (logLik(mod) - logLik(mod.r))))/(1 -
 ??????? exp(2/n * logLik(mod.r)))


 ? should do it?

On 2023-04-16 7:40 a.m., Anthony R. Ives via R-sig-mixed-models wrote:
> Skye,
>
> I?d use a partial R2. I know that people like marginal and conditional R2?s, but I don?t understand how they can be interpreted as ?amount of variation explained by?? A partial R2 explicitly asks how much loss-of-fit occurs with removal of a component (fixed or random) of a model. A (the) main problem solved by mixed models is violation of the exogeneity assumption of OLS, and marginal/conditional R2?s are insensitive to this problem.
>
>
> You can calculate a partial R2 from likelihoods (from models fit with ML): see equation 17 in Ives, A.R. (2019. Rs for Correlated Data: Phylogenetic Models, LMMs, and GLMMs. Systematic Biology, 68, 234-251). You could grab the code from the package rr2, but I don?t think it can be used directly because it won?t recognize the class for glmmTMB. If you need a hand, just shoot me a private email.
>
>
>
> Cheers, Tony
>
>
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Skye Bruce via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Date: Saturday, April 15, 2023 at 4:13 PM
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Calculating R2 for a GLMM with small response values/Tweedie family
> Greetings,
>
> I am emailing to ask about calculating R2 for a GLMM using Tweedie family of distributions in the glmmTMB + performance packages in R. My response variable contains many zeroes and very small values, and performance is having trouble calculating my model's distribution-specific variance, making the resulting R2 unreliable. Is there a more reliable way to calculate R2 for this GLMM?
>
> I have measured my response variable, monarch butterfly eggs and larvae per m2, on grazed lands that vary in (predictors) grazing management category, floral richness, milkweed density (stems/m2) over two years, with three visits per year to each site.
>
> Data .csv file attached.
>
> Input:
> mod1.egglarv1m.twe <- glmmTMB(egglarva1m ~ category + florarich + submilk1m + visit + year + category:year + (1|site),
>                                data = egglarv1m.scale,
>                                family = tweedie)
> performance::r2(mod1.egglarv1m.twe)
>
> Output:
> # R2 for Mixed Models
>
>    Conditional R2: 1.000
>       Marginal R2: 0.724
> Warning messages:
> 1: mu of 0.0 is too close to zero, estimate of random effect variances may be unreliable.
> 2: Can't calculate model's distribution-specific variance. Results are not reliable.
>
> Thank you for your assistance,
>
> Skye Bruce
>
> PhD Student
> University of Wisconsin?Madison | Entomology
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> 	[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From gkotech@ @end|ng |rom g@h@rv@rd@edu  Mon Apr 24 19:56:59 2023
From: gkotech@ @end|ng |rom g@h@rv@rd@edu (Kotecha, Gopal)
Date: Mon, 24 Apr 2023 13:56:59 -0400
Subject: [R-sig-ME] Estimation of random effects in generalized linear models
Message-ID: <b3d2dcc6-3970-e614-0288-4a9cc2bf22f1@g.harvard.edu>

Dear all,

I am trying to figure out how lme4 estimates individual random effect 
terms (the "b" terms in the following document 
https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf).

My understanding is that the random effect standard deviation and fixed 
effects are first estimated, plugged into the likelihood and then this 
quantity is maximized (or some transformation to that effect).? Is this 
correct?

(More specifically I am figuring out how BLME does it, and BLME obtains 
estimates from lme4)

I have been through the "Computational Methods for Mixed Models" 
document 
(https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf) but 
am not sure if it describes how estimation is carried out in the 
/generalized/ linear model case.

Thanks in advance for your time,

Gopal

	[[alternative HTML version deleted]]


From j@de@ @end|ng |rom he@|th@uc@d@edu  Tue May  2 20:25:33 2023
From: j@de@ @end|ng |rom he@|th@uc@d@edu (Ades, James)
Date: Tue, 2 May 2023 18:25:33 +0000
Subject: [R-sig-ME] Repeated measures in Census Tract Data:
Message-ID: <BY5PR19MB38591E73A61398811E9E91B5EA6F9@BY5PR19MB3859.namprd19.prod.outlook.com>

Hi all,

I am returning to multilevel models after a two-year program in ML techniques.

What I'm doing is nothing fancy, just accounting for the fact that different census tract variables (like median income, median house value, population density, percent those living in same house as they did a year ago, income disparity, percent white/black/Asian race, etc.) will be correlated.

There is 1 GEOID per row (sample of first four rows with reduced columns):
```
df  =
structure(list(kfr_pooled_pooled_p25 = c(0.45727569, 0.51709598,
0.45559084, 0.42194119), GEOID = c(6073000100, 6073000201, 6073000202,
6073000300), lognorm_crime = c(3.25809653802148, 3.66356164612965,
4.49980967033027, 4.00733318523247), median_hh_ = c(138879, 88125,
76658, 68679), income_gin = c(0.533, 0.5175, 0.459, 0.4416),
    per_white = c(0.907856450048497, 0.877313590692755, 0.857551739321885,
    0.852452758159954), per_black = c(0, 0.005288207297726, 0.000880669308675,
    0.061462111089903)), row.names = c(NA, -4L), class = c("tbl_df",
"tbl", "data.frame"))
```

I was surprised to get this error (number of levels of each grouping factor must be < number of observations) in specifying a null model:
```null = lmer(opportunity_score ~ 1 + (?1|GEOID), df, REML = FALSE, control = lmerControl(optimizer = "bobyqa"))??```

Which brought me to this post: https://stackoverflow.com/questions/19713228/lmer-error-grouping-factor-must-be-number-of-observations with Ben (Bolker). And it seems that I was just mistaken, as I thought the 1|GEOID would account for the correlation among subsequent variables within a GEOID. So is the only way to account for the dependence of these values to create a long dataset and then build out the model accordingly: let's say you wanted to build bivariate models regressing an opportunity score on each individual variable, you'd have to filter out only that individual variable (creating many different datasets)?

Also, as a follow-up question, I came across this site (https://www.rensvandeschoot.com/tutorials/lme4/) in researching my question and was surprised that pupils were never added into this model (in popularity dataset, model output provided below), but still van de Schoot writes that If we look at the summary output we see under the Random Effects that the residual variance on the class level 0.7021 and residual variance on the first level (pupil level) is 1.2218. I'm surprised that van de Schoot is essentially saying that the residual variance is solely accounted for at the pupil level. Isn't there much error that won't be accounted for that can't merely be explained by pupil differences? I ask this question because I'm also thinking about my own application with Census Tracts. It is the first model on this webpage (would've screen shot, but it made the email too big): https://www.rensvandeschoot.com/tutorials/lme4/.

Thanks!

James



	[[alternative HTML version deleted]]


From j@de@ @end|ng |rom he@|th@uc@d@edu  Thu May  4 03:24:35 2023
From: j@de@ @end|ng |rom he@|th@uc@d@edu (Ades, James)
Date: Thu, 4 May 2023 01:24:35 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 197, Issue 1
In-Reply-To: <mailman.20071.7.1683108001.58864.r-sig-mixed-models@r-project.org>
References: <mailman.20071.7.1683108001.58864.r-sig-mixed-models@r-project.org>
Message-ID: <BY5PR19MB3859E917B5A8B3D9BAF18002EA6D9@BY5PR19MB3859.namprd19.prod.outlook.com>

Please disregard the first question: the more I thought about it, it would never work, and would need to have at least a 2nd years worth of data such that there are, indeed, repeated measures.

I am still wondering about the 2nd question though:
 I came across this site (https://urldefense.com/v3/__https://www.rensvandeschoot.com/tutorials/lme4/__;!!LLK065n_VXAQ!jHvnv_iDmN8LXetaCrE1EjKr0Le6u7XTjkKBpBOMfagy4xw0KGu0pV6izhlFrC8oeJFV3Tv_mU3c6PdzXtOpmNwYtZjeUSs$ ) in researching my question and was surprised that pupils were never added into this model (in popularity dataset, model output provided below), but still van de Schoot writes that If we look at the summary output we see under the Random Effects that the residual variance on the class level 0.7021 and residual variance on the first level (pupil level) is 1.2218. I'm surprised that van de Schoot is essentially saying that the residual variance is solely accounted for at the pupil level. Isn't there much error that won't be accounted for that can't merely be explained by pupil differences? I ask this question because I'm also thinking about my own application with Census Tracts. It is the first model on this webpage (would've screen shot, but it made the email too big): https://urldefense.com/v3/__https://www.rensvandeschoot.com/tutorials/lme4/__;!!LLK065n_VXAQ!jHvnv_iDmN8LXetaCrE1EjKr0Le6u7XTjkKBpBOMfagy4xw0KGu0pV6izhlFrC8oeJFV3Tv_mU3c6PdzXtOpmNwYtZjeUSs$ .

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Sent: Wednesday, May 3, 2023 3:00 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: R-sig-mixed-models Digest, Vol 197, Issue 1

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LLK065n_VXAQ!jHvnv_iDmN8LXetaCrE1EjKr0Le6u7XTjkKBpBOMfagy4xw0KGu0pV6izhlFrC8oeJFV3Tv_mU3c6PdzXtOpmNwYbl83j_s$
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Repeated measures in Census Tract Data: (Ades, James)

----------------------------------------------------------------------

Message: 1
Date: Tue, 2 May 2023 18:25:33 +0000
From: "Ades, James" <jades at health.ucsd.edu>
To: "r-sig-mixed-models at r-project.org"
        <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Repeated measures in Census Tract Data:
Message-ID:
        <BY5PR19MB38591E73A61398811E9E91B5EA6F9 at BY5PR19MB3859.namprd19.prod.outlook.com>

Content-Type: text/plain; charset="utf-8"

Hi all,

I am returning to multilevel models after a two-year program in ML techniques.

What I'm doing is nothing fancy, just accounting for the fact that different census tract variables (like median income, median house value, population density, percent those living in same house as they did a year ago, income disparity, percent white/black/Asian race, etc.) will be correlated.

There is 1 GEOID per row (sample of first four rows with reduced columns):
```
df  =
structure(list(kfr_pooled_pooled_p25 = c(0.45727569, 0.51709598,
0.45559084, 0.42194119), GEOID = c(6073000100, 6073000201, 6073000202,
6073000300), lognorm_crime = c(3.25809653802148, 3.66356164612965,
4.49980967033027, 4.00733318523247), median_hh_ = c(138879, 88125,
76658, 68679), income_gin = c(0.533, 0.5175, 0.459, 0.4416),
    per_white = c(0.907856450048497, 0.877313590692755, 0.857551739321885,
    0.852452758159954), per_black = c(0, 0.005288207297726, 0.000880669308675,
    0.061462111089903)), row.names = c(NA, -4L), class = c("tbl_df",
"tbl", "data.frame"))
```

I was surprised to get this error (number of levels of each grouping factor must be < number of observations) in specifying a null model:
```null = lmer(opportunity_score ~ 1 + (?1|GEOID), df, REML = FALSE, control = lmerControl(optimizer = "bobyqa"))??```

Which brought me to this post: https://urldefense.com/v3/__https://stackoverflow.com/questions/19713228/lmer-error-grouping-factor-must-be-number-of-observations__;!!LLK065n_VXAQ!jHvnv_iDmN8LXetaCrE1EjKr0Le6u7XTjkKBpBOMfagy4xw0KGu0pV6izhlFrC8oeJFV3Tv_mU3c6PdzXtOpmNwYVTxWQe0$  with Ben (Bolker). And it seems that I was just mistaken, as I thought the 1|GEOID would account for the correlation among subsequent variables within a GEOID. So is the only way to account for the dependence of these values to create a long dataset and then build out the model accordingly: let's say you wanted to build bivariate models regressing an opportunity score on each individual variable, you'd have to filter out only that individual variable (creating many different datasets)?

Also, as a follow-up question, I came across this site (https://urldefense.com/v3/__https://www.rensvandeschoot.com/tutorials/lme4/__;!!LLK065n_VXAQ!jHvnv_iDmN8LXetaCrE1EjKr0Le6u7XTjkKBpBOMfagy4xw0KGu0pV6izhlFrC8oeJFV3Tv_mU3c6PdzXtOpmNwYtZjeUSs$ ) in researching my question and was surprised that pupils were never added into this model (in popularity dataset, model output provided below), but still van de Schoot writes that If we look at the summary output we see under the Random Effects that the residual variance on the class level 0.7021 and residual variance on the first level (pupil level) is 1.2218. I'm surprised that van de Schoot is essentially saying that the residual variance is solely accounted for at the pupil level. Isn't there much error that won't be accounted for that can't merely be explained by pupil differences? I ask this question because I'm also thinking about my own application with Census Tracts. It is the first model on this webpage (would've screen shot, but it made the email too big): https://urldefense.com/v3/__https://www.rensvandeschoot.com/tutorials/lme4/__;!!LLK065n_VXAQ!jHvnv_iDmN8LXetaCrE1EjKr0Le6u7XTjkKBpBOMfagy4xw0KGu0pV6izhlFrC8oeJFV3Tv_mU3c6PdzXtOpmNwYtZjeUSs$ .

Thanks!

James



        [[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LLK065n_VXAQ!jHvnv_iDmN8LXetaCrE1EjKr0Le6u7XTjkKBpBOMfagy4xw0KGu0pV6izhlFrC8oeJFV3Tv_mU3c6PdzXtOpmNwYbl83j_s$


------------------------------

End of R-sig-mixed-models Digest, Vol 197, Issue 1
**************************************************

	[[alternative HTML version deleted]]


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Tue May  9 15:10:09 2023
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Tue, 9 May 2023 15:10:09 +0200
Subject: [R-sig-ME] two fixed-effects, only one with repetitions
Message-ID: <CAHhX7WjwR7VdKB+sVH6VdQ2mNaLT8obyctYok16g8p6s9VnsbA@mail.gmail.com>

Dear all,

I am having issues structuring the random-effects of a mixed model using
nlme. There are two fixed factors, but only one of them is within-subjects.
I posted the question here
<https://stats.stackexchange.com/questions/614983/mixed-model-with-two-fixed-effects-with-repeated-measures-for-only-one-of-them>.
Any help would be appreciated!

Best
Cristiano

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Sun May 14 05:55:03 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Sat, 13 May 2023 22:55:03 -0500
Subject: [R-sig-ME] Improving residual distribution in glmmTMB
Message-ID: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>

Greetings,

I'm modeling the number of downloads (downs) of certain forms
(Document) by a number of school districts (District) of various
student sizes (ELs).

I've tried genpois(), nbinom1(), and nbinom2() families but the fitted
vs. residual doesn't look promising.

In glmmTMB, are there any additional ways to improve the residual
distribution for count-type data?

Thank you,
Tim M
### Reproducible data and code:
d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")

model = glmmTMB(downs ~ I(ELs/20) + Document +
                           (1|District) +
                           (1|Document),
                         family=genpois(),
                     #  ziformula = ~ Document,
                  # dispformula = ~ Document,
                         data = d)

plot(resid(model,type="pearson") ~ fitted(model))


From bbo|ker @end|ng |rom gm@||@com  Mon May 15 16:37:07 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 May 2023 10:37:07 -0400
Subject: [R-sig-ME] Improving residual distribution in glmmTMB
In-Reply-To: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>
References: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>
Message-ID: <94886a07-29bd-b119-99e3-57452d3507ee@gmail.com>

   I don't have any perfect solution, and I don't necessarily recommend 
the brute-force approach tried below, but a truncated negative binomial 
(2/quadratic parameterization) seems best. The genpois and nbinom1 are 
actually wonkiest, in terms of appearance of residuals.
   The COM-Poisson below is *very* slow, you might want to skip it (it 
took 20 minutes to fit on 16 cores, and the results are not that great 
anyway).
   I thought about implementing a Poisson-inverse-Gamma to allow for 
heavier tails, but haven't gotten around to it yet (it's not trivial ...)
   There seems to be something wonky about the reported sigma/Pearson 
residuals from truncated nbinom2, but the results are OK ...

### Reproducible data and code:
d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
library(glmmTMB)
library(purrr)
library(broom.mixed)
library(dplyr)
library(DHARMa)

model <- glmmTMB(downs ~ I(ELs/20) +
                     ## Document +
                     (1|District) +
                     (1|Document),
                 family=genpois(),
                      #  ziformula = ~ Document,
                   # dispformula = ~ Document,
                 data = d)

## very slow ...
system.time(model2 <- update(model, family = "compois",
                              control = glmmTMBControl(parallel = 16)))

##      user    system   elapsed
## 17194.076    11.103  1134.367

## truncated genpois doesn't work for some reason ...
fam <- c("genpois", "poisson", "nbinom1", "nbinom2")
fam <- c(fam, paste0("truncated_", fam[-1]))
mod_list <- lapply(fam,
                    function(f) {
                        cat(f, "\n")
                        update(model, family = f)
})
names(mod_list) <- fam
mod_list[["compois"]] <- model2


aictab <- (map_dfr(mod_list, glance, .id = "family")
     |> select(-c(nobs,logLik, BIC))
     |> mutate(across(c(AIC, deviance), ~ . - min(., na.rm = TRUE)))
     |> arrange(AIC)
)

##   family              sigma   AIC df.residual deviance
##   <chr>               <dbl> <dbl>       <int>    <dbl>
## 1 truncated_nbinom2 3.66e-8    0          569      NA
## 2 nbinom2           1.39e+0  665.         569       0
## 3 compois           5.29e+9  682.         569      NA
## 4 genpois           1.33e+1  768.         569      NA
## 5 nbinom1           8.11e+0  981.         569     191.
## 6 truncated_poisson 1   e+0 1996.         570      NA
## 7 poisson           1   e+0 2553.         570    2077.
## 8 truncated_nbinom1 7.84e+0   NA          569      NA

tnb <- mod_list[["truncated_nbinom2"]]
## Pearson resid calc messed up ???
plot(resid(tnb,type="pearson") ~ fitted(tnb))

plot(d$downs, predict(tnb, type = "response"), log = "xy")
abline(a=0, b=1, col = 2)

## reorder
mod_list <- mod_list[aictab$family]
op <- par(mfrow = c(3, 3), mfrow = c(3,2,1,1), las = 1)
lapply(mod_list,
        function(m) plot(resid(m,type="pearson") ~ fitted(m),
                         xlab = "", ylab = "", main = family(m)$family)
        )


## DHARMa
ss <- simulateResiduals(tnb)
plot(ss)
plotResiduals(ss, form = d$ELs/20)



On 2023-05-13 11:55 p.m., Timothy MacKenzie wrote:
> Greetings,
> 
> I'm modeling the number of downloads (downs) of certain forms
> (Document) by a number of school districts (District) of various
> student sizes (ELs).
> 
> I've tried genpois(), nbinom1(), and nbinom2() families but the fitted
> vs. residual doesn't look promising.
> 
> In glmmTMB, are there any additional ways to improve the residual
> distribution for count-type data?
> 
> Thank you,
> Tim M
> ### Reproducible data and code:
> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
> 
> model = glmmTMB(downs ~ I(ELs/20) + Document +
>                             (1|District) +
>                             (1|Document),
>                           family=genpois(),
>                       #  ziformula = ~ Document,
>                    # dispformula = ~ Document,
>                           data = d)
> 
> plot(resid(model,type="pearson") ~ fitted(model))
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From |@w|@wt @end|ng |rom gm@||@com  Tue May 16 00:52:55 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Mon, 15 May 2023 17:52:55 -0500
Subject: [R-sig-ME] Improving residual distribution in glmmTMB
In-Reply-To: <94886a07-29bd-b119-99e3-57452d3507ee@gmail.com>
References: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>
 <94886a07-29bd-b119-99e3-57452d3507ee@gmail.com>
Message-ID: <CADreqiweOFxqNCv1Q8HmjSrBoU63Rcz5cMgJPrtUiEiApuZ4MQ@mail.gmail.com>

Thank you, Ben, that's very helpful. I noticed that you removed the
fixed effect for "Document", that's, I'm guessing, to improve the
model fit (ex. avoiding singularity)? I was hoping to explore how many
times, on average, each unique Document was downloaded. Looks like
that may not be possible.

Thanks,
Tim M





On Mon, May 15, 2023 at 9:37?AM Ben Bolker <bbolker at gmail.com> wrote:
>
>    I don't have any perfect solution, and I don't necessarily recommend
> the brute-force approach tried below, but a truncated negative binomial
> (2/quadratic parameterization) seems best. The genpois and nbinom1 are
> actually wonkiest, in terms of appearance of residuals.
>    The COM-Poisson below is *very* slow, you might want to skip it (it
> took 20 minutes to fit on 16 cores, and the results are not that great
> anyway).
>    I thought about implementing a Poisson-inverse-Gamma to allow for
> heavier tails, but haven't gotten around to it yet (it's not trivial ...)
>    There seems to be something wonky about the reported sigma/Pearson
> residuals from truncated nbinom2, but the results are OK ...
>
> ### Reproducible data and code:
> d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
> library(glmmTMB)
> library(purrr)
> library(broom.mixed)
> library(dplyr)
> library(DHARMa)
>
> model <- glmmTMB(downs ~ I(ELs/20) +
>                      ## Document +
>                      (1|District) +
>                      (1|Document),
>                  family=genpois(),
>                       #  ziformula = ~ Document,
>                    # dispformula = ~ Document,
>                  data = d)
>
> ## very slow ...
> system.time(model2 <- update(model, family = "compois",
>                               control = glmmTMBControl(parallel = 16)))
>
> ##      user    system   elapsed
> ## 17194.076    11.103  1134.367
>
> ## truncated genpois doesn't work for some reason ...
> fam <- c("genpois", "poisson", "nbinom1", "nbinom2")
> fam <- c(fam, paste0("truncated_", fam[-1]))
> mod_list <- lapply(fam,
>                     function(f) {
>                         cat(f, "\n")
>                         update(model, family = f)
> })
> names(mod_list) <- fam
> mod_list[["compois"]] <- model2
>
>
> aictab <- (map_dfr(mod_list, glance, .id = "family")
>      |> select(-c(nobs,logLik, BIC))
>      |> mutate(across(c(AIC, deviance), ~ . - min(., na.rm = TRUE)))
>      |> arrange(AIC)
> )
>
> ##   family              sigma   AIC df.residual deviance
> ##   <chr>               <dbl> <dbl>       <int>    <dbl>
> ## 1 truncated_nbinom2 3.66e-8    0          569      NA
> ## 2 nbinom2           1.39e+0  665.         569       0
> ## 3 compois           5.29e+9  682.         569      NA
> ## 4 genpois           1.33e+1  768.         569      NA
> ## 5 nbinom1           8.11e+0  981.         569     191.
> ## 6 truncated_poisson 1   e+0 1996.         570      NA
> ## 7 poisson           1   e+0 2553.         570    2077.
> ## 8 truncated_nbinom1 7.84e+0   NA          569      NA
>
> tnb <- mod_list[["truncated_nbinom2"]]
> ## Pearson resid calc messed up ???
> plot(resid(tnb,type="pearson") ~ fitted(tnb))
>
> plot(d$downs, predict(tnb, type = "response"), log = "xy")
> abline(a=0, b=1, col = 2)
>
> ## reorder
> mod_list <- mod_list[aictab$family]
> op <- par(mfrow = c(3, 3), mfrow = c(3,2,1,1), las = 1)
> lapply(mod_list,
>         function(m) plot(resid(m,type="pearson") ~ fitted(m),
>                          xlab = "", ylab = "", main = family(m)$family)
>         )
>
>
> ## DHARMa
> ss <- simulateResiduals(tnb)
> plot(ss)
> plotResiduals(ss, form = d$ELs/20)
>
>
>
> On 2023-05-13 11:55 p.m., Timothy MacKenzie wrote:
> > Greetings,
> >
> > I'm modeling the number of downloads (downs) of certain forms
> > (Document) by a number of school districts (District) of various
> > student sizes (ELs).
> >
> > I've tried genpois(), nbinom1(), and nbinom2() families but the fitted
> > vs. residual doesn't look promising.
> >
> > In glmmTMB, are there any additional ways to improve the residual
> > distribution for count-type data?
> >
> > Thank you,
> > Tim M
> > ### Reproducible data and code:
> > d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
> >
> > model = glmmTMB(downs ~ I(ELs/20) + Document +
> >                             (1|District) +
> >                             (1|Document),
> >                           family=genpois(),
> >                       #  ziformula = ~ Document,
> >                    # dispformula = ~ Document,
> >                           data = d)
> >
> > plot(resid(model,type="pearson") ~ fitted(model))
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Tue May 16 01:18:34 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 May 2023 19:18:34 -0400
Subject: [R-sig-ME] Improving residual distribution in glmmTMB
In-Reply-To: <CADreqiweOFxqNCv1Q8HmjSrBoU63Rcz5cMgJPrtUiEiApuZ4MQ@mail.gmail.com>
References: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>
 <94886a07-29bd-b119-99e3-57452d3507ee@gmail.com>
 <CADreqiweOFxqNCv1Q8HmjSrBoU63Rcz5cMgJPrtUiEiApuZ4MQ@mail.gmail.com>
Message-ID: <d8d0377a-d42d-eac5-2e7c-4327d0f4fe3f@gmail.com>

   In general it doesn't make sense to include any term as both a fixed 
effect and a random-effect grouping variable (with a few exceptions).

   There's no reason you can't examine the model predictions of how 
often each document is downloaded (i.e., use predict() with each 
document and whatever baseline covariate settings you want)

On 2023-05-15 6:52 p.m., Timothy MacKenzie wrote:
> Thank you, Ben, that's very helpful. I noticed that you removed the
> fixed effect for "Document", that's, I'm guessing, to improve the
> model fit (ex. avoiding singularity)? I was hoping to explore how many
> times, on average, each unique Document was downloaded. Looks like
> that may not be possible.
> 
> Thanks,
> Tim M
> 
> 
> 
> 
> 
> On Mon, May 15, 2023 at 9:37?AM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     I don't have any perfect solution, and I don't necessarily recommend
>> the brute-force approach tried below, but a truncated negative binomial
>> (2/quadratic parameterization) seems best. The genpois and nbinom1 are
>> actually wonkiest, in terms of appearance of residuals.
>>     The COM-Poisson below is *very* slow, you might want to skip it (it
>> took 20 minutes to fit on 16 cores, and the results are not that great
>> anyway).
>>     I thought about implementing a Poisson-inverse-Gamma to allow for
>> heavier tails, but haven't gotten around to it yet (it's not trivial ...)
>>     There seems to be something wonky about the reported sigma/Pearson
>> residuals from truncated nbinom2, but the results are OK ...
>>
>> ### Reproducible data and code:
>> d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
>> library(glmmTMB)
>> library(purrr)
>> library(broom.mixed)
>> library(dplyr)
>> library(DHARMa)
>>
>> model <- glmmTMB(downs ~ I(ELs/20) +
>>                       ## Document +
>>                       (1|District) +
>>                       (1|Document),
>>                   family=genpois(),
>>                        #  ziformula = ~ Document,
>>                     # dispformula = ~ Document,
>>                   data = d)
>>
>> ## very slow ...
>> system.time(model2 <- update(model, family = "compois",
>>                                control = glmmTMBControl(parallel = 16)))
>>
>> ##      user    system   elapsed
>> ## 17194.076    11.103  1134.367
>>
>> ## truncated genpois doesn't work for some reason ...
>> fam <- c("genpois", "poisson", "nbinom1", "nbinom2")
>> fam <- c(fam, paste0("truncated_", fam[-1]))
>> mod_list <- lapply(fam,
>>                      function(f) {
>>                          cat(f, "\n")
>>                          update(model, family = f)
>> })
>> names(mod_list) <- fam
>> mod_list[["compois"]] <- model2
>>
>>
>> aictab <- (map_dfr(mod_list, glance, .id = "family")
>>       |> select(-c(nobs,logLik, BIC))
>>       |> mutate(across(c(AIC, deviance), ~ . - min(., na.rm = TRUE)))
>>       |> arrange(AIC)
>> )
>>
>> ##   family              sigma   AIC df.residual deviance
>> ##   <chr>               <dbl> <dbl>       <int>    <dbl>
>> ## 1 truncated_nbinom2 3.66e-8    0          569      NA
>> ## 2 nbinom2           1.39e+0  665.         569       0
>> ## 3 compois           5.29e+9  682.         569      NA
>> ## 4 genpois           1.33e+1  768.         569      NA
>> ## 5 nbinom1           8.11e+0  981.         569     191.
>> ## 6 truncated_poisson 1   e+0 1996.         570      NA
>> ## 7 poisson           1   e+0 2553.         570    2077.
>> ## 8 truncated_nbinom1 7.84e+0   NA          569      NA
>>
>> tnb <- mod_list[["truncated_nbinom2"]]
>> ## Pearson resid calc messed up ???
>> plot(resid(tnb,type="pearson") ~ fitted(tnb))
>>
>> plot(d$downs, predict(tnb, type = "response"), log = "xy")
>> abline(a=0, b=1, col = 2)
>>
>> ## reorder
>> mod_list <- mod_list[aictab$family]
>> op <- par(mfrow = c(3, 3), mfrow = c(3,2,1,1), las = 1)
>> lapply(mod_list,
>>          function(m) plot(resid(m,type="pearson") ~ fitted(m),
>>                           xlab = "", ylab = "", main = family(m)$family)
>>          )
>>
>>
>> ## DHARMa
>> ss <- simulateResiduals(tnb)
>> plot(ss)
>> plotResiduals(ss, form = d$ELs/20)
>>
>>
>>
>> On 2023-05-13 11:55 p.m., Timothy MacKenzie wrote:
>>> Greetings,
>>>
>>> I'm modeling the number of downloads (downs) of certain forms
>>> (Document) by a number of school districts (District) of various
>>> student sizes (ELs).
>>>
>>> I've tried genpois(), nbinom1(), and nbinom2() families but the fitted
>>> vs. residual doesn't look promising.
>>>
>>> In glmmTMB, are there any additional ways to improve the residual
>>> distribution for count-type data?
>>>
>>> Thank you,
>>> Tim M
>>> ### Reproducible data and code:
>>> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
>>>
>>> model = glmmTMB(downs ~ I(ELs/20) + Document +
>>>                              (1|District) +
>>>                              (1|Document),
>>>                            family=genpois(),
>>>                        #  ziformula = ~ Document,
>>>                     # dispformula = ~ Document,
>>>                            data = d)
>>>
>>> plot(resid(model,type="pearson") ~ fitted(model))
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>   > E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From |@w|@wt @end|ng |rom gm@||@com  Tue May 16 02:46:00 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Mon, 15 May 2023 19:46:00 -0500
Subject: [R-sig-ME] Improving residual distribution in glmmTMB
In-Reply-To: <d8d0377a-d42d-eac5-2e7c-4327d0f4fe3f@gmail.com>
References: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>
 <94886a07-29bd-b119-99e3-57452d3507ee@gmail.com>
 <CADreqiweOFxqNCv1Q8HmjSrBoU63Rcz5cMgJPrtUiEiApuZ4MQ@mail.gmail.com>
 <d8d0377a-d42d-eac5-2e7c-4327d0f4fe3f@gmail.com>
Message-ID: <CADreqiwvT8zPBnjWt5Wzq6W1=7oDMbgb1eRSYqNPpufniA11ug@mail.gmail.com>

I'm likely misunderstanding your recommendation for using predict()
for each Document. If our model has no fixed effect for Document, I'm
wondering how then we can predict() how often each document is
downloaded?

Do you mean averaging across predictions for each category of Document as in:

library(dplyr)
data.frame(d, fitted = predict(model, type = "response")) %>%
  group_by(Document) %>% mutate(ave_downs = mean(downs))

Tim M

model <- glmmTMB(downs ~ I(ELs/20) +
                    ## Document +
                   (1|District)+
                   (1|Document),
                 family=truncated_nbinom2(),
                 data = d)

On Mon, May 15, 2023 at 6:18?PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    In general it doesn't make sense to include any term as both a fixed
> effect and a random-effect grouping variable (with a few exceptions).
>
>    There's no reason you can't examine the model predictions of how
> often each document is downloaded (i.e., use predict() with each
> document and whatever baseline covariate settings you want)
>
> On 2023-05-15 6:52 p.m., Timothy MacKenzie wrote:
> > Thank you, Ben, that's very helpful. I noticed that you removed the
> > fixed effect for "Document", that's, I'm guessing, to improve the
> > model fit (ex. avoiding singularity)? I was hoping to explore how many
> > times, on average, each unique Document was downloaded. Looks like
> > that may not be possible.
> >
> > Thanks,
> > Tim M
> >
> >
> >
> >
> >
> > On Mon, May 15, 2023 at 9:37?AM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     I don't have any perfect solution, and I don't necessarily recommend
> >> the brute-force approach tried below, but a truncated negative binomial
> >> (2/quadratic parameterization) seems best. The genpois and nbinom1 are
> >> actually wonkiest, in terms of appearance of residuals.
> >>     The COM-Poisson below is *very* slow, you might want to skip it (it
> >> took 20 minutes to fit on 16 cores, and the results are not that great
> >> anyway).
> >>     I thought about implementing a Poisson-inverse-Gamma to allow for
> >> heavier tails, but haven't gotten around to it yet (it's not trivial ...)
> >>     There seems to be something wonky about the reported sigma/Pearson
> >> residuals from truncated nbinom2, but the results are OK ...
> >>
> >> ### Reproducible data and code:
> >> d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
> >> library(glmmTMB)
> >> library(purrr)
> >> library(broom.mixed)
> >> library(dplyr)
> >> library(DHARMa)
> >>
> >> model <- glmmTMB(downs ~ I(ELs/20) +
> >>                       ## Document +
> >>                       (1|District) +
> >>                       (1|Document),
> >>                   family=genpois(),
> >>                        #  ziformula = ~ Document,
> >>                     # dispformula = ~ Document,
> >>                   data = d)
> >>
> >> ## very slow ...
> >> system.time(model2 <- update(model, family = "compois",
> >>                                control = glmmTMBControl(parallel = 16)))
> >>
> >> ##      user    system   elapsed
> >> ## 17194.076    11.103  1134.367
> >>
> >> ## truncated genpois doesn't work for some reason ...
> >> fam <- c("genpois", "poisson", "nbinom1", "nbinom2")
> >> fam <- c(fam, paste0("truncated_", fam[-1]))
> >> mod_list <- lapply(fam,
> >>                      function(f) {
> >>                          cat(f, "\n")
> >>                          update(model, family = f)
> >> })
> >> names(mod_list) <- fam
> >> mod_list[["compois"]] <- model2
> >>
> >>
> >> aictab <- (map_dfr(mod_list, glance, .id = "family")
> >>       |> select(-c(nobs,logLik, BIC))
> >>       |> mutate(across(c(AIC, deviance), ~ . - min(., na.rm = TRUE)))
> >>       |> arrange(AIC)
> >> )
> >>
> >> ##   family              sigma   AIC df.residual deviance
> >> ##   <chr>               <dbl> <dbl>       <int>    <dbl>
> >> ## 1 truncated_nbinom2 3.66e-8    0          569      NA
> >> ## 2 nbinom2           1.39e+0  665.         569       0
> >> ## 3 compois           5.29e+9  682.         569      NA
> >> ## 4 genpois           1.33e+1  768.         569      NA
> >> ## 5 nbinom1           8.11e+0  981.         569     191.
> >> ## 6 truncated_poisson 1   e+0 1996.         570      NA
> >> ## 7 poisson           1   e+0 2553.         570    2077.
> >> ## 8 truncated_nbinom1 7.84e+0   NA          569      NA
> >>
> >> tnb <- mod_list[["truncated_nbinom2"]]
> >> ## Pearson resid calc messed up ???
> >> plot(resid(tnb,type="pearson") ~ fitted(tnb))
> >>
> >> plot(d$downs, predict(tnb, type = "response"), log = "xy")
> >> abline(a=0, b=1, col = 2)
> >>
> >> ## reorder
> >> mod_list <- mod_list[aictab$family]
> >> op <- par(mfrow = c(3, 3), mfrow = c(3,2,1,1), las = 1)
> >> lapply(mod_list,
> >>          function(m) plot(resid(m,type="pearson") ~ fitted(m),
> >>                           xlab = "", ylab = "", main = family(m)$family)
> >>          )
> >>
> >>
> >> ## DHARMa
> >> ss <- simulateResiduals(tnb)
> >> plot(ss)
> >> plotResiduals(ss, form = d$ELs/20)
> >>
> >>
> >>
> >> On 2023-05-13 11:55 p.m., Timothy MacKenzie wrote:
> >>> Greetings,
> >>>
> >>> I'm modeling the number of downloads (downs) of certain forms
> >>> (Document) by a number of school districts (District) of various
> >>> student sizes (ELs).
> >>>
> >>> I've tried genpois(), nbinom1(), and nbinom2() families but the fitted
> >>> vs. residual doesn't look promising.
> >>>
> >>> In glmmTMB, are there any additional ways to improve the residual
> >>> distribution for count-type data?
> >>>
> >>> Thank you,
> >>> Tim M
> >>> ### Reproducible data and code:
> >>> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
> >>>
> >>> model = glmmTMB(downs ~ I(ELs/20) + Document +
> >>>                              (1|District) +
> >>>                              (1|Document),
> >>>                            family=genpois(),
> >>>                        #  ziformula = ~ Document,
> >>>                     # dispformula = ~ Document,
> >>>                            data = d)
> >>>
> >>> plot(resid(model,type="pearson") ~ fitted(model))
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >> (Acting) Graduate chair, Mathematics & Statistics
> >>   > E-mail is sent at my convenience; I don't expect replies outside of
> >> working hours.
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.


From bbo|ker @end|ng |rom gm@||@com  Tue May 16 02:52:00 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 May 2023 20:52:00 -0400
Subject: [R-sig-ME] Improving residual distribution in glmmTMB
In-Reply-To: <CADreqiwvT8zPBnjWt5Wzq6W1=7oDMbgb1eRSYqNPpufniA11ug@mail.gmail.com>
References: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>
 <94886a07-29bd-b119-99e3-57452d3507ee@gmail.com>
 <CADreqiweOFxqNCv1Q8HmjSrBoU63Rcz5cMgJPrtUiEiApuZ4MQ@mail.gmail.com>
 <d8d0377a-d42d-eac5-2e7c-4327d0f4fe3f@gmail.com>
 <CADreqiwvT8zPBnjWt5Wzq6W1=7oDMbgb1eRSYqNPpufniA11ug@mail.gmail.com>
Message-ID: <978ca723-4350-bfca-32e4-9b1cc51a68c7@gmail.com>

   By default (the re.form argument to predict() is set to NULL), the 
predictions include the random effects.  So a 'newdata' data frame like:

ELs   Document  District
20    1         NA
20    2         NA
20    3         NA

would give you the predicted values for document 1, 2, 3, given ELs = 
20, and making a population-level prediction for District (i.e. *not* 
using the District RE/setting this info to 0)

On 2023-05-15 8:46 p.m., Timothy MacKenzie wrote:
> I'm likely misunderstanding your recommendation for using predict()
> for each Document. If our model has no fixed effect for Document, I'm
> wondering how then we can predict() how often each document is
> downloaded?
> 
> Do you mean averaging across predictions for each category of Document as in:
> 
> library(dplyr)
> data.frame(d, fitted = predict(model, type = "response")) %>%
>    group_by(Document) %>% mutate(ave_downs = mean(downs))
> 
> Tim M
> 
> model <- glmmTMB(downs ~ I(ELs/20) +
>                      ## Document +
>                     (1|District)+
>                     (1|Document),
>                   family=truncated_nbinom2(),
>                   data = d)
> 
> On Mon, May 15, 2023 at 6:18?PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     In general it doesn't make sense to include any term as both a fixed
>> effect and a random-effect grouping variable (with a few exceptions).
>>
>>     There's no reason you can't examine the model predictions of how
>> often each document is downloaded (i.e., use predict() with each
>> document and whatever baseline covariate settings you want)
>>
>> On 2023-05-15 6:52 p.m., Timothy MacKenzie wrote:
>>> Thank you, Ben, that's very helpful. I noticed that you removed the
>>> fixed effect for "Document", that's, I'm guessing, to improve the
>>> model fit (ex. avoiding singularity)? I was hoping to explore how many
>>> times, on average, each unique Document was downloaded. Looks like
>>> that may not be possible.
>>>
>>> Thanks,
>>> Tim M
>>>
>>>
>>>
>>>
>>>
>>> On Mon, May 15, 2023 at 9:37?AM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>      I don't have any perfect solution, and I don't necessarily recommend
>>>> the brute-force approach tried below, but a truncated negative binomial
>>>> (2/quadratic parameterization) seems best. The genpois and nbinom1 are
>>>> actually wonkiest, in terms of appearance of residuals.
>>>>      The COM-Poisson below is *very* slow, you might want to skip it (it
>>>> took 20 minutes to fit on 16 cores, and the results are not that great
>>>> anyway).
>>>>      I thought about implementing a Poisson-inverse-Gamma to allow for
>>>> heavier tails, but haven't gotten around to it yet (it's not trivial ...)
>>>>      There seems to be something wonky about the reported sigma/Pearson
>>>> residuals from truncated nbinom2, but the results are OK ...
>>>>
>>>> ### Reproducible data and code:
>>>> d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
>>>> library(glmmTMB)
>>>> library(purrr)
>>>> library(broom.mixed)
>>>> library(dplyr)
>>>> library(DHARMa)
>>>>
>>>> model <- glmmTMB(downs ~ I(ELs/20) +
>>>>                        ## Document +
>>>>                        (1|District) +
>>>>                        (1|Document),
>>>>                    family=genpois(),
>>>>                         #  ziformula = ~ Document,
>>>>                      # dispformula = ~ Document,
>>>>                    data = d)
>>>>
>>>> ## very slow ...
>>>> system.time(model2 <- update(model, family = "compois",
>>>>                                 control = glmmTMBControl(parallel = 16)))
>>>>
>>>> ##      user    system   elapsed
>>>> ## 17194.076    11.103  1134.367
>>>>
>>>> ## truncated genpois doesn't work for some reason ...
>>>> fam <- c("genpois", "poisson", "nbinom1", "nbinom2")
>>>> fam <- c(fam, paste0("truncated_", fam[-1]))
>>>> mod_list <- lapply(fam,
>>>>                       function(f) {
>>>>                           cat(f, "\n")
>>>>                           update(model, family = f)
>>>> })
>>>> names(mod_list) <- fam
>>>> mod_list[["compois"]] <- model2
>>>>
>>>>
>>>> aictab <- (map_dfr(mod_list, glance, .id = "family")
>>>>        |> select(-c(nobs,logLik, BIC))
>>>>        |> mutate(across(c(AIC, deviance), ~ . - min(., na.rm = TRUE)))
>>>>        |> arrange(AIC)
>>>> )
>>>>
>>>> ##   family              sigma   AIC df.residual deviance
>>>> ##   <chr>               <dbl> <dbl>       <int>    <dbl>
>>>> ## 1 truncated_nbinom2 3.66e-8    0          569      NA
>>>> ## 2 nbinom2           1.39e+0  665.         569       0
>>>> ## 3 compois           5.29e+9  682.         569      NA
>>>> ## 4 genpois           1.33e+1  768.         569      NA
>>>> ## 5 nbinom1           8.11e+0  981.         569     191.
>>>> ## 6 truncated_poisson 1   e+0 1996.         570      NA
>>>> ## 7 poisson           1   e+0 2553.         570    2077.
>>>> ## 8 truncated_nbinom1 7.84e+0   NA          569      NA
>>>>
>>>> tnb <- mod_list[["truncated_nbinom2"]]
>>>> ## Pearson resid calc messed up ???
>>>> plot(resid(tnb,type="pearson") ~ fitted(tnb))
>>>>
>>>> plot(d$downs, predict(tnb, type = "response"), log = "xy")
>>>> abline(a=0, b=1, col = 2)
>>>>
>>>> ## reorder
>>>> mod_list <- mod_list[aictab$family]
>>>> op <- par(mfrow = c(3, 3), mfrow = c(3,2,1,1), las = 1)
>>>> lapply(mod_list,
>>>>           function(m) plot(resid(m,type="pearson") ~ fitted(m),
>>>>                            xlab = "", ylab = "", main = family(m)$family)
>>>>           )
>>>>
>>>>
>>>> ## DHARMa
>>>> ss <- simulateResiduals(tnb)
>>>> plot(ss)
>>>> plotResiduals(ss, form = d$ELs/20)
>>>>
>>>>
>>>>
>>>> On 2023-05-13 11:55 p.m., Timothy MacKenzie wrote:
>>>>> Greetings,
>>>>>
>>>>> I'm modeling the number of downloads (downs) of certain forms
>>>>> (Document) by a number of school districts (District) of various
>>>>> student sizes (ELs).
>>>>>
>>>>> I've tried genpois(), nbinom1(), and nbinom2() families but the fitted
>>>>> vs. residual doesn't look promising.
>>>>>
>>>>> In glmmTMB, are there any additional ways to improve the residual
>>>>> distribution for count-type data?
>>>>>
>>>>> Thank you,
>>>>> Tim M
>>>>> ### Reproducible data and code:
>>>>> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
>>>>>
>>>>> model = glmmTMB(downs ~ I(ELs/20) + Document +
>>>>>                               (1|District) +
>>>>>                               (1|Document),
>>>>>                             family=genpois(),
>>>>>                         #  ziformula = ~ Document,
>>>>>                      # dispformula = ~ Document,
>>>>>                             data = d)
>>>>>
>>>>> plot(resid(model,type="pearson") ~ fitted(model))
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> --
>>>> Dr. Benjamin Bolker
>>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>>> Director, School of Computational Science and Engineering
>>>> (Acting) Graduate chair, Mathematics & Statistics
>>>>    > E-mail is sent at my convenience; I don't expect replies outside of
>>>> working hours.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>   > E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From |@w|@wt @end|ng |rom gm@||@com  Tue May 16 03:45:59 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Mon, 15 May 2023 20:45:59 -0500
Subject: [R-sig-ME] Improving residual distribution in glmmTMB
In-Reply-To: <978ca723-4350-bfca-32e4-9b1cc51a68c7@gmail.com>
References: <CADreqixsnXQc=gMad3xRvGS5P==YJ-WFRN7iivO1VJbS+JErwQ@mail.gmail.com>
 <94886a07-29bd-b119-99e3-57452d3507ee@gmail.com>
 <CADreqiweOFxqNCv1Q8HmjSrBoU63Rcz5cMgJPrtUiEiApuZ4MQ@mail.gmail.com>
 <d8d0377a-d42d-eac5-2e7c-4327d0f4fe3f@gmail.com>
 <CADreqiwvT8zPBnjWt5Wzq6W1=7oDMbgb1eRSYqNPpufniA11ug@mail.gmail.com>
 <978ca723-4350-bfca-32e4-9b1cc51a68c7@gmail.com>
Message-ID: <CADreqixjLR-JhEhJuF-kbT3GTNfHyNsuKFk47fotcY3Ee9wJyw@mail.gmail.com>

Many thanks, I wasn't aware of this. Looking forward to one day trying
the same data with the family=Poisson-inverse-Gamma().

Much appreciated,
Tim M

On Mon, May 15, 2023 at 7:52?PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    By default (the re.form argument to predict() is set to NULL), the
> predictions include the random effects.  So a 'newdata' data frame like:
>
> ELs   Document  District
> 20    1         NA
> 20    2         NA
> 20    3         NA
>
> would give you the predicted values for document 1, 2, 3, given ELs =
> 20, and making a population-level prediction for District (i.e. *not*
> using the District RE/setting this info to 0)
>
> On 2023-05-15 8:46 p.m., Timothy MacKenzie wrote:
> > I'm likely misunderstanding your recommendation for using predict()
> > for each Document. If our model has no fixed effect for Document, I'm
> > wondering how then we can predict() how often each document is
> > downloaded?
> >
> > Do you mean averaging across predictions for each category of Document as in:
> >
> > library(dplyr)
> > data.frame(d, fitted = predict(model, type = "response")) %>%
> >    group_by(Document) %>% mutate(ave_downs = mean(downs))
> >
> > Tim M
> >
> > model <- glmmTMB(downs ~ I(ELs/20) +
> >                      ## Document +
> >                     (1|District)+
> >                     (1|Document),
> >                   family=truncated_nbinom2(),
> >                   data = d)
> >
> > On Mon, May 15, 2023 at 6:18?PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     In general it doesn't make sense to include any term as both a fixed
> >> effect and a random-effect grouping variable (with a few exceptions).
> >>
> >>     There's no reason you can't examine the model predictions of how
> >> often each document is downloaded (i.e., use predict() with each
> >> document and whatever baseline covariate settings you want)
> >>
> >> On 2023-05-15 6:52 p.m., Timothy MacKenzie wrote:
> >>> Thank you, Ben, that's very helpful. I noticed that you removed the
> >>> fixed effect for "Document", that's, I'm guessing, to improve the
> >>> model fit (ex. avoiding singularity)? I was hoping to explore how many
> >>> times, on average, each unique Document was downloaded. Looks like
> >>> that may not be possible.
> >>>
> >>> Thanks,
> >>> Tim M
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> On Mon, May 15, 2023 at 9:37?AM Ben Bolker <bbolker at gmail.com> wrote:
> >>>>
> >>>>      I don't have any perfect solution, and I don't necessarily recommend
> >>>> the brute-force approach tried below, but a truncated negative binomial
> >>>> (2/quadratic parameterization) seems best. The genpois and nbinom1 are
> >>>> actually wonkiest, in terms of appearance of residuals.
> >>>>      The COM-Poisson below is *very* slow, you might want to skip it (it
> >>>> took 20 minutes to fit on 16 cores, and the results are not that great
> >>>> anyway).
> >>>>      I thought about implementing a Poisson-inverse-Gamma to allow for
> >>>> heavier tails, but haven't gotten around to it yet (it's not trivial ...)
> >>>>      There seems to be something wonky about the reported sigma/Pearson
> >>>> residuals from truncated nbinom2, but the results are OK ...
> >>>>
> >>>> ### Reproducible data and code:
> >>>> d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
> >>>> library(glmmTMB)
> >>>> library(purrr)
> >>>> library(broom.mixed)
> >>>> library(dplyr)
> >>>> library(DHARMa)
> >>>>
> >>>> model <- glmmTMB(downs ~ I(ELs/20) +
> >>>>                        ## Document +
> >>>>                        (1|District) +
> >>>>                        (1|Document),
> >>>>                    family=genpois(),
> >>>>                         #  ziformula = ~ Document,
> >>>>                      # dispformula = ~ Document,
> >>>>                    data = d)
> >>>>
> >>>> ## very slow ...
> >>>> system.time(model2 <- update(model, family = "compois",
> >>>>                                 control = glmmTMBControl(parallel = 16)))
> >>>>
> >>>> ##      user    system   elapsed
> >>>> ## 17194.076    11.103  1134.367
> >>>>
> >>>> ## truncated genpois doesn't work for some reason ...
> >>>> fam <- c("genpois", "poisson", "nbinom1", "nbinom2")
> >>>> fam <- c(fam, paste0("truncated_", fam[-1]))
> >>>> mod_list <- lapply(fam,
> >>>>                       function(f) {
> >>>>                           cat(f, "\n")
> >>>>                           update(model, family = f)
> >>>> })
> >>>> names(mod_list) <- fam
> >>>> mod_list[["compois"]] <- model2
> >>>>
> >>>>
> >>>> aictab <- (map_dfr(mod_list, glance, .id = "family")
> >>>>        |> select(-c(nobs,logLik, BIC))
> >>>>        |> mutate(across(c(AIC, deviance), ~ . - min(., na.rm = TRUE)))
> >>>>        |> arrange(AIC)
> >>>> )
> >>>>
> >>>> ##   family              sigma   AIC df.residual deviance
> >>>> ##   <chr>               <dbl> <dbl>       <int>    <dbl>
> >>>> ## 1 truncated_nbinom2 3.66e-8    0          569      NA
> >>>> ## 2 nbinom2           1.39e+0  665.         569       0
> >>>> ## 3 compois           5.29e+9  682.         569      NA
> >>>> ## 4 genpois           1.33e+1  768.         569      NA
> >>>> ## 5 nbinom1           8.11e+0  981.         569     191.
> >>>> ## 6 truncated_poisson 1   e+0 1996.         570      NA
> >>>> ## 7 poisson           1   e+0 2553.         570    2077.
> >>>> ## 8 truncated_nbinom1 7.84e+0   NA          569      NA
> >>>>
> >>>> tnb <- mod_list[["truncated_nbinom2"]]
> >>>> ## Pearson resid calc messed up ???
> >>>> plot(resid(tnb,type="pearson") ~ fitted(tnb))
> >>>>
> >>>> plot(d$downs, predict(tnb, type = "response"), log = "xy")
> >>>> abline(a=0, b=1, col = 2)
> >>>>
> >>>> ## reorder
> >>>> mod_list <- mod_list[aictab$family]
> >>>> op <- par(mfrow = c(3, 3), mfrow = c(3,2,1,1), las = 1)
> >>>> lapply(mod_list,
> >>>>           function(m) plot(resid(m,type="pearson") ~ fitted(m),
> >>>>                            xlab = "", ylab = "", main = family(m)$family)
> >>>>           )
> >>>>
> >>>>
> >>>> ## DHARMa
> >>>> ss <- simulateResiduals(tnb)
> >>>> plot(ss)
> >>>> plotResiduals(ss, form = d$ELs/20)
> >>>>
> >>>>
> >>>>
> >>>> On 2023-05-13 11:55 p.m., Timothy MacKenzie wrote:
> >>>>> Greetings,
> >>>>>
> >>>>> I'm modeling the number of downloads (downs) of certain forms
> >>>>> (Document) by a number of school districts (District) of various
> >>>>> student sizes (ELs).
> >>>>>
> >>>>> I've tried genpois(), nbinom1(), and nbinom2() families but the fitted
> >>>>> vs. residual doesn't look promising.
> >>>>>
> >>>>> In glmmTMB, are there any additional ways to improve the residual
> >>>>> distribution for count-type data?
> >>>>>
> >>>>> Thank you,
> >>>>> Tim M
> >>>>> ### Reproducible data and code:
> >>>>> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/b.csv")
> >>>>>
> >>>>> model = glmmTMB(downs ~ I(ELs/20) + Document +
> >>>>>                               (1|District) +
> >>>>>                               (1|Document),
> >>>>>                             family=genpois(),
> >>>>>                         #  ziformula = ~ Document,
> >>>>>                      # dispformula = ~ Document,
> >>>>>                             data = d)
> >>>>>
> >>>>> plot(resid(model,type="pearson") ~ fitted(model))
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>> --
> >>>> Dr. Benjamin Bolker
> >>>> Professor, Mathematics & Statistics and Biology, McMaster University
> >>>> Director, School of Computational Science and Engineering
> >>>> (Acting) Graduate chair, Mathematics & Statistics
> >>>>    > E-mail is sent at my convenience; I don't expect replies outside of
> >>>> working hours.
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >> (Acting) Graduate chair, Mathematics & Statistics
> >>   > E-mail is sent at my convenience; I don't expect replies outside of
> >> working hours.
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.


From h|b@n@b||@2 @end|ng |rom gm@||@com  Tue May 16 15:27:54 2023
From: h|b@n@b||@2 @end|ng |rom gm@||@com (nabila hiba)
Date: Tue, 16 May 2023 15:27:54 +0200
Subject: [R-sig-ME] (no subject)
Message-ID: <CALm_Up=AHXLm6xbS+kHxUWKvvX+AmBBUbRYSTZxJ8JOHRCeV5Q@mail.gmail.com>

Hi Everyone;
I am working on Species Distribution modeling on the correlative approach
and especially the abundance models.
I need to transform a numeric variable into ordinal information. Can you
please recommend me R packages that can help me do that? and how to do it ?
thank you

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue May 16 15:34:39 2023
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 16 May 2023 15:34:39 +0200
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CALm_Up=AHXLm6xbS+kHxUWKvvX+AmBBUbRYSTZxJ8JOHRCeV5Q@mail.gmail.com>
References: <CALm_Up=AHXLm6xbS+kHxUWKvvX+AmBBUbRYSTZxJ8JOHRCeV5Q@mail.gmail.com>
Message-ID: <CAJuCY5xE1EZ5byecQGUNQ1aoKaziiGzSk342KdXwYy4vpWAgqw@mail.gmail.com>

Dear Nabila,

Base R has the cut() function which does exactly that.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 16 mei 2023 om 15:28 schreef nabila hiba <hibanabila2 at gmail.com>:

> Hi Everyone;
> I am working on Species Distribution modeling on the correlative approach
> and especially the abundance models.
> I need to transform a numeric variable into ordinal information. Can you
> please recommend me R packages that can help me do that? and how to do it ?
> thank you
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From t|bor@k|@@ @end|ng |rom ruhr-un|-bochum@de  Thu May 18 13:09:55 2023
From: t|bor@k|@@ @end|ng |rom ruhr-un|-bochum@de (Tibor Kiss)
Date: Thu, 18 May 2023 13:09:55 +0200
Subject: [R-sig-ME] Specification of Random structure in glmer()
Message-ID: <33BC1930-F039-4905-8A1A-5D77855FDB5A@ruhr-uni-bochum.de>

Dear List Members,

I am somewhat confused about the random structures of two models. I?ll try to explain the problem without the code, which is available at https://github.com/Linguistic-Data-Science-Lab/SimRandom. 

I am assuming a binomial model with glmer with random slopes for subjects for two treatment coded factors (A, B) with two values (A1, A2, and B1, B2, respectively, A1 and B1 being reference levels) and their interaction as follows:

M1: glmer(CHOICE ~ A * B + (0 + A * B | subjects) + (1 | items), data = ..., family = ?) 

For this model, I am getting a random values for all four combinations A1B1, ?, A2B2 for the subjects.

I have also defined another model, which only differs from the first one in the treatment of the intercept in the random structure:

M2: glmer(predicted_value ~ A * B + (1 + A * B | subjects) + (1 | items), data = ..., family = ?) 

Now I would expect that the random slopes for the two models are related as follows (illustrated here for A2B1):

random slope for A2B1(M1) = random intercept for A1B1(M2) + random slope for A2B1(M2) 

This works out for the random intercept and the first random slope in M2. As an illustration consider the first subject:

A2B1(M1) = -0.05; intercept(M2) = 0.11, A2B1(M2) = -0.16.

Now I would expect that these equivalences hold for the other random slopes as well, but the values for the random slopes of A1B2 and A2B2 are identical in both models.  

I would have expected A1B2(M1) = A1B1(M2) + A1B2(M2), but instead, it is A1B2(M1) = A1B2(M2).  
I would also have expected A2B2(M1) = A1B1(M2) + A2B1(M2) + A1B2(M2) + A2B2(M2), but again, what I get is A2B2(M1) = A2B2(M2).

My question is: is my specification of the models wrong or is there something else that I have missed?


Thank you very much


Tibor


From j|@ver|@@|mo @end|ng |rom gm@||@com  Thu May 18 13:59:10 2023
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Thu, 18 May 2023 12:59:10 +0100
Subject: [R-sig-ME] Specification of Random structure in glmer()
In-Reply-To: <33BC1930-F039-4905-8A1A-5D77855FDB5A@ruhr-uni-bochum.de>
References: <33BC1930-F039-4905-8A1A-5D77855FDB5A@ruhr-uni-bochum.de>
Message-ID: <039942fb-6e31-6a12-1b1a-bab4a9f7c8c7@gmail.com>

- With treatment contrasts, the formula 0 + A * B yields the following 
estimates (this holds for the fixed or random effects):
cell A1/B1 ("AA1")
cell A1/B2 ("AA2")
B2 - B1, for A1 ("BB2")
interaction ("AA2:BB2")

- The formula 1 + A*B yields:
cell A1/B1 ("(Intercept)")
A2 - A1, for B1 ("AA2")
B2 - B1, for A1 ("BB2")
interaction ("AA2:BB2")

So only one of the estimates is different in the two models, and only 
for that one you get the relationship that you were expecting.

Jo?o

On 18/05/2023 12:09, Tibor Kiss via R-sig-mixed-models wrote:
> Dear List Members,
>
> I am somewhat confused about the random structures of two models. I?ll try to explain the problem without the code, which is available athttps://github.com/Linguistic-Data-Science-Lab/SimRandom.
>
> I am assuming a binomial model with glmer with random slopes for subjects for two treatment coded factors (A, B) with two values (A1, A2, and B1, B2, respectively, A1 and B1 being reference levels) and their interaction as follows:
>
> M1: glmer(CHOICE ~ A * B + (0 + A * B | subjects) + (1 | items), data = ..., family = ?)
>
> For this model, I am getting a random values for all four combinations A1B1, ?, A2B2 for the subjects.
>
> I have also defined another model, which only differs from the first one in the treatment of the intercept in the random structure:
>
> M2: glmer(predicted_value ~ A * B + (1 + A * B | subjects) + (1 | items), data = ..., family = ?)
>
> Now I would expect that the random slopes for the two models are related as follows (illustrated here for A2B1):
>
> random slope for A2B1(M1) = random intercept for A1B1(M2) + random slope for A2B1(M2)
>
> This works out for the random intercept and the first random slope in M2. As an illustration consider the first subject:
>
> A2B1(M1) = -0.05; intercept(M2) = 0.11, A2B1(M2) = -0.16.
>
> Now I would expect that these equivalences hold for the other random slopes as well, but the values for the random slopes of A1B2 and A2B2 are identical in both models.
>
> I would have expected A1B2(M1) = A1B1(M2) + A1B2(M2), but instead, it is A1B2(M1) = A1B2(M2).
> I would also have expected A2B2(M1) = A1B1(M2) + A2B1(M2) + A1B2(M2) + A2B2(M2), but again, what I get is A2B2(M1) = A2B2(M2).
>
> My question is: is my specification of the models wrong or is there something else that I have missed?
>
>
> Thank you very much
>
>
> Tibor
>
> _______________________________________________
> R-sig-mixed-models at r-project.org  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
*Jo?o Ver?ssimo*
Assistant Professor | /Professor Auxiliar/
School of Arts and Humanities | /Faculdade de Letras/
University of Lisbon | /Universidade de Lisboa/
	[[alternative HTML version deleted]]


From j|@ver|@@|mo @end|ng |rom gm@||@com  Thu May 18 14:05:51 2023
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Thu, 18 May 2023 13:05:51 +0100
Subject: [R-sig-ME] Specification of Random structure in glmer()
In-Reply-To: <039942fb-6e31-6a12-1b1a-bab4a9f7c8c7@gmail.com>
References: <33BC1930-F039-4905-8A1A-5D77855FDB5A@ruhr-uni-bochum.de>
 <039942fb-6e31-6a12-1b1a-bab4a9f7c8c7@gmail.com>
Message-ID: <44d7e1b8-424b-1cb4-a805-68d89f304926@gmail.com>

Sorry, typo. For 0 + A*B that should read:
cell A1/B1 ("AA1")
cell A2/B1 ("AA2")????????? <- had typo in previous reply
B2 - B1, for A1 ("BB2")
interaction ("AA2:BB2")


On 18/05/2023 12:59, Jo?o Ver?ssimo wrote:
> - With treatment contrasts, the formula 0 + A * B yields the following 
> estimates (this holds for the fixed or random effects):
> cell A1/B1 ("AA1")
> cell A1/B2 ("AA2")
> B2 - B1, for A1 ("BB2")
> interaction ("AA2:BB2")
>
> - The formula 1 + A*B yields:
> cell A1/B1 ("(Intercept)")
> A2 - A1, for B1 ("AA2")
> B2 - B1, for A1 ("BB2")
> interaction ("AA2:BB2")
>
> So only one of the estimates is different in the two models, and only 
> for that one you get the relationship that you were expecting.
>
> Jo?o
>
> On 18/05/2023 12:09, Tibor Kiss via R-sig-mixed-models wrote:
>> Dear List Members,
>>
>> I am somewhat confused about the random structures of two models. I?ll try to explain the problem without the code, which is available athttps://github.com/Linguistic-Data-Science-Lab/SimRandom.
>>
>> I am assuming a binomial model with glmer with random slopes for subjects for two treatment coded factors (A, B) with two values (A1, A2, and B1, B2, respectively, A1 and B1 being reference levels) and their interaction as follows:
>>
>> M1: glmer(CHOICE ~ A * B + (0 + A * B | subjects) + (1 | items), data = ..., family = ?)
>>
>> For this model, I am getting a random values for all four combinations A1B1, ?, A2B2 for the subjects.
>>
>> I have also defined another model, which only differs from the first one in the treatment of the intercept in the random structure:
>>
>> M2: glmer(predicted_value ~ A * B + (1 + A * B | subjects) + (1 | items), data = ..., family = ?)
>>
>> Now I would expect that the random slopes for the two models are related as follows (illustrated here for A2B1):
>>
>> random slope for A2B1(M1) = random intercept for A1B1(M2) + random slope for A2B1(M2)
>>
>> This works out for the random intercept and the first random slope in M2. As an illustration consider the first subject:
>>
>> A2B1(M1) = -0.05; intercept(M2) = 0.11, A2B1(M2) = -0.16.
>>
>> Now I would expect that these equivalences hold for the other random slopes as well, but the values for the random slopes of A1B2 and A2B2 are identical in both models.
>>
>> I would have expected A1B2(M1) = A1B1(M2) + A1B2(M2), but instead, it is A1B2(M1) = A1B2(M2).
>> I would also have expected A2B2(M1) = A1B1(M2) + A2B1(M2) + A1B2(M2) + A2B2(M2), but again, what I get is A2B2(M1) = A2B2(M2).
>>
>> My question is: is my specification of the models wrong or is there something else that I have missed?
>>
>>
>> Thank you very much
>>
>>
>> Tibor
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -- 
> *Jo?o Ver?ssimo*
> Assistant Professor | /Professor Auxiliar/
> School of Arts and Humanities | /Faculdade de Letras/
> University of Lisbon | /Universidade de Lisboa/

-- 
*Jo?o Ver?ssimo*
Assistant Professor | /Professor Auxiliar/
School of Arts and Humanities | /Faculdade de Letras/
University of Lisbon | /Universidade de Lisboa/
	[[alternative HTML version deleted]]


From d@n|e|@j@ck@on1 @end|ng |rom @@tr@zenec@@com  Fri May 26 11:33:33 2023
From: d@n|e|@j@ck@on1 @end|ng |rom @@tr@zenec@@com (Jackson, Daniel)
Date: Fri, 26 May 2023 09:33:33 +0000
Subject: [R-sig-ME] Toeplitz covariance structure
Message-ID: <VE1PR04MB74539C10FDDD76901F008368B3479@VE1PR04MB7453.eurprd04.prod.outlook.com>

Dear r-sig-mixed-models

I am interested in fitting a model with the Toeplitz covariance structure, using the gls function from the nlme package. I took an example from here

Mixed model repeated measures (MMRM) in Stata, SAS and R - The Stats Geek<https://thestatsgeek.com/2020/12/30/mixed-model-repeated-measures-mmrm-in-stata-sas-and-r/>

And

Mixed models repeated measures (mmrm) package for R - The Stats Geek<https://thestatsgeek.com/2022/10/31/mixed-models-repeated-measures-mmrm-package-for-r/>

I have tried fitting the model using both the new mmrm and the gls function, codes are below. But I have some questions


  1.  Am I correct in specifying the covariance structure using a corARMA structure with p = "number of visits" - 1 and q=0?
  2.  All estimates using my proposed gls implementation and the mmrm package seem to agree well except the Phi reported by gls do not seem to be in agreement with the correlation coefficients implied by the mmrm package? Are the Phi a transformation of the correlations?

Many thanks, code below:

# Code taken from/inspired by The stats geek website
# simulate data
###############################################################################################
expit <- function(x) {
  exp(x)/(1+exp(x))
}

set.seed(1234)
n <- 500
library(MASS)
#we will make correlation with baseline the same to visit 1 and visit 2
corr <- matrix(1, nrow=4, ncol=4) + diag(0.5, nrow=4)
corr
data <- mvrnorm(n, mu=c(0,0,0,0), Sigma=corr)

trt <- 1*(runif(n)<0.5)
y0 <- data[,1]
y1 <- data[,2]
y2 <- data[,3]
y3 <- data[,4]

#add in effect of treatment
y1 <- y1+trt*0.5
y2 <- y2+trt*1
y3 <- y3+trt*1.5

#now make some patients dropout before visit 1
#r1=1 indicates visit 1 observed
r1 <- 1*(runif(n)<expit(3-y0))

#dropout before visit 2, based on change from y0 to y1
r2 <- 1*(runif(n)<expit(3-(y1-y0)))
r2[r1==0] <- 0

#dropout before visit 3, based on change from y1 to y2
r3 <- 1*(runif(n)<expit(3-(y2-y1)))
r3[r2==0] <- 0

y1[r1==0] <- NA
y2[r2==0] <- NA
y3[r3==0] <- NA

wideData <- data.frame(id=1:n, trt=trt, y0=y0, y1=y1, y2=y2, y3=y3)
summary(wideData)

longData <- reshape(wideData, varying=c("y1", "y2", "y3"),
                    direction="long", sep="", idvar="id")
longData <- longData[order(longData$trt,longData$id,longData$time),]


## use gls - but is this correct? - p=2 because 3 visits and q=0 is correct?
require(nlme)
mmrm_toe <- gls(y~y0*factor(time)+trt*factor(time),
            na.action=na.omit, data=longData,
            correlation=nlme::corARMA(p=2, q=0, form=~time | id),
            weights=nlme::varIdent(form=~1|time))
summary(mmrm_toe)
## use mmrm package
library(mmrm)
#To fit the same model using the new mmrm package, I discovered I first needed to convert the id, time and trt variables to factors. I then fitted the MMRM model using:
longData_factor<-longData
longData_factor$time<-factor(longData_factor$time)
longData_factor$id<-factor(longData_factor$id)
longData_factor$trt<-factor(longData_factor$trt)



mmrm_new_toe <- mmrm(y~y0*time+trt*time+toeph(time|id), data=longData_factor)
summary(mmrm_new_toe)

## Questions: is gls implementation correct and why do Phi reported not seem to agree with correlations from mmrm?

Dan Jackson

________________________________

AstraZeneca UK Limited is a company incorporated in Engl...{{dropped:16}}


From @pr||m@rt|n|g @end|ng |rom hotm@||@com  Sun Jun  4 02:44:18 2023
From: @pr||m@rt|n|g @end|ng |rom hotm@||@com (April Martinig)
Date: Sun, 4 Jun 2023 00:44:18 +0000
Subject: [R-sig-ME] Selecting a family in glmmTMB for continuous proportion
 data that includes 0 and 1
Message-ID: <CY8PR19MB7034F883BB49286C3A46B744AA4CA@CY8PR19MB7034.namprd19.prod.outlook.com>

Hello,

I?ve noticed several questions about fitting proportion data with glmmTMB.

Every question I?ve encountered has been focused on 0 < x < 1. However, my data included 0 and 1. I am currently using "family=beta_family(link="logit"), ziformula= ~1? after making the 0s slightly non-zero (0.00001) and the 1s slightly smaller (0.99999) - I tried the solutions under zero inflation continuous data https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#continuous-data.

However, is there a way to appropriately fit the data as is (true zeros and true ones)?

I?ve attached an image of the distribution of the data.

Any suggestions would be much appreciated!

Take care,
April

?
Dr. April Martinig, Ph.D., M.Sc.
Postdoctoral fellow
University of New South Wales
martinig.weebly.com<http://martinig.weebly.com>
?I do not accept the conventional order of things as a given."


-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.pdf
Type: application/pdf
Size: 96651 bytes
Desc: plot.pdf
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20230604/35bfa505/attachment-0001.pdf>

From jh@|t|g@ @end|ng |rom gm@||@com  Sun Jun  4 06:10:46 2023
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sun, 4 Jun 2023 00:10:46 -0400
Subject: [R-sig-ME] ICC in lmer
Message-ID: <CAH_7VOkGSmc7P-M-G4CL2BSUaOj7K4C6a_+qGkhLSFE2snCD7w@mail.gmail.com>

Hi:

This may have already been covered though I did not see it in the archives
after a quick search. For linear mixed models, is there a way to get lmer
to calculate the ICC automatically so as to appear in the summary output?

Thanks,
JD

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Sun Jun  4 11:23:29 2023
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Sun, 4 Jun 2023 11:23:29 +0200
Subject: [R-sig-ME] [EXT]  ICC in lmer
In-Reply-To: <CAH_7VOkGSmc7P-M-G4CL2BSUaOj7K4C6a_+qGkhLSFE2snCD7w@mail.gmail.com>
References: <CAH_7VOkGSmc7P-M-G4CL2BSUaOj7K4C6a_+qGkhLSFE2snCD7w@mail.gmail.com>
Message-ID: <000c01d996c6$397bb580$ac732080$@uke.de>

The `summary()` method does not include the ICC. You can, however, use
`performance::icc()` (see
https://easystats.github.io/performance/reference/icc.html) to compute the
ICC; or use packages that create summary outputs including ICC, like the
modelsummary package. The parameters package, which returns "tidy" data
frames of regression results (similar to broom, but with more extra features
and nice printing) at least includes marginal/conditional R2.

library(lme4)
library(modelsummary)
library(parameters)

m <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)
modelsummary(m)
model_parameters(m, summary = TRUE)

Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von J.D. Haltigan
Gesendet: Sonntag, 4. Juni 2023 06:11
An: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Betreff: [EXT] [R-sig-ME] ICC in lmer

Hi:

This may have already been covered though I did not see it in the archives
after a quick search. For linear mixed models, is there a way to get lmer
to calculate the ICC automatically so as to appear in the summary output?

Thanks,
JD

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From d@|uedecke @end|ng |rom uke@de  Sun Jun  4 11:29:27 2023
From: d@|uedecke @end|ng |rom uke@de (=?utf-8?Q?Daniel_L=C3=BCdecke?=)
Date: Sun, 4 Jun 2023 11:29:27 +0200
Subject: [R-sig-ME] [EXT] Selecting a family in glmmTMB for continuous
 proportion data that includes 0 and 1
In-Reply-To: <CY8PR19MB7034F883BB49286C3A46B744AA4CA@CY8PR19MB7034.namprd19.prod.outlook.com>
References: <CY8PR19MB7034F883BB49286C3A46B744AA4CA@CY8PR19MB7034.namprd19.prod.outlook.com>
Message-ID: <000d01d996c7$0f5f9180$2e1eb480$@uke.de>

You can use the ordered beta family (https://doi.org/10.1017/pan.2022.20), which is implemented in glmmTMB (family = ordbeta()).

 

I also setup a page with overviews of modelling packages/functions for various outcome types:

http://htmlpreview.github.io/?https://github.com/strengejacke/mixed-models-snippets/blob/master/overview_modelling_packages.html

 

(comments welcome)

 

Daniel

 

Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von April Martinig
Gesendet: Sonntag, 4. Juni 2023 02:44
An: r-sig-mixed-models at r-project.org
Betreff: [EXT] [R-sig-ME] Selecting a family in glmmTMB for continuous proportion data that includes 0 and 1

 

Hello,

I?ve noticed several questions about fitting proportion data with glmmTMB.

Every question I?ve encountered has been focused on 0 < x < 1. However, my data included 0 and 1. I am currently using "family=beta_family(link="logit"), ziformula= ~1? after making the 0s slightly non-zero (0.00001) and the 1s slightly smaller (0.99999) - I tried the solutions under zero inflation continuous data https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#continuous-data.

However, is there a way to appropriately fit the data as is (true zeros and true ones)?

I?ve attached an image of the distribution of the data.

Any suggestions would be much appreciated!

Take care,
April

?
Dr. April Martinig, Ph.D., M.Sc.
Postdoctoral fellow
University of New South Wales
martinig.weebly.com<http://martinig.weebly.com>
?I do not accept the conventional order of things as a given."

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From roberto@me@eguer @end|ng |rom ud|@c@t  Sun Jun  4 22:43:15 2023
From: roberto@me@eguer @end|ng |rom ud|@c@t (Roberto Meseguer Rosagro)
Date: Sun, 4 Jun 2023 20:43:15 +0000
Subject: [R-sig-ME] Spatial autocorrelation correction lme4
Message-ID: <AM6PR09MB258146D1E68F37B0A39DBC76994CA@AM6PR09MB2581.eurprd09.prod.outlook.com>

Dear Dr. Bolker,

As you are one of the authors of the lme4 package and you are so active in Stack Overflow, I'm reaching you for the following reason (any help would be appreciated):

I'm building a GLMM (family=Gamma) in lme4 package with some spatially autocorrelated data. Is there any correction that can be applied to the model within this package?

I know the package nlme has this possibility, but it is not suitable for the Gamma distribution. That's why I ran my global model using the function glmmPQL, from the MASS package (is appropriate for GLMM, and you can use the same structures than in nlme package, so I finally could apply the correction). The problem is that, as glmmPQL uses Penalized Quasi-Likelihood, it doesn't compute an AIC nor a BIC criterion to your global model; so then you cannot dredge it to average the models with ?AIC < 2, as glmmPQL global model has not AIC!

That is why I am wondering if there is any workaround to apply a correction for spatially autocorrelated data to my global lme4 model.

Sorry for the inconvenience and thanks for your attention.

Best regards.

Roberto Meseguer


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jun  4 22:50:01 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 4 Jun 2023 16:50:01 -0400
Subject: [R-sig-ME] Spatial autocorrelation correction lme4
In-Reply-To: <AM6PR09MB258146D1E68F37B0A39DBC76994CA@AM6PR09MB2581.eurprd09.prod.outlook.com>
References: <AM6PR09MB258146D1E68F37B0A39DBC76994CA@AM6PR09MB2581.eurprd09.prod.outlook.com>
Message-ID: <b0db6be9-ecf0-17f9-b9a3-ee9f85fef15d@gmail.com>

    (Note the list is not just me! -- I should have mentioned that when 
I asked you to forward this e-mail to the mailing list ...)

   The CRAN mixed models task view 
https://cran.r-project.org/web/views/MixedModels.html lists the 
following packages:

Spatial models: nlme (with corStruct functions), CARBayesST, sphet, 
spind, spaMM, glmmfields, glmmTMB, inlabru (spatial point processes via 
log-Gaussian Cox processes), brms, LMMsolver, bamlss; see also the 
Spatial and SpatioTemporal CRAN task views.

   These don't all handle GLMMs, but many of them do.  glmmTMB or spaMM 
might be the quickest to adapt.

   There is a vignette about quasi-AIC associated with the bbmle 
package, but it's not very optimistic about the effort it would take to 
get a qAIC out of a glmmPQL fit: 
https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf



On 2023-06-04 4:43 p.m., Roberto Meseguer Rosagro wrote:
> Dear Dr. Bolker,
> 
> As you are one of the authors of the lme4 package and you are so active in Stack Overflow, I'm reaching you for the following reason (any help would be appreciated):
> 
> I'm building a GLMM (family=Gamma) in lme4 package with some spatially autocorrelated data. Is there any correction that can be applied to the model within this package?
> 
> I know the package nlme has this possibility, but it is not suitable for the Gamma distribution. That's why I ran my global model using the function glmmPQL, from the MASS package (is appropriate for GLMM, and you can use the same structures than in nlme package, so I finally could apply the correction). The problem is that, as glmmPQL uses Penalized Quasi-Likelihood, it doesn't compute an AIC nor a BIC criterion to your global model; so then you cannot dredge it to average the models with ?AIC < 2, as glmmPQL global model has not AIC!
> 
> That is why I am wondering if there is any workaround to apply a correction for spatially autocorrelated data to my global lme4 model.
> 
> Sorry for the inconvenience and thanks for your attention.
> 
> Best regards.
> 
> Roberto Meseguer
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Mon Jun  5 03:37:47 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 4 Jun 2023 21:37:47 -0400
Subject: [R-sig-ME] Toeplitz covariance structure
In-Reply-To: <VE1PR04MB74539C10FDDD76901F008368B3479@VE1PR04MB7453.eurprd04.prod.outlook.com>
References: <VE1PR04MB74539C10FDDD76901F008368B3479@VE1PR04MB7453.eurprd04.prod.outlook.com>
Message-ID: <e654e07d-2eba-aea3-1d85-618b8a452f8e@gmail.com>

   I will admit that I am having trouble getting the connection between 
the phi parameters and the correlations.  However, the fitted models 
(and their implied correlation matrices) are the same:

all.equal(c(logLik(mmrm_toe)), logLik(mmrm_new_toe))

all.equal(unclass(v1 <- getVarCov(mmrm_toe)),
           unname(v2 <- VarCorr(mmrm_new_toe)),
           tolerance = 1e-5)

cs <- mmrm_toe$modelStruct$corStruct
cc


Pinheiro and Bates (2009, via Google Books) say

## for AR models of order greater than 1, the correlation function
## does not admit a simple representation ... being defined recursively
## through the difference equation (Box et al., 1994, Sec 3.2.2)

## h(k, Phi) = phi_1*h(|k-1|,Phi) + ... + phi_p*h(|k-p|,Phi), k = 1,2,...

I don't understand this yet ... would have expected correlations phi1, 
phi1^2 + phi2, ....

   glmmTMB *should* be able to do this as well but I haven't succeeded 
in making the results match ...

On 2023-05-26 5:33 a.m., Jackson, Daniel wrote:
> Dear r-sig-mixed-models
> 
> I am interested in fitting a model with the Toeplitz covariance structure, using the gls function from the nlme package. I took an example from here
> 
> Mixed model repeated measures (MMRM) in Stata, SAS and R - The Stats Geek<https://thestatsgeek.com/2020/12/30/mixed-model-repeated-measures-mmrm-in-stata-sas-and-r/>
> 
> And
> 
> Mixed models repeated measures (mmrm) package for R - The Stats Geek<https://thestatsgeek.com/2022/10/31/mixed-models-repeated-measures-mmrm-package-for-r/>
> 
> I have tried fitting the model using both the new mmrm and the gls function, codes are below. But I have some questions
> 
> 
>    1.  Am I correct in specifying the covariance structure using a corARMA structure with p = "number of visits" - 1 and q=0?
>    2.  All estimates using my proposed gls implementation and the mmrm package seem to agree well except the Phi reported by gls do not seem to be in agreement with the correlation coefficients implied by the mmrm package? Are the Phi a transformation of the correlations?
> 
> Many thanks, code below:
> 
> # Code taken from/inspired by The stats geek website
> # simulate data
> ###############################################################################################
> expit <- function(x) {
>    exp(x)/(1+exp(x))
> }
> 
> set.seed(1234)
> n <- 500
> library(MASS)
> #we will make correlation with baseline the same to visit 1 and visit 2
> corr <- matrix(1, nrow=4, ncol=4) + diag(0.5, nrow=4)
> corr
> data <- mvrnorm(n, mu=c(0,0,0,0), Sigma=corr)
> 
> trt <- 1*(runif(n)<0.5)
> y0 <- data[,1]
> y1 <- data[,2]
> y2 <- data[,3]
> y3 <- data[,4]
> 
> #add in effect of treatment
> y1 <- y1+trt*0.5
> y2 <- y2+trt*1
> y3 <- y3+trt*1.5
> 
> #now make some patients dropout before visit 1
> #r1=1 indicates visit 1 observed
> r1 <- 1*(runif(n)<expit(3-y0))
> 
> #dropout before visit 2, based on change from y0 to y1
> r2 <- 1*(runif(n)<expit(3-(y1-y0)))
> r2[r1==0] <- 0
> 
> #dropout before visit 3, based on change from y1 to y2
> r3 <- 1*(runif(n)<expit(3-(y2-y1)))
> r3[r2==0] <- 0
> 
> y1[r1==0] <- NA
> y2[r2==0] <- NA
> y3[r3==0] <- NA
> 
> wideData <- data.frame(id=1:n, trt=trt, y0=y0, y1=y1, y2=y2, y3=y3)
> summary(wideData)
> 
> longData <- reshape(wideData, varying=c("y1", "y2", "y3"),
>                      direction="long", sep="", idvar="id")
> longData <- longData[order(longData$trt,longData$id,longData$time),]
> 
> 
> ## use gls - but is this correct? - p=2 because 3 visits and q=0 is correct?
> require(nlme)
> mmrm_toe <- gls(y~y0*factor(time)+trt*factor(time),
>              na.action=na.omit, data=longData,
>              correlation=nlme::corARMA(p=2, q=0, form=~time | id),
>              weights=nlme::varIdent(form=~1|time))
> summary(mmrm_toe)
> ## use mmrm package
> library(mmrm)
> #To fit the same model using the new mmrm package, I discovered I first needed to convert the id, time and trt variables to factors. I then fitted the MMRM model using:
> longData_factor<-longData
> longData_factor$time<-factor(longData_factor$time)
> longData_factor$id<-factor(longData_factor$id)
> longData_factor$trt<-factor(longData_factor$trt)
> 
> 
> 
> mmrm_new_toe <- mmrm(y~y0*time+trt*time+toeph(time|id), data=longData_factor)
> summary(mmrm_new_toe)
> 
> ## Questions: is gls implementation correct and why do Phi reported not seem to agree with correlations from mmrm?
> 
> Dan Jackson
> 
> ________________________________
> 
> AstraZeneca UK Limited is a company incorporated in Engl...{{dropped:16}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |@w|@wt @end|ng |rom gm@||@com  Fri Jun  9 21:29:20 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Fri, 9 Jun 2023 14:29:20 -0500
Subject: [R-sig-ME] One model of two subsets of data
Message-ID: <CADreqiwGN7Oag4BvEts4ig6G=+p2HqWH0-PJNOUC732AE4W7kQ@mail.gmail.com>

Hello All,

I have two questions:

First, I was wondering if "model_2" (even subset of items in model_1)
and "model_3" (odd subset of items in model_1) results (fixed and
random) can be derived from model_1?

Second, from "model_2" and "model_3", suppose I draw the `Subject`
random effects and correlate them:

ranef_model_2_even = data.frame(ranef(model_2)$Subject)
ranef_model_2_even$Subject <- row.names(ranef_model_2_even)
ranef_model_3_odd = data.frame(ranef(model_3)$Subject)
ranef_model_3_odd$Subject <- row.names(ranef_model_3_odd)

Subject = merge(ranef_model_2_even, ranef_model_3_odd, by = "Subject",
suffixes = c("_even", "_odd"))
cor(Subject$Conditionunrelated_even, Subject $Conditionunrelated_odd)
#  [1] 0.849635


**** Could we obtain the latent equivalent of the above correlation
(which may not be numerically the same as 0.849635) from
`VarCorr(model_1)`?

Thank you all, Tim M

## Reproducible data and code:
d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
library(optimx)
library(blme)

model_1 = blmer(I(-1/RT) ~ Condition:item_num +
(Condition:item_num|Subject) + (Condition:item_num|Item), data = d,
             control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))

# Subset 1:
model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
           subset = item_num == "Even")

# Subset 2:
model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
             subset = item_num == "Odd")


From j|@ver|@@|mo @end|ng |rom gm@||@com  Fri Jun  9 21:39:58 2023
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Fri, 9 Jun 2023 21:39:58 +0200
Subject: [R-sig-ME] One model of two subsets of data
In-Reply-To: <CADreqiwGN7Oag4BvEts4ig6G=+p2HqWH0-PJNOUC732AE4W7kQ@mail.gmail.com>
References: <CADreqiwGN7Oag4BvEts4ig6G=+p2HqWH0-PJNOUC732AE4W7kQ@mail.gmail.com>
Message-ID: <b5c11693-d35b-3689-ad18-646995578b29@gmail.com>

I don't know if that can be derived from model1, but I believe with the 
formula
-1/RT ~ item_num / Condition + (item_num / Condition | Subject)
you would be estimating the Condition effects for both 'even' and 'odd' 
item_num, as well as the correlation between the two corresponding 
by-subject random slopes.

-- 
Jo?o Ver?ssimo

On 09/06/2023 21:29, Timothy MacKenzie wrote:
> Hello All,
>
> I have two questions:
>
> First, I was wondering if "model_2" (even subset of items in model_1)
> and "model_3" (odd subset of items in model_1) results (fixed and
> random) can be derived from model_1?
>
> Second, from "model_2" and "model_3", suppose I draw the `Subject`
> random effects and correlate them:
>
> ranef_model_2_even = data.frame(ranef(model_2)$Subject)
> ranef_model_2_even$Subject <- row.names(ranef_model_2_even)
> ranef_model_3_odd = data.frame(ranef(model_3)$Subject)
> ranef_model_3_odd$Subject <- row.names(ranef_model_3_odd)
>
> Subject = merge(ranef_model_2_even, ranef_model_3_odd, by = "Subject",
> suffixes = c("_even", "_odd"))
> cor(Subject$Conditionunrelated_even, Subject $Conditionunrelated_odd)
> #  [1] 0.849635
>
>
> **** Could we obtain the latent equivalent of the above correlation
> (which may not be numerically the same as 0.849635) from
> `VarCorr(model_1)`?
>
> Thank you all, Tim M
>
> ## Reproducible data and code:
> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
> library(optimx)
> library(blme)
>
> model_1 = blmer(I(-1/RT) ~ Condition:item_num +
> (Condition:item_num|Subject) + (Condition:item_num|Item), data = d,
>               control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
>
> # Subset 1:
> model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>             subset = item_num == "Even")
>
> # Subset 2:
> model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>               subset = item_num == "Odd")
>
> _______________________________________________
> R-sig-mixed-models at r-project.org  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
*Jo?o Ver?ssimo*
Assistant Professor | /Professor Auxiliar/
School of Arts and Humanities | /Faculdade de Letras/
University of Lisbon | /Universidade de Lisboa/
	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Sat Jun 10 19:05:33 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Sat, 10 Jun 2023 12:05:33 -0500
Subject: [R-sig-ME] Reducing two mixed models into one
Message-ID: <CADreqix8_TF8b3TPTW_y--SHCFtzyJ7tDHFo1aZrBzje0Q9HrA@mail.gmail.com>

Hello All,

I'm hoping to clarify my prior post to elicit an informative response
from the experts on the list.

Currently, I'm running two models each using a subset of my data (below).

<Question>: Instead of running two separate models, is it possible to
create one model that captures both these separate models?

Thank you,
Tim M
################
d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
library(optimx)
library(blme)

# Subset 1:
model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
           subset = item_num == "Even")

# Subset 2:
model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
             subset = item_num == "Odd")


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jun 12 08:35:31 2023
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 12 Jun 2023 08:35:31 +0200
Subject: [R-sig-ME] Reducing two mixed models into one
In-Reply-To: <CADreqix8_TF8b3TPTW_y--SHCFtzyJ7tDHFo1aZrBzje0Q9HrA@mail.gmail.com>
References: <CADreqix8_TF8b3TPTW_y--SHCFtzyJ7tDHFo1aZrBzje0Q9HrA@mail.gmail.com>
Message-ID: <CAJuCY5z52ka+4=vyTaKx9znui3+3HYWVKO1byMdukAKv226mbw@mail.gmail.com>

Dear Timothy,

Add the interaction with item_num to every parameter and you should have
the same parameterization for both models in a single model.

# gives similar parameters as both models
I(-1/RT) ~ item_num + item_num:Condition + (item_num +
item_num:Condition|Subject)
+ (item_num + item_num:Condition|Item)
# same model fit, different parametrization
I(-1/RT) ~ item_num*Condition + (item_num*Condition|Subject) + (item_num*
Condition|Item)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op za 10 jun 2023 om 19:06 schreef Timothy MacKenzie <fswfswt at gmail.com>:

> Hello All,
>
> I'm hoping to clarify my prior post to elicit an informative response
> from the experts on the list.
>
> Currently, I'm running two models each using a subset of my data (below).
>
> <Question>: Instead of running two separate models, is it possible to
> create one model that captures both these separate models?
>
> Thank you,
> Tim M
> ################
> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
> library(optimx)
> library(blme)
>
> # Subset 1:
> model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) +
> (Condition|Item),
> data = d,
> control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>            subset = item_num == "Even")
>
> # Subset 2:
> model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) +
> (Condition|Item),
> data = d,
> control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>              subset = item_num == "Odd")
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Tue Jun 13 18:36:06 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Tue, 13 Jun 2023 11:36:06 -0500
Subject: [R-sig-ME] Reducing two mixed models into one
In-Reply-To: <CAJuCY5z52ka+4=vyTaKx9znui3+3HYWVKO1byMdukAKv226mbw@mail.gmail.com>
References: <CADreqix8_TF8b3TPTW_y--SHCFtzyJ7tDHFo1aZrBzje0Q9HrA@mail.gmail.com>
 <CAJuCY5z52ka+4=vyTaKx9znui3+3HYWVKO1byMdukAKv226mbw@mail.gmail.com>
Message-ID: <CADreqizdUMbQoeBjPz7rZ5guZSnzGXJMOcuuLykQpPk08JYtOw@mail.gmail.com>

Dear Thierry,

Thank you so much for your highly informative answer. If I may, I
wanted to ask a follow-up question.

Previously, from the two separate models, I used to compute a
correlation (0.849635) between the random slopes of subjects in
'Condition==unrelated' for Odd vs. Even items (shown below).

**Question: Could we obtain the latent equivalent of the above
correlation (which may not be numerically the same as 0.849635) from
`attr(VarCorr(First_Parametrization_Model)$Subject, "correlation")`?

Thank you so much again,
Tim M

ranef_model_2_even = data.frame(ranef(model_2)$Subject)
ranef_model_2_even$Subject <- row.names(ranef_model_2_even)
ranef_model_3_odd = data.frame(ranef(model_3)$Subject)
ranef_model_3_odd$Subject <- row.names(ranef_model_3_odd)

Subject = merge(ranef_model_2_even, ranef_model_3_odd, by = "Subject",
suffixes = c("_even", "_odd"))
cor(Subject$Conditionunrelated_even, Subject $Conditionunrelated_odd)
#  [1] 0.849635





On Mon, Jun 12, 2023 at 1:36?AM Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
>
> Dear Timothy,
>
> Add the interaction with item_num to every parameter and you should have the same parameterization for both models in a single model.
>
> # gives similar parameters as both models
> I(-1/RT) ~ item_num + item_num:Condition + (item_num + item_num:Condition|Subject) + (item_num + item_num:Condition|Item)
> # same model fit, different parametrization
> I(-1/RT) ~ item_num*Condition + (item_num*Condition|Subject) + (item_num*Condition|Item)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> Op za 10 jun 2023 om 19:06 schreef Timothy MacKenzie <fswfswt at gmail.com>:
>>
>> Hello All,
>>
>> I'm hoping to clarify my prior post to elicit an informative response
>> from the experts on the list.
>>
>> Currently, I'm running two models each using a subset of my data (below).
>>
>> <Question>: Instead of running two separate models, is it possible to
>> create one model that captures both these separate models?
>>
>> Thank you,
>> Tim M
>> ################
>> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
>> library(optimx)
>> library(blme)
>>
>> # Subset 1:
>> model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
>> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>>            subset = item_num == "Even")
>>
>> # Subset 2:
>> model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
>> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>>              subset = item_num == "Odd")
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j|@ver|@@|mo @end|ng |rom gm@||@com  Tue Jun 13 19:00:55 2023
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Tue, 13 Jun 2023 19:00:55 +0200
Subject: [R-sig-ME] Reducing two mixed models into one
In-Reply-To: <CADreqizdUMbQoeBjPz7rZ5guZSnzGXJMOcuuLykQpPk08JYtOw@mail.gmail.com>
References: <CADreqix8_TF8b3TPTW_y--SHCFtzyJ7tDHFo1aZrBzje0Q9HrA@mail.gmail.com>
 <CAJuCY5z52ka+4=vyTaKx9znui3+3HYWVKO1byMdukAKv226mbw@mail.gmail.com>
 <CADreqizdUMbQoeBjPz7rZ5guZSnzGXJMOcuuLykQpPk08JYtOw@mail.gmail.com>
Message-ID: <52f8e21f-0bf4-a2de-bef7-3d45ede9450a@gmail.com>

Hi Timothy,

The formula I've suggested before is identical to the first 
parametrization in Thierry's answer, i.e., writing "item_num / 
Condition" is the same as writing "item_num + item_num:Condition".
That parametrization gives you estimates for the Condition slopes 
separately for each level of item_num. So the correlation between the 
corresponding by-subject random slopes is (I believe) what you want:

> d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv") > 
model_1 <- lmer(I(-1000/RT) ~ item_num / Condition + (item_num / 
Condition|Subject) + (item_num / Condition|Item), data = d)> re.corrs <- 
attr(VarCorr(model_1)$Subject, "correlation") > 
re.corrs["item_numEven:Conditionunrelated", 
"item_numOdd:Conditionunrelated"] [1] 0.9499885


Jo?o

On 13/06/2023 18:36, Timothy MacKenzie wrote:
> Dear Thierry,
>
> Thank you so much for your highly informative answer. If I may, I
> wanted to ask a follow-up question.
>
> Previously, from the two separate models, I used to compute a
> correlation (0.849635) between the random slopes of subjects in
> 'Condition==unrelated' for Odd vs. Even items (shown below).
>
> **Question: Could we obtain the latent equivalent of the above
> correlation (which may not be numerically the same as 0.849635) from
> `attr(VarCorr(First_Parametrization_Model)$Subject, "correlation")`?
>
> Thank you so much again,
> Tim M
>
> ranef_model_2_even = data.frame(ranef(model_2)$Subject)
> ranef_model_2_even$Subject <- row.names(ranef_model_2_even)
> ranef_model_3_odd = data.frame(ranef(model_3)$Subject)
> ranef_model_3_odd$Subject <- row.names(ranef_model_3_odd)
>
> Subject = merge(ranef_model_2_even, ranef_model_3_odd, by = "Subject",
> suffixes = c("_even", "_odd"))
> cor(Subject$Conditionunrelated_even, Subject $Conditionunrelated_odd)
> #  [1] 0.849635
>
>
>
>
>
> On Mon, Jun 12, 2023 at 1:36?AM Thierry Onkelinx
> <thierry.onkelinx at inbo.be>  wrote:
>> Dear Timothy,
>>
>> Add the interaction with item_num to every parameter and you should have the same parameterization for both models in a single model.
>>
>> # gives similar parameters as both models
>> I(-1/RT) ~ item_num + item_num:Condition + (item_num + item_num:Condition|Subject) + (item_num + item_num:Condition|Item)
>> # same model fit, different parametrization
>> I(-1/RT) ~ item_num*Condition + (item_num*Condition|Subject) + (item_num*Condition|Item)
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> Op za 10 jun 2023 om 19:06 schreef Timothy MacKenzie<fswfswt at gmail.com>:
>>> Hello All,
>>>
>>> I'm hoping to clarify my prior post to elicit an informative response
>>> from the experts on the list.
>>>
>>> Currently, I'm running two models each using a subset of my data (below).
>>>
>>> <Question>: Instead of running two separate models, is it possible to
>>> create one model that captures both these separate models?
>>>
>>> Thank you,
>>> Tim M
>>> ################
>>> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
>>> library(optimx)
>>> library(blme)
>>>
>>> # Subset 1:
>>> model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
>>> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>>>             subset = item_num == "Even")
>>>
>>> # Subset 2:
>>> model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
>>> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>>>               subset = item_num == "Odd")
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org  mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Tue Jun 13 19:38:03 2023
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Tue, 13 Jun 2023 12:38:03 -0500
Subject: [R-sig-ME] Reducing two mixed models into one
In-Reply-To: <52f8e21f-0bf4-a2de-bef7-3d45ede9450a@gmail.com>
References: <CADreqix8_TF8b3TPTW_y--SHCFtzyJ7tDHFo1aZrBzje0Q9HrA@mail.gmail.com>
 <CAJuCY5z52ka+4=vyTaKx9znui3+3HYWVKO1byMdukAKv226mbw@mail.gmail.com>
 <CADreqizdUMbQoeBjPz7rZ5guZSnzGXJMOcuuLykQpPk08JYtOw@mail.gmail.com>
 <52f8e21f-0bf4-a2de-bef7-3d45ede9450a@gmail.com>
Message-ID: <CADreqiy9VB9QcpTgNyhBNfADVawTsDyHbWthwo9Nkn7n_w+o2g@mail.gmail.com>

Dear Jo?o,

Thank you for your clarification. You made two changes in your code
that I wanted to check with you.

First, you rescaled the outcome from -1/RT to -1000/RT. I wonder in
what way that improved the model?

Second, instead of blmer(), you used lmer() but your lmer() random
effects matrix is singular which makes me think if the correlation
(~0.95) estimated by lmer() is as dependable/reliable?

Thanks,
Tim M

On Tue, Jun 13, 2023 at 12:01?PM Jo?o Ver?ssimo <jl.verissimo at gmail.com> wrote:
>
> Hi Timothy,
>
> The formula I've suggested before is identical to the first parametrization in Thierry's answer, i.e., writing "item_num / Condition" is the same as writing "item_num + item_num:Condition".
> That parametrization gives you estimates for the Condition slopes separately for each level of item_num. So the correlation between the corresponding by-subject random slopes is (I believe) what you want:
>
> > d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
> > model_1 <- lmer(I(-1000/RT) ~ item_num / Condition + (item_num / Condition|Subject) + (item_num / Condition|Item), data = d)
> > re.corrs <- attr(VarCorr(model_1)$Subject, "correlation")
> > re.corrs["item_numEven:Conditionunrelated", "item_numOdd:Conditionunrelated"]
> [1] 0.9499885
>
>
> Jo?o
>
> On 13/06/2023 18:36, Timothy MacKenzie wrote:
>
> Dear Thierry,
>
> Thank you so much for your highly informative answer. If I may, I
> wanted to ask a follow-up question.
>
> Previously, from the two separate models, I used to compute a
> correlation (0.849635) between the random slopes of subjects in
> 'Condition==unrelated' for Odd vs. Even items (shown below).
>
> **Question: Could we obtain the latent equivalent of the above
> correlation (which may not be numerically the same as 0.849635) from
> `attr(VarCorr(First_Parametrization_Model)$Subject, "correlation")`?
>
> Thank you so much again,
> Tim M
>
> ranef_model_2_even = data.frame(ranef(model_2)$Subject)
> ranef_model_2_even$Subject <- row.names(ranef_model_2_even)
> ranef_model_3_odd = data.frame(ranef(model_3)$Subject)
> ranef_model_3_odd$Subject <- row.names(ranef_model_3_odd)
>
> Subject = merge(ranef_model_2_even, ranef_model_3_odd, by = "Subject",
> suffixes = c("_even", "_odd"))
> cor(Subject$Conditionunrelated_even, Subject $Conditionunrelated_odd)
> #  [1] 0.849635
>
>
>
>
>
> On Mon, Jun 12, 2023 at 1:36?AM Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
>
> Dear Timothy,
>
> Add the interaction with item_num to every parameter and you should have the same parameterization for both models in a single model.
>
> # gives similar parameters as both models
> I(-1/RT) ~ item_num + item_num:Condition + (item_num + item_num:Condition|Subject) + (item_num + item_num:Condition|Item)
> # same model fit, different parametrization
> I(-1/RT) ~ item_num*Condition + (item_num*Condition|Subject) + (item_num*Condition|Item)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> Op za 10 jun 2023 om 19:06 schreef Timothy MacKenzie <fswfswt at gmail.com>:
>
> Hello All,
>
> I'm hoping to clarify my prior post to elicit an informative response
> from the experts on the list.
>
> Currently, I'm running two models each using a subset of my data (below).
>
> <Question>: Instead of running two separate models, is it possible to
> create one model that captures both these separate models?
>
> Thank you,
> Tim M
> ################
> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
> library(optimx)
> library(blme)
>
> # Subset 1:
> model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>            subset = item_num == "Even")
>
> # Subset 2:
> model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>              subset = item_num == "Odd")
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From w@chr|@@oo@thu|zen @end|ng |rom gm@||@com  Wed Jun 14 00:08:21 2023
From: w@chr|@@oo@thu|zen @end|ng |rom gm@||@com (Chris Oosthuizen)
Date: Wed, 14 Jun 2023 00:08:21 +0200
Subject: [R-sig-ME] Prediction from Poisson MCMCglmm model fails
Message-ID: <CANKwuwEqUQbYRgqkMOwHVDDRzA7deqZTpZ_1+rm=TZKN=daUjA@mail.gmail.com>

Dear list,

I simulated the population trends of 26 populations over 60 years. Each
population (site) was counted once every year. The population growth rate
(lambda) correlates with a site's latitude. Each site only has one unique
latitude value associated with it.

I want to fit a mixed model to predict the population count every year. I
am using the simulated data as a test case for real data. I can predict
perfectly well after fitting a glmer (lme4) model. I cannot get it to work
with MCMCglmm.

I have a few questions relating to coding this model (data and code link
below):

1) Could someone please help me to diagnose the problem with MCMCglmm? I
(naively) assume that MCMCglmm will select a 'good enough' prior in
the code (see link below). I did not specify a prior here because I am not
fully understanding that syntax as yet, and when I did specify a prior the
model also gave poor output.

2) Am I correct that the random effect structure for these models are the
same?
m1 = glmer(count ~ year0 + latitude0 + (year0|site), family = "poisson",
data = df)
mc1<-MCMCglmm(count ~ year0 + latitude0, random=~us(1 + year0):site,
              rcov=~units, family="poisson", data = df)

3) What is the optimal model structure?  The hypothesis is that lambda
(i.e., the slope of the count~year regression) is associated with latitude
(which is unique for sites).

I fit the model like this, but it doesn't predict well:
mc1 <- MCMCglmm(count ~ year0 + latitude0, random=~us(1 + year0):site,
                  rcov=~units, family="poisson", data = df)

I have seen this model in print for a similar problem:
mx <- MCMCglmm(count ~ year0, random=~us(1 + latitude0):site,
                rcov=~units, family="poisson", data = df)

I don't agree with the random effect structure: should 'year' not also be a
random slope? Perhaps year and latitude as random slopes?

The simulated data and R code is available here:
https://drive.google.com/drive/folders/1ilKWSCLcrzL_FDrtEubNcm6X__ta1E0T?usp=sharing

Thank you,
Chris

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Jun 14 10:29:17 2023
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 14 Jun 2023 08:29:17 +0000
Subject: [R-sig-ME] Prediction from Poisson MCMCglmm model fails
In-Reply-To: <CANKwuwEqUQbYRgqkMOwHVDDRzA7deqZTpZ_1+rm=TZKN=daUjA@mail.gmail.com>
References: <CANKwuwEqUQbYRgqkMOwHVDDRzA7deqZTpZ_1+rm=TZKN=daUjA@mail.gmail.com>
Message-ID: <AS8PR05MB8659C9785099B08A42B656C9AC5AA@AS8PR05MB8659.eurprd05.prod.outlook.com>

Hi Chris,


You have marginalised the site effects in the prediction. Having marginal=NULL will fix the problem and glmer and MCMCglmm will give very similar answers. Also, better to use posterior="all" and not that having interval="prediction" rather than interval="confidence" will give different intervals than lmer, although the point estimates should still be comparable.

Note however that a difference between the glmer and MCMCglmm model is that the latter has an observation-level random effect (rcov=~units) which deals with any overdispersion, whereas the glmer model does not (but one could be fitted, and is generally recommended). Since the simulations do not have any overdispersion (although real data is very much likely to have some) this may create some issues with the residual variance being stuck at zero without a prior. Having the prior

prior=list(R=list(V=1, nu=0.002), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*100)))

should remedy this.

Cheers,

Jarrod

From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chris Oosthuizen <w.chris.oosthuizen at gmail.com>
Date: Tuesday, 13 June 2023 at 23:09
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Prediction from Poisson MCMCglmm model fails
This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.

Dear list,

I simulated the population trends of 26 populations over 60 years. Each
population (site) was counted once every year. The population growth rate
(lambda) correlates with a site's latitude. Each site only has one unique
latitude value associated with it.

I want to fit a mixed model to predict the population count every year. I
am using the simulated data as a test case for real data. I can predict
perfectly well after fitting a glmer (lme4) model. I cannot get it to work
with MCMCglmm.

I have a few questions relating to coding this model (data and code link
below):

1) Could someone please help me to diagnose the problem with MCMCglmm? I
(naively) assume that MCMCglmm will select a 'good enough' prior in
the code (see link below). I did not specify a prior here because I am not
fully understanding that syntax as yet, and when I did specify a prior the
model also gave poor output.

2) Am I correct that the random effect structure for these models are the
same?
m1 = glmer(count ~ year0 + latitude0 + (year0|site), family = "poisson",
data = df)
mc1<-MCMCglmm(count ~ year0 + latitude0, random=~us(1 + year0):site,
              rcov=~units, family="poisson", data = df)

3) What is the optimal model structure?  The hypothesis is that lambda
(i.e., the slope of the count~year regression) is associated with latitude
(which is unique for sites).

I fit the model like this, but it doesn't predict well:
mc1 <- MCMCglmm(count ~ year0 + latitude0, random=~us(1 + year0):site,
                  rcov=~units, family="poisson", data = df)

I have seen this model in print for a similar problem:
mx <- MCMCglmm(count ~ year0, random=~us(1 + latitude0):site,
                rcov=~units, family="poisson", data = df)

I don't agree with the random effect structure: should 'year' not also be a
random slope? Perhaps year and latitude as random slopes?

The simulated data and R code is available here:
https://drive.google.com/drive/folders/1ilKWSCLcrzL_FDrtEubNcm6X__ta1E0T?usp=sharing

Thank you,
Chris

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th' ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

	[[alternative HTML version deleted]]


From m@rt|c@@@|@ @end|ng |rom gm@||@com  Wed Jun 14 11:31:01 2023
From: m@rt|c@@@|@ @end|ng |rom gm@||@com (=?UTF-8?Q?Mart=C3=AD_Casals?=)
Date: Wed, 14 Jun 2023 11:31:01 +0200
Subject: [R-sig-ME] Doubt of assumption test of proportionality in an
 Ordinal Mixed Model
Message-ID: <CADtmEn6bJRa27D8ag-eHBKoDbmqL9V9p7euEP_Spkg1a3FLR=w@mail.gmail.com>

Hi,

We have a doubt regarding the assumption test of proportionality in a
specific case example of the Ordinal Mixed Model. In our analysis, we
fitted a model with a nested random effect using the following code: "mod
<- clmm(NRS ~ sex + week + (week | id.player), data = dades_in)". The
outcome NRS is an ordinal categorical variable with three levels.

Our inquiry revolves around whether there is a test available in R for
assessing the assumption of proportionality within the context of GLMM
Ordinal Mixed Models. We have explored various packages and functions such
as clmm and GLMMadaptive, but we have been unable to locate a suitable test
for this scenario.

Alternatively, we came across an article (
https://link.springer.com/article/10.1007/s10260-018-00437-7) that suggests
examining the assumption through plots and Odds ratios. Would you recommend
this approach, or are there any other tests or methods that we should
consider?

Thank you in advance for your assistance.

Best regards

-- 

Mart? Casals Toquero

EstaT?stic. Sports Statistician/Biostatistician. Lecturer at University of
Vic - Central University of Catalonia (UVic-UCC).

Website: https://marticasals.netlify.app/

*marticasals at gmail.com <marticasals at gmail.com>*

 Twitter: @CasalsTMarti <https://twitter.com/CasalsTMarti>

Researchgate: https://www.researchgate.net/profile/Marti_Casals
<https://www.researchgate.net/home>

Linkedin: *https://www.linkedin.com/in/marti-casalst-17101979/
<https://www.linkedin.com/in/marti-casalst-17101979/>*

	[[alternative HTML version deleted]]


From cdde@j@rd|n@ @end|ng |rom gm@||@com  Wed Jun 14 13:58:51 2023
From: cdde@j@rd|n@ @end|ng |rom gm@||@com (Christopher David Desjardins)
Date: Wed, 14 Jun 2023 07:58:51 -0400
Subject: [R-sig-ME] Fitting a partially nested model with lmer or lme
Message-ID: <CALrjt7_+_GhU2FwU43tMzuS+baaobYacdL-M3ofDsToWLSQuFQ@mail.gmail.com>

I am analyzing some longitudinal data (3 time points) where participants
were randomly assigned to either a treatment or control condition. Within
the treatment condition, participants were randomly assigned to 1 of 5
facilitators. Therefore, I have measurements nested within participants for
the control participants and measurements nested within participants nested
within facilitator for the treatment participants. How can I fit model that
accommodates for this design in lmer() or lme()?

If I let,

y = response variable
trt = 1 for treatment, 0 for control
ID = unique identifier for each participant
time = days since start of study (3 time points / participant)
facilitator = unique identifier for each facilitator, control participants
will have NA by design.

I would like to fit a model that looks like this with lmer() syntax,

lmer(y ~ trt * time + (1 | facilitator)  + (1 | facilitator:ID), data =
data)

But this model (obviously) drops all my treatment participants as they
don't have values for facilitator in my current coding.

Therefore, I've been fitting this model:

m0 <- lmer(y ~ trt * time + (1 | ID) , data = data)

But I was searching on StackOverflow and found this link,
https://stackoverflow.com/questions/37201754/three-level-partially-nested-model/37205167#37205167,
where it's suggested to recode NA for facilitator to "none". When I recode
facilitator from NA to "none" and fit this model:

m1 <- lmer(y ~ trt * time + (1 | facilitator)  + (1 | facilitator:ID), data
= data)

I get similar estimates to m0, however, the SE increase and the df decrease
(using lmerTest) substantially. I am wondering if this is caused by any
potential confounding of trt and facilitator because all participants that
received the treatment (trt = 1), will have "none" as their facilitator
despite not sharing a facilitator. Otherwise, the two models are nearly
identical in terms of log-likelihood.

I am wondering what approach makes the most sense for my design.

Thanks for the help.

Chris

	[[alternative HTML version deleted]]


From w|||thek|w| @end|ng |rom gm@||@com  Tue Jun 20 00:13:24 2023
From: w|||thek|w| @end|ng |rom gm@||@com (Will Hopkins)
Date: Tue, 20 Jun 2023 10:13:24 +1200
Subject: [R-sig-ME] Standard errors of variances; negative variance
Message-ID: <04d201d9a2fb$45d8afe0$d18a0fa0$@gmail.com>

I've just joined this list to get answers to a few questions. I would have
searched the archive before posting, but there seems to be no way of
searching except via quarterly summaries. I searched the last four quarters
without success.

I'm a SAS user, but a few years ago I tried the mixed model in R, with the
help of an R user (Alice Sweeting). At that time, the lme package did not
provide standard errors for the variances, nor did it allow negative
variance. Have these limitations been addressed?  As I recall, Alice found
some code that provided standard errors, but it gave values different from
those of the mixed model in SAS (Proc Mixed). I therefore opted to stay with
SAS, because allowing for negative variance for random effects other than
residuals and estimating uncertainties in variances are both fundamental to
mixed modeling, in my view. I also became fluent with SAS coding over the
years and did not want to make the effort with R coding. Interestingly, SAS
introduced a free cloud version called SAS Studio, evidently modeled on R
Studio, to try to win back customers!

Will


From bbo|ker @end|ng |rom gm@||@com  Tue Jun 20 01:35:52 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 19 Jun 2023 19:35:52 -0400
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <04d201d9a2fb$45d8afe0$d18a0fa0$@gmail.com>
References: <04d201d9a2fb$45d8afe0$d18a0fa0$@gmail.com>
Message-ID: <4b60d0b3-0e81-e855-3cd1-db942d6c8f80@gmail.com>

   Hi, Will,

Googling

  site:https://stat.ethz.ch/pipermail/r-sig-mixed-models/ "negative 
variance"

claims to get you 67 results (although only 11 that Google considers 
worth displaying by default),

   You can filter by date - there are only two hits since 2020:

https://www.google.com/search?q=site%3Ahttps%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F+%22negative+variance%22&client=firefox-b-d&tbs=cdr%3A1%2Ccd_min%3A01-01-2020%2Ccd_max%3A&tbm= 


   and these both look like false positives (they include "negative" and 
"variance" but not "negative variance" ...)

   The short answer is that I am not aware of any mixed effect package 
in R that will allow you to return negative values. You can see my 
answer here: 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q1/026437.html ...


   As for uncertainties in variances - the merDeriv package (dating back 
to 2017) will give you the standard errors of variances and covariances 
(although again, note that there's a theoretical issue here - the 
standard errors are often extremely poor summaries of the uncertainty or 
RE variances, the original authors of lme4 would certainly prefer that 
you use profile confidence intervals to summarize the uncertainty ...)

   That's what I know -- perhaps someone else knows about a package that 
allows for negative variances ... ??

On 2023-06-19 6:13 p.m., Will Hopkins wrote:
> I've just joined this list to get answers to a few questions. I would have
> searched the archive before posting, but there seems to be no way of
> searching except via quarterly summaries. I searched the last four quarters
> without success.
> 
> I'm a SAS user, but a few years ago I tried the mixed model in R, with the
> help of an R user (Alice Sweeting). At that time, the lme package did not
> provide standard errors for the variances, nor did it allow negative
> variance. Have these limitations been addressed?  As I recall, Alice found
> some code that provided standard errors, but it gave values different from
> those of the mixed model in SAS (Proc Mixed). I therefore opted to stay with
> SAS, because allowing for negative variance for random effects other than
> residuals and estimating uncertainties in variances are both fundamental to
> mixed modeling, in my view. I also became fluent with SAS coding over the
> years and did not want to make the effort with R coding. Interestingly, SAS
> introduced a free cloud version called SAS Studio, evidently modeled on R
> Studio, to try to win back customers!
> 
> Will
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jun 20 09:45:02 2023
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 20 Jun 2023 09:45:02 +0200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <4b60d0b3-0e81-e855-3cd1-db942d6c8f80@gmail.com>
References: <04d201d9a2fb$45d8afe0$d18a0fa0$@gmail.com>
 <4b60d0b3-0e81-e855-3cd1-db942d6c8f80@gmail.com>
Message-ID: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>

Dear all,

A negative variance seems odd to me. Isn't a variance positive by
definition? How would you interpret a random intercept with a negative
variance?

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 20 jun 2023 om 01:36 schreef Ben Bolker <bbolker at gmail.com>:

>    Hi, Will,
>
> Googling
>
>   site:https://stat.ethz.ch/pipermail/r-sig-mixed-models/ "negative
> variance"
>
> claims to get you 67 results (although only 11 that Google considers
> worth displaying by default),
>
>    You can filter by date - there are only two hits since 2020:
>
>
> https://www.google.com/search?q=site%3Ahttps%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F+%22negative+variance%22&client=firefox-b-d&tbs=cdr%3A1%2Ccd_min%3A01-01-2020%2Ccd_max%3A&tbm=
>
>
>    and these both look like false positives (they include "negative" and
> "variance" but not "negative variance" ...)
>
>    The short answer is that I am not aware of any mixed effect package
> in R that will allow you to return negative values. You can see my
> answer here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q1/026437.html ...
>
>
>    As for uncertainties in variances - the merDeriv package (dating back
> to 2017) will give you the standard errors of variances and covariances
> (although again, note that there's a theoretical issue here - the
> standard errors are often extremely poor summaries of the uncertainty or
> RE variances, the original authors of lme4 would certainly prefer that
> you use profile confidence intervals to summarize the uncertainty ...)
>
>    That's what I know -- perhaps someone else knows about a package that
> allows for negative variances ... ??
>
> On 2023-06-19 6:13 p.m., Will Hopkins wrote:
> > I've just joined this list to get answers to a few questions. I would
> have
> > searched the archive before posting, but there seems to be no way of
> > searching except via quarterly summaries. I searched the last four
> quarters
> > without success.
> >
> > I'm a SAS user, but a few years ago I tried the mixed model in R, with
> the
> > help of an R user (Alice Sweeting). At that time, the lme package did not
> > provide standard errors for the variances, nor did it allow negative
> > variance. Have these limitations been addressed?  As I recall, Alice
> found
> > some code that provided standard errors, but it gave values different
> from
> > those of the mixed model in SAS (Proc Mixed). I therefore opted to stay
> with
> > SAS, because allowing for negative variance for random effects other than
> > residuals and estimating uncertainties in variances are both fundamental
> to
> > mixed modeling, in my view. I also became fluent with SAS coding over the
> > years and did not want to make the effort with R coding. Interestingly,
> SAS
> > introduced a free cloud version called SAS Studio, evidently modeled on R
> > Studio, to try to win back customers!
> >
> > Will
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From t|motheebonnetc @end|ng |rom gm@||@com  Tue Jun 20 14:12:13 2023
From: t|motheebonnetc @end|ng |rom gm@||@com (Timothee)
Date: Tue, 20 Jun 2023 14:12:13 +0200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <mailman.20107.3.1687255202.37610.r-sig-mixed-models@r-project.org>
References: <mailman.20107.3.1687255202.37610.r-sig-mixed-models@r-project.org>
Message-ID: <f9b1f844-d1df-c255-9ab7-6ca5f97e6344@gmail.com>

Hi all,

For what it is worth, unfortunately it requires a license, you can 
obtain negative estimates of variance parameters in asreml-R. I agree 
with Thierry that negative estimates of variances are odd, but I have 
seen at least one case where they were practical: to identify that 
observations within a grouping level were actually very dissimilar while 
there was almost no variation across grouping level averages. That 
result was contrary to my expectation given the experimental design and 
I may have missed it otherwise. Arguably my models were misspecified, 
but that odd result helped me understand the biology of my system and 
specify more appropriate models later.

As for uncertainties of variances I usually go with Bayesian packages : 
MCMCglmm, brms, rstan, rjags... (or, again, asreml-R).

Best regards,

*************************************
Timoth?e Bonnet, PhD
Charg? de recherche / Researcher

Centre d?Etudes Biologiques de Chiz?
UMR 7372 Universit? de la Rochelle-CNRS
405 route de Priss? la Charri?re
79360 Villiers en Bois

timotheebonnetc at gmail.com
https://timotheenivalis.github.io//


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Tue Jun 20 15:21:07 2023
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Tue, 20 Jun 2023 13:21:07 +0000
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
Message-ID: <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>


Thierry,
I have the same question that you posed, how can a variance, a measure that is squared be negative? Will, please enlighten us!
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicinet
Baltimore VA Medical Center
10 North Greene Street<x-apple-data-detectors://12>
GRECC<x-apple-data-detectors://12> (BT/18/GR)
Baltimore, MD 21201-1524<x-apple-data-detectors://13/0>
(Phone) 410-605-711<tel:410-605-7119>9
(Fax) 410-605-7913<tel:410-605-7913> (Please call phone number above prior to faxing)

On Jun 20, 2023, at 3:45 AM, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

?Dear all,

A negative variance seems odd to me. Isn't a variance positive by
definition? How would you interpret a random intercept with a negative
variance?

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=sbP2Xemwg0iHjvxcc6zR8vtPbZf5ZoFCv1BIFIeDdBE%3D&reserved=0

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=I5HJ05o0Bd4ly0GL0Smc1iYm3cuZMc2IGCcxy8OWn%2B8%3D&reserved=0>


Op di 20 jun 2023 om 01:36 schreef Ben Bolker <bbolker at gmail.com>:

  Hi, Will,

Googling

 site:https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=vw%2FnMxnvA7L9A0qYuJfHa9suA2YBTnZ%2BqxPltyR3G%2FU%3D&reserved=0 "negative
variance"

claims to get you 67 results (although only 11 that Google considers
worth displaying by default),

  You can filter by date - there are only two hits since 2020:


https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dsite%253Ahttps%253A%252F%252Fstat.ethz.ch%252Fpipermail%252Fr-sig-mixed-models%252F%2B%2522negative%2Bvariance%2522%26client%3Dfirefox-b-d%26tbs%3Dcdr%253A1%252Ccd_min%253A01-01-2020%252Ccd_max%253A%26tbm%3D&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=xbWrjRwClEMYFKVkncDFgZga6SPNcmsPvbNs4kpUQjY%3D&reserved=0


  and these both look like false positives (they include "negative" and
"variance" but not "negative variance" ...)

  The short answer is that I am not aware of any mixed effect package
in R that will allow you to return negative values. You can see my
answer here:
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2018q1%2F026437.html&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=2E5S51uIXiPEsuH11f693MEOLYFb2dh5e39t2GSLor8%3D&reserved=0 ...


  As for uncertainties in variances - the merDeriv package (dating back
to 2017) will give you the standard errors of variances and covariances
(although again, note that there's a theoretical issue here - the
standard errors are often extremely poor summaries of the uncertainty or
RE variances, the original authors of lme4 would certainly prefer that
you use profile confidence intervals to summarize the uncertainty ...)

  That's what I know -- perhaps someone else knows about a package that
allows for negative variances ... ??

On 2023-06-19 6:13 p.m., Will Hopkins wrote:
I've just joined this list to get answers to a few questions. I would
have
searched the archive before posting, but there seems to be no way of
searching except via quarterly summaries. I searched the last four
quarters
without success.

I'm a SAS user, but a few years ago I tried the mixed model in R, with
the
help of an R user (Alice Sweeting). At that time, the lme package did not
provide standard errors for the variances, nor did it allow negative
variance. Have these limitations been addressed?  As I recall, Alice
found
some code that provided standard errors, but it gave values different
from
those of the mixed model in SAS (Proc Mixed). I therefore opted to stay
with
SAS, because allowing for negative variance for random effects other than
residuals and estimating uncertainties in variances are both fundamental
to
mixed modeling, in my view. I also became fluent with SAS coding over the
years and did not want to make the effort with R coding. Interestingly,
SAS
introduced a free cloud version called SAS Studio, evidently modeled on R
Studio, to try to win back customers!

Will

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0


   [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Jun 20 15:37:13 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 20 Jun 2023 09:37:13 -0400
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
Message-ID: <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>


 From Molenberghs and Verbeke 2011:

In the first view, where the focus is entirely on the resulting marginal 
model (1.2), negative values for ?2 are perfectly acceptable (Nelder, 
1954; Verbeke and Molenberghs, 2000, Section 5.6.2), because this merely 
corresponds to the occurrence of negative within-cluster correlation ? = 
?2/(?2 + ?2). In such a case, the only requirement is that ?2 + ?2 > 
0andVi = ?2 Jni + ?2 Ini is a positive definite, marginal covariance 
matrix. Further discussions on negative variance components, and their 
implications for inferences, can be found in Thompson (1962), Searle et 
al. (1996), Verbeke and Molenberghs (2003) and Molenberghs and Verbeke 
(2007). In the second view, when the link between marginal model (1.2) 
and its generating hierarchical model (1.1) is preserved, thereby 
including the concept of random effects bi and perhaps even requiring 
inferences about them, it has been considered imperative to restrict ?2 
to non-negative values.

   Molenberghs, Geert, and Geert Verbeke. 2011. ?A Note on a 
Hierarchical Interpretation for Negative Variance Components.? 
Statistical Modelling 11 (5): 389?408. 
https://doi.org/10.1177/1471082X1001100501.

    Since lme4 deals with the hierarchical model, I don't think that 
negative variances are going to work.

On 2023-06-20 9:21 a.m., Sorkin, John wrote:
> 
> Thierry,
> I have the same question that you posed, how can a variance, a measure 
> that is squared be negative? Will, please enlighten us!
> John
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and 
>> Geriatric Medicinet
>> Baltimore VA Medical Center
>> 10 North Greene Street <x-apple-data-detectors://12>
>> GRECC <x-apple-data-detectors://12>?(BT/18/GR)
>> Baltimore, MD 21201-1524 <x-apple-data-detectors://13/0>
>> (Phone) 410-605-711 <tel:410-605-7119>9
>> (Fax)410-605-7913 <tel:410-605-7913>?(Please call phone number above 
>> prior to faxing)
> 
>> On Jun 20, 2023, at 3:45 AM, Thierry Onkelinx via R-sig-mixed-models 
>> <r-sig-mixed-models at r-project.org> wrote:
>>
>> ?Dear all,
>>
>> A negative variance seems odd to me. Isn't a variance positive by
>> definition? How would you interpret a random intercept with a negative
>> variance?
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=sbP2Xemwg0iHjvxcc6zR8vtPbZf5ZoFCv1BIFIeDdBE%3D&reserved=0
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able 
>> to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of 
>> data.
>> ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=I5HJ05o0Bd4ly0GL0Smc1iYm3cuZMc2IGCcxy8OWn%2B8%3D&reserved=0>
>>
>>
>> Op di 20 jun 2023 om 01:36 schreef Ben Bolker <bbolker at gmail.com>:
>>
>>> ??Hi, Will,
>>>
>>> Googling
>>>
>>> ?site:https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=vw%2FnMxnvA7L9A0qYuJfHa9suA2YBTnZ%2BqxPltyR3G%2FU%3D&reserved=0 "negative
>>> variance"
>>>
>>> claims to get you 67 results (although only 11 that Google considers
>>> worth displaying by default),
>>>
>>> ??You can filter by date - there are only two hits since 2020:
>>>
>>>
>>> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dsite%253Ahttps%253A%252F%252Fstat.ethz.ch%252Fpipermail%252Fr-sig-mixed-models%252F%2B%2522negative%2Bvariance%2522%26client%3Dfirefox-b-d%26tbs%3Dcdr%253A1%252Ccd_min%253A01-01-2020%252Ccd_max%253A%26tbm%3D&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=xbWrjRwClEMYFKVkncDFgZga6SPNcmsPvbNs4kpUQjY%3D&reserved=0
>>>
>>>
>>> ??and these both look like false positives (they include "negative" and
>>> "variance" but not "negative variance" ...)
>>>
>>> ??The short answer is that I am not aware of any mixed effect package
>>> in R that will allow you to return negative values. You can see my
>>> answer here:
>>> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2018q1%2F026437.html&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=2E5S51uIXiPEsuH11f693MEOLYFb2dh5e39t2GSLor8%3D&reserved=0 ...
>>>
>>>
>>> ??As for uncertainties in variances - the merDeriv package (dating back
>>> to 2017) will give you the standard errors of variances and covariances
>>> (although again, note that there's a theoretical issue here - the
>>> standard errors are often extremely poor summaries of the uncertainty or
>>> RE variances, the original authors of lme4 would certainly prefer that
>>> you use profile confidence intervals to summarize the uncertainty ...)
>>>
>>> ??That's what I know -- perhaps someone else knows about a package that
>>> allows for negative variances ... ??
>>>
>>> On 2023-06-19 6:13 p.m., Will Hopkins wrote:
>>>> I've just joined this list to get answers to a few questions. I would
>>> have
>>>> searched the archive before posting, but there seems to be no way of
>>>> searching except via quarterly summaries. I searched the last four
>>> quarters
>>>> without success.
>>>>
>>>> I'm a SAS user, but a few years ago I tried the mixed model in R, with
>>> the
>>>> help of an R user (Alice Sweeting). At that time, the lme package 
>>>> did not
>>>> provide standard errors for the variances, nor did it allow negative
>>>> variance. Have these limitations been addressed? ?As I recall, Alice
>>> found
>>>> some code that provided standard errors, but it gave values different
>>> from
>>>> those of the mixed model in SAS (Proc Mixed). I therefore opted to stay
>>> with
>>>> SAS, because allowing for negative variance for random effects other 
>>>> than
>>>> residuals and estimating uncertainties in variances are both fundamental
>>> to
>>>> mixed modeling, in my view. I also became fluent with SAS coding 
>>>> over the
>>>> years and did not want to make the effort with R coding. Interestingly,
>>> SAS
>>>> introduced a free cloud version called SAS Studio, evidently modeled 
>>>> on R
>>>> Studio, to try to win back customers!
>>>>
>>>> Will
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
>>>
>>
>> ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From jepu@to @end|ng |rom gm@||@com  Tue Jun 20 16:02:33 2023
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Tue, 20 Jun 2023 09:02:33 -0500
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>
Message-ID: <CAFUVuJx_B6nUm4fSxY26gqmNyC1sC+muyh802ms+V2m8FNt-hA@mail.gmail.com>

Regarding standard errors for variance components: Will, I'm not sure if
you were asking about lme4::lmer() or nlme::lme(). If you're not familiar
with the latter, you might find it interesting. It is in some respects more
flexible than lmer(), such as providing model components for different
level-1 error structures and correlation structures, and so you might find
it more comparable to SAS. If you're using nlme::lme(), the lmeInfo package
provides a variance-covariance matrix for the variance component parameters
(based on the inverse expected information or average information):
https://jepusto.github.io/lmeInfo/
That said, I agree with the other folks who've suggested that likelihood
ratio tests and profile likelihood CIs might be a better choice for
inference on variance components.

Regarding negative variances, Ben's post is instructive. In addition, in
some specific problems related to meta-analysis, we've found that allowing
for negative variance components can improve the performance of score and
likelihood ratio tests involving other model parameters. My working theory
here is that bounding variances at zero means that the log likelihood is no
longer smooth, which seems to  muck up the behavior or tests that involve
the first and second derivatives of the log likelihood.

James

On Tue, Jun 20, 2023 at 8:37?AM Ben Bolker <bbolker at gmail.com> wrote:

>
>  From Molenberghs and Verbeke 2011:
>
> In the first view, where the focus is entirely on the resulting marginal
> model (1.2), negative values for ?2 are perfectly acceptable (Nelder,
> 1954; Verbeke and Molenberghs, 2000, Section 5.6.2), because this merely
> corresponds to the occurrence of negative within-cluster correlation ? =
> ?2/(?2 + ?2). In such a case, the only requirement is that ?2 + ?2 >
> 0andVi = ?2 Jni + ?2 Ini is a positive definite, marginal covariance
> matrix. Further discussions on negative variance components, and their
> implications for inferences, can be found in Thompson (1962), Searle et
> al. (1996), Verbeke and Molenberghs (2003) and Molenberghs and Verbeke
> (2007). In the second view, when the link between marginal model (1.2)
> and its generating hierarchical model (1.1) is preserved, thereby
> including the concept of random effects bi and perhaps even requiring
> inferences about them, it has been considered imperative to restrict ?2
> to non-negative values.
>
>    Molenberghs, Geert, and Geert Verbeke. 2011. ?A Note on a
> Hierarchical Interpretation for Negative Variance Components.?
> Statistical Modelling 11 (5): 389?408.
> https://doi.org/10.1177/1471082X1001100501.
>
>     Since lme4 deals with the hierarchical model, I don't think that
> negative variances are going to work.
>
> On 2023-06-20 9:21 a.m., Sorkin, John wrote:
> >
> > Thierry,
> > I have the same question that you posed, how can a variance, a measure
> > that is squared be negative? Will, please enlighten us!
> > John
> >> John David Sorkin M.D., Ph.D.
> >> Professor of Medicine
> >> Chief, Biostatistics and Informatics
> >> University of Maryland School of Medicine Division of Gerontology and
> >> Geriatric Medicinet
> >> Baltimore VA Medical Center
> >> 10 North Greene Street <x-apple-data-detectors://12>
> >> GRECC <x-apple-data-detectors://12> (BT/18/GR)
> >> Baltimore, MD 21201-1524 <x-apple-data-detectors://13/0>
> >> (Phone) 410-605-711 <tel:410-605-7119>9
> >> (Fax)410-605-7913 <tel:410-605-7913> (Please call phone number above
> >> prior to faxing)
> >
> >> On Jun 20, 2023, at 3:45 AM, Thierry Onkelinx via R-sig-mixed-models
> >> <r-sig-mixed-models at r-project.org> wrote:
> >>
> >> ?Dear all,
> >>
> >> A negative variance seems odd to me. Isn't a variance positive by
> >> definition? How would you interpret a random intercept with a negative
> >> variance?
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Statisticus / Statistician
> >>
> >> Vlaamse Overheid / Government of Flanders
> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> >> FOREST
> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> thierry.onkelinx at inbo.be
> >> Havenlaan 88 bus 73, 1000 Brussel
> >>
> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=sbP2Xemwg0iHjvxcc6zR8vtPbZf5ZoFCv1BIFIeDdBE%3D&reserved=0
> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able
> >> to say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of
> >> data.
> >> ~ John Tukey
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>
> >> <
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=I5HJ05o0Bd4ly0GL0Smc1iYm3cuZMc2IGCcxy8OWn%2B8%3D&reserved=0
> >
> >>
> >>
> >> Op di 20 jun 2023 om 01:36 schreef Ben Bolker <bbolker at gmail.com>:
> >>
> >>>   Hi, Will,
> >>>
> >>> Googling
> >>>
> >>>  site:
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=vw%2FnMxnvA7L9A0qYuJfHa9suA2YBTnZ%2BqxPltyR3G%2FU%3D&reserved=0
> "negative
> >>> variance"
> >>>
> >>> claims to get you 67 results (although only 11 that Google considers
> >>> worth displaying by default),
> >>>
> >>>   You can filter by date - there are only two hits since 2020:
> >>>
> >>>
> >>>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dsite%253Ahttps%253A%252F%252Fstat.ethz.ch%252Fpipermail%252Fr-sig-mixed-models%252F%2B%2522negative%2Bvariance%2522%26client%3Dfirefox-b-d%26tbs%3Dcdr%253A1%252Ccd_min%253A01-01-2020%252Ccd_max%253A%26tbm%3D&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=xbWrjRwClEMYFKVkncDFgZga6SPNcmsPvbNs4kpUQjY%3D&reserved=0
> >>>
> >>>
> >>>   and these both look like false positives (they include "negative" and
> >>> "variance" but not "negative variance" ...)
> >>>
> >>>   The short answer is that I am not aware of any mixed effect package
> >>> in R that will allow you to return negative values. You can see my
> >>> answer here:
> >>>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2018q1%2F026437.html&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=2E5S51uIXiPEsuH11f693MEOLYFb2dh5e39t2GSLor8%3D&reserved=0
> ...
> >>>
> >>>
> >>>   As for uncertainties in variances - the merDeriv package (dating back
> >>> to 2017) will give you the standard errors of variances and covariances
> >>> (although again, note that there's a theoretical issue here - the
> >>> standard errors are often extremely poor summaries of the uncertainty
> or
> >>> RE variances, the original authors of lme4 would certainly prefer that
> >>> you use profile confidence intervals to summarize the uncertainty ...)
> >>>
> >>>   That's what I know -- perhaps someone else knows about a package that
> >>> allows for negative variances ... ??
> >>>
> >>> On 2023-06-19 6:13 p.m., Will Hopkins wrote:
> >>>> I've just joined this list to get answers to a few questions. I would
> >>> have
> >>>> searched the archive before posting, but there seems to be no way of
> >>>> searching except via quarterly summaries. I searched the last four
> >>> quarters
> >>>> without success.
> >>>>
> >>>> I'm a SAS user, but a few years ago I tried the mixed model in R, with
> >>> the
> >>>> help of an R user (Alice Sweeting). At that time, the lme package
> >>>> did not
> >>>> provide standard errors for the variances, nor did it allow negative
> >>>> variance. Have these limitations been addressed?  As I recall, Alice
> >>> found
> >>>> some code that provided standard errors, but it gave values different
> >>> from
> >>>> those of the mixed model in SAS (Proc Mixed). I therefore opted to
> stay
> >>> with
> >>>> SAS, because allowing for negative variance for random effects other
> >>>> than
> >>>> residuals and estimating uncertainties in variances are both
> fundamental
> >>> to
> >>>> mixed modeling, in my view. I also became fluent with SAS coding
> >>>> over the
> >>>> years and did not want to make the effort with R coding.
> Interestingly,
> >>> SAS
> >>>> introduced a free cloud version called SAS Studio, evidently modeled
> >>>> on R
> >>>> Studio, to try to win back customers!
> >>>>
> >>>> Will
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> >>>
> >>
> >>    [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From w|||thek|w| @end|ng |rom gm@||@com  Wed Jun 21 02:08:14 2023
From: w|||thek|w| @end|ng |rom gm@||@com (Will Hopkins)
Date: Wed, 21 Jun 2023 12:08:14 +1200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <CAFUVuJx_B6nUm4fSxY26gqmNyC1sC+muyh802ms+V2m8FNt-hA@mail.gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>
 <CAFUVuJx_B6nUm4fSxY26gqmNyC1sC+muyh802ms+V2m8FNt-hA@mail.gmail.com>
Message-ID: <0e1101d9a3d4$7afbb210$70f31630$@gmail.com>

Thanks heaps for the seven replies from five people on this list. In summary, it looks like standard errors could be derived for variances in R: with asreml-R (which you have to pay for?); possibly with nlme; with merDeriv, but they may be untrustworthy; and with Bayesian packages (but I'd be specifying weakly informative priors that in the limit have no effect on the posterior, which might not work in some packages). Negative variance seems to be off the table, however. Ben, James and Timothee have indicated scenarios where negative variance made some sense. 

I had a particular reason for seeking advice on this list; see the bottom of my message. First, here's my justification for negative variance and standard errors of variances.

My favorite example is the variance representing individual responses to a treatment, derived as the variance of the change scores in an experimental group minus the variance of the change scores in a control group. In a mixed model, the dependent is the change score, there is a fixed effect for group (to estimate the difference in the mean changes), other fixed-effect modifiers if you want them, and a random effect for the interaction of a dummy variable (1 in the experimental group, 0 in the control group) with subject identity. I usually call the dummy variable something like xVarExpt, to indicate extra variance in the experimental change scores, and the code in SAS is random xVarExpt*SubjectID; or random intercept/subject=SubjectID;. And of course there is the residual. 

Usually the variance of the change scores in the experimental group is greater than that in the control group, owing to individual responses. But with small sample sizes, the variance on the experimental group could be less than that in the control, simply because of sampling variation. You will therefore get a negative variance point estimate. Importantly, its upper confidence limit will tell you how big and positive the individual responses could be. The confidence interval for variances estimated by Proc Mixed in SAS have good coverage in my experience with many simulations over the years. (The coverage isn't quite so good in meta-analytic mixed models when the study-estimate sample sizes are small, but the coverage is generally conservative, i.e., what you specify as a 90%CI has greater than 90% coverage, as I recall.) The coverage works well ONLY when you allow negative variance for the random effects. Interestingly, the default in SAS is positive-only variance, and if you ask for confidence limits, they are calculated from a standard error and the chi-squared distribution. The resulting confidence limits are unrealistic: you can get enormous upper limits. When you allow negative variance, they are realistic; quoting from the on-line documentation, "Wald Z-scores and normal quantiles are used to construct the limits". (See  https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_mixed_syntax01.htm There is no further information about how the standard errors are calculated and no mention of profile confidence limits.) The confidence limits for the residual(s) are always calculated from the chi-squared distribution, unless you specify otherwise, and these are always realistic and have correct coverage, in my experience.

The variance in the experimental group could truly be less than that in the control group, either because the treatment compresses the responses towards some upper or lower limit, or less likely because there are individual responses to the control treatment that exceed those to the experimental treatment. Either way negative variance is meaningful. You can turn the dummy variable around if you like, but you don't have to.

When I get a negative variance, or a negative lower confidence limit, I have no hesitation in changing the sign, taking the square root, and calling it a negative SD. It just simply means that the individual responses, or more generally whatever differences or variability are represented by the random effect, could be reduced differences or variability. I know a negative SD for the intercept random effect is a hard one to swallow, but it's better to see that and think again about your model and/or what might really be happening than to simply let it be set to zero. 

I would like to emphasize just how important the random effects are in the analysis of repeated measurement or other clustered data. That's where the individual differences and individual responses are found, which are crucial in this age of personalized medicine. Hence you need to make inferences about the random effects; they are not simply nuisance parameters that you have to include to make sure the uncertainty in the mean effects are trustworthy, then forget about. I make inferences about magnitudes of the random effects (Bayesian or hypothesis testing against smallest importants) assuming a normal distribution (chi-squared for residuals) and smallest importants for SDs that are half those for mean effects.

OK, enough of the hobby horse. I wanted to find out whether R allows for negative variances and standard errors of variances, because I am working with a colleague on a manuscript focusing on the correct way to analyze, report and interpret errors of measurement in various kinds of reliability study. Example: for some measures, the first measurement in a series of repeated measurements can have more error, which is easily specified and estimated with a dummy variable, as explained above for individual responses. Another example: the possibility of additional error arising between time-separated clusters of repeated measurements needs to be specified as a random effect that can have negative variance. We've simulated data and analyzed them all with SAS Studio, and we hope to publish the programs as supplementary material. We're looking for a co-author/collaborator who had experience of measurement studies and skill with mixed models in R to provide the same simulations and analyses with R. It's contingent upon estimating negative variance and standard errors of variances, both of which require more than lme or nlme, by the look of it. Maybe it's a good opportunity for someone to get involved and figure out the easiest way to get the same estimates and uncertainties as in SAS, because that would or should be useful for mixed modeling more generally with R.

Will


From bbo|ker @end|ng |rom gm@||@com  Wed Jun 21 02:59:22 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 20 Jun 2023 20:59:22 -0400
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <0e1101d9a3d4$7afbb210$70f31630$@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>
 <CAFUVuJx_B6nUm4fSxY26gqmNyC1sC+muyh802ms+V2m8FNt-hA@mail.gmail.com>
 <0e1101d9a3d4$7afbb210$70f31630$@gmail.com>
Message-ID: <5818db53-3100-5fbe-b585-fb51c7cbe406@gmail.com>


   A few *short* responses below.

On 2023-06-20 8:08 p.m., Will Hopkins wrote:
> Thanks heaps for the seven replies from five people on this list. In summary, it looks like standard errors could be derived for variances in R: with asreml-R (which you have to pay for?); possibly with nlme; with merDeriv, but they may be untrustworthy;

   not sure what the evidence is that merDeriv's results are untrustworthy?

  and with Bayesian packages (but I'd be specifying weakly informative 
priors that in the limit have no effect on the posterior, which might 
not work in some packages). Negative variance seems to be off the table, 
however. Ben, James and Timothee have indicated scenarios where negative 
variance made some sense.
> 
> I had a particular reason for seeking advice on this list; see the bottom of my message. First, here's my justification for negative variance and standard errors of variances.
> 
> My favorite example is the variance representing individual responses to a treatment, derived as the variance of the change scores in an experimental group minus the variance of the change scores in a control group. In a mixed model, the dependent is the change score, there is a fixed effect for group (to estimate the difference in the mean changes), other fixed-effect modifiers if you want them, and a random effect for the interaction of a dummy variable (1 in the experimental group, 0 in the control group) with subject identity. I usually call the dummy variable something like xVarExpt, to indicate extra variance in the experimental change scores, and the code in SAS is random xVarExpt*SubjectID; or random intercept/subject=SubjectID;. And of course there is the residual.
> 
> Usually the variance of the change scores in the experimental group is greater than that in the control group, owing to individual responses. But with small sample sizes, the variance on the experimental group could be less than that in the control, simply because of sampling variation. You will therefore get a negative variance point estimate. Importantly, its upper confidence limit will tell you how big and positive the individual responses could be. The confidence interval for variances estimated by Proc Mixed in SAS have good coverage in my experience with many simulations over the years. (The coverage isn't quite so good in meta-analytic mixed models when the study-estimate sample sizes are small, but the coverage is generally conservative, i.e., what you specify as a 90%CI has greater than 90% coverage, as I recall.) The coverage works well ONLY when you allow negative variance for the random effects. 


Interestingly, the default in SAS is positive-only variance, and if you 
ask f
>   or confidence limits, they are calculated from a standard error and the chi-squared distribution. The resulting confidence limits are unrealistic: you can get enormous upper limits. When you allow negative variance, they are realistic; quoting from the on-line documentation, "Wald Z-scores and normal quantiles are used to construct the limits". (See  https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_mixed_syntax01.htm There is no further information about how the standard errors are calculated and no mention of profile confidence limits.) The confidence limits for the residual(s) are always calculated from the chi-squared distribution, unless you specify otherwise, and these are always realistic and have correct coverage, in my experience.

   I would argue that an equally good (possibly even better?) way to 
test the maximum plausible size of the effect is computing an upper 
*likelihood profile* confidence limit.  This should not require allowing 
a negative estimate of the variance to get good coverage ... ??  (I can 
certainly see why a Wald-based confidence interval would fail if you 
didn't allow negative variances.  How does SAS compute these intervals? 
Are they assumed to be symmetric on the variance scale or on the 
log-variance scale?)

> 
> The variance in the experimental group could truly be less than that in the control group, either because the treatment compresses the responses towards some upper or lower limit, or less likely because there are individual responses to the control treatment that exceed those to the experimental treatment. Either way negative variance is meaningful. You can turn the dummy variable around if you like, but you don't have to.
> 
> When I get a negative variance, or a negative lower confidence limit, I have no hesitation in changing the sign, taking the square root, and calling it a negative SD. It just simply means that the individual responses, or more generally whatever differences or variability are represented by the random effect, could be reduced differences or variability. I know a negative SD for the intercept random effect is a hard one to swallow, but it's better to see that and think again about your model and/or what might really be happening than to simply let it be set to zero.
> 
> I would like to emphasize just how important the random effects are in the analysis of repeated measurement or other clustered data. That's where the individual differences and individual responses are found, which are crucial in this age of personalized medicine. Hence you need to make inferences about the random effects; they are not simply nuisance parameters that you have to include to make sure the uncertainty in the mean effects are trustworthy, then forget about. I make inferences about magnitudes of the random effects (Bayesian or hypothesis testing against smallest importants) assuming a normal distribution (chi-squared for residuals) and smallest importants for SDs that are half those for mean effects.

   This argument could presumably be turned around to say that we 
shouldn't rely on a method that only considers the marginal variance 
structure (i.e., the context in which negative variances make the most 
sense), but that we want to consider the 'true' structure of the 
variance (in which case we should probably be considering 
compound-symmetric variance structures ...)

> 
> OK, enough of the hobby horse. I wanted to find out whether R allows for negative variances and standard errors of variances, because I am working with a colleague on a manuscript focusing on the correct way to analyze, report and interpret errors of measurement in various kinds of reliability study. Example: for some measures, the first measurement in a series of repeated measurements can have more error, which is easily specified and estimated with a dummy variable, as explained above for individual responses. Another example: the possibility of additional error arising between time-separated clusters of repeated measurements needs to be specified as a random effect that can have negative variance. We've simulated data and analyzed them all with SAS Studio, and we hope to publish the programs as supplementary material. We're looking for a co-author/collaborator who had experience of measurement studies and skill with mixed models in R to provide the same simulations and analyses wi
>   th R. It's contingent upon estimating negative variance and standard errors of variances, both of which require more than lme or nlme, by the look of it. Maybe it's a good opportunity for someone to get involved and figure out the easiest way to get the same estimates and uncertainties as in SAS, because that would or should be useful for mixed modeling more generally with R.

   An alternative approach to this would be to model the 
heteroscedasticity directly, which can be done with (e.g.) lme and 
glmmTMB, although not at present in lme4 - no need to make up latent 
variables with negative variances ...

   cheers
     Ben Bolker

> 
> Will
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From stevedrd m@iii@g oii y@hoo@com  Wed Jun 21 13:03:33 2023
From: stevedrd m@iii@g oii y@hoo@com (stevedrd m@iii@g oii y@hoo@com)
Date: Wed, 21 Jun 2023 11:03:33 +0000 (UTC)
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <5818db53-3100-5fbe-b585-fb51c7cbe406@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>
 <CAFUVuJx_B6nUm4fSxY26gqmNyC1sC+muyh802ms+V2m8FNt-hA@mail.gmail.com>
 <0e1101d9a3d4$7afbb210$70f31630$@gmail.com>
 <5818db53-3100-5fbe-b585-fb51c7cbe406@gmail.com>
Message-ID: <430517929.1606207.1687345413161@mail.yahoo.com>

 Just sayin'
Part of the "negative variance" issue in this particular case could be due to using change scores as the dependent variable. Using the "pre" value as a covariate adjuster of the post values should go a long way toward alleviating this issue. See Frank Harrell's website/blog for better reasoning than I am able to do.
Steve Denham
    On Tuesday, June 20, 2023 at 08:59:43 PM EDT, Ben Bolker <bbolker at gmail.com> wrote:  
 
 
? A few *short* responses below.

On 2023-06-20 8:08 p.m., Will Hopkins wrote:
> Thanks heaps for the seven replies from five people on this list. In summary, it looks like standard errors could be derived for variances in R: with asreml-R (which you have to pay for?); possibly with nlme; with merDeriv, but they may be untrustworthy;

? not sure what the evidence is that merDeriv's results are untrustworthy?

? and with Bayesian packages (but I'd be specifying weakly informative 
priors that in the limit have no effect on the posterior, which might 
not work in some packages). Negative variance seems to be off the table, 
however. Ben, James and Timothee have indicated scenarios where negative 
variance made some sense.
> 
> I had a particular reason for seeking advice on this list; see the bottom of my message. First, here's my justification for negative variance and standard errors of variances.
> 
> My favorite example is the variance representing individual responses to a treatment, derived as the variance of the change scores in an experimental group minus the variance of the change scores in a control group. In a mixed model, the dependent is the change score, there is a fixed effect for group (to estimate the difference in the mean changes), other fixed-effect modifiers if you want them, and a random effect for the interaction of a dummy variable (1 in the experimental group, 0 in the control group) with subject identity. I usually call the dummy variable something like xVarExpt, to indicate extra variance in the experimental change scores, and the code in SAS is random xVarExpt*SubjectID; or random intercept/subject=SubjectID;. And of course there is the residual.
> 
> Usually the variance of the change scores in the experimental group is greater than that in the control group, owing to individual responses. But with small sample sizes, the variance on the experimental group could be less than that in the control, simply because of sampling variation. You will therefore get a negative variance point estimate. Importantly, its upper confidence limit will tell you how big and positive the individual responses could be. The confidence interval for variances estimated by Proc Mixed in SAS have good coverage in my experience with many simulations over the years. (The coverage isn't quite so good in meta-analytic mixed models when the study-estimate sample sizes are small, but the coverage is generally conservative, i.e., what you specify as a 90%CI has greater than 90% coverage, as I recall.) The coverage works well ONLY when you allow negative variance for the random effects. 


Interestingly, the default in SAS is positive-only variance, and if you 
ask f
>? or confidence limits, they are calculated from a standard error and the chi-squared distribution. The resulting confidence limits are unrealistic: you can get enormous upper limits. When you allow negative variance, they are realistic; quoting from the on-line documentation, "Wald Z-scores and normal quantiles are used to construct the limits". (See? https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_mixed_syntax01.htm There is no further information about how the standard errors are calculated and no mention of profile confidence limits.) The confidence limits for the residual(s) are always calculated from the chi-squared distribution, unless you specify otherwise, and these are always realistic and have correct coverage, in my experience.

? I would argue that an equally good (possibly even better?) way to 
test the maximum plausible size of the effect is computing an upper 
*likelihood profile* confidence limit.? This should not require allowing 
a negative estimate of the variance to get good coverage ... ??? (I can 
certainly see why a Wald-based confidence interval would fail if you 
didn't allow negative variances.? How does SAS compute these intervals? 
Are they assumed to be symmetric on the variance scale or on the 
log-variance scale?)

> 
> The variance in the experimental group could truly be less than that in the control group, either because the treatment compresses the responses towards some upper or lower limit, or less likely because there are individual responses to the control treatment that exceed those to the experimental treatment. Either way negative variance is meaningful. You can turn the dummy variable around if you like, but you don't have to.
> 
> When I get a negative variance, or a negative lower confidence limit, I have no hesitation in changing the sign, taking the square root, and calling it a negative SD. It just simply means that the individual responses, or more generally whatever differences or variability are represented by the random effect, could be reduced differences or variability. I know a negative SD for the intercept random effect is a hard one to swallow, but it's better to see that and think again about your model and/or what might really be happening than to simply let it be set to zero.
> 
> I would like to emphasize just how important the random effects are in the analysis of repeated measurement or other clustered data. That's where the individual differences and individual responses are found, which are crucial in this age of personalized medicine. Hence you need to make inferences about the random effects; they are not simply nuisance parameters that you have to include to make sure the uncertainty in the mean effects are trustworthy, then forget about. I make inferences about magnitudes of the random effects (Bayesian or hypothesis testing against smallest importants) assuming a normal distribution (chi-squared for residuals) and smallest importants for SDs that are half those for mean effects.

? This argument could presumably be turned around to say that we 
shouldn't rely on a method that only considers the marginal variance 
structure (i.e., the context in which negative variances make the most 
sense), but that we want to consider the 'true' structure of the 
variance (in which case we should probably be considering 
compound-symmetric variance structures ...)

> 
> OK, enough of the hobby horse. I wanted to find out whether R allows for negative variances and standard errors of variances, because I am working with a colleague on a manuscript focusing on the correct way to analyze, report and interpret errors of measurement in various kinds of reliability study. Example: for some measures, the first measurement in a series of repeated measurements can have more error, which is easily specified and estimated with a dummy variable, as explained above for individual responses. Another example: the possibility of additional error arising between time-separated clusters of repeated measurements needs to be specified as a random effect that can have negative variance. We've simulated data and analyzed them all with SAS Studio, and we hope to publish the programs as supplementary material. We're looking for a co-author/collaborator who had experience of measurement studies and skill with mixed models in R to provide the same simulations and analyses 
 wi
>? th R. It's contingent upon estimating negative variance and standard errors of variances, both of which require more than lme or nlme, by the look of it. Maybe it's a good opportunity for someone to get involved and figure out the easiest way to get the same estimates and uncertainties as in SAS, because that would or should be useful for mixed modeling more generally with R.

? An alternative approach to this would be to model the 
heteroscedasticity directly, which can be done with (e.g.) lme and 
glmmTMB, although not at present in lme4 - no need to make up latent 
variables with negative variances ...

? cheers
? ? Ben Bolker

> 
> Will
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  
	[[alternative HTML version deleted]]


From jhm@|ndon@|d @end|ng |rom gm@||@com  Wed Jun 21 23:53:07 2023
From: jhm@|ndon@|d @end|ng |rom gm@||@com (John H Maindonald)
Date: Thu, 22 Jun 2023 09:53:07 +1200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
Message-ID: <88D1C22C-1C21-4C97-B3A7-3FEA53FC447D@gmail.com>

Dear  All,
As with the square root of -1, negative variances are a convenient 
computational fiction.  The square root of -1 is an invitation to move
to a 2-dimensional word, where they make perfect sense.

A negative variance estimate, in those systems that allow it, is a useful 
warning that one needs to think and move beyond the one-dimensional 
representation in which the variances have been set.
John Maindonald
Statistics Research Associates, Wellington NZ.

> On 21/06/2023, at 01:21, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> 
> Thierry,
> I have the same question that you posed, how can a variance, a measure that is squared be negative? Will, please enlighten us!
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicinet
> Baltimore VA Medical Center
> 10 North Greene Street<x-apple-data-detectors://12>
> GRECC<x-apple-data-detectors://12> (BT/18/GR)
> Baltimore, MD 21201-1524<x-apple-data-detectors://13/0>
> (Phone) 410-605-711<tel:410-605-7119>9
> (Fax) 410-605-7913<tel:410-605-7913> (Please call phone number above prior to faxing)
> 
> On Jun 20, 2023, at 3:45 AM, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> 
> ?Dear all,
> 
> A negative variance seems odd to me. Isn't a variance positive by
> definition? How would you interpret a random intercept with a negative
> variance?
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=sbP2Xemwg0iHjvxcc6zR8vtPbZf5ZoFCv1BIFIeDdBE%3D&reserved=0
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=I5HJ05o0Bd4ly0GL0Smc1iYm3cuZMc2IGCcxy8OWn%2B8%3D&reserved=0>
> 
> 
> Op di 20 jun 2023 om 01:36 schreef Ben Bolker <bbolker at gmail.com>:
> 
>  Hi, Will,
> 
> Googling
> 
> site:https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=vw%2FnMxnvA7L9A0qYuJfHa9suA2YBTnZ%2BqxPltyR3G%2FU%3D&reserved=0 "negative
> variance"
> 
> claims to get you 67 results (although only 11 that Google considers
> worth displaying by default),
> 
>  You can filter by date - there are only two hits since 2020:
> 
> 
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dsite%253Ahttps%253A%252F%252Fstat.ethz.ch%252Fpipermail%252Fr-sig-mixed-models%252F%2B%2522negative%2Bvariance%2522%26client%3Dfirefox-b-d%26tbs%3Dcdr%253A1%252Ccd_min%253A01-01-2020%252Ccd_max%253A%26tbm%3D&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=xbWrjRwClEMYFKVkncDFgZga6SPNcmsPvbNs4kpUQjY%3D&reserved=0
> 
> 
>  and these both look like false positives (they include "negative" and
> "variance" but not "negative variance" ...)
> 
>  The short answer is that I am not aware of any mixed effect package
> in R that will allow you to return negative values. You can see my
> answer here:
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2018q1%2F026437.html&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=2E5S51uIXiPEsuH11f693MEOLYFb2dh5e39t2GSLor8%3D&reserved=0 ...
> 
> 
>  As for uncertainties in variances - the merDeriv package (dating back
> to 2017) will give you the standard errors of variances and covariances
> (although again, note that there's a theoretical issue here - the
> standard errors are often extremely poor summaries of the uncertainty or
> RE variances, the original authors of lme4 would certainly prefer that
> you use profile confidence intervals to summarize the uncertainty ...)
> 
>  That's what I know -- perhaps someone else knows about a package that
> allows for negative variances ... ??
> 
> On 2023-06-19 6:13 p.m., Will Hopkins wrote:
> I've just joined this list to get answers to a few questions. I would
> have
> searched the archive before posting, but there seems to be no way of
> searching except via quarterly summaries. I searched the last four
> quarters
> without success.
> 
> I'm a SAS user, but a few years ago I tried the mixed model in R, with
> the
> help of an R user (Alice Sweeting). At that time, the lme package did not
> provide standard errors for the variances, nor did it allow negative
> variance. Have these limitations been addressed?  As I recall, Alice
> found
> some code that provided standard errors, but it gave values different
> from
> those of the mixed model in SAS (Proc Mixed). I therefore opted to stay
> with
> SAS, because allowing for negative variance for random effects other than
> residuals and estimating uncertainties in variances are both fundamental
> to
> mixed modeling, in my view. I also became fluent with SAS coding over the
> years and did not want to make the effort with R coding. Interestingly,
> SAS
> introduced a free cloud version called SAS Studio, evidently modeled on R
> Studio, to try to win back customers!
> 
> Will
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> 
> 
>   [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From w|||thek|w| @end|ng |rom gm@||@com  Thu Jun 22 00:25:02 2023
From: w|||thek|w| @end|ng |rom gm@||@com (Will Hopkins)
Date: Thu, 22 Jun 2023 10:25:02 +1200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <0e1101d9a3d4$7afbb210$70f31630$@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>
 <CAFUVuJx_B6nUm4fSxY26gqmNyC1sC+muyh802ms+V2m8FNt-hA@mail.gmail.com>
 <0e1101d9a3d4$7afbb210$70f31630$@gmail.com>
Message-ID: <141201d9a48f$3b5735b0$b205a110$@gmail.com>

Someone emailed me personally to point out a mistake in my SAS random-effects code for individual responses. I had random xVarExpt*SubjectID, which is correct, but it is equivalent to random xVarExpt/subject=SubjectID, not intercept/subject=SubjectID. Sorry about that. It's distressingly easy to make such simple errors, but hopefully they become obvious when you run the program and get silly results, infinite likelihood, or failed to converge. 

If you model original scores rather than change scores, the fixed effect is Group*Trial and there are two random effects: SubjectID xVarExpt*SubjectID (or intercept xVarExpt/subject=SubjectID) along with the residual. By the way, with a big-enough sample size, you can estimate individual responses with this model for the original scores and data for only one group. The fixed effect is then simply Trial. Of course, there is a lot of uncertainty, depending on the sample size and the relative magnitudes of the between-subject SD and error-of-measurement (residual) SD. It still amazes me that Proc Mixed can partition out three variances from two SDs on the same subjects. If you don't estimate individual responses directly with a dummy variable, you can estimate a different residual variance in the pre- and post-test. The individual-response variance is the difference between the residual variances. Does lme have the option for specifying different random effects and/or residuals in different groups? In SAS its simply done with the /group= syntax (here repeated/group=Trial).

Stevedrd has raised the issue of adjusting for the pretest value. Yes, that improves precision by accounting for regression to the mean with change scores, when error of measurement is substantial relative to the between-subject SD in the pretest. I routinely include the pretest when modeling change scores; the fixed effects are then Group Group*PreTest. You thereby estimate the individual responses with improved precision, but it has no effect on their expected value, unless the pretest really does modify the treatment effect (which sometimes happens, especially with human performance). The resulting individual responses are those not explained by the pretest and by any other effect modifiers you put in the fixed-effects model. You can't include the pretest when you model original scores, unless you make the post-test value the dependent and adjust for the pretest; I don't normally do it that way, because modeling change scores is easier for people to understand and to visualize in scatterplots, IMHO.

In response to Ben Bolker... I said merDeriv's results may be untrustworthy, because you said previously that "the standard errors are often extremely poor summaries of the uncertainty or RE variances". I thought your comment was about the standard errors produced by merDeriv, not any standard errors for variances produced by mixed models. I can't remember what package Alice found for producing standard errors with lme, but it was around 2017 and so it may have been merDeriv. As I said in my first message, the SEs weren't the same as SAS's, so I assumed "extremely poor" referred to merDeriv. As for the standard errors being extremely poor summaries in general, I don't know where that assessment comes from. In my experience with SAS they are excellent summaries. For simple models you get exactly what you would expect for the degrees of freedom, and the confidence intervals have acceptable coverage. SAS assumes a normal sampling distribution for the variance, centered on the observed variance, not the log of the variance.

In response to Ben Peizer... The change score is the dependent variable in a controlled trial, with one observation per subject in the control group and one per subject in the experimental group. If the SD of the change scores in the experimental group is less than that in the control group, and you specify a model that estimates extra variance in the experimental group with a dummy variable, you will get negative variance. If instead you specify extra variance in the control group, you will get equal and opposite variance. The SE is the same. Why bother to specify extra variance in the experimental group, if you can see that the variance in that group is less than that in the control group?  Because there probably are real individual responses in the experimental group, and you want to see how big they could be, by estimating their upper confidence limit.  The observed SD of change scores in the experimental group may be less than that in the control group simply because of sampling variation, especially for small sample sizes. 

I like John Maindonald's comparison with square root of -1. I wonder if it is possible to work with SDs as complex numbers. I can't see how at the moment.

Will

-----Original Message-----
From: Will Hopkins <willthekiwi at gmail.com> 
Sent: Wednesday, June 21, 2023 12:08 PM
To: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Standard errors of variances; negative variance

Thanks heaps for the seven replies from five people on this list. In summary, it looks like standard errors could be derived for variances in R: with asreml-R (which you have to pay for?); possibly with nlme; with merDeriv, but they may be untrustworthy; and with Bayesian packages (but I'd be specifying weakly informative priors that in the limit have no effect on the posterior, which might not work in some packages). Negative variance seems to be off the table, however. Ben, James and Timothee have indicated scenarios where negative variance made some sense. 

I had a particular reason for seeking advice on this list; see the bottom of my message. First, here's my justification for negative variance and standard errors of variances.

My favorite example is the variance representing individual responses to a treatment, derived as the variance of the change scores in an experimental group minus the variance of the change scores in a control group. In a mixed model, the dependent is the change score, there is a fixed effect for group (to estimate the difference in the mean changes), other fixed-effect modifiers if you want them, and a random effect for the interaction of a dummy variable (1 in the experimental group, 0 in the control group) with subject identity. I usually call the dummy variable something like xVarExpt, to indicate extra variance in the experimental change scores, and the code in SAS is random xVarExpt*SubjectID; or random intercept/subject=SubjectID;. And of course there is the residual. 

Usually the variance of the change scores in the experimental group is greater than that in the control group, owing to individual responses. But with small sample sizes, the variance on the experimental group could be less than that in the control, simply because of sampling variation. You will therefore get a negative variance point estimate. Importantly, its upper confidence limit will tell you how big and positive the individual responses could be. The confidence interval for variances estimated by Proc Mixed in SAS have good coverage in my experience with many simulations over the years. (The coverage isn't quite so good in meta-analytic mixed models when the study-estimate sample sizes are small, but the coverage is generally conservative, i.e., what you specify as a 90%CI has greater than 90% coverage, as I recall.) The coverage works well ONLY when you allow negative variance for the random effects. Interestingly, the default in SAS is positive-only variance, and if you ask for confidence limits, they are calculated from a standard error and the chi-squared distribution. The resulting confidence limits are unrealistic: you can get enormous upper limits. When you allow negative variance, they are realistic; quoting from the on-line documentation, "Wald Z-scores and normal quantiles are used to construct the limits". (See  https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_mixed_syntax01.htm There is no further information about how the standard errors are calculated and no mention of profile confidence limits.) The confidence limits for the residual(s) are always calculated from the chi-squared distribution, unless you specify otherwise, and these are always realistic and have correct coverage, in my experience.

The variance in the experimental group could truly be less than that in the control group, either because the treatment compresses the responses towards some upper or lower limit, or less likely because there are individual responses to the control treatment that exceed those to the experimental treatment. Either way negative variance is meaningful. You can turn the dummy variable around if you like, but you don't have to.

When I get a negative variance, or a negative lower confidence limit, I have no hesitation in changing the sign, taking the square root, and calling it a negative SD. It just simply means that the individual responses, or more generally whatever differences or variability are represented by the random effect, could be reduced differences or variability. I know a negative SD for the intercept random effect is a hard one to swallow, but it's better to see that and think again about your model and/or what might really be happening than to simply let it be set to zero. 

I would like to emphasize just how important the random effects are in the analysis of repeated measurement or other clustered data. That's where the individual differences and individual responses are found, which are crucial in this age of personalized medicine. Hence you need to make inferences about the random effects; they are not simply nuisance parameters that you have to include to make sure the uncertainty in the mean effects are trustworthy, then forget about. I make inferences about magnitudes of the random effects (Bayesian or hypothesis testing against smallest importants) assuming a normal distribution (chi-squared for residuals) and smallest importants for SDs that are half those for mean effects.

OK, enough of the hobby horse. I wanted to find out whether R allows for negative variances and standard errors of variances, because I am working with a colleague on a manuscript focusing on the correct way to analyze, report and interpret errors of measurement in various kinds of reliability study. Example: for some measures, the first measurement in a series of repeated measurements can have more error, which is easily specified and estimated with a dummy variable, as explained above for individual responses. Another example: the possibility of additional error arising between time-separated clusters of repeated measurements needs to be specified as a random effect that can have negative variance. We've simulated data and analyzed them all with SAS Studio, and we hope to publish the programs as supplementary material. We're looking for a co-author/collaborator who had experience of measurement studies and skill with mixed models in R to provide the same simulations and analyses with R. It's contingent upon estimating negative variance and standard errors of variances, both of which require more than lme or nlme, by the look of it. Maybe it's a good opportunity for someone to get involved and figure out the easiest way to get the same estimates and uncertainties as in SAS, because that would or should be useful for mixed modeling more generally with R.

Will


From jhm@|ndon@|d @end|ng |rom gm@||@com  Thu Jun 22 03:15:57 2023
From: jhm@|ndon@|d @end|ng |rom gm@||@com (John H Maindonald)
Date: Thu, 22 Jun 2023 13:15:57 +1200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
Message-ID: <A9F40D25-C319-4948-AF05-6A8632B81E77@gmail.com>

Another way to look at the issue is that variance components are just
that ? components that cannot necessarily be interpreted as variances.
They cannot even necessarily be interpreted in a particularly meaningful 
way as variances, even if the values come out as positive.
John Maindonald
Statistics Research Associates, Wellington NZ.

Dear  All,
As with the square root of -1, negative variances are a convenient 
computational fiction.  The square root of -1 is an invitation to move
to a 2-dimensional word, where they make perfect sense.

A negative variance estimate, in those systems that allow it, is a useful 
warning that one needs to think and move beyond the one-dimensional 
representation in which the variances have been set.
John Maindonald
Statistics Research Associates, Wellington NZ.

> On 21/06/2023, at 01:21, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> 
> Thierry,
> I have the same question that you posed, how can a variance, a measure that is squared be negative? Will, please enlighten us!
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicinet
> Baltimore VA Medical Center
> 10 North Greene Street<x-apple-data-detectors://12>
> GRECC<x-apple-data-detectors://12> (BT/18/GR)
> Baltimore, MD 21201-1524<x-apple-data-detectors://13/0>
> (Phone) 410-605-711<tel:410-605-7119>9
> (Fax) 410-605-7913<tel:410-605-7913> (Please call phone number above prior to faxing)
> 
> On Jun 20, 2023, at 3:45 AM, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> 
> ?Dear all,
> 
> A negative variance seems odd to me. Isn't a variance positive by
> definition? How would you interpret a random intercept with a negative
> variance?
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=sbP2Xemwg0iHjvxcc6zR8vtPbZf5ZoFCv1BIFIeDdBE%3D&reserved=0
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=I5HJ05o0Bd4ly0GL0Smc1iYm3cuZMc2IGCcxy8OWn%2B8%3D&reserved=0>
> 
> 
> Op di 20 jun 2023 om 01:36 schreef Ben Bolker <bbolker at gmail.com>:
> 
> Hi, Will,
> 
> Googling
> 
> site:https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=vw%2FnMxnvA7L9A0qYuJfHa9suA2YBTnZ%2BqxPltyR3G%2FU%3D&reserved=0 "negative
> variance"
> 
> claims to get you 67 results (although only 11 that Google considers
> worth displaying by default),
> 
> You can filter by date - there are only two hits since 2020:
> 
> 
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dsite%253Ahttps%253A%252F%252Fstat.ethz.ch%252Fpipermail%252Fr-sig-mixed-models%252F%2B%2522negative%2Bvariance%2522%26client%3Dfirefox-b-d%26tbs%3Dcdr%253A1%252Ccd_min%253A01-01-2020%252Ccd_max%253A%26tbm%3D&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=xbWrjRwClEMYFKVkncDFgZga6SPNcmsPvbNs4kpUQjY%3D&reserved=0
> 
> 
> and these both look like false positives (they include "negative" and
> "variance" but not "negative variance" ...)
> 
> The short answer is that I am not aware of any mixed effect package
> in R that will allow you to return negative values. You can see my
> answer here:
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2018q1%2F026437.html&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=2E5S51uIXiPEsuH11f693MEOLYFb2dh5e39t2GSLor8%3D&reserved=0 ...
> 
> 
> As for uncertainties in variances - the merDeriv package (dating back
> to 2017) will give you the standard errors of variances and covariances
> (although again, note that there's a theoretical issue here - the
> standard errors are often extremely poor summaries of the uncertainty or
> RE variances, the original authors of lme4 would certainly prefer that
> you use profile confidence intervals to summarize the uncertainty ...)
> 
> That's what I know -- perhaps someone else knows about a package that
> allows for negative variances ... ??
> 
> On 2023-06-19 6:13 p.m., Will Hopkins wrote:
> I've just joined this list to get answers to a few questions. I would
> have
> searched the archive before posting, but there seems to be no way of
> searching except via quarterly summaries. I searched the last four
> quarters
> without success.
> 
> I'm a SAS user, but a few years ago I tried the mixed model in R, with
> the
> help of an R user (Alice Sweeting). At that time, the lme package did not
> provide standard errors for the variances, nor did it allow negative
> variance. Have these limitations been addressed?  As I recall, Alice
> found
> some code that provided standard errors, but it gave values different
> from
> those of the mixed model in SAS (Proc Mixed). I therefore opted to stay
> with
> SAS, because allowing for negative variance for random effects other than
> residuals and estimating uncertainties in variances are both fundamental
> to
> mixed modeling, in my view. I also became fluent with SAS coding over the
> years and did not want to make the effort with R coding. Interestingly,
> SAS
> introduced a free cloud version called SAS Studio, evidently modeled on R
> Studio, to try to win back customers!
> 
> Will
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> 
> 
>  [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jh@|t|g@ @end|ng |rom gm@||@com  Thu Jun 22 03:32:34 2023
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Wed, 21 Jun 2023 21:32:34 -0400
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <A9F40D25-C319-4948-AF05-6A8632B81E77@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <A9F40D25-C319-4948-AF05-6A8632B81E77@gmail.com>
Message-ID: <CAH_7VOmTmd3ew4C5NGZrywpH6-pOS2ssLr8WbexkDamLRxFBxw@mail.gmail.com>

This negative variance issue crops up in factor analysis oftentimes with
Heywood cases etc. One approach that has often been invoked in this
literature is to set them to zero, though it has been some time since I
have delved deep into this literature.

On Wed, Jun 21, 2023 at 9:16?PM John H Maindonald <jhmaindonald at gmail.com>
wrote:

> Another way to look at the issue is that variance components are just
> that ? components that cannot necessarily be interpreted as variances.
> They cannot even necessarily be interpreted in a particularly meaningful
> way as variances, even if the values come out as positive.
> John Maindonald
> Statistics Research Associates, Wellington NZ.
>
> Dear  All,
> As with the square root of -1, negative variances are a convenient
> computational fiction.  The square root of -1 is an invitation to move
> to a 2-dimensional word, where they make perfect sense.
>
> A negative variance estimate, in those systems that allow it, is a useful
> warning that one needs to think and move beyond the one-dimensional
> representation in which the variances have been set.
> John Maindonald
> Statistics Research Associates, Wellington NZ.
>
> > On 21/06/2023, at 01:21, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> >
> >
> > Thierry,
> > I have the same question that you posed, how can a variance, a measure
> that is squared be negative? Will, please enlighten us!
> > John
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicinet
> > Baltimore VA Medical Center
> > 10 North Greene Street<x-apple-data-detectors://12>
> > GRECC<x-apple-data-detectors://12> (BT/18/GR)
> > Baltimore, MD 21201-1524<x-apple-data-detectors://13/0>
> > (Phone) 410-605-711<tel:410-605-7119>9
> > (Fax) 410-605-7913<tel:410-605-7913> (Please call phone number above
> prior to faxing)
> >
> > On Jun 20, 2023, at 3:45 AM, Thierry Onkelinx via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org> wrote:
> >
> > ?Dear all,
> >
> > A negative variance seems odd to me. Isn't a variance positive by
> > definition? How would you interpret a random intercept with a negative
> > variance?
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> >
> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=sbP2Xemwg0iHjvxcc6zR8vtPbZf5ZoFCv1BIFIeDdBE%3D&reserved=0
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.inbo.be%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=I5HJ05o0Bd4ly0GL0Smc1iYm3cuZMc2IGCcxy8OWn%2B8%3D&reserved=0
> >
> >
> >
> > Op di 20 jun 2023 om 01:36 schreef Ben Bolker <bbolker at gmail.com>:
> >
> > Hi, Will,
> >
> > Googling
> >
> > site:
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=vw%2FnMxnvA7L9A0qYuJfHa9suA2YBTnZ%2BqxPltyR3G%2FU%3D&reserved=0
> "negative
> > variance"
> >
> > claims to get you 67 results (although only 11 that Google considers
> > worth displaying by default),
> >
> > You can filter by date - there are only two hits since 2020:
> >
> >
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3Dsite%253Ahttps%253A%252F%252Fstat.ethz.ch%252Fpipermail%252Fr-sig-mixed-models%252F%2B%2522negative%2Bvariance%2522%26client%3Dfirefox-b-d%26tbs%3Dcdr%253A1%252Ccd_min%253A01-01-2020%252Ccd_max%253A%26tbm%3D&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=xbWrjRwClEMYFKVkncDFgZga6SPNcmsPvbNs4kpUQjY%3D&reserved=0
> >
> >
> > and these both look like false positives (they include "negative" and
> > "variance" but not "negative variance" ...)
> >
> > The short answer is that I am not aware of any mixed effect package
> > in R that will allow you to return negative values. You can see my
> > answer here:
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F2018q1%2F026437.html&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=2E5S51uIXiPEsuH11f693MEOLYFb2dh5e39t2GSLor8%3D&reserved=0
> ...
> >
> >
> > As for uncertainties in variances - the merDeriv package (dating back
> > to 2017) will give you the standard errors of variances and covariances
> > (although again, note that there's a theoretical issue here - the
> > standard errors are often extremely poor summaries of the uncertainty or
> > RE variances, the original authors of lme4 would certainly prefer that
> > you use profile confidence intervals to summarize the uncertainty ...)
> >
> > That's what I know -- perhaps someone else knows about a package that
> > allows for negative variances ... ??
> >
> > On 2023-06-19 6:13 p.m., Will Hopkins wrote:
> > I've just joined this list to get answers to a few questions. I would
> > have
> > searched the archive before posting, but there seems to be no way of
> > searching except via quarterly summaries. I searched the last four
> > quarters
> > without success.
> >
> > I'm a SAS user, but a few years ago I tried the mixed model in R, with
> > the
> > help of an R user (Alice Sweeting). At that time, the lme package did not
> > provide standard errors for the variances, nor did it allow negative
> > variance. Have these limitations been addressed?  As I recall, Alice
> > found
> > some code that provided standard errors, but it gave values different
> > from
> > those of the mixed model in SAS (Proc Mixed). I therefore opted to stay
> > with
> > SAS, because allowing for negative variance for random effects other than
> > residuals and estimating uncertainties in variances are both fundamental
> > to
> > mixed modeling, in my view. I also became fluent with SAS coding over the
> > years and did not want to make the effort with R coding. Interestingly,
> > SAS
> > introduced a free cloud version called SAS Studio, evidently modeled on R
> > Studio, to try to win back customers!
> >
> > Will
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> >
> >
> >  [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Cjsorkin%40som.umaryland.edu%7C2c0d1047636b43c2bfcc08db71625f82%7C717009a620de461a88940312a395cac9%7C0%7C0%7C638228439560019013%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cPlRiZIOr3%2B4lUfOPHm26RrP4peEw9ZAkjtm5enO4Uw%3D&reserved=0
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Thu Jun 22 09:19:37 2023
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Thu, 22 Jun 2023 09:19:37 +0200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <141201d9a48f$3b5735b0$b205a110$@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <5be06498-6645-d96d-edf7-b2971f0b7754@gmail.com>
 <CAFUVuJx_B6nUm4fSxY26gqmNyC1sC+muyh802ms+V2m8FNt-hA@mail.gmail.com>
 <0e1101d9a3d4$7afbb210$70f31630$@gmail.com>
 <141201d9a48f$3b5735b0$b205a110$@gmail.com>
Message-ID: <CAFgPNS-_MC0mAKbfevQCftHWBSd8jkVHVB7b9raVqxzCZCAe_Q@mail.gmail.com>

Hi Will,

I was wondering if your "strange variance" result is basically comparable
to the following simple R script. Data are simulated, with no higher level
at all. For each "subject" there is only one single observation. Trying to
estimate both the residual variance SE and also a random intercept variance
with lmer (after switching off all mechanisms which prevent a user to
estimate such a "strange" model) and lme, leads to quite arbitrary results
for the two variance estimates. Obviously, estimating two quantities when
there exists only one is problematic.... so why would I like to estimate
such a model? But maybe your situation is different, a reproducible example
(data + sas code) might be enlightening. Best regards, Ben P.

y <- rnorm(100, 0, 1)
subject <- 1:100

library(lme4)
m1 <- lmer(y ~ (1|subject),
           control=lmerControl(check.nobs.vs.nlev = "ignore",
                               check.nobs.vs.rankZ = "ignore",
                               check.nobs.vs.nRE="ignore"))
summary(m1)

library(nlme)
m2 <- lme(y ~ 1, random=~1|subject)
summary(m2)



On Thu, 22 Jun 2023 at 00:25, Will Hopkins <willthekiwi at gmail.com> wrote:

> Someone emailed me personally to point out a mistake in my SAS
> random-effects code for individual responses. I had random
> xVarExpt*SubjectID, which is correct, but it is equivalent to random
> xVarExpt/subject=SubjectID, not intercept/subject=SubjectID. Sorry about
> that. It's distressingly easy to make such simple errors, but hopefully
> they become obvious when you run the program and get silly results,
> infinite likelihood, or failed to converge.
>
> If you model original scores rather than change scores, the fixed effect
> is Group*Trial and there are two random effects: SubjectID
> xVarExpt*SubjectID (or intercept xVarExpt/subject=SubjectID) along with the
> residual. By the way, with a big-enough sample size, you can estimate
> individual responses with this model for the original scores and data for
> only one group. The fixed effect is then simply Trial. Of course, there is
> a lot of uncertainty, depending on the sample size and the relative
> magnitudes of the between-subject SD and error-of-measurement (residual)
> SD. It still amazes me that Proc Mixed can partition out three variances
> from two SDs on the same subjects. If you don't estimate individual
> responses directly with a dummy variable, you can estimate a different
> residual variance in the pre- and post-test. The individual-response
> variance is the difference between the residual variances. Does lme have
> the option for specifying different random effects and/or residuals in diffe
>  rent groups? In SAS its simply done with the /group= syntax (here
> repeated/group=Trial).
>
> Stevedrd has raised the issue of adjusting for the pretest value. Yes,
> that improves precision by accounting for regression to the mean with
> change scores, when error of measurement is substantial relative to the
> between-subject SD in the pretest. I routinely include the pretest when
> modeling change scores; the fixed effects are then Group Group*PreTest. You
> thereby estimate the individual responses with improved precision, but it
> has no effect on their expected value, unless the pretest really does
> modify the treatment effect (which sometimes happens, especially with human
> performance). The resulting individual responses are those not explained by
> the pretest and by any other effect modifiers you put in the fixed-effects
> model. You can't include the pretest when you model original scores, unless
> you make the post-test value the dependent and adjust for the pretest; I
> don't normally do it that way, because modeling change scores is easier for
> people to understand and to visualize in
>  scatterplots, IMHO.
>
> In response to Ben Bolker... I said merDeriv's results may be
> untrustworthy, because you said previously that "the standard errors are
> often extremely poor summaries of the uncertainty or RE variances". I
> thought your comment was about the standard errors produced by merDeriv,
> not any standard errors for variances produced by mixed models. I can't
> remember what package Alice found for producing standard errors with lme,
> but it was around 2017 and so it may have been merDeriv. As I said in my
> first message, the SEs weren't the same as SAS's, so I assumed "extremely
> poor" referred to merDeriv. As for the standard errors being extremely poor
> summaries in general, I don't know where that assessment comes from. In my
> experience with SAS they are excellent summaries. For simple models you get
> exactly what you would expect for the degrees of freedom, and the
> confidence intervals have acceptable coverage. SAS assumes a normal
> sampling distribution for the variance, centered on the observed v
>  ariance, not the log of the variance.
>
> In response to Ben Peizer... The change score is the dependent variable in
> a controlled trial, with one observation per subject in the control group
> and one per subject in the experimental group. If the SD of the change
> scores in the experimental group is less than that in the control group,
> and you specify a model that estimates extra variance in the experimental
> group with a dummy variable, you will get negative variance. If instead you
> specify extra variance in the control group, you will get equal and
> opposite variance. The SE is the same. Why bother to specify extra variance
> in the experimental group, if you can see that the variance in that group
> is less than that in the control group?  Because there probably are real
> individual responses in the experimental group, and you want to see how big
> they could be, by estimating their upper confidence limit.  The observed SD
> of change scores in the experimental group may be less than that in the
> control group simply because of sampling
>   variation, especially for small sample sizes.
>
> I like John Maindonald's comparison with square root of -1. I wonder if it
> is possible to work with SDs as complex numbers. I can't see how at the
> moment.
>
> Will
>
> -----Original Message-----
> From: Will Hopkins <willthekiwi at gmail.com>
> Sent: Wednesday, June 21, 2023 12:08 PM
> To: r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Standard errors of variances; negative variance
>
> Thanks heaps for the seven replies from five people on this list. In
> summary, it looks like standard errors could be derived for variances in R:
> with asreml-R (which you have to pay for?); possibly with nlme; with
> merDeriv, but they may be untrustworthy; and with Bayesian packages (but
> I'd be specifying weakly informative priors that in the limit have no
> effect on the posterior, which might not work in some packages). Negative
> variance seems to be off the table, however. Ben, James and Timothee have
> indicated scenarios where negative variance made some sense.
>
> I had a particular reason for seeking advice on this list; see the bottom
> of my message. First, here's my justification for negative variance and
> standard errors of variances.
>
> My favorite example is the variance representing individual responses to a
> treatment, derived as the variance of the change scores in an experimental
> group minus the variance of the change scores in a control group. In a
> mixed model, the dependent is the change score, there is a fixed effect for
> group (to estimate the difference in the mean changes), other fixed-effect
> modifiers if you want them, and a random effect for the interaction of a
> dummy variable (1 in the experimental group, 0 in the control group) with
> subject identity. I usually call the dummy variable something like
> xVarExpt, to indicate extra variance in the experimental change scores, and
> the code in SAS is random xVarExpt*SubjectID; or random
> intercept/subject=SubjectID;. And of course there is the residual.
>
> Usually the variance of the change scores in the experimental group is
> greater than that in the control group, owing to individual responses. But
> with small sample sizes, the variance on the experimental group could be
> less than that in the control, simply because of sampling variation. You
> will therefore get a negative variance point estimate. Importantly, its
> upper confidence limit will tell you how big and positive the individual
> responses could be. The confidence interval for variances estimated by Proc
> Mixed in SAS have good coverage in my experience with many simulations over
> the years. (The coverage isn't quite so good in meta-analytic mixed models
> when the study-estimate sample sizes are small, but the coverage is
> generally conservative, i.e., what you specify as a 90%CI has greater than
> 90% coverage, as I recall.) The coverage works well ONLY when you allow
> negative variance for the random effects. Interestingly, the default in SAS
> is positive-only variance, and if you ask f
>  or confidence limits, they are calculated from a standard error and the
> chi-squared distribution. The resulting confidence limits are unrealistic:
> you can get enormous upper limits. When you allow negative variance, they
> are realistic; quoting from the on-line documentation, "Wald Z-scores and
> normal quantiles are used to construct the limits". (See
> https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_mixed_syntax01.htm
> There is no further information about how the standard errors are
> calculated and no mention of profile confidence limits.) The confidence
> limits for the residual(s) are always calculated from the chi-squared
> distribution, unless you specify otherwise, and these are always realistic
> and have correct coverage, in my experience.
>
> The variance in the experimental group could truly be less than that in
> the control group, either because the treatment compresses the responses
> towards some upper or lower limit, or less likely because there are
> individual responses to the control treatment that exceed those to the
> experimental treatment. Either way negative variance is meaningful. You can
> turn the dummy variable around if you like, but you don't have to.
>
> When I get a negative variance, or a negative lower confidence limit, I
> have no hesitation in changing the sign, taking the square root, and
> calling it a negative SD. It just simply means that the individual
> responses, or more generally whatever differences or variability are
> represented by the random effect, could be reduced differences or
> variability. I know a negative SD for the intercept random effect is a hard
> one to swallow, but it's better to see that and think again about your
> model and/or what might really be happening than to simply let it be set to
> zero.
>
> I would like to emphasize just how important the random effects are in the
> analysis of repeated measurement or other clustered data. That's where the
> individual differences and individual responses are found, which are
> crucial in this age of personalized medicine. Hence you need to make
> inferences about the random effects; they are not simply nuisance
> parameters that you have to include to make sure the uncertainty in the
> mean effects are trustworthy, then forget about. I make inferences about
> magnitudes of the random effects (Bayesian or hypothesis testing against
> smallest importants) assuming a normal distribution (chi-squared for
> residuals) and smallest importants for SDs that are half those for mean
> effects.
>
> OK, enough of the hobby horse. I wanted to find out whether R allows for
> negative variances and standard errors of variances, because I am working
> with a colleague on a manuscript focusing on the correct way to analyze,
> report and interpret errors of measurement in various kinds of reliability
> study. Example: for some measures, the first measurement in a series of
> repeated measurements can have more error, which is easily specified and
> estimated with a dummy variable, as explained above for individual
> responses. Another example: the possibility of additional error arising
> between time-separated clusters of repeated measurements needs to be
> specified as a random effect that can have negative variance. We've
> simulated data and analyzed them all with SAS Studio, and we hope to
> publish the programs as supplementary material. We're looking for a
> co-author/collaborator who had experience of measurement studies and skill
> with mixed models in R to provide the same simulations and analyses wi
>  th R. It's contingent upon estimating negative variance and standard
> errors of variances, both of which require more than lme or nlme, by the
> look of it. Maybe it's a good opportunity for someone to get involved and
> figure out the easiest way to get the same estimates and uncertainties as
> in SAS, because that would or should be useful for mixed modeling more
> generally with R.
>
> Will
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From w|||thek|w| @end|ng |rom gm@||@com  Fri Jun 23 03:42:02 2023
From: w|||thek|w| @end|ng |rom gm@||@com (Will Hopkins)
Date: Fri, 23 Jun 2023 13:42:02 +1200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <A9F40D25-C319-4948-AF05-6A8632B81E77@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <A9F40D25-C319-4948-AF05-6A8632B81E77@gmail.com>
Message-ID: <1c3901d9a573$ea99cb70$bfcd6250$@gmail.com>

In response to John Maindonald's latest post... John, you suggested that the variance components "cannot necessarily be interpreted as variances". I don?t think so. For any real data, variance components can and should be interpreted as the square of standard deviations, which have a direct interpretation in terms of differences between and/or changes within subjects and/or settings. You only have to simulate data to realize that: all the random effects are generated randomly with a mean of zero and a given SD. (Admittedly the data have to be generated with positive SDs. I'm not sure how to simulate data directly with a negative SD, although I can do it indirectly by adding random variability in the "wrong" or unexpected place.) To allow for sampling variation in the estimation of the SD, you have to allow negative variance. When you do that, you estimate the simulated SD without bias, and the confidence intervals have correct coverage. If you don't allow negative variance, you will get bias and unrealistic upper confidence limits, with small sample sizes anyway. Negative point estimates and negative lower confidence limits are realistic in the sense that they properly allow for sampling uncertainty, and in any case they may be real, in the sense that the extra variance could be in a different place from what you expected and modeled.

in response to Ben Pelzer's latest post... Ben, you can't get the extra variance with only one observation per subject in one group. You can get it with two observations on the same subject in one group; so for a group of subjects measured in two trials, without necessarily anything else happening, you can estimate the variance representing true differences between subjects with random int/subject=SubjectID and two residual variances with repeated/group=Trial. And with the same data and exactly the same results, you can estimate one residual variance and the difference between the residuals as extra variance, either on the first trial or the second trial, and it will positive or negative variance, depending on which residual was greater with the repeated/group=Trial analysis. (The variances add up exactly, but the predicted values differ very slightly between the models where the extra variance is positive and negative.) Here is the SAS code for doing all that, written with macro variables to allow you to change values of means, SDs and sample size. Remember that sample size has to large to get good precision for the SDs. I've set the sample size to 100. If you make it 10, there's huge uncertainty, and sometimes it gives infinite likelihood (although you can probably overcome that with suitable starting values for the covparms). Note that I have not added extra variance representing individual responses in Trial 2 (as shown with %let ir=0;), so half the simulations will produce negative extra variance in Trial 2, and you can play with estimating the extra variance in either of the trials to see that you get the same extra variance differing only in sign, and the same standard error.

*Simple test-retest reliability, allowing for different residuals in the two trials
 and individual responses in the second trial;
*Modify the program as shown in the proc mixed step to estimate one residual
 and extra variance one or other trial;

%let mean=100; *true grand mean in the first test;
%let sd=10; *true between-subject SD;
%let tem=5; *typical (standard) error of measurement;
%let deltamean=2; *change in mean test2-test1;
%let ir=0; *SD for individual responses (in Trial 2);
%let ss=100; *sample size;

*generate the data;
data dat1;
do SubjectID=1 to &ss;
  TruePerform=&mean+&sd*rannor(0);
  Trial=1;
  IndivResp=0;
  ObsvdPerform=TruePerform+&tem*rannor(0)+IndivResp;
  output;
  Trial=2;
  IndivResp=&ir*rannor(0);
  ObsvdPerform=TruePerform+&tem*rannor(0)+&deltamean+IndivResp;
  output;
  end;

title "Raw data, first 10 observations";
proc print data=dat1(obs=10);
format TruePerform ObsvdPerform IndivResp 5.1;
run;

title "Simple stats";
proc means maxdec=1;
var TruePerform ObsvdPerform IndivResp;
class Trial;
run;

*Set up dummy variables for estimating extra variance in Trial 1 or Trial 2;
data dat2;
set dat1;
xVarTrial1=0;
if Trial=1 then xVarTrial1=1;
xVarTrial2=0;
if Trial=2 then xVarTrial2=1;

ods select none;
title "Rely mixed model, ssize=&ss";
title2 "True mean=&mean, true between SD=&sd, TEM=&tem, delta mean=&deltamean";
proc mixed data=dat2 covtest cl alpha=0.1 nobound;
class SubjectID Trial;
model ObsvdPerform=Trial/noint ddfm=sat solution cl alpha=0.1 outp=pred alphap=0.1;
random int/subject=SubjectID s cl alpha=0.1; *This estimates true differences between subjects;
repeated/group=Trial; *This estimates different residuals in Trial 1 and 2;
*Star off the above two lines and unstar one or other (but not both) of the following two lines...;
*...to estimate one residual and extra variance on either Trial 1 or Trial 2;
*random int xVarTrial1/subject=SubjectID s cl alpha=0.1; *extra error on Trial 1;
*random int xVarTrial2/subject=SubjectID s cl alpha=0.1; *or extra variance on Trial 1;
estimate "Trial 2-1" Trial -1 1/cl alpha=0.1;
ods output classlevels=clev;
ods output covparms=cov;
ods output solutionf=solf;
ods output solutionr=solr;
ods output estimates=est;
run;
ods select all;

title3 "Class levels";
proc print data=clev;
run;

title3 "Covparms";
proc print data=cov;
run;

title3 "Predicteds and residuals, first 10 observations";
proc print data=pred(obs=10);
run;

title3 "Fixed-effects solution";
proc print data=solf;
run;

title3 "Random-effects solution, first 10 observations";
proc print data=solr(obs=10);
run;

title3 "Estimates";
proc print data=est;
run;


From jhm@|ndon@|d @end|ng |rom gm@||@com  Fri Jun 23 04:44:23 2023
From: jhm@|ndon@|d @end|ng |rom gm@||@com (John H Maindonald)
Date: Fri, 23 Jun 2023 14:44:23 +1200
Subject: [R-sig-ME] Standard errors of variances; negative variance
In-Reply-To: <A9F40D25-C319-4948-AF05-6A8632B81E77@gmail.com>
References: <CAJuCY5x2OVyhrbW3wLskM0ALR6_Kf2jXff9ystrPfXYUqXuaFQ@mail.gmail.com>
 <8C00A1BC-1807-4996-9687-8F616F5A2F58@som.umaryland.edu>
 <A9F40D25-C319-4948-AF05-6A8632B81E77@gmail.com>
Message-ID: <DF87310B-3943-44F4-916A-CE3A6083933D@gmail.com>

What I am saying is that if in a randomized  block design blocks are 
chosen to be overly heterogeneous, the within blocks component 
of variance will be exaggerated, and the between blocks component
reduced accordingly. A consequence is that the variance components
apply only to the particular layout of blocks and of plots within blocks
used for that particular experiment.  

There may in such cases be ways to use the data, together with what 
one knows of the field layout, to get a wider perspective on what the 
data may have to say. One is then moving outside of the confines of 
the analysis that gave the problematic ?variances?, whether negative 
or just distorted.  These sorts of issues carry over in different ways to
different contexts.

John Maindonald
Statistics Research Associates, Wellington NZ.

From yq|@n @end|ng |rom uw@ter|oo@c@  Tue Jun 27 17:16:05 2023
From: yq|@n @end|ng |rom uw@ter|oo@c@ (Yu qing Fan)
Date: Tue, 27 Jun 2023 15:16:05 +0000
Subject: [R-sig-ME] Inquiry about GLMM model
Message-ID: <YT2PR01MB8121D4D073AF5563D2B4DDFFDB27A@YT2PR01MB8121.CANPRD01.PROD.OUTLOOK.COM>

Hello,

Hope you all had a nice day. My name is Yuqing Fan and I am a Bachelor student. I am doing a longitudinal analysis using GLMM model, and now I encounter some diffculties.

As you might see in the codes, when generating the first model(fit1), R would say "function evaluation limit reached without convergence". I reduced the number of covariates like fit2 and fit3, and that's how I found the covaraite "position" led to error. I then cut levels of "position" from 5 to 3, yet the error still occurs. Could anyone please give me some advice about how can I fix problems here? Thank you for your time!

Yours sincerely,
Yuqing Fan

From me @end|ng |rom ph||||p@|d@y@com  Tue Jun 27 19:52:57 2023
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 27 Jun 2023 13:52:57 -0400 (EDT)
Subject: [R-sig-ME] Inquiry about GLMM model
In-Reply-To: <YT2PR01MB8121D4D073AF5563D2B4DDFFDB27A@YT2PR01MB8121.CANPRD01.PROD.OUTLOOK.COM>
References: <YT2PR01MB8121D4D073AF5563D2B4DDFFDB27A@YT2PR01MB8121.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <1433390380.147028.1687888377441@office.mailbox.org>

I think the code you reference was in an attachment, which didn't make it through the list serve. Can you post the relevant code in the email message body directy? 

> Yu qing Fan <yqfan at uwaterloo.ca> hat am 27.06.2023 11:16 EDT geschrieben:
> 
>  
> Hello,
> 
> Hope you all had a nice day. My name is Yuqing Fan and I am a Bachelor student. I am doing a longitudinal analysis using GLMM model, and now I encounter some diffculties.
> 
> As you might see in the codes, when generating the first model(fit1), R would say "function evaluation limit reached without convergence". I reduced the number of covariates like fit2 and fit3, and that's how I found the covaraite "position" led to error. I then cut levels of "position" from 5 to 3, yet the error still occurs. Could anyone please give me some advice about how can I fix problems here? Thank you for your time!
> 
> Yours sincerely,
> Yuqing Fan
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From rupprecht @end|ng |rom unbc@c@  Fri Jun 30 18:23:59 2023
From: rupprecht @end|ng |rom unbc@c@ (Meaghan Rupprecht)
Date: Fri, 30 Jun 2023 16:23:59 +0000
Subject: [R-sig-ME] GAMM- Missing/uncertain group id's in random effect
Message-ID: <YT4PR01MB98329EDC859766913B673AC5A32AA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>

I am currently modelling fish catch in the Amazon River in response to variables such as habitat, effort, gear type, and spatial locations. The model we have selected to accomplish this task is a GAMM, and we are currently using the mgcv and brms packages in R. We are facing an issue with random effects in our model, and I was hoping to get some insight about possible solutions. I've tried to find solutions online without much luck.

For each record of fish catch, there is information recorded such as boat name and boat length. We aimed at using this information to generate a unique boat id, which would be treated as a group id for a random effect variable in our model. A problem arises in boat names because they may not be unique, but boat lengths are somewhat unreliable information and could have varying responses. This creates some records where the boat names may be the same with slightly varying lengths, resulting in multiple id's being generated for what might actually be the same boat (i.e., boat 1 with length of 17m and boat 1 with length of 17.2m). This greatly complicates our attempts at identifying unique boats and generates uncertainty in our classifications.
Is there a method for dealing with uncertainty or missing group id's in random effects? I'd be happy to elaborate or provide additional information if anything above was unclear.
Thanks for your time.

	[[alternative HTML version deleted]]


From c@roz @end|ng |rom zed@t@|u-ber||n@de  Fri Jun 30 18:48:32 2023
From: c@roz @end|ng |rom zed@t@|u-ber||n@de (Caroline Zanchi)
Date: Fri, 30 Jun 2023 18:48:32 +0200
Subject: [R-sig-ME] Reply:  Inquiry about GLMM model
In-Reply-To: <YT2PR01MB81217997E80674581DFBF26ADB2AA@YT2PR01MB8121.CANPRD01.PROD.OUTLOOK.COM>
References: <YT2PR01MB8121D4D073AF5563D2B4DDFFDB27A@YT2PR01MB8121.CANPRD01.PROD.OUTLOOK.COM>
 <b9073fdd-65d1-7cfa-036b-cd93338e0fb5@zedat.fu-berlin.de>
 <YT2PR01MB81217997E80674581DFBF26ADB2AA@YT2PR01MB8121.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <d17700a9-be5d-6666-e2fd-015eca83850d@zedat.fu-berlin.de>

But you do have several treatments where some individuals die ?

If no individual died in one level of your variable, then simply say "no 
individuals died in treatment ...", and interpret the rest of your data.

Best,

Caroline

On 6/30/23 16:32, Yu qing Fan wrote:
> Hi,
>
> Yes, that is my case! All my individuals survived at last. Do you have 
> any recommendations for such scenario? Maybe a simpler modelling could 
> help?
>
> Thanks!
> Yuqing Fan
>
>
> ------------------------------------------------------------------------
> Caroline Zanchi <caroz at zedat.fu-berlin.de>
> Yu qing Fan <yqfan at uwaterloo.ca>
> *R*e: [R-sig-ME] Inquiry about GLMM model
> Hello !
>
> This can happen if there is a complete separation of the outcome for the
> response variable per explanatory variable level. For example, if you
> check proportion of surviving individuals and in one treatment all of
> them die, or on the contrary all of them survive.
>
> Is it your case by any chance ?
>
> Caroline
>
> On 6/27/23 17:16, Yu qing Fan wrote:
> > Hello,
> >
> > Hope you all had a nice day. My name is Yuqing Fan and I am a 
> Bachelor student. I am doing a longitudinal analysis using GLMM model, 
> and now I encounter some diffculties.
> >
> > As you might see in the codes, when generating the first 
> model(fit1), R would say "function evaluation limit reached without 
> convergence". I reduced the number of covariates like fit2 and fit3, 
> and that's how I found the covaraite "position" led to error. I then 
> cut levels of "position" from 5 to 3, yet the error still occurs. 
> Could anyone please give me some advice about how can I fix problems 
> here? Thank you for your time!
> >
> > Yours sincerely,
> > Yuqing Fan
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
	[[alternative HTML version deleted]]


