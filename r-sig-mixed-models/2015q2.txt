From hans.ekbrand at gmail.com  Wed Apr  1 03:45:21 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Wed, 1 Apr 2015 03:45:21 +0200
Subject: [R-sig-ME] predict() with varying betas (newparams)
Message-ID: <20150401014521.GA12461@hans>

Dear list,

I would like to predict() in lme4 using new betas. In order to try out
the option newparams I tried the following:

> mean(predict(my.fit, newdata = my.fit at frame, type = "response"))
[1] 0.1445534
> mean(predict(my.fit, newdata = my.fit at frame, type = "response", newparams = list(theta = my.fit at theta, beta = my.fit at beta)))
theta parameter vector not named: assuming same order as internal vector
beta parameter vector not named: assuming same order as internal vector
[1] 0.05619105

I don't understand what theta is, but I did find a slot in the fitted
object, my.fit, so I just passed that vector and hoped for the best :-)

I would have expected the results to be identical. What am I missing?

The long term objective is to calculate average marginal effects from
a glmer() object by using predict() with betas sampled from a
multivariate distribution, like

  library(MASS) ## 
  n.samples <- 100
  betas <- matrix(mvrnorm(n = n.samples, mu = my.fit at beta, Sigma = vcov(my.fit)), ncol = n.samples, byrow=TRUE)
  new.df <- my.fit at frame
  new.df$Some.var <- my.fit at frame$Some.var - 0.5
  mean(predict(my.fit, newdata = my.fit at frame, type = "response", newparams = list(theta = my.fit at theta, beta = betas[, 1])))
  new.df$Some.var <- my.fit at frame$Some.var + 0.5
  mean(predict(my.fit, newdata = my.fit at frame, type = "response", newparams = list(theta = my.fit at theta, beta = betas[, 1])))
  ... and again with betas[, 2] and so on.


From bbolker at gmail.com  Wed Apr  1 04:24:44 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 1 Apr 2015 02:24:44 +0000 (UTC)
Subject: [R-sig-ME] predict() with varying betas (newparams)
References: <20150401014521.GA12461@hans>
Message-ID: <loom.20150401T042111-618@post.gmane.org>

Hans Ekbrand <hans.ekbrand at ...> writes:

> 
> Dear list,
> 
> I would like to predict() in lme4 using new betas. In order to try out
> the option newparams I tried the following:
> 

> I don't understand what theta is, but I did find a slot in the fitted
> object, my.fit, so I just passed that vector and hoped for the best 
> 
> I would have expected the results to be identical. What am I missing?
> 
> The long term objective is to calculate average marginal effects from
> a glmer() object by using predict() with betas sampled from a
> multivariate distribution, like
> 

 [snip]

Good question.  I'll look into it, I don't understand what's going
on here since for the most part we've been using newparams=
and it has looked sensible -- and your application looks sensible.

A reproducible example:

library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
             data = cbpp, family = binomial)
mean(predict(gm1,newdata=model.frame(gm1),type="response"))
mean(predict(gm1,newdata=model.frame(gm1),
             newparams=getME(gm1,c("theta","beta")),type="response"))

mean(p0 <- predict(gm1,newdata=model.frame(gm1)))
mean(p1 <- predict(gm1,newdata=model.frame(gm1),
                   newparams=list(beta=fixef(gm1))))
             


>


From hans.ekbrand at gmail.com  Wed Apr  1 09:32:54 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Wed, 1 Apr 2015 09:32:54 +0200
Subject: [R-sig-ME] predict() with varying betas (newparams)
In-Reply-To: <20150401072846.GB12461@hans>
References: <20150401014521.GA12461@hans>
	<loom.20150401T042111-618@post.gmane.org>
	<20150401072846.GB12461@hans>
Message-ID: <20150401073254.GC12461@hans>

> On Wed, Apr 01, 2015 at 02:24:44AM +0000, Ben Bolker wrote:
> > Hans Ekbrand <hans.ekbrand at ...> writes:
> > > I would like to predict() in lme4 using new betas. In order to try out
> > > the option newparams I tried the following:
> > 
> > > I don't understand what theta is, but I did find a slot in the fitted
> > > object, my.fit, so I just passed that vector and hoped for the best 
> > > 
> > > I would have expected the results to be identical. What am I missing?

Perhaps it is well-known to you, but I noticed that using re.form = NA
gives exactly the same results as when using newparams

mean(predict(my.fit, newdata = my.fit at frame, type = "response",
		     newparams = list(theta = my.fit at theta, beta = my.fit at beta)))

theta parameter vector not named: assuming same order as internal vector
beta parameter vector not named: assuming same order as internal vector
[1] 0.05619105
mean(predict(my.fit, newdata = my.fit at frame, type = "response", re.form = NA))
[1] 0.05619105

Or, when using your reproducible example (thanks for that, BTW)

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
       			     data = cbpp, family = binomial)

identical(mean(p1 <- predict(gm1, re.form=NA)), mean(p1 <-
predict(gm1,newdata=model.frame(gm1), newparams=list(beta=fixef(gm1),
theta = gm1 at theta))))
theta parameter vector not named: assuming same order as internal vector
[1] TRUE


From chirleu at gmail.com  Wed Apr  1 14:30:31 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Wed, 1 Apr 2015 14:30:31 +0200
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
Message-ID: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>

Dear all,
I'm trying to boostrap repeatability estimated from a lme output.
The model includes one fixed factor (month), one random factor (ID) and one
correlation term to account for temporal autocorrelation of the replicates.
I prefer parametric bootstraping since it is the recommended option
according to Nakagawa and Schielzeth, 2010 (Biological reviews)

These have been my attepmts so far:

*Option 1: parametric bootstraping of the full model (what I really need)*

bootcoef<-function(data, index){
  dat<-data[index,]

mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))

return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
# this is the repeatability estimate
}
output=boot(depm3,bootcoef,100,sim=parametric)

*Error*: output$t yields 100 identical values.

*Option 2: non-parametric bootstraping of the full model*

bootcoef<-function(data, index){
  dat<-data[index,]

mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))

return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
# this is the repeatability estimate
}
output=boot(depm3,bootcoef,100)

*Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate must have
unique values within groups for "corAR1" objects

*Option 3: parametric bootstraping of the model without the autocorrelation
term*

bootcoef<-function(data, index){
  dat<-data[index,]
  mod<-lme(dvm~factor(month),random=~1|ID,data=dat)

return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
# this is the repeatability estimate
}
output=boot(depm3,bootcoef,100,sim=parametric)

*Erro*r: output$t yields 100 identical values which in addition I don't
like because the autocorrelation term is not int he model

*Option 4: non-parametric bootstraping of the model without the
autocorrelation term*

bootcoef<-function(data, index){
  dat<-data[index,]
  mod<-lme(dvm~factor(month),random=~1|ID,data=dat)

return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
# this is the repeatability estimate
}
output=boot(depm3,bootcoef,100)

*Result*: I got 100 different values (this is ok), but I really need the
autocorrelation term to be in.

Is this something that you can comment about without reproducible data? Any
suggestion would be greatly appreciated.

David

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Wed Apr  1 14:34:19 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Wed, 1 Apr 2015 14:34:19 +0200
Subject: [R-sig-ME] Is it possible to account for temporal autocorrelation
	in MCMCglmm?
Message-ID: <CALC46t8hp8JQ-aHP+JikkBUQC6gwfM0_B5YOFb4oBZYE0gRwbg@mail.gmail.com>

Dear all,
For a number of individuals, I have measured several behavioral traits in the
wild. Those traits (e.g. home range) can be estimated on different temporal
scales, for example daily, weekly or monthly. I want to estimate repeatability
of those traits, assuming that the daily/weekly/monthly
measurements (averages) represent replicates. I have 3 months (90 days) of
data for  each trait.

I have run a MCMCglmm model and extracted the residuals from it using:

res=data$trait-predict(model, marginal=NULL)

And then run:
acf(res)

And I found significant autocorrelation in lags 1 and 2.

Is there any way to account for this (temporal) autocorrelation in MCMCglmm?

Sorry for this pretty basic questions but I haven't found an answer so far.

Thanks!

David

	[[alternative HTML version deleted]]


From paolo.f.genova at gmail.com  Wed Apr  1 16:23:50 2015
From: paolo.f.genova at gmail.com (Paolo Fraccaro)
Date: Wed, 1 Apr 2015 14:23:50 +0000 (UTC)
Subject: [R-sig-ME] glmer does not converge,
	how inaccurate is using nAGQ = 0?
Message-ID: <loom.20150401T161133-576@post.gmane.org>

Hi 

I have a dataset of ~200k piece of hardware tested yearly for 10 years or 
until failure (~15k). Therefore, the overall dataset size is ~2,000k. I'm 
trying to fit a mixed effects logistic model with glmer, but the model 
does not converge with the default settings. I tried to increase the 
number of max iterations allowed (from 20 to 100) but still it does not 
converge. I then set the nAGQ = 0 and obtained the less accurate estimate 
of the model.

My questions would be:
Do you have any idea of what parameters I could modify to try to make the 
model converge?
How inaccurate is using nAGQ = 0?

Many thanks.

Paolo


From highstat at highstat.com  Wed Apr  1 23:46:53 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 01 Apr 2015 22:46:53 +0100
Subject: [R-sig-ME] 2 statistics courses in Perth
Message-ID: <551C674D.6020600@highstat.com>

Apologies for cross-posting


We would like to announce the following 2 statistics courses in Perth, 
Australia.

Course1:  Data exploration, regression, GLM & GAM with introduction to R
Location: UWA, Perth, Australia
Date:       20-24 July 2015
Price:       500 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_07Perth_regression_GLM_GAM.pdf


Course2:  Introduction to Linear mixed effects models,  GLMM and MCMC with R
Location: UWA, Perth, Australia
Date:       27-31 July 2015
Price:       500 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_07Perth_GLMM.pdf

Kind regards,

Alain Zuur




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From ken.beath at mq.edu.au  Thu Apr  2 00:03:00 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 2 Apr 2015 09:03:00 +1100
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
In-Reply-To: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
Message-ID: <CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>

For parametric bootstrapping what is required is a model for the data, and
using that you generate the bootstrap samples, there is no resampling
involved.

For non-parametric bootstrapping with multilevel data, resampling
individual observations is not sufficient, what is required is to resample
whole clusters/subjects. This is possible in R by converting teh data to a
wide format, then in thefitting function taking the samples and expanding
them back to long and fitting the model. You will also need to create
unique id for each cluster before converting to long.

I recommend reading something like Manly's book on resampling and
bootstrapping, although I don't think it talks about multilevel models.


On 1 April 2015 at 23:30, David Villegas R?os <chirleu at gmail.com> wrote:

> Dear all,
> I'm trying to boostrap repeatability estimated from a lme output.
> The model includes one fixed factor (month), one random factor (ID) and one
> correlation term to account for temporal autocorrelation of the replicates.
> I prefer parametric bootstraping since it is the recommended option
> according to Nakagawa and Schielzeth, 2010 (Biological reviews)
>
> These have been my attepmts so far:
>
> *Option 1: parametric bootstraping of the full model (what I really need)*
>
> bootcoef<-function(data, index){
>   dat<-data[index,]
>
>
> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>
>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> # this is the repeatability estimate
> }
> output=boot(depm3,bootcoef,100,sim=parametric)
>
> *Error*: output$t yields 100 identical values.
>
> *Option 2: non-parametric bootstraping of the full model*
>
> bootcoef<-function(data, index){
>   dat<-data[index,]
>
>
> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>
>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> # this is the repeatability estimate
> }
> output=boot(depm3,bootcoef,100)
>
> *Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate must have
> unique values within groups for "corAR1" objects
>
> *Option 3: parametric bootstraping of the model without the autocorrelation
> term*
>
> bootcoef<-function(data, index){
>   dat<-data[index,]
>   mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>
>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> # this is the repeatability estimate
> }
> output=boot(depm3,bootcoef,100,sim=parametric)
>
> *Erro*r: output$t yields 100 identical values which in addition I don't
> like because the autocorrelation term is not int he model
>
> *Option 4: non-parametric bootstraping of the model without the
> autocorrelation term*
>
> bootcoef<-function(data, index){
>   dat<-data[index,]
>   mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>
>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> # this is the repeatability estimate
> }
> output=boot(depm3,bootcoef,100)
>
> *Result*: I got 100 different values (this is ok), but I really need the
> autocorrelation term to be in.
>
> Is this something that you can comment about without reproducible data? Any
> suggestion would be greatly appreciated.
>
> David
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From ken.beath at mq.edu.au  Thu Apr  2 00:06:06 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 2 Apr 2015 09:06:06 +1100
Subject: [R-sig-ME] glmer does not converge,
 how inaccurate is using nAGQ = 0?
In-Reply-To: <loom.20150401T161133-576@post.gmane.org>
References: <loom.20150401T161133-576@post.gmane.org>
Message-ID: <CAF5_5czPaTHHFXwDR2qd7JoWoJ-6ns5SvxUnCPYaTC8Zbw84BQ@mail.gmail.com>

You could use a value of nAGQ that is higher, start with 5 and work up.

How good the approximation is, depends. If you are having convergence
problems it probably isn't.

On 2 April 2015 at 01:23, Paolo Fraccaro <paolo.f.genova at gmail.com> wrote:

> Hi
>
> I have a dataset of ~200k piece of hardware tested yearly for 10 years or
> until failure (~15k). Therefore, the overall dataset size is ~2,000k. I'm
> trying to fit a mixed effects logistic model with glmer, but the model
> does not converge with the default settings. I tried to increase the
> number of max iterations allowed (from 20 to 100) but still it does not
> converge. I then set the nAGQ = 0 and obtained the less accurate estimate
> of the model.
>
> My questions would be:
> Do you have any idea of what parameters I could modify to try to make the
> model converge?
> How inaccurate is using nAGQ = 0?
>
> Many thanks.
>
> Paolo
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Thu Apr  2 02:18:33 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 01 Apr 2015 20:18:33 -0400
Subject: [R-sig-ME] glmer does not converge,
 how inaccurate is using nAGQ = 0?
In-Reply-To: <CAF5_5czPaTHHFXwDR2qd7JoWoJ-6ns5SvxUnCPYaTC8Zbw84BQ@mail.gmail.com>
References: <loom.20150401T161133-576@post.gmane.org>
	<CAF5_5czPaTHHFXwDR2qd7JoWoJ-6ns5SvxUnCPYaTC8Zbw84BQ@mail.gmail.com>
Message-ID: <551C8AD9.5030800@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-04-01 06:06 PM, Ken Beath wrote:
> You could use a value of nAGQ that is higher, start with 5 and work
> up.
> 
> How good the approximation is, depends. If you are having
> convergence problems it probably isn't.

   What's the magnitude of the max scaled gradient (i.e., the number
in the warning)?  We are *still* struggling with the proper way to
scale the desired gradient as a function of sample size ...

  cheers
    Ben Bolker

> 
> On 2 April 2015 at 01:23, Paolo Fraccaro <paolo.f.genova at gmail.com>
> wrote:
> 
>> Hi
>> 
>> I have a dataset of ~200k piece of hardware tested yearly for 10
>> years or until failure (~15k). Therefore, the overall dataset
>> size is ~2,000k. I'm trying to fit a mixed effects logistic model
>> with glmer, but the model does not converge with the default
>> settings. I tried to increase the number of max iterations
>> allowed (from 20 to 100) but still it does not converge. I then
>> set the nAGQ = 0 and obtained the less accurate estimate of the
>> model.
>> 
>> My questions would be: Do you have any idea of what parameters I
>> could modify to try to make the model converge? How inaccurate is
>> using nAGQ = 0?
>> 
>> Many thanks.
>> 
>> Paolo
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVHIrZAAoJEOCV5YRblxUH+bgH/iPX84jD7zg9tB3L6DNt0y1T
+xOCqB7WZ1ZuLQ+EEZ2NNMF0NmDKmpP02zj7lESNmGjfE+L639qk2RhiA9y8OeH+
vdT5A5vXfXZzdLlTwDTor0oswU3ECkMYTMww3L4OfM2ykacBAMIL/QfJ3A7MEuul
vnCZCcvLULX2MSrMfK7v8Jkti+Mi/LQ84VNot3XxkEGF37jbfjY5JGdGciDRH5I+
GFHAF8mnkBki81Pnf52rqAy45iuTVzm/p98k6SQ5rsUb2tJYMfDgPeOTLiOsrNu8
iLe8bzlNj3huiW3m5l20FrmU2eJPQmWxjF4G6fHufdTtsCU29CMjgqCPuZpjbHk=
=UNaY
-----END PGP SIGNATURE-----


From ken.beath at mq.edu.au  Thu Apr  2 11:27:52 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 2 Apr 2015 20:27:52 +1100
Subject: [R-sig-ME] Problems with convergence
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F0978FF5A@UM-MAIL4112.unimaas.nl>
References: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>
	<loom.20150319T042938-705@post.gmane.org>
	<CAF5_5cy0BE9Mi-_VROBQ+fUXYM+GX8=vbmga+KygRVWfZHsQ5w@mail.gmail.com>
	<loom.20150330T220526-332@post.gmane.org>
	<077E31A57DA26E46AB0D493C9966AC730F0978FF5A@UM-MAIL4112.unimaas.nl>
Message-ID: <CAF5_5czKbU9bvOCLBaDzhd1snscg0FfT49Z77KRJJ35LKi8ORw@mail.gmail.com>

It would be nice to have this work properly, as I need it for certain
things and it seems that other people are having similar problems.

Getting it to work by increasing the quadrature points is a bit of an
aberration, it is not what typically happens, and I've put an example at
the end. At least in this one the profiling works which means the maximum
must be fairly close to that obtained from the optimisation.

My feeling on this, is that possibly the problem is not with the optimiser,
seeing that it fails with so many optimisers, but rather with the
calculation of the marginal likelihood. These optimisers don't tend to stop
with 0.001 gradients. When I have time I will find in the code how the node
locations are calculated and see what is happening.

Anyway, here is one that fails irrespective of  nAGQ value.

thedata <- structure(list(nEvents = c(10L, 53L, 17L, 18L, 22L, 6L, 16L,
14L, 13L, 18L, 15L, 19L, 52L, 19L, 8L, 16L, 50L, 8L, 9L, 4L,
26L, 45L, 18L, 20L, 5L, 16L, 18L, 7L, 3L, 19L, 30L, 26L, 66L,
23L, 29L, 18L, 72L, 25L, 9L, 2L), total = c(200, 200, 200, 200,
200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
200, 200, 200, 200, 200, 200, 200, 200, 200, 200), trt = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), id = structure(c(1L,
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
16L, 17L, 18L, 19L, 20L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L), .Label = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
"14", "15", "16", "17", "18", "19", "20"), class = "factor"),
trt12 = c(-0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5,
-0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5,
-0.5, -0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,
0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)), .Names =
c("nEvents",
"total", "trt", "id", "trt12"), row.names = c(NA, 40L), class =
"data.frame")

glmer1a <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt + factor(id) +
(0+trt12|id), data=thedata, family=binomial, nAGQ=7)

glmer1b <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt + factor(id) +
(0+trt12|id), data=thedata, family=binomial, nAGQ=21)





On 1 April 2015 at 02:25, Viechtbauer Wolfgang (STAT) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> This discussion piqued my interest. The model that Ken was fitting is in
> essence one of the models that is fitted by the rma.glmm() function in the
> metafor package. This is sometimes called the unconditional model with
> fixed study effects. To illustrate:
>
> ### original data
>
> thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> "2","3","4","5","6","7","8","9","10","11","12","13",
> "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> "total","trt","id"),row.names=c(NA,40L),class="data.frame")
>
> ### restructure data as needed for input into rma.glmm()
>
> dat <- cbind(thedata[1:20,], thedata[21:40,])
> dat$id <- dat$id <- dat$trt <- dat$trt <- NULL
> colnames(dat) <- c("ci", "n2i", "ai", "n1i")
>
> library(metafor)
> library(lme4)
>
> ### model fitted by Ken
> res1 <- glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) +
> (0+trt|id), data=thedata, family=binomial)
>
> ### fit unconditional model with fixed study effects via rma.glmm()
> res2 <- rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat,
> nAGQ=1)
>
> ### to get exact equivalence, use +-1/2 coding for the random effects
> thedata$trt12 <- thedata$trt - 1/2
> res3 <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt + factor(id) +
> (0+trt12|id), data=thedata, family=binomial)
>
> summary(res1)
> summary(res2)
> summary(res3)
>
> ### end example
>
> A few notes:
>
> 1) rma.glmm() uses nAGQ=7 by default, so I switched that to 1 for the
> comparison.
>
> 2) Some discussion of the 0/1 versus +-1/2 coding can be found in Turner
> et al. (2000) and Higgins et al. (2001). I tend to prefer the +-1/2 coding,
> so that is also what is currently implemented in rma.glmm(), but I may add
> the 0/1 coding as an option.
>
> 3) A nice discussion of the model is provided by Senn (2000). He also
> discusses a variety of other modeling options, including a model using
> random study effects.
>
> 4) In fact, the unconditional model with random study effects can be
> fitted with:
>
> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, model="
> UM.RS")
>
> (which makes use of glmer() underneath). As discussed by Senn, this model
> may violate what he calls the 'concurrent control principle', but his
> wording is cautious ('may violate', 'may be regarded as undesirable'),
> which reflects the lack of a thorough discussion in the literature
> comparing the various models.
>
> 5) Yet another option is the (mixed-effects) conditional logistic model.
> See, for example, Stijnen et al. (2010). This model is obtained when
> conditioning on the total number of events within each study and leads to
> non-central hypergeometric distributions for the data within each study.
> This model can be fitted with:
>
> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat,
> model="CM.EL")
>
> Sorry, it's slow (I haven't found a clever way of speeding up the
> integration over the non-central hypergeometric distributions). Much
> faster, thanks to lme4, is:
>
> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, model="
> CM.AL")
>
> which uses an approximation to the exact conditional likelihood.
>
> 6) And of course there are Bayesian implementations of such models.
>
> 7) With respect to the model fitted by Ken, it's maybe interesting to note
> that NOT using the Laplace approximation, but something like 7 quadrature
> points, does not cause any convergence warnings:
>
> glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) + (0+trt|id),
> data=thedata, family=binomial, nAGQ=7)
>
> Alright, I'll shut up now.
>
> References mentioned above:
>
> Higgins, J. P. T., Whitehead, A., Turner, R. M., Omar, R. Z., & Thompson,
> S. G. (2001). Meta-analysis of continuous outcome data from individual
> patients. Statistics in Medicine, 20(15), 2219-2241.
>
> Senn, S. (2000). The many modes of meta. Drug Information Journal, 34,
> 535-549.
>
> Stijnen, T., Hamza, T. H., & Ozdemir, P. (2010). Random effects
> meta-analysis of event outcome in the framework of the generalized linear
> mixed model with applications in sparse data. Statistics in Medicine,
> 29(29), 3046-3067.
>
> Turner, R. M., Omar, R. Z., Yang, M., Goldstein, H., & Thompson, S. G.
> (2000). A multilevel model framework for meta-analysis of clinical trials
> with binary outcomes. Statistics in Medicine, 19(24), 3417-3432.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Neuropsychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
>
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> > project.org] On Behalf Of Ben Bolker
> > Sent: Monday, March 30, 2015 22:21
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Problems with convergence
> >
> > Ken Beath <ken.beath at ...> writes:
> >
> > > Yes, I was demonstrating that it fails convergence and then as a
> > > consequence fails to profile. I have my doubts about
> > > convergence for the bobyqa
> > > algorithm, I have other applications where it doesn't converge
> > properly.
> > > For some of my own work I've used nlminb followed by Nelder-Mead if
> > there
> > > is a convergence failure. Not optimal but it seems to work.
> >
> >    I'm still not sure whether you expect it to converge (I think you
> > do), or whether you are just pointing out that the convergence warning
> > in this case is probably justified (in the face of so many convergence
> > warnings that turn out to be false positives, this is a useful piece
> > of information).
> >
> > > While it is fairly heavily parameterised it is a real model,
> > >  a frequentist
> > > implementation of Smith, T. C., Spiegelhalter, D. J., & Thomas, a.
> > (1995).
> > > Bayesian approaches to random-effects meta-analysis: a comparative
> > study.
> > > Statistics in Medicine, 14(24), 2685?99. The reason for having studies
> > as
> > > fixed effects is probably philosophical, the overall success rates are
> > not
> > > likely to be given by normally distributed random effects, and are in
> > many
> > > cases specifically chosen.
> >
> >   I can appreciate that, but I still think it's unrealistic to expect
> > to be able to fit 22 parameters to 40 observations except under very
> > special circumstances.  One point about switching from the Bayesian
> > to the frequentist world is that the Bayesians (by definition) put
> > priors on their parameters, which provides a degree of regularization
> > that is not by default available to frequentist methods.  What priors
> > did Smith et al. use?  It might be worth trying this in blme with
> > priors on the fixed effects ...
> >
> > > I did find that one of the data sets that I have also failed, but
> > fitted
> > > with a commercial program that is based on the EM algorithm. For this
> > type
> > > of problem it is actually faster, as any type of quasi-Newton needs to
> > > calculate lots of derivatives.
> >
> >   I could whine about the difficulty of finding globally robust,
> > reliable, and fast optimization algorithms, but I won't.  I can certainly
> > appreciate that there are more reliable methods for particular
> > sub-classes of problems.
> >
> > > Anyway, I'm going to keep looking at the methods, and eventually the
> > code
> > > for glmer and may eventually have some suggestions.
> >
> >   Would be happy to hear them.
> >
> >   It's worth pointing out that lme4 is using a preliminary "nAGQ=0"
> > step, which ignores the terms contributed by the integrals over the
> > distributions of the conditional modes and as a result is able to
> > fit both the fixed-effect parameters and the conditional modes in
> > a single linear-algebra step, reducing the dimensionality of the
> > nonlinear optimization to the length of the variance-covariance
> > parameter vector ...
> >
> > > On 19 March 2015 at 14:45, Ben Bolker <bbolker <at> gmail.com> wrote:
> > >
> > > > Ken Beath <ken.beath <at> ...> writes:
> > > >
> > > > > The following code shows that there are convergence problem
> > messages
> > > > > where there is a problem with convergence. The profiling shows that
> > > > > the maximum found is not the correct one. This is simulated data
> > for
> > > > > a binary meta-analysis with fixed effect for study and random
> > effect
> > > > > for treatment.
> > > >
> >
> >  [paragraph snipped to try to make Gmane happy]
> >
> > > >   However, may I comment that this is a slightly ridiculous scenario?
> > > > The data set here has 40 observations, and the model tries to fit 22
> > > > parameters.  The model that treats id as a random effect works much
> > > > better.  I can believe there are scenarios where you really do
> > > > want study as a fixed effect, but did you expect it to be practical
> > > > here?
> > > >
> > > > But maybe you're just trying to show that this is a "true positive"
> > > > case for the convergence warnings.
> > > >
> > > > Some random code I wrote while diagnosing what was going on:
> > > >
> > > > library(ggplot2); theme_set(theme_bw())
> > > >
> > > > ## proportion + weights is a little easier to handle
> > > > thedata <- transform(thedata,prop=nEvents/total)
> > > >
> > > > ggplot(thedata,aes(trt,prop))+geom_point(aes(size=total))+
> > > >     geom_line(aes(group=id),colour="gray")
> > > > glmer1 <- glmer(prop~trt+factor(id)+(0+trt|id),
> > > >                 weights=total,data=thedata,family=binomial)
> > > >
> > > > ## id as RE
> > > > glmer2 <- glmer(prop~trt+(1|id)+(0+trt|id),
> > > >                 weights=total,data=thedata,family=binomial)
> > > >
> > > > dd <- update(glmer1,devFunOnly=TRUE)
> > > > pars <- unlist(getME(glmer1,c("theta","fixef")))
> > > > library("bbmle")
> > > > ss <- slice2D(pars,dd)
> > > > library("lattice")
> > > > plot(ss)
> > > > ## too complex, but too much work to cut down significantly
> > > >
> > > > > library(lme4)
> > > > >
> > > > > thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> > > > > 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> > > > > 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> > > > > 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> > > > > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > > > > 200,200,200,200,200,200,200,200,200,200,200,200,200,
> > > > > 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> > > > > 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> > > > > 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> > > > > 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> > > > > 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> > > > > 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> > > > > "2","3","4","5","6","7","8","9","10","11","12","13",
> > > > >
> > "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> > > > > "total","trt","id"),row.names=c(NA,40L),class="data.frame")
> > > > >
> > > > > glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+
> > > > ##   (0+trt|id),data=thedata,family=binomial)
> > > > >
> > > > > # while glmer has problems with component 9 it is 8 with a problem
> > > > profile
> > > > > # I've use devtol so the discrepancy is printed
> > > > > prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From ken.beath at mq.edu.au  Thu Apr  2 12:10:03 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 2 Apr 2015 21:10:03 +1100
Subject: [R-sig-ME] glmer does not converge,
 how inaccurate is using nAGQ = 0?
In-Reply-To: <CAEbNFTG-JhQzXfp4sk+NtMMBxpeWa2vKSRAxVRyUzOh8uN=hAQ@mail.gmail.com>
References: <loom.20150401T161133-576@post.gmane.org>
	<CAF5_5czPaTHHFXwDR2qd7JoWoJ-6ns5SvxUnCPYaTC8Zbw84BQ@mail.gmail.com>
	<CAEbNFTG-JhQzXfp4sk+NtMMBxpeWa2vKSRAxVRyUzOh8uN=hAQ@mail.gmail.com>
Message-ID: <CAF5_5cw6nLK5udCc7biXXGcGtg9QpiV351VsOu6p+XSySAOPVg@mail.gmail.com>

I think you have other problems, although sometimes this can be a break
down in the approximations, and increasing nAGQ can work. Either your model
is not identifiable, which means that it is overparameterised or some of
your coefficients have become excessively negative, or you may have a very
high random effect variance. The last will be helped by increasing the
quadrature points, the second may be. Without seeing the output it is hard
to tell.

On 2 April 2015 at 20:36, Paolo Fraccaro <paolo.f.genova at gmail.com> wrote:

> Hi,
>
> thanks for your suggestions. I left it going overnight still with nAGQ=1
> and this time I got this warnings:
>
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.00191069 (tol = 0.001,
> component 4)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
>
> Is the solution of increasing nAGQ still the best thing to do?
>
> Many thanks,
>
> Paolo
>
> On 1 April 2015 at 23:06, Ken Beath <ken.beath at mq.edu.au> wrote:
>
>> You could use a value of nAGQ that is higher, start with 5 and work up.
>>
>> How good the approximation is, depends. If you are having convergence
>> problems it probably isn't.
>>
>> On 2 April 2015 at 01:23, Paolo Fraccaro <paolo.f.genova at gmail.com>
>> wrote:
>>
>>> Hi
>>>
>>> I have a dataset of ~200k piece of hardware tested yearly for 10 years or
>>> until failure (~15k). Therefore, the overall dataset size is ~2,000k. I'm
>>> trying to fit a mixed effects logistic model with glmer, but the model
>>> does not converge with the default settings. I tried to increase the
>>> number of max iterations allowed (from 20 to 100) but still it does not
>>> converge. I then set the nAGQ = 0 and obtained the less accurate estimate
>>> of the model.
>>>
>>> My questions would be:
>>> Do you have any idea of what parameters I could modify to try to make the
>>> model converge?
>>> How inaccurate is using nAGQ = 0?
>>>
>>> Many thanks.
>>>
>>> Paolo
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may contain
>> confidential information.  If you are not the intended recipient, please
>> delete it and notify the sender.  Views expressed in this message are those
>> of the individual sender, and are not necessarily the views of the Faculty
>> of Science, Department of Statistics or Macquarie University.
>>
>>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Thu Apr  2 16:19:19 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 02 Apr 2015 10:19:19 -0400
Subject: [R-sig-ME] Problems with convergence
In-Reply-To: <CAF5_5czKbU9bvOCLBaDzhd1snscg0FfT49Z77KRJJ35LKi8ORw@mail.gmail.com>
References: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>	<loom.20150319T042938-705@post.gmane.org>	<CAF5_5cy0BE9Mi-_VROBQ+fUXYM+GX8=vbmga+KygRVWfZHsQ5w@mail.gmail.com>	<loom.20150330T220526-332@post.gmane.org>	<077E31A57DA26E46AB0D493C9966AC730F0978FF5A@UM-MAIL4112.unimaas.nl>
	<CAF5_5czKbU9bvOCLBaDzhd1snscg0FfT49Z77KRJJ35LKi8ORw@mail.gmail.com>
Message-ID: <551D4FE7.5020605@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Hmm.  Have you tried with nlminb?  This works for me ...

glmer1a <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt +
     factor(id) +
      (0+trt12|id), data=thedata, family=binomial, nAGQ=7)

glmer1X <- update(glmer1a,
                  control=glmerControl(optimizer="nlminbwrap"))


  I don't know whether it works better overall (it does use a
different convergence criterion ...) or whether this is just the luck
of the draw on this particular case.

   cheers
    Ben Bolker

PS I don't remember when nlminbwrap was added to the code base, but
it's pretty simple:

function (par, fn, lower, upper, control = list(), ...)
{
    res <- nlminb(start = par, fn, gradient = NULL, hessian = NULL,
        scale = 1, lower = lower, upper = upper, control = control,
        ...)
    list(par = res$par, fval = res$objective, conv = res$convergence,
        message = res$message)
}


On 15-04-02 05:27 AM, Ken Beath wrote:
> It would be nice to have this work properly, as I need it for
> certain things and it seems that other people are having similar
> problems.
> 
> Getting it to work by increasing the quadrature points is a bit of
> an aberration, it is not what typically happens, and I've put an
> example at the end. At least in this one the profiling works which
> means the maximum must be fairly close to that obtained from the
> optimisation.
> 
> My feeling on this, is that possibly the problem is not with the
> optimiser, seeing that it fails with so many optimisers, but rather
> with the calculation of the marginal likelihood. These optimisers
> don't tend to stop with 0.001 gradients. When I have time I will
> find in the code how the node locations are calculated and see what
> is happening.
> 
> Anyway, here is one that fails irrespective of  nAGQ value.
> 
> thedata <- structure(list(nEvents = c(10L, 53L, 17L, 18L, 22L, 6L,
> 16L, 14L, 13L, 18L, 15L, 19L, 52L, 19L, 8L, 16L, 50L, 8L, 9L, 4L, 
> 26L, 45L, 18L, 20L, 5L, 16L, 18L, 7L, 3L, 19L, 30L, 26L, 66L, 23L,
> 29L, 18L, 72L, 25L, 9L, 2L), total = c(200, 200, 200, 200, 200,
> 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
> 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
> 200, 200, 200, 200, 200, 200, 200, 200, 200), trt = c(0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), id = structure(c(1L, 2L,
> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L), .Label = c("1", "2", "3",
> "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
> "16", "17", "18", "19", "20"), class = "factor"), trt12 = c(-0.5,
> -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5,
> -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.5, 0.5, 0.5, 0.5,
> 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,
> 0.5, 0.5, 0.5)), .Names = c("nEvents", "total", "trt", "id",
> "trt12"), row.names = c(NA, 40L), class = "data.frame")
> 
> glmer1a <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt +
> factor(id) + (0+trt12|id), data=thedata, family=binomial, nAGQ=7)
> 
> glmer1b <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt +
> factor(id) + (0+trt12|id), data=thedata, family=binomial, nAGQ=21)
> 
> 
> 
> 
> 
> On 1 April 2015 at 02:25, Viechtbauer Wolfgang (STAT) < 
> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> 
>> This discussion piqued my interest. The model that Ken was
>> fitting is in essence one of the models that is fitted by the
>> rma.glmm() function in the metafor package. This is sometimes
>> called the unconditional model with fixed study effects. To
>> illustrate:
>> 
>> ### original data
>> 
>> thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L, 
>> 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L, 
>> 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L, 
>> 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200, 
>> 200,200,200,200,200,200,200,200,200,200,200,200,200, 
>> 200,200,200,200,200,200,200,200,200,200,200,200,200, 
>> 200,200,200,200,200,200,200,200,200,200),trt=c(0, 
>> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1, 
>> 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L, 
>> 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L, 
>> 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L, 
>> 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1", 
>> "2","3","4","5","6","7","8","9","10","11","12","13", 
>> "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
>>
>> 
"total","trt","id"),row.names=c(NA,40L),class="data.frame")
>> 
>> ### restructure data as needed for input into rma.glmm()
>> 
>> dat <- cbind(thedata[1:20,], thedata[21:40,]) dat$id <- dat$id <-
>> dat$trt <- dat$trt <- NULL colnames(dat) <- c("ci", "n2i", "ai",
>> "n1i")
>> 
>> library(metafor) library(lme4)
>> 
>> ### model fitted by Ken res1 <-
>> glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) + 
>> (0+trt|id), data=thedata, family=binomial)
>> 
>> ### fit unconditional model with fixed study effects via
>> rma.glmm() res2 <- rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci,
>> n2i=n2i, data=dat, nAGQ=1)
>> 
>> ### to get exact equivalence, use +-1/2 coding for the random
>> effects thedata$trt12 <- thedata$trt - 1/2 res3 <-
>> glmer(cbind(nEvents,total-nEvents) ~ -1 + trt + factor(id) + 
>> (0+trt12|id), data=thedata, family=binomial)
>> 
>> summary(res1) summary(res2) summary(res3)
>> 
>> ### end example
>> 
>> A few notes:
>> 
>> 1) rma.glmm() uses nAGQ=7 by default, so I switched that to 1 for
>> the comparison.
>> 
>> 2) Some discussion of the 0/1 versus +-1/2 coding can be found in
>> Turner et al. (2000) and Higgins et al. (2001). I tend to prefer
>> the +-1/2 coding, so that is also what is currently implemented
>> in rma.glmm(), but I may add the 0/1 coding as an option.
>> 
>> 3) A nice discussion of the model is provided by Senn (2000). He
>> also discusses a variety of other modeling options, including a
>> model using random study effects.
>> 
>> 4) In fact, the unconditional model with random study effects can
>> be fitted with:
>> 
>> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat,
>> model=" UM.RS")
>> 
>> (which makes use of glmer() underneath). As discussed by Senn,
>> this model may violate what he calls the 'concurrent control
>> principle', but his wording is cautious ('may violate', 'may be
>> regarded as undesirable'), which reflects the lack of a thorough
>> discussion in the literature comparing the various models.
>> 
>> 5) Yet another option is the (mixed-effects) conditional logistic
>> model. See, for example, Stijnen et al. (2010). This model is
>> obtained when conditioning on the total number of events within
>> each study and leads to non-central hypergeometric distributions
>> for the data within each study. This model can be fitted with:
>> 
>> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, 
>> model="CM.EL")
>> 
>> Sorry, it's slow (I haven't found a clever way of speeding up
>> the integration over the non-central hypergeometric
>> distributions). Much faster, thanks to lme4, is:
>> 
>> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat,
>> model=" CM.AL")
>> 
>> which uses an approximation to the exact conditional likelihood.
>> 
>> 6) And of course there are Bayesian implementations of such
>> models.
>> 
>> 7) With respect to the model fitted by Ken, it's maybe
>> interesting to note that NOT using the Laplace approximation, but
>> something like 7 quadrature points, does not cause any
>> convergence warnings:
>> 
>> glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) +
>> (0+trt|id), data=thedata, family=binomial, nAGQ=7)
>> 
>> Alright, I'll shut up now.
>> 
>> References mentioned above:
>> 
>> Higgins, J. P. T., Whitehead, A., Turner, R. M., Omar, R. Z., &
>> Thompson, S. G. (2001). Meta-analysis of continuous outcome data
>> from individual patients. Statistics in Medicine, 20(15),
>> 2219-2241.
>> 
>> Senn, S. (2000). The many modes of meta. Drug Information
>> Journal, 34, 535-549.
>> 
>> Stijnen, T., Hamza, T. H., & Ozdemir, P. (2010). Random effects 
>> meta-analysis of event outcome in the framework of the
>> generalized linear mixed model with applications in sparse data.
>> Statistics in Medicine, 29(29), 3046-3067.
>> 
>> Turner, R. M., Omar, R. Z., Yang, M., Goldstein, H., & Thompson,
>> S. G. (2000). A multilevel model framework for meta-analysis of
>> clinical trials with binary outcomes. Statistics in Medicine,
>> 19(24), 3417-3432.
>> 
>> Best, Wolfgang
>> 
>> -- Wolfgang Viechtbauer, Ph.D., Statistician Department of
>> Psychiatry and Neuropsychology School for Mental Health and
>> Neuroscience Faculty of Health, Medicine, and Life Sciences 
>> Maastricht University, P.O. Box 616 (VIJV1) 6200 MD Maastricht,
>> The Netherlands +31 (43) 388-4170 | http://www.wvbauer.com
>> 
>>> -----Original Message----- From: R-sig-mixed-models
>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf Of
>>> Ben Bolker Sent: Monday, March 30, 2015 22:21 To:
>>> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME]
>>> Problems with convergence
>>> 
>>> Ken Beath <ken.beath at ...> writes:
>>> 
>>>> Yes, I was demonstrating that it fails convergence and then
>>>> as a consequence fails to profile. I have my doubts about 
>>>> convergence for the bobyqa algorithm, I have other
>>>> applications where it doesn't converge
>>> properly.
>>>> For some of my own work I've used nlminb followed by
>>>> Nelder-Mead if
>>> there
>>>> is a convergence failure. Not optimal but it seems to work.
>>> 
>>> I'm still not sure whether you expect it to converge (I think
>>> you do), or whether you are just pointing out that the
>>> convergence warning in this case is probably justified (in the
>>> face of so many convergence warnings that turn out to be false
>>> positives, this is a useful piece of information).
>>> 
>>>> While it is fairly heavily parameterised it is a real model, 
>>>> a frequentist implementation of Smith, T. C., Spiegelhalter,
>>>> D. J., & Thomas, a.
>>> (1995).
>>>> Bayesian approaches to random-effects meta-analysis: a
>>>> comparative
>>> study.
>>>> Statistics in Medicine, 14(24), 2685?99. The reason for
>>>> having studies
>>> as
>>>> fixed effects is probably philosophical, the overall success
>>>> rates are
>>> not
>>>> likely to be given by normally distributed random effects,
>>>> and are in
>>> many
>>>> cases specifically chosen.
>>> 
>>> I can appreciate that, but I still think it's unrealistic to
>>> expect to be able to fit 22 parameters to 40 observations
>>> except under very special circumstances.  One point about
>>> switching from the Bayesian to the frequentist world is that
>>> the Bayesians (by definition) put priors on their parameters,
>>> which provides a degree of regularization that is not by
>>> default available to frequentist methods.  What priors did
>>> Smith et al. use?  It might be worth trying this in blme with 
>>> priors on the fixed effects ...
>>> 
>>>> I did find that one of the data sets that I have also failed,
>>>> but
>>> fitted
>>>> with a commercial program that is based on the EM algorithm.
>>>> For this
>>> type
>>>> of problem it is actually faster, as any type of quasi-Newton
>>>> needs to calculate lots of derivatives.
>>> 
>>> I could whine about the difficulty of finding globally robust, 
>>> reliable, and fast optimization algorithms, but I won't.  I can
>>> certainly appreciate that there are more reliable methods for
>>> particular sub-classes of problems.
>>> 
>>>> Anyway, I'm going to keep looking at the methods, and
>>>> eventually the
>>> code
>>>> for glmer and may eventually have some suggestions.
>>> 
>>> Would be happy to hear them.
>>> 
>>> It's worth pointing out that lme4 is using a preliminary
>>> "nAGQ=0" step, which ignores the terms contributed by the
>>> integrals over the distributions of the conditional modes and
>>> as a result is able to fit both the fixed-effect parameters and
>>> the conditional modes in a single linear-algebra step, reducing
>>> the dimensionality of the nonlinear optimization to the length
>>> of the variance-covariance parameter vector ...
>>> 
>>>> On 19 March 2015 at 14:45, Ben Bolker <bbolker <at>
>>>> gmail.com> wrote:
>>>> 
>>>>> Ken Beath <ken.beath <at> ...> writes:
>>>>> 
>>>>>> The following code shows that there are convergence
>>>>>> problem
>>> messages
>>>>>> where there is a problem with convergence. The profiling
>>>>>> shows that the maximum found is not the correct one. This
>>>>>> is simulated data
>>> for
>>>>>> a binary meta-analysis with fixed effect for study and
>>>>>> random
>>> effect
>>>>>> for treatment.
>>>>> 
>>> 
>>> [paragraph snipped to try to make Gmane happy]
>>> 
>>>>> However, may I comment that this is a slightly ridiculous
>>>>> scenario? The data set here has 40 observations, and the
>>>>> model tries to fit 22 parameters.  The model that treats id
>>>>> as a random effect works much better.  I can believe there
>>>>> are scenarios where you really do want study as a fixed
>>>>> effect, but did you expect it to be practical here?
>>>>> 
>>>>> But maybe you're just trying to show that this is a "true
>>>>> positive" case for the convergence warnings.
>>>>> 
>>>>> Some random code I wrote while diagnosing what was going
>>>>> on:
>>>>> 
>>>>> library(ggplot2); theme_set(theme_bw())
>>>>> 
>>>>> ## proportion + weights is a little easier to handle 
>>>>> thedata <- transform(thedata,prop=nEvents/total)
>>>>> 
>>>>> ggplot(thedata,aes(trt,prop))+geom_point(aes(size=total))+ 
>>>>> geom_line(aes(group=id),colour="gray") glmer1 <-
>>>>> glmer(prop~trt+factor(id)+(0+trt|id), 
>>>>> weights=total,data=thedata,family=binomial)
>>>>> 
>>>>> ## id as RE glmer2 <- glmer(prop~trt+(1|id)+(0+trt|id), 
>>>>> weights=total,data=thedata,family=binomial)
>>>>> 
>>>>> dd <- update(glmer1,devFunOnly=TRUE) pars <-
>>>>> unlist(getME(glmer1,c("theta","fixef"))) library("bbmle") 
>>>>> ss <- slice2D(pars,dd) library("lattice") plot(ss) ## too
>>>>> complex, but too much work to cut down significantly
>>>>> 
>>>>>> library(lme4)
>>>>>> 
>>>>>> thedata <-
>>>>>> structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L, 
>>>>>> 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L, 
>>>>>> 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L, 
>>>>>> 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200, 
>>>>>> 200,200,200,200,200,200,200,200,200,200,200,200,200, 
>>>>>> 200,200,200,200,200,200,200,200,200,200,200,200,200, 
>>>>>> 200,200,200,200,200,200,200,200,200,200),trt=c(0, 
>>>>>> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1, 
>>>>>> 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L, 
>>>>>> 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L, 
>>>>>> 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L, 
>>>>>> 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
>>>>>>
>>>>>> 
"2","3","4","5","6","7","8","9","10","11","12","13",
>>>>>> 
>>> "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
>>>>>>
>>> 
"total","trt","id"),row.names=c(NA,40L),class="data.frame")
>>>>>> 
>>>>>> glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+
>>>>>
>>>>>> 
##   (0+trt|id),data=thedata,family=binomial)
>>>>>> 
>>>>>> # while glmer has problems with component 9 it is 8 with
>>>>>> a problem
>>>>> profile
>>>>>> # I've use devtol so the discrepancy is printed 
>>>>>> prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)
>> 
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVHU/nAAoJEOCV5YRblxUHxPEIAKQ6kISS1aANugvV6wvq7/6C
tIkLUZIxxqCn1UzfbB4naqVQ/4B9ipNlpWV8FEVJs5H7IxoQY1iCojONqihmiHO6
SE/m44U4xEsX94q47d/vWCNqbwk9sGyXZj7R4lAOsPZiUqkvaKKV4Py8IF+O2nwM
RjuzSGGw3ZusE7gIX6UB79lpgVvE8RZUOzJwR8pjKcBhbBHSYslAmdd9o8HpXTkm
EWhZ3PpFEnWopXfeG2uN5HWGD8OjP7w8578ZHKLJhOW/9VEZQ9ykI/I8/yOlb7OJ
dfbzRpQe/cKFghMYvF/xR2y0tdp98OwQUE7tKJneOJLqV2Q1u9w/m4oCRXVYNmA=
=8saW
-----END PGP SIGNATURE-----


From paolo.f.genova at gmail.com  Thu Apr  2 11:36:37 2015
From: paolo.f.genova at gmail.com (Paolo Fraccaro)
Date: Thu, 2 Apr 2015 10:36:37 +0100
Subject: [R-sig-ME] glmer does not converge,
 how inaccurate is using nAGQ = 0?
In-Reply-To: <CAF5_5czPaTHHFXwDR2qd7JoWoJ-6ns5SvxUnCPYaTC8Zbw84BQ@mail.gmail.com>
References: <loom.20150401T161133-576@post.gmane.org>
	<CAF5_5czPaTHHFXwDR2qd7JoWoJ-6ns5SvxUnCPYaTC8Zbw84BQ@mail.gmail.com>
Message-ID: <CAEbNFTG-JhQzXfp4sk+NtMMBxpeWa2vKSRAxVRyUzOh8uN=hAQ@mail.gmail.com>

Hi,

thanks for your suggestions. I left it going overnight still with nAGQ=1
and this time I got this warnings:

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00191069 (tol = 0.001,
component 4)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?

Is the solution of increasing nAGQ still the best thing to do?

Many thanks,

Paolo

On 1 April 2015 at 23:06, Ken Beath <ken.beath at mq.edu.au> wrote:

> You could use a value of nAGQ that is higher, start with 5 and work up.
>
> How good the approximation is, depends. If you are having convergence
> problems it probably isn't.
>
> On 2 April 2015 at 01:23, Paolo Fraccaro <paolo.f.genova at gmail.com> wrote:
>
>> Hi
>>
>> I have a dataset of ~200k piece of hardware tested yearly for 10 years or
>> until failure (~15k). Therefore, the overall dataset size is ~2,000k. I'm
>> trying to fit a mixed effects logistic model with glmer, but the model
>> does not converge with the default settings. I tried to increase the
>> number of max iterations allowed (from 20 to 100) but still it does not
>> converge. I then set the nAGQ = 0 and obtained the less accurate estimate
>> of the model.
>>
>> My questions would be:
>> Do you have any idea of what parameters I could modify to try to make the
>> model converge?
>> How inaccurate is using nAGQ = 0?
>>
>> Many thanks.
>>
>> Paolo
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:11}}


From paul.johnson at glasgow.ac.uk  Thu Apr  2 19:03:47 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Thu, 2 Apr 2015 17:03:47 +0000
Subject: [R-sig-ME] heritability from longitudinal zero-inflated count data
Message-ID: <534CC46A-750D-458F-92A9-40DB505A0679@glasgow.ac.uk>

Hi all,

I?d like to fit a model with the following features:

* The data are parasite counts recorded at a number of time points (say 4) for each individual 
* Zero-inflation, i.e. a mixture of binary and count data
* Separate fixed effects for the binary and count components
* Separate random effects for both components. One of the random effects will have a pedigree-derived correlation structure (as in an animal model). The random effects will have the same structure for both components, but need to allow different variances.
* The random effect variances are allowed to vary over time.

The main aim is to estimate heritabilities for each time point, separately for the binary and count parts of the mixture, because the factors driving the two processes (encountering parasites and resistance to parasites) are expected to be driven by quite different factors, genetic and otherwise.

Can this be done outside DIY software such as JAGS? I?d be interested in knowing how close MCMCglmm can get to this model, even if it can?t do everything.

Thanks for your help,
Paul


From j.hadfield at ed.ac.uk  Fri Apr  3 09:16:02 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 03 Apr 2015 08:16:02 +0100
Subject: [R-sig-ME] design matrices in MCMCglmm
In-Reply-To: <551AAA26.6050204@gmail.com>
References: <5515C00C.8000904@gmail.com>
	<20150328080133.381406iv6lkvpdjw@www.staffmail.ed.ac.uk>
	<551AAA26.6050204@gmail.com>
Message-ID: <20150403081602.11067i7jlpt3bz0g@www.staffmail.ed.ac.uk>

Hi,

Have columns mate_1, mate_2 ... mate_n where n is group size. In each  
column have the identity of each cage mate (order does not matter).  
Make sure each column has the same factor levels even if they don't  
appear. For example,

factor(mate_1, levels=all.ids)

where all.ids are all possible cage mates. Then fit:

random=~mm(mate_1+mate_2+...mate_n):animal

where animal is linked to the pedigree through the ginverse argument.

Cheers,

Jarrod



Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Tue, 31 Mar  
2015 10:07:34 -0400:

> Hi Jarrod,
>
> Thank you for your help.
> My question is now extended to the subject of associative indirect  
> genetic effects.
>
> For example in this data set :
> id    cage
> a    1
> b    2
> c    1
> d    1
> e    2
> f    2
> g    2
>
> cage is a grouping variable describing the composition of cages. For  
> instance, individuals a,c,d live in cage 1.
>
> Design matrix Z_cage typically produced by MCMCglmm should be:
>      c1   c2
> a    1    0
> b    0    1
> c    1    0
> d    1    0
> e    0    1
> f    0    1
> g    0    1
> where phenotype of individuals {a, b, ..., g} are linked to cages 1 and 2.
>
> Design matrix Z_mates, however, linking the phenotype of individual  
> i to its cage' mates is:
>      a    b    c    d    e    f    g
> a    0    0    1    1    0    0    0
> b    0    0    0    0    1    1    1
> c    1    0    0    1    0    0    0
> d    1    0    1    0    0    0    0
> e    0    1    0    0    0    1    1
> f    0    1    0    0    1    0    1
> g    0    1    0    0    1    1    0
>
> It is Z_cage that is given by default, whereas it is matrix Z_mates  
> that should be used to predict associative effects.
>
> Is it possible to force MCMCglmm to work with Z_mates instead of Z_cage?
>
> Thanks again!
>
> Alexandre
>
> Le 2015-03-28 04:01, Jarrod Hadfield a ?crit :
>> Hi Alexandre,
>>
>> The design matrices should be identical for both effects (z_{ij}=1 if
>> the jth individual is the mother of individual i). The difference is in
>> the correlation structure of the random effects. For environmental
>> maternal effects they are assumed iid (i.e. an identity matrix) but for
>> the maternal genetic effects they are assumed to be proportional to the
>> A matrix. inverseA will return the inverse of A if you pass it the
>> pedigree. It is this inverse that is required for forming the MME.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>> Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Fri, 27 Mar
>> 2015 16:39:40 -0400:
>>
>>> Dear all,
>>>
>>> I am working on estimating maternal effects (genetic and environmental)
>>> with MCMCglmm that is new for me.
>>>
>>> I am trying to apply to MCMCglmm what is shown in online Muir's course
>>> notes made for SAS. Leanning on Henderson?s Mixed Model Equation, these
>>> notes explain how to solve MME to predict random effects ?by hand?.
>>>
>>> Here is my concern:
>>>
>>> I do not know how to extract the design matrices for a MCMCglmm model,
>>> e.g. the relatedness matrix or the one for maternal genetic effects. I
>>> want that to understand how the design matrices are constructed by
>>> comparing them to what they are supposed to look like.  For instance,
>>> the design matrix for maternal genetic effects should relate offspring
>>> to all the individuals that are in the pedigree, whereas the design
>>> matrix for maternal environmental effects should just relate offspring
>>> to their mothers. Does such a difference exist when MCMCglmm constructs
>>> its design matrices? If not, how to include such different matrices in
>>> models?
>>>
>>>
>>> Any help will be greatly appreciated. Thank you!
>>>
>>>
>>> Alexandre
>>>
>>>    [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Apr  3 09:19:38 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 03 Apr 2015 08:19:38 +0100
Subject: [R-sig-ME] Is it possible to account for temporal
 autocorrelation in MCMCglmm?
In-Reply-To: <CALC46t8hp8JQ-aHP+JikkBUQC6gwfM0_B5YOFb4oBZYE0gRwbg@mail.gmail.com>
References: <CALC46t8hp8JQ-aHP+JikkBUQC6gwfM0_B5YOFb4oBZYE0gRwbg@mail.gmail.com>
Message-ID: <20150403081938.47435qio7d15n4co@www.staffmail.ed.ac.uk>

Hi David,

Sorry - this is not possible in MCMCglmm (yet).

Cheers,

Jarrod


Quoting David Villegas R?os <chirleu at gmail.com> on Wed, 1 Apr 2015  
14:34:19 +0200:

> Dear all,
> For a number of individuals, I have measured several behavioral traits in the
> wild. Those traits (e.g. home range) can be estimated on different temporal
> scales, for example daily, weekly or monthly. I want to estimate  
> repeatability
> of those traits, assuming that the daily/weekly/monthly
> measurements (averages) represent replicates. I have 3 months (90 days) of
> data for  each trait.
>
> I have run a MCMCglmm model and extracted the residuals from it using:
>
> res=data$trait-predict(model, marginal=NULL)
>
> And then run:
> acf(res)
>
> And I found significant autocorrelation in lags 1 and 2.
>
> Is there any way to account for this (temporal) autocorrelation in MCMCglmm?
>
> Sorry for this pretty basic questions but I haven't found an answer so far.
>
> Thanks!
>
> David
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Apr  3 09:27:01 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 03 Apr 2015 08:27:01 +0100
Subject: [R-sig-ME] heritability from longitudinal zero-inflated count
 data
In-Reply-To: <534CC46A-750D-458F-92A9-40DB505A0679@glasgow.ac.uk>
References: <534CC46A-750D-458F-92A9-40DB505A0679@glasgow.ac.uk>
Message-ID: <20150403082701.23568crwlrmtedhc@www.staffmail.ed.ac.uk>

Hi,

It is possible, but you will need a lot of data. For example

counts=~trait-1+x:trait,
random=~us(trait):animal+idh(at.level(trait,1):time):year

this models separate intercepts for the binary and count parts, and  
different regressions on x. us(trait):animal estimates the additive  
genetic variance in both parts, and the additive genetic variance  
between them.  idh(at.level(trait,1):year):nest  fits different  
between-nest variances for different years for the count part (trait 1).


Cheers,

Jarrod



Quoting Paul Johnson <paul.johnson at glasgow.ac.uk> on Thu, 2 Apr 2015  
17:03:47 +0000:

> Hi all,
>
> I'd like to fit a model with the following features:
>
> * The data are parasite counts recorded at a number of time points  
> (say 4) for each individual
> * Zero-inflation, i.e. a mixture of binary and count data
> * Separate fixed effects for the binary and count components
> * Separate random effects for both components. One of the random  
> effects will have a pedigree-derived correlation structure (as in an  
> animal model). The random effects will have the same structure for  
> both components, but need to allow different variances.
> * The random effect variances are allowed to vary over time.
>
> The main aim is to estimate heritabilities for each time point,  
> separately for the binary and count parts of the mixture, because  
> the factors driving the two processes (encountering parasites and  
> resistance to parasites) are expected to be driven by quite  
> different factors, genetic and otherwise.
>
> Can this be done outside DIY software such as JAGS? I'd be  
> interested in knowing how close MCMCglmm can get to this model, even  
> if it can't do everything.
>
> Thanks for your help,
> Paul
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Apr  3 09:51:12 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 03 Apr 2015 08:51:12 +0100
Subject: [R-sig-ME] design matrices in MCMCglmm
In-Reply-To: <20150403081602.11067i7jlpt3bz0g@www.staffmail.ed.ac.uk>
References: <5515C00C.8000904@gmail.com>
	<20150328080133.381406iv6lkvpdjw@www.staffmail.ed.ac.uk>
	<551AAA26.6050204@gmail.com>
	<20150403081602.11067i7jlpt3bz0g@www.staffmail.ed.ac.uk>
Message-ID: <20150403085112.12135095ttmnhoso@www.staffmail.ed.ac.uk>

Hi,

Sorry it should have been just:

random=~mm(mate_1+mate_2+...mate_n)

and it is the mate_1, mate_2, ... mate_n that need to be linked to the  
A inverse.

Cheers,

Jarrod

Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 03 Apr 2015  
08:16:02 +0100:

> Hi,
>
> Have columns mate_1, mate_2 ... mate_n where n is group size. In  
> each column have the identity of each cage mate (order does not  
> matter). Make sure each column has the same factor levels even if  
> they don't appear. For example,
>
> factor(mate_1, levels=all.ids)
>
> where all.ids are all possible cage mates. Then fit:
>
> random=~mm(mate_1+mate_2+...mate_n):animal
>
> where animal is linked to the pedigree through the ginverse argument.
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Tue, 31  
> Mar 2015 10:07:34 -0400:
>
>> Hi Jarrod,
>>
>> Thank you for your help.
>> My question is now extended to the subject of associative indirect  
>> genetic effects.
>>
>> For example in this data set :
>> id    cage
>> a    1
>> b    2
>> c    1
>> d    1
>> e    2
>> f    2
>> g    2
>>
>> cage is a grouping variable describing the composition of cages.  
>> For instance, individuals a,c,d live in cage 1.
>>
>> Design matrix Z_cage typically produced by MCMCglmm should be:
>>     c1   c2
>> a    1    0
>> b    0    1
>> c    1    0
>> d    1    0
>> e    0    1
>> f    0    1
>> g    0    1
>> where phenotype of individuals {a, b, ..., g} are linked to cages 1 and 2.
>>
>> Design matrix Z_mates, however, linking the phenotype of individual  
>> i to its cage' mates is:
>>     a    b    c    d    e    f    g
>> a    0    0    1    1    0    0    0
>> b    0    0    0    0    1    1    1
>> c    1    0    0    1    0    0    0
>> d    1    0    1    0    0    0    0
>> e    0    1    0    0    0    1    1
>> f    0    1    0    0    1    0    1
>> g    0    1    0    0    1    1    0
>>
>> It is Z_cage that is given by default, whereas it is matrix Z_mates  
>> that should be used to predict associative effects.
>>
>> Is it possible to force MCMCglmm to work with Z_mates instead of Z_cage?
>>
>> Thanks again!
>>
>> Alexandre
>>
>> Le 2015-03-28 04:01, Jarrod Hadfield a ?crit :
>>> Hi Alexandre,
>>>
>>> The design matrices should be identical for both effects (z_{ij}=1 if
>>> the jth individual is the mother of individual i). The difference is in
>>> the correlation structure of the random effects. For environmental
>>> maternal effects they are assumed iid (i.e. an identity matrix) but for
>>> the maternal genetic effects they are assumed to be proportional to the
>>> A matrix. inverseA will return the inverse of A if you pass it the
>>> pedigree. It is this inverse that is required for forming the MME.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>>
>>> Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Fri, 27 Mar
>>> 2015 16:39:40 -0400:
>>>
>>>> Dear all,
>>>>
>>>> I am working on estimating maternal effects (genetic and environmental)
>>>> with MCMCglmm that is new for me.
>>>>
>>>> I am trying to apply to MCMCglmm what is shown in online Muir's course
>>>> notes made for SAS. Leanning on Henderson?s Mixed Model Equation, these
>>>> notes explain how to solve MME to predict random effects ?by hand?.
>>>>
>>>> Here is my concern:
>>>>
>>>> I do not know how to extract the design matrices for a MCMCglmm model,
>>>> e.g. the relatedness matrix or the one for maternal genetic effects. I
>>>> want that to understand how the design matrices are constructed by
>>>> comparing them to what they are supposed to look like.  For instance,
>>>> the design matrix for maternal genetic effects should relate offspring
>>>> to all the individuals that are in the pedigree, whereas the design
>>>> matrix for maternal environmental effects should just relate offspring
>>>> to their mothers. Does such a difference exist when MCMCglmm constructs
>>>> its design matrices? If not, how to include such different matrices in
>>>> models?
>>>>
>>>>
>>>> Any help will be greatly appreciated. Thank you!
>>>>
>>>>
>>>> Alexandre
>>>>
>>>>   [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Apr  3 09:52:56 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 03 Apr 2015 08:52:56 +0100
Subject: [R-sig-ME] heritability from longitudinal zero-inflated count
 data
In-Reply-To: <20150403082701.23568crwlrmtedhc@www.staffmail.ed.ac.uk>
References: <534CC46A-750D-458F-92A9-40DB505A0679@glasgow.ac.uk>
	<20150403082701.23568crwlrmtedhc@www.staffmail.ed.ac.uk>
Message-ID: <20150403085256.66312p3ypyxevpyc@www.staffmail.ed.ac.uk>

Not having a good morning!

random=~us(trait):animal+idh(at.level(trait,1):time):year

should have read

random=~us(trait):animal+idh(at.level(trait,1):year):nest

Jarrod




Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 03 Apr 2015  
08:27:01 +0100:

> Hi,
>
> It is possible, but you will need a lot of data. For example
>
> counts=~trait-1+x:trait,
> random=~us(trait):animal+idh(at.level(trait,1):time):year
>
> this models separate intercepts for the binary and count parts, and  
> different regressions on x. us(trait):animal estimates the additive  
> genetic variance in both parts, and the additive genetic variance  
> between them.  idh(at.level(trait,1):year):nest  fits different  
> between-nest variances for different years for the count part (trait  
> 1).
>
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Paul Johnson <paul.johnson at glasgow.ac.uk> on Thu, 2 Apr 2015  
> 17:03:47 +0000:
>
>> Hi all,
>>
>> I'd like to fit a model with the following features:
>>
>> * The data are parasite counts recorded at a number of time points  
>> (say 4) for each individual
>> * Zero-inflation, i.e. a mixture of binary and count data
>> * Separate fixed effects for the binary and count components
>> * Separate random effects for both components. One of the random  
>> effects will have a pedigree-derived correlation structure (as in  
>> an animal model). The random effects will have the same structure  
>> for both components, but need to allow different variances.
>> * The random effect variances are allowed to vary over time.
>>
>> The main aim is to estimate heritabilities for each time point,  
>> separately for the binary and count parts of the mixture, because  
>> the factors driving the two processes (encountering parasites and  
>> resistance to parasites) are expected to be driven by quite  
>> different factors, genetic and otherwise.
>>
>> Can this be done outside DIY software such as JAGS? I'd be  
>> interested in knowing how close MCMCglmm can get to this model,  
>> even if it can't do everything.
>>
>> Thanks for your help,
>> Paul
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ken.beath at mq.edu.au  Sat Apr  4 04:57:02 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 4 Apr 2015 13:57:02 +1100
Subject: [R-sig-ME] glmer does not converge,
 how inaccurate is using nAGQ = 0?
In-Reply-To: <CAF5_5cw6nLK5udCc7biXXGcGtg9QpiV351VsOu6p+XSySAOPVg@mail.gmail.com>
References: <loom.20150401T161133-576@post.gmane.org>
	<CAF5_5czPaTHHFXwDR2qd7JoWoJ-6ns5SvxUnCPYaTC8Zbw84BQ@mail.gmail.com>
	<CAEbNFTG-JhQzXfp4sk+NtMMBxpeWa2vKSRAxVRyUzOh8uN=hAQ@mail.gmail.com>
	<CAF5_5cw6nLK5udCc7biXXGcGtg9QpiV351VsOu6p+XSySAOPVg@mail.gmail.com>
Message-ID: <CAF5_5czQvE5a-R6mRVdjgr5rH1pOJs=WptabEJ9NSZYZ8a0LuA@mail.gmail.com>

Paolo sent me the output, and there are a couple of problems:
1. The intercept is very large about 94, which may cause some problems.
This can be fixed by centering (subtracting the mean or some other suitable
value)  the continuous variables.
2. The standard deveriation for the random effect is large. This usually
requires more quadrature points.
3. As you have a huge number of observations and groups it doesn't really
matter that much about the approximations. Almost anything will be
significant. I would just try centering the continuous variables.
4. You can also try another optimiser, as in a post from Ben, which
will probably remove the convergence error.




On 2 April 2015 at 21:10, Ken Beath <ken.beath at mq.edu.au> wrote:

> I think you have other problems, although sometimes this can be a break
> down in the approximations, and increasing nAGQ can work. Either your model
> is not identifiable, which means that it is overparameterised or some of
> your coefficients have become excessively negative, or you may have a very
> high random effect variance. The last will be helped by increasing the
> quadrature points, the second may be. Without seeing the output it is hard
> to tell.
>
> On 2 April 2015 at 20:36, Paolo Fraccaro <paolo.f.genova at gmail.com> wrote:
>
>> Hi,
>>
>> thanks for your suggestions. I left it going overnight still with nAGQ=1
>> and this time I got this warnings:
>>
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 0.00191069 (tol = 0.001,
>> component 4)
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model is nearly unidentifiable: very large eigenvalue
>>  - Rescale variables?
>>
>> Is the solution of increasing nAGQ still the best thing to do?
>>
>> Many thanks,
>>
>> Paolo
>>
>> On 1 April 2015 at 23:06, Ken Beath <ken.beath at mq.edu.au> wrote:
>>
>>> You could use a value of nAGQ that is higher, start with 5 and work up.
>>>
>>> How good the approximation is, depends. If you are having convergence
>>> problems it probably isn't.
>>>
>>> On 2 April 2015 at 01:23, Paolo Fraccaro <paolo.f.genova at gmail.com>
>>> wrote:
>>>
>>>> Hi
>>>>
>>>> I have a dataset of ~200k piece of hardware tested yearly for 10 years
>>>> or
>>>> until failure (~15k). Therefore, the overall dataset size is ~2,000k.
>>>> I'm
>>>> trying to fit a mixed effects logistic model with glmer, but the model
>>>> does not converge with the default settings. I tried to increase the
>>>> number of max iterations allowed (from 20 to 100) but still it does not
>>>> converge. I then set the nAGQ = 0 and obtained the less accurate
>>>> estimate
>>>> of the model.
>>>>
>>>> My questions would be:
>>>> Do you have any idea of what parameters I could modify to try to make
>>>> the
>>>> model converge?
>>>> How inaccurate is using nAGQ = 0?
>>>>
>>>> Many thanks.
>>>>
>>>> Paolo
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>>
>>> --
>>>
>>> *Ken Beath*
>>> Lecturer
>>> Statistics Department
>>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>>
>>> Phone: +61 (0)2 9850 8516
>>>
>>> Building E4A, room 526
>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>>
>>> CRICOS Provider No 00002J
>>> This message is intended for the addressee named and may contain
>>> confidential information.  If you are not the intended recipient, please
>>> delete it and notify the sender.  Views expressed in this message are those
>>> of the individual sender, and are not necessarily the views of the Faculty
>>> of Science, Department of Statistics or Macquarie University.
>>>
>>>
>>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:31}}


From ken.beath at mq.edu.au  Sat Apr  4 06:17:59 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 4 Apr 2015 15:17:59 +1100
Subject: [R-sig-ME] Problems with convergence
In-Reply-To: <551D4FE7.5020605@gmail.com>
References: <CAF5_5cxHcAWSvgYL3876407aM5tM4pVBB+LTjr_gKPc7Bh8rbQ@mail.gmail.com>
	<loom.20150319T042938-705@post.gmane.org>
	<CAF5_5cy0BE9Mi-_VROBQ+fUXYM+GX8=vbmga+KygRVWfZHsQ5w@mail.gmail.com>
	<loom.20150330T220526-332@post.gmane.org>
	<077E31A57DA26E46AB0D493C9966AC730F0978FF5A@UM-MAIL4112.unimaas.nl>
	<CAF5_5czKbU9bvOCLBaDzhd1snscg0FfT49Z77KRJJ35LKi8ORw@mail.gmail.com>
	<551D4FE7.5020605@gmail.com>
Message-ID: <CAF5_5cwvWvv-m+M8RAQzDWgZNpRo-KPqAN9Efxv3hu9kq-V9Ag@mail.gmail.com>

Thanks. Yes, I've now changed to using nlminb. It doesn't seem to be in the
package, but the function works. One problem I've found with nlminb is that
it falsely indicates convergence problems when the random effect variance
is zero, so what I have done when it returns non-convergence is to the use
the final values as starting values for Nelder-Mead. I can perform that in
the optimisation function and that way the profiling works as well.

In a week or so my simulations will finish and I'll have an idea how
everything has worked.

On 3 April 2015 at 01:19, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>   Hmm.  Have you tried with nlminb?  This works for me ...
>
> glmer1a <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt +
>      factor(id) +
>       (0+trt12|id), data=thedata, family=binomial, nAGQ=7)
>
> glmer1X <- update(glmer1a,
>                   control=glmerControl(optimizer="nlminbwrap"))
>
>
>   I don't know whether it works better overall (it does use a
> different convergence criterion ...) or whether this is just the luck
> of the draw on this particular case.
>
>    cheers
>     Ben Bolker
>
> PS I don't remember when nlminbwrap was added to the code base, but
> it's pretty simple:
>
> function (par, fn, lower, upper, control = list(), ...)
> {
>     res <- nlminb(start = par, fn, gradient = NULL, hessian = NULL,
>         scale = 1, lower = lower, upper = upper, control = control,
>         ...)
>     list(par = res$par, fval = res$objective, conv = res$convergence,
>         message = res$message)
> }
>
>
> On 15-04-02 05:27 AM, Ken Beath wrote:
> > It would be nice to have this work properly, as I need it for
> > certain things and it seems that other people are having similar
> > problems.
> >
> > Getting it to work by increasing the quadrature points is a bit of
> > an aberration, it is not what typically happens, and I've put an
> > example at the end. At least in this one the profiling works which
> > means the maximum must be fairly close to that obtained from the
> > optimisation.
> >
> > My feeling on this, is that possibly the problem is not with the
> > optimiser, seeing that it fails with so many optimisers, but rather
> > with the calculation of the marginal likelihood. These optimisers
> > don't tend to stop with 0.001 gradients. When I have time I will
> > find in the code how the node locations are calculated and see what
> > is happening.
> >
> > Anyway, here is one that fails irrespective of  nAGQ value.
> >
> > thedata <- structure(list(nEvents = c(10L, 53L, 17L, 18L, 22L, 6L,
> > 16L, 14L, 13L, 18L, 15L, 19L, 52L, 19L, 8L, 16L, 50L, 8L, 9L, 4L,
> > 26L, 45L, 18L, 20L, 5L, 16L, 18L, 7L, 3L, 19L, 30L, 26L, 66L, 23L,
> > 29L, 18L, 72L, 25L, 9L, 2L), total = c(200, 200, 200, 200, 200,
> > 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
> > 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,
> > 200, 200, 200, 200, 200, 200, 200, 200, 200), trt = c(0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,
> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), id = structure(c(1L, 2L,
> > 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> > 18L, 19L, 20L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> > 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L), .Label = c("1", "2", "3",
> > "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
> > "16", "17", "18", "19", "20"), class = "factor"), trt12 = c(-0.5,
> > -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5,
> > -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.5, 0.5, 0.5, 0.5,
> > 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,
> > 0.5, 0.5, 0.5)), .Names = c("nEvents", "total", "trt", "id",
> > "trt12"), row.names = c(NA, 40L), class = "data.frame")
> >
> > glmer1a <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt +
> > factor(id) + (0+trt12|id), data=thedata, family=binomial, nAGQ=7)
> >
> > glmer1b <- glmer(cbind(nEvents,total-nEvents) ~ -1 + trt +
> > factor(id) + (0+trt12|id), data=thedata, family=binomial, nAGQ=21)
> >
> >
> >
> >
> >
> > On 1 April 2015 at 02:25, Viechtbauer Wolfgang (STAT) <
> > wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >
> >> This discussion piqued my interest. The model that Ken was
> >> fitting is in essence one of the models that is fitted by the
> >> rma.glmm() function in the metafor package. This is sometimes
> >> called the unconditional model with fixed study effects. To
> >> illustrate:
> >>
> >> ### original data
> >>
> >> thedata <- structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> >> 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> >> 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> >> 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> >> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> >> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> >> 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> >> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> >> 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> >> 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> >> 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> >> 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> >> "2","3","4","5","6","7","8","9","10","11","12","13",
> >> "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> >>
> >>
> "total","trt","id"),row.names=c(NA,40L),class="data.frame")
> >>
> >> ### restructure data as needed for input into rma.glmm()
> >>
> >> dat <- cbind(thedata[1:20,], thedata[21:40,]) dat$id <- dat$id <-
> >> dat$trt <- dat$trt <- NULL colnames(dat) <- c("ci", "n2i", "ai",
> >> "n1i")
> >>
> >> library(metafor) library(lme4)
> >>
> >> ### model fitted by Ken res1 <-
> >> glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) +
> >> (0+trt|id), data=thedata, family=binomial)
> >>
> >> ### fit unconditional model with fixed study effects via
> >> rma.glmm() res2 <- rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci,
> >> n2i=n2i, data=dat, nAGQ=1)
> >>
> >> ### to get exact equivalence, use +-1/2 coding for the random
> >> effects thedata$trt12 <- thedata$trt - 1/2 res3 <-
> >> glmer(cbind(nEvents,total-nEvents) ~ -1 + trt + factor(id) +
> >> (0+trt12|id), data=thedata, family=binomial)
> >>
> >> summary(res1) summary(res2) summary(res3)
> >>
> >> ### end example
> >>
> >> A few notes:
> >>
> >> 1) rma.glmm() uses nAGQ=7 by default, so I switched that to 1 for
> >> the comparison.
> >>
> >> 2) Some discussion of the 0/1 versus +-1/2 coding can be found in
> >> Turner et al. (2000) and Higgins et al. (2001). I tend to prefer
> >> the +-1/2 coding, so that is also what is currently implemented
> >> in rma.glmm(), but I may add the 0/1 coding as an option.
> >>
> >> 3) A nice discussion of the model is provided by Senn (2000). He
> >> also discusses a variety of other modeling options, including a
> >> model using random study effects.
> >>
> >> 4) In fact, the unconditional model with random study effects can
> >> be fitted with:
> >>
> >> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat,
> >> model=" UM.RS")
> >>
> >> (which makes use of glmer() underneath). As discussed by Senn,
> >> this model may violate what he calls the 'concurrent control
> >> principle', but his wording is cautious ('may violate', 'may be
> >> regarded as undesirable'), which reflects the lack of a thorough
> >> discussion in the literature comparing the various models.
> >>
> >> 5) Yet another option is the (mixed-effects) conditional logistic
> >> model. See, for example, Stijnen et al. (2010). This model is
> >> obtained when conditioning on the total number of events within
> >> each study and leads to non-central hypergeometric distributions
> >> for the data within each study. This model can be fitted with:
> >>
> >> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat,
> >> model="CM.EL")
> >>
> >> Sorry, it's slow (I haven't found a clever way of speeding up
> >> the integration over the non-central hypergeometric
> >> distributions). Much faster, thanks to lme4, is:
> >>
> >> rma.glmm(measure="OR", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat,
> >> model=" CM.AL")
> >>
> >> which uses an approximation to the exact conditional likelihood.
> >>
> >> 6) And of course there are Bayesian implementations of such
> >> models.
> >>
> >> 7) With respect to the model fitted by Ken, it's maybe
> >> interesting to note that NOT using the Laplace approximation, but
> >> something like 7 quadrature points, does not cause any
> >> convergence warnings:
> >>
> >> glmer(cbind(nEvents,total-nEvents) ~ trt + factor(id) +
> >> (0+trt|id), data=thedata, family=binomial, nAGQ=7)
> >>
> >> Alright, I'll shut up now.
> >>
> >> References mentioned above:
> >>
> >> Higgins, J. P. T., Whitehead, A., Turner, R. M., Omar, R. Z., &
> >> Thompson, S. G. (2001). Meta-analysis of continuous outcome data
> >> from individual patients. Statistics in Medicine, 20(15),
> >> 2219-2241.
> >>
> >> Senn, S. (2000). The many modes of meta. Drug Information
> >> Journal, 34, 535-549.
> >>
> >> Stijnen, T., Hamza, T. H., & Ozdemir, P. (2010). Random effects
> >> meta-analysis of event outcome in the framework of the
> >> generalized linear mixed model with applications in sparse data.
> >> Statistics in Medicine, 29(29), 3046-3067.
> >>
> >> Turner, R. M., Omar, R. Z., Yang, M., Goldstein, H., & Thompson,
> >> S. G. (2000). A multilevel model framework for meta-analysis of
> >> clinical trials with binary outcomes. Statistics in Medicine,
> >> 19(24), 3417-3432.
> >>
> >> Best, Wolfgang
> >>
> >> -- Wolfgang Viechtbauer, Ph.D., Statistician Department of
> >> Psychiatry and Neuropsychology School for Mental Health and
> >> Neuroscience Faculty of Health, Medicine, and Life Sciences
> >> Maastricht University, P.O. Box 616 (VIJV1) 6200 MD Maastricht,
> >> The Netherlands +31 (43) 388-4170 | http://www.wvbauer.com
> >>
> >>> -----Original Message----- From: R-sig-mixed-models
> >>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf Of
> >>> Ben Bolker Sent: Monday, March 30, 2015 22:21 To:
> >>> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME]
> >>> Problems with convergence
> >>>
> >>> Ken Beath <ken.beath at ...> writes:
> >>>
> >>>> Yes, I was demonstrating that it fails convergence and then
> >>>> as a consequence fails to profile. I have my doubts about
> >>>> convergence for the bobyqa algorithm, I have other
> >>>> applications where it doesn't converge
> >>> properly.
> >>>> For some of my own work I've used nlminb followed by
> >>>> Nelder-Mead if
> >>> there
> >>>> is a convergence failure. Not optimal but it seems to work.
> >>>
> >>> I'm still not sure whether you expect it to converge (I think
> >>> you do), or whether you are just pointing out that the
> >>> convergence warning in this case is probably justified (in the
> >>> face of so many convergence warnings that turn out to be false
> >>> positives, this is a useful piece of information).
> >>>
> >>>> While it is fairly heavily parameterised it is a real model,
> >>>> a frequentist implementation of Smith, T. C., Spiegelhalter,
> >>>> D. J., & Thomas, a.
> >>> (1995).
> >>>> Bayesian approaches to random-effects meta-analysis: a
> >>>> comparative
> >>> study.
> >>>> Statistics in Medicine, 14(24), 2685?99. The reason for
> >>>> having studies
> >>> as
> >>>> fixed effects is probably philosophical, the overall success
> >>>> rates are
> >>> not
> >>>> likely to be given by normally distributed random effects,
> >>>> and are in
> >>> many
> >>>> cases specifically chosen.
> >>>
> >>> I can appreciate that, but I still think it's unrealistic to
> >>> expect to be able to fit 22 parameters to 40 observations
> >>> except under very special circumstances.  One point about
> >>> switching from the Bayesian to the frequentist world is that
> >>> the Bayesians (by definition) put priors on their parameters,
> >>> which provides a degree of regularization that is not by
> >>> default available to frequentist methods.  What priors did
> >>> Smith et al. use?  It might be worth trying this in blme with
> >>> priors on the fixed effects ...
> >>>
> >>>> I did find that one of the data sets that I have also failed,
> >>>> but
> >>> fitted
> >>>> with a commercial program that is based on the EM algorithm.
> >>>> For this
> >>> type
> >>>> of problem it is actually faster, as any type of quasi-Newton
> >>>> needs to calculate lots of derivatives.
> >>>
> >>> I could whine about the difficulty of finding globally robust,
> >>> reliable, and fast optimization algorithms, but I won't.  I can
> >>> certainly appreciate that there are more reliable methods for
> >>> particular sub-classes of problems.
> >>>
> >>>> Anyway, I'm going to keep looking at the methods, and
> >>>> eventually the
> >>> code
> >>>> for glmer and may eventually have some suggestions.
> >>>
> >>> Would be happy to hear them.
> >>>
> >>> It's worth pointing out that lme4 is using a preliminary
> >>> "nAGQ=0" step, which ignores the terms contributed by the
> >>> integrals over the distributions of the conditional modes and
> >>> as a result is able to fit both the fixed-effect parameters and
> >>> the conditional modes in a single linear-algebra step, reducing
> >>> the dimensionality of the nonlinear optimization to the length
> >>> of the variance-covariance parameter vector ...
> >>>
> >>>> On 19 March 2015 at 14:45, Ben Bolker <bbolker <at>
> >>>> gmail.com> wrote:
> >>>>
> >>>>> Ken Beath <ken.beath <at> ...> writes:
> >>>>>
> >>>>>> The following code shows that there are convergence
> >>>>>> problem
> >>> messages
> >>>>>> where there is a problem with convergence. The profiling
> >>>>>> shows that the maximum found is not the correct one. This
> >>>>>> is simulated data
> >>> for
> >>>>>> a binary meta-analysis with fixed effect for study and
> >>>>>> random
> >>> effect
> >>>>>> for treatment.
> >>>>>
> >>>
> >>> [paragraph snipped to try to make Gmane happy]
> >>>
> >>>>> However, may I comment that this is a slightly ridiculous
> >>>>> scenario? The data set here has 40 observations, and the
> >>>>> model tries to fit 22 parameters.  The model that treats id
> >>>>> as a random effect works much better.  I can believe there
> >>>>> are scenarios where you really do want study as a fixed
> >>>>> effect, but did you expect it to be practical here?
> >>>>>
> >>>>> But maybe you're just trying to show that this is a "true
> >>>>> positive" case for the convergence warnings.
> >>>>>
> >>>>> Some random code I wrote while diagnosing what was going
> >>>>> on:
> >>>>>
> >>>>> library(ggplot2); theme_set(theme_bw())
> >>>>>
> >>>>> ## proportion + weights is a little easier to handle
> >>>>> thedata <- transform(thedata,prop=nEvents/total)
> >>>>>
> >>>>> ggplot(thedata,aes(trt,prop))+geom_point(aes(size=total))+
> >>>>> geom_line(aes(group=id),colour="gray") glmer1 <-
> >>>>> glmer(prop~trt+factor(id)+(0+trt|id),
> >>>>> weights=total,data=thedata,family=binomial)
> >>>>>
> >>>>> ## id as RE glmer2 <- glmer(prop~trt+(1|id)+(0+trt|id),
> >>>>> weights=total,data=thedata,family=binomial)
> >>>>>
> >>>>> dd <- update(glmer1,devFunOnly=TRUE) pars <-
> >>>>> unlist(getME(glmer1,c("theta","fixef"))) library("bbmle")
> >>>>> ss <- slice2D(pars,dd) library("lattice") plot(ss) ## too
> >>>>> complex, but too much work to cut down significantly
> >>>>>
> >>>>>> library(lme4)
> >>>>>>
> >>>>>> thedata <-
> >>>>>> structure(list(nEvents=c(10L,53L,17L,18L,22L,6L,16L,
> >>>>>> 14L,13L,18L,15L,19L,52L,19L,8L,16L,50L,8L,9L,4L,
> >>>>>> 26L,45L,18L,20L,5L,16L,18L,7L,3L,19L,30L,26L,66L,
> >>>>>> 23L,29L,18L,72L,25L,9L,2L),total=c(200,200,200,200,
> >>>>>> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> >>>>>> 200,200,200,200,200,200,200,200,200,200,200,200,200,
> >>>>>> 200,200,200,200,200,200,200,200,200,200),trt=c(0,
> >>>>>> 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
> >>>>>> 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),id=structure(c(1L,
> >>>>>> 2L,3L,4L,5L,6L,7L,8L,9L,10L,11L,12L,13L,14L,15L,
> >>>>>> 16L,17L,18L,19L,20L,1L,2L,3L,4L,5L,6L,7L,8L,9L,
> >>>>>> 10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L),.Label=c("1",
> >>>>>>
> >>>>>>
> "2","3","4","5","6","7","8","9","10","11","12","13",
> >>>>>>
> >>>
> "14","15","16","17","18","19","20"),class="factor")),.Names=c("nEvents",
> >>>>>>
> >>>
> "total","trt","id"),row.names=c(NA,40L),class="data.frame")
> >>>>>>
> >>>>>> glmer1<-glmer(cbind(nEvents,total-nEvents)~trt+factor(id)+
> >>>>>
> >>>>>>
> ##   (0+trt|id),data=thedata,family=binomial)
> >>>>>>
> >>>>>> # while glmer has problems with component 9 it is 8 with
> >>>>>> a problem
> >>>>> profile
> >>>>>> # I've use devtol so the discrepancy is printed
> >>>>>> prof.glmer1<-profile(glmer1,which=8,devtol=1.0e-3)
> >>
> >
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVHU/nAAoJEOCV5YRblxUHxPEIAKQ6kISS1aANugvV6wvq7/6C
> tIkLUZIxxqCn1UzfbB4naqVQ/4B9ipNlpWV8FEVJs5H7IxoQY1iCojONqihmiHO6
> SE/m44U4xEsX94q47d/vWCNqbwk9sGyXZj7R4lAOsPZiUqkvaKKV4Py8IF+O2nwM
> RjuzSGGw3ZusE7gIX6UB79lpgVvE8RZUOzJwR8pjKcBhbBHSYslAmdd9o8HpXTkm
> EWhZ3PpFEnWopXfeG2uN5HWGD8OjP7w8578ZHKLJhOW/9VEZQ9ykI/I8/yOlb7OJ
> dfbzRpQe/cKFghMYvF/xR2y0tdp98OwQUE7tKJneOJLqV2Q1u9w/m4oCRXVYNmA=
> =8saW
> -----END PGP SIGNATURE-----
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From hans.ekbrand at gmail.com  Sat Apr  4 11:29:49 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sat, 4 Apr 2015 11:29:49 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
Message-ID: <20150404092949.GE12461@hans>

Dear list,

I know, the failure to converge problem is boring, but still I would
like your input on my situation.

I have tried four optimizers/methods, and they all fail; glmer used.

1. Nelder_Mead: Model failed to converge with max|grad| = 0.00116526
   (tol = 0.001, component 6)

2. bobyqa: Model failed to converge with max|grad| = 0.00117064 (tol =
   0.001, component 7)

3. optimx, nlminb: Model failed to converge: degenerate Hessian with 4
   negative eigenvalues

4. optimx, L-BFGS-B: Model failed to converge with max|grad| =
   0.012963 (tol = 0.001, component 7)" "Model failed to converge:
   degenerate Hessian with 3 negative eigenvalues

The sample size is large: 1.833.793

The estimates resulting from fitting the model to data with the
different optimizers are similar:

                                     NM     bobyqa      nlmin       BFGS
(Intercept)                   4.9857379  3.7283744  4.9477121  3.2138480
QoG                           0.7866227  0.5962816  0.7534208  0.5991817
GDPLog                       -1.5161825 -1.3643422 -1.5111097 -1.2940261
Ruralyes                      4.3436228  4.3422641  4.3419199  4.3415551
KilledPerMillion5Log          0.6632158  0.6005677  0.6276264  0.5216984
Ruralyes:KilledPerMillion5Log 0.7313136  0.7316543  0.7314746  0.7329137

My theoretical focus is on the last two rows.

1. Is this likely to be a false positive? I'm willing to share data if
   that can help the development of lme4.

2. If the fits are bad, then what are my alternatives? continue with
   glmer and increase nAGQ? Other ideas? Or do I need to use other
   packages? I really love lme4, so I hope this will not be necessary.


Kind regards,

Hans Ekbrand







Postscript.

Here is the output of summary for the Nelder_Mead fit:

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: SanitationDeprivation ~ (1 | Country) + (1 | ClusterID) + QoG +  
    GDPLog + Rural * KilledPerMillion5Log
   Data: my.df.aid

      AIC       BIC    logLik  deviance  df.resid 
1013298.5 1013397.9 -506641.2 1013282.5   1833785 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-9.6390 -0.2883 -0.0508  0.0666 14.6730 

Random effects:
 Groups    Name        Variance Std.Dev.
 ClusterID (Intercept)  9.675   3.110   
 Country   (Intercept) 11.115   3.334   
Number of obs: 1833793, groups:  ClusterID, 38177; Country, 65

Fixed effects:
                              Estimate Std. Error z value Pr(>|z|)    
(Intercept)                    4.98574    0.08764   56.89  < 2e-16 ***
QoG                            0.78662    0.13190    5.96 2.46e-09 ***
GDPLog                        -1.51618    0.04841  -31.32  < 2e-16 ***
Ruralyes                       4.34362    0.04655   93.31  < 2e-16 ***
KilledPerMillion5Log           0.66322    0.15070    4.40 1.08e-05 ***
Ruralyes:KilledPerMillion5Log  0.73131    0.06059   12.07  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) QoG    GDPLog Rurlys KlPM5L
QoG         -0.042                            
GDPLog      -0.153  0.129                     
Ruralyes    -0.020  0.067 -0.037              
KlldPrMll5L -0.081 -0.113 -0.091 -0.131       
Rrlys:KPM5L -0.007 -0.088 -0.044 -0.426  0.205


From ken.beath at mq.edu.au  Sat Apr  4 12:10:35 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 4 Apr 2015 21:10:35 +1100
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150404092949.GE12461@hans>
References: <20150404092949.GE12461@hans>
Message-ID: <CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>

One of the problems is that you have a relatively high random effects
variance. A standard deviation of the intercept of 3 is a huge amount, it
means that there is massive variation in the random effect value needed to
model each cluster, to the point that some clusters will be all zeros and
some will be all ones. In this situation the assumption of approximate
normality of the likelihood around the nodes which is required for using
Laplace's method is very far from met.

I would find a spare computer and increase nAGQ to say 5. It might take a
while to run but hopefully it will be enough to make it converge. Then
increase nAGQ until the logLikelihood doesn't change. I have a preference
for nlminb.

Programs that do random effects logistic with more than one random effect
are scarce. I can try Latent Gold with Syntax Module but I'm not certain
what limit it has on number of observations.


On 4 April 2015 at 20:29, Hans Ekbrand <hans.ekbrand at gmail.com> wrote:

> Dear list,
>
> I know, the failure to converge problem is boring, but still I would
> like your input on my situation.
>
> I have tried four optimizers/methods, and they all fail; glmer used.
>
> 1. Nelder_Mead: Model failed to converge with max|grad| = 0.00116526
>    (tol = 0.001, component 6)
>
> 2. bobyqa: Model failed to converge with max|grad| = 0.00117064 (tol =
>    0.001, component 7)
>
> 3. optimx, nlminb: Model failed to converge: degenerate Hessian with 4
>    negative eigenvalues
>
> 4. optimx, L-BFGS-B: Model failed to converge with max|grad| =
>    0.012963 (tol = 0.001, component 7)" "Model failed to converge:
>    degenerate Hessian with 3 negative eigenvalues
>
> The sample size is large: 1.833.793
>
> The estimates resulting from fitting the model to data with the
> different optimizers are similar:
>
>                                      NM     bobyqa      nlmin       BFGS
> (Intercept)                   4.9857379  3.7283744  4.9477121  3.2138480
> QoG                           0.7866227  0.5962816  0.7534208  0.5991817
> GDPLog                       -1.5161825 -1.3643422 -1.5111097 -1.2940261
> Ruralyes                      4.3436228  4.3422641  4.3419199  4.3415551
> KilledPerMillion5Log          0.6632158  0.6005677  0.6276264  0.5216984
> Ruralyes:KilledPerMillion5Log 0.7313136  0.7316543  0.7314746  0.7329137
>
> My theoretical focus is on the last two rows.
>
> 1. Is this likely to be a false positive? I'm willing to share data if
>    that can help the development of lme4.
>
> 2. If the fits are bad, then what are my alternatives? continue with
>    glmer and increase nAGQ? Other ideas? Or do I need to use other
>    packages? I really love lme4, so I hope this will not be necessary.
>
>
> Kind regards,
>
> Hans Ekbrand
>
>
>
>
>
>
>
> Postscript.
>
> Here is the output of summary for the Nelder_Mead fit:
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: SanitationDeprivation ~ (1 | Country) + (1 | ClusterID) + QoG +
>     GDPLog + Rural * KilledPerMillion5Log
>    Data: my.df.aid
>
>       AIC       BIC    logLik  deviance  df.resid
> 1013298.5 1013397.9 -506641.2 1013282.5   1833785
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -9.6390 -0.2883 -0.0508  0.0666 14.6730
>
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  ClusterID (Intercept)  9.675   3.110
>  Country   (Intercept) 11.115   3.334
> Number of obs: 1833793, groups:  ClusterID, 38177; Country, 65
>
> Fixed effects:
>                               Estimate Std. Error z value Pr(>|z|)
> (Intercept)                    4.98574    0.08764   56.89  < 2e-16 ***
> QoG                            0.78662    0.13190    5.96 2.46e-09 ***
> GDPLog                        -1.51618    0.04841  -31.32  < 2e-16 ***
> Ruralyes                       4.34362    0.04655   93.31  < 2e-16 ***
> KilledPerMillion5Log           0.66322    0.15070    4.40 1.08e-05 ***
> Ruralyes:KilledPerMillion5Log  0.73131    0.06059   12.07  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) QoG    GDPLog Rurlys KlPM5L
> QoG         -0.042
> GDPLog      -0.153  0.129
> Ruralyes    -0.020  0.067 -0.037
> KlldPrMll5L -0.081 -0.113 -0.091 -0.131
> Rrlys:KPM5L -0.007 -0.088 -0.044 -0.426  0.205
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From hans.ekbrand at gmail.com  Sat Apr  4 20:15:11 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sat, 4 Apr 2015 20:15:11 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
Message-ID: <20150404181511.GF12461@hans>

On Sat, Apr 04, 2015 at 09:10:35PM +1100, Ken Beath wrote:
> One of the problems is that you have a relatively high random effects
> variance. A standard deviation of the intercept of 3 is a huge amount, it
> means that there is massive variation in the random effect value needed to
> model each cluster, to the point that some clusters will be all zeros and
> some will be all ones. In this situation the assumption of approximate
> normality of the likelihood around the nodes which is required for using
> Laplace's method is very far from met.

Thanks for your advice, I really appreciate it!

I tried nAGQ=5, but met with:

## Error: nAGQ > 1 is only available for models with a single, scalar
random-effects term

As you point out, some clusters will be all zeros (and some will be
all ones). While my data is on the individual level,

a) the variable I'm mainly interested in, KilledPerMillion5Log, varies
only at the country level, &

b) I currently have no variables in the model that vary at the
individual level

So, perhaps I could aggregate the individual level data to the cluster
level, and do without the random term for cluster? I mean, calculate
the proportions of yes in each cluster and use that as the dependent
variable.

This would, I assume, require that each cluster was given a weight
that corresponded to the number of individuals in it - or I would not
be able to say anything about probabilities at the individual level,
right?


From bbolker at gmail.com  Sun Apr  5 01:36:04 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 04 Apr 2015 19:36:04 -0400
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150404181511.GF12461@hans>
References: <20150404092949.GE12461@hans>	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans>
Message-ID: <55207564.1060501@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-04-04 02:15 PM, Hans Ekbrand wrote:
> On Sat, Apr 04, 2015 at 09:10:35PM +1100, Ken Beath wrote:
>> One of the problems is that you have a relatively high random
>> effects variance. A standard deviation of the intercept of 3 is a
>> huge amount, it means that there is massive variation in the
>> random effect value needed to model each cluster, to the point
>> that some clusters will be all zeros and some will be all ones.
>> In this situation the assumption of approximate normality of the
>> likelihood around the nodes which is required for using Laplace's
>> method is very far from met.
> 
> Thanks for your advice, I really appreciate it!
> 
> I tried nAGQ=5, but met with:
> 
> ## Error: nAGQ > 1 is only available for models with a single,
> scalar random-effects term
> 
> As you point out, some clusters will be all zeros (and some will
> be all ones). While my data is on the individual level,
> 
> a) the variable I'm mainly interested in, KilledPerMillion5Log,
> varies only at the country level, &
> 
> b) I currently have no variables in the model that vary at the 
> individual level
> 
> So, perhaps I could aggregate the individual level data to the
> cluster level, and do without the random term for cluster? I mean,
> calculate the proportions of yes in each cluster and use that as
> the dependent variable.
> 
> This would, I assume, require that each cluster was given a weight 
> that corresponded to the number of individuals in it - or I would
> not be able to say anything about probabilities at the individual
> level, right?

 I would say pretty much any time you can aggregate without losing
information, you should, for ease of computation (this accords with
the Murtaugh 2007 "Simplicity and complexity" paper that I cite here
on a regular basis).  If all of your covariates are at the cluster
level, then this reduces to a binomial GLM (you can account for
overdispersion either by using a quasi-binomial model in glm() or by
staying with glmer() and keeping the random effect of cluster (now an
observation-level random effect).

  Ben Bolker


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVIHVjAAoJEOCV5YRblxUHUYsH/243gzJN9hWayUICMmQop6iZ
+p+RIxh3lpSmB1lnRX+VXpghNpB4a5s98m+q5HZJB2eUyBCJ7pwXbHuTaZZ2t2D0
v6V/Ih2VeoqnbVqaSrPDNgDufNO1RhHlc4h6L0bIGf/etmOHgtHaPnly5JUXUmq4
QZdt5Sxotqshdbqf+4FvMNFVa1cNWJNLBY0XB2GecSLa8MI7vF1UHvlqdtDWIO9e
WalpfJq6C4oqIyz2kCsZWRijSHroFpPJ6eMlKmbLFLxfY6rP5dQZK11ktsANQ7lu
bnPHoF1Xzwnl87XDl/v6K9P1ge2x7bvihDUVodjBoK31CHc8UAYvh/5Ud4AGKoY=
=9xK3
-----END PGP SIGNATURE-----


From hans.ekbrand at gmail.com  Sun Apr  5 02:41:47 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 5 Apr 2015 02:41:47 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <55207564.1060501@gmail.com>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
Message-ID: <20150405004147.GG12461@hans>

On Sat, Apr 04, 2015 at 07:36:04PM -0400, Ben Bolker wrote:
> > So, perhaps I could aggregate the individual level data to the
> > cluster level, and do without the random term for cluster? I mean,
> > calculate the proportions of yes in each cluster and use that as
> > the dependent variable.
> > 
> > This would, I assume, require that each cluster was given a weight 
> > that corresponded to the number of individuals in it - or I would
> > not be able to say anything about probabilities at the individual
> > level, right?
> 
>  I would say pretty much any time you can aggregate without losing
> information, you should, for ease of computation (this accords with
> the Murtaugh 2007 "Simplicity and complexity" paper that I cite here
> on a regular basis).  If all of your covariates are at the cluster
> level

[ Thanks for your advice, it's much appreciated. ]

The covariates are not all at the cluster level. Actually only one
covariate is at the cluster level, the others are at the country
level.

> then this reduces to a binomial GLM (you can account for
> overdispersion either by using a quasi-binomial model in glm() or by
> staying with glmer() and keeping the random effect of cluster (now an
> observation-level random effect).

Since I still have the country level to account for, I need to use glmer().

I have created an aggregated data set with a variable for the
proportion deprived=TRUE in each cluster, and a variable for the
number of cases in that cluster (to use as weight).

Perhaps this is not a question specific for mixed models, but what
family and link function would be appropriate now? This was the best I
could come up with:

library(car)
lm1 <- lmer(logit(Prop.deprived.in.cluster) ~ (1|Country) + QoG + GDPLog + Rural * KilledPerMillion5Log, data = my.small.df, weights = my.small.df$weight)

Linear mixed model fit by REML ['lmerMod']
Formula: logit(Prop.deprived.in.cluster) ~ (1 | Country) + QoG + GDPLog +  
    Rural * KilledPerMillion5Log
   Data: my.small.df
Weights: my.small.df$weight

REML criterion at convergence: 157709.8

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-4.9983 -0.5626 -0.0622  0.4371  6.1171 

Random effects:
 Groups   Name        Variance Std.Dev.
 Country  (Intercept)   1.768   1.33   
 Residual             139.292  11.80   
Number of obs: 38028, groups:  Country, 65

Fixed effects:
                              Estimate Std. Error t value
(Intercept)                    1.25542    1.90567    0.66
QoG                            0.39120    0.40850    0.96
GDPLog                        -0.51799    0.23031   -2.25
Ruralyes                       1.91545    0.02232   85.80
KilledPerMillion5Log           0.06190    0.28557    0.22
Ruralyes:KilledPerMillion5Log  0.35303    0.03728    9.47

Correlation of Fixed Effects:
            (Intr) QoG    GDPLog Rurlys KlPM5L
QoG          0.571                            
GDPLog      -0.989 -0.486                     
Ruralyes    -0.013  0.001  0.006              
KlldPrMll5L -0.013  0.239 -0.009  0.045       
Rrlys:KPM5L  0.004 -0.001  0.000 -0.519 -0.084

my.small.df is available here if someone wants to have a go at it

http://hansekbrand.se/code/my.small.df.RData (1.1 MB)


From ken.beath at mq.edu.au  Sun Apr  5 11:31:25 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sun, 5 Apr 2015 19:31:25 +1000
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150405004147.GG12461@hans>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
Message-ID: <CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>

No, you need to treat this still as binomial data, using cbind(y,n-y) as
the response where y is the number of positives in each group, and n is the
total in each group. I suggest reading one of the books that discusses
fitting logistic models in R, most advanced texts have a
section. Introductory Statistics with R by Peter Dalgaard has the section
available in Amazon.

You also still need a random effect for the cluster.

While I'm thinking of it, should clusters and country random effects have
been crossed. Generally the sampling is setup so that clusters are nested
within countries which requires a different syntax.

On 5 April 2015 at 10:41, Hans Ekbrand <hans.ekbrand at gmail.com> wrote:

> On Sat, Apr 04, 2015 at 07:36:04PM -0400, Ben Bolker wrote:
> > > So, perhaps I could aggregate the individual level data to the
> > > cluster level, and do without the random term for cluster? I mean,
> > > calculate the proportions of yes in each cluster and use that as
> > > the dependent variable.
> > >
> > > This would, I assume, require that each cluster was given a weight
> > > that corresponded to the number of individuals in it - or I would
> > > not be able to say anything about probabilities at the individual
> > > level, right?
> >
> >  I would say pretty much any time you can aggregate without losing
> > information, you should, for ease of computation (this accords with
> > the Murtaugh 2007 "Simplicity and complexity" paper that I cite here
> > on a regular basis).  If all of your covariates are at the cluster
> > level
>
> [ Thanks for your advice, it's much appreciated. ]
>
> The covariates are not all at the cluster level. Actually only one
> covariate is at the cluster level, the others are at the country
> level.
>
> > then this reduces to a binomial GLM (you can account for
> > overdispersion either by using a quasi-binomial model in glm() or by
> > staying with glmer() and keeping the random effect of cluster (now an
> > observation-level random effect).
>
> Since I still have the country level to account for, I need to use glmer().
>
> I have created an aggregated data set with a variable for the
> proportion deprived=TRUE in each cluster, and a variable for the
> number of cases in that cluster (to use as weight).
>
> Perhaps this is not a question specific for mixed models, but what
> family and link function would be appropriate now? This was the best I
> could come up with:
>
> library(car)
> lm1 <- lmer(logit(Prop.deprived.in.cluster) ~ (1|Country) + QoG + GDPLog +
> Rural * KilledPerMillion5Log, data = my.small.df, weights =
> my.small.df$weight)
>
> Linear mixed model fit by REML ['lmerMod']
> Formula: logit(Prop.deprived.in.cluster) ~ (1 | Country) + QoG + GDPLog +
>     Rural * KilledPerMillion5Log
>    Data: my.small.df
> Weights: my.small.df$weight
>
> REML criterion at convergence: 157709.8
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -4.9983 -0.5626 -0.0622  0.4371  6.1171
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Country  (Intercept)   1.768   1.33
>  Residual             139.292  11.80
> Number of obs: 38028, groups:  Country, 65
>
> Fixed effects:
>                               Estimate Std. Error t value
> (Intercept)                    1.25542    1.90567    0.66
> QoG                            0.39120    0.40850    0.96
> GDPLog                        -0.51799    0.23031   -2.25
> Ruralyes                       1.91545    0.02232   85.80
> KilledPerMillion5Log           0.06190    0.28557    0.22
> Ruralyes:KilledPerMillion5Log  0.35303    0.03728    9.47
>
> Correlation of Fixed Effects:
>             (Intr) QoG    GDPLog Rurlys KlPM5L
> QoG          0.571
> GDPLog      -0.989 -0.486
> Ruralyes    -0.013  0.001  0.006
> KlldPrMll5L -0.013  0.239 -0.009  0.045
> Rrlys:KPM5L  0.004 -0.001  0.000 -0.519 -0.084
>
> my.small.df is available here if someone wants to have a go at it
>
> http://hansekbrand.se/code/my.small.df.RData (1.1 MB)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From b.pelzer at maw.ru.nl  Sun Apr  5 11:33:26 2015
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Sun, 05 Apr 2015 11:33:26 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150404181511.GF12461@hans>
References: <20150404092949.GE12461@hans>	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans>
Message-ID: <55210166.3020008@maw.ru.nl>

Dear Hans,

You could try Ben's suggestion for nAGQ = 5 in Stata. I believe that the 
routine"s "xtlogit" and "xtmelogit"  (in Stata 13 they are named 
differently, I don't remember the names right now)  are able do work 
with nested random effects and more than 1 quadr. point. These routines 
are however pretty time-consuming, may be even more so than glmer. Best 
regards,

Ben.



On 4-4-2015 20:15, Hans Ekbrand wrote:
> On Sat, Apr 04, 2015 at 09:10:35PM +1100, Ken Beath wrote:
>> One of the problems is that you have a relatively high random effects
>> variance. A standard deviation of the intercept of 3 is a huge amount, it
>> means that there is massive variation in the random effect value needed to
>> model each cluster, to the point that some clusters will be all zeros and
>> some will be all ones. In this situation the assumption of approximate
>> normality of the likelihood around the nodes which is required for using
>> Laplace's method is very far from met.
> Thanks for your advice, I really appreciate it!
>
> I tried nAGQ=5, but met with:
>
> ## Error: nAGQ > 1 is only available for models with a single, scalar
> random-effects term
>
> As you point out, some clusters will be all zeros (and some will be
> all ones). While my data is on the individual level,
>
> a) the variable I'm mainly interested in, KilledPerMillion5Log, varies
> only at the country level, &
>
> b) I currently have no variables in the model that vary at the
> individual level
>
> So, perhaps I could aggregate the individual level data to the cluster
> level, and do without the random term for cluster? I mean, calculate
> the proportions of yes in each cluster and use that as the dependent
> variable.
>
> This would, I assume, require that each cluster was given a weight
> that corresponded to the number of individuals in it - or I would not
> be able to say anything about probabilities at the individual level,
> right?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From hans.ekbrand at gmail.com  Sun Apr  5 12:12:01 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 5 Apr 2015 12:12:01 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
Message-ID: <20150405101201.GH12461@hans>

On Sun, Apr 05, 2015 at 07:31:25PM +1000, Ken Beath wrote:
> No, you need to treat this still as binomial data, using cbind(y,n-y) as
> the response where y is the number of positives in each group, and n is the
> total in each group.

OK, I'll try that. What is the interpretion of the outcome in this
case, is it still the logit of the probability of the outcome?

> I suggest reading one of the books that discusses
> fitting logistic models in R, most advanced texts have a
> section. Introductory Statistics with R by Peter Dalgaard has the section
> available in Amazon.

I actually already have that one, quite good.

> You also still need a random effect for the cluster.
> 
> While I'm thinking of it, should clusters and country random effects have
> been crossed. Generally the sampling is setup so that clusters are nested
> within countries which requires a different syntax.

I'm sorry but I haven't been clear on this, but the clusters are
nested within countries, so there are no crossed random effects to be
found.


From hans.ekbrand at gmail.com  Sun Apr  5 12:14:20 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 5 Apr 2015 12:14:20 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <55210166.3020008@maw.ru.nl>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55210166.3020008@maw.ru.nl>
Message-ID: <20150405101420.GI12461@hans>

On Sun, Apr 05, 2015 at 11:33:26AM +0200, Ben Pelzer wrote:
> Dear Hans,
> 
> You could try Ben's suggestion for nAGQ = 5 in Stata. I believe that
> the routine"s "xtlogit" and "xtmelogit"  (in Stata 13 they are named
> differently, I don't remember the names right now)  are able do work
> with nested random effects and more than 1 quadr. point. These
> routines are however pretty time-consuming, may be even more so than
> glmer. Best regards,

OK. Even if will handle this case with aggregation, it is good to know
what stata can do for future challenges.


From ken.beath at mq.edu.au  Sun Apr  5 13:14:19 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sun, 5 Apr 2015 21:14:19 +1000
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150405101201.GH12461@hans>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
	<20150405101201.GH12461@hans>
Message-ID: <CAF5_5cwjL_QUrmKbwu7YbtkcaRp_bnUm6eR+5Jj2=UunDFHWBA@mail.gmail.com>

On 5 April 2015 at 20:12, Hans Ekbrand <hans.ekbrand at gmail.com> wrote:

> On Sun, Apr 05, 2015 at 07:31:25PM +1000, Ken Beath wrote:
> > No, you need to treat this still as binomial data, using cbind(y,n-y) as
> > the response where y is the number of positives in each group, and n is
> the
> > total in each group.
>
> OK, I'll try that. What is the interpretion of the outcome in this
> case, is it still the logit of the probability of the outcome?
>
>
Yes.


> > I suggest reading one of the books that discusses
> > fitting logistic models in R, most advanced texts have a
> > section. Introductory Statistics with R by Peter Dalgaard has the section
> > available in Amazon.
>
> I actually already have that one, quite good.
>
> > You also still need a random effect for the cluster.
> >
> > While I'm thinking of it, should clusters and country random effects have
> > been crossed. Generally the sampling is setup so that clusters are nested
> > within countries which requires a different syntax.
>
> I'm sorry but I haven't been clear on this, but the clusters are
> nested within countries, so there are no crossed random effects to be
> found.
>
>
The  random effect then needs to be included as (1|country/clusterID)

-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From hans.ekbrand at gmail.com  Sun Apr  5 13:56:03 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 5 Apr 2015 13:56:03 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <CAF5_5cwjL_QUrmKbwu7YbtkcaRp_bnUm6eR+5Jj2=UunDFHWBA@mail.gmail.com>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
	<20150405101201.GH12461@hans>
	<CAF5_5cwjL_QUrmKbwu7YbtkcaRp_bnUm6eR+5Jj2=UunDFHWBA@mail.gmail.com>
Message-ID: <20150405115603.GJ12461@hans>

> > > While I'm thinking of it, should clusters and country random effects have
> > > been crossed. Generally the sampling is setup so that clusters are nested
> > > within countries which requires a different syntax.
> >
> > I'm sorry but I haven't been clear on this, but the clusters are
> > nested within countries, so there are no crossed random effects to be
> > found.
> >
> >
> The  random effect then needs to be included as (1|country/clusterID)

Well, no, cluster is implictly nested in country, just as sample is
implicitly nested in batch in the Pastes data (see p 39-40 in
http://lme4.r-forge.r-project.org/book/Ch2.pdf)


From hans.ekbrand at gmail.com  Sun Apr  5 13:58:52 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 5 Apr 2015 13:58:52 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150405115603.GJ12461@hans>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
	<20150405101201.GH12461@hans>
	<CAF5_5cwjL_QUrmKbwu7YbtkcaRp_bnUm6eR+5Jj2=UunDFHWBA@mail.gmail.com>
	<20150405115603.GJ12461@hans>
Message-ID: <20150405115851.GK12461@hans>

On Sun, Apr 05, 2015 at 01:56:03PM +0200, Hans Ekbrand wrote:
> > > > While I'm thinking of it, should clusters and country random effects have
> > > > been crossed. Generally the sampling is setup so that clusters are nested
> > > > within countries which requires a different syntax.
> > >
> > > I'm sorry but I haven't been clear on this, but the clusters are
> > > nested within countries, so there are no crossed random effects to be
> > > found.
> > >
> > >
> > The  random effect then needs to be included as (1|country/clusterID)
> 
> Well, no, cluster is implictly nested in country, just as sample is
> implicitly nested in batch in the Pastes data (see p 39-40 in
> http://lme4.r-forge.r-project.org/book/Ch2.pdf)

Sorry if this was unclear, but the ClusterID variable was created in a
similar way that Bates creates the sample variable on page 40 in that
text. [ English is not my native language ]


From ken.beath at mq.edu.au  Sun Apr  5 14:30:21 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sun, 5 Apr 2015 22:30:21 +1000
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150405115851.GK12461@hans>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
	<20150405101201.GH12461@hans>
	<CAF5_5cwjL_QUrmKbwu7YbtkcaRp_bnUm6eR+5Jj2=UunDFHWBA@mail.gmail.com>
	<20150405115603.GJ12461@hans> <20150405115851.GK12461@hans>
Message-ID: <CAF5_5cyGA2VojoNZQmJHugw59ebiS8y0m1mFsv1bu_+RniPYyw@mail.gmail.com>

OK then, the way you were doing it is OK.


On 5 April 2015 at 21:58, Hans Ekbrand <hans.ekbrand at gmail.com> wrote:

> On Sun, Apr 05, 2015 at 01:56:03PM +0200, Hans Ekbrand wrote:
> > > > > While I'm thinking of it, should clusters and country random
> effects have
> > > > > been crossed. Generally the sampling is setup so that clusters are
> nested
> > > > > within countries which requires a different syntax.
> > > >
> > > > I'm sorry but I haven't been clear on this, but the clusters are
> > > > nested within countries, so there are no crossed random effects to be
> > > > found.
> > > >
> > > >
> > > The  random effect then needs to be included as (1|country/clusterID)
> >
> > Well, no, cluster is implictly nested in country, just as sample is
> > implicitly nested in batch in the Pastes data (see p 39-40 in
> > http://lme4.r-forge.r-project.org/book/Ch2.pdf)
>
> Sorry if this was unclear, but the ClusterID variable was created in a
> similar way that Bates creates the sample variable on page 40 in that
> text. [ English is not my native language ]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From hans.ekbrand at gmail.com  Sun Apr  5 15:53:34 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 5 Apr 2015 15:53:34 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
Message-ID: <20150405135329.GL12461@hans>

On Sun, Apr 05, 2015 at 07:31:25PM +1000, Ken Beath wrote:
> You also still need a random effect for the cluster.

I think I've just stumbled into something that may deepen my
understanding of mixed-models, thanks to you.

I took your advice on how to create the dependent variable

cbind(y, n-y)

and included the random term for cluster,

Formula: cbind(Deprived, Not.deprived) ~ (1 | Country) + (1 | ClusterID) + QoG + GDPLog + Rural * KilledPerMillion5Log 
Data: my.small.df

and fitted the model to an aggregated version of the original data
set. However, while so doing I thought: "this will be exactly like the
model that glmer could not fit without warnings, I'll have exactly the
same warnings again".

In a sense it is the same model, the beta-coefficients are exactly the
same, but in another sense it apparently is not, the warnings are gone
:-)

I guess the difference is that glmer does not have to care about
residuals at the individual level anymore.

I now understand this model as a kind of repeated measures model,
where each cluster is measured repeatedly, once for each individual in
the cluster. While that tecnically does not describe how the data was
generated, it is a clever shortcut to get what I need. Thanks again!


From hans.ekbrand at gmail.com  Sun Apr  5 16:10:50 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 5 Apr 2015 16:10:50 +0200
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150405135329.GL12461@hans>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
	<20150405135329.GL12461@hans>
Message-ID: <20150405141050.GM12461@hans>

On Sun, Apr 05, 2015 at 03:53:29PM +0200, Hans Ekbrand wrote:
> In a sense it is the same model, the beta-coefficients are exactly the
> same,

Not exactly the same, tough.

KilledPerMillion5Log          -0.62841    0.69872   -0.90   0.3685    
Ruralyes:KilledPerMillion5Log -0.73146    0.07823   -9.35  < 2e-16 ***

Compared to 

                                     NM     bobyqa      nlmin       BFGS
(Intercept)                   4.9857379  3.7283744  4.9477121  3.2138480
QoG                           0.7866227  0.5962816  0.7534208  0.5991817
GDPLog                       -1.5161825 -1.3643422 -1.5111097 -1.2940261
Ruralyes                      4.3436228  4.3422641  4.3419199  4.3415551
KilledPerMillion5Log          0.6632158  0.6005677  0.6276264  0.5216984
Ruralyes:KilledPerMillion5Log 0.7313136  0.7316543  0.7314746  0.7329137    

But pretty damn close to nlmin, which you specifically prefered :-)


From rforumjacqueline at gmail.com  Sun Apr  5 23:40:52 2015
From: rforumjacqueline at gmail.com (R User)
Date: Sun, 5 Apr 2015 14:40:52 -0700
Subject: [R-sig-ME] Removing p.d. constraint for random effects in lme
Message-ID: <CAE17zCrkzo4Yfdq3Ra=DYsc23RG1_yvJQK92h66Exdfqc3y26w@mail.gmail.com>

Hi,

I am trying to fit a mixed model using lme, with a multivariate response.
I would like to try and replicate a SAS proc mixed model that has a type=un
structure for random effects.  I am not very experienced using lme, but it
seems like one of the differences is that lme constrains the random effect
matrix to be positive definite, whereas SAS does not impose this constraint
(only variances in SAS are constrained to be nonnegative).  Is there a way
to remove this positive definite constraint for random effects from lme and
how would this be specified in the model?  My current model looks something
like this:

lme(value ~ trait -1, data,
    random = ~ trait -1| line,
    correlation =  corSymm( form = ~ 1|line/rep),
    weights = varIdent(form = ~ 1 |trait),
    control=control,
    method="REML")

Thanks,
Jacqueline

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Apr  6 20:39:27 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 06 Apr 2015 14:39:27 -0400
Subject: [R-sig-ME] Removing p.d. constraint for random effects in lme
In-Reply-To: <CAE17zCrkzo4Yfdq3Ra=DYsc23RG1_yvJQK92h66Exdfqc3y26w@mail.gmail.com>
References: <CAE17zCrkzo4Yfdq3Ra=DYsc23RG1_yvJQK92h66Exdfqc3y26w@mail.gmail.com>
Message-ID: <5522D2DF.2000901@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-04-05 05:40 PM, R User wrote:
> Hi,
> 
> I am trying to fit a mixed model using lme, with a multivariate
> response. I would like to try and replicate a SAS proc mixed model
> that has a type=un structure for random effects.  I am not very
> experienced using lme, but it seems like one of the differences is
> that lme constrains the random effect matrix to be positive
> definite, whereas SAS does not impose this constraint (only
> variances in SAS are constrained to be nonnegative).  Is there a
> way to remove this positive definite constraint for random effects
> from lme and how would this be specified in the model?  My current
> model looks something like this:
> 
> lme(value ~ trait -1, data, random = ~ trait -1| line, correlation
> =  corSymm( form = ~ 1|line/rep), weights = varIdent(form = ~ 1
> |trait), control=control, method="REML")
> 
> Thanks, Jacqueline
> 

  This is likely to be difficult.

* Are you looking for positive *semi*definite variance-covariance
matrices (i.e. eigenvalues/variance >=0), or do you need to allow
(silly) negative definite var-cov matrices (eigenvalues/variances
strictly <0)?

* Can you give us more context?  Can you explain what a
non-positive-definite matrix would mean biologically in your example?
Can you show us a SAS example where you actually succeeded in fitting
a non-positive-definite (or negative-definite) variance-covariance matrix?

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVItLfAAoJEOCV5YRblxUHS7oH/1jQDf+0ms4MfVbUkY9dvHdZ
YoOYc4l1xEkkoasscYv6EI1gyA9tdK1Bk1z1btpAzjyqlHJ9Di+oKCIi1Ni8L0Mn
RZSVvF1rXh32/UldaR+Ixe6i0xtaTEmUzR9NABq5HB23xh3zrkfH43ko/R4G3QKS
VE+Fogs+rbIS1zz6CijOfeytRDB3Qs7AabA6abi1/3xAQuzPQtKntNMBuQJ6RlIj
V2sCCSgMgy/2BvggNZqspCeK3g4HfXtatKpDKUO0VUac1zydlIQhS888DrkoA2Ng
0KO8ABGxSkLx/qQ4YXk0n37QiajFP3MYHg/iV7b2nvmTP4EdupPVe0Af31I/OSw=
=D2J7
-----END PGP SIGNATURE-----


From bates at stat.wisc.edu  Mon Apr  6 21:41:45 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 06 Apr 2015 19:41:45 +0000
Subject: [R-sig-ME] Removing p.d. constraint for random effects in lme
In-Reply-To: <5522D2DF.2000901@gmail.com>
References: <CAE17zCrkzo4Yfdq3Ra=DYsc23RG1_yvJQK92h66Exdfqc3y26w@mail.gmail.com>
	<5522D2DF.2000901@gmail.com>
Message-ID: <CAO7JsnTxjzwhx5pJQN6EgSEk2k9+DtsARo1SWD2s8Oz5pT0AGw@mail.gmail.com>

It is possible that a fit using lmer in the lme4 package will end up with a
positive semi-definite covariance matrix for the random effects.  The way
that the nlme package fits the model the fitted covariance matrix cannot
have eigenvalues of zero.  They can be very small but not zero.

A considerable amount of the development of the numerical methods in lmer
was to be able to all the fitted covariance matrices to be semi-definite.

As for allowing an indefinite covariance matrix in the model, a covariance
matrix is, by definition, positive semi-definite and i stand by my
statement in

library(fortunes)
fortune("impediment")

On Mon, Apr 6, 2015 at 1:40 PM Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-04-05 05:40 PM, R User wrote:
> > Hi,
> >
> > I am trying to fit a mixed model using lme, with a multivariate
> > response. I would like to try and replicate a SAS proc mixed model
> > that has a type=un structure for random effects.  I am not very
> > experienced using lme, but it seems like one of the differences is
> > that lme constrains the random effect matrix to be positive
> > definite, whereas SAS does not impose this constraint (only
> > variances in SAS are constrained to be nonnegative).  Is there a
> > way to remove this positive definite constraint for random effects
> > from lme and how would this be specified in the model?  My current
> > model looks something like this:
> >
> > lme(value ~ trait -1, data, random = ~ trait -1| line, correlation
> > =  corSymm( form = ~ 1|line/rep), weights = varIdent(form = ~ 1
> > |trait), control=control, method="REML")
> >
> > Thanks, Jacqueline
> >
>
>   This is likely to be difficult.
>
> * Are you looking for positive *semi*definite variance-covariance
> matrices (i.e. eigenvalues/variance >=0), or do you need to allow
> (silly) negative definite var-cov matrices (eigenvalues/variances
> strictly <0)?
>
> * Can you give us more context?  Can you explain what a
> non-positive-definite matrix would mean biologically in your example?
> Can you show us a SAS example where you actually succeeded in fitting
> a non-positive-definite (or negative-definite) variance-covariance matrix?
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVItLfAAoJEOCV5YRblxUHS7oH/1jQDf+0ms4MfVbUkY9dvHdZ
> YoOYc4l1xEkkoasscYv6EI1gyA9tdK1Bk1z1btpAzjyqlHJ9Di+oKCIi1Ni8L0Mn
> RZSVvF1rXh32/UldaR+Ixe6i0xtaTEmUzR9NABq5HB23xh3zrkfH43ko/R4G3QKS
> VE+Fogs+rbIS1zz6CijOfeytRDB3Qs7AabA6abi1/3xAQuzPQtKntNMBuQJ6RlIj
> V2sCCSgMgy/2BvggNZqspCeK3g4HfXtatKpDKUO0VUac1zydlIQhS888DrkoA2Ng
> 0KO8ABGxSkLx/qQ4YXk0n37QiajFP3MYHg/iV7b2nvmTP4EdupPVe0Af31I/OSw=
> =D2J7
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Mon Apr  6 21:43:54 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 06 Apr 2015 19:43:54 +0000
Subject: [R-sig-ME] Removing p.d. constraint for random effects in lme
In-Reply-To: <CAO7JsnTxjzwhx5pJQN6EgSEk2k9+DtsARo1SWD2s8Oz5pT0AGw@mail.gmail.com>
References: <CAE17zCrkzo4Yfdq3Ra=DYsc23RG1_yvJQK92h66Exdfqc3y26w@mail.gmail.com>
	<5522D2DF.2000901@gmail.com>
	<CAO7JsnTxjzwhx5pJQN6EgSEk2k9+DtsARo1SWD2s8Oz5pT0AGw@mail.gmail.com>
Message-ID: <CAO7JsnSSPhueWghw_rYd6Fnv1Rx1LwowXDifj-dAd5nKbpaL5A@mail.gmail.com>

On Mon, Apr 6, 2015 at 2:41 PM Douglas Bates <bates at stat.wisc.edu> wrote:

> It is possible that a fit using lmer in the lme4 package will end up with
> a positive semi-definite covariance matrix for the random effects.  The way
> that the nlme package fits the model the fitted covariance matrix cannot
> have eigenvalues of zero.  They can be very small but not zero.
>
> A considerable amount of the development of the numerical methods in lmer
> was to be able to all the fitted covariance matrices to be semi-definite.
>

I meant to write "allow the fitted covariance ..."

As for allowing an indefinite covariance matrix in the model, a covariance
> matrix is, by definition, positive semi-definite and i stand by my
> statement in
>
> library(fortunes)
> fortune("impediment")
>

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Tue Apr  7 01:59:03 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Tue, 7 Apr 2015 09:59:03 +1000
Subject: [R-sig-ME] lme4, failure to converge with a range of optimisers,
 trust the fitted model anyway?
In-Reply-To: <20150405135329.GL12461@hans>
References: <20150404092949.GE12461@hans>
	<CAF5_5cyx1pEXxq=MZknFoKu-bgn8OHVombPYxEBm-gVaKYthVA@mail.gmail.com>
	<20150404181511.GF12461@hans> <55207564.1060501@gmail.com>
	<20150405004147.GG12461@hans>
	<CAF5_5czj+BSsUtQcL5bQHnpbW5H2xoaW26abOPsbW9h84RHn7w@mail.gmail.com>
	<20150405135329.GL12461@hans>
Message-ID: <CAF5_5cwPncH8kDT8S8cT9B0YYmWc53d1PHeJXXiMyr7K3tboSg@mail.gmail.com>

Yes, the model and so the likelihood is exactly the same, just that there
is a lot less effort in calculating it for the grouped data. Hopefully this
results in less numerical problems.

On 5 April 2015 at 23:53, Hans Ekbrand <hans.ekbrand at gmail.com> wrote:

> On Sun, Apr 05, 2015 at 07:31:25PM +1000, Ken Beath wrote:
> > You also still need a random effect for the cluster.
>
> I think I've just stumbled into something that may deepen my
> understanding of mixed-models, thanks to you.
>
> I took your advice on how to create the dependent variable
>
> cbind(y, n-y)
>
> and included the random term for cluster,
>
> Formula: cbind(Deprived, Not.deprived) ~ (1 | Country) + (1 | ClusterID) +
> QoG + GDPLog + Rural * KilledPerMillion5Log
> Data: my.small.df
>
> and fitted the model to an aggregated version of the original data
> set. However, while so doing I thought: "this will be exactly like the
> model that glmer could not fit without warnings, I'll have exactly the
> same warnings again".
>
> In a sense it is the same model, the beta-coefficients are exactly the
> same, but in another sense it apparently is not, the warnings are gone
> :-)
>
> I guess the difference is that glmer does not have to care about
> residuals at the individual level anymore.
>
> I now understand this model as a kind of repeated measures model,
> where each cluster is measured repeatedly, once for each individual in
> the cluster. While that tecnically does not describe how the data was
> generated, it is a clever shortcut to get what I need. Thanks again!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From paul.johnson at glasgow.ac.uk  Tue Apr  7 15:14:02 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 7 Apr 2015 13:14:02 +0000
Subject: [R-sig-ME] heritability from longitudinal zero-inflated count
 data
In-Reply-To: <20150403085256.66312p3ypyxevpyc@www.staffmail.ed.ac.uk>
References: <534CC46A-750D-458F-92A9-40DB505A0679@glasgow.ac.uk>
	<20150403082701.23568crwlrmtedhc@www.staffmail.ed.ac.uk>
	<20150403085256.66312p3ypyxevpyc@www.staffmail.ed.ac.uk>
Message-ID: <6AD70C2C-D722-4650-AADB-8D27DC81FD41@glasgow.ac.uk>

Thanks Jarrod & Chuck. I?m not very familiar with SAS and I don?t know what?s possible with NLMIXED, but good to know that it?s possible with MCMCglmm (given a very large data set).
Paul

On 2 Apr 2015, at 18:13, Rose, Charles E. (CDC/OID/NCHHSTP) <cvr7 at cdc.gov> wrote:

Aside from being unsure what is meant by pedigree-derived correlation structure, NLMIXED (SAS) can fit the model allowing for random effects in each component, chuck



> On 3 Apr 2015, at 08:52, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> 
> Not having a good morning!
> 
> random=~us(trait):animal+idh(at.level(trait,1):time):year
> 
> should have read
> 
> random=~us(trait):animal+idh(at.level(trait,1):year):nest
> 
> Jarrod
> 
> 
> 
> 
> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 03 Apr 2015 08:27:01 +0100:
> 
>> Hi,
>> 
>> It is possible, but you will need a lot of data. For example
>> 
>> counts=~trait-1+x:trait,
>> random=~us(trait):animal+idh(at.level(trait,1):time):year
>> 
>> this models separate intercepts for the binary and count parts, and different regressions on x. us(trait):animal estimates the additive genetic variance in both parts, and the additive genetic variance between them.  idh(at.level(trait,1):year):nest  fits different between-nest variances for different years for the count part (trait 1).
>> 
>> 
>> Cheers,
>> 
>> Jarrod
>> 
>> 
>> 
>> Quoting Paul Johnson <paul.johnson at glasgow.ac.uk> on Thu, 2 Apr 2015 17:03:47 +0000:
>> 
>>> Hi all,
>>> 
>>> I'd like to fit a model with the following features:
>>> 
>>> * The data are parasite counts recorded at a number of time points (say 4) for each individual
>>> * Zero-inflation, i.e. a mixture of binary and count data
>>> * Separate fixed effects for the binary and count components
>>> * Separate random effects for both components. One of the random effects will have a pedigree-derived correlation structure (as in an animal model). The random effects will have the same structure for both components, but need to allow different variances.
>>> * The random effect variances are allowed to vary over time.
>>> 
>>> The main aim is to estimate heritabilities for each time point, separately for the binary and count parts of the mixture, because the factors driving the two processes (encountering parasites and resistance to parasites) are expected to be driven by quite different factors, genetic and otherwise.
>>> 
>>> Can this be done outside DIY software such as JAGS? I'd be interested in knowing how close MCMCglmm can get to this model, even if it can't do everything.
>>> 
>>> Thanks for your help,
>>> Paul
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>> 
>> 
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


From chirleu at gmail.com  Tue Apr  7 15:29:04 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Tue, 7 Apr 2015 15:29:04 +0200
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
In-Reply-To: <CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
Message-ID: <CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>

Thanks Ken.
I tried to follow Faraday's book (Extending the linear model with R)
guidelines for parametric bootstraping but simulate() does not allow models
with a correlation structure, which is my case.
Is there any way to circumvent this issue?

David

2015-04-02 0:03 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:

> For parametric bootstrapping what is required is a model for the data, and
> using that you generate the bootstrap samples, there is no resampling
> involved.
>
> For non-parametric bootstrapping with multilevel data, resampling
> individual observations is not sufficient, what is required is to resample
> whole clusters/subjects. This is possible in R by converting teh data to a
> wide format, then in thefitting function taking the samples and expanding
> them back to long and fitting the model. You will also need to create
> unique id for each cluster before converting to long.
>
> I recommend reading something like Manly's book on resampling and
> bootstrapping, although I don't think it talks about multilevel models.
>
>
> On 1 April 2015 at 23:30, David Villegas R?os <chirleu at gmail.com> wrote:
>
>> Dear all,
>> I'm trying to boostrap repeatability estimated from a lme output.
>> The model includes one fixed factor (month), one random factor (ID) and
>> one
>> correlation term to account for temporal autocorrelation of the
>> replicates.
>> I prefer parametric bootstraping since it is the recommended option
>> according to Nakagawa and Schielzeth, 2010 (Biological reviews)
>>
>> These have been my attepmts so far:
>>
>> *Option 1: parametric bootstraping of the full model (what I really need)*
>>
>> bootcoef<-function(data, index){
>>   dat<-data[index,]
>>
>>
>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>>
>>
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> # this is the repeatability estimate
>> }
>> output=boot(depm3,bootcoef,100,sim=parametric)
>>
>> *Error*: output$t yields 100 identical values.
>>
>> *Option 2: non-parametric bootstraping of the full model*
>>
>> bootcoef<-function(data, index){
>>   dat<-data[index,]
>>
>>
>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>>
>>
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> # this is the repeatability estimate
>> }
>> output=boot(depm3,bootcoef,100)
>>
>> *Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate must have
>> unique values within groups for "corAR1" objects
>>
>> *Option 3: parametric bootstraping of the model without the
>> autocorrelation
>> term*
>>
>> bootcoef<-function(data, index){
>>   dat<-data[index,]
>>   mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>>
>>
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> # this is the repeatability estimate
>> }
>> output=boot(depm3,bootcoef,100,sim=parametric)
>>
>> *Erro*r: output$t yields 100 identical values which in addition I don't
>> like because the autocorrelation term is not int he model
>>
>> *Option 4: non-parametric bootstraping of the model without the
>> autocorrelation term*
>>
>> bootcoef<-function(data, index){
>>   dat<-data[index,]
>>   mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>>
>>
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> # this is the repeatability estimate
>> }
>> output=boot(depm3,bootcoef,100)
>>
>> *Result*: I got 100 different values (this is ok), but I really need the
>> autocorrelation term to be in.
>>
>> Is this something that you can comment about without reproducible data?
>> Any
>> suggestion would be greatly appreciated.
>>
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:12}}


From ken.beath at mq.edu.au  Wed Apr  8 00:50:36 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 8 Apr 2015 08:50:36 +1000
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
In-Reply-To: <CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
Message-ID: <CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>

There is a simulate function for lme, look for it under the help. Then you
should be able just to modify the code on page 182 of Faraway.



On 7 April 2015 at 23:29, David Villegas R?os <chirleu at gmail.com> wrote:

> Thanks Ken.
> I tried to follow Faraday's book (Extending the linear model with R)
> guidelines for parametric bootstraping but simulate() does not allow models
> with a correlation structure, which is my case.
> Is there any way to circumvent this issue?
>
> David
>
> 2015-04-02 0:03 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:
>
>> For parametric bootstrapping what is required is a model for the data,
>> and using that you generate the bootstrap samples, there is no resampling
>> involved.
>>
>> For non-parametric bootstrapping with multilevel data, resampling
>> individual observations is not sufficient, what is required is to resample
>> whole clusters/subjects. This is possible in R by converting teh data to a
>> wide format, then in thefitting function taking the samples and expanding
>> them back to long and fitting the model. You will also need to create
>> unique id for each cluster before converting to long.
>>
>> I recommend reading something like Manly's book on resampling and
>> bootstrapping, although I don't think it talks about multilevel models.
>>
>>
>> On 1 April 2015 at 23:30, David Villegas R?os <chirleu at gmail.com> wrote:
>>
>>> Dear all,
>>> I'm trying to boostrap repeatability estimated from a lme output.
>>> The model includes one fixed factor (month), one random factor (ID) and
>>> one
>>> correlation term to account for temporal autocorrelation of the
>>> replicates.
>>> I prefer parametric bootstraping since it is the recommended option
>>> according to Nakagawa and Schielzeth, 2010 (Biological reviews)
>>>
>>> These have been my attepmts so far:
>>>
>>> *Option 1: parametric bootstraping of the full model (what I really
>>> need)*
>>>
>>> bootcoef<-function(data, index){
>>>   dat<-data[index,]
>>>
>>>
>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>>>
>>>
>>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>> # this is the repeatability estimate
>>> }
>>> output=boot(depm3,bootcoef,100,sim=parametric)
>>>
>>> *Error*: output$t yields 100 identical values.
>>>
>>> *Option 2: non-parametric bootstraping of the full model*
>>>
>>> bootcoef<-function(data, index){
>>>   dat<-data[index,]
>>>
>>>
>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>>>
>>>
>>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>> # this is the repeatability estimate
>>> }
>>> output=boot(depm3,bootcoef,100)
>>>
>>> *Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate must have
>>> unique values within groups for "corAR1" objects
>>>
>>> *Option 3: parametric bootstraping of the model without the
>>> autocorrelation
>>> term*
>>>
>>> bootcoef<-function(data, index){
>>>   dat<-data[index,]
>>>   mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>>>
>>>
>>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>> # this is the repeatability estimate
>>> }
>>> output=boot(depm3,bootcoef,100,sim=parametric)
>>>
>>> *Erro*r: output$t yields 100 identical values which in addition I don't
>>> like because the autocorrelation term is not int he model
>>>
>>> *Option 4: non-parametric bootstraping of the model without the
>>> autocorrelation term*
>>>
>>> bootcoef<-function(data, index){
>>>   dat<-data[index,]
>>>   mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>>>
>>>
>>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>> # this is the repeatability estimate
>>> }
>>> output=boot(depm3,bootcoef,100)
>>>
>>> *Result*: I got 100 different values (this is ok), but I really need the
>>> autocorrelation term to be in.
>>>
>>> Is this something that you can comment about without reproducible data?
>>> Any
>>> suggestion would be greatly appreciated.
>>>
>>> David
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may contain
>> confidential information.  If you are not the intended recipient, please
>> delete it and notify the sender.  Views expressed in this message are those
>> of the individual sender, and are not necessarily the views of the Faculty
>> of Science, Department of Statistics or Macquarie University.
>>
>>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Wed Apr  8 02:33:40 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 07 Apr 2015 20:33:40 -0400
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
In-Reply-To: <CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>
Message-ID: <55247764.2070509@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-04-07 06:50 PM, Ken Beath wrote:
> There is a simulate function for lme, look for it under the help.
> Then you should be able just to modify the code on page 182 of
> Faraway.

  But the OP said that simulate() doesn't allow models with a
correlation structure (which doesn't really surprise me).
There's another problem, which is that simulate() for lme models does
*not*
work the same way that it does for most model type (the nlme package
is old enough that it had a simulate() method quite a while before
it was introduced as a more general method); it returns the
log-likelihoods
of null and full models rather than new (parametric-bootstrapped)
response vectors.

This might be hackable (especially to get simulate.lme() to return
vectors rather than log-likelihoods), but the internals of nlme are
not particularly simple & friendly ...

  cheers
    Ben Bolker

Reproducible example:

library("nlme")
fm1Dial <-
    lme(rate ~(pressure + I(pressure^2) + I(pressure^3) +
I(pressure^4))*QB,
        random= ~1|Subject, data= Dialyzer)
simulate(fm1Dial)
fm3Dial <- update(fm1Dial,
                 corr = corAR1(0.771, form = ~ 1 | Subject))
simulate(fm3Dial)
## Error in simulate.lme(fm3Dial) :
##   models with "corStruct" and/or "varFunc" objects not allowed

> 
> 
> 
> On 7 April 2015 at 23:29, David Villegas R?os <chirleu at gmail.com>
> wrote:
> 
>> Thanks Ken. I tried to follow Faraday's book (Extending the
>> linear model with R) guidelines for parametric bootstraping but
>> simulate() does not allow models with a correlation structure,
>> which is my case. Is there any way to circumvent this issue?
>> 
>> David
>> 
>> 2015-04-02 0:03 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:
>> 
>>> For parametric bootstrapping what is required is a model for
>>> the data, and using that you generate the bootstrap samples,
>>> there is no resampling involved.
>>> 
>>> For non-parametric bootstrapping with multilevel data,
>>> resampling individual observations is not sufficient, what is
>>> required is to resample whole clusters/subjects. This is
>>> possible in R by converting teh data to a wide format, then in
>>> thefitting function taking the samples and expanding them back
>>> to long and fitting the model. You will also need to create 
>>> unique id for each cluster before converting to long.
>>> 
>>> I recommend reading something like Manly's book on resampling
>>> and bootstrapping, although I don't think it talks about
>>> multilevel models.
>>> 
>>> 
>>> On 1 April 2015 at 23:30, David Villegas R?os
>>> <chirleu at gmail.com> wrote:
>>> 
>>>> Dear all, I'm trying to boostrap repeatability estimated from
>>>> a lme output. The model includes one fixed factor (month),
>>>> one random factor (ID) and one correlation term to account
>>>> for temporal autocorrelation of the replicates. I prefer
>>>> parametric bootstraping since it is the recommended option 
>>>> according to Nakagawa and Schielzeth, 2010 (Biological
>>>> reviews)
>>>> 
>>>> These have been my attepmts so far:
>>>> 
>>>> *Option 1: parametric bootstraping of the full model (what I
>>>> really need)*
>>>> 
>>>> bootcoef<-function(data, index){ dat<-data[index,]
>>>> 
>>>> 
>>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>>>>
>>>>
>>>>
>>>> 
return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>>> # this is the repeatability estimate } 
>>>> output=boot(depm3,bootcoef,100,sim=parametric)
>>>> 
>>>> *Error*: output$t yields 100 identical values.
>>>> 
>>>> *Option 2: non-parametric bootstraping of the full model*
>>>> 
>>>> bootcoef<-function(data, index){ dat<-data[index,]
>>>> 
>>>> 
>>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>>>>
>>>>
>>>>
>>>> 
return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>>> # this is the repeatability estimate } 
>>>> output=boot(depm3,bootcoef,100)
>>>> 
>>>> *Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate
>>>> must have unique values within groups for "corAR1" objects
>>>> 
>>>> *Option 3: parametric bootstraping of the model without the 
>>>> autocorrelation term*
>>>> 
>>>> bootcoef<-function(data, index){ dat<-data[index,] 
>>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>>>> 
>>>> 
>>>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>>>
>>>> 
# this is the repeatability estimate
>>>> } output=boot(depm3,bootcoef,100,sim=parametric)
>>>> 
>>>> *Erro*r: output$t yields 100 identical values which in
>>>> addition I don't like because the autocorrelation term is not
>>>> int he model
>>>> 
>>>> *Option 4: non-parametric bootstraping of the model without
>>>> the autocorrelation term*
>>>> 
>>>> bootcoef<-function(data, index){ dat<-data[index,] 
>>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>>>> 
>>>> 
>>>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>>>>
>>>> 
# this is the repeatability estimate
>>>> } output=boot(depm3,bootcoef,100)
>>>> 
>>>> *Result*: I got 100 different values (this is ok), but I
>>>> really need the autocorrelation term to be in.
>>>> 
>>>> Is this something that you can comment about without
>>>> reproducible data? Any suggestion would be greatly
>>>> appreciated.
>>>> 
>>>> David
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> 
>>> *Ken Beath* Lecturer Statistics Department MACQUARIE UNIVERSITY
>>> NSW 2109, Australia
>>> 
>>> Phone: +61 (0)2 9850 8516
>>> 
>>> Building E4A, room 526 
>>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>>
>>>
>>> 
CRICOS Provider No 00002J
>>> This message is intended for the addressee named and may
>>> contain confidential information.  If you are not the intended
>>> recipient, please delete it and notify the sender.  Views
>>> expressed in this message are those of the individual sender,
>>> and are not necessarily the views of the Faculty of Science,
>>> Department of Statistics or Macquarie University.
>>> 
>>> 
>> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVJHdkAAoJEOCV5YRblxUHc7UIAMnTzI3edqGmcdKKOJsWqhB+
DlhDK3N+FnEtyncLJZqSfG473IJqp6UpujUDsbKFCnGdiUNHK8mmuCuDFvkFJCX/
XSquyTPZwjCYSmECmvsXep7C18PS/BNj+HuUQSqM7AT82T4Rr2tSJbw7nhhAyncI
xlQpmjCEQSAbmn67aGenhY1ac7B4faieJ8TCkkZ+j4zYEbtP5Ov7ofexGZ1acQYg
9F0H1E6JlVqDyy2iJXcM8AHbB5wU7xLg+fHATPNUE18fp+VTc8PvSBPBvbLIP0QS
EVDbmnzRyLe6zyjMiIgQx7XhayMyLKDCjHBMNfCpzQuWTxliIJTVPuiFLkDQTHo=
=Up8Y
-----END PGP SIGNATURE-----


From ken.beath at mq.edu.au  Wed Apr  8 03:00:58 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 8 Apr 2015 11:00:58 +1000
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
In-Reply-To: <55247764.2070509@gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>
	<55247764.2070509@gmail.com>
Message-ID: <CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>

Misinterpreted that. Anyway, the solution is then from first principles
simulate the required data sets.This may not be difficult, but it is not
something I have done for this type of model.



On 8 April 2015 at 10:33, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-04-07 06:50 PM, Ken Beath wrote:
> > There is a simulate function for lme, look for it under the help.
> > Then you should be able just to modify the code on page 182 of
> > Faraway.
>
>   But the OP said that simulate() doesn't allow models with a
> correlation structure (which doesn't really surprise me).
> There's another problem, which is that simulate() for lme models does
> *not*
> work the same way that it does for most model type (the nlme package
> is old enough that it had a simulate() method quite a while before
> it was introduced as a more general method); it returns the
> log-likelihoods
> of null and full models rather than new (parametric-bootstrapped)
> response vectors.
>
> This might be hackable (especially to get simulate.lme() to return
> vectors rather than log-likelihoods), but the internals of nlme are
> not particularly simple & friendly ...
>
>   cheers
>     Ben Bolker
>
> Reproducible example:
>
> library("nlme")
> fm1Dial <-
>     lme(rate ~(pressure + I(pressure^2) + I(pressure^3) +
> I(pressure^4))*QB,
>         random= ~1|Subject, data= Dialyzer)
> simulate(fm1Dial)
> fm3Dial <- update(fm1Dial,
>                  corr = corAR1(0.771, form = ~ 1 | Subject))
> simulate(fm3Dial)
> ## Error in simulate.lme(fm3Dial) :
> ##   models with "corStruct" and/or "varFunc" objects not allowed
>
> >
> >
> >
> > On 7 April 2015 at 23:29, David Villegas R?os <chirleu at gmail.com>
> > wrote:
> >
> >> Thanks Ken. I tried to follow Faraday's book (Extending the
> >> linear model with R) guidelines for parametric bootstraping but
> >> simulate() does not allow models with a correlation structure,
> >> which is my case. Is there any way to circumvent this issue?
> >>
> >> David
> >>
> >> 2015-04-02 0:03 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:
> >>
> >>> For parametric bootstrapping what is required is a model for
> >>> the data, and using that you generate the bootstrap samples,
> >>> there is no resampling involved.
> >>>
> >>> For non-parametric bootstrapping with multilevel data,
> >>> resampling individual observations is not sufficient, what is
> >>> required is to resample whole clusters/subjects. This is
> >>> possible in R by converting teh data to a wide format, then in
> >>> thefitting function taking the samples and expanding them back
> >>> to long and fitting the model. You will also need to create
> >>> unique id for each cluster before converting to long.
> >>>
> >>> I recommend reading something like Manly's book on resampling
> >>> and bootstrapping, although I don't think it talks about
> >>> multilevel models.
> >>>
> >>>
> >>> On 1 April 2015 at 23:30, David Villegas R?os
> >>> <chirleu at gmail.com> wrote:
> >>>
> >>>> Dear all, I'm trying to boostrap repeatability estimated from
> >>>> a lme output. The model includes one fixed factor (month),
> >>>> one random factor (ID) and one correlation term to account
> >>>> for temporal autocorrelation of the replicates. I prefer
> >>>> parametric bootstraping since it is the recommended option
> >>>> according to Nakagawa and Schielzeth, 2010 (Biological
> >>>> reviews)
> >>>>
> >>>> These have been my attepmts so far:
> >>>>
> >>>> *Option 1: parametric bootstraping of the full model (what I
> >>>> really need)*
> >>>>
> >>>> bootcoef<-function(data, index){ dat<-data[index,]
> >>>>
> >>>>
> >>>>
> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
> >>>>
> >>>>
> >>>>
> >>>>
>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> >>>> # this is the repeatability estimate }
> >>>> output=boot(depm3,bootcoef,100,sim=parametric)
> >>>>
> >>>> *Error*: output$t yields 100 identical values.
> >>>>
> >>>> *Option 2: non-parametric bootstraping of the full model*
> >>>>
> >>>> bootcoef<-function(data, index){ dat<-data[index,]
> >>>>
> >>>>
> >>>>
> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
> >>>>
> >>>>
> >>>>
> >>>>
>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> >>>> # this is the repeatability estimate }
> >>>> output=boot(depm3,bootcoef,100)
> >>>>
> >>>> *Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate
> >>>> must have unique values within groups for "corAR1" objects
> >>>>
> >>>> *Option 3: parametric bootstraping of the model without the
> >>>> autocorrelation term*
> >>>>
> >>>> bootcoef<-function(data, index){ dat<-data[index,]
> >>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
> >>>>
> >>>>
> >>>>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> >>>>
> >>>>
> # this is the repeatability estimate
> >>>> } output=boot(depm3,bootcoef,100,sim=parametric)
> >>>>
> >>>> *Erro*r: output$t yields 100 identical values which in
> >>>> addition I don't like because the autocorrelation term is not
> >>>> int he model
> >>>>
> >>>> *Option 4: non-parametric bootstraping of the model without
> >>>> the autocorrelation term*
> >>>>
> >>>> bootcoef<-function(data, index){ dat<-data[index,]
> >>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
> >>>>
> >>>>
> >>>>
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> >>>>
> >>>>
> # this is the repeatability estimate
> >>>> } output=boot(depm3,bootcoef,100)
> >>>>
> >>>> *Result*: I got 100 different values (this is ok), but I
> >>>> really need the autocorrelation term to be in.
> >>>>
> >>>> Is this something that you can comment about without
> >>>> reproducible data? Any suggestion would be greatly
> >>>> appreciated.
> >>>>
> >>>> David
> >>>>
> >>>> [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>
> >>>
> >>> --
> >>>
> >>> *Ken Beath* Lecturer Statistics Department MACQUARIE UNIVERSITY
> >>> NSW 2109, Australia
> >>>
> >>> Phone: +61 (0)2 9850 8516
> >>>
> >>> Building E4A, room 526
> >>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
> >>>
> >>>
> >>>
> CRICOS Provider No 00002J
> >>> This message is intended for the addressee named and may
> >>> contain confidential information.  If you are not the intended
> >>> recipient, please delete it and notify the sender.  Views
> >>> expressed in this message are those of the individual sender,
> >>> and are not necessarily the views of the Faculty of Science,
> >>> Department of Statistics or Macquarie University.
> >>>
> >>>
> >>
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVJHdkAAoJEOCV5YRblxUHc7UIAMnTzI3edqGmcdKKOJsWqhB+
> DlhDK3N+FnEtyncLJZqSfG473IJqp6UpujUDsbKFCnGdiUNHK8mmuCuDFvkFJCX/
> XSquyTPZwjCYSmECmvsXep7C18PS/BNj+HuUQSqM7AT82T4Rr2tSJbw7nhhAyncI
> xlQpmjCEQSAbmn67aGenhY1ac7B4faieJ8TCkkZ+j4zYEbtP5Ov7ofexGZ1acQYg
> 9F0H1E6JlVqDyy2iJXcM8AHbB5wU7xLg+fHATPNUE18fp+VTc8PvSBPBvbLIP0QS
> EVDbmnzRyLe6zyjMiIgQx7XhayMyLKDCjHBMNfCpzQuWTxliIJTVPuiFLkDQTHo=
> =Up8Y
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From roslyn.dakin at gmail.com  Wed Apr  8 05:25:24 2015
From: roslyn.dakin at gmail.com (Roslyn Dakin)
Date: Tue, 7 Apr 2015 20:25:24 -0700
Subject: [R-sig-ME] bootstraping a mixed-model (lme)
Message-ID: <CAJBOW-uU4J_hhYxYcqUkVtJgKQJBUxrFZaE=xr-mPZdq2EX9jA@mail.gmail.com>

This question is in response to Ken's point about bootstrapping mixed
models (that you have to resample whole clusters/subjects for the
nonparametric bootstrap). Why can't you nonparametric bootstrap a mixed
model by stratified bootstrapping? i.e., resampling within each level of
the random effect, assuming you have a decent number of observations for
each level

Many thanks,
Roz

-- 

Roslyn Dakin, PhD
Department of Zoology
University of British Columbia

	[[alternative HTML version deleted]]


From David.Duffy at qimr.edu.au  Wed Apr  8 05:40:58 2015
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 8 Apr 2015 13:40:58 +1000
Subject: [R-sig-ME] bootstrapping a mixed-model (lme)
In-Reply-To: <CAJBOW-uU4J_hhYxYcqUkVtJgKQJBUxrFZaE=xr-mPZdq2EX9jA@mail.gmail.com>
References: <CAJBOW-uU4J_hhYxYcqUkVtJgKQJBUxrFZaE=xr-mPZdq2EX9jA@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1504081336290.6246@orpheus.qimr.edu.au>

On Wed, 8 Apr 2015, Roslyn Dakin wrote:

> This question is in response to Ken's point about bootstrapping mixed
> models (that you have to resample whole clusters/subjects for the
> nonparametric bootstrap).

I've played a bit with the delete-d jackknife (the book by Shao and Tu is 
good). You just delete a randomly selected subset of observations to 
generate each pseudosample - that way the underlying correlation 
structure/clustering is retained.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From ken.beath at mq.edu.au  Wed Apr  8 06:33:18 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 8 Apr 2015 14:33:18 +1000
Subject: [R-sig-ME] bootstraping a mixed-model (lme)
In-Reply-To: <CAJBOW-uU4J_hhYxYcqUkVtJgKQJBUxrFZaE=xr-mPZdq2EX9jA@mail.gmail.com>
References: <CAJBOW-uU4J_hhYxYcqUkVtJgKQJBUxrFZaE=xr-mPZdq2EX9jA@mail.gmail.com>
Message-ID: <CAF5_5cwy0m0iwMmB5LwNPnfyiijK71Map7MLA8=m=XOYV3C98A@mail.gmail.com>

The sampling of complete clusters works better, at least for normal data.
See Davison and Hinkley "Bootstrap Methods and their Application" section
3.8. If the clusters are large then there will be no difference if sampling
within clusters is performed as well, but there doesn't seem to be any
point.

On 8 April 2015 at 13:25, Roslyn Dakin <roslyn.dakin at gmail.com> wrote:

> This question is in response to Ken's point about bootstrapping mixed
> models (that you have to resample whole clusters/subjects for the
> nonparametric bootstrap). Why can't you nonparametric bootstrap a mixed
> model by stratified bootstrapping? i.e., resampling within each level of
> the random effect, assuming you have a decent number of observations for
> each level
>
> Many thanks,
> Roz
>
> --
>
> Roslyn Dakin, PhD
> Department of Zoology
> University of British Columbia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From chirleu at gmail.com  Wed Apr  8 08:55:11 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Wed, 8 Apr 2015 08:55:11 +0200
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
In-Reply-To: <CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>
	<55247764.2070509@gmail.com>
	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>
Message-ID: <CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>

Hi Ken and Ben.
Unfortunately this seems to be beyond my statistical/coding skills.
Maybe the solution is to look for alternatives to get a CI for the
repeatability for my model, like likelihood profiling as suggested by the
original paper of Nakagawa and Schielzeth, 2010. Does it sound good? Any
better alternative?
I will give it a try...

Thanks for your comments.

David



2015-04-08 3:00 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:

> Misinterpreted that. Anyway, the solution is then from first principles
> simulate the required data sets.This may not be difficult, but it is not
> something I have done for this type of model.
>
>
>
> On 8 April 2015 at 10:33, Ben Bolker <bbolker at gmail.com> wrote:
>
> > -----BEGIN PGP SIGNED MESSAGE-----
> > Hash: SHA1
> >
> > On 15-04-07 06:50 PM, Ken Beath wrote:
> > > There is a simulate function for lme, look for it under the help.
> > > Then you should be able just to modify the code on page 182 of
> > > Faraway.
> >
> >   But the OP said that simulate() doesn't allow models with a
> > correlation structure (which doesn't really surprise me).
> > There's another problem, which is that simulate() for lme models does
> > *not*
> > work the same way that it does for most model type (the nlme package
> > is old enough that it had a simulate() method quite a while before
> > it was introduced as a more general method); it returns the
> > log-likelihoods
> > of null and full models rather than new (parametric-bootstrapped)
> > response vectors.
> >
> > This might be hackable (especially to get simulate.lme() to return
> > vectors rather than log-likelihoods), but the internals of nlme are
> > not particularly simple & friendly ...
> >
> >   cheers
> >     Ben Bolker
> >
> > Reproducible example:
> >
> > library("nlme")
> > fm1Dial <-
> >     lme(rate ~(pressure + I(pressure^2) + I(pressure^3) +
> > I(pressure^4))*QB,
> >         random= ~1|Subject, data= Dialyzer)
> > simulate(fm1Dial)
> > fm3Dial <- update(fm1Dial,
> >                  corr = corAR1(0.771, form = ~ 1 | Subject))
> > simulate(fm3Dial)
> > ## Error in simulate.lme(fm3Dial) :
> > ##   models with "corStruct" and/or "varFunc" objects not allowed
> >
> > >
> > >
> > >
> > > On 7 April 2015 at 23:29, David Villegas R?os <chirleu at gmail.com>
> > > wrote:
> > >
> > >> Thanks Ken. I tried to follow Faraday's book (Extending the
> > >> linear model with R) guidelines for parametric bootstraping but
> > >> simulate() does not allow models with a correlation structure,
> > >> which is my case. Is there any way to circumvent this issue?
> > >>
> > >> David
> > >>
> > >> 2015-04-02 0:03 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:
> > >>
> > >>> For parametric bootstrapping what is required is a model for
> > >>> the data, and using that you generate the bootstrap samples,
> > >>> there is no resampling involved.
> > >>>
> > >>> For non-parametric bootstrapping with multilevel data,
> > >>> resampling individual observations is not sufficient, what is
> > >>> required is to resample whole clusters/subjects. This is
> > >>> possible in R by converting teh data to a wide format, then in
> > >>> thefitting function taking the samples and expanding them back
> > >>> to long and fitting the model. You will also need to create
> > >>> unique id for each cluster before converting to long.
> > >>>
> > >>> I recommend reading something like Manly's book on resampling
> > >>> and bootstrapping, although I don't think it talks about
> > >>> multilevel models.
> > >>>
> > >>>
> > >>> On 1 April 2015 at 23:30, David Villegas R?os
> > >>> <chirleu at gmail.com> wrote:
> > >>>
> > >>>> Dear all, I'm trying to boostrap repeatability estimated from
> > >>>> a lme output. The model includes one fixed factor (month),
> > >>>> one random factor (ID) and one correlation term to account
> > >>>> for temporal autocorrelation of the replicates. I prefer
> > >>>> parametric bootstraping since it is the recommended option
> > >>>> according to Nakagawa and Schielzeth, 2010 (Biological
> > >>>> reviews)
> > >>>>
> > >>>> These have been my attepmts so far:
> > >>>>
> > >>>> *Option 1: parametric bootstraping of the full model (what I
> > >>>> really need)*
> > >>>>
> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
> > >>>>
> > >>>>
> > >>>>
> >
> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
> > >>>>
> > >>>>
> > >>>>
> > >>>>
> >
> >
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> > >>>> # this is the repeatability estimate }
> > >>>> output=boot(depm3,bootcoef,100,sim=parametric)
> > >>>>
> > >>>> *Error*: output$t yields 100 identical values.
> > >>>>
> > >>>> *Option 2: non-parametric bootstraping of the full model*
> > >>>>
> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
> > >>>>
> > >>>>
> > >>>>
> >
> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
> > >>>>
> > >>>>
> > >>>>
> > >>>>
> >
> >
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> > >>>> # this is the repeatability estimate }
> > >>>> output=boot(depm3,bootcoef,100)
> > >>>>
> > >>>> *Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate
> > >>>> must have unique values within groups for "corAR1" objects
> > >>>>
> > >>>> *Option 3: parametric bootstraping of the model without the
> > >>>> autocorrelation term*
> > >>>>
> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
> > >>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
> > >>>>
> > >>>>
> > >>>>
> >
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> > >>>>
> > >>>>
> > # this is the repeatability estimate
> > >>>> } output=boot(depm3,bootcoef,100,sim=parametric)
> > >>>>
> > >>>> *Erro*r: output$t yields 100 identical values which in
> > >>>> addition I don't like because the autocorrelation term is not
> > >>>> int he model
> > >>>>
> > >>>> *Option 4: non-parametric bootstraping of the model without
> > >>>> the autocorrelation term*
> > >>>>
> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
> > >>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
> > >>>>
> > >>>>
> > >>>>
> >
> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
> > >>>>
> > >>>>
> > # this is the repeatability estimate
> > >>>> } output=boot(depm3,bootcoef,100)
> > >>>>
> > >>>> *Result*: I got 100 different values (this is ok), but I
> > >>>> really need the autocorrelation term to be in.
> > >>>>
> > >>>> Is this something that you can comment about without
> > >>>> reproducible data? Any suggestion would be greatly
> > >>>> appreciated.
> > >>>>
> > >>>> David
> > >>>>
> > >>>> [[alternative HTML version deleted]]
> > >>>>
> > >>>> _______________________________________________
> > >>>> R-sig-mixed-models at r-project.org mailing list
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>>>
> > >>>
> > >>>
> > >>>
> > >>> --
> > >>>
> > >>> *Ken Beath* Lecturer Statistics Department MACQUARIE UNIVERSITY
> > >>> NSW 2109, Australia
> > >>>
> > >>> Phone: +61 (0)2 9850 8516
> > >>>
> > >>> Building E4A, room 526
> > >>>
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
> > >>>
> > >>>
> > >>>
> > CRICOS Provider No 00002J
> > >>> This message is intended for the addressee named and may
> > >>> contain confidential information.  If you are not the intended
> > >>> recipient, please delete it and notify the sender.  Views
> > >>> expressed in this message are those of the individual sender,
> > >>> and are not necessarily the views of the Faculty of Science,
> > >>> Department of Statistics or Macquarie University.
> > >>>
> > >>>
> > >>
> > >
> > >
> >
> > -----BEGIN PGP SIGNATURE-----
> > Version: GnuPG v1.4.11 (GNU/Linux)
> >
> > iQEcBAEBAgAGBQJVJHdkAAoJEOCV5YRblxUHc7UIAMnTzI3edqGmcdKKOJsWqhB+
> > DlhDK3N+FnEtyncLJZqSfG473IJqp6UpujUDsbKFCnGdiUNHK8mmuCuDFvkFJCX/
> > XSquyTPZwjCYSmECmvsXep7C18PS/BNj+HuUQSqM7AT82T4Rr2tSJbw7nhhAyncI
> > xlQpmjCEQSAbmn67aGenhY1ac7B4faieJ8TCkkZ+j4zYEbtP5Ov7ofexGZ1acQYg
> > 9F0H1E6JlVqDyy2iJXcM8AHbB5wU7xLg+fHATPNUE18fp+VTc8PvSBPBvbLIP0QS
> > EVDbmnzRyLe6zyjMiIgQx7XhayMyLKDCjHBMNfCpzQuWTxliIJTVPuiFLkDQTHo=
> > =Up8Y
> > -----END PGP SIGNATURE-----
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:10}}


From highstat at highstat.com  Thu Apr  9 08:21:01 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 09 Apr 2015 07:21:01 +0100
Subject: [R-sig-ME] Statistics course: Darwin, Australia
Message-ID: <55261A4D.6050807@highstat.com>

Apologies for cross-posting


There are 8 remaining seats on the following course:

Course: Data exploration, regression, GLM & GAM with introduction to R
When: 3-7 August 2015
Where: Darwin, Australia
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_08Darwin_regression_GLM_GAM.pdf
URL: http://www.highstat.com/statscourse.htm




Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From ken.beath at mq.edu.au  Thu Apr  9 12:01:32 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 9 Apr 2015 20:01:32 +1000
Subject: [R-sig-ME] problem bootstraping a mixed-model (lme)
In-Reply-To: <CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>
	<55247764.2070509@gmail.com>
	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>
	<CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>
Message-ID: <CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>

Profile likelihood isn't available with lme, only with lmer. Non-parametric
bootstrap should be possible. Here is some code for it, including 2 where
the model is misspecified. I think the code should work with unequal
numbers per subject but that would need to be checked, and the code should
be checked anyway. It will cope with errors, but replacing the results with
NA is not the best but only option I can think of.


library(nlme)
library(lme4)
library(boot)

fm.lme <- lme(Reaction ~ Days, data=sleepstudy, random=~1 | Subject)

summary(fm.lme)

sleepstudy.wide <-
reshape(sleepstudy,v.names="Reaction",idvar="Subject",timevar="Days",direction="wide")

oneboot <- function(d,i) {
    d <- d[i,]
    # create new Subject id so each is unique
    d$Subject <- 1:dim(d)[1]
    d <- reshape(d,direction="long")
    thecoef <- tryCatch({bootfm.lme <- lme(Reaction ~ Days, data=d,
random=~1 | Subject)
             fixef(bootfm.lme)},
      error = function(e) {print(e)
             return(rep(NA,length(fixef(fm.lme))))})
#    browser()
    return(thecoef)
}

sleep.boot <- boot(sleepstudy.wide, oneboot, R = 999)

# the standard errors will change as the model is misspecified as it is
missing
# the random effect for Days which gave some problems with lme and
bootstrapping
# due to lack of convergence in some samples
print(sleep.boot)
boot.ci(sleep.boot,index=2,type=c("norm","perc"))

fm2.lme <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)

summary(fm2.lme)

Orthodont.wide <-
reshape(Orthodont,v.names=c("distance","Sex"),idvar="Subject",timevar="age",direction="wide")

oneboot2 <- function(d,i) {
  d <- d[i,]
  # create new Subject id so each is unique
  d$Subject <- 1:dim(d)[1]
  d <- reshape(d,direction="long")
  thecoef <- tryCatch({bootfm2.lme <- lme(distance ~ age + Sex, data = d,
random = ~ 1|Subject)
                       fixef(bootfm2.lme)},
                      error = function(e) {print(e)
                      return(rep(NA,length(fixef(fm2.lme))))})
  #    browser()
  return(thecoef)
}

Orthodont.boot <- boot(Orthodont.wide, oneboot2, R = 999)

print(Orthodont.boot)
boot.ci(Orthodont.boot,index=2,type=c("norm","perc"))
boot.ci(Orthodont.boot,index=3,type=c("norm","perc"))

# fit as incorrect linear model
# then bootstrap to obtain correct standard errors
# if used for nonlinear models the coefficients will change as model will
# be population averaged
fm3.lm <- lm(distance ~ age + Sex, data = Orthodont)

summary(fm3.lm)

oneboot4 <- function(d,i) {
  d <- d[i,]
  # create new Subject id so each is unique
  d$Subject <- 1:dim(d)[1]
  d <- reshape(d,direction="long")
  thecoef <- tryCatch({bootfm3.lm <- lm(distance ~ age + Sex, data = d)
                       coef(bootfm3.lm)},
                      error = function(e) {print(e)
                       return(rep(NA,length(coef(fm3.lm))))})
  #    browser()
  return(thecoef)
}

Orthodont.boot3 <- boot(Orthodont.wide, oneboot4, R = 999)

print(Orthodont.boot3)
boot.ci(Orthodont.boot3,index=2,type=c("norm","perc"))
boot.ci(Orthodont.boot3,index=3,type=c("norm","perc"))


On 8 April 2015 at 16:55, David Villegas R?os <chirleu at gmail.com> wrote:

> Hi Ken and Ben.
> Unfortunately this seems to be beyond my statistical/coding skills.
> Maybe the solution is to look for alternatives to get a CI for the
> repeatability for my model, like likelihood profiling as suggested by the
> original paper of Nakagawa and Schielzeth, 2010. Does it sound good? Any
> better alternative?
> I will give it a try...
>
> Thanks for your comments.
>
> David
>
>
>
> 2015-04-08 3:00 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:
>
>> Misinterpreted that. Anyway, the solution is then from first principles
>> simulate the required data sets.This may not be difficult, but it is not
>> something I have done for this type of model.
>>
>>
>>
>> On 8 April 2015 at 10:33, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> > -----BEGIN PGP SIGNED MESSAGE-----
>> > Hash: SHA1
>> >
>> > On 15-04-07 06:50 PM, Ken Beath wrote:
>> > > There is a simulate function for lme, look for it under the help.
>> > > Then you should be able just to modify the code on page 182 of
>> > > Faraway.
>> >
>> >   But the OP said that simulate() doesn't allow models with a
>> > correlation structure (which doesn't really surprise me).
>> > There's another problem, which is that simulate() for lme models does
>> > *not*
>> > work the same way that it does for most model type (the nlme package
>> > is old enough that it had a simulate() method quite a while before
>> > it was introduced as a more general method); it returns the
>> > log-likelihoods
>> > of null and full models rather than new (parametric-bootstrapped)
>> > response vectors.
>> >
>> > This might be hackable (especially to get simulate.lme() to return
>> > vectors rather than log-likelihoods), but the internals of nlme are
>> > not particularly simple & friendly ...
>> >
>> >   cheers
>> >     Ben Bolker
>> >
>> > Reproducible example:
>> >
>> > library("nlme")
>> > fm1Dial <-
>> >     lme(rate ~(pressure + I(pressure^2) + I(pressure^3) +
>> > I(pressure^4))*QB,
>> >         random= ~1|Subject, data= Dialyzer)
>> > simulate(fm1Dial)
>> > fm3Dial <- update(fm1Dial,
>> >                  corr = corAR1(0.771, form = ~ 1 | Subject))
>> > simulate(fm3Dial)
>> > ## Error in simulate.lme(fm3Dial) :
>> > ##   models with "corStruct" and/or "varFunc" objects not allowed
>> >
>> > >
>> > >
>> > >
>> > > On 7 April 2015 at 23:29, David Villegas R?os <chirleu at gmail.com>
>> > > wrote:
>> > >
>> > >> Thanks Ken. I tried to follow Faraday's book (Extending the
>> > >> linear model with R) guidelines for parametric bootstraping but
>> > >> simulate() does not allow models with a correlation structure,
>> > >> which is my case. Is there any way to circumvent this issue?
>> > >>
>> > >> David
>> > >>
>> > >> 2015-04-02 0:03 GMT+02:00 Ken Beath <ken.beath at mq.edu.au>:
>> > >>
>> > >>> For parametric bootstrapping what is required is a model for
>> > >>> the data, and using that you generate the bootstrap samples,
>> > >>> there is no resampling involved.
>> > >>>
>> > >>> For non-parametric bootstrapping with multilevel data,
>> > >>> resampling individual observations is not sufficient, what is
>> > >>> required is to resample whole clusters/subjects. This is
>> > >>> possible in R by converting teh data to a wide format, then in
>> > >>> thefitting function taking the samples and expanding them back
>> > >>> to long and fitting the model. You will also need to create
>> > >>> unique id for each cluster before converting to long.
>> > >>>
>> > >>> I recommend reading something like Manly's book on resampling
>> > >>> and bootstrapping, although I don't think it talks about
>> > >>> multilevel models.
>> > >>>
>> > >>>
>> > >>> On 1 April 2015 at 23:30, David Villegas R?os
>> > >>> <chirleu at gmail.com> wrote:
>> > >>>
>> > >>>> Dear all, I'm trying to boostrap repeatability estimated from
>> > >>>> a lme output. The model includes one fixed factor (month),
>> > >>>> one random factor (ID) and one correlation term to account
>> > >>>> for temporal autocorrelation of the replicates. I prefer
>> > >>>> parametric bootstraping since it is the recommended option
>> > >>>> according to Nakagawa and Schielzeth, 2010 (Biological
>> > >>>> reviews)
>> > >>>>
>> > >>>> These have been my attepmts so far:
>> > >>>>
>> > >>>> *Option 1: parametric bootstraping of the full model (what I
>> > >>>> really need)*
>> > >>>>
>> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
>> > >>>>
>> > >>>>
>> > >>>>
>> >
>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>> > >>>>
>> > >>>>
>> > >>>>
>> > >>>>
>> >
>> >
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> > >>>> # this is the repeatability estimate }
>> > >>>> output=boot(depm3,bootcoef,100,sim=parametric)
>> > >>>>
>> > >>>> *Error*: output$t yields 100 identical values.
>> > >>>>
>> > >>>> *Option 2: non-parametric bootstraping of the full model*
>> > >>>>
>> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
>> > >>>>
>> > >>>>
>> > >>>>
>> >
>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat,correlation=corAR1(form=~month))
>> > >>>>
>> > >>>>
>> > >>>>
>> > >>>>
>> >
>> >
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> > >>>> # this is the repeatability estimate }
>> > >>>> output=boot(depm3,bootcoef,100)
>> > >>>>
>> > >>>> *Error*: Error in Initialize.corAR1(X[[2L]], ...) : covariate
>> > >>>> must have unique values within groups for "corAR1" objects
>> > >>>>
>> > >>>> *Option 3: parametric bootstraping of the model without the
>> > >>>> autocorrelation term*
>> > >>>>
>> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
>> > >>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>> > >>>>
>> > >>>>
>> > >>>>
>> >
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> > >>>>
>> > >>>>
>> > # this is the repeatability estimate
>> > >>>> } output=boot(depm3,bootcoef,100,sim=parametric)
>> > >>>>
>> > >>>> *Erro*r: output$t yields 100 identical values which in
>> > >>>> addition I don't like because the autocorrelation term is not
>> > >>>> int he model
>> > >>>>
>> > >>>> *Option 4: non-parametric bootstraping of the model without
>> > >>>> the autocorrelation term*
>> > >>>>
>> > >>>> bootcoef<-function(data, index){ dat<-data[index,]
>> > >>>> mod<-lme(dvm~factor(month),random=~1|ID,data=dat)
>> > >>>>
>> > >>>>
>> > >>>>
>> >
>> return(as.numeric(VarCorr(mod))[1]/(as.numeric(VarCorr(mod))[1]+as.numeric(VarCorr(mod))[2]))
>> > >>>>
>> > >>>>
>> > # this is the repeatability estimate
>> > >>>> } output=boot(depm3,bootcoef,100)
>> > >>>>
>> > >>>> *Result*: I got 100 different values (this is ok), but I
>> > >>>> really need the autocorrelation term to be in.
>> > >>>>
>> > >>>> Is this something that you can comment about without
>> > >>>> reproducible data? Any suggestion would be greatly
>> > >>>> appreciated.
>> > >>>>
>> > >>>> David
>> > >>>>
>> > >>>> [[alternative HTML version deleted]]
>> > >>>>
>> > >>>> _______________________________________________
>> > >>>> R-sig-mixed-models at r-project.org mailing list
>> > >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>>>
>> > >>>
>> > >>>
>> > >>>
>> > >>> --
>> > >>>
>> > >>> *Ken Beath* Lecturer Statistics Department MACQUARIE UNIVERSITY
>> > >>> NSW 2109, Australia
>> > >>>
>> > >>> Phone: +61 (0)2 9850 8516
>> > >>>
>> > >>> Building E4A, room 526
>> > >>>
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>> > >>>
>> > >>>
>> > >>>
>> > CRICOS Provider No 00002J
>> > >>> This message is intended for the addressee named and may
>> > >>> contain confidential information.  If you are not the intended
>> > >>> recipient, please delete it and notify the sender.  Views
>> > >>> expressed in this message are those of the individual sender,
>> > >>> and are not necessarily the views of the Faculty of Science,
>> > >>> Department of Statistics or Macquarie University.
>> > >>>
>> > >>>
>> > >>
>> > >
>> > >
>> >
>> > -----BEGIN PGP SIGNATURE-----
>> > Version: GnuPG v1.4.11 (GNU/Linux)
>> >
>> > iQEcBAEBAgAGBQJVJHdkAAoJEOCV5YRblxUHc7UIAMnTzI3edqGmcdKKOJsWqhB+
>> > DlhDK3N+FnEtyncLJZqSfG473IJqp6UpujUDsbKFCnGdiUNHK8mmuCuDFvkFJCX/
>> > XSquyTPZwjCYSmECmvsXep7C18PS/BNj+HuUQSqM7AT82T4Rr2tSJbw7nhhAyncI
>> > xlQpmjCEQSAbmn67aGenhY1ac7B4faieJ8TCkkZ+j4zYEbtP5Ov7ofexGZ1acQYg
>> > 9F0H1E6JlVqDyy2iJXcM8AHbB5wU7xLg+fHATPNUE18fp+VTc8PvSBPBvbLIP0QS
>> > EVDbmnzRyLe6zyjMiIgQx7XhayMyLKDCjHBMNfCpzQuWTxliIJTVPuiFLkDQTHo=
>> > =Up8Y
>> > -----END PGP SIGNATURE-----
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may...{{dropped:9}}
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From dfulop.ucd at gmail.com  Fri Apr 10 03:32:11 2015
From: dfulop.ucd at gmail.com (Daniel Fulop)
Date: Thu, 09 Apr 2015 18:32:11 -0700
Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
Message-ID: <5527281B.3080607@gmail.com>

Hi mixed modelers,

I would like to contrast average slopes using predictions from an LMM 
model fit with MCMCglmm.  In essence I want to do something analogous to 
lsmeans' lstrends() function.  The predicted slopes are growth rates 
...more below.

I have 12 days of plant growth data for 10 closely related species at 2 
temperatures.  There are several individuals per species at each 
temperature, and they're fully randomized.  I want to asses whether each 
species' growth rate differs between temperatures.  What I mean by that 
is that I would like to contrast the average slopes for each species in 
control vs. cold temperature; these slopes are the growth rates.

I am modeling the data in MCMCglmm so I can account for phylogeny and 
also to be able to try multi-response models (to jointly model the stem, 
plastochrons, root, etc).  I am starting out with the stem length data 
and after trying different time dependencies settled on this 3rd degree 
polynomial model:

stemLen ~ poly(day, 3, raw=TRUE) * treatment * species + (1 + day | indiv)

where day is a numeric time variable, treatment a 2 level factor 
(control and cold), and species a 10 level factor.

I have a slight idea of how I would go about contrasting the average 
slopes for each species and that I would use the predict.MCMCglmm() 
function, but I would really appreciate some guidance before I go down 
the wrong the wrong path.

Thanks for your help!
Dan.

-- 
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616


From b.pelzer at maw.ru.nl  Fri Apr 10 12:54:41 2015
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Fri, 10 Apr 2015 12:54:41 +0200
Subject: [R-sig-ME] calculation max|grad value?
In-Reply-To: <CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>	<55247764.2070509@gmail.com>	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>	<CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>
	<CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>
Message-ID: <5527ABF1.4040707@maw.ru.nl>

Dear list,

For a given model in glmer (lme4_1.1-7), I got the warning message:

3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

   Model failed to converge with max|grad| = 0.0601483 (tol = 0.001, 
component 17)

My model has 15 fixed effects and two (uncorrelated) random effects.

There has been a lot of correspondence about convergence issues in the 
recent lme4 version(s) lately, but I cannot easily find what measure the
"max|grad" is exactly pointing to.  If I'm right, it is the "relative 
gradient" of one of the model parameters, apparantly parameter 17. But 
how exactly is this max|grad calculated? I found a command (coming from 
Ben Bolker):

gg <- model7 at optinfo$derivs$grad

which produces gradients that are much larger than 0.0601483, probably 
since they are "absolute" gradients.

In the book of Schnabel et al. I found a definition of the relative 
gradient in their equation (7.2.3):

         Delta(f) * x  / f

which I believe must be now interpreted as

         gradient * parameters estimate by glmer /  loglikelihood


Is this indeed the formula that is used in lme4 to derive the max|grad 
and is my interpretation of it correct?
(I would like to reproduce the max|grad value 0.0601483).

And which of the parameters in my model is actually "component 17" 
(which the warning message refers to)?

Thanks for any help!

Ben Pelzer.


*--------------------------.

Below is part of the glmer output and also the result from "gg <- 
model7 at optinfo$derivs$grad"

Generalized linear mixed model fit by maximum likelihood (Laplace
   Approximation) [glmerMod]
  Family: binomial  ( logit )
Formula: bottom10readA ~ 1 + female2 + (-1 + female2 | Country33) + (1 |
     SCHOOLID2) + SES_mean_cen + age_cen + secondgen_mean + native_mean +
     Parliament2013_cen + WLMP_cen + HDI2012_cen + selage_cen +
     ce + ZSTAND2012C + Fselage2 + FCE2 + FZstand_pisa_cen2
Control:
glmerControl(optimizer = "nloptwrap", optCtrl = list(algorithm = 
"NLOPT_LN_BOBYQA"))

      AIC      BIC   logLik deviance df.resid
151434.4 151613.4 -75700.2 151400.4   276524

Scaled residuals:
     Min      1Q  Median      3Q     Max
-4.6982 -0.3104 -0.1819 -0.1126 10.6450

Random effects:
  Groups    Name        Variance Std.Dev.
  SCHOOLID2 (Intercept) 2.314767 1.52144
  Country33 female2     0.008527 0.09234
Number of obs: 276541, groups:  SCHOOLID2, 10643; Country33, 35

Fixed effects:
                      Estimate Std. Error z value Pr(>|z|)
(Intercept)        -2.1629201  0.1006349 -21.493  < 2e-16 ***
female2            -0.4316766  0.0523024  -8.253  < 2e-16 ***
SES_mean_cen       -0.3901277  0.0257537 -15.148  < 2e-16 ***
age_cen            -0.1685527  0.0256951  -6.560 5.39e-11 ***
secondgen_mean     -0.2462713  0.1269396  -1.940   0.0524 .
native_mean        -1.0927106  0.0844515 -12.939  < 2e-16 ***
Parliament2013_cen -0.0020840  0.0025656  -0.812   0.4166
WLMP_cen            0.0002831  0.0027028   0.105   0.9166
HDI2012_cen        -0.0338573  0.0600986  -0.563   0.5732
selage_cen          0.0525462  0.0119847   4.384 1.16e-05 ***
ce                 -0.0902947  0.0496913  -1.817   0.0692 .
ZSTAND2012C        -0.0457672  0.1760672  -0.260   0.7949
Fselage2           -0.0092435  0.0096429  -0.959   0.3378
FCE2               -0.0650998  0.0450328  -1.446   0.1483
FZstand_pisa_cen2  -0.4586711  0.1497851  -3.062   0.0022 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


And finally the 17 gradients:

  gg

  [1]  -2.3293884   4.3723284  -5.6278026   0.2851749 1.6813773  -8.3454128
  [7]   4.1930703  -5.1109944  49.0449769 207.5065300 20.8115773 -31.4621360
[13]  14.0848733  -3.2661238 -24.9956165   7.0817152 -5.9149812




	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Fri Apr 10 23:57:18 2015
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Fri, 10 Apr 2015 21:57:18 +0000
Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E85CCED@itsnt443.iowa.uiowa.edu>

Daniel,

As long as you can get the regression coefficients, covariance of the coefficients, and a suitable grid of linear functions, you can obtain an lsmobj object that can be summarized and further analyzed in the 'lsmeans' package. For your question, I think something like this will work (I'm assuming your fitted mcmcGLMM object is named 'mod'):

# Get coefs and covariance matrix
bhat <- apply(mod$Sol, 2, mean)
V <- cov(mod$Sol)

# Set up desired factor levels (you likely want to change this)
levels <- list(day = 1:4, treatment = c("control", "cold"), species = factor(1:10))

# Obtain a differece quotient of model matrices 
lv1 <- lv2 <- levels
lv1$day = lv1$day - .0001
lv2$day = lv2$day + .0001
grid1 <- do.call(expand.grid, lv1)
grid2 <- do.call(expand.grid, lv2)
lf1 <- model.matrix(fixedForm, data = grid1)
lf2 <- model.matrix(fixedForm, data = grid2)
linfct <- (lf2 - lf1) / .0002

# Create the needed lsmobj
library(lsmeans)
mod.lsm <- lsmobj(bhat = bhat, V = V, levels = levels, 
    linfct = linfct, by = "species")

# Can now use summary, contrast, pairs, etc. on this result


I hope this helps

Russ

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017


-----Original Message-----
Date: Thu, 09 Apr 2015 18:32:11 -0700
From: Daniel Fulop <dfulop.ucd at gmail.com>
To: R_MixedModels <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
Message-ID: <5527281B.3080607 at gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Hi mixed modelers,

I would like to contrast average slopes using predictions from an LMM model fit with MCMCglmm.  In essence I want to do something analogous to lsmeans' lstrends() function.  The predicted slopes are growth rates ...more below.

I have 12 days of plant growth data for 10 closely related species at 2 temperatures.  There are several individuals per species at each temperature, and they're fully randomized.  I want to asses whether each species' growth rate differs between temperatures.  What I mean by that is that I would like to contrast the average slopes for each species in control vs. cold temperature; these slopes are the growth rates.

I am modeling the data in MCMCglmm so I can account for phylogeny and also to be able to try multi-response models (to jointly model the stem, plastochrons, root, etc).  I am starting out with the stem length data and after trying different time dependencies settled on this 3rd degree polynomial model:

stemLen ~ poly(day, 3, raw=TRUE) * treatment * species + (1 + day | indiv)

where day is a numeric time variable, treatment a 2 level factor (control and cold), and species a 10 level factor.

I have a slight idea of how I would go about contrasting the average slopes for each species and that I would use the predict.MCMCglmm() function, but I would really appreciate some guidance before I go down the wrong the wrong path.

Thanks for your help!
Dan.

--
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616


From dfulop.ucd at gmail.com  Sat Apr 11 00:38:59 2015
From: dfulop.ucd at gmail.com (Daniel Fulop)
Date: Fri, 10 Apr 2015 15:38:59 -0700
Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
In-Reply-To: <51F0C7C54B032A42A23B74A088E7141C2E85CCED@itsnt443.iowa.uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E85CCED@itsnt443.iowa.uiowa.edu>
Message-ID: <55285103.1030506@gmail.com>

Hi Russ,

Thanks a ton!  I did notice that lsmeans could be extended, but wasn't 
sure of how to get all the pieces from my MCMCglmm model object.  I was 
going to start getting the slopes from predictions on a grid of 'day' 
values to then average and finally subtract averages to contrast, but 
you've spared me that trouble.  Plus, I already have code to summarize 
and plot growth rate results from lsmeans, which I can now reuse.

I have one question about your example code, though.  Since I have 
posterior estimates, wouldn't it be better to get the bhat vector by 
using posterior.mode() instead of mean()?

Thanks,
Dan.


Lenth, Russell V wrote:
> Daniel,
>
> As long as you can get the regression coefficients, covariance of the coefficients, and a suitable grid of linear functions, you can obtain an lsmobj object that can be summarized and further analyzed in the 'lsmeans' package. For your question, I think something like this will work (I'm assuming your fitted mcmcGLMM object is named 'mod'):
>
> # Get coefs and covariance matrix
> bhat<- apply(mod$Sol, 2, mean)
> V<- cov(mod$Sol)
>
> # Set up desired factor levels (you likely want to change this)
> levels<- list(day = 1:4, treatment = c("control", "cold"), species = factor(1:10))
>
> # Obtain a differece quotient of model matrices
> lv1<- lv2<- levels
> lv1$day = lv1$day - .0001
> lv2$day = lv2$day + .0001
> grid1<- do.call(expand.grid, lv1)
> grid2<- do.call(expand.grid, lv2)
> lf1<- model.matrix(fixedForm, data = grid1)
> lf2<- model.matrix(fixedForm, data = grid2)
> linfct<- (lf2 - lf1) / .0002
>
> # Create the needed lsmobj
> library(lsmeans)
> mod.lsm<- lsmobj(bhat = bhat, V = V, levels = levels,
>      linfct = linfct, by = "species")
>
> # Can now use summary, contrast, pairs, etc. on this result
>
>
> I hope this helps
>
> Russ
>
> Russell V. Lenth  -  Professor Emeritus
> Department of Statistics and Actuarial Science
> The University of Iowa  -  Iowa City, IA 52242  USA
> Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
>
>
> -----Original Message-----
> Date: Thu, 09 Apr 2015 18:32:11 -0700
> From: Daniel Fulop<dfulop.ucd at gmail.com>
> To: R_MixedModels<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
> Message-ID:<5527281B.3080607 at gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hi mixed modelers,
>
> I would like to contrast average slopes using predictions from an LMM model fit with MCMCglmm.  In essence I want to do something analogous to lsmeans' lstrends() function.  The predicted slopes are growth rates ...more below.
>
> I have 12 days of plant growth data for 10 closely related species at 2 temperatures.  There are several individuals per species at each temperature, and they're fully randomized.  I want to asses whether each species' growth rate differs between temperatures.  What I mean by that is that I would like to contrast the average slopes for each species in control vs. cold temperature; these slopes are the growth rates.
>
> I am modeling the data in MCMCglmm so I can account for phylogeny and also to be able to try multi-response models (to jointly model the stem, plastochrons, root, etc).  I am starting out with the stem length data and after trying different time dependencies settled on this 3rd degree polynomial model:
>
> stemLen ~ poly(day, 3, raw=TRUE) * treatment * species + (1 + day | indiv)
>
> where day is a numeric time variable, treatment a 2 level factor (control and cold), and species a 10 level factor.
>
> I have a slight idea of how I would go about contrasting the average slopes for each species and that I would use the predict.MCMCglmm() function, but I would really appreciate some guidance before I go down the wrong the wrong path.
>
> Thanks for your help!
> Dan.
>
> --
> Daniel Fulop, Ph.D.
> Postdoctoral Scholar
> Dept. Plant Biology, UC Davis
> Maloof Lab, Rm. 2220
> Life Sciences Addition, One Shields Ave.
> Davis, CA 95616
>

-- 
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616

510-253-7462
dfulop at ucdavis.edu


From russell-lenth at uiowa.edu  Sat Apr 11 01:36:55 2015
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Fri, 10 Apr 2015 23:36:55 +0000
Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
In-Reply-To: <55285103.1030506@gmail.com>
References: <51F0C7C54B032A42A23B74A088E7141C2E85CCED@itsnt443.iowa.uiowa.edu>,
	<55285103.1030506@gmail.com>
Message-ID: <B6C78F33-4999-4048-95D8-86B7CE68C658@uiowa.edu>

On your question, maybe, but I'm not so sure the covariance matrix is right for that. Perhaps others can comment. It'd be good also to do some plots and perhaps other diagnostics to see if the sampler results are reasonably modeled as multivariate normal, as that is an underlying assumption of all the frequentist-style tests and CIs that you obtain.

Russ

Sent from my iPad

> On Apr 10, 2015, at 5:39 PM, Daniel Fulop <dfulop.ucd at gmail.com> wrote:
> 
> Hi Russ,
> 
> Thanks a ton!  I did notice that lsmeans could be extended, but wasn't sure of how to get all the pieces from my MCMCglmm model object.  I was going to start getting the slopes from predictions on a grid of 'day' values to then average and finally subtract averages to contrast, but you've spared me that trouble.  Plus, I already have code to summarize and plot growth rate results from lsmeans, which I can now reuse.
> 
> I have one question about your example code, though.  Since I have posterior estimates, wouldn't it be better to get the bhat vector by using posterior.mode() instead of mean()?
> 
> Thanks,
> Dan.
> 
> 
> Lenth, Russell V wrote:
>> Daniel,
>> 
>> As long as you can get the regression coefficients, covariance of the coefficients, and a suitable grid of linear functions, you can obtain an lsmobj object that can be summarized and further analyzed in the 'lsmeans' package. For your question, I think something like this will work (I'm assuming your fitted mcmcGLMM object is named 'mod'):
>> 
>> # Get coefs and covariance matrix
>> bhat<- apply(mod$Sol, 2, mean)
>> V<- cov(mod$Sol)
>> 
>> # Set up desired factor levels (you likely want to change this)
>> levels<- list(day = 1:4, treatment = c("control", "cold"), species = factor(1:10))
>> 
>> # Obtain a differece quotient of model matrices
>> lv1<- lv2<- levels
>> lv1$day = lv1$day - .0001
>> lv2$day = lv2$day + .0001
>> grid1<- do.call(expand.grid, lv1)
>> grid2<- do.call(expand.grid, lv2)
>> lf1<- model.matrix(fixedForm, data = grid1)
>> lf2<- model.matrix(fixedForm, data = grid2)
>> linfct<- (lf2 - lf1) / .0002
>> 
>> # Create the needed lsmobj
>> library(lsmeans)
>> mod.lsm<- lsmobj(bhat = bhat, V = V, levels = levels,
>>    linfct = linfct, by = "species")
>> 
>> # Can now use summary, contrast, pairs, etc. on this result
>> 
>> 
>> I hope this helps
>> 
>> Russ
>> 
>> Russell V. Lenth  -  Professor Emeritus
>> Department of Statistics and Actuarial Science
>> The University of Iowa  -  Iowa City, IA 52242  USA
>> Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
>> 
>> 
>> -----Original Message-----
>> Date: Thu, 09 Apr 2015 18:32:11 -0700
>> From: Daniel Fulop<dfulop.ucd at gmail.com>
>> To: R_MixedModels<r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
>> Message-ID:<5527281B.3080607 at gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>> 
>> Hi mixed modelers,
>> 
>> I would like to contrast average slopes using predictions from an LMM model fit with MCMCglmm.  In essence I want to do something analogous to lsmeans' lstrends() function.  The predicted slopes are growth rates ...more below.
>> 
>> I have 12 days of plant growth data for 10 closely related species at 2 temperatures.  There are several individuals per species at each temperature, and they're fully randomized.  I want to asses whether each species' growth rate differs between temperatures.  What I mean by that is that I would like to contrast the average slopes for each species in control vs. cold temperature; these slopes are the growth rates.
>> 
>> I am modeling the data in MCMCglmm so I can account for phylogeny and also to be able to try multi-response models (to jointly model the stem, plastochrons, root, etc).  I am starting out with the stem length data and after trying different time dependencies settled on this 3rd degree polynomial model:
>> 
>> stemLen ~ poly(day, 3, raw=TRUE) * treatment * species + (1 + day | indiv)
>> 
>> where day is a numeric time variable, treatment a 2 level factor (control and cold), and species a 10 level factor.
>> 
>> I have a slight idea of how I would go about contrasting the average slopes for each species and that I would use the predict.MCMCglmm() function, but I would really appreciate some guidance before I go down the wrong the wrong path.
>> 
>> Thanks for your help!
>> Dan.
>> 
>> --
>> Daniel Fulop, Ph.D.
>> Postdoctoral Scholar
>> Dept. Plant Biology, UC Davis
>> Maloof Lab, Rm. 2220
>> Life Sciences Addition, One Shields Ave.
>> Davis, CA 95616
> 
> -- 
> Daniel Fulop, Ph.D.
> Postdoctoral Scholar
> Dept. Plant Biology, UC Davis
> Maloof Lab, Rm. 2220
> Life Sciences Addition, One Shields Ave.
> Davis, CA 95616
> 
> 510-253-7462
> dfulop at ucdavis.edu
> 


From dfulop.ucd at gmail.com  Sat Apr 11 01:51:52 2015
From: dfulop.ucd at gmail.com (Daniel Fulop)
Date: Fri, 10 Apr 2015 16:51:52 -0700
Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
In-Reply-To: <B6C78F33-4999-4048-95D8-86B7CE68C658@uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E85CCED@itsnt443.iowa.uiowa.edu>,
	<55285103.1030506@gmail.com>
	<B6C78F33-4999-4048-95D8-86B7CE68C658@uiowa.edu>
Message-ID: <55286218.5010405@gmail.com>

Hi Russ,

Thanks again for the feedback and quick response!  My primary goal is 
simply to compare slopes within species and slope differences among 
species, the tests and CIs are a secondary concern.  lstrends() provides 
an easy means of estimating average slopes andslope differences .  I 
take your point about diagnostics and plotting, though, and will do some 
checking such as comparing the lstrends estimates to analogous estimates 
calculated using predict.MCMCglmm output.

On the point about the covariance matrix, the MCMCglmm output includes 
VCV samples.  So, I suppose I could calculate posterior modes of each 
cell in the vcv and use that instead?  Otherwise using the means should 
be fine.  From visual inspection of the posterior samples they're quite 
normal in appearance, so the means and modes should be quite close to 
each other.

Cheers,
Dan.



Lenth, Russell V wrote:
> On your question, maybe, but I'm not so sure the covariance matrix is right for that. Perhaps others can comment. It'd be good also to do some plots and perhaps other diagnostics to see if the sampler results are reasonably modeled as multivariate normal, as that is an underlying assumption of all the frequentist-style tests and CIs that you obtain.
>
> Russ
>
> Sent from my iPad
>
>> On Apr 10, 2015, at 5:39 PM, Daniel Fulop<dfulop.ucd at gmail.com>  wrote:
>>
>> Hi Russ,
>>
>> Thanks a ton!  I did notice that lsmeans could be extended, but wasn't sure of how to get all the pieces from my MCMCglmm model object.  I was going to start getting the slopes from predictions on a grid of 'day' values to then average and finally subtract averages to contrast, but you've spared me that trouble.  Plus, I already have code to summarize and plot growth rate results from lsmeans, which I can now reuse.
>>
>> I have one question about your example code, though.  Since I have posterior estimates, wouldn't it be better to get the bhat vector by using posterior.mode() instead of mean()?
>>
>> Thanks,
>> Dan.
>>
>>
>> Lenth, Russell V wrote:
>>> Daniel,
>>>
>>> As long as you can get the regression coefficients, covariance of the coefficients, and a suitable grid of linear functions, you can obtain an lsmobj object that can be summarized and further analyzed in the 'lsmeans' package. For your question, I think something like this will work (I'm assuming your fitted mcmcGLMM object is named 'mod'):
>>>
>>> # Get coefs and covariance matrix
>>> bhat<- apply(mod$Sol, 2, mean)
>>> V<- cov(mod$Sol)
>>>
>>> # Set up desired factor levels (you likely want to change this)
>>> levels<- list(day = 1:4, treatment = c("control", "cold"), species = factor(1:10))
>>>
>>> # Obtain a differece quotient of model matrices
>>> lv1<- lv2<- levels
>>> lv1$day = lv1$day - .0001
>>> lv2$day = lv2$day + .0001
>>> grid1<- do.call(expand.grid, lv1)
>>> grid2<- do.call(expand.grid, lv2)
>>> lf1<- model.matrix(fixedForm, data = grid1)
>>> lf2<- model.matrix(fixedForm, data = grid2)
>>> linfct<- (lf2 - lf1) / .0002
>>>
>>> # Create the needed lsmobj
>>> library(lsmeans)
>>> mod.lsm<- lsmobj(bhat = bhat, V = V, levels = levels,
>>>     linfct = linfct, by = "species")
>>>
>>> # Can now use summary, contrast, pairs, etc. on this result
>>>
>>>
>>> I hope this helps
>>>
>>> Russ
>>>
>>> Russell V. Lenth  -  Professor Emeritus
>>> Department of Statistics and Actuarial Science
>>> The University of Iowa  -  Iowa City, IA 52242  USA
>>> Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
>>>
>>>
>>> -----Original Message-----
>>> Date: Thu, 09 Apr 2015 18:32:11 -0700
>>> From: Daniel Fulop<dfulop.ucd at gmail.com>
>>> To: R_MixedModels<r-sig-mixed-models at r-project.org>
>>> Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
>>> Message-ID:<5527281B.3080607 at gmail.com>
>>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>>
>>> Hi mixed modelers,
>>>
>>> I would like to contrast average slopes using predictions from an LMM model fit with MCMCglmm.  In essence I want to do something analogous to lsmeans' lstrends() function.  The predicted slopes are growth rates ...more below.
>>>
>>> I have 12 days of plant growth data for 10 closely related species at 2 temperatures.  There are several individuals per species at each temperature, and they're fully randomized.  I want to asses whether each species' growth rate differs between temperatures.  What I mean by that is that I would like to contrast the average slopes for each species in control vs. cold temperature; these slopes are the growth rates.
>>>
>>> I am modeling the data in MCMCglmm so I can account for phylogeny and also to be able to try multi-response models (to jointly model the stem, plastochrons, root, etc).  I am starting out with the stem length data and after trying different time dependencies settled on this 3rd degree polynomial model:
>>>
>>> stemLen ~ poly(day, 3, raw=TRUE) * treatment * species + (1 + day | indiv)
>>>
>>> where day is a numeric time variable, treatment a 2 level factor (control and cold), and species a 10 level factor.
>>>
>>> I have a slight idea of how I would go about contrasting the average slopes for each species and that I would use the predict.MCMCglmm() function, but I would really appreciate some guidance before I go down the wrong the wrong path.
>>>
>>> Thanks for your help!
>>> Dan.
>>>
>>> --
>>> Daniel Fulop, Ph.D.
>>> Postdoctoral Scholar
>>> Dept. Plant Biology, UC Davis
>>> Maloof Lab, Rm. 2220
>>> Life Sciences Addition, One Shields Ave.
>>> Davis, CA 95616
>> -- 
>> Daniel Fulop, Ph.D.
>> Postdoctoral Scholar
>> Dept. Plant Biology, UC Davis
>> Maloof Lab, Rm. 2220
>> Life Sciences Addition, One Shields Ave.
>> Davis, CA 95616
>>
>> 510-253-7462
>> dfulop at ucdavis.edu
>>

-- 
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616

510-253-7462
dfulop at ucdavis.edu


From drmccloy at uw.edu  Sat Apr 11 01:51:44 2015
From: drmccloy at uw.edu (Daniel McCloy)
Date: Sat, 11 Apr 2015 07:51:44 +0800
Subject: [R-sig-ME] calculation max|grad value?
In-Reply-To: <5527ABF1.4040707@maw.ru.nl>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>	<55247764.2070509@gmail.com>	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>	<CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>	<CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>
	<5527ABF1.4040707@maw.ru.nl>
Message-ID: <55286210.8050404@uw.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

with a model called mod, you can get the relative gradient with

relgrad <- with(mod at optinfo$derivs, solve(Hessian, gradient))
print(max(abs(relgrad))

- -- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington


On 04/10/2015 06:54 PM, Ben Pelzer wrote:
> Dear list,
> 
> For a given model in glmer (lme4_1.1-7), I got the warning
> message:
> 
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  :
> 
> Model failed to converge with max|grad| = 0.0601483 (tol = 0.001, 
> component 17)
> 
> My model has 15 fixed effects and two (uncorrelated) random
> effects.
> 
> There has been a lot of correspondence about convergence issues in
> the recent lme4 version(s) lately, but I cannot easily find what
> measure the "max|grad" is exactly pointing to.  If I'm right, it is
> the "relative gradient" of one of the model parameters, apparantly
> parameter 17. But how exactly is this max|grad calculated? I found
> a command (coming from Ben Bolker):
> 
> gg <- model7 at optinfo$derivs$grad
> 
> which produces gradients that are much larger than 0.0601483,
> probably since they are "absolute" gradients.
> 
> In the book of Schnabel et al. I found a definition of the relative
>  gradient in their equation (7.2.3):
> 
> Delta(f) * x  / f
> 
> which I believe must be now interpreted as
> 
> gradient * parameters estimate by glmer /  loglikelihood
> 
> 
> Is this indeed the formula that is used in lme4 to derive the
> max|grad and is my interpretation of it correct? (I would like to
> reproduce the max|grad value 0.0601483).
> 
> And which of the parameters in my model is actually "component 17"
>  (which the warning message refers to)?
> 
> Thanks for any help!
> 
> Ben Pelzer.
> 
> 
> *--------------------------.
> 
> Below is part of the glmer output and also the result from "gg <- 
> model7 at optinfo$derivs$grad"
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace 
> Approximation) [glmerMod] Family: binomial  ( logit ) Formula:
> bottom10readA ~ 1 + female2 + (-1 + female2 | Country33) + (1 | 
> SCHOOLID2) + SES_mean_cen + age_cen + secondgen_mean + native_mean
> + Parliament2013_cen + WLMP_cen + HDI2012_cen + selage_cen + ce +
> ZSTAND2012C + Fselage2 + FCE2 + FZstand_pisa_cen2 Control: 
> glmerControl(optimizer = "nloptwrap", optCtrl = list(algorithm = 
> "NLOPT_LN_BOBYQA"))
> 
> AIC      BIC   logLik deviance df.resid 151434.4 151613.4 -75700.2
> 151400.4   276524
> 
> Scaled residuals: Min      1Q  Median      3Q     Max -4.6982
> -0.3104 -0.1819 -0.1126 10.6450
> 
> Random effects: Groups    Name        Variance Std.Dev. SCHOOLID2
> (Intercept) 2.314767 1.52144 Country33 female2     0.008527
> 0.09234 Number of obs: 276541, groups:  SCHOOLID2, 10643;
> Country33, 35
> 
> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> -2.1629201  0.1006349 -21.493  < 2e-16 *** female2
> -0.4316766  0.0523024  -8.253  < 2e-16 *** SES_mean_cen
> -0.3901277  0.0257537 -15.148  < 2e-16 *** age_cen
> -0.1685527  0.0256951  -6.560 5.39e-11 *** secondgen_mean
> -0.2462713  0.1269396  -1.940   0.0524 . native_mean
> -1.0927106  0.0844515 -12.939  < 2e-16 *** Parliament2013_cen
> -0.0020840  0.0025656  -0.812   0.4166 WLMP_cen
> 0.0002831  0.0027028   0.105   0.9166 HDI2012_cen        -0.0338573
> 0.0600986  -0.563   0.5732 selage_cen          0.0525462  0.0119847
> 4.384 1.16e-05 *** ce                 -0.0902947  0.0496913  -1.817
> 0.0692 . ZSTAND2012C        -0.0457672  0.1760672  -0.260   0.7949 
> Fselage2           -0.0092435  0.0096429  -0.959   0.3378 FCE2
> -0.0650998  0.0450328  -1.446   0.1483 FZstand_pisa_cen2
> -0.4586711  0.1497851  -3.062   0.0022 ** --- Signif. codes:  0
> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> And finally the 17 gradients:
> 
> gg
> 
> [1]  -2.3293884   4.3723284  -5.6278026   0.2851749 1.6813773
> -8.3454128 [7]   4.1930703  -5.1109944  49.0449769 207.5065300
> 20.8115773 -31.4621360 [13]  14.0848733  -3.2661238 -24.9956165
> 7.0817152 -5.9149812
> 
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (GNU/Linux)

iQEcBAEBAgAGBQJVKGIQAAoJEEzlbMQqUVLO8rUH/Al0jlkQJorokVi1eKnmImHC
fFOojbA6HrFZdtqAooueNdc3RroXXhdPLtlhxLgaNye+aaE8dJoe0FBMb94IxJV9
SB8thJyjCfEnuQvLvFFLgkHJYaorjMn/6J1fKz/ci9Ggun8d0abdpkclVcsycDaT
2BIBMT0qFcHMn8hzKz693xSz1Gfy9d7ggkkdOu0K0i4c/URP3XTjOVbO0Vyv2UIe
Xni7cuPJ9AMN6zzioGgZi3URd10ogOKljKOSLZTF1C8yBURc82w00/zOU8GzGPs8
pQ2SiQpLR9yxMeYZwGCPQ+gG3I3CBuBZxWJBPXFquJWpP5WQhcessyg6bV4YdQ4=
=W9ek
-----END PGP SIGNATURE-----


From dfulop.ucd at gmail.com  Sat Apr 11 03:55:55 2015
From: dfulop.ucd at gmail.com (Daniel Fulop)
Date: Fri, 10 Apr 2015 18:55:55 -0700
Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
In-Reply-To: <25202160-6C40-473B-997D-88592BC9CCE3@uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E85CCED@itsnt443.iowa.uiowa.edu>,
	<55285103.1030506@gmail.com>
	<B6C78F33-4999-4048-95D8-86B7CE68C658@uiowa.edu>,
	<55286218.5010405@gmail.com>
	<25202160-6C40-473B-997D-88592BC9CCE3@uiowa.edu>
Message-ID: <55287F2B.9040205@gmail.com>

Hi Russ,

Okay, I'll stick to your code.

As to the alternative, yes that would be better, but I'm afraid I have 
to sit down with pen and paper to figure out how to calculate the slope 
from each sample.  That's why I thought of resorting to using 
predict.MCMCglmm instead.  I guess I can use predict() and lstrends() to 
check that my slope samples are well calculated.

Thanks,
Dan.


Lenth, Russell V wrote:
> Dan,
>
> If you're talking about using the posterior mode of the variances and covariances, I think a whole big matrix of those would likely be very flaky. I think you are better off with my original suggestion.
>
> Alternatively, the really right thing to do is compute the slopes you need for *each* MCMC sample. Then you'll have a sample of each slope, from which you can obtain modes, HDRs, etc.
>
> Russ
>
> Sent from my iPhone
>
>> On Apr 10, 2015, at 6:51 PM, Daniel Fulop<dfulop.ucd at gmail.com>  wrote:
>>
>> Hi Russ,
>>
>> Thanks again for the feedback and quick response!  My primary goal is simply to compare slopes within species and slope differences among species, the tests and CIs are a secondary concern.  lstrends() provides an easy means of estimating average slopes andslope differences .  I take your point about diagnostics and plotting, though, and will do some checking such as comparing the lstrends estimates to analogous estimates calculated using predict.MCMCglmm output.
>>
>> On the point about the covariance matrix, the MCMCglmm output includes VCV samples.  So, I suppose I could calculate posterior modes of each cell in the vcv and use that instead?  Otherwise using the means should be fine.  From visual inspection of the posterior samples they're quite normal in appearance, so the means and modes should be quite close to each other.
>>
>> Cheers,
>> Dan.
>>
>>
>>
>> Lenth, Russell V wrote:
>>> On your question, maybe, but I'm not so sure the covariance matrix is right for that. Perhaps others can comment. It'd be good also to do some plots and perhaps other diagnostics to see if the sampler results are reasonably modeled as multivariate normal, as that is an underlying assumption of all the frequentist-style tests and CIs that you obtain.
>>>
>>> Russ
>>>
>>> Sent from my iPad
>>>
>>>> On Apr 10, 2015, at 5:39 PM, Daniel Fulop<dfulop.ucd at gmail.com>   wrote:
>>>>
>>>> Hi Russ,
>>>>
>>>> Thanks a ton!  I did notice that lsmeans could be extended, but wasn't sure of how to get all the pieces from my MCMCglmm model object.  I was going to start getting the slopes from predictions on a grid of 'day' values to then average and finally subtract averages to contrast, but you've spared me that trouble.  Plus, I already have code to summarize and plot growth rate results from lsmeans, which I can now reuse.
>>>>
>>>> I have one question about your example code, though.  Since I have posterior estimates, wouldn't it be better to get the bhat vector by using posterior.mode() instead of mean()?
>>>>
>>>> Thanks,
>>>> Dan.
>>>>
>>>>
>>>> Lenth, Russell V wrote:
>>>>> Daniel,
>>>>>
>>>>> As long as you can get the regression coefficients, covariance of the coefficients, and a suitable grid of linear functions, you can obtain an lsmobj object that can be summarized and further analyzed in the 'lsmeans' package. For your question, I think something like this will work (I'm assuming your fitted mcmcGLMM object is named 'mod'):
>>>>>
>>>>> # Get coefs and covariance matrix
>>>>> bhat<- apply(mod$Sol, 2, mean)
>>>>> V<- cov(mod$Sol)
>>>>>
>>>>> # Set up desired factor levels (you likely want to change this)
>>>>> levels<- list(day = 1:4, treatment = c("control", "cold"), species = factor(1:10))
>>>>>
>>>>> # Obtain a differece quotient of model matrices
>>>>> lv1<- lv2<- levels
>>>>> lv1$day = lv1$day - .0001
>>>>> lv2$day = lv2$day + .0001
>>>>> grid1<- do.call(expand.grid, lv1)
>>>>> grid2<- do.call(expand.grid, lv2)
>>>>> lf1<- model.matrix(fixedForm, data = grid1)
>>>>> lf2<- model.matrix(fixedForm, data = grid2)
>>>>> linfct<- (lf2 - lf1) / .0002
>>>>>
>>>>> # Create the needed lsmobj
>>>>> library(lsmeans)
>>>>> mod.lsm<- lsmobj(bhat = bhat, V = V, levels = levels,
>>>>>     linfct = linfct, by = "species")
>>>>>
>>>>> # Can now use summary, contrast, pairs, etc. on this result
>>>>>
>>>>>
>>>>> I hope this helps
>>>>>
>>>>> Russ
>>>>>
>>>>> Russell V. Lenth  -  Professor Emeritus
>>>>> Department of Statistics and Actuarial Science
>>>>> The University of Iowa  -  Iowa City, IA 52242  USA
>>>>> Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
>>>>>
>>>>>
>>>>> -----Original Message-----
>>>>> Date: Thu, 09 Apr 2015 18:32:11 -0700
>>>>> From: Daniel Fulop<dfulop.ucd at gmail.com>
>>>>> To: R_MixedModels<r-sig-mixed-models at r-project.org>
>>>>> Subject: [R-sig-ME] contrast of predicted slopes from MCMCglmm model
>>>>> Message-ID:<5527281B.3080607 at gmail.com>
>>>>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>>>>
>>>>> Hi mixed modelers,
>>>>>
>>>>> I would like to contrast average slopes using predictions from an LMM model fit with MCMCglmm.  In essence I want to do something analogous to lsmeans' lstrends() function.  The predicted slopes are growth rates ...more below.
>>>>>
>>>>> I have 12 days of plant growth data for 10 closely related species at 2 temperatures.  There are several individuals per species at each temperature, and they're fully randomized.  I want to asses whether each species' growth rate differs between temperatures.  What I mean by that is that I would like to contrast the average slopes for each species in control vs. cold temperature; these slopes are the growth rates.
>>>>>
>>>>> I am modeling the data in MCMCglmm so I can account for phylogeny and also to be able to try multi-response models (to jointly model the stem, plastochrons, root, etc).  I am starting out with the stem length data and after trying different time dependencies settled on this 3rd degree polynomial model:
>>>>>
>>>>> stemLen ~ poly(day, 3, raw=TRUE) * treatment * species + (1 + day | indiv)
>>>>>
>>>>> where day is a numeric time variable, treatment a 2 level factor (control and cold), and species a 10 level factor.
>>>>>
>>>>> I have a slight idea of how I would go about contrasting the average slopes for each species and that I would use the predict.MCMCglmm() function, but I would really appreciate some guidance before I go down the wrong the wrong path.
>>>>>
>>>>> Thanks for your help!
>>>>> Dan.
>>>>>
>>>>> --
>>>>> Daniel Fulop, Ph.D.
>>>>> Postdoctoral Scholar
>>>>> Dept. Plant Biology, UC Davis
>>>>> Maloof Lab, Rm. 2220
>>>>> Life Sciences Addition, One Shields Ave.
>>>>> Davis, CA 95616
>>>> -- 
>>>> Daniel Fulop, Ph.D.
>>>> Postdoctoral Scholar
>>>> Dept. Plant Biology, UC Davis
>>>> Maloof Lab, Rm. 2220
>>>> Life Sciences Addition, One Shields Ave.
>>>> Davis, CA 95616
>>>>
>>>> 510-253-7462
>>>> dfulop at ucdavis.edu
>> -- 
>> Daniel Fulop, Ph.D.
>> Postdoctoral Scholar
>> Dept. Plant Biology, UC Davis
>> Maloof Lab, Rm. 2220
>> Life Sciences Addition, One Shields Ave.
>> Davis, CA 95616
>>
>> 510-253-7462
>> dfulop at ucdavis.edu
>>

-- 
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616

510-253-7462
dfulop at ucdavis.edu


From b.pelzer at maw.ru.nl  Mon Apr 13 14:41:21 2015
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Mon, 13 Apr 2015 14:41:21 +0200
Subject: [R-sig-ME] calculation max|grad value?
In-Reply-To: <55286210.8050404@uw.edu>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>	<55247764.2070509@gmail.com>	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>	<CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>	<CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>
	<5527ABF1.4040707@maw.ru.nl> <55286210.8050404@uw.edu>
Message-ID: <552BB971.9030506@maw.ru.nl>

Hi Dan,

Thanks for pointing me to that formula. Am I right that in case of only 
one parameter (say a fixed intercept only), this measure means that the 
gradient of the intercept-estimate is divided by the (estimated) 
variance of the intercept? Could you explain to me the rationale behind 
this measure or to put it differently: why is it meaningful to use it as 
a criterion to evaluate the quality of the convergence?

In case of more than one parameter, it's even less clear to me what the 
measure exactly expresses and thus why it is used by glmer.

Thanks again for any help/explanation,

Ben Pelzer.



On 11-4-2015 1:51, Daniel McCloy wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> with a model called mod, you can get the relative gradient with
>
> relgrad <- with(mod at optinfo$derivs, solve(Hessian, gradient))
> print(max(abs(relgrad))
>
> - -- dan
>
> Daniel McCloy
> http://dan.mccloy.info/
> Postdoctoral Research Fellow
> Institute for Learning and Brain Sciences
> University of Washington
>
>
> On 04/10/2015 06:54 PM, Ben Pelzer wrote:
>> Dear list,
>>
>> For a given model in glmer (lme4_1.1-7), I got the warning
>> message:
>>
>> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  :
>>
>> Model failed to converge with max|grad| = 0.0601483 (tol = 0.001,
>> component 17)
>>
>> My model has 15 fixed effects and two (uncorrelated) random
>> effects.
>>
>> There has been a lot of correspondence about convergence issues in
>> the recent lme4 version(s) lately, but I cannot easily find what
>> measure the "max|grad" is exactly pointing to.  If I'm right, it is
>> the "relative gradient" of one of the model parameters, apparantly
>> parameter 17. But how exactly is this max|grad calculated? I found
>> a command (coming from Ben Bolker):
>>
>> gg <- model7 at optinfo$derivs$grad
>>
>> which produces gradients that are much larger than 0.0601483,
>> probably since they are "absolute" gradients.
>>
>> In the book of Schnabel et al. I found a definition of the relative
>>   gradient in their equation (7.2.3):
>>
>> Delta(f) * x  / f
>>
>> which I believe must be now interpreted as
>>
>> gradient * parameters estimate by glmer /  loglikelihood
>>
>>
>> Is this indeed the formula that is used in lme4 to derive the
>> max|grad and is my interpretation of it correct? (I would like to
>> reproduce the max|grad value 0.0601483).
>>
>> And which of the parameters in my model is actually "component 17"
>>   (which the warning message refers to)?
>>
>> Thanks for any help!
>>
>> Ben Pelzer.
>>
>>
>> *--------------------------.
>>
>> Below is part of the glmer output and also the result from "gg <-
>> model7 at optinfo$derivs$grad"
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) [glmerMod] Family: binomial  ( logit ) Formula:
>> bottom10readA ~ 1 + female2 + (-1 + female2 | Country33) + (1 |
>> SCHOOLID2) + SES_mean_cen + age_cen + secondgen_mean + native_mean
>> + Parliament2013_cen + WLMP_cen + HDI2012_cen + selage_cen + ce +
>> ZSTAND2012C + Fselage2 + FCE2 + FZstand_pisa_cen2 Control:
>> glmerControl(optimizer = "nloptwrap", optCtrl = list(algorithm =
>> "NLOPT_LN_BOBYQA"))
>>
>> AIC      BIC   logLik deviance df.resid 151434.4 151613.4 -75700.2
>> 151400.4   276524
>>
>> Scaled residuals: Min      1Q  Median      3Q     Max -4.6982
>> -0.3104 -0.1819 -0.1126 10.6450
>>
>> Random effects: Groups    Name        Variance Std.Dev. SCHOOLID2
>> (Intercept) 2.314767 1.52144 Country33 female2     0.008527
>> 0.09234 Number of obs: 276541, groups:  SCHOOLID2, 10643;
>> Country33, 35
>>
>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> -2.1629201  0.1006349 -21.493  < 2e-16 *** female2
>> -0.4316766  0.0523024  -8.253  < 2e-16 *** SES_mean_cen
>> -0.3901277  0.0257537 -15.148  < 2e-16 *** age_cen
>> -0.1685527  0.0256951  -6.560 5.39e-11 *** secondgen_mean
>> -0.2462713  0.1269396  -1.940   0.0524 . native_mean
>> -1.0927106  0.0844515 -12.939  < 2e-16 *** Parliament2013_cen
>> -0.0020840  0.0025656  -0.812   0.4166 WLMP_cen
>> 0.0002831  0.0027028   0.105   0.9166 HDI2012_cen        -0.0338573
>> 0.0600986  -0.563   0.5732 selage_cen          0.0525462  0.0119847
>> 4.384 1.16e-05 *** ce                 -0.0902947  0.0496913  -1.817
>> 0.0692 . ZSTAND2012C        -0.0457672  0.1760672  -0.260   0.7949
>> Fselage2           -0.0092435  0.0096429  -0.959   0.3378 FCE2
>> -0.0650998  0.0450328  -1.446   0.1483 FZstand_pisa_cen2
>> -0.4586711  0.1497851  -3.062   0.0022 ** --- Signif. codes:  0
>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>> And finally the 17 gradients:
>>
>> gg
>>
>> [1]  -2.3293884   4.3723284  -5.6278026   0.2851749 1.6813773
>> -8.3454128 [7]   4.1930703  -5.1109944  49.0449769 207.5065300
>> 20.8115773 -31.4621360 [13]  14.0848733  -3.2661238 -24.9956165
>> 7.0817152 -5.9149812
>>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVKGIQAAoJEEzlbMQqUVLO8rUH/Al0jlkQJorokVi1eKnmImHC
> fFOojbA6HrFZdtqAooueNdc3RroXXhdPLtlhxLgaNye+aaE8dJoe0FBMb94IxJV9
> SB8thJyjCfEnuQvLvFFLgkHJYaorjMn/6J1fKz/ci9Ggun8d0abdpkclVcsycDaT
> 2BIBMT0qFcHMn8hzKz693xSz1Gfy9d7ggkkdOu0K0i4c/URP3XTjOVbO0Vyv2UIe
> Xni7cuPJ9AMN6zzioGgZi3URd10ogOKljKOSLZTF1C8yBURc82w00/zOU8GzGPs8
> pQ2SiQpLR9yxMeYZwGCPQ+gG3I3CBuBZxWJBPXFquJWpP5WQhcessyg6bV4YdQ4=
> =W9ek
> -----END PGP SIGNATURE-----


From bates at stat.wisc.edu  Mon Apr 13 22:11:45 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Apr 2015 20:11:45 +0000
Subject: [R-sig-ME] calculation max|grad value?
In-Reply-To: <552BB971.9030506@maw.ru.nl>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>
	<55247764.2070509@gmail.com>
	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>
	<CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>
	<CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>
	<5527ABF1.4040707@maw.ru.nl> <55286210.8050404@uw.edu>
	<552BB971.9030506@maw.ru.nl>
Message-ID: <CAO7JsnTsxkVegqKW-_9VxSndfkg-OUx74ZzzaOz1WGC1cDH=zQ@mail.gmail.com>

On Mon, Apr 13, 2015 at 7:45 AM Ben Pelzer <b.pelzer at maw.ru.nl> wrote:

> Hi Dan,
>
> Thanks for pointing me to that formula. Am I right that in case of only
> one parameter (say a fixed intercept only), this measure means that the
> gradient of the intercept-estimate is divided by the (estimated)
> variance of the intercept? Could you explain to me the rationale behind
> this measure or to put it differently: why is it meaningful to use it as
> a criterion to evaluate the quality of the convergence?
>
> In case of more than one parameter, it's even less clear to me what the
> measure exactly expresses and thus why it is used by glmer.
>
> Thanks again for any help/explanation,
>
> Ben Pelzer.
>

There is some confusion here about what constitutes a parameter.  The
actual optimization in lmer is of a profiled log-likelihood that is a
function of variance component parameters only.  In the case of a model
with a scalar random effects term that parameter is the ratio of the
standard deviation of the random effects to the residual standard deviation.

See http://arxiv.org/abs/1406.5823 for more details.

The rationale for normalizing the gradient with respect to the Hessian is
to make it scale invariant.  (It turns out that the normalization used
wasn't the correct one to use but we will change that.)  Consider the
sleepstudy data in the lme4 package.  The response time is measured in
milliseconds, as is common in such experiments, and a typical response time
at the beginning of the experiment is around 250 ms.  Suppose that the
responses were converted to seconds, so the typical response time was 0.250
sec.  The scaling would affect the size of the gradient terms the same
way.  If the measurements were converted to microseconds all the gradient
terms would be multiplied by 1000.

The scaling is to make the quantity being compared to a fixed tolerance
dimensionless.  It is a basic principle that only dimensionless quantities
can be compared to a fixed tolerance.

>
>
>
> On 11-4-2015 1:51, Daniel McCloy wrote:
> > -----BEGIN PGP SIGNED MESSAGE-----
> > Hash: SHA1
> >
> > with a model called mod, you can get the relative gradient with
> >
> > relgrad <- with(mod at optinfo$derivs, solve(Hessian, gradient))
> > print(max(abs(relgrad))
> >
> > - -- dan
> >
> > Daniel McCloy
> > http://dan.mccloy.info/
> > Postdoctoral Research Fellow
> > Institute for Learning and Brain Sciences
> > University of Washington
> >
> >
> > On 04/10/2015 06:54 PM, Ben Pelzer wrote:
> >> Dear list,
> >>
> >> For a given model in glmer (lme4_1.1-7), I got the warning
> >> message:
> >>
> >> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> >> control$checkConv,  :
> >>
> >> Model failed to converge with max|grad| = 0.0601483 (tol = 0.001,
> >> component 17)
> >>
> >> My model has 15 fixed effects and two (uncorrelated) random
> >> effects.
> >>
> >> There has been a lot of correspondence about convergence issues in
> >> the recent lme4 version(s) lately, but I cannot easily find what
> >> measure the "max|grad" is exactly pointing to.  If I'm right, it is
> >> the "relative gradient" of one of the model parameters, apparantly
> >> parameter 17. But how exactly is this max|grad calculated? I found
> >> a command (coming from Ben Bolker):
> >>
> >> gg <- model7 at optinfo$derivs$grad
> >>
> >> which produces gradients that are much larger than 0.0601483,
> >> probably since they are "absolute" gradients.
> >>
> >> In the book of Schnabel et al. I found a definition of the relative
> >>   gradient in their equation (7.2.3):
> >>
> >> Delta(f) * x  / f
> >>
> >> which I believe must be now interpreted as
> >>
> >> gradient * parameters estimate by glmer /  loglikelihood
> >>
> >>
> >> Is this indeed the formula that is used in lme4 to derive the
> >> max|grad and is my interpretation of it correct? (I would like to
> >> reproduce the max|grad value 0.0601483).
> >>
> >> And which of the parameters in my model is actually "component 17"
> >>   (which the warning message refers to)?
> >>
> >> Thanks for any help!
> >>
> >> Ben Pelzer.
> >>
> >>
> >> *--------------------------.
> >>
> >> Below is part of the glmer output and also the result from "gg <-
> >> model7 at optinfo$derivs$grad"
> >>
> >> Generalized linear mixed model fit by maximum likelihood (Laplace
> >> Approximation) [glmerMod] Family: binomial  ( logit ) Formula:
> >> bottom10readA ~ 1 + female2 + (-1 + female2 | Country33) + (1 |
> >> SCHOOLID2) + SES_mean_cen + age_cen + secondgen_mean + native_mean
> >> + Parliament2013_cen + WLMP_cen + HDI2012_cen + selage_cen + ce +
> >> ZSTAND2012C + Fselage2 + FCE2 + FZstand_pisa_cen2 Control:
> >> glmerControl(optimizer = "nloptwrap", optCtrl = list(algorithm =
> >> "NLOPT_LN_BOBYQA"))
> >>
> >> AIC      BIC   logLik deviance df.resid 151434.4 151613.4 -75700.2
> >> 151400.4   276524
> >>
> >> Scaled residuals: Min      1Q  Median      3Q     Max -4.6982
> >> -0.3104 -0.1819 -0.1126 10.6450
> >>
> >> Random effects: Groups    Name        Variance Std.Dev. SCHOOLID2
> >> (Intercept) 2.314767 1.52144 Country33 female2     0.008527
> >> 0.09234 Number of obs: 276541, groups:  SCHOOLID2, 10643;
> >> Country33, 35
> >>
> >> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> >> -2.1629201  0.1006349 -21.493  < 2e-16 *** female2
> >> -0.4316766  0.0523024  -8.253  < 2e-16 *** SES_mean_cen
> >> -0.3901277  0.0257537 -15.148  < 2e-16 *** age_cen
> >> -0.1685527  0.0256951  -6.560 5.39e-11 *** secondgen_mean
> >> -0.2462713  0.1269396  -1.940   0.0524 . native_mean
> >> -1.0927106  0.0844515 -12.939  < 2e-16 *** Parliament2013_cen
> >> -0.0020840  0.0025656  -0.812   0.4166 WLMP_cen
> >> 0.0002831  0.0027028   0.105   0.9166 HDI2012_cen        -0.0338573
> >> 0.0600986  -0.563   0.5732 selage_cen          0.0525462  0.0119847
> >> 4.384 1.16e-05 *** ce                 -0.0902947  0.0496913  -1.817
> >> 0.0692 . ZSTAND2012C        -0.0457672  0.1760672  -0.260   0.7949
> >> Fselage2           -0.0092435  0.0096429  -0.959   0.3378 FCE2
> >> -0.0650998  0.0450328  -1.446   0.1483 FZstand_pisa_cen2
> >> -0.4586711  0.1497851  -3.062   0.0022 ** --- Signif. codes:  0
> >> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >>
> >> And finally the 17 gradients:
> >>
> >> gg
> >>
> >> [1]  -2.3293884   4.3723284  -5.6278026   0.2851749 1.6813773
> >> -8.3454128 [7]   4.1930703  -5.1109944  49.0449769 207.5065300
> >> 20.8115773 -31.4621360 [13]  14.0848733  -3.2661238 -24.9956165
> >> 7.0817152 -5.9149812
> >>
> >>
> >>
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org  mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> > -----BEGIN PGP SIGNATURE-----
> > Version: GnuPG v2.0.22 (GNU/Linux)
> >
> > iQEcBAEBAgAGBQJVKGIQAAoJEEzlbMQqUVLO8rUH/Al0jlkQJorokVi1eKnmImHC
> > fFOojbA6HrFZdtqAooueNdc3RroXXhdPLtlhxLgaNye+aaE8dJoe0FBMb94IxJV9
> > SB8thJyjCfEnuQvLvFFLgkHJYaorjMn/6J1fKz/ci9Ggun8d0abdpkclVcsycDaT
> > 2BIBMT0qFcHMn8hzKz693xSz1Gfy9d7ggkkdOu0K0i4c/URP3XTjOVbO0Vyv2UIe
> > Xni7cuPJ9AMN6zzioGgZi3URd10ogOKljKOSLZTF1C8yBURc82w00/zOU8GzGPs8
> > pQ2SiQpLR9yxMeYZwGCPQ+gG3I3CBuBZxWJBPXFquJWpP5WQhcessyg6bV4YdQ4=
> > =W9ek
> > -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Apr 13 23:25:17 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 13 Apr 2015 17:25:17 -0400
Subject: [R-sig-ME] calculation max|grad value?
In-Reply-To: <552BB971.9030506@maw.ru.nl>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>	<55247764.2070509@gmail.com>	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>	<CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>	<CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>	<5527ABF1.4040707@maw.ru.nl>
	<55286210.8050404@uw.edu> <552BB971.9030506@maw.ru.nl>
Message-ID: <552C343D.2050706@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-04-13 08:41 AM, Ben Pelzer wrote:
> Hi Dan,
> 
> Thanks for pointing me to that formula. Am I right that in case of
> only one parameter (say a fixed intercept only), this measure means
> that the gradient of the intercept-estimate is divided by the
> (estimated) variance of the intercept? Could you explain to me the
> rationale behind this measure or to put it differently: why is it
> meaningful to use it as a criterion to evaluate the quality of the
> convergence?
> 
> In case of more than one parameter, it's even less clear to me what
> the measure exactly expresses and thus why it is used by glmer.
> 
> Thanks again for any help/explanation,
> 
> Ben Pelzer.

  As Doug Bates pointed out and explained, we should really be using
solve(chol(Hessian), gradient) instead (I started this e-mail this
morning and have had the compose window sitting open all day).
Heuristically, what this means is that we're estimating the expected
change in the deviance over the scale of one standard error of the
parameter, rather than over the scale of one unit of the parameter (as
Doug points out, the latter can be rather arbitrary).

  We know and have known for a while that the convergence criteria
we're currently using are rather dodgy, but we've been struggling with
what to replace them with.  We know there are lots of false positives
for large (say nobs > 10^5) data sets, and we are trying to come up
with reasonable, simple criteria that will reduce the number of false
positives without completely scrapping the convergence criteria.

  In the meantime, I would say that the gold standard (at this point)
for "is my fit really OK?" is  whether you can refit with several
different optimizers (and possibly different starting points?) and get
practically the same result in each case; see e.g.
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html





> 
> 
> 
> On 11-4-2015 1:51, Daniel McCloy wrote: with a model called mod,
> you can get the relative gradient with
> 
> relgrad <- with(mod at optinfo$derivs, solve(Hessian, gradient)) 
> print(max(abs(relgrad))
> 
> -- dan
> 
> Daniel McCloy http://dan.mccloy.info/ Postdoctoral Research Fellow 
> Institute for Learning and Brain Sciences University of Washington
> 
> 
> On 04/10/2015 06:54 PM, Ben Pelzer wrote:
>>>> Dear list,
>>>> 
>>>> For a given model in glmer (lme4_1.1-7), I got the warning 
>>>> message:
>>>> 
>>>> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = 
>>>> control$checkConv,  :
>>>> 
>>>> Model failed to converge with max|grad| = 0.0601483 (tol =
>>>> 0.001, component 17)
>>>> 
>>>> My model has 15 fixed effects and two (uncorrelated) random 
>>>> effects.
>>>> 
>>>> There has been a lot of correspondence about convergence
>>>> issues in the recent lme4 version(s) lately, but I cannot
>>>> easily find what measure the "max|grad" is exactly pointing
>>>> to.  If I'm right, it is the "relative gradient" of one of
>>>> the model parameters, apparantly parameter 17. But how
>>>> exactly is this max|grad calculated? I found a command
>>>> (coming from Ben Bolker):
>>>> 
>>>> gg <- model7 at optinfo$derivs$grad
>>>> 
>>>> which produces gradients that are much larger than
>>>> 0.0601483, probably since they are "absolute" gradients.
>>>> 
>>>> In the book of Schnabel et al. I found a definition of the
>>>> relative gradient in their equation (7.2.3):
>>>> 
>>>> Delta(f) * x  / f
>>>> 
>>>> which I believe must be now interpreted as
>>>> 
>>>> gradient * parameters estimate by glmer /  loglikelihood
>>>> 
>>>> 
>>>> Is this indeed the formula that is used in lme4 to derive
>>>> the max|grad and is my interpretation of it correct? (I would
>>>> like to reproduce the max|grad value 0.0601483).
>>>> 
>>>> And which of the parameters in my model is actually
>>>> "component 17" (which the warning message refers to)?
>>>> 
>>>> Thanks for any help!
>>>> 
>>>> Ben Pelzer.
>>>> 
>>>> 
>>>> *--------------------------.
>>>> 
>>>> Below is part of the glmer output and also the result from
>>>> "gg <- model7 at optinfo$derivs$grad"
>>>> 
>>>> Generalized linear mixed model fit by maximum likelihood
>>>> (Laplace Approximation) [glmerMod] Family: binomial  ( logit
>>>> ) Formula: bottom10readA ~ 1 + female2 + (-1 + female2 |
>>>> Country33) + (1 | SCHOOLID2) + SES_mean_cen + age_cen +
>>>> secondgen_mean + native_mean + Parliament2013_cen + WLMP_cen
>>>> + HDI2012_cen + selage_cen + ce + ZSTAND2012C + Fselage2 +
>>>> FCE2 + FZstand_pisa_cen2 Control: glmerControl(optimizer =
>>>> "nloptwrap", optCtrl = list(algorithm = "NLOPT_LN_BOBYQA"))
>>>> 
>>>> AIC      BIC   logLik deviance df.resid 151434.4 151613.4
>>>> -75700.2 151400.4   276524
>>>> 
>>>> Scaled residuals: Min      1Q  Median      3Q     Max
>>>> -4.6982 -0.3104 -0.1819 -0.1126 10.6450
>>>> 
>>>> Random effects: Groups    Name        Variance Std.Dev.
>>>> SCHOOLID2 (Intercept) 2.314767 1.52144 Country33 female2
>>>> 0.008527 0.09234 Number of obs: 276541, groups:  SCHOOLID2,
>>>> 10643; Country33, 35
>>>> 
>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|)
>>>> (Intercept) -2.1629201  0.1006349 -21.493  < 2e-16 ***
>>>> female2 -0.4316766  0.0523024  -8.253  < 2e-16 ***
>>>> SES_mean_cen -0.3901277  0.0257537 -15.148  < 2e-16 ***
>>>> age_cen -0.1685527  0.0256951  -6.560 5.39e-11 ***
>>>> secondgen_mean -0.2462713  0.1269396  -1.940   0.0524 .
>>>> native_mean -1.0927106  0.0844515 -12.939  < 2e-16 ***
>>>> Parliament2013_cen -0.0020840  0.0025656  -0.812   0.4166
>>>> WLMP_cen 0.0002831  0.0027028   0.105   0.9166 HDI2012_cen
>>>> -0.0338573 0.0600986  -0.563   0.5732 selage_cen
>>>> 0.0525462  0.0119847 4.384 1.16e-05 *** ce
>>>> -0.0902947  0.0496913  -1.817 0.0692 . ZSTAND2012C
>>>> -0.0457672  0.1760672  -0.260   0.7949 Fselage2
>>>> -0.0092435  0.0096429  -0.959   0.3378 FCE2 -0.0650998
>>>> 0.0450328  -1.446   0.1483 FZstand_pisa_cen2 -0.4586711
>>>> 0.1497851  -3.062   0.0022 ** --- Signif. codes:  0 ?***?
>>>> 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> 
>>>> 
>>>> And finally the 17 gradients:
>>>> 
>>>> gg
>>>> 
>>>> [1]  -2.3293884   4.3723284  -5.6278026   0.2851749
>>>> 1.6813773 -8.3454128 [7]   4.1930703  -5.1109944  49.0449769
>>>> 207.5065300 20.8115773 -31.4621360 [13]  14.0848733
>>>> -3.2661238 -24.9956165 7.0817152 -5.9149812
>>>> 
>>>> 
>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org  mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVLDQ9AAoJEOCV5YRblxUH4E8IALrcXjAHXP9fmg77LwqYH9II
DaLh3QaQLcp3D2RB74U6zfHgXh9lsrO6ojGIPQDSa6k21L+Yfa4EBmmQs77hkzEz
+yBYJdgWCJl5YL0J3d3Rckbtl2ieYxO046E764r9X4m2w8kIz+wHT51SHma7S9ho
Ghw6GbFTaen9X5x9pPIC1otA3CVXHDtErZwYKi522ACF2hnvd1Z7GjkMAZZ6V868
fvBmXIx3BfgrGhYvbQpNKcxu1iQ2AbfHtq9JgjUA60jmnQIvbHDHOyqiNP0ksiJO
OFIt7x9n7RR0jEOPL4sTJAeUitvagw6eTFy4OqjHTHz4sysX8z9b9OJJ5FeOv88=
=A25k
-----END PGP SIGNATURE-----


From b.pelzer at maw.ru.nl  Wed Apr 15 11:53:29 2015
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 15 Apr 2015 11:53:29 +0200
Subject: [R-sig-ME] calculation max|grad value?
In-Reply-To: <CAO7JsnTsxkVegqKW-_9VxSndfkg-OUx74ZzzaOz1WGC1cDH=zQ@mail.gmail.com>
References: <CALC46t9+GeqephTCvmpzGnyM4FAQPYH1hnzRT8HwAHc9vZhJYw@mail.gmail.com>
	<CAF5_5cwobrDwMcnRA3q1z8QJ8hJCAOv2sEKd5Zkx1axJk0-NPA@mail.gmail.com>
	<CALC46t8hOsUPhf-WqNRkh77DyPDiBh_5ikH-jmLWP7z8TafL=Q@mail.gmail.com>
	<CAF5_5czuDqZ2Tgy=p2j2acNzNo7VRcdU2_VkzOuJSUZUUJeZLA@mail.gmail.com>
	<55247764.2070509@gmail.com>
	<CAF5_5cxZ1D3zmzmiii_1nVfon=p2MYnzvu+PrmT4Jh+wdZezew@mail.gmail.com>
	<CALC46t8PhQg703pTXsO6-cQyVHxZFHx8tCnOH1-pfcCwFALJpA@mail.gmail.com>
	<CAF5_5cytwW9bE+HSH4EjauUKGqxHcPO7VU0eoj1ULe=V0eTutw@mail.gmail.com>
	<5527ABF1.4040707@maw.ru.nl> <55286210.8050404@uw.edu>
	<552BB971.9030506@maw.ru.nl>
	<CAO7JsnTsxkVegqKW-_9VxSndfkg-OUx74ZzzaOz1WGC1cDH=zQ@mail.gmail.com>
Message-ID: <552E3519.8000905@maw.ru.nl>

Doug and Ben,

Thanks for your explanations! The milliseconds example is nice. Ben's 
remark about

the expected
change in the deviance over the scale of one standard error of the
parameter,

is very useful to understand this "relative gradience" measure.

But this also raises a question. I do not understand how Ben's 
interpretation follows from the formula
solve(hessian,gradient) or from solve(chol(hessian),gradient). This is 
probably due to my rather limited knowledge of MLE theory.

I know that the inverse of the information matrix gives the variances of 
the estimates. And that the inform. matrix equals minus the expected 
value of the hessian. I also understand that solve(hessian, gradient) 
results in the inverse(hessian) * gradient. In scalars, this looks like 
"dividing the gradient by the hessian" or scaling the gradient, making 
it dimensionless as Doug pointed out.

But to translate this to standard errors of the estimates, it looks as 
if there should be a minus sign and also a square root, something like 
-sqrt(solve(hessian)) * gradient? But maybe I'm wrong, as I said: 
limited knowledge.

Thanks once again for your help and your effort to explain all this!

Ben Pelzer.


On 13-4-2015 22:11, Douglas Bates wrote:
> On Mon, Apr 13, 2015 at 7:45 AM Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>> wrote:
>
>     Hi Dan,
>
>     Thanks for pointing me to that formula. Am I right that in case of
>     only
>     one parameter (say a fixed intercept only), this measure means
>     that the
>     gradient of the intercept-estimate is divided by the (estimated)
>     variance of the intercept? Could you explain to me the rationale
>     behind
>     this measure or to put it differently: why is it meaningful to use
>     it as
>     a criterion to evaluate the quality of the convergence?
>
>     In case of more than one parameter, it's even less clear to me
>     what the
>     measure exactly expresses and thus why it is used by glmer.
>
>     Thanks again for any help/explanation,
>
>     Ben Pelzer.
>
>
> There is some confusion here about what constitutes a parameter.  The 
> actual optimization in lmer is of a profiled log-likelihood that is a 
> function of variance component parameters only.  In the case of a 
> model with a scalar random effects term that parameter is the ratio of 
> the standard deviation of the random effects to the residual standard 
> deviation.
>
> See http://arxiv.org/abs/1406.5823 for more details.
>
> The rationale for normalizing the gradient with respect to the Hessian 
> is to make it scale invariant.  (It turns out that the normalization 
> used wasn't the correct one to use but we will change that.)  Consider 
> the sleepstudy data in the lme4 package.  The response time is 
> measured in milliseconds, as is common in such experiments, and a 
> typical response time at the beginning of the experiment is around 250 
> ms.  Suppose that the responses were converted to seconds, so the 
> typical response time was 0.250 sec.  The scaling would affect the 
> size of the gradient terms the same way.  If the measurements were 
> converted to microseconds all the gradient terms would be multiplied 
> by 1000.
>
> The scaling is to make the quantity being compared to a fixed 
> tolerance dimensionless.  It is a basic principle that only 
> dimensionless quantities can be compared to a fixed tolerance.
>
>
>
>
>     On 11-4-2015 1:51, Daniel McCloy wrote:
>     > -----BEGIN PGP SIGNED MESSAGE-----
>     > Hash: SHA1
>     >
>     > with a model called mod, you can get the relative gradient with
>     >
>     > relgrad <- with(mod at optinfo$derivs, solve(Hessian, gradient))
>     > print(max(abs(relgrad))
>     >
>     > - -- dan
>     >
>     > Daniel McCloy
>     > http://dan.mccloy.info/
>     > Postdoctoral Research Fellow
>     > Institute for Learning and Brain Sciences
>     > University of Washington
>     >
>     >
>     > On 04/10/2015 06:54 PM, Ben Pelzer wrote:
>     >> Dear list,
>     >>
>     >> For a given model in glmer (lme4_1.1-7), I got the warning
>     >> message:
>     >>
>     >> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>     >> control$checkConv,  :
>     >>
>     >> Model failed to converge with max|grad| = 0.0601483 (tol = 0.001,
>     >> component 17)
>     >>
>     >> My model has 15 fixed effects and two (uncorrelated) random
>     >> effects.
>     >>
>     >> There has been a lot of correspondence about convergence issues in
>     >> the recent lme4 version(s) lately, but I cannot easily find what
>     >> measure the "max|grad" is exactly pointing to.  If I'm right, it is
>     >> the "relative gradient" of one of the model parameters, apparantly
>     >> parameter 17. But how exactly is this max|grad calculated? I found
>     >> a command (coming from Ben Bolker):
>     >>
>     >> gg <- model7 at optinfo$derivs$grad
>     >>
>     >> which produces gradients that are much larger than 0.0601483,
>     >> probably since they are "absolute" gradients.
>     >>
>     >> In the book of Schnabel et al. I found a definition of the relative
>     >>   gradient in their equation (7.2.3):
>     >>
>     >> Delta(f) * x  / f
>     >>
>     >> which I believe must be now interpreted as
>     >>
>     >> gradient * parameters estimate by glmer / loglikelihood
>     >>
>     >>
>     >> Is this indeed the formula that is used in lme4 to derive the
>     >> max|grad and is my interpretation of it correct? (I would like to
>     >> reproduce the max|grad value 0.0601483).
>     >>
>     >> And which of the parameters in my model is actually "component 17"
>     >>   (which the warning message refers to)?
>     >>
>     >> Thanks for any help!
>     >>
>     >> Ben Pelzer.
>     >>
>     >>
>     >> *--------------------------.
>     >>
>     >> Below is part of the glmer output and also the result from "gg <-
>     >> model7 at optinfo$derivs$grad"
>     >>
>     >> Generalized linear mixed model fit by maximum likelihood (Laplace
>     >> Approximation) [glmerMod] Family: binomial  ( logit ) Formula:
>     >> bottom10readA ~ 1 + female2 + (-1 + female2 | Country33) + (1 |
>     >> SCHOOLID2) + SES_mean_cen + age_cen + secondgen_mean + native_mean
>     >> + Parliament2013_cen + WLMP_cen + HDI2012_cen + selage_cen + ce +
>     >> ZSTAND2012C + Fselage2 + FCE2 + FZstand_pisa_cen2 Control:
>     >> glmerControl(optimizer = "nloptwrap", optCtrl = list(algorithm =
>     >> "NLOPT_LN_BOBYQA"))
>     >>
>     >> AIC      BIC   logLik deviance df.resid 151434.4 151613.4 -75700.2
>     >> 151400.4   276524
>     >>
>     >> Scaled residuals: Min      1Q  Median      3Q  Max -4.6982
>     >> -0.3104 -0.1819 -0.1126 10.6450
>     >>
>     >> Random effects: Groups    Name        Variance Std.Dev. SCHOOLID2
>     >> (Intercept) 2.314767 1.52144 Country33 female2  0.008527
>     >> 0.09234 Number of obs: 276541, groups:  SCHOOLID2, 10643;
>     >> Country33, 35
>     >>
>     >> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>     >> -2.1629201  0.1006349 -21.493  < 2e-16 *** female2
>     >> -0.4316766  0.0523024  -8.253  < 2e-16 *** SES_mean_cen
>     >> -0.3901277  0.0257537 -15.148  < 2e-16 *** age_cen
>     >> -0.1685527  0.0256951  -6.560 5.39e-11 *** secondgen_mean
>     >> -0.2462713  0.1269396  -1.940   0.0524 . native_mean
>     >> -1.0927106  0.0844515 -12.939  < 2e-16 *** Parliament2013_cen
>     >> -0.0020840  0.0025656  -0.812   0.4166 WLMP_cen
>     >> 0.0002831  0.0027028   0.105   0.9166 HDI2012_cen       -0.0338573
>     >> 0.0600986  -0.563   0.5732 selage_cen 0.0525462  0.0119847
>     >> 4.384 1.16e-05 *** ce                 -0.0902947 0.0496913  -1.817
>     >> 0.0692 . ZSTAND2012C        -0.0457672  0.1760672 -0.260   0.7949
>     >> Fselage2           -0.0092435  0.0096429  -0.959  0.3378 FCE2
>     >> -0.0650998  0.0450328  -1.446   0.1483 FZstand_pisa_cen2
>     >> -0.4586711  0.1497851  -3.062   0.0022 ** --- Signif. codes:  0
>     >> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     >>
>     >>
>     >> And finally the 17 gradients:
>     >>
>     >> gg
>     >>
>     >> [1]  -2.3293884   4.3723284  -5.6278026   0.2851749 1.6813773
>     >> -8.3454128 [7]   4.1930703  -5.1109944  49.0449769 207.5065300
>     >> 20.8115773 -31.4621360 [13]  14.0848733  -3.2661238 -24.9956165
>     >> 7.0817152 -5.9149812
>     >>
>     >>
>     >>
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> _______________________________________________
>     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >>
>     > -----BEGIN PGP SIGNATURE-----
>     > Version: GnuPG v2.0.22 (GNU/Linux)
>     >
>     > iQEcBAEBAgAGBQJVKGIQAAoJEEzlbMQqUVLO8rUH/Al0jlkQJorokVi1eKnmImHC
>     > fFOojbA6HrFZdtqAooueNdc3RroXXhdPLtlhxLgaNye+aaE8dJoe0FBMb94IxJV9
>     > SB8thJyjCfEnuQvLvFFLgkHJYaorjMn/6J1fKz/ci9Ggun8d0abdpkclVcsycDaT
>     > 2BIBMT0qFcHMn8hzKz693xSz1Gfy9d7ggkkdOu0K0i4c/URP3XTjOVbO0Vyv2UIe
>     > Xni7cuPJ9AMN6zzioGgZi3URd10ogOKljKOSLZTF1C8yBURc82w00/zOU8GzGPs8
>     > pQ2SiQpLR9yxMeYZwGCPQ+gG3I3CBuBZxWJBPXFquJWpP5WQhcessyg6bV4YdQ4=
>     > =W9ek
>     > -----END PGP SIGNATURE-----
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From gaiarrido at gmail.com  Sat Apr 11 09:29:14 2015
From: gaiarrido at gmail.com (Mario Garrido)
Date: Sat, 11 Apr 2015 10:29:14 +0300
Subject: [R-sig-ME] Post-hoc test and Cook's distance vs. leverageplot for
 glmer from package lme4
Message-ID: <CABi7Y8YVOo9+Ei_UKLY2+TJ4SQXJ4y1Ng2YJoXVk0-7QqDQwiA@mail.gmail.com>

Hi,

My name's Mario Garrido, a postdoctoral student in Biology. I am relatively
new with r and despite I find it brilliant I am having some difficulties in
finding some functions and interpreting the syntaxes.

At the moment I am working on a GLZM model which fits a Poisson
distribution. I am having some problems with two issues

1.     after calculating Akaike weights, my best model is one including a
4-way interaction term. It is the following:

model7<-glmer(active~ treatment*daytype*time*age+(1|
indiv),family=poisson(link=log),nAGQ=1)

Is there any function or package to perform a Post hoc test to know which
subset of 2- and 3-way interaction terms have more influence on the model?


2.     In addition, I find how to compute Cook's distance both for the
function glmer and for the function lmer using the package influence.ME.
This package also allow to make some graphs but, is there any
package or function to do it and obtain a plot similar to this:
https://climateaudit.files.wordpress.com/2012/09/lew_cooks-distance1.png?



Thanks everybody,



Sincerely,

Mario Garrido

	[[alternative HTML version deleted]]


From mikedulrich at gmail.com  Tue Apr 14 17:36:17 2015
From: mikedulrich at gmail.com (Mike)
Date: Tue, 14 Apr 2015 15:36:17 +0000 (UTC)
Subject: [R-sig-ME] "mixed" MANOVAs
References: <1340989717.33487.YahooMailNeo@web29701.mail.ird.yahoo.com>
Message-ID: <loom.20150414T173518-389@post.gmane.org>

Chapter 16 of Snijders and Bosker 2012 solve the problem
 by creating a dummy variable to represent the different
response variables (Y), stacking the data (see quote on p284), 
and adding an additional level to your model to represent different
response variables within subject.

They include example R code at this site:
http://www.stats.ox.ac.uk/~snijders/ch16.r

And the chapter can be previewed on Google here:
http://goo.gl/865k9t

I tested this approach using univariate data and got nearly 
identical results as a traditional manova.

Hope this helps someone.

Mike Ulrich
PhD Candidate, Moore School of Business


From bbonit at tin.it  Thu Apr 16 09:28:38 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Thu, 16 Apr 2015 09:28:38 +0200 (CEST)
Subject: [R-sig-ME] Wheigts glmmADMB
Message-ID: <14cc1212aeb.bbonit@tin.it>

 Dear list, good morning My question is about glmmADMB.  In particular I'm interested for weights option in glmmadmb function, that if don' t wrong is  implemented.. I need it for propensity score matching that is always more frequently used nowadays.   Ok, one could suggest me to use another package ... but this is the only one ( if i don't wrong) that permit to fit generalized mixed models in R with beta distribution family I need beta distribution for analyzing  healt related quality of life HRQoL, the primary outcame in surgery and in another medicine fields,  also this more frequently used nowadays.  There is possibility to implementing weight option in this glmmadmb function in glmmADMB package? Sorry for noise  Thank in advance Best  Gianluca Bonitta 
	[[alternative HTML version deleted]]


From bbonit at tin.it  Thu Apr 16 21:17:49 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Thu, 16 Apr 2015 21:17:49 +0200 (CEST)
Subject: [R-sig-ME] Weights argument glmmADMB
Message-ID: <14cc3aa705e.bbonit@tin.it>

 Dear list, 
I'm interested to weights argument option in glmmadmb in glmmADMB package.
I will use it for propensity score matching (in different methods  i.e IPW) that nowadays is always more frequently used.
Do You think that will be possible?
Thank You in advance, sorry for noise
Gianluca Bonitta
 
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Apr 16 22:00:36 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 16 Apr 2015 20:00:36 +0000 (UTC)
Subject: [R-sig-ME] Weights argument glmmADMB
References: <14cc3aa705e.bbonit@tin.it>
Message-ID: <loom.20150416T214141-353@post.gmane.org>

bbonit at ... <bbonit at ...> writes:

> 
>  Dear list, 
> I'm interested to weights argument option in glmmadmb in glmmADMB package.
> I will use it for propensity score matching (in different
>  methods  i.e IPW) that nowadays is always more
> frequently used.
> Do You think that will be possible?
> Thank You in advance, sorry for noise
> Gianluca Bonitta

  I assume you're asking something like "what are the chances that
weights will be implemented in glmmADMB sometime soon"?

   Unfortunately, pretty small; there's already a fairly large
backlog of maintenance work on glmmADMB (does anyone want to volunteer
to help out??).  

  You may be able to implement your Beta model directly in 
AD Model Builder, or in WinBUGS/JAGS/Stan (or in SAS PROC NLMIXED ... ??)

  sorry,
   Ben Bolker


From bbolker at gmail.com  Thu Apr 16 22:09:34 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 16 Apr 2015 20:09:34 +0000 (UTC)
Subject: [R-sig-ME] Post-hoc test and Cook's distance vs. leverageplot
	for glmer from package lme4
References: <CABi7Y8YVOo9+Ei_UKLY2+TJ4SQXJ4y1Ng2YJoXVk0-7QqDQwiA@mail.gmail.com>
Message-ID: <loom.20150416T220046-473@post.gmane.org>

Mario Garrido <gaiarrido at ...> writes:

> 
> Hi,
> 
> My name's Mario Garrido, a postdoctoral student in Biology. I am relatively
> new with r and despite I find it brilliant I am having some difficulties in
> finding some functions and interpreting the syntaxes.
> 
> At the moment I am working on a GLZM model which fits a Poisson
> distribution. I am having some problems with two issues
> 
> 1.     after calculating Akaike weights, my best model is one including a
> 4-way interaction term. It is the following:
> 
> model7<-glmer(active~ treatment*daytype*time*age+(1|
> indiv),family=poisson(link=log),nAGQ=1)
> 
> Is there any function or package to perform a Post hoc test to know which
> subset of 2- and 3-way interaction terms have more influence on the model?

  It strikes me that this is a somewhat difficult question 
conceptually, as well as computationally.  How are you dealing
with the issues of marginality?  (See Venables "Exegeses on linear
models", available by internet-searching, for a discussion of
marginality ...)  In other words, how do you define what a
2- or 3-way interaction term means?

 *If* you can define what you mean (e.g. if simply setting the
parameters related to a specific lower-level interaction to zero
makes biological or scientific sense), then you could drop the
terms and look at the difference in AIC or log-likelihood, and
use some sort of multiple comparisons to deal with the post-hocness
of it all.

> 
> 2.     In addition, I find how to compute Cook's distance both for the
> function glmer and for the function lmer using the package influence.ME.
> This package also allow to make some graphs but, is there any
> package or function to do it and obtain a plot similar to this:
> https://climateaudit.files.wordpress.com/2012/09/lew_cooks-distance1.png?
> 

  Have you found a way to compute (or define) leverage for a GLMM?
(Maybe that's what you're asking for.) 

  Ben Bolker


From bbonit at tin.it  Fri Apr 17 10:00:21 2015
From: bbonit at tin.it (bbonit at tin.it)
Date: Fri, 17 Apr 2015 10:00:21 +0200 (CEST)
Subject: [R-sig-ME] Weights argument glmmADMB
Message-ID: <14cc66491d5.bbonit@tin.it>

 Sigh :-( 
 Thank you for replay professor Bolker.
 Best
 Gianluca Bonitta 
 
	[[alternative HTML version deleted]]


From joseph.bulbulia at icloud.com  Fri Apr 17 10:34:19 2015
From: joseph.bulbulia at icloud.com (Joseph Bulbulia)
Date: Fri, 17 Apr 2015 08:34:19 +0000 (GMT)
Subject: [R-sig-ME] Weights argument glmmADMB
In-Reply-To: <14cc66491d5.bbonit@tin.it>
References: <14cc66491d5.bbonit@tin.it>
Message-ID: <bd6a2271373c4306a1d96b2fcdb428a0@mailboxapp.com>

No, happy faces! ? ?thanks Ben for producing and maintaining such extraordinary software, free of charge, and beyond that, for the time you put into educating us here, ?at?http://glmm.wikidot.com/faq,?in your freely available publications, all over the place over really. I only wish I had the skills to chip in. This is the sensibility most of us have here, I imagine.

?

http://www.victoria.ac.nz/sacr/about/staff/joseph-bulbulia

www.nzvalues.org

www.abodeofthegods.org

On Fri, Apr 17, 2015 at 8:03 PM, bbonit at tin.it <bbonit at tin.it> wrote:

>  Sigh :-( 
>  Thank you for replay professor Bolker.
>  Best
>  Gianluca Bonitta 
>  
> 	[[alternative HTML version deleted]]
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
	[[alternative HTML version deleted]]


From m_garrido69 at hotmail.com  Sun Apr 19 09:05:39 2015
From: m_garrido69 at hotmail.com (Mario Garrido)
Date: Sun, 19 Apr 2015 10:05:39 +0300
Subject: [R-sig-ME] Post-hoc test and Cook's distance vs. leverageplot
 for glmer from package lme4
In-Reply-To: <loom.20150416T220046-473@post.gmane.org>
References: <CABi7Y8YVOo9+Ei_UKLY2+TJ4SQXJ4y1Ng2YJoXVk0-7QqDQwiA@mail.gmail.com>
	<loom.20150416T220046-473@post.gmane.org>
Message-ID: <CABi7Y8Z8hkRDZ4ijcG6RkU7hu1V_Y9dj+zER6aFO1thGJHjjRw@mail.gmail.com>

Hi,
thanks for the responses. I will explore in deep what both of you say.
I will be back once I got an answer...or more questions!




2015-04-16 23:09 GMT+03:00 Ben Bolker <bbolker at gmail.com>:

> Mario Garrido <gaiarrido at ...> writes:
>
> >
> > Hi,
> >
> > My name's Mario Garrido, a postdoctoral student in Biology. I am
> relatively
> > new with r and despite I find it brilliant I am having some difficulties
> in
> > finding some functions and interpreting the syntaxes.
> >
> > At the moment I am working on a GLZM model which fits a Poisson
> > distribution. I am having some problems with two issues
> >
> > 1.     after calculating Akaike weights, my best model is one including a
> > 4-way interaction term. It is the following:
> >
> > model7<-glmer(active~ treatment*daytype*time*age+(1|
> > indiv),family=poisson(link=log),nAGQ=1)
> >
> > Is there any function or package to perform a Post hoc test to know which
> > subset of 2- and 3-way interaction terms have more influence on the
> model?
>
>   It strikes me that this is a somewhat difficult question
> conceptually, as well as computationally.  How are you dealing
> with the issues of marginality?  (See Venables "Exegeses on linear
> models", available by internet-searching, for a discussion of
> marginality ...)  In other words, how do you define what a
> 2- or 3-way interaction term means?
>
>  *If* you can define what you mean (e.g. if simply setting the
> parameters related to a specific lower-level interaction to zero
> makes biological or scientific sense), then you could drop the
> terms and look at the difference in AIC or log-likelihood, and
> use some sort of multiple comparisons to deal with the post-hocness
> of it all.
>
> >
> > 2.     In addition, I find how to compute Cook's distance both for the
> > function glmer and for the function lmer using the package influence.ME.
> > This package also allow to make some graphs but, is there any
> > package or function to do it and obtain a plot similar to this:
> > https://climateaudit.files.wordpress.com/2012/09/lew_cooks-distance1.png
> ?
> >
>
>   Have you found a way to compute (or define) leverage for a GLMM?
> (Maybe that's what you're asking for.)
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

From Michelle.Gosse at foodstandards.gov.au  Tue Apr 21 22:14:22 2015
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Tue, 21 Apr 2015 20:14:22 +0000
Subject: [R-sig-ME] mixed effect models where time ordering is important
Message-ID: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>

Hi all,

I have repeated measures weight data on rats who were in a 28-day toxin study. I have one control group and the toxin was administered at one of three doses (low, medium, high). This is not a cross-over design, so (for example) the rats who were in the low dose group always got the low dose over the course of the study.

The rats were not fully grown when the study started. Body weights were measured every fourth day.

The interest is in seeing if the toxin has an influence on body weight. I am looking at using lmer to analyse this data, however I am unsure how to handle the ordering of time, as this will be correlated with increasing body weight.

If I did not have to worry about time ordering, I thought this model would work:

Weight ~ dose + (1|subject)

The doses are being treated as fixed effects as I am not wanting to extrapolate the impact of dose beyond what was administered in the study.

I was wondering if the appropriate model for my data would be:

Weight ~ dose * time + (1|subject)

However, time is measured as days from initial dose administration (e.g. day 1 = first day of dosing). While the rats are all very similar in age, I do not believe they were all born on the same day, and so I am unsure about time as a proxy for age (assuming an intercept in the model). And day is measured discontinuously (every fourth day). I feel that omitting day will remove one obvious explanatory variable from the model, which may bias the results as well as producing a model that poorly fits the data.

I have tried to find an example of a toxicology study that uses a mixed effects model in R on repeated measures, that specifies the model. I have been unable to locate one.

I would appreciate any advice/recommendations on how to handle this data. I have already advised that a series of separate ANOVAs are not statistically defensible given that the weights are likely to be auto-correlated and the statistical analysis needs to account for this.

Cheers
Michelle, note: I do not work Fridays


**********************************************************************
This email and any files transmitted with it are confide...{{dropped:12}}


From john.maindonald at anu.edu.au  Tue Apr 21 22:35:16 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 21 Apr 2015 20:35:16 +0000
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
References: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
Message-ID: <3FC91029-446B-4EAF-A28E-EFD2FC469070@anu.edu.au>

A quick initial response!  The starting point needs to be plots of weight vs time
for each rat separately, distinguished by treatment group.  These may not be
linear.  You may want to look at log(weight) vs time.  You may need to transform
the time scale to get something close to linear.  Sort out the error structure 
(is there a consistent difference in the pattern of change with time?) once you 
have a reasonable model for the pattern of change with time, for individual mice, 
perhaps somewhat separately for each dose.

John Maindonald             email: john.maindonald at anu.edu.au


> On 22/04/2015, at 08:14, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> 
> Hi all,
> 
> I have repeated measures weight data on rats who were in a 28-day toxin study. I have one control group and the toxin was administered at one of three doses (low, medium, high). This is not a cross-over design, so (for example) the rats who were in the low dose group always got the low dose over the course of the study.
> 
> The rats were not fully grown when the study started. Body weights were measured every fourth day.
> 
> The interest is in seeing if the toxin has an influence on body weight. I am looking at using lmer to analyse this data, however I am unsure how to handle the ordering of time, as this will be correlated with increasing body weight.
> 
> If I did not have to worry about time ordering, I thought this model would work:
> 
> Weight ~ dose + (1|subject)
> 
> The doses are being treated as fixed effects as I am not wanting to extrapolate the impact of dose beyond what was administered in the study.
> 
> I was wondering if the appropriate model for my data would be:
> 
> Weight ~ dose * time + (1|subject)
> 
> However, time is measured as days from initial dose administration (e.g. day 1 = first day of dosing). While the rats are all very similar in age, I do not believe they were all born on the same day, and so I am unsure about time as a proxy for age (assuming an intercept in the model). And day is measured discontinuously (every fourth day). I feel that omitting day will remove one obvious explanatory variable from the model, which may bias the results as well as producing a model that poorly fits the data.
> 
> I have tried to find an example of a toxicology study that uses a mixed effects model in R on repeated measures, that specifies the model. I have been unable to locate one.
> 
> I would appreciate any advice/recommendations on how to handle this data. I have already advised that a series of separate ANOVAs are not statistically defensible given that the weights are likely to be auto-correlated and the statistical analysis needs to account for this.
> 
> Cheers
> Michelle, note: I do not work Fridays
> 
> 
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:12}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From johannabradie at hotmail.com  Tue Apr 21 22:54:52 2015
From: johannabradie at hotmail.com (Johanna Bradie Simpkins)
Date: Tue, 21 Apr 2015 16:54:52 -0400
Subject: [R-sig-ME] GLMM Power Analysis
In-Reply-To: <BLU173-W731F8681211DB9E5B862DBBEF0@phx.gbl>
References: <BLU173-W731F8681211DB9E5B862DBBEF0@phx.gbl>
Message-ID: <BLU173-W201D6361A23C5F56E9B652BBEF0@phx.gbl>

I am attempting to do a simulation-based power analysis for
a study I will be conducting which will be analysed using GLMM.  

 

My study will focus on assessing different sampling and
analytic techniques for evaluating the number of individuals present in a water sample.  I will focus on two size classes of organisms: large and small.  For
the large size class, I will be analyzing 3 different sampling devices and 6
analytic techniques.  Devices can only be tested in pairs but the analytic
techniques will all be used with 3 replicate subsamples for each sample. 
For the small size class, I will not be testing a sampling device but
instead looking at the number of individuals present before and after
treatment.  For this size class, I have 10 different analytic techniques
which will be run in triplicate for each sample. The experiment will be conducted in the field, so the number of individuals actually present in the water will vary between trials. 

 

I understand how to implement the example given on the R
GLMM help page.  The stumbling block that I am having is that
I expect that there will be an interaction between my fixed effects (analytic methods
and sampling methods (where applicable)) and the random effect for trial (which
will affect the number of individuals actually present in the sample). 
For example, I anticipate that rather than each analytic device missing a set
number of individuals, each device will capture a given proportion of the
individuals present in the trial (e.g. 90%, 80%, 70%...).  Similarly, I expect that each sampling device will capture a given proportion of the individuals, so these will be multiplicative (i.e. b0*% captured by sampling device*% measured by analytic device).  
I am
not sure how to set up  the GLMM for the power analysis
in this case or how to look at the power when there are so many devices (i.e.
is that trial ?significant? if just 1 device is significantly different, or should
differences for all devices be significant?).

 Based on the GLMM help page, I have constructed the following for a simple version (6 analytic methods, no sampling devices, no treatment).  However, I am not sure if I am violating assumptions by setting it up in this way or whether I am pulling the appropriate statistics given the large number of devices that I am testing (i.e. is any significant effect of method the best statistic to look at?).  Any comments, assistance, or helpful resources would be very much appreciated. 
---------------------------------------------------------------------------------------------------------------------------------------------------------------
sim1 <- function(b0=1000,                 bmethod2=0.9,bmethod3=0.8,bmethod4=0.7,bmethod5=0.85,bmethod6=0.9,                 vtrial=10000, vsample=25, Verror=20) {  trial <- rep( 1:30, each=3*6)  replicate<-rep(c(1,2,3),length.out=30*6*3)  sample<-rep(1:180,each=3)  method<-rep(rep(1:6,each=3),length.out=540)    t.re <- rpois(30, sqrt(vtrial))   # random effects per trial  S.re <- rpois(180, sqrt(vsample))   # random effects per sample  eps <- rpois(30*18, sqrt(Verror))  # epsilons    # put it all together  Number <- b0 *     (1*(method=="1")+bmethod2*(method=="2") + bmethod3*(method=="3") +    bmethod4*(method=="4") + bmethod5*(method=="5")+    bmethod6*(method=="6")) +    S.re[sample] + t.re[trial] + eps    # put into a data frame  mydata <<- data.frame( trial = trial,                         replicate=paste('r',replicate, sep=''),                        sample=sample,                         method=method,                        Number = Number)
  mydata$trial=as.factor(mydata$trial)  mydata$method=as.factor(mydata$method)  mydata$sample=as.factor(mydata$sample)
  #look at whether difference in methods is detected  fit1 <- glmer( Number ~ method+ (1|trial)+ (1|sample), data=mydata, family="poisson")  fit2 <- glmer( Number ~ (1|trial)+ (1|sample), data=mydata,family="poisson")  anova(fit2,fit1)[2,8]}
out1 <- replicate( 100, {setWinProgressBar(pb, getWinProgressBar(pb)+1);                         sim1( bSex=10, bFreq=2, bSF=0.25, Vsub=4000, Vword=2500, Verror=10000)})hist(out1)mean( out1 < 0.05 )





 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From Michelle.Gosse at foodstandards.gov.au  Tue Apr 21 23:21:40 2015
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Tue, 21 Apr 2015 21:21:40 +0000
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <3FC91029-446B-4EAF-A28E-EFD2FC469070@anu.edu.au>
References: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
	<3FC91029-446B-4EAF-A28E-EFD2FC469070@anu.edu.au>
Message-ID: <D5ED07A4EA222E42AF840A9EEF26488001546898FB@FSEXMBX02.foodstandards.gov.au>

Thanks John,

I'll follow that approach,  and also see if the resulting error structure fits logically with the biology, in particular with the control groups.

Cheers
Michelle, note: I do not work Fridays


-----Original Message-----
From: John Maindonald [mailto:john.maindonald at anu.edu.au] 
Sent: Wednesday, 22 April 2015 8:35 AM
To: Gosse, Michelle
Cc: R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] mixed effect models where time ordering is important

A quick initial response!  The starting point needs to be plots of weight vs time for each rat separately, distinguished by treatment group.  These may not be linear.  You may want to look at log(weight) vs time.  You may need to transform the time scale to get something close to linear.  Sort out the error structure (is there a consistent difference in the pattern of change with time?) once you have a reasonable model for the pattern of change with time, for individual mice, perhaps somewhat separately for each dose.

John Maindonald             email: john.maindonald at anu.edu.au


> On 22/04/2015, at 08:14, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au> wrote:
> 
> Hi all,
> 
> I have repeated measures weight data on rats who were in a 28-day toxin study. I have one control group and the toxin was administered at one of three doses (low, medium, high). This is not a cross-over design, so (for example) the rats who were in the low dose group always got the low dose over the course of the study.
> 
> The rats were not fully grown when the study started. Body weights were measured every fourth day.
> 
> The interest is in seeing if the toxin has an influence on body weight. I am looking at using lmer to analyse this data, however I am unsure how to handle the ordering of time, as this will be correlated with increasing body weight.
> 
> If I did not have to worry about time ordering, I thought this model would work:
> 
> Weight ~ dose + (1|subject)
> 
> The doses are being treated as fixed effects as I am not wanting to extrapolate the impact of dose beyond what was administered in the study.
> 
> I was wondering if the appropriate model for my data would be:
> 
> Weight ~ dose * time + (1|subject)
> 
> However, time is measured as days from initial dose administration (e.g. day 1 = first day of dosing). While the rats are all very similar in age, I do not believe they were all born on the same day, and so I am unsure about time as a proxy for age (assuming an intercept in the model). And day is measured discontinuously (every fourth day). I feel that omitting day will remove one obvious explanatory variable from the model, which may bias the results as well as producing a model that poorly fits the data.
> 
> I have tried to find an example of a toxicology study that uses a mixed effects model in R on repeated measures, that specifies the model. I have been unable to locate one.
> 
> I would appreciate any advice/recommendations on how to handle this data. I have already advised that a series of separate ANOVAs are not statistically defensible given that the weights are likely to be auto-correlated and the statistical analysis needs to account for this.
> 
> Cheers
> Michelle, note: I do not work Fridays
> 
> 
> **********************************************************************
> This email and any files transmitted with it are 
> confide...{{dropped:12}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


**********************************************************************
This email and any files transmitted with it are confide...{{dropped:9}}


From tim.cole at ucl.ac.uk  Wed Apr 22 13:12:27 2015
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Wed, 22 Apr 2015 11:12:27 +0000
Subject: [R-sig-ME] mixed effect models where time ordering is important
Message-ID: <D15D3C90.D27E%tim.cole@ucl.ac.uk>

Michelle,

You may like to try my sitar growth curve model (see CRAN sitar package, based on nlme). It estimates a mean growth curve as a B-spline, assuming that each individual growth curve differs from the average in three respects - a random intercept on the weight scale, and two random effects on the age scale, location and scale. This matches the biology of individuals growing at different rates, which arise from differences on both the weight and time scales. A multiplicative (i.e. log) age scale makes best sense biologically.

The random effects have associated fixed effects which can also be modelled, e.g. to include the effect of the toxin. So for example rats with the toxin may be developmentally delayed, so the age scale is stretched relative to that for the control group.

Note that to avoid confounding of the random intercepts on the weight and age scales, the mean growth curve needs to be nonlinear. If that does not hold, the age location random effect can be dropped.

Best wishes,
Tim
---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK

Date: Tue, 21 Apr 2015 21:21:40 +0000
From: "Gosse, Michelle" <Michelle.Gosse at foodstandards.gov.au<mailto:Michelle.Gosse at foodstandards.gov.au>>
To: "'John Maindonald'" <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>>
Cc: "R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>"
<R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] mixed effect models where time ordering is
important
Thanks John,

I'll follow that approach,  and also see if the resulting error structure fits logically with the biology, in particular with the control groups.

Cheers
Michelle, note: I do not work Fridays

-----Original Message-----
From: John Maindonald [mailto:john.maindonald at anu.edu.au]
Sent: Wednesday, 22 April 2015 8:35 AM
To: Gosse, Michelle
Cc: R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] mixed effect models where time ordering is important

A quick initial response!  The starting point needs to be plots of weight vs time for each rat separately, distinguished by treatment group.  These may not be linear.  You may want to look at log(weight) vs time.  You may need to transform the time scale to get something close to linear.  Sort out the error structure (is there a consistent difference in the pattern of change with time?) once you have a reasonable model for the pattern of change with time, for individual mice, perhaps somewhat separately for each dose.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 22/04/2015, at 08:14, Gosse, Michelle <Michelle.Gosse at foodstandards.gov.au<mailto:Michelle.Gosse at foodstandards.gov.au>> wrote:
Hi all,
I have repeated measures weight data on rats who were in a 28-day toxin study. I have one control group and the toxin was administered at one of three doses (low, medium, high). This is not a cross-over design, so (for example) the rats who were in the low dose group always got the low dose over the course of the study.
The rats were not fully grown when the study started. Body weights were measured every fourth day.
The interest is in seeing if the toxin has an influence on body weight. I am looking at using lmer to analyse this data, however I am unsure how to handle the ordering of time, as this will be correlated with increasing body weight.
If I did not have to worry about time ordering, I thought this model would work:
Weight ~ dose + (1|subject)
The doses are being treated as fixed effects as I am not wanting to extrapolate the impact of dose beyond what was administered in the study.
I was wondering if the appropriate model for my data would be:
Weight ~ dose * time + (1|subject)
However, time is measured as days from initial dose administration (e.g. day 1 = first day of dosing). While the rats are all very similar in age, I do not believe they were all born on the same day, and so I am unsure about time as a proxy for age (assuming an intercept in the model). And day is measured discontinuously (every fourth day). I feel that omitting day will remove one obvious explanatory variable from the model, which may bias the results as well as producing a model that poorly fits the data.
I have tried to find an example of a toxicology study that uses a mixed effects model in R on repeated measures, that specifies the model. I have been unable to locate one.
I would appreciate any advice/recommendations on how to handle this data. I have already advised that a series of separate ANOVAs are not statistically defensible given that the weights are likely to be auto-correlated and the statistical analysis needs to account for this.
Cheers
Michelle, note: I do not work Fridays


	[[alternative HTML version deleted]]


From burwood70 at gmail.com  Wed Apr 22 13:16:09 2015
From: burwood70 at gmail.com (Steve Candy)
Date: Wed, 22 Apr 2015 21:16:09 +1000
Subject: [R-sig-ME] mixed effect models where time ordering is important
Message-ID: <00c301d07ced$bec79a70$3c56cf50$@gmail.com>

Michelle

 

If variation in initial weights is of concern you could use periodic growth
(i.e. first differences in weight) as the response variable. Also you could
fit cubic regression splines in time for each toxin level and control
specified as a 4-level factor (dose_f) combined with residual plots for each
animal to detect departures from the average shape of the time response for
each factor level. Something like

 

library(mgcv)

 

gamm_01 <- gamm(formula = log(Weight) ~ dose_f + s(time, by=dose_f,
bs="cr"), data=data, random=list(subject=~1),  

     correlation=corCAR1(form= ~ time | subject))

 

or replace Weight with Growth ={Weight(time_i+1)-Weight(time_i)}.

To model the dose response component and assuming a common time response
shape on the log scale you might want to consider; 1). specify a dummy (1,0)
for Control (0) vs Dosed (1) as "NotContr_d" (i.e. the intercept gives the
control intercept), 2). LogDose  is set to zero for the control and is the
log of the actual dose (low, medium, high) for the dosed treatments, and
define Control_f <- as.factor(NotContr_d)  then 3). replace the above gamm
with

 

gamm_01 <- gamm(formula = log(Weight) ~ NotContr_d + LogDose + s(time,
by=Control_f, bs="cr"), data=data, random=list(subject=~1),  

     correlation=corCAR1(form= ~ time | subject))

 

The log transforms used above are just suggestions which can be compared to
using raw Weights or Doses.

 

 

> Hi all,

> 

> I have repeated measures weight data on rats who were in a 28-day toxin
study. I have one control group and the toxin was administered at one of
three doses (low, medium, high). This is not a cross-over design, so (for
example) the rats who were in the low dose group always got the low dose
over the course of the study.

> 

> The rats were not fully grown when the study started. Body weights were
measured every fourth day.

> 

> The interest is in seeing if the toxin has an influence on body weight. I
am looking at using lmer to analyse this data, however I am unsure how to
handle the ordering of time, as this will be correlated with increasing body
weight.

> 

> If I did not have to worry about time ordering, I thought this model would
work:

> 

> Weight ~ dose + (1|subject)

> 

> The doses are being treated as fixed effects as I am not wanting to
extrapolate the impact of dose beyond what was administered in the study.

> 

> I was wondering if the appropriate model for my data would be:

> 

> Weight ~ dose * time + (1|subject)

> 

> However, time is measured as days from initial dose administration (e.g.
day 1 = first day of dosing). While the rats are all very similar in age, I
do not believe they were all born on the same day, and so I am unsure about
time as a proxy for age (assuming an intercept in the model). And day is
measured discontinuously (every fourth day). I feel that omitting day will
remove one obvious explanatory variable from the model, which may bias the
results as well as producing a model that poorly fits the data.

> 

> I have tried to find an example of a toxicology study that uses a mixed
effects model in R on repeated measures, that specifies the model. I have
been unable to locate one.

> 

> I would appreciate any advice/recommendations on how to handle this data.
I have already advised that a series of separate ANOVAs are not
statistically defensible given that the weights are likely to be
auto-correlated and the statistical analysis needs to account for this.

> 

> Cheers

> Michelle, note: I do not work Fridays

 

Dr Steven G. Candy

Director/Consultant

SCANDY STATISTICAL MODELLING PTY LTD

(ABN: 83 601 268 419)

70 Burwood Drive

Blackmans Bay, TASMANIA, Australia 7052

Mobile: (61) 0439284983

 


	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Wed Apr 22 13:42:21 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 22 Apr 2015 13:42:21 +0200
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <00c301d07ced$bec79a70$3c56cf50$@gmail.com>
References: <00c301d07ced$bec79a70$3c56cf50$@gmail.com>
Message-ID: <20150422114221.GE10214@info124.pharmacie.univ-paris5.fr>

I'm confused by the second model, the LogDose = 0 if control seems
strange to me. How does it distinguish, in the intercept term, the
? control ? (0 + 0) and ? dose = 10^-1 ? (1 + -1) groups? And if the
intercept is monotonic with dose, wouldn't be an annoyance to have the
? dose = 0 ? just somewhere between other points, depending on the
exact doses used (and the log basis and the unit used...)?

On Wed, Apr 22, 2015 at 09:16:09PM +1000, Steve Candy wrote:

? To model the dose response component and assuming a common time response
? shape on the log scale you might want to consider; 1). specify a dummy (1,0)
? for Control (0) vs Dosed (1) as "NotContr_d" (i.e. the intercept gives the
? control intercept), 2). LogDose  is set to zero for the control and is the
? log of the actual dose (low, medium, high) for the dosed treatments, and
? define Control_f <- as.factor(NotContr_d)  then 3). replace the above gamm
? with
? 
?  
? 
? gamm_01 <- gamm(formula = log(Weight) ~ NotContr_d + LogDose + s(time,
? by=Control_f, bs="cr"), data=data, random=list(subject=~1),  
? 
?      correlation=corCAR1(form= ~ time | subject))
? 
?  
? 
? The log transforms used above are just suggestions which can be compared to
? using raw Weights or Doses.
? 
?  
? 
?  
? 
? > Hi all,
? 
? > 
? 
? > I have repeated measures weight data on rats who were in a 28-day toxin
? study. I have one control group and the toxin was administered at one of
? three doses (low, medium, high). This is not a cross-over design, so (for
? example) the rats who were in the low dose group always got the low dose
? over the course of the study.
? 
? > 
? 
? > The rats were not fully grown when the study started. Body weights were
? measured every fourth day.
? 
? > 
? 
? > The interest is in seeing if the toxin has an influence on body weight. I
? am looking at using lmer to analyse this data, however I am unsure how to
? handle the ordering of time, as this will be correlated with increasing body
? weight.
? 
? > 
? 
? > If I did not have to worry about time ordering, I thought this model would
? work:
? 
? > 
? 
? > Weight ~ dose + (1|subject)
? 
? > 
? 
? > The doses are being treated as fixed effects as I am not wanting to
? extrapolate the impact of dose beyond what was administered in the study.
? 
? > 
? 
? > I was wondering if the appropriate model for my data would be:
? 
? > 
? 
? > Weight ~ dose * time + (1|subject)
? 
? > 
? 
? > However, time is measured as days from initial dose administration (e.g.
? day 1 = first day of dosing). While the rats are all very similar in age, I
? do not believe they were all born on the same day, and so I am unsure about
? time as a proxy for age (assuming an intercept in the model). And day is
? measured discontinuously (every fourth day). I feel that omitting day will
? remove one obvious explanatory variable from the model, which may bias the
? results as well as producing a model that poorly fits the data.
? 
? > 
? 
? > I have tried to find an example of a toxicology study that uses a mixed
? effects model in R on repeated measures, that specifies the model. I have
? been unable to locate one.
? 
? > 
? 
? > I would appreciate any advice/recommendations on how to handle this data.
? I have already advised that a series of separate ANOVAs are not
? statistically defensible given that the weights are likely to be
? auto-correlated and the statistical analysis needs to account for this.
? 
? > 
? 
? > Cheers
? 
? > Michelle, note: I do not work Fridays
? 
?  
? 
? Dr Steven G. Candy
? 
? Director/Consultant
? 
? SCANDY STATISTICAL MODELLING PTY LTD
? 
? (ABN: 83 601 268 419)
? 
? 70 Burwood Drive
? 
? Blackmans Bay, TASMANIA, Australia 7052
? 
? Mobile: (61) 0439284983
? 
?  
? 
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From burwood70 at gmail.com  Wed Apr 22 14:18:10 2015
From: burwood70 at gmail.com (Steve Candy)
Date: Wed, 22 Apr 2015 22:18:10 +1000
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <20150422114221.GE10214@info124.pharmacie.univ-paris5.fr>
References: <00c301d07ced$bec79a70$3c56cf50$@gmail.com>
	<20150422114221.GE10214@info124.pharmacie.univ-paris5.fr>
Message-ID: <00f501d07cf6$690308f0$3b091ad0$@gmail.com>

There is an intercept parameter, say beta0, then there is a beta1 parameter
associated with the regressor variable NotContr_d  (even though it's a dummy
variable), then there is a beta2 parameter for the regressor LogDose. The
control and dosed treatments have separate spline shapes and due to the
loglinear form of the model the product of 

exp(beta0+beta1)*exp(beta2*LogDose)*exp(s(time, Control_f=="1"))

gives the dose-time response for Weight for the dosed treatments.

For these dosed treatments this allows varying trajectories for Weight but
strictly according to this common shape model. The control time response
curve is

exp(beta0)*exp(s(time, Control_f=="0")). 

Therefore setting LogDose to zero for the Control makes sure this term does
not contribute to the predicted response since beta2*0=0. Note that beta1
takes care of the fact that LogDose for  a dosed treatment may be less than
zero i.e. one could always scale the Doses up by a constant so that LogDose
is always positive and this would have a complementary effect on beta1.

Note that "log(.)" is the natural not base10 logarithm.

See as an example Table 1 of the paper below in a toxicological application
that models survival rather than weight growth.

Hope that is clearer.

Modelling grouped survival times in toxicological studies using Generalized
Additive Models . Environmental and Ecological Statistics. DOI
10.1007/s10651-014-0306-3

On Wednesday, 22 April 2015 9:42 PM, Emmanuel Curis wrote:

>I'm confused by the second model, the LogDose = 0 if control seems strange
to me. How does it distinguish, in the intercept term, the < control > (0 +
0) and < dose = 10^-1 > (1 + -1) groups? And if the intercept is monotonic >
>with dose, wouldn't be an annoyance to have the < dose = 0 > just somewhere
between other points, depending on the exact doses used (and the log basis
and the unit used...)?

>On Wed, Apr 22, 2015 at 09:16:09PM +1000, Steve Candy wrote:

< To model the dose response component and assuming a common time response <
shape on the log scale you might want to consider; 1). specify a dummy (1,0)
< for Control (0) vs Dosed (1) as "NotContr_d" (i.e. the intercept gives the
< control intercept), 2). LogDose  is set to zero for the control and is the
< log of the actual dose (low, medium, high) for the dosed treatments, and <
define Control_f <- as.factor(NotContr_d)  then 3). replace the above gamm <
with < < < < gamm_01 <- gamm(formula = log(Weight) ~ NotContr_d + LogDose +
s(time, < by=Control_f, bs="cr"), data=data, random=list(subject=~1), < 
<      correlation=corCAR1(form= ~ time | subject))
<
<
<
< The log transforms used above are just suggestions which can be compared
to < using raw Weights or Doses.
<
<
<
<
<
< > Hi all,
<
< >
<
< > I have repeated measures weight data on rats who were in a 28-day toxin
< study. I have one control group and the toxin was administered at one of <
three doses (low, medium, high). This is not a cross-over design, so (for <
example) the rats who were in the low dose group always got the low dose <
over the course of the study.
<
< >
<
< > The rats were not fully grown when the study started. Body weights were
< measured every fourth day.
<
< >
<
< > The interest is in seeing if the toxin has an influence on body weight.
I < am looking at using lmer to analyse this data, however I am unsure how
to < handle the ordering of time, as this will be correlated with increasing
body < weight.
<
< >
<
< > If I did not have to worry about time ordering, I thought this model
would < work:
<
< >
<
< > Weight ~ dose + (1|subject)
<
< >
<
< > The doses are being treated as fixed effects as I am not wanting to <
extrapolate the impact of dose beyond what was administered in the study.
<
< >
<
< > I was wondering if the appropriate model for my data would be:
<
< >
<
< > Weight ~ dose * time + (1|subject)
<
< >
<
< > However, time is measured as days from initial dose administration (e.g.
< day 1 = first day of dosing). While the rats are all very similar in age,
I < do not believe they were all born on the same day, and so I am unsure
about < time as a proxy for age (assuming an intercept in the model). And
day is < measured discontinuously (every fourth day). I feel that omitting
day will < remove one obvious explanatory variable from the model, which may
bias the < results as well as producing a model that poorly fits the data.
<
< >
<
< > I have tried to find an example of a toxicology study that uses a mixed
< effects model in R on repeated measures, that specifies the model. I have
< been unable to locate one.
<
< >
<
< > I would appreciate any advice/recommendations on how to handle this
data.
< I have already advised that a series of separate ANOVAs are not <
statistically defensible given that the weights are likely to be <
auto-correlated and the statistical analysis needs to account for this.
<
< >
<
< > Cheers
<
< > Michelle, note: I do not work Fridays < < < < Dr Steven G. Candy < <
Director/Consultant < < SCANDY STATISTICAL MODELLING PTY LTD < < (ABN: 83
601 268 419) < < 70 Burwood Drive < < Blackmans Bay, TASMANIA, Australia
7052 < < Mobile: (61) 0439284983 < < < < 
< 	[[alternative HTML version deleted]]
<
< _______________________________________________
< R-sig-mixed-models at r-project.org mailing list <
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From pierces1 at msu.edu  Wed Apr 22 14:31:56 2015
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 22 Apr 2015 08:31:56 -0400
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
References: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
Message-ID: <000001d07cf8$524a0260$f6de0720$@msu.edu>

Michelle,

This looks like a fairly straightforward growth curve modeling problem. The first half of the Singer & Willett (2003) book is an excellent source on using mixed effects models for these sorts of analyses. You can describe each rat's individual longitudinal trajectory for weight in terms of starting weight (intercept) plus parameters that describe the shape of the trajectory over time (e.g., slope if the trajectory is linear). All of those parameters may vary across rats, but should also have some average value that describes a "typical" trajectory. If you introduce dose as a categorical variable, you can allow dose to predict parameters of the individual rats' trajectories, essentially allowing you to compare the average trajectories across the dose groups. You may want to consider allowing the time slope to vary across rats, as in the formula Weight ~ dose * time + (time + 1|subject).

You should also consider non-linear shapes for the trajectory. Right now, assuming time is a continuous variable, you appear to be considering only linear trends. You could account for the variation in age at the start of the trial by carefully considering how you code time. See Singer & Willett for excellent coverage of various methodological details that are relevant. 

Singer, J. D., & Willett, J. B. (2003). Applied longitudinal data analysis: Modeling change and event occurrence. New York, NY: Oxford University Press.


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Gosse, Michelle [mailto:Michelle.Gosse at foodstandards.gov.au] 
Sent: Tuesday, April 21, 2015 4:14 PM
To: 'R-sig-mixed-models at r-project.org'
Subject: [R-sig-ME] mixed effect models where time ordering is important

Hi all,

I have repeated measures weight data on rats who were in a 28-day toxin study. I have one control group and the toxin was administered at one of three doses (low, medium, high). This is not a cross-over design, so (for example) the rats who were in the low dose group always got the low dose over the course of the study.

The rats were not fully grown when the study started. Body weights were measured every fourth day.

The interest is in seeing if the toxin has an influence on body weight. I am looking at using lmer to analyse this data, however I am unsure how to handle the ordering of time, as this will be correlated with increasing body weight.

If I did not have to worry about time ordering, I thought this model would work:

Weight ~ dose + (1|subject)

The doses are being treated as fixed effects as I am not wanting to extrapolate the impact of dose beyond what was administered in the study.

I was wondering if the appropriate model for my data would be:

Weight ~ dose * time + (1|subject)

However, time is measured as days from initial dose administration (e.g. day 1 = first day of dosing). While the rats are all very similar in age, I do not believe they were all born on the same day, and so I am unsure about time as a proxy for age (assuming an intercept in the model). And day is measured discontinuously (every fourth day). I feel that omitting day will remove one obvious explanatory variable from the model, which may bias the results as well as producing a model that poorly fits the data.

I have tried to find an example of a toxicology study that uses a mixed effects model in R on repeated measures, that specifies the model. I have been unable to locate one.

I would appreciate any advice/recommendations on how to handle this data. I have already advised that a series of separate ANOVAs are not statistically defensible given that the weights are likely to be auto-correlated and the statistical analysis needs to account for this.

Cheers
Michelle, note: I do not work Fridays


**********************************************************************
This email and any files transmitted with it are confide...{{dropped:12}}


From emmanuel.curis at parisdescartes.fr  Wed Apr 22 15:22:54 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 22 Apr 2015 15:22:54 +0200
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <00f501d07cf6$690308f0$3b091ad0$@gmail.com>
References: <00c301d07ced$bec79a70$3c56cf50$@gmail.com>
	<20150422114221.GE10214@info124.pharmacie.univ-paris5.fr>
	<00f501d07cf6$690308f0$3b091ad0$@gmail.com>
Message-ID: <20150422132254.GG10214@info124.pharmacie.univ-paris5.fr>

I'm sorry if I'm slow, but I don't see how the exponential writing
solves the problem - it's just a rewrite that does not change the
behaviour of the system, since exp is bijective, right?

It is always possible with the first model to fine a given dose such
that gives the same pre-exponential model that the second one. If
treatment has no effect on the shape part, this means that we have a
strong discontinuity at 0 with a singular point having the same value
that another one on the curve --- in other words, it seems that this
assume that, for instance, at low dose subjects grow more slowly than
unexposed, but at high dose they grow more quickly, and somewhere
between the dose has no effect... Of course, this may be compensated
for/hidden by the different spline models, but it seems a strange
assumption, no?

I guess in several situations, the problematic dose exp(-beta1/beta2)
is not observed and may be not in the range of tested doses, so it may
not always be a concern, but may be it can in some circumstances?

On Wed, Apr 22, 2015 at 10:18:10PM +1000, Steve Candy wrote:
? There is an intercept parameter, say beta0, then there is a beta1 parameter
? associated with the regressor variable NotContr_d  (even though it's a dummy
? variable), then there is a beta2 parameter for the regressor LogDose. The
? control and dosed treatments have separate spline shapes and due to the
? loglinear form of the model the product of 
? 
? exp(beta0+beta1)*exp(beta2*LogDose)*exp(s(time, Control_f=="1"))
? 
? gives the dose-time response for Weight for the dosed treatments.
? 
? For these dosed treatments this allows varying trajectories for Weight but
? strictly according to this common shape model. The control time response
? curve is
? 
? exp(beta0)*exp(s(time, Control_f=="0")). 
? 
? Therefore setting LogDose to zero for the Control makes sure this term does
? not contribute to the predicted response since beta2*0=0. Note that beta1
? takes care of the fact that LogDose for  a dosed treatment may be less than
? zero i.e. one could always scale the Doses up by a constant so that LogDose
? is always positive and this would have a complementary effect on beta1.
? 
? Note that "log(.)" is the natural not base10 logarithm.
? 
? See as an example Table 1 of the paper below in a toxicological application
? that models survival rather than weight growth.
? 
? Hope that is clearer.
? 
? Modelling grouped survival times in toxicological studies using Generalized
? Additive Models . Environmental and Ecological Statistics. DOI
? 10.1007/s10651-014-0306-3
? 
? On Wednesday, 22 April 2015 9:42 PM, Emmanuel Curis wrote:
? 
? >I'm confused by the second model, the LogDose = 0 if control seems strange
? to me. How does it distinguish, in the intercept term, the < control > (0 +
? 0) and < dose = 10^-1 > (1 + -1) groups? And if the intercept is monotonic >
? >with dose, wouldn't be an annoyance to have the < dose = 0 > just somewhere
? between other points, depending on the exact doses used (and the log basis
? and the unit used...)?
? 
? >On Wed, Apr 22, 2015 at 09:16:09PM +1000, Steve Candy wrote:
? 
? < To model the dose response component and assuming a common time response <
? shape on the log scale you might want to consider; 1). specify a dummy (1,0)
? < for Control (0) vs Dosed (1) as "NotContr_d" (i.e. the intercept gives the
? < control intercept), 2). LogDose  is set to zero for the control and is the
? < log of the actual dose (low, medium, high) for the dosed treatments, and <
? define Control_f <- as.factor(NotContr_d)  then 3). replace the above gamm <
? with < < < < gamm_01 <- gamm(formula = log(Weight) ~ NotContr_d + LogDose +
? s(time, < by=Control_f, bs="cr"), data=data, random=list(subject=~1), < 
? <      correlation=corCAR1(form= ~ time | subject))
? <
? <
? <
? < The log transforms used above are just suggestions which can be compared
? to < using raw Weights or Doses.
? <
? <
? <
? <
? <
? < > Hi all,
? <
? < >
? <
? < > I have repeated measures weight data on rats who were in a 28-day toxin
? < study. I have one control group and the toxin was administered at one of <
? three doses (low, medium, high). This is not a cross-over design, so (for <
? example) the rats who were in the low dose group always got the low dose <
? over the course of the study.
? <
? < >
? <
? < > The rats were not fully grown when the study started. Body weights were
? < measured every fourth day.
? <
? < >
? <
? < > The interest is in seeing if the toxin has an influence on body weight.
? I < am looking at using lmer to analyse this data, however I am unsure how
? to < handle the ordering of time, as this will be correlated with increasing
? body < weight.
? <
? < >
? <
? < > If I did not have to worry about time ordering, I thought this model
? would < work:
? <
? < >
? <
? < > Weight ~ dose + (1|subject)
? <
? < >
? <
? < > The doses are being treated as fixed effects as I am not wanting to <
? extrapolate the impact of dose beyond what was administered in the study.
? <
? < >
? <
? < > I was wondering if the appropriate model for my data would be:
? <
? < >
? <
? < > Weight ~ dose * time + (1|subject)
? <
? < >
? <
? < > However, time is measured as days from initial dose administration (e.g.
? < day 1 = first day of dosing). While the rats are all very similar in age,
? I < do not believe they were all born on the same day, and so I am unsure
? about < time as a proxy for age (assuming an intercept in the model). And
? day is < measured discontinuously (every fourth day). I feel that omitting
? day will < remove one obvious explanatory variable from the model, which may
? bias the < results as well as producing a model that poorly fits the data.
? <
? < >
? <
? < > I have tried to find an example of a toxicology study that uses a mixed
? < effects model in R on repeated measures, that specifies the model. I have
? < been unable to locate one.
? <
? < >
? <
? < > I would appreciate any advice/recommendations on how to handle this
? data.
? < I have already advised that a series of separate ANOVAs are not <
? statistically defensible given that the weights are likely to be <
? auto-correlated and the statistical analysis needs to account for this.
? <
? < >
? <
? < > Cheers
? <
? < > Michelle, note: I do not work Fridays < < < < Dr Steven G. Candy < <
? Director/Consultant < < SCANDY STATISTICAL MODELLING PTY LTD < < (ABN: 83
? 601 268 419) < < 70 Burwood Drive < < Blackmans Bay, TASMANIA, Australia
? 7052 < < Mobile: (61) 0439284983 < < < < 
? < 	[[alternative HTML version deleted]]
? <
? < _______________________________________________
? < R-sig-mixed-models at r-project.org mailing list <
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? 
? -- 
?                                 Emmanuel CURIS
?                                 emmanuel.curis at parisdescartes.fr
? 
? Page WWW: http://emmanuel.curis.online.fr/index.html

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From zsa11 at mail.aub.edu  Mon Apr 20 13:58:44 2015
From: zsa11 at mail.aub.edu (Zahwa Al Ayyash (Student))
Date: Mon, 20 Apr 2015 11:58:44 +0000
Subject: [R-sig-ME] Zero inflation parameter in glmmadmb
Message-ID: <1429531121155.95341@mail.aub.edu>

Dear list,

The glmmadmb package uses zero-inflated (ZI) models to account for the excess of zero observations in the data. In the package manual, it has been mentioned that ZI models capture that aspect through the estimation of "pz" (zero inflation parameter) which is assumed constant as it is not modeled as a function as covariates like it is the case with hurdle models.


The package outputs its value along with the standard deviation. What does the estimated parameter indicate?


I would like to know more about how this parameters gets estimated for every individual. Are there available references that I can refer to?

Thank you a lot for any help in this!
Zahwa

Graduate Student, American University of Beirut


	[[alternative HTML version deleted]]


From Michelle.Gosse at foodstandards.gov.au  Wed Apr 22 22:49:41 2015
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Wed, 22 Apr 2015 20:49:41 +0000
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <000001d07cf8$524a0260$f6de0720$@msu.edu>
References: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
	<000001d07cf8$524a0260$f6de0720$@msu.edu>
Message-ID: <D5ED07A4EA222E42AF840A9EEF2648800154689D94@FSEXMBX02.foodstandards.gov.au>

Thanks everyone for the responses.

I'm confident I have a way forward now.

Cheers
Michelle, note: I do not work Fridays

-----Original Message-----
From: Steven J. Pierce [mailto:pierces1 at msu.edu] 
Sent: Thursday, 23 April 2015 12:32 AM
To: Gosse, Michelle
Cc: R-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] mixed effect models where time ordering is important

Michelle,

This looks like a fairly straightforward growth curve modeling problem. The first half of the Singer & Willett (2003) book is an excellent source on using mixed effects models for these sorts of analyses. You can describe each rat's individual longitudinal trajectory for weight in terms of starting weight (intercept) plus parameters that describe the shape of the trajectory over time (e.g., slope if the trajectory is linear). All of those parameters may vary across rats, but should also have some average value that describes a "typical" trajectory. If you introduce dose as a categorical variable, you can allow dose to predict parameters of the individual rats' trajectories, essentially allowing you to compare the average trajectories across the dose groups. You may want to consider allowing the time slope to vary across rats, as in the formula Weight ~ dose * time + (time + 1|subject).

You should also consider non-linear shapes for the trajectory. Right now, assuming time is a continuous variable, you appear to be considering only linear trends. You could account for the variation in age at the start of the trial by carefully considering how you code time. See Singer & Willett for excellent coverage of various methodological details that are relevant. 

Singer, J. D., & Willett, J. B. (2003). Applied longitudinal data analysis: Modeling change and event occurrence. New York, NY: Oxford University Press.


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT) Michigan State University
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Gosse, Michelle [mailto:Michelle.Gosse at foodstandards.gov.au]
Sent: Tuesday, April 21, 2015 4:14 PM
To: 'R-sig-mixed-models at r-project.org'
Subject: [R-sig-ME] mixed effect models where time ordering is important

Hi all,

I have repeated measures weight data on rats who were in a 28-day toxin study. I have one control group and the toxin was administered at one of three doses (low, medium, high). This is not a cross-over design, so (for example) the rats who were in the low dose group always got the low dose over the course of the study.

The rats were not fully grown when the study started. Body weights were measured every fourth day.

The interest is in seeing if the toxin has an influence on body weight. I am looking at using lmer to analyse this data, however I am unsure how to handle the ordering of time, as this will be correlated with increasing body weight.

If I did not have to worry about time ordering, I thought this model would work:

Weight ~ dose + (1|subject)

The doses are being treated as fixed effects as I am not wanting to extrapolate the impact of dose beyond what was administered in the study.

I was wondering if the appropriate model for my data would be:

Weight ~ dose * time + (1|subject)

However, time is measured as days from initial dose administration (e.g. day 1 = first day of dosing). While the rats are all very similar in age, I do not believe they were all born on the same day, and so I am unsure about time as a proxy for age (assuming an intercept in the model). And day is measured discontinuously (every fourth day). I feel that omitting day will remove one obvious explanatory variable from the model, which may bias the results as well as producing a model that poorly fits the data.

I have tried to find an example of a toxicology study that uses a mixed effects model in R on repeated measures, that specifies the model. I have been unable to locate one.

I would appreciate any advice/recommendations on how to handle this data. I have already advised that a series of separate ANOVAs are not statistically defensible given that the weights are likely to be auto-correlated and the statistical analysis needs to account for this.

Cheers
Michelle, note: I do not work Fridays


**********************************************************************
This email and any files transmitted with it are confide...{{dropped:12}}




**********************************************************************
This email and any files transmitted with it are confidential and
intended solely for the use of the individual or entity to whom they
are addressed. If you have received this email in error please notify
the system manager.

Scanned by Clearswift SECURE Email Gateway at Food Standards ANZ.

**********************************************************************

From ken.beath at mq.edu.au  Thu Apr 23 01:19:32 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 23 Apr 2015 09:19:32 +1000
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <000001d07cf8$524a0260$f6de0720$@msu.edu>
References: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
	<000001d07cf8$524a0260$f6de0720$@msu.edu>
Message-ID: <CAF5_5cy267Kt+QJN7x3bqk-K+_k3U1uj61PJj5Lz0g1Bzesn0w@mail.gmail.com>

Yes, first rule of statistics: start with the easy models first, and check
the diagnostics. So order of models would be linear, quadratic, nonlinear
(there are several used in infant growth modelling which may be
applicable), regression splines, then anything else. All of these may fit
better with log Weight as the response. I would also recommend Pinheiro and
Bates ":Mixed-Effects Models in S and S-Plus", and Verbeke and Molenberghs
"Linear Mixed Models for Longitudinal Data".

On 22 April 2015 at 22:31, Steven J. Pierce <pierces1 at msu.edu> wrote:

> Michelle,
>
> This looks like a fairly straightforward growth curve modeling problem.
> The first half of the Singer & Willett (2003) book is an excellent source
> on using mixed effects models for these sorts of analyses. You can describe
> each rat's individual longitudinal trajectory for weight in terms of
> starting weight (intercept) plus parameters that describe the shape of the
> trajectory over time (e.g., slope if the trajectory is linear). All of
> those parameters may vary across rats, but should also have some average
> value that describes a "typical" trajectory. If you introduce dose as a
> categorical variable, you can allow dose to predict parameters of the
> individual rats' trajectories, essentially allowing you to compare the
> average trajectories across the dose groups. You may want to consider
> allowing the time slope to vary across rats, as in the formula Weight ~
> dose * time + (time + 1|subject).
>
> You should also consider non-linear shapes for the trajectory. Right now,
> assuming time is a continuous variable, you appear to be considering only
> linear trends. You could account for the variation in age at the start of
> the trial by carefully considering how you code time. See Singer & Willett
> for excellent coverage of various methodological details that are relevant.
>
> Singer, J. D., & Willett, J. B. (2003). Applied longitudinal data
> analysis: Modeling change and event occurrence. New York, NY: Oxford
> University Press.
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Gosse, Michelle [mailto:Michelle.Gosse at foodstandards.gov.au]
> Sent: Tuesday, April 21, 2015 4:14 PM
> To: 'R-sig-mixed-models at r-project.org'
> Subject: [R-sig-ME] mixed effect models where time ordering is important
>
> Hi all,
>
> I have repeated measures weight data on rats who were in a 28-day toxin
> study. I have one control group and the toxin was administered at one of
> three doses (low, medium, high). This is not a cross-over design, so (for
> example) the rats who were in the low dose group always got the low dose
> over the course of the study.
>
> The rats were not fully grown when the study started. Body weights were
> measured every fourth day.
>
> The interest is in seeing if the toxin has an influence on body weight. I
> am looking at using lmer to analyse this data, however I am unsure how to
> handle the ordering of time, as this will be correlated with increasing
> body weight.
>
> If I did not have to worry about time ordering, I thought this model would
> work:
>
> Weight ~ dose + (1|subject)
>
> The doses are being treated as fixed effects as I am not wanting to
> extrapolate the impact of dose beyond what was administered in the study.
>
> I was wondering if the appropriate model for my data would be:
>
> Weight ~ dose * time + (1|subject)
>
> However, time is measured as days from initial dose administration (e.g.
> day 1 = first day of dosing). While the rats are all very similar in age, I
> do not believe they were all born on the same day, and so I am unsure about
> time as a proxy for age (assuming an intercept in the model). And day is
> measured discontinuously (every fourth day). I feel that omitting day will
> remove one obvious explanatory variable from the model, which may bias the
> results as well as producing a model that poorly fits the data.
>
> I have tried to find an example of a toxicology study that uses a mixed
> effects model in R on repeated measures, that specifies the model. I have
> been unable to locate one.
>
> I would appreciate any advice/recommendations on how to handle this data.
> I have already advised that a series of separate ANOVAs are not
> statistically defensible given that the weights are likely to be
> auto-correlated and the statistical analysis needs to account for this.
>
> Cheers
> Michelle, note: I do not work Fridays
>
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:12}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From Michelle.Gosse at foodstandards.gov.au  Thu Apr 23 01:23:06 2015
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Wed, 22 Apr 2015 23:23:06 +0000
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <CAF5_5cy267Kt+QJN7x3bqk-K+_k3U1uj61PJj5Lz0g1Bzesn0w@mail.gmail.com>
References: <D5ED07A4EA222E42AF840A9EEF26488001546898A4@FSEXMBX02.foodstandards.gov.au>
	<000001d07cf8$524a0260$f6de0720$@msu.edu> 
	<CAF5_5cy267Kt+QJN7x3bqk-K+_k3U1uj61PJj5Lz0g1Bzesn0w@mail.gmail.com>
Message-ID: <D5ED07A4EA222E42AF840A9EEF264880015468A4A5@FSEXMBX02.foodstandards.gov.au>

Thanks again for the advice. I have Pinheiro and Bates which I normally find sufficient, but not in this case. The recommendations for other books are very helpful.

Cheers
Michelle, note: I do not work Fridays

From: Ken Beath [mailto:ken.beath at mq.edu.au]
Sent: Thursday, 23 April 2015 11:20 AM
To: Steven J. Pierce
Cc: Gosse, Michelle; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] mixed effect models where time ordering is important

Yes, first rule of statistics: start with the easy models first, and check the diagnostics. So order of models would be linear, quadratic, nonlinear (there are several used in infant growth modelling which may be applicable), regression splines, then anything else. All of these may fit better with log Weight as the response. I would also recommend Pinheiro and Bates ":Mixed-Effects Models in S and S-Plus", and Verbeke and Molenberghs "Linear Mixed Models for Longitudinal Data".

On 22 April 2015 at 22:31, Steven J. Pierce <pierces1 at msu.edu<mailto:pierces1 at msu.edu>> wrote:
Michelle,

This looks like a fairly straightforward growth curve modeling problem. The first half of the Singer & Willett (2003) book is an excellent source on using mixed effects models for these sorts of analyses. You can describe each rat's individual longitudinal trajectory for weight in terms of starting weight (intercept) plus parameters that describe the shape of the trajectory over time (e.g., slope if the trajectory is linear). All of those parameters may vary across rats, but should also have some average value that describes a "typical" trajectory. If you introduce dose as a categorical variable, you can allow dose to predict parameters of the individual rats' trajectories, essentially allowing you to compare the average trajectories across the dose groups. You may want to consider allowing the time slope to vary across rats, as in the formula Weight ~ dose * time + (time + 1|subject).

You should also consider non-linear shapes for the trajectory. Right now, assuming time is a continuous variable, you appear to be considering only linear trends. You could account for the variation in age at the start of the trial by carefully considering how you code time. See Singer & Willett for excellent coverage of various methodological details that are relevant.

Singer, J. D., & Willett, J. B. (2003). Applied longitudinal data analysis: Modeling change and event occurrence. New York, NY: Oxford University Press.


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
Web: http://www.cstat.msu.edu

-----Original Message-----
From: Gosse, Michelle [mailto:Michelle.Gosse at foodstandards.gov.au<mailto:Michelle.Gosse at foodstandards.gov.au>]
Sent: Tuesday, April 21, 2015 4:14 PM
To: 'R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>'
Subject: [R-sig-ME] mixed effect models where time ordering is important

Hi all,

I have repeated measures weight data on rats who were in a 28-day toxin study. I have one control group and the toxin was administered at one of three doses (low, medium, high). This is not a cross-over design, so (for example) the rats who were in the low dose group always got the low dose over the course of the study.

The rats were not fully grown when the study started. Body weights were measured every fourth day.

The interest is in seeing if the toxin has an influence on body weight. I am looking at using lmer to analyse this data, however I am unsure how to handle the ordering of time, as this will be correlated with increasing body weight.

If I did not have to worry about time ordering, I thought this model would work:

Weight ~ dose + (1|subject)

The doses are being treated as fixed effects as I am not wanting to extrapolate the impact of dose beyond what was administered in the study.

I was wondering if the appropriate model for my data would be:

Weight ~ dose * time + (1|subject)

However, time is measured as days from initial dose administration (e.g. day 1 = first day of dosing). While the rats are all very similar in age, I do not believe they were all born on the same day, and so I am unsure about time as a proxy for age (assuming an intercept in the model). And day is measured discontinuously (every fourth day). I feel that omitting day will remove one obvious explanatory variable from the model, which may bias the results as well as producing a model that poorly fits the data.

I have tried to find an example of a toxicology study that uses a mixed effects model in R on repeated measures, that specifies the model. I have been unable to locate one.

I would appreciate any advice/recommendations on how to handle this data. I have already advised that a series of separate ANOVAs are not statistically defensible given that the weights are likely to be auto-correlated and the statistical analysis needs to account for this.

Cheers
Michelle, note: I do not work Fridays


**********************************************************************
This email and any files transmitted with it are confide...{{dropped:12}}

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--

Ken Beath
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may contain confidential information.  If you are not the intended recipient, please delete it and notify the sender.  Views expressed in this message are those of the individual sender, and are not necessarily the views of the Faculty of Science, Department of Statistics or Macquarie University.


**********************************************************************
This email and any files transmitted with it are confidential and
intended solely for the use of the individual or entity to whom they
are addressed. If you have received this email in error please notify
the system manager.

Scanned by Clearswift SECURE Email Gateway at Food Standards ANZ.

**********************************************************************

	[[alternative HTML version deleted]]


From lizestats at gmail.com  Thu Apr 23 18:16:26 2015
From: lizestats at gmail.com (Lize van der Merwe)
Date: Thu, 23 Apr 2015 18:16:26 +0200
Subject: [R-sig-ME] nested mixed effects logistic regression binomial glm)
	results differ by function.
Message-ID: <009401d07de0$dba71190$92f534b0$@gmail.com>

Please advise:

I have a dichotomous outcome on 2500 individuals. From 18 geographical
areas, and many households nested within areas. I need to assess the
association between various predictors and my outcome, adjusting for the
correlation within households, as well as within areas. The following R
functions provide dramatically different results.

glmer(CC~predictor+1|area/household,family=binomial)

and

glmmPQL(CC~predictor, random=~1|area/household),family=binomial)

Why? Which is correct?

Thanks in advance.  (I posted this on another site too.)

Lize

 


	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Apr 23 21:19:23 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 23 Apr 2015 20:19:23 +0100
Subject: [R-sig-ME] GLM course in Palm Cove
Message-ID: <553945BB.5070807@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course in Palm Cove, 
Australia.

Course1:  GLM with R (Bayesian and frequentist)
Location: Palm Cove, Australia
Date:       11-14 August 2015
Price:       475 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_08PalmCoveI.pdf


Keywords:
Bayesian statistics, MCMC and JAGS. Overdispersion and solutions. 
Poisson, negative binomial, Bernoulli, binomial,
beta, gamma, inverse Gaussian, lognormal, and binomial distributions. 
GLMs for count data and continuous data. Underdispersion. Truncated 
data. Power analysis.


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From burwood70 at gmail.com  Fri Apr 24 04:12:02 2015
From: burwood70 at gmail.com (Steve Candy)
Date: Fri, 24 Apr 2015 12:12:02 +1000
Subject: [R-sig-ME] mixed effect models where time ordering is important
In-Reply-To: <20150422132254.GG10214@info124.pharmacie.univ-paris5.fr>
References: <00c301d07ced$bec79a70$3c56cf50$@gmail.com>
	<20150422114221.GE10214@info124.pharmacie.univ-paris5.fr>
	<00f501d07cf6$690308f0$3b091ad0$@gmail.com>
	<20150422132254.GG10214@info124.pharmacie.univ-paris5.fr>
Message-ID: <002201d07e34$11a416f0$34ec44d0$@gmail.com>

Emmanuel

I think you make an interesting point that the exp(-beta1/beta2) appears to
be a "problem dose" if its within the range of doses tested but it doesn't
turn out to problematic as for example given the estimates in Table 1 of the
paper I referred to (DOI 10.1007/s10651-014-0306-3). The predictions for the
control and the data for one of the actual doses (=0.56),  where this dose
is very close to exp(-beta1/beta2), are quite different and the fit to the
data is very good in each case (see Figure 1). That is because the ratio of
predictions for control to that of dosed at a dose of exactly
exp(-beta1/beta2) is not 1 but is, as you note, 

exp(s(time, Control_f=="0"))/ exp(s(time, Control_f=="1")).

Incorporating a Control directly into a dose-response model that
incorporates a log(Dose) term is difficult since the control can be assumed
to have zero dose. The model I suggest is a workaround. One can ask why not
simply fit the control data separately, however, there are benefits in
modelling these data jointly with the dosed data. These include automatic
adjustment for control mortality in the case of survival data and pooled
estimates of error variance for determining confidence bounds on
predictions.



-----Original Message-----
From: Emmanuel Curis [mailto:emmanuel.curis at parisdescartes.fr] 
Sent: Wednesday, 22 April 2015 11:23 PM
To: Steve Candy
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] mixed effect models where time ordering is important

I'm sorry if I'm slow, but I don't see how the exponential writing solves
the problem - it's just a rewrite that does not change the behaviour of the
system, since exp is bijective, right?

It is always possible with the first model to fine a given dose such that
gives the same pre-exponential model that the second one. If treatment has
no effect on the shape part, this means that we have a strong discontinuity
at 0 with a singular point having the same value that another one on the
curve --- in other words, it seems that this assume that, for instance, at
low dose subjects grow more slowly than unexposed, but at high dose they
grow more quickly, and somewhere between the dose has no effect... Of
course, this may be compensated for/hidden by the different spline models,
but it seems a strange assumption, no?

I guess in several situations, the problematic dose exp(-beta1/beta2) is not
observed and may be not in the range of tested doses, so it may not always
be a concern, but may be it can in some circumstances?

On Wed, Apr 22, 2015 at 10:18:10PM +1000, Steve Candy wrote:
< There is an intercept parameter, say beta0, then there is a beta1
parameter < associated with the regressor variable NotContr_d  (even though
it's a dummy < variable), then there is a beta2 parameter for the regressor
LogDose. The < control and dosed treatments have separate spline shapes and
due to the < loglinear form of the model the product of < <
exp(beta0+beta1)*exp(beta2*LogDose)*exp(s(time, Control_f=="1")) < < gives
the dose-time response for Weight for the dosed treatments.
<
< For these dosed treatments this allows varying trajectories for Weight but
< strictly according to this common shape model. The control time response <
curve is < < exp(beta0)*exp(s(time, Control_f=="0")). 
<
< Therefore setting LogDose to zero for the Control makes sure this term
does < not contribute to the predicted response since beta2*0=0. Note that
beta1 < takes care of the fact that LogDose for  a dosed treatment may be
less than < zero i.e. one could always scale the Doses up by a constant so
that LogDose < is always positive and this would have a complementary effect
on beta1.
<
< Note that "log(.)" is the natural not base10 logarithm.
<
< See as an example Table 1 of the paper below in a toxicological
application < that models survival rather than weight growth.
<
< Hope that is clearer.
<
< Modelling grouped survival times in toxicological studies using
Generalized < Additive Models . Environmental and Ecological Statistics. DOI
< 10.1007/s10651-014-0306-3 < < On Wednesday, 22 April 2015 9:42 PM,
Emmanuel Curis wrote:
<
< >I'm confused by the second model, the LogDose = 0 if control seems
strange < to me. How does it distinguish, in the intercept term, the <
control > (0 + < 0) and < dose = 10^-1 > (1 + -1) groups? And if the
intercept is monotonic > < >with dose, wouldn't be an annoyance to have the
< dose = 0 > just somewhere < between other points, depending on the exact
doses used (and the log basis < and the unit used...)?
<
< >On Wed, Apr 22, 2015 at 09:16:09PM +1000, Steve Candy wrote:
<
< < To model the dose response component and assuming a common time response
< < shape on the log scale you might want to consider; 1). specify a dummy
(1,0) < < for Control (0) vs Dosed (1) as "NotContr_d" (i.e. the intercept
gives the < < control intercept), 2). LogDose  is set to zero for the
control and is the < < log of the actual dose (low, medium, high) for the
dosed treatments, and < < define Control_f <- as.factor(NotContr_d)  then
3). replace the above gamm < < with < < < < gamm_01 <- gamm(formula =
log(Weight) ~ NotContr_d + LogDose + < s(time, < by=Control_f, bs="cr"),
data=data, random=list(subject=~1), < 
< <      correlation=corCAR1(form= ~ time | subject))
< <
< <
< <
< < The log transforms used above are just suggestions which can be compared
< to < using raw Weights or Doses.
< <
< <
< <
< <
< <
< < > Hi all,
< <
< < >
< <
< < > I have repeated measures weight data on rats who were in a 28-day
toxin < < study. I have one control group and the toxin was administered at
one of < < three doses (low, medium, high). This is not a cross-over design,
so (for < < example) the rats who were in the low dose group always got the
low dose < < over the course of the study.
< <
< < >
< <
< < > The rats were not fully grown when the study started. Body weights
were < < measured every fourth day.
< <
< < >
< <
< < > The interest is in seeing if the toxin has an influence on body
weight.
< I < am looking at using lmer to analyse this data, however I am unsure how
< to < handle the ordering of time, as this will be correlated with
increasing < body < weight.
< <
< < >
< <
< < > If I did not have to worry about time ordering, I thought this model <
would < work:
< <
< < >
< <
< < > Weight ~ dose + (1|subject)
< <
< < >
< <
< < > The doses are being treated as fixed effects as I am not wanting to <
< extrapolate the impact of dose beyond what was administered in the study.
< <
< < >
< <
< < > I was wondering if the appropriate model for my data would be:
< <
< < >
< <
< < > Weight ~ dose * time + (1|subject) < < < < > < < < < > However, time
is measured as days from initial dose administration (e.g.
< < day 1 = first day of dosing). While the rats are all very similar in
age, < I < do not believe they were all born on the same day, and so I am
unsure < about < time as a proxy for age (assuming an intercept in the
model). And < day is < measured discontinuously (every fourth day). I feel
that omitting < day will < remove one obvious explanatory variable from the
model, which may < bias the < results as well as producing a model that
poorly fits the data.
< <
< < >
< <
< < > I have tried to find an example of a toxicology study that uses a
mixed < < effects model in R on repeated measures, that specifies the model.
I have < < been unable to locate one.
< <
< < >
< <
< < > I would appreciate any advice/recommendations on how to handle this <
data.
< < I have already advised that a series of separate ANOVAs are not < <
statistically defensible given that the weights are likely to be < <
auto-correlated and the statistical analysis needs to account for this.
< <
< < >
< <
< < > Cheers
< <
< < > Michelle, note: I do not work Fridays < < < < Dr Steven G. Candy < < <
Director/Consultant < < SCANDY STATISTICAL MODELLING PTY LTD < < (ABN: 83 <
601 268 419) < < 70 Burwood Drive < < Blackmans Bay, TASMANIA, Australia <
7052 < < Mobile: (61) 0439284983 < < < < 
< < 	[[alternative HTML version deleted]]
< <
< < _______________________________________________
< < R-sig-mixed-models at r-project.org mailing list < <
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<
< -- 
<                                 Emmanuel CURIS
<                                 emmanuel.curis at parisdescartes.fr
<
< Page WWW: http://emmanuel.curis.online.fr/index.html

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From David.Duffy at qimr.edu.au  Fri Apr 24 05:12:06 2015
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 24 Apr 2015 13:12:06 +1000
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
 glm)results differ by function.
In-Reply-To: <009401d07de0$dba71190$92f534b0$@gmail.com>
References: <009401d07de0$dba71190$92f534b0$@gmail.com>
Message-ID: <alpine.LMD.2.00.1504241257360.2323@orpheus.qimr.edu.au>

On Fri, 24 Apr 2015, Lize van der Merwe wrote:

> I have a dichotomous outcome on 2500 individuals. From 18 geographical
> areas, and many households nested within areas. I need to assess the
> association between various predictors and my outcome, adjusting for the
> correlation within households, as well as within areas. The following R
> functions provide dramatically different results.
>
> glmer(CC~predictor+1|area/household,family=binomial)
> glmmPQL(CC~predictor, random=~1|area/household),family=binomial)

PQL is known to be biased, the amount depending on a few things including 
the proportion CC in the sample, and number of levels for the REs. You 
could try hglm (package hglm, using EQL) and see how different the results 
are from that ;)  It is also possible one or both programs encountered 
numerical problems because of features of your data. If you can send your 
original data, or simulated data of the same structure (that gives a 
similar problem!), we could have a look.

Cheers, David.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From thierry.onkelinx at inbo.be  Fri Apr 24 09:43:20 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 24 Apr 2015 09:43:20 +0200
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
 glm) results differ by function.
In-Reply-To: <009401d07de0$dba71190$92f534b0$@gmail.com>
References: <009401d07de0$dba71190$92f534b0$@gmail.com>
Message-ID: <CAJuCY5z3n_jknM1x6dYOYe4q=-eaD+eCVuTEvj-9xBPJ2ZBBYA@mail.gmail.com>

Dear Lize,

glmmPQL() uses Penalized Quasi-Likelihood and glmer() uses the likelihood
in case of a binomial family. I prefer methods that uses the likelihood.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-23 18:16 GMT+02:00 Lize van der Merwe <lizestats at gmail.com>:

> Please advise:
>
> I have a dichotomous outcome on 2500 individuals. From 18 geographical
> areas, and many households nested within areas. I need to assess the
> association between various predictors and my outcome, adjusting for the
> correlation within households, as well as within areas. The following R
> functions provide dramatically different results.
>
> glmer(CC~predictor+1|area/household,family=binomial)
>
> and
>
> glmmPQL(CC~predictor, random=~1|area/household),family=binomial)
>
> Why? Which is correct?
>
> Thanks in advance.  (I posted this on another site too.)
>
> Lize
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From holtermann at hwwi.org  Fri Apr 24 10:32:27 2015
From: holtermann at hwwi.org (Linus Holtermann)
Date: Fri, 24 Apr 2015 08:32:27 +0000
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
 glm) results differ by function.
In-Reply-To: <CAJuCY5z3n_jknM1x6dYOYe4q=-eaD+eCVuTEvj-9xBPJ2ZBBYA@mail.gmail.com>
References: <009401d07de0$dba71190$92f534b0$@gmail.com>
	<CAJuCY5z3n_jknM1x6dYOYe4q=-eaD+eCVuTEvj-9xBPJ2ZBBYA@mail.gmail.com>
Message-ID: <7c6c132fcb8d404fbae1ef5de08a7a3e@winhexbeeu15.win.mail>

Dear Lize,

maybe you give Bayesian methods a try. The excellent MCMCglmm package should be able to handle your model. Often MCMC provides more reliable results when a wide range of variation in group size and relative small number of observations per group are present in the data.

Best regards,

Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org
?
Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im Auftrag von Thierry Onkelinx
Gesendet: Freitag, 24. April 2015 09:43
An: Lize van der Merwe
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] nested mixed effects logistic regression binomial glm) results differ by function.

Dear Lize,

glmmPQL() uses Penalized Quasi-Likelihood and glmer() uses the likelihood in case of a binomial family. I prefer methods that uses the likelihood.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-23 18:16 GMT+02:00 Lize van der Merwe <lizestats at gmail.com>:

> Please advise:
>
> I have a dichotomous outcome on 2500 individuals. From 18 geographical 
> areas, and many households nested within areas. I need to assess the 
> association between various predictors and my outcome, adjusting for 
> the correlation within households, as well as within areas. The 
> following R functions provide dramatically different results.
>
> glmer(CC~predictor+1|area/household,family=binomial)
>
> and
>
> glmmPQL(CC~predictor, random=~1|area/household),family=binomial)
>
> Why? Which is correct?
>
> Thanks in advance.  (I posted this on another site too.)
>
> Lize
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Fri Apr 24 10:59:56 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 24 Apr 2015 09:59:56 +0100
Subject: [R-sig-ME] nested mixed effects logistic regression binomial,
 glm)	results differ by function.
In-Reply-To: <mailman.6.1429864356.3255.r-sig-mixed-models@r-project.org>
References: <mailman.6.1429864356.3255.r-sig-mixed-models@r-project.org>
Message-ID: <553A060C.6080409@highstat.com>


> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 23 Apr 2015 18:16:26 +0200
> From: Lize van der Merwe <lizestats at gmail.com>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] nested mixed effects logistic regression binomial
> 	glm)	results differ by function.
> Message-ID: <009401d07de0$dba71190$92f534b0$@gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Please advise:
>
> I have a dichotomous outcome on 2500 individuals. From 18 geographical
> areas, and many households nested within areas. I need to assess the
> association between various predictors and my outcome, adjusting for the
> correlation within households, as well as within areas. The following R
> functions provide dramatically different results.
>
> glmer(CC~predictor+1|area/household,family=binomial)
>
> and
>
> glmmPQL(CC~predictor, random=~1|area/household),family=binomial)
>
> Why? Which is correct?
Instead of focusing on the 'which one is correct' question, I would 
focus more on 'why are they different'. If two techniques give you 
rather different results then perhaps your model is too complicated, or 
your data set does not allow for a 2-way nested model. Simulate a data 
set with 2500 observations with nicely balanced clusters and see whether 
you have the same problems. Then cripple the data set (make unbalanced 
clusters) and see when differences occur. And yes....doing it in a 
Bayesian context is a good idea too.

Alain


>
> Thanks in advance.  (I posted this on another site too.)
>
> Lize





-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From M.Fairbrother at bristol.ac.uk  Fri Apr 24 12:08:24 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 24 Apr 2015 12:08:24 +0200
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
 glm) results differ by function.
Message-ID: <CAAH-yP__mvZuRwg6Z4+BM=jTNgw9k+YeW8yp47xj-ij3NQMvpg@mail.gmail.com>

Dear Lize,

Does it make any difference if you try:
glmer(CC ~ predictor + (1 | area / household), family = binomial)
 ?

I may be wrong, but I thought the parentheses were important here.


Best wishes,
Malcolm



Date: Thu, 23 Apr 2015 18:16:26 +0200
> From: Lize van der Merwe <lizestats at gmail.com>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] nested mixed effects logistic regression binomial
>         glm)    results differ by function.
>
> Please advise:
>
> I have a dichotomous outcome on 2500 individuals. From 18 geographical
> areas, and many households nested within areas. I need to assess the
> association between various predictors and my outcome, adjusting for the
> correlation within households, as well as within areas. The following R
> functions provide dramatically different results.
>
> glmer(CC~predictor+1|area/household,family=binomial)
>
> and
>
> glmmPQL(CC~predictor, random=~1|area/household),family=binomial)
>
> Why? Which is correct?
>
> Thanks in advance.  (I posted this on another site too.)
>
> Lize
>

	[[alternative HTML version deleted]]


From lizestats at gmail.com  Fri Apr 24 12:48:58 2015
From: lizestats at gmail.com (Lize van der Merwe)
Date: Fri, 24 Apr 2015 12:48:58 +0200
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
	glm) results differ by function.
In-Reply-To: <CAAH-yP__mvZuRwg6Z4+BM=jTNgw9k+YeW8yp47xj-ij3NQMvpg@mail.gmail.com>
References: <CAAH-yP__mvZuRwg6Z4+BM=jTNgw9k+YeW8yp47xj-ij3NQMvpg@mail.gmail.com>
Message-ID: <00ec01d07e7c$484fd3e0$d8ef7ba0$@gmail.com>

Thankyou, Malcolm

This is embarrassing.  You are right, the parentheses are necessary and are in the models I ran.  I am sure I typed those parentheses, but they are not in my request any more ?  I think I know what happened.

Sorry about that. 

I am working through the other people?s suggestions, thankyou too.

Regards

Lize

 

 

From: Malcolm Fairbrother [mailto:M.Fairbrother at bristol.ac.uk] 
Sent: 24 April 2015 12:08
To: lizestats at gmail.com
Cc: r-sig-mixed-models
Subject: Re: nested mixed effects logistic regression binomial glm) results differ by function.

 

Dear Lize,

 

Does it make any difference if you try:

glmer(CC ~ predictor + (1 | area / household), family = binomial)

 ?

 

I may be wrong, but I thought the parentheses were important here.

 

 

Best wishes,
Malcolm

 

 

 

Date: Thu, 23 Apr 2015 18:16:26 +0200
From: Lize van der Merwe <lizestats at gmail.com>
To: <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
        glm)    results differ by function.

Please advise:

I have a dichotomous outcome on 2500 individuals. From 18 geographical
areas, and many households nested within areas. I need to assess the
association between various predictors and my outcome, adjusting for the
correlation within households, as well as within areas. The following R
functions provide dramatically different results.

glmer(CC~predictor+1|area/household,family=binomial)

and

glmmPQL(CC~predictor, random=~1|area/household),family=binomial)

Why? Which is correct?

Thanks in advance.  (I posted this on another site too.)

Lize


	[[alternative HTML version deleted]]


From lizestats at gmail.com  Fri Apr 24 14:26:04 2015
From: lizestats at gmail.com (Lize van der Merwe)
Date: Fri, 24 Apr 2015 14:26:04 +0200
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
	glm)results differ by function.
In-Reply-To: <alpine.LMD.2.00.1504241257360.2323@orpheus.qimr.edu.au>
References: <009401d07de0$dba71190$92f534b0$@gmail.com>
	<alpine.LMD.2.00.1504241257360.2323@orpheus.qimr.edu.au>
Message-ID: <010a01d07e89$d9042050$8b0c60f0$@gmail.com>

Thank you so very much to everyone responding to my request.  I learnt a
lot.  You helped me figure out my mistake.  I wanted to adjust for the
correlation inside households.  Most of the households, however, contained a
single individual.  When I combined them into a single cluster, the answers
were exactly what I needed.
Regards
Lize


-----Original Message-----
From: David Duffy [mailto:David.Duffy at qimr.edu.au] 
Sent: 24 April 2015 05:12
To: Lize van der Merwe
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nested mixed effects logistic regression binomial
glm)results differ by function.

On Fri, 24 Apr 2015, Lize van der Merwe wrote:

> I have a dichotomous outcome on 2500 individuals. From 18 geographical 
> areas, and many households nested within areas. I need to assess the 
> association between various predictors and my outcome, adjusting for 
> the correlation within households, as well as within areas. The 
> following R functions provide dramatically different results.
>
> glmer(CC~predictor+1|area/household,family=binomial)
> glmmPQL(CC~predictor, random=~1|area/household),family=binomial)

PQL is known to be biased, the amount depending on a few things including
the proportion CC in the sample, and number of levels for the REs. You could
try hglm (package hglm, using EQL) and see how different the results are
from that ;)  It is also possible one or both programs encountered numerical
problems because of features of your data. If you can send your original
data, or simulated data of the same structure (that gives a similar
problem!), we could have a look.

Cheers, David.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: 
| -0101 Genetic Epidemiology, QIMR Berghofer Institute of Medical 
| Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From quentin.schorpp at ti.bund.de  Fri Apr 24 15:08:04 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Fri, 24 Apr 2015 15:08:04 +0200
Subject: [R-sig-ME] Resulat from GLMM, error bars for predictions
Message-ID: <553A4034.5010605@ti.bund.de>

Hello Everyone,

I'm using glmmadmb() to model abundance data (counts) of soil organisms 
(e.g. earthworms).  My design covers agricultural fields of five 
different age classes . Every age-class has three field replicates. 
Additionally every field was sampled 3times during the investigation 
(atumn, spring, autumn -> sampling campaign).
with 4 samples taken randomly at each field (1 Sample = 0.25 m?). 
Several environmental parameters were assessed for each field but never 
for one of the four samples explicitly.
Hence the environmental data is often redundant for the samples, 
especially when climatic measurements were even similar for more ththan 
one field.

My hypothesis is that abundance increases with the age_class

My model is:

model <- glmmadmb(abundance ~ age_class + samplingCampaign + 
environmental1 + env2 + env3 + (1|field), data, family="poisson")

age_class = ordered factor
sampling campaign = continous, difference to the first sampling in days 
(first sampling always 0)
env(1-n) = continous
total number of samples = 180

Dispersion factor is 1.45

I do model validation with
1. plot pearson residuals against fitted values
2. plot pearson residuals against each covariate in the model
3. make a histogram of the residuals

In my opinion everything looks ok.

Now I have the really really big problem: *I just don't know how to 
present the results.*
I'd like to do a barplot with mean abundances for age_class and standard 
errors and do Post Hoc tukey test to look at differences between the 
factor levels. But i just don't know how to to these Post-Hoc tests.

I've got one approach for extracting predictions and standard errors for 
predictions using a test dataset with mean environmental variables:

test.data=expand.grid(age_class=levels(data$age_class),
                                         samplingCampaign = data$samcam),
                                         env1 = mean(data$env1),
                                         env2 = max(data$env2))

pred.abundance <- cbind(test.data,
                                               predict(model, test.data, 
type="link", se.fit=TRUE),
                                               abundance.response = 
predict(model, test.data, type="response"))

pred.anc <- within(pred.abundance, {
                                          anc <- 4*exp(fit)
                                          LL <- 4*exp(fit - 1.96 * se.fit)
                                          UL <- 4*exp(fit + 1.96 * 
se.fit)  })

Then I make a plot and get INCREDIBLY large standard errors and in 
contrast to the boxplot of the predicitons 
(plot(data$age_class,predict(model, type="response")), the abundance is 
not increasing with the age_class. I multiply by 4 since i want to 
present the results per m?

Do you know where the mistake is?

I would appreciate if you could help me with this analysis, since I'm 
trying to learn GLMM for more than a year and i can't ask a real person 
here at this Institution. Thanks in advance,
Quentin


-- 

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


	[[alternative HTML version deleted]]


From mwiederm at mtu.edu  Fri Apr 24 17:03:53 2015
From: mwiederm at mtu.edu (Magdalena Wiedermann)
Date: Fri, 24 Apr 2015 11:03:53 -0400
Subject: [R-sig-ME] mixed-effects model with crossed random effects
Message-ID: <553A5B59.4000500@mtu.edu>

Dear list,

I am using the nlme package to analyze a mixed effects model. I am 
dealing with crossed random effects, meaning that I have repeated 
measures in time and space (on a split plot design). We are sampling 
water at two depth within one of each vegetation treatment (3 veg 
treatments) organized in 4 blocks.

I figured that the code including the spacial component only would be!?:
<-lme(responses~veg*depth*year*Month, random=~1|block/veg)

I am aware that 4 blocks is not pretty for it to be a random effect, but 
I am not interested in it as fixed effects. Also I am aware that there 
are very many philosophies and views on what a random effect is/should be.

Can anybody please help me with adding the temporal component in? 
Samples on these plots were taken 5 times each year for 3 years => 15 
times of repeated measures

I'd be more than happy about any suggestions, similar examples etc.
Thank you so much!
Lena

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Apr 24 20:15:30 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 24 Apr 2015 14:15:30 -0400
Subject: [R-sig-ME] nested mixed effects logistic regression binomial
 glm) results differ by function.
In-Reply-To: <CAAH-yP__mvZuRwg6Z4+BM=jTNgw9k+YeW8yp47xj-ij3NQMvpg@mail.gmail.com>
References: <CAAH-yP__mvZuRwg6Z4+BM=jTNgw9k+YeW8yp47xj-ij3NQMvpg@mail.gmail.com>
Message-ID: <553A8842.7030405@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-04-24 06:08 AM, Malcolm Fairbrother wrote:
> Dear Lize,
> 
> Does it make any difference if you try: glmer(CC ~ predictor + (1 |
> area / household), family = binomial) ?
> 
> I may be wrong, but I thought the parentheses were important here.
> 
> 
> Best wishes, Malcolm
> 

  Nice catch! It would be interesting to try to develop a test (if not
exact, at least a heuristic) that would flag these problems ...

> 
> 
> Date: Thu, 23 Apr 2015 18:16:26 +0200
>> From: Lize van der Merwe <lizestats at gmail.com> To:
>> <r-sig-mixed-models at r-project.org> Subject: [R-sig-ME] nested
>> mixed effects logistic regression binomial glm)    results differ
>> by function.
>> 
>> Please advise:
>> 
>> I have a dichotomous outcome on 2500 individuals. From 18
>> geographical areas, and many households nested within areas. I
>> need to assess the association between various predictors and my
>> outcome, adjusting for the correlation within households, as well
>> as within areas. The following R functions provide dramatically
>> different results.
>> 
>> glmer(CC~predictor+1|area/household,family=binomial)
>> 
>> and
>> 
>> glmmPQL(CC~predictor, random=~1|area/household),family=binomial)
>> 
>> Why? Which is correct?
>> 
>> Thanks in advance.  (I posted this on another site too.)
>> 
>> Lize
>> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVOohBAAoJEOCV5YRblxUH/NQIAI+I9NjcKGIjOU5vJZna33O9
Xp90KymCj0ZAB+Wf489nWrsIJamlUc2bixicYqf1IMGFe9KId38bggWiddL1wlzj
8twRVdTEA6YRn+lbUV6r9JNZ8g21wHVRa77PSNAQwB3TR4v4sDkn7ItkNm3kDqSF
cMgU6iYTELruut8YxBQim/SvrmSNSWypehkMMjU1q6on/KyCvvOI2torxhcEiewt
8bKyq5PpVNbglrMVYQ1giPUJa8yD+yr4vG/gK3uEUASZP/q7BS+6qLrbaqCdwtHj
wxXL6SxipUUyFdx6HLiq2jTuxtaWjCYYMLpgpW/oqtYf8EpyOBdYtFEgLEUHZtY=
=3XWS
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Fri Apr 24 20:26:31 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 24 Apr 2015 18:26:31 +0000 (UTC)
Subject: [R-sig-ME] mixed-effects model with crossed random effects
References: <553A5B59.4000500@mtu.edu>
Message-ID: <loom.20150424T201934-232@post.gmane.org>

Magdalena Wiedermann <mwiederm at ...> writes:

> 
> Dear list,
> 
> I am using the nlme package to analyze a mixed effects model. I am 
> dealing with crossed random effects, meaning that I have repeated 
> measures in time and space (on a split plot design). We are sampling 
> water at two depth within one of each vegetation treatment (3 veg 
> treatments) organized in 4 blocks.
> 
> I figured that the code including the spacial component only would be!?:
> <-lme(responses~veg*depth*year*Month, random=~1|block/veg)
> 
> I am aware that 4 blocks is not pretty for it to be a random effect, but 
> I am not interested in it as fixed effects. Also I am aware that there 
> are very many philosophies and views on what a random effect is/should be.
> 
> Can anybody please help me with adding the temporal component in? 
> Samples on these plots were taken 5 times each year for 3 years => 15 
> times of repeated measures
> 
> I'd be more than happy about any suggestions, similar examples etc.
> Thank you so much!
> Lena


   It is possible to fit crossed random effects in lme (it's discussed
in one of the later chapters of Pinheiro and Bates), but it's a
bit of a hassle.  If you're willing to use lme4 instead (you can
use the lmerTest or pbkrtest if you need p-values, see ?pvalues)
this will be a little bit easier.

    Something like

  lmer(responses~veg + (veg|year/Month) + (veg|block), data= ...)

would seem to be a reasonable guess, although it may be too much
for your data since you will be estimating 3 3x3 variance-covariance
matrices of veg responses (within year, within Month-within-year,
within block).  I don't know whether you have trends over
the course of your time series (e.g. add a numeric covariate of
time period to the fixed effects) or consistent seasonal effects
(e.g. make your model (veg|year) + (veg|Month) + (veg|year:Month)) ...

   Ben Bolker


From thierry.onkelinx at inbo.be  Sun Apr 26 20:37:55 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 26 Apr 2015 20:37:55 +0200
Subject: [R-sig-ME] Resulat from GLMM, error bars for predictions
In-Reply-To: <553A4034.5010605@ti.bund.de>
References: <553A4034.5010605@ti.bund.de>
Message-ID: <CAJuCY5yG46M+8edUx8+AgQtcEm9ub1o95Y-z=Nta1LKXcEwOLg@mail.gmail.com>

Dear Quentin,

- You better use an offset if you want to express the model in terms of m?.
Just add offset(log(0.25)) to the model.
- I'd rather treat samplingCamping as a factor.
- You can get post hoc comparisons with the multcomp package. See the
example below.

library(glmmADMB)
Owls$Interaction <- interaction(Owls$FoodTreatment, Owls$SexParent)
om <- glmmadmb(SiblingNegotiation~
Interaction+(1|Nest)+offset(log(BroodSize)),zeroInflation=TRUE,family="nbinom",data=Owls)
library(multcomp)
pairwise <- glht(om, mcp(Interaction = "Tukey"))
pairwise.ci <- confint(pairwise)
library(ggplot2)
ggplot(pairwise.ci, aes(y = lhs, x = exp(estimate), xmin = exp(lwr), xmax =
exp(upr))) + geom_errorbarh() + geom_point() + geom_vline(xintercept = 1)


Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-24 15:08 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de>:

> Hello Everyone,
>
> I'm using glmmadmb() to model abundance data (counts) of soil organisms
> (e.g. earthworms).  My design covers agricultural fields of five
> different age classes . Every age-class has three field replicates.
> Additionally every field was sampled 3times during the investigation
> (atumn, spring, autumn -> sampling campaign).
> with 4 samples taken randomly at each field (1 Sample = 0.25 m?).
> Several environmental parameters were assessed for each field but never
> for one of the four samples explicitly.
> Hence the environmental data is often redundant for the samples,
> especially when climatic measurements were even similar for more ththan
> one field.
>
> My hypothesis is that abundance increases with the age_class
>
> My model is:
>
> model <- glmmadmb(abundance ~ age_class + samplingCampaign +
> environmental1 + env2 + env3 + (1|field), data, family="poisson")
>
> age_class = ordered factor
> sampling campaign = continous, difference to the first sampling in days
> (first sampling always 0)
> env(1-n) = continous
> total number of samples = 180
>
> Dispersion factor is 1.45
>
> I do model validation with
> 1. plot pearson residuals against fitted values
> 2. plot pearson residuals against each covariate in the model
> 3. make a histogram of the residuals
>
> In my opinion everything looks ok.
>
> Now I have the really really big problem: *I just don't know how to
> present the results.*
> I'd like to do a barplot with mean abundances for age_class and standard
> errors and do Post Hoc tukey test to look at differences between the
> factor levels. But i just don't know how to to these Post-Hoc tests.
>
> I've got one approach for extracting predictions and standard errors for
> predictions using a test dataset with mean environmental variables:
>
> test.data=expand.grid(age_class=levels(data$age_class),
>                                          samplingCampaign = data$samcam),
>                                          env1 = mean(data$env1),
>                                          env2 = max(data$env2))
>
> pred.abundance <- cbind(test.data,
>                                                predict(model, test.data,
> type="link", se.fit=TRUE),
>                                                abundance.response =
> predict(model, test.data, type="response"))
>
> pred.anc <- within(pred.abundance, {
>                                           anc <- 4*exp(fit)
>                                           LL <- 4*exp(fit - 1.96 * se.fit)
>                                           UL <- 4*exp(fit + 1.96 *
> se.fit)  })
>
> Then I make a plot and get INCREDIBLY large standard errors and in
> contrast to the boxplot of the predicitons
> (plot(data$age_class,predict(model, type="response")), the abundance is
> not increasing with the age_class. I multiply by 4 since i want to
> present the results per m?
>
> Do you know where the mistake is?
>
> I would appreciate if you could help me with this analysis, since I'm
> trying to learn GLMM for more than a year and i can't ask a real person
> here at this Institution. Thanks in advance,
> Quentin
>
>
> --
>
> Quentin Schorpp, M.Sc.
> Th?nen Institute of Biodiversity
> Bundesallee 50
> 38116 Braunschweig (Germany)
>
> Tel:  +49 531 596-2524
> Fax:  +49 531 596-2599
> Mail: quentin.schorpp at ti.bund.de
> Web:  http://www.ti.bund.de
>
> The Johann Heinrich von Th?nen Institute, Federal Research Institute for
> Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
> consists of 15 specialized institutes that carry out research and provide
> policy advice in the fields of economy, ecology and technology.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 27 10:50:16 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Apr 2015 10:50:16 +0200
Subject: [R-sig-ME] Results from GLMM, error bars for predictions
In-Reply-To: <553DE593.2040308@ti.bund.de>
References: <553A4034.5010605@ti.bund.de>
	<CAJuCY5yG46M+8edUx8+AgQtcEm9ub1o95Y-z=Nta1LKXcEwOLg@mail.gmail.com>
	<553DE593.2040308@ti.bund.de>
Message-ID: <CAJuCY5woXmvPjr+ibXXzLhWLvWYfDcYLfgKoyK2i-g2ctKpa+A@mail.gmail.com>

Dear Quentin,

Please keep the mailing list in cc.

Dropping non significant terms from an ordered factor is not ok. That would
change the interpretation of the factor. You wouldn't drop non significant
levels of an unordered factor either.

Ben's solution is about multiple comparisons with random (and fixed)
effects. You're only dealing with multiple comparisons with fixed effects.
So glht() will do the trick.

Try plotting the predicted values for all relevant combinations of the
fixed effects. I find that easier to interpret than just a bunch of
coefficients.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-27 9:30 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de>:

>  Dear Thierry,
>
> thank you very much for your advice, i didn't hear about the offset()
> argument, yet. I'll try this immidiately.
> My first intention was, that the large error bars are due to the high
> variability and the low number of replicates (3), which stays true, i
> think. The point was, that i just couldn't explain, why the output was so
> weird, despite that the model stated significance and 0 was not within the
> confidence intervals.
> Now, it makes me confident to have the advice of using glht from you. I
> was kind of  unsecure, regarding the glht procedure, because i read this
> post on stack overflow by Ben Bolker:
>
> http://stackoverflow.com/questions/25949701/post-hoc-test-in-generalised-linear-mixed-models-how-to-do
>
> Next I'll give up treating age_class as an ordered factor, although i
> found the idea quite interesting.
> Do you know where to get information about using ordered factors in a glmm?
> The output was not significant for the cubic term in my case, and i asked
> myself if i could/should skip it from the model.
>
> Probably i could use samplingCampaign as ordered factor.
>
> One thing I'm still interested in, is a tutorial that shows how to present
> results from more than one univariate analysis in a way to have it ready
> for publication.
> In my opinion eyerthing, even in the books, is about modeling procedure,
> validation, cryptic names of important coefficients. I know cooking with an
> 0815 recipe is dangerous, but that's not what I'm looking for.
>
> Thank you again for your help!!
> Quentin
>
>
> Am 26.04.2015 um 20:37 schrieb Thierry Onkelinx:
>
>  Dear Quentin,
>
>  - You better use an offset if you want to express the model in terms of
> m?. Just add offset(log(0.25)) to the model.
> - I'd rather treat samplingCamping as a factor.
> - You can get post hoc comparisons with the multcomp package. See the
> example below.
>
>  library(glmmADMB)
> Owls$Interaction <- interaction(Owls$FoodTreatment, Owls$SexParent)
> om <- glmmadmb(SiblingNegotiation~
> Interaction+(1|Nest)+offset(log(BroodSize)),zeroInflation=TRUE,family="nbinom",data=Owls)
> library(multcomp)
> pairwise <- glht(om, mcp(Interaction = "Tukey"))
> pairwise.ci <- confint(pairwise)
> library(ggplot2)
> ggplot(pairwise.ci, aes(y = lhs, x = exp(estimate), xmin = exp(lwr), xmax
> = exp(upr))) + geom_errorbarh() + geom_point() + geom_vline(xintercept = 1)
>
>
>  Best regards,
>
>  ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-24 15:08 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de>:
>
>> Hello Everyone,
>>
>> I'm using glmmadmb() to model abundance data (counts) of soil organisms
>> (e.g. earthworms).  My design covers agricultural fields of five
>> different age classes . Every age-class has three field replicates.
>> Additionally every field was sampled 3times during the investigation
>> (atumn, spring, autumn -> sampling campaign).
>> with 4 samples taken randomly at each field (1 Sample = 0.25 m?).
>> Several environmental parameters were assessed for each field but never
>> for one of the four samples explicitly.
>> Hence the environmental data is often redundant for the samples,
>> especially when climatic measurements were even similar for more ththan
>> one field.
>>
>> My hypothesis is that abundance increases with the age_class
>>
>> My model is:
>>
>> model <- glmmadmb(abundance ~ age_class + samplingCampaign +
>> environmental1 + env2 + env3 + (1|field), data, family="poisson")
>>
>> age_class = ordered factor
>> sampling campaign = continous, difference to the first sampling in days
>> (first sampling always 0)
>> env(1-n) = continous
>> total number of samples = 180
>>
>> Dispersion factor is 1.45
>>
>> I do model validation with
>> 1. plot pearson residuals against fitted values
>> 2. plot pearson residuals against each covariate in the model
>> 3. make a histogram of the residuals
>>
>> In my opinion everything looks ok.
>>
>> Now I have the really really big problem: *I just don't know how to
>> present the results.*
>> I'd like to do a barplot with mean abundances for age_class and standard
>> errors and do Post Hoc tukey test to look at differences between the
>> factor levels. But i just don't know how to to these Post-Hoc tests.
>>
>> I've got one approach for extracting predictions and standard errors for
>> predictions using a test dataset with mean environmental variables:
>>
>> test.data=expand.grid(age_class=levels(data$age_class),
>>                                          samplingCampaign = data$samcam),
>>                                          env1 = mean(data$env1),
>>                                          env2 = max(data$env2))
>>
>> pred.abundance <- cbind(test.data,
>>                                                predict(model, test.data,
>> type="link", se.fit=TRUE),
>>                                                abundance.response =
>> predict(model, test.data, type="response"))
>>
>> pred.anc <- within(pred.abundance, {
>>                                           anc <- 4*exp(fit)
>>                                           LL <- 4*exp(fit - 1.96 * se.fit)
>>                                           UL <- 4*exp(fit + 1.96 *
>> se.fit)  })
>>
>> Then I make a plot and get INCREDIBLY large standard errors and in
>> contrast to the boxplot of the predicitons
>> (plot(data$age_class,predict(model, type="response")), the abundance is
>> not increasing with the age_class. I multiply by 4 since i want to
>> present the results per m?
>>
>> Do you know where the mistake is?
>>
>> I would appreciate if you could help me with this analysis, since I'm
>> trying to learn GLMM for more than a year and i can't ask a real person
>> here at this Institution. Thanks in advance,
>> Quentin
>>
>>
>> --
>>
>> Quentin Schorpp, M.Sc.
>> Th?nen Institute of Biodiversity
>> Bundesallee 50
>> 38116 Braunschweig (Germany)
>>
>> Tel:  +49 531 596-2524
>> Fax:  +49 531 596-2599
>> Mail: quentin.schorpp at ti.bund.de
>> Web:  http://www.ti.bund.de
>>
>> The Johann Heinrich von Th?nen Institute, Federal Research Institute for
>> Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
>> consists of 15 specialized institutes that carry out research and provide
>> policy advice in the fields of economy, ecology and technology.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Quentin Schorpp, M.Sc.
> Th?nen-Institut f?r Biodiversit?t
> Bundesallee 50
> 38116 Braunschweig (Germany)
>
> Tel:  +49 531 596-2524
> Fax:  +49 531 596-2599
> Mail: quentin.schorpp at ti.bund.de
> Web:  http://www.ti.bund.de
>
> Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
> besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
>
> Quentin Schorpp, M.Sc.
> Th?nen Institute of Biodiversity
> Bundesallee 50
> 38116 Braunschweig (Germany)
>
> Tel:  +49 531 596-2524
> Fax:  +49 531 596-2599
> Mail: quentin.schorpp at ti.bund.de
> Web:  http://www.ti.bund.de
>
> The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
> consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
>
>

	[[alternative HTML version deleted]]


From quentin.schorpp at ti.bund.de  Mon Apr 27 11:30:30 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Mon, 27 Apr 2015 11:30:30 +0200
Subject: [R-sig-ME] Results from GLMM, error bars for predictions
In-Reply-To: <CAJuCY5woXmvPjr+ibXXzLhWLvWYfDcYLfgKoyK2i-g2ctKpa+A@mail.gmail.com>
References: <553A4034.5010605@ti.bund.de>	<CAJuCY5yG46M+8edUx8+AgQtcEm9ub1o95Y-z=Nta1LKXcEwOLg@mail.gmail.com>	<553DE593.2040308@ti.bund.de>
	<CAJuCY5woXmvPjr+ibXXzLhWLvWYfDcYLfgKoyK2i-g2ctKpa+A@mail.gmail.com>
Message-ID: <553E01B6.8030701@ti.bund.de>

Hello,

Thank you for writing,

I tried what you said, but simple addition of "offset(log(0.25))" did 
not work. Hence I created a factor "area" expressed as m? with the value 
0.25 for all observations:
  data$area <- rep(0.25, 180)
and added offset(log(area)) to the model formula.

Ok, plotting the predicted values for all relevant combinations of the 
fixed effects was also my intention. However, the problem with the 
errorbars occured. Or is it a faulty assumption of mine, that plots of 
predicted values need error-bars?

I'm sorry, i recognized that the answer was only adressed to you, after 
i send the mail. Then i send it again to the Mailing List, i hope it 
won't get to chaotic right now. Now i used "answer all"

kind regards



Am 27.04.2015 um 10:50 schrieb Thierry Onkelinx:
> Dear Quentin,
>
> Please keep the mailing list in cc.
>
> Dropping non significant terms from an ordered factor is not ok. That 
> would change the interpretation of the factor. You wouldn't drop non 
> significant levels of an unordered factor either.
>
> Ben's solution is about multiple comparisons with random (and fixed) 
> effects. You're only dealing with multiple comparisons with fixed 
> effects. So glht() will do the trick.
>
> Try plotting the predicted values for all relevant combinations of the 
> fixed effects. I find that easier to interpret than just a bunch of 
> coefficients.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2015-04-27 9:30 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de 
> <mailto:quentin.schorpp at ti.bund.de>>:
>
>     Dear Thierry,
>
>     thank you very much for your advice, i didn't hear about the
>     offset() argument, yet. I'll try this immidiately.
>     My first intention was, that the large error bars are due to the
>     high variability and the low number of replicates (3), which stays
>     true, i think. The point was, that i just couldn't explain, why
>     the output was so weird, despite that the model stated
>     significance and 0 was not within the confidence intervals.
>     Now, it makes me confident to have the advice of using glht from
>     you. I was kind of  unsecure, regarding the glht procedure,
>     because i read this post on stack overflow by Ben Bolker:
>     http://stackoverflow.com/questions/25949701/post-hoc-test-in-generalised-linear-mixed-models-how-to-do
>
>
>     Next I'll give up treating age_class as an ordered factor,
>     although i found the idea quite interesting.
>     Do you know where to get information about using ordered factors
>     in a glmm?
>     The output was not significant for the cubic term in my case, and
>     i asked myself if i could/should skip it from the model.
>
>     Probably i could use samplingCampaign as ordered factor.
>
>     One thing I'm still interested in, is a tutorial that shows how to
>     present results from more than one univariate analysis in a way to
>     have it ready for publication.
>     In my opinion eyerthing, even in the books, is about modeling
>     procedure, validation, cryptic names of important coefficients. I
>     know cooking with an 0815 recipe is dangerous, but that's not what
>     I'm looking for.
>
>     Thank you again for your help!!
>     Quentin
>
>
>     Am 26.04.2015 um 20:37 schrieb Thierry Onkelinx:
>>     Dear Quentin,
>>
>>     - You better use an offset if you want to express the model in
>>     terms of m?. Just add offset(log(0.25)) to the model.
>>     - I'd rather treat samplingCamping as a factor.
>>     - You can get post hoc comparisons with the multcomp package. See
>>     the example below.
>>
>>     library(glmmADMB)
>>     Owls$Interaction <- interaction(Owls$FoodTreatment, Owls$SexParent)
>>     om <- glmmadmb(SiblingNegotiation~
>>     Interaction+(1|Nest)+offset(log(BroodSize)),zeroInflation=TRUE,family="nbinom",data=Owls)
>>     library(multcomp)
>>     pairwise <- glht(om, mcp(Interaction = "Tukey"))
>>     pairwise.ci <http://pairwise.ci> <- confint(pairwise)
>>     library(ggplot2)
>>     ggplot(pairwise.ci <http://pairwise.ci>, aes(y = lhs, x =
>>     exp(estimate), xmin = exp(lwr), xmax = exp(upr))) +
>>     geom_errorbarh() + geom_point() + geom_vline(xintercept = 1)
>>
>>     Best regards,
>>
>>     ir. Thierry Onkelinx
>>     Instituut voor natuur- en bosonderzoek / Research Institute for
>>     Nature and Forest
>>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>     Assurance
>>     Kliniekstraat 25
>>     1070 Anderlecht
>>     Belgium
>>
>>     To call in the statistician after the experiment is done may be
>>     no more than asking him to perform a post-mortem examination: he
>>     may be able to say what the experiment died of. ~ Sir Ronald
>>     Aylmer Fisher
>>     The plural of anecdote is not data. ~ Roger Brinner
>>     The combination of some data and an aching desire for an answer
>>     does not ensure that a reasonable answer can be extracted from a
>>     given body of data. ~ John Tukey
>>
>>     2015-04-24 15:08 GMT+02:00 Quentin Schorpp
>>     <quentin.schorpp at ti.bund.de <mailto:quentin.schorpp at ti.bund.de>>:
>>
>>         Hello Everyone,
>>
>>         I'm using glmmadmb() to model abundance data (counts) of soil
>>         organisms
>>         (e.g. earthworms).  My design covers agricultural fields of five
>>         different age classes . Every age-class has three field
>>         replicates.
>>         Additionally every field was sampled 3times during the
>>         investigation
>>         (atumn, spring, autumn -> sampling campaign).
>>         with 4 samples taken randomly at each field (1 Sample = 0.25 m?).
>>         Several environmental parameters were assessed for each field
>>         but never
>>         for one of the four samples explicitly.
>>         Hence the environmental data is often redundant for the samples,
>>         especially when climatic measurements were even similar for
>>         more ththan
>>         one field.
>>
>>         My hypothesis is that abundance increases with the age_class
>>
>>         My model is:
>>
>>         model <- glmmadmb(abundance ~ age_class + samplingCampaign +
>>         environmental1 + env2 + env3 + (1|field), data, family="poisson")
>>
>>         age_class = ordered factor
>>         sampling campaign = continous, difference to the first
>>         sampling in days
>>         (first sampling always 0)
>>         env(1-n) = continous
>>         total number of samples = 180
>>
>>         Dispersion factor is 1.45
>>
>>         I do model validation with
>>         1. plot pearson residuals against fitted values
>>         2. plot pearson residuals against each covariate in the model
>>         3. make a histogram of the residuals
>>
>>         In my opinion everything looks ok.
>>
>>         Now I have the really really big problem: *I just don't know
>>         how to
>>         present the results.*
>>         I'd like to do a barplot with mean abundances for age_class
>>         and standard
>>         errors and do Post Hoc tukey test to look at differences
>>         between the
>>         factor levels. But i just don't know how to to these Post-Hoc
>>         tests.
>>
>>         I've got one approach for extracting predictions and standard
>>         errors for
>>         predictions using a test dataset with mean environmental
>>         variables:
>>
>>         test.data=expand.grid(age_class=levels(data$age_class),
>>          samplingCampaign = data$samcam),
>>                                                  env1 = mean(data$env1),
>>                                                  env2 = max(data$env2))
>>
>>         pred.abundance <- cbind(test.data,
>>          predict(model, test.data,
>>         type="link", se.fit=TRUE),
>>          abundance.response =
>>         predict(model, test.data, type="response"))
>>
>>         pred.anc <- within(pred.abundance, {
>>                                                   anc <- 4*exp(fit)
>>                                                   LL <- 4*exp(fit -
>>         1.96 * se.fit)
>>                                                   UL <- 4*exp(fit +
>>         1.96 *
>>         se.fit)  })
>>
>>         Then I make a plot and get INCREDIBLY large standard errors
>>         and in
>>         contrast to the boxplot of the predicitons
>>         (plot(data$age_class,predict(model, type="response")), the
>>         abundance is
>>         not increasing with the age_class. I multiply by 4 since i
>>         want to
>>         present the results per m?
>>
>>         Do you know where the mistake is?
>>
>>         I would appreciate if you could help me with this analysis,
>>         since I'm
>>         trying to learn GLMM for more than a year and i can't ask a
>>         real person
>>         here at this Institution. Thanks in advance,
>>         Quentin
>>
>>
>>         --
>>
>>         Quentin Schorpp, M.Sc.
>>         Th?nen Institute of Biodiversity
>>         Bundesallee 50
>>         38116 Braunschweig (Germany)
>>
>>         Tel: +49 531 596-2524 <tel:%2B49%20531%20596-2524>
>>         Fax: +49 531 596-2599 <tel:%2B49%20531%20596-2599>
>>         Mail: quentin.schorpp at ti.bund.de
>>         <mailto:quentin.schorpp at ti.bund.de>
>>         Web: http://www.ti.bund.de
>>
>>         The Johann Heinrich von Th?nen Institute, Federal Research
>>         Institute for Rural Areas, Forestry and Fisheries ? Th?nen
>>         Institute in brief ?
>>         consists of 15 specialized institutes that carry out research
>>         and provide policy advice in the fields of economy, ecology
>>         and technology.
>>
>>
>>                 [[alternative HTML version deleted]]
>>
>>         _______________________________________________
>>         R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>     -- 
>     Quentin Schorpp, M.Sc.
>     Th?nen-Institut f?r Biodiversit?t
>     Bundesallee 50
>     38116 Braunschweig (Germany)
>
>     Tel:+49 531 596-2524  <tel:%2B49%20531%20596-2524>
>     Fax:+49 531 596-2599  <tel:%2B49%20531%20596-2599>
>     Mail:quentin.schorpp at ti.bund.de  <mailto:quentin.schorpp at ti.bund.de>
>     Web:http://www.ti.bund.de
>
>     Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
>     besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
>
>     Quentin Schorpp, M.Sc.
>     Th?nen Institute of Biodiversity
>     Bundesallee 50
>     38116 Braunschweig (Germany)
>
>     Tel:+49 531 596-2524  <tel:%2B49%20531%20596-2524>
>     Fax:+49 531 596-2599  <tel:%2B49%20531%20596-2599>
>     Mail:quentin.schorpp at ti.bund.de  <mailto:quentin.schorpp at ti.bund.de>
>     Web:http://www.ti.bund.de
>
>     The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
>     consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
>
>

-- 
Quentin Schorpp, M.Sc.
Th?nen-Institut f?r Biodiversit?t
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 27 11:48:53 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Apr 2015 11:48:53 +0200
Subject: [R-sig-ME] Results from GLMM, error bars for predictions
In-Reply-To: <553E01B6.8030701@ti.bund.de>
References: <553A4034.5010605@ti.bund.de>
	<CAJuCY5yG46M+8edUx8+AgQtcEm9ub1o95Y-z=Nta1LKXcEwOLg@mail.gmail.com>
	<553DE593.2040308@ti.bund.de>
	<CAJuCY5woXmvPjr+ibXXzLhWLvWYfDcYLfgKoyK2i-g2ctKpa+A@mail.gmail.com>
	<553E01B6.8030701@ti.bund.de>
Message-ID: <CAJuCY5wsbaRRWSu-D+hnHp2_a3gpPvgQ7K5S69mJ1r7k4sfmgg@mail.gmail.com>

Dear Quentin,

IMHO, errorbars are more important than p-values. So yes, you need to
present them. Here is an example

library(glmmADMB)
om <- glmmadmb(SiblingNegotiation~ FoodTreatment * SexParent
+(1|Nest)+offset(log(BroodSize)),zeroInflation=TRUE,family="nbinom",data=Owls)
newdata <- expand.grid(
  FoodTreatment = unique(Owls$FoodTreatment),
  SexParent = unique(Owls$SexParent),
  BroodSize = 4
)
newdata <- cbind(newdata, predict(om, newdata = newdata, interval =
"confidence"))

library(ggplot2)
ggplot(newdata, aes(x = FoodTreatment, colour = SexParent, y = exp(fit),
ymin = exp(lwr), ymax = exp(upr))) + geom_errorbar(position =
position_dodge(1)) + geom_point(position = position_dodge(1))

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-27 11:30 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de>:

>  Hello,
>
> Thank you for writing,
>
> I tried what you said, but simple addition of "offset(log(0.25))" did not
> work. Hence I created a factor "area" expressed as m? with the value 0.25
> for all observations:
>  data$area <- rep(0.25, 180)
> and added offset(log(area)) to the model formula.
>
> Ok, plotting the predicted values for all relevant combinations of the
> fixed effects was also my intention. However, the problem with the
> errorbars occured. Or is it a faulty assumption of mine, that plots of
> predicted values need error-bars?
>
> I'm sorry, i recognized that the answer was only adressed to you, after i
> send the mail. Then i send it again to the Mailing List, i hope it won't
> get to chaotic right now. Now i used "answer all"
>
> kind regards
>
>
>
>
> Am 27.04.2015 um 10:50 schrieb Thierry Onkelinx:
>
> Dear Quentin,
>
>  Please keep the mailing list in cc.
>
>  Dropping non significant terms from an ordered factor is not ok. That
> would change the interpretation of the factor. You wouldn't drop non
> significant levels of an unordered factor either.
>
>  Ben's solution is about multiple comparisons with random (and fixed)
> effects. You're only dealing with multiple comparisons with fixed effects.
> So glht() will do the trick.
>
>  Try plotting the predicted values for all relevant combinations of the
> fixed effects. I find that easier to interpret than just a bunch of
> coefficients.
>
>  Best regards,
>
>
>  ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-27 9:30 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de>:
>
>>  Dear Thierry,
>>
>> thank you very much for your advice, i didn't hear about the offset()
>> argument, yet. I'll try this immidiately.
>> My first intention was, that the large error bars are due to the high
>> variability and the low number of replicates (3), which stays true, i
>> think. The point was, that i just couldn't explain, why the output was so
>> weird, despite that the model stated significance and 0 was not within the
>> confidence intervals.
>> Now, it makes me confident to have the advice of using glht from you. I
>> was kind of  unsecure, regarding the glht procedure, because i read this
>> post on stack overflow by Ben Bolker:
>>
>> http://stackoverflow.com/questions/25949701/post-hoc-test-in-generalised-linear-mixed-models-how-to-do
>>
>> Next I'll give up treating age_class as an ordered factor, although i
>> found the idea quite interesting.
>> Do you know where to get information about using ordered factors in a
>> glmm?
>> The output was not significant for the cubic term in my case, and i asked
>> myself if i could/should skip it from the model.
>>
>> Probably i could use samplingCampaign as ordered factor.
>>
>> One thing I'm still interested in, is a tutorial that shows how to
>> present results from more than one univariate analysis in a way to have it
>> ready for publication.
>> In my opinion eyerthing, even in the books, is about modeling procedure,
>> validation, cryptic names of important coefficients. I know cooking with an
>> 0815 recipe is dangerous, but that's not what I'm looking for.
>>
>> Thank you again for your help!!
>> Quentin
>>
>>
>> Am 26.04.2015 um 20:37 schrieb Thierry Onkelinx:
>>
>>  Dear Quentin,
>>
>>  - You better use an offset if you want to express the model in terms of
>> m?. Just add offset(log(0.25)) to the model.
>> - I'd rather treat samplingCamping as a factor.
>> - You can get post hoc comparisons with the multcomp package. See the
>> example below.
>>
>>  library(glmmADMB)
>> Owls$Interaction <- interaction(Owls$FoodTreatment, Owls$SexParent)
>> om <- glmmadmb(SiblingNegotiation~
>> Interaction+(1|Nest)+offset(log(BroodSize)),zeroInflation=TRUE,family="nbinom",data=Owls)
>> library(multcomp)
>> pairwise <- glht(om, mcp(Interaction = "Tukey"))
>> pairwise.ci <- confint(pairwise)
>> library(ggplot2)
>> ggplot(pairwise.ci, aes(y = lhs, x = exp(estimate), xmin = exp(lwr),
>> xmax = exp(upr))) + geom_errorbarh() + geom_point() + geom_vline(xintercept
>> = 1)
>>
>>
>>  Best regards,
>>
>>  ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-04-24 15:08 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de>:
>>
>>> Hello Everyone,
>>>
>>> I'm using glmmadmb() to model abundance data (counts) of soil organisms
>>> (e.g. earthworms).  My design covers agricultural fields of five
>>> different age classes . Every age-class has three field replicates.
>>> Additionally every field was sampled 3times during the investigation
>>> (atumn, spring, autumn -> sampling campaign).
>>> with 4 samples taken randomly at each field (1 Sample = 0.25 m?).
>>> Several environmental parameters were assessed for each field but never
>>> for one of the four samples explicitly.
>>> Hence the environmental data is often redundant for the samples,
>>> especially when climatic measurements were even similar for more ththan
>>> one field.
>>>
>>> My hypothesis is that abundance increases with the age_class
>>>
>>> My model is:
>>>
>>> model <- glmmadmb(abundance ~ age_class + samplingCampaign +
>>> environmental1 + env2 + env3 + (1|field), data, family="poisson")
>>>
>>> age_class = ordered factor
>>> sampling campaign = continous, difference to the first sampling in days
>>> (first sampling always 0)
>>> env(1-n) = continous
>>> total number of samples = 180
>>>
>>> Dispersion factor is 1.45
>>>
>>> I do model validation with
>>> 1. plot pearson residuals against fitted values
>>> 2. plot pearson residuals against each covariate in the model
>>> 3. make a histogram of the residuals
>>>
>>> In my opinion everything looks ok.
>>>
>>> Now I have the really really big problem: *I just don't know how to
>>> present the results.*
>>> I'd like to do a barplot with mean abundances for age_class and standard
>>> errors and do Post Hoc tukey test to look at differences between the
>>> factor levels. But i just don't know how to to these Post-Hoc tests.
>>>
>>> I've got one approach for extracting predictions and standard errors for
>>> predictions using a test dataset with mean environmental variables:
>>>
>>> test.data=expand.grid(age_class=levels(data$age_class),
>>>                                          samplingCampaign = data$samcam),
>>>                                          env1 = mean(data$env1),
>>>                                          env2 = max(data$env2))
>>>
>>> pred.abundance <- cbind(test.data,
>>>                                                predict(model, test.data,
>>> type="link", se.fit=TRUE),
>>>                                                abundance.response =
>>> predict(model, test.data, type="response"))
>>>
>>> pred.anc <- within(pred.abundance, {
>>>                                           anc <- 4*exp(fit)
>>>                                           LL <- 4*exp(fit - 1.96 *
>>> se.fit)
>>>                                           UL <- 4*exp(fit + 1.96 *
>>> se.fit)  })
>>>
>>> Then I make a plot and get INCREDIBLY large standard errors and in
>>> contrast to the boxplot of the predicitons
>>> (plot(data$age_class,predict(model, type="response")), the abundance is
>>> not increasing with the age_class. I multiply by 4 since i want to
>>> present the results per m?
>>>
>>> Do you know where the mistake is?
>>>
>>> I would appreciate if you could help me with this analysis, since I'm
>>> trying to learn GLMM for more than a year and i can't ask a real person
>>> here at this Institution. Thanks in advance,
>>> Quentin
>>>
>>>
>>> --
>>>
>>> Quentin Schorpp, M.Sc.
>>> Th?nen Institute of Biodiversity
>>> Bundesallee 50
>>> 38116 Braunschweig (Germany)
>>>
>>> Tel:  +49 531 596-2524 <%2B49%20531%20596-2524>
>>> Fax:  +49 531 596-2599 <%2B49%20531%20596-2599>
>>> Mail: quentin.schorpp at ti.bund.de
>>> Web:  http://www.ti.bund.de
>>>
>>> The Johann Heinrich von Th?nen Institute, Federal Research Institute for
>>> Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
>>> consists of 15 specialized institutes that carry out research and
>>> provide policy advice in the fields of economy, ecology and technology.
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Quentin Schorpp, M.Sc.
>> Th?nen-Institut f?r Biodiversit?t
>> Bundesallee 50
>> 38116 Braunschweig (Germany)
>>
>> Tel:  +49 531 596-2524
>> Fax:  +49 531 596-2599
>> Mail: quentin.schorpp at ti.bund.de
>> Web:  http://www.ti.bund.de
>>
>> Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
>> besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
>>
>> Quentin Schorpp, M.Sc.
>> Th?nen Institute of Biodiversity
>> Bundesallee 50
>> 38116 Braunschweig (Germany)
>>
>> Tel:  +49 531 596-2524
>> Fax:  +49 531 596-2599
>> Mail: quentin.schorpp at ti.bund.de
>> Web:  http://www.ti.bund.de
>>
>> The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
>> consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
>>
>>
>
> --
> Quentin Schorpp, M.Sc.
> Th?nen-Institut f?r Biodiversit?t
> Bundesallee 50
> 38116 Braunschweig (Germany)
>
> Tel:  +49 531 596-2524
> Fax:  +49 531 596-2599
> Mail: quentin.schorpp at ti.bund.de
> Web:  http://www.ti.bund.de
>
> Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
> besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
>
> Quentin Schorpp, M.Sc.
> Th?nen Institute of Biodiversity
> Bundesallee 50
> 38116 Braunschweig (Germany)
>
> Tel:  +49 531 596-2524
> Fax:  +49 531 596-2599
> Mail: quentin.schorpp at ti.bund.de
> Web:  http://www.ti.bund.de
>
> The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
> consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
>
>

	[[alternative HTML version deleted]]


From quentin.schorpp at ti.bund.de  Mon Apr 27 13:48:42 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Mon, 27 Apr 2015 13:48:42 +0200
Subject: [R-sig-ME] Results from GLMM, error bars for predictions
In-Reply-To: <CAJuCY5wsbaRRWSu-D+hnHp2_a3gpPvgQ7K5S69mJ1r7k4sfmgg@mail.gmail.com>
References: <553A4034.5010605@ti.bund.de>	<CAJuCY5yG46M+8edUx8+AgQtcEm9ub1o95Y-z=Nta1LKXcEwOLg@mail.gmail.com>	<553DE593.2040308@ti.bund.de>	<CAJuCY5woXmvPjr+ibXXzLhWLvWYfDcYLfgKoyK2i-g2ctKpa+A@mail.gmail.com>	<553E01B6.8030701@ti.bund.de>
	<CAJuCY5wsbaRRWSu-D+hnHp2_a3gpPvgQ7K5S69mJ1r7k4sfmgg@mail.gmail.com>
Message-ID: <553E221A.9080600@ti.bund.de>

Dear Thierry,

There's one thing that i don't understand.
Why do you plot the vertical line in
ggplot(pairwise.ci <http://pairwise.ci>, aes(y = lhs, x = exp(estimate), 
xmin = exp(lwr), xmax = exp(upr))) + geom_errorbarh() + geom_point() + 
geom_vline(xintercept = 1)

and how can i transfer this to other models?

kind regards,
Quentin

Am 27.04.2015 um 11:48 schrieb Thierry Onkelinx:
> Dear Quentin,
>
> IMHO, errorbars are more important than p-values. So yes, you need to 
> present them. Here is an example
>
> library(glmmADMB)
> om <- glmmadmb(SiblingNegotiation~ FoodTreatment * SexParent 
> +(1|Nest)+offset(log(BroodSize)),zeroInflation=TRUE,family="nbinom",data=Owls)
> newdata <- expand.grid(
>   FoodTreatment = unique(Owls$FoodTreatment),
>   SexParent = unique(Owls$SexParent),
>   BroodSize = 4
> )
> newdata <- cbind(newdata, predict(om, newdata = newdata, interval = 
> "confidence"))
>
> library(ggplot2)
> ggplot(newdata, aes(x = FoodTreatment, colour = SexParent, y = 
> exp(fit), ymin = exp(lwr), ymax = exp(upr))) + geom_errorbar(position 
> = position_dodge(1)) + geom_point(position = position_dodge(1))
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2015-04-27 11:30 GMT+02:00 Quentin Schorpp <quentin.schorpp at ti.bund.de 
> <mailto:quentin.schorpp at ti.bund.de>>:
>
>     Hello,
>
>     Thank you for writing,
>
>     I tried what you said, but simple addition of "offset(log(0.25))"
>     did not work. Hence I created a factor "area" expressed as m? with
>     the value 0.25 for all observations:
>      data$area <- rep(0.25, 180)
>     and added offset(log(area)) to the model formula.
>
>     Ok, plotting the predicted values for all relevant combinations of
>     the fixed effects was also my intention. However, the problem with
>     the errorbars occured. Or is it a faulty assumption of mine, that
>     plots of predicted values need error-bars?
>
>     I'm sorry, i recognized that the answer was only adressed to you,
>     after i send the mail. Then i send it again to the Mailing List, i
>     hope it won't get to chaotic right now. Now i used "answer all"
>
>     kind regards
>
>
>
>
>     Am 27.04.2015 um 10:50 schrieb Thierry Onkelinx:
>>     Dear Quentin,
>>
>>     Please keep the mailing list in cc.
>>
>>     Dropping non significant terms from an ordered factor is not ok.
>>     That would change the interpretation of the factor. You wouldn't
>>     drop non significant levels of an unordered factor either.
>>
>>     Ben's solution is about multiple comparisons with random (and
>>     fixed) effects. You're only dealing with multiple comparisons
>>     with fixed effects. So glht() will do the trick.
>>
>>     Try plotting the predicted values for all relevant combinations
>>     of the fixed effects. I find that easier to interpret than just a
>>     bunch of coefficients.
>>
>>     Best regards,
>>
>>
>>     ir. Thierry Onkelinx
>>     Instituut voor natuur- en bosonderzoek / Research Institute for
>>     Nature and Forest
>>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>     Assurance
>>     Kliniekstraat 25
>>     1070 Anderlecht
>>     Belgium
>>
>>     To call in the statistician after the experiment is done may be
>>     no more than asking him to perform a post-mortem examination: he
>>     may be able to say what the experiment died of. ~ Sir Ronald
>>     Aylmer Fisher
>>     The plural of anecdote is not data. ~ Roger Brinner
>>     The combination of some data and an aching desire for an answer
>>     does not ensure that a reasonable answer can be extracted from a
>>     given body of data. ~ John Tukey
>>
>>     2015-04-27 9:30 GMT+02:00 Quentin Schorpp
>>     <quentin.schorpp at ti.bund.de <mailto:quentin.schorpp at ti.bund.de>>:
>>
>>         Dear Thierry,
>>
>>         thank you very much for your advice, i didn't hear about the
>>         offset() argument, yet. I'll try this immidiately.
>>         My first intention was, that the large error bars are due to
>>         the high variability and the low number of replicates (3),
>>         which stays true, i think. The point was, that i just
>>         couldn't explain, why the output was so weird, despite that
>>         the model stated significance and 0 was not within the
>>         confidence intervals.
>>         Now, it makes me confident to have the advice of using glht
>>         from you. I was kind of  unsecure, regarding the glht
>>         procedure, because i read this post on stack overflow by Ben
>>         Bolker:
>>         http://stackoverflow.com/questions/25949701/post-hoc-test-in-generalised-linear-mixed-models-how-to-do
>>
>>
>>         Next I'll give up treating age_class as an ordered factor,
>>         although i found the idea quite interesting.
>>         Do you know where to get information about using ordered
>>         factors in a glmm?
>>         The output was not significant for the cubic term in my case,
>>         and i asked myself if i could/should skip it from the model.
>>
>>         Probably i could use samplingCampaign as ordered factor.
>>
>>         One thing I'm still interested in, is a tutorial that shows
>>         how to present results from more than one univariate analysis
>>         in a way to have it ready for publication.
>>         In my opinion eyerthing, even in the books, is about modeling
>>         procedure, validation, cryptic names of important
>>         coefficients. I know cooking with an 0815 recipe is
>>         dangerous, but that's not what I'm looking for.
>>
>>         Thank you again for your help!!
>>         Quentin
>>
>>
>>         Am 26.04.2015 um 20:37 schrieb Thierry Onkelinx:
>>>         Dear Quentin,
>>>
>>>         - You better use an offset if you want to express the model
>>>         in terms of m?. Just add offset(log(0.25)) to the model.
>>>         - I'd rather treat samplingCamping as a factor.
>>>         - You can get post hoc comparisons with the multcomp
>>>         package. See the example below.
>>>
>>>         library(glmmADMB)
>>>         Owls$Interaction <- interaction(Owls$FoodTreatment,
>>>         Owls$SexParent)
>>>         om <- glmmadmb(SiblingNegotiation~
>>>         Interaction+(1|Nest)+offset(log(BroodSize)),zeroInflation=TRUE,family="nbinom",data=Owls)
>>>         library(multcomp)
>>>         pairwise <- glht(om, mcp(Interaction = "Tukey"))
>>>         pairwise.ci <http://pairwise.ci> <- confint(pairwise)
>>>         library(ggplot2)
>>>         ggplot(pairwise.ci <http://pairwise.ci>, aes(y = lhs, x =
>>>         exp(estimate), xmin = exp(lwr), xmax = exp(upr))) +
>>>         geom_errorbarh() + geom_point() + geom_vline(xintercept = 1)
>>>
>>>         Best regards,
>>>
>>>         ir. Thierry Onkelinx
>>>         Instituut voor natuur- en bosonderzoek / Research Institute
>>>         for Nature and Forest
>>>         team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>>         Assurance
>>>         Kliniekstraat 25
>>>         1070 Anderlecht
>>>         Belgium
>>>
>>>         To call in the statistician after the experiment is done may
>>>         be no more than asking him to perform a post-mortem
>>>         examination: he may be able to say what the experiment died
>>>         of. ~ Sir Ronald Aylmer Fisher
>>>         The plural of anecdote is not data. ~ Roger Brinner
>>>         The combination of some data and an aching desire for an
>>>         answer does not ensure that a reasonable answer can be
>>>         extracted from a given body of data. ~ John Tukey
>>>
>>>         2015-04-24 15:08 GMT+02:00 Quentin Schorpp
>>>         <quentin.schorpp at ti.bund.de
>>>         <mailto:quentin.schorpp at ti.bund.de>>:
>>>
>>>             Hello Everyone,
>>>
>>>             I'm using glmmadmb() to model abundance data (counts) of
>>>             soil organisms
>>>             (e.g. earthworms).  My design covers agricultural fields
>>>             of five
>>>             different age classes . Every age-class has three field
>>>             replicates.
>>>             Additionally every field was sampled 3times during the
>>>             investigation
>>>             (atumn, spring, autumn -> sampling campaign).
>>>             with 4 samples taken randomly at each field (1 Sample =
>>>             0.25 m?).
>>>             Several environmental parameters were assessed for each
>>>             field but never
>>>             for one of the four samples explicitly.
>>>             Hence the environmental data is often redundant for the
>>>             samples,
>>>             especially when climatic measurements were even similar
>>>             for more ththan
>>>             one field.
>>>
>>>             My hypothesis is that abundance increases with the age_class
>>>
>>>             My model is:
>>>
>>>             model <- glmmadmb(abundance ~ age_class + samplingCampaign +
>>>             environmental1 + env2 + env3 + (1|field), data,
>>>             family="poisson")
>>>
>>>             age_class = ordered factor
>>>             sampling campaign = continous, difference to the first
>>>             sampling in days
>>>             (first sampling always 0)
>>>             env(1-n) = continous
>>>             total number of samples = 180
>>>
>>>             Dispersion factor is 1.45
>>>
>>>             I do model validation with
>>>             1. plot pearson residuals against fitted values
>>>             2. plot pearson residuals against each covariate in the
>>>             model
>>>             3. make a histogram of the residuals
>>>
>>>             In my opinion everything looks ok.
>>>
>>>             Now I have the really really big problem: *I just don't
>>>             know how to
>>>             present the results.*
>>>             I'd like to do a barplot with mean abundances for
>>>             age_class and standard
>>>             errors and do Post Hoc tukey test to look at differences
>>>             between the
>>>             factor levels. But i just don't know how to to these
>>>             Post-Hoc tests.
>>>
>>>             I've got one approach for extracting predictions and
>>>             standard errors for
>>>             predictions using a test dataset with mean environmental
>>>             variables:
>>>
>>>             test.data=expand.grid(age_class=levels(data$age_class),
>>>                  samplingCampaign = data$samcam),
>>>                  env1 = mean(data$env1),
>>>                  env2 = max(data$env2))
>>>
>>>             pred.abundance <- cbind(test.data,
>>>                        predict(model, test.data,
>>>             type="link", se.fit=TRUE),
>>>                        abundance.response =
>>>             predict(model, test.data, type="response"))
>>>
>>>             pred.anc <- within(pred.abundance, {
>>>                   anc <- 4*exp(fit)
>>>                   LL <- 4*exp(fit - 1.96 * se.fit)
>>>                   UL <- 4*exp(fit + 1.96 *
>>>             se.fit)  })
>>>
>>>             Then I make a plot and get INCREDIBLY large standard
>>>             errors and in
>>>             contrast to the boxplot of the predicitons
>>>             (plot(data$age_class,predict(model, type="response")),
>>>             the abundance is
>>>             not increasing with the age_class. I multiply by 4 since
>>>             i want to
>>>             present the results per m?
>>>
>>>             Do you know where the mistake is?
>>>
>>>             I would appreciate if you could help me with this
>>>             analysis, since I'm
>>>             trying to learn GLMM for more than a year and i can't
>>>             ask a real person
>>>             here at this Institution. Thanks in advance,
>>>             Quentin
>>>
>>>
>>>             --
>>>
>>>             Quentin Schorpp, M.Sc.
>>>             Th?nen Institute of Biodiversity
>>>             Bundesallee 50
>>>             38116 Braunschweig (Germany)
>>>
>>>             Tel: +49 531 596-2524 <tel:%2B49%20531%20596-2524>
>>>             Fax: +49 531 596-2599 <tel:%2B49%20531%20596-2599>
>>>             Mail: quentin.schorpp at ti.bund.de
>>>             <mailto:quentin.schorpp at ti.bund.de>
>>>             Web: http://www.ti.bund.de
>>>
>>>             The Johann Heinrich von Th?nen Institute, Federal
>>>             Research Institute for Rural Areas, Forestry and
>>>             Fisheries ? Th?nen Institute in brief ?
>>>             consists of 15 specialized institutes that carry out
>>>             research and provide policy advice in the fields of
>>>             economy, ecology and technology.
>>>
>>>
>>>                     [[alternative HTML version deleted]]
>>>
>>>             _______________________________________________
>>>             R-sig-mixed-models at r-project.org
>>>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>         -- 
>>         Quentin Schorpp, M.Sc.
>>         Th?nen-Institut f?r Biodiversit?t
>>         Bundesallee 50
>>         38116 Braunschweig (Germany)
>>
>>         Tel:+49 531 596-2524  <tel:%2B49%20531%20596-2524>
>>         Fax:+49 531 596-2599  <tel:%2B49%20531%20596-2599>
>>         Mail:quentin.schorpp at ti.bund.de  <mailto:quentin.schorpp at ti.bund.de>
>>         Web:http://www.ti.bund.de
>>
>>         Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
>>         besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
>>
>>         Quentin Schorpp, M.Sc.
>>         Th?nen Institute of Biodiversity
>>         Bundesallee 50
>>         38116 Braunschweig (Germany)
>>
>>         Tel:+49 531 596-2524  <tel:%2B49%20531%20596-2524>
>>         Fax:+49 531 596-2599  <tel:%2B49%20531%20596-2599>
>>         Mail:quentin.schorpp at ti.bund.de  <mailto:quentin.schorpp at ti.bund.de>
>>         Web:http://www.ti.bund.de
>>
>>         The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
>>         consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
>>
>>
>
>     -- 
>     Quentin Schorpp, M.Sc.
>     Th?nen-Institut f?r Biodiversit?t
>     Bundesallee 50
>     38116 Braunschweig (Germany)
>
>     Tel:+49 531 596-2524  <tel:%2B49%20531%20596-2524>
>     Fax:+49 531 596-2599  <tel:%2B49%20531%20596-2599>
>     Mail:quentin.schorpp at ti.bund.de  <mailto:quentin.schorpp at ti.bund.de>
>     Web:http://www.ti.bund.de
>
>     Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
>     besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.
>
>     Quentin Schorpp, M.Sc.
>     Th?nen Institute of Biodiversity
>     Bundesallee 50
>     38116 Braunschweig (Germany)
>
>     Tel:+49 531 596-2524  <tel:%2B49%20531%20596-2524>
>     Fax:+49 531 596-2599  <tel:%2B49%20531%20596-2599>
>     Mail:quentin.schorpp at ti.bund.de  <mailto:quentin.schorpp at ti.bund.de>
>     Web:http://www.ti.bund.de
>
>     The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
>     consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.
>
>

-- 
Quentin Schorpp, M.Sc.
Th?nen-Institut f?r Biodiversit?t
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

Das Johann Heinrich von Th?nen-Institut, Bundesforschungsinstitut f?r L?ndliche R?ume, Wald und Fischerei ? kurz: Th?nen-Institut ?
besteht aus 15 Fachinstituten, die in den Bereichen ?konomie, ?kologie und Technologie forschen und die Politik beraten.

Quentin Schorpp, M.Sc.
Th?nen Institute of Biodiversity
Bundesallee 50
38116 Braunschweig (Germany)

Tel:  +49 531 596-2524
Fax:  +49 531 596-2599
Mail: quentin.schorpp at ti.bund.de
Web:  http://www.ti.bund.de

The Johann Heinrich von Th?nen Institute, Federal Research Institute for Rural Areas, Forestry and Fisheries ? Th?nen Institute in brief ?
consists of 15 specialized institutes that carry out research and provide policy advice in the fields of economy, ecology and technology.


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Apr 27 15:34:16 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 27 Apr 2015 13:34:16 +0000 (UTC)
Subject: [R-sig-ME] Results from GLMM, error bars for predictions
References: <553A4034.5010605@ti.bund.de>	<CAJuCY5yG46M+8edUx8+AgQtcEm9ub1o95Y-z=Nta1LKXcEwOLg@mail.gmail.com>	<553DE593.2040308@ti.bund.de>	<CAJuCY5woXmvPjr+ibXXzLhWLvWYfDcYLfgKoyK2i-g2ctKpa+A@mail.gmail.com>	<553E01B6.8030701@ti.bund.de>
	<CAJuCY5wsbaRRWSu-D+hnHp2_a3gpPvgQ7K5S69mJ1r7k4sfmgg@mail.gmail.com>
	<553E221A.9080600@ti.bund.de>
Message-ID: <loom.20150427T153122-447@post.gmane.org>

Quentin Schorpp <quentin.schorpp at ...> writes:

> 
> Dear Thierry,
> 
> There's one thing that i don't understand.
> Why do you plot the vertical line in
> ggplot(pairwise.ci <http://pairwise.ci>, aes(y = lhs, x = exp(estimate), 
> xmin = exp(lwr), xmax = exp(upr))) + geom_errorbarh() + geom_point() + 
> geom_vline(xintercept = 1)
> 
> and how can i transfer this to other models?
> 
> kind regards,
> Quentin

  [Sorry to remove context, gmane doesn't like it ...]

  Since the model parameters are back-transformed (i.e.
exponentiated), the null value of the parameters (no effect)
is exp(0)=1; the horizontal line is showing the null value.
Thus for example if the 95% confidence intervals cross the
dotted line, the corresponding effect is not statistically
significant at p=0.05.


From robertzimbardo at gmail.com  Mon Apr 27 05:14:08 2015
From: robertzimbardo at gmail.com (Robert Zimbardo)
Date: Sun, 26 Apr 2015 20:14:08 -0700
Subject: [R-sig-ME] predict.merMod with random slopes - revisiting an older
	issue?
Message-ID: <CAGJyvhFfCQeJJ9PgY9qkT-QuU=b4tBfoUSt3rANBu+Zu2kR+VQ@mail.gmail.com>

Hi all

I am writing with regard to an issue that came up here before and that
I thought was resolved; here are the links:

https://github.com/lme4/lme4/issues/153
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q4/021284.html

Specifically, I have a very simple model

m <- lmer(y~x+(x|i)

Predictions without random effects, no problem:
predict(m, newdata=data.frame(i="3", x=0.2), re.form=NA) # works perfectly

But trying to get predictions with the random effects returns an error
know from the above links
predict(m, newdata=data.frame(i="3", x=0.2), re.form=NULL) # returns
"Error: sum(nb) == q is not TRUE"

I'm using RRO 8.0.1.beta, RStudio 0.99.408, lme4 1.1-7 on Win7 x64.

Any ideas?


From adrion at ibe.med.uni-muenchen.de  Tue Apr 28 13:42:42 2015
From: adrion at ibe.med.uni-muenchen.de (Christine Adrion)
Date: Tue, 28 Apr 2015 13:42:42 +0200
Subject: [R-sig-ME] glmer.nb(): Residual term ??
Message-ID: <692ffdafd54b1c1862c71590c2a41370.squirrel@webmail.ibe.med.uni-muenchen.de>

Hello,

I fit a negative binomial GLMM using the lme4 package (version
lme4_1.1-7), R-function glmer.nb(). It seems that this is still an
experimental feature. The help function does not explain the residual term
in the resulting R output.

#---------------
# Reproducible example:
tmpf <- function() {
    x <- runif(400) - 0.5
    z <- gl(n=40, k=10)
    m <- model.matrix(~x + z)
    u <- rnorm(40, sd=0.5)
    eta <- m %*% c(0, 3, u[-1] - u[1])
    y <- rnbinom(n=length(eta), size=3, mu=exp(eta))
    data.frame(y, x, z)
}

set.seed(2011)
simdf <- tmpf()
m <- glmer.nb(y ~ x + (1|z), data=simdf)
m

##------------ output --------------------
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: Negative Binomial(6.7839)  ( log )
Formula: y ~ x + (1 | z)
   Data: ..2
      AIC       BIC    logLik  deviance  df.resid
 890.5451  906.5109 -441.2725  882.5451       396
Random effects:
 Groups   Name        Std.Dev.
 z        (Intercept) 0.3923
 Residual             0.9665
Number of obs: 400, groups:  z, 40
Fixed Effects:
(Intercept)            x
    -0.5511       2.5969
#-----------------------------------------

Unfortunately, it's not clear to me what the measure "Residual" exactly
expresses and thus why it is used by glmer.nb.


[BTW, the fitted dispersion parameter 'size' is not very close to the true
one (which was 3).]

Thanks for any help/explanation.

Kind regards
Christine


From dfulop.ucd at gmail.com  Tue Apr 28 17:21:44 2015
From: dfulop.ucd at gmail.com (Daniel Fulop)
Date: Tue, 28 Apr 2015 08:21:44 -0700
Subject: [R-sig-ME] glmer.nb(): Residual term ??
In-Reply-To: <692ffdafd54b1c1862c71590c2a41370.squirrel@webmail.ibe.med.uni-muenchen.de>
References: <692ffdafd54b1c1862c71590c2a41370.squirrel@webmail.ibe.med.uni-muenchen.de>
Message-ID: <553FA588.4050809@gmail.com>

Hi Christine,

Others more knowledgeable than I may chime in, but as far as I know the 
GLMM parameterization that lme4 uses doesn't have a residual error 
term.  Other R software does have residuals, such as MCMCglmm.

HTH,
Dan.

Christine Adrion wrote:
> Hello,
>
> I fit a negative binomial GLMM using the lme4 package (version
> lme4_1.1-7), R-function glmer.nb(). It seems that this is still an
> experimental feature. The help function does not explain the residual term
> in the resulting R output.
>
> #---------------
> # Reproducible example:
> tmpf<- function() {
>      x<- runif(400) - 0.5
>      z<- gl(n=40, k=10)
>      m<- model.matrix(~x + z)
>      u<- rnorm(40, sd=0.5)
>      eta<- m %*% c(0, 3, u[-1] - u[1])
>      y<- rnbinom(n=length(eta), size=3, mu=exp(eta))
>      data.frame(y, x, z)
> }
>
> set.seed(2011)
> simdf<- tmpf()
> m<- glmer.nb(y ~ x + (1|z), data=simdf)
> m
>
> ##------------ output --------------------
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>   Family: Negative Binomial(6.7839)  ( log )
> Formula: y ~ x + (1 | z)
>     Data: ..2
>        AIC       BIC    logLik  deviance  df.resid
>   890.5451  906.5109 -441.2725  882.5451       396
> Random effects:
>   Groups   Name        Std.Dev.
>   z        (Intercept) 0.3923
>   Residual             0.9665
> Number of obs: 400, groups:  z, 40
> Fixed Effects:
> (Intercept)            x
>      -0.5511       2.5969
> #-----------------------------------------
>
> Unfortunately, it's not clear to me what the measure "Residual" exactly
> expresses and thus why it is used by glmer.nb.
>
>
> [BTW, the fitted dispersion parameter 'size' is not very close to the true
> one (which was 3).]
>
> Thanks for any help/explanation.
>
> Kind regards
> Christine
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616


From genevieve.c.perkins at gmail.com  Tue Apr 28 22:41:56 2015
From: genevieve.c.perkins at gmail.com (Genevieve Perkins)
Date: Tue, 28 Apr 2015 16:41:56 -0400
Subject: [R-sig-ME] GlmmADMB: random slopes and fixed effects
Message-ID: <CAH_uvpUsKt1KMVFdraNtEgHjC3YuKGO6tQ9JUU9Du7at3ESPYA@mail.gmail.com>

Hello,

I am a masters student new to the world of GLMMs. I have developed a mixed
model using the glmmADMB package and I have been scouring the literature
and help files, and trying to find an answer to my questions with no
success.

I want to estimate the effect of cats on bird abundance for birds with
particular traits (all traits are binary coded (0,1);
Specifically I am looking at the interaction estimate.

I included species as a random effect, and I wanted the species response to
vary with Vegetation (Veg) and Population (Pop). I also added a random
level observation term.

      Model 1: fitn <- glmmadmb(as.formula(bird.abund ~ Cat + trait + Cat:trait
+ (1 + Veg + Pop + Cat|Species) + (1|ID)), data = bdata,family= "nbinom")


I noticed however that if I include Veg and Pop as fixed effects (model 2)
my model estimate for cats at the fixed effect level and species level also
change.

      Model 2: fitn <- glmmadmb(as.formula(bird.abund ~ Cats + trait +
Cat:trait
+ Veg + Pop + (1 + Veg + Pop + Cats|Species) + (1|ID)), data = bdata,
family= "nbinom")


My questions are:
1)  Is it possible to include varying slope coefficients (ie: Veg and Pop)
in a GLMM model without including them as fixed effects? (I couldn't find
any examples of this format)

2) How are the estimates for the random effects treated without a corresponding
fixed effect in Glmmadmb. I was guessing they may be pooled to a group mean
of zero, but I was not able to find this information in the glmmadmb
literature.

All suggestions greatly appreciated!
Thanks

	[[alternative HTML version deleted]]


From markl033 at umn.edu  Wed Apr 29 07:24:53 2015
From: markl033 at umn.edu (Tricia Markle)
Date: Wed, 29 Apr 2015 00:24:53 -0500
Subject: [R-sig-ME] Adding additional factor to previously working MCMCglmm
 model kills it. Problem with priors? Help?
Message-ID: <CAO=0ZJXTc=YVW8twcAt+m1gUQ4YpZWGt05LZx-zUrS6_QMK-hg@mail.gmail.com>

Hello,



I have a working MCMCglmm model with phylogenetic consideration and repeat
measures. I realized after the fact that ?species? wasn?t properly included
in the model. When I added this additional factor (of 17 levels), however,
I received the following error message:

--------



Error in MCMCglmm(LVO2 ~ 1 + Temp + Acclm + Lat_Ext + LMass + Sex + species
+  :  ill-conditioned G/R structure: use proper priors if you haven't or
rescale data if you have

In addition: Warning message:

In MCMCglmm(LVO2 ~ 1 + Temp + Acclm + Lat_Ext + LMass + Sex + species +  :

  some fixed effects are not estimable and have been removed. Use
singular.ok=TRUE to sample these effects, but use an informative prior!



----------



I had some help with my priors originally so I am not sure the best way to
now tweak them to make them work? Could different priors help or is there
something ?wrong? with adding species as another factor?



My hypothesis centers around the remaining significant interaction term
Acclm:Lat_Ext ? whether the relationship of acclimation on oxygen
consumption (VO2) is differs depending on the latitudinal extent of a
species (while also considering a number of covariates).



Here is my code:



library(ape)

library(MCMCglmm)

dataset<-read.csv(file="RespData.csv", head=TRUE)

attach(dataset)

str(dataset) # confirming that sex, range, species, and ID are all factors



#Phylogeny Component

tree<-read.tree("Plethodontidae_comb61_PL.phy")

species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
"D._ochrophaeus_WKS05", "D._ocoee_B_KHK62", "D._orestes_KHK129",
"D._monticola_A",  "D._santeetlah_11775", "P_cinereus", "P_cylindraceus",
"P_glutinosus", "P_hubrichti", "P_montanus", "P_punctatus", "P_richmondi",
"P_teyahalee", "P_virginia", "P_wehrlei")

pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
tree$tip.label)])# Prune tree to just include species of interest

sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node")



treeAinv<-inverseA(sptree, nodes="TIPS")$Ainv

random=~us(1+Temp):species

prior<-list(G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
alpha.V=diag(2)*1000)), R=list(V=diag(1), nu=0.002))



#Model 1

model1<MCMCglmm(LVO2~1+Temp+Acclm+Lat_Ext+LMass+Sex+species+Temp*Acclm+Temp*Lat_Ext+Acclm*Lat_Ext+Temp*Acclm*Lat*Ext,
random=random, data=dataset, family="gaussian",
ginverse=list(species=treeAinv), prior=prior, nitt=300000, burnin=25000,
thin = 1000, verbose=FALSE)



Thank you kindly for your help!



Tricia

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Apr 29 07:46:11 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 29 Apr 2015 06:46:11 +0100
Subject: [R-sig-ME] Adding additional factor to previously working
 MCMCglmm model kills it. Problem with priors? Help?
In-Reply-To: <CAO=0ZJXTc=YVW8twcAt+m1gUQ4YpZWGt05LZx-zUrS6_QMK-hg@mail.gmail.com>
References: <CAO=0ZJXTc=YVW8twcAt+m1gUQ4YpZWGt05LZx-zUrS6_QMK-hg@mail.gmail.com>
Message-ID: <20150429064611.85661ub1jydm30pw@www.staffmail.ed.ac.uk>

Hi,

If you want iid species effects then put them in the random part. You  
will need to rename them so that they are not associated with the  
ginverse. For example,

dataset$species.ide<-dataset$species

and fit species.ide as a random effect.

You only have 17 species. This is not enough to get precise estimates  
of the variance components and so you should expect prior sensitivity,  
particularly with respect to the phylogenetic part. I would try and  
simplify your model. I'm not sure how many of the fixed effects are  
species-level or individual-level but I would try and reduce the  
complexity of the fixed part of the model too (for example is the  
4-way interaction needed?). The warning usually indicates that the  
model is overparameterised.

Cheers,

Jarrod




  Quoting Tricia Markle <markl033 at umn.edu> on Wed, 29 Apr 2015 00:24:53 -0500:

> Hello,
>
>
>
> I have a working MCMCglmm model with phylogenetic consideration and repeat
> measures. I realized after the fact that ?species? wasn?t properly included
> in the model. When I added this additional factor (of 17 levels), however,
> I received the following error message:
>
> --------
>
>
>
> Error in MCMCglmm(LVO2 ~ 1 + Temp + Acclm + Lat_Ext + LMass + Sex + species
> +  :  ill-conditioned G/R structure: use proper priors if you haven't or
> rescale data if you have
>
> In addition: Warning message:
>
> In MCMCglmm(LVO2 ~ 1 + Temp + Acclm + Lat_Ext + LMass + Sex + species +  :
>
>   some fixed effects are not estimable and have been removed. Use
> singular.ok=TRUE to sample these effects, but use an informative prior!
>
>
>
> ----------
>
>
>
> I had some help with my priors originally so I am not sure the best way to
> now tweak them to make them work? Could different priors help or is there
> something ?wrong? with adding species as another factor?
>
>
>
> My hypothesis centers around the remaining significant interaction term
> Acclm:Lat_Ext ? whether the relationship of acclimation on oxygen
> consumption (VO2) is differs depending on the latitudinal extent of a
> species (while also considering a number of covariates).
>
>
>
> Here is my code:
>
>
>
> library(ape)
>
> library(MCMCglmm)
>
> dataset<-read.csv(file="RespData.csv", head=TRUE)
>
> attach(dataset)
>
> str(dataset) # confirming that sex, range, species, and ID are all factors
>
>
>
> #Phylogeny Component
>
> tree<-read.tree("Plethodontidae_comb61_PL.phy")
>
> species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
> "D._ochrophaeus_WKS05", "D._ocoee_B_KHK62", "D._orestes_KHK129",
> "D._monticola_A",  "D._santeetlah_11775", "P_cinereus", "P_cylindraceus",
> "P_glutinosus", "P_hubrichti", "P_montanus", "P_punctatus", "P_richmondi",
> "P_teyahalee", "P_virginia", "P_wehrlei")
>
> pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
> tree$tip.label)])# Prune tree to just include species of interest
>
> sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node")
>
>
>
> treeAinv<-inverseA(sptree, nodes="TIPS")$Ainv
>
> random=~us(1+Temp):species
>
> prior<-list(G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
> alpha.V=diag(2)*1000)), R=list(V=diag(1), nu=0.002))
>
>
>
> #Model 1
>
> model1<MCMCglmm(LVO2~1+Temp+Acclm+Lat_Ext+LMass+Sex+species+Temp*Acclm+Temp*Lat_Ext+Acclm*Lat_Ext+Temp*Acclm*Lat*Ext,
> random=random, data=dataset, family="gaussian",
> ginverse=list(species=treeAinv), prior=prior, nitt=300000, burnin=25000,
> thin = 1000, verbose=FALSE)
>
>
>
> Thank you kindly for your help!
>
>
>
> Tricia
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From thierry.onkelinx at inbo.be  Wed Apr 29 09:51:24 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 29 Apr 2015 09:51:24 +0200
Subject: [R-sig-ME] GlmmADMB: random slopes and fixed effects
In-Reply-To: <CAH_uvpUsKt1KMVFdraNtEgHjC3YuKGO6tQ9JUU9Du7at3ESPYA@mail.gmail.com>
References: <CAH_uvpUsKt1KMVFdraNtEgHjC3YuKGO6tQ9JUU9Du7at3ESPYA@mail.gmail.com>
Message-ID: <CAJuCY5xsz0Th6BAXuvN62-DXNgv5bFhOPNvaNRsAVHhd-9moGw@mail.gmail.com>

Dear Genevieve,

An observation level random effect (OLRE) is used in a poisson or binomial
glmm to model the overdispersion. The negative binomial distribution has a
parameter that handles the overdispersion. So you don't need the ORLE.

Note that the as.formula() is not required.

Random slopes assume that the parameters follow a normal distribution with
zero mean. When the overall slope is not zero, this assumption is violated
when the variable is not used as a fixed effect.

Note that you better center random slopes to get more stable estimates. Do
you have enough data to fit such a complex model? The variance covariance
matrix of the Species random effect requires 10 parameters. I would strive
for >100 observations per species and >10 species.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-28 22:41 GMT+02:00 Genevieve Perkins <genevieve.c.perkins at gmail.com>
:

> Hello,
>
> I am a masters student new to the world of GLMMs. I have developed a mixed
> model using the glmmADMB package and I have been scouring the literature
> and help files, and trying to find an answer to my questions with no
> success.
>
> I want to estimate the effect of cats on bird abundance for birds with
> particular traits (all traits are binary coded (0,1);
> Specifically I am looking at the interaction estimate.
>
> I included species as a random effect, and I wanted the species response to
> vary with Vegetation (Veg) and Population (Pop). I also added a random
> level observation term.
>
>       Model 1: fitn <- glmmadmb(as.formula(bird.abund ~ Cat + trait +
> Cat:trait
> + (1 + Veg + Pop + Cat|Species) + (1|ID)), data = bdata,family= "nbinom")
>
>
> I noticed however that if I include Veg and Pop as fixed effects (model 2)
> my model estimate for cats at the fixed effect level and species level also
> change.
>
>       Model 2: fitn <- glmmadmb(as.formula(bird.abund ~ Cats + trait +
> Cat:trait
> + Veg + Pop + (1 + Veg + Pop + Cats|Species) + (1|ID)), data = bdata,
> family= "nbinom")
>
>
> My questions are:
> 1)  Is it possible to include varying slope coefficients (ie: Veg and Pop)
> in a GLMM model without including them as fixed effects? (I couldn't find
> any examples of this format)
>
> 2) How are the estimates for the random effects treated without a
> corresponding
> fixed effect in Glmmadmb. I was guessing they may be pooled to a group mean
> of zero, but I was not able to find this information in the glmmadmb
> literature.
>
> All suggestions greatly appreciated!
> Thanks
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From genevieve.c.perkins at gmail.com  Wed Apr 29 15:56:20 2015
From: genevieve.c.perkins at gmail.com (Genevieve Perkins)
Date: Wed, 29 Apr 2015 09:56:20 -0400
Subject: [R-sig-ME] GlmmADMB: random slopes and fixed effects
In-Reply-To: <CAJuCY5xsz0Th6BAXuvN62-DXNgv5bFhOPNvaNRsAVHhd-9moGw@mail.gmail.com>
References: <CAH_uvpUsKt1KMVFdraNtEgHjC3YuKGO6tQ9JUU9Du7at3ESPYA@mail.gmail.com>
	<CAJuCY5xsz0Th6BAXuvN62-DXNgv5bFhOPNvaNRsAVHhd-9moGw@mail.gmail.com>
Message-ID: <CAH_uvpXe2Bxzd3yGUVrZHV35G0sfJYZS09njKO8Dy=4ZjBDDuQ@mail.gmail.com>

Hi Thierry,
Thanks for the response and great advice.

I have 25 species, 59 sites and total of 1475 observations (including
absences).
I didn't mention in the post, but I centered all my predictor variables
prior to fitting the model (except trait,which is coded as -1 or +1 for
ease of interpretation).

I am able to run the model both with and without fixed affects :

 fitn <- glmmadmb(bird.abund ~ Cats + trait + Cat:trait + Veg + Pop + (1 +
Veg + Pop + Cats|Species), data = bdata, family= "nbinom").

The parameters for the random slope do not have normal distributions, so I
will take your advice and also include these as fixed effects.

Could you suggest any references which explain how random slopes are
treated. I have mainly been using Zurr, Gelman and Hill, chapters from
Ecological Statistics (eds. Fox et al.) and online postings.

Thanks again!





On 29 April 2015 at 03:51, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Genevieve,
>
> An observation level random effect (OLRE) is used in a poisson or binomial
> glmm to model the overdispersion. The negative binomial distribution has a
> parameter that handles the overdispersion. So you don't need the ORLE.
>
> Note that the as.formula() is not required.
>
> Random slopes assume that the parameters follow a normal distribution with
> zero mean. When the overall slope is not zero, this assumption is violated
> when the variable is not used as a fixed effect.
>
> Note that you better center random slopes to get more stable estimates. Do
> you have enough data to fit such a complex model? The variance covariance
> matrix of the Species random effect requires 10 parameters. I would strive
> for >100 observations per species and >10 species.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-28 22:41 GMT+02:00 Genevieve Perkins <
> genevieve.c.perkins at gmail.com>:
>
>> Hello,
>>
>> I am a masters student new to the world of GLMMs. I have developed a mixed
>> model using the glmmADMB package and I have been scouring the literature
>> and help files, and trying to find an answer to my questions with no
>> success.
>>
>> I want to estimate the effect of cats on bird abundance for birds with
>> particular traits (all traits are binary coded (0,1);
>> Specifically I am looking at the interaction estimate.
>>
>> I included species as a random effect, and I wanted the species response
>> to
>> vary with Vegetation (Veg) and Population (Pop). I also added a random
>> level observation term.
>>
>>       Model 1: fitn <- glmmadmb(as.formula(bird.abund ~ Cat + trait +
>> Cat:trait
>> + (1 + Veg + Pop + Cat|Species) + (1|ID)), data = bdata,family= "nbinom")
>>
>>
>> I noticed however that if I include Veg and Pop as fixed effects (model 2)
>> my model estimate for cats at the fixed effect level and species level
>> also
>> change.
>>
>>       Model 2: fitn <- glmmadmb(as.formula(bird.abund ~ Cats + trait +
>> Cat:trait
>> + Veg + Pop + (1 + Veg + Pop + Cats|Species) + (1|ID)), data = bdata,
>> family= "nbinom")
>>
>>
>> My questions are:
>> 1)  Is it possible to include varying slope coefficients (ie: Veg and Pop)
>> in a GLMM model without including them as fixed effects? (I couldn't find
>> any examples of this format)
>>
>> 2) How are the estimates for the random effects treated without a
>> corresponding
>> fixed effect in Glmmadmb. I was guessing they may be pooled to a group
>> mean
>> of zero, but I was not able to find this information in the glmmadmb
>> literature.
>>
>> All suggestions greatly appreciated!
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Thu Apr 30 01:58:53 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 30 Apr 2015 09:58:53 +1000
Subject: [R-sig-ME] GlmmADMB: random slopes and fixed effects
In-Reply-To: <CAH_uvpXe2Bxzd3yGUVrZHV35G0sfJYZS09njKO8Dy=4ZjBDDuQ@mail.gmail.com>
References: <CAH_uvpUsKt1KMVFdraNtEgHjC3YuKGO6tQ9JUU9Du7at3ESPYA@mail.gmail.com>
	<CAJuCY5xsz0Th6BAXuvN62-DXNgv5bFhOPNvaNRsAVHhd-9moGw@mail.gmail.com>
	<CAH_uvpXe2Bxzd3yGUVrZHV35G0sfJYZS09njKO8Dy=4ZjBDDuQ@mail.gmail.com>
Message-ID: <CAF5_5cxazzi7XEXOwEq3mfiSRJpySuEa-Ps6To3SHqGADtj_9g@mail.gmail.com>

A random effect for a slope means that the slopes have a random
distribution about the fixed effect. For example if the fixed effect is 5
then the slopes for each species will be distributed around this value. So
one species may have a slope of 4 and another 5.6. Why it is sensible to
have a fixed effect is that it is usually not realistic for the mean slope
to be zero, that is to have the random slopes distributed around zero. That
would imply that some slopes are negative.

On 29 April 2015 at 23:56, Genevieve Perkins <genevieve.c.perkins at gmail.com>
wrote:

> Hi Thierry,
> Thanks for the response and great advice.
>
> I have 25 species, 59 sites and total of 1475 observations (including
> absences).
> I didn't mention in the post, but I centered all my predictor variables
> prior to fitting the model (except trait,which is coded as -1 or +1 for
> ease of interpretation).
>
> I am able to run the model both with and without fixed affects :
>
>  fitn <- glmmadmb(bird.abund ~ Cats + trait + Cat:trait + Veg + Pop + (1 +
> Veg + Pop + Cats|Species), data = bdata, family= "nbinom").
>
> The parameters for the random slope do not have normal distributions, so I
> will take your advice and also include these as fixed effects.
>
> Could you suggest any references which explain how random slopes are
> treated. I have mainly been using Zurr, Gelman and Hill, chapters from
> Ecological Statistics (eds. Fox et al.) and online postings.
>
> Thanks again!
>
>
>
>
>
> On 29 April 2015 at 03:51, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> > Dear Genevieve,
> >
> > An observation level random effect (OLRE) is used in a poisson or
> binomial
> > glmm to model the overdispersion. The negative binomial distribution has
> a
> > parameter that handles the overdispersion. So you don't need the ORLE.
> >
> > Note that the as.formula() is not required.
> >
> > Random slopes assume that the parameters follow a normal distribution
> with
> > zero mean. When the overall slope is not zero, this assumption is
> violated
> > when the variable is not used as a fixed effect.
> >
> > Note that you better center random slopes to get more stable estimates.
> Do
> > you have enough data to fit such a complex model? The variance covariance
> > matrix of the Species random effect requires 10 parameters. I would
> strive
> > for >100 observations per species and >10 species.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-04-28 22:41 GMT+02:00 Genevieve Perkins <
> > genevieve.c.perkins at gmail.com>:
> >
> >> Hello,
> >>
> >> I am a masters student new to the world of GLMMs. I have developed a
> mixed
> >> model using the glmmADMB package and I have been scouring the literature
> >> and help files, and trying to find an answer to my questions with no
> >> success.
> >>
> >> I want to estimate the effect of cats on bird abundance for birds with
> >> particular traits (all traits are binary coded (0,1);
> >> Specifically I am looking at the interaction estimate.
> >>
> >> I included species as a random effect, and I wanted the species response
> >> to
> >> vary with Vegetation (Veg) and Population (Pop). I also added a random
> >> level observation term.
> >>
> >>       Model 1: fitn <- glmmadmb(as.formula(bird.abund ~ Cat + trait +
> >> Cat:trait
> >> + (1 + Veg + Pop + Cat|Species) + (1|ID)), data = bdata,family=
> "nbinom")
> >>
> >>
> >> I noticed however that if I include Veg and Pop as fixed effects (model
> 2)
> >> my model estimate for cats at the fixed effect level and species level
> >> also
> >> change.
> >>
> >>       Model 2: fitn <- glmmadmb(as.formula(bird.abund ~ Cats + trait +
> >> Cat:trait
> >> + Veg + Pop + (1 + Veg + Pop + Cats|Species) + (1|ID)), data = bdata,
> >> family= "nbinom")
> >>
> >>
> >> My questions are:
> >> 1)  Is it possible to include varying slope coefficients (ie: Veg and
> Pop)
> >> in a GLMM model without including them as fixed effects? (I couldn't
> find
> >> any examples of this format)
> >>
> >> 2) How are the estimates for the random effects treated without a
> >> corresponding
> >> fixed effect in Glmmadmb. I was guessing they may be pooled to a group
> >> mean
> >> of zero, but I was not able to find this information in the glmmadmb
> >> literature.
> >>
> >> All suggestions greatly appreciated!
> >> Thanks
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From bbolker at gmail.com  Thu Apr 30 02:52:04 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Apr 2015 20:52:04 -0400
Subject: [R-sig-ME] GlmmADMB: random slopes and fixed effects
In-Reply-To: <CAF5_5cxazzi7XEXOwEq3mfiSRJpySuEa-Ps6To3SHqGADtj_9g@mail.gmail.com>
References: <CAH_uvpUsKt1KMVFdraNtEgHjC3YuKGO6tQ9JUU9Du7at3ESPYA@mail.gmail.com>	<CAJuCY5xsz0Th6BAXuvN62-DXNgv5bFhOPNvaNRsAVHhd-9moGw@mail.gmail.com>	<CAH_uvpXe2Bxzd3yGUVrZHV35G0sfJYZS09njKO8Dy=4ZjBDDuQ@mail.gmail.com>
	<CAF5_5cxazzi7XEXOwEq3mfiSRJpySuEa-Ps6To3SHqGADtj_9g@mail.gmail.com>
Message-ID: <55417CB4.2010701@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-04-29 07:58 PM, Ken Beath wrote:
> A random effect for a slope means that the slopes have a random 
> distribution about the fixed effect. For example if the fixed
> effect is 5 then the slopes for each species will be distributed
> around this value. So one species may have a slope of 4 and another
> 5.6. Why it is sensible to have a fixed effect is that it is
> usually not realistic for the mean slope to be zero, that is to
> have the random slopes distributed around zero. That would imply
> that some slopes are negative.

   I would frame it slightly differently ...

   In the absence of evidence to the contrary (see
example(ranef.merMod) for some ways of plotting the random effects), I
would probably encourage you to retain species as a random effect,
while perhaps simplifying the random effect (as suggested by Thierry
Onkelinx below). Perhaps you can add some species-level covariates
(average body mass, habitat preference -- perhaps that's what 'trait'
is?) -- it's the *deviations* from the species-level predictions based
on fixed effects, on the log scale, that need to be Normal, not the
species-level predictions themselves.

   It's fine to have negative slopes -- that would just imply that the
expected response decreased when the covariate increased.  What's
unusual about a model that contains a random effect without the
corresponding fixed effect is that it assumes the average effect
across groups is exactly zero.  The only contexts I can think of in
which this makes sense are (1) if the data have already manipulated so
that the expected effect is standardized to zero (e.g. meta-analyses);
(2) as a null model for testing whether the average effect is non-zero.

> 
> On 29 April 2015 at 23:56, Genevieve Perkins
> <genevieve.c.perkins at gmail.com> wrote:
> 
>> Hi Thierry, Thanks for the response and great advice.
>> 
>> I have 25 species, 59 sites and total of 1475 observations
>> (including absences). I didn't mention in the post, but I
>> centered all my predictor variables prior to fitting the model
>> (except trait,which is coded as -1 or +1 for ease of
>> interpretation).
>> 
>> I am able to run the model both with and without fixed affects :
>> 
>> fitn <- glmmadmb(bird.abund ~ Cats + trait + Cat:trait + Veg +
>> Pop + (1 + Veg + Pop + Cats|Species), data = bdata, family=
>> "nbinom").
>> 
>> The parameters for the random slope do not have normal
>> distributions, so I will take your advice and also include these
>> as fixed effects.
>> 
>> Could you suggest any references which explain how random slopes
>> are treated. I have mainly been using Zurr, Gelman and Hill,
>> chapters from Ecological Statistics (eds. Fox et al.) and online
>> postings.
>> 
>> Thanks again!
>> 
>> 
>> 
>> 
>> 
>> On 29 April 2015 at 03:51, Thierry Onkelinx
>> <thierry.onkelinx at inbo.be> wrote:
>> 
>>> Dear Genevieve,
>>> 
>>> An observation level random effect (OLRE) is used in a poisson
>>> or
>> binomial
>>> glmm to model the overdispersion. The negative binomial
>>> distribution has
>> a
>>> parameter that handles the overdispersion. So you don't need
>>> the ORLE.
>>> 
>>> Note that the as.formula() is not required.
>>> 
>>> Random slopes assume that the parameters follow a normal
>>> distribution
>> with
>>> zero mean. When the overall slope is not zero, this assumption
>>> is
>> violated
>>> when the variable is not used as a fixed effect.
>>> 
>>> Note that you better center random slopes to get more stable
>>> estimates.
>> Do
>>> you have enough data to fit such a complex model? The variance
>>> covariance matrix of the Species random effect requires 10
>>> parameters. I would
>> strive
>>> for >100 observations per species and >10 species.
>>> 
>>> Best regards,
>>> 
>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>> Research Institute for Nature
>> and
>>> Forest team Biometrie & Kwaliteitszorg / team Biometrics &
>>> Quality Assurance Kliniekstraat 25 1070 Anderlecht Belgium
>>> 
>>> To call in the statistician after the experiment is done may be
>>> no more than asking him to perform a post-mortem examination:
>>> he may be able to
>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher The
>>> plural of anecdote is not data. ~ Roger Brinner The combination
>>> of some data and an aching desire for an answer does not ensure
>>> that a reasonable answer can be extracted from a given body of
>> data.
>>> ~ John Tukey
>>> 
>>> 2015-04-28 22:41 GMT+02:00 Genevieve Perkins < 
>>> genevieve.c.perkins at gmail.com>:
>>> 
>>>> Hello,
>>>> 
>>>> I am a masters student new to the world of GLMMs. I have
>>>> developed a
>> mixed
>>>> model using the glmmADMB package and I have been scouring the
>>>> literature and help files, and trying to find an answer to my
>>>> questions with no success.
>>>> 
>>>> I want to estimate the effect of cats on bird abundance for
>>>> birds with particular traits (all traits are binary coded
>>>> (0,1); Specifically I am looking at the interaction
>>>> estimate.
>>>> 
>>>> I included species as a random effect, and I wanted the
>>>> species response to vary with Vegetation (Veg) and Population
>>>> (Pop). I also added a random level observation term.
>>>> 
>>>> Model 1: fitn <- glmmadmb(as.formula(bird.abund ~ Cat + trait
>>>> + Cat:trait + (1 + Veg + Pop + Cat|Species) + (1|ID)), data =
>>>> bdata,family=
>> "nbinom")
>>>> 
>>>> 
>>>> I noticed however that if I include Veg and Pop as fixed
>>>> effects (model
>> 2)
>>>> my model estimate for cats at the fixed effect level and
>>>> species level also change.
>>>> 
>>>> Model 2: fitn <- glmmadmb(as.formula(bird.abund ~ Cats +
>>>> trait + Cat:trait + Veg + Pop + (1 + Veg + Pop +
>>>> Cats|Species) + (1|ID)), data = bdata, family= "nbinom")
>>>> 
>>>> 
>>>> My questions are: 1)  Is it possible to include varying slope
>>>> coefficients (ie: Veg and
>> Pop)
>>>> in a GLMM model without including them as fixed effects? (I
>>>> couldn't
>> find
>>>> any examples of this format)
>>>> 
>>>> 2) How are the estimates for the random effects treated
>>>> without a corresponding fixed effect in Glmmadmb. I was
>>>> guessing they may be pooled to a group mean of zero, but I
>>>> was not able to find this information in the glmmadmb 
>>>> literature.
>>>> 
>>>> All suggestions greatly appreciated! Thanks
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVQXy0AAoJEOCV5YRblxUHyEYIAImiOMFEfUxLfcYincSo7nM+
gI7sykoIEOiY3Pg32DH2lh5/gcCi19ezWBJlQtKgA0ZVBC9PoUDN6PkD+CiR4Tq/
YghExE/axBE8/mOnkhCtqulkx6ZsVbMvq+6efPG8Xc7YEp8obNnruW56co0/1/Sr
8JRK+07HqtD9ocjcKrJ6rF0Zv175+LSBVpiT+UslbObV1/l1NxfCrBVQDIJ9AKw9
VgxSiuX7A57JlLhbSzYD/f0WSDLk9C2XbRt1S7azfcFsJBZdFXzi4R4pwsgoxXDO
9zh+XSXgCv6xqv851gz58DqI8kaloHrcCFgNdNMacWOqPnBLReQabUYJ+40tNLU=
=JtYy
-----END PGP SIGNATURE-----


From markl033 at umn.edu  Thu Apr 30 06:12:37 2015
From: markl033 at umn.edu (Tricia Markle)
Date: Wed, 29 Apr 2015 23:12:37 -0500
Subject: [R-sig-ME] Adding additional factor to previously working
 MCMCglmm model kills it. Problem with priors? Help?
In-Reply-To: <20150429064611.85661ub1jydm30pw@www.staffmail.ed.ac.uk>
References: <CAO=0ZJXTc=YVW8twcAt+m1gUQ4YpZWGt05LZx-zUrS6_QMK-hg@mail.gmail.com>
	<20150429064611.85661ub1jydm30pw@www.staffmail.ed.ac.uk>
Message-ID: <CAO=0ZJUZYtz_U5_oEow7nzgZ-kotJpVAnNeuRwALPbF5Q1QSzw@mail.gmail.com>

Hi Jarrod,

Thanks for the response.

If I am understanding correctly, would I then end up with the code below?
If species is incorporated in the random part, would I then not include it
as a fixed factor?

tree<-read.tree("Plethodontidae_comb61_PL.phy")
species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
"D._ochrophaeus_WKS05", "D._ocoee_B_KHK62", "D._orestes_KHK129",
"D._monticola_A",  "D._santeetlah_11775", "P_cinereus", "P_cylindraceus",
"P_glutinosus", "P_hubrichti", "P_montanus", "P_punctatus", "P_richmondi",
"P_teyahalee", "P_virginia", "P_wehrlei")
pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
tree$tip.label)])# Prune tree to just include species of interest
sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node") #rename
nodes to be unique
treeAinv<-inverseA(sptree, nodes="TIPS")$Ainv

dataset$species.ide<-dataset$species
random=~us(1+Temp):species.ide

prior<-list(G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
alpha.V=diag(2)*1000)), R=list(V=diag(1), nu=0.002))

model6<-MCMCglmm(LVO2~1+Temp+Acclm+Range+Mass+Sex+Acclm*Range,
random=random, data=dataset, family="gaussian",
ginverse=list(species=treeAinv), prior=prior, nitt=300000, burnin=25000,
thin = 1000, verbose=FALSE)

Alternatively, someone mentioned to me that to reduce model complexity I
could group the handful of species I have with smaller samples sizes and
label them all as "other" in a second species list ("New_spp"). When I
added this new species assortment as a fixed factor in my original model it
runs! Is this a reasonable thing to do?

Thanks, Tricia

On Wed, Apr 29, 2015 at 12:46 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi,
>
> If you want iid species effects then put them in the random part. You will
> need to rename them so that they are not associated with the ginverse. For
> example,
>
> dataset$species.ide<-dataset$species
>
> and fit species.ide as a random effect.
>
> You only have 17 species. This is not enough to get precise estimates of
> the variance components and so you should expect prior sensitivity,
> particularly with respect to the phylogenetic part. I would try and
> simplify your model. I'm not sure how many of the fixed effects are
> species-level or individual-level but I would try and reduce the complexity
> of the fixed part of the model too (for example is the 4-way interaction
> needed?). The warning usually indicates that the model is overparameterised.
>
> Cheers,
>
> Jarrod
>
>
>
>
>  Quoting Tricia Markle <markl033 at umn.edu> on Wed, 29 Apr 2015 00:24:53
> -0500:
>
>  Hello,
>>
>>
>>
>> I have a working MCMCglmm model with phylogenetic consideration and repeat
>> measures. I realized after the fact that ?species? wasn?t properly
>> included
>> in the model. When I added this additional factor (of 17 levels), however,
>> I received the following error message:
>>
>> --------
>>
>>
>>
>> Error in MCMCglmm(LVO2 ~ 1 + Temp + Acclm + Lat_Ext + LMass + Sex +
>> species
>> +  :  ill-conditioned G/R structure: use proper priors if you haven't or
>> rescale data if you have
>>
>> In addition: Warning message:
>>
>> In MCMCglmm(LVO2 ~ 1 + Temp + Acclm + Lat_Ext + LMass + Sex + species +  :
>>
>>   some fixed effects are not estimable and have been removed. Use
>> singular.ok=TRUE to sample these effects, but use an informative prior!
>>
>>
>>
>> ----------
>>
>>
>>
>> I had some help with my priors originally so I am not sure the best way to
>> now tweak them to make them work? Could different priors help or is there
>> something ?wrong? with adding species as another factor?
>>
>>
>>
>>
>> My hypothesis centers around the remaining significant interaction term
>> Acclm:Lat_Ext ? whether the relationship of acclimation on oxygen
>> consumption (VO2) is differs depending on the latitudinal extent of a
>> species (while also considering a number of covariates).
>>
>>
>>
>> Here is my code:
>>
>>
>>
>> library(ape)
>>
>> library(MCMCglmm)
>>
>> dataset<-read.csv(file="RespData.csv", head=TRUE)
>>
>> attach(dataset)
>>
>> str(dataset) # confirming that sex, range, species, and ID are all factors
>>
>>
>>
>> #Phylogeny Component
>>
>> tree<-read.tree("Plethodontidae_comb61_PL.phy")
>>
>> species<-c("D._carolinensis_KHK103", "D._fuscus_KHK142",
>> "D._ochrophaeus_WKS05", "D._ocoee_B_KHK62", "D._orestes_KHK129",
>> "D._monticola_A",  "D._santeetlah_11775", "P_cinereus", "P_cylindraceus",
>> "P_glutinosus", "P_hubrichti", "P_montanus", "P_punctatus", "P_richmondi",
>> "P_teyahalee", "P_virginia", "P_wehrlei")
>>
>> pruned.tree<-drop.tip(tree,tree$tip.label[-match(species,
>> tree$tip.label)])# Prune tree to just include species of interest
>>
>> sptree<-makeNodeLabel(pruned.tree, method="number", prefix="node")
>>
>>
>>
>> treeAinv<-inverseA(sptree, nodes="TIPS")$Ainv
>>
>> random=~us(1+Temp):species
>>
>> prior<-list(G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
>> alpha.V=diag(2)*1000)), R=list(V=diag(1), nu=0.002))
>>
>>
>>
>> #Model 1
>>
>>
>> model1<MCMCglmm(LVO2~1+Temp+Acclm+Lat_Ext+LMass+Sex+species+Temp*Acclm+Temp*Lat_Ext+Acclm*Lat_Ext+Temp*Acclm*Lat*Ext,
>> random=random, data=dataset, family="gaussian",
>> ginverse=list(species=treeAinv), prior=prior, nitt=300000, burnin=25000,
>> thin = 1000, verbose=FALSE)
>>
>>
>>
>> Thank you kindly for your help!
>>
>>
>>
>> Tricia
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>

	[[alternative HTML version deleted]]


From sileiris at gmail.com  Thu Apr 30 14:50:03 2015
From: sileiris at gmail.com (=?UTF-8?Q?Silvia_Rodr=C3=ADguez_Fern=C3=A1ndez?=)
Date: Thu, 30 Apr 2015 14:50:03 +0200
Subject: [R-sig-ME] glmmADMB
Message-ID: <CABk1Hu2pq=U0Fgk0JxpCn2z0qJM7a1Bzido+cye3U1uNT2y2CA@mail.gmail.com>

Dear list members,

I?m a PhD student in trouble. I?m running a mix effects model with a
dependent variable (PA: presence/absence, 0/1), one fixed explanatory and
continuous variable (AL: altitude), one fixed factor (PE: initially 16
levels, but reduced to 4 to reduce complexity) and one random term (2421
sites). Basically, the structure of a logistic regression but with a random
term to prevent temporal pseudoreplication.

> model1<-glmmadmb(PA~PE+AL+(1|site), family="binomial")

My data are quite unbalanced becouse I?ve many more zeros than ones. I?ve
tried making a random selection of absences but I get similar problems than
when using the whole dataset.

I?m getting an output of results in R, but also getting a warning of lack
of convergence, such as:

Convergence failed:log-likelihood of gradient= -0.0195034


Can I trust my results in spite of the warning?

What other alternatives do you suggest?


I?ve tried with the classical lmer and glmer, and I also get convergence
problems as expected.

I?ve also tried with the MCMCglmm package, but I?ve problems with the
specification of the priors.


Any help is welcomed.


Silvia

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Apr 30 15:25:08 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 30 Apr 2015 15:25:08 +0200
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CABk1Hu2pq=U0Fgk0JxpCn2z0qJM7a1Bzido+cye3U1uNT2y2CA@mail.gmail.com>
References: <CABk1Hu2pq=U0Fgk0JxpCn2z0qJM7a1Bzido+cye3U1uNT2y2CA@mail.gmail.com>
Message-ID: <CAJuCY5wW3_oC-73htVqLb6vUCYCs-hwpC-fY3j4KT-v+AgXXQA@mail.gmail.com>

Dear Silvia,

I presume that the values of AL and PE are constant within the site. Did
you sample different locations within each site simultaneous ? Or did you
sample the same location at each site but at different dates?
In case of different locations per site you can simplify your model to.
glm(cbind(n.present, n.absent) ~ AL + PE, family = binomial) With n.present
the number of present locations per site.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-30 14:50 GMT+02:00 Silvia Rodr?guez Fern?ndez <sileiris at gmail.com>:

> Dear list members,
>
> I?m a PhD student in trouble. I?m running a mix effects model with a
> dependent variable (PA: presence/absence, 0/1), one fixed explanatory and
> continuous variable (AL: altitude), one fixed factor (PE: initially 16
> levels, but reduced to 4 to reduce complexity) and one random term (2421
> sites). Basically, the structure of a logistic regression but with a random
> term to prevent temporal pseudoreplication.
>
> > model1<-glmmadmb(PA~PE+AL+(1|site), family="binomial")
>
> My data are quite unbalanced becouse I?ve many more zeros than ones. I?ve
> tried making a random selection of absences but I get similar problems than
> when using the whole dataset.
>
> I?m getting an output of results in R, but also getting a warning of lack
> of convergence, such as:
>
> Convergence failed:log-likelihood of gradient= -0.0195034
>
>
> Can I trust my results in spite of the warning?
>
> What other alternatives do you suggest?
>
>
> I?ve tried with the classical lmer and glmer, and I also get convergence
> problems as expected.
>
> I?ve also tried with the MCMCglmm package, but I?ve problems with the
> specification of the priors.
>
>
> Any help is welcomed.
>
>
> Silvia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From sileiris at gmail.com  Thu Apr 30 17:08:01 2015
From: sileiris at gmail.com (=?UTF-8?Q?Silvia_Rodr=C3=ADguez_Fern=C3=A1ndez?=)
Date: Thu, 30 Apr 2015 17:08:01 +0200
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CAJuCY5wW3_oC-73htVqLb6vUCYCs-hwpC-fY3j4KT-v+AgXXQA@mail.gmail.com>
References: <CABk1Hu2pq=U0Fgk0JxpCn2z0qJM7a1Bzido+cye3U1uNT2y2CA@mail.gmail.com>
	<CAJuCY5wW3_oC-73htVqLb6vUCYCs-hwpC-fY3j4KT-v+AgXXQA@mail.gmail.com>
Message-ID: <CABk1Hu3GQrA=4SZn2AtYmXSFFXMVvDfQyrzR4yi_2fgcTdHAvA@mail.gmail.com>

Thierry, thanks a lot for your quick response.


We sampled each site (small water points) only once and we noted the
different PE (human disturbance types). However for our analyses we have
done as if each site was sampled more than once. That is we repeated each
row as many times as different perturbance types were recorded in each
site.


  Site

PA

AL

PE

1

0

38

1

 1

0

38

3

2

0

138

1

3

0

382

1

3

0

382

3

4

0

382

1

4

0

382

3


Our final aim is to obtain probabilities of presence/absence of each
amphibian species in a site in relation to the different types of
disturbance and altitude, using the "invlogit" function. I think the
"cbind" function is not useful in this case because we are not modelling
proportions.


What do you think?


Best regards,


Silvia

2015-04-30 15:25 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Silvia,
>
> I presume that the values of AL and PE are constant within the site. Did
> you sample different locations within each site simultaneous ? Or did you
> sample the same location at each site but at different dates?
> In case of different locations per site you can simplify your model to.
> glm(cbind(n.present, n.absent) ~ AL + PE, family = binomial) With n.present
> the number of present locations per site.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-04-30 14:50 GMT+02:00 Silvia Rodr?guez Fern?ndez <sileiris at gmail.com>
> :
>
>> Dear list members,
>>
>> I?m a PhD student in trouble. I?m running a mix effects model with a
>> dependent variable (PA: presence/absence, 0/1), one fixed explanatory and
>> continuous variable (AL: altitude), one fixed factor (PE: initially 16
>> levels, but reduced to 4 to reduce complexity) and one random term (2421
>> sites). Basically, the structure of a logistic regression but with a
>> random
>> term to prevent temporal pseudoreplication.
>>
>> > model1<-glmmadmb(PA~PE+AL+(1|site), family="binomial")
>>
>> My data are quite unbalanced becouse I?ve many more zeros than ones. I?ve
>> tried making a random selection of absences but I get similar problems
>> than
>> when using the whole dataset.
>>
>> I?m getting an output of results in R, but also getting a warning of lack
>> of convergence, such as:
>>
>> Convergence failed:log-likelihood of gradient= -0.0195034
>>
>>
>> Can I trust my results in spite of the warning?
>>
>> What other alternatives do you suggest?
>>
>>
>> I?ve tried with the classical lmer and glmer, and I also get convergence
>> problems as expected.
>>
>> I?ve also tried with the MCMCglmm package, but I?ve problems with the
>> specification of the priors.
>>
>>
>> Any help is welcomed.
>>
>>
>> Silvia
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From genevieve.c.perkins at gmail.com  Fri May  1 15:54:30 2015
From: genevieve.c.perkins at gmail.com (Genevieve Perkins)
Date: Fri, 1 May 2015 09:54:30 -0400
Subject: [R-sig-ME] GlmmADMB: random slopes and fixed effects
In-Reply-To: <55417CB4.2010701@gmail.com>
References: <CAH_uvpUsKt1KMVFdraNtEgHjC3YuKGO6tQ9JUU9Du7at3ESPYA@mail.gmail.com>
	<CAJuCY5xsz0Th6BAXuvN62-DXNgv5bFhOPNvaNRsAVHhd-9moGw@mail.gmail.com>
	<CAH_uvpXe2Bxzd3yGUVrZHV35G0sfJYZS09njKO8Dy=4ZjBDDuQ@mail.gmail.com>
	<CAF5_5cxazzi7XEXOwEq3mfiSRJpySuEa-Ps6To3SHqGADtj_9g@mail.gmail.com>
	<55417CB4.2010701@gmail.com>
Message-ID: <CAH_uvpWBihK-ZhmAfYOsUGmrf7uEh9sC1+CwzX6Q-Q=iVmaEMw@mail.gmail.com>

Thanks Ken and Ben for your help.

On 29 April 2015 at 20:52, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-04-29 07:58 PM, Ken Beath wrote:
> > A random effect for a slope means that the slopes have a random
> > distribution about the fixed effect. For example if the fixed
> > effect is 5 then the slopes for each species will be distributed
> > around this value. So one species may have a slope of 4 and another
> > 5.6. Why it is sensible to have a fixed effect is that it is
> > usually not realistic for the mean slope to be zero, that is to
> > have the random slopes distributed around zero. That would imply
> > that some slopes are negative.
>
>    I would frame it slightly differently ...
>
>    In the absence of evidence to the contrary (see
> example(ranef.merMod) for some ways of plotting the random effects), I
> would probably encourage you to retain species as a random effect,
> while perhaps simplifying the random effect (as suggested by Thierry
> Onkelinx below). Perhaps you can add some species-level covariates
> (average body mass, habitat preference -- perhaps that's what 'trait'
> is?) -- it's the *deviations* from the species-level predictions based
> on fixed effects, on the log scale, that need to be Normal, not the
> species-level predictions themselves.
>
>    It's fine to have negative slopes -- that would just imply that the
> expected response decreased when the covariate increased.  What's
> unusual about a model that contains a random effect without the
> corresponding fixed effect is that it assumes the average effect
> across groups is exactly zero.  The only contexts I can think of in
> which this makes sense are (1) if the data have already manipulated so
> that the expected effect is standardized to zero (e.g. meta-analyses);
> (2) as a null model for testing whether the average effect is non-zero.
>
> >
> > On 29 April 2015 at 23:56, Genevieve Perkins
> > <genevieve.c.perkins at gmail.com> wrote:
> >
> >> Hi Thierry, Thanks for the response and great advice.
> >>
> >> I have 25 species, 59 sites and total of 1475 observations
> >> (including absences). I didn't mention in the post, but I
> >> centered all my predictor variables prior to fitting the model
> >> (except trait,which is coded as -1 or +1 for ease of
> >> interpretation).
> >>
> >> I am able to run the model both with and without fixed affects :
> >>
> >> fitn <- glmmadmb(bird.abund ~ Cats + trait + Cat:trait + Veg +
> >> Pop + (1 + Veg + Pop + Cats|Species), data = bdata, family=
> >> "nbinom").
> >>
> >> The parameters for the random slope do not have normal
> >> distributions, so I will take your advice and also include these
> >> as fixed effects.
> >>
> >> Could you suggest any references which explain how random slopes
> >> are treated. I have mainly been using Zurr, Gelman and Hill,
> >> chapters from Ecological Statistics (eds. Fox et al.) and online
> >> postings.
> >>
> >> Thanks again!
> >>
> >>
> >>
> >>
> >>
> >> On 29 April 2015 at 03:51, Thierry Onkelinx
> >> <thierry.onkelinx at inbo.be> wrote:
> >>
> >>> Dear Genevieve,
> >>>
> >>> An observation level random effect (OLRE) is used in a poisson
> >>> or
> >> binomial
> >>> glmm to model the overdispersion. The negative binomial
> >>> distribution has
> >> a
> >>> parameter that handles the overdispersion. So you don't need
> >>> the ORLE.
> >>>
> >>> Note that the as.formula() is not required.
> >>>
> >>> Random slopes assume that the parameters follow a normal
> >>> distribution
> >> with
> >>> zero mean. When the overall slope is not zero, this assumption
> >>> is
> >> violated
> >>> when the variable is not used as a fixed effect.
> >>>
> >>> Note that you better center random slopes to get more stable
> >>> estimates.
> >> Do
> >>> you have enough data to fit such a complex model? The variance
> >>> covariance matrix of the Species random effect requires 10
> >>> parameters. I would
> >> strive
> >>> for >100 observations per species and >10 species.
> >>>
> >>> Best regards,
> >>>
> >>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> >>> Research Institute for Nature
> >> and
> >>> Forest team Biometrie & Kwaliteitszorg / team Biometrics &
> >>> Quality Assurance Kliniekstraat 25 1070 Anderlecht Belgium
> >>>
> >>> To call in the statistician after the experiment is done may be
> >>> no more than asking him to perform a post-mortem examination:
> >>> he may be able to
> >> say
> >>> what the experiment died of. ~ Sir Ronald Aylmer Fisher The
> >>> plural of anecdote is not data. ~ Roger Brinner The combination
> >>> of some data and an aching desire for an answer does not ensure
> >>> that a reasonable answer can be extracted from a given body of
> >> data.
> >>> ~ John Tukey
> >>>
> >>> 2015-04-28 22:41 GMT+02:00 Genevieve Perkins <
> >>> genevieve.c.perkins at gmail.com>:
> >>>
> >>>> Hello,
> >>>>
> >>>> I am a masters student new to the world of GLMMs. I have
> >>>> developed a
> >> mixed
> >>>> model using the glmmADMB package and I have been scouring the
> >>>> literature and help files, and trying to find an answer to my
> >>>> questions with no success.
> >>>>
> >>>> I want to estimate the effect of cats on bird abundance for
> >>>> birds with particular traits (all traits are binary coded
> >>>> (0,1); Specifically I am looking at the interaction
> >>>> estimate.
> >>>>
> >>>> I included species as a random effect, and I wanted the
> >>>> species response to vary with Vegetation (Veg) and Population
> >>>> (Pop). I also added a random level observation term.
> >>>>
> >>>> Model 1: fitn <- glmmadmb(as.formula(bird.abund ~ Cat + trait
> >>>> + Cat:trait + (1 + Veg + Pop + Cat|Species) + (1|ID)), data =
> >>>> bdata,family=
> >> "nbinom")
> >>>>
> >>>>
> >>>> I noticed however that if I include Veg and Pop as fixed
> >>>> effects (model
> >> 2)
> >>>> my model estimate for cats at the fixed effect level and
> >>>> species level also change.
> >>>>
> >>>> Model 2: fitn <- glmmadmb(as.formula(bird.abund ~ Cats +
> >>>> trait + Cat:trait + Veg + Pop + (1 + Veg + Pop +
> >>>> Cats|Species) + (1|ID)), data = bdata, family= "nbinom")
> >>>>
> >>>>
> >>>> My questions are: 1)  Is it possible to include varying slope
> >>>> coefficients (ie: Veg and
> >> Pop)
> >>>> in a GLMM model without including them as fixed effects? (I
> >>>> couldn't
> >> find
> >>>> any examples of this format)
> >>>>
> >>>> 2) How are the estimates for the random effects treated
> >>>> without a corresponding fixed effect in Glmmadmb. I was
> >>>> guessing they may be pooled to a group mean of zero, but I
> >>>> was not able to find this information in the glmmadmb
> >>>> literature.
> >>>>
> >>>> All suggestions greatly appreciated! Thanks
> >>>>
> >>>> [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVQXy0AAoJEOCV5YRblxUHyEYIAImiOMFEfUxLfcYincSo7nM+
> gI7sykoIEOiY3Pg32DH2lh5/gcCi19ezWBJlQtKgA0ZVBC9PoUDN6PkD+CiR4Tq/
> YghExE/axBE8/mOnkhCtqulkx6ZsVbMvq+6efPG8Xc7YEp8obNnruW56co0/1/Sr
> 8JRK+07HqtD9ocjcKrJ6rF0Zv175+LSBVpiT+UslbObV1/l1NxfCrBVQDIJ9AKw9
> VgxSiuX7A57JlLhbSzYD/f0WSDLk9C2XbRt1S7azfcFsJBZdFXzi4R4pwsgoxXDO
> 9zh+XSXgCv6xqv851gz58DqI8kaloHrcCFgNdNMacWOqPnBLReQabUYJ+40tNLU=
> =JtYy
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sat May  2 06:46:26 2015
From: hannah.hlx at gmail.com (li li)
Date: Sat, 2 May 2015 00:46:26 -0400
Subject: [R-sig-ME] Random effect in ancova model
Message-ID: <CAHLnndZ4doF+DUt87azNwqCNEe9-fz8HGRi23kekjx+DWuajmQ@mail.gmail.com>

Hi all,
  I have the following data and would like to consider the following model:
  value = type + batch (type) + beta1* month +beta2*type*month+ error
Here type is fixed effect and batch is a random effect neste within type,
and month is continuous.
Since there is a random effect in this model. I am not too sure about the
right syntax in R.
Can anyone give some suggestions?
  Thank you.
    Hanna




 > mydata
      value type  batch month
 [1,]   0.2    1 178380     0
 [2,]   0.3    1 178380     3
 [3,]   0.3    1 178380     6
 [4,]   0.3    1 178380     9
 [5,]   0.3    1 178380    12
 [6,]   0.3    1 178380    15
 [7,]   0.4    1 178380    18
 [8,]   0.5    1 178380    24
 [9,]   0.2    1 189617     0
[10,]   0.3    1 189617     3
[11,]   0.4    1 189617     6
[12,]   0.4    1 189617     9
[13,]   0.4    1 189617    12
[14,]   0.4    1 189617    15
[15,]   0.4    1 189617    18
[16,]   0.4    1 189617    24
[17,]   0.2    1 197367     0
[18,]   0.3    1 197367     3
[19,]   0.3    1 197367     6
[20,]   0.4    1 197367     9
[21,]   0.4    1 197367    12
[22,]   0.4    1 197367    15
[23,]   0.4    1 197367    18
[24,]   0.4    1 197367    24
[25,]   0.4    2 286571     0
[26,]   0.4    2 286571     3
[27,]   0.3    2 286571     6
[28,]   0.4    2 286571     9
[29,]   0.4    2 286571    12
[30,]    NA    2 286571    15
[31,]   0.4    2 297299     0
[32,]   0.4    2 297299     3
[33,]   0.4    2 297299     6
[34,]   0.4    2 297299     9
[35,]   0.4    2 297299    12
[36,]    NA    2 297299    15

	[[alternative HTML version deleted]]


From massimiliano.iraci at unisalento.it  Tue Apr 28 15:38:32 2015
From: massimiliano.iraci at unisalento.it (Massimiliano Mario Iraci)
Date: Tue, 28 Apr 2015 15:38:32 +0200
Subject: [R-sig-ME] Using lme4 with very limited number of observations
	makes sense?
Message-ID: <cfcb8d069a4738c5b945375181e2cc85.squirrel@webmail.unisalento.it>

Dear all,

my name is Massimiliano Iraci, I am a PhD student at the University of
Salento (Lecce, Italy) and University of Cologne (Germany). My PhD is on
Phonetics and Phonology and I am working on the kinematics of speech in
Parkinson's Disease.

I am very fresh with statistics and recently I am even switching from SPSS
to R, especially working with linear mixed models (lme4 package).
Unfortunately I am having some doubts about the use of this model with my
data.

In my field, the data acquisition is much complicated because of the
instruments, so eventually I always have few data for few subjects. So, in
order to power-up my data, I am used to record more (5-7) repetitions of
any item of interest.

So, for instance, if I want to focus on the displacement of the lower lip
during the production of a bilabial speech gesture, I consider the
voiced/unvoiced condition, in 2 contexts (singleton/geminate). Thus I will
have 7 repetitions of the same item x 2 conditions (voiced/unvoiced) x 2
contexts (singleton/geminate) x 10 subjects (5 pathological + 5 controls).
I fit the model as follows:
lip_displacement ~ PATvsCTR * condition * context + (1|repetitions) +
(1+condition|subject) + (1+context|subject)

I must highlight that:
- I don't have always 7 repetitions for any item: some subjects were able
to produce 5, some 6, some 7 differing from item to item (so generally
number of "same items" range from 5 to 7);
- 'repetitions' is a variable reporting the cardinal number associated to
the chronological order of the repetitions recorded (so ranging from 1 to
7)

This fit very often generates several errors and warnings ("large
eigenvalue ratio"; "degenerate Hessian with 1 negative eigenvalues"; etc.)
and if plotting the distribution of fitted/residuals I see stripes clearly
because of the repetitions.

Finally the questions are:
- could the repetitions be a problem for the model? Could it better to
work with an average of the repetitions in order to have only 1 value for
each item?
- if the previous is true, does it make sense to compare such a limited
number of values in such a limited number of subjects with this model?

I am sorry for my limited knowledge in statics. I would be really grateful
if you could help me to shed light on the problem. Thank you very much in
advance for your help.

I look forward to hearing from you.
Kind regards,

Massimiliano



===============================================================

Massimiliano Mario Iraci
PhD student

CRIL (Intedisciplinary Center for Research on Language) &
DReAM (Laboratory of Research Applied to Medicine)
University of Salento & Local Health Service (ASL Lecce)
c/o Vito Fazzi Hospital
Piazza Filippo Muratore - 73100 - Lecce (Italy)

web: http://www.cril.unisalento.it/en/staff_details.php?id=123
tel: 0039 - 0832 335008


From baron at psych.upenn.edu  Sun May  3 19:50:23 2015
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 3 May 2015 13:50:23 -0400
Subject: [R-sig-ME] Using lme4 with very limited number of observations
	makes sense?
In-Reply-To: <cfcb8d069a4738c5b945375181e2cc85.squirrel@webmail.unisalento.it>
References: <cfcb8d069a4738c5b945375181e2cc85.squirrel@webmail.unisalento.it>
Message-ID: <20150503175023.GA11102@psych.upenn.edu>

I can't resist replying to this, even though I won't have much to say
about lmer().

It seems to me that the big problem is the small number of
subjects. And the main issues are the differences between the two
groups. In order to find anything with such a small number, you would
need huge effects. Moreover, the patients will differ among themselves
as a function of the severity of their disease at the time, adding
additional variance. This means that you should have unequal variances
between the two groups. My hunch is that this is not a big problem
when you have large samples but could be a problem here even with
lmer(). [This is where I am not an expert.] Ordinary t-tests can
correct for unequal variance (and do so, in R, by default). You might
be able to remove this unequal variance if you include a measure of
disease severity (with the control group at 0). (And it might also
help to get more controls, especially if you can deal with the unequal
variance.)

My thought is that IF the effects of disease are large enough so that
you can get any kind of "significant" result with such a small sample,
THEN they would also be large enough to see them graphically. If I had
these data, the first thing I would do, and maybe the last, would be
to plot graphs of the results for each of the four sub-conditions
(defined by voicing and context). Each point would the mean for one
subject of one of the four conditions, and I would use different
colors for the two groups. And/or the horizontal axis could be some
measure of disease severity, with the control group at 0. If there
were a group difference, it would be significant by an eyeball
test. It would be so obvious that it hits you between the eyeballs. If
it isn't that obvious, then I suspect that nothing will help.

I don't much see the point of using lmer() here as opposed to
"ordinary least squares" regression or t-tests*, since you main
interest is the subjects. The one advantage of lmer() would (I think)
be to find effects of the manipulations (context and voicing), but
probably you already know that.

*You can test interactions with t-tests by computing differences for
 each subject.

Jon

On 04/28/15 15:38, Massimiliano Mario Iraci wrote:
>Dear all,
>
>my name is Massimiliano Iraci, I am a PhD student at the University of
>Salento (Lecce, Italy) and University of Cologne (Germany). My PhD is on
>Phonetics and Phonology and I am working on the kinematics of speech in
>Parkinson's Disease.
>
>I am very fresh with statistics and recently I am even switching from SPSS
>to R, especially working with linear mixed models (lme4 package).
>Unfortunately I am having some doubts about the use of this model with my
>data.
>
>In my field, the data acquisition is much complicated because of the
>instruments, so eventually I always have few data for few subjects. So, in
>order to power-up my data, I am used to record more (5-7) repetitions of
>any item of interest.
>
>So, for instance, if I want to focus on the displacement of the lower lip
>during the production of a bilabial speech gesture, I consider the
>voiced/unvoiced condition, in 2 contexts (singleton/geminate). Thus I will
>have 7 repetitions of the same item x 2 conditions (voiced/unvoiced) x 2
>contexts (singleton/geminate) x 10 subjects (5 pathological + 5 controls).
>I fit the model as follows:
>lip_displacement ~ PATvsCTR * condition * context + (1|repetitions) +
>(1+condition|subject) + (1+context|subject)
>
>I must highlight that:
>- I don't have always 7 repetitions for any item: some subjects were able
>to produce 5, some 6, some 7 differing from item to item (so generally
>number of "same items" range from 5 to 7);
>- 'repetitions' is a variable reporting the cardinal number associated to
>the chronological order of the repetitions recorded (so ranging from 1 to
>7)
>
>This fit very often generates several errors and warnings ("large
>eigenvalue ratio"; "degenerate Hessian with 1 negative eigenvalues"; etc.)
>and if plotting the distribution of fitted/residuals I see stripes clearly
>because of the repetitions.
>
>Finally the questions are:
>- could the repetitions be a problem for the model? Could it better to
>work with an average of the repetitions in order to have only 1 value for
>each item?
>- if the previous is true, does it make sense to compare such a limited
>number of values in such a limited number of subjects with this model?
>
>I am sorry for my limited knowledge in statics. I would be really grateful
>if you could help me to shed light on the problem. Thank you very much in
>advance for your help.
>
>I look forward to hearing from you.
>Kind regards,
>
>Massimiliano
>
>
>
>===============================================================
>
>Massimiliano Mario Iraci
>PhD student
>
>CRIL (Intedisciplinary Center for Research on Language) &
>DReAM (Laboratory of Research Applied to Medicine)
>University of Salento & Local Health Service (ASL Lecce)
>c/o Vito Fazzi Hospital
>Piazza Filippo Muratore - 73100 - Lecce (Italy)
>
>web: http://www.cril.unisalento.it/en/staff_details.php?id=123
>tel: 0039 - 0832 335008
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From ken.beath at mq.edu.au  Mon May  4 05:21:18 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Mon, 4 May 2015 13:21:18 +1000
Subject: [R-sig-ME] Using lme4 with very limited number of observations
 makes sense?
In-Reply-To: <cfcb8d069a4738c5b945375181e2cc85.squirrel@webmail.unisalento.it>
References: <cfcb8d069a4738c5b945375181e2cc85.squirrel@webmail.unisalento.it>
Message-ID: <CAF5_5czC=BTzByQdA3gny8kwctSEen-mYicOo-nJtiTN8kqmkQ@mail.gmail.com>

Having repetititions as a random effect seems unusual, as it doesn't
satisfy the assumptions, and estimating with only 7 groups may have
problems. I would look at it as a fixed effect, and possibly it would be
found that teh ordering does not have an effect. Averaging can be OK but
can also have all sorts of problems when the number of responses
varies.With the fixed effect there are 6 additional parameters but almost 7
times as much data,

What is more worrying is (1+condition|subject) + (1+context|subject) which
seems to include the 1|subject random effect twice.
(1+context+condition|subject)
may avoid the problems but will have a correlation between the random
effects for context and condition that you may not want. Probably you do
want them, but if you don't I'm not certain how to get rid of them.

Starting off with 3 way interactions like PATvsCTR * condition * context
can be a problem if there is not a lot of data. Try to get something
simpler like main effects only working and then try something more
complicated.



On 28 April 2015 at 23:38, Massimiliano Mario Iraci <
massimiliano.iraci at unisalento.it> wrote:

> Dear all,
>
> my name is Massimiliano Iraci, I am a PhD student at the University of
> Salento (Lecce, Italy) and University of Cologne (Germany). My PhD is on
> Phonetics and Phonology and I am working on the kinematics of speech in
> Parkinson's Disease.
>
> I am very fresh with statistics and recently I am even switching from SPSS
> to R, especially working with linear mixed models (lme4 package).
> Unfortunately I am having some doubts about the use of this model with my
> data.
>
> In my field, the data acquisition is much complicated because of the
> instruments, so eventually I always have few data for few subjects. So, in
> order to power-up my data, I am used to record more (5-7) repetitions of
> any item of interest.
>
> So, for instance, if I want to focus on the displacement of the lower lip
> during the production of a bilabial speech gesture, I consider the
> voiced/unvoiced condition, in 2 contexts (singleton/geminate). Thus I will
> have 7 repetitions of the same item x 2 conditions (voiced/unvoiced) x 2
> contexts (singleton/geminate) x 10 subjects (5 pathological + 5 controls).
> I fit the model as follows:
> lip_displacement ~ PATvsCTR * condition * context + (1|repetitions) +
> (1+condition|subject) + (1+context|subject)
>
> I must highlight that:
> - I don't have always 7 repetitions for any item: some subjects were able
> to produce 5, some 6, some 7 differing from item to item (so generally
> number of "same items" range from 5 to 7);
> - 'repetitions' is a variable reporting the cardinal number associated to
> the chronological order of the repetitions recorded (so ranging from 1 to
> 7)
>
> This fit very often generates several errors and warnings ("large
> eigenvalue ratio"; "degenerate Hessian with 1 negative eigenvalues"; etc.)
> and if plotting the distribution of fitted/residuals I see stripes clearly
> because of the repetitions.
>
> Finally the questions are:
> - could the repetitions be a problem for the model? Could it better to
> work with an average of the repetitions in order to have only 1 value for
> each item?
> - if the previous is true, does it make sense to compare such a limited
> number of values in such a limited number of subjects with this model?
>
> I am sorry for my limited knowledge in statics. I would be really grateful
> if you could help me to shed light on the problem. Thank you very much in
> advance for your help.
>
> I look forward to hearing from you.
> Kind regards,
>
> Massimiliano
>
>
>
> ===============================================================
>
> Massimiliano Mario Iraci
> PhD student
>
> CRIL (Intedisciplinary Center for Research on Language) &
> DReAM (Laboratory of Research Applied to Medicine)
> University of Salento & Local Health Service (ASL Lecce)
> c/o Vito Fazzi Hospital
> Piazza Filippo Muratore - 73100 - Lecce (Italy)
>
> web: http://www.cril.unisalento.it/en/staff_details.php?id=123
> tel: 0039 - 0832 335008
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From thierry.onkelinx at inbo.be  Mon May  4 08:46:42 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 4 May 2015 08:46:42 +0200
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CABk1Hu3GQrA=4SZn2AtYmXSFFXMVvDfQyrzR4yi_2fgcTdHAvA@mail.gmail.com>
References: <CABk1Hu2pq=U0Fgk0JxpCn2z0qJM7a1Bzido+cye3U1uNT2y2CA@mail.gmail.com>
	<CAJuCY5wW3_oC-73htVqLb6vUCYCs-hwpC-fY3j4KT-v+AgXXQA@mail.gmail.com>
	<CABk1Hu3GQrA=4SZn2AtYmXSFFXMVvDfQyrzR4yi_2fgcTdHAvA@mail.gmail.com>
Message-ID: <CAJuCY5xBN=AHHDpj1AxPW3TBXqnVDSz_JBAftrUUYRLbDN7Ojg@mail.gmail.com>

Dear Silva,

it's not a good idea to repeat the rows. It's better to transform PE into 4
TRUE/FALSE variables and add those variables to the model. This allows you
to keep the original number of rows. Your model reduces to a plain glm

PA ~ AL + PE1 + PE2 + PE3 + PE4

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-04-30 17:08 GMT+02:00 Silvia Rodr?guez Fern?ndez <sileiris at gmail.com>:

> Thierry, thanks a lot for your quick response.
>
>
> We sampled each site (small water points) only once and we noted the
> different PE (human disturbance types). However for our analyses we have
> done as if each site was sampled more than once. That is we repeated each
> row as many times as different perturbance types were recorded in each
> site.
>
>
>   Site
>
> PA
>
> AL
>
> PE
>
> 1
>
> 0
>
> 38
>
> 1
>
>  1
>
> 0
>
> 38
>
> 3
>
> 2
>
> 0
>
> 138
>
> 1
>
> 3
>
> 0
>
> 382
>
> 1
>
> 3
>
> 0
>
> 382
>
> 3
>
> 4
>
> 0
>
> 382
>
> 1
>
> 4
>
> 0
>
> 382
>
> 3
>
>
> Our final aim is to obtain probabilities of presence/absence of each
> amphibian species in a site in relation to the different types of
> disturbance and altitude, using the "invlogit" function. I think the
> "cbind" function is not useful in this case because we are not modelling
> proportions.
>
>
> What do you think?
>
>
> Best regards,
>
>
> Silvia
>
> 2015-04-30 15:25 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Silvia,
>>
>> I presume that the values of AL and PE are constant within the site. Did
>> you sample different locations within each site simultaneous ? Or did you
>> sample the same location at each site but at different dates?
>> In case of different locations per site you can simplify your model to.
>> glm(cbind(n.present, n.absent) ~ AL + PE, family = binomial) With n.present
>> the number of present locations per site.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-04-30 14:50 GMT+02:00 Silvia Rodr?guez Fern?ndez <sileiris at gmail.com
>> >:
>>
>>> Dear list members,
>>>
>>> I?m a PhD student in trouble. I?m running a mix effects model with a
>>> dependent variable (PA: presence/absence, 0/1), one fixed explanatory and
>>> continuous variable (AL: altitude), one fixed factor (PE: initially 16
>>> levels, but reduced to 4 to reduce complexity) and one random term (2421
>>> sites). Basically, the structure of a logistic regression but with a
>>> random
>>> term to prevent temporal pseudoreplication.
>>>
>>> > model1<-glmmadmb(PA~PE+AL+(1|site), family="binomial")
>>>
>>> My data are quite unbalanced becouse I?ve many more zeros than ones. I?ve
>>> tried making a random selection of absences but I get similar problems
>>> than
>>> when using the whole dataset.
>>>
>>> I?m getting an output of results in R, but also getting a warning of lack
>>> of convergence, such as:
>>>
>>> Convergence failed:log-likelihood of gradient= -0.0195034
>>>
>>>
>>> Can I trust my results in spite of the warning?
>>>
>>> What other alternatives do you suggest?
>>>
>>>
>>> I?ve tried with the classical lmer and glmer, and I also get convergence
>>> problems as expected.
>>>
>>> I?ve also tried with the MCMCglmm package, but I?ve problems with the
>>> specification of the priors.
>>>
>>>
>>> Any help is welcomed.
>>>
>>>
>>> Silvia
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From mwiederm at mtu.edu  Mon May  4 22:52:39 2015
From: mwiederm at mtu.edu (Magdalena Wiedermann)
Date: Mon, 04 May 2015 16:52:39 -0400
Subject: [R-sig-ME] mixed-effects model with crossed random effects
In-Reply-To: <loom.20150424T201934-232@post.gmane.org>
References: <553A5B59.4000500@mtu.edu>
	<loom.20150424T201934-232@post.gmane.org>
Message-ID: <5547DC17.30905@mtu.edu>



On 04/24/2015 02:26 PM, Ben Bolker wrote:
> Magdalena Wiedermann <mwiederm at ...> writes:
>
>> Dear list,
>>
>> I am using the nlme package to analyze a mixed effects model. I am
>> dealing with crossed random effects, meaning that I have repeated
>> measures in time and space (on a split plot design). We are sampling
>> water at two depth within one of each vegetation treatment (3 veg
>> treatments) organized in 4 blocks.
>>
>> I figured that the code including the spacial component only would be!?:
>> <-lme(responses~veg*depth*year*Month, random=~1|block/veg)
>>
>> I am aware that 4 blocks is not pretty for it to be a random effect, but
>> I am not interested in it as fixed effects. Also I am aware that there
>> are very many philosophies and views on what a random effect is/should be.
>>
>> Can anybody please help me with adding the temporal component in?
>> Samples on these plots were taken 5 times each year for 3 years => 15
>> times of repeated measures
>>
>> I'd be more than happy about any suggestions, similar examples etc.
>> Thank you so much!
>> Lena
>
>     It is possible to fit crossed random effects in lme (it's discussed
> in one of the later chapters of Pinheiro and Bates), but it's a
> bit of a hassle.  If you're willing to use lme4 instead (you can
> use the lmerTest or pbkrtest if you need p-values, see ?pvalues)
> this will be a little bit easier.
>
>      Something like
>
>    lmer(responses~veg + (veg|year/Month) + (veg|block), data= ...)
>
> would seem to be a reasonable guess, although it may be too much
> for your data since you will be estimating 3 3x3 variance-covariance
> matrices of veg responses (within year, within Month-within-year,
> within block).  I don't know whether you have trends over
> the course of your time series (e.g. add a numeric covariate of
> time period to the fixed effects) or consistent seasonal effects
> (e.g. make your model (veg|year) + (veg|Month) + (veg|year:Month)) ...
>
>     Ben Bolker
?Ben, thank you so much for your suggestions and help! I have a few 
follow up questions though....

1) Why do you choose to write (veg|year/Month) instead of 
(1|veg/year/Month)?
I am asking because I had read that for a continuous random effect it l 
would be written like ~veg  rather than  ~1|veg  which would be use for 
a categorical random effects. Is there anything to it?

2) How would ?lmer(response~veg + (veg|year/Month/block), data=...)? 
compare to your model ?lmer(responses~veg + (veg|year/Month) + 
(veg|block), data= ?)?

3) I am not sure what you mean by ? add a numeric covariate of time 
period to the fixed effects? can you please explain that.

sorry I should have provided more specifics about my spread sheet setup:
block: 1, 2, 3, 4
plot: a, b, c, d, e, f, g, h, I, j, k, l
veg: E, S, U
depth: 20, 40
Month: 5, 6, 7, 8, 9
year: 2012, 2013, 2014

Mainly I am interested in the main effects and interactions of veg*depth 
and I need to account for the fact that I have multiple readings from 
the sampling plots. I regarded it useful to think of it as a split plot 
setup with block divided into 3 veg treatments which each are split into 
two depth treatments. Samples from each exact depth point are taken 
repeatedly for 5 times throughout the year for 3 years. Does plot need 
to be included in the model?

As for seasonal trends: each year the measured values increase over the 
course of the year, but the slopes of this increase seem to vary between 
years. So, additionally it might be interesting to determine whether the 
slopes of the seasonal trends differ between years but that can possibly 
be done in a separate analyzes.

Thank you so much,
Lena
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From carbrae at gmail.com  Tue May  5 20:15:19 2015
From: carbrae at gmail.com (Bradley Carlson)
Date: Tue, 5 May 2015 14:15:19 -0400
Subject: [R-sig-ME] REML vs ML in lmerTest
Message-ID: <CAF37_NfuoeDYYbp25pugtPwspv_SfpDLB4pQPq_5Hp4c6nddGg@mail.gmail.com>

Hi everyone,

I'm a little confused about the use REML and ML. I fit models in lmer,
which were pretty straightforward (a few continuous and a few nominal
predictors, plus random intercepts for clusters of data). I tested the
fixed effects using the lmerTest anova function with Kenward-Roger df (I
have no interest in testing random effect significance). I get the same F
values, df, and p values regardless of whether the models were fit with
REML or ML, but the actual sums of squares in the anova output differ
modestly. Given that it didn't matter at all for the results, it doesn't
seem I should particularly care whether I use REML and ML in the lmer. But,
I want to report which I used.

So my questions:

-Why do I get the same statistical values except for SS with REML and ML?
-Which would be more appropriate - REML or ML? I'm thinking REML because I
have an unbalanced sample sizes for each level of the random effect (based
on Bolker et al. 2008), but I wanted to double check that this makes sense.

Thank you!
Brad

-- 

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN

Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
Website: https://sites.google.com/site/bradleyecarlson/home

	[[alternative HTML version deleted]]


From Daniel.Wright at act.org  Tue May  5 20:19:07 2015
From: Daniel.Wright at act.org (Daniel Wright)
Date: Tue, 5 May 2015 18:19:07 +0000
Subject: [R-sig-ME] REML vs ML in lmerTest
In-Reply-To: <CAF37_NfuoeDYYbp25pugtPwspv_SfpDLB4pQPq_5Hp4c6nddGg@mail.gmail.com>
References: <CAF37_NfuoeDYYbp25pugtPwspv_SfpDLB4pQPq_5Hp4c6nddGg@mail.gmail.com>
Message-ID: <BLUPR04MB803EFE7ED597171390AD6F3EAD10@BLUPR04MB803.namprd04.prod.outlook.com>

Check if the lmerTest function re-estimates the model with ML.  Not sure what lmerTest function you are using (which package?).

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bradley Carlson
Sent: Tuesday, May 05, 2015 1:15 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] REML vs ML in lmerTest

Hi everyone,

I'm a little confused about the use REML and ML. I fit models in lmer, which were pretty straightforward (a few continuous and a few nominal predictors, plus random intercepts for clusters of data). I tested the fixed effects using the lmerTest anova function with Kenward-Roger df (I have no interest in testing random effect significance). I get the same F values, df, and p values regardless of whether the models were fit with REML or ML, but the actual sums of squares in the anova output differ modestly. Given that it didn't matter at all for the results, it doesn't seem I should particularly care whether I use REML and ML in the lmer. But, I want to report which I used.

So my questions:

-Why do I get the same statistical values except for SS with REML and ML?
-Which would be more appropriate - REML or ML? I'm thinking REML because I have an unbalanced sample sizes for each level of the random effect (based on Bolker et al. 2008), but I wanted to double check that this makes sense.

Thank you!
Brad

-- 

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN

Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
Website: https://sites.google.com/site/bradleyecarlson/home

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From carbrae at gmail.com  Tue May  5 20:34:02 2015
From: carbrae at gmail.com (Bradley Carlson)
Date: Tue, 5 May 2015 14:34:02 -0400
Subject: [R-sig-ME] REML vs ML in lmerTest
In-Reply-To: <BLUPR04MB803EFE7ED597171390AD6F3EAD10@BLUPR04MB803.namprd04.prod.outlook.com>
References: <CAF37_NfuoeDYYbp25pugtPwspv_SfpDLB4pQPq_5Hp4c6nddGg@mail.gmail.com>
	<BLUPR04MB803EFE7ED597171390AD6F3EAD10@BLUPR04MB803.namprd04.prod.outlook.com>
Message-ID: <CAF37_NfytaKAo61-nPfFJva8fn_9938MT412OLMTO3JukU3LQg@mail.gmail.com>

The package is lmerTest, the function is anova within that package. I can't
find anyway to determine whether it is re-estimating the model (it doesn't
report anything about REML or ML). If it was re-estimating, though, then
the sums of squares shouldn't be different between the two - but they are.

On Tue, May 5, 2015 at 2:19 PM, Daniel Wright <Daniel.Wright at act.org> wrote:

> Check if the lmerTest function re-estimates the model with ML.  Not sure
> what lmerTest function you are using (which package?).
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Bradley Carlson
> Sent: Tuesday, May 05, 2015 1:15 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] REML vs ML in lmerTest
>
> Hi everyone,
>
> I'm a little confused about the use REML and ML. I fit models in lmer,
> which were pretty straightforward (a few continuous and a few nominal
> predictors, plus random intercepts for clusters of data). I tested the
> fixed effects using the lmerTest anova function with Kenward-Roger df (I
> have no interest in testing random effect significance). I get the same F
> values, df, and p values regardless of whether the models were fit with
> REML or ML, but the actual sums of squares in the anova output differ
> modestly. Given that it didn't matter at all for the results, it doesn't
> seem I should particularly care whether I use REML and ML in the lmer. But,
> I want to report which I used.
>
> So my questions:
>
> -Why do I get the same statistical values except for SS with REML and ML?
> -Which would be more appropriate - REML or ML? I'm thinking REML because I
> have an unbalanced sample sizes for each level of the random effect (based
> on Bolker et al. 2008), but I wanted to double check that this makes sense.
>
> Thank you!
> Brad
>
> --
>
> Bradley Evan Carlson
> Assistant Professor of Biology
> Wabash College, Crawfordsville IN
>
> Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
> Website: https://sites.google.com/site/bradleyecarlson/home
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN

Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
Website: https://sites.google.com/site/bradleyecarlson/home

	[[alternative HTML version deleted]]


From Daniel.Wright at act.org  Tue May  5 20:41:12 2015
From: Daniel.Wright at act.org (Daniel Wright)
Date: Tue, 5 May 2015 18:41:12 +0000
Subject: [R-sig-ME] REML vs ML in lmerTest
In-Reply-To: <CAF37_NfytaKAo61-nPfFJva8fn_9938MT412OLMTO3JukU3LQg@mail.gmail.com>
References: <CAF37_NfuoeDYYbp25pugtPwspv_SfpDLB4pQPq_5Hp4c6nddGg@mail.gmail.com>
	<BLUPR04MB803EFE7ED597171390AD6F3EAD10@BLUPR04MB803.namprd04.prod.outlook.com>
	<CAF37_NfytaKAo61-nPfFJva8fn_9938MT412OLMTO3JukU3LQg@mail.gmail.com>
Message-ID: <BLUPR04MB80353FF58A835605061B86CEAD10@BLUPR04MB803.namprd04.prod.outlook.com>

If the anova with lmerTest works like the method for merMod objects, it will refit (but has the option refit=TRUE). See

http://127.0.0.1:25203/library/lme4/html/merMod-class.html

I don't use the lmerTest package, so hopefully another reader with knowledge of it can respond if it works differently.

From: Bradley Carlson [mailto:carbrae at gmail.com]
Sent: Tuesday, May 05, 2015 1:34 PM
To: Daniel Wright
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] REML vs ML in lmerTest

The package is lmerTest, the function is anova within that package. I can't find anyway to determine whether it is re-estimating the model (it doesn't report anything about REML or ML). If it was re-estimating, though, then the sums of squares shouldn't be different between the two - but they are.

On Tue, May 5, 2015 at 2:19 PM, Daniel Wright <Daniel.Wright at act.org<mailto:Daniel.Wright at act.org>> wrote:
Check if the lmerTest function re-estimates the model with ML.  Not sure what lmerTest function you are using (which package?).

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Bradley Carlson
Sent: Tuesday, May 05, 2015 1:15 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] REML vs ML in lmerTest

Hi everyone,

I'm a little confused about the use REML and ML. I fit models in lmer, which were pretty straightforward (a few continuous and a few nominal predictors, plus random intercepts for clusters of data). I tested the fixed effects using the lmerTest anova function with Kenward-Roger df (I have no interest in testing random effect significance). I get the same F values, df, and p values regardless of whether the models were fit with REML or ML, but the actual sums of squares in the anova output differ modestly. Given that it didn't matter at all for the results, it doesn't seem I should particularly care whether I use REML and ML in the lmer. But, I want to report which I used.

So my questions:

-Why do I get the same statistical values except for SS with REML and ML?
-Which would be more appropriate - REML or ML? I'm thinking REML because I have an unbalanced sample sizes for each level of the random effect (based on Bolker et al. 2008), but I wanted to double check that this makes sense.

Thank you!
Brad

--

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN
Email: *carlsonb at wabash.edu<mailto:carlsonb at wabash.edu>* <+carlsonb at wabash.edu<mailto:carlsonb at wabash.edu>>
Website: https://sites.google.com/site/bradleyecarlson/home

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN

Email: carlsonb at wabash.edu<mailto:+carlsonb at wabash.edu>
Website: https://sites.google.com/site/bradleyecarlson/home

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Wed May  6 10:07:17 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Wed, 6 May 2015 10:07:17 +0200
Subject: [R-sig-ME] Including an autocorrelation term dramatically reduces
 random variance (lme)
Message-ID: <CALC46t9BdYFViiiOcR4sKY5JE_Kc6X==LRdk-2L6wDRqcUFkFw@mail.gmail.com>

Dear list,

My dataset includes 285 individuals for which I have measured one trait
over three months. The traits has been measured at two different time
scales: monthly (maximum 3 replicates per fish) and daily (maximum 90
replicates per fish). For one third of the fish, the trait was measured in
2012, for another third in 2013 and for the last third in 2014. But I
measured always in the same three months: june, july and august.

My objective is to use a mixed modelling approach to estimate repeatability
(Vrandom/(Vrandom+Vresidual)) of this trait. I want to account for three
fixed factors: area (two sites), total length (tl) and time. For
comparative purposes, I want to do it for the two temporal scales, i.e.,
one model using month and therefore three replicates per ID, and a
different model using (julian) day and 90 replicates per ID.

My attempts so far for the model with month:

MODEL 1: Mixed model without autocorrelation term

lme1=lme(loghr~area+tl+factor(month2),random=~1|fish,data=hrm3,method="REML")

> summary(lme1)
Linear mixed-effects model fit by REML
 Data: hrm3
       AIC      BIC    logLik
  1498.771 1531.537 -742.3854

Random effects:
 Formula: ~1 | fish
                (Intercept) Residual
StdDev:   0.4649101 0.4790193

Fixed effects: loghr ~ area + tl + factor(month2)
                            Value         Std.Error       DF    t-value
   p-value
(Intercept)           -1.1688029 0.15189536 514  -7.694790    0.0000
areatvedestrand -0.9943160 0.06490892 283  -15.318635  0.0000
tl                         -0.0034115 0.00308169 283  -1.107031    0.2692
factor(month2)7 -0.2242556 0.04074810 514  -5.503462     0.0000
factor(month2)8 -0.1269165 0.04245662 514  -2.989322     0.0029

Correlation:
                            (Intr)   artvds   tl         fc(2)7
areatvedestrand -0.224
tl                         -0.943  0.019
factor(month2)7 -0.121  0.003 -0.011
factor(month2)8 -0.113 -0.006 -0.011  0.475

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-2.7792032 -0.5127146 -0.1031226  0.3935509  4.3119462

Number of Observations: 802
Number of Groups: 286

The estimation of Repeatability from this model would be
0.46/(0.46+0.47)=0.485
However if I extract the residuals from this model
res=resid(lme,type="normalized") and do acf(residuals) the plot shows a
high autocorrelation in the first 15 lags. So I tried the following:

MODEL 2: same model including an autocorrelation term

lme3=update(lme1,correlation=corAR1(form=~month2))

> summary(lme)
Linear mixed-effects model fit by REML
 Data: hrm3
       AIC     BIC    logLik
  1461.013 1498.46 -722.5066

Random effects:
 Formula: ~1 | fish
              (Intercept)       Residual
StdDev: 0.0005272246 0.6819065

Correlation Structure: ARMA(1,0)
 Formula: ~month2 | fish
 Parameter estimate(s):
     Phi1
0.6097222
Fixed effects: loghr ~ area + tl + factor(month2)
                            Value         Std.Error      DF    t-value
  p-value
(Intercept)           -1.1584548 0.15740075 514  -7.359906  0.0000
areatvedestrand -1.0019165 0.06730508 283  -14.886194 0.0000
tl                         -0.0035497 0.00319449 283  -1.111192   0.2674
factor(month2)7 -0.2212453 0.03628563 514  -6.097327   0.0000
factor(month2)8 -0.1275377 0.04735955 514  -2.692968   0.0073
 Correlation:
                            (Intr) artvds tl     fc(2)7
areatvedestrand -0.227
tl                         -0.944  0.022
factor(month2)7 -0.104  0.003 -0.009
factor(month2)8 -0.124 -0.005 -0.013  0.611

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.62204450 -0.68663130 -0.08503995  0.58177543  3.79290975

Number of Observations: 802
Number of Groups: 286

If I plot acf(residual) now the plot looks much nicer (almost all the
autocorrelation has been corrected)

As you can see, the fact of including the autocorrelation term dramatically
reduces the random variance from 0.46 to 0.0005, which in turn reduces the
Repeatability from 0.485 to 5.98e-07.

NOW: if repeat this exercise working at a daily scale (90 replicates per
ID), the reduction in random variance and repeatability is much smaller
(from 0.46 to 0.16), but very noticeable still.

My questions are:
- How should I interpret this? Is the autocorrelation term in model 2
taking most of the random variance previously explained by the individual
ID in model 1?
- Model 2 yields a very low value of repeatability, however model selection
is telling me than the random effect (individual ID) has to be included in
the model. I interpret this as the repeatability being significantly
different from zero, even it is really low. Correct?
- With a different trait, I observe the same reduction after including a
"weights" argument. And with another trait, I observe a similar reduction
when I pass from an autocorrelation structure corAR1 to a correlation
structure corARMA (2,2). Any thought?
- Could I say that including explanatory variables (fixed part of the
model) will reduce the residual variance, and including terms in the random
part of the model (random factors, autocorrelations terms, weights, ...)
will reduce the random variance?

Many thanks in advance,

David

	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Wed May  6 10:22:34 2015
From: robgriffin247 at hotmail.com (Robert Griffin)
Date: Wed, 6 May 2015 10:22:34 +0200
Subject: [R-sig-ME] estimates of low variance in mcmcglmm (cont.)
Message-ID: <CAMm5Hay7abtSg6ODQwqTZL5gBwFjBPpcMfE2bKVMogup8q2RcQ@mail.gmail.com>

I am resending the below email because it appears it did not reach the list
last time, sent a few weeks back, now also edited):
It follows up on this thread (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023370.html)
-------------

Hi Jarrod - thanks for the tip,

What is concerning me is that I have tried this out with dummy data now, to
test whether a variance signal from line is detected when line variance
does not exist. From that I get an estimate of tiny line variance but the
quantiles are all positive (suggesting, to me, that it is significantly
larger than zero, though very close).

                   2.5%       25%       50%       75%     97.5%
line_variance 7.751e-07 8.486e-05 3.801e-04 1.039e-03 3.396e-03

Examining the plots of the chain VCV, however, shows that the density plot
for line is pushed up against zero, which leads me to believe that the
variance is *not *different from zero.

I am trying to test whether or not there is line variance - but given that
negative estimates of variance cannot be estimated, the quantiles will
never overlap zero. Would it make sense to randomly reassign the line
labels among individuals in my real data and then compare the density plots
of the posterior distributions for the real data and randomised data - then
if the plot for the real data does not stack up against zero, and the
randomised does, it appears that the line variance signal is genuine? Is
there a better way to test (and report) this?

Rob

Here is the dummy script (*run1 *and *run2 *need to be set as *yes* and *path
*needs setting to relevant file directory if you are repeating the
analysis) and the output is just below.

require("MCMCglmm")
set.seed(62346)

# Run chains
run1 = "no"
run2 = "no"

# File path
path = "C://Users//"

# Construct data
n = 50000 # number of samples
l = 33 # number of lines
b = 4 # number of blocks
v = 8 # number of vials

df = data.frame(
round(rnorm(n, 50, 3),0), # Response variable
sample(1:l, n, replace = T), # Assign lines
sample(1:b, n, replace = T), # Assign block
sample(1:v, n, replace = T) # Assign vial
)
colnames(df) = c("score", "line", "block", "vial")

# Check even distributions
hist(df$score, breaks = 25)
hist(df$line,  breaks = 25)
hist(df$block, breaks = 25)
hist(df$vial, breaks = 25)

# Visual approximation for line effect
boxplot(df$score ~ df$line)

# Chain parameters
nitt = 20000
burnin = 2000
thin = 10

# Prior
prior = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
R  = list(V = 1, nu=0.002))

# MCMC chains
if(run1 == "yes"){
chain100 = MCMCglmm(score ~1 + block,
random = ~line + vial,
rcov = ~units,
nitt = nitt,
thin = thin,
burnin = burnin,
prior = prior,
family = "gaussian",
start = list(QUASI = FALSE),
data = df)
file = paste(path, "chain100.rda", sep = "")
save(chain100, file = file)
}else{}


if(run2 == "yes"){
chain101 = MCMCglmm(score ~1 + block,
random = ~line + vial,
rcov = ~units,
nitt = nitt,
thin = thin,
burnin = burnin,
prior = prior,
family = "gaussian",
start = list(QUASI = FALSE),
data = df)
file = paste(path, "chain101.rda", sep = "")
save(chain101, file = file)
}else{}

# Load chains
chain_100 = load(paste(path, "chain100.rda", sep= ""))
chain_101 = load(paste(path, "chain101.rda", sep= ""))

# Chain function
chain_fun1 = function(chainX, chainSol){
chainX = mcmc(data =cbind(
# Mean score
mean_score = chainSol[,"(Intercept)"],
# Line variance
line_variance = chainX[,"line"],
# Vial variance
vial_variance = chainX[,"vial"],
# Residual variance
unit_variance = chainX[,"units"],
# Phenotypic variance
phen_variance = chainX[,"line"] + chainX[,"vial"] + chainX[,"units"]

),
start = attr(chainX, "mcpar")[1],
end = attr(chainX, "mcpar")[2],
thin = attr(chainX, "mcpar")[3])

chainX = mcmc(data =cbind( chainX,
# Heritability
heritability = chainX[,"line_variance"]/chainX[,"phen_variance"],
# Coefficient of Genetic Variance
gene.coeff = sqrt(chainX[,"line_variance"])/chainX[,"mean_score"],
# Coefficient of VP
phen.coeff = sqrt(chainX[,"phen_variance"])/chainX[,"mean_score"]


),
start = attr(chainX, "mcpar")[1],
end = attr(chainX, "mcpar")[2],
thin = attr(chainX, "mcpar")[3])
return(chainX)
}

results1 =
mcmc.list(chain_fun1(chain100$VCV,chain100$Sol),chain_fun1(chain101$VCV,chain101$Sol))
summary(results1)

plot(chain100$VCV[,1])
plot(chain101$VCV[,1])


## Output ##
> summary(results1)

Iterations = 2001:19991
Thinning interval = 10
Number of chains = 2
Sample size per chain = 1800

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

                   Mean        SD  Naive SE Time-series SE
mean_score    5.002e+01 0.0344920 5.749e-04      5.748e-04
line_variance 7.412e-04 0.0009462 1.577e-05      1.509e-05
vial_variance 5.333e-04 0.0009973 1.662e-05      1.696e-05
unit_variance 9.006e+00 0.0564273 9.405e-04      9.405e-04
phen_variance 9.008e+00 0.0564594 9.410e-04      9.410e-04
heritability  8.228e-05 0.0001050 1.750e-06      1.674e-06
gene.coeff    4.440e-04 0.0003149 5.248e-06      5.040e-06
phen.coeff    6.000e-02 0.0001936 3.226e-06      3.226e-06

2. Quantiles for each variable:

                   2.5%       25%       50%       75%     97.5%
mean_score    4.995e+01 5.000e+01 5.002e+01 5.005e+01 5.009e+01
line_variance 7.751e-07 8.486e-05 3.801e-04 1.039e-03 3.396e-03
vial_variance 3.095e-07 3.938e-05 1.884e-04 6.070e-04 3.010e-03
unit_variance 8.895e+00 8.969e+00 9.005e+00 9.046e+00 9.115e+00
phen_variance 8.895e+00 8.970e+00 9.006e+00 9.047e+00 9.116e+00
heritability  8.656e-08 9.481e-06 4.203e-05 1.154e-04 3.755e-04
gene.coeff    1.761e-05 1.840e-04 3.899e-04 6.441e-04 1.164e-03
phen.coeff    5.962e-02 5.987e-02 6.000e-02 6.013e-02 6.037e-02



----------------------
Previous message:

Hi Rob,

Parameter expanded priors are probably a better option:


prior = list(G = list( G1 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G2 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000),
G3 = list(V = 1, nu=1, alpha.mu=0, alpha.V=1000)),
R  = list(V = 1, nu=0.002))

This prior is approximately flat for the standard deviation. Note that
this does not imply it is flat for the variance; it still puts quite a
bit of mass at zero, but less than the inverse-Wishart with low degree
of belief. If you want something flat on the variance scale (e.g. a
uniform distribution) you'll have to move to WinBugs or JAGS.

Parameter expansion is not implemented for the residuals so I've left
the inverse-Wishart prior on the residual variance. Usually the data
overwhelm the prior for the residual variance so you can probably be
pretty relaxed about that.

Cheers,

Jarrod




Quoting Robert Griffin <robgriffin247 at hotmail.com
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>> on Fri, 27
Mar 2015
15:33:15 +0100:

>* Dear list,
*>>* I have sampled ~35 copies of a chromosome from a population because I want
*>* to estimate how much contribution that part of the genome makes to the
*>* variance in the traits. Therefore I want to estimate the additive genetic
*>* variance. I will do this by using making a univariate response model in
*>* MCMCglmm. The data for the trait was collected from 300-500 offspring per
*>* sampled chromosome, and measured in males. This was done across 4
*>* experimental *blocks *and within each *line *and *block *there were 4 *vials
*>* *of many individuals, each sourced from one of two *sets *of parents.
*>>* Within the model there are *block*, parental set (*set*), *vial*, and *line
*>* *effects to model. I have done this in the following way:
*>>* chain1 = MCMCglmm(trait ~1 + block,
*>* random = ~line + set + vial,
*>* rcov = ~units,
*>* nitt = nitt,
*>* thin = thin,
*>* burnin = burnin,
*>* prior = prior,
*>* family = "gaussian",
*>* start = list(QUASI = FALSE),
*>* data = df1)
*>>>* However, the phenotypic variance in this trait is large [var(trait) =
*>* ~150], and I am expecting an extremely large part of the variance to be
*>* environmental & measurement error (residual), and the variables of line,
*>* set, block, and vial to contribute very little (probably <5% of total
*>* variation each) - visual examination of the data suggests that there is
*>* almost no variance among lines, blocks, vials, or parental sets. Which
*>* leads me to my call for help.
*>>* I am mainly concerned about how to choose priors for variances which are
*>* expected to be near zero (when the aim is to test if line variance is not
*>* 0) - can this affect the outcome of the model? How should I define my
*>* priors in such a case? Currently my best estimate from reading the
*>* literature is to use the following:
*>>* prior = list(G = list( G1 = list(V = var(trait)/4, nu=0.002),
*>* G2 = list(V = var(trait)/4, nu=0.002),
*>* G3 = list(V = var(trait)/4, nu=0.002)),
*>* R  = list(V = var(trait)/4, nu=0.002))
*>>>* Advice about the priors (and the model in general if you happen spot
*>* anything- e.g. should the family be Gaussian?) would be greatly appreciated,
*>>* Rob
*>>>* -----------------------------
*>* Robert Griffin
*>* PhD candidate, Uppsala University
*>* griffinevo.wordpress.com <http://griffinevo.wordpress.com>
*>>* 	[[alternative HTML version deleted]]
*>>* _______________________________________________
*>* R-sig-mixed-models at r-project.org
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> mailing
list
*>* https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
*>>

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

	[[alternative HTML version deleted]]


From steve.bellan at gmail.com  Wed May  6 00:18:14 2015
From: steve.bellan at gmail.com (Steve Bellan)
Date: Tue, 5 May 2015 17:18:14 -0500
Subject: [R-sig-ME] gamm4 "no terms component nor attribute"
Message-ID: <FC4E93F5-3028-4190-AEC6-E5502F7B5092@gmail.com>

Hi all,

I can't even get gamm4 to run it's own example due to this error:

Error in terms.default(object, data = data) : 
  no terms component nor attribute

, let alone to work on my own data. Haven't been able to find much online. Help much appreciated! Session info & details below. Thanks,

Steve

Steven Bellan, PhD, MPH
Post-doctoral Researcher
Lauren Ancel Meyers Research Group
Center for Computational Biology and Bioinformatics
University of Texas at Austin
steve.bellan at gmail.com
http://www.bio.utexas.edu/research/meyers/steve_bellan/

> sessionInfo()
sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
> library(gamm4)
library(gamm4)
Loading required package: Matrix
Loading required package: lme4
Loading required package: Rcpp
Loading required package: mgcv
Loading required package: nlme

Attaching package: ?nlme?

The following object is masked from ?package:lme4?:

    lmList

This is mgcv 1.7-26. For overview type 'help("mgcv-package")'.
This is gamm4 0.2-3
> example(gamm4)
example(gamm4)

gamm4> ## NOTE: most examples are flagged as 'do not run' simply to
gamm4> ## save time in package checking on CRAN.
gamm4> 
gamm4> ###################################
gamm4> ## A simple additive mixed model...
gamm4> ###################################
gamm4> library(gamm4)

gamm4> set.seed(0) 

gamm4> dat <- gamSim(1,n=400,scale=2) ## simulate 4 term additive truth
Gu & Wahba 4 term additive model

gamm4> ## Now add 20 level random effect `fac'...
gamm4> dat$fac <- fac <- as.factor(sample(1:20,400,replace=TRUE))

gamm4> dat$y <- dat$y + model.matrix(~fac-1)%*%rnorm(20)*.5

gamm4> br <- gamm4(y~s(x0)+x1+s(x2),data=dat,random=~(1|fac))
Error in terms.default(object, data = data) : 
  no terms component nor attribute
> 







	[[alternative HTML version deleted]]


From markus.brauer at wisc.edu  Wed May  6 18:45:16 2015
From: markus.brauer at wisc.edu (Markus Brauer)
Date: Wed, 06 May 2015 11:45:16 -0500
Subject: [R-sig-ME] lmer: constraining sigma to 0
In-Reply-To: <532607A4.60209@gmail.com>
References: <532607A4.60209@gmail.com>
Message-ID: <554A451C.8020608@wisc.edu>


Dear colleague,

I came across a website/forum in which you talked about constraining the 
residual variance to zero (in LMEMs):

http://permalink.gmane.org/gmane.comp.lang.r.lme4.devel/11418

I am aware that you suggested to use blmer. Has there been any 
development since 2013? Is there a way to fix sigma EXACTLY to zero now?

Here is the problem. Like you, I teach statistics and linear 
mixed-effects models. My students and I frequently use lmer to analyze 
data with one or multiple sources of non-independence. However, I run 
into problems with designs that contain only dichotomous within-subject 
variables and only one data point per cell of the design per subject. In 
these designs, the residuals are zero (the level-1 models perfectly fit 
the data). I understand that technically, such a linear mixed-effects 
models are not identifiable. They would be identifiable, however, if I 
could fix the parameter for the variance of the residuals to zero.

I can, of course, transform my data into wide format and analyze them 
with a GLM procedure (e.g., lm) but it seems bizarre to have to go 
through the tedious data restructuring process (dcast ...) and use 
different commands for a certain type of design that is in fact quite 
similar to other designs that can easily be analyzed with lmer.

I tried a number of things (e.g., not including any random slopes, not 
including the random slope for the highest order interaction effect), 
but none of them gave me the ?right? values for the inferential 
statistics. Take a 2 x 2 within-subjects ANOVA with one data point per 
cell of the design from each participant. By transforming the data into 
wide format and using a standard GLM procedure I can obtain the ?right? 
F- and p-values. I have not found a way to obtain the same values with 
the data in long format (i.e., four lines per participant) and using 
lmer. It doesn?t matter which random effects structure I specify ? I am 
not getting the ?right? F- and p-values.

The only trick I have found in lmer is to suppress the error message 
with control=lmerControl(check.nobs.vs.nRE="ignore"). But suppressing 
the error message is not the same as constraining sigma to be zero.

Do you know how to fix the parameter for the variance of the residuals 
to zero?

Thanks a lot for your insight. Best wishes,

? Markus



-----------------------------------------------
Markus Brauer
Professor
Department of Psychology
University of Wisconsin - Madison
1202 West Johnson St.
Madison, WI 53706-1611
USA
Tel. +1-608-890-3313
Cell +1-608-692-3468
Fax  +1-608-262-4029
Office 417
Web Page: http://psych.wisc.edu/brauer/BrauerLab/




	[[alternative HTML version deleted]]


From markleeds2 at gmail.com  Wed May  6 19:57:51 2015
From: markleeds2 at gmail.com (Mark Leeds)
Date: Wed, 6 May 2015 13:57:51 -0400
Subject: [R-sig-ME] question about gls in nlme
Message-ID: <CAHz+bWZVtd_mbhvWsU4+-2rqsFrg+fPs7Z8u7u1iGPgz1HBQFQ@mail.gmail.com>

Hi: I've looked around for a long while and I can't figure out something
about
the gls function in the nlme package. If someone wouldn't mind explaining
it or knows of a good reference ( I have pinheiro and bates but it's 10
states away because I lent it to someone ) that explains the following,
that would be fine also.

Suppose I am estimating a  2 predictor regression model with AR(1) errors.

So, the mode isl y_t = B_0 + B_1*x_t + B2*y_2 +  u_t         t = 1,..... T

where u_t =  phi*u_t-1 + epsilon_t

where var(epsilon_t) is sigma^2.

My first question is:

When one runs the function gls, I can't tell what the residuals represent.
In other words, are they

A) the residuals associated with the transformed regression where the error
term is epsilon_t  with variance(sigma^2).

or

B) the residuals associated with the untransformed model written above
so with covariance matrix V and elements V_ij =   phi^(|j-i| * sigma^2 /
(1-phi^2).

My second question is:

Whether  the result represents A or B, is there a way to use a gls related
 function to convert back and forth between the two  ? Thanks a lot for any
wisdom references etc. I've looked all over and can't find much related to
my question.

The other possible  option is to consider using the systemfit package but I
have a feeling there must be a way to do this using gls.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May  6 22:47:44 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 06 May 2015 16:47:44 -0400
Subject: [R-sig-ME] lmer: constraining sigma to 0
In-Reply-To: <554A451C.8020608@wisc.edu>
References: <532607A4.60209@gmail.com> <554A451C.8020608@wisc.edu>
Message-ID: <554A7DF0.3010607@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-05-06 12:45 PM, Markus Brauer wrote:
> 
> Dear colleague,
> 
> I came across a website/forum in which you talked about
> constraining the residual variance to zero (in LMEMs):
> 
> http://permalink.gmane.org/gmane.comp.lang.r.lme4.devel/11418
> 
> I am aware that you suggested to use blmer. Has there been any 
> development since 2013? Is there a way to fix sigma EXACTLY to zero
> now?

I believe nothing has changed since 2013.  As I may have said in that
message (I'm not bothering to check ...), and as Doug Bates has
certainly said before, lmer's underlying parameterization is in terms
of a *relative* covariance parameter Sigma -- that is, all of the
random-effects (co)variances are expressed relative to the
observation-level/residual variance.

- From http://arxiv.org/abs/1406.5823 (hopefully coming to JSS any day now!)

Section 3.4:

We are now in a position to understand why the formulation in
equations 2 and 3 is particularly useful. We are able to explicitly
profile $\betavec$ and $\sigma$ out of the log-likelihood (Equation
25), to find a compact expression for the profiled deviance (negative
twice the profiled log-likelihood) and the profiled REML criterion as
a function of the relative covariance parameters, $\bm\theta$, only.
Furthermore these criteria can be evaluated quickly and accurately.

========

I can understand the problem this presents for you, but I don't know how
helpful I can be.   Besides the aforementioned tricks (e.g. using blmer),
I wonder if you could hack up a post-fitting summary that would combine
the unidentifiable variance components into a single (identifiable)
value ... ?


> 
> Here is the problem. Like you, I teach statistics and linear 
> mixed-effects models. My students and I frequently use lmer to
> analyze data with one or multiple sources of non-independence.
> However, I run into problems with designs that contain only
> dichotomous within-subject variables and only one data point per
> cell of the design per subject. In these designs, the residuals are
> zero (the level-1 models perfectly fit the data). I understand that
> technically, such a linear mixed-effects models are not
> identifiable. They would be identifiable, however, if I could fix
> the parameter for the variance of the residuals to zero.
> 
> I can, of course, transform my data into wide format and analyze
> them with a GLM procedure (e.g., lm) but it seems bizarre to have
> to go through the tedious data restructuring process (dcast ...)
> and use different commands for a certain type of design that is in
> fact quite similar to other designs that can easily be analyzed
> with lmer.
> 
> I tried a number of things (e.g., not including any random slopes,
> not including the random slope for the highest order interaction
> effect), but none of them gave me the ?right? values for the
> inferential statistics. Take a 2 x 2 within-subjects ANOVA with one
> data point per cell of the design from each participant. By
> transforming the data into wide format and using a standard GLM
> procedure I can obtain the ?right? F- and p-values. I have not
> found a way to obtain the same values with the data in long format
> (i.e., four lines per participant) and using lmer. It doesn?t
> matter which random effects structure I specify ? I am not getting
> the ?right? F- and p-values.
> 
> The only trick I have found in lmer is to suppress the error
> message with control=lmerControl(check.nobs.vs.nRE="ignore"). But
> suppressing the error message is not the same as constraining sigma
> to be zero.
> 
> Do you know how to fix the parameter for the variance of the
> residuals to zero?
> 
> Thanks a lot for your insight. Best wishes,
> 
> ? Markus
> 
> 
> 
> ----------------------------------------------- Markus Brauer 
> Professor Department of Psychology University of Wisconsin -
> Madison 1202 West Johnson St. Madison, WI 53706-1611 USA Tel.
> +1-608-890-3313 Cell +1-608-692-3468 Fax  +1-608-262-4029 Office
> 417 Web Page: http://psych.wisc.edu/brauer/BrauerLab/
> 
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVSn3vAAoJEOCV5YRblxUH4Y8H/3oKcCYyre/U75belQcsiiRi
mw+RWKwRU54hDeZK0r1tu2z4oZgSIXwOsqGEDw/eqWOh7pYId+2BW6rjRM6CJG7V
IAEAR5isFpX5mFLbDzbf1ad4vy2tSdelMSkcRwkV0XYf3R4zPl4tE3O8NdcdWibU
Pqpx4i1I1GNE8xSDF+Friihr6lz2/mfYxAUtJKCgIS0AoSSDKs3cyjEL3d9wjngB
x4vqlLjXqoPT8bfluYJ5bY4cZTcKW3NU224qRk4PvuypeQYB3KdN6sTobcfcoNS3
n0vTy0ygPndV2TDtf0ckaUnnHsP46MAd54/HQAyjYD6pP7NHoco3BSlJyaUgaDY=
=NHnZ
-----END PGP SIGNATURE-----


From ken.beath at mq.edu.au  Wed May  6 23:24:11 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 7 May 2015 07:24:11 +1000
Subject: [R-sig-ME] gamm4 "no terms component nor attribute"
In-Reply-To: <FC4E93F5-3028-4190-AEC6-E5502F7B5092@gmail.com>
References: <FC4E93F5-3028-4190-AEC6-E5502F7B5092@gmail.com>
Message-ID: <CAF5_5cxB113ArTnSaN9UgmegYmXoNq54srV_CEnOK+nQ7xbVAw@mail.gmail.com>

This is a problem with either your system, possibly in the way things are
installed or possibly something to do with gamm4.

Your problems may relate to having an 18 month old version of R and mvcv,
and the current version of gamm4. Standard practice is to update to the
current versions and then contact the package author.

On 6 May 2015 at 08:18, Steve Bellan <steve.bellan at gmail.com> wrote:

> Hi all,
>
> I can't even get gamm4 to run it's own example due to this error:
>
> Error in terms.default(object, data = data) :
>   no terms component nor attribute
>
> , let alone to work on my own data. Haven't been able to find much online.
> Help much appreciated! Session info & details below. Thanks,
>
> Steve
>
> Steven Bellan, PhD, MPH
> Post-doctoral Researcher
> Lauren Ancel Meyers Research Group
> Center for Computational Biology and Bioinformatics
> University of Texas at Austin
> steve.bellan at gmail.com
> http://www.bio.utexas.edu/research/meyers/steve_bellan/
>
> > sessionInfo()
> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> > library(gamm4)
> library(gamm4)
> Loading required package: Matrix
> Loading required package: lme4
> Loading required package: Rcpp
> Loading required package: mgcv
> Loading required package: nlme
>
> Attaching package: ?nlme?
>
> The following object is masked from ?package:lme4?:
>
>     lmList
>
> This is mgcv 1.7-26. For overview type 'help("mgcv-package")'.
> This is gamm4 0.2-3
> > example(gamm4)
> example(gamm4)
>
> gamm4> ## NOTE: most examples are flagged as 'do not run' simply to
> gamm4> ## save time in package checking on CRAN.
> gamm4>
> gamm4> ###################################
> gamm4> ## A simple additive mixed model...
> gamm4> ###################################
> gamm4> library(gamm4)
>
> gamm4> set.seed(0)
>
> gamm4> dat <- gamSim(1,n=400,scale=2) ## simulate 4 term additive truth
> Gu & Wahba 4 term additive model
>
> gamm4> ## Now add 20 level random effect `fac'...
> gamm4> dat$fac <- fac <- as.factor(sample(1:20,400,replace=TRUE))
>
> gamm4> dat$y <- dat$y + model.matrix(~fac-1)%*%rnorm(20)*.5
>
> gamm4> br <- gamm4(y~s(x0)+x1+s(x2),data=dat,random=~(1|fac))
> Error in terms.default(object, data = data) :
>   no terms component nor attribute
> >
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From epasipanodya at psych.udel.edu  Wed May  6 23:39:10 2015
From: epasipanodya at psych.udel.edu (Elizabeth Pasipanodya)
Date: Wed, 6 May 2015 17:39:10 -0400
Subject: [R-sig-ME] Interpreting the ACME in mediation
In-Reply-To: <8DC1EA0EB7E3FD419D9B3BE76BD403867B15439C5F@razor.psych.udel.edu>
References: <8DC1EA0EB7E3FD419D9B3BE76BD403867B15439C5F@razor.psych.udel.edu>
Message-ID: <8DC1EA0EB7E3FD419D9B3BE76BD403867B15439C60@razor.psych.udel.edu>

Hello All,

I am a doctoral student working on data from a project focusing on couples coping with breast cancer. I have a mediation model with two simultaneous predictors, X1 (a positive relationship event) and  X2 (a relationship conflict), a mediator, M (a measure of intimacy), and an outcome Y (a measure of anxiety). X1 and X2 are both binary while M is continuous. Additionally, Y follows a count distribution. These variables are repeatedly measured for each individual across a number of days and, thus, I used the R packages lme4 and mediation to conduct my analyses.

I would like to double-check the meaning of the ACME. My understanding is that it represents the expected difference in the potential outcome when the mediator takes the value that it would have under the treatment condition compared to the control condition, while the treatment condition is held constant. Since I have a count outcome, should I report and interpret my ACME in the same units as my count outcome, as one would a rate ratio? That is, the ACME shall represent, in the logs of expected counts, the estimated average change in Y among the treatment group (those with a relationship event) as a result of M (intimacy) rather than directly from X1 (positive relationship event) and X2 (negative relationship event)?

For instance, based on the mediation output below, could I say something like the following --- on a day in which participants reported experiencing at least one negative relationship event, their estimated average change in anxiety due to changes in intimacy was 1.08 times (e^0.07485) that of those without a relationship conflict, controlling for the occurrence of positive relationship events?

> med2 <- mediate(apath, bpath, treat = "X2", mediator = "M", sims=5000, control.value = -0.5, treat.value = 0.5, dropobs=TRUE, method = "boot", boot.type = "bca")
> summary(med2)

Causal Mediation Analysis

Quasi-Bayesian Confidence Intervals

Mediator Groups: ID

Outcome Groups: ID

Output Based on Overall Averages Across Groups

                          Estimate 95% CI Lower 95% CI Upper p-value
ACME (control)             0.07890      0.02639      0.15107    0.00
ACME (treated)             0.07080      0.02354      0.13856    0.00
ADE (control)             -0.06645     -0.32283      0.17712    0.50
ADE (treated)             -0.07455     -0.35353      0.19218    0.50
Total Effect               0.00435     -0.25810      0.26892    0.97
Prop. Mediated (control)   0.16404    -11.47515     12.32893    0.97
Prop. Mediated (treated)   0.20262     -9.82740     10.87888    0.97
ACME (average)             0.07485      0.02583      0.14364    0.00
ADE (average)             -0.07050     -0.33728      0.18478    0.50
Prop. Mediated (average)   0.18333    -10.80037     11.56373    0.97

Sample Size Used: 602


Simulations: 5000

Best,

Elizabeth Pasipanodya


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu May  7 10:08:24 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 7 May 2015 10:08:24 +0200
Subject: [R-sig-ME] Including an autocorrelation term dramatically
 reduces random variance (lme)
In-Reply-To: <CALC46t_8aWzs1JtfiomTWYUGM6K=MCyu8ZQXx_hmnpJvsQ8jEg@mail.gmail.com>
References: <CALC46t9BdYFViiiOcR4sKY5JE_Kc6X==LRdk-2L6wDRqcUFkFw@mail.gmail.com>
	<CAJuCY5xPGobCb3mrc1EnJ9OE02BapACw9omjm_rx1E+zDqurLA@mail.gmail.com>
	<CALC46t_8aWzs1JtfiomTWYUGM6K=MCyu8ZQXx_hmnpJvsQ8jEg@mail.gmail.com>
Message-ID: <CAJuCY5xSA3LeQcZOPHGtqMJSx9jO_kyf0E2rYqayBQe3mmKqoA@mail.gmail.com>

Dear David,

Please keep the mailing list in cc.

Correlation structures in nlme work on the residuals conditional on the
random effects. This implies that residuals from different levels of the
random effects are assumed to be independent (not correlated). Some of the
information can be described by both the random effect and the correlation
structure. In fact a random intercept is equivalent with a compound
symmetry correlation structure.

You have only 3 observations per random effect level. Then it is hard to
make the difference between the average of within the group (the random
effect) and the correlated residuals. In such cases the shrinkage kick in
very hard, reducing the random effect variance strongly.

IMHO you need choose a model than matches the design. The design dictates
that you need a random effect of fish. This leads to 3 per fish. 3
observations is not enough to estimate a AR1 correlation. Since you have
only 3 observations is doesn't make sense to look at 15 lags. You only have
2...

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-06 14:52 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:

> Dear Thierry, thank you for your kind response.
>
> I understand that the residual variance must be different between the two
> models (with and without autocorrelation term). However, as you can see in
> my original post, the main change (3 orders of magnitude) is in the random
> variance (the between-individuals variance). I don't understand this. It
> seems that the autocorrelation term "eats" all the variance previously
> explained by the individual ID...
>
> In addition, it makes sense of course to leave always the random ID in the
> model. But to me, the only way to test if the random variance (and
> therefore the repeatability) is different from zero, is to test if the
> model needs the random ID (AIC, anova,...between model with and model
> without random ID). Of course I could calculate the CI for the
> repeatability using parametric bootstrapping, but this seems a difficult
> task for such complex models according to this previous post:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023385.html
>
> Best,
>
> David
>
>
>
> 2015-05-06 14:21 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear David,
>>
>> A model without correlation has $\epsilon_t \sim N(0, \sigma_1)$
>> AR1 correlation implies: $\epsilon_t = \phi \epsilon_{t-1} + a_t$  with
>> $\a_t \sim N(0, \sigma_2)$ (see Pinheiro and Bates, 2000). So the residual
>> variance in this model is not the same thing. It makes sense that
>> $\sigma_2$ is smaller than $\sigma_1$.
>>
>> You should takes this into account when calculating the repeatability.
>>
>> Don't bother testing the need of ID. The design of your experiment
>> dictates the need to include it in the model.
>>
>> Weights affect the residual variance somewhat similar as a correlation
>> structure does. Have a look at the formulas in Pinheiro and Bates (2000).
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-05-06 10:07 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:
>>
>>> Dear list,
>>>
>>> My dataset includes 285 individuals for which I have measured one trait
>>> over three months. The traits has been measured at two different time
>>> scales: monthly (maximum 3 replicates per fish) and daily (maximum 90
>>> replicates per fish). For one third of the fish, the trait was measured
>>> in
>>> 2012, for another third in 2013 and for the last third in 2014. But I
>>> measured always in the same three months: june, july and august.
>>>
>>> My objective is to use a mixed modelling approach to estimate
>>> repeatability
>>> (Vrandom/(Vrandom+Vresidual)) of this trait. I want to account for three
>>> fixed factors: area (two sites), total length (tl) and time. For
>>> comparative purposes, I want to do it for the two temporal scales, i.e.,
>>> one model using month and therefore three replicates per ID, and a
>>> different model using (julian) day and 90 replicates per ID.
>>>
>>> My attempts so far for the model with month:
>>>
>>> MODEL 1: Mixed model without autocorrelation term
>>>
>>>
>>> lme1=lme(loghr~area+tl+factor(month2),random=~1|fish,data=hrm3,method="REML")
>>>
>>> > summary(lme1)
>>> Linear mixed-effects model fit by REML
>>>  Data: hrm3
>>>        AIC      BIC    logLik
>>>   1498.771 1531.537 -742.3854
>>>
>>> Random effects:
>>>  Formula: ~1 | fish
>>>                 (Intercept) Residual
>>> StdDev:   0.4649101 0.4790193
>>>
>>> Fixed effects: loghr ~ area + tl + factor(month2)
>>>                             Value         Std.Error       DF    t-value
>>>    p-value
>>> (Intercept)           -1.1688029 0.15189536 514  -7.694790    0.0000
>>> areatvedestrand -0.9943160 0.06490892 283  -15.318635  0.0000
>>> tl                         -0.0034115 0.00308169 283  -1.107031    0.2692
>>> factor(month2)7 -0.2242556 0.04074810 514  -5.503462     0.0000
>>> factor(month2)8 -0.1269165 0.04245662 514  -2.989322     0.0029
>>>
>>> Correlation:
>>>                             (Intr)   artvds   tl         fc(2)7
>>> areatvedestrand -0.224
>>> tl                         -0.943  0.019
>>> factor(month2)7 -0.121  0.003 -0.011
>>> factor(month2)8 -0.113 -0.006 -0.011  0.475
>>>
>>> Standardized Within-Group Residuals:
>>>        Min         Q1        Med         Q3        Max
>>> -2.7792032 -0.5127146 -0.1031226  0.3935509  4.3119462
>>>
>>> Number of Observations: 802
>>> Number of Groups: 286
>>>
>>> The estimation of Repeatability from this model would be
>>> 0.46/(0.46+0.47)=0.485
>>> However if I extract the residuals from this model
>>> res=resid(lme,type="normalized") and do acf(residuals) the plot shows a
>>> high autocorrelation in the first 15 lags. So I tried the following:
>>>
>>> MODEL 2: same model including an autocorrelation term
>>>
>>> lme3=update(lme1,correlation=corAR1(form=~month2))
>>>
>>> > summary(lme)
>>> Linear mixed-effects model fit by REML
>>>  Data: hrm3
>>>        AIC     BIC    logLik
>>>   1461.013 1498.46 -722.5066
>>>
>>> Random effects:
>>>  Formula: ~1 | fish
>>>               (Intercept)       Residual
>>> StdDev: 0.0005272246 0.6819065
>>>
>>> Correlation Structure: ARMA(1,0)
>>>  Formula: ~month2 | fish
>>>  Parameter estimate(s):
>>>      Phi1
>>> 0.6097222
>>> Fixed effects: loghr ~ area + tl + factor(month2)
>>>                             Value         Std.Error      DF    t-value
>>>   p-value
>>> (Intercept)           -1.1584548 0.15740075 514  -7.359906  0.0000
>>> areatvedestrand -1.0019165 0.06730508 283  -14.886194 0.0000
>>> tl                         -0.0035497 0.00319449 283  -1.111192   0.2674
>>> factor(month2)7 -0.2212453 0.03628563 514  -6.097327   0.0000
>>> factor(month2)8 -0.1275377 0.04735955 514  -2.692968   0.0073
>>>  Correlation:
>>>                             (Intr) artvds tl     fc(2)7
>>> areatvedestrand -0.227
>>> tl                         -0.944  0.022
>>> factor(month2)7 -0.104  0.003 -0.009
>>> factor(month2)8 -0.124 -0.005 -0.013  0.611
>>>
>>> Standardized Within-Group Residuals:
>>>         Min          Q1         Med          Q3         Max
>>> -2.62204450 -0.68663130 -0.08503995  0.58177543  3.79290975
>>>
>>> Number of Observations: 802
>>> Number of Groups: 286
>>>
>>> If I plot acf(residual) now the plot looks much nicer (almost all the
>>> autocorrelation has been corrected)
>>>
>>> As you can see, the fact of including the autocorrelation term
>>> dramatically
>>> reduces the random variance from 0.46 to 0.0005, which in turn reduces
>>> the
>>> Repeatability from 0.485 to 5.98e-07.
>>>
>>> NOW: if repeat this exercise working at a daily scale (90 replicates per
>>> ID), the reduction in random variance and repeatability is much smaller
>>> (from 0.46 to 0.16), but very noticeable still.
>>>
>>> My questions are:
>>> - How should I interpret this? Is the autocorrelation term in model 2
>>> taking most of the random variance previously explained by the individual
>>> ID in model 1?
>>> - Model 2 yields a very low value of repeatability, however model
>>> selection
>>> is telling me than the random effect (individual ID) has to be included
>>> in
>>> the model. I interpret this as the repeatability being significantly
>>> different from zero, even it is really low. Correct?
>>> - With a different trait, I observe the same reduction after including a
>>> "weights" argument. And with another trait, I observe a similar reduction
>>> when I pass from an autocorrelation structure corAR1 to a correlation
>>> structure corARMA (2,2). Any thought?
>>> - Could I say that including explanatory variables (fixed part of the
>>> model) will reduce the residual variance, and including terms in the
>>> random
>>> part of the model (random factors, autocorrelations terms, weights, ...)
>>> will reduce the random variance?
>>>
>>> Many thanks in advance,
>>>
>>> David
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu May  7 10:12:29 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 7 May 2015 10:12:29 +0200
Subject: [R-sig-ME] question about gls in nlme
In-Reply-To: <CAHz+bWZVtd_mbhvWsU4+-2rqsFrg+fPs7Z8u7u1iGPgz1HBQFQ@mail.gmail.com>
References: <CAHz+bWZVtd_mbhvWsU4+-2rqsFrg+fPs7Z8u7u1iGPgz1HBQFQ@mail.gmail.com>
Message-ID: <CAJuCY5xYuHJc=YKGfs3KKZkyYHSvGDP1riGAz-HgqS+Pqr7NNA@mail.gmail.com>

Dear Mark,

It depends on which residuals you extract from the model. See the type
argument of residuals.gls()

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-06 19:57 GMT+02:00 Mark Leeds <markleeds2 at gmail.com>:

> Hi: I've looked around for a long while and I can't figure out something
> about
> the gls function in the nlme package. If someone wouldn't mind explaining
> it or knows of a good reference ( I have pinheiro and bates but it's 10
> states away because I lent it to someone ) that explains the following,
> that would be fine also.
>
> Suppose I am estimating a  2 predictor regression model with AR(1) errors.
>
> So, the mode isl y_t = B_0 + B_1*x_t + B2*y_2 +  u_t         t = 1,..... T
>
> where u_t =  phi*u_t-1 + epsilon_t
>
> where var(epsilon_t) is sigma^2.
>
> My first question is:
>
> When one runs the function gls, I can't tell what the residuals represent.
> In other words, are they
>
> A) the residuals associated with the transformed regression where the error
> term is epsilon_t  with variance(sigma^2).
>
> or
>
> B) the residuals associated with the untransformed model written above
> so with covariance matrix V and elements V_ij =   phi^(|j-i| * sigma^2 /
> (1-phi^2).
>
> My second question is:
>
> Whether  the result represents A or B, is there a way to use a gls related
>  function to convert back and forth between the two  ? Thanks a lot for any
> wisdom references etc. I've looked all over and can't find much related to
> my question.
>
> The other possible  option is to consider using the systemfit package but I
> have a feeling there must be a way to do this using gls.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jakob.gaehrken at uni-kassel.de  Thu May  7 15:02:09 2015
From: jakob.gaehrken at uni-kassel.de (=?UTF-8?B?SmFrb2IgR8OkaHJrZW4=?=)
Date: Thu, 07 May 2015 15:02:09 +0200
Subject: [R-sig-ME] Number of Iterations lme4
Message-ID: <554B6251.8000503@uni-kassel.de>

Hello,
I was asked to forward my question to this mailing list. I would be glad 
to get some hints regarding my questions below:

I am an quit inexperienced R user but I try hard to learn fast. My 
problem is that while I try to run lme4 with the model:
model1 = glmer(Survival ~ Kohorte+KJ+Saison+KAE+(1|ID), family = 
binomial(link = "logit"), 
data=phenos,control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=1e6)))
I always get the warning :

1:In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
    Model failed to converge with max|grad| = 0.75662 (tol = 0.001, component 2)
2:In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
    Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

I know that my data has the promblem that the binary response variable has a skewed distribution (1.933 "0" vs. 68.031 "1"). And that this could be the reason for the converging problem and that I might look for alternatives.(btw. do you consider some kind of minimum proportion for the "minor observation" in this case "0" (2.8%) when you fit a model e.g. for diseases with low incidence)
But beside of the reason for the converging problem I am wondering because I tried to change the number of iterations using  : control=glmerControl(optCtrl=list(maxfun=...)).The used time which leads to the error message and also the  ...with max|grad| = 0.75662...are  always the same - no matter what value for maxfun I choose. So I am not sure how to control the number of iterations that are really done by R and whether the amount changes with different defined maxfun values in my case.

Thank you for your time and looking forward hearing from you,

Jakob G?hrken



	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu May  7 16:10:35 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 7 May 2015 16:10:35 +0200
Subject: [R-sig-ME] Number of Iterations lme4
In-Reply-To: <554B6251.8000503@uni-kassel.de>
References: <554B6251.8000503@uni-kassel.de>
Message-ID: <CAJuCY5yu5zxGfRNcvvV6SDm3H7Yd_iPv41wudFacBg9WcJ2EEQ@mail.gmail.com>

Dear Jacob,

This might be a problem of (quasi)-complete separation. You have probably
ID's with only 0 values.
Another possibility is that the warning is a false positive. Have you tried
other optimizers? See ?glmerControl() for more information.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-07 15:02 GMT+02:00 Jakob G?hrken <jakob.gaehrken at uni-kassel.de>:

> Hello,
> I was asked to forward my question to this mailing list. I would be glad
> to get some hints regarding my questions below:
>
> I am an quit inexperienced R user but I try hard to learn fast. My
> problem is that while I try to run lme4 with the model:
> model1 = glmer(Survival ~ Kohorte+KJ+Saison+KAE+(1|ID), family =
> binomial(link = "logit"),
>
> data=phenos,control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=1e6)))
> I always get the warning :
>
> 1:In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>     Model failed to converge with max|grad| = 0.75662 (tol = 0.001,
> component 2)
> 2:In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>     Model failed to converge: degenerate  Hessian with 1 negative
> eigenvalues
>
> I know that my data has the promblem that the binary response variable has
> a skewed distribution (1.933 "0" vs. 68.031 "1"). And that this could be
> the reason for the converging problem and that I might look for
> alternatives.(btw. do you consider some kind of minimum proportion for the
> "minor observation" in this case "0" (2.8%) when you fit a model e.g. for
> diseases with low incidence)
> But beside of the reason for the converging problem I am wondering because
> I tried to change the number of iterations using  :
> control=glmerControl(optCtrl=list(maxfun=...)).The used time which leads to
> the error message and also the  ...with max|grad| = 0.75662...are  always
> the same - no matter what value for maxfun I choose. So I am not sure how
> to control the number of iterations that are really done by R and whether
> the amount changes with different defined maxfun values in my case.
>
> Thank you for your time and looking forward hearing from you,
>
> Jakob G?hrken
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From steve.bellan at gmail.com  Thu May  7 17:31:52 2015
From: steve.bellan at gmail.com (Steve Bellan)
Date: Thu, 7 May 2015 10:31:52 -0500
Subject: [R-sig-ME] GAMM big data (70K rand effects) guidance
Message-ID: <C0B2A66D-BB13-4A55-8B40-19E7B157898E@gmail.com>

Hi all,

I am working with an patient data base of 70K HIV-infected individuals followed over time since treatment initiation, with 500K total observations that include a laboratory measurement (CD4 cell count?an indicator of immunocompetence). I?m trying to use GAMM to model the CD4 trajectory as a function of CD4 at treatment initiation (i.e. y-intercept) and other covariate classes (sex, age, etc). Thus, far I?ve struggled to fit GAMMs to the entire data set.

I?m using a gaussian link function to log(CD4+1) for now. With gamm, this gives the following:

> form <- as.formula('log(cd4 + 1) ~ sex + s(ayfu, by = CD4_cat_init, bs=?tp")')
> print(system.time(tg1 <- gamm(form, data = nd, order.groups=F, family=gaussian, random=list(PatientID=~1))))

where ayfu is time since treatment initiation and CD4_cat_init is the CD4 count at treatment initiation broken into 5 categories.

I ran that on a large memory (1TB) node on our HPC cluster and, after 12 hours using between 300-500 GB of memory, it crashed:

> Error in print(system.time(tg1 <- gamm(form, data = nd, order.groups = F,  : 
>   error in evaluating the argument 'x' in selecting a method for function 'print': Error in cbind(X1, X[[i]][, j] * X0) : 
>   long vectors not supported yet: bind.c:1301
> Calls: system.time ... extract.lme.cov2 -> cbind -> tensor.prod.model.matrix -> cbind

Google tells me that this has to do with limits on R?s array size. But I don?t totally follow how that is interacting with the gamm call.

I?m now trying out cubic regression splines (bs=?cs? instead of ?tp?) with gamm and also with gamm4. Running the code on subsets of the data (1K individuals) suggest only a mild improvement by using ?cs? for both packages, and a *decrease* in speed using gamm4 instead of gamm. The latter surprises me since I had thought that gamm4 was meant to be faster when the # of random effects was large.

Eventually I?d like to use smoother-by-group interactions other than the CD4_cat_init (i.e. sex, age etc) and test whether trajectories are significantly different between covariate classes using AIC. It would also be nice to somehow characterize how variable individuals? trends are within a covariate class, though I?m not exactly sure what?s the best way to do that.

But until I can get just one of these models to fit, these goals seem like a long shot. I?ve struggled to find much documentation online regarding fitting GAMMs to such large data sets, particularly one with so many random effects. Hence the trial and error exploration of different splines & packages. Does anyone have more concrete guidance on how to approach this problem or helpful documentation? Help much appreciated!

Thanks,

Steve

Steve Bellan, PhD, MPH
Post-doctoral Researcher
Lauren Ancel Meyers Research Group
Center for Computational Biology and Bioinformatics
University of Texas at Austin
http://www.bio.utexas.edu/research/meyers/steve_bellan/ <http://www.bio.utexas.edu/research/meyers/steve_bellan/>

	[[alternative HTML version deleted]]


From pharr011 at gold.ac.uk  Thu May  7 19:13:54 2015
From: pharr011 at gold.ac.uk (Peter Harrison)
Date: Thu, 7 May 2015 17:13:54 +0000
Subject: [R-sig-ME] Logistic modelling with guessing parameter
Message-ID: <VI1PR04MB1295D859341912D075CBD722AFDF0@VI1PR04MB1295.eurprd04.prod.outlook.com>

Hello everyone,

I'm currently modelling response data for a musical error detection experiment. Participants' responses can either be correct (1) or incorrect (0); the difficulty of the question is predicted by a number of factors, including accuracy (accurate performance -> errors are difficult to detect) and musical piece ("audio_name").

The model I'm fitting is similar to a 3-PL IRT model, with a constrained guessing parameter of 0.5 (i.e. the most difficult questions should be answered with a 50% success rate). However, instead of the normal conception of item difficulty, probability of correct response is given by a linear combination of difficulty-related predictors (such as accuracy and audio_name). Therefore:

probability of correct response = 0.5 + 0.5 / (1 + exp(predictors))

where predictors = e.g. a*accuracy + b*audio_name + c (but with audio_name dummy coded, with different b for each level of audio_name).

I've been using a script kindly posted by Ken Knoblauch back in 2010 (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/004531.html) to achieve this using lme4, simply changing a few terms to keep it up-to-date with current package versions (see bottom of message for the script). It seems to work fine with "accuracy" as a fixed effect and "p_ID" as a random effect. However, I want to add "audio_name" as a fixed effect, i.e. responses ~ accuracy + audio_name + (1|p_ID). But when I do this, I get the following error message: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate.

I'm not sure what this error message means, but have been assuming it is talking about a convergence problem. I've tried various things to fix it, including control=glmerControl(optimizer="bobyqa"), control=glmerControl(optimizer="Nelder_Mead"), and nAgQ=3, but none of these have worked.

Would anyone be able to help me with this error message, and what to do about it?

Thanks so much!
Peter


Key to data file:

accuracy = accuracy of the music clip (higher accuracy -> question is more difficult) = continuous variable
audio_name = musical piece played = categorical variable (27 levels, coded with text strings)
p_ID = participant ID = categorical variable (229 levels, coded 1:229)
behind_beat = whether clip was behind the beat or not = dichotomous (1 = TRUE, 0 = FALSE)

Script:

library(lme4)
data <- read.csv("https://dl.dropboxusercontent.com/s/szq2e2sxwfsuxo6/data.csv", header = TRUE)

mafc.logit <- function (.m = 2)
{
  .m <- as.integer(.m)
  if (.m < 2)
    stop(".m must be an integer > 1")
  linkfun <- function(mu) {
    mu <- pmax(mu, 1/.m + .Machine$double.eps)
    qlogis((.m * mu - 1)/(.m - 1))
  }
  linkinv <- function(eta) {
    1/.m + (.m - 1)/.m * binomial()$linkinv(eta)
  }
  mu.eta <- function(eta) ((.m - 1)/.m) * binomial()$mu.eta(eta)
  valideta <- function(eta) TRUE
  link <- paste("mafc.logit(", .m, ")", sep = "")
  structure(list(linkfun = linkfun, linkinv = linkinv, mu.eta = mu.eta,
                 valideta = valideta, name = link), class = "link-glm")
}

mod1 <- glmer(responses ~ accuracy + (1|p_ID), family = binomial(mafc.logit(2)), data=data)
summary(mod1)

	[[alternative HTML version deleted]]


From carbrae at gmail.com  Thu May  7 19:28:08 2015
From: carbrae at gmail.com (Bradley Carlson)
Date: Thu, 7 May 2015 13:28:08 -0400
Subject: [R-sig-ME] REML vs ML in lmerTest
In-Reply-To: <BLUPR04MB80353FF58A835605061B86CEAD10@BLUPR04MB803.namprd04.prod.outlook.com>
References: <CAF37_NfuoeDYYbp25pugtPwspv_SfpDLB4pQPq_5Hp4c6nddGg@mail.gmail.com>
	<BLUPR04MB803EFE7ED597171390AD6F3EAD10@BLUPR04MB803.namprd04.prod.outlook.com>
	<CAF37_NfytaKAo61-nPfFJva8fn_9938MT412OLMTO3JukU3LQg@mail.gmail.com>
	<BLUPR04MB80353FF58A835605061B86CEAD10@BLUPR04MB803.namprd04.prod.outlook.com>
Message-ID: <CAF37_Nda4KH2YiDMDKYRC+RC6b=VZLWWN7vZjeSAFkKV318oRA@mail.gmail.com>

Thanks for taking a stab at it. Unfortunately, refit in lmerTest anova
doesn't work. Anyone else have ideas about what's going on??

On Tue, May 5, 2015 at 2:41 PM, Daniel Wright <Daniel.Wright at act.org> wrote:

>  If the anova with lmerTest works like the method for merMod objects, it
> will refit (but has the option refit=TRUE). See
>
>
>
> http://127.0.0.1:25203/library/lme4/html/merMod-class.html
>
>
>
> I don't use the lmerTest package, so hopefully another reader with
> knowledge of it can respond if it works differently.
>
>
>
> *From:* Bradley Carlson [mailto:carbrae at gmail.com]
> *Sent:* Tuesday, May 05, 2015 1:34 PM
> *To:* Daniel Wright
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] REML vs ML in lmerTest
>
>
>
> The package is lmerTest, the function is anova within that package. I
> can't find anyway to determine whether it is re-estimating the model (it
> doesn't report anything about REML or ML). If it was re-estimating, though,
> then the sums of squares shouldn't be different between the two - but they
> are.
>
>
>
> On Tue, May 5, 2015 at 2:19 PM, Daniel Wright <Daniel.Wright at act.org>
> wrote:
>
> Check if the lmerTest function re-estimates the model with ML.  Not sure
> what lmerTest function you are using (which package?).
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Bradley Carlson
> Sent: Tuesday, May 05, 2015 1:15 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] REML vs ML in lmerTest
>
> Hi everyone,
>
> I'm a little confused about the use REML and ML. I fit models in lmer,
> which were pretty straightforward (a few continuous and a few nominal
> predictors, plus random intercepts for clusters of data). I tested the
> fixed effects using the lmerTest anova function with Kenward-Roger df (I
> have no interest in testing random effect significance). I get the same F
> values, df, and p values regardless of whether the models were fit with
> REML or ML, but the actual sums of squares in the anova output differ
> modestly. Given that it didn't matter at all for the results, it doesn't
> seem I should particularly care whether I use REML and ML in the lmer. But,
> I want to report which I used.
>
> So my questions:
>
> -Why do I get the same statistical values except for SS with REML and ML?
> -Which would be more appropriate - REML or ML? I'm thinking REML because I
> have an unbalanced sample sizes for each level of the random effect (based
> on Bolker et al. 2008), but I wanted to double check that this makes sense.
>
> Thank you!
> Brad
>
> --
>
> Bradley Evan Carlson
> Assistant Professor of Biology
> Wabash College, Crawfordsville IN
>
> Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
> Website: https://sites.google.com/site/bradleyecarlson/home
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
> --
>
>
> Bradley Evan Carlson
>
> Assistant Professor of Biology
>
> Wabash College, Crawfordsville IN
>
>
>
> Email: carlsonb at wabash.edu <+carlsonb at wabash.edu>
>
> Website: https://sites.google.com/site/bradleyecarlson/home
>



-- 

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN

Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
Website: https://sites.google.com/site/bradleyecarlson/home

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu May  7 21:17:30 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 07 May 2015 15:17:30 -0400
Subject: [R-sig-ME] Logistic modelling with guessing parameter
In-Reply-To: <VI1PR04MB1295D859341912D075CBD722AFDF0@VI1PR04MB1295.eurprd04.prod.outlook.com>
References: <VI1PR04MB1295D859341912D075CBD722AFDF0@VI1PR04MB1295.eurprd04.prod.outlook.com>
Message-ID: <554BBA4A.9000602@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


  Quick possibility: PIRLS failures are often a symptom of the
algorithm hitting a non-finite (infinite/NaN) value internally (this
should be better instrumented).  I would try instrumenting your
link/inverse-link/dmu.eta functions to have them warn/stop if they
would be returning a non-finite value ...



On 15-05-07 01:13 PM, Peter Harrison wrote:
> Hello everyone,
> 
> I'm currently modelling response data for a musical error detection
> experiment. Participants' responses can either be correct (1) or
> incorrect (0); the difficulty of the question is predicted by a
> number of factors, including accuracy (accurate performance ->
> errors are difficult to detect) and musical piece ("audio_name").
> 
> The model I'm fitting is similar to a 3-PL IRT model, with a
> constrained guessing parameter of 0.5 (i.e. the most difficult
> questions should be answered with a 50% success rate). However,
> instead of the normal conception of item difficulty, probability of
> correct response is given by a linear combination of
> difficulty-related predictors (such as accuracy and audio_name).
> Therefore:
> 
> probability of correct response = 0.5 + 0.5 / (1 +
> exp(predictors))
> 
> where predictors = e.g. a*accuracy + b*audio_name + c (but with
> audio_name dummy coded, with different b for each level of
> audio_name).
> 
> I've been using a script kindly posted by Ken Knoblauch back in
> 2010
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/004531.html)
> to achieve this using lme4, simply changing a few terms to keep it
> up-to-date with current package versions (see bottom of message for
> the script). It seems to work fine with "accuracy" as a fixed
> effect and "p_ID" as a random effect. However, I want to add
> "audio_name" as a fixed effect, i.e. responses ~ accuracy +
> audio_name + (1|p_ID). But when I do this, I get the following
> error message: (maxstephalfit) PIRLS step-halvings failed to reduce
> deviance in pwrssUpdate.
> 
> I'm not sure what this error message means, but have been assuming
> it is talking about a convergence problem. I've tried various
> things to fix it, including
> control=glmerControl(optimizer="bobyqa"),
> control=glmerControl(optimizer="Nelder_Mead"), and nAgQ=3, but none
> of these have worked.
> 
> Would anyone be able to help me with this error message, and what
> to do about it?
> 
> Thanks so much! Peter
> 
> 
> Key to data file:
> 
> accuracy = accuracy of the music clip (higher accuracy -> question
> is more difficult) = continuous variable audio_name = musical piece
> played = categorical variable (27 levels, coded with text strings) 
> p_ID = participant ID = categorical variable (229 levels, coded
> 1:229) behind_beat = whether clip was behind the beat or not =
> dichotomous (1 = TRUE, 0 = FALSE)
> 
> Script:
> 
> library(lme4) data <-
> read.csv("https://dl.dropboxusercontent.com/s/szq2e2sxwfsuxo6/data.csv",
> header = TRUE)
> 
> mafc.logit <- function (.m = 2) { .m <- as.integer(.m) if (.m < 2) 
> stop(".m must be an integer > 1") linkfun <- function(mu) { mu <-
> pmax(mu, 1/.m + .Machine$double.eps) qlogis((.m * mu - 1)/(.m -
> 1)) } linkinv <- function(eta) { 1/.m + (.m - 1)/.m *
> binomial()$linkinv(eta) } mu.eta <- function(eta) ((.m - 1)/.m) *
> binomial()$mu.eta(eta) valideta <- function(eta) TRUE link <-
> paste("mafc.logit(", .m, ")", sep = "") structure(list(linkfun =
> linkfun, linkinv = linkinv, mu.eta = mu.eta, valideta = valideta,
> name = link), class = "link-glm") }
> 
> mod1 <- glmer(responses ~ accuracy + (1|p_ID), family =
> binomial(mafc.logit(2)), data=data) summary(mod1)
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVS7pJAAoJEOCV5YRblxUHovcIAMYJkVuhG3eY6fCp8gI85feb
KLDB5K30K+LEF6duOZq2RTOqcLenQUJOrTPRzKpq/t6Hz6w+D0YAVA1ojuHI7/25
+KJrU31ndu2YGW7KB8YGj3BJ6Yn4gGMPD3MIHE0cmKaWYLWZ/+oTjOFhwYx1hqhU
erRaNdzvb4kT3m3YbAEluTuijTtHaMaFisjZiyBZ85FJ3MTc6rvicEaLTRyzul2l
Oduk8eNZvP0AXTIpvKP2SetT7gygsjq1+TAgi41XGvWWvXqqGA0PHC7colXEuAgh
OZKCn2aEb7YowsYCQuQ7In8o0S0UQU2Fzhfw/dewE9uguBXYYtLiOQYfHXK4qTE=
=7VFS
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Thu May  7 21:37:54 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 07 May 2015 15:37:54 -0400
Subject: [R-sig-ME] Logistic modelling with guessing parameter
In-Reply-To: <VI1PR04MB1295D859341912D075CBD722AFDF0@VI1PR04MB1295.eurprd04.prod.outlook.com>
References: <VI1PR04MB1295D859341912D075CBD722AFDF0@VI1PR04MB1295.eurprd04.prod.outlook.com>
Message-ID: <554BBF12.4040507@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  PS I had a closer look and most of your individual groups seem to
show complete separation ... this is generally going to be a problem ...

making audio_name a *random* effect seems to work OK.  You could also
look into doing some shrinkage/penalization via blmer ...


library(plyr)
sumvals <- ddply(data,c("audio_name","accuracy"),
      summarise,
      responses=mean(responses))

library(ggplot2); theme_set(theme_bw())
ggplot(data,aes(accuracy,responses,colour=audio_name))+
    stat_sum()+geom_smooth(method="glm",
                           family = binomial(mafc.logit(2)),
                           se=FALSE)+
        geom_point(data=sumvals,alpha=0.25)+
        geom_line(data=sumvals,alpha=0.25)
m1 <- lme4::lmList(response~accuracy|audio_name,
                   family = binomial(mafc.logit(2)),
                   data=data)

debug(lme4::lmList)
ff2 <- function(dat, formula=responses~accuracy) {
    data <- as.data.frame(dat)
    glm(formula=formula, family=binomial(mafc.logit(2)), data)
}
ss <- split(data,data$audio_name)
## 4: OK
sapply(ss,function(d) {
           !any(coef(ff2(d))>1e6)
       })
ff2(ss[[6]])
mod1 <- glmer(responses ~ accuracy + (1|p_ID),
              family = binomial(mafc.logit(2)), data=data)
mod2 <- update(mod1,. ~. + audio_name)
mod3 <- update(mod1,. ~. + (1|audio_name))
summary(mod1)



On 15-05-07 01:13 PM, Peter Harrison wrote:
> Hello everyone,
> 
> I'm currently modelling response data for a musical error detection
> experiment. Participants' responses can either be correct (1) or
> incorrect (0); the difficulty of the question is predicted by a
> number of factors, including accuracy (accurate performance ->
> errors are difficult to detect) and musical piece ("audio_name").
> 
> The model I'm fitting is similar to a 3-PL IRT model, with a
> constrained guessing parameter of 0.5 (i.e. the most difficult
> questions should be answered with a 50% success rate). However,
> instead of the normal conception of item difficulty, probability of
> correct response is given by a linear combination of
> difficulty-related predictors (such as accuracy and audio_name).
> Therefore:
> 
> probability of correct response = 0.5 + 0.5 / (1 +
> exp(predictors))
> 
> where predictors = e.g. a*accuracy + b*audio_name + c (but with
> audio_name dummy coded, with different b for each level of
> audio_name).
> 
> I've been using a script kindly posted by Ken Knoblauch back in
> 2010
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/004531.html)
> to achieve this using lme4, simply changing a few terms to keep it
> up-to-date with current package versions (see bottom of message for
> the script). It seems to work fine with "accuracy" as a fixed
> effect and "p_ID" as a random effect. However, I want to add
> "audio_name" as a fixed effect, i.e. responses ~ accuracy +
> audio_name + (1|p_ID). But when I do this, I get the following
> error message: (maxstephalfit) PIRLS step-halvings failed to reduce
> deviance in pwrssUpdate.
> 
> I'm not sure what this error message means, but have been assuming
> it is talking about a convergence problem. I've tried various
> things to fix it, including
> control=glmerControl(optimizer="bobyqa"),
> control=glmerControl(optimizer="Nelder_Mead"), and nAgQ=3, but none
> of these have worked.
> 
> Would anyone be able to help me with this error message, and what
> to do about it?
> 
> Thanks so much! Peter
> 
> 
> Key to data file:
> 
> accuracy = accuracy of the music clip (higher accuracy -> question
> is more difficult) = continuous variable audio_name = musical piece
> played = categorical variable (27 levels, coded with text strings) 
> p_ID = participant ID = categorical variable (229 levels, coded
> 1:229) behind_beat = whether clip was behind the beat or not =
> dichotomous (1 = TRUE, 0 = FALSE)
> 
> Script:
> 
> library(lme4) data <-
> read.csv("https://dl.dropboxusercontent.com/s/szq2e2sxwfsuxo6/data.csv",
> header = TRUE)
> 
> mafc.logit <- function (.m = 2) { .m <- as.integer(.m) if (.m < 2) 
> stop(".m must be an integer > 1") linkfun <- function(mu) { mu <-
> pmax(mu, 1/.m + .Machine$double.eps) qlogis((.m * mu - 1)/(.m -
> 1)) } linkinv <- function(eta) { 1/.m + (.m - 1)/.m *
> binomial()$linkinv(eta) } mu.eta <- function(eta) ((.m - 1)/.m) *
> binomial()$mu.eta(eta) valideta <- function(eta) TRUE link <-
> paste("mafc.logit(", .m, ")", sep = "") structure(list(linkfun =
> linkfun, linkinv = linkinv, mu.eta = mu.eta, valideta = valideta,
> name = link), class = "link-glm") }
> 
> mod1 <- glmer(responses ~ accuracy + (1|p_ID), family =
> binomial(mafc.logit(2)), data=data) summary(mod1)
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVS78SAAoJEOCV5YRblxUHt2QIAK5g3BvoQxKO3RLO9wwOFiU8
eIz77IpkDDMt+uec6dLp30I1/HlwVUuW2zlpK3mkEy4kAWF7YU8m4BtztvvLrDPX
mHfSH6oEgCqQHRbQwvH1FyqKt2Th7JW3pdfAsDfNKa0ctIwnK7qNmJJSKEG/jWtm
Z2ERNit8U2kHY0eEPhBwjPMBjxRqsR2gBncckqq0KntWw8l8QqBFJM3+qhPzLPB0
ftkA2tJfDkIZ0dqPTHqdeGyzW1IK84Pr8HObDiRBUMOgmS0UNhBXQWYutjCz6pwE
zuFzQoXvtvVBVVVPTgO8lOacX4IEgydYFncKh3L4wM1AdmJx73Wg8wi4eppXtuI=
=vRQM
-----END PGP SIGNATURE-----


From ken.knoblauch at inserm.fr  Fri May  8 00:28:38 2015
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Thu, 7 May 2015 22:28:38 +0000 (UTC)
Subject: [R-sig-ME] Logistic modelling with guessing parameter
References: <VI1PR04MB1295D859341912D075CBD722AFDF0@VI1PR04MB1295.eurprd04.prod.outlook.com>
Message-ID: <loom.20150508T002355-827@post.gmane.org>

Peter Harrison <pharr011 at ...> writes:
<< snip >>
> I've been using a script kindly posted by Ken Knoblauch 
back in 2010
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models
/2010q4/004531.html) to achieve this using
> (1|p_ID). But when I do this, I get the following 
error message: (maxstephalfit) PIRLS step-halvings
> failed to reduce deviance in pwrssUpdate.


You ought to be able to use the link directly from 
the psyphy package.  A lot has changed with lme4
and a little with psyphy so that the modification from
then isn't necessary.

When I try your problem, I get
library(lme4)
library(psyphy)
data <- read.csv("https://dl.dropboxusercontent.com/
s/szq2e2sxwfsuxo6/data.csv", header = TRUE)
mod1 <- glmer(responses ~ accuracy + (1|p_ID), 
family = binomial(mafc.logit(2)), data=data)
summary(mod1)
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( mafc.logit(2) )
Formula: responses ~ accuracy + (1 | p_ID)
   Data: data

     AIC      BIC   logLik deviance df.resid 
  6742.6   6762.8  -3368.3   6736.6     6180 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.9571 -1.1363  0.4520  0.6233  0.9299 

Random effects:
 Groups Name        Variance Std.Dev.
 p_ID   (Intercept) 0.4454   0.6674  
Number of obs: 6183, groups:  p_ID, 229

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   4.1656     0.2771   15.03   <2e-16 ***
accuracy     -5.6355     0.3772  -14.94   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
         (Intr)
accuracy -0.971

with no errors

> Thanks so much!
> Peter
> 



From Eike-Lena.Neuschulz at senckenberg.de  Thu May  7 16:20:44 2015
From: Eike-Lena.Neuschulz at senckenberg.de (Eike-Lena Neuschulz)
Date: Thu, 07 May 2015 16:20:44 +0200
Subject: [R-sig-ME] Including a correlation matrix with the metafor package
Message-ID: <554B90DC020000B000022FAB@snggwia.senckenberg.de>

Dear R mailing list,

I have a problem using the metafor package. I would like to include a spatial correlation matrix with the R argument. I get an error message about levels in the random effects that are not represented in the rows/columns of the distance matrix. However, when comparing column and row names of the matrix with the levels of the random effect, they seem to be identical. See the output below.

I very much appreciate any help. Thank you very much!
Best,
Eike Lena Neuschulz


> SMDpot = rma.mv(yi, vi, random =  ~ 1 |studyChr, 
+                 mods = ~ process  -1   , 
+                 R = list(studyChr = distMatModel), 
+                 data = SMD_big, method = "REML", 
+                 Rscale=FALSE)

Error in rma.mv(yi, vi, random = ~1 | studyChr, mods = ~process - 1, R = list(studyChr = distMatModel),  : 
  There are levels in 'studyChr' for which there are no rows/columns in the corresponding 'R' matrix.
> 
> 
> identical(row.names(distMatModel),levels(SMD_big$studyChr))
[1] TRUE
> identical(colnames(distMatModel),levels(SMD_big$studyChr))
[1] TRUE
>





>>>  07.05.15 12.01 Uhr >>>
Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Interpreting the ACME in mediation (Elizabeth Pasipanodya)
   2. Re: Including an autocorrelation term dramatically reduces
      random variance (lme) (Thierry Onkelinx)
   3. Re: question about gls in nlme (Thierry Onkelinx)


----------------------------------------------------------------------

Message: 1
Date: Wed, 6 May 2015 17:39:10 -0400
From: Elizabeth Pasipanodya 
To: "'r-sig-mixed-models at r-project.org'"
    
Subject: [R-sig-ME] Interpreting the ACME in mediation
Message-ID:
    <8DC1EA0EB7E3FD419D9B3BE76BD403867B15439C60 at razor.psych.udel.edu>
Content-Type: text/plain; charset="UTF-8"

Hello All,

I am a doctoral student working on data from a project focusing on couples coping with breast cancer. I have a mediation model with two simultaneous predictors, X1 (a positive relationship event) and  X2 (a relationship conflict), a mediator, M (a measure of intimacy), and an outcome Y (a measure of anxiety). X1 and X2 are both binary while M is continuous. Additionally, Y follows a count distribution. These variables are repeatedly measured for each individual across a number of days and, thus, I used the R packages lme4 and mediation to conduct my analyses.

I would like to double-check the meaning of the ACME. My understanding is that it represents the expected difference in the potential outcome when the mediator takes the value that it would have under the treatment condition compared to the control condition, while the treatment condition is held constant. Since I have a count outcome, should I report and interpret my ACME in the same units as my count outcome, as one would a rate ratio? That is, the ACME shall represent, in the logs of expected counts, the estimated average change in Y among the treatment group (those with a relationship event) as a result of M (intimacy) rather than directly from X1 (positive relationship event) and X2 (negative relationship event)?

For instance, based on the mediation output below, could I say something like the following --- on a day in which participants reported experiencing at least one negative relationship event, their estimated average change in anxiety due to changes in intimacy was 1.08 times (e^0.07485) that of those without a relationship conflict, controlling for the occurrence of positive relationship events?

> med2 <- mediate(apath, bpath, treat = "X2", mediator = "M", sims=5000, control.value = -0.5, treat.value = 0.5, dropobs=TRUE, method = "boot", boot.type = "bca")
> summary(med2)

Causal Mediation Analysis

Quasi-Bayesian Confidence Intervals

Mediator Groups: ID

Outcome Groups: ID

Output Based on Overall Averages Across Groups

                          Estimate 95% CI Lower 95% CI Upper p-value
ACME (control)             0.07890      0.02639      0.15107    0.00
ACME (treated)             0.07080      0.02354      0.13856    0.00
ADE (control)             -0.06645     -0.32283      0.17712    0.50
ADE (treated)             -0.07455     -0.35353      0.19218    0.50
Total Effect               0.00435     -0.25810      0.26892    0.97
Prop. Mediated (control)   0.16404    -11.47515     12.32893    0.97
Prop. Mediated (treated)   0.20262     -9.82740     10.87888    0.97
ACME (average)             0.07485      0.02583      0.14364    0.00
ADE (average)             -0.07050     -0.33728      0.18478    0.50
Prop. Mediated (average)   0.18333    -10.80037     11.56373    0.97

Sample Size Used: 602


Simulations: 5000

Best,

Elizabeth Pasipanodya


    [[alternative HTML version deleted]]



------------------------------

Message: 2
Date: Thu, 7 May 2015 10:08:24 +0200
From: Thierry Onkelinx 
To: David Villegas R?os ,
    "r-sig-mixed-models at r-project.org" 
Subject: Re: [R-sig-ME] Including an autocorrelation term dramatically
    reduces random variance (lme)
Message-ID:
    
Content-Type: text/plain; charset="UTF-8"

Dear David,

Please keep the mailing list in cc.

Correlation structures in nlme work on the residuals conditional on the
random effects. This implies that residuals from different levels of the
random effects are assumed to be independent (not correlated). Some of the
information can be described by both the random effect and the correlation
structure. In fact a random intercept is equivalent with a compound
symmetry correlation structure.

You have only 3 observations per random effect level. Then it is hard to
make the difference between the average of within the group (the random
effect) and the correlated residuals. In such cases the shrinkage kick in
very hard, reducing the random effect variance strongly.

IMHO you need choose a model than matches the design. The design dictates
that you need a random effect of fish. This leads to 3 per fish. 3
observations is not enough to estimate a AR1 correlation. Since you have
only 3 observations is doesn't make sense to look at 15 lags. You only have
2...

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-06 14:52 GMT+02:00 David Villegas R?os :

> Dear Thierry, thank you for your kind response.
>
> I understand that the residual variance must be different between the two
> models (with and without autocorrelation term). However, as you can see in
> my original post, the main change (3 orders of magnitude) is in the random
> variance (the between-individuals variance). I don't understand this. It
> seems that the autocorrelation term "eats" all the variance previously
> explained by the individual ID...
>
> In addition, it makes sense of course to leave always the random ID in the
> model. But to me, the only way to test if the random variance (and
> therefore the repeatability) is different from zero, is to test if the
> model needs the random ID (AIC, anova,...between model with and model
> without random ID). Of course I could calculate the CI for the
> repeatability using parametric bootstrapping, but this seems a difficult
> task for such complex models according to this previous post:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023385.html
>
> Best,
>
> David
>
>
>
> 2015-05-06 14:21 GMT+02:00 Thierry Onkelinx :
>
>> Dear David,
>>
>> A model without correlation has $\epsilon_t \sim N(0, \sigma_1)$
>> AR1 correlation implies: $\epsilon_t = \phi \epsilon_{t-1} + a_t$  with
>> $\a_t \sim N(0, \sigma_2)$ (see Pinheiro and Bates, 2000). So the residual
>> variance in this model is not the same thing. It makes sense that
>> $\sigma_2$ is smaller than $\sigma_1$.
>>
>> You should takes this into account when calculating the repeatability.
>>
>> Don't bother testing the need of ID. The design of your experiment
>> dictates the need to include it in the model.
>>
>> Weights affect the residual variance somewhat similar as a correlation
>> structure does. Have a look at the formulas in Pinheiro and Bates (2000).
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-05-06 10:07 GMT+02:00 David Villegas R?os :
>>
>>> Dear list,
>>>
>>> My dataset includes 285 individuals for which I have measured one trait
>>> over three months. The traits has been measured at two different time
>>> scales: monthly (maximum 3 replicates per fish) and daily (maximum 90
>>> replicates per fish). For one third of the fish, the trait was measured
>>> in
>>> 2012, for another third in 2013 and for the last third in 2014. But I
>>> measured always in the same three months: june, july and august.
>>>
>>> My objective is to use a mixed modelling approach to estimate
>>> repeatability
>>> (Vrandom/(Vrandom+Vresidual)) of this trait. I want to account for three
>>> fixed factors: area (two sites), total length (tl) and time. For
>>> comparative purposes, I want to do it for the two temporal scales, i.e.,
>>> one model using month and therefore three replicates per ID, and a
>>> different model using (julian) day and 90 replicates per ID.
>>>
>>> My attempts so far for the model with month:
>>>
>>> MODEL 1: Mixed model without autocorrelation term
>>>
>>>
>>> lme1=lme(loghr~area+tl+factor(month2),random=~1|fish,data=hrm3,method="REML")
>>>
>>> > summary(lme1)
>>> Linear mixed-effects model fit by REML
>>>  Data: hrm3
>>>        AIC      BIC    logLik
>>>   1498.771 1531.537 -742.3854
>>>
>>> Random effects:
>>>  Formula: ~1 | fish
>>>                 (Intercept) Residual
>>> StdDev:   0.4649101 0.4790193
>>>
>>> Fixed effects: loghr ~ area + tl + factor(month2)
>>>                             Value         Std.Error       DF    t-value
>>>    p-value
>>> (Intercept)           -1.1688029 0.15189536 514  -7.694790    0.0000
>>> areatvedestrand -0.9943160 0.06490892 283  -15.318635  0.0000
>>> tl                         -0.0034115 0.00308169 283  -1.107031    0.2692
>>> factor(month2)7 -0.2242556 0.04074810 514  -5.503462     0.0000
>>> factor(month2)8 -0.1269165 0.04245662 514  -2.989322     0.0029
>>>
>>> Correlation:
>>>                             (Intr)   artvds   tl         fc(2)7
>>> areatvedestrand -0.224
>>> tl                         -0.943  0.019
>>> factor(month2)7 -0.121  0.003 -0.011
>>> factor(month2)8 -0.113 -0.006 -0.011  0.475
>>>
>>> Standardized Within-Group Residuals:
>>>        Min         Q1        Med         Q3        Max
>>> -2.7792032 -0.5127146 -0.1031226  0.3935509  4.3119462
>>>
>>> Number of Observations: 802
>>> Number of Groups: 286
>>>
>>> The estimation of Repeatability from this model would be
>>> 0.46/(0.46+0.47)=0.485
>>> However if I extract the residuals from this model
>>> res=resid(lme,type="normalized") and do acf(residuals) the plot shows a
>>> high autocorrelation in the first 15 lags. So I tried the following:
>>>
>>> MODEL 2: same model including an autocorrelation term
>>>
>>> lme3=update(lme1,correlation=corAR1(form=~month2))
>>>
>>> > summary(lme)
>>> Linear mixed-effects model fit by REML
>>>  Data: hrm3
>>>        AIC     BIC    logLik
>>>   1461.013 1498.46 -722.5066
>>>
>>> Random effects:
>>>  Formula: ~1 | fish
>>>               (Intercept)       Residual
>>> StdDev: 0.0005272246 0.6819065
>>>
>>> Correlation Structure: ARMA(1,0)
>>>  Formula: ~month2 | fish
>>>  Parameter estimate(s):
>>>      Phi1
>>> 0.6097222
>>> Fixed effects: loghr ~ area + tl + factor(month2)
>>>                             Value         Std.Error      DF    t-value
>>>   p-value
>>> (Intercept)           -1.1584548 0.15740075 514  -7.359906  0.0000
>>> areatvedestrand -1.0019165 0.06730508 283  -14.886194 0.0000
>>> tl                         -0.0035497 0.00319449 283  -1.111192   0.2674
>>> factor(month2)7 -0.2212453 0.03628563 514  -6.097327   0.0000
>>> factor(month2)8 -0.1275377 0.04735955 514  -2.692968   0.0073
>>>  Correlation:
>>>                             (Intr) artvds tl     fc(2)7
>>> areatvedestrand -0.227
>>> tl                         -0.944  0.022
>>> factor(month2)7 -0.104  0.003 -0.009
>>> factor(month2)8 -0.124 -0.005 -0.013  0.611
>>>
>>> Standardized Within-Group Residuals:
>>>         Min          Q1         Med          Q3         Max
>>> -2.62204450 -0.68663130 -0.08503995  0.58177543  3.79290975
>>>
>>> Number of Observations: 802
>>> Number of Groups: 286
>>>
>>> If I plot acf(residual) now the plot looks much nicer (almost all the
>>> autocorrelation has been corrected)
>>>
>>> As you can see, the fact of including the autocorrelation term
>>> dramatically
>>> reduces the random variance from 0.46 to 0.0005, which in turn reduces
>>> the
>>> Repeatability from 0.485 to 5.98e-07.
>>>
>>> NOW: if repeat this exercise working at a daily scale (90 replicates per
>>> ID), the reduction in random variance and repeatability is much smaller
>>> (from 0.46 to 0.16), but very noticeable still.
>>>
>>> My questions are:
>>> - How should I interpret this? Is the autocorrelation term in model 2
>>> taking most of the random variance previously explained by the individual
>>> ID in model 1?
>>> - Model 2 yields a very low value of repeatability, however model
>>> selection
>>> is telling me than the random effect (individual ID) has to be included
>>> in
>>> the model. I interpret this as the repeatability being significantly
>>> different from zero, even it is really low. Correct?
>>> - With a different trait, I observe the same reduction after including a
>>> "weights" argument. And with another trait, I observe a similar reduction
>>> when I pass from an autocorrelation structure corAR1 to a correlation
>>> structure corARMA (2,2). Any thought?
>>> - Could I say that including explanatory variables (fixed part of the
>>> model) will reduce the residual variance, and including terms in the
>>> random
>>> part of the model (random factors, autocorrelations terms, weights, ...)
>>> will reduce the random variance?
>>>
>>> Many thanks in advance,
>>>
>>> David
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

    [[alternative HTML version deleted]]



------------------------------

Message: 3
Date: Thu, 7 May 2015 10:12:29 +0200
From: Thierry Onkelinx 
To: Mark Leeds 
Cc: "r-sig-mixed-models at r-project.org"
    
Subject: Re: [R-sig-ME] question about gls in nlme
Message-ID:
    
Content-Type: text/plain; charset="UTF-8"

Dear Mark,

It depends on which residuals you extract from the model. See the type
argument of residuals.gls()

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-06 19:57 GMT+02:00 Mark Leeds :

> Hi: I've looked around for a long while and I can't figure out something
> about
> the gls function in the nlme package. If someone wouldn't mind explaining
> it or knows of a good reference ( I have pinheiro and bates but it's 10
> states away because I lent it to someone ) that explains the following,
> that would be fine also.
>
> Suppose I am estimating a  2 predictor regression model with AR(1) errors.
>
> So, the mode isl y_t = B_0 + B_1*x_t + B2*y_2 +  u_t         t = 1,..... T
>
> where u_t =  phi*u_t-1 + epsilon_t
>
> where var(epsilon_t) is sigma^2.
>
> My first question is:
>
> When one runs the function gls, I can't tell what the residuals represent.
> In other words, are they
>
> A) the residuals associated with the transformed regression where the error
> term is epsilon_t  with variance(sigma^2).
>
> or
>
> B) the residuals associated with the untransformed model written above
> so with covariance matrix V and elements V_ij =   phi^(|j-i| * sigma^2 /
> (1-phi^2).
>
> My second question is:
>
> Whether  the result represents A or B, is there a way to use a gls related
>  function to convert back and forth between the two  ? Thanks a lot for any
> wisdom references etc. I've looked all over and can't find much related to
> my question.
>
> The other possible  option is to consider using the systemfit package but I
> have a feeling there must be a way to do this using gls.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

    [[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 101, Issue 8


From markleeds2 at gmail.com  Thu May  7 22:17:14 2015
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 7 May 2015 16:17:14 -0400
Subject: [R-sig-ME] another gls question
Message-ID: <CAHz+bWa8EC1XPGt5brLLpC-7oRh2s-VFkqXWdqUosyOc3xeFMA@mail.gmail.com>

Hi All. I'm sorry to bother this list again but I was able to extract the
orthogonal residuals
based on what Thierry suggested.  ( Thanks Thierry ).

If I understand correctly, the normalized residuals are the ones that come
out of
the transformed regression with independent error term which means that the
sums of square decomposition should hold when I use them.

Then. since the sums of squares decomposition should hold,  I would expect
to get the same values for r2= 1-(sse/sstot) and R2 = corr(predicted,
actual)^2.

Unfortunately, when I use these residuals, the SSTOT = SSREG + SSTOT
relation still
isn't holding. ( so of course the r^2 = R^2 relation isn't holding ).

 I've dputted the objects needed to run the code and the code below. Could
someone take a look and see if I'm doing anything dumb because,
theoretically, the decomposition should hold. It also could be that I'm
still not understanding the term "normalized" and what it implies about
where those residuals are coming from.

My other thought is that maybe ybar need to be modified by subtracting  the
theta*e_t-1 term
from it  since the residual is e_t now  rather than e_t + theta* e_t-1 ?

Thanks a lot.

#=================================================================

 dput(x)
structure(c(3200L, 3084L, 2864L, 2803L, 2755L, 2696L, 2646L,
2701L, 2654L, 2766L, 2832L, 2964L, 3041L, 3010L, 3018L, 3374L,
3545L, 3441L, 3456L, 3455L, 3503L, 3641L, 3721L, 3828L, 3831L,
3858L, 3925L, 3880L, 3935L, 3895L, 3840L, 3756L, 3669L, 3502L,
3145L, 2812L, 2586L, 2441L, 234L, 234L, 235L, 237L, 238L, 240L,
241L, 242L, 244L, 245L, 246L, 268L, 333L, 335L, 331L, 253L, 243L,
241L, 242L, 237L, 242L, 240L, 233L, 232L, 236L, 245L, 256L, 261L,
265L, 278L, 291L, 290L, 290L, 307L, 313L, 325L, 339L, 338L), .Dim = c(38L,
2L), .Dimnames = list(NULL, c("ewma.ret", "ewma.imbal")))
> dput(y)
c(77.1, 92.9, 98.3, 88.1, 79.4, 91, 100.4, 108.9, 123.6, 157.3,
154.3, 143.9, 147.5, 97.3, 76.6, 72.8, 68.9, 66.7, 55, 55, 55,
54.7, 47.9, 49, 44.4, 40.2, 43.8, 49.5, 50.4, 59.6, 72.4, 70.6,
82, 89.5, 101.3, 116.7, 115.2, 122.9)


gls.est <- gls(y~x, correlation=corARMA(q=1), method='ML')

ybar <- gls.est$coefficients[1]
residualsnorm <- residuals(gls.est, type = "normalized")

gls.est.ssenorm <- sum((residualsnorm)^2)
gls.est.ssreg <-sum((gls.est$fitted - ybar)^2)
gls.est.sstot <- sum((y - ybar)^2)

gls.est.rsquaredA <- 1 - (gls.est.ssenorm/gls.est.sstot)
gls.est.rsquaredB <- cor(y, gls.est$fitted)^2

cat("SSE + SSREG: ", gls.est.ssreg + gls.est.ssenorm, "\n")
cat("SSTOT: ", gls.est.sstot, "\n")

cat("GLS RSQUARED A : ", gls.est.rsquaredA, "\n")
cat("GLS RSQUARED B : ", gls.est.rsquaredB, "\n")

gls.sum <- summary(gls.est)
print(gls.sum)

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri May  8 09:27:05 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 8 May 2015 09:27:05 +0200
Subject: [R-sig-ME] another gls question
In-Reply-To: <CAHz+bWa8EC1XPGt5brLLpC-7oRh2s-VFkqXWdqUosyOc3xeFMA@mail.gmail.com>
References: <CAHz+bWa8EC1XPGt5brLLpC-7oRh2s-VFkqXWdqUosyOc3xeFMA@mail.gmail.com>
Message-ID: <CAJuCY5xPaqkSHH+AvFFDMKF+e9BijF3QhXr=QEXGFpX1jqTyRQ@mail.gmail.com>

Dear Mark,

SSTOT = SSREG + SSTOT is relation that holds with a lineair model with OLS.
I'm not sure if it still holds with gls.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-07 22:17 GMT+02:00 Mark Leeds <markleeds2 at gmail.com>:

> Hi All. I'm sorry to bother this list again but I was able to extract the
> orthogonal residuals
> based on what Thierry suggested.  ( Thanks Thierry ).
>
> If I understand correctly, the normalized residuals are the ones that come
> out of
> the transformed regression with independent error term which means that the
> sums of square decomposition should hold when I use them.
>
> Then. since the sums of squares decomposition should hold,  I would expect
> to get the same values for r2= 1-(sse/sstot) and R2 = corr(predicted,
> actual)^2.
>
> Unfortunately, when I use these residuals, the SSTOT = SSREG + SSTOT
> relation still
> isn't holding. ( so of course the r^2 = R^2 relation isn't holding ).
>
>  I've dputted the objects needed to run the code and the code below. Could
> someone take a look and see if I'm doing anything dumb because,
> theoretically, the decomposition should hold. It also could be that I'm
> still not understanding the term "normalized" and what it implies about
> where those residuals are coming from.
>
> My other thought is that maybe ybar need to be modified by subtracting  the
> theta*e_t-1 term
> from it  since the residual is e_t now  rather than e_t + theta* e_t-1 ?
>
> Thanks a lot.
>
> #=================================================================
>
>  dput(x)
> structure(c(3200L, 3084L, 2864L, 2803L, 2755L, 2696L, 2646L,
> 2701L, 2654L, 2766L, 2832L, 2964L, 3041L, 3010L, 3018L, 3374L,
> 3545L, 3441L, 3456L, 3455L, 3503L, 3641L, 3721L, 3828L, 3831L,
> 3858L, 3925L, 3880L, 3935L, 3895L, 3840L, 3756L, 3669L, 3502L,
> 3145L, 2812L, 2586L, 2441L, 234L, 234L, 235L, 237L, 238L, 240L,
> 241L, 242L, 244L, 245L, 246L, 268L, 333L, 335L, 331L, 253L, 243L,
> 241L, 242L, 237L, 242L, 240L, 233L, 232L, 236L, 245L, 256L, 261L,
> 265L, 278L, 291L, 290L, 290L, 307L, 313L, 325L, 339L, 338L), .Dim = c(38L,
> 2L), .Dimnames = list(NULL, c("ewma.ret", "ewma.imbal")))
> > dput(y)
> c(77.1, 92.9, 98.3, 88.1, 79.4, 91, 100.4, 108.9, 123.6, 157.3,
> 154.3, 143.9, 147.5, 97.3, 76.6, 72.8, 68.9, 66.7, 55, 55, 55,
> 54.7, 47.9, 49, 44.4, 40.2, 43.8, 49.5, 50.4, 59.6, 72.4, 70.6,
> 82, 89.5, 101.3, 116.7, 115.2, 122.9)
>
>
> gls.est <- gls(y~x, correlation=corARMA(q=1), method='ML')
>
> ybar <- gls.est$coefficients[1]
> residualsnorm <- residuals(gls.est, type = "normalized")
>
> gls.est.ssenorm <- sum((residualsnorm)^2)
> gls.est.ssreg <-sum((gls.est$fitted - ybar)^2)
> gls.est.sstot <- sum((y - ybar)^2)
>
> gls.est.rsquaredA <- 1 - (gls.est.ssenorm/gls.est.sstot)
> gls.est.rsquaredB <- cor(y, gls.est$fitted)^2
>
> cat("SSE + SSREG: ", gls.est.ssreg + gls.est.ssenorm, "\n")
> cat("SSTOT: ", gls.est.sstot, "\n")
>
> cat("GLS RSQUARED A : ", gls.est.rsquaredA, "\n")
> cat("GLS RSQUARED B : ", gls.est.rsquaredB, "\n")
>
> gls.sum <- summary(gls.est)
> print(gls.sum)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri May  8 09:44:01 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 8 May 2015 09:44:01 +0200
Subject: [R-sig-ME] GAMM big data (70K rand effects) guidance
In-Reply-To: <C0B2A66D-BB13-4A55-8B40-19E7B157898E@gmail.com>
References: <C0B2A66D-BB13-4A55-8B40-19E7B157898E@gmail.com>
Message-ID: <CAJuCY5weR4G_MTvhcF6xp30psOE5_sCing0M6UCNTMqUB3Gyvw@mail.gmail.com>

Dear Steven,

It looks like you have on average about 7 measurements per patient. Are
they taken at somewhat fixed timepoints? E.g. something like ayfu = seq(0,
by = 50, length = 7) + rnorm(7, sd = 2). In that case you could consider to
make the model less complex and treat ayfu as categorical. You won't loose
that much information. Then the model becomes lmer(log(cd4 + 1) ~sex +
timepoint * CD4 + (1|PatientID)). I recommend renaming CD4. Having CD4 and
cd4 in the samen dataset is confusing.

Another thing that I would try is to limit to complexity of the smoother be
setting k = 3.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-07 17:31 GMT+02:00 Steve Bellan <steve.bellan at gmail.com>:

> Hi all,
>
> I am working with an patient data base of 70K HIV-infected individuals
> followed over time since treatment initiation, with 500K total observations
> that include a laboratory measurement (CD4 cell count?an indicator of
> immunocompetence). I?m trying to use GAMM to model the CD4 trajectory as a
> function of CD4 at treatment initiation (i.e. y-intercept) and other
> covariate classes (sex, age, etc). Thus, far I?ve struggled to fit GAMMs to
> the entire data set.
>
> I?m using a gaussian link function to log(CD4+1) for now. With gamm, this
> gives the following:
>
> > form <- as.formula('log(cd4 + 1) ~ sex + s(ayfu, by = CD4_cat_init,
> bs=?tp")')
> > print(system.time(tg1 <- gamm(form, data = nd, order.groups=F,
> family=gaussian, random=list(PatientID=~1))))
>
> where ayfu is time since treatment initiation and CD4_cat_init is the CD4
> count at treatment initiation broken into 5 categories.
>
> I ran that on a large memory (1TB) node on our HPC cluster and, after 12
> hours using between 300-500 GB of memory, it crashed:
>
> > Error in print(system.time(tg1 <- gamm(form, data = nd, order.groups =
> F,  :
> >   error in evaluating the argument 'x' in selecting a method for
> function 'print': Error in cbind(X1, X[[i]][, j] * X0) :
> >   long vectors not supported yet: bind.c:1301
> > Calls: system.time ... extract.lme.cov2 -> cbind ->
> tensor.prod.model.matrix -> cbind
>
> Google tells me that this has to do with limits on R?s array size. But I
> don?t totally follow how that is interacting with the gamm call.
>
> I?m now trying out cubic regression splines (bs=?cs? instead of ?tp?) with
> gamm and also with gamm4. Running the code on subsets of the data (1K
> individuals) suggest only a mild improvement by using ?cs? for both
> packages, and a *decrease* in speed using gamm4 instead of gamm. The latter
> surprises me since I had thought that gamm4 was meant to be faster when the
> # of random effects was large.
>
> Eventually I?d like to use smoother-by-group interactions other than the
> CD4_cat_init (i.e. sex, age etc) and test whether trajectories are
> significantly different between covariate classes using AIC. It would also
> be nice to somehow characterize how variable individuals? trends are within
> a covariate class, though I?m not exactly sure what?s the best way to do
> that.
>
> But until I can get just one of these models to fit, these goals seem like
> a long shot. I?ve struggled to find much documentation online regarding
> fitting GAMMs to such large data sets, particularly one with so many random
> effects. Hence the trial and error exploration of different splines &
> packages. Does anyone have more concrete guidance on how to approach this
> problem or helpful documentation? Help much appreciated!
>
> Thanks,
>
> Steve
>
> Steve Bellan, PhD, MPH
> Post-doctoral Researcher
> Lauren Ancel Meyers Research Group
> Center for Computational Biology and Bioinformatics
> University of Texas at Austin
> http://www.bio.utexas.edu/research/meyers/steve_bellan/ <
> http://www.bio.utexas.edu/research/meyers/steve_bellan/>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri May  8 10:12:32 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 8 May 2015 10:12:32 +0200
Subject: [R-sig-ME] Including a correlation matrix with the metafor
 package
In-Reply-To: <554B90DC020000B000022FAB@snggwia.senckenberg.de>
References: <554B90DC020000B000022FAB@snggwia.senckenberg.de>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0C3433D3@UM-MAIL4112.unimaas.nl>

This is indeed peculiar.

I don't quite remember if I had fixed some issue related to this in the most recent version of metafor. I just happened to submit version 1.9-6 to CRAN yesterday; you could also just download the dev version as described here:

http://www.metafor-project.org/doku.php/installation#development_version

Just in case, maybe try updating and check if the error still occurs.

Otherwise, it's going to be difficult to diagnose this further without a reproducible example.

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Eike-Lena Neuschulz
> Sent: Thursday, May 07, 2015 16:21
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Including a correlation matrix with the metafor
> package
> 
> Dear R mailing list,
> 
> I have a problem using the metafor package. I would like to include a
> spatial correlation matrix with the R argument. I get an error message
> about levels in the random effects that are not represented in the
> rows/columns of the distance matrix. However, when comparing column and
> row names of the matrix with the levels of the random effect, they seem
> to be identical. See the output below.
> 
> I very much appreciate any help. Thank you very much!
> Best,
> Eike Lena Neuschulz
> 
> > SMDpot = rma.mv(yi, vi, random =  ~ 1 |studyChr,
> +                 mods = ~ process  -1   ,
> +                 R = list(studyChr = distMatModel),
> +                 data = SMD_big, method = "REML",
> +                 Rscale=FALSE)
> 
> Error in rma.mv(yi, vi, random = ~1 | studyChr, mods = ~process - 1, R =
> list(studyChr = distMatModel),  :
>   There are levels in 'studyChr' for which there are no rows/columns in
> the corresponding 'R' matrix.
> >
> >
> > identical(row.names(distMatModel),levels(SMD_big$studyChr))
> [1] TRUE
> > identical(colnames(distMatModel),levels(SMD_big$studyChr))
> [1] TRUE


From karl.ove.hufthammer at helse-bergen.no  Fri May  8 12:19:30 2015
From: karl.ove.hufthammer at helse-bergen.no (Hufthammer, Karl Ove)
Date: Fri, 8 May 2015 12:19:30 +0200
Subject: [R-sig-ME] another gls question
Message-ID: <0D0C1D497D86144EA6BD73E47CDB64CA11B6D11E7C@BGO-MCS005.ihelse.net>

Thierry Onkelinx:
> SSTOT = SSREG + SSTOT is relation that holds with a lineair model with OLS.
> I'm not sure if it still holds with gls.

For a R? measure for GLS models, see this paper:

A. Buse (1973): Goodness of Fit in Generalized Least Squares Estimation
The American Statistician, Vol. 27, No. 3, pp. 106-108
http://www.jstor.org/stable/2683631

-- 
Karl Ove Hufthammer


From pharr011 at gold.ac.uk  Fri May  8 13:56:47 2015
From: pharr011 at gold.ac.uk (Peter Harrison)
Date: Fri, 8 May 2015 11:56:47 +0000
Subject: [R-sig-ME] Logistic modelling with guessing parameter
Message-ID: <VI1PR04MB1295AB975D2547CCA9492836AFDE0@VI1PR04MB1295.eurprd04.prod.outlook.com>

Hello Ben and Ken,

Thanks very much for your useful responses!

Ben - thanks for your hint re non-finite values in PIRLS, I'll bear that in mind for the future. I added non-finite warning checks to the link functions etc. and nothing came up this time, unfortunately.

You're right, all of the groups show complete separation - I hadn't thought too carefully about this but realise now that it will be a problem. I think I might have to merge the musical tracks into larger groups, perhaps by metre, genre, etc.

Thanks a lot for the great graph, too!

Ken - thanks for the heads-up about using the link directly from the psyphy package, that definitely simplifies things! Sorry, the code I gave and you ran is an example that does work: responses ~ accuracy + (1|p_ID). The model I was having problems with was when I added the "audio_name" predictor, i.e. responses ~ accuracy + audio_name + (1|p_ID).

Best wishes,
Peter

	[[alternative HTML version deleted]]


From ken.knoblauch at inserm.fr  Fri May  8 16:28:41 2015
From: ken.knoblauch at inserm.fr (ken knoblauch)
Date: Fri, 8 May 2015 14:28:41 +0000 (UTC)
Subject: [R-sig-ME] Logistic modelling with guessing parameter
References: <VI1PR04MB1295AB975D2547CCA9492836AFDE0@VI1PR04MB1295.eurprd04.prod.outlook.com>
Message-ID: <loom.20150508T160336-963@post.gmane.org>

Peter Harrison <pharr011 at ...> writes:

> 
> Hello Ben and Ken,
> 
> Thanks very much for your useful responses!
> 
> Ben - thanks for your hint re non-finite values in PIRLS, I'll bear that 
in mind for the future. I added
> non-finite warning checks to the link functions etc. and nothing 
came up this time, unfortunately.
> 
> You're right, all of the groups show complete separation - I hadn't 
thought too carefully about this but
> realise now that it will be a problem. I think I might have to merge the
 musical tracks into larger groups,
> perhaps by metre, genre, etc.
> 
> Thanks a lot for the great graph, too!
> 
> Ken - thanks for the heads-up about using the link directly from 
the psyphy package, that definitely
> simplifies things! Sorry, the code I gave and you ran is 
an example that does work: responses ~ accuracy +
> (1|p_ID). The model I was having problems with 
was when I added the "audio_name" predictor, i.e.
> responses ~ accuracy + audio_name + (1|p_ID).

Something that you can try is the mafc.cauchit link 
that would impose a less steep slope because of
the heavy tails of the Cauchy. This might be less
sensitive to complete separation sort of like a
regularization of the psychometric function slope.
I have used this link to correct for the bias introduced
by lapses at the upper asymptote instead of introducing
a lapse parameter which is not obvious how to do
otherwise with glmer. 


> 
> Best wishes,
> Peter
> 
> 	[[alternative HTML version deleted]]
> 
>


From markleeds2 at gmail.com  Fri May  8 16:24:15 2015
From: markleeds2 at gmail.com (Mark Leeds)
Date: Fri, 8 May 2015 10:24:15 -0400
Subject: [R-sig-ME] another gls question
In-Reply-To: <0D0C1D497D86144EA6BD73E47CDB64CA11B6D11E7C@BGO-MCS005.ihelse.net>
References: <0D0C1D497D86144EA6BD73E47CDB64CA11B6D11E7C@BGO-MCS005.ihelse.net>
Message-ID: <CAHz+bWYN_s2uqaXBauXqUDX=u=wm11pAA18+YKCYn653_Pjg1g@mail.gmail.com>

Thanks Karl for the reference. I'll check it out.

Mark

Thierry:  In my last email, I meant L prime L = Omega inverse not Omega.
Essentially,
you find a transformation such that the error term becomes independent and
you
can use the Gauss Markov Theorem because the model has been transformed to
an OLS model. Any decent econometrics book will explain this approach way
more clearly than I currently am :).

My best guess is that, since the help file for gls refers to "Ruppert and
Carroll" as the
main reference, ( I've ordered it. If it's useful, I'll let this list know
), the gls function probably doesn't use the" Transform to  OLS" approach.
Therefore, the "normalized" residuals are referring to something else
rather than the OLS residuals.

Thanks again to both of you for your help.












On Fri, May 8, 2015 at 6:19 AM, Hufthammer, Karl Ove <
karl.ove.hufthammer at helse-bergen.no> wrote:

> Thierry Onkelinx:
> > SSTOT = SSREG + SSTOT is relation that holds with a lineair model with
> OLS.
> > I'm not sure if it still holds with gls.
>
> For a R? measure for GLS models, see this paper:
>
> A. Buse (1973): Goodness of Fit in Generalized Least Squares Estimation
> The American Statistician, Vol. 27, No. 3, pp. 106-108
> http://www.jstor.org/stable/2683631
>
> --
> Karl Ove Hufthammer
>

	[[alternative HTML version deleted]]


From pharr011 at gold.ac.uk  Fri May  8 21:02:50 2015
From: pharr011 at gold.ac.uk (Peter Harrison)
Date: Fri, 8 May 2015 19:02:50 +0000
Subject: [R-sig-ME] Logistic modelling with guessing parameter
In-Reply-To: <loom.20150508T160336-963@post.gmane.org>
References: <VI1PR04MB1295AB975D2547CCA9492836AFDE0@VI1PR04MB1295.eurprd04.prod.outlook.com>
	<loom.20150508T160336-963@post.gmane.org>
Message-ID: <VI1PR04MB1295AC14DD95685701056FB2AFDE0@VI1PR04MB1295.eurprd04.prod.outlook.com>

Thanks for the suggestion - mafc.cauchit  seems to work with p_ID and audio_name as random effects, but unfortunately not with audio_name as a fixed effect, as I'd hoped for ("cannot generate feasible simplex"). Oh well! 

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of ken knoblauch
Sent: 08 May 2015 15:29
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Logistic modelling with guessing parameter

Peter Harrison <pharr011 at ...> writes:

> 
> Hello Ben and Ken,
> 
> Thanks very much for your useful responses!
> 
> Ben - thanks for your hint re non-finite values in PIRLS, I'll bear 
> that
in mind for the future. I added
> non-finite warning checks to the link functions etc. and nothing
came up this time, unfortunately.
> 
> You're right, all of the groups show complete separation - I hadn't
thought too carefully about this but
> realise now that it will be a problem. I think I might have to merge 
> the
 musical tracks into larger groups,
> perhaps by metre, genre, etc.
> 
> Thanks a lot for the great graph, too!
> 
> Ken - thanks for the heads-up about using the link directly from
the psyphy package, that definitely
> simplifies things! Sorry, the code I gave and you ran is
an example that does work: responses ~ accuracy +
> (1|p_ID). The model I was having problems with
was when I added the "audio_name" predictor, i.e.
> responses ~ accuracy + audio_name + (1|p_ID).

Something that you can try is the mafc.cauchit link that would impose a less steep slope because of the heavy tails of the Cauchy. This might be less sensitive to complete separation sort of like a regularization of the psychometric function slope.
I have used this link to correct for the bias introduced by lapses at the upper asymptote instead of introducing a lapse parameter which is not obvious how to do otherwise with glmer. 


> 
> Best wishes,
> Peter
> 
> 	[[alternative HTML version deleted]]
> 
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ken.beath at mq.edu.au  Sat May  9 12:43:35 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 9 May 2015 20:43:35 +1000
Subject: [R-sig-ME] GAMM big data (70K rand effects) guidance
In-Reply-To: <C0B2A66D-BB13-4A55-8B40-19E7B157898E@gmail.com>
References: <C0B2A66D-BB13-4A55-8B40-19E7B157898E@gmail.com>
Message-ID: <CAF5_5cxm8VsGUYSAfwzWEWQD5ZJ2F4Y0u_1+o1bWWNHokTUeuw@mail.gmail.com>

Long vectors i.e. vectors of about length 2^31 or longer have been
progressively added to R, but not everywhere. In this case I think it is
because an array can't yet have a bounds of this size, although a vector
can.

> x <- 1
> x[2^31] <- 1
> y <- 1
> y[2^31] <- 1
> z <- cbind(x,y)
Error in cbind(x, y) :
  long vectors not supported yet:
../../../../R-3.1.3/src/include/Rinlinedfuns.h:137

Even if this is fixed the C and Fortran code in many packages would need to
be modified as well.


On 8 May 2015 at 01:31, Steve Bellan <steve.bellan at gmail.com> wrote:

> Hi all,
>
> I am working with an patient data base of 70K HIV-infected individuals
> followed over time since treatment initiation, with 500K total observations
> that include a laboratory measurement (CD4 cell count?an indicator of
> immunocompetence). I?m trying to use GAMM to model the CD4 trajectory as a
> function of CD4 at treatment initiation (i.e. y-intercept) and other
> covariate classes (sex, age, etc). Thus, far I?ve struggled to fit GAMMs to
> the entire data set.
>
> I?m using a gaussian link function to log(CD4+1) for now. With gamm, this
> gives the following:
>
> > form <- as.formula('log(cd4 + 1) ~ sex + s(ayfu, by = CD4_cat_init,
> bs=?tp")')
> > print(system.time(tg1 <- gamm(form, data = nd, order.groups=F,
> family=gaussian, random=list(PatientID=~1))))
>
> where ayfu is time since treatment initiation and CD4_cat_init is the CD4
> count at treatment initiation broken into 5 categories.
>
> I ran that on a large memory (1TB) node on our HPC cluster and, after 12
> hours using between 300-500 GB of memory, it crashed:
>
> > Error in print(system.time(tg1 <- gamm(form, data = nd, order.groups =
> F,  :
> >   error in evaluating the argument 'x' in selecting a method for
> function 'print': Error in cbind(X1, X[[i]][, j] * X0) :
> >   long vectors not supported yet: bind.c:1301
> > Calls: system.time ... extract.lme.cov2 -> cbind ->
> tensor.prod.model.matrix -> cbind
>
> Google tells me that this has to do with limits on R?s array size. But I
> don?t totally follow how that is interacting with the gamm call.
>
> I?m now trying out cubic regression splines (bs=?cs? instead of ?tp?) with
> gamm and also with gamm4. Running the code on subsets of the data (1K
> individuals) suggest only a mild improvement by using ?cs? for both
> packages, and a *decrease* in speed using gamm4 instead of gamm. The latter
> surprises me since I had thought that gamm4 was meant to be faster when the
> # of random effects was large.
>
> Eventually I?d like to use smoother-by-group interactions other than the
> CD4_cat_init (i.e. sex, age etc) and test whether trajectories are
> significantly different between covariate classes using AIC. It would also
> be nice to somehow characterize how variable individuals? trends are within
> a covariate class, though I?m not exactly sure what?s the best way to do
> that.
>
> But until I can get just one of these models to fit, these goals seem like
> a long shot. I?ve struggled to find much documentation online regarding
> fitting GAMMs to such large data sets, particularly one with so many random
> effects. Hence the trial and error exploration of different splines &
> packages. Does anyone have more concrete guidance on how to approach this
> problem or helpful documentation? Help much appreciated!
>
> Thanks,
>
> Steve
>
> Steve Bellan, PhD, MPH
> Post-doctoral Researcher
> Lauren Ancel Meyers Research Group
> Center for Computational Biology and Bioinformatics
> University of Texas at Austin
> http://www.bio.utexas.edu/research/meyers/steve_bellan/ <
> http://www.bio.utexas.edu/research/meyers/steve_bellan/>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From napovarj at gmail.com  Sat May  9 23:36:47 2015
From: napovarj at gmail.com (Napoleon Vargas)
Date: Sat, 09 May 2015 21:36:47 +0000
Subject: [R-sig-ME] Multiple threshold/ordinal traits in MCMCglmm
Message-ID: <CAC4AauTNcqPfVNGDeF0TirzY7f6NExJs-xfrGO-vjDjoxXmkBA@mail.gmail.com>

Dear all,

I was wondering if it is possible to fit multiple threshold/ordinal traits
in MCMCglmm? If so, how would the priors/variance structure be specified? I
have only fitted single traits, so I'd appreciate your response.

Cheers,

Napo

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun May 10 22:22:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 10 May 2015 16:22:00 -0400
Subject: [R-sig-ME] heterogeneous variance models
Message-ID: <554FBDE8.4020101@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


   Someone sent me an e-mail recently asking how/whether heterogeneous
variances can be implemented in lme4.  I can't find it any more, so
I'm answering here in hopes that they'll see it. The short answer is
that they can, at least for heterogeneity among categorical groups
(similar to what varIdent does in the nlme package), although it's a
bit of a nuisance for categorical variables with lots of levels, as
the variance terms all need to be specified separately.

   The trick is to set up a dummy variable for each level: there is a
helper function dummy() for this purpose, and example("dummy") gives
an example showing how to estimate heterogeneous residual variances
for females vs. males in the standard sleep study example.

  Ben Bolker


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVT73oAAoJEOCV5YRblxUHlzQIAMuoYv9K06NGG+3mEcvHcmPW
Xp7rLyxRfiTtRkmr/UieR52WpFDapxNgMurLT1aESD5TWeSBTXmeev2ltajPM5It
A5Mz1cNob1Tl67zsBCUrKMVVclRicO/Ymbpab1QJYcXxGAVZ03gkaguPWJpw3aHQ
kt2GZW6SGidbI17PwZXTyVb69cJ8p/mq459LwMAFNusD4MCiIt1/K2HTL8NnekVn
G7XPMDBg/JoyHmnqWpJbhzccjxZetNMtK6GyXaamlnyPJaJI0i9j6t/X0jKiAqO0
k1BdwNkLo03sneHodyhdRqAS5KMzeNSo8FOinDIUCLtVikz5k0IbQhHO6JWChz4=
=KPfA
-----END PGP SIGNATURE-----


From Michelle.Gosse at foodstandards.gov.au  Sun May 10 23:32:33 2015
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Sun, 10 May 2015 21:32:33 +0000
Subject: [R-sig-ME] toxicology dietary subchronic feed/weight analysis
Message-ID: <D5ED07A4EA222E42AF840A9EEF264880016B3C72F6@FSEXMBX01.foodstandards.gov.au>

Hi all,

Still continuing on the dataset I have for the effect of two toxins on rats, I managed to fit very nice linear mixed effects models for the effects on the toxins on body weight over time, using weight = toxin * time + (time + 1 | subject.ID) as per Steven Pierce's suggestion.

I didn't need to get into a nonlinear mixed effect model as the results were very nice staying within a linear framework.

The final analysis I need to do is to examine feed intake and see how this is associated with body weight, time, and drug. I have feed intake measured daily, so 28 intake data points per subject, but only 7 weight data points, so while I have repeated measures for both, I do not have a fully linked intake-weight series.

The research question is whether the toxin influenced feed intake (feed palatability issue). I'm interested in intake slopes/partial slopes, but obviously body weight should be the main driver of feed intake (heavier rats eat more).

I'm thinking of an analysis similar to: intake = toxin*body weight*time (time +1|subject.ID)

But I'm not sure I have the sample size to do a three-way effect, and I don't know that this is the correct model specification given that I have weight data which is not missing at random - all the rats were measured on  specific days such as Day 1, Day 4, Day 7.

Has anyone worked with a similar dataset to advise what model to fit.

Cheers
Michelle, note: I do not work Fridays


**********************************************************************
This email and any files transmitted with it are confide...{{dropped:12}}


From thierry.onkelinx at inbo.be  Mon May 11 09:04:50 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 11 May 2015 09:04:50 +0200
Subject: [R-sig-ME] toxicology dietary subchronic feed/weight analysis
In-Reply-To: <D5ED07A4EA222E42AF840A9EEF264880016B3C72F6@FSEXMBX01.foodstandards.gov.au>
References: <D5ED07A4EA222E42AF840A9EEF264880016B3C72F6@FSEXMBX01.foodstandards.gov.au>
Message-ID: <CAJuCY5xhMRNv8-gMw+4CFqZONi0Q_ADr6s1DLa=PsfZyjK_8-g@mail.gmail.com>

Dear Michelle,

The best solution for the next study is to measure weight as the same
frequency as the intake ;-)

I see two possible solutions for your current study. 1) Use multiple
imputation on the missing values of weight based on your weight model. 2)
Go Bayesian an fit both the weight and intake models simultaneously use a
hierarchical model.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-10 23:32 GMT+02:00 Gosse, Michelle <
Michelle.Gosse at foodstandards.gov.au>:

> Hi all,
>
> Still continuing on the dataset I have for the effect of two toxins on
> rats, I managed to fit very nice linear mixed effects models for the
> effects on the toxins on body weight over time, using weight = toxin * time
> + (time + 1 | subject.ID) as per Steven Pierce's suggestion.
>
> I didn't need to get into a nonlinear mixed effect model as the results
> were very nice staying within a linear framework.
>
> The final analysis I need to do is to examine feed intake and see how this
> is associated with body weight, time, and drug. I have feed intake measured
> daily, so 28 intake data points per subject, but only 7 weight data points,
> so while I have repeated measures for both, I do not have a fully linked
> intake-weight series.
>
> The research question is whether the toxin influenced feed intake (feed
> palatability issue). I'm interested in intake slopes/partial slopes, but
> obviously body weight should be the main driver of feed intake (heavier
> rats eat more).
>
> I'm thinking of an analysis similar to: intake = toxin*body weight*time
> (time +1|subject.ID)
>
> But I'm not sure I have the sample size to do a three-way effect, and I
> don't know that this is the correct model specification given that I have
> weight data which is not missing at random - all the rats were measured on
> specific days such as Day 1, Day 4, Day 7.
>
> Has anyone worked with a similar dataset to advise what model to fit.
>
> Cheers
> Michelle, note: I do not work Fridays
>
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:12}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ajmackey at gmail.com  Mon May 11 15:50:12 2015
From: ajmackey at gmail.com (Aaron Mackey)
Date: Mon, 11 May 2015 09:50:12 -0400
Subject: [R-sig-ME] heterogeneous variance models
In-Reply-To: <554FBDE8.4020101@gmail.com>
References: <554FBDE8.4020101@gmail.com>
Message-ID: <CAErFSoikVSaai_9BuX+LqShNdWE4jHQ4EELXUvWs=yh_4soxig@mail.gmail.com>

Thanks for this. What's confusing to me in the example is that the residual
std. dev is still 1.3100 whether the dummy term is included or not; I would
have thought that the residual sd without the dummy term would be
intermediate between the two sex-specific sd's seen in the full model
(reported as 1.0521 and 1.311).  The reported residuals also don't seem to
change between the two models.

thanks for any clarification you can provide,
-Aaron

On Sun, May 10, 2015 at 4:22 PM, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>    Someone sent me an e-mail recently asking how/whether heterogeneous
> variances can be implemented in lme4.  I can't find it any more, so
> I'm answering here in hopes that they'll see it. The short answer is
> that they can, at least for heterogeneity among categorical groups
> (similar to what varIdent does in the nlme package), although it's a
> bit of a nuisance for categorical variables with lots of levels, as
> the variance terms all need to be specified separately.
>
>    The trick is to set up a dummy variable for each level: there is a
> helper function dummy() for this purpose, and example("dummy") gives
> an example showing how to estimate heterogeneous residual variances
> for females vs. males in the standard sleep study example.
>
>   Ben Bolker
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVT73oAAoJEOCV5YRblxUHlzQIAMuoYv9K06NGG+3mEcvHcmPW
> Xp7rLyxRfiTtRkmr/UieR52WpFDapxNgMurLT1aESD5TWeSBTXmeev2ltajPM5It
> A5Mz1cNob1Tl67zsBCUrKMVVclRicO/Ymbpab1QJYcXxGAVZ03gkaguPWJpw3aHQ
> kt2GZW6SGidbI17PwZXTyVb69cJ8p/mq459LwMAFNusD4MCiIt1/K2HTL8NnekVn
> G7XPMDBg/JoyHmnqWpJbhzccjxZetNMtK6GyXaamlnyPJaJI0i9j6t/X0jKiAqO0
> k1BdwNkLo03sneHodyhdRqAS5KMzeNSo8FOinDIUCLtVikz5k0IbQhHO6JWChz4=
> =KPfA
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From karl.ove.hufthammer at helse-bergen.no  Mon May 11 17:03:35 2015
From: karl.ove.hufthammer at helse-bergen.no (Hufthammer, Karl Ove)
Date: Mon, 11 May 2015 17:03:35 +0200
Subject: [R-sig-ME] heterogeneous variance models
Message-ID: <0D0C1D497D86144EA6BD73E47CDB64CA11B6D11E92@BGO-MCS005.ihelse.net>

Also, the results don't seem to agree with the results from the old nlme package.

Example (using a slightly more sensible model than from the help file): Here's what the data looks like:

  xyplot(distance~age|Sex, groups=Subject, data=Orthodont, type="l", col="darkblue")

Let's fit lme4 and nlme models:

  l_new1 = lmer(distance ~ age + Sex + (age|Subject), data = Orthodont)
  l_new2 = update(l_new1, . ~ . + (0+dummy(Sex, "Female")|Subject))
  summary(l_new1)
  summary(l_new2)

  l_old1 = lme(distance ~ age + Sex, random=~age|Subject, data = Orthodont)
  l_old2 = update(l_old1, weights=varIdent(form=~1|Sex))
  summary(l_old1)
  summary(l_old2)

While the fixed effects estimates for the two models assuming homoscedasticity are very ~identical, the estimates from the heteroscedasticity models differ:

> fixef(l_new1)
(Intercept)         age   SexFemale 
 17.6351989   0.6601852  -2.1454883 
> fixef(l_new2)
(Intercept)         age   SexFemale 
 17.6487393   0.6601852  -2.1787238
> fixef(l_old1)
(Intercept)         age   SexFemale 
 17.6352002   0.6601852  -2.1454915
> fixef(l_old2)
(Intercept)         age   SexFemale 
 18.4385143   0.5795744  -1.9407706

It's a clever trick, but doesn't seem to work properly (or is it nlme that doesn't work properly?). (Also, it assumes that one *knows* which group has the lowest residual variance.)


Regards,
Karl Ove Hufthammer


-----Opphavleg melding-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] P? vegner av Aaron Mackey
Sent: 11. mai 2015 15:50
To: Ben Bolker
Kopi: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] heterogeneous variance models

Thanks for this. What's confusing to me in the example is that the residual std. dev is still 1.3100 whether the dummy term is included or not; I would have thought that the residual sd without the dummy term would be intermediate between the two sex-specific sd's seen in the full model (reported as 1.0521 and 1.311).  The reported residuals also don't seem to change between the two models.

thanks for any clarification you can provide, -Aaron

On Sun, May 10, 2015 at 4:22 PM, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>    Someone sent me an e-mail recently asking how/whether heterogeneous 
> variances can be implemented in lme4.  I can't find it any more, so 
> I'm answering here in hopes that they'll see it. The short answer is 
> that they can, at least for heterogeneity among categorical groups 
> (similar to what varIdent does in the nlme package), although it's a 
> bit of a nuisance for categorical variables with lots of levels, as 
> the variance terms all need to be specified separately.
>
>    The trick is to set up a dummy variable for each level: there is a 
> helper function dummy() for this purpose, and example("dummy") gives 
> an example showing how to estimate heterogeneous residual variances 
> for females vs. males in the standard sleep study example.
>
>   Ben Bolker
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVT73oAAoJEOCV5YRblxUHlzQIAMuoYv9K06NGG+3mEcvHcmPW
> Xp7rLyxRfiTtRkmr/UieR52WpFDapxNgMurLT1aESD5TWeSBTXmeev2ltajPM5It
> A5Mz1cNob1Tl67zsBCUrKMVVclRicO/Ymbpab1QJYcXxGAVZ03gkaguPWJpw3aHQ
> kt2GZW6SGidbI17PwZXTyVb69cJ8p/mq459LwMAFNusD4MCiIt1/K2HTL8NnekVn
> G7XPMDBg/JoyHmnqWpJbhzccjxZetNMtK6GyXaamlnyPJaJI0i9j6t/X0jKiAqO0
> k1BdwNkLo03sneHodyhdRqAS5KMzeNSo8FOinDIUCLtVikz5k0IbQhHO6JWChz4=
> =KPfA
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Mon May 11 17:28:01 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 May 2015 11:28:01 -0400
Subject: [R-sig-ME] heterogeneous variance models
In-Reply-To: <0D0C1D497D86144EA6BD73E47CDB64CA11B6D11E92@BGO-MCS005.ihelse.net>
References: <0D0C1D497D86144EA6BD73E47CDB64CA11B6D11E92@BGO-MCS005.ihelse.net>
Message-ID: <5550CA81.7060001@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Quick answer:  I think I shot from the hip and made a mistake.  If
you want to model heterogeneous *residual* variation, the dummy
variable should be applied to an *individual-level* random-effect,
i.e. define something like

   transform(mydata,obs=factor(seq(nrow(mydata)))
   lmer(...~... + (0+dummy(Sex,"Female")|obs)

 More later I hope.

On 15-05-11 11:03 AM, Hufthammer, Karl Ove wrote:
> 
> l_new1 = lmer(distance ~ age + Sex + (age|Subject), data =
> Orthodont) l_new2 = update(l_new1, . ~ . + (0+dummy(Sex,
> "Female")|Subject)) summary(l_new1) summary(l_new2)
> 
> l_old1 = lme(distance ~ age + Sex, random=~age|Subject, data =
> Orthodont) l_old2 = update(l_old1, weights=varIdent(form=~1|Sex)) 
> summary(l_old1) summary(l_old2)
> 
> While the fixed effects estimates for the two models assuming
> homoscedasticity are very ~identical, the estimates from the
> heteroscedasticity models differ:
> 
>>> fixef(l_new1)
> (Intercept)         age   SexFemale 17.6351989   0.6601852
> -2.1454883
>>> fixef(l_new2)
> (Intercept)         age   SexFemale 17.6487393   0.6601852
> -2.1787238
>>> fixef(l_old1)
> (Intercept)         age   SexFemale 17.6352002   0.6601852
> -2.1454915
>>> fixef(l_old2)
> (Intercept)         age   SexFemale 18.4385143   0.5795744
> -1.9407706
> 
> It's a clever trick, but doesn't seem to work properly (or is it
> nlme that doesn't work properly?). (Also, it assumes that one
> *knows* which group has the lowest residual variance.)
> 
> 
> Regards, Karl Ove Hufthammer

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVUMqAAAoJEOCV5YRblxUH3KkH/AgZfnd8nzrOOMXgsStOv6yE
nx4cp+bK9uXh9g43iPVFi2rWk7ZoacVt4WyOmsPfprlYOmxU6ri9hsAImyF1TCmM
nQAQd6oDCsJraU683nuizKeqxovntcY2xHOLjUQfITdG0nQUprwX/Oqe3hZS+wcv
IOoJaNk+FIdWEv8zxazkihfcwNCoaKCd55UttSEKVIxnxTOWOSoF+/82i62kBksd
AccTmVzyA5s2H8/yQgjzwWB1usYEqnRBbuu1+Th1RBqQt6eWjmxMRBXLBrLiQ+fR
cLDDdfjDLIKG4rOZiDi5g1ojqiYq/30tjHCuIj4PH1Q0EoSk4PXJuL+gMG6YVoc=
=KD6O
-----END PGP SIGNATURE-----


From highstat at highstat.com  Mon May 11 22:06:15 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 11 May 2015 22:06:15 +0200
Subject: [R-sig-ME] Course: Introduction to zero inflated models with R
Message-ID: <55510BB7.2000303@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course in Palm Cove, 
Australia.

Course:  Introduction to zero inflated models with R
Location: Palm Cove, Australia
Date:       17-21 August 2015
Price:       550 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_08PalmCoveII.pdf


Keywords:
Zero inflated GLM (ZIP, ZINB, ZAP, ZANB). Zero inflated GLMMs with 
random effects. Bayesian statistics,
MCMC and JAGS. lme4, glmmADMB, JAGS. Overdispersion and solutions. 
Poisson, negative binomial,
gamma, lognormal and binomial distributions. Count data. Continuous data.


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From lponisio at gmail.com  Wed May 13 08:04:23 2015
From: lponisio at gmail.com (Lauren Catherine Ponisio)
Date: Tue, 12 May 2015 23:04:23 -0700
Subject: [R-sig-ME] Fwd: random effects heteroscedasticity glmm
In-Reply-To: <CABaj+=cNJ8gZ=ia4hKscJHAk72YPEuRiKQ4K1=c5FO8zD9J3SQ@mail.gmail.com>
References: <CABaj+=cNJ8gZ=ia4hKscJHAk72YPEuRiKQ4K1=c5FO8zD9J3SQ@mail.gmail.com>
Message-ID: <CABaj+=fVowCXuofBSQRmiT7vru1dwCchaNFgyot2SQ9+Kn=DQg@mail.gmail.com>

Dear R-sig-mixed-models list members,

I have a glmm with some pretty severe heteroscedasticity in the random
effects and was hoping for some advice on how to model it, or alternative
approaches.

I have floral richness data from 18 sites over two years, four observations
within each year at each site. I am interested in the effect of landscape
diversity and fire severity. I have model with an interaction between
landscape diversity and fire severity, and a fixed effect of year, day of
the year, and a quadratic day of the year.  Also a random effect of site.
The continuous variables are scaled. I assumed a poisson error distribution
(I checked for overdispersion).

This is my model:

FloralRichness ~ s.simpson.div * SiteStatus + Year + s.doy +
    I(s.doy^2) + (1 | Site)

The data is available here:
https://www.dropbox.com/s/efdcxz20l3dpwvl/alldata.csv?dl=0

## my code
formula.flower <- as.formula(FloralRichness ~ s.simpson.div * SiteStatus +
Year + s.doy +
    I(s.doy^2) + (1 | Site))

flower.mod <- glmer(formula.flower, family="poisson", data=dat.mods)

## Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
## glmerMod]
##  Family: poisson  ( log )
## Formula: FloralRichness ~ s.simpson.div * SiteStatus + Year + s.doy +
##     I(s.doy^2) + (1 | Site)
##    Data: dat.mods

##      AIC      BIC   logLik deviance df.resid
##    688.7    718.4   -334.4    668.7      134

## Scaled residuals:
##      Min       1Q   Median       3Q      Max
## -2.77658 -0.39078 -0.02645  0.35389  1.83799

## Random effects:
##  Groups Name        Variance Std.Dev.
##  Site   (Intercept) 0.04093  0.2023
## Number of obs: 144, groups:  Site, 18

## Fixed effects:
##                              Estimate Std. Error z value Pr(>|z|)
## (Intercept)                   2.39930    0.11243  21.340  < 2e-16 ***
## s.simpson.div                 0.32838    0.11193   2.934 0.003347 **
## SiteStatusLOW                -0.36443    0.13975  -2.608 0.009115 **
## SiteStatusHIGH               -0.03427    0.14189  -0.242 0.809143
## Year2014                     -0.09582    0.06714  -1.427 0.153517
## s.doy                         0.05077    0.03658   1.388 0.165188
## I(s.doy^2)                   -0.09105    0.02764  -3.294 0.000986 ***
## s.simpson.div:SiteStatusLOW  -0.01073    0.15090  -0.071 0.943336
## s.simpson.div:SiteStatusHIGH -0.40605    0.14121  -2.876 0.004034 **
## ---
## Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

## residuals don't look great and also the site random effects are all
## over the place!

layout(matrix(1:4, nrow=2))
hist(residuals(flower.mod))
boxplot(residuals(flower.mod) ~ Site,
        data = dat.mods, main = "Site", ylab = "Residuals")

plot(fitted(flower.mod), residuals(flower.mod),
     xlab = "Fitted Values", ylab = "Residuals")
abline(h=0, lty=2)
lines(smooth.spline(fitted(flower.mod), residuals(flower.mod)))

## one thought was to create site-specific variances, so basically
## create a variable called observation for each sample at each site,
## and nest observation within site. I found a explanation of how to
## do this for a fixed effect here:
## http://rpubs.com/bbolker/6298

## and created this model that I think does the trick

as.formula(FloralRichness ~ s.simpson.div * SiteStatus + SiteStatus * Year
+
    s.doy + I(s.doy^2) + (Site | obs))

## the model slowly runs, but with 18 sites and not that much data, perhaps
##  this is not the best approach.

## is modeling the heteroscedasticity of the random effects a fruitful
## path to follow? Or have I made a more fundamental misstep?

Thanks,
Lauren

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed May 13 10:23:49 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 13 May 2015 10:23:49 +0200
Subject: [R-sig-ME] Fwd: random effects heteroscedasticity glmm
In-Reply-To: <CABaj+=fVowCXuofBSQRmiT7vru1dwCchaNFgyot2SQ9+Kn=DQg@mail.gmail.com>
References: <CABaj+=cNJ8gZ=ia4hKscJHAk72YPEuRiKQ4K1=c5FO8zD9J3SQ@mail.gmail.com>
	<CABaj+=fVowCXuofBSQRmiT7vru1dwCchaNFgyot2SQ9+Kn=DQg@mail.gmail.com>
Message-ID: <CAJuCY5zbyW-D5rZ2WnxO+EyKTNnJyJgLXNh7bJ+G-q7QUkc7wA@mail.gmail.com>

Dear Lauren,

Note that you have only 8 observations per site. This might give the
impression of heteroscedasticity. See the examples below. Your model first
model seems reasonable. The second model is too complex for the data.

# 8 observations per category. Some replicates display "heteroscedasticity".
set.seed(123456)
dataset <- data.frame(
  Lambda = rep(c(10, 100), 8)
)
layout(matrix(1:16, nrow=4))
replicate(16, {
  dataset$Y <- rpois(nrow(dataset), lambda = dataset$Lambda)
  model <- glm(Y ~ 0 + factor(Lambda), data = dataset, family = "poisson")
  boxplot(residuals(model) ~ dataset$Lambda)
})

# 200 observations per category. Homoscedasticity.
set.seed(123456)
dataset <- data.frame(
  Lambda = rep(c(10, 100), 200)
)
layout(matrix(1:16, nrow=4))
replicate(16, {
  dataset$Y <- rpois(nrow(dataset), lambda = dataset$Lambda)
  model <- glm(Y ~ 0 + factor(Lambda), data = dataset, family = "poisson")
  boxplot(residuals(model) ~ dataset$Lambda)
})

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-13 8:04 GMT+02:00 Lauren Catherine Ponisio <lponisio at gmail.com>:

> Dear R-sig-mixed-models list members,
>
> I have a glmm with some pretty severe heteroscedasticity in the random
> effects and was hoping for some advice on how to model it, or alternative
> approaches.
>
> I have floral richness data from 18 sites over two years, four observations
> within each year at each site. I am interested in the effect of landscape
> diversity and fire severity. I have model with an interaction between
> landscape diversity and fire severity, and a fixed effect of year, day of
> the year, and a quadratic day of the year.  Also a random effect of site.
> The continuous variables are scaled. I assumed a poisson error distribution
> (I checked for overdispersion).
>
> This is my model:
>
> FloralRichness ~ s.simpson.div * SiteStatus + Year + s.doy +
>     I(s.doy^2) + (1 | Site)
>
> The data is available here:
> https://www.dropbox.com/s/efdcxz20l3dpwvl/alldata.csv?dl=0
>
> ## my code
> formula.flower <- as.formula(FloralRichness ~ s.simpson.div * SiteStatus +
> Year + s.doy +
>     I(s.doy^2) + (1 | Site))
>
> flower.mod <- glmer(formula.flower, family="poisson", data=dat.mods)
>
> ## Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> ## glmerMod]
> ##  Family: poisson  ( log )
> ## Formula: FloralRichness ~ s.simpson.div * SiteStatus + Year + s.doy +
> ##     I(s.doy^2) + (1 | Site)
> ##    Data: dat.mods
>
> ##      AIC      BIC   logLik deviance df.resid
> ##    688.7    718.4   -334.4    668.7      134
>
> ## Scaled residuals:
> ##      Min       1Q   Median       3Q      Max
> ## -2.77658 -0.39078 -0.02645  0.35389  1.83799
>
> ## Random effects:
> ##  Groups Name        Variance Std.Dev.
> ##  Site   (Intercept) 0.04093  0.2023
> ## Number of obs: 144, groups:  Site, 18
>
> ## Fixed effects:
> ##                              Estimate Std. Error z value Pr(>|z|)
> ## (Intercept)                   2.39930    0.11243  21.340  < 2e-16 ***
> ## s.simpson.div                 0.32838    0.11193   2.934 0.003347 **
> ## SiteStatusLOW                -0.36443    0.13975  -2.608 0.009115 **
> ## SiteStatusHIGH               -0.03427    0.14189  -0.242 0.809143
> ## Year2014                     -0.09582    0.06714  -1.427 0.153517
> ## s.doy                         0.05077    0.03658   1.388 0.165188
> ## I(s.doy^2)                   -0.09105    0.02764  -3.294 0.000986 ***
> ## s.simpson.div:SiteStatusLOW  -0.01073    0.15090  -0.071 0.943336
> ## s.simpson.div:SiteStatusHIGH -0.40605    0.14121  -2.876 0.004034 **
> ## ---
> ## Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> ## residuals don't look great and also the site random effects are all
> ## over the place!
>
> layout(matrix(1:4, nrow=2))
> hist(residuals(flower.mod))
> boxplot(residuals(flower.mod) ~ Site,
>         data = dat.mods, main = "Site", ylab = "Residuals")
>
> plot(fitted(flower.mod), residuals(flower.mod),
>      xlab = "Fitted Values", ylab = "Residuals")
> abline(h=0, lty=2)
> lines(smooth.spline(fitted(flower.mod), residuals(flower.mod)))
>
> ## one thought was to create site-specific variances, so basically
> ## create a variable called observation for each sample at each site,
> ## and nest observation within site. I found a explanation of how to
> ## do this for a fixed effect here:
> ## http://rpubs.com/bbolker/6298
>
> ## and created this model that I think does the trick
>
> as.formula(FloralRichness ~ s.simpson.div * SiteStatus + SiteStatus * Year
> +
>     s.doy + I(s.doy^2) + (Site | obs))
>
> ## the model slowly runs, but with 18 sites and not that much data, perhaps
> ##  this is not the best approach.
>
> ## is modeling the heteroscedasticity of the random effects a fruitful
> ## path to follow? Or have I made a more fundamental misstep?
>
> Thanks,
> Lauren
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From alexandre.m.martin at gmail.com  Wed May 13 15:51:18 2015
From: alexandre.m.martin at gmail.com (Alexandre Martin)
Date: Wed, 13 May 2015 09:51:18 -0400
Subject: [R-sig-ME] genetic effects and multiple membership in MCMCglmm
References: <011d01d08d09$206cd5d0$61468170$@gmail.com> 
Message-ID: <018901d08d83$e3c539d0$ab4fad70$@gmail.com>

Dear Jarrod and esteemed mixed-modelers,

First, thank you again for your help on a previous post.
I am returning on the work on indirect genetic effects I had to set aside
last month and I am trying Jarrod's solution using the function "mm".
I am unfortunately unable to run a model that links mate_1, mate_2, ...,
mate_n to the A inverse. 

I used this dummy (and maybe too simple) data set to test the model:
ped=data.frame(animal=letters[1:11] ,dam= c(NA, NA, NA, gl(2,4,labels =
c("a","c"))), sire=c(NA,NA,NA,rep("b",8)))
dat= data.frame(animal=letters[4:11], pen=c(1,1,2,2,2,1,1,2), Y=rnorm(n =
8,mean = 5,sd =
0.4),m1=c("e","d","g","f","f","d","d","f"),m2=c("i","i","h","h","g","e","e
","g"),m3=c("j","j","k","k","k","j","i","h")), 
where "m" stands for "mate". I have verified that each column had the same
factor levels (following Jarrod's suggestion : factor(mate_1,
levels=all.ids))

Using this dummy dataset in this basic model, mtest <- MCMCglmm(Y~1,
random=~animal+mm(m1+m2+m3),pedigree=ped, data=dat, pr=T),
mm(m1+m2+m3):animal (and other crazy possibilities) led to this error :
"interactions not permitted in str and mm structures". 

Do anyone know how to link the different mates to the Ainverse in order to
obtain blups of m1, m2, ..., m_n.

I would be very grateful for any hint and instruction. 
Many thanks again for your help.

Alexandre

-----Message d'origine-----
De?: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] Envoy??: 3 avril 2015
03:51 ??: Jarrod Hadfield Cc?: Alexandre Martin;
'r-sig-mixed-models at r-project.org'
Objet?: Re: [R-sig-ME] design matrices in MCMCglmm

Hi,

Sorry it should have been just:

random=~mm(mate_1+mate_2+...mate_n)

and it is the mate_1, mate_2, ... mate_n that need to be linked to the A
inverse.

Cheers,

Jarrod

Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 03 Apr 2015
08:16:02 +0100:

> Hi,
>
> Have columns mate_1, mate_2 ... mate_n where n is group size. In each 
> column have the identity of each cage mate (order does not matter).
> Make sure each column has the same factor levels even if they don't 
> appear. For example,
>
> factor(mate_1, levels=all.ids)
>
> where all.ids are all possible cage mates. Then fit:
>
> random=~mm(mate_1+mate_2+...mate_n):animal
>
> where animal is linked to the pedigree through the ginverse argument.
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Tue, 31 Mar
> 2015 10:07:34 -0400:
>
>> Hi Jarrod,
>>
>> Thank you for your help.
>> My question is now extended to the subject of associative indirect 
>> genetic effects.
>>
>> For example in this data set :
>> id    cage
>> a    1
>> b    2
>> c    1
>> d    1
>> e    2
>> f    2
>> g    2
>>
>> cage is a grouping variable describing the composition of cages.
>> For instance, individuals a,c,d live in cage 1.
>>
>> Design matrix Z_cage typically produced by MCMCglmm should be:
>>     c1   c2
>> a    1    0
>> b    0    1
>> c    1    0
>> d    1    0
>> e    0    1
>> f    0    1
>> g    0    1
>> where phenotype of individuals {a, b, ..., g} are linked to cages 1 
>> and
2.
>>
>> Design matrix Z_mates, however, linking the phenotype of individual i 
>> to its cage' mates is:
>>     a    b    c    d    e    f    g
>> a    0    0    1    1    0    0    0
>> b    0    0    0    0    1    1    1
>> c    1    0    0    1    0    0    0
>> d    1    0    1    0    0    0    0
>> e    0    1    0    0    0    1    1
>> f    0    1    0    0    1    0    1
>> g    0    1    0    0    1    1    0
>>
>> It is Z_cage that is given by default, whereas it is matrix Z_mates 
>> that should be used to predict associative effects.
>>
>> Is it possible to force MCMCglmm to work with Z_mates instead of
Z_cage?
>>
>> Thanks again!
>>
>> Alexandre
>>
>> Le 2015-03-28 04:01, Jarrod Hadfield a ?crit :
>>> Hi Alexandre,
>>>
>>> The design matrices should be identical for both effects (z_{ij}=1 
>>> if the jth individual is the mother of individual i). The difference 
>>> is in the correlation structure of the random effects. For 
>>> environmental maternal effects they are assumed iid (i.e. an 
>>> identity matrix) but for the maternal genetic effects they are 
>>> assumed to be proportional to the A matrix. inverseA will return the 
>>> inverse of A if you pass it the pedigree. It is this inverse that is
required for forming the MME.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>>
>>> Quoting Alexandre Martin <alexandre.m.martin at gmail.com> on Fri, 27 
>>> Mar
>>> 2015 16:39:40 -0400:
>>>
>>>> Dear all,
>>>>
>>>> I am working on estimating maternal effects (genetic and
>>>> environmental) with MCMCglmm that is new for me.
>>>>
>>>> I am trying to apply to MCMCglmm what is shown in online Muir's 
>>>> course notes made for SAS. Leanning on Henderson?s Mixed Model 
>>>> Equation, these notes explain how to solve MME to predict random
effects ?by hand?.
>>>>
>>>> Here is my concern:
>>>>
>>>> I do not know how to extract the design matrices for a MCMCglmm 
>>>> model, e.g. the relatedness matrix or the one for maternal genetic 
>>>> effects. I want that to understand how the design matrices are 
>>>> constructed by comparing them to what they are supposed to look 
>>>> like.  For instance, the design matrix for maternal genetic effects 
>>>> should relate offspring to all the individuals that are in the 
>>>> pedigree, whereas the design matrix for maternal environmental 
>>>> effects should just relate offspring to their mothers. Does such a 
>>>> difference exist when MCMCglmm constructs its design matrices? If 
>>>> not, how to include such different matrices in models?
>>>>
>>>>
>>>> Any help will be greatly appreciated. Thank you!
>>>>
>>>>
>>>> Alexandre
>>>>
>>>>   [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in 
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



--
The University of Edinburgh is a charitable body, registered in Scotland,
with registration number SC005336.


From joaquin.aldabe at gmail.com  Wed May 13 23:15:39 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 13 May 2015 18:15:39 -0300
Subject: [R-sig-ME] glmm question
Message-ID: <CAMM93=LxSztxBoWPvMXC6vs7VWYK_ET2L8D8UG2HFtkxzdS70Q@mail.gmail.com>

Hello, this is Joaqu?n Aldabe from Uruguay. I?m trying to model shorebird
counts (Buff breasted Sandpiper, BBSA) with glmm (using lme4 package),
using continuous variables (grass height, field area, forest cover) and one
factor variable (presence/absence of other shorebird species: American
Golden Plover, AMGP). I sampled 19 fields during three years in December.
I?m interested in identifying predictors correlated with BBSA counts. I
used Year as a random effect as I?m not interested in Year as a fix effect
and because fields were counted three times (pseudoreplication).

The model doesn?t converge, and the output showed that the factorial
variable has not a significant effect. This is weird as in every field I
observed the Buff breasted Sandpiper I also observed the other
species. When I take AMGP out, the model runs ok.

This is the model I?m trying to run:

mysub3.3<-glmer(BBSA~Grass_height+Field_area+Field_enclosure_700m+Grass_height*Field_enclosure_700m+fAMGP+(1|fYear),family="poisson",
data=mysub3.2)

continuous variables were scaled.

I can send de data frame if somebody is interested.

Thanks in advanced for helping me on my master thesis.

Cheers,

Joaqu?n.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Thu May 14 00:17:34 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 14 May 2015 08:17:34 +1000
Subject: [R-sig-ME] glmm question
In-Reply-To: <CAMM93=LxSztxBoWPvMXC6vs7VWYK_ET2L8D8UG2HFtkxzdS70Q@mail.gmail.com>
References: <CAMM93=LxSztxBoWPvMXC6vs7VWYK_ET2L8D8UG2HFtkxzdS70Q@mail.gmail.com>
Message-ID: <CAF5_5cxHj81UC9_pV5OdMkBYQWeSkkNdt2L-f11BKeyAp5bCbw@mail.gmail.com>

Having a random effect with only 3 levels is not recommended, it usually
gives problems fitting. There are also some philosophical questions about
its use as a random effect.

A random effect for field is reasonable, but you may be fitting too many
parameters. With only 57 observations it is easy to overfit the models, and
a standard linear model may be all that is necessary.

On 14 May 2015 at 07:15, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:

> Hello, this is Joaqu?n Aldabe from Uruguay. I?m trying to model shorebird
> counts (Buff breasted Sandpiper, BBSA) with glmm (using lme4 package),
> using continuous variables (grass height, field area, forest cover) and one
> factor variable (presence/absence of other shorebird species: American
> Golden Plover, AMGP). I sampled 19 fields during three years in December.
> I?m interested in identifying predictors correlated with BBSA counts. I
> used Year as a random effect as I?m not interested in Year as a fix effect
> and because fields were counted three times (pseudoreplication).
>
> The model doesn?t converge, and the output showed that the factorial
> variable has not a significant effect. This is weird as in every field I
> observed the Buff breasted Sandpiper I also observed the other
> species. When I take AMGP out, the model runs ok.
>
> This is the model I?m trying to run:
>
>
> mysub3.3<-glmer(BBSA~Grass_height+Field_area+Field_enclosure_700m+Grass_height*Field_enclosure_700m+fAMGP+(1|fYear),family="poisson",
> data=mysub3.2)
>
> continuous variables were scaled.
>
> I can send de data frame if somebody is interested.
>
> Thanks in advanced for helping me on my master thesis.
>
> Cheers,
>
> Joaqu?n.
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From joaquin.aldabe at gmail.com  Thu May 14 14:55:24 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 14 May 2015 09:55:24 -0300
Subject: [R-sig-ME] glmm question
In-Reply-To: <CAF5_5cxHj81UC9_pV5OdMkBYQWeSkkNdt2L-f11BKeyAp5bCbw@mail.gmail.com>
References: <CAMM93=LxSztxBoWPvMXC6vs7VWYK_ET2L8D8UG2HFtkxzdS70Q@mail.gmail.com>
	<CAF5_5cxHj81UC9_pV5OdMkBYQWeSkkNdt2L-f11BKeyAp5bCbw@mail.gmail.com>
Message-ID: <CAMM93=L=amxdE__PS2F06V4Zhz1zU3ZifBaDLT_8R2hxGMUAFA@mail.gmail.com>

Thanks a lot Ken for your response. I had decided to use mix model with
random effects because I have repeated measures in each field (one per
year). If I perform a glm, how can I manage the pseudoreplication?
(repeated counts on the same field)

I have one data per field per year. So, no hierarchical or nested structure
of the data. Can I use field as a random effect anyway?

Thanks a lot for your help.

Cheers,
Joaqu?n.

2015-05-13 19:17 GMT-03:00 Ken Beath <ken.beath at mq.edu.au>:

> Having a random effect with only 3 levels is not recommended, it usually
> gives problems fitting. There are also some philosophical questions about
> its use as a random effect.
>
> A random effect for field is reasonable, but you may be fitting too many
> parameters. With only 57 observations it is easy to overfit the models, and
> a standard linear model may be all that is necessary.
>
> On 14 May 2015 at 07:15, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:
>
>> Hello, this is Joaqu?n Aldabe from Uruguay. I?m trying to model shorebird
>> counts (Buff breasted Sandpiper, BBSA) with glmm (using lme4 package),
>> using continuous variables (grass height, field area, forest cover) and
>> one
>> factor variable (presence/absence of other shorebird species: American
>> Golden Plover, AMGP). I sampled 19 fields during three years in December.
>> I?m interested in identifying predictors correlated with BBSA counts. I
>> used Year as a random effect as I?m not interested in Year as a fix effect
>> and because fields were counted three times (pseudoreplication).
>>
>> The model doesn?t converge, and the output showed that the factorial
>> variable has not a significant effect. This is weird as in every field I
>> observed the Buff breasted Sandpiper I also observed the other
>> species. When I take AMGP out, the model runs ok.
>>
>> This is the model I?m trying to run:
>>
>>
>> mysub3.3<-glmer(BBSA~Grass_height+Field_area+Field_enclosure_700m+Grass_height*Field_enclosure_700m+fAMGP+(1|fYear),family="poisson",
>> data=mysub3.2)
>>
>> continuous variables were scaled.
>>
>> I can send de data frame if somebody is interested.
>>
>> Thanks in advanced for helping me on my master thesis.
>>
>> Cheers,
>>
>> Joaqu?n.
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Building E4A, room 526
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:29}}


From emre_marmara2002 at yahoo.com  Thu May 14 16:43:18 2015
From: emre_marmara2002 at yahoo.com (emre karaman)
Date: Thu, 14 May 2015 07:43:18 -0700
Subject: [R-sig-ME] direct-maternal correlation
Message-ID: <1431614598.61516.YahooMailBasic@web161002.mail.bf1.yahoo.com>

Dear Dr.,

I am running a multi-trait (4 traits) animal model including maternal and maternal permanent environmental effects. Is there a way to obtain correlations between direct and maternal effects in MCMCglmm package?

With Best

Emre


From joaquin.aldabe at gmail.com  Wed May 13 23:12:14 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 13 May 2015 18:12:14 -0300
Subject: [R-sig-ME] glmm question
Message-ID: <CAMM93=KN1_k5j_xvzZ=J=JzhJ-ovSPJupQZJ6_Qh4fxpVAEbyQ@mail.gmail.com>

Hello, this is Joaqu?n Aldabe from Uruguay. I?m trying to model shorebird
counts (Buff breasted Sandpiper, BBSA) with glmm (using lme4 package),
using continuous variables (grass height, field area, forest cover) and one
factor variable (presence/absence of other shorebird species: American
Golden Plover, AMGP). I sampled 19 fields during three years in December.
I?m interested in identifying predictors correlated with BBSA counts. I
used Year as a random effect as I?m not interested in Year as a fix effect
and because fields were counted three times (pseudoreplication).

The model doesn?t converge, and the output showed that the factorial
variable has not a significant effect. This is weird as in every field I
observed the Buff breasted Sandpiper I also observed the other
species. When I take AMGP out, the model runs ok.

This is the model I?m trying to run:

mysub3.3<-glmer(BBSA~Grass_height+Field_area+Field_enclosure_700m+Grass_height*Field_enclosure_700m+fAMGP+(1|fYear),family="poisson",
data=mysub3.2)

continuous variables were scaled.

I can send de data frame if somebody is interested.

Thanks in advanced for helping me on my master thesis.

Cheers,

Joaqu?n.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

From ken.beath at mq.edu.au  Fri May 15 07:57:49 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 15 May 2015 15:57:49 +1000
Subject: [R-sig-ME] glmm question
In-Reply-To: <CAMM93=L=amxdE__PS2F06V4Zhz1zU3ZifBaDLT_8R2hxGMUAFA@mail.gmail.com>
References: <CAMM93=LxSztxBoWPvMXC6vs7VWYK_ET2L8D8UG2HFtkxzdS70Q@mail.gmail.com>
	<CAF5_5cxHj81UC9_pV5OdMkBYQWeSkkNdt2L-f11BKeyAp5bCbw@mail.gmail.com>
	<CAMM93=L=amxdE__PS2F06V4Zhz1zU3ZifBaDLT_8R2hxGMUAFA@mail.gmail.com>
Message-ID: <CAF5_5cz8xQu8FCX9ja1kyHuq1nFjdPJs8F7jsnaDGiDbrvtuaw@mail.gmail.com>

I think you would be better off to start with a mixed effects model with a
random effect for site and a fixed effect for year.

All a random effect is doing is to model the correlation between responses
allowing for other variables, in other words the residuals, by conditioning
on a variable that is unobserved. For the years there are only 3 so it is
just as easy or easier to model them using a known variable, the actual
year. It is also difficult to think of them as a random sample of years.
Now for the sites you would expect the same, that the 3 measurements within
a site, representing the 3 years would be correlated. Now it is reasonable
to model them using a random effect, as otherwise there would need to be a
fixed effect for each site, a large number of parameters. It is possible
that this random effect has variance zero then the model reverts to a
standard glm.

On 14 May 2015 at 22:55, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:

> Thanks a lot Ken for your response. I had decided to use mix model with
> random effects because I have repeated measures in each field (one per
> year). If I perform a glm, how can I manage the pseudoreplication?
> (repeated counts on the same field)
>
> I have one data per field per year. So, no hierarchical or nested
> structure of the data. Can I use field as a random effect anyway?
>
> Thanks a lot for your help.
>
> Cheers,
> Joaqu?n.
>
> 2015-05-13 19:17 GMT-03:00 Ken Beath <ken.beath at mq.edu.au>:
>
> Having a random effect with only 3 levels is not recommended, it usually
>> gives problems fitting. There are also some philosophical questions about
>> its use as a random effect.
>>
>> A random effect for field is reasonable, but you may be fitting too many
>> parameters. With only 57 observations it is easy to overfit the models, and
>> a standard linear model may be all that is necessary.
>>
>> On 14 May 2015 at 07:15, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:
>>
>>> Hello, this is Joaqu?n Aldabe from Uruguay. I?m trying to model shorebird
>>> counts (Buff breasted Sandpiper, BBSA) with glmm (using lme4 package),
>>> using continuous variables (grass height, field area, forest cover) and
>>> one
>>> factor variable (presence/absence of other shorebird species: American
>>> Golden Plover, AMGP). I sampled 19 fields during three years in December.
>>> I?m interested in identifying predictors correlated with BBSA counts. I
>>> used Year as a random effect as I?m not interested in Year as a fix
>>> effect
>>> and because fields were counted three times (pseudoreplication).
>>>
>>> The model doesn?t converge, and the output showed that the factorial
>>> variable has not a significant effect. This is weird as in every field I
>>> observed the Buff breasted Sandpiper I also observed the other
>>> species. When I take AMGP out, the model runs ok.
>>>
>>> This is the model I?m trying to run:
>>>
>>>
>>> mysub3.3<-glmer(BBSA~Grass_height+Field_area+Field_enclosure_700m+Grass_height*Field_enclosure_700m+fAMGP+(1|fYear),family="poisson",
>>> data=mysub3.2)
>>>
>>> continuous variables were scaled.
>>>
>>> I can send de data frame if somebody is interested.
>>>
>>> Thanks in advanced for helping me on my master thesis.
>>>
>>> Cheers,
>>>
>>> Joaqu?n.
>>>
>>> --
>>> *Joaqu?n Aldabe*
>>>
>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>
>>> *Departamento de Conservaci?n*
>>> Aves Uruguay
>>> BirdLife International
>>> Canelones 1164, Montevideo
>>>
>>> https://sites.google.com/site/joaquin.aldabe
>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Building E4A, room 526
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and may contain
>> confidential information.  If you are not the intended recipient, please
>> delete it and notify the sender.  Views expressed in this message are those
>> of the individual sender, and are not necessarily the views of the Faculty
>> of Science, Department of Statistics or Macquarie University.
>>
>>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From susanne.stat at gmx.de  Fri May 15 14:28:29 2015
From: susanne.stat at gmx.de (Susanne Susanne)
Date: Fri, 15 May 2015 14:28:29 +0200
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
Message-ID: <trinity-005f2089-7497-4d7e-b409-bf9ca61f473b-1431692909407@3capp-gmx-bs66>

Dear Mr Bates and Mr Bolker, Dear R-list,
?
I have a question regarding the lme4 package and would be very thankful if you could help me.
My data consists of several clusters with repeated measurements x.
Therefore, I want to use the lmer() function to regress the data using a mixed model:
?
lmer(y ~ x + (x | cluster).
?
I want to weight clusters, which have more measurements than others, slightly higher, as they provide more information.
?
Is this done automatically in the lmer() function or should I do it manually by myself? And how could this be realized?
?
I tried out small examples with fictitious data (and quite a few with real data) but it seems impossible for me to decide whether lmer() is weighting these clusters higher.
If I weight some clusters higher with the ?weights=? argument, it seems to matter how many measurements the cluster has. If I set default weights it doesn't seem to matter.
?
Many thanks in advance,
?
Yours sincerely,

Susanne


From romunov at gmail.com  Fri May 15 14:36:33 2015
From: romunov at gmail.com (romunov)
Date: Fri, 15 May 2015 14:36:33 +0200
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
In-Reply-To: <trinity-005f2089-7497-4d7e-b409-bf9ca61f473b-1431692909407@3capp-gmx-bs66>
References: <trinity-005f2089-7497-4d7e-b409-bf9ca61f473b-1431692909407@3capp-gmx-bs66>
Message-ID: <CAHT1vpjS=MPHEh0KNymVC_wsYbycNtqtUNFKRzKCZZNWyMrfeg@mail.gmail.com>

Hi,

something similar has been discussed before. Have you seen this?
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022481.html

Cheers,
Roman


On Fri, May 15, 2015 at 2:28 PM, Susanne Susanne <susanne.stat at gmx.de>
wrote:

> Dear Mr Bates and Mr Bolker, Dear R-list,
>
> I have a question regarding the lme4 package and would be very thankful if
> you could help me.
> My data consists of several clusters with repeated measurements x.
> Therefore, I want to use the lmer() function to regress the data using a
> mixed model:
>
> lmer(y ~ x + (x | cluster).
>
> I want to weight clusters, which have more measurements than others,
> slightly higher, as they provide more information.
>
> Is this done automatically in the lmer() function or should I do it
> manually by myself? And how could this be realized?
>
> I tried out small examples with fictitious data (and quite a few with real
> data) but it seems impossible for me to decide whether lmer() is weighting
> these clusters higher.
> If I weight some clusters higher with the ?weights=? argument, it seems to
> matter how many measurements the cluster has. If I set default weights it
> doesn't seem to matter.
>
> Many thanks in advance,
>
> Yours sincerely,
>
> Susanne
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From carbrae at gmail.com  Fri May 15 16:07:27 2015
From: carbrae at gmail.com (Bradley Carlson)
Date: Fri, 15 May 2015 10:07:27 -0400
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
In-Reply-To: <trinity-005f2089-7497-4d7e-b409-bf9ca61f473b-1431692909407@3capp-gmx-bs66>
References: <trinity-005f2089-7497-4d7e-b409-bf9ca61f473b-1431692909407@3capp-gmx-bs66>
Message-ID: <CAF37_Nd37mTvdwxK_VjC_t_rxWa1aDnNhGzKtFaxSoPDqzRP4w@mail.gmail.com>

Despite searching for previous discussions of the issue (which are often
wrestling with more specific questions than the one stated here by
Susanne), I too am confused about how lmer handles it when there is
variation in size among different groups, clusters, or whatever we want to
call levels of a random effect. Maybe I'm using the wrong search terms, but
my efforts seem to reveal that many people are confused by this and - with
the explosion of mixed models in research - are in need of guidance to
prevent serious but simple errors in model specification from being
published. Is there anyone who can give some straightforward guidance on
the issues?

What is the best practice(s) for estimating the effect of an independent
variable in a basic LMM (Y~X + (1|Group)) where the number of data points
varies among the groups?

Thank you in advance to whoever can shed some light!

On Fri, May 15, 2015 at 8:28 AM, Susanne Susanne <susanne.stat at gmx.de>
wrote:

> Dear Mr Bates and Mr Bolker, Dear R-list,
>
> I have a question regarding the lme4 package and would be very thankful if
> you could help me.
> My data consists of several clusters with repeated measurements x.
> Therefore, I want to use the lmer() function to regress the data using a
> mixed model:
>
> lmer(y ~ x + (x | cluster).
>
> I want to weight clusters, which have more measurements than others,
> slightly higher, as they provide more information.
>
> Is this done automatically in the lmer() function or should I do it
> manually by myself? And how could this be realized?
>
> I tried out small examples with fictitious data (and quite a few with real
> data) but it seems impossible for me to decide whether lmer() is weighting
> these clusters higher.
> If I weight some clusters higher with the ?weights=? argument, it seems to
> matter how many measurements the cluster has. If I set default weights it
> doesn't seem to matter.
>
> Many thanks in advance,
>
> Yours sincerely,
>
> Susanne
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN

Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
Website: https://sites.google.com/site/bradleyecarlson/home

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri May 15 16:25:26 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 15 May 2015 10:25:26 -0400
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
In-Reply-To: <CAHT1vpjS=MPHEh0KNymVC_wsYbycNtqtUNFKRzKCZZNWyMrfeg@mail.gmail.com>
References: <trinity-005f2089-7497-4d7e-b409-bf9ca61f473b-1431692909407@3capp-gmx-bs66>
	<CAHT1vpjS=MPHEh0KNymVC_wsYbycNtqtUNFKRzKCZZNWyMrfeg@mail.gmail.com>
Message-ID: <555601D6.60103@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  It really depends what you mean by "weight clusters which have more
measurements slightly higher".  Without any more detail about your
intended statistical model I would *guess* that the model you specify
below would be appropriate, but it's really hard to tell with this
level of detail.  Can you point e.g. to a paper that uses similar
techniques and specifies the  model it is using explicitly?

On 15-05-15 08:36 AM, romunov wrote:
> Hi,
> 
> something similar has been discussed before. Have you seen this? 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022481.html
>
>  Cheers, Roman
> 
> 
> On Fri, May 15, 2015 at 2:28 PM, Susanne Susanne
> <susanne.stat at gmx.de> wrote:
> 
>> Dear Mr Bates and Mr Bolker, Dear R-list,
>> 
>> I have a question regarding the lme4 package and would be very
>> thankful if you could help me. My data consists of several
>> clusters with repeated measurements x. Therefore, I want to use
>> the lmer() function to regress the data using a mixed model:
>> 
>> lmer(y ~ x + (x | cluster).
>> 
>> I want to weight clusters, which have more measurements than
>> others, slightly higher, as they provide more information.
>> 
>> Is this done automatically in the lmer() function or should I do
>> it manually by myself? And how could this be realized?
>> 
>> I tried out small examples with fictitious data (and quite a few
>> with real data) but it seems impossible for me to decide whether
>> lmer() is weighting these clusters higher. If I weight some
>> clusters higher with the ?weights=? argument, it seems to matter
>> how many measurements the cluster has. If I set default weights
>> it doesn't seem to matter.
>> 
>> Many thanks in advance,
>> 
>> Yours sincerely,
>> 
>> Susanne
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVVgHWAAoJEOCV5YRblxUHdW0H/RZ4yWDE/x7BiFswuYvFHYrI
huKSHvJYc213Uw3awx3A8qNcTnmarq3XiHaUg2OxnSnWcFWUEyya1g9+WiECHj77
40SfUq8RG7RtgzJBDzs5r3SdPtNE7Iz9sCCygqVXkKRMZwpCxN4fVxvBgLfmvTg5
zBnUiSmoOZtd/SPN2Kb0exBDX6PYX20vnVjknmMEOa7/sCkwfObY78ag89Vq60hd
sSK2Je+5woDkDwP8Z+Nrdp6fS+FMwmn41+5vftoQTtgWmq7a5bm7q3YgjVJW8r3Z
fuRWz7Io76yTK463qPJdXHRN+GDrl/bJ1PNYp1fBtx3Mr5CDYx4mlSYdI8yUFYE=
=oycY
-----END PGP SIGNATURE-----


From stevedrd at yahoo.com  Fri May 15 16:54:46 2015
From: stevedrd at yahoo.com (Steve Denham)
Date: Fri, 15 May 2015 14:54:46 +0000 (UTC)
Subject: [R-sig-ME] toxicology dietary subchronic feed/weight analysis
In-Reply-To: <D5ED07A4EA222E42AF840A9EEF264880016B3C72F6@FSEXMBX01.foodstandards.gov.au>
References: <D5ED07A4EA222E42AF840A9EEF264880016B3C72F6@FSEXMBX01.foodstandards.gov.au>
Message-ID: <724877855.1353848.1431701686570.JavaMail.yahoo@mail.yahoo.com>

To get around the "missingness", consider expressing feed intake as cumulative feed intake up to each body weight. ?This will match everything up, AND put BW and FI on the same unit basis (total grams). ?I would use the model expressed, possibly fitting an autoregressive covariance structure.?Steve Denham
Director, Biostatistics
MPI Research, Inc.
 
      From: "Gosse, Michelle" <Michelle.Gosse at foodstandards.gov.au>
 To: "r-sig-mixed-models at r-project.org" <R-sig-mixed-models at r-project.org> 
 Sent: Sunday, May 10, 2015 5:32 PM
 Subject: [R-sig-ME] toxicology dietary subchronic feed/weight analysis
   
Hi all,

Still continuing on the dataset I have for the effect of two toxins on rats, I managed to fit very nice linear mixed effects models for the effects on the toxins on body weight over time, using weight = toxin * time + (time + 1 | subject.ID) as per Steven Pierce's suggestion.

I didn't need to get into a nonlinear mixed effect model as the results were very nice staying within a linear framework.

The final analysis I need to do is to examine feed intake and see how this is associated with body weight, time, and drug. I have feed intake measured daily, so 28 intake data points per subject, but only 7 weight data points, so while I have repeated measures for both, I do not have a fully linked intake-weight series.

The research question is whether the toxin influenced feed intake (feed palatability issue). I'm interested in intake slopes/partial slopes, but obviously body weight should be the main driver of feed intake (heavier rats eat more).

I'm thinking of an analysis similar to: intake = toxin*body weight*time (time +1|subject.ID)

But I'm not sure I have the sample size to do a three-way effect, and I don't know that this is the correct model specification given that I have weight data which is not missing at random - all the rats were measured on? specific days such as Day 1, Day 4, Day 7.

Has anyone worked with a similar dataset to advise what model to fit.

Cheers
Michelle, note: I do not work Fridays


**********************************************************************
This email and any files transmitted with it are confide...{{dropped:12}}

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   

	[[alternative HTML version deleted]]


From stevedrd at yahoo.com  Fri May 15 16:59:36 2015
From: stevedrd at yahoo.com (Steve Denham)
Date: Fri, 15 May 2015 14:59:36 +0000 (UTC)
Subject: [R-sig-ME] toxicology dietary subchronic feed/weight analysis
In-Reply-To: <CAJuCY5xhMRNv8-gMw+4CFqZONi0Q_ADr6s1DLa=PsfZyjK_8-g@mail.gmail.com>
References: <CAJuCY5xhMRNv8-gMw+4CFqZONi0Q_ADr6s1DLa=PsfZyjK_8-g@mail.gmail.com>
Message-ID: <2013168119.1372985.1431701976828.JavaMail.yahoo@mail.yahoo.com>

Really no need for imputation if feed intake is re-parameterized as cumulative feed intake to each weight date. ?Granted this greatly reduces the number of observations (28 to 7) but it aligns each.
I do like the idea of a hierarchical model in this case as the best way to handle a continuously measure covariate.?Steve Denham
Director, Biostatistics
MPI Research, Inc.
 
      From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
 To: "Gosse, Michelle" <Michelle.Gosse at foodstandards.gov.au> 
Cc: "r-sig-mixed-models at r-project.org" <R-sig-mixed-models at r-project.org> 
 Sent: Monday, May 11, 2015 3:04 AM
 Subject: Re: [R-sig-ME] toxicology dietary subchronic feed/weight analysis
   
Dear Michelle,

The best solution for the next study is to measure weight as the same
frequency as the intake ;-)

I see two possible solutions for your current study. 1) Use multiple
imputation on the missing values of weight based on your weight model. 2)
Go Bayesian an fit both the weight and intake models simultaneously use a
hierarchical model.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-10 23:32 GMT+02:00 Gosse, Michelle <
Michelle.Gosse at foodstandards.gov.au>:

> Hi all,
>
> Still continuing on the dataset I have for the effect of two toxins on
> rats, I managed to fit very nice linear mixed effects models for the
> effects on the toxins on body weight over time, using weight = toxin * time
> + (time + 1 | subject.ID) as per Steven Pierce's suggestion.
>
> I didn't need to get into a nonlinear mixed effect model as the results
> were very nice staying within a linear framework.
>
> The final analysis I need to do is to examine feed intake and see how this
> is associated with body weight, time, and drug. I have feed intake measured
> daily, so 28 intake data points per subject, but only 7 weight data points,
> so while I have repeated measures for both, I do not have a fully linked
> intake-weight series.
>
> The research question is whether the toxin influenced feed intake (feed
> palatability issue). I'm interested in intake slopes/partial slopes, but
> obviously body weight should be the main driver of feed intake (heavier
> rats eat more).
>
> I'm thinking of an analysis similar to: intake = toxin*body weight*time
> (time +1|subject.ID)
>
> But I'm not sure I have the sample size to do a three-way effect, and I
> don't know that this is the correct model specification given that I have
> weight data which is not missing at random - all the rats were measured on
> specific days such as Day 1, Day 4, Day 7.
>
> Has anyone worked with a similar dataset to advise what model to fit.
>
> Cheers
> Michelle, note: I do not work Fridays
>
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:12}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

??? [[alternative HTML version deleted]]



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   

	[[alternative HTML version deleted]]


From susanne.stat at gmx.de  Fri May 15 17:45:35 2015
From: susanne.stat at gmx.de (Susanne Susanne)
Date: Fri, 15 May 2015 17:45:35 +0200
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
In-Reply-To: <555601D6.60103@gmail.com>
References: <trinity-005f2089-7497-4d7e-b409-bf9ca61f473b-1431692909407@3capp-gmx-bs66>
	<CAHT1vpjS=MPHEh0KNymVC_wsYbycNtqtUNFKRzKCZZNWyMrfeg@mail.gmail.com>,
	<555601D6.60103@gmail.com>
Message-ID: <trinity-126d78a3-1a3c-4f58-a9b4-a11de0152194-1431704735370@3capp-gmx-bs66>

A non-text attachment was scrubbed...
Name: Plots.png
Type: image/png
Size: 52978 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150515/9670d22d/attachment-0001.png>

From susanne.stat at gmx.de  Fri May 15 19:20:54 2015
From: susanne.stat at gmx.de (Susanne Susanne)
Date: Fri, 15 May 2015 19:20:54 +0200
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
Message-ID: <trinity-2eba7280-a3b6-4a23-8f97-93780121c96d-1431710454689@3capp-gmx-bs18>

A non-text attachment was scrubbed...
Name: Plots.png
Type: image/png
Size: 52978 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150515/d260d9ad/attachment-0001.png>

From asher.strauss at gmail.com  Sat May 16 08:19:05 2015
From: asher.strauss at gmail.com (Asher Strauss)
Date: Sat, 16 May 2015 09:19:05 +0300
Subject: [R-sig-ME] estimating AR1 parameters of level one error using lme
Message-ID: <CAJoaH8ke3WhTQmwhZokEzbhb7gB9GbA_X_5Vh+N+Vm9LvVgKEQ@mail.gmail.com>

Hi all,
I am new to using R for mixed effects (have been using SPSS until now),
please for give me if this is a trivial question.

I am trying to understand how to estimate AR1 parameters of level one error
using lme (I have understood that specifying level one variance-covariance
matrix is not easily possible in lmer, is this true?).

When using SPSS one estimates two parameters: AR1 diagonal and AR1 rho. I
am searching for an equivalent command in R.

for example using the Glucose data from the nlme package:

data(Glucose)

fGlucose<-filter(Glucose,Meal=="10am")

summary(
lme(
fixed=conc~Time,
random=~1+Time|Subject,
method="REML",
data=fGlucose,
na.action="na.omit",
correlation=corAR1(form=~1+Time|Subject))
)


I get an out put of:

Correlation Structure: ARMA(1,0)
 Formula: ~1 + Time | Subject
 Parameter estimate(s):
     Phi1
0.4334469

is Phi1 equivalent to Rho?  I do not believe so, since when estimating AR1
diagonal and AR1 rho using SPSS I received 1.349 and -0.942 respectively.

here is the SPSS syntax I am using:
COMPUTE filter_$=(Meal="10am").
VARIABLE LABELS filter_$ 'Meal="10am" (FILTER)'.
VALUE LABELS filter_$ 0 'Not Selected' 1 'Selected'.
FORMATS filter_$ (f1.0).
FILTER BY filter_$.
EXECUTE.

MIXED conc WITH Time
 /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
PCONVERGE(0.000001, ABSOLUTE)
  /FIXED=INTERCEPT Time | SSTYPE(3)
  /METHOD=REML
  /PRINT=SOLUTION TESTCOV
  /RANDOM=INTERCEPT Time | SUBJECT(Subject)
  /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).

Thank you!
Asher

	[[alternative HTML version deleted]]


From szymek.drobniak at uj.edu.pl  Thu May 14 23:38:45 2015
From: szymek.drobniak at uj.edu.pl (Szymek Drobniak)
Date: Thu, 14 May 2015 21:38:45 +0000
Subject: [R-sig-ME] genetic effects and multiple membership in MCMCglmm
 (Alexandre Martin)
Message-ID: <CANXb-o5zZBsrPa_6OmQhJcgLQpSxggydTeMhEcGKMFYhsRSWNQ@mail.gmail.com>

Hello Alexandre,

using ped assigns a given correlation structure only to the "animal" random
effect. You have to create an inverse of A matrix:

my_inverse <- inverseA(ped)$Ainv

and assign it in MCMCglmm to specific random effects:

MCMCglmm(Y~1,
random=~animal+mm(m1+m2+m3),
ginverse=list(animal=my_inverse, m1=my_inverse,
m2=my_inverse,m3=my_inverse), data=dat, pr=T).

Cheers
Szymek

	[[alternative HTML version deleted]]


From Michelle.Gosse at foodstandards.gov.au  Mon May 18 01:55:22 2015
From: Michelle.Gosse at foodstandards.gov.au (Gosse, Michelle)
Date: Sun, 17 May 2015 23:55:22 +0000
Subject: [R-sig-ME] toxicology dietary subchronic feed/weight analysis
In-Reply-To: <2013168119.1372985.1431701976828.JavaMail.yahoo@mail.yahoo.com>
References: <CAJuCY5xhMRNv8-gMw+4CFqZONi0Q_ADr6s1DLa=PsfZyjK_8-g@mail.gmail.com>
	<2013168119.1372985.1431701976828.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D5ED07A4EA222E42AF840A9EEF264880016B3CA7B0@FSEXMBX01.foodstandards.gov.au>

Thanks for those suggestions. I?m currently working out the hierarchical model structure.

Cheers
Michelle, note: I do not work Fridays

From: Steve Denham [mailto:stevedrd at yahoo.com]
Sent: Saturday, 16 May 2015 1:00 AM
To: Thierry Onkelinx; Gosse, Michelle
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] toxicology dietary subchronic feed/weight analysis

Really no need for imputation if feed intake is re-parameterized as cumulative feed intake to each weight date.  Granted this greatly reduces the number of observations (28 to 7) but it aligns each.

I do like the idea of a hierarchical model in this case as the best way to handle a continuously measure covariate.

Steve Denham
Director, Biostatistics
MPI Research, Inc.


________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
To: "Gosse, Michelle" <Michelle.Gosse at foodstandards.gov.au<mailto:Michelle.Gosse at foodstandards.gov.au>>
Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>
Sent: Monday, May 11, 2015 3:04 AM
Subject: Re: [R-sig-ME] toxicology dietary subchronic feed/weight analysis

Dear Michelle,

The best solution for the next study is to measure weight as the same
frequency as the intake ;-)

I see two possible solutions for your current study. 1) Use multiple
imputation on the missing values of weight based on your weight model. 2)
Go Bayesian an fit both the weight and intake models simultaneously use a
hierarchical model.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-10 23:32 GMT+02:00 Gosse, Michelle <
Michelle.Gosse at foodstandards.gov.au<mailto:Michelle.Gosse at foodstandards.gov.au>>:

> Hi all,
>
> Still continuing on the dataset I have for the effect of two toxins on
> rats, I managed to fit very nice linear mixed effects models for the
> effects on the toxins on body weight over time, using weight = toxin * time
> + (time + 1 | subject.ID) as per Steven Pierce's suggestion.
>
> I didn't need to get into a nonlinear mixed effect model as the results
> were very nice staying within a linear framework.
>
> The final analysis I need to do is to examine feed intake and see how this
> is associated with body weight, time, and drug. I have feed intake measured
> daily, so 28 intake data points per subject, but only 7 weight data points,
> so while I have repeated measures for both, I do not have a fully linked
> intake-weight series.
>
> The research question is whether the toxin influenced feed intake (feed
> palatability issue). I'm interested in intake slopes/partial slopes, but
> obviously body weight should be the main driver of feed intake (heavier
> rats eat more).
>
> I'm thinking of an analysis similar to: intake = toxin*body weight*time
> (time +1|subject.ID)
>
> But I'm not sure I have the sample size to do a three-way effect, and I
> don't know that this is the correct model specification given that I have
> weight data which is not missing at random - all the rats were measured on
> specific days such as Day 1, Day 4, Day 7.
>
> Has anyone worked with a similar dataset to advise what model to fit.
>
> Cheers
> Michelle, note: I do not work Fridays
>
>
> **********************************************************************
> This email and any files transmitted with it are confide...{{dropped:12}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

    [[alternative HTML version deleted]]



_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


**********************************************************************
This email and any files transmitted with it are confidential and
intended solely for the use of the individual or entity to whom they
are addressed. If you have received this email in error please notify
the system manager.

Scanned by Clearswift SECURE Email Gateway at Food Standards ANZ.

**********************************************************************

	[[alternative HTML version deleted]]


From Daniel.Wright at act.org  Mon May 18 20:01:36 2015
From: Daniel.Wright at act.org (Daniel Wright)
Date: Mon, 18 May 2015 18:01:36 +0000
Subject: [R-sig-ME] estimating AR1 parameters of level one error using
	lme
In-Reply-To: <CAJoaH8ke3WhTQmwhZokEzbhb7gB9GbA_X_5Vh+N+Vm9LvVgKEQ@mail.gmail.com>
References: <CAJoaH8ke3WhTQmwhZokEzbhb7gB9GbA_X_5Vh+N+Vm9LvVgKEQ@mail.gmail.com>
Message-ID: <BY2PR04MB80769100E87EC41CDF68B79EAC40@BY2PR04MB807.namprd04.prod.outlook.com>

It may also be convenient to use the gls function in nlme.

This is used in https://www.researchgate.net/publication/23134911_Multilevel_modelling_Beyond_the_basic_applications
and in http://www.ats.ucla.edu/stat/r/examples/alda/ch7.htm which is the UCLA page for Singer and Willet's wonderful book.


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Asher Strauss
Sent: Saturday, May 16, 2015 1:19 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] estimating AR1 parameters of level one error using lme

Hi all,
I am new to using R for mixed effects (have been using SPSS until now), please for give me if this is a trivial question.

I am trying to understand how to estimate AR1 parameters of level one error using lme (I have understood that specifying level one variance-covariance matrix is not easily possible in lmer, is this true?).

When using SPSS one estimates two parameters: AR1 diagonal and AR1 rho. I am searching for an equivalent command in R.

for example using the Glucose data from the nlme package:

data(Glucose)

fGlucose<-filter(Glucose,Meal=="10am")

summary(
lme(
fixed=conc~Time,
random=~1+Time|Subject,
method="REML",
data=fGlucose,
na.action="na.omit",
correlation=corAR1(form=~1+Time|Subject))
)


I get an out put of:

Correlation Structure: ARMA(1,0)
 Formula: ~1 + Time | Subject
 Parameter estimate(s):
     Phi1
0.4334469

is Phi1 equivalent to Rho?  I do not believe so, since when estimating AR1 diagonal and AR1 rho using SPSS I received 1.349 and -0.942 respectively.

here is the SPSS syntax I am using:
COMPUTE filter_$=(Meal="10am").
VARIABLE LABELS filter_$ 'Meal="10am" (FILTER)'.
VALUE LABELS filter_$ 0 'Not Selected' 1 'Selected'.
FORMATS filter_$ (f1.0).
FILTER BY filter_$.
EXECUTE.

MIXED conc WITH Time
 /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001, ABSOLUTE)
  /FIXED=INTERCEPT Time | SSTYPE(3)
  /METHOD=REML
  /PRINT=SOLUTION TESTCOV
  /RANDOM=INTERCEPT Time | SUBJECT(Subject)
  /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).

Thank you!
Asher

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From asher.strauss at gmail.com  Tue May 19 10:55:45 2015
From: asher.strauss at gmail.com (Asher Strauss)
Date: Tue, 19 May 2015 11:55:45 +0300
Subject: [R-sig-ME] estimating AR1 parameters of level one error using
	lme
In-Reply-To: <BY2PR04MB80769100E87EC41CDF68B79EAC40@BY2PR04MB807.namprd04.prod.outlook.com>
References: <CAJoaH8ke3WhTQmwhZokEzbhb7gB9GbA_X_5Vh+N+Vm9LvVgKEQ@mail.gmail.com>
	<BY2PR04MB80769100E87EC41CDF68B79EAC40@BY2PR04MB807.namprd04.prod.outlook.com>
Message-ID: <CAJoaH8na0rtH+Nyjzc-hGc47RVz8U7vEg=Txq3gU6zvbJ0Hfmg@mail.gmail.com>

Hi Daniel
and thank you very much for your reply!

I went over the documents you sent me, though couldn't find the sdtalt
package :(

I think using  lme is more suitable for my purposes since it is important
for me include random effects in my model.

I am still stuck with understanding the right code in R to specify a
homogeneous variance structure with correlations structured as AR1 (model
13 in your paper
https://www.researchgate.net/publication/23134911_Multilevel_modelling_Beyond_the_basic_applications
).
As I wrote in my previous message specifying this model in R (if I got the
code right - I assume not...) and in SPSS produces completely different
results.

I will be grateful if you or anybody else can point me towards a solution.

I am repeating here my previous example to make my difficulty easier to
address:

for example using the Glucose data from the nlme package:

data(Glucose)

fGlucose<-filter(Glucose,Meal=="10am")

summary(
lme(
fixed=conc~Time,
random=~1+Time|Subject,
method="REML",
data=fGlucose,
na.action="na.omit",
correlation=corAR1(form=~1+Time|Subject))
)


I get an output of:

Correlation Structure: ARMA(1,0)
 Formula: ~1 + Time | Subject
 Parameter estimate(s):
     Phi1
0.4334469

I am assuming  Phi1 is equivalent to Rho (am I right?). What makes me
suspect I am wrong, and confuses me, is that when estimating AR1
diagonal (homogeneous
level one error variance) and AR1 rho (the auto regression parameter)
 using SPSS I received 1.349 and -0.942 respectively.

here is the SPSS syntax I am using  on the same data set (Glucose):

COMPUTE filter_$=(Meal="10am").
VARIABLE LABELS filter_$ 'Meal="10am" (FILTER)'.
VALUE LABELS filter_$ 0 'Not Selected' 1 'Selected'.
FORMATS filter_$ (f1.0).
FILTER BY filter_$.
EXECUTE.

MIXED conc WITH Time
 /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
PCONVERGE(0.000001, ABSOLUTE)
  /FIXED=INTERCEPT Time | SSTYPE(3)
  /METHOD=REML
  /PRINT=SOLUTION TESTCOV
  /RANDOM=INTERCEPT Time | SUBJECT(Subject)
  /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).

It would be really great if you or anybody else can assist me here!
Thank you!

Best
Asher Strauss

On Mon, May 18, 2015 at 9:01 PM, Daniel Wright <Daniel.Wright at act.org>
wrote:

> It may also be convenient to use the gls function in nlme.
>
> This is used in
> https://www.researchgate.net/publication/23134911_Multilevel_modelling_Beyond_the_basic_applications
> and in http://www.ats.ucla.edu/stat/r/examples/alda/ch7.htm which is the
> UCLA page for Singer and Willet's wonderful book.
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Asher Strauss
> Sent: Saturday, May 16, 2015 1:19 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] estimating AR1 parameters of level one error using lme
>
> Hi all,
> I am new to using R for mixed effects (have been using SPSS until now),
> please for give me if this is a trivial question.
>
> I am trying to understand how to estimate AR1 parameters of level one
> error using lme (I have understood that specifying level one
> variance-covariance matrix is not easily possible in lmer, is this true?).
>
> When using SPSS one estimates two parameters: AR1 diagonal and AR1 rho. I
> am searching for an equivalent command in R.
>
> for example using the Glucose data from the nlme package:
>
> data(Glucose)
>
> fGlucose<-filter(Glucose,Meal=="10am")
>
> summary(
> lme(
> fixed=conc~Time,
> random=~1+Time|Subject,
> method="REML",
> data=fGlucose,
> na.action="na.omit",
> correlation=corAR1(form=~1+Time|Subject))
> )
>
>
> I get an out put of:
>
> Correlation Structure: ARMA(1,0)
>  Formula: ~1 + Time | Subject
>  Parameter estimate(s):
>      Phi1
> 0.4334469
>
> is Phi1 equivalent to Rho?  I do not believe so, since when estimating AR1
> diagonal and AR1 rho using SPSS I received 1.349 and -0.942 respectively.
>
> here is the SPSS syntax I am using:
> COMPUTE filter_$=(Meal="10am").
> VARIABLE LABELS filter_$ 'Meal="10am" (FILTER)'.
> VALUE LABELS filter_$ 0 'Not Selected' 1 'Selected'.
> FORMATS filter_$ (f1.0).
> FILTER BY filter_$.
> EXECUTE.
>
> MIXED conc WITH Time
>  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> PCONVERGE(0.000001, ABSOLUTE)
>   /FIXED=INTERCEPT Time | SSTYPE(3)
>   /METHOD=REML
>   /PRINT=SOLUTION TESTCOV
>   /RANDOM=INTERCEPT Time | SUBJECT(Subject)
>   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).
>
> Thank you!
> Asher
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue May 19 11:05:48 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 19 May 2015 11:05:48 +0200
Subject: [R-sig-ME] estimating AR1 parameters of level one error using
	lme
In-Reply-To: <CAJoaH8na0rtH+Nyjzc-hGc47RVz8U7vEg=Txq3gU6zvbJ0Hfmg@mail.gmail.com>
References: <CAJoaH8ke3WhTQmwhZokEzbhb7gB9GbA_X_5Vh+N+Vm9LvVgKEQ@mail.gmail.com>
	<BY2PR04MB80769100E87EC41CDF68B79EAC40@BY2PR04MB807.namprd04.prod.outlook.com>
	<CAJoaH8na0rtH+Nyjzc-hGc47RVz8U7vEg=Txq3gU6zvbJ0Hfmg@mail.gmail.com>
Message-ID: <CAJuCY5wDe-6rkJLrsNqba-QsdpYnLP28d7V3nqHh0199ak=VvA@mail.gmail.com>

Dear Asher,

I would focus on the mathematical expressions used for both the R and SPSS
models. Then it should be straightforward to see if both models fit the
same thing. And if so which parameters have the same interpretation.

You can find the expressions for nlme in Pinheiro and Bates (2000). I can't
help you with the SPSS part.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-19 10:55 GMT+02:00 Asher Strauss <asher.strauss at gmail.com>:

> Hi Daniel
> and thank you very much for your reply!
>
> I went over the documents you sent me, though couldn't find the sdtalt
> package :(
>
> I think using  lme is more suitable for my purposes since it is important
> for me include random effects in my model.
>
> I am still stuck with understanding the right code in R to specify a
> homogeneous variance structure with correlations structured as AR1 (model
> 13 in your paper
>
> https://www.researchgate.net/publication/23134911_Multilevel_modelling_Beyond_the_basic_applications
> ).
> As I wrote in my previous message specifying this model in R (if I got the
> code right - I assume not...) and in SPSS produces completely different
> results.
>
> I will be grateful if you or anybody else can point me towards a solution.
>
> I am repeating here my previous example to make my difficulty easier to
> address:
>
> for example using the Glucose data from the nlme package:
>
> data(Glucose)
>
> fGlucose<-filter(Glucose,Meal=="10am")
>
> summary(
> lme(
> fixed=conc~Time,
> random=~1+Time|Subject,
> method="REML",
> data=fGlucose,
> na.action="na.omit",
> correlation=corAR1(form=~1+Time|Subject))
> )
>
>
> I get an output of:
>
> Correlation Structure: ARMA(1,0)
>  Formula: ~1 + Time | Subject
>  Parameter estimate(s):
>      Phi1
> 0.4334469
>
> I am assuming  Phi1 is equivalent to Rho (am I right?). What makes me
> suspect I am wrong, and confuses me, is that when estimating AR1
> diagonal (homogeneous
> level one error variance) and AR1 rho (the auto regression parameter)
>  using SPSS I received 1.349 and -0.942 respectively.
>
> here is the SPSS syntax I am using  on the same data set (Glucose):
>
> COMPUTE filter_$=(Meal="10am").
> VARIABLE LABELS filter_$ 'Meal="10am" (FILTER)'.
> VALUE LABELS filter_$ 0 'Not Selected' 1 'Selected'.
> FORMATS filter_$ (f1.0).
> FILTER BY filter_$.
> EXECUTE.
>
> MIXED conc WITH Time
>  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> PCONVERGE(0.000001, ABSOLUTE)
>   /FIXED=INTERCEPT Time | SSTYPE(3)
>   /METHOD=REML
>   /PRINT=SOLUTION TESTCOV
>   /RANDOM=INTERCEPT Time | SUBJECT(Subject)
>   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).
>
> It would be really great if you or anybody else can assist me here!
> Thank you!
>
> Best
> Asher Strauss
>
> On Mon, May 18, 2015 at 9:01 PM, Daniel Wright <Daniel.Wright at act.org>
> wrote:
>
> > It may also be convenient to use the gls function in nlme.
> >
> > This is used in
> >
> https://www.researchgate.net/publication/23134911_Multilevel_modelling_Beyond_the_basic_applications
> > and in http://www.ats.ucla.edu/stat/r/examples/alda/ch7.htm which is the
> > UCLA page for Singer and Willet's wonderful book.
> >
> >
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:
> r-sig-mixed-models-bounces at r-project.org]
> > On Behalf Of Asher Strauss
> > Sent: Saturday, May 16, 2015 1:19 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] estimating AR1 parameters of level one error using
> lme
> >
> > Hi all,
> > I am new to using R for mixed effects (have been using SPSS until now),
> > please for give me if this is a trivial question.
> >
> > I am trying to understand how to estimate AR1 parameters of level one
> > error using lme (I have understood that specifying level one
> > variance-covariance matrix is not easily possible in lmer, is this
> true?).
> >
> > When using SPSS one estimates two parameters: AR1 diagonal and AR1 rho. I
> > am searching for an equivalent command in R.
> >
> > for example using the Glucose data from the nlme package:
> >
> > data(Glucose)
> >
> > fGlucose<-filter(Glucose,Meal=="10am")
> >
> > summary(
> > lme(
> > fixed=conc~Time,
> > random=~1+Time|Subject,
> > method="REML",
> > data=fGlucose,
> > na.action="na.omit",
> > correlation=corAR1(form=~1+Time|Subject))
> > )
> >
> >
> > I get an out put of:
> >
> > Correlation Structure: ARMA(1,0)
> >  Formula: ~1 + Time | Subject
> >  Parameter estimate(s):
> >      Phi1
> > 0.4334469
> >
> > is Phi1 equivalent to Rho?  I do not believe so, since when estimating
> AR1
> > diagonal and AR1 rho using SPSS I received 1.349 and -0.942 respectively.
> >
> > here is the SPSS syntax I am using:
> > COMPUTE filter_$=(Meal="10am").
> > VARIABLE LABELS filter_$ 'Meal="10am" (FILTER)'.
> > VALUE LABELS filter_$ 0 'Not Selected' 1 'Selected'.
> > FORMATS filter_$ (f1.0).
> > FILTER BY filter_$.
> > EXECUTE.
> >
> > MIXED conc WITH Time
> >  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> > SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> > PCONVERGE(0.000001, ABSOLUTE)
> >   /FIXED=INTERCEPT Time | SSTYPE(3)
> >   /METHOD=REML
> >   /PRINT=SOLUTION TESTCOV
> >   /RANDOM=INTERCEPT Time | SUBJECT(Subject)
> >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).
> >
> > Thank you!
> > Asher
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue May 19 14:55:28 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 19 May 2015 14:55:28 +0200
Subject: [R-sig-ME] estimating AR1 parameters of level one error
	using	lme
In-Reply-To: <CAJoaH8na0rtH+Nyjzc-hGc47RVz8U7vEg=Txq3gU6zvbJ0Hfmg@mail.gmail.com>
References: <CAJoaH8ke3WhTQmwhZokEzbhb7gB9GbA_X_5Vh+N+Vm9LvVgKEQ@mail.gmail.com>
	<BY2PR04MB80769100E87EC41CDF68B79EAC40@BY2PR04MB807.namprd04.prod.outlook.com>
	<CAJoaH8na0rtH+Nyjzc-hGc47RVz8U7vEg=Txq3gU6zvbJ0Hfmg@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0CA058FD@UM-MAIL4112.unimaas.nl>

First of all, double, no, tripple check that the data are exactly the same in R and in SPSS. I have seen too many cases of "Why are my results in R different than in <insert other software package here>?" that could be traced down to export/import issues/mistakes (e.g., things like -999 that are declared to be missing values in SPSS, but that are read in as is into R).

Assuming that the data are in fact the same -- yes, what is labeled 'Phi1' in the output from lme() is indeed the estimate of the autocorrelation parameter. However, there is already one thing that is different between your two models. In R, you used 'random=~1+Time|Subject' (you could also just write 'random=~Time|Subject' -- that does the same thing). That will add random intercepts and slopes to the model that are allowed to be correlated. In SPSS, you used '/RANDOM=INTERCEPT Time | SUBJECT(Subject)'. If I am not mistaken, the default is COVTYPE(VC), which adds random intercepts and slopes to the model, which are assumed to be independent. So, your models are not identical to begin with.

I would suggest to first fit the models without the AR(1) structure and make sure you get essentially the same results. Then you can add the AR(1) part and cross-check the results.

Best,
Wolfgang

--    
Wolfgang Viechtbauer, Ph.D., Statistician    
Department of Psychiatry and Neuropsychology    
School for Mental Health and Neuroscience    
Faculty of Health, Medicine, and Life Sciences    
Maastricht University, P.O. Box 616 (VIJV1)    
6200 MD Maastricht, The Netherlands    
+31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Asher Strauss
> Sent: Tuesday, May 19, 2015 10:56
> To: Daniel Wright
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] estimating AR1 parameters of level one error
> using lme
> 
> Hi Daniel
> and thank you very much for your reply!
> 
> I went over the documents you sent me, though couldn't find the sdtalt
> package :(
> 
> I think using  lme is more suitable for my purposes since it is important
> for me include random effects in my model.
> 
> I am still stuck with understanding the right code in R to specify a
> homogeneous variance structure with correlations structured as AR1 (model
> 13 in your paper
> https://www.researchgate.net/publication/23134911_Multilevel_modelling_Be
> yond_the_basic_applications
> ).
> As I wrote in my previous message specifying this model in R (if I got
> the
> code right - I assume not...) and in SPSS produces completely different
> results.
> 
> I will be grateful if you or anybody else can point me towards a
> solution.
> 
> I am repeating here my previous example to make my difficulty easier to
> address:
> 
> for example using the Glucose data from the nlme package:
> 
> data(Glucose)
> 
> fGlucose<-filter(Glucose,Meal=="10am")
> 
> summary(
> lme(
> fixed=conc~Time,
> random=~1+Time|Subject,
> method="REML",
> data=fGlucose,
> na.action="na.omit",
> correlation=corAR1(form=~1+Time|Subject))
> )
> 
> 
> I get an output of:
> 
> Correlation Structure: ARMA(1,0)
>  Formula: ~1 + Time | Subject
>  Parameter estimate(s):
>      Phi1
> 0.4334469
> 
> I am assuming  Phi1 is equivalent to Rho (am I right?). What makes me
> suspect I am wrong, and confuses me, is that when estimating AR1
> diagonal (homogeneous
> level one error variance) and AR1 rho (the auto regression parameter)
>  using SPSS I received 1.349 and -0.942 respectively.
> 
> here is the SPSS syntax I am using  on the same data set (Glucose):
> 
> COMPUTE filter_$=(Meal="10am").
> VARIABLE LABELS filter_$ 'Meal="10am" (FILTER)'.
> VALUE LABELS filter_$ 0 'Not Selected' 1 'Selected'.
> FORMATS filter_$ (f1.0).
> FILTER BY filter_$.
> EXECUTE.
> 
> MIXED conc WITH Time
>  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> SINGULAR(0.000000000001) HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> PCONVERGE(0.000001, ABSOLUTE)
>   /FIXED=INTERCEPT Time | SSTYPE(3)
>   /METHOD=REML
>   /PRINT=SOLUTION TESTCOV
>   /RANDOM=INTERCEPT Time | SUBJECT(Subject)
>   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).
> 
> It would be really great if you or anybody else can assist me here!
> Thank you!
> 
> Best
> Asher Strauss


From alexandre.m.martin at gmail.com  Tue May 19 16:29:33 2015
From: alexandre.m.martin at gmail.com (Alexandre Martin)
Date: Tue, 19 May 2015 10:29:33 -0400
Subject: [R-sig-ME] genetic effects and multiple membership in MCMCglmm
	(Alexandre Martin)
In-Reply-To: <CANXb-o5zZBsrPa_6OmQhJcgLQpSxggydTeMhEcGKMFYhsRSWNQ@mail.gmail.com>
References: <CANXb-o5zZBsrPa_6OmQhJcgLQpSxggydTeMhEcGKMFYhsRSWNQ@mail.gmail.com>
Message-ID: <00e101d09240$3a55ad00$af010700$@gmail.com>

Hi Szymek, 

 

Thank you very much for your excellent answer that allowed me to understand
a couple of things in MCMCglmm. 

Thanks again.

 

Alexandre

 

De : Szymek Drobniak [mailto:szymek.drobniak at uj.edu.pl] 
Envoy? : 14 mai 2015 17:39
? : r-sig-mixed-models at r-project.org
Cc : alexandre.m.martin at gmail.com
Objet : Re: genetic effects and multiple membership in MCMCglmm (Alexandre
Martin)

 

Hello Alexandre,

 

using ped assigns a given correlation structure only to the "animal" random
effect. You have to create an inverse of A matrix:

 

my_inverse <- inverseA(ped)$Ainv

 

and assign it in MCMCglmm to specific random effects:

 

MCMCglmm(Y~1,
random=~animal+mm(m1+m2+m3),

ginverse=list(animal=my_inverse, m1=my_inverse,
m2=my_inverse,m3=my_inverse), data=dat, pr=T).

 

Cheers

Szymek


	[[alternative HTML version deleted]]


From burwood70 at gmail.com  Wed May 20 13:13:37 2015
From: burwood70 at gmail.com (Steve Candy)
Date: Wed, 20 May 2015 21:13:37 +1000
Subject: [R-sig-ME] : estimating AR1 parameters of level one error
	using	lme
Message-ID: <006001d092ee$07dcb180$17961480$@gmail.com>

I question whether this model of dependency between residuals in repeated
measures analysis is sensible

> >   /RANDOM=INTERCEPT Time | SUBJECT(Subject)

corresponds to a random coefficients approach which implies a correlation
between time points within subjects which varies with time (also called
"the growth curve model" cf:  Diggle et al 2002 pg 98-99) while

> >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1)

also implies a correlation between time points within subjects which varies
with time (if the Phi1 is positive it implies a positive serial correlation
exponentially decaying to zero as the time lag increases).

Therefore these two error models compete with each other in explaining
correlation that varies with time which is very messy (i.e. what does the
theoretical semivariogram look like?)  and possibly over-parameterised.

However, it makes sense to combine random intercepts with an AR1 process
(Diggle et al. 2002, Section 5.2.3, Figure 5.4)

> >   /RANDOM=INTERCEPT | SUBJECT(Subject)
> >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).

My understanding is that the above SPSS error model is the same as the  lme
error model below  

> lme(
> fixed=conc~Time,
> random=~1|Subject,
> method="REML",
> data=fGlucose,
> na.action="na.omit",
> correlation=corAR1(form=~Time|Subject))

*Diggle, D. J., P. J. Heagerty, K. Y. Liang, and S. L. Zeger. 2002. Analysis
of Longitudinal Data. . Oxford University Press, Oxford, England.

Dr Steven G. Candy
Director/Consultant
SCANDY STATISTICAL MODELLING PTY LTD
(ABN: 83 601 268 419)
70 Burwood Drive
Blackmans Bay, TASMANIA, Australia 7052
Mobile: (61) 0439284983


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed May 20 14:10:53 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 20 May 2015 14:10:53 +0200
Subject: [R-sig-ME] : estimating AR1 parameters of level one error using
 lme
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0CA05B86@UM-MAIL4112.unimaas.nl>

It is certainly possible to have a model with random intercepts and slopes (for time) and also AR(1) correlated residuals over time within individuals. The random slopes model differences in the trend between individuals, while the AR(1) structure models how the residuals are fluctuating around the person-specific slopes within individuals. Of course, you need to have a sufficient number of follow-up measurements within individuals to distinguish those two elements. But this is certainly possible. And in fact, ignoring serial correlation in the residuals when it is present could lead to inflated Type I error rates for the mean trend effect.

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Steve Candy
> Sent: Wednesday, May 20, 2015 13:14
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] : estimating AR1 parameters of level one error
> using lme
> 
> I question whether this model of dependency between residuals in repeated
> measures analysis is sensible
> 
> > >   /RANDOM=INTERCEPT Time | SUBJECT(Subject)
> 
> corresponds to a random coefficients approach which implies a correlation
> between time points within subjects which varies with time (also called
> "the growth curve model" cf:  Diggle et al 2002 pg 98-99) while
> 
> > >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1)
> 
> also implies a correlation between time points within subjects which
> varies
> with time (if the Phi1 is positive it implies a positive serial
> correlation
> exponentially decaying to zero as the time lag increases).
> 
> Therefore these two error models compete with each other in explaining
> correlation that varies with time which is very messy (i.e. what does the
> theoretical semivariogram look like?)  and possibly over-parameterised.
> 
> However, it makes sense to combine random intercepts with an AR1 process
> (Diggle et al. 2002, Section 5.2.3, Figure 5.4)
> 
> > >   /RANDOM=INTERCEPT | SUBJECT(Subject)
> > >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).
> 
> My understanding is that the above SPSS error model is the same as the
> lme
> error model below
> 
> > lme(
> > fixed=conc~Time,
> > random=~1|Subject,
> > method="REML",
> > data=fGlucose,
> > na.action="na.omit",
> > correlation=corAR1(form=~Time|Subject))
> 
> *Diggle, D. J., P. J. Heagerty, K. Y. Liang, and S. L. Zeger. 2002.
> Analysis
> of Longitudinal Data. . Oxford University Press, Oxford, England.
> 
> Dr Steven G. Candy
> Director/Consultant
> SCANDY STATISTICAL MODELLING PTY LTD
> (ABN: 83 601 268 419)
> 70 Burwood Drive
> Blackmans Bay, TASMANIA, Australia 7052
> Mobile: (61) 0439284983
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From alberto.gc8 at gmail.com  Mon May 18 04:43:57 2015
From: alberto.gc8 at gmail.com (Alberto Gallano)
Date: Sun, 17 May 2015 22:43:57 -0400
Subject: [R-sig-ME] MCMCglmm phylogenetic model with polymorphic binary
	outcome
Message-ID: <CAO+b4j8uh04nPGkCHh=7nm-ty4tsHNx9LjjhW-2iVp8Sc+h+xA@mail.gmail.com>

I'm using MCMCglmm to construct phylogenetic mixed models with binary
outcomes (see code below). I have 106 species and between n=3 and n=110
individuals per species. My predictor variable (ratio of incisor size to
molar size) is split, using the van der Pol and Wright (2009) method, into
species-mean and within-species terms. I have several "binary.outcome"
variables. Some of these outcome variables are at the species level (i.e.,
all individuals within a species have the same outcome), while others
exhibit polymorphism (i.e., individuals within a species have different
outcomes).

My question is, is the model specification below appropriate for both
species-specific outcomes and those that vary within species? If not, what
would be appropriate for these two types of binary outcome? I'm ultimately
concerned with interpreting the between species slope of my predictor
variable.


prior1 <- list(
    B = list(mu = rep(0, 3), V = diag(3) * (1 + pi^2/3)),
    G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000),
             G2 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
    R = list(V = 1, fix = 1)
)

inv_phylo_mat <- inverseA(tree, nodes = "TIPS", scale = TRUE)

set.seed(1234)

fit <- MCMCglmm(
    fixed = binary.outcome ~ I2.M1.species.mean + I2.M1.within.species,
    random = ~ phylo + species,
    rcov = ~ units,
    data = incisor.dat,
    family = "categorical",
    ginverse = list(phylo = inv_phylo_mat$Ainv),
    prior = prior1,
    pr = TRUE,
    pl = TRUE,
    nitt = 1.1e+7, thin = 2000, burnin = 1e+5,
    verbose = FALSE,
    slice = TRUE
)

best,
Alberto

	[[alternative HTML version deleted]]


From Nadege.Jacot at unige.ch  Thu May 21 06:47:00 2015
From: Nadege.Jacot at unige.ch (=?iso-8859-1?Q?Nad=E8ge_Jacot?=)
Date: Thu, 21 May 2015 04:47:00 +0000
Subject: [R-sig-ME] lme4 and deviance
Message-ID: <F14352CFE7F2B74DA2C5597BD8BF3B2C0D31D936@hotel.isis.unige.ch>

Dear list,

I'm trying to understand why the deviance function returns -2 log likelihood in lme4 and not the "true" deviance as with lm().

The scaled deviance is defined as the difference of -2 log likelihood between the model of interest and the saturated model but what is the saturated mixed model? For balanced data, some authors (e.g. Hoffman 2014, Longitudinal Analysis: Modeling Within-Person Fluctuation and Change) define the saturated mixed model as a model with saturated means (one fixed effect for each time point) and unstructured variance but such a model is not available for unbalanced data.

And if we can compute the scaled deviance, what is the deviance?

Thanks in advance for any hint.

Nad?ge Jacot

	[[alternative HTML version deleted]]


From lponisio at gmail.com  Thu May 21 19:07:00 2015
From: lponisio at gmail.com (Lauren Catherine Ponisio)
Date: Thu, 21 May 2015 10:07:00 -0700
Subject: [R-sig-ME] error with parametric bootstrap for negative binomial
	model, lme4, pbkrtest
Message-ID: <CABaj+=dygzkJzumbdu=M17JxRdUOfYM9Y+4mP5UkuaMbjVJ=Qw@mail.gmail.com>

Hello list members,
I was hoping to use the a parametric bootstrap using the pbktest package,
PBmodcomp() function. With a negative binomial mixed model I get the
following error:

Error in lme4::.simulateFun(object = sm, nsim = nsim, seed = seed) : could
not find function "sfun"

I get the same error when I try to use the function simulate() on a
negative binomial model. With other families I do not get an error.

I found that Ben Bolker recommended a hack on the lme4 github site, but I
cannot get it to work.
https://github.com/lme4/lme4/issues/284

If fact, below is the code he suggested which gives me the above error.

library(lme4)
library(pbkrtest)

set.seed(101)
dd <- data.frame(f=factor(rep(1:10, each=50)),
                 x=runif(500),
                 y=rnbinom(500, size=2, mu=2))

g1 <- glmer.nb(y ~ x + (1|f), data=dd)
g0 <- glmer.nb(y ~ 1 + (1|f), data=dd)

PBmodcomp(g1, g0, nsim=10)

Thanks!
best,
Lauren

	[[alternative HTML version deleted]]


From burwood70 at gmail.com  Fri May 22 02:54:38 2015
From: burwood70 at gmail.com (Steve Candy)
Date: Fri, 22 May 2015 10:54:38 +1000
Subject: [R-sig-ME] estimating AR1 parameters of level one error
Message-ID: <002801d09429$e536acc0$afa40640$@gmail.com>

Thanks Wolfgang

Yes I agree its possible and I have fitted such a model using random
subject-splines. I found numerical instability but this may not be the case
with other applications. So my statement "not sensible" is not justifiable.
I should have said "can be problematic". The marginal covariance is much
more complex and harder to describe graphically  than the random intercepts
plus AR(1) error model which I have used extensively and combined with the
log-transform of the response to allow for "splaying-out" of curves in time
or adding extra variance parameters to model that or other types of variance
heterogeneity. I have found this type of model more stable in practice.

Thanks for correcting me.

Regards

Steve

>It is certainly possible to have a model with random intercepts and slopes
(for time) and also AR(1) correlated residuals over time within individuals.
The random slopes model differences in the trend between individuals, while
>the AR(1) structure models how the residuals are fluctuating around the
person-specific slopes within individuals. Of course, you need to have a
sufficient number of follow-up measurements within individuals to
distinguish >those two elements. But this is certainly possible. And in
fact, ignoring serial correlation in the residuals when it is present could
lead to inflated Type I error rates for the mean trend effect.

>Best,
>Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: Thursday, 21 May 2015 8:00 PM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 101, Issue 27

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific than
"Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: : estimating AR1 parameters of level one error	using	lme
      (Steve Candy)
   2. Re: : estimating AR1 parameters of level one error using lme
      (Viechtbauer Wolfgang (STAT))
   3. MCMCglmm phylogenetic model with polymorphic binary	outcome
      (Alberto Gallano)


----------------------------------------------------------------------

Message: 1
Date: Wed, 20 May 2015 21:13:37 +1000
From: "Steve Candy" <burwood70 at gmail.com>
To: <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] : estimating AR1 parameters of level one error
	using	lme
Message-ID: <006001d092ee$07dcb180$17961480$@gmail.com>
Content-Type: text/plain;	charset="us-ascii"

I question whether this model of dependency between residuals in repeated
measures analysis is sensible

> >   /RANDOM=INTERCEPT Time | SUBJECT(Subject)

corresponds to a random coefficients approach which implies a correlation
between time points within subjects which varies with time (also called "the
growth curve model" cf:  Diggle et al 2002 pg 98-99) while

> >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1)

also implies a correlation between time points within subjects which varies
with time (if the Phi1 is positive it implies a positive serial correlation
exponentially decaying to zero as the time lag increases).

Therefore these two error models compete with each other in explaining
correlation that varies with time which is very messy (i.e. what does the
theoretical semivariogram look like?)  and possibly over-parameterised.

However, it makes sense to combine random intercepts with an AR1 process
(Diggle et al. 2002, Section 5.2.3, Figure 5.4)

> >   /RANDOM=INTERCEPT | SUBJECT(Subject)
> >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).

My understanding is that the above SPSS error model is the same as the  lme
error model below  

> lme(
> fixed=conc~Time,
> random=~1|Subject,
> method="REML",
> data=fGlucose,
> na.action="na.omit",
> correlation=corAR1(form=~Time|Subject))

*Diggle, D. J., P. J. Heagerty, K. Y. Liang, and S. L. Zeger. 2002. Analysis
of Longitudinal Data. . Oxford University Press, Oxford, England.

Dr Steven G. Candy
Director/Consultant
SCANDY STATISTICAL MODELLING PTY LTD
(ABN: 83 601 268 419)
70 Burwood Drive
Blackmans Bay, TASMANIA, Australia 7052
Mobile: (61) 0439284983



------------------------------

Message: 2
Date: Wed, 20 May 2015 14:10:53 +0200
From: "Viechtbauer Wolfgang (STAT)"
	<wolfgang.viechtbauer at maastrichtuniversity.nl>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] : estimating AR1 parameters of level one error
	using lme
Message-ID:
	<077E31A57DA26E46AB0D493C9966AC730F0CA05B86 at UM-MAIL4112.unimaas.nl>
Content-Type: text/plain; charset="us-ascii"

It is certainly possible to have a model with random intercepts and slopes
(for time) and also AR(1) correlated residuals over time within individuals.
The random slopes model differences in the trend between individuals, while
the AR(1) structure models how the residuals are fluctuating around the
person-specific slopes within individuals. Of course, you need to have a
sufficient number of follow-up measurements within individuals to
distinguish those two elements. But this is certainly possible. And in fact,
ignoring serial correlation in the residuals when it is present could lead
to inflated Type I error rates for the mean trend effect.

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Steve Candy
> Sent: Wednesday, May 20, 2015 13:14
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] : estimating AR1 parameters of level one error 
> using lme
> 
> I question whether this model of dependency between residuals in 
> repeated measures analysis is sensible
> 
> > >   /RANDOM=INTERCEPT Time | SUBJECT(Subject)
> 
> corresponds to a random coefficients approach which implies a 
> correlation between time points within subjects which varies with time 
> (also called "the growth curve model" cf:  Diggle et al 2002 pg 98-99) 
> while
> 
> > >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1)
> 
> also implies a correlation between time points within subjects which 
> varies with time (if the Phi1 is positive it implies a positive serial 
> correlation exponentially decaying to zero as the time lag increases).
> 
> Therefore these two error models compete with each other in explaining 
> correlation that varies with time which is very messy (i.e. what does 
> the theoretical semivariogram look like?)  and possibly
over-parameterised.
> 
> However, it makes sense to combine random intercepts with an AR1 
> process (Diggle et al. 2002, Section 5.2.3, Figure 5.4)
> 
> > >   /RANDOM=INTERCEPT | SUBJECT(Subject)
> > >   /REPEATED=Time | SUBJECT(Subject)COVTYPE(AR1).
> 
> My understanding is that the above SPSS error model is the same as the 
> lme error model below
> 
> > lme(
> > fixed=conc~Time,
> > random=~1|Subject,
> > method="REML",
> > data=fGlucose,
> > na.action="na.omit",
> > correlation=corAR1(form=~Time|Subject))
> 
> *Diggle, D. J., P. J. Heagerty, K. Y. Liang, and S. L. Zeger. 2002.
> Analysis
> of Longitudinal Data. . Oxford University Press, Oxford, England.
> 
> Dr Steven G. Candy
> Director/Consultant
> SCANDY STATISTICAL MODELLING PTY LTD
> (ABN: 83 601 268 419)
> 70 Burwood Drive
> Blackmans Bay, TASMANIA, Australia 7052
> Mobile: (61) 0439284983
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



------------------------------

Message: 3
Date: Sun, 17 May 2015 22:43:57 -0400
From: Alberto Gallano <alberto.gc8 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] MCMCglmm phylogenetic model with polymorphic
	binary	outcome
Message-ID:
	<CAO+b4j8uh04nPGkCHh=7nm-ty4tsHNx9LjjhW-2iVp8Sc+h+xA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

I'm using MCMCglmm to construct phylogenetic mixed models with binary
outcomes (see code below). I have 106 species and between n=3 and n=110
individuals per species. My predictor variable (ratio of incisor size to
molar size) is split, using the van der Pol and Wright (2009) method, into
species-mean and within-species terms. I have several "binary.outcome"
variables. Some of these outcome variables are at the species level (i.e.,
all individuals within a species have the same outcome), while others
exhibit polymorphism (i.e., individuals within a species have different
outcomes).

My question is, is the model specification below appropriate for both
species-specific outcomes and those that vary within species? If not, what
would be appropriate for these two types of binary outcome? I'm ultimately
concerned with interpreting the between species slope of my predictor
variable.


prior1 <- list(
    B = list(mu = rep(0, 3), V = diag(3) * (1 + pi^2/3)),
    G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000),
             G2 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
    R = list(V = 1, fix = 1)
)

inv_phylo_mat <- inverseA(tree, nodes = "TIPS", scale = TRUE)

set.seed(1234)

fit <- MCMCglmm(
    fixed = binary.outcome ~ I2.M1.species.mean + I2.M1.within.species,
    random = ~ phylo + species,
    rcov = ~ units,
    data = incisor.dat,
    family = "categorical",
    ginverse = list(phylo = inv_phylo_mat$Ainv),
    prior = prior1,
    pr = TRUE,
    pl = TRUE,
    nitt = 1.1e+7, thin = 2000, burnin = 1e+5,
    verbose = FALSE,
    slice = TRUE
)

best,
Alberto

	[[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 101, Issue 27


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri May 22 21:48:12 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 22 May 2015 21:48:12 +0200
Subject: [R-sig-ME] estimating AR1 parameters of level one error
In-Reply-To: <002801d09429$e536acc0$afa40640$@gmail.com>
References: <002801d09429$e536acc0$afa40640$@gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0CA061B4@UM-MAIL4112.unimaas.nl>

Good point! In fact, besides the fact that the OP was not fitting exactly the same model, numerical instabilities may be another reason for why different values were obtained. I've been dealing with lots of analyses recently where we have 30-60 measurements per person, so fitting models with both random slopes and AR(1) structure is not an issue. But if there are only a handful of measurements, differences are more likely.

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Steve Candy
> Sent: Friday, May 22, 2015 02:55
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] estimating AR1 parameters of level one error
> 
> Thanks Wolfgang
> 
> Yes I agree its possible and I have fitted such a model using random
> subject-splines. I found numerical instability but this may not be the
> case with other applications. So my statement "not sensible" is not
> justifiable. I should have said "can be problematic". The marginal
> covariance is much more complex and harder to describe graphically  than
> the random intercepts plus AR(1) error model which I have used
> extensively and combined with the log-transform of the response to allow
> for "splaying-out" of curves in time or adding extra variance parameters
> to model that or other types of variance heterogeneity. I have found this
> type of model more stable in practice.
> 
> Thanks for correcting me.
> 
> Regards
> 
> Steve
> 
> >It is certainly possible to have a model with random intercepts and
> slopes
> (for time) and also AR(1) correlated residuals over time within
> individuals.
> The random slopes model differences in the trend between individuals,
> while
> >the AR(1) structure models how the residuals are fluctuating around the
> person-specific slopes within individuals. Of course, you need to have a
> sufficient number of follow-up measurements within individuals to
> distinguish >those two elements. But this is certainly possible. And in
> fact, ignoring serial correlation in the residuals when it is present
> could
> lead to inflated Type I error rates for the mean trend effect.
> 
> >Best,
> >Wolfgang


From thlytras at gmail.com  Mon May 25 12:49:04 2015
From: thlytras at gmail.com (Theodore Lytras)
Date: Mon, 25 May 2015 13:49:04 +0300
Subject: [R-sig-ME] metafor - Appropriate heterogeneity estimator when
	heterogeneity is extreme
Message-ID: <1907606.3VaPkruoRL@equinox2>

Hello everyone,

Sorry if this is not the right forum.
I am undertaking a meta-regression using the metafor package, with six binary 
predictors and no intercept (I am only interested in the coefficients, not in 
the pooled effect). I have a sufficient number of studies (N=52), and the 
study effects (log Risk Ratios) show substantial left skew when plotted on a 
normal plot.

The problem is that I get very different estimates for tau^2 (and therefore 
quite different SEs for the regression coefficients) depending on whether I 
use the DerSimonian-Laird (DL) estimator or the REML estimator. 
In both cases heterogeneity is extreme (I^2>99, H^2>150), but t^2 is twice as 
big with REML (0.1901) than with DL (0.0805).

Could someone give me any clues as to which estimator may be more appropriate 
in such a situation? 
Also, what may be the cause of such greatly divergent estimates? Is it the 
heterogeneity? The non-normal distribution of study effects? Or something 
else?

Here's the output:

> rma.uni(yi=logRR, sei=SElogRR, mods=cbind(e1,e2,e3,e4,e5,e6), 
intercept=FALSE, method="DL", data=a)

Mixed-Effects Model (k = 52; tau^2 estimator: DL)

tau^2 (estimated amount of residual heterogeneity):     0.0805 (SE = 0.0387)
tau (square root of estimated tau^2 value):             0.2837
I^2 (residual heterogeneity / unaccounted variability): 99.46%
H^2 (unaccounted variability / sampling variability):   185.55

Test for Residual Heterogeneity: 
QE(df = 46) = 8535.3517, p-val < .0001

Test of Moderators (coefficient(s) 1,2,3,4,5,6): 
QM(df = 6) = 314.3132, p-val < .0001

Model Results:

    estimate      se      zval    pval    ci.lb    ci.ub     
e1   -0.1973  0.0775   -2.5476  0.0108  -0.3491  -0.0455    *
e2   -0.1679  0.0825   -2.0358  0.0418  -0.3296  -0.0063    *
e3   -0.0413  0.0774   -0.5327  0.5942  -0.1930   0.1105     
e4   -0.1241  0.0990   -1.2539  0.2099  -0.3181   0.0699     
e5   -0.4916  0.1320   -3.7239  0.0002  -0.7503  -0.2329  ***
e6   -1.6907  0.1064  -15.8893  <.0001  -1.8992  -1.4821  ***

---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

> rma.uni(yi=logRR, sei=SElogRR, mods=cbind(e1,e2,e3,e4,e5,e6), 
intercept=FALSE, method="REML", data=a)  

Mixed-Effects Model (k = 52; tau^2 estimator: REML)

tau^2 (estimated amount of residual heterogeneity):     0.1901 (SE = 0.0411)
tau (square root of estimated tau^2 value):             0.4360
I^2 (residual heterogeneity / unaccounted variability): 99.77%
H^2 (unaccounted variability / sampling variability):   437.00

Test for Residual Heterogeneity: 
QE(df = 46) = 8535.3517, p-val < .0001

Test of Moderators (coefficient(s) 1,2,3,4,5,6): 
QM(df = 6) = 142.3333, p-val < .0001

Model Results:

    estimate      se      zval    pval    ci.lb    ci.ub     
e1   -0.1987  0.1175   -1.6913  0.0908  -0.4289   0.0316    .
e2   -0.1695  0.1243   -1.3638  0.1726  -0.4132   0.0741     
e3   -0.0491  0.1165   -0.4212  0.6736  -0.2774   0.1793     
e4   -0.1184  0.1502   -0.7880  0.4307  -0.4127   0.1760     
e5   -0.5140  0.1954   -2.6304  0.0085  -0.8970  -0.1310   **
e6   -1.6950  0.1588  -10.6722  <.0001  -2.0063  -1.3837  ***

---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 


For completeness, I checked the other heterogeneity estimators available in 
metafor. Most are close to REML, expect Hunter-Schmidt (HS) which gives an 
even lower tau^2 than DL.

     method  tau2    I2     H2
DL       DL 0.080 99.46 185.55
HS       HS 0.036 98.81  84.07
HE       HE 0.190 99.77 435.58
ML       ML 0.167 99.74 384.58
REML   REML 0.190 99.77 437.00
EB       EB 0.190 99.77 437.01
PM       PM 0.190 99.77 437.01
SJ       SJ 0.195 99.78 447.29

Thank you very much,

Theodore Lytras


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon May 25 14:22:30 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 25 May 2015 14:22:30 +0200
Subject: [R-sig-ME] metafor - Appropriate heterogeneity estimator when
 heterogeneity is extreme
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0CA06216@UM-MAIL4112.unimaas.nl>

Welcome to the wonderful world of heterogeneity (tau^2) estimators in meta-analysis. The question of which estimator to choose never fails to provide fun and entertainment for the entire family and I predict that it will do so for generations to come. Please quote me on that!

Now, to actually address your question. While in theory, the DL estimator is unbiased (under the assumptions of the random/mixed-effects model), there is some evidence out there that, in practice, the estimator underestimates the true amount of heterogeneity when tau^2 is in fact large, which seems to be especially an issue when meta-analyzing 2x2 table data (i.e., when meta-analyzing log odds/risk ratios and maybe also when meta-analyzing risk differences). And the REML estimator -- which cannot be proven to be unbiased, except under some special cases, but which has been studied quite extensively in simulation studies -- may possibly work better (on average) under such circumstances.

So, that may lead one to conclude that the results based on REML are closer to the truth for your particular case, but this is would be a rather big jump in conclusions. Bias is something that manifests itself *on average*, so in any particular case, we cannot know whether DL, REML, or any other of the dozens of tau^2 estimators out there is closest to the truth. So, while it may indeed be the case that the value you obtain from the DL estimator is also too small in your example, it could also be the one value that is most accurate.

So, in the end, that leaves you with some uncertainty as to what result you really should believe in. One thing that is certain though is that there is a lot of heterogeneity in these data, even when one would go with the DL estimator. Consider the results for 'e1' as an illustration. The log(RR) is -0.1973, which corresponds to a RR of about 0.82. With an estimate of tau^2 equal to 0.0805, we get a (very rough) 95% prediction interval for the true RR in any particular study (that is like an 'e1' study) with bounds:

round(exp(-0.1973 - 1.96*0.2837), 2)
round(exp(-0.1973 + 1.96*0.2837), 2)

that is, 0.47 to 1.43. So, in essence, while the true risk could be half as large in group 1 versus 2, it is not implausible that the true risk could also be almost 1.5 times larger in group 1 versus 2 (and this interval is still too narrow, as it ignores uncertainty in the estimate of the mean and the uncertainty in the estimate of tau^2 itself).

In the end, my recommendation would be to emphasize the large amount of heterogeneity, regardless of which estimator you go with, and to acknowledge that the exact amount is far from certain, due to the rather different values you obtain depending on which estimator you use. Formulate your conclusions accordingly (e.g., if you are inclined to say something about the average true log(RR) of 'e1' being significantly different from 0 or not based on the p-value being below .05 or not, do so cautiously!) and you've interpreted the data appropriately, at least as far as I am concerned (and based on the information given below).

Best,
Wolfgang

--    
Wolfgang Viechtbauer, Ph.D., Statistician    
Department of Psychiatry and Neuropsychology    
School for Mental Health and Neuroscience    
Faculty of Health, Medicine, and Life Sciences    
Maastricht University, P.O. Box 616 (VIJV1)    
6200 MD Maastricht, The Netherlands    
+31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Theodore Lytras
> Sent: Monday, May 25, 2015 12:49
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] metafor - Appropriate heterogeneity estimator when
> heterogeneity is extreme
> 
> Hello everyone,
> 
> Sorry if this is not the right forum.
> I am undertaking a meta-regression using the metafor package, with six
> binary
> predictors and no intercept (I am only interested in the coefficients,
> not in
> the pooled effect). I have a sufficient number of studies (N=52), and the
> study effects (log Risk Ratios) show substantial left skew when plotted
> on a
> normal plot.
> 
> The problem is that I get very different estimates for tau^2 (and
> therefore
> quite different SEs for the regression coefficients) depending on whether
> I
> use the DerSimonian-Laird (DL) estimator or the REML estimator.
> In both cases heterogeneity is extreme (I^2>99, H^2>150), but t^2 is
> twice as
> big with REML (0.1901) than with DL (0.0805).
> 
> Could someone give me any clues as to which estimator may be more
> appropriate
> in such a situation?
> Also, what may be the cause of such greatly divergent estimates? Is it
> the
> heterogeneity? The non-normal distribution of study effects? Or something
> else?
> 
> Here's the output:
> 
> > rma.uni(yi=logRR, sei=SElogRR, mods=cbind(e1,e2,e3,e4,e5,e6),
> intercept=FALSE, method="DL", data=a)
> 
> Mixed-Effects Model (k = 52; tau^2 estimator: DL)
> 
> tau^2 (estimated amount of residual heterogeneity):     0.0805 (SE =
> 0.0387)
> tau (square root of estimated tau^2 value):             0.2837
> I^2 (residual heterogeneity / unaccounted variability): 99.46%
> H^2 (unaccounted variability / sampling variability):   185.55
> 
> Test for Residual Heterogeneity:
> QE(df = 46) = 8535.3517, p-val < .0001
> 
> Test of Moderators (coefficient(s) 1,2,3,4,5,6):
> QM(df = 6) = 314.3132, p-val < .0001
> 
> Model Results:
> 
>     estimate      se      zval    pval    ci.lb    ci.ub
> e1   -0.1973  0.0775   -2.5476  0.0108  -0.3491  -0.0455    *
> e2   -0.1679  0.0825   -2.0358  0.0418  -0.3296  -0.0063    *
> e3   -0.0413  0.0774   -0.5327  0.5942  -0.1930   0.1105
> e4   -0.1241  0.0990   -1.2539  0.2099  -0.3181   0.0699
> e5   -0.4916  0.1320   -3.7239  0.0002  -0.7503  -0.2329  ***
> e6   -1.6907  0.1064  -15.8893  <.0001  -1.8992  -1.4821  ***
> 
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> > rma.uni(yi=logRR, sei=SElogRR, mods=cbind(e1,e2,e3,e4,e5,e6),
> intercept=FALSE, method="REML", data=a)
> 
> Mixed-Effects Model (k = 52; tau^2 estimator: REML)
> 
> tau^2 (estimated amount of residual heterogeneity):     0.1901 (SE =
> 0.0411)
> tau (square root of estimated tau^2 value):             0.4360
> I^2 (residual heterogeneity / unaccounted variability): 99.77%
> H^2 (unaccounted variability / sampling variability):   437.00
> 
> Test for Residual Heterogeneity:
> QE(df = 46) = 8535.3517, p-val < .0001
> 
> Test of Moderators (coefficient(s) 1,2,3,4,5,6):
> QM(df = 6) = 142.3333, p-val < .0001
> 
> Model Results:
> 
>     estimate      se      zval    pval    ci.lb    ci.ub
> e1   -0.1987  0.1175   -1.6913  0.0908  -0.4289   0.0316    .
> e2   -0.1695  0.1243   -1.3638  0.1726  -0.4132   0.0741
> e3   -0.0491  0.1165   -0.4212  0.6736  -0.2774   0.1793
> e4   -0.1184  0.1502   -0.7880  0.4307  -0.4127   0.1760
> e5   -0.5140  0.1954   -2.6304  0.0085  -0.8970  -0.1310   **
> e6   -1.6950  0.1588  -10.6722  <.0001  -2.0063  -1.3837  ***
> 
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> For completeness, I checked the other heterogeneity estimators available
> in
> metafor. Most are close to REML, expect Hunter-Schmidt (HS) which gives
> an
> even lower tau^2 than DL.
> 
>      method  tau2    I2     H2
> DL       DL 0.080 99.46 185.55
> HS       HS 0.036 98.81  84.07
> HE       HE 0.190 99.77 435.58
> ML       ML 0.167 99.74 384.58
> REML   REML 0.190 99.77 437.00
> EB       EB 0.190 99.77 437.01
> PM       PM 0.190 99.77 437.01
> SJ       SJ 0.195 99.78 447.29
> 
> Thank you very much,
> 
> Theodore Lytras
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From hannah.hlx at gmail.com  Tue May 26 20:13:54 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 26 May 2015 14:13:54 -0400
Subject: [R-sig-ME] lme function to obtain pvalue for fixed effect
Message-ID: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>

Hi all,
  I am using the lme function to run a random coefficient model. Please see
output (mod1) as below.
  I need to obtain the pvalue for the fixed effect. As you can see,
the pvalues given using the summary function is different from the
resutls given in anova function.
Why should they be different and which one is the correct one to use?
   Thanks!
      Hanna


> summary(mod1)
Linear mixed-effects model fit by REML
 Data: minus20C1
        AIC       BIC   logLik
  -82.60042 -70.15763 49.30021

Random effects:
 Formula: ~1 + months | lot
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 8.907584e-03 (Intr)
months      6.039781e-05 -0.096
Residual    4.471243e-02

Fixed effects: ti ~ type * months
                     Value   Std.Error DF   t-value p-value
(Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
type             0.13502089 0.026676101  4  5.061493  0.0072
months          0.00804790 0.001218941 31  6.602368  0.0000
type:months -0.00693679 0.002981859 31 -2.326329  0.0267
 Correlation:
               (Intr) typ months
type        -0.633
months         -0.785  0.497
type:months  0.321 -0.762 -0.409

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00

Number of Observations: 39
Number of Groups: 6
> anova(mod1)
            numDF denDF   F-value p-value
(Intercept)     1    31 2084.0265  <.0001
type            1     4   10.8957  0.0299
months          1    31   38.3462  <.0001
type:months     1    31    5.4118  0.0267


From byronvinu_8 at hotmail.com  Tue May 26 21:19:08 2015
From: byronvinu_8 at hotmail.com (byron vinueza)
Date: Tue, 26 May 2015 14:19:08 -0500
Subject: [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
Message-ID: <BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>

You can use the lmerTest package .





Enviado desde mi iPhone

> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com> escribi?:
> 
> Hi all,
>  I am using the lme function to run a random coefficient model. Please see
> output (mod1) as below.
>  I need to obtain the pvalue for the fixed effect. As you can see,
> the pvalues given using the summary function is different from the
> resutls given in anova function.
> Why should they be different and which one is the correct one to use?
>   Thanks!
>      Hanna
> 
> 
>> summary(mod1)
> Linear mixed-effects model fit by REML
> Data: minus20C1
>        AIC       BIC   logLik
>  -82.60042 -70.15763 49.30021
> 
> Random effects:
> Formula: ~1 + months | lot
> Structure: General positive-definite, Log-Cholesky parametrization
>            StdDev       Corr
> (Intercept) 8.907584e-03 (Intr)
> months      6.039781e-05 -0.096
> Residual    4.471243e-02
> 
> Fixed effects: ti ~ type * months
>                     Value   Std.Error DF   t-value p-value
> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
> type             0.13502089 0.026676101  4  5.061493  0.0072
> months          0.00804790 0.001218941 31  6.602368  0.0000
> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
> Correlation:
>               (Intr) typ months
> type        -0.633
> months         -0.785  0.497
> type:months  0.321 -0.762 -0.409
> 
> Standardized Within-Group Residuals:
>          Min            Q1           Med            Q3           Max
> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
> 
> Number of Observations: 39
> Number of Groups: 6
>> anova(mod1)
>            numDF denDF   F-value p-value
> (Intercept)     1    31 2084.0265  <.0001
> type            1     4   10.8957  0.0299
> months          1    31   38.3462  <.0001
> type:months     1    31    5.4118  0.0267
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From hannah.hlx at gmail.com  Tue May 26 21:46:11 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 26 May 2015 15:46:11 -0400
Subject: [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
	<BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>
Message-ID: <CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>

Thanks so much for replying.
Yes LimerTest package could be used to get pvalues when using lmer
function. But still the summary and anova function give different
pvalues.
   Hanna

2015-05-26 15:19 GMT-04:00, byron vinueza <byronvinu_8 at hotmail.com>:
> You can use the lmerTest package .
>
>
>
>
>
> Enviado desde mi iPhone
>
>> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com> escribi?:
>>
>> Hi all,
>>  I am using the lme function to run a random coefficient model. Please
>> see
>> output (mod1) as below.
>>  I need to obtain the pvalue for the fixed effect. As you can see,
>> the pvalues given using the summary function is different from the
>> resutls given in anova function.
>> Why should they be different and which one is the correct one to use?
>>   Thanks!
>>      Hanna
>>
>>
>>> summary(mod1)
>> Linear mixed-effects model fit by REML
>> Data: minus20C1
>>        AIC       BIC   logLik
>>  -82.60042 -70.15763 49.30021
>>
>> Random effects:
>> Formula: ~1 + months | lot
>> Structure: General positive-definite, Log-Cholesky parametrization
>>            StdDev       Corr
>> (Intercept) 8.907584e-03 (Intr)
>> months      6.039781e-05 -0.096
>> Residual    4.471243e-02
>>
>> Fixed effects: ti ~ type * months
>>                     Value   Std.Error DF   t-value p-value
>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>> type             0.13502089 0.026676101  4  5.061493  0.0072
>> months          0.00804790 0.001218941 31  6.602368  0.0000
>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>> Correlation:
>>               (Intr) typ months
>> type        -0.633
>> months         -0.785  0.497
>> type:months  0.321 -0.762 -0.409
>>
>> Standardized Within-Group Residuals:
>>          Min            Q1           Med            Q3           Max
>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>>
>> Number of Observations: 39
>> Number of Groups: 6
>>> anova(mod1)
>>            numDF denDF   F-value p-value
>> (Intercept)     1    31 2084.0265  <.0001
>> type            1     4   10.8957  0.0299
>> months          1    31   38.3462  <.0001
>> type:months     1    31    5.4118  0.0267
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From thierry.onkelinx at inbo.be  Tue May 26 22:09:49 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 26 May 2015 22:09:49 +0200
Subject: [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
	<BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>
	<CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>
Message-ID: <CAJuCY5ykuSex7iqwm-+V7fCAZrhD8h6U3B3Gb513qAYJs8G=Sg@mail.gmail.com>

Because they test different hypothesis.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-26 21:46 GMT+02:00 li li <hannah.hlx at gmail.com>:

> Thanks so much for replying.
> Yes LimerTest package could be used to get pvalues when using lmer
> function. But still the summary and anova function give different
> pvalues.
>    Hanna
>
> 2015-05-26 15:19 GMT-04:00, byron vinueza <byronvinu_8 at hotmail.com>:
> > You can use the lmerTest package .
> >
> >
> >
> >
> >
> > Enviado desde mi iPhone
> >
> >> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com> escribi?:
> >>
> >> Hi all,
> >>  I am using the lme function to run a random coefficient model. Please
> >> see
> >> output (mod1) as below.
> >>  I need to obtain the pvalue for the fixed effect. As you can see,
> >> the pvalues given using the summary function is different from the
> >> resutls given in anova function.
> >> Why should they be different and which one is the correct one to use?
> >>   Thanks!
> >>      Hanna
> >>
> >>
> >>> summary(mod1)
> >> Linear mixed-effects model fit by REML
> >> Data: minus20C1
> >>        AIC       BIC   logLik
> >>  -82.60042 -70.15763 49.30021
> >>
> >> Random effects:
> >> Formula: ~1 + months | lot
> >> Structure: General positive-definite, Log-Cholesky parametrization
> >>            StdDev       Corr
> >> (Intercept) 8.907584e-03 (Intr)
> >> months      6.039781e-05 -0.096
> >> Residual    4.471243e-02
> >>
> >> Fixed effects: ti ~ type * months
> >>                     Value   Std.Error DF   t-value p-value
> >> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
> >> type             0.13502089 0.026676101  4  5.061493  0.0072
> >> months          0.00804790 0.001218941 31  6.602368  0.0000
> >> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
> >> Correlation:
> >>               (Intr) typ months
> >> type        -0.633
> >> months         -0.785  0.497
> >> type:months  0.321 -0.762 -0.409
> >>
> >> Standardized Within-Group Residuals:
> >>          Min            Q1           Med            Q3           Max
> >> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
> >>
> >> Number of Observations: 39
> >> Number of Groups: 6
> >>> anova(mod1)
> >>            numDF denDF   F-value p-value
> >> (Intercept)     1    31 2084.0265  <.0001
> >> type            1     4   10.8957  0.0299
> >> months          1    31   38.3462  <.0001
> >> type:months     1    31    5.4118  0.0267
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From leithen at gmail.com  Thu May 21 19:23:04 2015
From: leithen at gmail.com (Leithen)
Date: Thu, 21 May 2015 10:23:04 -0700
Subject: [R-sig-ME] error with parametric bootstrap for negative
 binomial model, lme4, pbkrtest
In-Reply-To: <CABaj+=dygzkJzumbdu=M17JxRdUOfYM9Y+4mP5UkuaMbjVJ=Qw@mail.gmail.com>
References: <CABaj+=dygzkJzumbdu=M17JxRdUOfYM9Y+4mP5UkuaMbjVJ=Qw@mail.gmail.com>
Message-ID: <CAA+UucVOrRLdeKcm9zNP0CzsKeDoce4TJdimRVzqHvDTkBJZZQ@mail.gmail.com>

That looks perfect. Someone will definitely respond!

On Thu, May 21, 2015 at 10:07 AM, Lauren Catherine Ponisio <
lponisio at gmail.com> wrote:

> Hello list members,
> I was hoping to use the a parametric bootstrap using the pbktest package,
> PBmodcomp() function. With a negative binomial mixed model I get the
> following error:
>
> Error in lme4::.simulateFun(object = sm, nsim = nsim, seed = seed) : could
> not find function "sfun"
>
> I get the same error when I try to use the function simulate() on a
> negative binomial model. With other families I do not get an error.
>
> I found that Ben Bolker recommended a hack on the lme4 github site, but I
> cannot get it to work.
> https://github.com/lme4/lme4/issues/284
>
> If fact, below is the code he suggested which gives me the above error.
>
> library(lme4)
> library(pbkrtest)
>
> set.seed(101)
> dd <- data.frame(f=factor(rep(1:10, each=50)),
>                  x=runif(500),
>                  y=rnbinom(500, size=2, mu=2))
>
> g1 <- glmer.nb(y ~ x + (1|f), data=dd)
> g0 <- glmer.nb(y ~ 1 + (1|f), data=dd)
>
> PBmodcomp(g1, g0, nsim=10)
>
> Thanks!
> best,
> Lauren
>



-- 
Leithen M'Gonigle
Assistant Professor
Department of Biological Science
Florida State University
319 Stadium Dr, Tallahassee, FL, 32306
Phone (office): +1 (850) 645-9532
Email: lmgonigle at bio.fsu.edu
Web: http://www.bio.fsu.edu/~lmgonigle/

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed May 27 00:56:54 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 26 May 2015 18:56:54 -0400
Subject: [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <CAHLnndbrFTiL_hCk3BTtrgOw2vQQdaTyZkyBba=7ZP6rTZXR7Q@mail.gmail.com>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
	<BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>
	<CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>
	<CAJuCY5ykuSex7iqwm-+V7fCAZrhD8h6U3B3Gb513qAYJs8G=Sg@mail.gmail.com>
	<CAHLnndbrFTiL_hCk3BTtrgOw2vQQdaTyZkyBba=7ZP6rTZXR7Q@mail.gmail.com>
Message-ID: <CAHLnndZ+2zs12AMaoMsxYYLD=Fgt7ecdvCHDtWfrzN58KM_z4g@mail.gmail.com>

You are right! Then I am not sure whether the test in ANOVA
corresponding to a continuous variable makes sense.
    Hanna

2015-05-26 16:09 GMT-04:00, Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> Because they test different hypothesis.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-05-26 21:46 GMT+02:00 li li <hannah.hlx at gmail.com>:
>
>> Thanks so much for replying.
>> Yes LimerTest package could be used to get pvalues when using lmer
>> function. But still the summary and anova function give different
>> pvalues.
>>    Hanna
>>
>> 2015-05-26 15:19 GMT-04:00, byron vinueza <byronvinu_8 at hotmail.com>:
>> > You can use the lmerTest package .
>> >
>> >
>> >
>> >
>> >
>> > Enviado desde mi iPhone
>> >
>> >> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com> escribi?:
>> >>
>> >> Hi all,
>> >>  I am using the lme function to run a random coefficient model. Please
>> >> see
>> >> output (mod1) as below.
>> >>  I need to obtain the pvalue for the fixed effect. As you can see,
>> >> the pvalues given using the summary function is different from the
>> >> resutls given in anova function.
>> >> Why should they be different and which one is the correct one to use?
>> >>   Thanks!
>> >>      Hanna
>> >>
>> >>
>> >>> summary(mod1)
>> >> Linear mixed-effects model fit by REML
>> >> Data: minus20C1
>> >>        AIC       BIC   logLik
>> >>  -82.60042 -70.15763 49.30021
>> >>
>> >> Random effects:
>> >> Formula: ~1 + months | lot
>> >> Structure: General positive-definite, Log-Cholesky parametrization
>> >>            StdDev       Corr
>> >> (Intercept) 8.907584e-03 (Intr)
>> >> months      6.039781e-05 -0.096
>> >> Residual    4.471243e-02
>> >>
>> >> Fixed effects: ti ~ type * months
>> >>                     Value   Std.Error DF   t-value p-value
>> >> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>> >> type             0.13502089 0.026676101  4  5.061493  0.0072
>> >> months          0.00804790 0.001218941 31  6.602368  0.0000
>> >> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>> >> Correlation:
>> >>               (Intr) typ months
>> >> type        -0.633
>> >> months         -0.785  0.497
>> >> type:months  0.321 -0.762 -0.409
>> >>
>> >> Standardized Within-Group Residuals:
>> >>          Min            Q1           Med            Q3           Max
>> >> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>> >>
>> >> Number of Observations: 39
>> >> Number of Groups: 6
>> >>> anova(mod1)
>> >>            numDF denDF   F-value p-value
>> >> (Intercept)     1    31 2084.0265  <.0001
>> >> type            1     4   10.8957  0.0299
>> >> months          1    31   38.3462  <.0001
>> >> type:months     1    31    5.4118  0.0267
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From hannah.hlx at gmail.com  Wed May 27 01:09:39 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 26 May 2015 19:09:39 -0400
Subject: [R-sig-ME] different results from lme and lmer function
Message-ID: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>

Hi all,
  I am fitting a random slope and random intercept model using R. I
used both lme and lmer funciton for the same model. However I got
different results as shown below (different variance component
estimates and so on). I think that is really confusing. They should
produce close results. Anyone has any thoughts or suggestions. Also,
which one should be comparable to sas results?
 Thanks!
  Hanna

## using lme function
> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, na.action=na.omit,
+ data=one, control = lmeControl(opt = "optim"))
> summary(mod_lme)
Linear mixed-effects model fit by REML
 Data: one
        AIC       BIC   logLik
  -82.60042 -70.15763 49.30021

Random effects:
 Formula: ~1 + months | lot
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 8.907584e-03 (Intr)
months      6.039781e-05 -0.096
Residual    4.471243e-02

Fixed effects: ti ~ type * months
                     Value   Std.Error DF   t-value p-value
(Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
type            0.13502089 0.026676101  4  5.061493  0.0072
months          0.00804790 0.001218941 31  6.602368  0.0000
type:months -0.00693679 0.002981859 31 -2.326329  0.0267
 Correlation:
               (Intr) typPPQ months
type           -0.633
months         -0.785  0.497
type:months  0.321 -0.762 -0.409

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00

Number of Observations: 39
Number of Groups: 6




###Using lmer function
> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit, data=one)
> summary(mod_lmer)
Linear mixed model fit by REML t-tests use Satterthwaite approximations to
  degrees of freedom [merModLmerTest]
Formula: ti ~ type * months + (1 + months | lot)
   Data: one

REML criterion at convergence: -98.8

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.1347 -0.2156 -0.0067  0.3615  2.0840

Random effects:
 Groups   Name        Variance  Std.Dev.  Corr
 lot      (Intercept) 2.870e-04 0.0169424
          months      4.135e-07 0.0006431 -1.00
 Residual             1.950e-03 0.0441644
Number of obs: 39, groups:  lot, 6

Fixed effects:
                Estimate Std. Error        df t value Pr(>|t|)
(Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
type         0.135021   0.028880  6.802000   4.675  0.00245 **
months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) typPPQ months
type     -0.646
months      -0.825  0.533
type:month  0.347 -0.768 -0.421


From bbolker at gmail.com  Wed May 27 02:03:10 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 May 2015 20:03:10 -0400
Subject: [R-sig-ME] different results from lme and lmer function
In-Reply-To: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
Message-ID: <CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>

  These actually aren't terribly different from each other.  I suspect
that lmer is slightly closer to the correct answer, because lme
reports a "log-likelihood" (really -1/2 times the REML criterion) of
49.30021, while lmer reports a REML criterion of  -98.8 -> slightly
better fit at -R/2 = 49.4.  The residual sds are 0.0447 (lme) vs.
0.0442 (lmer); the intercept sd estimate is 0.016 vs 0.0089,
admittedly a bit low, and both month sds are very small.  lmer
indicates a singular fit (correlation of -1).    If you look at the
confidence intervals on these estimates (confint(fitted_model) in
lme4; intervals(fitted_model) in lme) I think you'll find that the
confidence intervals are much wider than these differences (you may
even find that lme reports that it can't give you the intervals
because the Hessian [curvature] matrix is not positive definite).

  Both should be comparable to SAS PROC MIXED results, I think, if
you get the syntax right ...

On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com> wrote:
> Hi all,
>   I am fitting a random slope and random intercept model using R. I
> used both lme and lmer funciton for the same model. However I got
> different results as shown below (different variance component
> estimates and so on). I think that is really confusing. They should
> produce close results. Anyone has any thoughts or suggestions. Also,
> which one should be comparable to sas results?
>  Thanks!
>   Hanna
>
> ## using lme function
>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, na.action=na.omit,
> + data=one, control = lmeControl(opt = "optim"))
>> summary(mod_lme)
> Linear mixed-effects model fit by REML
>  Data: one
>         AIC       BIC   logLik
>   -82.60042 -70.15763 49.30021
>
> Random effects:
>  Formula: ~1 + months | lot
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 8.907584e-03 (Intr)
> months      6.039781e-05 -0.096
> Residual    4.471243e-02
>
> Fixed effects: ti ~ type * months
>                      Value   Std.Error DF   t-value p-value
> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
> type            0.13502089 0.026676101  4  5.061493  0.0072
> months          0.00804790 0.001218941 31  6.602368  0.0000
> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>  Correlation:
>                (Intr) typPPQ months
> type           -0.633
> months         -0.785  0.497
> type:months  0.321 -0.762 -0.409
>
> Standardized Within-Group Residuals:
>           Min            Q1           Med            Q3           Max
> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>
> Number of Observations: 39
> Number of Groups: 6
>
>
>
>
> ###Using lmer function
>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit, data=one)
>> summary(mod_lmer)
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>   degrees of freedom [merModLmerTest]
> Formula: ti ~ type * months + (1 + months | lot)
>    Data: one
>
> REML criterion at convergence: -98.8
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.1347 -0.2156 -0.0067  0.3615  2.0840
>
> Random effects:
>  Groups   Name        Variance  Std.Dev.  Corr
>  lot      (Intercept) 2.870e-04 0.0169424
>           months      4.135e-07 0.0006431 -1.00
>  Residual             1.950e-03 0.0441644
> Number of obs: 39, groups:  lot, 6
>
> Fixed effects:
>                 Estimate Std. Error        df t value Pr(>|t|)
> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
> type         0.135021   0.028880  6.802000   4.675  0.00245 **
> months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) typPPQ months
> type     -0.646
> months      -0.825  0.533
> type:month  0.347 -0.768 -0.421
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed May 27 02:23:48 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 May 2015 20:23:48 -0400
Subject: [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <CAHLnndZ+2zs12AMaoMsxYYLD=Fgt7ecdvCHDtWfrzN58KM_z4g@mail.gmail.com>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>	<BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>	<CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>	<CAJuCY5ykuSex7iqwm-+V7fCAZrhD8h6U3B3Gb513qAYJs8G=Sg@mail.gmail.com>	<CAHLnndbrFTiL_hCk3BTtrgOw2vQQdaTyZkyBba=7ZP6rTZXR7Q@mail.gmail.com>
	<CAHLnndZ+2zs12AMaoMsxYYLD=Fgt7ecdvCHDtWfrzN58KM_z4g@mail.gmail.com>
Message-ID: <55650E94.5080408@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-05-26 06:56 PM, li li wrote:
> You are right! Then I am not sure whether the test in ANOVA 
> corresponding to a continuous variable makes sense. Hanna
> 

   I'm not sure what you mean.

   summary() gives Wald (marginal) tests of individual parameters;
anova gives *sequential* F tests.  (They agree for the interaction
term.)   This is a large topic.  You might find car::Anova() to be a
useful tool for this ...

> 2015-05-26 16:09 GMT-04:00, Thierry Onkelinx
> <thierry.onkelinx at inbo.be>:
>> Because they test different hypothesis.
>> 
>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>> Research Institute for Nature and Forest team Biometrie &
>> Kwaliteitszorg / team Biometrics & Quality Assurance 
>> Kliniekstraat 25 1070 Anderlecht Belgium
>> 
>> To call in the statistician after the experiment is done may be
>> no more than asking him to perform a post-mortem examination: he
>> may be able to say what the experiment died of. ~ Sir Ronald
>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>> Brinner The combination of some data and an aching desire for an
>> answer does not ensure that a reasonable answer can be extracted
>> from a given body of data. ~ John Tukey
>> 
>> 2015-05-26 21:46 GMT+02:00 li li <hannah.hlx at gmail.com>:
>> 
>>> Thanks so much for replying. Yes LimerTest package could be
>>> used to get pvalues when using lmer function. But still the
>>> summary and anova function give different pvalues. Hanna
>>> 
>>> 2015-05-26 15:19 GMT-04:00, byron vinueza
>>> <byronvinu_8 at hotmail.com>:
>>>> You can use the lmerTest package .
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Enviado desde mi iPhone
>>>> 
>>>>> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com>
>>>>> escribi?:
>>>>> 
>>>>> Hi all, I am using the lme function to run a random
>>>>> coefficient model. Please see output (mod1) as below. I
>>>>> need to obtain the pvalue for the fixed effect. As you can
>>>>> see, the pvalues given using the summary function is
>>>>> different from the resutls given in anova function. Why
>>>>> should they be different and which one is the correct one
>>>>> to use? Thanks! Hanna
>>>>> 
>>>>> 
>>>>>> summary(mod1)
>>>>> Linear mixed-effects model fit by REML Data: minus20C1 AIC
>>>>> BIC   logLik -82.60042 -70.15763 49.30021
>>>>> 
>>>>> Random effects: Formula: ~1 + months | lot Structure:
>>>>> General positive-definite, Log-Cholesky parametrization 
>>>>> StdDev       Corr (Intercept) 8.907584e-03 (Intr) months
>>>>> 6.039781e-05 -0.096 Residual    4.471243e-02
>>>>> 
>>>>> Fixed effects: ti ~ type * months Value   Std.Error DF
>>>>> t-value p-value (Intercept)     0.25831245 0.016891587 31
>>>>> 15.292373  0.0000 type             0.13502089 0.026676101
>>>>> 4  5.061493  0.0072 months          0.00804790 0.001218941
>>>>> 31  6.602368  0.0000 type:months -0.00693679 0.002981859 31
>>>>> -2.326329  0.0267 Correlation: (Intr) typ months type
>>>>> -0.633 months         -0.785  0.497 type:months  0.321
>>>>> -0.762 -0.409
>>>>> 
>>>>> Standardized Within-Group Residuals: Min            Q1
>>>>> Med            Q3           Max -2.162856e+00 -1.962972e-01
>>>>> -2.771184e-05  3.749035e-01  2.088392e+00
>>>>> 
>>>>> Number of Observations: 39 Number of Groups: 6
>>>>>> anova(mod1)
>>>>> numDF denDF   F-value p-value (Intercept)     1    31
>>>>> 2084.0265  <.0001 type            1     4   10.8957
>>>>> 0.0299 months          1    31   38.3462  <.0001 
>>>>> type:months     1    31    5.4118  0.0267
>>>>> 
>>>>> _______________________________________________ 
>>>>> R-sig-mixed-models at r-project.org mailing list 
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVZQ6UAAoJEOCV5YRblxUH738H/Rh9JRV3oT2E1p0vj8BhEuX6
Qfg/TvFjXg5LLK58c7UMj1mGlxf+IDOgr8IJ3veEVV6pr8PLoUT0QVAICVWQ5BUl
8c8lJnYRsluDSbki5WbwkRB5WJEnAZ8tOZV5DM1Xb6BVJb+LBes2q+DsmRY6ZN6N
PmMzbDQsc9Q1qRoYXWIbhkhpgqISPQdhSlmelltM6OQmy8AdhIoIN7Tx1fywMFuV
sB40Nk75rzb8WnRcbkpfEeD5rYKeeUCW3uunpVFD/NFUawkMz10g/9yaacxEBZ1w
59fvIaMvv1tlZEVGGnRL3ysaQZrXwXqN3QNp3OOCh40b5QNWeCP7Fv8yqOKsHdM=
=DaPE
-----END PGP SIGNATURE-----


From jsorkin at grecc.umaryland.edu  Wed May 27 02:47:12 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 26 May 2015 20:47:12 -0400
Subject: [R-sig-ME] [R]  different results from lme and lmer function
In-Reply-To: <CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
	<CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>
Message-ID: <5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>

Ben,
I doubt the very small difference in log likelihood gives much, if any
information about which model is a better fit. Even if we overlook the
limited precision of the estimate of the REML criterion, the difference
is so small as to me of minimal importance.
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On May 26, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>  These actually aren't terribly different from each other.  I suspect
> that lmer is slightly closer to the correct answer, because lme
> reports a "log-likelihood" (really -1/2 times the REML criterion) of
> 49.30021, while lmer reports a REML criterion of  -98.8 -> slightly
> better fit at -R/2 = 49.4.  The residual sds are 0.0447 (lme) vs.
> 0.0442 (lmer); the intercept sd estimate is 0.016 vs 0.0089,
> admittedly a bit low, and both month sds are very small.  lmer
> indicates a singular fit (correlation of -1).    If you look at the
> confidence intervals on these estimates (confint(fitted_model) in
> lme4; intervals(fitted_model) in lme) I think you'll find that the
> confidence intervals are much wider than these differences (you may
> even find that lme reports that it can't give you the intervals
> because the Hessian [curvature] matrix is not positive definite).
> 
>  Both should be comparable to SAS PROC MIXED results, I think, if
> you get the syntax right ...
> 
>> On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com> wrote:
>> Hi all,
>>  I am fitting a random slope and random intercept model using R. I
>> used both lme and lmer funciton for the same model. However I got
>> different results as shown below (different variance component
>> estimates and so on). I think that is really confusing. They should
>> produce close results. Anyone has any thoughts or suggestions. Also,
>> which one should be comparable to sas results?
>> Thanks!
>>  Hanna
>> 
>> ## using lme function
>>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot,
na.action=na.omit,
>> + data=one, control = lmeControl(opt = "optim"))
>>> summary(mod_lme)
>> Linear mixed-effects model fit by REML
>> Data: one
>>        AIC       BIC   logLik
>>  -82.60042 -70.15763 49.30021
>> 
>> Random effects:
>> Formula: ~1 + months | lot
>> Structure: General positive-definite, Log-Cholesky parametrization
>>            StdDev       Corr
>> (Intercept) 8.907584e-03 (Intr)
>> months      6.039781e-05 -0.096
>> Residual    4.471243e-02
>> 
>> Fixed effects: ti ~ type * months
>>                     Value   Std.Error DF   t-value p-value
>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>> type            0.13502089 0.026676101  4  5.061493  0.0072
>> months          0.00804790 0.001218941 31  6.602368  0.0000
>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>> Correlation:
>>               (Intr) typPPQ months
>> type           -0.633
>> months         -0.785  0.497
>> type:months  0.321 -0.762 -0.409
>> 
>> Standardized Within-Group Residuals:
>>          Min            Q1           Med            Q3           Max
>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>> 
>> Number of Observations: 39
>> Number of Groups: 6
>> 
>> 
>> 
>> 
>> ###Using lmer function
>>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit,
data=one)
>>> summary(mod_lmer)
>> Linear mixed model fit by REML t-tests use Satterthwaite
approximations to
>>  degrees of freedom [merModLmerTest]
>> Formula: ti ~ type * months + (1 + months | lot)
>>   Data: one
>> 
>> REML criterion at convergence: -98.8
>> 
>> Scaled residuals:
>>    Min      1Q  Median      3Q     Max
>> -2.1347 -0.2156 -0.0067  0.>> lot      (Intercept) 2.870e-04 0.0169424
>>          months      4.135e-07 0.0006431 -1.00
>> Residual             1.950e-03 0.0441644
>> Number of obs: 39, groups:  lot, 6
>> 
>> Fixed effects:
>>                Estimate Std. Error        df t value Pr(>|t|)
>> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
>> type         0.135021   0.028880  6.802000   4.675  0.00245 **
>> months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
>> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> Correlation of Fixed Effects:
>>            (Intr) typPPQ months
>> type     -0.646
>> months      -0.825  0.533
>> type:month  0.347 -0.768 -0.421
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From bbolker at gmail.com  Wed May 27 02:50:23 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 May 2015 20:50:23 -0400
Subject: [R-sig-ME] [R]  different results from lme and lmer function
In-Reply-To: <5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
	<CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>
	<5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>
Message-ID: <CABghstR5YxqZHgE4tjfgGNNo4zVBPXFmxaN3GV3v0e=sHYrUGw@mail.gmail.com>

I agree that the difference is trivially small/practically
unimportant.  The point here is that -- just for those of us who are
interested in the details of the methods -- lme4 and lme are fitting
*exactly* the same model, by similar methods, so in general they
should converge to the same answer (to a somewhat closer tolerance
than this).  Generally when they don't it's because the model is
slightly unstable, and I have generally found that lme4 does slightly
better (but I wouldn't rule out the opposite case).

 cheers
    Ben Bolker


On Tue, May 26, 2015 at 8:47 PM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> Ben,
> I doubt the very small difference in log likelihood gives much, if any
> information about which model is a better fit. Even if we overlook the
> limited precision of the estimate of the REML criterion, the difference is
> so small as to me of minimal importance.
> John
>
> John David Sorkin M.D., Ph.D.
>
> Professor of Medicine
>
> Chief, Biostatistics and Informatics
>
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
>
> Baltimore VA Medical Center
>
> 10 North Greene Street
>
> GRECC (BT/18/GR)
>
> Baltimore, MD 21201-1524
>
> (Phone) 410-605-7119
>
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> On May 26, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>  These actually aren't terribly different from each other.  I suspect
> that lmer is slightly closer to the correct answer, because lme
> reports a "log-likelihood" (really -1/2 times the REML criterion) of
> 49.30021, while lmer reports a REML criterion of  -98.8 -> slightly
> better fit at -R/2 = 49.4.  The residual sds are 0.0447 (lme) vs.
> 0.0442 (lmer); the intercept sd estimate is 0.016 vs 0.0089,
> admittedly a bit low, and both month sds are very small.  lmer
> indicates a singular fit (correlation of -1).    If you look at the
> confidence intervals on these estimates (confint(fitted_model) in
> lme4; intervals(fitted_model) in lme) I think you'll find that the
> confidence intervals are much wider than these differences (you may
> even find that lme reports that it can't give you the intervals
> because the Hessian [curvature] matrix is not positive definite).
>
>  Both should be comparable to SAS PROC MIXED results, I think, if
> you get the syntax right ...
>
> On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com> wrote:
>
> Hi all,
>
>  I am fitting a random slope and random intercept model using R. I
>
> used both lme and lmer funciton for the same model. However I got
>
> different results as shown below (different variance component
>
> estimates and so on). I think that is really confusing. They should
>
> produce close results. Anyone has any thoughts or suggestions. Also,
>
> which one should be comparable to sas results?
>
> Thanks!
>
>  Hanna
>
>
> ## using lme function
>
> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, na.action=na.omit,
>
> + data=one, control = lmeControl(opt = "optim"))
>
> summary(mod_lme)
>
> Linear mixed-effects model fit by REML
>
> Data: one
>
>        AIC       BIC   logLik
>
>  -82.60042 -70.15763 49.30021
>
>
> Random effects:
>
> Formula: ~1 + months | lot
>
> Structure: General positive-definite, Log-Cholesky parametrization
>
>            StdDev       Corr
>
> (Intercept) 8.907584e-03 (Intr)
>
> months      6.039781e-05 -0.096
>
> Residual    4.471243e-02
>
>
> Fixed effects: ti ~ type * months
>
>                     Value   Std.Error DF   t-value p-value
>
> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>
> type            0.13502089 0.026676101  4  5.061493  0.0072
>
> months          0.00804790 0.001218941 31  6.602368  0.0000
>
> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>
> Correlation:
>
>               (Intr) typPPQ months
>
> type           -0.633
>
> months         -0.785  0.497
>
> type:months  0.321 -0.762 -0.409
>
>
> Standardized Within-Group Residuals:
>
>          Min            Q1           Med            Q3           Max
>
> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>
>
> Number of Observations: 39
>
> Number of Groups: 6
>
>
>
>
>
> ###Using lmer function
>
> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit,
> data=one)
>
> summary(mod_lmer)
>
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>
>  degrees of freedom [merModLmerTest]
>
> Formula: ti ~ type * months + (1 + months | lot)
>
>   Data: one
>
>
> REML criterion at convergence: -98.8
>
>
> Scaled residuals:
>
>    Min      1Q  Median      3Q     Max
>
> -2.1347 -0.2156 -0.0067  0.3615  2.0840
>
>
> Random effects:
>
> Groups   Name        Variance  Std.Dev.  Corr
>
> lot      (Intercept) 2.870e-04 0.0169424
>
>          months      4.135e-07 0.0006431 -1.00
>
> Residual             1.950e-03 0.0441644
>
> Number of obs: 39, groups:  lot, 6
>
>
> Fixed effects:
>
>                Estimate Std. Error        df t value Pr(>|t|)
>
> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
>
> type         0.135021   0.028880  6.802000   4.675  0.00245 **
>
> months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
>
> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Correlation of Fixed Effects:
>
>            (Intr) typPPQ months
>
> type     -0.646
>
> months      -0.825  0.533
>
> type:month  0.347 -0.768 -0.421
>
>
> _______________________________________________
>
> R-sig-mixed-models at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Confidentiality Statement:
>
> This email message, including any attachments, is for ...{{dropped:7}}


From kalakouentin at gmail.com  Wed May 27 03:45:24 2015
From: kalakouentin at gmail.com (Pantelis Z. Hadjipantelis)
Date: Tue, 26 May 2015 18:45:24 -0700
Subject: [R-sig-ME] [R]  different results from lme and lmer function
In-Reply-To: <CABghstR5YxqZHgE4tjfgGNNo4zVBPXFmxaN3GV3v0e=sHYrUGw@mail.gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>	<CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>	<5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>
	<CABghstR5YxqZHgE4tjfgGNNo4zVBPXFmxaN3GV3v0e=sHYrUGw@mail.gmail.com>
Message-ID: <556521B4.9040400@gmail.com>

Ben,

I fully accept that the two procedures should converge at the same 
solution but as the OP does not give the versions used. Therefore I am 
not sure that the fitting is done using the same procedure ("bobyqa" vs. 
"Nelder_Mead"). Different optim. algorithms with different initial 
values might converge to different local minima. The OP has only 39 
subjects so for a model of this size over-fitting will not be unheard 
off given the number of parameters.

I am curious though for your later comment: I understand that in the 
case of an unstable model you might expect lme4 to be slightly better, 
but wouldn't the singular fit in the correlation (-1) suggest that 
lmer's fit is sub-optimal?

All best,
Pantelis


On 05/26/2015 05:50 PM, Ben Bolker wrote:
> I agree that the difference is trivially small/practically
> unimportant.  The point here is that -- just for those of us who are
> interested in the details of the methods -- lme4 and lme are fitting
> *exactly* the same model, by similar methods, so in general they
> should converge to the same answer (to a somewhat closer tolerance
> than this).  Generally when they don't it's because the model is
> slightly unstable, and I have generally found that lme4 does slightly
> better (but I wouldn't rule out the opposite case).
>
>   cheers
>      Ben Bolker
>
>
> On Tue, May 26, 2015 at 8:47 PM, John Sorkin
> <jsorkin at grecc.umaryland.edu> wrote:
>> Ben,
>> I doubt the very small difference in log likelihood gives much, if any
>> information about which model is a better fit. Even if we overlook the
>> limited precision of the estimate of the REML criterion, the difference is
>> so small as to me of minimal importance.
>> John
>>
>> John David Sorkin M.D., Ph.D.
>>
>> Professor of Medicine
>>
>> Chief, Biostatistics and Informatics
>>
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>>
>> Baltimore VA Medical Center
>>
>> 10 North Greene Street
>>
>> GRECC (BT/18/GR)
>>
>> Baltimore, MD 21201-1524
>>
>> (Phone) 410-605-7119
>>
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>> On May 26, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>   These actually aren't terribly different from each other.  I suspect
>> that lmer is slightly closer to the correct answer, because lme
>> reports a "log-likelihood" (really -1/2 times the REML criterion) of
>> 49.30021, while lmer reports a REML criterion of  -98.8 -> slightly
>> better fit at -R/2 = 49.4.  The residual sds are 0.0447 (lme) vs.
>> 0.0442 (lmer); the intercept sd estimate is 0.016 vs 0.0089,
>> admittedly a bit low, and both month sds are very small.  lmer
>> indicates a singular fit (correlation of -1).    If you look at the
>> confidence intervals on these estimates (confint(fitted_model) in
>> lme4; intervals(fitted_model) in lme) I think you'll find that the
>> confidence intervals are much wider than these differences (you may
>> even find that lme reports that it can't give you the intervals
>> because the Hessian [curvature] matrix is not positive definite).
>>
>>   Both should be comparable to SAS PROC MIXED results, I think, if
>> you get the syntax right ...
>>
>> On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com> wrote:
>>
>> Hi all,
>>
>>   I am fitting a random slope and random intercept model using R. I
>>
>> used both lme and lmer funciton for the same model. However I got
>>
>> different results as shown below (different variance component
>>
>> estimates and so on). I think that is really confusing. They should
>>
>> produce close results. Anyone has any thoughts or suggestions. Also,
>>
>> which one should be comparable to sas results?
>>
>> Thanks!
>>
>>   Hanna
>>
>>
>> ## using lme function
>>
>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, na.action=na.omit,
>>
>> + data=one, control = lmeControl(opt = "optim"))
>>
>> summary(mod_lme)
>>
>> Linear mixed-effects model fit by REML
>>
>> Data: one
>>
>>         AIC       BIC   logLik
>>
>>   -82.60042 -70.15763 49.30021
>>
>>
>> Random effects:
>>
>> Formula: ~1 + months | lot
>>
>> Structure: General positive-definite, Log-Cholesky parametrization
>>
>>             StdDev       Corr
>>
>> (Intercept) 8.907584e-03 (Intr)
>>
>> months      6.039781e-05 -0.096
>>
>> Residual    4.471243e-02
>>
>>
>> Fixed effects: ti ~ type * months
>>
>>                      Value   Std.Error DF   t-value p-value
>>
>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>>
>> type            0.13502089 0.026676101  4  5.061493  0.0072
>>
>> months          0.00804790 0.001218941 31  6.602368  0.0000
>>
>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>>
>> Correlation:
>>
>>                (Intr) typPPQ months
>>
>> type           -0.633
>>
>> months         -0.785  0.497
>>
>> type:months  0.321 -0.762 -0.409
>>
>>
>> Standardized Within-Group Residuals:
>>
>>           Min            Q1           Med            Q3           Max
>>
>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>>
>>
>> Number of Observations: 39
>>
>> Number of Groups: 6
>>
>>
>>
>>
>>
>> ###Using lmer function
>>
>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit,
>> data=one)
>>
>> summary(mod_lmer)
>>
>> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>>
>>   degrees of freedom [merModLmerTest]
>>
>> Formula: ti ~ type * months + (1 + months | lot)
>>
>>    Data: one
>>
>>
>> REML criterion at convergence: -98.8
>>
>>
>> Scaled residuals:
>>
>>     Min      1Q  Median      3Q     Max
>>
>> -2.1347 -0.2156 -0.0067  0.3615  2.0840
>>
>>
>> Random effects:
>>
>> Groups   Name        Variance  Std.Dev.  Corr
>>
>> lot      (Intercept) 2.870e-04 0.0169424
>>
>>           months      4.135e-07 0.0006431 -1.00
>>
>> Residual             1.950e-03 0.0441644
>>
>> Number of obs: 39, groups:  lot, 6
>>
>>
>> Fixed effects:
>>
>>                 Estimate Std. Error        df t value Pr(>|t|)
>>
>> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
>>
>> type         0.135021   0.028880  6.802000   4.675  0.00245 **
>>
>> months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
>>
>> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
>>
>> ---
>>
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>> Correlation of Fixed Effects:
>>
>>             (Intr) typPPQ months
>>
>> type     -0.646
>>
>> months      -0.825  0.533
>>
>> type:month  0.347 -0.768 -0.421
>>
>>
>> _______________________________________________
>>
>> R-sig-mixed-models at r-project.org mailing list
>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> Confidentiality Statement:
>>
>> This email message, including any attachments, is for ...{{dropped:7}}
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed May 27 03:51:24 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 May 2015 21:51:24 -0400
Subject: [R-sig-ME] [R]  different results from lme and lmer function
In-Reply-To: <556521B4.9040400@gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>	<CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>	<5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>	<CABghstR5YxqZHgE4tjfgGNNo4zVBPXFmxaN3GV3v0e=sHYrUGw@mail.gmail.com>
	<556521B4.9040400@gmail.com>
Message-ID: <5565231C.20208@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-05-26 09:45 PM, Pantelis Z. Hadjipantelis wrote:
> Ben,
> 
> I fully accept that the two procedures should converge at the same 
> solution but as the OP does not give the versions used. Therefore I
> am not sure that the fitting is done using the same procedure
> ("bobyqa" vs. "Nelder_Mead"). Different optim. algorithms with
> different initial values might converge to different local minima.
> The OP has only 39 subjects so for a model of this size
> over-fitting will not be unheard off given the number of
> parameters.
> 
> I am curious though for your later comment: I understand that in
> the case of an unstable model you might expect lme4 to be slightly
> better, but wouldn't the singular fit in the correlation (-1)
> suggest that lmer's fit is sub-optimal?
> 
> All best, Pantelis

  No, I suspect that the singular fit actually represents the best
fit/minimal achievable REML criterion for this problem.  I can't say
for sure (and of course none of us can without having the original
data to play with), but based on my previous experiences I do suspect
that this is just a very flat surface and that lme has stopped
*slightly* too soon.

  Ben Bolker


> 
> 
> On 05/26/2015 05:50 PM, Ben Bolker wrote:
>> I agree that the difference is trivially small/practically 
>> unimportant.  The point here is that -- just for those of us who
>> are interested in the details of the methods -- lme4 and lme are
>> fitting *exactly* the same model, by similar methods, so in
>> general they should converge to the same answer (to a somewhat
>> closer tolerance than this).  Generally when they don't it's
>> because the model is slightly unstable, and I have generally
>> found that lme4 does slightly better (but I wouldn't rule out the
>> opposite case).
>> 
>> cheers Ben Bolker
>> 
>> 
>> On Tue, May 26, 2015 at 8:47 PM, John Sorkin 
>> <jsorkin at grecc.umaryland.edu> wrote:
>>> Ben, I doubt the very small difference in log likelihood gives
>>> much, if any information about which model is a better fit.
>>> Even if we overlook the limited precision of the estimate of
>>> the REML criterion, the difference is so small as to me of
>>> minimal importance. John
>>> 
>>> John David Sorkin M.D., Ph.D.
>>> 
>>> Professor of Medicine
>>> 
>>> Chief, Biostatistics and Informatics
>>> 
>>> University of Maryland School of Medicine Division of
>>> Gerontology and Geriatric Medicine
>>> 
>>> Baltimore VA Medical Center
>>> 
>>> 10 North Greene Street
>>> 
>>> GRECC (BT/18/GR)
>>> 
>>> Baltimore, MD 21201-1524
>>> 
>>> (Phone) 410-605-7119
>>> 
>>> (Fax) 410-605-7913 (Please call phone number above prior to
>>> faxing)
>>> 
>>> 
>>> On May 26, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com>
>>> wrote:
>>> 
>>> These actually aren't terribly different from each other.  I
>>> suspect that lmer is slightly closer to the correct answer,
>>> because lme reports a "log-likelihood" (really -1/2 times the
>>> REML criterion) of 49.30021, while lmer reports a REML
>>> criterion of  -98.8 -> slightly better fit at -R/2 = 49.4.  The
>>> residual sds are 0.0447 (lme) vs. 0.0442 (lmer); the intercept
>>> sd estimate is 0.016 vs 0.0089, admittedly a bit low, and both
>>> month sds are very small.  lmer indicates a singular fit
>>> (correlation of -1).    If you look at the confidence intervals
>>> on these estimates (confint(fitted_model) in lme4;
>>> intervals(fitted_model) in lme) I think you'll find that the 
>>> confidence intervals are much wider than these differences (you
>>> may even find that lme reports that it can't give you the
>>> intervals because the Hessian [curvature] matrix is not
>>> positive definite).
>>> 
>>> Both should be comparable to SAS PROC MIXED results, I think,
>>> if you get the syntax right ...
>>> 
>>> On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com>
>>> wrote:
>>> 
>>> Hi all,
>>> 
>>> I am fitting a random slope and random intercept model using R.
>>> I used both lme and lmer funciton for the same model. However I
>>> got different results as shown below (different variance
>>> component estimates and so on). I think that is really
>>> confusing. They should produce close results. Anyone has any
>>> thoughts or suggestions. Also, which one should be comparable
>>> to sas results?
>>> 
>>> Thanks!
>>> 
>>> Hanna
>>> 
>>> 
>>> ## using lme function
>>> 
>>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, 
>>> na.action=na.omit,
>>> 
>>> + data=one, control = lmeControl(opt = "optim"))
>>> 
>>> summary(mod_lme)
>>> 
>>> Linear mixed-effects model fit by REML
>>> 
>>> Data: one
>>> 
>>> AIC       BIC   logLik
>>> 
>>> -82.60042 -70.15763 49.30021
>>> 
>>> 
>>> Random effects:
>>> 
>>> Formula: ~1 + months | lot
>>> 
>>> Structure: General positive-definite, Log-Cholesky
>>> parametrization
>>> 
>>> StdDev       Corr
>>> 
>>> (Intercept) 8.907584e-03 (Intr)
>>> 
>>> months      6.039781e-05 -0.096
>>> 
>>> Residual    4.471243e-02
>>> 
>>> 
>>> Fixed effects: ti ~ type * months
>>> 
>>> Value   Std.Error DF   t-value p-value
>>> 
>>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>>> 
>>> type            0.13502089 0.026676101  4  5.061493  0.0072
>>> 
>>> months          0.00804790 0.001218941 31  6.602368  0.0000
>>> 
>>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>>> 
>>> Correlation:
>>> 
>>> (Intr) typPPQ months
>>> 
>>> type           -0.633
>>> 
>>> months         -0.785  0.497
>>> 
>>> type:months  0.321 -0.762 -0.409
>>> 
>>> 
>>> Standardized Within-Group Residuals:
>>> 
>>> Min            Q1           Med            Q3           Max
>>> 
>>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01
>>> 2.088392e+00
>>> 
>>> 
>>> Number of Observations: 39
>>> 
>>> Number of Groups: 6
>>> 
>>> 
>>> 
>>> 
>>> 
>>> ###Using lmer function
>>> 
>>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot),
>>> na.action=na.omit, data=one)
>>> 
>>> summary(mod_lmer)
>>> 
>>> Linear mixed model fit by REML t-tests use Satterthwaite 
>>> approximations to
>>> 
>>> degrees of freedom [merModLmerTest]
>>> 
>>> Formula: ti ~ type * months + (1 + months | lot)
>>> 
>>> Data: one
>>> 
>>> 
>>> REML criterion at convergence: -98.8
>>> 
>>> 
>>> Scaled residuals:
>>> 
>>> Min      1Q  Median      3Q     Max
>>> 
>>> -2.1347 -0.2156 -0.0067  0.3615  2.0840
>>> 
>>> 
>>> Random effects:
>>> 
>>> Groups   Name        Variance  Std.Dev.  Corr
>>> 
>>> lot      (Intercept) 2.870e-04 0.0169424
>>> 
>>> months      4.135e-07 0.0006431 -1.00
>>> 
>>> Residual             1.950e-03 0.0441644
>>> 
>>> Number of obs: 39, groups:  lot, 6
>>> 
>>> 
>>> Fixed effects:
>>> 
>>> Estimate Std. Error        df t value Pr(>|t|)
>>> 
>>> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05
>>> ***
>>> 
>>> type         0.135021   0.028880  6.802000   4.675  0.00245 **
>>> 
>>> months          0.008048   0.001259 11.943000   6.390 3.53e-05
>>> ***
>>> 
>>> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
>>> 
>>> ---
>>> 
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> 
>>> Correlation of Fixed Effects:
>>> 
>>> (Intr) typPPQ months
>>> 
>>> type     -0.646
>>> 
>>> months      -0.825  0.533
>>> 
>>> type:month  0.347 -0.768 -0.421
>>> 
>>> 
>>> _______________________________________________
>>> 
>>> R-sig-mixed-models at r-project.org mailing list
>>> 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> ______________________________________________ 
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>> the posting guide http://www.R-project.org/posting-guide.html 
>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>> 
>>> 
>>> Confidentiality Statement:
>>> 
>>> This email message, including any attachments, is for
>>> ...{{dropped:7}}
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVZSMcAAoJEOCV5YRblxUH+gMH/iqfJA2s56KxPMfON+liOtIy
cvkOk+OO+xBjDfcz9axQ8i8t7RwihONcR02rCmzrpqlTfOjSQqHvwcTuancQVDEg
/QpMfamxn2t3+ah6VWCDg+gB6uhaGnUOPc+06V7rLw920bYBLuN67s74n1xGCnC2
f+wa1lzZ+YLbuZl73Q5KQwaKZmVX+BqDc0eyN2CGtjOZO1A0n7Wewc5IeOHPjh5k
QH0tynG7/Amv3YLGWLA3BYsoiYOW9AxGJy1FOKfY0XuwWm3+VsOEn8RFw15yCU8b
BbVRVbmrv6+Rjy3QOF83wWRHKTtAlb96+yxAt4Qi7Cazuplya5MchHNSmZyAFmg=
=8Jtz
-----END PGP SIGNATURE-----


From kalakouentin at gmail.com  Wed May 27 05:19:16 2015
From: kalakouentin at gmail.com (Pantelis Z. Hadjipantelis)
Date: Tue, 26 May 2015 20:19:16 -0700
Subject: [R-sig-ME] [R]  different results from lme and lmer function
In-Reply-To: <5565231C.20208@gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>	<CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>	<5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>	<CABghstR5YxqZHgE4tjfgGNNo4zVBPXFmxaN3GV3v0e=sHYrUGw@mail.gmail.com>	<556521B4.9040400@gmail.com>
	<5565231C.20208@gmail.com>
Message-ID: <556537B4.4000407@gmail.com>

Hmm... interesting rationale.
Thank you for your insights on this computational matter; they are 
invaluable.

Pantelis

On 26/05/15 18:51, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-05-26 09:45 PM, Pantelis Z. Hadjipantelis wrote:
>> Ben,
>>
>> I fully accept that the two procedures should converge at the same
>> solution but as the OP does not give the versions used. Therefore I
>> am not sure that the fitting is done using the same procedure
>> ("bobyqa" vs. "Nelder_Mead"). Different optim. algorithms with
>> different initial values might converge to different local minima.
>> The OP has only 39 subjects so for a model of this size
>> over-fitting will not be unheard off given the number of
>> parameters.
>>
>> I am curious though for your later comment: I understand that in
>> the case of an unstable model you might expect lme4 to be slightly
>> better, but wouldn't the singular fit in the correlation (-1)
>> suggest that lmer's fit is sub-optimal?
>>
>> All best, Pantelis
>    No, I suspect that the singular fit actually represents the best
> fit/minimal achievable REML criterion for this problem.  I can't say
> for sure (and of course none of us can without having the original
> data to play with), but based on my previous experiences I do suspect
> that this is just a very flat surface and that lme has stopped
> *slightly* too soon.
>
>    Ben Bolker
>
>
>>
>> On 05/26/2015 05:50 PM, Ben Bolker wrote:
>>> I agree that the difference is trivially small/practically
>>> unimportant.  The point here is that -- just for those of us who
>>> are interested in the details of the methods -- lme4 and lme are
>>> fitting *exactly* the same model, by similar methods, so in
>>> general they should converge to the same answer (to a somewhat
>>> closer tolerance than this).  Generally when they don't it's
>>> because the model is slightly unstable, and I have generally
>>> found that lme4 does slightly better (but I wouldn't rule out the
>>> opposite case).
>>>
>>> cheers Ben Bolker
>>>
>>>
>>> On Tue, May 26, 2015 at 8:47 PM, John Sorkin
>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>> Ben, I doubt the very small difference in log likelihood gives
>>>> much, if any information about which model is a better fit.
>>>> Even if we overlook the limited precision of the estimate of
>>>> the REML criterion, the difference is so small as to me of
>>>> minimal importance. John
>>>>
>>>> John David Sorkin M.D., Ph.D.
>>>>
>>>> Professor of Medicine
>>>>
>>>> Chief, Biostatistics and Informatics
>>>>
>>>> University of Maryland School of Medicine Division of
>>>> Gerontology and Geriatric Medicine
>>>>
>>>> Baltimore VA Medical Center
>>>>
>>>> 10 North Greene Street
>>>>
>>>> GRECC (BT/18/GR)
>>>>
>>>> Baltimore, MD 21201-1524
>>>>
>>>> (Phone) 410-605-7119
>>>>
>>>> (Fax) 410-605-7913 (Please call phone number above prior to
>>>> faxing)
>>>>
>>>>
>>>> On May 26, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com>
>>>> wrote:
>>>>
>>>> These actually aren't terribly different from each other.  I
>>>> suspect that lmer is slightly closer to the correct answer,
>>>> because lme reports a "log-likelihood" (really -1/2 times the
>>>> REML criterion) of 49.30021, while lmer reports a REML
>>>> criterion of  -98.8 -> slightly better fit at -R/2 = 49.4.  The
>>>> residual sds are 0.0447 (lme) vs. 0.0442 (lmer); the intercept
>>>> sd estimate is 0.016 vs 0.0089, admittedly a bit low, and both
>>>> month sds are very small.  lmer indicates a singular fit
>>>> (correlation of -1).    If you look at the confidence intervals
>>>> on these estimates (confint(fitted_model) in lme4;
>>>> intervals(fitted_model) in lme) I think you'll find that the
>>>> confidence intervals are much wider than these differences (you
>>>> may even find that lme reports that it can't give you the
>>>> intervals because the Hessian [curvature] matrix is not
>>>> positive definite).
>>>>
>>>> Both should be comparable to SAS PROC MIXED results, I think,
>>>> if you get the syntax right ...
>>>>
>>>> On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com>
>>>> wrote:
>>>>
>>>> Hi all,
>>>>
>>>> I am fitting a random slope and random intercept model using R.
>>>> I used both lme and lmer funciton for the same model. However I
>>>> got different results as shown below (different variance
>>>> component estimates and so on). I think that is really
>>>> confusing. They should produce close results. Anyone has any
>>>> thoughts or suggestions. Also, which one should be comparable
>>>> to sas results?
>>>>
>>>> Thanks!
>>>>
>>>> Hanna
>>>>
>>>>
>>>> ## using lme function
>>>>
>>>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot,
>>>> na.action=na.omit,
>>>>
>>>> + data=one, control = lmeControl(opt = "optim"))
>>>>
>>>> summary(mod_lme)
>>>>
>>>> Linear mixed-effects model fit by REML
>>>>
>>>> Data: one
>>>>
>>>> AIC       BIC   logLik
>>>>
>>>> -82.60042 -70.15763 49.30021
>>>>
>>>>
>>>> Random effects:
>>>>
>>>> Formula: ~1 + months | lot
>>>>
>>>> Structure: General positive-definite, Log-Cholesky
>>>> parametrization
>>>>
>>>> StdDev       Corr
>>>>
>>>> (Intercept) 8.907584e-03 (Intr)
>>>>
>>>> months      6.039781e-05 -0.096
>>>>
>>>> Residual    4.471243e-02
>>>>
>>>>
>>>> Fixed effects: ti ~ type * months
>>>>
>>>> Value   Std.Error DF   t-value p-value
>>>>
>>>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>>>>
>>>> type            0.13502089 0.026676101  4  5.061493  0.0072
>>>>
>>>> months          0.00804790 0.001218941 31  6.602368  0.0000
>>>>
>>>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>>>>
>>>> Correlation:
>>>>
>>>> (Intr) typPPQ months
>>>>
>>>> type           -0.633
>>>>
>>>> months         -0.785  0.497
>>>>
>>>> type:months  0.321 -0.762 -0.409
>>>>
>>>>
>>>> Standardized Within-Group Residuals:
>>>>
>>>> Min            Q1           Med            Q3           Max
>>>>
>>>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01
>>>> 2.088392e+00
>>>>
>>>>
>>>> Number of Observations: 39
>>>>
>>>> Number of Groups: 6
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ###Using lmer function
>>>>
>>>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot),
>>>> na.action=na.omit, data=one)
>>>>
>>>> summary(mod_lmer)
>>>>
>>>> Linear mixed model fit by REML t-tests use Satterthwaite
>>>> approximations to
>>>>
>>>> degrees of freedom [merModLmerTest]
>>>>
>>>> Formula: ti ~ type * months + (1 + months | lot)
>>>>
>>>> Data: one
>>>>
>>>>
>>>> REML criterion at convergence: -98.8
>>>>
>>>>
>>>> Scaled residuals:
>>>>
>>>> Min      1Q  Median      3Q     Max
>>>>
>>>> -2.1347 -0.2156 -0.0067  0.3615  2.0840
>>>>
>>>>
>>>> Random effects:
>>>>
>>>> Groups   Name        Variance  Std.Dev.  Corr
>>>>
>>>> lot      (Intercept) 2.870e-04 0.0169424
>>>>
>>>> months      4.135e-07 0.0006431 -1.00
>>>>
>>>> Residual             1.950e-03 0.0441644
>>>>
>>>> Number of obs: 39, groups:  lot, 6
>>>>
>>>>
>>>> Fixed effects:
>>>>
>>>> Estimate Std. Error        df t value Pr(>|t|)
>>>>
>>>> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05
>>>> ***
>>>>
>>>> type         0.135021   0.028880  6.802000   4.675  0.00245 **
>>>>
>>>> months          0.008048   0.001259 11.943000   6.390 3.53e-05
>>>> ***
>>>>
>>>> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
>>>>
>>>> ---
>>>>
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>>
>>>> Correlation of Fixed Effects:
>>>>
>>>> (Intr) typPPQ months
>>>>
>>>> type     -0.646
>>>>
>>>> months      -0.825  0.533
>>>>
>>>> type:month  0.347 -0.768 -0.421
>>>>
>>>>
>>>> _______________________________________________
>>>>
>>>> R-sig-mixed-models at r-project.org mailing list
>>>>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>>> the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>>
>>>>
>>>> Confidentiality Statement:
>>>>
>>>> This email message, including any attachments, is for
>>>> ...{{dropped:7}}
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVZSMcAAoJEOCV5YRblxUH+gMH/iqfJA2s56KxPMfON+liOtIy
> cvkOk+OO+xBjDfcz9axQ8i8t7RwihONcR02rCmzrpqlTfOjSQqHvwcTuancQVDEg
> /QpMfamxn2t3+ah6VWCDg+gB6uhaGnUOPc+06V7rLw920bYBLuN67s74n1xGCnC2
> f+wa1lzZ+YLbuZl73Q5KQwaKZmVX+BqDc0eyN2CGtjOZO1A0n7Wewc5IeOHPjh5k
> QH0tynG7/Amv3YLGWLA3BYsoiYOW9AxGJy1FOKfY0XuwWm3+VsOEn8RFw15yCU8b
> BbVRVbmrv6+Rjy3QOF83wWRHKTtAlb96+yxAt4Qi7Cazuplya5MchHNSmZyAFmg=
> =8Jtz
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Wed May 27 16:43:47 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 27 May 2015 14:43:47 +0000
Subject: [R-sig-ME] [R] different results from lme and lmer function
In-Reply-To: <5565231C.20208@gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
	<CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>
	<5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>
	<CABghstR5YxqZHgE4tjfgGNNo4zVBPXFmxaN3GV3v0e=sHYrUGw@mail.gmail.com>
	<556521B4.9040400@gmail.com> <5565231C.20208@gmail.com>
Message-ID: <CAO7JsnSNbksxznL+oF8joFuBA8bDd3nPv6SNpF9c5t4HDqcRSg@mail.gmail.com>

On Tue, May 26, 2015 at 8:52 PM Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-05-26 09:45 PM, Pantelis Z. Hadjipantelis wrote:
> > Ben,
> >
> > I fully accept that the two procedures should converge at the same
> > solution but as the OP does not give the versions used. Therefore I
> > am not sure that the fitting is done using the same procedure
> > ("bobyqa" vs. "Nelder_Mead"). Different optim. algorithms with
> > different initial values might converge to different local minima.
> > The OP has only 39 subjects so for a model of this size
> > over-fitting will not be unheard off given the number of
> > parameters.
> >
> > I am curious though for your later comment: I understand that in
> > the case of an unstable model you might expect lme4 to be slightly
> > better, but wouldn't the singular fit in the correlation (-1)
> > suggest that lmer's fit is sub-optimal?
> >
> > All best, Pantelis
>
>   No, I suspect that the singular fit actually represents the best
> fit/minimal achievable REML criterion for this problem.  I can't say
> for sure (and of course none of us can without having the original
> data to play with), but based on my previous experiences I do suspect
> that this is just a very flat surface and that lme has stopped
> *slightly* too soon.
>

Exactly.  You may recall the discussion in "Fitting Linear Mixed-Effects
Models with lme4" (http://arxiv.org/abs/1406.5823, some day, I hope within
my lifetime, to appear in jstatsoft.org) regarding solving the penalized
linear least squares problem, that the formulation in lme uses the relative
precision (inverse of the variance) factor and lmer uses the relative
covariance factor.  An important difference between the two forms is that
the lmer formulation can represent a singular model but the lme formulation
can't.

The lmer fit is singular and lme must stop before the singular model.

>
>   Ben Bolker
>
>
> >
> >
> > On 05/26/2015 05:50 PM, Ben Bolker wrote:
> >> I agree that the difference is trivially small/practically
> >> unimportant.  The point here is that -- just for those of us who
> >> are interested in the details of the methods -- lme4 and lme are
> >> fitting *exactly* the same model, by similar methods, so in
> >> general they should converge to the same answer (to a somewhat
> >> closer tolerance than this).  Generally when they don't it's
> >> because the model is slightly unstable, and I have generally
> >> found that lme4 does slightly better (but I wouldn't rule out the
> >> opposite case).
> >>
> >> cheers Ben Bolker
> >>
> >>
> >> On Tue, May 26, 2015 at 8:47 PM, John Sorkin
> >> <jsorkin at grecc.umaryland.edu> wrote:
> >>> Ben, I doubt the very small difference in log likelihood gives
> >>> much, if any information about which model is a better fit.
> >>> Even if we overlook the limited precision of the estimate of
> >>> the REML criterion, the difference is so small as to me of
> >>> minimal importance. John
> >>>
> >>> John David Sorkin M.D., Ph.D.
> >>>
> >>> Professor of Medicine
> >>>
> >>> Chief, Biostatistics and Informatics
> >>>
> >>> University of Maryland School of Medicine Division of
> >>> Gerontology and Geriatric Medicine
> >>>
> >>> Baltimore VA Medical Center
> >>>
> >>> 10 North Greene Street
> >>>
> >>> GRECC (BT/18/GR)
> >>>
> >>> Baltimore, MD 21201-1524
> >>>
> >>> (Phone) 410-605-7119
> >>>
> >>> (Fax) 410-605-7913 (Please call phone number above prior to
> >>> faxing)
> >>>
> >>>
> >>> On May 26, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com>
> >>> wrote:
> >>>
> >>> These actually aren't terribly different from each other.  I
> >>> suspect that lmer is slightly closer to the correct answer,
> >>> because lme reports a "log-likelihood" (really -1/2 times the
> >>> REML criterion) of 49.30021, while lmer reports a REML
> >>> criterion of  -98.8 -> slightly better fit at -R/2 = 49.4.  The
> >>> residual sds are 0.0447 (lme) vs. 0.0442 (lmer); the intercept
> >>> sd estimate is 0.016 vs 0.0089, admittedly a bit low, and both
> >>> month sds are very small.  lmer indicates a singular fit
> >>> (correlation of -1).    If you look at the confidence intervals
> >>> on these estimates (confint(fitted_model) in lme4;
> >>> intervals(fitted_model) in lme) I think you'll find that the
> >>> confidence intervals are much wider than these differences (you
> >>> may even find that lme reports that it can't give you the
> >>> intervals because the Hessian [curvature] matrix is not
> >>> positive definite).
> >>>
> >>> Both should be comparable to SAS PROC MIXED results, I think,
> >>> if you get the syntax right ...
> >>>
> >>> On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com>
> >>> wrote:
> >>>
> >>> Hi all,
> >>>
> >>> I am fitting a random slope and random intercept model using R.
> >>> I used both lme and lmer funciton for the same model. However I
> >>> got different results as shown below (different variance
> >>> component estimates and so on). I think that is really
> >>> confusing. They should produce close results. Anyone has any
> >>> thoughts or suggestions. Also, which one should be comparable
> >>> to sas results?
> >>>
> >>> Thanks!
> >>>
> >>> Hanna
> >>>
> >>>
> >>> ## using lme function
> >>>
> >>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot,
> >>> na.action=na.omit,
> >>>
> >>> + data=one, control = lmeControl(opt = "optim"))
> >>>
> >>> summary(mod_lme)
> >>>
> >>> Linear mixed-effects model fit by REML
> >>>
> >>> Data: one
> >>>
> >>> AIC       BIC   logLik
> >>>
> >>> -82.60042 -70.15763 49.30021
> >>>
> >>>
> >>> Random effects:
> >>>
> >>> Formula: ~1 + months | lot
> >>>
> >>> Structure: General positive-definite, Log-Cholesky
> >>> parametrization
> >>>
> >>> StdDev       Corr
> >>>
> >>> (Intercept) 8.907584e-03 (Intr)
> >>>
> >>> months      6.039781e-05 -0.096
> >>>
> >>> Residual    4.471243e-02
> >>>
> >>>
> >>> Fixed effects: ti ~ type * months
> >>>
> >>> Value   Std.Error DF   t-value p-value
> >>>
> >>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
> >>>
> >>> type            0.13502089 0.026676101  4  5.061493  0.0072
> >>>
> >>> months          0.00804790 0.001218941 31  6.602368  0.0000
> >>>
> >>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
> >>>
> >>> Correlation:
> >>>
> >>> (Intr) typPPQ months
> >>>
> >>> type           -0.633
> >>>
> >>> months         -0.785  0.497
> >>>
> >>> type:months  0.321 -0.762 -0.409
> >>>
> >>>
> >>> Standardized Within-Group Residuals:
> >>>
> >>> Min            Q1           Med            Q3           Max
> >>>
> >>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01
> >>> 2.088392e+00
> >>>
> >>>
> >>> Number of Observations: 39
> >>>
> >>> Number of Groups: 6
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> ###Using lmer function
> >>>
> >>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot),
> >>> na.action=na.omit, data=one)
> >>>
> >>> summary(mod_lmer)
> >>>
> >>> Linear mixed model fit by REML t-tests use Satterthwaite
> >>> approximations to
> >>>
> >>> degrees of freedom [merModLmerTest]
> >>>
> >>> Formula: ti ~ type * months + (1 + months | lot)
> >>>
> >>> Data: one
> >>>
> >>>
> >>> REML criterion at convergence: -98.8
> >>>
> >>>
> >>> Scaled residuals:
> >>>
> >>> Min      1Q  Median      3Q     Max
> >>>
> >>> -2.1347 -0.2156 -0.0067  0.3615  2.0840
> >>>
> >>>
> >>> Random effects:
> >>>
> >>> Groups   Name        Variance  Std.Dev.  Corr
> >>>
> >>> lot      (Intercept) 2.870e-04 0.0169424
> >>>
> >>> months      4.135e-07 0.0006431 -1.00
> >>>
> >>> Residual             1.950e-03 0.0441644
> >>>
> >>> Number of obs: 39, groups:  lot, 6
> >>>
> >>>
> >>> Fixed effects:
> >>>
> >>> Estimate Std. Error        df t value Pr(>|t|)
> >>>
> >>> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05
> >>> ***
> >>>
> >>> type         0.135021   0.028880  6.802000   4.675  0.00245 **
> >>>
> >>> months          0.008048   0.001259 11.943000   6.390 3.53e-05
> >>> ***
> >>>
> >>> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
> >>>
> >>> ---
> >>>
> >>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>
> >>>
> >>> Correlation of Fixed Effects:
> >>>
> >>> (Intr) typPPQ months
> >>>
> >>> type     -0.646
> >>>
> >>> months      -0.825  0.533
> >>>
> >>> type:month  0.347 -0.768 -0.421
> >>>
> >>>
> >>> _______________________________________________
> >>>
> >>> R-sig-mixed-models at r-project.org mailing list
> >>>
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
> >>> the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>
> >>>
> >>> Confidentiality Statement:
> >>>
> >>> This email message, including any attachments, is for
> >>> ...{{dropped:7}}
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVZSMcAAoJEOCV5YRblxUH+gMH/iqfJA2s56KxPMfON+liOtIy
> cvkOk+OO+xBjDfcz9axQ8i8t7RwihONcR02rCmzrpqlTfOjSQqHvwcTuancQVDEg
> /QpMfamxn2t3+ah6VWCDg+gB6uhaGnUOPc+06V7rLw920bYBLuN67s74n1xGCnC2
> f+wa1lzZ+YLbuZl73Q5KQwaKZmVX+BqDc0eyN2CGtjOZO1A0n7Wewc5IeOHPjh5k
> QH0tynG7/Amv3YLGWLA3BYsoiYOW9AxGJy1FOKfY0XuwWm3+VsOEn8RFw15yCU8b
> BbVRVbmrv6+Rjy3QOF83wWRHKTtAlb96+yxAt4Qi7Cazuplya5MchHNSmZyAFmg=
> =8Jtz
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Wed May 27 21:59:19 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 27 May 2015 19:59:19 +0000
Subject: [R-sig-ME] lme4 and deviance
In-Reply-To: <F14352CFE7F2B74DA2C5597BD8BF3B2C0D31D936@hotel.isis.unige.ch>
References: <F14352CFE7F2B74DA2C5597BD8BF3B2C0D31D936@hotel.isis.unige.ch>
Message-ID: <CAO7JsnSGuSfUD5N60V+R3BwOueO4R4qag+CunVbhmQQ0WCyLxw@mail.gmail.com>

I share your concern about how to define the scaled deviance.  The trick,
as you say, is deciding what the saturated mixed model is.  I don't know of
a good way of defining it.

It might be best to just refer to the log-likelihood and not derive
anything called "deviance".

On Thu, May 21, 2015 at 9:09 AM Nad?ge Jacot <Nadege.Jacot at unige.ch> wrote:

> Dear list,
>
> I'm trying to understand why the deviance function returns -2 log
> likelihood in lme4 and not the "true" deviance as with lm().
>
> The scaled deviance is defined as the difference of -2 log likelihood
> between the model of interest and the saturated model but what is the
> saturated mixed model? For balanced data, some authors (e.g. Hoffman 2014,
> Longitudinal Analysis: Modeling Within-Person Fluctuation and Change)
> define the saturated mixed model as a model with saturated means (one fixed
> effect for each time point) and unstructured variance but such a model is
> not available for unbalanced data.
>
> And if we can compute the scaled deviance, what is the deviance?
>
> Thanks in advance for any hint.
>
> Nad?ge Jacot
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From francescobryanromano at gmail.com  Wed May 27 23:00:11 2015
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Wed, 27 May 2015 23:00:11 +0200
Subject: [R-sig-ME] Zero cells in contrast matrix problem
Message-ID: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>

After giving up on a glmer for my data, I remembered a post by Roger Levy
suggesting to try the use non mixed effects glm when one of the cells in a
matrix is zero.

To put this into perspective:

> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name), data =
trialglm, family = binomial)

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.053657 (tol = 0.001,
component 4)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

My data has a binary outcome, correct or incorrect, a fixed effect
predictor factor with 8 levels, and a random effect for participants. I
believe the problem R is encountering is with one level of the factor (let
us call it level B) which has no counts (no I won' t try to post the table
from the paper with the counts because I know it will get garbled up!).

I attempt a glm with the same data:

> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm, family = binomial)
> anova(trial)
Analysis of Deviance Table

Model: binomial, link: logit

Response: Correct

Terms added sequentially (first to last)


                 Df Deviance Resid. Df Resid. Dev
NULL                               384     289.63
Syntax.Semantics  7   34.651       377     254.97
> summary(trial)

Call:
glm(formula = Correct ~ Syntax.Semantics, family = binomial,
    data = trialglm)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-0.79480  -0.62569  -0.34474  -0.00013   2.52113

Coefficients:
                           Estimate Std. Error z value Pr(>|z|)
(Intercept)                 -1.6917     0.4113  -4.113 3.91e-05 ***
Syntax.Semantics A   0.7013     0.5241   1.338   0.1809
Syntax.Semantics B -16.8744   904.5273  -0.019   0.9851
Syntax.Semantics C  -1.1015     0.7231  -1.523   0.1277
Syntax.Semantics D   0.1602     0.5667   0.283   0.7774
Syntax.Semantics E  -0.8733     0.7267  -1.202   0.2295
Syntax.Semantics F  -1.4438     0.8312  -1.737   0.0824 .
Syntax.Semantics G   0.4630     0.5262   0.880   0.3789
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 289.63  on 384  degrees of freedom
Residual deviance: 254.98  on 377  degrees of freedom
AIC: 270.98

Number of Fisher Scoring iterations: 17

 The comparison I'm interested in is between level B and the reference
level but it cannot be estimated as shown by the ridiculously high estimate
and SE value.

Any suggestions on how to get a decent beta, SE, z, and p? It's the only
comparison missing in the table for the levels I need so I think it would
be a bit unacademic of me to close this deal saying 'the difference could
not be estimated due to zero count'.

And by the way I have seen this comparison being generated using other
stats.

Thanks in advance,

Frank

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed May 27 23:21:28 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 27 May 2015 23:21:28 +0200
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>

You may need to consider using an 'exact', Bayesian, or penalized likelihood approach (along the lines proposed by Firth).

Maybe a place to start: http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Francesco Romano
> Sent: Wednesday, May 27, 2015 23:00
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Zero cells in contrast matrix problem
> 
> After giving up on a glmer for my data, I remembered a post by Roger Levy
> suggesting to try the use non mixed effects glm when one of the cells in
> a
> matrix is zero.
> 
> To put this into perspective:
> 
> > trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name), data =
> trialglm, family = binomial)
> 
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
>   Model failed to converge with max|grad| = 0.053657 (tol = 0.001,
> component 4)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
>   Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
> 
> My data has a binary outcome, correct or incorrect, a fixed effect
> predictor factor with 8 levels, and a random effect for participants. I
> believe the problem R is encountering is with one level of the factor
> (let
> us call it level B) which has no counts (no I won' t try to post the
> table
> from the paper with the counts because I know it will get garbled up!).
> 
> I attempt a glm with the same data:
> 
> > trial<-glm(Correct ~ Syntax.Semantics, data = trialglm, family =
> binomial)
> > anova(trial)
> Analysis of Deviance Table
> 
> Model: binomial, link: logit
> 
> Response: Correct
> 
> Terms added sequentially (first to last)
> 
> 
>                  Df Deviance Resid. Df Resid. Dev
> NULL                               384     289.63
> Syntax.Semantics  7   34.651       377     254.97
> > summary(trial)
> 
> Call:
> glm(formula = Correct ~ Syntax.Semantics, family = binomial,
>     data = trialglm)
> 
> Deviance Residuals:
>      Min        1Q    Median        3Q       Max
> -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> 
> Coefficients:
>                            Estimate Std. Error z value Pr(>|z|)
> (Intercept)                 -1.6917     0.4113  -4.113 3.91e-05 ***
> Syntax.Semantics A   0.7013     0.5241   1.338   0.1809
> Syntax.Semantics B -16.8744   904.5273  -0.019   0.9851
> Syntax.Semantics C  -1.1015     0.7231  -1.523   0.1277
> Syntax.Semantics D   0.1602     0.5667   0.283   0.7774
> Syntax.Semantics E  -0.8733     0.7267  -1.202   0.2295
> Syntax.Semantics F  -1.4438     0.8312  -1.737   0.0824 .
> Syntax.Semantics G   0.4630     0.5262   0.880   0.3789
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>     Null deviance: 289.63  on 384  degrees of freedom
> Residual deviance: 254.98  on 377  degrees of freedom
> AIC: 270.98
> 
> Number of Fisher Scoring iterations: 17
> 
>  The comparison I'm interested in is between level B and the reference
> level but it cannot be estimated as shown by the ridiculously high
> estimate
> and SE value.
> 
> Any suggestions on how to get a decent beta, SE, z, and p? It's the only
> comparison missing in the table for the levels I need so I think it would
> be a bit unacademic of me to close this deal saying 'the difference could
> not be estimated due to zero count'.
> 
> And by the way I have seen this comparison being generated using other
> stats.
> 
> Thanks in advance,
> 
> Frank
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From manabu.sakamoto at gmail.com  Thu May 28 00:46:06 2015
From: manabu.sakamoto at gmail.com (Manabu Sakamoto)
Date: Wed, 27 May 2015 23:46:06 +0100
Subject: [R-sig-ME] MCMCglmm prediction without marginalising
Message-ID: <CAErHMT2+xPjmUu_3=P8et9WMomY=ocrWt2ngBwDxC_J15fHq6Q@mail.gmail.com>

Dear list,

Apologies if this turns out to be a silly question but does
predict.MCMCglmm, marginalise residuals by default? I'd like to see how the
prediction performs when random effects are not marginalised, i.e.,
marginal=NULL, but the predictions look too close to the original data so I
am suspecting that this also un-marginalised the residuals as well...

Am I correct to interpret it this way, and is there a way to still
marginalise the residuals but not the random effects?

I want to see how close or how far away the predictions are from the
original responses when random effects are marginalised or not.

Many thanks,
Manabu

-- 
Manabu Sakamoto, PhD
manabu.sakamoto at gmail.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu May 28 02:28:26 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 27 May 2015 20:28:26 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
Message-ID: <CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>

And for what it's worth, you can do this in conjunction with lme4 by
using the blme package instead (a thin Bayesian wrapper around lme4),
or via the MCMCglmm package; see
http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html for
an example (search for "complete separation").

On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
<wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> You may need to consider using an 'exact', Bayesian, or penalized likelihood approach (along the lines proposed by Firth).
>
> Maybe a place to start: http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>
> Best,
> Wolfgang
>
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Francesco Romano
>> Sent: Wednesday, May 27, 2015 23:00
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Zero cells in contrast matrix problem
>>
>> After giving up on a glmer for my data, I remembered a post by Roger Levy
>> suggesting to try the use non mixed effects glm when one of the cells in
>> a
>> matrix is zero.
>>
>> To put this into perspective:
>>
>> > trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name), data =
>> trialglm, family = binomial)
>>
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> :
>>   Model failed to converge with max|grad| = 0.053657 (tol = 0.001,
>> component 4)
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> :
>>   Model is nearly unidentifiable: large eigenvalue ratio
>>  - Rescale variables?
>>
>> My data has a binary outcome, correct or incorrect, a fixed effect
>> predictor factor with 8 levels, and a random effect for participants. I
>> believe the problem R is encountering is with one level of the factor
>> (let
>> us call it level B) which has no counts (no I won' t try to post the
>> table
>> from the paper with the counts because I know it will get garbled up!).
>>
>> I attempt a glm with the same data:
>>
>> > trial<-glm(Correct ~ Syntax.Semantics, data = trialglm, family =
>> binomial)
>> > anova(trial)
>> Analysis of Deviance Table
>>
>> Model: binomial, link: logit
>>
>> Response: Correct
>>
>> Terms added sequentially (first to last)
>>
>>
>>                  Df Deviance Resid. Df Resid. Dev
>> NULL                               384     289.63
>> Syntax.Semantics  7   34.651       377     254.97
>> > summary(trial)
>>
>> Call:
>> glm(formula = Correct ~ Syntax.Semantics, family = binomial,
>>     data = trialglm)
>>
>> Deviance Residuals:
>>      Min        1Q    Median        3Q       Max
>> -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>>
>> Coefficients:
>>                            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)                 -1.6917     0.4113  -4.113 3.91e-05 ***
>> Syntax.Semantics A   0.7013     0.5241   1.338   0.1809
>> Syntax.Semantics B -16.8744   904.5273  -0.019   0.9851
>> Syntax.Semantics C  -1.1015     0.7231  -1.523   0.1277
>> Syntax.Semantics D   0.1602     0.5667   0.283   0.7774
>> Syntax.Semantics E  -0.8733     0.7267  -1.202   0.2295
>> Syntax.Semantics F  -1.4438     0.8312  -1.737   0.0824 .
>> Syntax.Semantics G   0.4630     0.5262   0.880   0.3789
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> (Dispersion parameter for binomial family taken to be 1)
>>
>>     Null deviance: 289.63  on 384  degrees of freedom
>> Residual deviance: 254.98  on 377  degrees of freedom
>> AIC: 270.98
>>
>> Number of Fisher Scoring iterations: 17
>>
>>  The comparison I'm interested in is between level B and the reference
>> level but it cannot be estimated as shown by the ridiculously high
>> estimate
>> and SE value.
>>
>> Any suggestions on how to get a decent beta, SE, z, and p? It's the only
>> comparison missing in the table for the levels I need so I think it would
>> be a bit unacademic of me to close this deal saying 'the difference could
>> not be estimated due to zero count'.
>>
>> And by the way I have seen this comparison being generated using other
>> stats.
>>
>> Thanks in advance,
>>
>> Frank
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Samantha.Patrick at liverpool.ac.uk  Wed May 27 16:55:29 2015
From: Samantha.Patrick at liverpool.ac.uk (Patrick, Samantha)
Date: Wed, 27 May 2015 14:55:29 +0000
Subject: [R-sig-ME] DHGLM Double hierarchical GLMs
In-Reply-To: <4EF872E635D62046B7ECF6D1781997C105339753@CHEXMBX2.livad.liv.ac.uk>
References: <4EF872E635D62046B7ECF6D1781997C10533951F@CHEXMBX2.livad.liv.ac.uk>,
	<4EF872E635D62046B7ECF6D1781997C1053395BE@CHEXMBX2.livad.liv.ac.uk>,
	<4EF872E635D62046B7ECF6D1781997C105339753@CHEXMBX2.livad.liv.ac.uk>
Message-ID: <4EF872E635D62046B7ECF6D1781997C105339849@CHEXMBX2.livad.liv.ac.uk>

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP, UK
Tel: 0151 795 4390
Skype: Sammy_Patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick

From: Samantha Patrick<mailto:spatrick at liverpool.ac.uk>
Sent: ?Wednesday?, ?27? ?May? ?2015 ?15?:?45
To: 'r-sig-mixed-models at r-project.org'<mailto:r-sig-mixed-models at r-project.org>

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP, UK
Tel: 0151 795 4390
Skype: Sammy_Patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick

From: Samantha Patrick<mailto:spatrick at liverpool.ac.uk>
Sent: ?Wednesday?, ?27? ?May? ?2015 ?13?:?03
To: 'r-sig-mixed-models at r-project.org'<mailto:r-sig-mixed-models at r-project.org>

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP
UK

Tel: 0151 7954390
Skype: sammy_patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick



From: Patrick, Samantha
Sent: 27 May 2015 12:04
To: r-sig-mixed-models at r-project.org
Subject: DHGLM Double hierarchical GLMs

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP
UK

Tel: 0151 7954390
Skype: sammy_patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick




	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Thu May 28 11:44:27 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Thu, 28 May 2015 11:44:27 +0200
Subject: [R-sig-ME] Release of the R package brms to fit Bayesian mixed
	effects models
Message-ID: <CAGoSky88LALXZEPdrHTsv2X3JuHQ4q9E2qv=pMBT-pNCqjsCbw@mail.gmail.com>

Hi all,

I just wanted to inform you about the release of a new R package for
fitting bayesian mixed effects models.

The package is called *brms* (Bayesian Regression Models using Stan) and is
based on the probabilistic programming language Stan (see
http://mc-stan.org/).

A wide range of families is supported, also including families for survival
regression such as "weibull" or ordinal regression such as "cumulative"
besides the standard families "gaussian", "poisson", "binomial", etc. The
formula syntax is basically that of lme4.

brms itself is available on CRAN. Unfortunately, the package rstan
(implementing Stan in R) is not on CRAN yet, so it has to be installed
manually before brms can be used to fit the models. For instructions on how
to install rstan please see
https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started

I am very grateful for every feedback regarding brms! If you have any
questions, please contact me.

Best
Paul

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Thu May 28 11:55:58 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 28 May 2015 19:55:58 +1000
Subject: [R-sig-ME] DHGLM Double hierarchical GLMs
In-Reply-To: <4EF872E635D62046B7ECF6D1781997C105339849@CHEXMBX2.livad.liv.ac.uk>
References: <4EF872E635D62046B7ECF6D1781997C10533951F@CHEXMBX2.livad.liv.ac.uk>
	<4EF872E635D62046B7ECF6D1781997C1053395BE@CHEXMBX2.livad.liv.ac.uk>
	<4EF872E635D62046B7ECF6D1781997C105339753@CHEXMBX2.livad.liv.ac.uk>
	<4EF872E635D62046B7ECF6D1781997C105339849@CHEXMBX2.livad.liv.ac.uk>
Message-ID: <CAF5_5cxFqPqcnirGZ+ArChSo0J8YD4L5kyPLq7jWv2=+OBky7w@mail.gmail.com>

It looks like the package doesn't work properly, not unusual with a package
that is nearly 4 years old. Send an e-mail to the maintainer.

Ken

On 28 May 2015 at 00:55, Patrick, Samantha <Samantha.Patrick at liverpool.ac.uk
> wrote:

> Hi
>
> I am using the package dhglm to run a double hierarchical GLM.  I have
> been using the data provided with the package to experiment and I am having
> problems getting the summary for the model.  This code is taken from the
> package documentation:
>
> ### DHGLM introducing random effects in the overdispersion for crack
> growth data
> library(dhglm)
>
> data(data_crack_growth)
>
> model_mu<-DHGLMMODELING(Model="mean",
>                         Link="log",
>                         LinPred=y~crack0+(1|specimen),
>                         RandDist="inverse-gamma")
>
> model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
>                          LinPred=phi~cycle+(1|specimen),
> RandDist="gaussian")
>
> res_crack<-dhglmfit(RespDist="gamma",
>                     DataMain=data_crack_growth,
>                     MeanModel=model_mu,
>                     DispersionModel=model_phi)
>
> summary(res_crack)
>
> ##The output here is:
>
>      Length Class  Mode
> [1,] 241    -none- numeric
> [2,] 241    -none- numeric
>
> ##when the instructions suggest it should contain:
>
> FixCoef
> RandCoef
> iter
> mtwolikelihood
>
>
> ##I have investigated looking at:
>
> str(res_crack)
>
>
> List of 2
>
>  $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...
>
>  $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..
>
> class(res_crack)
>
> [1] "list"
>
> ##However the documentation suggests it should be a dhglm object.  When I
> run:
>
> summary.dhglm
>
>
> object 'summary.dhglm' not found
>
> To me this suggests my computer can not locate the summary.dhglm command.
> Has anyone else had any experiences like this or success using the package?
>
> Many Thanks
>
> Sam
>
>
> Samantha Patrick
> Lecturer in Marine Biology
>
> School of Environmental Sciences
> University of Liverpool
> Nicholson Building
> Brownlow Street
> Liverpool
> L69 3GP, UK
> Tel: 0151 795 4390
> Skype: Sammy_Patrick
> Website: http://samanthacpatrick.wix.com/home
> Twitter: SamCPatrick
>
> From: Samantha Patrick<mailto:spatrick at liverpool.ac.uk>
> Sent: ?Wednesday?, ?27? ?May? ?2015 ?15?:?45
> To: 'r-sig-mixed-models at r-project.org'<mailto:
> r-sig-mixed-models at r-project.org>
>
> Hi
>
> I am using the package dhglm to run a double hierarchical GLM.  I have
> been using the data provided with the package to experiment and I am having
> problems getting the summary for the model.  This code is taken from the
> package documentation:
>
> ### DHGLM introducing random effects in the overdispersion for crack
> growth data
> library(dhglm)
>
> data(data_crack_growth)
>
> model_mu<-DHGLMMODELING(Model="mean",
>                         Link="log",
>                         LinPred=y~crack0+(1|specimen),
>                         RandDist="inverse-gamma")
>
> model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
>                          LinPred=phi~cycle+(1|specimen),
> RandDist="gaussian")
>
> res_crack<-dhglmfit(RespDist="gamma",
>                     DataMain=data_crack_growth,
>                     MeanModel=model_mu,
>                     DispersionModel=model_phi)
>
> summary(res_crack)
>
> ##The output here is:
>
>      Length Class  Mode
> [1,] 241    -none- numeric
> [2,] 241    -none- numeric
>
> ##when the instructions suggest it should contain:
>
> FixCoef
> RandCoef
> iter
> mtwolikelihood
>
>
> ##I have investigated looking at:
>
> str(res_crack)
>
>
> List of 2
>
>  $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...
>
>  $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..
>
> class(res_crack)
>
> [1] "list"
>
> ##However the documentation suggests it should be a dhglm object.  When I
> run:
>
> summary.dhglm
>
>
> object 'summary.dhglm' not found
>
> To me this suggests my computer can not locate the summary.dhglm command.
> Has anyone else had any experiences like this or success using the package?
>
> Many Thanks
>
> Sam
>
>
> Samantha Patrick
> Lecturer in Marine Biology
>
> School of Environmental Sciences
> University of Liverpool
> Nicholson Building
> Brownlow Street
> Liverpool
> L69 3GP, UK
> Tel: 0151 795 4390
> Skype: Sammy_Patrick
> Website: http://samanthacpatrick.wix.com/home
> Twitter: SamCPatrick
>
> From: Samantha Patrick<mailto:spatrick at liverpool.ac.uk>
> Sent: ?Wednesday?, ?27? ?May? ?2015 ?13?:?03
> To: 'r-sig-mixed-models at r-project.org'<mailto:
> r-sig-mixed-models at r-project.org>
>
> Hi
>
> I am using the package dhglm to run a double hierarchical GLM.  I have
> been using the data provided with the package to experiment and I am having
> problems getting the summary for the model.  This code is taken from the
> package documentation:
>
> ### DHGLM introducing random effects in the overdispersion for crack
> growth data
> library(dhglm)
>
> data(data_crack_growth)
>
> model_mu<-DHGLMMODELING(Model="mean",
>                         Link="log",
>                         LinPred=y~crack0+(1|specimen),
>                         RandDist="inverse-gamma")
>
> model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
>                          LinPred=phi~cycle+(1|specimen),
> RandDist="gaussian")
>
> res_crack<-dhglmfit(RespDist="gamma",
>                     DataMain=data_crack_growth,
>                     MeanModel=model_mu,
>                     DispersionModel=model_phi)
>
> summary(res_crack)
>
> ##The output here is:
>
>      Length Class  Mode
> [1,] 241    -none- numeric
> [2,] 241    -none- numeric
>
> ##when the instructions suggest it should contain:
>
> FixCoef
> RandCoef
> iter
> mtwolikelihood
>
>
> ##I have investigated looking at:
>
> str(res_crack)
>
>
> List of 2
>
>  $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...
>
>  $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..
>
> class(res_crack)
>
> [1] "list"
>
> ##However the documentation suggests it should be a dhglm object.  When I
> run:
>
> summary.dhglm
>
>
> object 'summary.dhglm' not found
>
> To me this suggests my computer can not locate the summary.dhglm command.
> Has anyone else had any experiences like this or success using the package?
>
> Many Thanks
>
> Sam
>
>
> Samantha Patrick
> Lecturer in Marine Biology
>
> School of Environmental Sciences
> University of Liverpool
> Nicholson Building
> Brownlow Street
> Liverpool
> L69 3GP
> UK
>
> Tel: 0151 7954390
> Skype: sammy_patrick
> Website: http://samanthacpatrick.wix.com/home
> Twitter: SamCPatrick
>
>
>
> From: Patrick, Samantha
> Sent: 27 May 2015 12:04
> To: r-sig-mixed-models at r-project.org
> Subject: DHGLM Double hierarchical GLMs
>
> Hi
>
> I am using the package dhglm to run a double hierarchical GLM.  I have
> been using the data provided with the package to experiment and I am having
> problems getting the summary for the model.  This code is taken from the
> package documentation:
>
> ### DHGLM introducing random effects in the overdispersion for crack
> growth data
> library(dhglm)
>
> data(data_crack_growth)
>
> model_mu<-DHGLMMODELING(Model="mean",
>                         Link="log",
>                         LinPred=y~crack0+(1|specimen),
>                         RandDist="inverse-gamma")
>
> model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
>                          LinPred=phi~cycle+(1|specimen),
> RandDist="gaussian")
>
> res_crack<-dhglmfit(RespDist="gamma",
>                     DataMain=data_crack_growth,
>                     MeanModel=model_mu,
>                     DispersionModel=model_phi)
>
> summary(res_crack)
>
> ##The output here is:
>
>      Length Class  Mode
> [1,] 241    -none- numeric
> [2,] 241    -none- numeric
>
> ##when the instructions suggest it should contain:
>
> FixCoef
> RandCoef
> iter
> mtwolikelihood
>
>
> ##I have investigated looking at:
>
> str(res_crack)
>
>
> List of 2
>
>  $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...
>
>  $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..
>
> class(res_crack)
>
> [1] "list"
>
> ##However the documentation suggests it should be a dhglm object.  When I
> run:
>
> summary.dhglm
>
>
> object 'summary.dhglm' not found
>
> To me this suggests my computer can not locate the summary.dhglm command.
> Has anyone else had any experiences like this or success using the package?
>
> Many Thanks
>
> Sam
>
>
> Samantha Patrick
> Lecturer in Marine Biology
>
> School of Environmental Sciences
> University of Liverpool
> Nicholson Building
> Brownlow Street
> Liverpool
> L69 3GP
> UK
>
> Tel: 0151 7954390
> Skype: sammy_patrick
> Website: http://samanthacpatrick.wix.com/home
> Twitter: SamCPatrick
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From francescobryanromano at gmail.com  Thu May 28 12:55:18 2015
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Thu, 28 May 2015 12:55:18 +0200
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
Message-ID: <CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>

Many thanks to both.

The approaches you suggest (and others online) help one deal with the
separation problem but don't offer any specific advice as to how getting a
valid p coefficient when comparing two levels of the model vexed by
separation.

Ben, here's the output of the bglmer which by the way would be ideal since
it allows me to retain the random effect so that all my pairwise
comparisons are conducted using mixed effects.

> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data = trialglm,
family = binomial)
Warning message:
package ?blme? was built under R version 3.1.2
> summary(trial)
Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf, posterior.scale =
cov, common.scale = TRUE)
Prior dev  : 1.4371

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['bglmerMod']
 Family: binomial  ( logit )
Formula: Correct ~ Syntax.Semantics + (1 | Part.name)
   Data: trialglm

     AIC      BIC   logLik deviance df.resid
   269.9    305.5   -126.0    251.9      376

Scaled residuals:
    Min      1Q  Median      3Q     Max
-0.9828 -0.4281 -0.2445 -0.0002  5.7872

Random effects:
 Groups    Name        Variance Std.Dev.
 Part.name (Intercept) 0.3836   0.6194
Number of obs: 385, groups:  Part.name, 16

Fixed effects:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  -1.8671     0.4538  -4.114 3.89e-05 ***
Syntax.Semantics A    0.8121     0.5397   1.505   0.1324
Syntax.Semantics B  -16.4391  1195.5031  -0.014   0.9890
Syntax.Semantics C   -1.1323     0.7462  -1.517   0.1292
Syntax.Semantics D    0.1789     0.5853   0.306   0.7598
Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
Syntax.Semantics G    0.4395     0.5417   0.811   0.4171
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Unfortunately the separation problem is still there. Should I be
constraining the parameter somehow? How would I do that? The data is below.

In passing I also tried brglm which solves the separation problem but tells
me comparison is significant which I don't believe one bit (see the data
below). I am pretty sure about this because when I reveled and look at the
comparisons I was able to compute using glmer, these turn out to be
non-significant, when glmer told me they were:

> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family =
binomial)
Warning messages:
1: package ?elrm? was built under R version 3.1.2
2: package ?coda? was built under R version 3.1.3
> summary(trial)

Call:
brglm(formula = Correct ~ Syntax.Semantics, family = binomial,
    data = trialglm)


Coefficients:
                           Estimate Std. Error z value Pr(>|z|)
(Intercept)                 -1.6358     0.4035  -4.053 5.05e-05 ***
Syntax.Semantics A   0.6689     0.5169   1.294   0.1957
Syntax.Semantics B  -3.0182     1.4902  -2.025   0.0428 *
Syntax.Semantics C  -1.0135     0.6889  -1.471   0.1413
Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
Syntax.Semantics G   0.4358     0.5186   0.840   0.4007
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 262.51  on 384  degrees of freedom
Residual deviance: 256.22  on 377  degrees of freedom
Penalized deviance: 245.5554
AIC:  272.22


MCMCglmm is too complex for me.

Wolfgang, I tried the penalized likelihood method (logistf function)
but output is hard to read:

> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm, family =
binomial)
Warning messages:
1: package ?logistf? was built under R version 3.1.2
2: package ?mice? was built under R version 3.1.2
> summary(trial)
logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
    family = binomial)

Model fitted by Penalized ML
Confidence intervals and p-values by Profile Likelihood Profile Likelihood
Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
Profile Likelihood Profile Likelihood

                                 coef  se(coef) lower 0.95 upper 0.95
Chisq            p
(Intercept)                 3.2094017 0.7724482  2.9648747  3.5127830
 0.000000 1.000000e+00
Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987 64.224452
1.110223e-15
Syntax.Semantics B -1.0583602 0.8959376 -1.3963977 -0.7625216  0.000000
1.000000e+00
Syntax.Semantics C -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000
1.000000e+00
Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908  1.156512
2.821901e-01
Syntax.Semantics E -0.6476907 0.9771824 -1.0076740 -0.3164066  0.000000
1.000000e+00
Syntax.Semantics F -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000
1.000000e+00
Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981  0.000000
1.000000e+00

Likelihood ratio test=121.9841 on 7 df, p=0, n=385
Wald test = 5.334321 on 7 df, p = 0.6192356

In particular, what is this model telling me? That Z (my ref level) and B
are significantly different?

I'm happy to try the elrm function with exact logistic regression but I am
not capable of programming it. Besides, would it give me valid estimates
for the comparison between the Z and B levels? The data frame should look
like this:

Outcome variable (Correct, incorrect)
Predictor variable (A, B, C, D, E, F, G, Z)
Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D: 36,8; C:45,3; A: 34,13;
F:65,22).

Thank you!
 F.

On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com> wrote:

> And for what it's worth, you can do this in conjunction with lme4 by
> using the blme package instead (a thin Bayesian wrapper around lme4),
> or via the MCMCglmm package; see
> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html for
> an example (search for "complete separation").
>
> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> > You may need to consider using an 'exact', Bayesian, or penalized
> likelihood approach (along the lines proposed by Firth).
> >
> > Maybe a place to start:
> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
> >
> > Best,
> > Wolfgang
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Francesco Romano
> >> Sent: Wednesday, May 27, 2015 23:00
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] Zero cells in contrast matrix problem
> >>
> >> After giving up on a glmer for my data, I remembered a post by Roger
> Levy
> >> suggesting to try the use non mixed effects glm when one of the cells in
> >> a
> >> matrix is zero.
> >>
> >> To put this into perspective:
> >>
> >> > trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name), data =
> >> trialglm, family = binomial)
> >>
> >> Warning messages:
> >> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> >> :
> >>   Model failed to converge with max|grad| = 0.053657 (tol = 0.001,
> >> component 4)
> >> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> >> :
> >>   Model is nearly unidentifiable: large eigenvalue ratio
> >>  - Rescale variables?
> >>
> >> My data has a binary outcome, correct or incorrect, a fixed effect
> >> predictor factor with 8 levels, and a random effect for participants. I
> >> believe the problem R is encountering is with one level of the factor
> >> (let
> >> us call it level B) which has no counts (no I won' t try to post the
> >> table
> >> from the paper with the counts because I know it will get garbled up!).
> >>
> >> I attempt a glm with the same data:
> >>
> >> > trial<-glm(Correct ~ Syntax.Semantics, data = trialglm, family =
> >> binomial)
> >> > anova(trial)
> >> Analysis of Deviance Table
> >>
> >> Model: binomial, link: logit
> >>
> >> Response: Correct
> >>
> >> Terms added sequentially (first to last)
> >>
> >>
> >>                  Df Deviance Resid. Df Resid. Dev
> >> NULL                               384     289.63
> >> Syntax.Semantics  7   34.651       377     254.97
> >> > summary(trial)
> >>
> >> Call:
> >> glm(formula = Correct ~ Syntax.Semantics, family = binomial,
> >>     data = trialglm)
> >>
> >> Deviance Residuals:
> >>      Min        1Q    Median        3Q       Max
> >> -0.79480  -0.62569  -0.34474  -0.00013   2.52113
> >>
> >> Coefficients:
> >>                            Estimate Std. Error z value Pr(>|z|)
> >> (Intercept)                 -1.6917     0.4113  -4.113 3.91e-05 ***
> >> Syntax.Semantics A   0.7013     0.5241   1.338   0.1809
> >> Syntax.Semantics B -16.8744   904.5273  -0.019   0.9851
> >> Syntax.Semantics C  -1.1015     0.7231  -1.523   0.1277
> >> Syntax.Semantics D   0.1602     0.5667   0.283   0.7774
> >> Syntax.Semantics E  -0.8733     0.7267  -1.202   0.2295
> >> Syntax.Semantics F  -1.4438     0.8312  -1.737   0.0824 .
> >> Syntax.Semantics G   0.4630     0.5262   0.880   0.3789
> >> ---
> >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >> (Dispersion parameter for binomial family taken to be 1)
> >>
> >>     Null deviance: 289.63  on 384  degrees of freedom
> >> Residual deviance: 254.98  on 377  degrees of freedom
> >> AIC: 270.98
> >>
> >> Number of Fisher Scoring iterations: 17
> >>
> >>  The comparison I'm interested in is between level B and the reference
> >> level but it cannot be estimated as shown by the ridiculously high
> >> estimate
> >> and SE value.
> >>
> >> Any suggestions on how to get a decent beta, SE, z, and p? It's the only
> >> comparison missing in the table for the levels I need so I think it
> would
> >> be a bit unacademic of me to close this deal saying 'the difference
> could
> >> not be estimated due to zero count'.
> >>
> >> And by the way I have seen this comparison being generated using other
> >> stats.
> >>
> >> Thanks in advance,
> >>
> >> Frank
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From r.travitzki at gmail.com  Thu May 28 13:56:59 2015
From: r.travitzki at gmail.com (Rodrigo Travitzki)
Date: Thu, 28 May 2015 12:56:59 +0100
Subject: [R-sig-ME] multilevel analysis with sample weighted data
In-Reply-To: <53FF343A.1060207@gmail.com>
References: <53FF0BFB.6060001@gmail.com> <53FF343A.1060207@gmail.com>
Message-ID: <5567028B.5050407@gmail.com>

Ben,
you are right, "weights=varFixed(~I(1/n))" seems to work like a charm!

And my apologies to the MLwiN team, which do a great job.

In time: in order to use multiple weigths (in different levels), we have 
to use varIdent, right?
Somethight, like:

weights=varIdent(~1|I(1/n1)*I(1/n2)*I(1/n3))


Best,
Rodrigo


On 28-08-2014 14:52, Ben Bolker wrote:
> On 14-08-28 07:01 AM, Rodrigo Travitzki wrote:
>> Dear R masters,
>> I'm looking for a R package to do multilevel analysis of a weighted data
>> (is a weigthed sample of brazilian educational data) but could not find
>> it. There is just a "weights" option in lme(), but is not about
>> frequency (or probability) weigths in data. In some foruns, no response
>> either.
>> So, could you please confirm this information for me? There is any R
>> package/function which do this? I really don't want to use proprietary
>> software, but if there is no option, I'll need to do so.
>> Thank you very much.
>>
>> Best wishes,
>> Rodrigo Travitzki
>    It depends a little bit what you want to do/the meaning of the
> weights.  I have successfully used weights=varFixed(~I(1/n))
> [inverse-variance weighting based on the number of samples per group] in
> lme; alternatively, you could use weights=n in lmer (from the lme4
> package) to get an equivalent result.
>
> If you want to deal with survey weighting, the story seems to be
> considerably more complicated -- I don't claim to understand it, but
> Andrew Gelman (a fairly prominent applied Bayesian statistician) claims
> that it's "a mess" (to use his phrase).  If the weights represent
> probability of inclusion in a survey, I believe he would recommend
> model-based inference -- that is, fit an unweighted multilevel
> regression model and then use post-stratification/weighting to make
> predictions (see http://andrewgelman.com/?s=survey+weights for various
> discussion and links to papers).
>
>    good luck,
>      Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Samantha.Patrick at liverpool.ac.uk  Thu May 28 14:41:06 2015
From: Samantha.Patrick at liverpool.ac.uk (Patrick, Samantha)
Date: Thu, 28 May 2015 12:41:06 +0000
Subject: [R-sig-ME] Fw: DHGLM Double hierarchical GLMs
In-Reply-To: <4EF872E635D62046B7ECF6D1781997C105339849@CHEXMBX2.livad.liv.ac.uk>
References: <4EF872E635D62046B7ECF6D1781997C10533951F@CHEXMBX2.livad.liv.ac.uk>,
	<4EF872E635D62046B7ECF6D1781997C1053395BE@CHEXMBX2.livad.liv.ac.uk>,
	<4EF872E635D62046B7ECF6D1781997C105339753@CHEXMBX2.livad.liv.ac.uk>,
	<4EF872E635D62046B7ECF6D1781997C105339849@CHEXMBX2.livad.liv.ac.uk>
Message-ID: <4EF872E635D62046B7ECF6D1781997C10533A2DA@CHEXMBX2.livad.liv.ac.uk>

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP, UK
Tel: 0151 795 4390
Skype: Sammy_Patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick

From: Samantha Patrick<mailto:spatrick at liverpool.ac.uk>
Sent: ?Wednesday?, ?27? ?May? ?2015 ?16?:?55
To: 'r-sig-mixed-models at r-project.org'<mailto:r-sig-mixed-models at r-project.org>

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP, UK
Tel: 0151 795 4390
Skype: Sammy_Patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick

From: Samantha Patrick<mailto:spatrick at liverpool.ac.uk>
Sent: ?Wednesday?, ?27? ?May? ?2015 ?15?:?45
To: 'r-sig-mixed-models at r-project.org'<mailto:r-sig-mixed-models at r-project.org>

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP, UK
Tel: 0151 795 4390
Skype: Sammy_Patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick

From: Samantha Patrick<mailto:spatrick at liverpool.ac.uk>
Sent: ?Wednesday?, ?27? ?May? ?2015 ?13?:?03
To: 'r-sig-mixed-models at r-project.org'<mailto:r-sig-mixed-models at r-project.org>

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP
UK

Tel: 0151 7954390
Skype: sammy_patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick



From: Patrick, Samantha
Sent: 27 May 2015 12:04
To: r-sig-mixed-models at r-project.org
Subject: DHGLM Double hierarchical GLMs

Hi

I am using the package dhglm to run a double hierarchical GLM.  I have been using the data provided with the package to experiment and I am having problems getting the summary for the model.  This code is taken from the package documentation:

### DHGLM introducing random effects in the overdispersion for crack growth data
library(dhglm)

data(data_crack_growth)

model_mu<-DHGLMMODELING(Model="mean",
                        Link="log",
                        LinPred=y~crack0+(1|specimen),
                        RandDist="inverse-gamma")

model_phi<-DHGLMMODELING(Model="dispersion", Link="log",
                         LinPred=phi~cycle+(1|specimen), RandDist="gaussian")

res_crack<-dhglmfit(RespDist="gamma",
                    DataMain=data_crack_growth,
                    MeanModel=model_mu,
                    DispersionModel=model_phi)

summary(res_crack)

##The output here is:

     Length Class  Mode
[1,] 241    -none- numeric
[2,] 241    -none- numeric

##when the instructions suggest it should contain:

FixCoef
RandCoef
iter
mtwolikelihood


##I have investigated looking at:

str(res_crack)


List of 2

 $ : num [1:241, 1] 1.2262 0.5985 -0.0856 1.1755 0.08 ...

 $ : num [1:241, 1] 0.0393 0.0447 0.0508 0.0577 0.0691 ..

class(res_crack)

[1] "list"

##However the documentation suggests it should be a dhglm object.  When I run:

summary.dhglm


object 'summary.dhglm' not found

To me this suggests my computer can not locate the summary.dhglm command.  Has anyone else had any experiences like this or success using the package?

Many Thanks

Sam


Samantha Patrick
Lecturer in Marine Biology

School of Environmental Sciences
University of Liverpool
Nicholson Building
Brownlow Street
Liverpool
L69 3GP
UK

Tel: 0151 7954390
Skype: sammy_patrick
Website: http://samanthacpatrick.wix.com/home
Twitter: SamCPatrick




	[[alternative HTML version deleted]]


From liberationecology at gmail.com  Thu May 28 20:32:11 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Thu, 28 May 2015 13:32:11 -0500
Subject: [R-sig-ME] MCMCglmm priors for multi-response multi-level model
Message-ID: <CAPNXFM4CiiWhs449K=ZY+Lo3G=ehP1KVBpA0zU5z4KMUXuJNyQ@mail.gmail.com>

Dear MCMCglmm'ers,

I'm attempting to model several related social behaviors (in humans) using
individual- and group-level predictor variables. I'll describe the
situation and then supply code and data following. The grouping variable is
very unbalanced.
The model I'm attempting to fit has...
? 3 continuous response variables (correlated)
? 2 continuous + 3 categorical predictors at the individual level (1 of
which is very unbalanced)
? 3 continuous predictors at the group level
? 4 interactions between individual- & group-level predictors
? 1 grouping variable - very unbalanced

I haven't succeeded yet in specifying the priors so that MCMCglmm won't
choke - and if I had, I would still be concerned
to make sure the model makes sense. I'd be grateful for any guidance.

When I attempt to fit it w/o priors, MCMCglmm gives this error:
"Mixed model equations singular: use a (stronger) prior"

With any of the prior specifications I've tried, MCMCglmm throws
"Error in priorformat(if (NOpriorG) { :
  V is the wrong dimension for some prior$G/prior$R elements"

Here are the two prior specifications that I've pieced together:

### my attempt at inverse-wishart
priors  <- list(
  R=list(V=diag(3), nu=3),
  G=list(
    G1=list(V=diag(3), nu=3),
    G2=list(V=diag(3), nu=3)
  ))

# attempt at inverse-wishart w/ expanded parameters
epriors  <- list(
  R=list(V=diag(3), nu=3.02),
  G=list(
    G1=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3), alpha.V=1000*diag(3)),
    G2=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3), alpha.V=1000*diag(3))
    ))

# As described above, I've tried fitting (1) w/o priors, and (2,3) with
each of the above specifications
mod1 <- MCMCglmm(cbind(y1, y2, y3) ~
                   -1 + trait +
                   trait:income + trait:age + trait:ethnicity +
trait:gender + trait:residence +
                   trait:education + trait:blvl1 + trait:blvl2 +
trait:blvl3 +
                   trait:blvl2:gender + trait:blvl3:gender +
trait:blvl3:ethnicity + trait:blvl3:income,
                 random = ~ idh(trait):ID  + idh(trait:block),
                 rcov = ~us(trait):units,
                 data = df,
#                 prior= epriors,
                 singular.ok=T,
                 family = c("gaussian", "gaussian", "gaussian"),
                 verbose = T)

dput() output is below...

Thanks so much for any help.

Warmly,
Rafter

# Here is a reduced sample of the data. The actual data N=727.
structure(list(y1 = c(-0.763597379301536, -0.763597379301536,
-0.171792242333942, -0.734122875740025, -0.729727821226569,
-0.714221346668209,
-0.683426795214863, -0.0425975249929617, 1.57140527810952,
-0.531520880112927,
-0.0327592125707866, -0.748043964474069, 0.548565498641651,
-0.240804466106604,
0.7833553612531, -0.159313834128096, -0.0439175728847974, 1.57140527810952,
-0.170472194442107, -0.817056188246731, 1.57140527810952,
-0.204294812247967,
-0.817056188246731, -0.487859949884892, -0.748043964474069,
-0.763597379301536,
0.991400614788918, -0.663790604075527, 0.367480878476142,
0.259242400166333,
-0.191428433473278, 0.911230030702245, -0.749364012365905,
1.57140527810952,
1.57140527810952, 0.724181449902613, -0.763597379301536,
-0.748043964474069,
-0.728407773334734, -0.748043964474069, -0.684746843106699,
-0.518654501338238,
1.57272532600136, -0.683426795214863, -0.718569460912559, 1.49123469402285,
-0.194456499825792, 0.170593985254335, -0.715541394560045,
-0.190108385581442,
-0.718569460912559, 1.50239305433686, -0.817056188246731, 1.57272532600136,
-0.749364012365905, -0.714221346668209, -0.763597379301536,
-0.694585155528874,
-0.240804466106604, -0.240804466106604, -0.193136451933956,
-0.568030533971564,
-0.763597379301536, -0.718569460912559, 0.269080712588508,
-0.753759066879361,
-0.817056188246731, -0.190108385581442, 1.57140527810952,
-0.817056188246731,
-0.684746843106699, -0.718569460912559, 0.991400614788918, 0.7833553612531,
-0.763597379301536, -0.748043964474069, -0.763597379301536,
-0.518654501338238,
-0.729727821226569, 0.00677850764036482, -0.728407773334734,
-0.694585155528874, 0.978922206583071, -0.551157071252262,
-0.147083062122296,
-0.0131230214314509, -0.728407773334734, 1.47291855077535,
0.960606063335571,
-0.748043964474069, -0.566710486079729, -0.763597379301536,
1.36165200611302,
-0.728407773334734, -0.749364012365905, -0.784553618332707,
1.57140527810952,
-0.487859949884892, 1.57140527810952, -0.763597379301536,
0.857771221757049,
0.270400760480343, 1.57140527810952, -0.784553618332707, 1.57140527810952,
-0.518654501338238, -0.763597379301536, -0.784553618332707,
1.57140527810952,
-0.694585155528874, 0.00677850764036482, -0.783233570440871,
1.57140527810952, 0.977214188122393, 1.57140527810952, -0.783233570440871,
-0.749364012365905, -0.817056188246731, -0.748043964474069,
-0.818376236138567,
-0.531520880112927, 1.57140527810952, -0.714221346668209,
-0.748043964474069,
-0.763597379301536, 1.57140527810952, -0.787581684685221,
-0.748043964474069,
-0.753759066879361, 0.877407412896385, 0.7833553612531, 0.729896552307904,
0.617577722414313, -0.748043964474069, 0.990080566897082,
-0.694585155528874,
0.991400614788918, 1.57140527810952, 1.54061072665617, 1.50810815674215,
0.97828009325009, 1.59236151714069, -0.0439175728847974, 1.57140527810952,
-0.170472194442107, -0.798740044999232, 0.416591573176988,
-0.817056188246731,
-0.694585155528874, 0.940704534263755, -0.190108385581442,
0.0362530112018755,
-0.0622337161322973), y2 = c(-1.10287793408861, -1.10287793408861,
-0.805771744394011, 0.68808527565847, -0.522406822405801,
-0.647532089184814,
0.857364112324029, -1.03278233531451, 1.3396330244827, -0.613170174228784,
1.07727948023885, -0.489375224837763, 1.27926123621074, -0.942018983491532,
-1.16771420345781, 0.732156054682871, -0.746715327076274, 1.3396330244827,
-1.09183875263225, -0.625622463935284, 1.3396330244827, -0.9336818882852,
-0.625622463935284, 1.33873477697753, -0.489375224837763,
-1.10287793408861,
0.851584260272568, 0.538265506517751, -0.664351122692637,
-1.04250614581665,
-0.486673138587732, -1.10865778614007, -0.203308216599523, 1.3396330244827,
1.3396330244827, 0.80610037299803, -1.10287793408861, -0.489375224837763,
-0.808473830644042, -0.489375224837763, 1.14343112056227,
-0.166161424531316,
1.05356601624446, 0.857364112324029, 1.30158798490932, -0.620609021929947,
1.17637992726816, -0.859654779107895, -0.361465080946574,
-0.772740146825973,
1.30158798490932, 1.20338578538518, -0.625622463935284, 1.05356601624446,
-0.203308216599523, -0.647532089184814, -1.10287793408861,
-0.966630694991092,
-0.942018983491532, -0.942018983491532, 0.890312919029921,
-0.621507269435115,
-1.10287793408861, 1.30158798490932, 1.06755566973671, 1.00718388146475,
-0.625622463935284, -0.772740146825973, 1.3396330244827,
-0.625622463935284,
1.14343112056227, 1.30158798490932, 0.851584260272568, -1.16771420345781,
-1.10287793408861, -0.489375224837763, -1.10287793408861,
-0.166161424531316,
-0.522406822405801, -0.577436490410715, -0.808473830644042,
-0.966630694991092,
-0.686343538804313, -0.294071568422505, -0.606492074672155,
0.75818087443257,
-0.808473830644042, -0.587577424361909, -0.653311941236275,
-0.489375224837763,
-0.907574277673355, -1.10287793408861, 0.69732061836997,
-0.808473830644042,
-0.203308216599523, -0.497712320044094, 1.3396330244827, 1.33873477697753,
1.3396330244827, -1.10287793408861, -0.631402315986745, 0.781488661498469,
1.3396330244827, -0.497712320044094, 1.3396330244827, -0.166161424531316,
-1.10287793408861, -0.497712320044094, 1.3396330244827, -0.966630694991092,
-0.577436490410715, -0.783779328282335, 1.3396330244827, 0.69064251881334,
1.3396330244827, -0.783779328282335, -0.203308216599523,
-0.625622463935284,
-0.489375224837763, -0.339555455697044, -0.613170174228784,
1.3396330244827,
-0.647532089184814, -0.489375224837763, -1.10287793408861, 1.3396330244827,
1.1653407458118, -0.489375224837763, 1.00718388146475, -0.950500921793024,
-1.16771420345781, -0.690458733304482, 1.41550847530826,
-0.489375224837763,
1.13765126851081, -0.966630694991092, 0.851584260272568, 1.3396330244827,
-0.165263177026148, -0.293173320917337, 1.32859384302633,
0.734467410438177,
-0.746715327076274, 1.3396330244827, -1.09183875263225, -0.658654061503322,
0.807513481248168, -0.625622463935284, -0.966630694991092,
0.682305423607009,
-0.772740146825973, 1.21352671933637, -0.713683729508236), y3 =
c(1.45365909507257,
1.45365909507257, 0.601293146626485, 1.33320216155997, -1.17984177910205,
0.248147677650784, 0.230928830854086, 1.8796154803882, 0.104896252216293,
-0.597205545538145, 1.24933322965163, -1.58642900961012, 1.22933377144681,
1.2969792468243, 0.275779814309676, 0.177487069321712, 1.7763773936723,
0.104896252216293, 0.704531233342381, -0.89074290941231, 0.104896252216293,
-1.13004545391852, -0.89074290941231, 0.607088890986195, -1.58642900961012,
1.45365909507257, 0.228133797137012, 0.740754148078057, 0.994480505663895,
0.32922157584205, 0.0914678294025141, 1.45086406135549, -1.68966709632602,
0.104896252216293, 0.104896252216293, 0.341183663770922, 1.45365909507257,
-1.58642900961012, -1.07660369238615, -1.58642900961012, 0.12769074413819,
0.624307737782894, 0.208134338932189, 0.230928830854086, -1.70688594312272,
1.32762651643477, -1.76032770465509, 0.51508235881589, 0.144909590934888,
0.19470591611841, -1.70688594312272, 0.800582352414105, -0.89074290941231,
0.208134338932189, -1.68966709632602, 0.248147677650784, 1.45365909507257,
0.757972994874755, 1.2969792468243, 1.2969792468243, -1.65708961793919,
1.82981915520468, 1.45365909507257, -1.70688594312272, -0.301060674894516,
0.823376844336001, -0.89074290941231, 0.19470591611841, 0.104896252216293,
-0.89074290941231, 0.12769074413819, -1.70688594312272, 0.228133797137012,
0.275779814309676, 1.45365909507257, -1.58642900961012, 1.45365909507257,
0.624307737782894, -1.17984177910205, 0.674104062966416, -1.07660369238615,
0.757972994874755, 0.651939874441785, -1.10703086276212, -1.09660315059097,
1.7591585468756, -1.07660369238615, 0.921039285926699, 0.24535264393371,
-1.58642900961012, 1.93305724192057, 1.45365909507257, -1.59601517795275,
-1.07660369238615, -1.68966709632602, 0.840595691132699, 0.104896252216293,
0.607088890986195, 0.104896252216293, 1.45365909507257, -0.893537943129384,
-0.19782258817862, 0.104896252216293, 0.840595691132699, 0.104896252216293,
0.624307737782894, 1.45365909507257, 0.840595691132699, 0.104896252216293,
0.757972994874755, 0.674104062966416, 0.943833777848596, 0.104896252216293,
-1.09661757289992, 0.104896252216293, 0.943833777848596, -1.68966709632602,
-0.89074290941231, -1.58642900961012, -0.993980996128206,
-0.597205545538145,
0.104896252216293, 0.248147677650784, -1.58642900961012, 1.45365909507257,
0.104896252216293, -1.0111998429249, -1.58642900961012, 0.823376844336001,
-0.383712625905413, 0.275779814309676, -2.0686221901752, 0.533647671248999,
-1.58642900961012, 0.124895710421116, 0.757972994874755, 0.228133797137012,
0.104896252216293, 0.122115099012992, -1.60922350153202, 0.854024113946479,
0.717959656156161, 1.7763773936723, 0.104896252216293, 0.704531233342381,
-0.484155678904235, 1.38384888937527, -0.89074290941231, 0.757972994874755,
1.3304071278429, 0.19470591611841, 0.553647129453821, 1.36979016316423
), age = c(1.12411608283392, 1.12411608283392, -0.965221814038959,
-0.965221814038959, 0.582435887348361, 0.814584542556459, 1.27888185297265,
1.04673319776456, -0.733073158830861, 0.427670117209629,
-0.810456043900227,
-0.965221814038959, 1.82056204845822, -0.655690273761495,
-0.578307388692129,
-0.887838928969593, -0.578307388692129, 1.35626473804202,
0.350287232140263,
1.12411608283392, 1.35626473804202, 0.0407556918627987, 0.118138576932165,
-0.423541618553397, 0.350287232140263, 0.659818772417727,
0.737201657487093,
0.350287232140263, 0.582435887348361, -1.04260469910833, 1.27888185297265,
1.27888185297265, 1.20149896790329, 0.0407556918627987, 0.582435887348361,
0.118138576932165, 1.89794493352758, -0.733073158830861, 0.814584542556459,
-0.655690273761495, 0.0407556918627987, 1.82056204845822,
-0.733073158830861,
0.427670117209629, -1.19737046924706, 0.118138576932165, -1.35213623938579,
0.195521462001531, -0.114010078275933, 0.427670117209629,
-0.423541618553397,
2.28485935887441, -0.500924503622763, -0.733073158830861,
-1.11998758417769,
-1.04260469910833, -0.423541618553397, 0.891967427625825,
-0.655690273761495,
0.118138576932165, -0.114010078275933, 0.272904347070897,
0.272904347070897,
-1.81643354980199, -0.500924503622763, 0.195521462001531,
0.195521462001531,
-0.733073158830861, -0.655690273761495, 0.659818772417727,
1.12411608283392,
0.814584542556459, 0.737201657487093, 0.118138576932165, 2.13009358873568,
0.427670117209629, 2.13009358873568, -1.19737046924706, 0.582435887348361,
-0.191392963345299, -0.965221814038959, -0.423541618553397,
-0.423541618553397,
-1.50690200952452, 1.27888185297265, 2.13009358873568, 0.272904347070897,
0.891967427625825, 0.350287232140263, -1.04260469910833, 0.659818772417727,
0.737201657487093, -1.04260469910833, -0.578307388692129, 1.51103050818075,
0.505053002278995, -0.346158733484031, -0.810456043900227,
-1.27475335431642,
0.118138576932165, -0.500924503622763, -0.114010078275933,
-1.11998758417769,
-1.27475335431642, -1.11998758417769, 1.82056204845822, 0.505053002278995,
-0.114010078275933, -0.655690273761495, 1.04673319776456,
-1.04260469910833,
1.74317916338885, -0.500924503622763, 0.118138576932165, -1.35213623938579,
-1.27475335431642, -0.423541618553397, 0.891967427625825,
-0.733073158830861,
-0.733073158830861, 1.89794493352758, -1.19737046924706,
-0.810456043900227,
-1.19737046924706, 1.51103050818075, 1.20149896790329, 1.58841339325012,
-0.810456043900227, -1.35213623938579, 1.89794493352758,
-0.578307388692129,
-1.35213623938579, -0.655690273761495, 0.427670117209629,
-0.423541618553397,
-0.0366271932065673, -1.19737046924706, 0.505053002278995,
-0.346158733484031,
-0.268775848414665, 1.35626473804202, -1.19737046924706,
-0.578307388692129,
-0.965221814038959, -1.19737046924706, 0.505053002278995, 1.12411608283392,
0.0407556918627987, 0.891967427625825, 0.582435887348361,
-1.19737046924706,
0.272904347070897, 0.582435887348361), income = c(-0.74106083852418,
-0.199273127201495, -0.632703296259643, -0.644743023177925,
-0.289571079088609,
0.517090624436278, 0.474951580222291, -0.337729986761736,
-0.470166982862837,
-0.151114219528367, -0.48822657324026, -0.0788758580186757,
-0.440067665567132,
-0.518325890535965, 0.631468030159956, -0.0427566772638301,
-0.723001248146757,
-0.0186772234272663, 0.360574174498613, -0.464147119403696,
-0.446087529026273,
-0.692901930851052, 0.125799499592116, -0.674842340473629,
0.143859089969539,
0.625448166700815, -0.397928621353146, 0.330474857202909, 1.23345437607405,
-0.0126573599681253, -0.632703296259643, -0.632703296259643,
0.330474857202909, 0.806044070475043, 2.65414215243131, -0.3618094405983,
-0.139074492610085, -0.415988211730569, -0.151114219528367,
-0.175193673364931,
0.228137178397513, -0.163153946446649, -0.259471761792904,
-0.723001248146757,
-0.163153946446649, -0.349769713680018, -0.313650532925173,
-0.542405344372529,
0.0355015477050023, -0.355789577139159, -0.289571079088609,
0.270276222611499,
-0.446087529026273, -0.259471761792904, -0.548425207831669,
1.58260645670423,
0.577289259027687, -0.29559094254775, -0.518325890535965,
-0.060816267641253,
1.28763314720632, -0.494246436699401, -0.55444507129081, 0.420772809090023,
0.0234618207867204, -0.452107392485414, 0.493011170599714,
0.071620728459848,
-0.644743023177925, -0.704941657769334, -0.452107392485414,
0.420772809090023,
-0.397928621353146, 0.607388576323392, -0.355789577139159,
-0.710961521228475,
-0.283551215629468, -0.42200807518971, -0.289571079088609,
0.806044070475043,
0.324454993743768, -0.385888894434864, -0.391908757894005,
-0.397928621353146,
0.420772809090023, 0.709726255128788, 1.67892427205048, -0.349769713680018,
-0.506286163617683, 0.228137178397513, -0.121014902232662,
0.228137178397513,
-0.650762886637066, -0.506286163617683, -0.163153946446649,
2.16051334878176,
0.438832399467446, -0.355789577139159, -0.723001248146757,
-0.692901930851052,
-0.0126573599681253, -0.548425207831669, 0.228137178397513,
-0.500266300158542,
-0.452107392485414, -0.163153946446649, 0.131819363051257,
-0.506286163617683,
-0.602603978963938, -0.548425207831669, -0.548425207831669,
-0.163153946446649,
-0.355789577139159, 0.306395403366345, -0.391908757894005,
-0.548425207831669,
0.222117314938372, 0.709726255128788, 0.228137178397513,
-0.638723159718784,
0.432812536008305, 0.0355015477050023, 0.185998134183526,
-0.566484798209092,
0.228137178397513, -0.199273127201495, 0.324454993743768,
-0.452107392485414,
-0.662802613555348, -0.349769713680018, 0.631468030159956,
-0.3618094405983,
-0.452107392485414, 1.69096399896876, -0.626683432800502,
0.131819363051257,
-0.355789577139159, 0.0355015477050023, -0.199273127201495,
0.0355015477050023,
-0.355789577139159, -0.355789577139159, -0.723001248146757,
0.270276222611499,
-0.355789577139159, 0.438832399467446, -0.355789577139159,
1.19131533186006,
-0.29559094254775, -0.355789577139159, 1.11907697035037,
-0.355789577139159,
0.228137178397513), ethnicity = structure(c(1L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L), .Label = c("POC", "White"), class = "factor"),
    gender = structure(c(2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L,
    2L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L,
    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L,
    1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L,
    1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L,
    1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 1L,
    1L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L,
    2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
    2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
    2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("Fem/Oth",
    "M"), class = "factor"), residence = structure(c(1L, 1L,
    2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L,
    1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L,
    1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L,
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L,
    1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L,
    2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L,
    2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 1L,
    1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 2L,
    2L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 2L,
    1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
    1L), .Label = c("Own", "Other"), class = "factor"), education =
structure(c(4L,
    2L, 2L, 4L, 4L, 2L, 3L, 2L, 3L, 4L, 4L, 4L, 3L, 4L, 2L, 4L,
    4L, 4L, 1L, 3L, 2L, 3L, 4L, 3L, 2L, 3L, 1L, 1L, 4L, 1L, 2L,
    1L, 3L, 3L, 2L, 3L, 3L, 4L, 3L, 1L, 1L, 3L, 3L, 3L, 4L, 3L,
    3L, 4L, 1L, 3L, 1L, 3L, 3L, 3L, 3L, 3L, 4L, 3L, 4L, 1L, 3L,
    3L, 4L, 1L, 4L, 4L, 1L, 3L, 3L, 3L, 4L, 4L, 1L, 1L, 3L, 4L,
    2L, 2L, 4L, 4L, 1L, 3L, 3L, 1L, 4L, 4L, 2L, 2L, 1L, 3L, 3L,
    3L, 4L, 3L, 3L, 3L, 4L, 4L, 3L, 4L, 4L, 2L, 4L, 3L, 3L, 3L,
    4L, 2L, 3L, 3L, 1L, 3L, 4L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L,
    3L, 4L, 2L, 4L, 2L, 4L, 4L, 2L, 4L, 2L, 3L, 4L, 1L, 1L, 3L,
    3L, 4L, 3L, 4L, 4L, 3L, 4L, 1L, 3L, 3L, 4L, 1L, 3L, 2L, 1L,
    4L, 4L), .Label = c("HighSchl", "2YrColl", "4YrColl", "Grad"
    ), class = c("ordered", "factor")), blvl1 = c(-0.50505029940877,
    -2.17303662248029, -4.65072504413022, -0.262139669835247,
    -0.375497963636224, 0.353233925084342, 0.353233925084342,
    0.353233925084342, 0.353233925084342, 0.353233925084342,
    -0.310721795749951, -0.310721795749951, -0.310721795749951,
    -0.310721795749951, -0.310721795749951, -0.084005208147997,
    -0.084005208147997, -0.084005208147997, -0.084005208147997,
    -0.084005208147997, 0.0455471276245484, 0.0455471276245484,
    0.0455471276245484, 0.0455471276245484, 0.0455471276245484,
    -1.62243919544697, -1.62243919544697, -1.62243919544697,
    -1.62243919544697, -1.62243919544697, -4.65072504413022,
    -4.65072504413022, -4.65072504413022, -4.65072504413022,
    -4.65072504413022, -0.666990719124451, -0.666990719124451,
    -0.666990719124451, -0.666990719124451, -0.666990719124451,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, -2.72363404951361,
    0.337039883112776, 0.353233925084342, 0.337039883112776,
    0.337039883112776, -0.666990719124451, 0.353233925084342,
    0.353233925084342, 0.337039883112776, 0.337039883112776,
    0.337039883112776, -0.375497963636224, 0.337039883112776,
    -0.310721795749951, 0.337039883112776, 0.353233925084342,
    -0.666990719124451, 0.337039883112776, 0.337039883112776,
    -0.666990719124451, 0.337039883112776, -0.666990719124451,
    0.353233925084342, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, -1.62243919544697,
    -0.375497963636224, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, -0.375497963636224,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    -0.084005208147997, -3.19326126668908, 0.337039883112776,
    0.337039883112776, 0.353233925084342, 0.353233925084342,
    0.353233925084342, 0.337039883112776, 0.337039883112776,
    0.337039883112776, -0.084005208147997, 0.0779352115676847,
    0.337039883112776, 0.337039883112776, 0.353233925084342,
    0.337039883112776, 0.337039883112776, -1.37952856587345,
    -1.62243919544697, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    -0.00303499829015614, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    0.337039883112776, -0.084005208147997, 0.337039883112776,
    0.337039883112776, -0.084005208147997, 0.337039883112776,
    0.337039883112776, -0.00303499829015614, -0.084005208147997,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    0.337039883112776, -0.084005208147997, 0.337039883112776,
    0.337039883112776, 0.337039883112776, -0.50505029940877,
    -0.310721795749951, 0.337039883112776, 0.337039883112776,
    0.353233925084342, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    -0.084005208147997, 0.353233925084342, 0.337039883112776,
    0.353233925084342, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776, 0.337039883112776,
    0.337039883112776, 0.337039883112776), blvl2 = c(0.354509613384445,
    -0.1700634432487, 2.26558672076527, -1.03570166744545,
2.66596756964428,
    -0.624199128319797, -0.624199128319797, -0.624199128319797,
    -0.624199128319797, -0.624199128319797, 1.21273337741677,
    1.21273337741677, 1.21273337741677, 1.21273337741677, 1.21273337741677,
    -0.227525509523001, -0.227525509523001, -0.227525509523001,
    -0.227525509523001, -0.227525509523001, 2.18773488903879,
    2.18773488903879, 2.18773488903879, 2.18773488903879, 2.18773488903879,
    0.119100503163918, 0.119100503163918, 0.119100503163918,
    0.119100503163918, 0.119100503163918, -1.98104533840977,
    -1.98104533840977, -1.98104533840977, -1.98104533840977,
    -1.98104533840977, 2.68265010501424, 2.68265010501424,
2.68265010501424,
    2.68265010501424, 2.68265010501424, -0.270158655468452,
-0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    1.3350719701298, -0.270158655468452, -0.624199128319797,
    -0.270158655468452, -0.270158655468452, 2.68265010501424,
    -0.624199128319797, -0.624199128319797, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, 2.66596756964428,
    -0.270158655468452, 1.21273337741677, -0.270158655468452,
    -0.624199128319797, 2.68265010501424, -0.270158655468452,
    -0.270158655468452, 2.68265010501424, -0.270158655468452,
    2.68265010501424, -0.624199128319797, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    0.119100503163918, 2.66596756964428, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    2.66596756964428, -0.270158655468452, -0.270158655468452,
    -0.270158655468452, -0.227525509523001, 4.33978195176347,
    -0.270158655468452, -0.270158655468452, -0.624199128319797,
    -0.624199128319797, -0.624199128319797, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.227525509523001,
    1.90969263287282, -0.270158655468452, -0.270158655468452,
    -0.624199128319797, -0.270158655468452, -0.270158655468452,
    -0.0773826911933738, 0.119100503163918, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    -0.270158655468452, -0.00509170459021939, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.227525509523001,
    -0.270158655468452, -0.270158655468452, -0.227525509523001,
    -0.270158655468452, -0.270158655468452, 2.52694644156129,
    -0.227525509523001, -0.270158655468452, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.227525509523001,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    0.354509613384445, 1.21273337741677, -0.270158655468452,
    -0.270158655468452, -0.624199128319797, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    -0.270158655468452, -0.227525509523001, -0.624199128319797,
    -0.270158655468452, -0.624199128319797, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452,
    -0.270158655468452, -0.270158655468452, -0.270158655468452
    ), blvl3 = c(-0.379922319079342, -0.435914902798495, 1.91577361340593,
    0.235996101831342, -0.687881529534684, -0.995840739990026,
    -0.995840739990026, -0.995840739990026, -0.995840739990026,
    -0.995840739990026, -0.967844448130449, -0.967844448130449,
    -0.967844448130449, -0.967844448130449, -0.967844448130449,
    -0.771870405113414, -0.771870405113414, -0.771870405113414,
    -0.771870405113414, -0.771870405113414, 0.0120257669547292,
    0.0120257669547292, 0.0120257669547292, 0.0120257669547292,
    0.0120257669547292, -0.183948276062306, -0.183948276062306,
    -0.183948276062306, -0.183948276062306, -0.183948276062306,
    1.01989227389948, 1.01989227389948, 1.01989227389948, 1.01989227389948,
    1.01989227389948, -0.883855572551719, -0.883855572551719,
    -0.883855572551719, -0.883855572551719, -0.883855572551719,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, 0.263992393690918, 4.23946583775078,
0.263992393690918,
    -0.995840739990026, 0.263992393690918, 0.263992393690918,
    -0.883855572551719, -0.995840739990026, -0.995840739990026,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    -0.687881529534684, 0.263992393690918, -0.967844448130449,
    0.263992393690918, -0.995840739990026, -0.883855572551719,
    0.263992393690918, 0.263992393690918, -0.883855572551719,
    0.263992393690918, -0.883855572551719, -0.995840739990026,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, -0.183948276062306, -0.687881529534684,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, -0.687881529534684, 0.263992393690918,
    0.263992393690918, 0.263992393690918, -0.771870405113414,
    4.5754213400657, 0.263992393690918, 0.263992393690918,
-0.995840739990026,
    -0.995840739990026, -0.995840739990026, 0.263992393690918,
    0.263992393690918, 0.263992393690918, -0.771870405113414,
    -1.27580365858579, 0.263992393690918, 0.263992393690918,
    -0.995840739990026, 0.263992393690918, 0.263992393690918,
    -1.13582219928791, -0.183948276062306, 0.263992393690918,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, -1.19181478300706, 0.263992393690918,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, 0.263992393690918, -0.771870405113414,
    0.263992393690918, 0.263992393690918, -0.771870405113414,
    0.263992393690918, 0.263992393690918, -1.47177770160283,
    -0.771870405113414, 0.263992393690918, 0.263992393690918,
    0.263992393690918, 0.263992393690918, -0.771870405113414,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    -0.379922319079342, -0.967844448130449, 0.263992393690918,
    0.263992393690918, -0.995840739990026, 0.263992393690918,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, -0.771870405113414, -0.995840739990026,
    0.263992393690918, -0.995840739990026, 0.263992393690918,
    0.263992393690918, 0.263992393690918, 0.263992393690918,
    0.263992393690918, 0.263992393690918, 0.263992393690918),
    block = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
    3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,
    6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L,
    9L, 9L, 9L, 9L, 9L, 1L, 9L, 2L, 9L, 9L, 8L, 2L, 2L, 9L, 9L,
    9L, 1L, 9L, 3L, 9L, 2L, 8L, 9L, 9L, 8L, 9L, 8L, 2L, 9L, 9L,
    9L, 9L, 6L, 1L, 9L, 9L, 9L, 9L, 1L, 9L, 9L, 9L, 4L, 1L, 9L,
    9L, 2L, 2L, 2L, 9L, 9L, 9L, 4L, 1L, 9L, 9L, 2L, 9L, 9L, 1L,
    6L, 9L, 9L, 9L, 9L, 9L, 1L, 9L, 9L, 9L, 9L, 9L, 9L, 4L, 9L,
    9L, 4L, 9L, 9L, 1L, 4L, 9L, 9L, 9L, 9L, 4L, 9L, 9L, 9L, 1L,
    3L, 9L, 9L, 2L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 4L, 2L, 9L,
    2L, 9L, 9L, 9L, 9L, 9L, 9L, 9L), .Label = c("1", "2", "3",
    "4", "5", "6", "7", "8", "9"), class = "factor"), ID = c("245",
    "423", "603", "601", "305", "560", "713", "638", "715", "393",
    "673", "553", "634", "465", "528", "666", "574", "175", "606",
    "567", "9", "383", "354", "719", "45", "416", "369", "43",
    "670", "401", "642", "372", "211", "227", "210", "409", "399",
    "380", "344", "513", "717", "691", "293", "576", "184", "29",
    "231", "99", "246", "556", "548", "313", "726", "293", "507",
    "224", "306", "163", "465", "107", "462", "196", "626", "569",
    "672", "561", "512", "615", "190", "2", "288", "526", "369",
    "608", "264", "579", "280", "702", "305", "303", "182", "698",
    "345", "597", "358", "80", "521", "111", "274", "125", "301",
    "511", "130", "653", "17", "157", "403", "159", "348", "434",
    "374", "27", "368", "179", "137", "691", "11", "247", "390",
    "14", "114", "270", "170", "582", "722", "244", "564", "230",
    "355", "711", "621", "54", "718", "422", "284", "200", "78",
    "208", "286", "611", "528", "251", "411", "657", "115", "28",
    "60", "701", "376", "605", "730", "138", "574", "275", "259",
    "529", "12", "238", "163", "563", "678", "229", "123")), row.names =
c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
"14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
"25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
"36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "291",
"231", "99", "246", "552", "544", "313", "722", "293", "505",
"224", "306", "163", "464", "107", "461", "196", "622", "565",
"668", "557", "510", "611", "190", "210", "288", "522", "368",
"604", "264", "575", "280", "698", "305", "303", "182", "694",
"344", "593", "357", "80", "517", "111", "274", "125", "301",
"509", "130", "649", "171", "157", "402", "159", "347", "433",
"373", "271", "367", "179", "137", "687", "112", "247", "389",
"141", "114", "270", "170", "578", "718", "244", "560", "230",
"354", "707", "617", "54", "714", "421", "284", "200", "78",
"208", "286", "607", "524", "251", "410", "653", "115", "281",
"60", "697", "375", "601", "726", "138", "570", "275", "259",
"146", "147", "148", "149", "150", "151", "152", "153"), .Names = c("y1",
"y2", "y3", "age", "income", "ethnicity", "gender", "residence",
"education", "blvl1", "blvl2", "blvl3", "block", "ID"), class =
"data.frame")



Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu May 28 20:39:26 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 May 2015 14:39:26 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
Message-ID: <556760DE.2080305@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-05-28 06:55 AM, Francesco Romano wrote:
> Many thanks to both.
> 
> The approaches you suggest (and others online) help one deal with
> the separation problem but don't offer any specific advice as to
> how getting a valid p coefficient when comparing two levels of the
> model vexed by separation.
> 
> Ben, here's the output of the bglmer which by the way would be
> ideal since it allows me to retain the random effect so that all my
> pairwise comparisons are conducted using mixed effects.
> 
>> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
>> trialglm,
> family = binomial) Warning message: package ?blme? was built under
> R version 3.1.2
>> summary(trial)
> Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
> posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace 
> Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
> Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
> 
> AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
> 251.9      376
> 
> Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
> -0.4281 -0.2445 -0.0002  5.7872
> 
> Random effects: Groups    Name        Variance Std.Dev. Part.name
> (Intercept) 0.3836   0.6194 Number of obs: 385, groups:  Part.name,
> 16
> 
> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
> 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
> 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323     0.7462
> -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
> 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819 
> Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 . 
> Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 --- 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Unfortunately the separation problem is still there. Should I be 
> constraining the parameter somehow? How would I do that? The data
> is below.

   Did you read the section in the URL I suggested?  Just using bglmer
isn't enough; you also have to set a prior on the fixed effects.

  Your data don't seem to be attached (note that the mailing list
strips most non-ASCII file types).

> 
> In passing I also tried brglm which solves the separation problem
> but tells me comparison is significant which I don't believe one
> bit (see the data below). I am pretty sure about this because when
> I reveled and look at the comparisons I was able to compute using
> glmer, these turn out to be non-significant, when glmer told me
> they were:
> 
>> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
>> =
> binomial) Warning messages: 1: package ?elrm? was built under R
> version 3.1.2 2: package ?coda? was built under R version 3.1.3
>> summary(trial)
> 
> Call: brglm(formula = Correct ~ Syntax.Semantics, family =
> binomial, data = trialglm)
> 
> 
> Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
> -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A   0.6689
> 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
> -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
> 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857 
> Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561 
> Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 . 
> Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 --- Signif.
> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
> Null deviance: 262.51  on 384  degrees of freedom Residual
> deviance: 256.22  on 377  degrees of freedom Penalized deviance:
> 245.5554 AIC:  272.22
> 
> 
> MCMCglmm is too complex for me.
> 
> Wolfgang, I tried the penalized likelihood method (logistf
> function) but output is hard to read:
> 
>> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>> family =
> binomial) Warning messages: 1: package ?logistf? was built under R
> version 3.1.2 2: package ?mice? was built under R version 3.1.2
>> summary(trial)
> logistf(formula = Correct ~ Syntax.Semantics, data = trialglm, 
> family = binomial)
> 
> Model fitted by Penalized ML Confidence intervals and p-values by
> Profile Likelihood Profile Likelihood Profile Likelihood Profile
> Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
> Profile Likelihood
> 
> coef  se(coef) lower 0.95 upper 0.95 Chisq            p (Intercept)
> 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00 
> Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
> 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
> -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
> -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00 
> Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
> 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
> -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
> -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00 
> Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
> 0.000000 1.000000e+00
> 
> Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
> 5.334321 on 7 df, p = 0.6192356
> 
> In particular, what is this model telling me? That Z (my ref level)
> and B are significantly different?
> 
> I'm happy to try the elrm function with exact logistic regression
> but I am not capable of programming it. Besides, would it give me
> valid estimates for the comparison between the Z and B levels? The
> data frame should look like this:
> 
> Outcome variable (Correct, incorrect) Predictor variable (A, B, C,
> D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
> 36,8; C:45,3; A: 34,13; F:65,22).
> 
> Thank you! F.
> 
> On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
> wrote:
> 
>> And for what it's worth, you can do this in conjunction with lme4
>> by using the blme package instead (a thin Bayesian wrapper around
>> lme4), or via the MCMCglmm package; see 
>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>> for an example (search for "complete separation").
>> 
>> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT) 
>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>> You may need to consider using an 'exact', Bayesian, or
>>> penalized
>> likelihood approach (along the lines proposed by Firth).
>>> 
>>> Maybe a place to start:
>> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>>>
>>>
>> 
Best,
>>> Wolfgang
>>> 
>>>> -----Original Message----- From: R-sig-mixed-models
>>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
>>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>>>> cells in contrast matrix problem
>>>> 
>>>> After giving up on a glmer for my data, I remembered a post
>>>> by Roger
>> Levy
>>>> suggesting to try the use non mixed effects glm when one of
>>>> the cells in a matrix is zero.
>>>> 
>>>> To put this into perspective:
>>>> 
>>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
>>>>> data =
>>>> trialglm, family = binomial)
>>>> 
>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>>>> opt$par, ctrl = control$checkConv, : Model failed to converge
>>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
>>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>> control$checkConv, : Model is nearly unidentifiable: large
>>>> eigenvalue ratio - Rescale variables?
>>>> 
>>>> My data has a binary outcome, correct or incorrect, a fixed
>>>> effect predictor factor with 8 levels, and a random effect
>>>> for participants. I believe the problem R is encountering is
>>>> with one level of the factor (let us call it level B) which
>>>> has no counts (no I won' t try to post the table from the
>>>> paper with the counts because I know it will get garbled
>>>> up!).
>>>> 
>>>> I attempt a glm with the same data:
>>>> 
>>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>>>>> family =
>>>> binomial)
>>>>> anova(trial)
>>>> Analysis of Deviance Table
>>>> 
>>>> Model: binomial, link: logit
>>>> 
>>>> Response: Correct
>>>> 
>>>> Terms added sequentially (first to last)
>>>> 
>>>> 
>>>> Df Deviance Resid. Df Resid. Dev NULL
>>>> 384     289.63 Syntax.Semantics  7   34.651       377
>>>> 254.97
>>>>> summary(trial)
>>>> 
>>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>>>> binomial, data = trialglm)
>>>> 
>>>> Deviance Residuals: Min        1Q    Median        3Q
>>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>>>> 
>>>> Coefficients: Estimate Std. Error z value Pr(>|z|) 
>>>> (Intercept)                 -1.6917     0.4113  -4.113
>>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>>>> ?.? 0.1 ? ? 1
>>>> 
>>>> (Dispersion parameter for binomial family taken to be 1)
>>>> 
>>>> Null deviance: 289.63  on 384  degrees of freedom Residual
>>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>>>> 
>>>> Number of Fisher Scoring iterations: 17
>>>> 
>>>> The comparison I'm interested in is between level B and the
>>>> reference level but it cannot be estimated as shown by the
>>>> ridiculously high estimate and SE value.
>>>> 
>>>> Any suggestions on how to get a decent beta, SE, z, and p?
>>>> It's the only comparison missing in the table for the levels
>>>> I need so I think it
>> would
>>>> be a bit unacademic of me to close this deal saying 'the
>>>> difference
>> could
>>>> not be estimated due to zero count'.
>>>> 
>>>> And by the way I have seen this comparison being generated
>>>> using other stats.
>>>> 
>>>> Thanks in advance,
>>>> 
>>>> Frank
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVZ2DeAAoJEOCV5YRblxUH9f0IAN/LTzJllxXqmdP4U2bbDNOR
XnjYDsQ+cF6eR6aRMxWK1nj7Lgdi1pvqOU/3CSMVke2HW2Cr07wR2VDtqHwWRAgZ
jTlzlJ/iA5o32T1U2Wm9jrle0E0RpTMrA8SZ8HsGVKT3cD/5TNo9eoPAw3DV45AO
hmwUJf0NYLhZwOJ2QAsk1rAn06CBmrVSXFUmdGKpODELFJ4whAn95phE8pLY+aW9
qfO4Rq4FcZt1wdRwlZmk8woEeqeySb+rBRxZCVQ0HuyoEGONHMq5Wa1hnffwVR3V
yiIo1Vtd7sTbxAs96DeP8AItyHTvgsKRJphEK/PYguDQCGeR70sQEL53FTdHM60=
=3UD2
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Thu May 28 22:46:31 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 May 2015 16:46:31 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+GYB7KLTp_V4P7hZ0JdQDgGijcnJ_DV5jTXRyCcvzbD5Q@mail.gmail.com>
Message-ID: <CABghstS=homC8L1eV1T_qkO5eodHGBRXXJpX=oc8ycRHUd7spg@mail.gmail.com>

  I don't see your data -- I see a little tiny subset, but that's not
really enough for a reproducible example.

This is the example given in the URL I sent:

cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
                       family=binomial,
                       fixef.prior = normal(cov = diag(9,4)))

trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name),
          data =trialglm,
         family = binomial,
        fixef.prior = normal(cov=diag(9,8)))

The last line specifies an 8x8 matrix (because you have 8 fixed effect
parameters) with a value of 9 on the diagonal, meaning the priors for
the fixed effects are independent and each is Normal with a sd of
sqrt(9)=3.


On Thu, May 28, 2015 at 3:25 PM, Francesco Romano
<francescobryanromano at gmail.com> wrote:
> Yes but this seems a bit above my head without your help. The data are in
> the three variables at the bottom of my email but I forgot to mention the
> random participant effect (n = 17). Thanks!
>
>
> Il gioved? 28 maggio 2015, Ben Bolker <bbolker at gmail.com> ha scritto:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 15-05-28 06:55 AM, Francesco Romano wrote:
>> > Many thanks to both.
>> >
>> > The approaches you suggest (and others online) help one deal with
>> > the separation problem but don't offer any specific advice as to
>> > how getting a valid p coefficient when comparing two levels of the
>> > model vexed by separation.
>> >
>> > Ben, here's the output of the bglmer which by the way would be
>> > ideal since it allows me to retain the random effect so that all my
>> > pairwise comparisons are conducted using mixed effects.
>> >
>> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
>> >> trialglm,
>> > family = binomial) Warning message: package ?blme? was built under
>> > R version 3.1.2
>> >> summary(trial)
>> > Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>> > posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
>> >
>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>> > Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
>> > Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>> >
>> > AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
>> > 251.9      376
>> >
>> > Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>> > -0.4281 -0.2445 -0.0002  5.7872
>> >
>> > Random effects: Groups    Name        Variance Std.Dev. Part.name
>> > (Intercept) 0.3836   0.6194 Number of obs: 385, groups:  Part.name,
>> > 16
>> >
>> > Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> > -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>> > 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
>> > 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323     0.7462
>> > -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
>> > 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
>> > Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>> > Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Unfortunately the separation problem is still there. Should I be
>> > constraining the parameter somehow? How would I do that? The data
>> > is below.
>>
>>    Did you read the section in the URL I suggested?  Just using bglmer
>> isn't enough; you also have to set a prior on the fixed effects.
>>
>>   Your data don't seem to be attached (note that the mailing list
>> strips most non-ASCII file types).
>>
>> >
>> > In passing I also tried brglm which solves the separation problem
>> > but tells me comparison is significant which I don't believe one
>> > bit (see the data below). I am pretty sure about this because when
>> > I reveled and look at the comparisons I was able to compute using
>> > glmer, these turn out to be non-significant, when glmer told me
>> > they were:
>> >
>> >> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
>> >> =
>> > binomial) Warning messages: 1: package ?elrm? was built under R
>> > version 3.1.2 2: package ?coda? was built under R version 3.1.3
>> >> summary(trial)
>> >
>> > Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>> > binomial, data = trialglm)
>> >
>> >
>> > Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> > -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A   0.6689
>> > 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
>> > -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
>> > 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
>> > Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>> > Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>> > Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 --- Signif.
>> > codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > (Dispersion parameter for binomial family taken to be 1)
>> >
>> > Null deviance: 262.51  on 384  degrees of freedom Residual
>> > deviance: 256.22  on 377  degrees of freedom Penalized deviance:
>> > 245.5554 AIC:  272.22
>> >
>> >
>> > MCMCglmm is too complex for me.
>> >
>> > Wolfgang, I tried the penalized likelihood method (logistf
>> > function) but output is hard to read:
>> >
>> >> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>> >> family =
>> > binomial) Warning messages: 1: package ?logistf? was built under R
>> > version 3.1.2 2: package ?mice? was built under R version 3.1.2
>> >> summary(trial)
>> > logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
>> > family = binomial)
>> >
>> > Model fitted by Penalized ML Confidence intervals and p-values by
>> > Profile Likelihood Profile Likelihood Profile Likelihood Profile
>> > Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
>> > Profile Likelihood
>> >
>> > coef  se(coef) lower 0.95 upper 0.95 Chisq            p (Intercept)
>> > 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
>> > Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
>> > 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
>> > -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
>> > -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00
>> > Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
>> > 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
>> > -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
>> > -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00
>> > Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
>> > 0.000000 1.000000e+00
>> >
>> > Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
>> > 5.334321 on 7 df, p = 0.6192356
>> >
>> > In particular, what is this model telling me? That Z (my ref level)
>> > and B are significantly different?
>> >
>> > I'm happy to try the elrm function with exact logistic regression
>> > but I am not capable of programming it. Besides, would it give me
>> > valid estimates for the comparison between the Z and B levels? The
>> > data frame should look like this:
>> >
>> > Outcome variable (Correct, incorrect) Predictor variable (A, B, C,
>> > D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
>> > 36,8; C:45,3; A: 34,13; F:65,22).
>> >
>> > Thank you! F.
>> >
>> > On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
>> > wrote:
>> >
>> >> And for what it's worth, you can do this in conjunction with lme4
>> >> by using the blme package instead (a thin Bayesian wrapper around
>> >> lme4), or via the MCMCglmm package; see
>> >> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>> >> for an example (search for "complete separation").
>> >>
>> >> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
>> >> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >>> You may need to consider using an 'exact', Bayesian, or
>> >>> penalized
>> >> likelihood approach (along the lines proposed by Firth).
>> >>>
>> >>> Maybe a place to start:
>> >>
>> >> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>> >>>
>> >>>
>> >>
>> Best,
>> >>> Wolfgang
>> >>>
>> >>>> -----Original Message----- From: R-sig-mixed-models
>> >>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
>> >>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
>> >>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>> >>>> cells in contrast matrix problem
>> >>>>
>> >>>> After giving up on a glmer for my data, I remembered a post
>> >>>> by Roger
>> >> Levy
>> >>>> suggesting to try the use non mixed effects glm when one of
>> >>>> the cells in a matrix is zero.
>> >>>>
>> >>>> To put this into perspective:
>> >>>>
>> >>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
>> >>>>> data =
>> >>>> trialglm, family = binomial)
>> >>>>
>> >>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>> >>>> opt$par, ctrl = control$checkConv, : Model failed to converge
>> >>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
>> >>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> >>>> control$checkConv, : Model is nearly unidentifiable: large
>> >>>> eigenvalue ratio - Rescale variables?
>> >>>>
>> >>>> My data has a binary outcome, correct or incorrect, a fixed
>> >>>> effect predictor factor with 8 levels, and a random effect
>> >>>> for participants. I believe the problem R is encountering is
>> >>>> with one level of the factor (let us call it level B) which
>> >>>> has no counts (no I won' t try to post the table from the
>> >>>> paper with the counts because I know it will get garbled
>> >>>> up!).
>> >>>>
>> >>>> I attempt a glm with the same data:
>> >>>>
>> >>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>> >>>>> family =
>> >>>> binomial)
>> >>>>> anova(trial)
>> >>>> Analysis of Deviance Table
>> >>>>
>> >>>> Model: binomial, link: logit
>> >>>>
>> >>>> Response: Correct
>> >>>>
>> >>>> Terms added sequentially (first to last)
>> >>>>
>> >>>>
>> >>>> Df Deviance Resid. Df Resid. Dev NULL
>> >>>> 384     289.63 Syntax.Semantics  7   34.651       377
>> >>>> 254.97
>> >>>>> summary(trial)
>> >>>>
>> >>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>> >>>> binomial, data = trialglm)
>> >>>>
>> >>>> Deviance Residuals: Min        1Q    Median        3Q
>> >>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>> >>>>
>> >>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>> >>>> (Intercept)                 -1.6917     0.4113  -4.113
>> >>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>> >>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>> >>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>> >>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>> >>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>> >>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>> >>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>> >>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>> >>>> ?.? 0.1 ? ? 1
>> >>>>
>> >>>> (Dispersion parameter for binomial family taken to be 1)
>> >>>>
>> >>>> Null deviance: 289.63  on 384  degrees of freedom Residual
>> >>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>> >>>>
>> >>>> Number of Fisher Scoring iterations: 17
>> >>>>
>> >>>> The comparison I'm interested in is between level B and the
>> >>>> reference level but it cannot be estimated as shown by the
>> >>>> ridiculously high estimate and SE value.
>> >>>>
>> >>>> Any suggestions on how to get a decent beta, SE, z, and p?
>> >>>> It's the only comparison missing in the table for the levels
>> >>>> I need so I think it
>> >> would
>> >>>> be a bit unacademic of me to close this deal saying 'the
>> >>>> difference
>> >> could
>> >>>> not be estimated due to zero count'.
>> >>>>
>> >>>> And by the way I have seen this comparison being generated
>> >>>> using other stats.
>> >>>>
>> >>>> Thanks in advance,
>> >>>>
>> >>>> Frank
>> >>>>
>> >>>> [[alternative HTML version deleted]]
>> >>>>
>> >>>> _______________________________________________
>> >>>> R-sig-mixed-models at r-project.org mailing list
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.4.11 (GNU/Linux)
>>
>> iQEcBAEBAgAGBQJVZ2DeAAoJEOCV5YRblxUH9f0IAN/LTzJllxXqmdP4U2bbDNOR
>> XnjYDsQ+cF6eR6aRMxWK1nj7Lgdi1pvqOU/3CSMVke2HW2Cr07wR2VDtqHwWRAgZ
>> jTlzlJ/iA5o32T1U2Wm9jrle0E0RpTMrA8SZ8HsGVKT3cD/5TNo9eoPAw3DV45AO
>> hmwUJf0NYLhZwOJ2QAsk1rAn06CBmrVSXFUmdGKpODELFJ4whAn95phE8pLY+aW9
>> qfO4Rq4FcZt1wdRwlZmk8woEeqeySb+rBRxZCVQ0HuyoEGONHMq5Wa1hnffwVR3V
>> yiIo1Vtd7sTbxAs96DeP8AItyHTvgsKRJphEK/PYguDQCGeR70sQEL53FTdHM60=
>> =3UD2
>> -----END PGP SIGNATURE-----
>
>
>
> --
> Sent from Gmail for IPhone


From bbolker at gmail.com  Fri May 29 20:32:24 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 29 May 2015 14:32:24 -0400
Subject: [R-sig-ME] Zero cells in contrast matrix problem
In-Reply-To: <CABZN5+EMzegCtb3pJA_k=vEq-4v3CYx4Rq21pxmuVxBf1aYiSA@mail.gmail.com>
References: <CABZN5+H=LCe=6a21x76CBCQf9xA6e4h-=T7nXBjomB6-GRdHPw@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0CCDD130@UM-MAIL4112.unimaas.nl>
	<CABghstQo0fJff8Kx=KMS6YmB=Wk2S0JgT7AxTz4rVigoWDV5tA@mail.gmail.com>
	<CABZN5+G=1KxvkZrSb=SnzZ8uOw64m=FRO8a3uDJaueFnogUt6Q@mail.gmail.com>
	<556760DE.2080305@gmail.com>
	<CABZN5+EMzegCtb3pJA_k=vEq-4v3CYx4Rq21pxmuVxBf1aYiSA@mail.gmail.com>
Message-ID: <CABghstRZ=18i2=MtfmgeTPtp8UbYYGnizHXhmL+YPhebA3fssQ@mail.gmail.com>

  [Please keep r-sig-mixed-models in the cc: list ...]

 It would seem consistent to me to use the penalized/Bayesian results
throughout, not just for the completely separated term. (It's not
"MCMCglmm-adjusted", unless I'm missing something ...)


On Fri, May 29, 2015 at 2:30 PM, Francesco Romano
<francescobryanromano at gmail.com> wrote:
> Ben that worked a charm!
> I guess now I'm only left with the question of whether it would be more
> appropriate to report the stats for all the pairwise comparisons, including
> those that were not subject to complete separation, from the
> MCMCglmm-adjusted model. In other words, the separation problem was only
> relevant to level B because there were no incorrect answers at all.
>
> Frank
>
> On Thu, May 28, 2015 at 8:39 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 15-05-28 06:55 AM, Francesco Romano wrote:
>> > Many thanks to both.
>> >
>> > The approaches you suggest (and others online) help one deal with
>> > the separation problem but don't offer any specific advice as to
>> > how getting a valid p coefficient when comparing two levels of the
>> > model vexed by separation.
>> >
>> > Ben, here's the output of the bglmer which by the way would be
>> > ideal since it allows me to retain the random effect so that all my
>> > pairwise comparisons are conducted using mixed effects.
>> >
>> >> trial<-bglmer(Correct ~ Syntax.Semantics+(1|Part.name), data =
>> >> trialglm,
>> > family = binomial) Warning message: package ?blme? was built under
>> > R version 3.1.2
>> >> summary(trial)
>> > Cov prior  : Part.name ~ wishart(df = 3.5, scale = Inf,
>> > posterior.scale = cov, common.scale = TRUE) Prior dev  : 1.4371
>> >
>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>> > Approximation) ['bglmerMod'] Family: binomial  ( logit ) Formula:
>> > Correct ~ Syntax.Semantics + (1 | Part.name) Data: trialglm
>> >
>> > AIC      BIC   logLik deviance df.resid 269.9    305.5   -126.0
>> > 251.9      376
>> >
>> > Scaled residuals: Min      1Q  Median      3Q     Max -0.9828
>> > -0.4281 -0.2445 -0.0002  5.7872
>> >
>> > Random effects: Groups    Name        Variance Std.Dev. Part.name
>> > (Intercept) 0.3836   0.6194 Number of obs: 385, groups:  Part.name,
>> > 16
>> >
>> > Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> > -1.8671     0.4538  -4.114 3.89e-05 *** Syntax.Semantics A
>> > 0.8121     0.5397   1.505   0.1324 Syntax.Semantics B  -16.4391
>> > 1195.5031  -0.014   0.9890 Syntax.Semantics C   -1.1323     0.7462
>> > -1.517   0.1292 Syntax.Semantics D    0.1789     0.5853   0.306
>> > 0.7598 Syntax.Semantics E   -0.8071     0.7500  -1.076   0.2819
>> > Syntax.Semantics F   -1.5051     0.8575  -1.755   0.0792 .
>> > Syntax.Semantics G    0.4395     0.5417   0.811   0.4171 ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Unfortunately the separation problem is still there. Should I be
>> > constraining the parameter somehow? How would I do that? The data
>> > is below.
>>
>>    Did you read the section in the URL I suggested?  Just using bglmer
>> isn't enough; you also have to set a prior on the fixed effects.
>>
>>   Your data don't seem to be attached (note that the mailing list
>> strips most non-ASCII file types).
>>
>> >
>> > In passing I also tried brglm which solves the separation problem
>> > but tells me comparison is significant which I don't believe one
>> > bit (see the data below). I am pretty sure about this because when
>> > I reveled and look at the comparisons I was able to compute using
>> > glmer, these turn out to be non-significant, when glmer told me
>> > they were:
>> >
>> >> trial<-brglm(Correct ~ Syntax.Semantics, data = trialglm, family
>> >> =
>> > binomial) Warning messages: 1: package ?elrm? was built under R
>> > version 3.1.2 2: package ?coda? was built under R version 3.1.3
>> >> summary(trial)
>> >
>> > Call: brglm(formula = Correct ~ Syntax.Semantics, family =
>> > binomial, data = trialglm)
>> >
>> >
>> > Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> > -1.6358     0.4035  -4.053 5.05e-05 *** Syntax.Semantics A   0.6689
>> > 0.5169   1.294   0.1957 Syntax.Semantics B  -3.0182     1.4902
>> > -2.025   0.0428 * Syntax.Semantics C  -1.0135     0.6889  -1.471
>> > 0.1413 Syntax.Semantics D   0.1515     0.5571   0.272   0.7857
>> > Syntax.Semantics E  -0.7878     0.6937  -1.136   0.2561
>> > Syntax.Semantics F  -1.2874     0.7702  -1.672   0.0946 .
>> > Syntax.Semantics G   0.4358     0.5186   0.840   0.4007 --- Signif.
>> > codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > (Dispersion parameter for binomial family taken to be 1)
>> >
>> > Null deviance: 262.51  on 384  degrees of freedom Residual
>> > deviance: 256.22  on 377  degrees of freedom Penalized deviance:
>> > 245.5554 AIC:  272.22
>> >
>> >
>> > MCMCglmm is too complex for me.
>> >
>> > Wolfgang, I tried the penalized likelihood method (logistf
>> > function) but output is hard to read:
>> >
>> >> trial<-logistf(Correct ~ Syntax.Semantics, data = trialglm,
>> >> family =
>> > binomial) Warning messages: 1: package ?logistf? was built under R
>> > version 3.1.2 2: package ?mice? was built under R version 3.1.2
>> >> summary(trial)
>> > logistf(formula = Correct ~ Syntax.Semantics, data = trialglm,
>> > family = binomial)
>> >
>> > Model fitted by Penalized ML Confidence intervals and p-values by
>> > Profile Likelihood Profile Likelihood Profile Likelihood Profile
>> > Likelihood Profile Likelihood Profile Likelihood Profile Likelihood
>> > Profile Likelihood
>> >
>> > coef  se(coef) lower 0.95 upper 0.95 Chisq            p (Intercept)
>> > 3.2094017 0.7724482  2.9648747  3.5127830 0.000000 1.000000e+00
>> > Syntax.Semantics A  4.1767737 6.3254344  0.4224696 12.0673987
>> > 64.224452 1.110223e-15 Syntax.Semantics B -1.0583602 0.8959376
>> > -1.3963977 -0.7625216  0.000000 1.000000e+00 Syntax.Semantics C
>> > -0.7299070 0.9308193 -1.0765598 -0.4180076  0.000000 1.000000e+00
>> > Syntax.Semantics D  0.2314740 1.1563731 -0.1704535  0.6479908
>> > 1.156512 2.821901e-01 Syntax.Semantics E -0.6476907 0.9771824
>> > -1.0076740 -0.3164066  0.000000 1.000000e+00 Syntax.Semantics F
>> > -0.8271499 0.9305931 -1.1743834 -0.5160799  0.000000 1.000000e+00
>> > Syntax.Semantics G  0.9909046 1.3787175  0.5457741  1.5353981
>> > 0.000000 1.000000e+00
>> >
>> > Likelihood ratio test=121.9841 on 7 df, p=0, n=385 Wald test =
>> > 5.334321 on 7 df, p = 0.6192356
>> >
>> > In particular, what is this model telling me? That Z (my ref level)
>> > and B are significantly different?
>> >
>> > I'm happy to try the elrm function with exact logistic regression
>> > but I am not capable of programming it. Besides, would it give me
>> > valid estimates for the comparison between the Z and B levels? The
>> > data frame should look like this:
>> >
>> > Outcome variable (Correct, incorrect) Predictor variable (A, B, C,
>> > D, E, F, G, Z) Counts (E: 38,3; B: 51,0; Z: 37,7; G: 40,12; D:
>> > 36,8; C:45,3; A: 34,13; F:65,22).
>> >
>> > Thank you! F.
>> >
>> > On Thu, May 28, 2015 at 2:28 AM, Ben Bolker <bbolker at gmail.com>
>> > wrote:
>> >
>> >> And for what it's worth, you can do this in conjunction with lme4
>> >> by using the blme package instead (a thin Bayesian wrapper around
>> >> lme4), or via the MCMCglmm package; see
>> >> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
>> >> for an example (search for "complete separation").
>> >>
>> >> On Wed, May 27, 2015 at 5:21 PM, Viechtbauer Wolfgang (STAT)
>> >> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >>> You may need to consider using an 'exact', Bayesian, or
>> >>> penalized
>> >> likelihood approach (along the lines proposed by Firth).
>> >>>
>> >>> Maybe a place to start:
>> >>
>> >> http://sas-and-r.blogspot.nl/2010/11/example-815-firth-logistic-regression.html
>> >>>
>> >>>
>> >>
>> Best,
>> >>> Wolfgang
>> >>>
>> >>>> -----Original Message----- From: R-sig-mixed-models
>> >>>> [mailto:r-sig-mixed-models-bounces at r- project.org] On Behalf
>> >>>> Of Francesco Romano Sent: Wednesday, May 27, 2015 23:00 To:
>> >>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Zero
>> >>>> cells in contrast matrix problem
>> >>>>
>> >>>> After giving up on a glmer for my data, I remembered a post
>> >>>> by Roger
>> >> Levy
>> >>>> suggesting to try the use non mixed effects glm when one of
>> >>>> the cells in a matrix is zero.
>> >>>>
>> >>>> To put this into perspective:
>> >>>>
>> >>>>> trial<-glmer(Correct ~ Syntax.Semantics + (1 | Part.name),
>> >>>>> data =
>> >>>> trialglm, family = binomial)
>> >>>>
>> >>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>> >>>> opt$par, ctrl = control$checkConv, : Model failed to converge
>> >>>> with max|grad| = 0.053657 (tol = 0.001, component 4) 2: In
>> >>>> checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> >>>> control$checkConv, : Model is nearly unidentifiable: large
>> >>>> eigenvalue ratio - Rescale variables?
>> >>>>
>> >>>> My data has a binary outcome, correct or incorrect, a fixed
>> >>>> effect predictor factor with 8 levels, and a random effect
>> >>>> for participants. I believe the problem R is encountering is
>> >>>> with one level of the factor (let us call it level B) which
>> >>>> has no counts (no I won' t try to post the table from the
>> >>>> paper with the counts because I know it will get garbled
>> >>>> up!).
>> >>>>
>> >>>> I attempt a glm with the same data:
>> >>>>
>> >>>>> trial<-glm(Correct ~ Syntax.Semantics, data = trialglm,
>> >>>>> family =
>> >>>> binomial)
>> >>>>> anova(trial)
>> >>>> Analysis of Deviance Table
>> >>>>
>> >>>> Model: binomial, link: logit
>> >>>>
>> >>>> Response: Correct
>> >>>>
>> >>>> Terms added sequentially (first to last)
>> >>>>
>> >>>>
>> >>>> Df Deviance Resid. Df Resid. Dev NULL
>> >>>> 384     289.63 Syntax.Semantics  7   34.651       377
>> >>>> 254.97
>> >>>>> summary(trial)
>> >>>>
>> >>>> Call: glm(formula = Correct ~ Syntax.Semantics, family =
>> >>>> binomial, data = trialglm)
>> >>>>
>> >>>> Deviance Residuals: Min        1Q    Median        3Q
>> >>>> Max -0.79480  -0.62569  -0.34474  -0.00013   2.52113
>> >>>>
>> >>>> Coefficients: Estimate Std. Error z value Pr(>|z|)
>> >>>> (Intercept)                 -1.6917     0.4113  -4.113
>> >>>> 3.91e-05 *** Syntax.Semantics A   0.7013     0.5241   1.338
>> >>>> 0.1809 Syntax.Semantics B -16.8744   904.5273  -0.019
>> >>>> 0.9851 Syntax.Semantics C  -1.1015     0.7231  -1.523
>> >>>> 0.1277 Syntax.Semantics D   0.1602     0.5667   0.283
>> >>>> 0.7774 Syntax.Semantics E  -0.8733     0.7267  -1.202
>> >>>> 0.2295 Syntax.Semantics F  -1.4438     0.8312  -1.737
>> >>>> 0.0824 . Syntax.Semantics G   0.4630     0.5262   0.880
>> >>>> 0.3789 --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>> >>>> ?.? 0.1 ? ? 1
>> >>>>
>> >>>> (Dispersion parameter for binomial family taken to be 1)
>> >>>>
>> >>>> Null deviance: 289.63  on 384  degrees of freedom Residual
>> >>>> deviance: 254.98  on 377  degrees of freedom AIC: 270.98
>> >>>>
>> >>>> Number of Fisher Scoring iterations: 17
>> >>>>
>> >>>> The comparison I'm interested in is between level B and the
>> >>>> reference level but it cannot be estimated as shown by the
>> >>>> ridiculously high estimate and SE value.
>> >>>>
>> >>>> Any suggestions on how to get a decent beta, SE, z, and p?
>> >>>> It's the only comparison missing in the table for the levels
>> >>>> I need so I think it
>> >> would
>> >>>> be a bit unacademic of me to close this deal saying 'the
>> >>>> difference
>> >> could
>> >>>> not be estimated due to zero count'.
>> >>>>
>> >>>> And by the way I have seen this comparison being generated
>> >>>> using other stats.
>> >>>>
>> >>>> Thanks in advance,
>> >>>>
>> >>>> Frank
>> >>>>
>> >>>> [[alternative HTML version deleted]]
>> >>>>
>> >>>> _______________________________________________
>> >>>> R-sig-mixed-models at r-project.org mailing list
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.4.11 (GNU/Linux)
>>
>> iQEcBAEBAgAGBQJVZ2DeAAoJEOCV5YRblxUH9f0IAN/LTzJllxXqmdP4U2bbDNOR
>> XnjYDsQ+cF6eR6aRMxWK1nj7Lgdi1pvqOU/3CSMVke2HW2Cr07wR2VDtqHwWRAgZ
>> jTlzlJ/iA5o32T1U2Wm9jrle0E0RpTMrA8SZ8HsGVKT3cD/5TNo9eoPAw3DV45AO
>> hmwUJf0NYLhZwOJ2QAsk1rAn06CBmrVSXFUmdGKpODELFJ4whAn95phE8pLY+aW9
>> qfO4Rq4FcZt1wdRwlZmk8woEeqeySb+rBRxZCVQ0HuyoEGONHMq5Wa1hnffwVR3V
>> yiIo1Vtd7sTbxAs96DeP8AItyHTvgsKRJphEK/PYguDQCGeR70sQEL53FTdHM60=
>> =3UD2
>> -----END PGP SIGNATURE-----
>
>


From alberto.gc8 at gmail.com  Thu May 28 03:29:41 2015
From: alberto.gc8 at gmail.com (Alberto Gallano)
Date: Wed, 27 May 2015 21:29:41 -0400
Subject: [R-sig-ME] MCMCglmm predictions with new data,
 marginalized with respect to random effects
Message-ID: <CAO+b4j_nXM46UZ-Jmp9PUW2=mYqsabVE07b-WYPPiqqKthFYow@mail.gmail.com>

I'm trying to calculate predictions for new data (with confidence
intervals) that are marginalized with respect to the random effects. I've
been able to get part of the way there thanks to the suggestions of Ben
Bolker in this post:

http://stackoverflow.com/questions/21057548/how-can-one-simulate-quantities-of-interest-from-the-posterior-density-in-mcmcgl


I have two questions:


1) how can I marginalize with respect to the random effects when using new
data?

(In other words, how should the information in the "temp" variable below be
incorporated into the "pred_frame" object?. Here, "temp" is a vector of
length 212 (106 random effects for each random term in the model formula -
I have 106 species in the dataset). Pages 46-47 of the course notes suggest
that the variance components should be summed (sigma^2) and then added to
the linear predictor to get the expectation of the outcome variable, but
I'm not sure how to do this with new data. Do I need to add the random
effects to the "pred_frame" object?)


2) how can I calculate confidence intervals (or standard errors) for the
predictions?

(ideally while marginalizing with respect to the random effects, but if
that's not possible, just using the fixed effects).



#--------------------------------------------------------------------
prior1 <- list(
    B = list(mu = rep(0, 5), V = diag(1e+08, 5)),
    G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000),
             G2 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
    R = list(V = 1, nu = 0.002)
)

set.seed(1234)
fit1 <- MCMCglmm(
    fixed = I1 ~ I2.species.mean + I2.within.species +
body.mass.species.mean + body.mass.within.species,
    random = ~ phylo + species,
    rcov = ~ units,
    data = incisor.dat,
    family = "gaussian",
    ginverse = list(phylo = inv_phylo_mat$Ainv),
    prior = prior1,
    pr = TRUE,
    pl = TRUE,
    nitt = 1.1e+7, thin = 2000, burnin = 5e+5,
    verbose = FALSE
    )

# prediction data frame
pred_frame <- expand.grid(
    I2.species.mean = seq(5, 12, by = 0.05),
    I2.within.species = mean(incisor.dat$I2.within.species),
    body.mass.species.mean = seq(1000, 5000, by = 100),
    body.mass.within.species = mean(incisor.dat$body.mass.within.species)
    )

# fixed effects design matrix
X <- model.matrix(~ I2.species.mean + I2.within.species +
                    body.mass.species.mean + body.mass.within.species,
                    data = pred_frame)

# multiply the fixed effects design matrix (X) by the chains of
coefficients
# stored in the Sol ("solution") component of the MCMCglmm object
pred_frame$I1 <- X %*% t(fit1$Sol[, colnames(X)])

# random effects design matrix (with intercept suppressed)
Z <- model.matrix(~ phylo + taxon - 1, data = incisor.dat)

# multiply the random effects design matrix (Z) by the $Liab component
(posterior distributions of latent variables)
# (note: set pl = TRUE when running the model to get it to save the latent
effects)
temp <- colMeans(fit1$Liab %*% Z)
sigma2 <- sum(temp)
#--------------------------------------------------------------------


best,
Alberto

	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Sat May 30 23:17:52 2015
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Sat, 30 May 2015 21:17:52 +0000
Subject: [R-sig-ME] MCMCglmm predictions with new data,
 marginalized with respect to random effects
Message-ID: <51F0C7C54B032A42A23B74A088E7141C440F9AF3@itsnt443.iowa.uiowa.edu>

You can streamline the process you describe somewhat using the lsmeans package; For your example, it'd be something like:

# -----------------------------------------
  library(lsmeans)

  fit1.rg <- ref.grid(fit1, 
    at = list(I2.species.mean = seq(5, 12, by = 0.05),
      body.mass.species.mean = seq(1000, 5000, by = 100)),
    data = incisor.dat)

  # frequentist summary -averages and SEs based on sample of fixed effects
  summary(fit1.rg)

  # posterior sample of predictions at each point in the grid
  #   for further analysis using the coda package
  #   (this will be too much, but could be useful for a coarser grid)
  fit1.mcmc <- as.mcmc(fit1.rg)

#--------------------------------------------

Note in the ref.grid call, it was not necessary to specify the value of I2.within.species or body.mass.within.species, because the mean will be used by default. See ?ref.grid, ?"lsmeans-package", and ?models for more information.

This does not address the part about incorporating the latent temp effects. Perhaps some others' answers could provide insights. 
Russ

PS - is the incisor.dat dataset publicly available somewhere?

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017



-----Original Message-----

Date: Wed, 27 May 2015 21:29:41 -0400
From: Alberto Gallano <alberto.gc8 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] MCMCglmm predictions with new data, marginalized
	with respect to random effects


I'm trying to calculate predictions for new data (with confidence
intervals) that are marginalized with respect to the random effects. I've
been able to get part of the way there thanks to the suggestions of Ben
Bolker in this post:

http://stackoverflow.com/questions/21057548/how-can-one-simulate-quantities-of-interest-from-the-posterior-density-in-mcmcgl


I have two questions:


1) how can I marginalize with respect to the random effects when using new
data?

(In other words, how should the information in the "temp" variable below be
incorporated into the "pred_frame" object?. Here, "temp" is a vector of
length 212 (106 random effects for each random term in the model formula -
I have 106 species in the dataset). Pages 46-47 of the course notes suggest
that the variance components should be summed (sigma^2) and then added to
the linear predictor to get the expectation of the outcome variable, but
I'm not sure how to do this with new data. Do I need to add the random
effects to the "pred_frame" object?)


2) how can I calculate confidence intervals (or standard errors) for the
predictions?

(ideally while marginalizing with respect to the random effects, but if
that's not possible, just using the fixed effects).



#--------------------------------------------------------------------
prior1 <- list(
    B = list(mu = rep(0, 5), V = diag(1e+08, 5)),
    G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000),
             G2 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
    R = list(V = 1, nu = 0.002)
)

set.seed(1234)
fit1 <- MCMCglmm(
    fixed = I1 ~ I2.species.mean + I2.within.species +
body.mass.species.mean + body.mass.within.species,
    random = ~ phylo + species,
    rcov = ~ units,
    data = incisor.dat,
    family = "gaussian",
    ginverse = list(phylo = inv_phylo_mat$Ainv),
    prior = prior1,
    pr = TRUE,
    pl = TRUE,
    nitt = 1.1e+7, thin = 2000, burnin = 5e+5,
    verbose = FALSE
    )

# prediction data frame
pred_frame <- expand.grid(
    I2.species.mean = seq(5, 12, by = 0.05),
    I2.within.species = mean(incisor.dat$I2.within.species),
    body.mass.species.mean = seq(1000, 5000, by = 100),
    body.mass.within.species = mean(incisor.dat$body.mass.within.species)
    )

# fixed effects design matrix
X <- model.matrix(~ I2.species.mean + I2.within.species +
                    body.mass.species.mean + body.mass.within.species,
                    data = pred_frame)

# multiply the fixed effects design matrix (X) by the chains of
coefficients
# stored in the Sol ("solution") component of the MCMCglmm object
pred_frame$I1 <- X %*% t(fit1$Sol[, colnames(X)])

# random effects design matrix (with intercept suppressed)
Z <- model.matrix(~ phylo + taxon - 1, data = incisor.dat)

# multiply the random effects design matrix (Z) by the $Liab component
(posterior distributions of latent variables)
# (note: set pl = TRUE when running the model to get it to save the latent
effects)
temp <- colMeans(fit1$Liab %*% Z)
sigma2 <- sum(temp)
#--------------------------------------------------------------------


best,
Alberto


From M.Fairbrother at bristol.ac.uk  Sun May 31 19:59:05 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 31 May 2015 19:59:05 +0200
Subject: [R-sig-ME] MCMCglmm predictions with new data,
 marginalized with respect to random effects
Message-ID: <CAAH-yP9hFNr18V2o3tGHQuqQdB2gJTLyKEmTA+LTZv0ypg8zPw@mail.gmail.com>

Dear Alberto,
If you haven't hit on them already, these two earlier threads may also be
useful to you (both conversations where Jarrod, author of MCMCglmm, helped
me out):
http://permalink.gmane.org/gmane.comp.lang.r.lme4.devel/11709
http://permalink.gmane.org/gmane.comp.lang.r.lme4.devel/9424
Your case is in some respects simpler, since as I understand it your
outcome is Normal--though you have some other model elements which (I'm not
sure) may complicate things.
Hope that's useful,
Malcolm





> Date: Sat, 30 May 2015 21:17:52 +0000
> From: "Lenth, Russell V" <russell-lenth at uiowa.edu>
> To: Alberto Gallano <alberto.gc8 at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] MCMCglmm predictions with new data,
>         marginalized with respect to random effects
>
> You can streamline the process you describe somewhat using the lsmeans
> package; For your example, it'd be something like:
>
> # -----------------------------------------
>   library(lsmeans)
>
>   fit1.rg <- ref.grid(fit1,
>     at = list(I2.species.mean = seq(5, 12, by = 0.05),
>       body.mass.species.mean = seq(1000, 5000, by = 100)),
>     data = incisor.dat)
>
>   # frequentist summary -averages and SEs based on sample of fixed effects
>   summary(fit1.rg)
>
>   # posterior sample of predictions at each point in the grid
>   #   for further analysis using the coda package
>   #   (this will be too much, but could be useful for a coarser grid)
>   fit1.mcmc <- as.mcmc(fit1.rg)
>
> #--------------------------------------------
>
> Note in the ref.grid call, it was not necessary to specify the value of
> I2.within.species or body.mass.within.species, because the mean will be
> used by default. See ?ref.grid, ?"lsmeans-package", and ?models for more
> information.
>
> This does not address the part about incorporating the latent temp
> effects. Perhaps some others' answers could provide insights.
> Russ
>
> PS - is the incisor.dat dataset publicly available somewhere?
>
> Russell V. Lenth  -  Professor Emeritus
> Department of Statistics and Actuarial Science
> The University of Iowa  -  Iowa City, IA 52242  USA
> Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
>
>
>
> -----Original Message-----
>
> Date: Wed, 27 May 2015 21:29:41 -0400
> From: Alberto Gallano <alberto.gc8 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] MCMCglmm predictions with new data, marginalized
>         with respect to random effects
>
>
> I'm trying to calculate predictions for new data (with confidence
> intervals) that are marginalized with respect to the random effects. I've
> been able to get part of the way there thanks to the suggestions of Ben
> Bolker in this post:
>
>
> http://stackoverflow.com/questions/21057548/how-can-one-simulate-quantities-of-interest-from-the-posterior-density-in-mcmcgl
>
>
> I have two questions:
>
>
> 1) how can I marginalize with respect to the random effects when using new
> data?
>
> (In other words, how should the information in the "temp" variable below be
> incorporated into the "pred_frame" object?. Here, "temp" is a vector of
> length 212 (106 random effects for each random term in the model formula -
> I have 106 species in the dataset). Pages 46-47 of the course notes suggest
> that the variance components should be summed (sigma^2) and then added to
> the linear predictor to get the expectation of the outcome variable, but
> I'm not sure how to do this with new data. Do I need to add the random
> effects to the "pred_frame" object?)
>
>
> 2) how can I calculate confidence intervals (or standard errors) for the
> predictions?
>
> (ideally while marginalizing with respect to the random effects, but if
> that's not possible, just using the fixed effects).
>
>
>
> #--------------------------------------------------------------------
> prior1 <- list(
>     B = list(mu = rep(0, 5), V = diag(1e+08, 5)),
>     G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000),
>              G2 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
>     R = list(V = 1, nu = 0.002)
> )
>
> set.seed(1234)
> fit1 <- MCMCglmm(
>     fixed = I1 ~ I2.species.mean + I2.within.species +
> body.mass.species.mean + body.mass.within.species,
>     random = ~ phylo + species,
>     rcov = ~ units,
>     data = incisor.dat,
>     family = "gaussian",
>     ginverse = list(phylo = inv_phylo_mat$Ainv),
>     prior = prior1,
>     pr = TRUE,
>     pl = TRUE,
>     nitt = 1.1e+7, thin = 2000, burnin = 5e+5,
>     verbose = FALSE
>     )
>
> # prediction data frame
> pred_frame <- expand.grid(
>     I2.species.mean = seq(5, 12, by = 0.05),
>     I2.within.species = mean(incisor.dat$I2.within.species),
>     body.mass.species.mean = seq(1000, 5000, by = 100),
>     body.mass.within.species = mean(incisor.dat$body.mass.within.species)
>     )
>
> # fixed effects design matrix
> X <- model.matrix(~ I2.species.mean + I2.within.species +
>                     body.mass.species.mean + body.mass.within.species,
>                     data = pred_frame)
>
> # multiply the fixed effects design matrix (X) by the chains of
> coefficients
> # stored in the Sol ("solution") component of the MCMCglmm object
> pred_frame$I1 <- X %*% t(fit1$Sol[, colnames(X)])
>
> # random effects design matrix (with intercept suppressed)
> Z <- model.matrix(~ phylo + taxon - 1, data = incisor.dat)
>
> # multiply the random effects design matrix (Z) by the $Liab component
> (posterior distributions of latent variables)
> # (note: set pl = TRUE when running the model to get it to save the latent
> effects)
> temp <- colMeans(fit1$Liab %*% Z)
> sigma2 <- sum(temp)
> #--------------------------------------------------------------------
>
>
> best,
> Alberto
>
>

	[[alternative HTML version deleted]]


From Lotte.Schoot at mpi.nl  Mon Jun  1 16:56:22 2015
From: Lotte.Schoot at mpi.nl (Lotte Schoot)
Date: Mon, 01 Jun 2015 16:56:22 +0200
Subject: [R-sig-ME] interactions lmer continuous and categorical fixed factor
Message-ID: <556C7296.1000307@mpi.nl>

Hi,

I am using the lmer function in lme4 to test a model like this:

DV ~ factor1 * factor2 (simplified for purposes of illustration, so 
without random effects structure)

DV = continuous (Reaction time)
factor1 = continuous
factor2 = categorical (3 levels)

summary(model) will give me output like this:

factor2-level1 * Factor1 = xxx
factor2-level2 * Factor1 = xxx
factor2-level3 * Factor1 = xxx

If I try to get p-values for this model, however, I only get one p-value 
for the interaction factor2 * factor 1.

What do you recommend to report in this case?
p-values with corresponding F-values and df, or the t-values found in 
summary(model), without any p-values?

Thanks in advance,
Lotte


From thierry.onkelinx at inbo.be  Mon Jun  1 17:18:52 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 1 Jun 2015 17:18:52 +0200
Subject: [R-sig-ME] interactions lmer continuous and categorical fixed
	factor
In-Reply-To: <556C7296.1000307@mpi.nl>
References: <556C7296.1000307@mpi.nl>
Message-ID: <CAJuCY5xOOmVzg0Wb7nNRNz0X6FO3ppyq7Oo7R1WJ4YpXVnAE+A@mail.gmail.com>

Dear Lotte,

I assume that the "one p-value for the interaction" is the p-value from
anova(model). Note that this tests a different hypothesis than the
hypothesis than summary(model) tests (without reporting p-values).

IMHO, p-values of parameters estimates are not that relevant. Confidence
intervals of those parameter estimates are much more relevant. I'd rather
report those.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-01 16:56 GMT+02:00 Lotte Schoot <Lotte.Schoot at mpi.nl>:

> Hi,
>
> I am using the lmer function in lme4 to test a model like this:
>
> DV ~ factor1 * factor2 (simplified for purposes of illustration, so
> without random effects structure)
>
> DV = continuous (Reaction time)
> factor1 = continuous
> factor2 = categorical (3 levels)
>
> summary(model) will give me output like this:
>
> factor2-level1 * Factor1 = xxx
> factor2-level2 * Factor1 = xxx
> factor2-level3 * Factor1 = xxx
>
> If I try to get p-values for this model, however, I only get one p-value
> for the interaction factor2 * factor 1.
>
> What do you recommend to report in this case?
> p-values with corresponding F-values and df, or the t-values found in
> summary(model), without any p-values?
>
> Thanks in advance,
> Lotte
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jun  1 17:31:05 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 01 Jun 2015 11:31:05 -0400
Subject: [R-sig-ME] interactions lmer continuous and categorical fixed
 factor
In-Reply-To: <CAJuCY5xOOmVzg0Wb7nNRNz0X6FO3ppyq7Oo7R1WJ4YpXVnAE+A@mail.gmail.com>
References: <556C7296.1000307@mpi.nl>
	<CAJuCY5xOOmVzg0Wb7nNRNz0X6FO3ppyq7Oo7R1WJ4YpXVnAE+A@mail.gmail.com>
Message-ID: <556C7AB9.9070505@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-06-01 11:18 AM, Thierry Onkelinx wrote:
> Dear Lotte,
> 
> I assume that the "one p-value for the interaction" is the p-value
> from anova(model). Note that this tests a different hypothesis than
> the hypothesis than summary(model) tests (without reporting
> p-values).
> 
> IMHO, p-values of parameters estimates are not that relevant.
> Confidence intervals of those parameter estimates are much more
> relevant. I'd rather report those.
> 
> Best regards,
> 
> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> Research Institute for Nature and Forest team Biometrie &
> Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat
> 25 1070 Anderlecht Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may
> be able to say what the experiment died of. ~ Sir Ronald Aylmer
> Fisher The plural of anecdote is not data. ~ Roger Brinner The
> combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given
> body of data. ~ John Tukey

  To follow up, I would say that
* you probably *should* be reporting just the p-value for the overall
test of the interaction (i.e. the one returned by anova()).
* if you really want the p-values of the individual parameters, look
at ?pvalues and specifically try the lmerTest package.
* if you're going to start looking at tests for lots of different
levels you might want to consider multiple-comparisons corrections,
see e.g.
http://stats.stackexchange.com/questions/5250/multiple-comparisons-on-a-mixed-effects-model

> 
> 2015-06-01 16:56 GMT+02:00 Lotte Schoot <Lotte.Schoot at mpi.nl>:
> 
>> Hi,
>> 
>> I am using the lmer function in lme4 to test a model like this:
>> 
>> DV ~ factor1 * factor2 (simplified for purposes of illustration,
>> so without random effects structure)
>> 
>> DV = continuous (Reaction time) factor1 = continuous factor2 =
>> categorical (3 levels)
>> 
>> summary(model) will give me output like this:
>> 
>> factor2-level1 * Factor1 = xxx factor2-level2 * Factor1 = xxx 
>> factor2-level3 * Factor1 = xxx
>> 
>> If I try to get p-values for this model, however, I only get one
>> p-value for the interaction factor2 * factor 1.
>> 
>> What do you recommend to report in this case? p-values with
>> corresponding F-values and df, or the t-values found in 
>> summary(model), without any p-values?
>> 
>> Thanks in advance, Lotte
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVbHq5AAoJEOCV5YRblxUHYrsIAMORxFwdNAJziLg8VODipKKl
IsAJl/jB7YEX93ec04stEqc4/z8QJ8Aj/tXq8szP67+iunrGKUteeSOoIlclc1yE
DfXJPk0OvsFc4OlsX6xeVya5tUebliVYC/xX97H2XSgwI+iiiXZ24t3BJVpZk1ZD
+rsjPY9+lzCmgH/NnuYZjlxhdrY5PJTkG5eRNRNAiGw9taq+atxGFHVr4mcf0e5I
0x3hGIy1iE2f9x2WFz85RpVOdfjTKFgf5pXeQr5LD+57ixfyR5JWRnyAbDhDSkvn
XtatAOHhhESaGlV47xDTzBnn11mUuqtChSa0x4KGktz1yEgBYLxKs3VArJ1k12Q=
=1BtA
-----END PGP SIGNATURE-----


From firespot71 at gmail.com  Wed Jun  3 17:40:56 2015
From: firespot71 at gmail.com (Thomas M)
Date: Wed, 03 Jun 2015 17:40:56 +0200
Subject: [R-sig-ME] proportion data based on finite population size
Message-ID: <556F2008.2060807@gmail.com>

Hi,

I need to fit a mixed model for the following data situation:
A number of locations have been sampled for (plant) species. Species 
were classified as either belonging to category A or B (strictly 
binary), where, roughly speaking, A represents 'was previously there', 
and B represents 'arrived recently'. For each location the total number 
of species per category is recorded, and the main question is how 
several predictor variables influence the proprotions. A mixed model is 
used due to pronounced spatial clustering of sampled locations. Species 
numbers in both A and B range from very low to relatively high.
Colleagues have suggested a plain binomial GLMM, with the number of 
species in A and B comprising the two response-matrix columns. My 
concern here is that I don't really see underlying independent Bernoulli 
trials which gave rise to the data. At each location the total number of 
species occurring is quasi an a priori fixed, finite value, and only 
then species become grouped into the two categories. I.e. for a given 
location I cannot take a hypothetical new species and evaluate that for 
belonging to A or B (as new Bernoulli trial). In practice I suppose that 
fitting such data by a Binomial-GLMM will artificially inflate the df, 
and I wouldn't be surprised to see pronounced overdispersion. Do you 
agree with these concerns?
If so, now on to possible solutions:
Is there some finite-sample-size, or otherwise appropriate correction 
available to GLMMs?
For a new random draw I'd have to sample a new location. So a candidate 
response could be calculating A / A + B per site (and thus one df per 
site - very conservative given that A or B may actually be quite large). 
For a GLM given the lack of a Beta-distributed response a 
quasi-likelihood fit might do it, but what would be the approach 
(options / function / package) for a mixed model? Transforming the 
response ratio and using a normally distributed response might not do 
it, I am afraid.
I am also thinking of using a Poisson-GLMM with say B as response, and 
log(A) as offset variable on the right-hand side. It accounts for the 
count data nature yet relating A and B (the latter of which makes sense 
biologically speaking in this case, as - ignoring the effects of other 
covariates - A and B should be well correlated).

thanks !


From timothy.gregoire at yale.edu  Thu Jun  4 13:50:38 2015
From: timothy.gregoire at yale.edu (Gregoire, Timothy)
Date: Thu, 4 Jun 2015 11:50:38 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 102, Issue 3
In-Reply-To: <mailman.1.1433412001.28475.r-sig-mixed-models@r-project.org>
References: <mailman.1.1433412001.28475.r-sig-mixed-models@r-project.org>
Message-ID: <8A2DF497F2B80E4B9BE3662392CD10D8085A09D8@X10-MBX9.yu.yale.edu>

Thomas,

I am puzzled by your statement "given the lack of a Beta-distributed response", because it seems to me that a beta regression indeed would be apt.

I have a biblio on the topic of beta regression; email me at timothy.gregoire at yale.edu, and I will send biblio pdf.

Tim

Timothy G. Gregoire
J. P. Weyerhaeuser Professor of Forest Management
School of Forestry & Environmental Studies
Yale University
360 Prospect St, New Haven, CT, U.S.A. 06511
Ph: 1.203.432.9398 mob: 1.203.508.4014? fax:1.203.432.3809


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: Thursday, June 04, 2015 6:00 AM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 102, Issue 3

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=AwICAg&c=-dg2m7zWuuDZ0MUcV7Sdqw&r=atRKEKX5W2zm-GsIgYzLo4oYM9D-Qn-eMFObHZtnEnI&m=RGd06U8u4MdvZEkteCZNX_WVArGqiQbSzapl8wHeyRY&s=1b9ldcHSeN3j_PWCf7E7p6a3ujKcnSym_A1NNC8JLKs&e=
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. proportion data based on finite population size (Thomas M)


----------------------------------------------------------------------

Message: 1
Date: Wed, 03 Jun 2015 17:40:56 +0200
From: Thomas M <firespot71 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] proportion data based on finite population size
Message-ID: <556F2008.2060807 at gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed

Hi,

I need to fit a mixed model for the following data situation:
A number of locations have been sampled for (plant) species. Species were classified as either belonging to category A or B (strictly binary), where, roughly speaking, A represents 'was previously there', and B represents 'arrived recently'. For each location the total number of species per category is recorded, and the main question is how several predictor variables influence the proprotions. A mixed model is used due to pronounced spatial clustering of sampled locations. Species numbers in both A and B range from very low to relatively high.
Colleagues have suggested a plain binomial GLMM, with the number of species in A and B comprising the two response-matrix columns. My concern here is that I don't really see underlying independent Bernoulli trials which gave rise to the data. At each location the total number of species occurring is quasi an a priori fixed, finite value, and only then species become grouped into the two categories. I.e. for a given location I cannot take a hypothetical new species and evaluate that for belonging to A or B (as new Bernoulli trial). In practice I suppose that fitting such data by a Binomial-GLMM will artificially inflate the df, and I wouldn't be surprised to see pronounced overdispersion. Do you agree with these concerns?
If so, now on to possible solutions:
Is there some finite-sample-size, or otherwise appropriate correction available to GLMMs?
For a new random draw I'd have to sample a new location. So a candidate response could be calculating A / A + B per site (and thus one df per site - very conservative given that A or B may actually be quite large). 
For a GLM given the lack of a Beta-distributed response a quasi-likelihood fit might do it, but what would be the approach (options / function / package) for a mixed model? Transforming the response ratio and using a normally distributed response might not do it, I am afraid.
I am also thinking of using a Poisson-GLMM with say B as response, and
log(A) as offset variable on the right-hand side. It accounts for the count data nature yet relating A and B (the latter of which makes sense biologically speaking in this case, as - ignoring the effects of other covariates - A and B should be well correlated).

thanks !



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=AwICAg&c=-dg2m7zWuuDZ0MUcV7Sdqw&r=atRKEKX5W2zm-GsIgYzLo4oYM9D-Qn-eMFObHZtnEnI&m=RGd06U8u4MdvZEkteCZNX_WVArGqiQbSzapl8wHeyRY&s=1b9ldcHSeN3j_PWCf7E7p6a3ujKcnSym_A1NNC8JLKs&e= 


------------------------------

End of R-sig-mixed-models Digest, Vol 102, Issue 3


From chirleu at gmail.com  Thu Jun  4 16:34:55 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 4 Jun 2015 16:34:55 +0200
Subject: [R-sig-ME] error when including correlation=corAR1 in a gamm model
Message-ID: <CALC46t80D=iw1JNUVZaC9kHwzhGLTFM6N4fk1mKst4ZQbrgfwA@mail.gmail.com>

Dear all.

I'm running a gamm model. From previous tests in lme, I know that a
correlation structure is needed, in this case I'm trying to use a corAR1
(the one I used in my tests in lme).

My model is as follows:

gamm1=gamm(hdb~year+area+s(week2,bs="cc",k=4),random=list(fish=~1),correlation=corAR1(form=~tim),
weights=varIdent(form=~1|year),data=horiw3, method="REML")

And I get this error:

Error in chol.default(V$V[[i]]) :
  the leading minor of order 11 is not positive definite

When I remove the correlation term, the model runs ok. In lme (in which
week2 is passed as a polynom of order 3), the model runs ok as well.

I have left the data in this link in case you want to test it by yourselves:

https://www.dropbox.com/s/ifpcfmlq09i2z3w/data.csv?dl=0

Thank you

David

	[[alternative HTML version deleted]]


From bkellman at eng.ucsd.edu  Fri Jun  5 01:05:23 2015
From: bkellman at eng.ucsd.edu (Benjamin Kellman)
Date: Thu, 4 Jun 2015 16:05:23 -0700
Subject: [R-sig-ME] Binomial Temporal GAMM does not converge (R::mgcv)
Message-ID: <CALbF_B7mS71bQxubpZ0av8p_Bs1dALyJGuUHHAOd_ZgL1AeuGA@mail.gmail.com>

Hello R sig,

I'm new to mixed effect models and I would really appreciate some help.
I've posted by question on cross validated:

http://stats.stackexchange.com/questions/155524/binomial-temporal-gamm-does-not-converge-rmgcv

If any of you would care to weigh in, it would be greatly appreciated.

Thank you

-- 
Benjamin P. Kellman

PhD Student
Bioinformatics and Systems Biology
UC, San Diego

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Sat Jun  6 02:59:44 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 6 Jun 2015 10:59:44 +1000
Subject: [R-sig-ME] Binomial Temporal GAMM does not converge (R::mgcv)
In-Reply-To: <CALbF_B7mS71bQxubpZ0av8p_Bs1dALyJGuUHHAOd_ZgL1AeuGA@mail.gmail.com>
References: <CALbF_B7mS71bQxubpZ0av8p_Bs1dALyJGuUHHAOd_ZgL1AeuGA@mail.gmail.com>
Message-ID: <CAF5_5cwUQ8um8pvJ5fPdOFNWt6gr3c0En=uPkq5cph0KGOLrPw@mail.gmail.com>

First rule of statistics is start with the simplest reasonable model and
then try to build something more complex if it is necessary.

I would start with a standard mixed effects with random effects for
intercept and slope, judging from what you have already. This can be done
in lmer, you will probably need to set the nAGQ value to something greater
than 1, increase it until nothing seems to change. This is due to the high
variance for the intercept random effect, and is probably causing the
problem with your other analysis, as it uses PQL which just won't work well
in this case.

Then look at residuals versus fitted values, with a lowess curve as they
will be very noisy, and see if you need something more complex.  If so a
regression spline is easiest using ns() and a small number of knots.

Ken

On 5 June 2015 at 09:05, Benjamin Kellman <bkellman at eng.ucsd.edu> wrote:

> Hello R sig,
>
> I'm new to mixed effect models and I would really appreciate some help.
> I've posted by question on cross validated:
>
>
> http://stats.stackexchange.com/questions/155524/binomial-temporal-gamm-does-not-converge-rmgcv
>
> If any of you would care to weigh in, it would be greatly appreciated.
>
> Thank you
>
> --
> Benjamin P. Kellman
>
> PhD Student
> Bioinformatics and Systems Biology
> UC, San Diego
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From hans.ekbrand at gmail.com  Mon Jun  8 15:07:52 2015
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Mon, 8 Jun 2015 15:07:52 +0200
Subject: [R-sig-ME] help with the logistic formula using nlme/nlmer
Message-ID: <20150608130752.GA7347@hans>

Dear list,

I model the effect of child labour on the childs probability of being
in school. The data comes from 22 countries. Countries have different
means on the outcome variable, ie. the probability is in school is to
a large part determined on in which country the child resides. The
sample includes only children aged 7-14 years.

Child labour is a numerical covariate measured in hours, being in
school is binary variable, age is a numerical covariate, measured in
years.

Data is available here: http://hansekbrand.se/code/cl.df.RData

> str(cl.df)
'data.frame':	345321 obs. of  8 variables:
 $ country           : Factor w/ 23 levels "Armenia","Burkina Faso",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ areaID            : Factor w/ 14584 levels "Armenia.1","Armenia.10",..: 3 3 3 3 3 3 2 2 2 2 ...
 $ school            : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2 ...
 $ age               : num  9 10 8 11 14 10 12 10 14 12 ...
 $ total.hours.worked: num  1 1 1 0 1 0 0 0 0 0 ...
 $ Chorehours        : num  1 1 1 0 1 0 0 0 0 0 ...
 $ Chwkhours         : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Chothwkhours      : num  0 0 0 0 0 0 0 0 0 0 ...

The distribution of child labour, which is indicated by the variable
total.hours.worked, has a positive skew.

> quantile(cl.df$total.hours.worked, probs = seq(from = 0, to = 1, by = 0.1))
  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% 
   0    0    0    0    3    5    7   10   14   28  133 

I have manually defined classes for this variable, 

library(car)
cl.df$hours.class <- recode(cl.df$total.hours.worked, recodes = ("lo:7=1;
 7:14=2; 14:21=3; 21:28=4; 28:35=5; 35:42=6; 42:49=7; 49:56=8; 56:63=9;
 63:hi='more than ten'"), as.factor.result=TRUE)

and used them like this:

fm1 <- glmer(school ~ age + hours.class + (1|country) + (1|areaID), data = cl.df, family = binomial)

this works, but I would prefer to fit a non-linear regression with a
polynomal form instead. I think a simple exponential function would
work.

E.g.

fm1 <- glmer(school ~ age + I(total.hours.worked^2) + (1|country) + (1|areaID), data = cl.df, family = binomial)

However, I *think* nlmer() could be used to find the optimal number
instead of "2" here. But I don't know how to do that. I have searched
the archive, but found rather few posts concerning nlmer(), so any
help is much appreciated.

If you can solve the problem with nlme() or anything else for that
matter, that's perfectly fine, I'm used to lme4, but I'm happy to
learn new stuff.


From thierry.onkelinx at inbo.be  Mon Jun  8 15:37:45 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 8 Jun 2015 15:37:45 +0200
Subject: [R-sig-ME] help with the logistic formula using nlme/nlmer
In-Reply-To: <20150608130752.GA7347@hans>
References: <20150608130752.GA7347@hans>
Message-ID: <CAJuCY5xq38TMUUhHU0DiDOxBfHDVx=ZMNaZCdL9qFf8DS6NGeg@mail.gmail.com>

Dear Hans,

I'd rather use a gamm with a penalized regression spline for
total.hours.worked with a small basis for the smoother (k = 3 of k = 4).

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-08 15:07 GMT+02:00 Hans Ekbrand <hans.ekbrand at gmail.com>:

> Dear list,
>
> I model the effect of child labour on the childs probability of being
> in school. The data comes from 22 countries. Countries have different
> means on the outcome variable, ie. the probability is in school is to
> a large part determined on in which country the child resides. The
> sample includes only children aged 7-14 years.
>
> Child labour is a numerical covariate measured in hours, being in
> school is binary variable, age is a numerical covariate, measured in
> years.
>
> Data is available here: http://hansekbrand.se/code/cl.df.RData
>
> > str(cl.df)
> 'data.frame':   345321 obs. of  8 variables:
>  $ country           : Factor w/ 23 levels "Armenia","Burkina Faso",..: 1
> 1 1 1 1 1 1 1 1 1 ...
>  $ areaID            : Factor w/ 14584 levels "Armenia.1","Armenia.10",..:
> 3 3 3 3 3 3 2 2 2 2 ...
>  $ school            : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
> ...
>  $ age               : num  9 10 8 11 14 10 12 10 14 12 ...
>  $ total.hours.worked: num  1 1 1 0 1 0 0 0 0 0 ...
>  $ Chorehours        : num  1 1 1 0 1 0 0 0 0 0 ...
>  $ Chwkhours         : num  0 0 0 0 0 0 0 0 0 0 ...
>  $ Chothwkhours      : num  0 0 0 0 0 0 0 0 0 0 ...
>
> The distribution of child labour, which is indicated by the variable
> total.hours.worked, has a positive skew.
>
> > quantile(cl.df$total.hours.worked, probs = seq(from = 0, to = 1, by =
> 0.1))
>   0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100%
>    0    0    0    0    3    5    7   10   14   28  133
>
> I have manually defined classes for this variable,
>
> library(car)
> cl.df$hours.class <- recode(cl.df$total.hours.worked, recodes = ("lo:7=1;
>  7:14=2; 14:21=3; 21:28=4; 28:35=5; 35:42=6; 42:49=7; 49:56=8; 56:63=9;
>  63:hi='more than ten'"), as.factor.result=TRUE)
>
> and used them like this:
>
> fm1 <- glmer(school ~ age + hours.class + (1|country) + (1|areaID), data =
> cl.df, family = binomial)
>
> this works, but I would prefer to fit a non-linear regression with a
> polynomal form instead. I think a simple exponential function would
> work.
>
> E.g.
>
> fm1 <- glmer(school ~ age + I(total.hours.worked^2) + (1|country) +
> (1|areaID), data = cl.df, family = binomial)
>
> However, I *think* nlmer() could be used to find the optimal number
> instead of "2" here. But I don't know how to do that. I have searched
> the archive, but found rather few posts concerning nlmer(), so any
> help is much appreciated.
>
> If you can solve the problem with nlme() or anything else for that
> matter, that's perfectly fine, I'm used to lme4, but I'm happy to
> learn new stuff.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Mon Jun  8 15:49:42 2015
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Mon, 8 Jun 2015 13:49:42 +0000
Subject: [R-sig-ME] help with the logistic formula using nlme/nlmer
In-Reply-To: <CAJuCY5xq38TMUUhHU0DiDOxBfHDVx=ZMNaZCdL9qFf8DS6NGeg@mail.gmail.com>
References: <20150608130752.GA7347@hans>
	<CAJuCY5xq38TMUUhHU0DiDOxBfHDVx=ZMNaZCdL9qFf8DS6NGeg@mail.gmail.com>
Message-ID: <1433771381.13988.2.camel@thorkell>

See for example the gamm4 package (which hooks into and extends the lme4
formula syntax). Instead of I(...), you would have s(...)

Best,

Phillip Alday

On Mon, 2015-06-08 at 15:37 +0200, Thierry Onkelinx wrote:
> Dear Hans,
> 
> I'd rather use a gamm with a penalized regression spline for
> total.hours.worked with a small basis for the smoother (k = 3 of k = 4).
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2015-06-08 15:07 GMT+02:00 Hans Ekbrand <hans.ekbrand at gmail.com>:
> 
> > Dear list,
> >
> > I model the effect of child labour on the childs probability of being
> > in school. The data comes from 22 countries. Countries have different
> > means on the outcome variable, ie. the probability is in school is to
> > a large part determined on in which country the child resides. The
> > sample includes only children aged 7-14 years.
> >
> > Child labour is a numerical covariate measured in hours, being in
> > school is binary variable, age is a numerical covariate, measured in
> > years.
> >
> > Data is available here: http://hansekbrand.se/code/cl.df.RData
> >
> > > str(cl.df)
> > 'data.frame':   345321 obs. of  8 variables:
> >  $ country           : Factor w/ 23 levels "Armenia","Burkina Faso",..: 1
> > 1 1 1 1 1 1 1 1 1 ...
> >  $ areaID            : Factor w/ 14584 levels "Armenia.1","Armenia.10",..:
> > 3 3 3 3 3 3 2 2 2 2 ...
> >  $ school            : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
> > ...
> >  $ age               : num  9 10 8 11 14 10 12 10 14 12 ...
> >  $ total.hours.worked: num  1 1 1 0 1 0 0 0 0 0 ...
> >  $ Chorehours        : num  1 1 1 0 1 0 0 0 0 0 ...
> >  $ Chwkhours         : num  0 0 0 0 0 0 0 0 0 0 ...
> >  $ Chothwkhours      : num  0 0 0 0 0 0 0 0 0 0 ...
> >
> > The distribution of child labour, which is indicated by the variable
> > total.hours.worked, has a positive skew.
> >
> > > quantile(cl.df$total.hours.worked, probs = seq(from = 0, to = 1, by =
> > 0.1))
> >   0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100%
> >    0    0    0    0    3    5    7   10   14   28  133
> >
> > I have manually defined classes for this variable,
> >
> > library(car)
> > cl.df$hours.class <- recode(cl.df$total.hours.worked, recodes = ("lo:7=1;
> >  7:14=2; 14:21=3; 21:28=4; 28:35=5; 35:42=6; 42:49=7; 49:56=8; 56:63=9;
> >  63:hi='more than ten'"), as.factor.result=TRUE)
> >
> > and used them like this:
> >
> > fm1 <- glmer(school ~ age + hours.class + (1|country) + (1|areaID), data =
> > cl.df, family = binomial)
> >
> > this works, but I would prefer to fit a non-linear regression with a
> > polynomal form instead. I think a simple exponential function would
> > work.
> >
> > E.g.
> >
> > fm1 <- glmer(school ~ age + I(total.hours.worked^2) + (1|country) +
> > (1|areaID), data = cl.df, family = binomial)
> >
> > However, I *think* nlmer() could be used to find the optimal number
> > instead of "2" here. But I don't know how to do that. I have searched
> > the archive, but found rather few posts concerning nlmer(), so any
> > help is much appreciated.
> >
> > If you can solve the problem with nlme() or anything else for that
> > matter, that's perfectly fine, I'm used to lme4, but I'm happy to
> > learn new stuff.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From daf3366 at vet.k-state.edu  Mon Jun  8 17:23:43 2015
From: daf3366 at vet.k-state.edu (Daniel Frese)
Date: Mon, 8 Jun 2015 15:23:43 +0000
Subject: [R-sig-ME] Fwd: glme output
References: <CABghstTM_bwBNXHsQ8Qb4db+vdc++LcY7Yivyfg9mizQHivL8g@mail.gmail.com>
Message-ID: <EB9A351D-911D-4E02-B0EE-92C9D83A8DE0@vet.ksu.edu>



Begin forwarded message:

From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Subject: Re: glme output
Date: June 7, 2015 at 8:29:12 PM CDT
To: Daniel Frese <daf3366 at vet.k-state.edu<mailto:daf3366 at vet.k-state.edu>>

Could you please send this to r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>?

 thanks
  Ben Bolker


On Sun, Jun 7, 2015 at 11:40 AM, Daniel Frese <daf3366 at vet.k-state.edu<mailto:daf3366 at vet.k-state.edu>> wrote:
Dr. Bolker,

I am in the process of learning R, and converting over from SAS.

I have the following model and I am having a difficult time finding code
that will get me the lumens output of the model.  What I am looking for is
an equivalent command to the SAS code of  LSMEANS within the PROC GLIMMIX.

Model is the following

fm14bf<-glmer(I(Steps+1)~Treatment*BFStrata*treathour  + time hour +
(1|Block) + (0+treatdate|Steer), family=poisson,data=datahourly)

summary(fm14bf,ddf="Kenward-Roger")
qqnorm(resid(fm14bf),main="QQ Model 14")
plot(fm14bf,main="Residual Model 14")
hist(residuals(fm14bf))


How would I go about getting LSMEANS and differences output from R

Thanks

Dan

Daniel Frese DVM
Graduate Teaching Assistant
Beef Cattle Institute
College of Veterinary Medicine
Kansas State University





	[[alternative HTML version deleted]]


From gaiarrido at gmail.com  Mon Jun  8 10:07:11 2015
From: gaiarrido at gmail.com (Mario Garrido)
Date: Mon, 8 Jun 2015 11:07:11 +0300
Subject: [R-sig-ME] Compute a repeated measures model in lme4
Message-ID: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>

?Dear list,
I am interesting in introduce in the same model ?these following groups of
variables
treatment*daytype*time*age
age*activity
time*activity
treatment*daytype+activity

Is this the correct way to do it? or is redundant and I get spurious
results?
lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)

Thanks!

	[[alternative HTML version deleted]]


From tom_philippi at nps.gov  Mon Jun  8 19:53:03 2015
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Mon, 8 Jun 2015 10:53:03 -0700
Subject: [R-sig-ME] Compute a repeated measures model in lme4
In-Reply-To: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
References: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
Message-ID: <CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>

Mario--
Yes your formula is redundant.  It may or may not describe the model you
are interested in.
Look at the documentation for formula specification:
* as in
treatment*daytype*time*age
includes both the individual main effects and the interactions up to the
4-way interaction, so your other terms are already included.
: specifies an interaction.

If you only want main effects plus those 3 2-way interactions, you can use
something like:
lme.mean7<-lmer(averageba~ treatment+daytype+time+age+
                             age:activity+ time:activity+treatment:daytype+
                            (1|indiv), REML = FALSE)
Again, ?formula will help you with the syntax to specify the model you are
interested in.

Also, think hard about your random effect.  While there are some repeated
measures models where (1|individual) is appropriate, in many cases
(1+time|individual) or equivalently (time|individual) is more appropriate
and informative.

I hope that this helps get you pointed in the right direction.

Tom 2


On Mon, Jun 8, 2015 at 1:07 AM, Mario Garrido <gaiarrido at gmail.com> wrote:

> ?Dear list,
> I am interesting in introduce in the same model ?these following groups of
> variables
> treatment*daytype*time*age
> age*activity
> time*activity
> treatment*daytype+activity
>
> Is this the correct way to do it? or is redundant and I get spurious
> results?
> lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
> time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)
>
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From rmh3093 at gmail.com  Mon Jun  8 20:17:18 2015
From: rmh3093 at gmail.com (Ryan Hope)
Date: Mon, 8 Jun 2015 14:17:18 -0400
Subject: [R-sig-ME] Compute a repeated measures model in lme4
In-Reply-To: <CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
References: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
	<CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
Message-ID: <CAA5gU8n+XHwzTKbiK4eZOQrZRsaTUg8-1-Ts-GeM6KGrz3ZvJw@mail.gmail.com>

You could use anova() to actually compare the models with different
random effects terms to see if a more complicated model is justified.

On Mon, Jun 8, 2015 at 1:53 PM, Philippi, Tom <tom_philippi at nps.gov> wrote:
> Mario--
> Yes your formula is redundant.  It may or may not describe the model you
> are interested in.
> Look at the documentation for formula specification:
> * as in
> treatment*daytype*time*age
> includes both the individual main effects and the interactions up to the
> 4-way interaction, so your other terms are already included.
> : specifies an interaction.
>
> If you only want main effects plus those 3 2-way interactions, you can use
> something like:
> lme.mean7<-lmer(averageba~ treatment+daytype+time+age+
>                              age:activity+ time:activity+treatment:daytype+
>                             (1|indiv), REML = FALSE)
> Again, ?formula will help you with the syntax to specify the model you are
> interested in.
>
> Also, think hard about your random effect.  While there are some repeated
> measures models where (1|individual) is appropriate, in many cases
> (1+time|individual) or equivalently (time|individual) is more appropriate
> and informative.
>
> I hope that this helps get you pointed in the right direction.
>
> Tom 2
>
>
> On Mon, Jun 8, 2015 at 1:07 AM, Mario Garrido <gaiarrido at gmail.com> wrote:
>
>> Dear list,
>> I am interesting in introduce in the same model these following groups of
>> variables
>> treatment*daytype*time*age
>> age*activity
>> time*activity
>> treatment*daytype+activity
>>
>> Is this the correct way to do it? or is redundant and I get spurious
>> results?
>> lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
>> time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)
>>
>> Thanks!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Ryan Hope, M.S.
CogWorks Lab
Cognitive Science Department
Rensselaer Polytechnic Institute


From tom_philippi at nps.gov  Mon Jun  8 20:38:51 2015
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Mon, 8 Jun 2015 11:38:51 -0700
Subject: [R-sig-ME] Compute a repeated measures model in lme4
In-Reply-To: <CABi7Y8bF5jAXsLF9zz7VcSEZ3_FEOUj+7BtxtnOzwGqPmmnRAg@mail.gmail.com>
References: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
	<CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
	<CABi7Y8Z+fVcAL1vXQO+tvYM4BevWV4q-4aWxty0AV9Ef5k91bg@mail.gmail.com>
	<CABi7Y8bF5jAXsLF9zz7VcSEZ3_FEOUj+7BtxtnOzwGqPmmnRAg@mail.gmail.com>
Message-ID: <CAM9kYqhRoQX0fdFPdsf0XJA+_Jrk6+xJFvE1jjuCpGt4gfUsbQ@mail.gmail.com>

The draft R-sig-mixed FAQ has some guidance on testing random effects (and
LRT via anova are not recommended):
http://glmm.wikidot.com/faq

Be careful.  In my applications of repeated measures to ecological data,
one model or the other for random effects is justified by the structure of
the sampling or experiment, and by the question of interest, not by
parsimony.

Also, if your O2 measurements have cyclic/periodic responses to time of
day, at the least I urge you to spend quality time with papers or books,
such as Faraway's "Extending the linear model" or Wood's "Generalized
additive models" or perhaps one of Zuur's, to fully understand the
differences between treatments in the data that are estimated or tested by
different models.

Ecologically, you may be more interested in specific parameters about the
O2 consumption: integrated 24hr consumption, estimated peak consumption,
shifts in time of peak consumption, rate of ramping up of consumption (your
rate of change of O2 might be a ramping up or ramping down following some
exertion).

Tom 2

On Mon, Jun 8, 2015 at 11:18 AM, Mario Garrido <gaiarrido at gmail.com> wrote:

> sorry, I reply without finishing my comments.
> I am trying to compare the rate of change in O2 consumption in 2
> consecutive days after a treatment (some individuals are treated while
> others do not) days. This is my treatment variable.
> daytype variable got 2 levels. the day before treatment and the day after
> treatment
> age variable are either juveniles or adults and time is time of teh day,
> dark and night.
>
> As I comparing the O2 consumption between day before and after. Random
> effect should be  1|individual) or (1+time|individual)?
>
>
> I always got the doubt.
>
> thanks!
>
> 2015-06-08 21:12 GMT+03:00 Mario Garrido <gaiarrido at gmail.com>:
>
>> This is really very useful, also what you tell about the random effect. I
>> just wondering about it right now.
>>
>> Thanks very much. I will look at with detail and get back here if needed.
>>
>>
>>
>> 2015-06-08 20:53 GMT+03:00 Philippi, Tom <tom_philippi at nps.gov>:
>>
>>> Mario--
>>> Yes your formula is redundant.  It may or may not describe the model you
>>> are interested in.
>>> Look at the documentation for formula specification:
>>> * as in
>>> treatment*daytype*time*age
>>> includes both the individual main effects and the interactions up to the
>>> 4-way interaction, so your other terms are already included.
>>> : specifies an interaction.
>>>
>>> If you only want main effects plus those 3 2-way interactions, you can
>>> use something like:
>>> lme.mean7<-lmer(averageba~ treatment+daytype+time+age+
>>>                              age:activity+ time:activity+treatment:
>>> daytype+
>>>                             (1|indiv), REML = FALSE)
>>> Again, ?formula will help you with the syntax to specify the model you
>>> are interested in.
>>>
>>> Also, think hard about your random effect.  While there are some
>>> repeated measures models where (1|individual) is appropriate, in many cases
>>> (1+time|individual) or equivalently (time|individual) is more appropriate
>>> and informative.
>>>
>>> I hope that this helps get you pointed in the right direction.
>>>
>>> Tom 2
>>>
>>>
>>> On Mon, Jun 8, 2015 at 1:07 AM, Mario Garrido <gaiarrido at gmail.com>
>>> wrote:
>>>
>>>> ?Dear list,
>>>> I am interesting in introduce in the same model ?these following groups
>>>> of
>>>> variables
>>>> treatment*daytype*time*age
>>>> age*activity
>>>> time*activity
>>>> treatment*daytype+activity
>>>>
>>>> Is this the correct way to do it? or is redundant and I get spurious
>>>> results?
>>>> lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
>>>> time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)
>>>>
>>>> Thanks!
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From gaiarrido at gmail.com  Mon Jun  8 20:12:19 2015
From: gaiarrido at gmail.com (Mario Garrido)
Date: Mon, 8 Jun 2015 21:12:19 +0300
Subject: [R-sig-ME] Compute a repeated measures model in lme4
In-Reply-To: <CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
References: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
	<CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
Message-ID: <CABi7Y8Z+fVcAL1vXQO+tvYM4BevWV4q-4aWxty0AV9Ef5k91bg@mail.gmail.com>

This is really very useful, also what you tell about the random effect. I
just wondering about it right now.

Thanks very much. I will look at with detail and get back here if needed.



2015-06-08 20:53 GMT+03:00 Philippi, Tom <tom_philippi at nps.gov>:

> Mario--
> Yes your formula is redundant.  It may or may not describe the model you
> are interested in.
> Look at the documentation for formula specification:
> * as in
> treatment*daytype*time*age
> includes both the individual main effects and the interactions up to the
> 4-way interaction, so your other terms are already included.
> : specifies an interaction.
>
> If you only want main effects plus those 3 2-way interactions, you can use
> something like:
> lme.mean7<-lmer(averageba~ treatment+daytype+time+age+
>                              age:activity+ time:activity+treatment:
> daytype+
>                             (1|indiv), REML = FALSE)
> Again, ?formula will help you with the syntax to specify the model you are
> interested in.
>
> Also, think hard about your random effect.  While there are some repeated
> measures models where (1|individual) is appropriate, in many cases
> (1+time|individual) or equivalently (time|individual) is more appropriate
> and informative.
>
> I hope that this helps get you pointed in the right direction.
>
> Tom 2
>
>
> On Mon, Jun 8, 2015 at 1:07 AM, Mario Garrido <gaiarrido at gmail.com> wrote:
>
>> ?Dear list,
>> I am interesting in introduce in the same model ?these following groups of
>> variables
>> treatment*daytype*time*age
>> age*activity
>> time*activity
>> treatment*daytype+activity
>>
>> Is this the correct way to do it? or is redundant and I get spurious
>> results?
>> lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
>> time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)
>>
>> Thanks!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
>
>

	[[alternative HTML version deleted]]


From gaiarrido at gmail.com  Mon Jun  8 20:18:00 2015
From: gaiarrido at gmail.com (Mario Garrido)
Date: Mon, 8 Jun 2015 21:18:00 +0300
Subject: [R-sig-ME] Compute a repeated measures model in lme4
In-Reply-To: <CABi7Y8Z+fVcAL1vXQO+tvYM4BevWV4q-4aWxty0AV9Ef5k91bg@mail.gmail.com>
References: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
	<CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
	<CABi7Y8Z+fVcAL1vXQO+tvYM4BevWV4q-4aWxty0AV9Ef5k91bg@mail.gmail.com>
Message-ID: <CABi7Y8bF5jAXsLF9zz7VcSEZ3_FEOUj+7BtxtnOzwGqPmmnRAg@mail.gmail.com>

sorry, I reply without finishing my comments.
I am trying to compare the rate of change in O2 consumption in 2
consecutive days after a treatment (some individuals are treated while
others do not) days. This is my treatment variable.
daytype variable got 2 levels. the day before treatment and the day after
treatment
age variable are either juveniles or adults and time is time of teh day,
dark and night.

As I comparing the O2 consumption between day before and after. Random
effect should be  1|individual) or (1+time|individual)?


I always got the doubt.

thanks!

2015-06-08 21:12 GMT+03:00 Mario Garrido <gaiarrido at gmail.com>:

> This is really very useful, also what you tell about the random effect. I
> just wondering about it right now.
>
> Thanks very much. I will look at with detail and get back here if needed.
>
>
>
> 2015-06-08 20:53 GMT+03:00 Philippi, Tom <tom_philippi at nps.gov>:
>
>> Mario--
>> Yes your formula is redundant.  It may or may not describe the model you
>> are interested in.
>> Look at the documentation for formula specification:
>> * as in
>> treatment*daytype*time*age
>> includes both the individual main effects and the interactions up to the
>> 4-way interaction, so your other terms are already included.
>> : specifies an interaction.
>>
>> If you only want main effects plus those 3 2-way interactions, you can
>> use something like:
>> lme.mean7<-lmer(averageba~ treatment+daytype+time+age+
>>                              age:activity+ time:activity+treatment:
>> daytype+
>>                             (1|indiv), REML = FALSE)
>> Again, ?formula will help you with the syntax to specify the model you
>> are interested in.
>>
>> Also, think hard about your random effect.  While there are some repeated
>> measures models where (1|individual) is appropriate, in many cases
>> (1+time|individual) or equivalently (time|individual) is more appropriate
>> and informative.
>>
>> I hope that this helps get you pointed in the right direction.
>>
>> Tom 2
>>
>>
>> On Mon, Jun 8, 2015 at 1:07 AM, Mario Garrido <gaiarrido at gmail.com>
>> wrote:
>>
>>> ?Dear list,
>>> I am interesting in introduce in the same model ?these following groups
>>> of
>>> variables
>>> treatment*daytype*time*age
>>> age*activity
>>> time*activity
>>> treatment*daytype+activity
>>>
>>> Is this the correct way to do it? or is redundant and I get spurious
>>> results?
>>> lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
>>> time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)
>>>
>>> Thanks!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From gaiarrido at gmail.com  Mon Jun  8 20:41:30 2015
From: gaiarrido at gmail.com (Mario Garrido)
Date: Mon, 8 Jun 2015 21:41:30 +0300
Subject: [R-sig-ME] Compute a repeated measures model in lme4
In-Reply-To: <CAM9kYqhRoQX0fdFPdsf0XJA+_Jrk6+xJFvE1jjuCpGt4gfUsbQ@mail.gmail.com>
References: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
	<CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
	<CABi7Y8Z+fVcAL1vXQO+tvYM4BevWV4q-4aWxty0AV9Ef5k91bg@mail.gmail.com>
	<CABi7Y8bF5jAXsLF9zz7VcSEZ3_FEOUj+7BtxtnOzwGqPmmnRAg@mail.gmail.com>
	<CAM9kYqhRoQX0fdFPdsf0XJA+_Jrk6+xJFvE1jjuCpGt4gfUsbQ@mail.gmail.com>
Message-ID: <CABi7Y8btKOOp-JGXqCPk5z-ndyTNXngmDddFNifTmLtdZ1fU9A@mail.gmail.com>

What a complete review of my study! Thanks very much. I got open Zuur
(2007) in this moment.

Mario

2015-06-08 21:38 GMT+03:00 Philippi, Tom <tom_philippi at nps.gov>:

> The draft R-sig-mixed FAQ has some guidance on testing random effects (and
> LRT via anova are not recommended):
> http://glmm.wikidot.com/faq
>
> Be careful.  In my applications of repeated measures to ecological data,
> one model or the other for random effects is justified by the structure of
> the sampling or experiment, and by the question of interest, not by
> parsimony.
>
> Also, if your O2 measurements have cyclic/periodic responses to time of
> day, at the least I urge you to spend quality time with papers or books,
> such as Faraway's "Extending the linear model" or Wood's "Generalized
> additive models" or perhaps one of Zuur's, to fully understand the
> differences between treatments in the data that are estimated or tested by
> different models.
>
> Ecologically, you may be more interested in specific parameters about the
> O2 consumption: integrated 24hr consumption, estimated peak consumption,
> shifts in time of peak consumption, rate of ramping up of consumption (your
> rate of change of O2 might be a ramping up or ramping down following some
> exertion).
>
> Tom 2
>
> On Mon, Jun 8, 2015 at 11:18 AM, Mario Garrido <gaiarrido at gmail.com>
> wrote:
>
>> sorry, I reply without finishing my comments.
>> I am trying to compare the rate of change in O2 consumption in 2
>> consecutive days after a treatment (some individuals are treated while
>> others do not) days. This is my treatment variable.
>> daytype variable got 2 levels. the day before treatment and the day after
>> treatment
>> age variable are either juveniles or adults and time is time of teh day,
>> dark and night.
>>
>> As I comparing the O2 consumption between day before and after. Random
>> effect should be  1|individual) or (1+time|individual)?
>>
>>
>> I always got the doubt.
>>
>> thanks!
>>
>> 2015-06-08 21:12 GMT+03:00 Mario Garrido <gaiarrido at gmail.com>:
>>
>>> This is really very useful, also what you tell about the random effect.
>>> I just wondering about it right now.
>>>
>>> Thanks very much. I will look at with detail and get back here if needed.
>>>
>>>
>>>
>>> 2015-06-08 20:53 GMT+03:00 Philippi, Tom <tom_philippi at nps.gov>:
>>>
>>>> Mario--
>>>> Yes your formula is redundant.  It may or may not describe the model
>>>> you are interested in.
>>>> Look at the documentation for formula specification:
>>>> * as in
>>>> treatment*daytype*time*age
>>>> includes both the individual main effects and the interactions up to
>>>> the 4-way interaction, so your other terms are already included.
>>>> : specifies an interaction.
>>>>
>>>> If you only want main effects plus those 3 2-way interactions, you can
>>>> use something like:
>>>> lme.mean7<-lmer(averageba~ treatment+daytype+time+age+
>>>>                              age:activity+ time:activity+treatment:
>>>> daytype+
>>>>                             (1|indiv), REML = FALSE)
>>>> Again, ?formula will help you with the syntax to specify the model you
>>>> are interested in.
>>>>
>>>> Also, think hard about your random effect.  While there are some
>>>> repeated measures models where (1|individual) is appropriate, in many cases
>>>> (1+time|individual) or equivalently (time|individual) is more appropriate
>>>> and informative.
>>>>
>>>> I hope that this helps get you pointed in the right direction.
>>>>
>>>> Tom 2
>>>>
>>>>
>>>> On Mon, Jun 8, 2015 at 1:07 AM, Mario Garrido <gaiarrido at gmail.com>
>>>> wrote:
>>>>
>>>>> ?Dear list,
>>>>> I am interesting in introduce in the same model ?these following
>>>>> groups of
>>>>> variables
>>>>> treatment*daytype*time*age
>>>>> age*activity
>>>>> time*activity
>>>>> treatment*daytype+activity
>>>>>
>>>>> Is this the correct way to do it? or is redundant and I get spurious
>>>>> results?
>>>>> lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
>>>>> time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)
>>>>>
>>>>> Thanks!
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jun  8 21:43:48 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 08 Jun 2015 15:43:48 -0400
Subject: [R-sig-ME] Fwd: glme output
In-Reply-To: <EB9A351D-911D-4E02-B0EE-92C9D83A8DE0@vet.ksu.edu>
References: <CABghstTM_bwBNXHsQ8Qb4db+vdc++LcY7Yivyfg9mizQHivL8g@mail.gmail.com>
	<EB9A351D-911D-4E02-B0EE-92C9D83A8DE0@vet.ksu.edu>
Message-ID: <5575F074.2000808@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-06-08 11:23 AM, Daniel Frese wrote:
> 

  [snip]

> I am in the process of learning R, and converting over from SAS.
> 
> I have the following model and I am having a difficult time finding
> code that will get me the lumens output of the model.  What I am
> looking for is an equivalent command to the SAS code of  LSMEANS
> within the PROC GLIMMIX.
> 
> Model is the following
> 
> fm14bf<-glmer(I(Steps+1)~Treatment*BFStrata*treathour  + time hour
> + (1|Block) + (0+treatdate|Steer), family=poisson,data=datahourly)
> 
> summary(fm14bf,ddf="Kenward-Roger") qqnorm(resid(fm14bf),main="QQ
> Model 14") plot(fm14bf,main="Residual Model 14") 
> hist(residuals(fm14bf))
> 
> 
> How would I go about getting LSMEANS and differences output from R
> 
> Thanks
> 
> Dan
> 
> Daniel Frese DVM Graduate Teaching Assistant Beef Cattle Institute 
> College of Veterinary Medicine Kansas State University


I would suggest that you take a look at the 'lsmeans' and 'effects'
packages for R -- I'm pretty sure they can both handle glmer models.

Some further questions/suggestions about your model:

* I'm not sure that summary(...,ddf="Kenward-Roger") is going to
do anything at all for a glmer model -- presumably you are using
the lmerTest package, which augments the summary method in this
way, but relies on the pbkrtest package, which does *not* implement
K-R for GLMMs (Stroup 2014 says that despite the lack of theoretical
grounding K-R *does* seem to give reasonable results for GLMMs).

* why are you using Steps+1 as your response variable in a Poisson model?
That seems odd -- a Poisson model *should* be able to handle Steps==0
responses perfectly well.  (I think you can actually get away without
I() for a model _response_)

* do you have a good reason to suppress the intercept variation among
Steers, i.e. are the starting values for each Steer constrained to
be exactly identical?

* you might want to consider adding an observation-level random effect
to allow for overdispersion ...

- ----
Stroup, Walter W. ?Rethinking the Analysis of Non-Normal Data in Plant
and Soil Science.? Agronomy Journal 106 (2014):
1?17. doi:10.2134/agronj2013.0342.








-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVdfB0AAoJEOCV5YRblxUHkRYH/2iGN3ddo/Ji0X0Q7a4bqfLr
YmAH9kDCueqCYOcGoBF0GEkY+yOpAs0kxhDcpcfvCSwoKrAwUlUCL11f7RjOg7p6
NE5coZs78aEtjRUpSTWlVLveCgIYWKb9H6Zc6OsniVr105S/x1KFiGiz5mJKzGBS
LwxrKLnq522K8kOML9QfBoF0lfFXLHiYEBa2HovowETd1gMUzPXtshPBQRkwsywz
VHByJW+la1iL2Nb7cbDl6fU7eCD80V4dtkolNEXd9qV3T91UuaKRsI+Iz6n9/zJy
coO1KDXfo6Ev537UuN0FrZ0WbO0ybY1m9T8LVvFWeSacNUqbxfHpbzs/PIZ3F+I=
=IDIw
-----END PGP SIGNATURE-----


From hannah.hlx at gmail.com  Tue Jun  9 19:39:15 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 9 Jun 2015 13:39:15 -0400
Subject: [R-sig-ME] Warning message when using lmer function
Message-ID: <CAHLnndawPxKq9hXwf97H-6QuYUeMFCxOhbZ+aKP0=dvkUrcrww@mail.gmail.com>

I got the following warning message when using the lmer function.
Does anyone know what is the implication? Thanks!

Warning message:
In anova(model, ddf = "lme4") : bytecode version mismatch; using eval


From bbolker at gmail.com  Tue Jun  9 20:02:04 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 09 Jun 2015 14:02:04 -0400
Subject: [R-sig-ME] Warning message when using lmer function
In-Reply-To: <CAHLnndawPxKq9hXwf97H-6QuYUeMFCxOhbZ+aKP0=dvkUrcrww@mail.gmail.com>
References: <CAHLnndawPxKq9hXwf97H-6QuYUeMFCxOhbZ+aKP0=dvkUrcrww@mail.gmail.com>
Message-ID: <55772A1C.5040200@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-06-09 01:39 PM, li li wrote:
> I got the following warning message when using the lmer function. 
> Does anyone know what is the implication? Thanks!
> 
> Warning message: In anova(model, ddf = "lme4") : bytecode version
> mismatch; using eval
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Have you made sure that you've re-installed lme4 and lmerTest since
the last time you updated R?

https://stat.ethz.ch/pipermail/r-help/2011-November/294486.html
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVdyocAAoJEOCV5YRblxUHwxUIALbCBUh5RBrPpXWG6Hx6ErWV
NP9/vIq+XiP1yTbCHv7GPF+stySUJuE8KBZ9k7pYrHqmknmp/Os4fKMq+UO6TI/V
8AsYb1Qf3wTThHiJYukGMDYX+pmsRPpFq8qYaIcO4P4dJtqhX2AZmWazFrpIP4Ap
w0sb7Du7SBtccFZKq/ETsEyyVGWSM8txv6LigMCs5ZYWtAL4C6YUkDdmjM8l0OQz
H9w+IV5RIahyTu1dYbZRjaZ2ubapQej42MyZkwyBVSF/9UAyFkkaHijE8E/bD/so
BeE6QF+RbIm4JsUH2izsfVHgLI59FFnP7TxmbLSPmqHUvq2bcbforh+OQt1J+Ts=
=Ue3Y
-----END PGP SIGNATURE-----


From hannah.hlx at gmail.com  Tue Jun  9 21:57:34 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 9 Jun 2015 15:57:34 -0400
Subject: [R-sig-ME] Different random intercepts but same random slope for
	groups
Message-ID: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>

Hi all,
  I'd like to fit a random intercept and random slope model. In my
data, there are three groups. I want to have different random
intercept for each group but the same random slope effect for all
three groups. I used the following R command.
However, there seems to be some problem. Any suggestions?



mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
group3+time|lot), na.action=na.omit, data=alldata)

> summary(mod2)
Model is not identifiable...
summary from lme4 is returned
some computational error has occurred in lmerTest
Linear mixed model fit by REML ['merModLmerTest']
Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
    lot)
   Data: alldata

REML criterion at convergence: 807.9

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.0112 -0.3364  0.0425  0.2903  3.2017

Random effects:
 Groups   Name     Variance Std.Dev. Corr
 lot      group1   0.00000 0.000
          group2   86.20156 9.284      NaN
          group3 55.91479 7.478      NaN  0.06
          time      0.02855 0.169      NaN -0.99  0.10
 Residual          39.91968 6.318
Number of obs: 119, groups:  lot, 15

Fixed effects:
                            Estimate Std. Error t value
(Intercept)                 100.1566     2.5108   39.89
group  group2        -2.9707     3.7490   -0.79
group  group3           -0.0717     2.8144   -0.03
time                         -0.1346     0.1780   -0.76
group  group2 :time   0.1450     0.2939    0.49
group  group3:time        0.1663     0.2152    0.77

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.147314 (tol = 0.002, component 2)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 2 negative eigenvalues


From thierry.onkelinx at inbo.be  Tue Jun  9 22:49:27 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 9 Jun 2015 22:49:27 +0200
Subject: [R-sig-ME] [R] Different random intercepts but same random
	slope for groups
In-Reply-To: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
Message-ID: <CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>

Your model is too complex for the data. This gives you two options: a)
simplify the model and b) get more data.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:

> Hi all,
>   I'd like to fit a random intercept and random slope model. In my
> data, there are three groups. I want to have different random
> intercept for each group but the same random slope effect for all
> three groups. I used the following R command.
> However, there seems to be some problem. Any suggestions?
>
>
>
> mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
> group3+time|lot), na.action=na.omit, data=alldata)
>
> > summary(mod2)
> Model is not identifiable...
> summary from lme4 is returned
> some computational error has occurred in lmerTest
> Linear mixed model fit by REML ['merModLmerTest']
> Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
>     lot)
>    Data: alldata
>
> REML criterion at convergence: 807.9
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.0112 -0.3364  0.0425  0.2903  3.2017
>
> Random effects:
>  Groups   Name     Variance Std.Dev. Corr
>  lot      group1   0.00000 0.000
>           group2   86.20156 9.284      NaN
>           group3 55.91479 7.478      NaN  0.06
>           time      0.02855 0.169      NaN -0.99  0.10
>  Residual          39.91968 6.318
> Number of obs: 119, groups:  lot, 15
>
> Fixed effects:
>                             Estimate Std. Error t value
> (Intercept)                 100.1566     2.5108   39.89
> group  group2        -2.9707     3.7490   -0.79
> group  group3           -0.0717     2.8144   -0.03
> time                         -0.1346     0.1780   -0.76
> group  group2 :time   0.1450     0.2939    0.49
> group  group3:time        0.1663     0.2152    0.77
>
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.147314 (tol = 0.002,
> component 2)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 2 negative eigenvalues
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Jun 10 00:08:39 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 09 Jun 2015 18:08:39 -0400
Subject: [R-sig-ME] [R] Different random intercepts but same random
 slope for groups
In-Reply-To: <CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
Message-ID: <557763E7.2040906@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  I don't understand your model specification.  What do you mean,
precisely, by "a different random intercept for each group but the
same random slope effect for all three groups"?  That sounds a lot
like a random intercept model? Do you mean that you want to specify a
single random-effects *variance* among slopes for all lots (regardless
of group) but different among-lot intercept variances for each group?

  If group1, group2, group3 are numeric dummy variables, then

lmer(result  ~ group*time+(0+time|lot) + (group1|lot) + (group2|lot) +
(group3|lot), data=alldata)

might work.

  That said, Thierry may still be right.  You have 15 groups and are
trying to fit 3 separate intercept-variance parameters ...


On 15-06-09 04:49 PM, Thierry Onkelinx wrote:
> Your model is too complex for the data. This gives you two options:
> a) simplify the model and b) get more data.
> 
> Best regards,
> 
> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> Research Institute for Nature and Forest team Biometrie &
> Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat
> 25 1070 Anderlecht Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may
> be able to say what the experiment died of. ~ Sir Ronald Aylmer
> Fisher The plural of anecdote is not data. ~ Roger Brinner The
> combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given
> body of data. ~ John Tukey
> 
> 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
> 
>> Hi all, I'd like to fit a random intercept and random slope
>> model. In my data, there are three groups. I want to have
>> different random intercept for each group but the same random
>> slope effect for all three groups. I used the following R
>> command. However, there seems to be some problem. Any
>> suggestions?
>> 
>> 
>> 
>> mod2 <- lmer(result  ~ group*time+(0+group1+ group2 + 
>> group3+time|lot), na.action=na.omit, data=alldata)
>> 
>>> summary(mod2)
>> Model is not identifiable... summary from lme4 is returned some
>> computational error has occurred in lmerTest Linear mixed model
>> fit by REML ['merModLmerTest'] Formula: result ~ group * time +
>> (0 + group1 + group2 + group3 + time | lot) Data: alldata
>> 
>> REML criterion at convergence: 807.9
>> 
>> Scaled residuals: Min      1Q  Median      3Q     Max -3.0112
>> -0.3364  0.0425  0.2903  3.2017
>> 
>> Random effects: Groups   Name     Variance Std.Dev. Corr lot
>> group1   0.00000 0.000 group2   86.20156 9.284      NaN group3
>> 55.91479 7.478      NaN  0.06 time      0.02855 0.169      NaN
>> -0.99  0.10 Residual          39.91968 6.318 Number of obs: 119,
>> groups:  lot, 15
>> 
>> Fixed effects: Estimate Std. Error t value (Intercept)
>> 100.1566     2.5108   39.89 group  group2        -2.9707
>> 3.7490   -0.79 group  group3           -0.0717     2.8144
>> -0.03 time                         -0.1346     0.1780   -0.76 
>> group  group2 :time   0.1450     0.2939    0.49 group
>> group3:time        0.1663     0.2152    0.77
>> 
>> Warning messages: 1: In checkConv(attr(opt, "derivs"), opt$par,
>> ctrl = control$checkConv,  : Model failed to converge with
>> max|grad| = 0.147314 (tol = 0.002, component 2) 2: In
>> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> : Model failed to converge: degenerate  Hessian with 2 negative
>> eigenvalues
>> 
>> ______________________________________________ 
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>> the posting guide http://www.R-project.org/posting-guide.html and
>> provide commented, minimal, self-contained, reproducible code.
>> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVd2PnAAoJEOCV5YRblxUHmRoH/22AjJ5RyFl3YEOeJ4/YerMf
byc8etuVyjX/QpB5VG5XidwdaLCb9tf98SttwR9iWKeYUB6sm+UEtPhzmhNuQVSS
O1aL8XgiTuoK0kNy1W8h7ZJovbaTeEl1FLy2sQ3ma5sRMvxfG30FZXI99NgvdLZf
qhClz3egICgwa7sz4DiT/UwPjvbgY993ZEKhjiWpzu2Zgy6HPVo1GrT/OKEqJwdD
4gczHoAOMkGdc38c+br1AmgPK1Me+Gc/OoZ2gQwniSTpTN0lrluvs3l6Y20/zVjD
0CmvQ+hSKkpPLWRENWGMwBlNpzINXMc+OXcE+LIqaxTuCWFOu9uh78ZjyD8EaHA=
=9aTo
-----END PGP SIGNATURE-----


From ken.beath at mq.edu.au  Wed Jun 10 01:10:56 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 10 Jun 2015 09:10:56 +1000
Subject: [R-sig-ME] [R] Different random intercepts but same random
 slope for groups
In-Reply-To: <557763E7.2040906@gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
	<557763E7.2040906@gmail.com>
Message-ID: <CAF5_5cxZeT0Gf-eeoe=vZXZU1Lv0=BB1Zsy8Cn7QcRi_-r=9bQ@mail.gmail.com>

Why not

mod2 <- lmer(result  ~ group*time+(1+time|lot), na.action=na.omit,
data=alldata)

This gives different slopes by group but same random effect variance for
all lots, which I think is what you actually want. A random intercept must
always be included with a random slope (there are probably exceptions but I
can't think of any).

On 10 June 2015 at 08:08, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>   I don't understand your model specification.  What do you mean,
> precisely, by "a different random intercept for each group but the
> same random slope effect for all three groups"?  That sounds a lot
> like a random intercept model? Do you mean that you want to specify a
> single random-effects *variance* among slopes for all lots (regardless
> of group) but different among-lot intercept variances for each group?
>
>   If group1, group2, group3 are numeric dummy variables, then
>
> lmer(result  ~ group*time+(0+time|lot) + (group1|lot) + (group2|lot) +
> (group3|lot), data=alldata)
>
> might work.
>
>   That said, Thierry may still be right.  You have 15 groups and are
> trying to fit 3 separate intercept-variance parameters ...
>
>
> On 15-06-09 04:49 PM, Thierry Onkelinx wrote:
> > Your model is too complex for the data. This gives you two options:
> > a) simplify the model and b) get more data.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> > Research Institute for Nature and Forest team Biometrie &
> > Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat
> > 25 1070 Anderlecht Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may
> > be able to say what the experiment died of. ~ Sir Ronald Aylmer
> > Fisher The plural of anecdote is not data. ~ Roger Brinner The
> > combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given
> > body of data. ~ John Tukey
> >
> > 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
> >
> >> Hi all, I'd like to fit a random intercept and random slope
> >> model. In my data, there are three groups. I want to have
> >> different random intercept for each group but the same random
> >> slope effect for all three groups. I used the following R
> >> command. However, there seems to be some problem. Any
> >> suggestions?
> >>
> >>
> >>
> >> mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
> >> group3+time|lot), na.action=na.omit, data=alldata)
> >>
> >>> summary(mod2)
> >> Model is not identifiable... summary from lme4 is returned some
> >> computational error has occurred in lmerTest Linear mixed model
> >> fit by REML ['merModLmerTest'] Formula: result ~ group * time +
> >> (0 + group1 + group2 + group3 + time | lot) Data: alldata
> >>
> >> REML criterion at convergence: 807.9
> >>
> >> Scaled residuals: Min      1Q  Median      3Q     Max -3.0112
> >> -0.3364  0.0425  0.2903  3.2017
> >>
> >> Random effects: Groups   Name     Variance Std.Dev. Corr lot
> >> group1   0.00000 0.000 group2   86.20156 9.284      NaN group3
> >> 55.91479 7.478      NaN  0.06 time      0.02855 0.169      NaN
> >> -0.99  0.10 Residual          39.91968 6.318 Number of obs: 119,
> >> groups:  lot, 15
> >>
> >> Fixed effects: Estimate Std. Error t value (Intercept)
> >> 100.1566     2.5108   39.89 group  group2        -2.9707
> >> 3.7490   -0.79 group  group3           -0.0717     2.8144
> >> -0.03 time                         -0.1346     0.1780   -0.76
> >> group  group2 :time   0.1450     0.2939    0.49 group
> >> group3:time        0.1663     0.2152    0.77
> >>
> >> Warning messages: 1: In checkConv(attr(opt, "derivs"), opt$par,
> >> ctrl = control$checkConv,  : Model failed to converge with
> >> max|grad| = 0.147314 (tol = 0.002, component 2) 2: In
> >> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> >> : Model failed to converge: degenerate  Hessian with 2 negative
> >> eigenvalues
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
> >> the posting guide http://www.R-project.org/posting-guide.html and
> >> provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVd2PnAAoJEOCV5YRblxUHmRoH/22AjJ5RyFl3YEOeJ4/YerMf
> byc8etuVyjX/QpB5VG5XidwdaLCb9tf98SttwR9iWKeYUB6sm+UEtPhzmhNuQVSS
> O1aL8XgiTuoK0kNy1W8h7ZJovbaTeEl1FLy2sQ3ma5sRMvxfG30FZXI99NgvdLZf
> qhClz3egICgwa7sz4DiT/UwPjvbgY993ZEKhjiWpzu2Zgy6HPVo1GrT/OKEqJwdD
> 4gczHoAOMkGdc38c+br1AmgPK1Me+Gc/OoZ2gQwniSTpTN0lrluvs3l6Y20/zVjD
> 0CmvQ+hSKkpPLWRENWGMwBlNpzINXMc+OXcE+LIqaxTuCWFOu9uh78ZjyD8EaHA=
> =9aTo
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From nouri4 at yahoo.com  Wed Jun 10 06:18:00 2015
From: nouri4 at yahoo.com (knouri)
Date: Wed, 10 Jun 2015 04:18:00 +0000 (UTC)
Subject: [R-sig-ME] Cross-over Data with Kenward-Roger correction
In-Reply-To: <360162227.8214165.1433730428235.JavaMail.yahoo@mail.yahoo.com>
References: <CA+vqiLEMkia_sjVm8KWxRB5sHZsN7PnLr03hOo1nFDvpgzj8Cw@mail.gmail.com>
	<360162227.8214165.1433730428235.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <180812510.9495.1433909880558.JavaMail.yahoo@mail.yahoo.com>

?Dear all:I have a SAS code but need to write it in R. Any advice will be greatly appreciated.
Here is the data ( a two-period) cross-over design comparing Trt 1 vs. Trt 2:

Sbj? Seq ?Per? Trt? PEF
1???? ?1?????? 1??? ?1?? 310
1???? ?1????? ?2???? 2?? 270
4???? ?1???? ? 1?????1?? 310
 4???? ?1???????2???? 2?? 260
6???? ?1?????? 1??? ?1?? 370
6???? ?1?????? 2??? ?2?? 300
7????? 1?????? 1??? ?1?? 410
7????? 1?????? 2???? 2?? 390
10??? 1?????? 1??? 1?? ?250
10??? 1?????? 2??? 2?? 210
11??? 1?????? 1?? ?1?? 380
11??? 1?????? 2??? 2?? 350
14??? 1?????? 1??? 1???330
14??? 1?????? 2??? 2?? 365
2????? 2?????? 1? ? 2?? 370
2????? 2?????? 2?? 1?? 385
3????? 2???? ?1??? 2?? 310
3???? ?2????? 2??? 1?? 400
5???? ?2????? 1??? 2?? 380
5????? 2????? 2??? 1?? 410
9????? 2???? ?1?? 2?? 290
9????? 2????? 2?? 1?? 320
12??? 2???? ?1?? 2?? 260
12??? 2???? ?2?? 1?? 340
13??? 2???? ?1?? 2??? 90
13??? 2???? ?2?? 1?? 220

Here is the SAS code:
#########################################################
proc mixed data=one method=reml;
class Sbj Per Trt;
model PEF = Per Trt /ddfm=kr;
repeated Trt / sub=Sbj type=un r;
lsmeans Trt / cl alpha=0.05;
estimate 'B vs. A' Trt -1? 1 / alpha=0.1 cl;
run;
###################################################
where kr option in model statement stands for "Kenward-Roger" correction.?The above SAS code produces (selected portions):

       
|  Covariance Parameter Estimates |
|  Cov Parm |  Subject |  Estimate |
|  UN(1,1) |  Sbj |  3567.58 |
|  UN(2,1) |  Sbj |  4437.00 |
|  UN(2,2) |  Sbj |  6760.65 |





| Type 3 Tests of Fixed Effects |
| Effect | Num DF | Den DF | F Value | Pr?>?F |
| Per | 1 | 11 | 2.59 | 0.1359 |
| Trt | 1 | 11.6 | 19.26 | 0.0010 |




     
|  Estimates |
|  Label |  Estimate |  Standard
 Error |  DF |  t?Value |  Pr > |t| |  Alpha |  Lower |  Upper |
|  B vs. A |  -46.5150 |  10.5999 |  11.6 |  -4.39 |  0.0010 |  0.1 |  -65.4629 |  -27.5671 |



      
|  Least Squares Means |
|  Effect |  Trt |  Estimate |  Standard
 Error |  DF |  t?Value |  Pr > |t| |  Alpha |  Lower |  Upper |
|  Trt |  1 |  341.72 |  16.5696 |  12 |  20.62 |  <.0001 |  0.05 |  305.62 |  377.82 |
|  Trt |  2 |  295.20 |  22.8073 |  12 |  12.94 |  <.0001 |  0.05 |  245.51 |  344.90 |






I used several R functions including lme, lmer. For example,? the following R code:
require(lme4)
require(pbkrtest)
require(lmerTest)
mydat$Trt = as.factor(mydat$Trt)
mydat$Per = as.factor(mydat$Per)fit.lmer <- lmer(PEF ~ Trt + Per + (1| Sbj), REML = TRUE, data=mydat)
anova(fit.lmer, ddf = "Kenward-Roger", type=3)( lsmeans(fit.lmer, test.effs="Trt") )
difflsmeans(fit.lmer, test.effs="Trt")

produces rather different results (compared to SAS), especially?for df's, standard errors, etc.
Analysis of Variance Table of type 3? with? Kenward-Roger approximation for degrees of freedom
?????? Sum Sq????? ?Mean Sq???? ? NumDF???? ? DenDF???? ?? F.value???? ? ?Pr(>F)?? 
Trt??? 14036???????? 14036?????????????? 1?????????????? ?11???????????? ?18.70???????? 0.0012 **
Per?? 1632?????????? 1632???????????????? 1??????????????? 11??????????????? 2.17???? ???? 0.1683?? 


Least Squares Means table:
??????? Trt??? Per??? Estimate??? Standard Error?? DF? ?t-value??? ?Lower CI Upper CI??????? p-value??? 
Trt? 1? 1.0? NA??? 341.8?????????? 20.0?????????????? 13.9??? 17.1????????? ?299????? 385??????????????? <2e-16 ***
Trt? 2? 2.0? NA??? 295.2?????????? 20.0?????????????? 13.9??? 14.8?????????? 252????? 338?????????????? ?<2e-16 ***

Differences of LSMEANS:
??????????????? Estimate????? Standard Error?? DF????? ?t-value???? ?Lower CI????? Upper CI???? p-value?? 
Trt 1 - 2???? 46.6?????????? 10.8??????????????????? 11.0??? 4.32????????????? 22.9??????????? 70.3?????????? 0.001 **


I am not quite sure if I am using the?right R functions. Any advice will be greatly appreciated,
Thanks again,
Keramat

? 
  
	[[alternative HTML version deleted]]


From lorenz.gygax at agroscope.admin.ch  Wed Jun 10 12:35:36 2015
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Wed, 10 Jun 2015 10:35:36 +0000
Subject: [R-sig-ME] PBmodcomp: pwrssUpdate does not converge with glmer
In-Reply-To: <000901d0a28f$9c667dd0$d5337970$@lorenzgygax.ch>
References: <000901d0a28f$9c667dd0$d5337970$@lorenzgygax.ch>
Message-ID: <7EC2E4DB4FC53A479711C3238C02EB83033E63@sb00111a.adb.intra.admin.ch>

Dear all,

In a current project (2 x 2 x 2 factorial design) we are interested in
calculating p-values for binary outcomes (we are aware that such an approach
is not unequivocal but circumstances are such that results will most easily
be communicated when we can conduct step-wise backwards model selection and
when we have the p-values).

The experimental design was hierarchically nested (350 observations
conducted in 178 phases of the experiment nested in 90 animal-IDs nested in
24 facilities). The three factors can and should be assigned to three
different hierarchical levels (error, phase, facility).

Even though the data does not look in any way extreme (zeros and ones occur
in all 8 factor combinations), there are some convergence issues with
running the models. These can be mostly dealt with by using: glmerControl
(optimizer= 'bobyqa', optCtrl= list (maxfun= 5000)).

Due to sample size and the assignment of the fixed effects to the different
hierarchical levels, we would like to use parametric bootstrap for
calculating the p-values as implemented in package pbkrtest (very nice!).

Obviously throughout calculating the bootstrap, some of the models will not
converge. As far as I can see, the bootstrap sample is simply accordingly
reduced. Some models, unfortunately, do not result in a warning but in an
error: "pwrssUpdate did not converge in (maxit) iterations with PBmodcomp".

These errors cause PBmodcomp to fail. Does anyone know whether there is a
reason why PBmodcomp reacts differently to warnings and erros in the
bootstrapped glmer's? Or has this just historically grown that the warnings
are captured but the errors are not? If the latter could catching errors be
easily incorporated as well? Where would that need to be done? I cannot find
the according code neither in pbkrtest::PBmodcomp.merMod nor in
pbkrtest::PBrefdist.merMod.

Many thanks for your ideas and best regards, Lorenz
-
Lorenz Gygax, PD Dr. sc. nat.
Federal Food Safety and Veterinary Office FFSVO
Centre for Proper Housing of Ruminants and Pigs


From bbolker at gmail.com  Wed Jun 10 13:52:17 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Jun 2015 07:52:17 -0400
Subject: [R-sig-ME] PBmodcomp: pwrssUpdate does not converge with glmer
In-Reply-To: <7EC2E4DB4FC53A479711C3238C02EB83033E63@sb00111a.adb.intra.admin.ch>
References: <000901d0a28f$9c667dd0$d5337970$@lorenzgygax.ch>
	<7EC2E4DB4FC53A479711C3238C02EB83033E63@sb00111a.adb.intra.admin.ch>
Message-ID: <CABghstSb8yLqqRbzO=q3=Q6YtLh-pE+V-zayao3xE=zpX687Sg@mail.gmail.com>

I'm not 100% sure, but a lot of this (at least the lme4 end, not
necessarily the pbkrtest end) sounds like the now-resolved (in the
development, soon-to-be-released version 1.1-8) issue
https://github.com/lme4/lme4/issues/231 .

On Wed, Jun 10, 2015 at 6:35 AM,  <lorenz.gygax at agroscope.admin.ch> wrote:
> Dear all,
>
> In a current project (2 x 2 x 2 factorial design) we are interested in
> calculating p-values for binary outcomes (we are aware that such an approach
> is not unequivocal but circumstances are such that results will most easily
> be communicated when we can conduct step-wise backwards model selection and
> when we have the p-values).
>
> The experimental design was hierarchically nested (350 observations
> conducted in 178 phases of the experiment nested in 90 animal-IDs nested in
> 24 facilities). The three factors can and should be assigned to three
> different hierarchical levels (error, phase, facility).
>
> Even though the data does not look in any way extreme (zeros and ones occur
> in all 8 factor combinations), there are some convergence issues with
> running the models. These can be mostly dealt with by using: glmerControl
> (optimizer= 'bobyqa', optCtrl= list (maxfun= 5000)).
>
> Due to sample size and the assignment of the fixed effects to the different
> hierarchical levels, we would like to use parametric bootstrap for
> calculating the p-values as implemented in package pbkrtest (very nice!).
>
> Obviously throughout calculating the bootstrap, some of the models will not
> converge. As far as I can see, the bootstrap sample is simply accordingly
> reduced. Some models, unfortunately, do not result in a warning but in an
> error: "pwrssUpdate did not converge in (maxit) iterations with PBmodcomp".
>
> These errors cause PBmodcomp to fail. Does anyone know whether there is a
> reason why PBmodcomp reacts differently to warnings and erros in the
> bootstrapped glmer's? Or has this just historically grown that the warnings
> are captured but the errors are not? If the latter could catching errors be
> easily incorporated as well? Where would that need to be done? I cannot find
> the according code neither in pbkrtest::PBmodcomp.merMod nor in
> pbkrtest::PBrefdist.merMod.
>
> Many thanks for your ideas and best regards, Lorenz
> -
> Lorenz Gygax, PD Dr. sc. nat.
> Federal Food Safety and Veterinary Office FFSVO
> Centre for Proper Housing of Ruminants and Pigs
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From alberto.gc8 at gmail.com  Wed Jun 10 16:58:28 2015
From: alberto.gc8 at gmail.com (Alberto Gallano)
Date: Wed, 10 Jun 2015 10:58:28 -0400
Subject: [R-sig-ME] MCMCglmm priors and random effects for phylogenetic
 mixed model
In-Reply-To: <20141226065015.124611gwbjfox0kg@www.staffmail.ed.ac.uk>
References: <CAO+b4j8ubheLUabLmvUXgHuHY8OvS4e3wKoN74w-6VsPqJq5Rw@mail.gmail.com>
	<20141226065015.124611gwbjfox0kg@www.staffmail.ed.ac.uk>
Message-ID: <CAO+b4j8G1BBtv-19ZJ=09p6R+kL4ca3NJPm8LPnFM1HYxYi4nA@mail.gmail.com>

Hi Jarrod,

this response was incredibly helpful. I decided ultimately that I didn't
need the random slopes in the model, which simplified things.

I have a follow-up question. I read the Phillimore et al. PNAS paper you
linked to with great interest. It seems in that paper you fitted a
multivariate (i.e., multiple response) mixed model as an alternative way
(from the van der Pol & Wright method) of decomposing between- and
within-species slopes (your Equation 4). The advantage, if I understand
correctly, is that the species-mean effect and individual-level deviations
from it are estimated, rather than calculated from the sample data. I'm
having a hard time figuring out how to alter the model I specified to fit
this framework (or if this is even possible).

My question is, how would I reconfigure the formula in this model to fit a
multivariate model that provides an estimate of the between species effect
(that's all i'm interested in)?

fit <- MCMCglmm(
    fixed = I1.M1 ~ I2.M1.species.mean + I2.M1.within.species,
    rcov = ~ units,
    random = ~ phylo + species,
    data = incisor.dat,
    family = "gaussian",
    ginverse = list(phylo = inv_phylo_mat$Ainv),
    prior = priors1,
    nitt = 1.1e+6, thin = 10, burnin = 1e+5
    )

Alberto


On Fri, Dec 26, 2014 at 1:50 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi Alberto,
>
> 1/ You can fit it at both levels if you like:
>
> us(1+I2.M1.within.species):phylo + us(1+I2.M1.within.species):species
>
> where the first term models between-species phylogentically correlated
> variation in intercepts and slopes  and the second term models
> between-species variation in intercepts and slopes that is not
> phylogenetically correlated. However, you have to be quite careful with the
> van der Pol & Wright method because measurement error in the species means
> (which will be high when n=3) can appear as random variation in slopes. The
> section "Within-Population Slope Heterogeneity" in this paper:
>
> http://www.pnas.org/content/107/18/8292.full
>
> discusses the problem, but unfortunately without a good resolution.
>
> 2/ I generally use parameter expanded priors of the form:
>
> G2 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V= diag(500,
> 2, 2))
>
> note V is an identity matrix rather than I*0.5. However, you should check
> to make sure you don't get big changes when you use other types of prior.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
>
>
> Quoting Alberto Gallano <alberto.gc8 at gmail.com> on Sun, 21 Dec 2014
> 17:59:09 -0500:
>
>  I have a question about prior and random effects specification for a
>> phylogenetic mixed model. I am fitting a linear mixed model using
>> MCMCglmm,
>> accounting for phylogenetic dependence in the residuals. My fixed effects
>> are two continuous variables (ratios of central and lateral incisor width
>> to first molar length) in various species of animals (n = 106). I have
>> measurements for multiple individuals within each species (ranging from
>> n=3
>> to n=110). I am mainly interested in the among-species slope and
>> intercept.
>> Therefore, I have used the methods outlined in (van der Pol & Wright,
>> 2009)
>> to split the explanatory variable into two: one with species means, the
>> other within-species centered. This disentangles effects for within- and
>> between species. For random effects, I am fitting random intercepts for
>> the
>> species level phylogenetic random effect (called "phylo"), random
>> intercepts for the species level non-phylogenetic random effect (called
>> "species"), and random slopes for the within-species centered variable.
>>
>> I have two questions:
>>
>> 1) I want to a model that allows random slopes to vary for each species,
>> but i'm not sure if I have this specified correctly? Also, should the
>> random slopes be coupled with the "species" or "phylo" random effect?
>>
>> 2) What is a good prior for the random slope / random intercept (here G2)?
>> I'm not sure whether this is specified correctly (e.g., should I used
>> parameter expanded priors)?
>>
>> Here are the priors and model:
>>
>> priors1 <- list(
>>     B = list(mu = rep(0, 3), V = diag(9, 3)),
>>     G = list(G1 = list(V = 1, nu = 0.002), G2 = list(V = diag(2)/2, nu =
>> 0.002)),
>>     R = list(V = 1, nu = 0.002)
>>     )
>>
>> # parameter expanded version
>> priors2 <- list(
>>     B = list(mu = rep(0, 3), V = diag(9, 3)),
>>     G = list(G1 = list(V = 1, nu = 0.002),
>>              G2 = list(V = diag(2)/2, nu = 2, alpha.mu = rep(0, 2),
>> alpha.V
>> = diag(500, 2, 2))),
>>     R = list(V = 1, nu = 0.002)
>>     )
>>
>> # inverse of sigma matrix of phylogenetic correlation
>> inv_phylo_mat <- inverseA(tree, nodes = "TIPS", scale = TRUE)
>>
>> fit <- MCMCglmm(
>>     fixed = I1.M1 ~ I2.M1.species.mean + I2.M1.within.species,
>>     rcov = ~ units,
>>     random = ~ phylo + idh(1+I2.M1.within.species):species,
>>     data = incisor.dat,
>>     family = "gaussian",
>>     ginverse = list(phylo = inv_phylo_mat$Ainv),
>>     prior = priors1,
>>     pr = TRUE,
>>     pl = TRUE,
>>     nitt = 1.1e+6, thin = 10, burnin = 1e+5,
>>     verbose = FALSE
>>     )
>>
>>
>> best,
>> Alberto
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun  9 23:25:12 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 9 Jun 2015 14:25:12 -0700
Subject: [R-sig-ME] [R] Different random intercepts but same random
	slope for groups
In-Reply-To: <CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
Message-ID: <CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>

Thierry:

I don't think so. It looks to me like her syntax/understanding is confused.
I think the call should be:

mod2 <- lmer(result  ~ group*time+(group + time|lot), na.action=na.omit,
data=alldata)

Her request for "the same random slope for each group" -- I assume it's for
time -- means to me that the time slope will vary "randomly" by lot only,
the slope would be the same for all groups within the lot.

Of course, I may be wrong also. If so, I suggest that she follow the
posting guide and post at least head(alldata) using dput() to enable folks
to understand the structure of her data. And only on r-sig-mixed-models --
crossposting is frowned upon here and the mixed models list is the best bet
for this sort of question anyway.

As always, corrections and criticism welcome.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Tue, Jun 9, 2015 at 1:49 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Your model is too complex for the data. This gives you two options: a)
> simplify the model and b) get more data.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
>
> > Hi all,
> >   I'd like to fit a random intercept and random slope model. In my
> > data, there are three groups. I want to have different random
> > intercept for each group but the same random slope effect for all
> > three groups. I used the following R command.
> > However, there seems to be some problem. Any suggestions?
> >
> >
> >
> > mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
> > group3+time|lot), na.action=na.omit, data=alldata)
> >
> > > summary(mod2)
> > Model is not identifiable...
> > summary from lme4 is returned
> > some computational error has occurred in lmerTest
> > Linear mixed model fit by REML ['merModLmerTest']
> > Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
> >     lot)
> >    Data: alldata
> >
> > REML criterion at convergence: 807.9
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -3.0112 -0.3364  0.0425  0.2903  3.2017
> >
> > Random effects:
> >  Groups   Name     Variance Std.Dev. Corr
> >  lot      group1   0.00000 0.000
> >           group2   86.20156 9.284      NaN
> >           group3 55.91479 7.478      NaN  0.06
> >           time      0.02855 0.169      NaN -0.99  0.10
> >  Residual          39.91968 6.318
> > Number of obs: 119, groups:  lot, 15
> >
> > Fixed effects:
> >                             Estimate Std. Error t value
> > (Intercept)                 100.1566     2.5108   39.89
> > group  group2        -2.9707     3.7490   -0.79
> > group  group3           -0.0717     2.8144   -0.03
> > time                         -0.1346     0.1780   -0.76
> > group  group2 :time   0.1450     0.2939    0.49
> > group  group3:time        0.1663     0.2152    0.77
> >
> > Warning messages:
> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> >   Model failed to converge with max|grad| = 0.147314 (tol = 0.002,
> > component 2)
> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> >   Model failed to converge: degenerate  Hessian with 2 negative
> eigenvalues
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From christian.noel.blanco at gmail.com  Tue Jun  9 23:25:43 2015
From: christian.noel.blanco at gmail.com (Christian Blanco)
Date: Tue, 9 Jun 2015 14:25:43 -0700
Subject: [R-sig-ME] Fwd: Clarifications on implementation of lmer (lme4) in
	R -weights
In-Reply-To: <CADjz9w+QvU7NmUoiLoRyBr=q5W=9wKyAGkaU9fyj=qjr1V5uAw@mail.gmail.com>
References: <CADjz9w+QvU7NmUoiLoRyBr=q5W=9wKyAGkaU9fyj=qjr1V5uAw@mail.gmail.com>
Message-ID: <CADjz9w+WwFZaV1h2o39ocOcmh_hX=himaoxyP0VF-Ko3YZTgQg@mail.gmail.com>

I was reviewing the documentation on lmer (lme4) found here:
http://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf. The
document refers to W^-1 as "known
prior weights".

Is this "weight" the same concept as using weights in a model "lm"?

I did some testing between the lme and lmer (with REML estimator; random
slope and intercept).

Without any weights, I get the same estimates for lme and lmer. However,
when I include a weight given by inverse of the sample size by ID. I get
very different results.

I think I may be interpreting these weights differently.

Sincerely,
Christian

	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Tue Jun  9 04:19:46 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Tue, 9 Jun 2015 12:19:46 +1000
Subject: [R-sig-ME] help with the logistic formula using nlme/nlmer
In-Reply-To: <20150608130752.GA7347@hans>
References: <20150608130752.GA7347@hans>
Message-ID: <alpine.LMD.2.00.1506091216240.12010@orpheus.qimr.edu.au>

On Mon, 8 Jun 2015, Hans Ekbrand wrote:

> If you can solve the problem with nlme() or anything else for that
> matter, that's perfectly fine,

gamm4 should do this.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From gaiarrido at gmail.com  Tue Jun  9 14:17:33 2015
From: gaiarrido at gmail.com (Mario Garrido)
Date: Tue, 9 Jun 2015 15:17:33 +0300
Subject: [R-sig-ME] Compute a repeated measures model in lme4
In-Reply-To: <CABi7Y8btKOOp-JGXqCPk5z-ndyTNXngmDddFNifTmLtdZ1fU9A@mail.gmail.com>
References: <CABi7Y8ZzacL6teZLfvPwtn-Smt9FwhTN38Fe-HNqGEQijtp8Bw@mail.gmail.com>
	<CAM9kYqg6vWZEuEC2UK8CywTL7r-8ppFQ4Vwfebs2DQNS6N4L+Q@mail.gmail.com>
	<CABi7Y8Z+fVcAL1vXQO+tvYM4BevWV4q-4aWxty0AV9Ef5k91bg@mail.gmail.com>
	<CABi7Y8bF5jAXsLF9zz7VcSEZ3_FEOUj+7BtxtnOzwGqPmmnRAg@mail.gmail.com>
	<CAM9kYqhRoQX0fdFPdsf0XJA+_Jrk6+xJFvE1jjuCpGt4gfUsbQ@mail.gmail.com>
	<CABi7Y8btKOOp-JGXqCPk5z-ndyTNXngmDddFNifTmLtdZ1fU9A@mail.gmail.com>
Message-ID: <CABi7Y8bCNe9vS=5Yc72BMv6v1Xxr5tRu83ByC+P9Zg_TVjTuqw@mail.gmail.com>

Hi again,
I got another question regarding the random factors.
when I compare models with nested random structures using REML as Zuur
recommended, I found this
> lme1<-lmer(O2.intake4days~1+(1|indiv),REML=FALSE)
> lme2<-lmer(O2.intake4days~1+(daytype|indiv),REML=FALSE)
> lme3<-lmer(O2.intake4days~1+(time|indiv),REML=FALSE)
> lme4<-lmer(O2.intake4days~1+(time+daytype|indiv),REML=FALSE) I compute
this but I am not very sure about the significance of it
> anova(lme1,lme2,lme3,lme4)
Data:
Models:
lme1: O2.intake4days ~ 1 + (1 | indiv)
lme2: O2.intake4days ~ 1 + (daytype | indiv)
lme3: O2.intake4days ~ 1 + (time | indiv)
lme4: O2.intake4days ~ 1 + (time + daytype | indiv)
     Df     AIC     BIC logLik deviance    Chisq Chi Df Pr(>Chisq)
lme1  3 -1115.6 -1106.2 560.81  -1121.6
lme2  5 -1111.6 -1096.0 560.81  -1121.6   0.0070      2     0.9965
lme3  5 -1388.2 -1372.6 699.09  -1398.2 276.5637      0     <2e-16 ***
lme4  8 -1384.7 -1359.7 700.33  -1400.7   2.4701      3     0.4807

*Daytype* is time before and after a treatment and *time* is if is night or
day. I know that individuals consumption is clearly different between night
and day.
So for each individual I got 4 data points. One for day before, one for day
after one for night before and one for night after. If there are changes
should be comparing day before and after and night before and after.
Got the random effect (time|indiv) sense in this way??
I looked in several place but I am not still sure.

Thanks, and sorry for such specific question


2015-06-08 21:41 GMT+03:00 Mario Garrido <gaiarrido at gmail.com>:

> What a complete review of my study! Thanks very much. I got open Zuur
> (2007) in this moment.
>
> Mario
>
> 2015-06-08 21:38 GMT+03:00 Philippi, Tom <tom_philippi at nps.gov>:
>
>> The draft R-sig-mixed FAQ has some guidance on testing random effects
>> (and LRT via anova are not recommended):
>> http://glmm.wikidot.com/faq
>>
>> Be careful.  In my applications of repeated measures to ecological data,
>> one model or the other for random effects is justified by the structure of
>> the sampling or experiment, and by the question of interest, not by
>> parsimony.
>>
>> Also, if your O2 measurements have cyclic/periodic responses to time of
>> day, at the least I urge you to spend quality time with papers or books,
>> such as Faraway's "Extending the linear model" or Wood's "Generalized
>> additive models" or perhaps one of Zuur's, to fully understand the
>> differences between treatments in the data that are estimated or tested by
>> different models.
>>
>> Ecologically, you may be more interested in specific parameters about the
>> O2 consumption: integrated 24hr consumption, estimated peak consumption,
>> shifts in time of peak consumption, rate of ramping up of consumption (your
>> rate of change of O2 might be a ramping up or ramping down following some
>> exertion).
>>
>> Tom 2
>>
>> On Mon, Jun 8, 2015 at 11:18 AM, Mario Garrido <gaiarrido at gmail.com>
>> wrote:
>>
>>> sorry, I reply without finishing my comments.
>>> I am trying to compare the rate of change in O2 consumption in 2
>>> consecutive days after a treatment (some individuals are treated while
>>> others do not) days. This is my treatment variable.
>>> daytype variable got 2 levels. the day before treatment and the day
>>> after treatment
>>> age variable are either juveniles or adults and time is time of teh day,
>>> dark and night.
>>>
>>> As I comparing the O2 consumption between day before and after. Random
>>> effect should be  1|individual) or (1+time|individual)?
>>>
>>>
>>> I always got the doubt.
>>>
>>> thanks!
>>>
>>> 2015-06-08 21:12 GMT+03:00 Mario Garrido <gaiarrido at gmail.com>:
>>>
>>>> This is really very useful, also what you tell about the random effect.
>>>> I just wondering about it right now.
>>>>
>>>> Thanks very much. I will look at with detail and get back here if
>>>> needed.
>>>>
>>>>
>>>>
>>>> 2015-06-08 20:53 GMT+03:00 Philippi, Tom <tom_philippi at nps.gov>:
>>>>
>>>>> Mario--
>>>>> Yes your formula is redundant.  It may or may not describe the model
>>>>> you are interested in.
>>>>> Look at the documentation for formula specification:
>>>>> * as in
>>>>> treatment*daytype*time*age
>>>>> includes both the individual main effects and the interactions up to
>>>>> the 4-way interaction, so your other terms are already included.
>>>>> : specifies an interaction.
>>>>>
>>>>> If you only want main effects plus those 3 2-way interactions, you can
>>>>> use something like:
>>>>> lme.mean7<-lmer(averageba~ treatment+daytype+time+age+
>>>>>                              age:activity+ time:activity+treatment:
>>>>> daytype+
>>>>>                             (1|indiv), REML = FALSE)
>>>>> Again, ?formula will help you with the syntax to specify the model you
>>>>> are interested in.
>>>>>
>>>>> Also, think hard about your random effect.  While there are some
>>>>> repeated measures models where (1|individual) is appropriate, in many cases
>>>>> (1+time|individual) or equivalently (time|individual) is more appropriate
>>>>> and informative.
>>>>>
>>>>> I hope that this helps get you pointed in the right direction.
>>>>>
>>>>> Tom 2
>>>>>
>>>>>
>>>>> On Mon, Jun 8, 2015 at 1:07 AM, Mario Garrido <gaiarrido at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> ?Dear list,
>>>>>> I am interesting in introduce in the same model ?these following
>>>>>> groups of
>>>>>> variables
>>>>>> treatment*daytype*time*age
>>>>>> age*activity
>>>>>> time*activity
>>>>>> treatment*daytype+activity
>>>>>>
>>>>>> Is this the correct way to do it? or is redundant and I get spurious
>>>>>> results?
>>>>>> lme.mean7<-lmer(averageba~ treatment*daytype*time*age+age*activity+
>>>>>> time*activity+treatment*daytype+activity+(1|indiv), REML = FALSE)
>>>>>>
>>>>>> Thanks!
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed Jun 10 18:40:16 2015
From: hannah.hlx at gmail.com (li li)
Date: Wed, 10 Jun 2015 12:40:16 -0400
Subject: [R-sig-ME] [R] Different random intercepts but same random
	slope for groups
In-Reply-To: <CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
	<CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>
Message-ID: <CAHLnndaBpMp-Jm+ns5xspPuXhF+qV_=bwDvbNgNs17K=FDSjWg@mail.gmail.com>

Thanks all for the reply,

I think what Bert specified is what I wanted. Thanks very much.
So this model allows different random intercept term but the same
random slope term for the three methods.

I have an additional question. I would like to require differnt
residual variance also for the three groups. Is that possible?

Thanks!!

2015-06-09 17:25 GMT-04:00, Bert Gunter <bgunter.4567 at gmail.com>:
> Thierry:
>
> I don't think so. It looks to me like her syntax/understanding is confused.
> I think the call should be:
>
> mod2 <- lmer(result  ~ group*time+(group + time|lot), na.action=na.omit,
> data=alldata)
>
> Her request for "the same random slope for each group" -- I assume it's for
> time -- means to me that the time slope will vary "randomly" by lot only,
> the slope would be the same for all groups within the lot.
>
> Of course, I may be wrong also. If so, I suggest that she follow the
> posting guide and post at least head(alldata) using dput() to enable folks
> to understand the structure of her data. And only on r-sig-mixed-models --
> crossposting is frowned upon here and the mixed models list is the best bet
> for this sort of question anyway.
>
> As always, corrections and criticism welcome.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>    -- Clifford Stoll
>
> On Tue, Jun 9, 2015 at 1:49 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Your model is too complex for the data. This gives you two options: a)
>> simplify the model and b) get more data.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
>>
>> > Hi all,
>> >   I'd like to fit a random intercept and random slope model. In my
>> > data, there are three groups. I want to have different random
>> > intercept for each group but the same random slope effect for all
>> > three groups. I used the following R command.
>> > However, there seems to be some problem. Any suggestions?
>> >
>> >
>> >
>> > mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
>> > group3+time|lot), na.action=na.omit, data=alldata)
>> >
>> > > summary(mod2)
>> > Model is not identifiable...
>> > summary from lme4 is returned
>> > some computational error has occurred in lmerTest
>> > Linear mixed model fit by REML ['merModLmerTest']
>> > Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
>> >     lot)
>> >    Data: alldata
>> >
>> > REML criterion at convergence: 807.9
>> >
>> > Scaled residuals:
>> >     Min      1Q  Median      3Q     Max
>> > -3.0112 -0.3364  0.0425  0.2903  3.2017
>> >
>> > Random effects:
>> >  Groups   Name     Variance Std.Dev. Corr
>> >  lot      group1   0.00000 0.000
>> >           group2   86.20156 9.284      NaN
>> >           group3 55.91479 7.478      NaN  0.06
>> >           time      0.02855 0.169      NaN -0.99  0.10
>> >  Residual          39.91968 6.318
>> > Number of obs: 119, groups:  lot, 15
>> >
>> > Fixed effects:
>> >                             Estimate Std. Error t value
>> > (Intercept)                 100.1566     2.5108   39.89
>> > group  group2        -2.9707     3.7490   -0.79
>> > group  group3           -0.0717     2.8144   -0.03
>> > time                         -0.1346     0.1780   -0.76
>> > group  group2 :time   0.1450     0.2939    0.49
>> > group  group3:time        0.1663     0.2152    0.77
>> >
>> > Warning messages:
>> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> :
>> >   Model failed to converge with max|grad| = 0.147314 (tol = 0.002,
>> > component 2)
>> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> :
>> >   Model failed to converge: degenerate  Hessian with 2 negative
>> eigenvalues
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From bbolker at gmail.com  Wed Jun 10 18:45:02 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Jun 2015 12:45:02 -0400
Subject: [R-sig-ME] [R] Different random intercepts but same random
 slope for groups
In-Reply-To: <CAHLnndaBpMp-Jm+ns5xspPuXhF+qV_=bwDvbNgNs17K=FDSjWg@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>	<CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>
	<CAHLnndaBpMp-Jm+ns5xspPuXhF+qV_=bwDvbNgNs17K=FDSjWg@mail.gmail.com>
Message-ID: <5578698E.4020103@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Li li: *please* stop cc'ing r-help on the reply.

  If group2 and group3 are numeric dummy variables you can add a
difference in the residual variance as follows ...

  alldata$obs <- factor(seq(nrow(alldata)))

  ... + (group2|obs) + (group3|obs) + ...

 you may need to use lmerControl() to override some of the
warnings/errors about having as many levels of the random effect as
there are observations.

  Or you could do this in lme and use weights=varIdent(form=~1|group)


On 15-06-10 12:40 PM, li li wrote:
> Thanks all for the reply,
> 
> I think what Bert specified is what I wanted. Thanks very much. So
> this model allows different random intercept term but the same 
> random slope term for the three methods.
> 
> I have an additional question. I would like to require differnt 
> residual variance also for the three groups. Is that possible?
> 
> Thanks!!
> 
> 2015-06-09 17:25 GMT-04:00, Bert Gunter <bgunter.4567 at gmail.com>:
>> Thierry:
>> 
>> I don't think so. It looks to me like her syntax/understanding is
>> confused. I think the call should be:
>> 
>> mod2 <- lmer(result  ~ group*time+(group + time|lot),
>> na.action=na.omit, data=alldata)
>> 
>> Her request for "the same random slope for each group" -- I
>> assume it's for time -- means to me that the time slope will vary
>> "randomly" by lot only, the slope would be the same for all
>> groups within the lot.
>> 
>> Of course, I may be wrong also. If so, I suggest that she follow
>> the posting guide and post at least head(alldata) using dput() to
>> enable folks to understand the structure of her data. And only on
>> r-sig-mixed-models -- crossposting is frowned upon here and the
>> mixed models list is the best bet for this sort of question
>> anyway.
>> 
>> As always, corrections and criticism welcome.
>> 
>> Cheers, Bert
>> 
>> Bert Gunter
>> 
>> "Data is not information. Information is not knowledge. And
>> knowledge is certainly not wisdom." -- Clifford Stoll
>> 
>> On Tue, Jun 9, 2015 at 1:49 PM, Thierry Onkelinx
>> <thierry.onkelinx at inbo.be> wrote:
>> 
>>> Your model is too complex for the data. This gives you two
>>> options: a) simplify the model and b) get more data.
>>> 
>>> Best regards,
>>> 
>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>> Research Institute for Nature and Forest team Biometrie &
>>> Kwaliteitszorg / team Biometrics & Quality Assurance 
>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>> 
>>> To call in the statistician after the experiment is done may be
>>> no more than asking him to perform a post-mortem examination:
>>> he may be able to say what the experiment died of. ~ Sir Ronald
>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>> Brinner The combination of some data and an aching desire for
>>> an answer does not ensure that a reasonable answer can be
>>> extracted from a given body of data. ~ John Tukey
>>> 
>>> 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
>>> 
>>>> Hi all, I'd like to fit a random intercept and random slope
>>>> model. In my data, there are three groups. I want to have
>>>> different random intercept for each group but the same random
>>>> slope effect for all three groups. I used the following R
>>>> command. However, there seems to be some problem. Any
>>>> suggestions?
>>>> 
>>>> 
>>>> 
>>>> mod2 <- lmer(result  ~ group*time+(0+group1+ group2 + 
>>>> group3+time|lot), na.action=na.omit, data=alldata)
>>>> 
>>>>> summary(mod2)
>>>> Model is not identifiable... summary from lme4 is returned 
>>>> some computational error has occurred in lmerTest Linear
>>>> mixed model fit by REML ['merModLmerTest'] Formula: result ~
>>>> group * time + (0 + group1 + group2 + group3 + time | lot) 
>>>> Data: alldata
>>>> 
>>>> REML criterion at convergence: 807.9
>>>> 
>>>> Scaled residuals: Min      1Q  Median      3Q     Max -3.0112
>>>> -0.3364  0.0425  0.2903  3.2017
>>>> 
>>>> Random effects: Groups   Name     Variance Std.Dev. Corr lot
>>>> group1   0.00000 0.000 group2   86.20156 9.284      NaN 
>>>> group3 55.91479 7.478      NaN  0.06 time      0.02855 0.169
>>>> NaN -0.99  0.10 Residual          39.91968 6.318 Number of
>>>> obs: 119, groups:  lot, 15
>>>> 
>>>> Fixed effects: Estimate Std. Error t value (Intercept)
>>>> 100.1566     2.5108   39.89 group  group2        -2.9707
>>>> 3.7490   -0.79 group  group3           -0.0717     2.8144
>>>> -0.03 time                         -0.1346     0.1780
>>>> -0.76 group  group2 :time   0.1450     0.2939    0.49 group
>>>> group3:time        0.1663     0.2152    0.77
>>>> 
>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>>>> opt$par, ctrl = control$checkConv,
>>> :
>>>> Model failed to converge with max|grad| = 0.147314 (tol =
>>>> 0.002, component 2) 2: In checkConv(attr(opt, "derivs"),
>>>> opt$par, ctrl = control$checkConv,
>>> :
>>>> Model failed to converge: degenerate  Hessian with 2
>>>> negative
>>> eigenvalues
>>>> 
>>>> ______________________________________________ 
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>>>> read the posting guide 
>>>> http://www.R-project.org/posting-guide.html and provide
>>>> commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________ 
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>> the posting guide http://www.R-project.org/posting-guide.html 
>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>> 
>> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVeGmOAAoJEOCV5YRblxUH+sQIANQ/wAdPE8ERp95iEKqmpK2B
FFCL7pBIGbO/mEry3GHk57v9h5QR0FhFwsRClJ6zrxXDCpsRW4juaulsqXGQog5Q
aI6WwMyime/pdIQgSozKCTVnpPBPWY6BNs9ZWcR1zwt6oPnwBGtDEcfKS2I6c2cw
Zi0OIoWf8xbD9Oujup7WrLG3RCPu/nS+UlaNxl/h6sFM7dHzhXXDsbaS9B2rwY3n
lkmE+bbHb6UuZJ7NVA5B+F17av7GeTF5F+M6AHH8z5XutnLHCb74CFgpsaCZkQo0
fMdOYAVmcp1hXAaGVsi6nBTXiomnGqfOGmbzCwSw5vQvzy8XCpeh1AUWpxwnugE=
=9z6N
-----END PGP SIGNATURE-----


From russell-lenth at uiowa.edu  Wed Jun 10 18:55:54 2015
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Wed, 10 Jun 2015 16:55:54 +0000
Subject: [R-sig-ME] Cross-over Data with Kenward-Roger correction
Message-ID: <51F0C7C54B032A42A23B74A088E7141C4411011B@itsnt443.iowa.uiowa.edu>

For some reason, there were scads of "?"s in your posting; I removed them in the quote below so it's easier to read.

You did not fit the same model in R as you did in SAS. The SAS one has unstructured covariance (3 covariance parameters plus residual error), whereas the R one has just one, and corresponds to the SAS model with the REPEATED statement replaced by "RANDOM SBJ;" 

I don't think you can fit the unstructured model with lmer (but I'm sure somebody will correct me if I'm wrong). It is possible to do that with lme in the nlme package, but you can't get the K-R d.f. with that.

Russ

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017



-----Original Message-----

Message: 1
Date: Wed, 10 Jun 2015 04:18:00 +0000 (UTC)
From: knouri <nouri4 at yahoo.com>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Cross-over Data with Kenward-Roger correction
Message-ID:
	<180812510.9495.1433909880558.JavaMail.yahoo at mail.yahoo.com>
Content-Type: text/plain; charset="UTF-8"

Dear all:I have a SAS code but need to write it in R. Any advice will be greatly appreciated.
Here is the data ( a two-period) cross-over design comparing Trt 1 vs. Trt 2:

Sbj  Seq  Per  Trt  PEF
1      1       1     1   310
1      1       2     2   270
4      1       1     1   310
 4      1       2     2   260
6      1       1     1   370
6      1       2     2   300
7      1       1     1   410
7      1       2     2   390
10    1       1    1    250
10    1       2    2   210
11    1       1    1   380
11    1       2    2   350
14    1       1    1   330
14    1       2    2   365
2      2       1    2   370
2      2       2   1   385
3      2      1    2   310
3      2      2    1   400
5      2      1    2   380
5      2      2    1   410
9      2      1   2   290
9      2      2   1   320
12    2      1   2   260
12    2      2   1   340
13    2      1   2    90
13    2      2   1   220

Here is the SAS code:
#########################################################
proc mixed data=one method=reml;
class Sbj Per Trt;
model PEF = Per Trt /ddfm=kr;
repeated Trt / sub=Sbj type=un r;
lsmeans Trt / cl alpha=0.05;
estimate 'B vs. A' Trt -1  1 / alpha=0.1 cl; run; ###################################################
where kr option in model statement stands for "Kenward-Roger" correction. The above SAS code produces (selected portions):

       
|  Covariance Parameter Estimates |
|  Cov Parm |  Subject |  Estimate |
|  UN(1,1) |  Sbj |  3567.58 |
|  UN(2,1) |  Sbj |  4437.00 |
|  UN(2,2) |  Sbj |  6760.65 |

| Type 3 Tests of Fixed Effects |
| Effect | Num DF | Den DF | F Value | Pr > F | Per | 1 | 11 | 2.59 | 
| 0.1359 | Trt | 1 | 11.6 | 19.26 | 0.0010 |
     
|  Estimates |
|  Label |  Estimate |  Standard
 Error |  DF |  t Value |  Pr > |t| |  Alpha |  Lower |  Upper |
|  B vs. A |  -46.5150 |  10.5999 |  11.6 |  -4.39 |  0.0010 |  0.1 |  -65.4629 |  -27.5671 |

|  Least Squares Means |
|  Effect |  Trt |  Estimate |  Standard
 Error |  DF |  t Value |  Pr > |t| |  Alpha |  Lower |  Upper |
|  Trt |  1 |  341.72 |  16.5696 |  12 |  20.62 |  <.0001 |  0.05 |  305.62 |  377.82 |
|  Trt |  2 |  295.20 |  22.8073 |  12 |  12.94 |  <.0001 |  0.05 |  245.51 |  344.90 |

I used several R functions including lme, lmer. For example,  the following R code:
require(lme4)
require(pbkrtest)
require(lmerTest)
mydat$Trt = as.factor(mydat$Trt)
mydat$Per = as.factor(mydat$Per)fit.lmer <- lmer(PEF ~ Trt + Per + (1| Sbj), REML = TRUE, data=mydat)
anova(fit.lmer, ddf = "Kenward-Roger", type=3)( lsmeans(fit.lmer, test.effs="Trt") )
difflsmeans(fit.lmer, test.effs="Trt")

produces rather different results (compared to SAS), especially for df's, standard errors, etc.
Analysis of Variance Table of type 3  with  Kenward-Roger approximation for degrees of freedom
       Sum Sq       Mean Sq       NumDF       DenDF        F.value        Pr(>F)   
Trt    14036         14036         1           11           18.70         0.0012 **
Per     1632          1632         1           11            2.17         0.1683   


Least Squares Means table:
        Trt  Per   Estimate    Standard Error   DF   t-value     Lower CI Upper CI      p-value    
Trt  1  1.0  NA    341.8       20.0             13.9    17.1     299      385           <2e-16 ***
Trt  2  2.0  NA    295.2       20.0             13.9    14.8     252      338           <2e-16 ***

Differences of LSMEANS:
              Estimate    Standard Error  DF       t-value      Lower CI      Upper CI    p-value   
Trt 1 - 2     46.6        10.8            11.0     4.32         22.9          70.3        0.001 **


I am not quite sure if I am using the right R functions. Any advice will be greatly appreciated,
Thanks again,
Keramat


From hannah.hlx at gmail.com  Wed Jun 10 19:39:44 2015
From: hannah.hlx at gmail.com (li li)
Date: Wed, 10 Jun 2015 13:39:44 -0400
Subject: [R-sig-ME] [R] Different random intercepts but same random
 slope for groups
In-Reply-To: <5578698E.4020103@gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
	<CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>
	<CAHLnndaBpMp-Jm+ns5xspPuXhF+qV_=bwDvbNgNs17K=FDSjWg@mail.gmail.com>
	<5578698E.4020103@gmail.com>
Message-ID: <CAHLnndZnxiikV8y4YH0gx4ax9=UryhfTiB4JO=KKNb0QVMrpRg@mail.gmail.com>

2015-06-10 12:45 GMT-04:00, Ben Bolker <bbolker at gmail.com>:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Li li: *please* stop cc'ing r-help on the reply.
>
>   If group2 and group3 are numeric dummy variables you can add a
> difference in the residual variance as follows ...
>
>   alldata$obs <- factor(seq(nrow(alldata)))
>
>   ... + (group2|obs) + (group3|obs) + ...
>
>  you may need to use lmerControl() to override some of the
> warnings/errors about having as many levels of the random effect as
> there are observations.
>
>   Or you could do this in lme and use weights=varIdent(form=~1|group)
>
>
> On 15-06-10 12:40 PM, li li wrote:
>> Thanks all for the reply,
>>
>> I think what Bert specified is what I wanted. Thanks very much. So
>> this model allows different random intercept term but the same
>> random slope term for the three methods.
>>
>> I have an additional question. I would like to require differnt
>> residual variance also for the three groups. Is that possible?
>>
>> Thanks!!
>>
>> 2015-06-09 17:25 GMT-04:00, Bert Gunter <bgunter.4567 at gmail.com>:
>>> Thierry:
>>>
>>> I don't think so. It looks to me like her syntax/understanding is
>>> confused. I think the call should be:
>>>
>>> mod2 <- lmer(result  ~ group*time+(group + time|lot),
>>> na.action=na.omit, data=alldata)
>>>
>>> Her request for "the same random slope for each group" -- I
>>> assume it's for time -- means to me that the time slope will vary
>>> "randomly" by lot only, the slope would be the same for all
>>> groups within the lot.
>>>
>>> Of course, I may be wrong also. If so, I suggest that she follow
>>> the posting guide and post at least head(alldata) using dput() to
>>> enable folks to understand the structure of her data. And only on
>>> r-sig-mixed-models -- crossposting is frowned upon here and the
>>> mixed models list is the best bet for this sort of question
>>> anyway.
>>>
>>> As always, corrections and criticism welcome.
>>>
>>> Cheers, Bert
>>>
>>> Bert Gunter
>>>
>>> "Data is not information. Information is not knowledge. And
>>> knowledge is certainly not wisdom." -- Clifford Stoll
>>>
>>> On Tue, Jun 9, 2015 at 1:49 PM, Thierry Onkelinx
>>> <thierry.onkelinx at inbo.be> wrote:
>>>
>>>> Your model is too complex for the data. This gives you two
>>>> options: a) simplify the model and b) get more data.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>> Research Institute for Nature and Forest team Biometrie &
>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be
>>>> no more than asking him to perform a post-mortem examination:
>>>> he may be able to say what the experiment died of. ~ Sir Ronald
>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>> Brinner The combination of some data and an aching desire for
>>>> an answer does not ensure that a reasonable answer can be
>>>> extracted from a given body of data. ~ John Tukey
>>>>
>>>> 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
>>>>
>>>>> Hi all, I'd like to fit a random intercept and random slope
>>>>> model. In my data, there are three groups. I want to have
>>>>> different random intercept for each group but the same random
>>>>> slope effect for all three groups. I used the following R
>>>>> command. However, there seems to be some problem. Any
>>>>> suggestions?
>>>>>
>>>>>
>>>>>
>>>>> mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
>>>>> group3+time|lot), na.action=na.omit, data=alldata)
>>>>>
>>>>>> summary(mod2)
>>>>> Model is not identifiable... summary from lme4 is returned
>>>>> some computational error has occurred in lmerTest Linear
>>>>> mixed model fit by REML ['merModLmerTest'] Formula: result ~
>>>>> group * time + (0 + group1 + group2 + group3 + time | lot)
>>>>> Data: alldata
>>>>>
>>>>> REML criterion at convergence: 807.9
>>>>>
>>>>> Scaled residuals: Min      1Q  Median      3Q     Max -3.0112
>>>>> -0.3364  0.0425  0.2903  3.2017
>>>>>
>>>>> Random effects: Groups   Name     Variance Std.Dev. Corr lot
>>>>> group1   0.00000 0.000 group2   86.20156 9.284      NaN
>>>>> group3 55.91479 7.478      NaN  0.06 time      0.02855 0.169
>>>>> NaN -0.99  0.10 Residual          39.91968 6.318 Number of
>>>>> obs: 119, groups:  lot, 15
>>>>>
>>>>> Fixed effects: Estimate Std. Error t value (Intercept)
>>>>> 100.1566     2.5108   39.89 group  group2        -2.9707
>>>>> 3.7490   -0.79 group  group3           -0.0717     2.8144
>>>>> -0.03 time                         -0.1346     0.1780
>>>>> -0.76 group  group2 :time   0.1450     0.2939    0.49 group
>>>>> group3:time        0.1663     0.2152    0.77
>>>>>
>>>>> Warning messages: 1: In checkConv(attr(opt, "derivs"),
>>>>> opt$par, ctrl = control$checkConv,
>>>> :
>>>>> Model failed to converge with max|grad| = 0.147314 (tol =
>>>>> 0.002, component 2) 2: In checkConv(attr(opt, "derivs"),
>>>>> opt$par, ctrl = control$checkConv,
>>>> :
>>>>> Model failed to converge: degenerate  Hessian with 2
>>>>> negative
>>>> eigenvalues
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>>>>> read the posting guide
>>>>> http://www.R-project.org/posting-guide.html and provide
>>>>> commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>>> the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVeGmOAAoJEOCV5YRblxUH+sQIANQ/wAdPE8ERp95iEKqmpK2B
> FFCL7pBIGbO/mEry3GHk57v9h5QR0FhFwsRClJ6zrxXDCpsRW4juaulsqXGQog5Q
> aI6WwMyime/pdIQgSozKCTVnpPBPWY6BNs9ZWcR1zwt6oPnwBGtDEcfKS2I6c2cw
> Zi0OIoWf8xbD9Oujup7WrLG3RCPu/nS+UlaNxl/h6sFM7dHzhXXDsbaS9B2rwY3n
> lkmE+bbHb6UuZJ7NVA5B+F17av7GeTF5F+M6AHH8z5XutnLHCb74CFgpsaCZkQo0
> fMdOYAVmcp1hXAaGVsi6nBTXiomnGqfOGmbzCwSw5vQvzy8XCpeh1AUWpxwnugE=
> =9z6N
> -----END PGP SIGNATURE-----
>


From hannah.hlx at gmail.com  Thu Jun 11 03:14:11 2015
From: hannah.hlx at gmail.com (li li)
Date: Wed, 10 Jun 2015 21:14:11 -0400
Subject: [R-sig-ME] factor specific residual variance for random coefficient
	model with lmer
Message-ID: <CAHLnndbtOhCAJw8fZVOF77_NyiBTQDkR41L6N2m2_DjRRgD2CQ@mail.gmail.com>

Hi all,
  I am wondering how to specify the model fm1 below so that the two
groups (treatment and control) specified by the column drug in the
data matrix have different residual variances. Any suggestion?
  Please see the codes below.
  Thanks very much!
    Hanna




set.seed(500)
n.timepoints <- 8
n.subj.per.tx <- 20
sd.d <- 5;
sd.p <- 2;
sd.res <- 1.3
drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
n.subj.per.tx))
drug.baseline <- rep( c(0,5), each=n.timepoints, times=n.subj.per.tx )
Patient <- rep(1:(n.subj.per.tx*2), each = n.timepoints)
Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, sd.p) ),
each=n.timepoints )
time <- factor(paste("Time-", rep(1:n.timepoints, n.subj.per.tx*2),
sep=""))
time.baseline <-
rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
dv <- rnorm( n.subj.per.tx*n.timepoints*2,
mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res )
dat.new <- data.frame(time, drug, dv, Patient)
dat.new$time.num = rep(1:n.timepoints, n.subj.per.tx*2)

library(lme4)
fm1 <- lmer( dv ~ time.num*drug + (0+ drug + time.num | Patient ),
data=dat.new )
summary(fm1)
resid(fm1)
plot(resid(fm1))


From hannah.hlx at gmail.com  Thu Jun 11 05:17:17 2015
From: hannah.hlx at gmail.com (li li)
Date: Wed, 10 Jun 2015 23:17:17 -0400
Subject: [R-sig-ME] factor specific residual variance for random
 coefficient model with lmer
In-Reply-To: <CAHLnndbtOhCAJw8fZVOF77_NyiBTQDkR41L6N2m2_DjRRgD2CQ@mail.gmail.com>
References: <CAHLnndbtOhCAJw8fZVOF77_NyiBTQDkR41L6N2m2_DjRRgD2CQ@mail.gmail.com>
Message-ID: <CAHLnndb6veWHPvxfZr0sc7KmLQPwGzBib8tHaxN4j7a1bFKXWA@mail.gmail.com>

Ok. I found from R help page that the weights argument could
accomplish different residual varainces for different factor levels
like below.


fm2 <- lmer( dv ~ time.num*drug + (0+ drug + time.num | Patient ),
data=dat.new,
weights = varIdent(form = ~1 | drug))
summary(fm2)


But the following error term returned.


Error in summary(fm2) :
  error in evaluating the argument 'object' in selecting a method for
function 'summary': Error: object 'fm2' not found

Any advice?

Thanks
  Hanna

2015-06-10 21:14 GMT-04:00, li li <hannah.hlx at gmail.com>:
> Hi all,
>   I am wondering how to specify the model fm1 below so that the two
> groups (treatment and control) specified by the column drug in the
> data matrix have different residual variances. Any suggestion?
>   Please see the codes below.
>   Thanks very much!
>     Hanna
>
>
>
>
> set.seed(500)
> n.timepoints <- 8
> n.subj.per.tx <- 20
> sd.d <- 5;
> sd.p <- 2;
> sd.res <- 1.3
> drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
> n.subj.per.tx))
> drug.baseline <- rep( c(0,5), each=n.timepoints, times=n.subj.per.tx )
> Patient <- rep(1:(n.subj.per.tx*2), each = n.timepoints)
> Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, sd.p) ),
> each=n.timepoints )
> time <- factor(paste("Time-", rep(1:n.timepoints, n.subj.per.tx*2),
> sep=""))
> time.baseline <-
> rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
> dv <- rnorm( n.subj.per.tx*n.timepoints*2,
> mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res )
> dat.new <- data.frame(time, drug, dv, Patient)
> dat.new$time.num = rep(1:n.timepoints, n.subj.per.tx*2)
>
> library(lme4)
> fm1 <- lmer( dv ~ time.num*drug + (0+ drug + time.num | Patient ),
> data=dat.new )
> summary(fm1)
> resid(fm1)
> plot(resid(fm1))
>


From lorenz.gygax at agroscope.admin.ch  Thu Jun 11 06:58:54 2015
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Thu, 11 Jun 2015 04:58:54 +0000
Subject: [R-sig-ME] Follow-up: PBmodcomp: pwrssUpdate does not converge with
	glmer
Message-ID: <7EC2E4DB4FC53A479711C3238C02EB8303432A@sb00111a.adb.intra.admin.ch>

Dear all,

Ben Bolker was kind enough to point out that in the most current (development) version of lme4 they had done some work on predict,  simulate, and refit which may help my problem. Indeed, with this version, the error mentioned in the title of this e-Mail does not occur any more (at least as far as we have tested) which is very helpful.

Still, specifically in the bootstraps for calculating p-values in PBmodcomp, quite a few models will not fully converge (in the order of 10%). Is there a recommendation on the maximum proportion of such models that should not be surpassed? Or are there any other ideas what could be done about such a case? Use one of the other approaches that are implemented in pbkrtest? So far it does not seem to be a huge issue because the different estimates of the p-values are quite close to each other really (even the LRT).

Thanks again and regards, Lorenz


-----Urspr?ngliche Nachricht-----
Von: Ben Bolker [mailto:bbolker at gmail.com] 
Gesendet: Mittwoch, 10. Juni 2015 13:52
An: Gygax Lorenz Agroscope
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] PBmodcomp: pwrssUpdate does not converge with glmer

I'm not 100% sure, but a lot of this (at least the lme4 end, not
necessarily the pbkrtest end) sounds like the now-resolved (in the
development, soon-to-be-released version 1.1-8) issue
https://github.com/lme4/lme4/issues/231 .

On Wed, Jun 10, 2015 at 6:35 AM,  <lorenz.gygax at agroscope.admin.ch> wrote:
> Dear all,
>
> In a current project (2 x 2 x 2 factorial design) we are interested in
> calculating p-values for binary outcomes (we are aware that such an approach
> is not unequivocal but circumstances are such that results will most easily
> be communicated when we can conduct step-wise backwards model selection and
> when we have the p-values).
>
> The experimental design was hierarchically nested (350 observations
> conducted in 178 phases of the experiment nested in 90 animal-IDs nested in
> 24 facilities). The three factors can and should be assigned to three
> different hierarchical levels (error, phase, facility).
>
> Even though the data does not look in any way extreme (zeros and ones occur
> in all 8 factor combinations), there are some convergence issues with
> running the models. These can be mostly dealt with by using: glmerControl
> (optimizer= 'bobyqa', optCtrl= list (maxfun= 5000)).
>
> Due to sample size and the assignment of the fixed effects to the different
> hierarchical levels, we would like to use parametric bootstrap for
> calculating the p-values as implemented in package pbkrtest (very nice!).
>
> Obviously throughout calculating the bootstrap, some of the models will not
> converge. As far as I can see, the bootstrap sample is simply accordingly
> reduced. Some models, unfortunately, do not result in a warning but in an
> error: "pwrssUpdate did not converge in (maxit) iterations with PBmodcomp".
>
> These errors cause PBmodcomp to fail. Does anyone know whether there is a
> reason why PBmodcomp reacts differently to warnings and erros in the
> bootstrapped glmer's? Or has this just historically grown that the warnings
> are captured but the errors are not? If the latter could catching errors be
> easily incorporated as well? Where would that need to be done? I cannot find
> the according code neither in pbkrtest::PBmodcomp.merMod nor in
> pbkrtest::PBrefdist.merMod.
>
> Many thanks for your ideas and best regards, Lorenz
> -
> Lorenz Gygax, PD Dr. sc. nat.
> Federal Food Safety and Veterinary Office FFSVO
> Centre for Proper Housing of Ruminants and Pigs
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From thierry.onkelinx at inbo.be  Thu Jun 11 09:00:57 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 11 Jun 2015 09:00:57 +0200
Subject: [R-sig-ME] factor specific residual variance for random
 coefficient model with lmer
In-Reply-To: <CAHLnndb6veWHPvxfZr0sc7KmLQPwGzBib8tHaxN4j7a1bFKXWA@mail.gmail.com>
References: <CAHLnndbtOhCAJw8fZVOF77_NyiBTQDkR41L6N2m2_DjRRgD2CQ@mail.gmail.com>
	<CAHLnndb6veWHPvxfZr0sc7KmLQPwGzBib8tHaxN4j7a1bFKXWA@mail.gmail.com>
Message-ID: <CAJuCY5xttR-hLzJOzNk5_dkPznPWTveaVa4-jiYstVgJS2UMWg@mail.gmail.com>

You are mixing lme4 and nlme syntax. Varident is a nlme function.
Op 11-jun.-2015 05:23 schreef "li li" <hannah.hlx at gmail.com>:

> Ok. I found from R help page that the weights argument could
> accomplish different residual varainces for different factor levels
> like below.
>
>
> fm2 <- lmer( dv ~ time.num*drug + (0+ drug + time.num | Patient ),
> data=dat.new,
> weights = varIdent(form = ~1 | drug))
> summary(fm2)
>
>
> But the following error term returned.
>
>
> Error in summary(fm2) :
>   error in evaluating the argument 'object' in selecting a method for
> function 'summary': Error: object 'fm2' not found
>
> Any advice?
>
> Thanks
>   Hanna
>
> 2015-06-10 21:14 GMT-04:00, li li <hannah.hlx at gmail.com>:
> > Hi all,
> >   I am wondering how to specify the model fm1 below so that the two
> > groups (treatment and control) specified by the column drug in the
> > data matrix have different residual variances. Any suggestion?
> >   Please see the codes below.
> >   Thanks very much!
> >     Hanna
> >
> >
> >
> >
> > set.seed(500)
> > n.timepoints <- 8
> > n.subj.per.tx <- 20
> > sd.d <- 5;
> > sd.p <- 2;
> > sd.res <- 1.3
> > drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
> > n.subj.per.tx))
> > drug.baseline <- rep( c(0,5), each=n.timepoints, times=n.subj.per.tx )
> > Patient <- rep(1:(n.subj.per.tx*2), each = n.timepoints)
> > Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, sd.p) ),
> > each=n.timepoints )
> > time <- factor(paste("Time-", rep(1:n.timepoints, n.subj.per.tx*2),
> > sep=""))
> > time.baseline <-
> > rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
> > dv <- rnorm( n.subj.per.tx*n.timepoints*2,
> > mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res )
> > dat.new <- data.frame(time, drug, dv, Patient)
> > dat.new$time.num = rep(1:n.timepoints, n.subj.per.tx*2)
> >
> > library(lme4)
> > fm1 <- lmer( dv ~ time.num*drug + (0+ drug + time.num | Patient ),
> > data=dat.new )
> > summary(fm1)
> > resid(fm1)
> > plot(resid(fm1))
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From daniel.gregory3 at gmail.com  Fri Jun 12 13:00:10 2015
From: daniel.gregory3 at gmail.com (Greg - Univ/Pro)
Date: Fri, 12 Jun 2015 13:00:10 +0200
Subject: [R-sig-ME] MCMCglmm Bivariate model and prior
Message-ID: <557ABBBA.4050600@gmail.com>

Dear MCMCglmm users,

My questions are simple and I hope you can answer me.
I wish to run a bivariate model with MCMCglmm package. But one response 
variable is a continuous one (family = gaussian) and the other is a 
binary one (family = ordinal).
I have sought a way to parameterize the model (in the archives of this 
list too), I tried some solution that I thought, but in vain. I have to 
fix to 1 the residual variance for the binary variable and leave it free 
for the continuous variable.
Is it possible in MCMCglmm ? And if yes : how do I parameterize the priors ?

Thanks for your help.

Gr?gory DANIEL
PhD Student - LBBE
University of Lyon 1
69100 Villeurbanne - FRANCE


From gaiarrido at gmail.com  Thu Jun 11 16:01:22 2015
From: gaiarrido at gmail.com (Mario Garrido)
Date: Thu, 11 Jun 2015 17:01:22 +0300
Subject: [R-sig-ME] Doubts with the syntax in lme4
Message-ID: <CABi7Y8aLfXf+d_UdUi98jE7Zd1qHPfkC8+RhR_8Y1eJV48cRCg@mail.gmail.com>

Dear list

I have got a question regarding the syntax of repeated measures in package
lme4 in R. I have not clear how to define my model using lmer.

I am right now using this syntax


model<-lmer(O2.intake4days~ treatment*daytype*time*age+activity+(1|indiv),
REML = FALSE)


but I guess if I need to add anything to define my within subject factors
that are time of the day (night/day) and day type (before/after).


Am I right in assuming that lmer() automatically differentiates between
within and between subjects factors by indication of the subject variable
(i.e. "individual" in my study) in the term (1|individual) and the fact
that age and treatment do not vary within subjects, whereas time of the day
(night/day) and day type (before/after) do?


I want to know if the O2 consumption of rodents is affected by fleas and
dependent at the same time in other variables as age and treatment
(between-subject variables) and time of the day and day type
(within-subject variables). So, for each individual I got 4 values:

1 during day before treatment

1 during night before treatment

1 during day after treatment

1 during night after treatment



I am working with 42 individuals, 18 juveniles and 24 adults. Among them, 9
juveniles are control and other 9 are treated (as I said, we have added the
fleas just the day after) and 12 ad are control and 12 treated.

I have not clear how to define the model using lmer. I am right now using
this syntax but I guess if I need to add anything to define my within
subject factors as time of the day (dark and night).



model<-lmer(O2.intake4days~ treatment*daytype*time*age+activity+(1|indiv),
REML = FALSE)



Here is a small example of the data



individual                   age                      treatment
          day type       time of the day                    O2 intake

211                         juv
fleas                      before
light                       0.020571

211                         juv
fleas                      after
light                       0.021416

211                         juv
fleas                      before
dark                       0.037797

211                         juv
fleas                      after
dark                       0.039788

213                         juv
control                  before
light                       0.026242

213                         juv
control                  after
light                       0.02446

213                         juv
control                  before                  dark
0.039787

213                         juv
control                  after
dark                       0.039849

23                           ad
control                  before
light                       0.011403

23                           ad
control                  after
light                       0.011588

23                           ad
control                  before                  dark
0.01783

23                           ad
control                  after
dark                       0.015907

36                           ad
fleas                      before
light                       0.011775

36                           ad
fleas                      after
light                       0.01303

36                           ad
fleas                      before
dark                       0.017582

36                           ad
fleas                      after
dark                       0.021021

	[[alternative HTML version deleted]]


From nicodeguines at gmail.com  Wed Jun 10 20:53:17 2015
From: nicodeguines at gmail.com (Nicolas Deguines)
Date: Wed, 10 Jun 2015 11:53:17 -0700
Subject: [R-sig-ME] lme4 - equal estimates of regression coefficients across
 levels of a random effect
Message-ID: <CAFzZfa2VRCa_w3bnrxHwfOkTAGu3+hL5jU5NnEOxfu7nZjKGMg@mail.gmail.com>

Dear lme4 authors & users,

I?m a postdoctoral research scholar working on the effect of
precipitation on the food web of a grassland semi-arid ecosystem in
California.

I am analyzing my dataset with version 1.1-7 of the lme4 package with
version 3.2.0 of R.
I encountered an issue while running a glmer model that includes
random effects from a categorical variable (?year?, 2010 and 2011) on
the slope of four explanatory variables.
Precisely, the estimated slope coefficients for 1 out of 4 explanatory
variables are identical in the two years. However, when running a
model including only this particular explanatory variable and the same
random effect from year on slope, estimates are different for the two
years (indeed, I did check that values are different in the two years.

It also happens for other models I?m running, e.g. with that
particular explanatory variable + two new ones: this time though, the
slope coefficients are different for that particular variable but
identical for the two new ones (nb: the response variable in this
model differs from the 1st model discussed).

Is this an issue that already occurred to other lme4 users? Any idea
about what I may be doing wrong?
I suspect it may come from the syntax of my models. I had fitted my model as:
glmer(response ~ x1 + x2 + x3 + x4 +(x1|year) +(x2|year) +(x3|year)
+(x4|year), ? )
But I tried the following model:
glmer(response ~ x1 + x2 + x3 + x4 +(x1 + x2 +x3 +x4 | year), ? )
it does estimate different slope coefficients for each year.
I don?t know what meanings are associated with these two different
syntaxes though, and I would really appreciate any information or
reference anyone can give to clarify this.

I would be glad to provide additional information that may be needed
about the models or the dataset.

I take the opportunity while writing this email to thank lme4 authors
for developing and improving the very useful package that is lme4!

Best regards,
Nicolas Deguines


From thierry.onkelinx at inbo.be  Thu Jun 11 19:17:01 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 11 Jun 2015 19:17:01 +0200
Subject: [R-sig-ME] lme4 - equal estimates of regression coefficients
 across levels of a random effect
In-Reply-To: <CAFzZfa2VRCa_w3bnrxHwfOkTAGu3+hL5jU5NnEOxfu7nZjKGMg@mail.gmail.com>
References: <CAFzZfa2VRCa_w3bnrxHwfOkTAGu3+hL5jU5NnEOxfu7nZjKGMg@mail.gmail.com>
Message-ID: <CAJuCY5w7HcXyF6j=H2Sz-_HVoVFW7rYvD8=Jut53q=-5o62ZjQ@mail.gmail.com>

Dear Nicolas,

Those models are different, hence you get different results. Note that two
levels are not enough to get stable variance estimates for the random
effect. See glmm wiki FAQ.
Op 11-jun.-2015 18:39 schreef "Nicolas Deguines" <nicodeguines at gmail.com>:

> Dear lme4 authors & users,
>
> I?m a postdoctoral research scholar working on the effect of
> precipitation on the food web of a grassland semi-arid ecosystem in
> California.
>
> I am analyzing my dataset with version 1.1-7 of the lme4 package with
> version 3.2.0 of R.
> I encountered an issue while running a glmer model that includes
> random effects from a categorical variable (?year?, 2010 and 2011) on
> the slope of four explanatory variables.
> Precisely, the estimated slope coefficients for 1 out of 4 explanatory
> variables are identical in the two years. However, when running a
> model including only this particular explanatory variable and the same
> random effect from year on slope, estimates are different for the two
> years (indeed, I did check that values are different in the two years.
>
> It also happens for other models I?m running, e.g. with that
> particular explanatory variable + two new ones: this time though, the
> slope coefficients are different for that particular variable but
> identical for the two new ones (nb: the response variable in this
> model differs from the 1st model discussed).
>
> Is this an issue that already occurred to other lme4 users? Any idea
> about what I may be doing wrong?
> I suspect it may come from the syntax of my models. I had fitted my model
> as:
> glmer(response ~ x1 + x2 + x3 + x4 +(x1|year) +(x2|year) +(x3|year)
> +(x4|year), ? )
> But I tried the following model:
> glmer(response ~ x1 + x2 + x3 + x4 +(x1 + x2 +x3 +x4 | year), ? )
> it does estimate different slope coefficients for each year.
> I don?t know what meanings are associated with these two different
> syntaxes though, and I would really appreciate any information or
> reference anyone can give to clarify this.
>
> I would be glad to provide additional information that may be needed
> about the models or the dataset.
>
> I take the opportunity while writing this email to thank lme4 authors
> for developing and improving the very useful package that is lme4!
>
> Best regards,
> Nicolas Deguines
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Thu Jun 11 19:22:04 2015
From: hannah.hlx at gmail.com (li li)
Date: Thu, 11 Jun 2015 13:22:04 -0400
Subject: [R-sig-ME] Error message in lme function and question about the
	residual plot
Message-ID: <CAHLnndba8qs=Mvt7hMLUaJjXDD3rZKXs0KjZ909bYw4ggevWDw@mail.gmail.com>

Hi all,
  I have the following data frame named "one" in which there is a
grouping factor method with three levels. The varibility is very
different among the three groups seen from the plot. I am trying to
compare three models as follows. I have the following two questions:
  1. As you can see the third model does not seem to work. I am not
sure whether it is a convergent issue.
  2. The first model doesnot take into account the variance
heterogeneity issue while the second one does. However, when I compare
the residual plot between mod1 and mod2, there is not much difference.
The residual for the second model still has much larger variance for
methods 2 and 3 than the method 1.

  Thanks very much!
  Hanna


> one
    method individual time       res
1        3         12    0 101.40000
2        3         12    3 101.50000
3        3         12    6 101.50000
4        3         12    9 101.30000
5        3         12   12 100.70000
6        3         12   15 101.00000
7        3         12   18 101.50000
14       3         10    0 101.30000
15       3         10    3 101.20000
16       3         10    6 101.50000
17       3         10    9 100.70000
18       3         10   12 101.50000
19       3         10   15 101.30000
20       3         10   18 101.30000
27       3         11    0 100.70000
28       3         11    3 101.10000
29       3         11    6 101.90000
30       3         11    9 100.80000
31       3         11   12  99.80000
32       3         11   15 100.60000
33       3         11   18 100.60000
40       3          1    0  97.50000
41       3          1    3  97.40000
42       3          1    6  97.70000
43       3          1    9  97.40000
44       3          1   12  97.30000
45       3          1   15  96.70000
46       3          1   18  96.60000
54       3          3    0  98.10000
55       3          3    3  98.50000
56       3          3    6  97.90000
57       3          3    9  97.90000
58       3          3   12  97.70000
59       3          3   15  98.00000
60       3          3   18  98.50000
67       3          6    0 100.20000
68       3          6    3  99.60000
69       3          6    6  99.90000
70       3          6    9  99.90000
71       3          6   12 100.30000
77       3          2    0  98.90000
78       3          2    3  98.90000
79       3          2    6  98.70000
80       3          2    9  98.90000
81       3          2   12  98.80000
82       3          2   15  97.80000
83       3          2   18  98.90000
90       3          4    0 100.20000
91       3          4    3  99.80000
92       3          4    6  99.50000
93       3          4    9 100.40000
96       3          5    0 100.70000
97       3          5    3 100.30000
98       3          5    6 100.70000
99       3          5    9 100.50000
102      3          7    0 100.90000
105      3          8    0  99.30000
108      3          9    0 100.20000
111      3         13    0 101.00000
114      3         14    0 100.80000
117      3         15    0 100.40000
8        2         12    0 108.00000
9        2         12   12  97.00000
21       2         10    0 112.00000
22       2         10   12  93.00000
34       2         11    0  98.00000
35       2         11   12  96.00000
47       2          1    0  94.00000
48       2          1   12 103.00000
49       2          1   18 103.00000
61       2          3    0  87.00000
62       2          3   12 105.00000
72       2          6    0 119.00000
73       2          6    3 105.00000
74       2          6   12  91.00000
84       2          2    0 105.00000
85       2          2   12 112.00000
95       2          4    0  96.00000
101      2          5    0 113.00000
104      2          7    0 106.00000
107      2          8    0  71.00000
110      2          9    0  95.00000
113      2         13    0  88.00000
116      2         14    0  86.00000
119      2         15    0  81.00000
86       1         12    0 105.90300
94       1         12   12  99.82400
10       1         12   15  91.26400
11       1         12   18  72.15000
191      1         10    0  91.14300
201      1         10   12 100.36800
211      1         10   15 104.79600
221      1         10   18 102.58200
301      1         11    0  78.32400
311      1         11   12  88.20900
321      1         11   15  95.52600
331      1         11   18 106.87200
411      1          1    0  99.04500
421      1          1   12  82.83600
431      1          1   15 116.51200
441      1          1   18  89.05600
52       1          3    0  97.81800
53       1          3   12  89.81500
541      1          3   15  82.11000
551      1          3   18  79.83400
611      1          6    0  89.06000
621      1          6   12 102.56500
701      1          2    0 112.32000
711      1          2   12 104.40000
721      1          2   15  90.06800
731      1          2   18 107.28000
781      1          4    0 125.92500
831      1          5    0  95.16000
851      1          7    0 111.28981
87       1          8    0 102.22482
89       1          9    0  91.61610
911      1         13    0 111.18053
931      1         14    0  91.70376
951      1         15    0  98.04994



library(nlme)
mod1 <- lme(fixed= res ~ method*time, random=~ 1+ time | individual, data=one)
summary(mod1)
anova(mod1)

mod2 <- lme(fixed= res ~ method*time, random=~ 1+ time | individual,
data=one, weights= varIdent(form=~1|method))
summary(mod2)
anova(mod2)

mod3 <- lme(fixed= res ~ method*time, random=~ 0+ method+ time |
individual, data=one, weights= varIdent(form=~1|assay))
summary(mod3)
anova(mod3)

par(mfrow=c(1,2))
plot(resid(mod1))
plot(resid(mod2))


From thierry.onkelinx at inbo.be  Thu Jun 11 19:44:05 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 11 Jun 2015 19:44:05 +0200
Subject: [R-sig-ME] Error message in lme function and question about the
 residual plot
In-Reply-To: <CAHLnndba8qs=Mvt7hMLUaJjXDD3rZKXs0KjZ909bYw4ggevWDw@mail.gmail.com>
References: <CAHLnndba8qs=Mvt7hMLUaJjXDD3rZKXs0KjZ909bYw4ggevWDw@mail.gmail.com>
Message-ID: <CAJuCY5ytc4g+dO3cniK+YWRjH_-VwSeGvaMxiu4PUBFuRpwR+Q@mail.gmail.com>

You need to add type ="norm" to resid() to see the effect of varIdent.

Make sure that assay is present in one before fitting model3
Op 11 jun. 2015 19:23 schreef "li li" <hannah.hlx at gmail.com>:

> Hi all,
>   I have the following data frame named "one" in which there is a
> grouping factor method with three levels. The varibility is very
> different among the three groups seen from the plot. I am trying to
> compare three models as follows. I have the following two questions:
>   1. As you can see the third model does not seem to work. I am not
> sure whether it is a convergent issue.
>   2. The first model doesnot take into account the variance
> heterogeneity issue while the second one does. However, when I compare
> the residual plot between mod1 and mod2, there is not much difference.
> The residual for the second model still has much larger variance for
> methods 2 and 3 than the method 1.
>
>   Thanks very much!
>   Hanna
>
>
> > one
>     method individual time       res
> 1        3         12    0 101.40000
> 2        3         12    3 101.50000
> 3        3         12    6 101.50000
> 4        3         12    9 101.30000
> 5        3         12   12 100.70000
> 6        3         12   15 101.00000
> 7        3         12   18 101.50000
> 14       3         10    0 101.30000
> 15       3         10    3 101.20000
> 16       3         10    6 101.50000
> 17       3         10    9 100.70000
> 18       3         10   12 101.50000
> 19       3         10   15 101.30000
> 20       3         10   18 101.30000
> 27       3         11    0 100.70000
> 28       3         11    3 101.10000
> 29       3         11    6 101.90000
> 30       3         11    9 100.80000
> 31       3         11   12  99.80000
> 32       3         11   15 100.60000
> 33       3         11   18 100.60000
> 40       3          1    0  97.50000
> 41       3          1    3  97.40000
> 42       3          1    6  97.70000
> 43       3          1    9  97.40000
> 44       3          1   12  97.30000
> 45       3          1   15  96.70000
> 46       3          1   18  96.60000
> 54       3          3    0  98.10000
> 55       3          3    3  98.50000
> 56       3          3    6  97.90000
> 57       3          3    9  97.90000
> 58       3          3   12  97.70000
> 59       3          3   15  98.00000
> 60       3          3   18  98.50000
> 67       3          6    0 100.20000
> 68       3          6    3  99.60000
> 69       3          6    6  99.90000
> 70       3          6    9  99.90000
> 71       3          6   12 100.30000
> 77       3          2    0  98.90000
> 78       3          2    3  98.90000
> 79       3          2    6  98.70000
> 80       3          2    9  98.90000
> 81       3          2   12  98.80000
> 82       3          2   15  97.80000
> 83       3          2   18  98.90000
> 90       3          4    0 100.20000
> 91       3          4    3  99.80000
> 92       3          4    6  99.50000
> 93       3          4    9 100.40000
> 96       3          5    0 100.70000
> 97       3          5    3 100.30000
> 98       3          5    6 100.70000
> 99       3          5    9 100.50000
> 102      3          7    0 100.90000
> 105      3          8    0  99.30000
> 108      3          9    0 100.20000
> 111      3         13    0 101.00000
> 114      3         14    0 100.80000
> 117      3         15    0 100.40000
> 8        2         12    0 108.00000
> 9        2         12   12  97.00000
> 21       2         10    0 112.00000
> 22       2         10   12  93.00000
> 34       2         11    0  98.00000
> 35       2         11   12  96.00000
> 47       2          1    0  94.00000
> 48       2          1   12 103.00000
> 49       2          1   18 103.00000
> 61       2          3    0  87.00000
> 62       2          3   12 105.00000
> 72       2          6    0 119.00000
> 73       2          6    3 105.00000
> 74       2          6   12  91.00000
> 84       2          2    0 105.00000
> 85       2          2   12 112.00000
> 95       2          4    0  96.00000
> 101      2          5    0 113.00000
> 104      2          7    0 106.00000
> 107      2          8    0  71.00000
> 110      2          9    0  95.00000
> 113      2         13    0  88.00000
> 116      2         14    0  86.00000
> 119      2         15    0  81.00000
> 86       1         12    0 105.90300
> 94       1         12   12  99.82400
> 10       1         12   15  91.26400
> 11       1         12   18  72.15000
> 191      1         10    0  91.14300
> 201      1         10   12 100.36800
> 211      1         10   15 104.79600
> 221      1         10   18 102.58200
> 301      1         11    0  78.32400
> 311      1         11   12  88.20900
> 321      1         11   15  95.52600
> 331      1         11   18 106.87200
> 411      1          1    0  99.04500
> 421      1          1   12  82.83600
> 431      1          1   15 116.51200
> 441      1          1   18  89.05600
> 52       1          3    0  97.81800
> 53       1          3   12  89.81500
> 541      1          3   15  82.11000
> 551      1          3   18  79.83400
> 611      1          6    0  89.06000
> 621      1          6   12 102.56500
> 701      1          2    0 112.32000
> 711      1          2   12 104.40000
> 721      1          2   15  90.06800
> 731      1          2   18 107.28000
> 781      1          4    0 125.92500
> 831      1          5    0  95.16000
> 851      1          7    0 111.28981
> 87       1          8    0 102.22482
> 89       1          9    0  91.61610
> 911      1         13    0 111.18053
> 931      1         14    0  91.70376
> 951      1         15    0  98.04994
>
>
>
> library(nlme)
> mod1 <- lme(fixed= res ~ method*time, random=~ 1+ time | individual,
> data=one)
> summary(mod1)
> anova(mod1)
>
> mod2 <- lme(fixed= res ~ method*time, random=~ 1+ time | individual,
> data=one, weights= varIdent(form=~1|method))
> summary(mod2)
> anova(mod2)
>
> mod3 <- lme(fixed= res ~ method*time, random=~ 0+ method+ time |
> individual, data=one, weights= varIdent(form=~1|assay))
> summary(mod3)
> anova(mod3)
>
> par(mfrow=c(1,2))
> plot(resid(mod1))
> plot(resid(mod2))
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Thu Jun 11 20:27:46 2015
From: hannah.hlx at gmail.com (li li)
Date: Thu, 11 Jun 2015 14:27:46 -0400
Subject: [R-sig-ME] Error message in lme function and question about the
 residual plot
In-Reply-To: <CAJuCY5ytc4g+dO3cniK+YWRjH_-VwSeGvaMxiu4PUBFuRpwR+Q@mail.gmail.com>
References: <CAHLnndba8qs=Mvt7hMLUaJjXDD3rZKXs0KjZ909bYw4ggevWDw@mail.gmail.com>
	<CAJuCY5ytc4g+dO3cniK+YWRjH_-VwSeGvaMxiu4PUBFuRpwR+Q@mail.gmail.com>
Message-ID: <CAHLnndZxAfS_e1_w-FCsLB_j=LstuR5FnNuPtcoycEqwXg4JjQ@mail.gmail.com>

Thanks very mcuh for reply.
  For question 1: There was a typo model 3. The model should be the following.
But I still get error message as follows.

> mod3 <- lme(fixed= res ~ method*time, random=~ 0+ method+ time | individual, data=one, weights= varIdent(form=~1|method))
Error in logLik.reStruct(object, conLin) :
  NA/NaN/Inf in foreign function call (arg 3)
  Thanks.
    Li

2015-06-11 13:44 GMT-04:00, Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> You need to add type ="norm" to resid() to see the effect of varIdent.
>
> Make sure that assay is present in one before fitting model3
> Op 11 jun. 2015 19:23 schreef "li li" <hannah.hlx at gmail.com>:
>
>> Hi all,
>>   I have the following data frame named "one" in which there is a
>> grouping factor method with three levels. The varibility is very
>> different among the three groups seen from the plot. I am trying to
>> compare three models as follows. I have the following two questions:
>>   1. As you can see the third model does not seem to work. I am not
>> sure whether it is a convergent issue.
>>   2. The first model doesnot take into account the variance
>> heterogeneity issue while the second one does. However, when I compare
>> the residual plot between mod1 and mod2, there is not much difference.
>> The residual for the second model still has much larger variance for
>> methods 2 and 3 than the method 1.
>>
>>   Thanks very much!
>>   Hanna
>>
>>
>> > one
>>     method individual time       res
>> 1        3         12    0 101.40000
>> 2        3         12    3 101.50000
>> 3        3         12    6 101.50000
>> 4        3         12    9 101.30000
>> 5        3         12   12 100.70000
>> 6        3         12   15 101.00000
>> 7        3         12   18 101.50000
>> 14       3         10    0 101.30000
>> 15       3         10    3 101.20000
>> 16       3         10    6 101.50000
>> 17       3         10    9 100.70000
>> 18       3         10   12 101.50000
>> 19       3         10   15 101.30000
>> 20       3         10   18 101.30000
>> 27       3         11    0 100.70000
>> 28       3         11    3 101.10000
>> 29       3         11    6 101.90000
>> 30       3         11    9 100.80000
>> 31       3         11   12  99.80000
>> 32       3         11   15 100.60000
>> 33       3         11   18 100.60000
>> 40       3          1    0  97.50000
>> 41       3          1    3  97.40000
>> 42       3          1    6  97.70000
>> 43       3          1    9  97.40000
>> 44       3          1   12  97.30000
>> 45       3          1   15  96.70000
>> 46       3          1   18  96.60000
>> 54       3          3    0  98.10000
>> 55       3          3    3  98.50000
>> 56       3          3    6  97.90000
>> 57       3          3    9  97.90000
>> 58       3          3   12  97.70000
>> 59       3          3   15  98.00000
>> 60       3          3   18  98.50000
>> 67       3          6    0 100.20000
>> 68       3          6    3  99.60000
>> 69       3          6    6  99.90000
>> 70       3          6    9  99.90000
>> 71       3          6   12 100.30000
>> 77       3          2    0  98.90000
>> 78       3          2    3  98.90000
>> 79       3          2    6  98.70000
>> 80       3          2    9  98.90000
>> 81       3          2   12  98.80000
>> 82       3          2   15  97.80000
>> 83       3          2   18  98.90000
>> 90       3          4    0 100.20000
>> 91       3          4    3  99.80000
>> 92       3          4    6  99.50000
>> 93       3          4    9 100.40000
>> 96       3          5    0 100.70000
>> 97       3          5    3 100.30000
>> 98       3          5    6 100.70000
>> 99       3          5    9 100.50000
>> 102      3          7    0 100.90000
>> 105      3          8    0  99.30000
>> 108      3          9    0 100.20000
>> 111      3         13    0 101.00000
>> 114      3         14    0 100.80000
>> 117      3         15    0 100.40000
>> 8        2         12    0 108.00000
>> 9        2         12   12  97.00000
>> 21       2         10    0 112.00000
>> 22       2         10   12  93.00000
>> 34       2         11    0  98.00000
>> 35       2         11   12  96.00000
>> 47       2          1    0  94.00000
>> 48       2          1   12 103.00000
>> 49       2          1   18 103.00000
>> 61       2          3    0  87.00000
>> 62       2          3   12 105.00000
>> 72       2          6    0 119.00000
>> 73       2          6    3 105.00000
>> 74       2          6   12  91.00000
>> 84       2          2    0 105.00000
>> 85       2          2   12 112.00000
>> 95       2          4    0  96.00000
>> 101      2          5    0 113.00000
>> 104      2          7    0 106.00000
>> 107      2          8    0  71.00000
>> 110      2          9    0  95.00000
>> 113      2         13    0  88.00000
>> 116      2         14    0  86.00000
>> 119      2         15    0  81.00000
>> 86       1         12    0 105.90300
>> 94       1         12   12  99.82400
>> 10       1         12   15  91.26400
>> 11       1         12   18  72.15000
>> 191      1         10    0  91.14300
>> 201      1         10   12 100.36800
>> 211      1         10   15 104.79600
>> 221      1         10   18 102.58200
>> 301      1         11    0  78.32400
>> 311      1         11   12  88.20900
>> 321      1         11   15  95.52600
>> 331      1         11   18 106.87200
>> 411      1          1    0  99.04500
>> 421      1          1   12  82.83600
>> 431      1          1   15 116.51200
>> 441      1          1   18  89.05600
>> 52       1          3    0  97.81800
>> 53       1          3   12  89.81500
>> 541      1          3   15  82.11000
>> 551      1          3   18  79.83400
>> 611      1          6    0  89.06000
>> 621      1          6   12 102.56500
>> 701      1          2    0 112.32000
>> 711      1          2   12 104.40000
>> 721      1          2   15  90.06800
>> 731      1          2   18 107.28000
>> 781      1          4    0 125.92500
>> 831      1          5    0  95.16000
>> 851      1          7    0 111.28981
>> 87       1          8    0 102.22482
>> 89       1          9    0  91.61610
>> 911      1         13    0 111.18053
>> 931      1         14    0  91.70376
>> 951      1         15    0  98.04994
>>
>>
>>
>> library(nlme)
>> mod1 <- lme(fixed= res ~ method*time, random=~ 1+ time | individual,
>> data=one)
>> summary(mod1)
>> anova(mod1)
>>
>> mod2 <- lme(fixed= res ~ method*time, random=~ 1+ time | individual,
>> data=one, weights= varIdent(form=~1|method))
>> summary(mod2)
>> anova(mod2)
>>
>> mod3 <- lme(fixed= res ~ method*time, random=~ 0+ method+ time |
>> individual, data=one, weights= varIdent(form=~1|assay))
>> summary(mod3)
>> anova(mod3)
>>
>> par(mfrow=c(1,2))
>> plot(resid(mod1))
>> plot(resid(mod2))
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From patricia.soto.b at gmail.com  Mon Jun 15 06:27:02 2015
From: patricia.soto.b at gmail.com (Patricia Soto)
Date: Sun, 14 Jun 2015 23:27:02 -0500
Subject: [R-sig-ME] Set and interpret interaction terms in MCMCglmm
Message-ID: <CAOCX56oLbFo3nTk1963+1V0im4DsGncWN01syp0j8uJks1wZGg@mail.gmail.com>

Greetings Everyone,

I am using Bayesian statistics for the first time in my life and while I am
delighted with MCMCglmm, I do need extra input to move on to the next part
of my analysis. The basic question I have is how to set and interpret the
output of interaction terms.

First the description of my data:

Dependent variable D: 10 categories
Explanatory variable X1: 2 categories: 0, 1
Explanatory variable X2: 2 categories: 0, 1
Random effects: X3 and X4.

Second: The reason why I am testing interaction terms:

The reviewer of the paper (that I need to resubmit!) suggests we analyze
the effect of the interaction X1 * X2 on the dependent variable. After tons
of reading (this mailing lists, online examples, and so), I was able to
craft a prior and a model:

Third: my model (so far):

m<- MCMCglmm(D ~ trait - 1 + X1 + X1:trait * X2:trait, random = ~
us(trait):X3 + us(trait):X4, prior = prior3, rcov = ~us(trait):units, data
= our_data, family = "categorical", verbose = TRUE, nitt = 13000*1,
burnin=3000*1, thin = 10*1)

Fourth: The issue;

1. To account for whether the interaction between X1 and X2 has an effect
on the dependent variable, do I have to explicitly add the interaction term
X1 * X2, or D ~ trait - 1 + X1 + X2 would be enough?
2. How could I interpret the following outputs?:
             post.mean  l-95% CI  u-95% CI eff.samp  pMCMC
D.8:X1:X2            -1.98682       -3.40467     -0.79391
15.226       0.002 **
 Would it make sense to say: When X2 = 1 and X1 = 1, then the probability
of getting D.8 decreases? (motivation: when we started our study, our
expectation was exactly the opposite; therefore, I want to rule out any
misunderstanding in the statistical modeling).

Thanks!

Patricia

patricia.soto.b at gmail.com

	[[alternative HTML version deleted]]


From marselalv at gmail.com  Mon Jun 15 15:06:31 2015
From: marselalv at gmail.com (Marsela Alvanopoulou)
Date: Mon, 15 Jun 2015 15:06:31 +0200
Subject: [R-sig-ME] clustered data with glmer() and glmmPQL()
Message-ID: <CAEB8rrS=sg1z9AdFHggRmXVGL4Tve6mULTh6Fe5RxFvwbjLh9g@mail.gmail.com>

Hello,

I'm
? ?
a master student from
? ?
Greece. I?m trying to model count data with
? ?
GLMM (lme4
? ?
package), using as discrete response variable the number of parasites per
fish and as categorical predictor variable three
? ?
different species.
? ?
I'm using as random effect the three different tanks I used and as fixed
the infection level
??
.
?
?
This is the model I'm running:

mod
? ?
<-
? ?
glmer
? ?
(parasite~species+(1|tank),
? ?
family=poisson
??
, data=mydata)

I noticed that the estimate of the intercept does not give the mean of the
first species, so I ran a simple glm model to get the estimate. With
summary() I got the p values that allow me to reject my hypothesis and
continue
? ?
to the Tukey test. Is it legal to use
?
TukeyHSD(aov(parasite~species, data=mydata))
? ?
?
?
Finally I tested the assumptions
? ?
and
? ?
I found violation of normality and independence.

I also tried MASS package where the assumption of independent residuals was
not violated anymore but the histogram gave me a much more skewed
distribution, but also anova() is not available for QTLs.

mod2 <- glmmPQL (parasite~species, random=~1|tank, family=poisson,
data=mydata)

Thank you in advance for your help.

Maria

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jun 15 16:34:38 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 15 Jun 2015 16:34:38 +0200
Subject: [R-sig-ME] clustered data with glmer() and glmmPQL()
In-Reply-To: <CAEB8rrS=sg1z9AdFHggRmXVGL4Tve6mULTh6Fe5RxFvwbjLh9g@mail.gmail.com>
References: <CAEB8rrS=sg1z9AdFHggRmXVGL4Tve6mULTh6Fe5RxFvwbjLh9g@mail.gmail.com>
Message-ID: <CAJuCY5ytOWtwx0ViwymzEwhg35=BcVSH5gP312FRQAZy6M1x_A@mail.gmail.com>

Dear Maria,

The assumption of normality is only required for the residuals of linear
(mixed) models, not for the residuals of generalised linear (mixed) models.

You can't use aov() for two reasons: it assumes a Gaussian distribution and
it assumes independent observations.

mod1 and mod2 are in principle the same model (but fitted differently).
Both assume the same correlation structure.

3 levels is not enough to get a sensible variance estimate for a random
effect. See glmm wiki faq for more details.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-15 15:06 GMT+02:00 Marsela Alvanopoulou <marselalv at gmail.com>:

> Hello,
>
> I'm
> ? ?
> a master student from
> ? ?
> Greece. I?m trying to model count data with
> ? ?
> GLMM (lme4
> ? ?
> package), using as discrete response variable the number of parasites per
> fish and as categorical predictor variable three
> ? ?
> different species.
> ? ?
> I'm using as random effect the three different tanks I used and as fixed
> the infection level
> ??
> .
> ?
> ?
> This is the model I'm running:
>
> mod
> ? ?
> <-
> ? ?
> glmer
> ? ?
> (parasite~species+(1|tank),
> ? ?
> family=poisson
> ??
> , data=mydata)
>
> I noticed that the estimate of the intercept does not give the mean of the
> first species, so I ran a simple glm model to get the estimate. With
> summary() I got the p values that allow me to reject my hypothesis and
> continue
> ? ?
> to the Tukey test. Is it legal to use
> ?
> TukeyHSD(aov(parasite~species, data=mydata))
> ? ?
> ?
> ?
> Finally I tested the assumptions
> ? ?
> and
> ? ?
> I found violation of normality and independence.
>
> I also tried MASS package where the assumption of independent residuals was
> not violated anymore but the histogram gave me a much more skewed
> distribution, but also anova() is not available for QTLs.
>
> mod2 <- glmmPQL (parasite~species, random=~1|tank, family=poisson,
> data=mydata)
>
> Thank you in advance for your help.
>
> Maria
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From r.travitzki at gmail.com  Mon Jun 15 18:59:30 2015
From: r.travitzki at gmail.com (Rodrigo Travitzki)
Date: Mon, 15 Jun 2015 18:59:30 +0200
Subject: [R-sig-ME] sample with two weights in different levels
Message-ID: <557F0472.50207@gmail.com>

Hi guys,
the problem of using data with (one) weight in nlme was solved!
(as Ben explained here: 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022570.html).

Now, the problem is how to use two weights, one in individual level and 
other in an aggregated level. Sorry about this basic questions, but 
actually I cound't find reliable information, and did not understand the 
help very well.

So, based on help information, I tried this code, that seems to run ok 
in most data. But I'm not sure this is the right solution, it look likes 
strange to me, because I need to insert the same information twice. 
Also, results of varPower and varExp seems to be similar.

Could you please help me once more?


# variables in dataframe 'dd'
# WT1 - weigth in desaggregated level (level 1)
# WT2 - weigth in aggregated level (level 2)
# ID_L2 - id for each group of level 2

# create object of aggregated weights with their names
ff=aggregate(dd$WT2, list(dd$ID_L2), function(x){1/(x[1])})
ff2=ff$x
names(ff2)=ff$Group.1

# define weights
ww=varComb(varFixed(~I(1/WT1)), varPower(fixed=ff2, form=~I(1/ WT2)|ID_L2))

# fit model
lme(fixed=depend.var~idepend.var, random=~1|ID_L2, weights=ww, 
na.action=na.omit, data=dd)


Thank you,
Rodrigo


From marselalv at gmail.com  Tue Jun 16 01:54:25 2015
From: marselalv at gmail.com (Marsela Alvanopoulou)
Date: Tue, 16 Jun 2015 01:54:25 +0200
Subject: [R-sig-ME] clustered data with glmer() and glmmPQL()
In-Reply-To: <CAJuCY5ytOWtwx0ViwymzEwhg35=BcVSH5gP312FRQAZy6M1x_A@mail.gmail.com>
References: <CAEB8rrS=sg1z9AdFHggRmXVGL4Tve6mULTh6Fe5RxFvwbjLh9g@mail.gmail.com>
	<CAJuCY5ytOWtwx0ViwymzEwhg35=BcVSH5gP312FRQAZy6M1x_A@mail.gmail.com>
Message-ID: <CAEB8rrSWhDutV2Jg_6BTps6BUvmRt0ORhmZHT+0+MPPVTMPi7w@mail.gmail.com>

Hi again,

Thank you very much for your response. I found most of the answers in glmm
wiki faq. I used MASS::glmmPQL for the model, car::Anova and multcomp::glht
for the hypothesis testing and I still need some work to check the effect
of the tank, if any.

I also want to check if there is a significant difference on the number of
parasites per gram (continuous response variable). I multiplied all values
by 100 to get a discrete variable like before. Does that affect the final
conclusions?

Thanks again!

On Mon, Jun 15, 2015 at 4:34 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Maria,
>
> The assumption of normality is only required for the residuals of linear
> (mixed) models, not for the residuals of generalised linear (mixed) models.
>
> You can't use aov() for two reasons: it assumes a Gaussian distribution
> and it assumes independent observations.
>
> mod1 and mod2 are in principle the same model (but fitted differently).
> Both assume the same correlation structure.
>
> 3 levels is not enough to get a sensible variance estimate for a random
> effect. See glmm wiki faq for more details.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-06-15 15:06 GMT+02:00 Marsela Alvanopoulou <marselalv at gmail.com>:
>
>> Hello,
>>
>> I'm
>> ? ?
>> a master student from
>> ? ?
>> Greece. I?m trying to model count data with
>> ? ?
>> GLMM (lme4
>> ? ?
>> package), using as discrete response variable the number of parasites per
>> fish and as categorical predictor variable three
>> ? ?
>> different species.
>> ? ?
>> I'm using as random effect the three different tanks I used and as fixed
>> the infection level
>> ??
>> .
>> ?
>> ?
>> This is the model I'm running:
>>
>> mod
>> ? ?
>> <-
>> ? ?
>> glmer
>> ? ?
>> (parasite~species+(1|tank),
>> ? ?
>> family=poisson
>> ??
>> , data=mydata)
>>
>> I noticed that the estimate of the intercept does not give the mean of the
>> first species, so I ran a simple glm model to get the estimate. With
>> summary() I got the p values that allow me to reject my hypothesis and
>> continue
>> ? ?
>> to the Tukey test. Is it legal to use
>> ?
>> TukeyHSD(aov(parasite~species, data=mydata))
>> ? ?
>> ?
>> ?
>> Finally I tested the assumptions
>> ? ?
>> and
>> ? ?
>> I found violation of normality and independence.
>>
>> I also tried MASS package where the assumption of independent residuals
>> was
>> not violated anymore but the histogram gave me a much more skewed
>> distribution, but also anova() is not available for QTLs.
>>
>> mod2 <- glmmPQL (parasite~species, random=~1|tank, family=poisson,
>> data=mydata)
>>
>> Thank you in advance for your help.
>>
>> Maria
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
Marsela Alvanopoulou
MSc Student, Biology Dept.,
University of Bergen, Norway

*e-mail: Marsela.Alvanopoulou at student.uib.no
<Marsela.Alvanopoulou at student.uib.no>*
*e-mail: marsela.alvanopoulou at imr.no <marsela.alvanopoulou at imr.no>*
*linkedin: gr.linkedin.com/pub/marsela-alvanopoulou/69/3b3/410/
<http://gr.linkedin.com/pub/marsela-alvanopoulou/69/3b3/410/>*

	[[alternative HTML version deleted]]


From J.Burgueno at cgiar.org  Mon Jun 15 19:25:16 2015
From: J.Burgueno at cgiar.org (=?utf-8?B?QlVSR1VFw5FPIEZFUlJFSVJBLCBKdWFuIEFuZHJlcyAoQ0lNTVlUKQ==?=)
Date: Mon, 15 Jun 2015 17:25:16 +0000
Subject: [R-sig-ME] Spatial analysis
Message-ID: <000f424b.4a8c05b30bbadbfb@cgiar.org>

Does anybody know how to analyze a complete block design modeling residual error with an AR1?AR1 model?

? means kronecker product

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Tue Jun 16 03:29:17 2015
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 15 Jun 2015 20:29:17 -0500
Subject: [R-sig-ME] Spatial analysis
In-Reply-To: <000f424b.4a8c05b30bbadbfb@cgiar.org>
References: <000f424b.4a8c05b30bbadbfb@cgiar.org>
Message-ID: <CAKFxdiRPD4dUrK+3n_4ktOXVS8LC8Y2EOVsX=8n0EaPeXxEzmQ@mail.gmail.com>

You can do this with asreml-r.  For example:
http://www.inside-r.org/packages/cran/agridat/docs/stroup.nin

Kevin

On Mon, Jun 15, 2015 at 12:25 PM, BURGUE?O FERREIRA, Juan Andres
(CIMMYT) <J.Burgueno at cgiar.org> wrote:
> Does anybody know how to analyze a complete block design modeling residual error with an AR1?AR1 model?
>
> ? means kronecker product
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Kevin Wright


From thierry.onkelinx at inbo.be  Tue Jun 16 09:45:29 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 16 Jun 2015 09:45:29 +0200
Subject: [R-sig-ME] clustered data with glmer() and glmmPQL()
In-Reply-To: <CAEB8rrSWhDutV2Jg_6BTps6BUvmRt0ORhmZHT+0+MPPVTMPi7w@mail.gmail.com>
References: <CAEB8rrS=sg1z9AdFHggRmXVGL4Tve6mULTh6Fe5RxFvwbjLh9g@mail.gmail.com>
	<CAJuCY5ytOWtwx0ViwymzEwhg35=BcVSH5gP312FRQAZy6M1x_A@mail.gmail.com>
	<CAEB8rrSWhDutV2Jg_6BTps6BUvmRt0ORhmZHT+0+MPPVTMPi7w@mail.gmail.com>
Message-ID: <CAJuCY5zynWJfbvwAoiuctwmM_jcEvJU=nzeovDTsaR8trc=zww@mail.gmail.com>

You can use tank as a fixed effect instead of a random effect. In that case
your model reduces to a general linear model. Personally I prefer a
likelihood based model (glmer) over a penalised quasi-likelihood model
(glmmPQL) unless I need things that are not available with glmer.

You need to use the log(weight) of the fish as an offset factor instead of
calculating the ratio.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-16 1:54 GMT+02:00 Marsela Alvanopoulou <marselalv at gmail.com>:

> Hi again,
>
> Thank you very much for your response. I found most of the answers in glmm
> wiki faq. I used MASS::glmmPQL for the model, car::Anova and multcomp::glht
> for the hypothesis testing and I still need some work to check the effect
> of the tank, if any.
>
> I also want to check if there is a significant difference on the number of
> parasites per gram (continuous response variable). I multiplied all values
> by 100 to get a discrete variable like before. Does that affect the final
> conclusions?
>
> Thanks again!
>
> On Mon, Jun 15, 2015 at 4:34 PM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Maria,
>>
>> The assumption of normality is only required for the residuals of linear
>> (mixed) models, not for the residuals of generalised linear (mixed) models.
>>
>> You can't use aov() for two reasons: it assumes a Gaussian distribution
>> and it assumes independent observations.
>>
>> mod1 and mod2 are in principle the same model (but fitted differently).
>> Both assume the same correlation structure.
>>
>> 3 levels is not enough to get a sensible variance estimate for a random
>> effect. See glmm wiki faq for more details.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-06-15 15:06 GMT+02:00 Marsela Alvanopoulou <marselalv at gmail.com>:
>>
>>> Hello,
>>>
>>> I'm
>>> ? ?
>>> a master student from
>>> ? ?
>>> Greece. I?m trying to model count data with
>>> ? ?
>>> GLMM (lme4
>>> ? ?
>>> package), using as discrete response variable the number of parasites per
>>> fish and as categorical predictor variable three
>>> ? ?
>>> different species.
>>> ? ?
>>> I'm using as random effect the three different tanks I used and as fixed
>>> the infection level
>>> ??
>>> .
>>> ?
>>> ?
>>> This is the model I'm running:
>>>
>>> mod
>>> ? ?
>>> <-
>>> ? ?
>>> glmer
>>> ? ?
>>> (parasite~species+(1|tank),
>>> ? ?
>>> family=poisson
>>> ??
>>> , data=mydata)
>>>
>>> I noticed that the estimate of the intercept does not give the mean of
>>> the
>>> first species, so I ran a simple glm model to get the estimate. With
>>> summary() I got the p values that allow me to reject my hypothesis and
>>> continue
>>> ? ?
>>> to the Tukey test. Is it legal to use
>>> ?
>>> TukeyHSD(aov(parasite~species, data=mydata))
>>> ? ?
>>> ?
>>> ?
>>> Finally I tested the assumptions
>>> ? ?
>>> and
>>> ? ?
>>> I found violation of normality and independence.
>>>
>>> I also tried MASS package where the assumption of independent residuals
>>> was
>>> not violated anymore but the histogram gave me a much more skewed
>>> distribution, but also anova() is not available for QTLs.
>>>
>>> mod2 <- glmmPQL (parasite~species, random=~1|tank, family=poisson,
>>> data=mydata)
>>>
>>> Thank you in advance for your help.
>>>
>>> Maria
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Marsela Alvanopoulou
> MSc Student, Biology Dept.,
> University of Bergen, Norway
>
> *e-mail: Marsela.Alvanopoulou at student.uib.no
> <Marsela.Alvanopoulou at student.uib.no>*
> *e-mail: marsela.alvanopoulou at imr.no <marsela.alvanopoulou at imr.no>*
> *linkedin: gr.linkedin.com/pub/marsela-alvanopoulou/69/3b3/410/
> <http://gr.linkedin.com/pub/marsela-alvanopoulou/69/3b3/410/>*
>

	[[alternative HTML version deleted]]


From akanksha.s1988 at gmail.com  Tue Jun 16 15:46:07 2015
From: akanksha.s1988 at gmail.com (Akanksha Singh)
Date: Tue, 16 Jun 2015 19:16:07 +0530
Subject: [R-sig-ME] (no subject)
Message-ID: <CAMKukUtm8AhzOQU2oGBocanf=ZN8QURML_zFf0P_=R776NS6XA@mail.gmail.com>

Sir,
I have used lme4 package to apply mixed model as follows.

lmer(LL ~ TMT +(1|FamID), data=fp1) -> lm

>From this I used lsmeans to extract the mean of each treatment and then
used it to define a function as follows:

myfcn = function(lm) {
lsm = predict(lsmeans(lm, c("TMT")))
apply(matrix(lsm, ncol = 2),  1,
function(x) diff(range(x)) / max(x) )
}

And then used the bootmer method to find the confidence interval of this
function as follows:

LL.boot <- bootMer(lm, myfcn, nsim=999, use.u=F, type="parametric")
boot.ci(LL.boot, index=1, type=c("norm", "basic", "perc"))

I have done this for three different data using the same procedure.
So my problem is that now I want to find out bootstrapped correlation and
its confidence interval using these three values of three dataset of the
function together. I know bootstrap cannot be done with three values, if I
store the values in a variable and then use it. So is there any method so I
can apply the bootstrap correlation on these three functions of three data
sets together. Sir I am very new to R and don't know about any programming
tricks. I will be highly greatful to you if you could help me out.

-- 
Thanks
Akanksha Singh

	[[alternative HTML version deleted]]


From ali_482002 at yahoo.com  Tue Jun 16 05:49:39 2015
From: ali_482002 at yahoo.com (ali)
Date: Tue, 16 Jun 2015 03:49:39 +0000 (UTC)
Subject: [R-sig-ME] mixed effect modeling with imputed data set
Message-ID: <loom.20150616T054603-176@post.gmane.org>

Hi all
I imputed my data using multiple imputation procedure in STATA. I would like
to conduct mixed effect modeling on the imputed data set in R. I do not know
how to write the code over the imputed data set.
My code is:	
fit <- glmer(y ~ x1+x2 +x3+(1|regiogid),family= binomial("logit"), data =mydata)

Best Regards


From dfulop.ucd at gmail.com  Tue Jun 16 18:26:59 2015
From: dfulop.ucd at gmail.com (Daniel Fulop)
Date: Tue, 16 Jun 2015 09:26:59 -0700
Subject: [R-sig-ME] mixed effect modeling with imputed data set
In-Reply-To: <loom.20150616T054603-176@post.gmane.org>
References: <loom.20150616T054603-176@post.gmane.org>
Message-ID: <55804E53.8040403@gmail.com>

Use one of the apply functions to iterate over your imputed datasets.

If your imputed datasets are in columns 5 through n+4 of "mydata" (i.e. 
assuming that x1, x2, x3, and regioid are in columns 1:4), the you could 
do something like:

model.list <- lapply(1:n, function(i)

glmer(mydata[,i+4] ~ x1+x2 +x3+(1|regiogid),family= binomial("logit"), data=mydata) )

The output will then be a list of model objects (i.e. model fits).  You 
can then iterated through this results list in order to calculate mean 
parameter values from all your imputed data fits.

Or, likewise:

model.list <- lapply(5:ncol(mydata), function(i) ...

Hope this helps,
Dan.

ali via R-sig-mixed-models wrote:
> Hi all
> I imputed my data using multiple imputation procedure in STATA. I would like
> to conduct mixed effect modeling on the imputed data set in R. I do not know
> how to write the code over the imputed data set.
> My code is:	
> fit<- glmer(y ~ x1+x2 +x3+(1|regiogid),family= binomial("logit"), data =mydata)
>
> Best Regards
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616

510-253-7462
dfulop at ucdavis.edu


From bbolker at gmail.com  Wed Jun 17 03:21:49 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 16 Jun 2015 21:21:49 -0400
Subject: [R-sig-ME] mixed effect modeling with imputed data set
In-Reply-To: <55804E53.8040403@gmail.com>
References: <loom.20150616T054603-176@post.gmane.org>
	<55804E53.8040403@gmail.com>
Message-ID: <CABghstTnYGE+52mtqRFM=yZsUmp_=KBCQQ8qXVZ-X8qVd0g06w@mail.gmail.com>

  For convenience, you might want to consider using imputation with
the 'mice' package in order to
stay within R for your analysis (I don't know Stata's capabilities in
this area; I'd expect them to be pretty good,
but it is my impression that 'mice' is also quite well-written/full-featured)

On Tue, Jun 16, 2015 at 12:26 PM, Daniel Fulop <dfulop.ucd at gmail.com> wrote:
> Use one of the apply functions to iterate over your imputed datasets.
>
> If your imputed datasets are in columns 5 through n+4 of "mydata" (i.e.
> assuming that x1, x2, x3, and regioid are in columns 1:4), the you could do
> something like:
>
> model.list <- lapply(1:n, function(i)
>
> glmer(mydata[,i+4] ~ x1+x2 +x3+(1|regiogid),family= binomial("logit"),
> data=mydata) )
>
> The output will then be a list of model objects (i.e. model fits).  You can
> then iterated through this results list in order to calculate mean parameter
> values from all your imputed data fits.
>
> Or, likewise:
>
> model.list <- lapply(5:ncol(mydata), function(i) ...
>
> Hope this helps,
> Dan.
>
>
> ali via R-sig-mixed-models wrote:
>>
>> Hi all
>> I imputed my data using multiple imputation procedure in STATA. I would
>> like
>> to conduct mixed effect modeling on the imputed data set in R. I do not
>> know
>> how to write the code over the imputed data set.
>> My code is:
>> fit<- glmer(y ~ x1+x2 +x3+(1|regiogid),family= binomial("logit"), data
>> =mydata)
>>
>> Best Regards
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Daniel Fulop, Ph.D.
> Postdoctoral Scholar
> Dept. Plant Biology, UC Davis
> Maloof Lab, Rm. 2220
> Life Sciences Addition, One Shields Ave.
> Davis, CA 95616
>
> 510-253-7462
> dfulop at ucdavis.edu
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ken.beath at mq.edu.au  Wed Jun 17 03:29:15 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 17 Jun 2015 11:29:15 +1000
Subject: [R-sig-ME] mixed effect modeling with imputed data set
In-Reply-To: <CABghstTnYGE+52mtqRFM=yZsUmp_=KBCQQ8qXVZ-X8qVd0g06w@mail.gmail.com>
References: <loom.20150616T054603-176@post.gmane.org>
	<55804E53.8040403@gmail.com>
	<CABghstTnYGE+52mtqRFM=yZsUmp_=KBCQQ8qXVZ-X8qVd0g06w@mail.gmail.com>
Message-ID: <CAF5_5cygM-v5RSeF-03Hz-fA_feE1J66Ype9tU7D1S2YTaDjtQ@mail.gmail.com>

mice is very easy to use and customise, I haven't used Stata's routines but
they seem a bit more complex to use but maybe less powerful. The advantage
with using mice is it is just a few statements to set up the analysis. The
author of mice has a book describing the capabilities and methods.


On 17 June 2015 at 11:21, Ben Bolker <bbolker at gmail.com> wrote:

>   For convenience, you might want to consider using imputation with
> the 'mice' package in order to
> stay within R for your analysis (I don't know Stata's capabilities in
> this area; I'd expect them to be pretty good,
> but it is my impression that 'mice' is also quite
> well-written/full-featured)
>
> On Tue, Jun 16, 2015 at 12:26 PM, Daniel Fulop <dfulop.ucd at gmail.com>
> wrote:
> > Use one of the apply functions to iterate over your imputed datasets.
> >
> > If your imputed datasets are in columns 5 through n+4 of "mydata" (i.e.
> > assuming that x1, x2, x3, and regioid are in columns 1:4), the you could
> do
> > something like:
> >
> > model.list <- lapply(1:n, function(i)
> >
> > glmer(mydata[,i+4] ~ x1+x2 +x3+(1|regiogid),family= binomial("logit"),
> > data=mydata) )
> >
> > The output will then be a list of model objects (i.e. model fits).  You
> can
> > then iterated through this results list in order to calculate mean
> parameter
> > values from all your imputed data fits.
> >
> > Or, likewise:
> >
> > model.list <- lapply(5:ncol(mydata), function(i) ...
> >
> > Hope this helps,
> > Dan.
> >
> >
> > ali via R-sig-mixed-models wrote:
> >>
> >> Hi all
> >> I imputed my data using multiple imputation procedure in STATA. I would
> >> like
> >> to conduct mixed effect modeling on the imputed data set in R. I do not
> >> know
> >> how to write the code over the imputed data set.
> >> My code is:
> >> fit<- glmer(y ~ x1+x2 +x3+(1|regiogid),family= binomial("logit"), data
> >> =mydata)
> >>
> >> Best Regards
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > --
> > Daniel Fulop, Ph.D.
> > Postdoctoral Scholar
> > Dept. Plant Biology, UC Davis
> > Maloof Lab, Rm. 2220
> > Life Sciences Addition, One Shields Ave.
> > Davis, CA 95616
> >
> > 510-253-7462
> > dfulop at ucdavis.edu
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From vasishth.shravan at gmail.com  Wed Jun 17 12:24:04 2015
From: vasishth.shravan at gmail.com (Shravan Vasishth)
Date: Wed, 17 Jun 2015 12:24:04 +0200
Subject: [R-sig-ME] New paper by Bates et al: Parsimonious mixed models
Message-ID: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>

Dear all,

People on this list will be interested in the following paper by Douglas
Bates et al:

http://arxiv.org/abs/1506.04967

This relates to discussions about model fitting that sometimes happen on
this list.

best,

--
Shravan Vasishth
Professor for Psycholinguistics and Neurolinguistics
Department of Linguistics
University of Potsdam, Germany
http://www.ling.uni-potsdam.de/~vasishth

	[[alternative HTML version deleted]]


From jackiewood7 at gmail.com  Wed Jun 17 18:47:02 2015
From: jackiewood7 at gmail.com (Jackie Wood)
Date: Wed, 17 Jun 2015 12:47:02 -0400
Subject: [R-sig-ME] Performing a single animal model that estimates additive
 genetic variation for many populations?
Message-ID: <CAOxxGRnmQHA5yP9KWO9sJJnny19+TkCBd9da-yL159KTFrZ8Jg@mail.gmail.com>

Hello R-users,

I'm working on a manuscript which investigates the relationship of various
metrics of adaptive potential (additive genetic variation (VA),
heritability (h2), and mean-scaled evolvability (IA)) with population size
in a common garden experiment using a large number of wild, isolated
populations of a vertebrate fish. One comment/request we received on the
manuscript was whether we could fit a single animal model that includes all
of our populations. That is, in addition to the standard terms to estimate
VA, whether we could also include population size and interactions with
population size such that we could examine whether VA (or h2 or IA) varies
among populations, and the magnitude of the interaction between population
and additive (and potentially maternal) effects.

As it currently stands we performed a separate model estimating VA for each
trait for each population which I feel is fairly standard practice, then
simply looked at the correlation between population size and VA (or h2, or
IA) for each trait. If this were a standard mixed-model it would be fairly
easy to incorporate the reviewer's suggestion but of course we are
implementing animal models to estimate our putative metrics of adaptability
and as such we require the use of a pedigree. I'm not sure if it is correct
or possible to construct a single pedigree that incorporates relatedness
information for a large number of populations such that you can estimate VA
for each population and also look at the relationship between VA and
population size in the same model. Is it possible to construct a giant
pedigree where every animal, dam, and sire across all populations get a
unique number but there is an additional column in the pedigree for
population size? Or is there a way to incorporate a large number of
separate pedigrees into a single model that estimates VA for all?

Any advice or insight regarding how to proceed would be greatly appreciated,

Cheers,
Jackie


-- 
Jacquelyn L.A. Wood, PhD.
Biology Department
Concordia University
7141 Sherbrooke St. West
Montreal, QC
H4B 1R6
Phone: (514) 293-7255

	[[alternative HTML version deleted]]


From juliah01 at uni-potsdam.de  Wed Jun 17 18:00:46 2015
From: juliah01 at uni-potsdam.de (Julia Hoffmann)
Date: Wed, 17 Jun 2015 18:00:46 +0200
Subject: [R-sig-ME] discrepancies in lme4
In-Reply-To: <CABghstT2Kejj2UH5=eK-LyY6u+Qj1mztSxMDUTmVBNMSV1M8eA@mail.gmail.com>
References: <ximss-6748209@be1.mail.uni-potsdam.de><CABghstT2Kejj2UH5=eK-LyY6u+Qj1mztSxMDUTmVBNMSV1M8eA@mail.gmail.com>
Message-ID: <ximss-6977099@be1.mail.uni-potsdam.de>

The change in lme4 version 1.1-4 does explain the changes in the standard 
errors of fixed effects in our models, but there are some exceptions where 
the output suggests, that these values are not computed correctly.

For example, I have a model where the output seems reasonably close to the 
older computations:

Generalized linear mixed model fit by maximum likelihood (Laplace 
 Approximation)
[glmerMod]
Family: gaussian  ( inverse )
Formula: Area1_ha ~ Light * tel_round + SEX + (1 | Enclosure/animal)
    Data: kern

Fixed effects:
   ? ? ? ? ? ? ? ? Estimate Std. Error t value Pr(>|z|)? ?
(Intercept)  ? ? ?  16.745? ? ? 3.611?  4.638 3.52e-06 ***
Light1  ? ? ? ? ? ? -1.010? ? ? 4.023? -0.251?  0.8017? ?
tel_round2  ? ? ? ?  0.442? ? ? 1.695?  0.261?  0.7943? ?
SEX1  ? ? ? ? ? ? ?  1.818? ? ? 2.944?  0.618?  0.5368? ?

Light1:tel_round2   -6.996? ? ? 2.860? -2.446?  0.0144 * ?


But after model simplification, where only one fixed factor is omitted, the 
output is extremely different. All the calculated standard errors are very 
small and similar leading to unrealistically high p-values which do not 
correspond at all to older computations:

Generalized linear mixed model fit by maximum likelihood (Laplace 
 Approximation)
  [glmerMod]
  Family: gaussian  ( inverse )
Formula: Area1_ha ~ Light * tel_round + (1 | Enclosure/animal)
    Data: kern

Fixed effects:
   ? ? ? ? ? ? ? ?  Estimate Std. Error t value Pr(>|z|)? ?
(Intercept)  ? ?  17.748296?  0.006443? 2754.5?  <2e-16 ***
Light1  ? ? ? ? ? -0.345857?  0.006444?  -53.7?  <2e-16 ***
tel_round2  ? ? ?  0.455012?  0.006445? ? 70.6?  <2e-16 ***
Light1:tel_round2 -7.368427   0.006445 -1143.3?  <2e-16 ***

Do you know what could be the problem in the calculation of the standard 
errors in the second model although it is so similar to the first one?


Thank you for your help,
Julia Hoffmann


On Mon, 15 Jun 2015 09:47:08 -0400
  Ben Bolker <bbolker at gmail.com> wrote:
>  I strongly suspect this is related to the following change in lme4
> version 1.1-4:
> 
> \item Standard errors of fixed effects are now computed from the
> approximate Hessian by default (see the \code{use.hessian} argument 
>in
> \code{vcov.merMod}); this gives better (correct) answers when the
> estimates of the random- and fixed-effect parameters are correlated
> (Github #47)
> 
> (see https://github.com/lme4/lme4/blob/master/inst/NEWS.Rd )
> 
>  This should apply only to your glmer results, not to lmer results.
> 
>  To check this, try summary(fitted_model,use.hessian=FALSE); it
> should give you the old results.
> 
>  A further check would be to run confint(fitted_model,parm="beta_"),
> which will give you more reliable likelihood profile confidence
> intervals (rather than relying on Wald approximations).
> 
>  Please follow up on r-sig-mixed-models at r-project.org if you have
> further questions ...
> 
> 
> On Mon, Jun 15, 2015 at 9:10 AM, Annika Schirmer
> <aschirme at uni-potsdam.de> wrote:
>> Dear Mr. Bolker,
>> we experienced some discrepancies/problems with the lme4 package in 
>>R and
>> would like to get your expertise on the subject. We?ve run mixed 
>>models with
>> the functions lmer and glmer and as of late the outputs given from 
>>the
>> summary function changed. The same models that were run a couple of 
>>month
>> ago produce now a different output, specifically different standard 
>>errors,
>> t values/ z values and p values and now scaled residuals are stated. 
>>Changes
>> in the specifications of the models were not made. In most cases 
>>those
>> differences are minimal and do not change the overall results of the 
>>models,
>> but in some extreme cases the standard errors experienced an extreme 
>>change
>> that led them to become very small and of the same value for all the 
>>fixed
>> factors in the model.
>>  As a result these models now produce highly significant p values 
>>which was
>> not the case a few month ago. Therefore the new results seem to us 
>>highly
>> unlikely and untrustworthy. The same discrepancy in the models
>> happens on two independent computers, therefore we exclude a general
>> software problem.
>> The R and lme4 versions we`re both working with are:
>>
>> R version 3.2.0 (2015-04-16)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 8 x64 (build 9200
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats  graphics  grDevices utils  datasets  methods  base
>>
>> other attached packages:
>> [1] lme4_1.1-7  Rcpp_0.11.6  Matrix_1.2-0
>>
>> loaded via a namespace (and not attached):
>> [1] minqa_1.2.4  MASS_7.3-40  splines_3.2.0  nlme_3.1-120
>> [5] grid_3.2.0  nloptr_1.0.4  lattice_0.20-31
>>
>> Was
>>  there a recent change in the lme4 package that could have lead to 
>>the new
>> output? Or could there maybe be a compatibility problem between the 
>>newest
>> version of R and lme4?
>>
>> We couldn`t find anything about similar problems on the internet 
>>thats why
>> we turn directly to you, in case it might be a general problem that 
>>needs
>> fixing or you have any idea what might be the problem.
>>
>> We would be very thankful for any kind of tip you could give us. 
>>Thanks in
>> advance.
>> Kind regards,
>>
>> Julia Hoffmann & Annika Schirmer


From thierry.onkelinx at inbo.be  Thu Jun 18 09:54:50 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 18 Jun 2015 09:54:50 +0200
Subject: [R-sig-ME] [R] Proc Mixed variance of random effects in R
In-Reply-To: <480114444.560625.1434563544236.JavaMail.yahoo@mail.yahoo.com>
References: <480114444.560625.1434563544236.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJuCY5wtTGR=0S5pk3F8gpJf46JH_R5C=uP_+8Tj4yriuJKMsQ@mail.gmail.com>

Dear Gram,

A few things first: Please don't post in HTML, it mangles your text.
R-sig-mixed model is a better list for questions on mixed models. Send
further replies only to that list and not to r-help.

You are probably not fitting the same model in R as the one in SAS. Please
provide the equations of the SAS model and then you can help you translate
that into R code. You are assuming that we all speak SAS, but this is an R
mailing list. The lingua franca among statistical software is mathematics.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-17 19:52 GMT+02:00 Grams Robins <grams_robins at yahoo.com>:

> Hi, I'm trying to convert the following SAS code in R to get the same
> result that I get from SAS. Here is the SAS code:
>     DATA plants;
>     INPUT  sample $  treatmt $ y ;
>     cards;
>
>     1   trt1    6.426264755
>     1   trt1    6.95419631
>     1   trt1    6.64385619
>     1   trt2    7.348728154
>     1   trt2    6.247927513
>     1   trt2    6.491853096
>     2   trt1    2.807354922
>     2   trt1    2.584962501
>     2   trt1    3.584962501
>     2   trt2    3.906890596
>     2   trt2    3
>     2   trt2    3.459431619
>     3   trt1    2
>     3   trt1    4.321928095
>     3   trt1    3.459431619
>     3   trt2    3.807354922
>     3   trt2    3
>     3   trt2    2.807354922
>     4   trt1    0
>     4   trt1    0
>     4   trt1    0
>     4   trt2    0
>     4   trt2    0
>     4   trt2    0
>     ;
>     RUN;
>
>     PROC MIXED ASYCOV NOBOUND  DATA=plants ALPHA=0.05 method=ML;
>     CLASS sample treatmt;
>     MODEL  y = treatmt ;
>     RANDOM int treatmt/ subject=sample ;
>     RUN; I get the following covariance estimates from SAS:Intercept
> sample ==> 5.5795treatmt sample ==> -0.08455Residual ==> 0.3181I tried the
> following in R, but I get different results.   options(contrasts = c(factor
> = "contr.SAS", ordered = "contr.poly"))
>     df$sample=as.factor(df$sample)
>     lmer(y~ 1+treatmt+(1+treatmt|sample),REML=FALSE, data = df) Since the
> results from R are standard deviations, I have to square all results to get
> the variances.    sample==> 2.357412^2 = 5.557391
>     sample*treatmt==>0.004977^2 = 2.477053e-05
>     residual==>0.517094^2 = 0.2673862As shown above, the results from SAS
> and R are different. Do you know how to get the exact values in R?I
> appreciate any help.Thanks,Gram
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From patricia.soto.b at gmail.com  Thu Jun 18 10:06:16 2015
From: patricia.soto.b at gmail.com (Patricia Soto)
Date: Thu, 18 Jun 2015 03:06:16 -0500
Subject: [R-sig-ME] MCMCgmml univariate model - binary response.
Message-ID: <CAOCX56pxZCooRUUaeivejOKF3AjnB95Xe4TjL5O2ruQUNLMSkg@mail.gmail.com>

Hello Everyone!

I am using MCMCglmm (Bayesian statistics for the first time in my life!) to
test whether Predictor1 and Predictor2 explain Response1 (Disclaimer:
apologies I am not naming my variables but the data is on students and
teachers and goes in a paper that I have to resubmit soon!). After reading
many, many times Hadfield's tutorial and course vignette, I came up with
the following specification of my model:

priorZ = list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V = 1, n
= 0), G2 = list(V = 1, n = 0)))
fac<-1
msgZ<-MCMCglmm(Response1 ~ Predictor1 + Predictor2 + Predictor1*Predictor2,
random = ~Random1 + Random2 , prior = priorZ, data = our_data, pr = TRUE,
family = "categorical",  verbose = TRUE, nitt = 13000 * fac, burnin = 3000
* fac, thin = 10 * fac)

Now the big question I have (and clearly I have not understood yet the
explanations found in a number of sources) is how to make sure my model is
meaningful.

Option 1: I thought I could go with the following,

> inv.logit(HPDinterval(msgZ$Sol, 0.95))

> inv.logit(posterior.mode(msgZ$Sol))


but I fail to interpret the very narrow lower - upper interval (what am I
missing in my understanding? do these values make sense?):

                                                lower        upper
(Intercept)              0.006123962        0.0006289942    0.02294555
Predictor1                0.998453915        0.9941636860    0.99961655
Predictor2.1             0.999625733        0.9884580704    0.99994442
Predictor2.2             0.988390462        0.9484153243    0.99898593
Predictor2.3             0.996238689        0.9871810929     0.99976048

Predictor1:Predictor2.1   0.188756844        0.0188979835    0.8300961

Predcitor1:Predictor2.2   0.006322825        0.0016985902    0.02754298
Predictor1:Predictor2.3   0.009168150        0.0016535274    0.02740872


I have tried several priors and while the posterior.mode remains about the
same, the lower bound of the CI interval changes dramatically. The upper
bound does not change much, if at all.

Option 2: With this approach, I feel I cannot argue in terms of how my
predictors explain the response variable:


> m.modelZ<-mcmc(mapply(msgZ.data.scale,msgZ$Sol, rowSums(msgZ$VCV)))> summary(m.modelZ)
Iterations = 1:72000
Thinning interval = 1
Number of chains = 1
Sample size per chain = 72000

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

          Mean             SD       Naive SE Time-series SE
     0.5022283      0.2586471      0.0009639      0.0303169

2. Quantiles for each variable:

   2.5%     25%     50%     75%   97.5%
0.04658 0.31975 0.49605 0.69394 0.98146


Option 3: Here I thought I could report based on:

>summary(msgZ)


                           post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)                 -5.410   -7.371   -3.751    86.79 <0.001 ***
Predictor1                  6.588    5.138    7.866    60.52 <0.001 ***
Predictor2.1                7.282    4.450    9.798    83.33 <0.001 ***

Predictor2.2                4.833    2.912    6.893    76.30 <0.001 ***

Predictor2.3                6.077    4.344    8.337    96.86 <0.001 ***

Response1:Predictor2.1     -1.024   -3.950    1.586    70.63  0.456

Response1:Predictor2.2     -5.096   -6.376   -3.564    75.21 <0.001 ***

Response1:Predictor2.3      -4.892   -6.403   -3.569    70.98 <0.001 ***


I can see significant statistics for most of my predictors. If I look at
the raw data, we actually expect Predictor1 to have the strongest effect (I
am almost certain I need to refine my definition of the random effects)

What would be the guidelines to report results for a peer-reviewed
publication? I know this is discipline dependent but I am trying to publish
this paper in a field of research new to me, so I am looking for quality
standards across disciplines.

Please, any insight, tip, suggestion is truly appreciated!

Patricia

patricia.soto.b at gmail.com

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Thu Jun 18 10:24:35 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 18 Jun 2015 18:24:35 +1000
Subject: [R-sig-ME] [R] Proc Mixed variance of random effects in R
In-Reply-To: <CAJuCY5wtTGR=0S5pk3F8gpJf46JH_R5C=uP_+8Tj4yriuJKMsQ@mail.gmail.com>
References: <480114444.560625.1434563544236.JavaMail.yahoo@mail.yahoo.com>
	<CAJuCY5wtTGR=0S5pk3F8gpJf46JH_R5C=uP_+8Tj4yriuJKMsQ@mail.gmail.com>
Message-ID: <CAF5_5cwoxfoUpQ9XWZiETkZTkpAnvwo4-Q0YQ+tbxFFO6Txohw@mail.gmail.com>

Actually what you want is the R results in SAS. The default in SAS is for
uncorrelated random effects, which is definitely not what is needed for
random intercept/slope models. Add TYPE=UN after the random statement.

On 18 June 2015 at 17:54, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

> Dear Gram,
>
> A few things first: Please don't post in HTML, it mangles your text.
> R-sig-mixed model is a better list for questions on mixed models. Send
> further replies only to that list and not to r-help.
>
> You are probably not fitting the same model in R as the one in SAS. Please
> provide the equations of the SAS model and then you can help you translate
> that into R code. You are assuming that we all speak SAS, but this is an R
> mailing list. The lingua franca among statistical software is mathematics.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-06-17 19:52 GMT+02:00 Grams Robins <grams_robins at yahoo.com>:
>
> > Hi, I'm trying to convert the following SAS code in R to get the same
> > result that I get from SAS. Here is the SAS code:
> >     DATA plants;
> >     INPUT  sample $  treatmt $ y ;
> >     cards;
> >
> >     1   trt1    6.426264755
> >     1   trt1    6.95419631
> >     1   trt1    6.64385619
> >     1   trt2    7.348728154
> >     1   trt2    6.247927513
> >     1   trt2    6.491853096
> >     2   trt1    2.807354922
> >     2   trt1    2.584962501
> >     2   trt1    3.584962501
> >     2   trt2    3.906890596
> >     2   trt2    3
> >     2   trt2    3.459431619
> >     3   trt1    2
> >     3   trt1    4.321928095
> >     3   trt1    3.459431619
> >     3   trt2    3.807354922
> >     3   trt2    3
> >     3   trt2    2.807354922
> >     4   trt1    0
> >     4   trt1    0
> >     4   trt1    0
> >     4   trt2    0
> >     4   trt2    0
> >     4   trt2    0
> >     ;
> >     RUN;
> >
> >     PROC MIXED ASYCOV NOBOUND  DATA=plants ALPHA=0.05 method=ML;
> >     CLASS sample treatmt;
> >     MODEL  y = treatmt ;
> >     RANDOM int treatmt/ subject=sample ;
> >     RUN; I get the following covariance estimates from SAS:Intercept
> > sample ==> 5.5795treatmt sample ==> -0.08455Residual ==> 0.3181I tried
> the
> > following in R, but I get different results.   options(contrasts =
> c(factor
> > = "contr.SAS", ordered = "contr.poly"))
> >     df$sample=as.factor(df$sample)
> >     lmer(y~ 1+treatmt+(1+treatmt|sample),REML=FALSE, data = df) Since the
> > results from R are standard deviations, I have to square all results to
> get
> > the variances.    sample==> 2.357412^2 = 5.557391
> >     sample*treatmt==>0.004977^2 = 2.477053e-05
> >     residual==>0.517094^2 = 0.2673862As shown above, the results from SAS
> > and R are different. Do you know how to get the exact values in R?I
> > appreciate any help.Thanks,Gram
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From David.Duffy at qimrberghofer.edu.au  Thu Jun 18 02:55:07 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Thu, 18 Jun 2015 10:55:07 +1000
Subject: [R-sig-ME] Performing a single animal model that estimates
 additive genetic variation for many populations?
In-Reply-To: <CAOxxGRnmQHA5yP9KWO9sJJnny19+TkCBd9da-yL159KTFrZ8Jg@mail.gmail.com>
References: <CAOxxGRnmQHA5yP9KWO9sJJnny19+TkCBd9da-yL159KTFrZ8Jg@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1506181010090.4993@orpheus.qimr.edu.au>

On Thu, 18 Jun 2015, Jackie Wood wrote:

> I'm working on a manuscript which investigates the relationship of various
> metrics of adaptive potential (additive genetic variation (VA),
> heritability (h2), and mean-scaled evolvability (IA)) with population size
> in a common garden experiment using a large number of wild, isolated
> populations of a vertebrate fish. One comment/request we received on the
> manuscript was whether we could fit a single animal model that includes all
> of our populations. That is, in addition to the standard terms to estimate
> VA, whether we could also include population size and interactions with
> population size such that we could examine whether VA (or h2 or IA) varies
> among populations, and the magnitude of the interaction between population
> and additive (and potentially maternal) effects.
>

Yes ;) It is essentially a GxE term. Probably MCMCglmm would be easiest.


| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From bbolker at gmail.com  Thu Jun 18 17:24:55 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 18 Jun 2015 11:24:55 -0400
Subject: [R-sig-ME] discrepancies in lme4
In-Reply-To: <ximss-6977099@be1.mail.uni-potsdam.de>
References: <ximss-6748209@be1.mail.uni-potsdam.de><CABghstT2Kejj2UH5=eK-LyY6u+Qj1mztSxMDUTmVBNMSV1M8eA@mail.gmail.com>
	<ximss-6977099@be1.mail.uni-potsdam.de>
Message-ID: <5582E2C7.1040605@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-06-17 12:00 PM, Julia Hoffmann wrote:
> The change in lme4 version 1.1-4 does explain the changes in the 
> standard errors of fixed effects in our models, but there are some 
> exceptions where the output suggests, that these values are not
> computed correctly.
> 
> For example, I have a model where the output seems reasonably close
> to the older computations:
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace 
> Approximation) [glmerMod] Family: gaussian  ( inverse ) Formula:
> Area1_ha ~ Light * tel_round + SEX + (1 | Enclosure/animal) Data:
> kern
> 
> Fixed effects: Estimate Std. Error t value Pr(>|z|) (Intercept)
> 16.745      3.611   4.638 3.52e-06 *** Light1              -1.010
> 4.023  -0.251   0.8017 tel_round2           0.442      1.695
> 0.261   0.7943 SEX1                 1.818      2.944   0.618
> 0.5368
> 
> Light1:tel_round2   -6.996      2.860  -2.446   0.0144 *
> 
> 
> But after model simplification, where only one fixed factor is
> omitted, the output is extremely different. All the calculated
> standard errors are very small and similar leading to
> unrealistically high p-values which do not correspond at all to
> older computations:
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace 
> Approximation) [glmerMod] Family: gaussian  ( inverse ) Formula:
> Area1_ha ~ Light * tel_round + (1 | Enclosure/animal) Data: kern
> 
> Fixed effects: Estimate Std. Error t value Pr(>|z|) (Intercept)
> 17.748296   0.006443  2754.5   <2e-16 *** Light1
> -0.345857   0.006444   -53.7   <2e-16 *** tel_round2
> 0.455012   0.006445    70.6   <2e-16 *** Light1:tel_round2
> -7.368427   0.006445 -1143.3   <2e-16 ***
> 
> Do you know what could be the problem in the calculation of the
> standard errors in the second model although it is so similar to
> the first one?
> 
> 
> Thank you for your help, Julia Hoffmann


   Without looking at the data, I'm not sure -- I only have one guess.
For large data sets (number of obs > 10^4) we have noticed that the
relatively crude finite-difference calculation we do to estimate the
variance-covariance matrix/standard errors is sometimes unreliable.

Here's a comparison of three methods of computing standard errors;
(1) using numDeriv::hessian (the most accurate general method we
currently have available); (2) using an internal finite-difference
calculation; (3) using internal stored information (the old method).

  In these cases the answers are quite similar (within a few percent),
but maybe they diverge in your case ...


library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              data = cbpp, family = binomial)
library(numDeriv)
dd <- update(gm1,devFunOnly=TRUE)
pp <- unlist(getME(gm1,c("theta","beta")))
H <- hessian(dd,pp)
all.equal(H,H0 <- gm1 at optinfo$derivs$Hessian)
sqrt(diag(solve(H/2))[-1])  ## use numDeriv::hessian
sqrt(diag(vcov(gm1)))       ## use internal finite-diff calc
## based on internal (obsolete) stored information
sqrt(diag(vcov(gm1,use.hessian=FALSE)))


> 
> 
> On Mon, 15 Jun 2015 09:47:08 -0400 Ben Bolker <bbolker at gmail.com>
> wrote:
>> I strongly suspect this is related to the following change in
>> lme4 version 1.1-4:
>> 
>> \item Standard errors of fixed effects are now computed from the 
>> approximate Hessian by default (see the \code{use.hessian}
>> argument in \code{vcov.merMod}); this gives better (correct)
>> answers when the estimates of the random- and fixed-effect
>> parameters are correlated (Github #47)
>> 
>> (see https://github.com/lme4/lme4/blob/master/inst/NEWS.Rd )
>> 
>> This should apply only to your glmer results, not to lmer
>> results.
>> 
>> To check this, try summary(fitted_model,use.hessian=FALSE); it 
>> should give you the old results.
>> 
>> A further check would be to run
>> confint(fitted_model,parm="beta_"), which will give you more
>> reliable likelihood profile confidence intervals (rather than
>> relying on Wald approximations).
>> 
>> Please follow up on r-sig-mixed-models at r-project.org if you have 
>> further questions ...
>> 
>> 
>> On Mon, Jun 15, 2015 at 9:10 AM, Annika Schirmer 
>> <aschirme at uni-potsdam.de> wrote:
>>> Dear Mr. Bolker, we experienced some discrepancies/problems
>>> with the lme4 package in R and would like to get your expertise
>>> on the subject. We?ve run mixed models with the functions lmer
>>> and glmer and as of late the outputs given from the summary
>>> function changed. The same models that were run a couple of 
>>> month ago produce now a different output, specifically
>>> different standard errors, t values/ z values and p values and
>>> now scaled residuals are stated. Changes in the specifications
>>> of the models were not made. In most cases those differences
>>> are minimal and do not change the overall results of the 
>>> models, but in some extreme cases the standard errors
>>> experienced an extreme change that led them to become very
>>> small and of the same value for all the fixed factors in the
>>> model. As a result these models now produce highly significant
>>> p values which was not the case a few month ago. Therefore the
>>> new results seem to us highly unlikely and untrustworthy. The
>>> same discrepancy in the models happens on two independent
>>> computers, therefore we exclude a general software problem. The
>>> R and lme4 versions we`re both working with are:
>>> 
>>> R version 3.2.0 (2015-04-16) Platform: x86_64-w64-mingw32/x64
>>> (64-bit) Running under: Windows 8 x64 (build 9200
>>> 
>>> locale: [1] LC_COLLATE=German_Germany.1252
>>> LC_CTYPE=German_Germany.1252 [3]
>>> LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5]
>>> LC_TIME=German_Germany.1252
>>> 
>>> attached base packages: [1] stats  graphics  grDevices utils
>>> datasets  methods  base
>>> 
>>> other attached packages: [1] lme4_1.1-7  Rcpp_0.11.6
>>> Matrix_1.2-0
>>> 
>>> loaded via a namespace (and not attached): [1] minqa_1.2.4
>>> MASS_7.3-40  splines_3.2.0  nlme_3.1-120 [5] grid_3.2.0
>>> nloptr_1.0.4  lattice_0.20-31
>>> 
>>> Was there a recent change in the lme4 package that could have
>>> lead to the new output? Or could there maybe be a compatibility
>>> problem between the newest version of R and lme4?
>>> 
>>> We couldn`t find anything about similar problems on the
>>> internet thats why we turn directly to you, in case it might be
>>> a general problem that needs fixing or you have any idea what
>>> might be the problem.
>>> 
>>> We would be very thankful for any kind of tip you could give
>>> us. Thanks in advance. Kind regards,
>>> 
>>> Julia Hoffmann & Annika Schirmer
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVguLHAAoJEOCV5YRblxUHxjwIAMY5bnDvAXTSeVAKPxezvmpT
96L31nxhxePuDJsDj/JXxbCQfj+itU2dclY9WA6jWqzo42rXnQX+Ek64Oyu+ursi
eqkXWHtVJ6Fn54BKYT8czeVP+NripsFBy2VVf1awEZnsSbKGMXsu/vSwSNcykOKY
w+oG0reOsQxYk+F0i6vio755kaYNLo519m9ciIU6uv5IqncYyQvFFdpaCgPUF1yV
IeQveVx1O23EZGJ3aRD+UzaaDsr1mK0YHxycm4hW0j+DYI06pbDyw06h96oM4dE0
PGXzGMzGMWhnMeQvvd883AUub63ksh8tMgWq66vmtWK3vCGHMW9BYmzQ7nT1si8=
=boUJ
-----END PGP SIGNATURE-----


From mtoncic at ffri.hr  Thu Jun 18 17:32:54 2015
From: mtoncic at ffri.hr (marKo)
Date: Thu, 18 Jun 2015 17:32:54 +0200
Subject: [R-sig-ME] New paper by Bates et al: Parsimonious mixed models
In-Reply-To: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>
References: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>
Message-ID: <5582E4A6.3010100@ffri.hr>

On 06/17/2015 12:24 PM, Shravan Vasishth wrote:
> Dear all,
>
> People on this list will be interested in the following paper by Douglas
> Bates et al:
>
> http://arxiv.org/abs/1506.04967
>
> This relates to discussions about model fitting that sometimes happen on
> this list.
>
> best,
>
> --
> Shravan Vasishth
> Professor for Psycholinguistics and Neurolinguistics
> Department of Linguistics
> University of Potsdam, Germany
> http://www.ling.uni-potsdam.de/~vasishth
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

Highly appreciated.

Thanks.

-- 
Marko Ton?i?
Research Assistant
University of Rijeka
Faculty of Humanities and Social Sciences
Department of Psychology
Sveucilisna avenija 4, 51000 Rijeka, CROATIA
e-mail: mtoncic at ffri.hr


From pierre.de.villemereuil at mailoo.org  Thu Jun 18 15:33:32 2015
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Thu, 18 Jun 2015 15:33:32 +0200
Subject: [R-sig-ME] Performing a single animal model that estimates
	additive genetic variation for many populations?
In-Reply-To: <alpine.LMD.2.00.1506181010090.4993@orpheus.qimr.edu.au>
References: <CAOxxGRnmQHA5yP9KWO9sJJnny19+TkCBd9da-yL159KTFrZ8Jg@mail.gmail.com>
	<alpine.LMD.2.00.1506181010090.4993@orpheus.qimr.edu.au>
Message-ID: <2591856.akHJoJOsm9@flyosfixe>

Dear all,

A kind of "multi-population" animal model framework which accounts for inter-
population, as well as for intra-population genetic structure has been developed 
by Ovaskainen /et al./:
Ovaskainen, O., Karhunen, M., Zheng, C., Arias, J. M. C. & Meril?, J. A new method to 
uncover signatures of divergent and stabilizing selection in quantitative traits. 
/Genetics/ *189,* 621?632 (2011). 

Instead of assuming a homogeneous Va across population, but maybe having a 
population?additive genetic interaction (i.e. a population-specific Va component) 
would solve this issue?

Regards,Pierre

Le jeudi 18 juin 2015, 10:55:07 David Duffy a ?crit :
> On Thu, 18 Jun 2015, Jackie Wood wrote:
> > I'm working on a manuscript which investigates the relationship of various
> > metrics of adaptive potential (additive genetic variation (VA),
> > heritability (h2), and mean-scaled evolvability (IA)) with population size
> > in a common garden experiment using a large number of wild, isolated
> > populations of a vertebrate fish. One comment/request we received on the
> > manuscript was whether we could fit a single animal model that includes
> > all
> > of our populations. That is, in addition to the standard terms to estimate
> > VA, whether we could also include population size and interactions with
> > population size such that we could examine whether VA (or h2 or IA) varies
> > among populations, and the magnitude of the interaction between population
> > and additive (and potentially maternal) effects.
> 
> Yes ;) It is essentially a GxE term. Probably MCMCglmm would be easiest.
> 
> | David Duffy (MBBS PhD)
> | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
> | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From liberationecology at gmail.com  Thu Jun 18 23:48:56 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Thu, 18 Jun 2015 16:48:56 -0500
Subject: [R-sig-ME] MCMCglmm: mix of good and bad eff.samp
Message-ID: <CAPNXFM6RBd=kJQTX9ZxLLOpBFmX0ig40wT-qo9Y01SUYV-Z14A@mail.gmail.com>

Hello,

I have a question about a mix of good and bad effective sample sizes. I've
read Jarrod's tutorial, course notes, and paper, and googled around
extensively, and haven't had any luck figuring this out. I'd be grateful
for any guidance.

Working with 721 observations, I fit a 2-level model with three Gaussian
response variables and several fixed effects and interactions. The model
looks good as far as trace plots and gelman diagnostics go.

My concern is with the effective sample size. Eff.samp overall and for
trait:block are quite good (1200, and mostly ~1200 w/ one 920,
respectively). But for trait:ID and residuals (trait:units) eff.samp is
terrible - mostly in the 150-200 range.

I'll post more model details below, but here are my questions:
? Do I need to worry about the poor eff.samp scores if I'm only interested
in the fixed effects?
? If it is a problem, could it be fixed by increasing iterations by a ~10x?

Here is the model I fit -
prior2 <- list(R=list(V=diag(3),nu=3),
               G=list(G1=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3),
alpha.V=1000*diag(3)),
                      G2=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3),
alpha.V=1000*diag(3))
               ) )

m2b <- MCMCglmm(cbind(professional, relational, practice) ~
                 -1 + trait +
                 trait:income + trait:age + trait:ethnicity + trait:gender
+ trait:residence +                  trait:education + trait:HDI +
trait:Ineq + trait:Enviro + trait:Enviro:gender + trait:Ineq:gender +
trait:Ineq:ethnicity + trait:Ineq:income,
               random= ~us(trait):block + us(trait):ID, rcov=
~us(trait):units,
               family=rep("gaussian",3),
               prior=prior2,
               nitt <- 80000, thin <- 25, burnin <- 50000,
               data=df_sel,
               verbose=TRUE)

Here is the first part of the model summary:
 Iterations = 50001:79976
 Thinning interval  = 25
 Sample size  = 1200

If a full data set will help, let me know and I'll post one.

Thanks so much for any suggestions!

Warmly,
Rafter



Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

	[[alternative HTML version deleted]]


From liberationecology at gmail.com  Fri Jun 19 16:36:21 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Fri, 19 Jun 2015 09:36:21 -0500
Subject: [R-sig-ME] MCMCglmm: mix of good and bad eff.samp
Message-ID: <CAPNXFM6g5sbTF0PR3NDnTn6_LAMAQsL2Fjze=hBVqPQTcSWuMg@mail.gmail.com>

In case any other newbie finds this thread in their searching:

Someone emailed me off-list and suggested going ahead and progressively
ramping up the iterations, and increasing the thin rate and burnin as well.

It worked great. All the model diagnostics I can throw at it are looking
good.


Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

On Thu, Jun 18, 2015 at 4:48 PM, rafter sass ferguson <
liberationecology at gmail.com> wrote:

> Hello,
>
> I have a question about a mix of good and bad effective sample sizes. I've
> read Jarrod's tutorial, course notes, and paper, and googled around
> extensively, and haven't had any luck figuring this out. I'd be grateful
> for any guidance.
>
> Working with 721 observations, I fit a 2-level model with three Gaussian
> response variables and several fixed effects and interactions. The model
> looks good as far as trace plots and gelman diagnostics go.
>
> My concern is with the effective sample size. Eff.samp overall and for
> trait:block are quite good (1200, and mostly ~1200 w/ one 920,
> respectively). But for trait:ID and residuals (trait:units) eff.samp is
> terrible - mostly in the 150-200 range.
>
> I'll post more model details below, but here are my questions:
> ? Do I need to worry about the poor eff.samp scores if I'm only interested
> in the fixed effects?
> ? If it is a problem, could it be fixed by increasing iterations by a ~10x?
>
> Here is the model I fit -
> prior2 <- list(R=list(V=diag(3),nu=3),
>                G=list(G1=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3),
> alpha.V=1000*diag(3)),
>                       G2=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3),
> alpha.V=1000*diag(3))
>                ) )
>
> m2b <- MCMCglmm(cbind(professional, relational, practice) ~
>                  -1 + trait +
>                  trait:income + trait:age + trait:ethnicity + trait:gender
> + trait:residence +                  trait:education + trait:HDI +
> trait:Ineq + trait:Enviro + trait:Enviro:gender + trait:Ineq:gender +
> trait:Ineq:ethnicity + trait:Ineq:income,
>                random= ~us(trait):block + us(trait):ID, rcov=
> ~us(trait):units,
>                family=rep("gaussian",3),
>                prior=prior2,
>                nitt <- 80000, thin <- 25, burnin <- 50000,
>                data=df_sel,
>                verbose=TRUE)
>
> Here is the first part of the model summary:
>  Iterations = 50001:79976
>  Thinning interval  = 25
>  Sample size  = 1200
>
> If a full data set will help, let me know and I'll post one.
>
> Thanks so much for any suggestions!
>
> Warmly,
> Rafter
>
>
>
> Rafter Sass Ferguson, MS
> PhD Candidate | Crop Sciences Department
> University of Illinois in Urbana-Champaign
> liberationecology.org
> 518 567 7407
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jun 19 16:45:07 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 19 Jun 2015 16:45:07 +0200
Subject: [R-sig-ME] New paper by Bates et al: Parsimonious mixed models
In-Reply-To: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>
References: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>
Message-ID: <21892.10995.123051.442388@stat.math.ethz.ch>

>>>>> "SV" == Shravan Vasishth <vasishth.shravan at gmail.com>
>>>>>     on Wed, 17 Jun 2015 12:24:04 +0200 writes:

    SV> Dear all, People on this list will be interested in the
    SV> following paper by Douglas Bates et al:

    SV> http://arxiv.org/abs/1506.04967

    SV> This relates to discussions about model fitting that
    SV> sometimes happen on this list.

    SV> best,

    SV> -- Shravan Vasishth Professor for Psycholinguistics and
    SV> Neurolinguistics Department of Linguistics University of
    SV> Potsdam, Germany
    SV> http://www.ling.uni-potsdam.de/~vasishth

    SV> 	[[alternative HTML version deleted]]

    SV> _______________________________________________
    SV> R-sig-mixed-models at r-project.org mailing list
    SV> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From singmann at psychologie.uzh.ch  Fri Jun 19 23:45:13 2015
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Fri, 19 Jun 2015 23:45:13 +0200
Subject: [R-sig-ME] New paper by Bates et al: Parsimonious mixed models
In-Reply-To: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>
References: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>
Message-ID: <55848D69.8050701@psychologie.uzh.ch>

It seems my first mail did not get through so I am trying it again. 
Sorry for double posting.

Dear Shravan,

Thanks a lot for sending this paper around, I was eagerly awaiting it 
and really enjoyed reading it.

Nevertheless, I would like to start a discussion on your response to 
Barr et al.'s (2013) suggestion to "keep it maximal". You conclude that 
"it is not necessary to aim for maximality when the interest is in a 
confirmatory analysis of factorial contrasts" (p. 25).

This conclusion is based on your reanalysis of several data sets showing 
that the maximal models for those cases are overparameterized. As a 
remedy you suggest a simplification strategy with the goal to reach a 
model that only contains parameters "actually well-supported by the 
information in the data" (p. 25). Nevertheless, for all cases discussed, 
the conclusion regarding the fixed effects agree between the 
overparameterized models and the simplified models.

In other words, there actually does not seem to be a downside of using 
maximal models for testing fixed effects. Likewise, the only upside of 
the simplified model is that one avoids superfluous variance and 
correlation parameters. Whereas the latter is clearly desirable from a 
statistical perspective, from the perspective of a researcher with the 
goal to avoid false positives (i.e., anticonservative fixed effects 
estimates) this does not sound overly convincing. Furthermore, your 
suggested simplification strategy, albeit clearly principled, is still a 
stepwise procedure that must share some of the problems stepwise 
procedures usually have. Specifically, I cannot see how it could 
guarantee that one does not occasionally exclude a random effects 
component that, once omitted, results in anticonservative estimates.

Based on this, I would perhaps suggest a somewhat different conclusion 
from your analyses for those interested in "confirmatory analysis":
1. Test your fixed effects on the maximal model.
2. Test your fixed effects on the optimal model found with the suggested 
simplification strategy.
If both results agree everything is fine.
If not things get more difficult: Either make convincing arguments while 
one of the results must be "more correct" (e.g., by analyzing the fixed 
effects estimates across a wider range of random effects structures), 
perhaps collect more data, or ...

(I have avoided discussing the "hidden complexities" as it goes beyond 
the issue of maximal or optimal LMMs.)

I am really interested in any thoughts on this matter and thanks again 
for the paper.

Cheers,
Henrik


PS: I found two small typos:
- In section 3.3 (reanalysis of Kronm?ller and Barr) you introduce the 
cognitie load manipulation as "L" whereas the formulas given later as 
well as the figures refer to it as "C".
- In the same section, subesction "Dropping non-significant variance 
components" (p. 11) you write "compared to the other standard-deviation 
estimates (> 64)." Inspection of the results from this reanalysis (e.g., 
in the KB vignette of RePsychLing) shows that there are dropped random 
effects with SDs above 64 (e.g., C) but also below 64 (e.g., SP).


Am 17.06.2015 um 12:24 schrieb Shravan Vasishth:
> Dear all,
>
> People on this list will be interested in the following paper by Douglas
> Bates et al:
>
> http://arxiv.org/abs/1506.04967
>
> This relates to discussions about model fitting that sometimes happen on
> this list.
>
> best,
>
> --
> Shravan Vasishth
> Professor for Psycholinguistics and Neurolinguistics
> Department of Linguistics
> University of Potsdam, Germany
> http://www.ling.uni-potsdam.de/~vasishth
>
> 	[[alternative HTML version deleted]]
>


From jake987722 at hotmail.com  Sat Jun 20 19:17:53 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Sat, 20 Jun 2015 11:17:53 -0600
Subject: [R-sig-ME] New paper by Bates et al: Parsimonious mixed models
In-Reply-To: <55848D69.8050701@psychologie.uzh.ch>
References: <CA+1m9_4k7SzN78jYON_LE-DSWMzV_QbU3RZD3h3xBU5sA54i5g@mail.gmail.com>,
	<55848D69.8050701@psychologie.uzh.ch>
Message-ID: <COL129-W941F9663E974A245F1CFDDCBA30@phx.gbl>

Henrik, Shravan, and everyone,

I have been eagerly awaiting this paper, but like Henrik, I was a little puzzled by this draft. I hope the comments that I offer below will be useful to the authors.

The paper assumes "that the experimental hypotheses relate to the fixed effects, not the random-effects structure" (p. 5), which I agree is usually the case, and more importantly is the situation considered by Barr et al. But then what is conspicuously missing is a discussion of what are the actual negative consequences that can arise *in interpreting the fixed effects* when one fits an overparameterized, maximal model (which nevertheless successfully converges and has no obviously wacky parameter estimates). The paper describes a nice, principled procedure for simplifying maximal models, but seems to simply take for granted that this is a useful and worthwhile thing to do--I think that this point is, at the least, NOT self-evident.

(Of course, often the maximal model won't converge and one will be pretty much forced to simplify the model--but then no one was ever saying otherwise!)

I am also not sure what to make of the section on "hidden complexities." It's very interesting. But it's hard to see what it has to do with the maximal model vs. parsimonious model issue. The best I can tell is that the argument is this: If one takes the maximal philosophy seriously, this would lead one to consider hopelessly complex models in which the theoretically maximal model would virtually never be well-supported by data sets of the typical size in cognitive science. Which is all fine I guess, but if it's a response to Barr et al. then it's sort of a straw man, since they obviously never did nor would advocate fitting such complex models as a matter of default routine. And if it's not a response to Barr et al. and the maximal philosophy, well, then it's not really clear why it's in the paper, as interesting as it is.

For me, the big contribution of Barr et al. is to provide workbench cognitive scientists with a model-selection strategy that (a) will typically provide stringent tests of the fixed effects in the model, (b) reduces the "researcher degrees of freedom" that are kind of inherent in the specification of the random part of the model, and (c) is easy to understand and implement for researchers who, for better or worse (but I guess we know which it is), have little understanding of how to find the "optimal" random effects structure and are unlikely to take the time to learn. Bates et al. do provide an alternative model-selection strategy, but from what I can tell, it seems to do no better or worse at (a) and will usually be worse at (b) and (c). I think it is obvious to most who have a good understanding of LMMs that the "best" random effects structure for almost any particular LMM will usually be something in between the most simple model and the theoretically maximal model. But I really don't see many compelling reasons in this current draft for why we should NOT continue to recommend keeping at maximal as the default strategy for researchers who don't have a great understanding of LMMs, which surely must be the majority.

And finally, I have saved the most pressing and important comment for last: The reference to my 2014 paper in the opening paragraph is wrong :) The author list, year, and journal are correct (assuming that's the paper you intended to cite), but the given title is from a different paper of ours published in 2015 in another journal. The correct references can be found on my website.

Jake
> To: r-sig-mixed-models at r-project.org
> From: singmann at psychologie.uzh.ch
> Date: Fri, 19 Jun 2015 23:45:13 +0200
> Subject: Re: [R-sig-ME] New paper by Bates et al: Parsimonious mixed models
> 
> It seems my first mail did not get through so I am trying it again. 
> Sorry for double posting.
> 
> Dear Shravan,
> 
> Thanks a lot for sending this paper around, I was eagerly awaiting it 
> and really enjoyed reading it.
> 
> Nevertheless, I would like to start a discussion on your response to 
> Barr et al.'s (2013) suggestion to "keep it maximal". You conclude that 
> "it is not necessary to aim for maximality when the interest is in a 
> confirmatory analysis of factorial contrasts" (p. 25).
> 
> This conclusion is based on your reanalysis of several data sets showing 
> that the maximal models for those cases are overparameterized. As a 
> remedy you suggest a simplification strategy with the goal to reach a 
> model that only contains parameters "actually well-supported by the 
> information in the data" (p. 25). Nevertheless, for all cases discussed, 
> the conclusion regarding the fixed effects agree between the 
> overparameterized models and the simplified models.
> 
> In other words, there actually does not seem to be a downside of using 
> maximal models for testing fixed effects. Likewise, the only upside of 
> the simplified model is that one avoids superfluous variance and 
> correlation parameters. Whereas the latter is clearly desirable from a 
> statistical perspective, from the perspective of a researcher with the 
> goal to avoid false positives (i.e., anticonservative fixed effects 
> estimates) this does not sound overly convincing. Furthermore, your 
> suggested simplification strategy, albeit clearly principled, is still a 
> stepwise procedure that must share some of the problems stepwise 
> procedures usually have. Specifically, I cannot see how it could 
> guarantee that one does not occasionally exclude a random effects 
> component that, once omitted, results in anticonservative estimates.
> 
> Based on this, I would perhaps suggest a somewhat different conclusion 
> from your analyses for those interested in "confirmatory analysis":
> 1. Test your fixed effects on the maximal model.
> 2. Test your fixed effects on the optimal model found with the suggested 
> simplification strategy.
> If both results agree everything is fine.
> If not things get more difficult: Either make convincing arguments while 
> one of the results must be "more correct" (e.g., by analyzing the fixed 
> effects estimates across a wider range of random effects structures), 
> perhaps collect more data, or ...
> 
> (I have avoided discussing the "hidden complexities" as it goes beyond 
> the issue of maximal or optimal LMMs.)
> 
> I am really interested in any thoughts on this matter and thanks again 
> for the paper.
> 
> Cheers,
> Henrik
> 
> 
> PS: I found two small typos:
> - In section 3.3 (reanalysis of Kronm?ller and Barr) you introduce the 
> cognitie load manipulation as "L" whereas the formulas given later as 
> well as the figures refer to it as "C".
> - In the same section, subesction "Dropping non-significant variance 
> components" (p. 11) you write "compared to the other standard-deviation 
> estimates (> 64)." Inspection of the results from this reanalysis (e.g., 
> in the KB vignette of RePsychLing) shows that there are dropped random 
> effects with SDs above 64 (e.g., C) but also below 64 (e.g., SP).
> 
> 
> Am 17.06.2015 um 12:24 schrieb Shravan Vasishth:
> > Dear all,
> >
> > People on this list will be interested in the following paper by Douglas
> > Bates et al:
> >
> > http://arxiv.org/abs/1506.04967
> >
> > This relates to discussions about model fitting that sometimes happen on
> > this list.
> >
> > best,
> >
> > --
> > Shravan Vasishth
> > Professor for Psycholinguistics and Neurolinguistics
> > Department of Linguistics
> > University of Potsdam, Germany
> > http://www.ling.uni-potsdam.de/~vasishth
> >
> > 	[[alternative HTML version deleted]]
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From r.travitzki at gmail.com  Sun Jun 21 23:56:29 2015
From: r.travitzki at gmail.com (Rodrigo Travitzki)
Date: Sun, 21 Jun 2015 23:56:29 +0200
Subject: [R-sig-ME] Fwd: Clarifications on implementation of lmer (lme4)
 in R -weights
In-Reply-To: <mailman.1.1434621601.11302.r-sig-mixed-models@r-project.org>
References: <mailman.1.1434621601.11302.r-sig-mixed-models@r-project.org>
Message-ID: <5587330D.8040802@gmail.com>

Christian,
as far as I know (not much) the use of 'lm' weights is similar to 
'lmer', but not to 'lme' functions.
But you can use both of them, because the weight is a covariate of the 
variance.
Basically, if in lm you use *weights=n* , so in multilevel models:
/
//in lmer: *weights=n* /
/in lme: *weights=varFixed(~I(1/n))* //[inverse-variance weighting based 
on the number of samples per group]//
/
This was explained by Ben Bolker here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022570.html

Good Luck!
Rodrigo


 > *Christian Blanco* wrotes on /Tue Jun 9 23:25:43 CEST 2015/

> I did some testing between the lme and lmer (with REML estimator; random
> slope and intercept).

> Without any weights, I get the same estimates for lme and lmer. However,
> when I include a weight given by inverse of the sample size by ID. I get
> very different results.


	[[alternative HTML version deleted]]


From chirleu at gmail.com  Mon Jun 22 11:16:55 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Mon, 22 Jun 2015 11:16:55 +0200
Subject: [R-sig-ME] correct specification and interpretation of multivariate
 mixed-model in lme
Message-ID: <CALC46t-3e=258GTUyokSuYZ0mf4=8-mGrh1-UQ0e-7TAJSysVA@mail.gmail.com>

Dear list,
I have a dataset of 8 response variables measured every month during a
period of 3 years for 290 individuals. Not all individuals have the same
number of replicates (range=3-18, mean=8). I'm trying to specify a
multivariate mixed-model using lme because *I'm interested in getting the
among-individual variace-covariance matrix.* I have made some attempts in
MCMCglmm using the following model:

mcmc1=MCMCglmm(cbind(t1,t2,t3,t4,t5,t6,t7,t8)~trait-1,random=~us(trait):id,rcov=~us(trait):units,data=wide2,

 family=c("gaussian","gaussian","gaussian","gaussian","gaussian","gaussian","gaussian","gaussian"),verbose=FALSE,prior=prior1,pr=TRUE)

However, there is strong temporal autocorrelation inside each individual
time series, and this is reflected in the residuals of the MCMCglmm model.
So my only alternative is to use lme (I guess). The univariate lme models
for each trait separately included an autocorrelation term (corAR1 in most
cases) which completely accounted for the temporal autocorrelation. So I
wanted to use the same approach for the multivariate model. Nevertheless I
haven't found much information on how to fit a multivariate lme. I have
checked the following sources:

   -
   http://stats.stackexchange.com/questions/108779/multivariate-model-in-lme-with-independent-random-effect-similar-to-mcmcglmm
   -
   http://scs.math.yorku.ca/index.php/Mixed_Models_with_R/Multivariate_Mixed_Models.Rmd
   -
   http://rstudio-pubs-static.s3.amazonaws.com/3336_03636030d93d47de9131e625b72f58c6.html
   - Alain Zuur book on "Mixed effects models and extensions in Ecology
   with R"


However I'm still not sure about how to specify the model I need.

This is the head() and str() of my data (which is already in long format):

> head(long)
           key trait      value   id month_year month year
1 2011-05 5491   t1   0.5039553 5491    2011-05     5 2011
2 2011-05 5492   t1   1.1132514 5492    2011-05     5 2011
3 2011-05 5493   t1   1.7398036 5493    2011-05     5 2011
4 2011-05 5494   t1  -0.1328723 5494    2011-05     5 2011
5 2011-05 5495   t1   0.5433441 5495    2011-05     5 2011
6 2011-05 5496   t1   0.8299277 5496    2011-05     5 2011

> str(long)
'data.frame': 17992 obs. of  7 variables:
 $ key       : Factor w/ 2249 levels "2011-05 5491",..: 1 2 3 4 5 6 7 8 9
10 ...
 $ trait     : Factor w/ 8 levels "t1","t2","t3",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ value     : num  0.504 1.113 1.74 -0.133 0.543 ...
 $ id        : Factor w/ 274 levels "5488","5489",..: 3 4 5 6 7 8 23 24 25
26 ...
 $ month_year: chr  "2011-05" "2011-05" "2011-05" "2011-05" ...
 $ month     : num  5 5 5 5 5 5 5 5 5 5 ...
 $ year      : Factor w/ 4 levels "2011","2012",..: 1 1 1 1 1 1 1 1 1 1 ...


Ideally, I want to fit exactly the same model I fit with MCMCglmm but
including the correlation term. This is my best attempt so far:

model=lme(value~trait-1, random=~trait-1|id,
weights=varIdent(form=~1|trait),
correlation=corAR1(form=trait~1|id),data=long)

My questions are:

   1. Correlation term: I need to account for temporal autocorrelation
   within each response variable and for each individual. Is it correctly
   specified? Or should I create a "timer" variable that specifies the
   temporal order of the data, and include it in the correlation term? Because
   right now I'm not telling the correlation term that the replicates follow a
   temporal order I think. How could I specify that? In the univariate models
   my correlation term was corAR1(form=~timer), being timer a dummy variable
   reflecting the "time sequence".
   2. My aim including the weights term is to account for different
   variances of the different response variables. I guess this is strictly
   neccesary, correct?
   3. There are no fixed effects in the model yet, so the fixed part is
   reduced to trait-1. Correct? In case I want to account for month variation
   within each reponse variable, how should I include it in the fixed part of
   the model: (trait*month-1)?

Of course I'm aware that the model might not converge with 8 response
variables (actually it doesn't...but maybe because it is not correctly
specified), but once I know how to specifiy what I want properly, I can try
with less variables (perhaps 3-4). However, one last very general question:

      4. In general, if a MCMCglmm model with 8 responses converge, should
I expect convergence as well in lme?

I'd trully appreciate your advise. Please let me know if providing the
dataset helps.

Many thanks,

David

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jun 22 16:47:48 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 22 Jun 2015 16:47:48 +0200
Subject: [R-sig-ME] correct specification and interpretation of
 multivariate mixed-model in lme
In-Reply-To: <CALC46t-3e=258GTUyokSuYZ0mf4=8-mGrh1-UQ0e-7TAJSysVA@mail.gmail.com>
References: <CALC46t-3e=258GTUyokSuYZ0mf4=8-mGrh1-UQ0e-7TAJSysVA@mail.gmail.com>
Message-ID: <CAJuCY5zBC+4y4r8t7=ujZ28+T-HmCf_OnabPPefpFAPNQgT6nQ@mail.gmail.com>

Dear David,

1. It's best to use a "timer" variable. You want either
corAR1(form=~timer|id) or corAR1(form=~timer|id:trait). Note that the
correlation only works on the residuals within the same grouping
level. Residuals among levels are assumed to be be independent;
2. You allow for a difference residual variance among trait. It's up
to you to decide whether this makes sense.
3. trait-1 is equivalent with a different intercept for each trait. It
makes sense to always include the interaction between trait and the
other covariates.
4. You'll have to try it.

Note that the INLA packages allows for multivariate mixed models too.
It allows for correlated random effects (rather than correlated
residuals). You can find INLA at R-inla.org

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-06-22 11:16 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:
> Dear list,
> I have a dataset of 8 response variables measured every month during a
> period of 3 years for 290 individuals. Not all individuals have the same
> number of replicates (range=3-18, mean=8). I'm trying to specify a
> multivariate mixed-model using lme because *I'm interested in getting the
> among-individual variace-covariance matrix.* I have made some attempts in
> MCMCglmm using the following model:
>
> mcmc1=MCMCglmm(cbind(t1,t2,t3,t4,t5,t6,t7,t8)~trait-1,random=~us(trait):id,rcov=~us(trait):units,data=wide2,
>
>  family=c("gaussian","gaussian","gaussian","gaussian","gaussian","gaussian","gaussian","gaussian"),verbose=FALSE,prior=prior1,pr=TRUE)
>
> However, there is strong temporal autocorrelation inside each individual
> time series, and this is reflected in the residuals of the MCMCglmm model.
> So my only alternative is to use lme (I guess). The univariate lme models
> for each trait separately included an autocorrelation term (corAR1 in most
> cases) which completely accounted for the temporal autocorrelation. So I
> wanted to use the same approach for the multivariate model. Nevertheless I
> haven't found much information on how to fit a multivariate lme. I have
> checked the following sources:
>
>    -
>    http://stats.stackexchange.com/questions/108779/multivariate-model-in-lme-with-independent-random-effect-similar-to-mcmcglmm
>    -
>    http://scs.math.yorku.ca/index.php/Mixed_Models_with_R/Multivariate_Mixed_Models.Rmd
>    -
>    http://rstudio-pubs-static.s3.amazonaws.com/3336_03636030d93d47de9131e625b72f58c6.html
>    - Alain Zuur book on "Mixed effects models and extensions in Ecology
>    with R"
>
>
> However I'm still not sure about how to specify the model I need.
>
> This is the head() and str() of my data (which is already in long format):
>
>> head(long)
>            key trait      value   id month_year month year
> 1 2011-05 5491   t1   0.5039553 5491    2011-05     5 2011
> 2 2011-05 5492   t1   1.1132514 5492    2011-05     5 2011
> 3 2011-05 5493   t1   1.7398036 5493    2011-05     5 2011
> 4 2011-05 5494   t1  -0.1328723 5494    2011-05     5 2011
> 5 2011-05 5495   t1   0.5433441 5495    2011-05     5 2011
> 6 2011-05 5496   t1   0.8299277 5496    2011-05     5 2011
>
>> str(long)
> 'data.frame': 17992 obs. of  7 variables:
>  $ key       : Factor w/ 2249 levels "2011-05 5491",..: 1 2 3 4 5 6 7 8 9
> 10 ...
>  $ trait     : Factor w/ 8 levels "t1","t2","t3",..: 1 1 1 1 1 1 1 1 1 1 ...
>  $ value     : num  0.504 1.113 1.74 -0.133 0.543 ...
>  $ id        : Factor w/ 274 levels "5488","5489",..: 3 4 5 6 7 8 23 24 25
> 26 ...
>  $ month_year: chr  "2011-05" "2011-05" "2011-05" "2011-05" ...
>  $ month     : num  5 5 5 5 5 5 5 5 5 5 ...
>  $ year      : Factor w/ 4 levels "2011","2012",..: 1 1 1 1 1 1 1 1 1 1 ...
>
>
> Ideally, I want to fit exactly the same model I fit with MCMCglmm but
> including the correlation term. This is my best attempt so far:
>
> model=lme(value~trait-1, random=~trait-1|id,
> weights=varIdent(form=~1|trait),
> correlation=corAR1(form=trait~1|id),data=long)
>
> My questions are:
>
>    1. Correlation term: I need to account for temporal autocorrelation
>    within each response variable and for each individual. Is it correctly
>    specified? Or should I create a "timer" variable that specifies the
>    temporal order of the data, and include it in the correlation term? Because
>    right now I'm not telling the correlation term that the replicates follow a
>    temporal order I think. How could I specify that? In the univariate models
>    my correlation term was corAR1(form=~timer), being timer a dummy variable
>    reflecting the "time sequence".
>    2. My aim including the weights term is to account for different
>    variances of the different response variables. I guess this is strictly
>    neccesary, correct?
>    3. There are no fixed effects in the model yet, so the fixed part is
>    reduced to trait-1. Correct? In case I want to account for month variation
>    within each reponse variable, how should I include it in the fixed part of
>    the model: (trait*month-1)?
>
> Of course I'm aware that the model might not converge with 8 response
> variables (actually it doesn't...but maybe because it is not correctly
> specified), but once I know how to specifiy what I want properly, I can try
> with less variables (perhaps 3-4). However, one last very general question:
>
>       4. In general, if a MCMCglmm model with 8 responses converge, should
> I expect convergence as well in lme?
>
> I'd trully appreciate your advise. Please let me know if providing the
> dataset helps.
>
> Many thanks,
>
> David
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From liberationecology at gmail.com  Mon Jun 22 17:57:39 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Mon, 22 Jun 2015 10:57:39 -0500
Subject: [R-sig-ME] MCMCglmm ignores custom contrasts in multi-response
	models
Message-ID: <CAPNXFM4UbsFeQ70SE9EikvvPAq0YSpgHbpAkWqJN=ku+EwDhcQ@mail.gmail.com>

MCMCglmm appears to consistently ignore set contrasts and revert to default
contrasts when fitting a multivariate model (and not when fitting a
univariate model).

Reproducible example:

### recreating the data from the Course Notes multi-response vignette
require(MCMCglmm)

set.seed(102)
n_indiv <- 500
n_per_indiv <- 4
n_tot <- n_indiv * n_per_indiv
id <- gl(n_indiv, n_per_indiv)
av_wealth <- rlnorm(n_indiv, 0, 1)
ac_wealth <- av_wealth[id] + rlnorm(n_tot, 0, 1)
av_ratio <- rbeta(n_indiv, 10, 10)
ac_ratio <- rbeta(n_tot, 2 * av_ratio[id], 2 * (1 - av_ratio[id]))
y.car <- (ac_wealth * ac_ratio)^0.25
y.hol <- (ac_wealth * (1 - ac_ratio))^0.25

Spending <- data.frame(y.hol, y.car, id)

### adding an ordered factor variable 'education'
Spending$edu <- factor(sample(c("1_HS", "2_2YrCol", "3_4YrCol", "4_Grad"),
size=n_indiv, replace=TRUE), levels=c("HS", "2YrCol", "4YrCol", "Grad"),
ordered=T)
### setting custom contrast
contrasts(Spending$edu) <- contr.helmert(4)

### fit samemodels to vignette, but adding education as predictor
m1_id <- MCMCglmm(y.car ~ y.hol + edu, random = ~id, data = Spending,
verbose = FALSE)
m1_idyr <- MCMCglmm(cbind(y.hol, y.car) ~ trait - 1 + trait:edu, random =
~us(trait):id,
                    rcov = ~us(trait):units, data = Spending, family =
c("gaussian", "gaussian"),
                    verbose = T)

summary(m1_id) ### Helmert contrasts retained for univariate
summary(m1_idyr) ### reverts to default polynomial contrasts for
multivariate

### making sure it's not specific to ordered factors - change edu to an
unordered
### factor with custom contrasts
Spending$edu <- factor(Spending$edu, ordered=F)
contrasts(Spending$edu) <- contr.treatment(4, base=3)

### re-fit models
m1_id2 <- MCMCglmm(y.car ~ y.hol + edu, random = ~id, data = Spending,
verbose = FALSE)
m1_idyr2 <- MCMCglmm(cbind(y.hol, y.car) ~ trait - 1 + trait:edu, random =
~us(trait):id,
                    rcov = ~us(trait):units, data = Spending, family =
c("gaussian", "gaussian"),
                    verbose = F)

### same results:
summary(m1_id2) ### custom contrasts (base=3) retained for univariate
summary(m1_idyr2) ### reverts to default (base=1) for multivariate






Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

	[[alternative HTML version deleted]]


From itc2 at georgetown.edu  Mon Jun 22 17:36:53 2015
From: itc2 at georgetown.edu (Ian Carroll)
Date: Mon, 22 Jun 2015 11:36:53 -0400
Subject: [R-sig-ME] recover simulated individual-level random effects with
	glmer?
Message-ID: <CAMyusG8EVeTFZYHC0fhcaEC4NvqBVW=K5OgCcg2vetaNFVt2UQ@mail.gmail.com>

I raised this question yesterday on Cross Validated (
stats.stackexchange.com/q/158043/43122), but now realize this might be the
more appropriate forum for help. Please excuse the cross-post if you track
both.

I simulated count data with an observation level random effect, then fit a
Poisson-family GLMM using glmer (lme4 version 1.1-7). The fitted random
intercepts show a strange pattern when compared to the simulated data, and
produce a kinked QQ plot. If this is expected, why is it okay? If not, what
am I doing wrong?

Simulated data and fitting:
> n <- 1000
> df <- data.frame(obs=factor(1:n))
> df$x <- rnorm(n)
> df$r <- rnorm(n, sd=3)
> df$y <- rpois(n=n, lambda=exp(2*df$x + df$r))
> glmer.fit <- glmer(y ~ x + (1|obs), family='poisson', data=df)

Questioned results:
> df$r.est <- ranef(glmer.fit)$obs[ , '(Intercept)']
> plot(df$r, df$r.est)
> qqnorm(df$r.est)

My results (posted on CV) are two overlapping clusters of points: in one r
and r.est show the expected correlation, in the other there is no
correlation. The normal QQ plot makes it look like different normal
distributions are obtained for positive and negative intercepts.

Thanks,
Ian

-- 
Ian Carroll | itc2 at georgetown.edu | 202-784-7182

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jun 22 20:47:40 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Jun 2015 14:47:40 -0400
Subject: [R-sig-ME] recover simulated individual-level random effects
 with glmer?
In-Reply-To: <CAMyusG8EVeTFZYHC0fhcaEC4NvqBVW=K5OgCcg2vetaNFVt2UQ@mail.gmail.com>
References: <CAMyusG8EVeTFZYHC0fhcaEC4NvqBVW=K5OgCcg2vetaNFVt2UQ@mail.gmail.com>
Message-ID: <5588584C.6090206@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-06-22 11:36 AM, Ian Carroll wrote:
> I raised this question yesterday on Cross Validated ( 
> stats.stackexchange.com/q/158043/43122), but now realize this might
> be the more appropriate forum for help. Please excuse the
> cross-post if you track both.
> 
> I simulated count data with an observation level random effect,
> then fit a Poisson-family GLMM using glmer (lme4 version 1.1-7).
> The fitted random intercepts show a strange pattern when compared
> to the simulated data, and produce a kinked QQ plot. If this is
> expected, why is it okay? If not, what am I doing wrong?
> 
> Simulated data and fitting:
>> n <- 1000 df <- data.frame(obs=factor(1:n)) df$x <- rnorm(n) df$r
>> <- rnorm(n, sd=3) df$y <- rpois(n=n, lambda=exp(2*df$x + df$r)) 
>> glmer.fit <- glmer(y ~ x + (1|obs), family='poisson', data=df)
> 
> Questioned results:
>> df$r.est <- ranef(glmer.fit)$obs[ , '(Intercept)'] plot(df$r,
>> df$r.est) qqnorm(df$r.est)
> 
> My results (posted on CV) are two overlapping clusters of points:
> in one r and r.est show the expected correlation, in the other
> there is no correlation. The normal QQ plot makes it look like
> different normal distributions are obtained for positive and
> negative intercepts.
> 
> Thanks, Ian


  I think this is inevitable.  If you think about it, the distribution
of the *conditional* modes of the observations with y=0 must be
different from that of the conditional modes of the obs. with y>0.
This is much easier to see with an even more trivial model that
doesn't include a covariate (see below ...)

  I don't think actually violates any of the assumptions we're using.
If you're worried about its effects on estimation & inference you
could do some simulation examples to see if it affects whatever it is
you're interested in (type I error rate, bias/variance of parameter
estimation, etc.)

library(lme4)
library(plyr) ## for mutate
set.seed(101)
n <- 1000
df <- data.frame(obs=factor(1:n),x=rnorm(n))
df <- mutate(df,
             r=rnorm(n, sd=3),
             y=rpois(n=n, lambda=exp(2*x + r)),
             y2 = rpois(n=n,lambda=exp(r)))


glmer.fit <- glmer(y ~ x + (1|obs), family='poisson', data=df)
glmer.fit2 <- update(glmer.fit,nAGQ=20)
glmer.fit3 <- update(glmer.fit, y2 ~ 1 + (1|obs))

## df$r.est <- ranef(glmer.fit2)$obs[ , '(Intercept)']
df$r.est <- ranef(glmer.fit3)$obs[ , '(Intercept)']
cvec <- c("#000000","#FF000080")
cvec2 <- cvec[as.numeric(df$y2==0)+1]
plot(df$r, df$r.est,col=cvec2)

qqnorm(df$r.est,col=cvec[as.numeric(df$y2==0)+1])

df$y2cat <- cut(df$y2,right=FALSE,include.lowest=TRUE,
                    breaks=c(0:6,Inf))
library("ggplot2"); theme_set(theme_bw())
ggplot(df,aes(r.est,fill=y))+
    geom_histogram(alpha=0.5,position="identity",
                   aes(y = ..density..))
ggplot(df,aes(r.est,fill=ycat))+
    geom_density(alpha=0.5,position="identity")



-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJViFhMAAoJEOCV5YRblxUH8gMIAMiLYfW2C57AYTyrVjb660wg
uvAkJGQjZ9ORIdm/MqDRydKTuNV16r3WfwSPXWCdLDBJjpdDq2w3dO5CxsbYjOH+
q7L0NWdX0KRjb1oKF2muLbz38dvH6Z4ExjOmJlW3funuVzCVvzhIGV7N/iIMqp5D
yTnK2y/YeVySuO91MqBgbKNtH/mGTfH1iGMbmhrssF1y8EfeWrw6RF7/uti8vhWE
cvAUDtkz74Q1gfJVyeCRPVRj7ADRb6tN7FuWbqukfEoK5etqYkO5QRIv6BLR4qoU
Hs+zPCymno6JZZDpY/D1UG5HChyXJZjFN6Xj7e+gnPtAvBUa5UTIxfy+z1cblT4=
=Ygc1
-----END PGP SIGNATURE-----


From nicodeguines at gmail.com  Mon Jun 22 21:21:43 2015
From: nicodeguines at gmail.com (Nicolas Deguines)
Date: Mon, 22 Jun 2015 12:21:43 -0700
Subject: [R-sig-ME] lme4 - equal estimates of regression coefficients
 across levels of a random effect
In-Reply-To: <CAJuCY5w7HcXyF6j=H2Sz-_HVoVFW7rYvD8=Jut53q=-5o62ZjQ@mail.gmail.com>
References: <CAFzZfa2VRCa_w3bnrxHwfOkTAGu3+hL5jU5NnEOxfu7nZjKGMg@mail.gmail.com>
	<CAJuCY5w7HcXyF6j=H2Sz-_HVoVFW7rYvD8=Jut53q=-5o62ZjQ@mail.gmail.com>
Message-ID: <CAFzZfa0W7UPCDL-6qTVfHOS=sv8_nAq1v+KoUktVT8f38ecTmA@mail.gmail.com>

Thank you Thierry for the note and pointing out the the glmm wiki FAQ.

I understand the models are different but does anyone have more specifics
regarding the meaning of coding a random effect on the slope of multiple
fixed variables, ie what's the difference between:
glmer(response ~ x1 + x2 + x3 + x4 +(x1|year) +(x2|year) +(x3|year)
+(x4|year), ? )
and
glmer(response ~ x1 + x2 + x3 + x4 +(x1 + x2 +x3 +x4 | year), ? )

Best,
Nicolas


On Thu, Jun 11, 2015 at 10:17 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Nicolas,
>
> Those models are different, hence you get different results. Note that two
> levels are not enough to get stable variance estimates for the random
> effect. See glmm wiki FAQ.
> Op 11-jun.-2015 18:39 schreef "Nicolas Deguines" <nicodeguines at gmail.com>:
>
>> Dear lme4 authors & users,
>>
>> I?m a postdoctoral research scholar working on the effect of
>> precipitation on the food web of a grassland semi-arid ecosystem in
>> California.
>>
>> I am analyzing my dataset with version 1.1-7 of the lme4 package with
>> version 3.2.0 of R.
>> I encountered an issue while running a glmer model that includes
>> random effects from a categorical variable (?year?, 2010 and 2011) on
>> the slope of four explanatory variables.
>> Precisely, the estimated slope coefficients for 1 out of 4 explanatory
>> variables are identical in the two years. However, when running a
>> model including only this particular explanatory variable and the same
>> random effect from year on slope, estimates are different for the two
>> years (indeed, I did check that values are different in the two years.
>>
>> It also happens for other models I?m running, e.g. with that
>> particular explanatory variable + two new ones: this time though, the
>> slope coefficients are different for that particular variable but
>> identical for the two new ones (nb: the response variable in this
>> model differs from the 1st model discussed).
>>
>> Is this an issue that already occurred to other lme4 users? Any idea
>> about what I may be doing wrong?
>> I suspect it may come from the syntax of my models. I had fitted my model
>> as:
>> glmer(response ~ x1 + x2 + x3 + x4 +(x1|year) +(x2|year) +(x3|year)
>> +(x4|year), ? )
>> But I tried the following model:
>> glmer(response ~ x1 + x2 + x3 + x4 +(x1 + x2 +x3 +x4 | year), ? )
>> it does estimate different slope coefficients for each year.
>> I don?t know what meanings are associated with these two different
>> syntaxes though, and I would really appreciate any information or
>> reference anyone can give to clarify this.
>>
>> I would be glad to provide additional information that may be needed
>> about the models or the dataset.
>>
>> I take the opportunity while writing this email to thank lme4 authors
>> for developing and improving the very useful package that is lme4!
>>
>> Best regards,
>> Nicolas Deguines
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jun 22 21:48:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Jun 2015 15:48:00 -0400
Subject: [R-sig-ME] lme4 - equal estimates of regression coefficients
 across levels of a random effect
In-Reply-To: <CAFzZfa0W7UPCDL-6qTVfHOS=sv8_nAq1v+KoUktVT8f38ecTmA@mail.gmail.com>
References: <CAFzZfa2VRCa_w3bnrxHwfOkTAGu3+hL5jU5NnEOxfu7nZjKGMg@mail.gmail.com>	<CAJuCY5w7HcXyF6j=H2Sz-_HVoVFW7rYvD8=Jut53q=-5o62ZjQ@mail.gmail.com>
	<CAFzZfa0W7UPCDL-6qTVfHOS=sv8_nAq1v+KoUktVT8f38ecTmA@mail.gmail.com>
Message-ID: <55886670.4040609@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-06-22 03:21 PM, Nicolas Deguines wrote:
> Thank you Thierry for the note and pointing out the the glmm wiki
> FAQ.
> 
> I understand the models are different but does anyone have more
> specifics regarding the meaning of coding a random effect on the
> slope of multiple fixed variables, ie what's the difference
> between: glmer(response ~ x1 + x2 + x3 + x4 +(x1|year) +(x2|year)
> +(x3|year) +(x4|year), ? ) and glmer(response ~ x1 + x2 + x3 + x4
> +(x1 + x2 +x3 +x4 | year), ? )
> 
> Best, Nicolas
> 
> 
> On Thu, Jun 11, 2015 at 10:17 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be
>> wrote:
> 
>> Dear Nicolas,
>> 
>> Those models are different, hence you get different results. Note
>> that two levels are not enough to get stable variance estimates
>> for the random effect. See glmm wiki FAQ. Op 11-jun.-2015 18:39
>> schreef "Nicolas Deguines" <nicodeguines at gmail.com>:
>> 
>>> Dear lme4 authors & users,
>>> 
>>> I?m a postdoctoral research scholar working on the effect of 
>>> precipitation on the food web of a grassland semi-arid
>>> ecosystem in California.
>>> 
>>> I am analyzing my dataset with version 1.1-7 of the lme4
>>> package with version 3.2.0 of R. I encountered an issue while
>>> running a glmer model that includes random effects from a
>>> categorical variable (?year?, 2010 and 2011) on the slope of
>>> four explanatory variables. Precisely, the estimated slope
>>> coefficients for 1 out of 4 explanatory variables are identical
>>> in the two years. However, when running a model including only
>>> this particular explanatory variable and the same random effect
>>> from year on slope, estimates are different for the two years
>>> (indeed, I did check that values are different in the two
>>> years.
>>> 
>>> It also happens for other models I?m running, e.g. with that 
>>> particular explanatory variable + two new ones: this time
>>> though, the slope coefficients are different for that
>>> particular variable but identical for the two new ones (nb: the
>>> response variable in this model differs from the 1st model
>>> discussed).
>>> 
>>> Is this an issue that already occurred to other lme4 users? Any
>>> idea about what I may be doing wrong? I suspect it may come
>>> from the syntax of my models. I had fitted my model as: 
>>> glmer(response ~ x1 + x2 + x3 + x4 +(x1|year) +(x2|year)
>>> +(x3|year) +(x4|year), ? ) But I tried the following model: 
>>> glmer(response ~ x1 + x2 + x3 + x4 +(x1 + x2 +x3 +x4 | year), ?
>>> ) it does estimate different slope coefficients for each year. 
>>> I don?t know what meanings are associated with these two
>>> different syntaxes though, and I would really appreciate any
>>> information or reference anyone can give to clarify this.

  I would like to start by emphasizing Thierry's point that it really
doesn't make sense to fit a random effect for a grouping variable with
only two levels.  That said, for future reference:


  Your first model fits slope *and* intercept for each response
separately; you probably want

 (1|year) + (0+x1|year) + (0+x2|year) + (0+x3|year)+(0+x4|year)

*or*

  (1+x1+x2+x3+x4||year)

instead.  Each of these fits 5 variance parameters, *assuming* the
random effects are uncorrelated.

  (x1+x2+x3+x4|year)  fits a 5x5 (including the intercept term)
variance-covariance matrix.  It is more general and arguably better
because it is robust to recentering -- the meaning and predictions of
the independent-terms model if you subtract a constant value from any
of the predictors -- but it is also much more complex and so may
overwhelm your data or your computer.  (This comes up in the current
Bates et al. "Parsimonious mixed models" vs Barr et al (2013) "Keep it
maximal" debate ...)




>>> 
>>> I would be glad to provide additional information that may be
>>> needed about the models or the dataset.
>>> 
>>> I take the opportunity while writing this email to thank lme4
>>> authors for developing and improving the very useful package
>>> that is lme4!
>>> 
>>> Best regards, Nicolas Deguines
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJViGZvAAoJEOCV5YRblxUHTgQIAJ3L47BSSgYcezMByair6Oje
74VCPk3Dk9cBmOFp0PS+omafYOdjwGIA4lQ+wY05PHIrcpm7faIgdAZg9J3KPom5
WndhldlJ6s5pAFbqmiFmEHeAQwEC7J3Z9952xcEVo4YKGC6x2y7vUjgywNKLH9cN
Kx4WqYQ4JSY1aHeYAlWF10YIFz/oC0HaYsW1mNhc0tA5nl5dGOl5ZqHBqM3vH+Fq
wPhTaZZQEfqyxhR+QKFwivtt+eypV+5qP6+WbD49EQgwZfkC3ZDmWgmW6a2LzoTr
UCg+alD6fMDWFVltdtWpTH40zMMezBeBMmNGdPDMoNl3yODyEqxBj7AhmtXiBUs=
=NeFY
-----END PGP SIGNATURE-----


From chirleu at gmail.com  Tue Jun 23 09:00:18 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Tue, 23 Jun 2015 09:00:18 +0200
Subject: [R-sig-ME] correct specification and interpretation of
 multivariate mixed-model in lme
In-Reply-To: <CAJuCY5zBC+4y4r8t7=ujZ28+T-HmCf_OnabPPefpFAPNQgT6nQ@mail.gmail.com>
References: <CALC46t-3e=258GTUyokSuYZ0mf4=8-mGrh1-UQ0e-7TAJSysVA@mail.gmail.com>
	<CAJuCY5zBC+4y4r8t7=ujZ28+T-HmCf_OnabPPefpFAPNQgT6nQ@mail.gmail.com>
Message-ID: <CALC46t_6OPoV0GCN-88fuB2OksvDigW47MLMfStDQ-ASMtuLSA@mail.gmail.com>

Dear Thierry, thanks for the comments (I'll try what you suggest) and the
link to INLA, which I didn't know - but seems really useful for some of my
data.
David

2015-06-22 16:47 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear David,
>
> 1. It's best to use a "timer" variable. You want either
> corAR1(form=~timer|id) or corAR1(form=~timer|id:trait). Note that the
> correlation only works on the residuals within the same grouping
> level. Residuals among levels are assumed to be be independent;
> 2. You allow for a difference residual variance among trait. It's up
> to you to decide whether this makes sense.
> 3. trait-1 is equivalent with a different intercept for each trait. It
> makes sense to always include the interaction between trait and the
> other covariates.
> 4. You'll have to try it.
>
> Note that the INLA packages allows for multivariate mixed models too.
> It allows for correlated random effects (rather than correlated
> residuals). You can find INLA at R-inla.org
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2015-06-22 11:16 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:
> > Dear list,
> > I have a dataset of 8 response variables measured every month during a
> > period of 3 years for 290 individuals. Not all individuals have the same
> > number of replicates (range=3-18, mean=8). I'm trying to specify a
> > multivariate mixed-model using lme because *I'm interested in getting the
> > among-individual variace-covariance matrix.* I have made some attempts in
> > MCMCglmm using the following model:
> >
> >
> mcmc1=MCMCglmm(cbind(t1,t2,t3,t4,t5,t6,t7,t8)~trait-1,random=~us(trait):id,rcov=~us(trait):units,data=wide2,
> >
> >
> family=c("gaussian","gaussian","gaussian","gaussian","gaussian","gaussian","gaussian","gaussian"),verbose=FALSE,prior=prior1,pr=TRUE)
> >
> > However, there is strong temporal autocorrelation inside each individual
> > time series, and this is reflected in the residuals of the MCMCglmm
> model.
> > So my only alternative is to use lme (I guess). The univariate lme models
> > for each trait separately included an autocorrelation term (corAR1 in
> most
> > cases) which completely accounted for the temporal autocorrelation. So I
> > wanted to use the same approach for the multivariate model. Nevertheless
> I
> > haven't found much information on how to fit a multivariate lme. I have
> > checked the following sources:
> >
> >    -
> >
> http://stats.stackexchange.com/questions/108779/multivariate-model-in-lme-with-independent-random-effect-similar-to-mcmcglmm
> >    -
> >
> http://scs.math.yorku.ca/index.php/Mixed_Models_with_R/Multivariate_Mixed_Models.Rmd
> >    -
> >
> http://rstudio-pubs-static.s3.amazonaws.com/3336_03636030d93d47de9131e625b72f58c6.html
> >    - Alain Zuur book on "Mixed effects models and extensions in Ecology
> >    with R"
> >
> >
> > However I'm still not sure about how to specify the model I need.
> >
> > This is the head() and str() of my data (which is already in long
> format):
> >
> >> head(long)
> >            key trait      value   id month_year month year
> > 1 2011-05 5491   t1   0.5039553 5491    2011-05     5 2011
> > 2 2011-05 5492   t1   1.1132514 5492    2011-05     5 2011
> > 3 2011-05 5493   t1   1.7398036 5493    2011-05     5 2011
> > 4 2011-05 5494   t1  -0.1328723 5494    2011-05     5 2011
> > 5 2011-05 5495   t1   0.5433441 5495    2011-05     5 2011
> > 6 2011-05 5496   t1   0.8299277 5496    2011-05     5 2011
> >
> >> str(long)
> > 'data.frame': 17992 obs. of  7 variables:
> >  $ key       : Factor w/ 2249 levels "2011-05 5491",..: 1 2 3 4 5 6 7 8 9
> > 10 ...
> >  $ trait     : Factor w/ 8 levels "t1","t2","t3",..: 1 1 1 1 1 1 1 1 1 1
> ...
> >  $ value     : num  0.504 1.113 1.74 -0.133 0.543 ...
> >  $ id        : Factor w/ 274 levels "5488","5489",..: 3 4 5 6 7 8 23 24
> 25
> > 26 ...
> >  $ month_year: chr  "2011-05" "2011-05" "2011-05" "2011-05" ...
> >  $ month     : num  5 5 5 5 5 5 5 5 5 5 ...
> >  $ year      : Factor w/ 4 levels "2011","2012",..: 1 1 1 1 1 1 1 1 1 1
> ...
> >
> >
> > Ideally, I want to fit exactly the same model I fit with MCMCglmm but
> > including the correlation term. This is my best attempt so far:
> >
> > model=lme(value~trait-1, random=~trait-1|id,
> > weights=varIdent(form=~1|trait),
> > correlation=corAR1(form=trait~1|id),data=long)
> >
> > My questions are:
> >
> >    1. Correlation term: I need to account for temporal autocorrelation
> >    within each response variable and for each individual. Is it correctly
> >    specified? Or should I create a "timer" variable that specifies the
> >    temporal order of the data, and include it in the correlation term?
> Because
> >    right now I'm not telling the correlation term that the replicates
> follow a
> >    temporal order I think. How could I specify that? In the univariate
> models
> >    my correlation term was corAR1(form=~timer), being timer a dummy
> variable
> >    reflecting the "time sequence".
> >    2. My aim including the weights term is to account for different
> >    variances of the different response variables. I guess this is
> strictly
> >    neccesary, correct?
> >    3. There are no fixed effects in the model yet, so the fixed part is
> >    reduced to trait-1. Correct? In case I want to account for month
> variation
> >    within each reponse variable, how should I include it in the fixed
> part of
> >    the model: (trait*month-1)?
> >
> > Of course I'm aware that the model might not converge with 8 response
> > variables (actually it doesn't...but maybe because it is not correctly
> > specified), but once I know how to specifiy what I want properly, I can
> try
> > with less variables (perhaps 3-4). However, one last very general
> question:
> >
> >       4. In general, if a MCMCglmm model with 8 responses converge,
> should
> > I expect convergence as well in lme?
> >
> > I'd trully appreciate your advise. Please let me know if providing the
> > dataset helps.
> >
> > Many thanks,
> >
> > David
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jun 23 14:11:11 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 23 Jun 2015 14:11:11 +0200
Subject: [R-sig-ME] recover simulated individual-level random effects
	with glmer?
In-Reply-To: <5588584C.6090206@gmail.com>
References: <CAMyusG8EVeTFZYHC0fhcaEC4NvqBVW=K5OgCcg2vetaNFVt2UQ@mail.gmail.com>
	<5588584C.6090206@gmail.com>
Message-ID: <CAJuCY5wEzvGVmnHN=_uNrzXt-L+jEvdUwfoziCjDTFSrCbN2Ng@mail.gmail.com>

Dear Ian,

Just a little remark on the variance of the observation level random
effect (ORLE). sd = 3 leads to a huge effect.

- We assume ORLE ~ N(0, sigma)
- Let's look at the 2.5% quantile for small values and the 97.5% for
high values.
- Hence the 2.5% and 97.5% quantiles are low = -1.96 * sigma and high
= 1.96 * sigma.
- high - low = 3.912 * sigma
- The ORLE is estimated on the log-scale. Backtransforming the
difference give the ratio between both quantiles:
- log(high - low) = log(high/low) = 3.912* sigma
- high / low = exp(3.912 * sigma)

The last expression yields 127999 when sigma = 3. So high = 127999 * low!!!!

Bottom-line: be very, very, very careful when you use an OLRE when its
variance is large. The tricky part is that even low numbers like sigma
= 3 trigger huge effects.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-06-22 20:47 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-06-22 11:36 AM, Ian Carroll wrote:
>> I raised this question yesterday on Cross Validated (
>> stats.stackexchange.com/q/158043/43122), but now realize this might
>> be the more appropriate forum for help. Please excuse the
>> cross-post if you track both.
>>
>> I simulated count data with an observation level random effect,
>> then fit a Poisson-family GLMM using glmer (lme4 version 1.1-7).
>> The fitted random intercepts show a strange pattern when compared
>> to the simulated data, and produce a kinked QQ plot. If this is
>> expected, why is it okay? If not, what am I doing wrong?
>>
>> Simulated data and fitting:
>>> n <- 1000 df <- data.frame(obs=factor(1:n)) df$x <- rnorm(n) df$r
>>> <- rnorm(n, sd=3) df$y <- rpois(n=n, lambda=exp(2*df$x + df$r))
>>> glmer.fit <- glmer(y ~ x + (1|obs), family='poisson', data=df)
>>
>> Questioned results:
>>> df$r.est <- ranef(glmer.fit)$obs[ , '(Intercept)'] plot(df$r,
>>> df$r.est) qqnorm(df$r.est)
>>
>> My results (posted on CV) are two overlapping clusters of points:
>> in one r and r.est show the expected correlation, in the other
>> there is no correlation. The normal QQ plot makes it look like
>> different normal distributions are obtained for positive and
>> negative intercepts.
>>
>> Thanks, Ian
>
>
>   I think this is inevitable.  If you think about it, the distribution
> of the *conditional* modes of the observations with y=0 must be
> different from that of the conditional modes of the obs. with y>0.
> This is much easier to see with an even more trivial model that
> doesn't include a covariate (see below ...)
>
>   I don't think actually violates any of the assumptions we're using.
> If you're worried about its effects on estimation & inference you
> could do some simulation examples to see if it affects whatever it is
> you're interested in (type I error rate, bias/variance of parameter
> estimation, etc.)
>
> library(lme4)
> library(plyr) ## for mutate
> set.seed(101)
> n <- 1000
> df <- data.frame(obs=factor(1:n),x=rnorm(n))
> df <- mutate(df,
>              r=rnorm(n, sd=3),
>              y=rpois(n=n, lambda=exp(2*x + r)),
>              y2 = rpois(n=n,lambda=exp(r)))
>
>
> glmer.fit <- glmer(y ~ x + (1|obs), family='poisson', data=df)
> glmer.fit2 <- update(glmer.fit,nAGQ=20)
> glmer.fit3 <- update(glmer.fit, y2 ~ 1 + (1|obs))
>
> ## df$r.est <- ranef(glmer.fit2)$obs[ , '(Intercept)']
> df$r.est <- ranef(glmer.fit3)$obs[ , '(Intercept)']
> cvec <- c("#000000","#FF000080")
> cvec2 <- cvec[as.numeric(df$y2==0)+1]
> plot(df$r, df$r.est,col=cvec2)
>
> qqnorm(df$r.est,col=cvec[as.numeric(df$y2==0)+1])
>
> df$y2cat <- cut(df$y2,right=FALSE,include.lowest=TRUE,
>                     breaks=c(0:6,Inf))
> library("ggplot2"); theme_set(theme_bw())
> ggplot(df,aes(r.est,fill=y))+
>     geom_histogram(alpha=0.5,position="identity",
>                    aes(y = ..density..))
> ggplot(df,aes(r.est,fill=ycat))+
>     geom_density(alpha=0.5,position="identity")
>
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJViFhMAAoJEOCV5YRblxUH8gMIAMiLYfW2C57AYTyrVjb660wg
> uvAkJGQjZ9ORIdm/MqDRydKTuNV16r3WfwSPXWCdLDBJjpdDq2w3dO5CxsbYjOH+
> q7L0NWdX0KRjb1oKF2muLbz38dvH6Z4ExjOmJlW3funuVzCVvzhIGV7N/iIMqp5D
> yTnK2y/YeVySuO91MqBgbKNtH/mGTfH1iGMbmhrssF1y8EfeWrw6RF7/uti8vhWE
> cvAUDtkz74Q1gfJVyeCRPVRj7ADRb6tN7FuWbqukfEoK5etqYkO5QRIv6BLR4qoU
> Hs+zPCymno6JZZDpY/D1UG5HChyXJZjFN6Xj7e+gnPtAvBUa5UTIxfy+z1cblT4=
> =Ygc1
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Tom.Wenseleers at bio.kuleuven.be  Tue Jun 23 17:02:47 2015
From: Tom.Wenseleers at bio.kuleuven.be (Tom Wenseleers)
Date: Tue, 23 Jun 2015 15:02:47 +0000
Subject: [R-sig-ME] Specification of binomial mixed model with custom
	intercept
Message-ID: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>

Dear all,
I have a binomial mixed model
fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time,family=binomial,data=data)
in which I am modelling the evolution of an infection in different social insect colonies across two treatment groups (INJECTED and CONTROL) as a function of time. 
However, as my INJECTED group individuals should all be infected at time=0, whereas none of my CONTROL individuals should be infected at time=0, I would like to force the model to go approx through 1 at time t=0 for the INJECTED group and to go approx through 0 at time t=1 for the CONTROL group. What would be the correct way to specify such a model?
I tried with
data$baseline=qlogis(c(0.001,0.999))[data$treatment]
fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time+offset(baseline),family=binomial,data=data)
but this doesn't seem to give sensible predictions.
Any thoughts on the correct syntax?

cheers,
Tom Wenseleers



From jake987722 at hotmail.com  Tue Jun 23 17:30:43 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Tue, 23 Jun 2015 09:30:43 -0600
Subject: [R-sig-ME] Specification of binomial mixed model with custom
 intercept
In-Reply-To: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>
Message-ID: <COL129-W198183686B973039916732CBA00@phx.gbl>

Hi Tom,

I'm not sure if this is a sensible thing to do. If your presumption about the proportion of infected insects in each group at time=0 is correct, then surely your data must already reflect this fact? In which case I don't see why you can't just estimate the unconstrained model that you wrote and let the model figure out for itself what p(infected) is at time=0. In short, I don't see the added value of the constraints you mention.

With that said, it occurs to me that if you really do want to implement the two constraints that you mentioned, then really you are not estimating any fixed-effect parameters at time=0. So it seems you could just as well exclude the time=0 data and just model the treatment factor at time=1. From those parameter estimates it would be easier to figure out what the time slopes are for each group, since they will just be the difference between the time=1 parameter estimates and whatever values you fixed the proportions at time=0 to. Hope this makes sense.

Jake

> From: Tom.Wenseleers at bio.kuleuven.be
> To: r-sig-mixed-models at r-project.org
> Date: Tue, 23 Jun 2015 15:02:47 +0000
> Subject: [R-sig-ME] Specification of binomial mixed model with custom	intercept
> 
> Dear all,
> I have a binomial mixed model
> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time,family=binomial,data=data)
> in which I am modelling the evolution of an infection in different social insect colonies across two treatment groups (INJECTED and CONTROL) as a function of time. 
> However, as my INJECTED group individuals should all be infected at time=0, whereas none of my CONTROL individuals should be infected at time=0, I would like to force the model to go approx through 1 at time t=0 for the INJECTED group and to go approx through 0 at time t=1 for the CONTROL group. What would be the correct way to specify such a model?
> I tried with
> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time+offset(baseline),family=binomial,data=data)
> but this doesn't seem to give sensible predictions.
> Any thoughts on the correct syntax?
> 
> cheers,
> Tom Wenseleers
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From Tom.Wenseleers at bio.kuleuven.be  Tue Jun 23 21:35:20 2015
From: Tom.Wenseleers at bio.kuleuven.be (Tom Wenseleers)
Date: Tue, 23 Jun 2015 19:35:20 +0000
Subject: [R-sig-ME] Specification of binomial mixed model with custom
 intercept
In-Reply-To: <COL129-W198183686B973039916732CBA00@phx.gbl>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W198183686B973039916732CBA00@phx.gbl>
Message-ID: <37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>

Hi Jake,
Well to clarify a bit - I have actual datapoints for time=4, 8, 12 and 16, but not for t=0 days.
For t=0, however, I know that based on my treatments (injecting individuals with virus lysate or with buffer) the proportion of infected individuals was ca 0% for the CONTROL treatment and 100% for the INJECTED group.
Problem is that if this a priori constraint is not taken into account and I fit my model and make an effect plot, the prediction is not exactly 0% for the CONTROL group or 100% for the INJECTED group, even though I know that it should. So my question is whether constraints such as these can be taken into account into either binomial GLMs or binomial mixed models, e.g. by specifying custom offsets/intercepts? (I also have other similar models where I would like to be able to specify that at time=0 the initial proportion is known a priori to be 0.5)

In general my aim of specifying constraints such as these would be to obtain better fits that better/more parsimoniously reflect known facts about the actual experiments.

cheers,
Tom

________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jake Westfall [jake987722 at hotmail.com]
Sent: 23 June 2015 17:30
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Specification of binomial mixed model with custom intercept

Hi Tom,

I'm not sure if this is a sensible thing to do. If your presumption about the proportion of infected insects in each group at time=0 is correct, then surely your data must already reflect this fact? In which case I don't see why you can't just estimate the unconstrained model that you wrote and let the model figure out for itself what p(infected) is at time=0. In short, I don't see the added value of the constraints you mention.

With that said, it occurs to me that if you really do want to implement the two constraints that you mentioned, then really you are not estimating any fixed-effect parameters at time=0. So it seems you could just as well exclude the time=0 data and just model the treatment factor at time=1. From those parameter estimates it would be easier to figure out what the time slopes are for each group, since they will just be the difference between the time=1 parameter estimates and whatever values you fixed the proportions at time=0 to. Hope this makes sense.

Jake

> From: Tom.Wenseleers at bio.kuleuven.be
> To: r-sig-mixed-models at r-project.org
> Date: Tue, 23 Jun 2015 15:02:47 +0000
> Subject: [R-sig-ME] Specification of binomial mixed model with custom intercept
>
> Dear all,
> I have a binomial mixed model
> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time,family=binomial,data=data)
> in which I am modelling the evolution of an infection in different social insect colonies across two treatment groups (INJECTED and CONTROL) as a function of time.
> However, as my INJECTED group individuals should all be infected at time=0, whereas none of my CONTROL individuals should be infected at time=0, I would like to force the model to go approx through 1 at time t=0 for the INJECTED group and to go approx through 0 at time t=1 for the CONTROL group. What would be the correct way to specify such a model?
> I tried with
> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time+offset(baseline),family=binomial,data=data)
> but this doesn't seem to give sensible predictions.
> Any thoughts on the correct syntax?
>
> cheers,
> Tom Wenseleers
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Tom.Wenseleers at bio.kuleuven.be  Tue Jun 23 23:23:01 2015
From: Tom.Wenseleers at bio.kuleuven.be (Tom Wenseleers)
Date: Tue, 23 Jun 2015 21:23:01 +0000
Subject: [R-sig-ME] Specification of binomial mixed model with custom
 intercept
In-Reply-To: <COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W198183686B973039916732CBA00@phx.gbl>,
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
Message-ID: <37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>

Hi Jake,
Many thanks for your advice! And yes realised the model would never quite get to 0% or 100% - that's why I had been trying putting in an intercept, as in
data$baseline=qlogis(c(0.001,0.999))[data$treatment]

But just tried adding points for t=0 and that does indeed seem to give sensible results - so I'll go with that then - thanks for the advice!

If anyone else on this list would know how to formally put in constraints like the ones I mentioned, please let me know though!

cheers,
Tom

________________________________
From: Jake Westfall [jake987722 at hotmail.com]
Sent: 23 June 2015 23:01
To: Tom Wenseleers
Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept

I see. This does seem more sensible. One complication I should point out is that you will never get your model to predict exactly 100% or 0%, as these correspond to logits of infinity or -infinity, respectively. You could set them to something high like logit = +/- 10 (corresonding to p = .99995 or .00005), but the exact values you fix them to are arbitrary and will affect the other model estimates. So it's tricky. One sort of klugey solution could be to put the time=0 measurements in the dataset "as if" you had recorded them -- with the justification being that you are virtually certain what the measurements would have been had you technically taken them at time=0 -- and then run the unconstrained model. This would basically just be a not-completely-arbitrary way of deciding what non-infinite values to fix the time=0 predictions to.


Jake

> From: Tom.Wenseleers at bio.kuleuven.be
> To: jake987722 at hotmail.com; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept
> Date: Tue, 23 Jun 2015 19:35:20 +0000
>
> Hi Jake,
> Well to clarify a bit - I have actual datapoints for time=4, 8, 12 and 16, but not for t=0 days.
> For t=0, however, I know that based on my treatments (injecting individuals with virus lysate or with buffer) the proportion of infected individuals was ca 0% for the CONTROL treatment and 100% for the INJECTED group.
> Problem is that if this a priori constraint is not taken into account and I fit my model and make an effect plot, the prediction is not exactly 0% for the CONTROL group or 100% for the INJECTED group, even though I know that it should. So my question is whether constraints such as these can be taken into account into either binomial GLMs or binomial mixed models, e.g. by specifying custom offsets/intercepts? (I also have other similar models where I would like to be able to specify that at time=0 the initial proportion is known a priori to be 0.5)
>
> In general my aim of specifying constraints such as these would be to obtain better fits that better/more parsimoniously reflect known facts about the actual experiments.
>
> cheers,
> Tom
>
> ________________________________________
> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jake Westfall [jake987722 at hotmail.com]
> Sent: 23 June 2015 17:30
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Specification of binomial mixed model with custom intercept
>
> Hi Tom,
>
> I'm not sure if this is a sensible thing to do. If your presumption about the proportion of infected insects in each group at time=0 is correct, then surely your data must already reflect this fact? In which case I don't see why you can't just estimate the unconstrained model that you wrote and let the model figure out for itself what p(infected) is at time=0. In short, I don't see the added value of the constraints you mention.
>
> With that said, it occurs to me that if you really do want to implement the two constraints that you mentioned, then really you are not estimating any fixed-effect parameters at time=0. So it seems you could just as well exclude the time=0 data and just model the treatment factor at time=1. >From those parameter estimates it would be easier to figure out what the time slopes are for each group, since they will just be the difference between the time=1 parameter estimates and whatever values you fixed the proportions at time=0 to. Hope this makes sense.
>
> Jake
>
> > From: Tom.Wenseleers at bio.kuleuven.be
> > To: r-sig-mixed-models at r-project.org
> > Date: Tue, 23 Jun 2015 15:02:47 +0000
> > Subject: [R-sig-ME] Specification of binomial mixed model with custom intercept
> >
> > Dear all,
> > I have a binomial mixed model
> > fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time,family=binomial,data=data)
> > in which I am modelling the evolution of an infection in different social insect colonies across two treatment groups (INJECTED and CONTROL) as a function of time.
> > However, as my INJECTED group individuals should all be infected at time=0, whereas none of my CONTROL individuals should be infected at time=0, I would like to force the model to go approx through 1 at time t=0 for the INJECTED group and to go approx through 0 at time t=1 for the CONTROL group. What would be the correct way to specify such a model?
> > I tried with
> > data$baseline=qlogis(c(0.001,0.999))[data$treatment]
> > fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time+offset(baseline),family=binomial,data=data)
> > but this doesn't seem to give sensible predictions.
> > Any thoughts on the correct syntax?
> >
> > cheers,
> > Tom Wenseleers
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mainajm at gmail.com  Wed Jun 24 02:10:55 2015
From: mainajm at gmail.com (Joseph Maina)
Date: Wed, 24 Jun 2015 10:10:55 +1000
Subject: [R-sig-ME] glmer and lme4 - Quick question
Message-ID: <01711809-16EF-4984-BF87-4C1CAC1D3BAE@gmail.com>

Hi,
I am running glmer in a model selection framework with >30 explanatory variables, where I am first  generating all possible combinations of variables but with a multicollinearity test results coinstraint,  before fitting the gmler. I am also including random effects of ?Year' (~20) and Regions (~13). The objective is to find the best model and determine the relative influence among predictors, and also to predict the model over space to global pixels.

My question regards the model structure of lme4 that I should adopt. I am currently fitting my model in the following structure:
m1<-glmer(y  ~ x1 + x2 + x3 + (1 |Region) + (1 | Year) +(1|Region), family=binomial('logit'),data=all.data)

However, I have been advised that in order to have a varying intercept and slope among my Regions (one of the random effects), I should fit my model as follows:
m1<-glmer(y ~ x1+ (0+x1|Region) + x2 + (0+x2|Region) + x3 + (0+x3|Region) + (1 | Year) +(1|Region), family=binomial('logit'),data=all.data)

The latter is a slightly complex structure and I am running into convergence issues. I was wondering what are the merits of using either structure?.  Also in the second structure, I am not sure what ?0+? means or what value it adds to the analyses. I also found that when using the first model structure if I take out the ?Region? random effect, the estimates for some of the variables change signs, and therefore could have an implicaition on the interpretation. 

Thanks,

Joseph


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Jun 24 09:33:47 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 24 Jun 2015 09:33:47 +0200
Subject: [R-sig-ME] glmer and lme4 - Quick question
In-Reply-To: <01711809-16EF-4984-BF87-4C1CAC1D3BAE@gmail.com>
References: <01711809-16EF-4984-BF87-4C1CAC1D3BAE@gmail.com>
Message-ID: <CAJuCY5ytebDQZ4m7cjkTSv0PRLMDkXxMVE+xLoJwMMn9RoyRyQ@mail.gmail.com>

Dear Joseph,

Have a look at http://glmm.wikidot.com/faq and search for "model
specification".

Convergence warnings might indicate that your model is too complex for the
data.

I would consider something like L1-penalisation for the model selection.
Have a look at the glmmLasso package.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-24 2:10 GMT+02:00 Joseph Maina <mainajm at gmail.com>:

> Hi,
> I am running glmer in a model selection framework with >30 explanatory
> variables, where I am first  generating all possible combinations of
> variables but with a multicollinearity test results coinstraint,  before
> fitting the gmler. I am also including random effects of ?Year' (~20) and
> Regions (~13). The objective is to find the best model and determine the
> relative influence among predictors, and also to predict the model over
> space to global pixels.
>
> My question regards the model structure of lme4 that I should adopt. I am
> currently fitting my model in the following structure:
> m1<-glmer(y  ~ x1 + x2 + x3 + (1 |Region) + (1 | Year) +(1|Region),
> family=binomial('logit'),data=all.data)
>
> However, I have been advised that in order to have a varying intercept and
> slope among my Regions (one of the random effects), I should fit my model
> as follows:
> m1<-glmer(y ~ x1+ (0+x1|Region) + x2 + (0+x2|Region) + x3 + (0+x3|Region)
> + (1 | Year) +(1|Region), family=binomial('logit'),data=all.data)
>
> The latter is a slightly complex structure and I am running into
> convergence issues. I was wondering what are the merits of using either
> structure?.  Also in the second structure, I am not sure what ?0+? means or
> what value it adds to the analyses. I also found that when using the first
> model structure if I take out the ?Region? random effect, the estimates for
> some of the variables change signs, and therefore could have an
> implicaition on the interpretation.
>
> Thanks,
>
> Joseph
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From susanne.stat at gmx.de  Wed Jun 24 15:10:41 2015
From: susanne.stat at gmx.de (Susanne Susanne)
Date: Wed, 24 Jun 2015 15:10:41 +0200
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
Message-ID: <trinity-db018112-783b-43a1-9a33-1b110c22d7cc-1435151441429@3capp-gmx-bs42>


Hello everyone,
?
I just saw now, that my last emails were empty. I had this question regarding the lme4 package. 
I want to  regress a simple
 
  lmer(y ~ x + (x | group),

but the number of datapoints vary among groups.
 
So what I want is to weight groups, which have more measurements than others, slightly higher (as they provide more information).

 
My question is: Is this done automatically in the lmer() function or should I do it manually by myself?


It seems an easy question, but I tried a small example which I attached and it's very contradictory.

The upper two pictures seem to proove that lmer doesn't weight groups higher which report more datapoints. I get the same regression line, independent of whether the blue group has more or less datapoints.

In the lower two pictures I used the "weights=" argument to weight the blue group higher. And then suddenly it seems to matter how many datapoints a group has. I used the same weights in both pictures, but now I get different regression lines, dependent of how many datapoints the blue group has. 
??

I really need to know this for my thesis and would be very thankful if someone could help me!

Susanne
?

?

I add my code:

# Data 
# many Values 
x <- c(2, 4, 1, 1.25, 1.5,1.75, 2,2.25, 2.5, 2.75, 3, 3.25, 3.5,3.75,4,4.25, 4.5, 4.75, 5) 
y <- c(0.2, 0.4, 0.5, 0.525, 0.57, 0.575, 0.62, 0.625, 0.65, 0.677, 0.7,0.726,0.75,0.775,0.8,0.827,0.85,0.873, 0.9) 
group <- c(1,1,rep(2,17)) 

# Less values 
x <- c(2, 4, 1, 3.25, 5) y <- c(0.2, 0.4,0.5,0.726, 0.9) 
group <- c(1,1,rep(2,3)) 

# Weights 
if(weights == "Default"){ w <- NULL } 

if(weights == "Disequilibrated"){
   w <- c(1,1, rep(5000,17)) 
  # or for less values 
  w <- c(1,1, rep(5000,3)) 
  # scale weights to sum weights=number of values 
  w <- length(w)*w/sum(w) } 

# Lme Model 
lmeModel <- lmer(y ~ x + (x|group), weights=w) 
s <- summary(lmeModel) 

# Plot 
plot(x,y, pch=16, col=c(1,1,rep(2,17)), xlim=c(min(x),max(x)),ylim=c(min(y),max(y)), ylab="y",xlab="x",main="Random Intercept + Slope") abline(s$coefficients[1,1],s$coefficients[2,1], lty=2, col = 1)


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Plots.png
Type: image/png
Size: 52978 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150624/7151476b/attachment-0001.png>

From ken.beath at mq.edu.au  Wed Jun 24 15:23:44 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Wed, 24 Jun 2015 23:23:44 +1000
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
In-Reply-To: <trinity-db018112-783b-43a1-9a33-1b110c22d7cc-1435151441429@3capp-gmx-bs42>
References: <trinity-db018112-783b-43a1-9a33-1b110c22d7cc-1435151441429@3capp-gmx-bs42>
Message-ID: <CAF5_5cyToSF32HZXQLMw-Bdod3s6=1aSPTP=HMH=g-j6Bzc2AA@mail.gmail.com>

lmer will sort out by itself the fact that some groups are larger than the
others. weights is used when an individual point is the summary of a number
of observations.

When generating data sets to test things 2 groups isn't enough, use a
similar number that would be used in the analysis, and generate the data
randomly, that way the results can be compared to what is expected.

On 24 June 2015 at 23:10, Susanne Susanne <susanne.stat at gmx.de> wrote:

>
> Hello everyone,
>
> I just saw now, that my last emails were empty. I had this question
> regarding the lme4 package.
> I want to  regress a simple
>
>   lmer(y ~ x + (x | group),
>
> but the number of datapoints vary among groups.
>
> So what I want is to weight groups, which have more measurements than
> others, slightly higher (as they provide more information).
>
>
> My question is: Is this done automatically in the lmer() function or
> should I do it manually by myself?
>
>
> It seems an easy question, but I tried a small example which I attached
> and it's very contradictory.
>
> The upper two pictures seem to proove that lmer doesn't weight groups
> higher which report more datapoints. I get the same regression line,
> independent of whether the blue group has more or less datapoints.
>
> In the lower two pictures I used the "weights=" argument to weight the
> blue group higher. And then suddenly it seems to matter how many datapoints
> a group has. I used the same weights in both pictures, but now I get
> different regression lines, dependent of how many datapoints the blue group
> has.
>
>
> I really need to know this for my thesis and would be very thankful if
> someone could help me!
>
> Susanne
>
>
>
>
> I add my code:
>
> # Data
> # many Values
> x <- c(2, 4, 1, 1.25, 1.5,1.75, 2,2.25, 2.5, 2.75, 3, 3.25,
> 3.5,3.75,4,4.25, 4.5, 4.75, 5)
> y <- c(0.2, 0.4, 0.5, 0.525, 0.57, 0.575, 0.62, 0.625, 0.65, 0.677,
> 0.7,0.726,0.75,0.775,0.8,0.827,0.85,0.873, 0.9)
> group <- c(1,1,rep(2,17))
>
> # Less values
> x <- c(2, 4, 1, 3.25, 5) y <- c(0.2, 0.4,0.5,0.726, 0.9)
> group <- c(1,1,rep(2,3))
>
> # Weights
> if(weights == "Default"){ w <- NULL }
>
> if(weights == "Disequilibrated"){
>    w <- c(1,1, rep(5000,17))
>   # or for less values
>   w <- c(1,1, rep(5000,3))
>   # scale weights to sum weights=number of values
>   w <- length(w)*w/sum(w) }
>
> # Lme Model
> lmeModel <- lmer(y ~ x + (x|group), weights=w)
> s <- summary(lmeModel)
>
> # Plot
> plot(x,y, pch=16, col=c(1,1,rep(2,17)),
> xlim=c(min(x),max(x)),ylim=c(min(y),max(y)), ylab="y",xlab="x",main="Random
> Intercept + Slope") abline(s$coefficients[1,1],s$coefficients[2,1], lty=2,
> col = 1)
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From dale.barr at glasgow.ac.uk  Wed Jun 24 18:27:26 2015
From: dale.barr at glasgow.ac.uk (Dale Barr)
Date: Wed, 24 Jun 2015 17:27:26 +0100
Subject: [R-sig-ME] Specification of binomial mixed model with custom
 intercept
In-Reply-To: <37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W198183686B973039916732CBA00@phx.gbl>,
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
Message-ID: <558ADA6E.1080909@glasgow.ac.uk>

Hi Tom,

You might want to try the original syntax again, but without estimation 
of the (known) intercept term, using the "-1" syntax:

fit=glmer(cbind(infected,not_infected) ~ -1 + (1|colony) + treatment * 
time, family=binomial, data=data)

-Dale

On 23/06/15 22:23, Tom Wenseleers wrote:
> Hi Jake,
> Many thanks for your advice! And yes realised the model would never quite get to 0% or 100% - that's why I had been trying putting in an intercept, as in
> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
>
> But just tried adding points for t=0 and that does indeed seem to give sensible results - so I'll go with that then - thanks for the advice!
>
> If anyone else on this list would know how to formally put in constraints like the ones I mentioned, please let me know though!
>
> cheers,
> Tom
>
> ________________________________
> From: Jake Westfall [jake987722 at hotmail.com]
> Sent: 23 June 2015 23:01
> To: Tom Wenseleers
> Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept
>
> I see. This does seem more sensible. One complication I should point out is that you will never get your model to predict exactly 100% or 0%, as these correspond to logits of infinity or -infinity, respectively. You could set them to something high like logit = +/- 10 (corresonding to p = .99995 or .00005), but the exact values you fix them to are arbitrary and will affect the other model estimates. So it's tricky. One sort of klugey solution could be to put the time=0 measurements in the dataset "as if" you had recorded them -- with the justification being that you are virtually certain what the measurements would have been had you technically taken them at time=0 -- and then run the unconstrained model. This would basically just be a not-completely-arbitrary way of deciding what non-infinite values to fix the time=0 predictions to.
>
>
> Jake
>
>> From: Tom.Wenseleers at bio.kuleuven.be
>> To: jake987722 at hotmail.com; r-sig-mixed-models at r-project.org
>> Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept
>> Date: Tue, 23 Jun 2015 19:35:20 +0000
>>
>> Hi Jake,
>> Well to clarify a bit - I have actual datapoints for time=4, 8, 12 and 16, but not for t=0 days.
>> For t=0, however, I know that based on my treatments (injecting individuals with virus lysate or with buffer) the proportion of infected individuals was ca 0% for the CONTROL treatment and 100% for the INJECTED group.
>> Problem is that if this a priori constraint is not taken into account and I fit my model and make an effect plot, the prediction is not exactly 0% for the CONTROL group or 100% for the INJECTED group, even though I know that it should. So my question is whether constraints such as these can be taken into account into either binomial GLMs or binomial mixed models, e.g. by specifying custom offsets/intercepts? (I also have other similar models where I would like to be able to specify that at time=0 the initial proportion is known a priori to be 0.5)
>>
>> In general my aim of specifying constraints such as these would be to obtain better fits that better/more parsimoniously reflect known facts about the actual experiments.
>>
>> cheers,
>> Tom
>>
>> ________________________________________
>> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jake Westfall [jake987722 at hotmail.com]
>> Sent: 23 June 2015 17:30
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>
>> Hi Tom,
>>
>> I'm not sure if this is a sensible thing to do. If your presumption about the proportion of infected insects in each group at time=0 is correct, then surely your data must already reflect this fact? In which case I don't see why you can't just estimate the unconstrained model that you wrote and let the model figure out for itself what p(infected) is at time=0. In short, I don't see the added value of the constraints you mention.
>>
>> With that said, it occurs to me that if you really do want to implement the two constraints that you mentioned, then really you are not estimating any fixed-effect parameters at time=0. So it seems you could just as well exclude the time=0 data and just model the treatment factor at time=1. >From those parameter estimates it would be easier to figure out what the time slopes are for each group, since they will just be the difference between the time=1 parameter estimates and whatever values you fixed the proportions at time=0 to. Hope this makes sense.
>>
>> Jake
>>
>>> From: Tom.Wenseleers at bio.kuleuven.be
>>> To: r-sig-mixed-models at r-project.org
>>> Date: Tue, 23 Jun 2015 15:02:47 +0000
>>> Subject: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>>
>>> Dear all,
>>> I have a binomial mixed model
>>> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time,family=binomial,data=data)
>>> in which I am modelling the evolution of an infection in different social insect colonies across two treatment groups (INJECTED and CONTROL) as a function of time.
>>> However, as my INJECTED group individuals should all be infected at time=0, whereas none of my CONTROL individuals should be infected at time=0, I would like to force the model to go approx through 1 at time t=0 for the INJECTED group and to go approx through 0 at time t=1 for the CONTROL group. What would be the correct way to specify such a model?
>>> I tried with
>>> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
>>> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time+offset(baseline),family=binomial,data=data)
>>> but this doesn't seem to give sensible predictions.
>>> Any thoughts on the correct syntax?
>>>
>>> cheers,
>>> Tom Wenseleers
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dale Barr
Institute of Neuroscience and Psychology
University of Glasgow
58 Hillhead Street
Glasgow G12 8QB


	[[alternative HTML version deleted]]


From dale.barr at glasgow.ac.uk  Wed Jun 24 18:31:16 2015
From: dale.barr at glasgow.ac.uk (Dale Barr)
Date: Wed, 24 Jun 2015 17:31:16 +0100
Subject: [R-sig-ME] Specification of binomial mixed model with custom
 intercept
In-Reply-To: <558ADA6E.1080909@glasgow.ac.uk>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W198183686B973039916732CBA00@phx.gbl>,
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk>
Message-ID: <558ADB54.3020304@glasgow.ac.uk>

[ ...and of course also including the offset(baseline) term in the 
formula... ]

On 24/06/15 17:27, Dale Barr wrote:
> Hi Tom,
>
> You might want to try the original syntax again, but without estimation
> of the (known) intercept term, using the "-1" syntax:
>
> fit=glmer(cbind(infected,not_infected) ~ -1 + (1|colony) + treatment *
> time, family=binomial, data=data)
>
> -Dale
>
> On 23/06/15 22:23, Tom Wenseleers wrote:
>> Hi Jake,
>> Many thanks for your advice! And yes realised the model would never quite get to 0% or 100% - that's why I had been trying putting in an intercept, as in
>> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
>>
>> But just tried adding points for t=0 and that does indeed seem to give sensible results - so I'll go with that then - thanks for the advice!
>>
>> If anyone else on this list would know how to formally put in constraints like the ones I mentioned, please let me know though!
>>
>> cheers,
>> Tom
>>
>> ________________________________
>> From: Jake Westfall [jake987722 at hotmail.com]
>> Sent: 23 June 2015 23:01
>> To: Tom Wenseleers
>> Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>
>> I see. This does seem more sensible. One complication I should point out is that you will never get your model to predict exactly 100% or 0%, as these correspond to logits of infinity or -infinity, respectively. You could set them to something high like logit = +/- 10 (corresonding to p = .99995 or .00005), but the exact values you fix them to are arbitrary and will affect the other model estimates. So it's tricky. One sort of klugey solution could be to put the time=0 measurements in the dataset "as if" you had recorded them -- with the justification being that you are virtually certain what the measurements would have been had you technically taken them at time=0 -- and then run the unconstrained model. This would basically just be a not-completely-arbitrary way of deciding what non-infinite values to fix the time=0 predictions to.
>>
>>
>> Jake
>>
>>> From: Tom.Wenseleers at bio.kuleuven.be
>>> To: jake987722 at hotmail.com; r-sig-mixed-models at r-project.org
>>> Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>> Date: Tue, 23 Jun 2015 19:35:20 +0000
>>>
>>> Hi Jake,
>>> Well to clarify a bit - I have actual datapoints for time=4, 8, 12 and 16, but not for t=0 days.
>>> For t=0, however, I know that based on my treatments (injecting individuals with virus lysate or with buffer) the proportion of infected individuals was ca 0% for the CONTROL treatment and 100% for the INJECTED group.
>>> Problem is that if this a priori constraint is not taken into account and I fit my model and make an effect plot, the prediction is not exactly 0% for the CONTROL group or 100% for the INJECTED group, even though I know that it should. So my question is whether constraints such as these can be taken into account into either binomial GLMs or binomial mixed models, e.g. by specifying custom offsets/intercepts? (I also have other similar models where I would like to be able to specify that at time=0 the initial proportion is known a priori to be 0.5)
>>>
>>> In general my aim of specifying constraints such as these would be to obtain better fits that better/more parsimoniously reflect known facts about the actual experiments.
>>>
>>> cheers,
>>> Tom
>>>
>>> ________________________________________
>>> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jake Westfall [jake987722 at hotmail.com]
>>> Sent: 23 June 2015 17:30
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>>
>>> Hi Tom,
>>>
>>> I'm not sure if this is a sensible thing to do. If your presumption about the proportion of infected insects in each group at time=0 is correct, then surely your data must already reflect this fact? In which case I don't see why you can't just estimate the unconstrained model that you wrote and let the model figure out for itself what p(infected) is at time=0. In short, I don't see the added value of the constraints you mention.
>>>
>>> With that said, it occurs to me that if you really do want to implement the two constraints that you mentioned, then really you are not estimating any fixed-effect parameters at time=0. So it seems you could just as well exclude the time=0 data and just model the treatment factor at time=1. >From those parameter estimates it would be easier to figure out what the time slopes are for each group, since they will just be the difference between the time=1 parameter estimates and whatever values you fixed the proportions at time=0 to. Hope this makes sense.
>>>
>>> Jake
>>>
>>>> From: Tom.Wenseleers at bio.kuleuven.be
>>>> To: r-sig-mixed-models at r-project.org
>>>> Date: Tue, 23 Jun 2015 15:02:47 +0000
>>>> Subject: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>>>
>>>> Dear all,
>>>> I have a binomial mixed model
>>>> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time,family=binomial,data=data)
>>>> in which I am modelling the evolution of an infection in different social insect colonies across two treatment groups (INJECTED and CONTROL) as a function of time.
>>>> However, as my INJECTED group individuals should all be infected at time=0, whereas none of my CONTROL individuals should be infected at time=0, I would like to force the model to go approx through 1 at time t=0 for the INJECTED group and to go approx through 0 at time t=1 for the CONTROL group. What would be the correct way to specify such a model?
>>>> I tried with
>>>> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
>>>> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time+offset(baseline),family=binomial,data=data)
>>>> but this doesn't seem to give sensible predictions.
>>>> Any thoughts on the correct syntax?
>>>>
>>>> cheers,
>>>> Tom Wenseleers
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dale Barr
Institute of Neuroscience and Psychology
University of Glasgow
58 Hillhead Street
Glasgow G12 8QB


From ken.beath at mq.edu.au  Thu Jun 25 05:46:54 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 25 Jun 2015 13:46:54 +1000
Subject: [R-sig-ME] glmer and lme4 - Quick question
In-Reply-To: <01711809-16EF-4984-BF87-4C1CAC1D3BAE@gmail.com>
References: <01711809-16EF-4984-BF87-4C1CAC1D3BAE@gmail.com>
Message-ID: <CAF5_5czKoqwCasSa-SjCPNTzPgSFy=dDqU_p_h4+H8tDSYhijA@mail.gmail.com>

What 0+ is doing is removing the intercept random effect. It is then
included with the 1|Region term, however there is now no correlation
between the slope and intercept random effects. I can understand why you
don't want to do that as including something like (x1+x2+x3|Region) means
estimating a large covariance matrix for the random effects. However the
bad news if the correlations are not zero then it will give lots of
estimation problems and probably some strange results. Your convergence
problems may well be due to not having a complex enough model.

Opinions vary on what to do. Either start with something simple and keep
adding, or start with all the random effects and remove until it converges
and then remove the unimportant random effects.

On 24 June 2015 at 10:10, Joseph Maina <mainajm at gmail.com> wrote:

> Hi,
> I am running glmer in a model selection framework with >30 explanatory
> variables, where I am first  generating all possible combinations of
> variables but with a multicollinearity test results coinstraint,  before
> fitting the gmler. I am also including random effects of ?Year' (~20) and
> Regions (~13). The objective is to find the best model and determine the
> relative influence among predictors, and also to predict the model over
> space to global pixels.
>
> My question regards the model structure of lme4 that I should adopt. I am
> currently fitting my model in the following structure:
> m1<-glmer(y  ~ x1 + x2 + x3 + (1 |Region) + (1 | Year) +(1|Region),
> family=binomial('logit'),data=all.data)
>
> However, I have been advised that in order to have a varying intercept and
> slope among my Regions (one of the random effects), I should fit my model
> as follows:
> m1<-glmer(y ~ x1+ (0+x1|Region) + x2 + (0+x2|Region) + x3 + (0+x3|Region)
> + (1 | Year) +(1|Region), family=binomial('logit'),data=all.data)
>
> The latter is a slightly complex structure and I am running into
> convergence issues. I was wondering what are the merits of using either
> structure?.  Also in the second structure, I am not sure what ?0+? means or
> what value it adds to the analyses. I also found that when using the first
> model structure if I take out the ?Region? random effect, the estimates for
> some of the variables change signs, and therefore could have an
> implicaition on the interpretation.
>
> Thanks,
>
> Joseph
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From Tom.Wilding at sams.ac.uk  Thu Jun 25 13:17:00 2015
From: Tom.Wilding at sams.ac.uk (Tom Wilding)
Date: Thu, 25 Jun 2015 11:17:00 +0000
Subject: [R-sig-ME] lme4 and random effects modelling.
Message-ID: <C3CE30FD1A1CBF469C59A5551FF29C19DCE01EDD@Verbiage2.sams.local>

Dear List

I have a question on random-effects model selection.  My data set is 'ecological', messy and is based on observational data.  I have made notes on the Models I have tried, and would welcome any comments on these.

I have ~100 Farms (random effect) within which Surveys (random effect) have been conducted over several years (~3 on average, per farm).  Survey is nested in Farm.  Each Survey consists of samples taken from different Distances: 1 sample from near the farm, 3 samples from intermediate distances and 2 samples from reference locations.  Assume the samples are taken non-independently (i.e. they represent pseudoreplicates).  Farms are variously treated with a chemical ("Treat", fixed effect, continuous and the main interest of this study) and there are several other environmental covariables associated with each sample.  Factor Distance is a major driver of patterns in the response, and the response is highly variable (within Farms, within Surveys within Farms and between pseudoreplicates).

A simple model (using library(lme4)) includes the hierarchical structure in the random effects:

Model1: Response~Treat+Distance +other covariables + (1|Farm/Survey)#AIC=3721
#Model1 doesn't model the non-independence of the Distance samples.
Model2: Response~Treat+Distance +other covariables + (1|Farm/Survey/Distance)#AIC=3586
#Model2 now nests Distance in Survey and accounts for the non-independence (pseudoreplication of samples taken at Distances).   This model accounts for the variance in each of the nested hierarchies.

It seems reasonable to test a random slope model, one that allows the effect of Distance to vary between different Farms and Surveys nested in Farms. Distance is a categorical predictor, the interpretation of 'slopes' with >2 levels (as here) seems relatively intuitive (but I have seen very little on random slopes with categorical predictors - Gelman and Hill's (Ref 1) radon example (page 281) with 'Floor' (2 levels) is the only example I can find).  I have fitted the following to allow for random slopes:

Model3: Response~Treat+Distance +other covariables + (1+Distance|Farm/Survey)#AIC=3549.
Model3 generates estimates of the standard deviation associated with each Distance within Surveys nested in Farms and within Farms and correlations between each Distance (Survey within Farm and within Farm).  This seems relatively intuitive.

On the basis of AIC (as recommended by Zuur, Ref 2), and likelihood ratio tests Model3 is the superior model although it is estimating a greater number of random effects hence, probably, on the basis of BIC Model3 is not as good as Model2.  My concern with Model 3 is that I don't see if it is accounting for the non-independence of measurements taken within Distance.  Comments on this aspect would be much appreciated.  I have noted this paper: http://arxiv.org/pdf/1506.04967v1.pdf but, for the moment, would rather use the logic of the observational design (not mine!), and graphical data exploration,  to derive the random-effects part of the model.

Many thanks

Tom.


Ref 1 - Gelman, A. and J. Hill (2007). Data analysis using regression and multilevel/hierarchical models, Cambridge University Press.
Ref 2 - Zuur, A. F., E. N. Ieno, N. J. Walker, A. A. Saveliev and G. M. Smith (2009). Mixed effects models and extensions in ecology with R, Springer, New York, USA.


The Scottish Association for Marine Science (SAMS) is registered in Scotland as a Company Limited by Guarantee (SC009292) and is a registered charity (9206). SAMS has two actively trading wholly owned subsidiary companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912). All Companies in the group are registered in Scotland and share a registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The content of this message may contain personal views which are not the views of SAMS unless specifically stated. Please note that all email traffic is monitored for purposes of security and spam filtering. As such individual emails may be examined in more detail.

From thierry.onkelinx at inbo.be  Thu Jun 25 13:49:41 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 25 Jun 2015 13:49:41 +0200
Subject: [R-sig-ME] lme4 and random effects modelling.
In-Reply-To: <C3CE30FD1A1CBF469C59A5551FF29C19DCE01EDD@Verbiage2.sams.local>
References: <C3CE30FD1A1CBF469C59A5551FF29C19DCE01EDD@Verbiage2.sams.local>
Message-ID: <CAJuCY5zsrPkdH=kohfxxFmj7ftej8G=bi8t-AcX7w+UmMaxQ=A@mail.gmail.com>

Dear Tom,

You talk about sampling locations and surveys. Does each survey reuse the
same locations or does each survey uses different locations?
If the locations are reused, then I would add a location random effect. The
random effects structure would be (1|Farm/Survey/Location) or (1|Farm) +
(1|Farm:Survey) + (1|Farm:Survey:Location). In case the id's of survey are
unique (not reused among farms) en the location id's are unique as well
then you can simply this to (1|Farm) + (1|Survey) + (1|Location). This is
the case without Distance as a random slope.

In case of a single categorical variable as a random slope I prefer (0 +
Distance|Farm) instead of (1 + Distance|Farm). The model fit is the same,
the difference is in the parametrisation. 0 + Distance gives the effect of
"near", "intermediate" and "referene" whereas 1 + Distance gives intercept
(= "near"), difference between "intermediate" and "near", difference
between "reference" and "near". 0 + Distance makes IMHO the random effects
and their variance-covariance parameters easier to interpret.

Your model 3 adds random slopes for both the farm and survey level. You
have to this if that makes sense or not. Given the number of surveys per
farm and the number of locations per survey, I would only add the random
slopes at the farm level. The structure would look like (0 + Distance|Farm)
+ (1|Survey) + (1|Location), assuming each Survey and Location is unique.

Such structure matches the design of the study. If there is an effect from
one of the levels (farm, survey or location),  then the model can cope with
that. If there is no effect, the variance will be very small. So IMHO there
is no need to find the "optimal" random effects structure, since the design
dictates what a minimal structure should be.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-25 13:17 GMT+02:00 Tom Wilding <Tom.Wilding at sams.ac.uk>:

> Dear List
>
> I have a question on random-effects model selection.  My data set is
> 'ecological', messy and is based on observational data.  I have made notes
> on the Models I have tried, and would welcome any comments on these.
>
> I have ~100 Farms (random effect) within which Surveys (random effect)
> have been conducted over several years (~3 on average, per farm).  Survey
> is nested in Farm.  Each Survey consists of samples taken from different
> Distances: 1 sample from near the farm, 3 samples from intermediate
> distances and 2 samples from reference locations.  Assume the samples are
> taken non-independently (i.e. they represent pseudoreplicates).  Farms are
> variously treated with a chemical ("Treat", fixed effect, continuous and
> the main interest of this study) and there are several other environmental
> covariables associated with each sample.  Factor Distance is a major driver
> of patterns in the response, and the response is highly variable (within
> Farms, within Surveys within Farms and between pseudoreplicates).
>
> A simple model (using library(lme4)) includes the hierarchical structure
> in the random effects:
>
> Model1: Response~Treat+Distance +other covariables +
> (1|Farm/Survey)#AIC=3721
> #Model1 doesn't model the non-independence of the Distance samples.
> Model2: Response~Treat+Distance +other covariables +
> (1|Farm/Survey/Distance)#AIC=3586
> #Model2 now nests Distance in Survey and accounts for the non-independence
> (pseudoreplication of samples taken at Distances).   This model accounts
> for the variance in each of the nested hierarchies.
>
> It seems reasonable to test a random slope model, one that allows the
> effect of Distance to vary between different Farms and Surveys nested in
> Farms. Distance is a categorical predictor, the interpretation of 'slopes'
> with >2 levels (as here) seems relatively intuitive (but I have seen very
> little on random slopes with categorical predictors - Gelman and Hill's
> (Ref 1) radon example (page 281) with 'Floor' (2 levels) is the only
> example I can find).  I have fitted the following to allow for random
> slopes:
>
> Model3: Response~Treat+Distance +other covariables +
> (1+Distance|Farm/Survey)#AIC=3549.
> Model3 generates estimates of the standard deviation associated with each
> Distance within Surveys nested in Farms and within Farms and correlations
> between each Distance (Survey within Farm and within Farm).  This seems
> relatively intuitive.
>
> On the basis of AIC (as recommended by Zuur, Ref 2), and likelihood ratio
> tests Model3 is the superior model although it is estimating a greater
> number of random effects hence, probably, on the basis of BIC Model3 is not
> as good as Model2.  My concern with Model 3 is that I don't see if it is
> accounting for the non-independence of measurements taken within Distance.
> Comments on this aspect would be much appreciated.  I have noted this
> paper: http://arxiv.org/pdf/1506.04967v1.pdf but, for the moment, would
> rather use the logic of the observational design (not mine!), and graphical
> data exploration,  to derive the random-effects part of the model.
>
> Many thanks
>
> Tom.
>
>
> Ref 1 - Gelman, A. and J. Hill (2007). Data analysis using regression and
> multilevel/hierarchical models, Cambridge University Press.
> Ref 2 - Zuur, A. F., E. N. Ieno, N. J. Walker, A. A. Saveliev and G. M.
> Smith (2009). Mixed effects models and extensions in ecology with R,
> Springer, New York, USA.
>
>
> The Scottish Association for Marine Science (SAMS) is registered in
> Scotland as a Company Limited by Guarantee (SC009292) and is a registered
> charity (9206). SAMS has two actively trading wholly owned subsidiary
> companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912).
> All Companies in the group are registered in Scotland and share a
> registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The
> content of this message may contain personal views which are not the views
> of SAMS unless specifically stated. Please note that all email traffic is
> monitored for purposes of security and spam filtering. As such individual
> emails may be examined in more detail.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Thu Jun 25 14:39:50 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 25 Jun 2015 14:39:50 +0200
Subject: [R-sig-ME] convergence issues in multivariate mixed-model in lme
Message-ID: <CALC46t95RzHtFy7c05wJKrn3u9AQV-p8jeuiaMbF3B4xyGfUow@mail.gmail.com>

Dear list,

This question builds on a question posted some days ago:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023697.html

I'm attempting to fit a multivariate mixed-model. MCMCglmm can do the job
pretty well, but I have strong temporal autocorrelation in my residuals,
which cannot be accounted for in MCMCglmm. So I'm trying in lme.

My dataset includes 274 individuals for which a total of 8 traits were
measured on a monthly basis until they died. The total study period covers
three years, but each individual was only monitored several months within
that period (mean=8 months, this is 8 replicates).

Following the suggestions by Thierry in my previous question, I built this
model:

model=lme(value~trait-1,data=longtwo,random=~trait-1|id,weights=varIdent(form=~1|trait),correlation=corAR1(form=~tim|id/trait))

I'm trying to run it in an increase order of complexity, this is, first I
try with two traits (bivariate model), then three traits, and so on until I
get convergence problems. Ideally, I'd like to include all my 8 traits in
the model, as I was able to do that in MCMCglmm. But I guess this is not
possible.

My objective is to get the variance-covariance matrices at the residual
(within individual) and random (among-individual) levels. I want to fit the
equivalent to "us" structure in MCMCglmm. This is, unstructured (all
covariances are estimated).

My problem: the model only runs with two traits. When I include three, I
get an error. Code:

# runs ok with two traits
datatwo=data[data$trait=="trait1"|data$trait=="trait2",]
mod2=lme(value~trait-1,data=datatwo,random=~trait-1|id,weights=varIdent(form=~1|trait),correlation=corAR1(form=~tim|id/trait))
summary(mod2)

# doesn't converge with these three traits
datathree=data[data$trait=="trait2"|data$trait=="trait3"|data$trait=="trait8",]
mod3=lme(value~trait-1,data=datathree,random=~trait-1|id,weights=varIdent(form=~1|trait),correlation=corAR1(form=~tim|id/trait))

Error in lme.formula(value ~ trait - 1, data = datathree, random = ~trait -
 :
  nlminb problem, convergence error code = 1
  message = iteration limit reached without convergence (10)

Increasing maxIter to 200 does not solve the problem

My questions:
1- Assuming that the model is correctly specified, is this lack of
convergence normal/expected? I was hoping that the model could converge
with 3-4-5 traits assuming that I have a quite large dataset with many
replicates per individual.
2- Assuming that lme cannot do the job (convergence problems), what would
be the best alternative knowing that temporal autocorrelation has to be
accounted for? Thierry suggested INLA, any other option?
3- In case I manage to run the models in lme, how can I extract the
variance-covariance matrices at both levels (residual and random)?

Data is available here:
https://drive.google.com/file/d/0B8zYlm7MEMdfUG1fejdlOHA4ZFk/view?usp=sharing

Thanks a lot!

	[[alternative HTML version deleted]]


From jrmorrongiello at gmail.com  Thu Jun 25 15:07:47 2015
From: jrmorrongiello at gmail.com (John Morrongiello)
Date: Thu, 25 Jun 2015 23:07:47 +1000
Subject: [R-sig-ME] comparing random effect variation between data sets
Message-ID: <CAPTgL1YVtUAuG8XGkk80BgTRb8dU8B2aE4JnfK_0Q1vnAxdzBQ@mail.gmail.com>

Hi all

I have movement data for two species of fish (say species X and species Y).
The response variable is 'distance from home' (distance) and multiple
measurements (5-17) are made for 20-30 individuals per species over a
period of 200 days. Distance is continuous and strictly positive so I am
using a gamma distribution with a log link. My collegues would like me to
fit seperate models for each species to explore temporal patterns in
movement (time). We believe there will be non-linear patterns in movement
through time so have I have fitted GAMMs

I'm happy with the two models and their interpretation. I would, however,
like to compare the level of among-individual variation in movement between
species. The species-average trends are pretty similar but it looks like
there is more variance among individuals for species X than species Y.

I was thinking of extracting the individual level random effects from the
two models and performing a variance test on these. My logic is that given
the response variables are the same and the model structures are the same,
I could make a meaningful comparison of random effects. The overall model
intercepts are different but I thought this is not an issue here as I'm
only interested in the variance of the random effects, not their average.

Is this approach valid, or am I violating assumptions/ these data are not
directly comparable ? If not, what would be a potential way to perform this
comparision? Below is the code I'm thinking of using.

Thanks very much for your time

John

#####GAMMs
X1<-gamm4(distance ~ s(time,k=4), random=~(1|CODE),data=speciesX,
family=Gamma(link=log))
Y1<-gamm4(distance ~ s(time,k=4), random=~(1|CODE),data=speciesY,
family=Gamma(link=log))

######extract random effects from the two models
X1ranef<-ranef(X1$mer)###extract random effects from model
X1ranef<-data.frame(matrix(unlist(X1ranef$'CODE'),ncol=1))##convert list of
random effects to data frame
names(X1ranef)<-c('CODE')

Y1ranef<-ranef(X1$mer)###extract random effects from model
Y1ranef<-data.frame(matrix(unlist(Y1ranef$'CODE'),ncol=1))##convert list of
random effects to data frame
names(Y1ranef)<-c('CODE')

######perform variance test
var.test(X1ranef$CODE,Y1ranef$CODE)

	[[alternative HTML version deleted]]


From susanne.stat at gmx.de  Fri Jun 26 12:01:54 2015
From: susanne.stat at gmx.de (Susanne Susanne)
Date: Fri, 26 Jun 2015 12:01:54 +0200
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
Message-ID: <trinity-60cb31e4-b1bc-4896-89e1-118a87e21971-1435312914318@3capp-gmx-bs08>


Hello Ken and everybody,
?

thank you very much for your answer! I tried out another example, generating the datapoints randomly.
I get different results, but it is just as hard to understand as before.
?
I fixed lines and chose datapoints randomly on these lines.
A) 10 groups, each with 10 datapoints
B) 10 groups. Group 1 has 40 datapoints, the others 10 each.
?

I get the same result. So first it seems for me as if the number of datapoints for a group doesn't matter.
?
Then I weighted group 1 with weight= 500000000 and the others with weight =1.
(If I use smaller weights, I can't see a difference. But it doesn't seem naturally...)
?
The result:
A) with no weights = B) with no weights = B) with weights [a regression line which lies in the middle of my generated lines]
!=
A) with weights [a regression line which almost lies on group 1, so clearly stronger influence of group 1]
?
So now it get's weird.? The version of group 1 with higher weight gives a regression line which is very close to the one of group 1. That's what I would expect from these extremely higher weights.
But if group 1 has 40 datapoints and this extremely higher weight, the result is a regression line just as the one without weighting.
?
Am I doing something wrong? Can someone explain me this?
?
Susanne
?
?
My code:
?

## 10 groups with 10 datapoints each
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
?
y.m <- x.m <- matrix(nrow=10,ncol=10)
?
# i th row is for ith group
for(i in 1:10){
? # generate randomly x values
? x.m[i,] <- runif(10,0,5)
? # y values
? y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
? }
?
# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <- c(rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
res <- lmer(y ~ x + (x|group))
?
#####################################################################
## 10 groups. 1. has 40 datapoints, others have 10
# if it matters, that group 1 has more datapoints, the regression line should have a smaller intercept and smaller slope
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
?
y.m <- x.m <- matrix(nrow=10,ncol=10)
# i th row is for ith group
for(i in 1:10){
? # generate randomly x values
? x.m[i,] <- runif(10,0,5)
?
? # y values
? y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}
?
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
?
# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <- c(rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
res <- lmer(y ~ x + (x|group))
res
?
###################################################################
# result:
# it's the same regression line for both
# => it doesn't matter that group 1 has more datapoints!!
##################################################################
?
# plot:
plot(x,y, pch=16, col=1, ylab="y",xlab="x",main=sprintf("plot")) ?
s <- summary(res)
# add linear regression lines
abline(s$coefficients[1,1],s$coefficients[2,1], lty=2, col = 1)
?
###################################################################
# check with weights:
##################################################################
?
# same as above:
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
y.m <- x.m <- matrix(nrow=10,ncol=10)
# i th row is for ith group
for(i in 1:10){
? # generate randomly x values
? x.m[i,] <- runif(10,0,5)
? # y values
? y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}
# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <- c(rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
## Add weights: 1. group has weight=5000, the others weight=1 #############
w <- c(rep(500000000,10),rep(1,90))
res <- lmer(y ~ x + (x|group), weights=w)
res
#################################################################
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
y.m <- x.m <- matrix(nrow=10,ncol=10)
# i th row is for ith group
for(i in 1:10){
? # generate randomly x values
? x.m[i,] <- runif(10,0,5)
? # y values
? y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}
?
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
?
# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <- c(rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
?
## Add weights: 1. group has weight=5000, the others weight=1 #############
w <- c(rep(500000000,40),rep(1,90))
res <- lmer(y ~ x + (x|group))
res
??
?
?
?
?
?

Gesendet:?Mittwoch, 24. Juni 2015 um 15:23 Uhr
Von:?"Ken Beath" <ken.beath at mq.edu.au>
An:?"Susanne Susanne" <susanne.stat at gmx.de>
Cc:?Rlist <r-sig-mixed-models at r-project.org>
Betreff:?Re: [R-sig-ME] lmer(): Higher weight in case of more measurements

lmer will sort out by itself the fact that some groups are larger than the others. weights is used when an individual point is the summary of a number of observations.
?
When generating data sets to test things 2 groups isn't enough, use a similar number that would be used in the analysis, and generate the data randomly, that way the results can be compared to what is expected.
?
On 24 June 2015 at 23:10, Susanne Susanne <susanne.stat at gmx.de> wrote:
Hello everyone,
?
I just saw now, that my last emails were empty. I had this question regarding the lme4 package.
I want to? regress a simple

? lmer(y ~ x + (x | group),

but the number of datapoints vary among groups.

So what I want is to weight groups, which have more measurements than others, slightly higher (as they provide more information).


My question is: Is this done automatically in the lmer() function or should I do it manually by myself?


It seems an easy question, but I tried a small example which I attached and it's very contradictory.

The upper two pictures seem to proove that lmer doesn't weight groups higher which report more datapoints. I get the same regression line, independent of whether the blue group has more or less datapoints.

In the lower two pictures I used the "weights=" argument to weight the blue group higher. And then suddenly it seems to matter how many datapoints a group has. I used the same weights in both pictures, but now I get different regression lines, dependent of how many datapoints the blue group has.
??

I really need to know this for my thesis and would be very thankful if someone could help me!

Susanne
?

?

I add my code:

# Data
# many Values
x <- c(2, 4, 1, 1.25, 1.5,1.75, 2,2.25, 2.5, 2.75, 3, 3.25, 3.5,3.75,4,4.25, 4.5, 4.75, 5)
y <- c(0.2, 0.4, 0.5, 0.525, 0.57, 0.575, 0.62, 0.625, 0.65, 0.677, 0.7,0.726,0.75,0.775,0.8,0.827,0.85,0.873, 0.9)
group <- c(1,1,rep(2,17))

# Less values
x <- c(2, 4, 1, 3.25, 5) y <- c(0.2, 0.4,0.5,0.726, 0.9)
group <- c(1,1,rep(2,3))

# Weights
if(weights == "Default"){ w <- NULL }

if(weights == "Disequilibrated"){
? ?w <- c(1,1, rep(5000,17))
? # or for less values
? w <- c(1,1, rep(5000,3))
? # scale weights to sum weights=number of values
? w <- length(w)*w/sum(w) }

# Lme Model
lmeModel <- lmer(y ~ x + (x|group), weights=w)
s <- summary(lmeModel)

# Plot
plot(x,y, pch=16, col=c(1,1,rep(2,17)), xlim=c(min(x),max(x)),ylim=c(min(y),max(y)), ylab="y",xlab="x",main="Random Intercept + Slope") abline(s$coefficients[1,1],s$coefficients[2,1], lty=2, col = 1)



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models[https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models]
??
?--

Ken Beath
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone:?+61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/[http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/]

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:8}}


From ken.beath at mq.edu.au  Fri Jun 26 13:05:46 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Fri, 26 Jun 2015 21:05:46 +1000
Subject: [R-sig-ME] lmer(): Higher weight in case of more measurements
In-Reply-To: <trinity-6a6bc7d0-3635-4c81-9f3a-8b7a93302747-1435244054751@3capp-gmx-bs13>
References: <trinity-db018112-783b-43a1-9a33-1b110c22d7cc-1435151441429@3capp-gmx-bs42>
	<CAF5_5cyToSF32HZXQLMw-Bdod3s6=1aSPTP=HMH=g-j6Bzc2AA@mail.gmail.com>
	<trinity-6a6bc7d0-3635-4c81-9f3a-8b7a93302747-1435244054751@3capp-gmx-bs13>
Message-ID: <CAF5_5cy-OM8nMDGhzyH8jQbb5SExsDYNjmj0KMpm9B_yF3wE0Q@mail.gmail.com>

Hi Susanne,

I've fixed a few problems with your code.

There is a difference between the group size. That is what you expect as
the analysis weights the first group higher when it has 40 points and that
drags the line down.

For the second analysis I've changed the weight to 5000, as it seems
sensible and is less likely to give numerical problems. This does what
would be expected. It assumes that each observation in in the 1st group is
actually the mean of 5000 points. From this it obtains the variation of a
single observation which will be much higher than before as the variation
in group 1 is unchanged. It actually violates the assumptions as the
residual variation in each group is not equal, but you will see that the
estimate of the residual variance is much higher. This can be fixed by
changing the residual variance in the first group to reflect the lower
variation in each observation, and that code is at the end, and seems to do
the right thing.

Ken


## 10 groups with 10 datapoints each
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)

y.m <- x.m <- matrix(nrow=10,ncol=10)

# i th row is for ith group
for(i in 1:10){
  # generate randomly x values
  x.m[i,] <- runif(10,0,5)
  # y values
  y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}

# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <-
c(rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
res <- lmer(y ~ x + (x|group))

summary(res)

#####################################################################
## 10 groups. 1. has 40 datapoints, others have 10
# if it matters, that group 1 has more datapoints, the regression line
should have a smaller intercept and smaller slope
# slope a and intercept b for lines

a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)

y.m <- x.m <- matrix(nrow=10,ncol=10)
# i th row is for ith group
for(i in 1:10){
  # generate randomly x values
  x.m[i,] <- runif(10,0,5)

  # y values
  y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}

x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)

# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <-
c(rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
res <- lmer(y ~ x + (x|group))
summary(res)

###################################################################
# result:
# it's the same regression line for both
# => it doesn't matter that group 1 has more datapoints!!
##################################################################

# plot:
plot(x,y, pch=16, col=1, ylab="y",xlab="x",main=sprintf("plot"))
s <- summary(res)
# add linear regression lines
abline(s$coefficients[1,1],s$coefficients[2,1], lty=2, col = 1)

###################################################################
# check with weights:
##################################################################

# same as above:
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
y.m <- x.m <- matrix(nrow=10,ncol=10)
# i th row is for ith group
for(i in 1:10){
  # generate randomly x values
  x.m[i,] <- runif(10,0,5)
  # y values
  y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}
# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <-
c(rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
## Add weights: 1. group has weight=5000, the others weight=1 #############
w <- c(rep(5000,10),rep(1,90))

res <- lmer(y ~ x + (x|group), weights=w)
summary(res)
#################################################################
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
y.m <- x.m <- matrix(nrow=10,ncol=10)
# i th row is for ith group
for(i in 1:10){
  # generate randomly x values
  x.m[i,] <- runif(10,0,5)
  # y values
  y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}

x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
x.m <- rbind(runif(10,0,5),x.m)
y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)

# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <-
c(rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))

## Add weights: 1. group has weight=5000, the others weight=1 #############
w <- c(rep(5000,40),rep(5000,100))

res <- lmer(y ~ x + (x|group), weights=w)
summary(res)

# correct variances for weights
# slope a and intercept b for lines
a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
y.m <- x.m <- matrix(nrow=10,ncol=10)
# i th row is for ith group
for(i in 1:10){
  # generate randomly x values
  x.m[i,] <- runif(10,0,5)
  # y values
  if (i==1) y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01/sqrt(5000))
  else y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
}
# convert to vectors with first row, then second row...
y <- as.vector(t(y.m))
x <- as.vector(t(x.m))
group <-
c(rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
## Add weights: 1. group has weight=5000, the others weight=1 #############
w <- c(rep(5000,10),rep(1,90))

res <- lmer(y ~ x + (x|group), weights=w)
summary(res)


On 26 June 2015 at 00:54, Susanne Susanne <susanne.stat at gmx.de> wrote:

> Hello Ken and everybody,
>
>  thank you very much for your answer! I tried out another example,
> generating the datapoints randomly.
> I get different results, but it is just as hard to understand as before.
>
> I fixed lines and chose datapoints randomly on these lines.
> A) 10 groups, each with 10 datapoints
> B) 10 groups. Group 1 has 40 datapoints, the others 10 each.
>
>  I get the same result. So first it seems for me as if the number of
> datapoints for a group doesn't matter.
>
> Then I weighted group 1 with weight= 500000000 and the others with weight
> =1.
> (If I use smaller weights, I can't see a difference. But it doesn't seem
> naturally...)
>
> The result:
> A) with no weights = B) with no weights = B) with weights [a regression
> line which lies in the middle of my generated lines]
> !=
> A) with weights [a regression line which almost lies on group 1, so
> clearly stronger influence of group 1]
>
> So now it get's weird.  The version of group 1 with higher weight gives a
> regression line which is very close to the one of group 1. That's what I
> would expect from these extremely higher weights.
> But if group 1 has 40 datapoints and this extremely higher weight, the
> result is a regression line just as the one without weighting.
>
> Am I doing something wrong? Can someone explain me this?
>
> Susanne
>
>
> My code:
>
>  ## 10 groups with 10 datapoints each
> # slope a and intercept b for lines
> a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
> b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
>
> y.m <- x.m <- matrix(nrow=10,ncol=10)
>
> # i th row is for ith group
> for(i in 1:10){
>   # generate randomly x values
>   x.m[i,] <- runif(10,0,5)
>   # y values
>   y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
>   }
>
> # convert to vectors with first row, then second row...
> y <- as.vector(t(y.m))
> x <- as.vector(t(x.m))
> group <-
> c(rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
> res <- lmer(y ~ x + (x|group))
>
> #####################################################################
> ## 10 groups. 1. has 40 datapoints, others have 10
> # if it matters, that group 1 has more datapoints, the regression line
> should have a smaller intercept and smaller slope
> # slope a and intercept b for lines
>
> a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
> b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
>
> y.m <- x.m <- matrix(nrow=10,ncol=10)
> # i th row is for ith group
> for(i in 1:10){
>   # generate randomly x values
>   x.m[i,] <- runif(10,0,5)
>
>   # y values
>   y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
> }
>
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
>
> # convert to vectors with first row, then second row...
> y <- as.vector(t(y.m))
> x <- as.vector(t(x.m))
> group <-
> c(rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
> res <- lmer(y ~ x + (x|group))
> res
>
> ###################################################################
> # result:
> # it's the same regression line for both
> # => it doesn't matter that group 1 has more datapoints!!
> ##################################################################
>
> # plot:
> plot(x,y, pch=16, col=1, ylab="y",xlab="x",main=sprintf("plot"))
> s <- summary(res)
> # add linear regression lines
> abline(s$coefficients[1,1],s$coefficients[2,1], lty=2, col = 1)
>
> ###################################################################
> # check with weights:
> ##################################################################
>
> # same as above:
> # slope a and intercept b for lines
> a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
> b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
> y.m <- x.m <- matrix(nrow=10,ncol=10)
> # i th row is for ith group
> for(i in 1:10){
>   # generate randomly x values
>   x.m[i,] <- runif(10,0,5)
>   # y values
>   y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
> }
> # convert to vectors with first row, then second row...
> y <- as.vector(t(y.m))
> x <- as.vector(t(x.m))
> group <-
> c(rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
> ## Add weights: 1. group has weight=5000, the others weight=1 #############
> w <- c(rep(500000000,10),rep(1,90))
>
> res <- lmer(y ~ x + (x|group), weights=w)
> res
> #################################################################
> # slope a and intercept b for lines
> a <- c(0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3,2.5)
> b <- c(0,0.3,0.5,0.8,1,1.3,1.5,1.8,2,2.3)
> y.m <- x.m <- matrix(nrow=10,ncol=10)
> # i th row is for ith group
> for(i in 1:10){
>   # generate randomly x values
>   x.m[i,] <- runif(10,0,5)
>   # y values
>   y.m[i,] <- a[i]*x.m[i,] + b[i] + rnorm(10,0,0.01)
> }
>
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
> x.m <- rbind(runif(10,0,5),x.m)
> y.m <- rbind(a[1]*x.m[1,] + b[1] + rnorm(10,0,0.01),y.m)
>
> # convert to vectors with first row, then second row...
> y <- as.vector(t(y.m))
> x <- as.vector(t(x.m))
> group <-
> c(rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(1,10),rep(2,10),rep(3,10),rep(4,10),rep(5,10),rep(6,10),rep(7,10),rep(8,10),rep(9,10),rep(10,10))
>
> ## Add weights: 1. group has weight=5000, the others weight=1 #############
> w <- c(rep(500000000,40),rep(1,90))
>
> res <- lmer(y ~ x + (x|group))
> res
>
>
>
>
>
>
>
>  *Gesendet:* Mittwoch, 24. Juni 2015 um 15:23 Uhr
> *Von:* "Ken Beath" <ken.beath at mq.edu.au>
> *An:* "Susanne Susanne" <susanne.stat at gmx.de>
> *Cc:* Rlist <r-sig-mixed-models at r-project.org>
> *Betreff:* Re: [R-sig-ME] lmer(): Higher weight in case of more
> measurements
>  lmer will sort out by itself the fact that some groups are larger than
> the others. weights is used when an individual point is the summary of a
> number of observations.
>
> When generating data sets to test things 2 groups isn't enough, use a
> similar number that would be used in the analysis, and generate the data
> randomly, that way the results can be compared to what is expected.
>
> On 24 June 2015 at 23:10, Susanne Susanne <susanne.stat at gmx.de> wrote:
>>
>>
>> Hello everyone,
>>
>> I just saw now, that my last emails were empty. I had this question
>> regarding the lme4 package.
>> I want to  regress a simple
>>
>>   lmer(y ~ x + (x | group),
>>
>> but the number of datapoints vary among groups.
>>
>> So what I want is to weight groups, which have more measurements than
>> others, slightly higher (as they provide more information).
>>
>>
>> My question is: Is this done automatically in the lmer() function or
>> should I do it manually by myself?
>>
>>
>> It seems an easy question, but I tried a small example which I attached
>> and it's very contradictory.
>>
>> The upper two pictures seem to proove that lmer doesn't weight groups
>> higher which report more datapoints. I get the same regression line,
>> independent of whether the blue group has more or less datapoints.
>>
>> In the lower two pictures I used the "weights=" argument to weight the
>> blue group higher. And then suddenly it seems to matter how many datapoints
>> a group has. I used the same weights in both pictures, but now I get
>> different regression lines, dependent of how many datapoints the blue group
>> has.
>>
>>
>> I really need to know this for my thesis and would be very thankful if
>> someone could help me!
>>
>> Susanne
>>
>>
>>
>>
>> I add my code:
>>
>> # Data
>> # many Values
>> x <- c(2, 4, 1, 1.25, 1.5,1.75, 2,2.25, 2.5, 2.75, 3, 3.25,
>> 3.5,3.75,4,4.25, 4.5, 4.75, 5)
>> y <- c(0.2, 0.4, 0.5, 0.525, 0.57, 0.575, 0.62, 0.625, 0.65, 0.677,
>> 0.7,0.726,0.75,0.775,0.8,0.827,0.85,0.873, 0.9)
>> group <- c(1,1,rep(2,17))
>>
>> # Less values
>> x <- c(2, 4, 1, 3.25, 5) y <- c(0.2, 0.4,0.5,0.726, 0.9)
>> group <- c(1,1,rep(2,3))
>>
>> # Weights
>> if(weights == "Default"){ w <- NULL }
>>
>> if(weights == "Disequilibrated"){
>>    w <- c(1,1, rep(5000,17))
>>   # or for less values
>>   w <- c(1,1, rep(5000,3))
>>   # scale weights to sum weights=number of values
>>   w <- length(w)*w/sum(w) }
>>
>> # Lme Model
>> lmeModel <- lmer(y ~ x + (x|group), weights=w)
>> s <- summary(lmeModel)
>>
>> # Plot
>> plot(x,y, pch=16, col=c(1,1,rep(2,17)),
>> xlim=c(min(x),max(x)),ylim=c(min(y),max(y)), ylab="y",xlab="x",main="Random
>> Intercept + Slope") abline(s$coefficients[1,1],s$coefficients[2,1], lty=2,
>> col = 1)
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Level 2, AHH
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and may contain
> confidential information.  If you are not the intended recipient, please
> delete it and notify the sender.  Views expressed in this message are those
> of the individual sender, and are not necessarily the views of the Faculty
> of Science, Department of Statistics or Macquarie University.
>
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may contain
confidential information.  If you are not the intended recipient, please
delete it and notify the sender.  Views expressed in this message are those
of the individual sender, and are not necessarily the views of the Faculty
of Science, Department of Statistics or Macquarie University.

	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Fri Jun 26 05:14:34 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Fri, 26 Jun 2015 13:14:34 +1000
Subject: [R-sig-ME] convergence issues in multivariate mixed-model in lme
In-Reply-To: <CALC46t95RzHtFy7c05wJKrn3u9AQV-p8jeuiaMbF3B4xyGfUow@mail.gmail.com>
References: <CALC46t95RzHtFy7c05wJKrn3u9AQV-p8jeuiaMbF3B4xyGfUow@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1506261309310.9907@orpheus.qimr.edu.au>

Only traits 2, 7 and 8 seem to have much relationship with tim, and there 
are a few outliers in there. Did the multitrait model run OK when you just 
use the mean trait value across occasions?

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From bdrwecki at regis.edu  Sat Jun 27 08:05:39 2015
From: bdrwecki at regis.edu (Drwecki, Brian B)
Date: Sat, 27 Jun 2015 06:05:39 +0000
Subject: [R-sig-ME] Dependence of Effect Sizes in meta analysis metafor
 (some statistical theory questions included)
Message-ID: <C8FD8136-A4D3-439F-9E18-1C0BF2B92356@regis.edu>

Hello all,

I apologize for the long post, but I want to be thorough.

My Goal: To conduct the appropriate mixed-effects (random effects meta analysis model+ one fixed effects moderator with two categorical levels) meta analysis where 11 of 38 papers/studies present effects for both levels of my Fixed Effects moderator (i.e. these 11 studies provide 2 effect sizes each =  22 total estimates; each pair of effects is dependent and violates assumptions of independence).

Background Reading I've Done:  I read Modeling Dependent Effect Sizes With Three-Level Meta-Analyses:A Structural Equation Modeling Approach by Mike W.-L. Cheung and Three-level meta-analysis of dependent effect sizes
Wim Van den Noortgate & Jos? Antonio L?pez-L?pez & Fulgencio Mar?n-Mart?nez & Julio S?nchez-Meca & http://www.metafor-project.org/doku.php/analyses:konstantopoulos2011. Note: the last time I looked at meta analysis was 2006 and this was for a dumbed down version in a class, so a lot of the concepts are new to me, and I while I think I understand what's going on here, I'm sure there are areas that I am missing.

Explanation of my situation:  So, I have been gathering effects for a small meta analysis on the average correlation between self-esteem and academic achievement for African American students. I conceptualized self-esteem in two different ways (a priori): Global (I love myself) and Academic Specific (I'm good at school).  I have 39 different papers; 11 of these papers have both correlations (one for Global and one for Academic Specific; i.e. these effects are dependent not independent).  I want to run this analysis in one mixed effects model, where my moderator (TypeSE) is entered as a Fixed Effect, and where the error structure accounts for the dependence of the 11 studies (and 22 effects) that have measures at both levels of my moderator.

I spent a lot of time going through this example and adapting it to my situation http://www.metafor-project.org/doku.php/analyses:konstantopoulos2011 only to read at the bottom of the article... "It is important to note that the models used above assume that the sampling errors of the effect size estimates are independent. This is typically an appropriate assumption as long as there is no overlap in the data/individuals used to compute the various estimates. However, when multiple estimates are obtained from the same group of individuals, then this assumption is most certainly violated."  But then I read Cheung's article that appears to suggest I could use the same type of 3-level meta analysis model to factor out dependence that occurs when multiple estimates are taken from the same study.  So, is the attached model doing what I think it is doing (creating a three level meta analysis model where the dependence between studies is being accounted for in the error structure)?  If not, then what is the appropriate model for my situation, in your opinion (using metafor)?

My METAFOR Model: resbasic6<-rma.mv(yi,vi,random=~factor(SampleID)|StudyID, mods =TypeSE, data=dat)
resbasic6 = nameholder
SampleID= unique number for all effects (so I have 58 effects total, and they are numbered 1-58; this was done in the original metaphor three level example referenced above)
StudyID = Identifier that denotes if two effects came from the same study
TypeSE = Fixed Effect Moderator (0 = Global; 1= Academic)

Additional Questions: Best textbook/paper/mook/webinar for understanding mixed effects meta analysis;  Same question, but mixed effects models in general (with a good focus on dealing with dependence in normal, not meta analysis, data sets).

Biggest Conceptual Difficulty I'm Having: I have difficulty translating the theoretical equations presented in the papers cited above into r code.

Thanks so much, and sorry for the long message!

Brian (ps my output is below)

Output if curious:

> resbasic6

Multivariate Meta-Analysis Model (k = 55; method: REML)

Variance Components:

outer factor: StudyID          (nlvls = 39)
inner factor: factor(SampleID) (nlvls = 55)

            estim    sqrt  fixed
tau^2      0.0085  0.0921     no
rho        0.3092             no

Test for Residual Heterogeneity:
QE(df = 53) = 162.1204, p-val < .0001

Test of Moderators (coefficient(s) 2):
QM(df = 1) = 37.1505, p-val < .0001

Model Results:

         estimate      se    zval    pval   ci.lb   ci.ub
intrcpt    0.1606  0.0234  6.8710  <.0001  0.1148  0.2064  ***
mods       0.1886  0.0309  6.0951  <.0001  0.1279  0.2492  ***

---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

>




	[[alternative HTML version deleted]]


From thlytras at gmail.com  Sat Jun 27 08:50:16 2015
From: thlytras at gmail.com (Theodore Lytras)
Date: Sat, 27 Jun 2015 09:50:16 +0300
Subject: [R-sig-ME] Dependence of Effect Sizes in meta analysis metafor
	(some statistical theory questions included)
In-Reply-To: <C8FD8136-A4D3-439F-9E18-1C0BF2B92356@regis.edu>
References: <C8FD8136-A4D3-439F-9E18-1C0BF2B92356@regis.edu>
Message-ID: <2863911.t5opWDuqUv@equinox2>

???? ??? 27 ???? 2015 06:05:39 Drwecki, Brian B ??????:
> Hello all,
> 
> I apologize for the long post, but I want to be thorough.
> 
> My Goal: To conduct the appropriate mixed-effects (random effects meta
> analysis model+ one fixed effects moderator with two categorical levels)
> meta analysis where 11 of 38 papers/studies present effects for both levels
> of my Fixed Effects moderator (i.e. these 11 studies provide 2 effect sizes
> each =  22 total estimates; each pair of effects is dependent and violates
> assumptions of independence).
[snip, snip]

Hello,

Maybe you can check package "robumeta" and the associated paper: 

Hedges LV, Tipton E, Johnson MC. Robust variance estimation in meta-regression 
with dependent effect size estimates. Res Synth Method. 2010;1(1):39?65. 
http://onlinelibrary.wiley.com/doi/10.1002/jrsm.5/abstract

I've recently dealt with a similar meta-analysis situation, with hierarchical 
dependence (multiple effect estimates clustered within the same study), and 
this approach worked well for me.

As a plus, you can have "robumeta" play nice ball with "metafor":

http://blogs.edb.utexas.edu/pusto/2014/04/21/a-meta-sandwich/

Hope this helps!

Kind regards,

Theodore Lytras


From mikewlcheung at gmail.com  Sat Jun 27 09:24:32 2015
From: mikewlcheung at gmail.com (Mike Cheung)
Date: Sat, 27 Jun 2015 15:24:32 +0800
Subject: [R-sig-ME] Dependence of Effect Sizes in meta analysis metafor
 (some statistical theory questions included)
In-Reply-To: <2863911.t5opWDuqUv@equinox2>
References: <C8FD8136-A4D3-439F-9E18-1C0BF2B92356@regis.edu>
	<2863911.t5opWDuqUv@equinox2>
Message-ID: <CADF7-FNjOEY2ZGz0gSA-9ckaBd9JUXro4h4Fu9dWA8ciMP39uQ@mail.gmail.com>

Hello,

 There are several types of dependence in a meta-analysis. The effect sizes
can be conditionally dependent because the same samples (participants) are
used in the analysis. There are formulas to estimate the amount the
dependence (sampling covariances among effect sizes) when enough summary
statistics are given. The second type of dependence is the covariances
among the true effect sizes at the population level. Both of them are
assumed in a multivariate random-effects meta-analysis. If the later
(covariances among the true effect sizes) is assumed zero, it becomes a
multivariate fixed-effects meta-analysis.

 A third type of dependence happens when there are multiple effect sizes
reported by the same study. One typical issue is that we may not have
enough information to estimate the sampling covariances among effect sizes.
Thus, the multivariate meta-analysis cannot be used. If we take the
assumptions that (1) the amount of dependence is random and (2) the effect
sizes are conditionally independent after controlling for the random
effects, we may use a three-level meta-analysis to model it. This is
basically what the note means.

 Some researchers further suggested to use the three-level meta-analysis to
conduct the multivariate meta-analysis because there is no need to
calculate the conditional sampling covariances among the effect sizes.
Under some assumptions (see the following links), this approach works. On
the other hand, the three-level meta-analysis is a special case of the
multivariate meta-analysis by imposing a few constraints. Since the
multivariate and three-level meta-analyses are related, I would suggest
studying both of them at the same time and see which one fits better for
your data and research questions.

 The followings are some excerpts from my book that are related to my
points.


https://books.google.com.sg/books?id=sp3TBgAAQBAJ&pg=PA121&dq=5.1.1+Types+of+dependence&hl=en&sa=X&ei=YUmOVfWKHpOGuASOsbTABg&redir_esc=y#v=onepage&q=5.1.1%20Types%20of%20dependence&f=false


https://books.google.com.sg/books?id=sp3TBgAAQBAJ&pg=PA195&dq=6.4+Relationship+between+the+multivariate+and+the+three-level+meta-analyses&hl=en&sa=X&ei=bEiOVZibL8ytuQS_moGwCg&redir_esc=y#v=onepage&q=6.4%20Relationship%20between%20the%20multivariate%20and%20the%20three-level%20meta-analyses&f=false


 Regards,
Mike

-- 
---------------------------------------------------------------------
 Mike W.L. Cheung               Phone: (65) 6516-3702
 Department of Psychology       Fax:   (65) 6773-1843
 National University of Singapore
 http://courses.nus.edu.sg/course/psycwlm/internet/
---------------------------------------------------------------------

On Sat, Jun 27, 2015 at 2:50 PM, Theodore Lytras <thlytras at gmail.com> wrote:

> ???? ??? 27 ???? 2015 06:05:39 Drwecki, Brian B ??????:
> > Hello all,
> >
> > I apologize for the long post, but I want to be thorough.
> >
> > My Goal: To conduct the appropriate mixed-effects (random effects meta
> > analysis model+ one fixed effects moderator with two categorical levels)
> > meta analysis where 11 of 38 papers/studies present effects for both
> levels
> > of my Fixed Effects moderator (i.e. these 11 studies provide 2 effect
> sizes
> > each =  22 total estimates; each pair of effects is dependent and
> violates
> > assumptions of independence).
> [snip, snip]
>
> Hello,
>
> Maybe you can check package "robumeta" and the associated paper:
>
> Hedges LV, Tipton E, Johnson MC. Robust variance estimation in
> meta-regression
> with dependent effect size estimates. Res Synth Method. 2010;1(1):39?65.
> http://onlinelibrary.wiley.com/doi/10.1002/jrsm.5/abstract
>
> I've recently dealt with a similar meta-analysis situation, with
> hierarchical
> dependence (multiple effect estimates clustered within the same study), and
> this approach worked well for me.
>
> As a plus, you can have "robumeta" play nice ball with "metafor":
>
> http://blogs.edb.utexas.edu/pusto/2014/04/21/a-meta-sandwich/
>
> Hope this helps!
>
> Kind regards,
>
> Theodore Lytras
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sat Jun 27 10:26:28 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Sat, 27 Jun 2015 10:26:28 +0200
Subject: [R-sig-ME] Dependence of Effect Sizes in meta analysis metafor
 (some statistical theory questions included)
In-Reply-To: <CADF7-FNjOEY2ZGz0gSA-9ckaBd9JUXro4h4Fu9dWA8ciMP39uQ@mail.gmail.com>
References: <C8FD8136-A4D3-439F-9E18-1C0BF2B92356@regis.edu>
	<2863911.t5opWDuqUv@equinox2>
	<CADF7-FNjOEY2ZGz0gSA-9ckaBd9JUXro4h4Fu9dWA8ciMP39uQ@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F1713161F@UM-MAIL4112.unimaas.nl>

These are already some excellent responses. Let me add a few comments of my own.

Brian mentioned the Konstantopoulos (2011) reanalysis (http://www.metafor-project.org/doku.php/analyses:konstantopoulos2011) but it is also useful to carefully examine the two pages linked to (http://www.metafor-project.org/doku.php/analyses:berkey1998 and http://www.metafor-project.org/doku.php/analyses:gleser2009). These discuss some methods/models when the *sampling errors* cannot be assumed to be independent.

In fact, I think there is a lot of confusion out there in the literature as to what type of methods/models are needed in multivariate/multilevel-type of situations when conducting a meta-analysis. To be more specific, when the same sample is used to obtain two (or more) effect size estimates (either because the same outcome is measured at two measurement occasions or because two different outcomes are measured), then the sampling errors of the estimates are likely to be dependent. I would emphasize that this dependence pertains to the *sampling errors* of the estimates -- and just like we can derive equations to compute (or rather, estimate) the variance of the sampling error for various effect size measures (e.g., log odds/risk ratios, raw or standardized mean differences, and so on), we can derive the necessary equations to compute/estimate the covariance of the sampling errors. This is what Gleser and Olkin (2009) describe at great length in their chapter (http://www.metafor-project.org/doku.php/analyses:gleser2009).

Unless the measurements over time or for multiple outcomes can be assumed to be independent (which would be very unlikely in most situations), it is a mathematical/statistical fact that the sampling errors for multiple estimates derived based on those measurements are going to be dependent as well.

Mike also nicely described that there can be another dependence as well, namely that of the underlying true effects. That is, the underlying true effects corresponding to the estimates arising from the same study/sample may be more similar to each other than those arising from different samples/studies (i.e., they may be correlated). Whether this is really the case or not is an empirical question and needs to be examined by estimating the covariance/correlation between the true effects (by means of an appropriate multilevel/multivariate model). This is illustrated/discussed, for example, in the paper by Berkey et al. (1998) (http://www.metafor-project.org/doku.php/analyses:berkey1998).

In fact, this type dependence may also be present when the sampling errors can be safely assumed to be uncorrelated within a study. For example, the two effect size estimates may pertain to the group of men and women within the study -- since the two samples do not overlap, the sampling errors can be assumed to be independent. Or multiple estimates may be available based on different studies reported in the same paper, based on completely different samples. This type of sitation is in fact what is described in the Konstantopoulos (2011) paper (http://www.metafor-project.org/doku.php/analyses:konstantopoulos2011).

However, it seems to me that there is a general misconception that it is sufficient to only consider/deal with the second time of dependence (i.e., the possible correlation among the underlying true effects) -- and the dependence in the sampling errors is ignored. There may be a rather pragmatic reason for that: Computing/estimating the covariance of the sampling errors typically requires information that is often not reported in the studies (e.g., the correlation among the measurements across multiple measurement occasions or the correlation among the different outcomes). That is, however, not a good/appropriate reason to ignore this dependence.

As Mike mentioned, there may be situations where ignoring this dependence may still lead to valid inferences, but the decision to ignore this dependence should then be made based on a very thorough consideration of all aspects of the analysis (data, model, assumptions, ...) and not be done routinely.

If the covariance among the sampling errors cannot be computed (even after contacting study authors to obtain the missing information needed), there are several options:

1) One can still often make a rough/educated guess how large correlations (or whatever else is needed to compute the covariances) are. Then one uses those 'guestimates' and conduct sensitivity analyses to ensure that conclusions remain unchanged when the values are varied within a reasonable range.

2) Theodore mentioned using robust methods -- in essence, we then consider the assumed variance-covariance matrix to be misspecified (i.e., we assume it is diagonal, when in fact we know it isn't) and then estimate the variance-covariance matrix of the fixed effects (which are typically of primary interest) using consistent methods even under such a model misspecification.

3) Resampling methods (i.e., bootstrapping and permutation testing) may also work.

4) There are also some alternative models that try to circumvent the problem by means of some simplification of the model. Specifically, in the model/approach by Riley and colleagues (see, for example: Riley, R. D., Abrams, K. R., Lambert, P. C., Sutton, A. J., & Thompson, J. R. (2007). An evaluation of bivariate random-effects meta-analysis for the joint synthesis of two correlated outcomes. Statistics in Medicine, 26(1), 78-97.), we assume that the correlation among the sampling errors is identical to the correlation among the underlying true effects, and then we just estimate that one correlation. This can work, but whether it does depends on how well that simplification matches up with reality.

5) There is always another option: Avoid any kind of statistical dependence via data reduction (e.g., selecting only one estimate, conducting separate analyses for different outcomes). This is still the most commonly used approach to 'handling' the problem, because it allows practitioners to stick to (relatively simple) models/methods/software they are already familiar with. But this approach can be wasteful and limits inference (e.g., if we conduct two separate meta-analyses for outcomes A and B, we cannot test whether the estimated effect is different for A and B unless we can again properly account for their covariance).

P.S.: Brian -- in your rma.mv() call, you used 'mods = TypeSE'. I would suggest to use 'mods = ~ TypeSE' (you can make use of formula syntax for the 'mods' argument).

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Mike Cheung
> Sent: Saturday, June 27, 2015 09:25
> To: Theodore Lytras
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Dependence of Effect Sizes in meta analysis
> metafor (some statistical theory questions included)
> 
> Hello,
> 
>  There are several types of dependence in a meta-analysis. The effect
> sizes
> can be conditionally dependent because the same samples (participants)
> are
> used in the analysis. There are formulas to estimate the amount the
> dependence (sampling covariances among effect sizes) when enough summary
> statistics are given. The second type of dependence is the covariances
> among the true effect sizes at the population level. Both of them are
> assumed in a multivariate random-effects meta-analysis. If the later
> (covariances among the true effect sizes) is assumed zero, it becomes a
> multivariate fixed-effects meta-analysis.
> 
>  A third type of dependence happens when there are multiple effect sizes
> reported by the same study. One typical issue is that we may not have
> enough information to estimate the sampling covariances among effect
> sizes.
> Thus, the multivariate meta-analysis cannot be used. If we take the
> assumptions that (1) the amount of dependence is random and (2) the
> effect
> sizes are conditionally independent after controlling for the random
> effects, we may use a three-level meta-analysis to model it. This is
> basically what the note means.
> 
>  Some researchers further suggested to use the three-level meta-analysis
> to
> conduct the multivariate meta-analysis because there is no need to
> calculate the conditional sampling covariances among the effect sizes.
> Under some assumptions (see the following links), this approach works. On
> the other hand, the three-level meta-analysis is a special case of the
> multivariate meta-analysis by imposing a few constraints. Since the
> multivariate and three-level meta-analyses are related, I would suggest
> studying both of them at the same time and see which one fits better for
> your data and research questions.
> 
>  The followings are some excerpts from my book that are related to my
> points.
> 
> https://books.google.com.sg/books?id=sp3TBgAAQBAJ&pg=PA121&dq=5.1.1+Types
> +of+dependence&hl=en&sa=X&ei=YUmOVfWKHpOGuASOsbTABg&redir_esc=y#v=onepage
> &q=5.1.1%20Types%20of%20dependence&f=false
> 
> https://books.google.com.sg/books?id=sp3TBgAAQBAJ&pg=PA195&dq=6.4+Relatio
> nship+between+the+multivariate+and+the+three-level+meta-
> analyses&hl=en&sa=X&ei=bEiOVZibL8ytuQS_moGwCg&redir_esc=y#v=onepage&q=6.4
> %20Relationship%20between%20the%20multivariate%20and%20the%20three-
> level%20meta-analyses&f=false
> 
>  Regards,
> Mike
> 
> --
> ---------------------------------------------------------------------
>  Mike W.L. Cheung               Phone: (65) 6516-3702
>  Department of Psychology       Fax:   (65) 6773-1843
>  National University of Singapore
>  http://courses.nus.edu.sg/course/psycwlm/internet/
> ---------------------------------------------------------------------
> 
> On Sat, Jun 27, 2015 at 2:50 PM, Theodore Lytras <thlytras at gmail.com>
> wrote:
> 
> > ???? ??? 27 ???? 2015 06:05:39 Drwecki, Brian B ??????:
> > > Hello all,
> > >
> > > I apologize for the long post, but I want to be thorough.
> > >
> > > My Goal: To conduct the appropriate mixed-effects (random effects
> meta
> > > analysis model+ one fixed effects moderator with two categorical
> levels)
> > > meta analysis where 11 of 38 papers/studies present effects for both
> > levels
> > > of my Fixed Effects moderator (i.e. these 11 studies provide 2 effect
> > sizes
> > > each =  22 total estimates; each pair of effects is dependent and
> > violates
> > > assumptions of independence).
> > [snip, snip]
> >
> > Hello,
> >
> > Maybe you can check package "robumeta" and the associated paper:
> >
> > Hedges LV, Tipton E, Johnson MC. Robust variance estimation in
> > meta-regression
> > with dependent effect size estimates. Res Synth Method. 2010;1(1):39?
> 65.
> > http://onlinelibrary.wiley.com/doi/10.1002/jrsm.5/abstract
> >
> > I've recently dealt with a similar meta-analysis situation, with
> > hierarchical
> > dependence (multiple effect estimates clustered within the same study),
> and
> > this approach worked well for me.
> >
> > As a plus, you can have "robumeta" play nice ball with "metafor":
> >
> > http://blogs.edb.utexas.edu/pusto/2014/04/21/a-meta-sandwich/
> >
> > Hope this helps!
> >
> > Kind regards,
> >
> > Theodore Lytras

From drmccloy at uw.edu  Sun Jun 28 01:57:03 2015
From: drmccloy at uw.edu (Dan McCloy)
Date: Sun, 28 Jun 2015 07:57:03 +0800
Subject: [R-sig-ME] trouble specifying cumulative-link mixed model
Message-ID: <CAOE0pYnz+vv+TunwFY7Fwr0-vXf92D7E5Ubm+020OYDvJShcMg@mail.gmail.com>

I'm having a little trouble figuring out how to set up my model. The data
are about pronunciation of vowel sounds in speech: 21556 observations of an
ordered categorical outcome ("none", "devoiced", "deleted"). I *think* what
I want is a cumulative-link mixed model, which I can get with the ordinal
package's clmm() function. However, the outcome is very unbalanced (which
may or may not be the source of my problems):

table(cleandata$reduction)
##     none devoiced  deleted
##    20776      360      420

I have random effects for nuisance variables speaker (n=6) and word
(n=1204). Observations within these two are fairly well-balanced (i.e.,
there is not much missing data; the vast majority of speaker-word pairings
have exactly 3 observations):

table(with(cleandata, table(word, speaker)))
##    0    1    2    3
##   14   11   52 7147

What I really care about is preceding consonant type (6 levels), following
consonant type (also 6 levels), and whether following consonant is itself
followed by another consonant ("coda", binary). Another predictor we expect
to be important is whether or not preceding and/or following consonant are
"aspirated", which is a property of only 2 of the 6 levels. The identity of
the vowel itself (10 levels) is not of primary interest but definitely
ought to be included; I am open to including it as a random effect, but
slightly prefer being able to see estimates for each level of the vowel if
possible.

What I'm struggling with is how to specify the fixed effects. If I include
everything (precedingCons + followingCons * coda + aspirated + random
effects), I get "numerically singular Hessian" problems, regardless of
whether I specify preceding / following consonant as factors, or set up
binary variables like "preceding.stop", "following.stop",
"preceding.fricative", etc. (which I think are equivalent anyway, since the
factor was treatment-coded).  I can get the model to converge if I do the
binary variables method but only include 3 of the 6 levels for preceding
and following consonant (plus "aspirated" & random effects).

My questions:
1. is CLMM the right modeling choice?  In principle I can collapse
"reduction" to binary and do a logit-link glmm, by collapsing "devoiced"
and "deleted" into one category, but really don't want to have to resort to
that.
2. is the imbalance in my outcome causing the problems with the modeling?
Do I need some sort of zero-inflation model (which I've heard talked about
on this list, but don't really understand yet)?
3. any suggestions for how to specify the fixed effects (i.e., factor
coding)?

Some additional tables showing distribution of the response levels are
included in a GitHub gist here:
https://gist.github.com/drammock/bf7a6d634bbd179b328f

thanks,
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington

	[[alternative HTML version deleted]]


From bdrwecki at regis.edu  Sun Jun 28 07:29:22 2015
From: bdrwecki at regis.edu (Drwecki, Brian B)
Date: Sun, 28 Jun 2015 05:29:22 +0000
Subject: [R-sig-ME] Dependence of Effect Sizes in meta analysis metafor
 (some statistical theory questions included)
In-Reply-To: <2863911.t5opWDuqUv@equinox2>
References: <C8FD8136-A4D3-439F-9E18-1C0BF2B92356@regis.edu>
	<2863911.t5opWDuqUv@equinox2>
Message-ID: <4EF2C57C-049D-4B43-AEE4-92ACFDDDCC48@regis.edu>

Thanks all, 

You've given me a lot of reading to do!  Thank you.   I'll post my final model just for the sake of those who come after me and who search the archive.  


BBD



On Jun 27, 2015, at 12:50 AM, Theodore Lytras <thlytras at gmail.com> wrote:

> ???? ??? 27 ???? 2015 06:05:39 Drwecki, Brian B ??????:
>> Hello all,
>> 
>> I apologize for the long post, but I want to be thorough.
>> 
>> My Goal: To conduct the appropriate mixed-effects (random effects meta
>> analysis model+ one fixed effects moderator with two categorical levels)
>> meta analysis where 11 of 38 papers/studies present effects for both levels
>> of my Fixed Effects moderator (i.e. these 11 studies provide 2 effect sizes
>> each =  22 total estimates; each pair of effects is dependent and violates
>> assumptions of independence).
> [snip, snip]
> 
> Hello,
> 
> Maybe you can check package "robumeta" and the associated paper: 
> 
> Hedges LV, Tipton E, Johnson MC. Robust variance estimation in meta-regression 
> with dependent effect size estimates. Res Synth Method. 2010;1(1):39?65. 
> http://onlinelibrary.wiley.com/doi/10.1002/jrsm.5/abstract
> 
> I've recently dealt with a similar meta-analysis situation, with hierarchical 
> dependence (multiple effect estimates clustered within the same study), and 
> this approach worked well for me.
> 
> As a plus, you can have "robumeta" play nice ball with "metafor":
> 
> http://blogs.edb.utexas.edu/pusto/2014/04/21/a-meta-sandwich/
> 
> Hope this helps!
> 
> Kind regards,
> 
> Theodore Lytras
> 
> 


From iandanilevicz at gmail.com  Sun Jun 28 17:45:08 2015
From: iandanilevicz at gmail.com (Ian Danilevicz)
Date: Sun, 28 Jun 2015 12:45:08 -0300
Subject: [R-sig-ME] [R] mixed model ANCOVA
Message-ID: <CADRJoZdkohHWBb8T++jzu7+D=pRpy7iSJiaCX8VxgyqocPwOzg@mail.gmail.com>

Hy,
I have read a post about mixed models (the link is below) and I still in
doubt.

https://stat.ethz.ch/pipermail/r-help/2013-December/364091.html

the problem was:

>* * 1 subject factor (random, between subjects) called Subject
*>* * 3 categorical within subjects factors called Emotion, Sex, Race
*>

* * 1 continuous covariate (**WITHIN subjects**) called Score*



*the suggested models were:*ModelRT <- lmer(logRT ~ Race*Sex*Emotion +
(1 | Subject))

or using lme from the nlme package:

ModelRT <- lme(logRT~Race*Sex*Emotion, random=~1|Subject)


However, where is the Score variable?

Best Regards, Ian

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Jun 28 18:36:19 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 28 Jun 2015 12:36:19 -0400
Subject: [R-sig-ME] [R] mixed model ANCOVA
In-Reply-To: <CADRJoZdkohHWBb8T++jzu7+D=pRpy7iSJiaCX8VxgyqocPwOzg@mail.gmail.com>
References: <CADRJoZdkohHWBb8T++jzu7+D=pRpy7iSJiaCX8VxgyqocPwOzg@mail.gmail.com>
Message-ID: <CABghstQ2+vo1TcyyY3f030F9DJFLo5VBG3AZF4s6o5DKBW-Csw@mail.gmail.com>

On Sun, Jun 28, 2015 at 11:45 AM, Ian Danilevicz
<iandanilevicz at gmail.com> wrote:
> Hy,
> I have read a post about mixed models (the link is below) and I still in
> doubt.
>
> https://stat.ethz.ch/pipermail/r-help/2013-December/364091.html
>
> the problem was:
>
>>* * 1 subject factor (random, between subjects) called Subject
> *>* * 3 categorical within subjects factors called Emotion, Sex, Race
> *>
>
> * * 1 continuous covariate (**WITHIN subjects**) called Score*
>
>
>
> *the suggested models were:*ModelRT <- lmer(logRT ~ Race*Sex*Emotion +
> (1 | Subject))
>
> or using lme from the nlme package:
>
> ModelRT <- lme(logRT~Race*Sex*Emotion, random=~1|Subject)
>
>
> However, where is the Score variable?

  Please try not to send HTML-formatted e-mail to the list ...

  You're right, I was too hasty in answering that question.  I think it should
have been

ModelRT <- lmer(logRT ~ Race*Sex*Emotion + Score +  (Score | Subject))

(I'm a little bit suspicious of the original description, which says
that Sex and Race are "within-subjects" factors ...)


From bbolker at gmail.com  Sun Jun 28 19:01:49 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 28 Jun 2015 22:31:49 +0530
Subject: [R-sig-ME] [R] mixed model ANCOVA
In-Reply-To: <CABghstQ2+vo1TcyyY3f030F9DJFLo5VBG3AZF4s6o5DKBW-Csw@mail.gmail.com>
References: <CADRJoZdkohHWBb8T++jzu7+D=pRpy7iSJiaCX8VxgyqocPwOzg@mail.gmail.com>
	<CABghstQ2+vo1TcyyY3f030F9DJFLo5VBG3AZF4s6o5DKBW-Csw@mail.gmail.com>
Message-ID: <CABghstQqtp7TXM5eChSOs75-WgSaCN+oLGhxohnxLxCAV_Jh-g@mail.gmail.com>

PS it might be worth considering (fixed) interactions of Race, Sex,
Emotion with Score as well, if you have enough data to make it
feasible.

On Sun, Jun 28, 2015 at 10:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
> On Sun, Jun 28, 2015 at 11:45 AM, Ian Danilevicz
> <iandanilevicz at gmail.com> wrote:
>> Hy,
>> I have read a post about mixed models (the link is below) and I still in
>> doubt.
>>
>> https://stat.ethz.ch/pipermail/r-help/2013-December/364091.html
>>
>> the problem was:
>>
>>>* * 1 subject factor (random, between subjects) called Subject
>> *>* * 3 categorical within subjects factors called Emotion, Sex, Race
>> *>
>>
>> * * 1 continuous covariate (**WITHIN subjects**) called Score*
>>
>>
>>
>> *the suggested models were:*ModelRT <- lmer(logRT ~ Race*Sex*Emotion +
>> (1 | Subject))
>>
>> or using lme from the nlme package:
>>
>> ModelRT <- lme(logRT~Race*Sex*Emotion, random=~1|Subject)
>>
>>
>> However, where is the Score variable?
>
>   Please try not to send HTML-formatted e-mail to the list ...
>
>   You're right, I was too hasty in answering that question.  I think it should
> have been
>
> ModelRT <- lmer(logRT ~ Race*Sex*Emotion + Score +  (Score | Subject))
>
> (I'm a little bit suspicious of the original description, which says
> that Sex and Race are "within-subjects" factors ...)


From bbolker at gmail.com  Mon Jun 29 05:21:56 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 28 Jun 2015 23:21:56 -0400
Subject: [R-sig-ME] comparing random effect variation between data sets
In-Reply-To: <CAPTgL1YVtUAuG8XGkk80BgTRb8dU8B2aE4JnfK_0Q1vnAxdzBQ@mail.gmail.com>
References: <CAPTgL1YVtUAuG8XGkk80BgTRb8dU8B2aE4JnfK_0Q1vnAxdzBQ@mail.gmail.com>
Message-ID: <CABghstSBJpbX-R-w9ftK45GZigG8cSdpVDpedyPrqXchwz96Sw@mail.gmail.com>

  A couple of quick thoughts:

* as a crude test, you could get the profile confidence intervals
for the random-effect SDs in each model and compare them
* a more formal test would put both species into the same model
and allow for different variances.  This might work:

library(lme4)
library(gamm4)
alldat <- rbind(data.frame(species="X",speciesX),
                data.frame(species="Y",speciesY))

comb <- gamm4(distance ~ s(time,k=4,by=species),
                  random=~(1|CODE)+(dummy(species,"Y")|CODE))

You could test of comb against the model with just random=~(1|CODE),
or look at the confidence intervals of the second RE term.


On Thu, Jun 25, 2015 at 9:07 AM, John Morrongiello
<jrmorrongiello at gmail.com> wrote:
> Hi all
>
> I have movement data for two species of fish (say species X and species Y).
> The response variable is 'distance from home' (distance) and multiple
> measurements (5-17) are made for 20-30 individuals per species over a
> period of 200 days. Distance is continuous and strictly positive so I am
> using a gamma distribution with a log link. My collegues would like me to
> fit seperate models for each species to explore temporal patterns in
> movement (time). We believe there will be non-linear patterns in movement
> through time so have I have fitted GAMMs
>
> I'm happy with the two models and their interpretation. I would, however,
> like to compare the level of among-individual variation in movement between
> species. The species-average trends are pretty similar but it looks like
> there is more variance among individuals for species X than species Y.
>
> I was thinking of extracting the individual level random effects from the
> two models and performing a variance test on these. My logic is that given
> the response variables are the same and the model structures are the same,
> I could make a meaningful comparison of random effects. The overall model
> intercepts are different but I thought this is not an issue here as I'm
> only interested in the variance of the random effects, not their average.
>
> Is this approach valid, or am I violating assumptions/ these data are not
> directly comparable ? If not, what would be a potential way to perform this
> comparision? Below is the code I'm thinking of using.
>
> Thanks very much for your time
>
> John
>
> #####GAMMs
> X1<-gamm4(distance ~ s(time,k=4), random=~(1|CODE),data=speciesX,
> family=Gamma(link=log))
> Y1<-gamm4(distance ~ s(time,k=4), random=~(1|CODE),data=speciesY,
> family=Gamma(link=log))
>
> ######extract random effects from the two models
> X1ranef<-ranef(X1$mer)###extract random effects from model
> X1ranef<-data.frame(matrix(unlist(X1ranef$'CODE'),ncol=1))##convert list of
> random effects to data frame
> names(X1ranef)<-c('CODE')
>
> Y1ranef<-ranef(X1$mer)###extract random effects from model
> Y1ranef<-data.frame(matrix(unlist(Y1ranef$'CODE'),ncol=1))##convert list of
> random effects to data frame
> names(Y1ranef)<-c('CODE')
>
> ######perform variance test
> var.test(X1ranef$CODE,Y1ranef$CODE)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jrmorrongiello at gmail.com  Mon Jun 29 06:02:58 2015
From: jrmorrongiello at gmail.com (John Morrongiello)
Date: Mon, 29 Jun 2015 14:02:58 +1000
Subject: [R-sig-ME] comparing random effect variation between data sets
In-Reply-To: <CABghstSBJpbX-R-w9ftK45GZigG8cSdpVDpedyPrqXchwz96Sw@mail.gmail.com>
References: <CAPTgL1YVtUAuG8XGkk80BgTRb8dU8B2aE4JnfK_0Q1vnAxdzBQ@mail.gmail.com>
	<CABghstSBJpbX-R-w9ftK45GZigG8cSdpVDpedyPrqXchwz96Sw@mail.gmail.com>
Message-ID: <CAPTgL1ZQEWh8fxfP6DwtcDbFsaNn3e-Pd+kWdjV=u6t+vLKTDg@mail.gmail.com>

Thanks very much for this suggestion Ben. Makes good sense and I'll see how
it goes.

On Mon, Jun 29, 2015 at 1:21 PM, Ben Bolker <bbolker at gmail.com> wrote:

>   A couple of quick thoughts:
>
> * as a crude test, you could get the profile confidence intervals
> for the random-effect SDs in each model and compare them
> * a more formal test would put both species into the same model
> and allow for different variances.  This might work:
>
> library(lme4)
> library(gamm4)
> alldat <- rbind(data.frame(species="X",speciesX),
>                 data.frame(species="Y",speciesY))
>
> comb <- gamm4(distance ~ s(time,k=4,by=species),
>                   random=~(1|CODE)+(dummy(species,"Y")|CODE))
>
> You could test of comb against the model with just random=~(1|CODE),
> or look at the confidence intervals of the second RE term.
>
>
> On Thu, Jun 25, 2015 at 9:07 AM, John Morrongiello
> <jrmorrongiello at gmail.com> wrote:
> > Hi all
> >
> > I have movement data for two species of fish (say species X and species
> Y).
> > The response variable is 'distance from home' (distance) and multiple
> > measurements (5-17) are made for 20-30 individuals per species over a
> > period of 200 days. Distance is continuous and strictly positive so I am
> > using a gamma distribution with a log link. My collegues would like me to
> > fit seperate models for each species to explore temporal patterns in
> > movement (time). We believe there will be non-linear patterns in movement
> > through time so have I have fitted GAMMs
> >
> > I'm happy with the two models and their interpretation. I would, however,
> > like to compare the level of among-individual variation in movement
> between
> > species. The species-average trends are pretty similar but it looks like
> > there is more variance among individuals for species X than species Y.
> >
> > I was thinking of extracting the individual level random effects from the
> > two models and performing a variance test on these. My logic is that
> given
> > the response variables are the same and the model structures are the
> same,
> > I could make a meaningful comparison of random effects. The overall model
> > intercepts are different but I thought this is not an issue here as I'm
> > only interested in the variance of the random effects, not their average.
> >
> > Is this approach valid, or am I violating assumptions/ these data are not
> > directly comparable ? If not, what would be a potential way to perform
> this
> > comparision? Below is the code I'm thinking of using.
> >
> > Thanks very much for your time
> >
> > John
> >
> > #####GAMMs
> > X1<-gamm4(distance ~ s(time,k=4), random=~(1|CODE),data=speciesX,
> > family=Gamma(link=log))
> > Y1<-gamm4(distance ~ s(time,k=4), random=~(1|CODE),data=speciesY,
> > family=Gamma(link=log))
> >
> > ######extract random effects from the two models
> > X1ranef<-ranef(X1$mer)###extract random effects from model
> > X1ranef<-data.frame(matrix(unlist(X1ranef$'CODE'),ncol=1))##convert list
> of
> > random effects to data frame
> > names(X1ranef)<-c('CODE')
> >
> > Y1ranef<-ranef(X1$mer)###extract random effects from model
> > Y1ranef<-data.frame(matrix(unlist(Y1ranef$'CODE'),ncol=1))##convert list
> of
> > random effects to data frame
> > names(Y1ranef)<-c('CODE')
> >
> > ######perform variance test
> > var.test(X1ranef$CODE,Y1ranef$CODE)
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Mon Jun 29 20:33:55 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 29 Jun 2015 13:33:55 -0500
Subject: [R-sig-ME] trouble specifying cumulative-link mixed model
In-Reply-To: <CAOE0pYnz+vv+TunwFY7Fwr0-vXf92D7E5Ubm+020OYDvJShcMg@mail.gmail.com>
References: <CAOE0pYnz+vv+TunwFY7Fwr0-vXf92D7E5Ubm+020OYDvJShcMg@mail.gmail.com>
Message-ID: <CAErODj9zjQva_LyQ73h7mGW0bUfa_ZZ2N-8o98tZxBHPCbfJgg@mail.gmail.com>

pj

On Sat, Jun 27, 2015 at 6:57 PM, Dan McCloy <drmccloy at uw.edu> wrote:
> I'm having a little trouble figuring out how to set up my model. The data
> are about pronunciation of vowel sounds in speech: 21556 observations of an
> ordered categorical outcome ("none", "devoiced", "deleted"). I *think* what
> I want is a cumulative-link mixed model, which I can get with the ordinal
> package's clmm() function. However, the outcome is very unbalanced (which
> may or may not be the source of my problems):
>
> table(cleandata$reduction)
> ##     none devoiced  deleted
> ##    20776      360      420
>

Your outcome is so imbalanced you might fall into the "rare events"
end of the spectrum.   We know logit models are biased, but we also
have pretty good tools for correcting the coefficients.  If you Google
"rare events logistic" you should come to a tempest-in-a-teapot type
of debate.  This note by Paul Allison rings true.

http://statisticalhorizons.com/logistic-regression-for-rare-events

The caution, however, is that it is almost impossible to get a
predicted value that is anything except "none" in this kind of data.

> I have random effects for nuisance variables speaker (n=6) and word
> (n=1204). Observations within these two are fairly well-balanced (i.e.,
> there is not much missing data; the vast majority of speaker-word pairings
> have exactly 3 observations):
>
> table(with(cleandata, table(word, speaker)))
> ##    0    1    2    3
> ##   14   11   52 7147
>

On the other hand, there is no happy answer for a grossly imbalanced
predictor. If that is the predictor, anyway.  It is virtually
impossible to say that being in category 3 has a significant effect
compared to category 2 when there are 7147 cases in 1 and 52 in the
other.

You should make a small simulation that generates ordinal data with
various predictors.  See if clmm gives you answers you believe/expect.
Then push the simulation toward the edges of unanimity, and see what
clmm gives you.  I can say, almost with certainty, you will see the
sampling distribution of the estimated coefficients get wider and
wider as the imbalance grows, and if you do that thing people always
do of choosing the ones with "good" p-values, then the ones you keep
will be badly biased.


> What I really care about is preceding consonant type (6 levels), following
> consonant type (also 6 levels), and whether following consonant is itself
> followed by another consonant ("coda", binary).  Another predictor we expect
> to be important is whether or not preceding and/or following consonant are
> "aspirated", which is a property of only 2 of the 6 levels. The identity of
> the vowel itself (10 levels) is not of primary interest but definitely
> ought to be included; I am open to including it as a random effect, but
> slightly prefer being able to see estimates for each level of the vowel if
> possible.
>
> What I'm struggling with is how to specify the fixed effects. If I include
> everything (precedingCons + followingCons * coda + aspirated + random
> effects), I get "numerically singular Hessian" problems, regardless of
> whether I specify preceding / following consonant as factors, or set up
> binary variables like "preceding.stop", "following.stop",
> "preceding.fricative", etc. (which I think are equivalent anyway, since the
> factor was treatment-coded).  I can get the model to converge if I do the
> binary variables method but only include 3 of the 6 levels for preceding
> and following consonant (plus "aspirated" & random effects).
>
This means your predictors are redundant. Not necessarily
theoretically, but in the data.  Use model.matrix to get a look at
your predictors as R wants to build your design matrix. I guarantee
some rows will be indentical or very similar.

You can manufacture new categories of predictors to simplify.  Here is
example of problem you likely have

1 1 1 1
1 0 0 0
1 0 0 0
1 0 0 0
1 0 1 1
1 0 1 1
1 0 1 1


We never get variable 1 with any value but 1.  We never get variable 3
without also a 1 on variable 4.  The only predictor that is separately
useful is the 2nd column.


> My questions:
> 1. is CLMM the right modeling choice?  In principle I can collapse
> "reduction" to binary and do a logit-link glmm, by collapsing "devoiced"
> and "deleted" into one category, but really don't want to have to resort to
> that.
> 2. is the imbalance in my outcome causing the problems with the modeling?
> Do I need some sort of zero-inflation model (which I've heard talked about
> on this list, but don't really understand yet)?
> 3. any suggestions for how to specify the fixed effects (i.e., factor
> coding)?
>
> Some additional tables showing distribution of the response levels are
> included in a GitHub gist here:
> https://gist.github.com/drammock/bf7a6d634bbd179b328f
>
> thanks,
> -- dan
>
> Daniel McCloy
> http://dan.mccloy.info/
> Postdoctoral Research Fellow
> Institute for Learning and Brain Sciences
> University of Washington
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From pauljohn32 at gmail.com  Mon Jun 29 21:35:28 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 29 Jun 2015 14:35:28 -0500
Subject: [R-sig-ME] constructed level 2 predictors/random effects
Message-ID: <CAErODj-2ek=wiC13=knDKddtebJwZMQD80T0PVvQYumzZkt8Dw@mail.gmail.com>

I see people wanting to average survey responses to manufacture
contextual variables. They just take the average of individual level
scores and treat it as if it were context.  Or in studies of
education, they average class Socio Economic or religious variables
and use the means for context.   Have you ever seen R packages that
try to facilitate this kind of work?

I am thinking about problems like this.

1. Can we account for the standard error of the mean at the group
level?  Will the come back to "not with lme4, but the old lme had
varIdent for weights?"

Of course, if there is 1 or 2 people within a cluster, and 50 in
another, we'd have an especially big reason to try to fix this.

2. It seems to me they should calculate a "leave one out" estimate for
each row, excluding that case's impact on the group-level average.

I'm thinking about the education studies that want to both create mean
SES as a predictor, and then look at individual variations against
that predictor.  If there are 100 people within each classroom, I
don't guess it matters.  But sometimes they have 2 or 5 people within
each group.

3. They are using raw averages, not pooled estimates for these
constructed level 2 variables.  It looks to me like we ought to fit a
multi level model on those variables, using the group as a random
effect. Then take the BLUPs as estimates of the context.  Otherwise,
these means at the group level are just as inefficent as the
one-regression-per group approach.

Even if you don't know of R work on this, I'd appreciate any pointers
to literature or such.

-- 
Paul E. Johnson
Professor, Political Science       Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://crmda.ku.edu


From pierces1 at msu.edu  Tue Jun 30 15:11:37 2015
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 30 Jun 2015 09:11:37 -0400
Subject: [R-sig-ME] constructed level 2 predictors/random effects
In-Reply-To: <CAErODj-2ek=wiC13=knDKddtebJwZMQD80T0PVvQYumzZkt8Dw@mail.gmail.com>
References: <CAErODj-2ek=wiC13=knDKddtebJwZMQD80T0PVvQYumzZkt8Dw@mail.gmail.com>
Message-ID: <000001d0b336$4c097b00$e41c7100$@msu.edu>

Paul,

I don?t know any R packages that are specific to this issue, but there are interesting theoretical and methods papers on measuring constructs at a higher level of analysis with via aggregation in the organizational psychology literature. Chan (1998) wrote some very interesting bits on conceptualizing constructs at multiple levels of analysis. Kozlowski & Klein (2000) discuss that further. The other papers listed below get more into specifics of measurement & validating constructs. One issue that Croon (2007) brought up was treating the aggregation as a latent variable via SEM techniques; subsequently L?dtke et al (2008) refined that idea, as did Marsh et al (2012). 

Chan, D. (1998). Functional relations among constructs in the same content domain at different levels of analysis: A typology of composition models. Journal of Applied Psychology, 83(2), 234-246. doi: 10.1037/0021-9010.83.2.234

Kozlowski, S. W. J., & Klein, K. J. (2000). A multilevel approach to theory and research in organizations: Contextual, temporal, and emergent processes. In K. J. Klein & S. W. J. Kozlowski (Eds.), Multilevel theory, research, and methods in organizations: Foundations, extensions, and new directions (pp. 3-90). San Francisco, CA: Jossey-Bass.

Cole, M. S., Bedeian, A. G., Hirschfeld, R. R., & Vogel, B. (2011). Dispersion-composition models in multilevel research: A data-analytic framework. Organizational Research Methods, 14(4), 718-734. doi: 10.1177/1094428110389078

Conway III, L. G., & Schaller, M. (1998). Methods for the measurement of consensual beliefs within groups. Group Dynamics: Theory, Research, and Practice, 2(4), 241-252. doi: 10.1037/1089-2699.2.4.241

Croon, M. A. (2007). Predicting group-level outcome variables from variables measured at the individual level: A latent variable multilevel model. Psychological Methods, 12(1), 45-57. doi: 10.1037/1082-989X.12.1.45

Liska, A. E. (1990). The significance of aggregate dependent variables and contextual independent variables for linking macro and micro theories. Social Psychology Quarterly, 53(4), 292-301.

L?dtke, O., Marsh, H. W., Robitzsch, A., Trautwein, U., Asparouhov, T., & Muth?n, B. (2008). The multilevel latent covariate model: A new, more reliable approach to group-level effects in contextual studies. Psychological Methods, 13(3), 203-229. doi: 10.1037/a0012869

Marsh, H. W., L?dtke, O., Nagengast, B., Trautwein, U., Morin, A. J. S., Abduljabbar, A. S., & K?ller, O. (2012). Classroom climate and contextual effects: Conceptual and methodological issues in the evaluation of group-level effects. Educational Psychologist, 47(2), 106-124. doi: 10.1080/00461520.2012.670488

Meade, A. W., & Eby, L. T. (2007). Using indices of group agreement in multilevel construct validation. Organizational Research Methods, 10(1), 75-96. doi: 10.1177/1094428106289390

Roberson, Q. M., Sturman, M. C., & Simons, T. L. (2007). Does the measure of dispersion matter in multilevel research? A comparison of the relative performance of dispersion indexes. Organizational Research Methods, 10(4), 564-588. doi: 10.1177/1094428106294746

van Mierlo, H., Vermunt, J. K., & Rutte, C. G. (2009). Composing group-level constructs from individual-level survey data. Organizational Research Methods, 12(2), 368-392. doi: 10.1177/1094428107309322



Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Paul Johnson [mailto:pauljohn32 at gmail.com] 
Sent: Monday, June 29, 2015 3:35 PM
To: R-SIG-Mixed-Models at r-project.org
Subject: [R-sig-ME] constructed level 2 predictors/random effects

I see people wanting to average survey responses to manufacture
contextual variables. They just take the average of individual level
scores and treat it as if it were context.  Or in studies of
education, they average class Socio Economic or religious variables
and use the means for context.   Have you ever seen R packages that
try to facilitate this kind of work?

I am thinking about problems like this.

1. Can we account for the standard error of the mean at the group
level?  Will the come back to "not with lme4, but the old lme had
varIdent for weights?"

Of course, if there is 1 or 2 people within a cluster, and 50 in
another, we'd have an especially big reason to try to fix this.

2. It seems to me they should calculate a "leave one out" estimate for
each row, excluding that case's impact on the group-level average.

I'm thinking about the education studies that want to both create mean
SES as a predictor, and then look at individual variations against
that predictor.  If there are 100 people within each classroom, I
don't guess it matters.  But sometimes they have 2 or 5 people within
each group.

3. They are using raw averages, not pooled estimates for these
constructed level 2 variables.  It looks to me like we ought to fit a
multi level model on those variables, using the group as a random
effect. Then take the BLUPs as estimates of the context.  Otherwise,
these means at the group level are just as inefficent as the
one-regression-per group approach.

Even if you don't know of R work on this, I'd appreciate any pointers
to literature or such.

-- 
Paul E. Johnson
Professor, Political Science       Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://crmda.ku.edu


