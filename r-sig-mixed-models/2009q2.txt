From r.turner at auckland.ac.nz  Wed Apr  1 01:31:11 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 1 Apr 2009 12:31:11 +1300
Subject: [R-sig-ME] Puzzled by simple example.
Message-ID: <D82F7938-6C25-40B2-A935-D39D9B0D46E5@auckland.ac.nz>


I continue to struggle to understand the syntax of lmer() from the  
lme4 package.

In an attempt to enlighten myself I simulated a rather simple data  
set.  The
imagined scenario is children's heights (in cm.) at ages 4, 5, 6, and  
7, although
no attempt has been made to make the data realistic.

Since the data are balanced, I thought I could check/compare the lmer 
() results
with results produced by aov().

The code I used is as follows:

#
# Script scr.01
#

# Generate the data.  No attempt is made to make these
# data realistic.
set.seed(42)
Beta <- c(40,50,60,70)
B  <- rnorm(80,0,2)
E  <- rnorm(80,0,0.25)
Y  <- Beta + B + E
ht.dat <- data.frame(y=Y,age=factor(rep(4:7,20)),child=factor(rep 
(1:20,each=4)))

# Fit with lmer():
f1 <- lmer(y ~ 0 + age + (1|child),data=ht.dat)

# Fit with aov():
f2 <- aov(y ~ 0 + age + Error(child),data=ht.dat)

# Clean up:
rm(Beta,B,E,Y)

When one does summary(f1) one gets values of the estimates of the  
mean heights
which are very close to the ``true'' values used to generate the  
data.  I am however
puzzled by the random effects estimates.  These are:

Random effects:
  Groups   Name        Variance   Std.Dev.
  child    (Intercept) 1.0362e-07 0.0003219
  Residual             4.6663e+00 2.1601657
Number of obs: 80, groups: child, 20

I thought at the ``child'' variance would be around 4 (the variance
used to simulate B) and that the residual variance would be around  
0.0625
(the variance used to simulate E).  This is clearly not so, so there is
clearly something I am misunderstanding here.  I am not interpreting the
random effects results correctly.  Can someone please point me in the
right direction?

In particular, how can I extract estimates of the variance of B and E?

I am assuming that the model I am fitting in both instances is

	y = X*Beta + Z*B + E

where X = kronecker(One_20,I_4) and Z = kronecker(I_20,One_4), where  
I_k is the
k-x-k identity and One_k is a k-x-1 matrix all of whose entries are 1.
Have I got this much right?  (In the forgoing Beta is a 4-vector of  
fixed effects
and B is a 20-vector of random effects.)

I am even more puzzled by the results of aov() --- I cannot connect  
anything
with anything from these results.  Where/how do I obtain estimates of  
the
variance of B and the variance of E?  Where/how do I obtain estimates  
of the
fixed effects?

If I do coeff(f2) I get

child :
     age4
220.0565

Within :
      age4      age5      age6
-29.86516 -20.91547 -11.09382

The ``Within'' coefficients are the differences age4 - age7, age5 -  
age7, age6 - age7,
respectively.  I don't understand the ``child'' coefficient (age4 =  
220.0565) at all.
Can anyone explain this to me?

One other puzzlement:  If one just types ``f2'' or ``print(f2)'' one  
gets messages,
for stratum 1 (child) ``3 out of 4 effects not estimable / Estimable  
effects are
balanced'', and for stratum 2 (Within) ``1 out of 4 effects not  
estimable / Estimated
effects may be unbalanced''  Huh?  What is going on?  How could a  
design possibly
be more balanced?

I would be grateful for some enlightenment.

	cheers,

		Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From sdorairaj at gmail.com  Wed Apr  1 02:24:08 2009
From: sdorairaj at gmail.com (Sundar Dorai-Raj)
Date: Tue, 31 Mar 2009 17:24:08 -0700
Subject: [R-sig-ME] Puzzled by simple example.
In-Reply-To: <D82F7938-6C25-40B2-A935-D39D9B0D46E5@auckland.ac.nz>
References: <D82F7938-6C25-40B2-A935-D39D9B0D46E5@auckland.ac.nz>
Message-ID: <c9ce82b00903311724n39b2ab2cv5250e4e98541fbbe@mail.gmail.com>

Hi, Rolf,

Sorry, but I can't absorb all your commentary below, but the
fundamental problem I believe is your simulation is not reflected by
the model you are fitting with lmer (also, I don't use aov so I won't
comment there). Here's the simulation you want, which I hope will show
you what lmer is fitting:

set.seed(42)
Beta <- c(40,50,60,70)
B  <- rnorm(20,0,2) ### note that length(B) = 20
E  <- rnorm(80,0,0.25)
ht.dat <- data.frame(age=factor(rep(4:7,20)),child=factor(rep(1:20,each=4)))
ht.dat$y <- with(ht.dat, Beta[age] + B[child] + E)

library(lme4)
# Fit with lmer():
f1 <- lmer(y ~ 0 + age + (1|child),data=ht.dat)

summary(f1)
<snip>
Random effects:
 Groups   Name        Variance Std.Dev.
 child    (Intercept) 6.888065 2.62451
 Residual             0.063592 0.25218
</snip>

HTH,

--sundar
On Tue, Mar 31, 2009 at 4:31 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> I continue to struggle to understand the syntax of lmer() from the lme4
> package.
>
> In an attempt to enlighten myself I simulated a rather simple data set. ?The
> imagined scenario is children's heights (in cm.) at ages 4, 5, 6, and 7,
> although
> no attempt has been made to make the data realistic.
>
> Since the data are balanced, I thought I could check/compare the lmer()
> results
> with results produced by aov().
>
> The code I used is as follows:
>
> #
> # Script scr.01
> #
>
> # Generate the data. ?No attempt is made to make these
> # data realistic.
> set.seed(42)
> Beta <- c(40,50,60,70)
> B ?<- rnorm(80,0,2)
> E ?<- rnorm(80,0,0.25)
> Y ?<- Beta + B + E
> ht.dat <-
> data.frame(y=Y,age=factor(rep(4:7,20)),child=factor(rep(1:20,each=4)))
>
> # Fit with lmer():
> f1 <- lmer(y ~ 0 + age + (1|child),data=ht.dat)
>
> # Fit with aov():
> f2 <- aov(y ~ 0 + age + Error(child),data=ht.dat)
>
> # Clean up:
> rm(Beta,B,E,Y)
>
> When one does summary(f1) one gets values of the estimates of the mean
> heights
> which are very close to the ``true'' values used to generate the data. ?I am
> however
> puzzled by the random effects estimates. ?These are:
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?child ? ?(Intercept) 1.0362e-07 0.0003219
> ?Residual ? ? ? ? ? ? 4.6663e+00 2.1601657
> Number of obs: 80, groups: child, 20
>
> I thought at the ``child'' variance would be around 4 (the variance
> used to simulate B) and that the residual variance would be around 0.0625
> (the variance used to simulate E). ?This is clearly not so, so there is
> clearly something I am misunderstanding here. ?I am not interpreting the
> random effects results correctly. ?Can someone please point me in the
> right direction?
>
> In particular, how can I extract estimates of the variance of B and E?
>
> I am assuming that the model I am fitting in both instances is
>
> ? ? ? ?y = X*Beta + Z*B + E
>
> where X = kronecker(One_20,I_4) and Z = kronecker(I_20,One_4), where I_k is
> the
> k-x-k identity and One_k is a k-x-1 matrix all of whose entries are 1.
> Have I got this much right? ?(In the forgoing Beta is a 4-vector of fixed
> effects
> and B is a 20-vector of random effects.)
>
> I am even more puzzled by the results of aov() --- I cannot connect anything
> with anything from these results. ?Where/how do I obtain estimates of the
> variance of B and the variance of E? ?Where/how do I obtain estimates of the
> fixed effects?
>
> If I do coeff(f2) I get
>
> child :
> ? ?age4
> 220.0565
>
> Within :
> ? ? age4 ? ? ?age5 ? ? ?age6
> -29.86516 -20.91547 -11.09382
>
> The ``Within'' coefficients are the differences age4 - age7, age5 - age7,
> age6 - age7,
> respectively. ?I don't understand the ``child'' coefficient (age4 =
> 220.0565) at all.
> Can anyone explain this to me?
>
> One other puzzlement: ?If one just types ``f2'' or ``print(f2)'' one gets
> messages,
> for stratum 1 (child) ``3 out of 4 effects not estimable / Estimable effects
> are
> balanced'', and for stratum 2 (Within) ``1 out of 4 effects not estimable /
> Estimated
> effects may be unbalanced'' ?Huh? ?What is going on? ?How could a design
> possibly
> be more balanced?
>
> I would be grateful for some enlightenment.
>
> ? ? ? ?cheers,
>
> ? ? ? ? ? ? ? ?Rolf Turner
>
> ######################################################################
> Attention:\ This e-mail message is privileged and confid...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From r.turner at auckland.ac.nz  Wed Apr  1 02:28:47 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 1 Apr 2009 13:28:47 +1300
Subject: [R-sig-ME] Puzzled by simple example.
In-Reply-To: <49D2A9EA.9020308@oakland.edu>
References: <D82F7938-6C25-40B2-A935-D39D9B0D46E5@auckland.ac.nz>
	<49D2A9EA.9020308@oakland.edu>
Message-ID: <45B31E58-503F-45D2-A842-13701466B97E@auckland.ac.nz>


On 1/04/2009, at 12:40 PM, Robert Kushler wrote:

> You need
>
>     B <- rep(rnorm(20,0,2),each=4)
>
> (the "child effect" should be the same for all four ages).

	Right.  That was a bit of duhhhhh, wasn't it?

	Anyhow --- I fixed that, and now the lmer() results
	make sense.  I get a standard deviation of 2.62 for
	the child effect (close enuff!) and 0.25 for the residual
	effect (bang on!).

	I still cannot make head or tail of the aov results however.

	Is my call to aov() correct?  I'm still getting the ``Estimated
	effects may be unbalanced'', usw, messages.

		 cheers,

			Rolf Turner

> I'm generally skeptical of forcing the intercept to be zero,
> but it's not illegal.   :-)
>
> Regards,   Rob Kushler
>
> Rolf Turner wrote:
>>
>> I continue to struggle to understand the syntax of lmer() from the  
>> lme4
>> package.
>>
>> In an attempt to enlighten myself I simulated a rather simple data  
>> set.
>> The
>> imagined scenario is children's heights (in cm.) at ages 4, 5, 6,  
>> and 7,
>> although
>> no attempt has been made to make the data realistic.
>>
>> Since the data are balanced, I thought I could check/compare the  
>> lmer()
>> results
>> with results produced by aov().
>>
>> The code I used is as follows:
>>
>> #
>> # Script scr.01
>> #
>>
>> # Generate the data.  No attempt is made to make these
>> # data realistic.
>> set.seed(42)
>> Beta <- c(40,50,60,70)
>> B  <- rnorm(80,0,2)
>> E  <- rnorm(80,0,0.25)
>> Y  <- Beta + B + E
>> ht.dat <-
>> data.frame(y=Y,age=factor(rep(4:7,20)),child=factor(rep 
>> (1:20,each=4)))
>>
>> # Fit with lmer():
>> f1 <- lmer(y ~ 0 + age + (1|child),data=ht.dat)
>>
>> # Fit with aov():
>> f2 <- aov(y ~ 0 + age + Error(child),data=ht.dat)
>>
>> # Clean up:
>> rm(Beta,B,E,Y)
>>
>> When one does summary(f1) one gets values of the estimates of the  
>> mean
>> heights
>> which are very close to the ``true'' values used to generate the  
>> data.
>> I am however
>> puzzled by the random effects estimates.  These are:
>>
>> Random effects:
>>  Groups   Name        Variance   Std.Dev.
>>  child    (Intercept) 1.0362e-07 0.0003219
>>  Residual             4.6663e+00 2.1601657
>> Number of obs: 80, groups: child, 20
>>
>> I thought at the ``child'' variance would be around 4 (the variance
>> used to simulate B) and that the residual variance would be around  
>> 0.0625
>> (the variance used to simulate E).  This is clearly not so, so  
>> there is
>> clearly something I am misunderstanding here.  I am not  
>> interpreting the
>> random effects results correctly.  Can someone please point me in the
>> right direction?
>>
>> In particular, how can I extract estimates of the variance of B  
>> and E?
>>
>> I am assuming that the model I am fitting in both instances is
>>
>>     y = X*Beta + Z*B + E
>>
>> where X = kronecker(One_20,I_4) and Z = kronecker(I_20,One_4),  
>> where I_k
>> is the
>> k-x-k identity and One_k is a k-x-1 matrix all of whose entries  
>> are 1.
>> Have I got this much right?  (In the forgoing Beta is a 4-vector of
>> fixed effects
>> and B is a 20-vector of random effects.)
>>
>> I am even more puzzled by the results of aov() --- I cannot connect
>> anything
>> with anything from these results.  Where/how do I obtain estimates  
>> of the
>> variance of B and the variance of E?  Where/how do I obtain  
>> estimates of
>> the
>> fixed effects?
>>
>> If I do coeff(f2) I get
>>
>> child :
>>     age4
>> 220.0565
>>
>> Within :
>>      age4      age5      age6
>> -29.86516 -20.91547 -11.09382
>>
>> The ``Within'' coefficients are the differences age4 - age7, age5 -
>> age7, age6 - age7,
>> respectively.  I don't understand the ``child'' coefficient (age4 =
>> 220.0565) at all.
>> Can anyone explain this to me?
>>
>> One other puzzlement:  If one just types ``f2'' or ``print(f2)'' one
>> gets messages,
>> for stratum 1 (child) ``3 out of 4 effects not estimable / Estimable
>> effects are
>> balanced'', and for stratum 2 (Within) ``1 out of 4 effects not
>> estimable / Estimated
>> effects may be unbalanced''  Huh?  What is going on?  How could a  
>> design
>> possibly
>> be more balanced?
>>
>> I would be grateful for some enlightenment.
>>
>>     cheers,
>>
>>         Rolf Turner
>>
>> ##################################################################### 
>> #
>> Attention:\ This e-mail message is privileged and confid... 
>> {{dropped:9}}
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From smckinney at bccrc.ca  Wed Apr  1 02:39:22 2009
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 31 Mar 2009 17:39:22 -0700
Subject: [R-sig-ME] Puzzled by simple example.
In-Reply-To: <6490_1238542396_1238542396_D82F7938-6C25-40B2-A935-D39D9B0D46E5@auckland.ac.nz>
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB01D5023A@crcmail1.BCCRC.CA>


Hi Rolf, 

Quick observation in-line below

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Rolf Turner
> Sent: Tuesday, March 31, 2009 4:31 PM
> To: R-Sig Mixed-models
> Subject: [R-sig-ME] Puzzled by simple example.
> 
> 
> I continue to struggle to understand the syntax of lmer() from the
> lme4 package.
> 
> In an attempt to enlighten myself I simulated a rather simple data
> set.  The
> imagined scenario is children's heights (in cm.) at ages 4, 5, 6, and
> 7, although
> no attempt has been made to make the data realistic.
> 
> Since the data are balanced, I thought I could check/compare the lmer
> () results
> with results produced by aov().
> 
> The code I used is as follows:
> 
> #
> # Script scr.01
> #
> 
> # Generate the data.  No attempt is made to make these
> # data realistic.
> set.seed(42)
> Beta <- c(40,50,60,70)
> B  <- rnorm(80,0,2)
> E  <- rnorm(80,0,0.25)
> Y  <- Beta + B + E

This does not appear to contain a random effects component.
This just looks like average height data with two independent
gaussian rv's added as noise (so in essence it's just an rnorm(80, 0,
sqrt(4.0625)) random error).  This model should only need 20
rnorm errors at the child level.  So it's a matter of getting
this model data constructed appropriately according to what
you outline below.  I'll try to get this done and post it,
but you or someone else may get there before I have time.

As I see it, this is why aov() is choking - there's no different
error structure at the whole child level.

Also note the following from the aov() help page
" The default 'contrasts' in R are not orthogonal contrasts, and aov and
its helper functions will work better with such contrasts: see the
examples for how to select these. "

so you might need to set orthog contrasts first
## Set orthogonal contrasts.
op <- options(contrasts=c("contr.helmert", "contr.poly"))

HTH

Steve McKinney


> ht.dat <- data.frame(y=Y,age=factor(rep(4:7,20)),child=factor(rep
> (1:20,each=4)))
> 
> # Fit with lmer():
> f1 <- lmer(y ~ 0 + age + (1|child),data=ht.dat)
> 
> # Fit with aov():
> f2 <- aov(y ~ 0 + age + Error(child),data=ht.dat)
> 
> # Clean up:
> rm(Beta,B,E,Y)
> 
> When one does summary(f1) one gets values of the estimates of the
> mean heights
> which are very close to the ``true'' values used to generate the
> data.  I am however
> puzzled by the random effects estimates.  These are:
> 
> Random effects:
>   Groups   Name        Variance   Std.Dev.
>   child    (Intercept) 1.0362e-07 0.0003219
>   Residual             4.6663e+00 2.1601657
> Number of obs: 80, groups: child, 20
> 
> I thought at the ``child'' variance would be around 4 (the variance
> used to simulate B) and that the residual variance would be around
> 0.0625
> (the variance used to simulate E).  This is clearly not so, so there
is
> clearly something I am misunderstanding here.  I am not interpreting
the
> random effects results correctly.  Can someone please point me in the
> right direction?
> 
> In particular, how can I extract estimates of the variance of B and E?
> 
> I am assuming that the model I am fitting in both instances is
> 
> 	y = X*Beta + Z*B + E
> 
> where X = kronecker(One_20,I_4) and Z = kronecker(I_20,One_4), where
> I_k is the
> k-x-k identity and One_k is a k-x-1 matrix all of whose entries are 1.
> Have I got this much right?  (In the forgoing Beta is a 4-vector of
> fixed effects
> and B is a 20-vector of random effects.)
> 
> I am even more puzzled by the results of aov() --- I cannot connect
> anything
> with anything from these results.  Where/how do I obtain estimates of
> the
> variance of B and the variance of E?  Where/how do I obtain estimates
> of the
> fixed effects?
> 
> If I do coeff(f2) I get
> 
> child :
>      age4
> 220.0565
> 
> Within :
>       age4      age5      age6
> -29.86516 -20.91547 -11.09382
> 
> The ``Within'' coefficients are the differences age4 - age7, age5 -
> age7, age6 - age7,
> respectively.  I don't understand the ``child'' coefficient (age4 =
> 220.0565) at all.
> Can anyone explain this to me?
> 
> One other puzzlement:  If one just types ``f2'' or ``print(f2)'' one
> gets messages,
> for stratum 1 (child) ``3 out of 4 effects not estimable / Estimable
> effects are
> balanced'', and for stratum 2 (Within) ``1 out of 4 effects not
> estimable / Estimated
> effects may be unbalanced''  Huh?  What is going on?  How could a
> design possibly
> be more balanced?
> 
> I would be grateful for some enlightenment.
> 
> 	cheers,
> 
> 		Rolf Turner
> 
> ######################################################################
> Attention:\ This e-mail message is privileged and
confid...{{dropped:9}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From chenlei at ibcas.ac.cn  Wed Apr  1 04:04:16 2009
From: chenlei at ibcas.ac.cn (=?gb2312?B?Y2hlbmxlaQ==?=)
Date: Wed, 1 Apr 2009 10:04:16 +0800 (CST)
Subject: [R-sig-ME] =?gb2312?b?bW9kZWxsaW5nIGEgbmVzdGVkIHN0dWRlbnQtc2No?=
 =?gb2312?b?b29sLWRpc3RyaWN0IG1vZGVs?=
Message-ID: <49D2CBA0.00000B.13528@app-03>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090401/c7b5146f/attachment.pl>

From vinod at fordham.edu  Wed Apr  1 01:51:01 2009
From: vinod at fordham.edu (HRISHIKESH D. VINOD)
Date: Tue, 31 Mar 2009 19:51:01 -0400
Subject: [R-sig-ME] R-conf. New York City, June 18-19, 2009,
 contribute your mixed-model R functions
Message-ID: <OF7010B95F.EA6D0CF7-ON8525758A.008303B3-8525758A.008303B6@fordham.edu>


Hi
I believe that following info is of interest to your special interest group
since we welcome presentation of ideas (R-functions) dealing with
mixed models which are often used in social sciences.

Conference on Quantitative Social Science Research Using R

June 18-19 (Thursday-Friday), 2009, Fordham University, 113 West 60th
Street, New York, NY. (next door to the Lincoln Center for Performing
Arts).

Conference website: http://www.cis.fordham.edu/QR2009

The conference offers opportunity to enthusiastic users of R (software and
Graphics system) to important policy and research problems in social
sciences to learn, meet and mingle.
1) Speakers include authors of books and /or packages for R, published
researchers and editors of important journals in Statistics and social
sciences: Andrew Gelman (Columbia), Kosuke Imai (Princeton), Roger Koenker
(Illinois), Keith A. Markus (Columbia), Bruce D. McCullough (Drexel), H. D.
Vinod (Fordham), Achim Zeileis (Vienna)?
2) The proceedings book will be published by Springer (publisher of Use R!
series) in 2009.
3) Opportunity to present Replication / extension of published papers using
R, poster session
4) Opportunity to present new useful R functions (including teaching
material) poster session
5) A tutorial cum refresher session teaching R will be given and useful





Hrishikesh (Rick) D. Vinod
Professor of Economics, Fordham University
E-Mail: Vinod at fordham.edu  Tel 718-817-4065,
Secretary 718-817-4048, Fax 718-817-3518
Web page:  http://www.fordham.edu/economics/vinod



From Herve.Chapuis at tours.inra.fr  Wed Apr  1 18:08:00 2009
From: Herve.Chapuis at tours.inra.fr (=?ISO-8859-1?Q?Herv=E9_CHAPUIS?=)
Date: Wed, 01 Apr 2009 18:08:00 +0200
Subject: [R-sig-ME] glmer vs. MCMCglmm
Message-ID: <49D39160.4000202@tours.inra.fr>

Hi everyone,

Hope my questionsare  not too stupid,  as I could easily be defined as a 
Bayesian dummy.
I intend to estimate the genetic variance for a binary trait (disease 
resistance) in a simulated population.
First, I have used lmer and glmer.  However, sometimes I have false 
convergences, and  I can't specify "nAGQ=5" when fitting two random 
effects (sire AND dam).
This is the reason why I have decided to give a glimpse at MCMCglmm.
Well, what can I do when I have this kind of error message :

"Erreur dans MCMCglmm(Y ~ 1, random = ~PERE, family = "categorical", 
data = PERF) :
  ill-conditioned G/R structure: use proper priors if you haven't or 
rescale data if you have". ???

How to specify proper priors ? If I have a binary trait, the residual 
variance can't be estimated, so that  it has to be fixed, isn't it ? 
unless I use a proper prior.

In another design, I obtain results, but the sampled sire variance far 
exceeds the parameter space boundaries, leading to  an abnormaly  high 
heritability coefficient (above 1). The glmer estimate, on the other 
hand, is much in adequation with the expected value.

I am still trying to implement an animal model as specified in the 
MCMCglmm manual, but I can't figure out how an heritability can be 
estimated so high without a big mistake. But I can't see it.
 
Any help will be greatly appreciated.

Thanks.

-- 
Cordialement, 


Herv? CHAPUIS
SYSAAF
Station de Recherches Avicoles
37380 NOUZILLY

tel : 02 47 42 76 77
fax : 02 47 42 76 46



From rogic at bioinformatics.ubc.ca  Wed Apr  1 20:44:29 2009
From: rogic at bioinformatics.ubc.ca (Sanja Rogic)
Date: Wed, 1 Apr 2009 11:44:29 -0700
Subject: [R-sig-ME] Help with lme modelling
Message-ID: <b376d07b0904011144j25c8e1d8r5b93f1f6d2eacef@mail.gmail.com>

I would like to apologize in advance if this is not the right forum
for posting this message, since I am using nlme instead of lme4
package, but it seamed to me that this is the best place for Mixed
Effects Models (MEM) questions.

I've recently started using MEM for the differential expression
analysis of genes in cases where I want to analyze compatible datasets
from different experiments/labs (modelling labs as random effects). I
was pretty happy with the results since MEM allows for direct use of
raw expression data, unlike some other meta-analysis approaches and
thus seem to be more sensitive.

However, I discovered several cases where MEM failed to make correct
predictions and I would like to find a way to automatically detect
these in the future (I am doing the analysis on thousands of genes so
it is not feasible to graphically inspect the quality of a model fit
for each one separately).

Here is an example:

#data frame

> data
          expr.val   lab treatment   age
X1        4.751217     A       sal   old
X2        4.660610     A       sal   old
X3        4.810334     A       sal   old
X4        5.235475     A        KA   old
X5        5.414665     A        KA   old
X6        4.451858     A        KA   old
X7        4.812522     A       sal young
X8        6.346419     A       sal young
X9        5.267596     A       sal young
X10       3.823031     A        KA young
X11       3.619814     A        KA young
X12       3.539568     A        KA young
X13       5.671991     B       sal   old
X14       5.715370     B       sal   old
X15       5.694324     B       sal   old
X16       5.457560     B        KA   old
X17       5.454112     B        KA   old
X18       5.430781     B        KA   old

As you can see the data comes from two labs, A and B, there are two
treatments, KA and sal, and the effect of these is my main interest
and there are also two age groups.

Fitting linear MEM (I expect some interaction between two fixed
effects, treatment and age):

> data.lme<- lme(expr.val~treatment*age,data=data,random=~1|lab)

> summary(data.lme)
Linear mixed-effects model fit by REML
 Data: m
       AIC      BIC    logLik
  33.76913 37.60347 -10.88456

Random effects:
 Formula: ~1 | Study
        (Intercept)  Residual
StdDev:   0.4553264 0.3960901

Fixed effects: E ~ Treatment * Age
                          Value Std.Error DF   t-value p-value
(Intercept)            5.240742 0.3602901 13 14.545894  0.0000
Treatmentsal          -0.023434 0.2286827 13 -0.102475  0.9199
Ageyoung              -1.276539 0.3000890 13 -4.253867  0.0009
Treatmentsal:Ageyoung  1.838143 0.3960901 13  4.640719  0.0005
 Correlation:
                      (Intr) Trtmnt Ageyng
Treatmentsal          -0.317
Ageyoung              -0.242  0.381
Treatmentsal:Ageyoung  0.183 -0.577 -0.660

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.6738372 -0.3845786 -0.2229425  0.4311380  2.1987599

Number of Observations: 18
Number of Groups: 2

> anova(data.lme)
              numDF denDF   F-value p-value
(Intercept)       1    13 232.76945  <.0001
Treatment         1    13   9.96020  0.0076
Age               1    13   2.51385  0.1369
Treatment:Age     1    13  21.53627  0.0005




What I do when automatically analyzing all the genes is to look at the
p-value from anova function to assess the significance of Treatment
effect and at the sign of estimated parameter (Treatmentsal) from the
summary function to decide on the direction of change (is it more
expressed after sal or KA treatment). In the above example the results
indicate that Treatment has significant effect and that there is more
expression for KA effect (Treatmentsal=-0.023434). However, when I
plot the raw data and superimpose the fitted values it is obvious that
the fit is not good for KA-old datapoints and this is probably caused
by contradictory data wrt to treatment effect between the two labs
(sal<KA for A and sal>KA for B).

My questions are:

1. How is the F-value in  anova function computed? I would like to
understand why I got such a small value when data is contradictory.

2. The Treatmentsal value seems to correspond only to the age=old
(change from a baseline treatment=KA, age=old). How do I compute the
Treatmentsal value for both age groups?

3. In general, what functions/parameters can I used in automated way
to decide if there is a significant effect of, for example, treatment
KA?

Sorry for the lengthy post and superficial understanding of how MEM
work (not much background in statistics). I would very much appreciate
any help on these issues.

Cheers,
Sanja Rogic



From lborger at uoguelph.ca  Wed Apr  1 21:15:57 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 1 Apr 2009 15:15:57 -0400
Subject: [R-sig-ME] Help with lme modelling
References: <b376d07b0904011144j25c8e1d8r5b93f1f6d2eacef@mail.gmail.com>
Message-ID: <90B2DB1F9D9C4B95913B32AE597BFD43@lborger>

Hello,

this doesn't directly answer your questions, but you have got only two
levels for your random effect (i.e. two labs). It is not advisable to fit
mixed effect models with only two levels of the grouping factor (you should
have at least 5 - 6 or so), as the variances can not be reliably estimated.
There have been posts by Prof Bates on this issue, you can find them in the
archives. Thus, you might consider lm models (or gls()), e.g. with lab as
block factor?


HTH


Cheers,

Luca


----- Original Message ----- 
From: "Sanja Rogic" <rogic at bioinformatics.ubc.ca>
To: <r-sig-mixed-models at r-project.org>
Sent: Wednesday, April 01, 2009 2:44 PM
Subject: [R-sig-ME] Help with lme modelling


>I would like to apologize in advance if this is not the right forum
> for posting this message, since I am using nlme instead of lme4
> package, but it seamed to me that this is the best place for Mixed
> Effects Models (MEM) questions.
>
> I've recently started using MEM for the differential expression
> analysis of genes in cases where I want to analyze compatible datasets
> from different experiments/labs (modelling labs as random effects). I
> was pretty happy with the results since MEM allows for direct use of
> raw expression data, unlike some other meta-analysis approaches and
> thus seem to be more sensitive.
>
> However, I discovered several cases where MEM failed to make correct
> predictions and I would like to find a way to automatically detect
> these in the future (I am doing the analysis on thousands of genes so
> it is not feasible to graphically inspect the quality of a model fit
> for each one separately).
>
> Here is an example:
>
> #data frame
>
>> data
>          expr.val   lab treatment   age
> X1        4.751217     A       sal   old
> X2        4.660610     A       sal   old
> X3        4.810334     A       sal   old
> X4        5.235475     A        KA   old
> X5        5.414665     A        KA   old
> X6        4.451858     A        KA   old
> X7        4.812522     A       sal young
> X8        6.346419     A       sal young
> X9        5.267596     A       sal young
> X10       3.823031     A        KA young
> X11       3.619814     A        KA young
> X12       3.539568     A        KA young
> X13       5.671991     B       sal   old
> X14       5.715370     B       sal   old
> X15       5.694324     B       sal   old
> X16       5.457560     B        KA   old
> X17       5.454112     B        KA   old
> X18       5.430781     B        KA   old
>
> As you can see the data comes from two labs, A and B, there are two
> treatments, KA and sal, and the effect of these is my main interest
> and there are also two age groups.
>
> Fitting linear MEM (I expect some interaction between two fixed
> effects, treatment and age):
>
>> data.lme<- lme(expr.val~treatment*age,data=data,random=~1|lab)
>
>> summary(data.lme)
> Linear mixed-effects model fit by REML
> Data: m
>       AIC      BIC    logLik
>  33.76913 37.60347 -10.88456
>
> Random effects:
> Formula: ~1 | Study
>        (Intercept)  Residual
> StdDev:   0.4553264 0.3960901
>
> Fixed effects: E ~ Treatment * Age
>                          Value Std.Error DF   t-value p-value
> (Intercept)            5.240742 0.3602901 13 14.545894  0.0000
> Treatmentsal          -0.023434 0.2286827 13 -0.102475  0.9199
> Ageyoung              -1.276539 0.3000890 13 -4.253867  0.0009
> Treatmentsal:Ageyoung  1.838143 0.3960901 13  4.640719  0.0005
> Correlation:
>                      (Intr) Trtmnt Ageyng
> Treatmentsal          -0.317
> Ageyoung              -0.242  0.381
> Treatmentsal:Ageyoung  0.183 -0.577 -0.660
>
> Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
> -1.6738372 -0.3845786 -0.2229425  0.4311380  2.1987599
>
> Number of Observations: 18
> Number of Groups: 2
>
>> anova(data.lme)
>              numDF denDF   F-value p-value
> (Intercept)       1    13 232.76945  <.0001
> Treatment         1    13   9.96020  0.0076
> Age               1    13   2.51385  0.1369
> Treatment:Age     1    13  21.53627  0.0005
>
>
>
>
> What I do when automatically analyzing all the genes is to look at the
> p-value from anova function to assess the significance of Treatment
> effect and at the sign of estimated parameter (Treatmentsal) from the
> summary function to decide on the direction of change (is it more
> expressed after sal or KA treatment). In the above example the results
> indicate that Treatment has significant effect and that there is more
> expression for KA effect (Treatmentsal=-0.023434). However, when I
> plot the raw data and superimpose the fitted values it is obvious that
> the fit is not good for KA-old datapoints and this is probably caused
> by contradictory data wrt to treatment effect between the two labs
> (sal<KA for A and sal>KA for B).
>
> My questions are:
>
> 1. How is the F-value in  anova function computed? I would like to
> understand why I got such a small value when data is contradictory.
>
> 2. The Treatmentsal value seems to correspond only to the age=old
> (change from a baseline treatment=KA, age=old). How do I compute the
> Treatmentsal value for both age groups?
>
> 3. In general, what functions/parameters can I used in automated way
> to decide if there is a significant effect of, for example, treatment
> KA?
>
> Sorry for the lengthy post and superficial understanding of how MEM
> work (not much background in statistics). I would very much appreciate
> any help on these issues.
>
> Cheers,
> Sanja Rogic
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From charpent at bacbuc.dyndns.org  Wed Apr  1 22:24:50 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Wed, 01 Apr 2009 22:24:50 +0200
Subject: [R-sig-ME] Help with lme modelling
In-Reply-To: <b376d07b0904011144j25c8e1d8r5b93f1f6d2eacef@mail.gmail.com>
References: <b376d07b0904011144j25c8e1d8r5b93f1f6d2eacef@mail.gmail.com>
Message-ID: <1238617489.6134.58.camel@yod>

Dear Sanja,

Let's temporarily put aside the issue pointed by Luca Borger (see at
end).

Your (first) problem is that anova.lme gives you by default *sequential*
F-tests, i.e. the "(Intercept)" lines tests the "model enhancement" of
the "X=someconstant" model (n? 1) over the "X=0" model (n? 0), the
second line "treatment" tests the "X=someconstant
+someotherconstant*treatment" model (n? 2) against the previous one (n?
1), the "age" lines tests the "X=someconstant
+someotherconstant*treatment+yetanotherconstant*age" model (n? 3)
against n? 2 and the "age*treatment" line tests the "X=someconstant
+someotherconstant*treatment+yetanotherconstant*age
+onemoreonstant*treatment*age" model (n? 4) against n? 3.

What you probably expected was probably what was called an "Analysis of
variance table" in the "classical" sense, where each factor is tested
against the full model, i. e. testing model n? 4 minus the relevant
factor vs model n? 4 in full. anova.lme allows that :

> anova(lme(expr.val~treatment*age,data=Chapuis,random=~1|
lab),type="marginal")
              numDF denDF   F-value p-value
(Intercept)       1    13 211.58292  <.0001
treatment         1    13   0.01050  0.9199
age               1    13  18.09537  0.0009
treatment:age     1    13  21.53626  0.0005

However, there are some serious problems with this approach. You should
use RSiteSearch to find Bill Venable's reflections on linear regression
(I keep forgetting the exact title and address of this paper. Shame on
me....). I won't paraphrase it, but just look :
> options("contrasts")
$contrasts
        unordered           ordered 
"contr.treatment"      "contr.poly" 
# This is R default...

> anova(lme(expr.val~treatment*age,data=Chapuis,random=~1|
lab),type="marginal")
              numDF denDF   F-value p-value
(Intercept)       1    13 211.58292  <.0001
treatment         1    13   0.01050  0.9199
age               1    13  18.09537  0.0009
treatment:age     1    13  21.53626  0.0005
# We already saw that...

# Let's try to get the (in)famous so called "Type III sum of squares" so
# popularized by SAS
> options(contrasts=c("contr.helmert","contr.poly"))
# See Bill Venable's paper and/or V&R for explanations. This works...
# BUT :
> anova(lme(expr.val~treatment*age,data=Chapuis,random=~1|
lab),type="marginal")
              numDF denDF   F-value p-value
(Intercept)       1    13 219.17719  <.0001
treatment         1    13  20.45202  0.0006
age               1    13   2.51384  0.1369
treatment:age     1    13  21.53626  0.0005

Ouch : quite different results !

The point is : when you have an unbalanced design, the results
(estimates and F-values) for the main effects in an analysis including
interactions depend on the way your factors are (re-)coded. The
so-called "type III SS" attempt to give answers for an (imaginary)
population as unbalanced as your sample.

V&R argue (strongly, and rightly, IMHO) against the use of this
computational artifact, dating back to the time when such analyses were
batched on expensive computers.

They also argue (even more importantly) that the demonstration of the
existence of an interaction effect renders meaningless the question of
the research of "a global effect" for the main factors. They state that
they "have not het seen a situation where this made statistical sense".
THIS IS THE ROOT OF YOUR PROBLEMS.

What you can do is to search for an effect of one factor in each of the
subsamples defined by the second factor :

> options(contrasts=c("contr.treatment","contr.poly"))
> anova(lme(expr.val~treatment,data=Rogic,subset=age=="young",random=~1|
lab),type="marginal")
            numDF denDF  F-value p-value
(Intercept)     1     4 27.49423  0.0063
treatment       1     4 15.38910  0.0172
> anova(lme(expr.val~treatment,data=Rogic,subset=age=="old",random=~1|
lab),type="marginal")
            numDF denDF   F-value p-value
(Intercept)     1     9 221.97631  <.0001
treatment       1     9   0.01962  0.8917

# i. e. treatment effect can be demonstrated only in young
# Conversively :

> anova(lme(expr.val~age,data=Rogic,subset=treatment=="sal",random=~1|
lab),type="marginal")
            numDF denDF   F-value p-value
(Intercept)     1     6 119.84139  <.0001
age             1     6   3.26905  0.1206
> anova(lme(expr.val~age,data=Rogic,subset=treatment=="KA",random=~1|
lab),type="marginal")
            numDF denDF  F-value p-value
(Intercept)     1     6 642.5785  <.0001
age             1     6  36.7017   9e-04

# i. e. age effect can be demonstrated only when treatment is KA.

Note : I jumped directly to the ANOVA tables. This is bad : in your
case, the center "B" has only old subjects, and the second analysis
should have spit out a warning...

Note 2 : your initial analysis using default contrasts used "old" and
"KA" as base levels for their respective factors. You saw that the
treatment effect cannot be demonstrated at the base level for age (old,
in your case), that an age effect exists in subjects receiving the base
treatment (KA in your case), and that an interaction destroyed these
conclusions for the other levels. Same (qualitative) conclusions. The
p-value differ because (among other) the number of subjects used to
assess the variance differ.

Now for the number of levels of the random effect. If your experiment is
balanced, lme will go ahead and give you what a classical "mixed-effect
analysis of variance" (that you can get with aov()) gives. However, your
sampling plan is wildly unbalanced, and inter-group variance assessment
may be poor. I defer to more knowledgeable people's judgement, but I'd
tend to worry only if your "real" data were strongly unbalanced.

Hope this helps,

					Emmanuel Charpentier

Le mercredi 01 avril 2009 ? 11:44 -0700, Sanja Rogic a ?crit :
> I would like to apologize in advance if this is not the right forum
> for posting this message, since I am using nlme instead of lme4
> package, but it seamed to me that this is the best place for Mixed
> Effects Models (MEM) questions.
> 
> I've recently started using MEM for the differential expression
> analysis of genes in cases where I want to analyze compatible datasets
> from different experiments/labs (modelling labs as random effects). I
> was pretty happy with the results since MEM allows for direct use of
> raw expression data, unlike some other meta-analysis approaches and
> thus seem to be more sensitive.
> 
> However, I discovered several cases where MEM failed to make correct
> predictions and I would like to find a way to automatically detect
> these in the future (I am doing the analysis on thousands of genes so
> it is not feasible to graphically inspect the quality of a model fit
> for each one separately).
> 
> Here is an example:
> 
> #data frame
> 
> > data
>           expr.val   lab treatment   age
> X1        4.751217     A       sal   old
> X2        4.660610     A       sal   old
> X3        4.810334     A       sal   old
> X4        5.235475     A        KA   old
> X5        5.414665     A        KA   old
> X6        4.451858     A        KA   old
> X7        4.812522     A       sal young
> X8        6.346419     A       sal young
> X9        5.267596     A       sal young
> X10       3.823031     A        KA young
> X11       3.619814     A        KA young
> X12       3.539568     A        KA young
> X13       5.671991     B       sal   old
> X14       5.715370     B       sal   old
> X15       5.694324     B       sal   old
> X16       5.457560     B        KA   old
> X17       5.454112     B        KA   old
> X18       5.430781     B        KA   old
> 
> As you can see the data comes from two labs, A and B, there are two
> treatments, KA and sal, and the effect of these is my main interest
> and there are also two age groups.
> 
> Fitting linear MEM (I expect some interaction between two fixed
> effects, treatment and age):
> 
> > data.lme<- lme(expr.val~treatment*age,data=data,random=~1|lab)
> 
> > summary(data.lme)
> Linear mixed-effects model fit by REML
>  Data: m
>        AIC      BIC    logLik
>   33.76913 37.60347 -10.88456
> 
> Random effects:
>  Formula: ~1 | Study
>         (Intercept)  Residual
> StdDev:   0.4553264 0.3960901
> 
> Fixed effects: E ~ Treatment * Age
>                           Value Std.Error DF   t-value p-value
> (Intercept)            5.240742 0.3602901 13 14.545894  0.0000
> Treatmentsal          -0.023434 0.2286827 13 -0.102475  0.9199
> Ageyoung              -1.276539 0.3000890 13 -4.253867  0.0009
> Treatmentsal:Ageyoung  1.838143 0.3960901 13  4.640719  0.0005
>  Correlation:
>                       (Intr) Trtmnt Ageyng
> Treatmentsal          -0.317
> Ageyoung              -0.242  0.381
> Treatmentsal:Ageyoung  0.183 -0.577 -0.660
> 
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -1.6738372 -0.3845786 -0.2229425  0.4311380  2.1987599
> 
> Number of Observations: 18
> Number of Groups: 2
> 
> > anova(data.lme)
>               numDF denDF   F-value p-value
> (Intercept)       1    13 232.76945  <.0001
> Treatment         1    13   9.96020  0.0076
> Age               1    13   2.51385  0.1369
> Treatment:Age     1    13  21.53627  0.0005
> 
> 
> 
> 
> What I do when automatically analyzing all the genes is to look at the
> p-value from anova function to assess the significance of Treatment
> effect and at the sign of estimated parameter (Treatmentsal) from the
> summary function to decide on the direction of change (is it more
> expressed after sal or KA treatment). In the above example the results
> indicate that Treatment has significant effect and that there is more
> expression for KA effect (Treatmentsal=-0.023434). However, when I
> plot the raw data and superimpose the fitted values it is obvious that
> the fit is not good for KA-old datapoints and this is probably caused
> by contradictory data wrt to treatment effect between the two labs
> (sal<KA for A and sal>KA for B).
> 
> My questions are:
> 
> 1. How is the F-value in  anova function computed? I would like to
> understand why I got such a small value when data is contradictory.
> 
> 2. The Treatmentsal value seems to correspond only to the age=old
> (change from a baseline treatment=KA, age=old). How do I compute the
> Treatmentsal value for both age groups?
> 
> 3. In general, what functions/parameters can I used in automated way
> to decide if there is a significant effect of, for example, treatment
> KA?
> 
> Sorry for the lengthy post and superficial understanding of how MEM
> work (not much background in statistics). I would very much appreciate
> any help on these issues.
> 
> Cheers,
> Sanja Rogic
> 



From smckinney at bccrc.ca  Wed Apr  1 23:45:36 2009
From: smckinney at bccrc.ca (Steven McKinney)
Date: Wed, 1 Apr 2009 14:45:36 -0700
Subject: [R-sig-ME] Help with lme modelling
References: <b376d07b0904011144j25c8e1d8r5b93f1f6d2eacef@mail.gmail.com>
	<1963_1238618186_1238618186_1238617489.6134.58.camel@yod>
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB0328A68A@crcmail1.BCCRC.CA>


Bill Venables most sensible discussion of the issues
referred to by Emmanuel below is titled
"Exegeses on Linear Models"
and can be found at
http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

Steve McKinney

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org on behalf of Emmanuel Charpentier
Sent: Wed 4/1/2009 1:24 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Help with lme modelling
 
Dear Sanja,

Let's temporarily put aside the issue pointed by Luca Borger (see at
end).

Your (first) problem is that anova.lme gives you by default *sequential*
F-tests, i.e. the "(Intercept)" lines tests the "model enhancement" of
the "X=someconstant" model (n? 1) over the "X=0" model (n? 0), the
second line "treatment" tests the "X=someconstant
+someotherconstant*treatment" model (n? 2) against the previous one (n?
1), the "age" lines tests the "X=someconstant
+someotherconstant*treatment+yetanotherconstant*age" model (n? 3)
against n? 2 and the "age*treatment" line tests the "X=someconstant
+someotherconstant*treatment+yetanotherconstant*age
+onemoreonstant*treatment*age" model (n? 4) against n? 3.

What you probably expected was probably what was called an "Analysis of
variance table" in the "classical" sense, where each factor is tested
against the full model, i. e. testing model n? 4 minus the relevant
factor vs model n? 4 in full. anova.lme allows that :

> anova(lme(expr.val~treatment*age,data=Chapuis,random=~1|
lab),type="marginal")
              numDF denDF   F-value p-value
(Intercept)       1    13 211.58292  <.0001
treatment         1    13   0.01050  0.9199
age               1    13  18.09537  0.0009
treatment:age     1    13  21.53626  0.0005

However, there are some serious problems with this approach. You should
use RSiteSearch to find Bill Venable's reflections on linear regression
(I keep forgetting the exact title and address of this paper. Shame on
me....). I won't paraphrase it, but just look :
> options("contrasts")
$contrasts
        unordered           ordered 
"contr.treatment"      "contr.poly" 
# This is R default...

> anova(lme(expr.val~treatment*age,data=Chapuis,random=~1|
lab),type="marginal")
              numDF denDF   F-value p-value
(Intercept)       1    13 211.58292  <.0001
treatment         1    13   0.01050  0.9199
age               1    13  18.09537  0.0009
treatment:age     1    13  21.53626  0.0005
# We already saw that...

# Let's try to get the (in)famous so called "Type III sum of squares" so
# popularized by SAS
> options(contrasts=c("contr.helmert","contr.poly"))
# See Bill Venable's paper and/or V&R for explanations. This works...
# BUT :
> anova(lme(expr.val~treatment*age,data=Chapuis,random=~1|
lab),type="marginal")
              numDF denDF   F-value p-value
(Intercept)       1    13 219.17719  <.0001
treatment         1    13  20.45202  0.0006
age               1    13   2.51384  0.1369
treatment:age     1    13  21.53626  0.0005

Ouch : quite different results !

The point is : when you have an unbalanced design, the results
(estimates and F-values) for the main effects in an analysis including
interactions depend on the way your factors are (re-)coded. The
so-called "type III SS" attempt to give answers for an (imaginary)
population as unbalanced as your sample.

V&R argue (strongly, and rightly, IMHO) against the use of this
computational artifact, dating back to the time when such analyses were
batched on expensive computers.

They also argue (even more importantly) that the demonstration of the
existence of an interaction effect renders meaningless the question of
the research of "a global effect" for the main factors. They state that
they "have not het seen a situation where this made statistical sense".
THIS IS THE ROOT OF YOUR PROBLEMS.

What you can do is to search for an effect of one factor in each of the
subsamples defined by the second factor :

> options(contrasts=c("contr.treatment","contr.poly"))
> anova(lme(expr.val~treatment,data=Rogic,subset=age=="young",random=~1|
lab),type="marginal")
            numDF denDF  F-value p-value
(Intercept)     1     4 27.49423  0.0063
treatment       1     4 15.38910  0.0172
> anova(lme(expr.val~treatment,data=Rogic,subset=age=="old",random=~1|
lab),type="marginal")
            numDF denDF   F-value p-value
(Intercept)     1     9 221.97631  <.0001
treatment       1     9   0.01962  0.8917

# i. e. treatment effect can be demonstrated only in young
# Conversively :

> anova(lme(expr.val~age,data=Rogic,subset=treatment=="sal",random=~1|
lab),type="marginal")
            numDF denDF   F-value p-value
(Intercept)     1     6 119.84139  <.0001
age             1     6   3.26905  0.1206
> anova(lme(expr.val~age,data=Rogic,subset=treatment=="KA",random=~1|
lab),type="marginal")
            numDF denDF  F-value p-value
(Intercept)     1     6 642.5785  <.0001
age             1     6  36.7017   9e-04

# i. e. age effect can be demonstrated only when treatment is KA.

Note : I jumped directly to the ANOVA tables. This is bad : in your
case, the center "B" has only old subjects, and the second analysis
should have spit out a warning...

Note 2 : your initial analysis using default contrasts used "old" and
"KA" as base levels for their respective factors. You saw that the
treatment effect cannot be demonstrated at the base level for age (old,
in your case), that an age effect exists in subjects receiving the base
treatment (KA in your case), and that an interaction destroyed these
conclusions for the other levels. Same (qualitative) conclusions. The
p-value differ because (among other) the number of subjects used to
assess the variance differ.

Now for the number of levels of the random effect. If your experiment is
balanced, lme will go ahead and give you what a classical "mixed-effect
analysis of variance" (that you can get with aov()) gives. However, your
sampling plan is wildly unbalanced, and inter-group variance assessment
may be poor. I defer to more knowledgeable people's judgement, but I'd
tend to worry only if your "real" data were strongly unbalanced.

Hope this helps,

					Emmanuel Charpentier

Le mercredi 01 avril 2009 ? 11:44 -0700, Sanja Rogic a ?crit :
> I would like to apologize in advance if this is not the right forum
> for posting this message, since I am using nlme instead of lme4
> package, but it seamed to me that this is the best place for Mixed
> Effects Models (MEM) questions.
> 
> I've recently started using MEM for the differential expression
> analysis of genes in cases where I want to analyze compatible datasets
> from different experiments/labs (modelling labs as random effects). I
> was pretty happy with the results since MEM allows for direct use of
> raw expression data, unlike some other meta-analysis approaches and
> thus seem to be more sensitive.
> 
> However, I discovered several cases where MEM failed to make correct
> predictions and I would like to find a way to automatically detect
> these in the future (I am doing the analysis on thousands of genes so
> it is not feasible to graphically inspect the quality of a model fit
> for each one separately).
> 
> Here is an example:
> 
> #data frame
> 
> > data
>           expr.val   lab treatment   age
> X1        4.751217     A       sal   old
> X2        4.660610     A       sal   old
> X3        4.810334     A       sal   old
> X4        5.235475     A        KA   old
> X5        5.414665     A        KA   old
> X6        4.451858     A        KA   old
> X7        4.812522     A       sal young
> X8        6.346419     A       sal young
> X9        5.267596     A       sal young
> X10       3.823031     A        KA young
> X11       3.619814     A        KA young
> X12       3.539568     A        KA young
> X13       5.671991     B       sal   old
> X14       5.715370     B       sal   old
> X15       5.694324     B       sal   old
> X16       5.457560     B        KA   old
> X17       5.454112     B        KA   old
> X18       5.430781     B        KA   old
> 
> As you can see the data comes from two labs, A and B, there are two
> treatments, KA and sal, and the effect of these is my main interest
> and there are also two age groups.
> 
> Fitting linear MEM (I expect some interaction between two fixed
> effects, treatment and age):
> 
> > data.lme<- lme(expr.val~treatment*age,data=data,random=~1|lab)
> 
> > summary(data.lme)
> Linear mixed-effects model fit by REML
>  Data: m
>        AIC      BIC    logLik
>   33.76913 37.60347 -10.88456
> 
> Random effects:
>  Formula: ~1 | Study
>         (Intercept)  Residual
> StdDev:   0.4553264 0.3960901
> 
> Fixed effects: E ~ Treatment * Age
>                           Value Std.Error DF   t-value p-value
> (Intercept)            5.240742 0.3602901 13 14.545894  0.0000
> Treatmentsal          -0.023434 0.2286827 13 -0.102475  0.9199
> Ageyoung              -1.276539 0.3000890 13 -4.253867  0.0009
> Treatmentsal:Ageyoung  1.838143 0.3960901 13  4.640719  0.0005
>  Correlation:
>                       (Intr) Trtmnt Ageyng
> Treatmentsal          -0.317
> Ageyoung              -0.242  0.381
> Treatmentsal:Ageyoung  0.183 -0.577 -0.660
> 
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -1.6738372 -0.3845786 -0.2229425  0.4311380  2.1987599
> 
> Number of Observations: 18
> Number of Groups: 2
> 
> > anova(data.lme)
>               numDF denDF   F-value p-value
> (Intercept)       1    13 232.76945  <.0001
> Treatment         1    13   9.96020  0.0076
> Age               1    13   2.51385  0.1369
> Treatment:Age     1    13  21.53627  0.0005
> 
> 
> 
> 
> What I do when automatically analyzing all the genes is to look at the
> p-value from anova function to assess the significance of Treatment
> effect and at the sign of estimated parameter (Treatmentsal) from the
> summary function to decide on the direction of change (is it more
> expressed after sal or KA treatment). In the above example the results
> indicate that Treatment has significant effect and that there is more
> expression for KA effect (Treatmentsal=-0.023434). However, when I
> plot the raw data and superimpose the fitted values it is obvious that
> the fit is not good for KA-old datapoints and this is probably caused
> by contradictory data wrt to treatment effect between the two labs
> (sal<KA for A and sal>KA for B).
> 
> My questions are:
> 
> 1. How is the F-value in  anova function computed? I would like to
> understand why I got such a small value when data is contradictory.
> 
> 2. The Treatmentsal value seems to correspond only to the age=old
> (change from a baseline treatment=KA, age=old). How do I compute the
> Treatmentsal value for both age groups?
> 
> 3. In general, what functions/parameters can I used in automated way
> to decide if there is a significant effect of, for example, treatment
> KA?
> 
> Sorry for the lengthy post and superficial understanding of how MEM
> work (not much background in statistics). I would very much appreciate
> any help on these issues.
> 
> Cheers,
> Sanja Rogic
> 

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Thu Apr  2 01:02:36 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 2 Apr 2009 09:02:36 +1000 (EST)
Subject: [R-sig-ME] glmer vs. MCMCglmm
In-Reply-To: <49D39160.4000202@tours.inra.fr>
References: <49D39160.4000202@tours.inra.fr>
Message-ID: <Pine.LNX.4.64.0904020745450.5779@orpheus.qimr.edu.au>

On Wed, 1 Apr 2009, Herv? CHAPUIS wrote:

> I intend to estimate the genetic variance for a binary trait (disease 
> resistance) in a simulated population.
> First, I have used lmer and glmer.  However, sometimes I have false 
> convergences, and  I can't specify "nAGQ=5" when fitting two random effects 
> (sire AND dam).

I presume you have data for just two generations, then?

> This is the reason why I have decided to give a glimpse at MCMCglmm.
>
> I am still trying to implement an animal model as specified in the MCMCglmm 
> manual, but I can't figure out how an heritability can be estimated so high 
> without a big mistake. But I can't see it.
>

Heritability for binary traits is a pretty unsatisfactory concept, but I 
don't see how to get it over 1 ;)  I presume you're following the vignette 
for PlodiaRB, where priors are discussed, but fitting the animal model. 
Does your job work for that dataset?

Cheers, David Duffy.

PS You may be interested in comparing results from the MCMC GLMM for 
pedigree data I have included in my Sib-pair program 
(http://www.qimr.edu.au/davidD).

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v

From r.turner at auckland.ac.nz  Thu Apr  2 03:47:07 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 2 Apr 2009 14:47:07 +1300
Subject: [R-sig-ME] Repeated measures in lmer().
Message-ID: <50052665-8062-4331-A543-EA02006CA5B1@auckland.ac.nz>



Yesterday I posted a query with subject line ``Puzzled by simple  
example.''

The puzzlement was really due to a clumsy stupidity on my part, about
which the less said the better. :-)

The example that I was (initially) puzzled by was really a preliminary
to getting to the real issue with which I am trying to come to grips.

This is the issue of fitting repeated measures models using lmer().

The model that was fitted in my yesterday's posting was

	lmer(y ~ age + (1 | child),data=ht.dat)

This assumes, as I far as I understand things (which is admittedly not
very far) a constant diagonal covariance matrix for the within-child
random effect.  This is a pretty unrealistic assumption.  Doug Bates
kindly informed me, many months ago, that to get a general positive
definite covariance matrix I should use the syntax

	lmer(y ~ age + (age | child),data=ht.dat)   # (*)

but that the model that lmer would be attempting to fit thereby would be
singular.

It has taken me this many months to get even a start at clearing away  
the
cobwebs from my thinking so that I could understand this, but I now  
think
I'm getting to square zero at least.

The model being fitted by (*) above is

	Y = X beta + Z_1 b_1 + Z_2 b_2 + E

but really the ``Z b'' terms (child effect + age-by-child interaction)
can be combined into a single term so the model becomes just

	Y = X beta + Z b + E

which is written entry by entry as

	y_ij = beta_i + B_ij + E_ij

where the E_ij are all i.i.d. N(0,sigma^2_E) and the B_ij are  
independent
of the E_ij, likewise Gaussian with mean 0, but each B_j =  
(B_1j,...,B_4j)'
has covariance matrix Sigma (4-x-4, positive definite, but with no other
specified structure).

The reason the model is singular is that you can ``blend'' as much or
as little as you choose of sigma^2_E into the diagonal of Sigma and have
the same model.  The miraculous thing is that despite the singularity,
lmer() gives the (or ``a'') correct answer, at least in the simulated
data experiments that I've tried.  E.g.:

#
# Script scr.02
#

library(MASS)
library(lme4)

# Generate the data.  No attempt is made to make these
# data realistic.
NCHILD <- 20
set.seed(42)
Beta <- c(40,50,60,70)
Sigma <- 2*matrix(c(1.00,0.50,0.25,0.10,
                     0.50,1.00,0.50,0.25,
                     0.25,0.50,1.00,0.50,
		    0.10,0.25,0.50,1.00),ncol=4)
MB <- mvrnorm(NCHILD,rep(0,4),Sigma)
B  <- as.vector(t(MB))
E  <- rnorm(4*NCHILD,0,0)
Y  <- Beta + B + E
ht.dat.2 <- data.frame(y=Y,age=factor(rep(4:7,NCHILD)),child=factor 
(rep(1:NCHILD,each=4)))

# Fit with lmer():
f2 <- lmer(y ~ 0 + age + (0+age|child),data=ht.dat.2,REML=TRUE)
V <- VarCorr(f2)
M <- V[[1]]
S <- attr(V,"sc")
covb.lmer <- M + diag(rep(S^2,4))
attributes(covb.lmer) <- attributes(covb.lmer)["dim"]
covb.chk <- var(MB)

# Clean up:
rm(NCHILD,Beta,Sigma,MB,B,E,Y,V,M,S)

You see that if you take the residual variance component and add it to
the diagonal of the ``child'' covariance matrix (``Sigma-hat'') you get
(very close to) exactly the right answer.  For NCHILD = 20 as in the
foregoing example we get:

 > range(covb.lmer-covb.chk)
[1] -1.288370e-04  1.467542e-05

Without even a warning.  If we jack NCHILD up to 500 we get a warning
about false convergence (well, I did yesterday, but when I sourced
scr.02 just now, I didn't --- ???) but the agreement is even better:

 > range(covb.lmer-covb.chk)
[1] -6.019627e-06  6.337365e-06

My question is:  Is this behaviour reliable?  Can I depend on this sort
of work-around for fitting a repeated measures model where there is
no replication, i.e. one observation per (age,child) combination, whence
no room for an E_ij term in the model?  Suppose the repeated measures
model is complicated by other factors.  E.g. instead of all girls we
have both sexes and put a sex factor into the model.  Or the children
are nested within localities or countries.  Can I still fit the model(s)
in this way?

``Ideally'' I'd like to be able to fit the model

	y_ij = beta_i + B_ij

i.e. suppress the residual error E_ij term (or lump it in with the
child random effect).   This is presumably not possible as lmer() is
currently constituted.  Would it/could it be possible?  I.e. could the
code be adjusted to accommodate this desideratum?  Would it be a
coding nightmare to do this?  It would seem to me to a fairly
*desirable* feature, since repeated measures data with no
replications are not at all uncommon.  But of course desirable and
feasible are two very different things.

On another tack:  Have I (at last) got hold of the right end of the
stick in respect of such models?  Or is my understanding still flawed?
Am I going at fitting repeated measures models in the right way?
Is there another --- better --- way to do this using lmer()?

I have tried a similar simulation experiment with two replicate  
observations
for each child.  (Height measured twice on each occasion; the E_ijk,  
k=1,2,
now representing measurement error.)  The answers appeared to make sense
although in these circumstances one cannot do an exact check since the
estimate of ``Sigma'' produced by lmer() will not be the same as var(MB)
*because of* the measurement error.

Comments?  Suggestions?  Enlightenment? Feedback?  Such from the horse's
mouth (i.e. Doug Bates) would be particularly welcome.

	cheers,

		Rolf Turner


######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From r.turner at auckland.ac.nz  Thu Apr  2 04:26:50 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 2 Apr 2009 15:26:50 +1300
Subject: [R-sig-ME] Repeated measures in lmer().
In-Reply-To: <0BE438149FF2254DB4199E2682C8DFEB01D5023B@crcmail1.BCCRC.CA>
References: <0BE438149FF2254DB4199E2682C8DFEB01D5023B@crcmail1.BCCRC.CA>
Message-ID: <C99CBD56-E396-4587-8EC0-9D3F002651CF@auckland.ac.nz>


On 2/04/2009, at 3:20 PM, Steven McKinney wrote:

> Hi Rolf
>
> E  <- rnorm(4*NCHILD,0,0)
>
> Is this correct?  Did you mean to have variance = 0?

Yes.  The E is just window dressing; it doesn't do anything.
I just put it there to emphasize that measurement error *could*
be there, but I really want to assume it away/absorb it into
the ``child effect'' (since it can't be distinguished from being
part of the child effect without replication).

I *thought* I had put a comment to this effect into my code; guess
it got deleted in the editing process.

Sorry for the confusion.

	cheers,

		Rolf

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From lamprianou at yahoo.com  Thu Apr  2 11:09:04 2009
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Thu, 2 Apr 2009 02:09:04 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 28, Issue 4
In-Reply-To: <mailman.9234.1238639296.4476.r-sig-mixed-models@r-project.org>
Message-ID: <803284.74288.qm@web54101.mail.re2.yahoo.com>


Dear all,
I'll re-send this request since I got no reply to the first one. 
It is an issue which I face currently with lmer and MLWin and SPSS. This problem makes me feel very undomfortable. I have one standardized variable which represents the academic performance of children,  and I also have information about their school and their class.  I run the model with SPSS and lmer and I get the same result (both use REML). Then I use MLWin and I get different (but more reasonable results). MLWin uses IGLS and RIGLS and MCMC (all three methods agree when I use MLWin). I hereby present my numbers:

I run the following model:

Linear mixed model fit by REML 
Formula: Zmg_Arxiki ~ 1 + (1 | school) 
   Data: data 
   AIC   BIC logLik deviance REMLdev
21693 21714 -10844    21684   21687
Random effects:
Groups   Name        Variance Std.Dev.
school   (Intercept) 0.37043  0.60863 
Residual             0.74465  0.86293 
Number of obs: 8448, groups: school, 47

Fixed effects:
            Estimate Std. Error t value
(Intercept) -0.13515    0.08971  -1.506

However, this is NOT reasonable because the variable is a standardized variable and the variance should be 1.0!! SPSS gives the same results.
If I run the same model in MlWin, I correctly get 

S2 for the school level=0.077
S2 (error) = 0.923
and the total is 1.0 (correct)!
Could anyone please let me know what happens? Any help is welcome.

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk







From j.hadfield at ed.ac.uk  Thu Apr  2 12:36:54 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 2 Apr 2009 11:36:54 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 27, Issue 36
In-Reply-To: <638571.68708.qm@web59908.mail.ac4.yahoo.com>
References: <638571.68708.qm@web59908.mail.ac4.yahoo.com>
Message-ID: <69F26DE2-62CD-462C-BEBD-66B820593238@ed.ac.uk>

Hi Luciano,

Perhaps you could tabulate your results so we could see whether this  
really is an over-fitting problem or a numerical problem. Something  
like:

table(lHatching, HatchOrder, Year)

should do it.

Cheers,

Jarrod


On 1 Apr 2009, at 22:04, Luciano La Sala wrote:

>
> Dear Ken and Jarrod,
>
> Thank you very much for shedding some light on my problem!
> Besides the points you've made, I was told that I could avoid over- 
> fitting in my second model by treating the interaction term as two  
> continuous variables instead of categorical ones  
> (HatchingOrder*Year). Well, after doind so, the output says "Error  
> in asMethod(object) : matrix is not symmetric [1,2]", so I guess  
> that that is not a feasible solution to the problem either, and I  
> wonder how far should one go to find one?
>
> If my model fell prey to Hauck-Donner effect - which may be causing  
> the std.. errors to be overestimated and the signifficance of the  
> effect to be missed - maybe I just should stop turturing my data and  
> admit that it is sparse?
>
> Should you come up with any ideas, I'd be glad to hear them.
>
> Luciano
>
>
>
>
> --- El lun 30-mar-09, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org 
> > escribi?:
>
>> De: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org 
>> >
>> Asunto: R-sig-mixed-models Digest, Vol 27, Issue 36
>> Para: r-sig-mixed-models at r-project.org
>> Fecha: lunes, 30 de marzo de 2009, 6:27 pm
>> Send R-sig-mixed-models mailing list submissions to
>> 	r-sig-mixed-models at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> or, via email, send a message with subject or body
>> 'help' to
>> 	r-sig-mixed-models-request at r-project.org
>>
>> You can reach the person managing the list at
>> 	r-sig-mixed-models-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more
>> specific
>> than "Re: Contents of R-sig-mixed-models
>> digest..."
>>
>>
>> Today's Topics:
>>
>>   1. Re: Can interaction term cause Estimates and Std.
>> Errors	to
>>      be too large? (Ken Beath)
>>   2. Re: Can interaction term cause Estimates and Std.
>> Errors	to
>>      be too large? (Jarrod Hadfield)
>>   3. Re: Can interaction term cause Estimates and Std.
>> Errors	to
>>      be too large? (Ken Beath)
>>   4. Meta-analysis using lmer (Yu-Kang Tu)
>>   5. Mixed Model for Travel Distance (Chuck Cleland)
>>   6. Re: Mixed Model for Travel Distance (Dimitris
>> Rizopoulos)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Mon, 30 Mar 2009 21:08:58 +1100
>> From: Ken Beath <ken at kjbeath.com.au>
>> Subject: Re: [R-sig-ME] Can interaction term cause
>> Estimates and Std.
>> 	Errors	to be too large?
>> To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Cc: r-sig-mixed-models at r-project.org,
>> lucianolasala at yahoo.com.ar
>> Message-ID:
>> <68347D8C-AE1C-48BF-B194-D7E1DDD50B50 at kjbeath.com.au>
>> Content-Type: text/plain; charset=US-ASCII; format=flowed;
>> delsp=yes
>>
>> I meant overfitting in the sense of trying to fit too
>> complex a model,
>> which is the same as what you are describing. Gelman has
>> some papers
>> on the use of priors, one is
>> http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>
>>  In the case of complete separation the results seem to be
>> very
>> dependent on the prior which doesn't look to be a good
>> thing. It would
>> appear much better to admit that there is insufficient data
>> to perform
>> the analysis.
>>
>> Ken
>>
>>
>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>
>>> Hi,
>>>
>>> I think it unlikely that the problem arises through
>> overfitting in
>>> the sense that there are too many parameters for the
>> amount of
>>> data.  It's more likely that the underlying
>> probabilities really are
>>> extreme for some categories causing what are also
>> known as "extreme
>>> category problems" (eg Miztal 1998 J. Dairy
>> Science 72 1557-1568):
>>> the binary variable in one or more groups is always 0
>> or 1, even
>>> though there are probably many eggs  in most
>> categories.  A solution
>>> to this type of problem is to place an informative
>> prior on the
>>> fixed effects to stop them wandering into extreme
>> values on the
>>> logit scale. For the purist this may be anathema, but
>> as a practical
>>> solution it seems to work quite well.  Having a normal
>> prior on the
>>> logit scale with mean zero and variance pi, is the
>> closest (I
>>> think?) to a uniform prior on the probability scale.
>> If there are
>>> more elegant solutions to the problem I'd be
>> interested to hear
>>> about them.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>> -- 
>>> The University of Edinburgh is a charitable body,
>> registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Mon, 30 Mar 2009 11:21:39 +0100
>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Subject: Re: [R-sig-ME] Can interaction term cause
>> Estimates and Std.
>> 	Errors	to be too large?
>> To: Ken Beath <ken at kjbeath.com.au>
>> Cc: r-sig-mixed-models at r-project.org,
>> lucianolasala at yahoo.com.ar
>> Message-ID:
>> <AC5DBE6D-DEEF-47A2-90BE-071FE9CBCC79 at ed.ac.uk>
>> Content-Type: text/plain; charset="us-ascii";
>> Format="flowed";
>> 	DelSp="yes"
>>
>> Hi Ken,
>>
>> Thanks for the reference, it looks interesting. I disagree
>> that
>> Luciano's second model should be classified as over
>> fitting. Imagine
>> this....
>>
>> y<-rbinom(100, 1, c(0.001, 0.999))
>> x<-gl(2,1,100)
>>
>> summary(glm(y~1, family="binomial"))
>> summary(glm(y~x, family="binomial"))
>>
>> There is a very high probability of complete separation,
>> the second
>> model gives non-significant p-values for the effect of x,
>> but I think
>> it would be a mistake to say the 2nd model is over-fitted
>> and should
>> be avoided.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> On 30 Mar 2009, at 11:08, Ken Beath wrote:
>>
>>> I meant overfitting in the sense of trying to fit too
>> complex a
>>> model, which is the same as what you are describing.
>> Gelman has some
>>> papers on the use of priors, one is
>> http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>
>>> In the case of complete separation the results seem
>> to be very
>>> dependent on the prior which doesn't look to be a
>> good thing. It
>>> would appear much better to admit that there is
>> insufficient data to
>>> perform the analysis.
>>>
>>> Ken
>>>
>>>
>>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>>
>>>> Hi,
>>>>
>>>> I think it unlikely that the problem arises
>> through overfitting in
>>>> the sense that there are too many parameters for
>> the amount of
>>>> data.  It's more likely that the underlying
>> probabilities really
>>>> are extreme for some categories causing what are
>> also known as
>>>> "extreme category problems" (eg Miztal
>> 1998 J. Dairy Science 72
>>>> 1557-1568): the binary variable in one or more
>> groups is always 0
>>>> or 1, even though there are probably many eggs  in
>> most
>>>> categories.  A solution to this type of problem is
>> to place an
>>>> informative prior on the fixed effects to stop
>> them wandering into
>>>> extreme values on the logit scale. For the purist
>> this may be
>>>> anathema, but as a practical solution it seems to
>> work quite well.
>>>> Having a normal prior on the logit scale with mean
>> zero and
>>>> variance pi, is the closest (I think?) to a
>> uniform prior on the
>>>> probability scale. If there are more elegant
>> solutions to the
>>>> problem I'd be interested to hear about them.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>> -- 
>>>> The University of Edinburgh is a charitable body,
>> registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>
>> -------------- next part --------------
>> An embedded and charset-unspecified text was scrubbed...
>> Name: not available
>> URL:
>> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090330/df46ef59/attachment-0001.pl 
>> >
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Mon, 30 Mar 2009 21:50:53 +1100
>> From: Ken Beath <ken at kjbeath.com.au>
>> Subject: Re: [R-sig-ME] Can interaction term cause
>> Estimates and Std.
>> 	Errors	to be too large?
>> To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Cc: "r-sig-mixed-models at r-project.org Models"
>> 	<r-sig-mixed-models at r-project.org>,
>> lucianolasala at yahoo.com.ar
>> Message-ID:
>> <AF2C8F6D-8857-4855-BAED-8DD9B525212D at kjbeath.com.au>
>> Content-Type: text/plain; charset=US-ASCII; format=flowed;
>> delsp=yes
>>
>> On 30/03/2009, at 9:21 PM, Jarrod Hadfield wrote:
>>
>>> Hi Ken,
>>>
>>> Thanks for the reference, it looks interesting. I
>> disagree that
>>> Luciano's second model should be classified as
>> over fitting. Imagine
>>> this....
>>>
>>> y<-rbinom(100, 1, c(0.001, 0.999))
>>> x<-gl(2,1,100)
>>>
>>> summary(glm(y~1, family="binomial"))
>>> summary(glm(y~x, family="binomial"))
>>>
>>> There is a very high probability of complete
>> separation, the second
>>> model gives non-significant p-values for the effect of
>> x, but I
>>> think it would be a mistake to say the 2nd model is
>> over-fitted and
>>> should be avoided.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>
>> My original posting said "usually" and obviously
>> you can create data
>> with perfect or almost perfect correlation over a large
>> table, but in
>> practice it commonly happens because there is a small
>> table. One good
>> reason for producing some descriptive tables before
>> fitting.
>>
>> Ken
>>
>>
>>>
>>> On 30 Mar 2009, at 11:08, Ken Beath wrote:
>>>
>>>> I meant overfitting in the sense of trying to fit
>> too complex a
>>>> model, which is the same as what you are
>> describing. Gelman has
>>>> some papers on the use of priors, one is
>> http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>
>>>> In the case of complete separation the results
>> seem to be very
>>>> dependent on the prior which doesn't look to
>> be a good thing. It
>>>> would appear much better to admit that there is
>> insufficient data
>>>> to perform the analysis.
>>>>
>>>> Ken
>>>>
>>>>
>>>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> I think it unlikely that the problem arises
>> through overfitting in
>>>>> the sense that there are too many parameters
>> for the amount of
>>>>> data.  It's more likely that the
>> underlying probabilities really
>>>>> are extreme for some categories causing what
>> are also known as
>>>>> "extreme category problems" (eg
>> Miztal 1998 J. Dairy Science 72
>>>>> 1557-1568): the binary variable in one or more
>> groups is always 0
>>>>> or 1, even though there are probably many eggs
>> in most
>>>>> categories.  A solution to this type of
>> problem is to place an
>>>>> informative prior on the fixed effects to stop
>> them wandering into
>>>>> extreme values on the logit scale. For the
>> purist this may be
>>>>> anathema, but as a practical solution it seems
>> to work quite
>>>>> well.  Having a normal prior on the logit
>> scale with mean zero and
>>>>> variance pi, is the closest (I think?) to a
>> uniform prior on the
>>>>> probability scale. If there are more elegant
>> solutions to the
>>>>> problem I'd be interested to hear about
>> them.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>> -- 
>>>>> The University of Edinburgh is a charitable
>> body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>
>>>>
>>>
>>> The University of Edinburgh is a charitable body,
>> registered in
>>> Scotland, with registration number SC005336.
>>
>>
>>
>> ------------------------------
>>
>> Message: 4
>> Date: Mon, 30 Mar 2009 18:16:46 +0100
>> From: Yu-Kang Tu <Y.K.Tu at leeds.ac.uk>
>> Subject: [R-sig-ME] Meta-analysis using lmer
>> To: "'r-sig-mixed-models at r-project.org'"
>> 	<r-sig-mixed-models at r-project.org>
>> Message-ID:
>> 	<7131EF1EF27893479833FCF59E7AAC440B3E818BE1 at HERMES9.ds.leeds.ac.uk>
>> Content-Type: text/plain; charset="us-ascii"
>>
>>
>> Hi,
>>
>> I am trying to use lme and lmer to do random effects
>> meta-analysis as described in Hox (2002) and UCLA website:
>> http://www.ats.ucla.edu/stat/mlwin/examples/ma_hox/chapter8.htm
>>
>> Basically, what I want to do is to constraint one residual
>> error variance to be unity and use the inverse of standard
>> errors as the covariate (weight) for this variance. And an
>> additional random effects terms is used to estimate the
>> between-study variation. I did take a look at the Pinheiro
>> & Bates book on varFunc, but unfortunately, I cannot
>> figure out how this can be done. Any suggestions/advices
>> will be greatly appreciated. Many thanks.
>>
>> Yu-Kang
>> --------------------------------------------
>> Dr Yu-Kang Tu
>> Senior Clinical Research Fellow
>> Division of Biostatistics, Centre for Epidemiology and
>> Biostatistics
>> Leeds Institute of Genetics, Health and Therapeutics, and
>> Department of Periodontology, Leeds Dental Institute
>> Room 8.01, Level 8, Worsley Building,
>> Clarendon Way
>> University of Leeds, LS2 9JT
>> Email: y.k.tu at leeds.ac.uk
>> Tel: +44 (0) 113 3431877
>> Fax: +44 (0) 113 3434877
>>
>>
>>
>> ------------------------------
>>
>> Message: 5
>> Date: Mon, 30 Mar 2009 13:29:15 -0400
>> From: Chuck Cleland <ccleland at optonline.net>
>> Subject: [R-sig-ME] Mixed Model for Travel Distance
>> To: r-sig-mixed-models at r-project.org
>> Message-ID: <49D1016B.8050808 at optonline.net>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> Hello:
>>  I am attempting to model the distance that clients travel
>> to a
>> treatment program.  There are 14385 clients nested in 83
>> treatment
>> programs (the grouping factor).  The raw data are in miles
>> driven from
>> the client's residence to the treatment program.  A
>> natural logarithm
>> transformation of miles driven works well to reduce the
>> positive skew in
>> miles driven.  I fit a model with lme() that looks like
>> this:
>>
>> Linear mixed-effects model fit by REML
>> Data: dist.df
>>       AIC      BIC    logLik
>>  38145.37 38319.54 -19049.68
>>
>> Random effects:
>> Formula: ~1 | PROGRAM
>>        (Intercept)  Residual
>> StdDev:   0.4268969 0.8988483
>>
>> Fixed effects: log(DIST5DZ + 1) ~ QUAD + BEAL_TRI +
>> log(RZIPAREA + 1) +
>> log(PZIPAREA + 1) + AGE.TRI + P3GEND + P5RACEX + EMPLD +
>> P13REASN +
>> METHFST + URGE.DI + WDRAW.DI + RX_30 + P7HR30
>>
>>                               Value  Std.Error    DF
>> t-value p-value
>> (Intercept)                1.2235603 0.13153231 14288
>> 9.30236  0.0000
>> QUADSouthEast              0.2100666 0.13200891    76
>> 1.59131  0.1157
>> QUADMidWest                0.2760390 0.15709516    76
>> 1.75715  0.0829
>> QUADWest                  -0.1655914 0.15536003    76
>> -1.06586  0.2899
>> BEAL_TRI250K-1M           -0.0264939 0.11724713    76
>> -0.22597  0.8218
>> BEAL_TRI<250K             -0.0965256 0.16399464    76
>> -0.58859  0.5579
>> log(RZIPAREA + 1)          0.2965304 0.00757138 14288
>> 39.16463  0.0000
>> log(PZIPAREA + 1)         -0.0042061 0.04413826    76
>> -0.09529  0.9243
>> AGE.TRI30-43              -0.0309444 0.01789442 14288
>> -1.72927  0.0838
>> AGE.TRI43-83              -0.1281177 0.02168648 14288
>> -5.90772  0.0000
>> P3GENDFemale              -0.0195289 0.01632703 14288
>> -1.19611  0.2317
>> P5RACEXLatino             -0.3527584 0.02904416 14288
>> -12.14559  0.0000
>> P5RACEXBlack              -0.5485861 0.03306146 14288
>> -16.59292  0.0000
>> P5RACEXOther              -0.1580669 0.04811350 14288
>> -3.28529  0.0010
>> EMPLDYes                   0.0098856 0.01650635 14288
>> 0.59890  0.5493
>> P13REASNYes               -0.0095057 0.01650128 14288
>> -0.57606  0.5646
>> METHFSTYes                 0.0073478 0.01672948 14288
>> 0.43921  0.6605
>> URGE.DI Strong-VeryStrong -0.0272769 0.02400068 14288
>> -1.13651  0.2558
>> WDRAW.DISevere-VerySevere  0.0012054 0.01810067 14288
>> 0.06659  0.9469
>> RX_30Yes                   0.0934411 0.02165389 14288
>> 4.31521  0.0000
>> P7HR30Yes                 -0.0408189 0.02256842 14288
>> -1.80867  0.0705
>>
>> Standardized Within-Group Residuals:
>>        Min          Q1         Med          Q3         Max
>> -4.17921640 -0.49875991  0.08672984  0.59020542  4.54644432
>>
>> Number of Observations: 14385
>> Number of Groups: 83
>>
>>  I would like to summarize the fixed effects in terms of
>> miles rather
>> than log(miles + 1).  How can that be done?  Are there
>> common
>> generalized linear mixed models for miles driven that would
>> avoid the
>> transformation and allow effects to be presented in miles?
>>
>> thanks,
>>
>> Chuck
>>
>> -- 
>> Chuck Cleland, Ph.D.
>> NDRI, Inc. (www.ndri.org)
>> 71 West 23rd Street, 8th floor
>> New York, NY 10010
>> tel: (212) 845-4495 (Tu, Th)
>> tel: (732) 512-0171 (M, W, F)
>> fax: (917) 438-0894
>>
>>
>>
>> ------------------------------
>>
>> Message: 6
>> Date: Mon, 30 Mar 2009 20:26:38 +0200
>> From: Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl>
>> Subject: Re: [R-sig-ME] Mixed Model for Travel Distance
>> To: Chuck Cleland <ccleland at optonline.net>
>> Cc: r-sig-mixed-models at r-project.org
>> Message-ID: <49D10EDE.8050501 at erasmusmc.nl>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> well, if you're only interested in the fixed effects,
>> then you can also
>> use a Generalized Estimating Equations approach that does
>> not make a
>> parametric assumption for the distribution of your error
>> terms, e.g.,
>> have a look at the 'geepack' package. Furthermore
>> and in case it is
>> relevant for your application, in GEE the estimated
>> parameters will have
>> a population interpretation, contrary to the GLMMs approach
>> in which
>> they will have a conditional on the random effects
>> interpretation.
>>
>>
>> I hope it helps.
>>
>> Best,
>> Dimitris
>>
>>
>> Chuck Cleland wrote:
>>> Hello:
>>>  I am attempting to model the distance that clients
>> travel to a
>>> treatment program.  There are 14385 clients nested in
>> 83 treatment
>>> programs (the grouping factor).  The raw data are in
>> miles driven from
>>> the client's residence to the treatment program.
>> A natural logarithm
>>> transformation of miles driven works well to reduce
>> the positive skew in
>>> miles driven.  I fit a model with lme() that looks
>> like this:
>>>
>>> Linear mixed-effects model fit by REML
>>> Data: dist.df
>>>       AIC      BIC    logLik
>>>  38145.37 38319.54 -19049.68
>>>
>>> Random effects:
>>> Formula: ~1 | PROGRAM
>>>        (Intercept)  Residual
>>> StdDev:   0.4268969 0.8988483
>>>
>>> Fixed effects: log(DIST5DZ + 1) ~ QUAD + BEAL_TRI +
>> log(RZIPAREA + 1) +
>>> log(PZIPAREA + 1) + AGE.TRI + P3GEND + P5RACEX + EMPLD
>> + P13REASN +
>>> METHFST + URGE.DI + WDRAW.DI + RX_30 + P7HR30
>>>
>>>                               Value  Std.Error    DF
>> t-value p-value
>>> (Intercept)                1.2235603 0.13153231 14288
>> 9.30236  0.0000
>>> QUADSouthEast              0.2100666 0.13200891    76
>> 1.59131  0.1157
>>> QUADMidWest                0.2760390 0.15709516    76
>> 1.75715  0.0829
>>> QUADWest                  -0.1655914 0.15536003    76
>> -1.06586  0.2899
>>> BEAL_TRI250K-1M           -0.0264939 0.11724713    76
>> -0.22597  0.8218
>>> BEAL_TRI<250K             -0.0965256 0.16399464
>> 76  -0.58859  0.5579
>>> log(RZIPAREA + 1)          0.2965304 0.00757138 14288
>> 39.16463  0.0000
>>> log(PZIPAREA + 1)         -0.0042061 0.04413826    76
>> -0.09529  0.9243
>>> AGE.TRI30-43              -0.0309444 0.01789442 14288
>> -1.72927  0.0838
>>> AGE.TRI43-83              -0.1281177 0.02168648 14288
>> -5.90772  0.0000
>>> P3GENDFemale              -0.0195289 0.01632703 14288
>> -1.19611  0.2317
>>> P5RACEXLatino             -0.3527584 0.02904416 14288
>> -12.14559  0.0000
>>> P5RACEXBlack              -0.5485861 0.03306146 14288
>> -16.59292  0.0000
>>> P5RACEXOther              -0.1580669 0.04811350 14288
>> -3.28529  0.0010
>>> EMPLDYes                   0.0098856 0.01650635 14288
>> 0.59890  0.5493
>>> P13REASNYes               -0.0095057 0.01650128 14288
>> -0.57606  0.5646
>>> METHFSTYes                 0.0073478 0.01672948 14288
>> 0.43921  0.6605
>>> URGE.DI Strong-VeryStrong -0.0272769 0.02400068 14288
>> -1.13651  0.2558
>>> WDRAW.DISevere-VerySevere  0.0012054 0.01810067 14288
>> 0.06659  0.9469
>>> RX_30Yes                   0.0934411 0.02165389 14288
>> 4.31521  0.0000
>>> P7HR30Yes                 -0.0408189 0.02256842 14288
>> -1.80867  0.0705
>>>
>>> Standardized Within-Group Residuals:
>>>        Min          Q1         Med          Q3
>> Max
>>> -4.17921640 -0.49875991  0.08672984  0.59020542
>> 4.54644432
>>>
>>> Number of Observations: 14385
>>> Number of Groups: 83
>>>
>>>  I would like to summarize the fixed effects in terms
>> of miles rather
>>> than log(miles + 1).  How can that be done?  Are there
>> common
>>> generalized linear mixed models for miles driven that
>> would avoid the
>>> transformation and allow effects to be presented in
>> miles?
>>>
>>> thanks,
>>>
>>> Chuck
>>>
>>
>> -- 
>> Dimitris Rizopoulos
>> Assistant Professor
>> Department of Biostatistics
>> Erasmus University Medical Center
>>
>> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
>> Tel: +31/(0)10/7043478
>> Fax: +31/(0)10/7043014
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> End of R-sig-mixed-models Digest, Vol 27, Issue 36
>> **************************************************
>
>
>      Yahoo! Cocina
> Recetas pr?cticas y comida saludable
> http://ar.mujer.yahoo.com/cocina/
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Apr  2 13:02:43 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 2 Apr 2009 12:02:43 +0100
Subject: [R-sig-ME] glmer vs. MCMCglmm
Message-ID: <5BD07134-5DE9-47A2-8A60-2DC628A38AD7@ed.ac.uk>

Hi,

As David suggested, the problem with binary data is that any residual  
variance in the underlying probability cannot be observed, unlike  
other types of data. For example, if data are generated according to  
the process

y ~ binom(n=1, p=inv.logit(mu + e_i))

then the data look the same irrespective of the variance of the e's:

y1<-rbinom(1000, 1, inv.logit(rnorm(1000, 0, 1)))
y2<-rbinom(1000, 1, inv.logit(rnorm(1000, 0, 10)))

table(y1)
table(y2)

Because there is no information on VE (residual variance) we have to  
make an assumption about its value.  In terms of the fit of the model  
to the data the choice of VE should make no difference because the  
parameter is redundant. I think (if some one could clarify this that  
would be great) that lmer fixes VE to zero, where with MCMCglmm the  
user is free to fix VE at any value.  Other than that I believe the  
models should be identical. However, as VE approaches zero in MCMCglmm  
mixing becomes  problem, and actually when VE=0 the chain no longer  
mixes at all.

With genetic models there are extra restrictions on the parameter  
values which are not met when fitting a simple dam-sire model. Often  
the parameter estimates lie within these restrictions, but with binary  
data this is often not the case.  The issue is that if genetic  
variance (VA) exists, then you know apriori that VE in a dam-sire  
model cannot be zero, because VE under this parameterisation actually  
contains some VA (due to mendelian sampling variation).  The animal  
model, which you should be able to fit using MCMCglmm, not only  
accounts for more complicated patterns of relatedness , but also  
ensures that these restrictions are met.  Even so, you still have no  
information regarding the non-genetic VE and you have to fix it at  
something. My guess is that there are certain things that are  
invariant to the choice of VE (such a as the genetic correlation in  
the Plodia example)  but off-hand I don't know what they are.   It may  
also be possible to obtain post-analysis what the posterior  
distribution of VA/fixed effects would be under a different assumption  
about VE - but again I don't know the literature well enough to say.

One other worrying issue is that comparing DIC for different models  
only seems valid if the same assumption regarding VE is used. Again,  
any ideas/insights into this problem would be great.

Cheers,

Jarrod








-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From rmh3093 at gmail.com  Thu Apr  2 21:51:49 2009
From: rmh3093 at gmail.com (Ryan Hope)
Date: Thu, 2 Apr 2009 15:51:49 -0400
Subject: [R-sig-ME] Wrong degrees of freedom in lmer model?
Message-ID: <48f7fe350904021251v25c5785apc9a85888e8b61fc7@mail.gmail.com>

I am trying to use the lmer function to analyze the data from the
thesis experiment. The response variable is a continuous variable,
completion time. I have 2 fixed factors, number of targets (4-levels:
4,9,14,19) and displacement per second (DPS) (3-levels: 72.42, 84.99,
88.99). I also have 3 random variables, participants, block (which
group the replicates of a combination of fixed factors), and target
displacement. The R code that I am using is listed below:

library(lme4)
datafile="http://people.rit.edu/rmh3093/master1.csv"
master1=read.table(datafile,header=T)
master1$Targets=as.factor(master1$Targets)
model=lmer(log(Completion_Time)~-1+Targets+DPS+(-1+Targets|Participant_ID)+(1|Block)+(1|Target_Displacement),data=master1)
anova(model)

Im not even sure if the lmer model I am using is 100% correct but it
seems the best to based on what I've read on
(http://www.let.uu.nl/~Hugo.Quene/personal/multilevel/jml2008/x24lmerlog.html).
Anyway, I do not understand the degrees of freedom reported by the
anova function based on my model (shown below):

Analysis of Variance Table
        Df Sum Sq Mean Sq    F value
Targets  4  33393    8348 39411.3500
DPS      1      2       2     7.7816

Since there are 4 levels of the Target factor, shouldn't the Df for
Targets be 3 not 4?

-Ryan



From sdorairaj at gmail.com  Thu Apr  2 22:17:45 2009
From: sdorairaj at gmail.com (Sundar Dorai-Raj)
Date: Thu, 2 Apr 2009 13:17:45 -0700
Subject: [R-sig-ME] Wrong degrees of freedom in lmer model?
In-Reply-To: <48f7fe350904021251v25c5785apc9a85888e8b61fc7@mail.gmail.com>
References: <48f7fe350904021251v25c5785apc9a85888e8b61fc7@mail.gmail.com>
Message-ID: <c9ce82b00904021317g5666f777qe466fbe8938ca16d@mail.gmail.com>

The "-1" in your formula is removing the intercept, which is why you
have an extra degree of freedom for Targets. Remove this an it drops
to 3 df:

> model=lmer(log(Completion_Time)~Targets+DPS+(-1+Targets|Participant_ID)+(1|Block)+(1|Target_Displacement),data=master1)
> anova(model)
Analysis of Variance Table
        Df  Sum Sq Mean Sq  F value
Targets  3 138.469  46.156 217.9088
DPS      1   1.648   1.648   7.7824

HTH,

--sundar

On Thu, Apr 2, 2009 at 12:51 PM, Ryan Hope <rmh3093 at gmail.com> wrote:
> I am trying to use the lmer function to analyze the data from the
> thesis experiment. The response variable is a continuous variable,
> completion time. I have 2 fixed factors, number of targets (4-levels:
> 4,9,14,19) and displacement per second (DPS) (3-levels: 72.42, 84.99,
> 88.99). I also have 3 random variables, participants, block (which
> group the replicates of a combination of fixed factors), and target
> displacement. The R code that I am using is listed below:
>
> library(lme4)
> datafile="http://people.rit.edu/rmh3093/master1.csv"
> master1=read.table(datafile,header=T)
> master1$Targets=as.factor(master1$Targets)
> model=lmer(log(Completion_Time)~-1+Targets+DPS+(-1+Targets|Participant_ID)+(1|Block)+(1|Target_Displacement),data=master1)
> anova(model)
>
> Im not even sure if the lmer model I am using is 100% correct but it
> seems the best to based on what I've read on
> (http://www.let.uu.nl/~Hugo.Quene/personal/multilevel/jml2008/x24lmerlog.html).
> Anyway, I do not understand the degrees of freedom reported by the
> anova function based on my model (shown below):
>
> Analysis of Variance Table
> ? ? ? ?Df Sum Sq Mean Sq ? ?F value
> Targets ?4 ?33393 ? ?8348 39411.3500
> DPS ? ? ?1 ? ? ?2 ? ? ? 2 ? ? 7.7816
>
> Since there are 4 levels of the Target factor, shouldn't the Df for
> Targets be 3 not 4?
>
> -Ryan
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Apr  2 22:31:54 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 2 Apr 2009 15:31:54 -0500
Subject: [R-sig-ME] Repeated measures in lmer().
In-Reply-To: <50052665-8062-4331-A543-EA02006CA5B1@auckland.ac.nz>
References: <50052665-8062-4331-A543-EA02006CA5B1@auckland.ac.nz>
Message-ID: <40e66e0b0904021331v58b74d47t469339a8c152f2a7@mail.gmail.com>

On Wed, Apr 1, 2009 at 8:47 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

> Yesterday I posted a query with subject line ``Puzzled by simple example.''

> The puzzlement was really due to a clumsy stupidity on my part, about
> which the less said the better. :-)

> The example that I was (initially) puzzled by was really a preliminary
> to getting to the real issue with which I am trying to come to grips.

> This is the issue of fitting repeated measures models using lmer().

> The model that was fitted in my yesterday's posting was

> ? ? ? ?lmer(y ~ age + (1 | child),data=ht.dat)

> This assumes, as I far as I understand things (which is admittedly not
> very far) a constant diagonal covariance matrix for the within-child
> random effect. ?This is a pretty unrealistic assumption. ?Doug Bates
> kindly informed me, many months ago, that to get a general positive
> definite covariance matrix I should use the syntax

> ? ? ? ?lmer(y ~ age + (age | child),data=ht.dat) ? # (*)

> but that the model that lmer would be attempting to fit thereby would be
> singular.

> It has taken me this many months to get even a start at clearing away the
> cobwebs from my thinking so that I could understand this, but I now think
> I'm getting to square zero at least.
>
> The model being fitted by (*) above is
>
> ? ? ? ?Y = X beta + Z_1 b_1 + Z_2 b_2 + E
>
> but really the ``Z b'' terms (child effect + age-by-child interaction)
> can be combined into a single term so the model becomes just
>
> ? ? ? ?Y = X beta + Z b + E
>
> which is written entry by entry as
>
> ? ? ? ?y_ij = beta_i + B_ij + E_ij
>
> where the E_ij are all i.i.d. N(0,sigma^2_E) and the B_ij are independent
> of the E_ij, likewise Gaussian with mean 0, but each B_j = (B_1j,...,B_4j)'
> has covariance matrix Sigma (4-x-4, positive definite, but with no other
> specified structure).
>
> The reason the model is singular is that you can ``blend'' as much or
> as little as you choose of sigma^2_E into the diagonal of Sigma and have
> the same model. ?The miraculous thing is that despite the singularity,
> lmer() gives the (or ``a'') correct answer, at least in the simulated
> data experiments that I've tried. ?E.g.:
>
> #
> # Script scr.02
> #
>
> library(MASS)
> library(lme4)
>
> # Generate the data. ?No attempt is made to make these
> # data realistic.
> NCHILD <- 20
> set.seed(42)
> Beta <- c(40,50,60,70)
> Sigma <- 2*matrix(c(1.00,0.50,0.25,0.10,
> ? ? ? ? ? ? ? ? ? ?0.50,1.00,0.50,0.25,
> ? ? ? ? ? ? ? ? ? ?0.25,0.50,1.00,0.50,
> ? ? ? ? ? ? ? ? ? ?0.10,0.25,0.50,1.00),ncol=4)
> MB <- mvrnorm(NCHILD,rep(0,4),Sigma)
> B ?<- as.vector(t(MB))
> E ?<- rnorm(4*NCHILD,0,0)
> Y ?<- Beta + B + E
> ht.dat.2 <-
> data.frame(y=Y,age=factor(rep(4:7,NCHILD)),child=factor(rep(1:NCHILD,each=4)))
>
> # Fit with lmer():
> f2 <- lmer(y ~ 0 + age + (0+age|child),data=ht.dat.2,REML=TRUE)
> V <- VarCorr(f2)
> M <- V[[1]]
> S <- attr(V,"sc")
> covb.lmer <- M + diag(rep(S^2,4))
> attributes(covb.lmer) <- attributes(covb.lmer)["dim"]
> covb.chk <- var(MB)
>
> # Clean up:
> rm(NCHILD,Beta,Sigma,MB,B,E,Y,V,M,S)
>
> You see that if you take the residual variance component and add it to
> the diagonal of the ``child'' covariance matrix (``Sigma-hat'') you get
> (very close to) exactly the right answer. ?For NCHILD = 20 as in the
> foregoing example we get:
>
>> range(covb.lmer-covb.chk)
> [1] -1.288370e-04 ?1.467542e-05
>
> Without even a warning. ?If we jack NCHILD up to 500 we get a warning
> about false convergence (well, I did yesterday, but when I sourced
> scr.02 just now, I didn't --- ???) but the agreement is even better:
>
>> range(covb.lmer-covb.chk)
> [1] -6.019627e-06 ?6.337365e-06
>
> My question is: ?Is this behaviour reliable? ?Can I depend on this sort
> of work-around for fitting a repeated measures model where there is
> no replication, i.e. one observation per (age,child) combination, whence
> no room for an E_ij term in the model? ?Suppose the repeated measures
> model is complicated by other factors. ?E.g. instead of all girls we
> have both sexes and put a sex factor into the model. ?Or the children
> are nested within localities or countries. ?Can I still fit the model(s)
> in this way?
>
> ``Ideally'' I'd like to be able to fit the model
>
> ? ? ? ?y_ij = beta_i + B_ij
>
> i.e. suppress the residual error E_ij term (or lump it in with the
> child random effect). ? This is presumably not possible as lmer() is
> currently constituted. ?Would it/could it be possible? ?I.e. could the
> code be adjusted to accommodate this desideratum? ?Would it be a
> coding nightmare to do this? ?It would seem to me to a fairly
> *desirable* feature, since repeated measures data with no
> replications are not at all uncommon. ?But of course desirable and
> feasible are two very different things.
>
> On another tack: ?Have I (at last) got hold of the right end of the
> stick in respect of such models? ?Or is my understanding still flawed?
> Am I going at fitting repeated measures models in the right way?
> Is there another --- better --- way to do this using lmer()?
>
> I have tried a similar simulation experiment with two replicate observations
> for each child. ?(Height measured twice on each occasion; the E_ijk, k=1,2,
> now representing measurement error.) ?The answers appeared to make sense
> although in these circumstances one cannot do an exact check since the
> estimate of ``Sigma'' produced by lmer() will not be the same as var(MB)
> *because of* the measurement error.
>
> Comments? ?Suggestions? ?Enlightenment? Feedback? ?Such from the horse's
> mouth (i.e. Doug Bates) would be particularly welcome.

I'm glad to see the word "mouth" in that sentence.  Occasionally I
have been described with reference to another part of a horse's
anatomy. :-)

I appreciate your difficulty in phrasing a model such as this for
lmer.  In fact, I don't think one could reliably fit the model that
you want to fit using lmer.

If I may be so bold, I would suggest that the fault is more in the
model formulation than in the software.

You are taking what may be termed a "classical" approach to repeated
measures data, specifically longitudinal data.  You require that the
data be expressible as a subjects by occasions table and essentially
extracting means and covariances from the columns of that table.
Sometime we refer to that organization is the wide format, as opposed
to the long format where each row corresponds to a single observation
with covariates of subject and occasion.  The key is that you are
regarding age as an unordered categorical variable.

The wide format view works fine until it doesn't.  When I first
started looking at longitudinal data I saw discussions of what to do
about missing data or what to do if the nominal ages are 10, 11 and 12
years but you actually see the subject at ages 10.10, 10.92 and 12.03
years.  If you think of putting the data into the long format these
questions don't come up.  If you are missing an observation then you
delete that row.  If different subjects are recorded at different ages
then so be it.  Record the ages at which you actually saw them.

Then examine the data, in my case I would use a lattice plot such as
the enclosed, to see what a typical within-subject trajectory is.  The
plot is generated with the enclosed scripts and some models are fit.
The data are balanced with respect to the number of occasions at which
the subject's height is measured but the actual ages are somewhat
unbalanced.  One can go ahead and fit a model to these data using age
as a covariate, even though there are 14, not 9, unique ages.

The model you want to fit would have 9 distinct random effects for
each subject, which would be a saturated model.  I would claim that
you almost never need a saturated model like that.  Here I have
allowed for fixed and random effects to a third-order polynomial but
even that is probably stretching the point.  Looking at the data plot
doesn't convince me that fitting cubic terms has practical
significance, even if it is statistically significant.

As I write this I hear George Box's voice extolling the virtues of
parsimony in a model.  Whenever you have a covariate like time I think
it is a waste to convert it to a categorical covariate, even if
everyone was measured at exactly the same times or ages.

The bottom line is that you can't fit a saturated linear mixed model
with lmer reliably because lmer will always throw in one variance
parameter in addition to those generated by the random-effects terms.
So my advice is "Don't do that." :-)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Oxboys.pdf
Type: application/pdf
Size: 50046 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090402/15ba152f/attachment.pdf>

From Thierry.ONKELINX at inbo.be  Thu Apr  2 22:48:46 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 2 Apr 2009 22:48:46 +0200
Subject: [R-sig-ME] Wrong degrees of freedom in lmer model?
In-Reply-To: <48f7fe350904021251v25c5785apc9a85888e8b61fc7@mail.gmail.com>
References: <48f7fe350904021251v25c5785apc9a85888e8b61fc7@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A104064B81C4@inboexch.inbo.be>

Dear Ryan,

Targets needs 4 degrees of freedom because you omitted the intercept
from your model. A model with intercept needs only 3 degrees of freedom
because the intercept estimates the effect of the reference level.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ryan Hope
Verzonden: donderdag 2 april 2009 21:52
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Wrong degrees of freedom in lmer model?

I am trying to use the lmer function to analyze the data from the
thesis experiment. The response variable is a continuous variable,
completion time. I have 2 fixed factors, number of targets (4-levels:
4,9,14,19) and displacement per second (DPS) (3-levels: 72.42, 84.99,
88.99). I also have 3 random variables, participants, block (which
group the replicates of a combination of fixed factors), and target
displacement. The R code that I am using is listed below:

library(lme4)
datafile="http://people.rit.edu/rmh3093/master1.csv"
master1=read.table(datafile,header=T)
master1$Targets=as.factor(master1$Targets)
model=lmer(log(Completion_Time)~-1+Targets+DPS+(-1+Targets|Participant_I
D)+(1|Block)+(1|Target_Displacement),data=master1)
anova(model)

Im not even sure if the lmer model I am using is 100% correct but it
seems the best to based on what I've read on
(http://www.let.uu.nl/~Hugo.Quene/personal/multilevel/jml2008/x24lmerlog
.html).
Anyway, I do not understand the degrees of freedom reported by the
anova function based on my model (shown below):

Analysis of Variance Table
        Df Sum Sq Mean Sq    F value
Targets  4  33393    8348 39411.3500
DPS      1      2       2     7.7816

Since there are 4 levels of the Target factor, shouldn't the Df for
Targets be 3 not 4?

-Ryan

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From bates at stat.wisc.edu  Thu Apr  2 23:02:05 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 2 Apr 2009 16:02:05 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 28, Issue 4
In-Reply-To: <803284.74288.qm@web54101.mail.re2.yahoo.com>
References: <mailman.9234.1238639296.4476.r-sig-mixed-models@r-project.org>
	<803284.74288.qm@web54101.mail.re2.yahoo.com>
Message-ID: <40e66e0b0904021402uabbec42t633d020b36ff8f64@mail.gmail.com>

On Thu, Apr 2, 2009 at 4:09 AM, Iasonas Lamprianou <lamprianou at yahoo.com> wrote:

> Dear all,
> I'll re-send this request since I got no reply to the first one.
> It is an issue which I face currently with lmer and MLWin and SPSS. This problem makes me feel very undomfortable. I have one standardized variable which represents the academic performance of children, ?and I also have information about their school and their class. ?I run the model with SPSS and lmer and I get the same result (both use REML). Then I use MLWin and I get different (but more reasonable results). MLWin uses IGLS and RIGLS and MCMC (all three methods agree when I use MLWin). I hereby present my numbers:

> I run the following model:

> Linear mixed model fit by REML
> Formula: Zmg_Arxiki ~ 1 + (1 | school)
> ? Data: data
> ? AIC ? BIC logLik deviance REMLdev
> 21693 21714 -10844 ? ?21684 ? 21687
> Random effects:
> Groups ? Name ? ? ? ?Variance Std.Dev.
> school ? (Intercept) 0.37043 ?0.60863
> Residual ? ? ? ? ? ? 0.74465 ?0.86293
> Number of obs: 8448, groups: school, 47

> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) -0.13515 ? ?0.08971 ?-1.506

> However, this is NOT reasonable because the variable is a standardized variable and the variance should be 1.0!! SPSS gives the same results.
> If I run the same model in MlWin, I correctly get

And you know there are the correct results because ...?

> S2 for the school level=0.077
> S2 (error) = 0.923
> and the total is 1.0 (correct)!

> Could anyone please let me know what happens? Any help is welcome.

I don't have access to neither the data nor MLWin so I don't have the
advantage of knowing what the correct results are.  :-)

Do you know if MLWin fits using maximum likelihood (ML) or REML?  If
it uses maximum likelihood then you might try fitting the model with
lmer setting REML = FALSE and see whether that can reproduce the
"correct" results.

By the way, why is it necessary that the sum of the variance estimates
in a mixed-effects model fit to a standardized variable must add to 1?
 Especially for imbalanced data I don't think that is required.



From r.turner at auckland.ac.nz  Fri Apr  3 00:19:27 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 3 Apr 2009 11:19:27 +1300
Subject: [R-sig-ME] Repeated measures in lmer().
In-Reply-To: <40e66e0b0904021331v58b74d47t469339a8c152f2a7@mail.gmail.com>
References: <50052665-8062-4331-A543-EA02006CA5B1@auckland.ac.nz>
	<40e66e0b0904021331v58b74d47t469339a8c152f2a7@mail.gmail.com>
Message-ID: <1E3624C5-CD11-449A-9100-7C32A09561E4@auckland.ac.nz>


On 3/04/2009, at 9:31 AM, Douglas Bates wrote:

	<My original post snipped out here.>

> I'm glad to see the word "mouth" in that sentence.  Occasionally I
> have been described with reference to another part of a horse's
> anatomy. :-)

	I can't imagine anyone being so ***rude***!  Especially
	not on ***this*** list! :-)

> I appreciate your difficulty in phrasing a model such as this for
> lmer.  In fact, I don't think one could reliably fit the model that
> you want to fit using lmer.

	That's what I was afraid of.  Tossing and turning on my bed
	of pain last night I realized that even though I could jigger
	the estimate of the within-child covariance matrix to get it
	right, any inferences based on such a fit would probably be
	all out to luntch.

> If I may be so bold, I would suggest that the fault is more in the
> model formulation than in the software.

	I cheerfully admit that the model is shonky.  But it was/is
	a *toy* model to illustrate the problem.  I shouldn't have
	used ``age'' as the fixed effect.  I cobbled together my
	toy example rather too quickly and with too little creativity.

> You are taking what may be termed a "classical" approach to repeated
> measures data, specifically longitudinal data.  You require that the
> data be expressible as a subjects by occasions table and essentially
> extracting means and covariances from the columns of that table.
> Sometime we refer to that organization is the wide format, as opposed
> to the long format where each row corresponds to a single observation
> with covariates of subject and occasion.  The key is that you are
> regarding age as an unordered categorical variable.

	In the real problem I am now thinking that I would want to
	consider the ``real'' variable corresponding to age to be
	an ***ordered*** categorical variable.  See below.  But
	I'm all at sea with ordered factors. :-(
>
> The wide format view works fine until it doesn't.  When I first
> started looking at longitudinal data I saw discussions of what to do
> about missing data or what to do if the nominal ages are 10, 11 and 12
> years but you actually see the subject at ages 10.10, 10.92 and 12.03
> years.  If you think of putting the data into the long format these
> questions don't come up.  If you are missing an observation then you
> delete that row.  If different subjects are recorded at different ages
> then so be it.  Record the ages at which you actually saw them.
>
> Then examine the data, in my case I would use a lattice plot such as
> the enclosed, to see what a typical within-subject trajectory is.  The
> plot is generated with the enclosed scripts and some models are fit.
> The data are balanced with respect to the number of occasions at which
> the subject's height is measured but the actual ages are somewhat
> unbalanced.  One can go ahead and fit a model to these data using age
> as a covariate, even though there are 14, not 9, unique ages.
>
> The model you want to fit would have 9 distinct random effects for
> each subject, which would be a saturated model.  I would claim that
> you almost never need a saturated model like that.  Here I have
> allowed for fixed and random effects to a third-order polynomial but
> even that is probably stretching the point.  Looking at the data plot
> doesn't convince me that fitting cubic terms has practical
> significance, even if it is statistically significant.
>
> As I write this I hear George Box's voice extolling the virtues of
> parsimony in a model.  Whenever you have a covariate like time I think
> it is a waste to convert it to a categorical covariate, even if
> everyone was measured at exactly the same times or ages.
>
> The bottom line is that you can't fit a saturated linear mixed model
> with lmer reliably because lmer will always throw in one variance
> parameter in addition to those generated by the random-effects terms.
> So my advice is "Don't do that." :-)

	Okay, I won't.  But in my ``real'' data the fixed effect (the
	one involving repeated measures) is not age but rather ``school
	year'' (or rather --- more complicatedly still --- ``school year
	gap''.  My clients are interested in the differences in test
	scores between the end of year 6 and the beginning of year 6,
	the beginning of year 7 and the end of year 6, and the end of
	year 7 and the beginning of year 7.  The three gaps in

		|---year 6---|---summer---|---year 7---|

	I didn't want to muddy the waters in my toy example by trying
	to explain all this complication.  (And the response variable
	is test scores, not heights! So we can have decreases which
	means negative values of the response.)

	Moreover I have a bunch of other variates to take into consideration;
	sex, ethnicity, first language (fixed effects) and school (random
	effect within which children are nested).

	I thought I should get my head around the ultra-simple scenario
	described in my toy example before I tackled the messiness of reality.

	So I have the variable ``gap'' (with three values) instead of the
	age variable that I used in my toy example.  It seems to me that
	``gap'' ***cannot*** be treated as a numeric variable, like age.

	So how should I treat it?  It would seem to make sense to treat it
	as an ***ordered*** factor.  Bozhemoi!  I've never understood ordered
	factors either. :-(

	Okay, s'pose I have a data frame with columns: ID, gap, test.res, sex,
	ethnicity, language, school.  Let's ignore all but the first three
	columns to start with to keep things simple.  As indicated above I am
	thinking of taking ``gap'' to be an ordered factor with levels 1, 2,  
and 3.

	Can you suggest a sensible recipe or two that I could try to get myself
	started with?

	I'm unclear as to the covariance structure induced or assumed in the  
polynomial
	models that you have fitted to the Oxboys data.  There are, for each  
boy,
	9 observations of the boy's height, at various ages.  If we let the  
heights for
	a particular boy be (H_1,...,H_9) what can we say --- or what are we  
assuming ---
	about, e.g., Cov(H_3,H_7)?  Is this expressed as some function of  
(age_3 - age_7)
	for that boy?  Or do these covariances not come into the picture at  
all?

	Grateful as always for enlightenment.

		cheers,

			Rolf

P. S.  If anyone wants to have a go at analyzing the real data ..... :-)

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From David.Duffy at qimr.edu.au  Fri Apr  3 04:45:54 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 3 Apr 2009 12:45:54 +1000 (EST)
Subject: [R-sig-ME] glmer vs. MCMCglmm
In-Reply-To: <5BD07134-5DE9-47A2-8A60-2DC628A38AD7@ed.ac.uk>
References: <5BD07134-5DE9-47A2-8A60-2DC628A38AD7@ed.ac.uk>
Message-ID: <Pine.LNX.4.64.0904031110030.19213@orpheus.qimr.edu.au>

On Thu, 2 Apr 2009, Jarrod Hadfield wrote:

> Hi,
>
> As David suggested, the problem with binary data is that any residual 
> variance in the underlying probability cannot be observed, unlike other types 
> of data. For example, if data are generated according to the process
>
> y ~ binom(n=1, p=inv.logit(mu + e_i))
>
> then the data look the same irrespective of the variance of the e's:
>
> y1<-rbinom(1000, 1, inv.logit(rnorm(1000, 0, 1)))
> y2<-rbinom(1000, 1, inv.logit(rnorm(1000, 0, 10)))
>
> Because there is no information on VE (residual variance) we have to make an 
> assumption about its value.  In terms of the fit of the model to the data the 
> choice of VE should make no difference because the parameter is redundant. I 
> think (if some one could clarify this that would be great) that lmer fixes VE 
> to zero, where with MCMCglmm the user is free to fix VE at any value.  Other 
> than that I believe the models should be identical. However, as VE approaches 
> zero in MCMCglmm mixing becomes  problem, and actually when VE=0 the chain no 
> longer mixes at all.
>

I'm not sure if this is of general interest or not.  I have been playing 
with that plodiaRB example, which has the advantage of just being 
sibship/cluster data.

random intercept model
            intercept  V_RE    intraclass r   LRT V_RE=0  Wald test SD_RE=0
lmer          -0.986  0.5602  0.145 (1)
glmmML        -0.986  0.5602  0.145          35.80       33.87
Sib-pair      -1.020  0.6085  0.155 (1)                  31.60
MCMCglmm(2)   -1.173  0.8830  0.469                      34.57
MCMCglmm(3)    0.023  0.3590

ANOVA icc estimator           0.098
Tarone test = 73.61
Variance chi-square = 127.54 (df=48)

(1) taken as V/(V+pi^2/3)
(2) units set to 1
(3) units set to 0.0001

animal model
            intercept  V_A     h2
Sib-pair      -1.068  0.7956  0.195 (1)
MCMCglmm(2)   -1.339  2.2174  0.679
MCMCglmm(3)   -0.046  0.3744   . 
Solar MFT (4)   .     0.375   0.375

(1) taken as VA/(VA+pi^2/3)
(2) units set to 1
(3) units set to 0.0001
(4) Multifactorial threshold model fitted using the SOLAR package

For the one traditional geneticists model, which uses the binary (ie Pearson)
correlations and a linear model for probabilities, the heritability should
be ~0.2.  Using the other, the MFT, which (essentially) fits to the
tetrachoric correlations, it is 0.38 (the relative magnitudes are the 
usual pattern I see).  For nongeneticists, the heritability can be 
thought of as the predicted intraclass correlation for identical twins, 
here one on the observed scale, the other on the linear predictor or 
latent variable scale.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From kingsfordjones at gmail.com  Fri Apr  3 09:51:15 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Fri, 3 Apr 2009 01:51:15 -0600
Subject: [R-sig-ME] Repeated measures in lmer().
In-Reply-To: <1E3624C5-CD11-449A-9100-7C32A09561E4@auckland.ac.nz>
References: <50052665-8062-4331-A543-EA02006CA5B1@auckland.ac.nz>
	<40e66e0b0904021331v58b74d47t469339a8c152f2a7@mail.gmail.com>
	<1E3624C5-CD11-449A-9100-7C32A09561E4@auckland.ac.nz>
Message-ID: <2ad0cc110904030051s64654008i87bce147a570a53b@mail.gmail.com>

On Thu, Apr 2, 2009 at 4:19 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

[snip]
> ? ? ? ?Can you suggest a sensible recipe or two that I could try to get
> myself
> ? ? ? ?started with?
>

Hi Rolf,

Assuming your data is set up with 3 rows per student, with the
response being the change in test score over each of the three time
periods, a nice starter recipe is:

lmer(scoreChange ~ ordered(gap) + (1|school/student), data=yourDat)


Using the default polynomial contrasts for ordered factors, this will
estimate linear and quadratic fixed effects for the gap term (i.e.
does the difference in scores increase or decrease over the 3 time
periods -- linearly or quadratically?), as well as random intercepts
for schools and for students nested within schools.  Here's an
example:

 library(lme4)
 set.seed(777)
 student <- factor(rep(1:15, each=3))
 school <- factor(rep(1:5, each=9))
 scoreChange <- rnorm(45, 2^(1:3), 2) +
                            rnorm(15)[student] +
                            rnorm(5)[school]
 gap = factor(rep(1:3, 15))

 f1 <- lmer(scoreChange ~ ordered(gap) + (1|school/student))
 summary(f1)


In the example there's not enough power to (clearly) pick up on the
positive quadratic trend in the change in changes in scores over time,
but it does provide strong evidence for the linear trend (also, notice
the 0 correlation between the linear and quadratic effects -- nice and
orthogonal).

If I'm thinking about things correctly, the random effects in this
model induce two layers of compound symmetric correlation structures,
where all scores within students share a constant correlation, and all
students within schools share constant correlation.  My logic is just
an extension of the case where there is a single random grouping
factor, and y_i represents the observations in group i.  Then Var(y_i)
 = Z_i sigma(2)^2 Z'_i + sigma(1)^2 I, where Z_i is the random effects
design matrix (just a column of 1's, but it could contain covariates
or factors for random slopes), sigma(2)^2 is the group to group
variance, sigma(1)^2 is error variance, and I is the identity matrix.
So, Var(y_i) has sigma(2)^2 off-diagonal and the sum of the two
variances on the diagonal ==> compound symmetry within a group.  Then,
combining all observations, Var(y) is block diagonal with the compound
symmetric group matrices along the diagonal and 0's off-diagonal (i.e.
observations between groups are independent).

Hopefully some of that is helpful,

Kingsford Jones


> ? ? ? ?I'm unclear as to the covariance structure induced or assumed in the
> polynomial
> ? ? ? ?models that you have fitted to the Oxboys data. ?There are, for each
> boy,
> ? ? ? ?9 observations of the boy's height, at various ages. ?If we let the
> heights for
> ? ? ? ?a particular boy be (H_1,...,H_9) what can we say --- or what are we
> assuming ---
> ? ? ? ?about, e.g., Cov(H_3,H_7)? ?Is this expressed as some function of
> (age_3 - age_7)
> ? ? ? ?for that boy? ?Or do these covariances not come into the picture at
> all?
>
> ? ? ? ?Grateful as always for enlightenment.
>
> ? ? ? ? ? ? ? ?cheers,
>
> ? ? ? ? ? ? ? ? ? ? ? ?Rolf
>
> P. S. ?If anyone wants to have a go at analyzing the real data ..... :-)
>
> ######################################################################
> Attention:\ This e-mail message is privileged and confid...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lucianolasala at yahoo.com.ar  Fri Apr  3 14:17:48 2009
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Fri, 3 Apr 2009 05:17:48 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 27, Issue 36
In-Reply-To: <69F26DE2-62CD-462C-BEBD-66B820593238@ed.ac.uk>
Message-ID: <863406.62793.qm@web59906.mail.ac4.yahoo.com>


Hello Jarrod, 

Thanks for the tip. Here is my tabulated data so that maybe someone can tell me wether this is numerical instability or over-fitting that I'm seing in my model. 

, , Year = 1

Hatching_Order
Hatching     1       2       3
       0    45      33      25
       1     2       0       5

, , Year = 2

Hatching_Order
Hatching     1       2       3
       0    64      34      13
       1     3      12      11

>From this table, I was not able to diagnose mu model's problem, but hopefully someone will! 

Best 

Luciano 




--- El jue 2-abr-09, Jarrod Hadfield <j.hadfield at ed.ac.uk> escribi?:

De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Asunto: Re: R-sig-mixed-models Digest, Vol 27, Issue 36
Para: lucianolasala at yahoo.com.ar
Cc: r-sig-mixed-models at r-project.org, ken at kjbeath.com.au
Fecha: jueves, 2 de abril de 2009, 10:36 am

Hi Luciano,

Perhaps you could tabulate your results so we could see whether this  
really is an over-fitting problem or a numerical problem. Something  
like:

table(lHatching, HatchOrder, Year)

should do it.

Cheers,

Jarrod


On 1 Apr 2009, at 22:04, Luciano La Sala wrote:

>
> Dear Ken and Jarrod,
>
> Thank you very much for shedding some light on my problem!
> Besides the points you've made, I was told that I could avoid over- 
> fitting in my second model by treating the interaction term as two  
> continuous variables instead of categorical ones  
> (HatchingOrder*Year). Well, after doind so, the output says "Error  
> in asMethod(object) : matrix is not symmetric [1,2]", so I guess  
> that that is not a feasible solution to the problem either, and I  
> wonder how far should one go to find one?
>
> If my model fell prey to Hauck-Donner effect - which may be causing  
> the std.. errors to be overestimated and the signifficance of the  
> effect to be missed - maybe I just should stop turturing my data and  
> admit that it is sparse?
>
> Should you come up with any ideas, I'd be glad to hear them.
>
> Luciano
>
>
>
>
> --- El lun 30-mar-09, r-sig-mixed-models-request at r-project.org
<r-sig-mixed-models-request at r-project.org 
> > escribi?:
>
>> De: r-sig-mixed-models-request at r-project.org
<r-sig-mixed-models-request at r-project.org 
>> >
>> Asunto: R-sig-mixed-models Digest, Vol 27, Issue 36
>> Para: r-sig-mixed-models at r-project.org
>> Fecha: lunes, 30 de marzo de 2009, 6:27 pm
>> Send R-sig-mixed-models mailing list submissions to
>> 	r-sig-mixed-models at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> or, via email, send a message with subject or body
>> 'help' to
>> 	r-sig-mixed-models-request at r-project.org
>>
>> You can reach the person managing the list at
>> 	r-sig-mixed-models-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more
>> specific
>> than "Re: Contents of R-sig-mixed-models
>> digest..."
>>
>>
>> Today's Topics:
>>
>>   1. Re: Can interaction term cause Estimates and Std.
>> Errors	to
>>      be too large? (Ken Beath)
>>   2. Re: Can interaction term cause Estimates and Std.
>> Errors	to
>>      be too large? (Jarrod Hadfield)
>>   3. Re: Can interaction term cause Estimates and Std.
>> Errors	to
>>      be too large? (Ken Beath)
>>   4. Meta-analysis using lmer (Yu-Kang Tu)
>>   5. Mixed Model for Travel Distance (Chuck Cleland)
>>   6. Re: Mixed Model for Travel Distance (Dimitris
>> Rizopoulos)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Mon, 30 Mar 2009 21:08:58 +1100
>> From: Ken Beath <ken at kjbeath.com.au>
>> Subject: Re: [R-sig-ME] Can interaction term cause
>> Estimates and Std.
>> 	Errors	to be too large?
>> To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Cc: r-sig-mixed-models at r-project.org,
>> lucianolasala at yahoo.com.ar
>> Message-ID:
>> <68347D8C-AE1C-48BF-B194-D7E1DDD50B50 at kjbeath.com.au>
>> Content-Type: text/plain; charset=US-ASCII; format=flowed;
>> delsp=yes
>>
>> I meant overfitting in the sense of trying to fit too
>> complex a model,
>> which is the same as what you are describing. Gelman has
>> some papers
>> on the use of priors, one is
>>
http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>
>>  In the case of complete separation the results seem to be
>> very
>> dependent on the prior which doesn't look to be a good
>> thing. It would
>> appear much better to admit that there is insufficient data
>> to perform
>> the analysis.
>>
>> Ken
>>
>>
>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>
>>> Hi,
>>>
>>> I think it unlikely that the problem arises through
>> overfitting in
>>> the sense that there are too many parameters for the
>> amount of
>>> data.  It's more likely that the underlying
>> probabilities really are
>>> extreme for some categories causing what are also
>> known as "extreme
>>> category problems" (eg Miztal 1998 J. Dairy
>> Science 72 1557-1568):
>>> the binary variable in one or more groups is always 0
>> or 1, even
>>> though there are probably many eggs  in most
>> categories.  A solution
>>> to this type of problem is to place an informative
>> prior on the
>>> fixed effects to stop them wandering into extreme
>> values on the
>>> logit scale. For the purist this may be anathema, but
>> as a practical
>>> solution it seems to work quite well.  Having a normal
>> prior on the
>>> logit scale with mean zero and variance pi, is the
>> closest (I
>>> think?) to a uniform prior on the probability scale.
>> If there are
>>> more elegant solutions to the problem I'd be
>> interested to hear
>>> about them.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>> -- 
>>> The University of Edinburgh is a charitable body,
>> registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Mon, 30 Mar 2009 11:21:39 +0100
>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Subject: Re: [R-sig-ME] Can interaction term cause
>> Estimates and Std.
>> 	Errors	to be too large?
>> To: Ken Beath <ken at kjbeath.com.au>
>> Cc: r-sig-mixed-models at r-project.org,
>> lucianolasala at yahoo.com.ar
>> Message-ID:
>> <AC5DBE6D-DEEF-47A2-90BE-071FE9CBCC79 at ed.ac.uk>
>> Content-Type: text/plain; charset="us-ascii";
>> Format="flowed";
>> 	DelSp="yes"
>>
>> Hi Ken,
>>
>> Thanks for the reference, it looks interesting. I disagree
>> that
>> Luciano's second model should be classified as over
>> fitting. Imagine
>> this....
>>
>> y<-rbinom(100, 1, c(0.001, 0.999))
>> x<-gl(2,1,100)
>>
>> summary(glm(y~1, family="binomial"))
>> summary(glm(y~x, family="binomial"))
>>
>> There is a very high probability of complete separation,
>> the second
>> model gives non-significant p-values for the effect of x,
>> but I think
>> it would be a mistake to say the 2nd model is over-fitted
>> and should
>> be avoided.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> On 30 Mar 2009, at 11:08, Ken Beath wrote:
>>
>>> I meant overfitting in the sense of trying to fit too
>> complex a
>>> model, which is the same as what you are describing.
>> Gelman has some
>>> papers on the use of priors, one is
>>
http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>
>>> In the case of complete separation the results seem
>> to be very
>>> dependent on the prior which doesn't look to be a
>> good thing. It
>>> would appear much better to admit that there is
>> insufficient data to
>>> perform the analysis.
>>>
>>> Ken
>>>
>>>
>>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>>
>>>> Hi,
>>>>
>>>> I think it unlikely that the problem arises
>> through overfitting in
>>>> the sense that there are too many parameters for
>> the amount of
>>>> data.  It's more likely that the underlying
>> probabilities really
>>>> are extreme for some categories causing what are
>> also known as
>>>> "extreme category problems" (eg Miztal
>> 1998 J. Dairy Science 72
>>>> 1557-1568): the binary variable in one or more
>> groups is always 0
>>>> or 1, even though there are probably many eggs  in
>> most
>>>> categories.  A solution to this type of problem is
>> to place an
>>>> informative prior on the fixed effects to stop
>> them wandering into
>>>> extreme values on the logit scale. For the purist
>> this may be
>>>> anathema, but as a practical solution it seems to
>> work quite well.
>>>> Having a normal prior on the logit scale with mean
>> zero and
>>>> variance pi, is the closest (I think?) to a
>> uniform prior on the
>>>> probability scale. If there are more elegant
>> solutions to the
>>>> problem I'd be interested to hear about them.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>> -- 
>>>> The University of Edinburgh is a charitable body,
>> registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>
>> -------------- next part --------------
>> An embedded and charset-unspecified text was scrubbed...
>> Name: not available
>> URL:
>>
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090330/df46ef59/attachment-0001.pl

>> >
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Mon, 30 Mar 2009 21:50:53 +1100
>> From: Ken Beath <ken at kjbeath.com.au>
>> Subject: Re: [R-sig-ME] Can interaction term cause
>> Estimates and Std.
>> 	Errors	to be too large?
>> To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Cc: "r-sig-mixed-models at r-project.org Models"
>> 	<r-sig-mixed-models at r-project.org>,
>> lucianolasala at yahoo.com.ar
>> Message-ID:
>> <AF2C8F6D-8857-4855-BAED-8DD9B525212D at kjbeath.com.au>
>> Content-Type: text/plain; charset=US-ASCII; format=flowed;
>> delsp=yes
>>
>> On 30/03/2009, at 9:21 PM, Jarrod Hadfield wrote:
>>
>>> Hi Ken,
>>>
>>> Thanks for the reference, it looks interesting. I
>> disagree that
>>> Luciano's second model should be classified as
>> over fitting. Imagine
>>> this....
>>>
>>> y<-rbinom(100, 1, c(0.001, 0.999))
>>> x<-gl(2,1,100)
>>>
>>> summary(glm(y~1, family="binomial"))
>>> summary(glm(y~x, family="binomial"))
>>>
>>> There is a very high probability of complete
>> separation, the second
>>> model gives non-significant p-values for the effect of
>> x, but I
>>> think it would be a mistake to say the 2nd model is
>> over-fitted and
>>> should be avoided.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>
>> My original posting said "usually" and obviously
>> you can create data
>> with perfect or almost perfect correlation over a large
>> table, but in
>> practice it commonly happens because there is a small
>> table. One good
>> reason for producing some descriptive tables before
>> fitting.
>>
>> Ken
>>
>>
>>>
>>> On 30 Mar 2009, at 11:08, Ken Beath wrote:
>>>
>>>> I meant overfitting in the sense of trying to fit
>> too complex a
>>>> model, which is the same as what you are
>> describing. Gelman has
>>>> some papers on the use of priors, one is
>>
http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>
>>>> In the case of complete separation the results
>> seem to be very
>>>> dependent on the prior which doesn't look to
>> be a good thing. It
>>>> would appear much better to admit that there is
>> insufficient data
>>>> to perform the analysis.
>>>>
>>>> Ken
>>>>
>>>>
>>>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> I think it unlikely that the problem arises
>> through overfitting in
>>>>> the sense that there are too many parameters
>> for the amount of
>>>>> data.  It's more likely that the
>> underlying probabilities really
>>>>> are extreme for some categories causing what
>> are also known as
>>>>> "extreme category problems" (eg
>> Miztal 1998 J. Dairy Science 72
>>>>> 1557-1568): the binary variable in one or more
>> groups is always 0
>>>>> or 1, even though there are probably many eggs
>> in most
>>>>> categories.  A solution to this type of
>> problem is to place an
>>>>> informative prior on the fixed effects to stop
>> them wandering into
>>>>> extreme values on the logit scale. For the
>> purist this may be
>>>>> anathema, but as a practical solution it seems
>> to work quite
>>>>> well.  Having a normal prior on the logit
>> scale with mean zero and
>>>>> variance pi, is the closest (I think?) to a
>> uniform prior on the
>>>>> probability scale. If there are more elegant
>> solutions to the
>>>>> problem I'd be interested to hear about
>> them.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>> -- 
>>>>> The University of Edinburgh is a charitable
>> body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>
>>>>
>>>
>>> The University of Edinburgh is a charitable body,
>> registered in
>>> Scotland, with registration number SC005336.
>>
>>
>>
>> ------------------------------
>>
>> Message: 4
>> Date: Mon, 30 Mar 2009 18:16:46 +0100
>> From: Yu-Kang Tu <Y.K.Tu at leeds.ac.uk>
>> Subject: [R-sig-ME] Meta-analysis using lmer
>> To: "'r-sig-mixed-models at r-project.org'"
>> 	<r-sig-mixed-models at r-project.org>
>> Message-ID:
>>
	<7131EF1EF27893479833FCF59E7AAC440B3E818BE1 at HERMES9.ds.leeds.ac.uk>
>> Content-Type: text/plain; charset="us-ascii"
>>
>>
>> Hi,
>>
>> I am trying to use lme and lmer to do random effects
>> meta-analysis as described in Hox (2002) and UCLA website:
>> http://www.ats.ucla.edu/stat/mlwin/examples/ma_hox/chapter8.htm
>>
>> Basically, what I want to do is to constraint one residual
>> error variance to be unity and use the inverse of standard
>> errors as the covariate (weight) for this variance. And an
>> additional random effects terms is used to estimate the
>> between-study variation. I did take a look at the Pinheiro
>> & Bates book on varFunc, but unfortunately, I cannot
>> figure out how this can be done. Any suggestions/advices
>> will be greatly appreciated. Many thanks.
>>
>> Yu-Kang
>> --------------------------------------------
>> Dr Yu-Kang Tu
>> Senior Clinical Research Fellow
>> Division of Biostatistics, Centre for Epidemiology and
>> Biostatistics
>> Leeds Institute of Genetics, Health and Therapeutics, and
>> Department of Periodontology, Leeds Dental Institute
>> Room 8.01, Level 8, Worsley Building,
>> Clarendon Way
>> University of Leeds, LS2 9JT
>> Email: y.k.tu at leeds.ac.uk
>> Tel: +44 (0) 113 3431877
>> Fax: +44 (0) 113 3434877
>>
>>
>>
>> ------------------------------
>>
>> Message: 5
>> Date: Mon, 30 Mar 2009 13:29:15 -0400
>> From: Chuck Cleland <ccleland at optonline.net>
>> Subject: [R-sig-ME] Mixed Model for Travel Distance
>> To: r-sig-mixed-models at r-project.org
>> Message-ID: <49D1016B.8050808 at optonline.net>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> Hello:
>>  I am attempting to model the distance that clients travel
>> to a
>> treatment program.  There are 14385 clients nested in 83
>> treatment
>> programs (the grouping factor).  The raw data are in miles
>> driven from
>> the client's residence to the treatment program.  A
>> natural logarithm
>> transformation of miles driven works well to reduce the
>> positive skew in
>> miles driven.  I fit a model with lme() that looks like
>> this:
>>
>> Linear mixed-effects model fit by REML
>> Data: dist.df
>>       AIC      BIC    logLik
>>  38145.37 38319.54 -19049.68
>>
>> Random effects:
>> Formula: ~1 | PROGRAM
>>        (Intercept)  Residual
>> StdDev:   0.4268969 0.8988483
>>
>> Fixed effects: log(DIST5DZ + 1) ~ QUAD + BEAL_TRI +
>> log(RZIPAREA + 1) +
>> log(PZIPAREA + 1) + AGE.TRI + P3GEND + P5RACEX + EMPLD +
>> P13REASN +
>> METHFST + URGE.DI + WDRAW.DI + RX_30 + P7HR30
>>
>>                               Value  Std.Error    DF
>> t-value p-value
>> (Intercept)                1.2235603 0.13153231 14288
>> 9.30236  0.0000
>> QUADSouthEast              0.2100666 0.13200891    76
>> 1.59131  0.1157
>> QUADMidWest                0.2760390 0.15709516    76
>> 1.75715  0.0829
>> QUADWest                  -0.1655914 0.15536003    76
>> -1.06586  0.2899
>> BEAL_TRI250K-1M           -0.0264939 0.11724713    76
>> -0.22597  0.8218
>> BEAL_TRI<250K             -0.0965256 0.16399464    76
>> -0.58859  0.5579
>> log(RZIPAREA + 1)          0.2965304 0.00757138 14288
>> 39.16463  0.0000
>> log(PZIPAREA + 1)         -0.0042061 0.04413826    76
>> -0.09529  0.9243
>> AGE.TRI30-43              -0.0309444 0.01789442 14288
>> -1.72927  0.0838
>> AGE.TRI43-83              -0.1281177 0.02168648 14288
>> -5.90772  0.0000
>> P3GENDFemale              -0.0195289 0.01632703 14288
>> -1.19611  0.2317
>> P5RACEXLatino             -0.3527584 0.02904416 14288
>> -12.14559  0.0000
>> P5RACEXBlack              -0.5485861 0.03306146 14288
>> -16.59292  0.0000
>> P5RACEXOther              -0.1580669 0.04811350 14288
>> -3.28529  0.0010
>> EMPLDYes                   0.0098856 0.01650635 14288
>> 0.59890  0.5493
>> P13REASNYes               -0.0095057 0.01650128 14288
>> -0.57606  0.5646
>> METHFSTYes                 0.0073478 0.01672948 14288
>> 0.43921  0.6605
>> URGE.DI Strong-VeryStrong -0.0272769 0.02400068 14288
>> -1.13651  0.2558
>> WDRAW.DISevere-VerySevere  0.0012054 0.01810067 14288
>> 0.06659  0.9469
>> RX_30Yes                   0.0934411 0.02165389 14288
>> 4.31521  0.0000
>> P7HR30Yes                 -0.0408189 0.02256842 14288
>> -1.80867  0.0705
>>
>> Standardized Within-Group Residuals:
>>        Min          Q1         Med          Q3         Max
>> -4.17921640 -0.49875991  0.08672984  0.59020542  4.54644432
>>
>> Number of Observations: 14385
>> Number of Groups: 83
>>
>>  I would like to summarize the fixed effects in terms of
>> miles rather
>> than log(miles + 1).  How can that be done?  Are there
>> common
>> generalized linear mixed models for miles driven that would
>> avoid the
>> transformation and allow effects to be presented in miles?
>>
>> thanks,
>>
>> Chuck
>>
>> -- 
>> Chuck Cleland, Ph.D.
>> NDRI, Inc. (www.ndri.org)
>> 71 West 23rd Street, 8th floor
>> New York, NY 10010
>> tel: (212) 845-4495 (Tu, Th)
>> tel: (732) 512-0171 (M, W, F)
>> fax: (917) 438-0894
>>
>>
>>
>> ------------------------------
>>
>> Message: 6
>> Date: Mon, 30 Mar 2009 20:26:38 +0200
>> From: Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl>
>> Subject: Re: [R-sig-ME] Mixed Model for Travel Distance
>> To: Chuck Cleland <ccleland at optonline.net>
>> Cc: r-sig-mixed-models at r-project.org
>> Message-ID: <49D10EDE.8050501 at erasmusmc.nl>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> well, if you're only interested in the fixed effects,
>> then you can also
>> use a Generalized Estimating Equations approach that does
>> not make a
>> parametric assumption for the distribution of your error
>> terms, e.g.,
>> have a look at the 'geepack' package. Furthermore
>> and in case it is
>> relevant for your application, in GEE the estimated
>> parameters will have
>> a population interpretation, contrary to the GLMMs approach
>> in which
>> they will have a conditional on the random effects
>> interpretation.
>>
>>
>> I hope it helps.
>>
>> Best,
>> Dimitris
>>
>>
>> Chuck Cleland wrote:
>>> Hello:
>>>  I am attempting to model the distance that clients
>> travel to a
>>> treatment program.  There are 14385 clients nested in
>> 83 treatment
>>> programs (the grouping factor).  The raw data are in
>> miles driven from
>>> the client's residence to the treatment program.
>> A natural logarithm
>>> transformation of miles driven works well to reduce
>> the positive skew in
>>> miles driven.  I fit a model with lme() that looks
>> like this:
>>>
>>> Linear mixed-effects model fit by REML
>>> Data: dist.df
>>>       AIC      BIC    logLik
>>>  38145.37 38319.54 -19049.68
>>>
>>> Random effects:
>>> Formula: ~1 | PROGRAM
>>>        (Intercept)  Residual
>>> StdDev:   0.4268969 0.8988483
>>>
>>> Fixed effects: log(DIST5DZ + 1) ~ QUAD + BEAL_TRI +
>> log(RZIPAREA + 1) +
>>> log(PZIPAREA + 1) + AGE.TRI + P3GEND + P5RACEX + EMPLD
>> + P13REASN +
>>> METHFST + URGE.DI + WDRAW.DI + RX_30 + P7HR30
>>>
>>>                               Value  Std.Error    DF
>> t-value p-value
>>> (Intercept)                1.2235603 0.13153231 14288
>> 9.30236  0.0000
>>> QUADSouthEast              0.2100666 0.13200891    76
>> 1.59131  0.1157
>>> QUADMidWest                0.2760390 0.15709516    76
>> 1.75715  0.0829
>>> QUADWest                  -0.1655914 0.15536003    76
>> -1.06586  0.2899
>>> BEAL_TRI250K-1M           -0.0264939 0.11724713    76
>> -0.22597  0.8218
>>> BEAL_TRI<250K             -0.0965256 0.16399464
>> 76  -0.58859  0.5579
>>> log(RZIPAREA + 1)          0.2965304 0.00757138 14288
>> 39.16463  0.0000
>>> log(PZIPAREA + 1)         -0.0042061 0.04413826    76
>> -0.09529  0.9243
>>> AGE.TRI30-43              -0.0309444 0.01789442 14288
>> -1.72927  0.0838
>>> AGE.TRI43-83              -0.1281177 0.02168648 14288
>> -5.90772  0.0000
>>> P3GENDFemale              -0.0195289 0.01632703 14288
>> -1.19611  0.2317
>>> P5RACEXLatino             -0.3527584 0.02904416 14288
>> -12.14559  0.0000
>>> P5RACEXBlack              -0.5485861 0.03306146 14288
>> -16.59292  0.0000
>>> P5RACEXOther              -0.1580669 0.04811350 14288
>> -3.28529  0.0010
>>> EMPLDYes                   0.0098856 0.01650635 14288
>> 0.59890  0.5493
>>> P13REASNYes               -0.0095057 0.01650128 14288
>> -0.57606  0.5646
>>> METHFSTYes                 0.0073478 0.01672948 14288
>> 0.43921  0.6605
>>> URGE.DI Strong-VeryStrong -0.0272769 0.02400068 14288
>> -1.13651  0.2558
>>> WDRAW.DISevere-VerySevere  0.0012054 0.01810067 14288
>> 0.06659  0.9469
>>> RX_30Yes                   0.0934411 0.02165389 14288
>> 4.31521  0.0000
>>> P7HR30Yes                 -0.0408189 0.02256842 14288
>> -1.80867  0.0705
>>>
>>> Standardized Within-Group Residuals:
>>>        Min          Q1         Med          Q3
>> Max
>>> -4.17921640 -0.49875991  0.08672984  0.59020542
>> 4.54644432
>>>
>>> Number of Observations: 14385
>>> Number of Groups: 83
>>>
>>>  I would like to summarize the fixed effects in terms
>> of miles rather
>>> than log(miles + 1).  How can that be done?  Are there
>> common
>>> generalized linear mixed models for miles driven that
>> would avoid the
>>> transformation and allow effects to be presented in
>> miles?
>>>
>>> thanks,
>>>
>>> Chuck
>>>
>>
>> -- 
>> Dimitris Rizopoulos
>> Assistant Professor
>> Department of Biostatistics
>> Erasmus University Medical Center
>>
>> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
>> Tel: +31/(0)10/7043478
>> Fax: +31/(0)10/7043014
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> End of R-sig-mixed-models Digest, Vol 27, Issue 36
>> **************************************************
>
>
>      Yahoo! Cocina
> Recetas pr?cticas y comida saludable
> http://ar.mujer.yahoo.com/cocina/
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.




      Yahoo! Cocina
Recetas pr?cticas y comida saludable
http://ar.mujer.yahoo.com/cocina/



From j.hadfield at ed.ac.uk  Fri Apr  3 14:55:22 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 3 Apr 2009 13:55:22 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 27, Issue 36
In-Reply-To: <863406.62793.qm@web59906.mail.ac4.yahoo.com>
References: <863406.62793.qm@web59906.mail.ac4.yahoo.com>
Message-ID: <ED5B9977-D615-4786-97D1-EDBF55F1D499@ed.ac.uk>

Hi,

There's a reasonable amount of data (the least replicated category has  
24 data points - Year2Egg3) so I would suggest this is not so much to  
do with over-fitting but more to do with the underlying probabilities  
for some categories being extreme. The paper that Ken sent round  
provides a Bayesian solution to the problem by placing weak priors on  
the fixed effects.  Cauchy/Scaled-t priors were recommended in that  
paper, and this can presumably be done in WinBUGS and maybe JAGS(?).  
Normal priors can be used in MCMCglmm or rhierBinLogit in the bayesm  
package, and these can be set to be weakly informative on the  
probability scale. For MCMCglmm at least,  the choice of prior will  
depend on your choice of residual variance.

Cheers,

Jarrod




On 3 Apr 2009, at 13:17, Luciano La Sala wrote:

>
> Hello Jarrod,
>
> Thanks for the tip. Here is my tabulated data so that maybe someone  
> can tell me wether this is numerical instability or over-fitting  
> that I'm seing in my model.
>
> , , Year = 1
>
> Hatching_Order
> Hatching     1       2       3
>       0    45      33      25
>       1     2       0       5
>
> , , Year = 2
>
> Hatching_Order
> Hatching     1       2       3
>       0    64      34      13
>       1     3      12      11
>
> From this table, I was not able to diagnose mu model's problem, but  
> hopefully someone will!
>
> Best
>
> Luciano
>
>
>
>
> --- El jue 2-abr-09, Jarrod Hadfield <j.hadfield at ed.ac.uk> escribi?:
>
> De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Asunto: Re: R-sig-mixed-models Digest, Vol 27, Issue 36
> Para: lucianolasala at yahoo.com.ar
> Cc: r-sig-mixed-models at r-project.org, ken at kjbeath.com.au
> Fecha: jueves, 2 de abril de 2009, 10:36 am
>
> Hi Luciano,
>
> Perhaps you could tabulate your results so we could see whether this
> really is an over-fitting problem or a numerical problem. Something
> like:
>
> table(lHatching, HatchOrder, Year)
>
> should do it.
>
> Cheers,
>
> Jarrod
>
>
> On 1 Apr 2009, at 22:04, Luciano La Sala wrote:
>
>>
>> Dear Ken and Jarrod,
>>
>> Thank you very much for shedding some light on my problem!
>> Besides the points you've made, I was told that I could avoid over-
>> fitting in my second model by treating the interaction term as two
>> continuous variables instead of categorical ones
>> (HatchingOrder*Year). Well, after doind so, the output says "Error
>> in asMethod(object) : matrix is not symmetric [1,2]", so I guess
>> that that is not a feasible solution to the problem either, and I
>> wonder how far should one go to find one?
>>
>> If my model fell prey to Hauck-Donner effect - which may be causing
>> the std.. errors to be overestimated and the signifficance of the
>> effect to be missed - maybe I just should stop turturing my data and
>> admit that it is sparse?
>>
>> Should you come up with any ideas, I'd be glad to hear them.
>>
>> Luciano
>>
>>
>>
>>
>> --- El lun 30-mar-09, r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org
>>> escribi?:
>>
>>> De: r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org
>>>>
>>> Asunto: R-sig-mixed-models Digest, Vol 27, Issue 36
>>> Para: r-sig-mixed-models at r-project.org
>>> Fecha: lunes, 30 de marzo de 2009, 6:27 pm
>>> Send R-sig-mixed-models mailing list submissions to
>>> 	r-sig-mixed-models at r-project.org
>>>
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> or, via email, send a message with subject or body
>>> 'help' to
>>> 	r-sig-mixed-models-request at r-project.org
>>>
>>> You can reach the person managing the list at
>>> 	r-sig-mixed-models-owner at r-project.org
>>>
>>> When replying, please edit your Subject line so it is more
>>> specific
>>> than "Re: Contents of R-sig-mixed-models
>>> digest..."
>>>
>>>
>>> Today's Topics:
>>>
>>>  1. Re: Can interaction term cause Estimates and Std.
>>> Errors	to
>>>     be too large? (Ken Beath)
>>>  2. Re: Can interaction term cause Estimates and Std.
>>> Errors	to
>>>     be too large? (Jarrod Hadfield)
>>>  3. Re: Can interaction term cause Estimates and Std.
>>> Errors	to
>>>     be too large? (Ken Beath)
>>>  4. Meta-analysis using lmer (Yu-Kang Tu)
>>>  5. Mixed Model for Travel Distance (Chuck Cleland)
>>>  6. Re: Mixed Model for Travel Distance (Dimitris
>>> Rizopoulos)
>>>
>>>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Mon, 30 Mar 2009 21:08:58 +1100
>>> From: Ken Beath <ken at kjbeath.com.au>
>>> Subject: Re: [R-sig-ME] Can interaction term cause
>>> Estimates and Std.
>>> 	Errors	to be too large?
>>> To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> Cc: r-sig-mixed-models at r-project.org,
>>> lucianolasala at yahoo.com.ar
>>> Message-ID:
>>> <68347D8C-AE1C-48BF-B194-D7E1DDD50B50 at kjbeath.com.au>
>>> Content-Type: text/plain; charset=US-ASCII; format=flowed;
>>> delsp=yes
>>>
>>> I meant overfitting in the sense of trying to fit too
>>> complex a model,
>>> which is the same as what you are describing. Gelman has
>>> some papers
>>> on the use of priors, one is
>>>
> http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>>
>>> In the case of complete separation the results seem to be
>>> very
>>> dependent on the prior which doesn't look to be a good
>>> thing. It would
>>> appear much better to admit that there is insufficient data
>>> to perform
>>> the analysis.
>>>
>>> Ken
>>>
>>>
>>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>>
>>>> Hi,
>>>>
>>>> I think it unlikely that the problem arises through
>>> overfitting in
>>>> the sense that there are too many parameters for the
>>> amount of
>>>> data.  It's more likely that the underlying
>>> probabilities really are
>>>> extreme for some categories causing what are also
>>> known as "extreme
>>>> category problems" (eg Miztal 1998 J. Dairy
>>> Science 72 1557-1568):
>>>> the binary variable in one or more groups is always 0
>>> or 1, even
>>>> though there are probably many eggs  in most
>>> categories.  A solution
>>>> to this type of problem is to place an informative
>>> prior on the
>>>> fixed effects to stop them wandering into extreme
>>> values on the
>>>> logit scale. For the purist this may be anathema, but
>>> as a practical
>>>> solution it seems to work quite well.  Having a normal
>>> prior on the
>>>> logit scale with mean zero and variance pi, is the
>>> closest (I
>>>> think?) to a uniform prior on the probability scale.
>>> If there are
>>>> more elegant solutions to the problem I'd be
>>> interested to hear
>>>> about them.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>> -- 
>>>> The University of Edinburgh is a charitable body,
>>> registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 2
>>> Date: Mon, 30 Mar 2009 11:21:39 +0100
>>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> Subject: Re: [R-sig-ME] Can interaction term cause
>>> Estimates and Std.
>>> 	Errors	to be too large?
>>> To: Ken Beath <ken at kjbeath.com.au>
>>> Cc: r-sig-mixed-models at r-project.org,
>>> lucianolasala at yahoo.com.ar
>>> Message-ID:
>>> <AC5DBE6D-DEEF-47A2-90BE-071FE9CBCC79 at ed.ac.uk>
>>> Content-Type: text/plain; charset="us-ascii";
>>> Format="flowed";
>>> 	DelSp="yes"
>>>
>>> Hi Ken,
>>>
>>> Thanks for the reference, it looks interesting. I disagree
>>> that
>>> Luciano's second model should be classified as over
>>> fitting. Imagine
>>> this....
>>>
>>> y<-rbinom(100, 1, c(0.001, 0.999))
>>> x<-gl(2,1,100)
>>>
>>> summary(glm(y~1, family="binomial"))
>>> summary(glm(y~x, family="binomial"))
>>>
>>> There is a very high probability of complete separation,
>>> the second
>>> model gives non-significant p-values for the effect of x,
>>> but I think
>>> it would be a mistake to say the 2nd model is over-fitted
>>> and should
>>> be avoided.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>> On 30 Mar 2009, at 11:08, Ken Beath wrote:
>>>
>>>> I meant overfitting in the sense of trying to fit too
>>> complex a
>>>> model, which is the same as what you are describing.
>>> Gelman has some
>>>> papers on the use of priors, one is
>>>
> http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>>
>>>> In the case of complete separation the results seem
>>> to be very
>>>> dependent on the prior which doesn't look to be a
>>> good thing. It
>>>> would appear much better to admit that there is
>>> insufficient data to
>>>> perform the analysis.
>>>>
>>>> Ken
>>>>
>>>>
>>>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> I think it unlikely that the problem arises
>>> through overfitting in
>>>>> the sense that there are too many parameters for
>>> the amount of
>>>>> data.  It's more likely that the underlying
>>> probabilities really
>>>>> are extreme for some categories causing what are
>>> also known as
>>>>> "extreme category problems" (eg Miztal
>>> 1998 J. Dairy Science 72
>>>>> 1557-1568): the binary variable in one or more
>>> groups is always 0
>>>>> or 1, even though there are probably many eggs  in
>>> most
>>>>> categories.  A solution to this type of problem is
>>> to place an
>>>>> informative prior on the fixed effects to stop
>>> them wandering into
>>>>> extreme values on the logit scale. For the purist
>>> this may be
>>>>> anathema, but as a practical solution it seems to
>>> work quite well.
>>>>> Having a normal prior on the logit scale with mean
>>> zero and
>>>>> variance pi, is the closest (I think?) to a
>>> uniform prior on the
>>>>> probability scale. If there are more elegant
>>> solutions to the
>>>>> problem I'd be interested to hear about them.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>> -- 
>>>>> The University of Edinburgh is a charitable body,
>>> registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>
>>>>
>>>
>>> -------------- next part --------------
>>> An embedded and charset-unspecified text was scrubbed...
>>> Name: not available
>>> URL:
>>>
> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090330/df46ef59/attachment-0001.pl
>
>>>>
>>>
>>> ------------------------------
>>>
>>> Message: 3
>>> Date: Mon, 30 Mar 2009 21:50:53 +1100
>>> From: Ken Beath <ken at kjbeath.com.au>
>>> Subject: Re: [R-sig-ME] Can interaction term cause
>>> Estimates and Std.
>>> 	Errors	to be too large?
>>> To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> Cc: "r-sig-mixed-models at r-project.org Models"
>>> 	<r-sig-mixed-models at r-project.org>,
>>> lucianolasala at yahoo.com.ar
>>> Message-ID:
>>> <AF2C8F6D-8857-4855-BAED-8DD9B525212D at kjbeath.com.au>
>>> Content-Type: text/plain; charset=US-ASCII; format=flowed;
>>> delsp=yes
>>>
>>> On 30/03/2009, at 9:21 PM, Jarrod Hadfield wrote:
>>>
>>>> Hi Ken,
>>>>
>>>> Thanks for the reference, it looks interesting. I
>>> disagree that
>>>> Luciano's second model should be classified as
>>> over fitting. Imagine
>>>> this....
>>>>
>>>> y<-rbinom(100, 1, c(0.001, 0.999))
>>>> x<-gl(2,1,100)
>>>>
>>>> summary(glm(y~1, family="binomial"))
>>>> summary(glm(y~x, family="binomial"))
>>>>
>>>> There is a very high probability of complete
>>> separation, the second
>>>> model gives non-significant p-values for the effect of
>>> x, but I
>>>> think it would be a mistake to say the 2nd model is
>>> over-fitted and
>>>> should be avoided.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>
>>> My original posting said "usually" and obviously
>>> you can create data
>>> with perfect or almost perfect correlation over a large
>>> table, but in
>>> practice it commonly happens because there is a small
>>> table. One good
>>> reason for producing some descriptive tables before
>>> fitting.
>>>
>>> Ken
>>>
>>>
>>>>
>>>> On 30 Mar 2009, at 11:08, Ken Beath wrote:
>>>>
>>>>> I meant overfitting in the sense of trying to fit
>>> too complex a
>>>>> model, which is the same as what you are
>>> describing. Gelman has
>>>>> some papers on the use of priors, one is
>>>
> http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1231424214
>>>
>>>>> In the case of complete separation the results
>>> seem to be very
>>>>> dependent on the prior which doesn't look to
>>> be a good thing. It
>>>>> would appear much better to admit that there is
>>> insufficient data
>>>>> to perform the analysis.
>>>>>
>>>>> Ken
>>>>>
>>>>>
>>>>> On 30/03/2009, at 7:48 PM, Jarrod Hadfield wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I think it unlikely that the problem arises
>>> through overfitting in
>>>>>> the sense that there are too many parameters
>>> for the amount of
>>>>>> data.  It's more likely that the
>>> underlying probabilities really
>>>>>> are extreme for some categories causing what
>>> are also known as
>>>>>> "extreme category problems" (eg
>>> Miztal 1998 J. Dairy Science 72
>>>>>> 1557-1568): the binary variable in one or more
>>> groups is always 0
>>>>>> or 1, even though there are probably many eggs
>>> in most
>>>>>> categories.  A solution to this type of
>>> problem is to place an
>>>>>> informative prior on the fixed effects to stop
>>> them wandering into
>>>>>> extreme values on the logit scale. For the
>>> purist this may be
>>>>>> anathema, but as a practical solution it seems
>>> to work quite
>>>>>> well.  Having a normal prior on the logit
>>> scale with mean zero and
>>>>>> variance pi, is the closest (I think?) to a
>>> uniform prior on the
>>>>>> probability scale. If there are more elegant
>>> solutions to the
>>>>>> problem I'd be interested to hear about
>>> them.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>> -- 
>>>>>> The University of Edinburgh is a charitable
>>> body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>> The University of Edinburgh is a charitable body,
>>> registered in
>>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 4
>>> Date: Mon, 30 Mar 2009 18:16:46 +0100
>>> From: Yu-Kang Tu <Y.K.Tu at leeds.ac.uk>
>>> Subject: [R-sig-ME] Meta-analysis using lmer
>>> To: "'r-sig-mixed-models at r-project.org'"
>>> 	<r-sig-mixed-models at r-project.org>
>>> Message-ID:
>>>
> 	<7131EF1EF27893479833FCF59E7AAC440B3E818BE1 at HERMES9.ds.leeds.ac.uk>
>>> Content-Type: text/plain; charset="us-ascii"
>>>
>>>
>>> Hi,
>>>
>>> I am trying to use lme and lmer to do random effects
>>> meta-analysis as described in Hox (2002) and UCLA website:
>>> http://www.ats.ucla.edu/stat/mlwin/examples/ma_hox/chapter8.htm
>>>
>>> Basically, what I want to do is to constraint one residual
>>> error variance to be unity and use the inverse of standard
>>> errors as the covariate (weight) for this variance. And an
>>> additional random effects terms is used to estimate the
>>> between-study variation. I did take a look at the Pinheiro
>>> & Bates book on varFunc, but unfortunately, I cannot
>>> figure out how this can be done. Any suggestions/advices
>>> will be greatly appreciated. Many thanks.
>>>
>>> Yu-Kang
>>> --------------------------------------------
>>> Dr Yu-Kang Tu
>>> Senior Clinical Research Fellow
>>> Division of Biostatistics, Centre for Epidemiology and
>>> Biostatistics
>>> Leeds Institute of Genetics, Health and Therapeutics, and
>>> Department of Periodontology, Leeds Dental Institute
>>> Room 8.01, Level 8, Worsley Building,
>>> Clarendon Way
>>> University of Leeds, LS2 9JT
>>> Email: y.k.tu at leeds.ac.uk
>>> Tel: +44 (0) 113 3431877
>>> Fax: +44 (0) 113 3434877
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 5
>>> Date: Mon, 30 Mar 2009 13:29:15 -0400
>>> From: Chuck Cleland <ccleland at optonline.net>
>>> Subject: [R-sig-ME] Mixed Model for Travel Distance
>>> To: r-sig-mixed-models at r-project.org
>>> Message-ID: <49D1016B.8050808 at optonline.net>
>>> Content-Type: text/plain; charset=ISO-8859-1
>>>
>>> Hello:
>>> I am attempting to model the distance that clients travel
>>> to a
>>> treatment program.  There are 14385 clients nested in 83
>>> treatment
>>> programs (the grouping factor).  The raw data are in miles
>>> driven from
>>> the client's residence to the treatment program.  A
>>> natural logarithm
>>> transformation of miles driven works well to reduce the
>>> positive skew in
>>> miles driven.  I fit a model with lme() that looks like
>>> this:
>>>
>>> Linear mixed-effects model fit by REML
>>> Data: dist.df
>>>      AIC      BIC    logLik
>>> 38145.37 38319.54 -19049.68
>>>
>>> Random effects:
>>> Formula: ~1 | PROGRAM
>>>       (Intercept)  Residual
>>> StdDev:   0.4268969 0.8988483
>>>
>>> Fixed effects: log(DIST5DZ + 1) ~ QUAD + BEAL_TRI +
>>> log(RZIPAREA + 1) +
>>> log(PZIPAREA + 1) + AGE.TRI + P3GEND + P5RACEX + EMPLD +
>>> P13REASN +
>>> METHFST + URGE.DI + WDRAW.DI + RX_30 + P7HR30
>>>
>>>                              Value  Std.Error    DF
>>> t-value p-value
>>> (Intercept)                1.2235603 0.13153231 14288
>>> 9.30236  0.0000
>>> QUADSouthEast              0.2100666 0.13200891    76
>>> 1.59131  0.1157
>>> QUADMidWest                0.2760390 0.15709516    76
>>> 1.75715  0.0829
>>> QUADWest                  -0.1655914 0.15536003    76
>>> -1.06586  0.2899
>>> BEAL_TRI250K-1M           -0.0264939 0.11724713    76
>>> -0.22597  0.8218
>>> BEAL_TRI<250K             -0.0965256 0.16399464    76
>>> -0.58859  0.5579
>>> log(RZIPAREA + 1)          0.2965304 0.00757138 14288
>>> 39.16463  0.0000
>>> log(PZIPAREA + 1)         -0.0042061 0.04413826    76
>>> -0.09529  0.9243
>>> AGE.TRI30-43              -0.0309444 0.01789442 14288
>>> -1.72927  0.0838
>>> AGE.TRI43-83              -0.1281177 0.02168648 14288
>>> -5.90772  0.0000
>>> P3GENDFemale              -0.0195289 0.01632703 14288
>>> -1.19611  0.2317
>>> P5RACEXLatino             -0.3527584 0.02904416 14288
>>> -12.14559  0.0000
>>> P5RACEXBlack              -0.5485861 0.03306146 14288
>>> -16.59292  0.0000
>>> P5RACEXOther              -0.1580669 0.04811350 14288
>>> -3.28529  0.0010
>>> EMPLDYes                   0.0098856 0.01650635 14288
>>> 0.59890  0.5493
>>> P13REASNYes               -0.0095057 0.01650128 14288
>>> -0.57606  0.5646
>>> METHFSTYes                 0.0073478 0.01672948 14288
>>> 0.43921  0.6605
>>> URGE.DI Strong-VeryStrong -0.0272769 0.02400068 14288
>>> -1.13651  0.2558
>>> WDRAW.DISevere-VerySevere  0.0012054 0.01810067 14288
>>> 0.06659  0.9469
>>> RX_30Yes                   0.0934411 0.02165389 14288
>>> 4.31521  0.0000
>>> P7HR30Yes                 -0.0408189 0.02256842 14288
>>> -1.80867  0.0705
>>>
>>> Standardized Within-Group Residuals:
>>>       Min          Q1         Med          Q3         Max
>>> -4.17921640 -0.49875991  0.08672984  0.59020542  4.54644432
>>>
>>> Number of Observations: 14385
>>> Number of Groups: 83
>>>
>>> I would like to summarize the fixed effects in terms of
>>> miles rather
>>> than log(miles + 1).  How can that be done?  Are there
>>> common
>>> generalized linear mixed models for miles driven that would
>>> avoid the
>>> transformation and allow effects to be presented in miles?
>>>
>>> thanks,
>>>
>>> Chuck
>>>
>>> -- 
>>> Chuck Cleland, Ph.D.
>>> NDRI, Inc. (www.ndri.org)
>>> 71 West 23rd Street, 8th floor
>>> New York, NY 10010
>>> tel: (212) 845-4495 (Tu, Th)
>>> tel: (732) 512-0171 (M, W, F)
>>> fax: (917) 438-0894
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 6
>>> Date: Mon, 30 Mar 2009 20:26:38 +0200
>>> From: Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl>
>>> Subject: Re: [R-sig-ME] Mixed Model for Travel Distance
>>> To: Chuck Cleland <ccleland at optonline.net>
>>> Cc: r-sig-mixed-models at r-project.org
>>> Message-ID: <49D10EDE.8050501 at erasmusmc.nl>
>>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>>
>>> well, if you're only interested in the fixed effects,
>>> then you can also
>>> use a Generalized Estimating Equations approach that does
>>> not make a
>>> parametric assumption for the distribution of your error
>>> terms, e.g.,
>>> have a look at the 'geepack' package. Furthermore
>>> and in case it is
>>> relevant for your application, in GEE the estimated
>>> parameters will have
>>> a population interpretation, contrary to the GLMMs approach
>>> in which
>>> they will have a conditional on the random effects
>>> interpretation.
>>>
>>>
>>> I hope it helps.
>>>
>>> Best,
>>> Dimitris
>>>
>>>
>>> Chuck Cleland wrote:
>>>> Hello:
>>>> I am attempting to model the distance that clients
>>> travel to a
>>>> treatment program.  There are 14385 clients nested in
>>> 83 treatment
>>>> programs (the grouping factor).  The raw data are in
>>> miles driven from
>>>> the client's residence to the treatment program.
>>> A natural logarithm
>>>> transformation of miles driven works well to reduce
>>> the positive skew in
>>>> miles driven.  I fit a model with lme() that looks
>>> like this:
>>>>
>>>> Linear mixed-effects model fit by REML
>>>> Data: dist.df
>>>>      AIC      BIC    logLik
>>>> 38145.37 38319.54 -19049.68
>>>>
>>>> Random effects:
>>>> Formula: ~1 | PROGRAM
>>>>       (Intercept)  Residual
>>>> StdDev:   0.4268969 0.8988483
>>>>
>>>> Fixed effects: log(DIST5DZ + 1) ~ QUAD + BEAL_TRI +
>>> log(RZIPAREA + 1) +
>>>> log(PZIPAREA + 1) + AGE.TRI + P3GEND + P5RACEX + EMPLD
>>> + P13REASN +
>>>> METHFST + URGE.DI + WDRAW.DI + RX_30 + P7HR30
>>>>
>>>>                              Value  Std.Error    DF
>>> t-value p-value
>>>> (Intercept)                1.2235603 0.13153231 14288
>>> 9.30236  0.0000
>>>> QUADSouthEast              0.2100666 0.13200891    76
>>> 1.59131  0.1157
>>>> QUADMidWest                0.2760390 0.15709516    76
>>> 1.75715  0.0829
>>>> QUADWest                  -0.1655914 0.15536003    76
>>> -1.06586  0.2899
>>>> BEAL_TRI250K-1M           -0.0264939 0.11724713    76
>>> -0.22597  0.8218
>>>> BEAL_TRI<250K             -0.0965256 0.16399464
>>> 76  -0.58859  0.5579
>>>> log(RZIPAREA + 1)          0.2965304 0.00757138 14288
>>> 39.16463  0.0000
>>>> log(PZIPAREA + 1)         -0.0042061 0.04413826    76
>>> -0.09529  0.9243
>>>> AGE.TRI30-43              -0.0309444 0.01789442 14288
>>> -1.72927  0.0838
>>>> AGE.TRI43-83              -0.1281177 0.02168648 14288
>>> -5.90772  0.0000
>>>> P3GENDFemale              -0.0195289 0.01632703 14288
>>> -1.19611  0.2317
>>>> P5RACEXLatino             -0.3527584 0.02904416 14288
>>> -12.14559  0.0000
>>>> P5RACEXBlack              -0.5485861 0.03306146 14288
>>> -16.59292  0.0000
>>>> P5RACEXOther              -0.1580669 0.04811350 14288
>>> -3.28529  0.0010
>>>> EMPLDYes                   0.0098856 0.01650635 14288
>>> 0.59890  0.5493
>>>> P13REASNYes               -0.0095057 0.01650128 14288
>>> -0.57606  0.5646
>>>> METHFSTYes                 0.0073478 0.01672948 14288
>>> 0.43921  0.6605
>>>> URGE.DI Strong-VeryStrong -0.0272769 0.02400068 14288
>>> -1.13651  0.2558
>>>> WDRAW.DISevere-VerySevere  0.0012054 0.01810067 14288
>>> 0.06659  0.9469
>>>> RX_30Yes                   0.0934411 0.02165389 14288
>>> 4.31521  0.0000
>>>> P7HR30Yes                 -0.0408189 0.02256842 14288
>>> -1.80867  0.0705
>>>>
>>>> Standardized Within-Group Residuals:
>>>>       Min          Q1         Med          Q3
>>> Max
>>>> -4.17921640 -0.49875991  0.08672984  0.59020542
>>> 4.54644432
>>>>
>>>> Number of Observations: 14385
>>>> Number of Groups: 83
>>>>
>>>> I would like to summarize the fixed effects in terms
>>> of miles rather
>>>> than log(miles + 1).  How can that be done?  Are there
>>> common
>>>> generalized linear mixed models for miles driven that
>>> would avoid the
>>>> transformation and allow effects to be presented in
>>> miles?
>>>>
>>>> thanks,
>>>>
>>>> Chuck
>>>>
>>>
>>> -- 
>>> Dimitris Rizopoulos
>>> Assistant Professor
>>> Department of Biostatistics
>>> Erasmus University Medical Center
>>>
>>> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
>>> Tel: +31/(0)10/7043478
>>> Fax: +31/(0)10/7043014
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> _______________________________________________
>>> R-sig-mixed-models mailing list
>>> R-sig-mixed-models at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> End of R-sig-mixed-models Digest, Vol 27, Issue 36
>>> **************************************************
>>
>>
>>     Yahoo! Cocina
>> Recetas pr?cticas y comida saludable
>> http://ar.mujer.yahoo.com/cocina/
>>
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>
>
>      Yahoo! Cocina
> Recetas pr?cticas y comida saludable
> http://ar.mujer.yahoo.com/cocina/
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From smckinney at bccrc.ca  Sat Apr  4 04:17:47 2009
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 3 Apr 2009 19:17:47 -0700
Subject: [R-sig-ME] marginality principle for mixed effects models
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB0328A699@crcmail1.BCCRC.CA>



Dear list,

I'm working on mapping all my old-school fixed effects linear
modeling teachings into the fabulous new(er) mixed effects world.

I've been looking at the "Oats" data used in the nlme library.
Here's a set of commands that build successively richer models,
and tests to evaluate differences due to variety.

library("nlme")
library("lme4")
plot(Oats, inner = TRUE)
print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))

anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
anova(om4, om2) ## Would this be the first test of variety?
anova(om4, om1) ## Would this not be the omnibus test for variety?
anova(om2, om1)

If I wanted to assess the effect of variety, it seems to me
the first test I'd want to look at is model om4 versus model om2.
This it seems to me would be in the spirit of testing an interaction
term with both main effects in the model in the old fixed effects
world.

An omnibus test of the importance of variety would seem to me
to be model om4 versus om1. 

Testing om4 versus om3 seems to me to violate the marginality
principle (testing a main effect in the presence of an interaction
involving that main effect).  Or is there something different in
the mixed effects world - does this marginality principle hold
for this scenario?  The plots and all the other tests seem to
strongly suggest that there are important differences due to variety,
but this test suggests otherwise.  This test does not seem 
appropriate.  

Any comments?  Is this paradigm mapping reasonable?



> library("nlme")
> library("lme4")
 
> plot(Oats, inner = TRUE) # Lattice plot of data

> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
Linear mixed-effects model fit by REML 
Formula: yield ~ nitro + (1 | Block) 
   Data: Oats 
   AIC   BIC logLik MLdeviance REMLdeviance
 610.7 617.5 -302.4      616.4        604.7
Random effects:
 Groups   Name        Variance Std.Dev.
 Block    (Intercept) 243.34   15.599  
 Residual             254.99   15.968  
number of obs: 72, groups: Block, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   81.872      7.104  11.524
nitro         73.667      8.416   8.753

Correlation of Fixed Effects:
      (Intr)
nitro -0.355


> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
Linear mixed-effects model fit by REML 
Formula: yield ~ nitro + Variety + (1 | Block) 
   Data: Oats 
   AIC BIC logLik MLdeviance REMLdeviance
 601.6 613 -295.8      608.8        591.6
Random effects:
 Groups   Name        Variance Std.Dev.
 Block    (Intercept) 245.03   15.653  
 Residual             234.73   15.321  
number of obs: 72, groups: Block, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   81.872      7.069  11.582
nitro         73.667      8.075   9.123
Variety1       2.646      2.211   1.196
Variety2      -3.174      1.277  -2.486

Correlation of Fixed Effects:
         (Intr) nitro  Varty1
nitro    -0.343              
Variety1  0.000  0.000       
Variety2  0.000  0.000  0.000


> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
Linear mixed-effects model fit by REML 
Formula: yield ~ nitro + (1 | Block/Variety) 
   Data: Oats 
 AIC   BIC logLik MLdeviance REMLdeviance
 601 610.1 -296.5      604.3          593
Random effects:
 Groups        Name        Variance Std.Dev.
 Variety:Block (Intercept) 121.33   11.015  
 Block         (Intercept) 210.28   14.501  
 Residual                  165.51   12.865  
number of obs: 72, groups: Variety:Block, 18; Block, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   81.872      6.944   11.79
nitro         73.667      6.781   10.86

Correlation of Fixed Effects:
      (Intr)
nitro -0.293


> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
Linear mixed-effects model fit by REML 
Formula: yield ~ nitro + Variety + (1 | Block/Variety) 
   Data: Oats 
   AIC   BIC logLik MLdeviance REMLdeviance
 594.5 608.1 -291.2      601.3        582.5
Random effects:
 Groups        Name        Variance Std.Dev.
 Variety:Block (Intercept) 108.94   10.437  
 Block         (Intercept) 214.57   14.648  
 Residual                  165.55   12.867  
number of obs: 72, groups: Variety:Block, 18; Block, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   81.872      6.946  11.786
nitro         73.667      6.781  10.863
Variety1       2.646      3.539   0.748
Variety2      -3.174      2.043  -1.553

Correlation of Fixed Effects:
         (Intr) nitro  Varty1
nitro    -0.293              
Variety1  0.000  0.000       
Variety2  0.000  0.000  0.000
> 





> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
Data: Oats
Models:
om3: yield ~ nitro + (1 | Block/Variety)
om4: yield ~ nitro + Variety + (1 | Block/Variety)
    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
om3  4  612.30  621.41 -302.15                         
om4  6  613.28  626.94 -300.64 3.0197      2     0.2209


> anova(om4, om2) ## Would this be the first test for effect of variety?
Data: Oats
Models:
om2: yield ~ nitro + Variety + (1 | Block)
om4: yield ~ nitro + Variety + (1 | Block/Variety)
    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)   
om2  5  618.85  630.23 -304.42                            
om4  6  613.28  626.94 -300.64 7.5629      1   0.005958 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 


> anova(om4, om1) ## Would this not be the omnibus test for variety?
Data: Oats
Models:
om1: yield ~ nitro + (1 | Block)
om4: yield ~ nitro + Variety + (1 | Block/Variety)
    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)   
om1  3  622.40  629.23 -308.20                            
om4  6  613.28  626.94 -300.64 15.114      3   0.001722 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 


> anova(om2, om1)
Data: Oats
Models:
om1: yield ~ nitro + (1 | Block)
om2: yield ~ nitro + Variety + (1 | Block)
    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)  
om1  3  622.40  629.23 -308.20                           
om2  5  618.85  630.23 -304.42 7.5512      2    0.02292 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 
> 



Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney +at+ bccrc +dot+ ca

tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C. 
V5Z 1L3
Canada



From rmh3093 at gmail.com  Sun Apr  5 20:49:22 2009
From: rmh3093 at gmail.com (Ryan Hope)
Date: Sun, 5 Apr 2009 14:49:22 -0400
Subject: [R-sig-ME] How do I model a factorial repeated measures experiment
	with replicates?
Message-ID: <48f7fe350904051149j59d85ae9vf305dffc4358fdd5@mail.gmail.com>

I've been trying to use the lmer() function to model my experiment by
following the examples in "The R Book" and some other papers
pertaining to mixed-effects models with crossed random effects. Since
I have never done an analysis like this before (and neither have my
professors) I have no confidence in the results that I come up with.
In fact, I am not even sure that my model correctly represents the
design of my experiment...

My experiment is a 4x3 fully factorial within-subjects design with
replicates (12 blocks with 5 trials in each block). My data is in the
standard "long" format and with 31 participants I have 1860 rows of
data. The data file for those who are interested is here:
http://people.rit.edu/rmh3093/master1.csv

Fixed Factors:
Targets 4-Levels (4,9,14,19)
Entropy 3-Levels (Low, Medium, High)

Random:
Participant_ID - Unique ID for participant
Trial_Order - The order in which each trial was performed (to see if
the participant got better or worse with time)
Replicate - Essentially reflects a time variable, each participant did
5 trials for a particular block of factor combinations. They did each
replicate one after another completing the block before going on to
the next block.
Block - A categorical indicator of the factor combination (another way
to group replicates basically)

Probably the most important note was that each trial was generated
randomly, no 2 trials were exactly the same.

The first part of the formula is for the most part obvious (I am not
worried about the interaction between the main factors) but I am not
sure if I am supposed to say anything about the intercept. Some
examples I see include it; others dont:

Completion_Time~(Targets+Entropy)
Completion_Time~(1+Targets+Entropy)
Completion_Time~(-1+Targets+Entropy)

And I definitely don't understand is the random effects part. How do I
tell the model that each participant performed each factor combination
5 times? I've tried the following for the random section:

((Targets+Entropy)|Participant_ID)
((Targets+Entropy)|Participant_ID)+(1|Replicate)
(1+(Targets+Entropy)|Participant_ID)+(1|Replicate)
(-1+(Targets+Entropy)|Participant_ID)+(1|Replicate)
(Targets|Participant_ID)+(Entropy|Participant_ID)
(Targets|Participant_ID)+(Entropy|Participant_ID)+(1|Replicate)
(1+Targets|Participant_ID)+(Entropy|Participant_ID)+(1|Replicate)
(-1+Targets|Participant_ID)+(Entropy|Participant_ID)+(1|Replicate)
(Targets/Replicate|Participant_ID)+(Entropy/Replicate|Participant_ID)
(Targets|Participant_ID/Replicate)+(Entropy|Participant_ID/Replicate)
(-1+Targets/Replicate|Participant_ID)+(-1+Entropy/Replicate|Participant_ID)
etc...


I am so lost here!  I don't know which one, if any of the above are
correct. Any suggestions would be greatly appreciated!!
Thanks for your time!

-Ryan



From ebszolocsucsor at freemail.hu  Mon Apr  6 19:09:30 2009
From: ebszolocsucsor at freemail.hu (=?ISO-8859-2?Q?Bal=E1zs_Lest=E1r?=)
Date: Mon, 6 Apr 2009 19:09:30 +0200 (CEST)
Subject: [R-sig-ME] R^2 for lme
Message-ID: <freemail.20090306190930.59287@fm21.freemail.hu>

Dear All,

Can anybody tell me how to get the R^2 and adjusted R^2 for an lme object?
I found a formula, but when I checked it with an lm function, it didn't return the same result like summary(lm.model)$ r.squared.

l.B <- logLik (lme.model)
l.0 <- logLik ( lme ( y~ 1, random= ~1| a / b ) )
Rsq <- 1 - exp( - ( 2 / length(y ) * (l.B - l.0) ) )

Is there any packages that can help me?



From charpent at bacbuc.dyndns.org  Mon Apr  6 20:30:05 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Mon, 06 Apr 2009 20:30:05 +0200
Subject: [R-sig-ME] marginality principle for mixed effects models
In-Reply-To: <0BE438149FF2254DB4199E2682C8DFEB0328A699@crcmail1.BCCRC.CA>
References: <0BE438149FF2254DB4199E2682C8DFEB0328A699@crcmail1.BCCRC.CA>
Message-ID: <1239042604.9081.127.camel@yod>

Le vendredi 03 avril 2009 ? 19:17 -0700, Steven McKinney a ?crit :
> 
> Dear list,
> 
> I'm working on mapping all my old-school fixed effects linear
> modeling teachings into the fabulous new(er) mixed effects world.
> 
> I've been looking at the "Oats" data used in the nlme library.
> Here's a set of commands that build successively richer models,
> and tests to evaluate differences due to variety.
> 
> library("nlme")
> library("lme4")
> plot(Oats, inner = TRUE)
> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
> 
> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
> anova(om4, om2) ## Would this be the first test of variety?
> anova(om4, om1) ## Would this not be the omnibus test for variety?
> anova(om2, om1)
> 
> If I wanted to assess the effect of variety, it seems to me
> the first test I'd want to look at is model om4 versus model om2.
> This it seems to me would be in the spirit of testing an interaction
> term with both main effects in the model in the old fixed effects
> world.
> 
> An omnibus test of the importance of variety would seem to me
> to be model om4 versus om1. 
> 
> Testing om4 versus om3 seems to me to violate the marginality
> principle (testing a main effect in the presence of an interaction
> involving that main effect).  Or is there something different in
> the mixed effects world - does this marginality principle hold
> for this scenario?  The plots and all the other tests seem to
> strongly suggest that there are important differences due to variety,
> but this test suggests otherwise.  This test does not seem 
> appropriate.  
> 
> Any comments?  Is this paradigm mapping reasonable?

[ Big brutal SNIP of computations... ]

Since it seems that you've got no "authorized" answers, here are two
(?)cents from a mere practitioner :

When you consider an effect as fixed, you are indeed stating that each
of it's levels has a specific meaning and can be reproduced. Exhibiting
an interaction on a dependant variable Y between two fixed effects A and
B means that there is no common effect of, for example, A, and that the
effect of A is dependant of B in a way that cannot be "explained away"
as variability (that's exactly what you do when you reject the null
hypothesis H0 of the absence of interaction between A and B : you
consider that the  probability of <your results or worse> under H0 is
too small to accept the conjunction of your results and H0 ; since you
do not want to reject your results, you reject the other term of the
conjunction, i. e. H0). In consequence, making a prediction on the
effect of A on Y will involve A and B ; however it's variability will be
a function of the variance of Y *for a given value of A and B*.

Demonstrating an interaction between a fixed effect A and a random
effect B means something entirely different : here, you state that B is
a source of randomness that has to be taken into account in predicting
the effect of A. But B is a random effect, that is something (that you
consider) irreproductible. The consequences are different : instead of
saying "my prediction an A's effect cannot be made without accounting
for B", you accept that B will decrease the precision of your prediction
of the effect of A on Y : it will involve the full variability of Y
according to B.

Let's take a (not so imaginary) example, simpler than the "Oats" example
(to which we'll get back eventually) : trying to assess the effect of a
care organization (factor A, that we'll take to have two levels) on the
results Y of treatments given to patients attending various hospitals of
the same hospital group (factor B). To answer this question, a
reasonable way is to run a randomized clinical trial comparing Ys on
patients receiving care under A1 or A2. Let's assume, for sake of
simplicity, that care organization can be choosen at will for each
patient (e. g. an imaging technique for a given clinical question), thus
allowing for simple allocation scheme. Your judgement criterium will be
(say) Y|A2-Y|A1 i. e. differences of means of Y in patients having
received care under A1 and A2 conditions.

To assess this difference of means in the best possible way, you will
adjust on B (center effect) and check the homogeneit? of the effect of A
between various Bs (hospitals).

If your point of view is the hospital's group manager, your problem is
to determine how to equip your various centers (a known collection).
Your analysis might be better done considering B as a fixed effect, and
you will assess anova(lm(Y~A*B, data=yourdata)). if the A*B effect "is
significant" (i. e. cannot be explained away as mere natural
variability), your answer will be that there is no "good" universal
solution to your problem, and you will have to compare for each center,
with something along the lines of by(yourdata, yourdata$B,
anova(lm(Y~A,...)))

However, if your point of view is the one of a physician trying to
assess a technique medical value, you might consider your hospital group
as a (pseudo-)random sample of all possible hospitals. Your problem is
to know if, *accounting for inter-centre variability*, there exist a
systematic difference between A1 and A2 nonwhistanding B
"value" (irreproductible by definition). You might try to assess this by
building lmer(Y~A+(A|B), data=yourdata, REML=FALSE) and assessing A2
coefficient.

Having a "significant" A:B interaction means that the A effect exhibits
some nonnegligible variation according to B, but the whole point of the
mixed models exercice is to assess A *against the various sources of
variability.*

Technical Notes : 1) if you want to make comparisons between models with
differing fixed effects structure, you should use maximum likelihood
maximization, not REML (see P&B chap 2) ; be aware, however, that this
technique might "bias" your estimates more than REML (for the exact
meaning of bias, the importance of these biases, the ways to reduce
them, I defer to thows who know. Mr Bates, would you mind ?)
2) Be aware that Douglas Bates has expressed serious doubts on the
validity of "classical" ways to compare models (e. g. LRT tests, with
"obvious" dof...). This subject has already suscited flows of
ink^Kelectrons on this list, and I don't consider myself competent
enough to express an opinion.
3) This explains why, in older times, people confronted with
interactions of fixed factors were tempted to rechristen one of them as
random and to test the other by comparison of its effect(s) not with the
residual variance but with the interaction variance. That's a "trick" I
learned an (uncomfortably) long time ago, which aims to answer an
ill-formulated question along the lines of "is there a an A effect
clearly (statistically) larger that the variations introduced by B to
this possible A effect ?". Which might be a valid question, but
different of the question originally answered to by the ANOVA...

Now to get back to "Oats". Here, the difficulty is well explained in
both V&R4 and P&B : The experimental plan is a split-plot. Having
exactly 3 plots and 3 varieties per block makes "Variety" in
"Block/Variety" *also* a synonym for "Plot %in% Block", which is a
random effect : there is absolutely no reason to think that the
properties of Plot 2 in Block IV has anything in common with Plot 2 in
Block II, for example. Both "Variety %in% Block" and "Plot %in% Block"
ate *arbitrary* labels.

Therefore, the same ("Variety") variable designates 1) a fixed effect
(reproductible) and 2) a source of variability (irreproductible). The
optimization technique used in lme(r) aims to partition the total
variability between varieties between the "Variety" (fixed) effect and
the "PlotDisguisedAsVariety" (random) effect. R. A. Fisher has proposed
in 1935 a way to do this oin the case of *balanced* data sets (designed
(and well-executed) experiments), implemented in aov(). Here, P&B
chapter 1 discuss this very data set (it's the last introductory
example) ; the discussion in V&R4 is skimpier but gives another "look"a
at this problem. Both are worth reading, and I won't paraphrase ...

I might be interested to any corrections or suggestions about this way
to explain random effects to "laymen" (usually physicians who don't give
a hoot about those technicalities) : that's something I have to explain
more and more often.

HTH,

					Emmanuel Charpentier



From bates at stat.wisc.edu  Mon Apr  6 20:46:30 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Apr 2009 13:46:30 -0500
Subject: [R-sig-ME] R^2 for lme
In-Reply-To: <freemail.20090306190930.59287@fm21.freemail.hu>
References: <freemail.20090306190930.59287@fm21.freemail.hu>
Message-ID: <40e66e0b0904061146y4d31574bh16bec5636db8bc39@mail.gmail.com>

2009/4/6 Bal?zs Lest?r <ebszolocsucsor at freemail.hu>:
> Dear All,

> Can anybody tell me how to get the R^2 and adjusted R^2 for an lme object?
> I found a formula, but when I checked it with an lm function, it didn't return the same result like summary(lm.model)$ r.squared.

> l.B <- logLik (lme.model)
> l.0 <- logLik ( lme ( y~ 1, random= ~1| a / b ) )
> Rsq <- 1 - exp( - ( 2 / length(y ) * (l.B - l.0) ) )

> Is there any packages that can help me?

Well, first you have to define what you mean by R^2.

The simplest way to consider R^2 is as the complement of the residual
sum of squares of the fitted model to the residual sum of squares for
the trivial model.

The residual sum of squares for the trivial model can be evaluated as
deviance(lm(y ~ 1)).  See the enclosed script for an example.

From bates at stat.wisc.edu  Mon Apr  6 20:51:47 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Apr 2009 13:51:47 -0500
Subject: [R-sig-ME] marginality principle for mixed effects models
In-Reply-To: <0BE438149FF2254DB4199E2682C8DFEB0328A699@crcmail1.BCCRC.CA>
References: <0BE438149FF2254DB4199E2682C8DFEB0328A699@crcmail1.BCCRC.CA>
Message-ID: <40e66e0b0904061151t26da0df1u603be92e10df7584@mail.gmail.com>

A minor technical point.  It is not a good idea to have the lme4 and
nlme packages attached at the same time.  They both define generic
functions fixef, ranef, etc. and these definitions conflict.

There is a package called MEMSS that provides the data sets from nlme
without conflicts.

On Fri, Apr 3, 2009 at 9:17 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
>
>
> Dear list,
>
> I'm working on mapping all my old-school fixed effects linear
> modeling teachings into the fabulous new(er) mixed effects world.
>
> I've been looking at the "Oats" data used in the nlme library.
> Here's a set of commands that build successively richer models,
> and tests to evaluate differences due to variety.
>
> library("nlme")
> library("lme4")
> plot(Oats, inner = TRUE)
> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
>
> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
> anova(om4, om2) ## Would this be the first test of variety?
> anova(om4, om1) ## Would this not be the omnibus test for variety?
> anova(om2, om1)
>
> If I wanted to assess the effect of variety, it seems to me
> the first test I'd want to look at is model om4 versus model om2.
> This it seems to me would be in the spirit of testing an interaction
> term with both main effects in the model in the old fixed effects
> world.
>
> An omnibus test of the importance of variety would seem to me
> to be model om4 versus om1.
>
> Testing om4 versus om3 seems to me to violate the marginality
> principle (testing a main effect in the presence of an interaction
> involving that main effect). ?Or is there something different in
> the mixed effects world - does this marginality principle hold
> for this scenario? ?The plots and all the other tests seem to
> strongly suggest that there are important differences due to variety,
> but this test suggests otherwise. ?This test does not seem
> appropriate.
>
> Any comments? ?Is this paradigm mapping reasonable?
>
>
>
>> library("nlme")
>> library("lme4")
>
>> plot(Oats, inner = TRUE) # Lattice plot of data
>
>> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
> Linear mixed-effects model fit by REML
> Formula: yield ~ nitro + (1 | Block)
> ? Data: Oats
> ? AIC ? BIC logLik MLdeviance REMLdeviance
> ?610.7 617.5 -302.4 ? ? ?616.4 ? ? ? ?604.7
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?Block ? ?(Intercept) 243.34 ? 15.599
> ?Residual ? ? ? ? ? ? 254.99 ? 15.968
> number of obs: 72, groups: Block, 6
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 81.872 ? ? ?7.104 ?11.524
> nitro ? ? ? ? 73.667 ? ? ?8.416 ? 8.753
>
> Correlation of Fixed Effects:
> ? ? ?(Intr)
> nitro -0.355
>
>
>> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
> Linear mixed-effects model fit by REML
> Formula: yield ~ nitro + Variety + (1 | Block)
> ? Data: Oats
> ? AIC BIC logLik MLdeviance REMLdeviance
> ?601.6 613 -295.8 ? ? ?608.8 ? ? ? ?591.6
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?Block ? ?(Intercept) 245.03 ? 15.653
> ?Residual ? ? ? ? ? ? 234.73 ? 15.321
> number of obs: 72, groups: Block, 6
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 81.872 ? ? ?7.069 ?11.582
> nitro ? ? ? ? 73.667 ? ? ?8.075 ? 9.123
> Variety1 ? ? ? 2.646 ? ? ?2.211 ? 1.196
> Variety2 ? ? ?-3.174 ? ? ?1.277 ?-2.486
>
> Correlation of Fixed Effects:
> ? ? ? ? (Intr) nitro ?Varty1
> nitro ? ?-0.343
> Variety1 ?0.000 ?0.000
> Variety2 ?0.000 ?0.000 ?0.000
>
>
>> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
> Linear mixed-effects model fit by REML
> Formula: yield ~ nitro + (1 | Block/Variety)
> ? Data: Oats
> ?AIC ? BIC logLik MLdeviance REMLdeviance
> ?601 610.1 -296.5 ? ? ?604.3 ? ? ? ? ?593
> Random effects:
> ?Groups ? ? ? ?Name ? ? ? ?Variance Std.Dev.
> ?Variety:Block (Intercept) 121.33 ? 11.015
> ?Block ? ? ? ? (Intercept) 210.28 ? 14.501
> ?Residual ? ? ? ? ? ? ? ? ?165.51 ? 12.865
> number of obs: 72, groups: Variety:Block, 18; Block, 6
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 81.872 ? ? ?6.944 ? 11.79
> nitro ? ? ? ? 73.667 ? ? ?6.781 ? 10.86
>
> Correlation of Fixed Effects:
> ? ? ?(Intr)
> nitro -0.293
>
>
>> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
> Linear mixed-effects model fit by REML
> Formula: yield ~ nitro + Variety + (1 | Block/Variety)
> ? Data: Oats
> ? AIC ? BIC logLik MLdeviance REMLdeviance
> ?594.5 608.1 -291.2 ? ? ?601.3 ? ? ? ?582.5
> Random effects:
> ?Groups ? ? ? ?Name ? ? ? ?Variance Std.Dev.
> ?Variety:Block (Intercept) 108.94 ? 10.437
> ?Block ? ? ? ? (Intercept) 214.57 ? 14.648
> ?Residual ? ? ? ? ? ? ? ? ?165.55 ? 12.867
> number of obs: 72, groups: Variety:Block, 18; Block, 6
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 81.872 ? ? ?6.946 ?11.786
> nitro ? ? ? ? 73.667 ? ? ?6.781 ?10.863
> Variety1 ? ? ? 2.646 ? ? ?3.539 ? 0.748
> Variety2 ? ? ?-3.174 ? ? ?2.043 ?-1.553
>
> Correlation of Fixed Effects:
> ? ? ? ? (Intr) nitro ?Varty1
> nitro ? ?-0.293
> Variety1 ?0.000 ?0.000
> Variety2 ?0.000 ?0.000 ?0.000
>>
>
>
>
>
>
>> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
> Data: Oats
> Models:
> om3: yield ~ nitro + (1 | Block/Variety)
> om4: yield ~ nitro + Variety + (1 | Block/Variety)
> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
> om3 ?4 ?612.30 ?621.41 -302.15
> om4 ?6 ?613.28 ?626.94 -300.64 3.0197 ? ? ?2 ? ? 0.2209
>
>
>> anova(om4, om2) ## Would this be the first test for effect of variety?
> Data: Oats
> Models:
> om2: yield ~ nitro + Variety + (1 | Block)
> om4: yield ~ nitro + Variety + (1 | Block/Variety)
> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
> om2 ?5 ?618.85 ?630.23 -304.42
> om4 ?6 ?613.28 ?626.94 -300.64 7.5629 ? ? ?1 ? 0.005958 **
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>> anova(om4, om1) ## Would this not be the omnibus test for variety?
> Data: Oats
> Models:
> om1: yield ~ nitro + (1 | Block)
> om4: yield ~ nitro + Variety + (1 | Block/Variety)
> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
> om1 ?3 ?622.40 ?629.23 -308.20
> om4 ?6 ?613.28 ?626.94 -300.64 15.114 ? ? ?3 ? 0.001722 **
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>> anova(om2, om1)
> Data: Oats
> Models:
> om1: yield ~ nitro + (1 | Block)
> om2: yield ~ nitro + Variety + (1 | Block)
> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
> om1 ?3 ?622.40 ?629.23 -308.20
> om2 ?5 ?618.85 ?630.23 -304.42 7.5512 ? ? ?2 ? ?0.02292 *
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>
>
>
> Steven McKinney, Ph.D.
>
> Statistician
> Molecular Oncology and Breast Cancer Program
> British Columbia Cancer Research Centre
>
> email: smckinney +at+ bccrc +dot+ ca
>
> tel: 604-675-8000 x7561
>
> BCCRC
> Molecular Oncology
> 675 West 10th Ave, Floor 4
> Vancouver B.C.
> V5Z 1L3
> Canada
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Mon Apr  6 20:57:10 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 06 Apr 2009 14:57:10 -0400
Subject: [R-sig-ME] marginality principle for mixed effects models
In-Reply-To: <40e66e0b0904061151t26da0df1u603be92e10df7584@mail.gmail.com>
References: <0BE438149FF2254DB4199E2682C8DFEB0328A699@crcmail1.BCCRC.CA>
	<40e66e0b0904061151t26da0df1u603be92e10df7584@mail.gmail.com>
Message-ID: <49DA5086.5080906@ufl.edu>


  I think you could also say

data(Oats,package="nlme")

  without loading the whole nlme package.


Douglas Bates wrote:
> A minor technical point.  It is not a good idea to have the lme4 and
> nlme packages attached at the same time.  They both define generic
> functions fixef, ranef, etc. and these definitions conflict.
> 
> There is a package called MEMSS that provides the data sets from nlme
> without conflicts.
> 
> On Fri, Apr 3, 2009 at 9:17 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
>>
>> Dear list,
>>
>> I'm working on mapping all my old-school fixed effects linear
>> modeling teachings into the fabulous new(er) mixed effects world.
>>
>> I've been looking at the "Oats" data used in the nlme library.
>> Here's a set of commands that build successively richer models,
>> and tests to evaluate differences due to variety.
>>
>> library("nlme")
>> library("lme4")
>> plot(Oats, inner = TRUE)
>> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
>> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
>> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
>> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
>>
>> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
>> anova(om4, om2) ## Would this be the first test of variety?
>> anova(om4, om1) ## Would this not be the omnibus test for variety?
>> anova(om2, om1)
>>
>> If I wanted to assess the effect of variety, it seems to me
>> the first test I'd want to look at is model om4 versus model om2.
>> This it seems to me would be in the spirit of testing an interaction
>> term with both main effects in the model in the old fixed effects
>> world.
>>
>> An omnibus test of the importance of variety would seem to me
>> to be model om4 versus om1.
>>
>> Testing om4 versus om3 seems to me to violate the marginality
>> principle (testing a main effect in the presence of an interaction
>> involving that main effect).  Or is there something different in
>> the mixed effects world - does this marginality principle hold
>> for this scenario?  The plots and all the other tests seem to
>> strongly suggest that there are important differences due to variety,
>> but this test suggests otherwise.  This test does not seem
>> appropriate.
>>
>> Any comments?  Is this paradigm mapping reasonable?
>>
>>
>>
>>> library("nlme")
>>> library("lme4")
>>> plot(Oats, inner = TRUE) # Lattice plot of data
>>> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
>> Linear mixed-effects model fit by REML
>> Formula: yield ~ nitro + (1 | Block)
>>   Data: Oats
>>   AIC   BIC logLik MLdeviance REMLdeviance
>>  610.7 617.5 -302.4      616.4        604.7
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  Block    (Intercept) 243.34   15.599
>>  Residual             254.99   15.968
>> number of obs: 72, groups: Block, 6
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   81.872      7.104  11.524
>> nitro         73.667      8.416   8.753
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> nitro -0.355
>>
>>
>>> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
>> Linear mixed-effects model fit by REML
>> Formula: yield ~ nitro + Variety + (1 | Block)
>>   Data: Oats
>>   AIC BIC logLik MLdeviance REMLdeviance
>>  601.6 613 -295.8      608.8        591.6
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  Block    (Intercept) 245.03   15.653
>>  Residual             234.73   15.321
>> number of obs: 72, groups: Block, 6
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   81.872      7.069  11.582
>> nitro         73.667      8.075   9.123
>> Variety1       2.646      2.211   1.196
>> Variety2      -3.174      1.277  -2.486
>>
>> Correlation of Fixed Effects:
>>         (Intr) nitro  Varty1
>> nitro    -0.343
>> Variety1  0.000  0.000
>> Variety2  0.000  0.000  0.000
>>
>>
>>> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
>> Linear mixed-effects model fit by REML
>> Formula: yield ~ nitro + (1 | Block/Variety)
>>   Data: Oats
>>  AIC   BIC logLik MLdeviance REMLdeviance
>>  601 610.1 -296.5      604.3          593
>> Random effects:
>>  Groups        Name        Variance Std.Dev.
>>  Variety:Block (Intercept) 121.33   11.015
>>  Block         (Intercept) 210.28   14.501
>>  Residual                  165.51   12.865
>> number of obs: 72, groups: Variety:Block, 18; Block, 6
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   81.872      6.944   11.79
>> nitro         73.667      6.781   10.86
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> nitro -0.293
>>
>>
>>> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
>> Linear mixed-effects model fit by REML
>> Formula: yield ~ nitro + Variety + (1 | Block/Variety)
>>   Data: Oats
>>   AIC   BIC logLik MLdeviance REMLdeviance
>>  594.5 608.1 -291.2      601.3        582.5
>> Random effects:
>>  Groups        Name        Variance Std.Dev.
>>  Variety:Block (Intercept) 108.94   10.437
>>  Block         (Intercept) 214.57   14.648
>>  Residual                  165.55   12.867
>> number of obs: 72, groups: Variety:Block, 18; Block, 6
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   81.872      6.946  11.786
>> nitro         73.667      6.781  10.863
>> Variety1       2.646      3.539   0.748
>> Variety2      -3.174      2.043  -1.553
>>
>> Correlation of Fixed Effects:
>>         (Intr) nitro  Varty1
>> nitro    -0.293
>> Variety1  0.000  0.000
>> Variety2  0.000  0.000  0.000
>>
>>
>>
>>
>>> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
>> Data: Oats
>> Models:
>> om3: yield ~ nitro + (1 | Block/Variety)
>> om4: yield ~ nitro + Variety + (1 | Block/Variety)
>>    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
>> om3  4  612.30  621.41 -302.15
>> om4  6  613.28  626.94 -300.64 3.0197      2     0.2209
>>
>>
>>> anova(om4, om2) ## Would this be the first test for effect of variety?
>> Data: Oats
>> Models:
>> om2: yield ~ nitro + Variety + (1 | Block)
>> om4: yield ~ nitro + Variety + (1 | Block/Variety)
>>    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
>> om2  5  618.85  630.23 -304.42
>> om4  6  613.28  626.94 -300.64 7.5629      1   0.005958 **
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>> anova(om4, om1) ## Would this not be the omnibus test for variety?
>> Data: Oats
>> Models:
>> om1: yield ~ nitro + (1 | Block)
>> om4: yield ~ nitro + Variety + (1 | Block/Variety)
>>    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
>> om1  3  622.40  629.23 -308.20
>> om4  6  613.28  626.94 -300.64 15.114      3   0.001722 **
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>> anova(om2, om1)
>> Data: Oats
>> Models:
>> om1: yield ~ nitro + (1 | Block)
>> om2: yield ~ nitro + Variety + (1 | Block)
>>    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
>> om1  3  622.40  629.23 -308.20
>> om2  5  618.85  630.23 -304.42 7.5512      2    0.02292 *
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>> Steven McKinney, Ph.D.
>>
>> Statistician
>> Molecular Oncology and Breast Cancer Program
>> British Columbia Cancer Research Centre
>>
>> email: smckinney +at+ bccrc +dot+ ca
>>
>> tel: 604-675-8000 x7561
>>
>> BCCRC
>> Molecular Oncology
>> 675 West 10th Ave, Floor 4
>> Vancouver B.C.
>> V5Z 1L3
>> Canada
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bates at stat.wisc.edu  Mon Apr  6 22:36:21 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 6 Apr 2009 15:36:21 -0500
Subject: [R-sig-ME] marginality principle for mixed effects models
In-Reply-To: <49DA5086.5080906@ufl.edu>
References: <0BE438149FF2254DB4199E2682C8DFEB0328A699@crcmail1.BCCRC.CA>
	<40e66e0b0904061151t26da0df1u603be92e10df7584@mail.gmail.com>
	<49DA5086.5080906@ufl.edu>
Message-ID: <40e66e0b0904061336k52e8f7c1hac4a6828d4b93b46@mail.gmail.com>

On Mon, Apr 6, 2009 at 1:57 PM, Ben Bolker <bolker at ufl.edu> wrote:
>
> ?I think you could also say
>
> data(Oats,package="nlme")
>
> ?without loading the whole nlme package.

Indeed.  However, the versions of the data sets in MEMSS are slightly
different from the nlme versions. The versions in nlme with all
inherit from the groupedData class.  The versions in MEMSS are data
frames.  I now feel that the groupedData class was a bit too baroque
and that it is better to stick with something simpler like a data
frame.  Every once in a while some of the characteristics of the
groupedData class, like converting grouping factors to ordered
factors, causes unexpected results.  That is why the groupedData class
was not propagated to the lme4 package.

>
>
> Douglas Bates wrote:
>> A minor technical point. ?It is not a good idea to have the lme4 and
>> nlme packages attached at the same time. ?They both define generic
>> functions fixef, ranef, etc. and these definitions conflict.
>>
>> There is a package called MEMSS that provides the data sets from nlme
>> without conflicts.
>>
>> On Fri, Apr 3, 2009 at 9:17 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
>>>
>>> Dear list,
>>>
>>> I'm working on mapping all my old-school fixed effects linear
>>> modeling teachings into the fabulous new(er) mixed effects world.
>>>
>>> I've been looking at the "Oats" data used in the nlme library.
>>> Here's a set of commands that build successively richer models,
>>> and tests to evaluate differences due to variety.
>>>
>>> library("nlme")
>>> library("lme4")
>>> plot(Oats, inner = TRUE)
>>> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
>>> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
>>> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
>>> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
>>>
>>> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
>>> anova(om4, om2) ## Would this be the first test of variety?
>>> anova(om4, om1) ## Would this not be the omnibus test for variety?
>>> anova(om2, om1)
>>>
>>> If I wanted to assess the effect of variety, it seems to me
>>> the first test I'd want to look at is model om4 versus model om2.
>>> This it seems to me would be in the spirit of testing an interaction
>>> term with both main effects in the model in the old fixed effects
>>> world.
>>>
>>> An omnibus test of the importance of variety would seem to me
>>> to be model om4 versus om1.
>>>
>>> Testing om4 versus om3 seems to me to violate the marginality
>>> principle (testing a main effect in the presence of an interaction
>>> involving that main effect). ?Or is there something different in
>>> the mixed effects world - does this marginality principle hold
>>> for this scenario? ?The plots and all the other tests seem to
>>> strongly suggest that there are important differences due to variety,
>>> but this test suggests otherwise. ?This test does not seem
>>> appropriate.
>>>
>>> Any comments? ?Is this paradigm mapping reasonable?
>>>
>>>
>>>
>>>> library("nlme")
>>>> library("lme4")
>>>> plot(Oats, inner = TRUE) # Lattice plot of data
>>>> print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
>>> Linear mixed-effects model fit by REML
>>> Formula: yield ~ nitro + (1 | Block)
>>> ? Data: Oats
>>> ? AIC ? BIC logLik MLdeviance REMLdeviance
>>> ?610.7 617.5 -302.4 ? ? ?616.4 ? ? ? ?604.7
>>> Random effects:
>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>> ?Block ? ?(Intercept) 243.34 ? 15.599
>>> ?Residual ? ? ? ? ? ? 254.99 ? 15.968
>>> number of obs: 72, groups: Block, 6
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 81.872 ? ? ?7.104 ?11.524
>>> nitro ? ? ? ? 73.667 ? ? ?8.416 ? 8.753
>>>
>>> Correlation of Fixed Effects:
>>> ? ? ?(Intr)
>>> nitro -0.355
>>>
>>>
>>>> print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
>>> Linear mixed-effects model fit by REML
>>> Formula: yield ~ nitro + Variety + (1 | Block)
>>> ? Data: Oats
>>> ? AIC BIC logLik MLdeviance REMLdeviance
>>> ?601.6 613 -295.8 ? ? ?608.8 ? ? ? ?591.6
>>> Random effects:
>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>> ?Block ? ?(Intercept) 245.03 ? 15.653
>>> ?Residual ? ? ? ? ? ? 234.73 ? 15.321
>>> number of obs: 72, groups: Block, 6
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 81.872 ? ? ?7.069 ?11.582
>>> nitro ? ? ? ? 73.667 ? ? ?8.075 ? 9.123
>>> Variety1 ? ? ? 2.646 ? ? ?2.211 ? 1.196
>>> Variety2 ? ? ?-3.174 ? ? ?1.277 ?-2.486
>>>
>>> Correlation of Fixed Effects:
>>> ? ? ? ? (Intr) nitro ?Varty1
>>> nitro ? ?-0.343
>>> Variety1 ?0.000 ?0.000
>>> Variety2 ?0.000 ?0.000 ?0.000
>>>
>>>
>>>> print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
>>> Linear mixed-effects model fit by REML
>>> Formula: yield ~ nitro + (1 | Block/Variety)
>>> ? Data: Oats
>>> ?AIC ? BIC logLik MLdeviance REMLdeviance
>>> ?601 610.1 -296.5 ? ? ?604.3 ? ? ? ? ?593
>>> Random effects:
>>> ?Groups ? ? ? ?Name ? ? ? ?Variance Std.Dev.
>>> ?Variety:Block (Intercept) 121.33 ? 11.015
>>> ?Block ? ? ? ? (Intercept) 210.28 ? 14.501
>>> ?Residual ? ? ? ? ? ? ? ? ?165.51 ? 12.865
>>> number of obs: 72, groups: Variety:Block, 18; Block, 6
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 81.872 ? ? ?6.944 ? 11.79
>>> nitro ? ? ? ? 73.667 ? ? ?6.781 ? 10.86
>>>
>>> Correlation of Fixed Effects:
>>> ? ? ?(Intr)
>>> nitro -0.293
>>>
>>>
>>>> print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data = Oats))
>>> Linear mixed-effects model fit by REML
>>> Formula: yield ~ nitro + Variety + (1 | Block/Variety)
>>> ? Data: Oats
>>> ? AIC ? BIC logLik MLdeviance REMLdeviance
>>> ?594.5 608.1 -291.2 ? ? ?601.3 ? ? ? ?582.5
>>> Random effects:
>>> ?Groups ? ? ? ?Name ? ? ? ?Variance Std.Dev.
>>> ?Variety:Block (Intercept) 108.94 ? 10.437
>>> ?Block ? ? ? ? (Intercept) 214.57 ? 14.648
>>> ?Residual ? ? ? ? ? ? ? ? ?165.55 ? 12.867
>>> number of obs: 72, groups: Variety:Block, 18; Block, 6
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 81.872 ? ? ?6.946 ?11.786
>>> nitro ? ? ? ? 73.667 ? ? ?6.781 ?10.863
>>> Variety1 ? ? ? 2.646 ? ? ?3.539 ? 0.748
>>> Variety2 ? ? ?-3.174 ? ? ?2.043 ?-1.553
>>>
>>> Correlation of Fixed Effects:
>>> ? ? ? ? (Intr) nitro ?Varty1
>>> nitro ? ?-0.293
>>> Variety1 ?0.000 ?0.000
>>> Variety2 ?0.000 ?0.000 ?0.000
>>>
>>>
>>>
>>>
>>>> anova(om4, om3) ## Does this violate the principle of marginality? (Testing main effect in presence of interaction?)
>>> Data: Oats
>>> Models:
>>> om3: yield ~ nitro + (1 | Block/Variety)
>>> om4: yield ~ nitro + Variety + (1 | Block/Variety)
>>> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
>>> om3 ?4 ?612.30 ?621.41 -302.15
>>> om4 ?6 ?613.28 ?626.94 -300.64 3.0197 ? ? ?2 ? ? 0.2209
>>>
>>>
>>>> anova(om4, om2) ## Would this be the first test for effect of variety?
>>> Data: Oats
>>> Models:
>>> om2: yield ~ nitro + Variety + (1 | Block)
>>> om4: yield ~ nitro + Variety + (1 | Block/Variety)
>>> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
>>> om2 ?5 ?618.85 ?630.23 -304.42
>>> om4 ?6 ?613.28 ?626.94 -300.64 7.5629 ? ? ?1 ? 0.005958 **
>>> ---
>>> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>>> anova(om4, om1) ## Would this not be the omnibus test for variety?
>>> Data: Oats
>>> Models:
>>> om1: yield ~ nitro + (1 | Block)
>>> om4: yield ~ nitro + Variety + (1 | Block/Variety)
>>> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
>>> om1 ?3 ?622.40 ?629.23 -308.20
>>> om4 ?6 ?613.28 ?626.94 -300.64 15.114 ? ? ?3 ? 0.001722 **
>>> ---
>>> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>>> anova(om2, om1)
>>> Data: Oats
>>> Models:
>>> om1: yield ~ nitro + (1 | Block)
>>> om2: yield ~ nitro + Variety + (1 | Block)
>>> ? ?Df ? ? AIC ? ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
>>> om1 ?3 ?622.40 ?629.23 -308.20
>>> om2 ?5 ?618.85 ?630.23 -304.42 7.5512 ? ? ?2 ? ?0.02292 *
>>> ---
>>> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>> Steven McKinney, Ph.D.
>>>
>>> Statistician
>>> Molecular Oncology and Breast Cancer Program
>>> British Columbia Cancer Research Centre
>>>
>>> email: smckinney +at+ bccrc +dot+ ca
>>>
>>> tel: 604-675-8000 x7561
>>>
>>> BCCRC
>>> Molecular Oncology
>>> 675 West 10th Ave, Floor 4
>>> Vancouver B.C.
>>> V5Z 1L3
>>> Canada
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>



From christina.bogner at uni-bayreuth.de  Tue Apr  7 09:59:13 2009
From: christina.bogner at uni-bayreuth.de (Christina Bogner)
Date: Tue, 07 Apr 2009 09:59:13 +0200
Subject: [R-sig-ME] R2 for lme
Message-ID: <49DB07D1.4020809@uni-bayreuth.de>

Hello,

as Dr. Bates already mentioned, you can define different R2. I used the 
formula proposed by Edwards et al (2008): An R-2 statistic for fixed 
effects in the linear mixed model, Statistics in Medicine 27(29): 
6137-6157. He compares a mixed-effects model with an empty model 
containing the same random-effects, but only the intercept as a 
fixed-effect. With his approach, you only need to fit the full model, so 
that the random-effects remain the same. To show the overall "goodness" 
of my models, I calculated the correlation coefficient between the 
fitted and the observed values.

HTH

Christina



From birdlists at gmail.com  Tue Apr  7 21:24:09 2009
From: birdlists at gmail.com (Jude Phillips)
Date: Tue, 7 Apr 2009 15:24:09 -0400
Subject: [R-sig-ME] heteroscedascity in fixed factor
Message-ID: <2d850d6d0904071224l3a66291ei817f5b6f8735db93@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090407/f60e6c75/attachment.pl>

From smckinney at bccrc.ca  Wed Apr  8 04:49:09 2009
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 7 Apr 2009 19:49:09 -0700
Subject: [R-sig-ME] marginality principle for mixed effects models
In-Reply-To: <29571_1239042734_1239042734_1239042604.9081.127.camel@yod>
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB01D50245@crcmail1.BCCRC.CA>

Thanks for your thoughtful discussion.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Emmanuel Charpentier
> Sent: Monday, April 06, 2009 11:30 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] marginality principle for mixed effects models
> 
> Le vendredi 03 avril 2009 ? 19:17 -0700, Steven McKinney a ?crit :
> >
> > Dear list,
> >
> > I'm working on mapping all my old-school fixed effects linear
> > modeling teachings into the fabulous new(er) mixed effects world.
> >
> > I've been looking at the "Oats" data used in the nlme library.
> > Here's a set of commands that build successively richer models,
> > and tests to evaluate differences due to variety.
> >
> > library("nlme")
> > library("lme4")
> > plot(Oats, inner = TRUE)
> > print(om1 <- lmer(yield ~ nitro + (1 | Block), data = Oats))
> > print(om2 <- lmer(yield ~ nitro + Variety + (1 | Block), data = Oats))
> > print(om3 <- lmer(yield ~ nitro + (1 | Block/Variety), data = Oats))
> > print(om4 <- lmer(yield ~ nitro + Variety + (1 | Block/Variety), data =
> Oats))
> >
> > anova(om4, om3) ## Does this violate the principle of marginality?
> (Testing main effect in presence of interaction?)
> > anova(om4, om2) ## Would this be the first test of variety?
> > anova(om4, om1) ## Would this not be the omnibus test for variety?
> > anova(om2, om1)
> >
> > If I wanted to assess the effect of variety, it seems to me
> > the first test I'd want to look at is model om4 versus model om2.
> > This it seems to me would be in the spirit of testing an interaction
> > term with both main effects in the model in the old fixed effects
> > world.
> >
> > An omnibus test of the importance of variety would seem to me
> > to be model om4 versus om1.
> >
> > Testing om4 versus om3 seems to me to violate the marginality
> > principle (testing a main effect in the presence of an interaction
> > involving that main effect).  Or is there something different in
> > the mixed effects world - does this marginality principle hold
> > for this scenario?  The plots and all the other tests seem to
> > strongly suggest that there are important differences due to variety,
> > but this test suggests otherwise.  This test does not seem
> > appropriate.
> >
> > Any comments?  Is this paradigm mapping reasonable?
> 
> [ Big brutal SNIP of computations... ]
> 
> Since it seems that you've got no "authorized" answers, here are two
> (?)cents from a mere practitioner :
> 
> When you consider an effect as fixed, you are indeed stating that each
> of it's levels has a specific meaning and can be reproduced. Exhibiting
> an interaction on a dependant variable Y between two fixed effects A and
> B means that there is no common effect of, for example, A, and that the
> effect of A is dependant of B in a way that cannot be "explained away"
> as variability (that's exactly what you do when you reject the null
> hypothesis H0 of the absence of interaction between A and B : you
> consider that the  probability of <your results or worse> under H0 is
> too small to accept the conjunction of your results and H0 ; since you
> do not want to reject your results, you reject the other term of the
> conjunction, i. e. H0). In consequence, making a prediction on the
> effect of A on Y will involve A and B ; however it's variability will be
> a function of the variance of Y *for a given value of A and B*.
> 
> Demonstrating an interaction between a fixed effect A and a random
> effect B means something entirely different : here, you state that B is
> a source of randomness that has to be taken into account in predicting
> the effect of A. But B is a random effect, that is something (that you
> consider) irreproductible. The consequences are different : instead of
> saying "my prediction an A's effect cannot be made without accounting
> for B", you accept that B will decrease the precision of your prediction
> of the effect of A on Y : it will involve the full variability of Y
> according to B.

Now if I add the additional random effect A:B is it always acceptable
to test the fixed effect A in the presence of the (random) A:B interaction?
This is the issue I'm trying to understand - how does the marginality
principle work in the mixed effects world?  I guess I'm coming to the conclusion that it is fine to test the fixed effect in the presence of its (random) interaction - I'm not sure it's okay to state that the factor is of no significance when it is still in the model as part of a random effects component - I'm thinking this is just a terminology issue in discussing structure in mixed effects models.

My mistake with the Oats example was not recognizing that 'Variety' and 'Plot' are confounded and the Variety:Block interaction is Plot:Block interaction.  I'm looking for a better example where the two are
separable - maybe I'm not thinking about this part properly though.

> 
> Let's take a (not so imaginary) example, simpler than the "Oats" example
> (to which we'll get back eventually) : trying to assess the effect of a
> care organization (factor A, that we'll take to have two levels) on the
> results Y of treatments given to patients attending various hospitals of
> the same hospital group (factor B). To answer this question, a
> reasonable way is to run a randomized clinical trial comparing Ys on
> patients receiving care under A1 or A2. Let's assume, for sake of
> simplicity, that care organization can be choosen at will for each
> patient (e. g. an imaging technique for a given clinical question), thus
> allowing for simple allocation scheme. Your judgement criterium will be
> (say) Y|A2-Y|A1 i. e. differences of means of Y in patients having
> received care under A1 and A2 conditions.
> 
> To assess this difference of means in the best possible way, you will
> adjust on B (center effect) and check the homogeneit? of the effect of A
> between various Bs (hospitals).
> 
> If your point of view is the hospital's group manager, your problem is
> to determine how to equip your various centers (a known collection).
> Your analysis might be better done considering B as a fixed effect, and
> you will assess anova(lm(Y~A*B, data=yourdata)). if the A*B effect "is
> significant" (i. e. cannot be explained away as mere natural
> variability), your answer will be that there is no "good" universal
> solution to your problem, and you will have to compare for each center,
> with something along the lines of by(yourdata, yourdata$B,
> anova(lm(Y~A,...)))
> 
> However, if your point of view is the one of a physician trying to
> assess a technique medical value, you might consider your hospital group
> as a (pseudo-)random sample of all possible hospitals. Your problem is
> to know if, *accounting for inter-centre variability*, there exist a
> systematic difference between A1 and A2 nonwhistanding B
> "value" (irreproductible by definition). You might try to assess this by
> building lmer(Y~A+(A|B), data=yourdata, REML=FALSE) and assessing A2
> coefficient.
> 
> Having a "significant" A:B interaction means that the A effect exhibits
> some nonnegligible variation according to B, but the whole point of the
> mixed models exercice is to assess A *against the various sources of
> variability.*

Right - so if I want to assess whether a given factor shows some 
structure beyond statistical noise, if that factor comprises a
fixed effect and has an interaction term with another random
effect, then presumably that factor is demonstrating structure
in the levels taken by the dependent variable (fixed effect
component) and in the variability exhibited (this is the part
I'm still trying to grok) so when we want to comment on the
'significance' of this factor, there's a variance component and
a levels component.  Does it make sense to test the levels component
and dismiss the variable from the fixed effects portion of the 
model and label it 'not significant' when it contributes to
variance structure?  Perhaps I'm just looking for reasonable
terminology to describe these different structural contributions
in the mixed effects world.

> 
> Technical Notes : 1) if you want to make comparisons between models with
> differing fixed effects structure, you should use maximum likelihood
> maximization, not REML (see P&B chap 2) ; be aware, however, that this
> technique might "bias" your estimates more than REML (for the exact
> meaning of bias, the importance of these biases, the ways to reduce
> them, I defer to thows who know. Mr Bates, would you mind ?)

Apologies - I don't do this in practice - I should have been explicit
in the example to use ML for anova test models and REML for parameter
estimates and discussion thereof.

I also do not load the nlme library concurrently - that was just
in the example as I didn't know I could get that data from
the MEMSS library.  Thanks to Doug Bates for pointing that out.

> 2) Be aware that Douglas Bates has expressed serious doubts on the
> validity of "classical" ways to compare models (e. g. LRT tests, with
> "obvious" dof...). This subject has already suscited flows of
> ink/electrons on this list, and I don't consider myself competent
> enough to express an opinion.

"All models are wrong.  Some models are useful."
The LRT has held up well in a variety of circumstances for decades.
Until smarter people than I show that the LRT is seriously flawed 
in mixed effects models, I'll continue to use it as an indicator as to what's (relatively) important amongst the factors under review.
I'll continue to monitor Doug Bates development of MCMC and
dof methods, and look forward to the next release from his
development line.  Grokking the MCMC is next on the list of
mixed effects learning but it's a bit of a moving target right
now.  Degrees of freedom are strongly related to information 
content, so I think someday RSN some new definitions
of dof will help clear up issues there.

> 3) This explains why, in older times, people confronted with
> interactions of fixed factors were tempted to rechristen one of them as
> random and to test the other by comparison of its effect(s) not with the
> residual variance but with the interaction variance. That's a "trick" I
> learned an (uncomfortably) long time ago, which aims to answer an
> ill-formulated question along the lines of "is there a an A effect
> clearly (statistically) larger that the variations introduced by B to
> this possible A effect ?". Which might be a valid question, but
> different of the question originally answered to by the ANOVA...
> 
> Now to get back to "Oats". Here, the difficulty is well explained in
> both V&R4 and P&B : The experimental plan is a split-plot. Having
> exactly 3 plots and 3 varieties per block makes "Variety" in
> "Block/Variety" *also* a synonym for "Plot %in% Block", which is a
> random effect : there is absolutely no reason to think that the
> properties of Plot 2 in Block IV has anything in common with Plot 2 in
> Block II, for example. Both "Variety %in% Block" and "Plot %in% Block"
> ate *arbitrary* labels.

This was part of my misunderstanding.  Since each plot has one variety,
variety is being used as an indicator for plot (the two are confounded).

> 
> Therefore, the same ("Variety") variable designates 1) a fixed effect
> (reproductible) and 2) a source of variability (irreproductible). The
> optimization technique used in lme(r) aims to partition the total
> variability between varieties between the "Variety" (fixed) effect and
> the "PlotDisguisedAsVariety" (random) effect. R. A. Fisher has proposed
> in 1935 a way to do this oin the case of *balanced* data sets (designed
> (and well-executed) experiments), implemented in aov(). Here, P&B
> chapter 1 discuss this very data set (it's the last introductory
> example) ; the discussion in V&R4 is skimpier but gives another "look"a
> at this problem. Both are worth reading, and I won't paraphrase ...


Reading and rereading...


> 
> I might be interested to any corrections or suggestions about this way
> to explain random effects to "laymen" (usually physicians who don't give
> a hoot about those technicalities) : that's something I have to explain
> more and more often.
> 
> HTH,

It certainly did, thanks much
Steve M

> 
> 					Emmanuel Charpentier
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Thierry.ONKELINX at inbo.be  Wed Apr  8 11:14:21 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 8 Apr 2009 11:14:21 +0200
Subject: [R-sig-ME] heteroscedascity in fixed factor
In-Reply-To: <2d850d6d0904071224l3a66291ei817f5b6f8735db93@mail.gmail.com>
References: <2d850d6d0904071224l3a66291ei817f5b6f8735db93@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A104064B8928@inboexch.inbo.be>

Have a look at the varClas options. In your case adding weights =
varIdent(~treatment) models the heteroscedasticity along the levels of
treatment.

lme(crop.height~treatment, random= ~1|field, height, weights =
varIdent(~treatment))

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Jude Phillips
Verzonden: dinsdag 7 april 2009 21:24
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] heteroscedascity in fixed factor

Hi,



I'm trying to fit a simple mixed effects model to data on a crop
experiment.




height.lme1<-lme(crop.height~treatment, random= ~1|field, height)



treatment is a categorical variable.  field is included as a random
variable
because the management history of each field might affect the outcome of
the
trials.  Also the observations are unbalanced; different numbers of
measurements were recorded in each field.  treatment has a significant
effect on crop.height



The problem I'm having is this; crop.height is not homoscedastic with
respect to treatment.  Therefore, is it possible that the significant
effect
of treatment is due to differences in variances rather than differences
in
means?  Is there any way around this?



Thanks for your help Megan Douglas

	[[alternative HTML version deleted]]


Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From christian.salas at yale.edu  Wed Apr  8 16:56:46 2009
From: christian.salas at yale.edu (Christian Salas)
Date: Wed, 08 Apr 2009 10:56:46 -0400
Subject: [R-sig-ME] error when update() a LME-with correlated errors object
Message-ID: <49DCBB2E.10502@yale.edu>

Hi there

I cannot update a fitted LME-with spatially correlated errors object, 
please check the example. Data from an R book, only 281 rows, the 
provided code download the data from my website.

I use R 2.8.1 under linux-ubuntu, For this session i was using the 
following packages
     Package Version
1      nlme  3.1-90
2  datasets   2.8.1
3      MASS  7.2-46
4     utils   2.8.1
5     stats   2.8.1
6  graphics   2.8.1
7 grDevices   2.8.1
8   methods   2.8.1
9      base   2.8.1


The code!!

# Fitting a LME with correlated errors
# Example and data from Book: Bivand et al 2008 "Applied spatial
# data analysis with R"
###################################################

#example--------------------------------
#1. read data
#data from the book, i built the .csv file
dbase <- 
read.csv(url("http://environment.yale.edu/salas/data/spatDataBivandetal08.csv"),
  header = TRUE)

head(dbase)
dim(dbase)

#fit a linear model (just for fun)
nylm <- lm(Z~PEXPOSURE+PCTAGE65P+PCTOWNHOME, data=dbase)
summary(nylm)

#fit a mixed-effect model [p.288 of Bivand et al] with correlated
# errros depending on the distance between the centroids of the areas
library(nlme)

#specify correlation structure [also explained in Pinheiro&Bates, p.238]
sp1 <- corSpatial(1, form = ~ x + y, type = "gaussian")
scor<-Initialize(sp1, dbase[,c("x", "y")], nugget=FALSE)

#fit the LME with correlated errors
spmodel<-lme(Z~PEXPOSURE+PCTAGE65P+PCTOWNHOME,
              random=~1|AREAKEY,
              data=dbase, correlation=scor, method="ML")

summary(spmodel)

#the problem------------
#I want to fit the same mixed-effect model with correlated structure
# for a different havin n-i observations and of course the same columns
dbnew=dbase[-1,]
nrow(dbnew) #one less observation than before

#here is the error, or bug?
update(spmodel, data=dbnew) #here is the error!!!!!, why?
#after running this, appear a large message, summarized here
#
#*** glibc detected *** /usr/lib/R/bin/exec/R: free(): invalid next size 
(normal): 0x0950f090 ***
#======= Backtrace: =========
#/lib/tls/i686/cmov/libc.so.6[0xb7b6e454]
#/lib/tls/i686/cmov/libc.so.6(cfree+0x96)[0xb7b704b6]
#b6ddb000-b6ddc000 r--p 00633000 08:05 1574
#Process R aborted at Mon Apr  6 09:12:41 2009

#I did also check this in a Windows OS, and I obtained the same problem.
#I did also check with an older version of nlme, and I obtained the same 
#problem.


any suggestion?

thanks in advance

-- 
-------------------------------------------------------------------------------
Christian Salas                     E-mail:christian.salas at yale.edu
PhD candidate                       http://environment.yale.edu/salas
School of Forestry and Environmental Studies
Yale University                     Tel: +1-(203)-432 5126
360 Prospect St                     Fax:+1-(203)-432 3809
New Haven, CT 06511-2189            Office: Room 35, Marsh Hall
USA

Yale Biometrics Lab                  http://environment.yale.edu/biometrics



From Virgilio.Gomez at uclm.es  Wed Apr  8 17:12:23 2009
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Wed, 08 Apr 2009 17:12:23 +0200
Subject: [R-sig-ME] error when update() a LME-with correlated errors
 object
In-Reply-To: <49DCBB2E.10502@yale.edu>
References: <49DCBB2E.10502@yale.edu>
Message-ID: <1239203543.29197.2.camel@Virgilio-Gomez>

Dear Christian,


> #the problem------------
> #I want to fit the same mixed-effect model with correlated structure
> # for a different havin n-i observations and of course the same columns
> dbnew=dbase[-1,]
> nrow(dbnew) #one less observation than before
> 
> #here is the error, or bug?
> update(spmodel, data=dbnew) #here is the error!!!!!, why?
> #after running this, appear a large message, summarized here
> #
> #*** glibc detected *** /usr/lib/R/bin/exec/R: free(): invalid next size 
> (normal): 0x0950f090 ***

My guess is that when you call update() R still thinks that you have 281
observations instead of 280. Why do not you try the following:

spmodel2<-lme(Z~PEXPOSURE+PCTAGE65P+PCTOWNHOME,
              random=~1|AREAKEY,
              data=dbnew, correlation=scor, method="ML")

I believe that this should work.

Best,

Virgilio



From christian.salas at yale.edu  Wed Apr  8 17:17:43 2009
From: christian.salas at yale.edu (Christian Salas)
Date: Wed, 08 Apr 2009 11:17:43 -0400
Subject: [R-sig-ME] error when update() a LME-with correlated errors
	object
In-Reply-To: <1239203543.29197.2.camel@Virgilio-Gomez>
References: <49DCBB2E.10502@yale.edu> <1239203543.29197.2.camel@Virgilio-Gomez>
Message-ID: <49DCC017.9010900@yale.edu>

thanks Virgilio!
that is a solution which of course it does work. Maybe I should explain 
before that I am trying to include this withing a  larger analysis where 
the models (i.e., the fixed part of the model) will change, then in that 
setting being able to just keep the best model being selected (i.e. the 
lme() fitted object) and use  update() is easier than writing the model 
again.

by the way, i like your book in spat-stat!!!
saludos de un chileno desde Yale :)

-------------------------------------------------------------------------------
Christian Salas                     E-mail:christian.salas at yale.edu
PhD candidate                       http://environment.yale.edu/salas
School of Forestry and Environmental Studies
Yale University                     Tel: +1-(203)-432 5126
360 Prospect St                     Fax:+1-(203)-432 3809
New Haven, CT 06511-2189            Office: Room 35, Marsh Hall
USA

Yale Biometrics Lab                  http://environment.yale.edu/biometrics
-------------------------------------------------------------------------------





Virgilio Gomez Rubio wrote:
> Dear Christian,
> 
> 
>> #the problem------------
>> #I want to fit the same mixed-effect model with correlated structure
>> # for a different havin n-i observations and of course the same columns
>> dbnew=dbase[-1,]
>> nrow(dbnew) #one less observation than before
>>
>> #here is the error, or bug?
>> update(spmodel, data=dbnew) #here is the error!!!!!, why?
>> #after running this, appear a large message, summarized here
>> #
>> #*** glibc detected *** /usr/lib/R/bin/exec/R: free(): invalid next size 
>> (normal): 0x0950f090 ***
> 
> My guess is that when you call update() R still thinks that you have 281
> observations instead of 280. Why do not you try the following:
> 
> spmodel2<-lme(Z~PEXPOSURE+PCTAGE65P+PCTOWNHOME,
>               random=~1|AREAKEY,
>               data=dbnew, correlation=scor, method="ML")
> 
> I believe that this should work.
> 
> Best,
> 
> Virgilio



From ebszolocsucsor at freemail.hu  Thu Apr  9 23:13:37 2009
From: ebszolocsucsor at freemail.hu (=?ISO-8859-2?Q?Bal=E1zs_Lest=E1r?=)
Date: Thu, 9 Apr 2009 23:13:37 +0200 (CEST)
Subject: [R-sig-ME] LME and nonlinearity?
Message-ID: <freemail.20090309231337.10618@fm22.freemail.hu>

Dear All,

I have a mixed model (LME), but one of my explanatory variables is not linearly related to the dependent variable.

 1.)     Somebody told me, to make a 2 or 3 level factor from the continuous variable. (I wouldn't prefer this)

  2.)     I saw in some statistical books that in these cases, I have to use in the model the quadratic term of the variable. (but the AIC is much greater than with the  factorized variable)

OR

 Is that possible, to use a poly() function in the lme? (this model seems to be the best, based on AIC).
 

I'm a bit confused, 'cause the LME supposes linear relation between variables. Isn't it right?

 3.)        Do I need a non-linear model?

Which solution is the best?


Regards,
Balazs



From john.maindonald at anu.edu.au  Fri Apr 10 00:50:41 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 10 Apr 2009 08:50:41 +1000
Subject: [R-sig-ME] LME and nonlinearity?
In-Reply-To: <freemail.20090309231337.10618@fm22.freemail.hu>
References: <freemail.20090309231337.10618@fm22.freemail.hu>
Message-ID: <A5F64057-797A-46FC-82D3-CD5B076E83A9@anu.edu.au>

Additional to the comments below: Think/check also whether  
transformation of one or more of the variables (log transformation?)  
makes the relationship more nearly linear.

On 10/04/2009, at 7:13 AM, Bal?zs Lest?r wrote:

> Dear All,
>
> I have a mixed model (LME), but one of my explanatory variables is  
> not linearly related to the dependent variable.
>
> 1.)     Somebody told me, to make a 2 or 3 level factor from the  
> continuous variable. (I wouldn't prefer this)

In general, this makes poor use of the information in the data.  You  
lose power.

> 2.)     I saw in some statistical books that in these cases, I have  
> to use in the model the quadratic term of the variable. (but the AIC  
> is much greater than with the  factorized variable)
>
> OR
>
> Is that possible, to use a poly() function in the lme? (this model  
> seems to be the best, based on AIC).

Yes.

> I'm a bit confused, 'cause the LME supposes linear relation between  
> variables. Isn't it right?

Linear models are linear in the parameters.  They can model highly  
nonlinear effects.

> 3.)        Do I need a non-linear model?

Only if you need a model that is non-linear in the parameters.   
Without checking out your data and model, one cannot say.


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.




> Which solution is the best?
>
>
> Regards,
> Balazs
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kevin.thorpe at utoronto.ca  Fri Apr 10 01:03:11 2009
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 09 Apr 2009 19:03:11 -0400
Subject: [R-sig-ME] LME and nonlinearity?
In-Reply-To: <A5F64057-797A-46FC-82D3-CD5B076E83A9@anu.edu.au>
References: <freemail.20090309231337.10618@fm22.freemail.hu>
	<A5F64057-797A-46FC-82D3-CD5B076E83A9@anu.edu.au>
Message-ID: <49DE7EAF.6070601@utoronto.ca>

John Maindonald wrote:
> Additional to the comments below: Think/check also whether 
> transformation of one or more of the variables (log transformation?) 
> makes the relationship more nearly linear.
> 
> On 10/04/2009, at 7:13 AM, Bal?zs Lest?r wrote:
> 
>> Dear All,
>>
>> I have a mixed model (LME), but one of my explanatory variables is not 
>> linearly related to the dependent variable.
>>
>> 1.)     Somebody told me, to make a 2 or 3 level factor from the 
>> continuous variable. (I wouldn't prefer this)
> 
> In general, this makes poor use of the information in the data.  You 
> lose power.
> 
>> 2.)     I saw in some statistical books that in these cases, I have to 
>> use in the model the quadratic term of the variable. (but the AIC is 
>> much greater than with the  factorized variable)
>>
>> OR
>>
>> Is that possible, to use a poly() function in the lme? (this model 
>> seems to be the best, based on AIC).
> 
> Yes.

I also used ns from the splines package recently to handle 
non-linearity.  It seemed to work like a charm.

> 
>> I'm a bit confused, 'cause the LME supposes linear relation between 
>> variables. Isn't it right?
> 
> Linear models are linear in the parameters.  They can model highly 
> nonlinear effects.
> 
>> 3.)        Do I need a non-linear model?
> 
> Only if you need a model that is non-linear in the parameters.  Without 
> checking out your data and model, one cannot say.
> 
> 
> 
> 
>> Which solution is the best?
>>
>>
>> Regards,
>> Balazs


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057



From smouksassi at Pharsight.com  Fri Apr 10 01:08:54 2009
From: smouksassi at Pharsight.com (Samer Mouksassi)
Date: Thu, 9 Apr 2009 16:08:54 -0700
Subject: [R-sig-ME] LME and nonlinearity?
In-Reply-To: <A5F64057-797A-46FC-82D3-CD5B076E83A9@anu.edu.au>
References: <freemail.20090309231337.10618@fm22.freemail.hu>
	<A5F64057-797A-46FC-82D3-CD5B076E83A9@anu.edu.au>
Message-ID: <5B833E900330354F9FDA984D06F9242805B487D9@ca-exchange.corp.pharsight.com>


Another possible way to diagnose the need of a non-linear model is to use a spline then replace it with more meaningful parametric model according to its shape.

Samer


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Maindonald
Sent: 2009-04-09 18:51
To: Bal?zs Lest?r
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] LME and nonlinearity?

Additional to the comments below: Think/check also whether  
transformation of one or more of the variables (log transformation?)  
makes the relationship more nearly linear.

On 10/04/2009, at 7:13 AM, Bal?zs Lest?r wrote:

> Dear All,
>
> I have a mixed model (LME), but one of my explanatory variables is  
> not linearly related to the dependent variable.
>
> 1.)     Somebody told me, to make a 2 or 3 level factor from the  
> continuous variable. (I wouldn't prefer this)

In general, this makes poor use of the information in the data.  You  
lose power.

> 2.)     I saw in some statistical books that in these cases, I have  
> to use in the model the quadratic term of the variable. (but the AIC  
> is much greater than with the  factorized variable)
>
> OR
>
> Is that possible, to use a poly() function in the lme? (this model  
> seems to be the best, based on AIC).

Yes.

> I'm a bit confused, 'cause the LME supposes linear relation between  
> variables. Isn't it right?

Linear models are linear in the parameters.  They can model highly  
nonlinear effects.

> 3.)        Do I need a non-linear model?

Only if you need a model that is non-linear in the parameters.   
Without checking out your data and model, one cannot say.


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.




> Which solution is the best?
>
>
> Regards,
> Balazs
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From John.Maindonald at anu.edu.au  Fri Apr 10 01:19:09 2009
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Fri, 10 Apr 2009 09:19:09 +1000
Subject: [R-sig-ME] LME and nonlinearity?
In-Reply-To: <5B833E900330354F9FDA984D06F9242805B487D9@ca-exchange.corp.pharsight.com>
References: <freemail.20090309231337.10618@fm22.freemail.hu>
	<A5F64057-797A-46FC-82D3-CD5B076E83A9@anu.edu.au>
	<5B833E900330354F9FDA984D06F9242805B487D9@ca-exchange.corp.pharsight.com>
Message-ID: <5FB1558E-36D3-4098-BCC7-29F449EA0831@anu.edu.au>

These various pieces of advice should come with a warning: Beware of  
all generalized advice.  It may miss key issues that are obvious only  
once one has gained some sense of the scientific background, seen the  
data, and done some preliminary analysis.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 10/04/2009, at 9:08 AM, Samer Mouksassi wrote:

>
> Another possible way to diagnose the need of a non-linear model is  
> to use a spline then replace it with more meaningful parametric  
> model according to its shape.
>
> Samer
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org 
> ] On Behalf Of John Maindonald
> Sent: 2009-04-09 18:51
> To: Bal?zs Lest?r
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] LME and nonlinearity?
>
> Additional to the comments below: Think/check also whether
> transformation of one or more of the variables (log transformation?)
> makes the relationship more nearly linear.
>
> On 10/04/2009, at 7:13 AM, Bal?zs Lest?r wrote:
>
>> Dear All,
>>
>> I have a mixed model (LME), but one of my explanatory variables is
>> not linearly related to the dependent variable.
>>
>> 1.)     Somebody told me, to make a 2 or 3 level factor from the
>> continuous variable. (I wouldn't prefer this)
>
> In general, this makes poor use of the information in the data.  You
> lose power.
>
>> 2.)     I saw in some statistical books that in these cases, I have
>> to use in the model the quadratic term of the variable. (but the AIC
>> is much greater than with the  factorized variable)
>>
>> OR
>>
>> Is that possible, to use a poly() function in the lme? (this model
>> seems to be the best, based on AIC).
>
> Yes.
>
>> I'm a bit confused, 'cause the LME supposes linear relation between
>> variables. Isn't it right?
>
> Linear models are linear in the parameters.  They can model highly
> nonlinear effects.
>
>> 3.)        Do I need a non-linear model?
>
> Only if you need a model that is non-linear in the parameters.
> Without checking out your data and model, one cannot say.
>
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
>
>
>
>> Which solution is the best?
>>
>>
>> Regards,
>> Balazs
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rob.robinson at bto.org  Tue Apr 14 12:14:35 2009
From: rob.robinson at bto.org (Rob Robinson)
Date: Tue, 14 Apr 2009 11:14:35 +0100
Subject: [R-sig-ME] LME and nonlinearity?
In-Reply-To: <freemail.20090309231337.10618@fm22.freemail.hu>
References: <freemail.20090309231337.10618@fm22.freemail.hu>
Message-ID: <8630D3CE8B5B4B7D829344B946BD3573@btodomain.bto.org>

>  3.)        Do I need a non-linear model?
> 

Probably not. As others have pointed out, models need only be linear in
their (transformed) parameters, they can model highly non-linear
relationships. Non-linear models are not linear in their parameters and
cannot be transormed so (the wikipedia page on nonlinear regression might
help in understanding the difference). Before progressing further it sounds
like you need to think carefully about the mechanism behind the relationship
you are trying to model. How is the non-linearity generated? this might help
in thinking the best model to fit. For exploratory purposes gams or splines
might help characterise the pattern (try gamm in mgcv). I'm not sure fitting
higher-order polynomials is really helpful as it's hard to think of what
would generate a quartic, quintic, ... (or even cubic) relationship. If
there's some sort of threshold in the response, then converting to a
factorial variable might help.
Hope that helps
Cheers
rob

*** Help us celebrate 100 yrs of Ringing http://btoringing.blogspot.com/ **

Dr Rob Robinson, Principal Ecologist
British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
Ph: +44 (0)1842 750050     E: rob.robinson at bto.org
Fx: +44 (0)1842 750030     W: www.bto.org/aboutBTO/cvs/rob_robinson.htm

====== "How can anyone be enlightened, when truth is so poorly lit" =======
 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Bal?zs Lest?r
> Sent: 09 April 2009 22:14
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] LME and nonlinearity?
> 
> Dear All,
> 
> I have a mixed model (LME), but one of my explanatory 
> variables is not linearly related to the dependent variable.
> 
>  1.)     Somebody told me, to make a 2 or 3 level factor from 
> the continuous variable. (I wouldn't prefer this)
> 
>   2.)     I saw in some statistical books that in these 
> cases, I have to use in the model the quadratic term of the 
> variable. (but the AIC is much greater than with the  
> factorized variable)
> 
> OR
> 
>  Is that possible, to use a poly() function in the lme? (this 
> model seems to be the best, based on AIC).
>  
> 
> I'm a bit confused, 'cause the LME supposes linear relation 
> between variables. Isn't it right?
> 
>  3.)        Do I need a non-linear model?
> 
> Which solution is the best?
> 
> 
> Regards,
> Balazs
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From harlancampbell at gmail.com  Tue Apr 14 16:20:05 2009
From: harlancampbell at gmail.com (H c)
Date: Tue, 14 Apr 2009 10:20:05 -0400
Subject: [R-sig-ME] Numerical methods used to compute correlation
	coefficients
Message-ID: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090414/8c53b42b/attachment.pl>

From mdekar at uark.edu  Tue Apr 14 17:03:13 2009
From: mdekar at uark.edu (Matthew P. Dekar)
Date: Tue, 14 Apr 2009 10:03:13 -0500
Subject: [R-sig-ME] unequal spacing in repeated measures
Message-ID: <e789c499ec24.49e45f61@uark.edu>

I would appreciate any advice in regards to the handling of unequal spacing in repeated measures regression with mixed models.  I sampled crayfish with funnel traps and measured environmental predictor variables monthly for two years in 12 stream pools.  Data are presented in terms of the average number of crayfish per trap per pool (response variable = catch-per-unit-effort = cpue).  However, the sampling interval was not fixed so I created a continuous time variable (day) indicating the number of days elapsed from the first sampling occasion (1,35,55,...,643).  As an example, I modeled cpue in a repeated measures framework with a single predictor variable (stream temperature = temp), pool as the subject/random variable, and day was included using a spatial covariance structure (Exponential = corExp) in lme following:

cpu1<-lme(cpue~temp, random=~1 | pool, data=CPU, method = "ML")
cpu2<- update(cpu1, correlation = corExp(form=~day))

Is this an appropriate usage of spatial covariance structures?  Can the above analysis be replicated in lmer?  Thanks very much for your time.

Matthew Dekar  

Arkansas Cooperative Fish & Wildlife Research Unit
Department of Biological Sciences
University of Arkansas
Fayetteville, AR 72701
(479) 575-6360



From bates at stat.wisc.edu  Tue Apr 14 18:37:58 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 14 Apr 2009 11:37:58 -0500
Subject: [R-sig-ME] Numerical methods used to compute correlation
	coefficients
In-Reply-To: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>
References: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>
Message-ID: <40e66e0b0904140937n268340a6maa2fbe1c56fe33f8@mail.gmail.com>

On Tue, Apr 14, 2009 at 9:20 AM, H c <harlancampbell at gmail.com> wrote:
> I have have already posted the following question: ?What numerical methods
> are used in nlme to estimate correlation parameters?
> I was referred to the Pinheiro and Bates book. ?Unfortunately, on p. 202,
> section 5.1.1, under the title "Estimation and Computational Methods", no
> description on a numerical method is provided. ?(When the data is
> transformed to work with the profiled likelihood(y->ystar), one needs the
> parameters that define Lambda. ?How are these parameters estimated?)

I'm not sure what you mean by "correlation parameters".  If you mean
the correlation parameters in the unconditional distribution of the
random effects then those are estimated by maximum likelihood (ML) or
residual maximum likelihood (REML).  The profiled deviance or the
profiled REML criterion is evaluated with respect to a transformed set
of parameters and this value is optimized.



From bolker at ufl.edu  Tue Apr 14 20:12:17 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 14 Apr 2009 14:12:17 -0400
Subject: [R-sig-ME] unequal spacing in repeated measures
In-Reply-To: <e789c499ec24.49e45f61@uark.edu>
References: <e789c499ec24.49e45f61@uark.edu>
Message-ID: <49E4D201.3010903@ufl.edu>

Matthew P. Dekar wrote:
> I would appreciate any advice in regards to the handling of unequal
> spacing in repeated measures regression with mixed models.  I sampled
> crayfish with funnel traps and measured environmental predictor
> variables monthly for two years in 12 stream pools.  Data are
> presented in terms of the average number of crayfish per trap per
> pool (response variable = catch-per-unit-effort = cpue).  However,
> the sampling interval was not fixed so I created a continuous time
> variable (day) indicating the number of days elapsed from the first
> sampling occasion (1,35,55,...,643).  As an example, I modeled cpue
> in a repeated measures framework with a single predictor variable
> (stream temperature = temp), pool as the subject/random variable, and
> day was included using a spatial covariance structure (Exponential =
> corExp) in lme following:
> 
> cpu1<-lme(cpue~temp, random=~1 | pool, data=CPU, method = "ML") 
> cpu2<- update(cpu1, correlation = corExp(form=~day))
> 
> Is this an appropriate usage of spatial covariance structures?  Can
> the above analysis be replicated in lmer?  Thanks very much for your
> time.
> 

  You should use correlation=corCAR1(form=~day) for a continuous
time covariate.

  You can't do this in lmer (yet, or for a while) -- Doug Bates has
stated that implementing correlation structures a la nlme is lower
on his list than working out other issues.

  good luck,
   Ben Bolker



From mick.wu at mail.mcgill.ca  Wed Apr 15 15:03:58 2009
From: mick.wu at mail.mcgill.ca (Gi-Mick Wu)
Date: Wed, 15 Apr 2009 09:03:58 -0400
Subject: [R-sig-ME] unequal spacing in repeated measures
Message-ID: <B89AE5DF4F2A964FB322E3F53F02EE0D24B2F2CA43@EXMBXVS4A.campus.mcgill.ca>


________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org [r-sig-mixed-models-request at r-project.org]
Sent: April 15, 2009 6:00 AM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 28, Issue 17

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: LME and nonlinearity? (Rob Robinson)
   2. Numerical methods used to compute correlation     coefficients (H c)
   3. unequal spacing in repeated measures (Matthew P. Dekar)
   4. Re: Numerical methods used to compute correlation
      coefficients (Douglas Bates)
   5. Re: unequal spacing in repeated measures (Ben Bolker)


----------------------------------------------------------------------

Message: 1
Date: Tue, 14 Apr 2009 11:14:35 +0100
From: "Rob Robinson" <rob.robinson at bto.org>
Subject: Re: [R-sig-ME] LME and nonlinearity?
To: " 'Bal?zs Lest?r' " <ebszolocsucsor at freemail.hu>
Cc: r-sig-mixed-models at r-project.org
Message-ID: <8630D3CE8B5B4B7D829344B946BD3573 at btodomain.bto.org>
Content-Type: text/plain;       charset="iso-8859-1"

>  3.)        Do I need a non-linear model?
>

Probably not. As others have pointed out, models need only be linear in
their (transformed) parameters, they can model highly non-linear
relationships. Non-linear models are not linear in their parameters and
cannot be transormed so (the wikipedia page on nonlinear regression might
help in understanding the difference). Before progressing further it sounds
like you need to think carefully about the mechanism behind the relationship
you are trying to model. How is the non-linearity generated? this might help
in thinking the best model to fit. For exploratory purposes gams or splines
might help characterise the pattern (try gamm in mgcv). I'm not sure fitting
higher-order polynomials is really helpful as it's hard to think of what
would generate a quartic, quintic, ... (or even cubic) relationship. If
there's some sort of threshold in the response, then converting to a
factorial variable might help.
Hope that helps
Cheers
rob

*** Help us celebrate 100 yrs of Ringing http://btoringing.blogspot.com/ **

Dr Rob Robinson, Principal Ecologist
British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
Ph: +44 (0)1842 750050     E: rob.robinson at bto.org
Fx: +44 (0)1842 750030     W: www.bto.org/aboutBTO/cvs/rob_robinson.htm

====== "How can anyone be enlightened, when truth is so poorly lit" =======


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
> Of Bal?zs Lest?r
> Sent: 09 April 2009 22:14
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] LME and nonlinearity?
>
> Dear All,
>
> I have a mixed model (LME), but one of my explanatory
> variables is not linearly related to the dependent variable.
>
>  1.)     Somebody told me, to make a 2 or 3 level factor from
> the continuous variable. (I wouldn't prefer this)
>
>   2.)     I saw in some statistical books that in these
> cases, I have to use in the model the quadratic term of the
> variable. (but the AIC is much greater than with the
> factorized variable)
>
> OR
>
>  Is that possible, to use a poly() function in the lme? (this
> model seems to be the best, based on AIC).
>
>
> I'm a bit confused, 'cause the LME supposes linear relation
> between variables. Isn't it right?
>
>  3.)        Do I need a non-linear model?
>
> Which solution is the best?
>
>
> Regards,
> Balazs
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



------------------------------

Message: 2
Date: Tue, 14 Apr 2009 10:20:05 -0400
From: H c <harlancampbell at gmail.com>
Subject: [R-sig-ME] Numerical methods used to compute correlation
        coefficients
To: r-sig-mixed-models at r-project.org
Message-ID:
        <222824550904140720qacc8580g98b1a889ca837712 at mail.gmail.com>
Content-Type: text/plain

I have have already posted the following question:  What numerical methods
are used in nlme to estimate correlation parameters?
I was referred to the Pinheiro and Bates book.  Unfortunately, on p. 202,
section 5.1.1, under the title "Estimation and Computational Methods", no
description on a numerical method is provided.  (When the data is
transformed to work with the profiled likelihood(y->ystar), one needs the
parameters that define Lambda.  How are these parameters estimated?)

Any help is always appreciated,

Harlan

        [[alternative HTML version deleted]]



------------------------------

Message: 3
Date: Tue, 14 Apr 2009 10:03:13 -0500
From: "Matthew P. Dekar" <mdekar at uark.edu>
Subject: [R-sig-ME] unequal spacing in repeated measures
To: r-sig-mixed-models at r-project.org
Message-ID: <e789c499ec24.49e45f61 at uark.edu>
Content-Type: text/plain; charset=us-ascii

I would appreciate any advice in regards to the handling of unequal spacing in repeated measures regression with mixed models.  I sampled crayfish with funnel traps and measured environmental predictor variables monthly for two years in 12 stream pools.  Data are presented in terms of the average number of crayfish per trap per pool (response variable = catch-per-unit-effort = cpue).  However, the sampling interval was not fixed so I created a continuous time variable (day) indicating the number of days elapsed from the first sampling occasion (1,35,55,...,643).  As an example, I modeled cpue in a repeated measures framework with a single predictor variable (stream temperature = temp), pool as the subject/random variable, and day was included using a spatial covariance structure (Exponential = corExp) in lme following:

cpu1<-lme(cpue~temp, random=~1 | pool, data=CPU, method = "ML")
cpu2<- update(cpu1, correlation = corExp(form=~day))

Is this an appropriate usage of spatial covariance structures?  Can the above analysis be replicated in lmer?  Thanks very much for your time.

Matthew Dekar

Arkansas Cooperative Fish & Wildlife Research Unit
Department of Biological Sciences
University of Arkansas
Fayetteville, AR 72701
(479) 575-6360



------------------------------

Message: 4
Date: Tue, 14 Apr 2009 11:37:58 -0500
From: Douglas Bates <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] Numerical methods used to compute correlation
        coefficients
To: H c <harlancampbell at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Message-ID:
        <40e66e0b0904140937n268340a6maa2fbe1c56fe33f8 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

On Tue, Apr 14, 2009 at 9:20 AM, H c <harlancampbell at gmail.com> wrote:
> I have have already posted the following question: ?What numerical methods
> are used in nlme to estimate correlation parameters?
> I was referred to the Pinheiro and Bates book. ?Unfortunately, on p. 202,
> section 5.1.1, under the title "Estimation and Computational Methods", no
> description on a numerical method is provided. ?(When the data is
> transformed to work with the profiled likelihood(y->ystar), one needs the
> parameters that define Lambda. ?How are these parameters estimated?)

I'm not sure what you mean by "correlation parameters".  If you mean
the correlation parameters in the unconditional distribution of the
random effects then those are estimated by maximum likelihood (ML) or
residual maximum likelihood (REML).  The profiled deviance or the
profiled REML criterion is evaluated with respect to a transformed set
of parameters and this value is optimized.



------------------------------

Message: 5
Date: Tue, 14 Apr 2009 14:12:17 -0400
From: Ben Bolker <bolker at ufl.edu>
Subject: Re: [R-sig-ME] unequal spacing in repeated measures
To: "Matthew P. Dekar" <mdekar at uark.edu>,       R Mixed Models
        <r-sig-mixed-models at r-project.org>
Message-ID: <49E4D201.3010903 at ufl.edu>
Content-Type: text/plain; charset=ISO-8859-1

Matthew P. Dekar wrote:
> I would appreciate any advice in regards to the handling of unequal
> spacing in repeated measures regression with mixed models.  I sampled
> crayfish with funnel traps and measured environmental predictor
> variables monthly for two years in 12 stream pools.  Data are
> presented in terms of the average number of crayfish per trap per
> pool (response variable = catch-per-unit-effort = cpue).  However,
> the sampling interval was not fixed so I created a continuous time
> variable (day) indicating the number of days elapsed from the first
> sampling occasion (1,35,55,...,643).  As an example, I modeled cpue
> in a repeated measures framework with a single predictor variable
> (stream temperature = temp), pool as the subject/random variable, and
> day was included using a spatial covariance structure (Exponential =
> corExp) in lme following:
>
> cpu1<-lme(cpue~temp, random=~1 | pool, data=CPU, method = "ML")
> cpu2<- update(cpu1, correlation = corExp(form=~day))
>
> Is this an appropriate usage of spatial covariance structures?  Can
> the above analysis be replicated in lmer?  Thanks very much for your
> time.
>

  You should use correlation=corCAR1(form=~day) for a continuous
time covariate.

  You can't do this in lmer (yet, or for a while) -- Doug Bates has
stated that implementing correlation structures a la nlme is lower
on his list than working out other issues.

  good luck,
   Ben Bolker

------------------------------

In the mean time, the function "geeglm" may do the job if the interest is in temperature (fixed effects at the population level) rather than specific differences among pools (random effect being only noise). 

The correlation structure among repeated observations can be specified with a "waves" argument to account for different sampling intervals.
Example with an auto-regressive correlation structure:
cpu1<-geeglm(cpue~temp, id=pool, corstruc="ar1", waves="day", data=CPU)

hope this helps,
Mick
ps is stream temperature constant throughout the sampling period?
pps This is my first attempt to help on the list, so feel free to correct me... (hopefully I will get better at it some day)



From harlancampbell at gmail.com  Wed Apr 15 16:32:55 2009
From: harlancampbell at gmail.com (H c)
Date: Wed, 15 Apr 2009 10:32:55 -0400
Subject: [R-sig-ME] Numerical methods used to compute correlation
	coefficients
In-Reply-To: <222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
References: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>
	<40e66e0b0904140937n268340a6maa2fbe1c56fe33f8@mail.gmail.com>
	<222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
Message-ID: <222824550904150732k16dc16ddtcb009f6ac23e0275@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090415/6de4555f/attachment.pl>

From harlancampbell at gmail.com  Wed Apr 15 16:33:38 2009
From: harlancampbell at gmail.com (H c)
Date: Wed, 15 Apr 2009 10:33:38 -0400
Subject: [R-sig-ME] Fwd: Numerical methods used to compute correlation
	coefficients
In-Reply-To: <222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
References: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>
	<40e66e0b0904140937n268340a6maa2fbe1c56fe33f8@mail.gmail.com>
	<222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
Message-ID: <222824550904150733p7de1d7caqd492d6c2d69751ef@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090415/7a2fb78b/attachment.pl>

From bates at stat.wisc.edu  Wed Apr 15 18:59:03 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 15 Apr 2009 11:59:03 -0500
Subject: [R-sig-ME] Numerical methods used to compute correlation
	coefficients
In-Reply-To: <222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
References: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>
	<40e66e0b0904140937n268340a6maa2fbe1c56fe33f8@mail.gmail.com>
	<222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
Message-ID: <40e66e0b0904150959m3434b21dof22360a71d345fa7@mail.gmail.com>

On Tue, Apr 14, 2009 at 12:02 PM, H c <harlancampbell at gmail.com> wrote:
> Thank you for the quick response.
> when I refer to "correlation parameters", I mean the "generally small set of
> parameters \lambda" that parametrize the \Lambda_{i} Variance-Covariance
> matrix.
> For example, one has time series data such that every subject has been
> observed at 4 time points. ?One wishes to model this using an AR(1)
> correlation structure within the mixed model.
> the AR(1) is parametrized by a fixed parameter, \phi :
> lme(y~X, random=~1|ID, method="ML", data=data,
> correlation=corAR1(0.5,form=~X,fixed=FALSE))

> Since there is no closed form solution for the maximum-likelihood estimate
> of \phi. ?what numerical methods are used to arrive at the given estimate?
> Hopefully this has clarified my question.

In the sense that I know what you mean by the correlation parameters.
I'm not sure how to characterize the numerical methods other than to
say that the deviance (negative twice the log-likelihood) or the
corresponding version of the REML criterion is expressed with respect
to an unconstrained parameter and the resulting function optimized
using optimization software within R (nlminb).  You can check the
definition of the corAR family to determine exactly how the
parameterization is defined.

> Thanks again,
> Harlan
>
> On Tue, Apr 14, 2009 at 12:37 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> On Tue, Apr 14, 2009 at 9:20 AM, H c <harlancampbell at gmail.com> wrote:
>> > I have have already posted the following question: ?What numerical
>> > methods
>> > are used in nlme to estimate correlation parameters?
>> > I was referred to the Pinheiro and Bates book. ?Unfortunately, on p.
>> > 202,
>> > section 5.1.1, under the title "Estimation and Computational Methods",
>> > no
>> > description on a numerical method is provided. ?(When the data is
>> > transformed to work with the profiled likelihood(y->ystar), one needs
>> > the
>> > parameters that define Lambda. ?How are these parameters estimated?)
>>
>> I'm not sure what you mean by "correlation parameters". ?If you mean
>> the correlation parameters in the unconditional distribution of the
>> random effects then those are estimated by maximum likelihood (ML) or
>> residual maximum likelihood (REML). ?The profiled deviance or the
>> profiled REML criterion is evaluated with respect to a transformed set
>> of parameters and this value is optimized.
>
>



From bates at stat.wisc.edu  Wed Apr 15 21:30:17 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 15 Apr 2009 14:30:17 -0500
Subject: [R-sig-ME] Numerical methods used to compute correlation
	coefficients
In-Reply-To: <222824550904151114n51c48dfdxc55d2727ba8f18e6@mail.gmail.com>
References: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>
	<40e66e0b0904140937n268340a6maa2fbe1c56fe33f8@mail.gmail.com>
	<222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
	<40e66e0b0904150959m3434b21dof22360a71d345fa7@mail.gmail.com>
	<222824550904151114n51c48dfdxc55d2727ba8f18e6@mail.gmail.com>
Message-ID: <40e66e0b0904151230w3423d816t5bb93aeb8fcd5376@mail.gmail.com>

On Wed, Apr 15, 2009 at 1:14 PM, H c <harlancampbell at gmail.com> wrote:

> Thank you. ?This ?is exactly what I wanted to know. ?Perhaps one last
> question. ?Is there any?particular?reason to prefer ?this optimization
> routine over another, such as "optimize()"?

optimize() only handles scalar problems and you must define an
interval in which the optimum is to be found.

I have used other unconstrained optimizers such as nlm() and optim()
but had trouble with both of those.  The original version of the nlme
package for S and S-PLUS used the ms() optimizer in S which was based
on some Fortran code by David Gay.  Initially that code could not be
used in R because it was not released under an open source license.
Eventually it was released to the public domain and I wrote the nlminb
interface code for R, primarily so I could use it as the optimizer in
the nlme and lme4 packages.

Even this code by David Gay is far from ideal.  The development
version of the lme4 package factors out the evaluation of the deviance
function or the REML criterion from the optimization of these, so that
those who are interested can experiment with different optimizers and
see what works best in their problems.

> On Wed, Apr 15, 2009 at 12:59 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> On Tue, Apr 14, 2009 at 12:02 PM, H c <harlancampbell at gmail.com> wrote:
>> > Thank you for the quick response.
>> > when I refer to "correlation parameters", I mean the "generally small
>> > set of
>> > parameters \lambda" that parametrize the \Lambda_{i} Variance-Covariance
>> > matrix.
>> > For example, one has time series data such that every subject has been
>> > observed at 4 time points. ?One wishes to model this using an AR(1)
>> > correlation structure within the mixed model.
>> > the AR(1) is parametrized by a fixed parameter, \phi :
>> > lme(y~X, random=~1|ID, method="ML", data=data,
>> > correlation=corAR1(0.5,form=~X,fixed=FALSE))
>>
>> > Since there is no closed form solution for the maximum-likelihood
>> > estimate
>> > of \phi. ?what numerical methods are used to arrive at the given
>> > estimate?
>> > Hopefully this has clarified my question.
>>
>> In the sense that I know what you mean by the correlation parameters.
>> I'm not sure how to characterize the numerical methods other than to
>> say that the deviance (negative twice the log-likelihood) or the
>> corresponding version of the REML criterion is expressed with respect
>> to an unconstrained parameter and the resulting function optimized
>> using optimization software within R (nlminb). ?You can check the
>> definition of the corAR family to determine exactly how the
>> parameterization is defined.
>>
>> > Thanks again,
>> > Harlan
>> >
>> > On Tue, Apr 14, 2009 at 12:37 PM, Douglas Bates <bates at stat.wisc.edu>
>> > wrote:
>> >>
>> >> On Tue, Apr 14, 2009 at 9:20 AM, H c <harlancampbell at gmail.com> wrote:
>> >> > I have have already posted the following question: ?What numerical
>> >> > methods
>> >> > are used in nlme to estimate correlation parameters?
>> >> > I was referred to the Pinheiro and Bates book. ?Unfortunately, on p.
>> >> > 202,
>> >> > section 5.1.1, under the title "Estimation and Computational
>> >> > Methods",
>> >> > no
>> >> > description on a numerical method is provided. ?(When the data is
>> >> > transformed to work with the profiled likelihood(y->ystar), one needs
>> >> > the
>> >> > parameters that define Lambda. ?How are these parameters estimated?)
>> >>
>> >> I'm not sure what you mean by "correlation parameters". ?If you mean
>> >> the correlation parameters in the unconditional distribution of the
>> >> random effects then those are estimated by maximum likelihood (ML) or
>> >> residual maximum likelihood (REML). ?The profiled deviance or the
>> >> profiled REML criterion is evaluated with respect to a transformed set
>> >> of parameters and this value is optimized.
>> >
>> >
>
>



From lucianolasala at yahoo.com.ar  Thu Apr 16 05:58:02 2009
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 15 Apr 2009 20:58:02 -0700 (PDT)
Subject: [R-sig-ME] p values absent in lmer output
Message-ID: <499060.22317.qm@web59904.mail.ac4.yahoo.com>


Dear R-mixed-models experts, 

I am running R version 2.8.1 on Windows Vista. I am studying factors which influence egg morphometrics in a seagull population. My dataset consists of: ?Year? (0,1), ?HatchingOrder? (HO) (1, 2, 3) and ?ClutchSize? (1, 2, 3) as independent variables, and ?Egg measurements? (I run models for max. breadth, length and volume) as dependent variable (continuous). I included ?NestID? as a random effect. 

I specified my model as follows: 

model <- lmer(EggVolume~HO+Year+ClutchSize+(1|NestID),Data)
summary(model)

(See output below)

At this point, my main questions are: 

1. Is my model correctly built? 

2. Why don?t I get p values for t? 

3. If I simplify my model to: lmer (EggVolume ~ HO+ (1|NestID), Data) 
.... I still don't get any p values. How is that possible? Is there any way to compute p values for the fixed effects? 

Linear mixed model fit by REML 
Formula: EggVol ~ HatchingOrder1 + EggVol + Year1 + ClutchSize + (1 | NestID) 
Data: Data 

AIC     BIC     logLik     deviance     REMLdev
1441    1469    -712.3     1431         1425

Random effects:
Groups     Name              Variance     Std.Dev.
NestID     (Intercept)       21.9883      4.6892  
Residual                      7.9196      2.8142  

Number of obs: 248, groups: NestID, 120

Fixed effects:
                       Estimate          Std. Error          t value
(Intercept)            77.060             1.124              68.54
HatchingOrder1Second   -2.227             0.443              -5.03
HatchingOrder1Third    -5.945             0.544              -10.93
Year2006               -2.504             0.969              -2.58
ClutchSizeTwo-eggs      2.101             1.349               1.56
ClutchSizeThree-eggs    5.869             1.243               4.72

Correlation of Fixed Effects:
               (Intr)     HtcO1S     HtcO1T    Y12006    CltchSzTw-
HtchngOrd1S   -0.004                                
HtchngOrd1T   -0.018      0.407                         
Year12006     -0.460      0.008      0.038                  
CltchSzTw-g   -0.598     -0.153      -0.067    -0.129          
CltchSzThr-   -0.734     -0.177      -0.216     0.046    0.616  
   
Thank you very much in advance! 

Luciano 



      Yahoo! Cocina
Recetas pr?cticas y comida saludable
http://ar.mujer.yahoo.com/cocina/



From christian.salas at yale.edu  Thu Apr 16 11:03:48 2009
From: christian.salas at yale.edu (Christian Salas)
Date: Thu, 16 Apr 2009 05:03:48 -0400
Subject: [R-sig-ME] logLik (old-fashion way) for mixed-effects models
In-Reply-To: <mailman.11699.1239814814.4476.r-sig-mixed-models@r-project.org>
References: <mailman.11699.1239814814.4476.r-sig-mixed-models@r-project.org>
Message-ID: <49E6F474.6010808@yale.edu>

If i already fit a lm() model, i can obtain the log-likelihood [i do not
  want to use AIC()] using the residuals from the model, and using the
  RMSE of the model as sigma for my normal pdf. This would be in R like

 > sum(dnorm(-resi,mean=0,sd=sigma,log=T))  [1]

  if i fit a gls model i can do the same

  for a lme() model, i know that we cannot just use the same loglik model
  [1], because they are different. I wonder if somedody already have 
some syntax in R similar to [1] but for  mixed-effects models, i mean 
something that compute the log-likelihood but without using lme() 
directly as summary(lme.obj)$AIC

  thanks in advance!

-------------------------------------------------------------------------------
Christian Salas                     E-mail:christian.salas at yale.edu
PhD candidate                       http://environment.yale.edu/salas
School of Forestry and Environmental Studies
Yale University                     Tel: +1-(203)-432 5126
360 Prospect St                     Fax:+1-(203)-432 3809
New Haven, CT 06511-2189            Office: Room 35, Marsh Hall
USA

Yale Biometrics Lab                  http://environment.yale.edu/biometrics



From a.renwick at abdn.ac.uk  Thu Apr 16 13:24:23 2009
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Thu, 16 Apr 2009 12:24:23 +0100
Subject: [R-sig-ME] Presentation of results from GLMMs
Message-ID: <B9D1301370916C44B5874AF340C18B9B8F0E90CB14@VMAILB.uoa.abdn.ac.uk>

Dear All

A while back there was a question regarding plotting predicted values (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/002044.html). There was not much response which I take to assume there is no definitive answer. However I wonder if anyone could give me a bit of advice as to how to present results for a GLMM model with a binomial error structure.

Here is an example:

y<-cbind(both$Totalmoreonce,both$UsedOnce)#an index of aggregation in a population of voles

hier3<-lmer(y~Sex+Margin+sess+(1|Farm/Site), family=binomial, data=both, REML=FALSE)

summary(hier3)
#Generalized linear mixed model fit by the Laplace approximation
#Formula: y ~ Sex + Margin + sess + (1 | Farm/Site)
#   Data: both
#   AIC   BIC logLik deviance
# 191.0 213.5 -86.49    173.0
#Random effects:
# Groups    Name        Variance Std.Dev.
# Site:Farm (Intercept) 0.039191 0.19797
# Farm      (Intercept) 0.000000 0.00000
#Number of obs: 90, groups: Site:Farm, 14; Farm, 7
#
#Fixed effects:
#             Estimate Std. Error z value Pr(>|z|)
#(Intercept)  -2.20209    0.33088  -6.655 2.83e-11 ***
#Sexmale      -0.31110    0.12781  -2.434 0.014928 *
#Marginmedium  0.07763    0.34604   0.224 0.822483
#Marginwide    1.23916    0.30748   4.030 5.58e-05 ***
#sessAugust    0.60537    0.18324   3.304 0.000954 ***
#sessJune      0.58132    0.18511   3.140 0.001687 **
#sessOctober  -0.64398    0.24468  -2.632 0.008491 **

Now I want to show graphically that y changes with margin width, ideally using predicted values while accounting for the other variables in the model.

invlogit<-function(x){1/(1+exp(-x))}#function to backtransform the logit values in model

#predicted values bsaed on only the fixed effects for each margin width
w<-invlogit(cbind(1,0,0,1,0,0,0)%*%fixef(hier3))#wide
m<-invlogit(cbind(1,0,0,0,0,0,0)%*%fixef(hier3))#medium
n<-invlogit(cbind(1,0,1,0,0,0,0)%*%fixef(hier3))#narrow

I become stuck when trying to predict the CI of these values.

I was wondering if anyone has any ideas either how to calculate the CI OR any better ways to present the data.

Many thanks,
Anna


The University of Aberdeen is a charity registered in Scotland, No SC013683.



From bates at stat.wisc.edu  Thu Apr 16 15:34:22 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 16 Apr 2009 08:34:22 -0500
Subject: [R-sig-ME] logLik (old-fashion way) for mixed-effects models
In-Reply-To: <49E6F474.6010808@yale.edu>
References: <mailman.11699.1239814814.4476.r-sig-mixed-models@r-project.org>
	<49E6F474.6010808@yale.edu>
Message-ID: <40e66e0b0904160634s3b46f797n7b20fec6a58ca1ef@mail.gmail.com>

On Thu, Apr 16, 2009 at 4:03 AM, Christian Salas
<christian.salas at yale.edu> wrote:
> If i already fit a lm() model, i can obtain the log-likelihood [i do not
> ?want to use AIC()] using the residuals from the model, and using the
> ?RMSE of the model as sigma for my normal pdf. This would be in R like

But the RMSE is not the maximum likelihood estimate of sigma.  It's
the REML estimate but not the MLE.

>> sum(dnorm(-resi,mean=0,sd=sigma,log=T)) ?[1]
>
> ?if i fit a gls model i can do the same
>
> ?for a lme() model, i know that we cannot just use the same loglik model
> ?[1], because they are different. I wonder if somedody already have some
> syntax in R similar to [1] but for ?mixed-effects models, i mean something
> that compute the log-likelihood but without using lme() directly as
> summary(lme.obj)$AIC

Assuming that you fit with method = "ML" then wouldn't it be simplest
just to use

logLik(lme.obj)

It isn't clear from your question whether you want another approach
involving residuals, etc. or if it is just the fact that you are not
aware of the logLik generic.

> ?thanks in advance!
>
> -------------------------------------------------------------------------------
> Christian Salas ? ? ? ? ? ? ? ? ? ? E-mail:christian.salas at yale.edu
> PhD candidate ? ? ? ? ? ? ? ? ? ? ? http://environment.yale.edu/salas
> School of Forestry and Environmental Studies
> Yale University ? ? ? ? ? ? ? ? ? ? Tel: +1-(203)-432 5126
> 360 Prospect St ? ? ? ? ? ? ? ? ? ? Fax:+1-(203)-432 3809
> New Haven, CT 06511-2189 ? ? ? ? ? ?Office: Room 35, Marsh Hall
> USA
>
> Yale Biometrics Lab ? ? ? ? ? ? ? ? ?http://environment.yale.edu/biometrics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From christian.salas at yale.edu  Thu Apr 16 15:50:05 2009
From: christian.salas at yale.edu (Christian Salas)
Date: Thu, 16 Apr 2009 09:50:05 -0400
Subject: [R-sig-ME] logLik (old-fashion way) for mixed-effects models
In-Reply-To: <40e66e0b0904160634s3b46f797n7b20fec6a58ca1ef@mail.gmail.com>
References: <mailman.11699.1239814814.4476.r-sig-mixed-models@r-project.org>	
	<49E6F474.6010808@yale.edu>
	<40e66e0b0904160634s3b46f797n7b20fec6a58ca1ef@mail.gmail.com>
Message-ID: <49E7378D.7030001@yale.edu>

Dear Prof. Bates:

I am aware of the logLik(lme.obj),  sorry if i was not clear before.
What I am aiming to find is a similar syntax (to the one that i use for 
lm) involving the residuals from a lme fitted object, but without using 
logLik(lme.obj), that allows me to compute the log-likelihood value of 
the fitted model. Probably this would require retrieving both the ML 
sigma for the errors and the sigma for the random effects of the lme.obj

thanks
c

-------------------------------------------------------------------------------
Christian Salas                     E-mail:christian.salas at yale.edu
PhD candidate                       http://environment.yale.edu/salas
School of Forestry and Environmental Studies
Yale University                     Tel: +1-(203)-432 5126
360 Prospect St                     Fax:+1-(203)-432 3809
New Haven, CT 06511-2189            Office: Room 35, Marsh Hall
USA

Yale Biometrics Lab                  http://environment.yale.edu/biometrics
-------------------------------------------------------------------------------





Douglas Bates wrote:
> On Thu, Apr 16, 2009 at 4:03 AM, Christian Salas
> <christian.salas at yale.edu> wrote:
>> If i already fit a lm() model, i can obtain the log-likelihood [i do not
>>  want to use AIC()] using the residuals from the model, and using the
>>  RMSE of the model as sigma for my normal pdf. This would be in R like
> 
> But the RMSE is not the maximum likelihood estimate of sigma.  It's
> the REML estimate but not the MLE.
> 
>>> sum(dnorm(-resi,mean=0,sd=sigma,log=T))  [1]
>>  if i fit a gls model i can do the same
>>
>>  for a lme() model, i know that we cannot just use the same loglik model
>>  [1], because they are different. I wonder if somedody already have some
>> syntax in R similar to [1] but for  mixed-effects models, i mean something
>> that compute the log-likelihood but without using lme() directly as
>> summary(lme.obj)$AIC
> 
> Assuming that you fit with method = "ML" then wouldn't it be simplest
> just to use
> 
> logLik(lme.obj)
> 
> It isn't clear from your question whether you want another approach
> involving residuals, etc. or if it is just the fact that you are not
> aware of the logLik generic.
> 
>>  thanks in advance!
>>
>> -------------------------------------------------------------------------------
>> Christian Salas                     E-mail:christian.salas at yale.edu
>> PhD candidate                       http://environment.yale.edu/salas
>> School of Forestry and Environmental Studies
>> Yale University                     Tel: +1-(203)-432 5126
>> 360 Prospect St                     Fax:+1-(203)-432 3809
>> New Haven, CT 06511-2189            Office: Room 35, Marsh Hall
>> USA
>>
>> Yale Biometrics Lab                  http://environment.yale.edu/biometrics
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From ggrothendieck at gmail.com  Thu Apr 16 15:55:14 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 16 Apr 2009 09:55:14 -0400
Subject: [R-sig-ME] logLik (old-fashion way) for mixed-effects models
In-Reply-To: <49E6F474.6010808@yale.edu>
References: <mailman.11699.1239814814.4476.r-sig-mixed-models@r-project.org> 
	<49E6F474.6010808@yale.edu>
Message-ID: <971536df0904160655k6c0c0cc7o5bd195f35daa703@mail.gmail.com>

The regress package maximizes log likelihood (as well as other
criteria) for mixed models whose covariance matrix is a linear
combination of known matrices.

On Thu, Apr 16, 2009 at 5:03 AM, Christian Salas
<christian.salas at yale.edu> wrote:
> If i already fit a lm() model, i can obtain the log-likelihood [i do not
> ?want to use AIC()] using the residuals from the model, and using the
> ?RMSE of the model as sigma for my normal pdf. This would be in R like
>
>> sum(dnorm(-resi,mean=0,sd=sigma,log=T)) ?[1]
>
> ?if i fit a gls model i can do the same
>
> ?for a lme() model, i know that we cannot just use the same loglik model
> ?[1], because they are different. I wonder if somedody already have some
> syntax in R similar to [1] but for ?mixed-effects models, i mean something
> that compute the log-likelihood but without using lme() directly as
> summary(lme.obj)$AIC
>
> ?thanks in advance!
>
> -------------------------------------------------------------------------------
> Christian Salas ? ? ? ? ? ? ? ? ? ? E-mail:christian.salas at yale.edu
> PhD candidate ? ? ? ? ? ? ? ? ? ? ? http://environment.yale.edu/salas
> School of Forestry and Environmental Studies
> Yale University ? ? ? ? ? ? ? ? ? ? Tel: +1-(203)-432 5126
> 360 Prospect St ? ? ? ? ? ? ? ? ? ? Fax:+1-(203)-432 3809
> New Haven, CT 06511-2189 ? ? ? ? ? ?Office: Room 35, Marsh Hall
> USA
>
> Yale Biometrics Lab ? ? ? ? ? ? ? ? ?http://environment.yale.edu/biometrics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Apr 16 16:16:58 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 16 Apr 2009 09:16:58 -0500
Subject: [R-sig-ME] logLik (old-fashion way) for mixed-effects models
In-Reply-To: <49E7378D.7030001@yale.edu>
References: <mailman.11699.1239814814.4476.r-sig-mixed-models@r-project.org>
	<49E6F474.6010808@yale.edu>
	<40e66e0b0904160634s3b46f797n7b20fec6a58ca1ef@mail.gmail.com>
	<49E7378D.7030001@yale.edu>
Message-ID: <40e66e0b0904160716p1815d608h450b2931b23a5000@mail.gmail.com>

On Thu, Apr 16, 2009 at 8:50 AM, Christian Salas
<christian.salas at yale.edu> wrote:
> Dear Prof. Bates:

> I am aware of the logLik(lme.obj), ?sorry if i was not clear before.
> What I am aiming to find is a similar syntax (to the one that i use for lm)
> involving the residuals from a lme fitted object, but without using
> logLik(lme.obj), that allows me to compute the log-likelihood value of the
> fitted model. Probably this would require retrieving both the ML sigma for
> the errors and the sigma for the random effects of the lme.obj

But that is not sufficient.  The log-likelihood for a mixed-effects
model involves the determinant of the conditional variance-covariance
matrix of the random effects, given the observed data and the
parameter estimates.

> Douglas Bates wrote:
>>
>> On Thu, Apr 16, 2009 at 4:03 AM, Christian Salas
>> <christian.salas at yale.edu> wrote:
>>>
>>> If i already fit a lm() model, i can obtain the log-likelihood [i do not
>>> ?want to use AIC()] using the residuals from the model, and using the
>>> ?RMSE of the model as sigma for my normal pdf. This would be in R like
>>
>> But the RMSE is not the maximum likelihood estimate of sigma. ?It's
>> the REML estimate but not the MLE.
>>
>>>> sum(dnorm(-resi,mean=0,sd=sigma,log=T)) ?[1]
>>>
>>> ?if i fit a gls model i can do the same
>>>
>>> ?for a lme() model, i know that we cannot just use the same loglik model
>>> ?[1], because they are different. I wonder if somedody already have some
>>> syntax in R similar to [1] but for ?mixed-effects models, i mean
>>> something
>>> that compute the log-likelihood but without using lme() directly as
>>> summary(lme.obj)$AIC
>>
>> Assuming that you fit with method = "ML" then wouldn't it be simplest
>> just to use
>>
>> logLik(lme.obj)
>>
>> It isn't clear from your question whether you want another approach
>> involving residuals, etc. or if it is just the fact that you are not
>> aware of the logLik generic.
>>
>>> ?thanks in advance!
>>>
>>>
>>> -------------------------------------------------------------------------------
>>> Christian Salas ? ? ? ? ? ? ? ? ? ? E-mail:christian.salas at yale.edu
>>> PhD candidate ? ? ? ? ? ? ? ? ? ? ? http://environment.yale.edu/salas
>>> School of Forestry and Environmental Studies
>>> Yale University ? ? ? ? ? ? ? ? ? ? Tel: +1-(203)-432 5126
>>> 360 Prospect St ? ? ? ? ? ? ? ? ? ? Fax:+1-(203)-432 3809
>>> New Haven, CT 06511-2189 ? ? ? ? ? ?Office: Room 35, Marsh Hall
>>> USA
>>>
>>> Yale Biometrics Lab
>>> ?http://environment.yale.edu/biometrics
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>



From ursa.reja at gmail.com  Thu Apr 16 18:22:25 2009
From: ursa.reja at gmail.com (Ursa Reja)
Date: Thu, 16 Apr 2009 18:22:25 +0200
Subject: [R-sig-ME] question
Message-ID: <63b87ebe0904160922y5e2d65bdle2a3fbbc37d6cf16@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090416/6d22660b/attachment.pl>

From Kate.Pressland at bristol.ac.uk  Thu Apr 16 19:28:38 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Thu, 16 Apr 2009 18:28:38 +0100
Subject: [R-sig-ME] model definition issues for repeat measures
Message-ID: <064141B660E4EA9EAACD6EB0@bio-mammal03.bio.bris.ac.uk>

I've scrolled through the archives and CRAN help pages and can't find an 
answer for my query: my apologies if it is rather basic.

I have a data set that is nested and unbalanced consisting of:

67 SITEs measured over several YEARs every WEEK (April-Sept) for a group of 
insects (SP per m - continuous data). Not all sites have all WEEKs 
recorded. I'm interested in the MANagement code (categorical: coded 0,1 or 
2) assigned to each site, but I have also data on TEMPerature, average SUN 
and WIND (some missing data with weather variables though). When looking at 
my SPecies data histogram it's clearly poisson distributed (common amongst 
count data), although it is in decimals. Over the WEEKs 1 to 26 there is a 
gaussian-esque distribution where species numbers peak uniformly during 
July. All YEARs show this trend.

My random factors are SITE, YEAR and WEEK as they denote the structure of 
the data, but I am not interested in their effects per se, I just want to 
explain the data structure. I figure that I cannot assume a normal model, 
so have been looking into lme4 and including family=poisson. Would this be 
correct? I also think there may be a need to include some kind of 
correlation function into the WEEK part of the equation (as week 2 might be 
dependent on week 1 but independent of week 20 and so on) but I am unsure 
how to do this or how necessary it really is.

My preliminary model looks as such:

	model.a<-lmer(SP ~ MAN + (1|SITE/YEAR/WEEK), data=ALL, family=poisson)

I get confused as to how to organise the random effects. My understanding 
is that to the left of the | you are looking at the slope, to the right of 
the | you are looking at the intercept. Is this correct? Should my random 
effects be (YEAR/WEEK|SITE) instead? When I run the above model I get this 
error:

	Error: length(f1) == length(f2) is not TRUE
	In addition: There are 50 or more warnings ...

What does this mean?

So, my key questions are:

1. What is the most appropriate random structure for my repeat measures?
2. Must I include a time series correlation structure for WEEKs? Which 
corStruct is most appropriate and how would I write that in for WEEK and 
not YEAR in the random effect section of the formula?
3. Should this model be family=poisson? Does that error message mean I have 
made an error with determining the data as poisson distributed?
4. Is it best to use ML or REML with unbalanced data if I'm going to create 
a model set for model selection by adding the weather variables as fixed 
effects? My hunch says ML if considering AIC/BIC values, but is REML more 
important due to the unbalanced data?

I've tried reading Pinheiro and Bates with the pages available through 
google books (our inadequate university libraries do not have a copy and 
have their spending account frozen due to recession!) which has helped and 
made this lowly student more confused simultaneously! Please can someone 
point me in the right direction?

Thank you for your time.

Kate
----------------
Kate.Pressland at bristol.ac.uk



From gregor.gorjanc at bfro.uni-lj.si  Thu Apr 16 21:15:05 2009
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Thu, 16 Apr 2009 19:15:05 +0000 (UTC)
Subject: [R-sig-ME] Presentation of results from GLMMs
References: <B9D1301370916C44B5874AF340C18B9B8F0E90CB14@VMAILB.uoa.abdn.ac.uk>
Message-ID: <loom.20090416T191413-640@post.gmane.org>

I find the Zelig (R package) approach quite usefull!

gg



From bates at stat.wisc.edu  Thu Apr 16 23:42:26 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 16 Apr 2009 16:42:26 -0500
Subject: [R-sig-ME] Numerical methods used to compute correlation
	coefficients
In-Reply-To: <222824550904161333s75282d59g3fcf7801dab0f0e8@mail.gmail.com>
References: <222824550904140720qacc8580g98b1a889ca837712@mail.gmail.com>
	<40e66e0b0904140937n268340a6maa2fbe1c56fe33f8@mail.gmail.com>
	<222824550904141002g26f33bcfl1485d080bf919633@mail.gmail.com>
	<40e66e0b0904150959m3434b21dof22360a71d345fa7@mail.gmail.com>
	<222824550904151114n51c48dfdxc55d2727ba8f18e6@mail.gmail.com>
	<40e66e0b0904151230w3423d816t5bb93aeb8fcd5376@mail.gmail.com>
	<222824550904161333s75282d59g3fcf7801dab0f0e8@mail.gmail.com>
Message-ID: <40e66e0b0904161442p4c7c426eo3f2e0fe0a8b43665@mail.gmail.com>

On Thu, Apr 16, 2009 at 3:33 PM, H c <harlancampbell at gmail.com> wrote:
> Thank you for the detailed answer. ?The reason I ask, is that I am
> attempting to fit a mixture of mixed models to a dataset using the standard
> EM approach. ?Exceptionally, the mixed models have AR(1) correlation. ?I
> have been able to do the math and arrive at maximum-likelihood solutions
> using an R implementation I wrote. ?However, the step that numerically
> calculates the \phi correlation coefficient(currently using optimize()) is
> extremely computationally expensive and thus makes any implementation of the
> algorithm on a large dataset impossible.
> I have attempted a few things in order to speed up estimation including
> transforming the data and maximizing the profiled likelihood rather then the
> likelihood. ?Unfortunately, no success. ?I have also tried using?nlminb()
> rather then optimize. ?Still?incredibly slow.
> Would you have any suggestions as to how one could numerically obtain
> maximum-weighted-likelihood estimates for correlation parameters in a
> reasonable amount?of time?
> Any suggestions would be greatly appreciated.

I'm afraid I don't have any immediate suggestions.  As you have seen,
there is a great deal of difference between writing some equations and
getting a working algorithm that is both robust and effective.  I
spent a considerable amount of time working with the EM algorithm and
variations like the ECME algorithm or the calculation of gradients of
the log-likelihood function with respect to some of the parameters
(these calculations are related to the EM algorithm).  In fact, I
would say that some of the best mathematics I have done was in
obtaining "simple" expressions for these quantities.

Unfortunately I found that in the implementation the use of ECME or
the analytic gradient just slowed down the convergence on large
complex problems.  Once I discovered that I could work out why it
happened but it was a disappointment to do such wonderful mathematics
and discover that it was for naught.

>
> ?Wed, Apr 15, 2009 at 3:30 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> On Wed, Apr 15, 2009 at 1:14 PM, H c <harlancampbell at gmail.com> wrote:
>>
>> > Thank you. ?This ?is exactly what I wanted to know. ?Perhaps one last
>> > question. ?Is there any?particular?reason to prefer ?this optimization
>> > routine over another, such as "optimize()"?
>>
>> optimize() only handles scalar problems and you must define an
>> interval in which the optimum is to be found.
>>
>> I have used other unconstrained optimizers such as nlm() and optim()
>> but had trouble with both of those. ?The original version of the nlme
>> package for S and S-PLUS used the ms() optimizer in S which was based
>> on some Fortran code by David Gay. ?Initially that code could not be
>> used in R because it was not released under an open source license.
>> Eventually it was released to the public domain and I wrote the nlminb
>> interface code for R, primarily so I could use it as the optimizer in
>> the nlme and lme4 packages.
>>
>> Even this code by David Gay is far from ideal. ?The development
>> version of the lme4 package factors out the evaluation of the deviance
>> function or the REML criterion from the optimization of these, so that
>> those who are interested can experiment with different optimizers and
>> see what works best in their problems.
>>
>> > On Wed, Apr 15, 2009 at 12:59 PM, Douglas Bates <bates at stat.wisc.edu>
>> > wrote:
>> >>
>> >> On Tue, Apr 14, 2009 at 12:02 PM, H c <harlancampbell at gmail.com> wrote:
>> >> > Thank you for the quick response.
>> >> > when I refer to "correlation parameters", I mean the "generally small
>> >> > set of
>> >> > parameters \lambda" that parametrize the \Lambda_{i}
>> >> > Variance-Covariance
>> >> > matrix.
>> >> > For example, one has time series data such that every subject has
>> >> > been
>> >> > observed at 4 time points. ?One wishes to model this using an AR(1)
>> >> > correlation structure within the mixed model.
>> >> > the AR(1) is parametrized by a fixed parameter, \phi :
>> >> > lme(y~X, random=~1|ID, method="ML", data=data,
>> >> > correlation=corAR1(0.5,form=~X,fixed=FALSE))
>> >>
>> >> > Since there is no closed form solution for the maximum-likelihood
>> >> > estimate
>> >> > of \phi. ?what numerical methods are used to arrive at the given
>> >> > estimate?
>> >> > Hopefully this has clarified my question.
>> >>
>> >> In the sense that I know what you mean by the correlation parameters.
>> >> I'm not sure how to characterize the numerical methods other than to
>> >> say that the deviance (negative twice the log-likelihood) or the
>> >> corresponding version of the REML criterion is expressed with respect
>> >> to an unconstrained parameter and the resulting function optimized
>> >> using optimization software within R (nlminb). ?You can check the
>> >> definition of the corAR family to determine exactly how the
>> >> parameterization is defined.
>> >>
>> >> > Thanks again,
>> >> > Harlan
>> >> >
>> >> > On Tue, Apr 14, 2009 at 12:37 PM, Douglas Bates <bates at stat.wisc.edu>
>> >> > wrote:
>> >> >>
>> >> >> On Tue, Apr 14, 2009 at 9:20 AM, H c <harlancampbell at gmail.com>
>> >> >> wrote:
>> >> >> > I have have already posted the following question: ?What numerical
>> >> >> > methods
>> >> >> > are used in nlme to estimate correlation parameters?
>> >> >> > I was referred to the Pinheiro and Bates book. ?Unfortunately, on
>> >> >> > p.
>> >> >> > 202,
>> >> >> > section 5.1.1, under the title "Estimation and Computational
>> >> >> > Methods",
>> >> >> > no
>> >> >> > description on a numerical method is provided. ?(When the data is
>> >> >> > transformed to work with the profiled likelihood(y->ystar), one
>> >> >> > needs
>> >> >> > the
>> >> >> > parameters that define Lambda. ?How are these parameters
>> >> >> > estimated?)
>> >> >>
>> >> >> I'm not sure what you mean by "correlation parameters". ?If you mean
>> >> >> the correlation parameters in the unconditional distribution of the
>> >> >> random effects then those are estimated by maximum likelihood (ML)
>> >> >> or
>> >> >> residual maximum likelihood (REML). ?The profiled deviance or the
>> >> >> profiled REML criterion is evaluated with respect to a transformed
>> >> >> set
>> >> >> of parameters and this value is optimized.
>> >> >
>> >> >
>> >
>> >
>
>



From lucianolasala at yahoo.com.ar  Fri Apr 17 02:40:02 2009
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Thu, 16 Apr 2009 17:40:02 -0700 (PDT)
Subject: [R-sig-ME] Error message in lmer
Message-ID: <103891.94578.qm@web59906.mail.ac4.yahoo.com>


Dear people, 

I am doing some exercises from The R Book by Crawley. When trying to fit a mixed model for the ?Rat? data (page 649 on this book), after loading the data and specifying the model I get the following error messages: 

model <- lmer(Glycogen~Treatment+(1|Treatment/Rat/Liver)
 
Error: Matrices must have same number of columns in rbind2(..1, r)
In addition: Warning messages:
1: In Rat:Treatment :
  numerical expression has 36 elements: only the first used
2: In Rat:Treatment :
  numerical expression has 36 elements: only the first used
3: In Liver:(Rat:Treatment) :
  numerical expression has 36 elements: only the first used
4: In Rat:Treatment :
  numerical expression has 36 elements: only the first used
5: In Rat:Treatment :
  numerical expression has 36 elements: only the first used

What's all this mean? Any tips as to where I may be going wrong? 

Thank you in advance! 

Luciano 

 



      Yahoo! Cocina
Recetas pr?cticas y comida saludable
http://ar.mujer.yahoo.com/cocina/



From Thierry.ONKELINX at inbo.be  Fri Apr 17 10:38:39 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 17 Apr 2009 10:38:39 +0200
Subject: [R-sig-ME] model definition issues for repeat measures
In-Reply-To: <064141B660E4EA9EAACD6EB0@bio-mammal03.bio.bris.ac.uk>
References: <064141B660E4EA9EAACD6EB0@bio-mammal03.bio.bris.ac.uk>
Message-ID: <2E9C414912813E4EB981326983E0A1040656FDA8@inboexch.inbo.be>

Dear Kate,

I presume that SP are some kind of counts along transects and you
divided the counts by the length of the transect. Assuming that all
transects have equal length, I would stick with the counts. Hence you
still can work with the interger data. If the lengths are different you
could add an offset term to the model.

(1|SITE/YEAR/WEEK) indicates 1) a random effect for each site. 2) within
each site a random effect of year. Notice that this effect is
independent for each site: the same year can have a different effect in
each site! That is probably not what you want. 3) A similar structure is
used for week.
Do you have a lot of years? If you have less than six years I would not
use them as a grouping factor in a random effect.

Maybe crossed random effects is more what you want. I would suggest
(1|SITE) + (1|YEAR/WEEK). Now each year has the same random intercept
regardless the site. If you have only a few years you could try (1|SITE)
+ (YEAR|WEEK) or YEAR + (1|SITE) + (1|WEEK). Note that in this case each
week needs a unique ID. The first week from year 1 can't have the same
ID as the first week of year 2. If that is not the case you can either
recode week or change the random effects to (1|SITE) + (YEAR|YEAR:WEEK)
or YEAR + (1|SITE) + (1|YEAR:WEEK). Unless you can assume that the first
week of year 1 has the same effect as the first week of all the other
years. Which is probabily not the case.

Note that with glmer() from lme4 package you can't use a correlation
structure. I believe that is on Douglas Bates to do list but with a low
priority. lme() from the nlme package allows to model a correlation
structure, but it can't handle crossed random effects. At least not that
easy as with lme4. And lme() only handles gaussian data. So I would
stick to glmer(). With WEEK as a grouping factor in the random effect
you can't add a correlation structure based on week. Because the random
effects are assumed to be independent between the group. So you will
have to choose between adding WEEK to the random effect or adding it to
the correlation structure.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens CL Pressland
Verzonden: donderdag 16 april 2009 19:29
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] model definition issues for repeat measures

I've scrolled through the archives and CRAN help pages and can't find an

answer for my query: my apologies if it is rather basic.

I have a data set that is nested and unbalanced consisting of:

67 SITEs measured over several YEARs every WEEK (April-Sept) for a group
of 
insects (SP per m - continuous data). Not all sites have all WEEKs 
recorded. I'm interested in the MANagement code (categorical: coded 0,1
or 
2) assigned to each site, but I have also data on TEMPerature, average
SUN 
and WIND (some missing data with weather variables though). When looking
at 
my SPecies data histogram it's clearly poisson distributed (common
amongst 
count data), although it is in decimals. Over the WEEKs 1 to 26 there is
a 
gaussian-esque distribution where species numbers peak uniformly during 
July. All YEARs show this trend.

My random factors are SITE, YEAR and WEEK as they denote the structure
of 
the data, but I am not interested in their effects per se, I just want
to 
explain the data structure. I figure that I cannot assume a normal
model, 
so have been looking into lme4 and including family=poisson. Would this
be 
correct? I also think there may be a need to include some kind of 
correlation function into the WEEK part of the equation (as week 2 might
be 
dependent on week 1 but independent of week 20 and so on) but I am
unsure 
how to do this or how necessary it really is.

My preliminary model looks as such:

	model.a<-lmer(SP ~ MAN + (1|SITE/YEAR/WEEK), data=ALL,
family=poisson)

I get confused as to how to organise the random effects. My
understanding 
is that to the left of the | you are looking at the slope, to the right
of 
the | you are looking at the intercept. Is this correct? Should my
random 
effects be (YEAR/WEEK|SITE) instead? When I run the above model I get
this 
error:

	Error: length(f1) == length(f2) is not TRUE
	In addition: There are 50 or more warnings ...

What does this mean?

So, my key questions are:

1. What is the most appropriate random structure for my repeat measures?
2. Must I include a time series correlation structure for WEEKs? Which 
corStruct is most appropriate and how would I write that in for WEEK and

not YEAR in the random effect section of the formula?
3. Should this model be family=poisson? Does that error message mean I
have 
made an error with determining the data as poisson distributed?
4. Is it best to use ML or REML with unbalanced data if I'm going to
create 
a model set for model selection by adding the weather variables as fixed

effects? My hunch says ML if considering AIC/BIC values, but is REML
more 
important due to the unbalanced data?

I've tried reading Pinheiro and Bates with the pages available through 
google books (our inadequate university libraries do not have a copy and

have their spending account frozen due to recession!) which has helped
and 
made this lowly student more confused simultaneously! Please can someone

point me in the right direction?

Thank you for your time.

Kate
----------------
Kate.Pressland at bristol.ac.uk

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From rense.nieuwenhuis at me.com  Sun Apr 19 17:56:21 2009
From: rense.nieuwenhuis at me.com (Rense Nieuwenhuis)
Date: Sun, 19 Apr 2009 17:56:21 +0200
Subject: [R-sig-ME] glmer: variable sequence matters?
Message-ID: <30832984-0E0B-4966-BF84-2D876579F018@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090419/d388730a/attachment.pl>

From ken at kjbeath.com.au  Mon Apr 20 01:43:26 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Sun, 19 Apr 2009 23:43:26 -0000 (GMT)
Subject: [R-sig-ME] glmer: variable sequence matters?
In-Reply-To: <30832984-0E0B-4966-BF84-2D876579F018@me.com>
References: <30832984-0E0B-4966-BF84-2D876579F018@me.com>
Message-ID: <1416.137.111.57.71.1240184606.squirrel@65.99.229.10>

This isn't very surprising, nonlinear optimisation tends to give slightly
different results depending on slight changes to things like starting
values or parameterisation. Sometimes this can be fixed by changes to the
convergence criteria (these don't seem to be accessible in nlmer) but
there can also be problems because the likelihood is not smooth around the
optimum due to numerical errors. There can be massive problems due to
multi-modal likelihoods but in your case results are well within the
standard errors, so there is obviously nothing wrong.

Ken


On Sun, April 19, 2009 3:56 pm, Rense Nieuwenhuis wrote:
> Dear all,
>
> while working on a package for influential data in mixed models, I
> encountered a peculiar situation. As I'll show in the examples below,
> I found that (at least in some situations) the sequence in which
> variables are entered in the model formula, influences the parameters
> of the model. In most cases, these differences are really small, but I
> did encounter an example which leads to rather huge differences.
>
> Unfortunately, I cannot publicly share the data, nor the outcomes, of
> that example, so I'll have to do with an example resulting in smaller
> differences. Nevertheless, I wouldn't expect any differences (neither
> small, nor big) when using exactly the same model formula on the same
> set of data, but only with a different sequence in which the variables
> are entered.
>
> In order to provide a reproducible example, I use the ScotsSec data
> from the mlmRev package, which I modify slightly. The first
> modifications relate to a manipulated intercept and added 'dummy'-
> variable, which is part of the procedure for determining influential
> data (but, the exact reasons for this are not very relevant for this
> problem). Note, however, that the intercept and the additional dummy
> variable (estex.2) are each others' opposite.
>
> library(mlmRev)
> data(ScotsSec)
>
> ScotsSec$intercept.alt <- ifelse(ScotsSec$second=="2", 0, 1)
> ScotsSec$estex.2 <- ifelse(ScotsSec$second=="2", 1, 0)
>
>
> I use these data, and its modifications, to estimate two models. Both
> data and variables in the model formulae are identical, except that in
> model.a the dummy-variable estex.2 is added as the last of the fixed
> effects, whereas in model.b it is added directly after the modified
> intercept-variable (intercept.alt). Also, in both models the
> 'standard' intercept is omitted. When the fixed effects of these two
> models are compared, these are exactly identical as expected.
>
>
> model.a <- lmer(attain ~ intercept.alt + verbal + social + estex.2 +
> 	(0 + intercept.alt | primary) + (0 + intercept.alt|second) -1 ,
> 	data=ScotsSec)
>
>
> model.b <- lmer(attain ~ intercept.alt + estex.2 + verbal + social +
> 	(0 + intercept.alt | primary) + (0 + intercept.alt|second) -1 ,
> 	data=ScotsSec)
>
>
> fixef(model.a)
> fixef(model.b) # Identical
>
> However, testing exactly these model formulae on a logistic set of
> data, results in (slightly) different estimates for the fixed effects.
> To illustrate this, I created a binary outcome variable ('pass'), and
> specify the same models as above, with the addition of the
> family="binomial" parameter.
>
> ScotsSec$pass <- ifelse(ScotsSec$attain > 5, 1,0)
> model.c <- lmer(pass ~ intercept.alt + verbal + social + estex.2 +
> 	(0 + intercept.alt | primary) + (0 + intercept.alt|second) -1 ,
> 	data=ScotsSec,
>      family="binomial")
>
> model.d <- lmer(pass ~ intercept.alt + estex.2 + verbal + social +
> 	(0 + intercept.alt | primary) + (0 + intercept.alt|second) -1 ,
> 	data=ScotsSec,
>      family="binomial")
>
> fixef(model.c)
> fixef(model.d) # Not Identical
>
> To my surprise, now the fixed effects differ. How is this possible,
> and, why does this only seem to occur using glmer? I would not have
> expected the model outcomes to be subject to the sequence in which the
> variables are specified.
>
> I would be grateful if anyone could shed some light on this (to me)
> rather peculiar situation,
>
> with kind regards,
>
> Rense Nieuwenhuis
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From levyofi at gmail.com  Mon Apr 20 19:06:36 2009
From: levyofi at gmail.com (Ofir Levy)
Date: Mon, 20 Apr 2009 20:06:36 +0300
Subject: [R-sig-ME] modelling zero inflated count data with glmm
Message-ID: <49ECAB9C.4010200@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090420/ad1a7df1/attachment.pl>

From bates at stat.wisc.edu  Mon Apr 20 21:25:20 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 20 Apr 2009 14:25:20 -0500
Subject: [R-sig-ME] Error message in lmer
In-Reply-To: <103891.94578.qm@web59906.mail.ac4.yahoo.com>
References: <103891.94578.qm@web59906.mail.ac4.yahoo.com>
Message-ID: <40e66e0b0904201225w1b88a2d1n55af2c9aefb22c1d@mail.gmail.com>

I would go about things in a different way than is described in that book.

This is an example of what happens when the data are organized with
"implicitly nested" factors.  My recollection of the data is that
there are 6 rats and 3 liver sections from each rat, creating a total
of 18 liver sections in which the glycogen was measured.  It may have
made sense in the past to designate the rats as 1 and 2 with the
implicit assumption that rat 1 in treatment 1 is different from rat 1
in treatment 2 or rat 1 in treatment 3 but I don't think this is a
need any more for that potentially confusing designation.

If instead you think of the three treatments as a factor that we will
model with fixed effects paramaters and the 6 rats and 18 liver
sections as defining random effects then the analysis is
straightforward.

> rats <- read.delim("/home/bates/Desktop/rats.txt")
> str(rats)
'data.frame':	36 obs. of  4 variables:
 $ Glycogen : int  131 130 131 125 136 142 150 148 140 143 ...
 $ Treatment: int  1 1 1 1 1 1 1 1 1 1 ...
 $ Rat      : int  1 1 1 1 1 1 2 2 2 2 ...
 $ Liver    : int  1 1 2 2 3 3 1 1 2 2 ...
> rats$Treatment <- factor(rats$Treatment, labels = LETTERS[1:3])
> rats$rr <- with(rats, Treatment:factor(Rat))
> rats$ll <- with(rats, Treatment:factor(Rat):factor(Liver))
> str(rats)
'data.frame':	36 obs. of  6 variables:
 $ Glycogen : int  131 130 131 125 136 142 150 148 140 143 ...
 $ Treatment: Factor w/ 3 levels "A","B","C": 1 1 1 1 1 1 1 1 1 1 ...
 $ Rat      : int  1 1 1 1 1 1 2 2 2 2 ...
 $ Liver    : int  1 1 2 2 3 3 1 1 2 2 ...
 $ rr       : Factor w/ 6 levels "A:1","A:2","B:1",..: 1 1 1 1 1 1 2 2 2 2 ...
 $ ll       : Factor w/ 18 levels "A:1:1","A:1:2",..: 1 1 2 2 3 3 4 4 5 5 ...
> rats
   Glycogen Treatment Rat Liver  rr    ll
1       131         A   1     1 A:1 A:1:1
2       130         A   1     1 A:1 A:1:1
3       131         A   1     2 A:1 A:1:2
4       125         A   1     2 A:1 A:1:2
5       136         A   1     3 A:1 A:1:3
6       142         A   1     3 A:1 A:1:3
7       150         A   2     1 A:2 A:2:1
8       148         A   2     1 A:2 A:2:1
9       140         A   2     2 A:2 A:2:2
10      143         A   2     2 A:2 A:2:2
11      160         A   2     3 A:2 A:2:3
12      150         A   2     3 A:2 A:2:3
13      157         B   1     1 B:1 B:1:1
14      145         B   1     1 B:1 B:1:1
15      154         B   1     2 B:1 B:1:2
16      142         B   1     2 B:1 B:1:2
17      147         B   1     3 B:1 B:1:3
18      153         B   1     3 B:1 B:1:3
19      151         B   2     1 B:2 B:2:1
20      155         B   2     1 B:2 B:2:1
21      147         B   2     2 B:2 B:2:2
22      147         B   2     2 B:2 B:2:2
23      162         B   2     3 B:2 B:2:3
24      152         B   2     3 B:2 B:2:3
25      134         C   1     1 C:1 C:1:1
26      125         C   1     1 C:1 C:1:1
27      138         C   1     2 C:1 C:1:2
28      138         C   1     2 C:1 C:1:2
29      135         C   1     3 C:1 C:1:3
30      136         C   1     3 C:1 C:1:3
31      138         C   2     1 C:2 C:2:1
32      140         C   2     1 C:2 C:2:1
33      139         C   2     2 C:2 C:2:2
34      138         C   2     2 C:2 C:2:2
35      134         C   2     3 C:2 C:2:3
36      127         C   2     3 C:2 C:2:3
> library(lme4)
Loading required package: Matrix

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 xtabs


	The following object(s) are masked from package:base :

	 rcond

> (fm1 <- lmer(Glycogen ~ Treatment + (1|rr) + (1|ll), rats))
Linear mixed model fit by REML
Formula: Glycogen ~ Treatment + (1 | rr) + (1 | ll)
   Data: rats
   AIC   BIC logLik deviance REMLdev
 231.6 241.1 -109.8    234.3   219.6
Random effects:
 Groups   Name        Variance Std.Dev.
 ll       (Intercept) 14.167   3.7639
 rr       (Intercept) 36.065   6.0054
 Residual             21.167   4.6007
Number of obs: 36, groups: ll, 18; rr, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)  140.500      4.707  29.851
TreatmentB    10.500      6.656   1.577
TreatmentC    -5.333      6.656  -0.801

Correlation of Fixed Effects:
           (Intr) TrtmnB
TreatmentB -0.707
TreatmentC -0.707  0.500

Also, if you look at the enclosed plot you will see that the main
reason for not having a significant difference due to treatment is
because the two rats who got treatment A had very different levels of
glycogen.  Furthermore there is considerable section to section
variability within rat and even assay to assay variability within the
same section (look at rat B:1's data).

On Thu, Apr 16, 2009 at 7:40 PM, Luciano La Sala
<lucianolasala at yahoo.com.ar> wrote:
>
> Dear people,
>
> I am doing some exercises from The R Book by Crawley. When trying to fit a mixed model for the ?Rat? data (page 649 on this book), after loading the data and specifying the model I get the following error messages:
>
> model <- lmer(Glycogen~Treatment+(1|Treatment/Rat/Liver)
>
> Error: Matrices must have same number of columns in rbind2(..1, r)
> In addition: Warning messages:
> 1: In Rat:Treatment :
> ?numerical expression has 36 elements: only the first used
> 2: In Rat:Treatment :
> ?numerical expression has 36 elements: only the first used
> 3: In Liver:(Rat:Treatment) :
> ?numerical expression has 36 elements: only the first used
> 4: In Rat:Treatment :
> ?numerical expression has 36 elements: only the first used
> 5: In Rat:Treatment :
> ?numerical expression has 36 elements: only the first used
>
> What's all this mean? Any tips as to where I may be going wrong?
>
> Thank you in advance!
>
> Luciano
>
>
>
>
>
> ? ? ?Yahoo! Cocina
> Recetas pr?cticas y comida saludable
> http://ar.mujer.yahoo.com/cocina/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Mon Apr 20 21:27:56 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 20 Apr 2009 14:27:56 -0500
Subject: [R-sig-ME] Error message in lmer
In-Reply-To: <40e66e0b0904201225w1b88a2d1n55af2c9aefb22c1d@mail.gmail.com>
References: <103891.94578.qm@web59906.mail.ac4.yahoo.com>
	<40e66e0b0904201225w1b88a2d1n55af2c9aefb22c1d@mail.gmail.com>
Message-ID: <40e66e0b0904201227o28273b62j38927a881b28d9a2@mail.gmail.com>

I forgot to attach the figure to my last message.

On Mon, Apr 20, 2009 at 2:25 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> I would go about things in a different way than is described in that book.
>
> This is an example of what happens when the data are organized with
> "implicitly nested" factors. ?My recollection of the data is that
> there are 6 rats and 3 liver sections from each rat, creating a total
> of 18 liver sections in which the glycogen was measured. ?It may have
> made sense in the past to designate the rats as 1 and 2 with the
> implicit assumption that rat 1 in treatment 1 is different from rat 1
> in treatment 2 or rat 1 in treatment 3 but I don't think this is a
> need any more for that potentially confusing designation.
>
> If instead you think of the three treatments as a factor that we will
> model with fixed effects paramaters and the 6 rats and 18 liver
> sections as defining random effects then the analysis is
> straightforward.
>
>> rats <- read.delim("/home/bates/Desktop/rats.txt")
>> str(rats)
> 'data.frame': ? 36 obs. of ?4 variables:
> ?$ Glycogen : int ?131 130 131 125 136 142 150 148 140 143 ...
> ?$ Treatment: int ?1 1 1 1 1 1 1 1 1 1 ...
> ?$ Rat ? ? ?: int ?1 1 1 1 1 1 2 2 2 2 ...
> ?$ Liver ? ?: int ?1 1 2 2 3 3 1 1 2 2 ...
>> rats$Treatment <- factor(rats$Treatment, labels = LETTERS[1:3])
>> rats$rr <- with(rats, Treatment:factor(Rat))
>> rats$ll <- with(rats, Treatment:factor(Rat):factor(Liver))
>> str(rats)
> 'data.frame': ? 36 obs. of ?6 variables:
> ?$ Glycogen : int ?131 130 131 125 136 142 150 148 140 143 ...
> ?$ Treatment: Factor w/ 3 levels "A","B","C": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ Rat ? ? ?: int ?1 1 1 1 1 1 2 2 2 2 ...
> ?$ Liver ? ?: int ?1 1 2 2 3 3 1 1 2 2 ...
> ?$ rr ? ? ? : Factor w/ 6 levels "A:1","A:2","B:1",..: 1 1 1 1 1 1 2 2 2 2 ...
> ?$ ll ? ? ? : Factor w/ 18 levels "A:1:1","A:1:2",..: 1 1 2 2 3 3 4 4 5 5 ...
>> rats
> ? Glycogen Treatment Rat Liver ?rr ? ?ll
> 1 ? ? ? 131 ? ? ? ? A ? 1 ? ? 1 A:1 A:1:1
> 2 ? ? ? 130 ? ? ? ? A ? 1 ? ? 1 A:1 A:1:1
> 3 ? ? ? 131 ? ? ? ? A ? 1 ? ? 2 A:1 A:1:2
> 4 ? ? ? 125 ? ? ? ? A ? 1 ? ? 2 A:1 A:1:2
> 5 ? ? ? 136 ? ? ? ? A ? 1 ? ? 3 A:1 A:1:3
> 6 ? ? ? 142 ? ? ? ? A ? 1 ? ? 3 A:1 A:1:3
> 7 ? ? ? 150 ? ? ? ? A ? 2 ? ? 1 A:2 A:2:1
> 8 ? ? ? 148 ? ? ? ? A ? 2 ? ? 1 A:2 A:2:1
> 9 ? ? ? 140 ? ? ? ? A ? 2 ? ? 2 A:2 A:2:2
> 10 ? ? ?143 ? ? ? ? A ? 2 ? ? 2 A:2 A:2:2
> 11 ? ? ?160 ? ? ? ? A ? 2 ? ? 3 A:2 A:2:3
> 12 ? ? ?150 ? ? ? ? A ? 2 ? ? 3 A:2 A:2:3
> 13 ? ? ?157 ? ? ? ? B ? 1 ? ? 1 B:1 B:1:1
> 14 ? ? ?145 ? ? ? ? B ? 1 ? ? 1 B:1 B:1:1
> 15 ? ? ?154 ? ? ? ? B ? 1 ? ? 2 B:1 B:1:2
> 16 ? ? ?142 ? ? ? ? B ? 1 ? ? 2 B:1 B:1:2
> 17 ? ? ?147 ? ? ? ? B ? 1 ? ? 3 B:1 B:1:3
> 18 ? ? ?153 ? ? ? ? B ? 1 ? ? 3 B:1 B:1:3
> 19 ? ? ?151 ? ? ? ? B ? 2 ? ? 1 B:2 B:2:1
> 20 ? ? ?155 ? ? ? ? B ? 2 ? ? 1 B:2 B:2:1
> 21 ? ? ?147 ? ? ? ? B ? 2 ? ? 2 B:2 B:2:2
> 22 ? ? ?147 ? ? ? ? B ? 2 ? ? 2 B:2 B:2:2
> 23 ? ? ?162 ? ? ? ? B ? 2 ? ? 3 B:2 B:2:3
> 24 ? ? ?152 ? ? ? ? B ? 2 ? ? 3 B:2 B:2:3
> 25 ? ? ?134 ? ? ? ? C ? 1 ? ? 1 C:1 C:1:1
> 26 ? ? ?125 ? ? ? ? C ? 1 ? ? 1 C:1 C:1:1
> 27 ? ? ?138 ? ? ? ? C ? 1 ? ? 2 C:1 C:1:2
> 28 ? ? ?138 ? ? ? ? C ? 1 ? ? 2 C:1 C:1:2
> 29 ? ? ?135 ? ? ? ? C ? 1 ? ? 3 C:1 C:1:3
> 30 ? ? ?136 ? ? ? ? C ? 1 ? ? 3 C:1 C:1:3
> 31 ? ? ?138 ? ? ? ? C ? 2 ? ? 1 C:2 C:2:1
> 32 ? ? ?140 ? ? ? ? C ? 2 ? ? 1 C:2 C:2:1
> 33 ? ? ?139 ? ? ? ? C ? 2 ? ? 2 C:2 C:2:2
> 34 ? ? ?138 ? ? ? ? C ? 2 ? ? 2 C:2 C:2:2
> 35 ? ? ?134 ? ? ? ? C ? 2 ? ? 3 C:2 C:2:3
> 36 ? ? ?127 ? ? ? ? C ? 2 ? ? 3 C:2 C:2:3
>> library(lme4)
> Loading required package: Matrix
>
> Attaching package: 'Matrix'
>
>
> ? ? ? ?The following object(s) are masked from package:stats :
>
> ? ? ? ? xtabs
>
>
> ? ? ? ?The following object(s) are masked from package:base :
>
> ? ? ? ? rcond
>
>> (fm1 <- lmer(Glycogen ~ Treatment + (1|rr) + (1|ll), rats))
> Linear mixed model fit by REML
> Formula: Glycogen ~ Treatment + (1 | rr) + (1 | ll)
> ? Data: rats
> ? AIC ? BIC logLik deviance REMLdev
> ?231.6 241.1 -109.8 ? ?234.3 ? 219.6
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?ll ? ? ? (Intercept) 14.167 ? 3.7639
> ?rr ? ? ? (Intercept) 36.065 ? 6.0054
> ?Residual ? ? ? ? ? ? 21.167 ? 4.6007
> Number of obs: 36, groups: ll, 18; rr, 6
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?140.500 ? ? ?4.707 ?29.851
> TreatmentB ? ?10.500 ? ? ?6.656 ? 1.577
> TreatmentC ? ?-5.333 ? ? ?6.656 ?-0.801
>
> Correlation of Fixed Effects:
> ? ? ? ? ? (Intr) TrtmnB
> TreatmentB -0.707
> TreatmentC -0.707 ?0.500
>
> Also, if you look at the enclosed plot you will see that the main
> reason for not having a significant difference due to treatment is
> because the two rats who got treatment A had very different levels of
> glycogen. ?Furthermore there is considerable section to section
> variability within rat and even assay to assay variability within the
> same section (look at rat B:1's data).
>
> On Thu, Apr 16, 2009 at 7:40 PM, Luciano La Sala
> <lucianolasala at yahoo.com.ar> wrote:
>>
>> Dear people,
>>
>> I am doing some exercises from The R Book by Crawley. When trying to fit a mixed model for the ?Rat? data (page 649 on this book), after loading the data and specifying the model I get the following error messages:
>>
>> model <- lmer(Glycogen~Treatment+(1|Treatment/Rat/Liver)
>>
>> Error: Matrices must have same number of columns in rbind2(..1, r)
>> In addition: Warning messages:
>> 1: In Rat:Treatment :
>> ?numerical expression has 36 elements: only the first used
>> 2: In Rat:Treatment :
>> ?numerical expression has 36 elements: only the first used
>> 3: In Liver:(Rat:Treatment) :
>> ?numerical expression has 36 elements: only the first used
>> 4: In Rat:Treatment :
>> ?numerical expression has 36 elements: only the first used
>> 5: In Rat:Treatment :
>> ?numerical expression has 36 elements: only the first used
>>
>> What's all this mean? Any tips as to where I may be going wrong?
>>
>> Thank you in advance!
>>
>> Luciano
>>
>>
>>
>>
>>
>> ? ? ?Yahoo! Cocina
>> Recetas pr?cticas y comida saludable
>> http://ar.mujer.yahoo.com/cocina/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rats.pdf
Type: application/pdf
Size: 10479 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090420/c3227d10/attachment.pdf>

From datkins at u.washington.edu  Mon Apr 20 22:02:53 2009
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 20 Apr 2009 13:02:53 -0700
Subject: [R-sig-ME] modelling zero inflated count data with glmm
In-Reply-To: <49ECAB9C.4010200@gmail.com>
References: <49ECAB9C.4010200@gmail.com>
Message-ID: <49ECD4ED.9060900@u.washington.edu>


Ofir--

I am fairly certain that you can not fit a zero-inflated model using 
glmer() (and I am not familiar with the fmr function).

As for whether you *need* a zero-inflated or negative binomial, there is 
evidence for over-dispersion (assuming we can trust the sigma reported 
in the quasipoisson, which I believe Doug Bates said might be suspect...).

One option could be to use the MCMCglmm package.  It fits a broad class 
of generalized linear mixed models from a Bayesian perspective using 
Markov Chain Monte Carlo (MCMC) methods.

If you look at its family argument, you will see that it can fit a 
zero-inflated Poisson.

I have just started using it myself and have found it very intuitive. 
Of course, it would help tremendously to have some familiarity with 
Bayesian statistics and the basics of MCMC fitting methods.

Jarrod Hadfield (the package author) may be able to provide more direct 
comments on what the call to MCMCglmm might look like for a 
zero-inflated Poisson (and perhaps a quasi-Poisson? ideally, it would be 
nice to test a succession of models re. over-dispersion).

See the tutorial vignette in the MCMCglmm package for an introduction.

Hope that helps.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu



Hello R users,


During My PhD I collected count data which I and seems as zero inflated.
I have run a statistical model with lmer with family=quasipoisson and
got summary(model)@sigma~10 so I believe there is overdispertion but it
does not high enough to use negative binomial or zero inflated models.
Am I right?


I thought maybe using the fmr function in the 'gnlm' library but it
seems it cannot handle random effects:


I have these variables in the model:
   count: the number of logs in a foraging tray (this is the response
variable).
   ta: the ambient temperature at the foraging tray.
   habitat: the habitat type of the foraging tray.
   season: the season in which the experiment session took place (summer
or winter).
   moon: the moon phase (new or full).
   position: a random factor (I had 4 foraging stations)
   individual_id: a random factor indicating the individual foraged in
the tray.

This is the lmer parameters I have used:
model<-lmer(count~ta*habitat*season*moon + (1|individual_id) +
(1|position), data=countdata, family=poisson)


Is it possible to run the same model with fmr?


I would really appreciate the help. I love working with R and it really
changed the way I work with my data.
Thanks again,
Ofir.




	[[alternative HTML version deleted]]



From jpais.albany at gmail.com  Tue Apr 21 01:40:18 2009
From: jpais.albany at gmail.com (Jeremy Pais)
Date: Mon, 20 Apr 2009 19:40:18 -0400
Subject: [R-sig-ME] Difference Score with Random Effects?
Message-ID: <c0943d2f0904201640l4b9b2bd7x828a94aa177d5640@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090420/58ccf0e2/attachment.pl>

From ken at kjbeath.com.au  Tue Apr 21 03:52:02 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Tue, 21 Apr 2009 01:52:02 -0000 (GMT)
Subject: [R-sig-ME] Difference Score with Random Effects?
In-Reply-To: <c0943d2f0904201640l4b9b2bd7x828a94aa177d5640@mail.gmail.com>
References: <c0943d2f0904201640l4b9b2bd7x828a94aa177d5640@mail.gmail.com>
Message-ID: <1434.137.111.57.71.1240278722.squirrel@65.99.229.10>

Assuming that the model for the Yit has a random intercept then
subtracting them will cancel out the random effect and it's estimate will
be zero.

Adding the Yit to the right hand side of the equation will put the random
component back into the equation, but this could just as easily be shifted
to the left hand side,  which the Ui will attempt to model.

Ken

On Mon, April 20, 2009 11:40 pm, Jeremy Pais wrote:
> In estimating a null/intercept only model using longitudinal panel data in
> person-year format (i.e., long, occasions, repeated measures) and a
> difference score as the dependent variable
>
>
>
> (Yit - Yit-1) = a + Ui + Eit
>
>
>
> the model fails to converge using stata?s xtmixed (?flat and continuous
> region?) and using lmer in R the between individual variation (Ui) is
> essentially zero. When I include Yit-1 as an independent variable:
>
>
>
> (Yit - Yit-1) = a + Yit-1 + Ui + Eit
>
>
>
> the model converges just fine and reports what seem to be reasonable
> results
> (and the results in Stata and in R correspond).  Below is an example using
> Stata. The dependent variable is the difference in family income from t-1
> to
> t in thousands of dollars and is grand mean centered.
>
>
>
>
>
> *. xtsum dinc*
>
>
>
> Variable         |      Mean   Std. Dev.       Min        Max |
> Observations
>
> -----------------+--------------------------------------------+----------------
>
> dinc     overall | -.1507094   47.16423  -2447.117   2749.135 |     N =
> 68075
>
>          between |             24.94159   -675.392   638.0056 |     n =
> 14869
>
>          within  |             44.31102  -2029.263   2437.635 | T-bar =
> 4.57832
>
>
>
> * *
>
> *. xtmixed dinc ||id: *
>
>
>
> Performing EM optimization:
>
>
>
> Performing gradient-based optimization:
>
>
>
> Iteration 0:   log restricted-likelihood = -359298.64
>
> numerical derivatives are approximate
>
> flat or discontinuous region encountered
>
> Iteration 1:   log restricted-likelihood = -358930.79
>
> numerical derivatives are approximate
>
> flat or discontinuous region encountered






























.
>
>
>
>
>
> *. xtmixed dinc laginc ||id:  *
>
>
>
> Performing EM optimization:
>
>
>
> Performing gradient-based optimization:
>
>
>
> Iteration 0:   log restricted-likelihood = -353006.12
>
> Iteration 1:   log restricted-likelihood = -353004.36
>
> Iteration 2:   log restricted-likelihood = -353004.35
>
>
>
> Computing standard errors:
>
>
>
> Mixed-effects REML regression                   Number of obs      =
> 68075
>
> Group variable: id                              Number of groups   =
> 14869
>
>
>
>                                                 Obs per group: min =
> 1
>
>                                                                avg =
> 4.6
>
>                                                                max =
> 11
>
>
>
>
>
>                                                 Wald chi2(1)       =
> 19885.84
>
> Log restricted-likelihood = -353004.35          Prob > chi2        =
> 0.0000
>
>
>
> ------------------------------------------------------------------------------
>
>         dinc |      Coef.   Std. Err.      z    P>|z|     [95% Conf.
> Interval]
>
> -------------+----------------------------------------------------------------
>
>       laginc |  -.4772225   .0033841  -141.02   0.000    -.4838553
> -.4705897
>
>        _cons |  -1.546629   .2300348    -6.72   0.000    -1.997489
> -1.095769
>
> ------------------------------------------------------------------------------
>
>
>
> ------------------------------------------------------------------------------
>
>   Random-effects Parameters  |   Estimate   Std. Err.     [95% Conf.
> Interval]
>
> -----------------------------+------------------------------------------------
>
> id: Identity                 |
>
>                    sd(_cons) |   17.95496   .2854801      17.40406
> 18.5233
>
> -----------------------------+------------------------------------------------
>
>                 sd(Residual) |   40.56819   .1264724      40.32107
> 40.81683
>
> ------------------------------------------------------------------------------
>
> LR test vs. linear regression: chibar2(01) =  1940.19 Prob >= chibar2 =
> 0.0000
>
>
>
>
>
> I?ve also replicated this pattern using other data (still in person-year
> format) and other dependent variables.
>
>
>
> I must be missing something obvious here. Does taking the first difference
> in a null model essentially condition out the between individual variation
> (like a fixed-effects estimator Xit-Xibar, even though there are more than
> two occasions with repeated measures)? And why then does the inclusion of
> a
> lagged variable seem to resolve the issue? Or does it?
>
>
>
> Any insight or suggested literature on this would be greatly appreciated.
>
>
>
> Jeremy
>
>
> --
> Jeremy Pais
> Doctoral Student
> Department of Sociology
> University at Albany, SUNY
>
> jeremy.pais01 at albany.edu
> jpais.albany at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From swbcole at gmail.com  Tue Apr 21 15:32:33 2009
From: swbcole at gmail.com (Stephen Cole)
Date: Tue, 21 Apr 2009 10:32:33 -0300
Subject: [R-sig-ME] Unbalanced nested design
Message-ID: <f7134c940904210632j76ed7c18y553c0c064e1c4b5f@mail.gmail.com>

Hello All - I would like to run a 2 factor nested ANOVA.  The design
is unbalanced as i have 6 sites in 3 regions and 3 sites in 1 other
region. Site is nested in region  I am interested in the differences
in mean recruit density among 4 regions.  I have used the lme function
in the nlme library and am confused about the output.  I have a copy
of P/B and I quote p. 25 " The lme function does produce sensible
maximum likelihood estimates or restricted maximum likelihood
estimates from the unbalanced data."  Thus, as i understand it lme can
handle this unbalanced data set that i have.  However, when i compared
the lme model to an aov model, the fixed effects results are
identical. (f-ratio and p-value).  How does lme handle unbalanced data
if the result is the same as aov which can not handle unbalanced data.
 Thank-you for any help provided.

I have attached a subsection of my data.  The total number of records
is 420, with a sample of 20 quadrat counts from each site (21 sites x
20 = 420)

Data:
          adults  recruits region site site2   site3
1      138 1268.3300    ANS    1     1    ANS:1
2      131  608.3300     ANS    1     1    ANS:1
3       13  696.8800     ANS    1     1    ANS:1
4       12  412.5000     ANS    1     1    ANS:1
5        2  355.5600     ANS    1     1    ANS:1
6        0  528.0000     ANS    1     1    ANS:1
7        4  421.2100     ANS    1     1    ANS:1
8        0  378.0000     ANS    1     1    ANS:1
9       92  893.3300    ANS    1     1    ANS:1
10      77 1184.3100   ANS    1     1    ANS:1
11      92  961.4200    ANS    1     1    ANS:1
12       0 1029.0000    ANS    1     1   ANS:1
13      19 1144.6800    ANS    1     1   ANS:1

Region (4 levels, fixed)
Site (6 levels and 3 levels, random)

data$site <- as.factor(data$site)
data$site3 <-factor(data$region:data$site)


mod.lme <- lme(recruits ~ region, data=data, random=~1|site3)

anova(mod)

            numDF denDF  F-value p-value
(Intercept)     1   399 93.58730  <.0001
region          3    17 19.21751  <.0001

 mod.aov <- aov(recruits ~ region + Error(site3), data=data)
 summary(mod.aov)\

Error: site3
                 Df   Sum Sq  Mean Sq F value    Pr(>F)
region        3  32024226 10674742  19.218 1.057e-05 ***
Residuals  17  9442984   555470
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Error: Within
                  Df   Sum Sq  Mean Sq F value Pr(>F)
Residuals  399 11839881    29674

Now, both F-ratios are 19.21, I am not sure what i am doing
incorrectly but I would appreciate any advice on my mistake.  Thanks
very much

Stephen Cole
Graduate student
Marine Ecology Lab
Saint Francis Xavier University



From levyofi at gmail.com  Tue Apr 21 23:26:34 2009
From: levyofi at gmail.com (Ofir Levy)
Date: Wed, 22 Apr 2009 00:26:34 +0300
Subject: [R-sig-ME] Using MCMCglmm with zero inflated count data
In-Reply-To: <mailman.3.1240308002.12659.r-sig-mixed-models@r-project.org>
References: <mailman.3.1240308002.12659.r-sig-mixed-models@r-project.org>
Message-ID: <49EE3A0A.9060500@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090422/51a52530/attachment.pl>

From bates at stat.wisc.edu  Wed Apr 22 14:50:36 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 22 Apr 2009 07:50:36 -0500
Subject: [R-sig-ME] Unbalanced nested design
In-Reply-To: <f7134c940904210632j76ed7c18y553c0c064e1c4b5f@mail.gmail.com>
References: <f7134c940904210632j76ed7c18y553c0c064e1c4b5f@mail.gmail.com>
Message-ID: <40e66e0b0904220550r1724ca7ke8e1142b6a4b4642@mail.gmail.com>

On Tue, Apr 21, 2009 at 8:32 AM, Stephen Cole <swbcole at gmail.com> wrote:
> Hello All - I would like to run a 2 factor nested ANOVA. ?The design
> is unbalanced as i have 6 sites in 3 regions and 3 sites in 1 other
> region. Site is nested in region ?I am interested in the differences
> in mean recruit density among 4 regions. ?I have used the lme function
> in the nlme library and am confused about the output. ?I have a copy
> of P/B and I quote p. 25 " The lme function does produce sensible
> maximum likelihood estimates or restricted maximum likelihood
> estimates from the unbalanced data." ?Thus, as i understand it lme can
> handle this unbalanced data set that i have. ?However, when i compared
> the lme model to an aov model, the fixed effects results are
> identical. (f-ratio and p-value). ?How does lme handle unbalanced data
> if the result is the same as aov which can not handle unbalanced data.
> ?Thank-you for any help provided.

Thank you for including a description of your data and the model that
you wish to fit.

The lme function and the newer lmer function in the lme4 package both
fit linear mixed-effects models by optimizing the log-likelihood (for
maximum likelihood, ML, estimates) or the REML criterion, which is a
related to the log-likelihood.

I can't really remember all the details of the aov fit.  I think it
goes something like obtaining a least squares fit to the fixed-effects
and the random effects combined then performing a further
decomposition of the residual sum of squares into the various error
strata and performing F tests based on these various components.  If
the design is completely balanced then the error strata are
orthogonal.  I'm not really sure what happens for unbalanced designs.

The REML criterion, which is the default estimation criterion for lme,
 is designed to "correct" the maximum likelihood estimates so they
more closely resemble the traditional results from the error strata
approach in the cases where error strata can be applied.  I don't
think that the fact that they match up in this case should be
alarming.  That is sort of what is supposed to happen.

> I have attached a subsection of my data. ?The total number of records
> is 420, with a sample of 20 quadrat counts from each site (21 sites x
> 20 = 420)
>
> Data:
> ? ? ? ? ?adults ?recruits region site site2 ? site3
> 1 ? ? ?138 1268.3300 ? ?ANS ? ?1 ? ? 1 ? ?ANS:1
> 2 ? ? ?131 ?608.3300 ? ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 3 ? ? ? 13 ?696.8800 ? ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 4 ? ? ? 12 ?412.5000 ? ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 5 ? ? ? ?2 ?355.5600 ? ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 6 ? ? ? ?0 ?528.0000 ? ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 7 ? ? ? ?4 ?421.2100 ? ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 8 ? ? ? ?0 ?378.0000 ? ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 9 ? ? ? 92 ?893.3300 ? ?ANS ? ?1 ? ? 1 ? ?ANS:1
> 10 ? ? ?77 1184.3100 ? ANS ? ?1 ? ? 1 ? ?ANS:1
> 11 ? ? ?92 ?961.4200 ? ?ANS ? ?1 ? ? 1 ? ?ANS:1
> 12 ? ? ? 0 1029.0000 ? ?ANS ? ?1 ? ? 1 ? ANS:1
> 13 ? ? ?19 1144.6800 ? ?ANS ? ?1 ? ? 1 ? ANS:1
>
> Region (4 levels, fixed)
> Site (6 levels and 3 levels, random)
>
> data$site <- as.factor(data$site)
> data$site3 <-factor(data$region:data$site)
>
>
> mod.lme <- lme(recruits ~ region, data=data, random=~1|site3)
>
> anova(mod)
>
> ? ? ? ? ? ?numDF denDF ?F-value p-value
> (Intercept) ? ? 1 ? 399 93.58730 ?<.0001
> region ? ? ? ? ?3 ? ?17 19.21751 ?<.0001
>
> ?mod.aov <- aov(recruits ~ region + Error(site3), data=data)
> ?summary(mod.aov)\
>
> Error: site3
> ? ? ? ? ? ? ? ? Df ? Sum Sq ?Mean Sq F value ? ?Pr(>F)
> region ? ? ? ?3 ?32024226 10674742 ?19.218 1.057e-05 ***
> Residuals ?17 ?9442984 ? 555470
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Error: Within
> ? ? ? ? ? ? ? ? ?Df ? Sum Sq ?Mean Sq F value Pr(>F)
> Residuals ?399 11839881 ? ?29674
>
> Now, both F-ratios are 19.21, I am not sure what i am doing
> incorrectly but I would appreciate any advice on my mistake. ?Thanks
> very much
>
> Stephen Cole
> Graduate student
> Marine Ecology Lab
> Saint Francis Xavier University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From mike.akresh at gmail.com  Wed Apr 22 17:38:23 2009
From: mike.akresh at gmail.com (Michael Akresh)
Date: Wed, 22 Apr 2009 11:38:23 -0400
Subject: [R-sig-ME] glmer with a quasi-Poisson?
Message-ID: <c128d55b0904220838n3dee8392g91ca9f7e6224fc03@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090422/63e7818a/attachment.pl>

From harlancampbell at gmail.com  Wed Apr 22 18:04:14 2009
From: harlancampbell at gmail.com (H c)
Date: Wed, 22 Apr 2009 12:04:14 -0400
Subject: [R-sig-ME] Suggestions for numerical optimization tools...
Message-ID: <222824550904220904h1609787ena24c221826cb4292@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090422/5768a414/attachment.pl>

From HDoran at air.org  Wed Apr 22 18:20:04 2009
From: HDoran at air.org (Doran, Harold)
Date: Wed, 22 Apr 2009 12:20:04 -0400
Subject: [R-sig-ME] Suggestions for numerical optimization tools...
In-Reply-To: <222824550904220904h1609787ena24c221826cb4292@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE023FDFC5@DC1EXCL01.air.org>

If the likelihood can be written out, why would the derivatives not be
known?  

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of H c
> Sent: Wednesday, April 22, 2009 12:04 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Suggestions for numerical optimization tools...
> 
> My current program relies on the ML estimation of a 
> parameter, \phi,  based on numerical methods.  The parameter, 
> \phi,  lies on the 0 to 1 interval and evaluation of the ML 
> given any value of \phi is computationally expensive.
>  I am currently using the "optimize()" function, optimizing 
> the Likelihood with respect to phi.  This is extremely 
> computationally expensive and is the bottleneck of an 
> otherwise efficient program.
> Does anyone have any suggestions of better tools for 
> numerical optimization.
>  (Derivatives are not known, so gradient decent options do 
> not appear to be applicable).
> 
> Anything helps,
> 
> Harlan
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From bolker at ufl.edu  Wed Apr 22 18:31:46 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 22 Apr 2009 12:31:46 -0400
Subject: [R-sig-ME] Suggestions for numerical optimization tools...
In-Reply-To: <222824550904220904h1609787ena24c221826cb4292@mail.gmail.com>
References: <222824550904220904h1609787ena24c221826cb4292@mail.gmail.com>
Message-ID: <49EF4672.2090508@ufl.edu>

  Is optimize() really the bottleneck, or is it the computation time
in the objective function?  Can you implement critical bits of the
objective function calculation in C or FORTRAN?  Based on the
description in optimize(), it seems that although it's a compromise
between robustness and efficiency, that it's usually pretty efficient.
How many function evaluations are typically being required to get
to the minimum?  Can you get away with a lower tolerance?  Can you find
some kind of Gaussian-quadrature approximation to your integral that
makes things more efficient?

  You could also try

http://code.google.com/p/rsympy/#Semi-Automatic_Differentiation

suggested by John Nash ...



H c wrote:
> My current program relies on the ML estimation of a parameter, \phi,  based
> on numerical methods.  The parameter, \phi,  lies on the 0 to 1 interval and
> evaluation of the ML given any value of \phi is computationally expensive.
>  I am currently using the "optimize()" function, optimizing the Likelihood
> with respect to phi.  This is extremely computationally expensive and is the
> bottleneck of an otherwise efficient program.
> Does anyone have any suggestions of better tools for numerical optimization.
>  (Derivatives are not known, so gradient decent options do not appear to be
> applicable).
> 
> Anything helps,
> 
> Harlan
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From diederik.strubbe at ua.ac.be  Wed Apr 22 19:13:51 2009
From: diederik.strubbe at ua.ac.be (Strubbe Diederik)
Date: Wed, 22 Apr 2009 19:13:51 +0200
Subject: [R-sig-ME] About glmer with a quasi-Poisson
Message-ID: <C9854550FEF14846A136100B3EC52F73B6B662@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090422/121efee6/attachment.pl>

From otter at otter-rsch.com  Wed Apr 22 21:22:29 2009
From: otter at otter-rsch.com (dave fournier)
Date: Wed, 22 Apr 2009 12:22:29 -0700
Subject: [R-sig-ME] About glmer with a quasi-Poisson
In-Reply-To: <C9854550FEF14846A136100B3EC52F73B6B662@xmail05.ad.ua.ac.be>
References: <C9854550FEF14846A136100B3EC52F73B6B662@xmail05.ad.ua.ac.be>
Message-ID: <49EF6E75.4010705@otter-rsch.com>

You can fit you data for these various model structures including
Zero Inflated Poisson Mixed models and
Zero Inflated Negative Binomial mixed models using AD Model Builder's
random effects module. glmmADMB was written using that package, however
if has only a few capabilities due to the difficulties inherent in
interfacing with R.  ADMB software is now freely available at
http://admb-project.org.

If you want more information you can contact me off list.
It would be interesting to compare the ADMB output with the lmer
quasi-poisson.

   Dave



-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From ken at kjbeath.com.au  Wed Apr 22 23:37:00 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 23 Apr 2009 07:37:00 +1000
Subject: [R-sig-ME] Suggestions for numerical optimization tools...
In-Reply-To: <222824550904220904h1609787ena24c221826cb4292@mail.gmail.com>
References: <222824550904220904h1609787ena24c221826cb4292@mail.gmail.com>
Message-ID: <8D5340CF-B4C5-44F9-8C2D-1C7923218BB9@kjbeath.com.au>

I assume this is part of the mixture model that you have mentioned  
previously, where you used EM.

It is probably better to use GEM, that is not to allow the  
optimisation of the maximisation part to complete but perform only a  
small number of iterations, possibly even 1. When the EM looks close  
to convergence switching to optimising the complete likelihood can  
also help.

Ken

On 23/04/2009, at 2:04 AM, H c wrote:

> My current program relies on the ML estimation of a parameter,  
> \phi,  based
> on numerical methods.  The parameter, \phi,  lies on the 0 to 1  
> interval and
> evaluation of the ML given any value of \phi is computationally  
> expensive.
> I am currently using the "optimize()" function, optimizing the  
> Likelihood
> with respect to phi.  This is extremely computationally expensive  
> and is the
> bottleneck of an otherwise efficient program.
> Does anyone have any suggestions of better tools for numerical  
> optimization.
> (Derivatives are not known, so gradient decent options do not appear  
> to be
> applicable).
>
> Anything helps,
>
> Harlan
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Thu Apr 23 01:13:15 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 23 Apr 2009 09:13:15 +1000
Subject: [R-sig-ME] Unbalanced nested design
In-Reply-To: <f7134c940904210632j76ed7c18y553c0c064e1c4b5f@mail.gmail.com>
References: <f7134c940904210632j76ed7c18y553c0c064e1c4b5f@mail.gmail.com>
Message-ID: <68903C9C-DA81-4B30-876F-CC5D4508531B@anu.edu.au>

Hi Stephen -
You'd get an exactly equivalent result if you calculated averages over  
site and based your analysis on those.  The analysis can be a one-way  
anova with site as a fixed effect, with just one source of random  
variation.  So the unbalance does not matter, except that the F- 
statistic is an approximate F-statistic.  (For comparisons between the  
region with 3 sites and the other region, you need the Welch or  
Satterthwaite approx; see under help(t.test).  The unbalance is  
however relatively mild, as such things go!)

The F-statistic that tests for fixed site differences in the anova is  
the same statistic that tests for a non-zero between site component of  
variance in the nlme analysis, if that is what you had.  (The multiple  
observations within sites do not affect the argument.

(Even if there had been unbalance in the number of observations per  
site, the anova and nlme would still come up with the same number for  
the F-test for comparing regions, but now all comparisons between  
regions might involve use of Satterthwaite type approximation, if you  
use that ancient technology!)

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 21/04/2009, at 11:32 PM, Stephen Cole wrote:

> Hello All - I would like to run a 2 factor nested ANOVA.  The design
> is unbalanced as i have 6 sites in 3 regions and 3 sites in 1 other
> region. Site is nested in region  I am interested in the differences
> in mean recruit density among 4 regions.  I have used the lme function
> in the nlme library and am confused about the output.  I have a copy
> of P/B and I quote p. 25 " The lme function does produce sensible
> maximum likelihood estimates or restricted maximum likelihood
> estimates from the unbalanced data."  Thus, as i understand it lme can
> handle this unbalanced data set that i have.  However, when i compared
> the lme model to an aov model, the fixed effects results are
> identical. (f-ratio and p-value).  How does lme handle unbalanced data
> if the result is the same as aov which can not handle unbalanced data.
> Thank-you for any help provided.
>
> I have attached a subsection of my data.  The total number of records
> is 420, with a sample of 20 quadrat counts from each site (21 sites x
> 20 = 420)
>
> Data:
>         adults  recruits region site site2   site3
> 1      138 1268.3300    ANS    1     1    ANS:1
> 2      131  608.3300     ANS    1     1    ANS:1
> 3       13  696.8800     ANS    1     1    ANS:1
> 4       12  412.5000     ANS    1     1    ANS:1
> 5        2  355.5600     ANS    1     1    ANS:1
> 6        0  528.0000     ANS    1     1    ANS:1
> 7        4  421.2100     ANS    1     1    ANS:1
> 8        0  378.0000     ANS    1     1    ANS:1
> 9       92  893.3300    ANS    1     1    ANS:1
> 10      77 1184.3100   ANS    1     1    ANS:1
> 11      92  961.4200    ANS    1     1    ANS:1
> 12       0 1029.0000    ANS    1     1   ANS:1
> 13      19 1144.6800    ANS    1     1   ANS:1
>
> Region (4 levels, fixed)
> Site (6 levels and 3 levels, random)
>
> data$site <- as.factor(data$site)
> data$site3 <-factor(data$region:data$site)
>
>
> mod.lme <- lme(recruits ~ region, data=data, random=~1|site3)
>
> anova(mod)
>
>           numDF denDF  F-value p-value
> (Intercept)     1   399 93.58730  <.0001
> region          3    17 19.21751  <.0001
>
> mod.aov <- aov(recruits ~ region + Error(site3), data=data)
> summary(mod.aov)\
>
> Error: site3
>                Df   Sum Sq  Mean Sq F value    Pr(>F)
> region        3  32024226 10674742  19.218 1.057e-05 ***
> Residuals  17  9442984   555470
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Error: Within
>                 Df   Sum Sq  Mean Sq F value Pr(>F)
> Residuals  399 11839881    29674
>
> Now, both F-ratios are 19.21, I am not sure what i am doing
> incorrectly but I would appreciate any advice on my mistake.  Thanks
> very much
>
> Stephen Cole
> Graduate student
> Marine Ecology Lab
> Saint Francis Xavier University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jhadfiel at staffmail.ed.ac.uk  Thu Apr 23 09:33:15 2009
From: jhadfiel at staffmail.ed.ac.uk (Jarrod Hadfield)
Date: Thu, 23 Apr 2009 08:33:15 +0100
Subject: [R-sig-ME] About glmer with a quasi-Poisson
In-Reply-To: <C9854550FEF14846A136100B3EC52F73B6B662@xmail05.ad.ua.ac.be>
References: <C9854550FEF14846A136100B3EC52F73B6B662@xmail05.ad.ua.ac.be>
Message-ID: <20090423083315.amm3acneo0wss0s4@www.staffmail.ed.ac.uk>

Hi,

This model can be fitted using MCMCglmm (and others I expect) if it is  
coded correctly. As Doug mentioned in an earlier email, calling  
different points in different sites the same name is not really  
necessary any more. If they are called different names then:

random=~site+point

is the same as the glmer model you use. If they are called the same thing then

random=~site+site:point

is the same as the glmer model below, as can be seen in the glmer summary.

Coded this way many packages can probably fit the type of model you envisage.

Cheers,

Jarrod





Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:

> Hey Mike,
>
> I am working on a similar dataset as you. I have point counts of   
> birds in 26 sites, in total 57 points [number of point counts per   
> site varying from 1 to 5]. These points were visited 5 times ( in   
> the same year). Most of the counts are 0 (> 90%), and the dataset is  
>  thus zero-inflated - which, as far as I know is a special case of   
> overdispersion. There  are 3 continuous explanatory variables under   
> consideration. I have been looking at different packages to fit a   
> model with
> 1)a  zero-inflated poison distribution
> 2)a nested random effect to account for the fact that I have points   
> located within sites
> 3)a random effect to account for the 5 visits (repeated measures)
>
> However, none of the packages that I tried is able to do this ( I   
> tried zeroinfl {pscl}, fmr {gnlm}, MCMCglmm {MCMCglmm} and   
> glmm.ADMB{glmmADMB}). The problem seems to be the nested random   
> effect (1|site/point in my case).
>
> The only function that I found able to handle this nested random   
> design and a distribution that comes close to be 'good' for my data   
> is glmer with a quasi-poisson distribution. My  model syntax is:
>
> test <-   
> glmer(data$abundance~data$pca1+data$pca2+data$Gynoxis+(1|site/point)  
>  + (1|visit),family=quasipoisson(link="log"))
>
> and yields the folowing output
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: data$abundance ~ data$pca1 + data$pca2 + data$Gynoxis + (1   
> |      site/point) + (1 | visit)
>    AIC   BIC logLik deviance
>  158.1 187.1 -71.05    142.1
> Random effects:
>  Groups     Name        Variance  Std.Dev.
>  point:site (Intercept) 0.0468101 0.216356
>  site       (Intercept) 0.0000000 0.000000
>  visit      (Intercept) 0.0012396 0.035208
>  Residual               0.0187386 0.136889
> Number of obs: 276, groups: point:site, 57; site, 26; visit, 5
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  -3.20340    0.10701 -29.936
> data$pca1    -0.02629    0.03100  -0.848
> data$pca2    -0.15055    0.02907  -5.180
> data$Gynoxis -0.02246    0.01320  -1.702
>
> Correlation of Fixed Effects:
>             (Intr) dt$pc1 dt$pc2
> data$pca1   -0.239
> data$pca2   -0.098 -0.071
> data$Gynoxs -0.878  0.330  0.205
>
> I was not aware of the comments of Ben Bolker on glmer and   
> quasi-Poisson, and am thus also interested in any responses on this.  
>  Am I right to conclude that, ecept glmer, none of the packages   
> mentioned above is capable to handle nested random effects and   
> zero-inflated Poisson data?
>
> Cheers and many thanks,
>
> Diederik
>
>
>
> Diederik Strubbe
> Evolutionary Ecology Group
> Department of Biology, University of Antwerp
> Universiteitsplein 1
> B-2610 Antwerp, Belgium
> http://webhost.ua.ac.be/deco
> tel : 32 3 820 23 85
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From diederik.strubbe at ua.ac.be  Fri Apr 24 19:11:06 2009
From: diederik.strubbe at ua.ac.be (Strubbe Diederik)
Date: Fri, 24 Apr 2009 19:11:06 +0200
Subject: [R-sig-ME] About glmer with a quasi-Poisson
References: <C9854550FEF14846A136100B3EC52F73B6B662@xmail05.ad.ua.ac.be>
	<20090423083315.amm3acneo0wss0s4@www.staffmail.ed.ac.uk>
Message-ID: <C9854550FEF14846A136100B3EC52F73B6B668@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090424/b8682727/attachment.pl>

From desja004 at umn.edu  Fri Apr 24 19:34:56 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Fri, 24 Apr 2009 12:34:56 -0500
Subject: [R-sig-ME] Default priors in MCMCglmm()
Message-ID: <1240594496.4820.2.camel@localhost.localdomain>

Hi I was curious what the default priors are that are used in
MCMCglmm()? Are they flat unless specified?
Cheers,
Chris



From yulya258 at hotmail.com  Sat Apr 25 17:03:20 2009
From: yulya258 at hotmail.com (J S)
Date: Sat, 25 Apr 2009 15:03:20 +0000
Subject: [R-sig-ME] What is this experimental design?
Message-ID: <BAY134-W30302455754799AA80630C88730@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090425/fa0d4963/attachment.pl>

From j.hadfield at ed.ac.uk  Sat Apr 25 20:43:25 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 25 Apr 2009 19:43:25 +0100
Subject: [R-sig-ME] Default priors in MCMCglmm()
In-Reply-To: <1240594496.4820.2.camel@localhost.localdomain>
References: <1240594496.4820.2.camel@localhost.localdomain>
Message-ID: <20090425194325.f3g5034ba8gkkso0@www.staffmail.ed.ac.uk>

Hi,

The default priors have n=0. To have non-informative priors in a
univariate (one response variable) model you need to specify n=-2 and
V=0.00000001.  V should really be zero but it will return an error
when it tries to invert it.  Improper priors can lead to numerical
problems, but hopefully MCMCglmm will pick up on these before they
create problems. Sometimes it doesn't, and you get a variance
"trapped" at zero or a correlation "trapped" at -1 or 1.

Please move on to version 1.09 if you haven't already.

Cheers,

Jarrod



Quoting Christopher David Desjardins <desja004 at umn.edu>:

> Hi I was curious what the default priors are that are used in
> MCMCglmm()? Are they flat unless specified?
> Cheers,
> Chris
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Sat Apr 25 20:45:58 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 25 Apr 2009 19:45:58 +0100
Subject: [R-sig-ME] About glmer with a quasi-Poisson
In-Reply-To: <C9854550FEF14846A136100B3EC52F73B6B668@xmail05.ad.ua.ac.be>
References: <C9854550FEF14846A136100B3EC52F73B6B662@xmail05.ad.ua.ac.be>
	<20090423083315.amm3acneo0wss0s4@www.staffmail.ed.ac.uk>
	<C9854550FEF14846A136100B3EC52F73B6B668@xmail05.ad.ua.ac.be>
Message-ID: <20090425194558.ri00kmkf4k0o0c4k@www.staffmail.ed.ac.uk>

Hi,

The zero-inflated Poisson is specified as a bivariate model, so the  
residual and random effect models usually follow a bivariate structure  
such as us(trait):site or idh(trait):units. These specify 2x2  
(co)variance matrices, in the first a covariance is estimated and in  
the second it is set to zero. For ZIP models I would use the idh  
function because the covariance between the Poisson process and the  
zero-inflation process cannot be estimated from the data. The prior  
term would have something like:

prior=list(R=list(V=diag(2), n=2, fix=2), G=list(G1=list(V=diag(2), n=2),
G2=list(V=diag(2), n=2), G3=list(V=diag(2), n=2)))

or if you don't want to have a random effect for the zero-inflation  
process have
something like:

prior=list(R=list(V=diag(2), n=2, fix=2), G=list(G1=list(V=diag(c(1,0.000001))
, n=2, fix=2), G2=list(V=diag(c(1,0.000001))
, n=2, fix=2), G3=list(V=diag(c(1,0.000001))
, n=2, fix=2))

Don't fix the residual variance to 0.000001 because the chain will not  
then mix.

As long as n is greater then or equal to the dimension of the  
covariance matrix the prior is proper and the covariance matrix should  
not become ill-conditioned.
Bear in mind that I just made these priors up - you need to pick  
something sensible, although the residual variance for the  
zero-inflation process (trait 2) is immaterial because there is no  
info in the data regarding this variance as with standard binary  
variables.

Cheers,

Jarrod




Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:

> Dear all,
>
> Thank you for the clarifications on the correct use and coding of   
> nested random effects. I decided to try the MCMCglmm package for my   
> analysis, but encountered some other problems.
>
> First: dataset of 57 points (each point has a unique ID (a,b,c,...)   
> and is nested in a certain site (26 sites, Site1,Site2,...). Points   
> have been visited 5 times (v1,v2,...,v5). For simplicity, I want to   
> relate the number of birds counted to one environmental variable,   
> called pca1. Using most default settings, the model should look like:
>
> MCMCglmm(abundance~data$pca1,family="zipoisson",random=~site+point+visit,data=data,verbose=TRUE)
>
> However, this results in the following error:"Error in   
> MCMCglmm(abundance ~ data$pca1, family = "zipoisson", random = ~site  
>  +  :   R-structure does not define unique residual for each data   
> point". [[ Note that if I specify another distribution, e.g. an   
> inappropriate Poisson, this error does not occur]]. As far as I   
> understand, this error relates to the rcov part of the model and I   
> updated the syntax to:
>
> MCMCglmm(abundance~data$pca1,family="zipoisson",rcov=~us(trait):units,random=~site+point+visit,data=data,verbose=TRUE)
>
> However, this results in another error:
> MCMC iteration = 0
> E[MH acceptance ratio] = 0.000431
> MCMC iteration = 1000
> E[MH acceptance ratio] = 0.439460
> MCMC iteration = 2000
> E[MH acceptance ratio] = 0.447993
> Error in MCMCglmm(abundance ~ data$pca1, family = "poisson", random   
> = ~site +  :
>   ill-conditioned G/R structure: use proper priors if you haven't or  
>  rescale data if you have
>
> From this I understand that I should define appropriate priors.   
> Based on the Plodia tutorial, I tried 3 priors:
> halfV = var(abundance)/2
> prior=list(R=list(n=1,V=halfV),G=list(G1=list(n=1,V=halfV)))
> ##halfV = 0.08639657##
> prior = list(R=list(V=1,n=1e+06),G=list(G1=list(V=1,n=0)))
> prior = list(R=list(V=1,n=0,fix=1),G=list(G1=list(V=1, +   n=0)))
>
> However, all of them result in the following error:
> Error in MCMCglmm(abundance ~ data$pca1, family = "zipoisson", rcov   
> = ~us(trait):units,  :
>   ill-conditioned G/R structure: use proper priors if you haven't or  
>  rescale data if you have
>
> Could anyone offer some advice on what my mistakes are? Or suggested  
>  papers to read, as this is my first encounter with Bayesian based   
> analysis.
>
> Many thanks,
>
> Diederik
>
>
> Diederik Strubbe
> Evolutionary Ecology Group
> Department of Biology, University of Antwerp
> Universiteitsplein 1
> B-2610 Antwerp, Belgium
> http://webhost.ua.ac.be/deco
> tel : 32 3 820 23 85
>
>
>
> -----Original Message-----
> From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
> Sent: Thu 23-4-2009 9:33
> To: Strubbe Diederik
> Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
> Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
>
>
>
> Diederik Strubbe
> Evolutionary Ecology Group
> Department of Biology, University of Antwerp
> Universiteitsplein 1
> B-2610 Antwerp, Belgium
> http://webhost.ua.ac.be/deco
> tel : 32 3 820 23 85
>
>
>
> -----Original Message-----
> From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
> Sent: Thu 23-4-2009 9:33
> To: Strubbe Diederik
> Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
> Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
>
> Hi,
>
> This model can be fitted using MCMCglmm (and others I expect) if it is
> coded correctly. As Doug mentioned in an earlier email, calling
> different points in different sites the same name is not really
> necessary any more. If they are called different names then:
>
> random=~site+point
>
> is the same as the glmer model you use. If they are called the same   
> thing then
>
> random=~site+site:point
>
> is the same as the glmer model below, as can be seen in the glmer summary.
>
> Coded this way many packages can probably fit the type of model you envisage.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:
>
>> Hey Mike,
>>
>> I am working on a similar dataset as you. I have point counts of
>> birds in 26 sites, in total 57 points [number of point counts per
>> site varying from 1 to 5]. These points were visited 5 times ( in
>> the same year). Most of the counts are 0 (> 90%), and the dataset is
>>  thus zero-inflated - which, as far as I know is a special case of
>> overdispersion. There  are 3 continuous explanatory variables under
>> consideration. I have been looking at different packages to fit a
>> model with
>> 1)a  zero-inflated poison distribution
>> 2)a nested random effect to account for the fact that I have points
>> located within sites
>> 3)a random effect to account for the 5 visits (repeated measures)
>>
>> However, none of the packages that I tried is able to do this ( I
>> tried zeroinfl {pscl}, fmr {gnlm}, MCMCglmm {MCMCglmm} and
>> glmm.ADMB{glmmADMB}). The problem seems to be the nested random
>> effect (1|site/point in my case).
>>
>> The only function that I found able to handle this nested random
>> design and a distribution that comes close to be 'good' for my data
>> is glmer with a quasi-poisson distribution. My  model syntax is:
>>
>> test <-
>> glmer(data$abundance~data$pca1+data$pca2+data$Gynoxis+(1|site/point)
>>  + (1|visit),family=quasipoisson(link="log"))
>>
>> and yields the folowing output
>>
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: data$abundance ~ data$pca1 + data$pca2 + data$Gynoxis + (1
>> |      site/point) + (1 | visit)
>>    AIC   BIC logLik deviance
>>  158.1 187.1 -71.05    142.1
>> Random effects:
>>  Groups     Name        Variance  Std.Dev.
>>  point:site (Intercept) 0.0468101 0.216356
>>  site       (Intercept) 0.0000000 0.000000
>>  visit      (Intercept) 0.0012396 0.035208
>>  Residual               0.0187386 0.136889
>> Number of obs: 276, groups: point:site, 57; site, 26; visit, 5
>>
>> Fixed effects:
>>              Estimate Std. Error t value
>> (Intercept)  -3.20340    0.10701 -29.936
>> data$pca1    -0.02629    0.03100  -0.848
>> data$pca2    -0.15055    0.02907  -5.180
>> data$Gynoxis -0.02246    0.01320  -1.702
>>
>> Correlation of Fixed Effects:
>>             (Intr) dt$pc1 dt$pc2
>> data$pca1   -0.239
>> data$pca2   -0.098 -0.071
>> data$Gynoxs -0.878  0.330  0.205
>>
>> I was not aware of the comments of Ben Bolker on glmer and
>> quasi-Poisson, and am thus also interested in any responses on this.
>>  Am I right to conclude that, ecept glmer, none of the packages
>> mentioned above is capable to handle nested random effects and
>> zero-inflated Poisson data?
>>
>> Cheers and many thanks,
>>
>> Diederik
>>
>>
>>
>> Diederik Strubbe
>> Evolutionary Ecology Group
>> Department of Biology, University of Antwerp
>> Universiteitsplein 1
>> B-2610 Antwerp, Belgium
>> http://webhost.ua.ac.be/deco
>> tel : 32 3 820 23 85
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From nikko at hailmail.net  Sun Apr 26 21:41:10 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sun, 26 Apr 2009 12:41:10 -0700
Subject: [R-sig-ME] Subject: Re:  About glmer with a quasi-Poisson
In-Reply-To: <mailman.1.1240740002.20272.r-sig-mixed-models@r-project.org>
References: <mailman.1.1240740002.20272.r-sig-mixed-models@r-project.org>
Message-ID: <1240774870.14309.1312396175@webmail.messagingengine.com>

Hi Jarrod,
Since there is no information in the data for the covariance between the
Poisson process and the 
zero-inflation process, in essence the model is not identified. If I am
understanding the structure
correctly, isn't it quite dangerous to even put a prior on the
covariance? Wouldn't it be better to 
write the model in a way that the covariance structure is explicit? For
instance could one 
not assume that the Poisson process and the zero inflation are
separable, can be written as
a product of the two distributions? I am shooting from the hip here, as
usual, but maybe I just need to write out the model to see it.

Nicholas  


> Message: 3
> Date: Sat, 25 Apr 2009 19:45:58 +0100
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
> To: Strubbe Diederik <diederik.strubbe at ua.ac.be>
> Cc: r-sig-mixed-models at r-project.org, boristmr at yahoo.com
> Message-ID: <20090425194558.ri00kmkf4k0o0c4k at www.staffmail.ed.ac.uk>
> Content-Type: text/plain;       charset=ISO-8859-1;     DelSp="Yes";
> 	format="flowed"
> 
> Hi,
> 
> The zero-inflated Poisson is specified as a bivariate model, so the  
> residual and random effect models usually follow a bivariate structure  
> such as us(trait):site or idh(trait):units. These specify 2x2  
> (co)variance matrices, in the first a covariance is estimated and in  
> the second it is set to zero. For ZIP models I would use the idh  
> function because the covariance between the Poisson process and the  
> zero-inflation process cannot be estimated from the data. The prior  
> term would have something like:
> 
> prior=list(R=list(V=diag(2), n=2, fix=2), G=list(G1=list(V=diag(2), n=2),
> G2=list(V=diag(2), n=2), G3=list(V=diag(2), n=2)))
> 
> or if you don't want to have a random effect for the zero-inflation  
> process have
> something like:
> 
> prior=list(R=list(V=diag(2), n=2, fix=2),
> G=list(G1=list(V=diag(c(1,0.000001))
> , n=2, fix=2), G2=list(V=diag(c(1,0.000001))
> , n=2, fix=2), G3=list(V=diag(c(1,0.000001))
> , n=2, fix=2))
> 
> Don't fix the residual variance to 0.000001 because the chain will not  
> then mix.
> 
> As long as n is greater then or equal to the dimension of the  
> covariance matrix the prior is proper and the covariance matrix should  
> not become ill-conditioned.
> Bear in mind that I just made these priors up - you need to pick  
> something sensible, although the residual variance for the  
> zero-inflation process (trait 2) is immaterial because there is no  
> info in the data regarding this variance as with standard binary  
> variables.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:
> 
> > Dear all,
> >
> > Thank you for the clarifications on the correct use and coding of   
> > nested random effects. I decided to try the MCMCglmm package for my   
> > analysis, but encountered some other problems.
> >
> > First: dataset of 57 points (each point has a unique ID (a,b,c,...)   
> > and is nested in a certain site (26 sites, Site1,Site2,...). Points   
> > have been visited 5 times (v1,v2,...,v5). For simplicity, I want to   
> > relate the number of birds counted to one environmental variable,   
> > called pca1. Using most default settings, the model should look like:
> >
> > MCMCglmm(abundance~data$pca1,family="zipoisson",random=~site+point+visit,data=data,verbose=TRUE)
> >
> > However, this results in the following error:"Error in   
> > MCMCglmm(abundance ~ data$pca1, family = "zipoisson", random = ~site  
> >  +  :   R-structure does not define unique residual for each data   
> > point". [[ Note that if I specify another distribution, e.g. an   
> > inappropriate Poisson, this error does not occur]]. As far as I   
> > understand, this error relates to the rcov part of the model and I   
> > updated the syntax to:
> >
> > MCMCglmm(abundance~data$pca1,family="zipoisson",rcov=~us(trait):units,random=~site+point+visit,data=data,verbose=TRUE)
> >
> > However, this results in another error:
> > MCMC iteration = 0
> > E[MH acceptance ratio] = 0.000431
> > MCMC iteration = 1000
> > E[MH acceptance ratio] = 0.439460
> > MCMC iteration = 2000
> > E[MH acceptance ratio] = 0.447993
> > Error in MCMCglmm(abundance ~ data$pca1, family = "poisson", random   
> > = ~site +  :
> >   ill-conditioned G/R structure: use proper priors if you haven't or  
> >  rescale data if you have
> >
> > From this I understand that I should define appropriate priors.   
> > Based on the Plodia tutorial, I tried 3 priors:
> > halfV = var(abundance)/2
> > prior=list(R=list(n=1,V=halfV),G=list(G1=list(n=1,V=halfV)))
> > ##halfV = 0.08639657##
> > prior = list(R=list(V=1,n=1e+06),G=list(G1=list(V=1,n=0)))
> > prior = list(R=list(V=1,n=0,fix=1),G=list(G1=list(V=1, +   n=0)))
> >
> > However, all of them result in the following error:
> > Error in MCMCglmm(abundance ~ data$pca1, family = "zipoisson", rcov   
> > = ~us(trait):units,  :
> >   ill-conditioned G/R structure: use proper priors if you haven't or  
> >  rescale data if you have
> >
> > Could anyone offer some advice on what my mistakes are? Or suggested  
> >  papers to read, as this is my first encounter with Bayesian based   
> > analysis.
> >
> > Many thanks,
> >
> > Diederik
> >
> >
> > Diederik Strubbe
> > Evolutionary Ecology Group
> > Department of Biology, University of Antwerp
> > Universiteitsplein 1
> > B-2610 Antwerp, Belgium
> > http://webhost.ua.ac.be/deco
> > tel : 32 3 820 23 85
> >
> >
> >
> > -----Original Message-----
> > From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
> > Sent: Thu 23-4-2009 9:33
> > To: Strubbe Diederik
> > Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
> > Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
> >
> >
> >
> > Diederik Strubbe
> > Evolutionary Ecology Group
> > Department of Biology, University of Antwerp
> > Universiteitsplein 1
> > B-2610 Antwerp, Belgium
> > http://webhost.ua.ac.be/deco
> > tel : 32 3 820 23 85
> >
> >
> >
> > -----Original Message-----
> > From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
> > Sent: Thu 23-4-2009 9:33
> > To: Strubbe Diederik
> > Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
> > Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
> >
> > Hi,
> >
> > This model can be fitted using MCMCglmm (and others I expect) if it is
> > coded correctly. As Doug mentioned in an earlier email, calling
> > different points in different sites the same name is not really
> > necessary any more. If they are called different names then:
> >
> > random=~site+point
> >
> > is the same as the glmer model you use. If they are called the same   
> > thing then
> >
> > random=~site+site:point
> >
> > is the same as the glmer model below, as can be seen in the glmer summary.
> >
> > Coded this way many packages can probably fit the type of model you envisage.
> >
> > Cheers,
> >
> > Jarrod
> >
> >
> >
> >
> >
> > Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:
> >
> >> Hey Mike,
> >>
> >> I am working on a similar dataset as you. I have point counts of
> >> birds in 26 sites, in total 57 points [number of point counts per
> >> site varying from 1 to 5]. These points were visited 5 times ( in
> >> the same year). Most of the counts are 0 (> 90%), and the dataset is
> >>  thus zero-inflated - which, as far as I know is a special case of
> >> overdispersion. There  are 3 continuous explanatory variables under
> >> consideration. I have been looking at different packages to fit a
> >> model with
> >> 1)a  zero-inflated poison distribution
> >> 2)a nested random effect to account for the fact that I have points
> >> located within sites
> >> 3)a random effect to account for the 5 visits (repeated measures)
> >>
> >> However, none of the packages that I tried is able to do this ( I
> >> tried zeroinfl {pscl}, fmr {gnlm}, MCMCglmm {MCMCglmm} and
> >> glmm.ADMB{glmmADMB}). The problem seems to be the nested random
> >> effect (1|site/point in my case).
> >>
> >> The only function that I found able to handle this nested random
> >> design and a distribution that comes close to be 'good' for my data
> >> is glmer with a quasi-poisson distribution. My  model syntax is:
> >>
> >> test <-
> >> glmer(data$abundance~data$pca1+data$pca2+data$Gynoxis+(1|site/point)
> >>  + (1|visit),family=quasipoisson(link="log"))
> >>
> >> and yields the folowing output
> >>
> >> Generalized linear mixed model fit by the Laplace approximation
> >> Formula: data$abundance ~ data$pca1 + data$pca2 + data$Gynoxis + (1
> >> |      site/point) + (1 | visit)
> >>    AIC   BIC logLik deviance
> >>  158.1 187.1 -71.05    142.1
> >> Random effects:
> >>  Groups     Name        Variance  Std.Dev.
> >>  point:site (Intercept) 0.0468101 0.216356
> >>  site       (Intercept) 0.0000000 0.000000
> >>  visit      (Intercept) 0.0012396 0.035208
> >>  Residual               0.0187386 0.136889
> >> Number of obs: 276, groups: point:site, 57; site, 26; visit, 5
> >>
> >> Fixed effects:
> >>              Estimate Std. Error t value
> >> (Intercept)  -3.20340    0.10701 -29.936
> >> data$pca1    -0.02629    0.03100  -0.848
> >> data$pca2    -0.15055    0.02907  -5.180
> >> data$Gynoxis -0.02246    0.01320  -1.702
> >>
> >> Correlation of Fixed Effects:
> >>             (Intr) dt$pc1 dt$pc2
> >> data$pca1   -0.239
> >> data$pca2   -0.098 -0.071
> >> data$Gynoxs -0.878  0.330  0.205
> >>
> >> I was not aware of the comments of Ben Bolker on glmer and
> >> quasi-Poisson, and am thus also interested in any responses on this.
> >>  Am I right to conclude that, ecept glmer, none of the packages
> >> mentioned above is capable to handle nested random effects and
> >> zero-inflated Poisson data?
> >>
> >> Cheers and many thanks,
> >>
> >> Diederik
> >>
> >>
> >>
> >> Diederik Strubbe
> >> Evolutionary Ecology Group
> >> Department of Biology, University of Antwerp
> >> Universiteitsplein 1
> >> B-2610 Antwerp, Belgium
> >> http://webhost.ua.ac.be/deco
> >> tel : 32 3 820 23 85
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >
> >
> >
> > --
> > The University of Edinburgh is a charitable body, registered in
> > Scotland, with registration number SC005336.
> >
> >
> >
> >
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 28, Issue 29
> **************************************************



From j.hadfield at ed.ac.uk  Sun Apr 26 22:05:05 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 26 Apr 2009 21:05:05 +0100
Subject: [R-sig-ME] Subject: Re:  About glmer with a quasi-Poisson
In-Reply-To: <1240774870.14309.1312396175@webmail.messagingengine.com>
References: <mailman.1.1240740002.20272.r-sig-mixed-models@r-project.org>
	<1240774870.14309.1312396175@webmail.messagingengine.com>
Message-ID: <20090426210505.jv1b310jk00wgc0k@www.staffmail.ed.ac.uk>

Hi Nicholas,

Specifying rcov=~idh(trait):units does as you suggest, with the  
covariance explicitly set to zero. I'm not sure there's technically  
anything wrong with specifying a fully parameterised covariance matrix  
(us(trait):units) with the covariance information coming from the  
prior, as long as it's recognised as such.

Cheers,

Jarrod





Quoting Nicholas Lewin-Koh <nikko at hailmail.net>:

> Hi Jarrod,
> Since there is no information in the data for the covariance between the
> Poisson process and the
> zero-inflation process, in essence the model is not identified. If I am
> understanding the structure
> correctly, isn't it quite dangerous to even put a prior on the
> covariance? Wouldn't it be better to
> write the model in a way that the covariance structure is explicit? For
> instance could one
> not assume that the Poisson process and the zero inflation are
> separable, can be written as
> a product of the two distributions? I am shooting from the hip here, as
> usual, but maybe I just need to write out the model to see it.
>
> Nicholas
>
>
>> Message: 3
>> Date: Sat, 25 Apr 2009 19:45:58 +0100
>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
>> To: Strubbe Diederik <diederik.strubbe at ua.ac.be>
>> Cc: r-sig-mixed-models at r-project.org, boristmr at yahoo.com
>> Message-ID: <20090425194558.ri00kmkf4k0o0c4k at www.staffmail.ed.ac.uk>
>> Content-Type: text/plain;       charset=ISO-8859-1;     DelSp="Yes";
>> 	format="flowed"
>>
>> Hi,
>>
>> The zero-inflated Poisson is specified as a bivariate model, so the
>> residual and random effect models usually follow a bivariate structure
>> such as us(trait):site or idh(trait):units. These specify 2x2
>> (co)variance matrices, in the first a covariance is estimated and in
>> the second it is set to zero. For ZIP models I would use the idh
>> function because the covariance between the Poisson process and the
>> zero-inflation process cannot be estimated from the data. The prior
>> term would have something like:
>>
>> prior=list(R=list(V=diag(2), n=2, fix=2), G=list(G1=list(V=diag(2), n=2),
>> G2=list(V=diag(2), n=2), G3=list(V=diag(2), n=2)))
>>
>> or if you don't want to have a random effect for the zero-inflation
>> process have
>> something like:
>>
>> prior=list(R=list(V=diag(2), n=2, fix=2),
>> G=list(G1=list(V=diag(c(1,0.000001))
>> , n=2, fix=2), G2=list(V=diag(c(1,0.000001))
>> , n=2, fix=2), G3=list(V=diag(c(1,0.000001))
>> , n=2, fix=2))
>>
>> Don't fix the residual variance to 0.000001 because the chain will not
>> then mix.
>>
>> As long as n is greater then or equal to the dimension of the
>> covariance matrix the prior is proper and the covariance matrix should
>> not become ill-conditioned.
>> Bear in mind that I just made these priors up - you need to pick
>> something sensible, although the residual variance for the
>> zero-inflation process (trait 2) is immaterial because there is no
>> info in the data regarding this variance as with standard binary
>> variables.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:
>>
>> > Dear all,
>> >
>> > Thank you for the clarifications on the correct use and coding of
>> > nested random effects. I decided to try the MCMCglmm package for my
>> > analysis, but encountered some other problems.
>> >
>> > First: dataset of 57 points (each point has a unique ID (a,b,c,...)
>> > and is nested in a certain site (26 sites, Site1,Site2,...). Points
>> > have been visited 5 times (v1,v2,...,v5). For simplicity, I want to
>> > relate the number of birds counted to one environmental variable,
>> > called pca1. Using most default settings, the model should look like:
>> >
>> >   
>> MCMCglmm(abundance~data$pca1,family="zipoisson",random=~site+point+visit,data=data,verbose=TRUE)
>> >
>> > However, this results in the following error:"Error in
>> > MCMCglmm(abundance ~ data$pca1, family = "zipoisson", random = ~site
>> >  +  :   R-structure does not define unique residual for each data
>> > point". [[ Note that if I specify another distribution, e.g. an
>> > inappropriate Poisson, this error does not occur]]. As far as I
>> > understand, this error relates to the rcov part of the model and I
>> > updated the syntax to:
>> >
>> >   
>> MCMCglmm(abundance~data$pca1,family="zipoisson",rcov=~us(trait):units,random=~site+point+visit,data=data,verbose=TRUE)
>> >
>> > However, this results in another error:
>> > MCMC iteration = 0
>> > E[MH acceptance ratio] = 0.000431
>> > MCMC iteration = 1000
>> > E[MH acceptance ratio] = 0.439460
>> > MCMC iteration = 2000
>> > E[MH acceptance ratio] = 0.447993
>> > Error in MCMCglmm(abundance ~ data$pca1, family = "poisson", random
>> > = ~site +  :
>> >   ill-conditioned G/R structure: use proper priors if you haven't or
>> >  rescale data if you have
>> >
>> > From this I understand that I should define appropriate priors.
>> > Based on the Plodia tutorial, I tried 3 priors:
>> > halfV = var(abundance)/2
>> > prior=list(R=list(n=1,V=halfV),G=list(G1=list(n=1,V=halfV)))
>> > ##halfV = 0.08639657##
>> > prior = list(R=list(V=1,n=1e+06),G=list(G1=list(V=1,n=0)))
>> > prior = list(R=list(V=1,n=0,fix=1),G=list(G1=list(V=1, +   n=0)))
>> >
>> > However, all of them result in the following error:
>> > Error in MCMCglmm(abundance ~ data$pca1, family = "zipoisson", rcov
>> > = ~us(trait):units,  :
>> >   ill-conditioned G/R structure: use proper priors if you haven't or
>> >  rescale data if you have
>> >
>> > Could anyone offer some advice on what my mistakes are? Or suggested
>> >  papers to read, as this is my first encounter with Bayesian based
>> > analysis.
>> >
>> > Many thanks,
>> >
>> > Diederik
>> >
>> >
>> > Diederik Strubbe
>> > Evolutionary Ecology Group
>> > Department of Biology, University of Antwerp
>> > Universiteitsplein 1
>> > B-2610 Antwerp, Belgium
>> > http://webhost.ua.ac.be/deco
>> > tel : 32 3 820 23 85
>> >
>> >
>> >
>> > -----Original Message-----
>> > From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
>> > Sent: Thu 23-4-2009 9:33
>> > To: Strubbe Diederik
>> > Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
>> > Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
>> >
>> >
>> >
>> > Diederik Strubbe
>> > Evolutionary Ecology Group
>> > Department of Biology, University of Antwerp
>> > Universiteitsplein 1
>> > B-2610 Antwerp, Belgium
>> > http://webhost.ua.ac.be/deco
>> > tel : 32 3 820 23 85
>> >
>> >
>> >
>> > -----Original Message-----
>> > From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
>> > Sent: Thu 23-4-2009 9:33
>> > To: Strubbe Diederik
>> > Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
>> > Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
>> >
>> > Hi,
>> >
>> > This model can be fitted using MCMCglmm (and others I expect) if it is
>> > coded correctly. As Doug mentioned in an earlier email, calling
>> > different points in different sites the same name is not really
>> > necessary any more. If they are called different names then:
>> >
>> > random=~site+point
>> >
>> > is the same as the glmer model you use. If they are called the same
>> > thing then
>> >
>> > random=~site+site:point
>> >
>> > is the same as the glmer model below, as can be seen in the glmer summary.
>> >
>> > Coded this way many packages can probably fit the type of model   
>> you envisage.
>> >
>> > Cheers,
>> >
>> > Jarrod
>> >
>> >
>> >
>> >
>> >
>> > Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:
>> >
>> >> Hey Mike,
>> >>
>> >> I am working on a similar dataset as you. I have point counts of
>> >> birds in 26 sites, in total 57 points [number of point counts per
>> >> site varying from 1 to 5]. These points were visited 5 times ( in
>> >> the same year). Most of the counts are 0 (> 90%), and the dataset is
>> >>  thus zero-inflated - which, as far as I know is a special case of
>> >> overdispersion. There  are 3 continuous explanatory variables under
>> >> consideration. I have been looking at different packages to fit a
>> >> model with
>> >> 1)a  zero-inflated poison distribution
>> >> 2)a nested random effect to account for the fact that I have points
>> >> located within sites
>> >> 3)a random effect to account for the 5 visits (repeated measures)
>> >>
>> >> However, none of the packages that I tried is able to do this ( I
>> >> tried zeroinfl {pscl}, fmr {gnlm}, MCMCglmm {MCMCglmm} and
>> >> glmm.ADMB{glmmADMB}). The problem seems to be the nested random
>> >> effect (1|site/point in my case).
>> >>
>> >> The only function that I found able to handle this nested random
>> >> design and a distribution that comes close to be 'good' for my data
>> >> is glmer with a quasi-poisson distribution. My  model syntax is:
>> >>
>> >> test <-
>> >> glmer(data$abundance~data$pca1+data$pca2+data$Gynoxis+(1|site/point)
>> >>  + (1|visit),family=quasipoisson(link="log"))
>> >>
>> >> and yields the folowing output
>> >>
>> >> Generalized linear mixed model fit by the Laplace approximation
>> >> Formula: data$abundance ~ data$pca1 + data$pca2 + data$Gynoxis + (1
>> >> |      site/point) + (1 | visit)
>> >>    AIC   BIC logLik deviance
>> >>  158.1 187.1 -71.05    142.1
>> >> Random effects:
>> >>  Groups     Name        Variance  Std.Dev.
>> >>  point:site (Intercept) 0.0468101 0.216356
>> >>  site       (Intercept) 0.0000000 0.000000
>> >>  visit      (Intercept) 0.0012396 0.035208
>> >>  Residual               0.0187386 0.136889
>> >> Number of obs: 276, groups: point:site, 57; site, 26; visit, 5
>> >>
>> >> Fixed effects:
>> >>              Estimate Std. Error t value
>> >> (Intercept)  -3.20340    0.10701 -29.936
>> >> data$pca1    -0.02629    0.03100  -0.848
>> >> data$pca2    -0.15055    0.02907  -5.180
>> >> data$Gynoxis -0.02246    0.01320  -1.702
>> >>
>> >> Correlation of Fixed Effects:
>> >>             (Intr) dt$pc1 dt$pc2
>> >> data$pca1   -0.239
>> >> data$pca2   -0.098 -0.071
>> >> data$Gynoxs -0.878  0.330  0.205
>> >>
>> >> I was not aware of the comments of Ben Bolker on glmer and
>> >> quasi-Poisson, and am thus also interested in any responses on this.
>> >>  Am I right to conclude that, ecept glmer, none of the packages
>> >> mentioned above is capable to handle nested random effects and
>> >> zero-inflated Poisson data?
>> >>
>> >> Cheers and many thanks,
>> >>
>> >> Diederik
>> >>
>> >>
>> >>
>> >> Diederik Strubbe
>> >> Evolutionary Ecology Group
>> >> Department of Biology, University of Antwerp
>> >> Universiteitsplein 1
>> >> B-2610 Antwerp, Belgium
>> >> http://webhost.ua.ac.be/deco
>> >> tel : 32 3 820 23 85
>> >>
>> >>
>> >> 	[[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >>
>> >
>> >
>> >
>> > --
>> > The University of Edinburgh is a charitable body, registered in
>> > Scotland, with registration number SC005336.
>> >
>> >
>> >
>> >
>> >
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> End of R-sig-mixed-models Digest, Vol 28, Issue 29
>> **************************************************
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From nikko at hailmail.net  Mon Apr 27 06:28:39 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sun, 26 Apr 2009 21:28:39 -0700
Subject: [R-sig-ME] Subject: Re:  About glmer with a quasi-Poisson
In-Reply-To: <20090426210505.jv1b310jk00wgc0k@www.staffmail.ed.ac.uk>
References: <mailman.1.1240740002.20272.r-sig-mixed-models@r-project.org><1240774870.14309.1312396175@webmail.messagingengine.com>
	<20090426210505.jv1b310jk00wgc0k@www.staffmail.ed.ac.uk>
Message-ID: <1240806519.32434.1312444169@webmail.messagingengine.com>

Hi Jarrod,
Comments below

On Sun, 26 Apr 2009 21:05 +0100, "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
wrote:
> Hi Nicholas,
> 
> Specifying rcov=~idh(trait):units does as you suggest, with the  
> covariance explicitly set to zero. 
Ah, I wasn't sure what the idh() function did

> I'm not sure there's technically  
> anything wrong with specifying a fully parameterised covariance matrix  
> (us(trait):units) with the covariance information coming from the  
> prior, as long as it's recognised as such.
What worries me here is that the prior on the covariance can have
effects on the other model parameters, and since 
the unspecified covariance model is not identified, ie no information
from the data, weird things can happen. Clearly one would not pay
attention to the covariance in the posterior, as it is just the prior,
but what is that doing to everything else? Maybe it is just me, but that
would
make me very uncomfortable about trusting anything else in the model. At
least explicitly setting the covariance, you can understand what is
going on.

Nicholas 
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> Quoting Nicholas Lewin-Koh <nikko at hailmail.net>:
> 
> > Hi Jarrod,
> > Since there is no information in the data for the covariance between the
> > Poisson process and the
> > zero-inflation process, in essence the model is not identified. If I am
> > understanding the structure
> > correctly, isn't it quite dangerous to even put a prior on the
> > covariance? Wouldn't it be better to
> > write the model in a way that the covariance structure is explicit? For
> > instance could one
> > not assume that the Poisson process and the zero inflation are
> > separable, can be written as
> > a product of the two distributions? I am shooting from the hip here, as
> > usual, but maybe I just need to write out the model to see it.
> >
> > Nicholas
> >
> >
> >> Message: 3
> >> Date: Sat, 25 Apr 2009 19:45:58 +0100
> >> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> >> Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
> >> To: Strubbe Diederik <diederik.strubbe at ua.ac.be>
> >> Cc: r-sig-mixed-models at r-project.org, boristmr at yahoo.com
> >> Message-ID: <20090425194558.ri00kmkf4k0o0c4k at www.staffmail.ed.ac.uk>
> >> Content-Type: text/plain;       charset=ISO-8859-1;     DelSp="Yes";
> >> 	format="flowed"
> >>
> >> Hi,
> >>
> >> The zero-inflated Poisson is specified as a bivariate model, so the
> >> residual and random effect models usually follow a bivariate structure
> >> such as us(trait):site or idh(trait):units. These specify 2x2
> >> (co)variance matrices, in the first a covariance is estimated and in
> >> the second it is set to zero. For ZIP models I would use the idh
> >> function because the covariance between the Poisson process and the
> >> zero-inflation process cannot be estimated from the data. The prior
> >> term would have something like:
> >>
> >> prior=list(R=list(V=diag(2), n=2, fix=2), G=list(G1=list(V=diag(2), n=2),
> >> G2=list(V=diag(2), n=2), G3=list(V=diag(2), n=2)))
> >>
> >> or if you don't want to have a random effect for the zero-inflation
> >> process have
> >> something like:
> >>
> >> prior=list(R=list(V=diag(2), n=2, fix=2),
> >> G=list(G1=list(V=diag(c(1,0.000001))
> >> , n=2, fix=2), G2=list(V=diag(c(1,0.000001))
> >> , n=2, fix=2), G3=list(V=diag(c(1,0.000001))
> >> , n=2, fix=2))
> >>
> >> Don't fix the residual variance to 0.000001 because the chain will not
> >> then mix.
> >>
> >> As long as n is greater then or equal to the dimension of the
> >> covariance matrix the prior is proper and the covariance matrix should
> >> not become ill-conditioned.
> >> Bear in mind that I just made these priors up - you need to pick
> >> something sensible, although the residual variance for the
> >> zero-inflation process (trait 2) is immaterial because there is no
> >> info in the data regarding this variance as with standard binary
> >> variables.
> >>
> >> Cheers,
> >>
> >> Jarrod
> >>
> >>
> >>
> >>
> >> Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:
> >>
> >> > Dear all,
> >> >
> >> > Thank you for the clarifications on the correct use and coding of
> >> > nested random effects. I decided to try the MCMCglmm package for my
> >> > analysis, but encountered some other problems.
> >> >
> >> > First: dataset of 57 points (each point has a unique ID (a,b,c,...)
> >> > and is nested in a certain site (26 sites, Site1,Site2,...). Points
> >> > have been visited 5 times (v1,v2,...,v5). For simplicity, I want to
> >> > relate the number of birds counted to one environmental variable,
> >> > called pca1. Using most default settings, the model should look like:
> >> >
> >> >   
> >> MCMCglmm(abundance~data$pca1,family="zipoisson",random=~site+point+visit,data=data,verbose=TRUE)
> >> >
> >> > However, this results in the following error:"Error in
> >> > MCMCglmm(abundance ~ data$pca1, family = "zipoisson", random = ~site
> >> >  +  :   R-structure does not define unique residual for each data
> >> > point". [[ Note that if I specify another distribution, e.g. an
> >> > inappropriate Poisson, this error does not occur]]. As far as I
> >> > understand, this error relates to the rcov part of the model and I
> >> > updated the syntax to:
> >> >
> >> >   
> >> MCMCglmm(abundance~data$pca1,family="zipoisson",rcov=~us(trait):units,random=~site+point+visit,data=data,verbose=TRUE)
> >> >
> >> > However, this results in another error:
> >> > MCMC iteration = 0
> >> > E[MH acceptance ratio] = 0.000431
> >> > MCMC iteration = 1000
> >> > E[MH acceptance ratio] = 0.439460
> >> > MCMC iteration = 2000
> >> > E[MH acceptance ratio] = 0.447993
> >> > Error in MCMCglmm(abundance ~ data$pca1, family = "poisson", random
> >> > = ~site +  :
> >> >   ill-conditioned G/R structure: use proper priors if you haven't or
> >> >  rescale data if you have
> >> >
> >> > From this I understand that I should define appropriate priors.
> >> > Based on the Plodia tutorial, I tried 3 priors:
> >> > halfV = var(abundance)/2
> >> > prior=list(R=list(n=1,V=halfV),G=list(G1=list(n=1,V=halfV)))
> >> > ##halfV = 0.08639657##
> >> > prior = list(R=list(V=1,n=1e+06),G=list(G1=list(V=1,n=0)))
> >> > prior = list(R=list(V=1,n=0,fix=1),G=list(G1=list(V=1, +   n=0)))
> >> >
> >> > However, all of them result in the following error:
> >> > Error in MCMCglmm(abundance ~ data$pca1, family = "zipoisson", rcov
> >> > = ~us(trait):units,  :
> >> >   ill-conditioned G/R structure: use proper priors if you haven't or
> >> >  rescale data if you have
> >> >
> >> > Could anyone offer some advice on what my mistakes are? Or suggested
> >> >  papers to read, as this is my first encounter with Bayesian based
> >> > analysis.
> >> >
> >> > Many thanks,
> >> >
> >> > Diederik
> >> >
> >> >
> >> > Diederik Strubbe
> >> > Evolutionary Ecology Group
> >> > Department of Biology, University of Antwerp
> >> > Universiteitsplein 1
> >> > B-2610 Antwerp, Belgium
> >> > http://webhost.ua.ac.be/deco
> >> > tel : 32 3 820 23 85
> >> >
> >> >
> >> >
> >> > -----Original Message-----
> >> > From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
> >> > Sent: Thu 23-4-2009 9:33
> >> > To: Strubbe Diederik
> >> > Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
> >> > Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
> >> >
> >> >
> >> >
> >> > Diederik Strubbe
> >> > Evolutionary Ecology Group
> >> > Department of Biology, University of Antwerp
> >> > Universiteitsplein 1
> >> > B-2610 Antwerp, Belgium
> >> > http://webhost.ua.ac.be/deco
> >> > tel : 32 3 820 23 85
> >> >
> >> >
> >> >
> >> > -----Original Message-----
> >> > From: Jarrod Hadfield [mailto:jhadfiel at staffmail.ed.ac.uk]
> >> > Sent: Thu 23-4-2009 9:33
> >> > To: Strubbe Diederik
> >> > Cc: r-sig-mixed-models at r-project.org; boristmr at yahoo.com
> >> > Subject: Re: [R-sig-ME] About glmer with a quasi-Poisson
> >> >
> >> > Hi,
> >> >
> >> > This model can be fitted using MCMCglmm (and others I expect) if it is
> >> > coded correctly. As Doug mentioned in an earlier email, calling
> >> > different points in different sites the same name is not really
> >> > necessary any more. If they are called different names then:
> >> >
> >> > random=~site+point
> >> >
> >> > is the same as the glmer model you use. If they are called the same
> >> > thing then
> >> >
> >> > random=~site+site:point
> >> >
> >> > is the same as the glmer model below, as can be seen in the glmer summary.
> >> >
> >> > Coded this way many packages can probably fit the type of model   
> >> you envisage.
> >> >
> >> > Cheers,
> >> >
> >> > Jarrod
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > Quoting Strubbe Diederik <diederik.strubbe at ua.ac.be>:
> >> >
> >> >> Hey Mike,
> >> >>
> >> >> I am working on a similar dataset as you. I have point counts of
> >> >> birds in 26 sites, in total 57 points [number of point counts per
> >> >> site varying from 1 to 5]. These points were visited 5 times ( in
> >> >> the same year). Most of the counts are 0 (> 90%), and the dataset is
> >> >>  thus zero-inflated - which, as far as I know is a special case of
> >> >> overdispersion. There  are 3 continuous explanatory variables under
> >> >> consideration. I have been looking at different packages to fit a
> >> >> model with
> >> >> 1)a  zero-inflated poison distribution
> >> >> 2)a nested random effect to account for the fact that I have points
> >> >> located within sites
> >> >> 3)a random effect to account for the 5 visits (repeated measures)
> >> >>
> >> >> However, none of the packages that I tried is able to do this ( I
> >> >> tried zeroinfl {pscl}, fmr {gnlm}, MCMCglmm {MCMCglmm} and
> >> >> glmm.ADMB{glmmADMB}). The problem seems to be the nested random
> >> >> effect (1|site/point in my case).
> >> >>
> >> >> The only function that I found able to handle this nested random
> >> >> design and a distribution that comes close to be 'good' for my data
> >> >> is glmer with a quasi-poisson distribution. My  model syntax is:
> >> >>
> >> >> test <-
> >> >> glmer(data$abundance~data$pca1+data$pca2+data$Gynoxis+(1|site/point)
> >> >>  + (1|visit),family=quasipoisson(link="log"))
> >> >>
> >> >> and yields the folowing output
> >> >>
> >> >> Generalized linear mixed model fit by the Laplace approximation
> >> >> Formula: data$abundance ~ data$pca1 + data$pca2 + data$Gynoxis + (1
> >> >> |      site/point) + (1 | visit)
> >> >>    AIC   BIC logLik deviance
> >> >>  158.1 187.1 -71.05    142.1
> >> >> Random effects:
> >> >>  Groups     Name        Variance  Std.Dev.
> >> >>  point:site (Intercept) 0.0468101 0.216356
> >> >>  site       (Intercept) 0.0000000 0.000000
> >> >>  visit      (Intercept) 0.0012396 0.035208
> >> >>  Residual               0.0187386 0.136889
> >> >> Number of obs: 276, groups: point:site, 57; site, 26; visit, 5
> >> >>
> >> >> Fixed effects:
> >> >>              Estimate Std. Error t value
> >> >> (Intercept)  -3.20340    0.10701 -29.936
> >> >> data$pca1    -0.02629    0.03100  -0.848
> >> >> data$pca2    -0.15055    0.02907  -5.180
> >> >> data$Gynoxis -0.02246    0.01320  -1.702
> >> >>
> >> >> Correlation of Fixed Effects:
> >> >>             (Intr) dt$pc1 dt$pc2
> >> >> data$pca1   -0.239
> >> >> data$pca2   -0.098 -0.071
> >> >> data$Gynoxs -0.878  0.330  0.205
> >> >>
> >> >> I was not aware of the comments of Ben Bolker on glmer and
> >> >> quasi-Poisson, and am thus also interested in any responses on this.
> >> >>  Am I right to conclude that, ecept glmer, none of the packages
> >> >> mentioned above is capable to handle nested random effects and
> >> >> zero-inflated Poisson data?
> >> >>
> >> >> Cheers and many thanks,
> >> >>
> >> >> Diederik
> >> >>
> >> >>
> >> >>
> >> >> Diederik Strubbe
> >> >> Evolutionary Ecology Group
> >> >> Department of Biology, University of Antwerp
> >> >> Universiteitsplein 1
> >> >> B-2610 Antwerp, Belgium
> >> >> http://webhost.ua.ac.be/deco
> >> >> tel : 32 3 820 23 85
> >> >>
> >> >>
> >> >> 	[[alternative HTML version deleted]]
> >> >>
> >> >> _______________________________________________
> >> >> R-sig-mixed-models at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>
> >> >>
> >> >
> >> >
> >> >
> >> > --
> >> > The University of Edinburgh is a charitable body, registered in
> >> > Scotland, with registration number SC005336.
> >> >
> >> >
> >> >
> >> >
> >> >
> >>
> >>
> >>
> >> --
> >> The University of Edinburgh is a charitable body, registered in
> >> Scotland, with registration number SC005336.
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> _______________________________________________
> >> R-sig-mixed-models mailing list
> >> R-sig-mixed-models at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >> End of R-sig-mixed-models Digest, Vol 28, Issue 29
> >> **************************************************
> >
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
>



From Kate.Pressland at bristol.ac.uk  Mon Apr 27 12:12:01 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Mon, 27 Apr 2009 11:12:01 +0100
Subject: [R-sig-ME] Subset data problems with mm
Message-ID: <2F9A2415D6D87A59D49A83BD@bio-mammal03.bio.bris.ac.uk>

Dear all,

Thank for your previous comments and help on my queries regarding mixed 
models.

I now have a problem regarding subsetting my data. For previous 
explanations on how my data is structured please see post "model definition 
with repeat measures". Briefly, my data is on lepidoptera surveyed over 
weeks and years on various sites that are all under different management. I 
am interested in whether management and leps are correlated in some way. I 
would like to subset the data frame but I am having problems and I think 
this may be down to my variable definitions.

An example model I tried:

	model1<-lme(Lep~MAN, random=~1|Site, data=new.ALL, subset = (Week > 15))

I get this error message:

	Error in sprintf(gettext(fmt, domain = domain), ...) :
  		object "Call" not found

I have created the variable Week by using this code:
	Week<-ordered(Weeks_rec)

Is this the cause of my problem? I think it's important that my variables 
are labelled (e.g. MAN<-factor(management)) but does this then interfere 
with subsetting code? As I have labeled Week as ordered(Weeks_rec), would I 
have to write individually != 1 & 1= 2...& != 15? This seem quite laborious!

My data is unbalanced so I also have included the command:
	new.ALL<-na.exclude(ALL)
	names(new.ALL)
	attach(new.ALL)

I have tried creating a new 'dataset':
	new.All1<-subset(new.ALL, Week > 15)

and writing that into the model instead
	model1<-lme(Lep~MAN, random=~1|Site, data=new.ALL1)

but I still get the same error message or the model runs with all the Week 
and not the subset. Would I need to write
	subset = (Week 1:16, >15) or similar?

I am very confused as I've used subsetting before without a problem. I've 
tried as many combinations as I could think of and it still won't work. Can 
anybody shed some light on this? Full code and variables labeling below if 
this is useful.

Your help is appreciated.

Kate

-------------

#full code:

ALL<-read.csv("location\\filename.txt",header=T)

attach(ALL)
names(ALL)
library(nlme)
library(lattice)

new.ALL<-na.exclude(ALL) # allowing NAs to be ignored but still keep the 
residuals and predictions padding to the correct length of the dataset
names(new.ALL)
attach(new.ALL)

#variables with correct labeling
Site<-factor(Site_ID)
Yr<-factor(Year)
Week<-ordered(Weeks_rec)		#1, 2, 3, ... , 26
MAN<-ordered(management_code)		#0,1,2
Lep<-log(Lep_m)				#log transformed
BAP<-factor(UK_BAP)			#TRUE, FALSE
Splist<-factor(Gen_Spec)		#NA, 0 (Generalist), 1 (Specialist)
Mgrnt<-factor(Migrant)			#TRUE, FALSE
Type<-factor(Lep_type)			#butterfly, moth
Sun<-asin(sqrt(Mean_Sun/100)) 	#arcsin transformation of %
Temp<-Mean_Temp
Wind<-ordered(Mean_Wind)		#NA,0,1,2,3,4,5,6



From andydolman at gmail.com  Mon Apr 27 12:54:56 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Mon, 27 Apr 2009 12:54:56 +0200
Subject: [R-sig-ME] Subset data problems with mm
In-Reply-To: <2F9A2415D6D87A59D49A83BD@bio-mammal03.bio.bris.ac.uk>
References: <2F9A2415D6D87A59D49A83BD@bio-mammal03.bio.bris.ac.uk>
Message-ID: <951234ac0904270354p671e3199g1f368804fd27a698@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090427/91a0a223/attachment.pl>

From Kate.Pressland at bristol.ac.uk  Mon Apr 27 13:12:19 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Mon, 27 Apr 2009 12:12:19 +0100
Subject: [R-sig-ME] Subset data problems with mm
In-Reply-To: <951234ac0904270354p671e3199g1f368804fd27a698@mail.gmail.com>
References: <2F9A2415D6D87A59D49A83BD@bio-mammal03.bio.bris.ac.uk>
	<951234ac0904270354p671e3199g1f368804fd27a698@mail.gmail.com>
Message-ID: <71A56656AA4BAB67AC42AF57@bio-mammal03.bio.bris.ac.uk>

AHA! That solved it. Crikey, I do feel a little stupid now for doing 
everything EXCEPT remove the additional brackets. Thanks for the help, 
seems to be working fine now.

Kate

--On 27 April 2009 12:54 +0200 Andrew Dolman <andydolman at gmail.com> wrote:

> Dear Kate,
>
> Try removing the brackets from around "(Week > 15)"
>
> e.g.
>
>
> model1<-lme(Lep~MAN, random=~1|Site, data=new.ALL, subset=Week > 15)
>
>
> Andy.
>
> andydolman at gmail.com
>
>
>
> 2009/4/27 CL Pressland <Kate.Pressland at bristol.ac.uk>
>
> Dear all,
>
> Thank for your previous comments and help on my queries regarding mixed
> models.
>
> I now have a problem regarding subsetting my data. For previous
> explanations on how my data is structured please see post "model
> definition with repeat measures". Briefly, my data is on lepidoptera
> surveyed over weeks and years on various sites that are all under
> different management. I am interested in whether management and leps are
> correlated in some way. I would like to subset the data frame but I am
> having problems and I think this may be down to my variable definitions.
>
> An example model I tried:
>
>  ? ? ? ?model1<-lme(Lep~MAN, random=~1|Site, data=new.ALL, subset =
> (Week > 15))
>
> I get this error message:
>
>  ? ? ? ?Error in sprintf(gettext(fmt, domain = domain), ...) :
>  ? ? ? ? ? ? ? ?object "Call" not found
>
> I have created the variable Week by using this code:
>  ? ? ? ?Week<-ordered(Weeks_rec)
>
> Is this the cause of my problem? I think it's important that my variables
> are labelled (e.g. MAN<-factor(management)) but does this then interfere
> with subsetting code? As I have labeled Week as ordered(Weeks_rec), would
> I have to write individually != 1 & 1= 2...& != 15? This seem quite
> laborious!
>
> My data is unbalanced so I also have included the command:
>  ? ? ? ?new.ALL<-na.exclude(ALL)
>  ? ? ? ?names(new.ALL)
>  ? ? ? ?attach(new.ALL)
>
> I have tried creating a new 'dataset':
>  ? ? ? ?new.All1<-subset(new.ALL, Week > 15)
>
> and writing that into the model instead
>  ? ? ? ?model1<-lme(Lep~MAN, random=~1|Site, data=new.ALL1)
>
> but I still get the same error message or the model runs with all the
> Week and not the subset. Would I need to write
>  ? ? ? ?subset = (Week 1:16, >15) or similar?
>
> I am very confused as I've used subsetting before without a problem. I've
> tried as many combinations as I could think of and it still won't work.
> Can anybody shed some light on this? Full code and variables labeling
> below if this is useful.
>
> Your help is appreciated.
>
> Kate
>
> -------------
>
># full code:
>
> ALL<-read.csv("location\\filename.txt",header=T)
>
> attach(ALL)
> names(ALL)
> library(nlme)
> library(lattice)
>
> new.ALL<-na.exclude(ALL) # allowing NAs to be ignored but still keep the
> residuals and predictions padding to the correct length of the dataset
> names(new.ALL)
> attach(new.ALL)
>
># variables with correct labeling
> Site<-factor(Site_ID)
> Yr<-factor(Year)
> Week<-ordered(Weeks_rec) ? ? ? ? ? ? ? ?#1, 2, 3, ... , 26
> MAN<-ordered(management_code) ? ? ? ? ? #0,1,2
> Lep<-log(Lep_m) ? ? ? ? ? ? ? ? ? ? ? ? #log transformed
> BAP<-factor(UK_BAP) ? ? ? ? ? ? ? ? ? ? #TRUE, FALSE
> Splist<-factor(Gen_Spec) ? ? ? ? ? ? ? ?#NA, 0 (Generalist), 1
> (Specialist)
> Mgrnt<-factor(Migrant) ? ? ? ? ? ? ? ? ?#TRUE, FALSE
> Type<-factor(Lep_type) ? ? ? ? ? ? ? ? ?#butterfly, moth
> Sun<-asin(sqrt(Mean_Sun/100)) ? #arcsin transformation of %
> Temp<-Mean_Temp
> Wind<-ordered(Mean_Wind) ? ? ? ? ? ? ? ?#NA,0,1,2,3,4,5,6
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



----------------------
Kate Pressland
Office D95
School of Biological Sciences
University of Bristol
Woodland Road
Bristol, BS8 1UG
Tel: 0117 9288918 (Internal 88918)
Kate.Pressland at bristol.ac.uk
www.bio.bris.ac.uk/people/staff.cfm?key=1137



From leem2 at upmc.edu  Mon Apr 27 05:12:18 2009
From: leem2 at upmc.edu (Lee, MinJae)
Date: Sun, 26 Apr 2009 23:12:18 -0400
Subject: [R-sig-ME] nonlinear mixed longitudinal model
In-Reply-To: <E42D3F7A39AA7A499F08A3DDB724083531B9E83B@MSXMBXNSPRD03.acct.upmchs.net>
References: <E42D3F7A39AA7A499F08A3DDB724083531B9E83B@MSXMBXNSPRD03.acct.upmchs.net>
Message-ID: <E42D3F7A39AA7A499F08A3DDB724083531B9E83F@MSXMBXNSPRD03.acct.upmchs.net>

Hello,


I was trying to convert the Proc nlmixed SAS to nlme in R.

especially, I'm considering the approach of Thi?baut and *Gadda( *Mixed models for longitudinal left-censored repeated measures in SAS program:

proc nlmixed

parms alpha=1 beta1=1 beta2=1   s11=0.5 s22=0.5 se=1;
bounds 0<=s11, 0<s22, 0<se;
eta=alpha+beta1*&gp+beta2*day+ u1+day*u2;
ll=(1-&cens)*(log((1/(sqrt(2*(3.14159)*se)))*exp((-1/(2*se))*((&coags-eta)**2))))
+(&cens)*(log(probnorm((&coags-eta)/(sqrt(se)))));
model &coags ~ general(ll);

random u1 u2 ~ normal([0,0],[s11,0,s22]) subject=subjectid;



I know there are a lot of differences between them(nlmixed vs nlme), but I really need to convert this program to R.

could you please give any advise for me?

is there any appropriate packages in R for this model?



Thank you so much in advance,

Minjae Lee



From spencer.graves at prodsyse.com  Mon Apr 27 17:55:22 2009
From: spencer.graves at prodsyse.com (spencerg)
Date: Mon, 27 Apr 2009 08:55:22 -0700
Subject: [R-sig-ME] nonlinear mixed longitudinal model
In-Reply-To: <E42D3F7A39AA7A499F08A3DDB724083531B9E83F@MSXMBXNSPRD03.acct.upmchs.net>
References: <E42D3F7A39AA7A499F08A3DDB724083531B9E83B@MSXMBXNSPRD03.acct.upmchs.net>
	<E42D3F7A39AA7A499F08A3DDB724083531B9E83F@MSXMBXNSPRD03.acct.upmchs.net>
Message-ID: <49F5D56A.6010207@prodsyse.com>

Hello: 


      The definitive reference on "nlme" is Pinheiro, J.C., and Bates, 
D.M. (2000) "Mixed-Effects Models in S and S-PLUS" (Springer). 


      Moreover, the "nlme" package installed with R includes a "scripts" 
subdirectory containing files like "ch01.R", ..., "ch08.R", containing R 
scripts necessary to work all the examples in the book.  This is 
important, because the R syntax today is slightly different from that 
described in the book, and these script files work where the text in the 
book in very rare occasions gives the wrong answer without warning. 

      You can find this "scripts" directory via "system.file('scripts', 
package='nlme')". 


      This does not answer your entire question, but it might help. 


      Best Wishes,
      Spencer

Lee, MinJae wrote:
> Hello,
>
>
> I was trying to convert the Proc nlmixed SAS to nlme in R.
>
> especially, I'm considering the approach of Thi?baut and *Gadda( *Mixed models for longitudinal left-censored repeated measures in SAS program:
>
> proc nlmixed
>
> parms alpha=1 beta1=1 beta2=1   s11=0.5 s22=0.5 se=1;
> bounds 0<=s11, 0<s22, 0<se;
> eta=alpha+beta1*&gp+beta2*day+ u1+day*u2;
> ll=(1-&cens)*(log((1/(sqrt(2*(3.14159)*se)))*exp((-1/(2*se))*((&coags-eta)**2))))
> +(&cens)*(log(probnorm((&coags-eta)/(sqrt(se)))));
> model &coags ~ general(ll);
>
> random u1 u2 ~ normal([0,0],[s11,0,s22]) subject=subjectid;
>
>
>
> I know there are a lot of differences between them(nlmixed vs nlme), but I really need to convert this program to R.
>
> could you please give any advise for me?
>
> is there any appropriate packages in R for this model?
>
>
>
> Thank you so much in advance,
>
> Minjae Lee
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From ken at kjbeath.com.au  Mon Apr 27 23:16:24 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Tue, 28 Apr 2009 07:16:24 +1000
Subject: [R-sig-ME] nonlinear mixed longitudinal model
In-Reply-To: <E42D3F7A39AA7A499F08A3DDB724083531B9E83F@MSXMBXNSPRD03.acct.upmchs.net>
References: <E42D3F7A39AA7A499F08A3DDB724083531B9E83B@MSXMBXNSPRD03.acct.upmchs.net>
	<E42D3F7A39AA7A499F08A3DDB724083531B9E83F@MSXMBXNSPRD03.acct.upmchs.net>
Message-ID: <8D80B8F9-5DE2-4438-8819-BB917BC5FCA7@kjbeath.com.au>

R, unlike SAS, doesn't provide functions for fitting random effects  
models with arbitrary likelihoods. The only solution is to write your  
own, using one of the integral approximations: Laplace, gauss-Hermite  
or adaptive Gauss-Hermite. Which one is appropriate depends on several  
factors. If speed doesn't matter, and clusters are not too large,  
Gauss-Hermite can be programmed very rapidly. A possibility is to  
modify the lme4 code but that doesn't look easy.

Ken

On 27/04/2009, at 1:12 PM, Lee, MinJae wrote:

> Hello,
>
>
> I was trying to convert the Proc nlmixed SAS to nlme in R.
>
> especially, I'm considering the approach of Thi?baut and  
> *Gadda( *Mixed models for longitudinal left-censored repeated  
> measures in SAS program:
>
> proc nlmixed
>
> parms alpha=1 beta1=1 beta2=1   s11=0.5 s22=0.5 se=1;
> bounds 0<=s11, 0<s22, 0<se;
> eta=alpha+beta1*&gp+beta2*day+ u1+day*u2;
> ll=(1-&cens)*(log((1/(sqrt(2*(3.14159)*se)))*exp((-1/ 
> (2*se))*((&coags-eta)**2))))
> +(&cens)*(log(probnorm((&coags-eta)/(sqrt(se)))));
> model &coags ~ general(ll);
>
> random u1 u2 ~ normal([0,0],[s11,0,s22]) subject=subjectid;
>
>
>
> I know there are a lot of differences between them(nlmixed vs nlme),  
> but I really need to convert this program to R.
>
> could you please give any advise for me?
>
> is there any appropriate packages in R for this model?
>
>
>
> Thank you so much in advance,
>
> Minjae Lee
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From otter at otter-rsch.com  Tue Apr 28 18:36:20 2009
From: otter at otter-rsch.com (dave fournier)
Date: Tue, 28 Apr 2009 09:36:20 -0700
Subject: [R-sig-ME] nonlinear mixed longitudinal model
In-Reply-To: <E42D3F7A39AA7A499F08A3DDB724083531B9E83F@MSXMBXNSPRD03.acct.upmchs.net>
References: <E42D3F7A39AA7A499F08A3DDB724083531B9E83F@MSXMBXNSPRD03.acct.upmchs.net>
Message-ID: <49F73084.7060707@otter-rsch.com>


If you want freely available software to do this you could look at
AD Model Builder's Random Effects Module available at

     http://admb-project.org

It combines the different advantages of software available on R and SAS
in that it deals with arbitrary nonlinear models like SAS, but also
allows crossed effects and in principal any level of nesting and
can use sparse matrix algorithms on the Hessian. It will do
the Laplace approximation for you.


-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From spluque at gmail.com  Wed Apr 29 07:05:08 2009
From: spluque at gmail.com (Sebastian P. Luque)
Date: Wed, 29 Apr 2009 00:05:08 -0500
Subject: [R-sig-ME] nlmer model definition and starting values
Message-ID: <87bpqgvym3.fsf@patagonia.sebmags.homelinux.org>

Hi,

I can't understand how to specify starting values for the following
nonlinear growth model.  The fake data produced below is designed to
closely match a real case scenario.  The model is for the following
Gompertz growth parameterization:

y=Linf * exp(-b * exp(-k * x))

where y is some size variable, and Linf, b, and k are parameters
indicating asymptotic size, size at birth, and a growth constant,
respectively.  I've hacked a self-start function for it.  Each row in
the fake data represents a single individual, with each individual
measured only once.  The data correspond to 4 species and 2 sexes, with
each combination having its own set of parameters, and some normal
heteroscedastic error added.

I would like to start with the assumption that b is a random effect,
while species and sex have fixed effects on Linf and k.


---<--------------------cut here---------------start------------------->---
"gompertz.fun" <- function(x, Linf, b, k) {Linf * exp(-b * exp(-k * x))}

## Set parameters for, say, 4 species and 2 sexes

grps <- expand.grid(species=LETTERS[1:4], sex=c("M", "F"))
parms <- c("Linf", "b", "k")
parms.mat <- matrix(c(432.3, 411.5, 389.7, 448.2,
                      381.5, 360.5, 338.1, 385.7,
                      1.16, 0.59, 0.73, 0.61,
                      7.56, 0.49, 0.51, 0.51,
                      0.15, 0.08, 0.07, 0.09,
                      0.29, 0.14, 0.11, 0.14),
                    ncol=3, dimnames=list(paste(grps[, 1], grps[, 2]), parms))

## Generate random x for each combination of species and sex, and y
## based on the parameters, with different y normal random noise
## (heteroscedastic) per combination
set.seed(123)
x <- rep(seq(1, 60, 3), 8) + runif(160, min=0, max=2)
fake <- data.frame(grps[rep(seq(nrow(grps)), each=20), ], x)
fake <- with(fake, fake[order(species, sex, x), ])
y <- apply(fake, 1, function(k) {
    grp <- paste(k[1], k[2])
    parms <- parms.mat[rownames(parms.mat) %in% grp, ]
    gompertz.fun(as.numeric(k[3]), parms[1], parms[2], parms[3])
})
## Add the increasing error
fake$y <- rnorm(160, mean=y, sd=seq(5, 30, length.out=20))
## Quick visualization
xyplot(y ~ x | species, data=fake, groups=sex, aspect=0.7,
       scales=list(alternating=1, tck=c(0.75, 0), rot=c(0, 90)))
---<--------------------cut here---------------end--------------------->---


How could I write the nlmer call for such a model, and how could I
anticipate the order of starting values to supply.  Thanks in advance
for any feedback on this.



Cheers,

-- 
Seb



From spluque at gmail.com  Wed Apr 29 07:13:55 2009
From: spluque at gmail.com (Sebastian P. Luque)
Date: Wed, 29 Apr 2009 00:13:55 -0500
Subject: [R-sig-ME] nlmer model definition and starting values
References: <87bpqgvym3.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <871vrcvy7g.fsf@patagonia.sebmags.homelinux.org>

Sorry, I forgot to include the self-start function:


---<--------------------cut here---------------start------------------->---
SSGompertz <- selfStart(~ Linf * exp(-b * exp(-k * x)),
                        function(mCall, data, LHS) {
                            xy <- sortedXyData(mCall[["x"]], LHS, data)
                            if (nrow(xy) < 4) {
                                stop("too few distinct input values to fit Gompertz model")
                            }
                            xyL <- xy
                            xyL$y <- log(abs(xyL$y))
                            pars <- NLSstAsymptotic(xyL)
                            pars <- coef(nls(y ~ exp(-b2 * b3 ^ x), data=xy, algorithm="plinear",
                                             start=c(b2=pars[["b1"]], b3=exp(-exp(pars[["lrc"]])))))
                            val <- pars[c(3, 1, 2)]
                            val[3] <- -log(val[3])
                            names(val) <- mCall[c("Linf", "b", "k")]
                            val
                        }, c("Linf", "b", "k"))
---<--------------------cut here---------------end--------------------->---


Thanks.



On Wed, 29 Apr 2009 00:05:08 -0500,
"Sebastian P. Luque" <spluque at gmail.com> wrote:

> Hi, I can't understand how to specify starting values for the
> following nonlinear growth model.  The fake data produced below is
> designed to closely match a real case scenario.  The model is for the
> following Gompertz growth parameterization:

> y=Linf * exp(-b * exp(-k * x))

> where y is some size variable, and Linf, b, and k are parameters
> indicating asymptotic size, size at birth, and a growth constant,
> respectively.  I've hacked a self-start function for it.  Each row in
> the fake data represents a single individual, with each individual
> measured only once.  The data correspond to 4 species and 2 sexes,
> with each combination having its own set of parameters, and some
> normal heteroscedastic error added.

> I would like to start with the assumption that b is a random effect,
> while species and sex have fixed effects on Linf and k.


> "gompertz.fun" <- function(x, Linf, b, k) {Linf * exp(-b * exp(-k *
> x))}

> ## Set parameters for, say, 4 species and 2 sexes

> grps <- expand.grid(species=LETTERS[1:4], sex=c("M", "F")) parms <-
> c("Linf", "b", "k") parms.mat <- matrix(c(432.3, 411.5, 389.7, 448.2,
> 381.5, 360.5, 338.1, 385.7, 1.16, 0.59, 0.73, 0.61, 7.56, 0.49, 0.51,
> 0.51, 0.15, 0.08, 0.07, 0.09, 0.29, 0.14, 0.11, 0.14), ncol=3,
> dimnames=list(paste(grps[, 1], grps[, 2]), parms))

> ## Generate random x for each combination of species and sex, and y ##
> based on the parameters, with different y normal random noise ##
> (heteroscedastic) per combination set.seed(123) x <- rep(seq(1, 60,
> 3), 8) + runif(160, min=0, max=2) fake <-
> data.frame(grps[rep(seq(nrow(grps)), each=20), ], x) fake <-
> with(fake, fake[order(species, sex, x), ]) y <- apply(fake, 1,
> function(k) { grp <- paste(k[1], k[2]) parms <-
> parms.mat[rownames(parms.mat) %in% grp, ]
> gompertz.fun(as.numeric(k[3]), parms[1], parms[2], parms[3]) }) ## Add
> the increasing error fake$y <- rnorm(160, mean=y, sd=seq(5, 30,
> length.out=20)) ## Quick visualization xyplot(y ~ x | species,
> data=fake, groups=sex, aspect=0.7, scales=list(alternating=1,
> tck=c(0.75, 0), rot=c(0, 90)))


> How could I write the nlmer call for such a model, and how could I
> anticipate the order of starting values to supply.  Thanks in advance
> for any feedback on this.



-- 
Seb



From Thierry.ONKELINX at inbo.be  Wed Apr 29 09:52:31 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 29 Apr 2009 09:52:31 +0200
Subject: [R-sig-ME] nlmer model definition and starting values
In-Reply-To: <871vrcvy7g.fsf@patagonia.sebmags.homelinux.org>
References: <87bpqgvym3.fsf@patagonia.sebmags.homelinux.org>
	<871vrcvy7g.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <2E9C414912813E4EB981326983E0A104066540E1@inboexch.inbo.be>

Dear Sebastian,

There is no need to define SSGompertz as SSgompertz is already included
in the stats package.

The helpfile for nlme() gives you a good example. Switching SSamymp into
SSgompertz is rather obvious. 

fm1 <- nlme(height ~ SSasymp(age, Asym, R0, lrc),
            data = Loblolly,
            fixed = Asym + R0 + lrc ~ 1,
            random = Asym ~ 1,
            start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
summary(fm1)
fm2 <- update(fm1, random = pdDiag(Asym + lrc ~ 1))
summary(fm2)
 
HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Sebastian P.
Luque
Verzonden: woensdag 29 april 2009 7:14
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] nlmer model definition and starting values

Sorry, I forgot to include the self-start function:


---<--------------------cut
here---------------start------------------->---
SSGompertz <- selfStart(~ Linf * exp(-b * exp(-k * x)),
                        function(mCall, data, LHS) {
                            xy <- sortedXyData(mCall[["x"]], LHS, data)
                            if (nrow(xy) < 4) {
                                stop("too few distinct input values to
fit Gompertz model")
                            }
                            xyL <- xy
                            xyL$y <- log(abs(xyL$y))
                            pars <- NLSstAsymptotic(xyL)
                            pars <- coef(nls(y ~ exp(-b2 * b3 ^ x),
data=xy, algorithm="plinear",
                                             start=c(b2=pars[["b1"]],
b3=exp(-exp(pars[["lrc"]])))))
                            val <- pars[c(3, 1, 2)]
                            val[3] <- -log(val[3])
                            names(val) <- mCall[c("Linf", "b", "k")]
                            val
                        }, c("Linf", "b", "k"))
---<--------------------cut
here---------------end--------------------->---


Thanks.



On Wed, 29 Apr 2009 00:05:08 -0500,
"Sebastian P. Luque" <spluque at gmail.com> wrote:

> Hi, I can't understand how to specify starting values for the
> following nonlinear growth model.  The fake data produced below is
> designed to closely match a real case scenario.  The model is for the
> following Gompertz growth parameterization:

> y=Linf * exp(-b * exp(-k * x))

> where y is some size variable, and Linf, b, and k are parameters
> indicating asymptotic size, size at birth, and a growth constant,
> respectively.  I've hacked a self-start function for it.  Each row in
> the fake data represents a single individual, with each individual
> measured only once.  The data correspond to 4 species and 2 sexes,
> with each combination having its own set of parameters, and some
> normal heteroscedastic error added.

> I would like to start with the assumption that b is a random effect,
> while species and sex have fixed effects on Linf and k.


> "gompertz.fun" <- function(x, Linf, b, k) {Linf * exp(-b * exp(-k *
> x))}

> ## Set parameters for, say, 4 species and 2 sexes

> grps <- expand.grid(species=LETTERS[1:4], sex=c("M", "F")) parms <-
> c("Linf", "b", "k") parms.mat <- matrix(c(432.3, 411.5, 389.7, 448.2,
> 381.5, 360.5, 338.1, 385.7, 1.16, 0.59, 0.73, 0.61, 7.56, 0.49, 0.51,
> 0.51, 0.15, 0.08, 0.07, 0.09, 0.29, 0.14, 0.11, 0.14), ncol=3,
> dimnames=list(paste(grps[, 1], grps[, 2]), parms))

> ## Generate random x for each combination of species and sex, and y ##
> based on the parameters, with different y normal random noise ##
> (heteroscedastic) per combination set.seed(123) x <- rep(seq(1, 60,
> 3), 8) + runif(160, min=0, max=2) fake <-
> data.frame(grps[rep(seq(nrow(grps)), each=20), ], x) fake <-
> with(fake, fake[order(species, sex, x), ]) y <- apply(fake, 1,
> function(k) { grp <- paste(k[1], k[2]) parms <-
> parms.mat[rownames(parms.mat) %in% grp, ]
> gompertz.fun(as.numeric(k[3]), parms[1], parms[2], parms[3]) }) ## Add
> the increasing error fake$y <- rnorm(160, mean=y, sd=seq(5, 30,
> length.out=20)) ## Quick visualization xyplot(y ~ x | species,
> data=fake, groups=sex, aspect=0.7, scales=list(alternating=1,
> tck=c(0.75, 0), rot=c(0, 90)))


> How could I write the nlmer call for such a model, and how could I
> anticipate the order of starting values to supply.  Thanks in advance
> for any feedback on this.



-- 
Seb

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From spluque at gmail.com  Wed Apr 29 15:07:23 2009
From: spluque at gmail.com (Sebastian P. Luque)
Date: Wed, 29 Apr 2009 08:07:23 -0500
Subject: [R-sig-ME] nlmer model definition and starting values
References: <87bpqgvym3.fsf@patagonia.sebmags.homelinux.org>
	<871vrcvy7g.fsf@patagonia.sebmags.homelinux.org>
	<2E9C414912813E4EB981326983E0A104066540E1@inboexch.inbo.be>
Message-ID: <87k553vcac.fsf@patagonia.sebmags.homelinux.org>

On Wed, 29 Apr 2009 09:52:31 +0200,
"ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:

> Dear Sebastian, There is no need to define SSGompertz as SSgompertz is
> already included in the stats package.

> The helpfile for nlme() gives you a good example. Switching SSamymp
> into SSgompertz is rather obvious.

> fm1 <- nlme(height ~ SSasymp(age, Asym, R0, lrc), data = Loblolly,
> fixed = Asym + R0 + lrc ~ 1, random = Asym ~ 1, start = c(Asym = 103,
> R0 = -8.5, lrc = -3.3)) summary(fm1) fm2 <- update(fm1, random =
> pdDiag(Asym + lrc ~ 1)) summary(fm2)

Thanks Thierry.  I was aware of SSgompertz(), but it is not the
parameterization that I need, and I don't know how I would have to
back-transform its results so that they correspond to the model I
showed.  I was also not sure how to define the call to nlmer() with the
fixed and random effects I described, and particularly how to set up the
start values.  The latter needs a named list or a vector, but I have
trouble anticipating what those names should be or the order of elements
in such a vector.


Cheers,

-- 
Seb



From Thierry.ONKELINX at inbo.be  Wed Apr 29 15:25:21 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 29 Apr 2009 15:25:21 +0200
Subject: [R-sig-ME] nlmer model definition and starting values
In-Reply-To: <87k553vcac.fsf@patagonia.sebmags.homelinux.org>
References: <87bpqgvym3.fsf@patagonia.sebmags.homelinux.org><871vrcvy7g.fsf@patagonia.sebmags.homelinux.org><2E9C414912813E4EB981326983E0A104066540E1@inboexch.inbo.be>
	<87k553vcac.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <2E9C414912813E4EB981326983E0A1040674178D@inboexch.inbo.be>

Dear Sebastian,

The names of the starting values should be identical to the names of the
coefficients in your model. A named vector has the advantage that the
order does not matter. With an unnamed vector the order should be
indentical as the order of the coefficients in your model.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Sebastian P.
Luque
Verzonden: woensdag 29 april 2009 15:07
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] nlmer model definition and starting values

On Wed, 29 Apr 2009 09:52:31 +0200,
"ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:

> Dear Sebastian, There is no need to define SSGompertz as SSgompertz is
> already included in the stats package.

> The helpfile for nlme() gives you a good example. Switching SSamymp
> into SSgompertz is rather obvious.

> fm1 <- nlme(height ~ SSasymp(age, Asym, R0, lrc), data = Loblolly,
> fixed = Asym + R0 + lrc ~ 1, random = Asym ~ 1, start = c(Asym = 103,
> R0 = -8.5, lrc = -3.3)) summary(fm1) fm2 <- update(fm1, random =
> pdDiag(Asym + lrc ~ 1)) summary(fm2)

Thanks Thierry.  I was aware of SSgompertz(), but it is not the
parameterization that I need, and I don't know how I would have to
back-transform its results so that they correspond to the model I
showed.  I was also not sure how to define the call to nlmer() with the
fixed and random effects I described, and particularly how to set up the
start values.  The latter needs a named list or a vector, but I have
trouble anticipating what those names should be or the order of elements
in such a vector.


Cheers,

-- 
Seb

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From bkelcey at umich.edu  Wed Apr 29 22:46:25 2009
From: bkelcey at umich.edu (Benjamin Michael Kelcey)
Date: Wed, 29 Apr 2009 16:46:25 -0400
Subject: [R-sig-ME] 3 level multivariate mixed effects IRT model
Message-ID: <20090429164625.16791s17727ew24g@web.mail.umich.edu>


Dear List,

Is anyone aware of how to implement a three level multivariate mixed  
effects IRT (2 parameter) model in lme4 or another package? I have  
found literature concerning the Rasch model using the lme4 package  
(e.g. Estimating the Multilevle Rasch Model) and a 2 level using the  
mlirt package but have not been able to find examples using both. Any  
suggestions would be much appreciated.

Thank you,
Ben



From drbn at yahoo.com  Wed Apr 29 22:30:46 2009
From: drbn at yahoo.com (David R.)
Date: Wed, 29 Apr 2009 13:30:46 -0700 (PDT)
Subject: [R-sig-ME] Modelling random effects with SITE, YEAR and SPECIES
Message-ID: <580180.24575.qm@web34801.mail.mud.yahoo.com>


Hello all,
?
First, sorry for the english and the basic questions. I'm using mixed models (lme4 package) to analyse variability in?13 SPECIES of birds observed during?15?YEARS across 5 SITES. All the SPECIES?were observed in all the sites in most years.
?
My fixed effects are A, B, C and Year. I'm interested in the stochastic effect of A, B and C on the dependent variable, but also in a possible linear trend of the dependent variable over time.
?
My random effects are SPECIES, YEAR and SITE, to control for the effects of nonindependence.
?
I have?a model with?SITE, YEAR?and SPECIES as crossed random effects like A + B + C + Year +?(1|SITE) + (1|YEAR) + (1|SPECIES). 
?
My questions are: 
?
1) Is this model correct? It is correct to model YEAR both as random effect and fixed effect? Is there the possibility that the variance accounted for by the random effect could robbing year as a fixed effect of explanatory power?
?
2)?It is meaningful, instead, ?to model YEAR as repeated measure, if the experimental unit were species within sites?
?
Thanks in advance
?
David






From bolker at ufl.edu  Wed Apr 29 23:58:27 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 29 Apr 2009 17:58:27 -0400
Subject: [R-sig-ME] Modelling random effects with SITE, YEAR and SPECIES
In-Reply-To: <580180.24575.qm@web34801.mail.mud.yahoo.com>
References: <580180.24575.qm@web34801.mail.mud.yahoo.com>
Message-ID: <49F8CD83.2040508@ufl.edu>

David R. wrote:
> Hello all,
> 
> First, sorry for the english and the basic questions. I'm using mixed
> models (lme4 package) to analyse variability in 13 SPECIES of birds
> observed during 15 YEARS across 5 SITES. All the SPECIES were
> observed in all the sites in most years.
> 
> My fixed effects are A, B, C and Year. I'm interested in the
> stochastic effect of A, B and C on the dependent variable, but also
> in a possible linear trend of the dependent variable over time.
> 
> My random effects are SPECIES, YEAR and SITE, to control for the
> effects of nonindependence.
> 
> I have a model with SITE, YEAR and SPECIES as crossed random effects
> like A + B + C + Year + (1|SITE) + (1|YEAR) + (1|SPECIES).
> 
> My questions are:
> 
> 1) Is this model correct? It is correct to model YEAR both as random
> effect and fixed effect? Is there the possibility that the variance
> accounted for by the random effect could robbing year as a fixed
> effect of explanatory power?

  Seems OK and sensible to me.
  I would guess that the linear trend and the random variation are
sufficiently different patterns that they would not conflict too badly,
but you could try the different nested models and see what happens ...

> 
> 2) It is meaningful, instead,  to model YEAR as repeated measure, if
> the experimental unit were species within sites?

  "Modeling YEAR as a random effect" and "Modeling YEAR as a repeated
measure" are, in my opinion, almost the same thing (but I'm ready to be
corrected, as always).  The only aspect of "repeated measures" that
would be different would be if you wanted to fit an autoregressive model
so that samples closer together in time were more correlated (which you
can't do with lmer at this
point).

  Ben Bolker



From cwilke at mail.utexas.edu  Fri May  1 22:22:35 2009
From: cwilke at mail.utexas.edu (Claus Wilke)
Date: Fri, 1 May 2009 15:22:35 -0500
Subject: [R-sig-ME] Testing for significance of a single random-effect
	factor in lme4
Message-ID: <200905011522.35907.cwilke@mail.utexas.edu>


I'm wondering how to test for the significance of a single random-effect 
factor in lme4. For example, in the famous Rail example, I might want to know 
whether the identity of the rail makes any difference. The naive approach 
would be:
> (a <- lmer( travel ~ (1|Rail) + 1, Rail ) )
> (b <- lmer( travel ~ 1, Rail ) )
> anova(a,b)
but this doesn't work because the second line causes an error:
> (b <- lmer( travel ~ 1, Rail ) )
Error in lmerFactorList(formula, fr, 0L, 0L) :
  No random effects terms specified in formula

An alternative would be to use 
> (b <- lm( travel ~ 1, Rail ) )
but then the anova function fails:
> anova(a,b)
Error in FUN(X[[1L]], ...) :
  no slot of name "call" for this object of class "lm"
(This case was already discussed in an earlier email to this list:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q2/000197.html
)

So I'm wondering whether I can just add a dummy factor which is the same for 
all data points and thus cannot explain any variance:
> Rail$dummy <- factor( rep( "X", nrow(Rail) ) ) # add a dummy factor
> (a <- lmer( travel ~ (1|Rail) + (1|dummy), Rail ) )
Linear mixed model fit by REML
Formula: travel ~ (1 | Rail) + (1 | dummy)
   Data: Rail
   AIC   BIC logLik deviance REMLdev
 130.2 133.7 -61.09    128.6   122.2
Random effects:
 Groups   Name        Variance Std.Dev.
 Rail     (Intercept) 615.3111 24.8055
 dummy    (Intercept)   2.3951  1.5476
 Residual              16.1667  4.0208
Number of obs: 18, groups: Rail, 6; dummy, 1

Fixed effects:
            Estimate Std. Error t value
(Intercept)    66.50      10.29   6.464
> (b <- lmer( travel ~ (1|dummy), Rail ) )
Linear mixed model fit by REML
Formula: travel ~ (1 | dummy)
   Data: Rail
   AIC   BIC logLik deviance REMLdev
 164.7 167.4 -79.34    165.2   158.7
Random effects:
 Groups   Name        Variance Std.Dev.
 dummy    (Intercept)  82.828   9.101
 Residual             559.088  23.645
Number of obs: 18, groups: dummy, 1

Fixed effects:
            Estimate Std. Error t value
(Intercept)    66.50      10.67   6.231
> anova(a,b)
Data: Rail
Models:
b: travel ~ (1 | dummy)
a: travel ~ (1 | Rail) + (1 | dummy)
  Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
b  3 171.226 173.897 -82.613
a  4 136.648 140.209 -64.324 36.578      1  1.467e-09 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

It seems to me that most of the estimates (likelihood, residuals, estimates 
for the Rail factor) are the same whether I use
	lmer( travel ~ (1|Rail) + (1|dummy), Rail )
or
	lmer( travel ~ (1|Rail) + 1, Rail )
but on the other hand AIC and BIC are somewhat different.

Thanks for your help,
  Claus Wilke

-- 
Claus Wilke
Section of Integrative Biology 
 and Center for Computational Biology and Bioinformatics 
University of Texas at Austin
1 University Station C0930
Austin, TX 78712
cwilke at mail.utexas.edu
512 471 6028



From j.hadfield at ed.ac.uk  Sat May  2 17:53:16 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 02 May 2009 16:53:16 +0100
Subject: [R-sig-ME] glmer vs. MCMCglmm
In-Reply-To: <Pine.LNX.4.64.0904031110030.19213@orpheus.qimr.edu.au>
References: <5BD07134-5DE9-47A2-8A60-2DC628A38AD7@ed.ac.uk>
	<Pine.LNX.4.64.0904031110030.19213@orpheus.qimr.edu.au>
Message-ID: <20090502165316.lck0c8400008k884@www.staffmail.ed.ac.uk>

Hi,

Sorry for not replying to this earlier - I'm in the middle of a field  
season at the moment so don't have much spare time. Thankfully  
Shinichi Nakagawa sent me the relevant information for reconciling  
MCMCglmm's results with sib-pair/lmer etc in the context of binary data.

The intra class correlation should be calculated as

VA/(VA+VE+pi^2/3)

where VE is a user-defined (and usually fixed) residual variance. This  
proportion is invariant to the choice of VE and for the PlodiaRB  
example gives an intra-class correlation of 0.15 which is the same as  
other programs.

If VE is set to 0.0001 (as in David's second MCMCglmm example), the  
chain will mix very poorly and not give valid inferences. This should  
be clear from basic mcmc diagnostics including plotting.

See Browne (2005) Journal of the Royal Statistical Society A 168  
599-613 for more info.

Cheers,

Jarrod



Quoting David Duffy <David.Duffy at qimr.edu.au>:

> On Thu, 2 Apr 2009, Jarrod Hadfield wrote:
>
>> Hi,
>>
>> As David suggested, the problem with binary data is that any   
>> residual variance in the underlying probability cannot be observed,  
>>  unlike other types of data. For example, if data are generated   
>> according to the process
>>
>> y ~ binom(n=1, p=inv.logit(mu + e_i))
>>
>> then the data look the same irrespective of the variance of the e's:
>>
>> y1<-rbinom(1000, 1, inv.logit(rnorm(1000, 0, 1)))
>> y2<-rbinom(1000, 1, inv.logit(rnorm(1000, 0, 10)))
>>
>> Because there is no information on VE (residual variance) we have   
>> to make an assumption about its value.  In terms of the fit of the   
>> model to the data the choice of VE should make no difference   
>> because the parameter is redundant. I think (if some one could   
>> clarify this that would be great) that lmer fixes VE to zero, where  
>>  with MCMCglmm the user is free to fix VE at any value.  Other than  
>>  that I believe the models should be identical. However, as VE   
>> approaches zero in MCMCglmm mixing becomes  problem, and actually   
>> when VE=0 the chain no longer mixes at all.
>>
>
> I'm not sure if this is of general interest or not.  I have been
> playing with that plodiaRB example, which has the advantage of just
> being sibship/cluster data.
>
> random intercept model
>            intercept  V_RE    intraclass r   LRT V_RE=0  Wald test SD_RE=0
> lmer          -0.986  0.5602  0.145 (1)
> glmmML        -0.986  0.5602  0.145          35.80       33.87
> Sib-pair      -1.020  0.6085  0.155 (1)                  31.60
> MCMCglmm(2)   -1.173  0.8830  0.469                      34.57
> MCMCglmm(3)    0.023  0.3590
>
> ANOVA icc estimator           0.098
> Tarone test = 73.61
> Variance chi-square = 127.54 (df=48)
>
> (1) taken as V/(V+pi^2/3)
> (2) units set to 1
> (3) units set to 0.0001
>
> animal model
>            intercept  V_A     h2
> Sib-pair      -1.068  0.7956  0.195 (1)
> MCMCglmm(2)   -1.339  2.2174  0.679
> MCMCglmm(3)   -0.046  0.3744   . Solar MFT (4)   .     0.375   0.375
>
> (1) taken as VA/(VA+pi^2/3)
> (2) units set to 1
> (3) units set to 0.0001
> (4) Multifactorial threshold model fitted using the SOLAR package
>
> For the one traditional geneticists model, which uses the binary (ie Pearson)
> correlations and a linear model for probabilities, the heritability should
> be ~0.2.  Using the other, the MFT, which (essentially) fits to the
> tetrachoric correlations, it is 0.38 (the relative magnitudes are the
> usual pattern I see).  For nongeneticists, the heritability can be
> thought of as the predicted intraclass correlation for identical twins,
> here one on the observed scale, the other on the linear predictor or
> latent variable scale.
>
> Cheers, David Duffy.
>
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From pxbeqa at rit.edu  Mon May  4 03:50:06 2009
From: pxbeqa at rit.edu (Peter Bajorski)
Date: Sun, 3 May 2009 21:50:06 -0400
Subject: [R-sig-ME] covariance structure of the within-group errors in lmer?
Message-ID: <CB3F49864DE9B048979F1C6A482CCB4205D0DAC8@svits11.main.ad.rit.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090503/9f533a1a/attachment.pl>

From pxbeqa at rit.edu  Mon May  4 03:58:55 2009
From: pxbeqa at rit.edu (Peter Bajorski)
Date: Sun, 3 May 2009 21:58:55 -0400
Subject: [R-sig-ME] covariance structure of the within-group errors in lmer?
	(Text based)
Message-ID: <CB3F49864DE9B048979F1C6A482CCB4205D0DAC9@svits11.main.ad.rit.edu>

Dear All,

Can anybody tell me if one can use variance functions from nlme (e.g.,
varIdent) in lmer? If not, can one specify the covariance structure of
the within-group errors in lmer and how?

Thanks,

Peter



From Fabian.Scheipl at stat.uni-muenchen.de  Mon May  4 10:43:48 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Mon, 4 May 2009 10:43:48 +0200
Subject: [R-sig-ME] Testing for significance of a single random-effect
	factor in lme4
Message-ID: <4836bc6a0905040143y1cfedc58pbbb6fdf032e849ca@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090504/1222b9e7/attachment.pl>

From charpent at bacbuc.dyndns.org  Tue May  5 09:37:07 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Tue, 05 May 2009 09:37:07 +0200
Subject: [R-sig-ME] How to compute deviance of a (g)lmer model under
 different values of the parameters ?
Message-ID: <1241509027.9821.24.camel@yod>

Dear list,

I'm trying to implement multiple imputations analysis of datasets with
missing values for mixed models. My interest goes mainly to the fixed
effects.

As you probably know, the principle of such an analysis is to impute
"reasonable" values to missing data a few times (with "reasonable"
variability), analyze these few completed datasets and pooling the
analyses.

Schafer(1999) states simple methods for pooling estimates of the model
and their variances. These methods can be applied to mixed models (with
a few snags : you need to *ignore* the variation of random effects
between imputed datasets beyond what is reflected in fixed effects' SE,
you need to guesstimate the residuals DoF, which is something Douglas
Bates has expressed grave doubts about). As it stands, these methods
give results which, at first look, does not seem unreasonable, and might
be used as a first approximation. More on this later.

My current goal is to build a function to build a "pooled test" for
likelihood ratio of two models. Such a test has been proposed by Meng &
Rubin (Biometrika, 1992), and, according to a presentation by RA
Medeiros, has been implemented in Stata under the name milrtest.

I'm trying to implement such a pooled test in R. My snag is that the
estimate is based on the estimation, for each imputed dataset, of the
(log)likelihood ratio of each of these datasets under the hypotheses of
the coefficients having precisely the values obtained in the coefficient
pooling step.

So what I need is a (if possible elegant and/or fast) way to compute
log-likelihood of a given dataset under a model (already built) under
this hypothesis, up to a quantity supposed constant between models.

The logLik(model) function will happily give me LL(model|parameters
giving makimum LL). What I need is something like logLik(model, coefs)
giving me (up to an additive constant) LL(model|parameters=coefs).

Do you have any suggestions ? I can always sum squares of residuals
recomputed under this alternative hypothesis, but I'm not quite sure
that's enough for my purposes, especially if I plan to include the
random effect estimates later...

					Emmanuel Charpentier



From charpent at bacbuc.dyndns.org  Tue May  5 23:02:24 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Tue, 05 May 2009 23:02:24 +0200
Subject: [R-sig-ME] How to compute deviance of a (g)lmer model under
 different values of the parameters ? Partial approximate answer
In-Reply-To: <1241509027.9821.24.camel@yod>
References: <1241509027.9821.24.camel@yod>
Message-ID: <1241557343.6878.43.camel@yod>

Answering to myself, at least for archive users' sake :

I have a partial approximate solution, which seems to work (= gives "not
seemingly unreasonable answers") for *linear* mixed effect models.

For these models, the deviance (= -2 logLik(themodel)) is easily
computed as the sum on all observations of the squared residuals. This
residual r is the difference between the observed value y and the
estimate by the model y.hat.

If, as usual, we denote the fixed effects model matrix by X, beta the
unknown fixed effects coefficients, with estimator beta.hat, Z the
random effects model matrix and b the unknown random effects
coefficients with estimator b.hat, we all know that

y.hat = X%*%beta.hat + Z%*%b.hat (1)

Therefore, r = y-y.hat = y-y.hat = y-(X%*%beta.hat + Z%*%b.hat). (2)

The problem is that Z%*%b.hat might be *quite* complicated to rebuilt
from ranef(model) and Z.

Since we seek a solution allowing to compute the LL of the model under a
new estimator of beta (say beta.hat.new) *computed while ignoring the
random effects beyond what is reflected in beta.hat variances*, it seems
reasonable to ignore what modifications to Z%*%b.hat an adjustment of
the model to the new fixed effect estimators beta.hat.new would entail,
and use (2) with the original values to compute the new "residuals". To
be precise :

a) Zbh=y.hat-X%*%beta.hat (computed from the original model)
b) r.new=y-(X%*%beta.hat.new+Zbh) (in the supposed new model)

which can be "onelined", of course... at the expense of clarity.
Computing deviance an logLik is trivial afterwards...

Two questions :
	a) What do you think ? Am I crazy like a fox ? (I wouldn't mind being
crazy like a Fox(*) ... :)
	b) Could such a trick be applied to *generalized* linear models ?
Computing the deviance from the residuals doesn't seem as easy as for
linear models...

Sincerely,

					Emmanuel Charpentier

(*) with apologies to John F, who has probably read|heard it a lot of
times... 

Le mardi 05 mai 2009 ? 09:37 +0200, Emmanuel Charpentier a ?crit :
> Dear list,
> 
> I'm trying to implement multiple imputations analysis of datasets with
> missing values for mixed models. My interest goes mainly to the fixed
> effects.
> 
> As you probably know, the principle of such an analysis is to impute
> "reasonable" values to missing data a few times (with "reasonable"
> variability), analyze these few completed datasets and pooling the
> analyses.
> 
> Schafer(1999) states simple methods for pooling estimates of the model
> and their variances. These methods can be applied to mixed models (with
> a few snags : you need to *ignore* the variation of random effects
> between imputed datasets beyond what is reflected in fixed effects' SE,
> you need to guesstimate the residuals DoF, which is something Douglas
> Bates has expressed grave doubts about). As it stands, these methods
> give results which, at first look, does not seem unreasonable, and might
> be used as a first approximation. More on this later.
> 
> My current goal is to build a function to build a "pooled test" for
> likelihood ratio of two models. Such a test has been proposed by Meng &
> Rubin (Biometrika, 1992), and, according to a presentation by RA
> Medeiros, has been implemented in Stata under the name milrtest.
> 
> I'm trying to implement such a pooled test in R. My snag is that the
> estimate is based on the estimation, for each imputed dataset, of the
> (log)likelihood ratio of each of these datasets under the hypotheses of
> the coefficients having precisely the values obtained in the coefficient
> pooling step.
> 
> So what I need is a (if possible elegant and/or fast) way to compute
> log-likelihood of a given dataset under a model (already built) under
> this hypothesis, up to a quantity supposed constant between models.
> 
> The logLik(model) function will happily give me LL(model|parameters
> giving makimum LL). What I need is something like logLik(model, coefs)
> giving me (up to an additive constant) LL(model|parameters=coefs).
> 
> Do you have any suggestions ? I can always sum squares of residuals
> recomputed under this alternative hypothesis, but I'm not quite sure
> that's enough for my purposes, especially if I plan to include the
> random effect estimates later...
> 
> 					Emmanuel Charpentier
>



From brant.inman at me.com  Wed May  6 05:00:04 2009
From: brant.inman at me.com (Brant Inman)
Date: Tue, 05 May 2009 23:00:04 -0400
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED with
	lmer
Message-ID: <663622AC-080A-4D7D-B218-A7B9CD0BA9EE@me.com>

R-experts:

In 2002, Hans Van Houwelingen et al. published a tutorial on how to do  
meta-regression in Statistics in Medicine.  They used the classic BCG  
dataset of Colditz to demonstrate correct methodology and computed the  
results using PROC MIXED in SAS. In trying to duplicate the results  
presented in this paper, I have discovered that I can reproduce  
certain items with lmer but not others.  I was hoping that someone  
might point out how I could correctly program R code to arrive at the  
correct solution.  I have placed the paper and the datasets used below  
at the following website for easy access to any helpers:  http://www.duke.edu/~bi6

I start by loading the data into R.

-----

bcg  	  <- read.csv('bcg.csv')
bcg.long  <- read.csv('bcg-long.csv')
bcg$study <- paste(bcg$author, bcg$year)

-----

I then perform standard meta-analysis using two different R functions:  
(1) the metabin function (meta package) to pool odds ratios with  
standard inverse variance techniques using the "wide" bcg dataset and  
(2) the lmer function (lme4 package) to perform a multilevel meta- 
analysis using the "long" dataset.  The only reason that the lmer  
function is possible here is because the outcome is binary  
(disease .vs. no disease) and I could create a long dataset.  A 3rd  
option is the mima function, but that is not presented here since I am  
interested in using lmer to extend to situations where there are study  
level (level 2) and individual level (level 1) predictors, something  
mima cannot currently handle.

-----

library(meta)
# Fixed and random effects models, no covariates
f0 <- metabin(bcg[,3], bcg[,4], bcg[,5], bcg[,6], sm='OR',  
method='Inverse')
	summary(f0)

library(lme4)
# Fixed effects model, no covariates
f1 <- lmer(tb ~ bcg + (1 | study), family=binomial, data=bcg.long)
	summary(f1)
	exp(fixef(f1)[2])				     	# OR
	exp(f1 at fixef[2] - (1.96*sqrt(vcov(f1)[2,2])))        	# lci
	exp(f1 at fixef[2] + (1.96*sqrt(vcov(f1)[2,2])))        	# uci

# Random effects model, no covariates.
f2 <- lmer(tb ~ bcg + (bcg | study), family=binomial,  
data=bcg.long)    # Random effects, no covariates
	summary(f2)
	exp(fixef(f2)[2])				        # OR
	exp(f2 at fixef[2] - (1.96*sqrt(vcov(f2)[2,2])))        	# lci
	exp(f2 at fixef[2] + (1.96*sqrt(vcov(f2)[2,2])))        	# uci
	as.numeric(summary(f2)@REmat[2,3])			# Tau

-----

So far these results look good and compare favorably to those obtained  
by Van Houwelingen. It is also obvious that although metabin and lmer  
give similar results, computational time is much longer with lmer than  
meta since it must use the long version of the dataset.  The problem  
comes when two covariates are added to model f2, latitude and year of  
publication.

-----

# Random effects model, 1 covariate
f3 <- lmer(tb ~ bcg + latitude + (bcg | study), family=binomial,  
data=bcg.long)
	summary(f3)
	exp(fixef(f3))				        # OR

# Random effects model, 1 covariate
f4 <- lmer(tb ~ bcg + year + (bcg | study), family=binomial,  
data=bcg.long)
	summary(f4)
	exp(fixef(f4))				        # OR


-----

I assumed, incorrectly, that models f3 and f4 would reproduce the  
results of Van Houwelingen in sections 5.2.1 and 5.2.2.  They do not  
seem to do so.  I would be very appreciative if someone pointed out my  
error with models f3 and f4 and why they do not seem to be correct.   
Incidentally, other sources (ex: Egger/Altman book on systematic  
reviews) report results on this dataset similar to Van Houwelingen, so  
I think that my code is definitely the problem.

Thanks,

Brant Inman



From r.turner at auckland.ac.nz  Wed May  6 05:43:23 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 6 May 2009 15:43:23 +1200
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED
	with lmer
In-Reply-To: <663622AC-080A-4D7D-B218-A7B9CD0BA9EE@me.com>
References: <663622AC-080A-4D7D-B218-A7B9CD0BA9EE@me.com>
Message-ID: <9150415E-C1BF-49CA-B38D-7433CBFFB844@auckland.ac.nz>


On 6/05/2009, at 3:00 PM, Brant Inman wrote:

> R-experts:
>
> In 2002, Hans Van Houwelingen et al. published a tutorial on how to do
> meta-regression in Statistics in Medicine.  They used the classic BCG
> dataset of Colditz to demonstrate correct methodology and computed the
> results using PROC MIXED in SAS. In trying to duplicate the results
> presented in this paper, I have discovered that I can reproduce
> certain items with lmer but not others.  I was hoping that someone
> might point out how I could correctly program R code to arrive at the
> correct solution.

	<snip>

There appears to be a tacit assertion here that the results from PROC
MIXED in The-Package-That-Must-Not-Be-Named are the correct results.

This assertion is very likely to bring the wrath of Doug Bates down
upon your head.  An outcome to be devoutly avoided! :-)

	cheers,

		Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From brant.inman at me.com  Wed May  6 12:43:45 2009
From: brant.inman at me.com (Brant Inman)
Date: Wed, 06 May 2009 06:43:45 -0400
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED
 with lmer
In-Reply-To: <9150415E-C1BF-49CA-B38D-7433CBFFB844@auckland.ac.nz>
References: <663622AC-080A-4D7D-B218-A7B9CD0BA9EE@me.com>
	<9150415E-C1BF-49CA-B38D-7433CBFFB844@auckland.ac.nz>
Message-ID: <73B9F011-427F-4B0B-8A6B-E3B530135FB7@me.com>

Rolf,

I actually don't believe that this is a SAS vs R issue since I have 3  
sources that report the same results.  I know that STATA, SAS and the  
mima function from R can all be used to give the correct results.  The  
question is related more to how I can get similar results with lmer.   
Currently, the code I provided generates VERY different results,  
especially related to between study variance estimation (tau) and  
regression coefficient standard errors. Basically, I think I got it  
all wrong in my coding of the models with covariates (f3 and f4), but  
I can't understand why.

Brant


On May 5, 2009, at 11:43 PM, Rolf Turner wrote:

>
> On 6/05/2009, at 3:00 PM, Brant Inman wrote:
>
>> R-experts:
>>
>> In 2002, Hans Van Houwelingen et al. published a tutorial on how to  
>> do
>> meta-regression in Statistics in Medicine.  They used the classic BCG
>> dataset of Colditz to demonstrate correct methodology and computed  
>> the
>> results using PROC MIXED in SAS. In trying to duplicate the results
>> presented in this paper, I have discovered that I can reproduce
>> certain items with lmer but not others.  I was hoping that someone
>> might point out how I could correctly program R code to arrive at the
>> correct solution.
>
> 	<snip>
>
> There appears to be a tacit assertion here that the results from PROC
> MIXED in The-Package-That-Must-Not-Be-Named are the correct results.
>
> This assertion is very likely to bring the wrath of Doug Bates down
> upon your head.  An outcome to be devoutly avoided! :-)
>
> 	cheers,
>
> 		Rolf Turner
>
> ######################################################################
> Attention: This e-mail message is privileged and confidential. If  
> you are not the intended recipient please delete the message and  
> notify the sender. Any views or opinions presented are solely those  
> of the author.
>
> This e-mail has been scanned and cleared by MailMarshal www.marshalsoftware.com
> ######################################################################



From ken at kjbeath.com.au  Wed May  6 14:02:57 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 6 May 2009 22:02:57 +1000
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED
	with lmer
In-Reply-To: <73B9F011-427F-4B0B-8A6B-E3B530135FB7@me.com>
References: <663622AC-080A-4D7D-B218-A7B9CD0BA9EE@me.com>
	<9150415E-C1BF-49CA-B38D-7433CBFFB844@auckland.ac.nz>
	<73B9F011-427F-4B0B-8A6B-E3B530135FB7@me.com>
Message-ID: <E833356F-8F89-4826-889C-299519790B11@kjbeath.com.au>

On 06/05/2009, at 8:43 PM, Brant Inman wrote:

> Rolf,
>
> I actually don't believe that this is a SAS vs R issue since I have  
> 3 sources that report the same results.  I know that STATA, SAS and  
> the mima function from R can all be used to give the correct  
> results.  The question is related more to how I can get similar  
> results with lmer.  Currently, the code I provided generates VERY  
> different results, especially related to between study variance  
> estimation (tau) and regression coefficient standard errors.  
> Basically, I think I got it all wrong in my coding of the models  
> with covariates (f3 and f4), but I can't understand why.
>
> Brant


This is closer but maybe not quite equivalent. It also avoids using  
the huge data file.

Ken

bcg <- read.csv("bcg.csv")
bcg$study <- paste(bcg$author, bcg$year)

# this is a bit messy but requires almost no thought
bcgnames <- bcg[,c(1,2,7:10)]
bcgvacc <- bcg[,3:4]
names(bcgvacc) <- c("tb","n")
bcgnovacc <- bcg[,5:6]
names(bcgnovacc) <- c("tb","n")

newbcg <- cbind(rbind(bcgnames,bcgnames),rbind(bcgvacc,bcgnovacc))
newbcg$bcg <- factor(rep(c("yes","no"),each=13))
newbcg$notb <- newbcg$n-newbcg$tb

newbcg$latitude <- newbcg$latitude-mean(newbcg$latitude)
newbcg$year <- newbcg$year-mean(newbcg$year)

library(meta)
# Fixed and random effects models, no covariates
f0 <- metabin(bcg[,3], bcg[,4], bcg[,5], bcg[,6], sm='OR',  
method='Inverse')
	summary(f0)

library(lme4)
# Fixed effects model, no covariates
f1 <- lmer(cbind(tb,notb) ~ bcg + (1 | study), family=binomial,  
data=newbcg)
	summary(f1)
	exp(fixef(f1)[2]) # OR
	exp(f1 at fixef[2] - (1.96*sqrt(vcov(f1)[2,2]))) # lci
	exp(f1 at fixef[2] + (1.96*sqrt(vcov(f1)[2,2])))  # uci

# Random effects model, no covariates.
f2 <- lmer(cbind(tb,notb) ~ bcg + (bcg | study), family=binomial,  
data=newbcg) # Random effects, no covariates
	summary(f2)
	exp(fixef(f2)[2]) # OR
	exp(f2 at fixef[2] - (1.96*sqrt(vcov(f2)[2,2]))) # lci
	exp(f2 at fixef[2] + (1.96*sqrt(vcov(f2)[2,2]))) # uci
	as.numeric(summary(f2)@REmat[2,3]) # Tau

# Random effects model, 1 covariate
f3 <- lmer(cbind(tb,notb) ~ latitude*bcg + (bcg | study),  
family=binomial, data=newbcg)
	summary(f3)
	exp(fixef(f3)) # OR

# Random effects model, 1 covariate
f4 <- lmer(cbind(tb,notb) ~ latitude*bcg + year*bcg + (bcg | study),  
family=binomial, data=newbcg)
	summary(f4)
	exp(fixef(f4)) # OR



From jloehrke at umassd.edu  Wed May  6 14:17:17 2009
From: jloehrke at umassd.edu (Jon Loehrke)
Date: Wed, 6 May 2009 08:17:17 -0400
Subject: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
Message-ID: <6CE77016-8CDC-40B4-A770-017F65E2D84F@umassd.edu>

Hi Mixed Modelers,

	I have  been using gls() to run some AR[2] models and occasionally  
receive the following error:

gls(Y~x1 + x2 + x3 + x4 + x5 + x6, data=na.omit(herrdata),  method  
='ML',corr=corARMA(p = 2, q = 0))

	Error in `coef<-.corARMA`(`*tmp*`, value = c(7.49067599726739,  
-15.2313908862033 :
   		Coefficient matrix not invertible

	I do not understand the problem enough to create a dataset and post  
an example.  However, I have established
a few things:

	if I use method='REML' then the error goes away
	if I reduce the number of parameters, the error goes away
	if I utilize an AR[1] correlation structure, the error goes away

	Would it be possible for somebody to explain this error to me?

Thank you very much, Jon

sessionInfo()
R version 2.8.1 Patched (2009-01-19 r47650)
i386-apple-darwin9.6.0

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets   
methods   base

other attached packages:
[1] nlme_3.1-90        car_1.2-9          xtable_1.5-4        
MASS_7.2-45        RColorBrewer_1.0-2 lattice_0.17-20     
reshape_0.8.2      plyr_0.1.3


Jon Loehrke
Graduate Research Assistant
Department of Fisheries Oceanography
School for Marine Science and Technology
University of Massachusetts
200 Mill Road, Suite 325
Fairhaven, MA 02719
jloehrke at umassd.edu



From Kate.Pressland at bristol.ac.uk  Wed May  6 20:18:01 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Wed, 06 May 2009 19:18:01 +0100
Subject: [R-sig-ME] Modelling random effects with SITE, YEAR and SPECIES
In-Reply-To: <49F8CD83.2040508@ufl.edu>
References: <580180.24575.qm@web34801.mail.mud.yahoo.com>
	<49F8CD83.2040508@ufl.edu>
Message-ID: <F241E78F7342007C9A159228@bio-mammal03.bio.bris.ac.uk>

How can you work out how A, B or C affect SPECIES? By this I mean, could 
you find out how species n is affected by A, B and C in the correlation 
output? Or would you need to adjust the response to look at individual 
species separately?

--On 29 April 2009 17:58 -0400 Ben Bolker <bolker at ufl.edu> wrote:

> David R. wrote:
>> Hello all,
>>
>> First, sorry for the english and the basic questions. I'm using mixed
>> models (lme4 package) to analyse variability in 13 SPECIES of birds
>> observed during 15 YEARS across 5 SITES. All the SPECIES were
>> observed in all the sites in most years.
>>
>> My fixed effects are A, B, C and Year. I'm interested in the
>> stochastic effect of A, B and C on the dependent variable, but also
>> in a possible linear trend of the dependent variable over time.
>>
>> My random effects are SPECIES, YEAR and SITE, to control for the
>> effects of nonindependence.
>>
>> I have a model with SITE, YEAR and SPECIES as crossed random effects
>> like A + B + C + Year + (1|SITE) + (1|YEAR) + (1|SPECIES).
>>
>> My questions are:
>>
>> 1) Is this model correct? It is correct to model YEAR both as random
>> effect and fixed effect? Is there the possibility that the variance
>> accounted for by the random effect could robbing year as a fixed
>> effect of explanatory power?
>
>   Seems OK and sensible to me.
>   I would guess that the linear trend and the random variation are
> sufficiently different patterns that they would not conflict too badly,
> but you could try the different nested models and see what happens ...
>
>>
>> 2) It is meaningful, instead,  to model YEAR as repeated measure, if
>> the experimental unit were species within sites?
>
>   "Modeling YEAR as a random effect" and "Modeling YEAR as a repeated
> measure" are, in my opinion, almost the same thing (but I'm ready to be
> corrected, as always).  The only aspect of "repeated measures" that
> would be different would be if you wanted to fit an autoregressive model
> so that samples closer together in time were more correlated (which you
> can't do with lmer at this
> point).
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
Kate Pressland
Office D95
School of Biological Sciences
University of Bristol
Woodland Road
Bristol, BS8 1UG
Tel: 0117 9288918 (Internal 88918)
Kate.Pressland at bristol.ac.uk
www.bio.bris.ac.uk/people/staff.cfm?key=1137



From harlancampbell at gmail.com  Wed May  6 20:19:00 2009
From: harlancampbell at gmail.com (H c)
Date: Wed, 6 May 2009 14:19:00 -0400
Subject: [R-sig-ME] NLMINB() produces NaN!
Message-ID: <222824550905061119h15a84dc7vbfb49f8354f27c1d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090506/a3b01442/attachment.pl>

From RVaradhan at jhmi.edu  Wed May  6 20:59:14 2009
From: RVaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 6 May 2009 14:59:14 -0400
Subject: [R-sig-ME] [R] NLMINB() produces NaN!
In-Reply-To: <222824550905061119h15a84dc7vbfb49f8354f27c1d@mail.gmail.com>
References: <222824550905061119h15a84dc7vbfb49f8354f27c1d@mail.gmail.com>
Message-ID: <002601c9ce7c$bfb75720$7c94100a@win.ad.jhu.edu>

Hi,

Can you provide a little more information about your problem?

If you are trying to find a local maximum of "maxphi", then you need to tell
that to optim(),.  It tries to find a local minimum by default.  You can do
this via the `fnscale' control parameter (control = list(fnscale = -1)).

If this still does not work, try the function spg() in the "BB" package.

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of H c
Sent: Wednesday, May 06, 2009 2:19 PM
To: r-sig-mixed-models at r-project.org; r-help at r-project.org
Subject: [R] NLMINB() produces NaN!

I am having the same problem as one Rebecca Sela(see bellow).


On 21/12/2007 12:07 AM, Rebecca Sela wrote:
>* I am trying to optimize a likelihood function using NLMINB.  After 
>running without a problem for quite a few iterations (enough that my 
>intermediate output extends further than I can scroll back), it tries a 
>vector of parameter values NaN.  This has happened with multiple Monte 
>Carlo datasets, and a few different (but very similar) likelihood 
>functions.  (They are complicated, but I can send them to someone if 
>desired.)*

Instead I try to use optim() for my optimization needs but it fails when
finding the 0/0:

"

Error in optim(c(phi[, k]), maxphi, lower = 0.01, upper = 0.99, method =
"L-BFGS-B") :
  L-BFGS-B needs finite values of 'fn'
In addition: There were 50 or more warnings (use warnings() to see the first
50)

"


Any suggestions?

Harlan Campbell

McGIll University

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From harlancampbell at gmail.com  Wed May  6 22:08:12 2009
From: harlancampbell at gmail.com (H c)
Date: Wed, 6 May 2009 16:08:12 -0400
Subject: [R-sig-ME] Using weights=varFixed(~(1/w^2)) to weigh observations
	in lme.
Message-ID: <222824550905061308n196aa745v4a57bb2a99394fe0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090506/fb11e2c8/attachment.pl>

From ken at kjbeath.com.au  Thu May  7 01:31:25 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 6 May 2009 23:31:25 -0000 (GMT)
Subject: [R-sig-ME] NLMINB() produces NaN!
In-Reply-To: <222824550905061119h15a84dc7vbfb49f8354f27c1d@mail.gmail.com>
References: <222824550905061119h15a84dc7vbfb49f8354f27c1d@mail.gmail.com>
Message-ID: <1502.137.111.57.71.1241652685.squirrel@65.99.229.10>

On Wed, May 6, 2009 6:19 pm, H c wrote:
> I am having the same problem as one Rebecca Sela(see bellow).
>
>
> On 21/12/2007 12:07 AM, Rebecca Sela wrote:
>>* I am trying to optimize a likelihood function using NLMINB.  After
>> running without a problem for quite a few iterations (enough that my
>> intermediate output extends further than I can scroll back), it tries a
>> vector of parameter values NaN.  This has happened with multiple Monte
>> Carlo datasets, and a few different (but very similar) likelihood
>> functions.  (They are complicated, but I can send them to someone if
>> desired.)*
>
> Instead I try to use optim() for my optimization needs but it fails
> when finding the 0/0:
>
> "
>
> Error in optim(c(phi[, k]), maxphi, lower = 0.01, upper = 0.99, method
> = "L-BFGS-B") :
>   L-BFGS-B needs finite values of 'fn'
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
>
> "
>
>
> Any suggestions?

I think you have a different problem to the original poster.

It looks like your function cannot be calculated for some values that
optim passes to it. This can easily happen. Some optimisers (eg nlm) seem
to cope with this, but produce lots of annoying warnings. My solution is
to check at the end of the likelihood function for finite or NAN and
replace with the maximum real value. eg

if (is.nan(ll) || is.infinite(ll)) ll <- .Machine$double.xmax

Ken



From doon75 at hotmail.com  Thu May  7 02:33:18 2009
From: doon75 at hotmail.com (Darren Norris)
Date: Wed, 06 May 2009 20:33:18 -0400
Subject: [R-sig-ME] how to specify priors in MCMCglmm?
Message-ID: <BLU0-SMTP42BA261008392A2293B77EC7670@phx.gbl>

Dear all,

I would like to know how to specify priors for a MCMCglmm model with a 
binary response. I have read the help (?MCMCglmm) and searched the best 
I can through nabble R and this list.
Unfortunately if the answer is there I am too stupid to understand it.

>From the MCMCglmm tutorial I see how to code a univariate version - but 
then I get lost about how to extend the prior specification to more 
complex models.
I also do no understand the prior terminology or how / why to specify what I 
need -  so if at all possible I need an idiots guide how to specify the 
priors.

I work for a conservation NGO and unfortunately we're not affiliated 
with an academic institution so don't have access to books or journal 
articles or any academic statistical support.
Any guidance would be much appreciated.
Many thanks,
Darren

R version 2.8.1 (2008-12-22) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] MCMCglmm_1.09      gtools_2.5.0       combinat_0.0-6     orthopolynom_1.0-1 polynom_1.3-4      pscl_1.03         
 [7] mvtnorm_0.9-4      ape_2.2-3          coda_0.13-4        Matrix_0.999375-18 lattice_0.17-17    tensorA_0.31      
[13] corpcor_1.5.2      MASS_7.2-45       

loaded via a namespace (and not attached):
[1] gee_4.13-13 grid_2.8.1  nlme_3.1-89


#make the data frame- using "sample" so data is not the same but the 
important difference is between probability of events in "cD" and the 
other two ("aD" and "bD")
# we coducted the work in 3 different places, each place has 3 habitat 
types.
#Each habitat type has 2 groups of samples (3 samples per group) each 
group in a habitat has a different type of  bait.
#I am trying to model how the occurence of events was influenced by 
habitat and bait. We checked samples repeatedly (atime).
#Specifying atime and agroup as random effects to deal with potential 
pseudo replication.

aD<-sample(0:1,108,replace="True",prob=c(0.6,0.4));
bD<-sample(0:1,108,replace="True",prob=c(0.6,0.4));
cD<-rep(0,108);
aevent<-c(aD,bD,cD);
aplace<-rep(c(8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10),9);
ahabitat<-c(rep(1,108),rep(2,108),rep(3,108));
atime<-rep(c(0,1,2,4,8,24),54);
abait<-rep(c(1,1,1,1,1,1,2,2,2,2,2,2),27);
agroup<-paste(aplace,ahabitat,abait);
MyDf<-data.frame(aplace,agroup,aevent,ahabitat,atime,abait)

#-using prior code examples from the MCMCglmm tutorial (section 1.2: 
produced April 17 2009), but priors are not right.
library(MCMCglmm);
prior = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V = 1,n 
= 0)));
MMCMm1 <- MCMCglmm(aevent ~ as.factor(ahabitat), random = ~agroup, 
family = "categorical",prior=prior,data = MyDf, verbose = FALSE)


# I would like to specify, but don't know how to specify priors:
MMCMm2 <- MCMCglmm(aevent ~ as.factor(ahabitat)*as.factor(bait), random 
= ~agroup + atime, family = "categorical",prior=prior,data = MyDf, 
verbose = FALSE)



From brant.inman at me.com  Thu May  7 05:00:38 2009
From: brant.inman at me.com (Brant Inman)
Date: Wed, 06 May 2009 23:00:38 -0400
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED
 with lmer
In-Reply-To: <E833356F-8F89-4826-889C-299519790B11@kjbeath.com.au>
References: <663622AC-080A-4D7D-B218-A7B9CD0BA9EE@me.com>
	<9150415E-C1BF-49CA-B38D-7433CBFFB844@auckland.ac.nz>
	<73B9F011-427F-4B0B-8A6B-E3B530135FB7@me.com>
	<E833356F-8F89-4826-889C-299519790B11@kjbeath.com.au>
Message-ID: <AC4585DE-F2BF-4C43-AE7B-14AF13877CBC@me.com>

Ken,

Thanks very much for the great advice.  You essentially suggest the  
following:

1) Add interaction term b/t covariates and treatment arm variable
2) Center continuous covariates
3) Use a wide dataset (improves computation time dramatically over a  
long dataset)

The estimates obtained with your method would seem at first glance to  
compare favorably with the published results.  However, on closer  
analysis I wonder if the interpretation of your model is the same as  
Van Houwelingen's.




YOUR MODEL, WHERE YEAR AND LATITUDE ARE ACTUALLY CENTERED VARIABLES

Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ bcg * latitude + bcg * year + (bcg | study)
    Data: newbcg
    AIC   BIC logLik deviance
  105.6 116.9  -43.8     87.6
Random effects:
  Groups Name        Variance   Std.Dev. Corr
  study  (Intercept) 0.60620909 0.778594
         bcgyes      0.00045554 0.021343 1.000
Number of obs: 26, groups: study, 13

Fixed effects:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)     -4.116305   0.221649 -18.571  < 2e-16 ***
bcgyes          -0.733330   0.049815 -14.721  < 2e-16 ***
latitude         0.024016   0.021007   1.143  0.25294
year            -0.099948   0.027955  -3.575  0.00035 ***
bcgyes:latitude -0.034332   0.003991  -8.601  < 2e-16 ***
bcgyes:year     -0.001489   0.005811  -0.256  0.79781
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?  
0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) bcgyes latitd year   bcgys:l
bcgyes       0.046
latitude    -0.004  0.006
year        -0.015  0.014  0.658
bcgyes:lttd  0.002  0.156  0.088  0.059
bcgyes:year  0.020 -0.234  0.049  0.078  0.706


VAN HOUWELINGEN's MODEL RESULTS (I BELIEVE THAT HE DID NOT CENTER THE  
VARIABLES):

5.2.4. Regression on latitude and year. When both covariates latitude  
and year are put into
the model, the residual between-study variance becomes only 0.002,  
corresponding with an
explained variance of 99.3 per cent, only slightly more than by  
latitude alone. The regression
coe??cients for the intercept, latitude and year are, respectively,  
0.494 (standard error = 0:529),
?0:034 (standard error = 0:004) and ?0:001 (standard error = 0:006).



After taking into account centering, do you believe that your  
regression equation is interpreted in the same way as his?

Brant




On May 6, 2009, at 8:02 AM, Ken Beath wrote:

> On 06/05/2009, at 8:43 PM, Brant Inman wrote:
>
>> Rolf,
>>
>> I actually don't believe that this is a SAS vs R issue since I have  
>> 3 sources that report the same results.  I know that STATA, SAS and  
>> the mima function from R can all be used to give the correct  
>> results.  The question is related more to how I can get similar  
>> results with lmer.  Currently, the code I provided generates VERY  
>> different results, especially related to between study variance  
>> estimation (tau) and regression coefficient standard errors.  
>> Basically, I think I got it all wrong in my coding of the models  
>> with covariates (f3 and f4), but I can't understand why.
>>
>> Brant
>
>
> This is closer but maybe not quite equivalent. It also avoids using  
> the huge data file.
>
> Ken
>
> bcg <- read.csv("bcg.csv")
> bcg$study <- paste(bcg$author, bcg$year)
>
> # this is a bit messy but requires almost no thought
> bcgnames <- bcg[,c(1,2,7:10)]
> bcgvacc <- bcg[,3:4]
> names(bcgvacc) <- c("tb","n")
> bcgnovacc <- bcg[,5:6]
> names(bcgnovacc) <- c("tb","n")
>
> newbcg <- cbind(rbind(bcgnames,bcgnames),rbind(bcgvacc,bcgnovacc))
> newbcg$bcg <- factor(rep(c("yes","no"),each=13))
> newbcg$notb <- newbcg$n-newbcg$tb
>
> newbcg$latitude <- newbcg$latitude-mean(newbcg$latitude)
> newbcg$year <- newbcg$year-mean(newbcg$year)
>
> library(meta)
> # Fixed and random effects models, no covariates
> f0 <- metabin(bcg[,3], bcg[,4], bcg[,5], bcg[,6], sm='OR',  
> method='Inverse')
> 	summary(f0)
>
> library(lme4)
> # Fixed effects model, no covariates
> f1 <- lmer(cbind(tb,notb) ~ bcg + (1 | study), family=binomial,  
> data=newbcg)
> 	summary(f1)
> 	exp(fixef(f1)[2]) # OR
> 	exp(f1 at fixef[2] - (1.96*sqrt(vcov(f1)[2,2]))) # lci
> 	exp(f1 at fixef[2] + (1.96*sqrt(vcov(f1)[2,2])))  # uci
>
> # Random effects model, no covariates.
> f2 <- lmer(cbind(tb,notb) ~ bcg + (bcg | study), family=binomial,  
> data=newbcg) # Random effects, no covariates
> 	summary(f2)
> 	exp(fixef(f2)[2]) # OR
> 	exp(f2 at fixef[2] - (1.96*sqrt(vcov(f2)[2,2]))) # lci
> 	exp(f2 at fixef[2] + (1.96*sqrt(vcov(f2)[2,2]))) # uci
> 	as.numeric(summary(f2)@REmat[2,3]) # Tau
>
> # Random effects model, 1 covariate
> f3 <- lmer(cbind(tb,notb) ~ latitude*bcg + (bcg | study),  
> family=binomial, data=newbcg)
> 	summary(f3)
> 	exp(fixef(f3)) # OR
>
> # Random effects model, 1 covariate
> f4 <- lmer(cbind(tb,notb) ~ latitude*bcg + year*bcg + (bcg | study),  
> family=binomial, data=newbcg)
> 	summary(f4)
> 	exp(fixef(f4)) # OR
>



From Thierry.ONKELINX at inbo.be  Thu May  7 10:16:11 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 7 May 2009 10:16:11 +0200
Subject: [R-sig-ME] Modelling random effects with SITE, YEAR and SPECIES
In-Reply-To: <F241E78F7342007C9A159228@bio-mammal03.bio.bris.ac.uk>
References: <580180.24575.qm@web34801.mail.mud.yahoo.com><49F8CD83.2040508@ufl.edu>
	<F241E78F7342007C9A159228@bio-mammal03.bio.bris.ac.uk>
Message-ID: <2E9C414912813E4EB981326983E0A104067422AB@inboexch.inbo.be>

Dear Kate,

Adding SPECIES as a random effect indicates that you want to take the
effect of SPECIES into account but not need to know the effect of the
individual SPECIES. If you do want to know that effect then you have to
add species to fixed effects. Examining the effect of A, B and C on
species (as a fixed effect) requires interactions between them. The
model then looks like (A + B + C) * SPECIES + Year + (1|SITE) + (1|YEAR)
This will only work if you have sufficiend data.

Another option is to keep species as a random effect and add random
slopes according to A, B and C. This will allow a different effect of A,
B anc C for each species. The model would look like A + B + C + Year +
(1|SITE) + (1|YEAR) + (A + B + C|SPECIES)

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens CL Pressland
Verzonden: woensdag 6 mei 2009 20:18
Aan: R Mixed Models
Onderwerp: Re: [R-sig-ME] Modelling random effects with SITE, YEAR and
SPECIES

How can you work out how A, B or C affect SPECIES? By this I mean, could

you find out how species n is affected by A, B and C in the correlation 
output? Or would you need to adjust the response to look at individual 
species separately?

--On 29 April 2009 17:58 -0400 Ben Bolker <bolker at ufl.edu> wrote:

> David R. wrote:
>> Hello all,
>>
>> First, sorry for the english and the basic questions. I'm using mixed
>> models (lme4 package) to analyse variability in 13 SPECIES of birds
>> observed during 15 YEARS across 5 SITES. All the SPECIES were
>> observed in all the sites in most years.
>>
>> My fixed effects are A, B, C and Year. I'm interested in the
>> stochastic effect of A, B and C on the dependent variable, but also
>> in a possible linear trend of the dependent variable over time.
>>
>> My random effects are SPECIES, YEAR and SITE, to control for the
>> effects of nonindependence.
>>
>> I have a model with SITE, YEAR and SPECIES as crossed random effects
>> like A + B + C + Year + (1|SITE) + (1|YEAR) + (1|SPECIES).
>>
>> My questions are:
>>
>> 1) Is this model correct? It is correct to model YEAR both as random
>> effect and fixed effect? Is there the possibility that the variance
>> accounted for by the random effect could robbing year as a fixed
>> effect of explanatory power?
>
>   Seems OK and sensible to me.
>   I would guess that the linear trend and the random variation are
> sufficiently different patterns that they would not conflict too
badly,
> but you could try the different nested models and see what happens ...
>
>>
>> 2) It is meaningful, instead,  to model YEAR as repeated measure, if
>> the experimental unit were species within sites?
>
>   "Modeling YEAR as a random effect" and "Modeling YEAR as a repeated
> measure" are, in my opinion, almost the same thing (but I'm ready to
be
> corrected, as always).  The only aspect of "repeated measures" that
> would be different would be if you wanted to fit an autoregressive
model
> so that samples closer together in time were more correlated (which
you
> can't do with lmer at this
> point).
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
Kate Pressland
Office D95
School of Biological Sciences
University of Bristol
Woodland Road
Bristol, BS8 1UG
Tel: 0117 9288918 (Internal 88918)
Kate.Pressland at bristol.ac.uk
www.bio.bris.ac.uk/people/staff.cfm?key=1137

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Thierry.ONKELINX at inbo.be  Thu May  7 10:38:54 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 7 May 2009 10:38:54 +0200
Subject: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
In-Reply-To: <6CE77016-8CDC-40B4-A770-017F65E2D84F@umassd.edu>
References: <6CE77016-8CDC-40B4-A770-017F65E2D84F@umassd.edu>
Message-ID: <2E9C414912813E4EB981326983E0A104067422D5@inboexch.inbo.be>

Dear Jon,

It seems to me like you are trying to fit a model that is too complex
for your dataset. Are you sure you have enough data? Furthermore I think
you have not specified the variable which indicates time. I am not sure
which variable is used by default.

HTH,

Thierry 


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Jon Loehrke
Verzonden: woensdag 6 mei 2009 14:17
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]

Hi Mixed Modelers,

	I have  been using gls() to run some AR[2] models and
occasionally  
receive the following error:

gls(Y~x1 + x2 + x3 + x4 + x5 + x6, data=na.omit(herrdata),  method  
='ML',corr=corARMA(p = 2, q = 0))

	Error in `coef<-.corARMA`(`*tmp*`, value = c(7.49067599726739,  
-15.2313908862033 :
   		Coefficient matrix not invertible

	I do not understand the problem enough to create a dataset and
post  
an example.  However, I have established
a few things:

	if I use method='REML' then the error goes away
	if I reduce the number of parameters, the error goes away
	if I utilize an AR[1] correlation structure, the error goes away

	Would it be possible for somebody to explain this error to me?

Thank you very much, Jon

sessionInfo()
R version 2.8.1 Patched (2009-01-19 r47650)
i386-apple-darwin9.6.0

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets   
methods   base

other attached packages:
[1] nlme_3.1-90        car_1.2-9          xtable_1.5-4        
MASS_7.2-45        RColorBrewer_1.0-2 lattice_0.17-20     
reshape_0.8.2      plyr_0.1.3


Jon Loehrke
Graduate Research Assistant
Department of Fisheries Oceanography
School for Marine Science and Technology
University of Massachusetts
200 Mill Road, Suite 325
Fairhaven, MA 02719
jloehrke at umassd.edu

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From gpbaitelli46 at gmail.com  Thu May  7 10:29:19 2009
From: gpbaitelli46 at gmail.com (giovanni parrinello)
Date: Thu, 7 May 2009 09:29:19 +0100
Subject: [R-sig-ME] two or three problems with lme(Augpred and predict.lme)
Message-ID: <1f01006a0905070129l29ee0d45wd296a5d31d2d28cf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090507/6646133f/attachment.pl>

From Wolfgang.Viechtbauer at STAT.unimaas.nl  Thu May  7 16:39:16 2009
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 7 May 2009 16:39:16 +0200
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED
	with lmer
In-Reply-To: <AC4585DE-F2BF-4C43-AE7B-14AF13877CBC@me.com>
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF0EB9426D@um-mail0136.unimaas.nl>

I have not followed the discussion fully, but I have a hunch that may be useful to examine. 

Suppose you want to meta-analyze k 2x2 table data using the odds ratio as the outcome measure. One approach is to calculate the log odds ratio with the corresponding sampling variances (or to be precise: estimates thereof) for those k tables and apply one of the usual meta-analytic models. Moderators can be added and van Houwelingen, Arends, and Stijnen (2002) nicely demonstrate how those types of models can be fitted with SAS.

An alternative approach is not to rely on the normal approximation and instead formulate a logistic regression model. An "equivalent" fixed-effects model then should include *dummy variables for the k tables* and a dummy variable for the group variable (e.g., bcg vaccinated = 1; not bcg vaccinated = 0). A constant term should also be in the model. If you want to add a moderator variable to this model, then one should add *the interaction between the group variable and the moderator variable* to the model (but NOT the main effect for the moderator variable, since then the model would be overparameterized).

If one wants a random-effects model, one should STILL add the *dummy variables for the k tables* and the dummy variable for the group variable, plus a random effect along with that group dummy variable (so that we get a random treatment effect). Again, moderators are included via an interaction term between the moderator variable and the group variable.

These could be considered the "equivalent" models to the usual meta-anaytic fixed-, random-, and mixed-effects models. 

As far as I can tell, Brant, there are no dummies in your model for the tables. Give that a try. And then, when you throw in moderators, just include the interaction between the moderator and the bcg variable. I'll be interested in what you find!

Best,

-- 
Wolfgang Viechtbauer
?Department of Methodology and Statistics
?University of Maastricht, The Netherlands
?http://www.wvbauer.com/



From j.hadfield at ed.ac.uk  Thu May  7 18:03:46 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 7 May 2009 17:03:46 +0100
Subject: [R-sig-ME] how to specify priors in MCMCglmm?
In-Reply-To: <BLU0-SMTP42BA261008392A2293B77EC7670@phx.gbl>
References: <BLU0-SMTP42BA261008392A2293B77EC7670@phx.gbl>
Message-ID: <07086505-7492-41C7-B2FD-EB5521E7619E@ed.ac.uk>

Hi Darren,

The prior you specified for the first model has the correct form:

prior = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V =  
1,n = 0)))

However, the prior is improper because n=0. This does not matter for  
the residual variance because it is fixed at 1 (V=1), but for the  
group variance it does matter. The posterior is tending to zero where  
two things may happen. It can get trapped at low values and give odd  
looking traces, or it can reach very low values at which point it will  
be picked up during matrix inversion and you'll get the error message  
" ill-conditioned G/R structure". If you make the prior proper the  
posterior is guaranteed to be proper also. In this case n=1 is enough  
to ensure propriety, and the chain should not get trapped at zero.   
You ca use higher n but this means the prior will be more informative.  
For more general models where V is a matrix (rather than a scalar)   
n>=dim(V) to ensure propriety.

For the second model you need to add an additional prior element in  
the G-structure because of the additional term (+atime). Something like

prior2 = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V =  
1,n = 1), G2 = list(V = 1,n = 1)))

but a more sensible value for V (or a check on the sensitivity to  
different choices of V) would be recommended.

Hope this helps,

Jarrod


On 7 May 2009, at 01:33, Darren Norris wrote:

> Dear all,
>
> I would like to know how to specify priors for a MCMCglmm model with  
> a binary response. I have read the help (?MCMCglmm) and searched the  
> best I can through nabble R and this list.
> Unfortunately if the answer is there I am too stupid to understand it.
>
>> From the MCMCglmm tutorial I see how to code a univariate version -  
>> but
> then I get lost about how to extend the prior specification to more  
> complex models.
> I also do no understand the prior terminology or how / why to  
> specify what I need -  so if at all possible I need an idiots guide  
> how to specify the priors.
>
> I work for a conservation NGO and unfortunately we're not affiliated  
> with an academic institution so don't have access to books or  
> journal articles or any academic statistical support.
> Any guidance would be much appreciated.
> Many thanks,
> Darren
>
> R version 2.8.1 (2008-12-22) i386-pc-mingw32
> locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United  
> Kingdom.1252;LC_MONETARY=English_United Kingdom. 
> 1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> other attached packages:
> [1] MCMCglmm_1.09      gtools_2.5.0       combinat_0.0-6      
> orthopolynom_1.0-1 polynom_1.3-4      pscl_1.03         [7]  
> mvtnorm_0.9-4      ape_2.2-3          coda_0.13-4         
> Matrix_0.999375-18 lattice_0.17-17    tensorA_0.31      [13]  
> corpcor_1.5.2      MASS_7.2-45
> loaded via a namespace (and not attached):
> [1] gee_4.13-13 grid_2.8.1  nlme_3.1-89
>
>
> #make the data frame- using "sample" so data is not the same but the  
> important difference is between probability of events in "cD" and  
> the other two ("aD" and "bD")
> # we coducted the work in 3 different places, each place has 3  
> habitat types.
> #Each habitat type has 2 groups of samples (3 samples per group)  
> each group in a habitat has a different type of  bait.
> #I am trying to model how the occurence of events was influenced by  
> habitat and bait. We checked samples repeatedly (atime).
> #Specifying atime and agroup as random effects to deal with  
> potential pseudo replication.
>
> aD<-sample(0:1,108,replace="True",prob=c(0.6,0.4));
> bD<-sample(0:1,108,replace="True",prob=c(0.6,0.4));
> cD<-rep(0,108);
> aevent<-c(aD,bD,cD);
> aplace<-rep(c(8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10),9);
> ahabitat<-c(rep(1,108),rep(2,108),rep(3,108));
> atime<-rep(c(0,1,2,4,8,24),54);
> abait<-rep(c(1,1,1,1,1,1,2,2,2,2,2,2),27);
> agroup<-paste(aplace,ahabitat,abait);
> MyDf<-data.frame(aplace,agroup,aevent,ahabitat,atime,abait)
>
> #-using prior code examples from the MCMCglmm tutorial (section 1.2:  
> produced April 17 2009), but priors are not right.
> library(MCMCglmm);
> prior = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V =  
> 1,n = 0)));
> MMCMm1 <- MCMCglmm(aevent ~ as.factor(ahabitat), random = ~agroup,  
> family = "categorical",prior=prior,data = MyDf, verbose = FALSE)
>
>
> # I would like to specify, but don't know how to specify priors:
> MMCMm2 <- MCMCglmm(aevent ~ as.factor(ahabitat)*as.factor(bait),  
> random = ~agroup + atime, family = "categorical",prior=prior,data =  
> MyDf, verbose = FALSE)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From lborger at uoguelph.ca  Thu May  7 19:35:18 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 7 May 2009 13:35:18 -0400
Subject: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
References: <6CE77016-8CDC-40B4-A770-017F65E2D84F@umassd.edu>
	<2E9C414912813E4EB981326983E0A104067422D5@inboexch.inbo.be>
Message-ID: <3937D6AA05504F34BAE3B5394BAE2B18@lborger>

Hello,

> you have not specified the variable which indicates time. I am not sure
> which variable is used by default.


If I understand correctly, if the position variable is not defined (form 
=~1) the within-group order of the positions is used by default (P&B 2000 
p.236).

HTH

Cheers,

Luca

---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1

office +1 519 824 4120 ext. 52975
lab     +1 519 824 4120 ext. 53594
fax:     +1 519 767 1656

email: lborger at uoguelph.ca
www.researcherid.com/rid/C-6003-2008
http://uoguelph.academia.edu/LucaBorger



----- Original Message ----- 
From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
To: "Jon Loehrke" <jloehrke at umassd.edu>; <r-sig-mixed-models at r-project.org>
Sent: Thursday, May 07, 2009 4:38 AM
Subject: Re: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]


> Dear Jon,
>
> It seems to me like you are trying to fit a model that is too complex
> for your dataset. Are you sure you have enough data? Furthermore I think
> you have not specified the variable which indicates time. I am not sure
> which variable is used by default.
>
> HTH,
>
> Thierry
>
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Jon Loehrke
> Verzonden: woensdag 6 mei 2009 14:17
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
>
> Hi Mixed Modelers,
>
> I have  been using gls() to run some AR[2] models and
> occasionally
> receive the following error:
>
> gls(Y~x1 + x2 + x3 + x4 + x5 + x6, data=na.omit(herrdata),  method
> ='ML',corr=corARMA(p = 2, q = 0))
>
> Error in `coef<-.corARMA`(`*tmp*`, value = c(7.49067599726739,
> -15.2313908862033 :
>   Coefficient matrix not invertible
>
> I do not understand the problem enough to create a dataset and
> post
> an example.  However, I have established
> a few things:
>
> if I use method='REML' then the error goes away
> if I reduce the number of parameters, the error goes away
> if I utilize an AR[1] correlation structure, the error goes away
>
> Would it be possible for somebody to explain this error to me?
>
> Thank you very much, Jon
>
> sessionInfo()
> R version 2.8.1 Patched (2009-01-19 r47650)
> i386-apple-darwin9.6.0
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
>
> other attached packages:
> [1] nlme_3.1-90        car_1.2-9          xtable_1.5-4
> MASS_7.2-45        RColorBrewer_1.0-2 lattice_0.17-20
> reshape_0.8.2      plyr_0.1.3
>
>
> Jon Loehrke
> Graduate Research Assistant
> Department of Fisheries Oceanography
> School for Marine Science and Technology
> University of Massachusetts
> 200 Mill Road, Suite 325
> Fairhaven, MA 02719
> jloehrke at umassd.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver 
> weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet 
> bevestigd is
> door een geldig ondertekend document. The views expressed in  this message
> and any annex are purely those of the writer and may not be regarded as 
> stating
> an official position of INBO, as long as the message is not confirmed by a 
> duly
> signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From brant.inman at me.com  Fri May  8 03:11:43 2009
From: brant.inman at me.com (Brant Inman)
Date: Thu, 07 May 2009 21:11:43 -0400
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED
 with lmer
In-Reply-To: <329A68716B57D54E8D39FD3F8A4A84DF0EB9426D@um-mail0136.unimaas.nl>
References: <329A68716B57D54E8D39FD3F8A4A84DF0EB9426D@um-mail0136.unimaas.nl>
Message-ID: <74B3E776-99AB-4431-979D-F29EAE7FF96D@me.com>

Wolfgang,

Thanks for the helpful comments.  To be clear, I am going to  
demonstrate the models you suggest, along with results so that anyone  
interested can provide insight without having to execute the code on  
their PCs.

Quick look at the famous BCG data, in the format that was suggested in  
the last post:

              author studyid    latitude       year  
startyear                 study  tb     n bcg  notb
1           Aronson       1  10.5384615 -18.230769      1935           
Aronson 1948   4   123 yes   119
2          Ferguson       2  21.5384615 -17.230769      1933          
Ferguson 1949   6   306 yes   300
3             Stein       6  10.5384615 -13.230769       
1935            Stein 1953 180  1541 yes  1361
4         Rosenthal       3   8.5384615  -6.230769      1941         
Rosenthal 1960   3   231 yes   228
5         Rosenthal      10   8.5384615  -5.230769      1937         
Rosenthal 1961  17  1716 yes  1699
6           Coetzee       9  -6.4615385   1.769231      1965           
Coetzee 1968  29  7499 yes  7470
7  Comstock-Webster      12  -0.4615385   2.769231      1947 Comstock- 
Webster 1969   5  2498 yes  2493
8    Frimont-Moller       5 -20.4615385   6.769231      1950   Frimont- 
Moller 1973  33  5069 yes  5036
9        Vandeviere       7 -14.4615385   6.769231      1965        
Vandeviere 1973   8  2545 yes  2537
10  Comstock School      11 -15.4615385   7.769231      1947  Comstock  
School 1974 186 50634 yes 50448
11    Comstock Comm      13  -0.4615385   9.769231      1950     
Comstock Comm 1976  27 16913 yes 16886
12             Hart       4  18.5384615  10.769231       
1950             Hart 1977  62 13598 yes 13536
13           Madras       8 -20.4615385  13.769231      1968            
Madras 1980 505 88391 yes 87886
14          Aronson       1  10.5384615 -18.230769      1935           
Aronson 1948  11   139  no   128
15         Ferguson       2  21.5384615 -17.230769      1933          
Ferguson 1949  29   303  no   274
16            Stein       6  10.5384615 -13.230769       
1935            Stein 1953 372  1451  no  1079
17        Rosenthal       3   8.5384615  -6.230769      1941         
Rosenthal 1960  11   220  no   209
18        Rosenthal      10   8.5384615  -5.230769      1937         
Rosenthal 1961  65  1665  no  1600
19          Coetzee       9  -6.4615385   1.769231      1965           
Coetzee 1968  45  7277  no  7232
20 Comstock-Webster      12  -0.4615385   2.769231      1947 Comstock- 
Webster 1969   3  2341  no  2338
21   Frimont-Moller       5 -20.4615385   6.769231      1950   Frimont- 
Moller 1973  47  5808  no  5761
22       Vandeviere       7 -14.4615385   6.769231      1965        
Vandeviere 1973  10   629  no   619
23  Comstock School      11 -15.4615385   7.769231      1947  Comstock  
School 1974 141 27338  no 27197
24    Comstock Comm      13  -0.4615385   9.769231      1950     
Comstock Comm 1976  29 17854  no 17825
25             Hart       4  18.5384615  10.769231       
1950             Hart 1977 248 12867  no 12619
26           Madras       8 -20.4615385  13.769231      1968            
Madras 1980 499 88391  no 87892



---------------------------------------------------------------------------
### Fixed effects model, no moderators

 > y <- cbind(newbcg$tb, newbcg$notb)
 > lmer(y ~ bcg + (1 | study), family=binomial, data=newbcg)

Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ bcg + (1 | study)
    Data: newbcg
    AIC   BIC logLik deviance
  260.4 264.2 -127.2    254.4
Random effects:
  Groups Name        Variance Std.Dev.
  study  (Intercept) 1.9885   1.4101
Number of obs: 26, groups: study, 13

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -4.20441    0.39456  -10.66   <2e-16 ***
bcgyes      -0.47747    0.04123  -11.58   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
        (Intr)
bcgyes -0.045


This model appears to give correct results for the fixed effects  
case.  Note that the variable that identifies the 2x2 table, "study",  
is assigned a random effect but is not a fixed effect.  The group  
dummy variable that identifies the treatment arm "bcg" is a fixed  
effect.

---------------------------------------------------------------------------
# Alternative method of coding the fixed effects model suggested by  
Wolfgang.  Result for treatment effect "bcg" is similar.

 > lmer(y ~ bcg + study + (1 | study), family=binomial, data=newbcg)

eneralized linear mixed model fit by the Laplace approximation
Formula: y ~ bcg + study + (1 | study)
    Data: newbcg
    AIC   BIC logLik deviance
  207.0 225.8 -88.48    177.0
Random effects:
  Groups Name        Variance Std.Dev.
  study  (Intercept)  0        0
Number of obs: 26, groups: study, 13

Fixed effects:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                -2.60205    0.26674  -9.755  < 2e-16 ***
bcgyes                     -0.47726    0.04123 -11.575  < 2e-16 ***
studyCoetzee 1968          -2.47540    0.29070  -8.515  < 2e-16 ***
studyComstock Comm 1976    -3.62322    0.29801 -12.158  < 2e-16 ***
studyComstock School 1974  -2.58468    0.27210  -9.499  < 2e-16 ***
studyComstock-Webster 1969 -3.58318    0.44288  -8.091 5.93e-16 ***
studyFerguson 1949          0.01952    0.31832   0.061  0.95109
studyFrimont-Moller 1973   -2.10792    0.28899  -7.294 3.01e-13 ***
studyHart 1977             -1.61561    0.27237  -5.932 3.00e-09 ***
studyMadras 1980           -2.35244    0.26818  -8.772  < 2e-16 ***
studyRosenthal 1960        -0.62094    0.38048  -1.632  0.10268
studyRosenthal 1961        -0.87730    0.28885  -3.037  0.00239 **
studyStein 1953             1.34371    0.27050   4.968 6.78e-07 ***
studyVandeviere 1973       -2.20159    0.35640  -6.177 6.52e-10 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) bcgyes sC1968 sCC197 sCS197 sC-W19 sF1949 sF-M19  
sH1977 sM1980 sR1960 sR1961 sS1953
bcgyes      -0.057
stdyCtz1968 -0.914 -0.003
stdyCmC1976 -0.892 -0.001  0.819
stdyCmS1974 -0.976 -0.026  0.897  0.875
stdyC-W1969 -0.600 -0.003  0.551  0.537  0.589
stdyFrg1949 -0.835 -0.004  0.766  0.748  0.819  0.503
stdyF-M1973 -0.920  0.002  0.844  0.823  0.902  0.554  0.771
stdyHrt1977 -0.976 -0.005  0.896  0.874  0.957  0.588  0.818  0.901
stdyMdr1980 -0.991 -0.003  0.910  0.887  0.972  0.597  0.831  0.915   
0.971
stdyRsn1960 -0.699 -0.004  0.641  0.625  0.685  0.421  0.586  0.645   
0.684  0.695
stdyRsn1961 -0.920 -0.004  0.845  0.824  0.902  0.554  0.771  0.850   
0.901  0.916  0.645
stdyStn1953 -0.982 -0.011  0.902  0.880  0.964  0.592  0.824  0.907   
0.963  0.978  0.689  0.908
stdyVnd1973 -0.744 -0.040  0.685  0.668  0.732  0.449  0.625  0.688   
0.731  0.742  0.523  0.689  0.736


---------------------------------------------------------------------------
# Random effects model, no moderators

Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ bcg + (bcg | study)
    Data: newbcg
    AIC   BIC logLik deviance
  119.0 125.3 -54.52    109.0
Random effects:
  Groups Name        Variance Std.Dev. Corr
  study  (Intercept) 2.43772  1.56132
         bcgyes      0.33610  0.57974  -0.739
Number of obs: 26, groups: study, 13

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)  -4.1234     0.4372  -9.431  < 2e-16 ***
bcgyes       -0.7417     0.1818  -4.079 4.52e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
        (Intr)
bcgyes -0.684


This model appears to give the correct results.

---------------------------------------------------------------------------
# Alternative way of coding random effects model suggested by  
Wolfgang.  Main difference: the estimate of between study variance  
(tau^2) is smaller in this version of the model.

 > lmer(y ~ bcg + study + (bcg | study), family=binomial, data=newbcg)

Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ bcg + study + (bcg | study)
    Data: newbcg
    AIC   BIC logLik deviance
  76.68 98.06 -21.34    42.68
Random effects:
  Groups Name        Variance Std.Dev. Corr
  study  (Intercept) 0.0000   0.00000
         bcgyes      0.2797   0.52887    NaN
Number of obs: 26, groups: study, 13

Fixed effects:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                 -2.4917     0.2934  -8.493  < 2e-16 ***
bcgyes                      -0.7639     0.1715  -4.455 8.39e-06 ***
studyCoetzee 1968           -2.5697     0.3257  -7.889 3.04e-15 ***
studyComstock Comm 1976     -3.8602     0.3387 -11.397  < 2e-16 ***
studyComstock School 1974   -2.7602     0.3045  -9.064  < 2e-16 ***
studyComstock-Webster 1969  -3.7729     0.4973  -7.586 3.30e-14 ***
studyFerguson 1949           0.1661     0.3499   0.475   0.6351
studyFrimont-Moller 1973    -2.2833     0.3241  -7.045 1.85e-12 ***
studyHart 1977              -1.4475     0.3001  -4.824 1.41e-06 ***
studyMadras 1980            -2.6741     0.2966  -9.015  < 2e-16 ***
studyRosenthal 1960         -0.5553     0.4162  -1.334   0.1821
studyRosenthal 1961         -0.7421     0.3184  -2.331   0.0198 *
studyStein 1953              1.4243     0.2992   4.760 1.93e-06 ***
studyVandeviere 1973        -1.8349     0.4230  -4.338 1.44e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) bcgyes sC1968 sCC197 sCS197 sC-W19 sF1949 sF-M19  
sH1977 sM1980 sR1960 sR1961 sS1953
bcgyes      -0.095
stdyCtz1968 -0.897  0.052
stdyCmC1976 -0.862  0.036  0.775
stdyCmS1974 -0.962  0.078  0.864  0.830
stdyC-W1969 -0.581 -0.041  0.524  0.505  0.560
stdyFrg1949 -0.834  0.036  0.750  0.721  0.803  0.489
stdyF-M1973 -0.902  0.053  0.811  0.779  0.868  0.527  0.754
stdyHrt1977 -0.977  0.085  0.877  0.842  0.940  0.568  0.815  0.882
stdyMdr1980 -0.989  0.090  0.887  0.852  0.951  0.574  0.825  0.892   
0.966
stdyRsn1960 -0.699  0.000  0.629  0.605  0.673  0.412  0.586  0.632   
0.683  0.691
stdyRsn1961 -0.919  0.062  0.826  0.793  0.884  0.536  0.768  0.830   
0.898  0.909  0.644
stdyStn1953 -0.980  0.086  0.880  0.845  0.943  0.570  0.818  0.884   
0.957  0.969  0.685  0.901
stdyVnd1973 -0.684 -0.033  0.617  0.594  0.660  0.407  0.575  0.620   
0.669  0.677  0.485  0.631  0.671

---------------------------------------------------------------------------
# Random effects model, adding two centered continuous moderator  
variables

 > lmer(y ~ bcg*latitude + bcg*year +(bcg | study), family=binomial,  
data=newbcg)

Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ bcg * latitude + bcg * year + (bcg | study)
    Data: newbcg
    AIC   BIC logLik deviance
  105.6 116.9  -43.8     87.6
Random effects:
  Groups Name        Variance   Std.Dev. Corr
  study  (Intercept) 0.60620909 0.778594
         bcgyes      0.00045554 0.021343 1.000
Number of obs: 26, groups: study, 13

Fixed effects:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)     -4.116305   0.221649 -18.571  < 2e-16 ***
bcgyes          -0.733330   0.049815 -14.721  < 2e-16 ***
latitude         0.024016   0.021007   1.143  0.25294
year            -0.099948   0.027955  -3.575  0.00035 ***
bcgyes:latitude -0.034332   0.003991  -8.601  < 2e-16 ***
bcgyes:year     -0.001489   0.005811  -0.256  0.79781
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) bcgyes latitd year   bcgys:l
bcgyes       0.046
latitude    -0.004  0.006
year        -0.015  0.014  0.658
bcgyes:lttd  0.002  0.156  0.088  0.059
bcgyes:year  0.020 -0.234  0.049  0.078  0.706

##
The Van Houwelingen results using non-centered moderators for a  
similar model are:

tau^2 = 0.002
intercept: 0.494 (se = 0.592)
latitude: -0.034 (se = 0.004)
year:     -0.001 (se = 0.006)

Note that there are significant differences in these estimates and  
those obtained in my model.

---------------------------------------------------------------------------
# Wolfgang's suggestion for the fixed effects model with moderators.

 > lmer(y ~ bcg*latitude + bcg*year + study + (bcg | study),  
family=binomial, data=newbcg)

Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In addition: Warning message:
In model.matrix.default(mt, mf, contrasts) :
   variable 'study' converted to a factor

Obviously a quite different result.

---------------------------------------------------------------------------

I hope these details help the smart people out there figure out what I  
have done wrong!

Brant





On May 7, 2009, at 10:39 AM, Viechtbauer Wolfgang (STAT) wrote:

> I have not followed the discussion fully, but I have a hunch that  
> may be useful to examine.
>
> Suppose you want to meta-analyze k 2x2 table data using the odds  
> ratio as the outcome measure. One approach is to calculate the log  
> odds ratio with the corresponding sampling variances (or to be  
> precise: estimates thereof) for those k tables and apply one of the  
> usual meta-analytic models. Moderators can be added and van  
> Houwelingen, Arends, and Stijnen (2002) nicely demonstrate how those  
> types of models can be fitted with SAS.
>
> An alternative approach is not to rely on the normal approximation  
> and instead formulate a logistic regression model. An "equivalent"  
> fixed-effects model then should include *dummy variables for the k  
> tables* and a dummy variable for the group variable (e.g., bcg  
> vaccinated = 1; not bcg vaccinated = 0). A constant term should also  
> be in the model. If you want to add a moderator variable to this  
> model, then one should add *the interaction between the group  
> variable and the moderator variable* to the model (but NOT the main  
> effect for the moderator variable, since then the model would be  
> overparameterized).
>
> If one wants a random-effects model, one should STILL add the *dummy  
> variables for the k tables* and the dummy variable for the group  
> variable, plus a random effect along with that group dummy variable  
> (so that we get a random treatment effect). Again, moderators are  
> included via an interaction term between the moderator variable and  
> the group variable.
>
> These could be considered the "equivalent" models to the usual meta- 
> anaytic fixed-, random-, and mixed-effects models.
>
> As far as I can tell, Brant, there are no dummies in your model for  
> the tables. Give that a try. And then, when you throw in moderators,  
> just include the interaction between the moderator and the bcg  
> variable. I'll be interested in what you find!
>
> Best,
>
> -- 
> Wolfgang Viechtbauer
>  Department of Methodology and Statistics
>  University of Maastricht, The Netherlands
>  http://www.wvbauer.com/
>
>



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Fri May  8 10:53:30 2009
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 8 May 2009 10:53:30 +0200
Subject: [R-sig-ME] Duplicating meta-regression results from PROC MIXED
	with lmer
In-Reply-To: <74B3E776-99AB-4431-979D-F29EAE7FF96D@me.com>
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF0EB9426E@um-mail0136.unimaas.nl>

I now had a chance to run these models myself. 

Here are the data that I used (study is a factor and the first column is the # of TB cases and the second the # of non-TB cases).

                group ablati syear study
 [1,]   4   119     1     44    48     1
 [2,]   6   300     1     55    49     2
 [3,]   3   228     1     42    60     3
 [4,]  62 13536     1     52    77     4
 [5,]  33  5036     1     13    73     5
 [6,] 180  1361     1     44    53     6
 [7,]   8  2537     1     19    73     7
 [8,] 505 87886     1     13    80     8
 [9,]  29  7470     1     27    68     9
[10,]  17  1699     1     42    61    10
[11,] 186 50448     1     18    74    11
[12,]   5  2493     1     33    69    12
[13,]  27 16886     1     33    76    13
[14,]  11   128     0     44    48     1
[15,]  29   274     0     55    49     2
[16,]  11   209     0     42    60     3
[17,] 248 12619     0     52    77     4
[18,]  47  5761     0     13    73     5
[19,] 372  1079     0     44    53     6
[20,]  10   619     0     19    73     7
[21,] 499 87892     0     13    80     8
[22,]  45  7232     0     27    68     9
[23,]  65  1600     0     42    61    10
[24,] 141 27197     0     18    74    11
[25,]   3  2338     0     33    69    12
[26,]  29 17825     0     33    76    13

If you want results that are essentially those from the paper, you should use:

lmer(y ~ group + ablati:group + syear:group + study + (group - 1| study), family=binomial)

The estimate of tau^2 is then essentially zero and:

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -2.426859   0.269031  -9.021  < 2e-16 ***
group         0.548365   0.493131   1.112  0.26613    
study2        0.131173   0.320457   0.409  0.68230    
...
study13      -3.716989   0.301366 -12.334  < 2e-16 ***
group:ablati -0.034185   0.003948  -8.659  < 2e-16 ***
group:syear  -0.001770   0.005753  -0.308  0.75838    

This matches up quite nicely with the results from the "usual" approach.

An alternative would be to add study as a random instead of a fixed effect. Then the main effects for absolute latitude and study year can also be added to the model:

lmer(y ~ group + ablati + ablati:group + syear + syear:group + (group | study), family=binomial)

Then the estimate of tau^2 is 0.00045553, still pretty much zero, and:

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.699707   2.386607   0.712  0.47635    
group         0.514024   0.497863   1.032  0.30186    
ablati        0.024016   0.021007   1.143  0.25294    
syear        -0.099948   0.027955  -3.575  0.00035 ***
group:ablati -0.034332   0.003991  -8.601  < 2e-16 ***
group:syear  -0.001488   0.005811  -0.256  0.79787    

which is still quite close.

Best,

-- 
Wolfgang Viechtbauer
?Department of Methodology and Statistics
?University of Maastricht, The Netherlands
?http://www.wvbauer.com/



From Thierry.ONKELINX at inbo.be  Fri May  8 11:19:25 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 8 May 2009 11:19:25 +0200
Subject: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
In-Reply-To: <3937D6AA05504F34BAE3B5394BAE2B18@lborger>
References: <6CE77016-8CDC-40B4-A770-017F65E2D84F@umassd.edu>
	<2E9C414912813E4EB981326983E0A104067422D5@inboexch.inbo.be>
	<3937D6AA05504F34BAE3B5394BAE2B18@lborger>
Message-ID: <2E9C414912813E4EB981326983E0A104067425E6@inboexch.inbo.be>

Dear Luca,

That seems reasonable. But that means that the order is important. So I still prefer to put the time variable explicitly in the correlation structure. Better save that sorry ;-)

HTH,

Thierry 


----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Luca Borger [mailto:lborger at uoguelph.ca] 
Verzonden: donderdag 7 mei 2009 19:35
Aan: ONKELINX, Thierry; Jon Loehrke; r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]

Hello,

> you have not specified the variable which indicates time. I am not sure
> which variable is used by default.


If I understand correctly, if the position variable is not defined (form 
=~1) the within-group order of the positions is used by default (P&B 2000 
p.236).

HTH

Cheers,

Luca

---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1

office +1 519 824 4120 ext. 52975
lab     +1 519 824 4120 ext. 53594
fax:     +1 519 767 1656

email: lborger at uoguelph.ca
www.researcherid.com/rid/C-6003-2008
http://uoguelph.academia.edu/LucaBorger



----- Original Message ----- 
From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
To: "Jon Loehrke" <jloehrke at umassd.edu>; <r-sig-mixed-models at r-project.org>
Sent: Thursday, May 07, 2009 4:38 AM
Subject: Re: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]


> Dear Jon,
>
> It seems to me like you are trying to fit a model that is too complex
> for your dataset. Are you sure you have enough data? Furthermore I think
> you have not specified the variable which indicates time. I am not sure
> which variable is used by default.
>
> HTH,
>
> Thierry
>
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Jon Loehrke
> Verzonden: woensdag 6 mei 2009 14:17
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
>
> Hi Mixed Modelers,
>
> I have  been using gls() to run some AR[2] models and
> occasionally
> receive the following error:
>
> gls(Y~x1 + x2 + x3 + x4 + x5 + x6, data=na.omit(herrdata),  method
> ='ML',corr=corARMA(p = 2, q = 0))
>
> Error in `coef<-.corARMA`(`*tmp*`, value = c(7.49067599726739,
> -15.2313908862033 :
>   Coefficient matrix not invertible
>
> I do not understand the problem enough to create a dataset and
> post
> an example.  However, I have established
> a few things:
>
> if I use method='REML' then the error goes away
> if I reduce the number of parameters, the error goes away
> if I utilize an AR[1] correlation structure, the error goes away
>
> Would it be possible for somebody to explain this error to me?
>
> Thank you very much, Jon
>
> sessionInfo()
> R version 2.8.1 Patched (2009-01-19 r47650)
> i386-apple-darwin9.6.0
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
>
> other attached packages:
> [1] nlme_3.1-90        car_1.2-9          xtable_1.5-4
> MASS_7.2-45        RColorBrewer_1.0-2 lattice_0.17-20
> reshape_0.8.2      plyr_0.1.3
>
>
> Jon Loehrke
> Graduate Research Assistant
> Department of Fisheries Oceanography
> School for Marine Science and Technology
> University of Massachusetts
> 200 Mill Road, Suite 325
> Fairhaven, MA 02719
> jloehrke at umassd.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver 
> weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet 
> bevestigd is
> door een geldig ondertekend document. The views expressed in  this message
> and any annex are purely those of the writer and may not be regarded as 
> stating
> an official position of INBO, as long as the message is not confirmed by a 
> duly
> signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From lborger at uoguelph.ca  Fri May  8 15:48:50 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Fri, 8 May 2009 09:48:50 -0400
Subject: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
References: <6CE77016-8CDC-40B4-A770-017F65E2D84F@umassd.edu>
	<2E9C414912813E4EB981326983E0A104067422D5@inboexch.inbo.be>
	<3937D6AA05504F34BAE3B5394BAE2B18@lborger>
	<2E9C414912813E4EB981326983E0A104067425E6@inboexch.inbo.be>
Message-ID: <EE7C9A27E0DE459DBA87183476ADF486@lborger>

Hello,

yes, by all means. By defining the position variable the function is also 
able to accomodate missing values (i.e., the values of the position variable 
do not need to be consecutive).


Cheers,

Luca


----- Original Message ----- 
From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
To: "Luca Borger" <lborger at uoguelph.ca>; "Jon Loehrke" 
<jloehrke at umassd.edu>; <r-sig-mixed-models at r-project.org>
Sent: Friday, May 08, 2009 5:19 AM
Subject: RE: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]


Dear Luca,

That seems reasonable. But that means that the order is important. So I 
still prefer to put the time variable explicitly in the correlation 
structure. Better save that sorry ;-)

HTH,

Thierry


----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and 
Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, 
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than 
asking him to perform a post-mortem examination: he may be able to say what 
the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not 
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Luca Borger [mailto:lborger at uoguelph.ca]
Verzonden: donderdag 7 mei 2009 19:35
Aan: ONKELINX, Thierry; Jon Loehrke; r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]

Hello,

> you have not specified the variable which indicates time. I am not sure
> which variable is used by default.


If I understand correctly, if the position variable is not defined (form
=~1) the within-group order of the positions is used by default (P&B 2000
p.236).

HTH

Cheers,

Luca

---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1

office +1 519 824 4120 ext. 52975
lab     +1 519 824 4120 ext. 53594
fax:     +1 519 767 1656

email: lborger at uoguelph.ca
www.researcherid.com/rid/C-6003-2008
http://uoguelph.academia.edu/LucaBorger



----- Original Message ----- 
From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
To: "Jon Loehrke" <jloehrke at umassd.edu>; <r-sig-mixed-models at r-project.org>
Sent: Thursday, May 07, 2009 4:38 AM
Subject: Re: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]


> Dear Jon,
>
> It seems to me like you are trying to fit a model that is too complex
> for your dataset. Are you sure you have enough data? Furthermore I think
> you have not specified the variable which indicates time. I am not sure
> which variable is used by default.
>
> HTH,
>
> Thierry
>
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Jon Loehrke
> Verzonden: woensdag 6 mei 2009 14:17
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] gls and AR>1 [Coefficient matrix not invertible]
>
> Hi Mixed Modelers,
>
> I have  been using gls() to run some AR[2] models and
> occasionally
> receive the following error:
>
> gls(Y~x1 + x2 + x3 + x4 + x5 + x6, data=na.omit(herrdata),  method
> ='ML',corr=corARMA(p = 2, q = 0))
>
> Error in `coef<-.corARMA`(`*tmp*`, value = c(7.49067599726739,
> -15.2313908862033 :
>   Coefficient matrix not invertible
>
> I do not understand the problem enough to create a dataset and
> post
> an example.  However, I have established
> a few things:
>
> if I use method='REML' then the error goes away
> if I reduce the number of parameters, the error goes away
> if I utilize an AR[1] correlation structure, the error goes away
>
> Would it be possible for somebody to explain this error to me?
>
> Thank you very much, Jon
>
> sessionInfo()
> R version 2.8.1 Patched (2009-01-19 r47650)
> i386-apple-darwin9.6.0
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
>
> other attached packages:
> [1] nlme_3.1-90        car_1.2-9          xtable_1.5-4
> MASS_7.2-45        RColorBrewer_1.0-2 lattice_0.17-20
> reshape_0.8.2      plyr_0.1.3
>
>
> Jon Loehrke
> Graduate Research Assistant
> Department of Fisheries Oceanography
> School for Marine Science and Technology
> University of Massachusetts
> 200 Mill Road, Suite 325
> Fairhaven, MA 02719
> jloehrke at umassd.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is
> door een geldig ondertekend document. The views expressed in  this message
> and any annex are purely those of the writer and may not be regarded as
> stating
> an official position of INBO, as long as the message is not confirmed by a
> duly
> signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
en binden het INBO onder geen enkel beding, zolang dit bericht niet 
bevestigd is
door een geldig ondertekend document. The views expressed in  this message
and any annex are purely those of the writer and may not be regarded as 
stating
an official position of INBO, as long as the message is not confirmed by a 
duly
signed document.



From bates at stat.wisc.edu  Sun May 10 16:17:41 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 10 May 2009 09:17:41 -0500
Subject: [R-sig-ME] How to compute deviance of a (g)lmer model under
	different values of the parameters ? Partial approximate answer
In-Reply-To: <1241557343.6878.43.camel@yod>
References: <1241509027.9821.24.camel@yod> <1241557343.6878.43.camel@yod>
Message-ID: <40e66e0b0905100717y8ef575el45cd8c940a222d75@mail.gmail.com>

Sorry to be so late in responding to this thread.  It has been a busy time.

This thread and others like it have convinced me that I should make
available an evaluation of the deviance of a fitted or an intermediate
lmer model at arbitrary values of the parameters.  For computational
efficiency the deviance and the REML criterion of a linear mixed model
is always optimized as the profiled deviance or the profiled REML
criterion.  This is an important characteristic of the lme4 package
because it provides much faster and robust model fits.  Nevertheless,
there are circumstances in which it is desirable to evaluate the
deviance or the REML criterion at arbitrary values of the parameters.

In section 2 of Bates and DebRoy (2004, J Multivariate Analysis, 1-17)
we derive general expressions for the deviance (eqn. 8) and for the
REML criterion (eqn. 18) as functions of all the parameters in the
model.  (You do need to be careful about the REML criterion in that it
does not depend on the values of the fixed-effects parameters.  For
clarity it would be best to stick to the likelihood-based criteria
like the deviance.)  For parameter estimation these are collapsed to
the profiled deviance (eqn. 10) and the profiled REML criterion (eqn.
15) but it would be possible to allow for arbitrary values of the
fixed-effects parameters and the residual variance to be included in
the evaluation.  It turns out that arbitrary fixed-effects parameters
are relatively easy.  Arbitrary residual variance is a bit more
complicated because of the way that the variances and covariances of
the random effects are expressed in the model.  They are expressed
relative to the residual variance and in a parameterization with
simple non-negativity constraints.  Going from arbitrary
variance-covariance parameters to this particular parameterization
would be somewhat challenging but not insurmountable.

Is the evaluation of the deviance for arbitrary values of the
fixed-effects parameters but with the conditional estimate of the
residual variance of use by itself?

On Tue, May 5, 2009 at 4:02 PM, Emmanuel Charpentier
<charpent at bacbuc.dyndns.org> wrote:
> Answering to myself, at least for archive users' sake :
>
> I have a partial approximate solution, which seems to work (= gives "not
> seemingly unreasonable answers") for *linear* mixed effect models.
>
> For these models, the deviance (= -2 logLik(themodel)) is easily
> computed as the sum on all observations of the squared residuals. This
> residual r is the difference between the observed value y and the
> estimate by the model y.hat.
>
> If, as usual, we denote the fixed effects model matrix by X, beta the
> unknown fixed effects coefficients, with estimator beta.hat, Z the
> random effects model matrix and b the unknown random effects
> coefficients with estimator b.hat, we all know that
>
> y.hat = X%*%beta.hat + Z%*%b.hat (1)
>
> Therefore, r = y-y.hat = y-y.hat = y-(X%*%beta.hat + Z%*%b.hat). (2)
>
> The problem is that Z%*%b.hat might be *quite* complicated to rebuilt
> from ranef(model) and Z.
>
> Since we seek a solution allowing to compute the LL of the model under a
> new estimator of beta (say beta.hat.new) *computed while ignoring the
> random effects beyond what is reflected in beta.hat variances*, it seems
> reasonable to ignore what modifications to Z%*%b.hat an adjustment of
> the model to the new fixed effect estimators beta.hat.new would entail,
> and use (2) with the original values to compute the new "residuals". To
> be precise :
>
> a) Zbh=y.hat-X%*%beta.hat (computed from the original model)
> b) r.new=y-(X%*%beta.hat.new+Zbh) (in the supposed new model)
>
> which can be "onelined", of course... at the expense of clarity.
> Computing deviance an logLik is trivial afterwards...
>
> Two questions :
> ? ? ? ?a) What do you think ? Am I crazy like a fox ? (I wouldn't mind being
> crazy like a Fox(*) ... :)
> ? ? ? ?b) Could such a trick be applied to *generalized* linear models ?
> Computing the deviance from the residuals doesn't seem as easy as for
> linear models...
>
> Sincerely,
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Emmanuel Charpentier
>
> (*) with apologies to John F, who has probably read|heard it a lot of
> times...
>
> Le mardi 05 mai 2009 ? 09:37 +0200, Emmanuel Charpentier a ?crit :
>> Dear list,
>>
>> I'm trying to implement multiple imputations analysis of datasets with
>> missing values for mixed models. My interest goes mainly to the fixed
>> effects.
>>
>> As you probably know, the principle of such an analysis is to impute
>> "reasonable" values to missing data a few times (with "reasonable"
>> variability), analyze these few completed datasets and pooling the
>> analyses.
>>
>> Schafer(1999) states simple methods for pooling estimates of the model
>> and their variances. These methods can be applied to mixed models (with
>> a few snags : you need to *ignore* the variation of random effects
>> between imputed datasets beyond what is reflected in fixed effects' SE,
>> you need to guesstimate the residuals DoF, which is something Douglas
>> Bates has expressed grave doubts about). As it stands, these methods
>> give results which, at first look, does not seem unreasonable, and might
>> be used as a first approximation. More on this later.
>>
>> My current goal is to build a function to build a "pooled test" for
>> likelihood ratio of two models. Such a test has been proposed by Meng &
>> Rubin (Biometrika, 1992), and, according to a presentation by RA
>> Medeiros, has been implemented in Stata under the name milrtest.
>>
>> I'm trying to implement such a pooled test in R. My snag is that the
>> estimate is based on the estimation, for each imputed dataset, of the
>> (log)likelihood ratio of each of these datasets under the hypotheses of
>> the coefficients having precisely the values obtained in the coefficient
>> pooling step.
>>
>> So what I need is a (if possible elegant and/or fast) way to compute
>> log-likelihood of a given dataset under a model (already built) under
>> this hypothesis, up to a quantity supposed constant between models.
>>
>> The logLik(model) function will happily give me LL(model|parameters
>> giving makimum LL). What I need is something like logLik(model, coefs)
>> giving me (up to an additive constant) LL(model|parameters=coefs).
>>
>> Do you have any suggestions ? I can always sum squares of residuals
>> recomputed under this alternative hypothesis, but I'm not quite sure
>> that's enough for my purposes, especially if I plan to include the
>> random effect estimates later...
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Emmanuel Charpentier
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From charpent at bacbuc.dyndns.org  Sun May 10 22:13:45 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Sun, 10 May 2009 22:13:45 +0200
Subject: [R-sig-ME] How to compute deviance of a (g)lmer model under
 different values of the parameters ? Partial approximate answer
In-Reply-To: <40e66e0b0905100717y8ef575el45cd8c940a222d75@mail.gmail.com>
References: <1241509027.9821.24.camel@yod> <1241557343.6878.43.camel@yod>
	<40e66e0b0905100717y8ef575el45cd8c940a222d75@mail.gmail.com>
Message-ID: <1241986425.22049.5.camel@yod>

Le dimanche 10 mai 2009 ? 09:17 -0500, Douglas Bates a ?crit :
> Sorry to be so late in responding to this thread.  It has been a busy time.

Thank you for your answer !

> This thread and others like it have convinced me that I should make
> available an evaluation of the deviance of a fitted or an intermediate
> lmer model at arbitrary values of the parameters.  For computational
> efficiency the deviance and the REML criterion of a linear mixed model
> is always optimized as the profiled deviance or the profiled REML
> criterion.  This is an important characteristic of the lme4 package
> because it provides much faster and robust model fits.  Nevertheless,
> there are circumstances in which it is desirable to evaluate the
> deviance or the REML criterion at arbitrary values of the parameters.

I think that mine is but one ...

> In section 2 of Bates and DebRoy (2004, J Multivariate Analysis, 1-17)
> we derive general expressions for the deviance (eqn. 8) and for the
> REML criterion (eqn. 18) as functions of all the parameters in the
> model.  (You do need to be careful about the REML criterion in that it
> does not depend on the values of the fixed-effects parameters.  For
> clarity it would be best to stick to the likelihood-based criteria
> like the deviance.)  For parameter estimation these are collapsed to
> the profiled deviance (eqn. 10) and the profiled REML criterion (eqn.
> 15) but it would be possible to allow for arbitrary values of the
> fixed-effects parameters and the residual variance to be included in
> the evaluation.  It turns out that arbitrary fixed-effects parameters
> are relatively easy.  Arbitrary residual variance is a bit more
> complicated because of the way that the variances and covariances of
> the random effects are expressed in the model.  They are expressed
> relative to the residual variance and in a parameterization with
> simple non-negativity constraints.  Going from arbitrary
> variance-covariance parameters to this particular parameterization
> would be somewhat challenging but not insurmountable.
> 
> Is the evaluation of the deviance for arbitrary values of the
> fixed-effects parameters but with the conditional estimate of the
> residual variance of use by itself?

Profiling  comes to mind ... Wald tests ? A rough estimator for score
tests ? I'm no big fan of hypothesis testing, but (some) journal editors
live and die by it... and won't take a bootstrap for an answer, alas !

Again, thank you !

					Emmanuel Charpentier


> On Tue, May 5, 2009 at 4:02 PM, Emmanuel Charpentier
> <charpent at bacbuc.dyndns.org> wrote:
> > Answering to myself, at least for archive users' sake :
> >
> > I have a partial approximate solution, which seems to work (= gives "not
> > seemingly unreasonable answers") for *linear* mixed effect models.
> >
> > For these models, the deviance (= -2 logLik(themodel)) is easily
> > computed as the sum on all observations of the squared residuals. This
> > residual r is the difference between the observed value y and the
> > estimate by the model y.hat.
> >
> > If, as usual, we denote the fixed effects model matrix by X, beta the
> > unknown fixed effects coefficients, with estimator beta.hat, Z the
> > random effects model matrix and b the unknown random effects
> > coefficients with estimator b.hat, we all know that
> >
> > y.hat = X%*%beta.hat + Z%*%b.hat (1)
> >
> > Therefore, r = y-y.hat = y-y.hat = y-(X%*%beta.hat + Z%*%b.hat). (2)
> >
> > The problem is that Z%*%b.hat might be *quite* complicated to rebuilt
> > from ranef(model) and Z.
> >
> > Since we seek a solution allowing to compute the LL of the model under a
> > new estimator of beta (say beta.hat.new) *computed while ignoring the
> > random effects beyond what is reflected in beta.hat variances*, it seems
> > reasonable to ignore what modifications to Z%*%b.hat an adjustment of
> > the model to the new fixed effect estimators beta.hat.new would entail,
> > and use (2) with the original values to compute the new "residuals". To
> > be precise :
> >
> > a) Zbh=y.hat-X%*%beta.hat (computed from the original model)
> > b) r.new=y-(X%*%beta.hat.new+Zbh) (in the supposed new model)
> >
> > which can be "onelined", of course... at the expense of clarity.
> > Computing deviance an logLik is trivial afterwards...
> >
> > Two questions :
> >        a) What do you think ? Am I crazy like a fox ? (I wouldn't mind being
> > crazy like a Fox(*) ... :)
> >        b) Could such a trick be applied to *generalized* linear models ?
> > Computing the deviance from the residuals doesn't seem as easy as for
> > linear models...
> >
> > Sincerely,
> >
> >                                        Emmanuel Charpentier
> >
> > (*) with apologies to John F, who has probably read|heard it a lot of
> > times...
> >
> > Le mardi 05 mai 2009 ? 09:37 +0200, Emmanuel Charpentier a ?crit :
> >> Dear list,
> >>
> >> I'm trying to implement multiple imputations analysis of datasets with
> >> missing values for mixed models. My interest goes mainly to the fixed
> >> effects.
> >>
> >> As you probably know, the principle of such an analysis is to impute
> >> "reasonable" values to missing data a few times (with "reasonable"
> >> variability), analyze these few completed datasets and pooling the
> >> analyses.
> >>
> >> Schafer(1999) states simple methods for pooling estimates of the model
> >> and their variances. These methods can be applied to mixed models (with
> >> a few snags : you need to *ignore* the variation of random effects
> >> between imputed datasets beyond what is reflected in fixed effects' SE,
> >> you need to guesstimate the residuals DoF, which is something Douglas
> >> Bates has expressed grave doubts about). As it stands, these methods
> >> give results which, at first look, does not seem unreasonable, and might
> >> be used as a first approximation. More on this later.
> >>
> >> My current goal is to build a function to build a "pooled test" for
> >> likelihood ratio of two models. Such a test has been proposed by Meng &
> >> Rubin (Biometrika, 1992), and, according to a presentation by RA
> >> Medeiros, has been implemented in Stata under the name milrtest.
> >>
> >> I'm trying to implement such a pooled test in R. My snag is that the
> >> estimate is based on the estimation, for each imputed dataset, of the
> >> (log)likelihood ratio of each of these datasets under the hypotheses of
> >> the coefficients having precisely the values obtained in the coefficient
> >> pooling step.
> >>
> >> So what I need is a (if possible elegant and/or fast) way to compute
> >> log-likelihood of a given dataset under a model (already built) under
> >> this hypothesis, up to a quantity supposed constant between models.
> >>
> >> The logLik(model) function will happily give me LL(model|parameters
> >> giving makimum LL). What I need is something like logLik(model, coefs)
> >> giving me (up to an additive constant) LL(model|parameters=coefs).
> >>
> >> Do you have any suggestions ? I can always sum squares of residuals
> >> recomputed under this alternative hypothesis, but I'm not quite sure
> >> that's enough for my purposes, especially if I plan to include the
> >> random effect estimates later...
> >>
> >>                                       Emmanuel Charpentier
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>



From greg.lee at utas.edu.au  Mon May 11 07:00:59 2009
From: greg.lee at utas.edu.au (Greg Lee)
Date: Mon, 11 May 2009 15:00:59 +1000
Subject: [R-sig-ME] MCMCglmm 'undefined columns' error
Message-ID: <54c8adaa0905102200g3ad7e760qc00bce4f50da2b1b@mail.gmail.com>

Dear List,

I am attempting to fit a GLMM using MCMCglmm(), but receive and
'undefined columns' error.

The data are counts of bunches of grapes at bud positions (1:10) on
canes (basal/distal) within vines within (vine type) clones within
(vineyard) sites. Two treatments relating to degree of pruning have
been imposed, and there are 5 replicates at each level combination.
The data are as follows:

> head(budfruit)

  site clone treat vine cane bud count
1    M  2051     1    1    b   1     1
2    M  2051     1    2    b   1     2
3    M  2051     1    3    b   1     1
4    M  2051     1    4    b   1     2
5    M  2051     1    5    b   1     1
6    M  2051     2    1    b   1     2
...

with counts taking values 0,1,2 or (very rarely) 3.

Applying a Poisson-based GLM, such as:

glm(count ~ treat + cane + bud, family = poisson, data = budfruit)

suggests serious under-dispersion (Residual deviance: 370.09 on 1184
degrees of freedom), from which I concluded that a multinomial-based
mixed model might be a better option. However, my initial attempt
using MCMCglmm

fit <- MCMCglmm(count ~ site + clone + treat + cane + bud,
                random =~ vine, family = 'multinomial4',
                data = budfruit, verbose = TRUE)

produces the error:

Error in `[.data.frame`(data, , match(response.names[0:nJ + nt],
names(data))) :
  undefined columns selected

Is there a problem with my understanding of the call to MCMCglmm(), or
is this perhaps a bug?

Any insight appreciated. Are there perhaps other packages within which
I could fit this model?

Regards,
Greg

> sessionInfo()

R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] MCMCglmm_1.09      gtools_2.5.0-1     combinat_0.0-6     orthopolynom_1.0-1
 [5] polynom_1.3-5      pscl_1.03          mvtnorm_0.9-5      ape_2.3
 [9] coda_0.13-4        Matrix_0.999375-26 lattice_0.17-22    tensorA_0.31
[13] corpcor_1.5.2      MASS_7.2-46

loaded via a namespace (and not attached):
[1] gee_4.13-13 grid_2.9.0  nlme_3.1-91


--------------
Greg Lee
Biometrician
Tasmanian Institute of Agricultural Research
New Town Research Laboratories
University of Tasmania
13 St Johns Avenue,
New Town, 7008
Australia
Ph: ?+613 6233 6858
Fax: +613 6233 6145



From j.hadfield at ed.ac.uk  Mon May 11 16:38:57 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 11 May 2009 15:38:57 +0100
Subject: [R-sig-ME] MCMCglmm 'undefined columns' error
In-Reply-To: <54c8adaa0905102200g3ad7e760qc00bce4f50da2b1b@mail.gmail.com>
References: <54c8adaa0905102200g3ad7e760qc00bce4f50da2b1b@mail.gmail.com>
Message-ID: <D6E4A810-03B2-4ED6-8CFE-451920658F00@ed.ac.uk>

Hi Greg,

There are two ways of fitting multinomial models when the number of  
observations per unit is 1 (as in your case). You specified  
family="multinomial4" so MCMCglmm is expecting a 4 column response  
variable with the counts in each column. In your case each row should  
contain 3 zeros and 1 one.  The response should be specified something  
like:

cbind(category1,category2,category3,category4)~

Alternatively, you can pass a single column of factors as a response  
and use family="categorical" and keep your original  syntax:

count ~

Both models are parameterised as a log-odds ratio against a baseline  
category. In the first model  the final category is the baseline  
category. I've done this because for binomial traits ("multinomial2")  
the standard glm syntax  is to pass cbind(successes, failures) and the  
results are the log odds of succeeding vs failing (ie failing is the  
base-line category).   In the second model  the first factor level is  
the baseline category.  I've done this because for binary traits it is  
natural to have zero's as the base-line and interpret the parameters  
as predicting 1's (successes).

For your data there will be three response variables in both cases  
({cat1-cat4, cat2-cat4, cat3-cat4} or {cat2-cat1, cat3-cat1, cat4- 
cat1}).   You will want to use the reserved variable "trait" so that  
different intercepts and effects are fitted for the three responses.  
For example count~trait-1 or possibly count~trait+trait:cane-1 etc.

A multivariate error structure must also be defined. You could use:

~ idh(trait):units or ~ us(trait):units

However, for multinomial models with a single count you can't estimate  
these from the data so you may as well fix them.  I recommend fixing  
the residual variances to 1, and the covariances to either 0 or 0.5.   
This is specified in the prior:

prior=list(R=list(V=diag(3), n=1, fix=1), G=Gprior)

where V=diag(3) is  3X3 (number of categories -1) identity matrix and  
fix=1 fixes the matrix at these values. The random effects should also  
have priors which are also passed as a list (Gprior)

Its up to you what type of structure you use for vine. The vine  
variance structure is also 3X3 and you could use any of these options:

~ vine                             # 1 parameter    
v1=v2=v3=c12=c13=c23      Gprior=list(G1=list(V=diag(1), n=1))
~ vine:trait                     # 1 parameter   v1=v2=v3   
c12=c13=c23=0  Gprior=list(G1=list(V=diag(1), n=1))
~ vine+vine:trait           # 2 parameters v1=v2=v3  c12=c13=c23        
Gprior=list(G1=list(V=diag(1), n=1)), G2=list(V=diag(1), n=1))
~idh(vine)                     # 3 parameters  v1 v2 v3     
c12=c13=c23=0  Gprior=list(G1=list(V=diag(3), n=3))
~idh(vine)+vine:trait   # 4 parameters  v1 v2 v3    c12=c13=c23        
Gprior=list(G1=list(V=diag(3), n=3), G2=list(V=diag(1), n=1))
~ us(vine)                     # 6 parameters  v1 v2 v3    c12 c13  
c23          Gprior=list(G1=list(V=diag(3), n=3))

where v1 v2 and v3 are the variances for each logg-odds ratio due to  
vine, and  c12 c13 c23  are the covarainces between them.  I've made  
up the prior (co)variances but I've put in the minimum degree of  
belief parameter (n) that is required to make the priors proper.

One obvious problem is that the multinomial model in this form looses  
the information about the ordering 0<1<2<3.

Cheers,

Jarrod


On 11 May 2009, at 06:00, Greg Lee wrote:

> Dear List,
>
> I am attempting to fit a GLMM using MCMCglmm(), but receive and
> 'undefined columns' error.
>
> The data are counts of bunches of grapes at bud positions (1:10) on
> canes (basal/distal) within vines within (vine type) clones within
> (vineyard) sites. Two treatments relating to degree of pruning have
> been imposed, and there are 5 replicates at each level combination.
> The data are as follows:
>
>> head(budfruit)
>
>  site clone treat vine cane bud count
> 1    M  2051     1    1    b   1     1
> 2    M  2051     1    2    b   1     2
> 3    M  2051     1    3    b   1     1
> 4    M  2051     1    4    b   1     2
> 5    M  2051     1    5    b   1     1
> 6    M  2051     2    1    b   1     2
> ...
>
> with counts taking values 0,1,2 or (very rarely) 3.
>
> Applying a Poisson-based GLM, such as:
>
> glm(count ~ treat + cane + bud, family = poisson, data = budfruit)
>
> suggests serious under-dispersion (Residual deviance: 370.09 on 1184
> degrees of freedom), from which I concluded that a multinomial-based
> mixed model might be a better option. However, my initial attempt
> using MCMCglmm
>
> fit <- MCMCglmm(count ~ site + clone + treat + cane + bud,
>                random =~ vine, family = 'multinomial4',
>                data = budfruit, verbose = TRUE)
>
> produces the error:
>
> Error in `[.data.frame`(data, , match(response.names[0:nJ + nt],
> names(data))) :
>  undefined columns selected
>
> Is there a problem with my understanding of the call to MCMCglmm(), or
> is this perhaps a bug?
>
> Any insight appreciated. Are there perhaps other packages within which
> I could fit this model?
>
> Regards,
> Greg
>
>> sessionInfo()
>
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia. 
> 1252;LC_MONETARY=English_Australia. 
> 1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] MCMCglmm_1.09      gtools_2.5.0-1     combinat_0.0-6      
> orthopolynom_1.0-1
> [5] polynom_1.3-5      pscl_1.03          mvtnorm_0.9-5      ape_2.3
> [9] coda_0.13-4        Matrix_0.999375-26 lattice_0.17-22     
> tensorA_0.31
> [13] corpcor_1.5.2      MASS_7.2-46
>
> loaded via a namespace (and not attached):
> [1] gee_4.13-13 grid_2.9.0  nlme_3.1-91
>
>
> --------------
> Greg Lee
> Biometrician
> Tasmanian Institute of Agricultural Research
> New Town Research Laboratories
> University of Tasmania
> 13 St Johns Avenue,
> New Town, 7008
> Australia
> Ph:  +613 6233 6858
> Fax: +613 6233 6145
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Kate.Pressland at bristol.ac.uk  Mon May 11 17:52:46 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Mon, 11 May 2009 16:52:46 +0100
Subject: [R-sig-ME] Modelling random effects with SITE, YEAR and SPECIES
Message-ID: <4F689E07E99C2AE36D96E6FF@bio-mammal03.bio.bris.ac.uk>

Theirry,

thank you for you informative reply. I have had a go at your suggestions 
but have been stumped:

--On 07 May 2009 10:16 +0200 "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> 
wrote:

> Dear Kate,
>
> Adding SPECIES as a random effect indicates that you want to take the
> effect of SPECIES into account but not need to know the effect of the
> individual SPECIES. If you do want to know that effect then you have to
> add species to fixed effects. Examining the effect of A, B and C on
> species (as a fixed effect) requires interactions between them. The
> model then looks like (A + B + C) * SPECIES + Year + (1|SITE) + (1|YEAR)
> This will only work if you have sufficiend data.

I tried this approach with data I have that is SPECIES recorded as SITES 
over YEARS but when I tried A*SPECIES as a fixed factor I received this 
error message:

"Error in mer_finalize(ans) : Downdated X'X is not positive definite, 88."

I've searched for what this error means but I cannot understand it.

This was written by Douglas Bates in response to [Re: [R] lme4, error in 
mer_finalize(ans)] posted 05 Dec 2008:
"That, admittedly obscure, error message relates to the fixed-effects 
specification rt ~ length + length:pos being rank deficient. If you look at 
the summary of the linear model fit you will see that there are 3 
coefficients that are not determined because of singularities. The lm 
function detects the singularities and fits a lower-rank model.  The lmer 
function is not as sophisticated. It just detects the singularities and 
quits."

I am unsure what this means or how it translates to my data. In my example, 
I have 78 "SPECIES" (factor, coded as numbers) and "A" is ordered data 0, 
1, 2. The y variable is number/m. You wrote that this would only work is 
you had sufficient data - each species is not recorded each time, so is 
this reduced data the cause i.e. not enough observations for n?

> Another option is to keep species as a random effect and add random
> slopes according to A, B and C. This will allow a different effect of A,
> B anc C for each species. The model would look like A + B + C + Year +
> (1|SITE) + (1|YEAR) + (A + B + C|SPECIES)

I have tried this way also but I am unsure of the output - it does not give 
species specific information and therefore I cannot work out which species 
is more affected by A, only if SPECIES as a whole are affected or not by 
each category of A. This is not useful to me as I would like to determine, 
given the random effects, if A 0, 1, or 2 affect which species in the data 
set.

Any thoughts?

Kate
>
> HTH,
>
> Thierry
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens CL Pressland
> Verzonden: woensdag 6 mei 2009 20:18
> Aan: R Mixed Models
> Onderwerp: Re: [R-sig-ME] Modelling random effects with SITE, YEAR and
> SPECIES
>
> How can you work out how A, B or C affect SPECIES? By this I mean, could
>
> you find out how species n is affected by A, B and C in the correlation
> output? Or would you need to adjust the response to look at individual
> species separately?
>
> --On 29 April 2009 17:58 -0400 Ben Bolker <bolker at ufl.edu> wrote:
>
>> David R. wrote:
>>> Hello all,
>>>
>>> First, sorry for the english and the basic questions. I'm using mixed
>>> models (lme4 package) to analyse variability in 13 SPECIES of birds
>>> observed during 15 YEARS across 5 SITES. All the SPECIES were
>>> observed in all the sites in most years.
>>>
>>> My fixed effects are A, B, C and Year. I'm interested in the
>>> stochastic effect of A, B and C on the dependent variable, but also
>>> in a possible linear trend of the dependent variable over time.
>>>
>>> My random effects are SPECIES, YEAR and SITE, to control for the
>>> effects of nonindependence.
>>>
>>> I have a model with SITE, YEAR and SPECIES as crossed random effects
>>> like A + B + C + Year + (1|SITE) + (1|YEAR) + (1|SPECIES).
>>>
>>> My questions are:
>>>
>>> 1) Is this model correct? It is correct to model YEAR both as random
>>> effect and fixed effect? Is there the possibility that the variance
>>> accounted for by the random effect could robbing year as a fixed
>>> effect of explanatory power?
>>
>>   Seems OK and sensible to me.
>>   I would guess that the linear trend and the random variation are
>> sufficiently different patterns that they would not conflict too
> badly,
>> but you could try the different nested models and see what happens ...
>>
>>>
>>> 2) It is meaningful, instead,  to model YEAR as repeated measure, if
>>> the experimental unit were species within sites?
>>
>>   "Modeling YEAR as a random effect" and "Modeling YEAR as a repeated
>> measure" are, in my opinion, almost the same thing (but I'm ready to
> be
>> corrected, as always).  The only aspect of "repeated measures" that
>> would be different would be if you wanted to fit an autoregressive
> model
>> so that samples closer together in time were more correlated (which
> you
>> can't do with lmer at this
>> point).
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> ----------------------
> Kate Pressland
> Office D95
> School of Biological Sciences
> University of Bristol
> Woodland Road
> Bristol, BS8 1UG
> Tel: 0117 9288918 (Internal 88918)
> Kate.Pressland at bristol.ac.uk
> www.bio.bris.ac.uk/people/staff.cfm?key=1137
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer  en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document. The views expressed in
> this message  and any annex are purely those of the writer and may not be
> regarded as stating  an official position of INBO, as long as the message
> is not confirmed by a duly  signed document.



----------------------
Kate Pressland
Office D95
School of Biological Sciences
University of Bristol
Woodland Road
Bristol, BS8 1UG
Tel: 0117 9288918 (Internal 88918)
Kate.Pressland at bristol.ac.uk
www.bio.bris.ac.uk/people/staff.cfm?key=1137



From jvb at zool.uzh.ch  Mon May 11 20:32:08 2009
From: jvb at zool.uzh.ch (Josh Van Buskirk)
Date: Mon, 11 May 2009 20:32:08 +0200
Subject: [R-sig-ME] zipoisson in MCMCglmm
Message-ID: <200905111832.n4BIW8vm029294@idmailgate1.unizh.ch>


Dear all,

Does anyone have experience working with Jarrod Hadfield's MCMCglmm 
package with a zero-inflated Poisson distribution? After fitting the 
model, I'm having trouble obtaining the fixed effect coefficients 
from the logistic (inflated) and Poisson parts of the model. I'm 
interested in estimating how the fixed effects influence both processes.

In this example, many random genotypes are sampled within many random 
populations. There are two fixed effects. The response variable is 
highly zero-inflated.

priors <- list(R=list(V=diag(2),n=2), G=list(G1=list(V=diag(2), n=2), 
G2=list(V=diag(2), n=2)))
model <- MCMCglmm(
         response ~ fixed1 + fixed2 ,
         random = ~idh(trait):Population + idh(trait):Genotype,
         family = "zipoisson",
         prior = priors,
         rcov = ~idh(trait):units,
         data = mydata )

After fitting the model, the object called model$VCV contains 8 
variance components, which makes a little bit of sense: zero-inflated 
and Poisson parts of two random effects (Population and Genotype), 
plus the same for the residual.

However, the object model$Sol contains estimates for three fixed 
effects (intercept, fixed1, fixed2). I expected there to be twice as 
many, because fixed effects can influence both the logistic and 
Poisson parts of the model. In fact, I'm not sure which process these 
estimates refer to (Poisson or logistic).

Any insight here?

Many thanks,

Josh Van Buskirk
University of Zurich
jvb at zool.uzh.ch



From j.hadfield at ed.ac.uk  Tue May 12 00:14:31 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 11 May 2009 23:14:31 +0100
Subject: [R-sig-ME] zipoisson in MCMCglmm
In-Reply-To: <200905111832.n4BIW8vm029294@idmailgate1.unizh.ch>
References: <200905111832.n4BIW8vm029294@idmailgate1.unizh.ch>
Message-ID: <20090511231431.hf7b863iuc0scwck@www.staffmail.ed.ac.uk>

Hi Josh,

As with the random effect specification you probably want to form  
interactions with the reserved variable "trait". These interactions  
allow you to model fixed effects for both processes.  Something like:

~ trait+trait:fixed1 + trait:fixed2-1

I usually use -1 so that the contrasts are within traits, rather than  
trait2-trait1. For zipossion models I would also save the posterior  
distribution of latent variables (pl=TRUE) to make sure its mixing  
properly by plotting the mcmc traces.

Most importantly, you should probably fix the residual variance of the  
zero-inflation process to something (I use 1) because it cannot be  
identified from the data:

priors <- list(R=list(V=diag(2),n=2, fix=2), G=list(G1=list(V=diag(2),  
n=2), G2=list(V=diag(2), n=2)))

fix=2 fixes the bottom right diagonal matrix starting at [2,2] (in  
this case the zero-inflation variance).

Cheers,

Jarrod

Quoting Josh Van Buskirk <jvb at zool.uzh.ch>:

>
> Dear all,
>
> Does anyone have experience working with Jarrod Hadfield's MCMCglmm
> package with a zero-inflated Poisson distribution? After fitting the
> model, I'm having trouble obtaining the fixed effect coefficients from
> the logistic (inflated) and Poisson parts of the model. I'm interested
> in estimating how the fixed effects influence both processes.
>
> In this example, many random genotypes are sampled within many random
> populations. There are two fixed effects. The response variable is
> highly zero-inflated.
>
> priors <- list(R=list(V=diag(2),n=2), G=list(G1=list(V=diag(2), n=2),
> G2=list(V=diag(2), n=2)))
> model <- MCMCglmm(
>         response ~ fixed1 + fixed2 ,
>         random = ~idh(trait):Population + idh(trait):Genotype,
>         family = "zipoisson",
>         prior = priors,
>         rcov = ~idh(trait):units,
>         data = mydata )
>
> After fitting the model, the object called model$VCV contains 8
> variance components, which makes a little bit of sense: zero-inflated
> and Poisson parts of two random effects (Population and Genotype), plus
> the same for the residual.
>
> However, the object model$Sol contains estimates for three fixed
> effects (intercept, fixed1, fixed2). I expected there to be twice as
> many, because fixed effects can influence both the logistic and Poisson
> parts of the model. In fact, I'm not sure which process these estimates
> refer to (Poisson or logistic).
>
> Any insight here?
>
> Many thanks,
>
> Josh Van Buskirk
> University of Zurich
> jvb at zool.uzh.ch
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Thierry.ONKELINX at inbo.be  Tue May 12 11:57:30 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 12 May 2009 11:57:30 +0200
Subject: [R-sig-ME] Modelling random effects with SITE, YEAR and SPECIES
In-Reply-To: <4F689E07E99C2AE36D96E6FF@bio-mammal03.bio.bris.ac.uk>
References: <4F689E07E99C2AE36D96E6FF@bio-mammal03.bio.bris.ac.uk>
Message-ID: <2E9C414912813E4EB981326983E0A10406828356@inboexch.inbo.be>

Dear Kate,

The error you get with A*SPECIES indicates that you have to few data.
Probabily because not all the combination of A and SPECIES exist in your
dataset. Which was what I feared would happen.

As I meantioned before, adding A as a random slope to the random effect
will give you opnly info on the variability of A between the different
species, but not estimates per species. That's the difference between
random effects and mixed effects.

If the info per species is that important, then I would suggest to build
a model for each species.


HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: CL Pressland [mailto:Kate.Pressland at bristol.ac.uk] 
Verzonden: maandag 11 mei 2009 17:53
Aan: ONKELINX, Thierry; R Mixed Models
Onderwerp: RE: [R-sig-ME] Modelling random effects with SITE, YEAR and
SPECIES

Theirry,

thank you for you informative reply. I have had a go at your suggestions

but have been stumped:

--On 07 May 2009 10:16 +0200 "ONKELINX, Thierry"
<Thierry.ONKELINX at inbo.be> 
wrote:

> Dear Kate,
>
> Adding SPECIES as a random effect indicates that you want to take the
> effect of SPECIES into account but not need to know the effect of the
> individual SPECIES. If you do want to know that effect then you have
to
> add species to fixed effects. Examining the effect of A, B and C on
> species (as a fixed effect) requires interactions between them. The
> model then looks like (A + B + C) * SPECIES + Year + (1|SITE) +
(1|YEAR)
> This will only work if you have sufficiend data.

I tried this approach with data I have that is SPECIES recorded as SITES

over YEARS but when I tried A*SPECIES as a fixed factor I received this 
error message:

"Error in mer_finalize(ans) : Downdated X'X is not positive definite,
88."

I've searched for what this error means but I cannot understand it.

This was written by Douglas Bates in response to [Re: [R] lme4, error in

mer_finalize(ans)] posted 05 Dec 2008:
"That, admittedly obscure, error message relates to the fixed-effects 
specification rt ~ length + length:pos being rank deficient. If you look
at 
the summary of the linear model fit you will see that there are 3 
coefficients that are not determined because of singularities. The lm 
function detects the singularities and fits a lower-rank model.  The
lmer 
function is not as sophisticated. It just detects the singularities and 
quits."

I am unsure what this means or how it translates to my data. In my
example, 
I have 78 "SPECIES" (factor, coded as numbers) and "A" is ordered data
0, 
1, 2. The y variable is number/m. You wrote that this would only work is

you had sufficient data - each species is not recorded each time, so is 
this reduced data the cause i.e. not enough observations for n?

> Another option is to keep species as a random effect and add random
> slopes according to A, B and C. This will allow a different effect of
A,
> B anc C for each species. The model would look like A + B + C + Year +
> (1|SITE) + (1|YEAR) + (A + B + C|SPECIES)

I have tried this way also but I am unsure of the output - it does not
give 
species specific information and therefore I cannot work out which
species 
is more affected by A, only if SPECIES as a whole are affected or not by

each category of A. This is not useful to me as I would like to
determine, 
given the random effects, if A 0, 1, or 2 affect which species in the
data 
set.

Any thoughts?

Kate
>
> HTH,
>
> Thierry
>
>
------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no
more
> than asking him to perform a post-mortem examination: he may be able
to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does
not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From steibelj at msu.edu  Tue May 12 23:22:14 2009
From: steibelj at msu.edu (Juan Pedro Steibel)
Date: Tue, 12 May 2009 17:22:14 -0400
Subject: [R-sig-ME] refit, update and the like
Message-ID: <4A09E886.9050001@msu.edu>

Hello everyone,
I have a questions on refitting models using lmer. Some time ago, I 
asked about refitting the same model (X,Z,R) to many responses and was 
pointed at the refit function as a more efficient alternative to just 
running lmer() function iteratively.
My question now is, suppose I want to change only one column from X (say 
replace covariate X1 with covariate X2), is there a faster way that just 
re-fitting the model with lmer. update() does not seem to be working for 
doing that in my case. I can update to drop only one random effect from 
the model but when I try to drop other terms, I get an error message.

Thanks in advance,
JP

-- 
=============================
Juan Pedro Steibel

Assistant Professor
Statistical Genetics and Genomics

Department of Animal Science & 
Department of Fisheries and Wildlife

Michigan State University
1205-I Anthony Hall
East Lansing, MI
48824 USA 

Phone: 1-517-353-5102
E-mail: steibelj at msu.edu



From bates at stat.wisc.edu  Tue May 12 23:48:18 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 12 May 2009 16:48:18 -0500
Subject: [R-sig-ME] refit, update and the like
In-Reply-To: <4A09E886.9050001@msu.edu>
References: <4A09E886.9050001@msu.edu>
Message-ID: <40e66e0b0905121448sc655708tfa9402709eb1a343@mail.gmail.com>

On Tue, May 12, 2009 at 4:22 PM, Juan Pedro Steibel <steibelj at msu.edu> wrote:
> Hello everyone,
> I have a questions on refitting models using lmer. Some time ago, I asked
> about refitting the same model (X,Z,R) to many responses and was pointed at
> the refit function as a more efficient alternative to just running lmer()
> function iteratively.
> My question now is, suppose I want to change only one column from X (say
> replace covariate X1 with covariate X2), is there a faster way that just
> re-fitting the model with lmer. update() does not seem to be working for
> doing that in my case. I can update to drop only one random effect from the
> model but when I try to drop other terms, I get an error message.

Could you provide a reproducible example please?



From maj at stats.waikato.ac.nz  Wed May 13 06:19:56 2009
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 13 May 2009 16:19:56 +1200
Subject: [R-sig-ME] Ecological mixed model example
In-Reply-To: <20090513075416.vsm6y3a9esk0oo0s@secure.math.canterbury.ac.nz>
References: <49E64573.8080704@math.canterbury.ac.nz>
	<49E65DBD.3010909@stats.waikato.ac.nz>
	<20090513075056.k1iityweeosoc4sg@secure.math.canterbury.ac.nz>
	<20090513075416.vsm6y3a9esk0oo0s@secure.math.canterbury.ac.nz>
Message-ID: <4A0A4A6C.9080100@stats.waikato.ac.nz>

I am trying to help a friend towards an appropriate lmer() analysis of 
her data and help myself understand how to use lmer syntax in the right way.

She says "...here is what I think is a very standard situation in 
ecology....

A normally distributed measure (say bird density) is collected for:

  5 years of data (fixed factor),
  2 seasons within each year (fixed factor),
  3 months within each season (fixed factor)..."

The response is measured at the same six sites at every visit. What 
follows is my interpretation of what she might want, which may not be 
what she really wants, but this may not matter for the purpose of 
creating an example.

I will simulate some data from a known model, then use lmer() to fit the 
model and compare the estimated parameters with those used in the 
simulation.

I would be interested in comments about

a)  whether I have simulated the data from my model correctly

and

b)  whether my lmer syntax is appropriate for my model.


The systematic part of my model is:

  \mu + \beta_{is} + \gamma_{sm}

where i varies over years, s over seasons, and m over months.

(I assume that months are nested within seasons but crossed with years.)

Now let me decide how these coefficients should vary with site. I am
going to assume that the constant term and the year-season term vary
with site but that month-within-season does not.

The random part of the model needs to be generated from a 1 + 5*2 =
11-dimensional multivariate normal. I will assume 1 correlation
parameter, that between two seasons in the same year. All other
correlations are zero.

Values for fixed effects:

Suppose  \mu = 10

    the beta_{i1} are   7, 8, 9, 6, 7.5
    the beta_{i2} are   1, 3, 4, 2, 2.5

    the gamma_{1m} are  0, 2, 1
    the gamma_{2m} are  0, -2, -2

The s.d. parameters are  sigma_mu = 3, sigma_beta = 2, sigma = 0.1
The correlation parameter is 0.4.

Instead of 6 sites I will assume nsite = 60.

I have written the following to generate data and fit the model:

library(mvtnorm)
library(lme4)
V = diag(11)
for ( i in 2:10) {
   V[i,i+1] = 0.4
   V[i+1,i] = 0.4
   }
sig = diag(c(3,rep(2,10)))
V = sig%*%V%*%sig
nsite = 60           #Why not?
sigma = 0.1
theta = c(10,7, 1, 8, 3, 9, 4, 6,2, 7.5,2.5)
P = rmvnorm(nsite,mean=theta,sigma=V)
a =  rep(1:10,rep(3,10))
TH =  cbind(rep(1,30),model.matrix(~factor(a)-1))
gg = rep(c(0,2,1,0,-2,-2),5)
y = as.vector(TH%*%t(P)) + rep(gg,nsite) + rnorm(30*nsite,0,sigma)
year = gl(5,2*3,30*nsite)
season = gl(2,3,30*nsite)
month = gl(3,1,30*nsite)
site = gl(nsite,30,30*nsite)
mod = lmer(y ~ year/season + season/month + (1 + year/season | site) )
summary(mod)


The output I get is

> library(mvtnorm)
> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


        The following object(s) are masked from package:stats :

         xtabs


        The following object(s) are masked from package:base :

         colMeans,
         colSums,
         rcond,
         rowMeans,
         rowSums

> V = diag(11)
> for ( i in 2:10) {
+    V[i,i+1] = 0.4
+    V[i+1,i] = 0.4
+    }
> sig = diag(c(3,rep(2,10)))
> V = sig%*%V%*%sig

> nsite = 60
> sigma = 0.1
> theta = c(10,7, 1, 8, 3, 9, 4, 6,2, 7.5,2.5)
> P = rmvnorm(nsite,mean=theta,sigma=V)
>
> a =  rep(1:10,rep(3,10))
> TH =  cbind(rep(1,30),model.matrix(~factor(a)-1))
> gg = rep(c(0,2,1,0,-2,-2),5)
> y = as.vector(TH%*%t(P)) + rep(gg,nsite) + rnorm(30*nsite,0,sigma)
> year = gl(5,2*3,30*nsite)
> season = gl(2,3,30*nsite)
> month = gl(3,1,30*nsite)
> site = gl(nsite,30,30*nsite)
> mod = lmer(y ~ year/season + season/month + (1 + year/season | site) )
> summary(mod)
Linear mixed model fit by REML
Formula: y ~ year/season + season/month + (1 + year/season | site)
  AIC  BIC logLik deviance REMLdev
1332 1717 -596.1     1153    1192
Random effects:
Groups   Name          Variance  Std.Dev.
Corr
site     (Intercept)   14.874181
3.85671
          year2          8.955943 2.99265
-0.234
          year3          8.751238 2.95825  -0.343
0.504
          year4          8.671103 2.94467  -0.208  0.450
0.422
          year5          7.388752 2.71823  -0.324  0.402  0.516
0.462
          year1:season2  4.283068 2.06956  -0.156  0.638  0.322  0.517
0.358
          year2:season2  5.046195 2.24637  -0.149 -0.469  0.223 -0.053
0.015 -0.308
          year3:season2  5.490231 2.34312   0.078 -0.139 -0.418  0.243
-0.007  0.019 -0.294
          year4:season2  5.353655 2.31380   0.135 -0.204 -0.056 -0.583
0.086 -0.254  0.009 -0.318
          year5:season2  5.400134 2.32382  -0.053  0.047  0.068 -0.044
-0.472 -0.068  0.074 -0.018
Residual                0.010340
0.10169

-0.301

Number of obs: 1800, groups: site, 60

Fixed effects:
                Estimate Std. Error t value
(Intercept)    17.473505   0.497980   35.09
year2           0.731252   0.386499    1.89
year3           1.965976   0.382058    5.15
year4          -1.014649   0.380309   -2.67
year5           0.688820   0.351081    1.96
season2        -6.255910   0.267479  -23.39
year2:season2   1.889409   0.451063    4.19
year3:season2   1.117068   0.400037    2.79
year4:season2   2.564384   0.448766    5.71
year5:season2   1.055936   0.415366    2.54
season1:month2  1.993234   0.008303  240.07
season2:month2 -2.029299   0.008303 -244.41
season1:month3  1.001748   0.008303  120.65
season2:month3 -2.027852   0.008303 -244.24

Correlation of Fixed Effects:
            (Intr) year2  year3  year4  year5  seasn2 yr2:s2 yr3:s2
yr4:s2 yr5:s2 ssn1:2 ssn2:2 ssn1:3
year2
-0.235 


year3       -0.343
0.504 


year4       -0.208  0.450
0.422
year5       -0.324  0.402  0.516
0.462
season2     -0.157  0.637  0.322  0.516
0.358
year2:sesn2 -0.003 -0.680 -0.047 -0.341 -0.203
-0.790
year3:sesn2  0.163 -0.531 -0.531 -0.162 -0.245 -0.654
0.377
year4:sesn2  0.183 -0.515 -0.229 -0.696 -0.156 -0.765  0.575
0.343
year5:sesn2  0.062 -0.376 -0.159 -0.364 -0.572 -0.693  0.572  0.444
0.377
sesn1:mnth2 -0.008  0.000  0.000  0.000  0.000  0.016  0.000  0.000
0.000  0.000
sesn2:mnth2  0.000  0.000  0.000  0.000  0.000 -0.016  0.000  0.000
0.000  0.000  0.000
sesn1:mnth3 -0.008  0.000  0.000  0.000  0.000  0.016  0.000  0.000
0.000  0.000  0.500  0.000
sesn2:mnth3  0.000  0.000  0.000  0.000  0.000 -0.016  0.000  0.000
0.000  0.000  0.000  0.500  0.000
>



The variance estimates for the random effects look large, but maybe
because of the way I have parameterized the model I am estimating some
combination of sigma_mu and sigma_beta?


Cheers,



Murray Jorgensen


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From reinhold.kliegl at gmail.com  Thu May 14 23:38:54 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 14 May 2009 23:38:54 +0200
Subject: [R-sig-ME] Ecological mixed model example
In-Reply-To: <4A0A4A6C.9080100@stats.waikato.ac.nz>
References: <49E64573.8080704@math.canterbury.ac.nz>
	<49E65DBD.3010909@stats.waikato.ac.nz>
	<20090513075056.k1iityweeosoc4sg@secure.math.canterbury.ac.nz>
	<20090513075416.vsm6y3a9esk0oo0s@secure.math.canterbury.ac.nz>
	<4A0A4A6C.9080100@stats.waikato.ac.nz>
Message-ID: <aefe4d0a0905141438n5713922eo3eead642fb5502d6@mail.gmail.com>

The following parameterization recovers both the fixed effects and
also sigma_mu, sigma_beta, and sigma. The correlation does not look
bad either. There are probably also ways of forcing some of the
irrelevant correlations to zero.

Reinhold Kliegl

############################################

....

P = rmvnorm(nsite,mean=theta,sigma=V, method="chol")
...

# specifying seasons nested within year
ys  <- factor(paste(year, season, sep="_"))
cmat.ys <- matrix(c(          -1,  1, rep(0,8),
                            rep(0,2), -1,  1, rep(0,6),
    	                    rep(0,4), -1,  1, rep(0,4),
                            rep(0,6), -1,  1, rep(0,2),
	                    rep(0,8), -1,  1             ),  10,  5)
colnames(cmat.ys) <- c(".s2-s1|y1", ".s2-s1|y2", ".s2-s1|y3",
".s2-s1|y4",".s2-s1|y5")
contrasts(ys, 5) <- cmat.ys

# specifying months nested within season
# contrasting months 2 vs 1 and 3 vs 2 within season
sm  <- factor(paste(season, month, sep="_"))
cmat.sm <- matrix(c(-2/3,  1/3,  1/3,    0,     0,     0,
    	                          -1/3, -1/3,  2/3,    0,     0,     0,
	                              0,     0,     0, -2/3,  1/3,  1/3,
	                              0,     0,     0, -1/3, -1/3,  2/3  ),  6,  4)
colnames(cmat.sm) <- c(".m2-m1|s1", ".m3-m2|s1", ".m2-m1|s2", ".m3-m2|s2")
contrasts(sm, 4) <- cmat.sm

mod.2 = lmer(y ~ ys + sm + (1 | site) + (0 + ys | site) )
print(summary(mod.2), cor=FALSE)

Linear mixed model fit by REML
Formula: y ~ ys + sm + (1 | site) + (0 + ys | site)
  AIC  BIC logLik deviance REMLdev
 1377 1745 -621.4     1200    1243
Random effects:
 Groups   Name  Variance  Std.Dev. Corr
 site   (Intercept) 7.894963 2.80980
 site   ys1_1        7.401678 2.72060
          ys1_2        4.987042 2.23317   0.691
          ys2_1        3.228583 1.79683   0.126  0.256
          ys2_2        5.913934 2.43186  -0.177 -0.205  0.419
          ys3_1      11.414706 3.37857  -0.239 -0.242  0.018  0.651
          ys3_2      10.336715 3.21508   0.109  0.070  0.244  0.426
0.661
          ys4_1        4.113868 2.02827   0.392  0.180 -0.115 -0.159
-0.015  0.521
          ys4_2        4.801364 2.19120   0.391  0.108 -0.268 -0.215
-0.061  0.217  0.503
          ys5_1        2.867584 1.69339   0.186 -0.073 -0.356 -0.190
0.107  0.373  0.097  0.268
          ys5_2        3.745493 1.93533  -0.002 -0.107 -0.049  0.075
0.174  0.224 -0.069  0.046  0.241
 Residual             0.010422 0.10209
Number of obs: 1800, groups: site, 60

Fixed effects:
             Estimate Std. Error t value
(Intercept) 13.892119   0.375663   36.98
ys.s2-s1|y1 -4.447045   0.122316  -36.36
ys.s2-s1|y2 -4.164777   0.120216  -34.64
ys.s2-s1|y3 -3.161133   0.155749  -20.30
ys.s2-s1|y4 -3.047036   0.129606  -23.51
ys.s2-s1|y5 -3.863464   0.136543  -28.29
sm.m2-m1|s1  1.988407   0.008335  238.55
sm.m3-m2|s1 -0.981789   0.008335 -117.79
sm.m2-m1|s2 -1.990586   0.008335 -238.81
sm.m3-m2|s2 -0.008253   0.008335   -0.99

###########################################


On Wed, May 13, 2009 at 6:19 AM, Murray Jorgensen
<maj at stats.waikato.ac.nz> wrote:
> I am trying to help a friend towards an appropriate lmer() analysis of her
> data and help myself understand how to use lmer syntax in the right way.
>
> She says "...here is what I think is a very standard situation in
> ecology....
>
> A normally distributed measure (say bird density) is collected for:
>
> ?5 years of data (fixed factor),
> ?2 seasons within each year (fixed factor),
> ?3 months within each season (fixed factor)..."
>
> The response is measured at the same six sites at every visit. What follows
> is my interpretation of what she might want, which may not be what she
> really wants, but this may not matter for the purpose of creating an
> example.
>
> I will simulate some data from a known model, then use lmer() to fit the
> model and compare the estimated parameters with those used in the
> simulation.
>
> I would be interested in comments about
>
> a) ?whether I have simulated the data from my model correctly
>
> and
>
> b) ?whether my lmer syntax is appropriate for my model.
>
>
> The systematic part of my model is:
>
> ?\mu + \beta_{is} + \gamma_{sm}
>
> where i varies over years, s over seasons, and m over months.
>
> (I assume that months are nested within seasons but crossed with years.)
>
> Now let me decide how these coefficients should vary with site. I am
> going to assume that the constant term and the year-season term vary
> with site but that month-within-season does not.
>
> The random part of the model needs to be generated from a 1 + 5*2 =
> 11-dimensional multivariate normal. I will assume 1 correlation
> parameter, that between two seasons in the same year. All other
> correlations are zero.
>
> Values for fixed effects:
>
> Suppose ?\mu = 10
>
> ? the beta_{i1} are ? 7, 8, 9, 6, 7.5
> ? the beta_{i2} are ? 1, 3, 4, 2, 2.5
>
> ? the gamma_{1m} are ?0, 2, 1
> ? the gamma_{2m} are ?0, -2, -2
>
> The s.d. parameters are ?sigma_mu = 3, sigma_beta = 2, sigma = 0.1
> The correlation parameter is 0.4.
>
> Instead of 6 sites I will assume nsite = 60.
>
> I have written the following to generate data and fit the model:
>
> library(mvtnorm)
> library(lme4)
> V = diag(11)
> for ( i in 2:10) {
> ?V[i,i+1] = 0.4
> ?V[i+1,i] = 0.4
> ?}
> sig = diag(c(3,rep(2,10)))
> V = sig%*%V%*%sig
> nsite = 60 ? ? ? ? ? #Why not?
> sigma = 0.1
> theta = c(10,7, 1, 8, 3, 9, 4, 6,2, 7.5,2.5)
> P = rmvnorm(nsite,mean=theta,sigma=V)
> a = ?rep(1:10,rep(3,10))
> TH = ?cbind(rep(1,30),model.matrix(~factor(a)-1))
> gg = rep(c(0,2,1,0,-2,-2),5)
> y = as.vector(TH%*%t(P)) + rep(gg,nsite) + rnorm(30*nsite,0,sigma)
> year = gl(5,2*3,30*nsite)
> season = gl(2,3,30*nsite)
> month = gl(3,1,30*nsite)
> site = gl(nsite,30,30*nsite)
> mod = lmer(y ~ year/season + season/month + (1 + year/season | site) )
> summary(mod)
>
>
> The output I get is
>
>> library(mvtnorm)
>> library(lme4)
>
>
>> V = diag(11)
>> for ( i in 2:10) {
>
> + ? ?V[i,i+1] = 0.4
> + ? ?V[i+1,i] = 0.4
> + ? ?}
>>
>> sig = diag(c(3,rep(2,10)))
>> V = sig%*%V%*%sig
>
>> nsite = 60
>> sigma = 0.1
>> theta = c(10,7, 1, 8, 3, 9, 4, 6,2, 7.5,2.5)
>> P = rmvnorm(nsite,mean=theta,sigma=V)
>>
>> a = ?rep(1:10,rep(3,10))
>> TH = ?cbind(rep(1,30),model.matrix(~factor(a)-1))
>> gg = rep(c(0,2,1,0,-2,-2),5)
>> y = as.vector(TH%*%t(P)) + rep(gg,nsite) + rnorm(30*nsite,0,sigma)
>> year = gl(5,2*3,30*nsite)
>> season = gl(2,3,30*nsite)
>> month = gl(3,1,30*nsite)
>> site = gl(nsite,30,30*nsite)
>> mod = lmer(y ~ year/season + season/month + (1 + year/season | site) )
>> summary(mod)
>
> Linear mixed model fit by REML
> Formula: y ~ year/season + season/month + (1 + year/season | site)
> ?AIC ?BIC logLik deviance REMLdev
> 1332 1717 -596.1 ? ? 1153 ? ?1192
> Random effects:
> Groups ? Name ? ? ? ? ?Variance ?Std.Dev.
> Corr
> site ? ? (Intercept) ? 14.874181
> 3.85671
> ? ? ? ? year2 ? ? ? ? ?8.955943 2.99265
> -0.234
> ? ? ? ? year3 ? ? ? ? ?8.751238 2.95825 ?-0.343
> 0.504
> ? ? ? ? year4 ? ? ? ? ?8.671103 2.94467 ?-0.208 ?0.450
> 0.422
> ? ? ? ? year5 ? ? ? ? ?7.388752 2.71823 ?-0.324 ?0.402 ?0.516
> 0.462
> ? ? ? ? year1:season2 ?4.283068 2.06956 ?-0.156 ?0.638 ?0.322 ?0.517
> 0.358
> ? ? ? ? year2:season2 ?5.046195 2.24637 ?-0.149 -0.469 ?0.223 -0.053
> 0.015 -0.308
> ? ? ? ? year3:season2 ?5.490231 2.34312 ? 0.078 -0.139 -0.418 ?0.243
> -0.007 ?0.019 -0.294
> ? ? ? ? year4:season2 ?5.353655 2.31380 ? 0.135 -0.204 -0.056 -0.583
> 0.086 -0.254 ?0.009 -0.318
> ? ? ? ? year5:season2 ?5.400134 2.32382 ?-0.053 ?0.047 ?0.068 -0.044
> -0.472 -0.068 ?0.074 -0.018
> Residual ? ? ? ? ? ? ? ?0.010340
> 0.10169
>
> -0.301
>
> Number of obs: 1800, groups: site, 60
>
> Fixed effects:
> ? ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) ? ?17.473505 ? 0.497980 ? 35.09
> year2 ? ? ? ? ? 0.731252 ? 0.386499 ? ?1.89
> year3 ? ? ? ? ? 1.965976 ? 0.382058 ? ?5.15
> year4 ? ? ? ? ?-1.014649 ? 0.380309 ? -2.67
> year5 ? ? ? ? ? 0.688820 ? 0.351081 ? ?1.96
> season2 ? ? ? ?-6.255910 ? 0.267479 ?-23.39
> year2:season2 ? 1.889409 ? 0.451063 ? ?4.19
> year3:season2 ? 1.117068 ? 0.400037 ? ?2.79
> year4:season2 ? 2.564384 ? 0.448766 ? ?5.71
> year5:season2 ? 1.055936 ? 0.415366 ? ?2.54
> season1:month2 ?1.993234 ? 0.008303 ?240.07
> season2:month2 -2.029299 ? 0.008303 -244.41
> season1:month3 ?1.001748 ? 0.008303 ?120.65
> season2:month3 -2.027852 ? 0.008303 -244.24
>
> Correlation of Fixed Effects:
> ? ? ? ? ? (Intr) year2 ?year3 ?year4 ?year5 ?seasn2 yr2:s2 yr3:s2
> yr4:s2 yr5:s2 ssn1:2 ssn2:2 ssn1:3
> year2
> -0.235
>
> year3 ? ? ? -0.343
> 0.504
>
> year4 ? ? ? -0.208 ?0.450
> 0.422
> year5 ? ? ? -0.324 ?0.402 ?0.516
> 0.462
> season2 ? ? -0.157 ?0.637 ?0.322 ?0.516
> 0.358
> year2:sesn2 -0.003 -0.680 -0.047 -0.341 -0.203
> -0.790
> year3:sesn2 ?0.163 -0.531 -0.531 -0.162 -0.245 -0.654
> 0.377
> year4:sesn2 ?0.183 -0.515 -0.229 -0.696 -0.156 -0.765 ?0.575
> 0.343
> year5:sesn2 ?0.062 -0.376 -0.159 -0.364 -0.572 -0.693 ?0.572 ?0.444
> 0.377
> sesn1:mnth2 -0.008 ?0.000 ?0.000 ?0.000 ?0.000 ?0.016 ?0.000 ?0.000
> 0.000 ?0.000
> sesn2:mnth2 ?0.000 ?0.000 ?0.000 ?0.000 ?0.000 -0.016 ?0.000 ?0.000
> 0.000 ?0.000 ?0.000
> sesn1:mnth3 -0.008 ?0.000 ?0.000 ?0.000 ?0.000 ?0.016 ?0.000 ?0.000
> 0.000 ?0.000 ?0.500 ?0.000
> sesn2:mnth3 ?0.000 ?0.000 ?0.000 ?0.000 ?0.000 -0.016 ?0.000 ?0.000
> 0.000 ?0.000 ?0.000 ?0.500 ?0.000
>>
>
>
>
> The variance estimates for the random effects look large, but maybe
> because of the way I have parameterized the model I am estimating some
> combination of sigma_mu and sigma_beta?
>
>
> Cheers,
>
>
>
> Murray Jorgensen
>
>
> --
> Dr Murray Jorgensen ? ? ?http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Fax 7 838 4155
> Phone ?+64 7 838 4773 wk ? ?Home +64 7 825 0441 ? Mobile 021 0200 8350
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From reinhold.kliegl at gmail.com  Fri May 15 01:11:46 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 15 May 2009 01:11:46 +0200
Subject: [R-sig-ME] Ecological mixed model example
In-Reply-To: <aefe4d0a0905141438n5713922eo3eead642fb5502d6@mail.gmail.com>
References: <49E64573.8080704@math.canterbury.ac.nz>
	<49E65DBD.3010909@stats.waikato.ac.nz>
	<20090513075056.k1iityweeosoc4sg@secure.math.canterbury.ac.nz>
	<20090513075416.vsm6y3a9esk0oo0s@secure.math.canterbury.ac.nz>
	<4A0A4A6C.9080100@stats.waikato.ac.nz>
	<aefe4d0a0905141438n5713922eo3eead642fb5502d6@mail.gmail.com>
Message-ID: <aefe4d0a0905141611y4e20b000o51294db550830108@mail.gmail.com>

Two more things:
(1) I accidentally left out the main effects for "year" in the
fixed-effect part of the lmer model. So the call should actually be:
> mod.2 = lmer(y ~ year + ys + sm + (1 | site) + (0 + ys | site) )
or for direct estimates of (almost all) cell means
> mod.3 = lmer(y ~ 0 + ys + sm + (1 | site) + (0 + ys | site) )
In real data, year should probably be specified with trends, e.g., as
poly(year, 2).

(2)  I think , in principle, replacing
> mod = lmer(y ~ year/season + season/month + (1 + year/season | site) )
with
> mod = lmer(y ~ year/season + season/month + (1 | site) + (0 + year/season | site) )
should also work for the sigmas in your script. I did run into a
convergence problem with this specification.
Also, the fixed effects were not very transparent to me in this specification.

Best
Reinhold Kliegl


On Thu, May 14, 2009 at 11:38 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> The following parameterization recovers both the fixed effects and
> also sigma_mu, sigma_beta, and sigma. The correlation does not look
> bad either. There are probably also ways of forcing some of the
> irrelevant correlations to zero.
>
> Reinhold Kliegl
>
> ############################################
>
> ....
>
> P = rmvnorm(nsite,mean=theta,sigma=V, method="chol")
> ...
>
> # specifying seasons nested within year
> ys ?<- factor(paste(year, season, sep="_"))
> cmat.ys <- matrix(c( ? ? ? ? ?-1, ?1, rep(0,8),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?rep(0,2), -1, ?1, rep(0,6),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?rep(0,4), -1, ?1, rep(0,4),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?rep(0,6), -1, ?1, rep(0,2),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?rep(0,8), -1, ?1 ? ? ? ? ? ? ), ?10, ?5)
> colnames(cmat.ys) <- c(".s2-s1|y1", ".s2-s1|y2", ".s2-s1|y3",
> ".s2-s1|y4",".s2-s1|y5")
> contrasts(ys, 5) <- cmat.ys
>
> # specifying months nested within season
> # contrasting months 2 vs 1 and 3 vs 2 within season
> sm ?<- factor(paste(season, month, sep="_"))
> cmat.sm <- matrix(c(-2/3, ?1/3, ?1/3, ? ?0, ? ? 0, ? ? 0,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?-1/3, -1/3, ?2/3, ? ?0, ? ? 0, ? ? 0,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?0, ? ? 0, ? ? 0, -2/3, ?1/3, ?1/3,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?0, ? ? 0, ? ? 0, -1/3, -1/3, ?2/3 ?), ?6, ?4)
> colnames(cmat.sm) <- c(".m2-m1|s1", ".m3-m2|s1", ".m2-m1|s2", ".m3-m2|s2")
> contrasts(sm, 4) <- cmat.sm
>
> mod.2 = lmer(y ~ ys + sm + (1 | site) + (0 + ys | site) )
> print(summary(mod.2), cor=FALSE)
>
> Linear mixed model fit by REML
> Formula: y ~ ys + sm + (1 | site) + (0 + ys | site)
> ?AIC ?BIC logLik deviance REMLdev
> ?1377 1745 -621.4 ? ? 1200 ? ?1243
> Random effects:
> ?Groups ? Name ?Variance ?Std.Dev. Corr
> ?site ? (Intercept) 7.894963 2.80980
> ?site ? ys1_1 ? ? ? ?7.401678 2.72060
> ? ? ? ? ?ys1_2 ? ? ? ?4.987042 2.23317 ? 0.691
> ? ? ? ? ?ys2_1 ? ? ? ?3.228583 1.79683 ? 0.126 ?0.256
> ? ? ? ? ?ys2_2 ? ? ? ?5.913934 2.43186 ?-0.177 -0.205 ?0.419
> ? ? ? ? ?ys3_1 ? ? ?11.414706 3.37857 ?-0.239 -0.242 ?0.018 ?0.651
> ? ? ? ? ?ys3_2 ? ? ?10.336715 3.21508 ? 0.109 ?0.070 ?0.244 ?0.426
> 0.661
> ? ? ? ? ?ys4_1 ? ? ? ?4.113868 2.02827 ? 0.392 ?0.180 -0.115 -0.159
> -0.015 ?0.521
> ? ? ? ? ?ys4_2 ? ? ? ?4.801364 2.19120 ? 0.391 ?0.108 -0.268 -0.215
> -0.061 ?0.217 ?0.503
> ? ? ? ? ?ys5_1 ? ? ? ?2.867584 1.69339 ? 0.186 -0.073 -0.356 -0.190
> 0.107 ?0.373 ?0.097 ?0.268
> ? ? ? ? ?ys5_2 ? ? ? ?3.745493 1.93533 ?-0.002 -0.107 -0.049 ?0.075
> 0.174 ?0.224 -0.069 ?0.046 ?0.241
> ?Residual ? ? ? ? ? ? 0.010422 0.10209
> Number of obs: 1800, groups: site, 60
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) 13.892119 ? 0.375663 ? 36.98
> ys.s2-s1|y1 -4.447045 ? 0.122316 ?-36.36
> ys.s2-s1|y2 -4.164777 ? 0.120216 ?-34.64
> ys.s2-s1|y3 -3.161133 ? 0.155749 ?-20.30
> ys.s2-s1|y4 -3.047036 ? 0.129606 ?-23.51
> ys.s2-s1|y5 -3.863464 ? 0.136543 ?-28.29
> sm.m2-m1|s1 ?1.988407 ? 0.008335 ?238.55
> sm.m3-m2|s1 -0.981789 ? 0.008335 -117.79
> sm.m2-m1|s2 -1.990586 ? 0.008335 -238.81
> sm.m3-m2|s2 -0.008253 ? 0.008335 ? -0.99
>
> ###########################################
>
>
> On Wed, May 13, 2009 at 6:19 AM, Murray Jorgensen
> <maj at stats.waikato.ac.nz> wrote:
>> I am trying to help a friend towards an appropriate lmer() analysis of her
>> data and help myself understand how to use lmer syntax in the right way.
>>
>> She says "...here is what I think is a very standard situation in
>> ecology....
>>
>> A normally distributed measure (say bird density) is collected for:
>>
>> ?5 years of data (fixed factor),
>> ?2 seasons within each year (fixed factor),
>> ?3 months within each season (fixed factor)..."
>>
>> The response is measured at the same six sites at every visit. What follows
>> is my interpretation of what she might want, which may not be what she
>> really wants, but this may not matter for the purpose of creating an
>> example.
>>
>> I will simulate some data from a known model, then use lmer() to fit the
>> model and compare the estimated parameters with those used in the
>> simulation.
>>
>> I would be interested in comments about
>>
>> a) ?whether I have simulated the data from my model correctly
>>
>> and
>>
>> b) ?whether my lmer syntax is appropriate for my model.
>>
>>
>> The systematic part of my model is:
>>
>> ?\mu + \beta_{is} + \gamma_{sm}
>>
>> where i varies over years, s over seasons, and m over months.
>>
>> (I assume that months are nested within seasons but crossed with years.)
>>
>> Now let me decide how these coefficients should vary with site. I am
>> going to assume that the constant term and the year-season term vary
>> with site but that month-within-season does not.
>>
>> The random part of the model needs to be generated from a 1 + 5*2 =
>> 11-dimensional multivariate normal. I will assume 1 correlation
>> parameter, that between two seasons in the same year. All other
>> correlations are zero.
>>
>> Values for fixed effects:
>>
>> Suppose ?\mu = 10
>>
>> ? the beta_{i1} are ? 7, 8, 9, 6, 7.5
>> ? the beta_{i2} are ? 1, 3, 4, 2, 2.5
>>
>> ? the gamma_{1m} are ?0, 2, 1
>> ? the gamma_{2m} are ?0, -2, -2
>>
>> The s.d. parameters are ?sigma_mu = 3, sigma_beta = 2, sigma = 0.1
>> The correlation parameter is 0.4.
>>
>> Instead of 6 sites I will assume nsite = 60.
>>
>> I have written the following to generate data and fit the model:
>>
>> library(mvtnorm)
>> library(lme4)
>> V = diag(11)
>> for ( i in 2:10) {
>> ?V[i,i+1] = 0.4
>> ?V[i+1,i] = 0.4
>> ?}
>> sig = diag(c(3,rep(2,10)))
>> V = sig%*%V%*%sig
>> nsite = 60 ? ? ? ? ? #Why not?
>> sigma = 0.1
>> theta = c(10,7, 1, 8, 3, 9, 4, 6,2, 7.5,2.5)
>> P = rmvnorm(nsite,mean=theta,sigma=V)
>> a = ?rep(1:10,rep(3,10))
>> TH = ?cbind(rep(1,30),model.matrix(~factor(a)-1))
>> gg = rep(c(0,2,1,0,-2,-2),5)
>> y = as.vector(TH%*%t(P)) + rep(gg,nsite) + rnorm(30*nsite,0,sigma)
>> year = gl(5,2*3,30*nsite)
>> season = gl(2,3,30*nsite)
>> month = gl(3,1,30*nsite)
>> site = gl(nsite,30,30*nsite)
>> mod = lmer(y ~ year/season + season/month + (1 + year/season | site) )
>> summary(mod)
>>
>>
>> The output I get is
>>
>>> library(mvtnorm)
>>> library(lme4)
>>
>>
>>> V = diag(11)
>>> for ( i in 2:10) {
>>
>> + ? ?V[i,i+1] = 0.4
>> + ? ?V[i+1,i] = 0.4
>> + ? ?}
>>>
>>> sig = diag(c(3,rep(2,10)))
>>> V = sig%*%V%*%sig
>>
>>> nsite = 60
>>> sigma = 0.1
>>> theta = c(10,7, 1, 8, 3, 9, 4, 6,2, 7.5,2.5)
>>> P = rmvnorm(nsite,mean=theta,sigma=V)
>>>
>>> a = ?rep(1:10,rep(3,10))
>>> TH = ?cbind(rep(1,30),model.matrix(~factor(a)-1))
>>> gg = rep(c(0,2,1,0,-2,-2),5)
>>> y = as.vector(TH%*%t(P)) + rep(gg,nsite) + rnorm(30*nsite,0,sigma)
>>> year = gl(5,2*3,30*nsite)
>>> season = gl(2,3,30*nsite)
>>> month = gl(3,1,30*nsite)
>>> site = gl(nsite,30,30*nsite)
>>> mod = lmer(y ~ year/season + season/month + (1 + year/season | site) )
>>> summary(mod)
>>
>> Linear mixed model fit by REML
>> Formula: y ~ year/season + season/month + (1 + year/season | site)
>> ?AIC ?BIC logLik deviance REMLdev
>> 1332 1717 -596.1 ? ? 1153 ? ?1192
>> Random effects:
>> Groups ? Name ? ? ? ? ?Variance ?Std.Dev.
>> Corr
>> site ? ? (Intercept) ? 14.874181
>> 3.85671
>> ? ? ? ? year2 ? ? ? ? ?8.955943 2.99265
>> -0.234
>> ? ? ? ? year3 ? ? ? ? ?8.751238 2.95825 ?-0.343
>> 0.504
>> ? ? ? ? year4 ? ? ? ? ?8.671103 2.94467 ?-0.208 ?0.450
>> 0.422
>> ? ? ? ? year5 ? ? ? ? ?7.388752 2.71823 ?-0.324 ?0.402 ?0.516
>> 0.462
>> ? ? ? ? year1:season2 ?4.283068 2.06956 ?-0.156 ?0.638 ?0.322 ?0.517
>> 0.358
>> ? ? ? ? year2:season2 ?5.046195 2.24637 ?-0.149 -0.469 ?0.223 -0.053
>> 0.015 -0.308
>> ? ? ? ? year3:season2 ?5.490231 2.34312 ? 0.078 -0.139 -0.418 ?0.243
>> -0.007 ?0.019 -0.294
>> ? ? ? ? year4:season2 ?5.353655 2.31380 ? 0.135 -0.204 -0.056 -0.583
>> 0.086 -0.254 ?0.009 -0.318
>> ? ? ? ? year5:season2 ?5.400134 2.32382 ?-0.053 ?0.047 ?0.068 -0.044
>> -0.472 -0.068 ?0.074 -0.018
>> Residual ? ? ? ? ? ? ? ?0.010340
>> 0.10169
>>
>> -0.301
>>
>> Number of obs: 1800, groups: site, 60
>>
>> Fixed effects:
>> ? ? ? ? ? ? ? Estimate Std. Error t value
>> (Intercept) ? ?17.473505 ? 0.497980 ? 35.09
>> year2 ? ? ? ? ? 0.731252 ? 0.386499 ? ?1.89
>> year3 ? ? ? ? ? 1.965976 ? 0.382058 ? ?5.15
>> year4 ? ? ? ? ?-1.014649 ? 0.380309 ? -2.67
>> year5 ? ? ? ? ? 0.688820 ? 0.351081 ? ?1.96
>> season2 ? ? ? ?-6.255910 ? 0.267479 ?-23.39
>> year2:season2 ? 1.889409 ? 0.451063 ? ?4.19
>> year3:season2 ? 1.117068 ? 0.400037 ? ?2.79
>> year4:season2 ? 2.564384 ? 0.448766 ? ?5.71
>> year5:season2 ? 1.055936 ? 0.415366 ? ?2.54
>> season1:month2 ?1.993234 ? 0.008303 ?240.07
>> season2:month2 -2.029299 ? 0.008303 -244.41
>> season1:month3 ?1.001748 ? 0.008303 ?120.65
>> season2:month3 -2.027852 ? 0.008303 -244.24
>>
>> Correlation of Fixed Effects:
>> ? ? ? ? ? (Intr) year2 ?year3 ?year4 ?year5 ?seasn2 yr2:s2 yr3:s2
>> yr4:s2 yr5:s2 ssn1:2 ssn2:2 ssn1:3
>> year2
>> -0.235
>>
>> year3 ? ? ? -0.343
>> 0.504
>>
>> year4 ? ? ? -0.208 ?0.450
>> 0.422
>> year5 ? ? ? -0.324 ?0.402 ?0.516
>> 0.462
>> season2 ? ? -0.157 ?0.637 ?0.322 ?0.516
>> 0.358
>> year2:sesn2 -0.003 -0.680 -0.047 -0.341 -0.203
>> -0.790
>> year3:sesn2 ?0.163 -0.531 -0.531 -0.162 -0.245 -0.654
>> 0.377
>> year4:sesn2 ?0.183 -0.515 -0.229 -0.696 -0.156 -0.765 ?0.575
>> 0.343
>> year5:sesn2 ?0.062 -0.376 -0.159 -0.364 -0.572 -0.693 ?0.572 ?0.444
>> 0.377
>> sesn1:mnth2 -0.008 ?0.000 ?0.000 ?0.000 ?0.000 ?0.016 ?0.000 ?0.000
>> 0.000 ?0.000
>> sesn2:mnth2 ?0.000 ?0.000 ?0.000 ?0.000 ?0.000 -0.016 ?0.000 ?0.000
>> 0.000 ?0.000 ?0.000
>> sesn1:mnth3 -0.008 ?0.000 ?0.000 ?0.000 ?0.000 ?0.016 ?0.000 ?0.000
>> 0.000 ?0.000 ?0.500 ?0.000
>> sesn2:mnth3 ?0.000 ?0.000 ?0.000 ?0.000 ?0.000 -0.016 ?0.000 ?0.000
>> 0.000 ?0.000 ?0.000 ?0.500 ?0.000
>>>
>>
>>
>>
>> The variance estimates for the random effects look large, but maybe
>> because of the way I have parameterized the model I am estimating some
>> combination of sigma_mu and sigma_beta?
>>
>>
>> Cheers,
>>
>>
>>
>> Murray Jorgensen
>>
>>
>> --
>> Dr Murray Jorgensen ? ? ?http://www.stats.waikato.ac.nz/Staff/maj.html
>> Department of Statistics, University of Waikato, Hamilton, New Zealand
>> Email: maj at waikato.ac.nz ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Fax 7 838 4155
>> Phone ?+64 7 838 4773 wk ? ?Home +64 7 825 0441 ? Mobile 021 0200 8350
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From john.maindonald at anu.edu.au  Fri May 15 03:24:08 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 15 May 2009 11:24:08 +1000
Subject: [R-sig-ME] Side effects from mcmcsamp()
Message-ID: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>

Dear Douglas -
The following is at the very least a serious trap!  The output
from VarCorr() and print() changes remarkably after running
mcmcsamp() with the lmer object as argument.  The estimate
of sigma is always (for these data) high, but roughly in the
middle of the range of values that come out of ant111b.samp at sigma

I have also been able to reproduce this behaviour
(a) under lme4_0.999375-28 [below, I use 30]
(b) under Mac OSX.  In fact, I thought initially that this
was an OSX problem!

While mcmcsamp() is in view, it would be very helpful
to have a progress report on where it is at.

Many thanks
John Maindonald.

I run the following code:

library(DAAG)
library(lme4)
ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
ant111b.lmer
VarCorr(ant111b.lmer)
ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)

## Now, extract the VarCorr and summary correlations
VarCorr(ant111b.lmer)
summary(ant111b.lmer)

 > ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
 > ant111b.lmer
Linear mixed model fit by REML
Formula: harvwt ~ 1 + (1 | site)
   Data: ant111b
   AIC   BIC logLik deviance REMLdev
100.4 104.8 -47.21    95.08   94.42
Random effects:
Groups   Name        Variance Std.Dev.
site     (Intercept) 2.36773  1.53874
Residual             0.57754  0.75996
Number of obs: 32, groups: site, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.2917     0.5603   7.659
 > library(DAAG)
 > library(lme4)
 > ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
 > ant111b.lmer
Linear mixed model fit by REML
Formula: harvwt ~ 1 + (1 | site)
   Data: ant111b
   AIC   BIC logLik deviance REMLdev
100.4 104.8 -47.21    95.08   94.42
Random effects:
Groups   Name        Variance Std.Dev.
site     (Intercept) 2.36773  1.53874
Residual             0.57754  0.75996
Number of obs: 32, groups: site, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.2917     0.5603   7.659
 > ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
 > VarCorr(ant111b.lmer)
$site
            (Intercept)
(Intercept)    8.363436
attr(,"stddev")
(Intercept)
   2.891961
attr(,"correlation")
            (Intercept)
(Intercept)           1

attr(,"sc")
sigmaREML
1.428289
 > summary(ant111b.lmer)
Linear mixed model fit by REML
Formula: harvwt ~ 1 + (1 | site)
   Data: ant111b
   AIC   BIC logLik deviance REMLdev
112.1 116.5 -53.04    105.7   106.1
Random effects:
Groups   Name        Variance Std.Dev.
site     (Intercept) 8.3634   2.8920
Residual             2.0400   1.4283
Number of obs: 32, groups: site, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.2917     0.4171   10.29

 > sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States. 
1252;LC_MONETARY=English_United States. 
1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-30   Matrix_0.999375-26 lattice_0.17-22
[4] DAAG_0.99-1        MASS_7.2-47

loaded via a namespace (and not attached):
[1] grid_2.9.0



John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From robert.espesser at lpl-aix.fr  Fri May 15 11:30:25 2009
From: robert.espesser at lpl-aix.fr (espesser)
Date: Fri, 15 May 2009 11:30:25 +0200
Subject: [R-sig-ME] Side effects from mcmcsamp()
In-Reply-To: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
References: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
Message-ID: <4A0D3631.6030100@lpl-aix.fr>

I think it's due to the same bug discussed in:

http://finzi.psych.upenn.edu/R/Rhelp08/2009-February/002001.html

R. Espesser
Laboratoire Parole et Langage
CNRS/Universit? Aix-Marseille


John Maindonald a ?crit :
> Dear Douglas -
> The following is at the very least a serious trap!  The output
> from VarCorr() and print() changes remarkably after running
> mcmcsamp() with the lmer object as argument.  The estimate
> of sigma is always (for these data) high, but roughly in the
> middle of the range of values that come out of ant111b.samp at sigma
>
> I have also been able to reproduce this behaviour
> (a) under lme4_0.999375-28 [below, I use 30]
> (b) under Mac OSX.  In fact, I thought initially that this
> was an OSX problem!
>
> While mcmcsamp() is in view, it would be very helpful
> to have a progress report on where it is at.
>
> Many thanks
> John Maindonald.
>
> I run the following code:
>
> library(DAAG)
> library(lme4)
> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
> ant111b.lmer
> VarCorr(ant111b.lmer)
> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>
> ## Now, extract the VarCorr and summary correlations
> VarCorr(ant111b.lmer)
> summary(ant111b.lmer)
>
> > ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
> > ant111b.lmer
> Linear mixed model fit by REML
> Formula: harvwt ~ 1 + (1 | site)
>   Data: ant111b
>   AIC   BIC logLik deviance REMLdev
> 100.4 104.8 -47.21    95.08   94.42
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 2.36773  1.53874
> Residual             0.57754  0.75996
> Number of obs: 32, groups: site, 8
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   4.2917     0.5603   7.659
> > library(DAAG)
> > library(lme4)
> > ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
> > ant111b.lmer
> Linear mixed model fit by REML
> Formula: harvwt ~ 1 + (1 | site)
>   Data: ant111b
>   AIC   BIC logLik deviance REMLdev
> 100.4 104.8 -47.21    95.08   94.42
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 2.36773  1.53874
> Residual             0.57754  0.75996
> Number of obs: 32, groups: site, 8
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   4.2917     0.5603   7.659
> > ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
> > VarCorr(ant111b.lmer)
> $site
>            (Intercept)
> (Intercept)    8.363436
> attr(,"stddev")
> (Intercept)
>   2.891961
> attr(,"correlation")
>            (Intercept)
> (Intercept)           1
>
> attr(,"sc")
> sigmaREML
> 1.428289
> > summary(ant111b.lmer)
> Linear mixed model fit by REML
> Formula: harvwt ~ 1 + (1 | site)
>   Data: ant111b
>   AIC   BIC logLik deviance REMLdev
> 112.1 116.5 -53.04    105.7   106.1
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 8.3634   2.8920
> Residual             2.0400   1.4283
> Number of obs: 32, groups: site, 8
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   4.2917     0.4171   10.29
>
> > sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
> States.1252;LC_MONETARY=English_United 
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-30   Matrix_0.999375-26 lattice_0.17-22
> [4] DAAG_0.99-1        MASS_7.2-47
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0
>
>
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From steibelj at msu.edu  Fri May 15 22:16:53 2009
From: steibelj at msu.edu (Juan Pedro Steibel)
Date: Fri, 15 May 2009 16:16:53 -0400
Subject: [R-sig-ME] Side effects from mcmcsamp()
In-Reply-To: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
References: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
Message-ID: <4A0DCDB5.3010003@msu.edu>

Hello,
I noticed this a wile ago. One thing that occurred to me was to copy to 
another object before running mcmcsamp, example:
obmix0<-obmix
where obmix is the lmer object.
then do: mcmcsamp(obmix)....
For some reason obmix0 gets modified too.

It's been a while since I checked this so it may have been fixed.

Anyways, a way around this is to extract all the info needed from your 
lmer object to other variables before running mcmcsamp, that's what I do 
now and it works fine.
Thanks
JP



John Maindonald wrote:
> Dear Douglas -
> The following is at the very least a serious trap!  The output
> from VarCorr() and print() changes remarkably after running
> mcmcsamp() with the lmer object as argument.  The estimate
> of sigma is always (for these data) high, but roughly in the
> middle of the range of values that come out of ant111b.samp at sigma
>
> I have also been able to reproduce this behaviour
> (a) under lme4_0.999375-28 [below, I use 30]
> (b) under Mac OSX.  In fact, I thought initially that this
> was an OSX problem!
>
> While mcmcsamp() is in view, it would be very helpful
> to have a progress report on where it is at.
>
> Many thanks
> John Maindonald.
>
> I run the following code:
>
> library(DAAG)
> library(lme4)
> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
> ant111b.lmer
> VarCorr(ant111b.lmer)
> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>
> ## Now, extract the VarCorr and summary correlations
> VarCorr(ant111b.lmer)
> summary(ant111b.lmer)
>
> > ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
> > ant111b.lmer
> Linear mixed model fit by REML
> Formula: harvwt ~ 1 + (1 | site)
>   Data: ant111b
>   AIC   BIC logLik deviance REMLdev
> 100.4 104.8 -47.21    95.08   94.42
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 2.36773  1.53874
> Residual             0.57754  0.75996
> Number of obs: 32, groups: site, 8
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   4.2917     0.5603   7.659
> > library(DAAG)
> > library(lme4)
> > ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
> > ant111b.lmer
> Linear mixed model fit by REML
> Formula: harvwt ~ 1 + (1 | site)
>   Data: ant111b
>   AIC   BIC logLik deviance REMLdev
> 100.4 104.8 -47.21    95.08   94.42
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 2.36773  1.53874
> Residual             0.57754  0.75996
> Number of obs: 32, groups: site, 8
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   4.2917     0.5603   7.659
> > ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
> > VarCorr(ant111b.lmer)
> $site
>            (Intercept)
> (Intercept)    8.363436
> attr(,"stddev")
> (Intercept)
>   2.891961
> attr(,"correlation")
>            (Intercept)
> (Intercept)           1
>
> attr(,"sc")
> sigmaREML
> 1.428289
> > summary(ant111b.lmer)
> Linear mixed model fit by REML
> Formula: harvwt ~ 1 + (1 | site)
>   Data: ant111b
>   AIC   BIC logLik deviance REMLdev
> 112.1 116.5 -53.04    105.7   106.1
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 8.3634   2.8920
> Residual             2.0400   1.4283
> Number of obs: 32, groups: site, 8
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   4.2917     0.4171   10.29
>
> > sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
> States.1252;LC_MONETARY=English_United 
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-30   Matrix_0.999375-26 lattice_0.17-22
> [4] DAAG_0.99-1        MASS_7.2-47
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0
>
>
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
=============================
Juan Pedro Steibel

Assistant Professor
Statistical Genetics and Genomics

Department of Animal Science & 
Department of Fisheries and Wildlife

Michigan State University
1205-I Anthony Hall
East Lansing, MI
48824 USA 

Phone: 1-517-353-5102
E-mail: steibelj at msu.edu



From bolker at ufl.edu  Fri May 15 23:52:36 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 15 May 2009 17:52:36 -0400
Subject: [R-sig-ME] Side effects from mcmcsamp()
In-Reply-To: <4A0DCDB5.3010003@msu.edu>
References: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
	<4A0DCDB5.3010003@msu.edu>
Message-ID: <4A0DE424.6020706@ufl.edu>

Juan Pedro Steibel wrote:
> Hello,
> I noticed this a wile ago. One thing that occurred to me was to copy to 
> another object before running mcmcsamp, example:
> obmix0<-obmix
> where obmix is the lmer object.
> then do: mcmcsamp(obmix)....
> For some reason obmix0 gets modified too.

  Yeah, this aspect of the whole thing mystified me.
I understand that mcmcsamp does nasty things internally,
but I don't understand why it would also do them to a *copy* of the
object.  I poked around in R manuals (language definitions etc.) but
didn't manage to find anything useful for understanding this.  I can
imagine there's some slick optimization where R says to itself "gee,
this object hasn't been modified from its original yet, so I won't
actually make a new copy ..." but is fooled by the internal
manipulation.  ("Don't anthromorphize computers -- they get really mad"
:-) )

> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 209832  5.7     467875 12.5   350000  9.4
Vcells 476846  3.7    1165368  8.9  1028740  7.9

## make a big object -- 70 Mb
> z <- runif(1e7)
> gc()
           used (Mb) gc trigger (Mb) max used (Mb)
Ncells   209821  5.7     467875 12.5   350000  9.4
Vcells 10476828 80.0   11888118 90.7 10477151 80.0

## make a copy
> z2 <- z

## Vcells only increases a little
> gc()
           used (Mb) gc trigger (Mb) max used (Mb)
Ncells   209826  5.7     467875 12.5   350000  9.4
Vcells 10476829 80.0   12562523 95.9 10477151 80.0

## ditto
> z3 <- z2
> gc()
           used (Mb) gc trigger  (Mb) max used (Mb)
Ncells   209831  5.7     467875  12.5   350000  9.4
Vcells 10476830 80.0   13270649 101.3 10477151 80.0

## tweak z3
> z3[1] <- z3[1]+1
> gc()
           used  (Mb) gc trigger  (Mb) max used  (Mb)
Ncells   209838   5.7     467875  12.5   350000   9.4
Vcells 20476831 156.3   22913123 174.9 20476845 156.3


## now memory usage increases

  I'm sure this is obvious to hardened R programmers, but I can't find
any explicit discussion in the R manuals.

  So I would imagine that making some trivial modification of the object
(like  "class(object) <- class(object)", for example)  would mark it as
a "new" object ...

  cheers
     Ben
> 
> It's been a while since I checked this so it may have been fixed.
> 
> Anyways, a way around this is to extract all the info needed from your 
> lmer object to other variables before running mcmcsamp, that's what I do 
> now and it works fine.
> Thanks
> JP
> 
> 
> 
> John Maindonald wrote:
>> Dear Douglas -
>> The following is at the very least a serious trap!  The output
>> from VarCorr() and print() changes remarkably after running
>> mcmcsamp() with the lmer object as argument.  The estimate
>> of sigma is always (for these data) high, but roughly in the
>> middle of the range of values that come out of ant111b.samp at sigma
>>
>> I have also been able to reproduce this behaviour
>> (a) under lme4_0.999375-28 [below, I use 30]
>> (b) under Mac OSX.  In fact, I thought initially that this
>> was an OSX problem!
>>
>> While mcmcsamp() is in view, it would be very helpful
>> to have a progress report on where it is at.
>>
>> Many thanks
>> John Maindonald.
>>
>> I run the following code:
>>
>> library(DAAG)
>> library(lme4)
>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>> ant111b.lmer
>> VarCorr(ant111b.lmer)
>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>
>> ## Now, extract the VarCorr and summary correlations
>> VarCorr(ant111b.lmer)
>> summary(ant111b.lmer)
>>
>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>> ant111b.lmer
>> Linear mixed model fit by REML
>> Formula: harvwt ~ 1 + (1 | site)
>>   Data: ant111b
>>   AIC   BIC logLik deviance REMLdev
>> 100.4 104.8 -47.21    95.08   94.42
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> site     (Intercept) 2.36773  1.53874
>> Residual             0.57754  0.75996
>> Number of obs: 32, groups: site, 8
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   4.2917     0.5603   7.659
>>> library(DAAG)
>>> library(lme4)
>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>> ant111b.lmer
>> Linear mixed model fit by REML
>> Formula: harvwt ~ 1 + (1 | site)
>>   Data: ant111b
>>   AIC   BIC logLik deviance REMLdev
>> 100.4 104.8 -47.21    95.08   94.42
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> site     (Intercept) 2.36773  1.53874
>> Residual             0.57754  0.75996
>> Number of obs: 32, groups: site, 8
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   4.2917     0.5603   7.659
>>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>> VarCorr(ant111b.lmer)
>> $site
>>            (Intercept)
>> (Intercept)    8.363436
>> attr(,"stddev")
>> (Intercept)
>>   2.891961
>> attr(,"correlation")
>>            (Intercept)
>> (Intercept)           1
>>
>> attr(,"sc")
>> sigmaREML
>> 1.428289
>>> summary(ant111b.lmer)
>> Linear mixed model fit by REML
>> Formula: harvwt ~ 1 + (1 | site)
>>   Data: ant111b
>>   AIC   BIC logLik deviance REMLdev
>> 112.1 116.5 -53.04    105.7   106.1
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> site     (Intercept) 8.3634   2.8920
>> Residual             2.0400   1.4283
>> Number of obs: 32, groups: site, 8
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   4.2917     0.4171   10.29
>>
>>> sessionInfo()
>> R version 2.9.0 (2009-04-17)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
>> States.1252;LC_MONETARY=English_United 
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_0.999375-30   Matrix_0.999375-26 lattice_0.17-22
>> [4] DAAG_0.99-1        MASS_7.2-47
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.9.0
>>
>>
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From baron at psych.upenn.edu  Sat May 16 00:22:03 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 15 May 2009 18:22:03 -0400
Subject: [R-sig-ME] Side effects from mcmcsamp()
In-Reply-To: <4A0DE424.6020706@ufl.edu>
References: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
	<4A0DCDB5.3010003@msu.edu> <4A0DE424.6020706@ufl.edu>
Message-ID: <20090515222203.GA8317@psych.upenn.edu>

I haven't tried this, but what if you just run lmer again?  At least
in the work I do, mcmcsamp takes MUCH longer than lmer.

Jon



From bates at stat.wisc.edu  Sat May 16 00:22:24 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 15 May 2009 17:22:24 -0500
Subject: [R-sig-ME] Side effects from mcmcsamp()
In-Reply-To: <4A0DE424.6020706@ufl.edu>
References: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
	<4A0DCDB5.3010003@msu.edu> <4A0DE424.6020706@ufl.edu>
Message-ID: <40e66e0b0905151522ud0d0667q5c7f6d14ab25a914@mail.gmail.com>

On Fri, May 15, 2009 at 4:52 PM, Ben Bolker <bolker at ufl.edu> wrote:
> Juan Pedro Steibel wrote:
>> Hello,
>> I noticed this a wile ago. One thing that occurred to me was to copy to
>> another object before running mcmcsamp, example:
>> obmix0<-obmix
>> where obmix is the lmer object.
>> then do: mcmcsamp(obmix)....
>> For some reason obmix0 gets modified too.
>
> ?Yeah, this aspect of the whole thing mystified me.
> I understand that mcmcsamp does nasty things internally,
> but I don't understand why it would also do them to a *copy* of the
> object. ?I poked around in R manuals (language definitions etc.) but
> didn't manage to find anything useful for understanding this. ?I can
> imagine there's some slick optimization where R says to itself "gee,
> this object hasn't been modified from its original yet, so I won't
> actually make a new copy ..." but is fooled by the internal
> manipulation. ?("Don't anthromorphize computers -- they get really mad"
> :-) )
>
>> gc()
> ? ? ? ? used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 209832 ?5.7 ? ? 467875 12.5 ? 350000 ?9.4
> Vcells 476846 ?3.7 ? ?1165368 ?8.9 ?1028740 ?7.9
>
> ## make a big object -- 70 Mb
>> z <- runif(1e7)
>> gc()
> ? ? ? ? ? used (Mb) gc trigger (Mb) max used (Mb)
> Ncells ? 209821 ?5.7 ? ? 467875 12.5 ? 350000 ?9.4
> Vcells 10476828 80.0 ? 11888118 90.7 10477151 80.0
>
> ## make a copy
>> z2 <- z
>
> ## Vcells only increases a little
>> gc()
> ? ? ? ? ? used (Mb) gc trigger (Mb) max used (Mb)
> Ncells ? 209826 ?5.7 ? ? 467875 12.5 ? 350000 ?9.4
> Vcells 10476829 80.0 ? 12562523 95.9 10477151 80.0
>
> ## ditto
>> z3 <- z2
>> gc()
> ? ? ? ? ? used (Mb) gc trigger ?(Mb) max used (Mb)
> Ncells ? 209831 ?5.7 ? ? 467875 ?12.5 ? 350000 ?9.4
> Vcells 10476830 80.0 ? 13270649 101.3 10477151 80.0
>
> ## tweak z3
>> z3[1] <- z3[1]+1
>> gc()
> ? ? ? ? ? used ?(Mb) gc trigger ?(Mb) max used ?(Mb)
> Ncells ? 209838 ? 5.7 ? ? 467875 ?12.5 ? 350000 ? 9.4
> Vcells 20476831 156.3 ? 22913123 174.9 20476845 156.3
>
>
> ## now memory usage increases
>
> ?I'm sure this is obvious to hardened R programmers, but I can't find
> any explicit discussion in the R manuals.
>
> ?So I would imagine that making some trivial modification of the object
> (like ?"class(object) <- class(object)", for example) ?would mark it as
> a "new" object ...

Exactly.  There is some deep magic in the internal structure of an R
object that allows for "copy on modify" semantics.  Strictly speaking
in a functional language the arguments to a function (including a
replacement function) are copied and you never touch the original
objects that are passed as arguments.  Of course if you did this in
practice the interpreter would slow to a crawl because it would be
spending all its time copying objects then discarding these copies.
Remember that in R, "everything is a function" so evaluating 2+2 is
actually "+"(2,2).

To maintain some semblance of sanity there is a special tag in an R
object that indicates if it is named (i.e. has been assigned to a
name) and changes to such objects require that they be copied - unless
you change the object within a .Call.  The .Call semantics are very
powerful and give you enough rope to hang yourself.   Inside C code
called through .Call you get access to the original object and can do
whatever you want to it.

The C code in mcmcsamp manipulates the structure of the fitted model
to produce the sample but it doesn't copy the object.  I had thought
that I had restored the fitted model object passed to mcmcsamp to its
original form before returning from mcmcsamp but obviously I didn't.
I'll fix it next week.  (Right now I am staring at a stack of over 150
exam booklets to be graded and wondering if I should consider another
career.)

What is happening here is that assigning the fitted model to a new
name doesn't really copy the object.  It just flags it as needing to
be copied if either it or the original are changed and passing it to
mcmcsamp doesn't count as changing the object, even though it does
change the object.

So why don't I copy it?  Well, these objects can be very big and
people get distressed if they can fit a model but run out of memory
trying to do something with it.  I have already had complaints that it
is possible to fit a model but not evaluate a "summary" of the object
or even "print" (which causes a summary).  That's the tradeoff.
> ?cheers
> ? ? Ben
>>
>> It's been a while since I checked this so it may have been fixed.
>>
>> Anyways, a way around this is to extract all the info needed from your
>> lmer object to other variables before running mcmcsamp, that's what I do
>> now and it works fine.
>> Thanks
>> JP
>>
>>
>>
>> John Maindonald wrote:
>>> Dear Douglas -
>>> The following is at the very least a serious trap! ?The output
>>> from VarCorr() and print() changes remarkably after running
>>> mcmcsamp() with the lmer object as argument. ?The estimate
>>> of sigma is always (for these data) high, but roughly in the
>>> middle of the range of values that come out of ant111b.samp at sigma
>>>
>>> I have also been able to reproduce this behaviour
>>> (a) under lme4_0.999375-28 [below, I use 30]
>>> (b) under Mac OSX. ?In fact, I thought initially that this
>>> was an OSX problem!
>>>
>>> While mcmcsamp() is in view, it would be very helpful
>>> to have a progress report on where it is at.
>>>
>>> Many thanks
>>> John Maindonald.
>>>
>>> I run the following code:
>>>
>>> library(DAAG)
>>> library(lme4)
>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>> ant111b.lmer
>>> VarCorr(ant111b.lmer)
>>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>>
>>> ## Now, extract the VarCorr and summary correlations
>>> VarCorr(ant111b.lmer)
>>> summary(ant111b.lmer)
>>>
>>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>> ant111b.lmer
>>> Linear mixed model fit by REML
>>> Formula: harvwt ~ 1 + (1 | site)
>>> ? Data: ant111b
>>> ? AIC ? BIC logLik deviance REMLdev
>>> 100.4 104.8 -47.21 ? ?95.08 ? 94.42
>>> Random effects:
>>> Groups ? Name ? ? ? ?Variance Std.Dev.
>>> site ? ? (Intercept) 2.36773 ?1.53874
>>> Residual ? ? ? ? ? ? 0.57754 ?0.75996
>>> Number of obs: 32, groups: site, 8
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 4.2917 ? ? 0.5603 ? 7.659
>>>> library(DAAG)
>>>> library(lme4)
>>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>> ant111b.lmer
>>> Linear mixed model fit by REML
>>> Formula: harvwt ~ 1 + (1 | site)
>>> ? Data: ant111b
>>> ? AIC ? BIC logLik deviance REMLdev
>>> 100.4 104.8 -47.21 ? ?95.08 ? 94.42
>>> Random effects:
>>> Groups ? Name ? ? ? ?Variance Std.Dev.
>>> site ? ? (Intercept) 2.36773 ?1.53874
>>> Residual ? ? ? ? ? ? 0.57754 ?0.75996
>>> Number of obs: 32, groups: site, 8
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 4.2917 ? ? 0.5603 ? 7.659
>>>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>>> VarCorr(ant111b.lmer)
>>> $site
>>> ? ? ? ? ? ?(Intercept)
>>> (Intercept) ? ?8.363436
>>> attr(,"stddev")
>>> (Intercept)
>>> ? 2.891961
>>> attr(,"correlation")
>>> ? ? ? ? ? ?(Intercept)
>>> (Intercept) ? ? ? ? ? 1
>>>
>>> attr(,"sc")
>>> sigmaREML
>>> 1.428289
>>>> summary(ant111b.lmer)
>>> Linear mixed model fit by REML
>>> Formula: harvwt ~ 1 + (1 | site)
>>> ? Data: ant111b
>>> ? AIC ? BIC logLik deviance REMLdev
>>> 112.1 116.5 -53.04 ? ?105.7 ? 106.1
>>> Random effects:
>>> Groups ? Name ? ? ? ?Variance Std.Dev.
>>> site ? ? (Intercept) 8.3634 ? 2.8920
>>> Residual ? ? ? ? ? ? 2.0400 ? 1.4283
>>> Number of obs: 32, groups: site, 8
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 4.2917 ? ? 0.4171 ? 10.29
>>>
>>>> sessionInfo()
>>> R version 2.9.0 (2009-04-17)
>>> i386-pc-mingw32
>>>
>>> locale:
>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>> States.1252;LC_MONETARY=English_United
>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-30 ? Matrix_0.999375-26 lattice_0.17-22
>>> [4] DAAG_0.99-1 ? ? ? ?MASS_7.2-47
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.9.0
>>>
>>>
>>>
>>> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Sat May 16 00:26:05 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 16 May 2009 08:26:05 +1000
Subject: [R-sig-ME] Side effects from mcmcsamp()
In-Reply-To: <4A0DE424.6020706@ufl.edu>
References: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
	<4A0DCDB5.3010003@msu.edu> <4A0DE424.6020706@ufl.edu>
Message-ID: <16FD2659-A7EF-4951-A927-1E473648962B@anu.edu.au>

I believe that assignment to a new name creates, in the first
place, a promise.  A new object is created only when obmix0
is changed.  John Chambers, in "Software for Data Analysis",
has a lot to say about promises, though not in this particular
connection as far as I could see at a quick check.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 16/05/2009, at 7:52 AM, Ben Bolker wrote:

> Juan Pedro Steibel wrote:
>> Hello,
>> I noticed this a wile ago. One thing that occurred to me was to  
>> copy to
>> another object before running mcmcsamp, example:
>> obmix0<-obmix
>> where obmix is the lmer object.
>> then do: mcmcsamp(obmix)....
>> For some reason obmix0 gets modified too.
>
> Yeah, this aspect of the whole thing mystified me.
> I understand that mcmcsamp does nasty things internally,
> but I don't understand why it would also do them to a *copy* of the
> object.  I poked around in R manuals (language definitions etc.) but
> didn't manage to find anything useful for understanding this.  I can
> imagine there's some slick optimization where R says to itself "gee,
> this object hasn't been modified from its original yet, so I won't
> actually make a new copy ..." but is fooled by the internal
> manipulation.  ("Don't anthromorphize computers -- they get really  
> mad"
> :-) )
>
>> gc()
>       used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 209832  5.7     467875 12.5   350000  9.4
> Vcells 476846  3.7    1165368  8.9  1028740  7.9
>
> ## make a big object -- 70 Mb
>> z <- runif(1e7)
>> gc()
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   209821  5.7     467875 12.5   350000  9.4
> Vcells 10476828 80.0   11888118 90.7 10477151 80.0
>
> ## make a copy
>> z2 <- z
>
> ## Vcells only increases a little
>> gc()
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   209826  5.7     467875 12.5   350000  9.4
> Vcells 10476829 80.0   12562523 95.9 10477151 80.0
>
> ## ditto
>> z3 <- z2
>> gc()
>         used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells   209831  5.7     467875  12.5   350000  9.4
> Vcells 10476830 80.0   13270649 101.3 10477151 80.0
>
> ## tweak z3
>> z3[1] <- z3[1]+1
>> gc()
>         used  (Mb) gc trigger  (Mb) max used  (Mb)
> Ncells   209838   5.7     467875  12.5   350000   9.4
> Vcells 20476831 156.3   22913123 174.9 20476845 156.3
>
>
> ## now memory usage increases
>
> I'm sure this is obvious to hardened R programmers, but I can't find
> any explicit discussion in the R manuals.
>
> So I would imagine that making some trivial modification of the object
> (like  "class(object) <- class(object)", for example)  would mark it  
> as
> a "new" object ...
>
> cheers
>   Ben
>>
>> It's been a while since I checked this so it may have been fixed.
>>
>> Anyways, a way around this is to extract all the info needed from  
>> your
>> lmer object to other variables before running mcmcsamp, that's what  
>> I do
>> now and it works fine.
>> Thanks
>> JP
>>
>>
>>
>> John Maindonald wrote:
>>> Dear Douglas -
>>> The following is at the very least a serious trap!  The output
>>> from VarCorr() and print() changes remarkably after running
>>> mcmcsamp() with the lmer object as argument.  The estimate
>>> of sigma is always (for these data) high, but roughly in the
>>> middle of the range of values that come out of ant111b.samp at sigma
>>>
>>> I have also been able to reproduce this behaviour
>>> (a) under lme4_0.999375-28 [below, I use 30]
>>> (b) under Mac OSX.  In fact, I thought initially that this
>>> was an OSX problem!
>>>
>>> While mcmcsamp() is in view, it would be very helpful
>>> to have a progress report on where it is at.
>>>
>>> Many thanks
>>> John Maindonald.
>>>
>>> I run the following code:
>>>
>>> library(DAAG)
>>> library(lme4)
>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>> ant111b.lmer
>>> VarCorr(ant111b.lmer)
>>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>>
>>> ## Now, extract the VarCorr and summary correlations
>>> VarCorr(ant111b.lmer)
>>> summary(ant111b.lmer)
>>>
>>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>> ant111b.lmer
>>> Linear mixed model fit by REML
>>> Formula: harvwt ~ 1 + (1 | site)
>>> Data: ant111b
>>> AIC   BIC logLik deviance REMLdev
>>> 100.4 104.8 -47.21    95.08   94.42
>>> Random effects:
>>> Groups   Name        Variance Std.Dev.
>>> site     (Intercept) 2.36773  1.53874
>>> Residual             0.57754  0.75996
>>> Number of obs: 32, groups: site, 8
>>>
>>> Fixed effects:
>>>         Estimate Std. Error t value
>>> (Intercept)   4.2917     0.5603   7.659
>>>> library(DAAG)
>>>> library(lme4)
>>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>> ant111b.lmer
>>> Linear mixed model fit by REML
>>> Formula: harvwt ~ 1 + (1 | site)
>>> Data: ant111b
>>> AIC   BIC logLik deviance REMLdev
>>> 100.4 104.8 -47.21    95.08   94.42
>>> Random effects:
>>> Groups   Name        Variance Std.Dev.
>>> site     (Intercept) 2.36773  1.53874
>>> Residual             0.57754  0.75996
>>> Number of obs: 32, groups: site, 8
>>>
>>> Fixed effects:
>>>         Estimate Std. Error t value
>>> (Intercept)   4.2917     0.5603   7.659
>>>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>>> VarCorr(ant111b.lmer)
>>> $site
>>>         (Intercept)
>>> (Intercept)    8.363436
>>> attr(,"stddev")
>>> (Intercept)
>>> 2.891961
>>> attr(,"correlation")
>>>         (Intercept)
>>> (Intercept)           1
>>>
>>> attr(,"sc")
>>> sigmaREML
>>> 1.428289
>>>> summary(ant111b.lmer)
>>> Linear mixed model fit by REML
>>> Formula: harvwt ~ 1 + (1 | site)
>>> Data: ant111b
>>> AIC   BIC logLik deviance REMLdev
>>> 112.1 116.5 -53.04    105.7   106.1
>>> Random effects:
>>> Groups   Name        Variance Std.Dev.
>>> site     (Intercept) 8.3634   2.8920
>>> Residual             2.0400   1.4283
>>> Number of obs: 32, groups: site, 8
>>>
>>> Fixed effects:
>>>         Estimate Std. Error t value
>>> (Intercept)   4.2917     0.4171   10.29
>>>
>>>> sessionInfo()
>>> R version 2.9.0 (2009-04-17)
>>> i386-pc-mingw32
>>>
>>> locale:
>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>> States.1252;LC_MONETARY=English_United
>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-30   Matrix_0.999375-26 lattice_0.17-22
>>> [4] DAAG_0.99-1        MASS_7.2-47
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.9.0
>>>
>>>
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From albrem04 at student.uwa.edu.au  Sun May 17 23:35:13 2009
From: albrem04 at student.uwa.edu.au (Matthew Albrecht)
Date: Mon, 18 May 2009 05:35:13 +0800
Subject: [R-sig-ME] lme/lmer for drug effects on blood pressure
Message-ID: <4A108311.50203@student.uwa.edu.au>

Dear list,
I am using lme/lmer to model blood pressure whilst under either drug or
placebo. Design- Every participant receives both drug and placebo on two
separate occasions. Blood pressure is measured in each person at 0, 75,
130, 180 and 270 min post ingestion. I have been reading Pinheiro and
Bates and the R-lists and just wanted to make sure my method is sound.
Looking at the data, it looks parabolic, so I fitted the data to a
second order polynomial:

lmer(pressure~drug*poly(timep,2)+(1|ID), data=drugdat)
or
lme(pressure~drug*poly(timep,2), random=~1|ID, data=drugdat,
na.action=na.omit)

More complicated random effects terms such as "(1|ID) + (1|ID:drug)" -
which to me means that each person has a different blood pressure
baseline, and each person's blood pressure reacts to the drug
differently(?) - make no improvements on the model (needs more
replicates?), anything I've missed or any errors in my thinking/process?

Thanks,
Matthew Albrecht
UWA, Pharmacology


Code below..............................................................

# Data generation
ID<-1:18
drug<-rep(c(1,2), c(90,90))
timep<-rep(c(0,75,130,180,270), c(18,18,18,18,18))
pressure<-c(104,128,117,115,122,122,114,107,124,88,125,97,138,126,131,133,140,111,
106,124,119,116,111,144,118,117,119,87,136,103,113,120,102,124,141,130,
92,119,117,107,107,133,108,114,114,NA,132,104,111,107,104,114,139,116,
107,126,114,96,115,142,114,120,132,103,132,102,113,122,114,123,131,115,
116,115,126,106,120,142,108,117,128,80,140,101,116,107,119,114,138,139,
104,127,128,118,140,138,120,106,126,95,118,97,107,134,123,107,136,103,
108,138,133,118,108,191,110,131,129,108,144,127,123,131,151,155,131,152,
120,143,136,123,134,164,150,130,135,NA,141,114,143,167,155,159,142,147,
135,157,141,129,141,153,136,129,149,130,NA,110,141,163,157,169,171,138,
143,153,138,129,144,160,135,130,124,114,122,114,133,140,144,153,166,132)
drugdat<-data.frame(ID, drug, timep, pressure)
drugdat$ID<-factor(drugdat$ID)
drugdat$drug<-factor(drugdat$drug)

# Quick look
with(drugdat[drugdat$pressure!="NA",], interaction.plot(timep, drug,
pressure))

# lmer/lme commands
lmer1<-lmer(pressure~drug*poly(timep,2)+(1|ID), data=drugdat)
plot(lmer1)
summary(lmer1)
anova(lmer1)

# Or the legacy version
lme1<-lme(pressure~drug*poly(timep,2), data=drugdat, random=~1|ID,
na.action=na.omit)
summary(lme1)
anova(lme1)
plot(lme1)


# More pictures if interested, I haven't figured out how the "fitted"
and the "predict" function interchange within the defined functions
below to use the lme/lmer fits yet, it is late - or early - at the moment...
lm1<-lm(pressure~drug*poly(timep,2), data=drugdat, na.action=na.omit)
plot(pressure~timep, data=drugdat, col=c("blue", "red")[drug], pch =
c(1,2)[drug])
fit<-function(x)
    predict(lm1, newdata=
        data.frame(timep=x, drug=rep(levels(drugdat$drug)[1], length(x))))
curve(fit, 0,270, add=TRUE, col="blue")
fit<-function(x)
    predict(lm1, newdata=
        data.frame(timep=x, drug=rep(levels(drugdat$drug)[2], length(x))))
curve(fit, 0,270, add=TRUE, col="red")



From s.ruiter at maw.ru.nl  Tue May 19 12:18:25 2009
From: s.ruiter at maw.ru.nl (Stijn Ruiter)
Date: Tue, 19 May 2009 12:18:25 +0200
Subject: [R-sig-ME] false convergence glmer when quadratic terms are included
Message-ID: <4A128771.7060200@maw.ru.nl>

Dear all,
Somehow I always get false convergence warnings when including a
quadratic term in a glmer equation. With lmer I have no such problems.
So, my guess is that this has to do with the different algorithm used
for glmer models.
The following example model (which can easily be estimated in
alternative mixed effects programs such as MLwiN or HLM) result in problems:

glmer(y~(1|level2id)+x+I(x^2),family=binomial,data=data)

It leads to:
Warning message:
In mer_finalize(ans) : false convergence (8)

What is the problem here? Why these convergence issues?

Stijn

-- 
Best regards,

Stijn Ruiter
Department of Sociology / ICS
Radboud University Nijmegen
P.O. Box 9104
6500 HE Nijmegen
Netherlands

Phone: + 31 24 361 2272
Fax:   + 31 24 361 2399

Visiting address:
Thomas van Aquinostraat 4.01.71
Nijmegen

website: http://oase.uci.ru.nl/~sruiter



From Thierry.ONKELINX at inbo.be  Tue May 19 12:32:09 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 19 May 2009 12:32:09 +0200
Subject: [R-sig-ME] false convergence glmer when quadratic terms are
	included
In-Reply-To: <4A128771.7060200@maw.ru.nl>
References: <4A128771.7060200@maw.ru.nl>
Message-ID: <2E9C414912813E4EB981326983E0A1040687F2BE@inboexch.inbo.be>

Dear Stijn,

Why don't you use poly(x, 2) instead? Adding x^2 with large or small
values will lead to even larger or smaller values. That may cause the
model to become unstable. Poly(x, 2) will avoid that by rescaling.

glmer(y~(1|level2id)+poly(x,2),family=binomial,data=data) 

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Stijn Ruiter
Verzonden: dinsdag 19 mei 2009 12:18
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] false convergence glmer when quadratic terms are
included

Dear all,
Somehow I always get false convergence warnings when including a
quadratic term in a glmer equation. With lmer I have no such problems.
So, my guess is that this has to do with the different algorithm used
for glmer models.
The following example model (which can easily be estimated in
alternative mixed effects programs such as MLwiN or HLM) result in
problems:

glmer(y~(1|level2id)+x+I(x^2),family=binomial,data=data)

It leads to:
Warning message:
In mer_finalize(ans) : false convergence (8)

What is the problem here? Why these convergence issues?

Stijn

--
Best regards,

Stijn Ruiter
Department of Sociology / ICS
Radboud University Nijmegen
P.O. Box 9104
6500 HE Nijmegen
Netherlands

Phone: + 31 24 361 2272
Fax:   + 31 24 361 2399

Visiting address:
Thomas van Aquinostraat 4.01.71
Nijmegen

website: http://oase.uci.ru.nl/~sruiter

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From bates at stat.wisc.edu  Tue May 19 16:06:25 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 19 May 2009 09:06:25 -0500
Subject: [R-sig-ME] false convergence glmer when quadratic terms are
	included
In-Reply-To: <2E9C414912813E4EB981326983E0A1040687F2BE@inboexch.inbo.be>
References: <4A128771.7060200@maw.ru.nl>
	<2E9C414912813E4EB981326983E0A1040687F2BE@inboexch.inbo.be>
Message-ID: <40e66e0b0905190706y7c44b39di12cf52018c3e73e4@mail.gmail.com>

On Tue, May 19, 2009 at 5:32 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> Dear Stijn,

> Why don't you use poly(x, 2) instead? Adding x^2 with large or small
> values will lead to even larger or smaller values. That may cause the
> model to become unstable. Poly(x, 2) will avoid that by rescaling.

> glmer(y~(1|level2id)+poly(x,2),family=binomial,data=data)

Exactly.

The general advice in a case like this is to add the optional argument

verbose = TRUE

in the call to glmer so that you get a display of the progress of the
iterations.   Take a look at

example(cbpp)

You will see that a line in the trace output is of the form

 16:     100.09586: 0.642264 -1.39853 -0.992327 -1.12866 -1.58032

where the first number is the iteration number, the second is the
current value of the deviance, the third is the standard deviation of
the random effects and the fourth and subsequent numbers are the
values of the fixed-effects parameters.  It is likely that one of the
fixed-effects parameters is very large or very small in your original
form of the model.


>
> HTH,
>
> Thierry
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Stijn Ruiter
> Verzonden: dinsdag 19 mei 2009 12:18
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] false convergence glmer when quadratic terms are
> included
>
> Dear all,
> Somehow I always get false convergence warnings when including a
> quadratic term in a glmer equation. With lmer I have no such problems.
> So, my guess is that this has to do with the different algorithm used
> for glmer models.
> The following example model (which can easily be estimated in
> alternative mixed effects programs such as MLwiN or HLM) result in
> problems:
>
> glmer(y~(1|level2id)+x+I(x^2),family=binomial,data=data)
>
> It leads to:
> Warning message:
> In mer_finalize(ans) : false convergence (8)
>
> What is the problem here? Why these convergence issues?
>
> Stijn
>
> --
> Best regards,
>
> Stijn Ruiter
> Department of Sociology / ICS
> Radboud University Nijmegen
> P.O. Box 9104
> 6500 HE Nijmegen
> Netherlands
>
> Phone: + 31 24 361 2272
> Fax: ? + 31 24 361 2399
>
> Visiting address:
> Thomas van Aquinostraat 4.01.71
> Nijmegen
>
> website: http://oase.uci.ru.nl/~sruiter
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed in ?this message
> and any annex are purely those of the writer and may not be regarded as stating
> an official position of INBO, as long as the message is not confirmed by a duly
> signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Tue May 19 22:25:52 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 19 May 2009 15:25:52 -0500
Subject: [R-sig-ME] Changing the displayed values of logLik,
	AIC and BIC for linear mixed 	models fit by REML
Message-ID: <40e66e0b0905191325t5a69ff6er61d4490e9f9ab4af@mail.gmail.com>

In writing about the statistics displayed for a linear mixed model I
have again considered an inconsistency in the definition of the
log-likelihood, the AIC and BIC criterion.  In the past some users
have noticed that the AIC, BIC and log-likelihood criteria are
displayed differently in the summary of a model fit by REML and in the
anova comparison of two such models.  Consider

> fm1
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 618.756  24.8748
          Days         35.572   5.9642  0.022
 Residual             654.075  25.5749
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.366      6.867   36.60
Days          10.467      1.555    6.73

Correlation of Fixed Effects:
     (Intr)
Days -0.170
> fm2
Linear mixed model fit by REML
Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1754 1770 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 627.520  25.0503
 Subject  Days         35.859   5.9883
 Residual             653.587  25.5653
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.885   36.51
Days          10.467      1.560    6.71

Correlation of Fixed Effects:
     (Intr)
Days -0.184
> anova(fm2,fm1)
Data: sleepstudy
Models:
fm2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
fm1: Reaction ~ Days + (Days | Subject)
    Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
fm2  5 1762.05 1778.01 -876.02
fm1  6 1764.04 1783.19 -876.02 0.0104      1     0.9188

Note that the logLik for fm2 is -871.8 in the model summary and
-876.02 in the anova output.

Now the short answer to why this happens is that differences in the
REML criterion do not always behave like differences in the deviance
so, to be on the safe side, the criteria in the anova output are
derived from the deviance, not the REML criterion.  (The name REMLdev
means the REML criterion on the deviance scale.)  In the summary the
quantity labeled "logLik" is negative half the REMLdev whereas in the
anova output it is negative half the deviance.  The AIC and BIC
criteria are derived from the value of the logLik in both cases.

I am considering changing the display of the summary so that the
logLik, AIC and BIC are always the values corresponding to the
deviance.  The disadvantage of doing this is that the display will be
inconsistent with earlier fits of the same model.  Also, the deviance
quoted for a REML fit is not the minimum possible deviance, which is
the deviance from the ML fit.  However, it is usually quite close to
the minimum.  This may seem peculiar because the parameter estimates
in the REML and ML fits can be quite different so why should the
deviances be similar? The trick is that the deviance and the REMLdev
values are the profiled deviance and the profiled REML criteria and
depend only on a reduced parameter vector.  Those parameters don't
change much between the REML and the ML fits.

The advantage of making the change is that the model summary and the
anova results would be consistent.  Also, I think that the quantity
labeled "logLik" should be a log-likelihood, not just something that
kind-of behaves like a log-likelihood.

I'm trying to think of what would be the downside of making the
change.  Obviously it would be upsetting to get apparently different
results from those obtained using previous versions of lme4 but I
think that the explanation of the inconsistency could be propagated
sufficiently widely for users to learn of it.  Would the results be
inconsistent with those reported by SAS PROC MIXED, SPSS, Stata, HLM,
MLWin, etc.?  Are there good reasons for wanting to evaluate negative
half the REMLdev value?  I have seen discussion of REML-based tests
and I remember that Ahn and Reinsel described advantages for them but
I have forgotten the details.  I believe I read a message on this list
about an R package for REML-based tests but I can't seem to find it
now.  Can anyone refresh my failing memory?



From maj at stats.waikato.ac.nz  Wed May 20 00:30:20 2009
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 20 May 2009 10:30:20 +1200
Subject: [R-sig-ME] Ecological mixed model example
In-Reply-To: <aefe4d0a0905141611y4e20b000o51294db550830108@mail.gmail.com>
References: <49E64573.8080704@math.canterbury.ac.nz>	
	<49E65DBD.3010909@stats.waikato.ac.nz>	
	<20090513075056.k1iityweeosoc4sg@secure.math.canterbury.ac.nz>	
	<20090513075416.vsm6y3a9esk0oo0s@secure.math.canterbury.ac.nz>	
	<4A0A4A6C.9080100@stats.waikato.ac.nz>	
	<aefe4d0a0905141438n5713922eo3eead642fb5502d6@mail.gmail.com>
	<aefe4d0a0905141611y4e20b000o51294db550830108@mail.gmail.com>
Message-ID: <4A1332FC.8090402@stats.waikato.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090520/226c05ef/attachment.pl>

From dale.w.steele at gmail.com  Wed May 20 01:10:22 2009
From: dale.w.steele at gmail.com (Dale Steele)
Date: Tue, 19 May 2009 19:10:22 -0400
Subject: [R-sig-ME] How to handle tabular form data in lmer/glmer without
	(or with) expanding the data into binary outcome form?
Message-ID: <72e8303a0905191610y6679b6e4u6d9752f6babc561e@mail.gmail.com>

A recent thread
<https://stat.ethz.ch/pipermail/r-help/2009-April/194750.html>
suggested the glmer can handle data in tabular form.  I'm working
through (not homework) the simple random effects example from Agresti,
An Introduction to Categorical Data Analysis, 2nd Ed. (pg 303 - 304)
and am having problems...

# Data from Table 10.2 n_i: number of free throws, p_i: observed
proportion of successes

id <- seq(1:15)
n <- c(13,10,15,14,6,10,10,4,11,10,8,9,9,8,6)
p <- c(.769, .9, .667, .643, .667, .9, .6, 1, .545, .9, .5, .889,
.778, .625, .167)
(success <- round(n * p))
fail <- n - success
data <- cbind(success, fail)

# Model to fit: logit(pi_i) = mu_i + alpha

library(lme4)
#  Model
m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
summary(m1)

The code runs, and produces results similar, but not exactly what
Agresti gets (alpha_hat=0.908 and sigma_hat=0.422). Shouldn't the
'number of obs' be 143 rather than 15?  Am I doing something wrong?

 > summary(m1)
> m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
> summary(m1)

Generalized linear mixed model fit by the adaptive Gaussian Hermite
approximation
Formula: data ~ 1 + (1 | id)
  AIC   BIC logLik deviance
 32.8 34.21  -14.4     28.8
Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 0.16258  0.40321
Number of obs: 15, groups: id, 15

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   0.9059     0.2142    4.23 2.34e-05 ***

I tried to run the same model by expanding the tabular data. Easy
enough to expand the id variable.
#
(subj <- rep(id,n))

However, I'm stuck on how to expand outcome variable for each player
and concatenate as a single vector...
# first player
oc1 <- rep(c(1,0), sf[1,])

Appreciate any insight anyone may provide on how to use tabular data
directly and how to expand tubular data.  Thanks! --Dale



From joaordaniel at gmail.com  Wed May 20 03:43:05 2009
From: joaordaniel at gmail.com (=?ISO-8859-1?Q?Jo=E3o_R=2E?=)
Date: Wed, 20 May 2009 02:43:05 +0100
Subject: [R-sig-ME] random factor variance
Message-ID: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090520/eb1e1fa3/attachment.pl>

From Paul.Prew at ecolab.com  Wed May 20 03:51:44 2009
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Tue, 19 May 2009 20:51:44 -0500
Subject: [R-sig-ME] repeated measures OR block with time covariate?
References: <mailman.5754.1242772296.4616.r-sig-mixed-models@r-project.org>
Message-ID: <6B810AFB14C606439FD57E5985E0379117A9B8@useagan1500p.GLOBAL.ECOLAB.CORP>

Hello,
 
I've received helpful advice in the past from the readers of this list, and would like some more advice.  I think I understand that a blocking / nuisance factor in ANOVA will not affect the significance estimates of fixed factors / 'factors of interest', regardless of whether the blocking factor is designed as random or fixed --- the same sum-of-squares are taken off the top in ANOVA.  Other quantities may be affected, such as prediction intervals for specified levels of the fixed factor.  Fixed block effects are welcome, because virtually all the literature in experimental design treats Randomized Complete Block Designs as having fixed effects for blocks.
 
In a discussion with a colleague today, the following question was posed about repeated measures ~
 
A cleaning product is being tested at a sample of hospitals.  Micro-organism counts are taken over a period of weeks, for a control formulation and an experimental formulation.  The hospitals are not of interest, and can be considered blocking factors.  So my interpretation is that there's no harm in designating the hospitals as a fixed effect.  
 
Within the hospital, we can see week-over-week reductions in micro-organisms.    There's a slope related to time.  
 
*****   Could a fixed effect for the blocking factor Hospital and a fixed covariate Time take the place of what seems to be a good candidate for a repeated measures analysis (assuming that the repeated measures implies Hospital = random effect)?  *****
 
Any thought are greatly appreciated.  There's actually a Standard Operating Procedure being written for our scientists and engineers designating they use the repeated measures analysis.  I think it's over their heads, given that few could credibly define degrees of freedom, p-value, or other basic statistical concepts.  An approach that sticks to the "Randomized Complete Block Designs / fixed effects for blocks" is better suited, if it performs as well as the repeated measures design.
 
Regards, Paul
 
 Paul Prew  |  Statistician
 651-795-5942   |   fax 651-204-7504
 Ecolab Research Center  | Mail Stop ESC-F4412-A
 655 Lone Oak Drive  |  Eagan, MN 55121-1560



CONFIDENTIALITY NOTICE: 
This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. 
Any unauthorized review, use, disclosure or distribution is prohibited. 
If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.


From ken at kjbeath.com.au  Wed May 20 11:09:32 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 20 May 2009 19:09:32 +1000
Subject: [R-sig-ME] random factor variance
In-Reply-To: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
Message-ID: <40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>

On 20/05/2009, at 11:43 AM, Jo?o R. wrote:

> Hello,
> I have recently used lme4 package to run a glmm, but a get 0 variance
> explained by the random effect. The model has 5 fixed effects, and I  
> have
> run each of them separately and for two of them (F1, F3) I also get 0
> variance for the random effect. Do you have any ideas of what might be
> causing this? Is this kind of result to be expected?
> thanks
>

This means that the variance of the random effect needed to explain  
your data is zero.  The clusters vary by the same amount or less than  
if there was a random effect, that is they can all be explained by  
subject variation.

Ken


>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: DV ~ F1 + F2 + F3 + F4 + F5 (1 | R1)
>   Data: JD
>   AIC   BIC logLik deviance
> 203.2 225.9  -94.6    189.2
> Random effects:
> Groups Name        Variance Std.Dev.
> R1  (Intercept)  0        0
> Number of obs: 190, groups: R1, 14
> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.8949     1.1869   1.596  0.11039
> F1          4.6740     2.4365   1.918  0.05507 .
> F2         -2.0657     0.7543  -2.739  0.00617 **
> F3       21.8036     8.8890   2.453  0.01417 *
> F4   1.0968     0.4874   2.250  0.02444 *
> F5      -1.7430     0.9583  -1.819  0.06894 .
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From albrem04 at student.uwa.edu.au  Wed May 20 11:30:55 2009
From: albrem04 at student.uwa.edu.au (Matthew Albrecht)
Date: Wed, 20 May 2009 17:30:55 +0800
Subject: [R-sig-ME] lme/lmer for drug effects on blood pressure
In-Reply-To: <4A108311.50203@student.uwa.edu.au>
References: <4A108311.50203@student.uwa.edu.au>
Message-ID: <4A13CDCF.3070307@student.uwa.edu.au>

Matthew Albrecht wrote:
> Looking at the data, it looks parabolic, so I fitted the data to a
> second order polynomial:

I've just been pointed out the incorrectness of this sentence.
Apologies, it should read:
"I fitted a second order polynomial to the data."

I'm using the excuse that it was quite a late night that night.
Matt



From joaordaniel at gmail.com  Wed May 20 13:35:46 2009
From: joaordaniel at gmail.com (=?ISO-8859-1?Q?Jo=E3o_R=2E?=)
Date: Wed, 20 May 2009 12:35:46 +0100
Subject: [R-sig-ME] random factor variance
In-Reply-To: <40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
	<40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
Message-ID: <57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090520/f38c371d/attachment.pl>

From bates at stat.wisc.edu  Wed May 20 14:24:16 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 20 May 2009 07:24:16 -0500
Subject: [R-sig-ME] How to handle tabular form data in lmer/glmer
	without (or with) expanding the data into binary outcome form?
In-Reply-To: <72e8303a0905191610y6679b6e4u6d9752f6babc561e@mail.gmail.com>
References: <72e8303a0905191610y6679b6e4u6d9752f6babc561e@mail.gmail.com>
Message-ID: <40e66e0b0905200524l7fcb1bb8h3bfda01197a61ea9@mail.gmail.com>

On Tue, May 19, 2009 at 6:10 PM, Dale Steele <dale.w.steele at gmail.com> wrote:
> A recent thread
> <https://stat.ethz.ch/pipermail/r-help/2009-April/194750.html>
> suggested the glmer can handle data in tabular form. ?I'm working
> through (not homework) the simple random effects example from Agresti,
> An Introduction to Categorical Data Analysis, 2nd Ed. (pg 303 - 304)
> and am having problems...

> # Data from Table 10.2 n_i: number of free throws, p_i: observed
> proportion of successes

> id <- seq(1:15)
> n <- c(13,10,15,14,6,10,10,4,11,10,8,9,9,8,6)
> p <- c(.769, .9, .667, .643, .667, .9, .6, 1, .545, .9, .5, .889,
> .778, .625, .167)
> (success <- round(n * p))
> fail <- n - success
> data <- cbind(success, fail)

> # Model to fit: logit(pi_i) = mu_i + alpha

> library(lme4)
> # ?Model
> m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
> summary(m1)

nAGQ = 50 is overkill in this case but the model is sufficiently
simple that it doesn't do much harm.  Gauss-Hermite quadrature without
centering and scaling (which is the "adaptive" part) could require a
huge number of quadrature points because most of the evaluations of
the unscaled density are wasted.  In adaptive Gauss-Hermite
quadrature, however, you get very close approximations for a small
number of evaluations.  I would rarely use more than nAGQ = 9.  (Also,
the number of quadrature points is always chosen to be odd so your 50
will be increased to 51.  With an odd number of points you get one
evaluation free - the one at a displacement of zero.)

> The code runs, and produces results similar, but not exactly what
> Agresti gets (alpha_hat=0.908 and sigma_hat=0.422). Shouldn't the
> 'number of obs' be 143 rather than 15? ?Am I doing something wrong?

No, it's the code that is wrong.  At last summer's UseR Conference
Andrew Gelman said that he was looking at the code for the glm
function and he was frustrated that the code was so long and involved
to be able to handle all the special cases.  This is a prime example
of why the code gets complicated.

I know that it is convenient and natural to want to list the number of
successes and failures instead of one row for each observation but
doing that requires a massive amount of really ugly code to get it
right.  (Look at the definitions of the various glm families some day.
 There is this very peculiar "n" object squirreled away in a common
environment of the family functions specifically for this one case -
it is never used otherwise and, in fact, wasn't even defined in other
cases until recently.)

All the structures in lmer/glmer/nlmer are based on the not
unreasonable assumption that the model frame is a model frame, meaning
that there is one observation per row.  Except that isn't the case
here.  Getting the count right would mean writing a large amount of
special case code to recognize this case and regenerate the original
number of observations.  It can be done but it is messy and low on the
priority list right now.

> ?> summary(m1)
>> m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
>> summary(m1)
>
> Generalized linear mixed model fit by the adaptive Gaussian Hermite
> approximation
> Formula: data ~ 1 + (1 | id)
> ?AIC ? BIC logLik deviance
> ?32.8 34.21 ?-14.4 ? ? 28.8
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?id ? ? (Intercept) 0.16258 ?0.40321
> Number of obs: 15, groups: id, 15
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? 0.9059 ? ? 0.2142 ? ?4.23 2.34e-05 ***
>
> I tried to run the same model by expanding the tabular data. Easy
> enough to expand the id variable.
> #
> (subj <- rep(id,n))
>
> However, I'm stuck on how to expand outcome variable for each player
> and concatenate as a single vector...
> # first player
> oc1 <- rep(c(1,0), sf[1,])
>
> Appreciate any insight anyone may provide on how to use tabular data
> directly and how to expand tubular data. ?Thanks! --Dale

I enclose a modified version of your script to do that.  The general
idea is to produce all the 1 responses, then produce all the zero
responses then rbind them.

From joaordaniel at gmail.com  Wed May 20 14:07:20 2009
From: joaordaniel at gmail.com (=?ISO-8859-1?Q?Jo=E3o_R=2E?=)
Date: Wed, 20 May 2009 13:07:20 +0100
Subject: [R-sig-ME] random factor variance
In-Reply-To: <4A13EF22.9060103@sbg.ac.at>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
	<40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
	<57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
	<4A13EF22.9060103@sbg.ac.at>
Message-ID: <57e71d6f0905200507n382aca82m226532c70303e532@mail.gmail.com>

Andy,
here goes the model with no fixed effects. (I've attached a plot)

Generalized linear mixed model fit by the Laplace approximation
Formula: DV ~ (1 | R1)
   Data: JD
   AIC   BIC logLik deviance
 223.1 229.6 -109.5    219.1
Random effects:
 Groups Name        Variance Std.Dev.
 R1  (Intercept) 0.17255  0.41539
Number of obs: 190, groups: VICT2, 14
Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -0.9106     0.2149  -4.237 2.27e-05 ***
Thanks



On Wed, May 20, 2009 at 12:53 PM, Andy Fugard <andy.fugard at sbg.ac.at> wrote:

> What happens if you fit the model with no fixed effects?  Is there then
> variances for R1?
>
> Also can you plot the data in some way, e.g.,
>
>  histogram(~ DV | R1, data = ...)
>
> A
>
>
>
> Jo?o R. wrote:
>
>>  Thanks Ken, but I did not fully understood you.
>>
>> *This means that the variance of the random effect needed to explain your
>> data is zero.*
>> This part I get, although the fact that the value for variance is an
>> absolute 0 makes me wonder if there is something wrong. I would be happy
>> with a low value, but not exactly 0.
>> The fact that two of the fixed factors are continuous variables might have
>> something to do with it?
>> *The clusters vary by the same amount or less than if there was a random
>> effect, that is they can all be explained by subject variation.*
>> This part I don't follow...
>>
>> Basically, I am trying to predict the occurrence of reconciliation after
>> conflicts in a primate group (dependent variable: 0-no occurrence;
>> 1-reconciliation). My random variable is the victim's identity of these
>> conflicts (since not all group members are victims of conflicts, and some
>> are "more victims" than others). As fixed effects I have a set of
>> variables
>> (describing the type of conflict and the relationship between opponents;
>> 23
>> variables), some continuous (ex. F1, F3) and other categorical (ex. F2, F4
>> e
>> F5). Using a forward selection procedure based on AIC values, the best fit
>> model is this one I presented with the five fixed factors.
>>
>> Thanks again.
>>
>>
>>
>>
>> On Wed, May 20, 2009 at 10:09 AM, Ken Beath <ken at kjbeath.com.au> wrote:
>>
>> On 20/05/2009, at 11:43 AM, Jo?o R. wrote:
>>>
>>> Hello,
>>>
>>>> I have recently used lme4 package to run a glmm, but a get 0 variance
>>>> explained by the random effect. The model has 5 fixed effects, and I
>>>> have
>>>> run each of them separately and for two of them (F1, F3) I also get 0
>>>> variance for the random effect. Do you have any ideas of what might be
>>>> causing this? Is this kind of result to be expected?
>>>> thanks
>>>>
>>>>
>>>> This means that the variance of the random effect needed to explain your
>>> data is zero.  The clusters vary by the same amount or less than if there
>>> was a random effect, that is they can all be explained by subject
>>> variation.
>>>
>>> Ken
>>>
>>>
>>>
>>> Generalized linear mixed model fit by the Laplace approximation
>>>> Formula:
>>>>
>>>  ~ F1 + F2 + F3 + F4 + F5 + (1 | R1)
>
>>   Data: JD
>>>>  AIC   BIC logLik deviance
>>>> 203.2 225.9  -94.6    189.2
>>>> Random effects:
>>>> Groups Name        Variance Std.Dev.
>>>> R1  (Intercept)  0        0
>>>> Number of obs: 190, groups: R1, 14
>>>> Fixed effects:
>>>>          Estimate Std. Error z value Pr(>|z|)
>>>> (Intercept)   1.8949     1.1869   1.596  0.11039
>>>> F1          4.6740     2.4365   1.918  0.05507 .
>>>> F2         -2.0657     0.7543  -2.739  0.00617 **
>>>> F3       21.8036     8.8890   2.453  0.01417 *
>>>> F4   1.0968     0.4874   2.250  0.02444 *
>>>> F5      -1.7430     0.9583  -1.819  0.06894 .
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Andy Fugard, Post-doc, ESF LogICCC (LcpR) project
> Fachbereich Psychologie, Universitaet Salzburg
>  Hellbrunnerstr. 34, 5020 Salzburg, Austria
> +43 (0)680 2199 346  http://figuraleffect.googlepages.com
>

From andydolman at gmail.com  Wed May 20 14:37:41 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 20 May 2009 14:37:41 +0200
Subject: [R-sig-ME] random factor variance
In-Reply-To: <57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
	<40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
	<57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
Message-ID: <951234ac0905200537t1f3dbaf2mbbaf2e807e042eb8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090520/c9e1d80a/attachment.pl>

From danielezrajohnson at gmail.com  Wed May 20 16:25:28 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Wed, 20 May 2009 10:25:28 -0400
Subject: [R-sig-ME] random factor variance
In-Reply-To: <951234ac0905200537t1f3dbaf2mbbaf2e807e042eb8@mail.gmail.com>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
	<40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
	<57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
	<951234ac0905200537t1f3dbaf2mbbaf2e807e042eb8@mail.gmail.com>
Message-ID: <a46630750905200725i21461488te96815fa10ea3968@mail.gmail.com>

On Wed, May 20, 2009 at 8:37 AM, Andrew Dolman <andydolman at gmail.com> wrote:
> Whatever your groups are (your R1), there's no difference between them, or
> at least so little that the variance is estimated as 0.
>

I think this often happens when there is a difference between groups
on the surface, but the model is telling you these differences are
actually nothing more than what would be predicted to occur by chance,
given the other parameters of the model (e.g. individual/subject
variation).



From joaordaniel at gmail.com  Wed May 20 16:48:12 2009
From: joaordaniel at gmail.com (=?ISO-8859-1?Q?Jo=E3o_R=2E?=)
Date: Wed, 20 May 2009 15:48:12 +0100
Subject: [R-sig-ME] random factor variance
In-Reply-To: <951234ac0905200537t1f3dbaf2mbbaf2e807e042eb8@mail.gmail.com>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
	<40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
	<57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
	<951234ac0905200537t1f3dbaf2mbbaf2e807e042eb8@mail.gmail.com>
Message-ID: <57e71d6f0905200748m4ad4143bm35a0412fc46eb39a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090520/27593b28/attachment.pl>

From bates at stat.wisc.edu  Wed May 20 17:22:56 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 20 May 2009 10:22:56 -0500
Subject: [R-sig-ME] repeated measures OR block with time covariate?
In-Reply-To: <6B810AFB14C606439FD57E5985E0379117A9B8@useagan1500p.GLOBAL.ECOLAB.CORP>
References: <mailman.5754.1242772296.4616.r-sig-mixed-models@r-project.org>
	<6B810AFB14C606439FD57E5985E0379117A9B8@useagan1500p.GLOBAL.ECOLAB.CORP>
Message-ID: <40e66e0b0905200822s1d416c48qa6739443a15efdcd@mail.gmail.com>

On Tue, May 19, 2009 at 8:51 PM, Prew, Paul <Paul.Prew at ecolab.com> wrote:
> Hello,

> I've received helpful advice in the past from the readers of this list, and would like some more advice. ?I think I understand that a blocking / nuisance factor in ANOVA will not affect the significance estimates of fixed factors / 'factors of interest', regardless of whether the blocking factor is designed as random or fixed --- the same sum-of-squares are taken off the top in ANOVA. ?Other quantities may be affected, such as prediction intervals for specified levels of the fixed factor. ?Fixed block effects are welcome, because virtually all the literature in experimental design treats Randomized Complete Block Designs as having fixed effects for blocks.

> In a discussion with a colleague today, the following question was posed about repeated measures ~

> A cleaning product is being tested at a sample of hospitals. ?Micro-organism counts are taken over a period of weeks, for a control formulation and an experimental formulation. ?The hospitals are not of interest, and can be considered blocking factors. ?So my interpretation is that there's no harm in designating the hospitals as a fixed effect.

> Within the hospital, we can see week-over-week reductions in micro-organisms. ? ?There's a slope related to time.

> ***** ? Could a fixed effect for the blocking factor Hospital and a fixed covariate Time take the place of what seems to be a good candidate for a repeated measures analysis (assuming that the repeated measures implies Hospital = random effect)? ?*****

Off the top of my head I would say that using fixed effects for the
blocking factor is a conservative approach and probably the best
approach in terms of simplicity.  I'm assuming that the design is
balanced in that each hospital is observed for the same number of
weeks, in which case the hospital and time effects would be
orthogonal.

With regard to the sums of squares, a model with random effects will
remove a smaller part of the sum of squares than will a model with
fixed effects because the random effects are shrunk relative to the
fixed effects.  Thus the residual sum of squares in a random effects
model will be at least as large as that in a model with fixed-effects
for the hospitals.  Consider the enclosed model fits for the
sleepstudy data.

library(lme4)
(fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
summary(fm2 <- lm(Reaction ~ Subject * Days, sleepstudy))
deviance(fm2)  # residual sum of squares for fixed-effects model
fm1 at deviance["wrss"]  # residual sum of squares for mixed model

When run it produces

> deviance(fm2)  # residual sum of squares for fixed-effects model
[1] 94311.5
> fm1 at deviance["wrss"]  # residual sum of squares for mixed model
    wrss
98880.24

There are differences in interpretation, of course.  It is a little
more difficult to decide how you would test for a significant
"typical" slope in the fixed-effects model than in the mixed model.
The parameter labeled "Days" in the fixed-effects model is the
estimate of the slope for the first Subject, not a typical subject.

The big advantage of using lm instead of lmer in a situation like this
is that lm gives you p-values and lmer doesn't. :-)


> Any thought are greatly appreciated. ?There's actually a Standard Operating Procedure being written for our scientists and engineers designating they use the repeated measures analysis. ?I think it's over their heads, given that few could credibly define degrees of freedom, p-value, or other basic statistical concepts. ?An approach that sticks to the "Randomized Complete Block Designs / fixed effects for blocks" is better suited, if it performs as well as the repeated measures design.
>
> Regards, Paul
>
> ?Paul Prew ?| ?Statistician
> ?651-795-5942 ? | ? fax 651-204-7504
> ?Ecolab Research Center ?| Mail Stop ESC-F4412-A
> ?655 Lone Oak Drive ?| ?Eagan, MN 55121-1560
>
>
>
> CONFIDENTIALITY NOTICE:
> This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above.
> Any unauthorized review, use, disclosure or distribution is prohibited.
> If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

From Robert.Espesser at lpl-aix.fr  Wed May 20 19:08:50 2009
From: Robert.Espesser at lpl-aix.fr (Robert ESPESSER)
Date: Wed, 20 May 2009 19:08:50 +0200 (CEST)
Subject: [R-sig-ME] How to handle tabular form data in lmer/glmer
 without (or with) expanding the data into binary outcome form?
In-Reply-To: <40e66e0b0905200524l7fcb1bb8h3bfda01197a61ea9@mail.gmail.com>
References: <72e8303a0905191610y6679b6e4u6d9752f6babc561e@mail.gmail.com>
	<40e66e0b0905200524l7fcb1bb8h3bfda01197a61ea9@mail.gmail.com>
Message-ID: <4192506.39558.1242839331057.JavaMail.root@frontal1>

Dear all,
I ran the model on the data "data" expanded in binary format, and I get the same results tahn
in tabular format( with the correct   number of observations).
Does it mean  that the sentence "the code is wrong" is relevant only for the calculs of number of observations ?
Thank you for reassuring me!

# dbin is the dataframe for the data in binary format

> summary(dbin)
       id       rep     
 3      :15   fail: 42  
 4      :14   suc :101  
 1      :13             
 9      :11             
 10     :10             
 2      :10             
 (Other):70  


> glmer(rep ~ 1 + (1 | id), family="binomial",data=dbin) -> m1.dbin
> summary(m1.dbin)
Generalized linear mixed model fit by the Laplace approximation 
Formula: rep ~ 1 + (1 | id) 
   Data: dbin 
   AIC   BIC logLik deviance
 176.8 182.7 -86.38    172.8
Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 0.16121  0.40151 
Number of obs: 143, groups: id, 15

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   0.9058     0.2139   4.233  2.3e-05 ***



> ----------------------------------------
> From: Douglas Bates <bates at stat.wisc.edu>
> Sent: Wed May 20 14:24:16 CEST 2009
> To: Dale Steele <dale.w.steele at gmail.com>
> Subject: Re: [R-sig-ME] How to handle tabular form data in lmer/glmer without (or with) expanding the data into binary outcome form?
> 
> 
> On Tue, May 19, 2009 at 6:10 PM, Dale Steele <dale.w.steele at gmail.com> wrote:
> > A recent thread
> > <https://stat.ethz.ch/pipermail/r-help/2009-April/194750.html>
> > suggested the glmer can handle data in tabular form. ?I'm working
> > through (not homework) the simple random effects example from Agresti,
> > An Introduction to Categorical Data Analysis, 2nd Ed. (pg 303 - 304)
> > and am having problems...
> 
> > # Data from Table 10.2 n_i: number of free throws, p_i: observed
> > proportion of successes
> 
> > id <- seq(1:15)
> > n <- c(13,10,15,14,6,10,10,4,11,10,8,9,9,8,6)
> > p <- c(.769, .9, .667, .643, .667, .9, .6, 1, .545, .9, .5, .889,
> > .778, .625, .167)
> > (success <- round(n * p))
> > fail <- n - success
> > data <- cbind(success, fail)
> 
> > # Model to fit: logit(pi_i) = mu_i + alpha
> 
> > library(lme4)
> > # ?Model
> > m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
> > summary(m1)
> 
> nAGQ = 50 is overkill in this case but the model is sufficiently
> simple that it doesn't do much harm.  Gauss-Hermite quadrature without
> centering and scaling (which is the "adaptive" part) could require a
> huge number of quadrature points because most of the evaluations of
> the unscaled density are wasted.  In adaptive Gauss-Hermite
> quadrature, however, you get very close approximations for a small
> number of evaluations.  I would rarely use more than nAGQ = 9.  (Also,
> the number of quadrature points is always chosen to be odd so your 50
> will be increased to 51.  With an odd number of points you get one
> evaluation free - the one at a displacement of zero.)
> 
> > The code runs, and produces results similar, but not exactly what
> > Agresti gets (alpha_hat=0.908 and sigma_hat=0.422). Shouldn't the
> > 'number of obs' be 143 rather than 15? ?Am I doing something wrong?
> 
> No, it's the code that is wrong.  At last summer's UseR Conference
> Andrew Gelman said that he was looking at the code for the glm
> function and he was frustrated that the code was so long and involved
> to be able to handle all the special cases.  This is a prime example
> of why the code gets complicated.
> 
> I know that it is convenient and natural to want to list the number of
> successes and failures instead of one row for each observation but
> doing that requires a massive amount of really ugly code to get it
> right.  (Look at the definitions of the various glm families some day.
>  There is this very peculiar "n" object squirreled away in a common
> environment of the family functions specifically for this one case -
> it is never used otherwise and, in fact, wasn't even defined in other
> cases until recently.)
> 
> All the structures in lmer/glmer/nlmer are based on the not
> unreasonable assumption that the model frame is a model frame, meaning
> that there is one observation per row.  Except that isn't the case
> here.  Getting the count right would mean writing a large amount of
> special case code to recognize this case and regenerate the original
> number of observations.  It can be done but it is messy and low on the
> priority list right now.
> 
> > ?> summary(m1)
> >> m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
> >> summary(m1)
> >
> > Generalized linear mixed model fit by the adaptive Gaussian Hermite
> > approximation
> > Formula: data ~ 1 + (1 | id)
> > ?AIC ? BIC logLik deviance
> > ?32.8 34.21 ?-14.4 ? ? 28.8
> > Random effects:
> > ?Groups Name ? ? ? ?Variance Std.Dev.
> > ?id ? ? (Intercept) 0.16258 ?0.40321
> > Number of obs: 15, groups: id, 15
> >
> > Fixed effects:
> > ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> > (Intercept) ? 0.9059 ? ? 0.2142 ? ?4.23 2.34e-05 ***
> >
> > I tried to run the same model by expanding the tabular data. Easy
> > enough to expand the id variable.
> > #
> > (subj <- rep(id,n))
> >
> > However, I'm stuck on how to expand outcome variable for each player
> > and concatenate as a single vector...
> > # first player
> > oc1 <- rep(c(1,0), sf[1,])
> >
> > Appreciate any insight anyone may provide on how to use tabular data
> > directly and how to expand tubular data. ?Thanks! --Dale
> 
> I enclose a modified version of your script to do that.  The general
> idea is to produce all the 1 responses, then produce all the zero
> responses then rbind them.



From bates at stat.wisc.edu  Wed May 20 19:16:03 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 20 May 2009 12:16:03 -0500
Subject: [R-sig-ME] How to handle tabular form data in lmer/glmer
	without (or with) expanding the data into binary outcome form?
In-Reply-To: <4192506.39558.1242839331057.JavaMail.root@frontal1>
References: <72e8303a0905191610y6679b6e4u6d9752f6babc561e@mail.gmail.com>
	<40e66e0b0905200524l7fcb1bb8h3bfda01197a61ea9@mail.gmail.com>
	<4192506.39558.1242839331057.JavaMail.root@frontal1>
Message-ID: <40e66e0b0905201016l6a70e178o54774e24cd32fc10@mail.gmail.com>

On Wed, May 20, 2009 at 12:08 PM, Robert ESPESSER
<Robert.Espesser at lpl-aix.fr> wrote:
> Dear all,
> I ran the model on the data "data" expanded in binary format, and I get the same results tahn
> in tabular format( with the correct ? number of observations).
> Does it mean ?that the sentence "the code is wrong" is relevant only for the calculs of number of observations ?

Yes, that is what I meant.  Sorry for alarming you.

(Well, actually there is another sense in which the calculations on
the collapsed data give a different result.  The calculated values of
the deviance, AIC and BIC are different for the extended and collapsed
data set and they should be the same.)

> Thank you for reassuring me!
>
> # dbin is the dataframe for the data in binary format
>
>> summary(dbin)
> ? ? ? id ? ? ? rep
> ?3 ? ? ?:15 ? fail: 42
> ?4 ? ? ?:14 ? suc :101
> ?1 ? ? ?:13
> ?9 ? ? ?:11
> ?10 ? ? :10
> ?2 ? ? ?:10
> ?(Other):70
>
>
>> glmer(rep ~ 1 + (1 | id), family="binomial",data=dbin) -> m1.dbin
>> summary(m1.dbin)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: rep ~ 1 + (1 | id)
> ? Data: dbin
> ? AIC ? BIC logLik deviance
> ?176.8 182.7 -86.38 ? ?172.8
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?id ? ? (Intercept) 0.16121 ?0.40151
> Number of obs: 143, groups: id, 15
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? 0.9058 ? ? 0.2139 ? 4.233 ?2.3e-05 ***
>
>
>
>> ----------------------------------------
>> From: Douglas Bates <bates at stat.wisc.edu>
>> Sent: Wed May 20 14:24:16 CEST 2009
>> To: Dale Steele <dale.w.steele at gmail.com>
>> Subject: Re: [R-sig-ME] How to handle tabular form data in lmer/glmer without (or with) expanding the data into binary outcome form?
>>
>>
>> On Tue, May 19, 2009 at 6:10 PM, Dale Steele <dale.w.steele at gmail.com> wrote:
>> > A recent thread
>> > <https://stat.ethz.ch/pipermail/r-help/2009-April/194750.html>
>> > suggested the glmer can handle data in tabular form. ?I'm working
>> > through (not homework) the simple random effects example from Agresti,
>> > An Introduction to Categorical Data Analysis, 2nd Ed. (pg 303 - 304)
>> > and am having problems...
>>
>> > # Data from Table 10.2 n_i: number of free throws, p_i: observed
>> > proportion of successes
>>
>> > id <- seq(1:15)
>> > n <- c(13,10,15,14,6,10,10,4,11,10,8,9,9,8,6)
>> > p <- c(.769, .9, .667, .643, .667, .9, .6, 1, .545, .9, .5, .889,
>> > .778, .625, .167)
>> > (success <- round(n * p))
>> > fail <- n - success
>> > data <- cbind(success, fail)
>>
>> > # Model to fit: logit(pi_i) = mu_i + alpha
>>
>> > library(lme4)
>> > # ?Model
>> > m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
>> > summary(m1)
>>
>> nAGQ = 50 is overkill in this case but the model is sufficiently
>> simple that it doesn't do much harm. ?Gauss-Hermite quadrature without
>> centering and scaling (which is the "adaptive" part) could require a
>> huge number of quadrature points because most of the evaluations of
>> the unscaled density are wasted. ?In adaptive Gauss-Hermite
>> quadrature, however, you get very close approximations for a small
>> number of evaluations. ?I would rarely use more than nAGQ = 9. ?(Also,
>> the number of quadrature points is always chosen to be odd so your 50
>> will be increased to 51. ?With an odd number of points you get one
>> evaluation free - the one at a displacement of zero.)
>>
>> > The code runs, and produces results similar, but not exactly what
>> > Agresti gets (alpha_hat=0.908 and sigma_hat=0.422). Shouldn't the
>> > 'number of obs' be 143 rather than 15? ?Am I doing something wrong?
>>
>> No, it's the code that is wrong. ?At last summer's UseR Conference
>> Andrew Gelman said that he was looking at the code for the glm
>> function and he was frustrated that the code was so long and involved
>> to be able to handle all the special cases. ?This is a prime example
>> of why the code gets complicated.
>>
>> I know that it is convenient and natural to want to list the number of
>> successes and failures instead of one row for each observation but
>> doing that requires a massive amount of really ugly code to get it
>> right. ?(Look at the definitions of the various glm families some day.
>> ?There is this very peculiar "n" object squirreled away in a common
>> environment of the family functions specifically for this one case -
>> it is never used otherwise and, in fact, wasn't even defined in other
>> cases until recently.)
>>
>> All the structures in lmer/glmer/nlmer are based on the not
>> unreasonable assumption that the model frame is a model frame, meaning
>> that there is one observation per row. ?Except that isn't the case
>> here. ?Getting the count right would mean writing a large amount of
>> special case code to recognize this case and regenerate the original
>> number of observations. ?It can be done but it is messy and low on the
>> priority list right now.
>>
>> > ?> summary(m1)
>> >> m1 <- glmer(data ~ 1 + (1 | id), family="binomial", nAGQ=50)
>> >> summary(m1)
>> >
>> > Generalized linear mixed model fit by the adaptive Gaussian Hermite
>> > approximation
>> > Formula: data ~ 1 + (1 | id)
>> > ?AIC ? BIC logLik deviance
>> > ?32.8 34.21 ?-14.4 ? ? 28.8
>> > Random effects:
>> > ?Groups Name ? ? ? ?Variance Std.Dev.
>> > ?id ? ? (Intercept) 0.16258 ?0.40321
>> > Number of obs: 15, groups: id, 15
>> >
>> > Fixed effects:
>> > ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> > (Intercept) ? 0.9059 ? ? 0.2142 ? ?4.23 2.34e-05 ***
>> >
>> > I tried to run the same model by expanding the tabular data. Easy
>> > enough to expand the id variable.
>> > #
>> > (subj <- rep(id,n))
>> >
>> > However, I'm stuck on how to expand outcome variable for each player
>> > and concatenate as a single vector...
>> > # first player
>> > oc1 <- rep(c(1,0), sf[1,])
>> >
>> > Appreciate any insight anyone may provide on how to use tabular data
>> > directly and how to expand tubular data. ?Thanks! --Dale
>>
>> I enclose a modified version of your script to do that. ?The general
>> idea is to produce all the 1 responses, then produce all the zero
>> responses then rbind them.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed May 20 19:56:00 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 20 May 2009 12:56:00 -0500
Subject: [R-sig-ME] Side effects from mcmcsamp()
In-Reply-To: <16FD2659-A7EF-4951-A927-1E473648962B@anu.edu.au>
References: <9A87DEE0-1F52-4B20-8CDD-2819B1F657FD@anu.edu.au>
	<4A0DCDB5.3010003@msu.edu> <4A0DE424.6020706@ufl.edu>
	<16FD2659-A7EF-4951-A927-1E473648962B@anu.edu.au>
Message-ID: <40e66e0b0905201056l127b5abr547710a426536028@mail.gmail.com>

I have uploaded a new version of the lme4 package to CRAN's incoming
directory.  This version (0.999375-31) forces a copy of the fitted
model object in the mcmcsamp function before passing it to the C code.
 I enclose a copy of John's example run with the new release of lme4.


On Fri, May 15, 2009 at 5:26 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> I believe that assignment to a new name creates, in the first
> place, a promise. ?A new object is created only when obmix0
> is changed. ?John Chambers, in "Software for Data Analysis",
> has a lot to say about promises, though not in this particular
> connection as far as I could see at a quick check.
>
> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
>
> On 16/05/2009, at 7:52 AM, Ben Bolker wrote:
>
>> Juan Pedro Steibel wrote:
>>>
>>> Hello,
>>> I noticed this a wile ago. One thing that occurred to me was to copy to
>>> another object before running mcmcsamp, example:
>>> obmix0<-obmix
>>> where obmix is the lmer object.
>>> then do: mcmcsamp(obmix)....
>>> For some reason obmix0 gets modified too.
>>
>> Yeah, this aspect of the whole thing mystified me.
>> I understand that mcmcsamp does nasty things internally,
>> but I don't understand why it would also do them to a *copy* of the
>> object. ?I poked around in R manuals (language definitions etc.) but
>> didn't manage to find anything useful for understanding this. ?I can
>> imagine there's some slick optimization where R says to itself "gee,
>> this object hasn't been modified from its original yet, so I won't
>> actually make a new copy ..." but is fooled by the internal
>> manipulation. ?("Don't anthromorphize computers -- they get really mad"
>> :-) )
>>
>>> gc()
>>
>> ? ? ?used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells 209832 ?5.7 ? ? 467875 12.5 ? 350000 ?9.4
>> Vcells 476846 ?3.7 ? ?1165368 ?8.9 ?1028740 ?7.9
>>
>> ## make a big object -- 70 Mb
>>>
>>> z <- runif(1e7)
>>> gc()
>>
>> ? ? ? ?used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells ? 209821 ?5.7 ? ? 467875 12.5 ? 350000 ?9.4
>> Vcells 10476828 80.0 ? 11888118 90.7 10477151 80.0
>>
>> ## make a copy
>>>
>>> z2 <- z
>>
>> ## Vcells only increases a little
>>>
>>> gc()
>>
>> ? ? ? ?used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells ? 209826 ?5.7 ? ? 467875 12.5 ? 350000 ?9.4
>> Vcells 10476829 80.0 ? 12562523 95.9 10477151 80.0
>>
>> ## ditto
>>>
>>> z3 <- z2
>>> gc()
>>
>> ? ? ? ?used (Mb) gc trigger ?(Mb) max used (Mb)
>> Ncells ? 209831 ?5.7 ? ? 467875 ?12.5 ? 350000 ?9.4
>> Vcells 10476830 80.0 ? 13270649 101.3 10477151 80.0
>>
>> ## tweak z3
>>>
>>> z3[1] <- z3[1]+1
>>> gc()
>>
>> ? ? ? ?used ?(Mb) gc trigger ?(Mb) max used ?(Mb)
>> Ncells ? 209838 ? 5.7 ? ? 467875 ?12.5 ? 350000 ? 9.4
>> Vcells 20476831 156.3 ? 22913123 174.9 20476845 156.3
>>
>>
>> ## now memory usage increases
>>
>> I'm sure this is obvious to hardened R programmers, but I can't find
>> any explicit discussion in the R manuals.
>>
>> So I would imagine that making some trivial modification of the object
>> (like ?"class(object) <- class(object)", for example) ?would mark it as
>> a "new" object ...
>>
>> cheers
>> ?Ben
>>>
>>> It's been a while since I checked this so it may have been fixed.
>>>
>>> Anyways, a way around this is to extract all the info needed from your
>>> lmer object to other variables before running mcmcsamp, that's what I do
>>> now and it works fine.
>>> Thanks
>>> JP
>>>
>>>
>>>
>>> John Maindonald wrote:
>>>>
>>>> Dear Douglas -
>>>> The following is at the very least a serious trap! ?The output
>>>> from VarCorr() and print() changes remarkably after running
>>>> mcmcsamp() with the lmer object as argument. ?The estimate
>>>> of sigma is always (for these data) high, but roughly in the
>>>> middle of the range of values that come out of ant111b.samp at sigma
>>>>
>>>> I have also been able to reproduce this behaviour
>>>> (a) under lme4_0.999375-28 [below, I use 30]
>>>> (b) under Mac OSX. ?In fact, I thought initially that this
>>>> was an OSX problem!
>>>>
>>>> While mcmcsamp() is in view, it would be very helpful
>>>> to have a progress report on where it is at.
>>>>
>>>> Many thanks
>>>> John Maindonald.
>>>>
>>>> I run the following code:
>>>>
>>>> library(DAAG)
>>>> library(lme4)
>>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>> ant111b.lmer
>>>> VarCorr(ant111b.lmer)
>>>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>>>
>>>> ## Now, extract the VarCorr and summary correlations
>>>> VarCorr(ant111b.lmer)
>>>> summary(ant111b.lmer)
>>>>
>>>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>>> ant111b.lmer
>>>>
>>>> Linear mixed model fit by REML
>>>> Formula: harvwt ~ 1 + (1 | site)
>>>> Data: ant111b
>>>> AIC ? BIC logLik deviance REMLdev
>>>> 100.4 104.8 -47.21 ? ?95.08 ? 94.42
>>>> Random effects:
>>>> Groups ? Name ? ? ? ?Variance Std.Dev.
>>>> site ? ? (Intercept) 2.36773 ?1.53874
>>>> Residual ? ? ? ? ? ? 0.57754 ?0.75996
>>>> Number of obs: 32, groups: site, 8
>>>>
>>>> Fixed effects:
>>>> ? ? ? ?Estimate Std. Error t value
>>>> (Intercept) ? 4.2917 ? ? 0.5603 ? 7.659
>>>>>
>>>>> library(DAAG)
>>>>> library(lme4)
>>>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>>> ant111b.lmer
>>>>
>>>> Linear mixed model fit by REML
>>>> Formula: harvwt ~ 1 + (1 | site)
>>>> Data: ant111b
>>>> AIC ? BIC logLik deviance REMLdev
>>>> 100.4 104.8 -47.21 ? ?95.08 ? 94.42
>>>> Random effects:
>>>> Groups ? Name ? ? ? ?Variance Std.Dev.
>>>> site ? ? (Intercept) 2.36773 ?1.53874
>>>> Residual ? ? ? ? ? ? 0.57754 ?0.75996
>>>> Number of obs: 32, groups: site, 8
>>>>
>>>> Fixed effects:
>>>> ? ? ? ?Estimate Std. Error t value
>>>> (Intercept) ? 4.2917 ? ? 0.5603 ? 7.659
>>>>>
>>>>> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
>>>>> VarCorr(ant111b.lmer)
>>>>
>>>> $site
>>>> ? ? ? ?(Intercept)
>>>> (Intercept) ? ?8.363436
>>>> attr(,"stddev")
>>>> (Intercept)
>>>> 2.891961
>>>> attr(,"correlation")
>>>> ? ? ? ?(Intercept)
>>>> (Intercept) ? ? ? ? ? 1
>>>>
>>>> attr(,"sc")
>>>> sigmaREML
>>>> 1.428289
>>>>>
>>>>> summary(ant111b.lmer)
>>>>
>>>> Linear mixed model fit by REML
>>>> Formula: harvwt ~ 1 + (1 | site)
>>>> Data: ant111b
>>>> AIC ? BIC logLik deviance REMLdev
>>>> 112.1 116.5 -53.04 ? ?105.7 ? 106.1
>>>> Random effects:
>>>> Groups ? Name ? ? ? ?Variance Std.Dev.
>>>> site ? ? (Intercept) 8.3634 ? 2.8920
>>>> Residual ? ? ? ? ? ? 2.0400 ? 1.4283
>>>> Number of obs: 32, groups: site, 8
>>>>
>>>> Fixed effects:
>>>> ? ? ? ?Estimate Std. Error t value
>>>> (Intercept) ? 4.2917 ? ? 0.4171 ? 10.29
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 2.9.0 (2009-04-17)
>>>> i386-pc-mingw32
>>>>
>>>> locale:
>>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>> States.1252;LC_MONETARY=English_United
>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>
>>>> other attached packages:
>>>> [1] lme4_0.999375-30 ? Matrix_0.999375-26 lattice_0.17-22
>>>> [4] DAAG_0.99-1 ? ? ? ?MASS_7.2-47
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.9.0
>>>>
>>>>
>>>>
>>>> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>>>> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>>>> Centre for Mathematics & Its Applications, Room 1194,
>>>> John Dedman Mathematical Sciences Building (Building 27)
>>>> Australian National University, Canberra ACT 0200.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------

R version 2.9.0 (2009-04-17)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(DAAG)
Loading required package: MASS

Attaching package: 'DAAG'


	The following object(s) are masked from package:MASS :

	 hills 

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 xtabs 


	The following object(s) are masked from package:base :

	 rcond 

> (ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b))
Linear mixed model fit by REML 
Formula: harvwt ~ 1 + (1 | site) 
   Data: ant111b 
   AIC   BIC logLik deviance REMLdev
 100.4 104.8 -47.21    95.08   94.42
Random effects:
 Groups   Name        Variance Std.Dev.
 site     (Intercept) 2.36773  1.53874 
 Residual             0.57754  0.75996 
Number of obs: 32, groups: site, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.2917     0.5603   7.659
> ant111b.samp <- mcmcsamp(ant111b.lmer, n=1000)
> VarCorr(ant111b.lmer)
$site
            (Intercept)
(Intercept)    2.367733
attr(,"stddev")
(Intercept) 
   1.538744 
attr(,"correlation")
            (Intercept)
(Intercept)           1

attr(,"sc")
sigmaREML 
 0.759959 
> summary(ant111b.lmer)
Linear mixed model fit by REML 
Formula: harvwt ~ 1 + (1 | site) 
   Data: ant111b 
   AIC   BIC logLik deviance REMLdev
 100.4 104.8 -47.21    95.08   94.42
Random effects:
 Groups   Name        Variance Std.Dev.
 site     (Intercept) 2.36773  1.53874 
 Residual             0.57754  0.75996 
Number of obs: 32, groups: site, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.2917     0.5603   7.659
> sessionInfo()
R version 2.9.0 (2009-04-17) 
x86_64-pc-linux-gnu 

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_0.999375-31   Matrix_0.999375-27 lattice_0.17-25    DAAG_0.99-1       
[5] MASS_7.2-47       

loaded via a namespace (and not attached):
[1] grid_2.9.0
> 
> proc.time()
   user  system elapsed 
 14.096   0.224  14.291 

From ken at kjbeath.com.au  Wed May 20 23:34:58 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 21 May 2009 07:34:58 +1000
Subject: [R-sig-ME] random factor variance
In-Reply-To: <57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
	<40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
	<57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
Message-ID: <24F43FB3-727C-44FB-8B6D-8A02A97A45D8@kjbeath.com.au>

On 20/05/2009, at 9:35 PM, Jo?o R. wrote:

> Thanks Ken, but I did not fully understood you.
>
> This means that the variance of the random effect needed to explain  
> your data is zero.
> This part I get, although the fact that the value for variance is an  
> absolute 0 makes me wonder if there is something wrong. I would be  
> happy with a low value, but not exactly 0.

Because the value can't go below zero, it may end up as zero. Even if  
the true value is small but non-zero then sampling variation may cause  
the estimate to be zero.


> The fact that two of the fixed factors are continuous variables  
> might have something to do with it?
> The clusters vary by the same amount or less than if there was a  
> random effect, that is they can all be explained by subject variation.
> This part I don't follow...
>

Think about a population and then dividing it randomly into a number  
of groups. I will assume normal distributions but the same ideas apply  
to binomial etc. We would expect that the groups will have different  
means, and we know how they will vary based on the population  
variance. When we fit a random effect the question we are asking is do  
these vary more than predicted from the population, in which case our  
random effect variance will be greater than zero.

> Basically, I am trying to predict the occurrence of reconciliation  
> after conflicts in a primate group (dependent variable: 0-no  
> occurrence; 1-reconciliation). My random variable is the victim's  
> identity of these conflicts (since not all group members are victims  
> of conflicts, and some are "more victims" than others). As fixed  
> effects I have a set of variables (describing the type of conflict  
> and the relationship between opponents; 23 variables), some  
> continuous (ex. F1, F3) and other categorical (ex. F2, F4 e F5).  
> Using a forward selection procedure based on AIC values, the best  
> fit model is this one I presented with the five fixed factors.
>

I suspect the problem is that your model is overfitted, because of the  
number of possible covariates, and the stepwise selection it has  
constructed a model that fits well without need for a random effect.

Ken


> Thanks again.
>
>
>
>
> On Wed, May 20, 2009 at 10:09 AM, Ken Beath <ken at kjbeath.com.au>  
> wrote:
> On 20/05/2009, at 11:43 AM, Jo?o R. wrote:
>
> Hello,
> I have recently used lme4 package to run a glmm, but a get 0 variance
> explained by the random effect. The model has 5 fixed effects, and I  
> have
> run each of them separately and for two of them (F1, F3) I also get 0
> variance for the random effect. Do you have any ideas of what might be
> causing this? Is this kind of result to be expected?
> thanks
>
>
> This means that the variance of the random effect needed to explain  
> your data is zero.  The clusters vary by the same amount or less  
> than if there was a random effect, that is they can all be explained  
> by subject variation.
>
> Ken
>
>
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: DV ~ F1 + F2 + F3 + F4 + F5 + (1 | R1)
> Data: JD
> AIC   BIC logLik deviance
> 203.2 225.9  -94.6    189.2
> Random effects:
> Groups Name        Variance Std.Dev.
> R1  (Intercept)  0        0
> Number of obs: 190, groups: R1, 14
> Fixed effects:
>          Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.8949     1.1869   1.596  0.11039
> F1          4.6740     2.4365   1.918  0.05507 .
> F2         -2.0657     0.7543  -2.739  0.00617 **
> F3       21.8036     8.8890   2.453  0.01417 *
> F4   1.0968     0.4874   2.250  0.02444 *
> F5      -1.7430     0.9583  -1.819  0.06894 .
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



From danielezrajohnson at gmail.com  Thu May 21 01:47:05 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Wed, 20 May 2009 19:47:05 -0400
Subject: [R-sig-ME] random factor variance
In-Reply-To: <24F43FB3-727C-44FB-8B6D-8A02A97A45D8@kjbeath.com.au>
References: <57e71d6f0905191843p3ace3714r4b4ae92b122113f5@mail.gmail.com>
	<40208989-7355-4317-99C2-99B26AE4D827@kjbeath.com.au>
	<57e71d6f0905200435l1476cfb2sd0c25c456099d650@mail.gmail.com>
	<24F43FB3-727C-44FB-8B6D-8A02A97A45D8@kjbeath.com.au>
Message-ID: <a46630750905201647p125fcdcfj8f339c51453d4793@mail.gmail.com>

> Think about a population and then dividing it randomly into a number of
> groups. I will assume normal distributions but the same ideas apply to
> binomial etc. We would expect that the groups will have different means, and
> we know how they will vary based on the population variance. When we fit a
> random effect the question we are asking is do these vary more than
> predicted from the population, in which case our random effect variance will
> be greater than zero.

This makes sense but doesn't it lead to the conclusion that a non-zero
random effect is always "statistically significant"? In fact I think
that is not necessarily so, and you need to run a test to determine
whether a given variance is significant (i.e. better than chance)...

D



From pa_mchugh at yahoo.com  Thu May 21 01:46:35 2009
From: pa_mchugh at yahoo.com (Peter McHugh)
Date: Wed, 20 May 2009 16:46:35 -0700 (PDT)
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
Message-ID: <447054.75511.qm@web56208.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090520/372904dd/attachment.pl>

From bolker at ufl.edu  Thu May 21 05:12:11 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 20 May 2009 23:12:11 -0400
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <447054.75511.qm@web56208.mail.re3.yahoo.com>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>
Message-ID: <4A14C68B.50107@ufl.edu>

Peter McHugh wrote:
> I apologize in advance if this is a fairly trivial set of questions,
> but I'm fairly new to multi-level models...
> 
> I'm analyzing the results from a field experiment and am interested
> in quantifying the effects of various fertilizer treatments (2
> factors, N and P, each with two levels) and environmental variables
> (i.e., site-level covariates [ENV1...ENVp] that were not controlled
> for, but measured) on plant growth [GROW] across a wide range of
> sites (SITE).  Also, treatments were replicated within sites using a
> randomized complete block (BLOCK) design (the blocks are arranged
> parallel to hillslope contours at each site, and there is no
> replication within blocks).  It's a fairly straightforward design,
> but I'm not 100% sure that I'm specifying my models correctly.  My
> questions are:
> 
> 1) If I'm interested in estimating the main effects of N and P (and
> their interaction) while incoporating site and block (nested within
> site) as random effects WITHOUT incorporating environmental
> variables, is the following model structure correct?
> 
> model1<- lmer(GROW ~ N + P + N*P + (1|SITE) + (1|SITE:BLOCK),
> options...)
> 
> The main reason I ask is that I'm obtaining a miniscule (almost zero)
> variance component for the SITE:BLOCK effect; though this isn't
> surprising, I want to make sure that I've at least specified the
> model correctly.

   The only thing I would check for is that your BLOCK numbers
are truly "nested" within SITE, i.e. that your blocks are numbered
1..n within each site, not 1:(n*N) (where n = # blocks per site,
N = # of sites).  What are n and N?  A common cause of low estimated
block variance is low replication ...

> 2) (partially a design question) Same basic analysis, but now I'm
> interested in incorporating some of the environmental variables that
> were measured at the site level into my model.  In particular, I'm
> interested determining how certain factors (though I didn't control
> for them) may have modified the response of plants to the
> experimental treatments.  Is the following the correct way to do so?
> 
> model2<-lmer(GROW ~ N + P + N*P + ENV1 [plus appropriate trt*cov
> interactions] + (1|SITE:BLOCK), options...)
> 
> I'm particularly curious if replacing the random categorical site
> effect with continuous covariate(s), while retaining the random
> nested block effect, makes sense here.  And if so, whether this is
> the correct way to specify such a model.

  I would leave (1|SITE) in the model to check whether there is residual
site variation that isn't explained by the environmental variables ...

  Ben Bolker



From j.o.villar at bio.uio.no  Thu May 21 13:03:06 2009
From: j.o.villar at bio.uio.no (Jaime Otero Villar)
Date: Thu, 21 May 2009 13:03:06 +0200
Subject: [R-sig-ME] correlation structures doubt
Message-ID: <A753546D-B3C3-4EC5-94DF-02F8FEB7EC95@ulrik.uio.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090521/6928c238/attachment.pl>

From DOgle at northland.edu  Thu May 21 14:03:13 2009
From: DOgle at northland.edu (Derek Ogle)
Date: Thu, 21 May 2009 07:03:13 -0500
Subject: [R-sig-ME] Help with LME model for fish length-weight
Message-ID: <D86C9EFF6AA3734193923FFA1EE4308B08371A9D@nc-mail2.northland.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090521/d4984605/attachment.pl>

From andydolman at gmail.com  Thu May 21 14:15:59 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Thu, 21 May 2009 14:15:59 +0200
Subject: [R-sig-ME] lme/lmer for drug effects on blood pressure
In-Reply-To: <4A13CDCF.3070307@student.uwa.edu.au>
References: <4A108311.50203@student.uwa.edu.au>
	<4A13CDCF.3070307@student.uwa.edu.au>
Message-ID: <951234ac0905210515m1ed5bf5s78618394491dc113@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090521/9953a43d/attachment.pl>

From Paul.Prew at ecolab.com  Thu May 21 17:41:58 2009
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Thu, 21 May 2009 10:41:58 -0500
Subject: [R-sig-ME] repeated measures OR block with time covariate?
In-Reply-To: <40e66e0b0905200822s1d416c48qa6739443a15efdcd@mail.gmail.com>
References: <mailman.5754.1242772296.4616.r-sig-mixed-models@r-project.org>
	<6B810AFB14C606439FD57E5985E0379117A9B8@useagan1500p.GLOBAL.ECOLAB.CORP>
	<40e66e0b0905200822s1d416c48qa6739443a15efdcd@mail.gmail.com>
Message-ID: <6B810AFB14C606439FD57E5985E03791039B7AD2@useagan1500p.GLOBAL.ECOLAB.CORP>

Dear Douglas,  thank you very much for the reply, it is the kind of advice I was looking for.  Regards, Paul


Paul Prew  |  Statistician
651-795-5942?? |?? fax 651-204-7504 
Ecolab Research Center  | Mail Stop ESC-F4412-A 
655 Lone Oak Drive  |  Eagan, MN 55121-1560 

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Wednesday, May 20, 2009 10:23 AM
To: Prew, Paul
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] repeated measures OR block with time covariate?

On Tue, May 19, 2009 at 8:51 PM, Prew, Paul <Paul.Prew at ecolab.com> wrote:
> Hello,

> I've received helpful advice in the past from the readers of this list, and would like some more advice. ?I think I understand that a blocking / nuisance factor in ANOVA will not affect the significance estimates of fixed factors / 'factors of interest', regardless of whether the blocking factor is designed as random or fixed --- the same sum-of-squares are taken off the top in ANOVA. ?Other quantities may be affected, such as prediction intervals for specified levels of the fixed factor. ?Fixed block effects are welcome, because virtually all the literature in experimental design treats Randomized Complete Block Designs as having fixed effects for blocks.

> In a discussion with a colleague today, the following question was posed about repeated measures ~

> A cleaning product is being tested at a sample of hospitals. ?Micro-organism counts are taken over a period of weeks, for a control formulation and an experimental formulation. ?The hospitals are not of interest, and can be considered blocking factors. ?So my interpretation is that there's no harm in designating the hospitals as a fixed effect.

> Within the hospital, we can see week-over-week reductions in micro-organisms. ? ?There's a slope related to time.

> ***** ? Could a fixed effect for the blocking factor Hospital and a fixed covariate Time take the place of what seems to be a good candidate for a repeated measures analysis (assuming that the repeated measures implies Hospital = random effect)? ?*****

Off the top of my head I would say that using fixed effects for the
blocking factor is a conservative approach and probably the best
approach in terms of simplicity.  I'm assuming that the design is
balanced in that each hospital is observed for the same number of
weeks, in which case the hospital and time effects would be
orthogonal.

With regard to the sums of squares, a model with random effects will
remove a smaller part of the sum of squares than will a model with
fixed effects because the random effects are shrunk relative to the
fixed effects.  Thus the residual sum of squares in a random effects
model will be at least as large as that in a model with fixed-effects
for the hospitals.  Consider the enclosed model fits for the
sleepstudy data.

library(lme4)
(fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
summary(fm2 <- lm(Reaction ~ Subject * Days, sleepstudy))
deviance(fm2)  # residual sum of squares for fixed-effects model
fm1 at deviance["wrss"]  # residual sum of squares for mixed model

When run it produces

> deviance(fm2)  # residual sum of squares for fixed-effects model
[1] 94311.5
> fm1 at deviance["wrss"]  # residual sum of squares for mixed model
    wrss
98880.24

There are differences in interpretation, of course.  It is a little
more difficult to decide how you would test for a significant
"typical" slope in the fixed-effects model than in the mixed model.
The parameter labeled "Days" in the fixed-effects model is the
estimate of the slope for the first Subject, not a typical subject.

The big advantage of using lm instead of lmer in a situation like this
is that lm gives you p-values and lmer doesn't. :-)


> Any thought are greatly appreciated. ?There's actually a Standard Operating Procedure being written for our scientists and engineers designating they use the repeated measures analysis. ?I think it's over their heads, given that few could credibly define degrees of freedom, p-value, or other basic statistical concepts. ?An approach that sticks to the "Randomized Complete Block Designs / fixed effects for blocks" is better suited, if it performs as well as the repeated measures design.
>
> Regards, Paul
>
> ?Paul Prew ?| ?Statistician
> ?651-795-5942 ? | ? fax 651-204-7504
> ?Ecolab Research Center ?| Mail Stop ESC-F4412-A
> ?655 Lone Oak Drive ?| ?Eagan, MN 55121-1560
>
>
>
> CONFIDENTIALITY NOTICE:
> This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above.
> Any unauthorized review, use, disclosure or distribution is prohibited.
> If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
CONFIDENTIALITY NOTICE: =\ \ This e-mail communication a...{{dropped:12}}



From Mark.Schultz2 at va.gov  Thu May 21 18:22:20 2009
From: Mark.Schultz2 at va.gov (Schultz, Mark R.)
Date: Thu, 21 May 2009 12:22:20 -0400
Subject: [R-sig-ME] Newbie looking for documentation
Message-ID: <263B04CBBF074046AFD8E36BA524E617041E786F@VHAV01MSGA2.v01.med.va.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090521/39d506ee/attachment.pl>

From HStevens at muohio.edu  Thu May 21 18:54:36 2009
From: HStevens at muohio.edu (Hank Stevens)
Date: Thu, 21 May 2009 12:54:36 -0400
Subject: [R-sig-ME] Newbie looking for documentation
In-Reply-To: <263B04CBBF074046AFD8E36BA524E617041E786F@VHAV01MSGA2.v01.med.va.gov>
References: <263B04CBBF074046AFD8E36BA524E617041E786F@VHAV01MSGA2.v01.med.va.gov>
Message-ID: <bfd10a120905210954m47aaf8a2j4f7fbed045ee5af0@mail.gmail.com>

I really really like
Gelman and Hill (2007) "Data Analysis Using Regression and
Multilevel/Hierarchical Models" Cambridge.

On Thu, May 21, 2009 at 12:22 PM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
> Hi All:
> ? I'm trying to make the transition from the dark side (SAS) and would
> like to lmer if I could find some good tutorial material to get me
> started. Any ideas?
> Many thanks,
> Mark Schultz
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Hank Stevens
http://www.cas.muohio.edu/~stevenmh/
513-529-4206
E pluribus unum



From baron at psych.upenn.edu  Thu May 21 19:04:44 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 21 May 2009 13:04:44 -0400
Subject: [R-sig-ME] Newbie looking for documentation
In-Reply-To: <bfd10a120905210954m47aaf8a2j4f7fbed045ee5af0@mail.gmail.com>
References: <263B04CBBF074046AFD8E36BA524E617041E786F@VHAV01MSGA2.v01.med.va.gov>
	<bfd10a120905210954m47aaf8a2j4f7fbed045ee5af0@mail.gmail.com>
Message-ID: <20090521170444.GA7524@psych.upenn.edu>

I like Gelman and Hill too, but it is not very helpful for people
interested in hypothesis testing.  It is, I think, written mainly for
those who work in fields (including many in the social sciences) where
it makes sense to say that "the null hypothesis is always false."
That is bothersome to those of us who design careful experiments
explicitly to give the null hypothesis a real chance (and where all
too often it grasps the opportunity).

If this is your situation, I recommend Bates's article in R-news:
http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf
and the papers in the last issue of the Journal of Memory and
Language, 2008, or maybe the one before that, starting with Baayen,
Davidson, and Bates.

Jon

On 05/21/09 12:54, Hank Stevens wrote:
> I really really like
> Gelman and Hill (2007) "Data Analysis Using Regression and
> Multilevel/Hierarchical Models" Cambridge.
> 
> On Thu, May 21, 2009 at 12:22 PM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
> > Hi All:
> >   I'm trying to make the transition from the dark side (SAS) and would
> > like to lmer if I could find some good tutorial material to get me
> > started. Any ideas?
> > Many thanks,
> > Mark Schultz
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> -- 
> Hank Stevens
> http://www.cas.muohio.edu/~stevenmh/
> 513-529-4206
> E pluribus unum
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From DAfshartous at med.miami.edu  Thu May 21 19:08:52 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Thu, 21 May 2009 13:08:52 -0400
Subject: [R-sig-ME] Newbie looking for documentation
In-Reply-To: <bfd10a120905210954m47aaf8a2j4f7fbed045ee5af0@mail.gmail.com>
Message-ID: <C63B02E4.A2C6%dafshartous@med.miami.edu>


Also check out the following link for SAS/SPSS/Stata users transitioning to R:
http://www.statmethods.net/index.html


On 5/21/09 12:54 PM, "Hank Stevens" <HStevens at muohio.edu> wrote:

I really really like
Gelman and Hill (2007) "Data Analysis Using Regression and
Multilevel/Hierarchical Models" Cambridge.

On Thu, May 21, 2009 at 12:22 PM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
> Hi All:
>   I'm trying to make the transition from the dark side (SAS) and would
> like to lmer if I could find some good tutorial material to get me
> started. Any ideas?
> Many thanks,
> Mark Schultz
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



--
Hank Stevens
http://www.cas.muohio.edu/~stevenmh/
513-529-4206
E pluribus unum

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rmh3093 at gmail.com  Thu May 21 19:42:48 2009
From: rmh3093 at gmail.com (Ryan Hope)
Date: Thu, 21 May 2009 13:42:48 -0400
Subject: [R-sig-ME] Newbie looking for documentation
In-Reply-To: <20090521170444.GA7524@psych.upenn.edu>
References: <263B04CBBF074046AFD8E36BA524E617041E786F@VHAV01MSGA2.v01.med.va.gov>
	<bfd10a120905210954m47aaf8a2j4f7fbed045ee5af0@mail.gmail.com>
	<20090521170444.GA7524@psych.upenn.edu>
Message-ID: <48f7fe350905211042s72ea5fbepe8180a2d8d683a0d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090521/ea35eeae/attachment.pl>

From r.turner at auckland.ac.nz  Thu May 21 23:05:37 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 22 May 2009 09:05:37 +1200
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <4A14C68B.50107@ufl.edu>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>
	<4A14C68B.50107@ufl.edu>
Message-ID: <E89DC451-E5C6-412E-A779-7012AA8258AA@auckland.ac.nz>


On 21/05/2009, at 3:12 PM, Ben Bolker wrote:

	<snip>

>    The only thing I would check for is that your BLOCK numbers
> are truly "nested" within SITE, i.e. that your blocks are numbered
> 1..n within each site, not 1:(n*N) (where n = # blocks per site,
> N = # of sites).

	<snip>

I was under the impression that lmer() required that nested effects
have *distinct* subscripts for their levels, e.g. block 1 in site 1
should *not* have the same index as block 1 in site 2 --- they being
after all, different blocks.  I thought that this was one of Doug
Bates' particular pet peeves about the (irrational) way that other
packages (e.g. The-Package-That-Must-Not-Be-Named) do things.

Have I been suffering from a misapprehension?  Wouldn't be the first  
time ....

	cheers,

		Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From HStevens at muohio.edu  Thu May 21 23:14:37 2009
From: HStevens at muohio.edu (Hank Stevens)
Date: Thu, 21 May 2009 17:14:37 -0400
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <E89DC451-E5C6-412E-A779-7012AA8258AA@auckland.ac.nz>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>
	<4A14C68B.50107@ufl.edu>
	<E89DC451-E5C6-412E-A779-7012AA8258AA@auckland.ac.nz>
Message-ID: <bfd10a120905211414w2fc5ab11occ6a3b8f897e12a1@mail.gmail.com>

HI Rolf,
The BLOCK numbers should reflect their "true" underlying nature.
These data would suggest that Site and Block are crossed because e.g.
BLOCK 1 exists at two sites:
SITE  BLOCK
1    1
1    2
1    3
2    1
2    2
2    3

These data would suggest that Blocks are unique (and therefore
necessarily nested within Sites):
SITE  BLOCK
1    1
1    2
1    3
2    4
2    5
2    6

Hank

On Thu, May 21, 2009 at 5:05 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 21/05/2009, at 3:12 PM, Ben Bolker wrote:
>
> ? ? ? ?<snip>
>
>> ? The only thing I would check for is that your BLOCK numbers
>> are truly "nested" within SITE, i.e. that your blocks are numbered
>> 1..n within each site, not 1:(n*N) (where n = # blocks per site,
>> N = # of sites).
>
> ? ? ? ?<snip>
>
> I was under the impression that lmer() required that nested effects
> have *distinct* subscripts for their levels, e.g. block 1 in site 1
> should *not* have the same index as block 1 in site 2 --- they being
> after all, different blocks. ?I thought that this was one of Doug
> Bates' particular pet peeves about the (irrational) way that other
> packages (e.g. The-Package-That-Must-Not-Be-Named) do things.
>
> Have I been suffering from a misapprehension? ?Wouldn't be the first time
> ....
>
> ? ? ? ?cheers,
>
> ? ? ? ? ? ? ? ?Rolf Turner
>
> ######################################################################
> Attention:\ This e-mail message is privileged and confid...{{dropped:9}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Hank Stevens
http://www.cas.muohio.edu/~stevenmh/
513-529-4206
E pluribus unum



From r.turner at auckland.ac.nz  Thu May 21 23:17:55 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 22 May 2009 09:17:55 +1200
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <bfd10a120905211414w2fc5ab11occ6a3b8f897e12a1@mail.gmail.com>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>
	<4A14C68B.50107@ufl.edu>
	<E89DC451-E5C6-412E-A779-7012AA8258AA@auckland.ac.nz>
	<bfd10a120905211414w2fc5ab11occ6a3b8f897e12a1@mail.gmail.com>
Message-ID: <90B8EF26-2715-469D-B3CB-6CCC25D17130@auckland.ac.nz>


On 22/05/2009, at 9:14 AM, Hank Stevens wrote:

> HI Rolf,
> The BLOCK numbers should reflect their "true" underlying nature.
> These data would suggest that Site and Block are crossed because e.g.
> BLOCK 1 exists at two sites:
> SITE  BLOCK
> 1    1
> 1    2
> 1    3
> 2    1
> 2    2
> 2    3
>
> These data would suggest that Blocks are unique (and therefore
> necessarily nested within Sites):
> SITE  BLOCK
> 1    1
> 1    2
> 1    3
> 2    4
> 2    5
> 2    6

That's what I thought.  But it's the opposite of what Ben Bolker said.
Unless, of course, I'm totally confused.

	cheers,

		Rolf

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From charpent at bacbuc.dyndns.org  Thu May 21 23:53:16 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Thu, 21 May 2009 23:53:16 +0200
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <90B8EF26-2715-469D-B3CB-6CCC25D17130@auckland.ac.nz>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>
	<4A14C68B.50107@ufl.edu>
	<E89DC451-E5C6-412E-A779-7012AA8258AA@auckland.ac.nz>
	<bfd10a120905211414w2fc5ab11occ6a3b8f897e12a1@mail.gmail.com>
	<90B8EF26-2715-469D-B3CB-6CCC25D17130@auckland.ac.nz>
Message-ID: <1242942795.5217.2.camel@yod>

Unless I'm badly mistaken, the notation (1|Site/Block) unambiguously
nests blocks within sites, whatever their labels might be. And means (1
| Site) + (1 | (RenamedBlocks:Site)

Right ?

					Emmanuel Charpentier

Le vendredi 22 mai 2009 ? 09:17 +1200, Rolf Turner a ?crit :
> On 22/05/2009, at 9:14 AM, Hank Stevens wrote:
> 
> > HI Rolf,
> > The BLOCK numbers should reflect their "true" underlying nature.
> > These data would suggest that Site and Block are crossed because e.g.
> > BLOCK 1 exists at two sites:
> > SITE  BLOCK
> > 1    1
> > 1    2
> > 1    3
> > 2    1
> > 2    2
> > 2    3
> >
> > These data would suggest that Blocks are unique (and therefore
> > necessarily nested within Sites):
> > SITE  BLOCK
> > 1    1
> > 1    2
> > 1    3
> > 2    4
> > 2    5
> > 2    6
> 
> That's what I thought.  But it's the opposite of what Ben Bolker said.
> Unless, of course, I'm totally confused.
> 
> 	cheers,
> 
> 		Rolf
> 
> ######################################################################
> Attention:\ This e-mail message is privileged and confid...{{dropped:9}}
> 



From bolker at ufl.edu  Fri May 22 01:46:54 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 21 May 2009 19:46:54 -0400
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <1242941308.11653.1.camel@stevenmh-desktop>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>	
	<4A14C68B.50107@ufl.edu>
	<1242941308.11653.1.camel@stevenmh-desktop>
Message-ID: <4A15E7EE.5010305@ufl.edu>

  what I meant was, that if your blocks within sites were labeled
uniquely as 1,...,n*N you should specify your (block "within" site)
effect as (1|BLOCK), whereas if they were labeled 1,..,n,1,..,n,1,..,n
... you should specify it as (1|SITE:BLOCK) as Rolf did.  If your
blocks are labeled uniquely and you specify (1|SITE:BLOCK) then you
end up with a lot of empty SITE:BLOCK combinations (because e.g.
block 72 only occurs in site 14, but your model includes terms for
block 72 in every site).
  I hope that's now clear and that I'm right, but please correct
me if necessary!

  cheers
    Ben

Hank Stevens wrote:
> Ben,
> Did you mean it like this? I was under the impression it was the other
> way around ... .
> Hank
> On Wed, 2009-05-20 at 23:12 -0400, Ben Bolker wrote:
>>    The only thing I would check for is that your BLOCK numbers
>> are truly "nested" within SITE, i.e. that your blocks are numbered
>> 1..n within each site, not 1:(n*N) (where n = # blocks per site,
>> N = # of sites).  What are n and N?  A common cause of low estimated
>> block variance is low replication ...
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From albrem04 at student.uwa.edu.au  Fri May 22 07:50:09 2009
From: albrem04 at student.uwa.edu.au (Matthew Albrecht)
Date: Fri, 22 May 2009 13:50:09 +0800
Subject: [R-sig-ME] lme/lmer for drug effects on blood pressure
In-Reply-To: <951234ac0905210515m1ed5bf5s78618394491dc113@mail.gmail.com>
References: <4A108311.50203@student.uwa.edu.au>	
	<4A13CDCF.3070307@student.uwa.edu.au>
	<951234ac0905210515m1ed5bf5s78618394491dc113@mail.gmail.com>
Message-ID: <4A163D11.9090205@student.uwa.edu.au>

Thanks Andrew, much appreciated.

Andrew Dolman wrote:
> Hi Matthew,
>
> You haven't had any other replies so I'll just note that
>
> lmer(pressure~drug*poly(timep,2)+(1|ID), data=drugdat)
>
> looks OK to me.
>
>
>
>
>
> andydolman at gmail.com <mailto:andydolman at gmail.com>
>
>
> 2009/5/20 Matthew Albrecht <albrem04 at student.uwa.edu.au
> <mailto:albrem04 at student.uwa.edu.au>>
>
>     Matthew Albrecht wrote:
>     > Looking at the data, it looks parabolic, so I fitted the data to a
>     > second order polynomial:
>
>     I've just been pointed out the incorrectness of this sentence.
>     Apologies, it should read:
>     "I fitted a second order polynomial to the data."
>
>     I'm using the excuse that it was quite a late night that night.
>     Matt
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From David.Duffy at qimr.edu.au  Fri May 22 08:12:57 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 22 May 2009 16:12:57 +1000 (EST)
Subject: [R-sig-ME] lme/lmer for drug effects on blood pressure
In-Reply-To: <4A163D11.9090205@student.uwa.edu.au>
References: <4A108311.50203@student.uwa.edu.au>
	<4A13CDCF.3070307@student.uwa.edu.au><951234ac0905210515m1ed5bf5s78618394491dc113@mail.gmail.com>
	<4A163D11.9090205@student.uwa.edu.au>
Message-ID: <Pine.LNX.4.64.0905221609560.2293@orpheus.qimr.edu.au>

On Fri, 22 May 2009, Matthew Albrecht wrote:

> Thanks Andrew, much appreciated.
>
> Andrew Dolman wrote:
>> Hi Matthew,
>>
>> You haven't had any other replies so I'll just note that
>>
>> lmer(pressure~drug*poly(timep,2)+(1|ID), data=drugdat)
>>
>> looks OK to me.
>

If the random effects are not too complicated and you are interested in 
the effects of timep, you might like to compare results using the
SemiPar and mgcv packages -- both can fit GAMMs and the like (and make 
pretty graphics ;))

Cheers, David Duffy.



From cotter.rs at gmail.com  Fri May 22 10:31:05 2009
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Fri, 22 May 2009 10:31:05 +0200
Subject: [R-sig-ME] Confidence interval when using lme
Message-ID: <742479270905220131g44c00999y514c595a2d4cde32@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090522/87873042/attachment.pl>

From HStevens at muohio.edu  Fri May 22 11:33:31 2009
From: HStevens at muohio.edu (Hank Stevens)
Date: Fri, 22 May 2009 05:33:31 -0400
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <4A15E7EE.5010305@ufl.edu>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>
	<4A14C68B.50107@ufl.edu> <1242941308.11653.1.camel@stevenmh-desktop>
	<4A15E7EE.5010305@ufl.edu>
Message-ID: <bfd10a120905220233h4e5f169djab17e0dad217c9c@mail.gmail.com>

Hi folks,
Turns out that regardless how they are coded,
... (1|site) + (1|site:block) and
... (1|site/block)

give the same model even though Ben is right that USUALLY SITE:BLOCK
would return a block 72 in each site. I checked str(model) and also
looked at the outputs and it turns out that lmer must quietly drop
used levels in random effects. HOWEVER, if you code BLOCKs
non-uniquely and then rwrite

... (1|SITE) + (1|BLOCK)

then you get crossed random effects.

Hank

On Thu, May 21, 2009 at 7:46 PM, Ben Bolker <bolker at ufl.edu> wrote:
> ?what I meant was, that if your blocks within sites were labeled
> uniquely as 1,...,n*N you should specify your (block "within" site)
> effect as (1|BLOCK), whereas if they were labeled 1,..,n,1,..,n,1,..,n
> ... you should specify it as (1|SITE:BLOCK) as Rolf did. ?If your
> blocks are labeled uniquely and you specify (1|SITE:BLOCK) then you
> end up with a lot of empty SITE:BLOCK combinations (because e.g.
> block 72 only occurs in site 14, but your model includes terms for
> block 72 in every site).
> ?I hope that's now clear and that I'm right, but please correct
> me if necessary!
>
> ?cheers
> ? ?Ben
>
> Hank Stevens wrote:
>> Ben,
>> Did you mean it like this? I was under the impression it was the other
>> way around ... .
>> Hank
>> On Wed, 2009-05-20 at 23:12 -0400, Ben Bolker wrote:
>>> ? ?The only thing I would check for is that your BLOCK numbers
>>> are truly "nested" within SITE, i.e. that your blocks are numbered
>>> 1..n within each site, not 1:(n*N) (where n = # blocks per site,
>>> N = # of sites). ?What are n and N? ?A common cause of low estimated
>>> block variance is low replication ...
>>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>



-- 
Hank Stevens
http://www.cas.muohio.edu/~stevenmh/
513-529-4206
E pluribus unum



From alison.johnston at bto.org  Fri May 22 12:45:56 2009
From: alison.johnston at bto.org (Alison Johnston)
Date: Fri, 22 May 2009 11:45:56 +0100
Subject: [R-sig-ME] models with overdispersion and autocorr.
Message-ID: <80AE0EFB21C046D1ACE3786CCB3FE8F5@btodomain.bto.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090522/fb3321c5/attachment.pl>

From bates at stat.wisc.edu  Fri May 22 15:51:13 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 22 May 2009 08:51:13 -0500
Subject: [R-sig-ME] New to LMER with 2 (easy?) questions...
In-Reply-To: <bfd10a120905220233h4e5f169djab17e0dad217c9c@mail.gmail.com>
References: <447054.75511.qm@web56208.mail.re3.yahoo.com>
	<4A14C68B.50107@ufl.edu> <1242941308.11653.1.camel@stevenmh-desktop>
	<4A15E7EE.5010305@ufl.edu>
	<bfd10a120905220233h4e5f169djab17e0dad217c9c@mail.gmail.com>
Message-ID: <40e66e0b0905220651l5642f1eaxf14b8db8a4a62892@mail.gmail.com>

On Fri, May 22, 2009 at 4:33 AM, Hank Stevens <HStevens at muohio.edu> wrote:
> Hi folks,
> Turns out that regardless how they are coded,
> ... (1|site) + (1|site:block) and
> ... (1|site/block)
>
> give the same model even though Ben is right that USUALLY SITE:BLOCK
> would return a block 72 in each site. I checked str(model) and also
> looked at the outputs and it turns out that lmer must quietly drop
> used levels in random effects.

I think you meant "drop unused levels" and yes, lmer does do that.
It's conventional in model-building functions to set
drop.unused.levels = TRUE in the call to model.frame

I think that the computational methods in lmer would continue to work
even if the unused levels were not dropped (although the conventional
approach wouldn't) but retaining them would just introduce a lot of
extra computation for no gain.

> HOWEVER, if you code BLOCKs
> non-uniquely and then rwrite
>
> ... (1|SITE) + (1|BLOCK)
>
> then you get crossed random effects.
>
> Hank
>
> On Thu, May 21, 2009 at 7:46 PM, Ben Bolker <bolker at ufl.edu> wrote:
>> ?what I meant was, that if your blocks within sites were labeled
>> uniquely as 1,...,n*N you should specify your (block "within" site)
>> effect as (1|BLOCK), whereas if they were labeled 1,..,n,1,..,n,1,..,n
>> ... you should specify it as (1|SITE:BLOCK) as Rolf did. ?If your
>> blocks are labeled uniquely and you specify (1|SITE:BLOCK) then you
>> end up with a lot of empty SITE:BLOCK combinations (because e.g.
>> block 72 only occurs in site 14, but your model includes terms for
>> block 72 in every site).
>> ?I hope that's now clear and that I'm right, but please correct
>> me if necessary!
>>
>> ?cheers
>> ? ?Ben
>>
>> Hank Stevens wrote:
>>> Ben,
>>> Did you mean it like this? I was under the impression it was the other
>>> way around ... .
>>> Hank
>>> On Wed, 2009-05-20 at 23:12 -0400, Ben Bolker wrote:
>>>> ? ?The only thing I would check for is that your BLOCK numbers
>>>> are truly "nested" within SITE, i.e. that your blocks are numbered
>>>> 1..n within each site, not 1:(n*N) (where n = # blocks per site,
>>>> N = # of sites). ?What are n and N? ?A common cause of low estimated
>>>> block variance is low replication ...
>>>>
>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>
>
>
> --
> Hank Stevens
> http://www.cas.muohio.edu/~stevenmh/
> 513-529-4206
> E pluribus unum
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From dieter.menne at menne-biomed.de  Fri May 22 15:58:14 2009
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 22 May 2009 13:58:14 +0000 (UTC)
Subject: [R-sig-ME] Confidence interval when using lme
References: <742479270905220131g44c00999y514c595a2d4cde32@mail.gmail.com>
Message-ID: <loom.20090522T135536-542@post.gmane.org>

R.S. Cotter <cotter.rs at ...> writes:

> 
> I have been using lme, and also intervals.lme to estimate the confidence
> interval for the parameter estimates.
> 
> Here is my model:
> 
> lmefitted1<-lme(Feedingtime ~ Weight*Feeder, random=~1|ID,data=prey)

You probably mean the popular curved confidence bands? The intervals of
the slope itself are given by Weight*Feeder
 
> How do I get the confidence intervals for the regression line when using
> lme?

As Spencer Graves said: It's difficult. And he cites Douglas Bates 
"it on the list".

http://markmail.org/message/2bapuxmpcc27diuw

Dieter



From charpent at bacbuc.dyndns.org  Fri May 22 16:16:44 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 22 May 2009 16:16:44 +0200
Subject: [R-sig-ME] models with overdispersion and autocorr.
In-Reply-To: <80AE0EFB21C046D1ACE3786CCB3FE8F5@btodomain.bto.org>
References: <80AE0EFB21C046D1ACE3786CCB3FE8F5@btodomain.bto.org>
Message-ID: <1243001804.13001.10.camel@yod>

Le vendredi 22 mai 2009 ? 11:45 +0100, Alison Johnston a ?crit :
> Hi there
> 
> I'm trying to fit repeated count models at several locations.  The locations are a random effect as there are >50, and we're not interested in the actual location values.
> But the data needs to be fitted with a quasi or zero-inflated model, and there is autocorrelation through time.  
> 
> I can't find a function which allows quasi/zi AND autocorrelation to be fitted.  Is there one?  Or is there another way the model could be constructed to avoid the problem?

Douglas Bates has written the necessary correlation and covariance
functions ... for nlme (function lme and such...). These functions do
not (yet) exist in lme4 (lmer and consorts), alas ... You might try to
bug him, but what he said about his current schedule makes me strongly
doubt this attemp would be met with any success (or popularity with him,
BTW :)...

I don't know what GAMs can do in this case, and I don't know what has
been implemented in availagle R packages.

May I drag from my (cluttered) cave the suggestion to find a relevant
change of variable which, temporarily disccarding the random effects,
might allow an approximate analysis with ... lme ? In other words, can
you think of a variable transformation that would approximately
normalize your residuals ? In this case, correlation and variance
modeling functions available in nlme would take care of autocorrelation
and possible remaining heteroscedasticity. Then lme and/or its nonlinear
cousins would be able to account for your random effects.

HTH,

					Emmanuel Charpentier



From charpent at bacbuc.dyndns.org  Fri May 22 17:09:58 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 22 May 2009 17:09:58 +0200
Subject: [R-sig-ME] Poor man's metaregression with lmer ?
Message-ID: <1243004997.13001.62.camel@yod>

Dear List,

I have a curious problem : I want to aggregate results from
*observational* studies (the only ones available on my particular
subject), attempt to assess the possible effect of a few (boolean)
factors and compare a single (new) study results, which gives results
extremely different from what is published, to this aggregation.

The study object is the failure rate of a certain medical device. The
current literature on the subject is extremely poor : what can be (more
or less) assessed on each study is participant's sex ratio, presence or
not of patient of three vaguely defined age groups, gross device
characteristics (small/medium/large, titanium/alloy), number of
patients, number of devices (more than one/pt is quite likely), number
of failures.

The first goal (aggregation) isn't very difficult, but...

One obvious solution is mima : transform each failure rate f in logit
(log(f/(1-f)) with estimated variance 1/(n*f+0.5)+1/(n*(1-f)+0.5). With
a hiccup : three of the series have no failure or no success (yes, both
can happen ...), which gives an infinite log(OR). Ouch ! Excluding them
is not acceptable, and adding 0.5 to all counts (aka "continuity
correction") will anyway be judged pass? by the panel ...

Another (ignorable ?) problem with this approach is that, while most of
the effects are indiscutably fixed (e. g. device material), others might
be considered random (device design...). I do not know how to specify
this in the (current) mima() function.

Another obvious solution is, of course, (g)lmer : fitting the null model
is as simple as :
null.mod<-lmer(cbind(Fail, NonFail)~1+(1|StudyId), data=MyData,
family=binomial, subset=StudyId!="MyStudy")

The (Intercept) estimator of this model is, IMHO, the estimator of the
logit of the "true" (i. e. thought of as universal) failure rate of this
kind of device. Which would solve my first problem.

And, for example, formally testing for an effect of device material (my
second problem) could be (at least approximately) with
Mat.mod<-update(null.mod, .~.+Mat)
anova(null.mod, Mat.mod, test="Chisq")

Do you see problems with this approach ?

The last problem is, IMHO, not really a problem : the "new" study
reports a failure rate more than twice what can be estimated from
previous studies. The "naive" (binomial) confidence intervals do not
even overlap ! But I'm quite certain that in the panel, some dumbass
playing Sunday statistician (their name is legion in the medical field)
will *require* a p-value.

What about :

MyStud.null.mod<-null.mod<-lmer(cbind(Fail, NonFail)~1+(1|StudyId),
data=MyData, family=binomial)
MyStud.mod<-update(MyStud.null.mod,.~.+I(StudyId=="MyStudy")
anova(MyStudNull,MyStud, test="Chisq")

Again : do you see problems with that ?

Thanks in advance

					Emmanuel Charpentier

PS : Note to Wolfgang Viechtbauer, if he reads this : your new version
of mima() is, as you can see, eagerly awaited...



From David.Duffy at qimr.edu.au  Fri May 22 23:50:24 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sat, 23 May 2009 07:50:24 +1000 (EST)
Subject: [R-sig-ME] Poor man's metaregression with lmer ?
In-Reply-To: <1243004997.13001.62.camel@yod>
References: <1243004997.13001.62.camel@yod>
Message-ID: <Pine.LNX.4.64.0905230740160.15554@orpheus.qimr.edu.au>

On Fri, 22 May 2009, Emmanuel Charpentier wrote:

> One obvious solution is mima : transform each failure rate f in logit
> (log(f/(1-f)) with estimated variance 1/(n*f+0.5)+1/(n*(1-f)+0.5). With
> a hiccup : three of the series have no failure or no success (yes, both
> can happen ...), which gives an infinite log(OR). Ouch ! Excluding them
> is not acceptable, and adding 0.5 to all counts (aka "continuity
> correction") will anyway be judged passe by the panel ...

You just have to explain that you are using maximum penalized likelihood, 
with the Jeffreys invariant prior as penalty function ;).  See the brlr 
and logistf packages and refs.  If you did have time to failure, there 
is also a coxphf.  We usually present results from both the fixed 
and random effects metaanalysis -- your lmer code looks OK to me.

David Duffy.



From charpent at bacbuc.dyndns.org  Sat May 23 09:28:37 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Sat, 23 May 2009 09:28:37 +0200
Subject: [R-sig-ME] Poor man's metaregression with lmer ?
In-Reply-To: <Pine.LNX.4.64.0905230740160.15554@orpheus.qimr.edu.au>
References: <1243004997.13001.62.camel@yod>
	<Pine.LNX.4.64.0905230740160.15554@orpheus.qimr.edu.au>
Message-ID: <1243063717.5431.14.camel@yod>

Le samedi 23 mai 2009 ? 07:50 +1000, David Duffy a ?crit :
> On Fri, 22 May 2009, Emmanuel Charpentier wrote:
> 
> > One obvious solution is mima : transform each failure rate f in logit
> > (log(f/(1-f)) with estimated variance 1/(n*f+0.5)+1/(n*(1-f)+0.5). With
> > a hiccup : three of the series have no failure or no success (yes, both
> > can happen ...), which gives an infinite log(OR). Ouch ! Excluding them
> > is not acceptable, and adding 0.5 to all counts (aka "continuity
> > correction") will anyway be judged passe by the panel ...
> 
> You just have to explain that you are using maximum penalized likelihood, 
> with the Jeffreys invariant prior as penalty function ;).

:-)) *I* won't face a panel : the student who (foolishly ? ) seeked my
help will...

>                                                            See the brlr 
> and logistf packages and refs.  If you did have time to failure, there 
> is also a coxphf.  We usually present results from both the fixed 
> and random effects metaanalysis -- your lmer code looks OK to me.

Thank you for your review ! So lmer() it probably will be (but I'll
check the mima() approximation...).

What a pity that lme4 doesn't (yet ...) have covariance and correlation
modelling functions...

					Emmanuel Charpentier



From highstat at highstat.com  Sat May 23 12:36:31 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Sat, 23 May 2009 11:36:31 +0100
Subject: [R-sig-ME] models with overdispersion and autocorr.
Message-ID: <20090523103629.89F83E38019@smtpauth02.csee.onr.siteprotect.com>


>Hi there
>
>I'm trying to fit repeated count models at several locations.  The 
>locations are a random effect as there are >50, and we're not 
>interested in the actual location values.
>But the data needs to be fitted with a quasi or zero-inflated model, 
>and there is autocorrelation through time.
>
>I can't find a function which allows quasi/zi AND autocorrelation to 
>be fitted.  Is there one?  Or is there another way the model could 
>be constructed to avoid the problem?
>
>Thanks,

Alison,
I guess you want the following:

Y_ijk ~ ZIP(mu_ijk, pi_ijk)              (or its NB cousin)
Y_ijk = observation i at time j at location k

logit(pi_ijk) = X_ijk* beta     + b_k + epsilon_ijk
log(mu_ijk) = X'_ijk * beta' +  b'_k  + eta_ijk

Then this can be solved in RBugs. So..MCMC stuff. The b_k and b'_k 
are the random intercepts for location. The epsilon and eta can be 
used to introduce some extra auto-regressive correlation. See also 
Ntzoufras (2009) for ZIP code, or Chapter 23 in Zuur et al (2009) for 
a simple auto-correlation Poisson GLM example. In fact, most of the 
ingredients are in Ntzoufras (2009).

But such a model would only do correlation between observations from 
the same location. Things get a bit more nasty if you also have 
correlation between locations (if your birds fly from one location to 
nearby locations in the same year)....and it becomes even more nasty 
if your birds fly from one location to another location the next 
year. I guess you could try to add some spatial correlations via the 
epsilon and the eta..using some of the spatial correlation functions 
described in Chapter 5 of Pinheiro and Bates (2000). That would be 
very nice to try...:-).  Try to visualise a very big correlation 
matrix for the entire data set. Which values would be most correlated?

The ZIP above can be fitted in RBugs.......but I guess that you want 
to do this in the context of a GAM? Then you need to program the 
spline into X*beta. See Wood (2006).


It is not impossible to solve this problem...but it will keep you 
busy for a while. We have a book scheduled for the end of 2009 in 
which all this stuff is applied; "Analysing Ecological Data; 
Practical Solutions When Things Get Complicated". Not that this is of 
much use to you right now.

Have fun..:-).

Alain




Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.



2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.



3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer





Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177



From ken at kjbeath.com.au  Sun May 24 02:11:50 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Sun, 24 May 2009 10:11:50 +1000
Subject: [R-sig-ME] lme/lmer for drug effects on blood pressure
In-Reply-To: <4A108311.50203@student.uwa.edu.au>
References: <4A108311.50203@student.uwa.edu.au>
Message-ID: <1CEA9FDF-CA7D-4316-A808-01C035268658@kjbeath.com.au>

On 18/05/2009, at 7:35 AM, Matthew Albrecht wrote:

> Dear list,
> I am using lme/lmer to model blood pressure whilst under either drug  
> or
> placebo. Design- Every participant receives both drug and placebo on  
> two
> separate occasions. Blood pressure is measured in each person at 0,  
> 75,
> 130, 180 and 270 min post ingestion. I have been reading Pinheiro and
> Bates and the R-lists and just wanted to make sure my method is sound.
> Looking at the data, it looks parabolic, so I fitted the data to a
> second order polynomial:
>
> lmer(pressure~drug*poly(timep,2)+(1|ID), data=drugdat)
> or
> lme(pressure~drug*poly(timep,2), random=~1|ID, data=drugdat,
> na.action=na.omit)
>
> More complicated random effects terms such as "(1|ID) + (1|ID:drug)" -
> which to me means that each person has a different blood pressure
> baseline, and each person's blood pressure reacts to the drug
> differently(?) - make no improvements on the model (needs more
> replicates?), anything I've missed or any errors in my thinking/ 
> process?
>

I would interpret (1|ID:drug) as each person has a different baseline  
depending on drug, which doesn't seem physically reasonable.

I tried random effects on the shape of the polynomial (I think I've  
got the lmer commands right, but I haven't put a lot of thought into it)

lmer2<-lmer(pressure~drug*poly(timep,2)+(poly(timep,2)|ID),  
data=drugdat)
lmer3<-lmer(pressure~drug*poly(timep,2)+(poly(timep,2)|ID/drug),  
data=drugdat)

They don't improve the model fit, but that is what you would expect  
with only 18 subjects, and a residual std dev of 10.

A graph shows that there is a fair amount of error in the measurements.

xyplot(pressure~timep|ID,groups=drug,type="l",data=drugdat)

Modelling log pressure may be an alternative worth trying.

Ken

> Thanks,
> Matthew Albrecht
> UWA, Pharmacology
>
>
> Code  
> below..............................................................
>
> # Data generation
> ID<-1:18
> drug<-rep(c(1,2), c(90,90))
> timep<-rep(c(0,75,130,180,270), c(18,18,18,18,18))
> pressure<- 
> c 
> (104,128,117,115,122,122,114,107,124,88,125,97,138,126,131,133,140,111 
> ,
> 106,124,119,116,111,144,118,117,119,87,136,103,113,120,102,124,141,130 
> ,
> 92,119,117,107,107,133,108,114,114,NA,132,104,111,107,104,114,139,116,
> 107,126,114,96,115,142,114,120,132,103,132,102,113,122,114,123,131,115 
> ,
> 116,115,126,106,120,142,108,117,128,80,140,101,116,107,119,114,138,139 
> ,
> 104,127,128,118,140,138,120,106,126,95,118,97,107,134,123,107,136,103,
> 108,138,133,118,108,191,110,131,129,108,144,127,123,131,151,155,131,152 
> ,
> 120,143,136,123,134,164,150,130,135,NA, 
> 141,114,143,167,155,159,142,147,
> 135,157,141,129,141,153,136,129,149,130,NA, 
> 110,141,163,157,169,171,138,
> 143,153,138,129,144,160,135,130,124,114,122,114,133,140,144,153,166,132 
> )
> drugdat<-data.frame(ID, drug, timep, pressure)
> drugdat$ID<-factor(drugdat$ID)
> drugdat$drug<-factor(drugdat$drug)
>
> # Quick look
> with(drugdat[drugdat$pressure!="NA",], interaction.plot(timep, drug,
> pressure))
>
> # lmer/lme commands
> lmer1<-lmer(pressure~drug*poly(timep,2)+(1|ID), data=drugdat)
> plot(lmer1)
> summary(lmer1)
> anova(lmer1)
>
> # Or the legacy version
> lme1<-lme(pressure~drug*poly(timep,2), data=drugdat, random=~1|ID,
> na.action=na.omit)
> summary(lme1)
> anova(lme1)
> plot(lme1)
>
>
> # More pictures if interested, I haven't figured out how the "fitted"
> and the "predict" function interchange within the defined functions
> below to use the lme/lmer fits yet, it is late - or early - at the  
> moment...
> lm1<-lm(pressure~drug*poly(timep,2), data=drugdat, na.action=na.omit)
> plot(pressure~timep, data=drugdat, col=c("blue", "red")[drug], pch =
> c(1,2)[drug])
> fit<-function(x)
>    predict(lm1, newdata=
>        data.frame(timep=x, drug=rep(levels(drugdat$drug)[1],  
> length(x))))
> curve(fit, 0,270, add=TRUE, col="blue")
> fit<-function(x)
>    predict(lm1, newdata=
>        data.frame(timep=x, drug=rep(levels(drugdat$drug)[2],  
> length(x))))
> curve(fit, 0,270, add=TRUE, col="red")
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From rlevy at ling.ucsd.edu  Mon May 25 00:46:41 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Sun, 24 May 2009 15:46:41 -0700
Subject: [R-sig-ME] specifying custom random-effects structures
Message-ID: <EDF4E855-B7E0-4105-B58C-F7622D956345@ling.ucsd.edu>

Dear all,

I want to understand the range of random-effects covariance structure  
specifications that (a) can be handled by lme4, MCMCglmm, and related  
packages; and (b) that are reasonable to posit in principle as random- 
effects covariance structures.

If I understand correctly, lme4 handles random-effects structures that  
can be expressed as the direct sum of k arbitrary covariance matrices  
-- that is, something that looks like

M1  0   0   0
0   M2  0   0
0   0  ...  0
0   0   0   Mk

where each Mi is a covariance matrix without any constraints placed on  
its internal structure.

Is it possible to place constraints on the internal structure of each  
of these covariance matrices?  For example, suppose Mi is the  
covariance matrix for variables x1, x2, and x3. Is it possible to  
specify that Mi has the structure

\sigma_11 \sigma_12    0
\sigma_12 \sigma_22 \sigma_23
   0      \sigma_23 \sigma_33

?  Likewise, if Mj is the covariance matrix for variables x4 and x5,  
is it possible to specify that Mj has the structure

\sigma_44    1
   1      \sigma_55

?

Additionally, regardless of technical feasibility, are these sensible  
specifications in principle?  I can imagine a circumstance in which  
the latter specification would make sense: when there is theoretical  
reason to believe that the role of x4 and x5 in determining the  
response is mediated through some inaccessible third variable that is  
a linear combination of x4 and x5, but the parameters of the linear  
combination are unknown.  I'm not so sure about the former  
specification...but for some datasets I work with, I have in fact seen  
inferred covariance structures close to this form.

Best

Roger

--

Roger Levy                      Email: rlevy at ling.ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy



From yuanjiayj at gmail.com  Mon May 25 04:03:42 2009
From: yuanjiayj at gmail.com (yuanjiayj)
Date: Mon, 25 May 2009 10:03:42 +0800
Subject: [R-sig-ME] Finding varibale select methods or packages
Message-ID: <c496045b0905241903i31221ed1qc347c4604ca3cb9b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090525/0788da28/attachment.pl>

From bates at stat.wisc.edu  Mon May 25 17:04:53 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 25 May 2009 10:04:53 -0500
Subject: [R-sig-ME] specifying custom random-effects structures
In-Reply-To: <EDF4E855-B7E0-4105-B58C-F7622D956345@ling.ucsd.edu>
References: <EDF4E855-B7E0-4105-B58C-F7622D956345@ling.ucsd.edu>
Message-ID: <40e66e0b0905250804j58c151d5x67cf7b8a08b73258@mail.gmail.com>

On Sun, May 24, 2009 at 5:46 PM, Roger Levy <rlevy at ling.ucsd.edu> wrote:
> Dear all,

> I want to understand the range of random-effects covariance structure
> specifications that (a) can be handled by lme4, MCMCglmm, and related
> packages; and (b) that are reasonable to posit in principle as
> random-effects covariance structures.

> If I understand correctly, lme4 handles random-effects structures that can
> be expressed as the direct sum of k arbitrary covariance matrices -- that
> is, something that looks like

> M1 ?0 ? 0 ? 0
> 0 ? M2 ?0 ? 0
> 0 ? 0 ?... ?0
> 0 ? 0 ? 0 ? Mk

> where each Mi is a covariance matrix without any constraints placed on its
> internal structure.

I view the variance-covariance structures available in the lme4
package as being related to random-effects terms in the model matrix.
A random-effects term is of the form (LMexpr | GrpFac).  The
expression on the right of the vertical bar is evaluated as a factor,
which I call the grouping factor.  The expression on the left is
evaluated as a linear model expression.  The number of columns in the
model matrix corresponding to this expression is the number of random
effects per level of the grouping factor.

The basic rules for the unconditional variance-covariance of the
random effects are:
  random effects generated from different random-effects terms are independent
  random effects corresponding to different levels of the grouping
factor are independent
  the vector of random effects for a given level of the grouping
factor have a general positive semidefinite symmetric
variance-covariance, which is common to all the levels of the grouping
factor.

In future versions of lme4 I plan to allow for extensions of the
unconditional variance-covariance structures.  If you look at the
development version in the branches/allcoef section of the SVN archive
at R-forge you will see that there is a virtual class called the
reCovFac (random-effects covariance factor) class.  If an actual class
is defined to extend reCovFac and certain methods (getPars, setPars,
getBounds, getLambda) are defined for the actual class then it can be
used instead of the default ST class.

> Is it possible to place constraints on the internal structure of each of
> these covariance matrices? ?For example, suppose Mi is the covariance matrix
> for variables x1, x2, and x3. Is it possible to specify that Mi has the
> structure

> \sigma_11 \sigma_12 ? ?0
> \sigma_12 \sigma_22 \sigma_23
> ?0 ? ? ?\sigma_23 \sigma_33

> ? ?Likewise, if Mj is the covariance matrix for variables x4 and x5, is it
> possible to specify that Mj has the structure
>
> \sigma_44 ? ?1
> ?1 ? ? ?\sigma_55
>
> ?

In its current implementation, no, the lme4 package does not allow
general modeling of the unconditional variance-covariance structure of
the random effects.  I doubt that it will, just because I find it
difficult to understand the model in that way.  Generalizing the model
is not just a matter of adding hooks - you also need to decide what
can go wrong in the generalized structure.  I have said that the most
valuable character trait for programmers is unbounded pessimism
because you spend so much of your time trying to decide how things
could fail to work.  In early designs of the nlme package when we
created a pdMat subclass to represent positive definite matrices that
were not matrices I knew we were in trouble.

You can try to extend the reCovFac class but doing so in a consistent
way is not always easy.

> Additionally, regardless of technical feasibility, are these sensible
> specifications in principle? ?I can imagine a circumstance in which the
> latter specification would make sense: when there is theoretical reason to
> believe that the role of x4 and x5 in determining the response is mediated
> through some inaccessible third variable that is a linear combination of x4
> and x5, but the parameters of the linear combination are unknown. ?I'm not
> so sure about the former specification...but for some datasets I work with,
> I have in fact seen inferred covariance structures close to this form.
>
> Best
>
> Roger
>
> --
>
> Roger Levy ? ? ? ? ? ? ? ? ? ? ?Email: rlevy at ling.ucsd.edu
> Assistant Professor ? ? ? ? ? ? Phone: 858-534-7219
> Department of Linguistics ? ? ? Fax: ? 858-534-4789
> UC San Diego ? ? ? ? ? ? ? ? ? ?Web: ? http://ling.ucsd.edu/~rlevy
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From rlevy at ling.ucsd.edu  Mon May 25 23:46:22 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Mon, 25 May 2009 14:46:22 -0700
Subject: [R-sig-ME] specifying custom random-effects structures
In-Reply-To: <40e66e0b0905250804j58c151d5x67cf7b8a08b73258@mail.gmail.com>
References: <EDF4E855-B7E0-4105-B58C-F7622D956345@ling.ucsd.edu>
	<40e66e0b0905250804j58c151d5x67cf7b8a08b73258@mail.gmail.com>
Message-ID: <4A1B11AE.9010900@ling.ucsd.edu>

Douglas Bates wrote:
> On Sun, May 24, 2009 at 5:46 PM, Roger Levy <rlevy at ling.ucsd.edu> wrote:
>> Dear all,
> 
>> I want to understand the range of random-effects covariance structure
>> specifications that (a) can be handled by lme4, MCMCglmm, and related
>> packages; and (b) that are reasonable to posit in principle as
>> random-effects covariance structures.
> 
>> If I understand correctly, lme4 handles random-effects structures that can
>> be expressed as the direct sum of k arbitrary covariance matrices -- that
>> is, something that looks like
> 
>> M1  0   0   0
>> 0   M2  0   0
>> 0   0  ...  0
>> 0   0   0   Mk
> 
>> where each Mi is a covariance matrix without any constraints placed on its
>> internal structure.
> 
> I view the variance-covariance structures available in the lme4
> package as being related to random-effects terms in the model matrix.
> A random-effects term is of the form (LMexpr | GrpFac).  The
> expression on the right of the vertical bar is evaluated as a factor,
> which I call the grouping factor.  The expression on the left is
> evaluated as a linear model expression.  The number of columns in the
> model matrix corresponding to this expression is the number of random
> effects per level of the grouping factor.
> 
> The basic rules for the unconditional variance-covariance of the
> random effects are:
>   random effects generated from different random-effects terms are independent
>   random effects corresponding to different levels of the grouping
> factor are independent
>   the vector of random effects for a given level of the grouping
> factor have a general positive semidefinite symmetric
> variance-covariance, which is common to all the levels of the grouping
> factor.
> 
> In future versions of lme4 I plan to allow for extensions of the
> unconditional variance-covariance structures.  If you look at the
> development version in the branches/allcoef section of the SVN archive
> at R-forge you will see that there is a virtual class called the
> reCovFac (random-effects covariance factor) class.  If an actual class
> is defined to extend reCovFac and certain methods (getPars, setPars,
> getBounds, getLambda) are defined for the actual class then it can be
> used instead of the default ST class.

Hi Doug,

Many thanks for your detailed response to my question -- I just want to 
ask one clarificatory follow-up.  By "*unconditional* 
variance-covariance structure" you are meaning prior to conditioning on 
the data, is that correct?

Best & thanks again,

Roger

> 
>> Is it possible to place constraints on the internal structure of each of
>> these covariance matrices?  For example, suppose Mi is the covariance matrix
>> for variables x1, x2, and x3. Is it possible to specify that Mi has the
>> structure
> 
>> \sigma_11 \sigma_12    0
>> \sigma_12 \sigma_22 \sigma_23
>>  0      \sigma_23 \sigma_33
> 
>> ?  Likewise, if Mj is the covariance matrix for variables x4 and x5, is it
>> possible to specify that Mj has the structure
>>
>> \sigma_44    1
>>  1      \sigma_55
>>
>> ?
> 
> In its current implementation, no, the lme4 package does not allow
> general modeling of the unconditional variance-covariance structure of
> the random effects.  I doubt that it will, just because I find it
> difficult to understand the model in that way.  Generalizing the model
> is not just a matter of adding hooks - you also need to decide what
> can go wrong in the generalized structure.  I have said that the most
> valuable character trait for programmers is unbounded pessimism
> because you spend so much of your time trying to decide how things
> could fail to work.  In early designs of the nlme package when we
> created a pdMat subclass to represent positive definite matrices that
> were not matrices I knew we were in trouble.
> 
> You can try to extend the reCovFac class but doing so in a consistent
> way is not always easy.
> 
>> Additionally, regardless of technical feasibility, are these sensible
>> specifications in principle?  I can imagine a circumstance in which the
>> latter specification would make sense: when there is theoretical reason to
>> believe that the role of x4 and x5 in determining the response is mediated
>> through some inaccessible third variable that is a linear combination of x4
>> and x5, but the parameters of the linear combination are unknown.  I'm not
>> so sure about the former specification...but for some datasets I work with,
>> I have in fact seen inferred covariance structures close to this form.
>>
>> Best
>>
>> Roger
>>
>> --
>>
>> Roger Levy                      Email: rlevy at ling.ucsd.edu
>> Assistant Professor             Phone: 858-534-7219
>> Department of Linguistics       Fax:   858-534-4789
>> UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From bates at stat.wisc.edu  Tue May 26 02:04:23 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 25 May 2009 19:04:23 -0500
Subject: [R-sig-ME] specifying custom random-effects structures
In-Reply-To: <4A1B11AE.9010900@ling.ucsd.edu>
References: <EDF4E855-B7E0-4105-B58C-F7622D956345@ling.ucsd.edu>
	<40e66e0b0905250804j58c151d5x67cf7b8a08b73258@mail.gmail.com>
	<4A1B11AE.9010900@ling.ucsd.edu>
Message-ID: <40e66e0b0905251704p3b49c8a5g989b456e2f375810@mail.gmail.com>

On Mon, May 25, 2009 at 4:46 PM, Roger Levy <rlevy at ling.ucsd.edu> wrote:
> Douglas Bates wrote:
>>
>> On Sun, May 24, 2009 at 5:46 PM, Roger Levy <rlevy at ling.ucsd.edu> wrote:
>>>
>>> Dear all,
>>
>>> I want to understand the range of random-effects covariance structure
>>> specifications that (a) can be handled by lme4, MCMCglmm, and related
>>> packages; and (b) that are reasonable to posit in principle as
>>> random-effects covariance structures.
>>
>>> If I understand correctly, lme4 handles random-effects structures that
>>> can
>>> be expressed as the direct sum of k arbitrary covariance matrices -- that
>>> is, something that looks like
>>
>>> M1 ?0 ? 0 ? 0
>>> 0 ? M2 ?0 ? 0
>>> 0 ? 0 ?... ?0
>>> 0 ? 0 ? 0 ? Mk
>>
>>> where each Mi is a covariance matrix without any constraints placed on
>>> its
>>> internal structure.
>>
>> I view the variance-covariance structures available in the lme4
>> package as being related to random-effects terms in the model matrix.
>> A random-effects term is of the form (LMexpr | GrpFac). ?The
>> expression on the right of the vertical bar is evaluated as a factor,
>> which I call the grouping factor. ?The expression on the left is
>> evaluated as a linear model expression. ?The number of columns in the
>> model matrix corresponding to this expression is the number of random
>> effects per level of the grouping factor.
>>
>> The basic rules for the unconditional variance-covariance of the
>> random effects are:
>> ?random effects generated from different random-effects terms are
>> independent
>> ?random effects corresponding to different levels of the grouping
>> factor are independent
>> ?the vector of random effects for a given level of the grouping
>> factor have a general positive semidefinite symmetric
>> variance-covariance, which is common to all the levels of the grouping
>> factor.
>>
>> In future versions of lme4 I plan to allow for extensions of the
>> unconditional variance-covariance structures. ?If you look at the
>> development version in the branches/allcoef section of the SVN archive
>> at R-forge you will see that there is a virtual class called the
>> reCovFac (random-effects covariance factor) class. ?If an actual class
>> is defined to extend reCovFac and certain methods (getPars, setPars,
>> getBounds, getLambda) are defined for the actual class then it can be
>> used instead of the default ST class.
>
> Hi Doug,
>
> Many thanks for your detailed response to my question -- I just want to ask
> one clarificatory follow-up. ?By "*unconditional* variance-covariance
> structure" you are meaning prior to conditioning on the data, is that
> correct?

Yes.

>>
>>> Is it possible to place constraints on the internal structure of each of
>>> these covariance matrices? ?For example, suppose Mi is the covariance
>>> matrix
>>> for variables x1, x2, and x3. Is it possible to specify that Mi has the
>>> structure
>>
>>> \sigma_11 \sigma_12 ? ?0
>>> \sigma_12 \sigma_22 \sigma_23
>>> ?0 ? ? ?\sigma_23 \sigma_33
>>
>>> ? ?Likewise, if Mj is the covariance matrix for variables x4 and x5, is
>>> it
>>> possible to specify that Mj has the structure
>>>
>>> \sigma_44 ? ?1
>>> ?1 ? ? ?\sigma_55
>>>
>>> ?
>>
>> In its current implementation, no, the lme4 package does not allow
>> general modeling of the unconditional variance-covariance structure of
>> the random effects. ?I doubt that it will, just because I find it
>> difficult to understand the model in that way. ?Generalizing the model
>> is not just a matter of adding hooks - you also need to decide what
>> can go wrong in the generalized structure. ?I have said that the most
>> valuable character trait for programmers is unbounded pessimism
>> because you spend so much of your time trying to decide how things
>> could fail to work. ?In early designs of the nlme package when we
>> created a pdMat subclass to represent positive definite matrices that
>> were not matrices I knew we were in trouble.
>>
>> You can try to extend the reCovFac class but doing so in a consistent
>> way is not always easy.
>>
>>> Additionally, regardless of technical feasibility, are these sensible
>>> specifications in principle? ?I can imagine a circumstance in which the
>>> latter specification would make sense: when there is theoretical reason
>>> to
>>> believe that the role of x4 and x5 in determining the response is
>>> mediated
>>> through some inaccessible third variable that is a linear combination of
>>> x4
>>> and x5, but the parameters of the linear combination are unknown. ?I'm
>>> not
>>> so sure about the former specification...but for some datasets I work
>>> with,
>>> I have in fact seen inferred covariance structures close to this form.
>>>
>>> Best
>>>
>>> Roger
>>>
>>> --
>>>
>>> Roger Levy ? ? ? ? ? ? ? ? ? ? ?Email: rlevy at ling.ucsd.edu
>>> Assistant Professor ? ? ? ? ? ? Phone: 858-534-7219
>>> Department of Linguistics ? ? ? Fax: ? 858-534-4789
>>> UC San Diego ? ? ? ? ? ? ? ? ? ?Web: ? http://ling.ucsd.edu/~rlevy
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>
>



From bates at stat.wisc.edu  Tue May 26 20:44:21 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 26 May 2009 13:44:21 -0500
Subject: [R-sig-ME] lmer and SAS proc mixed
In-Reply-To: <76fe59070905261125w98381cfnb30920e543d550ea@mail.gmail.com>
References: <76fe59070905261125w98381cfnb30920e543d550ea@mail.gmail.com>
Message-ID: <40e66e0b0905261144i5abce884r65e9397c66acf522@mail.gmail.com>

On Tue, May 26, 2009 at 1:25 PM, Julia Liu <liujulia7 at gmail.com> wrote:
> Prof. Bates:

> I am learning mixed-effect model, and I am building a simple mixed
> model using R lmer() function. Just for testing, I ran the same model
> using SAS proc mixed, and found that the estimates are different.

> The R code is
> lmer(y ~ x1 + x2+ x3+ x4+ x5 + (1 + x1 | pid), data=dt)

> The SAS code is:
> ==========================
> %let fvars=x1 x2 x3 x4 x5;
>
> proc mixed data=dt;
> ? ? ? class pid;
> ? ? ? model y= &fvars / solution outp=predicted;
> ? ? ? random intercept x1/sub=pid solution;
> ? ? ? ods output SolutionF=fbeta;
> ? ? ? ods output SolutionR=rbeta;
> run;
> quit;
> =========================

> I know that both lmer and proc mixed uses REML, so I am surprised to
> see the estimates come out different.

> I also tried the model with only intercept randomized (ie. lmer(y ~ x1
> + x2+ x3+ x4+ x5 + (1| pid), data=dt), this time, the estimates from R
> and SAS are the same. I do not know why. I know that you are an expert
> in mixed-effect model, and I was wondering whether you could shed some
> light on the difference between lmer and proc mixed.

I know what the lmer model fits but I don't know SAS PROC MIXED that
well so I can't tell you what model the SAS code would fit.  I have
sent a copy of this reply to the R-SIG-Mixed-Models mailing list in
the hopes that someone reading that list could say what model would be
fit.

The fact that the estimates coincide when you remove the random effect
for x1 indicates to me that the variance-covariance structure of the
model description for SAS may be other than the general positive
definite structure (which in SAS is called "unconstrained", I believe,
despite the fact that the matrix is subject to several constraints)
used in lmer.

> I can send you the data if you let me, ? it is about 263KB in a .csv format.
>
> Thank you very much,
> sincerely,
> Julia
>



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Tue May 26 21:10:55 2009
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 26 May 2009 21:10:55 +0200
Subject: [R-sig-ME] lmer and SAS proc mixed
In-Reply-To: <40e66e0b0905261144i5abce884r65e9397c66acf522@mail.gmail.com>
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF0EB942C0@um-mail0136.unimaas.nl>

Try:

proc mixed data=dt;
	class pid;
	model y= &fvars / solution outp=predicted;
	random intercept x1/sub=pid type=un solution;
	ods output SolutionF=fbeta;
	ods output SolutionR=rbeta;

(note the addition of type=un on the line starting with random). I believe type=vc is the default, which does not allow the random intercept and slope to be correlated (which lmer does).

Best,

-- 
Wolfgang Viechtbauer
 Department of Methodology and Statistics
 University of Maastricht, The Netherlands
 http://www.wvbauer.com/



----Original Message----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Douglas
Bates Sent: Tuesday, May 26, 2009 20:44 To: Julia Liu
Cc: R-mixed models mailing list
Subject: Re: [R-sig-ME] lmer and SAS proc mixed

> On Tue, May 26, 2009 at 1:25 PM, Julia Liu <liujulia7 at gmail.com> wrote:
>> Prof. Bates:
> 
>> I am learning mixed-effect model, and I am building a simple mixed
>> model using R lmer() function. Just for testing, I ran the same model
>> using SAS proc mixed, and found that the estimates are different.
> 
>> The R code is
>> lmer(y ~ x1 + x2+ x3+ x4+ x5 + (1 + x1 | pid), data=dt)
> 
>> The SAS code is:
>> ==========================
>> %let fvars=x1 x2 x3 x4 x5;
>> 
>> proc mixed data=dt;
>> ? ? ? class pid;
>> ? ? ? model y= &fvars / solution outp=predicted;
>> ? ? ? random intercept x1/sub=pid solution;
>> ? ? ? ods output SolutionF=fbeta;
>> ? ? ? ods output SolutionR=rbeta;
>> run;
>> quit;
>> =========================
> 
>> I know that both lmer and proc mixed uses REML, so I am surprised to
>> see the estimates come out different.
> 
>> I also tried the model with only intercept randomized (ie. lmer(y ~ x1
>> + x2+ x3+ x4+ x5 + (1| pid), data=dt), this time, the estimates from R
>> and SAS are the same. I do not know why. I know that you are an expert
>> in mixed-effect model, and I was wondering whether you could shed some
>> light on the difference between lmer and proc mixed.
> 
> I know what the lmer model fits but I don't know SAS PROC MIXED that well
> so I can't tell you what model the SAS code would fit.  I have sent a
> copy of this reply to the R-SIG-Mixed-Models mailing list in the hopes
> that someone reading that list could say what model would be fit.   
> 
> The fact that the estimates coincide when you remove the random effect
> for x1 indicates to me that the variance-covariance structure of the
> model description for SAS may be other than the general positive definite
> structure (which in SAS is called "unconstrained", I believe, despite the
> fact that the matrix is subject to several constraints) used in lmer.    
> 
>> I can send you the data if you let me, ? it is about 263KB in a .csv
>> format. 
>> 
>> Thank you very much,
>> sincerely,
>> Julia



From charpent at bacbuc.dyndns.org  Tue May 26 22:51:03 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Tue, 26 May 2009 22:51:03 +0200
Subject: [R-sig-ME] lmer and SAS proc mixed
In-Reply-To: <329A68716B57D54E8D39FD3F8A4A84DF0EB942C0@um-mail0136.unimaas.nl>
References: <40e66e0b0905261144i5abce884r65e9397c66acf522@mail.gmail.com>
	<329A68716B57D54E8D39FD3F8A4A84DF0EB942C0@um-mail0136.unimaas.nl>
Message-ID: <1243371062.6357.7.camel@yod>

Le mardi 26 mai 2009 ? 21:10 +0200, Viechtbauer Wolfgang (STAT) a
?crit :
> Try:
> 
> proc mixed data=dt;
> 	class pid;
> 	model y= &fvars / solution outp=predicted;
> 	random intercept x1/sub=pid type=un solution;
> 	ods output SolutionF=fbeta;
> 	ods output SolutionR=rbeta;
> 
> (note the addition of type=un on the line starting with random). I
> believe type=vc is the default, which does not allow the random
> intercept and slope to be correlated (which lmer does).

Can the parametrzation also play a role ?

In this case, I don't think : pid is the only "class" variable declared
in this proc step, which implies (or implied, in the times I was a SAS
user) that X1-...-X5 are continuous variables. Unless SAS started to
support a permanent class attribute in his datasets since v6.x (the last
I used with any kind of regularity)...

But I remember having been bitten by this  when first trying to learn R
and hitting differences in regression/ANOVA coefficients. And, yes, the
dreaded "Type III SS" problem, which Bill Venables' "Exegeses on the
linear model" considerably enlightened.

					Emmanuel Charpentier



From Linda.Mortensen at psy.ku.dk  Wed May 27 18:08:02 2009
From: Linda.Mortensen at psy.ku.dk (Linda Mortensen)
Date: Wed, 27 May 2009 18:08:02 +0200
Subject: [R-sig-ME] How to use mixed-effects models on multinomial data
Message-ID: <7A47FC91544BDC44B54C6807E6995019CE8D7B@ibtmail1.ibt.ku.dk.ad>

Dear list members,
 
In the past, I have used the lmer function to model data sets with crossed random effects (i.e., of subjects and items) and with either a continuous response variable (reaction times) or a binary response variable (correct vs. incorrect response). For the reaction time data, I use the formula:
lmer(response ~ predictor1 * predictor2 ....  + (1 + predictor1 * predictor2 .... | subject) + (1 + predictor1 * predictor2 .... | item), data)
And for the binomial data, I use the formula: 
lmer(response ~ predictor1 * predictor2 ....  + (1 + predictor1 * predictor2 .... | subject) + (1 + predictor1 * predictor2 .... | item), data, family="binomial").
 
I'm currently working on a data set for which the response variable is number of correct items with accuracy ranging from 0 to 5. So, here the response variable is not binomial but multinomial. I want to stay within the mixed-effects model framework, but am not sure how to modify the lmer function formula so that it will work on ordered multinomial data. I am not even sure whether this function can handle this kind of data at all.
I have tried to model the same data using the DPolmm function in the DPpackage, but this function doesn't seem to accept two random effect terms, at least it produces an error message when I enter "random = ..." twice. 
 
Does anyone know which function to use here? Any advice is very much appreciated. 
 
If this mailing list does not deal with inquiries of this kind, I apologise, but would appreciate if someone would re-direct me to another more suitable list. Thanks.   
 
Linda 
 
 
Linda Mortensen
Post-doctoral research fellow
Department of Psychology
University of Copenhagen 
?ster Farimagsgade 2A
1353 Copenhagen K
Denmark
Tel.: +45 3532 4889
E-mail: linda.mortensen at psy.ku.dk



From emmanuel.charpentier at sap.aphp.fr  Thu May 28 14:35:18 2009
From: emmanuel.charpentier at sap.aphp.fr (Emmanuel Charpentier)
Date: Thu, 28 May 2009 14:35:18 +0200
Subject: [R-sig-ME] How to use mixed-effects models on multinomial data
In-Reply-To: <7A47FC91544BDC44B54C6807E6995019CE8D7B@ibtmail1.ibt.ku.dk.ad>
References: <7A47FC91544BDC44B54C6807E6995019CE8D7B@ibtmail1.ibt.ku.dk.ad>
Message-ID: <1243507274.18023.53.camel@pc3-ec>

Le mercredi 27 mai 2009 ? 18:08 +0200, Linda Mortensen a ?crit :
> Dear list members,
>  
> In the past, I have used the lmer function to model data sets with
> crossed random effects (i.e., of subjects and items) and with either a
> continuous response variable (reaction times) or a binary response
> variable (correct vs. incorrect response). For the reaction time data,
> I use the formula:
> lmer(response ~ predictor1 * predictor2 ....  + (1 + predictor1 *
> predictor2 .... | subject) + (1 + predictor1 * predictor2 .... |
> item), data)
> And for the binomial data, I use the formula: 
> lmer(response ~ predictor1 * predictor2 ....  + (1 + predictor1 *
> predictor2 .... | subject) + (1 + predictor1 * predictor2 .... |
> item), data, family="binomial").
>  
> I'm currently working on a data set for which the response variable is
> number of correct items with accuracy ranging from 0 to 5. So, here
> the response variable is not binomial but multinomial.

Huh ?

Treating it as a "pure class" variable loses the (essential) ordering
information. Unless this ordering information (which seems to an
ignorant outsider the most important information about your subjects) is
essentially irrelevant to you problem, I'd rather use your number of
correct items as a "rough" measure of a numeric variable, and accept, as
a first approximation, its non-continuity as part of the experimental
error.

This approximation may be too rough with only 5 items, though.
Furthermore, depending on your beliefs on the cognitive model involved
in giving a "correct" response, the distance between 0 and 1 correct
response(s) may be close to or very different from the distance between
4 and 5 correct responses, which is exactly what proportional risks
model (polr) tries to explain away.

V&R4 (p 204 & sqq), explains that an ordered logistic regression is but
a set of logistic regressions on the (nested) orders induced by the
ordered response. It points to a "seminal" paper : McCullagh (1980) :
regresion models for ordinal data (with discussion), JRSS B 42:109-42,
and to McCullagh's book (to which I do not have access).

Maybe working with glmer's mixed effect logistic regression as a
building block would allow to build somewhat inneficiently) something
close to what polr does ?

What do you think ?

>                                                             I want to
> stay within the mixed-effects model framework, but am not sure how to
> modify the lmer function formula so that it will work on ordered
> multinomial data. I am not even sure whether this function can handle
> this kind of data at all.
> I have tried to model the same data using the DPolmm function in the
> DPpackage, but this function doesn't seem to accept two random effect
> terms, at least it produces an error message when I enter "random
> = ..." twice. 

I didn't know this one...

> Does anyone know which function to use here? Any advice is very much
> appreciated. 
>  
> If this mailing list does not deal with inquiries of this kind, I
> apologise, but would appreciate if someone would re-direct me to
> another more suitable list. Thanks.   

IMHO, you are on the suitable list. But your problem isn't probably very
usual...

> Linda 
>  
> 
> Linda Mortensen
> Post-doctoral research fellow
> Department of Psychology
> University of Copenhagen 
> ?ster Farimagsgade 2A
> 1353 Copenhagen K
> Denmark
> Tel.: +45 3532 4889
> E-mail: linda.mortensen at psy.ku.dk
>



From baron at psych.upenn.edu  Thu May 28 16:24:50 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 28 May 2009 10:24:50 -0400
Subject: [R-sig-ME] How to use mixed-effects models on multinomial data
In-Reply-To: <1243507274.18023.53.camel@pc3-ec>
References: <7A47FC91544BDC44B54C6807E6995019CE8D7B@ibtmail1.ibt.ku.dk.ad>
	<1243507274.18023.53.camel@pc3-ec>
Message-ID: <20090528142450.GA16888@psych.upenn.edu>

I had already replied to Linda Mortensen, but Emmanuel Charpentier's
reply gives me the courage to say to the whole list roughly what I
said before, plus a little more.

The assumption that 0-1, 1-2, ... 4-5 are equally spaced measures of
the underlying variable of interest may indeed be incorrect, but so
may the assumption that the difference between 200-300 msec reaction
time is equivalent to the difference between 300-400 msec (etc.).
Failure of the assumptions will lead to some additional error, but, as
argued by Dawes and Corrigan (Psych. Bull., 1974), not much.  (And you
can look at the residuals as a function of the predictions to see how
bad the situation is.)  In general, in my experience (for what that is
worth), you lose far less power by assuming equal spacing than you
lose by using a more "conservative" model that treats the dependent
measure as ordinal only.

Occasionally you may have a theoretical reason for NOT treating the
dependent measure as equally spaced (e.g., when doing conjoint
analysis), or for treating it as equally spaced (e.g., when testing
additive factors in reaction time).

In the former sort of case, it might be appropriate to fit a model to
each subject using some other method, then look at the coefficients
across subjects.  (This is what I did routinely before lmer.)

Jon

On 05/28/09 14:35, Emmanuel Charpentier wrote:
> Le mercredi 27 mai 2009 ?  18:08 +0200, Linda Mortensen a ?crit :
> > Dear list members,
> >  
> > In the past, I have used the lmer function to model data sets with
> > crossed random effects (i.e., of subjects and items) and with either a
> > continuous response variable (reaction times) or a binary response
> > variable (correct vs. incorrect response). For the reaction time data,
> > I use the formula:
> > lmer(response ~ predictor1 * predictor2 ....  + (1 + predictor1 *
> > predictor2 .... | subject) + (1 + predictor1 * predictor2 .... |
> > item), data)

I think that the second random effect term should be (0 + ...), since
there is already an intercept in the first one.

> > I'm currently working on a data set for which the response variable is
> > number of correct items with accuracy ranging from 0 to 5. So, here
> > the response variable is not binomial but multinomial.

> This approximation may be too rough with only 5 items, though.
> Furthermore, depending on your beliefs on the cognitive model involved
> in giving a "correct" response, the distance between 0 and 1 correct
> response(s) may be close to or very different from the distance between
> 4 and 5 correct responses, which is exactly what proportional risks
> model (polr) tries to explain away.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From rosi.wild at gmx.de  Thu May 28 16:58:56 2009
From: rosi.wild at gmx.de (Romy Wild)
Date: Thu, 28 May 2009 16:58:56 +0200
Subject: [R-sig-ME] Glmm and repeated measures anova
Message-ID: <C6447350.38E%rosi.wild@gmx.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090528/ee7a874a/attachment.pl>

From andydolman at gmail.com  Thu May 28 18:29:36 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Thu, 28 May 2009 18:29:36 +0200
Subject: [R-sig-ME] Glmm and repeated measures anova
In-Reply-To: <C6447350.38E%rosi.wild@gmx.de>
References: <C6447350.38E%rosi.wild@gmx.de>
Message-ID: <951234ac0905280929y3aa33capdd185b8152aea0c7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090528/a6003b46/attachment.pl>

From atyre2 at unlnotes.unl.edu  Thu May 28 18:40:32 2009
From: atyre2 at unlnotes.unl.edu (Andrew J Tyre)
Date: Thu, 28 May 2009 11:40:32 -0500
Subject: [R-sig-ME] Glmm and repeated measures anova
In-Reply-To: <C6447350.38E%rosi.wild@gmx.de>
Message-ID: <OF8E8DDB9C.FE5618E4-ON862575C4.005AF705-862575C4.005B9992@unl.edu>

Romy,

I don't think the problem is with your data layout, but rather with the 
formula you provided - it works (after fixing one comma that should be a 
period in the data):

lme(Do~time,random=~1|subj,data=romy) #this works fine

the key difference is the random effect is a VERTICAL BAR not a slash

and in addition if you want an "ANOVA" analysis of time as a categorical 
variable you need:
romy$time = as.factor(romy$time)

I think you're missing some information however by throwing away site:
romy$site = as.factor(rep(1:4,each=12))
romy

   subj time    Do site
1     A    1  9.24    1
2     A    2  9.46    1
3     A    3  9.74    1
4     B    1  9.05    1
...

summary(lme(Do~time,random=~1|site/subj,data=romy))
although there is very little variability associated with site, assuming 
I've got the sites set correctly.

cheers,

Drew Tyre

School of Natural Resources
University of Nebraska-Lincoln
416 Hardin Hall, East Campus
3310 Holdrege Street
Lincoln, NE 68583-0974

phone: +1 402 472 4054 
fax: +1 402 472 2946
email: atyre2 at unl.edu
http://snr.unl.edu/tyre
http://aminpractice.blogspot.com



Romy Wild <rosi.wild at gmx.de> 
Sent by: r-sig-mixed-models-bounces at r-project.org
05/28/2009 10:03 AM

To
<r-sig-mixed-models at r-project.org>
cc

Subject
[R-sig-ME] Glmm and repeated measures anova






Hello,
I?ve got to confess that my R knowledge is very basic and I have a problem
with a data set for what I am supposed to do a repeated measures anova and 
a
glmm. I?ve been all over the help lists and really tried quite a time but
there seems to be a mistake within my arrangement of data so I would be
really really glad if somebody with a bit more experience could look over
this and help me out.
Generaly the study was about a stream restoration. At three different 
point
of times  I made measurements of Dissolved Oxygen, pH,
conductivity,Nitrate,Nitrite,Ammonium, redox potential in 5 cm depth,10 
cm,
15 cm, and free flowing water to see how these values change over time. I
took this data on 4 sites for each date so that for each date I have a set
of data that contains 4 values of Oxygen in 5cm, 10 cm.....and all the 
same
for the other parameters. What I tried to start with was a repeated 
measures
anova to see whether there are differences among the different dates of 
data
collection at all, concerning each of the parameters.
For example for Oxygen I arranged the data like this:

            5.11     25.11       9.3
Site 1
5cm     9.24    9 .46       9.74
10cm   9.05    9.37        9.30
15cm  2.83     8.37        9.73
FW      9.91     9.55        9.85
And so on......

Site2
5cm 9.48 9.04 9.78 
10cm 4.47 8.99 9.53
15cm 4.71 7.74 8.77
FW 10.01 9.37 9.82 
Site3
5cm 5.38 9,28 9.56 
10cm 6.31 8.49 9.11
15cm 6.36 8.91 9.44
FW 9.97 9.55 9.89 
Site4
5cm 9.86 9.00 9.87 
10cm 4.82 8.93 9.13
15cm 4.41 8.69 7.32
FW 10.01 9.62 9.89
I arranged the data like this, so that every detph level has a capital
letter and the numbers from time stand for the different dates:

subj  time   Do 
A       1       9.24
A       2       9.46
A       3       9.74
B       1       9.05
B       2       9.37
B       3       9.30
C       1       2.83
C       2       8.37
C       3      9.73
D       1      9.91
D       2      9.55
D       3      9.85
E       1      9.48
E       2     9.04 
E       3      9.78
F       1      4.47
F       2      8.99
F       3      9.53
G       1     4.71 
G       2     7.74 
G       3     8.77 
H       1     10.01
H       2     9.37 
H       3     9.82 
I       1     5.38 
I       2      9,28
I       3      9.56
J       1      6.31
J       2      8.49
J       3      9.11
K      1      6.36 
K      2      8.91 
K      3      9.44 
L      1       9.97
L      2       9.55
L       3      9.89
M     1      9.86 
M     2      9.00 
M     3      9.87 
N      1      4.82 
N      2      8.93 
N      3      9.13 
O      1      4.41 
O      2      8.69 
O      3      7.32 
P       1      10.01
P       2      9.62
P       3      9.89

I tried to do the repeated measures anova as follows:
lme(Do~time,random=~/subj)
But that did not really work. Generally I?m not that interested in the
different depth levels, I going to analyse that differently anyway . I 
just
wanted to give it a try in the lme function.  But it would be great to 
have
a working repeated measures anova for analysing whether there are
differences between the different dates for all of the parameters.
Concerning the glmm I tried to get into this and read papers and help 
lists
articles but I have the feeling that this definetely exceeds my 
statistical
knowledge and if was hoping if someone could help me get an idea of how to
fit this data set in such a model. The problem starts that i don?t really
see what could be my response variable if not the time factor as there is
nothing from this data set that all the other parameters depend on. But I
don?t know how to fit the time/date factor in such a model.
I know this is probabls something rather trivial but as i said the
experience is lacking and help would take me a big big step closer to
getting this bachelor thesis done so thanks a lot to everybody who is
willing to look at this problem.
Thanks a lot and best regards ,
Romy Wild




                 [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From harlan at harris.name  Thu May 28 20:04:41 2009
From: harlan at harris.name (Harlan Harris)
Date: Thu, 28 May 2009 14:04:41 -0400
Subject: [R-sig-ME] How to use mixed-effects models on multinomial data
Message-ID: <924bb5e20905281104g16391f91u7bb56e59dc3209c7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090528/914d03e6/attachment.pl>

From bates at stat.wisc.edu  Thu May 28 20:13:37 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 28 May 2009 13:13:37 -0500
Subject: [R-sig-ME] How to use mixed-effects models on multinomial data
In-Reply-To: <20090528142450.GA16888@psych.upenn.edu>
References: <7A47FC91544BDC44B54C6807E6995019CE8D7B@ibtmail1.ibt.ku.dk.ad>
	<1243507274.18023.53.camel@pc3-ec>
	<20090528142450.GA16888@psych.upenn.edu>
Message-ID: <40e66e0b0905281113j1ff1a84cv5aa5819c082d6fb3@mail.gmail.com>

On Thu, May 28, 2009 at 9:24 AM, Jonathan Baron <baron at psych.upenn.edu> wrote:
> I had already replied to Linda Mortensen, but Emmanuel Charpentier's
> reply gives me the courage to say to the whole list roughly what I
> said before, plus a little more.

> The assumption that 0-1, 1-2, ... 4-5 are equally spaced measures of
> the underlying variable of interest may indeed be incorrect, but so
> may the assumption that the difference between 200-300 msec reaction
> time is equivalent to the difference between 300-400 msec (etc.).
> Failure of the assumptions will lead to some additional error, but, as
> argued by Dawes and Corrigan (Psych. Bull., 1974), not much. ?(And you
> can look at the residuals as a function of the predictions to see how
> bad the situation is.) ?In general, in my experience (for what that is
> worth), you lose far less power by assuming equal spacing than you
> lose by using a more "conservative" model that treats the dependent
> measure as ordinal only.

I'm glad to see you write that, Jonathon.  I don't have a lot of
experience modeling ordinal response data but my impression is that
there is more to lose by resorting to comparatively exotic models for
an ordinal response than by modeling it with a Gaussian "noise" term.
In cases like this where there are six levels, 0 to 5, I think your
suggestion of beginning with a linear mixed-effects model and checking
the residuals for undesirable behavior is a good start.

> Occasionally you may have a theoretical reason for NOT treating the
> dependent measure as equally spaced (e.g., when doing conjoint
> analysis), or for treating it as equally spaced (e.g., when testing
> additive factors in reaction time).
>
> In the former sort of case, it might be appropriate to fit a model to
> each subject using some other method, then look at the coefficients
> across subjects. ?(This is what I did routinely before lmer.)
>
> Jon
>
> On 05/28/09 14:35, Emmanuel Charpentier wrote:
>> Le mercredi 27 mai 2009 ? ?18:08 +0200, Linda Mortensen a ?crit :
>> > Dear list members,
>> >
>> > In the past, I have used the lmer function to model data sets with
>> > crossed random effects (i.e., of subjects and items) and with either a
>> > continuous response variable (reaction times) or a binary response
>> > variable (correct vs. incorrect response). For the reaction time data,
>> > I use the formula:
>> > lmer(response ~ predictor1 * predictor2 .... ?+ (1 + predictor1 *
>> > predictor2 .... | subject) + (1 + predictor1 * predictor2 .... |
>> > item), data)
>
> I think that the second random effect term should be (0 + ...), since
> there is already an intercept in the first one.

I don't think so.  It is quite legitimate to have random effects of
the form (1|subject) + (1|item) and the formula above is a
generalization of this.  A additive random effect for each subject is
not confounded with an additive random effect for each item.

I would be a more concerned about the number of random effects per
subject and per item when you have a complex formula like 1 +
predictor1 * predictor2 on the left hand side of the random-effects
term.  If predictor1 and predictor2 are both numeric predictors this
might be justified but I would look at it carefully.


> > I'm currently working on a data set for which the response variable is
>> > number of correct items with accuracy ranging from 0 to 5. So, here
>> > the response variable is not binomial but multinomial.
>
>> This approximation may be too rough with only 5 items, though.
>> Furthermore, depending on your beliefs on the cognitive model involved
>> in giving a "correct" response, the distance between 0 and 1 correct
>> response(s) may be close to or very different from the distance between
>> 4 and 5 correct responses, which is exactly what proportional risks
>> model (polr) tries to explain away.
>
> --
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page: http://www.sas.upenn.edu/~baron
> Editor: Judgment and Decision Making (http://journal.sjdm.org)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lindsayr at warnercnr.colostate.edu  Thu May 28 20:41:02 2009
From: lindsayr at warnercnr.colostate.edu (Lindsay Reynolds)
Date: Thu, 28 May 2009 12:41:02 -0600
Subject: [R-sig-ME] Model fit with a Poisson, cross-validation?
Message-ID: <4A1EDABE.8070901@warnercnr.colostate.edu>

Hello List,

I am in the process of learning mixed models in R and have a basic 
question. I am currently working on a model selection analysis with a 
suite of mixed models and Poisson-distributed count data. After reading 
Bolker et al 2009 (Trends In Ecology & Evolution 24:127-135) and having 
a basic understanding of standard model selection analysis (Burnam & 
Anderson) I was convinced that I could use the AICc alone to determine 
the best models. However, it has been suggested to me that I also 
include some sort of "R^2" value in my analysis to measure absolute fit 
of the model to the data. Since this does not exist for mixed models 
with Poisson distributed data, is was further suggested that I try 
cross-validating my models by building a predicted data set that I could 
compare to my observed data set.Can anyone point me to references who 
have done this sort of thing with mixed models in R? I would be much 
obliged.

More details on my analysis:
My data are counts of trees established per year within 'site'. I have 
built several models that include various combinations of climate 
variables as fixed explanatory variables and all models have 'site' as a 
random effect. In every model I include a continuous predictor variable 
called 'year' that accounts for the fact that we expect there to always 
be more young trees than older trees due to natural mortality. (year = 
1,2,3... n). I have tested for overdispersion using penalized, weighted 
residual sum of squares (pwrss) divided by the number of observations: 
pwrss/n. The values range between 0.9 and 2. I have interpreted this as 
my data are not too overdispersed so I have continued with using the 
Poisson distribution in my models. Also, I have run all my models with 
Poisson and with quasiPoisson and the results are very similar. My 
models look like this, with variations on the fixed effects:

rosite<-glmer(trees~wy+wy1+year+(1|site), family=poisson)

Many thanks,
Lindsay

~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Lindsay Reynolds
Ph.D. Candidate
Graduate Degree Program in Ecology
Office location: Forestry 208
Colorado State University
Campus Delivery 1472
Ft. Collins, CO 80523-1878



From rmh3093 at gmail.com  Thu May 28 21:35:17 2009
From: rmh3093 at gmail.com (Ryan Hope)
Date: Thu, 28 May 2009 15:35:17 -0400
Subject: [R-sig-ME] How do I calculate R^2 using Edwards, et. al.'s method?
Message-ID: <48f7fe350905281235n41bba1e7o23f89a4ff7241d00@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090528/57888fcf/attachment.pl>

From bolker at ufl.edu  Thu May 28 21:38:28 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 28 May 2009 15:38:28 -0400
Subject: [R-sig-ME] Model fit with a Poisson, cross-validation?
In-Reply-To: <4A1EDABE.8070901@warnercnr.colostate.edu>
References: <4A1EDABE.8070901@warnercnr.colostate.edu>
Message-ID: <4A1EE834.7080803@ufl.edu>

   I'm not sure I would call this "cross-validation" (unless I
misunderstand what you're trying to do). CV usually means re-fitting the
model with one or more data points held out each time to see how much
the results vary. Andrew Gelman talks a lot in (Gelman and Hill 2006)
about "posterior predictive checks", which may be close to what you have
in mind.
  Depending on what you want to do, the raw material would normally
be provided by the simulate() method for a fitted GLMM (mer) object,
but I think it doesn't work with the current released version of
lme4 -- there is one in the "allcoef" branch.  An alternative
is to download
<http://glmm.wikidot.com/local--files/basic-glmm-simulation/glmmfuns.R>
and use the my.mer.sim() function to simulate from the fitted model.

  For what it's worth, your description of your fitting process
sounds sensible.

  good luck,
    Ben Bolker

Lindsay Reynolds wrote:
> Hello List,
> 
> I am in the process of learning mixed models in R and have a basic 
> question. I am currently working on a model selection analysis with a 
> suite of mixed models and Poisson-distributed count data. After reading 
> Bolker et al 2009 (Trends In Ecology & Evolution 24:127-135) and having 
> a basic understanding of standard model selection analysis (Burnam & 
> Anderson) I was convinced that I could use the AICc alone to determine 
> the best models. However, it has been suggested to me that I also 
> include some sort of "R^2" value in my analysis to measure absolute fit 
> of the model to the data. Since this does not exist for mixed models 
> with Poisson distributed data, is was further suggested that I try 
> cross-validating my models by building a predicted data set that I could 
> compare to my observed data set.Can anyone point me to references who 
> have done this sort of thing with mixed models in R? I would be much 
> obliged.
> 
> More details on my analysis:
> My data are counts of trees established per year within 'site'. I have 
> built several models that include various combinations of climate 
> variables as fixed explanatory variables and all models have 'site' as a 
> random effect. In every model I include a continuous predictor variable 
> called 'year' that accounts for the fact that we expect there to always 
> be more young trees than older trees due to natural mortality. (year = 
> 1,2,3... n). I have tested for overdispersion using penalized, weighted 
> residual sum of squares (pwrss) divided by the number of observations: 
> pwrss/n. The values range between 0.9 and 2. I have interpreted this as 
> my data are not too overdispersed so I have continued with using the 
> Poisson distribution in my models. Also, I have run all my models with 
> Poisson and with quasiPoisson and the results are very similar. My 
> models look like this, with variations on the fixed effects:
> 
> rosite<-glmer(trees~wy+wy1+year+(1|site), family=poisson)
> 
> Many thanks,
> Lindsay
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Lindsay Reynolds
> Ph.D. Candidate
> Graduate Degree Program in Ecology
> Office location: Forestry 208
> Colorado State University
> Campus Delivery 1472
> Ft. Collins, CO 80523-1878
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From alban4040 at yahoo.com  Fri May 29 12:00:35 2009
From: alban4040 at yahoo.com (Alban Zeber)
Date: Fri, 29 May 2009 03:00:35 -0700 (PDT)
Subject: [R-sig-ME] error message from lmer routine in R
Message-ID: <591364.9697.qm@web58201.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090529/f1b13643/attachment.pl>

From bates at stat.wisc.edu  Fri May 29 15:53:01 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 29 May 2009 08:53:01 -0500
Subject: [R-sig-ME] error message from lmer routine in R
In-Reply-To: <591364.9697.qm@web58201.mail.re3.yahoo.com>
References: <591364.9697.qm@web58201.mail.re3.yahoo.com>
Message-ID: <40e66e0b0905290653q5ca5316cjc1b6394de428294d@mail.gmail.com>

On Fri, May 29, 2009 at 5:00 AM, Alban Zeber <alban4040 at yahoo.com> wrote:

> ?Dear All,

> ?I have a question concerning an error message I got when I used the lmer routine in R.
> ?I fit a multilevel logistic regression?with a binary response y and two factors DZ and DEL?? that are non nested and I got the error message:
> ??"Error in mer_finalize(ans) : q = 201 > n = 160".? See below.
> y is a binary variable (131 zeroes and 29 ones), DZ and DEL are factors with 80 and 121 levels, respectively, The sample size n is 160.

> ???M2 <- ?lmer(y ~ 1? +(1 | DZ) + (1 | DEL),family=binomial(link="logit"))
>> Error in mer_finalize(ans) : q = 201 > n = 160

> ??M2 <- ?glmer(y ~ 1? +(1 | DZ) + (1 | DEL),family=binomial(link="logit"))
>> Error in mer_finalize(ans) : q = 201 > n = 160

Admittedly the message is rather cryptic but it indicates that you are
trying to fit a model with more random effects (q = number of random
effects) than observations (n).  In the case of a linear mixed model
this will result in confounding.  Some have argued that the
confounding is not as important for generalized linear mixed models
because the conditional distribution of the data given the random
effects (Bernoulli, in this case) is different from the unconditional
distribution of the random effects (Gaussian).  However, it is also
true that the information content of binary responses is very low
(exactly 1 bit per observation) and it seems to me to be overly
optimistic to expect to fit a model with more random effects than you
have observations, even if the distributions are not confounded.

> ? It is not clear to me what the error is all about apart from the fact that I recognize that 201 = 80+121, the sum of the levels of the two non-nested factors. Do?you have any thoughts on the meaning of this error message?
>
> ??Regards,
>
>
> ?Alban
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From gts127 at psu.edu  Fri May 29 17:51:14 2009
From: gts127 at psu.edu (Grant T. Stokke)
Date: Fri, 29 May 2009 11:51:14 -0400
Subject: [R-sig-ME] increasing nAGQ causes error
Message-ID: <F3A782D566FF44959D90179666B0462F@GrantOTron>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090529/41c37c42/attachment.pl>

From bolker at ufl.edu  Fri May 29 18:11:44 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 29 May 2009 12:11:44 -0400
Subject: [R-sig-ME] increasing nAGQ causes error
In-Reply-To: <F3A782D566FF44959D90179666B0462F@GrantOTron>
References: <F3A782D566FF44959D90179666B0462F@GrantOTron>
Message-ID: <4A200940.60809@ufl.edu>

  This sounds worth digging into, but it's hard to dig
into without a reproducible example.  I don't get the
problem with the GLMM example in the lme4 package:

example(lmer)
update(gm1,nAGQ=8)
update(gm1,nAGQ=10)

etc.

  Can you post your data set, or a subset or simulated
data set that gives the same problem, somewhere?

  Ben Bolker

Grant T. Stokke wrote:
> Hello All,
> 
> I'm new to R and new to this mailing list, so I hope I've presented
> the proper info in this post.  I'm using GLMMs to model the selection
> of urban roosting locations by crows.  My dataset consists of 22
> cities, with each city containing 1000 unused locations and from 83
> to 2000 used locations.  I have three covariates for each used or
> unused location which I've standardized across all observations: %
> canopy (CANS), % impervious surfaces (IMPS), and nighttime light
> level (LTS).  Using the default setting nAGQ=1, my full model is
> fitted without error:
> 
>> CIL_CIL<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale)
>>  CIL_CIL
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: USED ~ 1 + CANS + IMPS + LTS + (1 + CANS + IMPS + LTS |
> CITY) Data: sitescale AIC   BIC logLik deviance 15122 15237  -7547
> 15094 Random effects: Groups Name        Variance   Std.Dev. Corr
>  CITY   (Intercept) 321.698184 17.93595 CANS          0.073271
> 0.27069  0.026 IMPS          0.661947  0.81360  0.080 -0.698 LTS
> 455.829122 21.35016 -0.988  0.031 -0.132 Number of obs: 27128,
> groups: CITY, 22
> 
> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> -16.21878    4.01227  -4.042 5.29e-05 *** CANS          0.07881
> 0.07162   1.100 0.271147 IMPS          0.63137    0.17750   3.557
> 0.000375 *** LTS          19.50827    4.78822   4.074 4.62e-05 *** 
> --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Correlation of Fixed Effects: (Intr) CANS   IMPS CANS  0.020
>  IMPS  0.074 -0.500 LTS  -0.989  0.025 -0.124
> 
> When I increase nAGQ to 8, however, I get the following error:
> 
>> CIL_CIL.nAGQ8<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale,nAGQ=8)
>>  CIL_CIL.nAGQ8
> Error in asMethod(object) : matrix is not symmetric [1,2]
> 
> I get the same error message with other values for nAGQ (I tried nAGQ
> = 2, 3, 5, and 50).  Is there anything I can do to fit the model
> using nAGQ > 1 without error?  Thanks in advance for your help!
> 
> -Grant Stokke
> 
> 
>> sessionInfo()
> R version 2.9.0 (2009-04-17) i386-pc-mingw32
> 
> locale: LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages: [1] stats     graphics  grDevices utils
> datasets  methods   base
> 
> other attached packages: [1] mgcv_1.5-5         lme4_0.999375-30
> Matrix_0.999375-26 lattice_0.17-22
> 
> loaded via a namespace (and not attached): [1] grid_2.9.0
> nlme_3.1-90 tools_2.9.0
>> CIL_CIL.nAGQ8
> Error in asMethod(object) : matrix is not symmetric [1,2]
>> traceback()
> 18: .Call(dense_to_symmetric, from, "U", TRUE) 17: asMethod(object) 
> 16: as(from, "symmetricMatrix") 15: .class1(object) 14: as(as(from,
> "symmetricMatrix"), "dMatrix") 13: .class1(object) 12: as(as(as(from,
> "symmetricMatrix"), "dMatrix"), "denseMatrix") 11: .class1(object) 
> 10: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix"),
>  "dpoMatrix") 9: asMethod(object) 8: as(sigma(object)^2 *
> chol2inv(object at RX, size = object at dims["p"]), "dpoMatrix") 7:
> vcov(object) 6: vcov(object) 5: summary(x) 4: summary(x) 3:
> printMer(object) 2: function (object) standardGeneric("show")(<S4
> object of class "mer">) 1: function (object) 
> standardGeneric("show")(<S4 object of class "mer">)
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Linda.Mortensen at psy.ku.dk  Fri May 29 19:13:59 2009
From: Linda.Mortensen at psy.ku.dk (Linda Mortensen)
Date: Fri, 29 May 2009 19:13:59 +0200
Subject: [R-sig-ME] How to use mixed-effects models on multinomial data
References: <7A47FC91544BDC44B54C6807E6995019CE8D7B@ibtmail1.ibt.ku.dk.ad><1243507274.18023.53.camel@pc3-ec><20090528142450.GA16888@psych.upenn.edu>
	<40e66e0b0905281113j1ff1a84cv5aa5819c082d6fb3@mail.gmail.com>
Message-ID: <7A47FC91544BDC44B54C6807E6995019CE8D85@ibtmail1.ibt.ku.dk.ad>

 
Thanks to all of you for your detailed comments. I find them very useful, although some of them point in different directions.

First, I should explain the structure of my data set in more detail: 

In the data set, each "item" is a list of 5 words. In an earlier analysis I carried out on these data, the response variable was the accuracy of recalling each word list (list recall). So, either subjects recalled a list correctly (i.e., recalled all 5 words in the list correctly), or they did not recall the list correctly (i.e., did not recall all 5 words correctly). Because the response in this analysis was binary, I used the mixed logit model. (Note that in my original e-mail, I only wanted to show the general structure of the lmer() formula that I'm using. The formula I'm actually using looks like this: lmer(response ~ predictor1 + predictor2 + predictor2 * predictor3 + (1 + predictor1 + predictor2 + predictor2 * predictor3 | subject) + (1 |item), data, family="binomial"). In short, I have random slopes for my subjects, but no random slopes for my items. This is because all three predictors are item-specific properties, and because I want to control for any variation between subjects in their sensitivity to these properties. On the basis of model comparisons, I then gradually simplify this initial model.

Now, the analysis I'm currently struggling with is carried out on the same data set, but the response variable is now the accuracy of recalling each word in a list (item recall), with subjects recalling either 0, 1, 2, 3, 4, or 5 words correctly. So, there are six, rather than two, possible responses. It is true that for each item, the response is still either correct or incorrect, but since it is the response for the entire list that concerns me, I would describe the responses as multinomial. Below, you see a subset of the trials in my data set:  

Subject Trial Item   W1 W2 W3 W4 W5     Predictor1    Predictor2    Predictor3   Correct

 1           3       9      1    1    0    1   1                  1               1               1               4

 1           4     12      1    0    0    0   1                  1                1               0              2

 1           5       4      0    0    0    0   0                  1                1               1              0

 1           6       6      1    1    1    1    1                 1                2               1              5

 

Profesors Baron's and Bates' suggest that I use a linear mixed-effects model, and as a consequence, disregard the information that is contained in the ordering of my 6 possible responses. They further suggest that I plot the residuals against each of my predictors. This is to get an idea of how well the model fits the observed pattern of each of my predictors, right? If, say, for predictor1 the residuals are very large, that would mean that the model has fitted the pattern of this predictor very poorly, right? I have produced the lmer model and have tried to make the residual plots, but have not succeeded. I can plot the residuals against the fitted values (but have to admit that I find it difficult to make sense of the plot), but how do I make separate plots for each of my predictors? Please let me know if I have misunderstood something here. 

Linda

 

________________________________

Fra: r-sig-mixed-models-bounces at r-project.org p? vegne af Douglas Bates
Sendt: to 28-05-2009 20:13
Til: Jonathan Baron
Cc: r-sig-mixed-models at r-project.org; Emmanuel Charpentier
Emne: Re: [R-sig-ME] How to use mixed-effects models on multinomial data



On Thu, May 28, 2009 at 9:24 AM, Jonathan Baron <baron at psych.upenn.edu> wrote:
> I had already replied to Linda Mortensen, but Emmanuel Charpentier's
> reply gives me the courage to say to the whole list roughly what I
> said before, plus a little more.

> The assumption that 0-1, 1-2, ... 4-5 are equally spaced measures of
> the underlying variable of interest may indeed be incorrect, but so
> may the assumption that the difference between 200-300 msec reaction
> time is equivalent to the difference between 300-400 msec (etc.).
> Failure of the assumptions will lead to some additional error, but, as
> argued by Dawes and Corrigan (Psych. Bull., 1974), not much.  (And you
> can look at the residuals as a function of the predictions to see how
> bad the situation is.)  In general, in my experience (for what that is
> worth), you lose far less power by assuming equal spacing than you
> lose by using a more "conservative" model that treats the dependent
> measure as ordinal only.

I'm glad to see you write that, Jonathon.  I don't have a lot of
experience modeling ordinal response data but my impression is that
there is more to lose by resorting to comparatively exotic models for
an ordinal response than by modeling it with a Gaussian "noise" term.
In cases like this where there are six levels, 0 to 5, I think your
suggestion of beginning with a linear mixed-effects model and checking
the residuals for undesirable behavior is a good start.

> Occasionally you may have a theoretical reason for NOT treating the
> dependent measure as equally spaced (e.g., when doing conjoint
> analysis), or for treating it as equally spaced (e.g., when testing
> additive factors in reaction time).
>
> In the former sort of case, it might be appropriate to fit a model to
> each subject using some other method, then look at the coefficients
> across subjects.  (This is what I did routinely before lmer.)
>
> Jon
>
> On 05/28/09 14:35, Emmanuel Charpentier wrote:
>> Le mercredi 27 mai 2009 ?  18:08 +0200, Linda Mortensen a ?crit :
>> > Dear list members,
>> >
>> > In the past, I have used the lmer function to model data sets with
>> > crossed random effects (i.e., of subjects and items) and with either a
>> > continuous response variable (reaction times) or a binary response
>> > variable (correct vs. incorrect response). For the reaction time data,
>> > I use the formula:
>> > lmer(response ~ predictor1 * predictor2 ....  + (1 + predictor1 *
>> > predictor2 .... | subject) + (1 + predictor1 * predictor2 .... |
>> > item), data)
>
> I think that the second random effect term should be (0 + ...), since
> there is already an intercept in the first one.

I don't think so.  It is quite legitimate to have random effects of
the form (1|subject) + (1|item) and the formula above is a
generalization of this.  A additive random effect for each subject is
not confounded with an additive random effect for each item.

I would be a more concerned about the number of random effects per
subject and per item when you have a complex formula like 1 +
predictor1 * predictor2 on the left hand side of the random-effects
term.  If predictor1 and predictor2 are both numeric predictors this
might be justified but I would look at it carefully.


> > I'm currently working on a data set for which the response variable is
>> > number of correct items with accuracy ranging from 0 to 5. So, here
>> > the response variable is not binomial but multinomial.
>
>> This approximation may be too rough with only 5 items, though.
>> Furthermore, depending on your beliefs on the cognitive model involved
>> in giving a "correct" response, the distance between 0 and 1 correct
>> response(s) may be close to or very different from the distance between
>> 4 and 5 correct responses, which is exactly what proportional risks
>> model (polr) tries to explain away.
>
> --
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page: http://www.sas.upenn.edu/~baron
> Editor: Judgment and Decision Making (http://journal.sjdm.org <http://journal.sjdm.org/> )
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From gts127 at psu.edu  Fri May 29 18:55:48 2009
From: gts127 at psu.edu (Grant T. Stokke)
Date: Fri, 29 May 2009 12:55:48 -0400
Subject: [R-sig-ME] increasing nAGQ causes error
In-Reply-To: <4A200940.60809@ufl.edu>
References: <F3A782D566FF44959D90179666B0462F@GrantOTron>
	<4A200940.60809@ufl.edu>
Message-ID: <F15C833BC6F94315B4AD18B1393B566E@GrantOTron>

Dr. Bolker,

Thanks for your prompt reply.  I created a subset of my dataset (attached). 
This subset contains 14 of the 22 cities in the full dataset, and one 
covariate (% impervious surfaces [IMP]).  I had convergence issues before 
standardizing covariates, so I used:

subset2$IMPS<-(subset2$IMP-mean(subset2$IMP))/(sqrt(var(subset2$IMP)))

Fitting all 3 covariates takes quite a long time, and I get the same error 
when using just one of them:

> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
> test2
Error in asMethod(object) : matrix is not symmetric [1,2]

Perhaps it's noteworthy that I did not receive the error when using a 
smaller subset with only the first 8 cities (in alphabetical order).

I look forward to your response.  Thanks again...

-Grant


----- Original Message ----- 
From: "Ben Bolker" <bolker at ufl.edu>
To: "Grant T. Stokke" <gts127 at psu.edu>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Friday, May 29, 2009 12:11 PM
Subject: Re: [R-sig-ME] increasing nAGQ causes error


>  This sounds worth digging into, but it's hard to dig
> into without a reproducible example.  I don't get the
> problem with the GLMM example in the lme4 package:
>
> example(lmer)
> update(gm1,nAGQ=8)
> update(gm1,nAGQ=10)
>
> etc.
>
>  Can you post your data set, or a subset or simulated
> data set that gives the same problem, somewhere?
>
>  Ben Bolker
>
> Grant T. Stokke wrote:
>> Hello All,
>>
>> I'm new to R and new to this mailing list, so I hope I've presented
>> the proper info in this post.  I'm using GLMMs to model the selection
>> of urban roosting locations by crows.  My dataset consists of 22
>> cities, with each city containing 1000 unused locations and from 83
>> to 2000 used locations.  I have three covariates for each used or
>> unused location which I've standardized across all observations: %
>> canopy (CANS), % impervious surfaces (IMPS), and nighttime light
>> level (LTS).  Using the default setting nAGQ=1, my full model is
>> fitted without error:
>>
>>> CIL_CIL<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale)
>>>  CIL_CIL
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: USED ~ 1 + CANS + IMPS + LTS + (1 + CANS + IMPS + LTS |
>> CITY) Data: sitescale AIC   BIC logLik deviance 15122 15237  -7547
>> 15094 Random effects: Groups Name        Variance   Std.Dev. Corr
>>  CITY   (Intercept) 321.698184 17.93595 CANS          0.073271
>> 0.27069  0.026 IMPS          0.661947  0.81360  0.080 -0.698 LTS
>> 455.829122 21.35016 -0.988  0.031 -0.132 Number of obs: 27128,
>> groups: CITY, 22
>>
>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>> -16.21878    4.01227  -4.042 5.29e-05 *** CANS          0.07881
>> 0.07162   1.100 0.271147 IMPS          0.63137    0.17750   3.557
>> 0.000375 *** LTS          19.50827    4.78822   4.074 4.62e-05 ***
>> --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Correlation of Fixed Effects: (Intr) CANS   IMPS CANS  0.020
>>  IMPS  0.074 -0.500 LTS  -0.989  0.025 -0.124
>>
>> When I increase nAGQ to 8, however, I get the following error:
>>
>>> CIL_CIL.nAGQ8<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale,nAGQ=8)
>>>  CIL_CIL.nAGQ8
>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>
>> I get the same error message with other values for nAGQ (I tried nAGQ
>> = 2, 3, 5, and 50).  Is there anything I can do to fit the model
>> using nAGQ > 1 without error?  Thanks in advance for your help!
>>
>> -Grant Stokke
>>
>>
>>> sessionInfo()
>> R version 2.9.0 (2009-04-17) i386-pc-mingw32
>>
>> locale: LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> States.1252;LC_MONETARY=English_United
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>
>> attached base packages: [1] stats     graphics  grDevices utils
>> datasets  methods   base
>>
>> other attached packages: [1] mgcv_1.5-5         lme4_0.999375-30
>> Matrix_0.999375-26 lattice_0.17-22
>>
>> loaded via a namespace (and not attached): [1] grid_2.9.0
>> nlme_3.1-90 tools_2.9.0
>>> CIL_CIL.nAGQ8
>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>> traceback()
>> 18: .Call(dense_to_symmetric, from, "U", TRUE) 17: asMethod(object)
>> 16: as(from, "symmetricMatrix") 15: .class1(object) 14: as(as(from,
>> "symmetricMatrix"), "dMatrix") 13: .class1(object) 12: as(as(as(from,
>> "symmetricMatrix"), "dMatrix"), "denseMatrix") 11: .class1(object)
>> 10: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix"),
>>  "dpoMatrix") 9: asMethod(object) 8: as(sigma(object)^2 *
>> chol2inv(object at RX, size = object at dims["p"]), "dpoMatrix") 7:
>> vcov(object) 6: vcov(object) 5: summary(x) 4: summary(x) 3:
>> printMer(object) 2: function (object) standardGeneric("show")(<S4
>> object of class "mer">) 1: function (object)
>> standardGeneric("show")(<S4 object of class "mer">)
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: subset2.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090529/eb8d7c90/attachment.txt>

From baron at psych.upenn.edu  Fri May 29 19:30:55 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 29 May 2009 13:30:55 -0400
Subject: [R-sig-ME] How to use mixed-effects models on multinomial data
In-Reply-To: <7A47FC91544BDC44B54C6807E6995019CE8D85@ibtmail1.ibt.ku.dk.ad>
References: <40e66e0b0905281113j1ff1a84cv5aa5819c082d6fb3@mail.gmail.com>
	<7A47FC91544BDC44B54C6807E6995019CE8D85@ibtmail1.ibt.ku.dk.ad>
Message-ID: <20090529173055.GA5559@psych.upenn.edu>

On 05/29/09 19:13, Linda Mortensen wrote:
> Profesors Baron's and Bates' suggest that I use a linear mixed-effects model, and as 
> a consequence, disregard the information that is contained in the ordering of my 6 
> possible responses.

I don't think you "disregard order."  You simply count the number of
correct recalls, 0-5, and use that number as your dependent variable.
I don't see how that disregards order, unless you meant something else
by order, like the order in which the items were recalled.  What you
disregard is "ordinal regression".

 They further suggest that I plot the residuals against each of 
> my predictors.  This is to get an idea of how well the model fits the observed 
> pattern of each of my predictors, right? If, say, for predictor1 the residuals are 
> very large, that would mean that the model has fitted the pattern of this predictor 
> very poorly, right?

I didn't mean "each predictor."  Rather, plot a graph of the residual
as a function of the predicted response, just as you would do with
ordinary regression.  (It is one of the default outputs for lm().)

 I have produced the lmer model and have tried to make the 
> residual plots, but have not succeeded. I can plot the residuals against the fitted 
> values (but have to admit that I find it difficult to make sense of the plot), but 
> how do I make separate plots for each of my predictors? Please let me know if I have 
> misunderstood something here. 

Yes.  I think you have what you want.  If the residuals are in one
direction (high, or low) at one end or the other (left side or right
side), then your assumption that the response is predicted linearly
from the predictors is wrong.  You can also check for
homeoscedascicity.  (My spell checker chokes on this one no matter how
I spell it.)

Jon



From bolker at ufl.edu  Fri May 29 20:08:37 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 29 May 2009 14:08:37 -0400
Subject: [R-sig-ME] increasing nAGQ causes error
In-Reply-To: <F15C833BC6F94315B4AD18B1393B566E@GrantOTron>
References: <F3A782D566FF44959D90179666B0462F@GrantOTron>
	<4A200940.60809@ufl.edu>
	<F15C833BC6F94315B4AD18B1393B566E@GrantOTron>
Message-ID: <4A2024A5.7090806@ufl.edu>

  Hmmm.  What version of lme4 are you using?  I have a
perhaps-more-recent version which gives me a different error:

  from sessionInfo()

other attached packages:
[1] lme4_0.999375-29   Matrix_0.999375-25 lattice_0.17-25

> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2)
> test2A <- update(test2,nAGQ=2)
Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.

  This is a more intentional and more standard error message which
basically means (?) that there has been a numerical/convergence problem
along the way ... (I'm not sure what the "1." means, haven't looked into
it).

  If I were in your position I might be satisfied with Laplace -- is
there a particular reason you need the greater accuracy of AGQ ... ?

  I am running the test code below and have so far figured out that
it happens for nAGQ=8 (but not for 2, 3, 4, 5) when one uses the
first 10 cities (but OK for up to 9).  It's OK for 11 cities
for all nAGQ tried (oddly enough, but this is not terribly surprising
when things are on th edge of numerical stability).  Haven't yet seen
how the rest of the pattern plays out.

  -------------------
testvals <- list()
nlev <- length(levels(subset2$CITY))
agqvals <- c(2,3,4,5,8)
for (i in 9:nlev) {
  testvals[[i-8]] <- list()
  for (j in 1:length(agqvals)) {
    agq <- agqvals[j]
    cat("***",i,agq,"\n")
    testvals[[i-8]][[j]]<-try(glmer(USED~1+IMPS+(1+IMPS|CITY),
                                family=binomial,data=subset2,
                                subset=as.numeric(CITY)<i,nAGQ=agq))

   ## should have used <=i rather than <i ...
  }
}






Grant T. Stokke wrote:
> Dr. Bolker,
> 
> Thanks for your prompt reply.  I created a subset of my dataset (attached). 
> This subset contains 14 of the 22 cities in the full dataset, and one 
> covariate (% impervious surfaces [IMP]).  I had convergence issues before 
> standardizing covariates, so I used:
> 
> subset2$IMPS<-(subset2$IMP-mean(subset2$IMP))/(sqrt(var(subset2$IMP)))
> 
> Fitting all 3 covariates takes quite a long time, and I get the same error 
> when using just one of them:
> 
>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
>> test2
> Error in asMethod(object) : matrix is not symmetric [1,2]
> 
> Perhaps it's noteworthy that I did not receive the error when using a 
> smaller subset with only the first 8 cities (in alphabetical order).
> 
> I look forward to your response.  Thanks again...
> 
> -Grant
> 
> 
> ----- Original Message ----- 
> From: "Ben Bolker" <bolker at ufl.edu>
> To: "Grant T. Stokke" <gts127 at psu.edu>
> Cc: <r-sig-mixed-models at r-project.org>
> Sent: Friday, May 29, 2009 12:11 PM
> Subject: Re: [R-sig-ME] increasing nAGQ causes error
> 
> 
>>  This sounds worth digging into, but it's hard to dig
>> into without a reproducible example.  I don't get the
>> problem with the GLMM example in the lme4 package:
>>
>> example(lmer)
>> update(gm1,nAGQ=8)
>> update(gm1,nAGQ=10)
>>
>> etc.
>>
>>  Can you post your data set, or a subset or simulated
>> data set that gives the same problem, somewhere?
>>
>>  Ben Bolker
>>
>> Grant T. Stokke wrote:
>>> Hello All,
>>>
>>> I'm new to R and new to this mailing list, so I hope I've presented
>>> the proper info in this post.  I'm using GLMMs to model the selection
>>> of urban roosting locations by crows.  My dataset consists of 22
>>> cities, with each city containing 1000 unused locations and from 83
>>> to 2000 used locations.  I have three covariates for each used or
>>> unused location which I've standardized across all observations: %
>>> canopy (CANS), % impervious surfaces (IMPS), and nighttime light
>>> level (LTS).  Using the default setting nAGQ=1, my full model is
>>> fitted without error:
>>>
>>>> CIL_CIL<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale)
>>>>  CIL_CIL
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: USED ~ 1 + CANS + IMPS + LTS + (1 + CANS + IMPS + LTS |
>>> CITY) Data: sitescale AIC   BIC logLik deviance 15122 15237  -7547
>>> 15094 Random effects: Groups Name        Variance   Std.Dev. Corr
>>>  CITY   (Intercept) 321.698184 17.93595 CANS          0.073271
>>> 0.27069  0.026 IMPS          0.661947  0.81360  0.080 -0.698 LTS
>>> 455.829122 21.35016 -0.988  0.031 -0.132 Number of obs: 27128,
>>> groups: CITY, 22
>>>
>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>> -16.21878    4.01227  -4.042 5.29e-05 *** CANS          0.07881
>>> 0.07162   1.100 0.271147 IMPS          0.63137    0.17750   3.557
>>> 0.000375 *** LTS          19.50827    4.78822   4.074 4.62e-05 ***
>>> --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> Correlation of Fixed Effects: (Intr) CANS   IMPS CANS  0.020
>>>  IMPS  0.074 -0.500 LTS  -0.989  0.025 -0.124
>>>
>>> When I increase nAGQ to 8, however, I get the following error:
>>>
>>>> CIL_CIL.nAGQ8<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale,nAGQ=8)
>>>>  CIL_CIL.nAGQ8
>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>
>>> I get the same error message with other values for nAGQ (I tried nAGQ
>>> = 2, 3, 5, and 50).  Is there anything I can do to fit the model
>>> using nAGQ > 1 without error?  Thanks in advance for your help!
>>>
>>> -Grant Stokke
>>>
>>>
>>>> sessionInfo()
>>> R version 2.9.0 (2009-04-17) i386-pc-mingw32
>>>
>>> locale: LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>> States.1252;LC_MONETARY=English_United
>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>
>>> attached base packages: [1] stats     graphics  grDevices utils
>>> datasets  methods   base
>>>
>>> other attached packages: [1] mgcv_1.5-5         lme4_0.999375-30
>>> Matrix_0.999375-26 lattice_0.17-22
>>>
>>> loaded via a namespace (and not attached): [1] grid_2.9.0
>>> nlme_3.1-90 tools_2.9.0
>>>> CIL_CIL.nAGQ8
>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>> traceback()
>>> 18: .Call(dense_to_symmetric, from, "U", TRUE) 17: asMethod(object)
>>> 16: as(from, "symmetricMatrix") 15: .class1(object) 14: as(as(from,
>>> "symmetricMatrix"), "dMatrix") 13: .class1(object) 12: as(as(as(from,
>>> "symmetricMatrix"), "dMatrix"), "denseMatrix") 11: .class1(object)
>>> 10: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix"),
>>>  "dpoMatrix") 9: asMethod(object) 8: as(sigma(object)^2 *
>>> chol2inv(object at RX, size = object at dims["p"]), "dpoMatrix") 7:
>>> vcov(object) 6: vcov(object) 5: summary(x) 4: summary(x) 3:
>>> printMer(object) 2: function (object) standardGeneric("show")(<S4
>>> object of class "mer">) 1: function (object)
>>> standardGeneric("show")(<S4 object of class "mer">)
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> -- 
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Fri May 29 23:43:37 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 29 May 2009 17:43:37 -0400
Subject: [R-sig-ME] increasing nAGQ causes error
In-Reply-To: <4A580B7E2EBA472F9FCB36341D5CAF3C@GrantOTron>
References: <F3A782D566FF44959D90179666B0462F@GrantOTron>
	<4A200940.60809@ufl.edu>
	<F15C833BC6F94315B4AD18B1393B566E@GrantOTron>
	<4A2024A5.7090806@ufl.edu>
	<4A580B7E2EBA472F9FCB36341D5CAF3C@GrantOTron>
Message-ID: <4A205709.3080409@ufl.edu>


  I updated to version xxx-31 and am still getting the "downdated X'X
not positive definite" error rather than a "not symmetric" error (weird.
platform-dependent numerical issues?)

  Based on a certain amount more messing around, I think there may
be an issue with city #15 (by Murphy's Law?) --  convergence failed
if I left out any city *except* #15.  This suggests looking at the
data (which of course I should have done earlier!) to see if something
suggests itself ...

library(ggplot2)

ggplot(subset2,aes(x=IMPS,y=USED)) + geom_point() + geom_smooth() +
facet_wrap(~CITY)

  doesn't suggest anything really odd about Lancaster, PA except the
highest overall fraction of sites used ...


=================
library(lme4)
subset2 <- read.table("~/subset2.txt",header=TRUE)
subset2$IMPS<-with(subset2,(IMP-mean(IMP))/sd(IMP))

if (FALSE) {

test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
  ## Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
}
testvals <- list()
nlev <- length(levels(subset2$CITY))
subvals <- 9:nlev
agqvals <- c(2,3,4,5,8,15)
for (i in 1:length(subvals)) {
  testvals[[i]] <- list()
  subval <- subvals[i]
  for (j in 1:length(agqvals)) {
    agq <- agqvals[j]
    cat("***",subval,agq,"\n")
    testvals[[i]][[j]]<-try(glmer(USED~1+IMPS+(1+IMPS|CITY),
                                    family=binomial,data=subset2,

subset=as.numeric(CITY)<=subval,nAGQ=agq))
  }
  save("testvals",file="agqsubs.RData")
}


Grant T. Stokke wrote:
> I'm using lme4 version lme4_0.999375-30 (as reported in sessionInfo(); 
> that's what you're referring to, right?).  I downloaded lme4 only about a 
> week ago, so I would imagine it's up-to-date.
> 
> Okay, I suppose maybe I should stick to the Laplacian approximation.  I 
> tried using AGQ not so much for accuracy, but because one of my models 
> refuses to converge, and I was checking to see if increasing nAGQ would 
> alleviate that issue.  (Maybe there's no way that would happen--I'll readily 
> admit that my understanding of the approximation methods is poor, but I 
> thought I'd give it a try.)  I was encouraged by the fact that changing nAGQ 
> didn't give convergence errors, but maybe convergence would still be a 
> problem anyway if glmer could get past the current error.
> 
> Thanks so much for trying to help me figure this out.  I'm enjoying learning 
> about GLMMs because they seem to be very useful in ecology, and I'm sure 
> I'll want to use them again in the future.
> 
> -Grant
> 
> ----- Original Message ----- 
> From: "Ben Bolker" <bolker at ufl.edu>
> To: "Grant T. Stokke" <gts127 at psu.edu>
> Cc: <r-sig-mixed-models at r-project.org>
> Sent: Friday, May 29, 2009 2:08 PM
> Subject: Re: [R-sig-ME] increasing nAGQ causes error
> 
> 
>>  Hmmm.  What version of lme4 are you using?  I have a
>> perhaps-more-recent version which gives me a different error:
>>
>>  from sessionInfo()
>>
>> other attached packages:
>> [1] lme4_0.999375-29   Matrix_0.999375-25 lattice_0.17-25
>>
>>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2)
>>> test2A <- update(test2,nAGQ=2)
>> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
>>
>>  This is a more intentional and more standard error message which
>> basically means (?) that there has been a numerical/convergence problem
>> along the way ... (I'm not sure what the "1." means, haven't looked into
>> it).
>>
>>  If I were in your position I might be satisfied with Laplace -- is
>> there a particular reason you need the greater accuracy of AGQ ... ?
>>
>>  I am running the test code below and have so far figured out that
>> it happens for nAGQ=8 (but not for 2, 3, 4, 5) when one uses the
>> first 10 cities (but OK for up to 9).  It's OK for 11 cities
>> for all nAGQ tried (oddly enough, but this is not terribly surprising
>> when things are on th edge of numerical stability).  Haven't yet seen
>> how the rest of the pattern plays out.
>>
>>  -------------------
>> testvals <- list()
>> nlev <- length(levels(subset2$CITY))
>> agqvals <- c(2,3,4,5,8)
>> for (i in 9:nlev) {
>>  testvals[[i-8]] <- list()
>>  for (j in 1:length(agqvals)) {
>>    agq <- agqvals[j]
>>    cat("***",i,agq,"\n")
>>    testvals[[i-8]][[j]]<-try(glmer(USED~1+IMPS+(1+IMPS|CITY),
>>                                family=binomial,data=subset2,
>>                                subset=as.numeric(CITY)<i,nAGQ=agq))
>>
>>   ## should have used <=i rather than <i ...
>>  }
>> }
>>
>>
>>
>>
>>
>>
>> Grant T. Stokke wrote:
>>> Dr. Bolker,
>>>
>>> Thanks for your prompt reply.  I created a subset of my dataset 
>>> (attached).
>>> This subset contains 14 of the 22 cities in the full dataset, and one
>>> covariate (% impervious surfaces [IMP]).  I had convergence issues before
>>> standardizing covariates, so I used:
>>>
>>> subset2$IMPS<-(subset2$IMP-mean(subset2$IMP))/(sqrt(var(subset2$IMP)))
>>>
>>> Fitting all 3 covariates takes quite a long time, and I get the same 
>>> error
>>> when using just one of them:
>>>
>>>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
>>>> test2
>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>
>>> Perhaps it's noteworthy that I did not receive the error when using a
>>> smaller subset with only the first 8 cities (in alphabetical order).
>>>
>>> I look forward to your response.  Thanks again...
>>>
>>> -Grant
>>>
>>>
>>> ----- Original Message ----- 
>>> From: "Ben Bolker" <bolker at ufl.edu>
>>> To: "Grant T. Stokke" <gts127 at psu.edu>
>>> Cc: <r-sig-mixed-models at r-project.org>
>>> Sent: Friday, May 29, 2009 12:11 PM
>>> Subject: Re: [R-sig-ME] increasing nAGQ causes error
>>>
>>>
>>>>  This sounds worth digging into, but it's hard to dig
>>>> into without a reproducible example.  I don't get the
>>>> problem with the GLMM example in the lme4 package:
>>>>
>>>> example(lmer)
>>>> update(gm1,nAGQ=8)
>>>> update(gm1,nAGQ=10)
>>>>
>>>> etc.
>>>>
>>>>  Can you post your data set, or a subset or simulated
>>>> data set that gives the same problem, somewhere?
>>>>
>>>>  Ben Bolker
>>>>
>>>> Grant T. Stokke wrote:
>>>>> Hello All,
>>>>>
>>>>> I'm new to R and new to this mailing list, so I hope I've presented
>>>>> the proper info in this post.  I'm using GLMMs to model the selection
>>>>> of urban roosting locations by crows.  My dataset consists of 22
>>>>> cities, with each city containing 1000 unused locations and from 83
>>>>> to 2000 used locations.  I have three covariates for each used or
>>>>> unused location which I've standardized across all observations: %
>>>>> canopy (CANS), % impervious surfaces (IMPS), and nighttime light
>>>>> level (LTS).  Using the default setting nAGQ=1, my full model is
>>>>> fitted without error:
>>>>>
>>>>>> CIL_CIL<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale)
>>>>>>  CIL_CIL
>>>>> Generalized linear mixed model fit by the Laplace approximation
>>>>> Formula: USED ~ 1 + CANS + IMPS + LTS + (1 + CANS + IMPS + LTS |
>>>>> CITY) Data: sitescale AIC   BIC logLik deviance 15122 15237  -7547
>>>>> 15094 Random effects: Groups Name        Variance   Std.Dev. Corr
>>>>>  CITY   (Intercept) 321.698184 17.93595 CANS          0.073271
>>>>> 0.27069  0.026 IMPS          0.661947  0.81360  0.080 -0.698 LTS
>>>>> 455.829122 21.35016 -0.988  0.031 -0.132 Number of obs: 27128,
>>>>> groups: CITY, 22
>>>>>
>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>>>> -16.21878    4.01227  -4.042 5.29e-05 *** CANS          0.07881
>>>>> 0.07162   1.100 0.271147 IMPS          0.63137    0.17750   3.557
>>>>> 0.000375 *** LTS          19.50827    4.78822   4.074 4.62e-05 ***
>>>>> --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>>>
>>>>> Correlation of Fixed Effects: (Intr) CANS   IMPS CANS  0.020
>>>>>  IMPS  0.074 -0.500 LTS  -0.989  0.025 -0.124
>>>>>
>>>>> When I increase nAGQ to 8, however, I get the following error:
>>>>>
>>>>>> CIL_CIL.nAGQ8<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale,nAGQ=8)
>>>>>>  CIL_CIL.nAGQ8
>>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>>
>>>>> I get the same error message with other values for nAGQ (I tried nAGQ
>>>>> = 2, 3, 5, and 50).  Is there anything I can do to fit the model
>>>>> using nAGQ > 1 without error?  Thanks in advance for your help!
>>>>>
>>>>> -Grant Stokke
>>>>>
>>>>>
>>>>>> sessionInfo()
>>>>> R version 2.9.0 (2009-04-17) i386-pc-mingw32
>>>>>
>>>>> locale: LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>>> States.1252;LC_MONETARY=English_United
>>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>>
>>>>> attached base packages: [1] stats     graphics  grDevices utils
>>>>> datasets  methods   base
>>>>>
>>>>> other attached packages: [1] mgcv_1.5-5         lme4_0.999375-30
>>>>> Matrix_0.999375-26 lattice_0.17-22
>>>>>
>>>>> loaded via a namespace (and not attached): [1] grid_2.9.0
>>>>> nlme_3.1-90 tools_2.9.0
>>>>>> CIL_CIL.nAGQ8
>>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>>> traceback()
>>>>> 18: .Call(dense_to_symmetric, from, "U", TRUE) 17: asMethod(object)
>>>>> 16: as(from, "symmetricMatrix") 15: .class1(object) 14: as(as(from,
>>>>> "symmetricMatrix"), "dMatrix") 13: .class1(object) 12: as(as(as(from,
>>>>> "symmetricMatrix"), "dMatrix"), "denseMatrix") 11: .class1(object)
>>>>> 10: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix"),
>>>>>  "dpoMatrix") 9: asMethod(object) 8: as(sigma(object)^2 *
>>>>> chol2inv(object at RX, size = object at dims["p"]), "dpoMatrix") 7:
>>>>> vcov(object) 6: vcov(object) 5: summary(x) 4: summary(x) 3:
>>>>> printMer(object) 2: function (object) standardGeneric("show")(<S4
>>>>> object of class "mer">) 1: function (object)
>>>>> standardGeneric("show")(<S4 object of class "mer">)
>>>>>
>>>>>
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> -- 
>>>> Ben Bolker
>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>>
>>
>> -- 
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From andydolman at gmail.com  Sat May 30 11:04:15 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Sat, 30 May 2009 11:04:15 +0200
Subject: [R-sig-ME] increasing nAGQ causes error
In-Reply-To: <4A205709.3080409@ufl.edu>
References: <F3A782D566FF44959D90179666B0462F@GrantOTron>
	<4A200940.60809@ufl.edu> <F15C833BC6F94315B4AD18B1393B566E@GrantOTron>
	<4A2024A5.7090806@ufl.edu>
	<4A580B7E2EBA472F9FCB36341D5CAF3C@GrantOTron>
	<4A205709.3080409@ufl.edu>
Message-ID: <951234ac0905300204y78bdf32bi545664c6c477354a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090530/bf9fc45d/attachment.pl>

From bolker at ufl.edu  Sat May 30 17:29:09 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 30 May 2009 11:29:09 -0400
Subject: [R-sig-ME] increasing nAGQ causes error
In-Reply-To: <951234ac0905300204y78bdf32bi545664c6c477354a@mail.gmail.com>
References: <F3A782D566FF44959D90179666B0462F@GrantOTron>	
	<4A200940.60809@ufl.edu>
	<F15C833BC6F94315B4AD18B1393B566E@GrantOTron>	
	<4A2024A5.7090806@ufl.edu>	
	<4A580B7E2EBA472F9FCB36341D5CAF3C@GrantOTron>	
	<4A205709.3080409@ufl.edu>
	<951234ac0905300204y78bdf32bi545664c6c477354a@mail.gmail.com>
Message-ID: <4A2150C5.2050602@ufl.edu>


  I think the problem is most likely in the higher _intercept_
in Lancaster, PA (City #15) -- if we fit glm(IMP*CITY) and
evaluate the mean and sd of the intercepts for the first 14
cities, Lancaster PA has a Z-score of >5 ... For what it's
worth, I can get the error to occur just with cities 14 and 15 ...

  With a data set this large, you could also probably simply
fit with a fixed effect of city (although technically your
inference would be different): the differences in coefficients
are very small ...


test3<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2)
test3B <- glm(USED~IMPS*CITY,family=binomial,data=subset2)

revals <- coef(test3)[[1]]

fixvals <- data.frame(int=coef(test3B)[1]+c(0,coef(test3B)[3:16]),
           IMPS=coef(test3B)[2]+c(0,coef(test3B)[17:30]))

par(mfrow=c(1,2),mar=c(5,3,1,0.5))
plot(revals[[1]],fixvals[[1]])
abline(a=0,b=1)
plot(revals[[2]],fixvals[[2]])

  Ben Bolker



Andrew Dolman wrote:
> Could the convergence issues be due to the large number of very low IMP values?
> 
> histogram(~IMP|CITY, data=subset2)
> 
> 
> 
> 
> andydolman at gmail.com<mailto:andydolman at gmail.com>
> 
> 
> 2009/5/29 Ben Bolker <bolker at ufl.edu<mailto:bolker at ufl.edu>>
> 
>  I updated to version xxx-31 and am still getting the "downdated X'X
> not positive definite" error rather than a "not symmetric" error (weird.
> platform-dependent numerical issues?)
> 
>  Based on a certain amount more messing around, I think there may
> be an issue with city #15 (by Murphy's Law?) --  convergence failed
> if I left out any city *except* #15.  This suggests looking at the
> data (which of course I should have done earlier!) to see if something
> suggests itself ...
> 
> library(ggplot2)
> 
> ggplot(subset2,aes(x=IMPS,y=USED)) + geom_point() + geom_smooth() +
> facet_wrap(~CITY)
> 
>  doesn't suggest anything really odd about Lancaster, PA except the
> highest overall fraction of sites used ...
> 
> 
> =================
> library(lme4)
> subset2 <- read.table("~/subset2.txt",header=TRUE)
> subset2$IMPS<-with(subset2,(IMP-mean(IMP))/sd(IMP))
> 
> if (FALSE) {
> 
> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
>  ## Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
> }
> testvals <- list()
> nlev <- length(levels(subset2$CITY))
> subvals <- 9:nlev
> agqvals <- c(2,3,4,5,8,15)
> for (i in 1:length(subvals)) {
>  testvals[[i]] <- list()
>  subval <- subvals[i]
>  for (j in 1:length(agqvals)) {
>    agq <- agqvals[j]
>    cat("***",subval,agq,"\n")
>    testvals[[i]][[j]]<-try(glmer(USED~1+IMPS+(1+IMPS|CITY),
>                                    family=binomial,data=subset2,
> 
> subset=as.numeric(CITY)<=subval,nAGQ=agq))
>  }
>  save("testvals",file="agqsubs.RData")
> }
> 
> 
> Grant T. Stokke wrote:
>> I'm using lme4 version lme4_0.999375-30 (as reported in sessionInfo();
>> that's what you're referring to, right?).  I downloaded lme4 only about a
>> week ago, so I would imagine it's up-to-date.
>>
>> Okay, I suppose maybe I should stick to the Laplacian approximation.  I
>> tried using AGQ not so much for accuracy, but because one of my models
>> refuses to converge, and I was checking to see if increasing nAGQ would
>> alleviate that issue.  (Maybe there's no way that would happen--I'll readily
>> admit that my understanding of the approximation methods is poor, but I
>> thought I'd give it a try.)  I was encouraged by the fact that changing nAGQ
>> didn't give convergence errors, but maybe convergence would still be a
>> problem anyway if glmer could get past the current error.
>>
>> Thanks so much for trying to help me figure this out.  I'm enjoying learning
>> about GLMMs because they seem to be very useful in ecology, and I'm sure
>> I'll want to use them again in the future.
>>
>> -Grant
>>
>> ----- Original Message -----
>> From: "Ben Bolker" <bolker at ufl.edu<mailto:bolker at ufl.edu>>
>> To: "Grant T. Stokke" <gts127 at psu.edu<mailto:gts127 at psu.edu>>
>> Cc: <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
>> Sent: Friday, May 29, 2009 2:08 PM
>> Subject: Re: [R-sig-ME] increasing nAGQ causes error
>>
>>
>>>  Hmmm.  What version of lme4 are you using?  I have a
>>> perhaps-more-recent version which gives me a different error:
>>>
>>>  from sessionInfo()
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-29   Matrix_0.999375-25 lattice_0.17-25
>>>
>>>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2)
>>>> test2A <- update(test2,nAGQ=2)
>>> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
>>>
>>>  This is a more intentional and more standard error message which
>>> basically means (?) that there has been a numerical/convergence problem
>>> along the way ... (I'm not sure what the "1." means, haven't looked into
>>> it).
>>>
>>>  If I were in your position I might be satisfied with Laplace -- is
>>> there a particular reason you need the greater accuracy of AGQ ... ?
>>>
>>>  I am running the test code below and have so far figured out that
>>> it happens for nAGQ=8 (but not for 2, 3, 4, 5) when one uses the
>>> first 10 cities (but OK for up to 9).  It's OK for 11 cities
>>> for all nAGQ tried (oddly enough, but this is not terribly surprising
>>> when things are on th edge of numerical stability).  Haven't yet seen
>>> how the rest of the pattern plays out.
>>>
>>>  -------------------
>>> testvals <- list()
>>> nlev <- length(levels(subset2$CITY))
>>> agqvals <- c(2,3,4,5,8)
>>> for (i in 9:nlev) {
>>>  testvals[[i-8]] <- list()
>>>  for (j in 1:length(agqvals)) {
>>>    agq <- agqvals[j]
>>>    cat("***",i,agq,"\n")
>>>    testvals[[i-8]][[j]]<-try(glmer(USED~1+IMPS+(1+IMPS|CITY),
>>>                                family=binomial,data=subset2,
>>>                                subset=as.numeric(CITY)<i,nAGQ=agq))
>>>
>>>   ## should have used <=i rather than <i ...
>>>  }
>>> }
>>>
>>>
>>>
>>>
>>>
>>>
>>> Grant T. Stokke wrote:
>>>> Dr. Bolker,
>>>>
>>>> Thanks for your prompt reply.  I created a subset of my dataset
>>>> (attached).
>>>> This subset contains 14 of the 22 cities in the full dataset, and one
>>>> covariate (% impervious surfaces [IMP]).  I had convergence issues before
>>>> standardizing covariates, so I used:
>>>>
>>>> subset2$IMPS<-(subset2$IMP-mean(subset2$IMP))/(sqrt(var(subset2$IMP)))
>>>>
>>>> Fitting all 3 covariates takes quite a long time, and I get the same
>>>> error
>>>> when using just one of them:
>>>>
>>>>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
>>>>> test2
>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>
>>>> Perhaps it's noteworthy that I did not receive the error when using a
>>>> smaller subset with only the first 8 cities (in alphabetical order).
>>>>
>>>> I look forward to your response.  Thanks again...
>>>>
>>>> -Grant
>>>>
>>>>
>>>> ----- Original Message -----
>>>> From: "Ben Bolker" <bolker at ufl.edu<mailto:bolker at ufl.edu>>
>>>> To: "Grant T. Stokke" <gts127 at psu.edu<mailto:gts127 at psu.edu>>
>>>> Cc: <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
>>>> Sent: Friday, May 29, 2009 12:11 PM
>>>> Subject: Re: [R-sig-ME] increasing nAGQ causes error
>>>>
>>>>
>>>>>  This sounds worth digging into, but it's hard to dig
>>>>> into without a reproducible example.  I don't get the
>>>>> problem with the GLMM example in the lme4 package:
>>>>>
>>>>> example(lmer)
>>>>> update(gm1,nAGQ=8)
>>>>> update(gm1,nAGQ=10)
>>>>>
>>>>> etc.
>>>>>
>>>>>  Can you post your data set, or a subset or simulated
>>>>> data set that gives the same problem, somewhere?
>>>>>
>>>>>  Ben Bolker
>>>>>
>>>>> Grant T. Stokke wrote:
>>>>>> Hello All,
>>>>>>
>>>>>> I'm new to R and new to this mailing list, so I hope I've presented
>>>>>> the proper info in this post.  I'm using GLMMs to model the selection
>>>>>> of urban roosting locations by crows.  My dataset consists of 22
>>>>>> cities, with each city containing 1000 unused locations and from 83
>>>>>> to 2000 used locations.  I have three covariates for each used or
>>>>>> unused location which I've standardized across all observations: %
>>>>>> canopy (CANS), % impervious surfaces (IMPS), and nighttime light
>>>>>> level (LTS).  Using the default setting nAGQ=1, my full model is
>>>>>> fitted without error:
>>>>>>
>>>>>>> CIL_CIL<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale)
>>>>>>>  CIL_CIL
>>>>>> Generalized linear mixed model fit by the Laplace approximation
>>>>>> Formula: USED ~ 1 + CANS + IMPS + LTS + (1 + CANS + IMPS + LTS |
>>>>>> CITY) Data: sitescale AIC   BIC logLik deviance 15122 15237  -7547
>>>>>> 15094 Random effects: Groups Name        Variance   Std.Dev. Corr
>>>>>>  CITY   (Intercept) 321.698184 17.93595 CANS          0.073271
>>>>>> 0.27069  0.026 IMPS          0.661947  0.81360  0.080 -0.698 LTS
>>>>>> 455.829122 21.35016 -0.988  0.031 -0.132 Number of obs: 27128,
>>>>>> groups: CITY, 22
>>>>>>
>>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>>>>> -16.21878    4.01227  -4.042 5.29e-05 *** CANS          0.07881
>>>>>> 0.07162   1.100 0.271147 IMPS          0.63137    0.17750   3.557
>>>>>> 0.000375 *** LTS          19.50827    4.78822   4.074 4.62e-05 ***
>>>>>> --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>>>>
>>>>>> Correlation of Fixed Effects: (Intr) CANS   IMPS CANS  0.020
>>>>>>  IMPS  0.074 -0.500 LTS  -0.989  0.025 -0.124
>>>>>>
>>>>>> When I increase nAGQ to 8, however, I get the following error:
>>>>>>
>>>>>>> CIL_CIL.nAGQ8<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale,nAGQ=8)
>>>>>>>  CIL_CIL.nAGQ8
>>>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>>>
>>>>>> I get the same error message with other values for nAGQ (I tried nAGQ
>>>>>> = 2, 3, 5, and 50).  Is there anything I can do to fit the model
>>>>>> using nAGQ > 1 without error?  Thanks in advance for your help!
>>>>>>
>>>>>> -Grant Stokke
>>>>>>
>>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 2.9.0 (2009-04-17) i386-pc-mingw32
>>>>>>
>>>>>> locale: LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>>>> States.1252;LC_MONETARY=English_United
>>>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>>>
>>>>>> attached base packages: [1] stats     graphics  grDevices utils
>>>>>> datasets  methods   base
>>>>>>
>>>>>> other attached packages: [1] mgcv_1.5-5         lme4_0.999375-30
>>>>>> Matrix_0.999375-26 lattice_0.17-22
>>>>>>
>>>>>> loaded via a namespace (and not attached): [1] grid_2.9.0
>>>>>> nlme_3.1-90 tools_2.9.0
>>>>>>> CIL_CIL.nAGQ8
>>>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>>>> traceback()
>>>>>> 18: .Call(dense_to_symmetric, from, "U", TRUE) 17: asMethod(object)
>>>>>> 16: as(from, "symmetricMatrix") 15: .class1(object) 14: as(as(from,
>>>>>> "symmetricMatrix"), "dMatrix") 13: .class1(object) 12: as(as(as(from,
>>>>>> "symmetricMatrix"), "dMatrix"), "denseMatrix") 11: .class1(object)
>>>>>> 10: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix"),
>>>>>>  "dpoMatrix") 9: asMethod(object) 8: as(sigma(object)^2 *
>>>>>> chol2inv(object at RX, size = object at dims["p"]), "dpoMatrix") 7:
>>>>>> vcov(object) 6: vcov(object) 5: summary(x) 4: summary(x) 3:
>>>>>> printMer(object) 2: function (object) standardGeneric("show")(<S4
>>>>>> object of class "mer">) 1: function (object)
>>>>>> standardGeneric("show")(<S4 object of class "mer">)
>>>>>>
>>>>>>
>>>>>>
>>>>>> [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> --
>>>>> Ben Bolker
>>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>>> bolker at ufl.edu<mailto:bolker at ufl.edu> / www.zoology.ufl.edu/bolker<http://www.zoology.ufl.edu/bolker>
>>>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc<http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>>>>>
>>> --
>>> Ben Bolker
>>> Associate professor, Biology Dep't, Univ. of Florida
>>> bolker at ufl.edu<mailto:bolker at ufl.edu> / www.zoology.ufl.edu/bolker<http://www.zoology.ufl.edu/bolker>
>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc<http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>>>
> 
> 
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu<mailto:bolker at ufl.edu> / www.zoology.ufl.edu/bolker<http://www.zoology.ufl.edu/bolker>
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc<http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From gts127 at psu.edu  Sat May 30 19:25:36 2009
From: gts127 at psu.edu (Grant T. Stokke)
Date: Sat, 30 May 2009 13:25:36 -0400
Subject: [R-sig-ME] increasing nAGQ causes error
In-Reply-To: <4A2150C5.2050602@ufl.edu>
References: <F3A782D566FF44959D90179666B0462F@GrantOTron>	
	<4A200940.60809@ufl.edu>
	<F15C833BC6F94315B4AD18B1393B566E@GrantOTron>	
	<4A2024A5.7090806@ufl.edu>	
	<4A580B7E2EBA472F9FCB36341D5CAF3C@GrantOTron>	
	<4A205709.3080409@ufl.edu>
	<951234ac0905300204y78bdf32bi545664c6c477354a@mail.gmail.com>
	<4A2150C5.2050602@ufl.edu>
Message-ID: <5E05860E54814DB58CA3324890452D40@GrantOTron>

First, I apologize for the large attachment--I hope it's not a problem.

Considering that Lancaster seems to be the culprit, I think the problem 
could be a result of different degrees of spatial autocorrelation among my 
observations.  I attached a figure to help illustrate my sampling scheme 
that may help to demonstrate the spatial autocorrelation.

I have 22 cities, with from 83 to ~2000 used points and (always) 1000 unused 
points within each city.  The used points are clustered together (with 
regular 30 m spacing in a grid configuration).  In contrast, the 1000 unused 
points are randomly selected points within the contiguous urban area.  In 
the figure, Waterbury has the minimum number of used points (i.e. ~83), 
while Lancaster has the maximum (~2000).  The used points are always more 
spatially autocorrelated than the unused points.  In some cities, I have 
only one observed used area (e.g. Waterbury), while in other cities, I have 
many observed areas (e.g. Lancaster).  A single used area produces the 
minimum # of used points for a city (83-85).

Sets of unused points from different cities can exhibit varying degrees of 
spatial autocorrelation because the contiguous urban area from which the 
unused points are sampled can vary in size.  Thus, on average, unused points 
are closer together (higher spatial autocorrelation) in small cities, and 
farther apart in large cities.  Not ideal, but probably not too terribly 
problematic when compared to the varying degrees of correlation among used 
points.

In cities with only one used area (e.g. Waterbury), all used points are 
approximately equally spatially autocorrelated.  In cities with numerous 
used areas (e.g. Lancaster), used points within the same used area are 
approximately equally (and highly) correlated with each other, but are 
considerably less correlated with used points in separate used areas within 
the city (which, in turn, are ~equally and highly autocorrelated with each 
other).

I'm toying around with the data to see if I can account for spatial 
autocorrelation by modeling it as a random effect.  So far, I haven't had 
any luck, but I'll keep you posted.  Of course, suggestions are more than 
welcome.  I realize that the "experimental" design here is a mess, and I may 
need to make some major changes.  Fortunately, the covariates are all 
generated in a GIS, so I can change the sampling scheme relatively easily. 
That the covariates have difficult distributions may also be problematic, as 
pointed out by Andrew Dolman.  I suppose I could use city as a fixed effect, 
and maybe that's what I'll need to do.  But since I want to make general 
inferences about roost-site selection across cities, using city as a random 
effect seems more suitable to me (?).

I should probably mention that my goal here is to estimate the fixed effects 
so that urban crow roost management programs in cities across the country 
could predict relative probabilities of where crows are likely to roost.  It 
would be very helpful to know what areas crows are likely to use if they are 
"evicted" from problematic urban roosting areas by harassment techniques 
(e.g. pyrotechnics, distress calls, etc.).  It's probably not realistic to 
expect highly accurate predictions, but I think being able to estimate 
relative probabilities of use would be a big improvement.

Thanks!

-Grant



----- Original Message ----- 
From: "Ben Bolker" <bolker at ufl.edu>
To: "Andrew Dolman" <andydolman at gmail.com>
Cc: "Grant T. Stokke" <gts127 at psu.edu>; "R Mixed Models" 
<r-sig-mixed-models at r-project.org>
Sent: Saturday, May 30, 2009 11:29 AM
Subject: Re: [R-sig-ME] increasing nAGQ causes error


>
>  I think the problem is most likely in the higher _intercept_
> in Lancaster, PA (City #15) -- if we fit glm(IMP*CITY) and
> evaluate the mean and sd of the intercepts for the first 14
> cities, Lancaster PA has a Z-score of >5 ... For what it's
> worth, I can get the error to occur just with cities 14 and 15 ...
>
>  With a data set this large, you could also probably simply
> fit with a fixed effect of city (although technically your
> inference would be different): the differences in coefficients
> are very small ...
>
>
> test3<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2)
> test3B <- glm(USED~IMPS*CITY,family=binomial,data=subset2)
>
> revals <- coef(test3)[[1]]
>
> fixvals <- data.frame(int=coef(test3B)[1]+c(0,coef(test3B)[3:16]),
>           IMPS=coef(test3B)[2]+c(0,coef(test3B)[17:30]))
>
> par(mfrow=c(1,2),mar=c(5,3,1,0.5))
> plot(revals[[1]],fixvals[[1]])
> abline(a=0,b=1)
> plot(revals[[2]],fixvals[[2]])
>
>  Ben Bolker
>
>
>
> Andrew Dolman wrote:
>> Could the convergence issues be due to the large number of very low IMP 
>> values?
>>
>> histogram(~IMP|CITY, data=subset2)
>>
>>
>>
>>
>> andydolman at gmail.com<mailto:andydolman at gmail.com>
>>
>>
>> 2009/5/29 Ben Bolker <bolker at ufl.edu<mailto:bolker at ufl.edu>>
>>
>>  I updated to version xxx-31 and am still getting the "downdated X'X
>> not positive definite" error rather than a "not symmetric" error (weird.
>> platform-dependent numerical issues?)
>>
>>  Based on a certain amount more messing around, I think there may
>> be an issue with city #15 (by Murphy's Law?) --  convergence failed
>> if I left out any city *except* #15.  This suggests looking at the
>> data (which of course I should have done earlier!) to see if something
>> suggests itself ...
>>
>> library(ggplot2)
>>
>> ggplot(subset2,aes(x=IMPS,y=USED)) + geom_point() + geom_smooth() +
>> facet_wrap(~CITY)
>>
>>  doesn't suggest anything really odd about Lancaster, PA except the
>> highest overall fraction of sites used ...
>>
>>
>> =================
>> library(lme4)
>> subset2 <- read.table("~/subset2.txt",header=TRUE)
>> subset2$IMPS<-with(subset2,(IMP-mean(IMP))/sd(IMP))
>>
>> if (FALSE) {
>>
>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
>>  ## Error in mer_finalize(ans) : Downdated X'X is not positive definite, 
>> 1.
>> }
>> testvals <- list()
>> nlev <- length(levels(subset2$CITY))
>> subvals <- 9:nlev
>> agqvals <- c(2,3,4,5,8,15)
>> for (i in 1:length(subvals)) {
>>  testvals[[i]] <- list()
>>  subval <- subvals[i]
>>  for (j in 1:length(agqvals)) {
>>    agq <- agqvals[j]
>>    cat("***",subval,agq,"\n")
>>    testvals[[i]][[j]]<-try(glmer(USED~1+IMPS+(1+IMPS|CITY),
>>                                    family=binomial,data=subset2,
>>
>> subset=as.numeric(CITY)<=subval,nAGQ=agq))
>>  }
>>  save("testvals",file="agqsubs.RData")
>> }
>>
>>
>> Grant T. Stokke wrote:
>>> I'm using lme4 version lme4_0.999375-30 (as reported in sessionInfo();
>>> that's what you're referring to, right?).  I downloaded lme4 only about 
>>> a
>>> week ago, so I would imagine it's up-to-date.
>>>
>>> Okay, I suppose maybe I should stick to the Laplacian approximation.  I
>>> tried using AGQ not so much for accuracy, but because one of my models
>>> refuses to converge, and I was checking to see if increasing nAGQ would
>>> alleviate that issue.  (Maybe there's no way that would happen--I'll 
>>> readily
>>> admit that my understanding of the approximation methods is poor, but I
>>> thought I'd give it a try.)  I was encouraged by the fact that changing 
>>> nAGQ
>>> didn't give convergence errors, but maybe convergence would still be a
>>> problem anyway if glmer could get past the current error.
>>>
>>> Thanks so much for trying to help me figure this out.  I'm enjoying 
>>> learning
>>> about GLMMs because they seem to be very useful in ecology, and I'm sure
>>> I'll want to use them again in the future.
>>>
>>> -Grant
>>>
>>> ----- Original Message -----
>>> From: "Ben Bolker" <bolker at ufl.edu<mailto:bolker at ufl.edu>>
>>> To: "Grant T. Stokke" <gts127 at psu.edu<mailto:gts127 at psu.edu>>
>>> Cc: 
>>> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
>>> Sent: Friday, May 29, 2009 2:08 PM
>>> Subject: Re: [R-sig-ME] increasing nAGQ causes error
>>>
>>>
>>>>  Hmmm.  What version of lme4 are you using?  I have a
>>>> perhaps-more-recent version which gives me a different error:
>>>>
>>>>  from sessionInfo()
>>>>
>>>> other attached packages:
>>>> [1] lme4_0.999375-29   Matrix_0.999375-25 lattice_0.17-25
>>>>
>>>>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2)
>>>>> test2A <- update(test2,nAGQ=2)
>>>> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
>>>>
>>>>  This is a more intentional and more standard error message which
>>>> basically means (?) that there has been a numerical/convergence problem
>>>> along the way ... (I'm not sure what the "1." means, haven't looked 
>>>> into
>>>> it).
>>>>
>>>>  If I were in your position I might be satisfied with Laplace -- is
>>>> there a particular reason you need the greater accuracy of AGQ ... ?
>>>>
>>>>  I am running the test code below and have so far figured out that
>>>> it happens for nAGQ=8 (but not for 2, 3, 4, 5) when one uses the
>>>> first 10 cities (but OK for up to 9).  It's OK for 11 cities
>>>> for all nAGQ tried (oddly enough, but this is not terribly surprising
>>>> when things are on th edge of numerical stability).  Haven't yet seen
>>>> how the rest of the pattern plays out.
>>>>
>>>>  -------------------
>>>> testvals <- list()
>>>> nlev <- length(levels(subset2$CITY))
>>>> agqvals <- c(2,3,4,5,8)
>>>> for (i in 9:nlev) {
>>>>  testvals[[i-8]] <- list()
>>>>  for (j in 1:length(agqvals)) {
>>>>    agq <- agqvals[j]
>>>>    cat("***",i,agq,"\n")
>>>>    testvals[[i-8]][[j]]<-try(glmer(USED~1+IMPS+(1+IMPS|CITY),
>>>>                                family=binomial,data=subset2,
>>>>                                subset=as.numeric(CITY)<i,nAGQ=agq))
>>>>
>>>>   ## should have used <=i rather than <i ...
>>>>  }
>>>> }
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Grant T. Stokke wrote:
>>>>> Dr. Bolker,
>>>>>
>>>>> Thanks for your prompt reply.  I created a subset of my dataset
>>>>> (attached).
>>>>> This subset contains 14 of the 22 cities in the full dataset, and one
>>>>> covariate (% impervious surfaces [IMP]).  I had convergence issues 
>>>>> before
>>>>> standardizing covariates, so I used:
>>>>>
>>>>> subset2$IMPS<-(subset2$IMP-mean(subset2$IMP))/(sqrt(var(subset2$IMP)))
>>>>>
>>>>> Fitting all 3 covariates takes quite a long time, and I get the same
>>>>> error
>>>>> when using just one of them:
>>>>>
>>>>>> test2<-glmer(USED~1+IMPS+(1+IMPS|CITY),family=binomial,data=subset2,nAGQ=8)
>>>>>> test2
>>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>>
>>>>> Perhaps it's noteworthy that I did not receive the error when using a
>>>>> smaller subset with only the first 8 cities (in alphabetical order).
>>>>>
>>>>> I look forward to your response.  Thanks again...
>>>>>
>>>>> -Grant
>>>>>
>>>>>
>>>>> ----- Original Message -----
>>>>> From: "Ben Bolker" <bolker at ufl.edu<mailto:bolker at ufl.edu>>
>>>>> To: "Grant T. Stokke" <gts127 at psu.edu<mailto:gts127 at psu.edu>>
>>>>> Cc: 
>>>>> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
>>>>> Sent: Friday, May 29, 2009 12:11 PM
>>>>> Subject: Re: [R-sig-ME] increasing nAGQ causes error
>>>>>
>>>>>
>>>>>>  This sounds worth digging into, but it's hard to dig
>>>>>> into without a reproducible example.  I don't get the
>>>>>> problem with the GLMM example in the lme4 package:
>>>>>>
>>>>>> example(lmer)
>>>>>> update(gm1,nAGQ=8)
>>>>>> update(gm1,nAGQ=10)
>>>>>>
>>>>>> etc.
>>>>>>
>>>>>>  Can you post your data set, or a subset or simulated
>>>>>> data set that gives the same problem, somewhere?
>>>>>>
>>>>>>  Ben Bolker
>>>>>>
>>>>>> Grant T. Stokke wrote:
>>>>>>> Hello All,
>>>>>>>
>>>>>>> I'm new to R and new to this mailing list, so I hope I've presented
>>>>>>> the proper info in this post.  I'm using GLMMs to model the 
>>>>>>> selection
>>>>>>> of urban roosting locations by crows.  My dataset consists of 22
>>>>>>> cities, with each city containing 1000 unused locations and from 83
>>>>>>> to 2000 used locations.  I have three covariates for each used or
>>>>>>> unused location which I've standardized across all observations: %
>>>>>>> canopy (CANS), % impervious surfaces (IMPS), and nighttime light
>>>>>>> level (LTS).  Using the default setting nAGQ=1, my full model is
>>>>>>> fitted without error:
>>>>>>>
>>>>>>>> CIL_CIL<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale)
>>>>>>>>  CIL_CIL
>>>>>>> Generalized linear mixed model fit by the Laplace approximation
>>>>>>> Formula: USED ~ 1 + CANS + IMPS + LTS + (1 + CANS + IMPS + LTS |
>>>>>>> CITY) Data: sitescale AIC   BIC logLik deviance 15122 15237  -7547
>>>>>>> 15094 Random effects: Groups Name        Variance   Std.Dev. Corr
>>>>>>>  CITY   (Intercept) 321.698184 17.93595 CANS          0.073271
>>>>>>> 0.27069  0.026 IMPS          0.661947  0.81360  0.080 -0.698 LTS
>>>>>>> 455.829122 21.35016 -0.988  0.031 -0.132 Number of obs: 27128,
>>>>>>> groups: CITY, 22
>>>>>>>
>>>>>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>>>>>> -16.21878    4.01227  -4.042 5.29e-05 *** CANS          0.07881
>>>>>>> 0.07162   1.100 0.271147 IMPS          0.63137    0.17750   3.557
>>>>>>> 0.000375 *** LTS          19.50827    4.78822   4.074 4.62e-05 ***
>>>>>>> --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>>>>>
>>>>>>> Correlation of Fixed Effects: (Intr) CANS   IMPS CANS  0.020
>>>>>>>  IMPS  0.074 -0.500 LTS  -0.989  0.025 -0.124
>>>>>>>
>>>>>>> When I increase nAGQ to 8, however, I get the following error:
>>>>>>>
>>>>>>>> CIL_CIL.nAGQ8<-glmer(USED~1+CANS+IMPS+LTS+(1+CANS+IMPS+LTS|CITY),family=binomial,data=sitescale,nAGQ=8)
>>>>>>>>  CIL_CIL.nAGQ8
>>>>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>>>>
>>>>>>> I get the same error message with other values for nAGQ (I tried 
>>>>>>> nAGQ
>>>>>>> = 2, 3, 5, and 50).  Is there anything I can do to fit the model
>>>>>>> using nAGQ > 1 without error?  Thanks in advance for your help!
>>>>>>>
>>>>>>> -Grant Stokke
>>>>>>>
>>>>>>>
>>>>>>>> sessionInfo()
>>>>>>> R version 2.9.0 (2009-04-17) i386-pc-mingw32
>>>>>>>
>>>>>>> locale: LC_COLLATE=English_United 
>>>>>>> States.1252;LC_CTYPE=English_United
>>>>>>> States.1252;LC_MONETARY=English_United
>>>>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>>>>
>>>>>>> attached base packages: [1] stats     graphics  grDevices utils
>>>>>>> datasets  methods   base
>>>>>>>
>>>>>>> other attached packages: [1] mgcv_1.5-5         lme4_0.999375-30
>>>>>>> Matrix_0.999375-26 lattice_0.17-22
>>>>>>>
>>>>>>> loaded via a namespace (and not attached): [1] grid_2.9.0
>>>>>>> nlme_3.1-90 tools_2.9.0
>>>>>>>> CIL_CIL.nAGQ8
>>>>>>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>>>>>>> traceback()
>>>>>>> 18: .Call(dense_to_symmetric, from, "U", TRUE) 17: asMethod(object)
>>>>>>> 16: as(from, "symmetricMatrix") 15: .class1(object) 14: as(as(from,
>>>>>>> "symmetricMatrix"), "dMatrix") 13: .class1(object) 12: 
>>>>>>> as(as(as(from,
>>>>>>> "symmetricMatrix"), "dMatrix"), "denseMatrix") 11: .class1(object)
>>>>>>> 10: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), 
>>>>>>> "denseMatrix"),
>>>>>>>  "dpoMatrix") 9: asMethod(object) 8: as(sigma(object)^2 *
>>>>>>> chol2inv(object at RX, size = object at dims["p"]), "dpoMatrix") 7:
>>>>>>> vcov(object) 6: vcov(object) 5: summary(x) 4: summary(x) 3:
>>>>>>> printMer(object) 2: function (object) standardGeneric("show")(<S4
>>>>>>> object of class "mer">) 1: function (object)
>>>>>>> standardGeneric("show")(<S4 object of class "mer">)
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> 
>>>>>>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> --
>>>>>> Ben Bolker
>>>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>>>> bolker at ufl.edu<mailto:bolker at ufl.edu> / 
>>>>>> www.zoology.ufl.edu/bolker<http://www.zoology.ufl.edu/bolker>
>>>>>> GPG key: 
>>>>>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc<http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>>>>>>
>>>> --
>>>> Ben Bolker
>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>> bolker at ufl.edu<mailto:bolker at ufl.edu> / 
>>>> www.zoology.ufl.edu/bolker<http://www.zoology.ufl.edu/bolker>
>>>> GPG key: 
>>>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc<http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>>>>
>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu<mailto:bolker at ufl.edu> / 
>> www.zoology.ufl.edu/bolker<http://www.zoology.ufl.edu/bolker>
>> GPG key: 
>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc<http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> 
>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> 

From sashag at stanford.edu  Sun May 31 00:23:51 2009
From: sashag at stanford.edu (Sasha Goodman)
Date: Sat, 30 May 2009 15:23:51 -0700
Subject: [R-sig-ME] cloglog link in lmer
Message-ID: <e6820af20905301523h7d98c90dpff88a28d1fe0cc85@mail.gmail.com>

We have been using lme4 with a logit link and crossed random effects.
It works very nicely. However, because our outcome is very rare, we
are trying the cloglog link with lmer. The model simply does not run,
however. The errors is  "mu[i] must be in the range (0,1)". A google
search reveals no one else has ever posted this particular problem.

I'm sending the following details in case it helps the developers.
Advice is also welcomed.

Descriptives for the two variables:
Y: [0,1], ? R, E=0.007238727, SE=0.08477285, the binary response
X : [0.4318617,0.998886], ? R, E=0.9886799, SE=0.03572924, continuous
in the range  [0.4318617,0.998886]

## Crossed with cloglog fails
h = lmer(Y ~ X + (1 | i) + (1 | j) + (1|t), D2 ,family =
binomial(link="cloglog"),control = list(msVerbose = 1))
  0:     5328.8713: 0.100868 0.0552843 0.00896829 -35.7191  31.0045
Error in mer_finalize(ans) :
  mu[i] must be in the range (0,1): mu = 0, i = 253517704

## Crossed with logit works
h = lmer(Y ~ X + (1 | i) + (1 | j) + (1|t), D2 ,family =
binomial(link="logit"),control = list(msVerbose = 1))
summary(h)
Generalized linear mixed model fit by the Laplace approximation
Formula: Y ~ X + (1 | i) + (1 | j) + (1 | t)
   Data: D2
  AIC  BIC logLik deviance
 1797 1843 -893.5     1787
Random effects:
 Groups Name        Variance Std.Dev.
 j      (Intercept)  17.9346  4.2349
 i      (Intercept) 126.9971 11.2693
 t      (Intercept)   2.6644  1.6323
Number of obs: 66310, groups: j, 253; i, 76; t, 2

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   -81.38      19.29  -4.219 2.46e-05 ***
X                  60.91      19.26   3.162  0.00157 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



## Simple GLM with the same data runs perfectly
h = glm(Y ~ X , D2 ,family = binomial(link="cloglog"))

glm(formula = Y ~ X, family = binomial(link = "cloglog"),
    data = D2)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-0.1316  -0.1271  -0.1270  -0.1212   3.9149

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -35.719      6.833  -5.228 1.72e-07 ***
X               31.004      6.869   4.514 6.37e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 5687.7  on 66309  degrees of freedom
Residual deviance: 5643.9  on 66308  degrees of freedom
AIC: 5647.9

Number of Fisher Scoring iterations: 10


--
Sasha Goodman
Doctoral Student, Organizational Behavior
Office: 1 (650) 492-4892
Skype: goodmansasha
sashag at stanford.edu



From baron at psych.upenn.edu  Mon Jun  1 16:11:48 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 1 Jun 2009 10:11:48 -0400
Subject: [R-sig-ME] r-sig-mixed-models now indexed in finzi.psych.upenn.edu
Message-ID: <20090601141148.GA23970@psych.upenn.edu>

I've added the complete archives of this mailing list to the index in
my search site: http://finzi.psych.upenn.edu/search.html

This is the same site as RSiteSearch, so "R-sig-mixed-models" might
work as an option in that function.

It is not in the default search path.  You have to check the box (or
choose the option in RSiteSearch).

Jon



From Christine.Griffiths at bristol.ac.uk  Mon Jun  1 19:00:20 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Mon, 01 Jun 2009 18:00:20 +0100
Subject: [R-sig-ME] zero variance query
Message-ID: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>


Dear R users,

I am having a problem with getting zero variance in my lmer models which 
specify two random effects. Having scoured the help lists, I have read that 
this could be because my variables are strongly correlated. However, when I 
simplify my model I still encounter the same problem.

My response variable is abundance which ranges from 0-0.14.

Below is an example of my model:
> m1<-lmer(Abundance~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> summary(m1)
Generalized linear mixed model fit by the Laplace approximation
Formula: Abundance ~ Treatment + (1 | Month) + (1 | Block)
   AIC   BIC logLik deviance
 17.55 36.00 -2.777    5.554
Random effects:
 Groups   Name        Variance   Std.Dev.
 Month    (Intercept) 5.1704e-17 7.1906e-09
 Block    (Intercept) 0.0000e+00 0.0000e+00
 Residual             1.0695e-03 3.2704e-02
Number of obs: 160, groups: Month, 10; Block, 6

Fixed effects:
                   Estimate Std. Error t value
(Intercept)        -3.73144    0.02728 -136.80
Treatment2.Radiata  0.58779    0.03521   16.69
Treatment3.Aldabra  0.47269    0.03606   13.11

Correlation of Fixed Effects:
            (Intr) Trt2.R
Trtmnt2.Rdt -0.775
Trtmnt3.Ald -0.756  0.586

1. Is it wrong to treat this as count data?
2. I would like to retain these as random factors given that I designed my 
experiment as a randomised block design and repeated measures, albeit 
non-orthogonal and unbalanced. Is it acceptable to retain these random 
factors, is all else is correct?
3. The above response variable was calculated per m2 by dividing the Count 
by the sample area. When I used the Count (range 0-9) as my response 
variable, I get a small but reasonable variation of random effects. Could 
anyone explain why this occurs and whether one response variable is better 
than another?

> m2<-lmer(Count~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> summary(m2)
Generalized linear mixed model fit by the Laplace approximation
Formula: Count ~ Treatment + (1 | Month) + (1 | Block)
   AIC BIC logLik deviance
 312.5 331 -150.3    300.5
Random effects:
 Groups   Name        Variance Std.Dev.
 Month    (Intercept) 0.14591  0.38198
 Block    (Intercept) 0.58690  0.76609
 Residual             2.79816  1.67277
Number of obs: 160, groups: Month, 10; Block, 6

Fixed effects:
                   Estimate Std. Error t value
(Intercept)          0.3098     0.3799  0.8155
Treatment2.Radiata   0.5879     0.2299  2.5575
Treatment3.Aldabra   0.5745     0.2382  2.4117

Correlation of Fixed Effects:
            (Intr) Trt2.R
Trtmnt2.Rdt -0.347
Trtmnt3.Ald -0.348  0.536

Many thanks,
Christine



From charpent at bacbuc.dyndns.org  Tue Jun  2 01:07:37 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Tue, 02 Jun 2009 01:07:37 +0200
Subject: [R-sig-ME] zero variance query
In-Reply-To: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
References: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
Message-ID: <1243897656.11231.14.camel@yod>

Le lundi 01 juin 2009 ? 18:00 +0100, Christine Griffiths a ?crit :
> Dear R users,
> 
> I am having a problem with getting zero variance in my lmer models which 
> specify two random effects. Having scoured the help lists, I have read that 
> this could be because my variables are strongly correlated. However, when I 
> simplify my model I still encounter the same problem.
> 
> My response variable is abundance which ranges from 0-0.14.
> 
> Below is an example of my model:
> > m1<-lmer(Abundance~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> > summary(m1)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Abundance ~ Treatment + (1 | Month) + (1 | Block)
>    AIC   BIC logLik deviance
>  17.55 36.00 -2.777    5.554
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  Month    (Intercept) 5.1704e-17 7.1906e-09
>  Block    (Intercept) 0.0000e+00 0.0000e+00
>  Residual             1.0695e-03 3.2704e-02
> Number of obs: 160, groups: Month, 10; Block, 6
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)        -3.73144    0.02728 -136.80
> Treatment2.Radiata  0.58779    0.03521   16.69
> Treatment3.Aldabra  0.47269    0.03606   13.11
> 
> Correlation of Fixed Effects:
>             (Intr) Trt2.R
> Trtmnt2.Rdt -0.775
> Trtmnt3.Ald -0.756  0.586
> 
> 1. Is it wrong to treat this as count data?

Hmmm... IST vaguely R that, when the world was young and I was (already)
silly, Poisson distribution used to be a *discrete* distribution. Of
course, this may or may not stand for "quasi"Poisson (for some value of
"quasi").

May I inquire if you tried to analyze log(Abundance) (or log(Count),
maybe including log(area) in the model) ?

HTH,

					Emmanuel Charpentier

> 2. I would like to retain these as random factors given that I designed my 
> experiment as a randomised block design and repeated measures, albeit 
> non-orthogonal and unbalanced. Is it acceptable to retain these random 
> factors, is all else is correct?
> 3. The above response variable was calculated per m2 by dividing the Count 
> by the sample area. When I used the Count (range 0-9) as my response 
> variable, I get a small but reasonable variation of random effects. Could 
> anyone explain why this occurs and whether one response variable is better 
> than another?
> 
> > m2<-lmer(Count~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> > summary(m2)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Count ~ Treatment + (1 | Month) + (1 | Block)
>    AIC BIC logLik deviance
>  312.5 331 -150.3    300.5
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Month    (Intercept) 0.14591  0.38198
>  Block    (Intercept) 0.58690  0.76609
>  Residual             2.79816  1.67277
> Number of obs: 160, groups: Month, 10; Block, 6
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)          0.3098     0.3799  0.8155
> Treatment2.Radiata   0.5879     0.2299  2.5575
> Treatment3.Aldabra   0.5745     0.2382  2.4117
> 
> Correlation of Fixed Effects:
>             (Intr) Trt2.R
> Trtmnt2.Rdt -0.347
> Trtmnt3.Ald -0.348  0.536
> 
> Many thanks,
> Christine
> 



From bolker at ufl.edu  Tue Jun  2 05:17:33 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 01 Jun 2009 23:17:33 -0400
Subject: [R-sig-ME] zero variance query
In-Reply-To: <1243897656.11231.14.camel@yod>
References: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
	<1243897656.11231.14.camel@yod>
Message-ID: <4A2499CD.2070906@ufl.edu>

Emmanuel Charpentier wrote:
> Le lundi 01 juin 2009 ? 18:00 +0100, Christine Griffiths a ?crit :
>> Dear R users,
>>
>> I am having a problem with getting zero variance in my lmer models which 
>> specify two random effects. Having scoured the help lists, I have read that 
>> this could be because my variables are strongly correlated. However, when I 
>> simplify my model I still encounter the same problem.
>>
>> My response variable is abundance which ranges from 0-0.14.
>>
>> Below is an example of my model:
>>> m1<-lmer(Abundance~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>>> summary(m1)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: Abundance ~ Treatment + (1 | Month) + (1 | Block)
>>    AIC   BIC logLik deviance
>>  17.55 36.00 -2.777    5.554
>> Random effects:
>>  Groups   Name        Variance   Std.Dev.
>>  Month    (Intercept) 5.1704e-17 7.1906e-09
>>  Block    (Intercept) 0.0000e+00 0.0000e+00
>>  Residual             1.0695e-03 3.2704e-02
>> Number of obs: 160, groups: Month, 10; Block, 6
>>
>> Fixed effects:
>>                    Estimate Std. Error t value
>> (Intercept)        -3.73144    0.02728 -136.80
>> Treatment2.Radiata  0.58779    0.03521   16.69
>> Treatment3.Aldabra  0.47269    0.03606   13.11
>>
>> Correlation of Fixed Effects:
>>             (Intr) Trt2.R
>> Trtmnt2.Rdt -0.775
>> Trtmnt3.Ald -0.756  0.586
>>
>> 1. Is it wrong to treat this as count data?
> 
> Hmmm... IST vaguely R that, when the world was young and I was (already)
> silly, Poisson distribution used to be a *discrete* distribution. Of
> course, this may or may not stand for "quasi"Poisson (for some value of
> "quasi").
> 
> May I inquire if you tried to analyze log(Abundance) (or log(Count),
> maybe including log(area) in the model) ?
> 
> HTH,
> 
> 					Emmanuel Charpentier
> 
>> 2. I would like to retain these as random factors given that I designed my 
>> experiment as a randomised block design and repeated measures, albeit 
>> non-orthogonal and unbalanced. Is it acceptable to retain these random 
>> factors, is all else is correct?

   I think so ...

>> 3. The above response variable was calculated per m2 by dividing the Count 
>> by the sample area. When I used the Count (range 0-9) as my response 
>> variable, I get a small but reasonable variation of random effects. Could 
>> anyone explain why this occurs and whether one response variable is better 
>> than another?

  To agree with what Emmanuel said above: you should use Count~...,
offset=log(area) for the correct analysis ...  that should solve
both your technical (zero random effects) and conceptual (even
quasiPoisson should be discrete data) issues.

>>
>>> m2<-lmer(Count~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>>> summary(m2)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: Count ~ Treatment + (1 | Month) + (1 | Block)
>>    AIC BIC logLik deviance
>>  312.5 331 -150.3    300.5
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  Month    (Intercept) 0.14591  0.38198
>>  Block    (Intercept) 0.58690  0.76609
>>  Residual             2.79816  1.67277
>> Number of obs: 160, groups: Month, 10; Block, 6
>>
>> Fixed effects:
>>                    Estimate Std. Error t value
>> (Intercept)          0.3098     0.3799  0.8155
>> Treatment2.Radiata   0.5879     0.2299  2.5575
>> Treatment3.Aldabra   0.5745     0.2382  2.4117
>>
>> Correlation of Fixed Effects:
>>             (Intr) Trt2.R
>> Trtmnt2.Rdt -0.347
>> Trtmnt3.Ald -0.348  0.536
>>
>> Many thanks,
>> Christine
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Tue Jun  2 13:43:23 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 02 Jun 2009 07:43:23 -0400
Subject: [R-sig-ME] zero variance query
In-Reply-To: <F09E2CE4AA38D4D95DD43A2C@bio-mammal026.bio.bris.ac.uk>
References: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
	<1243897656.11231.14.camel@yod> <4A2499CD.2070906@ufl.edu>
	<F09E2CE4AA38D4D95DD43A2C@bio-mammal026.bio.bris.ac.uk>
Message-ID: <4A25105B.8030101@ufl.edu>

Christine Griffiths wrote:
> Dear Emmanuel and Ben
> 
> Many thanks for your advice. Unfortunately, I don't think that I can offset 
> with log(area), given that each area is the same.

  Why not?  All the offset does is add a constant (i.e., fixed rather
than estimated -- could be the same or different for different
observations) to the regression model.

> My rationale for 
> converting to m2 was to standardise abundances to 1 m2 as I have other 
> parameters which were measured to different areas. 

   Don't quite understand this.  Parameters from other studies that you
want to compare in discussion?  If so, you can just rescale your
predictions/parameters *after* you estimate them ...

I had previously
> attempted to normalise my data by logging but felt that it did not improve 
> the distribution. I just hadn't tried it in my modelling. Logging my count 
> data dramatically improved the fit of the model (AIC 116.7 v 312.5), 
> however the variance still remains low. Does this appear acceptable?
> Furthermore, can I assess model fit of different transformations of the 
> same dataset using AIC values, i.e. compare log(Count) and inverse 
> transformed Count?

  No, not without a correction.  See
http://www.unc.edu/courses/2007spring/enst/562/001/docs/lectures/lecture22.htm

  Generalized linear modeling is not as flexible (in some ways) as
classical linear models -- you can't just transform the data any way you
want (in principle I suppose you could,  but it's basically not possible
to "transform to achieve a Poisson distribution" the way you would
transform continuous data to achieve normality etc.)

> 
> lncount<-log(Count+1)
> m1<-m1<-lmer(lncount~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> summary(m1)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: lncount ~ Treatment + (1 | Month) + (1 | Block)
>    AIC   BIC logLik deviance
>  116.7 135.1 -52.33    104.7
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  Month    (Intercept) 1.8937e-14 1.3761e-07
>  Block    (Intercept) 3.5018e-02 1.8713e-01
>  Residual             3.9318e-01 6.2704e-01
> Number of obs: 160, groups: Month, 10; Block, 6
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)         -0.4004     0.1239  -3.232
> Treatment2.Radiata   0.4596     0.1305   3.522
> Treatment3.Aldabra   0.4295     0.1334   3.220
> 
> Correlation of Fixed Effects:
>             (Intr) Trt2.R
> Trtmnt2.Rdt -0.581
> Trtmnt3.Ald -0.577  0.530
> 
> I used quasipoisson as my data is overdispersed. It was further improved by 
> an inverse transformation (AIC 43.54). Again I have small variances.
> 
> invcount<-1/(Count+1)
> m3<-lmer(invcount~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> summary(m3)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: invcount ~ Treatment + (1 | Month) + (1 | Block)
>    AIC BIC logLik deviance
>  43.54  62 -15.77    31.54
> Random effects:
>  Groups   Name        Variance  Std.Dev.
>  Month    (Intercept) 0.0000000 0.000000
>  Block    (Intercept) 0.0021038 0.045867
>  Residual             0.0926225 0.304339
> Number of obs: 160, groups: Month, 10; Block, 6
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)        -0.51644    0.05411  -9.545
> Treatment2.Radiata -0.36246    0.08401  -4.314
> Treatment3.Aldabra -0.29319    0.08197  -3.577
> 
> Correlation of Fixed Effects:
>             (Intr) Trt2.R
> Trtmnt2.Rdt -0.566
> Trtmnt3.Ald -0.580  0.372
> 
> Log(Abundance) did not solve the problem of zero variance. If quasipoisson 
> errors are not acceptable to use with abundance, i.e. non-integers, is 
> there a family of errors that would be recommended? Or should I simply 
> multiply abundance to obtain whole numbers?
> 
> Many thanks in advance,
> Christine
> 
> 
> --On 01 June 2009 23:17 -0400 Ben Bolker <bolker at ufl.edu> wrote:
> 
>> Emmanuel Charpentier wrote:
>>> Le lundi 01 juin 2009 ? 18:00 +0100, Christine Griffiths a ?crit :
>>>> Dear R users,
>>>>
>>>> I am having a problem with getting zero variance in my lmer models
>>>> which  specify two random effects. Having scoured the help lists, I
>>>> have read that  this could be because my variables are strongly
>>>> correlated. However, when I  simplify my model I still encounter the
>>>> same problem.
>>>>
>>>> My response variable is abundance which ranges from 0-0.14.
>>>>
>>>> Below is an example of my model:
>>>>> m1<-lmer(Abundance~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>>>>> summary(m1)
>>>> Generalized linear mixed model fit by the Laplace approximation
>>>> Formula: Abundance ~ Treatment + (1 | Month) + (1 | Block)
>>>>    AIC   BIC logLik deviance
>>>>  17.55 36.00 -2.777    5.554
>>>> Random effects:
>>>>  Groups   Name        Variance   Std.Dev.
>>>>  Month    (Intercept) 5.1704e-17 7.1906e-09
>>>>  Block    (Intercept) 0.0000e+00 0.0000e+00
>>>>  Residual             1.0695e-03 3.2704e-02
>>>> Number of obs: 160, groups: Month, 10; Block, 6
>>>>
>>>> Fixed effects:
>>>>                    Estimate Std. Error t value
>>>> (Intercept)        -3.73144    0.02728 -136.80
>>>> Treatment2.Radiata  0.58779    0.03521   16.69
>>>> Treatment3.Aldabra  0.47269    0.03606   13.11
>>>>
>>>> Correlation of Fixed Effects:
>>>>             (Intr) Trt2.R
>>>> Trtmnt2.Rdt -0.775
>>>> Trtmnt3.Ald -0.756  0.586
>>>>
>>>> 1. Is it wrong to treat this as count data?
>>> Hmmm... IST vaguely R that, when the world was young and I was (already)
>>> silly, Poisson distribution used to be a *discrete* distribution. Of
>>> course, this may or may not stand for "quasi"Poisson (for some value of
>>> "quasi").
>>>
>>> May I inquire if you tried to analyze log(Abundance) (or log(Count),
>>> maybe including log(area) in the model) ?
>>>
>>> HTH,
>>>
>>> 					Emmanuel Charpentier
>>>
>>>> 2. I would like to retain these as random factors given that I designed
>>>> my  experiment as a randomised block design and repeated measures,
>>>> albeit  non-orthogonal and unbalanced. Is it acceptable to retain these
>>>> random  factors, is all else is correct?
>>    I think so ...
>>
>>>> 3. The above response variable was calculated per m2 by dividing the
>>>> Count  by the sample area. When I used the Count (range 0-9) as my
>>>> response  variable, I get a small but reasonable variation of random
>>>> effects. Could  anyone explain why this occurs and whether one response
>>>> variable is better  than another?
>>   To agree with what Emmanuel said above: you should use Count~...,
>> offset=log(area) for the correct analysis ...  that should solve
>> both your technical (zero random effects) and conceptual (even
>> quasiPoisson should be discrete data) issues.
>>
>>>>> m2<-lmer(Count~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>>>>> summary(m2)
>>>> Generalized linear mixed model fit by the Laplace approximation
>>>> Formula: Count ~ Treatment + (1 | Month) + (1 | Block)
>>>>    AIC BIC logLik deviance
>>>>  312.5 331 -150.3    300.5
>>>> Random effects:
>>>>  Groups   Name        Variance Std.Dev.
>>>>  Month    (Intercept) 0.14591  0.38198
>>>>  Block    (Intercept) 0.58690  0.76609
>>>>  Residual             2.79816  1.67277
>>>> Number of obs: 160, groups: Month, 10; Block, 6
>>>>
>>>> Fixed effects:
>>>>                    Estimate Std. Error t value
>>>> (Intercept)          0.3098     0.3799  0.8155
>>>> Treatment2.Radiata   0.5879     0.2299  2.5575
>>>> Treatment3.Aldabra   0.5745     0.2382  2.4117
>>>>
>>>> Correlation of Fixed Effects:
>>>>             (Intr) Trt2.R
>>>> Trtmnt2.Rdt -0.347
>>>> Trtmnt3.Ald -0.348  0.536
>>>>
>>>> Many thanks,
>>>> Christine
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> ----------------------
> Christine Griffiths
> School of Biological Sciences
> University of Bristol
> Woodland Road
> Bristol BS8 1UG
> Tel: 0117 9287593
> Fax 0117 925 7374
> Christine.Griffiths at bristol.ac.uk
> http://www.bio.bris.ac.uk/research/mammal/tortoises.html


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From paolo.innocenti at ebc.uu.se  Tue Jun  2 14:53:42 2009
From: paolo.innocenti at ebc.uu.se (Paolo Innocenti)
Date: Tue, 02 Jun 2009 14:53:42 +0200
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression and
	iteration
Message-ID: <4A2520D6.6080108@ebc.uu.se>

Dear Douglas and list,

I am thinking about fitting a mixed model for a microarray experiment 
using lme4, since other specific software seems not suitable for my 
purposes. I'll briefly describe the model and kindly ask for suggestions 
on the model and the workflow I can use to get useful results.

My response variable Y is gene expression levels for a given gene (say 
g_i) from 120 samples.
The factor I want to include are:

Sex: fixed, two levels, M/F.
Line: 15 randomly picked genotypes from a large outbred population.

I am interested in:
- if the gene is differentially expressed in the 2 sexes (effect of 
sex), in the 15 lines (effect of line) and the interaction of the two.

- the variance component of line = how much of the variance is due to 
the genotype

- the variance component of the interaction = the genetic variation for 
sexual dimorphism.

Reading a bit of this mailing list, I came up with these three models:

m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))

or

m2 <- lmer(Y1 ~ sex + (sex|line))

or

m3 <- lmer(Y1 ~ sex + (0 + sex|line))

Which should all be the same model (and indeed they have all the same 
residuals) but different parametrization (see self-contained example 
below).

Now, in the light of my needs (see above), which model makes it easier 
to extract the components I need? Also, do they make different 
assumptions - as different levels of independency among levels of random 
factors?

I will need to be able to extract the variance component values in an 
iterative process (i have 18.000 genes): is VarCorr() the way to go?

VarCorr(m1)$'sex:line'[1]
VarCorr(m1)$'line'[1]

Last two question: what is the easier way to assess, in an iterative 
process, normality of residuals, and what is a sensible way to assess 
significant differential expression of genes (since I guess I can't get 
p-values and then apply FDR correction?)

Thanks a lot for reading so far and I'll be grateful for any kind of help.
paolo

Self-contained example:

Y1 <- as.numeric(
c("11.6625","11.3243","11.7819","11.5032","11.7578","11.9379","11.8491",
"11.9035","11.2042","11.0344","11.5137","11.1995","11.6327","11.7392",
"11.9869","11.6955","11.5631","11.7159","11.8435","11.5814","12.0756",
"12.3428","12.3342","11.9883","11.6067","11.6102","11.6517","11.4444",
"11.9567","12.0478","11.9683","11.8207","11.5860","11.6028","11.6522",
"11.6775","12.3570","12.2266","12.2444","12.1369","11.2573","11.4577",
"11.4432","11.2994","11.8486","11.9258","11.9864","11.9964","11.2806",
"11.2527","11.3672","11.0791","11.9501","11.7223","11.9825","11.8114",
"11.6116","11.4284","11.3731","11.6942","12.2153","12.0101","12.2150",
"12.1932","11.5617","11.3761","11.4813","11.7503","11.9889","12.1530",
"12.3299","12.4436","11.4566","11.4614","11.5527","11.3513","11.9764",
"11.8810","12.0999","11.9083","11.4870","11.6764","11.3973","11.4507",
"12.1141","11.9906","12.1118","11.9728","11.3382","11.4146","11.4590",
"11.2527","12.1101","12.0448","12.2191","11.8317","11.3982","11.3555",
"11.3897","11.7731","11.9749","11.8666","12.1984","12.0350","11.4642",
"11.4509","11.5552","11.4346","12.0714","11.7136","11.9019","11.8158",
"11.3132","11.3121","11.1612","11.2073","11.6658","11.7879","11.7847",
"11.5300"))
sex <- factor(rep(c("F","M"), 15, each=4))
line <- factor(rep(1:15, each=8))
m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
m2 <- lmer(Y1 ~ sex + (sex|line))
m3 <- lmer(Y1 ~ sex + (0 + sex|line))
VarCorr(m1)$'sex:line'[1]
VarCorr(m1)$'line'[1]

Output:

>> m1
> Linear mixed model fit by REML 
> Formula: Y1 ~ sex + (1 | line) + (1 | sex:line) 
>     AIC   BIC logLik deviance REMLdev
>  -91.13 -77.2  50.57   -111.1  -101.1
> Random effects:
>  Groups   Name        Variance  Std.Dev.
>  sex:line (Intercept) 0.0023237 0.048205
>  line     (Intercept) 0.0169393 0.130151
>  Residual             0.0168238 0.129707
> Number of obs: 120, groups: sex:line, 30; line, 15
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept) 11.45977    0.03955  289.72
> sexM         0.52992    0.02951   17.96
> 
> Correlation of Fixed Effects:
>      (Intr)
> sexM -0.373
>> m2
> Linear mixed model fit by REML 
> Formula: Y1 ~ sex + (sex | line) 
>  AIC    BIC logLik deviance REMLdev
>  -90 -73.27     51   -112.1    -102
> Random effects:
>  Groups   Name        Variance  Std.Dev. Corr  
>  line     (Intercept) 0.0152993 0.123691       
>           sexM        0.0046474 0.068172 0.194 
>  Residual             0.0168238 0.129707       
> Number of obs: 120, groups: line, 15
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept) 11.45977    0.03606   317.8
> sexM         0.52992    0.02951    18.0
> 
> Correlation of Fixed Effects:
>      (Intr)
> sexM -0.161
>> m3
> Linear mixed model fit by REML 
> Formula: Y1 ~ sex + (0 + sex | line) 
>  AIC    BIC logLik deviance REMLdev
>  -90 -73.27     51   -112.1    -102
> Random effects:
>  Groups   Name Variance Std.Dev. Corr  
>  line     sexF 0.015299 0.12369        
>           sexM 0.023227 0.15240  0.899 
>  Residual      0.016824 0.12971        
> Number of obs: 120, groups: line, 15
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept) 11.45977    0.03606   317.8
> sexM         0.52991    0.02951    18.0
> 
> Correlation of Fixed Effects:
>      (Intr)
> sexM -0.161



-- 
Paolo Innocenti
Department of Animal Ecology, EBC
Uppsala University
Norbyv?gen 18D
75236 Uppsala, Sweden



From Christine.Griffiths at bristol.ac.uk  Tue Jun  2 11:45:40 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Tue, 02 Jun 2009 10:45:40 +0100
Subject: [R-sig-ME] zero variance query
In-Reply-To: <4A2499CD.2070906@ufl.edu>
References: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
	<1243897656.11231.14.camel@yod> <4A2499CD.2070906@ufl.edu>
Message-ID: <F09E2CE4AA38D4D95DD43A2C@bio-mammal026.bio.bris.ac.uk>

Dear Emmanuel and Ben

Many thanks for your advice. Unfortunately, I don't think that I can offset 
with log(area), given that each area is the same. My rationale for 
converting to m2 was to standardise abundances to 1 m2 as I have other 
parameters which were measured to different areas. I had previously 
attempted to normalise my data by logging but felt that it did not improve 
the distribution. I just hadn't tried it in my modelling. Logging my count 
data dramatically improved the fit of the model (AIC 116.7 v 312.5), 
however the variance still remains low. Does this appear acceptable?
Furthermore, can I assess model fit of different transformations of the 
same dataset using AIC values, i.e. compare log(Count) and inverse 
transformed Count?

lncount<-log(Count+1)
m1<-m1<-lmer(lncount~Treatment+(1|Month)+(1|Block),family=quasipoisson)
summary(m1)
Generalized linear mixed model fit by the Laplace approximation
Formula: lncount ~ Treatment + (1 | Month) + (1 | Block)
   AIC   BIC logLik deviance
 116.7 135.1 -52.33    104.7
Random effects:
 Groups   Name        Variance   Std.Dev.
 Month    (Intercept) 1.8937e-14 1.3761e-07
 Block    (Intercept) 3.5018e-02 1.8713e-01
 Residual             3.9318e-01 6.2704e-01
Number of obs: 160, groups: Month, 10; Block, 6

Fixed effects:
                   Estimate Std. Error t value
(Intercept)         -0.4004     0.1239  -3.232
Treatment2.Radiata   0.4596     0.1305   3.522
Treatment3.Aldabra   0.4295     0.1334   3.220

Correlation of Fixed Effects:
            (Intr) Trt2.R
Trtmnt2.Rdt -0.581
Trtmnt3.Ald -0.577  0.530

I used quasipoisson as my data is overdispersed. It was further improved by 
an inverse transformation (AIC 43.54). Again I have small variances.

invcount<-1/(Count+1)
m3<-lmer(invcount~Treatment+(1|Month)+(1|Block),family=quasipoisson)
summary(m3)
Generalized linear mixed model fit by the Laplace approximation
Formula: invcount ~ Treatment + (1 | Month) + (1 | Block)
   AIC BIC logLik deviance
 43.54  62 -15.77    31.54
Random effects:
 Groups   Name        Variance  Std.Dev.
 Month    (Intercept) 0.0000000 0.000000
 Block    (Intercept) 0.0021038 0.045867
 Residual             0.0926225 0.304339
Number of obs: 160, groups: Month, 10; Block, 6

Fixed effects:
                   Estimate Std. Error t value
(Intercept)        -0.51644    0.05411  -9.545
Treatment2.Radiata -0.36246    0.08401  -4.314
Treatment3.Aldabra -0.29319    0.08197  -3.577

Correlation of Fixed Effects:
            (Intr) Trt2.R
Trtmnt2.Rdt -0.566
Trtmnt3.Ald -0.580  0.372

Log(Abundance) did not solve the problem of zero variance. If quasipoisson 
errors are not acceptable to use with abundance, i.e. non-integers, is 
there a family of errors that would be recommended? Or should I simply 
multiply abundance to obtain whole numbers?

Many thanks in advance,
Christine


--On 01 June 2009 23:17 -0400 Ben Bolker <bolker at ufl.edu> wrote:

> Emmanuel Charpentier wrote:
>> Le lundi 01 juin 2009 ? 18:00 +0100, Christine Griffiths a ?crit :
>>> Dear R users,
>>>
>>> I am having a problem with getting zero variance in my lmer models
>>> which  specify two random effects. Having scoured the help lists, I
>>> have read that  this could be because my variables are strongly
>>> correlated. However, when I  simplify my model I still encounter the
>>> same problem.
>>>
>>> My response variable is abundance which ranges from 0-0.14.
>>>
>>> Below is an example of my model:
>>>> m1<-lmer(Abundance~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>>>> summary(m1)
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: Abundance ~ Treatment + (1 | Month) + (1 | Block)
>>>    AIC   BIC logLik deviance
>>>  17.55 36.00 -2.777    5.554
>>> Random effects:
>>>  Groups   Name        Variance   Std.Dev.
>>>  Month    (Intercept) 5.1704e-17 7.1906e-09
>>>  Block    (Intercept) 0.0000e+00 0.0000e+00
>>>  Residual             1.0695e-03 3.2704e-02
>>> Number of obs: 160, groups: Month, 10; Block, 6
>>>
>>> Fixed effects:
>>>                    Estimate Std. Error t value
>>> (Intercept)        -3.73144    0.02728 -136.80
>>> Treatment2.Radiata  0.58779    0.03521   16.69
>>> Treatment3.Aldabra  0.47269    0.03606   13.11
>>>
>>> Correlation of Fixed Effects:
>>>             (Intr) Trt2.R
>>> Trtmnt2.Rdt -0.775
>>> Trtmnt3.Ald -0.756  0.586
>>>
>>> 1. Is it wrong to treat this as count data?
>>
>> Hmmm... IST vaguely R that, when the world was young and I was (already)
>> silly, Poisson distribution used to be a *discrete* distribution. Of
>> course, this may or may not stand for "quasi"Poisson (for some value of
>> "quasi").
>>
>> May I inquire if you tried to analyze log(Abundance) (or log(Count),
>> maybe including log(area) in the model) ?
>>
>> HTH,
>>
>> 					Emmanuel Charpentier
>>
>>> 2. I would like to retain these as random factors given that I designed
>>> my  experiment as a randomised block design and repeated measures,
>>> albeit  non-orthogonal and unbalanced. Is it acceptable to retain these
>>> random  factors, is all else is correct?
>
>    I think so ...
>
>>> 3. The above response variable was calculated per m2 by dividing the
>>> Count  by the sample area. When I used the Count (range 0-9) as my
>>> response  variable, I get a small but reasonable variation of random
>>> effects. Could  anyone explain why this occurs and whether one response
>>> variable is better  than another?
>
>   To agree with what Emmanuel said above: you should use Count~...,
> offset=log(area) for the correct analysis ...  that should solve
> both your technical (zero random effects) and conceptual (even
> quasiPoisson should be discrete data) issues.
>
>>>
>>>> m2<-lmer(Count~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>>>> summary(m2)
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: Count ~ Treatment + (1 | Month) + (1 | Block)
>>>    AIC BIC logLik deviance
>>>  312.5 331 -150.3    300.5
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  Month    (Intercept) 0.14591  0.38198
>>>  Block    (Intercept) 0.58690  0.76609
>>>  Residual             2.79816  1.67277
>>> Number of obs: 160, groups: Month, 10; Block, 6
>>>
>>> Fixed effects:
>>>                    Estimate Std. Error t value
>>> (Intercept)          0.3098     0.3799  0.8155
>>> Treatment2.Radiata   0.5879     0.2299  2.5575
>>> Treatment3.Aldabra   0.5745     0.2382  2.4117
>>>
>>> Correlation of Fixed Effects:
>>>             (Intr) Trt2.R
>>> Trtmnt2.Rdt -0.347
>>> Trtmnt3.Ald -0.348  0.536
>>>
>>> Many thanks,
>>> Christine
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
Christine Griffiths
School of Biological Sciences
University of Bristol
Woodland Road
Bristol BS8 1UG
Tel: 0117 9287593
Fax 0117 925 7374
Christine.Griffiths at bristol.ac.uk
http://www.bio.bris.ac.uk/research/mammal/tortoises.html



From andydolman at gmail.com  Tue Jun  2 19:54:56 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 2 Jun 2009 19:54:56 +0200
Subject: [R-sig-ME] zero variance query
In-Reply-To: <4A25105B.8030101@ufl.edu>
References: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
	<1243897656.11231.14.camel@yod> <4A2499CD.2070906@ufl.edu>
	<F09E2CE4AA38D4D95DD43A2C@bio-mammal026.bio.bris.ac.uk>
	<4A25105B.8030101@ufl.edu>
Message-ID: <951234ac0906021054h6f583ab8xc73fa488e4a54798@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090602/3568b0e3/attachment.pl>

From charpent at bacbuc.dyndns.org  Tue Jun  2 20:07:56 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Tue, 02 Jun 2009 20:07:56 +0200
Subject: [R-sig-ME] zero variance query
In-Reply-To: <F09E2CE4AA38D4D95DD43A2C@bio-mammal026.bio.bris.ac.uk>
References: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
	<1243897656.11231.14.camel@yod> <4A2499CD.2070906@ufl.edu>
	<F09E2CE4AA38D4D95DD43A2C@bio-mammal026.bio.bris.ac.uk>
Message-ID: <1243966076.5208.26.camel@yod>

Le mardi 02 juin 2009 ? 10:45 +0100, Christine Griffiths a ?crit :
> Dear Emmanuel and Ben
> 
> Many thanks for your advice. Unfortunately, I don't think that I can offset 
> with log(area), given that each area is the same. My rationale for 
> converting to m2 was to standardise abundances to 1 m2 as I have other 
> parameters which were measured to different areas. I had previously 
> attempted to normalise my data by logging but felt that it did not improve 
> the distribution. I just hadn't tried it in my modelling. Logging my count 
> data dramatically improved the fit of the model (AIC 116.7 v 312.5), 
> however the variance still remains low. Does this appear acceptable?
> Furthermore, can I assess model fit of different transformations of the 
> same dataset using AIC values, i.e. compare log(Count) and inverse 
> transformed Count?
> 
> lncount<-log(Count+1)
> m1<-m1<-lmer(lncount~Treatment+(1|Month)+(1|Block),family=quasipoisson)

Aaargh ! I thought that "lmer(lncount~Treatment+(1|Month)+(1|
Block),family=gaussian)" (+/- log(area somewhere in the model or the
fit) might give good hints as a first (known bad) approximation, and
didn't made myself clear. That's what happens when you try to be
sarcastic while dog-tired...

And maybe your random effects *are* quite low. What happens with :
summary(glm(Count~Treatment+Month+Block, family=quasipoisson) (or
something to that effect) ? What says a simple crosstabulation ? or a
graph ("caterpillar", for example) ?

HTH,

					Emmanuel Charpentier


> summary(m1)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: lncount ~ Treatment + (1 | Month) + (1 | Block)
>    AIC   BIC logLik deviance
>  116.7 135.1 -52.33    104.7
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  Month    (Intercept) 1.8937e-14 1.3761e-07
>  Block    (Intercept) 3.5018e-02 1.8713e-01
>  Residual             3.9318e-01 6.2704e-01
> Number of obs: 160, groups: Month, 10; Block, 6
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)         -0.4004     0.1239  -3.232
> Treatment2.Radiata   0.4596     0.1305   3.522
> Treatment3.Aldabra   0.4295     0.1334   3.220
> 
> Correlation of Fixed Effects:
>             (Intr) Trt2.R
> Trtmnt2.Rdt -0.581
> Trtmnt3.Ald -0.577  0.530
> 
> I used quasipoisson as my data is overdispersed. It was further improved by 
> an inverse transformation (AIC 43.54). Again I have small variances.
> 
> invcount<-1/(Count+1)
> m3<-lmer(invcount~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> summary(m3)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: invcount ~ Treatment + (1 | Month) + (1 | Block)
>    AIC BIC logLik deviance
>  43.54  62 -15.77    31.54
> Random effects:
>  Groups   Name        Variance  Std.Dev.
>  Month    (Intercept) 0.0000000 0.000000
>  Block    (Intercept) 0.0021038 0.045867
>  Residual             0.0926225 0.304339
> Number of obs: 160, groups: Month, 10; Block, 6
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)        -0.51644    0.05411  -9.545
> Treatment2.Radiata -0.36246    0.08401  -4.314
> Treatment3.Aldabra -0.29319    0.08197  -3.577
> 
> Correlation of Fixed Effects:
>             (Intr) Trt2.R
> Trtmnt2.Rdt -0.566
> Trtmnt3.Ald -0.580  0.372
> 
> Log(Abundance) did not solve the problem of zero variance. If quasipoisson 
> errors are not acceptable to use with abundance, i.e. non-integers, is 
> there a family of errors that would be recommended? Or should I simply 
> multiply abundance to obtain whole numbers?
> 
> Many thanks in advance,
> Christine
> 
> 
> --On 01 June 2009 23:17 -0400 Ben Bolker <bolker-hnhdhkBXzx8 at public.gmane.org> wrote:
> 
> > Emmanuel Charpentier wrote:
> >> Le lundi 01 juin 2009 ? 18:00 +0100, Christine Griffiths a ?crit :
> >>> Dear R users,
> >>>
> >>> I am having a problem with getting zero variance in my lmer models
> >>> which  specify two random effects. Having scoured the help lists, I
> >>> have read that  this could be because my variables are strongly
> >>> correlated. However, when I  simplify my model I still encounter the
> >>> same problem.
> >>>
> >>> My response variable is abundance which ranges from 0-0.14.
> >>>
> >>> Below is an example of my model:
> >>>> m1<-lmer(Abundance~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> >>>> summary(m1)
> >>> Generalized linear mixed model fit by the Laplace approximation
> >>> Formula: Abundance ~ Treatment + (1 | Month) + (1 | Block)
> >>>    AIC   BIC logLik deviance
> >>>  17.55 36.00 -2.777    5.554
> >>> Random effects:
> >>>  Groups   Name        Variance   Std.Dev.
> >>>  Month    (Intercept) 5.1704e-17 7.1906e-09
> >>>  Block    (Intercept) 0.0000e+00 0.0000e+00
> >>>  Residual             1.0695e-03 3.2704e-02
> >>> Number of obs: 160, groups: Month, 10; Block, 6
> >>>
> >>> Fixed effects:
> >>>                    Estimate Std. Error t value
> >>> (Intercept)        -3.73144    0.02728 -136.80
> >>> Treatment2.Radiata  0.58779    0.03521   16.69
> >>> Treatment3.Aldabra  0.47269    0.03606   13.11
> >>>
> >>> Correlation of Fixed Effects:
> >>>             (Intr) Trt2.R
> >>> Trtmnt2.Rdt -0.775
> >>> Trtmnt3.Ald -0.756  0.586
> >>>
> >>> 1. Is it wrong to treat this as count data?
> >>
> >> Hmmm... IST vaguely R that, when the world was young and I was (already)
> >> silly, Poisson distribution used to be a *discrete* distribution. Of
> >> course, this may or may not stand for "quasi"Poisson (for some value of
> >> "quasi").
> >>
> >> May I inquire if you tried to analyze log(Abundance) (or log(Count),
> >> maybe including log(area) in the model) ?
> >>
> >> HTH,
> >>
> >> 					Emmanuel Charpentier
> >>
> >>> 2. I would like to retain these as random factors given that I designed
> >>> my  experiment as a randomised block design and repeated measures,
> >>> albeit  non-orthogonal and unbalanced. Is it acceptable to retain these
> >>> random  factors, is all else is correct?
> >
> >    I think so ...
> >
> >>> 3. The above response variable was calculated per m2 by dividing the
> >>> Count  by the sample area. When I used the Count (range 0-9) as my
> >>> response  variable, I get a small but reasonable variation of random
> >>> effects. Could  anyone explain why this occurs and whether one response
> >>> variable is better  than another?
> >
> >   To agree with what Emmanuel said above: you should use Count~...,
> > offset=log(area) for the correct analysis ...  that should solve
> > both your technical (zero random effects) and conceptual (even
> > quasiPoisson should be discrete data) issues.
> >
> >>>
> >>>> m2<-lmer(Count~Treatment+(1|Month)+(1|Block),family=quasipoisson)
> >>>> summary(m2)
> >>> Generalized linear mixed model fit by the Laplace approximation
> >>> Formula: Count ~ Treatment + (1 | Month) + (1 | Block)
> >>>    AIC BIC logLik deviance
> >>>  312.5 331 -150.3    300.5
> >>> Random effects:
> >>>  Groups   Name        Variance Std.Dev.
> >>>  Month    (Intercept) 0.14591  0.38198
> >>>  Block    (Intercept) 0.58690  0.76609
> >>>  Residual             2.79816  1.67277
> >>> Number of obs: 160, groups: Month, 10; Block, 6
> >>>
> >>> Fixed effects:
> >>>                    Estimate Std. Error t value
> >>> (Intercept)          0.3098     0.3799  0.8155
> >>> Treatment2.Radiata   0.5879     0.2299  2.5575
> >>> Treatment3.Aldabra   0.5745     0.2382  2.4117
> >>>
> >>> Correlation of Fixed Effects:
> >>>             (Intr) Trt2.R
> >>> Trtmnt2.Rdt -0.347
> >>> Trtmnt3.Ald -0.348  0.536
> >>>
> >>> Many thanks,
> >>> Christine
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > --
> > Ben Bolker
> > Associate professor, Biology Dep't, Univ. of Florida
> > bolker at ufl.edu / www.zoology.ufl.edu/bolker
> > GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> ----------------------
> Christine Griffiths
> School of Biological Sciences
> University of Bristol
> Woodland Road
> Bristol BS8 1UG
> Tel: 0117 9287593
> Fax 0117 925 7374
> Christine.Griffiths at bristol.ac.uk
> http://www.bio.bris.ac.uk/research/mammal/tortoises.html
> 



From bates at stat.wisc.edu  Tue Jun  2 21:54:31 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 2 Jun 2009 14:54:31 -0500
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
	and iteration
In-Reply-To: <4A2520D6.6080108@ebc.uu.se>
References: <4A2520D6.6080108@ebc.uu.se>
Message-ID: <40e66e0b0906021254ta8463a2p71e03f05dfa8d453@mail.gmail.com>

On Tue, Jun 2, 2009 at 7:53 AM, Paolo Innocenti
<paolo.innocenti at ebc.uu.se> wrote:
> Dear Douglas and list,

> I am thinking about fitting a mixed model for a microarray experiment using
> lme4, since other specific software seems not suitable for my purposes. I'll
> briefly describe the model and kindly ask for suggestions on the model and
> the workflow I can use to get useful results.

> My response variable Y is gene expression levels for a given gene (say g_i)
> from 120 samples.
> The factor I want to include are:

> Sex: fixed, two levels, M/F.
> Line: 15 randomly picked genotypes from a large outbred population.

> I am interested in:
> - if the gene is differentially expressed in the 2 sexes (effect of sex), in
> the 15 lines (effect of line) and the interaction of the two.

> - the variance component of line = how much of the variance is due to the
> genotype

> - the variance component of the interaction = the genetic variation for
> sexual dimorphism.

> Reading a bit of this mailing list, I came up with these three models:

> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))

> or

> m2 <- lmer(Y1 ~ sex + (sex|line))

> or

> m3 <- lmer(Y1 ~ sex + (0 + sex|line))

> Which should all be the same model (and indeed they have all the same
> residuals) but different parametrization (see self-contained example below).

Not really.  m2 and m3 are different parameterizations of the same
model but m1 is different.  In models m2 and m3 the random effects for
F and for M are allowed to be correlated within a line.  Thus there
are three parameters determining the variance-covariance of the random
effects.  In model m1 the unconditional distribution of the random
effects for the sex:line interaction is independent of the
distribution of the random effects for line.

> Now, in the light of my needs (see above), which model makes it easier to
> extract the components I need? Also, do they make different assumptions - as
> different levels of independency among levels of random factors?

I would use either m1 or m3 because I find the correlation structure
in m3 easier to understand than that of m2.

> I will need to be able to extract the variance component values in an
> iterative process (i have 18.000 genes): is VarCorr() the way to go?

I think so.  I would definitely look into using refit to update the
fitted model rather than starting from scratch with each of the genes.

I would use the idiom

> unlist(VarCorr(m1))
   sex:line        line
0.002323722 0.016939242

to get the estimated variances.

> VarCorr(m1)$'sex:line'[1]
> VarCorr(m1)$'line'[1]
>
> Last two question: what is the easier way to assess, in an iterative
> process, normality of residuals, and what is a sensible way to assess
> significant differential expression of genes (since I guess I can't get
> p-values and then apply FDR correction?)
>
> Thanks a lot for reading so far and I'll be grateful for any kind of help.
> paolo
>
> Self-contained example:
>
> Y1 <- as.numeric(
> c("11.6625","11.3243","11.7819","11.5032","11.7578","11.9379","11.8491",
> "11.9035","11.2042","11.0344","11.5137","11.1995","11.6327","11.7392",
> "11.9869","11.6955","11.5631","11.7159","11.8435","11.5814","12.0756",
> "12.3428","12.3342","11.9883","11.6067","11.6102","11.6517","11.4444",
> "11.9567","12.0478","11.9683","11.8207","11.5860","11.6028","11.6522",
> "11.6775","12.3570","12.2266","12.2444","12.1369","11.2573","11.4577",
> "11.4432","11.2994","11.8486","11.9258","11.9864","11.9964","11.2806",
> "11.2527","11.3672","11.0791","11.9501","11.7223","11.9825","11.8114",
> "11.6116","11.4284","11.3731","11.6942","12.2153","12.0101","12.2150",
> "12.1932","11.5617","11.3761","11.4813","11.7503","11.9889","12.1530",
> "12.3299","12.4436","11.4566","11.4614","11.5527","11.3513","11.9764",
> "11.8810","12.0999","11.9083","11.4870","11.6764","11.3973","11.4507",
> "12.1141","11.9906","12.1118","11.9728","11.3382","11.4146","11.4590",
> "11.2527","12.1101","12.0448","12.2191","11.8317","11.3982","11.3555",
> "11.3897","11.7731","11.9749","11.8666","12.1984","12.0350","11.4642",
> "11.4509","11.5552","11.4346","12.0714","11.7136","11.9019","11.8158",
> "11.3132","11.3121","11.1612","11.2073","11.6658","11.7879","11.7847",
> "11.5300"))
> sex <- factor(rep(c("F","M"), 15, each=4))
> line <- factor(rep(1:15, each=8))
> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
> m2 <- lmer(Y1 ~ sex + (sex|line))
> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
> VarCorr(m1)$'sex:line'[1]
> VarCorr(m1)$'line'[1]
>
> Output:
>
>>> m1
>>
>> Linear mixed model fit by REML Formula: Y1 ~ sex + (1 | line) + (1 |
>> sex:line) ? ?AIC ? BIC logLik deviance REMLdev
>> ?-91.13 -77.2 ?50.57 ? -111.1 ?-101.1
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance ?Std.Dev.
>> ?sex:line (Intercept) 0.0023237 0.048205
>> ?line ? ? (Intercept) 0.0169393 0.130151
>> ?Residual ? ? ? ? ? ? 0.0168238 0.129707
>> Number of obs: 120, groups: sex:line, 30; line, 15
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) 11.45977 ? ?0.03955 ?289.72
>> sexM ? ? ? ? 0.52992 ? ?0.02951 ? 17.96
>>
>> Correlation of Fixed Effects:
>> ? ? (Intr)
>> sexM -0.373
>>>
>>> m2
>>
>> Linear mixed model fit by REML Formula: Y1 ~ sex + (sex | line) ?AIC
>> ?BIC logLik deviance REMLdev
>> ?-90 -73.27 ? ? 51 ? -112.1 ? ?-102
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance ?Std.Dev. Corr ??line ? ? (Intercept)
>> 0.0152993 0.123691 ? ? ? ? ? ? ? ?sexM ? ? ? ?0.0046474 0.068172 0.194
>> ?Residual ? ? ? ? ? ? 0.0168238 0.129707 ? ? ? Number of obs: 120, groups:
>> line, 15
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) 11.45977 ? ?0.03606 ? 317.8
>> sexM ? ? ? ? 0.52992 ? ?0.02951 ? ?18.0
>>
>> Correlation of Fixed Effects:
>> ? ? (Intr)
>> sexM -0.161
>>>
>>> m3
>>
>> Linear mixed model fit by REML Formula: Y1 ~ sex + (0 + sex | line) ?AIC
>> ?BIC logLik deviance REMLdev
>> ?-90 -73.27 ? ? 51 ? -112.1 ? ?-102
>> Random effects:
>> ?Groups ? Name Variance Std.Dev. Corr ??line ? ? sexF 0.015299 0.12369
>> ? ? ? ? ? ? ?sexM 0.023227 0.15240 ?0.899 ?Residual ? ? ?0.016824 0.12971
>> ? ? ?Number of obs: 120, groups: line, 15
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) 11.45977 ? ?0.03606 ? 317.8
>> sexM ? ? ? ? 0.52991 ? ?0.02951 ? ?18.0
>>
>> Correlation of Fixed Effects:
>> ? ? (Intr)
>> sexM -0.161
>
>
>
> --
> Paolo Innocenti
> Department of Animal Ecology, EBC
> Uppsala University
> Norbyv?gen 18D
> 75236 Uppsala, Sweden
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From r.turner at auckland.ac.nz  Wed Jun  3 00:54:19 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 3 Jun 2009 10:54:19 +1200
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
	and iteration
In-Reply-To: <4A2520D6.6080108@ebc.uu.se>
References: <4A2520D6.6080108@ebc.uu.se>
Message-ID: <822E44AA-73C9-4932-B34A-46A99EEB7CCE@auckland.ac.nz>


On 3/06/2009, at 12:53 AM, Paolo Innocenti wrote:

	<snip>

> Reading a bit of this mailing list, I came up with these three models:
>
> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>
> or
>
> m2 <- lmer(Y1 ~ sex + (sex|line))
>
> or
>
> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>
> Which should all be the same model (and indeed they have all the same
> residuals) but different parametrization (see self-contained example
> below).

	<snip>

	I don't think that the first two models are indeed the same model.

	My understanding --- which is very limited --- is that

		lmer(Y1 ~ sex + (1|line) + (1|sex:line))

	gives a model in which the effect of line j on sex 1 (say X_1j) and
	and the effect of line j on sex 2 (say X_2j) are uncorrelated.  I.e.
	X_1j and X_2j have covariance matrix of the form sigma^2 * I, where I
	is the 2 x 2 identity.  Thus one random effect parameter is  
contributed.

	In contrast,

		lmer(Y1 ~ sex + (sex|line))

	gives a model in which correlation between X_1j and X_2j, i.e. their
	covariance matrix is a ``general'' 2 x 2 positive definite matrix.
	Thus three random effect parameters are contributed.

	See

		http://www.nabble.com/lme-nesting-interaction-advice- 
td17131600i20.html#a17213604

	for the posting from Doug Bates upon which I am basing my  
understanding.

	Compare:

		lmer(score ~ Machine + (1|Worker/Machine), Machines)
	and

		lmer(score ~ Machine + (Machine|Worker), Machines)

	with your proposed models.

	I hope that I have not misinterpreted Prof. Bates' explanation.

		cheers,

			Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From bolker at ufl.edu  Wed Jun  3 03:23:14 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 02 Jun 2009 21:23:14 -0400
Subject: [R-sig-ME] extractor function for coefficient table from
	summary.mer ?
Message-ID: <4A25D082.4010608@ufl.edu>


  Request for comment: would it be reasonable to have the
"coef" method for "summary.mer" objects return the table
of parameter values, standard errors etc.?  This is parallel
to what (e.g.) coef does for summary.lm objects (in that
case by extracting the $coefficients element of the list) ...
I feel I should minimize my using of direct slot extraction
via @ ...

library(lme4)

setMethod("coef", signature(object = "summary.mer"), function(object)
object at coefs)

example(lmer)
ss <- summary(gm1)
coef(ss)

              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -1.3985351  0.2278906 -6.136871 8.416284e-10
period2     -0.9923347  0.3053852 -3.249452 1.156274e-03
period3     -1.1286754  0.3260491 -3.461673 5.368286e-04
period4     -1.5803739  0.4288037 -3.685542 2.282169e-04




-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From David.Duffy at qimr.edu.au  Wed Jun  3 05:05:11 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 3 Jun 2009 13:05:11 +1000 (EST)
Subject: [R-sig-ME] extractor function for coefficient table
 fromsummary.mer ?
In-Reply-To: <4A25D082.4010608@ufl.edu>
References: <4A25D082.4010608@ufl.edu>
Message-ID: <Pine.LNX.4.64.0906031304060.11415@orpheus.qimr.edu.au>

On Tue, 2 Jun 2009, Ben Bolker wrote:

>
>  Request for comment: would it be reasonable to have the
> "coef" method for "summary.mer" objects return the table
> of parameter values, standard errors etc.? 
>

Yes please, oh and a profile likelihood based confint.lmer() too,
thanks ;).

David Duffy.

--
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Kate.Pressland at bristol.ac.uk  Wed Jun  3 11:32:35 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Wed, 03 Jun 2009 10:32:35 +0100
Subject: [R-sig-ME] advice sought for double paired design
Message-ID: <5432C1F7B5462E6A8E7DC948@bio-mammal03.bio.bris.ac.uk>

Dear mixed modellers,

just want some opinions from those willing to share them - I have a design 
and wonder if mixed models could analyse it.

*I have 34 sites that are split into pairs of sites that do or do not 
receive a treatment. This means I have n=17 as the pairs are obviously not 
independent of each other.
*I surveyed information from them also _before_ and _after_ treatment was 
applied so each pair/site is also paired over time due to the repeat 
measurement. *With each survey 2 repeat measurements were taken 
simultaneously over 2 habitats.

I was wondering if this is a reasonable design to tackle with mixed models? 
I have researching matched pairs designs but they fail as there is the 
double pairing non-independence issue. I am interested in whether or not 
treatment affects y, and not how site A at time 1 is different to site A at 
time 2 - there is a seasonal issue so I know it will be different. 
Treatment is my key question, and if the 2 habitats are affected 
differently. My limited knowledge of mixed models tells me it is doable but 
I want to check with people that really know what they're talking about!

If in theory mixed models are suitable, would a design like this be 
appropriate or will it need to be a little more complex that this super 
simple model?
lmer(y~Treatment+Habitat+(1|Site)+(1|Treatment)+(1|Period)+(1|Time), data)

Any hints you could give me would be gratefully received.

Kate

-----------------------------------
Ph.D student and mixed model beginner



From andydolman at gmail.com  Wed Jun  3 13:46:22 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 3 Jun 2009 13:46:22 +0200
Subject: [R-sig-ME] advice sought for double paired design
In-Reply-To: <951234ac0906030444l61e23a4du8df0cbd4ac50f29b@mail.gmail.com>
References: <5432C1F7B5462E6A8E7DC948@bio-mammal03.bio.bris.ac.uk>
	<951234ac0906030444l61e23a4du8df0cbd4ac50f29b@mail.gmail.com>
Message-ID: <951234ac0906030446t33f9a80ia8b9fc269df093c5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090603/5c14a881/attachment.pl>

From Christine.Griffiths at bristol.ac.uk  Wed Jun  3 12:05:28 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Wed, 03 Jun 2009 11:05:28 +0100
Subject: [R-sig-ME] zero variance query
In-Reply-To: <1243966076.5208.26.camel@yod>
References: <AEB1645F39784310A23C16E6@bio-mammal026.bio.bris.ac.uk>
	<1243897656.11231.14.camel@yod> <4A2499CD.2070906@ufl.edu>
	<F09E2CE4AA38D4D95DD43A2C@bio-mammal026.bio.bris.ac.uk>
	<1243966076.5208.26.camel@yod>
Message-ID: <28CC50195644684E61D3B751@bio-mammal026.bio.bris.ac.uk>

Dear All

Thank you for all your incredibly helpful advice. Having done as suggested 
by Emmanuel, I have come to the conclusion that there is basically very 
little variation among my data, which is perhaps not surprising given that 
I have a small count range 0-9. I was just concerned that such low variance 
meant that there was something wrong with my analysis.

Emmanuel, logging my data does not improve the distribution and so I think 
I cannot use Gaussian errors. I have a large number of zeros. These are off 
biological significance and so I am interested in retaining them in the 
model.

Since Anna mentioned that quasi models are unstable in lme4, would you 
recommend using poisson models and calculating QAIC instead?

Many thanks
Christine


--On 02 June 2009 20:07 +0200 Emmanuel Charpentier 
<charpent at bacbuc.dyndns.org> wrote:

> Le mardi 02 juin 2009 ? 10:45 +0100, Christine Griffiths a ?crit :
>> Dear Emmanuel and Ben
>>
>> Many thanks for your advice. Unfortunately, I don't think that I can
>> offset  with log(area), given that each area is the same. My rationale
>> for  converting to m2 was to standardise abundances to 1 m2 as I have
>> other  parameters which were measured to different areas. I had
>> previously  attempted to normalise my data by logging but felt that it
>> did not improve  the distribution. I just hadn't tried it in my
>> modelling. Logging my count  data dramatically improved the fit of the
>> model (AIC 116.7 v 312.5),  however the variance still remains low. Does
>> this appear acceptable? Furthermore, can I assess model fit of different
>> transformations of the  same dataset using AIC values, i.e. compare
>> log(Count) and inverse  transformed Count?
>>
>> lncount<-log(Count+1)
>> m1<-m1<-lmer(lncount~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>
> Aaargh ! I thought that "lmer(lncount~Treatment+(1|Month)+(1|
> Block),family=gaussian)" (+/- log(area somewhere in the model or the
> fit) might give good hints as a first (known bad) approximation, and
> didn't made myself clear. That's what happens when you try to be
> sarcastic while dog-tired...
>
> And maybe your random effects *are* quite low. What happens with :
> summary(glm(Count~Treatment+Month+Block, family=quasipoisson) (or
> something to that effect) ? What says a simple crosstabulation ? or a
> graph ("caterpillar", for example) ?
>
> HTH,
>
> 					Emmanuel Charpentier
>
>
>> summary(m1)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: lncount ~ Treatment + (1 | Month) + (1 | Block)
>>    AIC   BIC logLik deviance
>>  116.7 135.1 -52.33    104.7
>> Random effects:
>>  Groups   Name        Variance   Std.Dev.
>>  Month    (Intercept) 1.8937e-14 1.3761e-07
>>  Block    (Intercept) 3.5018e-02 1.8713e-01
>>  Residual             3.9318e-01 6.2704e-01
>> Number of obs: 160, groups: Month, 10; Block, 6
>>
>> Fixed effects:
>>                    Estimate Std. Error t value
>> (Intercept)         -0.4004     0.1239  -3.232
>> Treatment2.Radiata   0.4596     0.1305   3.522
>> Treatment3.Aldabra   0.4295     0.1334   3.220
>>
>> Correlation of Fixed Effects:
>>             (Intr) Trt2.R
>> Trtmnt2.Rdt -0.581
>> Trtmnt3.Ald -0.577  0.530
>>
>> I used quasipoisson as my data is overdispersed. It was further improved
>> by  an inverse transformation (AIC 43.54). Again I have small variances.
>>
>> invcount<-1/(Count+1)
>> m3<-lmer(invcount~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>> summary(m3)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: invcount ~ Treatment + (1 | Month) + (1 | Block)
>>    AIC BIC logLik deviance
>>  43.54  62 -15.77    31.54
>> Random effects:
>>  Groups   Name        Variance  Std.Dev.
>>  Month    (Intercept) 0.0000000 0.000000
>>  Block    (Intercept) 0.0021038 0.045867
>>  Residual             0.0926225 0.304339
>> Number of obs: 160, groups: Month, 10; Block, 6
>>
>> Fixed effects:
>>                    Estimate Std. Error t value
>> (Intercept)        -0.51644    0.05411  -9.545
>> Treatment2.Radiata -0.36246    0.08401  -4.314
>> Treatment3.Aldabra -0.29319    0.08197  -3.577
>>
>> Correlation of Fixed Effects:
>>             (Intr) Trt2.R
>> Trtmnt2.Rdt -0.566
>> Trtmnt3.Ald -0.580  0.372
>>
>> Log(Abundance) did not solve the problem of zero variance. If
>> quasipoisson  errors are not acceptable to use with abundance, i.e.
>> non-integers, is  there a family of errors that would be recommended? Or
>> should I simply  multiply abundance to obtain whole numbers?
>>
>> Many thanks in advance,
>> Christine
>>
>>
>> --On 01 June 2009 23:17 -0400 Ben Bolker
>> <bolker-hnhdhkBXzx8 at public.gmane.org> wrote:
>>
>> > Emmanuel Charpentier wrote:
>> >> Le lundi 01 juin 2009 ? 18:00 +0100, Christine Griffiths a ?crit :
>> >>> Dear R users,
>> >>>
>> >>> I am having a problem with getting zero variance in my lmer models
>> >>> which  specify two random effects. Having scoured the help lists, I
>> >>> have read that  this could be because my variables are strongly
>> >>> correlated. However, when I  simplify my model I still encounter the
>> >>> same problem.
>> >>>
>> >>> My response variable is abundance which ranges from 0-0.14.
>> >>>
>> >>> Below is an example of my model:
>> >>>> m1<-lmer(Abundance~Treatment+(1|Month)+(1|Block),family=quasipoisso
>> >>>> n) summary(m1)
>> >>> Generalized linear mixed model fit by the Laplace approximation
>> >>> Formula: Abundance ~ Treatment + (1 | Month) + (1 | Block)
>> >>>    AIC   BIC logLik deviance
>> >>>  17.55 36.00 -2.777    5.554
>> >>> Random effects:
>> >>>  Groups   Name        Variance   Std.Dev.
>> >>>  Month    (Intercept) 5.1704e-17 7.1906e-09
>> >>>  Block    (Intercept) 0.0000e+00 0.0000e+00
>> >>>  Residual             1.0695e-03 3.2704e-02
>> >>> Number of obs: 160, groups: Month, 10; Block, 6
>> >>>
>> >>> Fixed effects:
>> >>>                    Estimate Std. Error t value
>> >>> (Intercept)        -3.73144    0.02728 -136.80
>> >>> Treatment2.Radiata  0.58779    0.03521   16.69
>> >>> Treatment3.Aldabra  0.47269    0.03606   13.11
>> >>>
>> >>> Correlation of Fixed Effects:
>> >>>             (Intr) Trt2.R
>> >>> Trtmnt2.Rdt -0.775
>> >>> Trtmnt3.Ald -0.756  0.586
>> >>>
>> >>> 1. Is it wrong to treat this as count data?
>> >>
>> >> Hmmm... IST vaguely R that, when the world was young and I was
>> >> (already) silly, Poisson distribution used to be a *discrete*
>> >> distribution. Of course, this may or may not stand for "quasi"Poisson
>> >> (for some value of "quasi").
>> >>
>> >> May I inquire if you tried to analyze log(Abundance) (or log(Count),
>> >> maybe including log(area) in the model) ?
>> >>
>> >> HTH,
>> >>
>> >> 					Emmanuel Charpentier
>> >>
>> >>> 2. I would like to retain these as random factors given that I
>> >>> designed my  experiment as a randomised block design and repeated
>> >>> measures, albeit  non-orthogonal and unbalanced. Is it acceptable to
>> >>> retain these random  factors, is all else is correct?
>> >
>> >    I think so ...
>> >
>> >>> 3. The above response variable was calculated per m2 by dividing the
>> >>> Count  by the sample area. When I used the Count (range 0-9) as my
>> >>> response  variable, I get a small but reasonable variation of random
>> >>> effects. Could  anyone explain why this occurs and whether one
>> >>> response variable is better  than another?
>> >
>> >   To agree with what Emmanuel said above: you should use Count~...,
>> > offset=log(area) for the correct analysis ...  that should solve
>> > both your technical (zero random effects) and conceptual (even
>> > quasiPoisson should be discrete data) issues.
>> >
>> >>>
>> >>>> m2<-lmer(Count~Treatment+(1|Month)+(1|Block),family=quasipoisson)
>> >>>> summary(m2)
>> >>> Generalized linear mixed model fit by the Laplace approximation
>> >>> Formula: Count ~ Treatment + (1 | Month) + (1 | Block)
>> >>>    AIC BIC logLik deviance
>> >>>  312.5 331 -150.3    300.5
>> >>> Random effects:
>> >>>  Groups   Name        Variance Std.Dev.
>> >>>  Month    (Intercept) 0.14591  0.38198
>> >>>  Block    (Intercept) 0.58690  0.76609
>> >>>  Residual             2.79816  1.67277
>> >>> Number of obs: 160, groups: Month, 10; Block, 6
>> >>>
>> >>> Fixed effects:
>> >>>                    Estimate Std. Error t value
>> >>> (Intercept)          0.3098     0.3799  0.8155
>> >>> Treatment2.Radiata   0.5879     0.2299  2.5575
>> >>> Treatment3.Aldabra   0.5745     0.2382  2.4117
>> >>>
>> >>> Correlation of Fixed Effects:
>> >>>             (Intr) Trt2.R
>> >>> Trtmnt2.Rdt -0.347
>> >>> Trtmnt3.Ald -0.348  0.536
>> >>>
>> >>> Many thanks,
>> >>> Christine
>> >>>
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>> > --
>> > Ben Bolker
>> > Associate professor, Biology Dep't, Univ. of Florida
>> > bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> > GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> ----------------------
>> Christine Griffiths
>> School of Biological Sciences
>> University of Bristol
>> Woodland Road
>> Bristol BS8 1UG
>> Tel: 0117 9287593
>> Fax 0117 925 7374
>> Christine.Griffiths at bristol.ac.uk
>> http://www.bio.bris.ac.uk/research/mammal/tortoises.html
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
Christine Griffiths
School of Biological Sciences
University of Bristol
Woodland Road
Bristol BS8 1UG
Tel: 0117 9287593
Fax 0117 925 7374
Christine.Griffiths at bristol.ac.uk
http://www.bio.bris.ac.uk/research/mammal/tortoises.html



From bates at stat.wisc.edu  Wed Jun  3 15:32:40 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Jun 2009 08:32:40 -0500
Subject: [R-sig-ME] extractor function for coefficient table from
	summary.mer ?
In-Reply-To: <4A25D082.4010608@ufl.edu>
References: <4A25D082.4010608@ufl.edu>
Message-ID: <40e66e0b0906030632i5cfc701ejc69ca4a6932a6266@mail.gmail.com>

On Tue, Jun 2, 2009 at 8:23 PM, Ben Bolker <bolker at ufl.edu> wrote:

> ?Request for comment: would it be reasonable to have the
> "coef" method for "summary.mer" objects return the table
> of parameter values, standard errors etc.? ?This is parallel
> to what (e.g.) coef does for summary.lm objects (in that
> case by extracting the $coefficients element of the list) ...
> I feel I should minimize my using of direct slot extraction
> via @ ...

Very good idea thanks.  I will add it to the next release.

> library(lme4)
>
> setMethod("coef", signature(object = "summary.mer"), function(object)
> object at coefs)
>
> example(lmer)
> ss <- summary(gm1)
> coef(ss)
>
> ? ? ? ? ? ? ?Estimate Std. Error ? z value ? ? Pr(>|z|)
> (Intercept) -1.3985351 ?0.2278906 -6.136871 8.416284e-10
> period2 ? ? -0.9923347 ?0.3053852 -3.249452 1.156274e-03
> period3 ? ? -1.1286754 ?0.3260491 -3.461673 5.368286e-04
> period4 ? ? -1.5803739 ?0.4288037 -3.685542 2.282169e-04
>
>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Kate.Pressland at bristol.ac.uk  Wed Jun  3 16:06:07 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Wed, 03 Jun 2009 15:06:07 +0100
Subject: [R-sig-ME] advice sought for double paired design
In-Reply-To: <951234ac0906030446t33f9a80ia8b9fc269df093c5@mail.gmail.com>
References: <5432C1F7B5462E6A8E7DC948@bio-mammal03.bio.bris.ac.uk>	
	<951234ac0906030444l61e23a4du8df0cbd4ac50f29b@mail.gmail.com>
	<951234ac0906030446t33f9a80ia8b9fc269df093c5@mail.gmail.com>
Message-ID: <BCEB6C80829D6B31C8A836B5@bio-mammal03.bio.bris.ac.uk>

Ah yes you're right, I didn't give much information. I realise also I wrote 
this incorrectly.

So, my data is as such:

34 SITES in 17 pairs - paired 'treatment' and 'no treatment', spatially 
close, same site type etc (TREATMENT=0,1, PAIR=1 to 17)
Pre and post treatment surveying (PERIOD=1,2)
2 repeat surveys each time (TRANSECT=1,2)
2 habitats surveyed (HABITAT=1,2)
y is continuous

BACIP - that sounds the just the ticket.

> Therefore you're interested in how y varies between Period 1 and 2
> (before and after), and how Treatment interacts with this, and how the
> treatment interaction varies by habitat.

This is exactly what I'm after.

> Your full model would be something like this:
>
> lmer(y~Period*Treatment*Habitat+Time+(1|Site), data)
>
> or perhaps this:
>
> lmer(y~Period*Treatment*Habitat+Time+(1|Pair), data)

I made an error here - TIME isn't needed. SITES were surveyed over 6 weeks 
for each PERIOD. I could put week/day in as a factor if I think it will be 
important I suppose, but seeing as the members of each pair were surveyed 
simultaneously it may be pointless. I have covariates of weather that 
should help sort out temporal issues too.

Each SITE itself is measured more than once so would I need to include that 
in the random effects, or is it accounted for by the combination of 
TREATMENT and PAIR (Site 1 = treatment (0), pair (1): each combination is 
unique). Am I essentially saying the same thing by having PAIR and SITE as 
random effects? Like so:

lmer(y~Period*Treatment*Habitat+(1|Pair)+(1|Site), data)

What about the TRANSECT repeat? Is it easier to just sum this information 
and ignore the variable altogether, or have it as an additional random 
effect therefore quantifying the variation here too?

lmer(y~Period*Treatment*Habitat+(1|Pair)+(1|Transect), data)

Great to know that I can use a mixed model for this analysis. I've been 
using lme4 for a little while now and it is a highly useful package (much 
thanks to Douglas Bates and Martin Maechler for providing this for us all!).

Kate

--On 03 June 2009 13:46 +0200 Andrew Dolman <andydolman at gmail.com> wrote:

>
>
> Hi Kate,
>
> It's a little difficult to know your data structure from your
> description, it's always helpful to include a sample of the data, or a
> dummy data set with the same structure.
>
>
>> lmer(y~Treatment+Habitat+(1|Site)+(1|Treatment)+(1|Period)+(1|Time),
>> data)
>
> Your Treatment variable presumably has only 2 levels, treated and
> untreated? It's not a good idea to include random effects with fewer that
> 4-5 levels because the model will be attempting to estimate the variance
> across those levels. In any case, Treatment is in no way "random" here.
>
> Likewise, Time and Period both have just 2 levels right?
>
> Period represents before and after treatment? And Time is the two seasons
> in which you measured whatever you measured?
>
> And at each Site you have 2 Habitats?
>
> And your 34 Sites are paired with 1 Site in each pair treated?
>
>
> It sounds like you have a kind of before-and-after-control-impact-pair
> setup BACIP.
>
> You probably want to add a variable, Pair, assuming that your Sites were
> really pairs in a meaningful way (like close together in space relative
> to the other pairs).
>
>
> Therefore you're interested in how y varies between Period 1 and 2
> (before and after), and how Treatment interacts with this, and how the
> treatment interaction varies by habitat.
>
> Your full model would be something like this:
>
> lmer(y~Period*Treatment*Habitat+Time+(1|Site), data)
>
> or perhaps this:
>
> lmer(y~Period*Treatment*Habitat+Time+(1|Pair), data)
>
> ?
>
> Andy.
>
>
>
>
> andydolman at gmail.com
>
>
>
> 2009/6/3 CL Pressland <Kate.Pressland at bristol.ac.uk>
>
>
>
>
> Dear mixed modellers,
>
> just want some opinions from those willing to share them - I have a
> design and wonder if mixed models could analyse it.
>
> *I have 34 sites that are split into pairs of sites that do or do not
> receive a treatment. This means I have n=17 as the pairs are obviously
> not independent of each other.
> *I surveyed information from them also _before_ and _after_ treatment was
> applied so each pair/site is also paired over time due to the repeat
> measurement. *With each survey 2 repeat measurements were taken
> simultaneously over 2 habitats.
>
> I was wondering if this is a reasonable design to tackle with mixed
> models? I have researching matched pairs designs but they fail as there
> is the double pairing non-independence issue. I am interested in whether
> or not treatment affects y, and not how site A at time 1 is different to
> site A at time 2 - there is a seasonal issue so I know it will be
> different. Treatment is my key question, and if the 2 habitats are
> affected differently. My limited knowledge of mixed models tells me it is
> doable but I want to check with people that really know what they're
> talking about!
>
> If in theory mixed models are suitable, would a design like this be
> appropriate or will it need to be a little more complex that this super
> simple model?
> lmer(y~Treatment+Habitat+(1|Site)+(1|Treatment)+(1|Period)+(1|Time), data)
>
> Any hints you could give me would be gratefully received.
>
> Kate
>
> -----------------------------------
> Ph.D student and mixed model beginner
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



----------------------
Kate Pressland
Office D95
School of Biological Sciences
University of Bristol
Woodland Road
Bristol, BS8 1UG
Tel: 0117 9288918 (Internal 88918)
Kate.Pressland at bristol.ac.uk
www.bio.bris.ac.uk/people/staff.cfm?key=1137



From arild.husby at ed.ac.uk  Wed Jun  3 16:48:56 2009
From: arild.husby at ed.ac.uk (Arild Husby)
Date: Wed, 03 Jun 2009 15:48:56 +0100
Subject: [R-sig-ME] how to extract all information from fitted object in a
	lme model
Message-ID: <4A268D58.1000004@ed.ac.uk>

Dear list,

I would like your help on how to extract the fitted values from a lme 
object.

For example, the following code will return the fitted values from a lme 
object in the Orthodont dataset (n=108, one for each age/subject 
combination):

library(nlme)
fm1 <- lme(distance ~ age, data = Orthodont)
fitted(fm1)

However, I do not manage to extract each observations fitted value 
together with its subject id (I can easily extract the values 
themselves, using fittted(fm1)[[1]], but not the subject level 
associated with the values!). Is there some way to get these into, say, 
a dataframe with dimensions 108,2 looking like below:

Subject   fitted_values
M01         24.81...
M01         26.57..
.
.
M02        
etc.

I would like to extract these values and then match them to the subject 
in the dataset using something like:

Orthodont$fitvalues <- match(Orthodont$Subject,matrix$fitted_values)

Probably need to match on both age and Subject code somehow, but age is 
not in the fitted output, but presumably in the right order as in 
dataset so might be possible to do this??

If this is a trivial question, or I have misunderstood some concepts, 
please feel free to point me to relevant literature.

Many thanks for your help,
Arild

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bates at stat.wisc.edu  Wed Jun  3 17:18:10 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Jun 2009 10:18:10 -0500
Subject: [R-sig-ME] how to extract all information from fitted object in
	a lme model
In-Reply-To: <4A268D58.1000004@ed.ac.uk>
References: <4A268D58.1000004@ed.ac.uk>
Message-ID: <40e66e0b0906030818i794637f1hb8eeeaebd74f06eb@mail.gmail.com>

On Wed, Jun 3, 2009 at 9:48 AM, Arild Husby <arild.husby at ed.ac.uk> wrote:
> Dear list,
>
> I would like your help on how to extract the fitted values from a lme
> object.
>
> For example, the following code will return the fitted values from a lme
> object in the Orthodont dataset (n=108, one for each age/subject
> combination):
>
> library(nlme)
> fm1 <- lme(distance ~ age, data = Orthodont)
> fitted(fm1)
>
> However, I do not manage to extract each observations fitted value together
> with its subject id (I can easily extract the values themselves, using
> fittted(fm1)[[1]], but not the subject level associated with the values!).
> Is there some way to get these into, say, a dataframe with dimensions 108,2
> looking like below:
>
> Subject ? fitted_values
> M01 ? ? ? ? 24.81...
> M01 ? ? ? ? 26.57..
> .
> .
> M02 ? ? ? ?etc.
>
> I would like to extract these values and then match them to the subject in
> the dataset using something like:

I think I would use

cbind(getData(fm1), .fitted = fitted(fm1))

to do that.  I think that will handle cases of, say, a missing value
in the original data frame correctly.

> Orthodont$fitvalues <- match(Orthodont$Subject,matrix$fitted_values)
>
> Probably need to match on both age and Subject code somehow, but age is not
> in the fitted output, but presumably in the right order as in dataset so
> might be possible to do this??
>
> If this is a trivial question, or I have misunderstood some concepts, please
> feel free to point me to relevant literature.
>
> Many thanks for your help,
> Arild
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andydolman at gmail.com  Wed Jun  3 17:18:54 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 3 Jun 2009 17:18:54 +0200
Subject: [R-sig-ME] advice sought for double paired design
In-Reply-To: <BCEB6C80829D6B31C8A836B5@bio-mammal03.bio.bris.ac.uk>
References: <5432C1F7B5462E6A8E7DC948@bio-mammal03.bio.bris.ac.uk>
	<951234ac0906030444l61e23a4du8df0cbd4ac50f29b@mail.gmail.com>
	<951234ac0906030446t33f9a80ia8b9fc269df093c5@mail.gmail.com>
	<BCEB6C80829D6B31C8A836B5@bio-mammal03.bio.bris.ac.uk>
Message-ID: <951234ac0906030818y49d5aae3u3292458820ffb683@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090603/e98fde7e/attachment.pl>

From steibelj at msu.edu  Wed Jun  3 19:04:55 2009
From: steibelj at msu.edu (Juan Pedro Steibel)
Date: Wed, 03 Jun 2009 13:04:55 -0400
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
 and	iteration
In-Reply-To: <4A2520D6.6080108@ebc.uu.se>
References: <4A2520D6.6080108@ebc.uu.se>
Message-ID: <4A26AD37.4040802@msu.edu>

Hello Paolo,
We are also starting to use lmer for gene expression analysis (genetical 
genomics too) so here are my thoughts.

Having two equivalent parameterizations, I would go with the 
computationally fastest one (a couple more miliseconds per model, easily 
add up to many hours when analyzing highly dimensional datasets). You 
can time the analysis for, say, 100 transcripts and go from there.

~note: other users commented on your models not being equivalent~

For p-values:

You could use LRT to test for variance components.

This is standard practice in genetic epidemiology: fit a model with and 
without the random effect in question, then compare the log (residual) 
likelihood ratio to a chi-square statistic. FDR can be used on top of 
that to account for multiple tests. Of course, now you have to fit three 
models (one null models for each VC), so your cpu  time has just 
multiplied by almost 3. Definitely using refit and update will help with 
compute time when having so many models.

I use sobj<-summary(result) as an intermediate step to get the info 
(although this may add to the computational burden and other suggestions 
you got may be faster and more efficient),

then ask for slots:
@REmat
@coefs
...for getting estimates of variance components and fixed effects.

@coefs gives you a t-statistic for fixed effects too... you could take a 
stab at an approximated df method and compute an (approximated) p-value.
I know that doing so can attract a lot of criticism in this list, but 
when you are fitting a several million models (10000s of transcripts and 
1000s of genomic positions as in my case), the mcmc approximation is 
(unfortunately) not computationally feasible.


Hope this helps!
JP



Paolo Innocenti wrote:
> Dear Douglas and list,
>
> I am thinking about fitting a mixed model for a microarray experiment 
> using lme4, since other specific software seems not suitable for my 
> purposes. I'll briefly describe the model and kindly ask for 
> suggestions on the model and the workflow I can use to get useful 
> results.
>
> My response variable Y is gene expression levels for a given gene (say 
> g_i) from 120 samples.
> The factor I want to include are:
>
> Sex: fixed, two levels, M/F.
> Line: 15 randomly picked genotypes from a large outbred population.
>
> I am interested in:
> - if the gene is differentially expressed in the 2 sexes (effect of 
> sex), in the 15 lines (effect of line) and the interaction of the two.
>
> - the variance component of line = how much of the variance is due to 
> the genotype
>
> - the variance component of the interaction = the genetic variation 
> for sexual dimorphism.
>
> Reading a bit of this mailing list, I came up with these three models:
>
> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>
> or
>
> m2 <- lmer(Y1 ~ sex + (sex|line))
>
> or
>
> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>
> Which should all be the same model (and indeed they have all the same 
> residuals) but different parametrization (see self-contained example 
> below).
>
> Now, in the light of my needs (see above), which model makes it easier 
> to extract the components I need? Also, do they make different 
> assumptions - as different levels of independency among levels of 
> random factors?
>
> I will need to be able to extract the variance component values in an 
> iterative process (i have 18.000 genes): is VarCorr() the way to go?
>
> VarCorr(m1)$'sex:line'[1]
> VarCorr(m1)$'line'[1]
>
> Last two question: what is the easier way to assess, in an iterative 
> process, normality of residuals, and what is a sensible way to assess 
> significant differential expression of genes (since I guess I can't 
> get p-values and then apply FDR correction?)
>
> Thanks a lot for reading so far and I'll be grateful for any kind of 
> help.
> paolo
>
> Self-contained example:
>
> Y1 <- as.numeric(
> c("11.6625","11.3243","11.7819","11.5032","11.7578","11.9379","11.8491",
> "11.9035","11.2042","11.0344","11.5137","11.1995","11.6327","11.7392",
> "11.9869","11.6955","11.5631","11.7159","11.8435","11.5814","12.0756",
> "12.3428","12.3342","11.9883","11.6067","11.6102","11.6517","11.4444",
> "11.9567","12.0478","11.9683","11.8207","11.5860","11.6028","11.6522",
> "11.6775","12.3570","12.2266","12.2444","12.1369","11.2573","11.4577",
> "11.4432","11.2994","11.8486","11.9258","11.9864","11.9964","11.2806",
> "11.2527","11.3672","11.0791","11.9501","11.7223","11.9825","11.8114",
> "11.6116","11.4284","11.3731","11.6942","12.2153","12.0101","12.2150",
> "12.1932","11.5617","11.3761","11.4813","11.7503","11.9889","12.1530",
> "12.3299","12.4436","11.4566","11.4614","11.5527","11.3513","11.9764",
> "11.8810","12.0999","11.9083","11.4870","11.6764","11.3973","11.4507",
> "12.1141","11.9906","12.1118","11.9728","11.3382","11.4146","11.4590",
> "11.2527","12.1101","12.0448","12.2191","11.8317","11.3982","11.3555",
> "11.3897","11.7731","11.9749","11.8666","12.1984","12.0350","11.4642",
> "11.4509","11.5552","11.4346","12.0714","11.7136","11.9019","11.8158",
> "11.3132","11.3121","11.1612","11.2073","11.6658","11.7879","11.7847",
> "11.5300"))
> sex <- factor(rep(c("F","M"), 15, each=4))
> line <- factor(rep(1:15, each=8))
> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
> m2 <- lmer(Y1 ~ sex + (sex|line))
> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
> VarCorr(m1)$'sex:line'[1]
> VarCorr(m1)$'line'[1]
>
> Output:
>
>>> m1
>> Linear mixed model fit by REML Formula: Y1 ~ sex + (1 | line) + (1 | 
>> sex:line)     AIC   BIC logLik deviance REMLdev
>>  -91.13 -77.2  50.57   -111.1  -101.1
>> Random effects:
>>  Groups   Name        Variance  Std.Dev.
>>  sex:line (Intercept) 0.0023237 0.048205
>>  line     (Intercept) 0.0169393 0.130151
>>  Residual             0.0168238 0.129707
>> Number of obs: 120, groups: sex:line, 30; line, 15
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept) 11.45977    0.03955  289.72
>> sexM         0.52992    0.02951   17.96
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> sexM -0.373
>>> m2
>> Linear mixed model fit by REML Formula: Y1 ~ sex + (sex | line) 
>>  AIC    BIC logLik deviance REMLdev
>>  -90 -73.27     51   -112.1    -102
>> Random effects:
>>  Groups   Name        Variance  Std.Dev. Corr   line     (Intercept) 
>> 0.0152993 0.123691                 sexM        0.0046474 0.068172 
>> 0.194  Residual             0.0168238 0.129707       Number of obs: 
>> 120, groups: line, 15
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept) 11.45977    0.03606   317.8
>> sexM         0.52992    0.02951    18.0
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> sexM -0.161
>>> m3
>> Linear mixed model fit by REML Formula: Y1 ~ sex + (0 + sex | line) 
>>  AIC    BIC logLik deviance REMLdev
>>  -90 -73.27     51   -112.1    -102
>> Random effects:
>>  Groups   Name Variance Std.Dev. Corr   line     sexF 0.015299 
>> 0.12369                  sexM 0.023227 0.15240  0.899  Residual      
>> 0.016824 0.12971        Number of obs: 120, groups: line, 15
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept) 11.45977    0.03606   317.8
>> sexM         0.52991    0.02951    18.0
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> sexM -0.161
>
>
>


-- 
=============================
Juan Pedro Steibel

Assistant Professor
Statistical Genetics and Genomics

Department of Animal Science & 
Department of Fisheries and Wildlife

Michigan State University
1205-I Anthony Hall
East Lansing, MI
48824 USA 

Phone: 1-517-353-5102
E-mail: steibelj at msu.edu



From paolo.innocenti at ebc.uu.se  Thu Jun  4 09:56:12 2009
From: paolo.innocenti at ebc.uu.se (Paolo Innocenti)
Date: Thu, 04 Jun 2009 09:56:12 +0200
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
 and	iteration
In-Reply-To: <4A26AD37.4040802@msu.edu>
References: <4A2520D6.6080108@ebc.uu.se> <4A26AD37.4040802@msu.edu>
Message-ID: <4A277E1C.5020604@ebc.uu.se>

Dear Douglas, Rolf, Juan and list,

thank you very much for your replies.
I now got a good working model, and the use of refit and VarCorr will 
definitely help.

I had a go with mcmcsamp(), and I must confirm that this approach is not 
feasible, both computationally and because if you get a "false 
convergence" for, say, 1 gene out of 20, it becomes impossible to go 
back and fix all the errors.

So, the alternative approach seems more promising. If I understand 
correctly, you suggest to calculate a p-value for random effects out of 
the LRT (Likelihood ratio test), and use approximated DFs to calculate 
standard p-values for the fixed effects.

I neved used this approach, so I appreciate if you can point me in the 
right direction.

Random effects:
I'd need to compare the this three model:
m1a <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
m1b <- lmer(Y1 ~ sex + (1|line))
m1c <- lmer(Y1 ~ sex)

and get the effect of the interaction from m1a-m1b,
and the effect of "line" from m1b-m1c.
It that correct?
Can anyone point me to any kind of documentation/examples to sort out 
the details?

Fixed effects:
I don't really know where to get the approximated degrees of freedom. 
Can you point me to an example?

Thanks again for all the help. Eventually, I'll be really happy to share 
my experience/code when everything is sorted, even if I doubt I can add 
anything helpful.

Best,
paolo

PS. I don't really understand what you mean by
sobj<-summary(result)
what object is your "result" here?




Juan Pedro Steibel wrote:
> Hello Paolo,
> We are also starting to use lmer for gene expression analysis (genetical 
> genomics too) so here are my thoughts.
> 
> Having two equivalent parameterizations, I would go with the 
> computationally fastest one (a couple more miliseconds per model, easily 
> add up to many hours when analyzing highly dimensional datasets). You 
> can time the analysis for, say, 100 transcripts and go from there.
> 
> ~note: other users commented on your models not being equivalent~
> 
> For p-values:
> 
> You could use LRT to test for variance components.
> 
> This is standard practice in genetic epidemiology: fit a model with and 
> without the random effect in question, then compare the log (residual) 
> likelihood ratio to a chi-square statistic. FDR can be used on top of 
> that to account for multiple tests. Of course, now you have to fit three 
> models (one null models for each VC), so your cpu  time has just 
> multiplied by almost 3. Definitely using refit and update will help with 
> compute time when having so many models.
> 
> I use sobj<-summary(result) as an intermediate step to get the info 
> (although this may add to the computational burden and other suggestions 
> you got may be faster and more efficient),
> 
> then ask for slots:
> @REmat
> @coefs
> ...for getting estimates of variance components and fixed effects.
> 
> @coefs gives you a t-statistic for fixed effects too... you could take a 
> stab at an approximated df method and compute an (approximated) p-value.
> I know that doing so can attract a lot of criticism in this list, but 
> when you are fitting a several million models (10000s of transcripts and 
> 1000s of genomic positions as in my case), the mcmc approximation is 
> (unfortunately) not computationally feasible.
> 
> 
> Hope this helps!
> JP
> 
> 
> 
> Paolo Innocenti wrote:
>> Dear Douglas and list,
>>
>> I am thinking about fitting a mixed model for a microarray experiment 
>> using lme4, since other specific software seems not suitable for my 
>> purposes. I'll briefly describe the model and kindly ask for 
>> suggestions on the model and the workflow I can use to get useful 
>> results.
>>
>> My response variable Y is gene expression levels for a given gene (say 
>> g_i) from 120 samples.
>> The factor I want to include are:
>>
>> Sex: fixed, two levels, M/F.
>> Line: 15 randomly picked genotypes from a large outbred population.
>>
>> I am interested in:
>> - if the gene is differentially expressed in the 2 sexes (effect of 
>> sex), in the 15 lines (effect of line) and the interaction of the two.
>>
>> - the variance component of line = how much of the variance is due to 
>> the genotype
>>
>> - the variance component of the interaction = the genetic variation 
>> for sexual dimorphism.
>>
>> Reading a bit of this mailing list, I came up with these three models:
>>
>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>>
>> or
>>
>> m2 <- lmer(Y1 ~ sex + (sex|line))
>>
>> or
>>
>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>>
>> Which should all be the same model (and indeed they have all the same 
>> residuals) but different parametrization (see self-contained example 
>> below).
>>
>> Now, in the light of my needs (see above), which model makes it easier 
>> to extract the components I need? Also, do they make different 
>> assumptions - as different levels of independency among levels of 
>> random factors?
>>
>> I will need to be able to extract the variance component values in an 
>> iterative process (i have 18.000 genes): is VarCorr() the way to go?
>>
>> VarCorr(m1)$'sex:line'[1]
>> VarCorr(m1)$'line'[1]
>>
>> Last two question: what is the easier way to assess, in an iterative 
>> process, normality of residuals, and what is a sensible way to assess 
>> significant differential expression of genes (since I guess I can't 
>> get p-values and then apply FDR correction?)
>>
>> Thanks a lot for reading so far and I'll be grateful for any kind of 
>> help.
>> paolo
>>
>> Self-contained example:
>>
>> Y1 <- as.numeric(
>> c("11.6625","11.3243","11.7819","11.5032","11.7578","11.9379","11.8491",
>> "11.9035","11.2042","11.0344","11.5137","11.1995","11.6327","11.7392",
>> "11.9869","11.6955","11.5631","11.7159","11.8435","11.5814","12.0756",
>> "12.3428","12.3342","11.9883","11.6067","11.6102","11.6517","11.4444",
>> "11.9567","12.0478","11.9683","11.8207","11.5860","11.6028","11.6522",
>> "11.6775","12.3570","12.2266","12.2444","12.1369","11.2573","11.4577",
>> "11.4432","11.2994","11.8486","11.9258","11.9864","11.9964","11.2806",
>> "11.2527","11.3672","11.0791","11.9501","11.7223","11.9825","11.8114",
>> "11.6116","11.4284","11.3731","11.6942","12.2153","12.0101","12.2150",
>> "12.1932","11.5617","11.3761","11.4813","11.7503","11.9889","12.1530",
>> "12.3299","12.4436","11.4566","11.4614","11.5527","11.3513","11.9764",
>> "11.8810","12.0999","11.9083","11.4870","11.6764","11.3973","11.4507",
>> "12.1141","11.9906","12.1118","11.9728","11.3382","11.4146","11.4590",
>> "11.2527","12.1101","12.0448","12.2191","11.8317","11.3982","11.3555",
>> "11.3897","11.7731","11.9749","11.8666","12.1984","12.0350","11.4642",
>> "11.4509","11.5552","11.4346","12.0714","11.7136","11.9019","11.8158",
>> "11.3132","11.3121","11.1612","11.2073","11.6658","11.7879","11.7847",
>> "11.5300"))
>> sex <- factor(rep(c("F","M"), 15, each=4))
>> line <- factor(rep(1:15, each=8))
>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>> m2 <- lmer(Y1 ~ sex + (sex|line))
>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>> VarCorr(m1)$'sex:line'[1]
>> VarCorr(m1)$'line'[1]
>>
>> Output:
>>
>>>> m1
>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (1 | line) + (1 | 
>>> sex:line)     AIC   BIC logLik deviance REMLdev
>>>  -91.13 -77.2  50.57   -111.1  -101.1
>>> Random effects:
>>>  Groups   Name        Variance  Std.Dev.
>>>  sex:line (Intercept) 0.0023237 0.048205
>>>  line     (Intercept) 0.0169393 0.130151
>>>  Residual             0.0168238 0.129707
>>> Number of obs: 120, groups: sex:line, 30; line, 15
>>>
>>> Fixed effects:
>>>             Estimate Std. Error t value
>>> (Intercept) 11.45977    0.03955  289.72
>>> sexM         0.52992    0.02951   17.96
>>>
>>> Correlation of Fixed Effects:
>>>      (Intr)
>>> sexM -0.373
>>>> m2
>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (sex | line) 
>>>  AIC    BIC logLik deviance REMLdev
>>>  -90 -73.27     51   -112.1    -102
>>> Random effects:
>>>  Groups   Name        Variance  Std.Dev. Corr   line     (Intercept) 
>>> 0.0152993 0.123691                 sexM        0.0046474 0.068172 
>>> 0.194  Residual             0.0168238 0.129707       Number of obs: 
>>> 120, groups: line, 15
>>>
>>> Fixed effects:
>>>             Estimate Std. Error t value
>>> (Intercept) 11.45977    0.03606   317.8
>>> sexM         0.52992    0.02951    18.0
>>>
>>> Correlation of Fixed Effects:
>>>      (Intr)
>>> sexM -0.161
>>>> m3
>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (0 + sex | line) 
>>>  AIC    BIC logLik deviance REMLdev
>>>  -90 -73.27     51   -112.1    -102
>>> Random effects:
>>>  Groups   Name Variance Std.Dev. Corr   line     sexF 0.015299 
>>> 0.12369                  sexM 0.023227 0.15240  0.899  Residual      
>>> 0.016824 0.12971        Number of obs: 120, groups: line, 15
>>>
>>> Fixed effects:
>>>             Estimate Std. Error t value
>>> (Intercept) 11.45977    0.03606   317.8
>>> sexM         0.52991    0.02951    18.0
>>>
>>> Correlation of Fixed Effects:
>>>      (Intr)
>>> sexM -0.161
>>
>>
>>
> 
> 

-- 
Paolo Innocenti
Department of Animal Ecology, EBC
Uppsala University
Norbyv?gen 18D
75236 Uppsala, Sweden



From paolo.innocenti at ebc.uu.se  Thu Jun  4 11:38:22 2009
From: paolo.innocenti at ebc.uu.se (Paolo Innocenti)
Date: Thu, 04 Jun 2009 11:38:22 +0200
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
 and	iteration
In-Reply-To: <4A277E1C.5020604@ebc.uu.se>
References: <4A2520D6.6080108@ebc.uu.se> <4A26AD37.4040802@msu.edu>
	<4A277E1C.5020604@ebc.uu.se>
Message-ID: <4A27960E.2070507@ebc.uu.se>

Sorry for replying to my own emails, but I found partial solution to my 
problems in Pinheiro and Bates at:

2.4.1 - Likelihood Ratio Tests (p.83)
to calculate logLik and p.values for random effects

and

2.4.2 - Hypothesis tests for Fixed-Effect Terms (p.87)
that is self-explanatory. Although I still don't understand how to 
calculate the "denominator degrees of freedom".

Best,
paolo

PS. Off-topic quick question: is there currently a "out-of-the-box" 
solution to get credible intervals for random effects in mcmcsamp()?
HPDinterval (from lme4 package) doesn't seem to work for that?




Paolo Innocenti wrote:
> Dear Douglas, Rolf, Juan and list,
> 
> thank you very much for your replies.
> I now got a good working model, and the use of refit and VarCorr will 
> definitely help.
> 
> I had a go with mcmcsamp(), and I must confirm that this approach is not 
> feasible, both computationally and because if you get a "false 
> convergence" for, say, 1 gene out of 20, it becomes impossible to go 
> back and fix all the errors.
> 
> So, the alternative approach seems more promising. If I understand 
> correctly, you suggest to calculate a p-value for random effects out of 
> the LRT (Likelihood ratio test), and use approximated DFs to calculate 
> standard p-values for the fixed effects.
> 
> I neved used this approach, so I appreciate if you can point me in the 
> right direction.
> 
> Random effects:
> I'd need to compare the this three model:
> m1a <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
> m1b <- lmer(Y1 ~ sex + (1|line))
> m1c <- lmer(Y1 ~ sex)
> 
> and get the effect of the interaction from m1a-m1b,
> and the effect of "line" from m1b-m1c.
> It that correct?
> Can anyone point me to any kind of documentation/examples to sort out 
> the details?
> 
> Fixed effects:
> I don't really know where to get the approximated degrees of freedom. 
> Can you point me to an example?
> 
> Thanks again for all the help. Eventually, I'll be really happy to share 
> my experience/code when everything is sorted, even if I doubt I can add 
> anything helpful.
> 
> Best,
> paolo
> 
> PS. I don't really understand what you mean by
> sobj<-summary(result)
> what object is your "result" here?
> 
> 
> 
> 
> Juan Pedro Steibel wrote:
>> Hello Paolo,
>> We are also starting to use lmer for gene expression analysis 
>> (genetical genomics too) so here are my thoughts.
>>
>> Having two equivalent parameterizations, I would go with the 
>> computationally fastest one (a couple more miliseconds per model, 
>> easily add up to many hours when analyzing highly dimensional 
>> datasets). You can time the analysis for, say, 100 transcripts and go 
>> from there.
>>
>> ~note: other users commented on your models not being equivalent~
>>
>> For p-values:
>>
>> You could use LRT to test for variance components.
>>
>> This is standard practice in genetic epidemiology: fit a model with 
>> and without the random effect in question, then compare the log 
>> (residual) likelihood ratio to a chi-square statistic. FDR can be used 
>> on top of that to account for multiple tests. Of course, now you have 
>> to fit three models (one null models for each VC), so your cpu  time 
>> has just multiplied by almost 3. Definitely using refit and update 
>> will help with compute time when having so many models.
>>
>> I use sobj<-summary(result) as an intermediate step to get the info 
>> (although this may add to the computational burden and other 
>> suggestions you got may be faster and more efficient),
>>
>> then ask for slots:
>> @REmat
>> @coefs
>> ...for getting estimates of variance components and fixed effects.
>>
>> @coefs gives you a t-statistic for fixed effects too... you could take 
>> a stab at an approximated df method and compute an (approximated) 
>> p-value.
>> I know that doing so can attract a lot of criticism in this list, but 
>> when you are fitting a several million models (10000s of transcripts 
>> and 1000s of genomic positions as in my case), the mcmc approximation 
>> is (unfortunately) not computationally feasible.
>>
>>
>> Hope this helps!
>> JP
>>
>>
>>
>> Paolo Innocenti wrote:
>>> Dear Douglas and list,
>>>
>>> I am thinking about fitting a mixed model for a microarray experiment 
>>> using lme4, since other specific software seems not suitable for my 
>>> purposes. I'll briefly describe the model and kindly ask for 
>>> suggestions on the model and the workflow I can use to get useful 
>>> results.
>>>
>>> My response variable Y is gene expression levels for a given gene 
>>> (say g_i) from 120 samples.
>>> The factor I want to include are:
>>>
>>> Sex: fixed, two levels, M/F.
>>> Line: 15 randomly picked genotypes from a large outbred population.
>>>
>>> I am interested in:
>>> - if the gene is differentially expressed in the 2 sexes (effect of 
>>> sex), in the 15 lines (effect of line) and the interaction of the two.
>>>
>>> - the variance component of line = how much of the variance is due to 
>>> the genotype
>>>
>>> - the variance component of the interaction = the genetic variation 
>>> for sexual dimorphism.
>>>
>>> Reading a bit of this mailing list, I came up with these three models:
>>>
>>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>>>
>>> or
>>>
>>> m2 <- lmer(Y1 ~ sex + (sex|line))
>>>
>>> or
>>>
>>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>>>
>>> Which should all be the same model (and indeed they have all the same 
>>> residuals) but different parametrization (see self-contained example 
>>> below).
>>>
>>> Now, in the light of my needs (see above), which model makes it 
>>> easier to extract the components I need? Also, do they make different 
>>> assumptions - as different levels of independency among levels of 
>>> random factors?
>>>
>>> I will need to be able to extract the variance component values in an 
>>> iterative process (i have 18.000 genes): is VarCorr() the way to go?
>>>
>>> VarCorr(m1)$'sex:line'[1]
>>> VarCorr(m1)$'line'[1]
>>>
>>> Last two question: what is the easier way to assess, in an iterative 
>>> process, normality of residuals, and what is a sensible way to assess 
>>> significant differential expression of genes (since I guess I can't 
>>> get p-values and then apply FDR correction?)
>>>
>>> Thanks a lot for reading so far and I'll be grateful for any kind of 
>>> help.
>>> paolo
>>>
>>> Self-contained example:
>>>
>>> Y1 <- as.numeric(
>>> c("11.6625","11.3243","11.7819","11.5032","11.7578","11.9379","11.8491",
>>> "11.9035","11.2042","11.0344","11.5137","11.1995","11.6327","11.7392",
>>> "11.9869","11.6955","11.5631","11.7159","11.8435","11.5814","12.0756",
>>> "12.3428","12.3342","11.9883","11.6067","11.6102","11.6517","11.4444",
>>> "11.9567","12.0478","11.9683","11.8207","11.5860","11.6028","11.6522",
>>> "11.6775","12.3570","12.2266","12.2444","12.1369","11.2573","11.4577",
>>> "11.4432","11.2994","11.8486","11.9258","11.9864","11.9964","11.2806",
>>> "11.2527","11.3672","11.0791","11.9501","11.7223","11.9825","11.8114",
>>> "11.6116","11.4284","11.3731","11.6942","12.2153","12.0101","12.2150",
>>> "12.1932","11.5617","11.3761","11.4813","11.7503","11.9889","12.1530",
>>> "12.3299","12.4436","11.4566","11.4614","11.5527","11.3513","11.9764",
>>> "11.8810","12.0999","11.9083","11.4870","11.6764","11.3973","11.4507",
>>> "12.1141","11.9906","12.1118","11.9728","11.3382","11.4146","11.4590",
>>> "11.2527","12.1101","12.0448","12.2191","11.8317","11.3982","11.3555",
>>> "11.3897","11.7731","11.9749","11.8666","12.1984","12.0350","11.4642",
>>> "11.4509","11.5552","11.4346","12.0714","11.7136","11.9019","11.8158",
>>> "11.3132","11.3121","11.1612","11.2073","11.6658","11.7879","11.7847",
>>> "11.5300"))
>>> sex <- factor(rep(c("F","M"), 15, each=4))
>>> line <- factor(rep(1:15, each=8))
>>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>>> m2 <- lmer(Y1 ~ sex + (sex|line))
>>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>>> VarCorr(m1)$'sex:line'[1]
>>> VarCorr(m1)$'line'[1]
>>>
>>> Output:
>>>
>>>>> m1
>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (1 | line) + (1 | 
>>>> sex:line)     AIC   BIC logLik deviance REMLdev
>>>>  -91.13 -77.2  50.57   -111.1  -101.1
>>>> Random effects:
>>>>  Groups   Name        Variance  Std.Dev.
>>>>  sex:line (Intercept) 0.0023237 0.048205
>>>>  line     (Intercept) 0.0169393 0.130151
>>>>  Residual             0.0168238 0.129707
>>>> Number of obs: 120, groups: sex:line, 30; line, 15
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error t value
>>>> (Intercept) 11.45977    0.03955  289.72
>>>> sexM         0.52992    0.02951   17.96
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> sexM -0.373
>>>>> m2
>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (sex | line) 
>>>>  AIC    BIC logLik deviance REMLdev
>>>>  -90 -73.27     51   -112.1    -102
>>>> Random effects:
>>>>  Groups   Name        Variance  Std.Dev. Corr   line     (Intercept) 
>>>> 0.0152993 0.123691                 sexM        0.0046474 0.068172 
>>>> 0.194  Residual             0.0168238 0.129707       Number of obs: 
>>>> 120, groups: line, 15
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error t value
>>>> (Intercept) 11.45977    0.03606   317.8
>>>> sexM         0.52992    0.02951    18.0
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> sexM -0.161
>>>>> m3
>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (0 + sex | line) 
>>>>  AIC    BIC logLik deviance REMLdev
>>>>  -90 -73.27     51   -112.1    -102
>>>> Random effects:
>>>>  Groups   Name Variance Std.Dev. Corr   line     sexF 0.015299 
>>>> 0.12369                  sexM 0.023227 0.15240  0.899  Residual      
>>>> 0.016824 0.12971        Number of obs: 120, groups: line, 15
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error t value
>>>> (Intercept) 11.45977    0.03606   317.8
>>>> sexM         0.52991    0.02951    18.0
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> sexM -0.161
>>>
>>>
>>>
>>
>>
> 

-- 
Paolo Innocenti
Department of Animal Ecology, EBC
Uppsala University
Norbyv?gen 18D
75236 Uppsala, Sweden



From aalisiyan at gmail.com  Thu Jun  4 14:45:09 2009
From: aalisiyan at gmail.com (alis villiyam)
Date: Thu, 4 Jun 2009 14:45:09 +0200
Subject: [R-sig-ME] RCBD IN R
Message-ID: <509507040906040545w757b492ase187e6f3d7057dfb@mail.gmail.com>

Dear R user

I've received helpful advice in the past from the readers of this list, and
would like some more advice.In a sand filtration column is being tested at a
some phisical propertice of soil.I have 4 treatment with 3 replacation in
RCBD.I am not sure this analysis be fully appropriate on repeated (or
longitudinal) measurements.

could you please advise me.

Kind Regards,

Alisa

From Fabian.Scheipl at stat.uni-muenchen.de  Thu Jun  4 15:22:08 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Thu, 4 Jun 2009 15:22:08 +0200
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
	and iteration
In-Reply-To: <4836bc6a0906040517u7649ac6aye5d3ee65730f05f6@mail.gmail.com>
References: <4836bc6a0906040517u7649ac6aye5d3ee65730f05f6@mail.gmail.com>
Message-ID: <4836bc6a0906040622g24d88bf8t6e1afb2a0285ce0f@mail.gmail.com>

Hi,

RE:
> For p-values:
>
> You could use LRT to test for variance components.
>
> This is standard practice in genetic epidemiology: fit a model with and without the random effect in question, then compare the log (residual) likelihood ratio to a chi-square  statistic.

This is borderline wrong - using a ChiSq(1) as the null distribution
for testing whether random effect variances are zero will give you a
terribly conservative test- at the least you should use a mixture of a
.5 point mass in zero and .5*ChiSq(1) as the reference distribution
(see Self/Liang (1987)).
More details on this can be found in Crainiceanu/Ruppert(2003)
<http://www.orie.cornell.edu/~davidr/papers/asymptoticpaper2.pdf>.

There is also a fairly fast and almost exact test for this type of
hypothesis implemented in package RLRsim which implements the ideas in
Crainiceanu/Ruppert(2003) and extends them to models with multiple
independent random effects (see our paper
<http://dx.doi.org/10.1016/j.csda.2007.10.022>).

I include some simulation code below to demonstrate why the
conventional (R)LRT is a really bad idea for this and why it might be
better? to consider using RLRsim or, at least, the ChiSq-Mixture
approximation (which will be worse if you have fewer i.i.d. subvectors
in your data, in your case: the less balanced your data is and the
less genotypes you've sampled).

##############
##begin? code ##
##############

#simulates data according to your description
#defaults taken from your reproducible example, except for sd.sexline
simData <- function(
??? ??? #no. of obs
??? ??? n = 120,
??? ??? #no. of genotypes
??? ??? n.line = 15,
??? ??? #sd of random intercept for genotype
??? ??? sd.line = 0.13,
??? ??? #sd of random intercpet for genotype:sex interaction
??? ??? sd.sexline = 0,
??? ??? #sd of errors
??? ??? sd.eps = 0.13,
??? ??? #fixed effect of sex
??? ??? beta.sex = 0.52,
??? ??? seed = NA)
{
??? if (!is.na(seed)) set.seed(seed)

??? sex <- factor(rep(c("M", "F"), times = n.line, each = n/n.line/2))
??? line <- factor(rep(1:n.line, each = n/n.line))

??? X <- model.matrix(~1 + sex)
??? Z <- model.matrix(~0 + line + sex:line)

??? Y1 <- X %*% c(0, beta.sex) +
             Z %*% c(rnorm(n.line, sd = sd.line),
                           rnorm(n.line, sd = sd.sexline)) +
             rnorm(n, sd = sd.eps)

??? return(data.frame(Y1, line, sex))
}

fitModels <- function(d)
{
??? require(lme4)
??? m1a <- lmer(Y1 ~ sex + (1 | line) + (1 | sex:line),
??? ??? ??? data = d)
??? m1b <- lmer(Y1 ~ sex + (1 | line), data = d)
??? return(list(sexline = m1a, line = m1b))
}

testSexLine <- function(models)
#test random effect for sex:line
{
??? require(RLRsim)

??? #exact Restricted Likelihood Ratio test of random effect
(1|sex:line) when random effect (1|line) is present in model
??? sexlineOnly <- update(models$sexline, . ~ . - (1 |
??? ??? ??? ??? ??? ??? line))
??? t <- exactRLRT(sexlineOnly, models$sexline, models$line)
??? p.exact <- t$p.value

??? #approximate distribution of RLRT is a mixture of .5 mass in zero
and .5 * ChiSq(1)
??? # see Self+Liang(1987)
??? p.approx <- 1 - (0.5 + 0.5 * pchisq(t$statistic, df = 1))

??? # ChiSq(1) as null distribution for Restricted LRT
??? p.naive <- 1 - pchisq(t$statistic, df = 1)

??? #return exact and approximate p-values
??? return(c(exact = p.exact, chiSqMix = p.approx, naive = p.naive))
}


#simulate data under H0:sd.sexline = 0 and test this hypothesis 500 times
set.seed(123)
simPvals.0 <- replicate(500, testSexLine(fitModels(simData())))
# get rejection probabilities for alpha=.05
(rowMeans(simPvals.0 < 0.05) )
#exact ? ? ? chiSqMix ???? naive
#0.050??????? 0.038?????????? 0.014
# --> approximations are (much) more conservative, far from nominal level

##############
## end? code ##
##############

So, for a nominal level of 5%, you have a rejection probability of
only 1.4% for the ChiSq(1) and 3.8% for the ChiSqMixture -that's
pretty bad don't you think? - Especially since

>
> FDR can be used on top of that to account for multiple tests.

I'm no expert at all as far as multiple testing is concerned, but I'd
imagine that basing corrections for multiple testing on tests that
don't have the nominal level would tend to mess things up.

Using the exact test or the mixture approximation will give you more
power to detect variance components that are actually present, see for
example simulated data with the estimated parameters from your
example:

##############
##begin? code ##
##############
set.seed(234)
simPvals.048 <- replicate(500,
testSexLine(fitModels(simData(sd.sexline = 0.048))))
rowMeans(simPvals.048 < 0.05)

# exact?? chiSqMix? naive
#? 0.148?? 0.132???   0.078

##############
## end? code ##
##############

The naive approach is really bad. Admittedly not a huge difference in
power between the exact test and the mixture approximation, but
remember: the mixture approximation will become even more conservative
for unbalanced data or data with fewer genotypes/ levels of line.

HTH,
Fabian



From Linda.Mortensen at psy.ku.dk  Thu Jun  4 17:28:52 2009
From: Linda.Mortensen at psy.ku.dk (Linda Mortensen)
Date: Thu, 4 Jun 2009 17:28:52 +0200
Subject: [R-sig-ME] How to include a quadratic term in an lmer model
Message-ID: <7A47FC91544BDC44B54C6807E6995019CE8D9A@ibtmail1.ibt.ku.dk.ad>

Hi list members,
 
I have recently e-mailed this list asking for some advice on how to use mixed-effects models on ordinal responses (see posts entitled "How to use mixed-effects models on multinomial data"). This query concerns the same data set, but since the topic is a different one, I post the query under a different header. 
Following several list members advice, I'm using a linear mixed-effects model to analyse the data described in the earlier posts, so I'm still working within this model framework. But when trying to decide on the best-fitting model, I have run into a problem: In the data set, there is a curved relationship between one of the explanatory variables (i.e., the serial position of items in a list) and the response variable. A model that includes both a linear and a quadratic term for this variable would most likely describe this relationship better than a model that includes only a linear variable. But when I try to include the quadratic term in the model, using the formula "lmer(y ~ x + I(x^2)", I get the following error message:    
"Error in `contrasts<-`(`*tmp*`, value = "contr.treatment") : 
  contrasts can be applied only to factors with 2 or more levels"
And the following warnings:
"In addition: Warning messages:
1: In Ops.factor(cposition, 2) : ^ not meaningful for factors
2: In Ops.factor(cposition, 2) : ^ not meaningful for factors"

Judging from the error message, the problem seems to be that I have coded the serial position variable using the (default) contrast coding system. The serial position variable has five levels (positions 1 through 5), so I don't understand why R is complaining about the number of levels. - There are 5 levels, so the serial position factor has "2 or more levels". Is it the coding system that is the problem? Can someone explain to me what I'm doing wrong here? Any suggestions are greatly appreciated.
 
Linda 

 
Linda Mortensen
Post-doctoral research fellow
Department of Psychology
University of Copenhagen 
?ster Farimagsgade 2A
1353 Copenhagen K
Denmark
Tel.: +45 3532 4889
E-mail: linda.mortensen at psy.ku.dk



From rmh3093 at gmail.com  Thu Jun  4 18:12:26 2009
From: rmh3093 at gmail.com (Ryan Hope)
Date: Thu, 4 Jun 2009 12:12:26 -0400
Subject: [R-sig-ME] How to include a quadratic term in an lmer model
In-Reply-To: <7A47FC91544BDC44B54C6807E6995019CE8D9A@ibtmail1.ibt.ku.dk.ad>
References: <7A47FC91544BDC44B54C6807E6995019CE8D9A@ibtmail1.ibt.ku.dk.ad>
Message-ID: <48f7fe350906040912w58aebb3bg685e7120ed57ab04@mail.gmail.com>

I believe you can only do I(x^2) if x is a continuous variable.

On 6/4/09, Linda Mortensen <Linda.Mortensen at psy.ku.dk> wrote:
> Hi list members,
>
> I have recently e-mailed this list asking for some advice on how to use
> mixed-effects models on ordinal responses (see posts entitled "How to use
> mixed-effects models on multinomial data"). This query concerns the same
> data set, but since the topic is a different one, I post the query under a
> different header.
> Following several list members advice, I'm using a linear mixed-effects
> model to analyse the data described in the earlier posts, so I'm still
> working within this model framework. But when trying to decide on the
> best-fitting model, I have run into a problem: In the data set, there is a
> curved relationship between one of the explanatory variables (i.e., the
> serial position of items in a list) and the response variable. A model that
> includes both a linear and a quadratic term for this variable would most
> likely describe this relationship better than a model that includes only a
> linear variable. But when I try to include the quadratic term in the model,
> using the formula "lmer(y ~ x + I(x^2)", I get the following error message:
>
> "Error in `contrasts<-`(`*tmp*`, value = "contr.treatment") :
>   contrasts can be applied only to factors with 2 or more levels"
> And the following warnings:
> "In addition: Warning messages:
> 1: In Ops.factor(cposition, 2) : ^ not meaningful for factors
> 2: In Ops.factor(cposition, 2) : ^ not meaningful for factors"
>
> Judging from the error message, the problem seems to be that I have coded
> the serial position variable using the (default) contrast coding system. The
> serial position variable has five levels (positions 1 through 5), so I don't
> understand why R is complaining about the number of levels. - There are 5
> levels, so the serial position factor has "2 or more levels". Is it the
> coding system that is the problem? Can someone explain to me what I'm doing
> wrong here? Any suggestions are greatly appreciated.
>
> Linda
>
>
> Linda Mortensen
> Post-doctoral research fellow
> Department of Psychology
> University of Copenhagen
> ?ster Farimagsgade 2A
> 1353 Copenhagen K
> Denmark
> Tel.: +45 3532 4889
> E-mail: linda.mortensen at psy.ku.dk
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From charpent at bacbuc.dyndns.org  Thu Jun  4 18:18:59 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Thu, 04 Jun 2009 18:18:59 +0200
Subject: [R-sig-ME] How to include a quadratic term in an lmer model
In-Reply-To: <7A47FC91544BDC44B54C6807E6995019CE8D9A@ibtmail1.ibt.ku.dk.ad>
References: <7A47FC91544BDC44B54C6807E6995019CE8D9A@ibtmail1.ibt.ku.dk.ad>
Message-ID: <1244132338.7263.29.camel@yod>

Le jeudi 04 juin 2009 ? 17:28 +0200, Linda Mortensen a ?crit :
> Hi list members,
>  
> I have recently e-mailed this list asking for some advice on how to
> use mixed-effects models on ordinal responses (see posts entitled "How
> to use mixed-effects models on multinomial data"). This query concerns
> the same data set, but since the topic is a different one, I post the
> query under a different header. 
> Following several list members advice, I'm using a linear
> mixed-effects model to analyse the data described in the earlier
> posts, so I'm still working within this model framework. But when
> trying to decide on the best-fitting model, I have run into a problem:
> In the data set, there is a curved relationship between one of the
> explanatory variables (i.e., the serial position of items in a list)
> and the response variable. A model that includes both a linear and a
> quadratic term for this variable would most likely describe this
> relationship better than a model that includes only a linear variable.
> But when I try to include the quadratic term in the model, using the
> formula "lmer(y ~ x + I(x^2)", I get the following error message:    
> "Error in `contrasts<-`(`*tmp*`, value = "contr.treatment") : 
>   contrasts can be applied only to factors with 2 or more levels"
> And the following warnings:
> "In addition: Warning messages:
> 1: In Ops.factor(cposition, 2) : ^ not meaningful for factors
> 2: In Ops.factor(cposition, 2) : ^ not meaningful for factors"
> 
> Judging from the error message, the problem seems to be that I have
> coded the serial position variable using the (default) contrast coding
> system.

So, your "x" is coded as a factor ? If so, x^2 isn't even defined.

To speak of a "curvature" *supposes* an a priori ordering of your "x"
variable. Two possibilities :

- code it as an *ordered* factor,
- code it as a continuous variable.

The second possibility entails more assumptions about x than the first
(additivity, fixed distances between levels, etc ...).

You might want to use poly(x,2) rather than x+I(x^2) : poly(x,order)
will use orthogonal polynomials, ensuring independence of the
coefficients of the linear and quadratic term estimators. However, the
coefficients have no easy interpretation, and getting back to the
original value might no be *that* easy. Therefore, you may use poly(x,2)
for testing purposes, and x+I(x^2) to get the numerical values :-). I'm
sure a better solution can be found by looking examples and R-help for
poly().

>          The serial position variable has five levels (positions 1
> through 5), so I don't understand why R is complaining about the
> number of levels. - There are 5 levels, so the serial position factor
> has "2 or more levels". Is it the coding system that is the problem?
> Can someone explain to me what I'm doing wrong here? Any suggestions
> are greatly appreciated.
>  
> Linda



From steibelj at msu.edu  Thu Jun  4 21:36:33 2009
From: steibelj at msu.edu (Juan Pedro Steibel)
Date: Thu, 04 Jun 2009 15:36:33 -0400
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
 and	iteration
In-Reply-To: <4A277E1C.5020604@ebc.uu.se>
References: <4A2520D6.6080108@ebc.uu.se> <4A26AD37.4040802@msu.edu>
	<4A277E1C.5020604@ebc.uu.se>
Message-ID: <4A282241.6070408@msu.edu>

Hello paolo,
sobj<-summary(result), where result is m1a, m1b or m1c.

Not that m1c is actually a fixed effects model, and can not be fit with 
lmer, so you'll need to reconstruct the -2LL from another source. But 
with a normal model that should not be a problem.

Fabian Scheipl answered in a post that the LRT chisquare(1) was wrong 
and said that al least a mixture of chisquares should be used. I did not 
explained myself very well, but I meant to recommend the mixture of 
chisquare and pointmass when testing a single variance component.  
Fabian's other method could be used, provided it will not take eons to 
get the results for a high dimensional dataset.

But keep reading and you will find a good reason to hammer on me for 
recomendations on df and computing p-values 8^D

Probably the whole point for having mcmcsamp was to actually not have to 
answer that question on ddfs...
Having said that, my approach in a particular project we are working on 
is to do ddf=n-p... (n=length(y), p=ncols(x), x= full rank incidence 
matrix of fixed effects). I'll run and take cover now... 8^D
Seriously, in our particular design such approximation does not seem to 
be way off, as I checked it with mcmcsamp for a handful of transcripts.

And finally, a more existential question:
Paolo, do you really need a p-value?
Sometimes in gene expression analysis we only need to rank genes for 
evidence of differential expression.
In those cases, you may well rank then using the t-statistic or the LRT 
(not their p-values), especially if you have the same basic design 
structure across all genes or transcripts (that you probably do).
For example if you want to do enrichment of GO terms after the mm 
analysis you could do a Kolmogorov-Smirnov type of GSE using the 
t-statistics (or LRTs) to rank genes.

Hope this makes sense?
Thanks!
JP



Paolo Innocenti wrote:
> Dear Douglas, Rolf, Juan and list,
>
> thank you very much for your replies.
> I now got a good working model, and the use of refit and VarCorr will 
> definitely help.
>
> I had a go with mcmcsamp(), and I must confirm that this approach is 
> not feasible, both computationally and because if you get a "false 
> convergence" for, say, 1 gene out of 20, it becomes impossible to go 
> back and fix all the errors.
>
> So, the alternative approach seems more promising. If I understand 
> correctly, you suggest to calculate a p-value for random effects out 
> of the LRT (Likelihood ratio test), and use approximated DFs to 
> calculate standard p-values for the fixed effects.
>
> I neved used this approach, so I appreciate if you can point me in the 
> right direction.
>
> Random effects:
> I'd need to compare the this three model:
> m1a <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
> m1b <- lmer(Y1 ~ sex + (1|line))
> m1c <- lmer(Y1 ~ sex)
>
> and get the effect of the interaction from m1a-m1b,
> and the effect of "line" from m1b-m1c.
> It that correct?
> Can anyone point me to any kind of documentation/examples to sort out 
> the details?
>
> Fixed effects:
> I don't really know where to get the approximated degrees of freedom. 
> Can you point me to an example?
>
> Thanks again for all the help. Eventually, I'll be really happy to 
> share my experience/code when everything is sorted, even if I doubt I 
> can add anything helpful.
>
> Best,
> paolo
>
> PS. I don't really understand what you mean by
> sobj<-summary(result)
> what object is your "result" here?
>
>
>
>
> Juan Pedro Steibel wrote:
>> Hello Paolo,
>> We are also starting to use lmer for gene expression analysis 
>> (genetical genomics too) so here are my thoughts.
>>
>> Having two equivalent parameterizations, I would go with the 
>> computationally fastest one (a couple more miliseconds per model, 
>> easily add up to many hours when analyzing highly dimensional 
>> datasets). You can time the analysis for, say, 100 transcripts and go 
>> from there.
>>
>> ~note: other users commented on your models not being equivalent~
>>
>> For p-values:
>>
>> You could use LRT to test for variance components.
>>
>> This is standard practice in genetic epidemiology: fit a model with 
>> and without the random effect in question, then compare the log 
>> (residual) likelihood ratio to a chi-square statistic. FDR can be 
>> used on top of that to account for multiple tests. Of course, now you 
>> have to fit three models (one null models for each VC), so your cpu  
>> time has just multiplied by almost 3. Definitely using refit and 
>> update will help with compute time when having so many models.
>>
>> I use sobj<-summary(result) as an intermediate step to get the info 
>> (although this may add to the computational burden and other 
>> suggestions you got may be faster and more efficient),
>>
>> then ask for slots:
>> @REmat
>> @coefs
>> ...for getting estimates of variance components and fixed effects.
>>
>> @coefs gives you a t-statistic for fixed effects too... you could 
>> take a stab at an approximated df method and compute an 
>> (approximated) p-value.
>> I know that doing so can attract a lot of criticism in this list, but 
>> when you are fitting a several million models (10000s of transcripts 
>> and 1000s of genomic positions as in my case), the mcmc approximation 
>> is (unfortunately) not computationally feasible.
>>
>>
>> Hope this helps!
>> JP
>>
>>
>>
>> Paolo Innocenti wrote:
>>> Dear Douglas and list,
>>>
>>> I am thinking about fitting a mixed model for a microarray 
>>> experiment using lme4, since other specific software seems not 
>>> suitable for my purposes. I'll briefly describe the model and kindly 
>>> ask for suggestions on the model and the workflow I can use to get 
>>> useful results.
>>>
>>> My response variable Y is gene expression levels for a given gene 
>>> (say g_i) from 120 samples.
>>> The factor I want to include are:
>>>
>>> Sex: fixed, two levels, M/F.
>>> Line: 15 randomly picked genotypes from a large outbred population.
>>>
>>> I am interested in:
>>> - if the gene is differentially expressed in the 2 sexes (effect of 
>>> sex), in the 15 lines (effect of line) and the interaction of the two.
>>>
>>> - the variance component of line = how much of the variance is due 
>>> to the genotype
>>>
>>> - the variance component of the interaction = the genetic variation 
>>> for sexual dimorphism.
>>>
>>> Reading a bit of this mailing list, I came up with these three models:
>>>
>>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>>>
>>> or
>>>
>>> m2 <- lmer(Y1 ~ sex + (sex|line))
>>>
>>> or
>>>
>>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>>>
>>> Which should all be the same model (and indeed they have all the 
>>> same residuals) but different parametrization (see self-contained 
>>> example below).
>>>
>>> Now, in the light of my needs (see above), which model makes it 
>>> easier to extract the components I need? Also, do they make 
>>> different assumptions - as different levels of independency among 
>>> levels of random factors?
>>>
>>> I will need to be able to extract the variance component values in 
>>> an iterative process (i have 18.000 genes): is VarCorr() the way to go?
>>>
>>> VarCorr(m1)$'sex:line'[1]
>>> VarCorr(m1)$'line'[1]
>>>
>>> Last two question: what is the easier way to assess, in an iterative 
>>> process, normality of residuals, and what is a sensible way to 
>>> assess significant differential expression of genes (since I guess I 
>>> can't get p-values and then apply FDR correction?)
>>>
>>> Thanks a lot for reading so far and I'll be grateful for any kind of 
>>> help.
>>> paolo
>>>
>>> Self-contained example:
>>>
>>> Y1 <- as.numeric(
>>> c("11.6625","11.3243","11.7819","11.5032","11.7578","11.9379","11.8491", 
>>>
>>> "11.9035","11.2042","11.0344","11.5137","11.1995","11.6327","11.7392",
>>> "11.9869","11.6955","11.5631","11.7159","11.8435","11.5814","12.0756",
>>> "12.3428","12.3342","11.9883","11.6067","11.6102","11.6517","11.4444",
>>> "11.9567","12.0478","11.9683","11.8207","11.5860","11.6028","11.6522",
>>> "11.6775","12.3570","12.2266","12.2444","12.1369","11.2573","11.4577",
>>> "11.4432","11.2994","11.8486","11.9258","11.9864","11.9964","11.2806",
>>> "11.2527","11.3672","11.0791","11.9501","11.7223","11.9825","11.8114",
>>> "11.6116","11.4284","11.3731","11.6942","12.2153","12.0101","12.2150",
>>> "12.1932","11.5617","11.3761","11.4813","11.7503","11.9889","12.1530",
>>> "12.3299","12.4436","11.4566","11.4614","11.5527","11.3513","11.9764",
>>> "11.8810","12.0999","11.9083","11.4870","11.6764","11.3973","11.4507",
>>> "12.1141","11.9906","12.1118","11.9728","11.3382","11.4146","11.4590",
>>> "11.2527","12.1101","12.0448","12.2191","11.8317","11.3982","11.3555",
>>> "11.3897","11.7731","11.9749","11.8666","12.1984","12.0350","11.4642",
>>> "11.4509","11.5552","11.4346","12.0714","11.7136","11.9019","11.8158",
>>> "11.3132","11.3121","11.1612","11.2073","11.6658","11.7879","11.7847",
>>> "11.5300"))
>>> sex <- factor(rep(c("F","M"), 15, each=4))
>>> line <- factor(rep(1:15, each=8))
>>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>>> m2 <- lmer(Y1 ~ sex + (sex|line))
>>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>>> VarCorr(m1)$'sex:line'[1]
>>> VarCorr(m1)$'line'[1]
>>>
>>> Output:
>>>
>>>>> m1
>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (1 | line) + (1 
>>>> | sex:line)     AIC   BIC logLik deviance REMLdev
>>>>  -91.13 -77.2  50.57   -111.1  -101.1
>>>> Random effects:
>>>>  Groups   Name        Variance  Std.Dev.
>>>>  sex:line (Intercept) 0.0023237 0.048205
>>>>  line     (Intercept) 0.0169393 0.130151
>>>>  Residual             0.0168238 0.129707
>>>> Number of obs: 120, groups: sex:line, 30; line, 15
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error t value
>>>> (Intercept) 11.45977    0.03955  289.72
>>>> sexM         0.52992    0.02951   17.96
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> sexM -0.373
>>>>> m2
>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (sex | line) 
>>>>  AIC    BIC logLik deviance REMLdev
>>>>  -90 -73.27     51   -112.1    -102
>>>> Random effects:
>>>>  Groups   Name        Variance  Std.Dev. Corr   line     
>>>> (Intercept) 0.0152993 0.123691                 sexM        
>>>> 0.0046474 0.068172 0.194  Residual             0.0168238 
>>>> 0.129707       Number of obs: 120, groups: line, 15
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error t value
>>>> (Intercept) 11.45977    0.03606   317.8
>>>> sexM         0.52992    0.02951    18.0
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> sexM -0.161
>>>>> m3
>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (0 + sex | line) 
>>>>  AIC    BIC logLik deviance REMLdev
>>>>  -90 -73.27     51   -112.1    -102
>>>> Random effects:
>>>>  Groups   Name Variance Std.Dev. Corr   line     sexF 0.015299 
>>>> 0.12369                  sexM 0.023227 0.15240  0.899  
>>>> Residual      0.016824 0.12971        Number of obs: 120, groups: 
>>>> line, 15
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error t value
>>>> (Intercept) 11.45977    0.03606   317.8
>>>> sexM         0.52991    0.02951    18.0
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> sexM -0.161
>>>
>>>
>>>
>>
>>
>


-- 
=============================
Juan Pedro Steibel

Assistant Professor
Statistical Genetics and Genomics

Department of Animal Science & 
Department of Fisheries and Wildlife

Michigan State University
1205-I Anthony Hall
East Lansing, MI
48824 USA 

Phone: 1-517-353-5102
E-mail: steibelj at msu.edu



From r.turner at auckland.ac.nz  Thu Jun  4 22:35:31 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 5 Jun 2009 08:35:31 +1200
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
	and iteration
In-Reply-To: <40e66e0b0906021254ta8463a2p71e03f05dfa8d453@mail.gmail.com>
References: <4A2520D6.6080108@ebc.uu.se>
	<40e66e0b0906021254ta8463a2p71e03f05dfa8d453@mail.gmail.com>
Message-ID: <BB9E9F6E-BCC7-49F2-8A98-7ED8DDE7D830@auckland.ac.nz>


Dear Doug,

Two issues have arisen in respect of this thread that I would like to
comment upon.

(1) In my previous posting I included the link to Doug's explanation  
of the
lmer() syntax:

http://www.nabble.com/lme-nesting-interaction-advice- 
td17131600i20.html#a17213604

I found this explanation incredibly useful, and apparently others  
have as well.
(I was thanked off-list for posting this link.)

Could, perhaps, the content of this link, in appropriately edited  
form, be
included in the documentation for lmer(), or perhaps in a vignette  
(to which
the documentation might direct the reader)?  To save on frustrating  
searching
for those who are coming in to this area fresh.

(2) In one of his posts Juan Pedro Steibel wrote:

> Note that m1c is actually a fixed effects model, and can not be fit  
> with
> lmer, so you'll need to reconstruct the -2LL from another source.

He goes on to say:

>  But with a normal model that should not be a problem.

Hah!  Not a problem for some, maybe.  But for those of us whose  
initially
few brain cells have been decimated by alcohol ( :-) ) it is a problem.

Might I make a ``feature request'' that it be made possible to fit  
models
with fixed effects only in lmer()?  (Basically for convenience of  
testing
whether random effects are ``useful''.)  I personally would also be  
comforted
by being able to do things like

	fit1 <- lmer(y ~ x, REML=TRUE)
	fit2 <- lmer(y ~ x, REML=FALSE)

and compare the resulting estimates of sigma^2 (which presumably  
should differ
by a factor of n/(n-2) if I'm understanding things correctly).  Being  
able to
do this would give me the comforting illusion ( :-) ) that I ***am***  
understanding
things correctly.  Or perhaps disabuse me of this illusion.

Would it be a Herculean task to adapt lmer() to have this capacity?   
Naively I would
have thought that if a model with fixed and random effects can be  
fitted, then
surely a (simpler) model with only fixed effects can be fitted.  OTOH  
the fixed effects
only scenario is in some sense ``on the boundary'', and boundary  
cases can be vexatious.

Not knowing how lmer() works, I have no idea how hard or easy making  
such a change
would be.

I would appreciate hearing your thoughts on this.

	cheers,

		Rolf

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From ursa.reja at gmail.com  Fri Jun  5 11:57:57 2009
From: ursa.reja at gmail.com (Ursa Reja)
Date: Fri, 5 Jun 2009 11:57:57 +0200
Subject: [R-sig-ME] catch non-convergence in lmer as variable
Message-ID: <63b87ebe0906050257j13f03372gf2f642f9d5da406d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090605/e60b92e8/attachment.pl>

From bolker at ufl.edu  Fri Jun  5 13:26:48 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 05 Jun 2009 07:26:48 -0400
Subject: [R-sig-ME] catch non-convergence in lmer as variable
In-Reply-To: <63b87ebe0906050257j13f03372gf2f642f9d5da406d@mail.gmail.com>
References: <63b87ebe0906050257j13f03372gf2f642f9d5da406d@mail.gmail.com>
Message-ID: <4A2900F8.8000905@ufl.edu>


  Hmm.  I don't know about type -- I generally use
if (inherits(fitmodel,"try-error"))

   do you have an extra space at the end of "try-error"
in your type variable?

   I was using

glmer2 <- function(...) {
  op <- options(warn=2)
  on.exit(options(op))
  x <- try(glmer(...),silent=TRUE)
  if (inherits(x,"try-error")) {
    stop(x,unclass(x))
  }
  x
}

Ursa Reja wrote:
> Dear R-users,
> 
> I am doing simulations with lmer function. For every simulation I extract
> estimates,...into a database, but I also want to have a variable that would
> indicate whether simulated data converged properly or not. (I get warnings,
> for ex. singular convergence, false convergence,...but the estimates are
> given anyway).
> 
> I tried to cope with the problem so that I change warnings to error (warn=2)
> and use function try, like below:
> 
> ok <- function(x,type= "try-error ") class(x)!=type
> 
> options(warn=2)
> 
> fitmodel <- try(lmer(modelformula,data))
> 
> but
> 
> ok(fitmodel)
> 
> gives me TRUE even if I get a warning!
> 
> 
> Thank you!
> 
> 
> Ursa Reja
> 
> 
> 
> 
> ######~~~~~~~~~~   extract deviances  ~~~~~~~~~~######
> 
> 
> 
> ##if(ok(fitmodel)&ok(fitmodel1)&ok(fitmodel2)&ok(fitmodel3))
> 
> ##if(ok(fitmodel))
> 
> ##{
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From ursa.reja at gmail.com  Fri Jun  5 14:25:44 2009
From: ursa.reja at gmail.com (Ursa Reja)
Date: Fri, 5 Jun 2009 14:25:44 +0200
Subject: [R-sig-ME] extract correlaton from VarCorr
Message-ID: <63b87ebe0906050525q55e8d0e9q37ee094356e91894@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090605/b857a748/attachment.pl>

From bolker at ufl.edu  Fri Jun  5 14:57:19 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 05 Jun 2009 08:57:19 -0400
Subject: [R-sig-ME] extract correlaton from VarCorr
In-Reply-To: <63b87ebe0906050525q55e8d0e9q37ee094356e91894@mail.gmail.com>
References: <63b87ebe0906050525q55e8d0e9q37ee094356e91894@mail.gmail.com>
Message-ID: <4A29162F.9080607@ufl.edu>

attr(VarCorr(fitmodel)$group,"correlation")[2,1]


Ursa Reja wrote:
> Dear R users,
> 
> how do I extract correlation between random effects of 0.06836857 got by
> VarCor function (look below)?
> Tnx?
> 
> VarCorr(fitmodel)
> $group
>             (Intercept)          x
> (Intercept)  0.25016744 0.01788204
> x            0.01788204 0.27345787
> attr(,"stddev")
> (Intercept)           x
>   0.5001674   0.5229320
> attr(,"correlation")
>             (Intercept)          x
> (Intercept)  1.00000000 0.06836857
> x            0.06836857 1.00000000
> 
> attr(,"sc")
> sigmaREML
> 0.7239645
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From ursa.reja at gmail.com  Fri Jun  5 15:18:11 2009
From: ursa.reja at gmail.com (Ursa Reja)
Date: Fri, 5 Jun 2009 15:18:11 +0200
Subject: [R-sig-ME] convergence problem in lmer
Message-ID: <63b87ebe0906050618k2322a8cn79ff2821c991ed3a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090605/4a7723cc/attachment.pl>

From paolo.innocenti at ebc.uu.se  Fri Jun  5 19:30:50 2009
From: paolo.innocenti at ebc.uu.se (Paolo Innocenti)
Date: Fri, 05 Jun 2009 19:30:50 +0200
Subject: [R-sig-ME] Mixed model (with interaction) for gene expression
 and	iteration
In-Reply-To: <4A282241.6070408@msu.edu>
References: <4A2520D6.6080108@ebc.uu.se> <4A26AD37.4040802@msu.edu>
	<4A277E1C.5020604@ebc.uu.se> <4A282241.6070408@msu.edu>
Message-ID: <4A29564A.6030104@ebc.uu.se>

Hi all,

thanks again to all of you for the replies.
I took Fabian's suggestion (thanks for the effort you made to make your 
point! amazing) but unfortunately for my purpose it requires to much 
computation time (in terms of model to be fitted and evaluation time). 
At the moment I am happy with

1-(0.5 + 0.5*pchisq(tempobj$Chisq[2], df=1))

for the p-values for the random effects.

For the p-values for fixed effects: yes, i do really need them. They are 
not really important for THE specific gene, but I need to be able to 
say: around 30% of the transcriptome is differentially expressed).

In my case, the effect I am testing is pretty big, my sample size is 
pretty large (120 observations, 60 per group - M/F), completely balanced 
and I can afford to be a bit conservative. That said, I found this link:

http://wiki.r-project.org/rwiki/doku.php?id=guides:lmer-tests

where Doug discuss about using a function hatTrace() and use it to 
calculate the trace and then the degrees of freedom (denDF = n - "trace" 
i think) and feed it to

1 - pf(F.ratio, numDF, ***)

It seems to be what I am looking for, but I can't find the function 
hatTrace...
Does anyone know how I could estimate my denDF? Any suggestion is most 
welcome (JP i have some problem in understanding your lingo... =)
Pinheiro and Bates says:

denDF = m_i - (m_(i-1) + p_i),  i = 1,...,Q+1

but I don't really understand what it means.

Thanks again to everyone!
Best,
paolo


Juan Pedro Steibel wrote:
> Hello paolo,
> sobj<-summary(result), where result is m1a, m1b or m1c.
> 
> Not that m1c is actually a fixed effects model, and can not be fit with 
> lmer, so you'll need to reconstruct the -2LL from another source. But 
> with a normal model that should not be a problem.
> 
> Fabian Scheipl answered in a post that the LRT chisquare(1) was wrong 
> and said that al least a mixture of chisquares should be used. I did not 
> explained myself very well, but I meant to recommend the mixture of 
> chisquare and pointmass when testing a single variance component.  
> Fabian's other method could be used, provided it will not take eons to 
> get the results for a high dimensional dataset.
> 
> But keep reading and you will find a good reason to hammer on me for 
> recomendations on df and computing p-values 8^D
> 
> Probably the whole point for having mcmcsamp was to actually not have to 
> answer that question on ddfs...
> Having said that, my approach in a particular project we are working on 
> is to do ddf=n-p... (n=length(y), p=ncols(x), x= full rank incidence 
> matrix of fixed effects). I'll run and take cover now... 8^D
> Seriously, in our particular design such approximation does not seem to 
> be way off, as I checked it with mcmcsamp for a handful of transcripts.
> 
> And finally, a more existential question:
> Paolo, do you really need a p-value?
> Sometimes in gene expression analysis we only need to rank genes for 
> evidence of differential expression.
> In those cases, you may well rank then using the t-statistic or the LRT 
> (not their p-values), especially if you have the same basic design 
> structure across all genes or transcripts (that you probably do).
> For example if you want to do enrichment of GO terms after the mm 
> analysis you could do a Kolmogorov-Smirnov type of GSE using the 
> t-statistics (or LRTs) to rank genes.
> 
> Hope this makes sense?
> Thanks!
> JP
> 
> 
> 
> Paolo Innocenti wrote:
>> Dear Douglas, Rolf, Juan and list,
>>
>> thank you very much for your replies.
>> I now got a good working model, and the use of refit and VarCorr will 
>> definitely help.
>>
>> I had a go with mcmcsamp(), and I must confirm that this approach is 
>> not feasible, both computationally and because if you get a "false 
>> convergence" for, say, 1 gene out of 20, it becomes impossible to go 
>> back and fix all the errors.
>>
>> So, the alternative approach seems more promising. If I understand 
>> correctly, you suggest to calculate a p-value for random effects out 
>> of the LRT (Likelihood ratio test), and use approximated DFs to 
>> calculate standard p-values for the fixed effects.
>>
>> I neved used this approach, so I appreciate if you can point me in the 
>> right direction.
>>
>> Random effects:
>> I'd need to compare the this three model:
>> m1a <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>> m1b <- lmer(Y1 ~ sex + (1|line))
>> m1c <- lmer(Y1 ~ sex)
>>
>> and get the effect of the interaction from m1a-m1b,
>> and the effect of "line" from m1b-m1c.
>> It that correct?
>> Can anyone point me to any kind of documentation/examples to sort out 
>> the details?
>>
>> Fixed effects:
>> I don't really know where to get the approximated degrees of freedom. 
>> Can you point me to an example?
>>
>> Thanks again for all the help. Eventually, I'll be really happy to 
>> share my experience/code when everything is sorted, even if I doubt I 
>> can add anything helpful.
>>
>> Best,
>> paolo
>>
>> PS. I don't really understand what you mean by
>> sobj<-summary(result)
>> what object is your "result" here?
>>
>>
>>
>>
>> Juan Pedro Steibel wrote:
>>> Hello Paolo,
>>> We are also starting to use lmer for gene expression analysis 
>>> (genetical genomics too) so here are my thoughts.
>>>
>>> Having two equivalent parameterizations, I would go with the 
>>> computationally fastest one (a couple more miliseconds per model, 
>>> easily add up to many hours when analyzing highly dimensional 
>>> datasets). You can time the analysis for, say, 100 transcripts and go 
>>> from there.
>>>
>>> ~note: other users commented on your models not being equivalent~
>>>
>>> For p-values:
>>>
>>> You could use LRT to test for variance components.
>>>
>>> This is standard practice in genetic epidemiology: fit a model with 
>>> and without the random effect in question, then compare the log 
>>> (residual) likelihood ratio to a chi-square statistic. FDR can be 
>>> used on top of that to account for multiple tests. Of course, now you 
>>> have to fit three models (one null models for each VC), so your cpu  
>>> time has just multiplied by almost 3. Definitely using refit and 
>>> update will help with compute time when having so many models.
>>>
>>> I use sobj<-summary(result) as an intermediate step to get the info 
>>> (although this may add to the computational burden and other 
>>> suggestions you got may be faster and more efficient),
>>>
>>> then ask for slots:
>>> @REmat
>>> @coefs
>>> ...for getting estimates of variance components and fixed effects.
>>>
>>> @coefs gives you a t-statistic for fixed effects too... you could 
>>> take a stab at an approximated df method and compute an 
>>> (approximated) p-value.
>>> I know that doing so can attract a lot of criticism in this list, but 
>>> when you are fitting a several million models (10000s of transcripts 
>>> and 1000s of genomic positions as in my case), the mcmc approximation 
>>> is (unfortunately) not computationally feasible.
>>>
>>>
>>> Hope this helps!
>>> JP
>>>
>>>
>>>
>>> Paolo Innocenti wrote:
>>>> Dear Douglas and list,
>>>>
>>>> I am thinking about fitting a mixed model for a microarray 
>>>> experiment using lme4, since other specific software seems not 
>>>> suitable for my purposes. I'll briefly describe the model and kindly 
>>>> ask for suggestions on the model and the workflow I can use to get 
>>>> useful results.
>>>>
>>>> My response variable Y is gene expression levels for a given gene 
>>>> (say g_i) from 120 samples.
>>>> The factor I want to include are:
>>>>
>>>> Sex: fixed, two levels, M/F.
>>>> Line: 15 randomly picked genotypes from a large outbred population.
>>>>
>>>> I am interested in:
>>>> - if the gene is differentially expressed in the 2 sexes (effect of 
>>>> sex), in the 15 lines (effect of line) and the interaction of the two.
>>>>
>>>> - the variance component of line = how much of the variance is due 
>>>> to the genotype
>>>>
>>>> - the variance component of the interaction = the genetic variation 
>>>> for sexual dimorphism.
>>>>
>>>> Reading a bit of this mailing list, I came up with these three models:
>>>>
>>>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>>>>
>>>> or
>>>>
>>>> m2 <- lmer(Y1 ~ sex + (sex|line))
>>>>
>>>> or
>>>>
>>>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>>>>
>>>> Which should all be the same model (and indeed they have all the 
>>>> same residuals) but different parametrization (see self-contained 
>>>> example below).
>>>>
>>>> Now, in the light of my needs (see above), which model makes it 
>>>> easier to extract the components I need? Also, do they make 
>>>> different assumptions - as different levels of independency among 
>>>> levels of random factors?
>>>>
>>>> I will need to be able to extract the variance component values in 
>>>> an iterative process (i have 18.000 genes): is VarCorr() the way to go?
>>>>
>>>> VarCorr(m1)$'sex:line'[1]
>>>> VarCorr(m1)$'line'[1]
>>>>
>>>> Last two question: what is the easier way to assess, in an iterative 
>>>> process, normality of residuals, and what is a sensible way to 
>>>> assess significant differential expression of genes (since I guess I 
>>>> can't get p-values and then apply FDR correction?)
>>>>
>>>> Thanks a lot for reading so far and I'll be grateful for any kind of 
>>>> help.
>>>> paolo
>>>>
>>>> Self-contained example:
>>>>
>>>> Y1 <- as.numeric(
>>>> c("11.6625","11.3243","11.7819","11.5032","11.7578","11.9379","11.8491", 
>>>>
>>>> "11.9035","11.2042","11.0344","11.5137","11.1995","11.6327","11.7392",
>>>> "11.9869","11.6955","11.5631","11.7159","11.8435","11.5814","12.0756",
>>>> "12.3428","12.3342","11.9883","11.6067","11.6102","11.6517","11.4444",
>>>> "11.9567","12.0478","11.9683","11.8207","11.5860","11.6028","11.6522",
>>>> "11.6775","12.3570","12.2266","12.2444","12.1369","11.2573","11.4577",
>>>> "11.4432","11.2994","11.8486","11.9258","11.9864","11.9964","11.2806",
>>>> "11.2527","11.3672","11.0791","11.9501","11.7223","11.9825","11.8114",
>>>> "11.6116","11.4284","11.3731","11.6942","12.2153","12.0101","12.2150",
>>>> "12.1932","11.5617","11.3761","11.4813","11.7503","11.9889","12.1530",
>>>> "12.3299","12.4436","11.4566","11.4614","11.5527","11.3513","11.9764",
>>>> "11.8810","12.0999","11.9083","11.4870","11.6764","11.3973","11.4507",
>>>> "12.1141","11.9906","12.1118","11.9728","11.3382","11.4146","11.4590",
>>>> "11.2527","12.1101","12.0448","12.2191","11.8317","11.3982","11.3555",
>>>> "11.3897","11.7731","11.9749","11.8666","12.1984","12.0350","11.4642",
>>>> "11.4509","11.5552","11.4346","12.0714","11.7136","11.9019","11.8158",
>>>> "11.3132","11.3121","11.1612","11.2073","11.6658","11.7879","11.7847",
>>>> "11.5300"))
>>>> sex <- factor(rep(c("F","M"), 15, each=4))
>>>> line <- factor(rep(1:15, each=8))
>>>> m1 <- lmer(Y1 ~ sex + (1|line) + (1|sex:line))
>>>> m2 <- lmer(Y1 ~ sex + (sex|line))
>>>> m3 <- lmer(Y1 ~ sex + (0 + sex|line))
>>>> VarCorr(m1)$'sex:line'[1]
>>>> VarCorr(m1)$'line'[1]
>>>>
>>>> Output:
>>>>
>>>>>> m1
>>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (1 | line) + (1 
>>>>> | sex:line)     AIC   BIC logLik deviance REMLdev
>>>>>  -91.13 -77.2  50.57   -111.1  -101.1
>>>>> Random effects:
>>>>>  Groups   Name        Variance  Std.Dev.
>>>>>  sex:line (Intercept) 0.0023237 0.048205
>>>>>  line     (Intercept) 0.0169393 0.130151
>>>>>  Residual             0.0168238 0.129707
>>>>> Number of obs: 120, groups: sex:line, 30; line, 15
>>>>>
>>>>> Fixed effects:
>>>>>             Estimate Std. Error t value
>>>>> (Intercept) 11.45977    0.03955  289.72
>>>>> sexM         0.52992    0.02951   17.96
>>>>>
>>>>> Correlation of Fixed Effects:
>>>>>      (Intr)
>>>>> sexM -0.373
>>>>>> m2
>>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (sex | line) 
>>>>>  AIC    BIC logLik deviance REMLdev
>>>>>  -90 -73.27     51   -112.1    -102
>>>>> Random effects:
>>>>>  Groups   Name        Variance  Std.Dev. Corr   line     
>>>>> (Intercept) 0.0152993 0.123691                 sexM        
>>>>> 0.0046474 0.068172 0.194  Residual             0.0168238 
>>>>> 0.129707       Number of obs: 120, groups: line, 15
>>>>>
>>>>> Fixed effects:
>>>>>             Estimate Std. Error t value
>>>>> (Intercept) 11.45977    0.03606   317.8
>>>>> sexM         0.52992    0.02951    18.0
>>>>>
>>>>> Correlation of Fixed Effects:
>>>>>      (Intr)
>>>>> sexM -0.161
>>>>>> m3
>>>>> Linear mixed model fit by REML Formula: Y1 ~ sex + (0 + sex | line) 
>>>>>  AIC    BIC logLik deviance REMLdev
>>>>>  -90 -73.27     51   -112.1    -102
>>>>> Random effects:
>>>>>  Groups   Name Variance Std.Dev. Corr   line     sexF 0.015299 
>>>>> 0.12369                  sexM 0.023227 0.15240  0.899  
>>>>> Residual      0.016824 0.12971        Number of obs: 120, groups: 
>>>>> line, 15
>>>>>
>>>>> Fixed effects:
>>>>>             Estimate Std. Error t value
>>>>> (Intercept) 11.45977    0.03606   317.8
>>>>> sexM         0.52991    0.02951    18.0
>>>>>
>>>>> Correlation of Fixed Effects:
>>>>>      (Intr)
>>>>> sexM -0.161
>>>>
>>>>
>>>>
>>>
>>>
>>
> 
> 

-- 
Paolo Innocenti
Department of Animal Ecology, EBC
Uppsala University
Norbyv?gen 18D
75236 Uppsala, Sweden



From jeroenooms at gmail.com  Sat Jun  6 19:03:01 2009
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sat, 6 Jun 2009 19:03:01 +0200
Subject: [R-sig-ME] Fixed effects only model with lme4
Message-ID: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090606/dfabeaf4/attachment.pl>

From bates at stat.wisc.edu  Sat Jun  6 19:49:37 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 6 Jun 2009 12:49:37 -0500
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
Message-ID: <40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>

On Sat, Jun 6, 2009 at 12:03 PM, Jeroen Ooms<jeroenooms at gmail.com> wrote:
> For my GUI, I would like the user to be able to compare a fixed effects
> model with a random effects model. For example:
> fm0 <- lmer(Reaction ~ Days, sleepstudy);
> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
> anova(fm0,fm1);
>
> However, this returns the obvious "No random effects terms specified in
> formula" error for the first model. I've also tried fitting the fixed
> effects model with lm:
>
> fm0 <- lm(Reaction ~ Days, sleepstudy);
> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
> anova(fm0,fm1);

Try listing them the other way around

anova(fm1, fm0)

If the first model in the call to anova is of class "lm" then the
method for that class is the one chosen and that method doesn't know
about models created by lmer.  You must list them so that the lmer
model comes first.

>
> However, now the anova function starts complaining. Is there a way to
> perform variance analysis on a fixed only model and a random effects model,
> similar to comparing two random effects models?
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jeroenooms at gmail.com  Sat Jun  6 19:57:46 2009
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sat, 6 Jun 2009 19:57:46 +0200
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com> 
	<40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
Message-ID: <673e1b980906061057h4caf2ef0u81ccdff223c66ec1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090606/5f778e7d/attachment.pl>

From rmh3093 at gmail.com  Sat Jun  6 20:45:09 2009
From: rmh3093 at gmail.com (Ryan Hope)
Date: Sat, 6 Jun 2009 14:45:09 -0400
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <673e1b980906061057h4caf2ef0u81ccdff223c66ec1@mail.gmail.com>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
	<40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
	<673e1b980906061057h4caf2ef0u81ccdff223c66ec1@mail.gmail.com>
Message-ID: <48f7fe350906061145l1cec6006ib089c917988c8b88@mail.gmail.com>

lmer requires a random effect's term so I doubt you can compare a lm
object to a lmer object

On 6/6/09, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> 2009/6/6 Douglas Bates <bates at stat.wisc.edu>
>
>>
>>
>> Try listing them the other way around
>>
>> anova(fm1, fm0)
>>
>> If the first model in the call to anova is of class "lm" then the
>> method for that class is the one chosen and that method doesn't know
>> about models created by lmer.  You must list them so that the lmer
>> model comes first.
>
>
> this still returns an error:
>> fm0 <- lm(Reaction ~ Days, sleepstudy);
>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
>> anova(fm0,fm1);
> Error in x$terms : $ operator not defined for this S4 class
>
>> anova(fm1,fm0);
> Error in FUN(X[[1L]], ...) :
>   no slot of name "call" for this object of class "lm"
>
> similar error if I use glm instead of lm.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Sat Jun  6 19:51:30 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 06 Jun 2009 13:51:30 -0400
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
Message-ID: <4A2AACA2.6000700@ufl.edu>

 I think you can do this with Fabian Scheipl's package RLRsim (which,
more importantly than the convenience details of setting up the
likelihood ratio test, addresses the deeper issues of inference in this
case).
Also see http://glmm.wikidot.com/reef-fish (search for "be careful").

Jeroen Ooms wrote:
> For my GUI, I would like the user to be able to compare a fixed effects
> model with a random effects model. For example:
> fm0 <- lmer(Reaction ~ Days, sleepstudy);
> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
> anova(fm0,fm1);
> 
> However, this returns the obvious "No random effects terms specified in
> formula" error for the first model. I've also tried fitting the fixed
> effects model with lm:
> 
> fm0 <- lm(Reaction ~ Days, sleepstudy);
> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
> anova(fm0,fm1);
> 
> However, now the anova function starts complaining. Is there a way to
> perform variance analysis on a fixed only model and a random effects model,
> similar to comparing two random effects models?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Sat Jun  6 19:53:14 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 06 Jun 2009 13:53:14 -0400
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
	<40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
Message-ID: <4A2AAD0A.2050408@ufl.edu>

  Be careful.  I'm not sure that the likelihoods as calculated
by lm and lmer have the same additive constants/are directly
comparable ... (see link in previous message).

Douglas Bates wrote:
> On Sat, Jun 6, 2009 at 12:03 PM, Jeroen Ooms<jeroenooms at gmail.com> wrote:
>> For my GUI, I would like the user to be able to compare a fixed effects
>> model with a random effects model. For example:
>> fm0 <- lmer(Reaction ~ Days, sleepstudy);
>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
>> anova(fm0,fm1);
>>
>> However, this returns the obvious "No random effects terms specified in
>> formula" error for the first model. I've also tried fitting the fixed
>> effects model with lm:
>>
>> fm0 <- lm(Reaction ~ Days, sleepstudy);
>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
>> anova(fm0,fm1);
> 
> Try listing them the other way around
> 
> anova(fm1, fm0)
> 
> If the first model in the call to anova is of class "lm" then the
> method for that class is the one chosen and that method doesn't know
> about models created by lmer.  You must list them so that the lmer
> model comes first.
> 
>> However, now the anova function starts complaining. Is there a way to
>> perform variance analysis on a fixed only model and a random effects model,
>> similar to comparing two random effects models?
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From charpent at bacbuc.dyndns.org  Sat Jun  6 23:49:05 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Sat, 06 Jun 2009 23:49:05 +0200
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
	<40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
Message-ID: <1244324944.5154.24.camel@yod>

Dear Pr Bates,

Le samedi 06 juin 2009 ? 12:49 -0500, Douglas Bates a ?crit :
> On Sat, Jun 6, 2009 at 12:03 PM, Jeroen Ooms<jeroenooms at gmail.com> wrote:
> > For my GUI, I would like the user to be able to compare a fixed effects
> > model with a random effects model. For example:
> > fm0 <- lmer(Reaction ~ Days, sleepstudy);
> > fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
> > anova(fm0,fm1);
> >
> > However, this returns the obvious "No random effects terms specified in
> > formula" error for the first model. I've also tried fitting the fixed
> > effects model with lm:
> >
> > fm0 <- lm(Reaction ~ Days, sleepstudy);
> > fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
> > anova(fm0,fm1);
> 
> Try listing them the other way around
> 
> anova(fm1, fm0)
> 
> If the first model in the call to anova is of class "lm" then the
> method for that class is the one chosen and that method doesn't know
> about models created by lmer.  You must list them so that the lmer
> model comes first.

You could do that ... with lme objects. As explained by the OP, this no
longer works with lmer objects.

One may always extract deviances and substract, and make rash hypotheses
in difference in numerator DFs, but, while this should work (= give
expected results) with lm and gaussian objects, nothing guarantees that
glm and lmer use the same parametrizations for non-gaussian models (the
GLM chapter in V&R4 states that deviances are computed up to an additive
constant. I tried to follow lmer code, but quickly got lost in C
code...).

May this join your (already well-grown) wishlist (along with
deviance/likelihood under arbitrary parameters, maybe :-) ?

Sincerely,

					Emmanuel Charpentier



From bolker at ufl.edu  Sun Jun  7 01:59:56 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 06 Jun 2009 19:59:56 -0400
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <673e1b980906061057h4caf2ef0u81ccdff223c66ec1@mail.gmail.com>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>
	<40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
	<673e1b980906061057h4caf2ef0u81ccdff223c66ec1@mail.gmail.com>
Message-ID: <4A2B02FC.8030609@ufl.edu>

  *If* you could trust that the log-likelihoods were generated using the
same additive constants in both cases (which I don't think you can), and
*if* you could trust the straight LRT for comparisons of random effects
(see Pinheiro and Bates 2000, Scheipl, etc., for why it is really closer
to a chi-squared mixture between 0 and 1 df) then you could use logLik()
to extract the loglikelihoods of both models and
pchisq(...,df=1,lower.tail=TRUE) to get a p-value (or divide that
p-value by 2 to use a 0/1-df chi-squared mixture).

  Ben Bolker

Jeroen Ooms wrote:
> 2009/6/6 Douglas Bates <bates at stat.wisc.edu>
> 
>>
>> Try listing them the other way around
>>
>> anova(fm1, fm0)
>>
>> If the first model in the call to anova is of class "lm" then the
>> method for that class is the one chosen and that method doesn't know
>> about models created by lmer.  You must list them so that the lmer
>> model comes first.
> 
> 
> this still returns an error:
>> fm0 <- lm(Reaction ~ Days, sleepstudy);
>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
>> anova(fm0,fm1);
> Error in x$terms : $ operator not defined for this S4 class
> 
>> anova(fm1,fm0);
> Error in FUN(X[[1L]], ...) :
>   no slot of name "call" for this object of class "lm"
> 
> similar error if I use glm instead of lm.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Sun Jun  7 02:08:12 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 06 Jun 2009 20:08:12 -0400
Subject: [R-sig-ME] Fixed effects only model with lme4
In-Reply-To: <1244324944.5154.24.camel@yod>
References: <673e1b980906061003xc215798q5addef996a465094@mail.gmail.com>	<40e66e0b0906061049x10e3ca49v70f791c495fd10f0@mail.gmail.com>
	<1244324944.5154.24.camel@yod>
Message-ID: <4A2B04EC.7070103@ufl.edu>

 A quick hack to compute a likelihood profile, for changing
random-effects variances.  A slight special case is to compute the
likelihood of a model with variance of the random effect set to zero.
This works only for a single-random-effect model, and is pulled from
code in Doug Bates's vignette.  In the past this would have dangerously
modified your original model, but I think that's fixed now.

   Other glmm hacks are available at
http://glmm.wikidot.com/local--files/reef-fish/glmmfuns.R

  I would be happy to hear about extensions or corrections.

  cheers
    Ben Bolker

## extract likelihood based on zero variance for a single random
##  effect
zerodev <- function(mm) {
  varprof(mm,0,0,1)[["ML"]]
}

varprof <- function(mm,lower=0,upper=20,n=101) {
  sg <- seq(lower, upper, len = n)
  orig.sd <- attr(VarCorr(mm)[[1]],"stddev")
  dev <- mm at deviance
  nc <- length(dev)
  nms <- names(dev)
  vals <- matrix(0, nrow = length(sg), ncol = nc, dimnames = list(NULL,
nms))
  update_dev <- function(sd) {
    .Call("mer_ST_setPars", mm, sd, PACKAGE = "lme4")
    .Call("mer_update_L", mm, PACKAGE = "lme4")
    res <- try(.Call("mer_update_RX", mm, PACKAGE = "lme4"), silent = TRUE)
    if (inherits(res, "try-error")) {
      val <- NA
    } else {
      .Call("mer_update_ranef", mm, PACKAGE = "lme4")
      .Call("mer_update_dev", mm, PACKAGE = "lme4") ## added for glmmML
      val <- mm at deviance
    }
    val
  }
  for (i in seq(along = sg)) {
      vals[i,] <- update_dev(sg[i])
    }
  update_dev(orig.sd) ## hack! to restore original sd
  data.frame(sd=sg,vals)
}


Emmanuel Charpentier wrote:
> Dear Pr Bates,
> 
> Le samedi 06 juin 2009 ? 12:49 -0500, Douglas Bates a ?crit :
>> On Sat, Jun 6, 2009 at 12:03 PM, Jeroen Ooms<jeroenooms at gmail.com> wrote:
>>> For my GUI, I would like the user to be able to compare a fixed effects
>>> model with a random effects model. For example:
>>> fm0 <- lmer(Reaction ~ Days, sleepstudy);
>>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
>>> anova(fm0,fm1);
>>>
>>> However, this returns the obvious "No random effects terms specified in
>>> formula" error for the first model. I've also tried fitting the fixed
>>> effects model with lm:
>>>
>>> fm0 <- lm(Reaction ~ Days, sleepstudy);
>>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy);
>>> anova(fm0,fm1);
>> Try listing them the other way around
>>
>> anova(fm1, fm0)
>>
>> If the first model in the call to anova is of class "lm" then the
>> method for that class is the one chosen and that method doesn't know
>> about models created by lmer.  You must list them so that the lmer
>> model comes first.
> 
> You could do that ... with lme objects. As explained by the OP, this no
> longer works with lmer objects.
> 
> One may always extract deviances and substract, and make rash hypotheses
> in difference in numerator DFs, but, while this should work (= give
> expected results) with lm and gaussian objects, nothing guarantees that
> glm and lmer use the same parametrizations for non-gaussian models (the
> GLM chapter in V&R4 states that deviances are computed up to an additive
> constant. I tried to follow lmer code, but quickly got lost in C
> code...).
> 
> May this join your (already well-grown) wishlist (along with
> deviance/likelihood under arbitrary parameters, maybe :-) ?
> 
> Sincerely,
> 
> 					Emmanuel Charpentier
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From jeroenooms at gmail.com  Mon Jun  8 13:04:29 2009
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 8 Jun 2009 13:04:29 +0200
Subject: [R-sig-ME] Rasch with lme4
Message-ID: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090608/7d86dc7d/attachment.pl>

From reinhold.kliegl at gmail.com  Mon Jun  8 17:00:08 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 8 Jun 2009 17:00:08 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
Message-ID: <12C80D7D-5940-4B41-93A1-CAB8F6F6372B@gmail.com>

  Conditional modes (generated from the model parameters and the data)  
are not independent observations. Therefore, only the second method is  
valid.

Reinhold Kliegl

On 08.06.2009, at 13:04, Jeroen Ooms wrote:

> I have tried to use lme4 to analyze IRT like datasets, but now I am
> confused. I have a data set with intelligence items (i.e. score 0 or  
> 1), for
> completely crossed subjects and items. Furthermore, the data  
> contains some
> personality scores on the subject level. Actually the data is more
> complicated than this, but let's keep it simple for now. My research
> question is whether a personality charcteristic, say extraversion, is
> related to intelligence. My question is how I should incorporate the
> extraversion variable in the analysis.
> When I analyse this data using the Rasch model, I usually first fit  
> the
> model, then extract the 'latent trait scores', and relate these to the
> extraversion scores. I could do the same with lmer:
>
> myModel <- lmer(y~1+(1|item)+(1|subject),data=mydata,  
> family=binomial);
> intelligence <- ranef(myModel)$subject[[1]];
> lm(intelligence~extraversion);
>
> However, in the context of multilevel analysis, it is also possible to
> incorporate the extraversion variable directly into the model:
>
> myModel2 <- lmer(y~1+(1|item)+(1|subject)+extraversion,data=mydata,
> family=binomial);
>
> Conceptually both methods feel very similar, but they give different
> results. What is the most appropriate method? What are the  
> differences in
> interpretation?
>
> Thank you!
>
> Jeroen
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ken at kjbeath.com.au  Tue Jun  9 00:04:16 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Tue, 9 Jun 2009 08:04:16 +1000
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
Message-ID: <AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>

The model treats item as a random effect and should be a fixed effect.

A problem with the first model is that the random effect estimates are  
treated as though they were measured without error, when aren't. This  
results in attenuation of the parameter estimate. On teh other hand  
people use it and find it OK. A better method is to use modern SEM  
software that handles binary variables.

At a first glance Model 2 seems sensible.

Another question to ask is whether the Rasch model is appropriate. If  
an IRT is more sensible it would cause some problems with the second  
model.

Ken

On 08/06/2009, at 9:04 PM, Jeroen Ooms wrote:

> I have tried to use lme4 to analyze IRT like datasets, but now I am
> confused. I have a data set with intelligence items (i.e. score 0 or  
> 1), for
> completely crossed subjects and items. Furthermore, the data  
> contains some
> personality scores on the subject level. Actually the data is more
> complicated than this, but let's keep it simple for now. My research
> question is whether a personality charcteristic, say extraversion, is
> related to intelligence. My question is how I should incorporate the
> extraversion variable in the analysis.
> When I analyse this data using the Rasch model, I usually first fit  
> the
> model, then extract the 'latent trait scores', and relate these to the
> extraversion scores. I could do the same with lmer:
>
> myModel <- lmer(y~1+(1|item)+(1|subject),data=mydata,  
> family=binomial);
> intelligence <- ranef(myModel)$subject[[1]];
> lm(intelligence~extraversion);
>
> However, in the context of multilevel analysis, it is also possible to
> incorporate the extraversion variable directly into the model:
>
> myModel2 <- lmer(y~1+(1|item)+(1|subject)+extraversion,data=mydata,
> family=binomial);
>
> Conceptually both methods feel very similar, but they give different
> results. What is the most appropriate method? What are the  
> differences in
> interpretation?
>
> Thank you!
>
> Jeroen
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From David.Duffy at qimr.edu.au  Tue Jun  9 00:09:48 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 9 Jun 2009 08:09:48 +1000 (EST)
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <12C80D7D-5940-4B41-93A1-CAB8F6F6372B@gmail.com>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<12C80D7D-5940-4B41-93A1-CAB8F6F6372B@gmail.com>
Message-ID: <Pine.LNX.4.64.0906090751240.11866@orpheus.qimr.edu.au>

On Mon, 8 Jun 2009, Reinhold Kliegl wrote:

> Conditional modes (generated from the model parameters and the data) are not 
> independent observations. Therefore, only the second method is valid.
>
> Reinhold Kliegl
>
> On 08.06.2009, at 13:04, Jeroen Ooms wrote:
>
>> I have tried to use lme4 to analyze IRT like datasets, but now I am
>> confused. I have a data set with intelligence items (i.e. score 0 or 1), 
>> for
>> completely crossed subjects and items. Furthermore, the data contains some
>> personality scores on the subject level. Actually the data is more
>> complicated than this, but let's keep it simple for now. My research
>> question is whether a personality charcteristic, say extraversion, is
>> related to intelligence. My question is how I should incorporate the
>> extraversion variable in the analysis.
>> When I analyse this data using the Rasch model, I usually first fit the
>> model, then extract the 'latent trait scores', and relate these to the
>> extraversion scores. I could do the same with lmer:
>> 
>> myModel <- lmer(y~1+(1|item)+(1|subject),data=mydata, family=binomial);
>> intelligence <- ranef(myModel)$subject[[1]];
>> lm(intelligence~extraversion);
>> 
>> However, in the context of multilevel analysis, it is also possible to
>> incorporate the extraversion variable directly into the model:
>> 
>> myModel2 <- lmer(y~1+(1|item)+(1|subject)+extraversion,data=mydata,
>> family=binomial);
>> 
>> Conceptually both methods feel very similar, but they give different
>> results. What is the most appropriate method? What are the differences in
>> interpretation?
>

Aside from Reinhold's comment, which is not a showstopper (you could 
bootstrap etc), they are quite different models. In the first model, the 
estimated IQ-extraversion correlation is disattenuated for measurement 
error -- the equivalent SEMs are something like (I think ;)):


IQ <-----> E  v.   E
| \                | \
v  v               v  v
i1 i2              i1 i2
                    ^  ^
                    | /
                    IQ

Most people would prefer something like the first model, and in fact would
estimate the correlation between IQ and E estimated (as if without error) 
from two measurement models given by the scoring rules for the 
instruments (these are essentially BLUPs).  Incorporating measurement 
error for both measures is the truest way to do it.

You could compare results using the sem and polycor packages to those from 
your lmer model.

my 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From s-luppescu at uchicago.edu  Tue Jun  9 00:58:47 2009
From: s-luppescu at uchicago.edu (Stuart Luppescu)
Date: Mon, 08 Jun 2009 17:58:47 -0500
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
Message-ID: <1244501927.10505.9.camel@musuko.spc.uchicago.edu>

On ?, 2009-06-09 at 08:04 +1000, Ken Beath wrote:
> The model treats item as a random effect and should be a fixed effect.

Hmm. In Doran, Bates, Bliese and Dowling (2007), the authors treat the
item as random. 

[snip]
> Another question to ask is whether the Rasch model is appropriate. If
> an IRT is more sensible it would cause some problems with the second  
> model.

Sorry, but I don't understand this at all.

-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 2.6.28-gentoo-r5                
Drusilla: How do you feel about eternal life? 
 Xander: We couldn't just start with coffee?  
 
 
 
 
 
 
 



From ral at lcfltd.com  Tue Jun  9 01:00:03 2009
From: ral at lcfltd.com (Robert A. LaBudde)
Date: Mon, 08 Jun 2009 19:00:03 -0400
Subject: [R-sig-ME] Confidence intervals for effects in glmer()
Message-ID: <0KKX00516ZWBY4P3@vms173019.mailsrvcs.net>

This may be blindingly obvious to the casual observer, but I'm 
chagrined to admit I'm stumped.

I'm fitting a simple mixed effect logistic model using 'lme4':

require('lme4')
fit4<- glmer(x ~ 1 + 1|lab, data=eg, nAGQ=5, family='binomial')
summary(fit4)
ranef(fit4)

I would like 95% confidence intervals on 'lab' and the residuals effects.

Using lme() in 'nlme', I had the function intervals() available. Now I don't.

Any hints to de-perplex a novice?

Thanks.
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From reinhold.kliegl at gmail.com  Tue Jun  9 01:06:30 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 9 Jun 2009 01:06:30 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <Pine.LNX.4.64.0906090751240.11866@orpheus.qimr.edu.au>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<12C80D7D-5940-4B41-93A1-CAB8F6F6372B@gmail.com>
	<Pine.LNX.4.64.0906090751240.11866@orpheus.qimr.edu.au>
Message-ID: <FABF4F1D-8B47-419D-A56F-43A448B8F3D8@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090609/7948e70b/attachment.pl>

From bolker at ufl.edu  Tue Jun  9 01:40:10 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 08 Jun 2009 19:40:10 -0400
Subject: [R-sig-ME] Confidence intervals for effects in glmer()
In-Reply-To: <0KKX00516ZWBY4P3@vms173019.mailsrvcs.net>
References: <0KKX00516ZWBY4P3@vms173019.mailsrvcs.net>
Message-ID: <4A2DA15A.8070205@ufl.edu>

  It depends on what approximations you're willing to accept.

  Crudely doing +/- 2 standard deviations, or (DANGER DANGER)
using the 'known' df to compute t-scores (the "gm1" example
given in ?glmer has a fairly straightforward structure, with
15 groups):

library(lme4)
example(glmer)
s <- summary(gm1)@coefs

fac <- 2
s[,"Estimate"]+fac*outer(c(-1,1),s[,"Std. Error"])

fac <- qt(0.975,df=14)
s[,"Estimate"]+fac*outer(c(-1,1),s[,"Std. Error"])


  Does anyone know the current status of mcmcsamp,
either for LMMs or for GLMMs ... ?

  Ben Bolker

Robert A. LaBudde wrote:
> This may be blindingly obvious to the casual observer, but I'm 
> chagrined to admit I'm stumped.
> 
> I'm fitting a simple mixed effect logistic model using 'lme4':
> 
> require('lme4')
> fit4<- glmer(x ~ 1 + 1|lab, data=eg, nAGQ=5, family='binomial')
> summary(fit4)
> ranef(fit4)
> 
> I would like 95% confidence intervals on 'lab' and the residuals effects.
> 
> Using lme() in 'nlme', I had the function intervals() available. Now I don't.
> 
> Any hints to de-perplex a novice?
> 
> Thanks.
> ================================================================
> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
> 824 Timberlake Drive                     Tel: 757-467-0954
> Virginia Beach, VA 23464-3239            Fax: 757-467-2947
> 
> "Vere scire est per causas scire"
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From HDoran at air.org  Tue Jun  9 01:53:52 2009
From: HDoran at air.org (Doran, Harold)
Date: Mon, 8 Jun 2009 19:53:52 -0400
Subject: [R-sig-ME] Rasch with lme4
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com><AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01C64B2B@DC1EXCL01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090608/b816609b/attachment.pl>

From David.Duffy at qimr.edu.au  Tue Jun  9 06:38:40 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 9 Jun 2009 14:38:40 +1000 (EST)
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <FABF4F1D-8B47-419D-A56F-43A448B8F3D8@gmail.com>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<12C80D7D-5940-4B41-93A1-CAB8F6F6372B@gmail.com>
	<Pine.LNX.4.64.0906090751240.11866@orpheus.qimr.edu.au>
	<FABF4F1D-8B47-419D-A56F-43A448B8F3D8@gmail.com>
Message-ID: <Pine.LNX.4.64.0906091143380.20917@orpheus.qimr.edu.au>

On Tue, 9 Jun 2009, Reinhold Kliegl wrote:

>
> On 09.06.2009, at 00:09, David Duffy wrote:
>
>> On Mon, 8 Jun 2009, Reinhold Kliegl wrote:
>> 
>>> Conditional modes (generated from the model parameters and the data) are 
>>> not independent observations. Therefore, only the second method is valid.
>>> 
>>>> myModel <- lmer(y~1+(1|item)+(1|subject),data=mydata, family=binomial);
>>>> intelligence <- ranef(myModel)$subject[[1]];
>>>> lm(intelligence~extraversion);

versus

>>>> myModel2 <- lmer(y~1+(1|item)+(1|subject)+extraversion,data=mydata,
>>>> family=binomial);

>> Most people would prefer something like the first model, and in fact would
>> estimate the correlation between IQ and E estimated (as if without error) 
>> from two measurement models given by the scoring rules for the instruments 
>> (these are essentially BLUPs).  Incorporating measurement error for both 
>> measures is the truest way to do it.
>> 
> Always interested to be corrected...
>
> My comment was referring to the use of conditional modes (formerly known as 
> BLUPs)--extracted with ranef()--not bootstrap or SEM. Not sure to what degree 
> these alternatives correspond to the use of conditional modes.  As far as 
> conditional modes are concerned, we (Kliegl, Masson, & Richter)  have a paper 
> in press (available at my publication page), in which we write the following:
>
> To this end, we 
> generated 100,000 sets of data for a simple LMM model including 30 ?subjects? 
> and a predictor with 10 levels, conforming to a known variance for intercept 
> and slope across subjects and varying the true correlation between these 
> parameters from -0.9 to +0.9 in 2,000 steps (i.e., each simulation used a 
> different correlation). ...
> ... [C]onditional means underestimate variances and exaggerate covariances 
> and correlations. The shrinkage of variance reflects the contribution of the 
> likelihood in the computation of conditional means. Shrinkage correction for 
> predictions leads to dampening of the variance components, but, as we have 
> shown in this section, not of the associated covariance component. The 
> shrinkage of variance prevents overfitting of unreliable data but, as a 
> curious side effect, the "correlations" based on conditional means for 
> individual subjects are larger in absolute value than the corresponding LMM 
> estimates of the correlation.
>

Well I'm not sure how much that reflects the specific model you have 
simulated, and I don't have the time right now to do simulations based on 
the original poster's setup.  (I have experienced your problems with 
shrinkage etc in a simple minded attempt to carry out genetic linkage 
analysis of breeding values (BLUPs) estimated from the same pedigree). 
And I would concur with your postscript.  And I will study your paper with 
great interest.

However, the impression I have is that usually the effects of just 
plugging in the factor scores when they are based on, say, 20 or 30 
individual items with a straightforward structure are not too misleading, 
and are just what people have been doing for the last 50 years. I am 
currently comparing results from a two-stage mixed model analysis of BLUPs 
from an IRT (carried out in BUGS) analysis of multiple ordinal measures 
adjusting for multiple fixed covariates to results of analyses I am performing on the 
original variables.  I have not seen any major inconsistencies, but I will 
look for effects of the type you have described.

Colleagues have examined the multitrait mixed model analysis of pedigree 
data using the full analysis and compared it to using BLUPs:

Dorret I. Boomsma and Conor V. Dolan (1998).  A Comparison of Power to 
Detect a QTL in Sib-Pair Data Using Multivariate Phenotypes, Mean 
Phenotypes, and Factor Scores. Behavior Genetics 28: 329-340

They found in their simulations that there was "negligible overestimation" 
of the genetic covariance in models where they split the sample in two, 
using one-half to generate the prediction model, which was applied to the 
other half to generate the BLUPs, and then vice-versa.

My specific comment was based on an impression that that the second model 
with Extraversion as a fixed effect doesn't give the original poster what 
he is interested in, viz an assessment of the relationship between two 
(imperfectly measured) psychological traits: IQ and E.

I find it a bit confusing, but the test of the single regression 
coefficient for Extraversion in the second model seems to me to be 
different from the that in the first.  Specifically, the E->IQ->item(1..N) 
model constrains the pattern of expected covariation between E and any 
one IQ item differently from the fixed effects model.

Finally, multiple imputation type methods are one way people get around 
these types of problems, as a full maximum likelihood analysis is often 
expensive computationally (with a multimodal likelihood surface). I don't 
think a simple bootstrap resampling repeatedly calling lmer and raneff 
would get around the biases you have noted.

Cheers, David Duffy

PS The OP may be aware of work of my colleagues on this particular topic:
http://genepi.qimr.edu.au/contents/p/staff/CV516.pdf

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From reinhold.kliegl at gmail.com  Tue Jun  9 11:28:10 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 9 Jun 2009 11:28:10 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <Pine.LNX.4.64.0906091143380.20917@orpheus.qimr.edu.au>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<12C80D7D-5940-4B41-93A1-CAB8F6F6372B@gmail.com>
	<Pine.LNX.4.64.0906090751240.11866@orpheus.qimr.edu.au>
	<FABF4F1D-8B47-419D-A56F-43A448B8F3D8@gmail.com>
	<Pine.LNX.4.64.0906091143380.20917@orpheus.qimr.edu.au>
Message-ID: <aefe4d0a0906090228l44caaab9o38017d62a34a805e@mail.gmail.com>

On Tue, Jun 9, 2009 at 6:38 AM, David Duffy<David.Duffy at qimr.edu.au> wrote:
> On Tue, 9 Jun 2009, Reinhold Kliegl wrote:
>
>>
>> On 09.06.2009, at 00:09, David Duffy wrote:
>>
>>> On Mon, 8 Jun 2009, Reinhold Kliegl wrote:
>>>
>>>> Conditional modes (generated from the model parameters and the data) are
>>>> not independent observations. Therefore, only the second method is valid.
>>>>
>>>>> myModel <- lmer(y~1+(1|item)+(1|subject),data=mydata, family=binomial);
>>>>> intelligence <- ranef(myModel)$subject[[1]];
>>>>> lm(intelligence~extraversion);
>
> versus
>
>>>>> myModel2 <- lmer(y~1+(1|item)+(1|subject)+extraversion,data=mydata,
>>>>> family=binomial);
>
>>> Most people would prefer something like the first model, and in fact
>>> would
>>> estimate the correlation between IQ and E estimated (as if without error)
>>> from two measurement models given by the scoring rules for the instruments
>>> (these are essentially BLUPs). ?Incorporating measurement error for both
>>> measures is the truest way to do it.
>>>
>> Always interested to be corrected...
>>
>> My comment was referring to the use of conditional modes (formerly known
>> as BLUPs)--extracted with ranef()--not bootstrap or SEM. Not sure to what
>> degree these alternatives correspond to the use of conditional modes. ?As
>> far as conditional modes are concerned, we (Kliegl, Masson, & Richter) ?have
>> a paper in press (available at my publication page), in which we write the
>> following:
>>
>> To this end, we generated 100,000 sets of data for a simple LMM model
>> including 30 ?subjects? and a predictor with 10 levels, conforming to a
>> known variance for intercept and slope across subjects and varying the true
>> correlation between these parameters from -0.9 to +0.9 in 2,000 steps (i.e.,
>> each simulation used a different correlation). ...
>> ... [C]onditional means underestimate variances and exaggerate covariances
>> and correlations. The shrinkage of variance reflects the contribution of the
>> likelihood in the computation of conditional means. Shrinkage correction for
>> predictions leads to dampening of the variance components, but, as we have
>> shown in this section, not of the associated covariance component. The
>> shrinkage of variance prevents overfitting of unreliable data but, as a
>> curious side effect, the "correlations" based on conditional means for
>> individual subjects are larger in absolute value than the corresponding LMM
>> estimates of the correlation.
>>
>
> Well I'm not sure how much that reflects the specific model you have
> simulated, and I don't have the time right now to do simulations based on
> the original poster's setup. ?(I have experienced your problems with
> shrinkage etc in a simple minded attempt to carry out genetic linkage
> analysis of breeding values (BLUPs) estimated from the same pedigree). And I
> would concur with your postscript. ?And I will study your paper with great
> interest.
>
> However, the impression I have is that usually the effects of just plugging
> in the factor scores when they are based on, say, 20 or 30 individual items
> with a straightforward structure are not too misleading, and are just what
> people have been doing for the last 50 years. I am currently comparing
> results from a two-stage mixed model analysis of BLUPs from an IRT (carried
> out in BUGS) analysis of multiple ordinal measures adjusting for multiple
> fixed covariates to results of analyses I am performing on the original
> variables. ?I have not seen any major inconsistencies, but I will look for
> effects of the type you have described.
>
> Colleagues have examined the multitrait mixed model analysis of pedigree
> data using the full analysis and compared it to using BLUPs:
>
> Dorret I. Boomsma and Conor V. Dolan (1998). ?A Comparison of Power to
> Detect a QTL in Sib-Pair Data Using Multivariate Phenotypes, Mean
> Phenotypes, and Factor Scores. Behavior Genetics 28: 329-340
>
> They found in their simulations that there was "negligible overestimation"
> of the genetic covariance in models where they split the sample in two,
> using one-half to generate the prediction model, which was applied to the
> other half to generate the BLUPs, and then vice-versa.
>
> My specific comment was based on an impression that that the second model
> with Extraversion as a fixed effect doesn't give the original poster what he
> is interested in, viz an assessment of the relationship between two
> (imperfectly measured) psychological traits: IQ and E.
>
> I find it a bit confusing, but the test of the single regression coefficient
> for Extraversion in the second model seems to me to be different from the
> that in the first. ?Specifically, the E->IQ->item(1..N) model constrains the
> pattern of expected covariation between E and any one IQ item differently
> from the fixed effects model.
>
> Finally, multiple imputation type methods are one way people get around
> these types of problems, as a full maximum likelihood analysis is often
> expensive computationally (with a multimodal likelihood surface). I don't
> think a simple bootstrap resampling repeatedly calling lmer and raneff would
> get around the biases you have noted.
>
> Cheers, David Duffy
>
> PS The OP may be aware of work of my colleagues on this particular topic:
> http://genepi.qimr.edu.au/contents/p/staff/CV516.pdf
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
>

You are correct that the models are not identical. I assume that the
problem of variance dampening of conditional modes will generalize to
the model under consideration, but one should simulate the specific
model--always a good idea until an analytic answer is available.

I also assumed the Jereon Oom's interest was in demonstrating a
relation between IQ and extroversion, irrespective of the specific
model. If the interest is in the specific correlation, there may
actually be an alternative. The sabreR package allows to estimate the
correlation between up to three dependent variables at the "subject"
level while at the same time allowing for the specification of a
"causal" path between them at the "observation" level (i.e., a
multivariate generalized linear mixed model). I think the
"correlation" model (i.e., m3 below) would be specified as follows:

attach(mydata)
m1 <- sabre(y ~ 1, case=subject, first.link="probit")
m1

m2 <- sabre(extroversion ~ 1, case=subject, first.family="gaussian")
m2

m3 <- sabre(y ~ 1 + extroversion,
                     extroversion ~ 1,
                     case=subject, first.family="binomial",
second.family="gaussian")
m3
detach()

m3 estimates (among other variance components)  a correlation between
the intercepts for y and extroversion across subjects.

The limitation is that sabreR does not allow the specification of
crossed random factors (i.e., of subjects and items). In this respect,
I agree with Harold Dolan on a different branch on this thread. Also
with sabreR you can only estimate the variance of the intercept of the
random effects, not the variance of the fixed effects (or their
associated covariances).  I should also say that I have only checked
out some of the examples in this package. So my experience is very
limited.

Reinhold Kliegl



From Kate.Pressland at bristol.ac.uk  Tue Jun  9 11:57:02 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Tue, 09 Jun 2009 10:57:02 +0100
Subject: [R-sig-ME] Confidence intervals for effects in glmer()
In-Reply-To: <4A2DA15A.8070205@ufl.edu>
References: <0KKX00516ZWBY4P3@vms173019.mailsrvcs.net>
	<4A2DA15A.8070205@ufl.edu>
Message-ID: <A28F975F69905F48B98D9F38@bio-mammal03.bio.bris.ac.uk>

Dear fellow novice,

I've used mcmc to estimate confidence intervals in lme4. You don't need the 
coda package as it's included in lme4 now. For you it would look like this:

fit4.mcmc<-mcmcsamp(fit4, n=1000) #or whatever resample number you think is 
appropriate
HPDinterval(fit4.mcmc)	#this will fit to alpha 0.05 as default.

As far as I am aware this is a fairly good method of estimating CIs in 
mixed models, but Ben are you saying that there may be issues with this 
process?

Kate

--On 08 June 2009 19:40 -0400 Ben Bolker <bolker at ufl.edu> wrote:

>   It depends on what approximations you're willing to accept.
>
>   Crudely doing +/- 2 standard deviations, or (DANGER DANGER)
> using the 'known' df to compute t-scores (the "gm1" example
> given in ?glmer has a fairly straightforward structure, with
> 15 groups):
>
> library(lme4)
> example(glmer)
> s <- summary(gm1)@coefs
>
> fac <- 2
> s[,"Estimate"]+fac*outer(c(-1,1),s[,"Std. Error"])
>
> fac <- qt(0.975,df=14)
> s[,"Estimate"]+fac*outer(c(-1,1),s[,"Std. Error"])
>
>
>   Does anyone know the current status of mcmcsamp,
> either for LMMs or for GLMMs ... ?
>
>   Ben Bolker
>
> Robert A. LaBudde wrote:
>> This may be blindingly obvious to the casual observer, but I'm
>> chagrined to admit I'm stumped.
>>
>> I'm fitting a simple mixed effect logistic model using 'lme4':
>>
>> require('lme4')
>> fit4<- glmer(x ~ 1 + 1|lab, data=eg, nAGQ=5, family='binomial')
>> summary(fit4)
>> ranef(fit4)
>>
>> I would like 95% confidence intervals on 'lab' and the residuals effects.
>>
>> Using lme() in 'nlme', I had the function intervals() available. Now I
>> don't.
>>
>> Any hints to de-perplex a novice?
>>
>> Thanks.
>> ================================================================
>> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
>> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
>> 824 Timberlake Drive                     Tel: 757-467-0954
>> Virginia Beach, VA 23464-3239            Fax: 757-467-2947
>>
>> "Vere scire est per causas scire"
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



----------------------
Kate Pressland
Office D95
School of Biological Sciences
University of Bristol
Woodland Road
Bristol, BS8 1UG

Kate.Pressland at bristol.ac.uk



From ken at kjbeath.com.au  Tue Jun  9 12:25:21 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Tue, 9 Jun 2009 20:25:21 +1000
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <1244501927.10505.9.camel@musuko.spc.uchicago.edu>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>
Message-ID: <0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>

On 09/06/2009, at 8:58 AM, Stuart Luppescu wrote:

> On ?, 2009-06-09 at 08:04 +1000, Ken Beath wrote:
>> The model treats item as a random effect and should be a fixed  
>> effect.
>
> Hmm. In Doran, Bates, Bliese and Dowling (2007), the authors treat the
> item as random.
>

It can be argued that the items are a sample from a population of  
items which is possibly reasonable for educational testing where there  
might be a population of questions which can be asked. Even so,  
assumptions about the distribution are optimistic and most items are  
used because they test something obvious. Maybe others have a  
different philosophy. A more pedantic argument is that this isn't the  
model Rasch used.

> [snip]
>> Another question to ask is whether the Rasch model is appropriate. If
>> an IRT is more sensible it would cause some problems with the second
>> model.
>
> Sorry, but I don't understand this at all.
>

By an IRT I mean the 2 parameter version where there is a discriminant  
parameter which varies among items, in contrast to the Rasch where it  
is constant. It probably gives problems with the other model as well  
but the second model should have more problems.

I don't like the idea of assuming a Rasch model at all, its popularity  
seems to derive from an era when fitting anything else was difficult.  
Modern software offers proper solutions, unfortunately at a cost but  
that shouldn't be a consideration.

Ken


> -- 
> Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
> University of Chicago -=- CCSR
> ???????? -=-    Kernel 2.6.28-gentoo-r5
> Drusilla: How do you feel about eternal life?
> Xander: We couldn't just start with coffee?
>
>
>
>
>
>
>
>



From arne.schulz at student.uni-kassel.de  Tue Jun  9 12:55:56 2009
From: arne.schulz at student.uni-kassel.de (Arne Schulz)
Date: Tue, 09 Jun 2009 12:55:56 +0200
Subject: [R-sig-ME] lmer maxiter not working?
Message-ID: <4A2E3FBC.3030802@student.uni-kassel.de>

Hi Jeff,
I stumbled over your post. I am currently facing the same problem. Did you find a solution anyway?

My System is XP 32 Bit with R 2.8.1 and lme4-0.999375-29 - the most recent Version, I got from r-forge.

Tranks,
Arne

    Addendum:
    	I have tried this now on XP 32 bit (R 2.8.0) and Ubuntu 64 bit
    (2.8.1) with the same errors. 

    Thanks again,

    Jeff Evans,
    Michigan State University




    I have been trying to change the number of iterations allowed by lmer in
    lme4 but it always runs for exactly 300 iterations.


    mp1 <- lmer(Siliques ~ State * Year +
    AdultsJuneD + RosOctD + SumSrv + WinSrv +
    soilsPC1 + soilsPC2 + 
    WinClimPC1 + WinClimPC2 + WinClimPC2_2 +
    (RosOctD*Year | Site) + (1 | ID),
    data=dat.gm,
    family="poisson",
    verbose=TRUE,
    control = list(maxIter = 100))

    299:     3796.3537: 0.669478 0.895477 5.18862e-10 0.612108 
    300:     3796.3537: 0.669478 0.895478  0.00000 0.612108 ......
    Warning message:
    In mer_finalize(ans) : iteration limit reached without convergence (9)

    changing to:
    ...control = list(maxIter = 10000))

    still only runs for 300 iterations with same warning

    Any thoughts?

    particulars:
    ?lme4? version 0.999375-28
    R version 2.8.1 (2008-12-22)
    Vista Ultimate 64 Bit sp1

    Thanks,
    Jeff



From andy.fugard at sbg.ac.at  Tue Jun  9 12:59:15 2009
From: andy.fugard at sbg.ac.at (Andy Fugard)
Date: Tue, 09 Jun 2009 12:59:15 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>
	<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>
Message-ID: <4A2E4083.6060204@sbg.ac.at>

Dear all,

What happens in practice when you compare the two approaches of item as 
a fixed versus as a random effect?

Consider:

   M1 = lmer(Reaction ~ Days + (1|Subject), sleepstudy)
   M2 = lm(Reaction ~ Days + factor(Subject), sleepstudy)

The slope estimates for Days for are practically identical, the mean 
intercepts differ:

For M1:

   ...
   Fixed effects:
               Estimate Std. Error t value
   (Intercept) 251.4051     9.7459   25.80
   Days         10.4673     0.8042   13.02
   ...

For M2:

                       Estimate Std. Error t value Pr(>|t|)
   (Intercept)         295.0310    10.4471  28.240  < 2e-16 ***
   Days                 10.4673     0.8042  13.015  < 2e-16 ***
   ...

I didn't look at the estimators for Subject, e.g., for M2 the predictors:

   factor(Subject)309 -126.9008    13.8597  -9.156 2.35e-16 ***
   factor(Subject)310 -111.1326    13.8597  -8.018 2.07e-13 ***
   factor(Subject)330  -38.9124    13.8597  -2.808 0.005609 **
   ...

But it could be done...

Is there a paper on these sorts of comparisons?  How does the mixed 
effects approach differ from a standard regression model with a heap of 
categorical predictors for representing, e.g., deviations from the mean 
intercept?

Presumably this could be done too for estimates for items, e.g., for 
binary logistic models and beyond.

Cheers,

Andy


Ken Beath wrote:
> On 09/06/2009, at 8:58 AM, Stuart Luppescu wrote:
> 
>> On ?, 2009-06-09 at 08:04 +1000, Ken Beath wrote:
>>> The model treats item as a random effect and should be a fixed effect.
>>
>> Hmm. In Doran, Bates, Bliese and Dowling (2007), the authors treat the
>> item as random.
>>
> 
> It can be argued that the items are a sample from a population of items 
> which is possibly reasonable for educational testing where there might 
> be a population of questions which can be asked. Even so, assumptions 
> about the distribution are optimistic and most items are used because 
> they test something obvious. Maybe others have a different philosophy. A 
> more pedantic argument is that this isn't the model Rasch used.
> 
>> [snip]
>>> Another question to ask is whether the Rasch model is appropriate. If
>>> an IRT is more sensible it would cause some problems with the second
>>> model.
>>
>> Sorry, but I don't understand this at all.
>>
> 
> By an IRT I mean the 2 parameter version where there is a discriminant 
> parameter which varies among items, in contrast to the Rasch where it is 
> constant. It probably gives problems with the other model as well but 
> the second model should have more problems.
> 
> I don't like the idea of assuming a Rasch model at all, its popularity 
> seems to derive from an era when fitting anything else was difficult. 
> Modern software offers proper solutions, unfortunately at a cost but 
> that shouldn't be a consideration.
> 
> Ken
> 
> 
>> -- 
>> Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
>> University of Chicago -=- CCSR
>> ???????? -=-    Kernel 2.6.28-gentoo-r5
>> Drusilla: How do you feel about eternal life?
>> Xander: We couldn't just start with coffee?
>>
>>
>>
>>
>>
>>
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Andy Fugard, Post-doc, ESF LogICCC (LcpR) project
Fachbereich Psychologie, Universitaet Salzburg
   Hellbrunnerstr. 34, 5020 Salzburg, Austria
+43 (0)680 2199 346  http://figuraleffect.googlepages.com



From Kate.Pressland at bristol.ac.uk  Tue Jun  9 13:29:36 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Tue, 09 Jun 2009 12:29:36 +0100
Subject: [R-sig-ME] (stupid) results interpretation question
Message-ID: <8EB315B8FDE708CB326F8D26@bio-mammal03.bio.bris.ac.uk>

I have a seemingly stupid but fundamental question I need answering.

I've had some strange plots and am now seriously questioning my 
interpretation of the lmer output: if I have a fixed effects results table 
that looks like this, can someone please check I'm interpreting it 
correctly?

---------
Fixed effects:
            Estimate Std. Error t value
1	(Intercept) -1.58481    0.18585   -8.53
2	GM1          0.02400    0.20472    0.12
3	GM2          0.17941    0.15916    1.13
4	Morph1      -1.54068    0.02202  -69.97
5	GM1:Morph1  -0.21681    0.04701   -4.61
6	GM2:Morph1  -0.12910    0.03321   -3.89
---------

1. Intercept is GM0 and Morph0
In my understanding the estimates given are the differences from the 
intercept alone so would give mean values for each category of:
1	-1.58481
2	-1.5601
3	-1.4054
4	-3.12549
5	-1.80162
6	-1.71391

Is this correct? Have I made a mistake in just looking at the difference 
from the intercept or do 2,3 and 4 need to be taken into account when 
calculating 5 and 6 i.e. 6 = 1 + 3 + 4?

I don't want to plough through thinking I've understood this when I may not 
have! I've tried looking in Pinheiro and Bates etc but they all just say 
the "estimate is the difference in the means" - I want to make sure I'm 
interpreting it correctly.

Anyone who can spare this simpleton student a swift reply would really help 
me out.

----------------------
Kate Pressland
School of Biological Sciences
University of Bristol
Woodland Road
Bristol, BS8 1UG

Kate.Pressland at bristol.ac.uk



From ken at kjbeath.com.au  Tue Jun  9 13:58:13 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Tue, 9 Jun 2009 21:58:13 +1000
Subject: [R-sig-ME] (stupid) results interpretation question
In-Reply-To: <8EB315B8FDE708CB326F8D26@bio-mammal03.bio.bris.ac.uk>
References: <8EB315B8FDE708CB326F8D26@bio-mammal03.bio.bris.ac.uk>
Message-ID: <1E2D5002-A146-4FA5-9C1E-4A888DB4BA55@kjbeath.com.au>

On 09/06/2009, at 9:29 PM, CL Pressland wrote:

> I have a seemingly stupid but fundamental question I need answering.
>
> I've had some strange plots and am now seriously questioning my  
> interpretation of the lmer output: if I have a fixed effects results  
> table that looks like this, can someone please check I'm  
> interpreting it correctly?
>
> ---------
> Fixed effects:
>           Estimate Std. Error t value
> 1	(Intercept) -1.58481    0.18585   -8.53
> 2	GM1          0.02400    0.20472    0.12
> 3	GM2          0.17941    0.15916    1.13
> 4	Morph1      -1.54068    0.02202  -69.97
> 5	GM1:Morph1  -0.21681    0.04701   -4.61
> 6	GM2:Morph1  -0.12910    0.03321   -3.89
> ---------
>
> 1. Intercept is GM0 and Morph0
> In my understanding the estimates given are the differences from the  
> intercept alone so would give mean values for each category of:
> 1	-1.58481
> 2	-1.5601
> 3	-1.4054
> 4	-3.12549
> 5	-1.80162
> 6	-1.71391
>
> Is this correct? Have I made a mistake in just looking at the  
> difference from the intercept or do 2,3 and 4 need to be taken into  
> account when calculating 5 and 6 i.e. 6 = 1 + 3 + 4?
>

Yes the lower terms need to be taken into account, so 6 is 1+3+4+6.

An easy way of working this out is to create a factor that corresponds  
to the 6 combinations of GM and Morph, fit the model without intercept  
and the values with SE should be calculated automatically.

There is a contrast package but it isn't advertised to work with lmer.

Ken

> I don't want to plough through thinking I've understood this when I  
> may not have! I've tried looking in Pinheiro and Bates etc but they  
> all just say the "estimate is the difference in the means" - I want  
> to make sure I'm interpreting it correctly.
>
> Anyone who can spare this simpleton student a swift reply would  
> really help me out.
>
> ----------------------
> Kate Pressland
> School of Biological Sciences
> University of Bristol
> Woodland Road
> Bristol, BS8 1UG
>
> Kate.Pressland at bristol.ac.uk
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Tue Jun  9 15:07:05 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 09 Jun 2009 09:07:05 -0400
Subject: [R-sig-ME] Confidence intervals for effects in glmer()
In-Reply-To: <A28F975F69905F48B98D9F38@bio-mammal03.bio.bris.ac.uk>
References: <0KKX00516ZWBY4P3@vms173019.mailsrvcs.net>	<4A2DA15A.8070205@ufl.edu>
	<A28F975F69905F48B98D9F38@bio-mammal03.bio.bris.ac.uk>
Message-ID: <4A2E5E79.6000709@ufl.edu>

  For a while mcmcsamp was withdrawn/labeled as untrustworthy by Doug
Bates, I'm not sure what its current status is.  In any case, as far as
I know it has never worked for GLMM (as opposed to LMM) fits -- which
is what the original poster asked about.  If it does work, mcmcsamp
is definitely better than the solutions I proposed.

  Ben Bolker


CL Pressland wrote:
> Dear fellow novice,
> 
> I've used mcmc to estimate confidence intervals in lme4. You don't need the 
> coda package as it's included in lme4 now. For you it would look like this:
> 
> fit4.mcmc<-mcmcsamp(fit4, n=1000) #or whatever resample number you think is 
> appropriate
> HPDinterval(fit4.mcmc)	#this will fit to alpha 0.05 as default.
> 
> As far as I am aware this is a fairly good method of estimating CIs in 
> mixed models, but Ben are you saying that there may be issues with this 
> process?
> 
> Kate
> 
> --On 08 June 2009 19:40 -0400 Ben Bolker <bolker at ufl.edu> wrote:
> 
>>   It depends on what approximations you're willing to accept.
>>
>>   Crudely doing +/- 2 standard deviations, or (DANGER DANGER)
>> using the 'known' df to compute t-scores (the "gm1" example
>> given in ?glmer has a fairly straightforward structure, with
>> 15 groups):
>>
>> library(lme4)
>> example(glmer)
>> s <- summary(gm1)@coefs
>>
>> fac <- 2
>> s[,"Estimate"]+fac*outer(c(-1,1),s[,"Std. Error"])
>>
>> fac <- qt(0.975,df=14)
>> s[,"Estimate"]+fac*outer(c(-1,1),s[,"Std. Error"])
>>
>>
>>   Does anyone know the current status of mcmcsamp,
>> either for LMMs or for GLMMs ... ?
>>
>>   Ben Bolker
>>
>> Robert A. LaBudde wrote:
>>> This may be blindingly obvious to the casual observer, but I'm
>>> chagrined to admit I'm stumped.
>>>
>>> I'm fitting a simple mixed effect logistic model using 'lme4':
>>>
>>> require('lme4')
>>> fit4<- glmer(x ~ 1 + 1|lab, data=eg, nAGQ=5, family='binomial')
>>> summary(fit4)
>>> ranef(fit4)
>>>
>>> I would like 95% confidence intervals on 'lab' and the residuals effects.
>>>
>>> Using lme() in 'nlme', I had the function intervals() available. Now I
>>> don't.
>>>
>>> Any hints to de-perplex a novice?
>>>
>>> Thanks.
>>> ================================================================
>>> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
>>> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
>>> 824 Timberlake Drive                     Tel: 757-467-0954
>>> Virginia Beach, VA 23464-3239            Fax: 757-467-2947
>>>
>>> "Vere scire est per causas scire"
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> ----------------------
> Kate Pressland
> Office D95
> School of Biological Sciences
> University of Bristol
> Woodland Road
> Bristol, BS8 1UG
> 
> Kate.Pressland at bristol.ac.uk
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Tue Jun  9 15:15:25 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 09 Jun 2009 09:15:25 -0400
Subject: [R-sig-ME] (stupid) results interpretation question
In-Reply-To: <8EB315B8FDE708CB326F8D26@bio-mammal03.bio.bris.ac.uk>
References: <8EB315B8FDE708CB326F8D26@bio-mammal03.bio.bris.ac.uk>
Message-ID: <4A2E606D.70507@ufl.edu>

CL Pressland wrote:
> I have a seemingly stupid but fundamental question I need answering.
> 
> I've had some strange plots and am now seriously questioning my 
> interpretation of the lmer output: if I have a fixed effects results table 
> that looks like this, can someone please check I'm interpreting it 
> correctly?
> 
> ---------
> Fixed effects:
>             Estimate Std. Error t value
> 1	(Intercept) -1.58481    0.18585   -8.53
> 2	GM1          0.02400    0.20472    0.12
> 3	GM2          0.17941    0.15916    1.13
> 4	Morph1      -1.54068    0.02202  -69.97
> 5	GM1:Morph1  -0.21681    0.04701   -4.61
> 6	GM2:Morph1  -0.12910    0.03321   -3.89
> ---------
> 
> 1. Intercept is GM0 and Morph0
> In my understanding the estimates given are the differences from the 
> intercept alone so would give mean values for each category of:
> 1	-1.58481
> 2	-1.5601
> 3	-1.4054
> 4	-3.12549
> 5	-1.80162
> 6	-1.71391
> 

  If z <- fixef(fit) then the last two should be
z[1]+z[2]+z[4]+z[5]=-3.32, z[1]+z[3]+z[4]+z[6]=-3.076
(i.e. "intercept plus difference from baseline in GM (if any)
plus difference difference from baseline in Morph (if any) plus
interaction").  You may be able to get more interpretable parameters
by using -1 (drop intercept) judiciously in your model statement,
although it will make tests of effects harder.

  You can also try to use predict() to see if you've understood
the parameterization correctly.

> I don't want to plough through thinking I've understood this when I may not 
> have! I've tried looking in Pinheiro and Bates etc but they all just say 
> the "estimate is the difference in the means" - I want to make sure I'm 
> interpreting it correctly.



From HDoran at air.org  Tue Jun  9 15:59:00 2009
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 Jun 2009 09:59:00 -0400
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE029FF930@DC1EXCL01.air.org>

> It can be argued that the items are a sample from a 
> population of items which is possibly reasonable for 
> educational testing where there might be a population of 
> questions which can be asked. Even so, assumptions about the 

I think the argument is easily supported, however. If you test my
ability to use R via a single test item (or even a small set of test
questions) isn't that only going to give an extremely myopic
perspective? There would certainly be a lot of variability in the
estimates given that another, exchangeable, set of test items could have
been used, no?

> distribution are optimistic and most items are used because 
> they test something obvious. 

Not sure I follow this, Ken. The distributional assumption about the
random effects in the mixed model is that they are normal. Is that what
you mean by optimistic?

> By an IRT I mean the 2 parameter version where there is a 
> discriminant parameter which varies among items, in contrast 
> to the Rasch where it is constant. It probably gives problems 
> with the other model as well but the second model should have 
> more problems.
> 
> I don't like the idea of assuming a Rasch model at all, its 
> popularity seems to derive from an era when fitting anything 
> else was difficult.  
> Modern software offers proper solutions, unfortunately at a 
> cost but that shouldn't be a consideration.

Wasn't it George Box who said, "Don't fall in love with a model?" I
agree to some extent. I don't think there is such a thing as "a proper
solution". The Bock and Aitkin MML method is perhaps what you mean, but
there are a lot of ways to generate IRT item parameters. 

There are many other reasons why Rasch is chosen in educational testing
situations, not only because of the fact that it is easy to estimate.

But, with different models come different issues that require different
assumptions. For instance, the 3PL estimates a "guessing" parameter.
But, the model cannot be identified without the use of a very strong
gamma prior. Since the variance of the prior is often extremely slim and
the mean is usually 1/k where k is number of options, the posterior is
pretty close to the prior. 

So, I think it's fair to look at all models, criticize the various
assumptions, not only the Rasch model. 



From danielezrajohnson at gmail.com  Tue Jun  9 16:09:36 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 9 Jun 2009 10:09:36 -0400
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <4A2E4083.6060204@sbg.ac.at>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>
	<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>
	<4A2E4083.6060204@sbg.ac.at>
Message-ID: <a46630750906090709w223b7a80hfe45ee4901d30bc@mail.gmail.com>

> What happens in practice when you compare the two approaches of [Subject] as a
> fixed versus as a random effect?
>
> Consider:
>
>  M1 = lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>  M2 = lm(Reaction ~ Days + factor(Subject), sleepstudy)
>
> The slope estimates for Days for are practically identical, the mean
> intercepts differ...

One important difference arises if you have a fixed effect that,
unlike Days, is "between subject", like Gender for example. In that
case you MUST use the M1 (mixed-model) approach with Subject as a
random effect. You CANNOT have Gender as a fixed effect AND Subject as
a fixed effect.

Dan



From Sebastiaan.DeSmedt at ua.ac.be  Tue Jun  9 16:55:04 2009
From: Sebastiaan.DeSmedt at ua.ac.be (De Smedt Sebastiaan)
Date: Tue, 9 Jun 2009 16:55:04 +0200
Subject: [R-sig-ME] mcmcsamp in lme4
Message-ID: <930B1A45F446404FA4D99A46F09209C401540CE8@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090609/94ac5fc7/attachment.pl>

From ral at lcfltd.com  Tue Jun  9 15:15:08 2009
From: ral at lcfltd.com (Robert A LaBudde)
Date: Tue, 09 Jun 2009 09:15:08 -0400
Subject: [R-sig-ME] Confidence intervals for effects in glmer()
In-Reply-To: <A28F975F69905F48B98D9F38@bio-mammal03.bio.bris.ac.uk>
References: <0KKX00516ZWBY4P3@vms173019.mailsrvcs.net>
	<4A2DA15A.8070205@ufl.edu>
	<A28F975F69905F48B98D9F38@bio-mammal03.bio.bris.ac.uk>
Message-ID: <0KKZ00FTL3HHR3XJ@vms173005.mailsrvcs.net>

At 05:57 AM 6/9/2009, CL Pressland wrote:
>Dear fellow novice,
>
>I've used mcmc to estimate confidence intervals in lme4. You don't 
>need the coda package as it's included in lme4 now. For you it would 
>look like this:
>
>fit4.mcmc<-mcmcsamp(fit4, n=1000) #or whatever resample number you 
>think is appropriate
>HPDinterval(fit4.mcmc)  #this will fit to alpha 0.05 as default.
>
>As far as I am aware this is a fairly good method of estimating CIs 
>in mixed models, but Ben are you saying that there may be issues 
>with this process?
>
>Kate

This method doesn't work in R 2.9.0:

 > eg<- read.table('example10.txt', header=TRUE)
 > eg$lab<- as.factor(eg$lab)
 > head(eg)
   lab x
1   1 1
2   1 1
3   1 1
4   1 1
5   1 0
6   1 0
 > require('lme4')
 > fit4<- glmer(x ~ 1 + 1|lab, data=eg, nAGQ=5, family='binomial') 
#random glm model
 > summary(fit4)
Generalized linear mixed model fit by the adaptive Gaussian Hermite 
approximation
Formula: x ~ 1 + 1 | lab
    Data: eg
    AIC   BIC logLik deviance
  172.4 177.9 -84.18    168.4
Random effects:
  Groups Name        Variance Std.Dev.
  lab    (Intercept) 0.26994  0.51956
Number of obs: 120, groups: lab, 10

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   0.1092     0.2477  0.4407     0.66
 > ranef(fit4)
$lab
    (Intercept)
1  -0.34766672
2  -0.34766672
3  -0.34766672
4  -0.04884925
5   0.40349845
6  -0.19803677
7  -0.04884925
8   0.71656475
9  -0.04884925
10  0.25117156

 > HPDinterval(mcmcsamp(fit4, n=1000))
Error in .local(object, n, verbose, ...) : Update not yet written
Error in HPDinterval(mcmcsamp(fit4, n = 1000)) :
   error in evaluating the argument 'object' in selecting a method 
for function 'HPDinterval'

The problem is with mcmcsamp(), which generates the "update not yet 
written" error message.


================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From andy.fugard at sbg.ac.at  Tue Jun  9 18:13:24 2009
From: andy.fugard at sbg.ac.at (Andy Fugard)
Date: Tue, 09 Jun 2009 18:13:24 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <a46630750906090709w223b7a80hfe45ee4901d30bc@mail.gmail.com>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>	
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>	
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>	
	<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>	
	<4A2E4083.6060204@sbg.ac.at>
	<a46630750906090709w223b7a80hfe45ee4901d30bc@mail.gmail.com>
Message-ID: <4A2E8A24.3090401@sbg.ac.at>

Daniel Ezra Johnson wrote:
>> What happens in practice when you compare the two approaches of [Subject] as a
>> fixed versus as a random effect?
>>
>> Consider:
>>
>>  M1 = lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>  M2 = lm(Reaction ~ Days + factor(Subject), sleepstudy)
>>
>> The slope estimates for Days for are practically identical, the mean
>> intercepts differ...
> 
> One important difference arises if you have a fixed effect that,
> unlike Days, is "between subject", like Gender for example. In that
> case you MUST use the M1 (mixed-model) approach with Subject as a
> random effect. You CANNOT have Gender as a fixed effect AND Subject as
> a fixed effect.

They're still similar for the example I tried.  (lmer vs. lm)

   Intercept:  250.0442 (SE = 10.0442) vs 293.6628 (SE = 10.8062)
   Days:    10.4498 (SE = 0.8067) vs 10.4511 (SE = 0.8067)
   SexMale: 2.5910 (SE = 4.6849) vs 2.4017 (SE = 4.6864)

(See below.)  The largest difference is in intercepts.

So I still need a good counterexample.  I feel a term like "shrinkage" 
will be involved in an explanation.

A

P.S. I guess lm still is a mixed effects approach - the residuals are a 
random effect at the level of observations? :-)


-------------------------------------------------------------------

 > M1 = lmer(Reaction ~ Days + (1|Subject), sleepstudy)
 >
 > # Use the random intercept to make up a Male/Female IV
 > sleepstudy$Sex = 
cut(ranef(M1)$Subject$"(Intercept)",2,labels=c("Female","Male"))
 >
 > # Now again: the same models:
 >
 > M1 = lmer(Reaction ~ Days + Sex + (1|Subject), sleepstudy)
 > summary(M1)
...
             Estimate Std. Error t value
(Intercept) 250.0442    10.0442  24.894
Days         10.4498     0.8067  12.954
SexMale       2.5910     4.6849   0.553

 >
 > M2 = lm(Reaction ~ Days + Sex + factor(Subject), sleepstudy)
 > summary(M2)

...

Coefficients:
                     Estimate Std. Error t value Pr(>|t|)
(Intercept)         293.6628    10.8062  27.176  < 2e-16 ***
Days                 10.4511     0.8067  12.956  < 2e-16 ***
SexMale               2.4017     4.6864   0.512 0.609020
...



From ccleland at optonline.net  Tue Jun  9 18:25:40 2009
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 09 Jun 2009 12:25:40 -0400
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <4A2E4083.6060204@sbg.ac.at>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>
	<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>
	<4A2E4083.6060204@sbg.ac.at>
Message-ID: <4A2E8D04.6020406@optonline.net>

On 6/9/2009 6:59 AM, Andy Fugard wrote:
> Dear all,
> 
> What happens in practice when you compare the two approaches of item as
> a fixed versus as a random effect?
> 
> Consider:
> 
>   M1 = lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>   M2 = lm(Reaction ~ Days + factor(Subject), sleepstudy)
> 
> The slope estimates for Days for are practically identical, the mean
> intercepts differ:
> 
> For M1:
> 
>   ...
>   Fixed effects:
>               Estimate Std. Error t value
>   (Intercept) 251.4051     9.7459   25.80
>   Days         10.4673     0.8042   13.02
>   ...
> 
> For M2:
> 
>                       Estimate Std. Error t value Pr(>|t|)
>   (Intercept)         295.0310    10.4471  28.240  < 2e-16 ***
>   Days                 10.4673     0.8042  13.015  < 2e-16 ***
>   ...
> 
> I didn't look at the estimators for Subject, e.g., for M2 the predictors:
> 
>   factor(Subject)309 -126.9008    13.8597  -9.156 2.35e-16 ***
>   factor(Subject)310 -111.1326    13.8597  -8.018 2.07e-13 ***
>   factor(Subject)330  -38.9124    13.8597  -2.808 0.005609 **
>   ...
> 
> But it could be done...
> 
> Is there a paper on these sorts of comparisons?  How does the mixed
> effects approach differ from a standard regression model with a heap of
> categorical predictors for representing, e.g., deviations from the mean
> intercept?

Allison, P.D. (2005).  Fixed Effects Regression Methods for Longitudinal
Data Using SAS. Cary, NC: SAS Institute.

  covers some of this territory.  As someone else pointed out, a
limitation is that including "Subject" as a factor precludes inclusion
of specific subject explanatory variables (e.g., gender).

> Presumably this could be done too for estimates for items, e.g., for
> binary logistic models and beyond.
> 
> Cheers,
> 
> Andy
> 
> 
> Ken Beath wrote:
>> On 09/06/2009, at 8:58 AM, Stuart Luppescu wrote:
>>
>>> On ?, 2009-06-09 at 08:04 +1000, Ken Beath wrote:
>>>> The model treats item as a random effect and should be a fixed effect.
>>>
>>> Hmm. In Doran, Bates, Bliese and Dowling (2007), the authors treat the
>>> item as random.
>>>
>>
>> It can be argued that the items are a sample from a population of
>> items which is possibly reasonable for educational testing where there
>> might be a population of questions which can be asked. Even so,
>> assumptions about the distribution are optimistic and most items are
>> used because they test something obvious. Maybe others have a
>> different philosophy. A more pedantic argument is that this isn't the
>> model Rasch used.
>>
>>> [snip]
>>>> Another question to ask is whether the Rasch model is appropriate. If
>>>> an IRT is more sensible it would cause some problems with the second
>>>> model.
>>>
>>> Sorry, but I don't understand this at all.
>>>
>>
>> By an IRT I mean the 2 parameter version where there is a discriminant
>> parameter which varies among items, in contrast to the Rasch where it
>> is constant. It probably gives problems with the other model as well
>> but the second model should have more problems.
>>
>> I don't like the idea of assuming a Rasch model at all, its popularity
>> seems to derive from an era when fitting anything else was difficult.
>> Modern software offers proper solutions, unfortunately at a cost but
>> that shouldn't be a consideration.
>>
>> Ken
>>
>>
>>> -- 
>>> Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
>>> University of Chicago -=- CCSR
>>> ???????? -=-    Kernel 2.6.28-gentoo-r5
>>> Drusilla: How do you feel about eternal life?
>>> Xander: We couldn't just start with coffee?
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Chuck Cleland, Ph.D.
NDRI, Inc. (www.ndri.org)
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From danielezrajohnson at gmail.com  Tue Jun  9 18:34:45 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 9 Jun 2009 12:34:45 -0400
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <4A2E8A24.3090401@sbg.ac.at>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>
	<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>
	<4A2E4083.6060204@sbg.ac.at>
	<a46630750906090709w223b7a80hfe45ee4901d30bc@mail.gmail.com>
	<4A2E8A24.3090401@sbg.ac.at>
Message-ID: <a46630750906090934k71469e5dqf1bdd18269721295@mail.gmail.com>

In the output for this model:

>> M2 = lm(Reaction ~ Days + Sex + factor(Subject), sleepstudy)
>> summary(M2)
>

You will see that one of the coefficients is NA. If you put
factor(Subject) before Sex it would be SexMale that comes out NA.

Nested fixed effects will always return an error (or incomplete
model), unless I'm completely mistaken.

Dan



From andy.fugard at sbg.ac.at  Tue Jun  9 19:06:54 2009
From: andy.fugard at sbg.ac.at (Andy Fugard)
Date: Tue, 09 Jun 2009 19:06:54 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <a46630750906090934k71469e5dqf1bdd18269721295@mail.gmail.com>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>	
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>	
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>	
	<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>	
	<4A2E4083.6060204@sbg.ac.at>	
	<a46630750906090709w223b7a80hfe45ee4901d30bc@mail.gmail.com>	
	<4A2E8A24.3090401@sbg.ac.at>
	<a46630750906090934k71469e5dqf1bdd18269721295@mail.gmail.com>
Message-ID: <4A2E96AE.4030707@sbg.ac.at>

Daniel Ezra Johnson wrote:
> In the output for this model:
> 
>>> M2 = lm(Reaction ~ Days + Sex + factor(Subject), sleepstudy)
>>> summary(M2)
> 
> You will see that one of the coefficients is NA. If you put
> factor(Subject) before Sex it would be SexMale that comes out NA.
> 
> Nested fixed effects will always return an error (or incomplete
> model), unless I'm completely mistaken.

Complete output pasted below.  It's been a long day, but I cannae see an 
NA!  Is your output different?

My intuition tells me that order of the variables shouldn't affect these 
estimates as addition is commutative.  I imagine they would affect a 
call to a (sequential) "anova" as this determines the order of nested 
model comparisons from the order of the variables.

A



 > M2a = lm(Reaction ~ Days + Sex + factor(Subject), sleepstudy)
 > summary(M2a)

Call:
lm(formula = Reaction ~ Days + Sex + factor(Subject), data = sleepstudy)

Residuals:
       Min        1Q    Median        3Q       Max
-101.4284  -17.2881    0.2311   15.2005  132.6242

Coefficients:
                     Estimate Std. Error t value Pr(>|t|)
(Intercept)         293.6628    10.8062  27.176  < 2e-16 ***
Days                 10.4511     0.8067  12.956  < 2e-16 ***
SexMale               2.4017     4.6864   0.512 0.609020
factor(Subject)309 -126.6607    13.8995  -9.113 3.18e-16 ***
factor(Subject)310 -111.1326    13.8915  -8.000 2.37e-13 ***
factor(Subject)330  -38.6722    13.8995  -2.782 0.006047 **
factor(Subject)331  -32.6978    13.8915  -2.354 0.019798 *
factor(Subject)332  -34.8318    13.8915  -2.507 0.013160 *
factor(Subject)333  -25.7353    13.8995  -1.852 0.065935 .
factor(Subject)334  -46.8318    13.8915  -3.371 0.000938 ***
factor(Subject)335  -91.8236    13.8995  -6.606 5.55e-10 ***
factor(Subject)337   33.5872    13.8915   2.418 0.016737 *
factor(Subject)349  -66.0592    13.8995  -4.753 4.44e-06 ***
factor(Subject)350  -28.5312    13.8915  -2.054 0.041618 *
factor(Subject)351  -51.7959    13.8995  -3.726 0.000269 ***
factor(Subject)352   -4.7123    13.8915  -0.339 0.734889
factor(Subject)369  -36.0992    13.8915  -2.599 0.010234 *
factor(Subject)370  -50.1919    13.8995  -3.611 0.000408 ***
factor(Subject)371  -47.1498    13.8915  -3.394 0.000868 ***
factor(Subject)372  -24.0075    13.8995  -1.727 0.086056 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 31.06 on 160 degrees of freedom
Multiple R-squared: 0.7282,     Adjusted R-squared: 0.6959
F-statistic: 22.56 on 19 and 160 DF,  p-value: < 2.2e-16

 >
 > M2b = lm(Reaction ~ Days + factor(Subject) + Sex, sleepstudy)
 > summary(M2b)

Call:
lm(formula = Reaction ~ Days + factor(Subject) + Sex, data = sleepstudy)

Residuals:
       Min        1Q    Median        3Q       Max
-101.4284  -17.2881    0.2311   15.2005  132.6242

Coefficients:
                     Estimate Std. Error t value Pr(>|t|)
(Intercept)         293.6628    10.8062  27.176  < 2e-16 ***
Days                 10.4511     0.8067  12.956  < 2e-16 ***
factor(Subject)309 -126.6607    13.8995  -9.113 3.18e-16 ***
factor(Subject)310 -111.1326    13.8915  -8.000 2.37e-13 ***
factor(Subject)330  -38.6722    13.8995  -2.782 0.006047 **
factor(Subject)331  -32.6978    13.8915  -2.354 0.019798 *
factor(Subject)332  -34.8318    13.8915  -2.507 0.013160 *
factor(Subject)333  -25.7353    13.8995  -1.852 0.065935 .
factor(Subject)334  -46.8318    13.8915  -3.371 0.000938 ***
factor(Subject)335  -91.8236    13.8995  -6.606 5.55e-10 ***
factor(Subject)337   33.5872    13.8915   2.418 0.016737 *
factor(Subject)349  -66.0592    13.8995  -4.753 4.44e-06 ***
factor(Subject)350  -28.5312    13.8915  -2.054 0.041618 *
factor(Subject)351  -51.7959    13.8995  -3.726 0.000269 ***
factor(Subject)352   -4.7123    13.8915  -0.339 0.734889
factor(Subject)369  -36.0992    13.8915  -2.599 0.010234 *
factor(Subject)370  -50.1919    13.8995  -3.611 0.000408 ***
factor(Subject)371  -47.1498    13.8915  -3.394 0.000868 ***
factor(Subject)372  -24.0075    13.8995  -1.727 0.086056 .
SexMale               2.4017     4.6864   0.512 0.609020
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 31.06 on 160 degrees of freedom
Multiple R-squared: 0.7282,     Adjusted R-squared: 0.6959
F-statistic: 22.56 on 19 and 160 DF,  p-value: < 2.2e-16



From andy.fugard at sbg.ac.at  Tue Jun  9 19:21:04 2009
From: andy.fugard at sbg.ac.at (Andy Fugard)
Date: Tue, 09 Jun 2009 19:21:04 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <4A2E8D04.6020406@optonline.net>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>
	<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>
	<1244501927.10505.9.camel@musuko.spc.uchicago.edu>
	<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>
	<4A2E4083.6060204@sbg.ac.at> <4A2E8D04.6020406@optonline.net>
Message-ID: <4A2E9A00.6080105@sbg.ac.at>

Chuck Cleland wrote:
> 
> Allison, P.D. (2005).  Fixed Effects Regression Methods for Longitudinal
> Data Using SAS. Cary, NC: SAS Institute.
> 
>   covers some of this territory.  As someone else pointed out, a
> limitation is that including "Subject" as a factor precludes inclusion
> of specific subject explanatory variables (e.g., gender).

Many thanks - shall track that down.  Though I haven't yet been able to 
replicate the limitation.

A



From andy.fugard at sbg.ac.at  Tue Jun  9 19:36:38 2009
From: andy.fugard at sbg.ac.at (Andy Fugard)
Date: Tue, 09 Jun 2009 19:36:38 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <4A2E96AE.4030707@sbg.ac.at>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com>		<AA0F2C2C-BCCD-4145-A984-75539BC6707B@kjbeath.com.au>		<1244501927.10505.9.camel@musuko.spc.uchicago.edu>		<0C894990-CA14-47C1-865A-F188B0BD456D@kjbeath.com.au>		<4A2E4083.6060204@sbg.ac.at>		<a46630750906090709w223b7a80hfe45ee4901d30bc@mail.gmail.com>		<4A2E8A24.3090401@sbg.ac.at>	<a46630750906090934k71469e5dqf1bdd18269721295@mail.gmail.com>
	<4A2E96AE.4030707@sbg.ac.at>
Message-ID: <4A2E9DA6.3050706@sbg.ac.at>

Andy Fugard wrote:
> Daniel Ezra Johnson wrote:
>> In the output for this model:
>>
>>>> M2 = lm(Reaction ~ Days + Sex + factor(Subject), sleepstudy)
>>>> summary(M2)
>>
>> You will see that one of the coefficients is NA. If you put
>> factor(Subject) before Sex it would be SexMale that comes out NA.
>>
>> Nested fixed effects will always return an error (or incomplete
>> model), unless I'm completely mistaken.

You were correct!  (Estimate for "factor(Subject)371" is broken.) 
Thanks for a tip off-list from Daniel and Chuck that I check how I made 
up the participants' sex :-)

So then does something similar happen for some cases when you try to 
model items as fixed effects?

A


 > # Try again again
 > M1 = lmer(Reaction ~ Days + (1|Subject), sleepstudy)
 >
 > # Use the random intercept to make up a Male/Female IV
 > ranefs = ranef(M1)$Subject
 > sexDF = data.frame(Sex = 
cut(ranefs$"(Intercept)",2,labels=c("Female","Male")),
+                    Subject = rownames(ranefs))
 >
 > sleepstudy.sex = merge(sleepstudy,sexDF)
 >
 >
 > M2 = lm(Reaction ~ Days + Sex + factor(Subject), sleepstudy.sex)
 > summary(M2)

Call:
lm(formula = Reaction ~ Days + Sex + factor(Subject), data = sleepstudy.sex)

Residuals:
     Min      1Q  Median      3Q     Max
-85.970 -13.790   1.767  12.957  53.056

Coefficients: (1 not defined because of singularities)
                    Estimate Std. Error t value Pr(>|t|)
(Intercept)        257.3095    14.5333  17.705  < 2e-16 ***
Days                10.6920     0.9627  11.106  < 2e-16 ***
SexMale             59.7598    18.0982   3.302 0.001472 **
factor(Subject)309 -85.8306    18.8055  -4.564 1.92e-05 ***
factor(Subject)310 -79.1101    19.8317  -3.989 0.000153 ***
factor(Subject)330 -63.0263    16.9719  -3.714 0.000391 ***
factor(Subject)331 -47.4795    16.1890  -2.933 0.004452 **
factor(Subject)332 -73.4632    16.1945  -4.536 2.13e-05 ***
factor(Subject)333 -45.4487    16.9719  -2.678 0.009098 **
factor(Subject)334  -5.9602    19.8186  -0.301 0.764446
factor(Subject)335 -58.4926    18.8025  -3.111 0.002638 **
factor(Subject)337  14.6896    16.1818   0.908 0.366900
factor(Subject)349 -28.7516    18.8055  -1.529 0.130498
factor(Subject)350 -67.3889    16.1826  -4.164 8.26e-05 ***
factor(Subject)351 -26.1381    18.8055  -1.390 0.168665
factor(Subject)352 -35.0784    16.1890  -2.167 0.033425 *
factor(Subject)369 -52.4248    16.1945  -3.237 0.001799 **
factor(Subject)370 -25.4865    18.8055  -1.355 0.179400
factor(Subject)371       NA         NA      NA       NA
factor(Subject)372 -45.9271    16.9741  -2.706 0.008433 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 28.03 on 75 degrees of freedom
Multiple R-squared: 0.8089,     Adjusted R-squared: 0.763
F-statistic: 17.63 on 18 and 75 DF,  p-value: < 2.2e-16

 >
 > # Broken as promised!



From HDoran at air.org  Tue Jun  9 21:01:36 2009
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 Jun 2009 15:01:36 -0400
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <4A2E9A00.6080105@sbg.ac.at>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE029FF996@DC1EXCL01.air.org>

There is another issue that I don't think has been raised yet. Assume
the fixed effects model is longitudinal in the sense that it contains
multiple scores per student and has students and schools as factors. It
turns out that the school effects are then identified only on the basis
of those students that move between schools.

Below is a link to a paper that discusses this in the context of
organizational studies. It is not the thesis of the paper, but it is
noted and discussed. I have a paper, which is more really notes on a
page jotted down, with all of the mathemtcail reasons why this would
occur. 

"Using Stata for a memory-saving fixed-effects estimation of the
three-way error-components model"
http://ideas.repec.org/p/boc/dsug08/07.html

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Andy Fugard
> Sent: Tuesday, June 09, 2009 1:21 PM
> To: Chuck Cleland
> Cc: R-SIG-Mixed-Models at R-project.org Models
> Subject: Re: [R-sig-ME] Rasch with lme4
> 
> Chuck Cleland wrote:
> > 
> > Allison, P.D. (2005).  Fixed Effects Regression Methods for 
> > Longitudinal Data Using SAS. Cary, NC: SAS Institute.
> > 
> >   covers some of this territory.  As someone else pointed out, a 
> > limitation is that including "Subject" as a factor 
> precludes inclusion 
> > of specific subject explanatory variables (e.g., gender).
> 
> Many thanks - shall track that down.  Though I haven't yet 
> been able to replicate the limitation.
> 
> A
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From maj at stats.waikato.ac.nz  Wed Jun 10 00:08:33 2009
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Wed, 10 Jun 2009 10:08:33 +1200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE029FF930@DC1EXCL01.air.org>
References: <ED7B522EE00C9A4FA515AA71724D61EE029FF930@DC1EXCL01.air.org>
Message-ID: <4A2EDD61.4040905@stats.waikato.ac.nz>

Fitting some alternative models may help if the normality of the random 
effects in the Rauch model is under doubt. For example the Rauch model 
could be fitted to transformed scores.

A more 'nonparametric' approach might be to use finite mixture models 
(usually called latent class models in this context).

Conclusions that are stable across a range of models can surely be 
trusted more.

Murray Jorgensen

Doran, Harold wrote:
>> It can be argued that the items are a sample from a 
>> population of items which is possibly reasonable for 
>> educational testing where there might be a population of 
>> questions which can be asked. Even so, assumptions about the 
> 
> I think the argument is easily supported, however. If you test my
> ability to use R via a single test item (or even a small set of test
> questions) isn't that only going to give an extremely myopic
> perspective? There would certainly be a lot of variability in the
> estimates given that another, exchangeable, set of test items could have
> been used, no?
> 
>> distribution are optimistic and most items are used because 
>> they test something obvious. 
> 
> Not sure I follow this, Ken. The distributional assumption about the
> random effects in the mixed model is that they are normal. Is that what
> you mean by optimistic?
> 
>> By an IRT I mean the 2 parameter version where there is a 
>> discriminant parameter which varies among items, in contrast 
>> to the Rasch where it is constant. It probably gives problems 
>> with the other model as well but the second model should have 
>> more problems.
>>
>> I don't like the idea of assuming a Rasch model at all, its 
>> popularity seems to derive from an era when fitting anything 
>> else was difficult.  
>> Modern software offers proper solutions, unfortunately at a 
>> cost but that shouldn't be a consideration.
> 
> Wasn't it George Box who said, "Don't fall in love with a model?" I
> agree to some extent. I don't think there is such a thing as "a proper
> solution". The Bock and Aitkin MML method is perhaps what you mean, but
> there are a lot of ways to generate IRT item parameters. 
> 
> There are many other reasons why Rasch is chosen in educational testing
> situations, not only because of the fact that it is easy to estimate.
> 
> But, with different models come different issues that require different
> assumptions. For instance, the 3PL estimates a "guessing" parameter.
> But, the model cannot be identified without the use of a very strong
> gamma prior. Since the variance of the prior is often extremely slim and
> the mean is usually 1/k where k is number of options, the posterior is
> pretty close to the prior. 
> 
> So, I think it's fair to look at all models, criticize the various
> assumptions, not only the Rasch model. 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From bolker at ufl.edu  Wed Jun 10 00:18:33 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 09 Jun 2009 18:18:33 -0400
Subject: [R-sig-ME] mcmcsamp in lme4
In-Reply-To: <930B1A45F446404FA4D99A46F09209C401540CE8@xmail05.ad.ua.ac.be>
References: <930B1A45F446404FA4D99A46F09209C401540CE8@xmail05.ad.ua.ac.be>
Message-ID: <4A2EDFB9.9090901@ufl.edu>

   There is indeed a simulate.lme() function in nlme:
can you use this to construct a Monte Carlo simulation?
i.e. (pseudocode)

 fit full model (model1)
 fit appropriate reduced model (model0)

 N times (using replicate() or a for loop) {
     simulate from reduced model, using simulate.lme(model0);
         pack it back into a copy of the original data frame
     fit full model [in lme4 there is a "refit" method that is
        more efficient, but apparently not in nlme]
            to simulated (null data)
     fit reduced model (minus one or more fixed terms), ditto
     compute/save deviance difference between full and reduced model
       as results[i]
}

compare observed deviance difference to simulated distribution:

 mean(c(results,obsdev)>=obsdev)

  cheers
    Ben


De Smedt Sebastiaan wrote:
> I fitted a mixed-effects model with a Variance Structure in nlme
> (because Variance Structures are not yet implemented in lme4). After
> several model fittings (with method="ML"), I found the optimal fixed
> structure of my explanatory variables. 
> 
> I understood from this mailing list that the p-values of the fixed
> effects, given by summary(namemodel) are not trustable and thus I want
> to use a Monte Carlo simulation in order to estimate the significance of
> the fixed terms. This command doesn't exist in nlme, and I can't fit my
> model in lme4. Is there a way to overcome this problem? Or another
> function in nlme that gives comparable results?
> 
>  
> 
>  
> 
> Thanks a lot,
> 
> Sebastiaan
> 
>  
> 
> Sebastiaan De Smedt
> 
> Research assistant
> 
> UA - Department of Bioscience Engineering
> 
>  
> 
> Groenenborgerlaan 171 - V6.16
> 
> B-2020 Antwerpen, Belgium
> 
> +32 (0)3 265 34 51
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From ral at lcfltd.com  Tue Jun  9 20:38:06 2009
From: ral at lcfltd.com (Robert A LaBudde)
Date: Tue, 09 Jun 2009 14:38:06 -0400
Subject: [R-sig-ME] mcmcsamp in lme4
In-Reply-To: <930B1A45F446404FA4D99A46F09209C401540CE8@xmail05.ad.ua.ac. be>
References: <930B1A45F446404FA4D99A46F09209C401540CE8@xmail05.ad.ua.ac.be>
Message-ID: <0KKZ00387IFQ5AO8@vms173005.mailsrvcs.net>

At 10:55 AM 6/9/2009, De Smedt Sebastiaan wrote:
>I fitted a mixed-effects model with a Variance Structure in nlme
>(because Variance Structures are not yet implemented in lme4). After
>several model fittings (with method="ML"), I found the optimal fixed
>structure of my explanatory variables.
>
>I understood from this mailing list that the p-values of the fixed
>effects, given by summary(namemodel) are not trustable and thus I want
>to use a Monte Carlo simulation in order to estimate the significance of
>the fixed terms. This command doesn't exist in nlme, and I can't fit my
>model in lme4. Is there a way to overcome this problem? Or another
>function in nlme that gives comparable results?

Try intervals(fit) in 'nlme'.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From yulya258 at hotmail.com  Wed Jun 10 13:11:14 2009
From: yulya258 at hotmail.com (J S)
Date: Wed, 10 Jun 2009 11:11:14 +0000
Subject: [R-sig-ME] DF in nonlinear mixed model with covarites in nlme
In-Reply-To: <0KKZ00387IFQ5AO8@vms173005.mailsrvcs.net>
References: <930B1A45F446404FA4D99A46F09209C401540CE8@xmail05.ad.ua.ac.be>
	<0KKZ00387IFQ5AO8@vms173005.mailsrvcs.net>
Message-ID: <BAY134-W1717CD53AF53728B0E25A188450@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090610/18bc6004/attachment.pl>

From Christine.Griffiths at bristol.ac.uk  Wed Jun 10 12:22:36 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Wed, 10 Jun 2009 11:22:36 +0100
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
Message-ID: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>

Hi R users,

Just a query as to whether lme4 can handle beta-binomial distributions as I 
read that this was not available.

If not, any suggestions on how to handle such a distribution to plot the 
following model:
y<-cbind(Biotic,Abiotic)
m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadrat))

y referring to percentage cover of biotic matter.

Cheers,
Christine



From bolker at ufl.edu  Wed Jun 10 15:18:21 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 10 Jun 2009 09:18:21 -0400
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
Message-ID: <4A2FB29D.1050608@ufl.edu>

  No.  You can use a quasi-binomial model, although
the support is a little bit spotty (and beware that
quasi- models may falsely report inflation of the
random effects).

  Ben Bolker


Christine Griffiths wrote:
> Hi R users,
> 
> Just a query as to whether lme4 can handle beta-binomial distributions as I 
> read that this was not available.
> 
> If not, any suggestions on how to handle such a distribution to plot the 
> following model:
> y<-cbind(Biotic,Abiotic)
> m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadrat))
> 
> y referring to percentage cover of biotic matter.
> 
> Cheers,
> Christine
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Christine.Griffiths at bristol.ac.uk  Wed Jun 10 15:34:53 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Wed, 10 Jun 2009 14:34:53 +0100
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <4A2FB29D.1050608@ufl.edu>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
	<4A2FB29D.1050608@ufl.edu>
Message-ID: <E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>

Thanks. I was hoping for a miracle that this had been developed within the 
last couple of months.

I am on the stats learning curve and am not quite sure how flexible to be 
with regards to distributions.  Is quasibinomial acceptable, despite having 
data with a lot of 0s and a lot of 100s?

Many thanks in advance,
Christine

--On 10 June 2009 09:18 -0400 Ben Bolker <bolker at ufl.edu> wrote:

>   No.  You can use a quasi-binomial model, although
> the support is a little bit spotty (and beware that
> quasi- models may falsely report inflation of the
> random effects).
>
>   Ben Bolker
>
>
> Christine Griffiths wrote:
>> Hi R users,
>>
>> Just a query as to whether lme4 can handle beta-binomial distributions
>> as I  read that this was not available.
>>
>> If not, any suggestions on how to handle such a distribution to plot the
>> following model:
>> y<-cbind(Biotic,Abiotic)
>> m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadrat))
>>
>> y referring to percentage cover of biotic matter.
>>
>> Cheers,
>> Christine
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Wed Jun 10 15:59:02 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 10 Jun 2009 09:59:02 -0400
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>	<4A2FB29D.1050608@ufl.edu>
	<E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>
Message-ID: <4A2FBC26.8040102@ufl.edu>

  That's a good question, answers will differ.  Since "all models are
wrong" anyway, provided that a mean-variance relationship of V =
phi*N*p*(1-p) seems plausible, I would say you should go for it.  You're
near the cutting edge anyway ... (I don't have a copy, but you might see
whether Zuur et al's book has anything to say on the subject -- they're
very pragmatic ecologists, and I think they use GEE/quasi models quite a
lot ...)

  Ben Bolker


Christine Griffiths wrote:
> Thanks. I was hoping for a miracle that this had been developed within the 
> last couple of months.
> 
> I am on the stats learning curve and am not quite sure how flexible to be 
> with regards to distributions.  Is quasibinomial acceptable, despite having 
> data with a lot of 0s and a lot of 100s?
> 
> Many thanks in advance,
> Christine
> 
> --On 10 June 2009 09:18 -0400 Ben Bolker <bolker at ufl.edu> wrote:
> 
>>   No.  You can use a quasi-binomial model, although
>> the support is a little bit spotty (and beware that
>> quasi- models may falsely report inflation of the
>> random effects).
>>
>>   Ben Bolker
>>
>>
>> Christine Griffiths wrote:
>>> Hi R users,
>>>
>>> Just a query as to whether lme4 can handle beta-binomial distributions
>>> as I  read that this was not available.
>>>
>>> If not, any suggestions on how to handle such a distribution to plot the
>>> following model:
>>> y<-cbind(Biotic,Abiotic)
>>> m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadrat))
>>>
>>> y referring to percentage cover of biotic matter.
>>>
>>> Cheers,
>>> Christine
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Thierry.ONKELINX at inbo.be  Wed Jun 10 16:16:06 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 10 Jun 2009 16:16:06 +0200
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <4A2FBC26.8040102@ufl.edu>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>	<4A2FB29D.1050608@ufl.edu><E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>
	<4A2FBC26.8040102@ufl.edu>
Message-ID: <2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>

Dear Christine,

We had recently a vivid discussion on whether it is appropriate to model
percentages by a (quasi)binomial model. We were modelling the precentage
of leaves that is missing from trees. The mixed model with the binomial
family had random effects with extremly small variances. My colleague
argued that this percentage did not come from a bernouilli experiment.
And hence the binomial family was not appropriate. He suggested to put
the percentage on a 0 to 100 scale and apply a log(x+1) transformation.
This resulted in a linear mixed model with random effects that had
reasonable variances. This convinced me that the binomial family only
makes sense with binary data.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ben Bolker
Verzonden: woensdag 10 juni 2009 15:59
Aan: Christine Griffiths
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Beta-binomial distributions with lmer?

  That's a good question, answers will differ.  Since "all models are
wrong" anyway, provided that a mean-variance relationship of V =
phi*N*p*(1-p) seems plausible, I would say you should go for it.  You're
near the cutting edge anyway ... (I don't have a copy, but you might see
whether Zuur et al's book has anything to say on the subject -- they're
very pragmatic ecologists, and I think they use GEE/quasi models quite a
lot ...)

  Ben Bolker


Christine Griffiths wrote:
> Thanks. I was hoping for a miracle that this had been developed within

> the last couple of months.
> 
> I am on the stats learning curve and am not quite sure how flexible to

> be with regards to distributions.  Is quasibinomial acceptable, 
> despite having data with a lot of 0s and a lot of 100s?
> 
> Many thanks in advance,
> Christine
> 
> --On 10 June 2009 09:18 -0400 Ben Bolker <bolker at ufl.edu> wrote:
> 
>>   No.  You can use a quasi-binomial model, although the support is a 
>> little bit spotty (and beware that
>> quasi- models may falsely report inflation of the random effects).
>>
>>   Ben Bolker
>>
>>
>> Christine Griffiths wrote:
>>> Hi R users,
>>>
>>> Just a query as to whether lme4 can handle beta-binomial 
>>> distributions as I  read that this was not available.
>>>
>>> If not, any suggestions on how to handle such a distribution to plot

>>> the following model:
>>> y<-cbind(Biotic,Abiotic)
>>> m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadr
>>> at))
>>>
>>> y referring to percentage cover of biotic matter.
>>>
>>> Cheers,
>>> Christine
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /

>> www.zoology.ufl.edu/bolker GPG key: 
>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /
www.zoology.ufl.edu/bolker GPG key:
www.zoology.ufl.edu/bolker/benbolker-publickey.asc

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From bolker at ufl.edu  Wed Jun 10 16:25:23 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 10 Jun 2009 10:25:23 -0400
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>	<4A2FB29D.1050608@ufl.edu><E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>
	<4A2FBC26.8040102@ufl.edu>
	<2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>
Message-ID: <4A2FC253.4030308@ufl.edu>

  Yes, but ...
  If the data get "scrunched" near 100% (as well as near zero), then
I'm not sure that this procedure would lead to stable variances?
(If it does, that's great.) Why not logit((proportion+m)/(1+2*m)) [where
m is a small value which can be interpreted as coming from a Bayesian
prior, if you like] instead? Once we've done all that, we're getting
pretty close to a quasi-binomial model anyway ...  (It sounds like all
the N values are the same in this example anyway, so there's no scaling
of variance with N to worry about.)

ONKELINX, Thierry wrote:
> Dear Christine,
> 
> We had recently a vivid discussion on whether it is appropriate to model
> percentages by a (quasi)binomial model. We were modelling the precentage
> of leaves that is missing from trees. The mixed model with the binomial
> family had random effects with extremly small variances. My colleague
> argued that this percentage did not come from a bernouilli experiment.
> And hence the binomial family was not appropriate. He suggested to put
> the percentage on a 0 to 100 scale and apply a log(x+1) transformation.
> This resulted in a linear mixed model with random effects that had
> reasonable variances. This convinced me that the binomial family only
> makes sense with binary data.
> 
> HTH,
> 
> Thierry
> 
> 
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>  
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ben Bolker
> Verzonden: woensdag 10 juni 2009 15:59
> Aan: Christine Griffiths
> CC: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] Beta-binomial distributions with lmer?
> 
>   That's a good question, answers will differ.  Since "all models are
> wrong" anyway, provided that a mean-variance relationship of V =
> phi*N*p*(1-p) seems plausible, I would say you should go for it.  You're
> near the cutting edge anyway ... (I don't have a copy, but you might see
> whether Zuur et al's book has anything to say on the subject -- they're
> very pragmatic ecologists, and I think they use GEE/quasi models quite a
> lot ...)
> 
>   Ben Bolker
> 
> 
> Christine Griffiths wrote:
>> Thanks. I was hoping for a miracle that this had been developed within
> 
>> the last couple of months.
>>
>> I am on the stats learning curve and am not quite sure how flexible to
> 
>> be with regards to distributions.  Is quasibinomial acceptable, 
>> despite having data with a lot of 0s and a lot of 100s?
>>
>> Many thanks in advance,
>> Christine
>>
>> --On 10 June 2009 09:18 -0400 Ben Bolker <bolker at ufl.edu> wrote:
>>
>>>   No.  You can use a quasi-binomial model, although the support is a 
>>> little bit spotty (and beware that
>>> quasi- models may falsely report inflation of the random effects).
>>>
>>>   Ben Bolker
>>>
>>>
>>> Christine Griffiths wrote:
>>>> Hi R users,
>>>>
>>>> Just a query as to whether lme4 can handle beta-binomial 
>>>> distributions as I  read that this was not available.
>>>>
>>>> If not, any suggestions on how to handle such a distribution to plot
> 
>>>> the following model:
>>>> y<-cbind(Biotic,Abiotic)
>>>> m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadr
>>>> at))
>>>>
>>>> y referring to percentage cover of biotic matter.
>>>>
>>>> Cheers,
>>>> Christine
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> --
>>> Ben Bolker
>>> Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /
> 
>>> www.zoology.ufl.edu/bolker GPG key: 
>>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /
> www.zoology.ufl.edu/bolker GPG key:
> www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
> en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed in  this message 
> and any annex are purely those of the writer and may not be regarded as stating 
> an official position of INBO, as long as the message is not confirmed by a duly 
> signed document.


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From otter at otter-rsch.com  Wed Jun 10 17:58:03 2009
From: otter at otter-rsch.com (dave fournier)
Date: Wed, 10 Jun 2009 08:58:03 -0700
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
Message-ID: <4A2FD80B.6070404@otter-rsch.com>

Hi,

You can fit this model with AD Model Builders random effects module
which is now freely available at http://admb-project.org.
Rather than arguing a priori about the applicability of various models I
prefer to fit them and look at the estimates and diagnostics for each one.

   dave

-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From Christine.Griffiths at bristol.ac.uk  Wed Jun 10 17:29:42 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Wed, 10 Jun 2009 16:29:42 +0100
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <4A2FC253.4030308@ufl.edu>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
	<4A2FB29D.1050608@ufl.edu>
	<E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>
	<4A2FBC26.8040102@ufl.edu>
	<2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>
	<4A2FC253.4030308@ufl.edu>
Message-ID: <317989582993CA09CAF21AA6@bio-mammal026.bio.bris.ac.uk>

Dear Ben and Thierry,

Thank you for the advice. I tried to do both suggested methods, however got 
stumped on Ben's suggestion of logit. Thierry's suggestion did improve the 
variances (e.g. 7.7e-04 to 1.94 for the residual variance) when I used 
quasipoisson family errors. Given that the values aren't discrete I am not 
sure this is correct. Ben you only suggest this method if it leads to 
"stable variance". I have tried searching what is meant by this term, but 
have not found any information. If you could clarify or point me in the 
right direction I would gratefully appreciate the assistance.

Cheers
Christine

--On 10 June 2009 10:25 -0400 Ben Bolker <bolker at ufl.edu> wrote:

>   Yes, but ...
>   If the data get "scrunched" near 100% (as well as near zero), then
> I'm not sure that this procedure would lead to stable variances?
> (If it does, that's great.) Why not logit((proportion+m)/(1+2*m)) [where
> m is a small value which can be interpreted as coming from a Bayesian
> prior, if you like] instead? Once we've done all that, we're getting
> pretty close to a quasi-binomial model anyway ...  (It sounds like all
> the N values are the same in this example anyway, so there's no scaling
> of variance with N to worry about.)
>
> ONKELINX, Thierry wrote:
>> Dear Christine,
>>
>> We had recently a vivid discussion on whether it is appropriate to model
>> percentages by a (quasi)binomial model. We were modelling the precentage
>> of leaves that is missing from trees. The mixed model with the binomial
>> family had random effects with extremly small variances. My colleague
>> argued that this percentage did not come from a bernouilli experiment.
>> And hence the binomial family was not appropriate. He suggested to put
>> the percentage on a 0 to 100 scale and apply a log(x+1) transformation.
>> This resulted in a linear mixed model with random effects that had
>> reasonable variances. This convinced me that the binomial family only
>> makes sense with binary data.
>>
>> HTH,
>>
>> Thierry
>>
>>
>> ------------------------------------------------------------------------
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
>> methodology and quality assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ben Bolker
>> Verzonden: woensdag 10 juni 2009 15:59
>> Aan: Christine Griffiths
>> CC: r-sig-mixed-models at r-project.org
>> Onderwerp: Re: [R-sig-ME] Beta-binomial distributions with lmer?
>>
>>   That's a good question, answers will differ.  Since "all models are
>> wrong" anyway, provided that a mean-variance relationship of V =
>> phi*N*p*(1-p) seems plausible, I would say you should go for it.  You're
>> near the cutting edge anyway ... (I don't have a copy, but you might see
>> whether Zuur et al's book has anything to say on the subject -- they're
>> very pragmatic ecologists, and I think they use GEE/quasi models quite a
>> lot ...)
>>
>>   Ben Bolker
>>
>>
>> Christine Griffiths wrote:
>>> Thanks. I was hoping for a miracle that this had been developed within
>>
>>> the last couple of months.
>>>
>>> I am on the stats learning curve and am not quite sure how flexible to
>>
>>> be with regards to distributions.  Is quasibinomial acceptable,
>>> despite having data with a lot of 0s and a lot of 100s?
>>>
>>> Many thanks in advance,
>>> Christine
>>>
>>> --On 10 June 2009 09:18 -0400 Ben Bolker <bolker at ufl.edu> wrote:
>>>
>>>>   No.  You can use a quasi-binomial model, although the support is a
>>>> little bit spotty (and beware that
>>>> quasi- models may falsely report inflation of the random effects).
>>>>
>>>>   Ben Bolker
>>>>
>>>>
>>>> Christine Griffiths wrote:
>>>>> Hi R users,
>>>>>
>>>>> Just a query as to whether lme4 can handle beta-binomial
>>>>> distributions as I  read that this was not available.
>>>>>
>>>>> If not, any suggestions on how to handle such a distribution to plot
>>
>>>>> the following model:
>>>>> y<-cbind(Biotic,Abiotic)
>>>>> m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadr
>>>>> at))
>>>>>
>>>>> y referring to percentage cover of biotic matter.
>>>>>
>>>>> Cheers,
>>>>> Christine
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> --
>>>> Ben Bolker
>>>> Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /
>>
>>>> www.zoology.ufl.edu/bolker GPG key:
>>>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /
>> www.zoology.ufl.edu/bolker GPG key:
>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
>> weer  en binden het INBO onder geen enkel beding, zolang dit bericht
>> niet bevestigd is door een geldig ondertekend document. The views
>> expressed in  this message  and any annex are purely those of the writer
>> and may not be regarded as stating  an official position of INBO, as
>> long as the message is not confirmed by a duly  signed document.
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



----------------------
Christine Griffiths
School of Biological Sciences
University of Bristol
Woodland Road
Bristol BS8 1UG
Tel: 0117 9287593
Fax 0117 3317985
Christine.Griffiths at bristol.ac.uk
http://www.bio.bris.ac.uk/research/mammal/tortoises.html



From bolker at ufl.edu  Wed Jun 10 20:14:18 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 10 Jun 2009 14:14:18 -0400
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <317989582993CA09CAF21AA6@bio-mammal026.bio.bris.ac.uk>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>	<4A2FB29D.1050608@ufl.edu>	<E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>	<4A2FBC26.8040102@ufl.edu>	<2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>	<4A2FC253.4030308@ufl.edu>
	<317989582993CA09CAF21AA6@bio-mammal026.bio.bris.ac.uk>
Message-ID: <4A2FF7FA.1060603@ufl.edu>



Christine Griffiths wrote:
> Dear Ben and Thierry,
> 
> Thank you for the advice. I tried to do both suggested methods, however got 
> stumped on Ben's suggestion of logit. Thierry's suggestion did improve the 
> variances (e.g. 7.7e-04 to 1.94 for the residual variance) when I used 
> quasipoisson family errors. Given that the values aren't discrete I am not 
> sure this is correct. Ben you only suggest this method if it leads to 
> "stable variance". I have tried searching what is meant by this term, but 
> have not found any information. If you could clarify or point me in the 
> right direction I would gratefully appreciate the assistance.
> 
> Cheers
> Christine

   If you transformed the data in some significant way, then the
residual variances aren't necessarily going to be comparable, so
I'm not sure I would take that as confirmation.

I think Thierry meant to suggest a LMM (i.e., assume normal
distributions, no transformation after the initial one) rather
than a GLMM (link function/exponential-family distribution or
quasi-distribution).

You may find more on "stabilizing variance" rather
than "stable variance" -- what I meant was that the variability in the
Pearson residuals (residuals scaled by the expected standard deviation,
which is what lmer gives you) should be independent of the fitted value
-- so try plot(sqrt(residuals(model)) ~ fitted(model)) and see if the
"amplitude" appears reasonably constant (this is approximately the same
as the "scale-location" plot that plot.lm gives you for a linear model).


> 
> --On 10 June 2009 10:25 -0400 Ben Bolker <bolker at ufl.edu> wrote:
> 
>>   Yes, but ...
>>   If the data get "scrunched" near 100% (as well as near zero), then
>> I'm not sure that this procedure would lead to stable variances?
>> (If it does, that's great.) Why not logit((proportion+m)/(1+2*m)) [where
>> m is a small value which can be interpreted as coming from a Bayesian
>> prior, if you like] instead? Once we've done all that, we're getting
>> pretty close to a quasi-binomial model anyway ...  (It sounds like all
>> the N values are the same in this example anyway, so there's no scaling
>> of variance with N to worry about.)
>>
>> ONKELINX, Thierry wrote:
>>> Dear Christine,
>>>
>>> We had recently a vivid discussion on whether it is appropriate to model
>>> percentages by a (quasi)binomial model. We were modelling the precentage
>>> of leaves that is missing from trees. The mixed model with the binomial
>>> family had random effects with extremly small variances. My colleague
>>> argued that this percentage did not come from a bernouilli experiment.
>>> And hence the binomial family was not appropriate. He suggested to put
>>> the percentage on a 0 to 100 scale and apply a log(x+1) transformation.
>>> This resulted in a linear mixed model with random effects that had
>>> reasonable variances. This convinced me that the binomial family only
>>> makes sense with binary data.
>>>
>>> HTH,
>>>
>>> Thierry
>>>
>>>
>>> ------------------------------------------------------------------------
>>> ----
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
>>> methodology and quality assurance
>>> Gaverstraat 4
>>> 9500 Geraardsbergen
>>> Belgium
>>> tel. + 32 54/436 185
>>> Thierry.Onkelinx at inbo.be
>>> www.inbo.be
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say what the experiment died of.
>>> ~ Sir Ronald Aylmer Fisher
>>>
>>> The plural of anecdote is not data.
>>> ~ Roger Brinner
>>>
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> -----Oorspronkelijk bericht-----
>>> Van: r-sig-mixed-models-bounces at r-project.org
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ben Bolker
>>> Verzonden: woensdag 10 juni 2009 15:59
>>> Aan: Christine Griffiths
>>> CC: r-sig-mixed-models at r-project.org
>>> Onderwerp: Re: [R-sig-ME] Beta-binomial distributions with lmer?
>>>
>>>   That's a good question, answers will differ.  Since "all models are
>>> wrong" anyway, provided that a mean-variance relationship of V =
>>> phi*N*p*(1-p) seems plausible, I would say you should go for it.  You're
>>> near the cutting edge anyway ... (I don't have a copy, but you might see
>>> whether Zuur et al's book has anything to say on the subject -- they're
>>> very pragmatic ecologists, and I think they use GEE/quasi models quite a
>>> lot ...)
>>>
>>>   Ben Bolker
>>>
>>>
>>> Christine Griffiths wrote:
>>>> Thanks. I was hoping for a miracle that this had been developed within
>>>> the last couple of months.
>>>>
>>>> I am on the stats learning curve and am not quite sure how flexible to
>>>> be with regards to distributions.  Is quasibinomial acceptable,
>>>> despite having data with a lot of 0s and a lot of 100s?
>>>>
>>>> Many thanks in advance,
>>>> Christine
>>>>
>>>> --On 10 June 2009 09:18 -0400 Ben Bolker <bolker at ufl.edu> wrote:
>>>>
>>>>>   No.  You can use a quasi-binomial model, although the support is a
>>>>> little bit spotty (and beware that
>>>>> quasi- models may falsely report inflation of the random effects).
>>>>>
>>>>>   Ben Bolker
>>>>>
>>>>>
>>>>> Christine Griffiths wrote:
>>>>>> Hi R users,
>>>>>>
>>>>>> Just a query as to whether lme4 can handle beta-binomial
>>>>>> distributions as I  read that this was not available.
>>>>>>
>>>>>> If not, any suggestions on how to handle such a distribution to plot
>>>>>> the following model:
>>>>>> y<-cbind(Biotic,Abiotic)
>>>>>> m1<-lmer(y~Treatment+Month.rain+(1|Month)+(1|Block/EnclosureID/Quadr
>>>>>> at))
>>>>>>
>>>>>> y referring to percentage cover of biotic matter.
>>>>>>
>>>>>> Cheers,
>>>>>> Christine
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> --
>>>>> Ben Bolker
>>>>> Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /
>>>>> www.zoology.ufl.edu/bolker GPG key:
>>>>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> --
>>> Ben Bolker
>>> Associate professor, Biology Dep't, Univ. of Florida bolker at ufl.edu /
>>> www.zoology.ufl.edu/bolker GPG key:
>>> www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
>>> weer  en binden het INBO onder geen enkel beding, zolang dit bericht
>>> niet bevestigd is door een geldig ondertekend document. The views
>>> expressed in  this message  and any annex are purely those of the writer
>>> and may not be regarded as stating  an official position of INBO, as
>>> long as the message is not confirmed by a duly  signed document.
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> 
> 
> 
> ----------------------
> Christine Griffiths
> School of Biological Sciences
> University of Bristol
> Woodland Road
> Bristol BS8 1UG
> Tel: 0117 9287593
> Fax 0117 3317985
> Christine.Griffiths at bristol.ac.uk
> http://www.bio.bris.ac.uk/research/mammal/tortoises.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Thierry.ONKELINX at inbo.be  Wed Jun 10 20:43:31 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 10 Jun 2009 20:43:31 +0200
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <4A2FF7FA.1060603@ufl.edu>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>	<4A2FB29D.1050608@ufl.edu>	<E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>	<4A2FBC26.8040102@ufl.edu>	<2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>	<4A2FC253.4030308@ufl.edu><317989582993CA09CAF21AA6@bio-mammal026.bio.bris.ac.uk>
	<4A2FF7FA.1060603@ufl.edu>
Message-ID: <2E9C414912813E4EB981326983E0A1040690D1D3@inboexch.inbo.be>

Dear Ben,

Indeed. I suggested to use a LMM with the transformed data. Then I would
have a look at how the residuals behave.

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ben Bolker
Verzonden: woensdag 10 juni 2009 20:14
Aan: Christine Griffiths
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Beta-binomial distributions with lmer?



Christine Griffiths wrote:
> Dear Ben and Thierry,
> 
> Thank you for the advice. I tried to do both suggested methods, 
> however got stumped on Ben's suggestion of logit. Thierry's suggestion

> did improve the variances (e.g. 7.7e-04 to 1.94 for the residual 
> variance) when I used quasipoisson family errors. Given that the 
> values aren't discrete I am not sure this is correct. Ben you only 
> suggest this method if it leads to "stable variance". I have tried 
> searching what is meant by this term, but have not found any 
> information. If you could clarify or point me in the right direction I
would gratefully appreciate the assistance.
> 
> Cheers
> Christine

   If you transformed the data in some significant way, then the
residual variances aren't necessarily going to be comparable, so I'm not
sure I would take that as confirmation.

I think Thierry meant to suggest a LMM (i.e., assume normal
distributions, no transformation after the initial one) rather than a
GLMM (link function/exponential-family distribution or
quasi-distribution).

You may find more on "stabilizing variance" rather than "stable
variance" -- what I meant was that the variability in the Pearson
residuals (residuals scaled by the expected standard deviation, which is
what lmer gives you) should be independent of the fitted value
-- so try plot(sqrt(residuals(model)) ~ fitted(model)) and see if the
"amplitude" appears reasonably constant (this is approximately the same
as the "scale-location" plot that plot.lm gives you for a linear model).

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From gts127 at psu.edu  Thu Jun 11 05:41:52 2009
From: gts127 at psu.edu (Grant T. Stokke)
Date: Wed, 10 Jun 2009 23:41:52 -0400
Subject: [R-sig-ME] GLMMs with unequal group sizes
In-Reply-To: <2E9C414912813E4EB981326983E0A1040690D1D3@inboexch.inbo.be>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>	<4A2FB29D.1050608@ufl.edu>	<E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>	<4A2FBC26.8040102@ufl.edu>	<2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>	<4A2FC253.4030308@ufl.edu><317989582993CA09CAF21AA6@bio-mammal026.bio.bris.ac.uk><4A2FF7FA.1060603@ufl.edu>
	<2E9C414912813E4EB981326983E0A1040690D1D3@inboexch.inbo.be>
Message-ID: <4A814D7C25E1493CAAF90A967ABAC712@GrantOTron>

Hello All,

I would like to use GLMMs with a binary response variable (logit link) to 
model the effects of three environmental covariates on whether resource 
units were used or unused by a wildlife species.  I have 15 different study 
areas, and very different numbers of used and unused units in each.  I'm 
interested in using fixed effects parameters estimates to predict the 
relative probabilities that resource units will be used across the entire 
population of study areas.  Numbers of used and unused units in each area 
look something like this:

Area    Unused    Used
01        281        2
02        4415      1
03        343        30
04        256        1
05        2052      4
06        4050      1
07        238        2
08        743        3
09        2476      18
10        2524      1
11        805        1
12        754        4
13        272        1
14        52          1
15        124        1

I've been using study area as a grouping factor for a random intercept and 
random slope effects:

fullmodel<-glmer(Used~1+x1+x2+x3+(1+x1+x2+x3|Area), family=binomial, 
data=mydata)

Using 'glmer', I've been able to fit models to my data without convergence 
issues, model fit is pretty good, and the results seem to make sense.  My 
questions are:  Given that the number of used units in each area are very 
unbalanced, to what degree can I generalize across the entire population of 
study areas?  Will my estimates for the fixed effects parameters be so 
reliant on areas 3 and 9 that I'm really just limited to inferences on these 
two areas?  Is there a way to quantify the relative weight of each study 
area in the estimation of the fixed effects parameters (i.e. the degree to 
which I can generalize across the entire population of study areas)?

I've read of borrow strength, which will certainly play a big role with this 
dataset, but I haven't found any examples of datasets that are as unbalanced 
as mine.

I realize that my questions relate to mixed models in general and less to 
their implementation in R, so I hope I'm not out-of-line in posting these 
questions here.  I'd guess there are probably answers to these questions in 
the literature, so I'd truly appreciate any advice on where I should look 
for more info.

Thanks in advance,

-Grant



From lborger at uoguelph.ca  Thu Jun 11 10:12:59 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 11 Jun 2009 04:12:59 -0400 (EDT)
Subject: [R-sig-ME] GLMMs with unequal group sizes
In-Reply-To: <4A814D7C25E1493CAAF90A967ABAC712@GrantOTron>
Message-ID: <863852546.2671241244707979246.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

as a simple quick check, have you tried fitting your model without area 3/9 or without both of them and compared the estimates? You could then also look at how well your fixed effects estimates predict the values in the left-out areas.

HTH

Cheers,

Luca


----- Original Message -----
From: Grant T. Stokke <gts127 at psu.edu>
To: r-sig-mixed-models at r-project.org
Sent: Wed, 10 Jun 2009 23:41:52 -0400 (EDT)
Subject: [R-sig-ME] GLMMs with unequal group sizes

Hello All,

I would like to use GLMMs with a binary response variable (logit link) to 
model the effects of three environmental covariates on whether resource 
units were used or unused by a wildlife species.  I have 15 different study 
areas, and very different numbers of used and unused units in each.  I'm 
interested in using fixed effects parameters estimates to predict the 
relative probabilities that resource units will be used across the entire 
population of study areas.  Numbers of used and unused units in each area 
look something like this:

Area    Unused    Used
01        281        2
02        4415      1
03        343        30
04        256        1
05        2052      4
06        4050      1
07        238        2
08        743        3
09        2476      18
10        2524      1
11        805        1
12        754        4
13        272        1
14        52          1
15        124        1

I've been using study area as a grouping factor for a random intercept and 
random slope effects:

fullmodel<-glmer(Used~1+x1+x2+x3+(1+x1+x2+x3|Area), family=binomial, 
data=mydata)

Using 'glmer', I've been able to fit models to my data without convergence 
issues, model fit is pretty good, and the results seem to make sense.  My 
questions are:  Given that the number of used units in each area are very 
unbalanced, to what degree can I generalize across the entire population of 
study areas?  Will my estimates for the fixed effects parameters be so 
reliant on areas 3 and 9 that I'm really just limited to inferences on these 
two areas?  Is there a way to quantify the relative weight of each study 
area in the estimation of the fixed effects parameters (i.e. the degree to 
which I can generalize across the entire population of study areas)?

I've read of borrow strength, which will certainly play a big role with this 
dataset, but I haven't found any examples of datasets that are as unbalanced 
as mine.

I realize that my questions relate to mixed models in general and less to 
their implementation in R, so I hope I'm not out-of-line in posting these 
questions here.  I'd guess there are probably answers to these questions in 
the literature, so I'd truly appreciate any advice on where I should look 
for more info.

Thanks in advance,

-Grant

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From f.m.underwood at reading.ac.uk  Thu Jun 11 14:14:46 2009
From: f.m.underwood at reading.ac.uk (Fiona Mary Underwood)
Date: Thu, 11 Jun 2009 13:14:46 +0100
Subject: [R-sig-ME] Binary data - zero random effects or not depending on a
	small change in the level 2 groups
Message-ID: <F6F0546CBBC4ED42B4663305298566F846714A@VIME-VS1.rdg-home.ad.rdg.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090611/3a498cb5/attachment.pl>

From f.calboli at imperial.ac.uk  Thu Jun 11 14:21:29 2009
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 11 Jun 2009 13:21:29 +0100
Subject: [R-sig-ME] Binary data - zero random effects or not depending
	on a small change in the level 2 groups
In-Reply-To: <F6F0546CBBC4ED42B4663305298566F846714A@VIME-VS1.rdg-home.ad.rdg.ac.uk>
References: <F6F0546CBBC4ED42B4663305298566F846714A@VIME-VS1.rdg-home.ad.rdg.ac.uk>
Message-ID: <6EA5ACC8-026F-4F73-9421-68BDBC8B6E89@imperial.ac.uk>

On 11 Jun 2009, at 13:14, Fiona Mary Underwood wrote:

> <snip>
>
>
> I get very different results for my random effects depending on  
> whether
> I use season or year.


Unfortunately I cannot help much, but, does the result change if year  
is coded as factor or as a continuous variable? what about season?

Best,

Federico

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From rense.nieuwenhuis at me.com  Thu Jun 11 14:24:29 2009
From: rense.nieuwenhuis at me.com (Rense Nieuwenhuis)
Date: Thu, 11 Jun 2009 14:24:29 +0200
Subject: [R-sig-ME] GLMMs with unequal group sizes
In-Reply-To: <863852546.2671241244707979246.JavaMail.root@huron.cs.uoguelph.ca>
References: <863852546.2671241244707979246.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <C0A9D4FE-9187-4B32-8E9E-15434CBFC204@me.com>

Hello Grant,

related to the previous remark (re-fitting the model without some of  
the areas), you might be interested in the influence.ME package, which  
I developed. Although focused on measures of influential data  
regarding variables at the level of the area (in your example), you  
could use the estex() function which will return the fixed estimates  
iteratively excluding each of the areas.

If you need help with using the package, you can contact me off-list.

Kind regards,

Rense Nieuwenhuis


On 11 jun 2009, at 10:12, Luca Borger wrote:

> Hello,
>
> as a simple quick check, have you tried fitting your model without  
> area 3/9 or without both of them and compared the estimates? You  
> could then also look at how well your fixed effects estimates  
> predict the values in the left-out areas.
>
> HTH
>
> Cheers,
>
> Luca
>
>
> ----- Original Message -----
> From: Grant T. Stokke <gts127 at psu.edu>
> To: r-sig-mixed-models at r-project.org
> Sent: Wed, 10 Jun 2009 23:41:52 -0400 (EDT)
> Subject: [R-sig-ME] GLMMs with unequal group sizes
>
> Hello All,
>
> I would like to use GLMMs with a binary response variable (logit  
> link) to
> model the effects of three environmental covariates on whether  
> resource
> units were used or unused by a wildlife species.  I have 15  
> different study
> areas, and very different numbers of used and unused units in each.   
> I'm
> interested in using fixed effects parameters estimates to predict the
> relative probabilities that resource units will be used across the  
> entire
> population of study areas.  Numbers of used and unused units in each  
> area
> look something like this:
>
> Area    Unused    Used
> 01        281        2
> 02        4415      1
> 03        343        30
> 04        256        1
> 05        2052      4
> 06        4050      1
> 07        238        2
> 08        743        3
> 09        2476      18
> 10        2524      1
> 11        805        1
> 12        754        4
> 13        272        1
> 14        52          1
> 15        124        1
>
> I've been using study area as a grouping factor for a random  
> intercept and
> random slope effects:
>
> fullmodel<-glmer(Used~1+x1+x2+x3+(1+x1+x2+x3|Area), family=binomial,
> data=mydata)
>
> Using 'glmer', I've been able to fit models to my data without  
> convergence
> issues, model fit is pretty good, and the results seem to make  
> sense.  My
> questions are:  Given that the number of used units in each area are  
> very
> unbalanced, to what degree can I generalize across the entire  
> population of
> study areas?  Will my estimates for the fixed effects parameters be so
> reliant on areas 3 and 9 that I'm really just limited to inferences  
> on these
> two areas?  Is there a way to quantify the relative weight of each  
> study
> area in the estimation of the fixed effects parameters (i.e. the  
> degree to
> which I can generalize across the entire population of study areas)?
>
> I've read of borrow strength, which will certainly play a big role  
> with this
> dataset, but I haven't found any examples of datasets that are as  
> unbalanced
> as mine.
>
> I realize that my questions relate to mixed models in general and  
> less to
> their implementation in R, so I hope I'm not out-of-line in posting  
> these
> questions here.  I'd guess there are probably answers to these  
> questions in
> the literature, so I'd truly appreciate any advice on where I should  
> look
> for more info.
>
> Thanks in advance,
>
> -Grant
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From danielezrajohnson at gmail.com  Thu Jun 11 14:49:53 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 11 Jun 2009 08:49:53 -0400
Subject: [R-sig-ME] Binary data - zero random effects or not depending
	on a small change in the level 2 groups
In-Reply-To: <6EA5ACC8-026F-4F73-9421-68BDBC8B6E89@imperial.ac.uk>
References: <F6F0546CBBC4ED42B4663305298566F846714A@VIME-VS1.rdg-home.ad.rdg.ac.uk>
	<6EA5ACC8-026F-4F73-9421-68BDBC8B6E89@imperial.ac.uk>
Message-ID: <a46630750906110549o3bdd6ebftfbe89d287d4b0da4@mail.gmail.com>

I would say that you have roughly zero variance in both cases.

On Thu, Jun 11, 2009 at 8:21 AM, Federico
Calboli<f.calboli at imperial.ac.uk> wrote:
> On 11 Jun 2009, at 13:14, Fiona Mary Underwood wrote:
>
>> <snip>
>>
>>
>> I get very different results for my random effects depending on whether
>> I use season or year.
>
>
> Unfortunately I cannot help much, but, does the result change if year is
> coded as factor or as a continuous variable? what about season?
>
> Best,
>
> Federico
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From danielezrajohnson at gmail.com  Thu Jun 11 14:56:56 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 11 Jun 2009 08:56:56 -0400
Subject: [R-sig-ME] GLMMs with unequal group sizes
In-Reply-To: <4A814D7C25E1493CAAF90A967ABAC712@GrantOTron>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
	<4A2FB29D.1050608@ufl.edu>
	<E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>
	<4A2FBC26.8040102@ufl.edu>
	<2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>
	<4A2FC253.4030308@ufl.edu>
	<317989582993CA09CAF21AA6@bio-mammal026.bio.bris.ac.uk>
	<4A2FF7FA.1060603@ufl.edu>
	<2E9C414912813E4EB981326983E0A1040690D1D3@inboexch.inbo.be>
	<4A814D7C25E1493CAAF90A967ABAC712@GrantOTron>
Message-ID: <a46630750906110556q23fd7b67yc26c93820f176e0f@mail.gmail.com>

On Wed, Jun 10, 2009 at 11:41 PM, Grant T. Stokke<gts127 at psu.edu> wrote:
> Hello All,
>
> I would like to use GLMMs with a binary response variable (logit link) to
> model the effects of three environmental covariates on whether resource
> units were used or unused by a wildlife species.  I have 15 different study
> areas, and very different numbers of used and unused units in each.  I'm
> interested in using fixed effects parameters estimates to predict the
> relative probabilities that resource units will be used across the entire
> population of study areas.  Numbers of used and unused units in each area
> look something like this:
>
> Area    Unused    Used
> 01        281        2
> 02        4415      1
> 03        343        30
> 04        256        1
> 05        2052      4
> 06        4050      1
> 07        238        2
> 08        743        3
> 09        2476      18
> 10        2524      1
> 11        805        1
> 12        754        4
> 13        272        1
> 14        52          1
> 15        124        1
>
> I've been using study area as a grouping factor for a random intercept and
> random slope effects:
>
> fullmodel<-glmer(Used~1+x1+x2+x3+(1+x1+x2+x3|Area), family=binomial,
> data=mydata)

Does this mean that the number of Unused units is not included
anywhere in the model?



From Fabian.Scheipl at stat.uni-muenchen.de  Thu Jun 11 17:17:46 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Thu, 11 Jun 2009 17:17:46 +0200
Subject: [R-sig-ME] GLMM-Implementation question
Message-ID: <4836bc6a0906110817x61b13510ia146b2ceeeefe6eb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090611/0db523ee/attachment.pl>

From adrihumanes at yahoo.com  Thu Jun 11 17:43:56 2009
From: adrihumanes at yahoo.com (AdRiAnA HuMaNeS)
Date: Thu, 11 Jun 2009 08:43:56 -0700 (PDT)
Subject: [R-sig-ME] Mixed model wiht 4 factors and unbalanced data
Message-ID: <179119.66434.qm@web33108.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090611/418cc839/attachment.pl>

From Fabian.Scheipl at stat.uni-muenchen.de  Thu Jun 11 17:38:25 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Thu, 11 Jun 2009 17:38:25 +0200
Subject: [R-sig-ME] GLMM-Implementation question
In-Reply-To: <4836bc6a0906110817x61b13510ia146b2ceeeefe6eb@mail.gmail.com>
References: <4836bc6a0906110817x61b13510ia146b2ceeeefe6eb@mail.gmail.com>
Message-ID: <4836bc6a0906110838t530cea7aqf7a4a0843693502b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090611/95797d9e/attachment.pl>

From bates at stat.wisc.edu  Thu Jun 11 18:06:28 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 11 Jun 2009 11:06:28 -0500
Subject: [R-sig-ME] GLMM-Implementation question
In-Reply-To: <4836bc6a0906110838t530cea7aqf7a4a0843693502b@mail.gmail.com>
References: <4836bc6a0906110817x61b13510ia146b2ceeeefe6eb@mail.gmail.com>
	<4836bc6a0906110838t530cea7aqf7a4a0843693502b@mail.gmail.com>
Message-ID: <40e66e0b0906110906m4088ab36nf7b254b8cc3a7663@mail.gmail.com>

On Thu, Jun 11, 2009 at 10:38 AM, Fabian
Scheipl<Fabian.Scheipl at stat.uni-muenchen.de> wrote:
> Never mind me, the answer to the second question is:
> update_u (called by update_dev) iteratively updates the orthonormalized
> random effects until convergence each time before S_nlminb_iterate is
> called.

Yes.  I was about to write that.

> On Thu, Jun 11, 2009 at 5:17 PM, Fabian Scheipl <
> Fabian.Scheipl at stat.uni-muenchen.de> wrote:

>> Dear List,
>>
>> Preparing the slides for a lecture on GLMMs I'm giving next week I noticed
>> that I don't quite understand eq. 40 (Laplace Approximation of a
>> GLMM-Likelihood) in the Implementation-vignette for lme4.
>> I would be extremely grateful ?(my students as well, of course, but
>> probably significiantly less so ;) ) if somebody would find the time to
>> offer his/her thoughts on some of the following points:
>>
>> I do not understand how the expression that is exponentiated ?in the second
>> line is equivalent to the quadratic Taylor-approximation of the penalized
>> log-likelihood around the conditional mode \tilde b.
>>
>> AFAIU the first two terms in the sum is just the penalized log-likelihood
>> evaluated at the conditional modes \tilde b. The first term is the
>> likelihood of y conditional on fixed and random effects, the second is
>> equivalent to \tilde b ' G^{-1} \tilde b.
>> [should be \tilde b^\star ' \tilde b^\star instead of ?\tilde b ' \tilde
>> b^\star, I think? Also, there are two plus signs after that].

I would have to go back and look at that document more carefully to be
able to answer these questions.  Unfortunately I am in "crunch mode"
on another project right now and I don't think I will be able to free
up the time today.

>> The next term should probably read (b^- \tilde b) ' D^-1 (b - \tilde b),
>> the quadratic term in the Taylor-approximation.
>> What bothers me is that, as D is defined in eq. 39 [ which should define
>> Var(b^\star|...), not Var(b|...) ],
>> it is the inverse of the expected Fisher-Info for b^\star, not the observed
>> - e.g. we are not using an expression for the second derivative but for its
>> expectation - ?doesn't that make a difference and is what we are doing still
>> a Laplace-Approximation in the conventional sense?
>>
>> My second question: I got lost in the source for lmer - in which function
>> called by ST_setPars ?do the PIRLS-updates for b happen and do we actually
>> do Fisher-scoring until convergence for b every time we update \beta and
>> \theta or is it just a single fisher-scoring step on b before each call to
>> S_nlminb_iterate?
>>
>> Best Wishes,
>> Fabian Scheipl
>>
>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From otter at otter-rsch.com  Thu Jun 11 19:12:38 2009
From: otter at otter-rsch.com (dave fournier)
Date: Thu, 11 Jun 2009 10:12:38 -0700
Subject: [R-sig-ME] Beta-binomial distributions with lmer?
In-Reply-To: <2E9C414912813E4EB981326983E0A1040690D1D3@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A1040690D1D3@inboexch.inbo.be>
Message-ID: <4A313B06.8080400@otter-rsch.com>


Well there are papers that argue against this sort of ad hoc approach.
See for example

http://psychology3.anu.edu.au/people/smithson/details/Pubs/Smithson_Verkuilen06.pdf

which is about beta regression for bounded dependent variables.


-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From cwilke at mail.utexas.edu  Thu Jun 11 19:58:23 2009
From: cwilke at mail.utexas.edu (Claus Wilke)
Date: Thu, 11 Jun 2009 12:58:23 -0500
Subject: [R-sig-ME] forcing uncorrelated random effects
Message-ID: <200906111258.23972.cwilke@mail.utexas.edu>

Dear list,

by default, lmer assumes that random effects are correlated. Is it possible to 
force them to be uncorrelated?

Specifically, assume I'm measuring cell counts in multiple patients over time, 
and want to fit the following two models:
> m1 = lmer( count ~ (1|patient)+time )
> m2 = lmer( count ~ (time|patient)+time )
Model 2 has two additional parameters over model 1, a variance of random 
slopes and a covariance of random slopes and random intercepts. How do I 
specify a model that has random slopes but no covariance between slopes and 
intercepts?

Thanks a lot,
  Claus

-- 
Claus Wilke
Section of Integrative Biology 
 and Center for Computational Biology and Bioinformatics 
University of Texas at Austin
1 University Station C0930
Austin, TX 78712
cwilke at mail.utexas.edu
512 471 6028



From danielezrajohnson at gmail.com  Thu Jun 11 20:03:10 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 11 Jun 2009 14:03:10 -0400
Subject: [R-sig-ME] forcing uncorrelated random effects
In-Reply-To: <200906111258.23972.cwilke@mail.utexas.edu>
References: <200906111258.23972.cwilke@mail.utexas.edu>
Message-ID: <a46630750906111103h5ffe89e1oe2713e64303d269e@mail.gmail.com>

>> m1 = lmer( count ~ (1|patient)+time )
>> m2 = lmer( count ~ (time|patient)+time )
> Model 2 has two additional parameters over model 1, a variance of random
> slopes and a covariance of random slopes and random intercepts. How do I
> specify a model that has random slopes but no covariance between slopes and
> intercepts?

m3  = lmer( count ~ (0+time|patient)+(1|patient)+time)

i believe this is what you are looking for.

dan



From HDoran at air.org  Thu Jun 11 20:19:56 2009
From: HDoran at air.org (Doran, Harold)
Date: Thu, 11 Jun 2009 14:19:56 -0400
Subject: [R-sig-ME] forcing uncorrelated random effects
In-Reply-To: <200906111258.23972.cwilke@mail.utexas.edu>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE029FFAEE@DC1EXCL01.air.org>

Here is an example. The second has no correlation.

(fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
(fm2 <- lmer(Reaction ~ Days + (Days - 1|Subject), sleepstudy)) 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Claus Wilke
> Sent: Thursday, June 11, 2009 1:58 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] forcing uncorrelated random effects
> 
> Dear list,
> 
> by default, lmer assumes that random effects are correlated. 
> Is it possible to force them to be uncorrelated?
> 
> Specifically, assume I'm measuring cell counts in multiple 
> patients over time, and want to fit the following two models:
> > m1 = lmer( count ~ (1|patient)+time )
> > m2 = lmer( count ~ (time|patient)+time )
> Model 2 has two additional parameters over model 1, a 
> variance of random slopes and a covariance of random slopes 
> and random intercepts. How do I specify a model that has 
> random slopes but no covariance between slopes and intercepts?
> 
> Thanks a lot,
>   Claus
> 
> --
> Claus Wilke
> Section of Integrative Biology
>  and Center for Computational Biology and Bioinformatics 
> University of Texas at Austin
> 1 University Station C0930
> Austin, TX 78712
> cwilke at mail.utexas.edu
> 512 471 6028
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From HDoran at air.org  Thu Jun 11 20:28:12 2009
From: HDoran at air.org (Doran, Harold)
Date: Thu, 11 Jun 2009 14:28:12 -0400
Subject: [R-sig-ME] forcing uncorrelated random effects
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE029FFAEE@DC1EXCL01.air.org>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE029FFAF4@DC1EXCL01.air.org>

I forgot a term

lmer(Reaction ~ Days + (1|Subject) + (Days-1|Subject), sleepstudy) 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Doran, Harold
> Sent: Thursday, June 11, 2009 2:20 PM
> To: Claus Wilke; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] forcing uncorrelated random effects
> 
> Here is an example. The second has no correlation.
> 
> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> (fm2 <- lmer(Reaction ~ Days + (Days - 1|Subject), sleepstudy)) 
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Claus 
> > Wilke
> > Sent: Thursday, June 11, 2009 1:58 PM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] forcing uncorrelated random effects
> > 
> > Dear list,
> > 
> > by default, lmer assumes that random effects are correlated. 
> > Is it possible to force them to be uncorrelated?
> > 
> > Specifically, assume I'm measuring cell counts in multiple patients 
> > over time, and want to fit the following two models:
> > > m1 = lmer( count ~ (1|patient)+time )
> > > m2 = lmer( count ~ (time|patient)+time )
> > Model 2 has two additional parameters over model 1, a variance of 
> > random slopes and a covariance of random slopes and random 
> intercepts. 
> > How do I specify a model that has random slopes but no covariance 
> > between slopes and intercepts?
> > 
> > Thanks a lot,
> >   Claus
> > 
> > --
> > Claus Wilke
> > Section of Integrative Biology
> >  and Center for Computational Biology and Bioinformatics 
> University of 
> > Texas at Austin
> > 1 University Station C0930
> > Austin, TX 78712
> > cwilke at mail.utexas.edu
> > 512 471 6028
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From cwilke at mail.utexas.edu  Thu Jun 11 20:28:50 2009
From: cwilke at mail.utexas.edu (Claus Wilke)
Date: Thu, 11 Jun 2009 13:28:50 -0500
Subject: [R-sig-ME] forcing uncorrelated random effects
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE029FFAEE@DC1EXCL01.air.org>
References: <ED7B522EE00C9A4FA515AA71724D61EE029FFAEE@DC1EXCL01.air.org>
Message-ID: <200906111328.50457.cwilke@mail.utexas.edu>

> Here is an example. The second has no correlation.
>
> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> (fm2 <- lmer(Reaction ~ Days + (Days - 1|Subject), sleepstudy))
I don't think that's the correct answer. Model fm2 is also lacking a random 
intercept:

> summary(fm2)               
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days - 1 | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1775 1787 -883.3     1774    1767
Random effects:
 Groups   Name Variance Std.Dev.
 Subject  Days  52.708   7.260
 Residual      842.030  29.018
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      4.020   62.54
Days          10.467      1.869    5.60

Correlation of Fixed Effects:
     (Intr)
Days -0.340


Compare this to the answer by Daniel Johnson:
> (fm2 <- lmer(Reaction ~ Days + (0+Days|Subject) + (1|Subject), sleepstudy))
Linear mixed model fit by REML
Formula: Reaction ~ Days + (0 + Days | Subject) + (1 | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1754 1770 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  Days         35.858   5.9882
 Subject  (Intercept) 627.568  25.0513
 Residual             653.584  25.5653
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.885   36.52
Days          10.467      1.560    6.71

Correlation of Fixed Effects:
     (Intr)
Days -0.184

-- 
Claus Wilke
Section of Integrative Biology 
 and Center for Computational Biology and Bioinformatics 
University of Texas at Austin
1 University Station C0930
Austin, TX 78712
cwilke at mail.utexas.edu
512 471 6028



From gts127 at psu.edu  Thu Jun 11 20:47:13 2009
From: gts127 at psu.edu (Grant T. Stokke)
Date: Thu, 11 Jun 2009 14:47:13 -0400
Subject: [R-sig-ME] GLMMs with unequal group sizes
In-Reply-To: <a46630750906110556q23fd7b67yc26c93820f176e0f@mail.gmail.com>
References: <3C0A193CF42FC1334489423A@bio-mammal026.bio.bris.ac.uk>
	<4A2FB29D.1050608@ufl.edu>
	<E6B0FDDA4134BC139C52C35D@bio-mammal026.bio.bris.ac.uk>
	<4A2FBC26.8040102@ufl.edu>
	<2E9C414912813E4EB981326983E0A1040690D192@inboexch.inbo.be>
	<4A2FC253.4030308@ufl.edu>
	<317989582993CA09CAF21AA6@bio-mammal026.bio.bris.ac.uk>
	<4A2FF7FA.1060603@ufl.edu>
	<2E9C414912813E4EB981326983E0A1040690D1D3@inboexch.inbo.be>
	<4A814D7C25E1493CAAF90A967ABAC712@GrantOTron>
	<a46630750906110556q23fd7b67yc26c93820f176e0f@mail.gmail.com>
Message-ID: <85881E901D3F4B2281E2237FA083E532@GrantOTron>

Sorry, I should have been more clear.  The number of unused units is 
included.  The response variable is "Used", so that used units have Used=1 
and unused units have Used=0.

Thanks for the input.  I've been looking at the influence of the areas with 
many used units on parameter estimates (by removing areas 3 and 9), and they 
appear to be more influential than I would like.  Ideally, I'd like each 
study area to receive approximately equal weight in parameter estimation. 
Is that possible?  Would it be inappropriate to use the 'weight' option in 
glmer to give study areas more equal weight?  Any suggestions?

Thanks,

-Grant

----- Original Message ----- 
From: "Daniel Ezra Johnson" <danielezrajohnson at gmail.com>
To: "Grant T. Stokke" <gts127 at psu.edu>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Thursday, June 11, 2009 8:56 AM
Subject: Re: [R-sig-ME] GLMMs with unequal group sizes


> On Wed, Jun 10, 2009 at 11:41 PM, Grant T. Stokke<gts127 at psu.edu> wrote:
>> Hello All,
>>
>> I would like to use GLMMs with a binary response variable (logit link) to
>> model the effects of three environmental covariates on whether resource
>> units were used or unused by a wildlife species.  I have 15 different 
>> study
>> areas, and very different numbers of used and unused units in each.  I'm
>> interested in using fixed effects parameters estimates to predict the
>> relative probabilities that resource units will be used across the entire
>> population of study areas.  Numbers of used and unused units in each area
>> look something like this:
>>
>> Area    Unused    Used
>> 01        281        2
>> 02        4415      1
>> 03        343        30
>> 04        256        1
>> 05        2052      4
>> 06        4050      1
>> 07        238        2
>> 08        743        3
>> 09        2476      18
>> 10        2524      1
>> 11        805        1
>> 12        754        4
>> 13        272        1
>> 14        52          1
>> 15        124        1
>>
>> I've been using study area as a grouping factor for a random intercept 
>> and
>> random slope effects:
>>
>> fullmodel<-glmer(Used~1+x1+x2+x3+(1+x1+x2+x3|Area), family=binomial,
>> data=mydata)
>
> Does this mean that the number of Unused units is not included
> anywhere in the model?
>



From mmackinnon at kilifi.kemri-wellcome.org  Fri Jun 12 14:00:30 2009
From: mmackinnon at kilifi.kemri-wellcome.org (Margaret Mackinnon)
Date: Fri, 12 Jun 2009 15:00:30 +0300
Subject: [R-sig-ME] Problem installing RLRsim
Message-ID: <4A326EC1.10CE.001C.0@kilifi.kemri-wellcome.org>

Hi

I am trying to install RLRsim.  I get an error message (below) saying that access is denied to one of the files

Error:  Access is denied.
Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll

Leow this message is the log when I try to use Winzip to unpack it. I get the same message as above when installing it through the R-GUI.

Thanks in advance for advice.

Margaret







Extracting to "C:\Program Files\R\R-2.8.1\library\RLRsim\"
Use Path: yes   Overlay Files: no
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\chtml\
Extracting RLRsim.chm
Extracting CONTENTS
Extracting DESCRIPTION
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\help\
Extracting AnIndex
Extracting exactLRT
Extracting exactRLRT
Extracting extract.lmeDesign
Extracting LRTSim
Extracting RLRsim-package
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\html\
Extracting 00Index.html
Extracting exactLRT.html
Extracting exactRLRT.html
Extracting extract.lmeDesign.html
Extracting LRTSim.html
Extracting RLRsim-package.html
Extracting INDEX
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\latex\
Extracting exactLRT.tex
Extracting exactRLRT.tex
Extracting extract.lmeDesign.tex
Extracting LRTSim.tex
Extracting RLRsim-package.tex
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\
Error:  Access is denied.
Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\man\
Extracting RLRsim.Rd.gz
Extracting MD5
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\Meta\
Extracting hsearch.rds
Extracting nsInfo.rds
Extracting package.rds
Extracting Rd.rds
Extracting NAMESPACE
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R\
Extracting RLRsim
Extracting RLRsim.rdb
Extracting RLRsim.rdx
creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R-ex\
Extracting exactLRT.R
Extracting exactRLRT.R
Extracting extract.lmeDesign.R
Extracting LRTSim.R



Dr. Margaret Mackinnon

KEMRI-Wellcome Collaborative Programme, Coast                        
PO Box 230   
Kilifi
Kenya
mmackinnon at kilifi.kemri-wellcome.org
+ 254 417 522535 Ext 228
+ 254 417 522390


This e-mail (including any attachment to it) contains information
which is confidential. It is intended only for the use of the named
recipient. If you have received this e-mail in error, please let us know
by replying to the sender, and immediately delete it from your system.
Please note, that in these circumstances, the use, disclosure,
distribution or copying of this information is strictly prohibited. We
apologize for any inconvenience that may have been caused to you.
KEMRI-Wellcome Trust Programmecannot accept any responsibility for the accuracy
or completeness of this message as it has been transmitted over a public
network. KEMRI-Wellcome Trust Programme reserves the right to monitor all incoming and
outgoing email traffic. Although the Programme has taken reasonable
precautions to ensure no viruses are present in emails, it cannot
accept responsibility for any loss or damage arising from the use of the
email or attachments. Any views expressed in this message are those of
the individual sender, except where the sender specifically states them
to be the views of KEMRI- Wellcome Trust Programme".



From ccleland at optonline.net  Fri Jun 12 15:16:56 2009
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 12 Jun 2009 09:16:56 -0400
Subject: [R-sig-ME] Problem installing RLRsim
In-Reply-To: <4A326EC1.10CE.001C.0@kilifi.kemri-wellcome.org>
References: <4A326EC1.10CE.001C.0@kilifi.kemri-wellcome.org>
Message-ID: <4A325548.6090302@optonline.net>

On 6/12/2009 8:00 AM, Margaret Mackinnon wrote:
> Hi
> 
> I am trying to install RLRsim.  I get an error message (below) saying that access is denied to one of the files
> 
> Error:  Access is denied.
> Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll
> 
> Leow this message is the log when I try to use Winzip to unpack it. I get the same message as above when installing it through the R-GUI.
> 
> Thanks in advance for advice.

  It works for me using install.packages():

> install.packages("RLRsim")
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.fhcrc.org/bin/windows/contrib/2.9/RLRsim_2.0-2.zip'
Content type 'application/zip' length 254255 bytes (248 Kb)
opened URL
downloaded 248 Kb

package 'RLRsim' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\Documents and Settings\Chuck\Local
Settings\Temp\RtmpDyABNe\downloaded_packages
updating HTML package descriptions

> library(RLRsim)

> library(mgcv)
This is mgcv  1.5-5 . For overview type `help("mgcv-package")'.

> data(trees)

> m.q<-gamm(I(log(Volume)) ~ Height + s(Girth, m = 3), data = trees,
method = "REML")$lme

Loading required package: nlme

> exactRLRT(m.q)

        simulated finite sample distribution of RLRT.  (p-value based on
10000 simulated values)

data:
RLRT = 0, p-value = 1

> sessionInfo()
R version 2.9.0 Patched (2009-05-23 r48600)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-92  mgcv_1.5-5   RLRsim_2.0-2

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-25 tools_2.9.0

> Margaret
> 
> Extracting to "C:\Program Files\R\R-2.8.1\library\RLRsim\"
> Use Path: yes   Overlay Files: no
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\chtml\
> Extracting RLRsim.chm
> Extracting CONTENTS
> Extracting DESCRIPTION
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\help\
> Extracting AnIndex
> Extracting exactLRT
> Extracting exactRLRT
> Extracting extract.lmeDesign
> Extracting LRTSim
> Extracting RLRsim-package
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\html\
> Extracting 00Index.html
> Extracting exactLRT.html
> Extracting exactRLRT.html
> Extracting extract.lmeDesign.html
> Extracting LRTSim.html
> Extracting RLRsim-package.html
> Extracting INDEX
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\latex\
> Extracting exactLRT.tex
> Extracting exactRLRT.tex
> Extracting extract.lmeDesign.tex
> Extracting LRTSim.tex
> Extracting RLRsim-package.tex
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\
> Error:  Access is denied.
> Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\man\
> Extracting RLRsim.Rd.gz
> Extracting MD5
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\Meta\
> Extracting hsearch.rds
> Extracting nsInfo.rds
> Extracting package.rds
> Extracting Rd.rds
> Extracting NAMESPACE
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R\
> Extracting RLRsim
> Extracting RLRsim.rdb
> Extracting RLRsim.rdx
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R-ex\
> Extracting exactLRT.R
> Extracting exactRLRT.R
> Extracting extract.lmeDesign.R
> Extracting LRTSim.R
> 
> 
> 
> Dr. Margaret Mackinnon
> 
> KEMRI-Wellcome Collaborative Programme, Coast                        
> PO Box 230   
> Kilifi
> Kenya
> mmackinnon at kilifi.kemri-wellcome.org
> + 254 417 522535 Ext 228
> + 254 417 522390
> 
> 
> This e-mail (including any attachment to it) contains information
> which is confidential. It is intended only for the use of the named
> recipient. If you have received this e-mail in error, please let us know
> by replying to the sender, and immediately delete it from your system.
> Please note, that in these circumstances, the use, disclosure,
> distribution or copying of this information is strictly prohibited. We
> apologize for any inconvenience that may have been caused to you.
> KEMRI-Wellcome Trust Programmecannot accept any responsibility for the accuracy
> or completeness of this message as it has been transmitted over a public
> network. KEMRI-Wellcome Trust Programme reserves the right to monitor all incoming and
> outgoing email traffic. Although the Programme has taken reasonable
> precautions to ensure no viruses are present in emails, it cannot
> accept responsibility for any loss or damage arising from the use of the
> email or attachments. Any views expressed in this message are those of
> the individual sender, except where the sender specifically states them
> to be the views of KEMRI- Wellcome Trust Programme".
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc. (www.ndri.org)
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From danielezrajohnson at gmail.com  Fri Jun 12 15:20:27 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Fri, 12 Jun 2009 09:20:27 -0400
Subject: [R-sig-ME] Problem installing RLRsim
In-Reply-To: <4A325548.6090302@optonline.net>
References: <4A326EC1.10CE.001C.0@kilifi.kemri-wellcome.org>
	<4A325548.6090302@optonline.net>
Message-ID: <a46630750906120620n55fb3f6xe0200a7bf4b660ae@mail.gmail.com>

A similar error used to occur for me when trying to install R packages
on an office computer to which I was not a "super-user". I think it's
having trouble writing to the Library directory.

Dan

On Fri, Jun 12, 2009 at 9:16 AM, Chuck Cleland<ccleland at optonline.net> wrote:
> On 6/12/2009 8:00 AM, Margaret Mackinnon wrote:
>> Hi
>>
>> I am trying to install RLRsim.  I get an error message (below) saying that access is denied to one of the files
>>
>> Error:  Access is denied.
>> Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll
>>
>> Leow this message is the log when I try to use Winzip to unpack it. I get the same message as above when installing it through the R-GUI.
>>
>> Thanks in advance for advice.
>
>  It works for me using install.packages():
>
>> install.packages("RLRsim")
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/2.9/RLRsim_2.0-2.zip'
> Content type 'application/zip' length 254255 bytes (248 Kb)
> opened URL
> downloaded 248 Kb
>
> package 'RLRsim' successfully unpacked and MD5 sums checked
>
> The downloaded packages are in
>        C:\Documents and Settings\Chuck\Local
> Settings\Temp\RtmpDyABNe\downloaded_packages
> updating HTML package descriptions
>
>> library(RLRsim)
>
>> library(mgcv)
> This is mgcv  1.5-5 . For overview type `help("mgcv-package")'.
>
>> data(trees)
>
>> m.q<-gamm(I(log(Volume)) ~ Height + s(Girth, m = 3), data = trees,
> method = "REML")$lme
>
> Loading required package: nlme
>
>> exactRLRT(m.q)
>
>        simulated finite sample distribution of RLRT.  (p-value based on
> 10000 simulated values)
>
> data:
> RLRT = 0, p-value = 1
>
>> sessionInfo()
> R version 2.9.0 Patched (2009-05-23 r48600)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] nlme_3.1-92  mgcv_1.5-5   RLRsim_2.0-2
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0      lattice_0.17-25 tools_2.9.0
>
>> Margaret
>>
>> Extracting to "C:\Program Files\R\R-2.8.1\library\RLRsim\"
>> Use Path: yes   Overlay Files: no
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\chtml\
>> Extracting RLRsim.chm
>> Extracting CONTENTS
>> Extracting DESCRIPTION
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\help\
>> Extracting AnIndex
>> Extracting exactLRT
>> Extracting exactRLRT
>> Extracting extract.lmeDesign
>> Extracting LRTSim
>> Extracting RLRsim-package
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\html\
>> Extracting 00Index.html
>> Extracting exactLRT.html
>> Extracting exactRLRT.html
>> Extracting extract.lmeDesign.html
>> Extracting LRTSim.html
>> Extracting RLRsim-package.html
>> Extracting INDEX
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\latex\
>> Extracting exactLRT.tex
>> Extracting exactRLRT.tex
>> Extracting extract.lmeDesign.tex
>> Extracting LRTSim.tex
>> Extracting RLRsim-package.tex
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\
>> Error:  Access is denied.
>> Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\man\
>> Extracting RLRsim.Rd.gz
>> Extracting MD5
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\Meta\
>> Extracting hsearch.rds
>> Extracting nsInfo.rds
>> Extracting package.rds
>> Extracting Rd.rds
>> Extracting NAMESPACE
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R\
>> Extracting RLRsim
>> Extracting RLRsim.rdb
>> Extracting RLRsim.rdx
>> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R-ex\
>> Extracting exactLRT.R
>> Extracting exactRLRT.R
>> Extracting extract.lmeDesign.R
>> Extracting LRTSim.R
>>
>>
>>
>> Dr. Margaret Mackinnon
>>
>> KEMRI-Wellcome Collaborative Programme, Coast
>> PO Box 230
>> Kilifi
>> Kenya
>> mmackinnon at kilifi.kemri-wellcome.org
>> + 254 417 522535 Ext 228
>> + 254 417 522390
>>
>>
>> This e-mail (including any attachment to it) contains information
>> which is confidential. It is intended only for the use of the named
>> recipient. If you have received this e-mail in error, please let us know
>> by replying to the sender, and immediately delete it from your system.
>> Please note, that in these circumstances, the use, disclosure,
>> distribution or copying of this information is strictly prohibited. We
>> apologize for any inconvenience that may have been caused to you.
>> KEMRI-Wellcome Trust Programmecannot accept any responsibility for the accuracy
>> or completeness of this message as it has been transmitted over a public
>> network. KEMRI-Wellcome Trust Programme reserves the right to monitor all incoming and
>> outgoing email traffic. Although the Programme has taken reasonable
>> precautions to ensure no viruses are present in emails, it cannot
>> accept responsibility for any loss or damage arising from the use of the
>> email or attachments. Any views expressed in this message are those of
>> the individual sender, except where the sender specifically states them
>> to be the views of KEMRI- Wellcome Trust Programme".
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc. (www.ndri.org)
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From mmackinnon at kilifi.kemri-wellcome.org  Fri Jun 12 16:33:36 2009
From: mmackinnon at kilifi.kemri-wellcome.org (Margaret Mackinnon)
Date: Fri, 12 Jun 2009 17:33:36 +0300
Subject: [R-sig-ME] Problem installing RLRsim
In-Reply-To: <4A325548.6090302@optonline.net>
References: <4A326EC1.10CE.001C.0@kilifi.kemri-wellcome.org>
	<4A325548.6090302@optonline.net>
Message-ID: <4A3292A3.10CE.001C.0@kilifi.kemri-wellcome.org>

Thanks.  I turned off McAfee virus software and it worked.

Mgt

Dr. Margaret Mackinnon

KEMRI-Wellcome Collaborative Programme, Coast                        
PO Box 230   
Kilifi
Kenya
mmackinnon at kilifi.kemri-wellcome.org
+ 254 417 522535 Ext 228
+ 254 417 522390


>>> Chuck Cleland <ccleland at optonline.net> 12 June 2009 16:16 >>>
On 6/12/2009 8:00 AM, Margaret Mackinnon wrote:
> Hi
> 
> I am trying to install RLRsim.  I get an error message (below) saying that access is denied to one of the files
> 
> Error:  Access is denied.
> Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll
> 
> Leow this message is the log when I try to use Winzip to unpack it. I get the same message as above when installing it through the R-GUI.
> 
> Thanks in advance for advice.

  It works for me using install.packages():

> install.packages("RLRsim")
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.fhcrc.org/bin/windows/contrib/2.9/RLRsim_2.0-2.zip'
Content type 'application/zip' length 254255 bytes (248 Kb)
opened URL
downloaded 248 Kb

package 'RLRsim' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\Documents and Settings\Chuck\Local
Settings\Temp\RtmpDyABNe\downloaded_packages
updating HTML package descriptions

> library(RLRsim)

> library(mgcv)
This is mgcv  1.5-5 . For overview type `help("mgcv-package")'.

> data(trees)

> m.q<-gamm(I(log(Volume)) ~ Height + s(Girth, m = 3), data = trees,
method = "REML")$lme

Loading required package: nlme

> exactRLRT(m.q)

        simulated finite sample distribution of RLRT.  (p-value based on
10000 simulated values)

data:
RLRT = 0, p-value = 1

> sessionInfo()
R version 2.9.0 Patched (2009-05-23 r48600)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-92  mgcv_1.5-5   RLRsim_2.0-2

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-25 tools_2.9.0

> Margaret
> 
> Extracting to "C:\Program Files\R\R-2.8.1\library\RLRsim\"
> Use Path: yes   Overlay Files: no
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\chtml\
> Extracting RLRsim.chm
> Extracting CONTENTS
> Extracting DESCRIPTION
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\help\
> Extracting AnIndex
> Extracting exactLRT
> Extracting exactRLRT
> Extracting extract.lmeDesign
> Extracting LRTSim
> Extracting RLRsim-package
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\html\
> Extracting 00Index.html
> Extracting exactLRT.html
> Extracting exactRLRT.html
> Extracting extract.lmeDesign.html
> Extracting LRTSim.html
> Extracting RLRsim-package.html
> Extracting INDEX
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\latex\
> Extracting exactLRT.tex
> Extracting exactRLRT.tex
> Extracting extract.lmeDesign.tex
> Extracting LRTSim.tex
> Extracting RLRsim-package.tex
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\
> Error:  Access is denied.
> Cannot create C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\libs\RLRsim.dll
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\man\
> Extracting RLRsim.Rd.gz
> Extracting MD5
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\Meta\
> Extracting hsearch.rds
> Extracting nsInfo.rds
> Extracting package.rds
> Extracting Rd.rds
> Extracting NAMESPACE
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R\
> Extracting RLRsim
> Extracting RLRsim.rdb
> Extracting RLRsim.rdx
> creating: C:\Program Files\R\R-2.8.1\library\RLRsim\RLRsim\R-ex\
> Extracting exactLRT.R
> Extracting exactRLRT.R
> Extracting extract.lmeDesign.R
> Extracting LRTSim.R
> 
> 
> 
> Dr. Margaret Mackinnon
> 
> KEMRI-Wellcome Collaborative Programme, Coast                        
> PO Box 230   
> Kilifi
> Kenya
> mmackinnon at kilifi.kemri-wellcome.org 
> + 254 417 522535 Ext 228
> + 254 417 522390
> 
> 
> This e-mail (including any attachment to it) contains information
> which is confidential. It is intended only for the use of the named
> recipient. If you have received this e-mail in error, please let us know
> by replying to the sender, and immediately delete it from your system.
> Please note, that in these circumstances, the use, disclosure,
> distribution or copying of this information is strictly prohibited. We
> apologize for any inconvenience that may have been caused to you.
> KEMRI-Wellcome Trust Programmecannot accept any responsibility for the accuracy
> or completeness of this message as it has been transmitted over a public
> network. KEMRI-Wellcome Trust Programme reserves the right to monitor all incoming and
> outgoing email traffic. Although the Programme has taken reasonable
> precautions to ensure no viruses are present in emails, it cannot
> accept responsibility for any loss or damage arising from the use of the
> email or attachments. Any views expressed in this message are those of
> the individual sender, except where the sender specifically states them
> to be the views of KEMRI- Wellcome Trust Programme".
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc. (www.ndri.org)
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894

This e-mail (including any attachment to it) contains information
which is confidential. It is intended only for the use of the named
recipient. If you have received this e-mail in error, please let us know
by replying to the sender, and immediately delete it from your system.
Please note, that in these circumstances, the use, disclosure,
distribution or copying of this information is strictly prohibited. We
apologize for any inconvenience that may have been caused to you.
KEMRI-Wellcome Trust Programmecannot accept any responsibility for the accuracy
or completeness of this message as it has been transmitted over a public
network. KEMRI-Wellcome Trust Programme reserves the right to monitor all incoming and
outgoing email traffic. Although the Programme has taken reasonable
precautions to ensure no viruses are present in emails, it cannot
accept responsibility for any loss or damage arising from the use of the
email or attachments. Any views expressed in this message are those of
the individual sender, except where the sender specifically states them
to be the views of KEMRI- Wellcome Trust Programme".



From leandro at cesgranrio.org.br  Fri Jun 12 20:39:04 2009
From: leandro at cesgranrio.org.br (Leandro Marino)
Date: Fri, 12 Jun 2009 15:39:04 -0300
Subject: [R-sig-ME] Hierarchical Linear Models
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAEadxqYXQLlLmuUnwe+aKQfCgAAAEAAAAC77JhBaCg5IvFu0IervzgUBAAAAAA==@cesgranrio.org.br>

Hi,

 I want use R to do some Hierarchical Linear Models. Anybody has an example, book or paper to do that into R? Now I use the HLM software.

Thanks, 

Atenciosamente,
Leandro Lins Marino
Centro de Avalia??o
Funda??o CESGRANRIO
Rua Santa Alexandrina, 1011 - 2? andar
Rio de Janeiro, RJ - CEP: 20261-903
R (21) 2103-9600 R.:236 
  (21) 8777-7907
( leandro at cesgranrio.org.br

"Aquele que suporta o peso da sociedade
    ? precisamente aquele que obt?m
 as menores vantagens". (SMITH, Adam)

?  Antes de imprimir pense em sua responsabilidade e compromisso com o MEIO AMBIENTE 

Esta mensagem, incluindo seus anexos, pode conter informacoes privilegiadas e/ou de carater confidencial, nao podendo ser retransmitida sem autorizacao do remetente. Se voce nao e o destinatario ou pessoa autorizada a recebe-la, informamos que o seu uso, divulgacao, copia ou arquivamento sao proibidos. 
Portanto, se voc? recebeu esta mensagem por engano, por favor, nos informe respondendo imediatamente a este e-mail e em seguida apague-a.



From ral at lcfltd.com  Fri Jun 12 23:21:33 2009
From: ral at lcfltd.com (Robert A LaBudde)
Date: Fri, 12 Jun 2009 17:21:33 -0400
Subject: [R-sig-ME] Hierarchical Linear Models
Message-ID: <0KL500ALMA08B5L1@vms173003.mailsrvcs.net>

At 02:39 PM 6/12/2009, Leandro Marino wrote:
>Hi, I want use R to do some Hierarchical Linear 
>Models. Anybody has an example, book or paper to 
>do that into R? Now I use the HLM software. 
>Thanks, Atenciosamente, Leandro Lins Marino 
>Centro de Avalia????o Funda????o CESGRANRIO Rua 
>Santa Alexandrina, 1011 - 2?? andar Rio de Janeiro, RJ - CEP:

See Pinheiro & Bates, Mixed Models in S and 
S-Plus, and West et al., Linear Mixed Models.


================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"
================================================================



From erich.studerus at bli.uzh.ch  Sat Jun 13 16:57:54 2009
From: erich.studerus at bli.uzh.ch (Erich Studerus)
Date: Sat, 13 Jun 2009 16:57:54 +0200
Subject: [R-sig-ME] testing simple main effects by contrasts
Message-ID: <web-18987407@idmailbe1b.unizh.ch>


Hi,

I have the following study design: Each of two groups of subjects (group A 
and group B) was tested repeatedly on two experimental days. At each 
experimental day, placebo or drug were administered in a randomized order 
and subjects were tested under the the influence of the drug in 3 
consecutive blocks. I have therefore one between subjects factor (Group A vs 
Group B) and two within subjects factors (Drug and Block). Here's a 
reproducible example:

x <- expand.grid(Block= paste('B', 1:3, sep=''),
  Drug = c('Placebo', 'Drug'), Subj=1:24)
df <- data.frame(x, Group = rep(c('A','B'), each=72),
  value=rnorm(144, sd=10))
m <- model.matrix(lm(value~Group*Drug+Block,df))
df$value <- df$value+m[,2]*7+ m[,3]*2 + m[,4]*5 + m[,5]*8 + m[,6]-2
#delete some observations to simulate an unbalanced design
df <- df[-as.numeric(sample(rownames(df),20)),]

mod <- lme(value ~ Group*Drug+Block, random = ~1|Subj, data = df)
anova(mod)

Now, since the interaction between Drug and Group is significant, the main 
effects of Drug and Group can not be interpreted. I therefore define 
contrasts to test the simple main effects, that is, the effect of the Drug 
in each Group, averaged over all levels of the Block factor.

I use the contrast package to set up the contrasts:
library(contrast)
con1 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'A', Drug = 
'Pla'),
      list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug'), 
type='average')
con2 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'B', Drug = 
'Pla'),
      list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug'), 
type='average')

Now, I use the multcomp-package to correct the p-values for multiple 
comparisons:

library(multcomp)
summary(glht(mod, linfct = rbind(con1$X,con2$X)))

This approach works fine with lme, but not with lmer. In the model above I 
modeled the block factor as a fixed effect. However, according to my 
understanding, it would be more parsimonious to model the block factor as a 
random effect. I'm not directly interested in its effect and it's just an 
additional source of variance due to habituation effects . Unfortunately, 
the Block and Subj factors are crossed and therefore can not easily be 
modeled by lme. After comparing different models, the best fitting model 
with lmer looks like this:

lmer(value ~ Group*Drug+(Drug|Subj)+(1|Block))

How can I set up contrasts to test simple main effects for this lmer model? 
I know, that lmer has a contrasts argument. However, as far as I can see, 
one can only test contrasts for the levels of one factor at a time. Any 
comments are highly appreciated.

Erich



From reinhold.kliegl at gmail.com  Sat Jun 13 20:19:49 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 13 Jun 2009 20:19:49 +0200
Subject: [R-sig-ME] testing simple main effects by contrasts
In-Reply-To: <web-18987407@idmailbe1b.unizh.ch>
References: <web-18987407@idmailbe1b.unizh.ch>
Message-ID: <aefe4d0a0906131119i4f337c42ga583080c99360063@mail.gmail.com>

>From what I understand you want to test the effect of Drug within each
of the two Groups. Here is a simple way to do this:

# Convert 2 Drug x 2 Group design to 1 x 4 Cond design
df$Cond <- factor(paste(df$Group, df$Drug, sep="_"))

# ANOVA: one main, two nested fixed effects
cmat <- matrix(c( -1, -1, +1, +1,             # Main effect of Group
	                     -1, +1,  0,  0,             # Effect of Drug | Group==A
	                       0,  0, -1, +1),  4,  3)    # Effect of Drug | Group==B
colnames(cmat) <- c(".group", ".drug_A", ".drug_B")

contrasts(df$Cond) <- cmat/2
print(mod <- lmer(value ~ Cond + (1 |Subj), data=df), cor=FALSE)
print(mod <- lmer(value ~ Cond + Block + (1 |Subj), data=df),
cor=FALSE)  # Block as fixed effect
print(mod <- lmer(value ~ Cond + (1 |Subj) + (1|Block), data=df),
cor=FALSE) # Block as random effect

The fixed-effect coefficients reported correspond to
(Intercept)  = mean of four conditions
Group  = difference between the two groups
.drug_A = difference between Drug levels in Group A
.drug_B = difference between Drug levels in Group B

and associated standard errors and "t-values".  Estimates line up with
table means for balanced designs.

You mention 2 Days of testing but this factor did not appear in the example.

The models you tested with lme and lmer where structurally different
with respect to Block. Given that you have only 3  Blocks, I would
include Block as a fixed effect, not as a random effect, but opinions
differ on this. Anyway, this has not much of a bearing on the
estimates of the Group difference and the estimates of Drug effects
within Groups.

Reinhold Kliegl

On Sat, Jun 13, 2009 at 4:57 PM, Erich
Studerus<erich.studerus at bli.uzh.ch> wrote:
>
> Hi,
>
> I have the following study design: Each of two groups of subjects (group A
> and group B) was tested repeatedly on two experimental days. At each
> experimental day, placebo or drug were administered in a randomized order
> and subjects were tested under the the influence of the drug in 3
> consecutive blocks. I have therefore one between subjects factor (Group A vs
> Group B) and two within subjects factors (Drug and Block). Here's a
> reproducible example:
>
> x <- expand.grid(Block= paste('B', 1:3, sep=''),
> ?Drug = c('Placebo', 'Drug'), Subj=1:24)
> df <- data.frame(x, Group = rep(c('A','B'), each=72),
> ?value=rnorm(144, sd=10))
> m <- model.matrix(lm(value~Group*Drug+Block,df))
> df$value <- df$value+m[,2]*7+ m[,3]*2 + m[,4]*5 + m[,5]*8 + m[,6]-2
> #delete some observations to simulate an unbalanced design
> df <- df[-as.numeric(sample(rownames(df),20)),]
>
> mod <- lme(value ~ Group*Drug+Block, random = ~1|Subj, data = df)
> anova(mod)
>
> Now, since the interaction between Drug and Group is significant, the main
> effects of Drug and Group can not be interpreted. I therefore define
> contrasts to test the simple main effects, that is, the effect of the Drug
> in each Group, averaged over all levels of the Block factor.
>
> I use the contrast package to set up the contrasts:
> library(contrast)
> con1 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'A', Drug =
> 'Pla'),
> ? ? list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug'),
> type='average')
> con2 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'B', Drug =
> 'Pla'),
> ? ? list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug'),
> type='average')
>
> Now, I use the multcomp-package to correct the p-values for multiple
> comparisons:
>
> library(multcomp)
> summary(glht(mod, linfct = rbind(con1$X,con2$X)))
>
> This approach works fine with lme, but not with lmer. In the model above I
> modeled the block factor as a fixed effect. However, according to my
> understanding, it would be more parsimonious to model the block factor as a
> random effect. I'm not directly interested in its effect and it's just an
> additional source of variance due to habituation effects . Unfortunately,
> the Block and Subj factors are crossed and therefore can not easily be
> modeled by lme. After comparing different models, the best fitting model
> with lmer looks like this:
>
> lmer(value ~ Group*Drug+(Drug|Subj)+(1|Block))
>
> How can I set up contrasts to test simple main effects for this lmer model?
> I know, that lmer has a contrasts argument. However, as far as I can see,
> one can only test contrasts for the levels of one factor at a time. Any
> comments are highly appreciated.
>
> Erich
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From erich.studerus at bli.uzh.ch  Mon Jun 15 15:04:35 2009
From: erich.studerus at bli.uzh.ch (Erich Studerus)
Date: Mon, 15 Jun 2009 15:04:35 +0200
Subject: [R-sig-ME] testing simple main effects by contrasts
In-Reply-To: <aefe4d0a0906131119i4f337c42ga583080c99360063@mail.gmail.com>
Message-ID: <200906151304.n5FD4fqi001737@idmailgate1.unizh.ch>

Thank you so much. I highly appreciate your help.

However, when I extend my example to the case of a design with 3 drug
levels, the results that I get with the contrast-package and the results
that I get with your approach seem to differ. I don't know why this is the
case. Could you please have a look at the following example and tell me what
I'm doing wrong.

#prepare an example data.frame
set.seed(5)
x <- expand.grid(Block= paste('B', 1:3, sep=''),
Drug = c('Pla', 'Drug1','Drug2'), Subj=1:24)
df <- data.frame(x, Group = rep(c('A','B'), each=108),
value=rnorm(216, sd=10))
m <- model.matrix(lm(value~Group*Drug+Block,df))
df$value <- df$value+m[,2]*7+ m[,3]*2 + m[,4]*5+
 m[,5]*8 + m[,6]*-2+m[,7]*3+m[,8]*-5 
df <- df[-as.numeric(sample(rownames(df),20)),]

mod <- lme(value~Group*Drug+Block, random=~1|Subj,data=df)

library(contrast)
#Effect of Drug1 | Group A
contrast(mod,
list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Pla'),
list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug1'),
type='average')

#Effect of Drug2 | Group A
contrast(mod,
list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Pla'),
list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug2'),
type='average')

#Effect of Drug1 | Group B
contrast(mod,
list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Pla'),
list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug1'),
type='average')

#Effect of Drug2 | Group B
contrast(mod,
list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Pla'),
list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug2'),
type='average')


df$Cond <- with(df, interaction(Drug, Group))
#Main effect of Group
group <- c(-1,-1,-1,1,1,1)
#Effect of Drug1 | Group A
Drug1.A <- c(-1,1,0,0,0,0)
#Effect of Drug2 | Group A
Drug2.A <- c(-1,0,1,0,0,0)
#Effect of Drug1 | Group B
Drug1.B <- c(0,0,0,-1,1,0)
#Effect of Drug2 | Group B
Drug2.B <- c(0,0,0,-1,0,1)
contrasts(df$Cond) <- cbind(group, Drug1.A, Drug2.A,
Drug1.B, Drug2.B)/2

summary(lme(value ~ Cond + Block, random=~1|Subj,data=df))



-----Urspr?ngliche Nachricht-----
Von: Reinhold Kliegl [mailto:reinhold.kliegl at gmail.com] 
Gesendet: Samstag, 13. Juni 2009 20:20
An: Erich Studerus
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] testing simple main effects by contrasts

>From what I understand you want to test the effect of Drug within each
of the two Groups. Here is a simple way to do this:

# Convert 2 Drug x 2 Group design to 1 x 4 Cond design
df$Cond <- factor(paste(df$Group, df$Drug, sep="_"))

# ANOVA: one main, two nested fixed effects
cmat <- matrix(c( -1, -1, +1, +1,             # Main effect of Group
	                     -1, +1,  0,  0,             # Effect of Drug |
Group==A
	                       0,  0, -1, +1),  4,  3)    # Effect of Drug |
Group==B
colnames(cmat) <- c(".group", ".drug_A", ".drug_B")

contrasts(df$Cond) <- cmat/2
print(mod <- lmer(value ~ Cond + (1 |Subj), data=df), cor=FALSE)
print(mod <- lmer(value ~ Cond + Block + (1 |Subj), data=df),
cor=FALSE)  # Block as fixed effect
print(mod <- lmer(value ~ Cond + (1 |Subj) + (1|Block), data=df),
cor=FALSE) # Block as random effect

The fixed-effect coefficients reported correspond to
(Intercept)  = mean of four conditions
Group  = difference between the two groups
.drug_A = difference between Drug levels in Group A
.drug_B = difference between Drug levels in Group B

and associated standard errors and "t-values".  Estimates line up with
table means for balanced designs.

You mention 2 Days of testing but this factor did not appear in the example.

The models you tested with lme and lmer where structurally different
with respect to Block. Given that you have only 3  Blocks, I would
include Block as a fixed effect, not as a random effect, but opinions
differ on this. Anyway, this has not much of a bearing on the
estimates of the Group difference and the estimates of Drug effects
within Groups.

Reinhold Kliegl

On Sat, Jun 13, 2009 at 4:57 PM, Erich
Studerus<erich.studerus at bli.uzh.ch> wrote:
>
> Hi,
>
> I have the following study design: Each of two groups of subjects (group A
> and group B) was tested repeatedly on two experimental days. At each
> experimental day, placebo or drug were administered in a randomized order
> and subjects were tested under the the influence of the drug in 3
> consecutive blocks. I have therefore one between subjects factor (Group A
vs
> Group B) and two within subjects factors (Drug and Block). Here's a
> reproducible example:
>
> x <- expand.grid(Block= paste('B', 1:3, sep=''),
> ?Drug = c('Placebo', 'Drug'), Subj=1:24)
> df <- data.frame(x, Group = rep(c('A','B'), each=72),
> ?value=rnorm(144, sd=10))
> m <- model.matrix(lm(value~Group*Drug+Block,df))
> df$value <- df$value+m[,2]*7+ m[,3]*2 + m[,4]*5 + m[,5]*8 + m[,6]-2
> #delete some observations to simulate an unbalanced design
> df <- df[-as.numeric(sample(rownames(df),20)),]
>
> mod <- lme(value ~ Group*Drug+Block, random = ~1|Subj, data = df)
> anova(mod)
>
> Now, since the interaction between Drug and Group is significant, the main
> effects of Drug and Group can not be interpreted. I therefore define
> contrasts to test the simple main effects, that is, the effect of the Drug
> in each Group, averaged over all levels of the Block factor.
>
> I use the contrast package to set up the contrasts:
> library(contrast)
> con1 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'A', Drug =
> 'Pla'),
> ? ? list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug'),
> type='average')
> con2 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'B', Drug =
> 'Pla'),
> ? ? list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug'),
> type='average')
>
> Now, I use the multcomp-package to correct the p-values for multiple
> comparisons:
>
> library(multcomp)
> summary(glht(mod, linfct = rbind(con1$X,con2$X)))
>
> This approach works fine with lme, but not with lmer. In the model above I
> modeled the block factor as a fixed effect. However, according to my
> understanding, it would be more parsimonious to model the block factor as
a
> random effect. I'm not directly interested in its effect and it's just an
> additional source of variance due to habituation effects . Unfortunately,
> the Block and Subj factors are crossed and therefore can not easily be
> modeled by lme. After comparing different models, the best fitting model
> with lmer looks like this:
>
> lmer(value ~ Group*Drug+(Drug|Subj)+(1|Block))
>
> How can I set up contrasts to test simple main effects for this lmer
model?
> I know, that lmer has a contrasts argument. However, as far as I can see,
> one can only test contrasts for the levels of one factor at a time. Any
> comments are highly appreciated.
>
> Erich
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jeroenooms at gmail.com  Mon Jun 15 14:44:24 2009
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 15 Jun 2009 14:44:24 +0200
Subject: [R-sig-ME] Rasch with lme4
In-Reply-To: <Pine.LNX.4.64.0906090751240.11866@orpheus.qimr.edu.au>
References: <673e1b980906080404n290964f8ic2db10a86c2e7c7b@mail.gmail.com> 
	<12C80D7D-5940-4B41-93A1-CAB8F6F6372B@gmail.com>
	<Pine.LNX.4.64.0906090751240.11866@orpheus.qimr.edu.au>
Message-ID: <673e1b980906150544u545c123fr6f0fe0f1c4a2857d@mail.gmail.com>

2009/6/9 David Duffy <David.Duffy at qimr.edu.au>
>
> Aside from Reinhold's comment, which is not a showstopper (you could bootstrap etc), they are quite different models. In the first model, the estimated IQ-extraversion correlation is disattenuated for measurement error -- the equivalent SEMs are something like (I think ;)):
>
>
> IQ <-----> E ?v. ? E
> | \ ? ? ? ? ? ? ? ?| \
> v ?v ? ? ? ? ? ? ? v ?v
> i1 i2 ? ? ? ? ? ? ?i1 i2
> ? ? ? ? ? ? ? ? ? ^ ?^
> ? ? ? ? ? ? ? ? ? | /
> ? ? ? ? ? ? ? ? ? IQ
>

I am not convinced the second SEM model correclty represents the
second lme model. In the sem model the effect of IQ on y seems to be
conditional on the effect of Extraversion, and vice versa. However,
the fixed effect of extraversion on y does not seem to change
tremendously whether a random effect of subjects is included in the
model or not. I think this is because 'IQ' is only represented by a
random effect in the multilevel model, and the sem model seems to
imply a fixed effect.



From Sebastiaan.DeSmedt at ua.ac.be  Mon Jun 15 16:22:36 2009
From: Sebastiaan.DeSmedt at ua.ac.be (De Smedt Sebastiaan)
Date: Mon, 15 Jun 2009 16:22:36 +0200
Subject: [R-sig-ME] Random formula
Message-ID: <930B1A45F446404FA4D99A46F09209C4EEB258@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090615/c85f993f/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Jun 15 17:00:23 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 15 Jun 2009 17:00:23 +0200
Subject: [R-sig-ME] Random formula
In-Reply-To: <930B1A45F446404FA4D99A46F09209C4EEB258@xmail05.ad.ua.ac.be>
References: <930B1A45F446404FA4D99A46F09209C4EEB258@xmail05.ad.ua.ac.be>
Message-ID: <2E9C414912813E4EB981326983E0A1040690D82B@inboexch.inbo.be>

Dear Sebastiaan,

Models with nested random effects can be done with nlme. Have a loot at
section 4.2.3 of Pinheiro and Bates (2000) Mixed effects models in S and
S-plus.

You will need something like

lme(response ~ climate_factor*pruning, random = list(provenance = ~
pruning, tree = ~1))

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens De Smedt
Sebastiaan
Verzonden: maandag 15 juni 2009 16:23
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Random formula

Hi,

I measured leaf characteristics. The leaves are grouped in trees which
are, on their turn, grouped in provenances.
I want to model those leaf characteristics in function of climate
variables (measured on provenance level) and pruning characteristics
(measured on tree level). I also want to see if the effect of pruning
differs between provenances (provenance-pruning interaction).
The problem is that there cannot be an interaction between pruning and
tree, because pruning is measured on tree level. 

in lme4, I think I can specify this model as follows:

response ~ climate_factor*pruning + (pruning|provenance) +
(1|provenance/tree)

Or is there another way?

Is it possible to define this model in the nlme library (I need a
variance structure, which doesn't exist in lme4)?

Thanks a lot!
Sebastiaan

Sebastiaan De Smedt
Department of Bioscience Engineering
University of Antwerp
Belgium
Tel.: +32 (0)3 265 35 17
Fax.: +32 (0)3 265 32 25

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From lborger at uoguelph.ca  Mon Jun 15 17:11:11 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Mon, 15 Jun 2009 11:11:11 -0400
Subject: [R-sig-ME] Random formula
References: <930B1A45F446404FA4D99A46F09209C4EEB258@xmail05.ad.ua.ac.be>
Message-ID: <946F40CF3E084677ABD773E1ABDCC9D2@lborger>

Hello,

given that you are fitting a gaussian response model and that your random 
effects are strictly nested (if I understand it correctly), nlme can be used 
easily (unless I get corrected by the experts on the list). You could fit 
them:

# m1, no random slope
response ~ climate_factor*pruning,
    random = list(provenance =~ 1, tree =~ 1),


# m2, random slope for pruning at provenance level
response ~ climate_factor*pruning,
    random = list(provenance =~ pruning, tree =~ 1),



HTH


Cheers,

Luca


----- Original Message ----- 
From: "De Smedt Sebastiaan" <Sebastiaan.DeSmedt at ua.ac.be>
To: <r-sig-mixed-models at r-project.org>
Sent: Monday, June 15, 2009 10:22 AM
Subject: [R-sig-ME] Random formula


> Hi,
>
> I measured leaf characteristics. The leaves are grouped in trees which 
> are, on their turn, grouped in provenances.
> I want to model those leaf characteristics in function of climate 
> variables (measured on provenance level) and pruning characteristics 
> (measured on tree level). I also want to see if the effect of pruning 
> differs between provenances (provenance-pruning interaction).
> The problem is that there cannot be an interaction between pruning and 
> tree, because pruning is measured on tree level.
>
> in lme4, I think I can specify this model as follows:
>
> response ~ climate_factor*pruning + (pruning|provenance) + 
> (1|provenance/tree)
>
> Or is there another way?
>
> Is it possible to define this model in the nlme library (I need a variance 
> structure, which doesn't exist in lme4)?
>
> Thanks a lot!
> Sebastiaan
>
> Sebastiaan De Smedt
> Department of Bioscience Engineering
> University of Antwerp
> Belgium
> Tel.: +32 (0)3 265 35 17
> Fax.: +32 (0)3 265 32 25
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From petemeyer at google.com  Mon Jun 15 20:58:44 2009
From: petemeyer at google.com (Pete Meyer)
Date: Mon, 15 Jun 2009 11:58:44 -0700
Subject: [R-sig-ME] Memory problems for a large model with 64bit Ubuntu
Message-ID: <50e00a40906151158q195d15f2n64a4f60b611d9fc8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090615/4d90e9b5/attachment.pl>

From reinhold.kliegl at gmail.com  Tue Jun 16 11:04:33 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 16 Jun 2009 11:04:33 +0200
Subject: [R-sig-ME] testing simple main effects by contrasts
In-Reply-To: <200906151304.n5FD4fqi001737@idmailgate1.unizh.ch>
References: <aefe4d0a0906131119i4f337c42ga583080c99360063@mail.gmail.com>
	<200906151304.n5FD4fqi001737@idmailgate1.unizh.ch>
Message-ID: <aefe4d0a0906160204m2c3629aawf8d5ce9adb76038b@mail.gmail.com>

You use a "contr.sum" specification for your Drug contrasts, leaving
out the Placebe level. That is, your coefficients represent the
difference of Drug1 and Drug2  from the mean of all three levels of
the Drug factor (within Group). This is probably not what you want.
You probably want to use Placebo as a reference condition for Drug1
and Drug2. If so, then you need a "contr.treatment" specification:
##
# Extension to three drug levels with treatment contrasts within groups
cmat.t <- matrix(c( -1, -1, -1, +1, +1, +1,         # Main effect of Group
	                 0, +1,  0,  0,  0,  0,           # Effect of Drug.1
vs. Placebo | Group==A
	                 0,  0, +1,  0,  0,  0,           # Effect of Drug.2
vs. Placebo | Group==A
	                 0,  0,  0,  0, +1,  0,           # Effect of Drug.1
vs. Placebo | Group==B
	                 0,  0,  0,  0,  0, +1), 6, 5)    # Effect of Drug.1
vs. Placebo | Group==B
colnames(cmat.t) <- c(".group", ".drug1_A", ".drug2_A",".drug1_B", ".drug2_B")

contrasts(df$Cond) <- cmat.r
print(mod <- lmer(value ~ Cond + Block + (1 |Subj), data=df), cor=FALSE)

## Alternatively, perhaps you want to compare drug1 against placebo
and drug2 against drug1
# Extension to three drug levels with simple difference contrasts within groups
cmat.r <- matrix(c(  -1,   -1,   -1,  +1,    +1,   +1,   # Main effect of Group
	               -2/3, +1/3, +1/3,   0,     0,    0,        # Drug.1
vs. Placebo | Group==A
	               -1/3, -1/3, +2/3,   0,     0,    0,        # Drug.2
vs. Drug1 | Group==A
	                  0,    0,    0, -2/3, +1/3, +1/3,        # Drug.1
vs. Placebo | Group==B
	                  0,    0,    0, -1/3, -1/3, +2/3), 6, 5)  # Drug.2
vs. Drug1 | Group==B
colnames(cmat.r) <- c(".group", ".drug1-plac_A",
".drug2-drug1_A",".drug1-plac_B", ".drug2-plac_B")

contrasts(df$Cond) <- cmat.r
print(mod <- lmer(value ~ Cond + Block + (1 |Subj), data=df), cor=FALSE)
############

I suspect the contrast package uses the treatment contrast, but I am
not familiar with it. Anyway, it does not matter what you use, but it
is important that coefficients estimate what you expect them to
estimate.

Reinhold Kliegl



On Mon, Jun 15, 2009 at 3:04 PM, Erich
Studerus<erich.studerus at bli.uzh.ch> wrote:
> Thank you so much. I highly appreciate your help.
>
> However, when I extend my example to the case of a design with 3 drug
> levels, the results that I get with the contrast-package and the results
> that I get with your approach seem to differ. I don't know why this is the
> case. Could you please have a look at the following example and tell me what
> I'm doing wrong.
>
> #prepare an example data.frame
> set.seed(5)
> x <- expand.grid(Block= paste('B', 1:3, sep=''),
> Drug = c('Pla', 'Drug1','Drug2'), Subj=1:24)
> df <- data.frame(x, Group = rep(c('A','B'), each=108),
> value=rnorm(216, sd=10))
> m <- model.matrix(lm(value~Group*Drug+Block,df))
> df$value <- df$value+m[,2]*7+ m[,3]*2 + m[,4]*5+
> ?m[,5]*8 + m[,6]*-2+m[,7]*3+m[,8]*-5
> df <- df[-as.numeric(sample(rownames(df),20)),]
>
> mod <- lme(value~Group*Drug+Block, random=~1|Subj,data=df)
>
> library(contrast)
> #Effect of Drug1 | Group A
> contrast(mod,
> list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Pla'),
> list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug1'),
> type='average')
>
> #Effect of Drug2 | Group A
> contrast(mod,
> list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Pla'),
> list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug2'),
> type='average')
>
> #Effect of Drug1 | Group B
> contrast(mod,
> list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Pla'),
> list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug1'),
> type='average')
>
> #Effect of Drug2 | Group B
> contrast(mod,
> list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Pla'),
> list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug2'),
> type='average')
>
>
> df$Cond <- with(df, interaction(Drug, Group))
> #Main effect of Group
> group <- c(-1,-1,-1,1,1,1)
> #Effect of Drug1 | Group A
> Drug1.A <- c(-1,1,0,0,0,0)
> #Effect of Drug2 | Group A
> Drug2.A <- c(-1,0,1,0,0,0)
> #Effect of Drug1 | Group B
> Drug1.B <- c(0,0,0,-1,1,0)
> #Effect of Drug2 | Group B
> Drug2.B <- c(0,0,0,-1,0,1)
> contrasts(df$Cond) <- cbind(group, Drug1.A, Drug2.A,
> Drug1.B, Drug2.B)/2
>
> summary(lme(value ~ Cond + Block, random=~1|Subj,data=df))
>
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Reinhold Kliegl [mailto:reinhold.kliegl at gmail.com]
> Gesendet: Samstag, 13. Juni 2009 20:20
> An: Erich Studerus
> Cc: r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] testing simple main effects by contrasts
>
> >From what I understand you want to test the effect of Drug within each
> of the two Groups. Here is a simple way to do this:
>
> # Convert 2 Drug x 2 Group design to 1 x 4 Cond design
> df$Cond <- factor(paste(df$Group, df$Drug, sep="_"))
>
> # ANOVA: one main, two nested fixed effects
> cmat <- matrix(c( -1, -1, +1, +1, ? ? ? ? ? ? # Main effect of Group
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? -1, +1, ?0, ?0, ? ? ? ? ? ? # Effect of Drug |
> Group==A
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0, ?0, -1, +1), ?4, ?3) ? ?# Effect of Drug |
> Group==B
> colnames(cmat) <- c(".group", ".drug_A", ".drug_B")
>
> contrasts(df$Cond) <- cmat/2
> print(mod <- lmer(value ~ Cond + (1 |Subj), data=df), cor=FALSE)
> print(mod <- lmer(value ~ Cond + Block + (1 |Subj), data=df),
> cor=FALSE) ?# Block as fixed effect
> print(mod <- lmer(value ~ Cond + (1 |Subj) + (1|Block), data=df),
> cor=FALSE) # Block as random effect
>
> The fixed-effect coefficients reported correspond to
> (Intercept) ?= mean of four conditions
> Group ?= difference between the two groups
> .drug_A = difference between Drug levels in Group A
> .drug_B = difference between Drug levels in Group B
>
> and associated standard errors and "t-values". ?Estimates line up with
> table means for balanced designs.
>
> You mention 2 Days of testing but this factor did not appear in the example.
>
> The models you tested with lme and lmer where structurally different
> with respect to Block. Given that you have only 3 ?Blocks, I would
> include Block as a fixed effect, not as a random effect, but opinions
> differ on this. Anyway, this has not much of a bearing on the
> estimates of the Group difference and the estimates of Drug effects
> within Groups.
>
> Reinhold Kliegl
>
> On Sat, Jun 13, 2009 at 4:57 PM, Erich
> Studerus<erich.studerus at bli.uzh.ch> wrote:
>>
>> Hi,
>>
>> I have the following study design: Each of two groups of subjects (group A
>> and group B) was tested repeatedly on two experimental days. At each
>> experimental day, placebo or drug were administered in a randomized order
>> and subjects were tested under the the influence of the drug in 3
>> consecutive blocks. I have therefore one between subjects factor (Group A
> vs
>> Group B) and two within subjects factors (Drug and Block). Here's a
>> reproducible example:
>>
>> x <- expand.grid(Block= paste('B', 1:3, sep=''),
>> ?Drug = c('Placebo', 'Drug'), Subj=1:24)
>> df <- data.frame(x, Group = rep(c('A','B'), each=72),
>> ?value=rnorm(144, sd=10))
>> m <- model.matrix(lm(value~Group*Drug+Block,df))
>> df$value <- df$value+m[,2]*7+ m[,3]*2 + m[,4]*5 + m[,5]*8 + m[,6]-2
>> #delete some observations to simulate an unbalanced design
>> df <- df[-as.numeric(sample(rownames(df),20)),]
>>
>> mod <- lme(value ~ Group*Drug+Block, random = ~1|Subj, data = df)
>> anova(mod)
>>
>> Now, since the interaction between Drug and Group is significant, the main
>> effects of Drug and Group can not be interpreted. I therefore define
>> contrasts to test the simple main effects, that is, the effect of the Drug
>> in each Group, averaged over all levels of the Block factor.
>>
>> I use the contrast package to set up the contrasts:
>> library(contrast)
>> con1 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'A', Drug =
>> 'Pla'),
>> ? ? list(Block=c('B1','B2','B3'), Group = 'A', Drug = 'Drug'),
>> type='average')
>> con2 <- contrast(mod, list(Block=c('B1','B2','B3'), Group = 'B', Drug =
>> 'Pla'),
>> ? ? list(Block=c('B1','B2','B3'), Group = 'B', Drug = 'Drug'),
>> type='average')
>>
>> Now, I use the multcomp-package to correct the p-values for multiple
>> comparisons:
>>
>> library(multcomp)
>> summary(glht(mod, linfct = rbind(con1$X,con2$X)))
>>
>> This approach works fine with lme, but not with lmer. In the model above I
>> modeled the block factor as a fixed effect. However, according to my
>> understanding, it would be more parsimonious to model the block factor as
> a
>> random effect. I'm not directly interested in its effect and it's just an
>> additional source of variance due to habituation effects . Unfortunately,
>> the Block and Subj factors are crossed and therefore can not easily be
>> modeled by lme. After comparing different models, the best fitting model
>> with lmer looks like this:
>>
>> lmer(value ~ Group*Drug+(Drug|Subj)+(1|Block))
>>
>> How can I set up contrasts to test simple main effects for this lmer
> model?
>> I know, that lmer has a contrasts argument. However, as far as I can see,
>> one can only test contrasts for the levels of one factor at a time. Any
>> comments are highly appreciated.
>>
>> Erich
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>



From s.chamaille at yahoo.fr  Wed Jun 17 15:44:35 2009
From: s.chamaille at yahoo.fr (=?iso-8859-1?Q?Simon_Chamaill=E9?=)
Date: Wed, 17 Jun 2009 13:44:35 +0000 (GMT)
Subject: [R-sig-ME] confidence intervals of estimates in polynomial
	regression
Message-ID: <219186.99448.qm@web24306.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090617/fb349851/attachment.pl>

From bates at stat.wisc.edu  Wed Jun 17 17:46:48 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Jun 2009 10:46:48 -0500
Subject: [R-sig-ME] extractor function for coefficient table
	fromsummary.mer ?
In-Reply-To: <Pine.LNX.4.64.0906031304060.11415@orpheus.qimr.edu.au>
References: <4A25D082.4010608@ufl.edu>
	<Pine.LNX.4.64.0906031304060.11415@orpheus.qimr.edu.au>
Message-ID: <40e66e0b0906170846k621e0257hd7d3fe7001169767@mail.gmail.com>

On Tue, Jun 2, 2009 at 10:05 PM, David Duffy<David.Duffy at qimr.edu.au> wrote:
> On Tue, 2 Jun 2009, Ben Bolker wrote:

>> ?Request for comment: would it be reasonable to have the
>> "coef" method for "summary.mer" objects return the table
>> of parameter values, standard errors etc.?

> Yes please, oh and a profile likelihood based confint.lmer() too,
> thanks ;).

I have been thinking about this recently and I have a way of
constructing a profile likelihood for the variance component
parameters.  Are those the parameters that are of interest or are you
more interested in the fixed-effects parameters?

The enclosed plots are from the simple random-effects model fit to the
Dyestuff data in the lme4 package.

Part of my purpose in producing such plots is to show why quoting an
estimate of a variance and a standard error for the estimate is not a
very reasonable summary.  In introductory courses we teach that a
confidence interval on the population variance based on the mythical
i.i.d. sample from a Gaussian population would be constructed from the
chi-squared distribution and would be quite asymmetric in most cases.
Yet somehow the variability in estimates of variance components in
much more complicated models can be expressed by quoting a standard
error.  As shown here, the variability is not at all symmetric.  For
the residual variance term the profiled likelihood is approximately
symmetric when considering the logarithm of the variance (or,
equivalently, the logarithm of the standard error) but even that is
inadequate for other variance components that could feasibly be zero.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Intro-devcontoursfm1.pdf
Type: application/pdf
Size: 48517 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090617/e28a3867/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Intro-profileddevfm1.pdf
Type: application/pdf
Size: 8096 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090617/e28a3867/attachment-0001.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Intro-profileddevsqfm1.pdf
Type: application/pdf
Size: 8002 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090617/e28a3867/attachment-0002.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Intro-profzfm1.pdf
Type: application/pdf
Size: 8217 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090617/e28a3867/attachment-0003.pdf>

From wuolong at gmail.com  Wed Jun 17 21:15:09 2009
From: wuolong at gmail.com (Michael Li)
Date: Wed, 17 Jun 2009 15:15:09 -0400
Subject: [R-sig-ME] lmer: problem in crossed random effect model with very
	different variances
Message-ID: <30b434fe0906171215m705f9ae0k29ea0f8f9ea7d493@mail.gmail.com>

Hi, I  remember seeing this mentioned somewhere but couldn't find it.

I used lmer to fit a simple linear mixed model with two crossed random
effects, day and analyst, with no other fixed effects.  So the syntax
is something like:

lmer (y ~ (1 | day) + (1 | analyst), data = data)

I can also fit the same model in PROC MIXED. Most of the time I got
the same answers.  But there seems to be a problem with lmer when one
of the random effect has a much smaller variance than others.

In my case, SAS would give random effect variances of 1552, 599133 and
213814 for analyst, day and residual effects, respectively but lmer
gives 2x10^-12, 599050, and 214680.  Basically all parameter estimates
are the same (more or less), except that lmer gives very tiny estimate
for the random effect of 'analyst'.

I probably should have used log-transformed y.  But aside from that,
how can I get lmer to give a sensible answer?  Or is SAS giving the
right answer?

Thanks,

Michael



From HDoran at air.org  Wed Jun 17 21:48:58 2009
From: HDoran at air.org (Doran, Harold)
Date: Wed, 17 Jun 2009 15:48:58 -0400
Subject: [R-sig-ME] lmer: problem in crossed random effect model with
	verydifferent variances
In-Reply-To: <30b434fe0906171215m705f9ae0k29ea0f8f9ea7d493@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE029FFDDE@DC1EXCL01.air.org>

Michael

I'll take a quick stab at this, but there is really no way to know what
the issue is given that there is no real description of your data.
First, SAS and lmer use different algorithms for generating parameter
estimates, so it's no surprise that the world does not line up exactly
between the two. However, the estimates should be similar. 

Lmer used REML by default. What did you use in SAS, ML or REML

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Michael Li
> Sent: Wednesday, June 17, 2009 3:15 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lmer: problem in crossed random effect 
> model with verydifferent variances
> 
> Hi, I  remember seeing this mentioned somewhere but couldn't find it.
> 
> I used lmer to fit a simple linear mixed model with two 
> crossed random effects, day and analyst, with no other fixed 
> effects.  So the syntax is something like:
> 
> lmer (y ~ (1 | day) + (1 | analyst), data = data)
> 
> I can also fit the same model in PROC MIXED. Most of the time 
> I got the same answers.  But there seems to be a problem with 
> lmer when one of the random effect has a much smaller 
> variance than others.
> 
> In my case, SAS would give random effect variances of 1552, 599133 and
> 213814 for analyst, day and residual effects, respectively 
> but lmer gives 2x10^-12, 599050, and 214680.  Basically all 
> parameter estimates are the same (more or less), except that 
> lmer gives very tiny estimate for the random effect of 'analyst'.
> 
> I probably should have used log-transformed y.  But aside 
> from that, how can I get lmer to give a sensible answer?  Or 
> is SAS giving the right answer?
> 
> Thanks,
> 
> Michael
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From lborger at uoguelph.ca  Wed Jun 17 21:56:36 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 17 Jun 2009 15:56:36 -0400
Subject: [R-sig-ME] lmer: problem in crossed random effect model with
	verydifferent variances
References: <30b434fe0906171215m705f9ae0k29ea0f8f9ea7d493@mail.gmail.com>
Message-ID: <18BDB5021FE2464588C5467A324600F0@lborger>

Hello,

>I probably should have used log-transformed y.

does the discrepancy between lmer&SAS persist if using log(y) (and are the 
distributional assumptions of the model reasonably met with the 
log-transformed response?). Furthermore, I think SAS and lme4 use different 
algorithms, which might contribute to differences in the estimates.


Cheers,

Luca

----- Original Message ----- 
From: "Michael Li" <wuolong at gmail.com>
To: <r-sig-mixed-models at r-project.org>
Sent: Wednesday, June 17, 2009 3:15 PM
Subject: [R-sig-ME] lmer: problem in crossed random effect model with 
verydifferent variances


> Hi, I  remember seeing this mentioned somewhere but couldn't find it.
>
> I used lmer to fit a simple linear mixed model with two crossed random
> effects, day and analyst, with no other fixed effects.  So the syntax
> is something like:
>
> lmer (y ~ (1 | day) + (1 | analyst), data = data)
>
> I can also fit the same model in PROC MIXED. Most of the time I got
> the same answers.  But there seems to be a problem with lmer when one
> of the random effect has a much smaller variance than others.
>
> In my case, SAS would give random effect variances of 1552, 599133 and
> 213814 for analyst, day and residual effects, respectively but lmer
> gives 2x10^-12, 599050, and 214680.  Basically all parameter estimates
> are the same (more or less), except that lmer gives very tiny estimate
> for the random effect of 'analyst'.
>
> I probably should have used log-transformed y.  But aside from that,
> how can I get lmer to give a sensible answer?  Or is SAS giving the
> right answer?
>
> Thanks,
>
> Michael
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Jun 17 22:02:14 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Jun 2009 15:02:14 -0500
Subject: [R-sig-ME] lmer: problem in crossed random effect model with
	verydifferent variances
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE029FFDDE@DC1EXCL01.air.org>
References: <30b434fe0906171215m705f9ae0k29ea0f8f9ea7d493@mail.gmail.com>
	<ED7B522EE00C9A4FA515AA71724D61EE029FFDDE@DC1EXCL01.air.org>
Message-ID: <40e66e0b0906171302i95f049bs3e89e133a135e440@mail.gmail.com>

On Wed, Jun 17, 2009 at 2:48 PM, Doran, Harold<HDoran at air.org> wrote:
> Michael

> I'll take a quick stab at this, but there is really no way to know what
> the issue is given that there is no real description of your data.
> First, SAS and lmer use different algorithms for generating parameter
> estimates, so it's no surprise that the world does not line up exactly
> between the two. However, the estimates should be similar.

> Lmer used REML by default. What did you use in SAS, ML or REML

What are the values of the REML criterion (or the deviance, if you
used ML estimates) at convergence?  If they are very close then it is
just a matter of the convergence criterion.  Consider that the
relative variance for the analyst in the SAS fit is less than 0.01.
When you estimate a variance relative to the residual variance as 0.01
it means "essentially zero"

You should read the result from lmer as an estimate of zero.  For some
reason the optimization software doesn't like to converge on the
boundary and often ends up at very small but non-zero values.



>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>> Of Michael Li
>> Sent: Wednesday, June 17, 2009 3:15 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] lmer: problem in crossed random effect
>> model with verydifferent variances
>>
>> Hi, I ?remember seeing this mentioned somewhere but couldn't find it.
>>
>> I used lmer to fit a simple linear mixed model with two
>> crossed random effects, day and analyst, with no other fixed
>> effects. ?So the syntax is something like:
>>
>> lmer (y ~ (1 | day) + (1 | analyst), data = data)
>>
>> I can also fit the same model in PROC MIXED. Most of the time
>> I got the same answers. ?But there seems to be a problem with
>> lmer when one of the random effect has a much smaller
>> variance than others.
>>
>> In my case, SAS would give random effect variances of 1552, 599133 and
>> 213814 for analyst, day and residual effects, respectively
>> but lmer gives 2x10^-12, 599050, and 214680. ?Basically all
>> parameter estimates are the same (more or less), except that
>> lmer gives very tiny estimate for the random effect of 'analyst'.
>>
>> I probably should have used log-transformed y. ?But aside
>> from that, how can I get lmer to give a sensible answer? ?Or
>> is SAS giving the right answer?
>>
>> Thanks,
>>
>> Michael
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Jun 17 22:04:14 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Jun 2009 15:04:14 -0500
Subject: [R-sig-ME] lmer: problem in crossed random effect model with
	verydifferent variances
In-Reply-To: <18BDB5021FE2464588C5467A324600F0@lborger>
References: <30b434fe0906171215m705f9ae0k29ea0f8f9ea7d493@mail.gmail.com>
	<18BDB5021FE2464588C5467A324600F0@lborger>
Message-ID: <40e66e0b0906171304t6d588f8bq6d26437a9daf77f5@mail.gmail.com>

On Wed, Jun 17, 2009 at 2:56 PM, Luca Borger<lborger at uoguelph.ca> wrote:
> Hello,

>> I probably should have used log-transformed y.

> does the discrepancy between lmer&SAS persist if using log(y) (and are the
> distributional assumptions of the model reasonably met with the
> log-transformed response?). Furthermore, I think SAS and lme4 use different
> algorithms, which might contribute to differences in the estimates.

I imagine they do but, because I don't know what SAS does, I can't
say.  As soon as SAS Institute goes Open Source we will be able to
make a meaningful comparison :-)

> ----- Original Message ----- From: "Michael Li" <wuolong at gmail.com>
> To: <r-sig-mixed-models at r-project.org>
> Sent: Wednesday, June 17, 2009 3:15 PM
> Subject: [R-sig-ME] lmer: problem in crossed random effect model with
> verydifferent variances
>
>
>> Hi, I ?remember seeing this mentioned somewhere but couldn't find it.
>>
>> I used lmer to fit a simple linear mixed model with two crossed random
>> effects, day and analyst, with no other fixed effects. ?So the syntax
>> is something like:
>>
>> lmer (y ~ (1 | day) + (1 | analyst), data = data)
>>
>> I can also fit the same model in PROC MIXED. Most of the time I got
>> the same answers. ?But there seems to be a problem with lmer when one
>> of the random effect has a much smaller variance than others.
>>
>> In my case, SAS would give random effect variances of 1552, 599133 and
>> 213814 for analyst, day and residual effects, respectively but lmer
>> gives 2x10^-12, 599050, and 214680. ?Basically all parameter estimates
>> are the same (more or less), except that lmer gives very tiny estimate
>> for the random effect of 'analyst'.
>>
>> I probably should have used log-transformed y. ?But aside from that,
>> how can I get lmer to give a sensible answer? ?Or is SAS giving the
>> right answer?
>>
>> Thanks,
>>
>> Michael
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From wuolong at gmail.com  Wed Jun 17 22:54:13 2009
From: wuolong at gmail.com (Michael Li)
Date: Wed, 17 Jun 2009 16:54:13 -0400
Subject: [R-sig-ME] lmer: problem in crossed random effect model with
	verydifferent variances
In-Reply-To: <40e66e0b0906171302i95f049bs3e89e133a135e440@mail.gmail.com>
References: <30b434fe0906171215m705f9ae0k29ea0f8f9ea7d493@mail.gmail.com>
	<ED7B522EE00C9A4FA515AA71724D61EE029FFDDE@DC1EXCL01.air.org>
	<40e66e0b0906171302i95f049bs3e89e133a135e440@mail.gmail.com>
Message-ID: <30b434fe0906171354i6defbff6i55a3abbbe6c79d9c@mail.gmail.com>

On Wed, Jun 17, 2009 at 4:02 PM, Douglas Bates<bates at stat.wisc.edu> wrote:
> On Wed, Jun 17, 2009 at 2:48 PM, Doran, Harold<HDoran at air.org> wrote:
>> Michael
>
>> I'll take a quick stab at this, but there is really no way to know what
>> the issue is given that there is no real description of your data.
>> First, SAS and lmer use different algorithms for generating parameter
>> estimates, so it's no surprise that the world does not line up exactly
>> between the two. However, the estimates should be similar.
>
>> Lmer used REML by default. What did you use in SAS, ML or REML

The default is in SAS is also REML. So REML was used for both lmer and
PROC MIXED.

> What are the values of the REML criterion (or the deviance, if you
> used ML estimates) at convergence? ?If they are very close then it is
> just a matter of the convergence criterion.

The REML criteria in fact were also close at convergence (SAS gives
448.45 while lmer says 448.5).

> Consider that the
> relative variance for the analyst in the SAS fit is less than 0.01.
> When you estimate a variance relative to the residual variance as 0.01
> it means "essentially zero"
>
> You should read the result from lmer as an estimate of zero. ?For some
> reason the optimization software doesn't like to converge on the
> boundary and often ends up at very small but non-zero values.

Certainly in practice, the difference between 1500 and 10^-12 does not
really matter
when the error variance is 200,000.  Still, 1500 seems to be more 'palatable'.
Anyway, it was just surprising to see the difference even though I
understand that lmer uses
difference algorithm and did not expect the answers to be exactly the same.

By the way, at log scale, SAS just gives 0 for analyst variance while
lmer says 10^-15.

I am attaching the code and data at the end of the email in case
anyone wants to try it out.

Thanks for the clarification.

Michael

R:
lmer (y ~ (1 | day) + (1 | analyst), data = tmp)

SAS:
proc mixed data = tmp;
       class day analyst;
       model y = / s;
       random day analyst;
run;

tmp:

   day analyst    y
1    1       1 5482
2    1       1 3285
3    1       1 4266
4    1       1 3818
5    1       1 4159
6    2       1 3007
7    2       1 3349
8    2       1 3178
9    2       1 3093
10   2       1 3242
11   3       1 2495
12   3       1 2687
13   3       1 2858
14   3       1 2090
15   3       1 2218
16   1       2 3882
17   1       2 4522
18   1       2 3647
19   1       2 3690
20   1       2 3754
21   2       2 3050
22   2       2 2858
23   2       2 3178
24   2       2 2901
25   2       2 2410
26   3       2 1855
27   3       2 3157
28   3       2 2111
29   3       2 2431
30   3       2 3114



From bates at stat.wisc.edu  Wed Jun 17 23:05:35 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Jun 2009 16:05:35 -0500
Subject: [R-sig-ME] lmer: problem in crossed random effect model with
	verydifferent variances
In-Reply-To: <30b434fe0906171354i6defbff6i55a3abbbe6c79d9c@mail.gmail.com>
References: <30b434fe0906171215m705f9ae0k29ea0f8f9ea7d493@mail.gmail.com>
	<ED7B522EE00C9A4FA515AA71724D61EE029FFDDE@DC1EXCL01.air.org>
	<40e66e0b0906171302i95f049bs3e89e133a135e440@mail.gmail.com>
	<30b434fe0906171354i6defbff6i55a3abbbe6c79d9c@mail.gmail.com>
Message-ID: <40e66e0b0906171405u7285c05an405ab9b4bcf12131@mail.gmail.com>

On Wed, Jun 17, 2009 at 3:54 PM, Michael Li<wuolong at gmail.com> wrote:
> On Wed, Jun 17, 2009 at 4:02 PM, Douglas Bates<bates at stat.wisc.edu> wrote:
>> On Wed, Jun 17, 2009 at 2:48 PM, Doran, Harold<HDoran at air.org> wrote:
>>> Michael
>>
>>> I'll take a quick stab at this, but there is really no way to know what
>>> the issue is given that there is no real description of your data.
>>> First, SAS and lmer use different algorithms for generating parameter
>>> estimates, so it's no surprise that the world does not line up exactly
>>> between the two. However, the estimates should be similar.
>>
>>> Lmer used REML by default. What did you use in SAS, ML or REML
>
> The default is in SAS is also REML. So REML was used for both lmer and
> PROC MIXED.
>
>> What are the values of the REML criterion (or the deviance, if you
>> used ML estimates) at convergence? ?If they are very close then it is
>> just a matter of the convergence criterion.
>
> The REML criteria in fact were also close at convergence (SAS gives
> 448.45 while lmer says 448.5).
>
>> Consider that the
>> relative variance for the analyst in the SAS fit is less than 0.01.
>> When you estimate a variance relative to the residual variance as 0.01
>> it means "essentially zero"
>>
>> You should read the result from lmer as an estimate of zero. ?For some
>> reason the optimization software doesn't like to converge on the
>> boundary and often ends up at very small but non-zero values.
>
> Certainly in practice, the difference between 1500 and 10^-12 does not
> really matter
> when the error variance is 200,000. ?Still, 1500 seems to be more 'palatable'.
> Anyway, it was just surprising to see the difference even though I
> understand that lmer uses
> difference algorithm and did not expect the answers to be exactly the same.
>
> By the way, at log scale, SAS just gives 0 for analyst variance while
> lmer says 10^-15.
>
> I am attaching the code and data at the end of the email in case
> anyone wants to try it out.
>
> Thanks for the clarification.
>
> Michael
>
> R:
> lmer (y ~ (1 | day) + (1 | analyst), data = tmp)
>
> SAS:
> proc mixed data = tmp;
> ? ? ? class day analyst;
> ? ? ? model y = / s;
> ? ? ? random day analyst;
> run;
>
> tmp:
>
> ? day analyst ? ?y
> 1 ? ?1 ? ? ? 1 5482
> 2 ? ?1 ? ? ? 1 3285
> 3 ? ?1 ? ? ? 1 4266
> 4 ? ?1 ? ? ? 1 3818
> 5 ? ?1 ? ? ? 1 4159
> 6 ? ?2 ? ? ? 1 3007
> 7 ? ?2 ? ? ? 1 3349
> 8 ? ?2 ? ? ? 1 3178
> 9 ? ?2 ? ? ? 1 3093
> 10 ? 2 ? ? ? 1 3242
> 11 ? 3 ? ? ? 1 2495
> 12 ? 3 ? ? ? 1 2687
> 13 ? 3 ? ? ? 1 2858
> 14 ? 3 ? ? ? 1 2090
> 15 ? 3 ? ? ? 1 2218
> 16 ? 1 ? ? ? 2 3882
> 17 ? 1 ? ? ? 2 4522
> 18 ? 1 ? ? ? 2 3647
> 19 ? 1 ? ? ? 2 3690
> 20 ? 1 ? ? ? 2 3754
> 21 ? 2 ? ? ? 2 3050
> 22 ? 2 ? ? ? 2 2858
> 23 ? 2 ? ? ? 2 3178
> 24 ? 2 ? ? ? 2 2901
> 25 ? 2 ? ? ? 2 2410
> 26 ? 3 ? ? ? 2 1855
> 27 ? 3 ? ? ? 2 3157
> 28 ? 3 ? ? ? 2 2111
> 29 ? 3 ? ? ? 2 2431
> 30 ? 3 ? ? ? 2 3114

Thanks for sending the data.  That clears things up a bit.  You only
have two analysts.  It is unrealistic to expect to estimate a variance
from two groups.  Just as a sanity check you could fit a model with
fixed effects for day and analyst

> str(dat)
'data.frame':	30 obs. of  3 variables:
 $ day    : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 2 2 2 2 2 ...
 $ analyst: Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ y      : int  5482 3285 4266 3818 4159 3007 3349 3178 3093 3242 ...
> summary(aov(y ~ day * analyst, dat))
            Df   Sum Sq  Mean Sq F value    Pr(>F)
day          2 12410291  6205146 27.8892 5.494e-07
analyst      1   237096   237096  1.0656    0.3122
day:analyst  2   219345   109672  0.4929    0.6169
Residuals   24  5339828   222493
> summary(aov(y ~ day  + analyst, dat))
            Df   Sum Sq  Mean Sq F value    Pr(>F)
day          2 12410291  6205146 29.0212 2.378e-07
analyst      1   237096   237096  1.1089     0.302
Residuals   26  5559173   213814

You can see that the effect of analyst is not significant, either in
the model that allows for interaction or in the additive model.



From David.Duffy at qimr.edu.au  Wed Jun 17 23:50:59 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 18 Jun 2009 07:50:59 +1000 (EST)
Subject: [R-sig-ME] extractor function for coefficient table
 fromsummary.mer ?
In-Reply-To: <40e66e0b0906170846k621e0257hd7d3fe7001169767@mail.gmail.com>
References: <4A25D082.4010608@ufl.edu>
	<Pine.LNX.4.64.0906031304060.11415@orpheus.qimr.edu.au>
	<40e66e0b0906170846k621e0257hd7d3fe7001169767@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0906180729180.11991@orpheus.qimr.edu.au>

On Wed, 17 Jun 2009, Douglas Bates wrote:

> On Tue, Jun 2, 2009 at 10:05 PM, David Duffy<David.Duffy at qimr.edu.au> wrote:
>> On Tue, 2 Jun 2009, Ben Bolker wrote:
>
>>> ?Request for comment: would it be reasonable to have the
>>> "coef" method for "summary.mer" objects return the table
>>> of parameter values, standard errors etc.?
>
>> Yes please, oh and a profile likelihood based confint.lmer() too,
>> thanks ;).
>
> I have been thinking about this recently and I have a way of
> constructing a profile likelihood for the variance component
> parameters.  Are those the parameters that are of interest or are you
> more interested in the fixed-effects parameters?
>

Yes, the variance components are of direct interest.

> Yet somehow the variability in estimates of variance components in
> much more complicated models can be expressed by quoting a standard
> error.
>

Yes, we usually try and produce appropriate confidence intervals and/or 
interpretable likelihood based test statistics.  The latter, of course, 
are tricky mixtures for multivariate hypotheses -- a typical one for us is 
a variance components linkage analysis test that the common component due 
a particular genome region is zero for three measures (repeated at 3 
occasions, but with differing contributions by occasion).  People still 
want a P-value, so they can carry out adjustment for genome-wide testing 
(linkage is supposed to be roughly equivalent to 50-60 tests for a human 
length genome, but the genome-wide corrected 5% P-value is usually quoted 
as 2e-5).

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v

From bolker at ufl.edu  Wed Jun 17 23:59:34 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 17 Jun 2009 17:59:34 -0400
Subject: [R-sig-ME] extractor function for coefficient table
 fromsummary.mer ?
In-Reply-To: <Pine.LNX.4.64.0906180729180.11991@orpheus.qimr.edu.au>
References: <4A25D082.4010608@ufl.edu>	<Pine.LNX.4.64.0906031304060.11415@orpheus.qimr.edu.au>	<40e66e0b0906170846k621e0257hd7d3fe7001169767@mail.gmail.com>
	<Pine.LNX.4.64.0906180729180.11991@orpheus.qimr.edu.au>
Message-ID: <4A396746.5060401@ufl.edu>

David Duffy wrote:
> On Wed, 17 Jun 2009, Douglas Bates wrote:
> 
>> On Tue, Jun 2, 2009 at 10:05 PM, David Duffy<David.Duffy at qimr.edu.au> wrote:
>>> On Tue, 2 Jun 2009, Ben Bolker wrote:
>>>>  Request for comment: would it be reasonable to have the
>>>> "coef" method for "summary.mer" objects return the table
>>>> of parameter values, standard errors etc.?
>>> Yes please, oh and a profile likelihood based confint.lmer() too,
>>> thanks ;).
>> I have been thinking about this recently and I have a way of
>> constructing a profile likelihood for the variance component
>> parameters.  Are those the parameters that are of interest or are you
>> more interested in the fixed-effects parameters?
>>
> 
> Yes, the variance components are of direct interest.
> 
>> Yet somehow the variability in estimates of variance components in
>> much more complicated models can be expressed by quoting a standard
>> error.
>>
> 
> Yes, we usually try and produce appropriate confidence intervals and/or 
> interpretable likelihood based test statistics.  The latter, of course, 
> are tricky mixtures for multivariate hypotheses -- a typical one for us is 
> a variance components linkage analysis test that the common component due 
> a particular genome region is zero for three measures (repeated at 3 
> occasions, but with differing contributions by occasion).  People still 
> want a P-value, so they can carry out adjustment for genome-wide testing 
> (linkage is supposed to be roughly equivalent to 50-60 tests for a human 
> length genome, but the genome-wide corrected 5% P-value is usually quoted 
> as 2e-5).
> 
> Cheers, David Duffy.
> 

  Fixed effect profiles are interesting too (to me) ... I have written
some of my own code to do this (happy to make it available), but it's
not very general/robust at the moment.


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Sebastiaan.DeSmedt at ua.ac.be  Thu Jun 18 10:10:27 2009
From: Sebastiaan.DeSmedt at ua.ac.be (De Smedt Sebastiaan)
Date: Thu, 18 Jun 2009 10:10:27 +0200
Subject: [R-sig-ME] generate simulated values with simulate.lme
Message-ID: <930B1A45F446404FA4D99A46F09209C401540CF8@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090618/f046516e/attachment.pl>

From bates at stat.wisc.edu  Thu Jun 18 14:46:26 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Jun 2009 07:46:26 -0500
Subject: [R-sig-ME] extractor function for coefficient table
	fromsummary.mer ?
In-Reply-To: <4A396746.5060401@ufl.edu>
References: <4A25D082.4010608@ufl.edu>
	<Pine.LNX.4.64.0906031304060.11415@orpheus.qimr.edu.au>
	<40e66e0b0906170846k621e0257hd7d3fe7001169767@mail.gmail.com>
	<Pine.LNX.4.64.0906180729180.11991@orpheus.qimr.edu.au>
	<4A396746.5060401@ufl.edu>
Message-ID: <40e66e0b0906180546u514cc5f5j8a826e5de9da5fab@mail.gmail.com>

On Wed, Jun 17, 2009 at 4:59 PM, Ben Bolker<bolker at ufl.edu> wrote:
> David Duffy wrote:
>> On Wed, 17 Jun 2009, Douglas Bates wrote:
>>
>>> On Tue, Jun 2, 2009 at 10:05 PM, David Duffy<David.Duffy at qimr.edu.au> wrote:
>>>> On Tue, 2 Jun 2009, Ben Bolker wrote:
>>>>> ?Request for comment: would it be reasonable to have the
>>>>> "coef" method for "summary.mer" objects return the table
>>>>> of parameter values, standard errors etc.?
>>>> Yes please, oh and a profile likelihood based confint.lmer() too,
>>>> thanks ;).
>>> I have been thinking about this recently and I have a way of
>>> constructing a profile likelihood for the variance component
>>> parameters. ?Are those the parameters that are of interest or are you
>>> more interested in the fixed-effects parameters?
>>>
>>
>> Yes, the variance components are of direct interest.
>>
>>> Yet somehow the variability in estimates of variance components in
>>> much more complicated models can be expressed by quoting a standard
>>> error.
>>>
>>
>> Yes, we usually try and produce appropriate confidence intervals and/or
>> interpretable likelihood based test statistics. ?The latter, of course,
>> are tricky mixtures for multivariate hypotheses -- a typical one for us is
>> a variance components linkage analysis test that the common component due
>> a particular genome region is zero for three measures (repeated at 3
>> occasions, but with differing contributions by occasion). ?People still
>> want a P-value, so they can carry out adjustment for genome-wide testing
>> (linkage is supposed to be roughly equivalent to 50-60 tests for a human
>> length genome, but the genome-wide corrected 5% P-value is usually quoted
>> as 2e-5).
>>
>> Cheers, David Duffy.
>>
>
> ?Fixed effect profiles are interesting too (to me) ... I have written
> some of my own code to do this (happy to make it available), but it's
> not very general/robust at the moment.

I think there is a general way of creating the profiles including with
respect to the fixed-effects parameters but, as always, the devil is
in the details.  I have already tripped up on the simplest case of
models like

lmer(Yield ~ 1 + (1|Batch), Dyestuff)

When you condition on the value of the one and only fixed-effects
parameter the code for the penalized least squares solution becomes
confused because the reduced model matrix for the fixed effects has
zero columns.



From DAfshartous at med.miami.edu  Mon Jun 22 16:28:05 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Mon, 22 Jun 2009 10:28:05 -0400
Subject: [R-sig-ME] Empirical variance estimator of SE's, lmer
Message-ID: <C6650D35.A888%dafshartous@med.miami.edu>

All,

I searched the archives and didn't find anything on empirical variance
estimates of SEs of fixed effects in lmer, i.e., replacing Var(Y_i) with
(y_i - X_i \hat{beta}) in the standard formula for Var(\hat{beta}).  Does
code exist for this?  It should only be a few lines but was just wondering
if it already existed.

Cheers,
David



From ahmatias at gmail.com  Mon Jun 22 16:51:37 2009
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Mon, 22 Jun 2009 16:51:37 +0200
Subject: [R-sig-ME] problems with 'false convergence' in lmer
Message-ID: <a0743530906220751w5f7e3f66h48fa4e13ca63d275@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090622/413c9c81/attachment.pl>

From ahmatias at gmail.com  Mon Jun 22 17:46:27 2009
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Mon, 22 Jun 2009 17:46:27 +0200
Subject: [R-sig-ME] problems with 'false convergence' in lmer
In-Reply-To: <OF27C0228E.8754AB2C-ON862575DD.0054EE5D-862575DD.00559A3E@unl.edu>
References: <a0743530906220751w5f7e3f66h48fa4e13ca63d275@mail.gmail.com>
	<OF27C0228E.8754AB2C-ON862575DD.0054EE5D-862575DD.00559A3E@unl.edu>
Message-ID: <a0743530906220846r3351639brc6ba0e6ebf4d7c98@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090622/c5ca2a29/attachment.pl>

From atyre2 at unlnotes.unl.edu  Mon Jun 22 17:37:31 2009
From: atyre2 at unlnotes.unl.edu (Andrew J Tyre)
Date: Mon, 22 Jun 2009 10:37:31 -0500
Subject: [R-sig-ME] problems with 'false convergence' in lmer
In-Reply-To: <a0743530906220751w5f7e3f66h48fa4e13ca63d275@mail.gmail.com>
Message-ID: <OF27C0228E.8754AB2C-ON862575DD.0054EE5D-862575DD.00559A3E@unl.edu>

Toni,

I assume that your predictor variables vary by territory, and that your 
random effect is applied to the intercept, like this

occupancy_ij ~ predictor1_i  + predictor2_i + (1|territoryID_i) + 
(1|year_j)

in that case, the territoryID random effect is "competing" to explain 
variation in occupancy between territories with predictors1 and 2. Hence 
the failure to converge. 

A better question to ask yourself is this: is the probability that a 
territory is occupied this year different depending on whether the 
territory was occupied last year? If yes, then you have AUTOCORRELATION, 
and that has to be handled differently - a random effect on territoryID 
influences the probability of the territory being occupied, as do the 
predictor variables, but that model still assumes that occupancy is 
independent from year to year. I do not know how to accomadate 
autocorrelation in a binomial model in lmer; in general, it isn't 
something that is easy to do. 

1) You cannot use the estimates from lmer if it hasn't converged, in my 
opinion. 

2) not sure ... looking forward to an answer from greater gurus. 

hth,

Drew Tyre

School of Natural Resources
University of Nebraska-Lincoln
416 Hardin Hall, East Campus
3310 Holdrege Street
Lincoln, NE 68583-0974

phone: +1 402 472 4054 
fax: +1 402 472 2946
email: atyre2 at unl.edu
http://snr.unl.edu/tyre
http://aminpractice.blogspot.com



Toni Hernandez-Matias <ahmatias at gmail.com> 
Sent by: r-sig-mixed-models-bounces at r-project.org
06/22/2009 09:54 AM

To
R-SIG-Mixed-Models at r-project.org
cc

Subject
[R-sig-ME] problems with 'false convergence' in lmer






Dear all,

I am analyzing a data set with the 'lmer' function (lme4_0.999375-28).
The dependent variable is binary: occupation status of a breeding site by 
a
bird species (territory ocupied vs. non-ocupied).
There are clustered observations: observations of the same territory for
several years and observations of different territories in the same year. 
So
I considered two random factors: territory identity and year.
I considered several predictors which are standardized.
I am using aic values to obtain the final model.

The problem is that the program generates the warning message in most of 
the
fitted models:
In mer_finalize(ans) : false convergence (8)

This probably happens because many territories are either occupied or
non-occupied for many or all years in the study. [there are no problems 
when
I include the random factor year in the formula, and I do not include the
random factor territory identity]

I added the  option 'verbose=TRUE', and  I found that the printed value of
deviance does not match with that saved by the model object (I extract it
using 'attr(summary(nameofthemodel),"AIC")$AIC').

My questions are:

(1) are the results (estimated parameters and se) of the fitted model
correct? Can I use them?

(2) how can I extract the deviance value of the printed table given by the
'verbose' option? I mean extract, as a R object. I need this because I am
performing a large set of models and I consider those with better aic.

Thank you very much in advance,


Toni Hernandez

-- 
*********************************************************

Antonio Hernandez Matias

Departament de Biologia Animal (Vertebrats)
Facultat de Biologia
Universitat de Barcelona

***********************************************************

                 [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ahmatias at gmail.com  Mon Jun 22 18:23:07 2009
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Mon, 22 Jun 2009 18:23:07 +0200
Subject: [R-sig-ME] problems with 'false convergence' in lmer
In-Reply-To: <OF27C0228E.8754AB2C-ON862575DD.0054EE5D-862575DD.00559A3E@unl.edu>
References: <a0743530906220751w5f7e3f66h48fa4e13ca63d275@mail.gmail.com>
	<OF27C0228E.8754AB2C-ON862575DD.0054EE5D-862575DD.00559A3E@unl.edu>
Message-ID: <a0743530906220923j584a62e9y76f320bc791a9650@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090622/c51a7b61/attachment.pl>

From wuolong at gmail.com  Mon Jun 22 22:45:38 2009
From: wuolong at gmail.com (Michael Li)
Date: Mon, 22 Jun 2009 16:45:38 -0400
Subject: [R-sig-ME] variance function in lmer
Message-ID: <30b434fe0906221345j1265aa88t4abf3cf47d7d0398@mail.gmail.com>

Hi, lme() allows the use of variance function in the "weights" option.
 In lmer() the "weights" seems to expect actual weights rather than a
function (as in lm()).

Can variance functions be used in lmer()?

Thanks,

Michael



From bates at stat.wisc.edu  Mon Jun 22 23:15:14 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 22 Jun 2009 16:15:14 -0500
Subject: [R-sig-ME] variance function in lmer
In-Reply-To: <30b434fe0906221345j1265aa88t4abf3cf47d7d0398@mail.gmail.com>
References: <30b434fe0906221345j1265aa88t4abf3cf47d7d0398@mail.gmail.com>
Message-ID: <40e66e0b0906221415n7f41866l795d467de8bc2753@mail.gmail.com>

On Mon, Jun 22, 2009 at 3:45 PM, Michael Li<wuolong at gmail.com> wrote:
> Hi, lme() allows the use of variance function in the "weights" option.
> ?In lmer() the "weights" seems to expect actual weights rather than a
> function (as in lm()).

And it's even documented that way too :-)

> Can variance functions be used in lmer()?

Not currently, no.



From wuolong at gmail.com  Tue Jun 23 18:00:31 2009
From: wuolong at gmail.com (Michael Li)
Date: Tue, 23 Jun 2009 12:00:31 -0400
Subject: [R-sig-ME] variance function in lmer
In-Reply-To: <40e66e0b0906221415n7f41866l795d467de8bc2753@mail.gmail.com>
References: <30b434fe0906221345j1265aa88t4abf3cf47d7d0398@mail.gmail.com>
	<40e66e0b0906221415n7f41866l795d467de8bc2753@mail.gmail.com>
Message-ID: <CC9BCEE3-C0B5-451B-B129-04F45BB57F6F@gmail.com>

On Jun 22, 2009, at 5:15 PM, Douglas Bates <bates at stat.wisc.edu> wrote:

> On Mon, Jun 22, 2009 at 3:45 PM, Michael Li<wuolong at gmail.com> wrote:
>
>> Can variance functions be used in lmer()?
>
> Not currently, no.

Thanks. I thought that was the case. Since nlme/lme4 are such  
important packages, Is there a "roadmap" in terms how they will evolve  
in the near future and what features are planned (e.g., empirical  
stderr)?

Michael



From f.calboli at imperial.ac.uk  Tue Jun 23 18:18:52 2009
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 23 Jun 2009 17:18:52 +0100
Subject: [R-sig-ME] lmer vs glmmPQL
Message-ID: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>

Hi All,

I'm doing a simple logistic regression with one fixed and one random  
effects, and I'm comparing the results I got from lmer() and  
glmmPQL(). I'm finding that lmer gives my a "better" p-value for my  
fixed effects. Because I'm a paranoid old man I'd go for the glmmPQL  
results then, but my collaborators are less paranoid and I'm sure  
they'd prefer the results from lmer. Am I too conservative? (I ralise  
it looks like I'm asking for counselling more than advice, but there  
you go...).

Best,

Federico

My models:

mod1 = glmmPQL(y ~ genotype, random = ~1|block, family = binomial, data)
mod2 = lmer(y ~ genotype + (1|block), family = binomial, data)

my data:

 > data
   genotype block y.1 y.2
1  A     a  16  29
2     B     a  19  26
3      C     a  23  23
4  A     c   6  24
5     B     c  11  11
6      C     c  13  14
7  A     b   4  17
8     B     b  10   8
9      C     b  12   6


 > data[[1]]
[1] A B    C     A B    C     A B    C
attr(,"contrasts")
         [,1] [,2]
B       1   -1
A   -2    0
C        1    1
Levels: B A C

my results:

 > summary(mod1)
Linear mixed-effects model fit by maximum likelihood
  Data: dat
   AIC BIC logLik
    NA  NA     NA

Random effects:
  Formula: ~1 | block
          (Intercept)  Residual
StdDev: 1.285532e-06 0.8077838

Variance function:
  Structure: fixed weights
  Formula: ~invwt
Fixed effects: y ~ genotype
                  Value  Std.Error DF   t-value p-value
(Intercept) -0.3327269 0.12516679  4 -2.658269  0.0565
genotype1    0.3288359 0.09065856  4  3.627190  0.0222
genotype2    0.1138920 0.14947659  4  0.761938  0.4885
  Correlation:
           (Intr) gntyp1
genotype1 -0.068
genotype2 -0.027 -0.019

Standardized Within-Group Residuals:
        Min         Q1        Med         Q3        Max
-1.0807836 -0.8047002 -0.4620287  0.8940787  1.5832300

Number of Observations: 9
Number of Groups: 3


 > summary(mod2)
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ genotype + (1 | block)
    Data: dat
    AIC   BIC logLik deviance
  13.92 14.71 -2.960    5.919
Random effects:
  Groups Name        Variance Std.Dev.
  block  (Intercept)  0        0
Number of obs: 9, groups: block, 3

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.33273    0.12652  -2.630 0.008541 **
genotype1    0.32884    0.09164   3.588 0.000333 ***
genotype2    0.11389    0.15109   0.754 0.450965
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr) gntyp1
genotype1 -0.068
genotype2 -0.027 -0.019




--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From Christine.Griffiths at bristol.ac.uk  Tue Jun 23 19:29:42 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Tue, 23 Jun 2009 18:29:42 +0100
Subject: [R-sig-ME] unreplicated repeated measures
Message-ID: <507AFCD5B72B924BCE816220@bio-mammal026.bio.bris.ac.uk>

Dear R users,

Sorry if this question is not applicable to this site. I am having problems 
analysing unreplicated repeated measures. I calculated food web properties 
for three treatments over time (10 months). It is unreplicated in that I 
only have one observation per month per treatment. My problem is that I am 
interested in how a food web property varies between Treatments and over 
time.

Originally I had tried using lmer:
m4<-lmer(lncon~Treatment*month+(1|month),data=dataset)
but this provides the following error for which I have not found an 
explanation to on the R site.
Error in mer_finalize(ans) : Calculated PWRSS for a LMM is negative

I suspect it is because I had treated month as a factor and consequently 
due to the lack of replication and trying to interact these two categorical 
variables it fails. I can overcome this problem by treating month as a 
continuous variable from which I calculated confidence intervals using MCMC 
method. However I am not sure how these are being calculated and if this is 
accurate, given I have no mean per Treatment as such. Is it acceptable to 
use month as a continuous variable?

Alternatively, I tried using repeated measures ANOVA, aov, to model the 
data. I am cautious to use this method as it indicates significant 
differences which are not apparent from the plotted raw data. Given that my 
data lacks replication, I am wary of this method.

I have investigated time series analysis, but I am reluctant to venture 
down this route.

Any reassurance or advice as to the best technique given my data would be 
greatly appreciated.

Many thanks,
Christine


----------------------
Christine



From rmh3093 at gmail.com  Tue Jun 23 20:13:09 2009
From: rmh3093 at gmail.com (Ryan Hope)
Date: Tue, 23 Jun 2009 14:13:09 -0400
Subject: [R-sig-ME] unreplicated repeated measures
In-Reply-To: <507AFCD5B72B924BCE816220@bio-mammal026.bio.bris.ac.uk>
References: <507AFCD5B72B924BCE816220@bio-mammal026.bio.bris.ac.uk>
Message-ID: <48f7fe350906231113q7cb90c9cm4ab78c16b7763b92@mail.gmail.com>

This would be your model:

m1<-lmer(lncon~Treatment+(1|month),data=dataset)

you did not manipulate the "month" variable thus it should not be in
the fixed effects side of the formula.

Now is treatment a coded variable for multiple factors? If so why are
you not using the actual factors like:

m2<-lmer(lncon~FactorA+FactorB+(1|month/(FactorA+FactorB)),data=dataset)


On Tue, Jun 23, 2009 at 1:29 PM, Christine
Griffiths<Christine.Griffiths at bristol.ac.uk> wrote:
> Dear R users,
>
> Sorry if this question is not applicable to this site. I am having problems
> analysing unreplicated repeated measures. I calculated food web properties
> for three treatments over time (10 months). It is unreplicated in that I
> only have one observation per month per treatment. My problem is that I am
> interested in how a food web property varies between Treatments and over
> time.
>
> Originally I had tried using lmer:
> m4<-lmer(lncon~Treatment*month+(1|month),data=dataset)
> but this provides the following error for which I have not found an
> explanation to on the R site.
> Error in mer_finalize(ans) : Calculated PWRSS for a LMM is negative
>
> I suspect it is because I had treated month as a factor and consequently due
> to the lack of replication and trying to interact these two categorical
> variables it fails. I can overcome this problem by treating month as a
> continuous variable from which I calculated confidence intervals using MCMC
> method. However I am not sure how these are being calculated and if this is
> accurate, given I have no mean per Treatment as such. Is it acceptable to
> use month as a continuous variable?
>
> Alternatively, I tried using repeated measures ANOVA, aov, to model the
> data. I am cautious to use this method as it indicates significant
> differences which are not apparent from the plotted raw data. Given that my
> data lacks replication, I am wary of this method.
>
> I have investigated time series analysis, but I am reluctant to venture down
> this route.
>
> Any reassurance or advice as to the best technique given my data would be
> greatly appreciated.
>
> Many thanks,
> Christine
>
>
> ----------------------
> Christine
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ken at kjbeath.com.au  Tue Jun 23 23:46:49 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 24 Jun 2009 07:46:49 +1000
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>
Message-ID: <7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>

On 24/06/2009, at 2:18 AM, Federico Calboli wrote:

> Hi All,
>
> I'm doing a simple logistic regression with one fixed and one random  
> effects, and I'm comparing the results I got from lmer() and  
> glmmPQL(). I'm finding that lmer gives my a "better" p-value for my  
> fixed effects. Because I'm a paranoid old man I'd go for the glmmPQL  
> results then, but my collaborators are less paranoid and I'm sure  
> they'd prefer the results from lmer. Am I too conservative? (I  
> ralise it looks like I'm asking for counselling more than advice,  
> but there you go...).
>

This seems to results from the use of a t-test with few df in glmmPQL  
and z in lmer. z seems fine to me. What is more of a problem is that  
your random effects variance is effectively 0. There are only 3 blocks  
so fitting a random effects model will be difficult and appears  
unnecessary.

Ken




> Best,
>
> Federico
>
> My models:
>
> mod1 = glmmPQL(y ~ genotype, random = ~1|block, family = binomial,  
> data)
> mod2 = lmer(y ~ genotype + (1|block), family = binomial, data)
>
> my data:
>
> > data
>  genotype block y.1 y.2
> 1  A     a  16  29
> 2     B     a  19  26
> 3      C     a  23  23
> 4  A     c   6  24
> 5     B     c  11  11
> 6      C     c  13  14
> 7  A     b   4  17
> 8     B     b  10   8
> 9      C     b  12   6
>
>
> > data[[1]]
> [1] A B    C     A B    C     A B    C
> attr(,"contrasts")
>        [,1] [,2]
> B       1   -1
> A   -2    0
> C        1    1
> Levels: B A C
>
> my results:
>
> > summary(mod1)
> Linear mixed-effects model fit by maximum likelihood
> Data: dat
>  AIC BIC logLik
>   NA  NA     NA
>
> Random effects:
> Formula: ~1 | block
>         (Intercept)  Residual
> StdDev: 1.285532e-06 0.8077838
>
> Variance function:
> Structure: fixed weights
> Formula: ~invwt
> Fixed effects: y ~ genotype
>                 Value  Std.Error DF   t-value p-value
> (Intercept) -0.3327269 0.12516679  4 -2.658269  0.0565
> genotype1    0.3288359 0.09065856  4  3.627190  0.0222
> genotype2    0.1138920 0.14947659  4  0.761938  0.4885
> Correlation:
>          (Intr) gntyp1
> genotype1 -0.068
> genotype2 -0.027 -0.019
>
> Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
> -1.0807836 -0.8047002 -0.4620287  0.8940787  1.5832300
>
> Number of Observations: 9
> Number of Groups: 3
>
>
> > summary(mod2)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: y ~ genotype + (1 | block)
>   Data: dat
>   AIC   BIC logLik deviance
> 13.92 14.71 -2.960    5.919
> Random effects:
> Groups Name        Variance Std.Dev.
> block  (Intercept)  0        0
> Number of obs: 9, groups: block, 3
>
> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept) -0.33273    0.12652  -2.630 0.008541 **
> genotype1    0.32884    0.09164   3.588 0.000333 ***
> genotype2    0.11389    0.15109   0.754 0.450965
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>          (Intr) gntyp1
> genotype1 -0.068
> genotype2 -0.027 -0.019
>
>
>
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From f.calboli at imperial.ac.uk  Wed Jun 24 11:45:46 2009
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 24 Jun 2009 10:45:46 +0100
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>
	<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>
Message-ID: <FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>

On 23 Jun 2009, at 22:46, Ken Beath wrote:
>
> This seems to results from the use of a t-test with few df in glmmPQL
> and z in lmer. z seems fine to me. What is more of a problem is that
> your random effects variance is effectively 0. There are only 3 blocks
> so fitting a random effects model will be difficult and appears
> unnecessary.


That was a sample dataset so I could see what kind of data I had to  
deal with, the 'real' hing should have a variance > 0 for the random  
effect. My philosphycal issue was, given such a relatively  
straightforward model, should I be more (glmmPQL) or less (lmer)  
conservative?

Best,

Federico

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bolker at ufl.edu  Wed Jun 24 14:15:51 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 24 Jun 2009 08:15:51 -0400
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>	<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>
	<FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>
Message-ID: <4A4218F7.4070108@ufl.edu>

Federico Calboli wrote:
> On 23 Jun 2009, at 22:46, Ken Beath wrote:
>> This seems to results from the use of a t-test with few df in glmmPQL
>> and z in lmer. z seems fine to me. What is more of a problem is that
>> your random effects variance is effectively 0. There are only 3 blocks
>> so fitting a random effects model will be difficult and appears
>> unnecessary.
> 
> 
> That was a sample dataset so I could see what kind of data I had to  
> deal with, the 'real' hing should have a variance > 0 for the random  
> effect. My philosphycal issue was, given such a relatively  
> straightforward model, should I be more (glmmPQL) or less (lmer)  
> conservative?
> 
> Best,
> 
> Federico

  My take would be to pick lmer over glmmPQL every time, provided
it can handle your problem -- in general it should be more accurate.
Picking on the basis of more or less conservative for any given problem
feels biased.

  Ben Bolker



From danielezrajohnson at gmail.com  Wed Jun 24 15:47:04 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Wed, 24 Jun 2009 09:47:04 -0400
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A4218F7.4070108@ufl.edu>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>
	<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>
	<FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>
	<4A4218F7.4070108@ufl.edu>
Message-ID: <a46630750906240647wc4adfd1j1dd69d0dba79fc69@mail.gmail.com>

Regarding this thread, what about the method of fitting nested models
and using anova() to estimate a p-value.

For example:

mod2 = lmer(y ~ genotype + (1|block), family = binomial, data)
mod0 = lmer(y ~ (1|block), family = binomial, data)

anova(mod0,mod2)

How does that p-value (which is one value for the whole term
"genotype") relate to the individual coefficient p-values derived from
the Z-scores inside summary(mod2)?

Thanks,
Dan



From bolker at ufl.edu  Wed Jun 24 18:48:01 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 24 Jun 2009 12:48:01 -0400
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <a46630750906240647wc4adfd1j1dd69d0dba79fc69@mail.gmail.com>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>	
	<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>	
	<FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>	
	<4A4218F7.4070108@ufl.edu>
	<a46630750906240647wc4adfd1j1dd69d0dba79fc69@mail.gmail.com>
Message-ID: <4A4258C1.2040108@ufl.edu>

Daniel Ezra Johnson wrote:
> Regarding this thread, what about the method of fitting nested models
> and using anova() to estimate a p-value.
> 
> For example:
> 
> mod2 = lmer(y ~ genotype + (1|block), family = binomial, data)
> mod0 = lmer(y ~ (1|block), family = binomial, data)
> 
> anova(mod0,mod2)
> 
> How does that p-value (which is one value for the whole term
> "genotype") relate to the individual coefficient p-values derived from
> the Z-scores inside summary(mod2)?
> 
> Thanks,
> Dan

   The Z-scores are Wald tests.  The anova results are likelihood
ratio tests.  The latter are in general more reliable but are known
to be *un*reliable for small-sample (i.e.
small-number-of-random-effects-levels) LMMs (Pinheiro and Bates).
Wald tests are not *known* to be unreliable in the small-sample
case, but I believe that is a statement of ignorance rather than
a statement that they're OK ...

  Ben Bolker


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From rlevy at ling.ucsd.edu  Wed Jun 24 19:14:58 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Wed, 24 Jun 2009 10:14:58 -0700
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A4258C1.2040108@ufl.edu>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>		<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>		<FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>		<4A4218F7.4070108@ufl.edu>	<a46630750906240647wc4adfd1j1dd69d0dba79fc69@mail.gmail.com>
	<4A4258C1.2040108@ufl.edu>
Message-ID: <4A425F12.2010403@ling.ucsd.edu>

Ben Bolker wrote:
> Daniel Ezra Johnson wrote:
>> Regarding this thread, what about the method of fitting nested models
>> and using anova() to estimate a p-value.
>>
>> For example:
>>
>> mod2 = lmer(y ~ genotype + (1|block), family = binomial, data)
>> mod0 = lmer(y ~ (1|block), family = binomial, data)
>>
>> anova(mod0,mod2)
>>
>> How does that p-value (which is one value for the whole term
>> "genotype") relate to the individual coefficient p-values derived from
>> the Z-scores inside summary(mod2)?
>>
>> Thanks,
>> Dan
> 
>    The Z-scores are Wald tests.  The anova results are likelihood
> ratio tests.  The latter are in general more reliable but are known
> to be *un*reliable for small-sample (i.e.
> small-number-of-random-effects-levels) LMMs (Pinheiro and Bates).
> Wald tests are not *known* to be unreliable in the small-sample
> case, but I believe that is a statement of ignorance rather than
> a statement that they're OK ...

This is an interesting issue -- as Ben points out, likelihood-ratio 
tests are known to be anti-conservative for tests between linear mixed 
models differing only in fixed-effects structure.  I think the 
best-known demonstration of this can be found in Pinheiro & Bates, 2000, 
pages 87-92.  F-tests are less problematic.

For logit mixed models, presumably the results will depend a bit on how 
fitting is done because the likelihood has to be approximated.  For the 
Laplace approximation currently in use in lme4, I've done some 
simulations and generally found that likelihood-ratio tests are still 
anti-conservative; tests based on Wald Z are not as anti-conservative, 
though they don't seem quite nominal.  You can do simulations along 
these lines:

set.seed(2)
invlogit <- function(x) {
   temp <- exp(x)
   return(temp/(1+temp))
}
L <- 10
REP <- 4
N <- 4*10
fac <- gl(L,REP)
f <- function(ignore) {
   x <- runif(N)
   r <- rnorm(L)
   y <- rbinom(N,1,invlogit(r[fac]))
   m0 <- lmer(y ~ (1 | fac), family="binomial")
   m1 <- lmer(y ~ x + (1 | fac), family="binomial")
   temp <- pnorm(fixef(m1)[2]/sqrt(vcov(m1)[2,2]))
   p.z <- 2*min(temp, 1-temp)
   p.lr <- 1-pchisq(as.numeric(2*(logLik(m1)-logLik(m0))),1)
   return(c(p.z,p.lr))
}
K <- 5000
p.vals <- sapply(1:K,f)
apply(p.vals, 1, function(x) sum(x<0.05))/K
# this gave me 0.0562 for Wald Z, 0.0608 for LRT

# Is Wald Z anti-conservative?  The below says "yes" with p=0.044
2*(1-pbinom(sum(p.vals[1,]<0.05), K, 0.05))


Unlike what Ben states above, however, it's my intuition (and informal 
observation on the basis of simulations) that what determines how 
anticonservative the LRT is is not the number of random effect levels 
but rather the ratio between the degrees of freedom involved in the LRT 
to the residual degrees of freedom in the more general model.  The more 
residual degrees of freedom (basically, the more observations), the less 
anti-conservative the LRT is.  This can be assessed for a specific 
dataset by fitting a null-hypothesis model, repeatedly generating new, 
artificial responses from it, and looking at the distribution of LRTs on 
the artificial responses (along the lines of P&B 2000).

Roger



From bolker at ufl.edu  Wed Jun 24 23:51:37 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 24 Jun 2009 17:51:37 -0400
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A425F12.2010403@ling.ucsd.edu>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>		<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>		<FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>		<4A4218F7.4070108@ufl.edu>	<a46630750906240647wc4adfd1j1dd69d0dba79fc69@mail.gmail.com>
	<4A4258C1.2040108@ufl.edu> <4A425F12.2010403@ling.ucsd.edu>
Message-ID: <4A429FE9.2040607@ufl.edu>

Roger Levy wrote:
> Ben Bolker wrote:
>> Daniel Ezra Johnson wrote:
>>> Regarding this thread, what about the method of fitting nested models
>>> and using anova() to estimate a p-value.
>>>
>>> For example:
>>>
>>> mod2 = lmer(y ~ genotype + (1|block), family = binomial, data)
>>> mod0 = lmer(y ~ (1|block), family = binomial, data)
>>>
>>> anova(mod0,mod2)
>>>
>>> How does that p-value (which is one value for the whole term
>>> "genotype") relate to the individual coefficient p-values derived from
>>> the Z-scores inside summary(mod2)?
>>>
>>> Thanks,
>>> Dan
>>    The Z-scores are Wald tests.  The anova results are likelihood
>> ratio tests.  The latter are in general more reliable but are known
>> to be *un*reliable for small-sample (i.e.
>> small-number-of-random-effects-levels) LMMs (Pinheiro and Bates).
>> Wald tests are not *known* to be unreliable in the small-sample
>> case, but I believe that is a statement of ignorance rather than
>> a statement that they're OK ...
> 
> This is an interesting issue -- as Ben points out, likelihood-ratio 
> tests are known to be anti-conservative for tests between linear mixed 
> models differing only in fixed-effects structure.  I think the 
> best-known demonstration of this can be found in Pinheiro & Bates, 2000, 
> pages 87-92.  F-tests are less problematic.

  But note that F tests may not be available or well-defined for
GLMMs ...  (Distinguishing here between conditional F tests (e.g. p. 90
of Pinheiro & Bates 2000) and Wald F tests of parameter combinations --
as far as I know the former are not applicable to GLMMs.
Wald F tests are always available but don't necessarily (???) share
the same properties/reliability as the conditional F tests in the LMM
case ...)

> For logit mixed models, presumably the results will depend a bit on how 
> fitting is done because the likelihood has to be approximated.  For the 
> Laplace approximation currently in use in lme4, I've done some 
> simulations and generally found that likelihood-ratio tests are still 
> anti-conservative; tests based on Wald Z are not as anti-conservative, 
> though they don't seem quite nominal.  

  Hmmm.  Can't we separate estimation (for which Laplace and AGQ are
probably adequate) from inference?  Would there be any point in
considering inference on estimates from a less accurate (PQL)
approximation scheme as long as we have more accurate schemes available?

  I worry whether the Wald Z tests are consistently better or
just "differently wrong" ...

You can do simulations along
> these lines:
> 
> set.seed(2)
> invlogit <- function(x) {
>    temp <- exp(x)
>    return(temp/(1+temp))
> }
> L <- 10
> REP <- 4
> N <- 4*10
> fac <- gl(L,REP)
> f <- function(ignore) {
>    x <- runif(N)
>    r <- rnorm(L)
>    y <- rbinom(N,1,invlogit(r[fac]))
>    m0 <- lmer(y ~ (1 | fac), family="binomial")
>    m1 <- lmer(y ~ x + (1 | fac), family="binomial")
>    temp <- pnorm(fixef(m1)[2]/sqrt(vcov(m1)[2,2]))
>    p.z <- 2*min(temp, 1-temp)
>    p.lr <- 1-pchisq(as.numeric(2*(logLik(m1)-logLik(m0))),1)
>    return(c(p.z,p.lr))
> }
> K <- 5000
> p.vals <- sapply(1:K,f)
> apply(p.vals, 1, function(x) sum(x<0.05))/K
> # this gave me 0.0562 for Wald Z, 0.0608 for LRT
> 
> # Is Wald Z anti-conservative?  The below says "yes" with p=0.044
> 2*(1-pbinom(sum(p.vals[1,]<0.05), K, 0.05))
> 
> 
> Unlike what Ben states above, however, it's my intuition (and informal 
> observation on the basis of simulations) that what determines how 
> anticonservative the LRT is is not the number of random effect levels 
> but rather the ratio between the degrees of freedom involved in the LRT 
> to the residual degrees of freedom in the more general model.  The more 
> residual degrees of freedom (basically, the more observations), the less 
> anti-conservative the LRT is.  This can be assessed for a specific 
> dataset by fitting a null-hypothesis model, repeatedly generating new, 
> artificial responses from it, and looking at the distribution of LRTs on 
> the artificial responses (along the lines of P&B 2000).

    Your conclusion agrees with what Pinheiro and Bates say (p. 88:
"as the number of parameters being removed from the fixed effects
becomes large, compared to the total number of observations, this
inaccuracy in the reported p-values can be substantial").
I don't really know how to decide what is more relevant to
"asymptopia" -- if N is the total number of obs., n the number
of blocks (say m = number per block so N=mn), and p the number of
parameters (fixed? random? variances counting as 1, or n-1, or
something in between?), is it 1-p/N [as PB suggest], or (N-p) [suggested
above], or n? Demidenko p. 145 shows that for LMMs  N \to \infty is
not sufficient for consistency, that n \to \infty is also required ...
I don't know if that helps in practice.

  I don't know where my intuition comes from -- perhaps it's just
conservatism/pessimism, since it's often easier to get N>>p than to get
n large ...

  I do agree that the gold standard is simulations as suggested above.
There are examples in the "worked example" section of glmm.wikidot.com .
These simulations can be very slow -- hopefully (??) Doug Bates will be
able to work out an mcmcsamp() scheme for GLMMs soon, and we can see
if that (much faster) approach generally agrees with null simulations ...


@book{demidenko_mixed_2004,
	edition = {1},
	title = {Mixed Models: Theory and Applications},
	isbn = {0471601616},
	publisher = {{Wiley-Interscience}},
	author = {Eugene Demidenko},
	month = jul,
	year = {2004}
}


> 
> Roger
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bates at stat.wisc.edu  Thu Jun 25 00:48:08 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 24 Jun 2009 17:48:08 -0500
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A429FE9.2040607@ufl.edu>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>
	<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>
	<FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>
	<4A4218F7.4070108@ufl.edu>
	<a46630750906240647wc4adfd1j1dd69d0dba79fc69@mail.gmail.com>
	<4A4258C1.2040108@ufl.edu> <4A425F12.2010403@ling.ucsd.edu>
	<4A429FE9.2040607@ufl.edu>
Message-ID: <40e66e0b0906241548r21cca774xffbcc557adc279a6@mail.gmail.com>

On Wed, Jun 24, 2009 at 4:51 PM, Ben Bolker<bolker at ufl.edu> wrote:
> Roger Levy wrote:
>> Ben Bolker wrote:
>>> Daniel Ezra Johnson wrote:
>>>> Regarding this thread, what about the method of fitting nested models
>>>> and using anova() to estimate a p-value.
>>>>
>>>> For example:
>>>>
>>>> mod2 = lmer(y ~ genotype + (1|block), family = binomial, data)
>>>> mod0 = lmer(y ~ (1|block), family = binomial, data)
>>>>
>>>> anova(mod0,mod2)
>>>>
>>>> How does that p-value (which is one value for the whole term
>>>> "genotype") relate to the individual coefficient p-values derived from
>>>> the Z-scores inside summary(mod2)?
>>>>
>>>> Thanks,
>>>> Dan
>>> ? ?The Z-scores are Wald tests. ?The anova results are likelihood
>>> ratio tests. ?The latter are in general more reliable but are known
>>> to be *un*reliable for small-sample (i.e.
>>> small-number-of-random-effects-levels) LMMs (Pinheiro and Bates).
>>> Wald tests are not *known* to be unreliable in the small-sample
>>> case, but I believe that is a statement of ignorance rather than
>>> a statement that they're OK ...
>>
>> This is an interesting issue -- as Ben points out, likelihood-ratio
>> tests are known to be anti-conservative for tests between linear mixed
>> models differing only in fixed-effects structure. ?I think the
>> best-known demonstration of this can be found in Pinheiro & Bates, 2000,
>> pages 87-92. ?F-tests are less problematic.
>
> ?But note that F tests may not be available or well-defined for
> GLMMs ... ?(Distinguishing here between conditional F tests (e.g. p. 90
> of Pinheiro & Bates 2000) and Wald F tests of parameter combinations --
> as far as I know the former are not applicable to GLMMs.
> Wald F tests are always available but don't necessarily (???) share
> the same properties/reliability as the conditional F tests in the LMM
> case ...)
>
>> For logit mixed models, presumably the results will depend a bit on how
>> fitting is done because the likelihood has to be approximated. ?For the
>> Laplace approximation currently in use in lme4, I've done some
>> simulations and generally found that likelihood-ratio tests are still
>> anti-conservative; tests based on Wald Z are not as anti-conservative,
>> though they don't seem quite nominal.
>
> ?Hmmm. ?Can't we separate estimation (for which Laplace and AGQ are
> probably adequate) from inference? ?Would there be any point in
> considering inference on estimates from a less accurate (PQL)
> approximation scheme as long as we have more accurate schemes available?
>
> ?I worry whether the Wald Z tests are consistently better or
> just "differently wrong" ...
>
> You can do simulations along
>> these lines:
>>
>> set.seed(2)
>> invlogit <- function(x) {
>> ? ?temp <- exp(x)
>> ? ?return(temp/(1+temp))
>> }
>> L <- 10
>> REP <- 4
>> N <- 4*10
>> fac <- gl(L,REP)
>> f <- function(ignore) {
>> ? ?x <- runif(N)
>> ? ?r <- rnorm(L)
>> ? ?y <- rbinom(N,1,invlogit(r[fac]))
>> ? ?m0 <- lmer(y ~ (1 | fac), family="binomial")
>> ? ?m1 <- lmer(y ~ x + (1 | fac), family="binomial")
>> ? ?temp <- pnorm(fixef(m1)[2]/sqrt(vcov(m1)[2,2]))
>> ? ?p.z <- 2*min(temp, 1-temp)
>> ? ?p.lr <- 1-pchisq(as.numeric(2*(logLik(m1)-logLik(m0))),1)
>> ? ?return(c(p.z,p.lr))
>> }
>> K <- 5000
>> p.vals <- sapply(1:K,f)
>> apply(p.vals, 1, function(x) sum(x<0.05))/K
>> # this gave me 0.0562 for Wald Z, 0.0608 for LRT
>>
>> # Is Wald Z anti-conservative? ?The below says "yes" with p=0.044
>> 2*(1-pbinom(sum(p.vals[1,]<0.05), K, 0.05))
>>
>>
>> Unlike what Ben states above, however, it's my intuition (and informal
>> observation on the basis of simulations) that what determines how
>> anticonservative the LRT is is not the number of random effect levels
>> but rather the ratio between the degrees of freedom involved in the LRT
>> to the residual degrees of freedom in the more general model. ?The more
>> residual degrees of freedom (basically, the more observations), the less
>> anti-conservative the LRT is. ?This can be assessed for a specific
>> dataset by fitting a null-hypothesis model, repeatedly generating new,
>> artificial responses from it, and looking at the distribution of LRTs on
>> the artificial responses (along the lines of P&B 2000).
>
> ? ?Your conclusion agrees with what Pinheiro and Bates say (p. 88:
> "as the number of parameters being removed from the fixed effects
> becomes large, compared to the total number of observations, this
> inaccuracy in the reported p-values can be substantial").
> I don't really know how to decide what is more relevant to
> "asymptopia" -- if N is the total number of obs., n the number
> of blocks (say m = number per block so N=mn), and p the number of
> parameters (fixed? random? variances counting as 1, or n-1, or
> something in between?), is it 1-p/N [as PB suggest], or (N-p) [suggested
> above], or n? Demidenko p. 145 shows that for LMMs ?N \to \infty is
> not sufficient for consistency, that n \to \infty is also required ...
> I don't know if that helps in practice.
>
> ?I don't know where my intuition comes from -- perhaps it's just
> conservatism/pessimism, since it's often easier to get N>>p than to get
> n large ...
>
> ?I do agree that the gold standard is simulations as suggested above.
> There are examples in the "worked example" section of glmm.wikidot.com .
> These simulations can be very slow -- hopefully (??) Doug Bates will be
> able to work out an mcmcsamp() scheme for GLMMs soon, and we can see
> if that (much faster) approach generally agrees with null simulations ...

If you look at Doug's schedule for July (www.stat.wisc.edu/~bates) you
will understand why he has been missing in action recently.  In my
"spare time" - when not working on a major report finished last week
and a grant proposal due this week and in preparing these various
courses - I am working on the draft of a book about lme4 because if I
don't get some part of that manuscript to John Kimmel soon he is going
to be very rude to me in Rennes.

>
>
> @book{demidenko_mixed_2004,
> ? ? ? ?edition = {1},
> ? ? ? ?title = {Mixed Models: Theory and Applications},
> ? ? ? ?isbn = {0471601616},
> ? ? ? ?publisher = {{Wiley-Interscience}},
> ? ? ? ?author = {Eugene Demidenko},
> ? ? ? ?month = jul,
> ? ? ? ?year = {2004}
> }
>
>
>>
>> Roger
>>
>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Thu Jun 25 03:33:47 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 24 Jun 2009 21:33:47 -0400
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <40e66e0b0906241548r21cca774xffbcc557adc279a6@mail.gmail.com>
References: <8948F101-98D0-45AC-AD22-D529C21DCEE4@imperial.ac.uk>	
	<7E3D98C4-12E5-4299-8083-FCC160FA9624@kjbeath.com.au>	
	<FD219D38-EC84-4154-90D5-D4654FE2E41F@imperial.ac.uk>	
	<4A4218F7.4070108@ufl.edu>	
	<a46630750906240647wc4adfd1j1dd69d0dba79fc69@mail.gmail.com>	
	<4A4258C1.2040108@ufl.edu> <4A425F12.2010403@ling.ucsd.edu>	
	<4A429FE9.2040607@ufl.edu>
	<40e66e0b0906241548r21cca774xffbcc557adc279a6@mail.gmail.com>
Message-ID: <4A42D3FB.1010903@ufl.edu>

>>  I do agree that the gold standard is simulations as suggested above.
>> There are examples in the "worked example" section of glmm.wikidot.com .
>> These simulations can be very slow -- hopefully (??) Doug Bates will be
>> able to work out an mcmcsamp() scheme for GLMMs soon, and we can see
>> if that (much faster) approach generally agrees with null simulations ...
> 
> If you look at Doug's schedule for July (www.stat.wisc.edu/~bates) you
> will understand why he has been missing in action recently.  In my
> "spare time" - when not working on a major report finished last week
> and a grant proposal due this week and in preparing these various
> courses - I am working on the draft of a book about lme4 because if I
> don't get some part of that manuscript to John Kimmel soon he is going
> to be very rude to me in Rennes.

  Just to clarify, I wasn't trying to nag ... very excited about
the prospect of the book !  (How would you, and Springer/John Kimmel,
feel, about drafts of the book being accessible prior to publication ??)

  Ben Bolker



From Fabian.Scheipl at stat.uni-muenchen.de  Thu Jun 25 10:33:46 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Thu, 25 Jun 2009 10:33:46 +0200
Subject: [R-sig-ME] lmer vs glmmPQL
Message-ID: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>

Ben Bolker said:
>
> My take would be to pick lmer over glmmPQL every time, provided
> it can handle your problem -- in general it should be more accurate.

That's what I wanted to demonstrate to my students last week, so I did
a small simulation study with a logit-model with random intercepts:

logit(P(y_ij=1)) =  x_ij + b_i;
b_i ~N(0,1);
 x_ij ~U[-1,1];
 i=1,..,m;
 j=1,...,n_i

The pdfs with the results are attached (m subjects, ni obs/subject,
RPQL is PQL with iterated REML fits on the working observations
instead of ML, nAGQ=11 for AGQ).
The results surprised me :
- For the estimated standard deviation of the random intercepts, PQL
actually has (much) lower rmse for small and medium-sized data sets
and bias is about the same for LA, AGQ and PQL for small datasets.
- There were no relevant differences in rmse or bias for the estimates
of the fixed effects.

Differences for poisson data should be even smaller, since their
likelihood is more normal-ish.
glmer may still be preferrable since its much faster and more stable
than glmmPQL, but accuracy for smaller datasets may be better for PQL.

Best,
Fabian
-------------- next part --------------
A non-text attachment was scrubbed...
Name: betaResults.pdf
Type: application/pdf
Size: 38107 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090625/8a96eded/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sdResults.pdf
Type: application/pdf
Size: 33515 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090625/8a96eded/attachment-0001.pdf>

From akelly at tcd.ie  Fri Jun 26 08:15:40 2009
From: akelly at tcd.ie (Alan Kelly)
Date: Fri, 26 Jun 2009 07:15:40 +0100
Subject: [R-sig-ME] nested cross-sectional model using lme4 or nlme
Message-ID: <ACCB294E-5F96-4D5C-9718-FC5EB2A55B33@tcd.ie>

Dear all, following a suggestion from one of your contributors, I'm  
posting the following query to R-sig-mixed having had limited response  
from R-help.

I'm attempting to analyse a nested cross-sectional design in which an  
intervention was offered to a series of randomly selected (small)  
communities, so the unit of randomisation is the community.  All  
available individuals in each community were interviewed before the  
intervention and again at follow-up post-intervention.  The set of  
available individuals at baseline and at follow-up was far from  
identical (a common feature of such designs).  Similarly, a series of  
control communities were interviewed.  This type of design is  used in  
epidemiological studies particularly in interventions designed to  
alter lifestyle factors.  Such designs tend to be highly unbalanced.   
Murray et al. discuss the appropriate analysis of such studies  
(Analysis of data from group-randomized trials with repeat  
observations on the same groups, Stats in Med. 17, 1581-1600).  They  
offer three examples of  SAS code - one of which is as follow:

proc mixed;
class cond unit timecat;
model y=cond timecat cond*timecat/ddfm=res;
random int timecat/subject=unit(cond);
run;

cond is 0/1 corresponding to control/intervention
timecat is 0/1 corresponding to baseline/follow-up
unit is 1 to 39 and identifies the communities.
and y is a continuous score

Unfortunately I'm not familiar with SAS code.  I would expect random  
effects for unit and timecat X unit.

I would much appreciate any suggestions on how to code the above in  
lme4 or nlme.

Alan Kelly
Trinity College Dublin



From emmanuel.charpentier at sap.aphp.fr  Fri Jun 26 14:54:37 2009
From: emmanuel.charpentier at sap.aphp.fr (Emmanuel Charpentier)
Date: Fri, 26 Jun 2009 14:54:37 +0200
Subject: [R-sig-ME] nested cross-sectional model using lme4 or nlme
In-Reply-To: <ACCB294E-5F96-4D5C-9718-FC5EB2A55B33@tcd.ie>
References: <ACCB294E-5F96-4D5C-9718-FC5EB2A55B33@tcd.ie>
Message-ID: <1246020875.4776.39.camel@pc3-ec>

Le vendredi 26 juin 2009 ? 07:15 +0100, Alan Kelly a ?crit :
> Dear all, following a suggestion from one of your contributors, I'm  
> posting the following query to R-sig-mixed having had limited response  
> from R-help.
> 
> I'm attempting to analyse a nested cross-sectional design in which an  
> intervention was offered to a series of randomly selected (small)  
> communities, so the unit of randomisation is the community.  All  
> available individuals in each community were interviewed before the  
> intervention and again at follow-up post-intervention.  The set of  
> available individuals at baseline and at follow-up was far from  
> identical (a common feature of such designs).  Similarly, a series of  
> control communities were interviewed.  This type of design is  used in  
> epidemiological studies particularly in interventions designed to  
> alter lifestyle factors.  Such designs tend to be highly unbalanced.   
> Murray et al. discuss the appropriate analysis of such studies  
> (Analysis of data from group-randomized trials with repeat  
> observations on the same groups, Stats in Med. 17, 1581-1600).  They  
> offer three examples of  SAS code - one of which is as follow:
> 
> proc mixed;
> class cond unit timecat;
> model y=cond timecat cond*timecat/ddfm=res;
> random int timecat/subject=unit(cond);
> run;
> 
> cond is 0/1 corresponding to control/intervention
> timecat is 0/1 corresponding to baseline/follow-up
> unit is 1 to 39 and identifies the communities.
> and y is a continuous score
> 
> Unfortunately I'm not familiar with SAS code.  I would expect random  
> effects for unit and timecat X unit.
> 
> I would much appreciate any suggestions on how to code the above in  
> lme4 or nlme.

Caution note : I have not used proc mixed in a log time, and I might be
(quite) rusty). Caveat emptor...

I assume that cond and timecat are coded either as boolean
(FALSE:control|baseline) or as factors (reference=control|baseline), and
that unit is a factor.

One thing is not clear in your description : is y measured at the
community level (i. e. one measure per community per occasion) or at an
individual level (i. e. n_i measures per community per occasion) ? If
the latter, can you individualize successive measures (responses of the
same individual) ? These three eventualities would, IMHO, lead to three
very different models.

In the first case (community-level answer), an "obvious" coding in lmer
would be :

lmer(y ~ cond * timecat + (timecat | unit), ...)

In lme, that would be

lme(y ~ cond * timecat, random=~timecat | unit, ...)

In this model, the "cond" fixed effect is in fact the difference between
conditions at baseline. Since your study is randomized, you should
expect this effect to be 0. The timecat effect is indeed the "natural
evolution" of you communities without intervention, and the net effect
of your intervention is measured by the cond:timecat interaction.

Since you have only one observation per experimental slot, I doubt that
you will get much precision...

You may also note that, in this case, your plan is balanced by
definition (1 observation per slot). aov() might do the job...

In the second case (individual answers, not identifiable between
occasions), the model is written the same way. Here, lme might be
prefered to lmer because the variance and correlation function might
allow you to model the variability between experimental slots (e. g.
heteroscedasticity, between-occasions correlation, etc...).

In the third case (individual answers identifiable between occasions),
another important coupling appears : the answers given by an individual
after intervention are quite likely related to the answers before
intervention. Assuming that an individual belongs to one community only,
it is tempting to exploit this by writing :

lmer(y ~ cond * timecat + (timecat | unit/individual), ...)


If individuals can "switch communities" between occasions (or belong to
more than one), this simple nesting is not valid. Here, lmer does
probably a better job than lme...

HTH,

					Emmanuel Charpentier



From bolker at ufl.edu  Fri Jun 26 20:21:18 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 26 Jun 2009 14:21:18 -0400
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>
References: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>
Message-ID: <4A45119E.9030503@ufl.edu>

  That's really interesting and kind of scary.
  Do you have any thoughts on why this should be so?
  I know of a few simulation studies (Browne and Draper, Breslow) that
test PQL and generally find reasonably "significant" bias for binary
data with large random variance components.  I guess I had simply
assumed that Laplace/AG(H)Q would be better.  (There are also some
theoretical demonstrations (Jiang?) that PQL is asymptotically
inconsistent, I think ...)

  * Are you working in a different regime from previous studies
(smaller data sets, or some other point)?
  * Does considering RMSE rather than bias give a qualitatively
different conclusion (i.e., PQL is biased but has lower variance)?
  * ?

  Since in a recent paper I recommended Laplace/AGHQ out of principle,
and Wald tests out of pragmatism, and thought the former recommendation
was reliable but the latter was not, it's interesting to be having
my world turned upside down ...

  Would welcome opinions & pointers to other studies ...

  Ben Bolker


@article{browne_comparison_2006,
	title = {A comparison of Bayesian and likelihood-based methods for
?tting multilevel models},
	volume = {1},
	url = {http://ba.stat.cmu.edu/journal/2006/vol01/issue03/draper2.pdf},
	number = {3},
	journal = {Bayesian Analysis},
	author = {William J. Browne and David Draper},
	year = {2006},
	pages = {473--514}
}

@incollection{breslow_whither_2004,
	title = {Whither {PQL?}},
	isbn = {0387208623},
	booktitle = {Proceedings of the second Seattle symposium in
biostatistics: Analysis of correlated data},
	publisher = {Springer},
	author = {N. E. Breslow},
	editor = {Danyu Y. Lin and P. J. Heagerty},
	year = {2004},
	pages = {1?22}
}
Fabian Scheipl wrote:
> Ben Bolker said:
>> My take would be to pick lmer over glmmPQL every time, provided
>> it can handle your problem -- in general it should be more accurate.
> 
> That's what I wanted to demonstrate to my students last week, so I did
> a small simulation study with a logit-model with random intercepts:
> 
> logit(P(y_ij=1)) =  x_ij + b_i;
> b_i ~N(0,1);
>  x_ij ~U[-1,1];
>  i=1,..,m;
>  j=1,...,n_i
> 
> The pdfs with the results are attached (m subjects, ni obs/subject,
> RPQL is PQL with iterated REML fits on the working observations
> instead of ML, nAGQ=11 for AGQ).
> The results surprised me :
> - For the estimated standard deviation of the random intercepts, PQL
> actually has (much) lower rmse for small and medium-sized data sets
> and bias is about the same for LA, AGQ and PQL for small datasets.
> - There were no relevant differences in rmse or bias for the estimates
> of the fixed effects.
> 
> Differences for poisson data should be even smaller, since their
> likelihood is more normal-ish.
> glmer may still be preferrable since its much faster and more stable
> than glmmPQL, but accuracy for smaller datasets may be better for PQL.
> 
> Best,
> Fabian
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From kingsfordjones at gmail.com  Fri Jun 26 22:28:09 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Fri, 26 Jun 2009 14:28:09 -0600
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A45119E.9030503@ufl.edu>
References: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>
	<4A45119E.9030503@ufl.edu>
Message-ID: <2ad0cc110906261328u4ab18cb4nf975ac12d6302f23@mail.gmail.com>

On Fri, Jun 26, 2009 at 12:21 PM, Ben Bolker<bolker at ufl.edu> wrote:
> ?That's really interesting and kind of scary.
> ?Do you have any thoughts on why this should be so?
> ?I know of a few simulation studies (Browne and Draper, Breslow) that
> test PQL and generally find reasonably "significant" bias for binary
> data with large random variance components. ?I guess I had simply
> assumed that Laplace/AG(H)Q would be better. ?(There are also some
> theoretical demonstrations (Jiang?) that PQL is asymptotically
> inconsistent, I think ...)
>
> ?* Are you working in a different regime from previous studies
> (smaller data sets, or some other point)?
> ?* Does considering RMSE rather than bias give a qualitatively
> different conclusion (i.e., PQL is biased but has lower variance)?
> ?* ?
>
> ?Since in a recent paper I recommended Laplace/AGHQ out of principle,
> and Wald tests out of pragmatism, and thought the former recommendation
> was reliable but the latter was not, it's interesting to be having
> my world turned upside down ...
>
> ?Would welcome opinions & pointers to other studies ...

Hi Ben -- Here's another simulation showing lower bias but increased
MSE with Laplace when compared to PQL.

@article{1225064,
 author = {Diaz, Rafael E.},
 title = {Comparison of PQL and Laplace 6 estimates of hierarchical
linear models when comparing groups of small incident rates in cluster
randomised trials},
 journal = {Comput. Stat. Data Anal.},
 volume = {51},
 number = {6},
 year = {2007},
 issn = {0167-9473},
 pages = {2871--2888},
 doi = {http://dx.doi.org/10.1016/j.csda.2006.10.005},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 abstract = {The variances of the random components in hierarchical
generalised linear models (HGLMs) with binary outcomes have been
reported to have a considerable downward bias when estimated with the
commonly used penalised quasilikelihood (PQL) technique. The more
recently proposed Laplace 6 approximation promises to reduce this
bias. This study compares the performance of these two techniques when
estimating the parameters of a particular HGLM. This comparison is
performed via Monte Carlo simulations in which the difference between
two groups of proportions, modelled after those appearing in many
epidemiological cluster randomised interventions, are tested using
this model. The Laplace 6 approximation does reduce the bias mentioned
above, but at the price of a higher mean square error. The results of
this study suggest that the optimal solution involves using a
combination of these two techniques. This combination is illustrated
by analysing a data set from a real cluster randomised intervention.}

 }


hth,
Kingsford Jones





>
> ?Ben Bolker
>
>
> @article{browne_comparison_2006,
> ? ? ? ?title = {A comparison of Bayesian and likelihood-based methods for
> ?tting multilevel models},
> ? ? ? ?volume = {1},
> ? ? ? ?url = {http://ba.stat.cmu.edu/journal/2006/vol01/issue03/draper2.pdf},
> ? ? ? ?number = {3},
> ? ? ? ?journal = {Bayesian Analysis},
> ? ? ? ?author = {William J. Browne and David Draper},
> ? ? ? ?year = {2006},
> ? ? ? ?pages = {473--514}
> }
>
> @incollection{breslow_whither_2004,
> ? ? ? ?title = {Whither {PQL?}},
> ? ? ? ?isbn = {0387208623},
> ? ? ? ?booktitle = {Proceedings of the second Seattle symposium in
> biostatistics: Analysis of correlated data},
> ? ? ? ?publisher = {Springer},
> ? ? ? ?author = {N. E. Breslow},
> ? ? ? ?editor = {Danyu Y. Lin and P. J. Heagerty},
> ? ? ? ?year = {2004},
> ? ? ? ?pages = {1?22}
> }
> Fabian Scheipl wrote:
>> Ben Bolker said:
>>> My take would be to pick lmer over glmmPQL every time, provided
>>> it can handle your problem -- in general it should be more accurate.
>>
>> That's what I wanted to demonstrate to my students last week, so I did
>> a small simulation study with a logit-model with random intercepts:
>>
>> logit(P(y_ij=1)) = ?x_ij + b_i;
>> b_i ~N(0,1);
>> ?x_ij ~U[-1,1];
>> ?i=1,..,m;
>> ?j=1,...,n_i
>>
>> The pdfs with the results are attached (m subjects, ni obs/subject,
>> RPQL is PQL with iterated REML fits on the working observations
>> instead of ML, nAGQ=11 for AGQ).
>> The results surprised me :
>> - For the estimated standard deviation of the random intercepts, PQL
>> actually has (much) lower rmse for small and medium-sized data sets
>> and bias is about the same for LA, AGQ and PQL for small datasets.
>> - There were no relevant differences in rmse or bias for the estimates
>> of the fixed effects.
>>
>> Differences for poisson data should be even smaller, since their
>> likelihood is more normal-ish.
>> glmer may still be preferrable since its much faster and more stable
>> than glmmPQL, but accuracy for smaller datasets may be better for PQL.
>>
>> Best,
>> Fabian
>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From pchapman at stat.colostate.edu  Sat Jun 27 00:42:09 2009
From: pchapman at stat.colostate.edu (Phillip Chapman)
Date: Fri, 26 Jun 2009 16:42:09 -0600
Subject: [R-sig-ME] Modeling correlation structure in mixed models
Message-ID: <4A454EC1.9030207@stat.colostate.edu>


Hi All,

I have been trying to learn mixed models in R by reading the books by 
Pinheiro and Bates; Faraway (both linear models books); and Crawley (R 
Book), but I would appreciate some guidance from the more experience R 
users. (I have a fair amount of experience with mixed models in SAS.)

1. Is there another (other than the above) suggested reference for 
understanding the workings of the nlme and lme4 libraries?

2. Is it the case that lme accepts correlated structures ONLY in the 
error term? I have problems in which I would like model random effects 
(such as year) using a random term with an autocorrelated structure. In 
SAS I use options to the ?repeated? statement to add correlation 
structure to the error term, and I use options to the ?random? statement 
to give correlation structure to the other random effects. I haven?t 
found anything in lme or lmer that allows me to specify correlated 
random effects. gee only allows correlation structure in the error term 
and does not allow random effects.

3. All of the examples of random effects in lme seem to have nested 
error structures. Is it the case that lme does not allow crossed random 
effects? lmer allows much more flexible specification of random effects, 
but I don?t see anything that allows correlated error structures.

Thanks in advance,

Phil Chapman



From milton.ruser at gmail.com  Sat Jun 27 01:34:17 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Fri, 26 Jun 2009 19:34:17 -0400
Subject: [R-sig-ME] Modeling correlation structure in mixed models
In-Reply-To: <4A454EC1.9030207@stat.colostate.edu>
References: <4A454EC1.9030207@stat.colostate.edu>
Message-ID: <3aaf1a030906261634h10090b71n65504f8d22f36d1b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090626/5e9b10ce/attachment.pl>

From ral at lcfltd.com  Sat Jun 27 01:34:08 2009
From: ral at lcfltd.com (Robert A LaBudde)
Date: Fri, 26 Jun 2009 19:34:08 -0400
Subject: [R-sig-ME] Modeling correlation structure in mixed models
In-Reply-To: <4A454EC1.9030207@stat.colostate.edu>
References: <4A454EC1.9030207@stat.colostate.edu>
Message-ID: <0KLV008BRDGZB334@vms173019.mailsrvcs.net>

West et al. Linear Mixed Models. Chapman & Hall.

This text uses SAS, SPSS, HLM and R to set up and solve a variety of 
hierarchical mixed models. The text uses 'nlme' exclusively, but the 
related website has 'lme4' equivalent scripts.

At 06:42 PM 6/26/2009, Phillip Chapman wrote:

>Hi All,
>
>I have been trying to learn mixed models in R by reading the books 
>by Pinheiro and Bates; Faraway (both linear models books); and 
>Crawley (R Book), but I would appreciate some guidance from the more 
>experience R users. (I have a fair amount of experience with mixed 
>models in SAS.)
>
>1. Is there another (other than the above) suggested reference for 
>understanding the workings of the nlme and lme4 libraries?
>
>2. Is it the case that lme accepts correlated structures ONLY in the 
>error term? I have problems in which I would like model random 
>effects (such as year) using a random term with an autocorrelated 
>structure. In SAS I use options to the "repeated" statement to add 
>correlation structure to the error term, and I use options to the 
>"random" statement to give correlation structure to the other random 
>effects. I haven't found anything in lme or lmer that allows me to 
>specify correlated random effects. gee only allows correlation 
>structure in the error term and does not allow random effects.
>
>3. All of the examples of random effects in lme seem to have nested 
>error structures. Is it the case that lme does not allow crossed 
>random effects? lmer allows much more flexible specification of 
>random effects, but I don't see anything that allows correlated 
>error structures.
>
>Thanks in advance,
>
>Phil Chapman
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From kingsfordjones at gmail.com  Sat Jun 27 04:48:16 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Fri, 26 Jun 2009 20:48:16 -0600
Subject: [R-sig-ME] Modeling correlation structure in mixed models
In-Reply-To: <4A454EC1.9030207@stat.colostate.edu>
References: <4A454EC1.9030207@stat.colostate.edu>
Message-ID: <2ad0cc110906261948v198ce4beg60ead55ecf9c045f@mail.gmail.com>

Hi Phillip,

Welcome.  Although I'm a fan of PROC MIXED, I think you'll find doing
your mixed modeling in R a relative joy.  Unfortunately, to experience
the joy one must learn to navigate the byzantine labyrinth of
documentation that has grown from this community effort.  A few leads
are offered below...


On Fri, Jun 26, 2009 at 4:42 PM, Phillip
Chapman<pchapman at stat.colostate.edu> wrote:
>
> Hi All,
>
> I have been trying to learn mixed models in R by reading the books by
> Pinheiro and Bates; Faraway (both linear models books); and Crawley (R
> Book), but I would appreciate some guidance from the more experience R
> users. (I have a fair amount of experience with mixed models in SAS.)
>
> 1. Is there another (other than the above) suggested reference for
> understanding the workings of the nlme and lme4 libraries?

P&B is of course the authoritative reference for the nlme package, and
Doug has mentioned on this list that in his (limited) spare time he is
working on a book to accompany lme4.  The lme4 package does come with
several vignettes that can be accessed from R by a call to the
vignette function or by simply opening the pdfs in
yourRlibrary/lme4/doc/.  There is also a vignette in the SASmixed
package called 'lmer for SAS PROC MIXED Users'.  Other helpful
references can be found on the CRAN contributed documentation section,
such as the Mixed Models Web Appendix to John Fox's book.  I haven't
read Gelman and Hill's Data Analysis and Regression using
Multilevel/Hierarchical models, but as I understand it they user lmer
extensively, with wrappers for Bayesian inferences.  Also, Harald
Baayen has a freely available draft of a book on analyzing linguistic
data that includes many lmer examples:
http://www.ualberta.ca/~baayen/publications.html

Googling the following may also be useful:
lmer filetype:pdf

Here are some of Doug's documents that show up:

www.stat.wisc.edu/~bates/reports/MixedComp.pdf
user2007.org/program/presentations/bates.pdf
http://www.jstatsoft.org/v20/i02
www.stat.wisc.edu/~bates/IMPS2008/lme4D.pdf


>
> 2. Is it the case that lme accepts correlated structures ONLY in the error
> term? I have problems in which I would like model random effects (such as
> year) using a random term with an autocorrelated structure. In SAS I use
> options to the ?repeated? statement to add correlation structure to the
> error term, and I use options to the ?random? statement to give correlation
> structure to the other random effects. I haven?t found anything in lme or
> lmer that allows me to specify correlated random effects. gee only allows
> correlation structure in the error term and does not allow random effects.
>

This is something that I have wondered about as well -- as far as I
know one can only specify a correlation structure for the error
covariance matrix, and only using the nlme package (not lme4).
However, given that there are thousands of R packages available I
would not be surprised if someone's already coded up a way to do this
(perhaps in one of the spatial packages using a Bayesian approach,
such as spBayes or geoRglm?)

> 3. All of the examples of random effects in lme seem to have nested error
> structures. Is it the case that lme does not allow crossed random effects?
> lmer allows much more flexible specification of random effects, but I don?t
> see anything that allows correlated error structures.

Although nlme is designed for nested data, crossed random effects can
be specified using a combination of pdBlocked and pdIdent objects (see
page 163 of P&B).  However it's an awkward specification and the
fitting can be slow (IIRC). On the other hand lmer offers elegant
methods of specifying crossed models and speedy methods for fitting
them.

>
> Thanks in advance,
>

You're welcome -- hope it helped,

Kingsford Jones




> Phil Chapman
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ggrothendieck at gmail.com  Sat Jun 27 11:35:53 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 27 Jun 2009 05:35:53 -0400
Subject: [R-sig-ME] Modeling correlation structure in mixed models
In-Reply-To: <2ad0cc110906261948v198ce4beg60ead55ecf9c045f@mail.gmail.com>
References: <4A454EC1.9030207@stat.colostate.edu>
	<2ad0cc110906261948v198ce4beg60ead55ecf9c045f@mail.gmail.com>
Message-ID: <971536df0906270235y5092a59fj73b792c88f2c87c2@mail.gmail.com>

In addition to the sources already mentioned there are chapters on
mixed models in the books associated with the mgcv and DAAG
R packages.

On Fri, Jun 26, 2009 at 10:48 PM, Kingsford
Jones<kingsfordjones at gmail.com> wrote:
> Hi Phillip,
>
> Welcome. ?Although I'm a fan of PROC MIXED, I think you'll find doing
> your mixed modeling in R a relative joy. ?Unfortunately, to experience
> the joy one must learn to navigate the byzantine labyrinth of
> documentation that has grown from this community effort. ?A few leads
> are offered below...
>
>
> On Fri, Jun 26, 2009 at 4:42 PM, Phillip
> Chapman<pchapman at stat.colostate.edu> wrote:
>>
>> Hi All,
>>
>> I have been trying to learn mixed models in R by reading the books by
>> Pinheiro and Bates; Faraway (both linear models books); and Crawley (R
>> Book), but I would appreciate some guidance from the more experience R
>> users. (I have a fair amount of experience with mixed models in SAS.)
>>
>> 1. Is there another (other than the above) suggested reference for
>> understanding the workings of the nlme and lme4 libraries?
>
> P&B is of course the authoritative reference for the nlme package, and
> Doug has mentioned on this list that in his (limited) spare time he is
> working on a book to accompany lme4. ?The lme4 package does come with
> several vignettes that can be accessed from R by a call to the
> vignette function or by simply opening the pdfs in
> yourRlibrary/lme4/doc/. ?There is also a vignette in the SASmixed
> package called 'lmer for SAS PROC MIXED Users'. ?Other helpful
> references can be found on the CRAN contributed documentation section,
> such as the Mixed Models Web Appendix to John Fox's book. ?I haven't
> read Gelman and Hill's Data Analysis and Regression using
> Multilevel/Hierarchical models, but as I understand it they user lmer
> extensively, with wrappers for Bayesian inferences. ?Also, Harald
> Baayen has a freely available draft of a book on analyzing linguistic
> data that includes many lmer examples:
> http://www.ualberta.ca/~baayen/publications.html
>
> Googling the following may also be useful:
> lmer filetype:pdf
>
> Here are some of Doug's documents that show up:
>
> www.stat.wisc.edu/~bates/reports/MixedComp.pdf
> user2007.org/program/presentations/bates.pdf
> http://www.jstatsoft.org/v20/i02
> www.stat.wisc.edu/~bates/IMPS2008/lme4D.pdf
>
>
>>
>> 2. Is it the case that lme accepts correlated structures ONLY in the error
>> term? I have problems in which I would like model random effects (such as
>> year) using a random term with an autocorrelated structure. In SAS I use
>> options to the ?repeated? statement to add correlation structure to the
>> error term, and I use options to the ?random? statement to give correlation
>> structure to the other random effects. I haven?t found anything in lme or
>> lmer that allows me to specify correlated random effects. gee only allows
>> correlation structure in the error term and does not allow random effects.
>>
>
> This is something that I have wondered about as well -- as far as I
> know one can only specify a correlation structure for the error
> covariance matrix, and only using the nlme package (not lme4).
> However, given that there are thousands of R packages available I
> would not be surprised if someone's already coded up a way to do this
> (perhaps in one of the spatial packages using a Bayesian approach,
> such as spBayes or geoRglm?)
>
>> 3. All of the examples of random effects in lme seem to have nested error
>> structures. Is it the case that lme does not allow crossed random effects?
>> lmer allows much more flexible specification of random effects, but I don?t
>> see anything that allows correlated error structures.
>
> Although nlme is designed for nested data, crossed random effects can
> be specified using a combination of pdBlocked and pdIdent objects (see
> page 163 of P&B). ?However it's an awkward specification and the
> fitting can be slow (IIRC). On the other hand lmer offers elegant
> methods of specifying crossed models and speedy methods for fitting
> them.
>
>>
>> Thanks in advance,
>>
>
> You're welcome -- hope it helped,
>
> Kingsford Jones
>
>
>
>
>> Phil Chapman
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From gregor.gorjanc at bfro.uni-lj.si  Sat Jun 27 15:09:33 2009
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sat, 27 Jun 2009 13:09:33 +0000 (UTC)
Subject: [R-sig-ME] Modeling correlation structure in mixed models
References: <4A454EC1.9030207@stat.colostate.edu>
	<2ad0cc110906261948v198ce4beg60ead55ecf9c045f@mail.gmail.com>
	<971536df0906270235y5092a59fj73b792c88f2c87c2@mail.gmail.com>
Message-ID: <loom.20090627T125505-908@post.gmane.org>

Hi,

Here are my 2 cents.

As far as I know, there is no way in lmer to specify anything but a simple
random effect (though there is ZStar package on R-forge that can be used to
infiltrate some nifty covar. structures as has been for example been done in
pedigreemm package). However, this does not mean that only residual has
a covariance matrix, which is actually a identity matrix times a residual
variance.

Take for example a model with three effects: a, b, and c. Both b and c are
to be modelled as 'random' effect. Then the lmer code is something like

lmer(y ~ a + (1 | b) + (1 | c))

This assumes the following model

y_ijk = a_i + b_j + c_k + e_ijk

note that a, b, and c need not be nested! The variance assumptions are

Var(y) = \sigma^2_b + \sigma^2_c + \sigma^2_e

Now for two records that come from the same b_j but not the same c_k, we have

Cov(y_1, y_2) = \sigma^2_b + \sigma^2_e

etc. However, there is no way to say that there is correlation between
different levels of b or c as can bee done in SAS (PROC MIXED) with a
variety of covariance matrices - full, ... That is at least from what I
know - Douglas can "pop in" here if I am wrong.

Additional thing that is possible in lmer is to use

lmer(y ~ a + x + (1 + x | b) + (1 | c))

which is the so called "random regression" model or "varying intercept and
varying slope" model or ... Here we have a 2x2 covariance matrix for the
effect of b.

Finally, my experience is that PROC MIXED my choke on large datasets, while
lmer handles them due to the use of sparse matrix techniques[1], though
there is some progress on this matter at SAS[2].

Regards, gg

[1]http://ggorjan.blogspot.com/2008/07/proc-mixed-vs-lmer.html
[2]http://support.sas.com/documentation/cdl/en/statug/59654/HTML/default/statug_hpmixed_sect001.htm



From highstat at highstat.com  Sun Jun 28 20:03:22 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Sun, 28 Jun 2009 20:03:22 +0200
Subject: [R-sig-ME] Modeling correlation structure in mixed models
Message-ID: <4A47B06A.2080407@highstat.com>

>Hi Phillip,

>I am happy with the book "Mixed Effects Models and Extensions in Ecology
>with R"
>by Zuur, Ieno, Walker, Saveliev and Smith. In fact I am reading chapter by
>chapter,
>and the reading is very digestible, as well as the examples are quite easy
>to understand and to be reference for our "real world".

That is appreciated..:-). 

Anyway..we have started with a sequel. I wanted to 
call it "Analysing Ecological Data - Shit happens", but of course you 
can't use a title like that for an academic book. But the idea is that
we use rather tricky data....nested...full of zeros...correlation at different
levels. However...too often, we are ending up with RBugs to analsye it as it allows you 
to easily implement difficult correlation structures in GLMMs. I found Ntzoufras (2009)
quite useful for this. He has a couple of sections explaining how correlations between 
residuals work their way to correlations between raw data in GLMMs. For the Gaussian
distribution this is trivial..but it is a bit more difficult for other distributions
and link functions. So..to answer the original question..for complicated correlation
structures, dig yourself into MCMC. But I think this is only an issue for longer time
series.

If..by the way...in due course, anyone on this list is a Bayesian specialist and would like
to proof-read a couple of chapters on ZIPs (and related stuff), nested data and MCMC, then that 
would be highly appreciated.

Alain Zuur


>
Cheers

>milton
>brazil=toronto

>
> I have been trying to learn mixed models in R by reading the books by
> Pinheiro and Bates; Faraway (both linear models books); and Crawley (R
> Book), but I would appreciate some guidance from the more experience R
> users. (I have a fair amount of experience with mixed models in SAS.)
>
> 1. Is there another (other than the above) suggested reference for
> understanding the workings of the nlme and lme4 libraries?
>
> 2. Is it the case that lme accepts correlated structures ONLY in the error
> term? I have problems in which I would like model random effects (such as
> year) using a random term with an autocorrelated structure. In SAS I use
> options to the ?repeated? statement to add correlation structure to the
> error term, and I use options to the ?random? statement to give correlation
> structure to the other random effects. I haven?t found anything in lme or
> lmer that allows me to specify correlated random effects. gee only allows
> correlation structure in the error term and does not allow random effects.
>
> 3. All of the examples of random effects in lme seem to have nested error
> structures. Is it the case that lme does not allow crossed random effects?
> lmer allows much more flexible specification of random effects, but I don?t
> see anything that allows correlated error structures.
>
> Thanks in advance,



From Thierry.ONKELINX at inbo.be  Mon Jun 29 09:25:46 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 29 Jun 2009 09:25:46 +0200
Subject: [R-sig-ME] Modeling correlation structure in mixed models
In-Reply-To: <loom.20090627T125505-908@post.gmane.org>
References: <4A454EC1.9030207@stat.colostate.edu><2ad0cc110906261948v198ce4beg60ead55ecf9c045f@mail.gmail.com><971536df0906270235y5092a59fj73b792c88f2c87c2@mail.gmail.com>
	<loom.20090627T125505-908@post.gmane.org>
Message-ID: <2E9C414912813E4EB981326983E0A1040694A809@inboexch.inbo.be>

Dear all,

A small remark on Gregor comment about the correlation structure in
lme4. It can handle two kind of correlation structures within the random
effects: a symmetric variance-covariance matrix (unstructured in SAS
terminology) and independent random effects.

lmer(y ~ a + (1 + x|b))
#symmetric variance-covariance matrix
z11 z12
Z12 z22
#equivalent to the default in nlme (pdSymm)

lmer(y ~ a + (1|b) + (x - 1|b))
#indepent random effects
z11 0
0   z22
#equivalent to pdDiag in nlme

nlme allows for several other correlation structures. Have a look at
?pdClasses. If you can't find the structure you need / like, then you
can allow code your own pdClass. But if you have a limited number of
years and a lot of data, then I would stick to an existing structure
like pdSymm. It will be less efficient than the 'true' structure in your
data, but you need much less assumptions on your model.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Gregor Gorjanc
Verzonden: zaterdag 27 juni 2009 15:10
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Modeling correlation structure in mixed models

Hi,

Here are my 2 cents.

As far as I know, there is no way in lmer to specify anything but a
simple random effect (though there is ZStar package on R-forge that can
be used to infiltrate some nifty covar. structures as has been for
example been done in pedigreemm package). However, this does not mean
that only residual has a covariance matrix, which is actually a identity
matrix times a residual variance.

Take for example a model with three effects: a, b, and c. Both b and c
are to be modelled as 'random' effect. Then the lmer code is something
like

lmer(y ~ a + (1 | b) + (1 | c))

This assumes the following model

y_ijk = a_i + b_j + c_k + e_ijk

note that a, b, and c need not be nested! The variance assumptions are

Var(y) = \sigma^2_b + \sigma^2_c + \sigma^2_e

Now for two records that come from the same b_j but not the same c_k, we
have

Cov(y_1, y_2) = \sigma^2_b + \sigma^2_e

etc. However, there is no way to say that there is correlation between
different levels of b or c as can bee done in SAS (PROC MIXED) with a
variety of covariance matrices - full, ... That is at least from what I
know - Douglas can "pop in" here if I am wrong.

Additional thing that is possible in lmer is to use

lmer(y ~ a + x + (1 + x | b) + (1 | c))

which is the so called "random regression" model or "varying intercept
and varying slope" model or ... Here we have a 2x2 covariance matrix for
the effect of b.

Finally, my experience is that PROC MIXED my choke on large datasets,
while lmer handles them due to the use of sparse matrix techniques[1],
though there is some progress on this matter at SAS[2].

Regards, gg

[1]http://ggorjan.blogspot.com/2008/07/proc-mixed-vs-lmer.html
[2]http://support.sas.com/documentation/cdl/en/statug/59654/HTML/default
/statug_hpmixed_sect001.htm

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Fabian.Scheipl at stat.uni-muenchen.de  Mon Jun 29 10:05:01 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Mon, 29 Jun 2009 10:05:01 +0200
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A45119E.9030503@ufl.edu>
References: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>
	<4A45119E.9030503@ufl.edu>
Message-ID: <4836bc6a0906290105s2e833280mc0c78bdeee798600@mail.gmail.com>

On Fri, Jun 26, 2009 at 8:21 PM, Ben Bolker <bolker at ufl.edu> wrote:
> ?* Are you working in a different regime from previous studies
> (smaller data sets, or some other point)?

I don't think so. The smallest setting has 10 groups with 5 obs. each,
the largest 500 groups with 20 obs. each, and the results indicate
that this is about the range in which interesting changes in mse/bias
happen for this (very simple) setting.

> ?* Does considering RMSE rather than bias give a qualitatively
> different conclusion (i.e., PQL is biased but has lower variance)?

Yes, that's what I tried to display in the graphics -  for the
estimates of the random intercept sd and for data with m=10 or m=50
groups, PQL and LA/AGQ have about the same amount of bias but rmse is
(much) smaller for PQL.



From DAfshartous at med.miami.edu  Mon Jun 29 16:03:20 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Mon, 29 Jun 2009 10:03:20 -0400
Subject: [R-sig-ME] Multivariate mixed effects model
Message-ID: <C66E41E8.A9C2%dafshartous@med.miami.edu>


All,

Has anyone performed a multivariate mixed model with lme or lmer?  An
example of such a model is in Fieuws & Verbeke (2004), "Joint modelling of
multivariate longitudinal profiles, pitfalls of the random effects
approach," Statistics in Medicine, 23:3093-3104.  They also developed a
pairwise fitting method for the case when the number of response variable is
large (Biometrics 2006; 62:424-431), and the implementation was done in SAS.
In any event, I'd rather avoid SAS and do my analysis in R and was wondering
if anyone here could provide any pointers.  Not much turned up in the
archives on this.

Cheers,
David


David Afshartous, Ph.D.
University of Miami
Miller School of Medicine
Division of Clinical Pharmacology
1500 N.W. 12th Avenue, 15th Floor West
Miami, Florida 33136



From pchapman at stat.colostate.edu  Mon Jun 29 21:59:26 2009
From: pchapman at stat.colostate.edu (Phillip Chapman)
Date: Mon, 29 Jun 2009 13:59:26 -0600
Subject: [R-sig-ME] Modeling correlation structure in mixed models
In-Reply-To: <0KLV008BRDGZB334@vms173019.mailsrvcs.net>
References: <4A454EC1.9030207@stat.colostate.edu>
	<0KLV008BRDGZB334@vms173019.mailsrvcs.net>
Message-ID: <4A491D1E.7020406@stat.colostate.edu>


Dear r-sig-mixed models board participants:

Rather than clutter the board with individual responses, I will just 
send one note thanking all those who made helpful responses to my 
inquiry about understanding mixed models in nlme and lme4.  Your info 
has been a great help.

1. Robert LaBudde:  I have the West, et al. Linear Mixed Models book, 
but wasn't aware that there was lme4 script on its web site.

2.  Kingsford Jones:  It is great news that Doug Bates is working on an 
companion book for lme4.  Perhaps some advance material will be 
available when it is closer to completion.  I will keep an eye on his 
web site for additional references.  Thanks for the other references and 
for calling my attention to the example on page 164.  In an agricultural 
context it would be called a "split block design."

3. Milton RUser:  I will buy a copy of the "Mixed Effects Models and 
Extensions in Ecology with R".  I had seen it on Amazon was close to 
buying it.  I think I will go ahead.

4. Gabor Grothendieck:  I'll look at the mgcv and DAAG packages.

5.  Alain Zuur;  I'll look forward to your sequel.  Ntzoufras looks 
useful, I'll take a closer look.

6.  Theirry Onkelinx:  I was aware that by listing both effects in the 
same specification that I could get an unstructured covariance.  The 
application that I am currently looking has 30 year, for which I would 
like to fit AR1 structure.

Thanks again,
Phil Chapman


>



From ken at kjbeath.com.au  Tue Jun 30 09:16:40 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Tue, 30 Jun 2009 17:16:40 +1000
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A45119E.9030503@ufl.edu>
References: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>
	<4A45119E.9030503@ufl.edu>
Message-ID: <87E6B088-2A58-4E32-B079-8A5388D2B541@kjbeath.com.au>

On 27/06/2009, at 4:21 AM, Ben Bolker wrote:

>  That's really interesting and kind of scary.
>  Do you have any thoughts on why this should be so?
>  I know of a few simulation studies (Browne and Draper, Breslow) that
> test PQL and generally find reasonably "significant" bias for binary
> data with large random variance components.  I guess I had simply
> assumed that Laplace/AG(H)Q would be better.  (There are also some
> theoretical demonstrations (Jiang?) that PQL is asymptotically
> inconsistent, I think ...)
>

MLE for nonlinear models are biased, so it is not unexpected that  
Laplace etc will be biased.

It appears that PQL with moderate random effect variance introduces a  
small bias in a direction that reduces the MSE, at least in the  
simulations chosen. For large variances the bias is probably excessive  
and the MSE will increase using PQL.

Ken




>  * Are you working in a different regime from previous studies
> (smaller data sets, or some other point)?
>  * Does considering RMSE rather than bias give a qualitatively
> different conclusion (i.e., PQL is biased but has lower variance)?
>  * ?
>
>  Since in a recent paper I recommended Laplace/AGHQ out of principle,
> and Wald tests out of pragmatism, and thought the former  
> recommendation
> was reliable but the latter was not, it's interesting to be having
> my world turned upside down ...
>
>  Would welcome opinions & pointers to other studies ...
>
>  Ben Bolker
>
>
> @article{browne_comparison_2006,
> 	title = {A comparison of Bayesian and likelihood-based methods for
> ?tting multilevel models},
> 	volume = {1},
> 	url = {http://ba.stat.cmu.edu/journal/2006/vol01/issue03/ 
> draper2.pdf},
> 	number = {3},
> 	journal = {Bayesian Analysis},
> 	author = {William J. Browne and David Draper},
> 	year = {2006},
> 	pages = {473--514}
> }
>
> @incollection{breslow_whither_2004,
> 	title = {Whither {PQL?}},
> 	isbn = {0387208623},
> 	booktitle = {Proceedings of the second Seattle symposium in
> biostatistics: Analysis of correlated data},
> 	publisher = {Springer},
> 	author = {N. E. Breslow},
> 	editor = {Danyu Y. Lin and P. J. Heagerty},
> 	year = {2004},
> 	pages = {1?22}
> }
> Fabian Scheipl wrote:
>> Ben Bolker said:
>>> My take would be to pick lmer over glmmPQL every time, provided
>>> it can handle your problem -- in general it should be more accurate.
>>
>> That's what I wanted to demonstrate to my students last week, so I  
>> did
>> a small simulation study with a logit-model with random intercepts:
>>
>> logit(P(y_ij=1)) =  x_ij + b_i;
>> b_i ~N(0,1);
>> x_ij ~U[-1,1];
>> i=1,..,m;
>> j=1,...,n_i
>>
>> The pdfs with the results are attached (m subjects, ni obs/subject,
>> RPQL is PQL with iterated REML fits on the working observations
>> instead of ML, nAGQ=11 for AGQ).
>> The results surprised me :
>> - For the estimated standard deviation of the random intercepts, PQL
>> actually has (much) lower rmse for small and medium-sized data sets
>> and bias is about the same for LA, AGQ and PQL for small datasets.
>> - There were no relevant differences in rmse or bias for the  
>> estimates
>> of the fixed effects.
>>
>> Differences for poisson data should be even smaller, since their
>> likelihood is more normal-ish.
>> glmer may still be preferrable since its much faster and more stable
>> than glmmPQL, but accuracy for smaller datasets may be better for  
>> PQL.
>>
>> Best,
>> Fabian
>>
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From chris.knight at manchester.ac.uk  Tue Jun 30 10:56:04 2009
From: chris.knight at manchester.ac.uk (Chris Knight)
Date: Tue, 30 Jun 2009 09:56:04 +0100
Subject: [R-sig-ME] spatial correlation structures in nlme, segfault
Message-ID: <4A49D324.1070501@manchester.ac.uk>

Hi,

I'm having a problem where attempting to fit spatial correlation 
structures in nlme crashes R with a segmentation fault- full details and 
example at the end.

I get the same issue with corLin(), corExp(), corGaus(), corSpher() and 
corRatio() on Mac, windows and linux setups  with R2.9.1 and R2.9.0, 32 
or 64 bit (admittedly I've not tried all possible combinations and the 
latter two OSs were virtual machines), but I don't get the problem using 
gnls() on a single level of the data, or using any of the ARMA 
correlation structures.

The actual datasets I'm working with are time series, larger and more 
complex than the example and the segfault takes some time to happen- 
ARMA classes, from my limited attempts, don't seem to do a sufficient 
job on the correlations (the semivariogram for my data modelled with 
corAR1() still looks like a reasonable approximation to a 'linear' 
semivariogram (e.g. as given on p233 of P&B), with no nugget and 
plateauing at a distance of ~20, correlation=corLin(value=20, 
form=~time) gives the segfault)

Any help/suggestions for alternative analyses or work-arounds much 
appreciated. Thanks,

Chris



This seems very similar to an issue identified by JR Ferrer-Paris back 
in 2007: (http://tolstoy.newcastle.edu.au/R/e2/help/07/03/12434.html) to 
which I haven't been able to find an answer. This is therefore his 
example based on the Ovary example from P&B p395ff, even though 
corGaus() doesn't seem a particularly appropriate variance function to 
use on this data(?).

My setup is a 2x2.8GHz Quad-Core Intel Xeon Mac pro with 24Gb RAM
running Mac OS X 10.5.7 (same problem in 10.5.6).

 > library(nlme)
 > sessionInfo()
R version 2.9.1 (2009-06-26)
i386-apple-darwin8.11.1

locale:
en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-92

loaded via a namespace (and not attached):
[1] grid_2.9.1      lattice_0.17-25
 > data(Ovary)
 >  fm10var.lme <-  lme(follicles ~ sin(2 * pi * Time) + cos(2 * pi * 
Time),data=Ovary,random=pdDiag(~sin(2*pi*Time)))
 >  fm50var.lme <- update(fm10var.lme,correlation=corARMA(p=1,q=1))
 > fm10var.nlme <- nlme(follicles ~ A + B * sin(2 * pi * w * Time) + C * 
cos(2 * pi * w * Time),data=Ovary, fixed= A+B+C+w~1, 
random=pdDiag(A+B+w~1), start = c(fixef(fm50var.lme),1))
 > plot(ACF(fm10var.nlme,maxLag=10),alpha=.05)
 > fm20var.nlme <- update(fm10var.nlme,corr=corAR1(0.311))
 > fm30var.nlme <- update(fm10var.nlme,corr=corARMA(p=0,q=2))
 > fm60var.nlme <- update(fm10var.nlme,corr=corGaus(form=~Time))

  *** caught segfault ***
address 0x18d38068, cause 'memory not mapped'

Traceback:
  1: .C(fit_nlme, thetaPNLS = as.double(c(as.vector(unlist(sran)), 
sfix)), pdFactor = as.double(pdFactor(nlmeSt$reStruct)), 
as.integer(unlist(rev(grpShrunk))), as.integer(unlist(Dims)), 
as.integer(attr(nlmeSt$reStruct, "settings"))[-(1:3)], as.double(cF), 
   as.double(vW), as.integer(unlist(cD)), settings = 
as.double(pnlsSettings),     additional = double(NReal * (pLen + 1)), 
as.integer(!is.null(correlation)),     as.integer(!is.null(weights)), 
nlModel, NAOK = TRUE)
  2: nlme.formula(model = follicles ~ A + B * sin(2 * pi * w * Time) + 
    C * cos(2 * pi * w * Time), data = Ovary, fixed = A + B +     C + w 
~ 1, random = pdDiag(A + B + w ~ 1), start = c(fixef(fm50var.lme), 
1), corr = corGaus(form = ~Time))
  3: eval(expr, envir, enclos)
  4: eval(call, parent.frame())
  5: update.nlme(fm10var.nlme, corr = corGaus(form = ~Time))
  6: update(fm10var.nlme, corr = corGaus(form = ~Time))

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:


  --
------------------------------------------------------------------------
Dr Christopher Knight                             Michael Smith Building
Wellcome Trust RCD Fellow                       Faculty of Life Sciences
Tel:  +44 (0)161 2755378                    The University of Manchester
room B.2012                                                  Oxford Road
www.dbkgroup.org/MCISB/people/knight/                 Manchester M13 9PT
? . ,,><(((?>                                                         UK



From akelly at tcd.ie  Tue Jun 30 12:00:28 2009
From: akelly at tcd.ie (Alan Kelly)
Date: Tue, 30 Jun 2009 11:00:28 +0100
Subject: [R-sig-ME] Re. nested cross-sectional model using lme4 or nlme
Message-ID: <3DC7B97E-0193-4614-8C89-E9486467DE16@tcd.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090630/1ef144cb/attachment.pl>

From charpent at bacbuc.dyndns.org  Tue Jun 30 18:32:39 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Tue, 30 Jun 2009 18:32:39 +0200
Subject: [R-sig-ME] Re. nested cross-sectional model using lme4 or nlme
In-Reply-To: <3DC7B97E-0193-4614-8C89-E9486467DE16@tcd.ie>
References: <3DC7B97E-0193-4614-8C89-E9486467DE16@tcd.ie>
Message-ID: <1246379559.5165.9.camel@yod>

Dear List, dear Alan,

Le mardi 30 juin 2009 ? 11:00 +0100, Alan Kelly a ?crit :
> Emmanuel - very many thanks for your detailed reply.
> Some points of clarification and some results... and I should mention  
> that I'm analysing these data on behalf of a colleague.
> Although the unit of randomization is the community, data are indeed  
> available at the level of the individual (but the same individuals  
> could not be guaranteed to be available at follow-up - which forces me  
> to adopt a nested cross-sectional design rather than a nested cohort  
> design) so your suggested model 2 is appropriate.
> "cond" and "timecat" and "unit" are factors.
> The imbalance I referred to arises from the variable numbers of  
> individuals available per community at baseline and again at follow-up  
> - only the number of communities (units) were fixed.
> You suggest that lme might be preferable to lmer in this case - point  
> taken, however, the model failed to run under lme - giving the  
> following message:
> 
> reg=lme(y~cond*timecat, random= ~timecat | unit)
> Error in lme.formula(y ~ cond * timecat, random = ~timecat | unit) :
>    nlminb problem, convergence error code = 1
>    message = iteration limit reached without convergence (9)

Did you try to force a larger iteration limit (using
control=lme.control(someparameterIcantrememberjustnow =
somethingmorethanthedefault) ? ISTR that a casual remark (in P&B ? In
V&R4 ?) noted that this is often necessary...

> Whereas it did run successfully under lmer....
> 
> reg=lmer(y~cond*timecat + (timecat|unit))
>  > summary(reg)
> Linear mixed model fit by REML
> Formula: y ~ cond * timecat + (timecat | unit)
>    AIC  BIC logLik deviance REMLdev
>   8628 8670  -4306     8611    8612
> Random effects:
>   Groups   Name        Variance Std.Dev. Corr
>   unit     (Intercept)  0.67586 0.82211
>            timecat      0.79892 0.89382  -1.000
>   Residual             34.92760 5.90996
> Number of obs: 1346, groups: unit, 37
> 
> Fixed effects:
>               Estimate Std. Error t value
> (Intercept)   12.0166     0.3118   38.53
> cond          -0.2387     0.5241   -0.46
> timecat       -1.0334     0.4498   -2.30
> cond:timecat   0.3727     0.7610    0.49
> 
> Correlation of Fixed Effects:
>              (Intr) cond   timect
> cond        -0.595
> timecat     -0.711  0.423
> cond:timect  0.420 -0.708 -0.591
> 
> For this outcome at least, the interaction term (essentially a  
> difference-in-differences estimate) is non-significant.... a little  
> disappointing, given the effort!

Shit happens ... Did you bootstrap this result to check its
"sensibleness" and/or jacknife it on various subsets to test its
sensitivity ? What do graphical representations say ?

Do you have reason to suspect heteroscedasticity ? If so, another effort
with lme and variance modelling function might worth the pain...

Last but not least, if individual present at two occasions are not "too"
scarce, a subanalysis in "model 3" might enlighten you, especially if
you can check that they do not differ "way too much" from non-repeating
individuals...

HTH,

					Emmanuel Charpentier

> With thanks and best wishes,
> Alan Kelly
> 
> 
> Le vendredi 26 juin 2009  07:15 +0100, Alan Kelly a crit :
>  > Dear all, following a suggestion from one of your contributors, I'm
>  > posting the following query to R-sig-mixed having had limited  
> response
>  > from R-help.
>  >
>  > I'm attempting to analyse a nested cross-sectional design in which an
>  > intervention was offered to a series of randomly selected (small)
>  > communities, so the unit of randomisation is the community.  All
>  > available individuals in each community were interviewed before the
>  > intervention and again at follow-up post-intervention.  The set of
>  > available individuals at baseline and at follow-up was far from
>  > identical (a common feature of such designs).  Similarly, a series of
>  > control communities were interviewed.  This type of design is  used  
> in
>  > epidemiological studies particularly in interventions designed to
>  > alter lifestyle factors.  Such designs tend to be highly unbalanced.
>  > Murray et al. discuss the appropriate analysis of such studies
>  > (Analysis of data from group-randomized trials with repeat
>  > observations on the same groups, Stats in Med. 17, 1581-1600).  They
>  > offer three examples of  SAS code - one of which is as follow:
>  >
>  > proc mixed;
>  > class cond unit timecat;
>  > model y=cond timecat cond*timecat/ddfm=res;
>  > random int timecat/subject=unit(cond);
>  > run;
>  >
>  > cond is 0/1 corresponding to control/intervention
>  > timecat is 0/1 corresponding to baseline/follow-up
>  > unit is 1 to 39 and identifies the communities.
>  > and y is a continuous score
>  >
>  > Unfortunately I'm not familiar with SAS code.  I would expect random
>  > effects for unit and timecat X unit.
>  >
>  > I would much appreciate any suggestions on how to code the above in
>  > lme4 or nlme.
> 
> Caution note : I have not used proc mixed in a log time, and I might be
> (quite) rusty). Caveat emptor...
> 
> I assume that cond and timecat are coded either as boolean
> (FALSE:control|baseline) or as factors (reference=control|baseline), and
> that unit is a factor.
> 
> One thing is not clear in your description : is y measured at the
> community level (i. e. one measure per community per occasion) or at an
> individual level (i. e. n_i measures per community per occasion) ? If
> the latter, can you individualize successive measures (responses of the
> same individual) ? These three eventualities would, IMHO, lead to three
> very different models.
> 
> In the first case (community-level answer), an "obvious" coding in lmer
> would be :
> 
> lmer(y ~ cond * timecat + (timecat | unit), ...)
> 
> In lme, that would be
> 
> lme(y ~ cond * timecat, random=~timecat | unit, ...)
> 
> In this model, the "cond" fixed effect is in fact the difference between
> conditions at baseline. Since your study is randomized, you should
> expect this effect to be 0. The timecat effect is indeed the "natural
> evolution" of you communities without intervention, and the net effect
> of your intervention is measured by the cond:timecat interaction.
> 
> Since you have only one observation per experimental slot, I doubt that
> you will get much precision...
> 
> You may also note that, in this case, your plan is balanced by
> definition (1 observation per slot). aov() might do the job...
> 
> In the second case (individual answers, not identifiable between
> occasions), the model is written the same way. Here, lme might be
> prefered to lmer because the variance and correlation function might
> allow you to model the variability between experimental slots (e. g.
> heteroscedasticity, between-occasions correlation, etc...).
> 
> In the third case (individual answers identifiable between occasions),
> another important coupling appears : the answers given by an individual
> after intervention are quite likely related to the answers before
> intervention. Assuming that an individual belongs to one community only,
> it is tempting to exploit this by writing :
> 
> lmer(y ~ cond * timecat + (timecat | unit/individual), ...)
> 
> 
> If individuals can "switch communities" between occasions (or belong to
> more than one), this simple nesting is not valid. Here, lmer does
> probably a better job than lme...
> 
> HTH,
> 
> 					Emmanuel Charpentier
> 
> 
> 
> 	[[alternative HTML version deleted]]
>



From mareike.kohlmann at stat.uni-muenchen.de  Tue Jun 30 22:21:32 2009
From: mareike.kohlmann at stat.uni-muenchen.de (Mareike Kohlmann)
Date: Tue, 30 Jun 2009 22:21:32 +0200
Subject: [R-sig-ME] Multivariate mixed effects model
References: <mailman.5.1246356002.21217.r-sig-mixed-models@r-project.org>
Message-ID: <005a01c9f9c0$5cdf87c0$0a01a8c0@medion>

Hi,

lme or lmer can be used when the multivariate variables are structured in
the same way as if only a univariate variable was analyzed. A set of dummy
codes need to be created to "flag" the outcomes accordingly.

For more details, see e.g:
Doran, H., Lockwood, J., 2006. Fitting value-added models in R. Journal of
Educational and Behavioral Statistics 31 (2), p. 205-230.

Cheers,
Mareike

***************************************
Mareike Kohlmann
Department of Statistics
Ludwig-Maximilians-University Munich
Germany
E-Mail: mareike.kohlmann at stat.uni-muenchen.de



From Fabian.Scheipl at stat.uni-muenchen.de  Tue Jun 30 18:24:33 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Tue, 30 Jun 2009 18:24:33 +0200
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <87E6B088-2A58-4E32-B079-8A5388D2B541@kjbeath.com.au>
References: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>
	<4A45119E.9030503@ufl.edu>
	<87E6B088-2A58-4E32-B079-8A5388D2B541@kjbeath.com.au>
Message-ID: <4836bc6a0906300924n259509bfu7b2fc7f97938dfa2@mail.gmail.com>

On Tue, Jun 30, 2009 at 9:16 AM, Ken Beath<ken at kjbeath.com.au> wrote:
> It appears that PQL with moderate random effect variance introduces a small
> bias in a direction that reduces the MSE, at least in the simulations
> chosen. For large variances the bias is probably excessive and the MSE will
> increase using PQL.

Results from simulations with sd(RandomIntercept)=3 instead of 1
(results attached) confirm your remark - with the possible exception
of very small data sets the performance (in rmse & bias) for Laplace
and AGQ is much much better than PQL.
I'm sorry for getting Ben Bolker and others all riled up with my earlier post.

One more thing to consider though:
 A random intercept variance of 1 in a logistic model means that the
medium  50% of subjects/groups are expected to have between about half
and about double the odds of a subject/group with random intercept=0,
which is already fairly large effect in my book.
##
> qlnorm(c(.1, .25, .75, .9))
[1] 0.28 0.51 1.96 3.60
##

For a random intercept sd of 3, the multiplicative effect on the
baseline odds for the middle 50% is between  0.13 and  7.6,
##
>qlnorm(c(.1, .25,  .75, .9), sdlog = 3)
[1]  0.021  0.132  7.565 46.743
##
which means really large inter-group/subject heterogeneity and might
not be encountered that frequently in real data (?) (or at least
suggest a mis-specified model that misses important
subject/group-level predictors...).

(Similar remarks concerning "effect size" of the random effect apply
to Poisson regression with log-link.)

So, what's the lesson --
Should we still prefer PQL if we expect to see small to intermediate
inter-group/subject heterogeneity?

Fabian
-------------- next part --------------
A non-text attachment was scrubbed...
Name: betaResults_sd3.pdf
Type: application/pdf
Size: 34241 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090630/b9826713/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sdResults_sd3.pdf
Type: application/pdf
Size: 33786 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090630/b9826713/attachment-0001.pdf>

