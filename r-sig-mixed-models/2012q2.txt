From bates at stat.wisc.edu  Sun Apr  1 09:50:02 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 1 Apr 2012 02:50:02 -0500
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
	<CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
Message-ID: <CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>

On Fri, Mar 30, 2012 at 3:44 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Ben,
>
> Many thanks for the help. ?I tried your suggestion out and it seemed
> to work (and I learned a bit about lme4 in the process :)
>
> library(lme4)
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm1Fun <- update(fm1,devFunOnly=TRUE)
> library(numDeriv)
> fm1_thpar <- getME(fm1,"theta")
> h <- hessian(fm1Fun, fm1_thpar)
> g <- grad(fm1Fun, fm1_thpar)
>
> which I can use (I think) to get standard errors of the variance parameters.
>
> library(MASS)
> sqrt(diag(ginv(h)))
>
> which plug into a longer formula that attempts to test the
> significance of indirect effects. ?Given that the variance parameters
> are not normally distributed, my hunch is that even though both fixed
> and random effects (and their variances/standard errors) are being
> built into the mediation test, it is probably not well-behaved either,
> but it is nice to be able to try to replicate models in the article.
> Even if they are not perfectly accurate, I am hoping I can use them as
> a sanity check for when I play with some mcmc and bootstrapping.

I have been travelling and haven't tracked messages on the list
closely so I might have missed something here.  What do you mean by
"the variance parameters"?  The theta parameters aren't variances and
covariances.  They are values from the relative covariance factor.
For the model you fit the first element of theta is the standard
deviation of the intercept random effects divided by the standard
deviation of the per-observation noise.  The second and third elements
only make sense in terms of the Cholesky factor of the relative
variance-covariance matrix.

This choice is not arbitrary.  Although we are accustomed to thinking
in terms of variances and covariances or in terms of standard
deviations and correlations, these are difficult scales on which to
optimize because the constraints on these values are complicated
nonlinear constraints.

So as long as you recognize that the "variance parameters" aren't
variances or covariances you should be okay.

> R Under development (unstable) (2012-03-29 r58868)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] MASS_7.3-17 ? ? ? ?reshape2_1.2.1 ? ? numDeriv_2012.3-1 ?lme4_0.999902344-0
> [5] Matrix_1.0-6 ? ? ? lattice_0.20-6
>
> loaded via a namespace (and not attached):
> [1] grid_2.16.0 ? ?minqa_1.2.0 ? ?nlme_3.1-103 ? plyr_1.7.1 ? ? splines_2.16.0
> [6] stringr_0.6 ? ?tools_2.16.0
>
> On Mon, Mar 19, 2012 at 12:15 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Joshua Wiley <jwiley.psych at ...> writes:
>>
>>>
>>> Hi,
>>>
>>> I am trying to use a multivariate mixed effects linear model to
>>> examine mediation. ?This works fine. ?The final step is to compute the
>>> indirect effect and its standard error. ?The indirect effect is easy
>>> (product of coefficients plus their covariance). ?For the standard
>>> error, I need the gradient (D) and the hessian (H):
>>> the variance is then:
>>>
>>> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
>>>
>>> This is all given in the Appendix of
>>> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>>>
>>> Is there a way to get this out of a mer class object? ?Looking at
>>> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$. ?@V
>>> seems like it would give me the gradient but is null for a basic lmer
>>> model.
>>
>> ?If you're willing to try out the development version (i.e., lme4
>> from r-forge), I think you can do this as follows:
>>
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>> library(numDeriv)
>> fm1_thpar <- getME(fm1,"theta")
>> h <- hessian(fm1Fun,fm1_thpar)
>>
>> ?and similarly for the gradient.
>>
>> ?Let me know how it goes.
>>
>> ?Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From keith.larson at biol.lu.se  Sun Apr  1 13:26:57 2012
From: keith.larson at biol.lu.se (Keith Larson)
Date: Sun, 1 Apr 2012 13:26:57 +0200
Subject: [R-sig-ME] interpreting random effects
Message-ID: <CAM1PXy3HPWC2we3Vj9hd2b02jJvC0AGm8atFXn3v=tcjnsvZnw@mail.gmail.com>

I have have measured the trait frequency for a "mountain" associated
allele across a number of sites and years. In my (glmer) model I have
summarized the allele frequency by site and year as the dependent
(binomial) variable and specified site and year as random effects. The
fixed effects are latitude, longitude, altitude, and
latitude|longitude. When I run the model and then drop and update each
random effect separately to see if they are important to the model,
site appears to be significant and year does not. Two questions:

1. Can I re-summarize my dependent variable for by site rather than
site and year?

2. Given that we did not sample each site the same number of times
(years) and have different numbers of samples at each site (and year),
should I standardize my dependent variable?

Thanks,
Keith Larson, PhD Student
Evolutionary Ecology, Lund University



From pierces1 at msu.edu  Sun Apr  1 15:47:03 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Sun, 1 Apr 2012 09:47:03 -0400
Subject: [R-sig-ME] MCMC model selection reference
In-Reply-To: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>
References: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>
Message-ID: <000a01cd100d$ec8a0560$c59e1020$@msu.edu>

Here are a couple references on DIC that I happen to have handy:

Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & van der Linde, A.
(2002). Bayesian measures of model complexity and fit. Journal of the Royal
Statistical Society: Series B (Statistical Methodology), 64(4), 583-639.
doi: 10.1111/1467-9868.00353  http://www.jstor.org/stable/3088806 

Barnett, A. G., Koper, N., Dobson, A. J., Schmiegelow, F., & Manseau, M.
(2010). Using information criteria to select the correct variance-covariance
structure for longitudinal data in ecology. Methods in Ecology and
Evolution, 1(1), 15-24. doi: 10.1111/j.2041-210X.2009.00009.x
http://dx.doi.org/10.1111/j.2041-210X.2009.00009.x 


Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Ray Danner [mailto:danner.ray at gmail.com] 
Sent: Saturday, March 31, 2012 2:24 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] MCMC model selection reference

Dear list,

I'm looking for guidance on model selection using DIC values.  I'm
particularly interested in comparing mixed models created with the
package MCMCglmm.  I currently use AIC for my models built with lme
and (g)lmer and like the ability to calculate evidence ratios and
model average predictions, which are very easy for readers to
conceptualize.  AICcmodavg is great for these things.

Can anyone recommend a resource that describes the appropriate use of
DIC for model selection (and its limitations)?  I'm mainly an
ecologist, so a less-technical treatment would be ideal.

My main questions are:
1. Can DIC be used to select among mixed models?
Kery and Schaub (2012 p. 42) raise concerns about counting the correct
number of parameters and state that WinBUGS does not calculate them
appropriately, though Millar (2009) provides a method that is
appropriate for hierarchical models.  On the other hand, Saveliev et
al. (2009) use DIC to compare models with random effects built with
the BRugs package.  Hadfield's MCMCglmm Tutorial says that lower DIC
is better, but doesn't give details about use.

2. Any rules of thumb on what constitutes sufficiently large deltaDIC
values?  Are evidence ratios acceptable?

3. Can DIC be used to calculate model average predictions?

Thanks in advance and please forgive me if I missed your publication.
Ray


Refs
Kery and Schaub. 2012. Bayesian Population Analysis Using WinBUGS: A
Hierarchical Perspective.
Millar. 2009. Comparison of hierarchical Bayesian models for
overdispersed count data using DIC and Bayes' Factors. Biometrics
65:962-969.
Saveliev et al. 2009. Ch. 23 in Zuur, Mixed Effects Models and
Extensions in Ecology with R.



From pdalgd at gmail.com  Sun Apr  1 15:53:55 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 1 Apr 2012 15:53:55 +0200
Subject: [R-sig-ME] repeated measures: lme(r) vs manova
In-Reply-To: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
References: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
Message-ID: <BCB1C781-ACDB-4893-870A-66F24E13CDB6@gmail.com>


On Mar 19, 2012, at 22:31 , Nathan Lemoine wrote:

> Hi all,
> Sorry in advance for the length of this post, but I've searched around and couldn't find anything that addressed this issue:
> 
> I recently ran into the issue of deciding on the appropriate way to analyze a repeated measures design. We enriched quadrats to measure productivity and we monitored them for three years. Four quadrats were nested within plots. Here are the data:
> 
> "plot" "quad" "nut" "t1" "t3" "t4"
> "1" 1 "A" "nut" 17.69130435 70.4 57.8
> "2" 1 "A" "no nut" 65.4173913 125.8 109.9
> "3" 1 "B" "nut" 19.56521739 103.2 100.8
> "4" 1 "B" "no nut" 89.03636364 131.3 99.1
> "5" 1 "C" "nut" 29.88723404 25.7 29.9
> "6" 1 "C" "no nut" 45.45454545 113.1 110.6
> "7" 1 "D" "nut" 18.28181818 60.9 67.7
> "8" 1 "D" "no nut" 68.88888889 136 95
> "9" 2 "A" "nut" 35.41666667 61.6 16
> "10" 2 "A" "no nut" 40.90909091 59.4 64.7
> "11" 2 "B" "nut" 34.14255319 26.7 23.1
> "12" 2 "B" "no nut" 36.27021277 71.6 47.2
> "13" 2 "C" "nut" 13.33333333 20.9 26.4
> "14" 2 "C" "no nut" 7.118181818 31.2 19.1
> "15" 2 "D" "nut" 20 30.9 27.8
> "16" 2 "D" "no nut" 19.34893617 31.3 16.7
> "17" 3 "A" "nut" 22.22222222 130.7 163.6
> "18" 3 "A" "no nut" 32.90869565 83.8 86.2
> "19" 3 "B" "nut" 38.29787234 99 110.1
> "20" 3 "B" "no nut" 38.83636364 127.1 115.2
> "21" 3 "C" "nut" 38.88888889 81.7 193.7
> "22" 3 "C" "no nut" 28.98888889 72.1 103.8
> "23" 3 "D" "nut" 50 111.3 117.7
> "24" 3 "D" "no nut" 26.86666667 94.2 113
> "25" 4 "A" "nut" 63.63636364 128.4 114.8
> "26" 4 "A" "no nut" 108.8956522 121 80.7
> "27" 4 "B" "nut" 104.4444444 146.5 102.2
> "28" 4 "B" "no nut" 84.74444444 111.5 109.9
> "29" 4 "C" "nut" 71.31111111 86.2 118.4
> "30" 4 "C" "no nut" 115.9555556 131.4 141.9
> "31" 4 "D" "nut" 75.65555556 141.5 92.5
> "32" 4 "D" "no nut" 108.9888889 146.6 122.2
> "33" 5 "A" "nut" 20.2 57.4 14.6
> "34" 5 "A" "no nut" 12.34489796 55.4 13.4
> "35" 5 "B" "nut" 48.98888889 56.3 28.7
> "36" 5 "B" "no nut" 35.65555556 55.8 17.6
> "37" 5 "C" "nut" 22.22222222 45.9 7.3
> "38" 5 "C" "no nut" 9.088888889 55.6 20.5
> "39" 5 "D" "nut" 64.44444444 86.1 61.7
> "40" 5 "D" "no nut" 15.65555556 75.7 41.8
> "41" 6 "A" "nut" 22.22222222 101.1 69.8
> "42" 6 "A" "no nut" 53.33333333 171.2 113.5
> "43" 6 "B" "nut" 37.87777778 111.1 66.8
> "44" 6 "B" "no nut" 46.96666667 120.8 83.8
> "45" 6 "C" "nut" 17.87777778 120.7 84
> "46" 6 "C" "no nut" 21.21212121 116.3 76.8
> "47" 6 "D" "nut" 24.01304348 86.1 64.6
> "48" 6 "D" "no nut" 29.51034483 112.5 51.9
> 
> The basic question is: When is it appropriate to use a MANOVA-based repeated measures design over a mixed effects model? 
> 
> For example, the MANOVA approach:
> library(car)
> repeated.manova <- lm(cbind(t1,t3,t4)~nut+plot+quad, data=manova.data)
> Manova(repeated.manova)
> 
> nut is not significant and there are 40 denominator df. 
> 
> If I set up the data and run lme:
> 
> mixed.dat <- melt(manova.data, id=c("plot","quad","nut"))
> colnames(mixed.dat)[4:5] <- c("time","prod")
> mixed.dat$time <- as.numeric(mixed.dat$time))
> 
> library(nlme)
> lme.repeated <- lme(prod~nut, random=~nut|time, data=mixed.dat)
> anova(lme.repeated)
> 
> Gives 140 denominator df. I'm also not sure this is the appropriate set up for a repeated measures design. Running the following code seems more in line with what I've read to take into account the correlation in observations within the same plot:
> 
> lme.repeated2 <- lme(prod~nut*time, random=~time|plot, data=mixed.dat)
> anova(lme.repeated2)
> 
> This model seems much more appropriate, as observations within plots are now allowed to be correlated, but there is still a huge difference between the MANOVA-based approach and the mixed-effects-based approach, as the mixed-effects model gives me a significant result. The MANOVA assumes that I have three (correlated) observations on 48 independent units, whereas the lme approach assumes that I have 144 observations on correlated units. Also not sure if that interpretation is correct.
> 
> Alternatively, I used lmer() for non-nested, multilevel models allowing observations to be correlated in space and time:
> 
> repeated.mixed3 <- lmer(prod~nut + (1|plot) + (1|time), data=mixed.dat)
> repeated.mixed4 <- lmer(prod~ (1|plot) + (1|time), data=mixed.dat)
> anova(repeated.mixed3, repeated.mixed4)
> 
> This approach also gives me a significant result. Which of these is the most appropriate? The differences between lme and lmer are trivial (in this case), but the difference between the MANOVA approach and mixed-effects is substantial. I figure the MANOVA approach is probably in correct on account of the nested design, but my question extends to situations when the design is not nested. 
> 
> Thanks in advance for your help,
> 

You need to be careful to compare similar models. Your MANOVA model is effectively treating plot:quad:nut (i.e. anything not involving time) as the observational unit. In particular, this ignores the pairing of the two nut levels at the same level of plot:quad. Also notice that a MANOVA model tests the effect of a trivariate outcome by comparing a model with three parameters for the effect (one for each variate) with a model with no effect at all, i.e. the test has three d.f. So your MANOVA test is effectively that of time:nut in the following model:

> mixed.dat$ia <- with(mixed.dat, interaction(plot,quad,nut))
> lme.repeated2 <- lme(prod~time/nut, random=~time|ia, data=mixed.dat)
> anova(lme.repeated2)
            numDF denDF   F-value p-value
(Intercept)     1    91 155.47120  <.0001
time            2    91  60.29474  <.0001
time:nut        3    91   1.08992  0.3575

which is fairly similar to 

> anova(repeated.manova)
Analysis of Variance Table

            Df  Pillai approx F num Df den Df Pr(>F)    
(Intercept)  1 0.85717   88.019      3     44 <2e-16 ***
nut          1 0.06636    1.043      3     44 0.3832    
Residuals   46                                          

At this point, a rather long thread could be spun about the differences between the two analyses, but I think you'll agree that they are broadly in agreement. Both are pretty clearly wrong though. At the very least, you'd want to include the design properly, especially the paired nature of the comparisons of levels of nut.

-?d


> Nathan
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From bbolker at gmail.com  Sun Apr  1 18:39:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 1 Apr 2012 16:39:10 +0000 (UTC)
Subject: [R-sig-ME] lme4a installation
References: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>
Message-ID: <loom.20120401T172659-142@post.gmane.org>

Boris Shor <boris at ...> writes:

> I saw your post on the mixed models mailing list. I'm running R2.15 and I'm
> getting the same installation error for "lme4a". Did you resolve the issue?
> 

  I'm not sure who you're responding to ...
  We're working to update the versions at 
http://lme4.r-forge.r-project.org/repos ; these have been uploaded to SVN
and should be online within 24 hours (along with more detailed installation
instructions).

  However, in the meantime, as I responded to an earlier post, lme4a is
now deprecated in favor of the r-forge version of lme4.  If you find that
there's anything you can't do with r-forge lme4 (version 0.999902344-0)
that you could do with lme4a, please let the maintainers know ...

  Ben Bolker



From bbolker at gmail.com  Sun Apr  1 19:30:23 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 01 Apr 2012 13:30:23 -0400
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
	<CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
	<CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>
Message-ID: <4F7890AF.9010106@gmail.com>

On 12-04-01 03:50 AM, Douglas Bates wrote:
> On Fri, Mar 30, 2012 at 3:44 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> Hi Ben,
>>
>> Many thanks for the help.  I tried your suggestion out and it seemed
>> to work (and I learned a bit about lme4 in the process :)
>>
>> library(lme4)
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>> library(numDeriv)
>> fm1_thpar <- getME(fm1,"theta")
>> h <- hessian(fm1Fun, fm1_thpar)
>> g <- grad(fm1Fun, fm1_thpar)
>>
>> which I can use (I think) to get standard errors of the variance parameters.
>>
>> library(MASS)
>> sqrt(diag(ginv(h)))
>>
>> which plug into a longer formula that attempts to test the
>> significance of indirect effects.  Given that the variance parameters
>> are not normally distributed, my hunch is that even though both fixed
>> and random effects (and their variances/standard errors) are being
>> built into the mediation test, it is probably not well-behaved either,
>> but it is nice to be able to try to replicate models in the article.
>> Even if they are not perfectly accurate, I am hoping I can use them as
>> a sanity check for when I play with some mcmc and bootstrapping.
> 
> I have been travelling and haven't tracked messages on the list
> closely so I might have missed something here.  What do you mean by
> "the variance parameters"?  The theta parameters aren't variances and
> covariances.  They are values from the relative covariance factor.
> For the model you fit the first element of theta is the standard
> deviation of the intercept random effects divided by the standard
> deviation of the per-observation noise.  The second and third elements
> only make sense in terms of the Cholesky factor of the relative
> variance-covariance matrix.
> 
> This choice is not arbitrary.  Although we are accustomed to thinking
> in terms of variances and covariances or in terms of standard
> deviations and correlations, these are difficult scales on which to
> optimize because the constraints on these values are complicated
> nonlinear constraints.
> 
> So as long as you recognize that the "variance parameters" aren't
> variances or covariances you should be okay.

  The warning is worthwhile.  I haven't taken enough time to figure out
the context (Appendix of

http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf

as stated), but to me it actually seems that the context there is
actually using the RE variances as plug-in estimates (i.e. ignoring
their uncertainty) ... ??


> 
>> R Under development (unstable) (2012-03-29 r58868)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] MASS_7.3-17        reshape2_1.2.1     numDeriv_2012.3-1  lme4_0.999902344-0
>> [5] Matrix_1.0-6       lattice_0.20-6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.16.0    minqa_1.2.0    nlme_3.1-103   plyr_1.7.1     splines_2.16.0
>> [6] stringr_0.6    tools_2.16.0
>>
>> On Mon, Mar 19, 2012 at 12:15 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>> Joshua Wiley <jwiley.psych at ...> writes:
>>>
>>>>
>>>> Hi,
>>>>
>>>> I am trying to use a multivariate mixed effects linear model to
>>>> examine mediation.  This works fine.  The final step is to compute the
>>>> indirect effect and its standard error.  The indirect effect is easy
>>>> (product of coefficients plus their covariance).  For the standard
>>>> error, I need the gradient (D) and the hessian (H):
>>>> the variance is then:
>>>>
>>>> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
>>>>
>>>> This is all given in the Appendix of
>>>> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>>>>
>>>> Is there a way to get this out of a mer class object?  Looking at
>>>> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$.  @V
>>>> seems like it would give me the gradient but is null for a basic lmer
>>>> model.
>>>
>>>  If you're willing to try out the development version (i.e., lme4
>>> from r-forge), I think you can do this as follows:
>>>
>>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>>> library(numDeriv)
>>> fm1_thpar <- getME(fm1,"theta")
>>> h <- hessian(fm1Fun,fm1_thpar)
>>>
>>>  and similarly for the gradient.
>>>
>>>  Let me know how it goes.
>>>
>>>  Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ramos.grad.student at gmail.com  Sun Apr  1 19:35:41 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Sun, 1 Apr 2012 10:35:41 -0700
Subject: [R-sig-ME] lme4a installation
In-Reply-To: <loom.20120401T172659-142@post.gmane.org>
References: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>
	<loom.20120401T172659-142@post.gmane.org>
Message-ID: <CAHawB9v65g-p=F5yPykemW-p=E+8KKZY5XWEDuPuHW7pvmJRhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120401/14ad233e/attachment-0001.pl>

From j.hadfield at ed.ac.uk  Sun Apr  1 20:30:03 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 01 Apr 2012 19:30:03 +0100
Subject: [R-sig-ME] MCMC model selection reference
In-Reply-To: <000a01cd100d$ec8a0560$c59e1020$@msu.edu>
References: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>
	<000a01cd100d$ec8a0560$c59e1020$@msu.edu>
Message-ID: <20120401193003.10433zixro7z1egw@www.staffmail.ed.ac.uk>

Hi,

My understanding of DIC (and information criterion generally) is  
woeful, but here are my thoughts on DIC - which I hope others will  
correct if they disagree.

Does DIC wok in principal  - yes, could it work in practice  -  
sometimes, does it work in practice - rarely (for hierarchical models).

DIC needs to be "focused". Imagine you have single Gaussian  
observations (y) on children within schools.  We have fixed effects b,  
random effects u, and variance parameters Vs (between school variance)  
and Ve (within school variance). We also have the fixed-effect design  
matrix X and random-effect design matrix Z.  We could calculate the  
deviance using two likelihoods:

a) dmvnorm(y, X%*%b+Z%*%u, I*Ve)
b) dmvnorm(y, X%*%b, Z%*%t(Z)*Vs+I*Ve)

In a) we are conditioning on the school effects in b) we marginalise  
them. The focus in a) is of the form "can we predict new observations  
in *these* schools" and in b) "can we predict new observations in  
*new* schools".

As a parent you're probably interested in a) as a scientist you're  
probably interested in b).

MCMCglmm (and I believe WinBUGS, depending on how the model is  
parameterised) focuses at the highest level a). The reason for this is  
that MCMCglmm Gibbs samples u and then Gibbs samples Vs conditional on  
u with out the need to calculate b) which is expensive (If DIC=TRUE,  
a) will be calculated and this is easy). Presumably WinBUGS could  
calculate a) or b) depending on how it is set up, but I think b) is  
more usual (?) because of performance issues.

With over-dispersed non-Gaussian data the case for DIC (as  
implemented) is very bad, because the highest level is the latent  
variable (linear predictor).  Lets imagine our observations on  
children were how many times they missed the bus and we treated them  
as log-normal Poisson. DIC would be focused at "can we predict how  
many times *these* children miss the bus".

Modelling over-dispersion using a two-parameter distribution (without  
observational-level effects), perhaps a negative binomial in our  
example, may get us back to "can we predict how many times children  
from *these* schools miss the bus" but getting down to a) may be more  
difficult because with non-Gaussian data the random effects cannot be  
marginalised analytically.

For non-Gaussian data I never use DIC, and have seriously considered  
removing it from MCMCglmm.

Cheers,

Jarrod



Quoting "Steven J. Pierce" <pierces1 at msu.edu> on Sun, 1 Apr 2012  
09:47:03 -0400:

> Here are a couple references on DIC that I happen to have handy:
>
> Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & van der Linde, A.
> (2002). Bayesian measures of model complexity and fit. Journal of the Royal
> Statistical Society: Series B (Statistical Methodology), 64(4), 583-639.
> doi: 10.1111/1467-9868.00353  http://www.jstor.org/stable/3088806
>
> Barnett, A. G., Koper, N., Dobson, A. J., Schmiegelow, F., & Manseau, M.
> (2010). Using information criteria to select the correct variance-covariance
> structure for longitudinal data in ecology. Methods in Ecology and
> Evolution, 1(1), 15-24. doi: 10.1111/j.2041-210X.2009.00009.x
> http://dx.doi.org/10.1111/j.2041-210X.2009.00009.x
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Ray Danner [mailto:danner.ray at gmail.com]
> Sent: Saturday, March 31, 2012 2:24 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] MCMC model selection reference
>
> Dear list,
>
> I'm looking for guidance on model selection using DIC values.  I'm
> particularly interested in comparing mixed models created with the
> package MCMCglmm.  I currently use AIC for my models built with lme
> and (g)lmer and like the ability to calculate evidence ratios and
> model average predictions, which are very easy for readers to
> conceptualize.  AICcmodavg is great for these things.
>
> Can anyone recommend a resource that describes the appropriate use of
> DIC for model selection (and its limitations)?  I'm mainly an
> ecologist, so a less-technical treatment would be ideal.
>
> My main questions are:
> 1. Can DIC be used to select among mixed models?
> Kery and Schaub (2012 p. 42) raise concerns about counting the correct
> number of parameters and state that WinBUGS does not calculate them
> appropriately, though Millar (2009) provides a method that is
> appropriate for hierarchical models.  On the other hand, Saveliev et
> al. (2009) use DIC to compare models with random effects built with
> the BRugs package.  Hadfield's MCMCglmm Tutorial says that lower DIC
> is better, but doesn't give details about use.
>
> 2. Any rules of thumb on what constitutes sufficiently large deltaDIC
> values?  Are evidence ratios acceptable?
>
> 3. Can DIC be used to calculate model average predictions?
>
> Thanks in advance and please forgive me if I missed your publication.
> Ray
>
>
> Refs
> Kery and Schaub. 2012. Bayesian Population Analysis Using WinBUGS: A
> Hierarchical Perspective.
> Millar. 2009. Comparison of hierarchical Bayesian models for
> overdispersed count data using DIC and Bayes' Factors. Biometrics
> 65:962-969.
> Saveliev et al. 2009. Ch. 23 in Zuur, Mixed Effects Models and
> Extensions in Ecology with R.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From jwiley.psych at gmail.com  Sun Apr  1 22:02:10 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 1 Apr 2012 13:02:10 -0700
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <4F7890AF.9010106@gmail.com>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
	<CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
	<CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>
	<4F7890AF.9010106@gmail.com>
Message-ID: <CANz9Z_LJnsmf5ZAtaPcaGAY-87GGBCAPT4bSV6EVX3Rib7Gj5w@mail.gmail.com>

Thanks to both of you.  Really.  Your time both developing software
and supporting it is amazing and greatly appreciated.

On Sun, Apr 1, 2012 at 10:30 AM, Ben Bolker <bbolker at gmail.com> wrote:
> On 12-04-01 03:50 AM, Douglas Bates wrote:
>> On Fri, Mar 30, 2012 at 3:44 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>> Hi Ben,
>>>
>>> Many thanks for the help. ?I tried your suggestion out and it seemed
>>> to work (and I learned a bit about lme4 in the process :)
>>>
>>> library(lme4)
>>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>>> library(numDeriv)
>>> fm1_thpar <- getME(fm1,"theta")
>>> h <- hessian(fm1Fun, fm1_thpar)
>>> g <- grad(fm1Fun, fm1_thpar)
>>>
>>> which I can use (I think) to get standard errors of the variance parameters.
>>>
>>> library(MASS)
>>> sqrt(diag(ginv(h)))
>>>
>>> which plug into a longer formula that attempts to test the
>>> significance of indirect effects. ?Given that the variance parameters
>>> are not normally distributed, my hunch is that even though both fixed
>>> and random effects (and their variances/standard errors) are being
>>> built into the mediation test, it is probably not well-behaved either,
>>> but it is nice to be able to try to replicate models in the article.
>>> Even if they are not perfectly accurate, I am hoping I can use them as
>>> a sanity check for when I play with some mcmc and bootstrapping.
>>
>> I have been travelling and haven't tracked messages on the list
>> closely so I might have missed something here. ?What do you mean by
>> "the variance parameters"? ?The theta parameters aren't variances and
>> covariances. ?They are values from the relative covariance factor.
>> For the model you fit the first element of theta is the standard
>> deviation of the intercept random effects divided by the standard
>> deviation of the per-observation noise. ?The second and third elements
>> only make sense in terms of the Cholesky factor of the relative
>> variance-covariance matrix.

Okay, good to know.  Thank you for pointing this out.  I have a copy
of your book (Pinheiro & Bates) and the draft chapters for lme4 on
R-forge.  If there are any other references you think would help me
gain a good understanding of how lme4 works, I would happily get and
read them.

>>
>> This choice is not arbitrary. ?Although we are accustomed to thinking
>> in terms of variances and covariances or in terms of standard
>> deviations and correlations, these are difficult scales on which to
>> optimize because the constraints on these values are complicated
>> nonlinear constraints.

That makes sense.

>> So as long as you recognize that the "variance parameters" aren't
>> variances or covariances you should be okay.
>
> ?The warning is worthwhile. ?I haven't taken enough time to figure out
> the context (Appendix of
>
> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>
> as stated), but to me it actually seems that the context there is
> actually using the RE variances as plug-in estimates (i.e. ignoring
> their uncertainty) ... ??

Here is more context and an example but I certainly do not expect
anyone to read through all of this and try it.  You have done more
than enough already.

Perhaps an example closer to a real use case would be helpful.  In
psychology, it is common to think of mediation, where one variable
(say x) is associated with an outcome of interest (say y), but the
cause link is believed to be through a third variable, the mediator
(say m).  To give a hypothetical economics example, suppose taxes are
lowered (x), which causes business and people to be more productive
and earn more (m), which causes overall government revenue (y) to
increase, even though the tax rate is lower.

Sometimes diagrammed:
x -> m -> y

causality is often the theory, but is not necessarily assessed so set
that aside for the moment.  The interest is in the average indirect
effect of x on y through the variable m.  Again in psychology, this is
usually assessed as the product of coefficients of x predicting m and
m predicting y, controlling for x.  In models with mixed effects, this
complicated by the fact that one or both of these effects may be
random, not fixed.

To accurately estimate all the necessary parameters, it is necessary
to have them in a single model.  This can be done in a structural
equation model framework with a series of equations or in mixed
effects models by 'stacking' the two dependent variables (y and m) and
using indicator variables.  The paper referenced presented a technique
for estimating the indirect effect (say g):

g = ab + cov(a, b)

where a is the average RE of x predicting m, and b is the average RE
of m predicting y.  The appendix of the paper that I referenced uses
covariance matrix of the REs, gradient, and hessian to come up with an
estimate of

Var(g) to construct an assymptotic test like:

g/sqrt(Var(g))

in order to test whether the average indirect RE is significantly
different from zero.  I have my doubts about how accurate this
approach is given that products of coefficients tend not to be
normally distributed, and I do want to try other methods for creating
a confidence interval or perhaps move to a bayesian framework and use
a credible interval.  But for first steps, I figured try to replicate
the article (which was done in SAS) in R, and then go on to try
additional techniques.  Here is a dataset online and R code for the
type of model I am trying to run.  I have been able to replicate the
paper's point estimate of the indirect effect (the authors provide
sample data and SAS code), in nlme, and fairly close in lme4
(complicated by difficulties for me to get a heterogenous residual
variance structure for the stacked outcomes).

##############################################
require(foreign)
d <- read.dta("http://www.ats.ucla.edu/stat/data/ml_sim.dta")

require(reshape2)
d$fid <- 1:nrow(d)
stacked <- melt(d, id.vars = c("fid", "id", "x", "m"),
  measure.vars = c("y", "m"), value.name = "z")
stacked <- within(stacked, {
    sy <- as.integer(variable == "y")
    sm <- as.integer(variable == "m")
})

require(lme4)
mm <- lmer(z ~ 0 + sm + sm:x + sy + sy:m + sy:x +
              (0 + sm + sm:x + sy + sy:m + sy:x | id) +
              (0 + sm | fid), data = stacked)
summary(mm)

## effect of interest is x's effect on y through m
## i.e., sm:x * sy:m + cov_{sm:x, sy:m} because they are REs
## (0 + sm | fid) is an attempt to account for differential
## variability in the m versus y outcomes, something
## (though far from exactly) like this in nlme:

require(nlme)
mm.alt <- lme(z ~ 0 + sm + sm:x + sy + sy:m + sy:x, data = stacked,
       random = ~ 0 + sm + sm:x + sy + sy:m + sy:x | id,
       weights = varIdent(form = ~ 1 | variable))
summary(mm.alt)
##############################################

Cheers,

Josh

[snip]



From denis.vile at supagro.inra.fr  Sun Apr  1 22:31:48 2012
From: denis.vile at supagro.inra.fr (Denis Vile)
Date: Sun, 01 Apr 2012 22:31:48 +0200
Subject: [R-sig-ME] crossed effects with lmer but correlation structure
 with lme
In-Reply-To: <loom.20120330T215721-195@post.gmane.org>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<4F7418A5.7050500@supagro.inra.fr>
	<4F7594C1.1000101@supagro.inra.fr>
	<loom.20120330T215721-195@post.gmane.org>
Message-ID: <4F78BB34.2060801@supagro.inra.fr>

Thank you very much Ben ! I'm going to look at this attentively.
Sincerely,
Denis

Le 30/03/2012 22:09, Ben Bolker a ?crit :
> Denis Vile<denis.vile at ...>  writes:
>
>> Hi all,
>>
>> Was my problem not sufficiently well exposed or no one could help me ?
>>
>> Sincerely,
>>
>> Denis
>    The canonical reference for this is p. 163ff of Pinheiro
> and Bates 2000 (section 4.2.2,  http://tinyurl.com/crossedRE )
> You are correct that lme4 doesn't handle 'R-side' correlation
> structures, nor will it in the near future ...
>
>
>   (I've added this information to glmm.wikidot.com/faq ...)
>
>    Ben Bolker
>
>
>> Le 29/03/2012 10:09, Denis Vile a ?crit :
>>> Dear R users,
>>>
>>> I'm trying to fit a crossed-effects mixed model that would include a
>>> spatial correlation structure..
>>> The data come from four controlled experiments (control, treatment1,
>>> treatment2, treatment1+treatment2) on plants grown in a growth
>>> chamber.  Individual replicates of different genotypes were grown
>>> together and response traits were measured. A covariate X is included
>>> in the model with a quadratic form.
>>>
>>> We fitted the following model using lmer:
>>>
>>> fm1<- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
>>> (1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
>>>              (1|Trt1:Trt2:idGenotype), data=...)
>>>
>    [snip snip snip]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 

*Denis VILE*
Charg? de Recherche
Laboratoire d'Ecophysiologie des Plantes sous Stress Environnementaux 
(*LEPSE*)
UMR 759 *INRA*-SUPAGRO // Institut de Biologie Int?grative des Plantes 
(IBIP, b?t 7)
2 place Pierre Viala
34060 Montpellier Cedex 2
Tel +33 (0)4 99 61 31 87
Fax +33 (0)4 67 52 21 16
http://www1.montpellier.inra.fr/ibip/lepse/



From dhocking at wildcats.unh.edu  Sun Apr  1 20:46:31 2012
From: dhocking at wildcats.unh.edu (Daniel Hocking)
Date: Sun, 1 Apr 2012 14:46:31 -0400
Subject: [R-sig-ME]  MCMC model selection reference
In-Reply-To: <mailman.6435.1333301440.4502.r-sig-mixed-models@r-project.org>
References: <mailman.6435.1333301440.4502.r-sig-mixed-models@r-project.org>
Message-ID: <94169223-CDB8-4026-9EB5-A48B4A9FA956@wildcats.unh.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120401/efa1794a/attachment-0001.pl>

From c.ryan.king at gmail.com  Mon Apr  2 01:44:06 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Sun, 1 Apr 2012 18:44:06 -0500
Subject: [R-sig-ME] MCMC model selection reference
Message-ID: <CAEQ+J27t-tbeV14K-ofRHbKh2M1RfnCtBYVXqTsA8RFn4DdT8A@mail.gmail.com>

I'd be interested if you find something good. Lately I've been
interested in a new criterion, WAIC. It's supposed to be an improved
estimate of out-of-sample / cross-validation prediction error (which
DIC is supposed to be also).

Discussion here:
http://andrewgelman.com/2011/06/plummer_on_dic/
http://andrewgelman.com/2011/06/deviance_dic_ai/

>From plummer's 2008 paper discussion:

"The question of what constitutes a noteworthy difference in DIC
between 2 models has not yet received a satisfactory answer. Whereas
calibration scales have been proposed for Bayes factors (Kass and
Raftery, 1995), no credible scale has been proposed for the difference
in DIC between 2 models. Indeed, such a scale is unlikely be useful.
Ripley (1996) shows that the sampling error of the difference in AIC
between 2 models is Op(1) when the models are nested, and the smaller
model is true, but the error may be Op(sqrt(n)) for nonnested models.
No absolute scale for interpretation of AIC could be valid in both
situations. DIC inherits this behavior since it includes AIC as a
special case."

The related question of how much cross-validation error is a lot is
unknown; in fact it is known that there does not exist an unbiased
estimate of the variance of CV error.
Bengio, Y. & Grandvalet, Y. No unbiased estimator of the variance of
k-fold cross-validation. The Journal of Machine Learning Research 5,
1089?1105 (2004).

There are concentration
inequalities which are generally too loose to be useful (or so I'm
told). There are
some promising recent theory papers that I haven't been able to fully
read. Plummer goes on to suggest parametric simulation to calibrate
his DIC variant. That or non-parametric simulation (bootstrap,
permutation) is all that I've seen applied papers do. I've tried
simulating calibration scales and found that the sampling variance of
 CV depends on how complex the model is / is allowed to be.

The WAIC paper is nice in that is says explicitly what it is trying
the calculate: the cross-validation loss of the log-evidence and shows
its relationship to DIC and BIC.

Ryan King
University of Chicago
Dept Health Studies



From geralttee at gmail.com  Mon Apr  2 10:30:21 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Mon, 2 Apr 2012 10:30:21 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 64, Issue 3
In-Reply-To: <mailman.6456.1333320954.4502.r-sig-mixed-models@r-project.org>
References: <mailman.6456.1333320954.4502.r-sig-mixed-models@r-project.org>
Message-ID: <CANXb-o5uKXY78U10+xTv3ZJO6qvGbK2RSJMF0=E62oM_=_RCjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120402/1c6a0716/attachment-0001.pl>

From maechler at stat.math.ethz.ch  Mon Apr  2 17:19:13 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 Apr 2012 17:19:13 +0200
Subject: [R-sig-ME] lme4a installation
In-Reply-To: <loom.20120401T172659-142@post.gmane.org>
References: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>
	<loom.20120401T172659-142@post.gmane.org>
Message-ID: <20345.50033.264322.607310@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Sun, 1 Apr 2012 16:39:10 +0000 (UTC) writes:

    > Boris Shor <boris at ...> writes:
    >> I saw your post on the mixed models mailing list. I'm running R2.15
    >> and I'm getting the same installation error for "lme4a". Did you
    >> resolve the issue?
    >> 

    > I'm not sure who you're responding to ...  We're working to update the
    > versions at http://lme4.r-forge.r-project.org/repos ; these have been
    > uploaded to SVN and should be online within 24 hours (along with more
    > detailed installation instructions).

    > However, in the meantime, as I responded to an earlier post, lme4a is
    > now deprecated in favor of the r-forge version of lme4.  If you find
    > that there's anything you can't do with r-forge lme4 (version
    > 0.999902344-0) that you could do with lme4a, please let the maintainers
    > know ...

 lmer(*,  sparseX = TRUE)
glmer(*,  sparseX = TRUE)


{ but then, the maintainers know ;-) }



From bbolker at gmail.com  Mon Apr  2 17:42:09 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Apr 2012 15:42:09 +0000 (UTC)
Subject: [R-sig-ME] interpreting random effects
References: <CAM1PXy3HPWC2we3Vj9hd2b02jJvC0AGm8atFXn3v=tcjnsvZnw@mail.gmail.com>
Message-ID: <loom.20120402T173632-237@post.gmane.org>

Keith Larson <keith.larson at ...> writes:

> 
> I have have measured the trait frequency for a "mountain" associated
> allele across a number of sites and years. In my (glmer) model I have
> summarized the allele frequency by site and year as the dependent
> (binomial) variable and specified site and year as random effects. The
> fixed effects are latitude, longitude, altitude, and
> latitude|longitude. When I run the model and then drop and update each
> random effect separately to see if they are important to the model,
> site appears to be significant and year does not. Two questions:
> 
> 1. Can I re-summarize my dependent variable for by site rather than
> site and year?

  You certainly *can*.  What is your goal in presenting this summary?

> 2. Given that we did not sample each site the same number of times
> (years) and have different numbers of samples at each site (and year),
> should I standardize my dependent variable?

  Depending on your answer to the question above, I would guess that
the best predictor of allele frequency at a given site would be the
prediction based on the fixed effects, plus the random effect of site
(back-transformed from the scale of the linear predictor (log or logit)
to the frequency scale, of course).
Leaving year in the model, but setting its prediction to zero, should
give you a reasonable measure of "expected allele frequency at site X
in a randomly chosen year", and should handle the unequal weighting.



From helixed2 at yahoo.com  Mon Apr  2 18:25:25 2012
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Mon, 2 Apr 2012 09:25:25 -0700 (PDT)
Subject: [R-sig-ME] Binomial GLMM -- denominator of proportion as fixed
	effect predictor?
Message-ID: <1333383925.58110.YahooMailNeo@web161805.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120402/0bf6f702/attachment-0001.pl>

From f.calboli at imperial.ac.uk  Mon Apr  2 18:48:35 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 2 Apr 2012 17:48:35 +0100
Subject: [R-sig-ME] cannot connect to
	http://lme4.r-forge.r-project.org/repos/
Message-ID: <BC5D9196-B2BE-4149-B979-8181B24025BF@imperial.ac.uk>

As by subject. I am on a Mac, OS 10.7.3, XCode 4.3.2, CLI stuff installed, fortran installed through http://r.research.att.com/ 

> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.15.0

When I try to connect (through the GUI package manager) to http://lme4.r-forge.r-project.org/repos/ I get:

Warning: unable to access index for repository http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.15/src/contrib

Additionally,

> install.packages("lme4",repos="http://r-forge.r-project.org", dependencies  = T)
Warning: unable to access index for repository http://r-forge.r-project.org/bin/macosx/leopard/contrib/2.15
Warning message:
package ?lme4? is not available (for R version 2.15.0) 
> install.packages("lme4",repos="http://r-forge.r-project.org/repos", dependencies  = T)
Warning: unable to access index for repository http://r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.15
Warning message:
package ?lme4? is not available (for R version 2.15.0) 

though going by hand to the repo I can see both lme4 ane RcppEigen.

BW

Federico








--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From roby.joehanes at nih.gov  Mon Apr  2 20:27:20 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 2 Apr 2012 14:27:20 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
Message-ID: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>

Hi:

I am trying to port pedigreemm to use the new lme4. However, the new lme4 is somewhat opaque to me and hence I need help. Specifically, how can I extract the following terms:
lmf$FL$trms[[tn]]$Zt
lmf$FL$trms[[tn]]$A

The information lies within lmf at pp object, but it is too opaque to me to fish anything out.

I understand that lmf$FL$fl is lmf at flist and that lmer_finalize calls should be replaced with optwrap and mkMerMod. Nevertheless, I think that the lmer or glmer could use some refactoring to ease the calls.

I appreciate any help on these.

Thanks,
Roby



From agalecki at umich.edu  Mon Apr  2 21:57:59 2012
From: agalecki at umich.edu (Andrzej T Galecki 1)
Date: Mon, 02 Apr 2012 15:57:59 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
Message-ID: <0fdcade662bf745019d5178ca7dc992a@umich.edu>


Hi Roby,

Ben prepared getME(} function to extract various components of the model
fit
obtained using lme4.0 and new lme4.

Try 
getME(lmf,"Zt")
getME(lmf,"A")
getME(lmf,"flist")

Andrzej

On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
<roby.joehanes at nih.gov> wrote:
> Hi:
> 
> I am trying to port pedigreemm to use the new lme4. However, the new lme4
> is somewhat opaque to me and hence I need help. Specifically, how can I
> extract the following terms:
> lmf$FL$trms[[tn]]$Zt
> lmf$FL$trms[[tn]]$A
> 
> The information lies within lmf at pp object, but it is too opaque to me to
> fish anything out.
> 
> I understand that lmf$FL$fl is lmf at flist and that lmer_finalize calls
> should be replaced with optwrap and mkMerMod. Nevertheless, I think that
> the lmer or glmer could use some refactoring to ease the calls.
> 
> I appreciate any help on these.
> 
> Thanks,
> Roby
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Mon Apr  2 22:17:49 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Apr 2012 20:17:49 +0000 (UTC)
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
Message-ID: <loom.20120402T221015-332@post.gmane.org>

Andrzej T Galecki 1 <agalecki at ...> writes:

> Ben prepared getME(} function to extract various components of the model
> fit
> obtained using lme4.0 and new lme4.
> 
> Try 
> getME(lmf,"Zt")
> getME(lmf,"A")
> getME(lmf,"flist")
> 
> Andrzej
> 
> On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
> <roby.joehanes at ...> wrote:
> > Hi:
> > 
> > I am trying to port pedigreemm to use the new lme4. However, the new lme4
> > is somewhat opaque to me and hence I need help. Specifically, how can I
> > extract the following terms:
> > lmf$FL$trms[[tn]]$Zt
> > lmf$FL$trms[[tn]]$A
> > 
> > The information lies within lmf <at> pp object, but it is too opaque to me to
> > fish anything out.
> > 
> > I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
> > should be replaced with optwrap and mkMerMod. Nevertheless, I think that
> > the lmer or glmer could use some refactoring to ease the calls.
> > 
> > I appreciate any help on these.
> > 

   A couple of questions:

 1. how broadly are you using A?  Off-list, Doug Bates has commented to
me that defining A is relatively straightforward for LMMs but not necessarily
as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
that people are using it for [GN]LMMs as welll ...

  2. I can't quite tell from your e-mail -- would it be useful to have
the stuff between the first optwrap() and the last mkMerMod abstracted
into a single (exposed) function?  For [GN]LMMs it should probably
also allow control of whether the preliminary "nAGQ=0" optimization
is done or not ...

  (All comments are mine alone, not necessarily speaking for all lme4
authors ...)

  Ben Bolker



From roby.joehanes at nih.gov  Mon Apr  2 22:24:32 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 2 Apr 2012 16:24:32 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <loom.20120402T221015-332@post.gmane.org>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
Message-ID: <C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>

Hi Ben and Andrzej:

Thank you for the info. I am trying to get pedigreemm to work with the new lme4 and I am now stuck on how to translate the following line:
lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt

Because the matrix A is defined in getME method as:
PR$Lambdat %*% PR$Zt

I am still trying to figure the code out. I think we can do away with the A matrix since it is apparently not essential to the computation. I think the crux of the pedigreemm call to the underlying lme4 is in the following short lines:

    pnms <- names(pedigree)
    stopifnot(all(pnms %in% names(getME(lmf, "flist"))))
    asgn <- attr(getME(lmf, "flist"), "assign")
    for (i in seq_along(pedigree)) {
        tn <- which(match(pnms[i], names(getME(lmf, "flist"))) == asgn)
        if (length(tn) > 1)
            stop("a pedigree factor must be associated with only one r.e. term")
        Zt <- getME(lmf, "Zt")
        relfac[[i]] <- relfactor(pedigree[[i]], rownames(Zt))
        lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
    }
    ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize else lme4:::lmer_finalize, lmf)
    ans <- new("pedigreemm", relfac = relfac, ans)

Any help is appreciated.

Thanks,
Roby


On Apr 2, 2012, at 4:17 PM, Ben Bolker wrote:

Andrzej T Galecki 1 <agalecki at ...> writes:

Ben prepared getME(} function to extract various components of the model
fit
obtained using lme4.0 and new lme4.

Try
getME(lmf,"Zt")
getME(lmf,"A")
getME(lmf,"flist")

Andrzej

On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
<roby.joehanes at ...> wrote:
Hi:

I am trying to port pedigreemm to use the new lme4. However, the new lme4
is somewhat opaque to me and hence I need help. Specifically, how can I
extract the following terms:
lmf$FL$trms[[tn]]$Zt
lmf$FL$trms[[tn]]$A

The information lies within lmf <at> pp object, but it is too opaque to me to
fish anything out.

I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
should be replaced with optwrap and mkMerMod. Nevertheless, I think that
the lmer or glmer could use some refactoring to ease the calls.

I appreciate any help on these.


  A couple of questions:

1. how broadly are you using A?  Off-list, Doug Bates has commented to
me that defining A is relatively straightforward for LMMs but not necessarily
as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
that people are using it for [GN]LMMs as welll ...

 2. I can't quite tell from your e-mail -- would it be useful to have
the stuff between the first optwrap() and the last mkMerMod abstracted
into a single (exposed) function?  For [GN]LMMs it should probably
also allow control of whether the preliminary "nAGQ=0" optimization
is done or not ...

 (All comments are mine alone, not necessarily speaking for all lme4
authors ...)

 Ben Bolker



From bbolker at gmail.com  Mon Apr  2 22:22:24 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Apr 2012 20:22:24 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?cannot_connect_to=09http=3A//lme4=2Er-forge?=
	=?utf-8?q?=2Er-project=2Eorg/repos/?=
References: <BC5D9196-B2BE-4149-B979-8181B24025BF@imperial.ac.uk>
Message-ID: <loom.20120402T222103-700@post.gmane.org>

Federico Calboli <f.calboli at ...> writes:

>  As by subject. I am on a Mac, OS 10.7.3, XCode 4.3.2, CLI stuff
> installed, fortran installed through http://r.research.att.com/

 
  [snip]

> When I try to connect (through the GUI package manager) to
> http://lme4.r-forge.r-project.org/repos/ I get: Warning: unable to
> access index for repository
> http://lme4.r-forge.r-project.org/repos/[snip]

  Thanks for the heads-up, this was a screwed-up PACKAGES file.
This is fixed now, should propagate within 24 hours (and in the
meantime you can of course download the files and install them
locally ...)

  Ben Bolker



From roby.joehanes at nih.gov  Tue Apr  3 00:19:04 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 2 Apr 2012 18:19:04 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
Message-ID: <6C288834-4360-4B79-9781-2758C038664E@nih.gov>

Hi all:

Just a follow up: It seems that some changes need to be made in the new lme4 so that the pedigreemm can be modified to use it. They are:
1. To allow the return of all necessary internal variables required for invoking the optimizer (especially rho plus devfun in one call), without invoking the optimizer itself. Right now I did two calls, the first to get the devfun, the second to get the rest. However, I cannot obtain rho in all cases.
#lmerc$doFit <- FALSE # call lmer without pedigree and with doFit = FALSE
l... <- list(...)
lmerc$devFunOnly <- TRUE
devFun <- eval(lmerc, parent.frame())
lmerc$devFunOnly <- FALSE
lmf <- eval(lmerc, parent.frame())

2. Some partitioning of Zt that allows duplicate level names for multiple random factors. That is, if random factors 1 and 2 (let's call them RF1 and RF2) share the same level-string, my current hack will not work. Perhaps someone can propose a better way. My current hack is as follows:
Zt <- getME(lmf, "Zt")
Zt <- Zt[rownames(Zt) %in% levels(getME(lmf, "flist")[[tn]]), ]
(The original was: Zt <- lmf$FL$trms[[tn]]$Zt)

Since I cannot get rho, I cannot realize the lmer_finalize or glmer_finalize. Any help is appreciated. I am stuck right now since I have installed the lme4 SVN version, but the pedigreemm package still assumes the CRAN version.

Thank you,
Roby


On Apr 2, 2012, at 4:24 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

Hi Ben and Andrzej:

Thank you for the info. I am trying to get pedigreemm to work with the new lme4 and I am now stuck on how to translate the following line:
lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt

Because the matrix A is defined in getME method as:
PR$Lambdat %*% PR$Zt

I am still trying to figure the code out. I think we can do away with the A matrix since it is apparently not essential to the computation. I think the crux of the pedigreemm call to the underlying lme4 is in the following short lines:

   pnms <- names(pedigree)
   stopifnot(all(pnms %in% names(getME(lmf, "flist"))))
   asgn <- attr(getME(lmf, "flist"), "assign")
   for (i in seq_along(pedigree)) {
       tn <- which(match(pnms[i], names(getME(lmf, "flist"))) == asgn)
       if (length(tn) > 1)
           stop("a pedigree factor must be associated with only one r.e. term")
       Zt <- getME(lmf, "Zt")
       relfac[[i]] <- relfactor(pedigree[[i]], rownames(Zt))
       lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
   }
   ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize else lme4:::lmer_finalize, lmf)
   ans <- new("pedigreemm", relfac = relfac, ans)

Any help is appreciated.

Thanks,
Roby


On Apr 2, 2012, at 4:17 PM, Ben Bolker wrote:

Andrzej T Galecki 1 <agalecki at ...> writes:

Ben prepared getME(} function to extract various components of the model
fit
obtained using lme4.0 and new lme4.

Try
getME(lmf,"Zt")
getME(lmf,"A")
getME(lmf,"flist")

Andrzej

On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
<roby.joehanes at ...> wrote:
Hi:

I am trying to port pedigreemm to use the new lme4. However, the new lme4
is somewhat opaque to me and hence I need help. Specifically, how can I
extract the following terms:
lmf$FL$trms[[tn]]$Zt
lmf$FL$trms[[tn]]$A

The information lies within lmf <at> pp object, but it is too opaque to me to
fish anything out.

I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
should be replaced with optwrap and mkMerMod. Nevertheless, I think that
the lmer or glmer could use some refactoring to ease the calls.

I appreciate any help on these.


 A couple of questions:

1. how broadly are you using A?  Off-list, Doug Bates has commented to
me that defining A is relatively straightforward for LMMs but not necessarily
as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
that people are using it for [GN]LMMs as welll ...

2. I can't quite tell from your e-mail -- would it be useful to have
the stuff between the first optwrap() and the last mkMerMod abstracted
into a single (exposed) function?  For [GN]LMMs it should probably
also allow control of whether the preliminary "nAGQ=0" optimization
is done or not ...

(All comments are mine alone, not necessarily speaking for all lme4
authors ...)

Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From djsamperi at gmail.com  Tue Apr  3 06:32:40 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 3 Apr 2012 00:32:40 -0400
Subject: [R-sig-ME] Group selection and multi-level modeling
Message-ID: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>

The new E. O. Wilson book 'The Social Conquest of Earth" claims
that the long dismissed idea of group selection is gaining some
traction in part due to "multi-level modeling."

Can anyone point to work that aims to support this idea and
that employs the kind of models and software that is discussed
here on the SIG-ME list?

Thanks,
Dominick



From David.Duffy at qimr.edu.au  Tue Apr  3 07:16:53 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 3 Apr 2012 15:16:53 +1000 (EST)
Subject: [R-sig-ME] Group selection and multi-level modeling
In-Reply-To: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>
References: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1204031509540.1624@orpheus.qimr.edu.au>

On Tue, 3 Apr 2012, Dominick Samperi wrote:

> The new E. O. Wilson book 'The Social Conquest of Earth" claims
> that the long dismissed idea of group selection is gaining some
> traction in part due to "multi-level modeling."
>
> Can anyone point to work that aims to support this idea and
> that employs the kind of models and software that is discussed
> here on the SIG-ME list?

Like http://www.pnas.org/content/108/35/14426.full (uses MLwin)?
Are you thinking of multi-level selection, perhaps?  From my limited 
reading, group selection is still pooh-poohed by a lot of people in the 
field.

I am more familiar with attempts to model assortment and gene-environment 
covariation, which give rise to recursive systems that are more easily 
modelled in a structural equation type framework.

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From djsamperi at gmail.com  Tue Apr  3 14:57:53 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 3 Apr 2012 08:57:53 -0400
Subject: [R-sig-ME] Group selection and multi-level modeling
In-Reply-To: <Pine.LNX.4.64.1204031509540.1624@orpheus.qimr.edu.au>
References: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>
	<Pine.LNX.4.64.1204031509540.1624@orpheus.qimr.edu.au>
Message-ID: <CADUbQ5jbJZBhgUqP1kWHaMb8NY0QuiKr9c3ahDsaL-bJe+oBRQ@mail.gmail.com>

On Tue, Apr 3, 2012 at 1:16 AM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Tue, 3 Apr 2012, Dominick Samperi wrote:
>
>> The new E. O. Wilson book 'The Social Conquest of Earth" claims
>> that the long dismissed idea of group selection is gaining some
>> traction in part due to "multi-level modeling."
>>
>> Can anyone point to work that aims to support this idea and
>> that employs the kind of models and software that is discussed
>> here on the SIG-ME list?
>
>
> Like http://www.pnas.org/content/108/35/14426.full (uses MLwin)?
> Are you thinking of multi-level selection, perhaps? ?From my limited
> reading, group selection is still pooh-poohed by a lot of people in the
> field.

Thank you for the pointer David. This article seems to challenge the idea
by replacing group selection notions with environmental effects. I am
thinking of
"group selection" as multi-level selection, which would include the
environment (another level).

Wilson says the new understanding "opposes the theory of inclusive fitness
and replaces it with standard models of population genetics applied to
multiple levels of natural selection."

Perhaps the term "group selection" simply comes with too much baggage
and can be easily misinterpreted.

Dominick

> I am more familiar with attempts to model assortment and gene-environment
> covariation, which give rise to recursive systems that are more easily
> modelled in a structural equation type framework.
>
> Just 2c, David Duffy.
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v



From roby.joehanes at nih.gov  Tue Apr  3 19:53:41 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 3 Apr 2012 13:53:41 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <6C288834-4360-4B79-9781-2758C038664E@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
Message-ID: <85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>

Hi all:

I have created a patch for the latest lmer.R to accommodate calls by pedigreemm. I see that there is potentially a way to create a single "finalize" method instead of one for each lmer, glmer, and nlmer. I assume that nAGQ is 0 for lmer, correct? Or is it possible for glmer or nlmer to specify nAGQ=0?

Perhaps I should submit the patch into the patch database to see whether it is accepted or not. If it is accepted, then I can make the changes to pedigreemm accordingly.

Thank you,
Roby


On Apr 2, 2012, at 6:19 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi all:
>
> Just a follow up: It seems that some changes need to be made in the new lme4 so that the pedigreemm can be modified to use it. They are:
> 1. To allow the return of all necessary internal variables required for invoking the optimizer (especially rho plus devfun in one call), without invoking the optimizer itself. Right now I did two calls, the first to get the devfun, the second to get the rest. However, I cannot obtain rho in all cases.
> #lmerc$doFit <- FALSE # call lmer without pedigree and with doFit = FALSE
> l... <- list(...)
> lmerc$devFunOnly <- TRUE
> devFun <- eval(lmerc, parent.frame())
> lmerc$devFunOnly <- FALSE
> lmf <- eval(lmerc, parent.frame())
>
> 2. Some partitioning of Zt that allows duplicate level names for multiple random factors. That is, if random factors 1 and 2 (let's call them RF1 and RF2) share the same level-string, my current hack will not work. Perhaps someone can propose a better way. My current hack is as follows:
> Zt <- getME(lmf, "Zt")
> Zt <- Zt[rownames(Zt) %in% levels(getME(lmf, "flist")[[tn]]), ]
> (The original was: Zt <- lmf$FL$trms[[tn]]$Zt)
>
> Since I cannot get rho, I cannot realize the lmer_finalize or glmer_finalize. Any help is appreciated. I am stuck right now since I have installed the lme4 SVN version, but the pedigreemm package still assumes the CRAN version.
>
> Thank you,
> Roby
>
>
> On Apr 2, 2012, at 4:24 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:
>
> Hi Ben and Andrzej:
>
> Thank you for the info. I am trying to get pedigreemm to work with the new lme4 and I am now stuck on how to translate the following line:
> lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
>
> Because the matrix A is defined in getME method as:
> PR$Lambdat %*% PR$Zt
>
> I am still trying to figure the code out. I think we can do away with the A matrix since it is apparently not essential to the computation. I think the crux of the pedigreemm call to the underlying lme4 is in the following short lines:
>
>   pnms <- names(pedigree)
>   stopifnot(all(pnms %in% names(getME(lmf, "flist"))))
>   asgn <- attr(getME(lmf, "flist"), "assign")
>   for (i in seq_along(pedigree)) {
>       tn <- which(match(pnms[i], names(getME(lmf, "flist"))) == asgn)
>       if (length(tn) > 1)
>           stop("a pedigree factor must be associated with only one r.e. term")
>       Zt <- getME(lmf, "Zt")
>       relfac[[i]] <- relfactor(pedigree[[i]], rownames(Zt))
>       lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
>   }
>   ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize else lme4:::lmer_finalize, lmf)
>   ans <- new("pedigreemm", relfac = relfac, ans)
>
> Any help is appreciated.
>
> Thanks,
> Roby
>
>
> On Apr 2, 2012, at 4:17 PM, Ben Bolker wrote:
>
> Andrzej T Galecki 1 <agalecki at ...> writes:
>
> Ben prepared getME(} function to extract various components of the model
> fit
> obtained using lme4.0 and new lme4.
>
> Try
> getME(lmf,"Zt")
> getME(lmf,"A")
> getME(lmf,"flist")
>
> Andrzej
>
> On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
> <roby.joehanes at ...> wrote:
> Hi:
>
> I am trying to port pedigreemm to use the new lme4. However, the new lme4
> is somewhat opaque to me and hence I need help. Specifically, how can I
> extract the following terms:
> lmf$FL$trms[[tn]]$Zt
> lmf$FL$trms[[tn]]$A
>
> The information lies within lmf <at> pp object, but it is too opaque to me to
> fish anything out.
>
> I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
> should be replaced with optwrap and mkMerMod. Nevertheless, I think that
> the lmer or glmer could use some refactoring to ease the calls.
>
> I appreciate any help on these.
>
>
> A couple of questions:
>
> 1. how broadly are you using A?  Off-list, Doug Bates has commented to
> me that defining A is relatively straightforward for LMMs but not necessarily
> as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
> am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
> I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
> that people are using it for [GN]LMMs as welll ...
>
> 2. I can't quite tell from your e-mail -- would it be useful to have
> the stuff between the first optwrap() and the last mkMerMod abstracted
> into a single (exposed) function?  For [GN]LMMs it should probably
> also allow control of whether the preliminary "nAGQ=0" optimization
> is done or not ...
>
> (All comments are mine alone, not necessarily speaking for all lme4
> authors ...)
>
> Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-patch-for-pedigreemm.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/ea362fa5/attachment-0001.txt>

From M.FAIRBROTHER at bristol.ac.uk  Tue Apr  3 20:10:45 2012
From: M.FAIRBROTHER at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 3 Apr 2012 19:10:45 +0100
Subject: [R-sig-ME] Xj correlated with Uj?
Message-ID: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>

Dear list,

Code below simulates a simple two-level dataset, but where a level-2 covariate (Xj) is correlated with the level-2 random effects (Uj). In fitting the model, using the call below, the estimate for the fixed effect of Xj is substantially biased.

Is there a way to recover the correct parameter (1)? Presumably it's possible if one knows the variance-covariance matrix "s", but could it be done without that knowledge?

Any thoughts (particularly though not only suggested code) would be much appreciated.

- Malcolm


library(lme4); library(multicore); library(mnormt)
N <- 25
T <- 30
s <- matrix(c(2,0.7,0.7,3), ncol=2)
dgp <- function(N, T, s) {
	dat <- data.frame(group=1:N, rmnorm(n=N, varcov=s))[rep(1:N,each=T),]
	names(dat)[2:3] <- c("Xj", "Uj")
	dat$y <- 1 + dat$Xj + dat$Uj + rnorm(nrow(dat))
	dat
	}
res1 <- do.call("rbind", mclapply(1:100, function(yy) fixef(lmer(y ~ Xj + (1 | group), dgp(N=N, T=T, s=s)))))
colMeans(res1)



From roby.joehanes at nih.gov  Tue Apr  3 21:04:54 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 3 Apr 2012 15:04:54 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
Message-ID: <E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>

Hi all:

Attached please find the patch to pedigreemm toward using the new lme4 (with the patch I submitted earlier). However, the patch does NOT work with the following error:
Error in function (value)  : Field "Zt" is read-only

I believe the error is thrown at this statement:
lmf$rho$pp$Zt <- relfac[[i]] %*% Zt

I have no idea how to proceed. Any help is appreciated.

Thank you,
Roby

On Apr 3, 2012, at 1:53 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

Hi all:

I have created a patch for the latest lmer.R to accommodate calls by pedigreemm. I see that there is potentially a way to create a single "finalize" method instead of one for each lmer, glmer, and nlmer. I assume that nAGQ is 0 for lmer, correct? Or is it possible for glmer or nlmer to specify nAGQ=0?

Perhaps I should submit the patch into the patch database to see whether it is accepted or not. If it is accepted, then I can make the changes to pedigreemm accordingly.

Thank you,
Roby


On Apr 2, 2012, at 6:19 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

Hi all:

Just a follow up: It seems that some changes need to be made in the new lme4 so that the pedigreemm can be modified to use it. They are:
1. To allow the return of all necessary internal variables required for invoking the optimizer (especially rho plus devfun in one call), without invoking the optimizer itself. Right now I did two calls, the first to get the devfun, the second to get the rest. However, I cannot obtain rho in all cases.
#lmerc$doFit <- FALSE # call lmer without pedigree and with doFit = FALSE
l... <- list(...)
lmerc$devFunOnly <- TRUE
devFun <- eval(lmerc, parent.frame())
lmerc$devFunOnly <- FALSE
lmf <- eval(lmerc, parent.frame())

2. Some partitioning of Zt that allows duplicate level names for multiple random factors. That is, if random factors 1 and 2 (let's call them RF1 and RF2) share the same level-string, my current hack will not work. Perhaps someone can propose a better way. My current hack is as follows:
Zt <- getME(lmf, "Zt")
Zt <- Zt[rownames(Zt) %in% levels(getME(lmf, "flist")[[tn]]), ]
(The original was: Zt <- lmf$FL$trms[[tn]]$Zt)

Since I cannot get rho, I cannot realize the lmer_finalize or glmer_finalize. Any help is appreciated. I am stuck right now since I have installed the lme4 SVN version, but the pedigreemm package still assumes the CRAN version.

Thank you,
Roby

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pedigreemm-patch-svnlme4-v1-notworking.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/a0322610/attachment-0001.txt>

From bbolker at gmail.com  Wed Apr  4 00:52:18 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Apr 2012 22:52:18 +0000 (UTC)
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
	<E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>
Message-ID: <loom.20120404T004614-494@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> 
> Hi all:
> 
> Attached please find the patch to pedigreemm toward using the new lme4 (with
the patch I submitted
> earlier). However, the patch does NOT work with the following error:
> Error in function (value)  : Field "Zt" is read-only
> 
> I believe the error is thrown at this statement:
> lmf$rho$pp$Zt <- relfac[[i]] %*% Zt
> 
> I have no idea how to proceed. Any help is appreciated.
> 
> Thank you,
> Roby

  I will take a look at this as soon as I can.
  Setting components of objects in new-lme4 is tricky because
the objects are defined as reference classes, so that messing
with their internals can disrupt existing objects that they
have been copied from (!!) 

 Abstracting the equivalent of "mer_finalize" is, I think, a good
idea.  Yes, nAGQ=0 is allowed for [NG]LMMs ... the idea being (I think)
that for a well-behaved but very large problem one could save time
by just doing the "zeroth-order" fit (even faster than nAGQ=1,
which corresponds to Laplace approximation)

  Ben Bolker



From roby.joehanes at nih.gov  Wed Apr  4 01:06:49 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 3 Apr 2012 19:06:49 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <loom.20120404T004614-494@post.gmane.org>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
	<E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>
	<loom.20120404T004614-494@post.gmane.org>
Message-ID: <5043C756-EA38-45C8-AA87-65F28424AE57@nih.gov>

Hi Ben and everyone:


I made some semi-working patch here (attached). I tried the examples mentioned in the paper of Vazquez, et al. (J. Anim. Sci. 2010, 88:497-504) and got the first example (fm1) working and the result is the same as the older one:
milk <- within(milk, sdMilk <- milk / sd(milk))
fm1 <- pedigreemm(sdMilk ~ lact + log(dim) + (1|id) + (1|herd), data=milk, pedigree=list(id=pedCowsR))

Result:
----
Linear mixed model fit by REML ['lmerMod']
Formula: sdMilk ~ lact + log(dim) + (1 | id) + (1 | herd)
   Data: milk

REML criterion at convergence: 8384.794

Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 0.2780   0.5273
 herd     (Intercept) 0.2078   0.4559
 Residual             0.4833   0.6952
Number of obs: 3397, groups: id, 1359; herd, 57

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.70371    0.26854   6.344
lact        -0.10779    0.01232  -8.747
log(dim)     0.73594    0.04380  16.804

Correlation of Fixed Effects:
         (Intr) lact
lact     -0.296
log(dim) -0.960  0.221
----

However, when I tried the second example (fm2) below, I got an error.
milk <- within(milk, sdMilk <- milk / sd(milk))
milk <- within(milk, idPE <- id)
fm2 <- pedigreemm(sdMilk ~ lact + (1|id) + log(dim) + (1|idPE) + (1|herd), data=milk, pedigree=list(id=pedCows))

The error message is:
Error in .local(x, ...) : previous CHOLMOD factorization was unsuccessful
In addition: Warning message:
In .local(x, ...) :
  Cholmod warning 'not positive definite' at file ../Cholesky/t_cholmod_rowfac.c, line 432

I could not get the third example to work either:
fm3 <- pedigreemm(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="poisson")

The error message is:
Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite

The fourth example also does not work:
fm4 <- pedigreemm(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="binomial"(link="probit"))

Error message:
Error in FUN(1:3[[1L]], ...) :
  step factor reduced below 0.001 without reducing pwrss

I think I messed up somewhere in the internals and got these errors.

Thanks,
Roby



On Apr 3, 2012, at 6:52 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
>
>>
>> Hi all:
>>
>> Attached please find the patch to pedigreemm toward using the new lme4 (with
> the patch I submitted
>> earlier). However, the patch does NOT work with the following error:
>> Error in function (value)  : Field "Zt" is read-only
>>
>> I believe the error is thrown at this statement:
>> lmf$rho$pp$Zt <- relfac[[i]] %*% Zt
>>
>> I have no idea how to proceed. Any help is appreciated.
>>
>> Thank you,
>> Roby
>
>  I will take a look at this as soon as I can.
>  Setting components of objects in new-lme4 is tricky because
> the objects are defined as reference classes, so that messing
> with their internals can disrupt existing objects that they
> have been copied from (!!)
>
> Abstracting the equivalent of "mer_finalize" is, I think, a good
> idea.  Yes, nAGQ=0 is allowed for [NG]LMMs ... the idea being (I think)
> that for a well-behaved but very large problem one could save time
> by just doing the "zeroth-order" fit (even faster than nAGQ=1,
> which corresponds to Laplace approximation)
>
>  Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-patch-for-pedigreemm.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/5d884ed4/attachment-0002.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pedigreemm-patch-v2.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/5d884ed4/attachment-0003.txt>

From markus.jantti at iki.fi  Wed Apr  4 11:17:45 2012
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Wed, 04 Apr 2012 11:17:45 +0200
Subject: [R-sig-ME] Xj correlated with Uj?
In-Reply-To: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
References: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
Message-ID: <4F7C11B9.2010503@iki.fi>

On 04/03/2012 08:10 PM, Malcolm Fairbrother wrote:
> Dear list,
>
> Code below simulates a simple two-level dataset, but where a level-2 covariate (Xj) is correlated with the level-2 random effects (Uj). In fitting the model, using the call below, the estimate for the fixed effect of Xj is substantially biased.
>
> Is there a way to recover the correct parameter (1)? Presumably it's possible if one knows the variance-covariance matrix "s", but could it be done without that knowledge?
>
> Any thoughts (particularly though not only suggested code) would be much appreciated.
>

In an ordinary least-squares setting, this is the school-book example of a 
violation of the assumption that the error term in the regression is 
uncorrelated with the covariate.

To estimate the parameters consistently, you would require and instrument, a 
variable that is correlated with Xj but not Uj. Whether instrumental-variable 
estimation has been implemented in a multi-level setting I can not say, but it 
would probably be possible to do this "manually" by estimating an IV-regression 
with no regard to multi-level, using the residuals from that to estimate the 
variance components, then use the implied variance structure to transform the 
original data and re-estimate the IV-regression. This presupposes the existence 
of an instrument however, which is usually a big problem.

Best
Markus

> - Malcolm
>
>
> library(lme4); library(multicore); library(mnormt)
> N<- 25
> T<- 30
> s<- matrix(c(2,0.7,0.7,3), ncol=2)
> dgp<- function(N, T, s) {
> 	dat<- data.frame(group=1:N, rmnorm(n=N, varcov=s))[rep(1:N,each=T),]
> 	names(dat)[2:3]<- c("Xj", "Uj")
> 	dat$y<- 1 + dat$Xj + dat$Uj + rnorm(nrow(dat))
> 	dat
> 	}
> res1<- do.call("rbind", mclapply(1:100, function(yy) fixef(lmer(y ~ Xj + (1 | group), dgp(N=N, T=T, s=s)))))
> colMeans(res1)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Markus Jantti
Professor of Economics
Swedish Institute for Social Research
Stockholm University



From rstuff.miles at gmail.com  Wed Apr  4 14:08:28 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Wed, 4 Apr 2012 08:08:28 -0400
Subject: [R-sig-ME] Xj correlated with Uj?
In-Reply-To: <4F7C11B9.2010503@iki.fi>
References: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
	<4F7C11B9.2010503@iki.fi>
Message-ID: <2B79B7BD-6B2C-4647-ACB6-AB2722D47FED@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/809b986f/attachment-0001.pl>

From roby.joehanes at nih.gov  Wed Apr  4 18:50:23 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Wed, 4 Apr 2012 12:50:23 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <5043C756-EA38-45C8-AA87-65F28424AE57@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
	<E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>
	<loom.20120404T004614-494@post.gmane.org>
	<5043C756-EA38-45C8-AA87-65F28424AE57@nih.gov>
Message-ID: <5F4DDA81-94AC-40D6-93E9-2E8A6F079DF9@nih.gov>

Hi all:

Please find the updated patch. I think I got examples 1 and 2 to work (see below) and the numbers do match. However, I still cannot get examples 3 and 4 to work. Apparently, if I run glmer instead of pedigreemm, I got the same error. Namely, both of these statements:
fm3 <- pedigreemm(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="poisson")
fm3x <- glmer(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, family="poisson")

yielded the same error: Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite

And both of these:
fm4 <- pedigreemm(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="binomial"(link="probit"))
fm4x <- glmer(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, family="binomial"(link="probit"))

also yielded the same error: Error in FUN(1:3[[1L]], ...) :   step factor reduced below 0.001 without reducing pwrss

So, I think the problem lies with the new lme4 since the older lme4 can run fm3x and fm4x just fine. I am just wondering if anyone can give me pointers to fix these problems. I used the SVN version 1694, which I believe to be the latest at the time of this writing.

Thank you,
Roby


On Apr 3, 2012, at 7:06 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi Ben and everyone:
>
>
> I made some semi-working patch here (attached). I tried the examples mentioned in the paper of Vazquez, et al. (J. Anim. Sci. 2010, 88:497-504) and got the first example (fm1) working and the result is the same as the older one:
> milk <- within(milk, sdMilk <- milk / sd(milk))
> fm1 <- pedigreemm(sdMilk ~ lact + log(dim) + (1|id) + (1|herd), data=milk, pedigree=list(id=pedCowsR))
>
> Result:
> ----
> Linear mixed model fit by REML ['lmerMod']
> Formula: sdMilk ~ lact + log(dim) + (1 | id) + (1 | herd)
>   Data: milk
>
> REML criterion at convergence: 8384.794
>
> Random effects:
> Groups   Name        Variance Std.Dev.
> id       (Intercept) 0.2780   0.5273
> herd     (Intercept) 0.2078   0.4559
> Residual             0.4833   0.6952
> Number of obs: 3397, groups: id, 1359; herd, 57
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  1.70371    0.26854   6.344
> lact        -0.10779    0.01232  -8.747
> log(dim)     0.73594    0.04380  16.804
>
> Correlation of Fixed Effects:
>         (Intr) lact
> lact     -0.296
> log(dim) -0.960  0.221
> ----
>
> However, when I tried the second example (fm2) below, I got an error.
> milk <- within(milk, sdMilk <- milk / sd(milk))
> milk <- within(milk, idPE <- id)
> fm2 <- pedigreemm(sdMilk ~ lact + (1|id) + log(dim) + (1|idPE) + (1|herd), data=milk, pedigree=list(id=pedCows))
>
> The error message is:
> Error in .local(x, ...) : previous CHOLMOD factorization was unsuccessful
> In addition: Warning message:
> In .local(x, ...) :
>  Cholmod warning 'not positive definite' at file ../Cholesky/t_cholmod_rowfac.c, line 432
>
> I could not get the third example to work either:
> fm3 <- pedigreemm(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="poisson")
>
> The error message is:
> Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite
>
> The fourth example also does not work:
> fm4 <- pedigreemm(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="binomial"(link="probit"))
>
> Error message:
> Error in FUN(1:3[[1L]], ...) :
>  step factor reduced below 0.001 without reducing pwrss
>
> I think I messed up somewhere in the internals and got these errors.
>
> Thanks,
> Roby

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-patch-for-pedigreemm-v2.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/a2e46e16/attachment-0002.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pedigreemm-patch-v3.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/a2e46e16/attachment-0003.txt>

From nyaga.nyawira at gmail.com  Wed Apr  4 19:08:10 2012
From: nyaga.nyawira at gmail.com (victoriah nyawira)
Date: Wed, 4 Apr 2012 19:08:10 +0200
Subject: [R-sig-ME] Problem with lmer
Message-ID: <CAJ5izBRNtYq-R__cXu0w_qYMUMTiwg6c+Von8oiE=wM9WUcGLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/6ee39eed/attachment-0001.pl>

From bbolker at gmail.com  Wed Apr  4 22:18:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Apr 2012 20:18:10 +0000 (UTC)
Subject: [R-sig-ME] Problem with lmer
References: <CAJ5izBRNtYq-R@mail.gmail.com>
Message-ID: <loom.20120404T221517-247@post.gmane.org>

victoriah nyawira <nyaga.nyawira at ...> writes:

> Am running this code
> fixdslope <- lmer(score ~ logtime + (1 | id), data)
> but I get this error:
> Error in asMethod(object) : could not find function ".M.classEnv"
> The code ran in windows 7, R 1.14.2, but am currently using OpenSUSE 12.1,
> with the latest R 2.15.0.


 [snip]

  That's a rather odd error message.

.M.classEnv appears to be an internal Matrix function (e.g.
see [broken URL!]

https://r-forge.r-project.org/scm/viewvc.php/pkg/Matrix/R/zzz.R?
  root=matrix&r1=2765&r2=2764&pathrev=2765&diff_format=s

).  Have you run update.packages() [and/or update.packages(checkBuilt=TRUE),
and/or install.packages("Matrix")]?  What are the results of 
sessionInfo()?  Can you provide a reproducible
example?

   Ben Bolker



From jude.girard at gmail.com  Wed Apr  4 22:54:21 2012
From: jude.girard at gmail.com (jude girard)
Date: Wed, 4 Apr 2012 16:54:21 -0400
Subject: [R-sig-ME] graphing fixed effects from mixed effects model
Message-ID: <CAJ6voQFVDaun=PkcDK5c6B25zeJCe=x5oo6Tv1tdUWPRysKNRw@mail.gmail.com>

I feel like this must be a common problem, but I can?t find any
information on how to graph the results of my mixed effects model.

I am trying to predict insect biomass from weed cover and month.  I
have 9 pairs of organic and conventional fields; each field has a
unique site id.  In each field, insect biomass weed cover were
measured in june and july.  So my model is

model<lme(biomass~weed.cover+month, data=weeds, random=~1|pair/site)

I would like to plot a graph showing the raw data, together with two
lines, one showing the predicted relationship between biomass and weed
cover in June and one showing the predicted relationship in July.  I?m
not interested in showing the slopes for the individual sites; this is
included in the model only to account for the longitudinal nature of
the design, not because I am interested in this variation.

So, is there some way to calculate and average slope across sites in
each month, or do I have to pick one site to use as a reference and
just graph the result for that site?  And if so, are there any
guidelines for which site to use as the reference?

Thanks for your help!

Jude Girard


>summary(model)
Linear mixed-effects model fit by REML
 Data: weeds
       AIC      BIC    logLik
  65.07516 73.86958 -26.53758

Random effects:
 Formula: ~1 | pair
         (Intercept)
StdDev: 3.967212e-05

 Formula: ~1 | site %in% pair
        (Intercept)  Residual
StdDev:   0.1402752 0.4805598

Fixed effects: biomass ~ weed.cover +      month
                                 Value Std.Error DF    t-value p-value
(Intercept)                 -2.1694761 0.1263224 15 -17.174124  0.0000
weed.cover 0.2168042 0.3158289 15   0.686461  0.5029
monthJuly             0.4870690 0.2069135 15   2.353974  0.0326
 Correlation:
                            (Intr) a((./1
weed.cover -0.277
monthJuly            -0.351 -0.618

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.5283318 -0.5597323 -0.2046855  0.7638652  1.9944551

Number of Observations: 35
Number of Groups:
          pair site %in% pair
             9             18

> anova(model)
                            numDF denDF  F-value p-value
(Intercept)                     1    15 443.8127  <.0001
weed.cover     1    15   7.4109  0.0157
month                  1    15   5.5412  0.0326



From bbolker at gmail.com  Wed Apr  4 23:25:02 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Apr 2012 21:25:02 +0000 (UTC)
Subject: [R-sig-ME] graphing fixed effects from mixed effects model
References: <CAJ6voQFVDaun=PkcDK5c6B25zeJCe=x5oo6Tv1tdUWPRysKNRw@mail.gmail.com>
Message-ID: <loom.20120404T231826-612@post.gmane.org>

jude girard <jude.girard at ...> writes:

> 
> I feel like this must be a common problem, but I can?t find any
> information on how to graph the results of my mixed effects model.
> 
> I am trying to predict insect biomass from weed cover and month.  I
> have 9 pairs of organic and conventional fields; each field has a
> unique site id.  In each field, insect biomass weed cover were
> measured in june and july.  So my model is
> 
> model<lme(biomass~weed.cover+month, data=weeds, random=~1|pair/site)
> 
> I would like to plot a graph showing the raw data, together with two
> lines, one showing the predicted relationship between biomass and weed
> cover in June and one showing the predicted relationship in July.  I?m
> not interested in showing the slopes for the individual sites; this is
> included in the model only to account for the longitudinal nature of
> the design, not because I am interested in this variation.
> 
> So, is there some way to calculate and average slope across sites in
> each month, or do I have to pick one site to use as a reference and
> just graph the result for that site?  And if so, are there any
> guidelines for which site to use as the reference?
> 

   I would do something like this:

predframe <- with(weeds,expand.grid(month=levels(month),
                weed.cover=seq(min(weed.cover),max(weed.cover),25))
predframe$biomass <- predict.lme(model,level=0,newdata=predframe)
then I would be tempted to use ggplot:

library(ggplot2)
ggplot(weeds,aes(x=weed.cover,y=biomass,colour=month))+
   geom_point()+
   geom_line(data=predframe)

  This plots the data and superimposes the predicted values.

You might also get most of the way there via

  plot(augPred(model,level=0))

the 'level' argument specifies that you want to predict at
the population level (i.e. ignoring site-to-site variation)



From M.FAIRBROTHER at bristol.ac.uk  Thu Apr  5 14:33:35 2012
From: M.FAIRBROTHER at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 5 Apr 2012 13:33:35 +0100
Subject: [R-sig-ME] Xj correlated with Uj?
In-Reply-To: <2B79B7BD-6B2C-4647-ACB6-AB2722D47FED@gmail.com>
References: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
	<4F7C11B9.2010503@iki.fi>
	<2B79B7BD-6B2C-4647-ACB6-AB2722D47FED@gmail.com>
Message-ID: <A9597263-8FDA-4C38-BCED-9EEBB694FC45@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/42abc70f/attachment-0001.pl>

From julierushmore at gmail.com  Thu Apr  5 16:27:53 2012
From: julierushmore at gmail.com (Julie Rushmore)
Date: Thu, 5 Apr 2012 10:27:53 -0400
Subject: [R-sig-ME] MCMCglmm warning: observations with zero weight not used
 for calculating dispersion
Message-ID: <CAMOdrumrechT=v-b6G=Wk2XzoZ4NUnTmRpbYjyE=b-0UkOt87A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/017983f3/attachment-0001.pl>

From j.hadfield at ed.ac.uk  Thu Apr  5 16:49:37 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 05 Apr 2012 15:49:37 +0100
Subject: [R-sig-ME] MCMCglmm warning: observations with zero weight not
 used for calculating dispersion
In-Reply-To: <CAMOdrumrechT=v-b6G=Wk2XzoZ4NUnTmRpbYjyE=b-0UkOt87A@mail.gmail.com>
References: <CAMOdrumrechT=v-b6G=Wk2XzoZ4NUnTmRpbYjyE=b-0UkOt87A@mail.gmail.com>
Message-ID: <20120405154937.12911f3cugw7uccg@www.staffmail.ed.ac.uk>

Hi,

This is warning in from glm which MCMCglmm uses to get starting  
values. It is not necessarily anything to worry about, but it may  
indicate that the data are set up wrong. I think the most likely  
reason is that Suc_5+Fa_5 = 0 for some observations.

Cheers,

Jarrod


Quoting Julie Rushmore <julierushmore at gmail.com> on Thu, 5 Apr 2012  
10:27:53 -0400:

> Hi all,
>
> I am modeling association patterns among a community of chimpanzees using a
> logistic mixed effects model in the MCMCglmm package. When I run my model,
> I get the following warning message:
>
> Warning message:
> In summary.glm(glm(cbind(MCMC_y, MCMC_y.additional) ~ 1, family =
> "quasibinomial",  :
>   observations with zero weight not used for calculating dispersion
>
> I can't tell if this warning is related to zero-inflation, overdispersion,
> or something else. Also, I'm not sure 1) if this is a serious concern, or
> 2) how to deal with this in the MCMCglmm framework.
>
> Below is the code for my model:
>
> #priors:
> priors1<- list(R = list(V = 1, nu = 0.002), G = list(G1 = list(V =1, nu =
> 0.002), G2 = list(V =1, nu = 0.002)))
> #model:
> m1<- MCMCglmm(cbind(Suc_5,Fa_5)~
> Related+Sex.Estrus+FamilyDiff+RankDiffNew+EstrusAd3*Age, random =
> ~idv(mult.memb(~Actor1+Actor2))+PID, family="multinomial2", data=dat,
> verbose = FALSE, prior=priors1, saveX=TRUE, saveZ=TRUE, pr=TRUE)
>
> *The response variable uses Suc_5 (two IDs observed together) and Fa_5 (two
> IDs not observed together) to calculate pairwise association indices.
> *The fixed effect predictor variables are all categorical and measure
> pair-wise attributes about two individuals in a pair (with the exception of
> EstrusAd3, which is a temporal variable - the number of females in
> estrus/month).
> *Random effects include animal ID (i.e., the multi-member component) and
> pair ID (PID).
>
> Thanks for your feedback!
> Julie
>
> --
> Julie Rushmore
> DVM/PhD Candidate
> Odum School of Ecology
> University of Georgia
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From helixed2 at yahoo.com  Thu Apr  5 23:48:37 2012
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Thu, 5 Apr 2012 14:48:37 -0700 (PDT)
Subject: [R-sig-ME] Does glm (and glmer) no longer vectorize proportions
	when estimating a binomial GLM(M)?
Message-ID: <1333662517.15306.YahooMailNeo@web161805.mail.bf1.yahoo.com>

A while ago, I posted this message to the listserv:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006717.html

Specifically, I had noted that this code:

smoking.aggregated <- glmer (cbind(smoking observations, total observations) ~ AGE + (1|Individual), family = binomial, data = aggregated)

generates the same estimates as this code, which simply uses an unaggregated vector of data with a binary outcome variable instead of the proportions via cbind: 


smoking.unaggregated <- glmer (smoking ~ AGE + (1|Individual), family = binomial, data = unaggregated)


In response, Doug Bates described the underlying code and functions as a bit of a "hack" -- see: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006724.html

Well, I no longer get the same estimates when using the two above lines of code, which along with Doug's comment makes me wonder if subsequent versions of the base and lme4 packages now treat these models differently.

Thanks, all.



From ramos.grad.student at gmail.com  Fri Apr  6 01:09:08 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 5 Apr 2012 16:09:08 -0700
Subject: [R-sig-ME] lme4.0
Message-ID: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/d3c412be/attachment-0001.pl>

From Mike.Lawrence at dal.ca  Fri Apr  6 02:40:51 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Thu, 5 Apr 2012 21:40:51 -0300
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
Message-ID: <CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>

I believe that this isn't about what version of R you have, but about
the fact that there is no such package as "lme4.0" on CRAN at all yet.
The "new" lme4 hasn't been released to CRAN yet, it's solely on
R-Forge, so when you install "lme4" from CRAN, you're getting the
"old" version. When the new lme4 is pushed to cran, I understand that
the old version will be pushed as a new package called "lme4.0".




On Thu, Apr 5, 2012 at 8:09 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> Hi all,
>
> ?Apparently lme4.0 it is still not available for lastest R
>
> install.packages("lme4.0")
> Installing package(s) into
> ?/Library/Frameworks/R.framework/Versions/2.15/Resources/library?
> (as ?lib? is unspecified)
> Warning in install.packages :
> ?package ?lme4.0? is not available (for R version 2.15.0)
>
> so, the only solution is to re-install an older version of R ? That's why
> I'm always worried of using the latest version of it ...
>
> Many thanks,
>
> apr.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ramos.grad.student at gmail.com  Fri Apr  6 02:54:13 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 5 Apr 2012 17:54:13 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9tdk6_2Y-DN2vpZPrG-w2jUHRj4cXuu5eXcFg4pBF0n_w@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<CAHawB9tdk6_2Y-DN2vpZPrG-w2jUHRj4cXuu5eXcFg4pBF0n_w@mail.gmail.com>
Message-ID: <CAHawB9u3tbf2HJJN-HA0e8Ny1DVscFS+jx4T42VPP6=ARXvkBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/9976b408/attachment-0001.pl>

From j.deikumah2 at uq.edu.au  Fri Apr  6 03:29:45 2012
From: j.deikumah2 at uq.edu.au (Justus Deikumah)
Date: Fri, 6 Apr 2012 01:29:45 +0000
Subject: [R-sig-ME] looping with multiple response variables lme4
Message-ID: <74C378BE307E5D49898BABE3CCFD29A3CF03@uqexmdb2.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120406/82807a55/attachment-0001.pl>

From bbolker at gmail.com  Fri Apr  6 03:57:06 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Apr 2012 01:57:06 +0000 (UTC)
Subject: [R-sig-ME] lme4.0
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
Message-ID: <loom.20120406T035618-491@post.gmane.org>

Mike Lawrence <Mike.Lawrence at ...> writes:

> 
> I believe that this isn't about what version of R you have, but about
> the fact that there is no such package as "lme4.0" on CRAN at all yet.
> The "new" lme4 hasn't been released to CRAN yet, it's solely on
> R-Forge, so when you install "lme4" from CRAN, you're getting the
> "old" version. When the new lme4 is pushed to cran, I understand that
> the old version will be pushed as a new package called "lme4.0".

  Correct.  If you want lme4.0, try

install.packages("lme4.0",repos="http://r-forge.r-project.org")

 also see

  http://lme4.r-forge.r-project.org/



From renaud.lancelot at cirad.fr  Fri Apr  6 07:55:13 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Fri, 06 Apr 2012 07:55:13 +0200
Subject: [R-sig-ME] lme4.0
In-Reply-To: <loom.20120406T035618-491@post.gmane.org>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
Message-ID: <4F7E8541.2040207@cirad.fr>

Well...

 > install.packages("lme4.0",repos="http://r-forge.r-project.org")
Installation d(es) package(s) dans ?C:/R/RLIBS?
(car ?lib? n'est pas sp?cifi?)
Message d'avis :
package ?lme4.0? is not available (for R version 2.15.0)

lme4.0 seems to be available only from
http://lme4.r-forge.r-project.org/repos/src/contrib/

So it should be installed from source:

install.packages("lme4.0", repos="http://r-forge.r-project.org", 
type="source")

which works fine for me.


However, I now have on my system:

lme4
lme4a
lme4b
lme4.0
lme4Eigen

This is really confusing, even for lme4xxx aficionados!

All the best,

Renaud






-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From ramos.grad.student at gmail.com  Fri Apr  6 08:05:17 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 5 Apr 2012 23:05:17 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F7E8541.2040207@cirad.fr>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
Message-ID: <CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/86db865d/attachment-0001.pl>

From jwiley.psych at gmail.com  Fri Apr  6 09:01:28 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 6 Apr 2012 00:01:28 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
Message-ID: <CANz9Z_+tspNxQe=4NXcaiz+wh_Nd4yUdZx5svjbTBWmHqN+S_A@mail.gmail.com>

To install from source, you need to have the necessary compilers
installed on your system.  lme4 (any incarnation) is not a pure R
implementation.

On Thu, Apr 5, 2012 at 11:05 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> it doesn't work either though I am geting a weird error message:
>
>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
> type="source")
> Installing package(s) into
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
> (as ?lib? is unspecified)
> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
> opened URL
> ==================================================
> downloaded 1013 Kb
>
> * installing *source* package ?lme4.0? ...
> ** libs
> *** arch - i386
> sh: make: command not found

You should not be getting this (make) by itself, but here is a link to
the webpage describing what that command utility is:
http://www.gnu.org/software/make/manual/make.html

It is standard for software development.  When you install packages
with defaults, R installs binaries which are precompiled for systems
like yours (OS, architecture 32/64 bit, etc.).  When you use 'type =
"source"', you are attempting to install from the raw source code
which requires your system to be able to compile the binaries itself.
If you do not have the software required for that, you will
understandably get errors.


> ERROR: compilation failed for package ?lme4.0?
> * removing
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
> Warning in install.packages :
> ?installation of package ?lme4.0? had non-zero exit status

zero exit status means no problems, non-zero means something went
wrong.  If you want, it is pretty straightforward to get all the tools
you need.  *nix tends to come distributed with the appropriate
compilers or you can apt get or use the package manager to get what
you need, not sure about Mac, on Windows it is easy to use the Rtools
distributed now on CRAN.  Anyway, here is the R manual describing how
to go about building from source:
http://cran.r-project.org/doc/manuals/R-admin.html

HTH,

Josh

>
> The downloaded packages are in
> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>
>
>
>
>
>
> On Thu, Apr 5, 2012 at 10:55 PM, lancelot <renaud.lancelot at cirad.fr> wrote:
>
>> Well...
>>
>>
>> > install.packages("lme4.0",**repos="http://r-forge.r-**project.org<http://r-forge.r-project.org>
>> ")
>> Installation d(es) package(s) dans ?C:/R/RLIBS?
>> (car ?lib? n'est pas sp?cifi?)
>> Message d'avis :
>>
>> package ?lme4.0? is not available (for R version 2.15.0)
>>
>> lme4.0 seems to be available only from
>> http://lme4.r-forge.r-project.**org/repos/src/contrib/<http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>
>> So it should be installed from source:
>>
>> install.packages("lme4.0", repos="http://r-forge.r-**project.org<http://r-forge.r-project.org>",
>> type="source")
>>
>> which works fine for me.
>>
>>
>> However, I now have on my system:
>>
>> lme4
>> lme4a
>> lme4b
>> lme4.0
>> lme4Eigen
>>
>> This is really confusing, even for lme4xxx aficionados!
>>
>> All the best,
>>
>> Renaud
>>
>>
>>
>>
>>
>>
>> --
>> Renaud Lancelot
>> EDENext Project, coordinator: http://www.edenext.eu/
>>
>> CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>> F34398 Montpellier
>>
>> Tel. ?+33 4 67 59 37 17 ?- ?Fax ?+33 4 67 59 37 98
>> Secr. +33 4 67 59 37 37 ?- Cell. +33 6 77 52 08 69
>>
>>
>> ______________________________**_________________
>> R-sig-mixed-models at r-project.**org <R-sig-mixed-models at r-project.org>mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Fri Apr  6 13:34:23 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 06 Apr 2012 07:34:23 -0400
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
Message-ID: <4F7ED4BF.2070801@gmail.com>

  Things are discombobulated on R-forge, it looks like (as is not so
unusual these days) -- perhaps due to the transition to R 2.15.

  We've tried to put information at http://lme4.r-forge.r-project.org
about current versions etc..

  For right now, there are only three versions you should think about at
all:

  lme4 on CRAN "0.999375-42"
  lme4 on r-forge -- development version, supersedes lme4Eigen and
(eventually) CRAN-lme4
  lme4.0 on r-forge: backward compatibility branch

  Ben Bolker


On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
> it doesn't work either though I am geting a weird error message:
> 
>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
> type="source")
> Installing package(s) into
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
> (as ?lib? is unspecified)
> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
> opened URL
> ==================================================
> downloaded 1013 Kb
> 
> * installing *source* package ?lme4.0? ...
> ** libs
> *** arch - i386
> sh: make: command not found
> ERROR: compilation failed for package ?lme4.0?
> * removing
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
> Warning in install.packages :
>   installation of package ?lme4.0? had non-zero exit status
> 
> The downloaded packages are in
> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
> 
> 
> 
> 
> 
> 
> On Thu, Apr 5, 2012 at 10:55 PM, lancelot <renaud.lancelot at cirad.fr
> <mailto:renaud.lancelot at cirad.fr>> wrote:
> 
>     Well...
> 
> 
>     > install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>     <http://r-forge.r-project.org>")
>     Installation d(es) package(s) dans ?C:/R/RLIBS?
>     (car ?lib? n'est pas sp?cifi?)
>     Message d'avis :
> 
>     package ?lme4.0? is not available (for R version 2.15.0)
> 
>     lme4.0 seems to be available only from
>     http://lme4.r-forge.r-project.__org/repos/src/contrib/
>     <http://lme4.r-forge.r-project.org/repos/src/contrib/>
> 
>     So it should be installed from source:
> 
>     install.packages("lme4.0", repos="http://r-forge.r-__project.org
>     <http://r-forge.r-project.org>", type="source")
> 
>     which works fine for me.
> 
> 
>     However, I now have on my system:
> 
>     lme4
>     lme4a
>     lme4b
>     lme4.0
>     lme4Eigen
> 
>     This is really confusing, even for lme4xxx aficionados!
> 
>     All the best,
> 
>     Renaud
> 
> 
> 
> 
> 
> 
>     -- 
>     Renaud Lancelot
>     EDENext Project, coordinator: http://www.edenext.eu/
> 
>     CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>     F34398 Montpellier
> 
>     Tel.  +33 4 67 59 37 17 <tel:%2B33%204%2067%2059%2037%2017>  -  Fax
>      +33 4 67 59 37 98 <tel:%2B33%204%2067%2059%2037%2098>
>     Secr. +33 4 67 59 37 37 <tel:%2B33%204%2067%2059%2037%2037>  - Cell.
>     +33 6 77 52 08 69 <tel:%2B33%206%2077%2052%2008%2069>
> 
> 
>     _________________________________________________
>     R-sig-mixed-models at r-project.__org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
>



From reinhold.kliegl at gmail.com  Fri Apr  6 13:44:51 2012
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 6 Apr 2012 13:44:51 +0200
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F7ED4BF.2070801@gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com>
Message-ID: <CAG+WrEwnCWqp2geyLCcTcbGJD_4vY+JtCB1YcXMwXgw3xUoAQg@mail.gmail.com>

"-- perhaps due to the transition to R 2.15"
This is my impression, too.  Necessary packages are not always
immediately available after a transition (at least for Mac OS X). I
think I had a similar problem as described in this thread about a week
ago. After updating all packages today problems were gone. It was not
a systematic test though.
Reinhold Kliegl

On Fri, Apr 6, 2012 at 1:34 PM, Ben Bolker <bbolker at gmail.com> wrote:
> ?Things are discombobulated on R-forge, it looks like (as is not so
> unusual these days) -- perhaps due to the transition to R 2.15.
>
> ?We've tried to put information at http://lme4.r-forge.r-project.org
> about current versions etc..
>
> ?For right now, there are only three versions you should think about at
> all:
>
> ?lme4 on CRAN "0.999375-42"
> ?lme4 on r-forge -- development version, supersedes lme4Eigen and
> (eventually) CRAN-lme4
> ?lme4.0 on r-forge: backward compatibility branch
>
> ?Ben Bolker
>
>
> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>> it doesn't work either though I am geting a weird error message:
>>
>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>> type="source")
>> Installing package(s) into
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>> (as ?lib? is unspecified)
>> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>> opened URL
>> ==================================================
>> downloaded 1013 Kb
>>
>> * installing *source* package ?lme4.0? ...
>> ** libs
>> *** arch - i386
>> sh: make: command not found
>> ERROR: compilation failed for package ?lme4.0?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>> Warning in install.packages :
>> ? installation of package ?lme4.0? had non-zero exit status
>>
>> The downloaded packages are in
>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>
>>
>>
>>
>>
>>
>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot <renaud.lancelot at cirad.fr
>> <mailto:renaud.lancelot at cirad.fr>> wrote:
>>
>> ? ? Well...
>>
>>
>> ? ? > install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>> ? ? <http://r-forge.r-project.org>")
>> ? ? Installation d(es) package(s) dans ?C:/R/RLIBS?
>> ? ? (car ?lib? n'est pas sp?cifi?)
>> ? ? Message d'avis :
>>
>> ? ? package ?lme4.0? is not available (for R version 2.15.0)
>>
>> ? ? lme4.0 seems to be available only from
>> ? ? http://lme4.r-forge.r-project.__org/repos/src/contrib/
>> ? ? <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>
>> ? ? So it should be installed from source:
>>
>> ? ? install.packages("lme4.0", repos="http://r-forge.r-__project.org
>> ? ? <http://r-forge.r-project.org>", type="source")
>>
>> ? ? which works fine for me.
>>
>>
>> ? ? However, I now have on my system:
>>
>> ? ? lme4
>> ? ? lme4a
>> ? ? lme4b
>> ? ? lme4.0
>> ? ? lme4Eigen
>>
>> ? ? This is really confusing, even for lme4xxx aficionados!
>>
>> ? ? All the best,
>>
>> ? ? Renaud
>>
>>
>>
>>
>>
>>
>> ? ? --
>> ? ? Renaud Lancelot
>> ? ? EDENext Project, coordinator: http://www.edenext.eu/
>>
>> ? ? CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>> ? ? F34398 Montpellier
>>
>> ? ? Tel. ?+33 4 67 59 37 17 <tel:%2B33%204%2067%2059%2037%2017> ?- ?Fax
>> ? ? ?+33 4 67 59 37 98 <tel:%2B33%204%2067%2059%2037%2098>
>> ? ? Secr. +33 4 67 59 37 37 <tel:%2B33%204%2067%2059%2037%2037> ?- Cell.
>> ? ? +33 6 77 52 08 69 <tel:%2B33%206%2077%2052%2008%2069>
>>
>>
>> ? ? _________________________________________________
>> ? ? R-sig-mixed-models at r-project.__org
>> ? ? <mailto:R-sig-mixed-models at r-project.org> mailing list
>> ? ? https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>> ? ? <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From roby.joehanes at nih.gov  Fri Apr  6 16:17:52 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Fri, 6 Apr 2012 10:17:52 -0400
Subject: [R-sig-ME] looping with multiple response variables lme4
In-Reply-To: <74C378BE307E5D49898BABE3CCFD29A3CF03@uqexmdb2.soe.uq.edu.au>
References: <74C378BE307E5D49898BABE3CCFD29A3CF03@uqexmdb2.soe.uq.edu.au>
Message-ID: <7C2166C8-7769-40C2-A30E-B513837AEA65@nih.gov>

Hi Justus:

I think you forgot to surround the formula with quotes, like this:
stmLM <- as.formula(paste(Response[i],"~ccov + x5k_c + ltr + x5k_fr + elev + (1|P_ID) + (1|mtx) + (1|site)"))

The error is basically saying you are trying to paste a string into a formula, which does not work.

Hope this helps,
Roby


On Apr 5, 2012, at 9:29 PM, Justus Deikumah wrote:

> Dear lme4 professionals
> 
> Thank you for any help on the subject matter.
> 
> I am doing a linear mixed effects modelling with 10 response variables and 5 predictors using lme4. I have 126 model combinations if I run my model with one response variable at a time. This seems very manual and will take the rest of my PhD. I have tried haven read some of your recent papers on loops and iterations so I have tried to write a sript for this with help from some friends as follows:
> What I want the loop to do for me is to model each response with all the candidate predictors, drop one predictor and run the models again for all the 126 combinations. Then I want to produce Estimated coefficients of fixed effects, SD, SE, AICs etc as output that can be sent into an excel template for model averaging?
> attach(var1)
> Response <- c("gnst", "spst", "fvt", "Oph", "cniv", "frgv", "gniv", "inct","omnv","Sobs", "ACE", "Chao1","Chao2", "Abund")
> 
> ## Output storage step up
> results <- vector("list", length(Response))
> ##Start the loop
> #Create the formula string
> #stmLM <- as.formula(paste(Response[i]~ccov + x5k_c + ltr + x5k_fr + elev + (1|P_ID) + (1|mtx) + (1|site)))
> 
> 
> 
> lmer <- lmer(stmLM)
> 
> # Save the results{
> results[[i]] <- summary(lmer)
> }
> {
> print(results[[i]])
> }
> My problem is anytime I reach summary and results portion of the analysis then i receive the error message below;
> 
> Error: length(formula <- as.formula(formula)) == 3 is not TRUE
> this is making my R-training uneasy for me. Can someone pls tell me what is wrong as I believe there may be a problem with the for loop of which i am new to anyway. What does the error message say? Has anyone any scripts for this??I am using the imer function? What kind of object doest lmer produce?
> Hope someone understands my question and can help, Please!!
> Thank you
> 
> 
> 
> Deikumah Justus
> PhD Candidate (Confirmed) - Landscape Ecology & Conservation
> Landscape Ecology and Conservation Group
> School of Geography, Planning and Environmental Management
> The University of Queensland
> Brisbane Qld 4072
> Australia
> 
> Chamberlain Building (35)
> Campbell Rd - St Lucia Campus
> 
> W: http://www.gpem.uq.edu.au/cser-jdeikumah
> E: j.deikumah2 at uq.edu.au
> M: +61 424481796, +61 479094200
> If you don't like something, Change it. If you can't change it, change your Attitude. DON'T COMPLAIN (Maya Angelou)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From renaud.lancelot at cirad.fr  Sat Apr  7 11:17:28 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sat, 07 Apr 2012 11:17:28 +0200
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F7ED4BF.2070801@gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com>
Message-ID: <4F800628.3050205@cirad.fr>

Dear Ben,

The installation of lme4 from source does not work for me:

 > install.packages("lme4",repos="http://r-forge.r-project.org", 
type="source")
Installation d(es) package(s) dans ?C:/R/RLIBS?
(car ?lib? n'est pas sp?cifi?)
essai de l'URL 
'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
URL ouverte
downloaded 1.2 Mb
* installing *source* package 'lme4' ...
** libs
cygwin warning:
   MS-DOS style path detected: C:/R/etc/i386/Makeconf
   Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
   CYGWIN environment variable option "nodosfilewarning" turns off this 
warning.
   Consult the user's guide for more details about POSIX paths:
     http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c external.cpp -o external.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c glmFamily.cpp -o glmFamily.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c optimizer.cpp -o optimizer.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c predModule.cpp -o predModule.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c respModule.cpp -o respModule.o
Syntax error: Unterminated quoted string
make: *** [lme4.dll] Error 2
ERROR: compilation failed for package 'lme4'
* removing 'C:/R/RLIBS/lme4'

Les packages source t?l?charg?s sont dans
         ?C:\Temp\RtmpYziZpk\downloaded_packages?
Messages d'avis :
1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l 
"C:/R/RLIBS" 
C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz' 
renvoie un statut 1
2: In install.packages("lme4", repos = "http://r-forge.r-project.org",  :
   l'installation du package ?lme4? a eu un statut de sortie non nul


My configuration:

 > sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252 
LC_MONETARY=French_France.1252 LC_NUMERIC=C 
LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] fortunes_1.4-2

loaded via a namespace (and not attached):
[1] tools_2.15.0

All the best,

Renaud




Le 06/04/2012 13:34, Ben Bolker a ?crit :
>    Things are discombobulated on R-forge, it looks like (as is not so
> unusual these days) -- perhaps due to the transition to R 2.15.
>
>    We've tried to put information at http://lme4.r-forge.r-project.org
> about current versions etc..
>
>    For right now, there are only three versions you should think about at
> all:
>
>    lme4 on CRAN "0.999375-42"
>    lme4 on r-forge -- development version, supersedes lme4Eigen and
> (eventually) CRAN-lme4
>    lme4.0 on r-forge: backward compatibility branch
>
>    Ben Bolker
>
>
> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>> it doesn't work either though I am geting a weird error message:
>>
>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>> type="source")
>> Installing package(s) into
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>> (as ?lib? is unspecified)
>> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>> opened URL
>> ==================================================
>> downloaded 1013 Kb
>>
>> * installing *source* package ?lme4.0? ...
>> ** libs
>> *** arch - i386
>> sh: make: command not found
>> ERROR: compilation failed for package ?lme4.0?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>> Warning in install.packages :
>>    installation of package ?lme4.0? had non-zero exit status
>>
>> The downloaded packages are in
>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>
>>
>>
>>
>>
>>
>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>> <mailto:renaud.lancelot at cirad.fr>>  wrote:
>>
>>      Well...
>>
>>
>>      >  install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>      <http://r-forge.r-project.org>")
>>      Installation d(es) package(s) dans ?C:/R/RLIBS?
>>      (car ?lib? n'est pas sp?cifi?)
>>      Message d'avis :
>>
>>      package ?lme4.0? is not available (for R version 2.15.0)
>>
>>      lme4.0 seems to be available only from
>>      http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>      <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>
>>      So it should be installed from source:
>>
>>      install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>      <http://r-forge.r-project.org>", type="source")
>>
>>      which works fine for me.
>>
>>
>>      However, I now have on my system:
>>
>>      lme4
>>      lme4a
>>      lme4b
>>      lme4.0
>>      lme4Eigen
>>
>>      This is really confusing, even for lme4xxx aficionados!
>>
>>      All the best,
>>
>>      Renaud
>>
>>
>>
>>
>>
>>
>>      --
>>      Renaud Lancelot
>>      EDENext Project, coordinator: http://www.edenext.eu/
>>
>>      CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>      F34398 Montpellier
>>
>>      Tel.  +33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017>   -  Fax
>>       +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>      Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037>   - Cell.
>>      +33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>
>>
>>      _________________________________________________
>>      R-sig-mixed-models at r-project.__org
>>      <mailto:R-sig-mixed-models at r-project.org>  mailing list
>>      https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From ajhhermansson at gmail.com  Fri Apr  6 16:16:19 2012
From: ajhhermansson at gmail.com (Henrik Hermansson)
Date: Fri, 6 Apr 2012 15:16:19 +0100
Subject: [R-sig-ME] Binary clustered data with negative intraclass
	correlation
Message-ID: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>

Dear all,

I have been searching far and wide for a solution to the following problem:

I have clustered data with a binary outcome. But, rather unusually
(but logically, given the application) the correlation within the
clusters is negative, as a result of competition within the cluster. I
understand from Ten Have et al. (1998) that in such cases, most
clustered-standard-errors estimators will be biased, since they assume
a positive intraclass (intracluster) correlation.

Thomas R. Ten Have, Allen Kunselman & Euginia Zharichenko (1998):
Accommodating negative intracluster correlation with a mixed effects
logistic model for bivariate binary data, Journal of Biopharmaceutical
Statistics, 8:1, 131-149

I'm hoping that someone will be able to point me towards a R package
(or similar) which can perform random effect clustered standard errors
regression without the limitation of an assumed positive intraclass
correlation.

Many thanks in advance for any help and guidance!

Best regards
Henrik Hermansson
PhD Candidate
Department of Political Science
Trinity College Dublin



From bates at stat.wisc.edu  Sat Apr  7 16:29:18 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 7 Apr 2012 09:29:18 -0500
Subject: [R-sig-ME] Does glm (and glmer) no longer vectorize proportions
 when estimating a binomial GLM(M)?
In-Reply-To: <1333662517.15306.YahooMailNeo@web161805.mail.bf1.yahoo.com>
References: <1333662517.15306.YahooMailNeo@web161805.mail.bf1.yahoo.com>
Message-ID: <CAO7JsnQi_nA=3w=pYaFj5DuGChG6wfHb_0K2wd_PLQW0LYVh1g@mail.gmail.com>

On Thu, Apr 5, 2012 at 4:48 PM, Jeremy Koster <helixed2 at yahoo.com> wrote:
> A while ago, I posted this message to the listserv:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006717.html
>
> Specifically, I had noted that this code:
>
> smoking.aggregated <- glmer (cbind(smoking observations, total observations) ~ AGE + (1|Individual), family = binomial, data = aggregated)
>
> generates the same estimates as this code, which simply uses an unaggregated vector of data with a binary outcome variable instead of the proportions via cbind:
>
>
> smoking.unaggregated <- glmer (smoking ~ AGE + (1|Individual), family = binomial, data = unaggregated)
>
>
> In response, Doug Bates described the underlying code and functions as a bit of a "hack" -- see: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006724.html

That comment was with respect to the ways that generalized linear
model families are defined in R.  There are several functions in a
family that are mis-named for historical reasons.  Initial short-cuts
were later found not to be sufficiently general and other functions to
be added to the family.  The distinction between Bernoulli and
binomial responses is to some extent determined by the weights but
then there may be both prior weights and a binomial representation of
Bernoulli responses so this mysterious 'n' vector was added, etc.

The misnomers are:
  - the dev.resid function which is documented to return the deviance
residuals doesn't.  It returns the square of the deviance residuals.
  - the aic function doesn't return the AIC, it returns the deviance.

Once you filter through all this misdirection there is still a
difference in the deviance between the Bernoulli representation of the
data and the representation as binomial responses.  The deviance from
the Bernoulli representation is based on the likelihood of the
parameters for the particular order of the observations in the data.
The deviance from the binomial representation is based on the
likelihood for any of the n_i choose k_i possible orderings of
responses as described in the binomial summary.

At one point I thought that the deviance for the two representations
should be the same but now I have convinced myself that there is a
good reason for them to be different.

> Well, I no longer get the same estimates when using the two above lines of code, which along with Doug's comment makes me wonder if subsequent versions of the base and lme4 packages now treat these models differently.

Can you provide an example where you get different parameter
estimates?  As far as I know the parameter estimates should be the
same, it is just the log-likelihood and quantities derived from it
(deviance, AIC, BIC) that are different.



From j.hadfield at ed.ac.uk  Sat Apr  7 16:47:09 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 07 Apr 2012 15:47:09 +0100
Subject: [R-sig-ME] Binary clustered data with negative intraclass
 correlation
In-Reply-To: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>
References: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>
Message-ID: <20120407154709.10961wgt5tg0bs5c@www.staffmail.ed.ac.uk>

Hi,

Do you have two observations per cluster, as in the paper you cite?

Cheers,

Jarrod


Quoting Henrik Hermansson <ajhhermansson at gmail.com> on Fri, 6 Apr 2012  
15:16:19 +0100:

> Dear all,
>
> I have been searching far and wide for a solution to the following problem:
>
> I have clustered data with a binary outcome. But, rather unusually
> (but logically, given the application) the correlation within the
> clusters is negative, as a result of competition within the cluster. I
> understand from Ten Have et al. (1998) that in such cases, most
> clustered-standard-errors estimators will be biased, since they assume
> a positive intraclass (intracluster) correlation.
>
> Thomas R. Ten Have, Allen Kunselman & Euginia Zharichenko (1998):
> Accommodating negative intracluster correlation with a mixed effects
> logistic model for bivariate binary data, Journal of Biopharmaceutical
> Statistics, 8:1, 131-149
>
> I'm hoping that someone will be able to point me towards a R package
> (or similar) which can perform random effect clustered standard errors
> regression without the limitation of an assumed positive intraclass
> correlation.
>
> Many thanks in advance for any help and guidance!
>
> Best regards
> Henrik Hermansson
> PhD Candidate
> Department of Political Science
> Trinity College Dublin
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Sat Apr  7 23:07:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 07 Apr 2012 17:07:34 -0400
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F800628.3050205@cirad.fr>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com> <4F800628.3050205@cirad.fr>
Message-ID: <4F80AC96.50107@gmail.com>

  Hmmm.

  I don't have access to a Windows machine before Monday.  Thanks for
the heads-up: you *should* in general be able to do this, I will check
to see what's going on.  In the meantime, I was going to say that you
could get Windows binaries etc. from lme4.r-forge.r-project.org/repos ,
but I see that I failed to build/install these for Windows.  Sorry,
thanks for your patience ...

  Ben Bolker


On 12-04-07 05:17 AM, lancelot wrote:
> Dear Ben,
> 
> The installation of lme4 from source does not work for me:
> 
>> install.packages("lme4",repos="http://r-forge.r-project.org",
> type="source")
> Installation d(es) package(s) dans ?C:/R/RLIBS?
> (car ?lib? n'est pas sp?cifi?)
> essai de l'URL
> 'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
> Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
> URL ouverte
> downloaded 1.2 Mb
> * installing *source* package 'lme4' ...
> ** libs
> cygwin warning:
>   MS-DOS style path detected: C:/R/etc/i386/Makeconf
>   Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
>   CYGWIN environment variable option "nodosfilewarning" turns off this
> warning.
>   Consult the user's guide for more details about POSIX paths:
>     http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c external.cpp -o external.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c glmFamily.cpp -o glmFamily.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c optimizer.cpp -o optimizer.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c predModule.cpp -o predModule.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c respModule.cpp -o respModule.o
> Syntax error: Unterminated quoted string
> make: *** [lme4.dll] Error 2
> ERROR: compilation failed for package 'lme4'
> * removing 'C:/R/RLIBS/lme4'
> 
> Les packages source t?l?charg?s sont dans
>         ?C:\Temp\RtmpYziZpk\downloaded_packages?
> Messages d'avis :
> 1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l
> "C:/R/RLIBS"
> C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz'
> renvoie un statut 1
> 2: In install.packages("lme4", repos = "http://r-forge.r-project.org",  :
>   l'installation du package ?lme4? a eu un statut de sortie non nul
> 
> 
> My configuration:
> 
>> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
> LC_MONETARY=French_France.1252 LC_NUMERIC=C LC_TIME=French_France.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] fortunes_1.4-2
> 
> loaded via a namespace (and not attached):
> [1] tools_2.15.0
> 
> All the best,
> 
> Renaud
> 
> 
> 
> 
> Le 06/04/2012 13:34, Ben Bolker a ?crit :
>>    Things are discombobulated on R-forge, it looks like (as is not so
>> unusual these days) -- perhaps due to the transition to R 2.15.
>>
>>    We've tried to put information at http://lme4.r-forge.r-project.org
>> about current versions etc..
>>
>>    For right now, there are only three versions you should think about at
>> all:
>>
>>    lme4 on CRAN "0.999375-42"
>>    lme4 on r-forge -- development version, supersedes lme4Eigen and
>> (eventually) CRAN-lme4
>>    lme4.0 on r-forge: backward compatibility branch
>>
>>    Ben Bolker
>>
>>
>> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>>> it doesn't work either though I am geting a weird error message:
>>>
>>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>>> type="source")
>>> Installing package(s) into
>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>>> (as ?lib? is unspecified)
>>> trying URL
>>> 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>>> opened URL
>>> ==================================================
>>> downloaded 1013 Kb
>>>
>>> * installing *source* package ?lme4.0? ...
>>> ** libs
>>> *** arch - i386
>>> sh: make: command not found
>>> ERROR: compilation failed for package ?lme4.0?
>>> * removing
>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>>> Warning in install.packages :
>>>    installation of package ?lme4.0? had non-zero exit status
>>>
>>> The downloaded packages are in
>>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>>> <mailto:renaud.lancelot at cirad.fr>>  wrote:
>>>
>>>      Well...
>>>
>>>
>>>      > 
>>> install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>>      <http://r-forge.r-project.org>")
>>>      Installation d(es) package(s) dans ?C:/R/RLIBS?
>>>      (car ?lib? n'est pas sp?cifi?)
>>>      Message d'avis :
>>>
>>>      package ?lme4.0? is not available (for R version 2.15.0)
>>>
>>>      lme4.0 seems to be available only from
>>>      http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>>      <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>>
>>>      So it should be installed from source:
>>>
>>>      install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>>      <http://r-forge.r-project.org>", type="source")
>>>
>>>      which works fine for me.
>>>
>>>
>>>      However, I now have on my system:
>>>
>>>      lme4
>>>      lme4a
>>>      lme4b
>>>      lme4.0
>>>      lme4Eigen
>>>
>>>      This is really confusing, even for lme4xxx aficionados!
>>>
>>>      All the best,
>>>
>>>      Renaud
>>>
>>>
>>>
>>>
>>>
>>>
>>>      --
>>>      Renaud Lancelot
>>>      EDENext Project, coordinator: http://www.edenext.eu/
>>>
>>>      CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>>      F34398 Montpellier
>>>
>>>      Tel.  +33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017>   -  Fax
>>>       +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>>      Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037>   -
>>> Cell.
>>>      +33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>>
>>>
>>>      _________________________________________________
>>>      R-sig-mixed-models at r-project.__org
>>>      <mailto:R-sig-mixed-models at r-project.org>  mailing list
>>>      https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>>
>>
>>
>



From jwiley.psych at gmail.com  Sat Apr  7 23:46:47 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 7 Apr 2012 14:46:47 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F80AC96.50107@gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com> <4F800628.3050205@cirad.fr>
	<4F80AC96.50107@gmail.com>
Message-ID: <CANz9Z_Jmzhv0igAXCa3qJauxYuGv6=X5RMv2JBBSWOaC7gGKRQ@mail.gmail.com>

FYI, yesterday I was able to install lme4 and lme4.0 from source form
R forge without a glitch on a Windows x64 system with the most recent
version of Rtools and unsuffered consequences.

Josh

On Sat, Apr 7, 2012 at 2:07 PM, Ben Bolker <bbolker at gmail.com> wrote:
> ?Hmmm.
>
> ?I don't have access to a Windows machine before Monday. ?Thanks for
> the heads-up: you *should* in general be able to do this, I will check
> to see what's going on. ?In the meantime, I was going to say that you
> could get Windows binaries etc. from lme4.r-forge.r-project.org/repos ,
> but I see that I failed to build/install these for Windows. ?Sorry,
> thanks for your patience ...
>
> ?Ben Bolker
>
>
> On 12-04-07 05:17 AM, lancelot wrote:
>> Dear Ben,
>>
>> The installation of lme4 from source does not work for me:
>>
>>> install.packages("lme4",repos="http://r-forge.r-project.org",
>> type="source")
>> Installation d(es) package(s) dans ?C:/R/RLIBS?
>> (car ?lib? n'est pas sp?cifi?)
>> essai de l'URL
>> 'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
>> Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
>> URL ouverte
>> downloaded 1.2 Mb
>> * installing *source* package 'lme4' ...
>> ** libs
>> cygwin warning:
>> ? MS-DOS style path detected: C:/R/etc/i386/Makeconf
>> ? Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
>> ? CYGWIN environment variable option "nodosfilewarning" turns off this
>> warning.
>> ? Consult the user's guide for more details about POSIX paths:
>> ? ? http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c external.cpp -o external.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c glmFamily.cpp -o glmFamily.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c optimizer.cpp -o optimizer.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c predModule.cpp -o predModule.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c respModule.cpp -o respModule.o
>> Syntax error: Unterminated quoted string
>> make: *** [lme4.dll] Error 2
>> ERROR: compilation failed for package 'lme4'
>> * removing 'C:/R/RLIBS/lme4'
>>
>> Les packages source t?l?charg?s sont dans
>> ? ? ? ? ?C:\Temp\RtmpYziZpk\downloaded_packages?
>> Messages d'avis :
>> 1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l
>> "C:/R/RLIBS"
>> C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz'
>> renvoie un statut 1
>> 2: In install.packages("lme4", repos = "http://r-forge.r-project.org", ?:
>> ? l'installation du package ?lme4? a eu un statut de sortie non nul
>>
>>
>> My configuration:
>>
>>> sessionInfo()
>> R version 2.15.0 (2012-03-30)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=French_France.1252 ?LC_CTYPE=French_France.1252
>> LC_MONETARY=French_France.1252 LC_NUMERIC=C LC_TIME=French_France.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] fortunes_1.4-2
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.15.0
>>
>> All the best,
>>
>> Renaud
>>
>>
>>
>>
>> Le 06/04/2012 13:34, Ben Bolker a ?crit :
>>> ? ?Things are discombobulated on R-forge, it looks like (as is not so
>>> unusual these days) -- perhaps due to the transition to R 2.15.
>>>
>>> ? ?We've tried to put information at http://lme4.r-forge.r-project.org
>>> about current versions etc..
>>>
>>> ? ?For right now, there are only three versions you should think about at
>>> all:
>>>
>>> ? ?lme4 on CRAN "0.999375-42"
>>> ? ?lme4 on r-forge -- development version, supersedes lme4Eigen and
>>> (eventually) CRAN-lme4
>>> ? ?lme4.0 on r-forge: backward compatibility branch
>>>
>>> ? ?Ben Bolker
>>>
>>>
>>> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>>>> it doesn't work either though I am geting a weird error message:
>>>>
>>>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>>>> type="source")
>>>> Installing package(s) into
>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>>>> (as ?lib? is unspecified)
>>>> trying URL
>>>> 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>>>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>>>> opened URL
>>>> ==================================================
>>>> downloaded 1013 Kb
>>>>
>>>> * installing *source* package ?lme4.0? ...
>>>> ** libs
>>>> *** arch - i386
>>>> sh: make: command not found
>>>> ERROR: compilation failed for package ?lme4.0?
>>>> * removing
>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>>>> Warning in install.packages :
>>>> ? ?installation of package ?lme4.0? had non-zero exit status
>>>>
>>>> The downloaded packages are in
>>>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>>>> <mailto:renaud.lancelot at cirad.fr>> ?wrote:
>>>>
>>>> ? ? ?Well...
>>>>
>>>>
>>>> ? ? ?>
>>>> install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>>> ? ? ?<http://r-forge.r-project.org>")
>>>> ? ? ?Installation d(es) package(s) dans ?C:/R/RLIBS?
>>>> ? ? ?(car ?lib? n'est pas sp?cifi?)
>>>> ? ? ?Message d'avis :
>>>>
>>>> ? ? ?package ?lme4.0? is not available (for R version 2.15.0)
>>>>
>>>> ? ? ?lme4.0 seems to be available only from
>>>> ? ? ?http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>>> ? ? ?<http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>>>
>>>> ? ? ?So it should be installed from source:
>>>>
>>>> ? ? ?install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>>> ? ? ?<http://r-forge.r-project.org>", type="source")
>>>>
>>>> ? ? ?which works fine for me.
>>>>
>>>>
>>>> ? ? ?However, I now have on my system:
>>>>
>>>> ? ? ?lme4
>>>> ? ? ?lme4a
>>>> ? ? ?lme4b
>>>> ? ? ?lme4.0
>>>> ? ? ?lme4Eigen
>>>>
>>>> ? ? ?This is really confusing, even for lme4xxx aficionados!
>>>>
>>>> ? ? ?All the best,
>>>>
>>>> ? ? ?Renaud
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ? ? ?--
>>>> ? ? ?Renaud Lancelot
>>>> ? ? ?EDENext Project, coordinator: http://www.edenext.eu/
>>>>
>>>> ? ? ?CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>>> ? ? ?F34398 Montpellier
>>>>
>>>> ? ? ?Tel. ?+33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017> ? - ?Fax
>>>> ? ? ? +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>>> ? ? ?Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037> ? -
>>>> Cell.
>>>> ? ? ?+33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>>>
>>>>
>>>> ? ? ?_________________________________________________
>>>> ? ? ?R-sig-mixed-models at r-project.__org
>>>> ? ? ?<mailto:R-sig-mixed-models at r-project.org> ?mailing list
>>>> ? ? ?https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>>> ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>
>>>>
>>>
>>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Sun Apr  8 00:02:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 07 Apr 2012 18:02:51 -0400
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CANz9Z_Jmzhv0igAXCa3qJauxYuGv6=X5RMv2JBBSWOaC7gGKRQ@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com> <4F800628.3050205@cirad.fr>
	<4F80AC96.50107@gmail.com>
	<CANz9Z_Jmzhv0igAXCa3qJauxYuGv6=X5RMv2JBBSWOaC7gGKRQ@mail.gmail.com>
Message-ID: <4F80B98B.7020805@gmail.com>

On 12-04-07 05:46 PM, Joshua Wiley wrote:
> FYI, yesterday I was able to install lme4 and lme4.0 from source form
> R forge without a glitch on a Windows x64 system with the most recent
> version of Rtools and unsuffered consequences.
> 
> Josh
> 

  Thanks.  I just built current versions of lme4.0 and lme4 on
win-builder.r-project.org and installed them in the lme4 repository --
it will take a little while for that change to propagate, but that
should be a good fallback for when r-forge is glitchy.

  Ben

> On Sat, Apr 7, 2012 at 2:07 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>  Hmmm.
>>
>>  I don't have access to a Windows machine before Monday.  Thanks for
>> the heads-up: you *should* in general be able to do this, I will check
>> to see what's going on.  In the meantime, I was going to say that you
>> could get Windows binaries etc. from lme4.r-forge.r-project.org/repos ,
>> but I see that I failed to build/install these for Windows.  Sorry,
>> thanks for your patience ...
>>
>>  Ben Bolker
>>
>>
>> On 12-04-07 05:17 AM, lancelot wrote:
>>> Dear Ben,
>>>
>>> The installation of lme4 from source does not work for me:
>>>
>>>> install.packages("lme4",repos="http://r-forge.r-project.org",
>>> type="source")
>>> Installation d(es) package(s) dans ?C:/R/RLIBS?
>>> (car ?lib? n'est pas sp?cifi?)
>>> essai de l'URL
>>> 'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
>>> Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
>>> URL ouverte
>>> downloaded 1.2 Mb
>>> * installing *source* package 'lme4' ...
>>> ** libs
>>> cygwin warning:
>>>   MS-DOS style path detected: C:/R/etc/i386/Makeconf
>>>   Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
>>>   CYGWIN environment variable option "nodosfilewarning" turns off this
>>> warning.
>>>   Consult the user's guide for more details about POSIX paths:
>>>     http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c external.cpp -o external.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c glmFamily.cpp -o glmFamily.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c optimizer.cpp -o optimizer.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c predModule.cpp -o predModule.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c respModule.cpp -o respModule.o
>>> Syntax error: Unterminated quoted string
>>> make: *** [lme4.dll] Error 2
>>> ERROR: compilation failed for package 'lme4'
>>> * removing 'C:/R/RLIBS/lme4'
>>>
>>> Les packages source t?l?charg?s sont dans
>>>         ?C:\Temp\RtmpYziZpk\downloaded_packages?
>>> Messages d'avis :
>>> 1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l
>>> "C:/R/RLIBS"
>>> C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz'
>>> renvoie un statut 1
>>> 2: In install.packages("lme4", repos = "http://r-forge.r-project.org",  :
>>>   l'installation du package ?lme4? a eu un statut de sortie non nul
>>>
>>>
>>> My configuration:
>>>
>>>> sessionInfo()
>>> R version 2.15.0 (2012-03-30)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
>>> LC_MONETARY=French_France.1252 LC_NUMERIC=C LC_TIME=French_France.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] fortunes_1.4-2
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.15.0
>>>
>>> All the best,
>>>
>>> Renaud
>>>
>>>
>>>
>>>
>>> Le 06/04/2012 13:34, Ben Bolker a ?crit :
>>>>    Things are discombobulated on R-forge, it looks like (as is not so
>>>> unusual these days) -- perhaps due to the transition to R 2.15.
>>>>
>>>>    We've tried to put information at http://lme4.r-forge.r-project.org
>>>> about current versions etc..
>>>>
>>>>    For right now, there are only three versions you should think about at
>>>> all:
>>>>
>>>>    lme4 on CRAN "0.999375-42"
>>>>    lme4 on r-forge -- development version, supersedes lme4Eigen and
>>>> (eventually) CRAN-lme4
>>>>    lme4.0 on r-forge: backward compatibility branch
>>>>
>>>>    Ben Bolker
>>>>
>>>>
>>>> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>>>>> it doesn't work either though I am geting a weird error message:
>>>>>
>>>>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>>>>> type="source")
>>>>> Installing package(s) into
>>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>>>>> (as ?lib? is unspecified)
>>>>> trying URL
>>>>> 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>>>>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>>>>> opened URL
>>>>> ==================================================
>>>>> downloaded 1013 Kb
>>>>>
>>>>> * installing *source* package ?lme4.0? ...
>>>>> ** libs
>>>>> *** arch - i386
>>>>> sh: make: command not found
>>>>> ERROR: compilation failed for package ?lme4.0?
>>>>> * removing
>>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>>>>> Warning in install.packages :
>>>>>    installation of package ?lme4.0? had non-zero exit status
>>>>>
>>>>> The downloaded packages are in
>>>>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>>>>> <mailto:renaud.lancelot at cirad.fr>>  wrote:
>>>>>
>>>>>      Well...
>>>>>
>>>>>
>>>>>      >
>>>>> install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>>>>      <http://r-forge.r-project.org>")
>>>>>      Installation d(es) package(s) dans ?C:/R/RLIBS?
>>>>>      (car ?lib? n'est pas sp?cifi?)
>>>>>      Message d'avis :
>>>>>
>>>>>      package ?lme4.0? is not available (for R version 2.15.0)
>>>>>
>>>>>      lme4.0 seems to be available only from
>>>>>      http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>>>>      <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>>>>
>>>>>      So it should be installed from source:
>>>>>
>>>>>      install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>>>>      <http://r-forge.r-project.org>", type="source")
>>>>>
>>>>>      which works fine for me.
>>>>>
>>>>>
>>>>>      However, I now have on my system:
>>>>>
>>>>>      lme4
>>>>>      lme4a
>>>>>      lme4b
>>>>>      lme4.0
>>>>>      lme4Eigen
>>>>>
>>>>>      This is really confusing, even for lme4xxx aficionados!
>>>>>
>>>>>      All the best,
>>>>>
>>>>>      Renaud
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>      --
>>>>>      Renaud Lancelot
>>>>>      EDENext Project, coordinator: http://www.edenext.eu/
>>>>>
>>>>>      CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>>>>      F34398 Montpellier
>>>>>
>>>>>      Tel.  +33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017>   -  Fax
>>>>>       +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>>>>      Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037>   -
>>>>> Cell.
>>>>>      +33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>>>>
>>>>>
>>>>>      _________________________________________________
>>>>>      R-sig-mixed-models at r-project.__org
>>>>>      <mailto:R-sig-mixed-models at r-project.org>  mailing list
>>>>>      https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>



From trea26 at gmail.com  Sun Apr  8 03:47:46 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sat, 07 Apr 2012 22:47:46 -0300
Subject: [R-sig-ME] looping with multiple response variables lme4
Message-ID: <4F80EE42.9090103@gmail.com>

Hi Justus,
Maybe the following functions from package "LMERConvenienceFunctions" 
can be of help:

bfFixefLMER_F.fnc       Back-fits an LMER model on p-values from ANOVA
                         and, optionally, on LLRT.
bfFixefLMER_t.fnc       Back-fits an LMER model on absolute t-value
                         and, optionally, on LLRT.
fitLMER.fnc             Back-fit fixed effects and forward-fit random
                         effects of an LMER mo

Basically you can have a model with say a 10-way interaction and all 
lower-level interactions and main effects) and these fucntions will 
iteratively remove any non-significant model term starting with the 
highest-order interaction and going down to the main effects. If a 
lower-order interaction or main effect is part of a higher-order one, 
the term won't be pruned (the marginality principle). It also prints a 
log of the steps it went through. Here's an example:

# fit initial model
m1 = lmer(Fz ~ FreqB * LengthB * WMC + (1 | Subject) +
        (1 | Item), data = eeg)

# backfit fixed effects on F
m2 = bfFixefLMER_F.fnc(mB, eeg, log.file = FALSE,
        llrt = FALSE)

processing model terms of interaction level 3
     iteration 1
         p-value for term "FreqB:LengthB:WMC" = 0.1152 > 0.05
         not part of higher-order interaction
         removing term
processing model terms of interaction level 2
     iteration 2
         p-value for term "FreqB:WMC" = 0.9552 > 0.05
         not part of higher-order interaction
         removing term
     iteration 3
         p-value for term "FreqB:LengthB" = 0.6564 > 0.05
         not part of higher-order interaction
         removing term
processing model terms of interaction level 1
     iteration 4
         p-value for term "WMC" = 0.7796 > 0.05
         part of higher-order interaction
         skipping term
     iteration 5
         p-value for term "FreqB" = 0.7635 > 0.05
         not part of higher-order interaction
         removing term
     iteration 6
         p-value for term "LengthB" = 0.0924 > 0.05
         part of higher-order interaction
         skipping term
pruning random effects structure ...
     nothing to prune


The output will simply be a pruned lme model. You can certainly look at 
the code and tweak it so it'll return SD, SE, and AIC.

Antoine
NeuroCognitive Imaging Laboratory
Dalhousie University
Halifax, Nova Scotia
Canada


 > Hi Justus:
 >
 > I think you forgot to surround the formula with quotes, like this:
 > stmLM <- as.formula(paste(Response[i],"~ccov + x5k_c + ltr + x5k_fr + 
 > elev + (1|P_ID) + (1|mtx) + (1|site)"))
 >
 > The error is basically saying you are trying to paste a string into a 
 > formula, which does not work.
 >
 > Hope this helps,
 > Roby
 >
 >
 > On Apr 5, 2012, at 9:29 PM, Justus Deikumah wrote:
 >
 >> Dear lme4 professionals
 >>
 >> Thank you for any help on the subject matter.
 >>
 >> I am doing a linear mixed effects modelling with 10 response 
variables and 5 predictors using lme4. I have 126 model combinations if 
I run my model with one response variable at a time. This seems very 
manual and will take the rest of my PhD. I have tried haven read some of 
your recent papers on loops and iterations so I have tried to write a 
sript for this with help from some friends as follows:
 > What I want the loop to do for me is to model each response with all 
the candidate predictors, drop one predictor and run the models again 
for all the 126 combinations. Then I want to produce Estimated 
coefficients of fixed effects, SD, SE, AICs etc as output that can be 
sent into an excel template for model averaging?
 >> attach(var1)
 >> Response <- c("gnst", "spst", "fvt", "Oph", "cniv", "frgv", "gniv", 
"inct","omnv","Sobs", "ACE", "Chao1","Chao2", "Abund")
 >
 > ## Output storage step up
 > results <- vector("list", length(Response))
 > ##Start the loop
 > #Create the formula string
 > #stmLM <- as.formula(paste(Response[i]~ccov + x5k_c + ltr + x5k_fr + 
elev + (1|P_ID) + (1|mtx) + (1|site)))
 >
 >
 >
 > lmer <- lmer(stmLM)
 >
 > # Save the results{
 > results[[i]] <- summary(lmer)
 > }
 > {
 > print(results[[i]])
 > }
 > My problem is anytime I reach summary and results portion of the 
analysis then i receive the error message below;
 >
 > Error: length(formula <- as.formula(formula)) == 3 is not TRUE
 > this is making my R-training uneasy for me. Can someone pls tell me 
what is wrong as I believe there may be a problem with the for loop of 
which i am new to anyway. What does the error message say? Has anyone 
any scripts for this??I am using the lmer function? What kind of object 
doest lmer produce?
 > Hope someone understands my question and can help, Please!!
 > Thank you
 >
 >
 >
 > Deikumah Justus
 > PhD Candidate (Confirmed) - Landscape Ecology & Conservation
 > Landscape Ecology and Conservation Group
 > School of Geography, Planning and Environmental Management
 > The University of Queensland
 > Brisbane Qld 4072
 > Australia
 >
 > Chamberlain Building (35)
 > Campbell Rd - St Lucia Campus
 >
 > W: http://www.gpem.uq.edu.au/cser-jdeikumah
 > E: j.deikumah2 at uq.edu.au
 > M: +61 424481796, +61 479094200
 > If you don't like something, Change it. If you can't change it, 
change your Attitude. DON'T COMPLAIN (Maya Angelou)
 >
 >     [[alternative HTML version deleted]]
 >
 > _______________________________________________
 > R-sig-mixed-models at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Antoine Tremblay, PhD
NeuroCognitive Imaging Laboratory
Dalhousie University
Halifax, NS B3H 3J5,
Canada

Tel.: (902) 494-1911
eom



From roby.joehanes at nih.gov  Mon Apr  9 19:15:16 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 9 Apr 2012 13:15:16 -0400
Subject: [R-sig-ME] Kinship vs. Pedigreemm
Message-ID: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>

Dear all:

I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).

Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?

Thank you,
Roby


From f.calboli at imperial.ac.uk  Mon Apr  9 19:32:19 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 9 Apr 2012 18:32:19 +0100
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
Message-ID: <5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>

On 9 Apr 2012, at 18:15, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Dear all:
> 
> I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).
> 
> Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?

I thought that Kinship is now replaced by Kinship2 (http://cran.r-project.org/web/packages/kinship2/index.html).

BW


F



> 
> Thank you,
> Roby
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From roby.joehanes at nih.gov  Mon Apr  9 19:58:16 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 9 Apr 2012 13:58:16 -0400
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
	<5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
Message-ID: <A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>

Hi:

Yes, you are right. It appears that package kinship is now broken into several packages: coxme, kinship2, bdsmatrix, among others. Are you aware of the difference between them and pedigreemm?

Thank you,
Roby


On Apr 9, 2012, at 1:32 PM, Federico Calboli wrote:

> On 9 Apr 2012, at 18:15, Joehanes, Roby (NIH/NHLBI) [F] wrote:
> 
>> Dear all:
>> 
>> I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).
>> 
>> Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?
> 
> I thought that Kinship is now replaced by Kinship2 (http://cran.r-project.org/web/packages/kinship2/index.html).
> 
> BW
> 
> 
> F
> 



From f.calboli at imperial.ac.uk  Mon Apr  9 20:05:26 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 9 Apr 2012 19:05:26 +0100
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
	<5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
	<A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
Message-ID: <D5D3BC1A-64F1-4D4E-A589-3576449B13B4@imperial.ac.uk>

On 9 Apr 2012, at 18:58, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi:
> 
> Yes, you are right. It appears that package kinship is now broken into several packages: coxme, kinship2, bdsmatrix, among others. Are you aware of the difference between them and pedigreemm?

I would not know personally, but others on the list might know more.

BW

F


> 
> Thank you,
> Roby
> 
> 
> On Apr 9, 2012, at 1:32 PM, Federico Calboli wrote:
> 
>> On 9 Apr 2012, at 18:15, Joehanes, Roby (NIH/NHLBI) [F] wrote:
>> 
>>> Dear all:
>>> 
>>> I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).
>>> 
>>> Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?
>> 
>> I thought that Kinship is now replaced by Kinship2 (http://cran.r-project.org/web/packages/kinship2/index.html).
>> 
>> BW
>> 
>> 
>> F
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From pauljohn32 at gmail.com  Mon Apr  9 23:48:10 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 9 Apr 2012 16:48:10 -0500
Subject: [R-sig-ME] Is there a final-ish format for lme4 objects now?
Message-ID: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>

Greetings:

Long ago, I wrote a function "outreg" to make LaTeX tables for
regressions.  Now I've put it in a package
called rockchalk.  Because I put it in a package on CRAN, people I
don't know write to me saying
"it works for lm and glm, but what about lme4".

In 2008 or so, I had tried to incorporate lme4 output, but I ran into
the trouble. Version changes
of lme4 regularly broke my output code.  I asked about it here, and
learned I was "jumping the gun" because
lme4 was still adjusting.

Has lme4 output reached a point where I can treat the output from lme4
functions as "more or less"
stable?  If I make the table maker function work with lme4 objects
(the stable CRAN version),  is that function
likely to also work with the development version of lme4?  I know the
class of the objects
changed from mer to merMod.  Is that a signal that I am again too
early to try to do this?

pj
-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu



From David.Duffy at qimr.edu.au  Tue Apr 10 04:36:54 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 10 Apr 2012 12:36:54 +1000 (EST)
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov><5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
	<A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
Message-ID: <Pine.LNX.4.64.1204101233140.29974@orpheus.qimr.edu.au>

On Mon, 9 Apr 2012, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Yes, you are right. It appears that package kinship is now broken into 
> several packages: coxme, kinship2, bdsmatrix, among others. Are you 
> aware of the difference between them and pedigreemm?

Terry Therneau wrote in the lmekin vignette:

"Let me emphasis this: most models that can be fit with the lmekin 
function can also be fit with lme and/or lmer. For any such model the 
lme/lmer functions will be faster and have superior support routines 
(residuals, printing, plotting, etc.) The solution code for lmer is likely 
also more reliable since it has been exercised on a much wider variety of 
data sets.

"However, there are models that lmekin will fit which lme will not. The 
most obvious of these are models with a random genetic effect, e.g. a 
kinship matrix. The second class will be models for which the user has 
written their own variance extension, as described in the variance 
vignette."


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bates at stat.wisc.edu  Sun Apr  1 09:50:02 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 1 Apr 2012 02:50:02 -0500
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
	<CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
Message-ID: <CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>

On Fri, Mar 30, 2012 at 3:44 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Ben,
>
> Many thanks for the help. ?I tried your suggestion out and it seemed
> to work (and I learned a bit about lme4 in the process :)
>
> library(lme4)
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm1Fun <- update(fm1,devFunOnly=TRUE)
> library(numDeriv)
> fm1_thpar <- getME(fm1,"theta")
> h <- hessian(fm1Fun, fm1_thpar)
> g <- grad(fm1Fun, fm1_thpar)
>
> which I can use (I think) to get standard errors of the variance parameters.
>
> library(MASS)
> sqrt(diag(ginv(h)))
>
> which plug into a longer formula that attempts to test the
> significance of indirect effects. ?Given that the variance parameters
> are not normally distributed, my hunch is that even though both fixed
> and random effects (and their variances/standard errors) are being
> built into the mediation test, it is probably not well-behaved either,
> but it is nice to be able to try to replicate models in the article.
> Even if they are not perfectly accurate, I am hoping I can use them as
> a sanity check for when I play with some mcmc and bootstrapping.

I have been travelling and haven't tracked messages on the list
closely so I might have missed something here.  What do you mean by
"the variance parameters"?  The theta parameters aren't variances and
covariances.  They are values from the relative covariance factor.
For the model you fit the first element of theta is the standard
deviation of the intercept random effects divided by the standard
deviation of the per-observation noise.  The second and third elements
only make sense in terms of the Cholesky factor of the relative
variance-covariance matrix.

This choice is not arbitrary.  Although we are accustomed to thinking
in terms of variances and covariances or in terms of standard
deviations and correlations, these are difficult scales on which to
optimize because the constraints on these values are complicated
nonlinear constraints.

So as long as you recognize that the "variance parameters" aren't
variances or covariances you should be okay.

> R Under development (unstable) (2012-03-29 r58868)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] MASS_7.3-17 ? ? ? ?reshape2_1.2.1 ? ? numDeriv_2012.3-1 ?lme4_0.999902344-0
> [5] Matrix_1.0-6 ? ? ? lattice_0.20-6
>
> loaded via a namespace (and not attached):
> [1] grid_2.16.0 ? ?minqa_1.2.0 ? ?nlme_3.1-103 ? plyr_1.7.1 ? ? splines_2.16.0
> [6] stringr_0.6 ? ?tools_2.16.0
>
> On Mon, Mar 19, 2012 at 12:15 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Joshua Wiley <jwiley.psych at ...> writes:
>>
>>>
>>> Hi,
>>>
>>> I am trying to use a multivariate mixed effects linear model to
>>> examine mediation. ?This works fine. ?The final step is to compute the
>>> indirect effect and its standard error. ?The indirect effect is easy
>>> (product of coefficients plus their covariance). ?For the standard
>>> error, I need the gradient (D) and the hessian (H):
>>> the variance is then:
>>>
>>> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
>>>
>>> This is all given in the Appendix of
>>> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>>>
>>> Is there a way to get this out of a mer class object? ?Looking at
>>> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$. ?@V
>>> seems like it would give me the gradient but is null for a basic lmer
>>> model.
>>
>> ?If you're willing to try out the development version (i.e., lme4
>> from r-forge), I think you can do this as follows:
>>
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>> library(numDeriv)
>> fm1_thpar <- getME(fm1,"theta")
>> h <- hessian(fm1Fun,fm1_thpar)
>>
>> ?and similarly for the gradient.
>>
>> ?Let me know how it goes.
>>
>> ?Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From keith.larson at biol.lu.se  Sun Apr  1 13:26:57 2012
From: keith.larson at biol.lu.se (Keith Larson)
Date: Sun, 1 Apr 2012 13:26:57 +0200
Subject: [R-sig-ME] interpreting random effects
Message-ID: <CAM1PXy3HPWC2we3Vj9hd2b02jJvC0AGm8atFXn3v=tcjnsvZnw@mail.gmail.com>

I have have measured the trait frequency for a "mountain" associated
allele across a number of sites and years. In my (glmer) model I have
summarized the allele frequency by site and year as the dependent
(binomial) variable and specified site and year as random effects. The
fixed effects are latitude, longitude, altitude, and
latitude|longitude. When I run the model and then drop and update each
random effect separately to see if they are important to the model,
site appears to be significant and year does not. Two questions:

1. Can I re-summarize my dependent variable for by site rather than
site and year?

2. Given that we did not sample each site the same number of times
(years) and have different numbers of samples at each site (and year),
should I standardize my dependent variable?

Thanks,
Keith Larson, PhD Student
Evolutionary Ecology, Lund University



From pierces1 at msu.edu  Sun Apr  1 15:47:03 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Sun, 1 Apr 2012 09:47:03 -0400
Subject: [R-sig-ME] MCMC model selection reference
In-Reply-To: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>
References: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>
Message-ID: <000a01cd100d$ec8a0560$c59e1020$@msu.edu>

Here are a couple references on DIC that I happen to have handy:

Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & van der Linde, A.
(2002). Bayesian measures of model complexity and fit. Journal of the Royal
Statistical Society: Series B (Statistical Methodology), 64(4), 583-639.
doi: 10.1111/1467-9868.00353  http://www.jstor.org/stable/3088806 

Barnett, A. G., Koper, N., Dobson, A. J., Schmiegelow, F., & Manseau, M.
(2010). Using information criteria to select the correct variance-covariance
structure for longitudinal data in ecology. Methods in Ecology and
Evolution, 1(1), 15-24. doi: 10.1111/j.2041-210X.2009.00009.x
http://dx.doi.org/10.1111/j.2041-210X.2009.00009.x 


Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Ray Danner [mailto:danner.ray at gmail.com] 
Sent: Saturday, March 31, 2012 2:24 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] MCMC model selection reference

Dear list,

I'm looking for guidance on model selection using DIC values.  I'm
particularly interested in comparing mixed models created with the
package MCMCglmm.  I currently use AIC for my models built with lme
and (g)lmer and like the ability to calculate evidence ratios and
model average predictions, which are very easy for readers to
conceptualize.  AICcmodavg is great for these things.

Can anyone recommend a resource that describes the appropriate use of
DIC for model selection (and its limitations)?  I'm mainly an
ecologist, so a less-technical treatment would be ideal.

My main questions are:
1. Can DIC be used to select among mixed models?
Kery and Schaub (2012 p. 42) raise concerns about counting the correct
number of parameters and state that WinBUGS does not calculate them
appropriately, though Millar (2009) provides a method that is
appropriate for hierarchical models.  On the other hand, Saveliev et
al. (2009) use DIC to compare models with random effects built with
the BRugs package.  Hadfield's MCMCglmm Tutorial says that lower DIC
is better, but doesn't give details about use.

2. Any rules of thumb on what constitutes sufficiently large deltaDIC
values?  Are evidence ratios acceptable?

3. Can DIC be used to calculate model average predictions?

Thanks in advance and please forgive me if I missed your publication.
Ray


Refs
Kery and Schaub. 2012. Bayesian Population Analysis Using WinBUGS: A
Hierarchical Perspective.
Millar. 2009. Comparison of hierarchical Bayesian models for
overdispersed count data using DIC and Bayes' Factors. Biometrics
65:962-969.
Saveliev et al. 2009. Ch. 23 in Zuur, Mixed Effects Models and
Extensions in Ecology with R.



From pdalgd at gmail.com  Sun Apr  1 15:53:55 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 1 Apr 2012 15:53:55 +0200
Subject: [R-sig-ME] repeated measures: lme(r) vs manova
In-Reply-To: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
References: <51773094-94E5-4567-A061-E9DAD71968BE@gmail.com>
Message-ID: <BCB1C781-ACDB-4893-870A-66F24E13CDB6@gmail.com>


On Mar 19, 2012, at 22:31 , Nathan Lemoine wrote:

> Hi all,
> Sorry in advance for the length of this post, but I've searched around and couldn't find anything that addressed this issue:
> 
> I recently ran into the issue of deciding on the appropriate way to analyze a repeated measures design. We enriched quadrats to measure productivity and we monitored them for three years. Four quadrats were nested within plots. Here are the data:
> 
> "plot" "quad" "nut" "t1" "t3" "t4"
> "1" 1 "A" "nut" 17.69130435 70.4 57.8
> "2" 1 "A" "no nut" 65.4173913 125.8 109.9
> "3" 1 "B" "nut" 19.56521739 103.2 100.8
> "4" 1 "B" "no nut" 89.03636364 131.3 99.1
> "5" 1 "C" "nut" 29.88723404 25.7 29.9
> "6" 1 "C" "no nut" 45.45454545 113.1 110.6
> "7" 1 "D" "nut" 18.28181818 60.9 67.7
> "8" 1 "D" "no nut" 68.88888889 136 95
> "9" 2 "A" "nut" 35.41666667 61.6 16
> "10" 2 "A" "no nut" 40.90909091 59.4 64.7
> "11" 2 "B" "nut" 34.14255319 26.7 23.1
> "12" 2 "B" "no nut" 36.27021277 71.6 47.2
> "13" 2 "C" "nut" 13.33333333 20.9 26.4
> "14" 2 "C" "no nut" 7.118181818 31.2 19.1
> "15" 2 "D" "nut" 20 30.9 27.8
> "16" 2 "D" "no nut" 19.34893617 31.3 16.7
> "17" 3 "A" "nut" 22.22222222 130.7 163.6
> "18" 3 "A" "no nut" 32.90869565 83.8 86.2
> "19" 3 "B" "nut" 38.29787234 99 110.1
> "20" 3 "B" "no nut" 38.83636364 127.1 115.2
> "21" 3 "C" "nut" 38.88888889 81.7 193.7
> "22" 3 "C" "no nut" 28.98888889 72.1 103.8
> "23" 3 "D" "nut" 50 111.3 117.7
> "24" 3 "D" "no nut" 26.86666667 94.2 113
> "25" 4 "A" "nut" 63.63636364 128.4 114.8
> "26" 4 "A" "no nut" 108.8956522 121 80.7
> "27" 4 "B" "nut" 104.4444444 146.5 102.2
> "28" 4 "B" "no nut" 84.74444444 111.5 109.9
> "29" 4 "C" "nut" 71.31111111 86.2 118.4
> "30" 4 "C" "no nut" 115.9555556 131.4 141.9
> "31" 4 "D" "nut" 75.65555556 141.5 92.5
> "32" 4 "D" "no nut" 108.9888889 146.6 122.2
> "33" 5 "A" "nut" 20.2 57.4 14.6
> "34" 5 "A" "no nut" 12.34489796 55.4 13.4
> "35" 5 "B" "nut" 48.98888889 56.3 28.7
> "36" 5 "B" "no nut" 35.65555556 55.8 17.6
> "37" 5 "C" "nut" 22.22222222 45.9 7.3
> "38" 5 "C" "no nut" 9.088888889 55.6 20.5
> "39" 5 "D" "nut" 64.44444444 86.1 61.7
> "40" 5 "D" "no nut" 15.65555556 75.7 41.8
> "41" 6 "A" "nut" 22.22222222 101.1 69.8
> "42" 6 "A" "no nut" 53.33333333 171.2 113.5
> "43" 6 "B" "nut" 37.87777778 111.1 66.8
> "44" 6 "B" "no nut" 46.96666667 120.8 83.8
> "45" 6 "C" "nut" 17.87777778 120.7 84
> "46" 6 "C" "no nut" 21.21212121 116.3 76.8
> "47" 6 "D" "nut" 24.01304348 86.1 64.6
> "48" 6 "D" "no nut" 29.51034483 112.5 51.9
> 
> The basic question is: When is it appropriate to use a MANOVA-based repeated measures design over a mixed effects model? 
> 
> For example, the MANOVA approach:
> library(car)
> repeated.manova <- lm(cbind(t1,t3,t4)~nut+plot+quad, data=manova.data)
> Manova(repeated.manova)
> 
> nut is not significant and there are 40 denominator df. 
> 
> If I set up the data and run lme:
> 
> mixed.dat <- melt(manova.data, id=c("plot","quad","nut"))
> colnames(mixed.dat)[4:5] <- c("time","prod")
> mixed.dat$time <- as.numeric(mixed.dat$time))
> 
> library(nlme)
> lme.repeated <- lme(prod~nut, random=~nut|time, data=mixed.dat)
> anova(lme.repeated)
> 
> Gives 140 denominator df. I'm also not sure this is the appropriate set up for a repeated measures design. Running the following code seems more in line with what I've read to take into account the correlation in observations within the same plot:
> 
> lme.repeated2 <- lme(prod~nut*time, random=~time|plot, data=mixed.dat)
> anova(lme.repeated2)
> 
> This model seems much more appropriate, as observations within plots are now allowed to be correlated, but there is still a huge difference between the MANOVA-based approach and the mixed-effects-based approach, as the mixed-effects model gives me a significant result. The MANOVA assumes that I have three (correlated) observations on 48 independent units, whereas the lme approach assumes that I have 144 observations on correlated units. Also not sure if that interpretation is correct.
> 
> Alternatively, I used lmer() for non-nested, multilevel models allowing observations to be correlated in space and time:
> 
> repeated.mixed3 <- lmer(prod~nut + (1|plot) + (1|time), data=mixed.dat)
> repeated.mixed4 <- lmer(prod~ (1|plot) + (1|time), data=mixed.dat)
> anova(repeated.mixed3, repeated.mixed4)
> 
> This approach also gives me a significant result. Which of these is the most appropriate? The differences between lme and lmer are trivial (in this case), but the difference between the MANOVA approach and mixed-effects is substantial. I figure the MANOVA approach is probably in correct on account of the nested design, but my question extends to situations when the design is not nested. 
> 
> Thanks in advance for your help,
> 

You need to be careful to compare similar models. Your MANOVA model is effectively treating plot:quad:nut (i.e. anything not involving time) as the observational unit. In particular, this ignores the pairing of the two nut levels at the same level of plot:quad. Also notice that a MANOVA model tests the effect of a trivariate outcome by comparing a model with three parameters for the effect (one for each variate) with a model with no effect at all, i.e. the test has three d.f. So your MANOVA test is effectively that of time:nut in the following model:

> mixed.dat$ia <- with(mixed.dat, interaction(plot,quad,nut))
> lme.repeated2 <- lme(prod~time/nut, random=~time|ia, data=mixed.dat)
> anova(lme.repeated2)
            numDF denDF   F-value p-value
(Intercept)     1    91 155.47120  <.0001
time            2    91  60.29474  <.0001
time:nut        3    91   1.08992  0.3575

which is fairly similar to 

> anova(repeated.manova)
Analysis of Variance Table

            Df  Pillai approx F num Df den Df Pr(>F)    
(Intercept)  1 0.85717   88.019      3     44 <2e-16 ***
nut          1 0.06636    1.043      3     44 0.3832    
Residuals   46                                          

At this point, a rather long thread could be spun about the differences between the two analyses, but I think you'll agree that they are broadly in agreement. Both are pretty clearly wrong though. At the very least, you'd want to include the design properly, especially the paired nature of the comparisons of levels of nut.

-?d


> Nathan
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From bbolker at gmail.com  Sun Apr  1 18:39:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 1 Apr 2012 16:39:10 +0000 (UTC)
Subject: [R-sig-ME] lme4a installation
References: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>
Message-ID: <loom.20120401T172659-142@post.gmane.org>

Boris Shor <boris at ...> writes:

> I saw your post on the mixed models mailing list. I'm running R2.15 and I'm
> getting the same installation error for "lme4a". Did you resolve the issue?
> 

  I'm not sure who you're responding to ...
  We're working to update the versions at 
http://lme4.r-forge.r-project.org/repos ; these have been uploaded to SVN
and should be online within 24 hours (along with more detailed installation
instructions).

  However, in the meantime, as I responded to an earlier post, lme4a is
now deprecated in favor of the r-forge version of lme4.  If you find that
there's anything you can't do with r-forge lme4 (version 0.999902344-0)
that you could do with lme4a, please let the maintainers know ...

  Ben Bolker



From bbolker at gmail.com  Sun Apr  1 19:30:23 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 01 Apr 2012 13:30:23 -0400
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
	<CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
	<CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>
Message-ID: <4F7890AF.9010106@gmail.com>

On 12-04-01 03:50 AM, Douglas Bates wrote:
> On Fri, Mar 30, 2012 at 3:44 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> Hi Ben,
>>
>> Many thanks for the help.  I tried your suggestion out and it seemed
>> to work (and I learned a bit about lme4 in the process :)
>>
>> library(lme4)
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>> library(numDeriv)
>> fm1_thpar <- getME(fm1,"theta")
>> h <- hessian(fm1Fun, fm1_thpar)
>> g <- grad(fm1Fun, fm1_thpar)
>>
>> which I can use (I think) to get standard errors of the variance parameters.
>>
>> library(MASS)
>> sqrt(diag(ginv(h)))
>>
>> which plug into a longer formula that attempts to test the
>> significance of indirect effects.  Given that the variance parameters
>> are not normally distributed, my hunch is that even though both fixed
>> and random effects (and their variances/standard errors) are being
>> built into the mediation test, it is probably not well-behaved either,
>> but it is nice to be able to try to replicate models in the article.
>> Even if they are not perfectly accurate, I am hoping I can use them as
>> a sanity check for when I play with some mcmc and bootstrapping.
> 
> I have been travelling and haven't tracked messages on the list
> closely so I might have missed something here.  What do you mean by
> "the variance parameters"?  The theta parameters aren't variances and
> covariances.  They are values from the relative covariance factor.
> For the model you fit the first element of theta is the standard
> deviation of the intercept random effects divided by the standard
> deviation of the per-observation noise.  The second and third elements
> only make sense in terms of the Cholesky factor of the relative
> variance-covariance matrix.
> 
> This choice is not arbitrary.  Although we are accustomed to thinking
> in terms of variances and covariances or in terms of standard
> deviations and correlations, these are difficult scales on which to
> optimize because the constraints on these values are complicated
> nonlinear constraints.
> 
> So as long as you recognize that the "variance parameters" aren't
> variances or covariances you should be okay.

  The warning is worthwhile.  I haven't taken enough time to figure out
the context (Appendix of

http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf

as stated), but to me it actually seems that the context there is
actually using the RE variances as plug-in estimates (i.e. ignoring
their uncertainty) ... ??


> 
>> R Under development (unstable) (2012-03-29 r58868)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] MASS_7.3-17        reshape2_1.2.1     numDeriv_2012.3-1  lme4_0.999902344-0
>> [5] Matrix_1.0-6       lattice_0.20-6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.16.0    minqa_1.2.0    nlme_3.1-103   plyr_1.7.1     splines_2.16.0
>> [6] stringr_0.6    tools_2.16.0
>>
>> On Mon, Mar 19, 2012 at 12:15 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>> Joshua Wiley <jwiley.psych at ...> writes:
>>>
>>>>
>>>> Hi,
>>>>
>>>> I am trying to use a multivariate mixed effects linear model to
>>>> examine mediation.  This works fine.  The final step is to compute the
>>>> indirect effect and its standard error.  The indirect effect is easy
>>>> (product of coefficients plus their covariance).  For the standard
>>>> error, I need the gradient (D) and the hessian (H):
>>>> the variance is then:
>>>>
>>>> D'\Sigma(\theta)D + \frac{1}{2}Tr{(\mathbf{H}\boldsymbol{\Sigma}(\theta))^{2}}
>>>>
>>>> This is all given in the Appendix of
>>>> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>>>>
>>>> Is there a way to get this out of a mer class object?  Looking at
>>>> class?mer, the appropriate bits of vcov give me $\Sigma(\theta)$.  @V
>>>> seems like it would give me the gradient but is null for a basic lmer
>>>> model.
>>>
>>>  If you're willing to try out the development version (i.e., lme4
>>> from r-forge), I think you can do this as follows:
>>>
>>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>>> library(numDeriv)
>>> fm1_thpar <- getME(fm1,"theta")
>>> h <- hessian(fm1Fun,fm1_thpar)
>>>
>>>  and similarly for the gradient.
>>>
>>>  Let me know how it goes.
>>>
>>>  Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ramos.grad.student at gmail.com  Sun Apr  1 19:35:41 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Sun, 1 Apr 2012 10:35:41 -0700
Subject: [R-sig-ME] lme4a installation
In-Reply-To: <loom.20120401T172659-142@post.gmane.org>
References: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>
	<loom.20120401T172659-142@post.gmane.org>
Message-ID: <CAHawB9v65g-p=F5yPykemW-p=E+8KKZY5XWEDuPuHW7pvmJRhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120401/14ad233e/attachment-0002.pl>

From j.hadfield at ed.ac.uk  Sun Apr  1 20:30:03 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 01 Apr 2012 19:30:03 +0100
Subject: [R-sig-ME] MCMC model selection reference
In-Reply-To: <000a01cd100d$ec8a0560$c59e1020$@msu.edu>
References: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>
	<000a01cd100d$ec8a0560$c59e1020$@msu.edu>
Message-ID: <20120401193003.10433zixro7z1egw@www.staffmail.ed.ac.uk>

Hi,

My understanding of DIC (and information criterion generally) is  
woeful, but here are my thoughts on DIC - which I hope others will  
correct if they disagree.

Does DIC wok in principal  - yes, could it work in practice  -  
sometimes, does it work in practice - rarely (for hierarchical models).

DIC needs to be "focused". Imagine you have single Gaussian  
observations (y) on children within schools.  We have fixed effects b,  
random effects u, and variance parameters Vs (between school variance)  
and Ve (within school variance). We also have the fixed-effect design  
matrix X and random-effect design matrix Z.  We could calculate the  
deviance using two likelihoods:

a) dmvnorm(y, X%*%b+Z%*%u, I*Ve)
b) dmvnorm(y, X%*%b, Z%*%t(Z)*Vs+I*Ve)

In a) we are conditioning on the school effects in b) we marginalise  
them. The focus in a) is of the form "can we predict new observations  
in *these* schools" and in b) "can we predict new observations in  
*new* schools".

As a parent you're probably interested in a) as a scientist you're  
probably interested in b).

MCMCglmm (and I believe WinBUGS, depending on how the model is  
parameterised) focuses at the highest level a). The reason for this is  
that MCMCglmm Gibbs samples u and then Gibbs samples Vs conditional on  
u with out the need to calculate b) which is expensive (If DIC=TRUE,  
a) will be calculated and this is easy). Presumably WinBUGS could  
calculate a) or b) depending on how it is set up, but I think b) is  
more usual (?) because of performance issues.

With over-dispersed non-Gaussian data the case for DIC (as  
implemented) is very bad, because the highest level is the latent  
variable (linear predictor).  Lets imagine our observations on  
children were how many times they missed the bus and we treated them  
as log-normal Poisson. DIC would be focused at "can we predict how  
many times *these* children miss the bus".

Modelling over-dispersion using a two-parameter distribution (without  
observational-level effects), perhaps a negative binomial in our  
example, may get us back to "can we predict how many times children  
from *these* schools miss the bus" but getting down to a) may be more  
difficult because with non-Gaussian data the random effects cannot be  
marginalised analytically.

For non-Gaussian data I never use DIC, and have seriously considered  
removing it from MCMCglmm.

Cheers,

Jarrod



Quoting "Steven J. Pierce" <pierces1 at msu.edu> on Sun, 1 Apr 2012  
09:47:03 -0400:

> Here are a couple references on DIC that I happen to have handy:
>
> Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & van der Linde, A.
> (2002). Bayesian measures of model complexity and fit. Journal of the Royal
> Statistical Society: Series B (Statistical Methodology), 64(4), 583-639.
> doi: 10.1111/1467-9868.00353  http://www.jstor.org/stable/3088806
>
> Barnett, A. G., Koper, N., Dobson, A. J., Schmiegelow, F., & Manseau, M.
> (2010). Using information criteria to select the correct variance-covariance
> structure for longitudinal data in ecology. Methods in Ecology and
> Evolution, 1(1), 15-24. doi: 10.1111/j.2041-210X.2009.00009.x
> http://dx.doi.org/10.1111/j.2041-210X.2009.00009.x
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Ray Danner [mailto:danner.ray at gmail.com]
> Sent: Saturday, March 31, 2012 2:24 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] MCMC model selection reference
>
> Dear list,
>
> I'm looking for guidance on model selection using DIC values.  I'm
> particularly interested in comparing mixed models created with the
> package MCMCglmm.  I currently use AIC for my models built with lme
> and (g)lmer and like the ability to calculate evidence ratios and
> model average predictions, which are very easy for readers to
> conceptualize.  AICcmodavg is great for these things.
>
> Can anyone recommend a resource that describes the appropriate use of
> DIC for model selection (and its limitations)?  I'm mainly an
> ecologist, so a less-technical treatment would be ideal.
>
> My main questions are:
> 1. Can DIC be used to select among mixed models?
> Kery and Schaub (2012 p. 42) raise concerns about counting the correct
> number of parameters and state that WinBUGS does not calculate them
> appropriately, though Millar (2009) provides a method that is
> appropriate for hierarchical models.  On the other hand, Saveliev et
> al. (2009) use DIC to compare models with random effects built with
> the BRugs package.  Hadfield's MCMCglmm Tutorial says that lower DIC
> is better, but doesn't give details about use.
>
> 2. Any rules of thumb on what constitutes sufficiently large deltaDIC
> values?  Are evidence ratios acceptable?
>
> 3. Can DIC be used to calculate model average predictions?
>
> Thanks in advance and please forgive me if I missed your publication.
> Ray
>
>
> Refs
> Kery and Schaub. 2012. Bayesian Population Analysis Using WinBUGS: A
> Hierarchical Perspective.
> Millar. 2009. Comparison of hierarchical Bayesian models for
> overdispersed count data using DIC and Bayes' Factors. Biometrics
> 65:962-969.
> Saveliev et al. 2009. Ch. 23 in Zuur, Mixed Effects Models and
> Extensions in Ecology with R.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From jwiley.psych at gmail.com  Sun Apr  1 22:02:10 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 1 Apr 2012 13:02:10 -0700
Subject: [R-sig-ME] extracting gradient and hessian matrix from lme4
In-Reply-To: <4F7890AF.9010106@gmail.com>
References: <CANz9Z_J=Kttq+sBKD86bFiXHoJm0EZAtFfWfJcpZjzzF0r6HdQ@mail.gmail.com>
	<loom.20120319T195110-259@post.gmane.org>
	<CANz9Z_L6-xysLntS8R2Dr0MqVARQf_BoLPJcvfSuQfHXQ4arJA@mail.gmail.com>
	<CAO7JsnS=Kv3ERNUOqe=evjJ2UKZHf6E=1HKeGMzUgSV2B2tTbw@mail.gmail.com>
	<4F7890AF.9010106@gmail.com>
Message-ID: <CANz9Z_LJnsmf5ZAtaPcaGAY-87GGBCAPT4bSV6EVX3Rib7Gj5w@mail.gmail.com>

Thanks to both of you.  Really.  Your time both developing software
and supporting it is amazing and greatly appreciated.

On Sun, Apr 1, 2012 at 10:30 AM, Ben Bolker <bbolker at gmail.com> wrote:
> On 12-04-01 03:50 AM, Douglas Bates wrote:
>> On Fri, Mar 30, 2012 at 3:44 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>> Hi Ben,
>>>
>>> Many thanks for the help. ?I tried your suggestion out and it seemed
>>> to work (and I learned a bit about lme4 in the process :)
>>>
>>> library(lme4)
>>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>> fm1Fun <- update(fm1,devFunOnly=TRUE)
>>> library(numDeriv)
>>> fm1_thpar <- getME(fm1,"theta")
>>> h <- hessian(fm1Fun, fm1_thpar)
>>> g <- grad(fm1Fun, fm1_thpar)
>>>
>>> which I can use (I think) to get standard errors of the variance parameters.
>>>
>>> library(MASS)
>>> sqrt(diag(ginv(h)))
>>>
>>> which plug into a longer formula that attempts to test the
>>> significance of indirect effects. ?Given that the variance parameters
>>> are not normally distributed, my hunch is that even though both fixed
>>> and random effects (and their variances/standard errors) are being
>>> built into the mediation test, it is probably not well-behaved either,
>>> but it is nice to be able to try to replicate models in the article.
>>> Even if they are not perfectly accurate, I am hoping I can use them as
>>> a sanity check for when I play with some mcmc and bootstrapping.
>>
>> I have been travelling and haven't tracked messages on the list
>> closely so I might have missed something here. ?What do you mean by
>> "the variance parameters"? ?The theta parameters aren't variances and
>> covariances. ?They are values from the relative covariance factor.
>> For the model you fit the first element of theta is the standard
>> deviation of the intercept random effects divided by the standard
>> deviation of the per-observation noise. ?The second and third elements
>> only make sense in terms of the Cholesky factor of the relative
>> variance-covariance matrix.

Okay, good to know.  Thank you for pointing this out.  I have a copy
of your book (Pinheiro & Bates) and the draft chapters for lme4 on
R-forge.  If there are any other references you think would help me
gain a good understanding of how lme4 works, I would happily get and
read them.

>>
>> This choice is not arbitrary. ?Although we are accustomed to thinking
>> in terms of variances and covariances or in terms of standard
>> deviations and correlations, these are difficult scales on which to
>> optimize because the constraints on these values are complicated
>> nonlinear constraints.

That makes sense.

>> So as long as you recognize that the "variance parameters" aren't
>> variances or covariances you should be okay.
>
> ?The warning is worthwhile. ?I haven't taken enough time to figure out
> the context (Appendix of
>
> http://www.unc.edu/~dbauer/manuscripts/bauer-preacher-gil-PM-2006.pdf
>
> as stated), but to me it actually seems that the context there is
> actually using the RE variances as plug-in estimates (i.e. ignoring
> their uncertainty) ... ??

Here is more context and an example but I certainly do not expect
anyone to read through all of this and try it.  You have done more
than enough already.

Perhaps an example closer to a real use case would be helpful.  In
psychology, it is common to think of mediation, where one variable
(say x) is associated with an outcome of interest (say y), but the
cause link is believed to be through a third variable, the mediator
(say m).  To give a hypothetical economics example, suppose taxes are
lowered (x), which causes business and people to be more productive
and earn more (m), which causes overall government revenue (y) to
increase, even though the tax rate is lower.

Sometimes diagrammed:
x -> m -> y

causality is often the theory, but is not necessarily assessed so set
that aside for the moment.  The interest is in the average indirect
effect of x on y through the variable m.  Again in psychology, this is
usually assessed as the product of coefficients of x predicting m and
m predicting y, controlling for x.  In models with mixed effects, this
complicated by the fact that one or both of these effects may be
random, not fixed.

To accurately estimate all the necessary parameters, it is necessary
to have them in a single model.  This can be done in a structural
equation model framework with a series of equations or in mixed
effects models by 'stacking' the two dependent variables (y and m) and
using indicator variables.  The paper referenced presented a technique
for estimating the indirect effect (say g):

g = ab + cov(a, b)

where a is the average RE of x predicting m, and b is the average RE
of m predicting y.  The appendix of the paper that I referenced uses
covariance matrix of the REs, gradient, and hessian to come up with an
estimate of

Var(g) to construct an assymptotic test like:

g/sqrt(Var(g))

in order to test whether the average indirect RE is significantly
different from zero.  I have my doubts about how accurate this
approach is given that products of coefficients tend not to be
normally distributed, and I do want to try other methods for creating
a confidence interval or perhaps move to a bayesian framework and use
a credible interval.  But for first steps, I figured try to replicate
the article (which was done in SAS) in R, and then go on to try
additional techniques.  Here is a dataset online and R code for the
type of model I am trying to run.  I have been able to replicate the
paper's point estimate of the indirect effect (the authors provide
sample data and SAS code), in nlme, and fairly close in lme4
(complicated by difficulties for me to get a heterogenous residual
variance structure for the stacked outcomes).

##############################################
require(foreign)
d <- read.dta("http://www.ats.ucla.edu/stat/data/ml_sim.dta")

require(reshape2)
d$fid <- 1:nrow(d)
stacked <- melt(d, id.vars = c("fid", "id", "x", "m"),
  measure.vars = c("y", "m"), value.name = "z")
stacked <- within(stacked, {
    sy <- as.integer(variable == "y")
    sm <- as.integer(variable == "m")
})

require(lme4)
mm <- lmer(z ~ 0 + sm + sm:x + sy + sy:m + sy:x +
              (0 + sm + sm:x + sy + sy:m + sy:x | id) +
              (0 + sm | fid), data = stacked)
summary(mm)

## effect of interest is x's effect on y through m
## i.e., sm:x * sy:m + cov_{sm:x, sy:m} because they are REs
## (0 + sm | fid) is an attempt to account for differential
## variability in the m versus y outcomes, something
## (though far from exactly) like this in nlme:

require(nlme)
mm.alt <- lme(z ~ 0 + sm + sm:x + sy + sy:m + sy:x, data = stacked,
       random = ~ 0 + sm + sm:x + sy + sy:m + sy:x | id,
       weights = varIdent(form = ~ 1 | variable))
summary(mm.alt)
##############################################

Cheers,

Josh

[snip]



From denis.vile at supagro.inra.fr  Sun Apr  1 22:31:48 2012
From: denis.vile at supagro.inra.fr (Denis Vile)
Date: Sun, 01 Apr 2012 22:31:48 +0200
Subject: [R-sig-ME] crossed effects with lmer but correlation structure
 with lme
In-Reply-To: <loom.20120330T215721-195@post.gmane.org>
References: <CDB7793F-44BC-4D8E-BC07-6F0008ECEF05@usherbrooke.ca>
	<4F7418A5.7050500@supagro.inra.fr>
	<4F7594C1.1000101@supagro.inra.fr>
	<loom.20120330T215721-195@post.gmane.org>
Message-ID: <4F78BB34.2060801@supagro.inra.fr>

Thank you very much Ben ! I'm going to look at this attentively.
Sincerely,
Denis

Le 30/03/2012 22:09, Ben Bolker a ?crit :
> Denis Vile<denis.vile at ...>  writes:
>
>> Hi all,
>>
>> Was my problem not sufficiently well exposed or no one could help me ?
>>
>> Sincerely,
>>
>> Denis
>    The canonical reference for this is p. 163ff of Pinheiro
> and Bates 2000 (section 4.2.2,  http://tinyurl.com/crossedRE )
> You are correct that lme4 doesn't handle 'R-side' correlation
> structures, nor will it in the near future ...
>
>
>   (I've added this information to glmm.wikidot.com/faq ...)
>
>    Ben Bolker
>
>
>> Le 29/03/2012 10:09, Denis Vile a ?crit :
>>> Dear R users,
>>>
>>> I'm trying to fit a crossed-effects mixed model that would include a
>>> spatial correlation structure..
>>> The data come from four controlled experiments (control, treatment1,
>>> treatment2, treatment1+treatment2) on plants grown in a growth
>>> chamber.  Individual replicates of different genotypes were grown
>>> together and response traits were measured. A covariate X is included
>>> in the model with a quadratic form.
>>>
>>> We fitted the following model using lmer:
>>>
>>> fm1<- lmer(Y ~ 1 + Trt1*Trt2*poly(X, degree=2, raw=T) +
>>> (1|idGenotype) + (1|Trt2:idGenotype) + (1|Trt1:idGenotype) +
>>>              (1|Trt1:Trt2:idGenotype), data=...)
>>>
>    [snip snip snip]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 

*Denis VILE*
Charg? de Recherche
Laboratoire d'Ecophysiologie des Plantes sous Stress Environnementaux 
(*LEPSE*)
UMR 759 *INRA*-SUPAGRO // Institut de Biologie Int?grative des Plantes 
(IBIP, b?t 7)
2 place Pierre Viala
34060 Montpellier Cedex 2
Tel +33 (0)4 99 61 31 87
Fax +33 (0)4 67 52 21 16
http://www1.montpellier.inra.fr/ibip/lepse/



From dhocking at wildcats.unh.edu  Sun Apr  1 20:46:31 2012
From: dhocking at wildcats.unh.edu (Daniel Hocking)
Date: Sun, 1 Apr 2012 14:46:31 -0400
Subject: [R-sig-ME]  MCMC model selection reference
In-Reply-To: <mailman.6435.1333301440.4502.r-sig-mixed-models@r-project.org>
References: <mailman.6435.1333301440.4502.r-sig-mixed-models@r-project.org>
Message-ID: <94169223-CDB8-4026-9EB5-A48B4A9FA956@wildcats.unh.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120401/efa1794a/attachment-0002.pl>

From c.ryan.king at gmail.com  Mon Apr  2 01:44:06 2012
From: c.ryan.king at gmail.com (Ryan King)
Date: Sun, 1 Apr 2012 18:44:06 -0500
Subject: [R-sig-ME] MCMC model selection reference
Message-ID: <CAEQ+J27t-tbeV14K-ofRHbKh2M1RfnCtBYVXqTsA8RFn4DdT8A@mail.gmail.com>

I'd be interested if you find something good. Lately I've been
interested in a new criterion, WAIC. It's supposed to be an improved
estimate of out-of-sample / cross-validation prediction error (which
DIC is supposed to be also).

Discussion here:
http://andrewgelman.com/2011/06/plummer_on_dic/
http://andrewgelman.com/2011/06/deviance_dic_ai/

>From plummer's 2008 paper discussion:

"The question of what constitutes a noteworthy difference in DIC
between 2 models has not yet received a satisfactory answer. Whereas
calibration scales have been proposed for Bayes factors (Kass and
Raftery, 1995), no credible scale has been proposed for the difference
in DIC between 2 models. Indeed, such a scale is unlikely be useful.
Ripley (1996) shows that the sampling error of the difference in AIC
between 2 models is Op(1) when the models are nested, and the smaller
model is true, but the error may be Op(sqrt(n)) for nonnested models.
No absolute scale for interpretation of AIC could be valid in both
situations. DIC inherits this behavior since it includes AIC as a
special case."

The related question of how much cross-validation error is a lot is
unknown; in fact it is known that there does not exist an unbiased
estimate of the variance of CV error.
Bengio, Y. & Grandvalet, Y. No unbiased estimator of the variance of
k-fold cross-validation. The Journal of Machine Learning Research 5,
1089?1105 (2004).

There are concentration
inequalities which are generally too loose to be useful (or so I'm
told). There are
some promising recent theory papers that I haven't been able to fully
read. Plummer goes on to suggest parametric simulation to calibrate
his DIC variant. That or non-parametric simulation (bootstrap,
permutation) is all that I've seen applied papers do. I've tried
simulating calibration scales and found that the sampling variance of
 CV depends on how complex the model is / is allowed to be.

The WAIC paper is nice in that is says explicitly what it is trying
the calculate: the cross-validation loss of the log-evidence and shows
its relationship to DIC and BIC.

Ryan King
University of Chicago
Dept Health Studies



From geralttee at gmail.com  Mon Apr  2 10:30:21 2012
From: geralttee at gmail.com (Szymek Drobniak)
Date: Mon, 2 Apr 2012 10:30:21 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 64, Issue 3
In-Reply-To: <mailman.6456.1333320954.4502.r-sig-mixed-models@r-project.org>
References: <mailman.6456.1333320954.4502.r-sig-mixed-models@r-project.org>
Message-ID: <CANXb-o5uKXY78U10+xTv3ZJO6qvGbK2RSJMF0=E62oM_=_RCjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120402/1c6a0716/attachment-0002.pl>

From maechler at stat.math.ethz.ch  Mon Apr  2 17:19:13 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 Apr 2012 17:19:13 +0200
Subject: [R-sig-ME] lme4a installation
In-Reply-To: <loom.20120401T172659-142@post.gmane.org>
References: <CAGddWLSagQiG9zr93SYaCd0GjuyyftPCrPp_=fZ6bfUkEPy3LQ@mail.gmail.com>
	<loom.20120401T172659-142@post.gmane.org>
Message-ID: <20345.50033.264322.607310@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Sun, 1 Apr 2012 16:39:10 +0000 (UTC) writes:

    > Boris Shor <boris at ...> writes:
    >> I saw your post on the mixed models mailing list. I'm running R2.15
    >> and I'm getting the same installation error for "lme4a". Did you
    >> resolve the issue?
    >> 

    > I'm not sure who you're responding to ...  We're working to update the
    > versions at http://lme4.r-forge.r-project.org/repos ; these have been
    > uploaded to SVN and should be online within 24 hours (along with more
    > detailed installation instructions).

    > However, in the meantime, as I responded to an earlier post, lme4a is
    > now deprecated in favor of the r-forge version of lme4.  If you find
    > that there's anything you can't do with r-forge lme4 (version
    > 0.999902344-0) that you could do with lme4a, please let the maintainers
    > know ...

 lmer(*,  sparseX = TRUE)
glmer(*,  sparseX = TRUE)


{ but then, the maintainers know ;-) }



From bbolker at gmail.com  Mon Apr  2 17:42:09 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Apr 2012 15:42:09 +0000 (UTC)
Subject: [R-sig-ME] interpreting random effects
References: <CAM1PXy3HPWC2we3Vj9hd2b02jJvC0AGm8atFXn3v=tcjnsvZnw@mail.gmail.com>
Message-ID: <loom.20120402T173632-237@post.gmane.org>

Keith Larson <keith.larson at ...> writes:

> 
> I have have measured the trait frequency for a "mountain" associated
> allele across a number of sites and years. In my (glmer) model I have
> summarized the allele frequency by site and year as the dependent
> (binomial) variable and specified site and year as random effects. The
> fixed effects are latitude, longitude, altitude, and
> latitude|longitude. When I run the model and then drop and update each
> random effect separately to see if they are important to the model,
> site appears to be significant and year does not. Two questions:
> 
> 1. Can I re-summarize my dependent variable for by site rather than
> site and year?

  You certainly *can*.  What is your goal in presenting this summary?

> 2. Given that we did not sample each site the same number of times
> (years) and have different numbers of samples at each site (and year),
> should I standardize my dependent variable?

  Depending on your answer to the question above, I would guess that
the best predictor of allele frequency at a given site would be the
prediction based on the fixed effects, plus the random effect of site
(back-transformed from the scale of the linear predictor (log or logit)
to the frequency scale, of course).
Leaving year in the model, but setting its prediction to zero, should
give you a reasonable measure of "expected allele frequency at site X
in a randomly chosen year", and should handle the unequal weighting.



From helixed2 at yahoo.com  Mon Apr  2 18:25:25 2012
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Mon, 2 Apr 2012 09:25:25 -0700 (PDT)
Subject: [R-sig-ME] Binomial GLMM -- denominator of proportion as fixed
	effect predictor?
Message-ID: <1333383925.58110.YahooMailNeo@web161805.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120402/0bf6f702/attachment-0002.pl>

From f.calboli at imperial.ac.uk  Mon Apr  2 18:48:35 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 2 Apr 2012 17:48:35 +0100
Subject: [R-sig-ME] cannot connect to
	http://lme4.r-forge.r-project.org/repos/
Message-ID: <BC5D9196-B2BE-4149-B979-8181B24025BF@imperial.ac.uk>

As by subject. I am on a Mac, OS 10.7.3, XCode 4.3.2, CLI stuff installed, fortran installed through http://r.research.att.com/ 

> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.15.0

When I try to connect (through the GUI package manager) to http://lme4.r-forge.r-project.org/repos/ I get:

Warning: unable to access index for repository http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.15/src/contrib

Additionally,

> install.packages("lme4",repos="http://r-forge.r-project.org", dependencies  = T)
Warning: unable to access index for repository http://r-forge.r-project.org/bin/macosx/leopard/contrib/2.15
Warning message:
package ?lme4? is not available (for R version 2.15.0) 
> install.packages("lme4",repos="http://r-forge.r-project.org/repos", dependencies  = T)
Warning: unable to access index for repository http://r-forge.r-project.org/repos/bin/macosx/leopard/contrib/2.15
Warning message:
package ?lme4? is not available (for R version 2.15.0) 

though going by hand to the repo I can see both lme4 ane RcppEigen.

BW

Federico








--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From roby.joehanes at nih.gov  Mon Apr  2 20:27:20 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 2 Apr 2012 14:27:20 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
Message-ID: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>

Hi:

I am trying to port pedigreemm to use the new lme4. However, the new lme4 is somewhat opaque to me and hence I need help. Specifically, how can I extract the following terms:
lmf$FL$trms[[tn]]$Zt
lmf$FL$trms[[tn]]$A

The information lies within lmf at pp object, but it is too opaque to me to fish anything out.

I understand that lmf$FL$fl is lmf at flist and that lmer_finalize calls should be replaced with optwrap and mkMerMod. Nevertheless, I think that the lmer or glmer could use some refactoring to ease the calls.

I appreciate any help on these.

Thanks,
Roby



From agalecki at umich.edu  Mon Apr  2 21:57:59 2012
From: agalecki at umich.edu (Andrzej T Galecki 1)
Date: Mon, 02 Apr 2012 15:57:59 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
Message-ID: <0fdcade662bf745019d5178ca7dc992a@umich.edu>


Hi Roby,

Ben prepared getME(} function to extract various components of the model
fit
obtained using lme4.0 and new lme4.

Try 
getME(lmf,"Zt")
getME(lmf,"A")
getME(lmf,"flist")

Andrzej

On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
<roby.joehanes at nih.gov> wrote:
> Hi:
> 
> I am trying to port pedigreemm to use the new lme4. However, the new lme4
> is somewhat opaque to me and hence I need help. Specifically, how can I
> extract the following terms:
> lmf$FL$trms[[tn]]$Zt
> lmf$FL$trms[[tn]]$A
> 
> The information lies within lmf at pp object, but it is too opaque to me to
> fish anything out.
> 
> I understand that lmf$FL$fl is lmf at flist and that lmer_finalize calls
> should be replaced with optwrap and mkMerMod. Nevertheless, I think that
> the lmer or glmer could use some refactoring to ease the calls.
> 
> I appreciate any help on these.
> 
> Thanks,
> Roby
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Mon Apr  2 22:17:49 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Apr 2012 20:17:49 +0000 (UTC)
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
Message-ID: <loom.20120402T221015-332@post.gmane.org>

Andrzej T Galecki 1 <agalecki at ...> writes:

> Ben prepared getME(} function to extract various components of the model
> fit
> obtained using lme4.0 and new lme4.
> 
> Try 
> getME(lmf,"Zt")
> getME(lmf,"A")
> getME(lmf,"flist")
> 
> Andrzej
> 
> On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
> <roby.joehanes at ...> wrote:
> > Hi:
> > 
> > I am trying to port pedigreemm to use the new lme4. However, the new lme4
> > is somewhat opaque to me and hence I need help. Specifically, how can I
> > extract the following terms:
> > lmf$FL$trms[[tn]]$Zt
> > lmf$FL$trms[[tn]]$A
> > 
> > The information lies within lmf <at> pp object, but it is too opaque to me to
> > fish anything out.
> > 
> > I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
> > should be replaced with optwrap and mkMerMod. Nevertheless, I think that
> > the lmer or glmer could use some refactoring to ease the calls.
> > 
> > I appreciate any help on these.
> > 

   A couple of questions:

 1. how broadly are you using A?  Off-list, Doug Bates has commented to
me that defining A is relatively straightforward for LMMs but not necessarily
as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
that people are using it for [GN]LMMs as welll ...

  2. I can't quite tell from your e-mail -- would it be useful to have
the stuff between the first optwrap() and the last mkMerMod abstracted
into a single (exposed) function?  For [GN]LMMs it should probably
also allow control of whether the preliminary "nAGQ=0" optimization
is done or not ...

  (All comments are mine alone, not necessarily speaking for all lme4
authors ...)

  Ben Bolker



From roby.joehanes at nih.gov  Mon Apr  2 22:24:32 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 2 Apr 2012 16:24:32 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <loom.20120402T221015-332@post.gmane.org>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
Message-ID: <C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>

Hi Ben and Andrzej:

Thank you for the info. I am trying to get pedigreemm to work with the new lme4 and I am now stuck on how to translate the following line:
lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt

Because the matrix A is defined in getME method as:
PR$Lambdat %*% PR$Zt

I am still trying to figure the code out. I think we can do away with the A matrix since it is apparently not essential to the computation. I think the crux of the pedigreemm call to the underlying lme4 is in the following short lines:

    pnms <- names(pedigree)
    stopifnot(all(pnms %in% names(getME(lmf, "flist"))))
    asgn <- attr(getME(lmf, "flist"), "assign")
    for (i in seq_along(pedigree)) {
        tn <- which(match(pnms[i], names(getME(lmf, "flist"))) == asgn)
        if (length(tn) > 1)
            stop("a pedigree factor must be associated with only one r.e. term")
        Zt <- getME(lmf, "Zt")
        relfac[[i]] <- relfactor(pedigree[[i]], rownames(Zt))
        lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
    }
    ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize else lme4:::lmer_finalize, lmf)
    ans <- new("pedigreemm", relfac = relfac, ans)

Any help is appreciated.

Thanks,
Roby


On Apr 2, 2012, at 4:17 PM, Ben Bolker wrote:

Andrzej T Galecki 1 <agalecki at ...> writes:

Ben prepared getME(} function to extract various components of the model
fit
obtained using lme4.0 and new lme4.

Try
getME(lmf,"Zt")
getME(lmf,"A")
getME(lmf,"flist")

Andrzej

On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
<roby.joehanes at ...> wrote:
Hi:

I am trying to port pedigreemm to use the new lme4. However, the new lme4
is somewhat opaque to me and hence I need help. Specifically, how can I
extract the following terms:
lmf$FL$trms[[tn]]$Zt
lmf$FL$trms[[tn]]$A

The information lies within lmf <at> pp object, but it is too opaque to me to
fish anything out.

I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
should be replaced with optwrap and mkMerMod. Nevertheless, I think that
the lmer or glmer could use some refactoring to ease the calls.

I appreciate any help on these.


  A couple of questions:

1. how broadly are you using A?  Off-list, Doug Bates has commented to
me that defining A is relatively straightforward for LMMs but not necessarily
as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
that people are using it for [GN]LMMs as welll ...

 2. I can't quite tell from your e-mail -- would it be useful to have
the stuff between the first optwrap() and the last mkMerMod abstracted
into a single (exposed) function?  For [GN]LMMs it should probably
also allow control of whether the preliminary "nAGQ=0" optimization
is done or not ...

 (All comments are mine alone, not necessarily speaking for all lme4
authors ...)

 Ben Bolker



From bbolker at gmail.com  Mon Apr  2 22:22:24 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Apr 2012 20:22:24 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?cannot_connect_to=09http=3A//lme4=2Er-forge?=
	=?utf-8?q?=2Er-project=2Eorg/repos/?=
References: <BC5D9196-B2BE-4149-B979-8181B24025BF@imperial.ac.uk>
Message-ID: <loom.20120402T222103-700@post.gmane.org>

Federico Calboli <f.calboli at ...> writes:

>  As by subject. I am on a Mac, OS 10.7.3, XCode 4.3.2, CLI stuff
> installed, fortran installed through http://r.research.att.com/

 
  [snip]

> When I try to connect (through the GUI package manager) to
> http://lme4.r-forge.r-project.org/repos/ I get: Warning: unable to
> access index for repository
> http://lme4.r-forge.r-project.org/repos/[snip]

  Thanks for the heads-up, this was a screwed-up PACKAGES file.
This is fixed now, should propagate within 24 hours (and in the
meantime you can of course download the files and install them
locally ...)

  Ben Bolker



From roby.joehanes at nih.gov  Tue Apr  3 00:19:04 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 2 Apr 2012 18:19:04 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
Message-ID: <6C288834-4360-4B79-9781-2758C038664E@nih.gov>

Hi all:

Just a follow up: It seems that some changes need to be made in the new lme4 so that the pedigreemm can be modified to use it. They are:
1. To allow the return of all necessary internal variables required for invoking the optimizer (especially rho plus devfun in one call), without invoking the optimizer itself. Right now I did two calls, the first to get the devfun, the second to get the rest. However, I cannot obtain rho in all cases.
#lmerc$doFit <- FALSE # call lmer without pedigree and with doFit = FALSE
l... <- list(...)
lmerc$devFunOnly <- TRUE
devFun <- eval(lmerc, parent.frame())
lmerc$devFunOnly <- FALSE
lmf <- eval(lmerc, parent.frame())

2. Some partitioning of Zt that allows duplicate level names for multiple random factors. That is, if random factors 1 and 2 (let's call them RF1 and RF2) share the same level-string, my current hack will not work. Perhaps someone can propose a better way. My current hack is as follows:
Zt <- getME(lmf, "Zt")
Zt <- Zt[rownames(Zt) %in% levels(getME(lmf, "flist")[[tn]]), ]
(The original was: Zt <- lmf$FL$trms[[tn]]$Zt)

Since I cannot get rho, I cannot realize the lmer_finalize or glmer_finalize. Any help is appreciated. I am stuck right now since I have installed the lme4 SVN version, but the pedigreemm package still assumes the CRAN version.

Thank you,
Roby


On Apr 2, 2012, at 4:24 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

Hi Ben and Andrzej:

Thank you for the info. I am trying to get pedigreemm to work with the new lme4 and I am now stuck on how to translate the following line:
lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt

Because the matrix A is defined in getME method as:
PR$Lambdat %*% PR$Zt

I am still trying to figure the code out. I think we can do away with the A matrix since it is apparently not essential to the computation. I think the crux of the pedigreemm call to the underlying lme4 is in the following short lines:

   pnms <- names(pedigree)
   stopifnot(all(pnms %in% names(getME(lmf, "flist"))))
   asgn <- attr(getME(lmf, "flist"), "assign")
   for (i in seq_along(pedigree)) {
       tn <- which(match(pnms[i], names(getME(lmf, "flist"))) == asgn)
       if (length(tn) > 1)
           stop("a pedigree factor must be associated with only one r.e. term")
       Zt <- getME(lmf, "Zt")
       relfac[[i]] <- relfactor(pedigree[[i]], rownames(Zt))
       lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
   }
   ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize else lme4:::lmer_finalize, lmf)
   ans <- new("pedigreemm", relfac = relfac, ans)

Any help is appreciated.

Thanks,
Roby


On Apr 2, 2012, at 4:17 PM, Ben Bolker wrote:

Andrzej T Galecki 1 <agalecki at ...> writes:

Ben prepared getME(} function to extract various components of the model
fit
obtained using lme4.0 and new lme4.

Try
getME(lmf,"Zt")
getME(lmf,"A")
getME(lmf,"flist")

Andrzej

On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
<roby.joehanes at ...> wrote:
Hi:

I am trying to port pedigreemm to use the new lme4. However, the new lme4
is somewhat opaque to me and hence I need help. Specifically, how can I
extract the following terms:
lmf$FL$trms[[tn]]$Zt
lmf$FL$trms[[tn]]$A

The information lies within lmf <at> pp object, but it is too opaque to me to
fish anything out.

I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
should be replaced with optwrap and mkMerMod. Nevertheless, I think that
the lmer or glmer could use some refactoring to ease the calls.

I appreciate any help on these.


 A couple of questions:

1. how broadly are you using A?  Off-list, Doug Bates has commented to
me that defining A is relatively straightforward for LMMs but not necessarily
as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
that people are using it for [GN]LMMs as welll ...

2. I can't quite tell from your e-mail -- would it be useful to have
the stuff between the first optwrap() and the last mkMerMod abstracted
into a single (exposed) function?  For [GN]LMMs it should probably
also allow control of whether the preliminary "nAGQ=0" optimization
is done or not ...

(All comments are mine alone, not necessarily speaking for all lme4
authors ...)

Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From djsamperi at gmail.com  Tue Apr  3 06:32:40 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 3 Apr 2012 00:32:40 -0400
Subject: [R-sig-ME] Group selection and multi-level modeling
Message-ID: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>

The new E. O. Wilson book 'The Social Conquest of Earth" claims
that the long dismissed idea of group selection is gaining some
traction in part due to "multi-level modeling."

Can anyone point to work that aims to support this idea and
that employs the kind of models and software that is discussed
here on the SIG-ME list?

Thanks,
Dominick



From David.Duffy at qimr.edu.au  Tue Apr  3 07:16:53 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 3 Apr 2012 15:16:53 +1000 (EST)
Subject: [R-sig-ME] Group selection and multi-level modeling
In-Reply-To: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>
References: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1204031509540.1624@orpheus.qimr.edu.au>

On Tue, 3 Apr 2012, Dominick Samperi wrote:

> The new E. O. Wilson book 'The Social Conquest of Earth" claims
> that the long dismissed idea of group selection is gaining some
> traction in part due to "multi-level modeling."
>
> Can anyone point to work that aims to support this idea and
> that employs the kind of models and software that is discussed
> here on the SIG-ME list?

Like http://www.pnas.org/content/108/35/14426.full (uses MLwin)?
Are you thinking of multi-level selection, perhaps?  From my limited 
reading, group selection is still pooh-poohed by a lot of people in the 
field.

I am more familiar with attempts to model assortment and gene-environment 
covariation, which give rise to recursive systems that are more easily 
modelled in a structural equation type framework.

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From djsamperi at gmail.com  Tue Apr  3 14:57:53 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 3 Apr 2012 08:57:53 -0400
Subject: [R-sig-ME] Group selection and multi-level modeling
In-Reply-To: <Pine.LNX.4.64.1204031509540.1624@orpheus.qimr.edu.au>
References: <CADUbQ5hqV+BePE-RgkY6LWyXrJte2nXt8sVkL9cayvxdBGQ9CQ@mail.gmail.com>
	<Pine.LNX.4.64.1204031509540.1624@orpheus.qimr.edu.au>
Message-ID: <CADUbQ5jbJZBhgUqP1kWHaMb8NY0QuiKr9c3ahDsaL-bJe+oBRQ@mail.gmail.com>

On Tue, Apr 3, 2012 at 1:16 AM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Tue, 3 Apr 2012, Dominick Samperi wrote:
>
>> The new E. O. Wilson book 'The Social Conquest of Earth" claims
>> that the long dismissed idea of group selection is gaining some
>> traction in part due to "multi-level modeling."
>>
>> Can anyone point to work that aims to support this idea and
>> that employs the kind of models and software that is discussed
>> here on the SIG-ME list?
>
>
> Like http://www.pnas.org/content/108/35/14426.full (uses MLwin)?
> Are you thinking of multi-level selection, perhaps? ?From my limited
> reading, group selection is still pooh-poohed by a lot of people in the
> field.

Thank you for the pointer David. This article seems to challenge the idea
by replacing group selection notions with environmental effects. I am
thinking of
"group selection" as multi-level selection, which would include the
environment (another level).

Wilson says the new understanding "opposes the theory of inclusive fitness
and replaces it with standard models of population genetics applied to
multiple levels of natural selection."

Perhaps the term "group selection" simply comes with too much baggage
and can be easily misinterpreted.

Dominick

> I am more familiar with attempts to model assortment and gene-environment
> covariation, which give rise to recursive systems that are more easily
> modelled in a structural equation type framework.
>
> Just 2c, David Duffy.
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v



From roby.joehanes at nih.gov  Tue Apr  3 19:53:41 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 3 Apr 2012 13:53:41 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <6C288834-4360-4B79-9781-2758C038664E@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
Message-ID: <85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>

Hi all:

I have created a patch for the latest lmer.R to accommodate calls by pedigreemm. I see that there is potentially a way to create a single "finalize" method instead of one for each lmer, glmer, and nlmer. I assume that nAGQ is 0 for lmer, correct? Or is it possible for glmer or nlmer to specify nAGQ=0?

Perhaps I should submit the patch into the patch database to see whether it is accepted or not. If it is accepted, then I can make the changes to pedigreemm accordingly.

Thank you,
Roby


On Apr 2, 2012, at 6:19 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi all:
>
> Just a follow up: It seems that some changes need to be made in the new lme4 so that the pedigreemm can be modified to use it. They are:
> 1. To allow the return of all necessary internal variables required for invoking the optimizer (especially rho plus devfun in one call), without invoking the optimizer itself. Right now I did two calls, the first to get the devfun, the second to get the rest. However, I cannot obtain rho in all cases.
> #lmerc$doFit <- FALSE # call lmer without pedigree and with doFit = FALSE
> l... <- list(...)
> lmerc$devFunOnly <- TRUE
> devFun <- eval(lmerc, parent.frame())
> lmerc$devFunOnly <- FALSE
> lmf <- eval(lmerc, parent.frame())
>
> 2. Some partitioning of Zt that allows duplicate level names for multiple random factors. That is, if random factors 1 and 2 (let's call them RF1 and RF2) share the same level-string, my current hack will not work. Perhaps someone can propose a better way. My current hack is as follows:
> Zt <- getME(lmf, "Zt")
> Zt <- Zt[rownames(Zt) %in% levels(getME(lmf, "flist")[[tn]]), ]
> (The original was: Zt <- lmf$FL$trms[[tn]]$Zt)
>
> Since I cannot get rho, I cannot realize the lmer_finalize or glmer_finalize. Any help is appreciated. I am stuck right now since I have installed the lme4 SVN version, but the pedigreemm package still assumes the CRAN version.
>
> Thank you,
> Roby
>
>
> On Apr 2, 2012, at 4:24 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:
>
> Hi Ben and Andrzej:
>
> Thank you for the info. I am trying to get pedigreemm to work with the new lme4 and I am now stuck on how to translate the following line:
> lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
>
> Because the matrix A is defined in getME method as:
> PR$Lambdat %*% PR$Zt
>
> I am still trying to figure the code out. I think we can do away with the A matrix since it is apparently not essential to the computation. I think the crux of the pedigreemm call to the underlying lme4 is in the following short lines:
>
>   pnms <- names(pedigree)
>   stopifnot(all(pnms %in% names(getME(lmf, "flist"))))
>   asgn <- attr(getME(lmf, "flist"), "assign")
>   for (i in seq_along(pedigree)) {
>       tn <- which(match(pnms[i], names(getME(lmf, "flist"))) == asgn)
>       if (length(tn) > 1)
>           stop("a pedigree factor must be associated with only one r.e. term")
>       Zt <- getME(lmf, "Zt")
>       relfac[[i]] <- relfactor(pedigree[[i]], rownames(Zt))
>       lmf$FL$trms[[tn]]$Zt <- lmf$FL$trms[[tn]]$A <- relfac[[i]] %*% Zt
>   }
>   ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize else lme4:::lmer_finalize, lmf)
>   ans <- new("pedigreemm", relfac = relfac, ans)
>
> Any help is appreciated.
>
> Thanks,
> Roby
>
>
> On Apr 2, 2012, at 4:17 PM, Ben Bolker wrote:
>
> Andrzej T Galecki 1 <agalecki at ...> writes:
>
> Ben prepared getME(} function to extract various components of the model
> fit
> obtained using lme4.0 and new lme4.
>
> Try
> getME(lmf,"Zt")
> getME(lmf,"A")
> getME(lmf,"flist")
>
> Andrzej
>
> On Mon, 2 Apr 2012 14:27:20 -0400, "Joehanes, Roby (NIH/NHLBI) [F]"
> <roby.joehanes at ...> wrote:
> Hi:
>
> I am trying to port pedigreemm to use the new lme4. However, the new lme4
> is somewhat opaque to me and hence I need help. Specifically, how can I
> extract the following terms:
> lmf$FL$trms[[tn]]$Zt
> lmf$FL$trms[[tn]]$A
>
> The information lies within lmf <at> pp object, but it is too opaque to me to
> fish anything out.
>
> I understand that lmf$FL$fl is lmf <at> flist and that lmer_finalize calls
> should be replaced with optwrap and mkMerMod. Nevertheless, I think that
> the lmer or glmer could use some refactoring to ease the calls.
>
> I appreciate any help on these.
>
>
> A couple of questions:
>
> 1. how broadly are you using A?  Off-list, Doug Bates has commented to
> me that defining A is relatively straightforward for LMMs but not necessarily
> as simple (nor uniquely defined!) for [GN]LMMs -- for the time being, I
> am quite likely to add code that *disallows* getME(.,"A") except for LMMs --
> I can imagine that the bulk of pedigreemm use is for LMMs, but I suppose
> that people are using it for [GN]LMMs as welll ...
>
> 2. I can't quite tell from your e-mail -- would it be useful to have
> the stuff between the first optwrap() and the last mkMerMod abstracted
> into a single (exposed) function?  For [GN]LMMs it should probably
> also allow control of whether the preliminary "nAGQ=0" optimization
> is done or not ...
>
> (All comments are mine alone, not necessarily speaking for all lme4
> authors ...)
>
> Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-patch-for-pedigreemm.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/ea362fa5/attachment-0002.txt>

From M.FAIRBROTHER at bristol.ac.uk  Tue Apr  3 20:10:45 2012
From: M.FAIRBROTHER at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 3 Apr 2012 19:10:45 +0100
Subject: [R-sig-ME] Xj correlated with Uj?
Message-ID: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>

Dear list,

Code below simulates a simple two-level dataset, but where a level-2 covariate (Xj) is correlated with the level-2 random effects (Uj). In fitting the model, using the call below, the estimate for the fixed effect of Xj is substantially biased.

Is there a way to recover the correct parameter (1)? Presumably it's possible if one knows the variance-covariance matrix "s", but could it be done without that knowledge?

Any thoughts (particularly though not only suggested code) would be much appreciated.

- Malcolm


library(lme4); library(multicore); library(mnormt)
N <- 25
T <- 30
s <- matrix(c(2,0.7,0.7,3), ncol=2)
dgp <- function(N, T, s) {
	dat <- data.frame(group=1:N, rmnorm(n=N, varcov=s))[rep(1:N,each=T),]
	names(dat)[2:3] <- c("Xj", "Uj")
	dat$y <- 1 + dat$Xj + dat$Uj + rnorm(nrow(dat))
	dat
	}
res1 <- do.call("rbind", mclapply(1:100, function(yy) fixef(lmer(y ~ Xj + (1 | group), dgp(N=N, T=T, s=s)))))
colMeans(res1)



From roby.joehanes at nih.gov  Tue Apr  3 21:04:54 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 3 Apr 2012 15:04:54 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
Message-ID: <E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>

Hi all:

Attached please find the patch to pedigreemm toward using the new lme4 (with the patch I submitted earlier). However, the patch does NOT work with the following error:
Error in function (value)  : Field "Zt" is read-only

I believe the error is thrown at this statement:
lmf$rho$pp$Zt <- relfac[[i]] %*% Zt

I have no idea how to proceed. Any help is appreciated.

Thank you,
Roby

On Apr 3, 2012, at 1:53 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

Hi all:

I have created a patch for the latest lmer.R to accommodate calls by pedigreemm. I see that there is potentially a way to create a single "finalize" method instead of one for each lmer, glmer, and nlmer. I assume that nAGQ is 0 for lmer, correct? Or is it possible for glmer or nlmer to specify nAGQ=0?

Perhaps I should submit the patch into the patch database to see whether it is accepted or not. If it is accepted, then I can make the changes to pedigreemm accordingly.

Thank you,
Roby


On Apr 2, 2012, at 6:19 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

Hi all:

Just a follow up: It seems that some changes need to be made in the new lme4 so that the pedigreemm can be modified to use it. They are:
1. To allow the return of all necessary internal variables required for invoking the optimizer (especially rho plus devfun in one call), without invoking the optimizer itself. Right now I did two calls, the first to get the devfun, the second to get the rest. However, I cannot obtain rho in all cases.
#lmerc$doFit <- FALSE # call lmer without pedigree and with doFit = FALSE
l... <- list(...)
lmerc$devFunOnly <- TRUE
devFun <- eval(lmerc, parent.frame())
lmerc$devFunOnly <- FALSE
lmf <- eval(lmerc, parent.frame())

2. Some partitioning of Zt that allows duplicate level names for multiple random factors. That is, if random factors 1 and 2 (let's call them RF1 and RF2) share the same level-string, my current hack will not work. Perhaps someone can propose a better way. My current hack is as follows:
Zt <- getME(lmf, "Zt")
Zt <- Zt[rownames(Zt) %in% levels(getME(lmf, "flist")[[tn]]), ]
(The original was: Zt <- lmf$FL$trms[[tn]]$Zt)

Since I cannot get rho, I cannot realize the lmer_finalize or glmer_finalize. Any help is appreciated. I am stuck right now since I have installed the lme4 SVN version, but the pedigreemm package still assumes the CRAN version.

Thank you,
Roby

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pedigreemm-patch-svnlme4-v1-notworking.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/a0322610/attachment-0002.txt>

From bbolker at gmail.com  Wed Apr  4 00:52:18 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Apr 2012 22:52:18 +0000 (UTC)
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
	<E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>
Message-ID: <loom.20120404T004614-494@post.gmane.org>

Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:

> 
> Hi all:
> 
> Attached please find the patch to pedigreemm toward using the new lme4 (with
the patch I submitted
> earlier). However, the patch does NOT work with the following error:
> Error in function (value)  : Field "Zt" is read-only
> 
> I believe the error is thrown at this statement:
> lmf$rho$pp$Zt <- relfac[[i]] %*% Zt
> 
> I have no idea how to proceed. Any help is appreciated.
> 
> Thank you,
> Roby

  I will take a look at this as soon as I can.
  Setting components of objects in new-lme4 is tricky because
the objects are defined as reference classes, so that messing
with their internals can disrupt existing objects that they
have been copied from (!!) 

 Abstracting the equivalent of "mer_finalize" is, I think, a good
idea.  Yes, nAGQ=0 is allowed for [NG]LMMs ... the idea being (I think)
that for a well-behaved but very large problem one could save time
by just doing the "zeroth-order" fit (even faster than nAGQ=1,
which corresponds to Laplace approximation)

  Ben Bolker



From roby.joehanes at nih.gov  Wed Apr  4 01:06:49 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 3 Apr 2012 19:06:49 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <loom.20120404T004614-494@post.gmane.org>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
	<E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>
	<loom.20120404T004614-494@post.gmane.org>
Message-ID: <5043C756-EA38-45C8-AA87-65F28424AE57@nih.gov>

Hi Ben and everyone:


I made some semi-working patch here (attached). I tried the examples mentioned in the paper of Vazquez, et al. (J. Anim. Sci. 2010, 88:497-504) and got the first example (fm1) working and the result is the same as the older one:
milk <- within(milk, sdMilk <- milk / sd(milk))
fm1 <- pedigreemm(sdMilk ~ lact + log(dim) + (1|id) + (1|herd), data=milk, pedigree=list(id=pedCowsR))

Result:
----
Linear mixed model fit by REML ['lmerMod']
Formula: sdMilk ~ lact + log(dim) + (1 | id) + (1 | herd)
   Data: milk

REML criterion at convergence: 8384.794

Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 0.2780   0.5273
 herd     (Intercept) 0.2078   0.4559
 Residual             0.4833   0.6952
Number of obs: 3397, groups: id, 1359; herd, 57

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.70371    0.26854   6.344
lact        -0.10779    0.01232  -8.747
log(dim)     0.73594    0.04380  16.804

Correlation of Fixed Effects:
         (Intr) lact
lact     -0.296
log(dim) -0.960  0.221
----

However, when I tried the second example (fm2) below, I got an error.
milk <- within(milk, sdMilk <- milk / sd(milk))
milk <- within(milk, idPE <- id)
fm2 <- pedigreemm(sdMilk ~ lact + (1|id) + log(dim) + (1|idPE) + (1|herd), data=milk, pedigree=list(id=pedCows))

The error message is:
Error in .local(x, ...) : previous CHOLMOD factorization was unsuccessful
In addition: Warning message:
In .local(x, ...) :
  Cholmod warning 'not positive definite' at file ../Cholesky/t_cholmod_rowfac.c, line 432

I could not get the third example to work either:
fm3 <- pedigreemm(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="poisson")

The error message is:
Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite

The fourth example also does not work:
fm4 <- pedigreemm(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="binomial"(link="probit"))

Error message:
Error in FUN(1:3[[1L]], ...) :
  step factor reduced below 0.001 without reducing pwrss

I think I messed up somewhere in the internals and got these errors.

Thanks,
Roby



On Apr 3, 2012, at 6:52 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
>
>>
>> Hi all:
>>
>> Attached please find the patch to pedigreemm toward using the new lme4 (with
> the patch I submitted
>> earlier). However, the patch does NOT work with the following error:
>> Error in function (value)  : Field "Zt" is read-only
>>
>> I believe the error is thrown at this statement:
>> lmf$rho$pp$Zt <- relfac[[i]] %*% Zt
>>
>> I have no idea how to proceed. Any help is appreciated.
>>
>> Thank you,
>> Roby
>
>  I will take a look at this as soon as I can.
>  Setting components of objects in new-lme4 is tricky because
> the objects are defined as reference classes, so that messing
> with their internals can disrupt existing objects that they
> have been copied from (!!)
>
> Abstracting the equivalent of "mer_finalize" is, I think, a good
> idea.  Yes, nAGQ=0 is allowed for [NG]LMMs ... the idea being (I think)
> that for a well-behaved but very large problem one could save time
> by just doing the "zeroth-order" fit (even faster than nAGQ=1,
> which corresponds to Laplace approximation)
>
>  Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-patch-for-pedigreemm.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/5d884ed4/attachment-0004.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pedigreemm-patch-v2.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120403/5d884ed4/attachment-0005.txt>

From markus.jantti at iki.fi  Wed Apr  4 11:17:45 2012
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Wed, 04 Apr 2012 11:17:45 +0200
Subject: [R-sig-ME] Xj correlated with Uj?
In-Reply-To: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
References: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
Message-ID: <4F7C11B9.2010503@iki.fi>

On 04/03/2012 08:10 PM, Malcolm Fairbrother wrote:
> Dear list,
>
> Code below simulates a simple two-level dataset, but where a level-2 covariate (Xj) is correlated with the level-2 random effects (Uj). In fitting the model, using the call below, the estimate for the fixed effect of Xj is substantially biased.
>
> Is there a way to recover the correct parameter (1)? Presumably it's possible if one knows the variance-covariance matrix "s", but could it be done without that knowledge?
>
> Any thoughts (particularly though not only suggested code) would be much appreciated.
>

In an ordinary least-squares setting, this is the school-book example of a 
violation of the assumption that the error term in the regression is 
uncorrelated with the covariate.

To estimate the parameters consistently, you would require and instrument, a 
variable that is correlated with Xj but not Uj. Whether instrumental-variable 
estimation has been implemented in a multi-level setting I can not say, but it 
would probably be possible to do this "manually" by estimating an IV-regression 
with no regard to multi-level, using the residuals from that to estimate the 
variance components, then use the implied variance structure to transform the 
original data and re-estimate the IV-regression. This presupposes the existence 
of an instrument however, which is usually a big problem.

Best
Markus

> - Malcolm
>
>
> library(lme4); library(multicore); library(mnormt)
> N<- 25
> T<- 30
> s<- matrix(c(2,0.7,0.7,3), ncol=2)
> dgp<- function(N, T, s) {
> 	dat<- data.frame(group=1:N, rmnorm(n=N, varcov=s))[rep(1:N,each=T),]
> 	names(dat)[2:3]<- c("Xj", "Uj")
> 	dat$y<- 1 + dat$Xj + dat$Uj + rnorm(nrow(dat))
> 	dat
> 	}
> res1<- do.call("rbind", mclapply(1:100, function(yy) fixef(lmer(y ~ Xj + (1 | group), dgp(N=N, T=T, s=s)))))
> colMeans(res1)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Markus Jantti
Professor of Economics
Swedish Institute for Social Research
Stockholm University



From rstuff.miles at gmail.com  Wed Apr  4 14:08:28 2012
From: rstuff.miles at gmail.com (Andrew Miles)
Date: Wed, 4 Apr 2012 08:08:28 -0400
Subject: [R-sig-ME] Xj correlated with Uj?
In-Reply-To: <4F7C11B9.2010503@iki.fi>
References: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
	<4F7C11B9.2010503@iki.fi>
Message-ID: <2B79B7BD-6B2C-4647-ACB6-AB2722D47FED@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/809b986f/attachment-0002.pl>

From roby.joehanes at nih.gov  Wed Apr  4 18:50:23 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Wed, 4 Apr 2012 12:50:23 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <5043C756-EA38-45C8-AA87-65F28424AE57@nih.gov>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
	<E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>
	<loom.20120404T004614-494@post.gmane.org>
	<5043C756-EA38-45C8-AA87-65F28424AE57@nih.gov>
Message-ID: <5F4DDA81-94AC-40D6-93E9-2E8A6F079DF9@nih.gov>

Hi all:

Please find the updated patch. I think I got examples 1 and 2 to work (see below) and the numbers do match. However, I still cannot get examples 3 and 4 to work. Apparently, if I run glmer instead of pedigreemm, I got the same error. Namely, both of these statements:
fm3 <- pedigreemm(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="poisson")
fm3x <- glmer(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, family="poisson")

yielded the same error: Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite

And both of these:
fm4 <- pedigreemm(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="binomial"(link="probit"))
fm4x <- glmer(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, family="binomial"(link="probit"))

also yielded the same error: Error in FUN(1:3[[1L]], ...) :   step factor reduced below 0.001 without reducing pwrss

So, I think the problem lies with the new lme4 since the older lme4 can run fm3x and fm4x just fine. I am just wondering if anyone can give me pointers to fix these problems. I used the SVN version 1694, which I believe to be the latest at the time of this writing.

Thank you,
Roby


On Apr 3, 2012, at 7:06 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi Ben and everyone:
>
>
> I made some semi-working patch here (attached). I tried the examples mentioned in the paper of Vazquez, et al. (J. Anim. Sci. 2010, 88:497-504) and got the first example (fm1) working and the result is the same as the older one:
> milk <- within(milk, sdMilk <- milk / sd(milk))
> fm1 <- pedigreemm(sdMilk ~ lact + log(dim) + (1|id) + (1|herd), data=milk, pedigree=list(id=pedCowsR))
>
> Result:
> ----
> Linear mixed model fit by REML ['lmerMod']
> Formula: sdMilk ~ lact + log(dim) + (1 | id) + (1 | herd)
>   Data: milk
>
> REML criterion at convergence: 8384.794
>
> Random effects:
> Groups   Name        Variance Std.Dev.
> id       (Intercept) 0.2780   0.5273
> herd     (Intercept) 0.2078   0.4559
> Residual             0.4833   0.6952
> Number of obs: 3397, groups: id, 1359; herd, 57
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  1.70371    0.26854   6.344
> lact        -0.10779    0.01232  -8.747
> log(dim)     0.73594    0.04380  16.804
>
> Correlation of Fixed Effects:
>         (Intr) lact
> lact     -0.296
> log(dim) -0.960  0.221
> ----
>
> However, when I tried the second example (fm2) below, I got an error.
> milk <- within(milk, sdMilk <- milk / sd(milk))
> milk <- within(milk, idPE <- id)
> fm2 <- pedigreemm(sdMilk ~ lact + (1|id) + log(dim) + (1|idPE) + (1|herd), data=milk, pedigree=list(id=pedCows))
>
> The error message is:
> Error in .local(x, ...) : previous CHOLMOD factorization was unsuccessful
> In addition: Warning message:
> In .local(x, ...) :
>  Cholmod warning 'not positive definite' at file ../Cholesky/t_cholmod_rowfac.c, line 432
>
> I could not get the third example to work either:
> fm3 <- pedigreemm(NCM ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="poisson")
>
> The error message is:
> Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite
>
> The fourth example also does not work:
> fm4 <- pedigreemm(mastitis ~ birth + calvingYear + (1|sire) + (1|herd), data=mastitis, pedigree=list(sire=pedSires), family="binomial"(link="probit"))
>
> Error message:
> Error in FUN(1:3[[1L]], ...) :
>  step factor reduced below 0.001 without reducing pwrss
>
> I think I messed up somewhere in the internals and got these errors.
>
> Thanks,
> Roby

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: lmer-patch-for-pedigreemm-v2.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/a2e46e16/attachment-0004.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pedigreemm-patch-v3.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/a2e46e16/attachment-0005.txt>

From nyaga.nyawira at gmail.com  Wed Apr  4 19:08:10 2012
From: nyaga.nyawira at gmail.com (victoriah nyawira)
Date: Wed, 4 Apr 2012 19:08:10 +0200
Subject: [R-sig-ME] Problem with lmer
Message-ID: <CAJ5izBRNtYq-R__cXu0w_qYMUMTiwg6c+Von8oiE=wM9WUcGLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120404/6ee39eed/attachment-0002.pl>

From bbolker at gmail.com  Wed Apr  4 22:18:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Apr 2012 20:18:10 +0000 (UTC)
Subject: [R-sig-ME] Problem with lmer
References: <CAJ5izBRNtYq-R@mail.gmail.com>
Message-ID: <loom.20120404T221517-247@post.gmane.org>

victoriah nyawira <nyaga.nyawira at ...> writes:

> Am running this code
> fixdslope <- lmer(score ~ logtime + (1 | id), data)
> but I get this error:
> Error in asMethod(object) : could not find function ".M.classEnv"
> The code ran in windows 7, R 1.14.2, but am currently using OpenSUSE 12.1,
> with the latest R 2.15.0.


 [snip]

  That's a rather odd error message.

.M.classEnv appears to be an internal Matrix function (e.g.
see [broken URL!]

https://r-forge.r-project.org/scm/viewvc.php/pkg/Matrix/R/zzz.R?
  root=matrix&r1=2765&r2=2764&pathrev=2765&diff_format=s

).  Have you run update.packages() [and/or update.packages(checkBuilt=TRUE),
and/or install.packages("Matrix")]?  What are the results of 
sessionInfo()?  Can you provide a reproducible
example?

   Ben Bolker



From jude.girard at gmail.com  Wed Apr  4 22:54:21 2012
From: jude.girard at gmail.com (jude girard)
Date: Wed, 4 Apr 2012 16:54:21 -0400
Subject: [R-sig-ME] graphing fixed effects from mixed effects model
Message-ID: <CAJ6voQFVDaun=PkcDK5c6B25zeJCe=x5oo6Tv1tdUWPRysKNRw@mail.gmail.com>

I feel like this must be a common problem, but I can?t find any
information on how to graph the results of my mixed effects model.

I am trying to predict insect biomass from weed cover and month.  I
have 9 pairs of organic and conventional fields; each field has a
unique site id.  In each field, insect biomass weed cover were
measured in june and july.  So my model is

model<lme(biomass~weed.cover+month, data=weeds, random=~1|pair/site)

I would like to plot a graph showing the raw data, together with two
lines, one showing the predicted relationship between biomass and weed
cover in June and one showing the predicted relationship in July.  I?m
not interested in showing the slopes for the individual sites; this is
included in the model only to account for the longitudinal nature of
the design, not because I am interested in this variation.

So, is there some way to calculate and average slope across sites in
each month, or do I have to pick one site to use as a reference and
just graph the result for that site?  And if so, are there any
guidelines for which site to use as the reference?

Thanks for your help!

Jude Girard


>summary(model)
Linear mixed-effects model fit by REML
 Data: weeds
       AIC      BIC    logLik
  65.07516 73.86958 -26.53758

Random effects:
 Formula: ~1 | pair
         (Intercept)
StdDev: 3.967212e-05

 Formula: ~1 | site %in% pair
        (Intercept)  Residual
StdDev:   0.1402752 0.4805598

Fixed effects: biomass ~ weed.cover +      month
                                 Value Std.Error DF    t-value p-value
(Intercept)                 -2.1694761 0.1263224 15 -17.174124  0.0000
weed.cover 0.2168042 0.3158289 15   0.686461  0.5029
monthJuly             0.4870690 0.2069135 15   2.353974  0.0326
 Correlation:
                            (Intr) a((./1
weed.cover -0.277
monthJuly            -0.351 -0.618

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.5283318 -0.5597323 -0.2046855  0.7638652  1.9944551

Number of Observations: 35
Number of Groups:
          pair site %in% pair
             9             18

> anova(model)
                            numDF denDF  F-value p-value
(Intercept)                     1    15 443.8127  <.0001
weed.cover     1    15   7.4109  0.0157
month                  1    15   5.5412  0.0326



From bbolker at gmail.com  Wed Apr  4 23:25:02 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Apr 2012 21:25:02 +0000 (UTC)
Subject: [R-sig-ME] graphing fixed effects from mixed effects model
References: <CAJ6voQFVDaun=PkcDK5c6B25zeJCe=x5oo6Tv1tdUWPRysKNRw@mail.gmail.com>
Message-ID: <loom.20120404T231826-612@post.gmane.org>

jude girard <jude.girard at ...> writes:

> 
> I feel like this must be a common problem, but I can?t find any
> information on how to graph the results of my mixed effects model.
> 
> I am trying to predict insect biomass from weed cover and month.  I
> have 9 pairs of organic and conventional fields; each field has a
> unique site id.  In each field, insect biomass weed cover were
> measured in june and july.  So my model is
> 
> model<lme(biomass~weed.cover+month, data=weeds, random=~1|pair/site)
> 
> I would like to plot a graph showing the raw data, together with two
> lines, one showing the predicted relationship between biomass and weed
> cover in June and one showing the predicted relationship in July.  I?m
> not interested in showing the slopes for the individual sites; this is
> included in the model only to account for the longitudinal nature of
> the design, not because I am interested in this variation.
> 
> So, is there some way to calculate and average slope across sites in
> each month, or do I have to pick one site to use as a reference and
> just graph the result for that site?  And if so, are there any
> guidelines for which site to use as the reference?
> 

   I would do something like this:

predframe <- with(weeds,expand.grid(month=levels(month),
                weed.cover=seq(min(weed.cover),max(weed.cover),25))
predframe$biomass <- predict.lme(model,level=0,newdata=predframe)
then I would be tempted to use ggplot:

library(ggplot2)
ggplot(weeds,aes(x=weed.cover,y=biomass,colour=month))+
   geom_point()+
   geom_line(data=predframe)

  This plots the data and superimposes the predicted values.

You might also get most of the way there via

  plot(augPred(model,level=0))

the 'level' argument specifies that you want to predict at
the population level (i.e. ignoring site-to-site variation)



From M.FAIRBROTHER at bristol.ac.uk  Thu Apr  5 14:33:35 2012
From: M.FAIRBROTHER at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 5 Apr 2012 13:33:35 +0100
Subject: [R-sig-ME] Xj correlated with Uj?
In-Reply-To: <2B79B7BD-6B2C-4647-ACB6-AB2722D47FED@gmail.com>
References: <2D3FF0E6-C643-4271-9F50-B0A1CA37A5ED@bristol.ac.uk>
	<4F7C11B9.2010503@iki.fi>
	<2B79B7BD-6B2C-4647-ACB6-AB2722D47FED@gmail.com>
Message-ID: <A9597263-8FDA-4C38-BCED-9EEBB694FC45@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/42abc70f/attachment-0002.pl>

From julierushmore at gmail.com  Thu Apr  5 16:27:53 2012
From: julierushmore at gmail.com (Julie Rushmore)
Date: Thu, 5 Apr 2012 10:27:53 -0400
Subject: [R-sig-ME] MCMCglmm warning: observations with zero weight not used
 for calculating dispersion
Message-ID: <CAMOdrumrechT=v-b6G=Wk2XzoZ4NUnTmRpbYjyE=b-0UkOt87A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/017983f3/attachment-0002.pl>

From j.hadfield at ed.ac.uk  Thu Apr  5 16:49:37 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 05 Apr 2012 15:49:37 +0100
Subject: [R-sig-ME] MCMCglmm warning: observations with zero weight not
 used for calculating dispersion
In-Reply-To: <CAMOdrumrechT=v-b6G=Wk2XzoZ4NUnTmRpbYjyE=b-0UkOt87A@mail.gmail.com>
References: <CAMOdrumrechT=v-b6G=Wk2XzoZ4NUnTmRpbYjyE=b-0UkOt87A@mail.gmail.com>
Message-ID: <20120405154937.12911f3cugw7uccg@www.staffmail.ed.ac.uk>

Hi,

This is warning in from glm which MCMCglmm uses to get starting  
values. It is not necessarily anything to worry about, but it may  
indicate that the data are set up wrong. I think the most likely  
reason is that Suc_5+Fa_5 = 0 for some observations.

Cheers,

Jarrod


Quoting Julie Rushmore <julierushmore at gmail.com> on Thu, 5 Apr 2012  
10:27:53 -0400:

> Hi all,
>
> I am modeling association patterns among a community of chimpanzees using a
> logistic mixed effects model in the MCMCglmm package. When I run my model,
> I get the following warning message:
>
> Warning message:
> In summary.glm(glm(cbind(MCMC_y, MCMC_y.additional) ~ 1, family =
> "quasibinomial",  :
>   observations with zero weight not used for calculating dispersion
>
> I can't tell if this warning is related to zero-inflation, overdispersion,
> or something else. Also, I'm not sure 1) if this is a serious concern, or
> 2) how to deal with this in the MCMCglmm framework.
>
> Below is the code for my model:
>
> #priors:
> priors1<- list(R = list(V = 1, nu = 0.002), G = list(G1 = list(V =1, nu =
> 0.002), G2 = list(V =1, nu = 0.002)))
> #model:
> m1<- MCMCglmm(cbind(Suc_5,Fa_5)~
> Related+Sex.Estrus+FamilyDiff+RankDiffNew+EstrusAd3*Age, random =
> ~idv(mult.memb(~Actor1+Actor2))+PID, family="multinomial2", data=dat,
> verbose = FALSE, prior=priors1, saveX=TRUE, saveZ=TRUE, pr=TRUE)
>
> *The response variable uses Suc_5 (two IDs observed together) and Fa_5 (two
> IDs not observed together) to calculate pairwise association indices.
> *The fixed effect predictor variables are all categorical and measure
> pair-wise attributes about two individuals in a pair (with the exception of
> EstrusAd3, which is a temporal variable - the number of females in
> estrus/month).
> *Random effects include animal ID (i.e., the multi-member component) and
> pair ID (PID).
>
> Thanks for your feedback!
> Julie
>
> --
> Julie Rushmore
> DVM/PhD Candidate
> Odum School of Ecology
> University of Georgia
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From helixed2 at yahoo.com  Thu Apr  5 23:48:37 2012
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Thu, 5 Apr 2012 14:48:37 -0700 (PDT)
Subject: [R-sig-ME] Does glm (and glmer) no longer vectorize proportions
	when estimating a binomial GLM(M)?
Message-ID: <1333662517.15306.YahooMailNeo@web161805.mail.bf1.yahoo.com>

A while ago, I posted this message to the listserv:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006717.html

Specifically, I had noted that this code:

smoking.aggregated <- glmer (cbind(smoking observations, total observations) ~ AGE + (1|Individual), family = binomial, data = aggregated)

generates the same estimates as this code, which simply uses an unaggregated vector of data with a binary outcome variable instead of the proportions via cbind: 


smoking.unaggregated <- glmer (smoking ~ AGE + (1|Individual), family = binomial, data = unaggregated)


In response, Doug Bates described the underlying code and functions as a bit of a "hack" -- see: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006724.html

Well, I no longer get the same estimates when using the two above lines of code, which along with Doug's comment makes me wonder if subsequent versions of the base and lme4 packages now treat these models differently.

Thanks, all.



From ramos.grad.student at gmail.com  Fri Apr  6 01:09:08 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 5 Apr 2012 16:09:08 -0700
Subject: [R-sig-ME] lme4.0
Message-ID: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/d3c412be/attachment-0002.pl>

From Mike.Lawrence at dal.ca  Fri Apr  6 02:40:51 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Thu, 5 Apr 2012 21:40:51 -0300
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
Message-ID: <CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>

I believe that this isn't about what version of R you have, but about
the fact that there is no such package as "lme4.0" on CRAN at all yet.
The "new" lme4 hasn't been released to CRAN yet, it's solely on
R-Forge, so when you install "lme4" from CRAN, you're getting the
"old" version. When the new lme4 is pushed to cran, I understand that
the old version will be pushed as a new package called "lme4.0".




On Thu, Apr 5, 2012 at 8:09 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> Hi all,
>
> ?Apparently lme4.0 it is still not available for lastest R
>
> install.packages("lme4.0")
> Installing package(s) into
> ?/Library/Frameworks/R.framework/Versions/2.15/Resources/library?
> (as ?lib? is unspecified)
> Warning in install.packages :
> ?package ?lme4.0? is not available (for R version 2.15.0)
>
> so, the only solution is to re-install an older version of R ? That's why
> I'm always worried of using the latest version of it ...
>
> Many thanks,
>
> apr.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ramos.grad.student at gmail.com  Fri Apr  6 02:54:13 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 5 Apr 2012 17:54:13 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9tdk6_2Y-DN2vpZPrG-w2jUHRj4cXuu5eXcFg4pBF0n_w@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<CAHawB9tdk6_2Y-DN2vpZPrG-w2jUHRj4cXuu5eXcFg4pBF0n_w@mail.gmail.com>
Message-ID: <CAHawB9u3tbf2HJJN-HA0e8Ny1DVscFS+jx4T42VPP6=ARXvkBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/9976b408/attachment-0002.pl>

From j.deikumah2 at uq.edu.au  Fri Apr  6 03:29:45 2012
From: j.deikumah2 at uq.edu.au (Justus Deikumah)
Date: Fri, 6 Apr 2012 01:29:45 +0000
Subject: [R-sig-ME] looping with multiple response variables lme4
Message-ID: <74C378BE307E5D49898BABE3CCFD29A3CF03@uqexmdb2.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120406/82807a55/attachment-0002.pl>

From bbolker at gmail.com  Fri Apr  6 03:57:06 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Apr 2012 01:57:06 +0000 (UTC)
Subject: [R-sig-ME] lme4.0
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
Message-ID: <loom.20120406T035618-491@post.gmane.org>

Mike Lawrence <Mike.Lawrence at ...> writes:

> 
> I believe that this isn't about what version of R you have, but about
> the fact that there is no such package as "lme4.0" on CRAN at all yet.
> The "new" lme4 hasn't been released to CRAN yet, it's solely on
> R-Forge, so when you install "lme4" from CRAN, you're getting the
> "old" version. When the new lme4 is pushed to cran, I understand that
> the old version will be pushed as a new package called "lme4.0".

  Correct.  If you want lme4.0, try

install.packages("lme4.0",repos="http://r-forge.r-project.org")

 also see

  http://lme4.r-forge.r-project.org/



From renaud.lancelot at cirad.fr  Fri Apr  6 07:55:13 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Fri, 06 Apr 2012 07:55:13 +0200
Subject: [R-sig-ME] lme4.0
In-Reply-To: <loom.20120406T035618-491@post.gmane.org>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
Message-ID: <4F7E8541.2040207@cirad.fr>

Well...

 > install.packages("lme4.0",repos="http://r-forge.r-project.org")
Installation d(es) package(s) dans ?C:/R/RLIBS?
(car ?lib? n'est pas sp?cifi?)
Message d'avis :
package ?lme4.0? is not available (for R version 2.15.0)

lme4.0 seems to be available only from
http://lme4.r-forge.r-project.org/repos/src/contrib/

So it should be installed from source:

install.packages("lme4.0", repos="http://r-forge.r-project.org", 
type="source")

which works fine for me.


However, I now have on my system:

lme4
lme4a
lme4b
lme4.0
lme4Eigen

This is really confusing, even for lme4xxx aficionados!

All the best,

Renaud






-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From ramos.grad.student at gmail.com  Fri Apr  6 08:05:17 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 5 Apr 2012 23:05:17 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F7E8541.2040207@cirad.fr>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
Message-ID: <CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120405/86db865d/attachment-0002.pl>

From jwiley.psych at gmail.com  Fri Apr  6 09:01:28 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 6 Apr 2012 00:01:28 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
Message-ID: <CANz9Z_+tspNxQe=4NXcaiz+wh_Nd4yUdZx5svjbTBWmHqN+S_A@mail.gmail.com>

To install from source, you need to have the necessary compilers
installed on your system.  lme4 (any incarnation) is not a pure R
implementation.

On Thu, Apr 5, 2012 at 11:05 PM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> it doesn't work either though I am geting a weird error message:
>
>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
> type="source")
> Installing package(s) into
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
> (as ?lib? is unspecified)
> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
> opened URL
> ==================================================
> downloaded 1013 Kb
>
> * installing *source* package ?lme4.0? ...
> ** libs
> *** arch - i386
> sh: make: command not found

You should not be getting this (make) by itself, but here is a link to
the webpage describing what that command utility is:
http://www.gnu.org/software/make/manual/make.html

It is standard for software development.  When you install packages
with defaults, R installs binaries which are precompiled for systems
like yours (OS, architecture 32/64 bit, etc.).  When you use 'type =
"source"', you are attempting to install from the raw source code
which requires your system to be able to compile the binaries itself.
If you do not have the software required for that, you will
understandably get errors.


> ERROR: compilation failed for package ?lme4.0?
> * removing
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
> Warning in install.packages :
> ?installation of package ?lme4.0? had non-zero exit status

zero exit status means no problems, non-zero means something went
wrong.  If you want, it is pretty straightforward to get all the tools
you need.  *nix tends to come distributed with the appropriate
compilers or you can apt get or use the package manager to get what
you need, not sure about Mac, on Windows it is easy to use the Rtools
distributed now on CRAN.  Anyway, here is the R manual describing how
to go about building from source:
http://cran.r-project.org/doc/manuals/R-admin.html

HTH,

Josh

>
> The downloaded packages are in
> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>
>
>
>
>
>
> On Thu, Apr 5, 2012 at 10:55 PM, lancelot <renaud.lancelot at cirad.fr> wrote:
>
>> Well...
>>
>>
>> > install.packages("lme4.0",**repos="http://r-forge.r-**project.org<http://r-forge.r-project.org>
>> ")
>> Installation d(es) package(s) dans ?C:/R/RLIBS?
>> (car ?lib? n'est pas sp?cifi?)
>> Message d'avis :
>>
>> package ?lme4.0? is not available (for R version 2.15.0)
>>
>> lme4.0 seems to be available only from
>> http://lme4.r-forge.r-project.**org/repos/src/contrib/<http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>
>> So it should be installed from source:
>>
>> install.packages("lme4.0", repos="http://r-forge.r-**project.org<http://r-forge.r-project.org>",
>> type="source")
>>
>> which works fine for me.
>>
>>
>> However, I now have on my system:
>>
>> lme4
>> lme4a
>> lme4b
>> lme4.0
>> lme4Eigen
>>
>> This is really confusing, even for lme4xxx aficionados!
>>
>> All the best,
>>
>> Renaud
>>
>>
>>
>>
>>
>>
>> --
>> Renaud Lancelot
>> EDENext Project, coordinator: http://www.edenext.eu/
>>
>> CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>> F34398 Montpellier
>>
>> Tel. ?+33 4 67 59 37 17 ?- ?Fax ?+33 4 67 59 37 98
>> Secr. +33 4 67 59 37 37 ?- Cell. +33 6 77 52 08 69
>>
>>
>> ______________________________**_________________
>> R-sig-mixed-models at r-project.**org <R-sig-mixed-models at r-project.org>mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Fri Apr  6 13:34:23 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 06 Apr 2012 07:34:23 -0400
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
Message-ID: <4F7ED4BF.2070801@gmail.com>

  Things are discombobulated on R-forge, it looks like (as is not so
unusual these days) -- perhaps due to the transition to R 2.15.

  We've tried to put information at http://lme4.r-forge.r-project.org
about current versions etc..

  For right now, there are only three versions you should think about at
all:

  lme4 on CRAN "0.999375-42"
  lme4 on r-forge -- development version, supersedes lme4Eigen and
(eventually) CRAN-lme4
  lme4.0 on r-forge: backward compatibility branch

  Ben Bolker


On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
> it doesn't work either though I am geting a weird error message:
> 
>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
> type="source")
> Installing package(s) into
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
> (as ?lib? is unspecified)
> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
> opened URL
> ==================================================
> downloaded 1013 Kb
> 
> * installing *source* package ?lme4.0? ...
> ** libs
> *** arch - i386
> sh: make: command not found
> ERROR: compilation failed for package ?lme4.0?
> * removing
> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
> Warning in install.packages :
>   installation of package ?lme4.0? had non-zero exit status
> 
> The downloaded packages are in
> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
> 
> 
> 
> 
> 
> 
> On Thu, Apr 5, 2012 at 10:55 PM, lancelot <renaud.lancelot at cirad.fr
> <mailto:renaud.lancelot at cirad.fr>> wrote:
> 
>     Well...
> 
> 
>     > install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>     <http://r-forge.r-project.org>")
>     Installation d(es) package(s) dans ?C:/R/RLIBS?
>     (car ?lib? n'est pas sp?cifi?)
>     Message d'avis :
> 
>     package ?lme4.0? is not available (for R version 2.15.0)
> 
>     lme4.0 seems to be available only from
>     http://lme4.r-forge.r-project.__org/repos/src/contrib/
>     <http://lme4.r-forge.r-project.org/repos/src/contrib/>
> 
>     So it should be installed from source:
> 
>     install.packages("lme4.0", repos="http://r-forge.r-__project.org
>     <http://r-forge.r-project.org>", type="source")
> 
>     which works fine for me.
> 
> 
>     However, I now have on my system:
> 
>     lme4
>     lme4a
>     lme4b
>     lme4.0
>     lme4Eigen
> 
>     This is really confusing, even for lme4xxx aficionados!
> 
>     All the best,
> 
>     Renaud
> 
> 
> 
> 
> 
> 
>     -- 
>     Renaud Lancelot
>     EDENext Project, coordinator: http://www.edenext.eu/
> 
>     CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>     F34398 Montpellier
> 
>     Tel.  +33 4 67 59 37 17 <tel:%2B33%204%2067%2059%2037%2017>  -  Fax
>      +33 4 67 59 37 98 <tel:%2B33%204%2067%2059%2037%2098>
>     Secr. +33 4 67 59 37 37 <tel:%2B33%204%2067%2059%2037%2037>  - Cell.
>     +33 6 77 52 08 69 <tel:%2B33%206%2077%2052%2008%2069>
> 
> 
>     _________________________________________________
>     R-sig-mixed-models at r-project.__org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
>



From reinhold.kliegl at gmail.com  Fri Apr  6 13:44:51 2012
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 6 Apr 2012 13:44:51 +0200
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F7ED4BF.2070801@gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com>
Message-ID: <CAG+WrEwnCWqp2geyLCcTcbGJD_4vY+JtCB1YcXMwXgw3xUoAQg@mail.gmail.com>

"-- perhaps due to the transition to R 2.15"
This is my impression, too.  Necessary packages are not always
immediately available after a transition (at least for Mac OS X). I
think I had a similar problem as described in this thread about a week
ago. After updating all packages today problems were gone. It was not
a systematic test though.
Reinhold Kliegl

On Fri, Apr 6, 2012 at 1:34 PM, Ben Bolker <bbolker at gmail.com> wrote:
> ?Things are discombobulated on R-forge, it looks like (as is not so
> unusual these days) -- perhaps due to the transition to R 2.15.
>
> ?We've tried to put information at http://lme4.r-forge.r-project.org
> about current versions etc..
>
> ?For right now, there are only three versions you should think about at
> all:
>
> ?lme4 on CRAN "0.999375-42"
> ?lme4 on r-forge -- development version, supersedes lme4Eigen and
> (eventually) CRAN-lme4
> ?lme4.0 on r-forge: backward compatibility branch
>
> ?Ben Bolker
>
>
> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>> it doesn't work either though I am geting a weird error message:
>>
>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>> type="source")
>> Installing package(s) into
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>> (as ?lib? is unspecified)
>> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>> opened URL
>> ==================================================
>> downloaded 1013 Kb
>>
>> * installing *source* package ?lme4.0? ...
>> ** libs
>> *** arch - i386
>> sh: make: command not found
>> ERROR: compilation failed for package ?lme4.0?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>> Warning in install.packages :
>> ? installation of package ?lme4.0? had non-zero exit status
>>
>> The downloaded packages are in
>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>
>>
>>
>>
>>
>>
>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot <renaud.lancelot at cirad.fr
>> <mailto:renaud.lancelot at cirad.fr>> wrote:
>>
>> ? ? Well...
>>
>>
>> ? ? > install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>> ? ? <http://r-forge.r-project.org>")
>> ? ? Installation d(es) package(s) dans ?C:/R/RLIBS?
>> ? ? (car ?lib? n'est pas sp?cifi?)
>> ? ? Message d'avis :
>>
>> ? ? package ?lme4.0? is not available (for R version 2.15.0)
>>
>> ? ? lme4.0 seems to be available only from
>> ? ? http://lme4.r-forge.r-project.__org/repos/src/contrib/
>> ? ? <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>
>> ? ? So it should be installed from source:
>>
>> ? ? install.packages("lme4.0", repos="http://r-forge.r-__project.org
>> ? ? <http://r-forge.r-project.org>", type="source")
>>
>> ? ? which works fine for me.
>>
>>
>> ? ? However, I now have on my system:
>>
>> ? ? lme4
>> ? ? lme4a
>> ? ? lme4b
>> ? ? lme4.0
>> ? ? lme4Eigen
>>
>> ? ? This is really confusing, even for lme4xxx aficionados!
>>
>> ? ? All the best,
>>
>> ? ? Renaud
>>
>>
>>
>>
>>
>>
>> ? ? --
>> ? ? Renaud Lancelot
>> ? ? EDENext Project, coordinator: http://www.edenext.eu/
>>
>> ? ? CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>> ? ? F34398 Montpellier
>>
>> ? ? Tel. ?+33 4 67 59 37 17 <tel:%2B33%204%2067%2059%2037%2017> ?- ?Fax
>> ? ? ?+33 4 67 59 37 98 <tel:%2B33%204%2067%2059%2037%2098>
>> ? ? Secr. +33 4 67 59 37 37 <tel:%2B33%204%2067%2059%2037%2037> ?- Cell.
>> ? ? +33 6 77 52 08 69 <tel:%2B33%206%2077%2052%2008%2069>
>>
>>
>> ? ? _________________________________________________
>> ? ? R-sig-mixed-models at r-project.__org
>> ? ? <mailto:R-sig-mixed-models at r-project.org> mailing list
>> ? ? https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>> ? ? <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From roby.joehanes at nih.gov  Fri Apr  6 16:17:52 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Fri, 6 Apr 2012 10:17:52 -0400
Subject: [R-sig-ME] looping with multiple response variables lme4
In-Reply-To: <74C378BE307E5D49898BABE3CCFD29A3CF03@uqexmdb2.soe.uq.edu.au>
References: <74C378BE307E5D49898BABE3CCFD29A3CF03@uqexmdb2.soe.uq.edu.au>
Message-ID: <7C2166C8-7769-40C2-A30E-B513837AEA65@nih.gov>

Hi Justus:

I think you forgot to surround the formula with quotes, like this:
stmLM <- as.formula(paste(Response[i],"~ccov + x5k_c + ltr + x5k_fr + elev + (1|P_ID) + (1|mtx) + (1|site)"))

The error is basically saying you are trying to paste a string into a formula, which does not work.

Hope this helps,
Roby


On Apr 5, 2012, at 9:29 PM, Justus Deikumah wrote:

> Dear lme4 professionals
> 
> Thank you for any help on the subject matter.
> 
> I am doing a linear mixed effects modelling with 10 response variables and 5 predictors using lme4. I have 126 model combinations if I run my model with one response variable at a time. This seems very manual and will take the rest of my PhD. I have tried haven read some of your recent papers on loops and iterations so I have tried to write a sript for this with help from some friends as follows:
> What I want the loop to do for me is to model each response with all the candidate predictors, drop one predictor and run the models again for all the 126 combinations. Then I want to produce Estimated coefficients of fixed effects, SD, SE, AICs etc as output that can be sent into an excel template for model averaging?
> attach(var1)
> Response <- c("gnst", "spst", "fvt", "Oph", "cniv", "frgv", "gniv", "inct","omnv","Sobs", "ACE", "Chao1","Chao2", "Abund")
> 
> ## Output storage step up
> results <- vector("list", length(Response))
> ##Start the loop
> #Create the formula string
> #stmLM <- as.formula(paste(Response[i]~ccov + x5k_c + ltr + x5k_fr + elev + (1|P_ID) + (1|mtx) + (1|site)))
> 
> 
> 
> lmer <- lmer(stmLM)
> 
> # Save the results{
> results[[i]] <- summary(lmer)
> }
> {
> print(results[[i]])
> }
> My problem is anytime I reach summary and results portion of the analysis then i receive the error message below;
> 
> Error: length(formula <- as.formula(formula)) == 3 is not TRUE
> this is making my R-training uneasy for me. Can someone pls tell me what is wrong as I believe there may be a problem with the for loop of which i am new to anyway. What does the error message say? Has anyone any scripts for this??I am using the imer function? What kind of object doest lmer produce?
> Hope someone understands my question and can help, Please!!
> Thank you
> 
> 
> 
> Deikumah Justus
> PhD Candidate (Confirmed) - Landscape Ecology & Conservation
> Landscape Ecology and Conservation Group
> School of Geography, Planning and Environmental Management
> The University of Queensland
> Brisbane Qld 4072
> Australia
> 
> Chamberlain Building (35)
> Campbell Rd - St Lucia Campus
> 
> W: http://www.gpem.uq.edu.au/cser-jdeikumah
> E: j.deikumah2 at uq.edu.au
> M: +61 424481796, +61 479094200
> If you don't like something, Change it. If you can't change it, change your Attitude. DON'T COMPLAIN (Maya Angelou)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From renaud.lancelot at cirad.fr  Sat Apr  7 11:17:28 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sat, 07 Apr 2012 11:17:28 +0200
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F7ED4BF.2070801@gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com>
Message-ID: <4F800628.3050205@cirad.fr>

Dear Ben,

The installation of lme4 from source does not work for me:

 > install.packages("lme4",repos="http://r-forge.r-project.org", 
type="source")
Installation d(es) package(s) dans ?C:/R/RLIBS?
(car ?lib? n'est pas sp?cifi?)
essai de l'URL 
'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
URL ouverte
downloaded 1.2 Mb
* installing *source* package 'lme4' ...
** libs
cygwin warning:
   MS-DOS style path detected: C:/R/etc/i386/Makeconf
   Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
   CYGWIN environment variable option "nodosfilewarning" turns off this 
warning.
   Consult the user's guide for more details about POSIX paths:
     http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c external.cpp -o external.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c glmFamily.cpp -o glmFamily.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c optimizer.cpp -o optimizer.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c predModule.cpp -o predModule.o
g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE 
-I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2 
-Wall  -mtune=core2 -c respModule.cpp -o respModule.o
Syntax error: Unterminated quoted string
make: *** [lme4.dll] Error 2
ERROR: compilation failed for package 'lme4'
* removing 'C:/R/RLIBS/lme4'

Les packages source t?l?charg?s sont dans
         ?C:\Temp\RtmpYziZpk\downloaded_packages?
Messages d'avis :
1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l 
"C:/R/RLIBS" 
C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz' 
renvoie un statut 1
2: In install.packages("lme4", repos = "http://r-forge.r-project.org",  :
   l'installation du package ?lme4? a eu un statut de sortie non nul


My configuration:

 > sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252 
LC_MONETARY=French_France.1252 LC_NUMERIC=C 
LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] fortunes_1.4-2

loaded via a namespace (and not attached):
[1] tools_2.15.0

All the best,

Renaud




Le 06/04/2012 13:34, Ben Bolker a ?crit :
>    Things are discombobulated on R-forge, it looks like (as is not so
> unusual these days) -- perhaps due to the transition to R 2.15.
>
>    We've tried to put information at http://lme4.r-forge.r-project.org
> about current versions etc..
>
>    For right now, there are only three versions you should think about at
> all:
>
>    lme4 on CRAN "0.999375-42"
>    lme4 on r-forge -- development version, supersedes lme4Eigen and
> (eventually) CRAN-lme4
>    lme4.0 on r-forge: backward compatibility branch
>
>    Ben Bolker
>
>
> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>> it doesn't work either though I am geting a weird error message:
>>
>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>> type="source")
>> Installing package(s) into
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>> (as ?lib? is unspecified)
>> trying URL 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>> opened URL
>> ==================================================
>> downloaded 1013 Kb
>>
>> * installing *source* package ?lme4.0? ...
>> ** libs
>> *** arch - i386
>> sh: make: command not found
>> ERROR: compilation failed for package ?lme4.0?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>> Warning in install.packages :
>>    installation of package ?lme4.0? had non-zero exit status
>>
>> The downloaded packages are in
>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>
>>
>>
>>
>>
>>
>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>> <mailto:renaud.lancelot at cirad.fr>>  wrote:
>>
>>      Well...
>>
>>
>>      >  install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>      <http://r-forge.r-project.org>")
>>      Installation d(es) package(s) dans ?C:/R/RLIBS?
>>      (car ?lib? n'est pas sp?cifi?)
>>      Message d'avis :
>>
>>      package ?lme4.0? is not available (for R version 2.15.0)
>>
>>      lme4.0 seems to be available only from
>>      http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>      <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>
>>      So it should be installed from source:
>>
>>      install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>      <http://r-forge.r-project.org>", type="source")
>>
>>      which works fine for me.
>>
>>
>>      However, I now have on my system:
>>
>>      lme4
>>      lme4a
>>      lme4b
>>      lme4.0
>>      lme4Eigen
>>
>>      This is really confusing, even for lme4xxx aficionados!
>>
>>      All the best,
>>
>>      Renaud
>>
>>
>>
>>
>>
>>
>>      --
>>      Renaud Lancelot
>>      EDENext Project, coordinator: http://www.edenext.eu/
>>
>>      CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>      F34398 Montpellier
>>
>>      Tel.  +33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017>   -  Fax
>>       +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>      Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037>   - Cell.
>>      +33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>
>>
>>      _________________________________________________
>>      R-sig-mixed-models at r-project.__org
>>      <mailto:R-sig-mixed-models at r-project.org>  mailing list
>>      https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From ajhhermansson at gmail.com  Fri Apr  6 16:16:19 2012
From: ajhhermansson at gmail.com (Henrik Hermansson)
Date: Fri, 6 Apr 2012 15:16:19 +0100
Subject: [R-sig-ME] Binary clustered data with negative intraclass
	correlation
Message-ID: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>

Dear all,

I have been searching far and wide for a solution to the following problem:

I have clustered data with a binary outcome. But, rather unusually
(but logically, given the application) the correlation within the
clusters is negative, as a result of competition within the cluster. I
understand from Ten Have et al. (1998) that in such cases, most
clustered-standard-errors estimators will be biased, since they assume
a positive intraclass (intracluster) correlation.

Thomas R. Ten Have, Allen Kunselman & Euginia Zharichenko (1998):
Accommodating negative intracluster correlation with a mixed effects
logistic model for bivariate binary data, Journal of Biopharmaceutical
Statistics, 8:1, 131-149

I'm hoping that someone will be able to point me towards a R package
(or similar) which can perform random effect clustered standard errors
regression without the limitation of an assumed positive intraclass
correlation.

Many thanks in advance for any help and guidance!

Best regards
Henrik Hermansson
PhD Candidate
Department of Political Science
Trinity College Dublin



From bates at stat.wisc.edu  Sat Apr  7 16:29:18 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 7 Apr 2012 09:29:18 -0500
Subject: [R-sig-ME] Does glm (and glmer) no longer vectorize proportions
 when estimating a binomial GLM(M)?
In-Reply-To: <1333662517.15306.YahooMailNeo@web161805.mail.bf1.yahoo.com>
References: <1333662517.15306.YahooMailNeo@web161805.mail.bf1.yahoo.com>
Message-ID: <CAO7JsnQi_nA=3w=pYaFj5DuGChG6wfHb_0K2wd_PLQW0LYVh1g@mail.gmail.com>

On Thu, Apr 5, 2012 at 4:48 PM, Jeremy Koster <helixed2 at yahoo.com> wrote:
> A while ago, I posted this message to the listserv:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006717.html
>
> Specifically, I had noted that this code:
>
> smoking.aggregated <- glmer (cbind(smoking observations, total observations) ~ AGE + (1|Individual), family = binomial, data = aggregated)
>
> generates the same estimates as this code, which simply uses an unaggregated vector of data with a binary outcome variable instead of the proportions via cbind:
>
>
> smoking.unaggregated <- glmer (smoking ~ AGE + (1|Individual), family = binomial, data = unaggregated)
>
>
> In response, Doug Bates described the underlying code and functions as a bit of a "hack" -- see: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006724.html

That comment was with respect to the ways that generalized linear
model families are defined in R.  There are several functions in a
family that are mis-named for historical reasons.  Initial short-cuts
were later found not to be sufficiently general and other functions to
be added to the family.  The distinction between Bernoulli and
binomial responses is to some extent determined by the weights but
then there may be both prior weights and a binomial representation of
Bernoulli responses so this mysterious 'n' vector was added, etc.

The misnomers are:
  - the dev.resid function which is documented to return the deviance
residuals doesn't.  It returns the square of the deviance residuals.
  - the aic function doesn't return the AIC, it returns the deviance.

Once you filter through all this misdirection there is still a
difference in the deviance between the Bernoulli representation of the
data and the representation as binomial responses.  The deviance from
the Bernoulli representation is based on the likelihood of the
parameters for the particular order of the observations in the data.
The deviance from the binomial representation is based on the
likelihood for any of the n_i choose k_i possible orderings of
responses as described in the binomial summary.

At one point I thought that the deviance for the two representations
should be the same but now I have convinced myself that there is a
good reason for them to be different.

> Well, I no longer get the same estimates when using the two above lines of code, which along with Doug's comment makes me wonder if subsequent versions of the base and lme4 packages now treat these models differently.

Can you provide an example where you get different parameter
estimates?  As far as I know the parameter estimates should be the
same, it is just the log-likelihood and quantities derived from it
(deviance, AIC, BIC) that are different.



From j.hadfield at ed.ac.uk  Sat Apr  7 16:47:09 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 07 Apr 2012 15:47:09 +0100
Subject: [R-sig-ME] Binary clustered data with negative intraclass
 correlation
In-Reply-To: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>
References: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>
Message-ID: <20120407154709.10961wgt5tg0bs5c@www.staffmail.ed.ac.uk>

Hi,

Do you have two observations per cluster, as in the paper you cite?

Cheers,

Jarrod


Quoting Henrik Hermansson <ajhhermansson at gmail.com> on Fri, 6 Apr 2012  
15:16:19 +0100:

> Dear all,
>
> I have been searching far and wide for a solution to the following problem:
>
> I have clustered data with a binary outcome. But, rather unusually
> (but logically, given the application) the correlation within the
> clusters is negative, as a result of competition within the cluster. I
> understand from Ten Have et al. (1998) that in such cases, most
> clustered-standard-errors estimators will be biased, since they assume
> a positive intraclass (intracluster) correlation.
>
> Thomas R. Ten Have, Allen Kunselman & Euginia Zharichenko (1998):
> Accommodating negative intracluster correlation with a mixed effects
> logistic model for bivariate binary data, Journal of Biopharmaceutical
> Statistics, 8:1, 131-149
>
> I'm hoping that someone will be able to point me towards a R package
> (or similar) which can perform random effect clustered standard errors
> regression without the limitation of an assumed positive intraclass
> correlation.
>
> Many thanks in advance for any help and guidance!
>
> Best regards
> Henrik Hermansson
> PhD Candidate
> Department of Political Science
> Trinity College Dublin
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Sat Apr  7 23:07:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 07 Apr 2012 17:07:34 -0400
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F800628.3050205@cirad.fr>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com> <4F800628.3050205@cirad.fr>
Message-ID: <4F80AC96.50107@gmail.com>

  Hmmm.

  I don't have access to a Windows machine before Monday.  Thanks for
the heads-up: you *should* in general be able to do this, I will check
to see what's going on.  In the meantime, I was going to say that you
could get Windows binaries etc. from lme4.r-forge.r-project.org/repos ,
but I see that I failed to build/install these for Windows.  Sorry,
thanks for your patience ...

  Ben Bolker


On 12-04-07 05:17 AM, lancelot wrote:
> Dear Ben,
> 
> The installation of lme4 from source does not work for me:
> 
>> install.packages("lme4",repos="http://r-forge.r-project.org",
> type="source")
> Installation d(es) package(s) dans ?C:/R/RLIBS?
> (car ?lib? n'est pas sp?cifi?)
> essai de l'URL
> 'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
> Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
> URL ouverte
> downloaded 1.2 Mb
> * installing *source* package 'lme4' ...
> ** libs
> cygwin warning:
>   MS-DOS style path detected: C:/R/etc/i386/Makeconf
>   Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
>   CYGWIN environment variable option "nodosfilewarning" turns off this
> warning.
>   Consult the user's guide for more details about POSIX paths:
>     http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c external.cpp -o external.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c glmFamily.cpp -o glmFamily.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c optimizer.cpp -o optimizer.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c predModule.cpp -o predModule.o
> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
> -Wall  -mtune=core2 -c respModule.cpp -o respModule.o
> Syntax error: Unterminated quoted string
> make: *** [lme4.dll] Error 2
> ERROR: compilation failed for package 'lme4'
> * removing 'C:/R/RLIBS/lme4'
> 
> Les packages source t?l?charg?s sont dans
>         ?C:\Temp\RtmpYziZpk\downloaded_packages?
> Messages d'avis :
> 1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l
> "C:/R/RLIBS"
> C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz'
> renvoie un statut 1
> 2: In install.packages("lme4", repos = "http://r-forge.r-project.org",  :
>   l'installation du package ?lme4? a eu un statut de sortie non nul
> 
> 
> My configuration:
> 
>> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
> LC_MONETARY=French_France.1252 LC_NUMERIC=C LC_TIME=French_France.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] fortunes_1.4-2
> 
> loaded via a namespace (and not attached):
> [1] tools_2.15.0
> 
> All the best,
> 
> Renaud
> 
> 
> 
> 
> Le 06/04/2012 13:34, Ben Bolker a ?crit :
>>    Things are discombobulated on R-forge, it looks like (as is not so
>> unusual these days) -- perhaps due to the transition to R 2.15.
>>
>>    We've tried to put information at http://lme4.r-forge.r-project.org
>> about current versions etc..
>>
>>    For right now, there are only three versions you should think about at
>> all:
>>
>>    lme4 on CRAN "0.999375-42"
>>    lme4 on r-forge -- development version, supersedes lme4Eigen and
>> (eventually) CRAN-lme4
>>    lme4.0 on r-forge: backward compatibility branch
>>
>>    Ben Bolker
>>
>>
>> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>>> it doesn't work either though I am geting a weird error message:
>>>
>>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>>> type="source")
>>> Installing package(s) into
>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>>> (as ?lib? is unspecified)
>>> trying URL
>>> 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>>> opened URL
>>> ==================================================
>>> downloaded 1013 Kb
>>>
>>> * installing *source* package ?lme4.0? ...
>>> ** libs
>>> *** arch - i386
>>> sh: make: command not found
>>> ERROR: compilation failed for package ?lme4.0?
>>> * removing
>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>>> Warning in install.packages :
>>>    installation of package ?lme4.0? had non-zero exit status
>>>
>>> The downloaded packages are in
>>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>>> <mailto:renaud.lancelot at cirad.fr>>  wrote:
>>>
>>>      Well...
>>>
>>>
>>>      > 
>>> install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>>      <http://r-forge.r-project.org>")
>>>      Installation d(es) package(s) dans ?C:/R/RLIBS?
>>>      (car ?lib? n'est pas sp?cifi?)
>>>      Message d'avis :
>>>
>>>      package ?lme4.0? is not available (for R version 2.15.0)
>>>
>>>      lme4.0 seems to be available only from
>>>      http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>>      <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>>
>>>      So it should be installed from source:
>>>
>>>      install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>>      <http://r-forge.r-project.org>", type="source")
>>>
>>>      which works fine for me.
>>>
>>>
>>>      However, I now have on my system:
>>>
>>>      lme4
>>>      lme4a
>>>      lme4b
>>>      lme4.0
>>>      lme4Eigen
>>>
>>>      This is really confusing, even for lme4xxx aficionados!
>>>
>>>      All the best,
>>>
>>>      Renaud
>>>
>>>
>>>
>>>
>>>
>>>
>>>      --
>>>      Renaud Lancelot
>>>      EDENext Project, coordinator: http://www.edenext.eu/
>>>
>>>      CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>>      F34398 Montpellier
>>>
>>>      Tel.  +33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017>   -  Fax
>>>       +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>>      Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037>   -
>>> Cell.
>>>      +33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>>
>>>
>>>      _________________________________________________
>>>      R-sig-mixed-models at r-project.__org
>>>      <mailto:R-sig-mixed-models at r-project.org>  mailing list
>>>      https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>>
>>
>>
>



From jwiley.psych at gmail.com  Sat Apr  7 23:46:47 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 7 Apr 2012 14:46:47 -0700
Subject: [R-sig-ME] lme4.0
In-Reply-To: <4F80AC96.50107@gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com> <4F800628.3050205@cirad.fr>
	<4F80AC96.50107@gmail.com>
Message-ID: <CANz9Z_Jmzhv0igAXCa3qJauxYuGv6=X5RMv2JBBSWOaC7gGKRQ@mail.gmail.com>

FYI, yesterday I was able to install lme4 and lme4.0 from source form
R forge without a glitch on a Windows x64 system with the most recent
version of Rtools and unsuffered consequences.

Josh

On Sat, Apr 7, 2012 at 2:07 PM, Ben Bolker <bbolker at gmail.com> wrote:
> ?Hmmm.
>
> ?I don't have access to a Windows machine before Monday. ?Thanks for
> the heads-up: you *should* in general be able to do this, I will check
> to see what's going on. ?In the meantime, I was going to say that you
> could get Windows binaries etc. from lme4.r-forge.r-project.org/repos ,
> but I see that I failed to build/install these for Windows. ?Sorry,
> thanks for your patience ...
>
> ?Ben Bolker
>
>
> On 12-04-07 05:17 AM, lancelot wrote:
>> Dear Ben,
>>
>> The installation of lme4 from source does not work for me:
>>
>>> install.packages("lme4",repos="http://r-forge.r-project.org",
>> type="source")
>> Installation d(es) package(s) dans ?C:/R/RLIBS?
>> (car ?lib? n'est pas sp?cifi?)
>> essai de l'URL
>> 'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
>> Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
>> URL ouverte
>> downloaded 1.2 Mb
>> * installing *source* package 'lme4' ...
>> ** libs
>> cygwin warning:
>> ? MS-DOS style path detected: C:/R/etc/i386/Makeconf
>> ? Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
>> ? CYGWIN environment variable option "nodosfilewarning" turns off this
>> warning.
>> ? Consult the user's guide for more details about POSIX paths:
>> ? ? http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c external.cpp -o external.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c glmFamily.cpp -o glmFamily.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c optimizer.cpp -o optimizer.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c predModule.cpp -o predModule.o
>> g++ ?-I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include" ? ? ?-O2
>> -Wall ?-mtune=core2 -c respModule.cpp -o respModule.o
>> Syntax error: Unterminated quoted string
>> make: *** [lme4.dll] Error 2
>> ERROR: compilation failed for package 'lme4'
>> * removing 'C:/R/RLIBS/lme4'
>>
>> Les packages source t?l?charg?s sont dans
>> ? ? ? ? ?C:\Temp\RtmpYziZpk\downloaded_packages?
>> Messages d'avis :
>> 1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l
>> "C:/R/RLIBS"
>> C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz'
>> renvoie un statut 1
>> 2: In install.packages("lme4", repos = "http://r-forge.r-project.org", ?:
>> ? l'installation du package ?lme4? a eu un statut de sortie non nul
>>
>>
>> My configuration:
>>
>>> sessionInfo()
>> R version 2.15.0 (2012-03-30)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=French_France.1252 ?LC_CTYPE=French_France.1252
>> LC_MONETARY=French_France.1252 LC_NUMERIC=C LC_TIME=French_France.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] fortunes_1.4-2
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.15.0
>>
>> All the best,
>>
>> Renaud
>>
>>
>>
>>
>> Le 06/04/2012 13:34, Ben Bolker a ?crit :
>>> ? ?Things are discombobulated on R-forge, it looks like (as is not so
>>> unusual these days) -- perhaps due to the transition to R 2.15.
>>>
>>> ? ?We've tried to put information at http://lme4.r-forge.r-project.org
>>> about current versions etc..
>>>
>>> ? ?For right now, there are only three versions you should think about at
>>> all:
>>>
>>> ? ?lme4 on CRAN "0.999375-42"
>>> ? ?lme4 on r-forge -- development version, supersedes lme4Eigen and
>>> (eventually) CRAN-lme4
>>> ? ?lme4.0 on r-forge: backward compatibility branch
>>>
>>> ? ?Ben Bolker
>>>
>>>
>>> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>>>> it doesn't work either though I am geting a weird error message:
>>>>
>>>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>>>> type="source")
>>>> Installing package(s) into
>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>>>> (as ?lib? is unspecified)
>>>> trying URL
>>>> 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>>>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>>>> opened URL
>>>> ==================================================
>>>> downloaded 1013 Kb
>>>>
>>>> * installing *source* package ?lme4.0? ...
>>>> ** libs
>>>> *** arch - i386
>>>> sh: make: command not found
>>>> ERROR: compilation failed for package ?lme4.0?
>>>> * removing
>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>>>> Warning in install.packages :
>>>> ? ?installation of package ?lme4.0? had non-zero exit status
>>>>
>>>> The downloaded packages are in
>>>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>>>> <mailto:renaud.lancelot at cirad.fr>> ?wrote:
>>>>
>>>> ? ? ?Well...
>>>>
>>>>
>>>> ? ? ?>
>>>> install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>>> ? ? ?<http://r-forge.r-project.org>")
>>>> ? ? ?Installation d(es) package(s) dans ?C:/R/RLIBS?
>>>> ? ? ?(car ?lib? n'est pas sp?cifi?)
>>>> ? ? ?Message d'avis :
>>>>
>>>> ? ? ?package ?lme4.0? is not available (for R version 2.15.0)
>>>>
>>>> ? ? ?lme4.0 seems to be available only from
>>>> ? ? ?http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>>> ? ? ?<http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>>>
>>>> ? ? ?So it should be installed from source:
>>>>
>>>> ? ? ?install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>>> ? ? ?<http://r-forge.r-project.org>", type="source")
>>>>
>>>> ? ? ?which works fine for me.
>>>>
>>>>
>>>> ? ? ?However, I now have on my system:
>>>>
>>>> ? ? ?lme4
>>>> ? ? ?lme4a
>>>> ? ? ?lme4b
>>>> ? ? ?lme4.0
>>>> ? ? ?lme4Eigen
>>>>
>>>> ? ? ?This is really confusing, even for lme4xxx aficionados!
>>>>
>>>> ? ? ?All the best,
>>>>
>>>> ? ? ?Renaud
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ? ? ?--
>>>> ? ? ?Renaud Lancelot
>>>> ? ? ?EDENext Project, coordinator: http://www.edenext.eu/
>>>>
>>>> ? ? ?CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>>> ? ? ?F34398 Montpellier
>>>>
>>>> ? ? ?Tel. ?+33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017> ? - ?Fax
>>>> ? ? ? +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>>> ? ? ?Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037> ? -
>>>> Cell.
>>>> ? ? ?+33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>>>
>>>>
>>>> ? ? ?_________________________________________________
>>>> ? ? ?R-sig-mixed-models at r-project.__org
>>>> ? ? ?<mailto:R-sig-mixed-models at r-project.org> ?mailing list
>>>> ? ? ?https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>>> ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>
>>>>
>>>
>>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/



From bbolker at gmail.com  Sun Apr  8 00:02:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 07 Apr 2012 18:02:51 -0400
Subject: [R-sig-ME] lme4.0
In-Reply-To: <CANz9Z_Jmzhv0igAXCa3qJauxYuGv6=X5RMv2JBBSWOaC7gGKRQ@mail.gmail.com>
References: <CAHawB9vPK30QkksNxcCGjKOyz9gLRxnpoWBjvAU+sgRB+oGuPw@mail.gmail.com>
	<CAB+QPJCiWy9zFS1QqHxQLs5uzz0W1RqJYBBSixcsFb4_8CgKvw@mail.gmail.com>
	<loom.20120406T035618-491@post.gmane.org>
	<4F7E8541.2040207@cirad.fr>
	<CAHawB9umf7caz+PSQbhe9zeB8tYzSgR7SXAd9CkFr7nQQ+C0bQ@mail.gmail.com>
	<4F7ED4BF.2070801@gmail.com> <4F800628.3050205@cirad.fr>
	<4F80AC96.50107@gmail.com>
	<CANz9Z_Jmzhv0igAXCa3qJauxYuGv6=X5RMv2JBBSWOaC7gGKRQ@mail.gmail.com>
Message-ID: <4F80B98B.7020805@gmail.com>

On 12-04-07 05:46 PM, Joshua Wiley wrote:
> FYI, yesterday I was able to install lme4 and lme4.0 from source form
> R forge without a glitch on a Windows x64 system with the most recent
> version of Rtools and unsuffered consequences.
> 
> Josh
> 

  Thanks.  I just built current versions of lme4.0 and lme4 on
win-builder.r-project.org and installed them in the lme4 repository --
it will take a little while for that change to propagate, but that
should be a good fallback for when r-forge is glitchy.

  Ben

> On Sat, Apr 7, 2012 at 2:07 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>  Hmmm.
>>
>>  I don't have access to a Windows machine before Monday.  Thanks for
>> the heads-up: you *should* in general be able to do this, I will check
>> to see what's going on.  In the meantime, I was going to say that you
>> could get Windows binaries etc. from lme4.r-forge.r-project.org/repos ,
>> but I see that I failed to build/install these for Windows.  Sorry,
>> thanks for your patience ...
>>
>>  Ben Bolker
>>
>>
>> On 12-04-07 05:17 AM, lancelot wrote:
>>> Dear Ben,
>>>
>>> The installation of lme4 from source does not work for me:
>>>
>>>> install.packages("lme4",repos="http://r-forge.r-project.org",
>>> type="source")
>>> Installation d(es) package(s) dans ?C:/R/RLIBS?
>>> (car ?lib? n'est pas sp?cifi?)
>>> essai de l'URL
>>> 'http://r-forge.r-project.org/src/contrib/lme4_0.999902344-0.tar.gz'
>>> Content type 'application/x-gzip' length 1254848 bytes (1.2 Mb)
>>> URL ouverte
>>> downloaded 1.2 Mb
>>> * installing *source* package 'lme4' ...
>>> ** libs
>>> cygwin warning:
>>>   MS-DOS style path detected: C:/R/etc/i386/Makeconf
>>>   Preferred POSIX equivalent is: /cygdrive/c/R/etc/i386/Makeconf
>>>   CYGWIN environment variable option "nodosfilewarning" turns off this
>>> warning.
>>>   Consult the user's guide for more details about POSIX paths:
>>>     http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c external.cpp -o external.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c glmFamily.cpp -o glmFamily.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c mcmcsamp.cpp -o mcmcsamp.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c optimizer.cpp -o optimizer.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c predModule.cpp -o predModule.o
>>> g++  -I"C:/R/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE
>>> -I"C:/R/RLIBS/Rcpp/include" -I"C:/R/RLIBS/RcppEigen/include"      -O2
>>> -Wall  -mtune=core2 -c respModule.cpp -o respModule.o
>>> Syntax error: Unterminated quoted string
>>> make: *** [lme4.dll] Error 2
>>> ERROR: compilation failed for package 'lme4'
>>> * removing 'C:/R/RLIBS/lme4'
>>>
>>> Les packages source t?l?charg?s sont dans
>>>         ?C:\Temp\RtmpYziZpk\downloaded_packages?
>>> Messages d'avis :
>>> 1: l'ex?cution de la commande 'C:/R/bin/i386/R CMD INSTALL -l
>>> "C:/R/RLIBS"
>>> C:\Temp\RtmpYziZpk/downloaded_packages/lme4_0.999902344-0.tar.gz'
>>> renvoie un statut 1
>>> 2: In install.packages("lme4", repos = "http://r-forge.r-project.org",  :
>>>   l'installation du package ?lme4? a eu un statut de sortie non nul
>>>
>>>
>>> My configuration:
>>>
>>>> sessionInfo()
>>> R version 2.15.0 (2012-03-30)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
>>> LC_MONETARY=French_France.1252 LC_NUMERIC=C LC_TIME=French_France.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] fortunes_1.4-2
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.15.0
>>>
>>> All the best,
>>>
>>> Renaud
>>>
>>>
>>>
>>>
>>> Le 06/04/2012 13:34, Ben Bolker a ?crit :
>>>>    Things are discombobulated on R-forge, it looks like (as is not so
>>>> unusual these days) -- perhaps due to the transition to R 2.15.
>>>>
>>>>    We've tried to put information at http://lme4.r-forge.r-project.org
>>>> about current versions etc..
>>>>
>>>>    For right now, there are only three versions you should think about at
>>>> all:
>>>>
>>>>    lme4 on CRAN "0.999375-42"
>>>>    lme4 on r-forge -- development version, supersedes lme4Eigen and
>>>> (eventually) CRAN-lme4
>>>>    lme4.0 on r-forge: backward compatibility branch
>>>>
>>>>    Ben Bolker
>>>>
>>>>
>>>> On 12-04-06 02:05 AM, Antonio P. Ramos wrote:
>>>>> it doesn't work either though I am geting a weird error message:
>>>>>
>>>>>> install.packages("lme4.0", repos="http://r-forge.r-project.org",
>>>>> type="source")
>>>>> Installing package(s) into
>>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library?
>>>>> (as ?lib? is unspecified)
>>>>> trying URL
>>>>> 'http://r-forge.r-project.org/src/contrib/lme4.0_0.9999-1.tar.gz'
>>>>> Content type 'application/x-gzip' length 1037389 bytes (1013 Kb)
>>>>> opened URL
>>>>> ==================================================
>>>>> downloaded 1013 Kb
>>>>>
>>>>> * installing *source* package ?lme4.0? ...
>>>>> ** libs
>>>>> *** arch - i386
>>>>> sh: make: command not found
>>>>> ERROR: compilation failed for package ?lme4.0?
>>>>> * removing
>>>>> ?/Library/Frameworks/R.framework/Versions/2.14/Resources/library/lme4.0?
>>>>> Warning in install.packages :
>>>>>    installation of package ?lme4.0? had non-zero exit status
>>>>>
>>>>> The downloaded packages are in
>>>>> ?/private/var/folders/fl/ckbqsv051f1fj4njt__g9thw0000gn/T/RtmpQnLuAo/downloaded_packages?
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Thu, Apr 5, 2012 at 10:55 PM, lancelot<renaud.lancelot at cirad.fr
>>>>> <mailto:renaud.lancelot at cirad.fr>>  wrote:
>>>>>
>>>>>      Well...
>>>>>
>>>>>
>>>>>      >
>>>>> install.packages("lme4.0",__repos="http://r-forge.r-__project.org
>>>>>      <http://r-forge.r-project.org>")
>>>>>      Installation d(es) package(s) dans ?C:/R/RLIBS?
>>>>>      (car ?lib? n'est pas sp?cifi?)
>>>>>      Message d'avis :
>>>>>
>>>>>      package ?lme4.0? is not available (for R version 2.15.0)
>>>>>
>>>>>      lme4.0 seems to be available only from
>>>>>      http://lme4.r-forge.r-project.__org/repos/src/contrib/
>>>>>      <http://lme4.r-forge.r-project.org/repos/src/contrib/>
>>>>>
>>>>>      So it should be installed from source:
>>>>>
>>>>>      install.packages("lme4.0", repos="http://r-forge.r-__project.org
>>>>>      <http://r-forge.r-project.org>", type="source")
>>>>>
>>>>>      which works fine for me.
>>>>>
>>>>>
>>>>>      However, I now have on my system:
>>>>>
>>>>>      lme4
>>>>>      lme4a
>>>>>      lme4b
>>>>>      lme4.0
>>>>>      lme4Eigen
>>>>>
>>>>>      This is really confusing, even for lme4xxx aficionados!
>>>>>
>>>>>      All the best,
>>>>>
>>>>>      Renaud
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>      --
>>>>>      Renaud Lancelot
>>>>>      EDENext Project, coordinator: http://www.edenext.eu/
>>>>>
>>>>>      CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>>>>>      F34398 Montpellier
>>>>>
>>>>>      Tel.  +33 4 67 59 37 17<tel:%2B33%204%2067%2059%2037%2017>   -  Fax
>>>>>       +33 4 67 59 37 98<tel:%2B33%204%2067%2059%2037%2098>
>>>>>      Secr. +33 4 67 59 37 37<tel:%2B33%204%2067%2059%2037%2037>   -
>>>>> Cell.
>>>>>      +33 6 77 52 08 69<tel:%2B33%206%2077%2052%2008%2069>
>>>>>
>>>>>
>>>>>      _________________________________________________
>>>>>      R-sig-mixed-models at r-project.__org
>>>>>      <mailto:R-sig-mixed-models at r-project.org>  mailing list
>>>>>      https://stat.ethz.ch/mailman/__listinfo/r-sig-mixed-models
>>>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>



From trea26 at gmail.com  Sun Apr  8 03:47:46 2012
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sat, 07 Apr 2012 22:47:46 -0300
Subject: [R-sig-ME] looping with multiple response variables lme4
Message-ID: <4F80EE42.9090103@gmail.com>

Hi Justus,
Maybe the following functions from package "LMERConvenienceFunctions" 
can be of help:

bfFixefLMER_F.fnc       Back-fits an LMER model on p-values from ANOVA
                         and, optionally, on LLRT.
bfFixefLMER_t.fnc       Back-fits an LMER model on absolute t-value
                         and, optionally, on LLRT.
fitLMER.fnc             Back-fit fixed effects and forward-fit random
                         effects of an LMER mo

Basically you can have a model with say a 10-way interaction and all 
lower-level interactions and main effects) and these fucntions will 
iteratively remove any non-significant model term starting with the 
highest-order interaction and going down to the main effects. If a 
lower-order interaction or main effect is part of a higher-order one, 
the term won't be pruned (the marginality principle). It also prints a 
log of the steps it went through. Here's an example:

# fit initial model
m1 = lmer(Fz ~ FreqB * LengthB * WMC + (1 | Subject) +
        (1 | Item), data = eeg)

# backfit fixed effects on F
m2 = bfFixefLMER_F.fnc(mB, eeg, log.file = FALSE,
        llrt = FALSE)

processing model terms of interaction level 3
     iteration 1
         p-value for term "FreqB:LengthB:WMC" = 0.1152 > 0.05
         not part of higher-order interaction
         removing term
processing model terms of interaction level 2
     iteration 2
         p-value for term "FreqB:WMC" = 0.9552 > 0.05
         not part of higher-order interaction
         removing term
     iteration 3
         p-value for term "FreqB:LengthB" = 0.6564 > 0.05
         not part of higher-order interaction
         removing term
processing model terms of interaction level 1
     iteration 4
         p-value for term "WMC" = 0.7796 > 0.05
         part of higher-order interaction
         skipping term
     iteration 5
         p-value for term "FreqB" = 0.7635 > 0.05
         not part of higher-order interaction
         removing term
     iteration 6
         p-value for term "LengthB" = 0.0924 > 0.05
         part of higher-order interaction
         skipping term
pruning random effects structure ...
     nothing to prune


The output will simply be a pruned lme model. You can certainly look at 
the code and tweak it so it'll return SD, SE, and AIC.

Antoine
NeuroCognitive Imaging Laboratory
Dalhousie University
Halifax, Nova Scotia
Canada


 > Hi Justus:
 >
 > I think you forgot to surround the formula with quotes, like this:
 > stmLM <- as.formula(paste(Response[i],"~ccov + x5k_c + ltr + x5k_fr + 
 > elev + (1|P_ID) + (1|mtx) + (1|site)"))
 >
 > The error is basically saying you are trying to paste a string into a 
 > formula, which does not work.
 >
 > Hope this helps,
 > Roby
 >
 >
 > On Apr 5, 2012, at 9:29 PM, Justus Deikumah wrote:
 >
 >> Dear lme4 professionals
 >>
 >> Thank you for any help on the subject matter.
 >>
 >> I am doing a linear mixed effects modelling with 10 response 
variables and 5 predictors using lme4. I have 126 model combinations if 
I run my model with one response variable at a time. This seems very 
manual and will take the rest of my PhD. I have tried haven read some of 
your recent papers on loops and iterations so I have tried to write a 
sript for this with help from some friends as follows:
 > What I want the loop to do for me is to model each response with all 
the candidate predictors, drop one predictor and run the models again 
for all the 126 combinations. Then I want to produce Estimated 
coefficients of fixed effects, SD, SE, AICs etc as output that can be 
sent into an excel template for model averaging?
 >> attach(var1)
 >> Response <- c("gnst", "spst", "fvt", "Oph", "cniv", "frgv", "gniv", 
"inct","omnv","Sobs", "ACE", "Chao1","Chao2", "Abund")
 >
 > ## Output storage step up
 > results <- vector("list", length(Response))
 > ##Start the loop
 > #Create the formula string
 > #stmLM <- as.formula(paste(Response[i]~ccov + x5k_c + ltr + x5k_fr + 
elev + (1|P_ID) + (1|mtx) + (1|site)))
 >
 >
 >
 > lmer <- lmer(stmLM)
 >
 > # Save the results{
 > results[[i]] <- summary(lmer)
 > }
 > {
 > print(results[[i]])
 > }
 > My problem is anytime I reach summary and results portion of the 
analysis then i receive the error message below;
 >
 > Error: length(formula <- as.formula(formula)) == 3 is not TRUE
 > this is making my R-training uneasy for me. Can someone pls tell me 
what is wrong as I believe there may be a problem with the for loop of 
which i am new to anyway. What does the error message say? Has anyone 
any scripts for this??I am using the lmer function? What kind of object 
doest lmer produce?
 > Hope someone understands my question and can help, Please!!
 > Thank you
 >
 >
 >
 > Deikumah Justus
 > PhD Candidate (Confirmed) - Landscape Ecology & Conservation
 > Landscape Ecology and Conservation Group
 > School of Geography, Planning and Environmental Management
 > The University of Queensland
 > Brisbane Qld 4072
 > Australia
 >
 > Chamberlain Building (35)
 > Campbell Rd - St Lucia Campus
 >
 > W: http://www.gpem.uq.edu.au/cser-jdeikumah
 > E: j.deikumah2 at uq.edu.au
 > M: +61 424481796, +61 479094200
 > If you don't like something, Change it. If you can't change it, 
change your Attitude. DON'T COMPLAIN (Maya Angelou)
 >
 >     [[alternative HTML version deleted]]
 >
 > _______________________________________________
 > R-sig-mixed-models at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Antoine Tremblay, PhD
NeuroCognitive Imaging Laboratory
Dalhousie University
Halifax, NS B3H 3J5,
Canada

Tel.: (902) 494-1911
eom



From roby.joehanes at nih.gov  Mon Apr  9 19:15:16 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 9 Apr 2012 13:15:16 -0400
Subject: [R-sig-ME] Kinship vs. Pedigreemm
Message-ID: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>

Dear all:

I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).

Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?

Thank you,
Roby


From f.calboli at imperial.ac.uk  Mon Apr  9 19:32:19 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 9 Apr 2012 18:32:19 +0100
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
Message-ID: <5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>

On 9 Apr 2012, at 18:15, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Dear all:
> 
> I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).
> 
> Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?

I thought that Kinship is now replaced by Kinship2 (http://cran.r-project.org/web/packages/kinship2/index.html).

BW


F



> 
> Thank you,
> Roby
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From roby.joehanes at nih.gov  Mon Apr  9 19:58:16 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Mon, 9 Apr 2012 13:58:16 -0400
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
	<5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
Message-ID: <A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>

Hi:

Yes, you are right. It appears that package kinship is now broken into several packages: coxme, kinship2, bdsmatrix, among others. Are you aware of the difference between them and pedigreemm?

Thank you,
Roby


On Apr 9, 2012, at 1:32 PM, Federico Calboli wrote:

> On 9 Apr 2012, at 18:15, Joehanes, Roby (NIH/NHLBI) [F] wrote:
> 
>> Dear all:
>> 
>> I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).
>> 
>> Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?
> 
> I thought that Kinship is now replaced by Kinship2 (http://cran.r-project.org/web/packages/kinship2/index.html).
> 
> BW
> 
> 
> F
> 



From f.calboli at imperial.ac.uk  Mon Apr  9 20:05:26 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 9 Apr 2012 19:05:26 +0100
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
	<5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
	<A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
Message-ID: <D5D3BC1A-64F1-4D4E-A589-3576449B13B4@imperial.ac.uk>

On 9 Apr 2012, at 18:58, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Hi:
> 
> Yes, you are right. It appears that package kinship is now broken into several packages: coxme, kinship2, bdsmatrix, among others. Are you aware of the difference between them and pedigreemm?

I would not know personally, but others on the list might know more.

BW

F


> 
> Thank you,
> Roby
> 
> 
> On Apr 9, 2012, at 1:32 PM, Federico Calboli wrote:
> 
>> On 9 Apr 2012, at 18:15, Joehanes, Roby (NIH/NHLBI) [F] wrote:
>> 
>>> Dear all:
>>> 
>>> I wonder if any of you are familiar with both packages Kinship and PedigreeMM? What are the major differences other than Kinship using NLME and PedigreeMM using LME4? From the source code, though, the main Kinship routine, lmekin, does not appear to use nlme; it appears to minimize the likelihood function directly using optim (L-BFGS-B option).
>>> 
>>> Also, it appears that package Kinship has been obsoleted from the CRAN. Why is that? Is it because Kinship package has been largely obsoleted by PedigreeMM?
>> 
>> I thought that Kinship is now replaced by Kinship2 (http://cran.r-project.org/web/packages/kinship2/index.html).
>> 
>> BW
>> 
>> 
>> F
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From pauljohn32 at gmail.com  Mon Apr  9 23:48:10 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 9 Apr 2012 16:48:10 -0500
Subject: [R-sig-ME] Is there a final-ish format for lme4 objects now?
Message-ID: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>

Greetings:

Long ago, I wrote a function "outreg" to make LaTeX tables for
regressions.  Now I've put it in a package
called rockchalk.  Because I put it in a package on CRAN, people I
don't know write to me saying
"it works for lm and glm, but what about lme4".

In 2008 or so, I had tried to incorporate lme4 output, but I ran into
the trouble. Version changes
of lme4 regularly broke my output code.  I asked about it here, and
learned I was "jumping the gun" because
lme4 was still adjusting.

Has lme4 output reached a point where I can treat the output from lme4
functions as "more or less"
stable?  If I make the table maker function work with lme4 objects
(the stable CRAN version),  is that function
likely to also work with the development version of lme4?  I know the
class of the objects
changed from mer to merMod.  Is that a signal that I am again too
early to try to do this?

pj
-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu



From David.Duffy at qimr.edu.au  Tue Apr 10 04:36:54 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 10 Apr 2012 12:36:54 +1000 (EST)
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov><5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
	<A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
Message-ID: <Pine.LNX.4.64.1204101233140.29974@orpheus.qimr.edu.au>

On Mon, 9 Apr 2012, Joehanes, Roby (NIH/NHLBI) [F] wrote:

> Yes, you are right. It appears that package kinship is now broken into 
> several packages: coxme, kinship2, bdsmatrix, among others. Are you 
> aware of the difference between them and pedigreemm?

Terry Therneau wrote in the lmekin vignette:

"Let me emphasis this: most models that can be fit with the lmekin 
function can also be fit with lme and/or lmer. For any such model the 
lme/lmer functions will be faster and have superior support routines 
(residuals, printing, plotting, etc.) The solution code for lmer is likely 
also more reliable since it has been exercised on a much wider variety of 
data sets.

"However, there are models that lmekin will fit which lme will not. The 
most obvious of these are models with a random genetic effect, e.g. a 
kinship matrix. The second class will be models for which the user has 
written their own variance extension, as described in the variance 
vignette."


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From maechler at stat.math.ethz.ch  Tue Apr 10 16:22:06 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 10 Apr 2012 16:22:06 +0200
Subject: [R-sig-ME] Is there a final-ish format for lme4 objects now?
In-Reply-To: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
Message-ID: <20356.16910.332273.687519@stat.math.ethz.ch>

>>>>> Paul Johnson <pauljohn32 at gmail.com>
>>>>>     on Mon, 9 Apr 2012 16:48:10 -0500 writes:

    > Greetings: Long ago, I wrote a function "outreg" to make
    > LaTeX tables for regressions.  Now I've put it in a
    > package called rockchalk.  Because I put it in a package
    > on CRAN, people I don't know write to me saying "it works
    > for lm and glm, but what about lme4".

    > In 2008 or so, I had tried to incorporate lme4 output, but
    > I ran into the trouble. Version changes of lme4 regularly
    > broke my output code.  I asked about it here, and learned
    > I was "jumping the gun" because lme4 was still adjusting.

    > Has lme4 output reached a point where I can treat the
    > output from lme4 functions as "more or less" stable?  If I
    > make the table maker function work with lme4 objects (the
    > stable CRAN version), is that function likely to also work
    > with the development version of lme4? 

Yes, if you do *not* access slots of the resulting object
directly,
but rather use methods such as
    residuals(), fitted(), coefficients(), varCorr()
*or* then, the 
    getME()  function which we've been providing for  CRAN-lme4
for a while now, to make the transition between CRAN-lme4
(will become "lme4.0" and basically unmaintained) and  R-forge-lme4
which will become the new CRAN-lme4
as soon as we have removed the few remaining show-stopping
glitches.

See this posting:
  https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q4/006786.html

and the examples in  ?getME  in CRAN-lme4.

    > I know the class of
    > the objects changed from mer to merMod.  Is that a signal
    > that I am again too early to try to do this?

no, because we tried to ensure that useRs and package writers
can build on top of old- or new-lme4, *not* accessing the
objects directly.

Martin

--
Martin <Maechler at stat.math.ethz.ch>  http://stat.ethz.ch/people/maechler
Seminar f?r Statistik, ETH Z?rich  HG G 16      R?mistrasse 101
CH-8092 Zurich, SWITZERLAND
phone: +41-44-632-3408       fax: ...-1228      <><

    > pj
    > -- 
    > Paul E. Johnson Professor, Political Science ?
    > ?Assoc. Director 1541 Lilac Lane, Room 504 ? ? Center for
    > Research Methods University of Kansas ? ? ? ? ? ? ?
    > University of Kansas http://pj.freefaculty.org ? ? ? ? ?
    > ?http://quant.ku.edu


From bbolker at gmail.com  Tue Apr 10 17:38:40 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Apr 2012 15:38:40 +0000 (UTC)
Subject: [R-sig-ME] Is there a final-ish format for lme4 objects now?
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
Message-ID: <loom.20120410T173244-591@post.gmane.org>

Martin Maechler <maechler at ...> writes:

> 
> >>>>> Paul Johnson <pauljohn32 at ...>
> >>>>>     on Mon, 9 Apr 2012 16:48:10 -0500 writes:
> 
 
  [snip]

>     > Has lme4 output reached a point where I can treat the
>     > output from lme4 functions as "more or less" stable?  If I
>     > make the table maker function work with lme4 objects (the
>     > stable CRAN version), is that function likely to also work
>     > with the development version of lme4? 
> 
> Yes, if you do *not* access slots of the resulting object
> directly,
> but rather use methods such as
>     residuals(), fitted(), coefficients(), varCorr()
> *or* then, the 
>     getME()  function which we've been providing for  CRAN-lme4
> for a while now, to make the transition between CRAN-lme4
> (will become "lme4.0" and basically unmaintained) and  R-forge-lme4
> which will become the new CRAN-lme4
> as soon as we have removed the few remaining show-stopping
> glitches.
> 

  By the way, that's VarCorr() ... vcov() may be useful as well.
The format of the object returned by VarCorr() is a little clunky --
there may be some more convenient/pretty interfaces to it coming,
but the structure itself as described in ?VarCorr should stay
the same.

  You might take a look at my coefplot2 package (on r-forge,
not yet on CRAN) to see if you can use any of its technology
for extracting information from a range of model outputs ...


 Ben Bolker


From roby.joehanes at nih.gov  Tue Apr 10 23:54:32 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 10 Apr 2012 17:54:32 -0400
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <Pine.LNX.4.64.1204101233140.29974@orpheus.qimr.edu.au>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov><5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
	<A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
	<Pine.LNX.4.64.1204101233140.29974@orpheus.qimr.edu.au>
Message-ID: <02802642-70C4-4C87-AB66-19B43531CB79@nih.gov>

Hi David and lmers:

Thank you. Pedigreemm, whose backend is lmer, also can fit mixed model with a kinship matrix. I think both packages can.

I did a little bit of experiment with both packages and found that the -2 log likelihood value (-2LL) of pedigreemm output is consistently smaller than that of kinship, suggesting better convergence. This is perhaps reflected by the backend numerical optimizers used by the package. Moreover, in pedigreemm, I could specify which random effects are affected by the pedigree factor and which ones are not. I could not find such option in kinship package.

Other than these, I am not aware of any differences---especially on models that can or cannot be specified by either package. I wonder if any of you know of this.

Thank you again,
Roby


On Apr 9, 2012, at 10:36 PM, David Duffy wrote:

> On Mon, 9 Apr 2012, Joehanes, Roby (NIH/NHLBI) [F] wrote:
> 
>> Yes, you are right. It appears that package kinship is now broken into 
>> several packages: coxme, kinship2, bdsmatrix, among others. Are you 
>> aware of the difference between them and pedigreemm?
> 
> Terry Therneau wrote in the lmekin vignette:
> 
> "Let me emphasis this: most models that can be fit with the lmekin 
> function can also be fit with lme and/or lmer. For any such model the 
> lme/lmer functions will be faster and have superior support routines 
> (residuals, printing, plotting, etc.) The solution code for lmer is likely 
> also more reliable since it has been exercised on a much wider variety of 
> data sets.
> 
> "However, there are models that lmekin will fit which lme will not. The 
> most obvious of these are models with a random genetic effect, e.g. a 
> kinship matrix. The second class will be models for which the user has 
> written their own variance extension, as described in the variance 
> vignette."
> 
> 
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From roby.joehanes at nih.gov  Tue Apr 10 23:58:30 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 10 Apr 2012 17:58:30 -0400
Subject: [R-sig-ME] Questions about porting pedigreemm to the new lme4
In-Reply-To: <loom.20120404T004614-494@post.gmane.org>
References: <3BBB42A1-2AFB-45F1-B819-4D2ACFDE8696@nih.gov>
	<0fdcade662bf745019d5178ca7dc992a@umich.edu>
	<loom.20120402T221015-332@post.gmane.org>
	<C35F24C8-F5BB-4B4A-8B13-FD5D0C9B6413@nih.gov>
	<6C288834-4360-4B79-9781-2758C038664E@nih.gov>
	<85A822E5-6FAF-4561-B7CF-3EFF23D95A17@nih.gov>
	<E61CFD49-B62E-414A-A069-D0472CA5DA6E@nih.gov>
	<loom.20120404T004614-494@post.gmane.org>
Message-ID: <6BBF4E61-931E-4756-B148-18D7FFC3B85F@nih.gov>

Hi Ben:

I am wondering I should work more on the mer_finalize abstraction. I would like the official stream to accept my patches toward getting pedigreemm to work with the new lme4.

Also, is there anything I can help with fixing the broken pedigreemm examples? Even simple calls to glmer no longer work.

Thank you,
Roby

On Apr 3, 2012, at 6:52 PM, Ben Bolker wrote:

> Joehanes, Roby (NIH/NHLBI) [F] <roby.joehanes at ...> writes:
> 
>> 
>> Hi all:
>> 
>> Attached please find the patch to pedigreemm toward using the new lme4 (with
> the patch I submitted
>> earlier). However, the patch does NOT work with the following error:
>> Error in function (value)  : Field "Zt" is read-only
>> 
>> I believe the error is thrown at this statement:
>> lmf$rho$pp$Zt <- relfac[[i]] %*% Zt
>> 
>> I have no idea how to proceed. Any help is appreciated.
>> 
>> Thank you,
>> Roby
> 
>  I will take a look at this as soon as I can.
>  Setting components of objects in new-lme4 is tricky because
> the objects are defined as reference classes, so that messing
> with their internals can disrupt existing objects that they
> have been copied from (!!) 
> 
> Abstracting the equivalent of "mer_finalize" is, I think, a good
> idea.  Yes, nAGQ=0 is allowed for [NG]LMMs ... the idea being (I think)
> that for a well-behaved but very large problem one could save time
> by just doing the "zeroth-order" fit (even faster than nAGQ=1,
> which corresponds to Laplace approximation)
> 
>  Ben Bolker


From j.deikumah2 at uq.edu.au  Wed Apr 11 03:27:24 2012
From: j.deikumah2 at uq.edu.au (Justus Deikumah)
Date: Wed, 11 Apr 2012 01:27:24 +0000
Subject: [R-sig-ME] Loops lme4
Message-ID: <74C378BE307E5D49898BABE3CCFD29A3DFB0@uqexmdb2.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120411/94fcaf87/attachment.pl>

From David.Duffy at qimr.edu.au  Wed Apr 11 07:17:21 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 11 Apr 2012 15:17:21 +1000 (EST)
Subject: [R-sig-ME] Loops lme4
In-Reply-To: <74C378BE307E5D49898BABE3CCFD29A3DFB0@uqexmdb2.soe.uq.edu.au>
References: <74C378BE307E5D49898BABE3CCFD29A3DFB0@uqexmdb2.soe.uq.edu.au>
Message-ID: <Pine.LNX.4.64.1204111503440.32401@orpheus.qimr.edu.au>

Your example data has very few of the variables in your example model. 
But anyway, I guess you need to look at the results from

> str(m126)

and work out which bits you want to pull out, eg

summary(m126)@coefs[,1:2] contains the beta and SE from the fixed effects 
bit, so

#
# No, not tested
#
se <- beta <- matrix(NA, nr=Nmodels, nc=Nfixef)
all.xvars <-  c("elev",  "Sobs", etc )
colnames(se) <- colnames(beta) <- c("(Intercept)", all.xvars)

for(i in seq(1, Nmodels)) {
   xvars <- make.list.of.xvars(i, all.xvars)
   form <- make.formula(i, xvars, zvars)
   mod <- lmer(form, data=x)
   fixed <- summary(mod)@coefs[,1:2])
   beta[i, xvars] <- fixed[,1]
   se[i, xvars] <- fixed[,2]
}

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From David.Duffy at qimr.edu.au  Wed Apr 11 07:37:23 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 11 Apr 2012 15:37:23 +1000 (EST)
Subject: [R-sig-ME] Binary clustered data with negative
	intraclasscorrelation
In-Reply-To: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>
References: <CACSsqTMDMdJSFvoPTbW4SvNBZxewatUwMkftVpeb8Bx3Qzcr5g@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1204111535060.32401@orpheus.qimr.edu.au>

On Fri, 6 Apr 2012, Henrik Hermansson wrote:

> I have clustered data with a binary outcome. But, rather unusually
> (but logically, given the application) the correlation within the
> clusters is negative, as a result of competition within the cluster.

Did someone suggest the VGAM package
("vglm(ymat ~ x, binom2.or(exch=TRUE))")

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From klasen at mpipz.mpg.de  Wed Apr 11 09:57:22 2012
From: klasen at mpipz.mpg.de (Jonas Klasen)
Date: Wed, 11 Apr 2012 09:57:22 +0200
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <02802642-70C4-4C87-AB66-19B43531CB79@nih.gov>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov>
	<5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk>
	<A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov>
	<Pine.LNX.4.64.1204101233140.29974@orpheus.qimr.edu.au>
	<02802642-70C4-4C87-AB66-19B43531CB79@nih.gov>
Message-ID: <4F853962.4040303@mpipz.mpg.de>

There is a difference if you have only one observation per individual. 
Then you have to make slight change in the lme4 package (cran) to get 
pedigreemm to work. See: 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003340.html

So far as I know, in the pedigreemm package, there is only the internal 
function pedigreemm:::ZStar which can handle covariance relationship 
matrices. So there is no officially supported way for implementing a 
kinship in pedigreemm,or I'm wrong?

On 04/10/2012 11:54 PM, Joehanes, Roby (NIH/NHLBI) [F] wrote:
> Hi David and lmers:
>
> Thank you. Pedigreemm, whose backend is lmer, also can fit mixed model with a kinship matrix. I think both packages can.
>
> I did a little bit of experiment with both packages and found that the -2 log likelihood value (-2LL) of pedigreemm output is consistently smaller than that of kinship, suggesting better convergence. This is perhaps reflected by the backend numerical optimizers used by the package. Moreover, in pedigreemm, I could specify which random effects are affected by the pedigree factor and which ones are not. I could not find such option in kinship package.
>
> Other than these, I am not aware of any differences---especially on models that can or cannot be specified by either package. I wonder if any of you know of this.
>
> Thank you again,
> Roby
>
>
> On Apr 9, 2012, at 10:36 PM, David Duffy wrote:
>
>> On Mon, 9 Apr 2012, Joehanes, Roby (NIH/NHLBI) [F] wrote:
>>
>>> Yes, you are right. It appears that package kinship is now broken into
>>> several packages: coxme, kinship2, bdsmatrix, among others. Are you
>>> aware of the difference between them and pedigreemm?
>> Terry Therneau wrote in the lmekin vignette:
>>
>> "Let me emphasis this: most models that can be fit with the lmekin
>> function can also be fit with lme and/or lmer. For any such model the
>> lme/lmer functions will be faster and have superior support routines
>> (residuals, printing, plotting, etc.) The solution code for lmer is likely
>> also more reliable since it has been exercised on a much wider variety of
>> data sets.
>>
>> "However, there are models that lmekin will fit which lme will not. The
>> most obvious of these are models with a random genetic effect, e.g. a
>> kinship matrix. The second class will be models for which the user has
>> written their own variance extension, as described in the variance
>> vignette."
>>
>>
>> -- 
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
__________________________________________________

  Jonas Klasen
  PhD student
  Genome Plasticity and Computational Genetics
  Max Planck Institute for Plant Breeding Research


From David.Duffy at qimr.edu.au  Wed Apr 11 10:53:03 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 11 Apr 2012 18:53:03 +1000 (EST)
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <4F853962.4040303@mpipz.mpg.de>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov><5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk><A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov><Pine.LNX.4.64.1204101233140.29974@orpheus.qimr.edu.au><02802642-70C4-4C87-AB66-19B43531CB79@nih.gov>
	<4F853962.4040303@mpipz.mpg.de>
Message-ID: <Pine.LNX.4.64.1204111834450.8953@orpheus.qimr.edu.au>

On Wed, 11 Apr 2012, Jonas Klasen wrote:

> So far as I know, in the pedigreemm package, there is only the internal 
> function pedigreemm:::ZStar which can handle covariance relationship 
> matrices. So there is no officially supported way for implementing a kinship 
> in pedigreemm,or I'm wrong?

I thought that pedigreemm(...pedigree=list()) was the official 
interface for including "the (left) Cholesky factor of the relationship 
matrix".  But yes, it sounds like it doesn't yet work with the latest 
lme4.

Cheers, David Duffy

P.S. For the curious, you can also see some code

http://genepi.qimr.edu.au/staff/davidD/Sib-pair/Src/sib-pair.R

for the LMM and probit-normal GLMM (function do_varcomp()).  It allows to 
you to add an empirical kinship matrix for VC linkage analysis.  Fitting 
is direct maximization of the likelihood using optim().  It is pretty slow 
on large kindreds (no sparse matrices etc), but a proof it is pretty easy 
to roll your own in R.  It does have the advantage of not complaining 
about non-full-rank NRMs.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From roby.joehanes at nih.gov  Wed Apr 11 16:28:35 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Wed, 11 Apr 2012 10:28:35 -0400
Subject: [R-sig-ME] Kinship vs. Pedigreemm
In-Reply-To: <Pine.LNX.4.64.1204111834450.8953@orpheus.qimr.edu.au>
References: <E42E2C1D-5C35-4DE9-9ABC-A1539426CE6C@nih.gov><5794A882-AA50-4905-BCE8-31C2CE7BDD19@imperial.ac.uk><A1A68647-6B93-467B-8066-86DEA0FF493A@nih.gov><Pine.LNX.4.64.1204101233140.29974@orpheus.qimr.edu.au><02802642-70C4-4C87-AB66-19B43531CB79@nih.gov>
	<4F853962.4040303@mpipz.mpg.de>
	<Pine.LNX.4.64.1204111834450.8953@orpheus.qimr.edu.au>
Message-ID: <88945A59-7EF1-4B44-A76B-2EB698C2D283@nih.gov>

Hi Jonas and David and lmers:

Yes, I noticed that I needed to make modifications to allow one observation per individual. That was done in my last patches, which I have submitted to lme4 bug tracker. However, I noticed that the new lme4 (as of SVN revision 1703) still has bugs in the glmer function. This prevents pedigreemm to work with the new glmer (even after my patches). However, my patches allow pedigreemm to work with the new lmer.

Indeed, ZStar allows us to specify any covariance relationship matrix (provided it is symmetric positive definite), but the matrix has to be Cholesky-decomposed first. As far as I know, ZStar is undocumented. From the code, it looks very much similar to pedigreemm(..., pedigree=list(...)) except that it allows custom relationship matrix.

I will check your code, David. Optim is used even in kinship. I am pretty much against optim since I found bobyqa routine in minqa package is much more efficient. Thanks a lot.

Sincerely,
Roby


On Apr 11, 2012, at 4:53 AM, David Duffy wrote:

> On Wed, 11 Apr 2012, Jonas Klasen wrote:
> 
>> So far as I know, in the pedigreemm package, there is only the internal 
>> function pedigreemm:::ZStar which can handle covariance relationship 
>> matrices. So there is no officially supported way for implementing a kinship 
>> in pedigreemm,or I'm wrong?
> 
> I thought that pedigreemm(...pedigree=list()) was the official 
> interface for including "the (left) Cholesky factor of the relationship 
> matrix".  But yes, it sounds like it doesn't yet work with the latest 
> lme4.
> 
> Cheers, David Duffy
> 
> P.S. For the curious, you can also see some code
> 
> http://genepi.qimr.edu.au/staff/davidD/Sib-pair/Src/sib-pair.R
> 
> for the LMM and probit-normal GLMM (function do_varcomp()).  It allows to 
> you to add an empirical kinship matrix for VC linkage analysis.  Fitting 
> is direct maximization of the likelihood using optim().  It is pretty slow 
> on large kindreds (no sparse matrices etc), but a proof it is pretty easy 
> to roll your own in R.  It does have the advantage of not complaining 
> about non-full-rank NRMs.


From deter088 at umn.edu  Wed Apr 11 18:12:25 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 11 Apr 2012 11:12:25 -0500
Subject: [R-sig-ME] gls and lme?
Message-ID: <CAOLJphk+Up2zFPvoTfX_Tmcc4EMHKL0NFC_z2j0_DuERzKQm8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120411/d1e042b5/attachment.pl>

From atyre2 at unl.edu  Wed Apr 11 17:56:59 2012
From: atyre2 at unl.edu (Drew Tyre)
Date: Wed, 11 Apr 2012 10:56:59 -0500
Subject: [R-sig-ME] Loops lme4
In-Reply-To: <74C378BE307E5D49898BABE3CCFD29A3DFB0@uqexmdb2.soe.uq.edu.au>
References: <74C378BE307E5D49898BABE3CCFD29A3DFB0@uqexmdb2.soe.uq.edu.au>
Message-ID: <CAE-6tvwDdk6ywM4RFfqpY_rTVmnFZsw4kKK+fFK33r88_vPnEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120411/66f137f8/attachment.pl>

From timothy.paine at ieu.uzh.ch  Wed Apr 11 19:33:51 2012
From: timothy.paine at ieu.uzh.ch (C. E. Timothy Paine)
Date: Wed, 11 Apr 2012 19:33:51 +0200
Subject: [R-sig-ME] Loops lme4
In-Reply-To: <CAE-6tvwDdk6ywM4RFfqpY_rTVmnFZsw4kKK+fFK33r88_vPnEA@mail.gmail.com>
References: <74C378BE307E5D49898BABE3CCFD29A3DFB0@uqexmdb2.soe.uq.edu.au>
	<CAE-6tvwDdk6ywM4RFfqpY_rTVmnFZsw4kKK+fFK33r88_vPnEA@mail.gmail.com>
Message-ID: <2C3CEA32-E71F-45FD-8EDC-6E7989ADA73F@ieu.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120411/dfeb710b/attachment.pl>

From aghaynes at gmail.com  Thu Apr 12 13:38:45 2012
From: aghaynes at gmail.com (Alan Haynes)
Date: Thu, 12 Apr 2012 13:38:45 +0200
Subject: [R-sig-ME] gls and lme?
In-Reply-To: <CAOLJphk+Up2zFPvoTfX_Tmcc4EMHKL0NFC_z2j0_DuERzKQm8A@mail.gmail.com>
References: <CAOLJphk+Up2zFPvoTfX_Tmcc4EMHKL0NFC_z2j0_DuERzKQm8A@mail.gmail.com>
Message-ID: <CAPdSD+7rcGaq+3T5Lr4Usi32ZMp+bPsYt6bot_UKRjs9dJZOJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120412/57c6979b/attachment.pl>

From h.colleran at ucl.ac.uk  Thu Apr 12 14:53:55 2012
From: h.colleran at ucl.ac.uk (Heidi Colleran)
Date: Thu, 12 Apr 2012 13:53:55 +0100
Subject: [R-sig-ME] Summarising Model fit using PML in R package 'blme'
Message-ID: <CAL27_TGhW0CGDQcMPsgHR8WJbO-HR2frSaj2oLA+nBJvvaU6GA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120412/66786476/attachment.pl>

From deter088 at umn.edu  Thu Apr 12 15:54:33 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 12 Apr 2012 08:54:33 -0500
Subject: [R-sig-ME] gls and lme?
In-Reply-To: <CAPdSD+7rcGaq+3T5Lr4Usi32ZMp+bPsYt6bot_UKRjs9dJZOJw@mail.gmail.com>
References: <CAOLJphk+Up2zFPvoTfX_Tmcc4EMHKL0NFC_z2j0_DuERzKQm8A@mail.gmail.com>
	<CAPdSD+7rcGaq+3T5Lr4Usi32ZMp+bPsYt6bot_UKRjs9dJZOJw@mail.gmail.com>
Message-ID: <CAOLJphn7Mh4cdKXGkcRpy7w=7XtXuWZ-gkLbL-SE+SycJ00Zfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120412/7f6861ec/attachment.pl>

From eef201 at exeter.ac.uk  Thu Apr 12 16:19:02 2012
From: eef201 at exeter.ac.uk (Flores-de-Gracia, Eric)
Date: Thu, 12 Apr 2012 15:19:02 +0100
Subject: [R-sig-ME] Continuous variables interaction plot
Message-ID: <8395A297256F694B9308A0446D3CF6A53BDCA800DC@EXCHMBS03.isad.isadroot.ex.ac.uk>

Dear all.

I have been working with three continuous variables, to explore the effects of jnd_lum and jnd_colour on seg_expos

My minimal model is:

expos1<-lm (seg_expos~jnd_colour+jnd_lum+jnd_colour:jnd_lum,na.action=na.omit)

The interaction jnd_colour:jnd_lum is significant so want to plot such effect on the variable seg_expos

I have tried the following function but without much success:

wireframe(seg_expos~jnd_colour+jnd_lum,screen=list(z=245,x=-75),

Any hint will be appreciated, regards,

Eric Flores De Gracia
School of Biosciences
University of Exeter, Cornwall Campus
Penryn, Cornwall
TR10 9EZ
United Kingdom
Mobilephone: +044 07578724705
http://biosciences.exeter.ac.uk/staff/postgradresearch/ericflores/

From renaud.lancelot at cirad.fr  Thu Apr 12 20:05:42 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Thu, 12 Apr 2012 20:05:42 +0200
Subject: [R-sig-ME] lme4 broken ?
In-Reply-To: <20356.16910.332273.687519@stat.math.ethz.ch>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
Message-ID: <4F871976.8000700@cirad.fr>

Dear all,

I just noticed:

 > library(lme4)
Le chargement a n?cessit? le package : Matrix
Le chargement a n?cessit? le package : lattice

Attachement du package : ?lme4?

The following object(s) are masked from ?package:stats?:

     AIC, BIC

 > example(lmer)

lmer> ## linear mixed models
lmer> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Erreur dans diag(val) :
   7 arguments passed to .Internal(identical) which requires 6

 > sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
[3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
[5] LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-42 Matrix_1.0-7     lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.15.0   nlme_3.1-103  stats4_2.15.0 tools_2.15.0

Might it be related to the latest release of Matrix?

It also happens with the development lme4 version on R-Forge.

Kind regards,

Renaud


-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From roby.joehanes at nih.gov  Thu Apr 12 20:11:32 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Thu, 12 Apr 2012 14:11:32 -0400
Subject: [R-sig-ME] lme4 broken ?
In-Reply-To: <4F871976.8000700@cirad.fr>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
	<4F871976.8000700@cirad.fr>
Message-ID: <A7A15D25-0B9B-437F-BDB7-13EDE956666B@nih.gov>

Hi Renaud,

It works okay in my computer (Linux). Maybe you want to update all underlying libraries?

Hope this helps,
Roby

 (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))


From renaud.lancelot at cirad.fr  Fri Apr 13 08:55:24 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Fri, 13 Apr 2012 08:55:24 +0200
Subject: [R-sig-ME] lme4 broken ?
In-Reply-To: <A7A15D25-0B9B-437F-BDB7-13EDE956666B@nih.gov>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
	<4F871976.8000700@cirad.fr>
	<A7A15D25-0B9B-437F-BDB7-13EDE956666B@nih.gov>
Message-ID: <4F87CDDC.9070806@cirad.fr>

I re-installed the previous version of Matrix (Matrix_1.0-5.tar.gz 
available on CRAN) from source, and it now works (see below).

I confirm there is a problem - at least on Windows - between lme4 (CRAN 
and R-Forge present versions) and the present version of Matrix 1.0-6.

All the best,

Renaud

 > sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252 
LC_MONETARY=French_France.1252 LC_NUMERIC=C 
LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999902344-0 Matrix_1.0-5       lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.15.0    MASS_7.3-17    minqa_1.2.0    nlme_3.1-103 
splines_2.15.0 tools_2.15.0


 > library(lme4)
Le chargement a n?cessit? le package : lattice
Le chargement a n?cessit? le package : Matrix
 > example(lmer)

lmer> ## linear mixed models - reference values from older code
lmer> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Linear mixed model fit by REML ['lmerMod']
Formula: Reaction ~ Days + (Days | Subject)
    Data: sleepstudy

REML criterion at convergence: 1743.628

Random effects:
  Groups   Name        Variance Std.Dev. Corr
  Subject  (Intercept) 612.10   24.741
           Days         35.07    5.922   0.066
  Residual             654.94   25.592
Number of obs: 180, groups: Subject, 18

Fixed effects:
             Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
      (Intr)
Days -0.138

lmer> (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), 
sleepstudy))
Linear mixed model fit by REML ['lmerMod']
Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
    Data: sleepstudy

REML criterion at convergence: 1743.669

Random effects:
  Groups   Name        Variance Std.Dev.
  Subject  (Intercept) 627.58   25.052
  Subject  Days         35.86    5.988
  Residual             653.58   25.565
Number of obs: 180, groups: Subject, 18

Fixed effects:
             Estimate Std. Error t value
(Intercept)  251.405      6.885   36.51
Days          10.467      1.560    6.71

Correlation of Fixed Effects:
      (Intr)
Days -0.184

lmer> anova(fm1, fm2)
Data: sleepstudy
Models:
fm2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
fm1: Reaction ~ Days + (Days | Subject)
     Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
fm2  5 1762.0 1778.0 -876.00   1752.0
fm1  6 1763.9 1783.1 -875.97   1751.9 0.0639      1     0.8004



Le 12/04/2012 20:11, Joehanes, Roby (NIH/NHLBI) [F] a ?crit :
> Hi Renaud,
>
> It works okay in my computer (Linux). Maybe you want to update all underlying libraries?
>
> Hope this helps,
> Roby
>
>   (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From Christoph.Scherber at agr.uni-goettingen.de  Fri Apr 13 09:04:58 2012
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Fri, 13 Apr 2012 09:04:58 +0200
Subject: [R-sig-ME] gls and lme?
In-Reply-To: <CAOLJphk+Up2zFPvoTfX_Tmcc4EMHKL0NFC_z2j0_DuERzKQm8A@mail.gmail.com>
References: <CAOLJphk+Up2zFPvoTfX_Tmcc4EMHKL0NFC_z2j0_DuERzKQm8A@mail.gmail.com>
Message-ID: <4F87D01A.7010803@agr.uni-goettingen.de>

Dear Charles,

Your error comes because your lme model needs to have a random component.

You need to make sure that your correlation structure and your random 
effects structure match exactly:

fit.10=lme(met~group+Event_name+
	survival+group*Event_name,
	random=~1|ID,
	data=set1,
	corr=corSymm(form=~1|ID),
	weights=varIdent(form=~1|Event_name))

Best wishes
Christoph



On 11.04.2012 18:12, Charles Determan Jr wrote:
> Greetings R users,
>
> I have been trying to generate a mixed model of some data and I have run
> into a stumble.  I am trying to do what sas refers to as 'unstructured'
> variance structure.  The comparable correlation structure in the nlme
> package is corSymm().  I am able to run it generally just fine but when I
> try unstructured I run into this problem.  I am able to run a gls() script
> but when I try and run the same thing with lme(), I get the error shown
> below.
>
> In the simplest form, the model that works perfectly is:
>
> fit.7=lme(met~group+Event_name+
>      Survival+group*Event_name,
>      data=set1,
>      random=~1|ID/Event_name)
>
> The random is structured because the set is nested data.  I have been
> trying to run an unstructured version.
>
>
>
> The gls() version using corSymm works but I didn't think this was still a
> mixed model but a general least squares model instead.
>
> fit.10=gls(met~group+Event_name+
>      survival+group*Event_name,
>      data=set1,
>      corr=corSymm(form=~1|ID),
>      weights=varIdent(form=~1|Event_name))
>
>
> The model I wish to fit is with lme()
>
> fit.10=lme(met~group+Event_name+
>      survival+group*Event_name,
>      data=set1,
>      corr=corSymm(form=~1|ID),
>      weights=varIdent(form=~1|Event_name))
>
> Error in lme.formula(met ~ group + Event_name + survival + group *  :
>    Incompatible formulas for groups in "random" and "correlation"
> Done.
>
> Is there some syntax I have mistaken or coded incorrectly?  Why is it that
> the lme() script doesn't work?  Any general advice is appreciated.
>
> Charles
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From maechler at stat.math.ethz.ch  Fri Apr 13 09:19:07 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 13 Apr 2012 09:19:07 +0200
Subject: [R-sig-ME] lme4 broken ?
In-Reply-To: <4F87CDDC.9070806@cirad.fr>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
	<4F871976.8000700@cirad.fr>
	<A7A15D25-0B9B-437F-BDB7-13EDE956666B@nih.gov>
	<4F87CDDC.9070806@cirad.fr>
Message-ID: <20359.54123.865732.109331@stat.math.ethz.ch>

>>>>> "l" == lancelot  <renaud.lancelot at cirad.fr>
>>>>>     on Fri, 13 Apr 2012 08:55:24 +0200 writes:

    > I re-installed the previous version of Matrix (Matrix_1.0-5.tar.gz 
    > available on CRAN) from source, and it now works (see below).

    > I confirm there is a problem - at least on Windows - between lme4
    > and R-Forge present versions) and the present version of
    > Matrix 1.0-6.

Hmm, I very much doubt this, at it least in this generality.
Other people have seen similar problems (not involving lme4 at
all), on R-help or R-devel, and the solution has been to
re-install packages (or R!) only.

The mismatch of number of arguments of .Internal(identical)
is really from using packages that were *built* with one version
of R, in a different version of *R*.

So, in principle

    update.packages(checkBuilt = TRUE)

should get you there.

Regards,
Martin Maechler


    > All the best,

    > Renaud

    >> sessionInfo()
    > R version 2.15.0 (2012-03-30)
    > Platform: i386-pc-mingw32/i386 (32-bit)

    > locale:
    > [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252 
    > LC_MONETARY=French_France.1252 LC_NUMERIC=C 
    > LC_TIME=French_France.1252

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base

    > other attached packages:
    > [1] lme4_0.999902344-0 Matrix_1.0-5       lattice_0.20-6

    > loaded via a namespace (and not attached):
    > [1] grid_2.15.0    MASS_7.3-17    minqa_1.2.0    nlme_3.1-103 
    > splines_2.15.0 tools_2.15.0


    >> library(lme4)
    > Le chargement a n?cessit? le package : lattice
    > Le chargement a n?cessit? le package : Matrix
    >> example(lmer)

    lmer> ## linear mixed models - reference values from older code
    lmer> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    > Linear mixed model fit by REML ['lmerMod']
    > Formula: Reaction ~ Days + (Days | Subject)
    > Data: sleepstudy

    > REML criterion at convergence: 1743.628

    > Random effects:
    > Groups   Name        Variance Std.Dev. Corr
    > Subject  (Intercept) 612.10   24.741
    > Days         35.07    5.922   0.066
    > Residual             654.94   25.592
    > Number of obs: 180, groups: Subject, 18

    > Fixed effects:
    > Estimate Std. Error t value
    > (Intercept)  251.405      6.825   36.84
    > Days          10.467      1.546    6.77

    > Correlation of Fixed Effects:
    > (Intr)
    > Days -0.138

    lmer> (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), 
    > sleepstudy))
    > Linear mixed model fit by REML ['lmerMod']
    > Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
    > Data: sleepstudy

    > REML criterion at convergence: 1743.669

    > Random effects:
    > Groups   Name        Variance Std.Dev.
    > Subject  (Intercept) 627.58   25.052
    > Subject  Days         35.86    5.988
    > Residual             653.58   25.565
    > Number of obs: 180, groups: Subject, 18

    > Fixed effects:
    > Estimate Std. Error t value
    > (Intercept)  251.405      6.885   36.51
    > Days          10.467      1.560    6.71

    > Correlation of Fixed Effects:
    > (Intr)
    > Days -0.184

    lmer> anova(fm1, fm2)
    > Data: sleepstudy
    > Models:
    > fm2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
    > fm1: Reaction ~ Days + (Days | Subject)
    > Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
    > fm2  5 1762.0 1778.0 -876.00   1752.0
    > fm1  6 1763.9 1783.1 -875.97   1751.9 0.0639      1     0.8004



    > Le 12/04/2012 20:11, Joehanes, Roby (NIH/NHLBI) [F] a ?crit :
    >> Hi Renaud,
    >> 
    >> It works okay in my computer (Linux). Maybe you want to update all
    >> underlying libraries?
    >> 
    >> Hope this helps, Roby
    >> 
    >> (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >> 
    >> _______________________________________________
    >> R-sig-mixed-models at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> 

    > -- 
    > Renaud Lancelot
    > EDENext Project, coordinator: http://www.edenext.eu/

    > CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
    > F34398 Montpellier

    > Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
    > Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From torvon at gmail.com  Fri Apr 13 11:32:14 2012
From: torvon at gmail.com (Eiko Fried)
Date: Fri, 13 Apr 2012 11:32:14 +0200
Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
Message-ID: <CACm_P7p5sFCzs-a=t30ZSt0MNEp-iU5x5AeeAqqhKYSumWRjMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120413/660a17bc/attachment.pl>

From renaud.lancelot at cirad.fr  Fri Apr 13 11:49:20 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Fri, 13 Apr 2012 11:49:20 +0200
Subject: [R-sig-ME] lme4 broken ?
In-Reply-To: <20359.54123.865732.109331@stat.math.ethz.ch>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
	<4F871976.8000700@cirad.fr>
	<A7A15D25-0B9B-437F-BDB7-13EDE956666B@nih.gov>
	<4F87CDDC.9070806@cirad.fr>
	<20359.54123.865732.109331@stat.math.ethz.ch>
Message-ID: <4F87F6A0.7030302@cirad.fr>

Dear Martin and all,

Thank you very much for your time. However:

 > remove.packages("lme4")
Elimination de(s) package(s) de ?C:/R/RLIBS?
(car ?lib? n'est pas sp?cifi?)
 > install.packages("lme4")
Installation d(es) package(s) dans ?C:/R/RLIBS?
(car ?lib? n'est pas sp?cifi?)
essai de l'URL 
'http://cran.r-project.org/bin/windows/contrib/2.15/lme4_0.999375-42.zip'
Content type 'application/zip' length 1300772 bytes (1.2 Mb)
URL ouverte
downloaded 1.2 Mb

le package ?lme4? a ?t? d?compress? et les sommes MD5 ont ?t? v?rifi?es 
avec succ?s

Les packages binaires t?l?charg?s sont dans
         C:\Temp\RtmpsnSVf7\downloaded_packages
 > update.packages(checkBuilt = TRUE)
Matrix :
  Version 1.0-5 installed in C:/R/RLIBS built under R 2.15.0
  Version 1.0-7 available at http://R-Forge.R-project.org
Update (y/N/c)?  y
essai de l'URL 
'http://R-Forge.R-project.org/bin/windows/contrib/2.15/Matrix_1.0-7.zip'
Content type 'application/zip' length 3252028 bytes (3.1 Mb)
URL ouverte
downloaded 3.1 Mb

le package ?Matrix? a ?t? d?compress? et les sommes MD5 ont ?t? 
v?rifi?es avec succ?s

Les packages binaires t?l?charg?s sont dans
         C:\Temp\RtmpCGB7op\downloaded_packages
 > library(lme4)
Le chargement a n?cessit? le package : lattice
Le chargement a n?cessit? le package : Matrix
 > example(lmer)

lmer> ## linear mixed models - reference values from older code
lmer> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Erreur dans diag(val) :
   7 arguments passed to .Internal(identical) which requires 6


Renaud


Le 13/04/2012 09:19, Martin Maechler a ?crit :
>>>>>> "l" == lancelot<renaud.lancelot at cirad.fr>
>>>>>>      on Fri, 13 Apr 2012 08:55:24 +0200 writes:
>
>      >  I re-installed the previous version of Matrix (Matrix_1.0-5.tar.gz
>      >  available on CRAN) from source, and it now works (see below).
>
>      >  I confirm there is a problem - at least on Windows - between lme4
>      >  and R-Forge present versions) and the present version of
>      >  Matrix 1.0-6.
>
> Hmm, I very much doubt this, at it least in this generality.
> Other people have seen similar problems (not involving lme4 at
> all), on R-help or R-devel, and the solution has been to
> re-install packages (or R!) only.
>
> The mismatch of number of arguments of .Internal(identical)
> is really from using packages that were *built* with one version
> of R, in a different version of *R*.
>
> So, in principle
>
>      update.packages(checkBuilt = TRUE)
>
> should get you there.
>
> Regards,
> Martin Maechler
>
>
>      >  All the best,
>
>      >  Renaud
>
>      >>  sessionInfo()
>      >  R version 2.15.0 (2012-03-30)
>      >  Platform: i386-pc-mingw32/i386 (32-bit)
>
>      >  locale:
>      >  [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
>      >  LC_MONETARY=French_France.1252 LC_NUMERIC=C
>      >  LC_TIME=French_France.1252
>
>      >  attached base packages:
>      >  [1] stats     graphics  grDevices utils     datasets  methods   base
>
>      >  other attached packages:
>      >  [1] lme4_0.999902344-0 Matrix_1.0-5       lattice_0.20-6
>
>      >  loaded via a namespace (and not attached):
>      >  [1] grid_2.15.0    MASS_7.3-17    minqa_1.2.0    nlme_3.1-103
>      >  splines_2.15.0 tools_2.15.0
>
>
>      >>  library(lme4)
>      >  Le chargement a n?cessit? le package : lattice
>      >  Le chargement a n?cessit? le package : Matrix
>      >>  example(lmer)
>
>      lmer>  ## linear mixed models - reference values from older code
>      lmer>  (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>      >  Linear mixed model fit by REML ['lmerMod']
>      >  Formula: Reaction ~ Days + (Days | Subject)
>      >  Data: sleepstudy
>
>      >  REML criterion at convergence: 1743.628
>
>      >  Random effects:
>      >  Groups   Name        Variance Std.Dev. Corr
>      >  Subject  (Intercept) 612.10   24.741
>      >  Days         35.07    5.922   0.066
>      >  Residual             654.94   25.592
>      >  Number of obs: 180, groups: Subject, 18
>
>      >  Fixed effects:
>      >  Estimate Std. Error t value
>      >  (Intercept)  251.405      6.825   36.84
>      >  Days          10.467      1.546    6.77
>
>      >  Correlation of Fixed Effects:
>      >  (Intr)
>      >  Days -0.138
>
>      lmer>  (fm2<- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
>      >  sleepstudy))
>      >  Linear mixed model fit by REML ['lmerMod']
>      >  Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
>      >  Data: sleepstudy
>
>      >  REML criterion at convergence: 1743.669
>
>      >  Random effects:
>      >  Groups   Name        Variance Std.Dev.
>      >  Subject  (Intercept) 627.58   25.052
>      >  Subject  Days         35.86    5.988
>      >  Residual             653.58   25.565
>      >  Number of obs: 180, groups: Subject, 18
>
>      >  Fixed effects:
>      >  Estimate Std. Error t value
>      >  (Intercept)  251.405      6.885   36.51
>      >  Days          10.467      1.560    6.71
>
>      >  Correlation of Fixed Effects:
>      >  (Intr)
>      >  Days -0.184
>
>      lmer>  anova(fm1, fm2)
>      >  Data: sleepstudy
>      >  Models:
>      >  fm2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
>      >  fm1: Reaction ~ Days + (Days | Subject)
>      >  Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>      >  fm2  5 1762.0 1778.0 -876.00   1752.0
>      >  fm1  6 1763.9 1783.1 -875.97   1751.9 0.0639      1     0.8004
>
>
>
>      >  Le 12/04/2012 20:11, Joehanes, Roby (NIH/NHLBI) [F] a ?crit :
>      >>  Hi Renaud,
>      >>
>      >>  It works okay in my computer (Linux). Maybe you want to update all
>      >>  underlying libraries?
>      >>
>      >>  Hope this helps, Roby
>      >>
>      >>  (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>      >>
>      >>  _______________________________________________
>      >>  R-sig-mixed-models at r-project.org mailing list
>      >>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      >>
>
>      >  --
>      >  Renaud Lancelot
>      >  EDENext Project, coordinator: http://www.edenext.eu/
>
>      >  CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>      >  F34398 Montpellier
>
>      >  Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
>      >  Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
>
>      >  _______________________________________________
>      >  R-sig-mixed-models at r-project.org mailing list
>      >  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From maechler at stat.math.ethz.ch  Fri Apr 13 12:00:05 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 13 Apr 2012 12:00:05 +0200
Subject: [R-sig-ME] lme4 broken ?
In-Reply-To: <4F87F6A0.7030302@cirad.fr>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
	<4F871976.8000700@cirad.fr>
	<A7A15D25-0B9B-437F-BDB7-13EDE956666B@nih.gov>
	<4F87CDDC.9070806@cirad.fr>
	<20359.54123.865732.109331@stat.math.ethz.ch>
	<4F87F6A0.7030302@cirad.fr>
Message-ID: <20359.63781.250170.417590@stat.math.ethz.ch>

As Matrix comes with R,  could you try to just use the version
that comes with R 2.15.0, and *then* install lme4 ?
Or in any case, install lm4 after Matrix, as lme4 depends on
Matrix?

I agree that this is not "useful" behavior...
Martin

>>>>> lancelot  <renaud.lancelot at cirad.fr>
>>>>>     on Fri, 13 Apr 2012 11:49:20 +0200 writes:

    > Dear Martin and all,
    > Thank you very much for your time. However:

    >> remove.packages("lme4")
    > Elimination de(s) package(s) de ?C:/R/RLIBS?
    > (car ?lib? n'est pas sp?cifi?)
    >> install.packages("lme4") Installation d(es) package(s) dans
    > ?C:/R/RLIBS? (car ?lib? n'est pas sp?cifi?) essai de l'URL
    > 'http://cran.r-project.org/bin/windows/contrib/2.15/lme4_0.999375-42.zip'
    > Content type 'application/zip' length 1300772 bytes (1.2 Mb) URL
    > ouverte downloaded 1.2 Mb

    > le package ?lme4? a ?t? d?compress? et les sommes MD5 ont ?t? v?rifi?es
    > avec succ?s

    > Les packages binaires t?l?charg?s sont dans
    > C:\Temp\RtmpsnSVf7\downloaded_packages
    >> update.packages(checkBuilt = TRUE) Matrix : Version 1.0-5 installed in
    > C:/R/RLIBS built under R 2.15.0 Version 1.0-7 available at
    > http://R-Forge.R-project.org Update (y/N/c)?  y essai de l'URL
    > 'http://R-Forge.R-project.org/bin/windows/contrib/2.15/Matrix_1.0-7.zip'
    > Content type 'application/zip' length 3252028 bytes (3.1 Mb) URL
    > ouverte downloaded 3.1 Mb

    > le package ?Matrix? a ?t? d?compress? et les sommes MD5 ont ?t? 
    > v?rifi?es avec succ?s

    > Les packages binaires t?l?charg?s sont dans
    > C:\Temp\RtmpCGB7op\downloaded_packages
    >> library(lme4)
    > Le chargement a n?cessit? le package : lattice
    > Le chargement a n?cessit? le package : Matrix
    >> example(lmer)

    lmer> ## linear mixed models - reference values from older code
    lmer> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    > Erreur dans diag(val) :
    > 7 arguments passed to .Internal(identical) which requires 6


    > Renaud


    > Le 13/04/2012 09:19, Martin Maechler a ?crit :
    >>>>>>> "l" == lancelot<renaud.lancelot at cirad.fr>
    >>>>>>> on Fri, 13 Apr 2012 08:55:24 +0200 writes:
    >> 
    >> >  I re-installed the previous version of Matrix (Matrix_1.0-5.tar.gz
    >> >  available on CRAN) from source, and it now works (see below).
    >> 
    >> >  I confirm there is a problem - at least on Windows - between lme4
    >> >  and R-Forge present versions) and the present version of
    >> >  Matrix 1.0-6.
    >> 
    >> Hmm, I very much doubt this, at it least in this generality.
    >> Other people have seen similar problems (not involving lme4 at
    >> all), on R-help or R-devel, and the solution has been to
    >> re-install packages (or R!) only.
    >> 
    >> The mismatch of number of arguments of .Internal(identical)
    >> is really from using packages that were *built* with one version
    >> of R, in a different version of *R*.
    >> 
    >> So, in principle
    >> 
    >> update.packages(checkBuilt = TRUE)
    >> 
    >> should get you there.
    >> 
    >> Regards,
    >> Martin Maechler
    >> 
    >> 
    >> >  All the best,
    >> 
    >> >  Renaud
    >> 
    >> >>  sessionInfo()
    >> >  R version 2.15.0 (2012-03-30)
    >> >  Platform: i386-pc-mingw32/i386 (32-bit)
    >> 
    >> >  locale:
    >> >  [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
    >> >  LC_MONETARY=French_France.1252 LC_NUMERIC=C
    >> >  LC_TIME=French_France.1252
    >> 
    >> >  attached base packages: [1] stats graphics grDevices utils datasets
    >> >  methods base
    >> 
    >> >  other attached packages:
    >> >  [1] lme4_0.999902344-0 Matrix_1.0-5       lattice_0.20-6
    >> 
    >> >  loaded via a namespace (and not attached):
    >> >  [1] grid_2.15.0    MASS_7.3-17    minqa_1.2.0    nlme_3.1-103
    >> >  splines_2.15.0 tools_2.15.0
    >> 
    >> 
    >> >>  library(lme4)
    >> >  Le chargement a n?cessit? le package : lattice
    >> >  Le chargement a n?cessit? le package : Matrix
    >> >>  example(lmer)
    >> 
    lmer> ## linear mixed models - reference values from older code
    lmer> (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >> >  Linear mixed model fit by REML ['lmerMod']
    >> >  Formula: Reaction ~ Days + (Days | Subject)
    >> >  Data: sleepstudy
    >> 
    >> >  REML criterion at convergence: 1743.628
    >> 
    >> >  Random effects:
    >> >  Groups   Name        Variance Std.Dev. Corr
    >> >  Subject  (Intercept) 612.10   24.741
    >> >  Days         35.07    5.922   0.066
    >> >  Residual             654.94   25.592
    >> >  Number of obs: 180, groups: Subject, 18
    >> 
    >> >  Fixed effects:
    >> >  Estimate Std. Error t value
    >> >  (Intercept)  251.405      6.825   36.84
    >> >  Days          10.467      1.546    6.77
    >> 
    >> >  Correlation of Fixed Effects:
    >> >  (Intr)
    >> >  Days -0.138
    >> 
    lmer> (fm2<- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
    >> >  sleepstudy))
    >> >  Linear mixed model fit by REML ['lmerMod']
    >> >  Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
    >> >  Data: sleepstudy
    >> 
    >> >  REML criterion at convergence: 1743.669
    >> 
    >> >  Random effects:
    >> >  Groups   Name        Variance Std.Dev.
    >> >  Subject  (Intercept) 627.58   25.052
    >> >  Subject  Days         35.86    5.988
    >> >  Residual             653.58   25.565
    >> >  Number of obs: 180, groups: Subject, 18
    >> 
    >> >  Fixed effects:
    >> >  Estimate Std. Error t value
    >> >  (Intercept)  251.405      6.885   36.51
    >> >  Days          10.467      1.560    6.71
    >> 
    >> >  Correlation of Fixed Effects:
    >> >  (Intr)
    >> >  Days -0.184
    >> 
    lmer> anova(fm1, fm2)
    >> >  Data: sleepstudy
    >> >  Models:
    >> >  fm2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
    >> >  fm1: Reaction ~ Days + (Days | Subject)
    >> >  Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
    >> >  fm2  5 1762.0 1778.0 -876.00   1752.0
    >> >  fm1  6 1763.9 1783.1 -875.97   1751.9 0.0639      1     0.8004
    >> 
    >> 
    >> 
    >> >  Le 12/04/2012 20:11, Joehanes, Roby (NIH/NHLBI) [F] a ?crit :
    >> >>  Hi Renaud,
    >> >>
    >> >>  It works okay in my computer (Linux). Maybe you want to update all
    >> >>  underlying libraries?
    >> >>
    >> >>  Hope this helps, Roby
    >> >>
    >> >>  (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >> >>
    >> >>  _______________________________________________
    >> >>  R-sig-mixed-models at r-project.org mailing list
    >> >>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> >>
    >> 
    >> >  --
    >> >  Renaud Lancelot
    >> >  EDENext Project, coordinator: http://www.edenext.eu/
    >> 
    >> >  CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
    >> >  F34398 Montpellier
    >> 
    >> >  Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
    >> >  Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
    >> 
    >> >  _______________________________________________
    >> >  R-sig-mixed-models at r-project.org mailing list
    >> >  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> 

    > -- 
    > Renaud Lancelot
    > EDENext Project, coordinator: http://www.edenext.eu/

    > CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
    > F34398 Montpellier

    > Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
    > Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From renaud.lancelot at cirad.fr  Fri Apr 13 12:26:00 2012
From: renaud.lancelot at cirad.fr (lancelot)
Date: Fri, 13 Apr 2012 12:26:00 +0200
Subject: [R-sig-ME] lme4 broken ?
In-Reply-To: <20359.63781.250170.417590@stat.math.ethz.ch>
References: <CAErODj8GUs3i5RU_FOTHTt-CtrZz9_FXQm5DJtOuFQHyFyUS-g@mail.gmail.com>
	<20356.16910.332273.687519@stat.math.ethz.ch>
	<4F871976.8000700@cirad.fr>
	<A7A15D25-0B9B-437F-BDB7-13EDE956666B@nih.gov>
	<4F87CDDC.9070806@cirad.fr>
	<20359.54123.865732.109331@stat.math.ethz.ch>
	<4F87F6A0.7030302@cirad.fr>
	<20359.63781.250170.417590@stat.math.ethz.ch>
Message-ID: <4F87FF38.20606@cirad.fr>

Dear Martin,

I just installed the patched version of R, and then re-installed from 
source the CRAN version of lme4. It now works fine. The same for the 
R-Forge version of lme4. Here is the session info for the latter case:

 > sessionInfo()
R version 2.15.0 Patched (2012-04-09 r58947)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
[3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
[5] LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999902344-0 Matrix_1.0-7       lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.15.0    MASS_7.3-17    minqa_1.2.0    nlme_3.1-103 
splines_2.15.0
[6] tools_2.15.0

Thank you very much for your help.

Best regards,

Renaud

Le 13/04/2012 12:00, Martin Maechler a ?crit :
> As Matrix comes with R,  could you try to just use the version
> that comes with R 2.15.0, and *then* install lme4 ?
> Or in any case, install lm4 after Matrix, as lme4 depends on
> Matrix?
>
> I agree that this is not "useful" behavior...
> Martin
>
>>>>>> lancelot<renaud.lancelot at cirad.fr>
>>>>>>      on Fri, 13 Apr 2012 11:49:20 +0200 writes:
>
>      >  Dear Martin and all,
>      >  Thank you very much for your time. However:
>
>      >>  remove.packages("lme4")
>      >  Elimination de(s) package(s) de ?C:/R/RLIBS?
>      >  (car ?lib? n'est pas sp?cifi?)
>      >>  install.packages("lme4") Installation d(es) package(s) dans
>      >  ?C:/R/RLIBS? (car ?lib? n'est pas sp?cifi?) essai de l'URL
>      >  'http://cran.r-project.org/bin/windows/contrib/2.15/lme4_0.999375-42.zip'
>      >  Content type 'application/zip' length 1300772 bytes (1.2 Mb) URL
>      >  ouverte downloaded 1.2 Mb
>
>      >  le package ?lme4? a ?t? d?compress? et les sommes MD5 ont ?t? v?rifi?es
>      >  avec succ?s
>
>      >  Les packages binaires t?l?charg?s sont dans
>      >  C:\Temp\RtmpsnSVf7\downloaded_packages
>      >>  update.packages(checkBuilt = TRUE) Matrix : Version 1.0-5 installed in
>      >  C:/R/RLIBS built under R 2.15.0 Version 1.0-7 available at
>      >  http://R-Forge.R-project.org Update (y/N/c)?  y essai de l'URL
>      >  'http://R-Forge.R-project.org/bin/windows/contrib/2.15/Matrix_1.0-7.zip'
>      >  Content type 'application/zip' length 3252028 bytes (3.1 Mb) URL
>      >  ouverte downloaded 3.1 Mb
>
>      >  le package ?Matrix? a ?t? d?compress? et les sommes MD5 ont ?t?
>      >  v?rifi?es avec succ?s
>
>      >  Les packages binaires t?l?charg?s sont dans
>      >  C:\Temp\RtmpCGB7op\downloaded_packages
>      >>  library(lme4)
>      >  Le chargement a n?cessit? le package : lattice
>      >  Le chargement a n?cessit? le package : Matrix
>      >>  example(lmer)
>
>      lmer>  ## linear mixed models - reference values from older code
>      lmer>  (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>      >  Erreur dans diag(val) :
>      >  7 arguments passed to .Internal(identical) which requires 6
>
>
>      >  Renaud
>
>
>      >  Le 13/04/2012 09:19, Martin Maechler a ?crit :
>      >>>>>>>  "l" == lancelot<renaud.lancelot at cirad.fr>
>      >>>>>>>  on Fri, 13 Apr 2012 08:55:24 +0200 writes:
>      >>
>      >>  >   I re-installed the previous version of Matrix (Matrix_1.0-5.tar.gz
>      >>  >   available on CRAN) from source, and it now works (see below).
>      >>
>      >>  >   I confirm there is a problem - at least on Windows - between lme4
>      >>  >   and R-Forge present versions) and the present version of
>      >>  >   Matrix 1.0-6.
>      >>
>      >>  Hmm, I very much doubt this, at it least in this generality.
>      >>  Other people have seen similar problems (not involving lme4 at
>      >>  all), on R-help or R-devel, and the solution has been to
>      >>  re-install packages (or R!) only.
>      >>
>      >>  The mismatch of number of arguments of .Internal(identical)
>      >>  is really from using packages that were *built* with one version
>      >>  of R, in a different version of *R*.
>      >>
>      >>  So, in principle
>      >>
>      >>  update.packages(checkBuilt = TRUE)
>      >>
>      >>  should get you there.
>      >>
>      >>  Regards,
>      >>  Martin Maechler
>      >>
>      >>
>      >>  >   All the best,
>      >>
>      >>  >   Renaud
>      >>
>      >>  >>   sessionInfo()
>      >>  >   R version 2.15.0 (2012-03-30)
>      >>  >   Platform: i386-pc-mingw32/i386 (32-bit)
>      >>
>      >>  >   locale:
>      >>  >   [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
>      >>  >   LC_MONETARY=French_France.1252 LC_NUMERIC=C
>      >>  >   LC_TIME=French_France.1252
>      >>
>      >>  >   attached base packages: [1] stats graphics grDevices utils datasets
>      >>  >   methods base
>      >>
>      >>  >   other attached packages:
>      >>  >   [1] lme4_0.999902344-0 Matrix_1.0-5       lattice_0.20-6
>      >>
>      >>  >   loaded via a namespace (and not attached):
>      >>  >   [1] grid_2.15.0    MASS_7.3-17    minqa_1.2.0    nlme_3.1-103
>      >>  >   splines_2.15.0 tools_2.15.0
>      >>
>      >>
>      >>  >>   library(lme4)
>      >>  >   Le chargement a n?cessit? le package : lattice
>      >>  >   Le chargement a n?cessit? le package : Matrix
>      >>  >>   example(lmer)
>      >>
>      lmer>  ## linear mixed models - reference values from older code
>      lmer>  (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>      >>  >   Linear mixed model fit by REML ['lmerMod']
>      >>  >   Formula: Reaction ~ Days + (Days | Subject)
>      >>  >   Data: sleepstudy
>      >>
>      >>  >   REML criterion at convergence: 1743.628
>      >>
>      >>  >   Random effects:
>      >>  >   Groups   Name        Variance Std.Dev. Corr
>      >>  >   Subject  (Intercept) 612.10   24.741
>      >>  >   Days         35.07    5.922   0.066
>      >>  >   Residual             654.94   25.592
>      >>  >   Number of obs: 180, groups: Subject, 18
>      >>
>      >>  >   Fixed effects:
>      >>  >   Estimate Std. Error t value
>      >>  >   (Intercept)  251.405      6.825   36.84
>      >>  >   Days          10.467      1.546    6.77
>      >>
>      >>  >   Correlation of Fixed Effects:
>      >>  >   (Intr)
>      >>  >   Days -0.138
>      >>
>      lmer>  (fm2<- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
>      >>  >   sleepstudy))
>      >>  >   Linear mixed model fit by REML ['lmerMod']
>      >>  >   Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
>      >>  >   Data: sleepstudy
>      >>
>      >>  >   REML criterion at convergence: 1743.669
>      >>
>      >>  >   Random effects:
>      >>  >   Groups   Name        Variance Std.Dev.
>      >>  >   Subject  (Intercept) 627.58   25.052
>      >>  >   Subject  Days         35.86    5.988
>      >>  >   Residual             653.58   25.565
>      >>  >   Number of obs: 180, groups: Subject, 18
>      >>
>      >>  >   Fixed effects:
>      >>  >   Estimate Std. Error t value
>      >>  >   (Intercept)  251.405      6.885   36.51
>      >>  >   Days          10.467      1.560    6.71
>      >>
>      >>  >   Correlation of Fixed Effects:
>      >>  >   (Intr)
>      >>  >   Days -0.184
>      >>
>      lmer>  anova(fm1, fm2)
>      >>  >   Data: sleepstudy
>      >>  >   Models:
>      >>  >   fm2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
>      >>  >   fm1: Reaction ~ Days + (Days | Subject)
>      >>  >   Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>      >>  >   fm2  5 1762.0 1778.0 -876.00   1752.0
>      >>  >   fm1  6 1763.9 1783.1 -875.97   1751.9 0.0639      1     0.8004
>      >>
>      >>
>      >>
>      >>  >   Le 12/04/2012 20:11, Joehanes, Roby (NIH/NHLBI) [F] a ?crit :
>      >>  >>   Hi Renaud,
>      >>  >>
>      >>  >>   It works okay in my computer (Linux). Maybe you want to update all
>      >>  >>   underlying libraries?
>      >>  >>
>      >>  >>   Hope this helps, Roby
>      >>  >>
>      >>  >>   (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>      >>  >>
>      >>  >>   _______________________________________________
>      >>  >>   R-sig-mixed-models at r-project.org mailing list
>      >>  >>   https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      >>  >>
>      >>
>      >>  >   --
>      >>  >   Renaud Lancelot
>      >>  >   EDENext Project, coordinator: http://www.edenext.eu/
>      >>
>      >>  >   CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>      >>  >   F34398 Montpellier
>      >>
>      >>  >   Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
>      >>  >   Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
>      >>
>      >>  >   _______________________________________________
>      >>  >   R-sig-mixed-models at r-project.org mailing list
>      >>  >   https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      >>
>
>      >  --
>      >  Renaud Lancelot
>      >  EDENext Project, coordinator: http://www.edenext.eu/
>
>      >  CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>      >  F34398 Montpellier
>
>      >  Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
>      >  Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From m.fairbrother at bristol.ac.uk  Fri Apr 13 13:14:30 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 13 Apr 2012 12:14:30 +0100
Subject: [R-sig-ME] predictions from a binomial GLMM
In-Reply-To: <mailman.7070.1333559307.4502.r-sig-mixed-models@r-project.org>
References: <mailman.7070.1333559307.4502.r-sig-mixed-models@r-project.org>
Message-ID: <64111161-C98D-4D1C-8E5B-C7565EB4108B@bristol.ac.uk>

Dear list,

This issue has come up before, but after reading previous threads I'm still not quite clear on how to do this. After fitting a binomial model, with "cbind(successes, failures)" as the outcome and a single covariate "x", how would one generate predicted probabilities for different values of x? Below is an example, with my attempt to do this, where I am interested primarily in plotting a 95% confidence interval for predictions for a new/hypothetical unit (i.e., one not included in the data and thus for which no random effect has been estimated).

I thought that using a parametric bootstrap would be appropriate and reasonably straightforward, allowing me to get predictions with something like:

newdata %*% fixef(mod) .

However, from what I've seen (e.g., on Ben Bolker's wiki at http://glmm.wikidot.com/faq, and related threads such as https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q2/016356.html), something more is needed? though I'm not clear on whether that remains true:
(a) if one uses a bootstrap, and
(b) if the predictions are for new units (rather than ones for which the model has produced random effects).

The code below shows where I've got to. Any further assistance would be much appreciated.

Thanks,
Malcolm


library(lme4.0); library(multicore)
n <- 30
dat <- data.frame(obs=1:n, x=runif(n, -1, 1))
dat <- with(dat, data.frame(dat, y=rbinom(n, 10, prob=plogis(-1 + 2*x + rnorm(n)))))
(mod <- lmer(cbind(y,10-y) ~ x + (1 | obs), dat, family=binomial))
sims <- do.call("rbind", mclapply(1:200, function(x) fixef(refit(mod, simulate(mod))))) # parametric bootstrap
newdat <- cbind(1,seq(-1,1,0.1)) # define datapoints for which to calculate predictions
preds <- apply(sims, 1, function(x) newdat %*% x) # get predictions for each resample
loCI <- apply(preds, 1, function(x) quantile(x, 0.025)) # get, for example, the lower bound of a 95% CI
loCI <- plogis(loCI) # convert the lower bound to the data scale


From m.fairbrother at bristol.ac.uk  Fri Apr 13 13:43:09 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 13 Apr 2012 12:43:09 +0100
Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
In-Reply-To: <mailman.7.1334311203.25886.r-sig-mixed-models@r-project.org>
References: <mailman.7.1334311203.25886.r-sig-mixed-models@r-project.org>
Message-ID: <F8645B87-7D26-4CCC-8642-28F549DCA428@bristol.ac.uk>

Dear Eiko,

You can certainly conduct this analysis in R, though some aspects of what you want to do are not simple. You might do best to start with some general reading/self-study re. mixed/multilevel models (natural scientists and statisticians tend to refer to "mixed" models, social scientists to "multilevel" or "random effects" or "hierarchical linear" models). Alternatively, if your uncertainty is less about such models generally than about R as a specific tool/software environment, the suggestions below may get you started, and http://glmm.wikidot.com/ may be a good resource as well (even though it's aimed at biological scientists).

R packages that may be useful to you are lme4, MCMCglmm, and nlme--the latter because it would allow you to check for temporal autocorrelation, which may be a concern particularly if your measurement occasions are close together in time. There are helpful coursenotes and worked examples for the first two packages on the web, and for nlme the best resource to start with would probably be the book "Mixed Effects Models in S and S-Plus", by Pinheiro and Bates.

There are ways of modelling multiple outcomes simultaneously (see the MCMCglmm documentation on Multi-response models at http://cran.md.tsukuba.ac.jp/web/packages/MCMCglmm/vignettes/CourseNotes.pdf), but nine is a lot. Perhaps an exploratory factor analysis could help you reduce the nine items to a smaller and more manageable number? There are also techniques common in psychology that may be appropriate for what you want, though I am less familiar with those (see e.g., http://www.jstatsoft.org/v20/a02/paper).

Hope that's useful.
- Malcolm


> Date: Fri, 13 Apr 2012 11:32:14 +0200
> From: Eiko Fried <torvon at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
> 
> Hello.
> 
> I have a problem that I have not been able to solve within the last months.
> Maybe R offers options to tackle this.
> 
> My dataset:
> 
> * N = 1000, 5 measurement points
> * 9 categorical dependent variables (depressive symptoms, scored 0, 1, 2 or
> 3) that are intercorrelated
> * 7 time-varying covariates that are dichotomous life events (yes/no) at
> each measurement point (people can have multiple life events, therefor this
> is not just one categorical with 0=no life event, 1=life event1, 2=life
> event2 etc.)
> * A bunch of time-invariant baseline predictors (e.g. neuroticism, early
> family environment, genotype, gender, family history of depression ... ),
> measured only once at the first measurement point.
> 
> My core question is whether different life events lead to different
> depressive symptom profiles (controlling for baseline variables).
> 
> I can confirm this hypothesis in nine univariate repeated measurement
> mixed-models (some life events are predictors for some symptoms but not
> others, and vice versa), but that invites the problem of (1) not being able
> to control for multiple models, and (2) ignoring the correlated structure
> of my categorical response variables.
> 
> So I'm looking for multivariate multilevel models currently to do all of
> this in one analysis.
> Could this be achieved with R? The more palpable the recommendations the
> better, I have little experience with R.
> 
> Thank you
> Eiko


From Thierry.ONKELINX at inbo.be  Fri Apr 13 15:38:15 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 13 Apr 2012 13:38:15 +0000
Subject: [R-sig-ME] Bug in lme4?
Message-ID: <AA818EAD2576BC488B4F623941DA74275736279B@inbomail.inbo.be>

Dear all,

After upgrading to R 2.15.0 and updating all the packages I get this error. Is this a bug?

Best regards,

Thierry

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'lme4'

The following object(s) are masked from 'package:stats':

    AIC, BIC

> set.seed(123)
> dummy <- expand.grid(X = 1:20, A = factor(1:40))
> dummy$Y <- with(dummy, 0.05 * X + rnorm(length(levels(A)))[A]) + rnorm(nrow(dummy))
> model <- lmer(Y ~ X + (1|A), data = dummy)
> model
Error in diag(val) :
  7 arguments passed to .Internal(identical) which requires 6
> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252    LC_MONETARY=Dutch_Belgium.1252
[4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-42 Matrix_1.0-7     lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.15.0   nlme_3.1-103  stats4_2.15.0 tools_2.15.0


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Thierry.ONKELINX at inbo.be  Fri Apr 13 16:25:27 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 13 Apr 2012 14:25:27 +0000
Subject: [R-sig-ME] Bug in lme4?
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275736279B@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA74275736279B@inbomail.inbo.be>
Message-ID: <AA818EAD2576BC488B4F623941DA7427573627F2@inbomail.inbo.be>

Please ignore my previous email. Everything works fine with R 2.15.0 patched

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'lme4'

The following object(s) are masked from 'package:stats':

    AIC, BIC

> set.seed(123)
> dummy <- expand.grid(X = 1:20, A = factor(1:40))
> dummy$Y <- with(dummy, 0.05 * X + rnorm(length(levels(A)))[A]) + rnorm(nrow(dummy))
> model <- lmer(Y ~ X + (1|A), data = dummy)
> model
Linear mixed model fit by REML
Formula: Y ~ X + (1 | A)
   Data: dummy
  AIC  BIC logLik deviance REMLdev
 2388 2407  -1190     2370    2380
Random effects:
 Groups   Name        Variance Std.Dev.
 A        (Intercept) 0.82560  0.90863
 Residual             0.98304  0.99148
Number of obs: 800, groups: A, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept) 0.102605   0.161058   0.637
X           0.044820   0.006079   7.373

Correlation of Fixed Effects:
  (Intr)
X -0.396
> sessionInfo()
R version 2.15.0 Patched (2012-04-09 r58947)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
[3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
[5] LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-42 Matrix_1.0-6     lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.15.0   nlme_3.1-103  stats4_2.15.0

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens ONKELINX, Thierry
Verzonden: vrijdag 13 april 2012 15:38
Aan: R-SIG-Mixed-Models at r-project.org
Onderwerp: [R-sig-ME] Bug in lme4?

Dear all,

After upgrading to R 2.15.0 and updating all the packages I get this error. Is this a bug?

Best regards,

Thierry

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'lme4'

The following object(s) are masked from 'package:stats':

    AIC, BIC

> set.seed(123)
> dummy <- expand.grid(X = 1:20, A = factor(1:40)) dummy$Y <-
> with(dummy, 0.05 * X + rnorm(length(levels(A)))[A]) +
> rnorm(nrow(dummy)) model <- lmer(Y ~ X + (1|A), data = dummy) model
Error in diag(val) :
  7 arguments passed to .Internal(identical) which requires 6
> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252    LC_MONETARY=Dutch_Belgium.1252
[4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-42 Matrix_1.0-7     lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.15.0   nlme_3.1-103  stats4_2.15.0 tools_2.15.0


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From david.r.afshartous at vanderbilt.edu  Fri Apr 13 17:21:07 2012
From: david.r.afshartous at vanderbilt.edu (David Afshartous)
Date: Fri, 13 Apr 2012 10:21:07 -0500
Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
In-Reply-To: <CACm_P7p5sFCzs-a=t30ZSt0MNEp-iU5x5AeeAqqhKYSumWRjMQ@mail.gmail.com>
References: <CACm_P7p5sFCzs-a=t30ZSt0MNEp-iU5x5AeeAqqhKYSumWRjMQ@mail.gmail.com>
Message-ID: <4F884463.9080703@vanderbilt.edu>


There are a few old threads on this topic that may be useful to you.  
Google "[r-sig-ME]  multivariate mixed effects model" and they should 
come up.   A good place to start is:
Doran, H., Lockwood, J., 2006. Fitting value-added models in R. Journal 
of Educational and Behavioral Statistics 31 (2), p. 205-230.



On 04/13/2012 04:32 AM, Eiko Fried wrote:
> Hello.
>
> I have a problem that I have not been able to solve within the last months.
> Maybe R offers options to tackle this.
>
> My dataset:
>
> * N = 1000, 5 measurement points
> * 9 categorical dependent variables (depressive symptoms, scored 0, 1, 2 or
> 3) that are intercorrelated
> * 7 time-varying covariates that are dichotomous life events (yes/no) at
> each measurement point (people can have multiple life events, therefor this
> is not just one categorical with 0=no life event, 1=life event1, 2=life
> event2 etc.)
> * A bunch of time-invariant baseline predictors (e.g. neuroticism, early
> family environment, genotype, gender, family history of depression ... ),
> measured only once at the first measurement point.
>
> My core question is whether different life events lead to different
> depressive symptom profiles (controlling for baseline variables).
>
> I can confirm this hypothesis in nine univariate repeated measurement
> mixed-models (some life events are predictors for some symptoms but not
> others, and vice versa), but that invites the problem of (1) not being able
> to control for multiple models, and (2) ignoring the correlated structure
> of my categorical response variables.
>
> So I'm looking for multivariate multilevel models currently to do all of
> this in one analysis.
> Could this be achieved with R? The more palpable the recommendations the
> better, I have little experience with R.
>
> Thank you
> Eiko
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
David Afshartous, Ph.D.
Research Associate Professor
PSTAT?: ASA Accredited Professional Statistician
Department of Biostatistics
Vanderbilt University Medical Center


From Tom_Philippi at nps.gov  Fri Apr 13 17:45:24 2012
From: Tom_Philippi at nps.gov (Tom_Philippi at nps.gov)
Date: Fri, 13 Apr 2012 08:45:24 -0700
Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
In-Reply-To: <F8645B87-7D26-4CCC-8642-28F549DCA428@bristol.ac.uk>
References: <mailman.7.1334311203.25886.r-sig-mixed-models@r-project.org>
	<F8645B87-7D26-4CCC-8642-28F549DCA428@bristol.ac.uk>
Message-ID: <OF3F274F01.31F93FE8-ON852579DF.00544ABC-882579DF.00568ED7@nps.gov>

Eiko--

If you have a strong understanding of mixed models and are asking about
tools for fitting mixed models with multivariate responses, Rob Crouchley's
sabreR package may be the tool you need.  There's also a book: Berridge &
Crouchley 2011 Multivariate generalized linear mixed models using R, which
uses mostly social science examples, and has a companion website at:
http://sabre.lancs.ac.uk/.  From my experience, the R coding for this
approach is much less of a hurdle than actually understanding the models
and techniques and applying the methods to my questions, but that's for
ecological applications, and your mileage may vary if you have a better
background.

Tom 2

-------------------------------------------
Tom Philippi, Ph.D.
Quantitative Ecologist
Inventory and Monitoring Program
National Park Service
c/o Cabrillo National Monument
1800 Cabrillo Memorial Dr
San Diego, CA 92106
(619) 523-4576
Tom_philippi at NPS.gov
http://science.nature.nps.gov/im/monitor
-------------------------------------------



                                                                           
             Malcolm                                                       
             Fairbrother                                                   
             <m.fairbrother at br                                          To 
             istol.ac.uk>              torvon at gmail.com                    
             Sent by:                                                   cc 
             r-sig-mixed-model         r-sig-mixed-models at r-project.org    
             s-bounces at r-proje                                     Subject 
             ct.org                    Re: [R-sig-ME] Multivariate         
                                       Multilevel Mixed-Effects Model      
                                                                           
             04/13/2012 12:43                                              
             PM CET                                                        
                                                                           
                                                                           
                                                                           




Dear Eiko,

You can certainly conduct this analysis in R, though some aspects of what
you want to do are not simple. You might do best to start with some general
reading/self-study re. mixed/multilevel models (natural scientists and
statisticians tend to refer to "mixed" models, social scientists to
"multilevel" or "random effects" or "hierarchical linear" models).
Alternatively, if your uncertainty is less about such models generally than
about R as a specific tool/software environment, the suggestions below may
get you started, and http://glmm.wikidot.com/ may be a good resource as
well (even though it's aimed at biological scientists).

R packages that may be useful to you are lme4, MCMCglmm, and nlme--the
latter because it would allow you to check for temporal autocorrelation,
which may be a concern particularly if your measurement occasions are close
together in time. There are helpful coursenotes and worked examples for the
first two packages on the web, and for nlme the best resource to start with
would probably be the book "Mixed Effects Models in S and S-Plus", by
Pinheiro and Bates.

There are ways of modelling multiple outcomes simultaneously (see the
MCMCglmm documentation on Multi-response models at
http://cran.md.tsukuba.ac.jp/web/packages/MCMCglmm/vignettes/CourseNotes.pdf
), but nine is a lot. Perhaps an exploratory factor analysis could help you
reduce the nine items to a smaller and more manageable number? There are
also techniques common in psychology that may be appropriate for what you
want, though I am less familiar with those (see e.g.,
http://www.jstatsoft.org/v20/a02/paper).

Hope that's useful.
- Malcolm


> Date: Fri, 13 Apr 2012 11:32:14 +0200
> From: Eiko Fried <torvon at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
>
> Hello.
>
> I have a problem that I have not been able to solve within the last
months.
> Maybe R offers options to tackle this.
>
> My dataset:
>
> * N = 1000, 5 measurement points
> * 9 categorical dependent variables (depressive symptoms, scored 0, 1, 2
or
> 3) that are intercorrelated
> * 7 time-varying covariates that are dichotomous life events (yes/no) at
> each measurement point (people can have multiple life events, therefor
this
> is not just one categorical with 0=no life event, 1=life event1, 2=life
> event2 etc.)
> * A bunch of time-invariant baseline predictors (e.g. neuroticism, early
> family environment, genotype, gender, family history of depression ... ),
> measured only once at the first measurement point.
>
> My core question is whether different life events lead to different
> depressive symptom profiles (controlling for baseline variables).
>
> I can confirm this hypothesis in nine univariate repeated measurement
> mixed-models (some life events are predictors for some symptoms but not
> others, and vice versa), but that invites the problem of (1) not being
able
> to control for multiple models, and (2) ignoring the correlated structure
> of my categorical response variables.
>
> So I'm looking for multivariate multilevel models currently to do all of
> this in one analysis.
> Could this be achieved with R? The more palpable the recommendations the
> better, I have little experience with R.
>
> Thank you
> Eiko

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Apr 13 17:57:29 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Apr 2012 15:57:29 +0000 (UTC)
Subject: [R-sig-ME] predictions from a binomial GLMM
References: <mailman.7070.1333559307.4502.r-sig-mixed-models@r-project.org>
	<64111161-C98D-4D1C-8E5B-C7565EB4108B@bristol.ac.uk>
Message-ID: <loom.20120413T175101-438@post.gmane.org>

Malcolm Fairbrother <m.fairbrother at ...> writes:

> This issue has come up before, but after reading previous threads
> I'm still not quite clear on how to do this.  After fitting a
> binomial model, with "cbind(successes, failures)" as the outcome and
> a single covariate "x", how would one generate predicted
> probabilities for different values of x? Below is an example, with
> my attempt to do this, where I am interested primarily in plotting a
> 95% confidence interval for predictions for a new/hypothetical unit
> (i.e., one not included in the data and thus for which no random
> effect has been estimated).


>  I thought that using a parametric bootstrap would be appropriate
> and reasonably straightforward, allowing me to get predictions with
> something like: newdata %*% fixef(mod) .  However, from what I've
> seen (e.g., on Ben Bolker's wiki at http://glmm.wikidot.com/faq, and
> related threads such as
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q2/016356.html),
> something more is needed? though I'm not clear on whether that
> remains true: (a) if one uses a bootstrap, and (b) if the
> predictions are for new units (rather than ones for which the model
> has produced random effects).

  Hmm.  I can't see that you're missing anything obvious ...
the parametric bootstrap _should_ take care of the issue of
the uncertainty in the random-effects parameters (I think ...)

  I tweaked your code in a few places, but all the changes
are essentially cosmetic.  In this case, interestingly (?)
there doesn't seem to be much difference between the naive
(plug-in fixed effect variances only) CIs and the ones
computed in this way.

--------------
library(lme4.0)
library(parallel)  ## newer than multicore, otherwise not much difference
n <- 30
set.seed(101)      ## set RNG seed ...
dat <- data.frame(obs=1:n, x=runif(n, -1, 1))
dat <- with(dat, data.frame(dat, 
       y=rbinom(n, 10, prob=plogis(-1 + 2*x + rnorm(n)))))
(mod <- lmer(cbind(y,10-y) ~ x + (1 | obs), dat, family=binomial))
sims <- do.call("rbind", mclapply(1:200, 
     function(x) fixef(refit(mod, simulate(mod)))))
## parametric bootstrap
## define datapoints for which to calculate predictions
newdat <- cbind(1,seq(-1,1,0.1)) 
preds <- newdat %*% t(sims) # get predictions for each resample
eta_CI <- t(apply(preds, 1, function(x) quantile(x, c(0.025,0.975))))
CI <- plogis(eta_CI) # convert the lower bound to the data scale
colnames(CI) <- c("lwr","upr")
pred <- data.frame(x=newdat[,2],eta=newdat %*% fixef(mod),CI)
pred$m <- plogis(pred$eta)
library(ggplot2)
(q1 <- qplot(x,m,ymin=lwr,ymax=upr,data=pred,geom="line")+
    geom_ribbon(colour=NA,alpha=0.3)+theme_bw())

## compare naive prediction intervals:
eta_sd <- sqrt(diag(newdat %*% vcov(mod) %*% t(newdat)))
CI2 <- data.frame(x=pred$x,
      m=pred$m,plogis(pred$eta+t(1.96*outer(c(-1,1),eta_sd))))
names(CI2)[3:4] <- c("lwr","upr")

q1+geom_ribbon(data=CI2,colour=NA,alpha=0.3,fill="blue")


From shigesong at gmail.com  Fri Apr 13 17:57:47 2012
From: shigesong at gmail.com (Shige Song)
Date: Fri, 13 Apr 2012 11:57:47 -0400
Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
In-Reply-To: <OF3F274F01.31F93FE8-ON852579DF.00544ABC-882579DF.00568ED7@nps.gov>
References: <mailman.7.1334311203.25886.r-sig-mixed-models@r-project.org>
	<F8645B87-7D26-4CCC-8642-28F549DCA428@bristol.ac.uk>
	<OF3F274F01.31F93FE8-ON852579DF.00544ABC-882579DF.00568ED7@nps.gov>
Message-ID: <CAGuGQcy-sGqRHne5o2VJ7meM0eFLAmDe+3We_xDuZE29CSD2Xg@mail.gmail.com>

I don't think SabreR handle nine outcomes (correct me I am wrong). In
theory, you can do this using aML (http://www.applied-ml.com/), now an
open source software. But, with nine outcomes, you will have a lots of
issues with the numerical routines (I only tried five but eventually
gave up).

Best,
Shige

On Fri, Apr 13, 2012 at 11:45 AM,  <Tom_Philippi at nps.gov> wrote:
> Eiko--
>
> If you have a strong understanding of mixed models and are asking about
> tools for fitting mixed models with multivariate responses, Rob Crouchley's
> sabreR package may be the tool you need. ?There's also a book: Berridge &
> Crouchley 2011 Multivariate generalized linear mixed models using R, which
> uses mostly social science examples, and has a companion website at:
> http://sabre.lancs.ac.uk/. ?From my experience, the R coding for this
> approach is much less of a hurdle than actually understanding the models
> and techniques and applying the methods to my questions, but that's for
> ecological applications, and your mileage may vary if you have a better
> background.
>
> Tom 2
>
> -------------------------------------------
> Tom Philippi, Ph.D.
> Quantitative Ecologist
> Inventory and Monitoring Program
> National Park Service
> c/o Cabrillo National Monument
> 1800 Cabrillo Memorial Dr
> San Diego, CA 92106
> (619) 523-4576
> Tom_philippi at NPS.gov
> http://science.nature.nps.gov/im/monitor
> -------------------------------------------
>
>
>
>
> ? ? ? ? ? ? Malcolm
> ? ? ? ? ? ? Fairbrother
> ? ? ? ? ? ? <m.fairbrother at br ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?To
> ? ? ? ? ? ? istol.ac.uk> ? ? ? ? ? ? ?torvon at gmail.com
> ? ? ? ? ? ? Sent by: ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cc
> ? ? ? ? ? ? r-sig-mixed-model ? ? ? ? r-sig-mixed-models at r-project.org
> ? ? ? ? ? ? s-bounces at r-proje ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Subject
> ? ? ? ? ? ? ct.org ? ? ? ? ? ? ? ? ? ?Re: [R-sig-ME] Multivariate
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Multilevel Mixed-Effects Model
>
> ? ? ? ? ? ? 04/13/2012 12:43
> ? ? ? ? ? ? PM CET
>
>
>
>
>
>
>
> Dear Eiko,
>
> You can certainly conduct this analysis in R, though some aspects of what
> you want to do are not simple. You might do best to start with some general
> reading/self-study re. mixed/multilevel models (natural scientists and
> statisticians tend to refer to "mixed" models, social scientists to
> "multilevel" or "random effects" or "hierarchical linear" models).
> Alternatively, if your uncertainty is less about such models generally than
> about R as a specific tool/software environment, the suggestions below may
> get you started, and http://glmm.wikidot.com/ may be a good resource as
> well (even though it's aimed at biological scientists).
>
> R packages that may be useful to you are lme4, MCMCglmm, and nlme--the
> latter because it would allow you to check for temporal autocorrelation,
> which may be a concern particularly if your measurement occasions are close
> together in time. There are helpful coursenotes and worked examples for the
> first two packages on the web, and for nlme the best resource to start with
> would probably be the book "Mixed Effects Models in S and S-Plus", by
> Pinheiro and Bates.
>
> There are ways of modelling multiple outcomes simultaneously (see the
> MCMCglmm documentation on Multi-response models at
> http://cran.md.tsukuba.ac.jp/web/packages/MCMCglmm/vignettes/CourseNotes.pdf
> ), but nine is a lot. Perhaps an exploratory factor analysis could help you
> reduce the nine items to a smaller and more manageable number? There are
> also techniques common in psychology that may be appropriate for what you
> want, though I am less familiar with those (see e.g.,
> http://www.jstatsoft.org/v20/a02/paper).
>
> Hope that's useful.
> - Malcolm
>
>
>> Date: Fri, 13 Apr 2012 11:32:14 +0200
>> From: Eiko Fried <torvon at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
>>
>> Hello.
>>
>> I have a problem that I have not been able to solve within the last
> months.
>> Maybe R offers options to tackle this.
>>
>> My dataset:
>>
>> * N = 1000, 5 measurement points
>> * 9 categorical dependent variables (depressive symptoms, scored 0, 1, 2
> or
>> 3) that are intercorrelated
>> * 7 time-varying covariates that are dichotomous life events (yes/no) at
>> each measurement point (people can have multiple life events, therefor
> this
>> is not just one categorical with 0=no life event, 1=life event1, 2=life
>> event2 etc.)
>> * A bunch of time-invariant baseline predictors (e.g. neuroticism, early
>> family environment, genotype, gender, family history of depression ... ),
>> measured only once at the first measurement point.
>>
>> My core question is whether different life events lead to different
>> depressive symptom profiles (controlling for baseline variables).
>>
>> I can confirm this hypothesis in nine univariate repeated measurement
>> mixed-models (some life events are predictors for some symptoms but not
>> others, and vice versa), but that invites the problem of (1) not being
> able
>> to control for multiple models, and (2) ignoring the correlated structure
>> of my categorical response variables.
>>
>> So I'm looking for multivariate multilevel models currently to do all of
>> this in one analysis.
>> Could this be achieved with R? The more palpable the recommendations the
>> better, I have little experience with R.
>>
>> Thank you
>> Eiko
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Apr 13 22:43:16 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 13 Apr 2012 20:43:16 +0000 (UTC)
Subject: [R-sig-ME] Continuous variables interaction plot
References: <8395A297256F694B9308A0446D3CF6A53BDCA800DC@EXCHMBS03.isad.isadroot.ex.ac.uk>
Message-ID: <loom.20120413T224212-299@post.gmane.org>

Flores-de-Gracia, Eric <eef201 at ...> writes:

> 
> Dear all.
> 
> I have been working with three continuous variables, 
>   to explore the effects of jnd_lum and jnd_colour on seg_expos
> 
> My minimal model is:
> 
> expos1<-lm (seg_expos~jnd_colour+jnd_lum+jnd_colour:jnd_lum,na.action=na.omit)
> 
> The interaction jnd_colour:jnd_lum is significant so want to plot such effect
on the variable seg_expos
> 
> I have tried the following function but without much success:
> 
> wireframe(seg_expos~jnd_colour+jnd_lum,screen=list(z=245,x=-75),
> 
> Any hint will be appreciated, regards,


  Try this on the regular (r-help at r-project.org) mailing list,
after reading the posting guide and generating a small reproducible
example?  (i.e., this doesn't seem to be a question about mixed models)

  Ben Bolker


From j.deikumah2 at uq.edu.au  Sun Apr 15 07:18:04 2012
From: j.deikumah2 at uq.edu.au (Justus Deikumah)
Date: Sun, 15 Apr 2012 05:18:04 +0000
Subject: [R-sig-ME] Random& fixed variables
Message-ID: <74C378BE307E5D49898BABE3CCFD29A301260E@uqexmdb2.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120415/f03d6ac6/attachment.pl>

From bbolker at gmail.com  Sun Apr 15 18:23:40 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 15 Apr 2012 16:23:40 +0000 (UTC)
Subject: [R-sig-ME] Random& fixed variables
References: <74C378BE307E5D49898BABE3CCFD29A301260E@uqexmdb2.soe.uq.edu.au>
Message-ID: <loom.20120415T181455-380@post.gmane.org>

Justus Deikumah <j.deikumah2 at ...> writes:

>  However, I still need some assistance as follows:
> 
> I have sampled birds from 2 main landscapes, Agricultural and minining areas.
> 
> 32 sites in located in 16 remnant forest patches

> 16sites at edge and i6 interior patches 
                                  ^^^^^^^
                              sites?

> are selected such that the
> adjacent matrix is either agricultural or an active mine site.

  You probably want to be a little bit more careful with terminology
here:

> in each site, bird surveys were conducted for a period of 1yrs.
> 
> vegetation characteistics and microclimates were messured as covaiates.
> 
> With lme4, is the below grouping of site and patch ok??
 
> Because sites were coded 1/2 for edge/interior,matrix also same, can
> I also group by matrix??
 
> In the model below, can I consider put a fixed variable in my model
> aslso a random? because I was thinking I could group by matrix as
> well but knowing very well that matrix has a significant negative
> influence during data exploration.

  Yes, sort of.  (1) You can specify (e.g.) site WITHIN patch as
well as a main effect of site.  (2) If you have a continuous
predictor (e.g. mm of precipitation/month) with more than
one observation per x value, it sometimes make sense to specify it
as a continuous fixed effect (i.e. estimating the slope)
and as a random effect (estimating deviations of groups from
the line)

I think you want:

m <- lmer(spst~(1|patch/site)+site+mtx+elev+psize+X1fr+logyr_patch,
   family= poisson, data=var32)

  this specifies a random effect of patch and of patch within site,
as well as a fixed-effect difference between edge and interior.
Formally this is equivalent to (1|patch)+(1|patch:site).
 
  It's fine to have mtx={1,2} and site={1,2} (i.e. both coded
with the same dummy variables, although in the long run it's probably
more straightforward to code them as factors (mtx={"agric","mine"},
site={"edge","interior"}), for three reasons
  * R will take care of translation into dummy variables
  * the variables are easier to interpret (you don't have to remember
the coding yourself)
  * it is easier not to screw up and have R treat variables as
continuous that you really wanted to be categorical


From mirjam.amcoff at ebc.uu.se  Sun Apr 15 19:32:12 2012
From: mirjam.amcoff at ebc.uu.se (Mirjam Amcoff)
Date: Sun, 15 Apr 2012 19:32:12 +0200
Subject: [R-sig-ME] Prior for multi-response model MCMCglmm
Message-ID: <20120415193212.91983xs60pnhdnoc@webmail.uu.se>

Hi all,

I am trying to do a phylogenetic test of correlated evolution between  
two traits using MCMCglmm but am having trouble with setting the priors.

My response variable consists of one multinomial variable (cbind(yes,  
no)) and one ordinal variable with three levels (low, some, high). I  
have a phylogeny with 61 species and the raw data are:

table(data$Pred, data$Yes)

       0  1
High  1  8
Low  24  1
Some  8 19

The full model I want to run looks like this:

MCMCglmm(cbind(cbind(Yes, No), Pred ~ trait-1, random =  
~us(trait):animal, rcov = ~us(trait):units, family = c("multinomial2",  
"ordinal"), pedigree = tree, prior = prior1, data = data, nitt =  
1100000, burnin = 100000, thin = 100)

I want to compare this model with one where the covariance is  
constrained to estimate correlated evolution between the two response  
traits:

MCMCglmm(cbind(cbind(Yes, No), Pred ~ trait-1, random =  
~idh(trait):animal, rcov = ~us(trait):units, family =  
c("multinomial2", "ordinal"), pedigree = tree, prior = prior1, data =  
data, nitt = 1100000, burnin = 100000, thin = 100)

As far as I have understood the following prior should be appropriate  
with the residual variance fixed to 1 and the random effect prior  
being uninformative for the covariance and parameter expanded to  
improve mixing.

prior1 <- list(R = list(V = diag(2), nu = 0.002, fix=1), G = list(G1 =  
list(V = diag(2)*1e-6 , nu = 3, alpha.mu=c(0,0), alpha.V=diag(2)*25^2)))

However, when I try with this prior the mixing is exceedingly poor and  
when I try to increase the number of iterations I get the following  
error message:

Error in MCMCglmm(cbind(cbind(Yes, No), Pred) ~ trait - 1, random =  
~us(trait):animal,  :
   ill-conditioned G/R structure: use proper priors if you haven't or  
rescale data if you have

I find this strange as the only difference is that I increased the  
number of iterations?

When I try with the following prior things look much better:

prior2 <- list(R = list(V = diag(2), nu = 0.002, fix=1), G = list(G1 =  
list(V = diag(2) , nu = 3, alpha.mu=c(0,0), alpha.V=diag(2)*25^2)))

The only difference is that I used V = diag(2) instead of V =  
diag(2)*1e-6. The mixing in the ordinal variable is still quite poor  
but I think I could get away from that by running the chain longer  
than I have tried so far.

I do not understand enough about how the priors work in these models  
so I would be very grateful if someone could help me and tell me if  
the second prior is OK or not and, if it's not, what can I do to  
improve the mixing using the first model?


Here is an example of the output I get from the test models I have run  
using the second prior, note that the effective sample size is still  
very low for the ordinal (Pred) trait:

  Iterations = 6599801
  Thinning interval  = 600001
  Sample size  = 30000

  DIC: 393.0197

  G-structure:  ~us(trait):animal

                    post.mean   l-95% CI u-95% CI eff.samp
Yes:Yes.animal        0.4458  3.053e-08    1.410    29465
Pred:Yes.animal      1.0145 -8.075e-01    3.653    22451
Yes:Pred.animal      1.0145 -8.075e-01    3.653    22451
Pred:Pred.animal   15.5067  5.446e-01   41.764     5068

  R-structure:  ~us(trait):units

                   post.mean l-95% CI u-95% CI eff.samp
Yes:Yes.units             1        1        1        0
Pred:Yes.units           0        0        0        0
Yes:Pred.units           0        0        0        0
Pred:Pred.units         1        1        1        0

  Location effects: cbind(cbind(Yes, No), Pred) ~ trait - 1

            post.mean l-95% CI u-95% CI eff.samp pMCMC
traitYes     -0.1474  -1.0387   0.6735    27585 0.706
traitPred   -0.8047  -4.7517   2.9530    10050 0.650

  Cutpoints:
                       post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitPred.1    0.2244   0.2244   0.2244        0


Thank you very much in advance,

//Mirjam


From j.hadfield at ed.ac.uk  Mon Apr 16 15:33:19 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 16 Apr 2012 14:33:19 +0100
Subject: [R-sig-ME] Prior for multi-response model MCMCglmm
In-Reply-To: <20120415193212.91983xs60pnhdnoc@webmail.uu.se>
References: <20120415193212.91983xs60pnhdnoc@webmail.uu.se>
Message-ID: <20120416143319.69522h1vbaxlj6as@www.staffmail.ed.ac.uk>

Hi,

i) The syntax for your response is incorrect it should be cbind(Yes,  
No, Pred) (but I guess you had this right when you ran it).  If the  
multinomial response is Bernoulli it would be slightly quicker to have  
it as a single column of Yes/No's and have the family argument as  
"categorical".


ii) your output from table(data$Pred, data$Yes) looks like the levels  
are not ordered properly as it suggestes High>Some>Low rather than   
High>Low>Some (but perhaps this intentional?)

iii) although the residual variances are not identified for either  
trait, the residual correlation is. I would advise estimating it:   
rcov=~cor(trait):units.

iv) I would suggest saving the latent variables (pl=TRUE) and checking  
that they are not outside of the range -7/7 or -20/20 for the ordinal  
variable or categorical/multinomial variables respectively. If they  
are the model cannot be trusted because the probit/logit functions are  
under/overflowing.

v) prior2 should behave relatively OK (although having nu=2 (us) or  
nu=1 (idh) rather than nu=3 is more usual). However, it does put  
weight on a phylogenetic H^2 of 1 which could be a problem if there is  
high support in this area.


vi) the ordinal part is not mixing at all well: cutpoint.traitPred.1  
has zero effective sample size.  I would try and diagnose the problem  
with a univariate analysis of the ordinal response - perhaps your  
phylogeny has two clades; one clade containing species with all  
"High"/"Some" and the other clade containing species with all "Low"?

Cheers,

Jarrod





Quoting Mirjam Amcoff <mirjam.amcoff at ebc.uu.se> on Sun, 15 Apr 2012  
19:32:12 +0200:

> Hi all,
>
> I am trying to do a phylogenetic test of correlated evolution  
> between two traits using MCMCglmm but am having trouble with setting  
> the priors.
>
> My response variable consists of one multinomial variable  
> (cbind(yes, no)) and one ordinal variable with three levels (low,  
> some, high). I have a phylogeny with 61 species and the raw data are:
>
> table(data$Pred, data$Yes)
>
>       0  1
> High  1  8
> Low  24  1
> Some  8 19
>
> The full model I want to run looks like this:
>
> MCMCglmm(cbind(cbind(Yes, No), Pred ~ trait-1, random =  
> ~us(trait):animal, rcov = ~us(trait):units, family =  
> c("multinomial2", "ordinal"), pedigree = tree, prior = prior1, data  
> = data, nitt = 1100000, burnin = 100000, thin = 100)
>
> I want to compare this model with one where the covariance is  
> constrained to estimate correlated evolution between the two  
> response traits:
>
> MCMCglmm(cbind(cbind(Yes, No), Pred ~ trait-1, random =  
> ~idh(trait):animal, rcov = ~us(trait):units, family =  
> c("multinomial2", "ordinal"), pedigree = tree, prior = prior1, data  
> = data, nitt = 1100000, burnin = 100000, thin = 100)
>
> As far as I have understood the following prior should be  
> appropriate with the residual variance fixed to 1 and the random  
> effect prior being uninformative for the covariance and parameter  
> expanded to improve mixing.
>
> prior1 <- list(R = list(V = diag(2), nu = 0.002, fix=1), G = list(G1  
> = list(V = diag(2)*1e-6 , nu = 3, alpha.mu=c(0,0),  
> alpha.V=diag(2)*25^2)))
>
> However, when I try with this prior the mixing is exceedingly poor  
> and when I try to increase the number of iterations I get the  
> following error message:
>
> Error in MCMCglmm(cbind(cbind(Yes, No), Pred) ~ trait - 1, random =  
> ~us(trait):animal,  :
>   ill-conditioned G/R structure: use proper priors if you haven't or  
> rescale data if you have
>
> I find this strange as the only difference is that I increased the  
> number of iterations?
>
> When I try with the following prior things look much better:
>
> prior2 <- list(R = list(V = diag(2), nu = 0.002, fix=1), G = list(G1  
> = list(V = diag(2) , nu = 3, alpha.mu=c(0,0), alpha.V=diag(2)*25^2)))
>
> The only difference is that I used V = diag(2) instead of V =  
> diag(2)*1e-6. The mixing in the ordinal variable is still quite poor  
> but I think I could get away from that by running the chain longer  
> than I have tried so far.
>
> I do not understand enough about how the priors work in these models  
> so I would be very grateful if someone could help me and tell me if  
> the second prior is OK or not and, if it's not, what can I do to  
> improve the mixing using the first model?
>
>
> Here is an example of the output I get from the test models I have  
> run using the second prior, note that the effective sample size is  
> still very low for the ordinal (Pred) trait:
>
>  Iterations = 6599801
>  Thinning interval  = 600001
>  Sample size  = 30000
>
>  DIC: 393.0197
>
>  G-structure:  ~us(trait):animal
>
>                    post.mean   l-95% CI u-95% CI eff.samp
> Yes:Yes.animal        0.4458  3.053e-08    1.410    29465
> Pred:Yes.animal      1.0145 -8.075e-01    3.653    22451
> Yes:Pred.animal      1.0145 -8.075e-01    3.653    22451
> Pred:Pred.animal   15.5067  5.446e-01   41.764     5068
>
>  R-structure:  ~us(trait):units
>
>                   post.mean l-95% CI u-95% CI eff.samp
> Yes:Yes.units             1        1        1        0
> Pred:Yes.units           0        0        0        0
> Yes:Pred.units           0        0        0        0
> Pred:Pred.units         1        1        1        0
>
>  Location effects: cbind(cbind(Yes, No), Pred) ~ trait - 1
>
>            post.mean l-95% CI u-95% CI eff.samp pMCMC
> traitYes     -0.1474  -1.0387   0.6735    27585 0.706
> traitPred   -0.8047  -4.7517   2.9530    10050 0.650
>
>  Cutpoints:
>                       post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitPred.1    0.2244   0.2244   0.2244        0
>
>
> Thank you very much in advance,
>
> //Mirjam
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From torvon at gmail.com  Tue Apr 17 12:45:23 2012
From: torvon at gmail.com (Eiko Fried)
Date: Tue, 17 Apr 2012 12:45:23 +0200
Subject: [R-sig-ME] Time-varying vs. time-invariant covariates in
 longitudinal multivariate mixed-models
Message-ID: <CACm_P7qLpVMfx3CzjGzpH5VwKWSxAWVZUTwL6NqN92d+Pgknjw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120417/f7723aca/attachment.pl>

From slu at ccsr.uchicago.edu  Tue Apr 17 17:33:57 2012
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 17 Apr 2012 10:33:57 -0500
Subject: [R-sig-ME] Time-varying vs. time-invariant covariates in
 longitudinal multivariate mixed-models
In-Reply-To: <CACm_P7qLpVMfx3CzjGzpH5VwKWSxAWVZUTwL6NqN92d+Pgknjw@mail.gmail.com>
References: <CACm_P7qLpVMfx3CzjGzpH5VwKWSxAWVZUTwL6NqN92d+Pgknjw@mail.gmail.com>
Message-ID: <1334676837.16676.3.camel@localhost>

On Tue, 2012-04-17 at 12:45 +0200, Eiko Fried wrote:
> (2) Where can I find information about how to treat (highly skewed)
> ordinal outcome variables in LME4? My outcome variables are ordinal,
> with the values of
> * 0 (not in the last weeks),
> * 1 (2 days within the last week),
> * 2 (4 days in the last week),
> * 3 (nearly on all days in the last week), 

I don't think you can do this in lme4. I have a similar problem for
which I use MCMCglmm, which works quite well. The author of the package,
Jarrod Hadfield, has written voluminous documentation that is very
helpful. Get the MCMCglmm_Overview.pdf and MCMCglmm_CourseNotes.pdf. If
you still have problems, Jarrod is very generous with his time to help
people on this list.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 3.2.1-gentoo-r2                
I recently attended a Ph.D. prelim exam where the
 candidate had proposed research on various ways of
 defining an R^2 statistic in the original data
 scale from a linear model fit to data in a
 transformed scale determined by the Box-Cox
 method. There were seven different possible
 definitions for R^2, all of which, as acknowledged
 by the candidate and by the thesis advisor, were
 incorrect. The purpose of this path-breaking study


From m.fairbrother at bristol.ac.uk  Tue Apr 17 17:34:57 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 17 Apr 2012 16:34:57 +0100
Subject: [R-sig-ME] predictions from a binomial GLMM
In-Reply-To: <mailman.1465.1334332675.4540.r-sig-mixed-models@r-project.org>
References: <mailman.1465.1334332675.4540.r-sig-mixed-models@r-project.org>
Message-ID: <DABC2102-D263-4278-AFD0-F5EE12A49046@bristol.ac.uk>

Thanks Ben for the help.

However, I'm now trying this with the new lme4, and finding a couple problems--see below. Is this a (seemingly small) bug in the new lme4, or am I missing some change in syntax or functionality?

Thanks again,
Malcolm



First, with the new lme4 (but not lme4.0), the code you posted below fails at the call to "lmer", giving the error:

Error in FUN(1:3[[1L]], ...) : Downdated VtV is not positive definite

Second, slightly modified code gets past that hurdle but then fails at the call to "refit":

library(lme4)
library(parallel)
n <- 30
set.seed(101)
dat <- data.frame(obs=1:n, x=runif(n, -1, 1))[rep(1:n, each=5),]
dat <- with(dat, data.frame(dat, 
      y=rbinom(n, 10, prob=plogis(-1 + 2*x + rnorm(n)[rep(1:n, each=5)]))))
(mod <- lmer(cbind(y,10-y) ~ x + (1 | obs), dat, family=binomial))
sims <- do.call("rbind", mclapply(1:200, 
    function(x) fixef(refit(mod, simulate(mod)))))

Warning message:
In mclapply(1:200, function(x) fixef(refit(mod, simulate(mod)))) :
  all scheduled cores encountered errors in user code

test <- simulate(mod) # works
test <- refit(mod, simulate(mod)) # fails:
Error in stopifnot(length(newresp <- as.numeric(as.vector(newresp))) ==  : 
  (list) object cannot be coerced to type 'double'



> Date: Fri, 13 Apr 2012 15:57:29 +0000 (UTC)
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] predictions from a binomial GLMM
> 
> Malcolm Fairbrother <m.fairbrother at ...> writes:
> 
>> This issue has come up before, but after reading previous threads
>> I'm still not quite clear on how to do this.  After fitting a
>> binomial model, with "cbind(successes, failures)" as the outcome and
>> a single covariate "x", how would one generate predicted
>> probabilities for different values of x? Below is an example, with
>> my attempt to do this, where I am interested primarily in plotting a
>> 95% confidence interval for predictions for a new/hypothetical unit
>> (i.e., one not included in the data and thus for which no random
>> effect has been estimated).
> 
> 
>> I thought that using a parametric bootstrap would be appropriate
>> and reasonably straightforward, allowing me to get predictions with
>> something like: newdata %*% fixef(mod) .  However, from what I've
>> seen (e.g., on Ben Bolker's wiki at http://glmm.wikidot.com/faq, and
>> related threads such as
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q2/016356.html),
>> something more is needed? though I'm not clear on whether that
>> remains true: (a) if one uses a bootstrap, and (b) if the
>> predictions are for new units (rather than ones for which the model
>> has produced random effects).
> 
>  Hmm.  I can't see that you're missing anything obvious ...
> the parametric bootstrap _should_ take care of the issue of
> the uncertainty in the random-effects parameters (I think ...)
> 
>  I tweaked your code in a few places, but all the changes
> are essentially cosmetic.  In this case, interestingly (?)
> there doesn't seem to be much difference between the naive
> (plug-in fixed effect variances only) CIs and the ones
> computed in this way.
> 
> --------------
> library(lme4.0)
> library(parallel)  ## newer than multicore, otherwise not much difference
> n <- 30
> set.seed(101)      ## set RNG seed ...
> dat <- data.frame(obs=1:n, x=runif(n, -1, 1))
> dat <- with(dat, data.frame(dat, 
>       y=rbinom(n, 10, prob=plogis(-1 + 2*x + rnorm(n)))))
> (mod <- lmer(cbind(y,10-y) ~ x + (1 | obs), dat, family=binomial))
> sims <- do.call("rbind", mclapply(1:200, 
>     function(x) fixef(refit(mod, simulate(mod)))))
> ## parametric bootstrap
> ## define datapoints for which to calculate predictions
> newdat <- cbind(1,seq(-1,1,0.1)) 
> preds <- newdat %*% t(sims) # get predictions for each resample
> eta_CI <- t(apply(preds, 1, function(x) quantile(x, c(0.025,0.975))))
> CI <- plogis(eta_CI) # convert the lower bound to the data scale
> colnames(CI) <- c("lwr","upr")
> pred <- data.frame(x=newdat[,2],eta=newdat %*% fixef(mod),CI)
> pred$m <- plogis(pred$eta)
> library(ggplot2)
> (q1 <- qplot(x,m,ymin=lwr,ymax=upr,data=pred,geom="line")+
>    geom_ribbon(colour=NA,alpha=0.3)+theme_bw())
> 
> ## compare naive prediction intervals:
> eta_sd <- sqrt(diag(newdat %*% vcov(mod) %*% t(newdat)))
> CI2 <- data.frame(x=pred$x,
>      m=pred$m,plogis(pred$eta+t(1.96*outer(c(-1,1),eta_sd))))
> names(CI2)[3:4] <- c("lwr","upr")
> 
> q1+geom_ribbon(data=CI2,colour=NA,alpha=0.3,fill="blue")
> 


From bbolker at gmail.com  Tue Apr 17 17:36:18 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Apr 2012 11:36:18 -0400
Subject: [R-sig-ME] predictions from a binomial GLMM
In-Reply-To: <DABC2102-D263-4278-AFD0-F5EE12A49046@bristol.ac.uk>
References: <mailman.1465.1334332675.4540.r-sig-mixed-models@r-project.org>
	<DABC2102-D263-4278-AFD0-F5EE12A49046@bristol.ac.uk>
Message-ID: <4F8D8DF2.5090200@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-04-17 11:34 AM, Malcolm Fairbrother wrote:
> Thanks Ben for the help.
> 
> However, I'm now trying this with the new lme4, and finding a
> couple problems--see below. Is this a (seemingly small) bug in the
> new lme4, or am I missing some change in syntax or functionality?
> 
> Thanks again, Malcolm
> 

  GLMMs are messed up in new lme4 at the moment.

  sorry ...
    Ben
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPjY3yAAoJED2whTVMEyK9q74H/io6H0ek2+PUO1XL4TYLNO0f
yqelrM7nBiwvoMr13pu/qYbjnrcKiWsGFuumVtQ6js+raLUXYg7s7ChG6+g3hdSV
nFd6ESvlAAtaGxIFS67UyCTgxKBKhS8UqocdhAapK9TKXRHjnmdZJLZsas1k6CLI
fXObQ3LelrKfvjnZ6f86NN5C6kkdb7uN/BY7LOUXf5EiSqLPvPmP6ycQjHKhd5jV
0a5fwVdDMx5fWkixJqZWpf5fBTwv5KqQbq1P0LZ2/xcFFfB6lk+2iX86YKBSLUjU
8yCSp+9V6hXGiC4duZh5M6E18xY1C2E08HCmGekB3SUN4qxw9woYDvzwNVFhaIo=
=Uh/g
-----END PGP SIGNATURE-----


From roby.joehanes at nih.gov  Tue Apr 17 20:47:56 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 17 Apr 2012 14:47:56 -0400
Subject: [R-sig-ME] Patches for lme4 / pedigreemm
Message-ID: <81853F55-09FA-4E23-838E-336814694B15@nih.gov>

Hi all:

I have updated the patch for lme4 and pedigreemm against SVN release 1706 so that they can work together. Check this page:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1928&group_id=60&atid=300

The SVN release 1706 of lme4 reflects a big change in glmer, presumably to fix issues in glmer. I adapted my previous changes to the new source. I also unified lmer_finalize and glmer_finalize into mer_finalize, as requested. I also added options for nlmer fitting into pedigreemm. I just do not know whether such situation is needed.

In this update, I also modified the refit routine so that we can choose any optimizer we want. The fixme tag in that section can be deleted now. Other than that, I also fixed a typo in the comment (familiy -> family).

Too bad that there is no date stamp in the attachment sections. The older updates are obsolete and I have no way to delete them.

Thanks,
Roby


From steven.brady at yale.edu  Tue Apr 17 23:05:50 2012
From: steven.brady at yale.edu (Steven Brady)
Date: Tue, 17 Apr 2012 17:05:50 -0400
Subject: [R-sig-ME] MCMC model selection reference
In-Reply-To: <20120401193003.10433zixro7z1egw@www.staffmail.ed.ac.uk>
References: <CACdHj0O1-0iCgaY=ZgFkgWgi+LZLebfjR2Np8kpkXDBWXBWNsg@mail.gmail.com>
	<000a01cd100d$ec8a0560$c59e1020$@msu.edu>
	<20120401193003.10433zixro7z1egw@www.staffmail.ed.ac.uk>
Message-ID: <7F35B481-0745-410D-B963-55A10B9DEEE7@yale.edu>

Hi,

In regard to your last comment below about not using DIC for non-Gaussian data, would it be reasonable to instead conduct AIC based model selection (say with glmer) and then run the preferred model in MCMCglmm for inference?

Many thanks,

Steve
On Apr 1, 2012, at 2:30 PM, Jarrod Hadfield wrote:

> Hi,
> 
> My understanding of DIC (and information criterion generally) is woeful, but here are my thoughts on DIC - which I hope others will correct if they disagree.
> 
> Does DIC wok in principal  - yes, could it work in practice  - sometimes, does it work in practice - rarely (for hierarchical models).
> 
> DIC needs to be "focused". Imagine you have single Gaussian observations (y) on children within schools.  We have fixed effects b, random effects u, and variance parameters Vs (between school variance) and Ve (within school variance). We also have the fixed-effect design matrix X and random-effect design matrix Z.  We could calculate the deviance using two likelihoods:
> 
> a) dmvnorm(y, X%*%b+Z%*%u, I*Ve)
> b) dmvnorm(y, X%*%b, Z%*%t(Z)*Vs+I*Ve)
> 
> In a) we are conditioning on the school effects in b) we marginalise them. The focus in a) is of the form "can we predict new observations in *these* schools" and in b) "can we predict new observations in *new* schools".
> 
> As a parent you're probably interested in a) as a scientist you're probably interested in b).
> 
> MCMCglmm (and I believe WinBUGS, depending on how the model is parameterised) focuses at the highest level a). The reason for this is that MCMCglmm Gibbs samples u and then Gibbs samples Vs conditional on u with out the need to calculate b) which is expensive (If DIC=TRUE, a) will be calculated and this is easy). Presumably WinBUGS could calculate a) or b) depending on how it is set up, but I think b) is more usual (?) because of performance issues.
> 
> With over-dispersed non-Gaussian data the case for DIC (as implemented) is very bad, because the highest level is the latent variable (linear predictor).  Lets imagine our observations on children were how many times they missed the bus and we treated them as log-normal Poisson. DIC would be focused at "can we predict how many times *these* children miss the bus".
> 
> Modelling over-dispersion using a two-parameter distribution (without observational-level effects), perhaps a negative binomial in our example, may get us back to "can we predict how many times children from *these* schools miss the bus" but getting down to a) may be more difficult because with non-Gaussian data the random effects cannot be marginalised analytically.
> 
> For non-Gaussian data I never use DIC, and have seriously considered removing it from MCMCglmm.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> Quoting "Steven J. Pierce" <pierces1 at msu.edu> on Sun, 1 Apr 2012 09:47:03 -0400:
> 
>> Here are a couple references on DIC that I happen to have handy:
>> 
>> Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & van der Linde, A.
>> (2002). Bayesian measures of model complexity and fit. Journal of the Royal
>> Statistical Society: Series B (Statistical Methodology), 64(4), 583-639.
>> doi: 10.1111/1467-9868.00353  http://www.jstor.org/stable/3088806
>> 
>> Barnett, A. G., Koper, N., Dobson, A. J., Schmiegelow, F., & Manseau, M.
>> (2010). Using information criteria to select the correct variance-covariance
>> structure for longitudinal data in ecology. Methods in Ecology and
>> Evolution, 1(1), 15-24. doi: 10.1111/j.2041-210X.2009.00009.x
>> http://dx.doi.org/10.1111/j.2041-210X.2009.00009.x
>> 
>> 
>> Steven J. Pierce, Ph.D.
>> Associate Director
>> Center for Statistical Training & Consulting (CSTAT)
>> Michigan State University
>> E-mail: pierces1 at msu.edu
>> Web: http://www.cstat.msu.edu
>> 
>> -----Original Message-----
>> From: Ray Danner [mailto:danner.ray at gmail.com]
>> Sent: Saturday, March 31, 2012 2:24 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] MCMC model selection reference
>> 
>> Dear list,
>> 
>> I'm looking for guidance on model selection using DIC values.  I'm
>> particularly interested in comparing mixed models created with the
>> package MCMCglmm.  I currently use AIC for my models built with lme
>> and (g)lmer and like the ability to calculate evidence ratios and
>> model average predictions, which are very easy for readers to
>> conceptualize.  AICcmodavg is great for these things.
>> 
>> Can anyone recommend a resource that describes the appropriate use of
>> DIC for model selection (and its limitations)?  I'm mainly an
>> ecologist, so a less-technical treatment would be ideal.
>> 
>> My main questions are:
>> 1. Can DIC be used to select among mixed models?
>> Kery and Schaub (2012 p. 42) raise concerns about counting the correct
>> number of parameters and state that WinBUGS does not calculate them
>> appropriately, though Millar (2009) provides a method that is
>> appropriate for hierarchical models.  On the other hand, Saveliev et
>> al. (2009) use DIC to compare models with random effects built with
>> the BRugs package.  Hadfield's MCMCglmm Tutorial says that lower DIC
>> is better, but doesn't give details about use.
>> 
>> 2. Any rules of thumb on what constitutes sufficiently large deltaDIC
>> values?  Are evidence ratios acceptable?
>> 
>> 3. Can DIC be used to calculate model average predictions?
>> 
>> Thanks in advance and please forgive me if I missed your publication.
>> Ray
>> 
>> 
>> Refs
>> Kery and Schaub. 2012. Bayesian Population Analysis Using WinBUGS: A
>> Hierarchical Perspective.
>> Millar. 2009. Comparison of hierarchical Bayesian models for
>> overdispersed count data using DIC and Bayes' Factors. Biometrics
>> 65:962-969.
>> Saveliev et al. 2009. Ch. 23 in Zuur, Mixed Effects Models and
>> Extensions in Ecology with R.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jokel.meyer at googlemail.com  Wed Apr 18 14:09:55 2012
From: jokel.meyer at googlemail.com (Jokel Meyer)
Date: Wed, 18 Apr 2012 14:09:55 +0200
Subject: [R-sig-ME] Mixed-model formulation: repeated-measures and covariate
Message-ID: <CAEOpRxa8b82O=aPMjqERjAbmb4SFFPCQ0477k0wNCYpj2Y1znw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120418/b38c53a6/attachment.pl>

From raffmares at gmail.com  Fri Apr 20 14:16:56 2012
From: raffmares at gmail.com (Rafael Mares)
Date: Fri, 20 Apr 2012 13:16:56 +0100
Subject: [R-sig-ME] using MuMIn with glmmADMB
Message-ID: <CAFBzU9Nj-TeYvda=nCxihEU4XwdEvyAa5x2_OP0Ket=O_9cG9A@mail.gmail.com>

Dear all

Has anyone tried to use MuMIn along with glmmADMB? I'm trying to use
the importance() function from the MuMIn package (version 1.7.7) to
the get the sum of AIC weights across models that include a given
explanatory variable, within a set of candidate models fitted using
glmmADMB (version 0.7).

I've used this for models fitted with lme4, and it works like this:
importance(c(mod0, mod1, mod2, mod3))
where mod[i] is the model name.

This doesn't seem to work for models fitted with glmmADMB, as I get:
"Error in formula.default(x) : invalid formula"

I would be grateful if anyone had ideas/suggestions on how to work
around this problem. I can create a table with the AIC weights for
each model without using MuMIn, but importance() quickly does the
final step of adding these weights for all of my explanatory
variables.
Thank you very much.

Raff


From torvon at gmail.com  Fri Apr 20 16:42:29 2012
From: torvon at gmail.com (Eiko Fried)
Date: Fri, 20 Apr 2012 16:42:29 +0200
Subject: [R-sig-ME] MCMCglmm & multilevel multivariate models
Message-ID: <CACm_P7rdGAo2keY58EY_1-H0pFnU7P+fOtyCN9GaTxz5_FBLHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120420/00571d26/attachment.pl>

From j.hadfield at ed.ac.uk  Fri Apr 20 18:42:02 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 20 Apr 2012 17:42:02 +0100
Subject: [R-sig-ME] MCMCglmm & multilevel multivariate models
In-Reply-To: <CACm_P7rdGAo2keY58EY_1-H0pFnU7P+fOtyCN9GaTxz5_FBLHQ@mail.gmail.com>
References: <CACm_P7rdGAo2keY58EY_1-H0pFnU7P+fOtyCN9GaTxz5_FBLHQ@mail.gmail.com>
Message-ID: <20120420174202.11151cqyohupa3no@www.staffmail.ed.ac.uk>

Hi,

If your data are laid out like:

y1 y2 id time  x1  z1

0  0  a   1    1   0
0  1  a   2    1   0
1  1  a   3    1   1
3  2  b   1    2   1
0  3  b   2    2   1
1  0  b   3    2   0

for example then:

m1<-MCMCglmm(cbind(y1,y2)~trait-1+trait:x1+trait:z1,  
random=~us(trait):id, rcov=~cor(trait):units)

is probably the most complete ordinal model, with separate regressions  
of x1 and z1 on each response, correlated subject effects and  
correlated observation effects.

Regarding Shige's earlier comment I would be very very careful about  
fitting fully parameterised high dimensional models, and would try and  
simplify somehow.

Cheers,

Jarrod



Quoting Eiko Fried <torvon at gmail.com> on Fri, 20 Apr 2012 16:42:29 +0200:

> Stuart kindly hinted at MCMCglmm as a possible solution for the model I
> would like to calculate.
>
> I studied the MCMCglmm package and wonderfully detailed documentation in
> the last days, but was not able to answer a couple of questions, the two
> most important ones being:
>
> (1) How would a sample syntax look like for both a (a) multivariate model
> which is (b) at the same time repeated measure, including subjects as
> random effect also?
>
> (2) How does one differentiate between time-varying and time-invariant
> covariates in MCMCglmm?
>
> My goal is to calculate something like this:
> * y1 - y9; they are intercorrelated ordinal (0,1,2,3) items from a
> psychological screening instrument, left-skewed (plenty of 0s, few 3s)
> * x1 - x5: baseline covariates (ordered and continuous)
> * z1 - z10: time-varying dichotomous covariates (life events, assessed at
> every measurement point for the time between this and the last measurement
> point)
> * 5 measurement points
> * heterogeneity in intercepts and slopes between subjects, so this should
> also go in as random effect.
>
> The current hypothesis in the literature is that the predictors affect the
> outcome variables in a similar fashion (because the outcome variables load
> onto the same factor), my main goal is in showing that this is not the
> case, and that there are differential effects of the predictors on the
> response variables.
>
> Any advice as to how to do this in MCMCglmm would be highly appreciated.
>
> Thank you
> Eiko
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From karel.viaene at Ugent.be  Fri Apr 20 17:18:01 2012
From: karel.viaene at Ugent.be (Karel Viaene)
Date: Fri, 20 Apr 2012 17:18:01 +0200
Subject: [R-sig-ME] How to test if two gamm-predictions are significantly
	different?
Message-ID: <4F917E29.9060900@Ugent.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120420/3135b54f/attachment.pl>

From bbolker at gmail.com  Sat Apr 21 15:11:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Apr 2012 13:11:08 +0000 (UTC)
Subject: [R-sig-ME] using MuMIn with glmmADMB
References: <CAFBzU9Nj-TeYvda=nCxihEU4XwdEvyAa5x2_OP0Ket=O_9cG9A@mail.gmail.com>
Message-ID: <loom.20120421T150816-423@post.gmane.org>

Rafael Mares <raffmares at ...> writes:

> Has anyone tried to use MuMIn along with glmmADMB? I'm trying to use
> the importance() function from the MuMIn package (version 1.7.7) to
> the get the sum of AIC weights across models that include a given
> explanatory variable, within a set of candidate models fitted using
> glmmADMB (version 0.7).
> 
> I've used this for models fitted with lme4, and it works like this:
> importance(c(mod0, mod1, mod2, mod3))
> where mod[i] is the model name.
> 
> This doesn't seem to work for models fitted with glmmADMB, as I get:
> "Error in formula.default(x) : invalid formula"
 
[snip]

  It seems to work fine if I use list(mod0,mod1), for example:

library(glmmADMB)
example(glmmadmb)
bfit1 <- update(bfit,.~.-trt)
importance(list(bfit1,bfit))


From raffmares at gmail.com  Sat Apr 21 15:35:30 2012
From: raffmares at gmail.com (Rafael Mares)
Date: Sat, 21 Apr 2012 14:35:30 +0100
Subject: [R-sig-ME] using MuMIn with glmmADMB
In-Reply-To: <loom.20120421T150816-423@post.gmane.org>
References: <CAFBzU9Nj-TeYvda=nCxihEU4XwdEvyAa5x2_OP0Ket=O_9cG9A@mail.gmail.com>
	<loom.20120421T150816-423@post.gmane.org>
Message-ID: <CAFBzU9OEsxQPw+TW6mWz_xobZN+CPU-PF5Uh+hjq7U2Qi1sU4Q@mail.gmail.com>

Yes, that worked. Thank you very much Ben.

Raff


On 21 April 2012 14:11, Ben Bolker <bbolker at gmail.com> wrote:
> Rafael Mares <raffmares at ...> writes:
>
>> Has anyone tried to use MuMIn along with glmmADMB? I'm trying to use
>> the importance() function from the MuMIn package (version 1.7.7) to
>> the get the sum of AIC weights across models that include a given
>> explanatory variable, within a set of candidate models fitted using
>> glmmADMB (version 0.7).
>>
>> I've used this for models fitted with lme4, and it works like this:
>> importance(c(mod0, mod1, mod2, mod3))
>> where mod[i] is the model name.
>>
>> This doesn't seem to work for models fitted with glmmADMB, as I get:
>> "Error in formula.default(x) : invalid formula"
>
> [snip]
>
> ?It seems to work fine if I use list(mod0,mod1), for example:
>
> library(glmmADMB)
> example(glmmadmb)
> bfit1 <- update(bfit,.~.-trt)
> importance(list(bfit1,bfit))
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From torvon at gmail.com  Mon Apr 23 14:24:11 2012
From: torvon at gmail.com (Eiko Fried)
Date: Mon, 23 Apr 2012 14:24:11 +0200
Subject: [R-sig-ME] Multivariate Multilevel Mixed-Effects Model
In-Reply-To: <CAGuGQcy-sGqRHne5o2VJ7meM0eFLAmDe+3We_xDuZE29CSD2Xg@mail.gmail.com>
References: <mailman.7.1334311203.25886.r-sig-mixed-models@r-project.org>
	<F8645B87-7D26-4CCC-8642-28F549DCA428@bristol.ac.uk>
	<OF3F274F01.31F93FE8-ON852579DF.00544ABC-882579DF.00568ED7@nps.gov>
	<CAGuGQcy-sGqRHne5o2VJ7meM0eFLAmDe+3We_xDuZE29CSD2Xg@mail.gmail.com>
Message-ID: <CACm_P7piDZ4t111wC4edd-qnrymFNrbW4eM+-8z_GEW6kC2SUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120423/a44e32eb/attachment.pl>

From torvon at gmail.com  Mon Apr 23 14:25:42 2012
From: torvon at gmail.com (Eiko Fried)
Date: Mon, 23 Apr 2012 14:25:42 +0200
Subject: [R-sig-ME] MCMCglmm & multilevel multivariate models
In-Reply-To: <20120420174202.11151cqyohupa3no@www.staffmail.ed.ac.uk>
References: <CACm_P7rdGAo2keY58EY_1-H0pFnU7P+fOtyCN9GaTxz5_FBLHQ@mail.gmail.com>
	<20120420174202.11151cqyohupa3no@www.staffmail.ed.ac.uk>
Message-ID: <CACm_P7qGukWX=kx89pOJ-Qsd4_UymAxAtZ+_drx2dNZ8HDQfYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120423/5249a95e/attachment.pl>

From oseguera.david at gmail.com  Mon Apr 23 18:44:15 2012
From: oseguera.david at gmail.com (david oseguera montiel)
Date: Mon, 23 Apr 2012 11:44:15 -0500
Subject: [R-sig-ME] How to extract num. of observations and groups used in a
 mixed model using gee package
Message-ID: <4F9586DF.8060609@gmail.com>

Does anyone know how can extract the number of observations and groups used
in a mixed model with gee package?
The summary function in gee package does not provide this information.
e.g.
data(warpbreaks)
summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
corstr="exchangeable"))

I much appreciate any help,

David Oseguera Montiel
Phd student Wageningen University

pd. I asked this a few days ago in R-help list and I did not get any answer yet.


From ccleland at optonline.net  Mon Apr 23 18:58:02 2012
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 23 Apr 2012 12:58:02 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <4F9586DF.8060609@gmail.com>
References: <4F9586DF.8060609@gmail.com>
Message-ID: <4F958A1A.9060306@optonline.net>

On 4/23/2012 12:44 PM, david oseguera montiel wrote:
> Does anyone know how can extract the number of observations and groups used
> in a mixed model with gee package?
> The summary function in gee package does not provide this information.
> e.g.
> data(warpbreaks)
> summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
> corstr="exchangeable"))
>
> I much appreciate any help,
>
> David Oseguera Montiel
> Phd student Wageningen University
>
> pd. I asked this a few days ago in R-help list and I did not get any
> answer yet.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

library(gee)

data(warpbreaks)

fm1 <- gee(breaks ~ tension, id=wool, data=warpbreaks, 
corstr="exchangeable")

str(fm1)

 > fm1$nobs
[1] 54

 > length(unique(fm1$id))
[1] 2

-- 
Chuck Cleland, Ph.D.
NYU College of Nursing
726 Broadway, 10th floor
New York, NY 10003


From dwinsemius at comcast.net  Mon Apr 23 20:28:20 2012
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 23 Apr 2012 14:28:20 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
	in a mixed model using gee package
In-Reply-To: <4F9586DF.8060609@gmail.com>
References: <4F9586DF.8060609@gmail.com>
Message-ID: <EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>


On Apr 23, 2012, at 12:44 PM, david oseguera montiel wrote:

> Does anyone know how can extract the number of observations and  
> groups used
> in a mixed model with gee package?
> The summary function in gee package does not provide this information.
> e.g.
> data(warpbreaks)
> summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
> corstr="exchangeable"))

Does this address all of those puzzles?

summgee <- summary(gee(breaks ~ tension, id=wool, data=warpbreaks,   
corstr="exchangeable"))
Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
running glm to get initial regression estimate
(Intercept)    tensionM    tensionH
    36.38889   -10.00000   -14.72222
 > names(summgee)
  [1] "call"                "version"              
"nobs"                "residual.summary"
  [5] "model"               "title"                
"coefficients"        "working.correlation"
  [9] "scale"               "error"               "iterations"
 > summgee$nobs
[1] 54

 > summgee$call
gee(formula = breaks ~ tension, id = wool, data = warpbreaks,
     corstr = "exchangeable")
 > summgee$coefficients
              Estimate Naive S.E.   Naive z Robust S.E.  Robust z
(Intercept)  36.38889   3.069434 11.855246    5.774705  6.301428
tensionM    -10.00000   3.910008 -2.557539    7.463905 -1.339781
tensionH    -14.72222   3.910008 -3.765266    3.731952 -3.944912
 > rownames(summgee$coefficients)
[1] "(Intercept)" "tensionM"    "tensionH"

>
> I much appreciate any help,
>
> David Oseguera Montiel
> Phd student Wageningen University
>
> pd. I asked this a few days ago in R-help list and I did not get any  
> answer yet.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius, MD
West Hartford, CT


From oseguera.david at gmail.com  Tue Apr 24 05:25:41 2012
From: oseguera.david at gmail.com (david oseguera montiel)
Date: Mon, 23 Apr 2012 22:25:41 -0500
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
Message-ID: <4F961D35.7040209@gmail.com>

David,
Thank you very much. Number of observations solved, but I am still 
missing how to find out the number of groups used. In the warpbreaks 
data set these are 2. Any ideas. Thank you.

On 23/04/2012 13:28, David Winsemius wrote:
>
> On Apr 23, 2012, at 12:44 PM, david oseguera montiel wrote:
>
>> Does anyone know how can extract the number of observations and 
>> groups used
>> in a mixed model with gee package?
>> The summary function in gee package does not provide this information.
>> e.g.
>> data(warpbreaks)
>> summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
>> corstr="exchangeable"))
>
> Does this address all of those puzzles?
>
> summgee <- summary(gee(breaks ~ tension, id=wool, data=warpbreaks,  
> corstr="exchangeable"))
> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
> running glm to get initial regression estimate
> (Intercept)    tensionM    tensionH
>    36.38889   -10.00000   -14.72222
> > names(summgee)
>  [1] "call"                "version"             "nobs"                
> "residual.summary"
>  [5] "model"               "title"               "coefficients"        
> "working.correlation"
>  [9] "scale"               "error"               "iterations"
> > summgee$nobs
> [1] 54
>
> > summgee$call
> gee(formula = breaks ~ tension, id = wool, data = warpbreaks,
>     corstr = "exchangeable")
> > summgee$coefficients
>              Estimate Naive S.E.   Naive z Robust S.E.  Robust z
> (Intercept)  36.38889   3.069434 11.855246    5.774705  6.301428
> tensionM    -10.00000   3.910008 -2.557539    7.463905 -1.339781
> tensionH    -14.72222   3.910008 -3.765266    3.731952 -3.944912
> > rownames(summgee$coefficients)
> [1] "(Intercept)" "tensionM"    "tensionH"
>
>>
>> I much appreciate any help,
>>
>> David Oseguera Montiel
>> Phd student Wageningen University
>>
>> pd. I asked this a few days ago in R-help list and I did not get any 
>> answer yet.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> David Winsemius, MD
> West Hartford, CT
>


From dwinsemius at comcast.net  Tue Apr 24 05:57:26 2012
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 23 Apr 2012 23:57:26 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
	in a mixed model using gee package
In-Reply-To: <4F961D35.7040209@gmail.com>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
Message-ID: <9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>


On Apr 23, 2012, at 11:25 PM, david oseguera montiel wrote:

> David,
> Thank you very much. Number of observations solved, but I am still  
> missing how to find out the number of groups used. In the warpbreaks  
> data set these are 2. Any ideas. Thank you.
>
I must be unclear what you mean by "number of groups".
-- 
David.


> On 23/04/2012 13:28, David Winsemius wrote:
>>
>> On Apr 23, 2012, at 12:44 PM, david oseguera montiel wrote:
>>
>>> Does anyone know how can extract the number of observations and  
>>> groups used
>>> in a mixed model with gee package?
>>> The summary function in gee package does not provide this  
>>> information.
>>> e.g.
>>> data(warpbreaks)
>>> summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
>>> corstr="exchangeable"))
>>
>> Does this address all of those puzzles?
>>
>> summgee <- summary(gee(breaks ~ tension, id=wool, data=warpbreaks,   
>> corstr="exchangeable"))
>> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
>> running glm to get initial regression estimate
>> (Intercept)    tensionM    tensionH
>>   36.38889   -10.00000   -14.72222
>> > names(summgee)
>> [1] "call"                "version"              
>> "nobs"                "residual.summary"
>> [5] "model"               "title"                
>> "coefficients"        "working.correlation"
>> [9] "scale"               "error"               "iterations"
>> > summgee$nobs
>> [1] 54
>>
>> > summgee$call
>> gee(formula = breaks ~ tension, id = wool, data = warpbreaks,
>>    corstr = "exchangeable")
>> > summgee$coefficients
>>             Estimate Naive S.E.   Naive z Robust S.E.  Robust z
>> (Intercept)  36.38889   3.069434 11.855246    5.774705  6.301428
>> tensionM    -10.00000   3.910008 -2.557539    7.463905 -1.339781
>> tensionH    -14.72222   3.910008 -3.765266    3.731952 -3.944912
>> > rownames(summgee$coefficients)
>> [1] "(Intercept)" "tensionM"    "tensionH"
>>
>>>
>>> I much appreciate any help,
>>>
>>> David Oseguera Montiel
>>> Phd student Wageningen University
>>>
>>> pd. I asked this a few days ago in R-help list and I did not get  
>>> any answer yet.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> David Winsemius, MD
>> West Hartford, CT
>>
>

David Winsemius, MD
West Hartford, CT


From smartpink111 at yahoo.com  Tue Apr 24 06:40:18 2012
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Apr 2012 21:40:18 -0700 (PDT)
Subject: [R-sig-ME] Nested longitudinal
Message-ID: <1335242418.27560.YahooMailNeo@web39406.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120423/45823b01/attachment.pl>

From oseguera.david at gmail.com  Tue Apr 24 06:43:41 2012
From: oseguera.david at gmail.com (david oseguera montiel)
Date: Mon, 23 Apr 2012 23:43:41 -0500
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
Message-ID: <4F962F7D.7020805@gmail.com>

I meant the grouping factor in the model indicated by id. From gee 
documentation 'id = a vector which identifies the clusters..'. So in the 
warpbreaks data set, id = wool has 54 obs, in two clusters (groups).
library(gee)
library(Hmisc)
 > describe(warpbreaks$wool)
warpbreaks$wool
       n missing  unique
      54       0       2

A (27, 50%), B (27, 50%)



On 23/04/2012 22:57, David Winsemius wrote:
>
> On Apr 23, 2012, at 11:25 PM, david oseguera montiel wrote:
>
>> David,
>> Thank you very much. Number of observations solved, but I am still 
>> missing how to find out the number of groups used. In the warpbreaks 
>> data set these are 2. Any ideas. Thank you.
>>
> I must be unclear what you mean by "number of groups".


From bbolker at gmail.com  Tue Apr 24 15:46:26 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Apr 2012 13:46:26 +0000 (UTC)
Subject: [R-sig-ME] How to extract num. of observations and groups used
	in a mixed model using gee package
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
Message-ID: <loom.20120424T154528-100@post.gmane.org>

david oseguera montiel <oseguera.david at ...> writes:

> 
> I meant the grouping factor in the model indicated by id. From gee 
> documentation 'id = a vector which identifies the clusters..'. So in the 
> warpbreaks data set, id = wool has 54 obs, in two clusters (groups).

 [snip]

> >> David,
> >> Thank you very much. Number of observations solved, but I am still 
> >> missing how to find out the number of groups used. In the warpbreaks 
> >> data set these are 2. Any ideas. Thank you.
> >>
> > I must be unclear what you mean by "number of groups".


 Didn't Chuck Cleland's answer work, i.e. length(unique(model$id)) ... ?


From dwinsemius at comcast.net  Tue Apr 24 16:15:08 2012
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Apr 2012 10:15:08 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
	in a mixed model using gee package
In-Reply-To: <4F962F7D.7020805@gmail.com>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
Message-ID: <4481ABBD-D42E-4149-AD41-0DF7DC1AAC59@comcast.net>


On Apr 24, 2012, at 12:43 AM, david oseguera montiel wrote:

> I meant the grouping

> factor in the model indicated by id. From gee documentation 'id = a  
> vector which identifies the clusters..'. So in the warpbreaks data  
> set, id = wool has 54 obs, in two clusters (groups).
> library(gee)
> library(Hmisc)
> > describe(warpbreaks$wool)
> warpbreaks$wool
>      n missing  unique
>     54       0       2
>
> A (27, 50%), B (27, 50%)

So you would use this information to direct your search:

summgee <- summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
                     corstr="exchangeable"))

summgee$call$id
# wool
length(levels(warpbreaks[[as.character(summgee$call$id)]]))
#[1] 2

>
>
>
> On 23/04/2012 22:57, David Winsemius wrote:
>>
>> On Apr 23, 2012, at 11:25 PM, david oseguera montiel wrote:
>>
>>> David,
>>> Thank you very much. Number of observations solved, but I am still  
>>> missing how to find out the number of groups used. In the  
>>> warpbreaks data set these are 2. Any ideas. Thank you.
>>>
>> I must be unclear what you mean by "number of groups".
>

David Winsemius, MD
West Hartford, CT


From dwinsemius at comcast.net  Tue Apr 24 16:25:06 2012
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Apr 2012 10:25:06 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
	in a mixed model using gee package
In-Reply-To: <loom.20120424T154528-100@post.gmane.org>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
	<loom.20120424T154528-100@post.gmane.org>
Message-ID: <E479ECBC-6766-454C-9C2E-1A6DE3427DC5@comcast.net>


On Apr 24, 2012, at 9:46 AM, Ben Bolker wrote:

> david oseguera montiel <oseguera.david at ...> writes:
>
>>
>> I meant the grouping factor in the model indicated by id. From gee
>> documentation 'id = a vector which identifies the clusters..'. So  
>> in the
>> warpbreaks data set, id = wool has 54 obs, in two clusters (groups).
>
> [snip]
>
>>>> David,
>>>> Thank you very much. Number of observations solved, but I am still
>>>> missing how to find out the number of groups used. In the  
>>>> warpbreaks
>>>> data set these are 2. Any ideas. Thank you.
>>>>
>>> I must be unclear what you mean by "number of groups".
>
>
> Didn't Chuck Cleland's answer work, i.e. length(unique(model 
> $id)) ... ?

It didn't work for me.
length(unique(summgee$id))
[1] 0
 > summgee$id
NULL

See my other reply for what did work. I suppose it could be that both  
the OP and I are behind on gee versions. Mine is 4.13-17 and I see  
that there is a more recent binary on CRAN. With a (slightly out-of- 
date)  version loaded, I am loath to detach because getting things to  
all sync up is a bit of a hassle and error-prone without a fresh start  
and I have other work time-consuming  running in this session.

-- 

David Winsemius, MD
West Hartford, CT


From oseguera.david at gmail.com  Tue Apr 24 16:52:19 2012
From: oseguera.david at gmail.com (david oseguera montiel)
Date: Tue, 24 Apr 2012 09:52:19 -0500
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <4481ABBD-D42E-4149-AD41-0DF7DC1AAC59@comcast.net>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
	<4481ABBD-D42E-4149-AD41-0DF7DC1AAC59@comcast.net>
Message-ID: <4F96BE23.5040300@gmail.com>

David,
I much appreciate your help, thank you so much.
On 24/04/2012 09:15, David Winsemius wrote:
>
> On Apr 24, 2012, at 12:43 AM, david oseguera montiel wrote:
>
>> I meant the grouping
>
>> factor in the model indicated by id. From gee documentation 'id = a 
>> vector which identifies the clusters..'. So in the warpbreaks data 
>> set, id = wool has 54 obs, in two clusters (groups).
>> library(gee)
>> library(Hmisc)
>> > describe(warpbreaks$wool)
>> warpbreaks$wool
>>      n missing  unique
>>     54       0       2
>>
>> A (27, 50%), B (27, 50%)
>
> So you would use this information to direct your search:
>
> summgee <- summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
>                     corstr="exchangeable"))
>
> summgee$call$id
> # wool
> length(levels(warpbreaks[[as.character(summgee$call$id)]]))
> #[1] 2
>
>>
>>
>>
>> On 23/04/2012 22:57, David Winsemius wrote:
>>>
>>> On Apr 23, 2012, at 11:25 PM, david oseguera montiel wrote:
>>>
>>>> David,
>>>> Thank you very much. Number of observations solved, but I am still 
>>>> missing how to find out the number of groups used. In the 
>>>> warpbreaks data set these are 2. Any ideas. Thank you.
>>>>
>>> I must be unclear what you mean by "number of groups".
>>
>
> David Winsemius, MD
> West Hartford, CT
>


From kushler at oakland.edu  Tue Apr 24 16:54:58 2012
From: kushler at oakland.edu (Robert Kushler)
Date: Tue, 24 Apr 2012 10:54:58 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <E479ECBC-6766-454C-9C2E-1A6DE3427DC5@comcast.net>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
	<loom.20120424T154528-100@post.gmane.org>
	<E479ECBC-6766-454C-9C2E-1A6DE3427DC5@comcast.net>
Message-ID: <4F96BEC2.90009@oakland.edu>


The following lines from the gee help page ...

Details

Though input data need not be sorted by the variable named "id", the program will interpret physically contiguous 
records possessing the same value of id as members of the same cluster. Thus it is possible to use the following vector 
as an id vector to discriminate 4 clusters of size 4: c(0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1).


  ... indicate that the proposed strategy may not yield a correct answer.  In fact, the above suggests
that you could get different results depending on whether or not your data set is sorted.  I find
this quite disturbing, but haven't taken the time to test it.

Regards,   Rob Kushler





On 4/24/2012 10:25 AM, David Winsemius wrote:
>
> On Apr 24, 2012, at 9:46 AM, Ben Bolker wrote:
>
>> david oseguera montiel <oseguera.david at ...> writes:
>>
>>>
>>> I meant the grouping factor in the model indicated by id. From gee
>>> documentation 'id = a vector which identifies the clusters..'. So in the
>>> warpbreaks data set, id = wool has 54 obs, in two clusters (groups).
>>
>> [snip]
>>
>>>>> David,
>>>>> Thank you very much. Number of observations solved, but I am still
>>>>> missing how to find out the number of groups used. In the warpbreaks
>>>>> data set these are 2. Any ideas. Thank you.
>>>>>
>>>> I must be unclear what you mean by "number of groups".
>>
>>
>> Didn't Chuck Cleland's answer work, i.e. length(unique(model$id)) ... ?
>
> It didn't work for me.
> length(unique(summgee$id))
> [1] 0
>  > summgee$id
> NULL
>
> See my other reply for what did work. I suppose it could be that both the OP and I are behind on gee versions. Mine is
> 4.13-17 and I see that there is a more recent binary on CRAN. With a (slightly out-of-date) version loaded, I am loath
> to detach because getting things to all sync up is a bit of a hassle and error-prone without a fresh start and I have
> other work time-consuming running in this session.
>


From bbolker at gmail.com  Tue Apr 24 17:01:24 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Apr 2012 11:01:24 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <4F96BEC2.90009@oakland.edu>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
	<loom.20120424T154528-100@post.gmane.org>
	<E479ECBC-6766-454C-9C2E-1A6DE3427DC5@comcast.net>
	<4F96BEC2.90009@oakland.edu>
Message-ID: <4F96C044.2080209@gmail.com>

On 12-04-24 10:54 AM, Robert Kushler wrote:
> 
> The following lines from the gee help page ...
> 
> Details
> 
> Though input data need not be sorted by the variable named "id", the
> program will interpret physically contiguous records possessing the same
> value of id as members of the same cluster. Thus it is possible to use
> the following vector as an id vector to discriminate 4 clusters of size
> 4: c(0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1).
> 
> 
>  ... indicate that the proposed strategy may not yield a correct
> answer.  In fact, the above suggests
> that you could get different results depending on whether or not your
> data set is sorted.  I find
> this quite disturbing, but haven't taken the time to test it.
> 
> Regards,   Rob Kushler

  Yow.  Good catch.

 Maybe length(rle(geemodel$id)$length) would work?


> (id <- rep(c(0,1,0),each=3))
[1] 0 0 0 1 1 1 0 0 0
> length(rle(id)$lengths)
[1] 3
> (id <- rep(c(0,1,0,1),each=3))
 [1] 0 0 0 1 1 1 0 0 0 1 1 1
> length(rle(id)$lengths)
[1] 4

> 
> 
> 
> 
> 
> On 4/24/2012 10:25 AM, David Winsemius wrote:
>>
>> On Apr 24, 2012, at 9:46 AM, Ben Bolker wrote:
>>
>>> david oseguera montiel <oseguera.david at ...> writes:
>>>
>>>>
>>>> I meant the grouping factor in the model indicated by id. From gee
>>>> documentation 'id = a vector which identifies the clusters..'. So in
>>>> the
>>>> warpbreaks data set, id = wool has 54 obs, in two clusters (groups).
>>>
>>> [snip]
>>>
>>>>>> David,
>>>>>> Thank you very much. Number of observations solved, but I am still
>>>>>> missing how to find out the number of groups used. In the warpbreaks
>>>>>> data set these are 2. Any ideas. Thank you.
>>>>>>
>>>>> I must be unclear what you mean by "number of groups".
>>>
>>>
>>> Didn't Chuck Cleland's answer work, i.e. length(unique(model$id)) ... ?
>>
>> It didn't work for me.
>> length(unique(summgee$id))
>> [1] 0
>>  > summgee$id
>> NULL
>>
>> See my other reply for what did work. I suppose it could be that both
>> the OP and I are behind on gee versions. Mine is
>> 4.13-17 and I see that there is a more recent binary on CRAN. With a
>> (slightly out-of-date) version loaded, I am loath
>> to detach because getting things to all sync up is a bit of a hassle
>> and error-prone without a fresh start and I have
>> other work time-consuming running in this session.
>>


From j.hadfield at ed.ac.uk  Tue Apr 24 17:26:59 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 24 Apr 2012 16:26:59 +0100
Subject: [R-sig-ME] MCMCglmm & multilevel multivariate models
In-Reply-To: <CACm_P7qGukWX=kx89pOJ-Qsd4_UymAxAtZ+_drx2dNZ8HDQfYA@mail.gmail.com>
References: <CACm_P7rdGAo2keY58EY_1-H0pFnU7P+fOtyCN9GaTxz5_FBLHQ@mail.gmail.com>
	<20120420174202.11151cqyohupa3no@www.staffmail.ed.ac.uk>
	<CACm_P7qGukWX=kx89pOJ-Qsd4_UymAxAtZ+_drx2dNZ8HDQfYA@mail.gmail.com>
Message-ID: <20120424162659.14766eo74rj7lm88@www.staffmail.ed.ac.uk>

Hi,

1) I like Gelman at al's Bayesian Data Analysis

2) MCMCglmm does not deal with missing values in the predictors

3) a) time could be added, and you probably want to interact it with trait.

3) b) & 4) family=c("ordinal", "ordinal")

Jarrod


  Quoting Eiko Fried <torvon at gmail.com> on Mon, 23 Apr 2012 14:25:42 +0200:

> Some questions about MCMCglmm:
>
> (1) I worked myself thoroughly through the wonderful documentation (both
> the overview and the course notes), but found no actual R output with
> explanations what exactly means what. Are there any examples somewhere
> else? I'm no expert in Bayesian statistics, to whom the output will most
> likely be extremely straightforward.
>
> (2) Missing Values
> "Error in MCMCglmm(phq1 ~ Neuro, random = ~time, family = "ordinal", data =
> data) :
> missing values in the fixed predictors"
>
> I do have between 2% and 30% missings on my response variables (the later
> in the study the more missings, as typical in depression studies), but that
> doesn't seem to be the problem. The fixed covariates are, they have between
> 1% and 20% missings. I read a paper that stated FIML is better than
> multiple imputation, so I left the missings (MPLUS handles them easily).
> I am not sure what MCMCglmm does with missing values and can't find
> documentation, could you recommend what I should do?
>
> (3) Model
> (a) You suggested:
>
> m1<-MCMCglmm(cbind(y1,y2)~trait-1+trait:x1+trait:z1, random=~us(trait):id,
> rcov=~cor(trait):units)
> I do understand what it does, however wonder whether "time" (the variable
> denominating my measurement points) is already covered by converting data
> into units and traits? It seems counter-intuitive not to mention time as
> covariate in the analysis, seeing that it is usually done in nlme and lme4.
> (b) I don't have to mention "family=ordinal"?
>
> (4) Family
> "m1<-MCMCglmm(cbind(phq1,phq2)~trait-1+trait:Neuro+trait:ALE4,random=~us(trait):UserID,
> rcov=~cor(trait):units, data=data)"
> "Error in MCMCglmm(cbind(phq1, phq2) ~ trait - 1 + trait:Neuro +
> trait:ALE4,: family must have the same length as the number of responses"
> Adding "family=ordinal" doesn't solve this. Probably a beginner's error,
> but I can't solve it.
>
> Thank you very much for your time!
>
> On 20 April 2012 18:42, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi,
>>
>> If your data are laid out like:
>>
>> y1 y2 id time  x1  z1
>>
>> 0  0  a   1    1   0
>> 0  1  a   2    1   0
>> 1  1  a   3    1   1
>> 3  2  b   1    2   1
>> 0  3  b   2    2   1
>> 1  0  b   3    2   0
>>
>> for example then:
>>
>> m1<-MCMCglmm(cbind(y1,y2)~**trait-1+trait:x1+trait:z1,
>> random=~us(trait):id, rcov=~cor(trait):units)
>>
>> is probably the most complete ordinal model, with separate regressions of
>> x1 and z1 on each response, correlated subject effects and correlated
>> observation effects.
>>
>> Regarding Shige's earlier comment I would be very very careful about
>> fitting fully parameterised high dimensional models, and would try and
>> simplify somehow.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Eiko Fried <torvon at gmail.com> on Fri, 20 Apr 2012 16:42:29 +0200:
>>
>>  Stuart kindly hinted at MCMCglmm as a possible solution for the model I
>>> would like to calculate.
>>>
>>> I studied the MCMCglmm package and wonderfully detailed documentation in
>>> the last days, but was not able to answer a couple of questions, the two
>>> most important ones being:
>>>
>>> (1) How would a sample syntax look like for both a (a) multivariate model
>>> which is (b) at the same time repeated measure, including subjects as
>>> random effect also?
>>>
>>> (2) How does one differentiate between time-varying and time-invariant
>>> covariates in MCMCglmm?
>>>
>>> My goal is to calculate something like this:
>>> * y1 - y9; they are intercorrelated ordinal (0,1,2,3) items from a
>>> psychological screening instrument, left-skewed (plenty of 0s, few 3s)
>>> * x1 - x5: baseline covariates (ordered and continuous)
>>> * z1 - z10: time-varying dichotomous covariates (life events, assessed at
>>> every measurement point for the time between this and the last measurement
>>> point)
>>> * 5 measurement points
>>> * heterogeneity in intercepts and slopes between subjects, so this should
>>> also go in as random effect.
>>>
>>> The current hypothesis in the literature is that the predictors affect the
>>> outcome variables in a similar fashion (because the outcome variables load
>>> onto the same factor), my main goal is in showing that this is not the
>>> case, and that there are differential effects of the predictors on the
>>> response variables.
>>>
>>> Any advice as to how to do this in MCMCglmm would be highly appreciated.
>>>
>>> Thank you
>>> Eiko
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________**_________________
>>> R-sig-mixed-models at r-project.**org  
>>> <R-sig-mixed-models at r-project.org>mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From kushler at oakland.edu  Tue Apr 24 17:30:17 2012
From: kushler at oakland.edu (Robert Kushler)
Date: Tue, 24 Apr 2012 11:30:17 -0400
Subject: [R-sig-ME] Nested longitudinal
In-Reply-To: <1335242418.27560.YahooMailNeo@web39406.mail.mud.yahoo.com>
References: <1335242418.27560.YahooMailNeo@web39406.mail.mud.yahoo.com>
Message-ID: <4F96C709.3020309@oakland.edu>


I'm breaking my own rules by offering answers before getting answers to my own
questions.  However:

1) The simple general answer to your basic question is that the "/" character
is used to represent nested factors, while a "*" is used to indicate "crossed"
factors that might interact.  Your use of "+" in the model formula below means
you are *assuming* that the factors do not interact - and assuming something
doesn't make it true.   :-)

2) If both strains are tested at both wavelengths, then the factors are crossed.
However, treating them as nested produces an alternative parametrization that
may be easier to interpret.  If you use "Wavelength*Strain" the three resulting
parameters will represent traditional "main effect" and "interaction" terms,
while using "Wavelength/Strain" will yield a "main effect" for Wavelength and
two "simple effects" for Strain (one for each "Wavelength).  The difference
between the latter two parameters indirectly represents the interaction.

3) Unless you use the same "subject" more that once, "subject" is nested in
"Startingresponse" rather than the other way around.  (Is it really a response,
or did you place the subjects in their initial positions?  Perhaps the factor
should be called "Startingcondition".)

4) It seems to me that there will be very strong serial correlation in the 15
measurements on an individual subject.  Unfortunately lmer doesn't include this
as a modeling option.  Your current syntax does one of the following:  (a) fits
a linear "time effect" with a random slope and intercept or (b) if time is a factor
you are trying to estimate an "unstructured" (sorry, Doug Bates) 15 by 15 matrix.
Both approaches are problematic here.  I suggest you collapse the data by time and
record y = number of minutes (out of 15) spent in light (or dark - doesn't matter)
areas, and then use "cbind(y,15-y)" as the response.  You probably should also try
some alternatives to the binomial family (e.g., "quasibinomial").

Regards,   Rob Kushler



On 4/24/2012 12:40 AM, arun wrote:
> Hi,
>
> I have some difficulty in figuring out whether I am doing correct or not.
>
>
> A brief introduction about the work: It is a light/dark choice test
> conducted in insect larvae.  The response is binary (0- present in dark
> area, 1-present in light area) and the experiment is run for 15 min, so
> there are 15 measurements per individual larva at 1 min
> intervals.  The factors which affect this study are Strain (2 levels-G
> and S),  wavelength of light (4 levels-blue, green, UV, red), and
> starting response at 0 min (two levels- animal present in dark-D or
> light-L).  This is how I think it is nested.  Strain nested inside
> Wavelength, Subject (individual) nested within strain, Starting response within subject, and time within Starting response.   The data looks like this:
>
>           Number              Wavelength     Strain             Subject           Startingresponse              time (min)
>                  1                        Red              G                   1                          L                               1
>                  2                        Red              G                   1                          L                               2
>              ---------------------------------------------------------------------------------------------------------------
>          ---------------------------------------------------------------------------------------------------------------------
>                20
>   Red              G                     1                         L                                20
>                 21                      Red              G                      2                        D                                1
>                  22                      Red               G                    2                        D                                2
>
>              ---------------------------------------------------------------------------------------------------------------
>
>      -----------------------------------------------------------------------------------------------------------------------
>
>   40                      Red               G                      2
>                     D                             20
>
>   -----------------------------------------------------------------------------------------------------------------
>               ----------------------------------------------------------------------------------------------------------------
>
>             121                     Green             G
>     7                           D                             1
>              122                    Green              G                    7                           D                             2
>     ------------------------------------------------------------------------------------------------------------------------
> ---------------------------------------------------------------------------------------------------------------------------
>
> The model I used was:
>
>
> (fm2<-lmer(Response~Wavelength+Startingresponse+Strain+ time + (time|Subject),family=binomial, data=Behavdat))
>
> I am not sure how to specify the nested structures
>   within the
>   model.
>
> Any help will be appreciated.
> Thanks.
> 	[[alternative HTML version deleted]]
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From oseguera.david at gmail.com  Tue Apr 24 18:11:19 2012
From: oseguera.david at gmail.com (david oseguera montiel)
Date: Tue, 24 Apr 2012 11:11:19 -0500
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <4F96C044.2080209@gmail.com>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
	<loom.20120424T154528-100@post.gmane.org>
	<E479ECBC-6766-454C-9C2E-1A6DE3427DC5@comcast.net>
	<4F96BEC2.90009@oakland.edu> <4F96C044.2080209@gmail.com>
Message-ID: <4F96D0A7.1090900@gmail.com>

Ben, Rob and David,
Thank you all, to resume, the option given by Ben worked when id 
variable is stored like in the sleeping data set.

library(lme4)
mod <- gee(Reaction ~ Days, id=Subject, data=sleepstudy, 
corstr="exchangeable")
length(unique(mod$id))
[1] 18

The option given by David worked when id variable is stored like in the 
warpbreaks data set.


summgee <- summary(gee(breaks ~ tension, id=wool, data=warpbreaks,
                     corstr="exchangeable"))

summgee$call$id
# wool
length(levels(warpbreaks[[as.character(summgee$call$id)]]))
#[1] 2


On 24/04/2012 10:01, Ben Bolker wrote:
> On 12-04-24 10:54 AM, Robert Kushler wrote:
>> The following lines from the gee help page ...
>>
>> Details
>>
>> Though input data need not be sorted by the variable named "id", the
>> program will interpret physically contiguous records possessing the same
>> value of id as members of the same cluster. Thus it is possible to use
>> the following vector as an id vector to discriminate 4 clusters of size
>> 4: c(0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1).
>>
>>
>>   ... indicate that the proposed strategy may not yield a correct
>> answer.  In fact, the above suggests
>> that you could get different results depending on whether or not your
>> data set is sorted.  I find
>> this quite disturbing, but haven't taken the time to test it.
>>
>> Regards,   Rob Kushler
>    Yow.  Good catch.
>
>   Maybe length(rle(geemodel$id)$length) would work?
>
>
>> (id<- rep(c(0,1,0),each=3))
> [1] 0 0 0 1 1 1 0 0 0
>> length(rle(id)$lengths)
> [1] 3
>> (id<- rep(c(0,1,0,1),each=3))
>   [1] 0 0 0 1 1 1 0 0 0 1 1 1
>> length(rle(id)$lengths)
> [1] 4
>
>>
>>
>>
>>
>> On 4/24/2012 10:25 AM, David Winsemius wrote:
>>> On Apr 24, 2012, at 9:46 AM, Ben Bolker wrote:
>>>
>>>> david oseguera montiel<oseguera.david at ...>  writes:
>>>>
>>>>> I meant the grouping factor in the model indicated by id. From gee
>>>>> documentation 'id = a vector which identifies the clusters..'. So in
>>>>> the
>>>>> warpbreaks data set, id = wool has 54 obs, in two clusters (groups).
>>>> [snip]
>>>>
>>>>>>> David,
>>>>>>> Thank you very much. Number of observations solved, but I am still
>>>>>>> missing how to find out the number of groups used. In the warpbreaks
>>>>>>> data set these are 2. Any ideas. Thank you.
>>>>>>>
>>>>>> I must be unclear what you mean by "number of groups".
>>>>
>>>> Didn't Chuck Cleland's answer work, i.e. length(unique(model$id)) ... ?
>>> It didn't work for me.
>>> length(unique(summgee$id))
>>> [1] 0
>>>   >  summgee$id
>>> NULL
>>>
>>> See my other reply for what did work. I suppose it could be that both
>>> the OP and I are behind on gee versions. Mine is
>>> 4.13-17 and I see that there is a more recent binary on CRAN. With a
>>> (slightly out-of-date) version loaded, I am loath
>>> to detach because getting things to all sync up is a bit of a hassle
>>> and error-prone without a fresh start and I have
>>> other work time-consuming running in this session.
>>>


From bbolker at gmail.com  Tue Apr 24 18:19:29 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Apr 2012 12:19:29 -0400
Subject: [R-sig-ME] How to extract num. of observations and groups used
 in a mixed model using gee package
In-Reply-To: <4F96D0A7.1090900@gmail.com>
References: <4F9586DF.8060609@gmail.com>
	<EB26D8EA-1373-4E60-B743-2153F9F82CF0@comcast.net>
	<4F961D35.7040209@gmail.com>
	<9AEE381C-C3F6-4762-B8EF-5BEDCFE2198B@comcast.net>
	<4F962F7D.7020805@gmail.com>
	<loom.20120424T154528-100@post.gmane.org>
	<E479ECBC-6766-454C-9C2E-1A6DE3427DC5@comcast.net>
	<4F96BEC2.90009@oakland.edu> <4F96C044.2080209@gmail.com>
	<4F96D0A7.1090900@gmail.com>
Message-ID: <4F96D291.80205@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-04-24 12:11 PM, david oseguera montiel wrote:
> Ben, Rob and David, Thank you all, to resume, the option given by
> Ben worked when id variable is stored like in the sleeping data
> set.
> 
> library(lme4) mod <- gee(Reaction ~ Days, id=Subject,
> data=sleepstudy, corstr="exchangeable") length(unique(mod$id)) [1]
> 18
> 
> The option given by David worked when id variable is stored like in
> the warpbreaks data set.
> 
> 
> summgee <- summary(gee(breaks ~ tension, id=wool, data=warpbreaks, 
> corstr="exchangeable"))
> 
> summgee$call$id # wool 
> length(levels(warpbreaks[[as.character(summgee$call$id)]])) #[1] 2
> 

  This is the difference between a 'gee' object and 'summary.gee'
object.  Please make sure to read the details quoted below, to make
sure that you are not misled in cases where the clusters are coded as
non-unique (but contiguous) levels ... (and it wasn't my idea, it was
Chuck Cleland's).

  Ben

> 
> On 24/04/2012 10:01, Ben Bolker wrote:
>> On 12-04-24 10:54 AM, Robert Kushler wrote:
>>> The following lines from the gee help page ...
>>> 
>>> Details
>>> 
>>> Though input data need not be sorted by the variable named
>>> "id", the program will interpret physically contiguous records
>>> possessing the same value of id as members of the same cluster.
>>> Thus it is possible to use the following vector as an id vector
>>> to discriminate 4 clusters of size 4:
>>> c(0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1).
>>> 
>>> 
>>> ... indicate that the proposed strategy may not yield a
>>> correct answer.  In fact, the above suggests that you could get
>>> different results depending on whether or not your data set is
>>> sorted.  I find this quite disturbing, but haven't taken the
>>> time to test it.
>>> 
>>> Regards,   Rob Kushler
>> Yow.  Good catch.
>> 
>> Maybe length(rle(geemodel$id)$length) would work?
>> 
>> 
>>> (id<- rep(c(0,1,0),each=3))
>> [1] 0 0 0 1 1 1 0 0 0
>>> length(rle(id)$lengths)
>> [1] 3
>>> (id<- rep(c(0,1,0,1),each=3))
>> [1] 0 0 0 1 1 1 0 0 0 1 1 1
>>> length(rle(id)$lengths)
>> [1] 4
>> 
>>> 
>>> 
>>> 
>>> 
>>> On 4/24/2012 10:25 AM, David Winsemius wrote:
>>>> On Apr 24, 2012, at 9:46 AM, Ben Bolker wrote:
>>>> 
>>>>> david oseguera montiel<oseguera.david at ...>  writes:
>>>>> 
>>>>>> I meant the grouping factor in the model indicated by id.
>>>>>> From gee documentation 'id = a vector which identifies
>>>>>> the clusters..'. So in the warpbreaks data set, id = wool
>>>>>> has 54 obs, in two clusters (groups).
>>>>> [snip]
>>>>> 
>>>>>>>> David, Thank you very much. Number of observations
>>>>>>>> solved, but I am still missing how to find out the
>>>>>>>> number of groups used. In the warpbreaks data set
>>>>>>>> these are 2. Any ideas. Thank you.
>>>>>>>> 
>>>>>>> I must be unclear what you mean by "number of groups".
>>>>> 
>>>>> Didn't Chuck Cleland's answer work, i.e.
>>>>> length(unique(model$id)) ... ?
>>>> It didn't work for me. length(unique(summgee$id)) [1] 0
>>>>> summgee$id
>>>> NULL
>>>> 
>>>> See my other reply for what did work. I suppose it could be
>>>> that both the OP and I are behind on gee versions. Mine is 
>>>> 4.13-17 and I see that there is a more recent binary on CRAN.
>>>> With a (slightly out-of-date) version loaded, I am loath to
>>>> detach because getting things to all sync up is a bit of a
>>>> hassle and error-prone without a fresh start and I have other
>>>> work time-consuming running in this session.
>>>> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPltKQAAoJED2whTVMEyK9nUQH/0DZis3/ko00hw4TaHQcK7LT
pxMpbrjnwEO/RWFnmAosXznjHyfCuxZkWA4YJZPsEcNTC7RxLo8LuMITp1U5DVTt
JOuJExiAE1oR9/EnRhu2VmhHqeyMgU94Lg5SKZ2GWofgTlPw8Rly3o2DYG7K/s8M
QRWeXdqSJsl6sjmQGpy1t0PClEJ9ix9OBEMVJsAsNBY6pHIsB1dbBI1eTor21imU
ihJb3Yu11ye1nPZJqhXC13OP1quv8BQzDgDCaFQxT94Lm6z1QjiGE7HAp8RA4UwR
3nZIWZ4BlZFbFhVzK2JvOASXN9u75WYAioVob0nLq6r1gnuDSWCyg20V5RuJOkI=
=ep+g
-----END PGP SIGNATURE-----


From angelina.mukherjee88 at gmail.com  Tue Apr 24 19:10:50 2012
From: angelina.mukherjee88 at gmail.com (Angelina Mukherjee)
Date: Tue, 24 Apr 2012 18:10:50 +0100
Subject: [R-sig-ME] Gene expression lme
Message-ID: <CAMFXY1nNsAsvoiqUUrtwP5fnMddZBaFJax69TUfgjh42-whPTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120424/5e859b0b/attachment.pl>

From bbolker at gmail.com  Wed Apr 25 00:14:39 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Apr 2012 22:14:39 +0000 (UTC)
Subject: [R-sig-ME] Nested longitudinal
References: <1335242418.27560.YahooMailNeo@web39406.mail.mud.yahoo.com>
	<4F96C709.3020309@oakland.edu>
Message-ID: <loom.20120425T000648-117@post.gmane.org>

Robert Kushler <kushler at ...> writes:

> 
> 
> I'm breaking my own rules by offering answers before getting answers to my own
> questions.  

  Hmmm.  I didn't see any outstanding unanswered questions from you 
on the list -- did I miss some?  Or have you not asked them yet?

> 1) The simple general answer to your basic question is that the "/"
> character is used to represent nested factors, while a "*" is used
> to indicate "crossed" factors that might interact.  Your use of "+"
> in the model formula below means you are *assuming* that the factors
> do not interact - and assuming something doesn't make it true.

  [snip]

>  4) It seems to me that there will be very strong serial correlation
> in the 15 measurements on an individual subject.  Unfortunately lmer
> doesn't include this as a modeling option.  Your current syntax does
> one of the following: (a) fits a linear "time effect" with a random
> slope and intercept or (b) if time is a factor you are trying to
> estimate an "unstructured" (sorry, Doug Bates) 15 by 15 matrix.
> Both approaches are problematic here.  I suggest you collapse the
> data by time and record y = number of minutes (out of 15) spent in
> light (or dark - doesn't matter) areas, and then use "cbind(y,15-y)"
> as the response.  You probably should also try some alternatives to
> the binomial family (e.g., "quasibinomial").

   lmer doesn't include it at least in part because it's difficult to
fit into a conditional GLMM framework -- the most sensible way to
define this would be to allow a per-observation random effect (which
would then also make the binomial overdispersed by definition), and
then specify that the individual-level random effects were themselves
temporally correlated.

  Usually when you find packages that can incorporate temporal
correlation in a GLMM they either require that you specify the full
statistical model yourself (WinBUGS/JAGS, AD Model Builder), *or* they
are in some sense marginal models (glmmPQL in the MASS package [I
know] and ASREML [I think] allow 'R-side' structures such as temporal
correlation in GLMMs, but they use penalized quasi-likelihood for
estimation, which may under some circumstances be problematic).

  For what it's worth you can't use quasi- families in glmer(); you
can either add an individual-level random effect, or use MASS::glmmPQL
if you want quasi- (see http://glmm.wikidot.com/faq for more
discussion of overdispersion in GLMMs).

 
> Regards,   Rob Kushler
> 
> On 4/24/2012 12:40 AM, arun wrote:

 [snip]

> > A brief introduction about the work: It is a light/dark choice
> > test conducted in insect larvae.  The response is binary (0-
> > present in dark area, 1-present in light area) and the experiment
> > is run for 15 min, so there are 15 measurements per individual
> > larva at 1 min intervals.  The factors which affect this study are
> > Strain (2 levels-G and S), wavelength of light (4 levels-blue,
> > green, UV, red), and starting response at 0 min (two levels-
> > animal present in dark-D or light-L).  This is how I think it is
> > nested.  Strain nested inside Wavelength, Subject (individual)
> > nested within strain, Starting response within subject, and time >
> > within Starting response.  The data looks like this:

[snip]

> >
> >
> > (fm2<-lmer(Response~Wavelength+Startingresponse+Strain+ time +
> (time|Subject),family=binomial, data=Behavdat))
> >
> > I am not sure how to specify the nested structures
> >   within the
> >   model.


From bbolker at gmail.com  Wed Apr 25 00:25:17 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Apr 2012 22:25:17 +0000 (UTC)
Subject: [R-sig-ME] Gene expression lme
References: <CAMFXY1nNsAsvoiqUUrtwP5fnMddZBaFJax69TUfgjh42-whPTw@mail.gmail.com>
Message-ID: <loom.20120425T002159-783@post.gmane.org>

Angelina Mukherjee <angelina.mukherjee88 at ...> writes:

> I have gene expression data and have a subset of the same, comprising
> about 20,000 rows (genes) and 3 factors. I am interested in how these
> factors like patient affect the gene expression. An outline of my data
> frame is shown below:
> 
>    Probe  patient region subregion expression
> 1  650349    1      1         1    12.969875
> 2 2510494    1      1         1    9.042255
> 3 2940041    1      1         1    7.010943
> 4 3830112    1      1         1    7.520437
> 5 6560392    1      1         1    7.685423
> 6 1450041    1      1         1    6.595077
> 
> I fit the following: *> fit <- lme(expression ~ Probe + region +
> subregion , random=~1|patient/region/subregion, data=df)*
> 
> I get the following error:*Error in model.matrix.default(fixed, data = X) :
>   allocMatrix: too many elements specified*
> 
> Here I am investigating whether different subregions within multiple
> different regions nested within various patients affect gene
> expression response. I cannot model the response per *probe* as I'd
> have only one observation then.

  Any chance of a reproducible example 
(see http://tinyurl.com/reproducible-000 ), e.g. post the data
or a subset of the data that reproduces the error somewhere, or
simulate some data accordingly (you can probably replace your
"expression" column with random numbers) ?

  I'm a little concerned that 'Probe' is being treated as numeric,
although that might not be relevant to the particular error message.
How many distinct probes and patients are there, and how do they
overlap?  (e.g. multiple probes per patient, or patients per probe,
or ... ?)

  If it turns out that this is due to a limitation of lme and
not to some syntax and/or data issue, it's possible that switching
to lme4/lmer would help.

  Ben Bolker


From aghaynes at gmail.com  Wed Apr 25 15:15:05 2012
From: aghaynes at gmail.com (Alan Haynes)
Date: Wed, 25 Apr 2012 15:15:05 +0200
Subject: [R-sig-ME] effective degrees of freedom
Message-ID: <CAPdSD+72nZx4nE0_MDYph9aou3sRAnmRZyRBD_Q6A+QG7=J3ng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120425/28d31875/attachment.pl>

From bbolker at gmail.com  Wed Apr 25 15:57:37 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Apr 2012 13:57:37 +0000 (UTC)
Subject: [R-sig-ME] effective degrees of freedom
References: <CAPdSD+72nZx4nE0_MDYph9aou3sRAnmRZyRBD_Q6A+QG7=J3ng@mail.gmail.com>
Message-ID: <loom.20120425T153647-59@post.gmane.org>

Alan Haynes <aghaynes at ...> writes:

> This isnt so much an R question, as a theoretical question, but this is
> probably the best place to find an answer.
> Im attempting to calculate my effective sample size. Following Zuur et al
> 2009, for models with a single random effect, this seems to be relatively
> simple:
> 
> Intraclass correlation, ICC:
> 
> ICC = d^2 / (d^2+sigma^2)
> 
> in R:
> ranmod <- summary(mod)@REmat

   I would strongly encourage you to use the accessor
method (VarCorr) provided for this, i.e.

vc <- VarCorr(mod)
v <- vc[[1]][1,1]

 or more explicitly

v.subj <- vc[["Subject"]]["(Intercept)","(Intercept)"]

  i.e. pull out the subject-level random variance-covariance
matrix, extract the intercept-level variance

v.resid <- attr(vc,"sc")^2
ICC <- v.subj/(v.subj + v.resid)

> Using the random effects matrix from the summary.mer object we take the
> St.Dev value for the value of d and the residual St.Dev for sigma.
> 
> ICC is then used to calculate a "design effect" :
> 
> DE = 1 + (n-1) * ICC
> 
> in R:


> DE <- 1 + (length(ranef(mod)[,1])-1)*IC

  Hmmm.  I don't know what version of lme4 you're using, but for
me 

n <- nrow(ranef(mod)[[1]])

works better (there's no real difference between nrow(x) and length(x[,1]),
but the [[1]] is necessary to pull out the first element of the *list*
of random effects)
  
  
> 
> where n is the number of levels for the random effect. This is then used to
> calculate the effect sample size, N_effective:
> 
> N_effective = (N * n) / DE
> 
> in R:
> N_effective <- N*length(ranef(mod)[,1]) / DE
> (I havent come up with a good way to find N...)

  Well, this is a balanced design, so N*n is just the total number of
observations.  nobs(mod) **should** work but doesn't (in the stable
version of lme4), but nrow(model.frame(mod)) does ...
> 
> where N is the number of samples per level of the random effect.
> 
> I was wondering whether anyone had any idea how to calculate this for a
> model with 2 random effects. I havent been able to find any suggestions
> beyond this single random effect. I assume multiple random effects affect
> d, N and n.

  Well, the formulas that Zuur et al. give are from Snijders and Bosker 1999
(An Introduction to Basic and Advanced Multilevel Modeling); I suspect
you'd have to go there.

You can get a glance here:

http://tinyurl.com/snijdersboskerDE

However, this is likely to be a big can of worms.  If your two random
effects are nested, then the design effect should probably be calculated
according to the relevant level for whichever effect you are testing
(e.g. in a split-plot design, different effects are tested at different
levels).  If your two random effects are crossed, there's probably
no good answer.

> Perhaps more relevant, is it even worth worrying about effective sample
> size for use as a denominator DF when calculating P-Values?

   See http://glmm.wikidot.com/faq for some discussion of denominator
df and p-values ...

  Ben Bolker


From yann.hautier at ieu.uzh.ch  Wed Apr 25 17:36:54 2012
From: yann.hautier at ieu.uzh.ch (Yann Hautier)
Date: Wed, 25 Apr 2012 17:36:54 +0200
Subject: [R-sig-ME] Predictions and/or confidence (or prediction) intervals
	on predictions
Message-ID: <4F981A16.7000202@ieu.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120425/037d4d00/attachment.pl>

From agalecki at umich.edu  Wed Apr 25 18:14:22 2012
From: agalecki at umich.edu (Andrzej)
Date: Wed, 25 Apr 2012 12:14:22 -0400
Subject: [R-sig-ME] Predictions and/or confidence (or prediction)
 intervals on predictions
In-Reply-To: <4F981A16.7000202@ieu.uzh.ch>
References: <4F981A16.7000202@ieu.uzh.ch>
Message-ID: <4F9822DE.2060809@umich.edu>

Hi Yann,

Reparameterize the  model. This is probably what you are looking for:

 > fm1a <- lme(distance ~ -1 + Sex +age:Sex, random = ~ 1 + age | 
Subject, data = Orthodont)
 > fixef(fm1a)
       SexMale     SexFemale   SexMale:age SexFemale:age
    16.3406250    17.3727273     0.7843750     0.4795455

Hope it helps

Andrzej

PS. age is continuous not "sort of categorical"

On 4/25/2012 11:36 AM, Yann Hautier wrote:
> Dear all,
>
> On the FAQ page of http://glmm.wikidot.com/faq, Ben Bolker gives a nice
> example of how to get predictions and/or confidence (or prediction)
> intervals on predictions from the following model for lme:
> fm1<- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data =
> Orthodont)
> and for lmer
> fm1 = lmer(formula = distance ~ age*Sex + (age|Subject), data = Orthodont,)|
>
> |In this example, to calculate the predictions and confidence intervals,
> the variable age is sort of considered as categorical,
> age=c(8,10,12,14), and therefore the coefficients reported are the means
> with their SE.
> However, the fixef(fm1) output of the model shows that age is a
> continuous variable and therefore the output
> (Intercept)         age     SexMale age:SexMale
>       17.3727      0.4795     -1.0321      0.3048
> reports the intercept of Female (Intercept), the slope of Female (age),
> the difference in the intercept for Male (SexMale) and the difference in
> slope for Male (age:SexMale). The intercept and slope for Male have to
> be calculated, the intercept is then 17.3727+(-1.0321)=16.3406 and the
> slope is then 0.4795+0.3048=0.7843.
>
> Here is my question. In the same fashion as the means are calculated
> with the model.matrix
> newdat<- expand.grid(age=c(8,10,12,14),Sex=c("Male","Female"),distance = 0)
> mm = model.matrix(terms(fm1),newdat)
> newdat$distance = mm %*% fixef(fm1)
> Is it possible to directly calculate the slopes and intercepts from this
> model? I am of course talking about the estimates of each of the slope
> and intercept for each gender (male and female). So with the calculation
> from the fixef(lm1) output.
>
> Thanks in advance,
> Yann
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From torvon at gmail.com  Wed Apr 25 19:32:07 2012
From: torvon at gmail.com (Eiko Fried)
Date: Wed, 25 Apr 2012 19:32:07 +0200
Subject: [R-sig-ME] Comparison of predictors in lme4
Message-ID: <CACm_P7qFNdH84=61dt-B08Dk57UjWeQgci4T-_WE_4m6nNczgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120425/39a64700/attachment.pl>

From bbolker at gmail.com  Wed Apr 25 20:13:06 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Apr 2012 14:13:06 -0400
Subject: [R-sig-ME] Nested longitudinal
In-Reply-To: <1335377196.49812.YahooMailNeo@web39401.mail.mud.yahoo.com>
References: <1335242418.27560.YahooMailNeo@web39406.mail.mud.yahoo.com>
	<4F96C709.3020309@oakland.edu>
	<loom.20120425T000648-117@post.gmane.org>
	<1335377196.49812.YahooMailNeo@web39401.mail.mud.yahoo.com>
Message-ID: <4F983EB2.5030108@gmail.com>

  a. these weren't my comments (mostly), they were Rob Kushler's

  b. in general it's best to keep these conversations on-list, in case
someone else wants to chime in and to keep the information public and
archivable for future reference.  I've cc'd back to r-sig-mixed-models.

  Ben Bolker


On 12-04-25 02:06 PM, arun wrote:
> 
> 
> Hi Ben, Thanks for the suggestions.  I did the analysis again by
> collapsing the data by time, but I made a small change.  Instead of
> collapsing the whole data, I made it collapsed in 5 minute intervals
> (1-5), (6-10), (11-15).  So, I have 3 levels -5, 10, 15 for time.
> The new dataset is run using the model after fitting the observation
> level random effects:
> 
> 
> Behavdat2$resid<-as.factor(1:dim(Behavdat2)[1])
> 
> lmer gives error message when I used family=quasibinomial.

  Yes.  See the last paragraph of my comments below.
> 
> 
> Response2 <- 5-Behavdat2$Response 
> Response3 <-cbind(Response,Response2)
> 
> My model:
> 
> (fm1<-lmer(Response3~Wavelength*(Start_Resp/Time)+(1|Subject)+(1|resid),
> family=binomial,data=Behavdat2))
> 
> I didn't use the Strain as only a subset of the data with 1 level of
> strain was analyzed.
> 
> In the model, I specified Time as being nested within Start_Resp.  I
> think Time could be nested under Subject, but I would like to run
> Time as a fixed effect with 4 levels and my aim will  be to look for
> whether there is any change in light/dark response to various
> wavelengths (3 levels used - Red, Blue, Green) as time changes.
> 
> Is it a correct model to find the changes in light response in
> different time levels for different wavelengths?  Do I need to have
> an interaction model with Wavelength*Start_Resp*Time, given that the
> correlations within subject will be taken care by 1|resid statement
> in the model?
> 
> I appreciate your comments. Thanks AK
> 
> 
> My  dataset: Number Wavelength Strain Subject Start_Resp time
> Response 1 Red G 1 L 5 3 2 Red G 1 L 10 0 3 Red G 1 L 15 0
> 
> 
> 
> 
> 
> 
> 
> 5 Red G 2 L 5 3 6 Red G 2 L 10 3 7 Red G 2 L 15 3
> 
> ===== ======
> 
> ===============
> 
> ====-------------------------------------------
> 
> 
> 
> 
> 
> From: Ben Bolker <bbolker at gmail.com> To:
> r-sig-mixed-models at r-project.org Sent: Tuesday, April 24, 2012 6:14
> PM Subject: Re: [R-sig-ME] Nested longitudinal
> 
> Robert Kushler <kushler at ...> writes:
> 
>> 
>> 
>> I'm breaking my own rules by offering answers before getting
>> answers to my own questions.
> 
> Hmmm.  I didn't see any outstanding unanswered questions from you on
> the list -- did I miss some?  Or have you not asked them yet?
> 
>> 1) The simple general answer to your basic question is that the
>> "/" character is used to represent nested factors, while a "*" is
>> used to indicate "crossed" factors that might interact.  Your use
>> of "+" in the model formula below means you are *assuming* that the
>> factors do not interact - and assuming something doesn't make it
>> true.
> 
> [snip]
> 
>> 4) It seems to me that there will be very strong serial
>> correlation in the 15 measurements on an individual subject.
>> Unfortunately lmer doesn't include this as a modeling option.  Your
>> current syntax does one of the following: (a) fits a linear "time
>> effect" with a random slope and intercept or (b) if time is a
>> factor you are trying to estimate an "unstructured" (sorry, Doug
>> Bates) 15 by 15 matrix. Both approaches are problematic here.  I
>> suggest you collapse the data by time and record y = number of
>> minutes (out of 15) spent in light (or dark - doesn't matter)
>> areas, and then use "cbind(y,15-y)" as the response.  You probably
>> should also try some alternatives to the binomial family (e.g.,
>> "quasibinomial").
> 
> lmer doesn't include it at least in part because it's difficult to 
> fit into a conditional GLMM framework -- the most sensible way to 
> define this would be to allow a per-observation random effect (which 
> would then also make the binomial overdispersed by definition), and 
> then specify that the individual-level random effects were
> themselves temporally correlated.
> 
> Usually when you find packages that can incorporate temporal 
> correlation in a GLMM they either require that you specify the full 
> statistical model yourself (WinBUGS/JAGS, AD Model Builder), *or*
> they are in some sense marginal models (glmmPQL in the MASS package
> [I know] and ASREML [I think] allow 'R-side' structures such as
> temporal correlation in GLMMs, but they use penalized
> quasi-likelihood for estimation, which may under some circumstances
> be problematic).
> 
> For what it's worth you can't use quasi- families in glmer(); you can
> either add an individual-level random effect, or use MASS::glmmPQL if
> you want quasi- (see http://glmm.wikidot.com/faq for more discussion
> of overdispersion in GLMMs).
> 
> 
>> Regards,   Rob Kushler
>> 
>> On 4/24/2012 12:40 AM, arun wrote:
> 
> [snip]
> 
>>> A brief introduction about the work: It is a light/dark choice 
>>> test conducted in insect larvae.  The response is binary (0- 
>>> present in dark area, 1-present in light area) and the
>>> experiment is run for 15 min, so there are 15 measurements per
>>> individual larva at 1 min intervals.  The factors which affect
>>> this study are Strain (2 levels-G and S), wavelength of light (4
>>> levels-blue, green, UV, red), and starting response at 0 min (two
>>> levels- animal present in dark-D or light-L).  This is how I
>>> think it is nested.  Strain nested inside Wavelength, Subject
>>> (individual) nested within strain, Starting response within
>>> subject, and time > within Starting response.  The data looks
>>> like this:
> 
> [snip]
> 
>>> 
>>> 
>>> (fm2<-lmer(Response~Wavelength+Startingresponse+Strain+ time +
>> (time|Subject),family=binomial, data=Behavdat))
>>> 
>>> I am not sure how to specify the nested structures within the 
>>> model.
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From torvon at gmail.com  Wed Apr 25 22:09:56 2012
From: torvon at gmail.com (Eiko Fried)
Date: Wed, 25 Apr 2012 22:09:56 +0200
Subject: [R-sig-ME] MCMCglmm & multilevel multivariate models
In-Reply-To: <20120424162659.14766eo74rj7lm88@www.staffmail.ed.ac.uk>
References: <CACm_P7rdGAo2keY58EY_1-H0pFnU7P+fOtyCN9GaTxz5_FBLHQ@mail.gmail.com>
	<20120420174202.11151cqyohupa3no@www.staffmail.ed.ac.uk>
	<CACm_P7qGukWX=kx89pOJ-Qsd4_UymAxAtZ+_drx2dNZ8HDQfYA@mail.gmail.com>
	<20120424162659.14766eo74rj7lm88@www.staffmail.ed.ac.uk>
Message-ID: <CACm_P7o4rVZA9OgOsPQOdFYWSO=2pxMZMU1vrmcMktRjgG63-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120425/8f878cb4/attachment.pl>

From chris at trickysolutions.com.au  Thu Apr 26 00:48:53 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 26 Apr 2012 08:48:53 +1000
Subject: [R-sig-ME] Comparison of predictors in lme4
In-Reply-To: <CACm_P7qFNdH84=61dt-B08Dk57UjWeQgci4T-_WE_4m6nNczgA@mail.gmail.com>
References: <CACm_P7qFNdH84=61dt-B08Dk57UjWeQgci4T-_WE_4m6nNczgA@mail.gmail.com>
Message-ID: <1416490043590576948@unknownmsgid>

U could calculate prediction intervals.  The smaller the interval the
'better' the estimation.



Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 26/04/2012, at 3:34, Eiko Fried <torvon at gmail.com> wrote:

> If I have two models:
>
>> m1 ~ lmer ( y1 ~ x1 + ( 1 | subject) )
>> m2 ~ lmer ( y2 ~ x1 + ( 1 | subject) )
>
> and
> m1: fixed effects t-value x1 = 25
> m2: fixed effects t-value x1 = 5
>
> is there a way to calculate whether there is a statistical difference in
> the prediction of y1 vs y2 by x1, i.e. whether y1 is predicted in a
> significantly stronger way by x1 that y2? Something like ... R or eta
> square maybe?
>
> Thank you
> Eiko
>
> (PS.: the solution of transforming the data and using a multivariate
> response y and then calculating the interaction y~y_type*x is an option I'm
> exploring currently, but I wonder what a solution would be in separate
> univariate models)
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From yann.hautier at ieu.uzh.ch  Thu Apr 26 10:06:49 2012
From: yann.hautier at ieu.uzh.ch (Yann Hautier)
Date: Thu, 26 Apr 2012 10:06:49 +0200
Subject: [R-sig-ME] Predictions and/or confidence (or prediction)
 intervals on predictions
In-Reply-To: <4F9822DE.2060809@umich.edu>
References: <4F981A16.7000202@ieu.uzh.ch> <4F9822DE.2060809@umich.edu>
Message-ID: <4F990219.7020101@ieu.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120426/180f0829/attachment.pl>

From torvon at gmail.com  Thu Apr 26 12:08:45 2012
From: torvon at gmail.com (Eiko Fried)
Date: Thu, 26 Apr 2012 12:08:45 +0200
Subject: [R-sig-ME] Comparison of predictors in lme4
In-Reply-To: <1416490043590576948@unknownmsgid>
References: <CACm_P7qFNdH84=61dt-B08Dk57UjWeQgci4T-_WE_4m6nNczgA@mail.gmail.com>
	<1416490043590576948@unknownmsgid>
Message-ID: <CACm_P7r7_sWv6UkRe-TKou=LSoPK7cwMQVePLt=HKzr5nuXGaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120426/27d4c941/attachment.pl>

From m.balzan at sssup.it  Thu Apr 26 13:15:05 2012
From: m.balzan at sssup.it (Mario V. Balzan)
Date: Thu, 26 Apr 2012 13:15:05 +0200
Subject: [R-sig-ME] plot glmmPQL
Message-ID: <CA+avhtgNnEcM7APtLVMDbP6odm7k3mVuY62qHUvZVVnuKD=A2Q@mail.gmail.com>

Dear all,

I am investigating the influence of some experimental treatments
(A,B,C,...) on fecundity of a lepidoptera. These data have been
collected over time from different experimental plots (A1, A2, ... ).
I am using glmmPQL function with quasipoisson errors since these are
count data and with overdispersion.

the model which I came up with is as follows:
glmmPQL(Fecundity~Treatment,random=~Time|Plot, family="quasipoisson")

I would like to plot a curve of fecundity against time for each
treatment from this model. Is that possible? Would appreciate if
someone could help me out with this.

this is a sample of my data:
  Time. Fecundity Plot Treatment
      2        40   A1         A
      4        10   A1         A
      6         0   A1         A
      8         0   A1         A
      2        21   A2         A
      4         0   A2         A
      6         0   A2         A
      2         9   A3         A
      4         0   A3         A
    2        23   A4         A
     4         0   A4         A
     6         2   A4         A
     2         0   B1         B
    4         0   B1         B
    6        10   B1         B
     8         0   B1         B
   11         0   B1         B
    2         1   B2         B
    4         2   B2         B
    6         0   B2         B
    8        25   B2         B
   11         6   B2         B
    13         4   B2         B
    15        10   B2         B
    18         8   B2         B
     2         5   B3         B
     4         6   B3         B
     6        20   B3         B
     8         2   B3         B
    11         2   B3         B
     2        23   C1         C
     4         8   C1         C
     6         4   C1         C
     8         0   C1         C
    10         2   C1         C
   13         0   C1         C
     2        15   C2         C
     4        15   C2         C
     6         4   C2         C
     8         0   C2         C
    10         0   C2         C
    13         0   C2         C
     2        65   C3         C
     4         2   C3         C
     6         8   C3         C
     8        10   C3         C
    10         6   C3         C
   13         2   C3         C
...


Thanks in advance,
Mario


From angelina.mukherjee88 at gmail.com  Thu Apr 26 17:30:00 2012
From: angelina.mukherjee88 at gmail.com (Angelina Mukherjee)
Date: Thu, 26 Apr 2012 16:30:00 +0100
Subject: [R-sig-ME]  Gene expression lme
In-Reply-To: <CAMFXY1n2d6V2=2tXw70Vh6P9PE77ddUMSapxEpxrO=d_U9M4jw@mail.gmail.com>
References: <CAMFXY1nNsAsvoiqUUrtwP5fnMddZBaFJax69TUfgjh42-whPTw@mail.gmail.com>
	<loom.20120425T002159-783@post.gmane.org>
	<CAMFXY1n2d6V2=2tXw70Vh6P9PE77ddUMSapxEpxrO=d_U9M4jw@mail.gmail.com>
Message-ID: <CAMFXY1mB51mzEYiZpGHWgnVEMRoRSMeF9Mb8UAsBk=Jy5BwSVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120426/aae90320/attachment.pl>

From f.calboli at imperial.ac.uk  Thu Apr 26 17:43:05 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 26 Apr 2012 16:43:05 +0100
Subject: [R-sig-ME] Gene expression lme
In-Reply-To: <CAMFXY1mB51mzEYiZpGHWgnVEMRoRSMeF9Mb8UAsBk=Jy5BwSVQ@mail.gmail.com>
References: <CAMFXY1nNsAsvoiqUUrtwP5fnMddZBaFJax69TUfgjh42-whPTw@mail.gmail.com>
	<loom.20120425T002159-783@post.gmane.org>
	<CAMFXY1n2d6V2=2tXw70Vh6P9PE77ddUMSapxEpxrO=d_U9M4jw@mail.gmail.com>
	<CAMFXY1mB51mzEYiZpGHWgnVEMRoRSMeF9Mb8UAsBk=Jy5BwSVQ@mail.gmail.com>
Message-ID: <8C3E5927-0560-41A4-BAE4-1A04115F5C8B@imperial.ac.uk>

On 26 Apr 2012, at 16:30, Angelina Mukherjee wrote:
> 
> I have 2 patients, with around 20,000 probes each. Each patient has
> observations of gene expression (response) taken from some regions of their
> tissue. Then the next level in the hierarchy of the data is the sub region
> - we have data from several subregions for each region of each patient. So
> I have 3 levels of nesting : subregion within region within patient.
> 
> Here, A, B, C and D correspond to subregions of patient 1 and together they
> comprise Region 1 for the first patient. GHIJ comprise the next and so on.
> In such a situation, is the following the correct syntax for the lmer
> command?
> ( I am considering patient, region and subregion to be random factors. )
> 
> *fit <- lmer(expression ~ 1  + probe + (1|patient)+ (1|patient:region) +
> (1|patient: region: subregion) )*

If each subregion is uniquely identified, so that subregion A can only be associated with patient X, and subregion Z can only be found in patient Y (and similarly, the same is done for regions), I though that

lmer(epression ~ probe + (1|patient) + (1|region) + (1|subregion)) 

would work.  Unique identifiers for the same region in different patients might sound odd at first, but in my experience it works and simplifies the specification of the nesting, which then happens automatically



> 
> The problem is that this encounters the same problem as lme. The whole data
> is of the dimension 20,000 x 22, where 20,000 is the number of probes and
> 22 is the number of samples/arrays.
> 
> Any advice would be very helpful!
> 
> Cheers,
> Angelina
> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From f.calboli at imperial.ac.uk  Thu Apr 26 17:56:30 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 26 Apr 2012 16:56:30 +0100
Subject: [R-sig-ME] Gene expression lme
In-Reply-To: <8C3E5927-0560-41A4-BAE4-1A04115F5C8B@imperial.ac.uk>
References: <CAMFXY1nNsAsvoiqUUrtwP5fnMddZBaFJax69TUfgjh42-whPTw@mail.gmail.com>
	<loom.20120425T002159-783@post.gmane.org>
	<CAMFXY1n2d6V2=2tXw70Vh6P9PE77ddUMSapxEpxrO=d_U9M4jw@mail.gmail.com>
	<CAMFXY1mB51mzEYiZpGHWgnVEMRoRSMeF9Mb8UAsBk=Jy5BwSVQ@mail.gmail.com>
	<8C3E5927-0560-41A4-BAE4-1A04115F5C8B@imperial.ac.uk>
Message-ID: <7764C54D-C4A3-460E-8575-D36D626AE673@imperial.ac.uk>

On 26 Apr 2012, at 16:43, Federico Calboli wrote:

> 
> If each subregion is uniquely identified, so that subregion A can only be associated with patient X, and subregion Z can only be found in patient Y (and similarly, the same is done for regions), I though that
> 
> lmer(epression ~ probe + (1|patient) + (1|region) + (1|subregion)) 
> 
> would work.  Unique identifiers for the same region in different patients might sound odd at first, but in my experience it works and simplifies the specification of the nesting, which then happens automatically

I might have been too fast in my reply.  It occours to me that if you want to have some sort of matching between say, the first region in patient one and the first region in patient 2 my advice above won't work.  It will work if you do not care about such matching though

F




--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From smartpink111 at yahoo.com  Thu Apr 26 20:02:56 2012
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Apr 2012 11:02:56 -0700 (PDT)
Subject: [R-sig-ME] lmer model comparison
Message-ID: <1335463376.3678.YahooMailNeo@web39402.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120426/01ba1a04/attachment.pl>

From armstrong.whit at gmail.com  Fri Apr 27 03:42:23 2012
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 26 Apr 2012 21:42:23 -0400
Subject: [R-sig-ME] MCMCglmm for binomial models? -- updated to use
	rcppbugs
Message-ID: <CAMi=pg4ssP85yE6UMRS92fNhLn3Gs1WxY5DJpSM2nAx8LrybWA@mail.gmail.com>

I know this is an old thread, but since I've just posted the first
version of rcppbugs on CRAN, I thought I'd see if I could convert this
model.

This model is implemented in pure R (no c++ required).  The source
code is posted below.

It runs in about 30s (for 300k burn and 300k iterations) on my
workstation and shows results simiilar to the first post I made back
in 2010.

Sadly, I had to update one of the functions in the package (to allow
for more arguments), so no one will be able to run this code with the
version currently on CRAN.  But probably by Monday, a new version will
be released.

Comments welcome.

-Whit


warmstrong at krypton:~/dvl/scripts/bugs$ Rscript herd.r
Loading required package: Rcpp
Loading required package: methods
Loading required package: RcppArmadillo
Loading required package: Matrix
Loading required package: lattice

Attaching package: ?lme4?

The following object(s) are masked from ?package:stats?:

    AIC, BIC

running rcppbugs model...
runtime:
   user  system elapsed
 27.329   0.024  27.425
b:
[1] -1.472493 -1.279835 -1.327631 -1.928502
b herd:
               [,1]
 [1,]  0.0558199125
 [2,] -0.0812092810
 [3,]  0.0563029683
 [4,] -0.1821773460
 [5,] -0.0192440062
 [6,] -0.0381335848
 [7,]  0.1131237285
 [8,]  0.0770301723
 [9,] -0.0583487056
[10,] -0.0953579466
[11,]  0.0006177299
[12,] -0.0585625319
[13,] -0.1661447844
[14,]  0.0719714339
[15,] -0.1351594312
warmstrong at krypton:~/dvl/scripts/bugs$


source code follows:

library(rcppbugs)
library(lme4)
data(cbpp)

cbpp.incidence <- cbpp[,"incidence"]
n <- cbpp[,"size"]

X <- matrix(0,nrow=nrow(cbpp),ncol=4)
X[1:nrow(X) + (as.integer(cbpp[,"period"]) -1) * nrow(cbpp)] <- 1
X[,1] <- 1.0

herd <- as.integer(cbpp[,"herd"])
NR <- nrow(cbpp)
J <- length(unique(herd))

tau.overdisp <- mcmc.uniform(runif(1),0,100)
overdisp <- mcmc.normal(rnorm(NR),0, tau.overdisp)
b <- mcmc.normal(rnorm(ncol(X)),mu=0,tau=0.0001)
tau.b.herd <- mcmc.uniform(runif(1),0,100)
b.herd <- mcmc.normal(rnorm(J),mu=0,tau=tau.b.herd)
phi <- deterministic(function(X,herd,b,b.herd,overdisp) { 1/(1 +
exp(-(X %*% b + b.herd[herd] + overdisp))) }, X, herd, b, b.herd,
overdisp)
incidence <- mcmc.binomial(cbpp.incidence,n=n,p=phi,observed=TRUE)
m <- create.model(tau.overdisp,overdisp,b,tau.b.herd,b.herd,phi,incidence)

iterations <- 3e5L
burn <- iterations
adapt <- 1e3L
thin <- 10L

cat("running rcppbugs model...\n")
rcppbugs.time <- system.time(ans <- run.model(m,
iterations=iterations, burn=burn, adapt=adapt, thin=thin))
cat("runtime:\n")
print(rcppbugs.time)

cat("b:\n")
print(apply(ans[["b"]],2,mean))

cat("b herd:\n")
print(as.matrix(apply(ans[["b.herd"]],2,mean)))

##cat("overdisp:")
##print(as.matrix(apply(ans[["overdisp"]],2,mean)))



On Tue, Sep 21, 2010 at 4:26 PM, Whit Armstrong
<armstrong.whit at gmail.com> wrote:
> so much for intuition. ?consolidating the b's doesn't make any
> material speed difference, but it does simplify the model code a bit.
>
> btw, this run and the previous post were using 1e6 interations, 1e5
> burn-in, and 50 thin: m.sample(1e6,1e5,50).
>
> -Whit
>
>
> warmstrong at krypton:~/dvl/c++/CppBugs/test$ g++ -I.. -Wall -O2
> herd.fast.cpp -llapack
> warmstrong at krypton:~/dvl/c++/CppBugs/test$ time ./a.out
> samples: 17999
> b:
> ?-1.5077
> ?-1.2344
> ?-1.3518
> ?-1.8819
>
> tau_overdisp: 1.54806
> tau_b_herd: 22.059
> sigma_overdisp: 0.878115
> sigma_b_herd: 0.245386
> b_herd:
> ? 0.1464
> ?-0.0475
> ? 0.0739
> ? 0.0070
> ?-0.0353
> ?-0.0866
> ? 0.1661
> ? 0.0658
> ?-0.0585
> ?-0.0904
> ? 0.0052
> ?-0.0138
> ?-0.1324
> ? 0.0947
> ?-0.0902
>
>
> real ? ?0m21.905s
> user ? ?0m21.880s
> sys ? ? 0m0.020s
> warmstrong at krypton:~/dvl/c++/CppBugs/test$
>
>
> updated code:
> class HerdModel: public MCModel {
> ?const ivec incidence;
> ?const ivec size;
> ?const ivec herd;
> ?const mat fixed;
> ?int N, N_herd;
> ?mat permutation_matrix;
>
> public:
> ?NormalStatic<vec> b;
> ?UniformStatic<double> tau_overdisp;
> ?UniformStatic<double> tau_b_herd;
> ?Deterministic<double> sigma_overdisp;
> ?Deterministic<double> sigma_b_herd;
> ?Normal<vec> b_herd;
> ?Normal<vec> overdisp;
> ?Deterministic<vec> phi;
> ?Binomial<ivec> likelihood;
>
>
> ?HerdModel(const ivec& incidence_,const ivec& size_,const ivec&
> herd_,const mat& fixed_,int N_, int N_herd_):
> ? ?incidence(incidence_),size(size_),herd(herd_),
> ? ?fixed(fixed_),N(N_),N_herd(N_herd_),permutation_matrix(N,N_herd),
> ? ?b(randn<vec>(4),0,0.001),tau_overdisp(1,0,1000),tau_b_herd(1,0,100),
> ? ?sigma_overdisp(1),sigma_b_herd(1),
> ? ?b_herd(randn<vec>(N_herd_)),overdisp(randn<vec>(N)),
> ? ?phi(randu<vec>(N)),
> ? ?likelihood(incidence_,true)
> ?{
> ? ?permutation_matrix.fill(0.0);
> ? ?for(uint i = 0; i < herd.n_elem; i++) {
> ? ? ?permutation_matrix(i,herd[i]) = 1.0;
> ? ?}
> ? ?add(b);
> ? ?add(tau_overdisp);
> ? ?add(tau_b_herd);
> ? ?add(sigma_overdisp);
> ? ?add(sigma_b_herd);
> ? ?add(b_herd);
> ? ?add(overdisp);
> ? ?add(phi);
> ? ?add(likelihood);
> ?}
>
> ?void update() {
> ? ?phi.value = fixed*b.value + sum(permutation_matrix*b_herd.value,1)
> + overdisp.value;
> ? ?phi.value = 1/(1+exp(-phi.value));
> ? ?sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
> ? ?sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
> ?}
> ?double logp() const {
> ? ?return b.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
> b_herd.logp(0, tau_b_herd.value) +
> ? ? ?overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
> ?}
> };
>
>
>
> On Tue, Sep 21, 2010 at 3:41 PM, Whit Armstrong
> <armstrong.whit at gmail.com> wrote:
>> Bob,
>>
>> Just wanted to post the results from my project. ?It is still very
>> much alpha quality software, but the speed is good. ?Your sample model
>> runs in 22secs on my workstation. ?I ran the model in JAGS earlier but
>> it took ages (20min or so).
>>
>> These are my results which are closer to the MCMCglmm run than the
>> WinBUGS run. ?Eventually, I'll try to make it easy to run these models
>> directly from R.
>>
>> The full code for this model is posted in-line below. ?However, the
>> guts are just two functions which just separate the winbugs model into
>> separate "update" and "logp" functions:
>>
>> ?void update() {
>> ? ?phi.value = b0.value + b_period2.value*period2 +
>> b_period3.value*period3 + b_period4.value*period4 +
>> sum(permutation_matrix*b_herd.value,1) + overdisp.value;
>> ? ?phi.value = 1/(1+exp(-phi.value));
>> ? ?sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
>> ? ?sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
>> ?}
>> ?double logp() const {
>> ? ?return b0.logp() + b_period2.logp() + b_period3.logp() +
>> b_period4.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
>> b_herd.logp(0, tau_b_herd.value) +
>> ? ? ?overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
>> ?}
>>
>> The speed of the model could probably be improved by consolidating all
>> the b's into a vector. ?I'll try that later on. ?Code for this model,
>> and some other examples will go up on github sometime in the near
>> future.
>>
>> I've also cc'd Chris Fonnesbeck, since he may want to chime in on the
>> pymc front. ?I haven't had time to code up an equivalent pymc model,
>> but it should be very easy to do.
>>
>> Feedback welcome.
>>
>> -Whit
>>
>>
>> results:
>> warmstrong at krypton:~/dvl/c++/CppBugs/test$ time ./a.out
>> samples: 17999
>> b0: -1.52515
>> b_period2: -1.21971
>> b_period3: -1.32685
>> b_period4: -1.88475
>> tau_overdisp: 1.59118
>> tau_b_herd: 25.9476
>> sigma_overdisp: 0.886191
>> sigma_b_herd: 0.258111
>> b_herd:
>> ? 0.1623
>> ?-0.0524
>> ? 0.0852
>> ? 0.0080
>> ?-0.0506
>> ?-0.0953
>> ? 0.1859
>> ? 0.0835
>> ?-0.0690
>> ?-0.0897
>> ? 0.0096
>> ?-0.0183
>> ?-0.1496
>> ? 0.1133
>> ?-0.1061
>>
>>
>> real ? ?0m21.930s
>> user ? ?0m21.920s
>> sys ? ? 0m0.000s
>> warmstrong at krypton:~/dvl/c++/CppBugs/test$
>>
>>
>> model code:
>> class HerdModel: public MCModel {
>> ?const ivec incidence;
>> ?const ivec size;
>> ?const ivec herd;
>> ?const vec period2;
>> ?const vec period3;
>> ?const vec period4;
>> ?int N, N_herd;
>> ?mat permutation_matrix;
>>
>> public:
>> ?NormalStatic<double> b0;
>> ?NormalStatic<double> b_period2;
>> ?NormalStatic<double> b_period3;
>> ?NormalStatic<double> b_period4;
>> ?UniformStatic<double> tau_overdisp;
>> ?UniformStatic<double> tau_b_herd;
>> ?Deterministic<double> sigma_overdisp;
>> ?Deterministic<double> sigma_b_herd;
>> ?Normal<vec> b_herd;
>> ?Normal<vec> overdisp;
>> ?Deterministic<vec> phi;
>> ?Binomial<ivec> likelihood;
>>
>>
>> ?HerdModel(const ivec& incidence_,const ivec& size_,const ivec& herd_,
>> ? ? ? ? ? ?const vec& period2_,const vec& period3_,const vec&
>> period4_, int N_, int N_herd_):
>> ? ?incidence(incidence_),size(size_),herd(herd_),
>> ? ?period2(period2_),period3(period3_),period4(period4_),
>> ? ?N(N_),N_herd(N_herd_),permutation_matrix(N,N_herd),
>> ? ?b0(0,0,0.001),b_period2(0,0,0.001),b_period3(0,0,0.001),b_period4(0,0,0.001),
>> ? ?tau_overdisp(1,0,1000),tau_b_herd(1,0,100),
>> ? ?sigma_overdisp(1),sigma_b_herd(1),
>> ? ?b_herd(randn<vec>(N_herd_)),overdisp(randn<vec>(N)),
>> ? ?phi(randu<vec>(N)),
>> ? ?likelihood(incidence_,true)
>> ?{
>> ? ?permutation_matrix.fill(0.0);
>> ? ?for(uint i = 0; i < herd.n_elem; i++) {
>> ? ? ?permutation_matrix(i,herd[i]) = 1.0;
>> ? ?}
>> ? ?add(b0);
>> ? ?add(b_period2);
>> ? ?add(b_period3);
>> ? ?add(b_period4);
>> ? ?add(tau_overdisp);
>> ? ?add(tau_b_herd);
>> ? ?add(sigma_overdisp);
>> ? ?add(sigma_b_herd);
>> ? ?add(b_herd);
>> ? ?add(overdisp);
>> ? ?add(phi);
>> ? ?add(likelihood);
>> ?}
>>
>> ?void update() {
>> ? ?phi.value = b0.value + b_period2.value*period2 +
>> b_period3.value*period3 + b_period4.value*period4 +
>> sum(permutation_matrix*b_herd.value,1) + overdisp.value;
>> ? ?phi.value = 1/(1+exp(-phi.value));
>> ? ?sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
>> ? ?sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
>> ?}
>> ?double logp() const {
>> ? ?return b0.logp() + b_period2.logp() + b_period3.logp() +
>> b_period4.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
>> b_herd.logp(0, tau_b_herd.value) +
>> ? ? ?overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
>> ?}
>> };
>>
>>
>>
>> On Mon, Sep 20, 2010 at 5:47 PM, Bob Farmer <farmerb at gmail.com> wrote:
>>> Thanks for the further detail. ?I wasn't familiar with these two
>>> methods of overdispersion; I think I only understood them in the
>>> WinBUGS sense, which, I believe, is additive (e.g. overdisp[i] as a
>>> parameter). ?I'll have to explore the family() helpfiles a bit more.
>>>
>>> Below is a summary of the model outputs from the three methods
>>> described earlier. ?Note that here, I bumped the WinBUGS iterations to
>>> 750E3 to reduce the Rhats a bit further.
>>> I also use an adaptation of the bugsParallel function to make my
>>> WinBUGS runs 3x faster (time for this run: ?5.8 minutes); I can
>>> provide details if anybody else would like to use this function (and
>>> some other bugs summary functions I've written).
>>> Hope this is useful or interesting -- I appreciate this discussion!
>>>
>>> --Bob
>>>
>>> **glmer**
>>>> summary(gm3)@coefs
>>> ? ? ? ? ? ? ?Estimate Std. Error ? t value
>>> (Intercept) -1.3985351 0.01698321 -82.34810
>>> period2 ? ? -0.9923347 0.02275838 -43.60304
>>> period3 ? ? -1.1286754 0.02429833 -46.45075
>>> period4 ? ? -1.5803739 0.03195596 -49.45474
>>>
>>> **MCMCglmm**
>>>> summary(mc3)
>>> ?Iterations = 749351
>>> ?Thinning interval ?= 100001
>>> ?Sample size ?= 1000
>>> ?DIC: 539.7889
>>> ?G-structure: ?~herd
>>> ? ? post.mean ?l-95% CI u-95% CI eff.samp
>>> herd ? ?0.2894 1.309e-06 ? ?1.035 ? ? 1000
>>> ?R-structure: ?~units
>>> ? ? ?post.mean l-95% CI u-95% CI eff.samp
>>> units ? ? ?0.93 0.003825 ? ? 1.98 ? ? 1000
>>> ?Location effects: cbind(incidence, size - incidence) ~ period
>>> ? ? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp ?pMCMC
>>> (Intercept) ? -1.5263 ?-2.2221 ?-0.9602 ? 1000.0 <0.001 ***
>>> period2 ? ? ? -1.2407 ?-2.2072 ?-0.2449 ? ?947.2 ?0.012 *
>>> period3 ? ? ? -1.3574 ?-2.4534 ?-0.3472 ? 1000.0 ?0.012 *
>>> period4 ? ? ? -1.9126 ?-3.2662 ?-0.8298 ? 1136.0 ?0.002 **
>>>
>>> **WinBUGS**
>>>> bug3$summary[which(rownames(bug3$summary) %in% params), c("mean", "sd", "2.5%", "97.5%", "Rhat", "n.eff")]
>>> ? ? ? ? ? ? ? ? ? ? mean ? ? ? ?sd ? ? ? ?2.5% ? ? ?97.5% ? ? Rhat n.eff
>>> B.0 ? ? ? ? ? ?-1.6070301 0.3556674 -2.33980000 -0.9947425 1.039548 ? ?69
>>> B.period2 ? ? ?-1.2761798 0.4895902 -2.14292500 -0.2391200 1.018612 ? 210
>>> B.period3 ? ? ?-1.5100405 0.6337780 -2.63680000 -0.2266425 1.123427 ? ?22
>>> B.period4 ? ? ?-2.0678331 0.6539004 -3.31892500 -0.8586700 1.018622 ? 270
>>> sigma.overdisp ?1.1975969 0.3147531 ?0.69358404 ?1.8740000 1.045062 ? ?55
>>> sigma.b.herd ? ?0.5120043 0.3825848 ?0.01658429 ?1.3659249 1.542432 ? ? 7
>>> (note that I can provide a link to parameter histograms, if you want
>>> more detail)
>>>
>>> --Bob
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>


From chris at trickysolutions.com.au  Fri Apr 27 05:32:23 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 27 Apr 2012 13:32:23 +1000
Subject: [R-sig-ME] Comparison of predictors in lme4
In-Reply-To: <CACm_P7r7_sWv6UkRe-TKou=LSoPK7cwMQVePLt=HKzr5nuXGaA@mail.gmail.com>
References: <CACm_P7qFNdH84=61dt-B08Dk57UjWeQgci4T-_WE_4m6nNczgA@mail.gmail.com>
	<1416490043590576948@unknownmsgid>
	<CACm_P7r7_sWv6UkRe-TKou=LSoPK7cwMQVePLt=HKzr5nuXGaA@mail.gmail.com>
Message-ID: <-3785881897811067910@unknownmsgid>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120427/f1c26f02/attachment.pl>

From angelina.mukherjee88 at gmail.com  Fri Apr 27 11:11:00 2012
From: angelina.mukherjee88 at gmail.com (Angelina Mukherjee)
Date: Fri, 27 Apr 2012 10:11:00 +0100
Subject: [R-sig-ME] Gene expression lme
In-Reply-To: <7764C54D-C4A3-460E-8575-D36D626AE673@imperial.ac.uk>
References: <CAMFXY1nNsAsvoiqUUrtwP5fnMddZBaFJax69TUfgjh42-whPTw@mail.gmail.com>
	<loom.20120425T002159-783@post.gmane.org>
	<CAMFXY1n2d6V2=2tXw70Vh6P9PE77ddUMSapxEpxrO=d_U9M4jw@mail.gmail.com>
	<CAMFXY1mB51mzEYiZpGHWgnVEMRoRSMeF9Mb8UAsBk=Jy5BwSVQ@mail.gmail.com>
	<8C3E5927-0560-41A4-BAE4-1A04115F5C8B@imperial.ac.uk>
	<7764C54D-C4A3-460E-8575-D36D626AE673@imperial.ac.uk>
Message-ID: <CAMFXY1kMfyTx=SvK6fPetCQ_u2yX-GbdUK26QZf5q1QDROgTDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120427/03951795/attachment.pl>

From c.decat at leeds.ac.uk  Fri Apr 27 14:19:12 2012
From: c.decat at leeds.ac.uk (Cecile De Cat)
Date: Fri, 27 Apr 2012 13:19:12 +0100
Subject: [R-sig-ME] lmer model evaluation vs fixed-effect significance
Message-ID: <CAFYxgOB+_D8hvw5yQj10u01F1GwEMaa78UCJ7owEFY76QCuprw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120427/445fe283/attachment.pl>

From bbolker at gmail.com  Fri Apr 27 16:00:57 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 27 Apr 2012 14:00:57 +0000 (UTC)
Subject: [R-sig-ME] plot glmmPQL
References: <CA+avhtgNnEcM7APtLVMDbP6odm7k3mVuY62qHUvZVVnuKD=A2Q@mail.gmail.com>
Message-ID: <loom.20120427T152915-121@post.gmane.org>

Mario V. Balzan <m.balzan at ...> writes:

> 
> Dear all,
> 
> I am investigating the influence of some experimental treatments
> (A,B,C,...) on fecundity of a lepidoptera. These data have been
> collected over time from different experimental plots (A1, A2, ... ).
> I am using glmmPQL function with quasipoisson errors since these are
> count data and with overdispersion.
> 
> the model which I came up with is as follows:
> glmmPQL(Fecundity~Treatment,random=~Time|Plot, family="quasipoisson")
> 
> I would like to plot a curve of fecundity against time for each
> treatment from this model. Is that possible? Would appreciate if
> someone could help me out with this.
> 

  [snip]

  It sounds a lot like you want a fixed effect of Treatment+Time,
or possibly even Treatment*Time. It is odd (although not absolutely
impossible) to consider a model where there is no overall effect of
time (i.e. the mean time trajectory across plots is *exactly* zero)
but there is variation in the time effect across plot.

  If you fit Treatment+Time (an additive model), then the expected
time effects are the same for each treatment.  If you fit Treatment*Time
then they differ.  
  Probably the most straightforward way to do this is just to pick
out the relevant coefficients from your model, compute
(intercept)+(slope)*time for each treatment, and then exponentiate
(since you are using the default log link for the quasipoisson).
Alternatively, you can use the 'predict' method for glmmPQL to
generate predictions (use expand.grid() to create a full data frame
of combinations of times and treatments, then apply your model
to it with predict())


From smartpink111 at yahoo.com  Sat Apr 28 00:34:33 2012
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Apr 2012 15:34:33 -0700 (PDT)
Subject: [R-sig-ME] Correlation of random effects in lmer
Message-ID: <1335566073.77668.YahooMailNeo@web39403.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120427/defdb58b/attachment.pl>

From bbolker at gmail.com  Sat Apr 28 04:39:33 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 28 Apr 2012 02:39:33 +0000 (UTC)
Subject: [R-sig-ME] Correlation of random effects in lmer
References: <1335566073.77668.YahooMailNeo@web39403.mail.mud.yahoo.com>
Message-ID: <loom.20120428T040207-435@post.gmane.org>

arun <smartpink111 at ...> writes:

> I am testing a couple of logistic regression longitudinal models
> using lmer. ?I got stuck in a position where I found that the
> correlation between random effects is 1.00 (intercept and slope
> -model with one term for the same grouping factor), while the
> std. deviation is very low for the slope. ?Then, I tested another
> model with more than one term for the same grouping factor. ?The LRT
> test p value is not significant. ?Is it okay to keep the second
> model in this case?

  I'm not sure I agree with your terminology here -- there are really
two terms in both the (1+time|subject) model and the (1|subject) +
(0+time|subject) model, they are just forced to be independent in the
second case while the first case allows them to be correlated.

> Random effects:
> ?Groups ?Name ? ? ? ?Variance ? Std.Dev. Corr ?
> ?resid ? (Intercept) 10.9575146 3.310214 ? ? ??
> ?Subject (Intercept) ?0.8220584 0.906674 ? ? ??
> ? ? ? ? ?time ? ? ? ? 0.0041092 0.064103 1.000?
> Number of obs: 392, groups: resid, 392; Subject, 25
> 
> > anova(fm2_BDat,fm1_BDat)
> Data: Behavdat
> Models:
> fm2_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 | resid) +?
> fm2_BDat: ? ? (1 | Subject_BDat) + (0 + time | Subject_BDat)
> fm1_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 | resid) +?
> fm1_BDat: ? ? (1 + time | Subject_BDat)
> ? ? ? ? ?Df ? ?AIC ? ?BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
> fm2_BDat 15 754.30 813.87 -362.15 ? ? ? ? ? ? ? ? ? ? ? ??
> fm1_BDat 16 754.24 817.78 -361.12 2.0564 ? ? ?1 ? ? 0.1516

  This is a very common situation, and a bit of a tough call (I
haven't seen much in the way of formal, rigorously tested guidance for
this situation.)  What glmer is telling you is essentially that you
really don't have enough data to fit two separate random effects
((intercept):Subject and time:Subject), so the fit is collapsing
onto a linear combination of the two.  Your second model (fm2_BDat)
is enforcing a zero correlation between the two random effects: I would
not be surprised if the variance of one of the two were very close
to zero (although you haven't shown us that).

  I will give several (conflicting) arguments here, I would be
interested to hear what others have to say:

  1. You have no _a priori_ way of knowing that the correlation
*is* exactly zero (if you had enough data, you would almost certainly
find that there was a non-zero correlation between these terms);
you shouldn't be doing 'sacrificial' or stepwise removal of terms.
Keep the more complex model.

  2. You should be trying to select the 'minimal adequate' model; in
particular, overfitting the model (including zero and/or perfectly
correlated terms) is more likely to lead to numeric problems, so it's
better to try to reduce the model until all the terms can be uniquely
estimated.  (This is the approach suggested in Bolker et al 2008
_Trends in Ecology and Evolution_)

 3.  AIC (which is looking for the best *predictive* model) very
slightly favors the model with correlation, although it's almost a
wash; if you were finding model-averaged predictions, they would be
nearly a 50/50 mixture of the predictions from the two models.

 4. BIC (which is looking for the "true" model, i.e. identifying the
correct dimensionality) favors the simpler (no-correlation) model.

 5. If you are most interested in inference on the fixed-effect terms,
I doubt it matters -- my guess is that these two models give nearly
identical fixed-effect estimates.

  As long as you decide what to do in a principled way (which
approach seems to best fit the analysis you want to do?) rather
than by selecting the one that gives you the answers you like
best, I think either model is defensible.


From A.Robinson at ms.unimelb.edu.au  Sat Apr 28 05:27:52 2012
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 28 Apr 2012 13:27:52 +1000
Subject: [R-sig-ME] Correlation of random effects in lmer
In-Reply-To: <loom.20120428T040207-435@post.gmane.org>
References: <1335566073.77668.YahooMailNeo@web39403.mail.mud.yahoo.com>
	<loom.20120428T040207-435@post.gmane.org>
Message-ID: <20120428032752.GN934@ms.unimelb.edu.au>

I wonder if the data have been scaled?  Try transforming all numeric
predictors to have zero mean and unit variance before fitting.

Cheers

Andrew

On Sat, Apr 28, 2012 at 02:39:33AM +0000, Ben Bolker wrote:
> arun <smartpink111 at ...> writes:
> 
> > I am testing a couple of logistic regression longitudinal models
> > using lmer. ?I got stuck in a position where I found that the
> > correlation between random effects is 1.00 (intercept and slope
> > -model with one term for the same grouping factor), while the
> > std. deviation is very low for the slope. ?Then, I tested another
> > model with more than one term for the same grouping factor. ?The LRT
> > test p value is not significant. ?Is it okay to keep the second
> > model in this case?
> 
>   I'm not sure I agree with your terminology here -- there are really
> two terms in both the (1+time|subject) model and the (1|subject) +
> (0+time|subject) model, they are just forced to be independent in the
> second case while the first case allows them to be correlated.
> 
> > Random effects:
> > ?Groups ?Name ? ? ? ?Variance ? Std.Dev. Corr ?
> > ?resid ? (Intercept) 10.9575146 3.310214 ? ? ??
> > ?Subject (Intercept) ?0.8220584 0.906674 ? ? ??
> > ? ? ? ? ?time ? ? ? ? 0.0041092 0.064103 1.000?
> > Number of obs: 392, groups: resid, 392; Subject, 25
> > 
> > > anova(fm2_BDat,fm1_BDat)
> > Data: Behavdat
> > Models:
> > fm2_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 | resid) +?
> > fm2_BDat: ? ? (1 | Subject_BDat) + (0 + time | Subject_BDat)
> > fm1_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 | resid) +?
> > fm1_BDat: ? ? (1 + time | Subject_BDat)
> > ? ? ? ? ?Df ? ?AIC ? ?BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
> > fm2_BDat 15 754.30 813.87 -362.15 ? ? ? ? ? ? ? ? ? ? ? ??
> > fm1_BDat 16 754.24 817.78 -361.12 2.0564 ? ? ?1 ? ? 0.1516
> 
>   This is a very common situation, and a bit of a tough call (I
> haven't seen much in the way of formal, rigorously tested guidance for
> this situation.)  What glmer is telling you is essentially that you
> really don't have enough data to fit two separate random effects
> ((intercept):Subject and time:Subject), so the fit is collapsing
> onto a linear combination of the two.  Your second model (fm2_BDat)
> is enforcing a zero correlation between the two random effects: I would
> not be surprised if the variance of one of the two were very close
> to zero (although you haven't shown us that).
> 
>   I will give several (conflicting) arguments here, I would be
> interested to hear what others have to say:
> 
>   1. You have no _a priori_ way of knowing that the correlation
> *is* exactly zero (if you had enough data, you would almost certainly
> find that there was a non-zero correlation between these terms);
> you shouldn't be doing 'sacrificial' or stepwise removal of terms.
> Keep the more complex model.
> 
>   2. You should be trying to select the 'minimal adequate' model; in
> particular, overfitting the model (including zero and/or perfectly
> correlated terms) is more likely to lead to numeric problems, so it's
> better to try to reduce the model until all the terms can be uniquely
> estimated.  (This is the approach suggested in Bolker et al 2008
> _Trends in Ecology and Evolution_)
> 
>  3.  AIC (which is looking for the best *predictive* model) very
> slightly favors the model with correlation, although it's almost a
> wash; if you were finding model-averaged predictions, they would be
> nearly a 50/50 mixture of the predictions from the two models.
> 
>  4. BIC (which is looking for the "true" model, i.e. identifying the
> correct dimensionality) favors the simpler (no-correlation) model.
> 
>  5. If you are most interested in inference on the fixed-effect terms,
> I doubt it matters -- my guess is that these two models give nearly
> identical fixed-effect estimates.
> 
>   As long as you decide what to do in a principled way (which
> approach seems to best fit the analysis you want to do?) rather
> than by selecting the one that gives you the answers you like
> best, I think either model is defensible.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/


From smartpink111 at yahoo.com  Sat Apr 28 06:00:17 2012
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Apr 2012 21:00:17 -0700 (PDT)
Subject: [R-sig-ME] Correlation of random effects in lmer
In-Reply-To: <20120428032752.GN934@ms.unimelb.edu.au>
References: <1335566073.77668.YahooMailNeo@web39403.mail.mud.yahoo.com>
	<loom.20120428T040207-435@post.gmane.org>
	<20120428032752.GN934@ms.unimelb.edu.au>
Message-ID: <1335585617.66335.YahooMailNeo@web39404.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120427/e82710b6/attachment.pl>

From bbolker at gmail.com  Sat Apr 28 16:29:59 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 28 Apr 2012 10:29:59 -0400
Subject: [R-sig-ME] Correlation of random effects in lmer
In-Reply-To: <4F9B5FDF.5040203@gmail.com>
References: <1335566073.77668.YahooMailNeo@web39403.mail.mud.yahoo.com>
	<loom.20120428T040207-435@post.gmane.org>
	<4F9B5FDF.5040203@gmail.com>
Message-ID: <4F9BFEE7.30009@gmail.com>

On 12-04-27 11:11 PM, R. Scott Davidson wrote:
> I don't have an answer to the question posed but isn't there a problem
> with using either AIC or BIC to select between models with different
> random effects?  The -2lnl for both models is virtually the same so any
> difference in scores will be due to the penalty term for the number of
> parameters (esp as the fixed parameters are the same).  If you're going
> to use either AIC or BIC to select between the two models with different
> random effect structures shouldn't the "actual" number of parameters for
> the random effects be estimated as described in the Vaida and Blanchard
> 2005 paper?  I guess it will come down to how the number of parameters
> for the random effects is counted?
> 
> Cheers
> Scott

  [taking the liberty of cc'ing this back to the list]

  Yes, fair enough.  This is going to be pretty slippery in any case.

  One thing to keep in mind is that the Vaida and Blanchard
conditional-AIC approach is appropriate when you want to maximize
predictive accuracy at the *individual* (subject) level; if you want to
maximize predictive accuracy at the population level it is generally
more appropriate to count parameters in a more naive way, essentially
counting the number of 'theta' (variance and covariance) parameters. See
"How do I count the number of degrees of freedom for a random effect?"
in http://glmm.wikidot.com/faq ...


> 
> 
> On 4/28/2012 14:39, Ben Bolker wrote:
>> arun<smartpink111 at ...>  writes:
>>
>>> I am testing a couple of logistic regression longitudinal models
>>> using lmer.  I got stuck in a position where I found that the
>>> correlation between random effects is 1.00 (intercept and slope
>>> -model with one term for the same grouping factor), while the
>>> std. deviation is very low for the slope.  Then, I tested another
>>> model with more than one term for the same grouping factor.  The LRT
>>> test p value is not significant.  Is it okay to keep the second
>>> model in this case?
>>    I'm not sure I agree with your terminology here -- there are really
>> two terms in both the (1+time|subject) model and the (1|subject) +
>> (0+time|subject) model, they are just forced to be independent in the
>> second case while the first case allows them to be correlated.
>>
>>> Random effects:
>>>   Groups  Name        Variance   Std.Dev. Corr    resid   (Intercept)
>>> 10.9575146 3.310214         Subject (Intercept)  0.8220584
>>> 0.906674                 time         0.0041092 0.064103 1.000 Number
>>> of obs: 392, groups: resid, 392; Subject, 25
>>>
>>>> anova(fm2_BDat,fm1_BDat)
>>> Data: Behavdat
>>> Models:
>>> fm2_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 |
>>> resid) + fm2_BDat:     (1 | Subject_BDat) + (0 + time | Subject_BDat)
>>> fm1_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 |
>>> resid) + fm1_BDat:     (1 + time | Subject_BDat)
>>>           Df    AIC    BIC  logLik  Chisq Chi Df Pr(>Chisq)
>>> fm2_BDat 15 754.30 813.87 -362.15                         fm1_BDat 16
>>> 754.24 817.78 -361.12 2.0564      1     0.1516
>>    This is a very common situation, and a bit of a tough call (I
>> haven't seen much in the way of formal, rigorously tested guidance for
>> this situation.)  What glmer is telling you is essentially that you
>> really don't have enough data to fit two separate random effects
>> ((intercept):Subject and time:Subject), so the fit is collapsing
>> onto a linear combination of the two.  Your second model (fm2_BDat)
>> is enforcing a zero correlation between the two random effects: I would
>> not be surprised if the variance of one of the two were very close
>> to zero (although you haven't shown us that).
>>
>>    I will give several (conflicting) arguments here, I would be
>> interested to hear what others have to say:
>>
>>    1. You have no _a priori_ way of knowing that the correlation
>> *is* exactly zero (if you had enough data, you would almost certainly
>> find that there was a non-zero correlation between these terms);
>> you shouldn't be doing 'sacrificial' or stepwise removal of terms.
>> Keep the more complex model.
>>
>>    2. You should be trying to select the 'minimal adequate' model; in
>> particular, overfitting the model (including zero and/or perfectly
>> correlated terms) is more likely to lead to numeric problems, so it's
>> better to try to reduce the model until all the terms can be uniquely
>> estimated.  (This is the approach suggested in Bolker et al 2008
>> _Trends in Ecology and Evolution_)
>>
>>   3.  AIC (which is looking for the best *predictive* model) very
>> slightly favors the model with correlation, although it's almost a
>> wash; if you were finding model-averaged predictions, they would be
>> nearly a 50/50 mixture of the predictions from the two models.
>>
>>   4. BIC (which is looking for the "true" model, i.e. identifying the
>> correct dimensionality) favors the simpler (no-correlation) model.
>>
>>   5. If you are most interested in inference on the fixed-effect terms,
>> I doubt it matters -- my guess is that these two models give nearly
>> identical fixed-effect estimates.
>>
>>    As long as you decide what to do in a principled way (which
>> approach seems to best fit the analysis you want to do?) rather
>> than by selecting the one that gives you the answers you like
>> best, I think either model is defensible.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From m.balzan at sssup.it  Sat Apr 28 16:55:26 2012
From: m.balzan at sssup.it (Mario V. Balzan)
Date: Sat, 28 Apr 2012 16:55:26 +0200
Subject: [R-sig-ME] plot glmmPQL
In-Reply-To: <CA+avhtik=+Jn0SsMxNCygQkwTqRy4M6sBK5qHbchX5ikSNjSuA@mail.gmail.com>
References: <CA+avhtik=+Jn0SsMxNCygQkwTqRy4M6sBK5qHbchX5ikSNjSuA@mail.gmail.com>
Message-ID: <CA+avhtiHvTO0=YFWhCMHwkKzcsyzKD4L9myVTWcCsXYNNHoWtg@mail.gmail.com>

Many thanks for your reply.
Indeed, I do need time as a fixed effect as treatment does have an
influence across the temporal period. By referring to your
instructions, I managed to plot the model.


From rsdavidson99 at gmail.com  Sun Apr 29 01:27:01 2012
From: rsdavidson99 at gmail.com (R. Scott Davidson)
Date: Sun, 29 Apr 2012 11:27:01 +1200
Subject: [R-sig-ME] Correlation of random effects in lmer
In-Reply-To: <4F9BFEE7.30009@gmail.com>
References: <1335566073.77668.YahooMailNeo@web39403.mail.mud.yahoo.com>
	<loom.20120428T040207-435@post.gmane.org>
	<4F9B5FDF.5040203@gmail.com> <4F9BFEE7.30009@gmail.com>
Message-ID: <4F9C7CC5.3040208@gmail.com>

My understanding was that because of the issues with counting degrees of 
freedom if the focus was on the population level then it was better to 
identify the most appropriate random effect model (given structure of 
the data, etc) and then to use that for the model selection while 
varying the fixed effects (the final paragraph in your initial response).

I guess I would ask, in a wider context, if you're looking at 
identifying the best predictive model for the population is it 
reasonable to use AIC (or BIC) to select between models with different 
random effects, or is it better to select one random effect model and to 
then do model selection using that?

Cheers
Scott

On 4/29/2012 02:29, Ben Bolker wrote:
> On 12-04-27 11:11 PM, R. Scott Davidson wrote:
>> I don't have an answer to the question posed but isn't there a problem
>> with using either AIC or BIC to select between models with different
>> random effects?  The -2lnl for both models is virtually the same so any
>> difference in scores will be due to the penalty term for the number of
>> parameters (esp as the fixed parameters are the same).  If you're going
>> to use either AIC or BIC to select between the two models with different
>> random effect structures shouldn't the "actual" number of parameters for
>> the random effects be estimated as described in the Vaida and Blanchard
>> 2005 paper?  I guess it will come down to how the number of parameters
>> for the random effects is counted?
>>
>> Cheers
>> Scott
>    [taking the liberty of cc'ing this back to the list]
>
>    Yes, fair enough.  This is going to be pretty slippery in any case.
>
>    One thing to keep in mind is that the Vaida and Blanchard
> conditional-AIC approach is appropriate when you want to maximize
> predictive accuracy at the *individual* (subject) level; if you want to
> maximize predictive accuracy at the population level it is generally
> more appropriate to count parameters in a more naive way, essentially
> counting the number of 'theta' (variance and covariance) parameters. See
> "How do I count the number of degrees of freedom for a random effect?"
> in http://glmm.wikidot.com/faq ...
>
>
>>
>> On 4/28/2012 14:39, Ben Bolker wrote:
>>> arun<smartpink111 at ...>   writes:
>>>
>>>> I am testing a couple of logistic regression longitudinal models
>>>> using lmer.  I got stuck in a position where I found that the
>>>> correlation between random effects is 1.00 (intercept and slope
>>>> -model with one term for the same grouping factor), while the
>>>> std. deviation is very low for the slope.  Then, I tested another
>>>> model with more than one term for the same grouping factor.  The LRT
>>>> test p value is not significant.  Is it okay to keep the second
>>>> model in this case?
>>>     I'm not sure I agree with your terminology here -- there are really
>>> two terms in both the (1+time|subject) model and the (1|subject) +
>>> (0+time|subject) model, they are just forced to be independent in the
>>> second case while the first case allows them to be correlated.
>>>
>>>> Random effects:
>>>>    Groups  Name        Variance   Std.Dev. Corr    resid   (Intercept)
>>>> 10.9575146 3.310214         Subject (Intercept)  0.8220584
>>>> 0.906674                 time         0.0041092 0.064103 1.000 Number
>>>> of obs: 392, groups: resid, 392; Subject, 25
>>>>
>>>>> anova(fm2_BDat,fm1_BDat)
>>>> Data: Behavdat
>>>> Models:
>>>> fm2_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 |
>>>> resid) + fm2_BDat:     (1 | Subject_BDat) + (0 + time | Subject_BDat)
>>>> fm1_BDat: Response3 ~ 1 + Wavelength * Start_Resp * time + (1 |
>>>> resid) + fm1_BDat:     (1 + time | Subject_BDat)
>>>>            Df    AIC    BIC  logLik  Chisq Chi Df Pr(>Chisq)
>>>> fm2_BDat 15 754.30 813.87 -362.15                         fm1_BDat 16
>>>> 754.24 817.78 -361.12 2.0564      1     0.1516
>>>     This is a very common situation, and a bit of a tough call (I
>>> haven't seen much in the way of formal, rigorously tested guidance for
>>> this situation.)  What glmer is telling you is essentially that you
>>> really don't have enough data to fit two separate random effects
>>> ((intercept):Subject and time:Subject), so the fit is collapsing
>>> onto a linear combination of the two.  Your second model (fm2_BDat)
>>> is enforcing a zero correlation between the two random effects: I would
>>> not be surprised if the variance of one of the two were very close
>>> to zero (although you haven't shown us that).
>>>
>>>     I will give several (conflicting) arguments here, I would be
>>> interested to hear what others have to say:
>>>
>>>     1. You have no _a priori_ way of knowing that the correlation
>>> *is* exactly zero (if you had enough data, you would almost certainly
>>> find that there was a non-zero correlation between these terms);
>>> you shouldn't be doing 'sacrificial' or stepwise removal of terms.
>>> Keep the more complex model.
>>>
>>>     2. You should be trying to select the 'minimal adequate' model; in
>>> particular, overfitting the model (including zero and/or perfectly
>>> correlated terms) is more likely to lead to numeric problems, so it's
>>> better to try to reduce the model until all the terms can be uniquely
>>> estimated.  (This is the approach suggested in Bolker et al 2008
>>> _Trends in Ecology and Evolution_)
>>>
>>>    3.  AIC (which is looking for the best *predictive* model) very
>>> slightly favors the model with correlation, although it's almost a
>>> wash; if you were finding model-averaged predictions, they would be
>>> nearly a 50/50 mixture of the predictions from the two models.
>>>
>>>    4. BIC (which is looking for the "true" model, i.e. identifying the
>>> correct dimensionality) favors the simpler (no-correlation) model.
>>>
>>>    5. If you are most interested in inference on the fixed-effect terms,
>>> I doubt it matters -- my guess is that these two models give nearly
>>> identical fixed-effect estimates.
>>>
>>>     As long as you decide what to do in a principled way (which
>>> approach seems to best fit the analysis you want to do?) rather
>>> than by selecting the one that gives you the answers you like
>>> best, I think either model is defensible.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From smartpink111 at yahoo.com  Sun Apr 29 10:57:30 2012
From: smartpink111 at yahoo.com (arun)
Date: Sun, 29 Apr 2012 01:57:30 -0700 (PDT)
Subject: [R-sig-ME] Correlation of random effects in lmer
In-Reply-To: <4F9C7CC5.3040208@gmail.com>
References: <1335566073.77668.YahooMailNeo@web39403.mail.mud.yahoo.com>
	<loom.20120428T040207-435@post.gmane.org>
	<4F9B5FDF.5040203@gmail.com> <4F9BFEE7.30009@gmail.com>
	<4F9C7CC5.3040208@gmail.com>
Message-ID: <1335689850.22681.YahooMailNeo@web39402.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120429/5ee2b1c4/attachment.pl>

From smartpink111 at yahoo.com  Sun Apr 29 20:27:06 2012
From: smartpink111 at yahoo.com (arun)
Date: Sun, 29 Apr 2012 11:27:06 -0700 (PDT)
Subject: [R-sig-ME] Xy plot help
Message-ID: <1335724026.17943.YahooMailNeo@web39401.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120429/e38ac7f0/attachment.pl>

From Hugo.Mildenberger at web.de  Sun Apr 29 20:58:42 2012
From: Hugo.Mildenberger at web.de (Hugo.Mildenberger at web.de)
Date: Sun, 29 Apr 2012 20:58:42 +0200
Subject: [R-sig-ME] Xy plot help
In-Reply-To: <1335724026.17943.YahooMailNeo@web39401.mail.mud.yahoo.com>
References: <1335724026.17943.YahooMailNeo@web39401.mail.mud.yahoo.com>
Message-ID: <20120429205842.98c0bd9a.hm@zotac.lan>

On Sun, 29 Apr 2012 11:27:06 -0700 (PDT)

arun <smartpink111 at yahoo.com> wrote:

> I tried to get xyplot shrink fit for my mixed model._ But, the mixed model line is not seen in the graph.
> I would like to know if there is anything wrong with my code.

Typo? Try  panel.abline(fixef(fm1),... or panel.abline(ff), ...


From jdnewmil at dcn.davis.CA.us  Sun Apr 29 21:00:56 2012
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 29 Apr 2012 12:00:56 -0700
Subject: [R-sig-ME] Xy plot help
In-Reply-To: <1335724026.17943.YahooMailNeo@web39401.mail.mud.yahoo.com>
References: <1335724026.17943.YahooMailNeo@web39401.mail.mud.yahoo.com>
Message-ID: <87ca7e92-d774-4acc-bceb-1428cf73a96b@email.android.com>

A) Yes, there is something wrong. Code not reproducible. Behavdat not found.

B) Last time I used it, Yahoo Mail could send in plain text. Admittedly that has been awhile, but Google sez read [1] and/or [2].

[1] http://help.yahoo.com/tutorials/mail/mail_persmsg1.html
[2] http://email.about.com/od/yahoomailtips/qt/et/plain_text.htm
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

arun <smartpink111 at yahoo.com> wrote:

>Dear R group,
>
>Tried to turn off the html in yahoo.? So far? not successful.?
>Apologies!
>
>I tried to get xyplot shrink fit for my mixed model.? But, the mixed
>model line is not seen in the graph.
>I would like to know if there is anything wrong with my code.
>Thanks,
>A.K.
>
>
>
>(fm1 <- lmer(Response3 ~1+ Wavelength*Start_Resp*time + (1|resid) +
>(1+time|Subject_BDat), family=binomial, 
>data=Behavdat, REML=0))
>
>df <- coef(lmList(Response ~ time | SubjectBDat, Behavdat)) 
>fclow <- subset(df, '(Intercept)' < -4.1) 
>fchigh <- subset(df, '(Intercept)' > -4.1) 
>cc1 <- as.data.frame(coef(fm1)$Subject) 
>names(cc1) <- c("A", "B","C","D","E","F","G","H","I","K","L","M") 
>df <- cbind(df, cc1) 
>ff <- fixef(fm1)
>SubjectBDat<-as.factor(Behavdat$Subject)
>print(xyplot(Response ~ time | SubjectBDat, Behavdat, 
>????????????? type = c("g", "p", "r"), 
>???????????? coef.list = df[,3:14], 
>???????????? panel = function(..., coef.list) { 
>???????????????? panel.xyplot(...) 
>???????????????? panel.abline(as.numeric(coef.list[packet.number(),]), 
>????????????????????????????? col.line =
>trellis.par.get("superpose.line")$col[2], 
>????????????????????????????? lty =
>trellis.par.get("superpose.line")$lty[2] 
>????????????????????????????? ) 
>???????????????? panel.abline(fixef(fm), 
>????????????????????????????? col.line =
>trellis.par.get("superpose.line")$col[4], 
>????????????????????????????? lty =
>trellis.par.get("superpose.line")$lty[4] 
>????????????????????????????? ) 
>???????????? }, 
>???????????? index.cond = function(x,y) coef(lm(y ~ x))[1], 
>???????????? xlab = "time", 
>???????????? ylab = "Response", 
>???????????? key = list(space = "top", columns = 3, 
>???????????? text = list(c("Within-subject", "Mixed model",
>"Population")), 
>???????????? lines = list(col =
>trellis.par.get("superpose.line")$col[c(1:2,4)], 
>???????????? lty = trellis.par.get("superpose.line")$lty[c(1:2,4)]))))
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From smartpink111 at yahoo.com  Mon Apr 30 00:24:54 2012
From: smartpink111 at yahoo.com (arun)
Date: Sun, 29 Apr 2012 15:24:54 -0700 (PDT)
Subject: [R-sig-ME] Xy plot help
In-Reply-To: <20120429205842.98c0bd9a.hm@zotac.lan>
References: <1335724026.17943.YahooMailNeo@web39401.mail.mud.yahoo.com>
	<20120429205842.98c0bd9a.hm@zotac.lan>
Message-ID: <1335738294.51521.YahooMailNeo@web39405.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120429/bd22e4ec/attachment.pl>

From jdjgilbert at gmail.com  Mon Apr 30 14:15:04 2012
From: jdjgilbert at gmail.com (James Gilbert)
Date: Mon, 30 Apr 2012 22:15:04 +1000
Subject: [R-sig-ME] MCMCglmm - detecting covariance patterns?
Message-ID: <CAPSfTN5UVPT4H9vJsD2cz4xdVWfVWQ2+bXTg4yg1bXMe=QhjSw@mail.gmail.com>

Dear list,

I'm a relative newcomer to MCMCglmm and have a correspondingly newbie question.

I am trying to conduct a multivariate GLMM in order to ask whether a
continuous predictor affects the covariance between two response
variables, while at the same time incorporating non-independence due
to phylogeny.

I have 62 species of syrphid flies for each of which I have two
response variables, PCA1 and PCA2 -  calculated using phylogenetic PCA
(Liam Revell's method). n.b. these come from a wider dataset of 17
morphological characters from 259 species.

The 62 species are a subset of these for which I also have information
on total chromosome length (TCL, i.e. the sum of the lengths of the
chromosomes from the karyotype).

As well as asking whether TCL is related directly to PCA1 or PCA2 as a
fixed effect, I also want to ask whether TCL affects the strength of
correlation between these two principal components (which by
definition are uncorrelated in the wider sample, but may be related
among subsets of the species).

I would like to know whether it is appropriate for me to ask this
question by incorporating TCL as part of the random term in the model
or part of the residual term?

After reading the course notes and a few relevant posts on this list,
here are what I believe are my options:

EITHER incorporate the covariate into the random term, as follows:

str(pmdat)
'data.frame':	62 obs. of  5 variables:
 $ PCA1: num  30.75 -2.93 17.2 -31.58 27.81 ...
 $ PCA2: num  1.92 11.82 2.84 -1.96 6.35 ...
 $ TCL   : num  53.7 58.6 54.9 51.5 46.2 52.2 72.3 53.6 57 63.6 ...
 $ animal: chr  "Allograpta_obliqua" "Asemosyrphus_mexicanus"
"Cheilosia_burkei" "Cheilosia_illustrata" ...

phen.var<-matrix(c(var(pmdat$PCA1,na.rm=TRUE),0,0,
var(pmdat$PCA2,na.rm=TRUE)),2,2)

pr    <-list(G=list(G1=list(V=phen.var/3,nu=2, alpha.mu=c(0,0),
alpha.V=diag(2)*1000),
                    G2=list(V=diag(2)*2,nu=2, alpha.mu=c(0,0),
alpha.V=diag(2)*1000)),
                    R=list(V=diag(2)*2,n=3))

mcmod <- MCMCglmm(cbind(PCA1,PCA2) ~ (trait-1) * TCL,
                  random=~us(trait):animal + us(trait):TCL,
                  rcov=~us(trait):units, family=c("gaussian","gaussian"),
                  pedigree=tree.dat, nodes='TIPS',
                  data=pmdat, prior=pr,verbose=T, thin=100,
nitt=330000, burnin=30000)

TCL_effect_on_covariance <- posterior.mode(mcmod$VCV[,'PCA2:PCA1.TCL'])
TCL_effect_on_covariance_CI <- HPDinterval(mcmod$VCV[,'PCA2:PCA1.TCL'])


OR incorporate the covariate into the residual term, as follows -
although I am doubtful of my syntax for the rcov term:

pr    <-list(G=list(G1=list(V=phen.var/3,nu=2, alpha.mu=c(0,0),
alpha.V=diag(2)*1000)),
             R=list(V=diag(2)*2,n=3))

mcmod1<- MCMCglmm(cbind(PCA1,PCA2) ~ (trait-1) * TCL,
                  random=~us(trait):animal,
                  rcov=~us(trait:TCL):units,
                  family=c("gaussian","gaussian"),
                  pedigree=tree.dat, nodes='TIPS',
                  data=pmdat, prior=pr,
                  verbose=T, thin=100, nitt=330000, burnin=30000)

TCL_effect_on_covariance <-
posterior.mode(mcmod1$VCV[,'PCA2:TCL:PCA1:TCL.units'])
TCL_effect_on_covariance_CI <-
HPDinterval(mcmod1$VCV[,'PCA2:TCL:PCA1:TCL.units'])

Both models appear to run fine without any obvious issues, and I'm
just wondering which (if either) is more appropriate - and, if
neither, what would be the correct way to specify the model and
extract the effect I am interested in.

Many thanks in advance!

James Gilbert


--
t:+612 9351 4661? m:+614 5804 4038 ?w: http://jdjgilbert.wordpress.com
Heydon-Lawrence Bdg A08, Univ. of Sydney, NSW 2006, Australia
"I am dying by inches, for lack of anyone to talk to about insects.."
Darwin, diary entry


From pauljohn32 at gmail.com  Tue May  1 02:37:38 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 30 Apr 2012 19:37:38 -0500
Subject: [R-sig-ME] MCMCglmm for binomial models? -- updated to use
	rcppbugs
In-Reply-To: <CAMi=pg4ssP85yE6UMRS92fNhLn3Gs1WxY5DJpSM2nAx8LrybWA@mail.gmail.com>
References: <CAMi=pg4ssP85yE6UMRS92fNhLn3Gs1WxY5DJpSM2nAx8LrybWA@mail.gmail.com>
Message-ID: <CAErODj9QiNDeqyxgZuCy4KY2PcgMLE6uyDgOJWgAFKGSOLpawQ@mail.gmail.com>

> I know this is an old thread, but since I've just posted the first
> version of rcppbugs on CRAN, I thought I'd see if I could convert this
> model.

> This model is implemented in pure R (no c++ required).  The source
> code is posted below.


Hi, Whit:

I don't have the thread going back to the ancient times (:)), so I
can't tell what the point of this might be.  I wonder "what the hell
is he talking about?" and "why would I want a package called rcppbugs
if the project he describes doesn't have any C++ in it?"

I tried to install rcppbugs on Debian, but ended in failure,  so
obviously I'm missing some devel headers*.  While I track back to find
out WTF on that, how about you post an explanation of why rcppbugs is
worth the effort in the first place?


[*]
* DONE (RcppArmadillo)
* installing *source* package ?rcppbugs? ...
** package ?rcppbugs? successfully unpacked and MD5 sums checked
** libs
g++ -I/usr/share/R/include -DNDEBUG
-I"/home/pauljohn/R/x86_64-pc-linux-gnu-library/2.15/Rcpp/include"
-I"/home/pauljohn/R/x86_64-pc-linux-gnu-library/2.15/RcppArmadillo/include"
 -I./cppbugs -fpic  -O3 -pipe  -g  -c helpers.cpp -o helpers.o
g++ -I/usr/share/R/include -DNDEBUG
-I"/home/pauljohn/R/x86_64-pc-linux-gnu-library/2.15/Rcpp/include"
-I"/home/pauljohn/R/x86_64-pc-linux-gnu-library/2.15/RcppArmadillo/include"
 -I./cppbugs -fpic  -O3 -pipe  -g  -c interface.cpp -o interface.o
In file included from ./cppbugs/cppbugs/mcmc.dynamic.stochastic.hpp:25:0,
                 from ./cppbugs/cppbugs/mcmc.normal.hpp:22,
                 from interface.cpp:24:
./cppbugs/cppbugs/mcmc.math.hpp:23:50: fatal error:
boost/math/special_functions/gamma.hpp: No such file or directory
compilation terminated.
make: *** [interface.o] Error 1
ERROR: compilation failed for package ?rcppbugs?

-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From armstrong.whit at gmail.com  Tue May  1 03:36:54 2012
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Mon, 30 Apr 2012 21:36:54 -0400
Subject: [R-sig-ME] MCMCglmm for binomial models? -- updated to use
	rcppbugs
In-Reply-To: <CAErODj9QiNDeqyxgZuCy4KY2PcgMLE6uyDgOJWgAFKGSOLpawQ@mail.gmail.com>
References: <CAMi=pg4ssP85yE6UMRS92fNhLn3Gs1WxY5DJpSM2nAx8LrybWA@mail.gmail.com>
	<CAErODj9QiNDeqyxgZuCy4KY2PcgMLE6uyDgOJWgAFKGSOLpawQ@mail.gmail.com>
Message-ID: <CAMi=pg4LkgMNXBSmcA5ydWUi3CfR4KMyu2=J_78GsdrkP-AYUg@mail.gmail.com>

Paul,

Quick reply: rcppbugs is a new package that attempts to provide a pure
R alternative to using OpenBUGS/WinBUGS/JAGS for MCMC.

The core of the package is c++, but the model specification is in R
(hence my previous post saying no c++ required).

The first versions of the software shipped as pure c++, so one needed
to write a c++ model and use Rcpp and inline to call the model.  This
version still ships standalone and can be found here:
https://github.com/armstrtw/CppBugs

The R api for cppbugs is rcppbugs, and the project page is here:
https://github.com/armstrtw/rcppbugs

I'll reply to the other questions in line, but let me post an example
of a linear model so everyone can get the flavor of the package:

## assuming your data is in matrix X and vector y, and NC is the
number of columns of X

library(rcppbugs)
b <- mcmc.normal(rnorm(NC),mu=0,tau=0.0001)
tau.y <- mcmc.gamma(runif(1),alpha=0.1,beta=0.1)
y.hat <- linear(X,b)
y.lik <- mcmc.normal(y,mu=y.hat,tau=tau.y,observed=TRUE)
m <- create.model(b, tau.y, y.hat, y.lik)

## then to run the model:
cat("running model...\n")
ans <- run.model(m, iterations=1e5L, burn=1e4L, adapt=1e3L, thin=10L)

## and view the 'trace' of b
print(ans[["b"]])

> I don't have the thread going back to the ancient times (:)), so I
> can't tell what the point of this might be. ?I wonder "what the hell

You're cracking me up.  The original post was by Bob Farmer
investigating why his MCMCglmm results were not converging to his
WinBUGS model.

That was about the time that I produced a stable api for the pure c++
version of my code, so I posted the c++ model as an example.  It was
about 25x faster than JAGs.

Now that I've released the R version of cppbugs, I re-posted the model
in rcppbugs form.

> I tried to install rcppbugs on Debian, but ended in failure, ?so
> obviously I'm missing some devel headers*.

Looks like you just need the boost headers, which ship with debian, so
you should be good to go after that.

> While I track back to find
> out WTF on that, how about you post an explanation of why rcppbugs is
> worth the effort in the first place?

I posted some crude benchmarks over on the Rcpp list. Happy to post
them here as well (or off list if you want).

Very roughly, for the linear model above, rcppbugs is between 3x and
5x faster vs MCMCpack, and between 50x and 75x faster than JAGS.

-Whit


From shankarlanke at gmail.com  Tue May  1 05:49:04 2012
From: shankarlanke at gmail.com (Shankar Lanke)
Date: Mon, 30 Apr 2012 23:49:04 -0400
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 64, Issue 44
In-Reply-To: <mailman.3.1335780003.20564.r-sig-mixed-models@r-project.org>
References: <mailman.3.1335780003.20564.r-sig-mixed-models@r-project.org>
Message-ID: <CAKFdi_vEWuH27B-tDYzJCF9UXVdvJMuP=wmQhWrAwi6+TzSAEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120430/e3f2f4d3/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue May  1 08:08:36 2012
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 30 Apr 2012 23:08:36 -0700
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 64, Issue 44
In-Reply-To: <CAKFdi_vEWuH27B-tDYzJCF9UXVdvJMuP=wmQhWrAwi6+TzSAEw@mail.gmail.com>
References: <mailman.3.1335780003.20564.r-sig-mixed-models@r-project.org>
	<CAKFdi_vEWuH27B-tDYzJCF9UXVdvJMuP=wmQhWrAwi6+TzSAEw@mail.gmail.com>
Message-ID: <f0b1c834-ff40-49b1-ba33-63bae0bc4623@email.android.com>

You cannot save them in the same file. Save them separately, and if you think you need one file then use something like zip or tar package them together.

BTW this question is off topic for this list. It belongs on R-help.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Shankar Lanke <shankarlanke at gmail.com> wrote:

>Dear R users,
>
>I have a naive question since I am beginner.
>
>I am trying to save all my work in R, not just the code but also the
>results and subset data that I have created while working in a single
>file.
>
>I have tried saving the file using following commands, but manually I
>can
>save by clicking file (Top left hand corner), the save to
>file,(lastsave).
>Can we do this with a code.
>
>savehistory(file = 1CMD1.Rhistory")
>save.image("1CMD1.RData")
>
>But when I double click the save.image file, the work I have done is
>not
>displayed, how we can view it.
>
>I appreciate your help in advance.
>
>Thank you very much.
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From torvon at gmail.com  Tue May  1 16:16:27 2012
From: torvon at gmail.com (Eiko Fried)
Date: Tue, 1 May 2012 16:16:27 +0200
Subject: [R-sig-ME] ordinal response: GLMM in LME4
Message-ID: <CACm_P7p1ya0-EknjLWqP=DrUs4=ERipT9AKiJfskihLPmy-DYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120501/086ca542/attachment.pl>

From deter088 at umn.edu  Tue May  1 19:39:23 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 1 May 2012 12:39:23 -0500
Subject: [R-sig-ME] lme interaction result strange
Message-ID: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120501/b6959d0f/attachment.pl>

From deter088 at umn.edu  Tue May  1 19:53:22 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 1 May 2012 12:53:22 -0500
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
Message-ID: <CAOLJph=Kx0ZT1k4pYpxUGnpy4f8oPFgC_Xn0k21OK+hCFJuceA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120501/f2fb22bb/attachment.pl>

From istazahn at gmail.com  Tue May  1 19:51:06 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 1 May 2012 13:51:06 -0400
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
Message-ID: <CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>

Hi Charles,

My first guess is that you have (a) categorical variable(s) in your
predictors, and that the contrasts in SAS are different than those in
R.

Best,
Ista

On Tue, May 1, 2012 at 1:39 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Dear R users,
>
> I have been working on replicating some linear mixed models from SAS. ?The
> first one matches perfectly when the SAS model is simple with the three
> separate factors.
>
> fit=lme(var~group+Event_name+Died,
> ? ?data=liv34,
> ? ?random=~1|ID)
> anova.lme(fit, type="marginal", adjustSigma=F)
>
> However, once I put an interaction into the formula the values don't match.
>
> fit=lme(var~group+Event_name+Died+Event_name*Died,
> ? ?data=liv34,
> ? ?random=~1|ID)
> anova.lme(fit, type="marginal", adjustSigma=F)
>
> ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
> (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
> group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
> Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
> Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
> Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
> Done.
>
> The numbers *bold* don't match up. ?They should be approximately .0290 and
> .1318 respectively. ?The other two are still exact matches. ?I know looking
> for exact matches is ambitious but the numbers should be at least similar
> that the conclusions don't change so drastically.
>
> Any thoughts as to why this discrepancy is happening would be most
> appreciated.
>
> Regards,
>
> Charles
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From istazahn at gmail.com  Tue May  1 20:09:23 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 1 May 2012 14:09:23 -0400
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CAOLJph=Kx0ZT1k4pYpxUGnpy4f8oPFgC_Xn0k21OK+hCFJuceA@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<CAOLJph=Kx0ZT1k4pYpxUGnpy4f8oPFgC_Xn0k21OK+hCFJuceA@mail.gmail.com>
Message-ID: <CA+vqiLF9JDv3b5KKG3OD11isYKNVn702K2h6pLGZeaa_yn_spg@mail.gmail.com>

Hi Charles,

You can print and assign contrasts in R using the contrasts function.
See ?contrasts for details. You may also wish to look at ?contr.SAS

HTH,
Ista

On Tue, May 1, 2012 at 1:53 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Thank you for your response Ista.? Do you have a recommendations how I might
> address variation in the contrasts?
>
> Regards,
> Charles
>
>
> On Tue, May 1, 2012 at 12:51 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> Hi Charles,
>>
>> My first guess is that you have (a) categorical variable(s) in your
>> predictors, and that the contrasts in SAS are different than those in
>> R.
>>
>> Best,
>> Ista
>>
>> On Tue, May 1, 2012 at 1:39 PM, Charles Determan Jr <deter088 at umn.edu>
>> wrote:
>> > Dear R users,
>> >
>> > I have been working on replicating some linear mixed models from SAS.
>> > ?The
>> > first one matches perfectly when the SAS model is simple with the three
>> > separate factors.
>> >
>> > fit=lme(var~group+Event_name+Died,
>> > ? ?data=liv34,
>> > ? ?random=~1|ID)
>> > anova.lme(fit, type="marginal", adjustSigma=F)
>> >
>> > However, once I put an interaction into the formula the values don't
>> > match.
>> >
>> > fit=lme(var~group+Event_name+Died+Event_name*Died,
>> > ? ?data=liv34,
>> > ? ?random=~1|ID)
>> > anova.lme(fit, type="marginal", adjustSigma=F)
>> >
>> > ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
>> > (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
>> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
>> > Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
>> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
>> > Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
>> > Done.
>> >
>> > The numbers *bold* don't match up. ?They should be approximately .0290
>> > and
>> > .1318 respectively. ?The other two are still exact matches. ?I know
>> > looking
>> > for exact matches is ambitious but the numbers should be at least
>> > similar
>> > that the conclusions don't change so drastically.
>> >
>> > Any thoughts as to why this discrepancy is happening would be most
>> > appreciated.
>> >
>> > Regards,
>> >
>> > Charles
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From Thierry.ONKELINX at inbo.be  Tue May  1 20:34:51 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 1 May 2012 18:34:51 +0000
Subject: [R-sig-ME] ordinal response: GLMM in LME4
In-Reply-To: <CACm_P7p1ya0-EknjLWqP=DrUs4=ERipT9AKiJfskihLPmy-DYQ@mail.gmail.com>
References: <CACm_P7p1ya0-EknjLWqP=DrUs4=ERipT9AKiJfskihLPmy-DYQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757369AB2@inbomail.inbo.be>

I think that clmm from the ordinal package is more suitable for that kind of response.

Best regards,

Thierry
________________________________________
Van: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] namens Eiko Fried [torvon at gmail.com]
Verzonden: dinsdag 1 mei 2012 16:16
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] ordinal response: GLMM in LME4

I am running repeated measurement mixed models, my response variable is
ordered, I'm trying to run GLMMs in LME4.
The variables are highly skewed (40% "0", 30% "1", 20% "2", 10% "3"), 0
refers to "never within the last week", 1 to "one around two days within
the last week", 2 to 4 days, 3 to "nearly on all days".

How does one treat this response variable in terms of family and link
function in GLMM in LME4?

And: is there more information about GLMM in LME4 except for the 2011
presentation (http://lme4.r-forge.r-project.org/slides/2011-01-11-Madison)?
GLMMs are not addressed in the current 4 chapters of the LME4 handbook.

Thank you
-- E

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Paul.Thompson at SanfordHealth.org  Tue May  1 20:39:41 2012
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Tue, 1 May 2012 18:39:41 +0000
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>

There is another issue. From the error df, it seems like this is a multi-level/RM/multiple obs study, and SAS and R do not always agree on the computation of the df, as well as the type of SS that is being computed. You need to present both outputs, so that we can see both.

I know almost nothing about R, and so my comments may not be relevant.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ista Zahn
Sent: Tuesday, May 01, 2012 12:51 PM
To: Charles Determan Jr
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme interaction result strange

Hi Charles,

My first guess is that you have (a) categorical variable(s) in your
predictors, and that the contrasts in SAS are different than those in
R.

Best,
Ista

On Tue, May 1, 2012 at 1:39 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Dear R users,
>
> I have been working on replicating some linear mixed models from SAS. ?The
> first one matches perfectly when the SAS model is simple with the three
> separate factors.
>
> fit=lme(var~group+Event_name+Died,
> ? ?data=liv34,
> ? ?random=~1|ID)
> anova.lme(fit, type="marginal", adjustSigma=F)
>
> However, once I put an interaction into the formula the values don't match.
>
> fit=lme(var~group+Event_name+Died+Event_name*Died,
> ? ?data=liv34,
> ? ?random=~1|ID)
> anova.lme(fit, type="marginal", adjustSigma=F)
>
> ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
> (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
> group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
> Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
> Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
> Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
> Done.
>
> The numbers *bold* don't match up. ?They should be approximately .0290 and
> .1318 respectively. ?The other two are still exact matches. ?I know looking
> for exact matches is ambitious but the numbers should be at least similar
> that the conclusions don't change so drastically.
>
> Any thoughts as to why this discrepancy is happening would be most
> appreciated.
>
> Regards,
>
> Charles
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.



From deter088 at umn.edu  Tue May  1 20:54:53 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 1 May 2012 13:54:53 -0500
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
Message-ID: <CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120501/f09f1f6f/attachment.pl>

From istazahn at gmail.com  Tue May  1 21:02:31 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 1 May 2012 15:02:31 -0400
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
Message-ID: <CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>

Hi Charles,

Ask yourself what the Event_name and Died terms represent in this
model. When you understand that, you'll understand why you need to
know what contrasts were used if you hope to correctly interpret these
terms.

Alternatively, you can interpret the Event_name and Died terms from
the first model (without the interaction term), and interpret just the
interaction term from this model (so-called type II sums of squares by
some).

Best,
Ista

On Tue, May 1, 2012 at 2:54 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> I have yet to attempt the contrast suggestion yet but here is the SAS output
> to complement the R.
>
> SAS output for the simple and interaction models.? I have presented the Type
> III tests for simplicity.? As you can see from my prior R output, the DFs
> match exactly.? The only variation is with the F and p value of the
> Event_name and Died in the interaction model.
>
> Type 3 Tests of Fixed Effects
>
> Effect?????????? ?NumDF DenDF F Value Pr > F
>
> group ???? ? ? ? ? ? 1 ?? ? ? ??? 23 ??? ?????0.65 ???0.4293
>
> Event_name??? ?5 ???????????96 ?????????2.09 ???0.0738
>
> Died ?????????????????1 ???????????23???????? ?1.83 ???0.1889
>
>
>
> Type 3 Tests of Fixed Effects
>
> Effect ???????????? ??????NumDF DenDF ? ? F Value Pr > F
>
> group ?????????? ? ? ? ? ?? 1 ?????????????23 ??????????0.47 ????0.5015
>
> Event_name ???? ?? ?? 5 ?????????????91 ??????????2.62 ???0.0290
>
> Died ??????????????????? ? ? 1 ?????????????23 ??????????2.44 ????0.1318
>
> Event_name*Died 5 ?????????????91 ?????????1.10 ????0.3637
>
>
> R output of interaction model
>
> ? ? ? ? ? ? ? ? ? ? ? ?? numDF denDF ? ? F-value ? ? ?p-value
> (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
>
> group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
> Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
> Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
> Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
> Done.
>
>
> Regards,
>
> Charles
>
>
>
> On Tue, May 1, 2012 at 1:39 PM, Thompson,Paul
> <Paul.Thompson at sanfordhealth.org> wrote:
>>
>> There is another issue. From the error df, it seems like this is a
>> multi-level/RM/multiple obs study, and SAS and R do not always agree on the
>> computation of the df, as well as the type of SS that is being computed. You
>> need to present both outputs, so that we can see both.
>>
>> I know almost nothing about R, and so my comments may not be relevant.
>>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ista Zahn
>> Sent: Tuesday, May 01, 2012 12:51 PM
>> To: Charles Determan Jr
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] lme interaction result strange
>>
>> Hi Charles,
>>
>> My first guess is that you have (a) categorical variable(s) in your
>> predictors, and that the contrasts in SAS are different than those in
>> R.
>>
>> Best,
>> Ista
>>
>> On Tue, May 1, 2012 at 1:39 PM, Charles Determan Jr <deter088 at umn.edu>
>> wrote:
>> > Dear R users,
>> >
>> > I have been working on replicating some linear mixed models from SAS.
>> > ?The
>> > first one matches perfectly when the SAS model is simple with the three
>> > separate factors.
>> >
>> > fit=lme(var~group+Event_name+Died,
>> > ? ?data=liv34,
>> > ? ?random=~1|ID)
>> > anova.lme(fit, type="marginal", adjustSigma=F)
>> >
>> > However, once I put an interaction into the formula the values don't
>> > match.
>> >
>> > fit=lme(var~group+Event_name+Died+Event_name*Died,
>> > ? ?data=liv34,
>> > ? ?random=~1|ID)
>> > anova.lme(fit, type="marginal", adjustSigma=F)
>> >
>> > ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
>> > (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
>> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
>> > Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
>> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
>> > Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
>> > Done.
>> >
>> > The numbers *bold* don't match up. ?They should be approximately .0290
>> > and
>> > .1318 respectively. ?The other two are still exact matches. ?I know
>> > looking
>> > for exact matches is ambitious but the numbers should be at least
>> > similar
>> > that the conclusions don't change so drastically.
>> >
>> > Any thoughts as to why this discrepancy is happening would be most
>> > appreciated.
>> >
>> > Regards,
>> >
>> > Charles
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> -----------------------------------------------------------------------
>> Confidentiality Notice: This e-mail message, including any attachments,
>> is for the sole use of the intended recipient(s) and may contain
>> privileged and confidential information. ?Any unauthorized review, use,
>> disclosure or distribution is prohibited. ?If you are not the intended
>> recipient, please contact the sender by reply e-mail and destroy
>> all copies of the original message.
>>
>


From bbolker at gmail.com  Wed May  2 02:15:07 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 May 2012 00:15:07 +0000 (UTC)
Subject: [R-sig-ME] ordinal response: GLMM in LME4
References: <CACm_P7p1ya0-EknjLWqP=DrUs4=ERipT9AKiJfskihLPmy-DYQ@mail.gmail.com>
Message-ID: <loom.20120502T021329-103@post.gmane.org>

Eiko Fried <torvon at ...> writes:

> 
   [snip]

> 
> And: is there more information about GLMM in LME4 except for the 2011
> presentation (http://lme4.r-forge.r-project.org/slides/2011-01-11-Madison)?
> GLMMs are not addressed in the current 4 chapters of the LME4 handbook.
> 

  You might look at 

https://r-forge.r-project.org/scm/viewvc.php/www/lMMwR/?root=lme4

 and in particular

https://r-forge.r-project.org/scm/viewvc.php/www/lMMwR
   /ChGLMMBinomial.Rnw?view=markup&revision=1059&root=lme4

(url line-broken to make Gmane happy)


From Thierry.ONKELINX at inbo.be  Wed May  2 10:48:39 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 2 May 2012 08:48:39 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 64, Issue 44
In-Reply-To: <CAKFdi_vEWuH27B-tDYzJCF9UXVdvJMuP=wmQhWrAwi6+TzSAEw@mail.gmail.com>
References: <mailman.3.1335780003.20564.r-sig-mixed-models@r-project.org>
	<CAKFdi_vEWuH27B-tDYzJCF9UXVdvJMuP=wmQhWrAwi6+TzSAEw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275736AE11@inbomail.inbo.be>

Dear Shankar,

R-help is better suited for this kind of general questions. This mailing list is dedicated to mixed models.

I'd recommend to use a script instead of saving the history. You don't need to keep all your typos and stuff that didn't work.

Futhermore I prefer save() to save just the objects that I really want to keep. Again I don't want all the clutter origination from typos and trail and error.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Shankar Lanke
Verzonden: dinsdag 1 mei 2012 5:49
Aan: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 64, Issue 44

Dear R users,

I have a naive question since I am beginner.

I am trying to save all my work in R, not just the code but also the results and subset data that I have created while working in a single file.

I have tried saving the file using following commands, but manually I can save by clicking file (Top left hand corner), the save to file,(lastsave).
Can we do this with a code.

savehistory(file = 1CMD1.Rhistory")
save.image("1CMD1.RData")

But when I double click the save.image file, the work I have done is not displayed, how we can view it.

I appreciate your help in advance.

Thank you very much.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From spatrick at cebc.cnrs.fr  Wed May  2 12:08:06 2012
From: spatrick at cebc.cnrs.fr (Samantha Patrick)
Date: Wed, 02 May 2012 12:08:06 +0200
Subject: [R-sig-ME]  Calculating repeatability with ordinal data
In-Reply-To: <4F990193.4000107@cebc.cnrs.fr>
References: <4F990193.4000107@cebc.cnrs.fr>
Message-ID: <4FA10786.6090007@cebc.cnrs.fr>


Hi

Firstly I sent this message last week but can find no evidence that it actually sent.
However, if this is a double posting I am very sorry.

I am currently working with repeated measures for individuals and I am
trying to quantify individual repeatability.  Normally, for continuous
distributions, I would use a mixed model and calculate the variance
explained by individual divided by the total variance.  However my individual scores
are ordinal and I have been using the clmm function in the Ordinal package:

example of data:
ID        Bird        Sex    scoremax    year
622    BS8831    M       2                 2008
623    BS8831    M       1                 2010
624    BS8831    M       1                 2011
625    BS9065    M       1                 2010
626    BS9065    M       3                 2011
627   BS19724    F       4                 2010
628   BS19724    F       5                 2010
629   BS21302    F       1                 2010
630   BS25376    F       1                 2011
631    BS9184    F       2                 2009
632   BS19989    M       3                 2011
633   BS21617    M       4                 2008
634   BS21617    M       2                 2009
635   BS21617    M       1                 2010

where scoremax ranges from 1-5, and there are 1188 birds and 1638
observations.

scoremax<-as.factor(scoremax)
bird<-as.factor(bird)
year<-as.factor(year)
fmm1<- clmm(scoremax~year+ (1|bird), link = c("probit"), Hess =TRUE)

summary(fmm1)

but this only gives the variance estimate for bird, with no residual
estimate.  Some investigations reveal that using an ordinal regression
in MCMCglmm will also not estimate the residual variance, and it seems
you need to constrain this value.  I have been unable to find any posts
about repeatability in ordinal data.

My questions I guess are:
Is using a mixed model appropriate for calculating the repeatability of
ordinal data (and if not does anyone know any other methods)?

If it is, does anyone have any hints on how to calculate the residual variance,
to enable repeatability estimates to be calculated.

Many Thanks

Sam

-- 

Dr Samantha Patrick
Post Doctoral Fellow
Centre d'Etudes Biologiques de Chiz? - CNRS
79360 Villiers-en-Bois
France
T:+33 549 097 846
M:+33 675 603 451
Skype: sammy_patrick
http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
http://www.researchgate.net/profile/Samantha_Patrick/


From f.calboli at imperial.ac.uk  Wed May  2 12:38:24 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 2 May 2012 11:38:24 +0100
Subject: [R-sig-ME] Calculating repeatability with ordinal data
In-Reply-To: <4FA10786.6090007@cebc.cnrs.fr>
References: <4F990193.4000107@cebc.cnrs.fr> <4FA10786.6090007@cebc.cnrs.fr>
Message-ID: <0BB9E1F2-BE5A-4987-B7B7-CB0D0189FBA8@imperial.ac.uk>

On 2 May 2012, at 11:08, Samantha Patrick wrote:

> 
> Hi
> 
> Firstly I sent this message last week but can find no evidence that it actually sent.
> However, if this is a double posting I am very sorry.
> 
> I am currently working with repeated measures for individuals and I am
> trying to quantify individual repeatability.  Normally, for continuous
> distributions, I would use a mixed model and calculate the variance
> explained by individual divided by the total variance.  However my individual scores
> are ordinal and I have been using the clmm function in the Ordinal package:
> 
> example of data:
> ID        Bird        Sex    scoremax    year
> 622    BS8831    M       2                 2008
> 623    BS8831    M       1                 2010
> 624    BS8831    M       1                 2011
> 625    BS9065    M       1                 2010
> 626    BS9065    M       3                 2011
> 627   BS19724    F       4                 2010
> 628   BS19724    F       5                 2010
> 629   BS21302    F       1                 2010
> 630   BS25376    F       1                 2011
> 631    BS9184    F       2                 2009
> 632   BS19989    M       3                 2011
> 633   BS21617    M       4                 2008
> 634   BS21617    M       2                 2009
> 635   BS21617    M       1                 2010
> 
> where scoremax ranges from 1-5, and there are 1188 birds and 1638
> observations.
> 
> scoremax<-as.factor(scoremax)

does 

scoremax = as.ordered(scoremax)

make any difference in your results?

I ask this because as.factor() does not, strictly speaking, create an ordered factor.

BW

F




> bird<-as.factor(bird)
> year<-as.factor(year)
> fmm1<- clmm(scoremax~year+ (1|bird), link = c("probit"), Hess =TRUE)
> 
> summary(fmm1)
> 
> but this only gives the variance estimate for bird, with no residual
> estimate.  Some investigations reveal that using an ordinal regression
> in MCMCglmm will also not estimate the residual variance, and it seems
> you need to constrain this value.  I have been unable to find any posts
> about repeatability in ordinal data.
> 
> My questions I guess are:
> Is using a mixed model appropriate for calculating the repeatability of
> ordinal data (and if not does anyone know any other methods)?
> 
> If it is, does anyone have any hints on how to calculate the residual variance,
> to enable repeatability estimates to be calculated.
> 
> Many Thanks
> 
> Sam
> 
> -- 
> 
> Dr Samantha Patrick
> Post Doctoral Fellow
> Centre d'Etudes Biologiques de Chiz? - CNRS
> 79360 Villiers-en-Bois
> France
> T:+33 549 097 846
> M:+33 675 603 451
> Skype: sammy_patrick
> http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
> http://www.researchgate.net/profile/Samantha_Patrick/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From angelina.mukherjee88 at gmail.com  Wed May  2 12:49:05 2012
From: angelina.mukherjee88 at gmail.com (Angelina Mukherjee)
Date: Wed, 2 May 2012 11:49:05 +0100
Subject: [R-sig-ME] Covariance structure specification
Message-ID: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120502/2ba397c6/attachment.pl>

From spatrick at cebc.cnrs.fr  Wed May  2 13:11:09 2012
From: spatrick at cebc.cnrs.fr (Samantha Patrick)
Date: Wed, 02 May 2012 13:11:09 +0200
Subject: [R-sig-ME] Calculating repeatability with ordinal data
In-Reply-To: <0BB9E1F2-BE5A-4987-B7B7-CB0D0189FBA8@imperial.ac.uk>
References: <4F990193.4000107@cebc.cnrs.fr> <4FA10786.6090007@cebc.cnrs.fr>
	<0BB9E1F2-BE5A-4987-B7B7-CB0D0189FBA8@imperial.ac.uk>
Message-ID: <4FA1164D.6040603@cebc.cnrs.fr>

Hi

Thank you for the tip - I had editted my code!  However, sadly it 
doesn't  solve the problem of how to estimate the residual variance.

Many Thanks

Sam


Le 02/05/2012 12:38, Federico Calboli a ?crit :
> On 2 May 2012, at 11:08, Samantha Patrick wrote:
>
>> Hi
>>
>> Firstly I sent this message last week but can find no evidence that it actually sent.
>> However, if this is a double posting I am very sorry.
>>
>> I am currently working with repeated measures for individuals and I am
>> trying to quantify individual repeatability.  Normally, for continuous
>> distributions, I would use a mixed model and calculate the variance
>> explained by individual divided by the total variance.  However my individual scores
>> are ordinal and I have been using the clmm function in the Ordinal package:
>>
>> example of data:
>> ID        Bird        Sex    scoremax    year
>> 622    BS8831    M       2                 2008
>> 623    BS8831    M       1                 2010
>> 624    BS8831    M       1                 2011
>> 625    BS9065    M       1                 2010
>> 626    BS9065    M       3                 2011
>> 627   BS19724    F       4                 2010
>> 628   BS19724    F       5                 2010
>> 629   BS21302    F       1                 2010
>> 630   BS25376    F       1                 2011
>> 631    BS9184    F       2                 2009
>> 632   BS19989    M       3                 2011
>> 633   BS21617    M       4                 2008
>> 634   BS21617    M       2                 2009
>> 635   BS21617    M       1                 2010
>>
>> where scoremax ranges from 1-5, and there are 1188 birds and 1638
>> observations.
>>
>> scoremax<-as.factor(scoremax)
> does
>
> scoremax = as.ordered(scoremax)
>
> make any difference in your results?
>
> I ask this because as.factor() does not, strictly speaking, create an ordered factor.
>
> BW
>
> F
>
>
>
>
>> bird<-as.factor(bird)
>> year<-as.factor(year)
>> fmm1<- clmm(scoremax~year+ (1|bird), link = c("probit"), Hess =TRUE)
>>
>> summary(fmm1)
>>
>> but this only gives the variance estimate for bird, with no residual
>> estimate.  Some investigations reveal that using an ordinal regression
>> in MCMCglmm will also not estimate the residual variance, and it seems
>> you need to constrain this value.  I have been unable to find any posts
>> about repeatability in ordinal data.
>>
>> My questions I guess are:
>> Is using a mixed model appropriate for calculating the repeatability of
>> ordinal data (and if not does anyone know any other methods)?
>>
>> If it is, does anyone have any hints on how to calculate the residual variance,
>> to enable repeatability estimates to be calculated.
>>
>> Many Thanks
>>
>> Sam
>>
>> -- 
>>
>> Dr Samantha Patrick
>> Post Doctoral Fellow
>> Centre d'Etudes Biologiques de Chiz? - CNRS
>> 79360 Villiers-en-Bois
>> France
>> T:+33 549 097 846
>> M:+33 675 603 451
>> Skype: sammy_patrick
>> http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
>> http://www.researchgate.net/profile/Samantha_Patrick/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> --
> Federico C. F. Calboli
> Neuroepidemiology and Ageing Research
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
>
>

-- 

Dr Samantha Patrick
Post Doctoral Fellow
Centre d'Etudes Biologiques de Chiz? - CNRS
79360 Villiers-en-Bois
France
T:+33 549 097 846
M:+33 675 603 451
Skype: sammy_patrick
http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
http://www.researchgate.net/profile/Samantha_Patrick/


From deter088 at umn.edu  Wed May  2 15:14:04 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 2 May 2012 08:14:04 -0500
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
	<CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>
Message-ID: <CAOLJph=O8VXQ9PES37Ym6Aw07O8AR8F8mzwSmMwsj6FRgrnTRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120502/3a474568/attachment.pl>

From Thierry.ONKELINX at inbo.be  Wed May  2 15:24:54 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 2 May 2012 13:24:54 +0000
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CAOLJph=O8VXQ9PES37Ym6Aw07O8AR8F8mzwSmMwsj6FRgrnTRw@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
	<CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>
	<CAOLJph=O8VXQ9PES37Ym6Aw07O8AR8F8mzwSmMwsj6FRgrnTRw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275736AFF3@inbomail.inbo.be>

Dear Charles,

Are you sure that SAS and lme apply the same tests? So you'll need to know how the F-values are calculated. Futhermore: what is the relevance of testing the effect of a main effect when an interaction with that main effect is present?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Charles Determan Jr
Verzonden: woensdag 2 mei 2012 15:14
Aan: Ista Zahn
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] lme interaction result strange

I have checked the contrasts and 'unfortunately' they are identical.  Is that a statistically correct avenue to just take the interaction term from the interaction model and use the first ones?  That seems odd to me as the numbers aren't the same even in the SAS output between the models.  I certainly appreciate your prior suggestion but perhaps you or someone else has another idea?  Something else seems to be strange, perhaps the syntax needs to be different when doing an interaction term?

Thanks,
Charles

On Tue, May 1, 2012 at 2:02 PM, Ista Zahn <istazahn at gmail.com> wrote:

> Hi Charles,
>
> Ask yourself what the Event_name and Died terms represent in this
> model. When you understand that, you'll understand why you need to
> know what contrasts were used if you hope to correctly interpret these
> terms.
>
> Alternatively, you can interpret the Event_name and Died terms from
> the first model (without the interaction term), and interpret just the
> interaction term from this model (so-called type II sums of squares by
> some).
>
> Best,
> Ista
>
> On Tue, May 1, 2012 at 2:54 PM, Charles Determan Jr <deter088 at umn.edu>
> wrote:
> > I have yet to attempt the contrast suggestion yet but here is the
> > SAS
> output
> > to complement the R.
> >
> > SAS output for the simple and interaction models.  I have presented
> > the
> Type
> > III tests for simplicity.  As you can see from my prior R output,
> > the DFs match exactly.  The only variation is with the F and p value
> > of the Event_name and Died in the interaction model.
> >
> > Type 3 Tests of Fixed Effects
> >
> > Effect            NumDF DenDF F Value Pr > F
> >
> > group                1            23          0.65    0.4293
> >
> > Event_name     5            96          2.09    0.0738
> >
> > Died                  1            23          1.83    0.1889
> >
> >
> >
> > Type 3 Tests of Fixed Effects
> >
> > Effect                    NumDF DenDF     F Value Pr > F
> >
> > group                       1              23           0.47     0.5015
> >
> > Event_name            5              91           2.62    0.0290
> >
> > Died                         1              23           2.44     0.1318
> >
> > Event_name*Died 5              91          1.10     0.3637
> >
> >
> > R output of interaction model
> >
> >                          numDF denDF     F-value      p-value
> > (Intercept)               1        91       111.20483  <.0001
> >
> > group                      1        23        0.46632     0.5015
> > Event_name            5        91        1.14042     *0.3449*
> > Died                       1        23        0.50989    * 0.4824*
> > Event_name:Died     5       91        1.10436     0.3637
> > Done.
> >
> >
> > Regards,
> >
> > Charles
> >
> >
> >
> > On Tue, May 1, 2012 at 1:39 PM, Thompson,Paul
> > <Paul.Thompson at sanfordhealth.org> wrote:
> >>
> >> There is another issue. From the error df, it seems like this is a
> >> multi-level/RM/multiple obs study, and SAS and R do not always
> >> agree on
> the
> >> computation of the df, as well as the type of SS that is being
> computed. You
> >> need to present both outputs, so that we can see both.
> >>
> >> I know almost nothing about R, and so my comments may not be relevant.
> >>
> >> -----Original Message-----
> >> From: r-sig-mixed-models-bounces at r-project.org
> >> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ista
> Zahn
> >> Sent: Tuesday, May 01, 2012 12:51 PM
> >> To: Charles Determan Jr
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] lme interaction result strange
> >>
> >> Hi Charles,
> >>
> >> My first guess is that you have (a) categorical variable(s) in your
> >> predictors, and that the contrasts in SAS are different than those
> >> in R.
> >>
> >> Best,
> >> Ista
> >>
> >> On Tue, May 1, 2012 at 1:39 PM, Charles Determan Jr
> >> <deter088 at umn.edu>
> >> wrote:
> >> > Dear R users,
> >> >
> >> > I have been working on replicating some linear mixed models from SAS.
> >> >  The
> >> > first one matches perfectly when the SAS model is simple with the
> three
> >> > separate factors.
> >> >
> >> > fit=lme(var~group+Event_name+Died,
> >> >    data=liv34,
> >> >    random=~1|ID)
> >> > anova.lme(fit, type="marginal", adjustSigma=F)
> >> >
> >> > However, once I put an interaction into the formula the values
> >> > don't match.
> >> >
> >> > fit=lme(var~group+Event_name+Died+Event_name*Died,
> >> >    data=liv34,
> >> >    random=~1|ID)
> >> > anova.lme(fit, type="marginal", adjustSigma=F)
> >> >
> >> >                          numDF denDF     F-value      p-value
> >> > (Intercept)               1        91       111.20483  <.0001
> >> > group                      1        23        0.46632     0.5015
> >> > Event_name            5        91        1.14042     *0.3449*
> >> > Died                       1        23        0.50989    * 0.4824*
> >> > Event_name:Died     5       91        1.10436     0.3637
> >> > Done.
> >> >
> >> > The numbers *bold* don't match up.  They should be approximately
> >> > .0290 and
> >> > .1318 respectively.  The other two are still exact matches.  I
> >> > know looking for exact matches is ambitious but the numbers
> >> > should be at least similar that the conclusions don't change so
> >> > drastically.
> >> >
> >> > Any thoughts as to why this discrepancy is happening would be
> >> > most appreciated.
> >> >
> >> > Regards,
> >> >
> >> > Charles
> >> >
> >> >        [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> -------------------------------------------------------------------
> >> ---- Confidentiality Notice: This e-mail message, including any
> >> attachments, is for the sole use of the intended recipient(s) and
> >> may contain privileged and confidential information.  Any
> >> unauthorized review, use, disclosure or distribution is prohibited.
> >> If you are not the intended recipient, please contact the sender by
> >> reply e-mail and destroy all copies of the original message.
> >>
> >
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From deter088 at umn.edu  Wed May  2 15:31:42 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 2 May 2012 08:31:42 -0500
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <AA818EAD2576BC488B4F623941DA74275736AFF3@inbomail.inbo.be>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
	<CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>
	<CAOLJph=O8VXQ9PES37Ym6Aw07O8AR8F8mzwSmMwsj6FRgrnTRw@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275736AFF3@inbomail.inbo.be>
Message-ID: <CAOLJphm82gkZicJw0u+JfeThgYaEFL7OfoCEk50tnjg_WgTXLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120502/8b5b6c4d/attachment.pl>

From j.hadfield at ed.ac.uk  Wed May  2 15:43:31 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 02 May 2012 14:43:31 +0100
Subject: [R-sig-ME] Calculating repeatability with ordinal data
In-Reply-To: <4FA1164D.6040603@cebc.cnrs.fr>
References: <4F990193.4000107@cebc.cnrs.fr> <4FA10786.6090007@cebc.cnrs.fr>
	<0BB9E1F2-BE5A-4987-B7B7-CB0D0189FBA8@imperial.ac.uk>
	<4FA1164D.6040603@cebc.cnrs.fr>
Message-ID: <20120502144331.23435ulmbjxwk4ws@www.staffmail.ed.ac.uk>

Hi,

The residual variance can never be estimated from ordinal data. Most  
programs will set it to zero, some programs allow you to set it at  
anything (MCMCglmm). I have not seen repeatabilities for ordinal data  
but I presume you can add the variance of the relevant distribution  
(pi^2/3 or 1 for logit/probit) to the denominator in order to get an  
intra-class correlation. I'm not confident how this would be  
interpreted for an ordinal response though. Note that if you do use  
MCMCglmm you need to include the constrained residual variance in the  
denominator (i.e. to get the denominator you need to add two to the  
"Bird" variance if you have constrained the residual variance to one).

Cheers,

Jarrod


Quoting Samantha Patrick <spatrick at cebc.cnrs.fr> on Wed, 02 May 2012  
13:11:09 +0200:

> Hi
>
> Thank you for the tip - I had editted my code!  However, sadly it  
> doesn't  solve the problem of how to estimate the residual variance.
>
> Many Thanks
>
> Sam
>
>
> Le 02/05/2012 12:38, Federico Calboli a ?crit :
>> On 2 May 2012, at 11:08, Samantha Patrick wrote:
>>
>>> Hi
>>>
>>> Firstly I sent this message last week but can find no evidence  
>>> that it actually sent.
>>> However, if this is a double posting I am very sorry.
>>>
>>> I am currently working with repeated measures for individuals and I am
>>> trying to quantify individual repeatability.  Normally, for continuous
>>> distributions, I would use a mixed model and calculate the variance
>>> explained by individual divided by the total variance.  However my  
>>> individual scores
>>> are ordinal and I have been using the clmm function in the Ordinal package:
>>>
>>> example of data:
>>> ID        Bird        Sex    scoremax    year
>>> 622    BS8831    M       2                 2008
>>> 623    BS8831    M       1                 2010
>>> 624    BS8831    M       1                 2011
>>> 625    BS9065    M       1                 2010
>>> 626    BS9065    M       3                 2011
>>> 627   BS19724    F       4                 2010
>>> 628   BS19724    F       5                 2010
>>> 629   BS21302    F       1                 2010
>>> 630   BS25376    F       1                 2011
>>> 631    BS9184    F       2                 2009
>>> 632   BS19989    M       3                 2011
>>> 633   BS21617    M       4                 2008
>>> 634   BS21617    M       2                 2009
>>> 635   BS21617    M       1                 2010
>>>
>>> where scoremax ranges from 1-5, and there are 1188 birds and 1638
>>> observations.
>>>
>>> scoremax<-as.factor(scoremax)
>> does
>>
>> scoremax = as.ordered(scoremax)
>>
>> make any difference in your results?
>>
>> I ask this because as.factor() does not, strictly speaking, create  
>> an ordered factor.
>>
>> BW
>>
>> F
>>
>>
>>
>>
>>> bird<-as.factor(bird)
>>> year<-as.factor(year)
>>> fmm1<- clmm(scoremax~year+ (1|bird), link = c("probit"), Hess =TRUE)
>>>
>>> summary(fmm1)
>>>
>>> but this only gives the variance estimate for bird, with no residual
>>> estimate.  Some investigations reveal that using an ordinal regression
>>> in MCMCglmm will also not estimate the residual variance, and it seems
>>> you need to constrain this value.  I have been unable to find any posts
>>> about repeatability in ordinal data.
>>>
>>> My questions I guess are:
>>> Is using a mixed model appropriate for calculating the repeatability of
>>> ordinal data (and if not does anyone know any other methods)?
>>>
>>> If it is, does anyone have any hints on how to calculate the  
>>> residual variance,
>>> to enable repeatability estimates to be calculated.
>>>
>>> Many Thanks
>>>
>>> Sam
>>>
>>> -- 
>>>
>>> Dr Samantha Patrick
>>> Post Doctoral Fellow
>>> Centre d'Etudes Biologiques de Chiz? - CNRS
>>> 79360 Villiers-en-Bois
>>> France
>>> T:+33 549 097 846
>>> M:+33 675 603 451
>>> Skype: sammy_patrick
>>> http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
>>> http://www.researchgate.net/profile/Samantha_Patrick/
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> --
>> Federico C. F. Calboli
>> Neuroepidemiology and Ageing Research
>> Imperial College, St. Mary's Campus
>> Norfolk Place, London W2 1PG
>>
>> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>>
>> f.calboli [.a.t] imperial.ac.uk
>> f.calboli [.a.t] gmail.com
>>
>>
>>
>
> -- 
>
> Dr Samantha Patrick
> Post Doctoral Fellow
> Centre d'Etudes Biologiques de Chiz? - CNRS
> 79360 Villiers-en-Bois
> France
> T:+33 549 097 846
> M:+33 675 603 451
> Skype: sammy_patrick
> http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
> http://www.researchgate.net/profile/Samantha_Patrick/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From istazahn at gmail.com  Wed May  2 16:41:56 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 2 May 2012 10:41:56 -0400
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CAOLJphm82gkZicJw0u+JfeThgYaEFL7OfoCEk50tnjg_WgTXLQ@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
	<CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>
	<CAOLJph=O8VXQ9PES37Ym6Aw07O8AR8F8mzwSmMwsj6FRgrnTRw@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275736AFF3@inbomail.inbo.be>
	<CAOLJphm82gkZicJw0u+JfeThgYaEFL7OfoCEk50tnjg_WgTXLQ@mail.gmail.com>
Message-ID: <CA+vqiLEMHFgUYLCDx69jwfDy41955kCdeNYNLtzKBFSDtyX0tA@mail.gmail.com>

I still think the difference is in the default contrasts. Try this
example, and notice that the default output differs for Age, and that
the same results are obtained when the contrasts in R are set to
contr.sum. I would be very surprised if this is not the source of your
confusion.

* SAS
input Person Gender $ y1 y2 y3 y4;
y=y1; Age=8;  output;
y=y2; Age=10; output;
y=y3; Age=12; output;
y=y4; Age=14; output;
drop y1-y4;
datalines;
1   F   21.0    20.0    21.5    23.0
2   F   21.0    21.5    24.0    25.5
3   F   20.5    24.0    24.5    26.0
4   F   23.5    24.5    25.0    26.5
5   F   21.5    23.0    22.5    23.5
6   F   20.0    21.0    21.0    22.5
7   F   21.5    22.5    23.0    25.0
8   F   23.0    23.0    23.5    24.0
9   F   20.0    21.0    22.0    21.5
10   F   16.5    19.0    19.0    19.5
11   F   24.5    25.0    28.0    28.0
12   M   26.0    25.0    29.0    31.0
13   M   21.5    22.5    23.0    26.5
14   M   23.0    22.5    24.0    27.5
15   M   25.5    27.5    26.5    27.0
16   M   20.0    23.5    22.5    26.0
17   M   24.5    25.5    27.0    28.5
18   M   22.0    22.0    24.5    26.5
19   M   24.0    21.5    24.5    25.5
20   M   23.0    20.5    31.0    26.0
21   M   27.5    28.0    31.0    31.5
22   M   23.0    23.0    23.5    25.0
23   M   21.5    23.5    24.0    28.0
24   M   17.0    24.5    26.0    29.5
25   M   22.5    25.5    25.5    26.0
26   M   23.0    24.5    26.0    30.0
27   M   22.0    21.5    23.5    25.0
;

proc mixed data=pr method=ml covtest;
class Person Gender;
model y = Age Gender Gender*Age/solution;
random intercept/type=un subject=Person;
run;

Type 3 Tests of Fixed Effects
Effect Num DF Den DF F Value Pr > F
Age 1 79 111.10 <.0001
Gender 1 79 0.47 0.4960
Age*Gender 1 79 6.46 0.0130

# R

dat <- read.table(text = 'Person,Gender,y,Age
1,F,21,8
1,F,20,10
1,F,21.5,12
1,F,23,14
2,F,21,8
2,F,21.5,10
2,F,24,12
2,F,25.5,14
3,F,20.5,8
3,F,24,10
3,F,24.5,12
3,F,26,14
4,F,23.5,8
4,F,24.5,10
4,F,25,12
4,F,26.5,14
5,F,21.5,8
5,F,23,10
5,F,22.5,12
5,F,23.5,14
6,F,20,8
6,F,21,10
6,F,21,12
6,F,22.5,14
7,F,21.5,8
7,F,22.5,10
7,F,23,12
7,F,25,14
8,F,23,8
8,F,23,10
8,F,23.5,12
8,F,24,14
9,F,20,8
9,F,21,10
9,F,22,12
9,F,21.5,14
10,F,16.5,8
10,F,19,10
10,F,19,12
10,F,19.5,14
11,F,24.5,8
11,F,25,10
11,F,28,12
11,F,28,14
12,M,26,8
12,M,25,10
12,M,29,12
12,M,31,14
13,M,21.5,8
13,M,22.5,10
13,M,23,12
13,M,26.5,14
14,M,23,8
14,M,22.5,10
14,M,24,12
14,M,27.5,14
15,M,25.5,8
15,M,27.5,10
15,M,26.5,12
15,M,27,14
16,M,20,8
16,M,23.5,10
16,M,22.5,12
16,M,26,14
17,M,24.5,8
17,M,25.5,10
17,M,27,12
17,M,28.5,14
18,M,22,8
18,M,22,10
18,M,24.5,12
18,M,26.5,14
19,M,24,8
19,M,21.5,10
19,M,24.5,12
19,M,25.5,14
20,M,23,8
20,M,20.5,10
20,M,31,12
20,M,26,14
21,M,27.5,8
21,M,28,10
21,M,31,12
21,M,31.5,14
22,M,23,8
22,M,23,10
22,M,23.5,12
22,M,25,14
23,M,21.5,8
23,M,23.5,10
23,M,24,12
23,M,28,14
24,M,17,8
24,M,24.5,10
24,M,26,12
24,M,29.5,14
25,M,22.5,8
25,M,25.5,10
25,M,25.5,12
25,M,26,14
26,M,23,8
26,M,24.5,10
26,M,26,12
26,M,30,14
27,M,22,8
27,M,21.5,10
27,M,23.5,12
27,M,25,14',
                  header = TRUE,
                  sep = ",")

dat$Person <- factor(dat$Person)

library(nlme)

fit1 <- lme(y~Gender*Age,
            data=dat,
            method = "ML",
            random=~1|Person)

anova(fit1, type="marginal", adjustSigma=F)

contrasts(dat$Gender) <- contr.sum(n = 2)

fit2 <- lme(y~Gender*Age,
        data=dat,
        method = "ML",
        random=~1|Person)

anova(fit2, type="marginal", adjustSigma=F)

On Wed, May 2, 2012 at 9:31 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Thank you Thierry,
>
> To answer your questions, I am sure it applies the same test as the simple
> model matches perfectly.? Furthermore, two of the interaction model
> components match but the two 'middle' effects are very different.? As such,
> I was wondering if there was something in the R syntax that would throw this
> off and haven't preoccupied myself with the calculation of the F-value as
> this is a multivariate dataset.? The relevance here is that this is a
> practice set to see if I can replicate the mixed model analysis in R.
>
> Regards,
> Charles
>
>
> On Wed, May 2, 2012 at 8:24 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>
> wrote:
>>
>> Dear Charles,
>>
>> Are you sure that SAS and lme apply the same tests? So you'll need to know
>> how the F-values are calculated. Futhermore: what is the relevance of
>> testing the effect of a main effect when an interaction with that main
>> effect is present?
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> + 32 2 525 02 51
>> + 32 54 43 61 85
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Charles Determan Jr
>> Verzonden: woensdag 2 mei 2012 15:14
>> Aan: Ista Zahn
>> CC: r-sig-mixed-models at r-project.org
>> Onderwerp: Re: [R-sig-ME] lme interaction result strange
>>
>> I have checked the contrasts and 'unfortunately' they are identical. ?Is
>> that a statistically correct avenue to just take the interaction term from
>> the interaction model and use the first ones? ?That seems odd to me as the
>> numbers aren't the same even in the SAS output between the models. ?I
>> certainly appreciate your prior suggestion but perhaps you or someone else
>> has another idea? ?Something else seems to be strange, perhaps the syntax
>> needs to be different when doing an interaction term?
>>
>> Thanks,
>> Charles
>>
>> On Tue, May 1, 2012 at 2:02 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> > Hi Charles,
>> >
>> > Ask yourself what the Event_name and Died terms represent in this
>> > model. When you understand that, you'll understand why you need to
>> > know what contrasts were used if you hope to correctly interpret these
>> > terms.
>> >
>> > Alternatively, you can interpret the Event_name and Died terms from
>> > the first model (without the interaction term), and interpret just the
>> > interaction term from this model (so-called type II sums of squares by
>> > some).
>> >
>> > Best,
>> > Ista
>> >
>> > On Tue, May 1, 2012 at 2:54 PM, Charles Determan Jr <deter088 at umn.edu>
>> > wrote:
>> > > I have yet to attempt the contrast suggestion yet but here is the
>> > > SAS
>> > output
>> > > to complement the R.
>> > >
>> > > SAS output for the simple and interaction models. ?I have presented
>> > > the
>> > Type
>> > > III tests for simplicity. ?As you can see from my prior R output,
>> > > the DFs match exactly. ?The only variation is with the F and p value
>> > > of the Event_name and Died in the interaction model.
>> > >
>> > > Type 3 Tests of Fixed Effects
>> > >
>> > > Effect ? ? ? ? ? ?NumDF DenDF F Value Pr > F
>> > >
>> > > group ? ? ? ? ? ? ? ?1 ? ? ? ? ? ?23 ? ? ? ? ?0.65 ? ?0.4293
>> > >
>> > > Event_name ? ? 5 ? ? ? ? ? ?96 ? ? ? ? ?2.09 ? ?0.0738
>> > >
>> > > Died ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ?23 ? ? ? ? ?1.83 ? ?0.1889
>> > >
>> > >
>> > >
>> > > Type 3 Tests of Fixed Effects
>> > >
>> > > Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF ? ? F Value Pr > F
>> > >
>> > > group ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ?23 ? ? ? ? ? 0.47
>> > > 0.5015
>> > >
>> > > Event_name ? ? ? ? ? ?5 ? ? ? ? ? ? ?91 ? ? ? ? ? 2.62 ? ?0.0290
>> > >
>> > > Died ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ?23 ? ? ? ? ? 2.44
>> > > 0.1318
>> > >
>> > > Event_name*Died 5 ? ? ? ? ? ? ?91 ? ? ? ? ?1.10 ? ? 0.3637
>> > >
>> > >
>> > > R output of interaction model
>> > >
>> > > ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
>> > > (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
>> > >
>> > > group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
>> > > Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
>> > > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
>> > > Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
>> > > Done.
>> > >
>> > >
>> > > Regards,
>> > >
>> > > Charles
>> > >
>> > >
>> > >
>> > > On Tue, May 1, 2012 at 1:39 PM, Thompson,Paul
>> > > <Paul.Thompson at sanfordhealth.org> wrote:
>> > >>
>> > >> There is another issue. From the error df, it seems like this is a
>> > >> multi-level/RM/multiple obs study, and SAS and R do not always
>> > >> agree on
>> > the
>> > >> computation of the df, as well as the type of SS that is being
>> > computed. You
>> > >> need to present both outputs, so that we can see both.
>> > >>
>> > >> I know almost nothing about R, and so my comments may not be
>> > >> relevant.
>> > >>
>> > >> -----Original Message-----
>> > >> From: r-sig-mixed-models-bounces at r-project.org
>> > >> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ista
>> > Zahn
>> > >> Sent: Tuesday, May 01, 2012 12:51 PM
>> > >> To: Charles Determan Jr
>> > >> Cc: r-sig-mixed-models at r-project.org
>> > >> Subject: Re: [R-sig-ME] lme interaction result strange
>> > >>
>> > >> Hi Charles,
>> > >>
>> > >> My first guess is that you have (a) categorical variable(s) in your
>> > >> predictors, and that the contrasts in SAS are different than those
>> > >> in R.
>> > >>
>> > >> Best,
>> > >> Ista
>> > >>
>> > >> On Tue, May 1, 2012 at 1:39 PM, Charles Determan Jr
>> > >> <deter088 at umn.edu>
>> > >> wrote:
>> > >> > Dear R users,
>> > >> >
>> > >> > I have been working on replicating some linear mixed models from
>> > >> > SAS.
>> > >> > ?The
>> > >> > first one matches perfectly when the SAS model is simple with the
>> > three
>> > >> > separate factors.
>> > >> >
>> > >> > fit=lme(var~group+Event_name+Died,
>> > >> > ? ?data=liv34,
>> > >> > ? ?random=~1|ID)
>> > >> > anova.lme(fit, type="marginal", adjustSigma=F)
>> > >> >
>> > >> > However, once I put an interaction into the formula the values
>> > >> > don't match.
>> > >> >
>> > >> > fit=lme(var~group+Event_name+Died+Event_name*Died,
>> > >> > ? ?data=liv34,
>> > >> > ? ?random=~1|ID)
>> > >> > anova.lme(fit, type="marginal", adjustSigma=F)
>> > >> >
>> > >> > ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
>> > >> > (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
>> > >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
>> > >> > Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
>> > >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
>> > >> > Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
>> > >> > Done.
>> > >> >
>> > >> > The numbers *bold* don't match up. ?They should be approximately
>> > >> > .0290 and
>> > >> > .1318 respectively. ?The other two are still exact matches. ?I
>> > >> > know looking for exact matches is ambitious but the numbers
>> > >> > should be at least similar that the conclusions don't change so
>> > >> > drastically.
>> > >> >
>> > >> > Any thoughts as to why this discrepancy is happening would be
>> > >> > most appreciated.
>> > >> >
>> > >> > Regards,
>> > >> >
>> > >> > Charles
>> > >> >
>> > >> > ? ? ? ?[[alternative HTML version deleted]]
>> > >> >
>> > >> > _______________________________________________
>> > >> > R-sig-mixed-models at r-project.org mailing list
>> > >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>
>> > >> _______________________________________________
>> > >> R-sig-mixed-models at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>
>> > >> -------------------------------------------------------------------
>> > >> ---- Confidentiality Notice: This e-mail message, including any
>> > >> attachments, is for the sole use of the intended recipient(s) and
>> > >> may contain privileged and confidential information. ?Any
>> > >> unauthorized review, use, disclosure or distribution is prohibited.
>> > >> If you are not the intended recipient, please contact the sender by
>> > >> reply e-mail and destroy all copies of the original message.
>> > >>
>> > >
>> >
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
>> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
>> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
>> bevestigd is door een geldig ondertekend document.
>> The views expressed in this message and any annex are purely those of the
>> writer and may not be regarded as stating an official position of INBO, as
>> long as the message is not confirmed by a duly signed document.
>
>


From istazahn at gmail.com  Wed May  2 16:51:23 2012
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 2 May 2012 10:51:23 -0400
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CAOLJphm82gkZicJw0u+JfeThgYaEFL7OfoCEk50tnjg_WgTXLQ@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
	<CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>
	<CAOLJph=O8VXQ9PES37Ym6Aw07O8AR8F8mzwSmMwsj6FRgrnTRw@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275736AFF3@inbomail.inbo.be>
	<CAOLJphm82gkZicJw0u+JfeThgYaEFL7OfoCEk50tnjg_WgTXLQ@mail.gmail.com>
Message-ID: <CA+vqiLHD8Gb-0rpzCnyNouKPNfp-pmFs7o4US8GxY4Ysr6fEdw@mail.gmail.com>

On Wed, May 2, 2012 at 9:31 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Thank you Thierry,
>
> To answer your questions, I am sure it applies the same test as the simple
> model matches perfectly.? Furthermore, two of the interaction model
> components match but the two 'middle' effects are very different.? As such,
> I was wondering if there was something in the R syntax that would throw this
> off

This is not a useful way to think about it. I still don't think you've
understood what the Event and Died terms represent. The Event term is
the effect of Event when DIed is zero. The Died term is the effect of
Died when Event is zero. So it matters how the contrasts are set up,
because this will change where the zero point is! Despite your
assurances that the contrasts are the same (how did you verify this?)
I remain confident that this is the most likely source of the
difference between the R and SAS results

and haven't preoccupied myself with the calculation of the F-value as
> this is a multivariate dataset.

Yes, good, I don't think this is needed.

Best,
Ista

The relevance here is that this is a
> practice set to see if I can replicate the mixed model analysis in R.

Yes, usually one can. But it won't always be easy to get the settings
to match, as you've discovered!

Best,
Ista

>
> Regards,
> Charles
>
>
> On Wed, May 2, 2012 at 8:24 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>
> wrote:
>>
>> Dear Charles,
>>
>> Are you sure that SAS and lme apply the same tests? So you'll need to know
>> how the F-values are calculated. Futhermore: what is the relevance of
>> testing the effect of a main effect when an interaction with that main
>> effect is present?
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> + 32 2 525 02 51
>> + 32 54 43 61 85
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Charles Determan Jr
>> Verzonden: woensdag 2 mei 2012 15:14
>> Aan: Ista Zahn
>> CC: r-sig-mixed-models at r-project.org
>> Onderwerp: Re: [R-sig-ME] lme interaction result strange
>>
>> I have checked the contrasts and 'unfortunately' they are identical. ?Is
>> that a statistically correct avenue to just take the interaction term from
>> the interaction model and use the first ones? ?That seems odd to me as the
>> numbers aren't the same even in the SAS output between the models. ?I
>> certainly appreciate your prior suggestion but perhaps you or someone else
>> has another idea? ?Something else seems to be strange, perhaps the syntax
>> needs to be different when doing an interaction term?
>>
>> Thanks,
>> Charles
>>
>> On Tue, May 1, 2012 at 2:02 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> > Hi Charles,
>> >
>> > Ask yourself what the Event_name and Died terms represent in this
>> > model. When you understand that, you'll understand why you need to
>> > know what contrasts were used if you hope to correctly interpret these
>> > terms.
>> >
>> > Alternatively, you can interpret the Event_name and Died terms from
>> > the first model (without the interaction term), and interpret just the
>> > interaction term from this model (so-called type II sums of squares by
>> > some).
>> >
>> > Best,
>> > Ista
>> >
>> > On Tue, May 1, 2012 at 2:54 PM, Charles Determan Jr <deter088 at umn.edu>
>> > wrote:
>> > > I have yet to attempt the contrast suggestion yet but here is the
>> > > SAS
>> > output
>> > > to complement the R.
>> > >
>> > > SAS output for the simple and interaction models. ?I have presented
>> > > the
>> > Type
>> > > III tests for simplicity. ?As you can see from my prior R output,
>> > > the DFs match exactly. ?The only variation is with the F and p value
>> > > of the Event_name and Died in the interaction model.
>> > >
>> > > Type 3 Tests of Fixed Effects
>> > >
>> > > Effect ? ? ? ? ? ?NumDF DenDF F Value Pr > F
>> > >
>> > > group ? ? ? ? ? ? ? ?1 ? ? ? ? ? ?23 ? ? ? ? ?0.65 ? ?0.4293
>> > >
>> > > Event_name ? ? 5 ? ? ? ? ? ?96 ? ? ? ? ?2.09 ? ?0.0738
>> > >
>> > > Died ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ?23 ? ? ? ? ?1.83 ? ?0.1889
>> > >
>> > >
>> > >
>> > > Type 3 Tests of Fixed Effects
>> > >
>> > > Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF ? ? F Value Pr > F
>> > >
>> > > group ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ?23 ? ? ? ? ? 0.47
>> > > 0.5015
>> > >
>> > > Event_name ? ? ? ? ? ?5 ? ? ? ? ? ? ?91 ? ? ? ? ? 2.62 ? ?0.0290
>> > >
>> > > Died ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ?23 ? ? ? ? ? 2.44
>> > > 0.1318
>> > >
>> > > Event_name*Died 5 ? ? ? ? ? ? ?91 ? ? ? ? ?1.10 ? ? 0.3637
>> > >
>> > >
>> > > R output of interaction model
>> > >
>> > > ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
>> > > (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
>> > >
>> > > group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
>> > > Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
>> > > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
>> > > Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
>> > > Done.
>> > >
>> > >
>> > > Regards,
>> > >
>> > > Charles
>> > >
>> > >
>> > >
>> > > On Tue, May 1, 2012 at 1:39 PM, Thompson,Paul
>> > > <Paul.Thompson at sanfordhealth.org> wrote:
>> > >>
>> > >> There is another issue. From the error df, it seems like this is a
>> > >> multi-level/RM/multiple obs study, and SAS and R do not always
>> > >> agree on
>> > the
>> > >> computation of the df, as well as the type of SS that is being
>> > computed. You
>> > >> need to present both outputs, so that we can see both.
>> > >>
>> > >> I know almost nothing about R, and so my comments may not be
>> > >> relevant.
>> > >>
>> > >> -----Original Message-----
>> > >> From: r-sig-mixed-models-bounces at r-project.org
>> > >> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ista
>> > Zahn
>> > >> Sent: Tuesday, May 01, 2012 12:51 PM
>> > >> To: Charles Determan Jr
>> > >> Cc: r-sig-mixed-models at r-project.org
>> > >> Subject: Re: [R-sig-ME] lme interaction result strange
>> > >>
>> > >> Hi Charles,
>> > >>
>> > >> My first guess is that you have (a) categorical variable(s) in your
>> > >> predictors, and that the contrasts in SAS are different than those
>> > >> in R.
>> > >>
>> > >> Best,
>> > >> Ista
>> > >>
>> > >> On Tue, May 1, 2012 at 1:39 PM, Charles Determan Jr
>> > >> <deter088 at umn.edu>
>> > >> wrote:
>> > >> > Dear R users,
>> > >> >
>> > >> > I have been working on replicating some linear mixed models from
>> > >> > SAS.
>> > >> > ?The
>> > >> > first one matches perfectly when the SAS model is simple with the
>> > three
>> > >> > separate factors.
>> > >> >
>> > >> > fit=lme(var~group+Event_name+Died,
>> > >> > ? ?data=liv34,
>> > >> > ? ?random=~1|ID)
>> > >> > anova.lme(fit, type="marginal", adjustSigma=F)
>> > >> >
>> > >> > However, once I put an interaction into the formula the values
>> > >> > don't match.
>> > >> >
>> > >> > fit=lme(var~group+Event_name+Died+Event_name*Died,
>> > >> > ? ?data=liv34,
>> > >> > ? ?random=~1|ID)
>> > >> > anova.lme(fit, type="marginal", adjustSigma=F)
>> > >> >
>> > >> > ? ? ? ? ? ? ? ? ? ? ? ? ?numDF denDF ? ? F-value ? ? ?p-value
>> > >> > (Intercept) ? ? ? ? ? ? ? 1 ? ? ? ?91 ? ? ? 111.20483 ?<.0001
>> > >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ?23 ? ? ? ?0.46632 ? ? 0.5015
>> > >> > Event_name ? ? ? ? ? ?5 ? ? ? ?91 ? ? ? ?1.14042 ? ? *0.3449*
>> > >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ?23 ? ? ? ?0.50989 ? ?* 0.4824*
>> > >> > Event_name:Died ? ? 5 ? ? ? 91 ? ? ? ?1.10436 ? ? 0.3637
>> > >> > Done.
>> > >> >
>> > >> > The numbers *bold* don't match up. ?They should be approximately
>> > >> > .0290 and
>> > >> > .1318 respectively. ?The other two are still exact matches. ?I
>> > >> > know looking for exact matches is ambitious but the numbers
>> > >> > should be at least similar that the conclusions don't change so
>> > >> > drastically.
>> > >> >
>> > >> > Any thoughts as to why this discrepancy is happening would be
>> > >> > most appreciated.
>> > >> >
>> > >> > Regards,
>> > >> >
>> > >> > Charles
>> > >> >
>> > >> > ? ? ? ?[[alternative HTML version deleted]]
>> > >> >
>> > >> > _______________________________________________
>> > >> > R-sig-mixed-models at r-project.org mailing list
>> > >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>
>> > >> _______________________________________________
>> > >> R-sig-mixed-models at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>
>> > >> -------------------------------------------------------------------
>> > >> ---- Confidentiality Notice: This e-mail message, including any
>> > >> attachments, is for the sole use of the intended recipient(s) and
>> > >> may contain privileged and confidential information. ?Any
>> > >> unauthorized review, use, disclosure or distribution is prohibited.
>> > >> If you are not the intended recipient, please contact the sender by
>> > >> reply e-mail and destroy all copies of the original message.
>> > >>
>> > >
>> >
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
>> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
>> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
>> bevestigd is door een geldig ondertekend document.
>> The views expressed in this message and any annex are purely those of the
>> writer and may not be regarded as stating an official position of INBO, as
>> long as the message is not confirmed by a duly signed document.
>
>


From deter088 at umn.edu  Wed May  2 22:02:48 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 2 May 2012 15:02:48 -0500
Subject: [R-sig-ME] lme interaction result strange
In-Reply-To: <CA+vqiLHD8Gb-0rpzCnyNouKPNfp-pmFs7o4US8GxY4Ysr6fEdw@mail.gmail.com>
References: <CAOLJph=RQ-HjoqCqww-bhgrbwE_pd=p2B4EUzSdPndc4eo6HeQ@mail.gmail.com>
	<CA+vqiLGymS6F5ioRb=p+=Ye-iS1+m2YRKPaioYfWYOOcGmPTuQ@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D972B2304C9@SFPCEXMBX2.sanfordhealth.org>
	<CAOLJphneeUV3G2F=oG8Y9sOOmboWqBR+EW5Uq6X5GDftNR==6A@mail.gmail.com>
	<CA+vqiLFV66Bi_S=eH6JJ4LrK8yn4jJePRe7PDRURogQw+S1Nww@mail.gmail.com>
	<CAOLJph=O8VXQ9PES37Ym6Aw07O8AR8F8mzwSmMwsj6FRgrnTRw@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA74275736AFF3@inbomail.inbo.be>
	<CAOLJphm82gkZicJw0u+JfeThgYaEFL7OfoCEk50tnjg_WgTXLQ@mail.gmail.com>
	<CA+vqiLHD8Gb-0rpzCnyNouKPNfp-pmFs7o4US8GxY4Ysr6fEdw@mail.gmail.com>
Message-ID: <CAOLJphn13k5gMLVEeoHDvdPZ69jpCy5NZNVXC0gQnEjfoRW_DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120502/708cb93c/attachment.pl>

From bonamy at horus.ens.fr  Thu May  3 12:57:36 2012
From: bonamy at horus.ens.fr (Pierre de Villemereuil)
Date: Thu, 03 May 2012 12:57:36 +0200
Subject: [R-sig-ME] pedigreemm and heritability of binary data
Message-ID: <4FA264A0.4060903@horus.ens.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120503/db9bde95/attachment.pl>

From jphughes at u.washington.edu  Wed May  2 01:24:06 2012
From: jphughes at u.washington.edu (James Hughes)
Date: Tue, 1 May 2012 16:24:06 -0700 (Pacific Daylight Time)
Subject: [R-sig-ME] Specification of design matrix for random effects (Z)
Message-ID: <alpine.WNT.2.00.1205011614190.1864@Hughes-J.cfas.washington.edu>

Hello

I would like to specify the following model using lmer:

Y_ij ~ Binomial(N,p_ij)

p_ij = u + b_i + b_j

where b ~ N(0,s^2).

For example, for the 5 observations (Y_12, Y_13, Y_23, Y_14, Y_24) the 
random effect vector would be b = (b_1, b_2, b_3, b_4) and the design 
matrix for the random effects (Z) would be

Z <- matrix(c(1,1,0,0, 1,0,1,0, 0,1,1,0, 1,0,0,1, 0,1,0,1),5,4,byrow=T)

Can such a model be specified in lmer? Thanks for your thoughts.

Jim


From Thierry.ONKELINX at inbo.be  Thu May  3 13:41:35 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 3 May 2012 11:41:35 +0000
Subject: [R-sig-ME] Specification of design matrix for random effects (Z)
In-Reply-To: <alpine.WNT.2.00.1205011614190.1864@Hughes-J.cfas.washington.edu>
References: <alpine.WNT.2.00.1205011614190.1864@Hughes-J.cfas.washington.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA74275736B79C@inbomail.inbo.be>

Dear James,

I don't think that it is possible with lme4. But it is a Bradley Terry model, so:

library(sos)
findFn("bradley terry")

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens James Hughes
Verzonden: woensdag 2 mei 2012 1:24
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Specification of design matrix for random effects (Z)

Hello

I would like to specify the following model using lmer:

Y_ij ~ Binomial(N,p_ij)

p_ij = u + b_i + b_j

where b ~ N(0,s^2).

For example, for the 5 observations (Y_12, Y_13, Y_23, Y_14, Y_24) the random effect vector would be b = (b_1, b_2, b_3, b_4) and the design matrix for the random effects (Z) would be

Z <- matrix(c(1,1,0,0, 1,0,1,0, 0,1,1,0, 1,0,0,1, 0,1,0,1),5,4,byrow=T)

Can such a model be specified in lmer? Thanks for your thoughts.

Jim

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bbolker at gmail.com  Thu May  3 14:31:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 May 2012 12:31:51 +0000 (UTC)
Subject: [R-sig-ME] Covariance structure specification
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
Message-ID: <loom.20120503T142736-959@post.gmane.org>

Angelina Mukherjee <angelina.mukherjee88 at ...> writes:

> I have response measures corresponding to 2 patients. The structure is as
> follows:
> 
> Patient 1:  Region 1             Region 2              Region 3
>                S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4
> 
> Patient 2:  Region 1               Region 2            Region 3
>                 S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4


  Hmm.  Do you really have only two patients, i.e. a total of
24 response values?  I understand that you're trying to do a
variance decomposition here (no fixed effects, only random
effects), but your estimates of variance will be extremely
inaccurate based on only two patients (you might want to consider
making patient a fixed effect, then you would at least have
6 data points (5 df) for the patient:region variance ...
 
> Each patient has 3 regions and each region has 4 sub-regions. (nested
> design)
> 
> Fitting   *lme( Response ~ 1, random=~ Patient + Region +Subregion |
> Patient/Region/Subregion )*
> allows me to specify covariance structure for the 'sub-region' term.
> 
> But I'm trying to fit a random effects model of the form as I have only 1
> observation per 'sub-region':
> *lme( Response ~ 1, random=~ Patient + Region | Patient/Region )*
> 
> Is there a way I can specify a covariance structure like
> the auto-regressive (to specify that correlation decreases with distance as
> one moves from Subregion 1 to Subregion 4) for the 'sub-region' term only
> as it is not included in my random effects model but I'd like to account
> for the correlation in it?

   I would think that something like

lme(Response~1, random = ~1|Patient/Region,
   correlation=corAR1(~Subregion))

  But I also think you're fitting a more complicated model
than can really be supported by 24 data points ...

  Ben Bolker


From Freedom.Gumedze at uct.ac.za  Thu May  3 14:46:14 2012
From: Freedom.Gumedze at uct.ac.za (Freedom Gumedze)
Date: Thu, 03 May 2012 14:46:14 +0200
Subject: [R-sig-ME] Extracting variances of the estimated variance
 components in lme4
In-Reply-To: <loom.20120503T142736-959@post.gmane.org>
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
	<loom.20120503T142736-959@post.gmane.org>
Message-ID: <4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>

Dear all,
 
How does one extract extracting variances of the variance components in
lme4?
vcov(model) only gives the covariance matrix of fixed part of the
fitted model,
while VarCorr(model) only gives the estimated variance components
without their corresponding standard errors.
Yes the standard errors are asymptotic but how does one extract them
from the fit?
 
many thanks,
Freedom
>>> Ben Bolker <bbolker at gmail.com> 2012/05/03 02:31 PM >>>
Angelina Mukherjee <angelina.mukherjee88 at ...> writes:

> I have response measures corresponding to 2 patients. The structure
is as
> follows:
> 
> Patient 1:  Region 1             Region 2              Region 3
>                S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4
> 
> Patient 2:  Region 1               Region 2            Region 3
>                 S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4


  Hmm.  Do you really have only two patients, i.e. a total of
24 response values?  I understand that you're trying to do a
variance decomposition here (no fixed effects, only random
effects), but your estimates of variance will be extremely
inaccurate based on only two patients (you might want to consider
making patient a fixed effect, then you would at least have
6 data points (5 df) for the patient:region variance ...

> Each patient has 3 regions and each region has 4 sub-regions.
(nested
> design)
> 
> Fitting   *lme( Response ~ 1, random=~ Patient + Region +Subregion |
> Patient/Region/Subregion )*
> allows me to specify covariance structure for the 'sub-region' term.
> 
> But I'm trying to fit a random effects model of the form as I have
only 1
> observation per 'sub-region':
> *lme( Response ~ 1, random=~ Patient + Region | Patient/Region )*
> 
> Is there a way I can specify a covariance structure like
> the auto-regressive (to specify that correlation decreases with
distance as
> one moves from Subregion 1 to Subregion 4) for the 'sub-region' term
only
> as it is not included in my random effects model but I'd like to
account
> for the correlation in it?

   I would think that something like

lme(Response~1, random = ~1|Patient/Region,
   correlation=corAR1(~Subregion))

  But I also think you're fitting a more complicated model
than can really be supported by 24 data points ...

  Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





###

UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mail disclaimer
published on our website at
http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from
+27 21 650 9111. This e-mail is intended only for the person(s) to whom
it is addressed. If the e-mail has reached you in error, please notify
the author. If you are not the intended recipient of the e-mail you may
not use, disclose, copy, redirect or print the content. If this e-mail
is not related to the business of UCT it is sent by the sender in the
sender's individual capacity.

###

From Thierry.ONKELINX at inbo.be  Thu May  3 15:32:13 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 3 May 2012 13:32:13 +0000
Subject: [R-sig-ME] Extracting variances of the estimated variance
 components in lme4
In-Reply-To: <4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
	<loom.20120503T142736-959@post.gmane.org>
	<4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>
Message-ID: <AA818EAD2576BC488B4F623941DA74275736B86C@inbomail.inbo.be>

Dear Freedom,

Please note that the Std. Dev. In the model output is the standard deviation of the random effects (sigma) and thus exactly the square root of the variance (sigma ^ 2). It is *NOT* the standard error of the variance. That information is not available in the output of lme() or lmer().

If you want confidence intervals on the variance, then you have to do some math. Since (n - 1) s ^2 / sigma ^ 2  ~ chisq(n - 1). You could approxiate it by

library(lme4)
model <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
s2 <- VarCorr(model)$Subject[1]
n <- nrow(ranef(model)$Subject)
CI <- (n - 1) * s2 / qchisq(c(0.975, 0.025), df = n - 1)
CI

Note that confidence intervals will be very wide unless you have a very large number of random effect levels.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Freedom Gumedze
Verzonden: donderdag 3 mei 2012 14:46
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Extracting variances of the estimated variance components in lme4

Dear all,

How does one extract extracting variances of the variance components in lme4?
vcov(model) only gives the covariance matrix of fixed part of the fitted model, while VarCorr(model) only gives the estimated variance components without their corresponding standard errors.
Yes the standard errors are asymptotic but how does one extract them from the fit?

many thanks,
Freedom
>>> Ben Bolker <bbolker at gmail.com> 2012/05/03 02:31 PM >>>
Angelina Mukherjee <angelina.mukherjee88 at ...> writes:

> I have response measures corresponding to 2 patients. The structure
is as
> follows:
>
> Patient 1:  Region 1             Region 2              Region 3
>                S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4
>
> Patient 2:  Region 1               Region 2            Region 3
>                 S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4


  Hmm.  Do you really have only two patients, i.e. a total of
24 response values?  I understand that you're trying to do a variance decomposition here (no fixed effects, only random effects), but your estimates of variance will be extremely inaccurate based on only two patients (you might want to consider making patient a fixed effect, then you would at least have
6 data points (5 df) for the patient:region variance ...

> Each patient has 3 regions and each region has 4 sub-regions.
(nested
> design)
>
> Fitting   *lme( Response ~ 1, random=~ Patient + Region +Subregion |
> Patient/Region/Subregion )*
> allows me to specify covariance structure for the 'sub-region' term.
>
> But I'm trying to fit a random effects model of the form as I have
only 1
> observation per 'sub-region':
> *lme( Response ~ 1, random=~ Patient + Region | Patient/Region )*
>
> Is there a way I can specify a covariance structure like the
> auto-regressive (to specify that correlation decreases with
distance as
> one moves from Subregion 1 to Subregion 4) for the 'sub-region' term
only
> as it is not included in my random effects model but I'd like to
account
> for the correlation in it?

   I would think that something like

lme(Response~1, random = ~1|Patient/Region,
   correlation=corAR1(~Subregion))

  But I also think you're fitting a more complicated model than can really be supported by 24 data points ...

  Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





###

UNIVERSITY OF CAPE TOWN

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:19}}


From karelvia at gmail.com  Thu May  3 14:34:24 2012
From: karelvia at gmail.com (Karel Viaene)
Date: Thu, 03 May 2012 14:34:24 +0200
Subject: [R-sig-ME] How to test if two gamm-predictions are significantly
	different?
Message-ID: <4FA27B50.8010106@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120503/0d8ad72d/attachment.pl>

From bates at stat.wisc.edu  Thu May  3 16:01:12 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 3 May 2012 09:01:12 -0500
Subject: [R-sig-ME] Extracting variances of the estimated variance
 components in lme4
In-Reply-To: <4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
	<loom.20120503T142736-959@post.gmane.org>
	<4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>
Message-ID: <CAO7JsnQdQO4uNtAaPjjDTxdm19zK3fpSQyoqY2y+Y=qipBgUxQ@mail.gmail.com>

On Thu, May 3, 2012 at 7:46 AM, Freedom Gumedze
<Freedom.Gumedze at uct.ac.za> wrote:
> Dear all,
>
> How does one extract extracting variances of the variance components in
> lme4?
> vcov(model) only gives the covariance matrix of fixed part of the
> fitted model,
> while VarCorr(model) only gives the estimated variance components
> without their corresponding standard errors.
> Yes the standard errors are asymptotic but how does one extract them
> from the fit?

The omission of standard errors on variance components is intentional.
 The distribution of an estimator of a variance component is highly
skewed and obtaining an estimate of the standard deviation of a skewed
distribution is not very useful.  A much better approach is based on
profiling the objective function.  See
http://lme4.R-forge.R-project.org/slides/2012-03-22-Paris/Profiling.pdf
(that URL may not be visible for an hour or so).


> many thanks,
> Freedom
>>>> Ben Bolker <bbolker at gmail.com> 2012/05/03 02:31 PM >>>
> Angelina Mukherjee <angelina.mukherjee88 at ...> writes:
>
>> I have response measures corresponding to 2 patients. The structure
> is as
>> follows:
>>
>> Patient 1: ?Region 1 ? ? ? ? ? ? Region 2 ? ? ? ? ? ? ?Region 3
>> ? ? ? ? ? ? ? ?S1 S2 S3 S4 ? ? ? S1 S2 S3 S4 ? ? ? ?S1 S2 S3 S4
>>
>> Patient 2: ?Region 1 ? ? ? ? ? ? ? Region 2 ? ? ? ? ? ?Region 3
>> ? ? ? ? ? ? ? ? S1 S2 S3 S4 ? ? ? S1 S2 S3 S4 ? ? ? ?S1 S2 S3 S4
>
>
> ?Hmm. ?Do you really have only two patients, i.e. a total of
> 24 response values? ?I understand that you're trying to do a
> variance decomposition here (no fixed effects, only random
> effects), but your estimates of variance will be extremely
> inaccurate based on only two patients (you might want to consider
> making patient a fixed effect, then you would at least have
> 6 data points (5 df) for the patient:region variance ...
>
>> Each patient has 3 regions and each region has 4 sub-regions.
> (nested
>> design)
>>
>> Fitting ? *lme( Response ~ 1, random=~ Patient + Region +Subregion |
>> Patient/Region/Subregion )*
>> allows me to specify covariance structure for the 'sub-region' term.
>>
>> But I'm trying to fit a random effects model of the form as I have
> only 1
>> observation per 'sub-region':
>> *lme( Response ~ 1, random=~ Patient + Region | Patient/Region )*
>>
>> Is there a way I can specify a covariance structure like
>> the auto-regressive (to specify that correlation decreases with
> distance as
>> one moves from Subregion 1 to Subregion 4) for the 'sub-region' term
> only
>> as it is not included in my random effects model but I'd like to
> account
>> for the correlation in it?
>
> ? I would think that something like
>
> lme(Response~1, random = ~1|Patient/Region,
> ? correlation=corAR1(~Subregion))
>
> ?But I also think you're fitting a more complicated model
> than can really be supported by 24 data points ...
>
> ?Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
> ###
>
> UNIVERSITY OF CAPE TOWN
>
> This e-mail is subject to the UCT ICT policies and e-mail disclaimer
> published on our website at
> http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from
> +27 21 650 9111. This e-mail is intended only for the person(s) to whom
> it is addressed. If the e-mail has reached you in error, please notify
> the author. If you are not the intended recipient of the e-mail you may
> not use, disclose, copy, redirect or print the content. If this e-mail
> is not related to the business of UCT it is sent by the sender in the
> sender's individual capacity.
>
> ###
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Freedom.Gumedze at uct.ac.za  Thu May  3 16:22:04 2012
From: Freedom.Gumedze at uct.ac.za (Freedom Gumedze)
Date: Thu, 03 May 2012 16:22:04 +0200
Subject: [R-sig-ME] Extracting variances of the estimated variance
 components in lme4
In-Reply-To: <CAO7JsnQdQO4uNtAaPjjDTxdm19zK3fpSQyoqY2y+Y=qipBgUxQ@mail.gmail.com>
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
	<loom.20120503T142736-959@post.gmane.org>
	<4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>
	<CAO7JsnQdQO4uNtAaPjjDTxdm19zK3fpSQyoqY2y+Y=qipBgUxQ@mail.gmail.com>
Message-ID: <4FA2B0AD020000EE0009DDEE@gwiasmtp.uct.ac.za>

Douglas and Thierry,
 
Many thanks Douglas for the advice. I will look at the suggestion by
Douglas when the URL is visible.
The omission of the option for the standard errors of the estimated
variances (or std deviations) is understandable to avoid their 'abuse
e.g. in significance testing'. However, they should be available (if
needed) as they can be obtained from the inverse of information matrix
for the var. components.
 
Freedom  

>>> Douglas Bates <bates at stat.wisc.edu> 2012/05/03 04:01 PM >>>
On Thu, May 3, 2012 at 7:46 AM, Freedom Gumedze
<Freedom.Gumedze at uct.ac.za> wrote:
> Dear all,
>
> How does one extract extracting variances of the variance components
in
> lme4?
> vcov(model) only gives the covariance matrix of fixed part of the
> fitted model,
> while VarCorr(model) only gives the estimated variance components
> without their corresponding standard errors.
> Yes the standard errors are asymptotic but how does one extract them
> from the fit?

The omission of standard errors on variance components is intentional.
The distribution of an estimator of a variance component is highly
skewed and obtaining an estimate of the standard deviation of a skewed
distribution is not very useful.  A much better approach is based on
profiling the objective function.  See
http://lme4.R-forge.R-project.org/slides/2012-03-22-Paris/Profiling.pdf
(that URL may not be visible for an hour or so).


> many thanks,
> Freedom
>>>> Ben Bolker <bbolker at gmail.com> 2012/05/03 02:31 PM >>>
> Angelina Mukherjee <angelina.mukherjee88 at ...> writes:
>
>> I have response measures corresponding to 2 patients. The structure
> is as
>> follows:
>>
>> Patient 1:  Region 1             Region 2              Region 3
>>                S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4
>>
>> Patient 2:  Region 1               Region 2            Region 3
>>                 S1 S2 S3 S4       S1 S2 S3 S4        S1 S2 S3 S4
>
>
>  Hmm.  Do you really have only two patients, i.e. a total of
> 24 response values?  I understand that you're trying to do a
> variance decomposition here (no fixed effects, only random
> effects), but your estimates of variance will be extremely
> inaccurate based on only two patients (you might want to consider
> making patient a fixed effect, then you would at least have
> 6 data points (5 df) for the patient:region variance ...
>
>> Each patient has 3 regions and each region has 4 sub-regions.
> (nested
>> design)
>>
>> Fitting   *lme( Response ~ 1, random=~ Patient + Region +Subregion
|
>> Patient/Region/Subregion )*
>> allows me to specify covariance structure for the 'sub-region'
term.
>>
>> But I'm trying to fit a random effects model of the form as I have
> only 1
>> observation per 'sub-region':
>> *lme( Response ~ 1, random=~ Patient + Region | Patient/Region )*
>>
>> Is there a way I can specify a covariance structure like
>> the auto-regressive (to specify that correlation decreases with
> distance as
>> one moves from Subregion 1 to Subregion 4) for the 'sub-region'
term
> only
>> as it is not included in my random effects model but I'd like to
> account
>> for the correlation in it?
>
>   I would think that something like
>
> lme(Response~1, random = ~1|Patient/Region,
>   correlation=corAR1(~Subregion))
>
>  But I also think you're fitting a more complicated model
> than can really be supported by 24 data points ...
>
>  Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
> ###
>
> UNIVERSITY OF CAPE TOWN
>
> This e-mail is subject to the UCT ICT policies and e-mail disclaimer
> published on our website at
> http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable
from
> +27 21 650 9111. This e-mail is intended only for the person(s) to
whom
> it is addressed. If the e-mail has reached you in error, please
notify
> the author. If you are not the intended recipient of the e-mail you
may
> not use, disclose, copy, redirect or print the content. If this
e-mail
> is not related to the business of UCT it is sent by the sender in
the
> sender's individual capacity.
>
> ###
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>





###

UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mail disclaimer
published on our website at
http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from
+27 21 650 9111. This e-mail is intended only for the person(s) to whom
it is addressed. If the e-mail has reached you in error, please notify
the author. If you are not the intended recipient of the e-mail you may
not use, disclose, copy, redirect or print the content. If this e-mail
is not related to the business of UCT it is sent by the sender in the
sender's individual capacity.

###
 

From angelina.mukherjee88 at gmail.com  Thu May  3 16:39:21 2012
From: angelina.mukherjee88 at gmail.com (Angelina Mukherjee)
Date: Thu, 3 May 2012 15:39:21 +0100
Subject: [R-sig-ME] Covariance structure specification
In-Reply-To: <loom.20120503T142736-959@post.gmane.org>
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
	<loom.20120503T142736-959@post.gmane.org>
Message-ID: <CAMFXY1k_v6YTG6-W6sEEPMpNArKYObVAxObyq3Zw2NMHW2mniA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120503/29aa31ee/attachment.pl>

From smartpink111 at yahoo.com  Thu May  3 20:05:11 2012
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 May 2012 11:05:11 -0700 (PDT)
Subject: [R-sig-ME] Nested subject-longitudinal logit design
Message-ID: <1336068311.32240.YahooMailNeo@web39402.mail.mud.yahoo.com>

Dear R mixed group,

I posted recently regarding inputs for a longitudinal logit model using lme4.? I got some valuable comments from the group.? Still, I have some doubts regarding the random effects in the model.? For e.g., in the model below, I am measuring the binary response (1- insect present in light area, 0- insect present in dark area) as dependent variable, with fixed effects of Wavelength (3 levels) of light applied on insect in a petridish (half-covered with aluminium foil) for a period starting from 1 min to 20 min.? Depending on the starting response (animal present in dark or light zone of petridish at 0 min), there is another factor (Start_Resp - 2 levels - L starting in light zone, D- starting in dark zone).? It was really important to introduce this factor, as the response is drastically different in both levels of the factor for each of the wavelengths.? Since, we are measuring the response every 1 min (0 or 1), for 20 min, time is also a factor with
 20 levels or a covariate. ? In the present model, I introduce time as a covariate and extracted deviations for individual measurements as a random effect in "resid".??
BehavdatOrig$resid<-as.factor(1:dim(BehavdatOrig)[1])

(fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject), family=binomial,data=BehavdatOrig)

If Wavelength, starting response are fixed effects and time as covariate, I think I can have an interaction term as Wavelength*Start_Resp*time.? But, subjects are not repeated for the experiment.? If I have column called "Rep" (replication) in the dataset for each treatment (another column - Treatment = Combination of Wavelength*Strain*Start_Resp) does it make sense to introduce Subject as nested within Treatment using the? 


BehavdatOrig <- within(BehavdatOrig, Subject <- factor(Treatment:Rep)) 


It is an unbalanced dataset with respect to number of replications.? I made a mistake in my previous analysis as I used Subject as replicates which gave me completely different results.? The shrink fit model graph for each subject looks to have small deviations from the population.? In this scenario, should I have to replace this model with quasibinomial model.


?Quasibinomial model with cbind( sum of response for every 5 minute, and 5-response) with this new settings.? For one thing, there is no quasibinomial link function in lmer, still I used binomial link to get results.? Another problem with quasibinomial is that I am not able to get the shrink fit graph with quasibinomal response.? Should be a problem with lattice graph plots.? Any advice on this direction will be appreicated. ?? 


Thanking you,

A.K.


The above fm model provides output as:
Formula: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 +????? time | Subject) 
?? Data: BehavdatOrig 
? AIC? BIC logLik deviance
?1323 1413 -645.7???? 1291
Random effects:
?Groups? Name??????? Variance?? Std.Dev.?? Corr?? 
?resid?? (Intercept) 8.3103e-12 2.8828e-06??????? 
?Subject (Intercept) 1.6026e+01 4.0033e+00??????? 
???????? time??????? 1.2760e-01 3.5722e-01 -0.552 
Number of obs: 1960, groups: resid, 1960; Subject, 98



I also tried uncorrelated model fma. 


Formula: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 |????? Subject) + (0 + time | Subject) 
?? Data: BehavdatOrig 
? AIC? BIC logLik deviance
?1333 1417 -651.6???? 1303
Random effects:
?Groups? Name??????? Variance?? Std.Dev.? 
?resid?? (Intercept) 6.9660e-14 2.6393e-07
?Subject time??????? 1.0964e-01 3.3112e-01
?Subject (Intercept) 1.1732e+01 3.4252e+00
et results:

Anova comparison favors the correlated model:
> anova(fma,fm)
Data: BehavdatOrig
Models:
fma: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 | 
fma:???? Subject) + (0 + time | Subject)
fm: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 + 
fm:???? time | Subject)
??? Df??? AIC??? BIC? logLik? Chisq Chi Df Pr(>Chisq)??? 
fma 15 1333.2 1416.9 -651.57???????????????????????????? 
fm? 16 1323.4 1412.7 -645.69 11.767????? 1? 0.0006031 ***


From bbolker at gmail.com  Thu May  3 20:44:23 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 May 2012 18:44:23 +0000 (UTC)
Subject: [R-sig-ME] Nested subject-longitudinal logit design
References: <1336068311.32240.YahooMailNeo@web39402.mail.mud.yahoo.com>
Message-ID: <loom.20120503T202246-303@post.gmane.org>

arun <smartpink111 at ...> writes:
 
> I posted recently regarding inputs for a longitudinal logit model
> using lme4.? 

[snip]

> ... I am measuring the binary response (1- insect present in light
> area, 0- insect present in dark area) as dependent variable, with
> fixed effects of Wavelength (3 levels) of light applied on insect in
> a petridish (half-covered with aluminium foil) for a period starting
> from 1 min to 20 min.?  Depending on the starting response (animal
> present in dark or light zone of petridish at 0 min), there is
> another factor (Start_Resp - 2 levels - L starting in light zone, D-
> starting in dark zone).? It was really important to introduce this
> factor, as the response is drastically different in both levels of
> the factor for each of the wavelengths.?  Since, we are measuring
> the response every 1 min (0 or 1), for 20 min, time is also a factor
> with 20 levels or a covariate. ? In the present model, I introduce
> time as a covariate and extracted deviations for individual
> measurements as a random effect in "resid".

> BehavdatOrig$resid<-as.factor(1:dim(BehavdatOrig)[1])

  I would say that factor(1:nrow(BehavdatOrig)) is slightly
more readable, but OK

[A] (fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject), 
     family=binomial,data=BehavdatOrig)

This seems reasonable

> If Wavelength, starting response are fixed effects and time as
> covariate, I think I can have an interaction term as
> Wavelength*Start_Resp*time.? But, subjects are not repeated for the
> experiment.? 

I'm guessing this means that each individual is only measured
in a single level of Wavelength*Start_Resp ... ?

> If I have column called "Rep" (replication) in the
> dataset for each treatment (another column - Treatment = Combination
> of Wavelength*Strain*Start_Resp) does it make sense to introduce
> Subject as nested within Treatment using the?

 > BehavdatOrig <- within(BehavdatOrig, Subject <- factor(Treatment:Rep)) 

How is Subject coded?  i.e. is it coded 1..n_i for each Treatment:Rep
combination (explicit nesting), or is it coded 1..N for the entire
data set (implicit nesting)?

Similarly, how is Rep coded?

Assuming for the moment that Subject is implicitly nested and Rep is
explicitly nested, and that there is more than one Subject per Rep
(and that Rep is not crossed with Subject, i.e. each Subject is
measured only within a single Rep), then you should use something like

BehavdatOrig$RepNest <- with(BehavdatOrig,interaction(Treatment,Rep))

(1|resid) + (1+time|Subject) + (1|RepNest)

This allows for variation in intercept and slope across Subject, and
intercept (only) across RepNest.

  This specification would also be correct if Subject *were* crossed
with RepNest and numbered appropriately (i.e. 1..n for each level of
RepNest).  The only problem is if it is explicitly nested, in which
case you need (1+time|Subject:RepNest)

> It is an unbalanced dataset with respect to number of replications.?
> I made a mistake in my previous analysis as I used Subject as
> replicates which gave me completely different results.? The shrink
> fit model graph for each subject looks to have small deviations from
> the population.? In this scenario, should I have to replace this
> model with quasibinomial model.

  I don't know what the "shrink fit model graph" is ...

> ?Quasibinomial model with cbind( sum of response for every 5 minute,
> and 5-response) with this new settings.? For one thing, there is no
> quasibinomial link function in lmer, still I used binomial link to
> get results.? Another problem with quasibinomial is that I am not
> able to get the shrink fit graph with quasibinomal response.? Should
> be a problem with lattice graph plots.? Any advice on this direction
> will be appreicated.

   Not sure what's going on here.  Are you using

glmmPQL(...,family="quasibinomial")

(which is the only way I know of to fit quasibinomial GLMMs in R?)

Your inclusion of the 'resid' random effect above should have
taken care of overdispersion.



# The above fm model provides output as:
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + (1 +?time | Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1323 1413 -645.7???? 1291
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.?? Corr?? 
# ?resid?? (Intercept) 8.3103e-12 2.8828e-06??????? 
# ?Subject (Intercept) 1.6026e+01 4.0033e+00??????? 
# ???????? time??????? 1.2760e-01 3.5722e-01 -0.552 
# Number of obs: 1960, groups: resid, 1960; Subject, 98
# 
# I also tried uncorrelated model fma. 
# 
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + 
## (1 |?????Subject) + (0 + time |
# Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1333 1417 -651.6???? 1303
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.? 
# ?resid?? (Intercept) 6.9660e-14 2.6393e-07
# ?Subject time??????? 1.0964e-01 3.3112e-01
# ?Subject (Intercept) 1.1732e+01 3.4252e+00
# et results:
# 
# Anova comparison favors the correlated model:
# > anova(fma,fm)
# Data: BehavdatOrig
# Models:
# fma: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 | 
# fma:???? Subject) + (0 + time | Subject)
# fm: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 + 
# fm:???? time | Subject)
# ??? Df??? AIC??? BIC? logLik? Chisq Chi Df Pr(>Chisq)??? 
# fma 15 1333.2 1416.9 -651.57???????????????????????????? 
# fm? 16 1323.4 1412.7 -645.69 11.767????? 1? 0.0006031 ***


From smartpink111 at yahoo.com  Thu May  3 21:12:32 2012
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 May 2012 12:12:32 -0700 (PDT)
Subject: [R-sig-ME] Nested subject-longitudinal logit design
In-Reply-To: <loom.20120503T202246-303@post.gmane.org>
References: <1336068311.32240.YahooMailNeo@web39402.mail.mud.yahoo.com>
	<loom.20120503T202246-303@post.gmane.org>
Message-ID: <1336072352.63933.YahooMailNeo@web39404.mail.mud.yahoo.com>

Hi Ben,
Thanks for the quick response.



----- Original Message -----
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Cc: 
Sent: Thursday, May 3, 2012 2:44 PM
Subject: Re: [R-sig-ME] Nested subject-longitudinal logit design

arun <smartpink111 at ...> writes:

> I posted recently regarding inputs for a longitudinal logit model
> using lme4.? 

[snip]

> ... I am measuring the binary response (1- insect present in light
> area, 0- insect present in dark area) as dependent variable, with
> fixed effects of Wavelength (3 levels) of light applied on insect in
> a petridish (half-covered with aluminium foil) for a period starting
> from 1 min to 20 min.?? Depending on the starting response (animal
> present in dark or light zone of petridish at 0 min), there is
> another factor (Start_Resp - 2 levels - L starting in light zone, D-
> starting in dark zone).? It was really important to introduce this
> factor, as the response is drastically different in both levels of
> the factor for each of the wavelengths.?? Since, we are measuring
> the response every 1 min (0 or 1), for 20 min, time is also a factor
> with 20 levels or a covariate. ? In the present model, I introduce
> time as a covariate and extracted deviations for individual
> measurements as a random effect in "resid".

> BehavdatOrig$resid<-as.factor(1:dim(BehavdatOrig)[1])

? I would say that factor(1:nrow(BehavdatOrig)) is slightly
more readable, but OK

[A] (fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject), 
? ?  family=binomial,data=BehavdatOrig)

This seems reasonable

> If Wavelength, starting response are fixed effects and time as
> covariate, I think I can have an interaction term as
> Wavelength*Start_Resp*time.? But, subjects are not repeated for the
> experiment.? 

I'm guessing this means that each individual is only measured
in a single level of Wavelength*Start_Resp ... ?

Yes, it is only measured once in a single level of Wavelength*start_resp for 20 minutes.? After that, the animal is discarded.

> If I have column called "Rep" (replication) in the
> dataset for each treatment (another column - Treatment = Combination
> of Wavelength*Strain*Start_Resp) does it make sense to introduce
> Subject as nested within Treatment using the?

> BehavdatOrig <- within(BehavdatOrig, Subject <- factor(Treatment:Rep)) 

How is Subject coded?? i.e. is it coded 1..n_i for each Treatment:Rep
combination (explicit nesting), or is it coded 1..N for the entire
data set (implicit nesting)?

Similarly, how is Rep coded?

Subject is coded from 1..N (implicit nesting).? Rep is coded from 1:n_i for each treatment combination
 
Number Wavelength Strain Start_Resp Treatment Rep Subject time Response 
1 Red GAI L RedGAI_L 1 1 1 1 
2 Red GAI L RedGAI_L 1 1 2 1 
3 Red GAI L RedGAI_L 1 1 3 1 
4 Red GAI L RedGAI_L 1 1 4 0 
5 Red GAI L RedGAI_L 1 1 5 0 
6 Red GAI L RedGAI_L 1 1 6 0 
7 Red GAI L RedGAI_L 1 1 7 0 
8 Red GAI L RedGAI_L 1 1 8 0 
9 Red GAI L RedGAI_L 1 1 9 0 
10 Red GAI L RedGAI_L 1 1 10 0 
11 Red GAI L RedGAI_L 1 1 11 0 
12 Red GAI L RedGAI_L 1 1 12 0 
13 Red GAI L RedGAI_L 1 1 13 0 
14 Red GAI L RedGAI_L 1 1 14 0 
15 Red GAI L RedGAI_L 1 1 15 0 
16 Red GAI L RedGAI_L 1 1 16 0 
17 Red GAI L RedGAI_L 1 1 17 0 
18 Red GAI L RedGAI_L 1 1 18 0 
19 Red GAI L RedGAI_L 1 1 19 0 
20 Red GAI L RedGAI_L 1 1 20 0 
21 Red GAI L RedGAI_L 2 2 1 1 
22 Red GAI L RedGAI_L 2 2 2 1 ???????????? ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 
1921 Green GAI D Green_GAI_D 21 97 1 0 
1922 Green GAI D Green_GAI_D 21 97 2 0 
1923 Green GAI D Green_GAI_D 21 97 3 0 
1924 Green GAI D Green_GAI_D 21 97 4 0 
1925 Green GAI D Green_GAI_D 21 97 5 0 
1926 Green GAI D Green_GAI_D 21 97 6 0 
1927 Green GAI D Green_GAI_D 21 97 7 0 
1928 Green GAI D Green_GAI_D 21 97 8 0 







Assuming for the moment that Subject is implicitly nested and Rep is
explicitly nested, and that there is more than one Subject per Rep
(and that Rep is not crossed with Subject, i.e. each Subject is
measured only within a single Rep), then you should use something like

BehavdatOrig$RepNest <- with(BehavdatOrig,interaction(Treatment,Rep))

(1|resid) + (1+time|Subject) + (1|RepNest)

This allows for variation in intercept and slope across Subject, and
intercept (only) across RepNest.

It makes sense.


? This specification would also be correct if Subject *were* crossed
with RepNest and numbered appropriately (i.e. 1..n for each level of
RepNest).? The only problem is if it is explicitly nested, in which
case you need (1+time|Subject:RepNest)
?
?This is not the case.
> It is an unbalanced dataset with respect to number of replications.?
> I made a mistake in my previous analysis as I used Subject as
> replicates which gave me completely different results.? The shrink
> fit model graph for each subject looks to have small deviations from
> the population.? In this scenario, should I have to replace this
> model with quasibinomial model.

? I don't know what the "shrink fit model graph" is ...

I got the example graph from Douglas Bates lme4 chapter4.R (sleepstudy dataset).? I used the same settings, only changed the coefficient list to be used.

> ?Quasibinomial model with cbind( sum of response for every 5 minute,
> and 5-response) with this new settings.? For one thing, there is no
> quasibinomial link function in lmer, still I used binomial link to
> get results.? Another problem with quasibinomial is that I am not
> able to get the shrink fit graph with quasibinomal response.? Should
> be a problem with lattice graph plots.? Any advice on this direction
> will be appreicated.

?  Not sure what's going on here.? Are you using

glmmPQL(...,family="quasibinomial")

No, I was using lmer with binomial link. 


(which is the only way I know of to fit quasibinomial GLMMs in R?)

Your inclusion of the 'resid' random effect above should have
taken care of overdispersion.

Let me compare the results from lmer and glmmPQL.

Thank you 
A.K.

# The above fm model provides output as:
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + (1 +?time | Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1323 1413 -645.7???? 1291
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.?? Corr?? 
# ?resid?? (Intercept) 8.3103e-12 2.8828e-06??????? 
# ?Subject (Intercept) 1.6026e+01 4.0033e+00??????? 
# ???????? time??????? 1.2760e-01 3.5722e-01 -0.552 
# Number of obs: 1960, groups: resid, 1960; Subject, 98
# 
# I also tried uncorrelated model fma. 
# 
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + 
## (1 |?????Subject) + (0 + time |
# Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1333 1417 -651.6???? 1303
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.? 
# ?resid?? (Intercept) 6.9660e-14 2.6393e-07
# ?Subject time??????? 1.0964e-01 3.3112e-01
# ?Subject (Intercept) 1.1732e+01 3.4252e+00
# et results:
# 
# Anova comparison favors the correlated model:
# > anova(fma,fm)
# Data: BehavdatOrig
# Models:
# fma: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 | 
# fma:???? Subject) + (0 + time | Subject)
# fm: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 + 
# fm:???? time | Subject)
# ??? Df??? AIC??? BIC? logLik? Chisq Chi Df Pr(>Chisq)??? 
# fma 15 1333.2 1416.9 -651.57???????????????????????????? 
# fm? 16 1323.4 1412.7 -645.69 11.767????? 1? 0.0006031 ***

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From deter088 at umn.edu  Thu May  3 21:58:25 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 3 May 2012 14:58:25 -0500
Subject: [R-sig-ME] gls vs lme covariance structures
Message-ID: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120503/21983b4d/attachment.pl>

From jstraka at uvic.ca  Thu May  3 22:19:19 2012
From: jstraka at uvic.ca (J Straka)
Date: Thu, 3 May 2012 13:19:19 -0700
Subject: [R-sig-ME] Trouble running full ZINB or ZANB model: NaNs produced
	and errors in optim()
Message-ID: <CAAHjLoaOQCiTiOcAbRtza50T_8hLR73GHH1vEdhMH+_TBgbZ8Q@mail.gmail.com>

Hello,

I?m attempting to run zero-inflated and hurdle models using the pscl()
package, but keep encountering problems with running my
fully-parameterized model and I?m not sure why.
My data consist of measurements of seed set (the response, which is
zero-inflated and overdispersed) for two treatments and a control (B,
F, and O) at three elevations (low, mid, and high).? At each elevation
I also measured average temperature (AvgTemp) and abundance of insects
(N).? My goal is to construct a model that best describes seed set
using the four predictors above (and interactions, if necessary).
I find that I have no problems running a partial model with only my
two categorical predictors as follows (just an example using hurdle(),
but results are the same for zeroinfl()):

H1B <- hurdle(AVInt ~ Elev + Treatment ?| ?Elev + Treatment, dist =
"negbin", link = "logit", data = erytseeds)

It?s when I try to add the two continuous predictors that things begin
to get messy;

H4B <- hurdle(AVInt ~ Elev*Treatment*AvgTemp*N | Elev*Treatment*AvgTemp*N)

This results in the error:
Warning message:
In sqrt(diag(object$vcov)) : NaNs produced
Error in optim(fn = loglikfun, gr = gradfun, par = c(start$count, start$zero,? :
non-finite value supplied by optim

Even when I run the model using one continuous predictor and one
categorical predictor, or both continuous predictors, I end up with
NAs in the summary table of the count, but not in the zero-inflated
portion of the model.? For example:

>summary(H9B)

Call:
zeroinfl(AVInt ~ AvgTemp+N | AvgTemp+N, data = erytseeds, dist =
"negbin", link = "logit")

Pearson residuals:
Min????? 1Q? Median????? 3Q???? Max
-0.5807 -0.4566 -0.2791 -0.2791? 5.5813

Count model coefficients (negbin with log link):

???????????? Estimate Std. Error z value Pr(>|z|)
(Intercept) -3.770120?? 0.452221? -8.337?? <2e-16 ***
AvgTemp????? 0.404550?? 0.173458?? 2.332?? 0.0197 *
N??????????? 0.001211???????? NA????? NA?????? NA
Log(theta)?? 1.308387???????? NA????? NA?????? NA

Zero-inflation model coefficients (binomial with logit link):

????????????? Estimate Std. Error z value Pr(>|z|)
(Intercept) -4.814e+01? 8.115e+00? -5.932 2.99e-09 ***
AvgTemp????? 4.039e+00? 7.158e-01?? 5.642 1.68e-08 ***
N??????????? 3.010e-03? 4.863e-04?? 6.189 6.04e-10 ***

---
Theta = 3.7002
Number of iterations in BFGS optimization: 31
Log-likelihood: -456.4 on 7 Df

> summary(H10B)

Call:
zeroinfl(AVInt ~ Treatment+N | Treatment+N, data = erytseeds, dist =
"negbin", link = "logit")

Pearson residuals:
??? Min????? 1Q? Median????? 3Q???? Max
-0.6608 -0.4684 -0.3565 -0.2956? 6.1730

Count model coefficients (negbin with log link):

???????????? Estimate Std. Error z value Pr(>|z|)
(Intercept) 0.9555134???????? NA????? NA?????? NA
TreatmentF? 0.1407240? 0.1844811?? 0.763??? 0.446
TreatmentO? 0.0430166? 0.1647207?? 0.261??? 0.794
N?????????? 0.0009843???????? NA????? NA?????? NA
Log(theta)? 1.3049021???????? NA????? NA?????? NA

Zero-inflation model coefficients (binomial with logit link):

????????????? Estimate Std. Error z value Pr(>|z|)
(Intercept)? 0.0685048? 1.0056156?? 0.068? 0.94569
TreatmentF? -0.3822091? 0.3631982? -1.052? 0.29264
TreatmentO? -1.1624582? 0.3551596? -3.273? 0.00106 **
N??????????? 0.0009120? 0.0004773?? 1.911? 0.05603 .
---
Theta = 3.6873
Number of iterations in BFGS optimization: 31
Log-likelihood: -458.1 on 9 Df

Reading other posts, I know that my values are all >= 0, and there are
no missing values that could be causing this, but there ARE lots of
zeroes.  So my questions are as follows:

1) Why am I getting all these NaNs, and why can?t I run the full
(saturated) model, including continuous as well as categorical
predictors and interactions?? How can I begin the process of model
simplification if I can?t get the full model to run?

2) If this is a result of the many zeroes in my data set, is there a
way to work around this?

Any advice would be greatly appreciated.

Jason Straka
University of Victoria


From jwiley.psych at gmail.com  Thu May  3 22:21:16 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 3 May 2012 13:21:16 -0700
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
References: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
Message-ID: <CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>

Hi Charles,

Could you upload the dataset you are using somewhere and post the
link?  Something like:

##########
dat34 <- read.csv("http:/wherever/you/uploaded/yourdata.csv", header = TRUE)
## code to convert to factors anything that needs to be etc.
##########

Then it is easier for us to try things that way.

corAR1 and corSymm seem appropriate.  Have you checked the examples in
their documents?  I found them helpful.

Cheers,

Josh

On Thu, May 3, 2012 at 12:58 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Greetings R users,
>
> I have been attempting to replicate various covariance structures from
> SAS's analysis of mixed models. ?I have successfully been able to replicate
> compound symmetry, however it becomes confusing with autoregression and
> unstructured. ?As such, there are two questions regarding this issue.
>
> Autoregression
> SAS output (Type III fixed effects) for covariance structure AR(1)
>
> *Type 3 Tests of Fixed Effects*
>
> *Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF F Value Pr > F*
>
> *group ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?0.99 ? ? ?0.3293
>
> *Event_name ? ? ? ? ? ? ? *5 ? ? ? ? 91 ? ? ? ? 16.23 ? ?<.0001
>
> *Died ? ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?1.70 ? ? ?0.2047
>
> *group*Event_name ?*5 ? ? ? ?91 ? ? ? ? ?3.04 ? ? 0.0140
>
> R output (corAR1=AR(1)?)
> I can replicate these results if I run the following:
>
> fit.18=gls(var~group+Event_name+Died+group*Event_name,
> ? ?data=dat34,
> ? ?corr=corAR1(, ~1|ID),
> ? ?weight=varIdent(~1|Event_name))
> anova(fit.18, type="marginal", adjustSigma=F)
>
> #the DenDF are off with gls, so use the 'correct' ones
> 1-pf(.9935, 1, 23)
> 1-pf(16.2323, 5, 91)
> 1-pf(1.7041, 1, 23)
> 1-pf(3.0367, 5, 91)
> #and the output matches exactly
>
> However, I can not get the lme function to run the autoregression. ?The
> output is very different:
>
> fit.11=lme(var~group+Event_name+Died+group*Event_name,
> ? ?data=dat34,
> ? ?random=~1|ID,
> ? ?corr=corAR1(ID),
> ? ?weight=varIdent(~1|Event_name))
> anova.lme(fit.11, type="marginal", adjustSigma=F)
>
> ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
> (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
> group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
> Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
> Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>
> Is this type of covariance structure only done with gls and I should
> continue with the analysis as such or am I doing something silly with lme?
>
> My second question is with regards to the unstructured covariance.
> SAS output (UN)
>
> *Type 3 Tests of Fixed Effects*
>
> *Effect ? ? ? ?NumDF DenDF F Value Pr > F*
>
> *Pig_group ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 2.73 ? ?0.1120
>
> *Event_name *5 ? ? ? ? ? ?23 ? ? ? ? 1.11 ? ?0.3806
>
> *Died ? ? ? ? ? ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 0.51 ? ?0.4833
>
> R output (corSymm = UN?)
> fit.11=lme(var2~group+Event_name+Died,
> ? ?data=dat34,
> ? ?random=~1|ID,
> ? ?corr=corSymm(, ~1|ID),
> ? ?weight=varIdent(~1|Event_name))
> anova.lme(fit.11, type="marginal", adjustSigma=F)
>
> #same as corAR1???
> ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
> (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
> group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
> Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
> Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>
> but with gls
> fit.18=gls(var~group+Event_name+Died,
> ? ?data=dat34,
> ? ?corr=corSymm(~1|ID),
> ? ?weight=varIdent(~1|Event_name))
> anova(fit.18, type="marginal", adjustSigma=F)
>
> 1-pf(2.869837, 1, 23)
> 1-pf(1.126747, 5, 23)
> 1-pf(.514726, 1, 23)
>
> [1] 0.1037549
> [1] 0.3742309
> [1] 0.4803239
>
> #close but not exact (however I can work with this if it is indeed correct)
>
> Overall, I want to clarify the difference between gls and lme and if I am
> simply making some weird syntax error with lme that I can't seem to get the
> covariance structures to match.
>
>
> Apologies for lots of information in one go, but hopefully this provides
> necessary information to point me in the correct direction.
>
> Thanks to any and all who give their time to these questions,
>
> Regards,
> Charles
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From bbolker at gmail.com  Thu May  3 22:22:41 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 May 2012 20:22:41 +0000 (UTC)
Subject: [R-sig-ME] Extracting variances of the estimated variance
	components in lme4
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
	<loom.20120503T142736-959@post.gmane.org>
	<4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>
	<CAO7JsnQdQO4uNtAaPjjDTxdm19zK3fpSQyoqY2y+Y=qipBgUxQ@mail.gmail.com>
	<4FA2B0AD020000EE0009DDEE@gwiasmtp.uct.ac.za>
Message-ID: <loom.20120503T213623-311@post.gmane.org>

Freedom Gumedze <Freedom.Gumedze at ...> writes:

> Douglas and Thierry,
> 
> Many thanks Douglas for the advice. I will look at the suggestion by
> Douglas when the URL is visible.
> The omission of the option for the standard errors of the estimated
> variances (or std deviations) is understandable to avoid their 'abuse
> e.g. in significance testing'. However, they should be available (if
> needed) as they can be obtained from the inverse of information matrix
> for the var. components.

  It's not quite that easy, because the variance components are not
estimated on the scale of variances or standard deviations, but on the
Cholesky scale, so (depending on the model) the information matrix of
the 'theta' parameter vector (a concatenated vector of the lower triangles
of the Cholesky factors) may not be easy to translate to the
information matrix of the standard deviations or variances.  I posted
some code earlier in response to a query of Josh Wiley's, based on the
development version of lme4 (sorry), that extracts the deviance function
and wraps it in a function that transforms standard deviations to 
the Cholesky-factor parameterization -- combining this with finite-difference
approximations of second derivatives (e.g. from the numDeriv package)
will give the standard errors of the estimated parameters, if you want
them.

  I have the intention of including this stuff in a skull-and-crossbones-marked
section of an "lme4-extras" vignette (if Doug lets me).  The vignette is
in progress, I can send it on request.

  Ben Bolker


From bbolker at gmail.com  Thu May  3 22:26:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 May 2012 20:26:51 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Trouble_running_full_ZINB_or_ZANB_model=3A_N?=
	=?utf-8?q?aNs_produced=09and_errors_in_optim=28=29?=
References: <CAAHjLoaOQCiTiOcAbRtza50T_8hLR73GHH1vEdhMH+_TBgbZ8Q@mail.gmail.com>
Message-ID: <loom.20120503T222332-275@post.gmane.org>

J Straka <jstraka at ...> writes:

> 
> Hello,
> 
> I?m attempting to run zero-inflated and hurdle models using the pscl()
> package, but keep encountering problems with running my
> fully-parameterized model and I?m not sure why.
> My data consist of measurements of seed set (the response, which is
> zero-inflated and overdispersed) for two treatments and a control (B,
> F, and O) at three elevations (low, mid, and high).? At each elevation
> I also measured average temperature (AvgTemp) and abundance of insects
> (N).? My goal is to construct a model that best describes seed set
> using the four predictors above (and interactions, if necessary).
> I find that I have no problems running a partial model with only my
> two categorical predictors as follows (just an example using hurdle(),
> but results are the same for zeroinfl()):

  [snip snip]

 This isn't a mixed model question, so it really belongs somewhere
else (r-help or r-sig-ecology spring to mind).

   I wouldn't be shocked if it turned out that your data set was
too small and/or noisy to support what you are trying to do (rule
of thumb is that you probably need about 10 observations per parameter
you are trying to estimate).  I would also suggest centering
(and possibly scaling) your continuous predictors (see
e.g. Schielzeth 2010 Methods in Ecology and Evolution)


From deter088 at umn.edu  Thu May  3 22:44:19 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 3 May 2012 15:44:19 -0500
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>
References: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
	<CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>
Message-ID: <CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120503/ba2039fd/attachment.pl>

From ramos.grad.student at gmail.com  Thu May  3 22:52:56 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Thu, 3 May 2012 13:52:56 -0700
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>
References: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
	<CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>
	<CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>
Message-ID: <CAHawB9tXoYj==U8gerO9j7pMPitJMRupZR2GP+HxUXs63E3Pkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120503/4fa3c4df/attachment.pl>

From jwiley.psych at gmail.com  Thu May  3 22:59:15 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 3 May 2012 13:59:15 -0700
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>
References: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
	<CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>
	<CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>
Message-ID: <CANz9Z_JYcSput9=kB8ibkvooKcABZWfTRDm4QZU9tmYYcxnOHQ@mail.gmail.com>

Hi Charles,

Well you could post a subset of it, or make up some data that is
sharable (whether the data make any sense is not important to us, just
nice to have runable code, for example your previous thread about
contrasts could have been solved in one email if we could have shown
you how to set the contrasts on your data and then it matched your SAS
output).  In any case, whether you use lme or gls really depends on
your question and goals, I think.  Generalized least squares is not
the same as a random effects model.  If you want a random effect, you
cannot use gls.  If you just want correlated errors, gls is fine.

This part of your code strikes me as atypical though I cannot promise
it is wrong/not what you want: corr=corAR1(ID)

Cheers,

Josh


On Thu, May 3, 2012 at 1:44 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Hi Joshua,
>
> Thanks for your response.? It is probably best that I don't post the data as
> some of it is not yet published.? My main question is whether UN and AR(1)
> should be done with gls or if I have done the syntax incorrectly with lme.
> Since AR(1) is replicated perfectly if I put the correct dendf, I can work
> with it.? And UN is close, so I just want to be sure my use and syntax are
> correct, not necessarily modifying the data.
>
> Regards,
> Charles
>
>
> On Thu, May 3, 2012 at 3:21 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>
>> Hi Charles,
>>
>> Could you upload the dataset you are using somewhere and post the
>> link? ?Something like:
>>
>> ##########
>> dat34 <- read.csv("http:/wherever/you/uploaded/yourdata.csv", header =
>> TRUE)
>> ## code to convert to factors anything that needs to be etc.
>> ##########
>>
>> Then it is easier for us to try things that way.
>>
>> corAR1 and corSymm seem appropriate. ?Have you checked the examples in
>> their documents? ?I found them helpful.
>>
>> Cheers,
>>
>> Josh
>>
>> On Thu, May 3, 2012 at 12:58 PM, Charles Determan Jr <deter088 at umn.edu>
>> wrote:
>> > Greetings R users,
>> >
>> > I have been attempting to replicate various covariance structures from
>> > SAS's analysis of mixed models. ?I have successfully been able to
>> > replicate
>> > compound symmetry, however it becomes confusing with autoregression and
>> > unstructured. ?As such, there are two questions regarding this issue.
>> >
>> > Autoregression
>> > SAS output (Type III fixed effects) for covariance structure AR(1)
>> >
>> > *Type 3 Tests of Fixed Effects*
>> >
>> > *Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF F Value Pr > F*
>> >
>> > *group ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?0.99 ? ? ?0.3293
>> >
>> > *Event_name ? ? ? ? ? ? ? *5 ? ? ? ? 91 ? ? ? ? 16.23 ? ?<.0001
>> >
>> > *Died ? ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?1.70 ? ? ?0.2047
>> >
>> > *group*Event_name ?*5 ? ? ? ?91 ? ? ? ? ?3.04 ? ? 0.0140
>> >
>> > R output (corAR1=AR(1)?)
>> > I can replicate these results if I run the following:
>> >
>> > fit.18=gls(var~group+Event_name+Died+group*Event_name,
>> > ? ?data=dat34,
>> > ? ?corr=corAR1(, ~1|ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova(fit.18, type="marginal", adjustSigma=F)
>> >
>> > #the DenDF are off with gls, so use the 'correct' ones
>> > 1-pf(.9935, 1, 23)
>> > 1-pf(16.2323, 5, 91)
>> > 1-pf(1.7041, 1, 23)
>> > 1-pf(3.0367, 5, 91)
>> > #and the output matches exactly
>> >
>> > However, I can not get the lme function to run the autoregression. ?The
>> > output is very different:
>> >
>> > fit.11=lme(var~group+Event_name+Died+group*Event_name,
>> > ? ?data=dat34,
>> > ? ?random=~1|ID,
>> > ? ?corr=corAR1(ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>> >
>> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
>> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
>> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
>> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>> >
>> > Is this type of covariance structure only done with gls and I should
>> > continue with the analysis as such or am I doing something silly with
>> > lme?
>> >
>> > My second question is with regards to the unstructured covariance.
>> > SAS output (UN)
>> >
>> > *Type 3 Tests of Fixed Effects*
>> >
>> > *Effect ? ? ? ?NumDF DenDF F Value Pr > F*
>> >
>> > *Pig_group ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 2.73 ? ?0.1120
>> >
>> > *Event_name *5 ? ? ? ? ? ?23 ? ? ? ? 1.11 ? ?0.3806
>> >
>> > *Died ? ? ? ? ? ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 0.51 ? ?0.4833
>> >
>> > R output (corSymm = UN?)
>> > fit.11=lme(var2~group+Event_name+Died,
>> > ? ?data=dat34,
>> > ? ?random=~1|ID,
>> > ? ?corr=corSymm(, ~1|ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>> >
>> > #same as corAR1???
>> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
>> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
>> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
>> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>> >
>> > but with gls
>> > fit.18=gls(var~group+Event_name+Died,
>> > ? ?data=dat34,
>> > ? ?corr=corSymm(~1|ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova(fit.18, type="marginal", adjustSigma=F)
>> >
>> > 1-pf(2.869837, 1, 23)
>> > 1-pf(1.126747, 5, 23)
>> > 1-pf(.514726, 1, 23)
>> >
>> > [1] 0.1037549
>> > [1] 0.3742309
>> > [1] 0.4803239
>> >
>> > #close but not exact (however I can work with this if it is indeed
>> > correct)
>> >
>> > Overall, I want to clarify the difference between gls and lme and if I
>> > am
>> > simply making some weird syntax error with lme that I can't seem to get
>> > the
>> > covariance structures to match.
>> >
>> >
>> > Apologies for lots of information in one go, but hopefully this provides
>> > necessary information to point me in the correct direction.
>> >
>> > Thanks to any and all who give their time to these questions,
>> >
>> > Regards,
>> > Charles
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/
>
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From smartpink111 at yahoo.com  Thu May  3 23:11:44 2012
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 May 2012 14:11:44 -0700 (PDT)
Subject: [R-sig-ME] Nested subject-longitudinal logit design
In-Reply-To: <loom.20120503T202246-303@post.gmane.org>
References: <1336068311.32240.YahooMailNeo@web39402.mail.mud.yahoo.com>
	<loom.20120503T202246-303@post.gmane.org>
Message-ID: <1336079504.19449.YahooMailNeo@web39405.mail.mud.yahoo.com>

Hi Ben,

I tried to run the model,

(fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject)+(1|RepNest), family=binomial,data=BehavdatOrig2))


I got the result, but at the end there was a warning sign 


Warning message:
In mer_finalize(ans) : false convergence (8)

? Data: BehavdatOrig2 
? AIC? BIC logLik deviance
?1357 1452 -661.7???? 1323
Random effects:
?Groups? Name??????? Variance Std.Dev. Corr?? 
?resid?? (Intercept) 0.094236 0.30698???????? 
?RepNest (Intercept) 2.859728 1.69107???????? 
?Subject (Intercept) 1.921401 1.38615???????? 
???????? time??????? 0.172905 0.41582? -0.724 
Number of obs: 1960, groups: resid, 1960; RepNest, 98; Subject, 98




Then, I tried the uncorrelated model.
?(fma<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1|RepNest)+(0+time|Subject), family=binomial,data=BehavdatOrig2))
There were no warnings.? 


?AIC? BIC logLik deviance
?1333 1417 -651.6???? 1303
Random effects:
?Groups? Name??????? Variance?? Std.Dev.? 
?resid?? (Intercept) 8.4733e-12 2.9109e-06
?Subject time??????? 1.0964e-01 3.3112e-01
?RepNest (Intercept) 1.1732e+01 3.4252e+00

I compared the two models:

> anova(fma, fm)
Data: BehavdatOrig2
Models:
fma: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 | 
fma:???? RepNest) + (0 + time | Subject)
fm: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 + 
fm:???? time | Subject) + (1 | RepNest)
??? Df??? AIC??? BIC? logLik Chisq Chi Df Pr(>Chisq)
fma 15 1333.2 1416.9 -651.57??????????????????????? 
fm? 17 1357.4 1452.2 -661.69???? 0????? 2????????? 1

The results implies I should select the uncorrelated model over the correlated one (-0.724).? It is like the one I described in one of my previous posts.

I am also worried about the false convergence in my correlated model.? This was not observed when I run my previous correlated model?
BehavdatOrig <- within(BehavdatOrig, Subject <- factor(Treatment:Rep)) 
((fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject), 
? ?  family=binomial,data=BehavdatOrig)? 

The correlated model was selected with model comparison (P< 0.0006031 ***).


Thanking you,
A.K.




----- Original Message -----
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Cc: 
Sent: Thursday, May 3, 2012 2:44 PM
Subject: Re: [R-sig-ME] Nested subject-longitudinal logit design

arun <smartpink111 at ...> writes:

> I posted recently regarding inputs for a longitudinal logit model
> using lme4.? 

[snip]

> ... I am measuring the binary response (1- insect present in light
> area, 0- insect present in dark area) as dependent variable, with
> fixed effects of Wavelength (3 levels) of light applied on insect in
> a petridish (half-covered with aluminium foil) for a period starting
> from 1 min to 20 min.?? Depending on the starting response (animal
> present in dark or light zone of petridish at 0 min), there is
> another factor (Start_Resp - 2 levels - L starting in light zone, D-
> starting in dark zone).? It was really important to introduce this
> factor, as the response is drastically different in both levels of
> the factor for each of the wavelengths.?? Since, we are measuring
> the response every 1 min (0 or 1), for 20 min, time is also a factor
> with 20 levels or a covariate. ? In the present model, I introduce
> time as a covariate and extracted deviations for individual
> measurements as a random effect in "resid".

> BehavdatOrig$resid<-as.factor(1:dim(BehavdatOrig)[1])

? I would say that factor(1:nrow(BehavdatOrig)) is slightly
more readable, but OK

[A] (fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject), 
? ?  family=binomial,data=BehavdatOrig)

This seems reasonable

> If Wavelength, starting response are fixed effects and time as
> covariate, I think I can have an interaction term as
> Wavelength*Start_Resp*time.? But, subjects are not repeated for the
> experiment.? 

I'm guessing this means that each individual is only measured
in a single level of Wavelength*Start_Resp ... ?

> If I have column called "Rep" (replication) in the
> dataset for each treatment (another column - Treatment = Combination
> of Wavelength*Strain*Start_Resp) does it make sense to introduce
> Subject as nested within Treatment using the?

> BehavdatOrig <- within(BehavdatOrig, Subject <- factor(Treatment:Rep)) 

How is Subject coded?? i.e. is it coded 1..n_i for each Treatment:Rep
combination (explicit nesting), or is it coded 1..N for the entire
data set (implicit nesting)?

Similarly, how is Rep coded?

Assuming for the moment that Subject is implicitly nested and Rep is
explicitly nested, and that there is more than one Subject per Rep
(and that Rep is not crossed with Subject, i.e. each Subject is
measured only within a single Rep), then you should use something like

BehavdatOrig$RepNest <- with(BehavdatOrig,interaction(Treatment,Rep))

(1|resid) + (1+time|Subject) + (1|RepNest)

This allows for variation in intercept and slope across Subject, and
intercept (only) across RepNest.

? This specification would also be correct if Subject *were* crossed
with RepNest and numbered appropriately (i.e. 1..n for each level of
RepNest).? The only problem is if it is explicitly nested, in which
case you need (1+time|Subject:RepNest)

> It is an unbalanced dataset with respect to number of replications.?
> I made a mistake in my previous analysis as I used Subject as
> replicates which gave me completely different results.? The shrink
> fit model graph for each subject looks to have small deviations from
> the population.? In this scenario, should I have to replace this
> model with quasibinomial model.

? I don't know what the "shrink fit model graph" is ...

> ?Quasibinomial model with cbind( sum of response for every 5 minute,
> and 5-response) with this new settings.? For one thing, there is no
> quasibinomial link function in lmer, still I used binomial link to
> get results.? Another problem with quasibinomial is that I am not
> able to get the shrink fit graph with quasibinomal response.? Should
> be a problem with lattice graph plots.? Any advice on this direction
> will be appreicated.

?  Not sure what's going on here.? Are you using

glmmPQL(...,family="quasibinomial")

(which is the only way I know of to fit quasibinomial GLMMs in R?)

Your inclusion of the 'resid' random effect above should have
taken care of overdispersion.



# The above fm model provides output as:
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + (1 +?time | Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1323 1413 -645.7???? 1291
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.?? Corr?? 
# ?resid?? (Intercept) 8.3103e-12 2.8828e-06??????? 
# ?Subject (Intercept) 1.6026e+01 4.0033e+00??????? 
# ???????? time??????? 1.2760e-01 3.5722e-01 -0.552 
# Number of obs: 1960, groups: resid, 1960; Subject, 98
# 
# I also tried uncorrelated model fma. 
# 
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + 
## (1 |?????Subject) + (0 + time |
# Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1333 1417 -651.6???? 1303
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.? 
# ?resid?? (Intercept) 6.9660e-14 2.6393e-07
# ?Subject time??????? 1.0964e-01 3.3112e-01
# ?Subject (Intercept) 1.1732e+01 3.4252e+00
# et results:
# 
# Anova comparison favors the correlated model:
# > anova(fma,fm)
# Data: BehavdatOrig
# Models:
# fma: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 | 
# fma:???? Subject) + (0 + time | Subject)
# fm: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 + 
# fm:???? time | Subject)
# ??? Df??? AIC??? BIC? logLik? Chisq Chi Df Pr(>Chisq)??? 
# fma 15 1333.2 1416.9 -651.57???????????????????????????? 
# fm? 16 1323.4 1412.7 -645.69 11.767????? 1? 0.0006031 ***

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jwiley.psych at gmail.com  Thu May  3 23:16:50 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 3 May 2012 14:16:50 -0700
Subject: [R-sig-ME] Extracting variances of the estimated variance
 components in lme4
In-Reply-To: <loom.20120503T213623-311@post.gmane.org>
References: <CAMFXY1=FGZH-Eiv92f29Mgv5Q4sdYPkjhCuwGcnnU1iotEnrVw@mail.gmail.com>
	<loom.20120503T142736-959@post.gmane.org>
	<4FA29A36020000EE0009DD5B@gwiasmtp.uct.ac.za>
	<CAO7JsnQdQO4uNtAaPjjDTxdm19zK3fpSQyoqY2y+Y=qipBgUxQ@mail.gmail.com>
	<4FA2B0AD020000EE0009DDEE@gwiasmtp.uct.ac.za>
	<loom.20120503T213623-311@post.gmane.org>
Message-ID: <CANz9Z_+dHwd6MM_W14s0SQE-Hkchke=eNwJ7_6k5C9mzr=nH-A@mail.gmail.com>

On Thu, May 3, 2012 at 1:22 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Freedom Gumedze <Freedom.Gumedze at ...> writes:
>
>> Douglas and Thierry,
>>
>> Many thanks Douglas for the advice. I will look at the suggestion by
>> Douglas when the URL is visible.
>> The omission of the option for the standard errors of the estimated
>> variances (or std deviations) is understandable to avoid their 'abuse
>> e.g. in significance testing'. However, they should be available (if
>> needed) as they can be obtained from the inverse of information matrix
>> for the var. components.
>
> ?It's not quite that easy, because the variance components are not
> estimated on the scale of variances or standard deviations, but on the
> Cholesky scale, so (depending on the model) the information matrix of
> the 'theta' parameter vector (a concatenated vector of the lower triangles
> of the Cholesky factors) may not be easy to translate to the
> information matrix of the standard deviations or variances. ?I posted
> some code earlier in response to a query of Josh Wiley's, based on the
> development version of lme4 (sorry), that extracts the deviance function
> and wraps it in a function that transforms standard deviations to
> the Cholesky-factor parameterization -- combining this with finite-difference
> approximations of second derivatives (e.g. from the numDeriv package)
> will give the standard errors of the estimated parameters, if you want
> them.
>
> ?I have the intention of including this stuff in a skull-and-crossbones-marked
> section of an "lme4-extras" vignette (if Doug lets me). ?The vignette is
> in progress, I can send it on request.

I would certainly be interested in this (more to understand than
anything else).  I agree with not using the standard errors for
significance tests, besides, how cool are those profile plots in Doug
Bates slides?  Nice!  Cannot wait to play with that.


> ?Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From M.A.MOHAMMED at bham.ac.uk  Fri May  4 02:12:49 2012
From: M.A.MOHAMMED at bham.ac.uk (Mohammed Mohammed)
Date: Fri, 4 May 2012 01:12:49 +0100
Subject: [R-sig-ME] Very small random effect estimation in lmer but not in
	stata xtmixed
Message-ID: <3AA2D3466F17A14B81EB6DBE74A8D0CC067DE53258@mds-exch-02.adf.bham.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120504/0314912a/attachment.pl>

From jstraka at uvic.ca  Fri May  4 04:58:49 2012
From: jstraka at uvic.ca (J Straka)
Date: Thu, 3 May 2012 19:58:49 -0700
Subject: [R-sig-ME] Trouble running full ZINB or ZANB model: NaNs
 produced and errors in optim()
Message-ID: <CAAHjLoas1adXejS+UtDE9XyA_9FQAeR4SuLWvQ_D-fQzmvDvLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120503/65d2d07d/attachment.pl>

From tw at netstorm.be  Fri May  4 10:04:10 2012
From: tw at netstorm.be (tw at netstorm.be)
Date: Fri, 4 May 2012 10:04:10 +0200 (CEST)
Subject: [R-sig-ME] LME4 to MCMCglmm
Message-ID: <4a1b0e2be250c4d7650c87d1f27965e4.squirrel@www.netstorm.be>

Hi all,

I am trying to run an lme4 model (logistic regression with mixed effects)
in MCMCglmm but am unsure how to implement it properly.

Currently, my lme4 model formula looks as follows: "outcome ~ (1 + var1 +
var2 | study) + var1 + var2"

In English, this means that I am fitting a random effects model, where the
intercept, var1 and var2 are jointly distributed according to study.

My question is now how I would translate this formula to the fixed and
random terms in MCMCglmm.

For the fixed part, I figured that I should make a variable
nooutcome=abs(1-outcome) because it can then be modeled with a
multinomial2 family as there is no binomial(logit) option available. 
Then, the fixed part would look as follows:

cbind(outcome,nooutcome)~1+var1+var2

However, I am unsure how to specify the random effects over the intercept,
var1 and var2 jointly. So far, I was able to generate the following:

random=~us(var1):study+us(var2):study+us(1):study

which I think corresponds to  "outcome ~ (1  | study) + (0+var1  | study) 
+ (0+var2  | study) +  var1 + var2" instead of "outcome ~ (1 + var1 + var2
| study) + var1 + var2"

I would appreciate any help.

Thomas


From tw at netstorm.be  Fri May  4 10:38:07 2012
From: tw at netstorm.be (tw at netstorm.be)
Date: Fri, 4 May 2012 10:38:07 +0200 (CEST)
Subject: [R-sig-ME] LME4 to MCMCglmm
Message-ID: <365be0c95f271592233eb91e933a27d6.squirrel@www.netstorm.be>

I figured the random effect should look like this:

~us(1+var1+var2):study

but now I am struggling to define a proper prior. Again, any help would be
welcome




2012/5/4 <tw at netstorm.be>

    Hi all,

    I am trying to run an lme4 model (logistic regression with mixed effects)
    in MCMCglmm but am unsure how to implement it properly.

    Currently, my lme4 model formula looks as follows: "outcome ~ (1 + var1 +
    var2 | study) + var1 + var2"

    In English, this means that I am fitting a random effects model, where
the
    intercept, var1 and var2 are jointly distributed according to study.

    My question is now how I would translate this formula to the fixed and
    random terms in MCMCglmm.

    For the fixed part, I figured that I should make a variable
    nooutcome=abs(1-outcome) because it can then be modeled with a
    multinomial2 family as there is no binomial(logit) option available.
    Then, the fixed part would look as follows:

    cbind(outcome,nooutcome)~1+var1+var2

    However, I am unsure how to specify the random effects over the
intercept,
    var1 and var2 jointly. So far, I was able to generate the following:

    random=~us(var1):study+us(var2):study+us(1):study

    which I think corresponds to  "outcome ~ (1  | study) + (0+var1  | study)
    + (0+var2  | study) +  var1 + var2" instead of "outcome ~ (1 + var1 +
var2
    | study) + var1 + var2"

    I would appreciate any help.

    Thomas

    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From e.rapsomaniki at ucl.ac.uk  Fri May  4 13:31:18 2012
From: e.rapsomaniki at ucl.ac.uk (Rapsomaniki, Eleni)
Date: Fri, 4 May 2012 11:31:18 +0000
Subject: [R-sig-ME] lme with heteroscedacity- how to plot within-person
	variability
Message-ID: <B9A4D9CE43DAC5489E46CB4996D5B9EEE2AC33@AMSPRD0104MB148.eurprd01.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120504/95c6570f/attachment.pl>

From bbolker at gmail.com  Fri May  4 14:39:58 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 4 May 2012 12:39:58 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Very_small_random_effect_estimation_in_lmer_?=
	=?utf-8?q?but_not_in=09stata_xtmixed?=
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC067DE53258@mds-exch-02.adf.bham.ac.uk>
Message-ID: <loom.20120504T143544-469@post.gmane.org>

Mohammed Mohammed <M.A.MOHAMMED at ...> writes:


> I am using the lmer function (in the lme4 library) to analyse some
> data where individuals are clustered into sets (using the SetID
> variable) with a single fixed effect (cc - 0 or 1). The lmer model
> and output is shown below.



> Whilst the fixed effects are consistent with stata (using xtmixed,
> see below), the std dev of the random effect for SetID is very very
> small (3.5803e-05)compared to stata's (see below 1.002). Any ideas
> why this should be happening please....?

> I am happy to share my data if that helps.
> 

  Nothing really obvious pops out.  Have you tried
nlme (i.e library(nlme); lme(AnxietyScore ~cc, random=~1|SetID,data=mydf))
as a cross-check?

  Can you send/post data?

  Ben Bolker


From deter088 at umn.edu  Fri May  4 15:00:25 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 4 May 2012 08:00:25 -0500
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <CANz9Z_JYcSput9=kB8ibkvooKcABZWfTRDm4QZU9tmYYcxnOHQ@mail.gmail.com>
References: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
	<CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>
	<CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>
	<CANz9Z_JYcSput9=kB8ibkvooKcABZWfTRDm4QZU9tmYYcxnOHQ@mail.gmail.com>
Message-ID: <CAOLJphnt-5=+3+ESLQXEfB4ccqS22XtFabV=mFXOQkvkOi_Fhw@mail.gmail.com>

Joshua,

My apologies, I never intended to make it more difficult for people to
help.  I only wish to be very careful when I every work with data.  I
have created a subset as you requested in the attached csv file.  The
two covariance structures I wish to do with a mixed model are (UN) for
var, and (AR(1)) for var2.

dat=read.table("C:/?/subset.csv",sep=",",header=TRUE, na.strings=".")
attach(dat)

dat34=dat[Pig_group %in% c("3", "4"),]
attach(dat34)
dat34=within(dat34, {
	group=factor(group)
	Event_name=factor(Event_name)
	Died=factor(Died)
	ID=factor(ID)
})
attach(dat34)

contrasts(dat34$Event_name)=contr.sum(n=6)
contrasts(dat34$group)=contr.sum(n=2)
contrasts(dat34$Died)=contr.sum(n=2)


The models I wish to fit with a mixed model are:
UN
var~group+Event_name+Died,
random=~1|ID
corr=corSymm()?
anova(fit, type=?marginal?, adjustSigma=F)

#Output should be: (SAS mixed procedure with UN)
Type 3 Tests of Fixed Effects
Effect	      NumDF DenDF F Value Pr > F
Pig_group          1  	23  	2.73    0.1120
Event_name       5  	23 	1.11    0.3806
Died                  1  	23  	0.51    0.4833

AR(1)
var2~group+Event_name+Died+group*Event_name
random=~1|ID
corr=corAR1()?
anova(fit, type=?marginal?, adjustSigma=F)

Output should be:
Type 3 Tests of Fixed Effects (SAS mixed procedure with AR(1))
Effect 		         	NumDF     DenDF F Value Pr > F
Pig_group                              1  	     23    0.99      0.3293
Event_name                           5  	     91    16.23    <.0001
Died                                      1	             23    1.70      0.2047
Pig_group*Event_name           5  	     91    3.04     0.0140


Many thanks, I truly appreciate the guidance,
Charles

On Thu, May 3, 2012 at 3:59 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>
> Hi Charles,
>
> Well you could post a subset of it, or make up some data that is
> sharable (whether the data make any sense is not important to us, just
> nice to have runable code, for example your previous thread about
> contrasts could have been solved in one email if we could have shown
> you how to set the contrasts on your data and then it matched your SAS
> output). ?In any case, whether you use lme or gls really depends on
> your question and goals, I think. ?Generalized least squares is not
> the same as a random effects model. ?If you want a random effect, you
> cannot use gls. ?If you just want correlated errors, gls is fine.
>
> This part of your code strikes me as atypical though I cannot promise
> it is wrong/not what you want: corr=corAR1(ID)
>
> Cheers,
>
> Josh
>
>
> On Thu, May 3, 2012 at 1:44 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> > Hi Joshua,
> >
> > Thanks for your response.? It is probably best that I don't post the data as
> > some of it is not yet published.? My main question is whether UN and AR(1)
> > should be done with gls or if I have done the syntax incorrectly with lme.
> > Since AR(1) is replicated perfectly if I put the correct dendf, I can work
> > with it.? And UN is close, so I just want to be sure my use and syntax are
> > correct, not necessarily modifying the data.
> >
> > Regards,
> > Charles
> >
> >
> > On Thu, May 3, 2012 at 3:21 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> >>
> >> Hi Charles,
> >>
> >> Could you upload the dataset you are using somewhere and post the
> >> link? ?Something like:
> >>
> >> ##########
> >> dat34 <- read.csv("http:/wherever/you/uploaded/yourdata.csv", header =
> >> TRUE)
> >> ## code to convert to factors anything that needs to be etc.
> >> ##########
> >>
> >> Then it is easier for us to try things that way.
> >>
> >> corAR1 and corSymm seem appropriate. ?Have you checked the examples in
> >> their documents? ?I found them helpful.
> >>
> >> Cheers,
> >>
> >> Josh
> >>
> >> On Thu, May 3, 2012 at 12:58 PM, Charles Determan Jr <deter088 at umn.edu>
> >> wrote:
> >> > Greetings R users,
> >> >
> >> > I have been attempting to replicate various covariance structures from
> >> > SAS's analysis of mixed models. ?I have successfully been able to
> >> > replicate
> >> > compound symmetry, however it becomes confusing with autoregression and
> >> > unstructured. ?As such, there are two questions regarding this issue.
> >> >
> >> > Autoregression
> >> > SAS output (Type III fixed effects) for covariance structure AR(1)
> >> >
> >> > *Type 3 Tests of Fixed Effects*
> >> >
> >> > *Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF F Value Pr > F*
> >> >
> >> > *group ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?0.99 ? ? ?0.3293
> >> >
> >> > *Event_name ? ? ? ? ? ? ? *5 ? ? ? ? 91 ? ? ? ? 16.23 ? ?<.0001
> >> >
> >> > *Died ? ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?1.70 ? ? ?0.2047
> >> >
> >> > *group*Event_name ?*5 ? ? ? ?91 ? ? ? ? ?3.04 ? ? 0.0140
> >> >
> >> > R output (corAR1=AR(1)?)
> >> > I can replicate these results if I run the following:
> >> >
> >> > fit.18=gls(var~group+Event_name+Died+group*Event_name,
> >> > ? ?data=dat34,
> >> > ? ?corr=corAR1(, ~1|ID),
> >> > ? ?weight=varIdent(~1|Event_name))
> >> > anova(fit.18, type="marginal", adjustSigma=F)
> >> >
> >> > #the DenDF are off with gls, so use the 'correct' ones
> >> > 1-pf(.9935, 1, 23)
> >> > 1-pf(16.2323, 5, 91)
> >> > 1-pf(1.7041, 1, 23)
> >> > 1-pf(3.0367, 5, 91)
> >> > #and the output matches exactly
> >> >
> >> > However, I can not get the lme function to run the autoregression. ?The
> >> > output is very different:
> >> >
> >> > fit.11=lme(var~group+Event_name+Died+group*Event_name,
> >> > ? ?data=dat34,
> >> > ? ?random=~1|ID,
> >> > ? ?corr=corAR1(ID),
> >> > ? ?weight=varIdent(~1|Event_name))
> >> > anova.lme(fit.11, type="marginal", adjustSigma=F)
> >> >
> >> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
> >> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
> >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
> >> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
> >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
> >> >
> >> > Is this type of covariance structure only done with gls and I should
> >> > continue with the analysis as such or am I doing something silly with
> >> > lme?
> >> >
> >> > My second question is with regards to the unstructured covariance.
> >> > SAS output (UN)
> >> >
> >> > *Type 3 Tests of Fixed Effects*
> >> >
> >> > *Effect ? ? ? ?NumDF DenDF F Value Pr > F*
> >> >
> >> > *Pig_group ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 2.73 ? ?0.1120
> >> >
> >> > *Event_name *5 ? ? ? ? ? ?23 ? ? ? ? 1.11 ? ?0.3806
> >> >
> >> > *Died ? ? ? ? ? ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 0.51 ? ?0.4833
> >> >
> >> > R output (corSymm = UN?)
> >> > fit.11=lme(var2~group+Event_name+Died,
> >> > ? ?data=dat34,
> >> > ? ?random=~1|ID,
> >> > ? ?corr=corSymm(, ~1|ID),
> >> > ? ?weight=varIdent(~1|Event_name))
> >> > anova.lme(fit.11, type="marginal", adjustSigma=F)
> >> >
> >> > #same as corAR1???
> >> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
> >> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
> >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
> >> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
> >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
> >> >
> >> > but with gls
> >> > fit.18=gls(var~group+Event_name+Died,
> >> > ? ?data=dat34,
> >> > ? ?corr=corSymm(~1|ID),
> >> > ? ?weight=varIdent(~1|Event_name))
> >> > anova(fit.18, type="marginal", adjustSigma=F)
> >> >
> >> > 1-pf(2.869837, 1, 23)
> >> > 1-pf(1.126747, 5, 23)
> >> > 1-pf(.514726, 1, 23)
> >> >
> >> > [1] 0.1037549
> >> > [1] 0.3742309
> >> > [1] 0.4803239
> >> >
> >> > #close but not exact (however I can work with this if it is indeed
> >> > correct)
> >> >
> >> > Overall, I want to clarify the difference between gls and lme and if I
> >> > am
> >> > simply making some weird syntax error with lme that I can't seem to get
> >> > the
> >> > covariance structures to match.
> >> >
> >> >
> >> > Apologies for lots of information in one go, but hopefully this provides
> >> > necessary information to point me in the correct direction.
> >> >
> >> > Thanks to any and all who give their time to these questions,
> >> >
> >> > Regards,
> >> > Charles
> >> >
> >> > ? ? ? ?[[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >> --
> >> Joshua Wiley
> >> Ph.D. Student, Health Psychology
> >> Programmer Analyst II, Statistical Consulting Group
> >> University of California, Los Angeles
> >> https://joshuawiley.com/
> >
> >
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/

From joerg.luedicke at gmail.com  Fri May  4 15:46:11 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Fri, 4 May 2012 06:46:11 -0700
Subject: [R-sig-ME] Very small random effect estimation in lmer but not
 in stata xtmixed
In-Reply-To: <loom.20120504T143544-469@post.gmane.org>
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC067DE53258@mds-exch-02.adf.bham.ac.uk>
	<loom.20120504T143544-469@post.gmane.org>
Message-ID: <CAEn158RMTtyta59cuFdVBrPT1rtdKjx7PXCe-LrNsG12mAO=XQ@mail.gmail.com>

Ben,

OP initially posted his problem over at the R-help forum:

https://stat.ethz.ch/pipermail/r-help/2012-May/311685.html

and so there was some discussion already.

Mohammed sent me his data off-list and there does not seem to be a
problem with his data, as far as I can see. The problem rather seems
to be that lmer has some difficulties with estimating the variance
parameter for varying intercepts when the sample size is small and the
lower level variance is high relative to the group level variance.
Please see my following post from the R-help forum:

https://stat.ethz.ch/pipermail/r-help/2012-May/311766.html

Any thoughts on this?

Joerg

On Fri, May 4, 2012 at 5:39 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Mohammed Mohammed <M.A.MOHAMMED at ...> writes:
>
>
>> I am using the lmer function (in the lme4 library) to analyse some
>> data where individuals are clustered into sets (using the SetID
>> variable) with a single fixed effect (cc - 0 or 1). The lmer model
>> and output is shown below.
>
>
>
>> Whilst the fixed effects are consistent with stata (using xtmixed,
>> see below), the std dev of the random effect for SetID is very very
>> small (3.5803e-05)compared to stata's (see below 1.002). Any ideas
>> why this should be happening please....?
>
>> I am happy to share my data if that helps.
>>
>
> ?Nothing really obvious pops out. ?Have you tried
> nlme (i.e library(nlme); lme(AnxietyScore ~cc, random=~1|SetID,data=mydf))
> as a cross-check?
>
> ?Can you send/post data?
>
> ?Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri May  4 15:54:00 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 04 May 2012 09:54:00 -0400
Subject: [R-sig-ME] Very small random effect estimation in lmer but not
 in stata xtmixed
In-Reply-To: <CAEn158RMTtyta59cuFdVBrPT1rtdKjx7PXCe-LrNsG12mAO=XQ@mail.gmail.com>
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC067DE53258@mds-exch-02.adf.bham.ac.uk>
	<loom.20120504T143544-469@post.gmane.org>
	<CAEn158RMTtyta59cuFdVBrPT1rtdKjx7PXCe-LrNsG12mAO=XQ@mail.gmail.com>
Message-ID: <4FA3DF78.9040508@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-05-04 09:46 AM, Joerg Luedicke wrote:
> Ben,
> 
> OP initially posted his problem over at the R-help forum:
> 
> https://stat.ethz.ch/pipermail/r-help/2012-May/311685.html
> 
> and so there was some discussion already.
> 
> Mohammed sent me his data off-list and there does not seem to be a 
> problem with his data, as far as I can see. The problem rather
> seems to be that lmer has some difficulties with estimating the
> variance parameter for varying intercepts when the sample size is
> small and the lower level variance is high relative to the group
> level variance. Please see my following post from the R-help
> forum:
> 
> https://stat.ethz.ch/pipermail/r-help/2012-May/311766.html
> 
> Any thoughts on this?
> 
> Joerg
> 

  I would love to see the data and/or the comparison with (1) nlme and
(2) the development version of lme4, to know if the problem is
fixed/fixable. My (not very informed at this point) guess is that it
is basically a nonlinear optimization problem.  I would like to see
the plot of REML vs. estimated RE variance -- my guess is that it has
two maxima ...

  (Thomas Lumley's answer on r-help looks wrong to me: I think he was
reading the model output too quickly and confused the correlation
among fixed effects with an among-RE correlation.)

  Ben Bolker


> On Fri, May 4, 2012 at 5:39 AM, Ben Bolker <bbolker at gmail.com>
> wrote:
>> Mohammed Mohammed <M.A.MOHAMMED at ...> writes:
>> 
>> 
>>> I am using the lmer function (in the lme4 library) to analyse
>>> some data where individuals are clustered into sets (using the
>>> SetID variable) with a single fixed effect (cc - 0 or 1). The
>>> lmer model and output is shown below.
>> 
>> 
>> 
>>> Whilst the fixed effects are consistent with stata (using
>>> xtmixed, see below), the std dev of the random effect for SetID
>>> is very very small (3.5803e-05)compared to stata's (see below
>>> 1.002). Any ideas why this should be happening please....?
>> 
>>> I am happy to share my data if that helps.
>>> 
>> 
>> Nothing really obvious pops out.  Have you tried nlme (i.e
>> library(nlme); lme(AnxietyScore ~cc, random=~1|SetID,data=mydf)) 
>> as a cross-check?
>> 
>> Can you send/post data?
>> 
>> Ben Bolker
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPo994AAoJED2whTVMEyK9s1UH/R/YZS5XMpt0a1M6b7NWIpL1
rz1yV6gR1xauHxJZkD46v++R5DUsJ7z1RSBYEhTvfVj/wVPoP/L/a7TIOD4ffQHJ
+8gae/jJngrPt7zsM+2YdgST1aRiAHRKgjXcys6hhz27QaTxNGrLqxhICV6P/OsU
6WH3MqCxsevcaU7hWRi83mUGX0zyyQ4OAgATh+EK5zP5dzWLISQt9uvUk8B7/AL1
2H52IL8f0TTcLce309aH2nR/C9HPGolHusIYOZrIvgWze/Rwx9UkDxeUBaXoB9eK
b30tdTFPOTIBZfsBr7+zc+HDKmuQrQMpLwiE5ovZOnazPb5Vk57UY6GUmw1e6WQ=
=aWBF
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Fri May  4 16:17:42 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 04 May 2012 10:17:42 -0400
Subject: [R-sig-ME] Very small random effect estimation in lmer but not
 in stata xtmixed
In-Reply-To: <CAEn158RMTtyta59cuFdVBrPT1rtdKjx7PXCe-LrNsG12mAO=XQ@mail.gmail.com>
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC067DE53258@mds-exch-02.adf.bham.ac.uk>
	<loom.20120504T143544-469@post.gmane.org>
	<CAEn158RMTtyta59cuFdVBrPT1rtdKjx7PXCe-LrNsG12mAO=XQ@mail.gmail.com>
Message-ID: <4FA3E506.7050703@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12-05-04 09:46 AM, Joerg Luedicke wrote:
> Ben,
> 
> OP initially posted his problem over at the R-help forum:
> 
> https://stat.ethz.ch/pipermail/r-help/2012-May/311685.html
> 
> and so there was some discussion already.
> 
> Mohammed sent me his data off-list and there does not seem to be a 
> problem with his data, as far as I can see. The problem rather
> seems to be that lmer has some difficulties with estimating the
> variance parameter for varying intercepts when the sample size is
> small and the lower level variance is high relative to the group
> level variance. Please see my following post from the R-help
> forum:
> 
> https://stat.ethz.ch/pipermail/r-help/2012-May/311766.html
> 
> Any thoughts on this?
> 
> Joerg

  I've just tried this out with nlme and development lme4, and both of
those do fine, so it seems (urgh) to be a problem with stable lme4 ...

(Code below assumes that the stable lme4 version is installed from
r-forge, where it is known as lme4.0; lme4 is the r-forge
(development) version ...)

  At the moment I would suggest going either backward to nlme or
forward to development lme4 (GLMMs in development lme4 are quite
unstable at the moment, and there may be some internal changes, but
LMMs should be quite stable).


> 
dat <- na.omit(read.csv("lmmTest.csv"))
library(nlme)
lme(AnxietyScore~cc,random=~1|SetID,data=dat)
detach("package:nlme")
library(lme4.0)
lmer(AnxietyScore~cc+(1|SetID),data=dat)
detach("package:lme4.0")
library(lme4)
(fm1 <- lmer(AnxietyScore~cc+(1|SetID),data=dat))
fmFun <- update(fm1,devFunOnly=TRUE)
getME(fm1,"theta")
thetavec <- seq(0,0.5,length=101)
dvec <- sapply(thetavec,fmFun)
plot(thetavec,dvec,type="l")
xyplot(profile(fm1))
detach("package:lme4")



> On Fri, May 4, 2012 at 5:39 AM, Ben Bolker <bbolker at gmail.com>
> wrote:
>> Mohammed Mohammed <M.A.MOHAMMED at ...> writes:
>> 
>> 
>>> I am using the lmer function (in the lme4 library) to analyse
>>> some data where individuals are clustered into sets (using the
>>> SetID variable) with a single fixed effect (cc - 0 or 1). The
>>> lmer model and output is shown below.
>> 
>> 
>> 
>>> Whilst the fixed effects are consistent with stata (using
>>> xtmixed, see below), the std dev of the random effect for SetID
>>> is very very small (3.5803e-05)compared to stata's (see below
>>> 1.002). Any ideas why this should be happening please....?
>> 
>>> I am happy to share my data if that helps.
>>> 
>> 
>> Nothing really obvious pops out.  Have you tried nlme (i.e
>> library(nlme); lme(AnxietyScore ~cc, random=~1|SetID,data=mydf)) 
>> as a cross-check?
>> 
>> Can you send/post data?
>> 
>> Ben Bolker
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPo+UGAAoJED2whTVMEyK9aTsH/jO6aGVbgryPvIZniOYSn4be
QtRac5qpS8fFSzRpIKFx5BhfnaeL6huGb9OK9xQkg8/M0YreMskO7g8PNY69SymW
yAhoSmuMhOfC2HFRLI5ii2TPg5mECL0UMPu393kj18YwUhvFklv5R+zCNmQQQIrC
7zfr1Qd33+qTNMM6VTtMp3lj96PrUEsllMzqcayP9MrkZaAfl5qmMcuBQZKLwTUX
T7xcHPsuZqjOuM1JgaZSWxygZkQg9PnzS3Q1f8+HtdNXd38bWA0jqnJmtHj0bvjp
tpocBAn6JnUrcpZsvLt7mneAh/0C8mVBtMXoouUOmSPSZCvJfHZeYvX7GSlteIw=
=JWCc
-----END PGP SIGNATURE-----


From joerg.luedicke at gmail.com  Fri May  4 18:25:33 2012
From: joerg.luedicke at gmail.com (Joerg Luedicke)
Date: Fri, 4 May 2012 09:25:33 -0700
Subject: [R-sig-ME] Very small random effect estimation in lmer but not
 in stata xtmixed
In-Reply-To: <4FA3E506.7050703@gmail.com>
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC067DE53258@mds-exch-02.adf.bham.ac.uk>
	<loom.20120504T143544-469@post.gmane.org>
	<CAEn158RMTtyta59cuFdVBrPT1rtdKjx7PXCe-LrNsG12mAO=XQ@mail.gmail.com>
	<4FA3E506.7050703@gmail.com>
Message-ID: <CAEn158R0ebvcKekH8RY0XCT7zKed1E-H62NwbckW++6v03f1Uw@mail.gmail.com>

I apologize for my sloppiness in that I did not mention what lme4
version I was using.

It was version 0.999375-42.

Joerg

On Fri, May 4, 2012 at 7:17 AM, Ben Bolker <bbolker at gmail.com> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 12-05-04 09:46 AM, Joerg Luedicke wrote:
>> Ben,
>>
>> OP initially posted his problem over at the R-help forum:
>>
>> https://stat.ethz.ch/pipermail/r-help/2012-May/311685.html
>>
>> and so there was some discussion already.
>>
>> Mohammed sent me his data off-list and there does not seem to be a
>> problem with his data, as far as I can see. The problem rather
>> seems to be that lmer has some difficulties with estimating the
>> variance parameter for varying intercepts when the sample size is
>> small and the lower level variance is high relative to the group
>> level variance. Please see my following post from the R-help
>> forum:
>>
>> https://stat.ethz.ch/pipermail/r-help/2012-May/311766.html
>>
>> Any thoughts on this?
>>
>> Joerg
>
> ?I've just tried this out with nlme and development lme4, and both of
> those do fine, so it seems (urgh) to be a problem with stable lme4 ...
>
> (Code below assumes that the stable lme4 version is installed from
> r-forge, where it is known as lme4.0; lme4 is the r-forge
> (development) version ...)
>
> ?At the moment I would suggest going either backward to nlme or
> forward to development lme4 (GLMMs in development lme4 are quite
> unstable at the moment, and there may be some internal changes, but
> LMMs should be quite stable).
>
>
>>
> dat <- na.omit(read.csv("lmmTest.csv"))
> library(nlme)
> lme(AnxietyScore~cc,random=~1|SetID,data=dat)
> detach("package:nlme")
> library(lme4.0)
> lmer(AnxietyScore~cc+(1|SetID),data=dat)
> detach("package:lme4.0")
> library(lme4)
> (fm1 <- lmer(AnxietyScore~cc+(1|SetID),data=dat))
> fmFun <- update(fm1,devFunOnly=TRUE)
> getME(fm1,"theta")
> thetavec <- seq(0,0.5,length=101)
> dvec <- sapply(thetavec,fmFun)
> plot(thetavec,dvec,type="l")
> xyplot(profile(fm1))
> detach("package:lme4")
>
>
>
>> On Fri, May 4, 2012 at 5:39 AM, Ben Bolker <bbolker at gmail.com>
>> wrote:
>>> Mohammed Mohammed <M.A.MOHAMMED at ...> writes:
>>>
>>>
>>>> I am using the lmer function (in the lme4 library) to analyse
>>>> some data where individuals are clustered into sets (using the
>>>> SetID variable) with a single fixed effect (cc - 0 or 1). The
>>>> lmer model and output is shown below.
>>>
>>>
>>>
>>>> Whilst the fixed effects are consistent with stata (using
>>>> xtmixed, see below), the std dev of the random effect for SetID
>>>> is very very small (3.5803e-05)compared to stata's (see below
>>>> 1.002). Any ideas why this should be happening please....?
>>>
>>>> I am happy to share my data if that helps.
>>>>
>>>
>>> Nothing really obvious pops out. ?Have you tried nlme (i.e
>>> library(nlme); lme(AnxietyScore ~cc, random=~1|SetID,data=mydf))
>>> as a cross-check?
>>>
>>> Can you send/post data?
>>>
>>> Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iQEcBAEBAgAGBQJPo+UGAAoJED2whTVMEyK9aTsH/jO6aGVbgryPvIZniOYSn4be
> QtRac5qpS8fFSzRpIKFx5BhfnaeL6huGb9OK9xQkg8/M0YreMskO7g8PNY69SymW
> yAhoSmuMhOfC2HFRLI5ii2TPg5mECL0UMPu393kj18YwUhvFklv5R+zCNmQQQIrC
> 7zfr1Qd33+qTNMM6VTtMp3lj96PrUEsllMzqcayP9MrkZaAfl5qmMcuBQZKLwTUX
> T7xcHPsuZqjOuM1JgaZSWxygZkQg9PnzS3Q1f8+HtdNXd38bWA0jqnJmtHj0bvjp
> tpocBAn6JnUrcpZsvLt7mneAh/0C8mVBtMXoouUOmSPSZCvJfHZeYvX7GSlteIw=
> =JWCc
> -----END PGP SIGNATURE-----


From raphael.royaute at gmail.com  Fri May  4 18:33:55 2012
From: raphael.royaute at gmail.com (Raphael Royaute)
Date: Fri, 4 May 2012 12:33:55 -0400
Subject: [R-sig-ME] Questions on model selection and nested random effects
 for multiresponse models with MCMCglmm
Message-ID: <CADx9CcpiARZSsvp2N++Lg6io36tYjr4hx6qv_CgQv0XprDhYAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120504/f32790ea/attachment.pl>

From bbolker at gmail.com  Sat May  5 00:03:24 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 4 May 2012 22:03:24 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lme_with_heteroscedacity-_how_to_plot_within?=
	=?utf-8?q?-person=09variability?=
References: <B9A4D9CE43DAC5489E46CB4996D5B9EEE2AC33@AMSPRD0104MB148.eurprd01.prod.exchangelabs.com>
Message-ID: <loom.20120505T000255-537@post.gmane.org>

Rapsomaniki, Eleni <e.rapsomaniki at ...> writes:

> 
> Dear list members,
> 
> I wasn't sure whether to post this in the sig-mixed-models list, as it
concerns the nlme package.
> 
> Suppose the following model:
> model.lme=lme(distance ~ Sex*age, data=Orthodont,random=~age|Subject,
> weights=varIdent(form=~1|Sex),correlation=corExp(form=~age, nugget=T))
 
> I would like to plot within-subject variability (e.g. the standard
> deviation of the fitted 'distance') over age. I expect that the
> vector of this variability (one per person per observed age?) is
> returned in model.lme, but I'm a bit confused with what to extract
> from the output.

  There may be a good better to do this, but here's what I came up
with:


library(nlme)
model.lme=lme(distance ~ Sex*age, data=Orthodont,random=~age|Subject,
 weights=varIdent(form=~1|Sex),
correlation=corExp(form=~age, nugget=TRUE))


## extract relative sd terms per sex
sdw <- 1/unique(varWeights(model.lme$modelStruct))
## fixed-effect variance-covariance matrix
fv <- vcov(model.lme)
## data for prediction
dd <- expand.grid(Sex=factor(levels(Orthodont$Sex)),
      age=seq(min(Orthodont$age),max(Orthodont$age),length.out=41))
## design matrix
X <- model.matrix(~Sex*age,data=dd)
## sample variances of predictions of a linear model
dd$cvar <- diag(X %*% fv %*% t(X))
## residual variances, scaled
##    by sex-specific weighting (make sure the order is right!)
dd$pvar <- summary(model.lme)$sigma^2*sdw[as.numeric(dd$Sex)]^2
dd$sd <- sqrt(dd$cvar+dd$pvar)

## one way to plot the results
library(lattice)
xyplot(sd~age,group=Sex,data=dd,type="l",
   ylim=c(0,2))

Note that these are prediction intervals (including the
residual variance, which is what the heteroscedasticity
term applies to). The estimate of the model standard deviations
(i.e. based on the fixed effect sampling variances) does *not*
take the uncertainty of the variances themselves into account.
 
> Also regarding the nugget, should I initialise it to some value? Or
> just assume the value chosen by the model fitted are the actual
> 'measurement error' (please correct me if this is not what the
> nugget represents)?

I would let the nugget be estimated automatically unless you
have reason to believe the estimate is wonky.
 
> Finally, am I right to think that heteroscedastic variances are
>  still not possible with lme4?

  Correct.


From ramos.grad.student at gmail.com  Sat May  5 03:29:55 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Fri, 4 May 2012 18:29:55 -0700
Subject: [R-sig-ME] question about contrast package with lme model
Message-ID: <CAHawB9uYmDv-HAPOsNFXaanfLtW5omnMxn1Gq2jGUPwjTr_pfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120504/8ffa2635/attachment.pl>

From epitta at upatras.gr  Sat May  5 10:17:17 2012
From: epitta at upatras.gr (=?UTF-8?Q?=CE=A0=CE=AF=CF=84=CF=84=CE=B1_E=CF=8D=CE=B1?=)
Date: Sat, 05 May 2012 11:17:17 +0300
Subject: [R-sig-ME] request for help with glmm
Message-ID: <51ce960b90f4e1eee409a9d4a3c37b00@upatras.gr>

Hi,

I am a phd student in Greece. And I have some questions regarding the 
use of glmm if the data include dissimilarity values.
I do not know if this mailing list is appropriate for my questions but 
I do not know who else to turn to.
My data include islands in various archipelagos and presence-absence of 
species of 3 taxa on the them.
I estimated beta diversity as compositional dissimilarity between pairs 
of islands in the same archipelago using the Jaccard coefficient 
(proportion of common species between two islands).
For example if I have 5 islands in a given archipelago I end up with 10 
dissimilarity values.
I fitted a glmm model (using package lme4) to test for the effect of 
taxon and also the effect of inter-island distance, area and elevation 
differences between pairs of islands
on beta diversity using archipelago as a random factor.
However, dissimilarity values (and the rest) are not independent of 
each other in the same archipelago, because each island contributes to N 
- 1 of them.
I read that a glmm allows for correlation between the observations of 
the same random factor. Does this mean that a glmm takes into account 
the fact that the dissimilarity values are not independent
from each other? Or should I somehow take into account the fact that 
dissimilarity values in the same archipelago are not independent of each 
other.
I would really appreciate your help.


Thank you for your time

Eva


From smartpink111 at yahoo.com  Sat May  5 16:50:05 2012
From: smartpink111 at yahoo.com (arun)
Date: Sat, 5 May 2012 07:50:05 -0700 (PDT)
Subject: [R-sig-ME] Fw:  Nested subject-longitudinal logit design
In-Reply-To: <1336079504.19449.YahooMailNeo@web39405.mail.mud.yahoo.com>
References: <1336068311.32240.YahooMailNeo@web39402.mail.mud.yahoo.com>
	<loom.20120503T202246-303@post.gmane.org>
	<1336079504.19449.YahooMailNeo@web39405.mail.mud.yahoo.com>
Message-ID: <1336229405.67783.YahooMailNeo@web39406.mail.mud.yahoo.com>

HI Ben,


Thanks for helping me.
I posted this 2 days back. ?Probably, you haven't seen this. ?Any ideas on how to fix the convergence issue. ?The parameter estimates are now half of the all the other models. ?I used verbose=TRUE in the statement. ?Is it because of the unbalanced data? ?For some of the treatment combinations, there are 25 replications, while for some there are only 10 replications.?


----- Forwarded Message -----
From: arun <smartpink111 at yahoo.com>
To: Ben Bolker <bbolker at gmail.com>
Cc: R mixed models <r-sig-mixed-models at r-project.org>
Sent: Thursday, May 3, 2012 5:11 PM
Subject: Re: [R-sig-ME] Nested subject-longitudinal logit design

Hi Ben,

I tried to run the model,

(fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject)+(1|RepNest), family=binomial,data=BehavdatOrig2))


I got the result, but at the end there was a warning sign 


Warning message:
In mer_finalize(ans) : false convergence (8)

? Data: BehavdatOrig2 
? AIC? BIC logLik deviance
?1357 1452 -661.7???? 1323
Random effects:
?Groups? Name??????? Variance Std.Dev. Corr?? 
?resid?? (Intercept) 0.094236 0.30698???????? 
?RepNest (Intercept) 2.859728 1.69107???????? 
?Subject (Intercept) 1.921401 1.38615???????? 
???????? time??????? 0.172905 0.41582? -0.724 
Number of obs: 1960, groups: resid, 1960; RepNest, 98; Subject, 98




Then, I tried the uncorrelated model.
?(fma<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1|RepNest)+(0+time|Subject), family=binomial,data=BehavdatOrig2))
There were no warnings.? 


?AIC? BIC logLik deviance
?1333 1417 -651.6???? 1303
Random effects:
?Groups? Name??????? Variance?? Std.Dev.? 
?resid?? (Intercept) 8.4733e-12 2.9109e-06
?Subject time??????? 1.0964e-01 3.3112e-01
?RepNest (Intercept) 1.1732e+01 3.4252e+00

I compared the two models:

> anova(fma, fm)
Data: BehavdatOrig2
Models:
fma: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 | 
fma:???? RepNest) + (0 + time | Subject)
fm: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 + 
fm:???? time | Subject) + (1 | RepNest)
??? Df??? AIC??? BIC? logLik Chisq Chi Df Pr(>Chisq)
fma 15 1333.2 1416.9 -651.57??????????????????????? 
fm? 17 1357.4 1452.2 -661.69???? 0????? 2????????? 1

The results implies I should select the uncorrelated model over the correlated one (-0.724).? It is like the one I described in one of my previous posts.

I am also worried about the false convergence in my correlated model.? This was not observed when I run my previous correlated model?
BehavdatOrig <- within(BehavdatOrig, Subject <- factor(Treatment:Rep)) 
((fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject), 
? ?? family=binomial,data=BehavdatOrig)? 

The correlated model was selected with model comparison (P< 0.0006031 ***).


Thanking you,
A.K.




----- Original Message -----
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Cc: 
Sent: Thursday, May 3, 2012 2:44 PM
Subject: Re: [R-sig-ME] Nested subject-longitudinal logit design

arun <smartpink111 at ...> writes:

> I posted recently regarding inputs for a longitudinal logit model
> using lme4.? 

[snip]

> ... I am measuring the binary response (1- insect present in light
> area, 0- insect present in dark area) as dependent variable, with
> fixed effects of Wavelength (3 levels) of light applied on insect in
> a petridish (half-covered with aluminium foil) for a period starting
> from 1 min to 20 min.?? Depending on the starting response (animal
> present in dark or light zone of petridish at 0 min), there is
> another factor (Start_Resp - 2 levels - L starting in light zone, D-
> starting in dark zone).? It was really important to introduce this
> factor, as the response is drastically different in both levels of
> the factor for each of the wavelengths.?? Since, we are measuring
> the response every 1 min (0 or 1), for 20 min, time is also a factor
> with 20 levels or a covariate. ? In the present model, I introduce
> time as a covariate and extracted deviations for individual
> measurements as a random effect in "resid".

> BehavdatOrig$resid<-as.factor(1:dim(BehavdatOrig)[1])

? I would say that factor(1:nrow(BehavdatOrig)) is slightly
more readable, but OK

[A] (fm<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject), 
? ?? family=binomial,data=BehavdatOrig)

This seems reasonable

> If Wavelength, starting response are fixed effects and time as
> covariate, I think I can have an interaction term as
> Wavelength*Start_Resp*time.? But, subjects are not repeated for the
> experiment.? 

I'm guessing this means that each individual is only measured
in a single level of Wavelength*Start_Resp ... ?

> If I have column called "Rep" (replication) in the
> dataset for each treatment (another column - Treatment = Combination
> of Wavelength*Strain*Start_Resp) does it make sense to introduce
> Subject as nested within Treatment using the?

> BehavdatOrig <- within(BehavdatOrig, Subject <- factor(Treatment:Rep)) 

How is Subject coded?? i.e. is it coded 1..n_i for each Treatment:Rep
combination (explicit nesting), or is it coded 1..N for the entire
data set (implicit nesting)?

Similarly, how is Rep coded?

Assuming for the moment that Subject is implicitly nested and Rep is
explicitly nested, and that there is more than one Subject per Rep
(and that Rep is not crossed with Subject, i.e. each Subject is
measured only within a single Rep), then you should use something like

BehavdatOrig$RepNest <- with(BehavdatOrig,interaction(Treatment,Rep))

(1|resid) + (1+time|Subject) + (1|RepNest)

This allows for variation in intercept and slope across Subject, and
intercept (only) across RepNest.

? This specification would also be correct if Subject *were* crossed
with RepNest and numbered appropriately (i.e. 1..n for each level of
RepNest).? The only problem is if it is explicitly nested, in which
case you need (1+time|Subject:RepNest)

> It is an unbalanced dataset with respect to number of replications.?
> I made a mistake in my previous analysis as I used Subject as
> replicates which gave me completely different results.? The shrink
> fit model graph for each subject looks to have small deviations from
> the population.? In this scenario, should I have to replace this
> model with quasibinomial model.

? I don't know what the "shrink fit model graph" is ...

> ?Quasibinomial model with cbind( sum of response for every 5 minute,
> and 5-response) with this new settings.? For one thing, there is no
> quasibinomial link function in lmer, still I used binomial link to
> get results.? Another problem with quasibinomial is that I am not
> able to get the shrink fit graph with quasibinomal response.? Should
> be a problem with lattice graph plots.? Any advice on this direction
> will be appreicated.

?? Not sure what's going on here.? Are you using

glmmPQL(...,family="quasibinomial")

(which is the only way I know of to fit quasibinomial GLMMs in R?)

Your inclusion of the 'resid' random effect above should have
taken care of overdispersion.



# The above fm model provides output as:
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + (1 +?time | Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1323 1413 -645.7???? 1291
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.?? Corr?? 
# ?resid?? (Intercept) 8.3103e-12 2.8828e-06??????? 
# ?Subject (Intercept) 1.6026e+01 4.0033e+00??????? 
# ???????? time??????? 1.2760e-01 3.5722e-01 -0.552 
# Number of obs: 1960, groups: resid, 1960; Subject, 98
# 
# I also tried uncorrelated model fma. 
# 
# Formula: Response ~ Wavelength * Start_Resp * time + 
## (1 | resid) + 
## (1 |?????Subject) + (0 + time |
# Subject) 
# ?? Data: BehavdatOrig 
# ? AIC? BIC logLik deviance
# ?1333 1417 -651.6???? 1303
# Random effects:
# ?Groups? Name??????? Variance?? Std.Dev.? 
# ?resid?? (Intercept) 6.9660e-14 2.6393e-07
# ?Subject time??????? 1.0964e-01 3.3112e-01
# ?Subject (Intercept) 1.1732e+01 3.4252e+00
# et results:
# 
# Anova comparison favors the correlated model:
# > anova(fma,fm)
# Data: BehavdatOrig
# Models:
# fma: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 | 
# fma:???? Subject) + (0 + time | Subject)
# fm: Response ~ Wavelength * Start_Resp * time + (1 | resid) + (1 + 
# fm:???? time | Subject)
# ??? Df??? AIC??? BIC? logLik? Chisq Chi Df Pr(>Chisq)??? 
# fma 15 1333.2 1416.9 -651.57???????????????????????????? 
# fm? 16 1323.4 1412.7 -645.69 11.767????? 1? 0.0006031 ***

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jwiley.psych at gmail.com  Sat May  5 17:05:26 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 5 May 2012 08:05:26 -0700
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <CAOLJphnt-5=+3+ESLQXEfB4ccqS22XtFabV=mFXOQkvkOi_Fhw@mail.gmail.com>
References: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
	<CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>
	<CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>
	<CANz9Z_JYcSput9=kB8ibkvooKcABZWfTRDm4QZU9tmYYcxnOHQ@mail.gmail.com>
	<CAOLJphnt-5=+3+ESLQXEfB4ccqS22XtFabV=mFXOQkvkOi_Fhw@mail.gmail.com>
Message-ID: <CANz9Z_+3Y5qO2MbdH5_opWpQPdT4Lv5kdqiZLeRD4CTkQPsbYg@mail.gmail.com>

Hi Charles,

I know you were not trying to make it difficult, no worries.  Most of
the results seem to match fairly closely.  Here is some stuff you can
try if you want (also added some residual plots and examination of the
distribution of random effects which is assumed gaussian).

Cheers,

Josh

####################################################
dat=read.table("subset.csv",sep=",",header=TRUE, na.strings=".")
dat34=dat[dat$group %in% c("3", "4"),]
dat34=within(dat34, {
        group=factor(group)
        Event_name=factor(Event_name)
        Died=factor(Died)
        ID=factor(ID)
})
contrasts(dat34$Event_name)=contr.sum(n=6)
contrasts(dat34$group)=contr.sum(n=2)
contrasts(dat34$Died)=contr.sum(n=2)
dat34$rep <- unlist(sapply(rle(as.numeric(dat34$ID))$lengths, seq.int))

require(nlme)
require(lattice)

m.run <- lme(var ~ group + Event_name + Died,
  random = ~ 1 | ID, corr = corSymm(), data = dat34)
## store residuals and plot
dat34$r.mrun <- resid(m.run)
xyplot(r.mrun ~ rep | ID, data = dat34)
## examine distribution of random effects
qqmath(ranef(m.run)[[1]])
summary(m.run)
## Linear mixed-effects model fit by REML
##  Data: dat34
##        AIC      BIC   logLik
##   47.06365 116.5417 1.468174

## Random effects:
##  Formula: ~1 | ID
##         (Intercept)  Residual
## StdDev:   0.3934213 0.2635925

## Correlation Structure: General
##  Formula: ~1 | ID
##  Parameter estimate(s):
##  Correlation:  <-- you can see the unstructure correlation matrix
##   1      2      3      4      5
## 2  0.289
## 3  0.553  0.774
## 4  0.225  0.532  0.752
## 5  0.532  0.635  0.844  0.662
## 6  0.717 -0.052  0.361 -0.053  0.535

anova(m.run, type = "marginal", adjustSigma = FALSE)
##             numDF denDF  F-value p-value
## (Intercept)     1    96 9.816408  0.0023
## group           1    23 0.131949  0.7197
## Event_name      5    96 1.081781  0.3754
## Died            1    23 0.074427  0.7874


#Output should be: (SAS mixed procedure with UN)
#Type 3 Tests of Fixed Effects
#Effect        NumDF DenDF  F Value    Pr > F
#Pig_group         1    23     2.73    0.1120
#Event_name        5    23     1.11    0.3806
#Died              1    23     0.51    0.4833


## group*Event_name expands to: group + Event_name + group:Event_name
## i.e., main effects + interaction, like "group | Event_name in proc mixed
m.run2 <- lme(var2 ~ group*Event_name + Died,
  random = ~ 1 | ID, corr = corSymm(), data = dat34)
dat34$r.run2 <- resid(m.run2)
xyplot(r.run2 ~ rep | ID, data = dat34)
## examine distribution of random effects
qqmath(ranef(m.run2)[[1]])
summary(m.run2)

## auto regressive model
m.rar1 <- lme(var2 ~ group*Event_name + Died,
  random = ~ 1 | ID, corr = corAR1(), data = dat34)
## store residuals and plot
dat34$r.rar1 <- resid(m.rar1)
xyplot(r.rar1 ~ rep | ID, data = dat34)
## examine distribution of random effects
qqmath(ranef(m.rar1)[[1]])
summary(m.rar1)
## Linear mixed-effects model fit by REML
##  Data: dat34
##        AIC     BIC    logLik
##   413.8188 457.598 -190.9094

## Random effects:
##  Formula: ~1 | ID
##         (Intercept) Residual
## StdDev:    0.383367 1.004379

## Correlation Structure: AR(1)
##  Formula: ~1 | ID
##  Parameter estimate(s):
##       Phi
## 0.1092874 <-- phi (rho) autocorrelation estimate

anova(m.rar1, type = "marginal", adjustSigma = FALSE)
##                  numDF denDF  F-value p-value
## (Intercept)          1    91 337.2176  <.0001
## group                1    23   0.9015  0.3523
## Event_name           5    91  15.9816  <.0001
## Died                 1    23   1.4741  0.2370
## group:Event_name     5    91   3.4790  0.0064

## Output should be:
## Type 3 Tests of Fixed Effects (SAS mixed procedure with AR(1))
## Effect                 NumDF   DenDF F Value  Pr > F
## Pig_group                  1      23    0.99  0.3293
## Event_name                 5      91   16.23  <.0001
## Died                       1      23    1.70  0.2047
## Pig_group*Event_name       5      91    3.04  0.0140


## compare auto regressive with unstructured
anova(m.run2, m.rar1)
####################################################


On Fri, May 4, 2012 at 6:00 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Joshua,
>
> My apologies, I never intended to make it more difficult for people to
> help. ?I only wish to be very careful when I every work with data. ?I
> have created a subset as you requested in the attached csv file. ?The
> two covariance structures I wish to do with a mixed model are (UN) for
> var, and (AR(1)) for var2.
>
> dat=read.table("C:/?/subset.csv",sep=",",header=TRUE, na.strings=".")
> attach(dat)
>
> dat34=dat[Pig_group %in% c("3", "4"),]
> attach(dat34)
> dat34=within(dat34, {
> ? ? ? ?group=factor(group)
> ? ? ? ?Event_name=factor(Event_name)
> ? ? ? ?Died=factor(Died)
> ? ? ? ?ID=factor(ID)
> })
> attach(dat34)
>
> contrasts(dat34$Event_name)=contr.sum(n=6)
> contrasts(dat34$group)=contr.sum(n=2)
> contrasts(dat34$Died)=contr.sum(n=2)
>
>
> The models I wish to fit with a mixed model are:
> UN
> var~group+Event_name+Died,
> random=~1|ID
> corr=corSymm()?
> anova(fit, type=?marginal?, adjustSigma=F)
>
> #Output should be: (SAS mixed procedure with UN)
> Type 3 Tests of Fixed Effects
> Effect ? ? ? ?NumDF DenDF F Value Pr > F
> Pig_group ? ? ? ? ?1 ? ?23 ? ? ?2.73 ? ?0.1120
> Event_name ? ? ? 5 ? ? ?23 ? ? ?1.11 ? ?0.3806
> Died ? ? ? ? ? ? ? ? ?1 ? ? ? ? 23 ? ? ?0.51 ? ?0.4833
>
> AR(1)
> var2~group+Event_name+Died+group*Event_name
> random=~1|ID
> corr=corAR1()?
> anova(fit, type=?marginal?, adjustSigma=F)
>
> Output should be:
> Type 3 Tests of Fixed Effects (SAS mixed procedure with AR(1))
> Effect ? ? ? ? ? ? ? ? ? ? ? ? ?NumDF ? ? DenDF F Value Pr > F
> Pig_group ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? 23 ? ?0.99 ? ? ?0.3293
> Event_name ? ? ? ? ? ? ? ? ? ? ? ? ? 5 ? ? ? ? ? ? ? 91 ? ?16.23 ? ?<.0001
> Died ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ?23 ? ?1.70 ? ? ?0.2047
> Pig_group*Event_name ? ? ? ? ? 5 ? ? ? ? ? ? 91 ? ?3.04 ? ? 0.0140
>
>
> Many thanks, I truly appreciate the guidance,
> Charles
>
> On Thu, May 3, 2012 at 3:59 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>
>> Hi Charles,
>>
>> Well you could post a subset of it, or make up some data that is
>> sharable (whether the data make any sense is not important to us, just
>> nice to have runable code, for example your previous thread about
>> contrasts could have been solved in one email if we could have shown
>> you how to set the contrasts on your data and then it matched your SAS
>> output). ?In any case, whether you use lme or gls really depends on
>> your question and goals, I think. ?Generalized least squares is not
>> the same as a random effects model. ?If you want a random effect, you
>> cannot use gls. ?If you just want correlated errors, gls is fine.
>>
>> This part of your code strikes me as atypical though I cannot promise
>> it is wrong/not what you want: corr=corAR1(ID)
>>
>> Cheers,
>>
>> Josh
>>
>>
>> On Thu, May 3, 2012 at 1:44 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
>> > Hi Joshua,
>> >
>> > Thanks for your response.? It is probably best that I don't post the data as
>> > some of it is not yet published.? My main question is whether UN and AR(1)
>> > should be done with gls or if I have done the syntax incorrectly with lme.
>> > Since AR(1) is replicated perfectly if I put the correct dendf, I can work
>> > with it.? And UN is close, so I just want to be sure my use and syntax are
>> > correct, not necessarily modifying the data.
>> >
>> > Regards,
>> > Charles
>> >
>> >
>> > On Thu, May 3, 2012 at 3:21 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> >>
>> >> Hi Charles,
>> >>
>> >> Could you upload the dataset you are using somewhere and post the
>> >> link? ?Something like:
>> >>
>> >> ##########
>> >> dat34 <- read.csv("http:/wherever/you/uploaded/yourdata.csv", header =
>> >> TRUE)
>> >> ## code to convert to factors anything that needs to be etc.
>> >> ##########
>> >>
>> >> Then it is easier for us to try things that way.
>> >>
>> >> corAR1 and corSymm seem appropriate. ?Have you checked the examples in
>> >> their documents? ?I found them helpful.
>> >>
>> >> Cheers,
>> >>
>> >> Josh
>> >>
>> >> On Thu, May 3, 2012 at 12:58 PM, Charles Determan Jr <deter088 at umn.edu>
>> >> wrote:
>> >> > Greetings R users,
>> >> >
>> >> > I have been attempting to replicate various covariance structures from
>> >> > SAS's analysis of mixed models. ?I have successfully been able to
>> >> > replicate
>> >> > compound symmetry, however it becomes confusing with autoregression and
>> >> > unstructured. ?As such, there are two questions regarding this issue.
>> >> >
>> >> > Autoregression
>> >> > SAS output (Type III fixed effects) for covariance structure AR(1)
>> >> >
>> >> > *Type 3 Tests of Fixed Effects*
>> >> >
>> >> > *Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF F Value Pr > F*
>> >> >
>> >> > *group ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?0.99 ? ? ?0.3293
>> >> >
>> >> > *Event_name ? ? ? ? ? ? ? *5 ? ? ? ? 91 ? ? ? ? 16.23 ? ?<.0001
>> >> >
>> >> > *Died ? ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?1.70 ? ? ?0.2047
>> >> >
>> >> > *group*Event_name ?*5 ? ? ? ?91 ? ? ? ? ?3.04 ? ? 0.0140
>> >> >
>> >> > R output (corAR1=AR(1)?)
>> >> > I can replicate these results if I run the following:
>> >> >
>> >> > fit.18=gls(var~group+Event_name+Died+group*Event_name,
>> >> > ? ?data=dat34,
>> >> > ? ?corr=corAR1(, ~1|ID),
>> >> > ? ?weight=varIdent(~1|Event_name))
>> >> > anova(fit.18, type="marginal", adjustSigma=F)
>> >> >
>> >> > #the DenDF are off with gls, so use the 'correct' ones
>> >> > 1-pf(.9935, 1, 23)
>> >> > 1-pf(16.2323, 5, 91)
>> >> > 1-pf(1.7041, 1, 23)
>> >> > 1-pf(3.0367, 5, 91)
>> >> > #and the output matches exactly
>> >> >
>> >> > However, I can not get the lme function to run the autoregression. ?The
>> >> > output is very different:
>> >> >
>> >> > fit.11=lme(var~group+Event_name+Died+group*Event_name,
>> >> > ? ?data=dat34,
>> >> > ? ?random=~1|ID,
>> >> > ? ?corr=corAR1(ID),
>> >> > ? ?weight=varIdent(~1|Event_name))
>> >> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>> >> >
>> >> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>> >> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
>> >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
>> >> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
>> >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>> >> >
>> >> > Is this type of covariance structure only done with gls and I should
>> >> > continue with the analysis as such or am I doing something silly with
>> >> > lme?
>> >> >
>> >> > My second question is with regards to the unstructured covariance.
>> >> > SAS output (UN)
>> >> >
>> >> > *Type 3 Tests of Fixed Effects*
>> >> >
>> >> > *Effect ? ? ? ?NumDF DenDF F Value Pr > F*
>> >> >
>> >> > *Pig_group ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 2.73 ? ?0.1120
>> >> >
>> >> > *Event_name *5 ? ? ? ? ? ?23 ? ? ? ? 1.11 ? ?0.3806
>> >> >
>> >> > *Died ? ? ? ? ? ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 0.51 ? ?0.4833
>> >> >
>> >> > R output (corSymm = UN?)
>> >> > fit.11=lme(var2~group+Event_name+Died,
>> >> > ? ?data=dat34,
>> >> > ? ?random=~1|ID,
>> >> > ? ?corr=corSymm(, ~1|ID),
>> >> > ? ?weight=varIdent(~1|Event_name))
>> >> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>> >> >
>> >> > #same as corAR1???
>> >> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>> >> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
>> >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
>> >> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
>> >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>> >> >
>> >> > but with gls
>> >> > fit.18=gls(var~group+Event_name+Died,
>> >> > ? ?data=dat34,
>> >> > ? ?corr=corSymm(~1|ID),
>> >> > ? ?weight=varIdent(~1|Event_name))
>> >> > anova(fit.18, type="marginal", adjustSigma=F)
>> >> >
>> >> > 1-pf(2.869837, 1, 23)
>> >> > 1-pf(1.126747, 5, 23)
>> >> > 1-pf(.514726, 1, 23)
>> >> >
>> >> > [1] 0.1037549
>> >> > [1] 0.3742309
>> >> > [1] 0.4803239
>> >> >
>> >> > #close but not exact (however I can work with this if it is indeed
>> >> > correct)
>> >> >
>> >> > Overall, I want to clarify the difference between gls and lme and if I
>> >> > am
>> >> > simply making some weird syntax error with lme that I can't seem to get
>> >> > the
>> >> > covariance structures to match.
>> >> >
>> >> >
>> >> > Apologies for lots of information in one go, but hopefully this provides
>> >> > necessary information to point me in the correct direction.
>> >> >
>> >> > Thanks to any and all who give their time to these questions,
>> >> >
>> >> > Regards,
>> >> > Charles
>> >> >
>> >> > ? ? ? ?[[alternative HTML version deleted]]
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-mixed-models at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >>
>> >>
>> >> --
>> >> Joshua Wiley
>> >> Ph.D. Student, Health Psychology
>> >> Programmer Analyst II, Statistical Consulting Group
>> >> University of California, Los Angeles
>> >> https://joshuawiley.com/
>> >
>> >
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From curis at pharmacie.univ-paris5.fr  Fri May  4 16:26:05 2012
From: curis at pharmacie.univ-paris5.fr (Emmanuel Curis)
Date: Fri, 4 May 2012 16:26:05 +0200
Subject: [R-sig-ME] lme with heteroscedacity- how to plot
	within-person	variability
In-Reply-To: <B9A4D9CE43DAC5489E46CB4996D5B9EEE2AC33@AMSPRD0104MB148.eurprd01.prod.exchangelabs.com>
References: <B9A4D9CE43DAC5489E46CB4996D5B9EEE2AC33@AMSPRD0104MB148.eurprd01.prod.exchangelabs.com>
Message-ID: <20120504142604.GA30784@info124.pharmacie.univ-paris5.fr>

Hello,

On Fri, May 04, 2012 at 11:31:18AM +0000, Rapsomaniki, Eleni wrote:
? Finally, am I right to think that heteroscedastic variances are
? still not possible with lme4?

I'm still discovering mixed models formalism, and its application in
nlme and lme4, so I would appreciate to be corrected if I am wrong,
but I was guessing that heteroscedasticty between groups can also be
seen as an interaction between the random effect and the fixed effect
defining the group --- but I am not sure if it always apply for more
complex models, or models with other structures than the one I use
currently?

I assume random effect is for variable ? subject ? and the group is
defined as a fixed effect factor in the variable ? group ? with only a
few levels.

If so, it may be used in lme4 as (1 + group|subject) in lme4. To get
rid of the correlation however seems more difficult, if one only wants
heteroscedaticity: I tried to use (1|subject) + (0+group|subject), but
it seems to remove only the correlation between the base level and
others, not between other levels. I guess one has to manually define
the indicator variables for each level and do something like

(1|subject) + (is_level_2|subject) + (is_level_3|subject) + ... 

to have full removal or correlations.

PS: the model I have in mind, in case my ideas are not generalizable,
  to check it is a least correct in that case, is a model with three
  factors :

 - genotype (fixed, 3 levels)
 - visit (fixed, 4 levels)
 - patient (random)

with patient nested in genotype and only one measure for each
(patient, visit, genotype) set; my idea was that assuming different
variances between genotypes was formally equivalent to add a
genotype:patient interaction, and so on...

Any comment really appreciated,

-- 
                                Emmanuel CURIS
                                emmanuel.curis at univ-paris5.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From john_szumiloski at merck.com  Fri May  4 15:18:39 2012
From: john_szumiloski at merck.com (Szumiloski, John)
Date: Fri, 4 May 2012 09:18:39 -0400
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <mailman.4837.1336079816.4540.r-sig-mixed-models@r-project.org>
References: <mailman.4837.1336079816.4540.r-sig-mixed-models@r-project.org>
Message-ID: <78AB1F8EE6D76741958317F29EA5F1CB01215750A835@USCTMXP51004.merck.com>

I just wanted to point out that for simple repeated measures, longitudinal data, it --is-- possible to mimic some simple reasonable lme models with gls.

If lme uses the random effects specification

	random = ~1 | Subject

Then gls can mimic that by using 

	correlation = corCompSymm(form = ~1 | Subject)

The resulting parameterizations are different, but they give the same predictions and SEs for the "fixed"/model effects.

-----

I often take this gls paradigm a step further and make it a habit to use

	correlation = corrExp(form = LongitudinalTimeVariable | Subject, nugget = TRUE)

In the limit of the range parameter going to +infinity, the model reduces to the above corCompSymm model equivalent to an lme model.  In the limit as the nugget parameter going to zero, the model reduces to a CAR1 model.  (see ?corrExp and other corXXX)  I see cases of both of these.  But what astonishes me is that how often this two parameter correlation model fits my data so well: it mirrors nearly exactly what a full unrestricted correlation structure, using corSymm, gives.  (of course, that is my data, YMMV.)  Furthermore, the product of the nugget parameter and the overall variance gives an estimate of cross sectional replication variance, a nicety since I don't believe one can use replicated data with the corXXX functions.  

John
John  Szumiloski,  Ph.D.

Senior Biometrician
Biometrics Research
WP53B-120
Merck Research Laboratories
P.O. Box 0004
West Point, PA 19486-0004

>(215) 652-7346 (PH)
>(215) 993-1835 (FAX)
>




-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: Thursday, May 03, 2012 5:17 PM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 65, Issue 12

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: gls vs lme covariance structures (Joshua Wiley)
   2. Re: Nested subject-longitudinal logit design (arun)
   3. Re: Extracting variances of the estimated variance components
      in lme4 (Joshua Wiley)


----------------------------------------------------------------------

Message: 1
Date: Thu, 3 May 2012 13:59:15 -0700
From: Joshua Wiley <jwiley.psych at gmail.com>
To: Charles Determan Jr <deter088 at umn.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] gls vs lme covariance structures
Message-ID:
	<CANz9Z_JYcSput9=kB8ibkvooKcABZWfTRDm4QZU9tmYYcxnOHQ at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

Hi Charles,

Well you could post a subset of it, or make up some data that is sharable (whether the data make any sense is not important to us, just nice to have runable code, for example your previous thread about contrasts could have been solved in one email if we could have shown you how to set the contrasts on your data and then it matched your SAS output).  In any case, whether you use lme or gls really depends on your question and goals, I think.  Generalized least squares is not the same as a random effects model.  If you want a random effect, you cannot use gls.  If you just want correlated errors, gls is fine.

This part of your code strikes me as atypical though I cannot promise it is wrong/not what you want: corr=corAR1(ID)

Cheers,

Josh


On Thu, May 3, 2012 at 1:44 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Hi Joshua,
>
> Thanks for your response.? It is probably best that I don't post the 
> data as some of it is not yet published.? My main question is whether 
> UN and AR(1) should be done with gls or if I have done the syntax incorrectly with lme.
> Since AR(1) is replicated perfectly if I put the correct dendf, I can 
> work with it.? And UN is close, so I just want to be sure my use and 
> syntax are correct, not necessarily modifying the data.
>
> Regards,
> Charles
>
>
> On Thu, May 3, 2012 at 3:21 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>
>> Hi Charles,
>>
>> Could you upload the dataset you are using somewhere and post the 
>> link? ?Something like:
>>
>> ##########
>> dat34 <- read.csv("http:/wherever/you/uploaded/yourdata.csv", header 
>> =
>> TRUE)
>> ## code to convert to factors anything that needs to be etc.
>> ##########
>>
>> Then it is easier for us to try things that way.
>>
>> corAR1 and corSymm seem appropriate. ?Have you checked the examples 
>> in their documents? ?I found them helpful.
>>
>> Cheers,
>>
>> Josh
>>
>> On Thu, May 3, 2012 at 12:58 PM, Charles Determan Jr 
>> <deter088 at umn.edu>
>> wrote:
>> > Greetings R users,
>> >
>> > I have been attempting to replicate various covariance structures 
>> > from SAS's analysis of mixed models. ?I have successfully been able 
>> > to replicate compound symmetry, however it becomes confusing with 
>> > autoregression and unstructured. ?As such, there are two questions 
>> > regarding this issue.
>> >
>> > Autoregression
>> > SAS output (Type III fixed effects) for covariance structure AR(1)
>> >
>> > *Type 3 Tests of Fixed Effects*
>> >
>> > *Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF F Value Pr > F*
>> >
>> > *group ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?0.99 ? ? 
>> > ?0.3293
>> >
>> > *Event_name ? ? ? ? ? ? ? *5 ? ? ? ? 91 ? ? ? ? 16.23 ? ?<.0001
>> >
>> > *Died ? ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?1.70 ? ? 
>> > ?0.2047
>> >
>> > *group*Event_name ?*5 ? ? ? ?91 ? ? ? ? ?3.04 ? ? 0.0140
>> >
>> > R output (corAR1=AR(1)?)
>> > I can replicate these results if I run the following:
>> >
>> > fit.18=gls(var~group+Event_name+Died+group*Event_name,
>> > ? ?data=dat34,
>> > ? ?corr=corAR1(, ~1|ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova(fit.18, type="marginal", adjustSigma=F)
>> >
>> > #the DenDF are off with gls, so use the 'correct' ones 1-pf(.9935, 
>> > 1, 23) 1-pf(16.2323, 5, 91) 1-pf(1.7041, 1, 23) 1-pf(3.0367, 5, 91) 
>> > #and the output matches exactly
>> >
>> > However, I can not get the lme function to run the autoregression. 
>> > ?The output is very different:
>> >
>> > fit.11=lme(var~group+Event_name+Died+group*Event_name,
>> > ? ?data=dat34,
>> > ? ?random=~1|ID,
>> > ? ?corr=corAR1(ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>> >
>> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023 group ? ? 
>> > ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197 Event_name ? ? ? ? 
>> > ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754 Died ? ? ? ? ? ? ? ? ? ? ? 1 ? 
>> > ?23 ? ? ? ?0.074428 ?0.7874
>> >
>> > Is this type of covariance structure only done with gls and I 
>> > should continue with the analysis as such or am I doing something 
>> > silly with lme?
>> >
>> > My second question is with regards to the unstructured covariance.
>> > SAS output (UN)
>> >
>> > *Type 3 Tests of Fixed Effects*
>> >
>> > *Effect ? ? ? ?NumDF DenDF F Value Pr > F*
>> >
>> > *Pig_group ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 2.73 ? ?0.1120
>> >
>> > *Event_name *5 ? ? ? ? ? ?23 ? ? ? ? 1.11 ? ?0.3806
>> >
>> > *Died ? ? ? ? ? ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 0.51 ? ?0.4833
>> >
>> > R output (corSymm = UN?)
>> > fit.11=lme(var2~group+Event_name+Died,
>> > ? ?data=dat34,
>> > ? ?random=~1|ID,
>> > ? ?corr=corSymm(, ~1|ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>> >
>> > #same as corAR1???
>> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023 group ? ? 
>> > ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197 Event_name ? ? ? ? 
>> > ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754 Died ? ? ? ? ? ? ? ? ? ? ? 1 ? 
>> > ?23 ? ? ? ?0.074428 ?0.7874
>> >
>> > but with gls
>> > fit.18=gls(var~group+Event_name+Died,
>> > ? ?data=dat34,
>> > ? ?corr=corSymm(~1|ID),
>> > ? ?weight=varIdent(~1|Event_name))
>> > anova(fit.18, type="marginal", adjustSigma=F)
>> >
>> > 1-pf(2.869837, 1, 23)
>> > 1-pf(1.126747, 5, 23)
>> > 1-pf(.514726, 1, 23)
>> >
>> > [1] 0.1037549
>> > [1] 0.3742309
>> > [1] 0.4803239
>> >
>> > #close but not exact (however I can work with this if it is indeed
>> > correct)
>> >
>> > Overall, I want to clarify the difference between gls and lme and 
>> > if I am simply making some weird syntax error with lme that I can't 
>> > seem to get the covariance structures to match.
>> >
>> >
>> > Apologies for lots of information in one go, but hopefully this 
>> > provides necessary information to point me in the correct direction.
>> >
>> > Thanks to any and all who give their time to these questions,
>> >
>> > Regards,
>> > Charles
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list 
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group University of 
>> California, Los Angeles https://joshuawiley.com/
>
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


[...snip...]

------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 65, Issue 12
**************************************************
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From mbrooks at ufl.edu  Sat May  5 19:16:11 2012
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Sat, 5 May 2012 13:16:11 -0400
Subject: [R-sig-ME] convert stddev of fixed to random
Message-ID: <677FA16D-8DE2-418B-8FC8-F1F1E81AB1F6@ufl.edu>

Hi,
I have 4 plots in my dataset, too few to fit them as a random effect. So I'm fitting a different fixed effect intercept for each plot.

I also have individuals within plots and everything measured repeatedly for 10 years. 
My formula in glmer looks like this:
response~-1 + plot + size + (1 | individual) + (1 | year) 

I'm interested in parsing out the variability. I realize that the intercepts for year and individual have shrinkage because they're fit as random effects, while the intercepts of plot do not have shrinkage. Other than that, can I compare the standard deviation among plot intercepts to the standard deviation of the random effects? Or do I need to subtract out some variation expected from the individuals within plots?

thanks,
Mollie

Mollie Brooks
Ph.D. Candidate
NSF IGERT Fellow
Biology Department
University of Florida
mbrooks at ufl.edu
http://people.biology.ufl.edu/mbrooks


From praguewatermelon at gmail.com  Sun May  6 01:41:33 2012
From: praguewatermelon at gmail.com (Xiao He)
Date: Sat, 5 May 2012 16:41:33 -0700
Subject: [R-sig-ME] How to capture the warning message when a lmer model
 fails to converge or have singular convergence
Message-ID: <CAGBzz=LaW-qnfC1y8ezF7EVeNdxzJZZD+yLgL76TEA_0ELofSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120505/580c6724/attachment.pl>

From bbolker at gmail.com  Sun May  6 02:39:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 6 May 2012 00:39:21 +0000 (UTC)
Subject: [R-sig-ME] How to capture the warning message when a lmer model
	fails to converge or have singular convergence
References: <CAGBzz=LaW-qnfC1y8ezF7EVeNdxzJZZD+yLgL76TEA_0ELofSg@mail.gmail.com>
Message-ID: <loom.20120506T023432-668@post.gmane.org>

Xiao He <praguewatermelon at ...> writes:

> 
> Hi dear R users,
> 
> I am trying to write a script to compare models with the same fixed effects
> but different random effects e.g.,
> 
   [snip]
> 
> The idea is that I can input a full model (e.g., model1), and the script
> will compare it with model2, if the p-value is above a user-defined level
> (e.g., 0.1), model2 will be selected. Then the script will compare model2
> with model3. etc.
> 
> Since sometimes certain models fail to converge or have singular
> convergence, I would like the script to be able to note that and decide
> what to do next accordingly.
> 
> For example, in the case of failure to converge (e.g., if model1 fails to
> converge), I would like the script to choose a simpler model (e.g., Model2)
> and compare it with an even simpler model (e.g., model3).
> 
> I am not sure if this is doable within my capacity. So far, I've been able
> to write a script to do a series of comparisons, but problems arise when
> there are errors such as failure to converge.
> 

  This is a bit of a pain, but you can either (more simply) use
options(warning=2) to promote warnings to errors and then catch
the errors with try(), or you can do a more thorough/rigorous
version by using withCallingHandlers() to intercept the warnings.
This is (to my mind) a bit tricky but you can see an example in
http://glmm.wdfiles.com/local--files/examples/Zhang_simfuns.R


From ims203 at exeter.ac.uk  Sun May  6 03:44:16 2012
From: ims203 at exeter.ac.uk (Stott, Iain)
Date: Sun, 6 May 2012 02:44:16 +0100
Subject: [R-sig-ME] MCMCglmm: uninformative priors for covariance matrices
Message-ID: <77E2354C3B011A4D9A7D8EAA55555FB73708F5EAC1@EXCHMBS05.isad.isadroot.ex.ac.uk>

Hi all,

I'm having some trouble specifying priors for a couple of phylogenetic MCMCglmm models, and hoping someone can help!  I posted something similar a while back on the general list, but have progressed since (and think this list is perhaps a better place to be posting to).

I'm trying to run 2 similar MCMCglmm models, both with 2 (correlated) response variables, a single 5-level factorial explanatory, and a phylogeny structuring the error (but no random effects).  For both models, each data point represents a mean response per species.  The first model has response variables of logit-transformed proportion data (range of -3.5 to +10).  The data contains a large number of proportions close to 1, which I think may be complicating things.  The second model has response variables of log-transformed data (range of -3 to 5).  This has quite a positive skew, which I also think may be a causing problems.

Here's my code:
prior<-list(R = list(V = diag(2)*a, n=b),
            G = list(G1=list(V = diag(2)*a, n=b)))

model<-MCMCglmm(cbind(y1,y2) ~ trait:x - 1, 
                random=~us(trait):animal, rcov=~us(trait):units, family=c("gaussian","gaussian"),
                prior=prior, data=data, pedigree=tree, nodes="TIPS",
                thin=100, nitt=150000, burnin=30000, verbose=F)

I've used us(trait) in errors and residuals to deal with the correlated responses.  I'm using default uninformative priors for fixed effects, but I'm having issues choosing priors for errors and residuals: I want to keep these as uninformative as possible, and have been playing around with different parameters by varying a and b in the code above.

The MCMCglmm course notes suggest an uninformative improper prior of V=diag(2)*0, n=-1, but my models won't run with improper priors (I assume due to reducibility).  An alternative of V=diag(2)*0.02, n=3 is suggested.  This runs, but doesn't converge well.  Posterior marginals for animal:trait are very positively skewed (and sometimes bimodal for proportion models), and there is high autocorrelation in chains (which is not remedied by increasing iterations/burnin and/or thinning interval).  Both problems are more marked for proportion models.  The only way I can get normal posteriors is by increasing either the diagonals of V (but this affects variance estimates significantly, and I can't see any obvious justification), or by increasing nu (but again, I can't see any justification). (Note that this doesn't apply to fixed solutions or trait:units, which are much better behaved).

Has anyone got any suggestions for appropriate priors that are as uninformative as possible?  And, am I doing things correctly?  (I'm completely new to MCMCglmm and Bayesian stats as of 2 weeks ago, so please forgive any misinterpretations!)


Thanks,

Iain



--------------------------------------------------------------------------------
Iain Stott
Centre for Ecology and Conservation
University of Exeter, Cornwall Campus
Tremough
Treliever Road
Penryn
Cornwall
TR10 9EZ
Tel: 01326 371852
http://biosciences.exeter.ac.uk/cec/staff/postgradresearch/iainstott/
--------------------------------------------------------------------------------

From gabidequeiroz at gmail.com  Sun May  6 18:35:30 2012
From: gabidequeiroz at gmail.com (Gabriela de Queiroz)
Date: Sun, 6 May 2012 13:35:30 -0300
Subject: [R-sig-ME] problem with ranef
Message-ID: <CAHHAJft1+bCL+p5k2T-aJDUPezJnFRa_ZLUJef7+GLL6aT84VA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120506/85754295/attachment.pl>

From gabidequeiroz at gmail.com  Sun May  6 18:43:27 2012
From: gabidequeiroz at gmail.com (Gabriela de Queiroz)
Date: Sun, 6 May 2012 13:43:27 -0300
Subject: [R-sig-ME] problem with ranef
In-Reply-To: <CAHHAJft1+bCL+p5k2T-aJDUPezJnFRa_ZLUJef7+GLL6aT84VA@mail.gmail.com>
References: <CAHHAJft1+bCL+p5k2T-aJDUPezJnFRa_ZLUJef7+GLL6aT84VA@mail.gmail.com>
Message-ID: <CAHHAJfsjnckN=4SMx+vf5VCFt5TdwwLa3pguvXf3Nq2vnyaToQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120506/b6de4c5f/attachment.pl>

From smartpink111 at yahoo.com  Sun May  6 20:26:06 2012
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 May 2012 11:26:06 -0700 (PDT)
Subject: [R-sig-ME] Fw:  problem with ranef
In-Reply-To: <1336328743.40187.YahooMailNeo@web39405.mail.mud.yahoo.com>
References: <CAHHAJft1+bCL+p5k2T-aJDUPezJnFRa_ZLUJef7+GLL6aT84VA@mail.gmail.com>
	<CAHHAJfsjnckN=4SMx+vf5VCFt5TdwwLa3pguvXf3Nq2vnyaToQ@mail.gmail.com>
	<1336328743.40187.YahooMailNeo@web39405.mail.mud.yahoo.com>
Message-ID: <1336328766.97661.YahooMailNeo@web39402.mail.mud.yahoo.com>





----- Forwarded Message -----
From: arun <smartpink111 at yahoo.com>
To: Gabriela de Queiroz <gabidequeiroz at gmail.com>
Cc: 
Sent: Sunday, May 6, 2012 2:25 PM
Subject: Re: [R-sig-ME] problem with ranef

Have you tried
fm3 <- lmer(diameter ~ 1+ (1|plate)+(1|sample), Penicillin),
A.K.


----- Original Message -----
From: Gabriela de Queiroz <gabidequeiroz at gmail.com>
To: r-sig-mixed-models at r-project.org
Cc: 
Sent: Sunday, May 6, 2012 12:43 PM
Subject: Re: [R-sig-ME] problem with ranef

Sorry, I mean:

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
ranef(fm1)

Error in UseMethod("ranef") :
no applicable method for 'ranef' applied to an object of class "mer"




On Sun, May 6, 2012 at 1:35 PM, Gabriela de Queiroz <gabidequeiroz at gmail.com
> wrote:

> Dear users,
>
> Is there someone having problem with *ranef*? I used that before but now
> it is not working.
>
> I tried the example on the help page but it didn't work.
>
> fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
> > ranef(fm1)
>
> Error in UseMethod("ranef") :
> no applicable method for 'ranef' applied to an object of class "mer"
>
>
> Any thoughts?
>
> - Gabriela
>

??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From gabidequeiroz at gmail.com  Sun May  6 20:32:07 2012
From: gabidequeiroz at gmail.com (Gabriela de Queiroz)
Date: Sun, 6 May 2012 15:32:07 -0300
Subject: [R-sig-ME] problem with ranef
In-Reply-To: <1482022614.445664.1336325936694.JavaMail.root@erie.cs.uoguelph.ca>
References: <CAHHAJft1+bCL+p5k2T-aJDUPezJnFRa_ZLUJef7+GLL6aT84VA@mail.gmail.com>
	<1482022614.445664.1336325936694.JavaMail.root@erie.cs.uoguelph.ca>
Message-ID: <CAHHAJfs0MMP=Kd8BE_gsb=_rvJk5H0L_Nwfmazv7J0mN4ZNfmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120506/8a7e3a29/attachment.pl>

From smartpink111 at yahoo.com  Sun May  6 20:36:35 2012
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 May 2012 11:36:35 -0700 (PDT)
Subject: [R-sig-ME] problem with ranef
In-Reply-To: <CAHHAJfsjnckN=4SMx+vf5VCFt5TdwwLa3pguvXf3Nq2vnyaToQ@mail.gmail.com>
References: <CAHHAJft1+bCL+p5k2T-aJDUPezJnFRa_ZLUJef7+GLL6aT84VA@mail.gmail.com>
	<CAHHAJfsjnckN=4SMx+vf5VCFt5TdwwLa3pguvXf3Nq2vnyaToQ@mail.gmail.com>
Message-ID: <1336329395.62655.YahooMailNeo@web39406.mail.mud.yahoo.com>

HI,

I was just responding to your other email.?

Which version of R are you using?

I am using the latest version (R 2.15.0). ?Never had any problems with ranef, as I used it recently.


A.K.?


----- Original Message -----
From: Gabriela de Queiroz <gabidequeiroz at gmail.com>
To: r-sig-mixed-models at r-project.org
Cc: 
Sent: Sunday, May 6, 2012 12:43 PM
Subject: Re: [R-sig-ME] problem with ranef

Sorry, I mean:

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
ranef(fm1)

Error in UseMethod("ranef") :
no applicable method for 'ranef' applied to an object of class "mer"




On Sun, May 6, 2012 at 1:35 PM, Gabriela de Queiroz <gabidequeiroz at gmail.com
> wrote:

> Dear users,
>
> Is there someone having problem with *ranef*? I used that before but now
> it is not working.
>
> I tried the example on the help page but it didn't work.
>
> fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
> > ranef(fm1)
>
> Error in UseMethod("ranef") :
> no applicable method for 'ranef' applied to an object of class "mer"
>
>
> Any thoughts?
>
> - Gabriela
>

??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Geraldine.Mabille at nina.no  Mon May  7 10:50:27 2012
From: Geraldine.Mabille at nina.no (Mabille, Geraldine)
Date: Mon, 7 May 2012 08:50:27 +0000
Subject: [R-sig-ME] lme4 false convergence
Message-ID: <8CE1729E87FB844DA7A496C2ACCEE265472C191A@NINSRV05.nina.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120507/2e11edf3/attachment.pl>

From m.fairbrother at bristol.ac.uk  Mon May  7 11:31:30 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 7 May 2012 10:31:30 +0100
Subject: [R-sig-ME] problem with ranef
In-Reply-To: <mailman.5316.1336380650.4540.r-sig-mixed-models@r-project.org>
References: <mailman.5316.1336380650.4540.r-sig-mixed-models@r-project.org>
Message-ID: <9A457AC9-E6CE-472B-BF55-642998D1DB26@bristol.ac.uk>

Hi Gabriela,

You'll probably get a more helpful response about this if you provide the output from:

sessionInfo()

This will tell people what version of lme4 you're using, among other things.

- Malcolm



> From: Gabriela de Queiroz <gabidequeiroz at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Cc: 
> Sent: Sunday, May 6, 2012 12:43 PM
> Subject: Re: [R-sig-ME] problem with ranef
> 
> Sorry, I mean:
> 
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
> fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
> ranef(fm1)
> 
> Error in UseMethod("ranef") :
> no applicable method for 'ranef' applied to an object of class "mer"
> 
> 
> 
> 
> On Sun, May 6, 2012 at 1:35 PM, Gabriela de Queiroz <gabidequeiroz at gmail.com
>> wrote:
> 
>> Dear users,
>> 
>> Is there someone having problem with *ranef*? I used that before but now
>> it is not working.
>> 
>> I tried the example on the help page but it didn't work.
>> 
>> fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
>>> ranef(fm1)
>> 
>> Error in UseMethod("ranef") :
>> no applicable method for 'ranef' applied to an object of class "mer"
>> 
>> 
>> Any thoughts?
>> 
>> - Gabriela


From gabidequeiroz at gmail.com  Mon May  7 14:50:43 2012
From: gabidequeiroz at gmail.com (Gabriela de Queiroz)
Date: Mon, 7 May 2012 09:50:43 -0300
Subject: [R-sig-ME] problem with ranef
In-Reply-To: <9A457AC9-E6CE-472B-BF55-642998D1DB26@bristol.ac.uk>
References: <mailman.5316.1336380650.4540.r-sig-mixed-models@r-project.org>
	<9A457AC9-E6CE-472B-BF55-642998D1DB26@bristol.ac.uk>
Message-ID: <CAHHAJfuVw8hmOTyFs8NgkdCNxrT=B61yNQZ+aybwZZpFSxw1HA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120507/edd45196/attachment.pl>

From bbolker at gmail.com  Mon May  7 15:30:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 7 May 2012 13:30:22 +0000 (UTC)
Subject: [R-sig-ME] request for help with glmm
References: <51ce960b90f4e1eee409a9d4a3c37b00@upatras.gr>
Message-ID: <loom.20120507T152423-307@post.gmane.org>

????? E?? <epitta at ...> writes:

> 
> Hi,
> 
> I am a phd student in Greece. And I have some questions regarding the 
> use of glmm if the data include dissimilarity values.

> I do not know if this mailing list is appropriate for my questions but 
> I do not know who else to turn to.

  You might be better off with the r-sig-ecology mailing list,
where there will be more expertise on community ecology topics
such as beta diversity ...

> My data include islands in various archipelagos and presence-absence
> of species of 3 taxa on the them.  I estimated beta diversity as
> compositional dissimilarity between pairs of islands in the same
> archipelago using the Jaccard coefficient (proportion of common
> species between two islands).  For example if I have 5 islands in a
> given archipelago I end up with 10 dissimilarity values.  I fitted a
> glmm model (using package lme4) to test for the effect of taxon and
> also the effect of inter-island distance, area and elevation
> differences between pairs of islands on beta diversity using
> archipelago as a random factor.  However, dissimilarity values (and
> the rest) are not independent of each other in the same archipelago,
> because each island contributes to N - 1 of them.  I read that a
> glmm allows for correlation between the observations of the same
> random factor. Does this mean that a glmm takes into account the
> fact that the dissimilarity values are not independent from each
> other? Or should I somehow take into account the fact that
> dissimilarity values in the same archipelago are not independent of
> each other.

  This is a little bit tricky.  You *might* be able to do this
by using 'island identity' as a random factor as well, but it's
also quite possible that you would just run out of data that way.
People often use Mantel and partial Mantel tests to do inference
on these kinds of pairwise comparisons (i.e. use randomization
to compare the matrix of pairwise area differences with the matrix
of pairwise compositional dissimilarities).  It's certainly
the case that the model you've set up so far does *not* account
for the correlation due to island identity.

  Ben Bolker


From bbolker at gmail.com  Mon May  7 15:33:48 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 7 May 2012 13:33:48 +0000 (UTC)
Subject: [R-sig-ME] problem with ranef
References: <mailman.5316.1336380650.4540.r-sig-mixed-models@r-project.org>
	<9A457AC9-E6CE-472B-BF55-642998D1DB26@bristol.ac.uk>
	<CAHHAJfuVw8hmOTyFs8NgkdCNxrT=B61yNQZ+aybwZZpFSxw1HA@mail.gmail.com>
Message-ID: <loom.20120507T153223-676@post.gmane.org>

Gabriela de Queiroz <gabidequeiroz at ...> writes:

> 
> Thanks Malcom!
> 
> This is a good command. I didn't know it.
> 
> I was having problem with library conflicts. I unloaded everything and then
> loaded only lme4.
> 
> Thanks again,
> Gabriela

Googling the entire error message

no applicable method for 'ranef' applied to an object of class "mer"

finds

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003458.html

which answers the question too ... I have also added this to 
the error message section of http://glmm.wikidot.com/faq now.


From highstat at highstat.com  Mon May  7 15:59:37 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 07 May 2012 09:59:37 -0400
Subject: [R-sig-ME] New book: Zero Inflated Models and GLMM with R
Message-ID: <4FA7D549.5000401@highstat.com>

Apologies for cross-posting

Members of this mailing list may be interested in the following book:


Zero Inflated Models and Generalized Linear Mixed Models with R.
Zuur, Saveliev, Ieno. (2012)


This book is only available from:
http://www.highstat.com/book4.htm

Kind regards,

Alain Zuur

-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From epitta at upatras.gr  Mon May  7 17:25:16 2012
From: epitta at upatras.gr (=?UTF-8?Q?=CE=A0=CE=AF=CF=84=CF=84=CE=B1_E=CF=8D=CE=B1?=)
Date: Mon, 07 May 2012 18:25:16 +0300
Subject: [R-sig-ME] request for help with glmm
Message-ID: <04e55313a87e72e41a43798e0986f6a8@upatras.gr>

Thank you for your response.
I have built this model:

data.lmer6=glmer(Beta_diversity ~ 
Taxon+Island+log10(Area+1)+log10(Distance+1)+log10(Elevation+1)+(1|Archipelago/Island), 
data=data_mine, family="binomial", weights=c(N))


The problem of non independence is restricted only to data from the 
same archipelago but I used archipelago as a random factor.
If a glmm allows for correlation between the observations of the same 
random factor doesn't it mean that I can use it in this case?

? did partial mantel tests to check for correlations between beta 
diveristy and inter-island distance, area and elevation differences 
between islands
in the same archipelago (in my case an archipelago can have oceanic or 
landbridge islands but not both kinds).
But I also wanted to test for the effect of taxon and island type 
(oceanic vs landbridge) on beta diversity and I could not do
that with mantel tests. So I used a mixed model.

The data are to complex for any other kind of analyses.
I understand that if the observations where from only one archipelago I 
could run a regression and due to the lack of independence of 
observations
I would estimate the regression parameters using bootstrap.
But in this case (because I have 11 archipelagos) I do not have a 
complete lack of independence because observations from different 
archipelagos are independent.
And even if a bootstrap was the correct way to go I do not think that 
there is an available procedure for this. Or if it is even possible to 
bootstrap a mixed effects model.

I have enough data (3076 observations) to support a glmm.

The output from the model is the following:

Generalized linear mixed model fit by the Laplace approximation
Formula: Beta_diversity ~ Taxon + Island + log10(Area + 1) + 
log10(Distance +      1) + log10(Elevation + 1) + (1 | 
Archipelago/Island)
    Data: data_mine
   AIC  BIC logLik deviance
  4723 4777  -2353     4705
Random effects:
  Groups             Name        Variance Std.Dev.
  Island:Archipelago (Intercept) 0.22045  0.46952
  Archipelago        (Intercept) 0.22045  0.46952
Number of obs: 3076, groups: Island:Archipelago, 11; Archipelago, 11

Fixed effects:
                      Estimate Std. Error z value Pr(>|z|)
(Intercept)          -1.84347    0.31407  -5.870 4.37e-09 ***
Taxonlizards         -0.27649    0.09055  -3.053  0.00226 **
Taxonsnakes          -0.10781    0.09258  -1.165  0.24420
Islandoceanic         0.84422    0.41087   2.055  0.03991 *
log10(Area + 1)       0.12917    0.02497   5.173 2.31e-07 ***
log10(Distance + 1)   0.41862    0.02587  16.182  < 2e-16 ***
log10(Elevation + 1)  0.16041    0.03128   5.128 2.93e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) Txnlzr Txnsnk Islndc l10(A+1 l10(D+1
Taxonlizrds -0.221
Taxonsnakes -0.212  0.922
Islandocenc -0.560 -0.061 -0.049
log10(Ar+1) -0.038  0.047  0.031 -0.014
lg10(Dst+1) -0.399  0.014  0.009 -0.017  0.023
lg10(Elv+1) -0.131  0.008  0.001  0.003 -0.608  -0.014


Do you think I could trust this model?

Thnak's
Eva Pitta



????? E?? <epitta at ...> writes:


     Hi, I am a phd student in Greece. And I have some questions 
regarding the use of glmm if the data include dissimilarity values.


     I do not know if this mailing list is appropriate for my questions 
but I do not know who else to turn to.


   You might be better off with the r-sig-ecology mailing list,
where there will be more expertise on community ecology topics
such as beta diversity ...


     My data include islands in various archipelagos and 
presence-absence of species of 3 taxa on the them. I estimated beta 
diversity as compositional dissimilarity between pairs of islands in the 
same archipelago using the Jaccard coefficient (proportion of common 
species between two islands). For example if I have 5 islands in a given 
archipelago I end up with 10 dissimilarity values. I fitted a glmm model 
(using package lme4) to test for the effect of taxon and also the effect 
of inter-island distance, area and elevation differences between pairs 
of islands on beta diversity using archipelago as a random factor. 
However, dissimilarity values (and the rest) are not independent of each 
other in the same archipelago, because each island contributes to N - 1 
of them. I read that a glmm allows for correlation between the 
observations of the same random factor. Does this mean that a glmm takes 
into account the fact that the dissimilarity values are not independent 
from each other? Or should I somehow take into account the fact that 
dissimilarity values in the same archipelago are not independent of each 
other.


   This is a little bit tricky.  You *might* be able to do this
by using 'island identity' as a random factor as well, but it's
also quite possible that you would just run out of data that way.
People often use Mantel and partial Mantel tests to do inference
on these kinds of pairwise comparisons (i.e. use randomization
to compare the matrix of pairwise area differences with the matrix
of pairwise compositional dissimilarities).  It's certainly
the case that the model you've set up so far does *not* account
for the correlation due to island identity.

   Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From praguewatermelon at gmail.com  Mon May  7 18:44:09 2012
From: praguewatermelon at gmail.com (Xiao He)
Date: Mon, 7 May 2012 09:44:09 -0700
Subject: [R-sig-ME] How to capture the warning message when a lmer model
 fails to converge or have singular convergence
Message-ID: <CAGBzz=L4thqQ2zkuzfq_wLQz7j1ctnOe5uNPmkWJwfkE-3BMiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120507/2d163a6f/attachment.pl>

From doon75 at hotmail.com  Mon May  7 19:33:20 2012
From: doon75 at hotmail.com (Darren)
Date: Mon, 7 May 2012 14:33:20 -0300
Subject: [R-sig-ME] request for help with glmm
Message-ID: <DUB109-DS142E58FBAD59F135A84D56C7130@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120507/b527d9b0/attachment.pl>

From David.Duffy at qimr.edu.au  Tue May  8 00:05:54 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 8 May 2012 08:05:54 +1000
Subject: [R-sig-ME] pedigreemm and heritability of binary data
Message-ID: <6F35A958A12B9149BD16E3C2F3B0AD0DB3786A@SPHINX.adqimr.ad.lan>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120508/3d85e42d/attachment.pl>

From angelina.mukherjee88 at gmail.com  Tue May  8 15:33:05 2012
From: angelina.mukherjee88 at gmail.com (Angelina Mukherjee)
Date: Tue, 8 May 2012 14:33:05 +0100
Subject: [R-sig-ME] Specifying correlation structure in lme
Message-ID: <CAMFXY1=qZvt5T9Jx2hoJ3689p5fd+VRAbWD57h-gY27f0qoN4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120508/dee3a244/attachment.pl>

From deter088 at umn.edu  Tue May  8 15:42:17 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 8 May 2012 08:42:17 -0500
Subject: [R-sig-ME] gls vs lme covariance structures
In-Reply-To: <CANz9Z_+3Y5qO2MbdH5_opWpQPdT4Lv5kdqiZLeRD4CTkQPsbYg@mail.gmail.com>
References: <CAOLJph=S5OcrPLzMe0sWu7=5KxSaPc9AZ9ce6Rk3s4UaOp2aYg@mail.gmail.com>
	<CANz9Z_L0uOyOi9FJsDGgh807VSfqOhqd514=H3YegPf_NbwCCw@mail.gmail.com>
	<CAOLJph=ErPh_zAWMigjj7uw3BpXV8kZc66x0WWCJpcMfdkWOFg@mail.gmail.com>
	<CANz9Z_JYcSput9=kB8ibkvooKcABZWfTRDm4QZU9tmYYcxnOHQ@mail.gmail.com>
	<CAOLJphnt-5=+3+ESLQXEfB4ccqS22XtFabV=mFXOQkvkOi_Fhw@mail.gmail.com>
	<CANz9Z_+3Y5qO2MbdH5_opWpQPdT4Lv5kdqiZLeRD4CTkQPsbYg@mail.gmail.com>
Message-ID: <CAOLJphmYJ=MJTzdDXS=EnP-a=CXcX-Dd_A1gd1_jriZ-=jpQWg@mail.gmail.com>

Thanks for your assistance Joshua, I really appreciate you weighing in
on this.  The autoregressive results are just fine; however, the
unstructured results are still very different between the SAS UN
structure and R corSymm().  Any further thoughts as to why this may be
or how it may be addressed?

Regards,
Charles

On Sat, May 5, 2012 at 10:05 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Charles,
>
> I know you were not trying to make it difficult, no worries. ?Most of
> the results seem to match fairly closely. ?Here is some stuff you can
> try if you want (also added some residual plots and examination of the
> distribution of random effects which is assumed gaussian).
>
> Cheers,
>
> Josh
>
> ####################################################
> dat=read.table("subset.csv",sep=",",header=TRUE, na.strings=".")
> dat34=dat[dat$group %in% c("3", "4"),]
> dat34=within(dat34, {
> ? ? ? ?group=factor(group)
> ? ? ? ?Event_name=factor(Event_name)
> ? ? ? ?Died=factor(Died)
> ? ? ? ?ID=factor(ID)
> })
> contrasts(dat34$Event_name)=contr.sum(n=6)
> contrasts(dat34$group)=contr.sum(n=2)
> contrasts(dat34$Died)=contr.sum(n=2)
> dat34$rep <- unlist(sapply(rle(as.numeric(dat34$ID))$lengths, seq.int))
>
> require(nlme)
> require(lattice)
>
> m.run <- lme(var ~ group + Event_name + Died,
> ?random = ~ 1 | ID, corr = corSymm(), data = dat34)
> ## store residuals and plot
> dat34$r.mrun <- resid(m.run)
> xyplot(r.mrun ~ rep | ID, data = dat34)
> ## examine distribution of random effects
> qqmath(ranef(m.run)[[1]])
> summary(m.run)
> ## Linear mixed-effects model fit by REML
> ## ?Data: dat34
> ## ? ? ? ?AIC ? ? ?BIC ? logLik
> ## ? 47.06365 116.5417 1.468174
>
> ## Random effects:
> ## ?Formula: ~1 | ID
> ## ? ? ? ? (Intercept) ?Residual
> ## StdDev: ? 0.3934213 0.2635925
>
> ## Correlation Structure: General
> ## ?Formula: ~1 | ID
> ## ?Parameter estimate(s):
> ## ?Correlation: ?<-- you can see the unstructure correlation matrix
> ## ? 1 ? ? ?2 ? ? ?3 ? ? ?4 ? ? ?5
> ## 2 ?0.289
> ## 3 ?0.553 ?0.774
> ## 4 ?0.225 ?0.532 ?0.752
> ## 5 ?0.532 ?0.635 ?0.844 ?0.662
> ## 6 ?0.717 -0.052 ?0.361 -0.053 ?0.535
>
> anova(m.run, type = "marginal", adjustSigma = FALSE)
> ## ? ? ? ? ? ? numDF denDF ?F-value p-value
> ## (Intercept) ? ? 1 ? ?96 9.816408 ?0.0023
> ## group ? ? ? ? ? 1 ? ?23 0.131949 ?0.7197
> ## Event_name ? ? ?5 ? ?96 1.081781 ?0.3754
> ## Died ? ? ? ? ? ?1 ? ?23 0.074427 ?0.7874
>
>
> #Output should be: (SAS mixed procedure with UN)
> #Type 3 Tests of Fixed Effects
> #Effect ? ? ? ?NumDF DenDF ?F Value ? ?Pr > F
> #Pig_group ? ? ? ? 1 ? ?23 ? ? 2.73 ? ?0.1120
> #Event_name ? ? ? ?5 ? ?23 ? ? 1.11 ? ?0.3806
> #Died ? ? ? ? ? ? ?1 ? ?23 ? ? 0.51 ? ?0.4833
>
>
> ## group*Event_name expands to: group + Event_name + group:Event_name
> ## i.e., main effects + interaction, like "group | Event_name in proc mixed
> m.run2 <- lme(var2 ~ group*Event_name + Died,
> ?random = ~ 1 | ID, corr = corSymm(), data = dat34)
> dat34$r.run2 <- resid(m.run2)
> xyplot(r.run2 ~ rep | ID, data = dat34)
> ## examine distribution of random effects
> qqmath(ranef(m.run2)[[1]])
> summary(m.run2)
>
> ## auto regressive model
> m.rar1 <- lme(var2 ~ group*Event_name + Died,
> ?random = ~ 1 | ID, corr = corAR1(), data = dat34)
> ## store residuals and plot
> dat34$r.rar1 <- resid(m.rar1)
> xyplot(r.rar1 ~ rep | ID, data = dat34)
> ## examine distribution of random effects
> qqmath(ranef(m.rar1)[[1]])
> summary(m.rar1)
> ## Linear mixed-effects model fit by REML
> ## ?Data: dat34
> ## ? ? ? ?AIC ? ? BIC ? ?logLik
> ## ? 413.8188 457.598 -190.9094
>
> ## Random effects:
> ## ?Formula: ~1 | ID
> ## ? ? ? ? (Intercept) Residual
> ## StdDev: ? ?0.383367 1.004379
>
> ## Correlation Structure: AR(1)
> ## ?Formula: ~1 | ID
> ## ?Parameter estimate(s):
> ## ? ? ? Phi
> ## 0.1092874 <-- phi (rho) autocorrelation estimate
>
> anova(m.rar1, type = "marginal", adjustSigma = FALSE)
> ## ? ? ? ? ? ? ? ? ?numDF denDF ?F-value p-value
> ## (Intercept) ? ? ? ? ?1 ? ?91 337.2176 ?<.0001
> ## group ? ? ? ? ? ? ? ?1 ? ?23 ? 0.9015 ?0.3523
> ## Event_name ? ? ? ? ? 5 ? ?91 ?15.9816 ?<.0001
> ## Died ? ? ? ? ? ? ? ? 1 ? ?23 ? 1.4741 ?0.2370
> ## group:Event_name ? ? 5 ? ?91 ? 3.4790 ?0.0064
>
> ## Output should be:
> ## Type 3 Tests of Fixed Effects (SAS mixed procedure with AR(1))
> ## Effect ? ? ? ? ? ? ? ? NumDF ? DenDF F Value ?Pr > F
> ## Pig_group ? ? ? ? ? ? ? ? ?1 ? ? ?23 ? ?0.99 ?0.3293
> ## Event_name ? ? ? ? ? ? ? ? 5 ? ? ?91 ? 16.23 ?<.0001
> ## Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ?23 1.70 0.2047
> ## Pig_group*Event_name ? ? ? 5 ? ? ?91 ? ?3.04 ?0.0140
>
>
> ## compare auto regressive with unstructured
> anova(m.run2, m.rar1)
> ####################################################
>
>
> On Fri, May 4, 2012 at 6:00 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
>> Joshua,
>>
>> My apologies, I never intended to make it more difficult for people to
>> help. ?I only wish to be very careful when I every work with data. ?I
>> have created a subset as you requested in the attached csv file. ?The
>> two covariance structures I wish to do with a mixed model are (UN) for
>> var, and (AR(1)) for var2.
>>
>> dat=read.table("C:/?/subset.csv",sep=",",header=TRUE, na.strings=".")
>> attach(dat)
>>
>> dat34=dat[Pig_group %in% c("3", "4"),]
>> attach(dat34)
>> dat34=within(dat34, {
>> ? ? ? ?group=factor(group)
>> ? ? ? ?Event_name=factor(Event_name)
>> ? ? ? ?Died=factor(Died)
>> ? ? ? ?ID=factor(ID)
>> })
>> attach(dat34)
>>
>> contrasts(dat34$Event_name)=contr.sum(n=6)
>> contrasts(dat34$group)=contr.sum(n=2)
>> contrasts(dat34$Died)=contr.sum(n=2)
>>
>>
>> The models I wish to fit with a mixed model are:
>> UN
>> var~group+Event_name+Died,
>> random=~1|ID
>> corr=corSymm()?
>> anova(fit, type=?marginal?, adjustSigma=F)
>>
>> #Output should be: (SAS mixed procedure with UN)
>> Type 3 Tests of Fixed Effects
>> Effect ? ? ? ?NumDF DenDF F Value Pr > F
>> Pig_group ? ? ? ? ?1 ? ?23 ? ? ?2.73 ? ?0.1120
>> Event_name ? ? ? 5 ? ? ?23 ? ? ?1.11 ? ?0.3806
>> Died ? ? ? ? ? ? ? ? ?1 ? ? ? ? 23 ? ? ?0.51 ? ?0.4833
>>
>> AR(1)
>> var2~group+Event_name+Died+group*Event_name
>> random=~1|ID
>> corr=corAR1()?
>> anova(fit, type=?marginal?, adjustSigma=F)
>>
>> Output should be:
>> Type 3 Tests of Fixed Effects (SAS mixed procedure with AR(1))
>> Effect ? ? ? ? ? ? ? ? ? ? ? ? ?NumDF ? ? DenDF F Value Pr > F
>> Pig_group ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? 23 ? ?0.99 ? ? ?0.3293
>> Event_name ? ? ? ? ? ? ? ? ? ? ? ? ? 5 ? ? ? ? ? ? ? 91 ? ?16.23 ? ?<.0001
>> Died ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ?23 ? ?1.70 ? ? ?0.2047
>> Pig_group*Event_name ? ? ? ? ? 5 ? ? ? ? ? ? 91 ? ?3.04 ? ? 0.0140
>>
>>
>> Many thanks, I truly appreciate the guidance,
>> Charles
>>
>> On Thu, May 3, 2012 at 3:59 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>>
>>> Hi Charles,
>>>
>>> Well you could post a subset of it, or make up some data that is
>>> sharable (whether the data make any sense is not important to us, just
>>> nice to have runable code, for example your previous thread about
>>> contrasts could have been solved in one email if we could have shown
>>> you how to set the contrasts on your data and then it matched your SAS
>>> output). ?In any case, whether you use lme or gls really depends on
>>> your question and goals, I think. ?Generalized least squares is not
>>> the same as a random effects model. ?If you want a random effect, you
>>> cannot use gls. ?If you just want correlated errors, gls is fine.
>>>
>>> This part of your code strikes me as atypical though I cannot promise
>>> it is wrong/not what you want: corr=corAR1(ID)
>>>
>>> Cheers,
>>>
>>> Josh
>>>
>>>
>>> On Thu, May 3, 2012 at 1:44 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
>>> > Hi Joshua,
>>> >
>>> > Thanks for your response.? It is probably best that I don't post the data as
>>> > some of it is not yet published.? My main question is whether UN and AR(1)
>>> > should be done with gls or if I have done the syntax incorrectly with lme.
>>> > Since AR(1) is replicated perfectly if I put the correct dendf, I can work
>>> > with it.? And UN is close, so I just want to be sure my use and syntax are
>>> > correct, not necessarily modifying the data.
>>> >
>>> > Regards,
>>> > Charles
>>> >
>>> >
>>> > On Thu, May 3, 2012 at 3:21 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>>> >>
>>> >> Hi Charles,
>>> >>
>>> >> Could you upload the dataset you are using somewhere and post the
>>> >> link? ?Something like:
>>> >>
>>> >> ##########
>>> >> dat34 <- read.csv("http:/wherever/you/uploaded/yourdata.csv", header =
>>> >> TRUE)
>>> >> ## code to convert to factors anything that needs to be etc.
>>> >> ##########
>>> >>
>>> >> Then it is easier for us to try things that way.
>>> >>
>>> >> corAR1 and corSymm seem appropriate. ?Have you checked the examples in
>>> >> their documents? ?I found them helpful.
>>> >>
>>> >> Cheers,
>>> >>
>>> >> Josh
>>> >>
>>> >> On Thu, May 3, 2012 at 12:58 PM, Charles Determan Jr <deter088 at umn.edu>
>>> >> wrote:
>>> >> > Greetings R users,
>>> >> >
>>> >> > I have been attempting to replicate various covariance structures from
>>> >> > SAS's analysis of mixed models. ?I have successfully been able to
>>> >> > replicate
>>> >> > compound symmetry, however it becomes confusing with autoregression and
>>> >> > unstructured. ?As such, there are two questions regarding this issue.
>>> >> >
>>> >> > Autoregression
>>> >> > SAS output (Type III fixed effects) for covariance structure AR(1)
>>> >> >
>>> >> > *Type 3 Tests of Fixed Effects*
>>> >> >
>>> >> > *Effect ? ? ? ? ? ? ? ? ? ?NumDF DenDF F Value Pr > F*
>>> >> >
>>> >> > *group ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?0.99 ? ? ?0.3293
>>> >> >
>>> >> > *Event_name ? ? ? ? ? ? ? *5 ? ? ? ? 91 ? ? ? ? 16.23 ? ?<.0001
>>> >> >
>>> >> > *Died ? ? ? ? ? ? ? ? ? ? ? ? ? ?*1 ? ? ? ? 23 ? ? ? ? ?1.70 ? ? ?0.2047
>>> >> >
>>> >> > *group*Event_name ?*5 ? ? ? ?91 ? ? ? ? ?3.04 ? ? 0.0140
>>> >> >
>>> >> > R output (corAR1=AR(1)?)
>>> >> > I can replicate these results if I run the following:
>>> >> >
>>> >> > fit.18=gls(var~group+Event_name+Died+group*Event_name,
>>> >> > ? ?data=dat34,
>>> >> > ? ?corr=corAR1(, ~1|ID),
>>> >> > ? ?weight=varIdent(~1|Event_name))
>>> >> > anova(fit.18, type="marginal", adjustSigma=F)
>>> >> >
>>> >> > #the DenDF are off with gls, so use the 'correct' ones
>>> >> > 1-pf(.9935, 1, 23)
>>> >> > 1-pf(16.2323, 5, 91)
>>> >> > 1-pf(1.7041, 1, 23)
>>> >> > 1-pf(3.0367, 5, 91)
>>> >> > #and the output matches exactly
>>> >> >
>>> >> > However, I can not get the lme function to run the autoregression. ?The
>>> >> > output is very different:
>>> >> >
>>> >> > fit.11=lme(var~group+Event_name+Died+group*Event_name,
>>> >> > ? ?data=dat34,
>>> >> > ? ?random=~1|ID,
>>> >> > ? ?corr=corAR1(ID),
>>> >> > ? ?weight=varIdent(~1|Event_name))
>>> >> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>>> >> >
>>> >> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>>> >> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
>>> >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
>>> >> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
>>> >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>>> >> >
>>> >> > Is this type of covariance structure only done with gls and I should
>>> >> > continue with the analysis as such or am I doing something silly with
>>> >> > lme?
>>> >> >
>>> >> > My second question is with regards to the unstructured covariance.
>>> >> > SAS output (UN)
>>> >> >
>>> >> > *Type 3 Tests of Fixed Effects*
>>> >> >
>>> >> > *Effect ? ? ? ?NumDF DenDF F Value Pr > F*
>>> >> >
>>> >> > *Pig_group ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 2.73 ? ?0.1120
>>> >> >
>>> >> > *Event_name *5 ? ? ? ? ? ?23 ? ? ? ? 1.11 ? ?0.3806
>>> >> >
>>> >> > *Died ? ? ? ? ? ? ?*1 ? ? ? ? ? ?23 ? ? ? ? 0.51 ? ?0.4833
>>> >> >
>>> >> > R output (corSymm = UN?)
>>> >> > fit.11=lme(var2~group+Event_name+Died,
>>> >> > ? ?data=dat34,
>>> >> > ? ?random=~1|ID,
>>> >> > ? ?corr=corSymm(, ~1|ID),
>>> >> > ? ?weight=varIdent(~1|Event_name))
>>> >> > anova.lme(fit.11, type="marginal", adjustSigma=F)
>>> >> >
>>> >> > #same as corAR1???
>>> >> > ? ? ? ? ? ? ? ? ? ? ? numDF denDF ?F-value ? ? ?p-value
>>> >> > (Intercept) ? ? ? ? ? ? ? 1 ? ?96 ? ? ? ?9.816419 ?0.0023
>>> >> > group ? ? ? ? ? ? ? ? ? ? ?1 ? ?23 ? ? ? 0.131950 ?0.7197
>>> >> > Event_name ? ? ? ? ? ?5 ? ?96 ? ? ? ?1.081785 ?0.3754
>>> >> > Died ? ? ? ? ? ? ? ? ? ? ? 1 ? ?23 ? ? ? ?0.074428 ?0.7874
>>> >> >
>>> >> > but with gls
>>> >> > fit.18=gls(var~group+Event_name+Died,
>>> >> > ? ?data=dat34,
>>> >> > ? ?corr=corSymm(~1|ID),
>>> >> > ? ?weight=varIdent(~1|Event_name))
>>> >> > anova(fit.18, type="marginal", adjustSigma=F)
>>> >> >
>>> >> > 1-pf(2.869837, 1, 23)
>>> >> > 1-pf(1.126747, 5, 23)
>>> >> > 1-pf(.514726, 1, 23)
>>> >> >
>>> >> > [1] 0.1037549
>>> >> > [1] 0.3742309
>>> >> > [1] 0.4803239
>>> >> >
>>> >> > #close but not exact (however I can work with this if it is indeed
>>> >> > correct)
>>> >> >
>>> >> > Overall, I want to clarify the difference between gls and lme and if I
>>> >> > am
>>> >> > simply making some weird syntax error with lme that I can't seem to get
>>> >> > the
>>> >> > covariance structures to match.
>>> >> >
>>> >> >
>>> >> > Apologies for lots of information in one go, but hopefully this provides
>>> >> > necessary information to point me in the correct direction.
>>> >> >
>>> >> > Thanks to any and all who give their time to these questions,
>>> >> >
>>> >> > Regards,
>>> >> > Charles
>>> >> >
>>> >> > ? ? ? ?[[alternative HTML version deleted]]
>>> >> >
>>> >> > _______________________________________________
>>> >> > R-sig-mixed-models at r-project.org mailing list
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> Joshua Wiley
>>> >> Ph.D. Student, Health Psychology
>>> >> Programmer Analyst II, Statistical Consulting Group
>>> >> University of California, Los Angeles
>>> >> https://joshuawiley.com/
>>> >
>>> >
>>>
>>>
>>>
>>> --
>>> Joshua Wiley
>>> Ph.D. Student, Health Psychology
>>> Programmer Analyst II, Statistical Consulting Group
>>> University of California, Los Angeles
>>> https://joshuawiley.com/
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/


From torvon at gmail.com  Tue May  8 18:52:46 2012
From: torvon at gmail.com (Eiko Fried)
Date: Tue, 8 May 2012 18:52:46 +0200
Subject: [R-sig-ME] LME4: interpretation of multivariate interaction effect
Message-ID: <CACm_P7r8PsHz=bDmDxCeiBhTVYGfjEoetawU_epM4ChpS9bb5w@mail.gmail.com>

Dear Mailing List,

My model is this:
> m1<-lmer( Y ~ -1 + as.factor(Y_index) * X + (-1+as.factor(Y_Index)|subject), data=data2, REML=FALSE)

I have 9 response variables (items from a screening instrument), and
reorganized the data to have them in one row ("Y"). The variable
"Y_index" denominates the 9 different variables for Y (e.g. Y_index=2
is my second response variable).
The data are in a long format, every subjects has 9 lines.

I have a hard time interpreting the interaction output.

Fixed effects:
                                 Estimate  Std. Error  t value
as.factor(Y_index)1      0.46177    0.05965   7.742
as.factor(Y_index)2      0.40207    0.05908   6.806
as.factor(Y_index)3      0.44255    0.07527   5.879
as.factor(Y_index)4      0.92783    0.07236  12.822
as.factor(Y_index)5      0.55113    0.07881   6.993
as.factor(Y_index)6      0.31863    0.06442   4.946
as.factor(Y_index)7      0.28208    0.06152   4.585
as.factor(Y_index)8      0.17036    0.04734   3.598
as.factor(Y_index)9      0.10635    0.03836   2.772
X                                0.02473    0.03732   0.663
as.factor(Y_index)2:X   0.04296    0.03197   1.344
as.factor(Y_index)3:X   0.16419    0.04482   3.664
as.factor(Y_index)4:X   0.10612    0.04076   2.604
as.factor(Y_index)5:X   0.09108    0.04480   2.033
as.factor(Y_index)6:X   0.06488    0.03307   1.962
as.factor(Y_index)7:X   0.03331    0.03633   0.917
as.factor(Y_index)8:X  -0.01012    0.03591  -0.282
as.factor(Y_index)9:X  -0.05029    0.03893  -1.292


Do I understand correctly that "X" here is (Y_index)1:X, and the
reference line for the interpretation of the other interaction lines?
E.g. (Y_index)5, my 5th response variable, is [Estimate] .09 higher
than (Y_index)1, my first response variable, and with a t of 2.033
probably significantly higher? That is, X affects my fifth response
variable significantly stronger than my first response variable?

Thank you for your patience
E


From bbolker at gmail.com  Tue May  8 19:22:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 May 2012 17:22:34 +0000 (UTC)
Subject: [R-sig-ME] Specifying correlation structure in lme
References: <CAMFXY1=qZvt5T9Jx2hoJ3689p5fd+VRAbWD57h-gY27f0qoN4Q@mail.gmail.com>
Message-ID: <loom.20120508T191149-276@post.gmane.org>

Angelina Mukherjee <angelina.mukherjee88 at ...> writes:


> I'm trying to use AR1 as a correlation structure in modeling data. My
> variables, Patient and Region, are factors with Region nested in Patient.
> Expression is my Response variable.
> 
> *Patient <- c(rep('1', 10), rep('2', 12))*
> 
> *Region <- c(rep('1', 3), rep('2', 3), rep('3', 4), rep('4', 4), rep('5',
> 4), rep('6', 4))*
> library(nlme)

  Are you really using character variables?  I don't think that works
(although other aspects of your coding appear to have been mangled
in transition, so maybe that's another one).

I can replicate your error as follows:

df <- data.frame(Patient=factor(rep(1:2,c(10,12))),
                 Region=rep(1:6,c(3,3,4,4,4,4)),
                 Expression=rnorm(22))

library(nlme)
m0 <- lme(Expression ~ Patient + Region,
    random = ~1 |Patient/Region,
    correlation=corAR1(form=~1 | Patient/Region), data=df)

lme(Expression ~ Patient  + Region,
    random = ~1 | Patient/Region,
    correlation=corAR1(form=~Region | Patient/Region), data=df)

You're basically stuck here, the constraint on gls models is
as suggested by the error message -- covariate values must be
unique within grouping factors.

By the way, there are several other potential issues here (some
of which I think I've pointed out previously)

 * I don't remember whether you said you really only have two
patients; in that case treating patient as a random effect is
unlikely to work very well.
 * In any case, including a categorical predictor (such as Patient)
as both a random and a fixed effect probably leads to an
unidentifiable model (intervals(m0) indicates an non-positive-definite
variance-covariance matrix, a sign of trouble)
 * ideally I would probably prefer to use a random effect of
interaction(Patient,Region), and put correlations on Region
within Patient, but that is really beyond the scope of lme.

  Accepting a cruder model, or finding a local statistical
consultant, may be your choices ...


From maddie.wang at yahoo.com  Tue May  8 20:05:33 2012
From: maddie.wang at yahoo.com (Maddie Wang)
Date: Tue, 8 May 2012 11:05:33 -0700 (PDT)
Subject: [R-sig-ME] some questions about "lmer" in GLMM
Message-ID: <1336500333.3424.YahooMailNeo@web120601.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120508/15615750/attachment.pl>

From mheggli at gmx.net  Tue May  8 22:46:50 2012
From: mheggli at gmx.net (Martin Heggli)
Date: Tue, 8 May 2012 22:46:50 +0200
Subject: [R-sig-ME] Estimating p-value for fixed effect which occurs also in
	interaction
Message-ID: <120984CC-F714-447D-ADD9-8AE508F6DD8C@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120508/6c2eb997/attachment.pl>

From David.Duffy at qimr.edu.au  Wed May  9 01:32:23 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 9 May 2012 09:32:23 +1000 (EST)
Subject: [R-sig-ME] some questions about "lmer" in GLMM
In-Reply-To: <1336500333.3424.YahooMailNeo@web120601.mail.ne1.yahoo.com>
References: <1336500333.3424.YahooMailNeo@web120601.mail.ne1.yahoo.com>
Message-ID: <Pine.LNX.4.64.1205090918520.30765@orpheus.qimr.edu.au>

On Tue, 8 May 2012, Maddie Wang wrote:

Hi.

> I have a question about lmer for GLMM that I cannot find an answer 
> on-line for quite a bit time. Suppose the response y is from a binomial 
> distribution. The GLMM can be written as 
> logit(pi)=x*\beta+z1b1+z2b2+z3b3, where pi is the expectation of 
> binomial proportion, \beta is the fixed coefficients, b1,b2 and b3 are 
> three random effects, where b1 is from a multivariate normal MN(0, \tau1 
> * I_(3X3)), b2 is from a multivariate normal MN(0, \tau2 * I_(3X3)), and 
> b3 is from a multivariate normal MN(0, \tau3 * I_(4X4)).

I'm having trouble understanding your setup.  Why is b3 4X4 - are these 
crossed indicator variables with 3,3,4 levels?  And if so, what design and 
how much data?  Are the taus prespecified somehow?

Cheers, David Duffy.


From David.Duffy at qimr.edu.au  Wed May  9 01:37:55 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 9 May 2012 09:37:55 +1000 (EST)
Subject: [R-sig-ME] Estimating p-value for fixed effect which occurs
	also ininteraction
In-Reply-To: <120984CC-F714-447D-ADD9-8AE508F6DD8C@gmx.net>
References: <120984CC-F714-447D-ADD9-8AE508F6DD8C@gmx.net>
Message-ID: <Pine.LNX.4.64.1205090933050.30765@orpheus.qimr.edu.au>

On Tue, 8 May 2012, Martin Heggli wrote:

> Dear listers,
>
> I am evaluating an experiment in plant ecology. Since the experiment has 
> both crossed and nested random factors and the data are unbalanced, I 
> decided to use linear mixed effects models (lmer from lme4). Right now, 
> I am struggling to determine the significance of the fixed factors. I 
> tried to estimate the p-value for the fixed factors by dropping 
> individual factors from the model and comparing the two models with 
> anova (cf. code below). However, I run into trouble when I try to drop 
> the factor Origin from the model which occurs also in the Origin:Soil 
> interaction term.

The main effect of Origin gets absorbed by Origin:Soil ie you have only 
changed the interpretation.  If Origin:Soil is necessary to the model, you 
probably want to examine Soil within each level of Origin.

Just 2c, David Duffy.


From broog731 at newschool.edu  Wed May  9 02:28:04 2012
From: broog731 at newschool.edu (Geoff Brookshire)
Date: Tue, 8 May 2012 20:28:04 -0400
Subject: [R-sig-ME] Estimating p-value for fixed effect which occurs
	also ininteraction
In-Reply-To: <Pine.LNX.4.64.1205090933050.30765@orpheus.qimr.edu.au>
References: <120984CC-F714-447D-ADD9-8AE508F6DD8C@gmx.net>
	<Pine.LNX.4.64.1205090933050.30765@orpheus.qimr.edu.au>
Message-ID: <CAE1hoOqMomPvm+jqpNr-n=JP-d-5kFUoh0+DEoF8mw2_A=PAZw@mail.gmail.com>

Here's a similar question from a few months ago, with Ben Bolker's
very helpful response:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006690.html

cheers,
geoff

On Tue, May 8, 2012 at 7:37 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Tue, 8 May 2012, Martin Heggli wrote:
>
>> Dear listers,
>>
>> I am evaluating an experiment in plant ecology. Since the experiment has
>> both crossed and nested random factors and the data are unbalanced, I
>> decided to use linear mixed effects models (lmer from lme4). Right now, I am
>> struggling to determine the significance of the fixed factors. I tried to
>> estimate the p-value for the fixed factors by dropping individual factors
>> from the model and comparing the two models with anova (cf. code below).
>> However, I run into trouble when I try to drop the factor Origin from the
>> model which occurs also in the Origin:Soil interaction term.
>
>
> The main effect of Origin gets absorbed by Origin:Soil ie you have only
> changed the interpretation. ?If Origin:Soil is necessary to the model, you
> probably want to examine Soil within each level of Origin.
>
> Just 2c, David Duffy.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m.fairbrother at bristol.ac.uk  Wed May  9 11:11:25 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Wed, 9 May 2012 10:11:25 +0100
Subject: [R-sig-ME] spatial simultaneous autoregressive models
In-Reply-To: <A29D4105-737C-4298-A170-B5AB0DBCB52F@sheffield.ac.uk>
References: <A29D4105-737C-4298-A170-B5AB0DBCB52F@sheffield.ac.uk>
Message-ID: <D4698670-E8DC-4798-9872-84E116A5E570@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120509/84a00308/attachment.pl>

From alaextractor1 at gmail.com  Wed May  9 09:00:11 2012
From: alaextractor1 at gmail.com (rad ushan)
Date: Wed, 9 May 2012 03:00:11 -0400
Subject: [R-sig-ME] lmer, formula composition, repeated measurement
Message-ID: <CAGuTB==KHmhTLbVk6KFofkzvsR+wqsyj5ge0t94MgxGnLPh9Zg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120509/a254dc94/attachment.pl>

From bonamy at horus.ens.fr  Wed May  9 14:39:39 2012
From: bonamy at horus.ens.fr (Pierre de Villemereuil)
Date: Wed, 09 May 2012 14:39:39 +0200
Subject: [R-sig-ME] pedigreemm and heritability of binary data
In-Reply-To: <6F35A958A12B9149BD16E3C2F3B0AD0DB3786A@SPHINX.adqimr.ad.lan>
References: <6F35A958A12B9149BD16E3C2F3B0AD0DB3786A@SPHINX.adqimr.ad.lan>
Message-ID: <4FAA658B.1050502@horus.ens.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120509/739e41d8/attachment.pl>

From angelina.mukherjee88 at gmail.com  Wed May  9 16:59:51 2012
From: angelina.mukherjee88 at gmail.com (Angelina Mukherjee)
Date: Wed, 9 May 2012 15:59:51 +0100
Subject: [R-sig-ME] Specifying correlation structure in lme
In-Reply-To: <loom.20120508T191149-276@post.gmane.org>
References: <CAMFXY1=qZvt5T9Jx2hoJ3689p5fd+VRAbWD57h-gY27f0qoN4Q@mail.gmail.com>
	<loom.20120508T191149-276@post.gmane.org>
Message-ID: <CAMFXY1mqKWPuzxtTEy4oKiVB8iCVB7gM5-vMC==NJmU2kOT2sw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120509/f84d8d01/attachment.pl>

From Thierry.ONKELINX at inbo.be  Wed May  9 17:15:56 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 9 May 2012 15:15:56 +0000
Subject: [R-sig-ME] lmer, formula composition, repeated measurement
In-Reply-To: <CAGuTB==KHmhTLbVk6KFofkzvsR+wqsyj5ge0t94MgxGnLPh9Zg@mail.gmail.com>
References: <CAGuTB==KHmhTLbVk6KFofkzvsR+wqsyj5ge0t94MgxGnLPh9Zg@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427573842C8@inbomail.inbo.be>

Have a look at http://glmm.wikidot.com/faq and look for "Model specification"

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens rad ushan
Verzonden: woensdag 9 mei 2012 9:00
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] lmer, formula composition, repeated measurement

Dear all, I have a simple question regarding how to compose a formula for using with lmer.
Say I have 10 subjects with different phenotypes (dependent var Y) and one predictor variable measured 3 times for each subject (X). By other words:

Y Subj X
1  1  1.2
1  1  1.3
1  1  0.7
3  2  2.1
3  2  2.5
3  2  4
5  3  3
5  3  4
5  3  4
...

I would like know the correlation of Y with X (Y~X) and the effect of within subject variance on this correlation (say correlation corrected adjusted with variance).
How to compose a formula for lmer function? Is it correct: Y~X|subj or may be Y~x+1|subj? Thank you.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From smartpink111 at yahoo.com  Wed May  9 19:21:04 2012
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 May 2012 10:21:04 -0700 (PDT)
Subject: [R-sig-ME] Lmer- Convergence issues
Message-ID: <1336584064.30587.YahooMailNeo@web39406.mail.mud.yahoo.com>

Dear R mixed group,

Last week I posted a convergence issue (Warning message:In mer_finalize(ans) : false convergence (8)) while I was running one of my models.

(fmNC<-lmer(Response~Wavelength*Start_Resp*time+(1|resid)+(1+time|Subject)+(1|RepNest), verbose=TRUE,family=binomial,data=BehavdatOrig2)).? 


Then I came across David Hugh's blog (http://davidhughjones.blogspot.com/2009/11/lme-false-convergence.html) about the lmer false convergence. 


I divided the variable time by 10 (as it's estimate for beta was the smallest) and called it a new variable time1.? When I run the new model,

(fm<-lmer(Response~Wavelength*Start_Resp*time1+(1|resid)+(1+time1|Subject)+(1|RepNest), verbose=TRUE,family=binomial,data=BehavdatOrig2)), the convergence issue was solved and I am getting estimates of coefficients closer to what I get in other models.? Only difference in the coefficients were in the estimates and standard errors involving time.? It is now one decimal to the left (estimates for time I was getting previously in other models were 0.08, 0.086 with same z value and p value.? Same is true for the interactions).? 


I guess I need to convert to one decimal right for the time variable when I report.? 


I tried several ways to converge (from other posts), but none of them worked except the division,? 


Any comments will be appreciated.? ? 


Thanking you,
A.K.? ? 



Generalized linear mixed model fit by the Laplace approximation 
Formula: Response ~ Wavelength * Start_Resp * time1 + (1 | resid) + (1 + time1 | Subject) + (1 | RepNest) 
?? Data: BehavdatOrig2 
? AIC? BIC logLik deviance
?1325 1420 -645.7???? 1291
Random effects:
?Groups? Name??????? Variance?? Std.Dev.?? Corr?? 
?resid?? (Intercept) 6.9806e-11 8.3550e-06??????? 
?RepNest (Intercept) 9.0018e+00 3.0003e+00??????? 
?Subject (Intercept) 7.0247e+00 2.6504e+00??????? 
???????? time1?????? 1.2760e+01 3.5722e+00 -0.833 
Number of obs: 1960, groups: resid, 1960; RepNest, 98; Subject, 98

Fixed effects:
????????????????????????????????? Estimate Std. Error z value Pr(>|z|)??? 
(Intercept)??????????????????????? -4.0456???? 0.9875? -4.097 4.19e-05 ***
WavelengthGreen???????????????????? 0.5634???? 1.4388?? 0.392?? 0.6954??? 
WavelengthRed????????????????????? -5.1001???? 3.2495? -1.570?? 0.1165??? 
Start_RespL??????????????????????? 10.9094???? 1.9002?? 5.741 9.41e-09 ***
time1?????????????????????????????? 0.8834???? 0.8693?? 1.016?? 0.3095??? 
WavelengthGreen:Start_RespL??????? -2.7382???? 2.4821? -1.103?? 0.2700??? 
WavelengthRed:Start_RespL?????????? 1.9070???? 3.9939?? 0.477?? 0.6330??? 
WavelengthGreen:time1????????????? -0.9994???? 1.2802? -0.781?? 0.4350??? 
WavelengthRed:time1???????????????? 1.0487???? 2.4436?? 0.429?? 0.6678??? 
Start_RespL:time1????????????????? -3.8931???? 1.5605? -2.495?? 0.0126 *? 
WavelengthGreen:Start_RespL:time1? -0.1811???? 2.1123? -0.086?? 0.9317??? 
WavelengthRed:Start_RespL:time1???? 3.5655???? 3.2699?? 1.090?? 0.2755?? 



From lauren.hooton at gmail.com  Wed May  9 21:58:46 2012
From: lauren.hooton at gmail.com (Lauren Hooton)
Date: Wed, 9 May 2012 15:58:46 -0400
Subject: [R-sig-ME] How to use nlmer on a dataset with multiple fixed and
	random effects
Message-ID: <CAJLSt58z0Cd8c2E9rWfF4N6L+D6xh_d+xfMpKnHOC=7UScs7QA@mail.gmail.com>

Hello,

I am trying to model the effect of weather variables on bat activity
(passes/hour) over three years and multiple geographic locations.
Specifically, the effects are:

Fixed = temperature, wind speed, wind direction, pressure,
precipitation, relative humidity
Random = year, week, detector, hour
(Within each year there were multiple detectors recording bat
activity, and these detectors (locations) changed each year).

I started out using glmer() in lme4, with the following code:
LACI.model.8 <-
glmer(LACI~AvgTemp+AvgSpeed+AvgDirection+Pressure+Precip+RH+(1|year)+(1|weeks_July1)+(1|detector)+(1|GMT_hour),
data=allbatwxstd, family=poisson)

This worked well, but I now want to explore using a non-linear mixed
model instead, since I think that may be more appropriate (when bat
activity is plotted against the environmental effects, the
relationship between the two types of data appears roughly quadratic
in nature (an inverted parabola)).  I want to use nlmer() as opposed
to nlme(), since I have crossed random effects, but I am unsure of how
to write it. I have looked in the nlmer help file and tried to
understand the example using the Orange dataset, but I am confused as
to how the Asym, xmid, scal variables fit in, and how to use those in
conjunction with my variables.  Also, I don't know how to specify what
the starting values should be (ie:, how do you come up with starting
values?).

Any advice you could give on how to approach nlmer would be greatly appreciated.

Lauren Hooton, M.Sc.
Bat Biologist


From comtech.usa at gmail.com  Wed May  9 23:01:55 2012
From: comtech.usa at gmail.com (Michael)
Date: Wed, 9 May 2012 16:01:55 -0500
Subject: [R-sig-ME] How to convert the formula from LME4 to NLME?
Message-ID: <CAPNjSFaJpmQp-PSQ9SNAZWegdheC2zhLNTBmR_u+bQQu5B1jMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120509/09cd08cc/attachment.pl>

From bbolker at gmail.com  Wed May  9 23:07:13 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 May 2012 21:07:13 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?How_to_use_nlmer_on_a_dataset_with_multiple_?=
	=?utf-8?q?fixed_and=09random_effects?=
References: <CAJLSt58z0Cd8c2E9rWfF4N6L+D6xh_d+xfMpKnHOC=7UScs7QA@mail.gmail.com>
Message-ID: <loom.20120509T230519-662@post.gmane.org>

Lauren Hooton <lauren.hooton at ...> writes:

> 
> Hello,
> 
> I am trying to model the effect of weather variables on bat activity
> (passes/hour) over three years and multiple geographic locations.
> Specifically, the effects are:
> 
> Fixed = temperature, wind speed, wind direction, pressure,
> precipitation, relative humidity
> Random = year, week, detector, hour
> (Within each year there were multiple detectors recording bat
> activity, and these detectors (locations) changed each year).
> 
> I started out using glmer() in lme4, with the following code:
> LACI.model.8 <-
> glmer(LACI~AvgTemp+AvgSpeed+AvgDirection+Pressure+
>   Precip+RH+(1|year)+(1|weeks_July1)+(1|detector)+(1|GMT_hour),
> data=allbatwxstd, family=poisson)

  A quick question: can you use a quadratic function of one or
more of your continuous predictors in your model?  That is nonlinear
in terms of the original predictor, but it is still a linear *model*
(i.e. it is linear in terms of the parameters of the model).  You can
use either (e.g.) Pressure + I(Pressure^2), or (more numerically
stable and statistically sounder but possibly harder to interpret)
poly(Pressure,2) to add a quadratic term in Pressure ...

  (Sorry if this isn't relevant, I'm posting in a hurry)


From gangchen at mail.nih.gov  Wed May  9 23:31:07 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Wed, 9 May 2012 17:31:07 -0400
Subject: [R-sig-ME] How to convert the formula from LME4 to NLME?
In-Reply-To: <CAPNjSFaJpmQp-PSQ9SNAZWegdheC2zhLNTBmR_u+bQQu5B1jMw@mail.gmail.com>
References: <CAPNjSFaJpmQp-PSQ9SNAZWegdheC2zhLNTBmR_u+bQQu5B1jMw@mail.gmail.com>
Message-ID: <CAHmzXO7Hp9mmQxAUBYWZ7kxvMfJL4AUntmUtPR_eV3o5YYM_Dg@mail.gmail.com>

Here is my suggestion:

> summary(fm9 <- lmer(Reaction ~ 1 + Days + (1|Subject) + (0+Days|Subject), sleepstudy, REML = 0))Linear mixed model fit by maximum likelihood

Formula: Reaction ~ 1 + Days + (1 | Subject) + (0 + Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1762 1778   -876     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 584.250  24.1713
 Subject  Days         33.633   5.7994
 Residual             653.116  25.5561
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.708   37.48
Days          10.467      1.519    6.89

Correlation of Fixed Effects:
     (Intr)
Days -0.194

> summary(fm10 <- lme(Reaction ~ 1 + Days, random=list(Subject=pdBlocked(list(pdIdent(~1), pdSymm(~0+Days)))), sleepstudy, method='ML'))

Linear mixed-effects model fit by maximum likelihood
 Data: sleepstudy
       AIC      BIC    logLik
  1762.003 1777.968 -876.0016

Random effects:
 Composite Structure: Blocked

 Block 1: (Intercept)
 Formula: ~1 | Subject
        (Intercept)
StdDev:    24.17127

 Block 2: Days
 Formula: ~0 + Days | Subject
            Days Residual
StdDev: 5.799409 25.55613

Fixed effects: Reaction ~ 1 + Days
                Value Std.Error  DF  t-value p-value
(Intercept) 251.40510  6.745252 161 37.27142       0
Days         10.46729  1.527826 161  6.85110       0
 Correlation:
     (Intr)
Days -0.194

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-3.9535402 -0.4672676  0.0239343  0.4625157  5.1883448

Number of Observations: 180
Number of Groups: 18


On Wed, May 9, 2012 at 5:01 PM, Michael <comtech.usa at gmail.com> wrote:
> How to convert the formula from LME4 to NLME?
>
> Hi all,
>
> We have the following fomular in LME4:
>
> ?> (fm9 <- lmer(Reaction ~ 1 + Days + (1|Subject) + (0+Days|Subject),
> + sleepstudy, REML = 0))
>
> How to do the same in NLME?
>
> Thanks a lot!
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From David.Duffy at qimr.edu.au  Thu May 10 00:35:29 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 10 May 2012 08:35:29 +1000 (EST)
Subject: [R-sig-ME] pedigreemm and heritability of binary data
In-Reply-To: <4FAA658B.1050502@horus.ens.fr>
References: <6F35A958A12B9149BD16E3C2F3B0AD0DB3786A@SPHINX.adqimr.ad.lan>
	<4FAA658B.1050502@horus.ens.fr>
Message-ID: <Pine.LNX.4.64.1205100752030.25928@orpheus.qimr.edu.au>

On Wed, 9 May 2012, Pierre de Villemereuil wrote:

> Ana Vazquez (who is in charge of the development of pedigreemm I shall
> think) responded me that the package was not meant to deal with this
> kind of model.
>
> If I understood correctly, the function is not designed to fit GLMM with
> p=n (i.e. number of effects equal to the number of observations =
> generalized animal model in my case).

If you briefly reconsider, you will realise this is not very likely, given 
the entire purpose of the package.  The problem a while back was that a 
rather coarse check for nonidentified models was added to lmer(): by 
testing for p >= n.  This stopped pedigreemm from working, as well as 
blocking the perfectly valid fitting of overdispersion GLMMs with one p 
per observation.  That is to say, you _should_ be able to get a sensible 
answer.

There are several R packages that can fit an animal model GLMM: 
pedigreemm, AnimalINLA, MCMCglmm (see eg the thread starting from 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/014702.html).
There are several non-R packages you can compare numerical results to for 
the probit-normal at least.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From comtech.usa at gmail.com  Thu May 10 00:39:36 2012
From: comtech.usa at gmail.com (Michael)
Date: Wed, 9 May 2012 17:39:36 -0500
Subject: [R-sig-ME] How to convert the formula from LME4 to NLME?
In-Reply-To: <CAHmzXO7Hp9mmQxAUBYWZ7kxvMfJL4AUntmUtPR_eV3o5YYM_Dg@mail.gmail.com>
References: <CAPNjSFaJpmQp-PSQ9SNAZWegdheC2zhLNTBmR_u+bQQu5B1jMw@mail.gmail.com>
	<CAHmzXO7Hp9mmQxAUBYWZ7kxvMfJL4AUntmUtPR_eV3o5YYM_Dg@mail.gmail.com>
Message-ID: <CAPNjSFZ5aCqvyMEZ57Zj05RXcTn2EuDL44qseQO-9=ENLr44VQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120509/01840e6a/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu May 10 10:34:30 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 10 May 2012 08:34:30 +0000
Subject: [R-sig-ME] How to convert the formula from LME4 to NLME?
In-Reply-To: <CAPNjSFZ5aCqvyMEZ57Zj05RXcTn2EuDL44qseQO-9=ENLr44VQ@mail.gmail.com>
References: <CAPNjSFaJpmQp-PSQ9SNAZWegdheC2zhLNTBmR_u+bQQu5B1jMw@mail.gmail.com>
	<CAHmzXO7Hp9mmQxAUBYWZ7kxvMfJL4AUntmUtPR_eV3o5YYM_Dg@mail.gmail.com>
	<CAPNjSFZ5aCqvyMEZ57Zj05RXcTn2EuDL44qseQO-9=ENLr44VQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742757385871@inbomail.inbo.be>

Michael,

This formula is nonsens since you're fitting two random intercepts on the same grouping factor.
(fm9 <- lmer(Reaction ~ 1 + Days + (1+Days|Subject), sleepstudy, REML = FALSE)) is more sensible.

And translates to
lme(Reaction ~ 1 + Days, random = ~1+Days|Subject, sleepstudy, method = "ML")


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Michael
Verzonden: donderdag 10 mei 2012 0:40
Aan: Gang Chen
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] How to convert the formula from LME4 to NLME?

Thanks a lot!

How about this one?


 > (fm9 <- lmer(Reaction ~ 1 + Days + (1|Subject) + (1+Days|Subject),
+ sleepstudy, REML = 0))

On Wed, May 9, 2012 at 4:31 PM, Gang Chen <gangchen at mail.nih.gov> wrote:

> Here is my suggestion:
>
> > summary(fm9 <- lmer(Reaction ~ 1 + Days + (1|Subject) +
> (0+Days|Subject), sleepstudy, REML = 0))Linear mixed model fit by
> maximum likelihood
>
> Formula: Reaction ~ 1 + Days + (1 | Subject) + (0 + Days | Subject)
>   Data: sleepstudy
>  AIC  BIC logLik deviance REMLdev
>  1762 1778   -876     1752    1744
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Subject  (Intercept) 584.250  24.1713
>  Subject  Days         33.633 5.7994 <33.633%20%20%205.7994>
>  Residual             653.116  25.5561
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  251.405      6.708   37.48
> Days          10.467      1.519    6.89
>
> Correlation of Fixed Effects:
>     (Intr)
> Days -0.194
>
> > summary(fm10 <- lme(Reaction ~ 1 + Days,
> random=list(Subject=pdBlocked(list(pdIdent(~1), pdSymm(~0+Days)))),
> sleepstudy, method='ML'))
>
> Linear mixed-effects model fit by maximum likelihood
>  Data: sleepstudy
>       AIC      BIC    logLik
>  1762.003 1777.968 -876.0016
>
> Random effects:
>  Composite Structure: Blocked
>
>  Block 1: (Intercept)
>  Formula: ~1 | Subject
>        (Intercept)
> StdDev:    24.17127
>
>  Block 2: Days
>  Formula: ~0 + Days | Subject
>            Days Residual
> StdDev: 5.799409 25.55613
>
> Fixed effects: Reaction ~ 1 + Days
>                Value Std.Error  DF  t-value p-value
> (Intercept) 251.40510  6.745252 161 37.27142       0
> Days         10.46729  1.527826 161  6.85110       0
>  Correlation:
>     (Intr)
> Days -0.194
>
> Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
> -3.9535402 -0.4672676  0.0239343  0.4625157  5.1883448
>
> Number of Observations: 180
> Number of Groups: 18
>
>
> On Wed, May 9, 2012 at 5:01 PM, Michael <comtech.usa at gmail.com> wrote:
> > How to convert the formula from LME4 to NLME?
> >
> > Hi all,
> >
> > We have the following fomular in LME4:
> >
> >  > (fm9 <- lmer(Reaction ~ 1 + Days + (1|Subject) +
> > (0+Days|Subject),
> > + sleepstudy, REML = 0))
> >
> > How to do the same in NLME?
> >
> > Thanks a lot!
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From comtech.usa at gmail.com  Thu May 10 16:35:33 2012
From: comtech.usa at gmail.com (Michael)
Date: Thu, 10 May 2012 09:35:33 -0500
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do
 when facing "fail to converge"?
Message-ID: <CAPNjSFZfDvV2mTT9j0TgnAUKpza2tfTE0peHDTmY8Phbo3u7Bg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120510/343b26a2/attachment.pl>

From smartpink111 at yahoo.com  Thu May 10 17:41:20 2012
From: smartpink111 at yahoo.com (arun)
Date: Thu, 10 May 2012 08:41:20 -0700 (PDT)
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do
	when facing "fail to converge"?
In-Reply-To: <CAPNjSFZfDvV2mTT9j0TgnAUKpza2tfTE0peHDTmY8Phbo3u7Bg@mail.gmail.com>
References: <CAPNjSFZfDvV2mTT9j0TgnAUKpza2tfTE0peHDTmY8Phbo3u7Bg@mail.gmail.com>
Message-ID: <1336664480.80125.YahooMailNeo@web39401.mail.mud.yahoo.com>

HI Michael,

I also had a similar warning message but with lmer ( (Warning message:In mer_finalize(ans) : false convergence (8)).? I used verbose=TRUE in the model statement.? It will print each iteration estimates.? I also tried to increase the iterations, but it didn't work.? Then, I found this blog (http://davidhughjones.blogspot.com/2009/11/lme-false-convergence.html).? It says to look for betas with estimates very low and divide that variable by 10 or 100.? This was the only solution that worked for me.? But, the estimates of beta for the variable and its interactions will be 10 fold higher than expected. 


Your warning is bit different, so I am not sure whether it will work or not.

A.K.? 



----- Original Message -----
From: Michael <comtech.usa at gmail.com>
To: r-sig-mixed-models at r-project.org
Cc: 
Sent: Thursday, May 10, 2012 10:35 AM
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do when facing "fail to converge"?

Help! What are the typical diagnosis that one can do when facing "fail to
converge"?

Could anybody please shed some lights on us, besides increasing the number
of iteration limit?

2012-05-10 09:28:45 :? WARNING: lme fit failed with? Error in lme(MyForm,
data = tmp, weights = MyCovStruct, random = MyRndStruct): nlminb problem,
convergence error code = 1
? message = iteration limit reached without convergence (10)

Thank you so much!

??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From deter088 at umn.edu  Thu May 10 18:00:52 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 10 May 2012 11:00:52 -0500
Subject: [R-sig-ME] VC covariance structure for lme model?
Message-ID: <CAOLJphmjZBL6Q0TsVBFExJz8F6Me_a=odkNT7kYuTSwD31c8Fw@mail.gmail.com>

Greetings again R users,

Some of you will likley recognize me but I hope you can help me once
more.  I have previously attempted to replicate the UN, CS, and AR(1)
covariance structures used in SAS PROC MIXED.  However, my efforts
have fallen short on replicating the Variance Components (VC)
structure.  I have read that it is also known as a diagonal structure.
 Below I have copied over all the models I have tried and their output
with no success.  Perhaps someone here will see my error or something
I have overlooked.  I have attached the data for this particular
model.  Thanks to all, I certainly cannot thank this help list enough.
 I you need any further information/clarification, please ask.
Cheers, Charles

dat=read.table("C:/subset.csv",sep=",",header=TRUE, na.strings=".")
attach(dat)

dat34=dat[Group %in% c("3", "4"),]
attach(dat34)
liver34=within(dat34, {
	Group=factor(Group)
	Event_name=factor(Event_name)
	Died=factor(Died)
	ID=factor(ID)
})
attach(liver34)

##What is should be from SAS
#CV var
#Type 3 Tests of Fixed Effects
#Effect		 NumDF DenDF F Value Pr > F
#Group 	        	 1 	22 	0.25 	0.6244
#Died			 1 	22 	6.55 	0.0179
#Group*Died		 1 	22	4.43 	0.0470

fit.1=lme(var~Group*Died,
	random=~1|ID,
	data=dat34)
anova(fit.1, type="marginal", adjustSigma=F)
#               numDF denDF   F-value p-value
#(Intercept)    1   101 227.58700  <.0001
#Group          1    22   0.18320  0.6728
#Died           1    22   3.63388  0.0698
#Group:Died     1    22   3.04103  0.0951

fit.2=lme(var~Group*Died,
	data=dat34,
	random=~1|ID/Died)
anova(fit.2, type="marginal", adjustSigma=F)
#               numDF denDF  F-value p-value
#(Intercept)    1   101 77.99004  <.0001
#Group          1    22  1.46275  0.2393
#Died           1    22  5.84535  0.0243
#Group:Died     1    22  3.04103  0.0951

fit.3=lme(var~Group*Died,
	random=list(ID=pdSymm(~Event_name)),
	data=dat34)
anova(fit.3, type="marginal", adjustSigma=F)
#               numDF denDF   F-value p-value
#(Intercept)    1   101 273.10918  <.0001
#Group          1    22   0.69692  0.4128
#Died           1    22   1.43316  0.2440
#Group:Died     1    22   5.74399  0.0255

fit.4=lme(var~Group*Died,
	random=list(ID=pdSymm(~Group)),
	data=dat34)
anova(fit.4, type="marginal", adjustSigma=F)
#               numDF denDF   F-value p-value
#(Intercept)    1   101 235.13889  <.0001
#Group          1    22   0.15878  0.6941
#Died           1    22   3.83253  0.0631
#Group:Died     1    22   3.01222  0.0966

fit.5=lme(var~Group*Died,
	random=list(ID=pdSymm(~Group)),
	data=dat34,
	weights=varIdent(form=~1|Event_name))
anova(fit.5, type="marginal", adjustSigma=F)
#               numDF denDF   F-value p-value
#(Intercept)    1   101 277.16705  <.0001
#Group          1    22   0.23901  0.6298
#Died           1    22   3.99283  0.0582
#Group:Died     1    22   3.23135  0.0860

fit.6=lme(var~Group*Died,
	random=list(ID=pdSymm(~Group)),
	data=dat34,
	weights=varIdent(form=~1|Event_name))
anova(fit.6, type="marginal", adjustSigma=F)
#               numDF denDF   F-value p-value
#(Intercept)    1   101 277.16705  <.0001
#Group          1    22   0.23901  0.6298
#Died           1    22   3.99283  0.0582
#Group:Died     1    22   3.23135  0.0860

fit.7=lme(var~(Group*Died),
	random=list(ID=pdCompSymm(~Died)),
	data=dat34)
anova(fit.7, type="marginal", adjustSigma=F)
#               numDF denDF  F-value p-value
#(Intercept)    1   101 85.83799  <.0001
#Group          1    22  1.60624  0.2183
#Died           1    22  4.71795  0.0409
#Group:Died     1    22  2.65379  0.1175

fit.8=lme(var~(Group*Died),
	data=dat34,
	random=~1|ID,
	corr=corSymm())
anova(fit.8, type="marginal", adjustSigma=F)
#               numDF denDF   F-value p-value
#(Intercept)    1   101 119.54403  <.0001
#Group          1    22   4.58972  0.0435
#Died           1    22   8.01715  0.0097
#Group:Died     1    22   5.27470  0.0315

fit.9=lme(var~(Group*Died),
	data=dat34,
	random=list(ID=pdDiag(~Group*Died)),
	corr=corSymm(, ~1|ID))
#  Error in lme.formula(var ~ (Group * Died), data = dat34, random =
list(ID = pdDiag(~Group *  :
#  nlminb problem, convergence error code = 1
#  message = iteration limit reached without convergence (9)

fit.10=lme(var~(Group*Died),
	data=dat34,
	random=list(ID=pdDiag(~Group*Died)),
	corr=NULL)
anova(fit.10, type="marginal", adjustSigma=F)
#               numDF denDF  F-value p-value
#(Intercept)    1   101 93.90211  <.0001
#Group          1    22  1.75311  0.1991
#Died           1    22  6.84379  0.0158
#Group:Died     1    22  3.11458  0.0915

fit.11=lme(var~Group*Died,
	data=dat34,
	random=list(ID=pdDiag(~Group*Died)))
anova(fit.11, type="marginal", adjustSigma=F)
#               numDF denDF  F-value p-value
#(Intercept)    1   101 93.90211  <.0001
#Group          1    22  1.75311  0.1991
#Died           1    22  6.84379  0.0158
#Group:Died     1    22  3.11458  0.0915

fit.12=lme(var~Group*Died,
	data=dat34,
	random=list(ID=pdDiag(~Event_name)))
anova(fit.12, type="marginal", adjustSigma=F)
#               numDF denDF  F-value p-value
#(Intercept)    1   101 87.33040  <.0001
#Group          1    22  1.09661  0.3064
#Died           1    22  5.46329  0.0289
#Group:Died     1    22  2.94589  0.1001
summary(fit.12)

fit.13=lme(var~Group*Died,
	data=dat34,
	random=list(ID=pdDiag(~Group)))
anova(fit.13, type="marginal", adjustSigma=F)
#               numDF denDF  F-value p-value
#(Intercept)    1   101 77.99004  <.0001
#Group          1    22  1.46275  0.2393
#Died           1    22  5.84535  0.0243
#Group:Died     1    22  3.04103  0.0951

fit.14=lme(var~Group*Died,
	data=dat34,
	random=list(ID=pdDiag(~Died)))
anova(fit.14, type="marginal", adjustSigma=F)
#               numDF denDF  F-value p-value
#(Intercept)    1   101 85.83800  <.0001
#Group          1    22  1.60624  0.2183
#Died           1    22  4.71795  0.0409
#Group:Died     1    22  2.65379  0.1175

fit.15=lme(var~Group*Died,
	data=dat34,
	random=~1|ID,
	corr=corCompSymm())
anova(fit.15, type="marginal", adjustSigma=F)
#same as fit.13

fit.16=lme(var~Group*Died,
	data=dat34,
	random=~1|ID/Event_name)
anova(fit.16, type="marginal", adjustSigma=F)
#same as fit.13
#######################

From charliethebrown77 at gmail.com  Thu May 10 18:06:22 2012
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Thu, 10 May 2012 11:06:22 -0500
Subject: [R-sig-ME] newbie repeated measures regression questions
Message-ID: <CABnkouojuTQh+R6ryn7fhb0MvwiFYPiH7tGVvtxhqaDUJupm_w@mail.gmail.com>

Hello,
I have a repeated measures situation and would like some help to determine
if this is 1) appropriate, and 2) how to properly interpret the results.
Unfortunately, these data are very limited (but I have been asked to
analyze them anyway).  Here is an example of the data:

Basically, I have repeated measures of "Y" recorded in consecutive years
(94:98) taken at approximately the same time (July) at the same 6 sites; Y
is a percentage that I would like to regress along the continuous variable
called "env.gradient".

# Data
#######################################################################
dat <- structure(list(site = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L,
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 6L, 6L, 6L, 6L, 6L), .Label = c("C1", "C2", "C3", "Q1",
"Q2", "Q3"), class = "factor"), year = c(94L, 95L, 96L, 97L,
98L, 94L, 95L, 96L, 97L, 98L, 94L, 95L, 96L, 97L, 98L, 94L, 95L,
96L, 97L, 98L, 94L, 95L, 96L, 97L, 98L, 94L, 95L, 96L, 97L, 98L
), env.gradient = c(18, 18, 18, 18, 18, 3.5, 3.5, 3.5, 3.5, 3.5,
14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 8, 8, 8, 8, 8, 6.5, 6.5,
6.5, 6.5, 6.5), Y = c(0.171158638926407, 0.169713288641782,
0.152153933837569,
0.197575217418616, 0.203910975101867, 0.0750279002284801,
0.170743241890423,
0.124641793138257, 0.114178607721316, 0.094511173181886, 0.246397132453605,
0.204852712848377, 0.127234745915353, 0.250078422865994, 0.167826032256711,
0.179431760128959, 0.197893902312921, 0.129699846863689, 0.149706090438842,
0.138852795878536, 0.125088313507783, 0.178352158019673, 0.116281351771267,
0.147501950163454, 0.118865506981108, 0.0924414290963082,
0.144984499149044,
0.132532609540349, 0.137715018373314, 0.134704824360581)), .Names =
c("site",
"year", "env.gradient", "Y"), class = "data.frame", row.names = c(NA,
-30L))

# Analysis
#########################################################################
# I am trying to follow Venables and Ripley (2002), Chapter 10.
# I am likely compleely misguided on how to proceed, so please correct me

dat1.lm <- with(dat, lm(Y~as.factor(year)/env.gradient - 1))
summary(dat1.lm)

# if I understand this right, and looking at a graph of the data, this
seems correct, the 1st 6 rows (e.g. "as.factor(year)94  0.0485") are the
intercepts, and the rest are the slope estimates (which makes sense, I've
never run a regression like this). It looks like there is a relatively
large variation in both slopes and intercepts with these data.  I will
assume that I cannot adopt a parallel-line or even same slope model.

# What does "-1" mean in that formula?

# now to the fun stuff
library(nlme)

dat1.lme <- lme(Y ~ as.factor(year) + env.gradient , random=~1|site,
data=dat)
summary(dat1.lme)

# What does "~1" mean in that formula.... random is the 1st variable in the
formula given the site ??

# interpretation
#############################################################################
>From the looks of this summary, all null hypotheses regarding slope are
rejected at the 5% significance level except for 1994, which looking at the
graph, I can see that it likely isn't sig. different from zero.  Further,
all of the slopes are significant except for 1995 and 1996, as these are
relatively flat.  The overall model is significant, but I don't really
understand what that means regarding 95 and 96 since they were not...

Can you please tell me what I have done wrong, need to do additionally, and
how to properly interpret this.

I also have checked none of the assumptions of a linear model at this time,
are these the same as with a simple linear model (which should I be most
concerned about).


THANK YOU for any advice.
Chuck
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.png
Type: image/png
Size: 11070 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120510/c4660c91/attachment-0001.png>

From bbolker at gmail.com  Thu May 10 18:10:15 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 10 May 2012 16:10:15 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Help!_What_are_the_typical_diagnosis_that_on?=
	=?utf-8?q?e_can_do=09when_facing_=22fail_to_converge=22=3F?=
References: <CAPNjSFZfDvV2mTT9j0TgnAUKpza2tfTE0peHDTmY8Phbo3u7Bg@mail.gmail.com>
	<1336664480.80125.YahooMailNeo@web39401.mail.mud.yahoo.com>
Message-ID: <loom.20120510T180005-770@post.gmane.org>

arun <smartpink111 at ...> writes:

> I also had a similar warning message but with lmer ( (Warning
> message:In mer_finalize(ans) : false convergence (8)).? I used
> verbose=TRUE in the model statement.? It will print each iteration
> estimates.? I also tried to increase the iterations, but it didn't
> work.? Then, I found this blog
> (http://davidhughjones.blogspot.com/2009/11/lme-false-convergence.html).
> It says to look for betas with estimates very low and divide that
> variable by 10 or 100.? This was the only solution that worked for
> me.? But, the estimates of beta for the variable and its
> interactions will be 10 fold higher than expected.

  A more generic piece of advice would be to scale and center
all continuous predictor variables ... it won't always
help, but it's easy to try.

orig_data <- data.frame(V1=factor(1:5),V2=1:5,V3=(1:5)*0.001,V4=LETTERS[1:5])
scaled_data <- as.data.frame(lapply(orig_data,
                   function(x) {
                        if (class(x) %in% c("integer","numeric")) {
                              scale(x) } else x
                    }))

In doing this, the scaling and centering factors seem to get lost,
so it's not a perfect solution.
A full-fledged auto-scaling solution *might* be built into some
future version of lme4 ...


From bbolker at gmail.com  Thu May 10 18:12:43 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 10 May 2012 16:12:43 +0000 (UTC)
Subject: [R-sig-ME] How to convert the formula from LME4 to NLME?
References: <CAPNjSFaJpmQp-PSQ9SNAZWegdheC2zhLNTBmR_u+bQQu5B1jMw@mail.gmail.com>
	<CAHmzXO7Hp9mmQxAUBYWZ7kxvMfJL4AUntmUtPR_eV3o5YYM_Dg@mail.gmail.com>
	<CAPNjSFZ5aCqvyMEZ57Zj05RXcTn2EuDL44qseQO-9=ENLr44VQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA742757385871@inbomail.inbo.be>
Message-ID: <loom.20120510T181107-265@post.gmane.org>

ONKELINX, Thierry <Thierry.ONKELINX at ...> writes:

> 
> Michael,
 
> This formula is nonsens since you're fitting 
> two random intercepts on the same grouping factor.
> (fm9 <- lmer(Reaction ~ 1 + Days + (1+Days|Subject), 
> sleepstudy, REML = FALSE)) is more sensible.
> And translates to
> lme(Reaction ~ 1 + Days, 
>   random = ~1+Days|Subject, sleepstudy, method = "ML")
> 

  By the way, if anyone wants to start an "lme to lmer translation"
section or table on http://glmm.wikidot.com/faq , they're more
than welcome to do so ...

  Ben Bolker


From highstat at highstat.com  Thu May 10 18:17:22 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 10 May 2012 12:17:22 -0400
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do
 when, facing "fail to converge"?
In-Reply-To: <mailman.6090.1336666014.4540.r-sig-mixed-models@r-project.org>
References: <mailman.6090.1336666014.4540.r-sig-mixed-models@r-project.org>
Message-ID: <4FABEA12.5090906@highstat.com>



> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 10 May 2012 09:35:33 -0500
> From: Michael<comtech.usa at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Help! What are the typical diagnosis that one can
> 	do when facing "fail to converge"?
> Message-ID:
> 	<CAPNjSFZfDvV2mTT9j0TgnAUKpza2tfTE0peHDTmY8Phbo3u7Bg at mail.gmail.com>
> Content-Type: text/plain
>
> Help! What are the typical diagnosis that one can do when facing "fail to
> converge"?
>
> Could anybody please shed some lights on us, besides increasing the number
> of iteration limit?
>
> 2012-05-10 09:28:45 :  WARNING: lme fit failed with  Error in lme(MyForm,
> data = tmp, weights = MyCovStruct, random = MyRndStruct): nlminb problem,
> convergence error code = 1
>    message = iteration limit reached without convergence (10)
>
> Thank you so much!
>
> 	[[alternative HTML version deleted]]
>
>


1. Simplify your model
2. Center or standardise your covariates
3. Increase the number of iterations
4. Lower the convergence criteria
5. Provide starting values.

Most likely you will need to do 1.
2 may work....
3-5 is for if you are stubborn and don't want to do 1.


For a more specific answer you will need to provide more details.

Alain




-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From lauren.hooton at gmail.com  Thu May 10 18:53:29 2012
From: lauren.hooton at gmail.com (Lauren Hooton)
Date: Thu, 10 May 2012 12:53:29 -0400
Subject: [R-sig-ME] How to use nlmer on a dataset with multiple fixed and
	random effects
Message-ID: <CAJLSt5-Q9zOJdXPWbp+xDzbiyZ4_DOgSVc9kik+kMFyC0b5p6Q@mail.gmail.com>

>
>>
>> Hello,
>>
>> I am trying to model the effect of weather variables on bat activity
>> (passes/hour) over three years and multiple geographic locations.
>> Specifically, the effects are:
>>
>> Fixed = temperature, wind speed, wind direction, pressure,
>> precipitation, relative humidity
>> Random = year, week, detector, hour
>> (Within each year there were multiple detectors recording bat
>> activity, and these detectors (locations) changed each year).
>>
>> I started out using glmer() in lme4, with the following code:
>> LACI.model.8 <-
>> glmer(LACI~AvgTemp+AvgSpeed+AvgDirection+Pressure+
>> ? Precip+RH+(1|year)+(1|weeks_July1)+(1|detector)+(1|GMT_hour),
>> data=allbatwxstd, family=poisson)
>
> ?A quick question: can you use a quadratic function of one or
> more of your continuous predictors in your model? ?That is nonlinear
> in terms of the original predictor, but it is still a linear *model*
> (i.e. it is linear in terms of the parameters of the model). ?You can
> use either (e.g.) Pressure + I(Pressure^2), or (more numerically
> stable and statistically sounder but possibly harder to interpret)
> poly(Pressure,2) to add a quadratic term in Pressure ...
>
> ?(Sorry if this isn't relevant, I'm posting in a hurry)
>
Thanks for responding - a few others have also suggested including
quadratic terms.  However, I'm not sure that quadratic is the best fit
for the data either....the residual plots are still not great.  My
uncertainty as to what would be the best method for my data led me to
want to pursue non-linear methods.  Perhaps I should have phrased my
question as: How do you know which model is the best? Ie: a glmer with
or without quadratic terms? A non-linear model?
Is the best method to look at the fitted values vs the residuals?

Thanks,
Lauren


From comtech.usa at gmail.com  Thu May 10 18:55:22 2012
From: comtech.usa at gmail.com (Michael)
Date: Thu, 10 May 2012 11:55:22 -0500
Subject: [R-sig-ME] Help! My lme function had been running for more than 24
	hours...
Message-ID: <CAPNjSFb-m5=J-EiFzqVTrXaRLBHkqoFMK9trm0vuHDCfe1+uPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120510/98cf7f58/attachment.pl>

From charliethebrown77 at gmail.com  Thu May 10 19:05:25 2012
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Thu, 10 May 2012 12:05:25 -0500
Subject: [R-sig-ME] newbie repeated measures regression questions
In-Reply-To: <CABnkouojuTQh+R6ryn7fhb0MvwiFYPiH7tGVvtxhqaDUJupm_w@mail.gmail.com>
References: <CABnkouojuTQh+R6ryn7fhb0MvwiFYPiH7tGVvtxhqaDUJupm_w@mail.gmail.com>
Message-ID: <CABnkoup_8Jv9YnwXsGMzck9P5jPjwvWruM4MfphToMAjLZFi7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120510/86487a54/attachment.pl>

From charliethebrown77 at gmail.com  Thu May 10 19:31:34 2012
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Thu, 10 May 2012 12:31:34 -0500
Subject: [R-sig-ME] redo: newbie repeated measures regression questions
Message-ID: <CABnkourfFxdD8NEfW+QXg4aB1-G=COYj_cNMA1qGr7Sm3tJjLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120510/db568b83/attachment.pl>

From bbolker at gmail.com  Thu May 10 19:46:00 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 10 May 2012 17:46:00 +0000 (UTC)
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do
	when, facing
References: <mailman.6090.1336666014.4540.r-sig-mixed-models@r-project.org>
	<4FABEA12.5090906@highstat.com>
Message-ID: <loom.20120510T182455-54@post.gmane.org>

Highland Statistics Ltd <highstat at ...> writes:


> > Help! What are the typical diagnosis that one can do when facing "fail to
> > converge"?
> > Could anybody please shed some lights on us, besides increasing the number
> > of iteration limit?

  [snip]

> 1. Simplify your model
> 2. Center or standardise your covariates
> 3. Increase the number of iterations
> 4. Lower the convergence criteria
> 5. Provide starting values.

  Very nice.

  #6 try an alternative package/optimization platform, if one
is available (in this case, if you are using a complex model
for heteroscedasticity and want to stay within R, probably not ...)
> 
> Most likely you will need to do 1.
> 2 may work....
> 3-5 is for if you are stubborn and don't want to do 1.
> 
> For a more specific answer you will need to provide more details.


From jwiley.psych at gmail.com  Thu May 10 19:57:46 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 10 May 2012 10:57:46 -0700
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do
 when facing "fail to converge"?
In-Reply-To: <loom.20120510T180005-770@post.gmane.org>
References: <CAPNjSFZfDvV2mTT9j0TgnAUKpza2tfTE0peHDTmY8Phbo3u7Bg@mail.gmail.com>
	<1336664480.80125.YahooMailNeo@web39401.mail.mud.yahoo.com>
	<loom.20120510T180005-770@post.gmane.org>
Message-ID: <CANz9Z_JCOuu3cAFZZtpBdzrYCHU1b5OK=Od=rBYp2UDxOb-yKw@mail.gmail.com>

On Thu, May 10, 2012 at 9:10 AM, Ben Bolker <bbolker at gmail.com> wrote:
> arun <smartpink111 at ...> writes:
>
>> I also had a similar warning message but with lmer ( (Warning
>> message:In mer_finalize(ans) : false convergence (8)).? I used
>> verbose=TRUE in the model statement.? It will print each iteration
>> estimates.? I also tried to increase the iterations, but it didn't
>> work.? Then, I found this blog
>> (http://davidhughjones.blogspot.com/2009/11/lme-false-convergence.html).
>> It says to look for betas with estimates very low and divide that
>> variable by 10 or 100.? This was the only solution that worked for
>> me.? But, the estimates of beta for the variable and its
>> interactions will be 10 fold higher than expected.
>
> ?A more generic piece of advice would be to scale and center
> all continuous predictor variables ... it won't always
> help, but it's easy to try.
>
> orig_data <- data.frame(V1=factor(1:5),V2=1:5,V3=(1:5)*0.001,V4=LETTERS[1:5])
> scaled_data <- as.data.frame(lapply(orig_data,
> ? ? ? ? ? ? ? ? ? function(x) {
> ? ? ? ? ? ? ? ? ? ? ? ?if (class(x) %in% c("integer","numeric")) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?scale(x) } else x
> ? ? ? ? ? ? ? ? ? ?}))
>
> In doing this, the scaling and centering factors seem to get lost,
> so it's not a perfect solution.
> A full-fledged auto-scaling solution *might* be built into some
> future version of lme4 ...

if so FYI is.numeric tests the mode and the mode of both integer and
numeric classes is numeric so you can simplify slightly to:
if (is.numeric(x)) {
  scale(x)
} else x

>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From deter088 at umn.edu  Thu May 10 19:59:21 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 10 May 2012 12:59:21 -0500
Subject: [R-sig-ME] VC covariance structure for lme model?
In-Reply-To: <CAKFxdiTKPfYGAomatJqsPDBR0trsYVWvben8qvxJWyqjSqSysw@mail.gmail.com>
References: <CAOLJphmjZBL6Q0TsVBFExJz8F6Me_a=odkNT7kYuTSwD31c8Fw@mail.gmail.com>
	<CAKFxdiTKPfYGAomatJqsPDBR0trsYVWvben8qvxJWyqjSqSysw@mail.gmail.com>
Message-ID: <CAOLJphmQOrbWa2qKb-9si6ZsEO2L=pCEMATaMpKn85WwKg+WNQ@mail.gmail.com>

Thanks for your feedback again Kevin, I did post the data but I will
attach it again here.  I will also look into this asreml package too.

Regards,
Charles

On Thu, May 10, 2012 at 11:15 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> Some comments:
>
> 1. Posting the data would help.
> 2. As I mentioned months ago, looking at the fixed effects tests is
> generally not satisfactory. ?It's better, IMHO, to make comparisons
> using the variance structures.
> 3. You appear to be at UMN. ?If so, you might want to try asreml-r,
> which is sooooooooo much cleaner and clearer about variance
> structures. ?You can grab the beta version here:
> http://www.mmontap.org/tracker
> Download this one: asreml_3.0-1.zip
>
> You'll need to contact VSN for a free license: http://www.vsni.co.uk/software
>
> Kevin
>
>
> On Thu, May 10, 2012 at 11:00 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
>> Greetings again R users,
>>
>> Some of you will likley recognize me but I hope you can help me once
>> more. ?I have previously attempted to replicate the UN, CS, and AR(1)
>> covariance structures used in SAS PROC MIXED. ?However, my efforts
>> have fallen short on replicating the Variance Components (VC)
>> structure. ?I have read that it is also known as a diagonal structure.
>> ?Below I have copied over all the models I have tried and their output
>> with no success. ?Perhaps someone here will see my error or something
>> I have overlooked. ?I have attached the data for this particular
>> model. ?Thanks to all, I certainly cannot thank this help list enough.
>> ?I you need any further information/clarification, please ask.
>> Cheers, Charles
>>
>> dat=read.table("C:/subset.csv",sep=",",header=TRUE, na.strings=".")
>> attach(dat)
>>
>> dat34=dat[Group %in% c("3", "4"),]
>> attach(dat34)
>> liver34=within(dat34, {
>> ? ? ? ?Group=factor(Group)
>> ? ? ? ?Event_name=factor(Event_name)
>> ? ? ? ?Died=factor(Died)
>> ? ? ? ?ID=factor(ID)
>> })
>> attach(liver34)
>>
>> ##What is should be from SAS
>> #CV var
>> #Type 3 Tests of Fixed Effects
>> #Effect ? ? ? ? ?NumDF DenDF F Value Pr > F
>> #Group ? ? ? ? ? ? ? ? ? 1 ? ? ?22 ? ? ?0.25 ? ?0.6244
>> #Died ? ? ? ? ? ? ? ? ? ?1 ? ? ?22 ? ? ?6.55 ? ?0.0179
>> #Group*Died ? ? ? ? ? ? ?1 ? ? ?22 ? ? ?4.43 ? ?0.0470
>>
>> fit.1=lme(var~Group*Died,
>> ? ? ? ?random=~1|ID,
>> ? ? ? ?data=dat34)
>> anova(fit.1, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 227.58700 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.18320 ?0.6728
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.63388 ?0.0698
>> #Group:Died ? ? 1 ? ?22 ? 3.04103 ?0.0951
>>
>> fit.2=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID/Died)
>> anova(fit.2, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 77.99004 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.46275 ?0.2393
>> #Died ? ? ? ? ? 1 ? ?22 ?5.84535 ?0.0243
>> #Group:Died ? ? 1 ? ?22 ?3.04103 ?0.0951
>>
>> fit.3=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Event_name)),
>> ? ? ? ?data=dat34)
>> anova(fit.3, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 273.10918 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.69692 ?0.4128
>> #Died ? ? ? ? ? 1 ? ?22 ? 1.43316 ?0.2440
>> #Group:Died ? ? 1 ? ?22 ? 5.74399 ?0.0255
>>
>> fit.4=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Group)),
>> ? ? ? ?data=dat34)
>> anova(fit.4, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 235.13889 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.15878 ?0.6941
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.83253 ?0.0631
>> #Group:Died ? ? 1 ? ?22 ? 3.01222 ?0.0966
>>
>> fit.5=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Group)),
>> ? ? ? ?data=dat34,
>> ? ? ? ?weights=varIdent(form=~1|Event_name))
>> anova(fit.5, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 277.16705 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.23901 ?0.6298
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.99283 ?0.0582
>> #Group:Died ? ? 1 ? ?22 ? 3.23135 ?0.0860
>>
>> fit.6=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Group)),
>> ? ? ? ?data=dat34,
>> ? ? ? ?weights=varIdent(form=~1|Event_name))
>> anova(fit.6, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 277.16705 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.23901 ?0.6298
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.99283 ?0.0582
>> #Group:Died ? ? 1 ? ?22 ? 3.23135 ?0.0860
>>
>> fit.7=lme(var~(Group*Died),
>> ? ? ? ?random=list(ID=pdCompSymm(~Died)),
>> ? ? ? ?data=dat34)
>> anova(fit.7, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 85.83799 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.60624 ?0.2183
>> #Died ? ? ? ? ? 1 ? ?22 ?4.71795 ?0.0409
>> #Group:Died ? ? 1 ? ?22 ?2.65379 ?0.1175
>>
>> fit.8=lme(var~(Group*Died),
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID,
>> ? ? ? ?corr=corSymm())
>> anova(fit.8, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 119.54403 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 4.58972 ?0.0435
>> #Died ? ? ? ? ? 1 ? ?22 ? 8.01715 ?0.0097
>> #Group:Died ? ? 1 ? ?22 ? 5.27470 ?0.0315
>>
>> fit.9=lme(var~(Group*Died),
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group*Died)),
>> ? ? ? ?corr=corSymm(, ~1|ID))
>> # ?Error in lme.formula(var ~ (Group * Died), data = dat34, random =
>> list(ID = pdDiag(~Group * ?:
>> # ?nlminb problem, convergence error code = 1
>> # ?message = iteration limit reached without convergence (9)
>>
>> fit.10=lme(var~(Group*Died),
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group*Died)),
>> ? ? ? ?corr=NULL)
>> anova(fit.10, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 93.90211 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.75311 ?0.1991
>> #Died ? ? ? ? ? 1 ? ?22 ?6.84379 ?0.0158
>> #Group:Died ? ? 1 ? ?22 ?3.11458 ?0.0915
>>
>> fit.11=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group*Died)))
>> anova(fit.11, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 93.90211 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.75311 ?0.1991
>> #Died ? ? ? ? ? 1 ? ?22 ?6.84379 ?0.0158
>> #Group:Died ? ? 1 ? ?22 ?3.11458 ?0.0915
>>
>> fit.12=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Event_name)))
>> anova(fit.12, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 87.33040 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.09661 ?0.3064
>> #Died ? ? ? ? ? 1 ? ?22 ?5.46329 ?0.0289
>> #Group:Died ? ? 1 ? ?22 ?2.94589 ?0.1001
>> summary(fit.12)
>>
>> fit.13=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group)))
>> anova(fit.13, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 77.99004 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.46275 ?0.2393
>> #Died ? ? ? ? ? 1 ? ?22 ?5.84535 ?0.0243
>> #Group:Died ? ? 1 ? ?22 ?3.04103 ?0.0951
>>
>> fit.14=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Died)))
>> anova(fit.14, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 85.83800 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.60624 ?0.2183
>> #Died ? ? ? ? ? 1 ? ?22 ?4.71795 ?0.0409
>> #Group:Died ? ? 1 ? ?22 ?2.65379 ?0.1175
>>
>> fit.15=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID,
>> ? ? ? ?corr=corCompSymm())
>> anova(fit.15, type="marginal", adjustSigma=F)
>> #same as fit.13
>>
>> fit.16=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID/Event_name)
>> anova(fit.16, type="marginal", adjustSigma=F)
>> #same as fit.13
>> #######################
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Kevin Wright

From jwiley.psych at gmail.com  Thu May 10 20:05:50 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 10 May 2012 11:05:50 -0700
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do
 when, facing
In-Reply-To: <loom.20120510T182455-54@post.gmane.org>
References: <mailman.6090.1336666014.4540.r-sig-mixed-models@r-project.org>
	<4FABEA12.5090906@highstat.com>
	<loom.20120510T182455-54@post.gmane.org>
Message-ID: <CANz9Z_KsDGu-3ahH3E3WuANmUVNbkepoqAU2Xh6r5AFfYBUgAg@mail.gmail.com>

On Thu, May 10, 2012 at 10:46 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Highland Statistics Ltd <highstat at ...> writes:
>
>
>> > Help! What are the typical diagnosis that one can do when facing "fail to
>> > converge"?
>> > Could anybody please shed some lights on us, besides increasing the number
>> > of iteration limit?
>
> ?[snip]
>
>> 1. Simplify your model
>> 2. Center or standardise your covariates
>> 3. Increase the number of iterations
>> 4. Lower the convergence criteria
>> 5. Provide starting values.
>
> ?Very nice.
>
> ?#6 try an alternative package/optimization platform, if one
> is available (in this case, if you are using a complex model
> for heteroscedasticity and want to stay within R, probably not ...)

You could specify a different optimization method via the control
argument.  I think depending on the sort of complex model, OpenMx is a
viable alternative.  It does not handle random effects yet to my
knowledge (I know the developers are hard at work to incorporate
that), but if you just have repeated measures, you fit a latent growth
style model, and create pretty much any pattern of associations you
can dream up a matrix for.  If you are not used to working with
specifying matrices for SEM style models, that could be a substantial
learning curve but it puts you in a very powerful and flexible
framework for fitting many types of models.


>>
>> Most likely you will need to do 1.
>> 2 may work....
>> 3-5 is for if you are stubborn and don't want to do 1.
>>
>> For a more specific answer you will need to provide more details.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From bbolker at gmail.com  Thu May 10 20:20:50 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 10 May 2012 14:20:50 -0400
Subject: [R-sig-ME] Help! What are the typical diagnosis that one can do
 when, facing
In-Reply-To: <CANz9Z_KsDGu-3ahH3E3WuANmUVNbkepoqAU2Xh6r5AFfYBUgAg@mail.gmail.com>
References: <mailman.6090.1336666014.4540.r-sig-mixed-models@r-project.org>
	<4FABEA12.5090906@highstat.com>
	<loom.20120510T182455-54@post.gmane.org>
	<CANz9Z_KsDGu-3ahH3E3WuANmUVNbkepoqAU2Xh6r5AFfYBUgAg@mail.gmail.com>
Message-ID: <4FAC0702.40700@gmail.com>

On 12-05-10 02:05 PM, Joshua Wiley wrote:
> On Thu, May 10, 2012 at 10:46 AM, Ben Bolker <bbolker at gmail.com>
> wrote:
>> Highland Statistics Ltd <highstat at ...> writes:
>> 
>> 
>>>> Help! What are the typical diagnosis that one can do when
>>>> facing "fail to converge"? Could anybody please shed some
>>>> lights on us, besides increasing the number of iteration
>>>> limit?
>> 
>> [snip]
>> 
>>> 1. Simplify your model 2. Center or standardise your
>>> covariates 3. Increase the number of iterations 4. Lower the
>>> convergence criteria 5. Provide starting values.
>> 
>> Very nice.
>> 
>> #6 try an alternative package/optimization platform, if one is
>> available (in this case, if you are using a complex model for
>> heteroscedasticity and want to stay within R, probably not ...)
> 
> You could specify a different optimization method via the control 
> argument.

 [snip]

 Thanks, I had forgotten about this (or didn't know).  See ?lmeControl
and particularly the "opt" and "optimMethod" arguments: you can choose
"L-BFGS-B".  I don't know what happens if you (1) specify a
non-derivative-based method such as Nelder-Mead; (2) specify a method
that doesn't allow box constraints ...


From comtech.usa at gmail.com  Thu May 10 20:42:19 2012
From: comtech.usa at gmail.com (Michael)
Date: Thu, 10 May 2012 13:42:19 -0500
Subject: [R-sig-ME] Help! My lme function had been running for more than
 24 hours...
In-Reply-To: <CAKFxdiRiFGT1x9XZ1Cg7fe8tMQQhzw5VcVFc_BvQi6T5kuWkFQ@mail.gmail.com>
References: <CAPNjSFb-m5=J-EiFzqVTrXaRLBHkqoFMK9trm0vuHDCfe1+uPQ@mail.gmail.com>
	<CAKFxdiRiFGT1x9XZ1Cg7fe8tMQQhzw5VcVFc_BvQi6T5kuWkFQ@mail.gmail.com>
Message-ID: <CAPNjSFY2ys2G3a2wOX=pgKLDEOhSgLV=UhSOqcyo9XjwXXTPTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120510/9bfc80a1/attachment.pl>

From bbolker at gmail.com  Fri May 11 15:42:43 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 11 May 2012 13:42:43 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?How_to_use_nlmer_on_a_dataset_with_multiple_?=
	=?utf-8?q?fixed_and=09random_effects?=
References: <CAJLSt5-Q9zOJdXPWbp+xDzbiyZ4_DOgSVc9kik+kMFyC0b5p6Q@mail.gmail.com>
Message-ID: <loom.20120511T151409-84@post.gmane.org>

Lauren Hooton <lauren.hooton at ...> writes:

> >> I am trying to model the effect of weather variables on bat activity
> >> (passes/hour) over three years and multiple geographic locations.
> >> Specifically, the effects are:
> >>
> >> Fixed = temperature, wind speed, wind direction, pressure,
> >> precipitation, relative humidity
> >> Random = year, week, detector, hour
> >> (Within each year there were multiple detectors recording bat
> >> activity, and these detectors (locations) changed each year).
> >>
> >> I started out using glmer() in lme4, with the following code:
> >> LACI.model.8 <-
> >> glmer(LACI~AvgTemp+AvgSpeed+AvgDirection+Pressure+
> >> ? Precip+RH+(1|year)+(1|weeks_July1)+(1|detector)+(1|GMT_hour),
> >> data=allbatwxstd, family=poisson)
> >
> > ?A quick question: can you use a quadratic function of one or
> > more of your continuous predictors in your model? ?That is nonlinear
> > in terms of the original predictor, but it is still a linear *model*
> > (i.e. it is linear in terms of the parameters of the model). ?You can
> > use either (e.g.) Pressure + I(Pressure^2), or (more numerically
> > stable and statistically sounder but possibly harder to interpret)
> > poly(Pressure,2) to add a quadratic term in Pressure ...
> >
> > ?(Sorry if this isn't relevant, I'm posting in a hurry)
> >
> Thanks for responding - a few others have also suggested including
> quadratic terms.  However, I'm not sure that quadratic is the best fit
> for the data either....the residual plots are still not great.  My
> uncertainty as to what would be the best method for my data led me to
> want to pursue non-linear methods.  Perhaps I should have phrased my
> question as: How do you know which model is the best? Ie: a glmer with
> or without quadratic terms? A non-linear model?
> Is the best method to look at the fitted values vs the residuals?

   "How do you know which model is the best" is a very good question,
and one that's hard to answer in a single cut-and-dried way.

 * Looking at residuals plots is certainly a good first step.
It's handy for two reasons: (1) since it removes the signal (fitted
values) from the response, it makes it easier to see the deviations;
(2) you can *always* plot residuals vs fitted values -- you don't
need to know anything about the structure of the data set.

* However, I often like overlaying the _predicted_ values on the
original data as well.  This puts deviations of predicted vs
actual in context (you may be worrying about a deviation that is
small in absolute terms), and often makes it easier to see where
in the data set the deviation occurs (because in this case you
have to plot the predicted and observed values against the values
of the predictor variables).

* One thing to remember about GLMMs is that, due to the link
functions, the models *are* nonlinear (in a specific, restricted
sense).  If you're using a Poisson model, then the default is
a log link -- so by default you're fitting an exponential model
to the data.  If you include a quadratic term, then the model
is 'Gaussian' (in shape, i.e. exp(-x^2), not in the distribution
of the residuals).  It is true that it's hard to fit some patterns
this way, e.g. an increasing but saturating curve (although the
left half of a Gaussian looks a bit like this).  

* People do often use quadratic models to try to fit slightly
nonlinear patterns -- it makes sense as the next term in a
polynomial expansion.  If you want a quantitative test, you
can try a likelihood ratio test or calculating the AIC of
a linear vs quadratic model.

* The other way to allow for more complex shapes (technically
not 'nonlinear' but allowing for a very broad class of curves
is to use generalized additive models -- see 'gam' in the mgcv
package.


From Beatriz.DeFrancisco at sams.ac.uk  Fri May 11 17:28:47 2012
From: Beatriz.DeFrancisco at sams.ac.uk (Beatriz De Francisco)
Date: Fri, 11 May 2012 15:28:47 +0000
Subject: [R-sig-ME] Cook's distance in for lme?
Message-ID: <6B2C4C7276688144852E9630133C76BA3C514975@Verbiage1.sams.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120511/dce898ec/attachment.pl>

From habeck.cw at gmail.com  Fri May 11 17:33:04 2012
From: habeck.cw at gmail.com (Chris Habeck)
Date: Fri, 11 May 2012 11:33:04 -0400
Subject: [R-sig-ME] constraining interactions to include a specified variable
Message-ID: <CAKnLeieHQokFD80vTA2TGELna5q2enWKcPmf+rf_NS4K49eYTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120511/f7fbae11/attachment.pl>

From nospamjehol-lists at yahoo.fr  Fri May 11 09:16:30 2012
From: nospamjehol-lists at yahoo.fr (nospamjehol-lists at yahoo.fr)
Date: Fri, 11 May 2012 08:16:30 +0100 (BST)
Subject: [R-sig-ME] Variance estimate at 0 with lmer - not with lme - issue
	or rounding ?
Message-ID: <1336720590.91850.YahooMailNeo@web29305.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120511/b522396a/attachment.pl>

From alaextractor1 at gmail.com  Thu May 10 18:11:29 2012
From: alaextractor1 at gmail.com (rad mac)
Date: Thu, 10 May 2012 12:11:29 -0400
Subject: [R-sig-ME] Outcome~predictor model evaluation, repeated measurements
Message-ID: <CAGuTB=mCrqaKcbBXhDR0m9KdEAAonQSV1dQb1fRG79Hb1ZLTMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120510/001f7650/attachment.pl>

From comtech.usa at gmail.com  Fri May 11 18:13:57 2012
From: comtech.usa at gmail.com (Michael)
Date: Fri, 11 May 2012 11:13:57 -0500
Subject: [R-sig-ME] Replicating the lmer weighted LMM case manually...
Message-ID: <CAPNjSFZjufX0ZOXOtdJsrwWD9uJY3TO_iWHXni9vC-at5Eh_wg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120511/174f9feb/attachment.pl>

From comtech.usa at gmail.com  Fri May 11 18:51:48 2012
From: comtech.usa at gmail.com (Michael)
Date: Fri, 11 May 2012 11:51:48 -0500
Subject: [R-sig-ME] Replicating the lmer weighted LMM case manually...
In-Reply-To: <CAPNjSFZjufX0ZOXOtdJsrwWD9uJY3TO_iWHXni9vC-at5Eh_wg@mail.gmail.com>
References: <CAPNjSFZjufX0ZOXOtdJsrwWD9uJY3TO_iWHXni9vC-at5Eh_wg@mail.gmail.com>
Message-ID: <CAPNjSFYKgB-wK4reu5+eLs_NLY3HmtQQe6ECRvfNO4_49bMGaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120511/42998b29/attachment.pl>

From comtech.usa at gmail.com  Fri May 11 18:57:44 2012
From: comtech.usa at gmail.com (Michael)
Date: Fri, 11 May 2012 11:57:44 -0500
Subject: [R-sig-ME] Replicating the lmer weighted LMM case manually...
In-Reply-To: <CAPNjSFYKgB-wK4reu5+eLs_NLY3HmtQQe6ECRvfNO4_49bMGaA@mail.gmail.com>
References: <CAPNjSFZjufX0ZOXOtdJsrwWD9uJY3TO_iWHXni9vC-at5Eh_wg@mail.gmail.com>
	<CAPNjSFYKgB-wK4reu5+eLs_NLY3HmtQQe6ECRvfNO4_49bMGaA@mail.gmail.com>
Message-ID: <CAPNjSFakZZMrahP+tSXqYi2AhX3NH_DVWDtZB8-XKfGxZU7PqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120511/a72e3366/attachment.pl>

From bates at stat.wisc.edu  Fri May 11 21:14:31 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 11 May 2012 14:14:31 -0500
Subject: [R-sig-ME] Variance estimate at 0 with lmer - not with lme -
 issue or rounding ?
In-Reply-To: <1336720590.91850.YahooMailNeo@web29305.mail.ird.yahoo.com>
References: <1336720590.91850.YahooMailNeo@web29305.mail.ird.yahoo.com>
Message-ID: <CAO7JsnQHOuqyayvZeFKgERQas=dsvfjYdT-S7T4hpo2Yb6K2yw@mail.gmail.com>

On Fri, May 11, 2012 at 2:16 AM, nospamjehol-lists at yahoo.fr
<nospamjehol-lists at yahoo.fr> wrote:
> Hello all,
>
> I'm getting puzzled by the following:
>
> I'm fitting a simple hierarchical model with individual identity as random factor. Fitted with lmer (lme4 package) the result look like this:
>
> Formula: response ~ some fixed effects + (1 | indiv)
> Random effects:
> ?Groups?? Name??????? Variance Std.Dev.
> ?indiv???? (Intercept) 0.0000?? 0.0000
> ?Residual???????????? 1.4802?? 1.2166
> Number of obs: 116, groups: name, 69
>
> The variance estimate for individuals is a perfect 0 (which is always suspicious...and maybe an indication of problem in data distribution across effects)

No, an estimate of zero is not suspicious.  It is simply an indication
that the variability between individuals is not significantly larger
than what one would expect from the random variability in the
response.  (By the way, is that really the output from the model fit
because the name "name" in the last line should be "indiv".)

> I then fitted the model with lme (in nlme package) and got:
> Formula: lme(fixed=response ~ some fixed effects,random= ~ 1 | indiv)
> Random effects:
> ?Formula: ~1 | indiv
> ???????? (Intercept) Residual
> StdDev: 9.796623e-05 1.2166
> which I agree is a (very) small variance estimate but is less suspicious.

One of the internal differences between lme and lmer is that the
variance component estimates in lmer can go to zero gracefully whereas
in lme they can't because lme works on the scale of the logarithm of
the relative standard deviation.  It took a long time to figure out
how to solve the "going to zero gracefully" problem.

> I'm hitting this "issue" regularly with this dataset, as under some combination of fixed effect variables the variance estimate for individuals suddenly drops to a perfect 0.
>
> So to help me figure out if I should look for a problem in the distribution of data across variables, my question is:
>
> Is the difference in variance estimated by lmer and lme function such as the one observed here likely just caused by a rounding issue (and thus I should assume that with lmer the estimate is correct and simply 0), or is it sign of a real "problem" in my dataset?

Just a rounding issue.

> As ever, thanks for your help (here and in other posts that provide answers so we don't have to ask)
>
> Jehol
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From roby.joehanes at nih.gov  Fri May 11 21:48:27 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Fri, 11 May 2012 15:48:27 -0400
Subject: [R-sig-ME] Updated patch on lme4 and pedigreemm interoperability
Message-ID: <CBD2E54B.1E43%joehanesr@mail.nih.gov>

Dear all:

I updated the patch to reflect changes on SVN rev 1724 (the most current revision at the time of this writing). I packaged the newest pedigreemm patch along with the lme4 patch into one zip file called lme4-patch-svn1724.zip. New pedigreemm patch allows specification of IBD matrix into the model.

Click here for the details:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1928&group_id=60&atid=300

Sincerely,
Roby


From comtech.usa at gmail.com  Sat May 12 04:46:27 2012
From: comtech.usa at gmail.com (Michael)
Date: Fri, 11 May 2012 21:46:27 -0500
Subject: [R-sig-ME] Help! "Singular convergence problem" and "Singular
	precision matrix"!
Message-ID: <CAPNjSFYhLueA_fP3RRyduVhJ0TWeyAmnKfyQBaa+tiyMxkYz7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120511/6a8328d0/attachment.pl>

From bbolker at gmail.com  Sat May 12 06:57:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 12 May 2012 04:57:21 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Help!_=22Singular_convergence_problem=22_and?=
	=?utf-8?q?_=22Singular=09precision_matrix=22!?=
References: <CAPNjSFYhLueA_fP3RRyduVhJ0TWeyAmnKfyQBaa+tiyMxkYz7g@mail.gmail.com>
Message-ID: <loom.20120512T065623-209@post.gmane.org>

Michael <comtech.usa at ...> writes:

> Error in lme.formula(y ~ X - 1, data = tmp, weights = mycov, random =
> myrnd, : nlminb problem, convergence error code = 1
>   message = singular convergence (7)
> 
> Also, on different data sets, I've got the following:
> 
> Warning messages:
> 1: In logLik.reStruct(object, conLin) :
>   Singular precision matrix in level -1, block 3
> 
> Could you please shed some lights on this?

  You've probably got an overfitted model or wonky data, but it's
very hard to say without a reproducible example ... see e.g
http://tinyurl.com/reproducible-000


From laurent_step at yahoo.fr  Sat May 12 10:38:18 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Sat, 12 May 2012 09:38:18 +0100 (BST)
Subject: [R-sig-ME] Re : Variance estimate at 0 with lmer - not with lme -
	issue or rounding ?
In-Reply-To: <CAO7JsnQHOuqyayvZeFKgERQas=dsvfjYdT-S7T4hpo2Yb6K2yw@mail.gmail.com>
References: <1336720590.91850.YahooMailNeo@web29305.mail.ird.yahoo.com>
	<CAO7JsnQHOuqyayvZeFKgERQas=dsvfjYdT-S7T4hpo2Yb6K2yw@mail.gmail.com>
Message-ID: <1336811898.5432.YahooMailNeo@web29504.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120512/e00fc9c7/attachment.pl>

From s.chamaille at yahoo.fr  Sat May 12 09:11:16 2012
From: s.chamaille at yahoo.fr (Simon =?ISO-8859-1?Q?Chamaill=E9-Jammes?=)
Date: Sat, 12 May 2012 09:11:16 +0200
Subject: [R-sig-ME] Variance estimate at 0 with lmer - not with lme -
 issue or rounding ?
In-Reply-To: <CAO7JsnQHOuqyayvZeFKgERQas=dsvfjYdT-S7T4hpo2Yb6K2yw@mail.gmail.com>
References: <1336720590.91850.YahooMailNeo@web29305.mail.ird.yahoo.com>
	<CAO7JsnQHOuqyayvZeFKgERQas=dsvfjYdT-S7T4hpo2Yb6K2yw@mail.gmail.com>
Message-ID: <1336806676.2019.38.camel@simon-laptop>

Very much appreciated. Excellent (and quick) support as usual.

Jehol. 

<(By the way, is that really the output from the model fit
< because the name "name" in the last line should be "indiv".)
I had indeed converting the variables' names to make my message more
general. I forgot to change this one, but it's the right model output.


 

On Fri, 2012-05-11 at 14:14 -0500, Douglas Bates wrote:
> On Fri, May 11, 2012 at 2:16 AM, nospamjehol-lists at yahoo.fr
> <nospamjehol-lists at yahoo.fr> wrote:
> > Hello all,
> >
> > I'm getting puzzled by the following:
> >
> > I'm fitting a simple hierarchical model with individual identity as random factor. Fitted with lmer (lme4 package) the result look like this:
> >
> > Formula: response ~ some fixed effects + (1 | indiv)
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  indiv     (Intercept) 0.0000   0.0000
> >  Residual             1.4802   1.2166
> > Number of obs: 116, groups: name, 69
> >
> > The variance estimate for individuals is a perfect 0 (which is always suspicious...and maybe an indication of problem in data distribution across effects)
> 
> No, an estimate of zero is not suspicious.  It is simply an indication
> that the variability between individuals is not significantly larger
> than what one would expect from the random variability in the
> response.  (By the way, is that really the output from the model fit
> because the name "name" in the last line should be "indiv".)
> 
> > I then fitted the model with lme (in nlme package) and got:
> > Formula: lme(fixed=response ~ some fixed effects,random= ~ 1 | indiv)
> > Random effects:
> >  Formula: ~1 | indiv
> >          (Intercept) Residual
> > StdDev: 9.796623e-05 1.2166
> > which I agree is a (very) small variance estimate but is less suspicious.
> 
> One of the internal differences between lme and lmer is that the
> variance component estimates in lmer can go to zero gracefully whereas
> in lme they can't because lme works on the scale of the logarithm of
> the relative standard deviation.  It took a long time to figure out
> how to solve the "going to zero gracefully" problem.
> 
> > I'm hitting this "issue" regularly with this dataset, as under some combination of fixed effect variables the variance estimate for individuals suddenly drops to a perfect 0.
> >
> > So to help me figure out if I should look for a problem in the distribution of data across variables, my question is:
> >
> > Is the difference in variance estimated by lmer and lme function such as the one observed here likely just caused by a rounding issue (and thus I should assume that with lmer the estimate is correct and simply 0), or is it sign of a real "problem" in my dataset?
> 
> Just a rounding issue.
> 
> > As ever, thanks for your help (here and in other posts that provide answers so we don't have to ask)
> >
> > Jehol
> >        [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >


From r.anderson at umail.ucc.ie  Sat May 12 19:58:15 2012
From: r.anderson at umail.ucc.ie (Roslyn Anderson)
Date: Sat, 12 May 2012 18:58:15 +0100
Subject: [R-sig-ME] Plotting results of interaction from GLMM using model
	summary coefficients
Message-ID: <CAPk3JwR+ujofhXO+uMfdGyFJAe-EPy9ZxPmqUx_JVMg2BfVieQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120512/e6fdb155/attachment.pl>

From benton at stat.berkeley.edu  Mon May 14 01:40:51 2012
From: benton at stat.berkeley.edu (Kathryn Benton)
Date: Sun, 13 May 2012 19:40:51 -0400
Subject: [R-sig-ME] extracting random effect stddev from glmer
Message-ID: <7DFDC00A-C0B5-48D7-AF2C-864B99D4632B@stat.berkeley.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120513/be24f701/attachment.pl>

From jwiley.psych at gmail.com  Mon May 14 01:56:45 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 13 May 2012 16:56:45 -0700
Subject: [R-sig-ME] extracting random effect stddev from glmer
In-Reply-To: <7DFDC00A-C0B5-48D7-AF2C-864B99D4632B@stat.berkeley.edu>
References: <7DFDC00A-C0B5-48D7-AF2C-864B99D4632B@stat.berkeley.edu>
Message-ID: <CANz9Z_L7T8H0nCgMq16CuAa5mB2OWsod0QjmSfKSVwZZjYHfsA@mail.gmail.com>

Hi Kathryn,

If you do:

str(VarCorr(pf1))

you will see that it is a list because you have multiple random
effects.  attr(obj, "stddev") only works for the specific elements of
the list which have attributes.  The overall list does not (okay, it
does, but not that one).

attr(VarCorr(pf1)$vblock, "stddev")

should work.

Alternately, something like:

sqrt(unlist(VarCorr(pf1)))

may work, to unlist the list (for your case I think it may return a
vector, but maybe something more complex if the elements had more than
one number in each).  Then the square root of the variances is your
standard deviation.

Cheers,

Josh

On Sun, May 13, 2012 at 4:40 PM, Kathryn Benton
<benton at stat.berkeley.edu> wrote:
> Hi:
>
> I am attempting to extract the RE standard deviations from my glmer object. I've used the following code, but it gives cval "NULL".
>
> pf1 <- glmer(PfPrev ~ 1 + Age + I(Age^2) + SinWeek + CosWeek + ITN ?+ (1|vblock) + (1|cblock), family = binomial, data = all.prev)
>
> ChildRE <- VarCorr(pf1)[1]
> cval <- attr(ChildRE, "stddev")
>
> I also tried:
>
> ChildRE <- VarCorr(pf1)
> cval <- attr(ChildRE, "sc")
>
> Thanks for your help.
>
> Kind regards,
>
> Katie Benton
>
>
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From bbolker at gmail.com  Mon May 14 15:01:36 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 May 2012 13:01:36 +0000 (UTC)
Subject: [R-sig-ME] constraining interactions to include a specified
	variable
References: <CAKnLeieHQokFD80vTA2TGELna5q2enWKcPmf+rf_NS4K49eYTw@mail.gmail.com>
Message-ID: <loom.20120514T145947-326@post.gmane.org>

Chris Habeck <habeck.cw at ...> writes:

> I am trying to constrain interactions within a model to always include a
> particular variable of interest and to limited interaction complexity to
> three-way. The later is straight forward, for example:
> 
> lme(response ~ (a + b + c + d + e + f)^3)
> 
> However, my goal is to constrain all 3-way interactions to always include
> variable "a". Is there efficient code for this problem?

   Would something like response ~ a*(b+c+d+e+f)^2  work for you?

  Ben Bolker


From deter088 at umn.edu  Mon May 14 15:36:26 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 14 May 2012 08:36:26 -0500
Subject: [R-sig-ME] Fwd:  VC covariance structure for lme model?
In-Reply-To: <CAOLJphmQOrbWa2qKb-9si6ZsEO2L=pCEMATaMpKn85WwKg+WNQ@mail.gmail.com>
References: <CAOLJphmjZBL6Q0TsVBFExJz8F6Me_a=odkNT7kYuTSwD31c8Fw@mail.gmail.com>
	<CAKFxdiTKPfYGAomatJqsPDBR0trsYVWvben8qvxJWyqjSqSysw@mail.gmail.com>
	<CAOLJphmQOrbWa2qKb-9si6ZsEO2L=pCEMATaMpKn85WwKg+WNQ@mail.gmail.com>
Message-ID: <CAOLJphm6yF1XxbTwBJZc6Pv8wNgh6wBs9DA5DULVqOnq=Qe4zw@mail.gmail.com>

On the off chance, I wanted to push this question once more that
someone is familiar with it.  I am currently trying to contact asreml
but I would like to try and accomplish VC covariance structure with
lme if possible. Below are all my attempts.  Thanks for any
assistance,

>> dat=read.table("C:/subset.csv",sep=",",header=TRUE, na.strings=".")
>> attach(dat)
>>
>> dat34=dat[Group %in% c("3", "4"),]
>> attach(dat34)
>> liver34=within(dat34, {
>>        Group=factor(Group)
>>        Event_name=factor(Event_name)
>>        Died=factor(Died)
>>        ID=factor(ID)
>> })
>> attach(liver34)
>>
>> ##What is should be from SAS
>> #CV var
>> #Type 3 Tests of Fixed Effects
>> #Effect          NumDF DenDF F Value Pr > F
>> #Group                   1      22      0.25    0.6244
>> #Died                    1      22      6.55    0.0179
>> #Group*Died              1      22      4.43    0.0470
>>
>> fit.1=lme(var~Group*Died,
>>        random=~1|ID,
>>        data=dat34)
>> anova(fit.1, type="marginal", adjustSigma=F)
>> #               numDF denDF   F-value p-value
>> #(Intercept)    1   101 227.58700  <.0001
>> #Group          1    22   0.18320  0.6728
>> #Died           1    22   3.63388  0.0698
>> #Group:Died     1    22   3.04103  0.0951
>>
>> fit.2=lme(var~Group*Died,
>>        data=dat34,
>>        random=~1|ID/Died)
>> anova(fit.2, type="marginal", adjustSigma=F)
>> #               numDF denDF  F-value p-value
>> #(Intercept)    1   101 77.99004  <.0001
>> #Group          1    22  1.46275  0.2393
>> #Died           1    22  5.84535  0.0243
>> #Group:Died     1    22  3.04103  0.0951
>>
>> fit.3=lme(var~Group*Died,
>>        random=list(ID=pdSymm(~Event_name)),
>>        data=dat34)
>> anova(fit.3, type="marginal", adjustSigma=F)
>> #               numDF denDF   F-value p-value
>> #(Intercept)    1   101 273.10918  <.0001
>> #Group          1    22   0.69692  0.4128
>> #Died           1    22   1.43316  0.2440
>> #Group:Died     1    22   5.74399  0.0255
>>
>> fit.4=lme(var~Group*Died,
>>        random=list(ID=pdSymm(~Group)),
>>        data=dat34)
>> anova(fit.4, type="marginal", adjustSigma=F)
>> #               numDF denDF   F-value p-value
>> #(Intercept)    1   101 235.13889  <.0001
>> #Group          1    22   0.15878  0.6941
>> #Died           1    22   3.83253  0.0631
>> #Group:Died     1    22   3.01222  0.0966
>>
>> fit.5=lme(var~Group*Died,
>>        random=list(ID=pdSymm(~Group)),
>>        data=dat34,
>>        weights=varIdent(form=~1|Event_name))
>> anova(fit.5, type="marginal", adjustSigma=F)
>> #               numDF denDF   F-value p-value
>> #(Intercept)    1   101 277.16705  <.0001
>> #Group          1    22   0.23901  0.6298
>> #Died           1    22   3.99283  0.0582
>> #Group:Died     1    22   3.23135  0.0860
>>
>> fit.6=lme(var~Group*Died,
>>        random=list(ID=pdSymm(~Group)),
>>        data=dat34,
>>        weights=varIdent(form=~1|Event_name))
>> anova(fit.6, type="marginal", adjustSigma=F)
>> #               numDF denDF   F-value p-value
>> #(Intercept)    1   101 277.16705  <.0001
>> #Group          1    22   0.23901  0.6298
>> #Died           1    22   3.99283  0.0582
>> #Group:Died     1    22   3.23135  0.0860
>>
>> fit.7=lme(var~(Group*Died),
>>        random=list(ID=pdCompSymm(~Died)),
>>        data=dat34)
>> anova(fit.7, type="marginal", adjustSigma=F)
>> #               numDF denDF  F-value p-value
>> #(Intercept)    1   101 85.83799  <.0001
>> #Group          1    22  1.60624  0.2183
>> #Died           1    22  4.71795  0.0409
>> #Group:Died     1    22  2.65379  0.1175
>>
>> fit.8=lme(var~(Group*Died),
>>        data=dat34,
>>        random=~1|ID,
>>        corr=corSymm())
>> anova(fit.8, type="marginal", adjustSigma=F)
>> #               numDF denDF   F-value p-value
>> #(Intercept)    1   101 119.54403  <.0001
>> #Group          1    22   4.58972  0.0435
>> #Died           1    22   8.01715  0.0097
>> #Group:Died     1    22   5.27470  0.0315
>>
>> fit.9=lme(var~(Group*Died),
>>        data=dat34,
>>        random=list(ID=pdDiag(~Group*Died)),
>>        corr=corSymm(, ~1|ID))
>> #  Error in lme.formula(var ~ (Group * Died), data = dat34, random =
>> list(ID = pdDiag(~Group *  :
>> #  nlminb problem, convergence error code = 1
>> #  message = iteration limit reached without convergence (9)
>>
>> fit.10=lme(var~(Group*Died),
>>        data=dat34,
>>        random=list(ID=pdDiag(~Group*Died)),
>>        corr=NULL)
>> anova(fit.10, type="marginal", adjustSigma=F)
>> #               numDF denDF  F-value p-value
>> #(Intercept)    1   101 93.90211  <.0001
>> #Group          1    22  1.75311  0.1991
>> #Died           1    22  6.84379  0.0158
>> #Group:Died     1    22  3.11458  0.0915
>>
>> fit.11=lme(var~Group*Died,
>>        data=dat34,
>>        random=list(ID=pdDiag(~Group*Died)))
>> anova(fit.11, type="marginal", adjustSigma=F)
>> #               numDF denDF  F-value p-value
>> #(Intercept)    1   101 93.90211  <.0001
>> #Group          1    22  1.75311  0.1991
>> #Died           1    22  6.84379  0.0158
>> #Group:Died     1    22  3.11458  0.0915
>>
>> fit.12=lme(var~Group*Died,
>>        data=dat34,
>>        random=list(ID=pdDiag(~Event_name)))
>> anova(fit.12, type="marginal", adjustSigma=F)
>> #               numDF denDF  F-value p-value
>> #(Intercept)    1   101 87.33040  <.0001
>> #Group          1    22  1.09661  0.3064
>> #Died           1    22  5.46329  0.0289
>> #Group:Died     1    22  2.94589  0.1001
>> summary(fit.12)
>>
>> fit.13=lme(var~Group*Died,
>>        data=dat34,
>>        random=list(ID=pdDiag(~Group)))
>> anova(fit.13, type="marginal", adjustSigma=F)
>> #               numDF denDF  F-value p-value
>> #(Intercept)    1   101 77.99004  <.0001
>> #Group          1    22  1.46275  0.2393
>> #Died           1    22  5.84535  0.0243
>> #Group:Died     1    22  3.04103  0.0951
>>
>> fit.14=lme(var~Group*Died,
>>        data=dat34,
>>        random=list(ID=pdDiag(~Died)))
>> anova(fit.14, type="marginal", adjustSigma=F)
>> #               numDF denDF  F-value p-value
>> #(Intercept)    1   101 85.83800  <.0001
>> #Group          1    22  1.60624  0.2183
>> #Died           1    22  4.71795  0.0409
>> #Group:Died     1    22  2.65379  0.1175
>>
>> fit.15=lme(var~Group*Died,
>>        data=dat34,
>>        random=~1|ID,
>>        corr=corCompSymm())
>> anova(fit.15, type="marginal", adjustSigma=F)
>> #same as fit.13
>>
>> fit.16=lme(var~Group*Died,
>>        data=dat34,
>>        random=~1|ID/Event_name)
>> anova(fit.16, type="marginal", adjustSigma=F)
>> #same as fit.13
>> #######################
---------- Forwarded message ----------
From: Charles Determan Jr <deter088 at umn.edu>
Date: Thu, May 10, 2012 at 12:59 PM
Subject: Re: [R-sig-ME] VC covariance structure for lme model?
To: Kevin Wright <kw.stat at gmail.com>
Cc: r-sig-mixed-models at r-project.org


Thanks for your feedback again Kevin, I did post the data but I will
attach it again here. ?I will also look into this asreml package too.

Regards,
Charles

On Thu, May 10, 2012 at 11:15 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> Some comments:
>
> 1. Posting the data would help.
> 2. As I mentioned months ago, looking at the fixed effects tests is
> generally not satisfactory. ?It's better, IMHO, to make comparisons
> using the variance structures.
> 3. You appear to be at UMN. ?If so, you might want to try asreml-r,
> which is sooooooooo much cleaner and clearer about variance
> structures. ?You can grab the beta version here:
> http://www.mmontap.org/tracker
> Download this one: asreml_3.0-1.zip
>
> You'll need to contact VSN for a free license: http://www.vsni.co.uk/software
>
> Kevin
>
>
> On Thu, May 10, 2012 at 11:00 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
>> Greetings again R users,
>>
>> Some of you will likley recognize me but I hope you can help me once
>> more. ?I have previously attempted to replicate the UN, CS, and AR(1)
>> covariance structures used in SAS PROC MIXED. ?However, my efforts
>> have fallen short on replicating the Variance Components (VC)
>> structure. ?I have read that it is also known as a diagonal structure.
>> ?Below I have copied over all the models I have tried and their output
>> with no success. ?Perhaps someone here will see my error or something
>> I have overlooked. ?I have attached the data for this particular
>> model. ?Thanks to all, I certainly cannot thank this help list enough.
>> ?I you need any further information/clarification, please ask.
>> Cheers, Charles
>>
>> dat=read.table("C:/subset.csv",sep=",",header=TRUE, na.strings=".")
>> attach(dat)
>>
>> dat34=dat[Group %in% c("3", "4"),]
>> attach(dat34)
>> liver34=within(dat34, {
>> ? ? ? ?Group=factor(Group)
>> ? ? ? ?Event_name=factor(Event_name)
>> ? ? ? ?Died=factor(Died)
>> ? ? ? ?ID=factor(ID)
>> })
>> attach(liver34)
>>
>> ##What is should be from SAS
>> #CV var
>> #Type 3 Tests of Fixed Effects
>> #Effect ? ? ? ? ?NumDF DenDF F Value Pr > F
>> #Group ? ? ? ? ? ? ? ? ? 1 ? ? ?22 ? ? ?0.25 ? ?0.6244
>> #Died ? ? ? ? ? ? ? ? ? ?1 ? ? ?22 ? ? ?6.55 ? ?0.0179
>> #Group*Died ? ? ? ? ? ? ?1 ? ? ?22 ? ? ?4.43 ? ?0.0470
>>
>> fit.1=lme(var~Group*Died,
>> ? ? ? ?random=~1|ID,
>> ? ? ? ?data=dat34)
>> anova(fit.1, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 227.58700 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.18320 ?0.6728
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.63388 ?0.0698
>> #Group:Died ? ? 1 ? ?22 ? 3.04103 ?0.0951
>>
>> fit.2=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID/Died)
>> anova(fit.2, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 77.99004 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.46275 ?0.2393
>> #Died ? ? ? ? ? 1 ? ?22 ?5.84535 ?0.0243
>> #Group:Died ? ? 1 ? ?22 ?3.04103 ?0.0951
>>
>> fit.3=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Event_name)),
>> ? ? ? ?data=dat34)
>> anova(fit.3, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 273.10918 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.69692 ?0.4128
>> #Died ? ? ? ? ? 1 ? ?22 ? 1.43316 ?0.2440
>> #Group:Died ? ? 1 ? ?22 ? 5.74399 ?0.0255
>>
>> fit.4=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Group)),
>> ? ? ? ?data=dat34)
>> anova(fit.4, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 235.13889 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.15878 ?0.6941
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.83253 ?0.0631
>> #Group:Died ? ? 1 ? ?22 ? 3.01222 ?0.0966
>>
>> fit.5=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Group)),
>> ? ? ? ?data=dat34,
>> ? ? ? ?weights=varIdent(form=~1|Event_name))
>> anova(fit.5, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 277.16705 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.23901 ?0.6298
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.99283 ?0.0582
>> #Group:Died ? ? 1 ? ?22 ? 3.23135 ?0.0860
>>
>> fit.6=lme(var~Group*Died,
>> ? ? ? ?random=list(ID=pdSymm(~Group)),
>> ? ? ? ?data=dat34,
>> ? ? ? ?weights=varIdent(form=~1|Event_name))
>> anova(fit.6, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 277.16705 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 0.23901 ?0.6298
>> #Died ? ? ? ? ? 1 ? ?22 ? 3.99283 ?0.0582
>> #Group:Died ? ? 1 ? ?22 ? 3.23135 ?0.0860
>>
>> fit.7=lme(var~(Group*Died),
>> ? ? ? ?random=list(ID=pdCompSymm(~Died)),
>> ? ? ? ?data=dat34)
>> anova(fit.7, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 85.83799 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.60624 ?0.2183
>> #Died ? ? ? ? ? 1 ? ?22 ?4.71795 ?0.0409
>> #Group:Died ? ? 1 ? ?22 ?2.65379 ?0.1175
>>
>> fit.8=lme(var~(Group*Died),
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID,
>> ? ? ? ?corr=corSymm())
>> anova(fit.8, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ? F-value p-value
>> #(Intercept) ? ?1 ? 101 119.54403 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ? 4.58972 ?0.0435
>> #Died ? ? ? ? ? 1 ? ?22 ? 8.01715 ?0.0097
>> #Group:Died ? ? 1 ? ?22 ? 5.27470 ?0.0315
>>
>> fit.9=lme(var~(Group*Died),
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group*Died)),
>> ? ? ? ?corr=corSymm(, ~1|ID))
>> # ?Error in lme.formula(var ~ (Group * Died), data = dat34, random =
>> list(ID = pdDiag(~Group * ?:
>> # ?nlminb problem, convergence error code = 1
>> # ?message = iteration limit reached without convergence (9)
>>
>> fit.10=lme(var~(Group*Died),
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group*Died)),
>> ? ? ? ?corr=NULL)
>> anova(fit.10, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 93.90211 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.75311 ?0.1991
>> #Died ? ? ? ? ? 1 ? ?22 ?6.84379 ?0.0158
>> #Group:Died ? ? 1 ? ?22 ?3.11458 ?0.0915
>>
>> fit.11=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group*Died)))
>> anova(fit.11, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 93.90211 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.75311 ?0.1991
>> #Died ? ? ? ? ? 1 ? ?22 ?6.84379 ?0.0158
>> #Group:Died ? ? 1 ? ?22 ?3.11458 ?0.0915
>>
>> fit.12=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Event_name)))
>> anova(fit.12, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 87.33040 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.09661 ?0.3064
>> #Died ? ? ? ? ? 1 ? ?22 ?5.46329 ?0.0289
>> #Group:Died ? ? 1 ? ?22 ?2.94589 ?0.1001
>> summary(fit.12)
>>
>> fit.13=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Group)))
>> anova(fit.13, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 77.99004 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.46275 ?0.2393
>> #Died ? ? ? ? ? 1 ? ?22 ?5.84535 ?0.0243
>> #Group:Died ? ? 1 ? ?22 ?3.04103 ?0.0951
>>
>> fit.14=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=list(ID=pdDiag(~Died)))
>> anova(fit.14, type="marginal", adjustSigma=F)
>> # ? ? ? ? ? ? ? numDF denDF ?F-value p-value
>> #(Intercept) ? ?1 ? 101 85.83800 ?<.0001
>> #Group ? ? ? ? ?1 ? ?22 ?1.60624 ?0.2183
>> #Died ? ? ? ? ? 1 ? ?22 ?4.71795 ?0.0409
>> #Group:Died ? ? 1 ? ?22 ?2.65379 ?0.1175
>>
>> fit.15=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID,
>> ? ? ? ?corr=corCompSymm())
>> anova(fit.15, type="marginal", adjustSigma=F)
>> #same as fit.13
>>
>> fit.16=lme(var~Group*Died,
>> ? ? ? ?data=dat34,
>> ? ? ? ?random=~1|ID/Event_name)
>> anova(fit.16, type="marginal", adjustSigma=F)
>> #same as fit.13
>> #######################
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Kevin Wright

From petri.lankoski at gmail.com  Mon May 14 16:29:50 2012
From: petri.lankoski at gmail.com (Petri Lankoski)
Date: Mon, 14 May 2012 16:29:50 +0200
Subject: [R-sig-ME] Interpreting clmm results with ordinal effect
Message-ID: <4FB116DE.30204@gmail.com>


Dear list members,

I have questionnaire data (5 point likert-scale) as well as some 
categorical variable (the ordinal data is not normally distributed). I 
have started to analyze the data with ordinal package and its clmm 
function.  With the categorical data the outputs are understandable, but 
I have not able to understand the output with ordinal data (tutorials 
and books I have referenced have not been helpful). How I should 
interpret L, Q, C and ^4 in output?

Cumulative Link Mixed Model fitted with the Laplace approximation

formula: q4 ~ q7 + sex + (1 | game)
data:    df

  link  threshold nobs logLik  AIC     niter   max.grad cond.H
  logit symmetric 562  -558.69 1135.37 20(857) 7.52e-06 2.8e+01

Random effects:
         Var Std.Dev
game 0.1026  0.3204
Number of groups:  game 11

Coefficients:
       Estimate Std. Error z value Pr(>|z|)
q7.L    4.3726     0.3815  11.461   <2e-16 ***
q7.Q    0.3842     0.3014   1.275   0.2024
q7.C    0.2504     0.2504   1.000   0.3173
q7^4    0.2771     0.2117   1.309   0.1905
sex.L   0.2659     0.1297   2.050   0.0404 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
           Estimate Std. Error z value
central.1  -2.5827     0.2212 -11.676
central.2  -0.3151     0.1818  -1.733
spacing.1   2.5340     0.1506  16.828


Any help or pointers appreciated!

-- 
Petri Lankoski, petri.lankoski at iki.fi
www.iki.fi/petri.lankoski


From lunamoonmoon at gmail.com  Mon May 14 17:00:20 2012
From: lunamoonmoon at gmail.com (Luna)
Date: Mon, 14 May 2012 10:00:20 -0500
Subject: [R-sig-ME] Which package handles both auto-correlation and
	heteroskedacity?
Message-ID: <CAPNjSFbxxYYnJcPgE4bgFEXzKhbhvRSQZe0SMM5o6Uf+E8LtOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120514/7077839d/attachment.pl>

From highstat at highstat.com  Mon May 14 17:26:23 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 14 May 2012 11:26:23 -0400
Subject: [R-sig-ME] Which package handles both auto-correlation and,
	heteroskedacity?
In-Reply-To: <mailman.6675.1337007645.4540.r-sig-mixed-models@r-project.org>
References: <mailman.6675.1337007645.4540.r-sig-mixed-models@r-project.org>
Message-ID: <4FB1241F.3040207@highstat.com>








------------------------------

Message: 4
Date: Mon, 14 May 2012 10:00:20 -0500
From: Luna<lunamoonmoon at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Which package handles both auto-correlation and
	heteroskedacity?
Message-ID:
	<CAPNjSFbxxYYnJcPgE4bgFEXzKhbhvRSQZe0SMM5o6Uf+E8LtOQ at mail.gmail.com>
Content-Type: text/plain

Which package handles both auto-correlation and heteroskedacity?

Hi all,


Using the terminology on this webpage:

http://www.nyu.edu/its/pubs/connect/fall03/yaffee_primer.html

We are in need of doing the "Dynamic Panel Models".

We would like to incorporate "auto-correlation" along the time axis and the
"heteroskedacity" cross-sectionally.

> From literature reading, the "time series" concept is sometimes called
"longitudinal".

Could you please recommend a package for that (nlme or lme4 or others)?

And could you please point us to a concrete example on this?

Thanks a lot!







You already answered your own question....nlme. Chapter 5 of Pinheiro and Bates contains plenty of examples.
So does our 2009 volume (Zuur et al 2009). Or a recent paper in MEE:

Neglected biological patterns in the residuals. A behavioural ecologist?s guide to co-operating with heteroscedasticity
Ian R. Cleasby&  Shinichi Nakagawa

Alain








------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 65, Issue 35


From shirkpl at mymail.vcu.edu  Mon May 14 17:34:14 2012
From: shirkpl at mymail.vcu.edu (Philip Shirk)
Date: Mon, 14 May 2012 11:34:14 -0400
Subject: [R-sig-ME] GLMM random-effect conceptualization
Message-ID: <CANG=JfGBs0ytAPJ92b4X871izB5A1KbDziO50HFRRuD0OMmcQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120514/253b3f3c/attachment.pl>

From rhbc at imm.dtu.dk  Tue May 15 09:20:56 2012
From: rhbc at imm.dtu.dk (Rune Haubo)
Date: Tue, 15 May 2012 09:20:56 +0200
Subject: [R-sig-ME] Interpreting clmm results with ordinal effect
In-Reply-To: <4FB116DE.30204@gmail.com>
References: <4FB116DE.30204@gmail.com>
Message-ID: <CAG_uk90SNS71=StwnTTY3D-CdfVpkut+AujosH5uh3U_N-O4GA@mail.gmail.com>

Petri,

I think you are confused about the use of orthogonal polynomials for
ordered factors in model formulas rather than cumulative link models.
If you first remove the ordering from the factors, I think you will
find the output from clmm more familiar:

df$q7_f <- factor(df$q7, ordered=FALSE)
df$sex_f <- factor(df$sex, ordered=FALSE)

It is correct, though, that the response variable, q4 should be an
ordered factor or at least a factor from which the ordering can be
inferred.

As an example consider the wine data from the ordinal package. We can
fit two models where bottle is interpreted as a factor and an ordered
factor respectively:

> library(ordinal)
Loading required package: MASS
Loading required package: ucminf
Loading required package: Matrix
Loading required package: lattice
> data(wine)
> fm1 <- clmm(rating ~ bottle + (1|judge), data=wine)
> summary(fm1)
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: rating ~ bottle + (1 | judge)
data:    wine

 link  threshold nobs logLik AIC    niter    max.grad cond.H
 logit flexible  72   -80.26 184.52 21(1578) 5.23e-06 1.0e+02

Random effects:
        Var Std.Dev
judge 1.321   1.149
Number of groups:  judge 9

Coefficients:
        Estimate Std. Error z value Pr(>|z|)
bottle2   1.1992     0.9653   1.242 0.214112
bottle3   2.6116     1.0441   2.501 0.012373 *
bottle4   2.2340     1.0175   2.196 0.028126 *
bottle5   3.3366     1.0621   3.141 0.001682 **
bottle6   4.0071     1.0960   3.656 0.000256 ***
bottle7   5.9393     1.2202   4.868 1.13e-06 ***
bottle8   5.4546     1.1552   4.722 2.34e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.0696     0.8472  -1.263
2|3   2.1406     0.8946   2.393
3|4   4.9217     1.0581   4.651
4|5   6.8276     1.1853   5.760
> wine <- transform(wine, bottle2 = factor(bottle, ordered=TRUE))
> fm2 <- clmm(rating ~ bottle2 + (1|judge), data=wine)
> summary(fm2)
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: rating ~ bottle2 + (1 | judge)
data:    wine

 link  threshold nobs logLik AIC    niter    max.grad cond.H
 logit flexible  72   -80.26 184.52 19(1428) 6.90e-06 1.6e+01

Random effects:
        Var Std.Dev
judge 1.321   1.149
Number of groups:  judge 9

Coefficients:
          Estimate Std. Error z value Pr(>|z|)
bottle2.L  5.18240    0.91856   5.642 1.68e-08 ***
bottle2.Q -0.18429    0.67894  -0.271    0.786
bottle2.C  0.08646    0.66414   0.130    0.896
bottle2^4 -0.98063    0.67058  -1.462    0.144
bottle2^5 -0.65429    0.66913  -0.978    0.328
bottle2^6  0.09092    0.66348   0.137    0.891
bottle2^7 -0.63177    0.65730  -0.961    0.336
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -4.1674     0.7787  -5.352
2|3  -0.9572     0.5110  -1.873
3|4   1.8239     0.5595   3.260
4|5   3.7298     0.7056   5.286

The L Q and C terms for bottle2 in fm2 denote linear, quadratic and
cubic components. In fm1 bottle has the standard treatment contrasts.
Observe that the likelihoods are identical, hence the models are
merely reparameterizations of each other.

Hope this helps,
Rune


On 14 May 2012 16:29, Petri Lankoski <petri.lankoski at gmail.com> wrote:
>
> Dear list members,
>
> I have questionnaire data (5 point likert-scale) as well as some categorical
> variable (the ordinal data is not normally distributed). I have started to
> analyze the data with ordinal package and its clmm function. ?With the
> categorical data the outputs are understandable, but I have not able to
> understand the output with ordinal data (tutorials and books I have
> referenced have not been helpful). How I should interpret L, Q, C and ^4 in
> output?
>
> Cumulative Link Mixed Model fitted with the Laplace approximation
>
> formula: q4 ~ q7 + sex + (1 | game)
> data: ? ?df
>
> ?link ?threshold nobs logLik ?AIC ? ? niter ? max.grad cond.H
> ?logit symmetric 562 ?-558.69 1135.37 20(857) 7.52e-06 2.8e+01
>
> Random effects:
> ? ? ? ?Var Std.Dev
> game 0.1026 ?0.3204
> Number of groups: ?game 11
>
> Coefficients:
> ? ? ?Estimate Std. Error z value Pr(>|z|)
> q7.L ? ?4.3726 ? ? 0.3815 ?11.461 ? <2e-16 ***
> q7.Q ? ?0.3842 ? ? 0.3014 ? 1.275 ? 0.2024
> q7.C ? ?0.2504 ? ? 0.2504 ? 1.000 ? 0.3173
> q7^4 ? ?0.2771 ? ? 0.2117 ? 1.309 ? 0.1905
> sex.L ? 0.2659 ? ? 0.1297 ? 2.050 ? 0.0404 *
> ---
> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Threshold coefficients:
> ? ? ? ? ?Estimate Std. Error z value
> central.1 ?-2.5827 ? ? 0.2212 -11.676
> central.2 ?-0.3151 ? ? 0.1818 ?-1.733
> spacing.1 ? 2.5340 ? ? 0.1506 ?16.828
>
>
> Any help or pointers appreciated!
>
> --
> Petri Lankoski, petri.lankoski at iki.fi
> www.iki.fi/petri.lankoski
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Rune Haubo Bojesen Christensen

Ph.D. Student, M.Sc. Eng.
Phone: (+45) 45 25 33 63
Mobile: (+45) 30 26 45 54

DTU Informatics, Section for Statistics
Technical University of Denmark, Build. 305, Room 122,
DK-2800 Kgs. Lyngby, Denmark


From gangchen at mail.nih.gov  Tue May 15 12:27:52 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 15 May 2012 06:27:52 -0400
Subject: [R-sig-ME] Specifying correlation structure
Message-ID: <CAHmzXO7ArCyA45PgqnD_dcx=SEvQXpfuwySWN6zkZPd8eCunfA@mail.gmail.com>

I have some time series data (with 100 time points) collected from one
subject. At each time point three measures were taken under three
conditions, and there is an explanatory variable for each condition.

Below is just some fake data to demonstrate the data structure:

# 100 time points per condition
tp <- 100                             # time points
trials <- seq(1, tp, 1)          # time counter
condition <- c('a', 'b', 'c')   # three conditions

# fake data
set.seed(5)
Dat <- data.frame(time=rep(trials, 3), cond=rep(condition, each=tp),
res=rnorm(3*tp))

reg1 <- c(rnorm(tp), rep(0, 2*tp))            # explanatory variable
for condition 1
reg2 <- c(rep(0, tp), rnorm(tp), rep(0, tp))   # explanatory variable
for condition 2
reg3 <- c(rep(0, 2*tp), rnorm(tp))             # explanatory variable
for condition 3

First I thought that I'd start with gls in nlme package with an ARMA
model for the correlation structure:

(fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
form=~time, p=1,q=1), data=Dat))

The above model does not work because of the following error:

Error in Initialize.corARMA(X[[1L]], ...) :
  Covariate must have unique values within groups for corARMA objects

Moreover, I would like to account for the fact that the ARMA structure
should be similar or the same across the three conditions. My
questions are:

1) how to impose a same ARMA structure across the three conditions?
2) alternatively I'd like to have something like:

(fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
form=~time:condition, p=1,q=1), data=Dat))

but this would not work either, and seems to crash R!

3) maybe construct a multivariate gls model, but how to do that? what package?

Thanks,
Gang


From gavin.simpson at ucl.ac.uk  Tue May 15 14:11:06 2012
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 15 May 2012 13:11:06 +0100
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <CAHmzXO7ArCyA45PgqnD_dcx=SEvQXpfuwySWN6zkZPd8eCunfA@mail.gmail.com>
References: <CAHmzXO7ArCyA45PgqnD_dcx=SEvQXpfuwySWN6zkZPd8eCunfA@mail.gmail.com>
Message-ID: <1337083866.7883.6.camel@prometheus.geog.ucl.ac.uk>

On Tue, 2012-05-15 at 06:27 -0400, Gang Chen wrote:
> I have some time series data (with 100 time points) collected from one
> subject. At each time point three measures were taken under three
> conditions, and there is an explanatory variable for each condition.

The temporal correlation is, in this sense, *nested* within the three
different conditions. You were close with time:condition, but what I
think you need is

corARMA(c(0.02, 0.03), form = ~ time | condition)

HTH

G

> Below is just some fake data to demonstrate the data structure:
> 
> # 100 time points per condition
> tp <- 100                             # time points
> trials <- seq(1, tp, 1)          # time counter
> condition <- c('a', 'b', 'c')   # three conditions
> 
> # fake data
> set.seed(5)
> Dat <- data.frame(time=rep(trials, 3), cond=rep(condition, each=tp),
> res=rnorm(3*tp))
> 
> reg1 <- c(rnorm(tp), rep(0, 2*tp))            # explanatory variable
> for condition 1
> reg2 <- c(rep(0, tp), rnorm(tp), rep(0, tp))   # explanatory variable
> for condition 2
> reg3 <- c(rep(0, 2*tp), rnorm(tp))             # explanatory variable
> for condition 3
> 
> First I thought that I'd start with gls in nlme package with an ARMA
> model for the correlation structure:
> 
> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
> form=~time, p=1,q=1), data=Dat))
> 
> The above model does not work because of the following error:
> 
> Error in Initialize.corARMA(X[[1L]], ...) :
>   Covariate must have unique values within groups for corARMA objects
> 
> Moreover, I would like to account for the fact that the ARMA structure
> should be similar or the same across the three conditions. My
> questions are:
> 
> 1) how to impose a same ARMA structure across the three conditions?
> 2) alternatively I'd like to have something like:
> 
> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
> form=~time:condition, p=1,q=1), data=Dat))
> 
> but this would not work either, and seems to crash R!
> 
> 3) maybe construct a multivariate gls model, but how to do that? what package?
> 
> Thanks,
> Gang
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From gangchen at mail.nih.gov  Tue May 15 15:07:06 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 15 May 2012 09:07:06 -0400
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <1337083866.7883.6.camel@prometheus.geog.ucl.ac.uk>
References: <CAHmzXO7ArCyA45PgqnD_dcx=SEvQXpfuwySWN6zkZPd8eCunfA@mail.gmail.com>
	<1337083866.7883.6.camel@prometheus.geog.ucl.ac.uk>
Message-ID: <CAHmzXO6BAkpDFAWXzgeDfti9sJad0FJrBF1LTQO3n-mHYG0SVA@mail.gmail.com>

Many thanks for the suggestion. It seems that gls does not like that either:

> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03), form=~time|condition, p=1,q=1), data=Dat))

Error in model.frame.default(formula = ~time + condition + res + reg1 +  :
  variable lengths differ (found for 'condition')


On Tue, May 15, 2012 at 8:11 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> On Tue, 2012-05-15 at 06:27 -0400, Gang Chen wrote:
>> I have some time series data (with 100 time points) collected from one
>> subject. At each time point three measures were taken under three
>> conditions, and there is an explanatory variable for each condition.
>
> The temporal correlation is, in this sense, *nested* within the three
> different conditions. You were close with time:condition, but what I
> think you need is
>
> corARMA(c(0.02, 0.03), form = ~ time | condition)
>
> HTH
>
> G
>
>> Below is just some fake data to demonstrate the data structure:
>>
>> # 100 time points per condition
>> tp <- 100 ? ? ? ? ? ? ? ? ? ? ? ? ? ? # time points
>> trials <- seq(1, tp, 1) ? ? ? ? ?# time counter
>> condition <- c('a', 'b', 'c') ? # three conditions
>>
>> # fake data
>> set.seed(5)
>> Dat <- data.frame(time=rep(trials, 3), cond=rep(condition, each=tp),
>> res=rnorm(3*tp))
>>
>> reg1 <- c(rnorm(tp), rep(0, 2*tp)) ? ? ? ? ? ?# explanatory variable
>> for condition 1
>> reg2 <- c(rep(0, tp), rnorm(tp), rep(0, tp)) ? # explanatory variable
>> for condition 2
>> reg3 <- c(rep(0, 2*tp), rnorm(tp)) ? ? ? ? ? ? # explanatory variable
>> for condition 3
>>
>> First I thought that I'd start with gls in nlme package with an ARMA
>> model for the correlation structure:
>>
>> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
>> form=~time, p=1,q=1), data=Dat))
>>
>> The above model does not work because of the following error:
>>
>> Error in Initialize.corARMA(X[[1L]], ...) :
>> ? Covariate must have unique values within groups for corARMA objects
>>
>> Moreover, I would like to account for the fact that the ARMA structure
>> should be similar or the same across the three conditions. My
>> questions are:
>>
>> 1) how to impose a same ARMA structure across the three conditions?
>> 2) alternatively I'd like to have something like:
>>
>> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
>> form=~time:condition, p=1,q=1), data=Dat))
>>
>> but this would not work either, and seems to crash R!
>>
>> 3) maybe construct a multivariate gls model, but how to do that? what package?
>>
>> Thanks,
>> Gang
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> ?Dr. Gavin Simpson ? ? ? ? ? ? [t] +44 (0)20 7679 0522
> ?ECRC, UCL Geography, ? ? ? ? ?[f] +44 (0)20 7679 0565
> ?Pearson Building, ? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
> ?Gower Street, London ? ? ? ? ?[w] http://www.ucl.ac.uk/~ucfagls/
> ?UK. WC1E 6BT. ? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
>


From gavin.simpson at ucl.ac.uk  Tue May 15 17:39:43 2012
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 15 May 2012 16:39:43 +0100
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <CAHmzXO6BAkpDFAWXzgeDfti9sJad0FJrBF1LTQO3n-mHYG0SVA@mail.gmail.com>
References: <CAHmzXO7ArCyA45PgqnD_dcx=SEvQXpfuwySWN6zkZPd8eCunfA@mail.gmail.com>
	<1337083866.7883.6.camel@prometheus.geog.ucl.ac.uk>
	<CAHmzXO6BAkpDFAWXzgeDfti9sJad0FJrBF1LTQO3n-mHYG0SVA@mail.gmail.com>
Message-ID: <1337096383.7883.15.camel@prometheus.geog.ucl.ac.uk>

Your variables are looked up in *Dat*, it would be a mistake to try rely
upon variable being found in various environments as you are doing here.
That would also force you to consider what you are doing and how you are
setting up your data in R. Put everything into `Dat`, including the
`regx` variables.

I didn't realise this at the time but you are doing this:

Dat <- data.frame(time=rep(trials, 3), cond=rep(condition, each=tp),
                  res=rnorm(3*tp))

notice you are now calling the condition variable `cond`! So it is no
wonder that `condition` doesn't have the required length.

If you use the `Dat` as defined, then

(fm <- gls(res ~ 1+reg1+reg2+reg3,
           correlation=corARMA(c(0.02, 0.03), form=~time|cond, p=1,q=1),
           data=Dat))

works fine

> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
form=~time|cond, p=1,q=1), data=Dat))
Generalized least squares fit by REML
  Model: res ~ 1 + reg1 + reg2 + reg3 
  Data: Dat 
  Log-restricted-likelihood: -425.2665

Coefficients:
(Intercept)        reg1        reg2        reg3 
 0.01305633 -0.03300839 -0.08407831  0.03701266 

Correlation Structure: ARMA(1,1)
 Formula: ~time | cond 
 Parameter estimate(s):
      Phi1     Theta1 
-0.1197791  0.1345616 
Degrees of freedom: 300 total; 296 residual
Residual standard error: 0.9848909

Although I would probably clean up my working environment and call `Dat
$cond` `Dat$condition` but it is up to you. Just make sure you are
referring to things **in** `Dat` with the correct names.

HTH

G

On Tue, 2012-05-15 at 09:07 -0400, Gang Chen wrote:
> Many thanks for the suggestion. It seems that gls does not like that either:
> 
> > (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03), form=~time|condition, p=1,q=1), data=Dat))
> 
> Error in model.frame.default(formula = ~time + condition + res + reg1 +  :
>   variable lengths differ (found for 'condition')
> 
> 
> On Tue, May 15, 2012 at 8:11 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > On Tue, 2012-05-15 at 06:27 -0400, Gang Chen wrote:
> >> I have some time series data (with 100 time points) collected from one
> >> subject. At each time point three measures were taken under three
> >> conditions, and there is an explanatory variable for each condition.
> >
> > The temporal correlation is, in this sense, *nested* within the three
> > different conditions. You were close with time:condition, but what I
> > think you need is
> >
> > corARMA(c(0.02, 0.03), form = ~ time | condition)
> >
> > HTH
> >
> > G
> >
> >> Below is just some fake data to demonstrate the data structure:
> >>
> >> # 100 time points per condition
> >> tp <- 100                             # time points
> >> trials <- seq(1, tp, 1)          # time counter
> >> condition <- c('a', 'b', 'c')   # three conditions
> >>
> >> # fake data
> >> set.seed(5)
> >> Dat <- data.frame(time=rep(trials, 3), cond=rep(condition, each=tp),
> >> res=rnorm(3*tp))
> >>
> >> reg1 <- c(rnorm(tp), rep(0, 2*tp))            # explanatory variable
> >> for condition 1
> >> reg2 <- c(rep(0, tp), rnorm(tp), rep(0, tp))   # explanatory variable
> >> for condition 2
> >> reg3 <- c(rep(0, 2*tp), rnorm(tp))             # explanatory variable
> >> for condition 3
> >>
> >> First I thought that I'd start with gls in nlme package with an ARMA
> >> model for the correlation structure:
> >>
> >> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
> >> form=~time, p=1,q=1), data=Dat))
> >>
> >> The above model does not work because of the following error:
> >>
> >> Error in Initialize.corARMA(X[[1L]], ...) :
> >>   Covariate must have unique values within groups for corARMA objects
> >>
> >> Moreover, I would like to account for the fact that the ARMA structure
> >> should be similar or the same across the three conditions. My
> >> questions are:
> >>
> >> 1) how to impose a same ARMA structure across the three conditions?
> >> 2) alternatively I'd like to have something like:
> >>
> >> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
> >> form=~time:condition, p=1,q=1), data=Dat))
> >>
> >> but this would not work either, and seems to crash R!
> >>
> >> 3) maybe construct a multivariate gls model, but how to do that? what package?
> >>
> >> Thanks,
> >> Gang
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > --
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >  Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
> >  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> >  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> >  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> >  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >
> >
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From highstat at highstat.com  Tue May 15 17:47:22 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 15 May 2012 11:47:22 -0400
Subject: [R-sig-ME] Specifying correlation structure
Message-ID: <4FB27A8A.9020702@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120515/dbce7391/attachment.pl>

From chantepie at mnhn.fr  Tue May 15 18:11:43 2012
From: chantepie at mnhn.fr (Stephane Chantepie)
Date: Tue, 15 May 2012 18:11:43 +0200
Subject: [R-sig-ME] Error in variance estimation using bivariate animal model
Message-ID: <201205151811.43325.chantepie@mnhn.fr>

Dear all,

I am using MCMCglmm function to construct bivariate animal models of bustard 
sperm production according to age. Until six years old, each age are 
considered as a trait. After 6 years old, age-class "7-8" and "9-11" are 
computed to have enought information.

In a first part, additive genetic variance have been estimated by using simple 
animal model. Results are not sensitive to prior and give quite realistic 
estimations

In a second part, I have tried to estimate covariance between these ages. And 
I have some problems in estimating variance-covariance for the bivariate 
models which use the age class "7-8" or "9-11". For example, when I compute 
the model cbind(age_1,age_9_11), the estimation of variance for age_1 and 
age_9_11 are similar to estimations of the  simple animal models. The 
estimation of covariance also appears consistent with the others covariance 
results, so it pretty good. But when I do cbind(age_2,age_9_11), the variance 
estimation of age_9_11 become really hight (out of the range I have found in 
the simple model). So the covariance estimation appears really hight too. I do 
not really understand why it works when I use age_1 against my age-class and 
not when I use the age 2 3 4 5 6. The chains seem to converge and there is no 
autocorrelation 
All variance estimation given by bivariate model wich do not use age-class are 
consistent with the simple models.

result for cbind(age_1,age_9_11) : http://ubuntuone.com/2xewilItvXmqvZZhMW3sTN
result for cbind(age_2,age_9_11) : http://ubuntuone.com/7hVy0DZ2z0qNHkfiZUZXis

I run five times the same model (as below) and concatenate results (same  
prior,same burning, same thin and random seed)
I have just added a ID random parameter when I use a age-class as one of 
bivariate trait (because I have repeated measures)

** spz_var=as.numeric(cbind(var(na.omit(age_2)/2),var(na.omit(age_7_8)/2)))
** prior<-list(R=list(V=diag(2)*spz_var,nu=2), 		
G=list(G1=list(V=diag(2)*spz_var, nu=2),
G2=list(V=diag(2)*spz_var, nu=2),
G3=list(V=diag(2)*spz_var, nu=2)))
** spz<-MCMCglmm(cbind(age_2,age_7_8)~ trait-1, random=~us(trait):animal + 
us(trait):birth + us(trait):ID, rcov=~us(trait):units,nitt=1300000, thin=1000, 
burnin=300000, prior=prior, verbose=TRUE, pedigree=ped, 
family=c("gaussian","gaussian"), data=dat)

Should I modify  "us(trait):ID" to fit random parameter only on the second 
trait? How can I do that? Is my results arenormal?

If you have any idea

Many thanks for your reply

--
Stephane Chantepie
CNRS Phd  candidate
Mus?um national d'Histoire naturelle
55 rue Buffon
75005 paris
E-mail : chantepie_at_mnhn_dot_fr
--


From gavin.simpson at ucl.ac.uk  Tue May 15 18:15:07 2012
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 15 May 2012 17:15:07 +0100
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <4FB27A8A.9020702@highstat.com>
References: <4FB27A8A.9020702@highstat.com>
Message-ID: <1337098507.7883.56.camel@prometheus.geog.ucl.ac.uk>

On Tue, 2012-05-15 at 11:47 -0400, Highland Statistics Ltd wrote:
> Many thanks for the suggestion. It seems that gls does not like that either:
> 
> >/  (fm<- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03), form=~time|condition, p=1,q=1), data=Dat))
> /
> Error in model.frame.default(formula = ~time + condition + res + reg1 +  :
>    variable lengths differ (found for 'condition')

<snip />

> 
> That is because 'condition' is not in your Dat object. I guess it should be cond.
> Why corARMA and not corAR1?
> 
> I'm actually not sure whether your modelling approach is correct. The
> unit is the subject....but the time | cond is imposing the correlation
> inside the observations from the same condition. Is that what you
> want? It would ignore any correlation between 2 observations from
> different
> conditions....but still from the same subject. But perhaps I did not
> fully understand your original post.

Those are good points Alain. My comment would be that the OP mentioned
that there was just a single subject; whether that was just the example
or a real property of the data, who knows? ;-)

Like you, without further info, whether the nested ARMA(1,1) is
sufficient will depend on the OP providing more info.

G

> 
> Alain
> 
> 
> /
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From gangchen at mail.nih.gov  Tue May 15 18:52:26 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 15 May 2012 12:52:26 -0400
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <1337096383.7883.15.camel@prometheus.geog.ucl.ac.uk>
References: <CAHmzXO7ArCyA45PgqnD_dcx=SEvQXpfuwySWN6zkZPd8eCunfA@mail.gmail.com>
	<1337083866.7883.6.camel@prometheus.geog.ucl.ac.uk>
	<CAHmzXO6BAkpDFAWXzgeDfti9sJad0FJrBF1LTQO3n-mHYG0SVA@mail.gmail.com>
	<1337096383.7883.15.camel@prometheus.geog.ucl.ac.uk>
Message-ID: <CAHmzXO5WYPLeP32CJej1hoQFgm_exair63rBYDjF6rH8xS4cqQ@mail.gmail.com>

The mixing of cond vs. condition was really a silly mistake of mine!
Thanks a lot for spotting that...

Yes, corARMA(c(0.02, 0.03), form=~time|cond, p=1,q=1) seems to work by
imposing the SAME ARMA(1, 1) structure for all the conditions.

May I ask one more question: how can I specify an ARMA model for each
condition separately while also accounting for the fact the three
conditions are correlated? That is why I originally thought about
something like "form=~time:condition". Any thought?

Thanks again,
Gang


On Tue, May 15, 2012 at 11:39 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> Your variables are looked up in *Dat*, it would be a mistake to try rely
> upon variable being found in various environments as you are doing here.
> That would also force you to consider what you are doing and how you are
> setting up your data in R. Put everything into `Dat`, including the
> `regx` variables.
>
> I didn't realise this at the time but you are doing this:
>
> Dat <- data.frame(time=rep(trials, 3), cond=rep(condition, each=tp),
> ? ? ? ? ? ? ? ? ?res=rnorm(3*tp))
>
> notice you are now calling the condition variable `cond`! So it is no
> wonder that `condition` doesn't have the required length.
>
> If you use the `Dat` as defined, then
>
> (fm <- gls(res ~ 1+reg1+reg2+reg3,
> ? ? ? ? ? correlation=corARMA(c(0.02, 0.03), form=~time|cond, p=1,q=1),
> ? ? ? ? ? data=Dat))
>
> works fine
>
>> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
> form=~time|cond, p=1,q=1), data=Dat))
> Generalized least squares fit by REML
> ?Model: res ~ 1 + reg1 + reg2 + reg3
> ?Data: Dat
> ?Log-restricted-likelihood: -425.2665
>
> Coefficients:
> (Intercept) ? ? ? ?reg1 ? ? ? ?reg2 ? ? ? ?reg3
> ?0.01305633 -0.03300839 -0.08407831 ?0.03701266
>
> Correlation Structure: ARMA(1,1)
> ?Formula: ~time | cond
> ?Parameter estimate(s):
> ? ? ?Phi1 ? ? Theta1
> -0.1197791 ?0.1345616
> Degrees of freedom: 300 total; 296 residual
> Residual standard error: 0.9848909
>
> Although I would probably clean up my working environment and call `Dat
> $cond` `Dat$condition` but it is up to you. Just make sure you are
> referring to things **in** `Dat` with the correct names.
>
> HTH
>
> G
>
> On Tue, 2012-05-15 at 09:07 -0400, Gang Chen wrote:
>> Many thanks for the suggestion. It seems that gls does not like that either:
>>
>> > (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03), form=~time|condition, p=1,q=1), data=Dat))
>>
>> Error in model.frame.default(formula = ~time + condition + res + reg1 + ?:
>> ? variable lengths differ (found for 'condition')
>>
>>
>> On Tue, May 15, 2012 at 8:11 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
>> > On Tue, 2012-05-15 at 06:27 -0400, Gang Chen wrote:
>> >> I have some time series data (with 100 time points) collected from one
>> >> subject. At each time point three measures were taken under three
>> >> conditions, and there is an explanatory variable for each condition.
>> >
>> > The temporal correlation is, in this sense, *nested* within the three
>> > different conditions. You were close with time:condition, but what I
>> > think you need is
>> >
>> > corARMA(c(0.02, 0.03), form = ~ time | condition)
>> >
>> > HTH
>> >
>> > G
>> >
>> >> Below is just some fake data to demonstrate the data structure:
>> >>
>> >> # 100 time points per condition
>> >> tp <- 100 ? ? ? ? ? ? ? ? ? ? ? ? ? ? # time points
>> >> trials <- seq(1, tp, 1) ? ? ? ? ?# time counter
>> >> condition <- c('a', 'b', 'c') ? # three conditions
>> >>
>> >> # fake data
>> >> set.seed(5)
>> >> Dat <- data.frame(time=rep(trials, 3), cond=rep(condition, each=tp),
>> >> res=rnorm(3*tp))
>> >>
>> >> reg1 <- c(rnorm(tp), rep(0, 2*tp)) ? ? ? ? ? ?# explanatory variable
>> >> for condition 1
>> >> reg2 <- c(rep(0, tp), rnorm(tp), rep(0, tp)) ? # explanatory variable
>> >> for condition 2
>> >> reg3 <- c(rep(0, 2*tp), rnorm(tp)) ? ? ? ? ? ? # explanatory variable
>> >> for condition 3
>> >>
>> >> First I thought that I'd start with gls in nlme package with an ARMA
>> >> model for the correlation structure:
>> >>
>> >> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
>> >> form=~time, p=1,q=1), data=Dat))
>> >>
>> >> The above model does not work because of the following error:
>> >>
>> >> Error in Initialize.corARMA(X[[1L]], ...) :
>> >> ? Covariate must have unique values within groups for corARMA objects
>> >>
>> >> Moreover, I would like to account for the fact that the ARMA structure
>> >> should be similar or the same across the three conditions. My
>> >> questions are:
>> >>
>> >> 1) how to impose a same ARMA structure across the three conditions?
>> >> 2) alternatively I'd like to have something like:
>> >>
>> >> (fm <- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03),
>> >> form=~time:condition, p=1,q=1), data=Dat))
>> >>
>> >> but this would not work either, and seems to crash R!
>> >>
>> >> 3) maybe construct a multivariate gls model, but how to do that? what package?
>> >>
>> >> Thanks,
>> >> Gang
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> > --
>> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>> > ?Dr. Gavin Simpson ? ? ? ? ? ? [t] +44 (0)20 7679 0522
>> > ?ECRC, UCL Geography, ? ? ? ? ?[f] +44 (0)20 7679 0565
>> > ?Pearson Building, ? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
>> > ?Gower Street, London ? ? ? ? ?[w] http://www.ucl.ac.uk/~ucfagls/
>> > ?UK. WC1E 6BT. ? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
>> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>> >
>> >
>>
>
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> ?Dr. Gavin Simpson ? ? ? ? ? ? [t] +44 (0)20 7679 0522
> ?ECRC, UCL Geography, ? ? ? ? ?[f] +44 (0)20 7679 0565
> ?Pearson Building, ? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
> ?Gower Street, London ? ? ? ? ?[w] http://www.ucl.ac.uk/~ucfagls/
> ?UK. WC1E 6BT. ? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
>


From gangchen at mail.nih.gov  Tue May 15 18:59:46 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 15 May 2012 12:59:46 -0400
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <1337098507.7883.56.camel@prometheus.geog.ucl.ac.uk>
References: <4FB27A8A.9020702@highstat.com>
	<1337098507.7883.56.camel@prometheus.geog.ucl.ac.uk>
Message-ID: <CAHmzXO5RNSE6w4JZvjDrTDmx9XahxWMw2u48xSq9xfg7vQwDvA@mail.gmail.com>

Thanks for the comments!

Currently I'm only trying to work on the model specification part with
one subject. With multiple subjects, I can easily switch from gls to
lme. Also the issue of corARMA or corAR1 or others is not important
right now. Instead my focus is, how to correctly specify the
correlation structure across the three conditions? You've kindly
helped me out on imposing the same correlation structure for the three
conditions. The only dangling part is, how to specify a different
correlation structure for each condition while modeling the
correlation similarity across the three conditions?

Gang


On Tue, May 15, 2012 at 12:15 PM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> On Tue, 2012-05-15 at 11:47 -0400, Highland Statistics Ltd wrote:
>> Many thanks for the suggestion. It seems that gls does not like that either:
>>
>> >/ ?(fm<- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03), form=~time|condition, p=1,q=1), data=Dat))
>> /
>> Error in model.frame.default(formula = ~time + condition + res + reg1 + ?:
>> ? ?variable lengths differ (found for 'condition')
>
> <snip />
>
>>
>> That is because 'condition' is not in your Dat object. I guess it should be cond.
>> Why corARMA and not corAR1?
>>
>> I'm actually not sure whether your modelling approach is correct. The
>> unit is the subject....but the time | cond is imposing the correlation
>> inside the observations from the same condition. Is that what you
>> want? It would ignore any correlation between 2 observations from
>> different
>> conditions....but still from the same subject. But perhaps I did not
>> fully understand your original post.
>
> Those are good points Alain. My comment would be that the OP mentioned
> that there was just a single subject; whether that was just the example
> or a real property of the data, who knows? ;-)
>
> Like you, without further info, whether the nested ARMA(1,1) is
> sufficient will depend on the OP providing more info.
>
> G
>
>>
>> Alain
>>
>>
>> /
>>
>
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> ?Dr. Gavin Simpson ? ? ? ? ? ? [t] +44 (0)20 7679 0522
> ?ECRC, UCL Geography, ? ? ? ? ?[f] +44 (0)20 7679 0565
> ?Pearson Building, ? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
> ?Gower Street, London ? ? ? ? ?[w] http://www.ucl.ac.uk/~ucfagls/
> ?UK. WC1E 6BT. ? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Tue May 15 19:26:45 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 15 May 2012 13:26:45 -0400
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <CAHmzXO5RNSE6w4JZvjDrTDmx9XahxWMw2u48xSq9xfg7vQwDvA@mail.gmail.com>
References: <4FB27A8A.9020702@highstat.com>
	<1337098507.7883.56.camel@prometheus.geog.ucl.ac.uk>
	<CAHmzXO5RNSE6w4JZvjDrTDmx9XahxWMw2u48xSq9xfg7vQwDvA@mail.gmail.com>
Message-ID: <4FB291D5.9080500@highstat.com>

On 15/05/2012 12:59, Gang Chen wrote:
> Thanks for the comments!
>
> Currently I'm only trying to work on the model specification part with
> one subject. With multiple subjects, I can easily switch from gls to
> lme. Also the issue of corARMA or corAR1 or others is not important
> right now. Instead my focus is, how to correctly specify the
> correlation structure across the three conditions? You've kindly
> helped me out on imposing the same correlation structure for the three
> conditions. The only dangling part is, how to specify a different
> correlation structure for each condition while modeling the
> correlation similarity across the three conditions?

gls would use the same AR parameter (and therefore correlation 
structure) for all your conditions. If you use both random effects and 
AR1 then you would need to take a pen and paper to work out how exactly 
the correlation looks like (and also ensure that the two terms don't 
compete with each other). If you want to have different AR parameters, 
then one option would be to fit the model within an MCMC context. See 
our 2012 book (sperm whale chapter) for examples how to do this...or 
chapter 23 in our 2009 book for multiple AR parameters.

A random intercept and slope model would be an alternative (the 
correlation would depend on the covariate used as random slope)....but 
whether this is sensible for your data depends on your data, questions 
and your variables.


Alain

>
> Gang
>
>
> On Tue, May 15, 2012 at 12:15 PM, Gavin Simpson<gavin.simpson at ucl.ac.uk>  wrote:
>> On Tue, 2012-05-15 at 11:47 -0400, Highland Statistics Ltd wrote:
>>> Many thanks for the suggestion. It seems that gls does not like that either:
>>>
>>>> /  (fm<- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03), form=~time|condition, p=1,q=1), data=Dat))
>>> /
>>> Error in model.frame.default(formula = ~time + condition + res + reg1 +  :
>>>     variable lengths differ (found for 'condition')
>> <snip />
>>
>>> That is because 'condition' is not in your Dat object. I guess it should be cond.
>>> Why corARMA and not corAR1?
>>>
>>> I'm actually not sure whether your modelling approach is correct. The
>>> unit is the subject....but the time | cond is imposing the correlation
>>> inside the observations from the same condition. Is that what you
>>> want? It would ignore any correlation between 2 observations from
>>> different
>>> conditions....but still from the same subject. But perhaps I did not
>>> fully understand your original post.
>> Those are good points Alain. My comment would be that the OP mentioned
>> that there was just a single subject; whether that was just the example
>> or a real property of the data, who knows? ;-)
>>
>> Like you, without further info, whether the nested ARMA(1,1) is
>> sufficient will depend on the OP providing more info.
>>
>> G
>>
>>> Alain
>>>
>>>
>>> /
>>>
>> --
>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>   Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
>>   ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
>>   Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
>>   Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
>>   UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From Thierry.ONKELINX at inbo.be  Wed May 16 15:06:38 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 16 May 2012 13:06:38 +0000
Subject: [R-sig-ME] Plotting results of interaction from GLMM using
 model	summary coefficients
In-Reply-To: <CAPk3JwR+ujofhXO+uMfdGyFJAe-EPy9ZxPmqUx_JVMg2BfVieQ@mail.gmail.com>
References: <CAPk3JwR+ujofhXO+uMfdGyFJAe-EPy9ZxPmqUx_JVMg2BfVieQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427573B4EA1@inbomail.inbo.be>

Dear Roslyn,

It seems to me like you are confusing coefficients and predictions. How did you make the plots? Did you back-transform the data of the glmer with poisson? Note that the poisson family uses the lok-link by default.

A reproducible example would ben ice.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Roslyn Anderson
Verzonden: zaterdag 12 mei 2012 19:58
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Plotting results of interaction from GLMM using model summary coefficients

Dear List Members,

I have a query regarding the plotting of results from a GLMM model.

I am working with both linear mixed effects models (LMMs) and generalised linear mixed models (GLMMs), mainly using the nlme and lme4 packages in R (2.14.2).

The study involved looking at the effects of *altitude* and the *percentage of traditional sheep on a farm* on various measures of plant diversity.
Here I will concentrate on the response variable *plant species richness*(which ranges from 4 - 26). It is count data so I have used a Poisson distribution.

The experimental design had a nested structure, so I chose to use LMMs and GLMMs. Model syntax for plant species richness is:

*SR <- glmer (plant.spp.rich ~ log10(alt) * TRADEWE.cat + (1|site/farm/habitat), family = poisson, data=veg)*

Fixed effects are:
1) log10(alt) - a log10 transformation on altitude (m) (range: 1.56 - 2.78) and
2) TRADEWE.cat - the percentage of traditional sheep on a farm split into four categories (1 = 0%, 2 = 50%, 3 = 70%, 4 = 100%). Groups are of unequal size, therefore data is unbalanced.

Random effects are:
habitats (categories 1-12), which are nested within farms (categories 1-12), which are nested within sites (categories 1-4).

After rigorous model simplification and validation I am happy with the model summary output and the interaction between log10(alt) and
TRADEWE.cat1 is significantly different to the interaction between
log10(alt) and TRADEWE.cat4. Therefore I wanted to plot this result with plant species richness on the y-axis, log10(alt) on the x-axis and each of the four traditional sheep categories as regression lines on the plot.

See summary below from the GLMM model and then the output of a linear regression model containing the same variables:

> *library(lme4)*

> *SR<-glmer(plant.spp.rich ~ log10(alt) * TRADEWE.cat +
(1|site/farm/habitat), family=poisson, data=veg)*

> *summary(SR)*

Generalized linear mixed model fit by the Laplace approximation
Formula: plant.spp.rich ~ log10(alt) * TRADEWE.cat + (1 |
site/farm/habitat)
Data: veg
AIC   BIC logLik deviance
146.3 178.9 -62.13    124.3
Random effects:
Groups                       Name        Variance Std.Dev.
habitat:(farm:site)    (Intercept)  0.028298 0.16822
farm:site                    (Intercept)  0.000000 0.00000
site                            (Intercept)   0.000000 0.00000
Number of obs: 144, groups: habitat:(farm:site), 48; farm:site, 12; site, 4

Fixed effects:
                                                Estimate Std. Error z value
Pr(>|z|)
(Intercept)                                2.0134     0.5203   3.870
0.000109 ***
log10(alt)                                  0.1717     0.2365   0.726
0.467844
TRADEWE.cat2                     -1.3003     1.7218  -0.755 0.450117
TRADEWE.cat3                     0.5645     1.5340   0.368 0.712872
TRADEWE.cat4                     1.6082     0.6260   2.569 0.010200 *
log10(alt):TRADEWE.cat2   0.5322     0.6907   0.771 0.440985
log10(alt):TRADEWE.cat3   -0.2772     0.7047  -0.393 0.694059
log10(alt):TRADEWE.cat4   -0.6733     0.2814  -2.393 0.016720 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
               (Intr) lg10() TRADEWE.2 TRADEWE.3 TRADEWE.4 l10():TRADEWE.2
l10():TRADEWE.3
log10(alt)      -0.991

TRADEWE.ct2     -0.302  0.299

TRADEWE.ct3     -0.339  0.336  0.102

TRADEWE.ct4     -0.831  0.824  0.251     0.282

l10():TRADEWE.2  0.339 -0.342 -0.997    -0.115    -0.282

l10():TRADEWE.3  0.333 -0.336 -0.100    -0.996    -0.276     0.115

l10():TRADEWE.4  0.833 -0.841 -0.252    -0.282    -0.991     0.288
  0.282


> *SRa<-lm(plant.spp.rich ~ log10(alt) * TRADEWE.cat, data=veg)*

> *summary(SRa)*

Call:
lm(formula = plant.spp.rich ~ log10(alt) * TRADEWE.cat, data = veg)

Residuals:
  Min     1Q Median     3Q    Max
-7.955 -2.091 -0.221  1.943 12.404

Coefficients:
                                                Estimate Std. Error t value
Pr(>|t|)
(Intercept)                                 7.092      4.421   1.604
 0.11096
log10(alt)                                   1.837      2.017   0.911
 0.36397
TRADEWE.cat2                      -17.959     15.078  -1.191  0.23570
TRADEWE.cat3                       6.066     12.795   0.474  0.63618
TRADEWE.cat4                      19.437      5.365   3.623  0.00041 ***
log10(alt):TRADEWE.cat2     7.318      6.058   1.208  0.22913
log10(alt):TRADEWE.cat3    -3.025      5.875  -0.515  0.60747
log10(alt):TRADEWE.cat4    -8.101      2.409  -3.363  0.00100 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.54 on 136 degrees of freedom
Multiple R-squared: 0.1819,     Adjusted R-squared: 0.1398
F-statistic: 4.319 on 7 and 136 DF,  p-value: 0.0002399

My question is why, when using a linear regression model, my coefficients (intercept and slope) for each traditional sheep category fit nice regression lines within the data points on the plot but when using an LMM or a GLMM the coefficients are much lower (and therefore the regression lines are also much lower) than the actual data points on the plot? Is this related to the random effects?

I was just wondering if anyone could suggest an alternative method I might use to plot this result using the coefficients from the GLMM output?

Many, many thanks in advance for any help, advice or guidance.

Best Wishes,

Roz

        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From gangchen at mail.nih.gov  Wed May 16 16:00:30 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Wed, 16 May 2012 10:00:30 -0400
Subject: [R-sig-ME] Specifying correlation structure
In-Reply-To: <4FB291D5.9080500@highstat.com>
References: <4FB27A8A.9020702@highstat.com>
	<1337098507.7883.56.camel@prometheus.geog.ucl.ac.uk>
	<CAHmzXO5RNSE6w4JZvjDrTDmx9XahxWMw2u48xSq9xfg7vQwDvA@mail.gmail.com>
	<4FB291D5.9080500@highstat.com>
Message-ID: <CAHmzXO4X=X9-k_6UL8jeZXteszqh=E7_Lfsd+QUDx4cNYWpQuQ@mail.gmail.com>

I really appreciate the suggestions, Alain! I'll try to check out your
books and play with more models...

Gang

On Tue, May 15, 2012 at 1:26 PM, Highland Statistics Ltd
<highstat at highstat.com> wrote:
> On 15/05/2012 12:59, Gang Chen wrote:
>> Thanks for the comments!
>>
>> Currently I'm only trying to work on the model specification part with
>> one subject. With multiple subjects, I can easily switch from gls to
>> lme. Also the issue of corARMA or corAR1 or others is not important
>> right now. Instead my focus is, how to correctly specify the
>> correlation structure across the three conditions? You've kindly
>> helped me out on imposing the same correlation structure for the three
>> conditions. The only dangling part is, how to specify a different
>> correlation structure for each condition while modeling the
>> correlation similarity across the three conditions?
>
> gls would use the same AR parameter (and therefore correlation
> structure) for all your conditions. If you use both random effects and
> AR1 then you would need to take a pen and paper to work out how exactly
> the correlation looks like (and also ensure that the two terms don't
> compete with each other). If you want to have different AR parameters,
> then one option would be to fit the model within an MCMC context. See
> our 2012 book (sperm whale chapter) for examples how to do this...or
> chapter 23 in our 2009 book for multiple AR parameters.
>
> A random intercept and slope model would be an alternative (the
> correlation would depend on the covariate used as random slope)....but
> whether this is sensible for your data depends on your data, questions
> and your variables.
>
>
> Alain
>
>>
>> Gang
>>
>>
>> On Tue, May 15, 2012 at 12:15 PM, Gavin Simpson<gavin.simpson at ucl.ac.uk> ?wrote:
>>> On Tue, 2012-05-15 at 11:47 -0400, Highland Statistics Ltd wrote:
>>>> Many thanks for the suggestion. It seems that gls does not like that either:
>>>>
>>>>> / ?(fm<- gls(res ~ 1+reg1+reg2+reg3, correlation=corARMA(c(0.02, 0.03), form=~time|condition, p=1,q=1), data=Dat))
>>>> /
>>>> Error in model.frame.default(formula = ~time + condition + res + reg1 + ?:
>>>> ? ? variable lengths differ (found for 'condition')
>>> <snip />
>>>
>>>> That is because 'condition' is not in your Dat object. I guess it should be cond.
>>>> Why corARMA and not corAR1?
>>>>
>>>> I'm actually not sure whether your modelling approach is correct. The
>>>> unit is the subject....but the time | cond is imposing the correlation
>>>> inside the observations from the same condition. Is that what you
>>>> want? It would ignore any correlation between 2 observations from
>>>> different
>>>> conditions....but still from the same subject. But perhaps I did not
>>>> fully understand your original post.
>>> Those are good points Alain. My comment would be that the OP mentioned
>>> that there was just a single subject; whether that was just the example
>>> or a real property of the data, who knows? ;-)
>>>
>>> Like you, without further info, whether the nested ARMA(1,1) is
>>> sufficient will depend on the OP providing more info.
>>>
>>> G
>>>
>>>> Alain
>>>>
>>>>
>>>> /
>>>>
>>> --
>>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>> ? Dr. Gavin Simpson ? ? ? ? ? ? [t] +44 (0)20 7679 0522
>>> ? ECRC, UCL Geography, ? ? ? ? ?[f] +44 (0)20 7679 0565
>>> ? Pearson Building, ? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
>>> ? Gower Street, London ? ? ? ? ?[w] http://www.ucl.ac.uk/~ucfagls/
>>> ? UK. WC1E 6BT. ? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
>>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
>
> Dr. Alain F. Zuur
> First author of:
>
> 1. Analysing Ecological Data (2007).
> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
> URL: www.springer.com/0-387-45967-7
>
>
> 2. Mixed effects models and extensions in ecology with R. (2009).
> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
>
>
> 3. A Beginner's Guide to R (2009).
> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
>
>
> 4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
> http://www.highstat.com/book4.htm
>
> Other books: http://www.highstat.com/books.htm
>
>
> Statistical consultancy, courses, data analysis and software
> Highland Statistics Ltd.
> 6 Laverock road
> UK - AB41 6FN Newburgh
> Tel: 0044 1358 788177
> Email: highstat at highstat.com
> URL: www.highstat.com
> URL: www.brodgar.com
>


From gabriela_escati at yahoo.com.ar  Wed May 16 16:00:59 2012
From: gabriela_escati at yahoo.com.ar (=?utf-8?B?Z2FicmllbGEgZXNjYXRpIHBlw7FhbG96YQ==?=)
Date: Wed, 16 May 2012 07:00:59 -0700 (PDT)
Subject: [R-sig-ME] differences estimates between nlme vs nlmer
Message-ID: <1337176859.86272.YahooMailClassic@web113813.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120516/6c07d32f/attachment.pl>

From r.anderson at umail.ucc.ie  Wed May 16 16:36:16 2012
From: r.anderson at umail.ucc.ie (Roslyn Anderson)
Date: Wed, 16 May 2012 15:36:16 +0100
Subject: [R-sig-ME] Plotting results of interaction from GLMM using
 model summary coefficients
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427573B4EA1@inbomail.inbo.be>
References: <CAPk3JwR+ujofhXO+uMfdGyFJAe-EPy9ZxPmqUx_JVMg2BfVieQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427573B4EA1@inbomail.inbo.be>
Message-ID: <CAPk3JwQ4Johq7qiHL1WL4whS+bNycsgAYotSQvLRVJ60K9FW1Q@mail.gmail.com>

Dear Thierry,


Many thanks for your email. I think I may be confusing coefficients and
predictions. Please see below the code that I used to plot the figure and
the figure as an attachment. My maximum value for the response variable,
plant species richness, is 26:

> veg$plant.spp.rich

[1] 15 14 11 10 11 11 11 15 12 15 14 12 14 16 14  5  4  5 17 12  7 12 11  9
8

[26]  7 10 12 13 12  7 12 11 20 15 15 13  8  9 18 16 15 15 13 17 14  9 11
23 26

[51] 16  5  9  7  6 12 10 13 12 11 11 11  9 10  8  8 11 14 14 12 10  9 12
15 13

[76] 11  9  7  8 14 13  9 11 11 12 18 11 16 13 10 13 14 15 10  9  9  8  7  7
11

[101] 10  9  7  9 11 12 13 22 11 10 10 16 15 13  9 11  9  9  9 10  9  5  7
11 11

[126] 11 13 24 18 14 11  6 18 21 19 11 10 10 14 13 16 12  8 11

> tapply(veg$plant.spp.rich, veg$TRADEWE.cat, max)

1  2  3  4

24 20 14 26

However, the intercepts and slopes that I have calculated for each
TRADEWE.cat (1-4) are all quite a bit below this.


> SR<-glmer(plant.spp.rich ~ log10(alt) * TRADEWE.cat +
(1|site/farm/habitat), family=poisson, data=veg)

> summary(SR)

Generalized linear mixed model fit by the Laplace approximation

Formula: plant.spp.rich ~ log10(alt) * TRADEWE.cat + (1 |
site/farm/habitat)

   Data: veg

   AIC   BIC logLik deviance

 146.3 178.9 -62.13    124.3

Random effects:

 Groups              Name        Variance Std.Dev.

 habitat:(farm:site) (Intercept) 0.028298 0.16822

 farm:site           (Intercept) 0.000000 0.00000

 site                (Intercept) 0.000000 0.00000

Number of obs: 144, groups: habitat:(farm:site), 48; farm:site, 12; site, 4



Fixed effects:

                                          Estimate Std. Error z value
Pr(>|z|)

(Intercept)                         2.0134     0.5203   3.870 0.000109 ***

log10(alt)                          0.1717     0.2365   0.726 0.467844

TRADEWE.cat2             -1.3003     1.7218  -0.755 0.450117

TRADEWE.cat3              0.5645     1.5340   0.368 0.712872

TRADEWE.cat4              1.6082     0.6260   2.569 0.010200 *

log10(alt):TRADEWE.cat2   0.5322     0.6907   0.771 0.440985

log10(alt):TRADEWE.cat3  -0.2772     0.7047  -0.393 0.694059

log10(alt):TRADEWE.cat4  -0.6733     0.2814  -2.393 0.016720 *

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:

                (Intr) lg10() TRADEWE.2 TRADEWE.3 TRADEWE.4 l10():TRADEWE.2

log10(alt)      -0.991

TRADEWE.ct2     -0.302  0.299

TRADEWE.ct3     -0.339  0.336  0.102

TRADEWE.ct4     -0.831  0.824  0.251     0.282

l10():TRADEWE.2  0.339 -0.342 -0.997    -0.115    -0.282

l10():TRADEWE.3  0.333 -0.336 -0.100    -0.996    -0.276     0.115

l10():TRADEWE.4  0.833 -0.841 -0.252    -0.282    -0.991     0.288

                l10():TRADEWE.3

log10(alt)

TRADEWE.ct2

TRADEWE.ct3

TRADEWE.ct4

l10():TRADEWE.2

l10():TRADEWE.3

l10():TRADEWE.4  0.282



# for TRADEWE.cat = 1

plant.spp.rich = 2.0134 + 0.1717*log10(alt) #intercept = 2.0134, slope =
0.1717

 # for TRADEWE.cat = 2

plant.spp.rich = (2.0134 ? 1.3003) + (0.1717 + 0.5322)*log10(alt)
#intercept = 0.7131, slope = 0.7039

 # for TRADEWE.cat = 3

plant.spp.rich = (2.0134 + 0.5645) + (0.1717 ? 0.2772)*log10(alt)
#intercept = 2.5779, slope = -0.1055

 # for TRADEWE.cat = 4

plant.spp.rich = (2.0134 + 1.6082) + (0.1717 ? 0.6733)*log10(alt)
#intercept = 3.6216, slope = -0.5016



> par(mfrow=c(2,2), mar=c(2,3,2,1), oma=c(3,1.5,0,1))

> plot(plant.spp.rich[TRADEWE.cat=="1"]~log10(alt)[TRADEWE.cat=="1"],
pch=1, xlim=c(1.0, 4.0), ylim=c(0,30), xlab="", ylab="", cex.axis=0.6,
main="0% traditional ewes", cex.main = 0.75, data=veg)

> abline(2.01, 0.17, lty=1, lwd=1)

> plot(plant.spp.rich[TRADEWE.cat=="2"]~log10(alt)[TRADEWE.cat=="2"],pch=2,
xlim=c(1.0, 4.0), ylim=c(0,30),xlab="", ylab="", cex.axis=0.6,main="50%
traditional ewes",cex.main = 0.75,data=veg)

> abline(0.71, 0.70, lty=2, lwd=2)

> plot(plant.spp.rich[TRADEWE.cat=="3"]~log10(alt)[TRADEWE.cat=="3"],pch=3,
xlim=c(1.0, 4.0), ylim=c(0,30), xlab="", ylab="", cex.axis=0.6,main="70%
traditional ewes",cex.main = 0.75, data=veg)

> abline(2.58, -0.12, lty=3, lwd=3)

> mtext(side=2, "plant species richness", cex=0.5, at =30, font=2, line=3)

> plot(plant.spp.rich[TRADEWE.cat=="4"]~log10(alt)[TRADEWE.cat=="4"],pch=4,
xlim=c(1.0, 4.0), ylim=c(0,30), xlab="", ylab="", cex.axis=0.6,main="100%
traditional ewes",cex.main = 0.75, data=veg)

> abline(3.62, -0.50, lty=4, lwd=4)

> mtext(side=1, expression("log"[10]*" altitude (m)"), cex=0.5, at =0,
font=2, line=3)


I haven?t back-transformed the data of the glmer with poisson. I apologise
for my basic knowledge of statistical procedures in R but what would be the
best way to go about doing this? Could I then use this to create regression
lines which run through the real data points?

Please let me know if you would like me to provide any further information.


Many thanks again for all your advice and guidance,


Best Wishes,


Roz


On 16 May 2012 14:06, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:

> Dear Roslyn,
>
> It seems to me like you are confusing coefficients and predictions. How
> did you make the plots? Did you back-transform the data of the glmer with
> poisson? Note that the poisson family uses the lok-link by default.
>
> A reproducible example would ben ice.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] Namens Roslyn Anderson
> Verzonden: zaterdag 12 mei 2012 19:58
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Plotting results of interaction from GLMM using
> model summary coefficients
>
> Dear List Members,
>
> I have a query regarding the plotting of results from a GLMM model.
>
> I am working with both linear mixed effects models (LMMs) and generalised
> linear mixed models (GLMMs), mainly using the nlme and lme4 packages in R
> (2.14.2).
>
> The study involved looking at the effects of *altitude* and the
> *percentage of traditional sheep on a farm* on various measures of plant
> diversity.
> Here I will concentrate on the response variable *plant species
> richness*(which ranges from 4 - 26). It is count data so I have used a
> Poisson distribution.
>
> The experimental design had a nested structure, so I chose to use LMMs and
> GLMMs. Model syntax for plant species richness is:
>
> *SR <- glmer (plant.spp.rich ~ log10(alt) * TRADEWE.cat +
> (1|site/farm/habitat), family = poisson, data=veg)*
>
> Fixed effects are:
> 1) log10(alt) - a log10 transformation on altitude (m) (range: 1.56 -
> 2.78) and
> 2) TRADEWE.cat - the percentage of traditional sheep on a farm split into
> four categories (1 = 0%, 2 = 50%, 3 = 70%, 4 = 100%). Groups are of unequal
> size, therefore data is unbalanced.
>
> Random effects are:
> habitats (categories 1-12), which are nested within farms (categories
> 1-12), which are nested within sites (categories 1-4).
>
> After rigorous model simplification and validation I am happy with the
> model summary output and the interaction between log10(alt) and
> TRADEWE.cat1 is significantly different to the interaction between
> log10(alt) and TRADEWE.cat4. Therefore I wanted to plot this result with
> plant species richness on the y-axis, log10(alt) on the x-axis and each of
> the four traditional sheep categories as regression lines on the plot.
>
> See summary below from the GLMM model and then the output of a linear
> regression model containing the same variables:
>
> > *library(lme4)*
>
> > *SR<-glmer(plant.spp.rich ~ log10(alt) * TRADEWE.cat +
> (1|site/farm/habitat), family=poisson, data=veg)*
>
> > *summary(SR)*
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: plant.spp.rich ~ log10(alt) * TRADEWE.cat + (1 |
> site/farm/habitat)
> Data: veg
> AIC   BIC logLik deviance
> 146.3 178.9 -62.13    124.3
> Random effects:
> Groups                       Name        Variance Std.Dev.
> habitat:(farm:site)    (Intercept)  0.028298 0.16822
> farm:site                    (Intercept)  0.000000 0.00000
> site                            (Intercept)   0.000000 0.00000
> Number of obs: 144, groups: habitat:(farm:site), 48; farm:site, 12; site, 4
>
> Fixed effects:
>                                                Estimate Std. Error z value
> Pr(>|z|)
> (Intercept)                                2.0134     0.5203   3.870
> 0.000109 ***
> log10(alt)                                  0.1717     0.2365   0.726
> 0.467844
> TRADEWE.cat2                     -1.3003     1.7218  -0.755 0.450117
> TRADEWE.cat3                     0.5645     1.5340   0.368 0.712872
> TRADEWE.cat4                     1.6082     0.6260   2.569 0.010200 *
> log10(alt):TRADEWE.cat2   0.5322     0.6907   0.771 0.440985
> log10(alt):TRADEWE.cat3   -0.2772     0.7047  -0.393 0.694059
> log10(alt):TRADEWE.cat4   -0.6733     0.2814  -2.393 0.016720 *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>               (Intr) lg10() TRADEWE.2 TRADEWE.3 TRADEWE.4 l10():TRADEWE.2
> l10():TRADEWE.3
> log10(alt)      -0.991
>
> TRADEWE.ct2     -0.302  0.299
>
> TRADEWE.ct3     -0.339  0.336  0.102
>
> TRADEWE.ct4     -0.831  0.824  0.251     0.282
>
> l10():TRADEWE.2  0.339 -0.342 -0.997    -0.115    -0.282
>
> l10():TRADEWE.3  0.333 -0.336 -0.100    -0.996    -0.276     0.115
>
> l10():TRADEWE.4  0.833 -0.841 -0.252    -0.282    -0.991     0.288
>  0.282
>
>
> > *SRa<-lm(plant.spp.rich ~ log10(alt) * TRADEWE.cat, data=veg)*
>
> > *summary(SRa)*
>
> Call:
> lm(formula = plant.spp.rich ~ log10(alt) * TRADEWE.cat, data = veg)
>
> Residuals:
>  Min     1Q Median     3Q    Max
> -7.955 -2.091 -0.221  1.943 12.404
>
> Coefficients:
>                                                Estimate Std. Error t value
> Pr(>|t|)
> (Intercept)                                 7.092      4.421   1.604
>  0.11096
> log10(alt)                                   1.837      2.017   0.911
>  0.36397
> TRADEWE.cat2                      -17.959     15.078  -1.191  0.23570
> TRADEWE.cat3                       6.066     12.795   0.474  0.63618
> TRADEWE.cat4                      19.437      5.365   3.623  0.00041 ***
> log10(alt):TRADEWE.cat2     7.318      6.058   1.208  0.22913
> log10(alt):TRADEWE.cat3    -3.025      5.875  -0.515  0.60747
> log10(alt):TRADEWE.cat4    -8.101      2.409  -3.363  0.00100 **
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Residual standard error: 3.54 on 136 degrees of freedom
> Multiple R-squared: 0.1819,     Adjusted R-squared: 0.1398
> F-statistic: 4.319 on 7 and 136 DF,  p-value: 0.0002399
>
> My question is why, when using a linear regression model, my coefficients
> (intercept and slope) for each traditional sheep category fit nice
> regression lines within the data points on the plot but when using an LMM
> or a GLMM the coefficients are much lower (and therefore the regression
> lines are also much lower) than the actual data points on the plot? Is this
> related to the random effects?
>
> I was just wondering if anyone could suggest an alternative method I might
> use to plot this result using the coefficients from the GLMM output?
>
> Many, many thanks in advance for any help, advice or guidance.
>
> Best Wishes,
>
> Roz
>
>        [[alternative HTML version deleted]]
>
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>

From maj at waikato.ac.nz  Thu May 17 00:35:02 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Thu, 17 May 2012 10:35:02 +1200
Subject: [R-sig-ME] Likelihood drops on adding random effect
Message-ID: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120517/c5581795/attachment.pl>

From David.Duffy at qimr.edu.au  Thu May 17 02:22:30 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 17 May 2012 10:22:30 +1000 (EST)
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>

On Thu, 17 May 2012, Murray Jorgensen wrote:

> it is counterintuitive to me that adding a random effect to a GLMM should
> lead to a drop in the likelihood of the fitted model

> f0128bit: fincr ~ icfac + (1 | gap) + (1 | box) + (1 | gap:box) + (1 |
> f0128bit:     tree)
>         Df    AIC    BIC  logLik Chisq Chi Df Pr(>Chisq)
> f0128bi   7 615.73 655.48 -300.87
> f0128bit  8 687.01 732.43 -335.51     0      1          1

It's not counterintuitive, it's wrong  ;)  So either N's are different or 
program got stuck.  Try fiddling with starting values.


From maj at waikato.ac.nz  Thu May 17 03:04:49 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Thu, 17 May 2012 13:04:49 +1200
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
Message-ID: <CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120517/fdc626ab/attachment.pl>

From bbolker at gmail.com  Thu May 17 04:33:35 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 May 2012 02:33:35 +0000 (UTC)
Subject: [R-sig-ME] Likelihood drops on adding random effect
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
Message-ID: <loom.20120517T043239-420@post.gmane.org>

Murray Jorgensen <maj at ...> writes:

> 
> *I tried using 'update' which should (I believe) initialise at the simpler
> model:
> 
> > f0128biu = update(f0128bi, . ~ . + (1|tree))
> Error in model.frame.default(formula = fincr ~ icfac + (1 + gap) + (1 +  :
>   invalid type (closure) for variable 'box'
> 
> Murray
> 

  It's not really shocking to me that update() doesn't work, fiddling
with random effects formulas can be tricky.  Are you willing to post
data somewhere (or e-mail it to me)?

  Ben Bolker


From David.Duffy at qimr.edu.au  Thu May 17 04:34:28 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 17 May 2012 12:34:28 +1000 (EST)
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com><Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>

On Thu, 17 May 2012, Murray Jorgensen wrote:

> *I tried using 'update' which should (I believe) initialise at the simpler
> model:
>
>> f0128biu = update(f0128bi, . ~ . + (1|tree))
> Error in model.frame.default(formula = fincr ~ icfac + (1 + gap) + (1 +  :
>  invalid type (closure) for variable 'box'

It's finding the box() function.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From maj at waikato.ac.nz  Thu May 17 04:48:45 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Thu, 17 May 2012 14:48:45 +1200
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
	<Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
Message-ID: <CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120517/a53e2452/attachment.pl>

From bates at stat.wisc.edu  Thu May 17 05:58:16 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 16 May 2012 22:58:16 -0500
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
	<Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
	<CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
Message-ID: <CAO7JsnQXN8cDa=vjzGS8fZMhMHokUb6CybbSmNQLn4iWZ74sxg@mail.gmail.com>

On Wed, May 16, 2012 at 9:48 PM, Murray Jorgensen <maj at waikato.ac.nz> wrote:
> *Thanks for that, David.
>
>> boxx <- box
>> f0128bi = lmer(fincr ~ icfac + (1|gap) + (1|boxx)+ (1|gap:boxx), family =
> binomial)
>> f0128biu = update(f0128bi, . ~ . + (1|tree))
>> anova(f0128bi,f0128biu)
> Data:
> Models:
> f0128bi: fincr ~ icfac + (1 | gap) + (1 | boxx) + (1 | gap:boxx)
> f0128biu: fincr ~ icfac + (1 | gap) + (1 | boxx) + (1 | gap:boxx) + (1 |
> f0128biu: ? ? tree)
> ? ? ? ? Df ? ?AIC ? ?BIC ?logLik Chisq Chi Df Pr(>Chisq)
> f0128bi ? 7 615.73 655.48 -300.87
> f0128biu ?8 687.01 732.43 -335.51 ? ? 0 ? ? ?1 ? ? ? ? ?1
>
> So update() does not help. I guess I will need to fool with starting values.

update() can't help in this context.  All update does is take the call
from the previous fit, modify it according to the other arguments to
update, then evaluate the modified call.

Notice that your first model fit has a zero estimate for the 1080
random effects associated with the gap:box interaction, so the model
reduces to

 fincr ~ icfac + (1 | gap) + (1 | box) + (1 | tree)

Models with a random effect for gap:box have over 1080 random effects
for 2160 binary observations.

As with all such cases, I would start with setting verbose=2 or
something like that to see where the iterations are headed.  The model
is probably converging to a local optimum on the boundary.

> On 17 May 2012 14:34, David Duffy <David.Duffy at qimr.edu.au> wrote:
>
>> On Thu, 17 May 2012, Murray Jorgensen wrote:
>>
>> ?*I tried using 'update' which should (I believe) initialise at the simpler
>>>
>>> model:
>>>
>>> ?f0128biu = update(f0128bi, . ~ . + (1|tree))
>>>>
>>> Error in model.frame.default(formula = fincr ~ icfac + (1 + gap) + (1 + ?:
>>> ?invalid type (closure) for variable 'box'
>>>
>>
>> It's finding the box() function.
>>
>> --
>> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
>> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
>> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
>>
>
>
>
> --
> Dr Murray Jorgensen ? ? ?http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz ? ?majorgensen at ihug.co.nz ? ? ?Fax 7 838 4155
> Phone ?+64 7 838 4773 wk ? ?Home +64 7 825 0441 ? Mobile 021 0200 8350
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From maj at waikato.ac.nz  Thu May 17 07:06:25 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Thu, 17 May 2012 17:06:25 +1200
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <4FB47B48.80407@waikato.ac.nz>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
	<Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
	<CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
	<CAO7JsnQXN8cDa=vjzGS8fZMhMHokUb6CybbSmNQLn4iWZ74sxg@mail.gmail.com>
	<4FB47B48.80407@waikato.ac.nz>
Message-ID: <CAE85cPn8w58nKo=7cXARVPbzKRtL70SvHwYpgf5=O-cPEvADOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120517/14ac5835/attachment.pl>

From maj at waikato.ac.nz  Thu May 17 07:37:29 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Thu, 17 May 2012 17:37:29 +1200
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
	<Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
	<CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
Message-ID: <4FB48E99.4010401@waikato.ac.nz>

PS  I also tried

start = list( fixef = c( -9.28405,  2.81300, -4.75935,  2.91080),
         ST = c(0, 8.29931, 2.56368e-06,  0.00000))

and

start = list( fixef = list( -9.28405,  2.81300, -4.75935,  2.91080), 

        ST = list(0, 8.29931, 2.56368e-06,  0.00000))

to no avail.


From bates at stat.wisc.edu  Thu May 17 19:48:07 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 17 May 2012 12:48:07 -0500
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <4FB48E99.4010401@waikato.ac.nz>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
	<Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
	<CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
	<4FB48E99.4010401@waikato.ac.nz>
Message-ID: <CAO7JsnSD6y0VqHyv0=UVb53MXnmTmOnit-cgOVeanojn_wXqEQ@mail.gmail.com>

Look at the values of the coefficients and standard deviations that
you are "converging" to.  Your intercept is -9.28, which, with a
binomial family, corresponds to probabilities below 1e-4.  With icfac
= fem the linear predictor is -9.28 - 4.76 = -14.04 corresponding to a
probability of 8e-07.

You are going to need to look at the data and the proportions of
positives for different levels of icfac to see what would make sense.
This problem will create a very ill-defined likelihood surface because
the fitted values will lose sensitivity to the parameters when the
probabilities are so extreme.  If you start extreme values you will
never be able to converge.

On Thu, May 17, 2012 at 12:37 AM, Murray Jorgensen <maj at waikato.ac.nz> wrote:
> PS ?I also tried
>
> start = list( fixef = c( -9.28405, ?2.81300, -4.75935, ?2.91080),
> ? ? ? ?ST = c(0, 8.29931, 2.56368e-06, ?0.00000))
>
> and
>
> start = list( fixef = list( -9.28405, ?2.81300, -4.75935, ?2.91080),
> ? ? ? ST = list(0, 8.29931, 2.56368e-06, ?0.00000))
>
> to no avail.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From maj at waikato.ac.nz  Fri May 18 01:36:04 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Fri, 18 May 2012 11:36:04 +1200
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <CAO7JsnSD6y0VqHyv0=UVb53MXnmTmOnit-cgOVeanojn_wXqEQ@mail.gmail.com>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
	<Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
	<CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
	<4FB48E99.4010401@waikato.ac.nz>
	<CAO7JsnSD6y0VqHyv0=UVb53MXnmTmOnit-cgOVeanojn_wXqEQ@mail.gmail.com>
Message-ID: <4FB58B64.70503@waikato.ac.nz>

I guess we may have a case of a sort of spike in the loglikelihood that 
indicates that the MLE (or at least the lmer estimate) for the model 
without the 'tree' effect is spurious. (Probably the sort of thing that 
would be smoothed away by any reasonable prior.) I really was looking 
more closely at the other fixed effect parameters, regarding the 
intercept as a bit of a nuisance. I hope to say more about the data set 
later. Maybe I will do a sort of profile around the intercept value and 
just fit the other parameters.

I would like to ask the list for some more help with the 'start =' 
parameter though because I don't seem to be quite using it correctly.

 > ip2 = c(0, 8.29931, 2.56368e-06,  0.00000)
 > f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + 
(1|tree), family = binomial,
+                  verbose = TRUE, start = ip2)
   0:     775.67797:  0.00000  8.29931 2.56368e-06  0.00000 -3.22238 
1.44743 -2.20257  1.02515
   1:     747.52247:  0.00000  5.04306 6.75518e-05  0.00000 -4.34098 
2.12417 -3.74289 -0.121576
   2:     736.84946:  0.00000  4.55878 0.000215665  0.00000 -4.39655 
1.52182 -3.63273 -0.115459
...
  45:     671.01076: 4.57910e-09 0.287720 0.350164 0.711054 -3.43481 
1.45346 -2.57398 0.293897
  46:     671.01076:  0.00000 0.287721 0.350162 0.711064 -3.43483 
1.45346 -2.57397 0.293955

That works well for initialising the variance parameters only.

 > f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + 
(1|tree), family = binomial,
+               verbose = TRUE, start = list( fixef = list( -9.28405, 
2.81300, -4.75935,  2.91080),
+ ST = list(0, 8.29931, 2.56368e-06,  0.00000))
+ )
Error: class(STnew[[i]]) == class(ST[[i]]) is not TRUE
In addition: Warning message:
In sort(names(start)) == sort(names(FL)) :
   longer object length is not a multiple of shorter object length

A failed attempt to initialise both fixed and random parameters.

 > f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + 
(1|tree), family = binomial,
+               verbose = TRUE, start = list( fixef = c( -9.28405, 
2.81300, -4.75935,  2.91080),
+ ST = c(0, 8.29931, 2.56368e-06,  0.00000))
+ )
Error: is.list(STnew) is not TRUE
In addition: Warning message:
In sort(names(start)) == sort(names(FL)) :
   longer object length is not a multiple of shorter object length

Another failure.

 > initpar = c(0, 8.29931, 2.56368e-06,  0.00000, -9.28405,  2.81300, 
-4.75935,  2.91080)
 > f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + 
(1|tree), family = binomial,
+                  verbose = TRUE, start = initpar)
   0:     696.35176:  1.15470 0.222222 0.182574 0.157135 -3.22238 
1.44743 -2.20257  1.02515
   1:     687.88422: 0.646498 0.349241 0.199295 0.375671 -4.02981 
1.29061 -2.23330  1.01588
  ...
  26:     671.01076:  0.00000 0.287718 0.350162 0.711060 -3.43482 
1.45346 -2.57397 0.293937
  27:     671.01076:  0.00000 0.287721 0.350163 0.711061 -3.43482 
1.45346 -2.57398 0.293936

Runs, but does not seem to use the supplied starting parameters.

Thanks, for your comments.

Murray

On 18/05/2012 5:48 a.m., Douglas Bates wrote:
> Look at the values of the coefficients and standard deviations that
> you are "converging" to.  Your intercept is -9.28, which, with a
> binomial family, corresponds to probabilities below 1e-4.  With icfac
> = fem the linear predictor is -9.28 - 4.76 = -14.04 corresponding to a
> probability of 8e-07.
>
> You are going to need to look at the data and the proportions of
> positives for different levels of icfac to see what would make sense.
> This problem will create a very ill-defined likelihood surface because
> the fitted values will lose sensitivity to the parameters when the
> probabilities are so extreme.  If you start extreme values you will
> never be able to converge.
>
> On Thu, May 17, 2012 at 12:37 AM, Murray Jorgensen<maj at waikato.ac.nz>  wrote:
>> PS  I also tried
>>
>> start = list( fixef = c( -9.28405,  2.81300, -4.75935,  2.91080),
>>         ST = c(0, 8.29931, 2.56368e-06,  0.00000))
>>
>> and
>>
>> start = list( fixef = list( -9.28405,  2.81300, -4.75935,  2.91080),
>>        ST = list(0, 8.29931, 2.56368e-06,  0.00000))
>>
>> to no avail.
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz      majmurr at gmail.com         Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350


From davef at otter-rsch.com  Fri May 18 01:21:40 2012
From: davef at otter-rsch.com (dave fournier)
Date: Thu, 17 May 2012 16:21:40 -0700
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
Message-ID: <4FB58804.80108@otter-rsch.com>


This discussion reminds me of some reanalysis
I did a while back.

     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q4/006953.html


The results were that the Laplace approximation may not be accurate enough
for this type of model and that AGHQ seems to be broken on lme?.

Perhaps that is the source of your problem. I would advise reanalyzing
with AD Model builder's random effects package. It can deal with crossed 
effects
by extending the Laplace approximation with various types of importance
sampling.


From bates at stat.wisc.edu  Fri May 18 02:16:56 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 17 May 2012 19:16:56 -0500
Subject: [R-sig-ME] Likelihood drops on adding random effect
In-Reply-To: <4FB58B64.70503@waikato.ac.nz>
References: <CAE85cP=98PW8AMUu9y_8fK8CtZGroNdw0GHb4ah5eR1LVoWFtQ@mail.gmail.com>
	<Pine.LNX.4.64.1205171019430.31013@orpheus.qimr.edu.au>
	<CAE85cPnaiAhMa5qKZQLCwsq=0GXMb4YBtUHAy-jc4xUFcvteFw@mail.gmail.com>
	<Pine.LNX.4.64.1205171233520.2840@orpheus.qimr.edu.au>
	<CAE85cP=jrSTh293bY=8RzibgoHWfWbisMF_44CryAgm_+5mgew@mail.gmail.com>
	<4FB48E99.4010401@waikato.ac.nz>
	<CAO7JsnSD6y0VqHyv0=UVb53MXnmTmOnit-cgOVeanojn_wXqEQ@mail.gmail.com>
	<4FB58B64.70503@waikato.ac.nz>
Message-ID: <CAO7JsnTBHZ63N3ENaWobW-hCqCp1TZPBsYLqh3G==5by3T1i4w@mail.gmail.com>

Is it possible to provide the data to us, Murray?  We're putting the
final touches on a new version of lme4 and would like to head off any
glitches before release.

The new version uses different optimizers and a somewhat different
representation of the model.  It also allows for evaluation of the
deviance by adaptive Gauss-Hermite quadrature (AGQ) which, as Dave
Fournier indicates, may stabilize the optimization.

On Thu, May 17, 2012 at 6:36 PM, Murray Jorgensen <maj at waikato.ac.nz> wrote:
> I guess we may have a case of a sort of spike in the loglikelihood that
> indicates that the MLE (or at least the lmer estimate) for the model without
> the 'tree' effect is spurious. (Probably the sort of thing that would be
> smoothed away by any reasonable prior.) I really was looking more closely at
> the other fixed effect parameters, regarding the intercept as a bit of a
> nuisance. I hope to say more about the data set later. Maybe I will do a
> sort of profile around the intercept value and just fit the other
> parameters.
>
> I would like to ask the list for some more help with the 'start =' parameter
> though because I don't seem to be quite using it correctly.
>
>> ip2 = c(0, 8.29931, 2.56368e-06, ?0.00000)
>
>> f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + (1|tree),
>> family = binomial,
> + ? ? ? ? ? ? ? ? ?verbose = TRUE, start = ip2)
> ?0: ? ? 775.67797: ?0.00000 ?8.29931 2.56368e-06 ?0.00000 -3.22238 1.44743
> -2.20257 ?1.02515
> ?1: ? ? 747.52247: ?0.00000 ?5.04306 6.75518e-05 ?0.00000 -4.34098 2.12417
> -3.74289 -0.121576
> ?2: ? ? 736.84946: ?0.00000 ?4.55878 0.000215665 ?0.00000 -4.39655 1.52182
> -3.63273 -0.115459
> ...
> ?45: ? ? 671.01076: 4.57910e-09 0.287720 0.350164 0.711054 -3.43481 1.45346
> -2.57398 0.293897
> ?46: ? ? 671.01076: ?0.00000 0.287721 0.350162 0.711064 -3.43483 1.45346
> -2.57397 0.293955
>
> That works well for initialising the variance parameters only.
>
>
>> f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + (1|tree),
>> family = binomial,
> + ? ? ? ? ? ? ? verbose = TRUE, start = list( fixef = list( -9.28405,
> 2.81300, -4.75935, ?2.91080),
> + ST = list(0, 8.29931, 2.56368e-06, ?0.00000))
> + )
> Error: class(STnew[[i]]) == class(ST[[i]]) is not TRUE
> In addition: Warning message:
> In sort(names(start)) == sort(names(FL)) :
> ?longer object length is not a multiple of shorter object length
>
> A failed attempt to initialise both fixed and random parameters.
>
>
>> f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + (1|tree),
>> family = binomial,
> + ? ? ? ? ? ? ? verbose = TRUE, start = list( fixef = c( -9.28405, 2.81300,
> -4.75935, ?2.91080),
> + ST = c(0, 8.29931, 2.56368e-06, ?0.00000))
> + )
> Error: is.list(STnew) is not TRUE
> In addition: Warning message:
> In sort(names(start)) == sort(names(FL)) :
> ?longer object length is not a multiple of shorter object length
>
> Another failure.
>
>
>> initpar = c(0, 8.29931, 2.56368e-06, ?0.00000, -9.28405, ?2.81300,
>> -4.75935, ?2.91080)
>> f0128bit = lmer(fincr ~ icfac + (1|gap) + (1|box)+ (1|gap:box) + (1|tree),
>> family = binomial,
> + ? ? ? ? ? ? ? ? ?verbose = TRUE, start = initpar)
> ?0: ? ? 696.35176: ?1.15470 0.222222 0.182574 0.157135 -3.22238 1.44743
> -2.20257 ?1.02515
> ?1: ? ? 687.88422: 0.646498 0.349241 0.199295 0.375671 -4.02981 1.29061
> -2.23330 ?1.01588
> ?...
>
> ?26: ? ? 671.01076: ?0.00000 0.287718 0.350162 0.711060 -3.43482 1.45346
> -2.57397 0.293937
> ?27: ? ? 671.01076: ?0.00000 0.287721 0.350163 0.711061 -3.43482 1.45346
> -2.57398 0.293936
>
> Runs, but does not seem to use the supplied starting parameters.
>
> Thanks, for your comments.
>
> Murray
>
>
> On 18/05/2012 5:48 a.m., Douglas Bates wrote:
>>
>> Look at the values of the coefficients and standard deviations that
>> you are "converging" to. ?Your intercept is -9.28, which, with a
>> binomial family, corresponds to probabilities below 1e-4. ?With icfac
>> = fem the linear predictor is -9.28 - 4.76 = -14.04 corresponding to a
>> probability of 8e-07.
>>
>> You are going to need to look at the data and the proportions of
>> positives for different levels of icfac to see what would make sense.
>> This problem will create a very ill-defined likelihood surface because
>> the fitted values will lose sensitivity to the parameters when the
>> probabilities are so extreme. ?If you start extreme values you will
>> never be able to converge.
>>
>> On Thu, May 17, 2012 at 12:37 AM, Murray Jorgensen<maj at waikato.ac.nz>
>> ?wrote:
>>>
>>> PS ?I also tried
>>>
>>> start = list( fixef = c( -9.28405, ?2.81300, -4.75935, ?2.91080),
>>> ? ? ? ?ST = c(0, 8.29931, 2.56368e-06, ?0.00000))
>>>
>>> and
>>>
>>> start = list( fixef = list( -9.28405, ?2.81300, -4.75935, ?2.91080),
>>> ? ? ? ST = list(0, 8.29931, 2.56368e-06, ?0.00000))
>>>
>>> to no avail.
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Dr Murray Jorgensen ? ? ?http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz ? ? ?majmurr at gmail.com ? ? ? ? Fax 7 838 4155
>
> Phone ?+64 7 838 4773 wk ? ?Home +64 7 825 0441 ? Mobile 021 0200 8350


From jwiley.psych at gmail.com  Fri May 18 03:00:11 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 17 May 2012 18:00:11 -0700
Subject: [R-sig-ME] lmekin complains about dimnames
Message-ID: <CANz9Z_+FeY+aeAqS0i940YGthhTwXJfh+Z8eU9f01DpP0hOzog@mail.gmail.com>

Hi All,

I am trying to estimate disease heritability ultimately, but to get
started, I wanted to model a continuous outcome using lmekin().  I
tried something very similar (I think) to example 3 (GAW) of the
lmekin vignette from the coxme package
http://cran.r-project.org/web/packages/coxme/vignettes/lmekin.pdf

However, I get an error about the variance matrix not having dimnames.
 Although there does not seem to be data provided with the vignette, I
believe I should be essentially perfectly replicating the steps.  Any
ideas on what to do?  Below is made up data and an example along with
my session info.

Thanks!

Josh

################################################
require(kinship2)
adat <- data.frame(PersonID = 1:12,
  FatherID = c(NA, NA, NA, 1, 1, 1, 1, 4, 4, 4, 4, 4),
  MotherID = c(NA, NA, NA, 2, 2, 2, 2, 3, 3, 3, 3, 3),
  sex      = c(0,  1,  1,  0, 0, 1, 1, 0, 0, 0, 1, 1))
adat <- do.call("rbind", rep(list(adat), 100))
adat$FamilyID <- rep(1:100, each = 12)
set.seed(10)
adat$Outcome <- rnorm(nrow(adat), mean = adat$sex + rep(rnorm(100), each = 12))
gadat <- with(adat, pedigree(PersonID, FatherID, MotherID, sex, famid
= FamilyID))
## plot family structure (identical for all)
plot(gadat[1])
kamat <- kinship(gadat)
require(coxme)
(gfit1 <- lmekin(Outcome ~ factor(sex) + (1 | FamilyID), data=adat,
varlist=kamat))
# Error in bdsmatrix.reconcile(varlist, bname) :
#  No dimnames found on a variance matrix


Here is my sessionInfo():

R Under development (unstable) (2012-05-08 r59331)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] coxme_2.2-2      nlme_3.1-103     bdsmatrix_1.3    survival_2.36-14
[5] kinship2_1.3.3   quadprog_1.5-4   Matrix_1.0-6     lattice_0.20-6

loaded via a namespace (and not attached):
[1] compiler_2.16.0 grid_2.16.0     tools_2.16.0



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From David.Duffy at qimr.edu.au  Fri May 18 03:15:57 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 18 May 2012 11:15:57 +1000 (EST)
Subject: [R-sig-ME] Error in variance estimation using bivariate animal
	model
In-Reply-To: <201205151811.43325.chantepie@mnhn.fr>
References: <201205151811.43325.chantepie@mnhn.fr>
Message-ID: <Pine.LNX.4.64.1205181102280.31191@orpheus.qimr.edu.au>

On Tue, 15 May 2012, Stephane Chantepie wrote:

> I am using MCMCglmm function to construct bivariate animal models of 
> bustard sperm production according to age. Until six years old, each age 
> are considered as a trait. After 6 years old, age-class "7-8" and "9-11" 
> are computed to have enough information.

> In a second part, I have tried to estimate covariance between these 
> ages. And I have some problems in estimating variance-covariance for the 
> bivariate models which use the age class "7-8" or "9-11". For example, 
> when I compute the model cbind(age_1,age_9_11), the estimation of 
> variance for age_1 and age_9_11 are similar to estimations of the simple 
> animal models. The estimation of covariance also appears consistent with 
> the others covariance results, so it pretty good. But when I do 
> cbind(age_2,age_9_11), the variance estimation of age_9_11 become really 
> high (out of the range I have found in the simple model). So the 
> covariance estimation appears really high too. I do not really 
> understand why it works when I use age_1 against my age-class and not 
> when I use the age 2 3 4 5 6. The chains seem to converge and there is 
> no autocorrelation

I can only suggest checking the results against another package (given you 
are fitting LMMs). Are these large pedigrees?

> I have just added a ID random parameter when I use a age-class as one of
> bivariate trait (because I have repeated measures).

Is this needed, if you already have rcov=~us(trait):units ?

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From David.Duffy at qimr.edu.au  Fri May 18 04:09:08 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 18 May 2012 12:09:08 +1000 (EST)
Subject: [R-sig-ME] lmekin complains about dimnames
In-Reply-To: <CANz9Z_+FeY+aeAqS0i940YGthhTwXJfh+Z8eU9f01DpP0hOzog@mail.gmail.com>
References: <CANz9Z_+FeY+aeAqS0i940YGthhTwXJfh+Z8eU9f01DpP0hOzog@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1205181127170.31191@orpheus.qimr.edu.au>

On Thu, 17 May 2012, Joshua Wiley wrote:

> require(kinship2)
> gadat <- with(adat, pedigree(PersonID, FatherID, MotherID, sex,
                famid = FamilyID))
> kamat <- kinship(gadat)

> (gfit1 <- lmekin(Outcome ~ factor(sex) + (1 | FamilyID), data=adat,
> varlist=kamat))
> # Error in bdsmatrix.reconcile(varlist, bname) :
> #  No dimnames found on a variance matrix

kamat is a kinship matrix, so you need (1|id) rather than FamilyID.  But 
aside from that, there seems to be a problem in the new kinship, as it
only sets dimnames for the second dimension.  An ugly temporary solution 
is:

dimnames(kamat)[[1]] <-  dimnames(kamat)[[2]]

The second problem is that the individual IDs were non-unique. Since 
PersonIDs were non-unique, kinship generates a new ID, which is now needed 
to match up the correct kinship values

adat$gid <- paste(adat$FamilyID,adat$PersonID,sep="/")
lmekin(Outcome ~ factor(sex) + (1 | gid),
        data=adat,varlist=list(gid=kamat))


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From Mike.Lawrence at dal.ca  Fri May 18 15:02:48 2012
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 18 May 2012 10:02:48 -0300
Subject: [R-sig-ME] non-linear mixed effects model with binomial error
Message-ID: <CAB+QPJBoFr5a+Tx-Fqp4rtoCTKy2p8Mce75EgJ0OdBGAeSwYSQ@mail.gmail.com>

Hi folks,

This (http://stats.stackexchange.com/questions/24293) recent-ish post
to stats.stackexchange.com suggests that when it comes to tools
available in R, one cannot fit a non-linear mixed effects model with
binomial error. I just wanted to double check that this is an accurate
portrayal of the state of the aRt.

(In case it matters, I'm looking to follow up the answer to my
question here [http://stats.stackexchange.com/questions/22895])

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar: http://goo.gl/BYH99

~ Certainty is folly... I think. ~


From deter088 at umn.edu  Fri May 18 15:21:53 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 18 May 2012 08:21:53 -0500
Subject: [R-sig-ME] conflict of degrees of freedom or f value in lme
Message-ID: <CAOLJphmnv+Ww4eZSsjqMBvPbuS2dsEqXoGg6LrmRDbuXMMVrAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120518/6c4b64df/attachment.pl>

From jwiley.psych at gmail.com  Fri May 18 15:27:49 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 18 May 2012 06:27:49 -0700
Subject: [R-sig-ME] lmekin complains about dimnames
In-Reply-To: <Pine.LNX.4.64.1205181127170.31191@orpheus.qimr.edu.au>
References: <CANz9Z_+FeY+aeAqS0i940YGthhTwXJfh+Z8eU9f01DpP0hOzog@mail.gmail.com>
	<Pine.LNX.4.64.1205181127170.31191@orpheus.qimr.edu.au>
Message-ID: <CANz9Z_J55_DY541tifZ8AVjeDKyNR6N=MoStWGHkYVr-FUcxTA@mail.gmail.com>

Hi David,

I did not understand what the ID was at first, but I see now.  I also
heard offlist from Terry Therneau that he is looking into why the
kinship matrix is lacking dimnames.

Thanks for your help!

Josh


On Thu, May 17, 2012 at 7:09 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Thu, 17 May 2012, Joshua Wiley wrote:
>
>> require(kinship2)
>>
>> gadat <- with(adat, pedigree(PersonID, FatherID, MotherID, sex,
>
> ? ? ? ? ? ? ? famid = FamilyID))
>>
>> kamat <- kinship(gadat)
>
>
>> (gfit1 <- lmekin(Outcome ~ factor(sex) + (1 | FamilyID), data=adat,
>> varlist=kamat))
>> # Error in bdsmatrix.reconcile(varlist, bname) :
>> # ?No dimnames found on a variance matrix
>
>
> kamat is a kinship matrix, so you need (1|id) rather than FamilyID. ?But
> aside from that, there seems to be a problem in the new kinship, as it
> only sets dimnames for the second dimension. ?An ugly temporary solution is:
>
> dimnames(kamat)[[1]] <- ?dimnames(kamat)[[2]]
>
> The second problem is that the individual IDs were non-unique. Since
> PersonIDs were non-unique, kinship generates a new ID, which is now needed
> to match up the correct kinship values
>
> adat$gid <- paste(adat$FamilyID,adat$PersonID,sep="/")
> lmekin(Outcome ~ factor(sex) + (1 | gid),
> ? ? ? data=adat,varlist=list(gid=kamat))
>
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From kheise at uke.uni-hamburg.de  Fri May 18 15:13:04 2012
From: kheise at uke.uni-hamburg.de (Kirstin-Friederike Heise)
Date: Fri, 18 May 2012 15:13:04 +0200
Subject: [R-sig-ME] fitting model for repeated measures cross-over design?
Message-ID: <07302261-9F9C-4A12-9FA6-9834190332EE@uke.uni-hamburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120518/b38a4350/attachment.pl>

From annebj at gmail.com  Fri May 18 20:19:28 2012
From: annebj at gmail.com (Anne Bjorkman)
Date: Fri, 18 May 2012 11:19:28 -0700
Subject: [R-sig-ME] Very odd parameter estimates using GEE with AR-1
	correlation structure
Message-ID: <CAHem2OFgQ+FuF7U4aA5tc9PH2SexyykTY_EnBQjAD9Gk_qc45w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120518/3810b58b/attachment.pl>

From David.Costantini at glasgow.ac.uk  Sat May 19 11:16:15 2012
From: David.Costantini at glasgow.ac.uk (David Costantini)
Date: Sat, 19 May 2012 10:16:15 +0100
Subject: [R-sig-ME] help with MANOVE with mixed effects
Message-ID: <CD5460DE8502AF4C9DE3C5C037E7051E0462D9B5@exchange-be8.centre.ad.gla.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120519/bb1fd30d/attachment.pl>

From praguewatermelon at gmail.com  Sat May 19 16:27:40 2012
From: praguewatermelon at gmail.com (Xiao He)
Date: Sat, 19 May 2012 07:27:40 -0700
Subject: [R-sig-ME] Use LRT to assess the effect of lower order terms in the
 presence of a significant higher order term (e.g., interaction)
Message-ID: <CAGBzz=KKVw--yuLAbri69nKAMZ6vsgA6vcxW6QctKkVqSWfHfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120519/e13707e6/attachment.pl>

From torvon at gmail.com  Sun May 20 13:53:00 2012
From: torvon at gmail.com (Eiko Fried)
Date: Sun, 20 May 2012 13:53:00 +0200
Subject: [R-sig-ME] LME4: output interpretation of tricky model
Message-ID: <CACm_P7oX49zeD0qh02gbnbv-GHUQO=HNAXLmtB3ph3xZCAdWag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120520/094e95cc/attachment.pl>

From m.fairbrother at bristol.ac.uk  Sun May 20 17:49:25 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 20 May 2012 16:49:25 +0100
Subject: [R-sig-ME] error from clmm
Message-ID: <78678DB3-9021-44DE-899B-68D71E64E042@bristol.ac.uk>

Dear list,

I am making use of the "clmm" function from the "ordinal" package, for fitting mixed models with ordinal outcomes.

When fitting quite a few models, I get the error:

Error in if (maxGrad < rho$ctrl$gradTol) { : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In sqrt(phi2) : NaNs produced

Can anyone help me to understand why this may be happening, and/or whether there's anything obvious I should be doing different? With some seemingly small/arbitrary specification changes--or when taking (some) random subsets of my dataset--I don't get this message. But I'd like to find a way of reducing the frequency with which I do get it.

I don't think there's anything unusual about my call:

mod1 <- clmm(as.ordered(y) ~ x + (1 | fac1) + (1 | fac2), data=dat, link="logit", threshold="symmetric")

I'm running:
R version 2.15.0 (2012-03-30)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

Many thanks to anyone who can assist,

Malcolm


From cmgast at gmail.com  Sun May 20 23:12:27 2012
From: cmgast at gmail.com (Chris Gast)
Date: Sun, 20 May 2012 14:12:27 -0700
Subject: [R-sig-ME] Help with simple LME model specification in MCMCglmm
Message-ID: <CAPedOKgRDkWyUUcNpaQ7TbeeD5HH3q4ruzNsUiQBE8gFieGv9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120520/4ee73a7d/attachment.pl>

From cmgast at gmail.com  Mon May 21 00:08:09 2012
From: cmgast at gmail.com (Chris Gast)
Date: Sun, 20 May 2012 15:08:09 -0700
Subject: [R-sig-ME] Help with simple LME model specification in MCMCglmm
In-Reply-To: <CAPedOKgRDkWyUUcNpaQ7TbeeD5HH3q4ruzNsUiQBE8gFieGv9Q@mail.gmail.com>
References: <CAPedOKgRDkWyUUcNpaQ7TbeeD5HH3q4ruzNsUiQBE8gFieGv9Q@mail.gmail.com>
Message-ID: <CAPedOKiyM3t3RgYOvzDmTFrGKapb0G74aWPwSyz82Ma0GpUWAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120520/471350ba/attachment.pl>

From David.Duffy at qimr.edu.au  Mon May 21 01:08:41 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 21 May 2012 09:08:41 +1000 (EST)
Subject: [R-sig-ME] error from clmm
In-Reply-To: <78678DB3-9021-44DE-899B-68D71E64E042@bristol.ac.uk>
References: <78678DB3-9021-44DE-899B-68D71E64E042@bristol.ac.uk>
Message-ID: <Pine.LNX.4.64.1205210905001.1017@orpheus.qimr.edu.au>

On Sun, 20 May 2012, Malcolm Fairbrother wrote:

> Error in if (maxGrad < rho$ctrl$gradTol) { :
>  missing value where TRUE/FALSE needed
> In addition: Warning message:
> In sqrt(phi2) : NaNs produced
>
> Can anyone help me to understand why this may be happening, and/or 
> whether there's anything obvious I should be doing different? With some 
> seemingly small/arbitrary specification changes--or when taking (some) 
> random subsets of my dataset--I don't get this message. But I'd like to 
> find a way of reducing the frequency with which I do get it.

If you google "Error in if (maxGrad < rho$ctrl$gradTol)", you will find an 
email to the list from the package author in Oct 2011.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From David.Duffy at qimr.edu.au  Mon May 21 01:42:08 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 21 May 2012 09:42:08 +1000 (EST)
Subject: [R-sig-ME] Use LRT to assess the effect of lower order terms in
	the presence of a significant higher order term (e.g., interaction)
In-Reply-To: <CAGBzz=KKVw--yuLAbri69nKAMZ6vsgA6vcxW6QctKkVqSWfHfQ@mail.gmail.com>
References: <CAGBzz=KKVw--yuLAbri69nKAMZ6vsgA6vcxW6QctKkVqSWfHfQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1205210910500.1017@orpheus.qimr.edu.au>

On Sat, 19 May 2012, Xiao He wrote:

> I have a couple of questions regrading how to assess the effects of lower
> order terms when a higher order term is significant using likelihood ratio
> tests. I am interested to examine how two independent variables (iv1 and
> iv2) affect subjects' log-transformed reaction time (logRT).
>
> In a series of responses that Dr. Bates made in this thread:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/005399.html, he
> recommended that non-significant fixed effects be removed from a model
> before further llkelihood ratio tests.

[snip]

> #Models:
> #model.main: logRT ~ iv1 + iv2 + (1 + iv2 | subject) + (1 | item)
> #model.inter: logRT ~ iv1 * iv2 + (1 + iv2 | subject) + (1 | item)
> #            Df    AIC    BIC  logLik  Chisq Chi Df Pr(>Chisq)
> #model.main   8 236.31 271.43 -110.15
> #model.inter  9 229.10 268.61 -105.55 9.2097      1   0.002407 **
>
> (1). My first question is as follows:
>
> For example, in the case above, the interaction is shown as significant.  I
> know that when an interaction is present, main effects are often not
> interpretable, so probably that makes it unnecessary to even assess main
> effects? But say, if for whatever reason, I need to assess lower order
> terms - for example iv2, should I compare the first pair of models below,
> or the second pair of models below? It seems to me that comparing the 2nd
> pair makes more sense because the significant interaction probably
> shouldn't be removed from the model.
>
> First pair:
> model.main: logRT ~ iv1 + iv2 + (1 + iv2 | subject) + (1 | item)
> model.iv1:  logRT ~ iv1 + (1 + iv2 | subject) + (1 | item)
>
> Second pair
> model.main: logRT ~ iv1 + iv2 + iv1:iv2 (1 + iv2 | subject) + (1 | item)
> model:      logRT ~ iv1 + iv1:iv2 + (1 + iv2 | subject) + (1 | item)

Did you actually try the second one?

> (2). My second question has to do with random effect specification. As you
> can see, in all the models I showed above, I have iv2 as the random slope -
> which I decided based upon comparing models that have the same fixed
> effects ( iv1 * iv2) but have different nested random effect
> specifications. While including iv2 makes sense for models that have iv2 as
> a fixed effect (e.g., model.main, model.inter), its inclusion doesn't seem
> to make sense in models where iv2 is not included as a fixed effect - for
> example, the null model and model.iv1. However, it seems necessary to
> include it when I compare the models below. I wonder if someone can tell me
> what is the proper way of dealing with random effects in this kind of
> scenario and the reasons behind.
>
> model.main: logRT ~ iv1 + iv2 + (1 + iv2 | subject) + (1 | item)
> model.iv1:  logRT ~ iv1 + (1 + iv2 | subject) + (1 | item)

I think all this requires you to consult locally about your exact problem 
domain.  Would you expact iv1 and iv2 to interact?  Would you expect a 
subject specific slope on iv2?  If iv2, why not iv1?  If you choose a 
different transformation of RT, some of these complications might 
disappear, so that the interpretation will be cleaner.

If iv2 is a well known important covariate of RT from the literature *or* 
subject specific slopes are needed, iv2 should be in as a main effect. 
The next questions are whether you also need iv1 in the random effects 
part of the model (given you find an iv1:iv2 interaction), and whether you 
have enough data to support estimating all these effects.

Cheers, David Duffy,


From chris at trickysolutions.com.au  Mon May 21 01:47:01 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 21 May 2012 09:47:01 +1000
Subject: [R-sig-ME] Very odd parameter estimates using GEE with AR-1
 correlation structure
In-Reply-To: <CAHem2OFgQ+FuF7U4aA5tc9PH2SexyykTY_EnBQjAD9Gk_qc45w@mail.gmail.com>
References: <CAHem2OFgQ+FuF7U4aA5tc9PH2SexyykTY_EnBQjAD9Gk_qc45w@mail.gmail.com>
Message-ID: <1650010089452289106@unknownmsgid>

I can't comment much on GEE's but I believe u can use mixed models for
population inference, if correctly specified and interpreted.

I think when predicting though u need to use only the population level
parameters and not the resp level ones.

Others will know more about this than I and can likely comment or
suggest relevant papers.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 19/05/2012, at 4:22, Anne Bjorkman <annebj at gmail.com> wrote:

> Hello mixed modelers,
>
> I am having problems with some GEE models I am trying to run using geepack.
>
> I have species abundance data for 52 different species in 154 sites over 47
> years, and I am trying to extract slope parameter estimates so that I can
> look at whether these species have increased or decreased in abundance over
> time, while taking into account the repeated measurements at each site over
> time.  I originally started doing this with mixed models, but have been
> advised that GEE would be more appropriate for my data as it gives
> population-averaged responses.
>
> However, when I try to run GEE's on my data I get really bizarre parameter
> estimates for some of my species.  As my dataset is huge I unfortunately
> cannot provide the whole thing, but I have uploaded a subset of the data
> for one species with a particularly bizarre slope parameter estimate here:
> http://dl.dropbox.com/u/4481861/Example_for_GEE_one_species.csv
>
> The data look like this:
>
>  Site Year Species Value_Pres Value_Abs
> 1    1 1961       1          0            2089
> 2    1 1962       1          0            2120
> 3    1 1963       1          0            2089
> 4    1 1964       1          0            2225
> 5    1 1965       1          0            2197
> 6    1 1966       1          0            2208
>
> I have been using the following model specification (I have been running a
> loop to calculate estimates for all 52 species separately, but this is for
> just one species):
>
>
> speciesA<-orderBy(~Site+Year,data=speciesA) #using the doBy package to
> order by subject then time
>
>
> speciesA.mod<-geeglm(cbind(Value_Pres,Value_Abs)~I(Year-1961),data=speciesA,
> family=binomial,id=Site,corstr="ar1")
>
>
> Call:
>
> geeglm(formula = cbind(Value_Pres, Value_Abs) ~ I(Year - 1961),
>
>    family = binomial, data = speciesA, id = Site, corstr = "ar1")
>
>
> Coefficients:
>
>                Estimate   Std.err    Wald Pr(>|W|)
>
> (Intercept)    -2.99e+14  9.10e+11  107705   <2e-16 ***
>
> I(Year - 1961) -9.62e+13  3.88e+10 6155147   <2e-16 ***
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Estimated Scale Parameters:
>
>            Estimate  Std.err
>
> (Intercept) 6.57e+10 5.62e+30
>
>
> Correlation: Structure = ar1  Link = identity
>
>
> Estimated Correlation Parameters:
>
>      Estimate Std.err
>
> alpha     0.98 4.4e+18
>
> Number of clusters:   154   Maximum cluster size: 47
>
>
> I suspect the problem might have something to do with the correlation
> structure, as species abundances in subsequent years are often very highly
> correlated, even if there is substantial change over the 47 years overall.
> If I use the corstr="independence" command I get parameter estimate that
> are very similar to those I got using mixed effects models (at least, the
> slopes for species responses relative to each other are similar).
> Furthermore, if I use corstr="ar1" but subset my data to every 5 years
> instead of every year, I get much more reasonable slope estimates for this
> particular species as well as most of the other species (slope values are
> very similar to the corstr="independence" value), but a few different
> species' slopes then get very weird. (By get weird I mean that they have
> abnormally large positive or negative slopes that don't reflect what's
> happening in the raw data at all).
>
>
> I would really appreciate some insight into what the problem with my data
> could be, or, more particularly, how to fix it! My head and my wall would
> be very grateful! Perhaps I should just give up on GEE's and go back to
> mixed models??
>
>
> Thanks very much,
>
> Anne
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From David.Duffy at qimr.edu.au  Mon May 21 02:16:59 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 21 May 2012 10:16:59 +1000 (EST)
Subject: [R-sig-ME] help with MANOVE with mixed effects
In-Reply-To: <CD5460DE8502AF4C9DE3C5C037E7051E0462D9B5@exchange-be8.centre.ad.gla.ac.uk>
References: <CD5460DE8502AF4C9DE3C5C037E7051E0462D9B5@exchange-be8.centre.ad.gla.ac.uk>
Message-ID: <Pine.LNX.4.64.1205210942540.1017@orpheus.qimr.edu.au>

On Sat, 19 May 2012, David Costantini wrote:

> Dear All I wonder if anyone can help with this issue? I have two 
> fixed factors (experimental group and sex) and a random factor (brood). 
> I need the random factor to control for pseudoreplication because each 
> brood provides a certain number of siblings, which are 
> pseudoreplicates because share genes/environment. Then I have 8 
> variables. so I would like to to compare the covariance structures among 
> groups while controlling for the random factor. I was told that R might 
> do that, I mean a manova with mixed effects (manova(lme(....))

Not as easily as that ;) One can represent a multivariate model as a lmer 
or lme univariate model with appropriate random effects representing each 
item (there is recent query about this on the list).

MCMCglmm will fit as a multivariate model.

Or you can use structural equation modelling packages eg OpenMx.

Or you can go outside of R to other packages eg WOMBAT 
(http://didgeridoo.une.edu.au/km/wombat.php), MENDEL, ASReml...

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From David.Costantini at glasgow.ac.uk  Mon May 21 10:07:13 2012
From: David.Costantini at glasgow.ac.uk (David Costantini)
Date: Mon, 21 May 2012 09:07:13 +0100
Subject: [R-sig-ME] help with MANOVE with mixed effects
References: <CD5460DE8502AF4C9DE3C5C037E7051E0462D9B5@exchange-be8.centre.ad.gla.ac.uk>
	<Pine.LNX.4.64.1205210942540.1017@orpheus.qimr.edu.au>
Message-ID: <CD5460DE8502AF4C9DE3C5C037E7051E0462D9BA@exchange-be8.centre.ad.gla.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120521/32e3cc2e/attachment.pl>

From deter088 at umn.edu  Mon May 21 14:45:29 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 21 May 2012 07:45:29 -0500
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
Message-ID: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120521/b51d93dd/attachment.pl>

From jwiley.psych at gmail.com  Mon May 21 17:02:54 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 21 May 2012 08:02:54 -0700
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
Message-ID: <CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>

Hi Charles,

Out of curiosity, what is the log likelihood from SAS?  Does it match
that from lme()?

logLik(fit.13)

will give it to you.

Cheers,

Josh

On Mon, May 21, 2012 at 5:45 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Greetings R users,
>
>
> I am trying to match some SAS output of a mixed model. ?After running PROC
> MIXED with the covariance structure as AR1 the output below is given. ?Now
> when I try to replicate this with lme, I get the correct degrees of freedom
> and somewhat close values. ?If I try with gls, I get the exact F value but
> the incorrect denominator degrees of freedom. ?Is there some syntax or
> parameter I can adjust to get lme to have the same F values as gls? ?That
> way the correct degrees of freedom would be applied and I would get the
> replicated model. ?The data is also included below. ?Thanks to any who can
> help with this issue.
>
>
> Regards,
>
> Charles
>
>
> Row ? ID Group Died Event_name ? ? ?var
> 1 ? ?12510 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.05257
> 2 ? ?12510 ? ? 3 ?YES ? ? ? ?S45 ? ?-1.00000
> 3 ? ?12510 ? ? 3 ?YES ? ? ? ?FR2 ? -1.14630
> 4 ? ?12510 ? ? 3 ?YES ? ? ? ?FR8 ? -1.08831
> 5 ? ?12510 ? ? 3 ?YES ? ? ? FR20 ? -1.03339
> 6 ? ?21510 ? ? 3 ? NO ? ? ? ? ?B ? ? ?-0.87290
> 7 ? ?21510 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.22185
> 8 ? ?21510 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.01592
> 9 ? ?21510 ? ? 3 ? NO ? ? ? ?FR8 ? ?-1.06550
> 10 ? 21510 ? ? 3 ? NO ? ? ? PR48 ? ?-0.65326
> 11 ? 22210 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.37059
> 12 ? 30810 ? ? 3 ? NO ? ? ? ? ?B ? ? -0.92959
> 13 ? 30810 ? ? 3 ? NO ? ? ? ?S45 ? ?-1.26680
> 14 ? 30810 ? ? 3 ? NO ? ? ? ?FR2 ? ?-0.99396
> 15 ? 30810 ? ? 3 ? NO ? ? ? ?FR8 ? ?-1.04769
> 16 ? 30810 ? ? 3 ? NO ? ? ? FR20 ? ?-1.04769
> 17 ? 31510 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.50585
> 18 ? 31510 ? ? 4 ?YES ? ? ? ?S45 ? ?-1.35262
> 19 ? 31510 ? ? 4 ?YES ? ? ? ?FR2 ? -1.26520
> 20 ? 31510 ? ? 4 ?YES ? ? ? ?FR8 ? ?-1.11407
> 21 ? 31510 ? ? 4 ?YES ? ? ? FR20 ? ?-0.97757
> 22 ? 40510 ? ? 2 ?YES ? ? ? ? ?B ? ? ?-1.04721
> 23 ? 40510 ? ? 2 ?YES ? ? ? ?S45 ? ? -1.13371
> 24 ? 51010 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ?-1.21467
> 25 ? 51010 ? ? 3 ? NO ? ? ? ?S45 ? ? ?-1.18177
> 26 ? 51010 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.23582
> 27 ? 51010 ? ? 3 ? NO ? ? ? ?FR8 ? ? -1.35262
> 28 ? 51010 ? ? 3 ? NO ? ? ? FR20 ? ?-0.69897
> 29 ? 51010 ? ? 3 ? NO ? ? ? PR48 ? ?-1.14086
> 30 ? 51710 ? ? 4 ? NO ? ? ? ? ?B ? ? ?-1.13371
> 31 ? 51710 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.24336
> 32 ? 51710 ? ? 4 ? NO ? ? ? ?FR2 ? ? -0.85201
> 33 ? 51710 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.72700
> 34 ? 51710 ? ? 4 ? NO ? ? ? FR20 ? ? -0.71220
> 35 ? 51710 ? ? 4 ? NO ? ? ? PR48 ? ? -1.10735
> 36 ? 51809 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.70752
> 37 ? 51809 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.58120
> 38 ? 51809 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.71332
> 39 ? 51809 ? ? 1 ? NO ? ? ? FR20 ? ? -0.37212
> 40 ? 61410 ? ? 4 ? NO ? ? ? ? ?B ? ? -1.25493
> 41 ? 61410 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.24949
> 42 ? 61410 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.18310
> 43 ? 61410 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.87517
> 44 ? 61410 ? ? 4 ? NO ? ? ? FR20 ? ? -0.34679
> 45 ? 61410 ? ? 4 ? NO ? ? ? PR48 ? ? -0.76472
> 46 ? 62110 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.34199
> 47 ? 62110 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.23657
> 48 ? 62110 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.20412
> 49 ? 62110 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.72011
> 50 ? 62110 ? ? 3 ? NO ? ? ? FR20 ? ? -0.72308
> 51 ? 62110 ? ? 3 ? NO ? ? ? PR48 ? ? -0.89688
> 52 ? 62209 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -0.74041
> 53 ? 62209 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.99183
> 54 ? 62209 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.06854
> 55 ? 62209 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.94386
> 56 ? 62209 ? ? 3 ? NO ? ? ? FR20 ? ? -0.38817
> 57 ? 71210 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.23657
> 58 ? 71210 ? ? 4 ?YES ? ? ? ?S45 ? ? -0.94808
> 59 ? 71309 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.14630
> 60 ? 71309 ? ? 4 ?YES ? ? ? ?S45 ? ? -1.10568
> 61 ? 71309 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.94462
> 62 ? 71309 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.89211
> 63 ? 71309 ? ? 4 ?YES ? ? ? FR20 ? ? -0.98970
> 64 ? 71309 ? ? 4 ?YES ? ? ? PR48 ? ? -0.83387
> 65 ? 81009 ? ? 4 ?YES ? ? ? ? ?B ? ? ? ? -1.15989
> 66 ? 81009 ? ? 4 ?YES ? ? ? ?S45 ? ? -0.93779
> 67 ? 81009 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.86710
> 68 ? 81009 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.69379
> 69 ? 81610 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -1.04769
> 70 ? 81610 ? ? 1 ? NO ? ? ? ?S45 ? ? -1.02780
> 71 ? 81610 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.96098
> 72 ? 81610 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.91829
> 73 ? 81610 ? ? 1 ? NO ? ? ? FR20 ? ? -0.68550
> 74 ? 81610 ? ? 1 ? NO ? ? ? PR48 ? ? -0.66374
> 75 ? 81709 ? ? 4 ?YES ? ? ? ? ?B ? ?-0.65521
> 76 ? 82410 ? ? 3 ? NO ? ? ? ? ?B ? ? -1.06702
> 77 ? 82410 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.30103
> 78 ? 82410 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.96617
> 79 ? 82410 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.84497
> 80 ? 82410 ? ? 3 ? NO ? ? ? FR20 ? ? -0.47716
> 81 ? 82410 ? ? 3 ? NO ? ? ? PR48 ? ? -0.68131
> 82 ? 91310 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.30803
> 83 ? 91310 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.07212
> 84 ? 91310 ? ? 4 ? NO ? ? ? ?FR2 ? ? -0.94615
> 85 ? 91310 ? ? 4 ? NO ? ? ? ?FR8 ? ? -1.29414
> 86 ? 91310 ? ? 4 ? NO ? ? ? FR20 ? ? -0.81304
> 87 ? 91310 ? ? 4 ? NO ? ? ? PR48 ? ? -0.86519
> 88 ? 91409 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.12321
> 89 ? 91409 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.08831
> 90 ? 91409 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.11862
> 91 ? 91409 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.87976
> 92 ? 91409 ? ? 4 ? NO ? ? ? FR20 ? ? -0.87517
> 93 ? 91409 ? ? 4 ? NO ? ? ? PR48 ? ? -0.68867
> 94 ? 92109 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.15120
> 95 ? 92109 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.99525
> 96 ? 92109 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.95429
> 97 ? 92109 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.54914
> 98 ? 92109 ? ? 3 ? NO ? ? ? FR20 ? ? -0.67264
> 99 ? 92109 ? ? 3 ? NO ? ? ? PR48 ? ? -0.74256
> 100 ?92110 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.05012
> 101 ?92110 ? ? 4 ?YES ? ? ? ?S45 ? ? -1.14086
> 102 ?92110 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.91901
> 103 ?92110 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.80521
> 104 ?92110 ? ? 4 ?YES ? ? ? FR20 ? ? -0.88807
> 105 ?92710 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.20412
> 106 ?92710 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.21325
> 107 ?92710 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.19518
> 108 ?92710 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.92959
> 109 ?92710 ? ? 4 ? NO ? ? ? FR20 ? ? -0.69315
> 110 ?92710 ? ? 4 ? NO ? ? ? PR48 ? ? -0.73779
> 111 100410 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.92300
> 112 100410 ? ? 1 ? NO ? ? ? ?S45 ? ? -1.07314
> 113 100410 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.80162
> 114 100410 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.63283
> 115 100410 ? ? 1 ? NO ? ? ? FR20 ? ? -0.73119
> 116 100410 ? ? 1 ? NO ? ? ? PR48 ? ? ?0.10102
> 117 101209 ? ? 3 ? NO ? ? ? ? ?B ? ? -1.24718
> 118 101209 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.00524
> 119 101209 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.01592
> 120 101209 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.85201
> 121 101209 ? ? 3 ? NO ? ? ? FR20 ? ? -0.51670
> 122 101209 ? ? 3 ? NO ? ? ? PR48 ? ? -0.72239
> 123 101909 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.13549
> 124 101909 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.92665
> 125 101909 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.98548
> 126 101909 ? ? 3 ? NO ? ? ? ?FR8 ? ? -1.03152
> 127 101909 ? ? 3 ? NO ? ? ? FR20 ? ? -0.71715
> 128 101909 ? ? 3 ? NO ? ? ? PR48 ? ? -1.07935
> 129 102510 ? ? 2 ?YES ? ? ? ? ?B ? ? ? ? -1.30103
> 130 102510 ? ? 2 ?YES ? ? ? ?S45 ? ? -0.83387
> 131 110810 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.21968
> 132 110810 ? ? 3 ?YES ? ? ? ?S45 ? ? -0.68048
> 133 110810 ? ? 3 ?YES ? ? ? ?FR2 ? ? -1.09474
> 134 110909 ? ? 2 ?YES ? ? ? ? ?B ? ? ? ? -1.09259
> 135 110909 ? ? 2 ?YES ? ? ? ?S45 ? ? -0.91293
> 136 111510 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.39794
> 137 111510 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.42366
> 138 111510 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.22621
> 139 111510 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.98885
> 140 111510 ? ? 3 ? NO ? ? ? FR20 ? ? -0.66055
> 141 111510 ? ? 3 ? NO ? ? ? PR48 ? ? -0.84497
> 142 111609 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.79942
> 143 111609 ? ? 1 ? NO ? ? ? ?S45 ? ? -0.87517
> 144 111609 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.74041
> 145 111609 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.64092
> 146 111609 ? ? 1 ? NO ? ? ? FR20 ? ? -0.53835
> 147 111609 ? ? 1 ? NO ? ? ? PR48 ? ? -0.68719
> 148 120610 ? ? 4 ? NO ? ? ? ? ?B ? ? -1.05110
> 149 120610 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.45100
> 150 120610 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.21183
> 151 120610 ? ? 4 ? NO ? ? ? ?FR8 ? ? -1.04144
> 152 120610 ? ? 4 ? NO ? ? ? FR20 ? ? -0.61101
> 153 120610 ? ? 4 ? NO ? ? ? PR48 ? ? -0.81702
> 154 120709 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.84497
> 155 120709 ? ? 1 ? NO ? ? ? ?S45 ? ? -0.99439
> 156 120709 ? ? 1 ? NO ? ? ? ?FR2 ? ? -1.13430
> 157 120709 ? ? 1 ? NO ? ? ? FR20 ? ? -0.57187
> 158 120709 ? ? 1 ? NO ? ? ? PR48 ? ? -0.80632
> 159 121310 ? ? 3 ?YES ? ? ? ? ?B ? ? ? ? -1.16115
> 160 121310 ? ? 3 ?YES ? ? ? ?S45 ? ? -1.18310
>
> dat=read.table("C:/?/subset.csv",sep=",",header=TRUE, na.strings=".")
>
> attach(dat)
>
>
>
> dat34=dat[Pig_group %in% c("3", "4"),]
>
> attach(dat34)
>
> dat34=within(dat34, {
>
> ? ? ? ? ? ? ? ? ? ?group=factor(group)
>
> ? ? ? ? ? ? ? ? ? ?Event_name=factor(Event_name)
>
> ? ? ? ? ? ? ? ? ? ?Died=factor(Died)
>
> ? ? ? ? ? ? ? ? ? ?ID=factor(ID)
>
> })
>
> attach(dat34)
>
>
>
> contrasts(dat34$Event_name)=contr.sum(n=6)
>
> contrasts(dat34$group)=contr.sum(n=2)
>
> contrasts(dat34$Died)=contr.sum(n=2)
>
>
> ?# What the results should be from SAS AR1 var
> #Type 3 Tests of Fixed Effects
> #Effect ? ? ? ? ?NumDF DenDF F Value Pr > F
> #Event_name ? ? ?5 ? 91 ? ?7.43 ? ?<.0001
> #Died ? ? ? ? ? ? ?1 ? 24 ? ?0.08 ? ?0.7756
> #Event_name*Died 5 ? 91 ? ?3.09 ? ?0.0128
>
> fit.13=lme(var~Event_name*Died,
> ? ?data=liver34,
> ? ?random=~1|ID,
> ? ?corr=corAR1())
> anova(fit.13, type="marginal", adjustSigma=F)
> # ? ? ? ? ? ? ? ? ? ?numDF denDF ? F-value p-value
> #(Intercept) ? ? ? ? ? ? 1 ? ?91 1342.7364 ?<.0001
> #Event_name ? ? ? ? ?5 ? ?91 ? ?8.7143 ?<.0001
> #Died ? ? ? ? ? ? ? ? ? ?1 ? ?24 ? ?0.0527 ?0.8204
> #Event_name:Died ? ? 5 ? ?91 ? ?3.0909 ?0.0127
>
> ######################################################
> ###THIS DOES IT but not lme function (need dfs)
> fit.16=gls(var~Event_name*Died,
> ? ?data=liver34,
> ? ?corr=corAR1(, ~1|ID))
> anova(fit.16, type="marginal", adjustSigma=F)
> #Denom. DF: 115
> # ? ? ? ? ? ? ? ? ? ?numDF ? F-value p-value
> #(Intercept) ? ? ? ? ? ? 1 1496.9032 ?<.0001
> #Event_name ? ? ? ? ?5 ? ?7.4304 ?<.0001
> #Died ? ? ? ? ? ? ? ? ? ?1 ? ?0.0831 ?0.7736
> #Event_name:Died ? ? 5 ? ?3.0871 ?0.0119
>
> ?#Give exact replicated answers
> 1-pf(7.4304, 5, 91)
> 1-pf(.0831, 1, 24)
> 1-pf(3.0871, 5, 91)
> #######################################################
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/

From deter088 at umn.edu  Mon May 21 18:16:10 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 21 May 2012 11:16:10 -0500
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
Message-ID: <CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120521/44db7e0e/attachment.pl>

From bates at stat.wisc.edu  Mon May 21 19:22:25 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 21 May 2012 12:22:25 -0500
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
	<CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
Message-ID: <CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>

I don't really think there is a way of defining the degrees of freedom
for all lme and gls model fits so that they correspond to the
"correct" values, which often seems to mean the values returned by
SAS.  If you feel that SAS provides the correct analysis in all cases
then you should use SAS.  We can't reproduce the SAS results in R
because SAS is proprietary code and we don't know how those results
are calculated.

The whole question of degrees of freedom for certain tests is very
complicated.  Often there is no answer because the distribution of the
test statistic is not a t or an F distribution.

On Mon, May 21, 2012 at 11:16 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Thank you for giving this some thought Joshua. ?I will be sure to keep
> troubleshooting this as well. ?Would it be related to how gls calculates
> its values that is somehow reports the 'correct' F value perhaps?
>
> Regards,
> Charles
>
> On Mon, May 21, 2012 at 11:08 AM, Joshua Wiley <jwiley.psych at gmail.com>wrote:
>
>> That suggests they are fitting different models somehow (not just that
>> the specifc effect estimates are different). ?No brilliant ideas on in
>> what way though...
>>
>> I checked REML versus ML but that was not it. ?I'll let you know if I
>> have any ideas.
>>
>> Cheers,
>>
>> Josh
>>
>> On Mon, May 21, 2012 at 9:02 AM, Charles Determan Jr <deter088 at umn.edu>
>> wrote:
>> > Hi Joshua,
>> >
>> > The -2 Log-likelihood from SAS is -58.6
>> > The log-likelihood from R fit.13 is 21.9. ?I assume this would be
>> multiplied
>> > by -2 which would give -43.8.
>> >
>> > Regards,
>> > Charles
>> >
>> >
>> > On Mon, May 21, 2012 at 10:02 AM, Joshua Wiley <jwiley.psych at gmail.com>
>> > wrote:
>> >>
>> >> Hi Charles,
>> >>
>> >> Out of curiosity, what is the log likelihood from SAS? ?Does it match
>> >> that from lme()?
>> >>
>> >> logLik(fit.13)
>> >>
>> >> will give it to you.
>> >>
>> >> Cheers,
>> >>
>> >> Josh
>> >>
>> >> On Mon, May 21, 2012 at 5:45 AM, Charles Determan Jr <deter088 at umn.edu>
>> >> wrote:
>> >> > Greetings R users,
>> >> >
>> >> >
>> >> > I am trying to match some SAS output of a mixed model. ?After running
>> >> > PROC
>> >> > MIXED with the covariance structure as AR1 the output below is given.
>> >> > ?Now
>> >> > when I try to replicate this with lme, I get the correct degrees of
>> >> > freedom
>> >> > and somewhat close values. ?If I try with gls, I get the exact F value
>> >> > but
>> >> > the incorrect denominator degrees of freedom. ?Is there some syntax or
>> >> > parameter I can adjust to get lme to have the same F values as gls?
>> >> > ?That
>> >> > way the correct degrees of freedom would be applied and I would get
>> the
>> >> > replicated model. ?The data is also included below. ?Thanks to any who
>> >> > can
>> >> > help with this issue.
>> >> >
>> >> >
>> >> > Regards,
>> >> >
>> >> > Charles
>> >> >
>> >> >
>> >> > Row ? ID Group Died Event_name ? ? ?var
>> >> > 1 ? ?12510 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.05257
>> >> > 2 ? ?12510 ? ? 3 ?YES ? ? ? ?S45 ? ?-1.00000
>> >> > 3 ? ?12510 ? ? 3 ?YES ? ? ? ?FR2 ? -1.14630
>> >> > 4 ? ?12510 ? ? 3 ?YES ? ? ? ?FR8 ? -1.08831
>> >> > 5 ? ?12510 ? ? 3 ?YES ? ? ? FR20 ? -1.03339
>> >> > 6 ? ?21510 ? ? 3 ? NO ? ? ? ? ?B ? ? ?-0.87290
>> >> > 7 ? ?21510 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.22185
>> >> > 8 ? ?21510 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.01592
>> >> > 9 ? ?21510 ? ? 3 ? NO ? ? ? ?FR8 ? ?-1.06550
>> >> > 10 ? 21510 ? ? 3 ? NO ? ? ? PR48 ? ?-0.65326
>> >> > 11 ? 22210 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.37059
>> >> > 12 ? 30810 ? ? 3 ? NO ? ? ? ? ?B ? ? -0.92959
>> >> > 13 ? 30810 ? ? 3 ? NO ? ? ? ?S45 ? ?-1.26680
>> >> > 14 ? 30810 ? ? 3 ? NO ? ? ? ?FR2 ? ?-0.99396
>> >> > 15 ? 30810 ? ? 3 ? NO ? ? ? ?FR8 ? ?-1.04769
>> >> > 16 ? 30810 ? ? 3 ? NO ? ? ? FR20 ? ?-1.04769
>> >> > 17 ? 31510 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.50585
>> >> > 18 ? 31510 ? ? 4 ?YES ? ? ? ?S45 ? ?-1.35262
>> >> > 19 ? 31510 ? ? 4 ?YES ? ? ? ?FR2 ? -1.26520
>> >> > 20 ? 31510 ? ? 4 ?YES ? ? ? ?FR8 ? ?-1.11407
>> >> > 21 ? 31510 ? ? 4 ?YES ? ? ? FR20 ? ?-0.97757
>> >> > 22 ? 40510 ? ? 2 ?YES ? ? ? ? ?B ? ? ?-1.04721
>> >> > 23 ? 40510 ? ? 2 ?YES ? ? ? ?S45 ? ? -1.13371
>> >> > 24 ? 51010 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ?-1.21467
>> >> > 25 ? 51010 ? ? 3 ? NO ? ? ? ?S45 ? ? ?-1.18177
>> >> > 26 ? 51010 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.23582
>> >> > 27 ? 51010 ? ? 3 ? NO ? ? ? ?FR8 ? ? -1.35262
>> >> > 28 ? 51010 ? ? 3 ? NO ? ? ? FR20 ? ?-0.69897
>> >> > 29 ? 51010 ? ? 3 ? NO ? ? ? PR48 ? ?-1.14086
>> >> > 30 ? 51710 ? ? 4 ? NO ? ? ? ? ?B ? ? ?-1.13371
>> >> > 31 ? 51710 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.24336
>> >> > 32 ? 51710 ? ? 4 ? NO ? ? ? ?FR2 ? ? -0.85201
>> >> > 33 ? 51710 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.72700
>> >> > 34 ? 51710 ? ? 4 ? NO ? ? ? FR20 ? ? -0.71220
>> >> > 35 ? 51710 ? ? 4 ? NO ? ? ? PR48 ? ? -1.10735
>> >> > 36 ? 51809 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.70752
>> >> > 37 ? 51809 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.58120
>> >> > 38 ? 51809 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.71332
>> >> > 39 ? 51809 ? ? 1 ? NO ? ? ? FR20 ? ? -0.37212
>> >> > 40 ? 61410 ? ? 4 ? NO ? ? ? ? ?B ? ? -1.25493
>> >> > 41 ? 61410 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.24949
>> >> > 42 ? 61410 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.18310
>> >> > 43 ? 61410 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.87517
>> >> > 44 ? 61410 ? ? 4 ? NO ? ? ? FR20 ? ? -0.34679
>> >> > 45 ? 61410 ? ? 4 ? NO ? ? ? PR48 ? ? -0.76472
>> >> > 46 ? 62110 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.34199
>> >> > 47 ? 62110 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.23657
>> >> > 48 ? 62110 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.20412
>> >> > 49 ? 62110 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.72011
>> >> > 50 ? 62110 ? ? 3 ? NO ? ? ? FR20 ? ? -0.72308
>> >> > 51 ? 62110 ? ? 3 ? NO ? ? ? PR48 ? ? -0.89688
>> >> > 52 ? 62209 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -0.74041
>> >> > 53 ? 62209 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.99183
>> >> > 54 ? 62209 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.06854
>> >> > 55 ? 62209 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.94386
>> >> > 56 ? 62209 ? ? 3 ? NO ? ? ? FR20 ? ? -0.38817
>> >> > 57 ? 71210 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.23657
>> >> > 58 ? 71210 ? ? 4 ?YES ? ? ? ?S45 ? ? -0.94808
>> >> > 59 ? 71309 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.14630
>> >> > 60 ? 71309 ? ? 4 ?YES ? ? ? ?S45 ? ? -1.10568
>> >> > 61 ? 71309 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.94462
>> >> > 62 ? 71309 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.89211
>> >> > 63 ? 71309 ? ? 4 ?YES ? ? ? FR20 ? ? -0.98970
>> >> > 64 ? 71309 ? ? 4 ?YES ? ? ? PR48 ? ? -0.83387
>> >> > 65 ? 81009 ? ? 4 ?YES ? ? ? ? ?B ? ? ? ? -1.15989
>> >> > 66 ? 81009 ? ? 4 ?YES ? ? ? ?S45 ? ? -0.93779
>> >> > 67 ? 81009 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.86710
>> >> > 68 ? 81009 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.69379
>> >> > 69 ? 81610 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -1.04769
>> >> > 70 ? 81610 ? ? 1 ? NO ? ? ? ?S45 ? ? -1.02780
>> >> > 71 ? 81610 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.96098
>> >> > 72 ? 81610 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.91829
>> >> > 73 ? 81610 ? ? 1 ? NO ? ? ? FR20 ? ? -0.68550
>> >> > 74 ? 81610 ? ? 1 ? NO ? ? ? PR48 ? ? -0.66374
>> >> > 75 ? 81709 ? ? 4 ?YES ? ? ? ? ?B ? ?-0.65521
>> >> > 76 ? 82410 ? ? 3 ? NO ? ? ? ? ?B ? ? -1.06702
>> >> > 77 ? 82410 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.30103
>> >> > 78 ? 82410 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.96617
>> >> > 79 ? 82410 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.84497
>> >> > 80 ? 82410 ? ? 3 ? NO ? ? ? FR20 ? ? -0.47716
>> >> > 81 ? 82410 ? ? 3 ? NO ? ? ? PR48 ? ? -0.68131
>> >> > 82 ? 91310 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.30803
>> >> > 83 ? 91310 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.07212
>> >> > 84 ? 91310 ? ? 4 ? NO ? ? ? ?FR2 ? ? -0.94615
>> >> > 85 ? 91310 ? ? 4 ? NO ? ? ? ?FR8 ? ? -1.29414
>> >> > 86 ? 91310 ? ? 4 ? NO ? ? ? FR20 ? ? -0.81304
>> >> > 87 ? 91310 ? ? 4 ? NO ? ? ? PR48 ? ? -0.86519
>> >> > 88 ? 91409 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.12321
>> >> > 89 ? 91409 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.08831
>> >> > 90 ? 91409 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.11862
>> >> > 91 ? 91409 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.87976
>> >> > 92 ? 91409 ? ? 4 ? NO ? ? ? FR20 ? ? -0.87517
>> >> > 93 ? 91409 ? ? 4 ? NO ? ? ? PR48 ? ? -0.68867
>> >> > 94 ? 92109 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.15120
>> >> > 95 ? 92109 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.99525
>> >> > 96 ? 92109 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.95429
>> >> > 97 ? 92109 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.54914
>> >> > 98 ? 92109 ? ? 3 ? NO ? ? ? FR20 ? ? -0.67264
>> >> > 99 ? 92109 ? ? 3 ? NO ? ? ? PR48 ? ? -0.74256
>> >> > 100 ?92110 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.05012
>> >> > 101 ?92110 ? ? 4 ?YES ? ? ? ?S45 ? ? -1.14086
>> >> > 102 ?92110 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.91901
>> >> > 103 ?92110 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.80521
>> >> > 104 ?92110 ? ? 4 ?YES ? ? ? FR20 ? ? -0.88807
>> >> > 105 ?92710 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.20412
>> >> > 106 ?92710 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.21325
>> >> > 107 ?92710 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.19518
>> >> > 108 ?92710 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.92959
>> >> > 109 ?92710 ? ? 4 ? NO ? ? ? FR20 ? ? -0.69315
>> >> > 110 ?92710 ? ? 4 ? NO ? ? ? PR48 ? ? -0.73779
>> >> > 111 100410 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.92300
>> >> > 112 100410 ? ? 1 ? NO ? ? ? ?S45 ? ? -1.07314
>> >> > 113 100410 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.80162
>> >> > 114 100410 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.63283
>> >> > 115 100410 ? ? 1 ? NO ? ? ? FR20 ? ? -0.73119
>> >> > 116 100410 ? ? 1 ? NO ? ? ? PR48 ? ? ?0.10102
>> >> > 117 101209 ? ? 3 ? NO ? ? ? ? ?B ? ? -1.24718
>> >> > 118 101209 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.00524
>> >> > 119 101209 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.01592
>> >> > 120 101209 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.85201
>> >> > 121 101209 ? ? 3 ? NO ? ? ? FR20 ? ? -0.51670
>> >> > 122 101209 ? ? 3 ? NO ? ? ? PR48 ? ? -0.72239
>> >> > 123 101909 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.13549
>> >> > 124 101909 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.92665
>> >> > 125 101909 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.98548
>> >> > 126 101909 ? ? 3 ? NO ? ? ? ?FR8 ? ? -1.03152
>> >> > 127 101909 ? ? 3 ? NO ? ? ? FR20 ? ? -0.71715
>> >> > 128 101909 ? ? 3 ? NO ? ? ? PR48 ? ? -1.07935
>> >> > 129 102510 ? ? 2 ?YES ? ? ? ? ?B ? ? ? ? -1.30103
>> >> > 130 102510 ? ? 2 ?YES ? ? ? ?S45 ? ? -0.83387
>> >> > 131 110810 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.21968
>> >> > 132 110810 ? ? 3 ?YES ? ? ? ?S45 ? ? -0.68048
>> >> > 133 110810 ? ? 3 ?YES ? ? ? ?FR2 ? ? -1.09474
>> >> > 134 110909 ? ? 2 ?YES ? ? ? ? ?B ? ? ? ? -1.09259
>> >> > 135 110909 ? ? 2 ?YES ? ? ? ?S45 ? ? -0.91293
>> >> > 136 111510 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.39794
>> >> > 137 111510 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.42366
>> >> > 138 111510 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.22621
>> >> > 139 111510 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.98885
>> >> > 140 111510 ? ? 3 ? NO ? ? ? FR20 ? ? -0.66055
>> >> > 141 111510 ? ? 3 ? NO ? ? ? PR48 ? ? -0.84497
>> >> > 142 111609 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.79942
>> >> > 143 111609 ? ? 1 ? NO ? ? ? ?S45 ? ? -0.87517
>> >> > 144 111609 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.74041
>> >> > 145 111609 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.64092
>> >> > 146 111609 ? ? 1 ? NO ? ? ? FR20 ? ? -0.53835
>> >> > 147 111609 ? ? 1 ? NO ? ? ? PR48 ? ? -0.68719
>> >> > 148 120610 ? ? 4 ? NO ? ? ? ? ?B ? ? -1.05110
>> >> > 149 120610 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.45100
>> >> > 150 120610 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.21183
>> >> > 151 120610 ? ? 4 ? NO ? ? ? ?FR8 ? ? -1.04144
>> >> > 152 120610 ? ? 4 ? NO ? ? ? FR20 ? ? -0.61101
>> >> > 153 120610 ? ? 4 ? NO ? ? ? PR48 ? ? -0.81702
>> >> > 154 120709 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.84497
>> >> > 155 120709 ? ? 1 ? NO ? ? ? ?S45 ? ? -0.99439
>> >> > 156 120709 ? ? 1 ? NO ? ? ? ?FR2 ? ? -1.13430
>> >> > 157 120709 ? ? 1 ? NO ? ? ? FR20 ? ? -0.57187
>> >> > 158 120709 ? ? 1 ? NO ? ? ? PR48 ? ? -0.80632
>> >> > 159 121310 ? ? 3 ?YES ? ? ? ? ?B ? ? ? ? -1.16115
>> >> > 160 121310 ? ? 3 ?YES ? ? ? ?S45 ? ? -1.18310
>> >> >
>> >> > dat=read.table("C:/?/subset.csv",sep=",",header=TRUE, na.strings=".")
>> >> >
>> >> > attach(dat)
>> >> >
>> >> >
>> >> >
>> >> > dat34=dat[Pig_group %in% c("3", "4"),]
>> >> >
>> >> > attach(dat34)
>> >> >
>> >> > dat34=within(dat34, {
>> >> >
>> >> > ? ? ? ? ? ? ? ? ? ?group=factor(group)
>> >> >
>> >> > ? ? ? ? ? ? ? ? ? ?Event_name=factor(Event_name)
>> >> >
>> >> > ? ? ? ? ? ? ? ? ? ?Died=factor(Died)
>> >> >
>> >> > ? ? ? ? ? ? ? ? ? ?ID=factor(ID)
>> >> >
>> >> > })
>> >> >
>> >> > attach(dat34)
>> >> >
>> >> >
>> >> >
>> >> > contrasts(dat34$Event_name)=contr.sum(n=6)
>> >> >
>> >> > contrasts(dat34$group)=contr.sum(n=2)
>> >> >
>> >> > contrasts(dat34$Died)=contr.sum(n=2)
>> >> >
>> >> >
>> >> > ?# What the results should be from SAS AR1 var
>> >> > #Type 3 Tests of Fixed Effects
>> >> > #Effect ? ? ? ? ?NumDF DenDF F Value Pr > F
>> >> > #Event_name ? ? ?5 ? 91 ? ?7.43 ? ?<.0001
>> >> > #Died ? ? ? ? ? ? ?1 ? 24 ? ?0.08 ? ?0.7756
>> >> > #Event_name*Died 5 ? 91 ? ?3.09 ? ?0.0128
>> >> >
>> >> > fit.13=lme(var~Event_name*Died,
>> >> > ? ?data=liver34,
>> >> > ? ?random=~1|ID,
>> >> > ? ?corr=corAR1())
>> >> > anova(fit.13, type="marginal", adjustSigma=F)
>> >> > # ? ? ? ? ? ? ? ? ? ?numDF denDF ? F-value p-value
>> >> > #(Intercept) ? ? ? ? ? ? 1 ? ?91 1342.7364 ?<.0001
>> >> > #Event_name ? ? ? ? ?5 ? ?91 ? ?8.7143 ?<.0001
>> >> > #Died ? ? ? ? ? ? ? ? ? ?1 ? ?24 ? ?0.0527 ?0.8204
>> >> > #Event_name:Died ? ? 5 ? ?91 ? ?3.0909 ?0.0127
>> >> >
>> >> > ######################################################
>> >> > ###THIS DOES IT but not lme function (need dfs)
>> >> > fit.16=gls(var~Event_name*Died,
>> >> > ? ?data=liver34,
>> >> > ? ?corr=corAR1(, ~1|ID))
>> >> > anova(fit.16, type="marginal", adjustSigma=F)
>> >> > #Denom. DF: 115
>> >> > # ? ? ? ? ? ? ? ? ? ?numDF ? F-value p-value
>> >> > #(Intercept) ? ? ? ? ? ? 1 1496.9032 ?<.0001
>> >> > #Event_name ? ? ? ? ?5 ? ?7.4304 ?<.0001
>> >> > #Died ? ? ? ? ? ? ? ? ? ?1 ? ?0.0831 ?0.7736
>> >> > #Event_name:Died ? ? 5 ? ?3.0871 ?0.0119
>> >> >
>> >> > ?#Give exact replicated answers
>> >> > 1-pf(7.4304, 5, 91)
>> >> > 1-pf(.0831, 1, 24)
>> >> > 1-pf(3.0871, 5, 91)
>> >> > #######################################################
>> >> >
>> >> > ? ? ? ?[[alternative HTML version deleted]]
>> >> >
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-mixed-models at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >> Joshua Wiley
>> >> Ph.D. Student, Health Psychology
>> >> Programmer Analyst II, Statistical Consulting Group
>> >> University of California, Los Angeles
>> >> https://joshuawiley.com/
>> >
>> >
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From deter088 at umn.edu  Mon May 21 21:09:31 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 21 May 2012 14:09:31 -0500
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
	<CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
	<CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
Message-ID: <CAOLJph==vUPu=Jd2TZVuynZZSor3_EAZvfnfb67zaZByeH5n1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120521/60909408/attachment.pl>

From annebj at gmail.com  Tue May 22 02:30:06 2012
From: annebj at gmail.com (Anne Bjorkman)
Date: Mon, 21 May 2012 17:30:06 -0700
Subject: [R-sig-ME] Very odd parameter estimates using GEE with AR-1
 correlation structure
In-Reply-To: <1650010089452289106@unknownmsgid>
References: <CAHem2OFgQ+FuF7U4aA5tc9PH2SexyykTY_EnBQjAD9Gk_qc45w@mail.gmail.com>
	<1650010089452289106@unknownmsgid>
Message-ID: <CAHem2OHVL1SxB8B7cwmiuLdqHUCzCgO7KwFstu=3HK-DiixMXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120521/cdd745c1/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Tue May 22 03:07:22 2012
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 22 May 2012 11:07:22 +1000
Subject: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer -
 justified to run a glm instead?
Message-ID: <CAOCHjhTanwXyPt4oXRdiLsWgsxOujd+cw30p9T5q-+BA8figLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/067c9d45/attachment.pl>

From smartpink111 at yahoo.com  Tue May 22 03:12:45 2012
From: smartpink111 at yahoo.com (arun)
Date: Mon, 21 May 2012 18:12:45 -0700 (PDT)
Subject: [R-sig-ME] [R] Random effect in an Incomplete block design
In-Reply-To: <1337632578.68726.YahooMailNeo@web36207.mail.mud.yahoo.com>
References: <1337632578.68726.YahooMailNeo@web36207.mail.mud.yahoo.com>
Message-ID: <1337649165.48565.YahooMailNeo@web39406.mail.mud.yahoo.com>

HI Reza,

This should be forwarded to r mixed group.

I would use lme4 package.
Regarding the factors nested within replicates is a bit confusing.? It is normally the other way around.? Also, I have doubts in the model statement with year*factors included as fixed effects, because you mentioned it as random.? I may be wrong.? I hope some expert from the mixed group will respond to this problem.

A.K.





----- Original Message -----
From: Reza Deihimfard <deihim59 at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Monday, May 21, 2012 4:36 PM
Subject: [R] Random effect in an Incomplete block design

Dear R Users,

I am facing a problem analyzing an incomplete block design with two replicates. As you can see in the attached .xls file, the factor2 (6 levels) nested within factor1(two levels) nested within replicates all were chosen as random effects in the statistical model (see below). Note that the replicates are incomplete. The effect of year crossed with these factors as random.??To handle incomplete design and random effects, I used lme package instead of aov as follows:

library(nlme)
data<- read.table("C:\\Users\\user\\Desktop\\sb.txt",header=T)
attach(data)
model<-lme(var~1+ year+ year*replicates+ year*factor1+ year*factor2, random=~1|replicates/factor1/factor2)
summary(model)
?
?The above-code is runnable. However, could you please make me sure of the following points?

1- Have I defined the interactions correctly (particularly year by other factors) ?
?
2- Which one should I include into the statistical model, replicates or block.incomplete?
?
3- How can I compare different levels of each factor (i.e. factor1, factor2, year)? In other words, is there any way to use LSD or SED methods in the package lme?
?
Your help would be highly appreciated.
?
Best regards,
Reza
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Julia.Sommerfeld at utas.edu.au  Tue May 22 03:27:12 2012
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 22 May 2012 11:27:12 +1000
Subject: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer -
 justified to run a glm instead?
Message-ID: <CAOCHjhS3hX47vJ7nRz7fM_1NQRgpvBTU=GVhvhAATfNNx23bhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/1ab20c53/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Tue May 22 03:31:22 2012
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 22 May 2012 11:31:22 +1000
Subject: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer -
 justified to run a glm instead?
In-Reply-To: <4D0A9BF6-5903-40B9-8E22-C67E7B5E570F@stanford.edu>
References: <CAOCHjhTanwXyPt4oXRdiLsWgsxOujd+cw30p9T5q-+BA8figLA@mail.gmail.com>
	<4D0A9BF6-5903-40B9-8E22-C67E7B5E570F@stanford.edu>
Message-ID: <CAOCHjhRzJ-He0dGYt+aptJMirM17JJ3DnmYEKUfoh-KWLj+X7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/4345c491/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Tue May 22 05:06:00 2012
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 22 May 2012 13:06:00 +1000
Subject: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer -
 justified to run a glm instead?
In-Reply-To: <3C5FCA7D-38A6-4B51-AC4E-4DEE735195F1@stanford.edu>
References: <CAOCHjhTanwXyPt4oXRdiLsWgsxOujd+cw30p9T5q-+BA8figLA@mail.gmail.com>
	<4D0A9BF6-5903-40B9-8E22-C67E7B5E570F@stanford.edu>
	<CAOCHjhRzJ-He0dGYt+aptJMirM17JJ3DnmYEKUfoh-KWLj+X7g@mail.gmail.com>
	<3C5FCA7D-38A6-4B51-AC4E-4DEE735195F1@stanford.edu>
Message-ID: <CAOCHjhSouS6sox=XPqY4VCvtgFkNu=AULJJoHOyJH8iXoO=FVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/9fc8d2a1/attachment.pl>

From kfrost at wisc.edu  Tue May 22 05:24:54 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Mon, 21 May 2012 22:24:54 -0500
Subject: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer -
 justified to run a glm instead?
In-Reply-To: <7640c53b7c808.4fbb06da@wiscmail.wisc.edu>
References: <CAOCHjhTanwXyPt4oXRdiLsWgsxOujd+cw30p9T5q-+BA8figLA@mail.gmail.com>
	<4D0A9BF6-5903-40B9-8E22-C67E7B5E570F@stanford.edu>
	<CAOCHjhRzJ-He0dGYt+aptJMirM17JJ3DnmYEKUfoh-KWLj+X7g@mail.gmail.com>
	<3C5FCA7D-38A6-4B51-AC4E-4DEE735195F1@stanford.edu>
	<CAOCHjhSouS6sox=XPqY4VCvtgFkNu=AULJJoHOyJH8iXoO=FVQ@mail.gmail.com>
	<7620affd791b3.4fbb069d@wiscmail.wisc.edu>
	<7640c53b7c808.4fbb06da@wiscmail.wisc.edu>
Message-ID: <76e0d2c67bd3a.4fbac0b6@wiscmail.wisc.edu>

Try
dat$sitc <- scale(dat$sit, center = TRUE, scale = FALSE)

On 05/21/12, Julia Sommerfeld 
 wrote:
> the fixed effect "sit" is a logit transformed proportion of "psit". Some of
> the values in "psit" equal zero. Other than that, I don't know what could
> be the problem. To be honest, I haven't use the scale function before in a
> lmer. Thus, I don't quite understand why a different coef estimate is a
> problem? Since I transformed the "sit" values, why shouldn't the coef
> change accordingly?
> 
> Julia
> 
> 
> 
> 2012/5/22 Ewart Thomas <ethomas at stanford.edu>
> 
> > julia, there's something funny about your new fixed effects. i expected
> > the intercept to change, and it did - a reduction of 1.1.
> >
> > i expected the effect of sitc (1.3) to be the same as that of sit (.75);
> > and the effect of dive to be the same. why the change in the sitc coeff.
> > scale() just centers, it doesn't standardise, correct?
> >
> > see if you can figure out what's 'wrong', e.g., by looking at your raw
> > data file, coding of birds (as a factor), coding of sit as numeric. i
> > estimate the sit mean to be 0.84. is this right? ...
> > ewart
> >
> > On May 21, 2012, at 6:31 PM, Julia Sommerfeld wrote:
> >
> > Hi Ewart,
> >
> > Thanks for the quick reply. I've run the model using "sitc". But the
> > variance is still zero.
> >
> > dat$sitc <- scale(dat$sit)
> >
> > > mod8 <- lmer(ars1 ~ sitc + dive + (1|bird), data=dat, family=binomial)
> >
> > > summary(mod8)
> > Generalized linear mixed model fit by the Laplace approximation
> > Formula: ars1 ~ sitc + dive + (1 | bird)
> > Data: dat
> > AIC BIC logLik deviance
> > 159.4 171.7 -75.71 151.4
> > Random effects:
> > Groups Name Variance Std.Dev.
> > bird (Intercept) 0 0
> > Number of obs: 160, groups: bird, 25
> >
> > Fixed effects:
> > Estimate Std. Error z value Pr(>|z|)
> > (Intercept) -1.5423 0.3705 -4.163 3.14e-05 ***
> > sitc 1.2913 0.2495 5.175 2.28e-07 ***
> > dive 1.3076 0.4374 2.990 0.00279 **
> > ---
> > Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> > (Intr) sitc
> > sitc -0.156
> > dive -0.827 0.005
> >
> >
> > 2012/5/22 Ewart Thomas <ethomas at stanford.edu>
> >
> >> julia, while doug bates is right in noting that the 0 estimate suggests
> >> that var(intercept) is truly 0 (and can be omitted), i think your result is
> >> suspicious (not wrong).
> >>
> >> try centering 'sit': sitc = scale(sit)
> >>
> >> then use sitc instead of sit in mod6. the meaning of 'intercept' for
> >> each bird has changed: it is now a bird's average response (on the logit(p)
> >> scale) when the bird happens to have it's 'sit' value = the sample mean of
> >> 'sit'. you may know how best to interpret such 'intercepts'.
> >>
> >> good luck!
> >> ewart
> >>
> >> On May 21, 2012, at 6:07 PM, Julia Sommerfeld wrote:
> >>
> >> > Dear list,
> >> >
> >> > I'm running a lmer (package lme4) with a binomial error distribution and
> >> > "bird" as the random effect (160 observations of 25 birds). The response
> >> > variable "ars1" is coded as 0, 1.
> >> > The fixed effect "sit" is numerical and "dive" is categorical (0, 1).
> >> >
> >> > What puzzles me a little is that the a variance and sd of the random
> >> effect
> >> > is ZERO. Same question has been posted before and Douglas Bates answer
> >> was:
> >> >
> >> > "No, an estimate of zero is not suspicious. It is simply an indication
> >> >
> >> > that the variability between individuals is not significantly larger
> >> > than what one would expect from the random variability in the
> >> > response."
> >> >
> >> >
> >> > While another answer suggested that the model was "wrong":
> >> >
> >> >
> >> > "A zero estimate of a variance possibly indicates the model is wrong."
> >> This
> >> > wrong model seemed to be related to a negative covariation of one of the
> >> > fixed effects ?
> >> >
> >> >
> >> >
> >> > My simplified model is:
> >> >
> >> > mod6 <- lmer(ars1 ~ sit + dive + (1|bird), data=dat, family=binomial)
> >> >
> >> >> summary(mod6)
> >> > Generalized linear mixed model fit by the Laplace approximation
> >> > Formula: ars1 ~ sit + dive + (1 | bird)
> >> > Data: dat
> >> > AIC BIC logLik deviance
> >> > 159.4 171.7 -75.71 151.4
> >> > Random effects:
> >> > Groups Name Variance Std.Dev.
> >> > bird (Intercept) 0 0
> >> > Number of obs: 160, groups: bird, 25
> >> >
> >> > Fixed effects:
> >> > Estimate Std. Error z value Pr(>|z|)
> >> > (Intercept) -0.3615 0.4037 -0.895 0.37059
> >> > sit 0.7492 0.1448 5.175 2.28e-07 ***
> >> > dive 1.3076 0.4374 2.990 0.00279 **
> >> > ---
> >> > Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >
> >> > Correlation of Fixed Effects:
> >> > (Intr) sit
> >> > sit 0.422
> >> > dive -0.756 0.005
> >> >>
> >> >
> >> >
> >> > Based on the summary output (zero variance and sd) and the two plots
> >> below,
> >> > I'm inclined to believe that in fact my random effect bird does not
> >> account
> >> > for any of the variance in the model. I.e., that there is no significant
> >> > variability between birds that I should account for.
> >> >
> >> > *QUESTION: Could I be overlooking something or is it justified to run a
> >> glm
> >> > without the random effect bird instead of a lmer?*
> >> >
> >> > Thank you!
> >> >
> >> > Best regards, Julia
> >> >
> >> >
> >> > dotplot(ranef(mod6, postVar=TRUE))
> >> >
> >> >
> >> >
> >> > qqnorm(unlist(ranef(mod6)), main="normal qq-plot, random effects")
> >> > qqline(unlist(ranef(mod6))) # qq of random effects
> >> >
> >> > [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >
> >
> > --
> > Julia Sommerfeld - PhD Candidate
> > Institute for Marine and Antarctic Studies
> > University of Tasmania
> > Private Bag 129, Hobart
> > TAS 7001
> >
> > Phone: +61 477 289 301
> > Email: julia.somma at gmx.de
> > Julia.Sommerfeld at utas.edu.au
> >
> >
> >
> 
> 
> -- 
> Julia Sommerfeld - PhD Candidate
> Institute for Marine and Antarctic Studies
> University of Tasmania
> Private Bag 129, Hobart
> TAS 7001
> 
> Phone: +61 477 289 301
> Email: julia.somma at gmx.de
> Julia.Sommerfeld at utas.edu.au
> 
> [[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Julia.Sommerfeld at utas.edu.au  Tue May 22 06:36:52 2012
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 22 May 2012 14:36:52 +1000
Subject: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer -
 justified to run a glm instead?
In-Reply-To: <76e0d2c67bd3a.4fbac0b6@wiscmail.wisc.edu>
References: <CAOCHjhTanwXyPt4oXRdiLsWgsxOujd+cw30p9T5q-+BA8figLA@mail.gmail.com>
	<4D0A9BF6-5903-40B9-8E22-C67E7B5E570F@stanford.edu>
	<CAOCHjhRzJ-He0dGYt+aptJMirM17JJ3DnmYEKUfoh-KWLj+X7g@mail.gmail.com>
	<3C5FCA7D-38A6-4B51-AC4E-4DEE735195F1@stanford.edu>
	<CAOCHjhSouS6sox=XPqY4VCvtgFkNu=AULJJoHOyJH8iXoO=FVQ@mail.gmail.com>
	<7620affd791b3.4fbb069d@wiscmail.wisc.edu>
	<7640c53b7c808.4fbb06da@wiscmail.wisc.edu>
	<76e0d2c67bd3a.4fbac0b6@wiscmail.wisc.edu>
Message-ID: <CAOCHjhT2bMx35adjF2pMc6rsYTL0iLO1LW3mOKuGtqyQzXt5cA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/fdf59acd/attachment.pl>

From AhmadR at sbscibus.com.au  Tue May 22 06:51:12 2012
From: AhmadR at sbscibus.com.au (Ahmad Rabiee)
Date: Tue, 22 May 2012 04:51:12 +0000
Subject: [R-sig-ME] reaped measures with unequal intervals
Message-ID: <F82E4A0E5D9F0D44939AC32130AE0BF42DB8BC9B@SBSSERVER.sbs.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/d58f1062/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue May 22 12:48:26 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 22 May 2012 10:48:26 +0000
Subject: [R-sig-ME] LME4: output interpretation of tricky model
In-Reply-To: <CACm_P7oX49zeD0qh02gbnbv-GHUQO=HNAXLmtB3ph3xZCAdWag@mail.gmail.com>
References: <CACm_P7oX49zeD0qh02gbnbv-GHUQO=HNAXLmtB3ph3xZCAdWag@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275A76F64E@inbomail.inbo.be>

Dear Eiko,

Try to write out the model by hand. E.g. if you want a prediction for Y_index = 1, time = 1, x1 = 2 and x2 = 4, which coefficient would you use? And what is the values for Y_index, time, x1 and x2 change (look especially at time = 0, x1 =  and x2 = 0)?

If the interpretation of the coefficients is important, then I would model it as

Y ~ -1 + time + Y_index:x1 + Y_index:x2 + ( - 1 + Y_index | subject)

Which gives the same model fit but with a different parametrisation.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Eiko Fried
Verzonden: zondag 20 mei 2012 13:53
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] LME4: output interpretation of tricky model

Dear Mailinglist,

I would be very glad to get some assistance with interpreting a tricky model output in LME4.

The model is this:

Y ~ -1 + Y_index + time + Y_index*x1 + Y_index*x2 + ( - 1 + Y_index |
subject)

What I am doing with this is modeling 9 items of a questionnaire as a multivariate response variable Y.
Y_index is a categorical variable defining the number of item of the questionnaire (1 through 9), and I am checking with interaction effects on
x1 and x2 whether these covariates have differential effects on my multivariate response. It is a longitudinal design with 5 measurement points, and I expect that x1 only affects some of my 9 items (the same for x2).

The dataset is in long-long format (Y_index * time), so each subject has
9*5 lines.
(I found the suggestion for that kind of analysis in Hox, 2010).

The for me relevant part of the output looks like this:

Fixed effects:
                              Estimate    Std. Error    t value
Y_index1                 0.3161592  0.0780922   4.049
Y_index2                 0.4685218  0.0775360   6.043
Y_index3                 0.9531528  0.0969119   9.835
Y_index4                 0.2366093  0.0898923   2.632
Y_index5                 0.3055025  0.0955639   3.197
Y_index6                 0.2581729  0.0819606   3.150
Y_index7                 0.4556287  0.0817002   5.577
Y_index8                 0.6027990  0.0691566   8.716
Y_index9                 0.8697155  0.0620898  14.007
time                        0.5726978  0.0374384  15.297
x1                           0.0196260  0.0020225   9.704
x2                          -0.0415874  0.0350631  -1.186
Y_index2:x1            0.0023080  0.0018770   1.230
Y_index3:x1           -0.0019870  0.0027166  -0.731
Y_index4:x1           -0.0006285  0.0023784  -0.264
Y_index5:x1            0.0033737  0.0026178   1.289
Y_index6:x1            0.0067164  0.0020428   3.288
Y_index7:x1           -0.0016510  0.0021435  -0.770
Y_index8:x1           -0.0080817  0.0020414  -3.959
Y_index9:x1           -0.0140743  0.0021874  -6.434
Y_index2:x2            0.0358944  0.0325015   1.104
Y_index3:x2           -0.0675878  0.0470604  -1.436
Y_index4:x2            0.0037518  0.0411980   0.091
Y_index5:x2           -0.0456199  0.0453805  -1.005
Y_index6:x2            0.0333067  0.0353716   0.942
Y_index7:x2            0.0443440  0.0371040   1.195
Y_index8:x2            0.0595453  0.0353532   1.684
Y_index9:x2            0.0223958  0.0379038   0.591

What I don't understand is
(1) why Y_index1 is missing in my interaction output with x1 and x2 (the lists start with Y_index2), and
(2) what the interaction lines exactly mean. Is it a comparison to a baseline? Is it difference from the main effect?

I do apologize in case this is a very simple question, but I cannot get my head around it.

Thank you
--E

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Thierry.ONKELINX at inbo.be  Tue May 22 13:53:48 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 22 May 2012 11:53:48 +0000
Subject: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer -
 justified to run a glm instead?
In-Reply-To: <CAOCHjhTanwXyPt4oXRdiLsWgsxOujd+cw30p9T5q-+BA8figLA@mail.gmail.com>
References: <CAOCHjhTanwXyPt4oXRdiLsWgsxOujd+cw30p9T5q-+BA8figLA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275A770799@inbomail.inbo.be>

Dear Julia,

Make sure that you ran the model with a recent version of lme4. I recall a similar question were the model gave different results when run with a more recent version.

If the variance stays zero, then I still would not worry yet. The ecological interpretation would be that the probability for ars1 does not depend on the individuals. And I would stick with the mixed model because of the design of your study.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Julia Sommerfeld
Verzonden: dinsdag 22 mei 2012 3:07
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] ZERO variance and ZERO sd of random effect in lmer - justified to run a glm instead?

Dear list,

I'm running a lmer (package lme4) with a binomial error distribution and "bird" as the random effect (160 observations of 25 birds). The response variable "ars1" is coded as 0, 1.
The fixed effect "sit" is numerical and "dive" is categorical (0, 1).

What puzzles me a little is that the a variance and sd of the random effect is ZERO. Same question has been posted before and Douglas Bates answer was:

"No, an estimate of zero is not suspicious.  It is simply an indication

that the variability between individuals is not significantly larger than what one would expect from the random variability in the response."


While another answer suggested that the model was "wrong":


"A zero estimate of a variance possibly indicates the model is wrong."  This wrong model seemed to be related to a negative covariation of one of the fixed effects ?



 My simplified model is:

mod6 <- lmer(ars1 ~ sit + dive + (1|bird), data=dat, family=binomial)

> summary(mod6)
Generalized linear mixed model fit by the Laplace approximation
Formula: ars1 ~ sit + dive + (1 | bird)
   Data: dat
   AIC   BIC logLik deviance
 159.4 171.7 -75.71    151.4
Random effects:
 Groups Name        Variance Std.Dev.
 bird   (Intercept)  0        0
Number of obs: 160, groups: bird, 25

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -0.3615     0.4037  -0.895  0.37059
sit           0.7492     0.1448   5.175 2.28e-07 ***
dive          1.3076     0.4374   2.990  0.00279 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
     (Intr) sit
sit   0.422
dive -0.756  0.005
>


Based on the summary output (zero variance and sd) and the two plots below, I'm inclined to believe that in fact my random effect bird does not account for any of the variance in the model. I.e., that there is no significant variability between birds that I should account for.

*QUESTION: Could I be overlooking something or is it justified to run a glm without the random effect bird instead of a lmer?*

Thank you!

Best regards, Julia


dotplot(ranef(mod6, postVar=TRUE))



qqnorm(unlist(ranef(mod6)), main="normal qq-plot, random effects")
qqline(unlist(ranef(mod6))) # qq of random effects

        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From dkoya at mac.com  Tue May 22 15:16:25 2012
From: dkoya at mac.com (Daisuke Koya)
Date: Tue, 22 May 2012 14:16:25 +0100
Subject: [R-sig-ME] Syntax for lme function to model random factors and
	interactions
Message-ID: <CC31277E-24E7-46E1-BC3A-2A7786A0FF1F@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/ac0a8dfa/attachment.pl>

From rhbc at imm.dtu.dk  Tue May 22 15:51:01 2012
From: rhbc at imm.dtu.dk (Rune Haubo)
Date: Tue, 22 May 2012 15:51:01 +0200
Subject: [R-sig-ME] error from clmm
In-Reply-To: <78678DB3-9021-44DE-899B-68D71E64E042@bristol.ac.uk>
References: <78678DB3-9021-44DE-899B-68D71E64E042@bristol.ac.uk>
Message-ID: <CAG_uk93R0z8R-2toMV5SUes+_2c+Hs0SRNX0JGM-EUxNhLf5+Q@mail.gmail.com>

Malcolm,

It happens that I have been doing some work tracking down that
particular error message in the last couple of days, and I believe I
have found a solution, at least for the most common link functions. I
have committed the changes to R-Forge, so you should be able to
install with install.packages("ordinal",
repos="http://R-Forge.R-project.org") when the package has been build
- make sure you get at least version 2012-05-22 corresponding to
revision 78. I will submit an updated version to CRAN after doing a
little more work on the package.

I will be very interested to know if this resolves your problems. If
it doesn't, perhaps you could share your data with me off list? I
haven't got an example where I can reproduce the problem and such
examples are crucial when tracking down such bugs.

Cheers,
Rune

On 20 May 2012 17:49, Malcolm Fairbrother <m.fairbrother at bristol.ac.uk> wrote:
> Dear list,
>
> I am making use of the "clmm" function from the "ordinal" package, for fitting mixed models with ordinal outcomes.
>
> When fitting quite a few models, I get the error:
>
> Error in if (maxGrad < rho$ctrl$gradTol) { :
> ?missing value where TRUE/FALSE needed
> In addition: Warning message:
> In sqrt(phi2) : NaNs produced
>
> Can anyone help me to understand why this may be happening, and/or whether there's anything obvious I should be doing different? With some seemingly small/arbitrary specification changes--or when taking (some) random subsets of my dataset--I don't get this message. But I'd like to find a way of reducing the frequency with which I do get it.
>
> I don't think there's anything unusual about my call:
>
> mod1 <- clmm(as.ordered(y) ~ x + (1 | fac1) + (1 | fac2), data=dat, link="logit", threshold="symmetric")
>
> I'm running:
> R version 2.15.0 (2012-03-30)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> Many thanks to anyone who can assist,
>
> Malcolm
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Rune Haubo Bojesen Christensen

Ph.D. Student, M.Sc. Eng.
Phone: (+45) 45 25 33 63
Mobile: (+45) 30 26 45 54

DTU Informatics, Section for Statistics
Technical University of Denmark, Build. 305, Room 122,
DK-2800 Kgs. Lyngby, Denmark


From spatrick at cebc.cnrs.fr  Tue May 22 16:22:26 2012
From: spatrick at cebc.cnrs.fr (Samantha Patrick)
Date: Tue, 22 May 2012 16:22:26 +0200
Subject: [R-sig-ME] Calculating repeatability with ordinal data
In-Reply-To: <20120502144331.23435ulmbjxwk4ws@www.staffmail.ed.ac.uk>
References: <4F990193.4000107@cebc.cnrs.fr> <4FA10786.6090007@cebc.cnrs.fr>
	<0BB9E1F2-BE5A-4987-B7B7-CB0D0189FBA8@imperial.ac.uk>
	<4FA1164D.6040603@cebc.cnrs.fr>
	<20120502144331.23435ulmbjxwk4ws@www.staffmail.ed.ac.uk>
Message-ID: <4FBBA122.7090702@cebc.cnrs.fr>

Hi

Thanks for the comments - sorry for the delayed response, I had to learn 
how to use MCMCglmm!

Following Shinichi's advice I have been using an adapted version of the 
code in Dean et al 2012 (Am Nat). To start with I have been trying to 
fit the data as categorical, as the original script is based on this 
distribution.

Simplified code:

Bird = factor with 1183 levels with 1638 observations
Year = factor with 4 levels
scoremax = ordinal factor with 5 levels (0-4)


year<-as.factor(year)

# setting prior probabilities for random effects
IJ<-(1/5)*(diag(4) + matrix(1,4,4))

priortest1 <- list(R=list(V = IJ, nu = 0.002), G = list(G1 = list(V = 1, 
nu = 0.002), G2 = list(V = 1, nu = 0.002)))

model1b<-MCMCglmm(scoremax~trait-1, random =~Bird +year, rcov = 
~us(trait):units, data = Data, prior = priortest1, family = "categorical")

# Getting "adjusted" repeatability - Equation A10
summary(model1$VCV[,1]/(model1$VCV[,1]+2/3+pi^2/3))
posterior.mode(model1$VCV[,1]/(model1$VCV[,1]+2/3+pi^2/3))

This does run but the model fit is pretty bad.  I haven't tried to 
optimise it as it is important that my data is ordered so I am trying to 
work on the script below:

priortest2 <- list(R=list(V = 1 , fix=1), G = list(G1=list(V=1, nu=1, 
alpha.mu=0, alpha.V=100),G2=list(V=1, nu=1, alpha.mu=0, alpha.V=100))) 
##  this seems to be a commonly used prior for ordinal data so I was 
using it as a starting point but have not got as far as to test whether 
it is more suitable than priortest1 due to the problem below

model1b<-MCMCglmm(scoremax~trait-1, random =~Bird + year, rcov = 
~us(trait):units, data = Data, prior = priortest2, family = "ordinal")

At this stage I get an error message which says:

Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
   contrasts can be applied only to factors with 2 or more levels

I have tried to create dummy data to seek out the problem.  I thought 
the problem may stem from the model trying to estimate contrasts between 
each level of the ordinal response ie. 0-1, 1-0, 0-2, 2-0, 0-3, 3-0, 0-4 
etc.  Within the data individuals move between all scores but not both 
ways (i.e.  There are individuals who change between 1 and 2, but not 
necessarily individuals that move from 1 to 2 AND 2 to 1).  However, I 
have not fitted observation number in the model (the temporal order of 
observations is not specified) and altering the order of observation 
does not seem to fix this.  I have simplified the model and run without 
year, but I get the same error.

I can happily post more data if it is helpful.

Any advice would be greatly appreciated!

Thanks

Sam




Le 02/05/2012 15:43, Jarrod Hadfield a ?crit :
> Hi,
>
> The residual variance can never be estimated from ordinal data. Most
> programs will set it to zero, some programs allow you to set it at
> anything (MCMCglmm). I have not seen repeatabilities for ordinal data
> but I presume you can add the variance of the relevant distribution
> (pi^2/3 or 1 for logit/probit) to the denominator in order to get an
> intra-class correlation. I'm not confident how this would be
> interpreted for an ordinal response though. Note that if you do use
> MCMCglmm you need to include the constrained residual variance in the
> denominator (i.e. to get the denominator you need to add two to the
> "Bird" variance if you have constrained the residual variance to one).
>
> Cheers,
>
> Jarrod
>
>
> Quoting Samantha Patrick <spatrick at cebc.cnrs.fr> on Wed, 02 May 2012
> 13:11:09 +0200:
>
>> Hi
>>
>> Thank you for the tip - I had editted my code!  However, sadly it
>> doesn't  solve the problem of how to estimate the residual variance.
>>
>> Many Thanks
>>
>> Sam
>>
>>
>> Le 02/05/2012 12:38, Federico Calboli a ?crit :
>>> On 2 May 2012, at 11:08, Samantha Patrick wrote:
>>>
>>>> Hi
>>>>
>>>> Firstly I sent this message last week but can find no evidence that
>>>> it actually sent.
>>>> However, if this is a double posting I am very sorry.
>>>>
>>>> I am currently working with repeated measures for individuals and I am
>>>> trying to quantify individual repeatability.  Normally, for continuous
>>>> distributions, I would use a mixed model and calculate the variance
>>>> explained by individual divided by the total variance.  However my
>>>> individual scores
>>>> are ordinal and I have been using the clmm function in the Ordinal
>>>> package:
>>>>
>>>> example of data:
>>>> ID        Bird        Sex    scoremax    year
>>>> 622    BS8831    M       2                 2008
>>>> 623    BS8831    M       1                 2010
>>>> 624    BS8831    M       1                 2011
>>>> 625    BS9065    M       1                 2010
>>>> 626    BS9065    M       3                 2011
>>>> 627   BS19724    F       4                 2010
>>>> 628   BS19724    F       5                 2010
>>>> 629   BS21302    F       1                 2010
>>>> 630   BS25376    F       1                 2011
>>>> 631    BS9184    F       2                 2009
>>>> 632   BS19989    M       3                 2011
>>>> 633   BS21617    M       4                 2008
>>>> 634   BS21617    M       2                 2009
>>>> 635   BS21617    M       1                 2010
>>>>
>>>> where scoremax ranges from 1-5, and there are 1188 birds and 1638
>>>> observations.
>>>>
>>>> scoremax<-as.factor(scoremax)
>>> does
>>>
>>> scoremax = as.ordered(scoremax)
>>>
>>> make any difference in your results?
>>>
>>> I ask this because as.factor() does not, strictly speaking, create
>>> an ordered factor.
>>>
>>> BW
>>>
>>> F
>>>
>>>
>>>
>>>
>>>> bird<-as.factor(bird)
>>>> year<-as.factor(year)
>>>> fmm1<- clmm(scoremax~year+ (1|bird), link = c("probit"), Hess =TRUE)
>>>>
>>>> summary(fmm1)
>>>>
>>>> but this only gives the variance estimate for bird, with no residual
>>>> estimate.  Some investigations reveal that using an ordinal regression
>>>> in MCMCglmm will also not estimate the residual variance, and it seems
>>>> you need to constrain this value.  I have been unable to find any
>>>> posts
>>>> about repeatability in ordinal data.
>>>>
>>>> My questions I guess are:
>>>> Is using a mixed model appropriate for calculating the
>>>> repeatability of
>>>> ordinal data (and if not does anyone know any other methods)?
>>>>
>>>> If it is, does anyone have any hints on how to calculate the
>>>> residual variance,
>>>> to enable repeatability estimates to be calculated.
>>>>
>>>> Many Thanks
>>>>
>>>> Sam
>>>>
>>>> --
>>>>
>>>> Dr Samantha Patrick
>>>> Post Doctoral Fellow
>>>> Centre d'Etudes Biologiques de Chiz? - CNRS
>>>> 79360 Villiers-en-Bois
>>>> France
>>>> T:+33 549 097 846
>>>> M:+33 675 603 451
>>>> Skype: sammy_patrick
>>>> http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
>>>> http://www.researchgate.net/profile/Samantha_Patrick/
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> --
>>> Federico C. F. Calboli
>>> Neuroepidemiology and Ageing Research
>>> Imperial College, St. Mary's Campus
>>> Norfolk Place, London W2 1PG
>>>
>>> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>>>
>>> f.calboli [.a.t] imperial.ac.uk
>>> f.calboli [.a.t] gmail.com
>>>
>>>
>>>
>>
>> --
>>
>> Dr Samantha Patrick
>> Post Doctoral Fellow
>> Centre d'Etudes Biologiques de Chiz? - CNRS
>> 79360 Villiers-en-Bois
>> France
>> T:+33 549 097 846
>> M:+33 675 603 451
>> Skype: sammy_patrick
>> http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
>> http://www.researchgate.net/profile/Samantha_Patrick/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>

-- 

Dr Samantha Patrick
Post Doctoral Fellow
Centre d'Etudes Biologiques de Chiz? - CNRS
79360 Villiers-en-Bois
France
T:+33 549 097 846
M:+33 675 603 451
Skype: sammy_patrick
http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
http://www.researchgate.net/profile/Samantha_Patrick/


From bonamy at horus.ens.fr  Tue May 22 16:43:55 2012
From: bonamy at horus.ens.fr (Pierre de Villemereuil)
Date: Tue, 22 May 2012 16:43:55 +0200
Subject: [R-sig-ME] Calculating repeatability with ordinal data
In-Reply-To: <4FBBA122.7090702@cebc.cnrs.fr>
References: <4F990193.4000107@cebc.cnrs.fr> <4FA10786.6090007@cebc.cnrs.fr>
	<0BB9E1F2-BE5A-4987-B7B7-CB0D0189FBA8@imperial.ac.uk>
	<4FA1164D.6040603@cebc.cnrs.fr>
	<20120502144331.23435ulmbjxwk4ws@www.staffmail.ed.ac.uk>
	<4FBBA122.7090702@cebc.cnrs.fr>
Message-ID: <4FBBA62B.4060108@horus.ens.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/67717dca/attachment.pl>

From deter088 at umn.edu  Tue May 22 17:01:15 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 22 May 2012 10:01:15 -0500
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
	<CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
	<CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
Message-ID: <CAOLJphkVfNio+dO3CWEEncsFzh1LukyKfy9xu0aK+jB1KRwh3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/ce0641b2/attachment.pl>

From spatrick at cebc.cnrs.fr  Tue May 22 17:12:57 2012
From: spatrick at cebc.cnrs.fr (Samantha Patrick)
Date: Tue, 22 May 2012 17:12:57 +0200
Subject: [R-sig-ME] Calculating repeatability with ordinal data
In-Reply-To: <4FBBA62B.4060108@horus.ens.fr>
References: <4F990193.4000107@cebc.cnrs.fr> <4FA10786.6090007@cebc.cnrs.fr>
	<0BB9E1F2-BE5A-4987-B7B7-CB0D0189FBA8@imperial.ac.uk>
	<4FA1164D.6040603@cebc.cnrs.fr>
	<20120502144331.23435ulmbjxwk4ws@www.staffmail.ed.ac.uk>
	<4FBBA122.7090702@cebc.cnrs.fr> <4FBBA62B.4060108@horus.ens.fr>
Message-ID: <4FBBACF9.8000701@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/6ec51476/attachment.pl>

From jbaldwin at fs.fed.us  Tue May 22 17:20:52 2012
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Tue, 22 May 2012 15:20:52 +0000
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CAOLJphkVfNio+dO3CWEEncsFzh1LukyKfy9xu0aK+jB1KRwh3Q@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
	<CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
	<CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
	<CAOLJphkVfNio+dO3CWEEncsFzh1LukyKfy9xu0aK+jB1KRwh3Q@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45690EC960AD@001FSN2MPN1-062.001f.mgd2.msft.net>

Have you considered the other direction?  SAS offers 5 different options for constructing the denominator degrees of freedom:  BETWITHIN, CONTAIN, KENWARDROGER, RESIDUAL, SATTERTHWAITE.  Also reading the associated references for those methods will help with understanding why there isn't a single method that is "correct" for all situations.  (My apologies for showing part of a SAS manual on this list.)

Jim

Jim Baldwin
Station Statistician
Pacific Southwest Research Station
USDA Forest Service
Albany, California


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles Determan Jr
Sent: Tuesday, May 22, 2012 8:01 AM
To: Douglas Bates
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme

Dr. Bates,

After another thought, would it be possible to modify the gls source code to incorporate the same denDF calculation used in the lme function from this package?  I have been looking through the source code of the nlme package and by adding the denDF to the gls function I would solve my initial problem of having consistent F values and dfs.  However, I would prefer to work with one of the authors regarding any modification.  Perhaps I should contact R core mailing list?

Regards,
Charles

On Mon, May 21, 2012 at 12:22 PM, Douglas Bates <bates at stat.wisc.edu> wrote:

> I don't really think there is a way of defining the degrees of freedom
> for all lme and gls model fits so that they correspond to the
> "correct" values, which often seems to mean the values returned by
> SAS.  If you feel that SAS provides the correct analysis in all cases
> then you should use SAS.  We can't reproduce the SAS results in R
> because SAS is proprietary code and we don't know how those results
> are calculated.
>
> The whole question of degrees of freedom for certain tests is very
> complicated.  Often there is no answer because the distribution of the
> test statistic is not a t or an F distribution.
>
> On Mon, May 21, 2012 at 11:16 AM, Charles Determan Jr
> <deter088 at umn.edu>
> wrote:
> > Thank you for giving this some thought Joshua.  I will be sure to
> > keep troubleshooting this as well.  Would it be related to how gls
> > calculates its values that is somehow reports the 'correct' F value perhaps?
> >
> > Regards,
> > Charles
> >
> > On Mon, May 21, 2012 at 11:08 AM, Joshua Wiley
> ><jwiley.psych at gmail.com
> >wrote:
> >
> >> That suggests they are fitting different models somehow (not just
> >> that the specifc effect estimates are different).  No brilliant
> >> ideas on in what way though...
> >>
> >> I checked REML versus ML but that was not it.  I'll let you know if
> >> I have any ideas.
> >>
> >> Cheers,
> >>
> >> Josh
> >>
> >> On Mon, May 21, 2012 at 9:02 AM, Charles Determan Jr
> >> <deter088 at umn.edu>
> >> wrote:
> >> > Hi Joshua,
> >> >
> >> > The -2 Log-likelihood from SAS is -58.6 The log-likelihood from R
> >> > fit.13 is 21.9.  I assume this would be
> >> multiplied
> >> > by -2 which would give -43.8.
> >> >
> >> > Regards,
> >> > Charles
> >> >
> >> >
> >> > On Mon, May 21, 2012 at 10:02 AM, Joshua Wiley <
> jwiley.psych at gmail.com>
> >> > wrote:
> >> >>
> >> >> Hi Charles,
> >> >>
> >> >> Out of curiosity, what is the log likelihood from SAS?  Does it
> >> >> match that from lme()?
> >> >>
> >> >> logLik(fit.13)
> >> >>
> >> >> will give it to you.
> >> >>
> >> >> Cheers,
> >> >>
> >> >> Josh
> >> >>
> >> >> On Mon, May 21, 2012 at 5:45 AM, Charles Determan Jr <
> deter088 at umn.edu>
> >> >> wrote:
> >> >> > Greetings R users,
> >> >> >
> >> >> >
> >> >> > I am trying to match some SAS output of a mixed model.  After
> running
> >> >> > PROC
> >> >> > MIXED with the covariance structure as AR1 the output below is
> given.
> >> >> >  Now
> >> >> > when I try to replicate this with lme, I get the correct
> >> >> > degrees of freedom and somewhat close values.  If I try with
> >> >> > gls, I get the exact F
> value
> >> >> > but
> >> >> > the incorrect denominator degrees of freedom.  Is there some
> syntax or
> >> >> > parameter I can adjust to get lme to have the same F values as gls?
> >> >> >  That
> >> >> > way the correct degrees of freedom would be applied and I
> >> >> > would get
> >> the
> >> >> > replicated model.  The data is also included below.  Thanks to
> >> >> > any
> who
> >> >> > can
> >> >> > help with this issue.
> >> >> >
> >> >> >
> >> >> > Regards,
> >> >> >
> >> >> > Charles
> >> >> >
> >> >> >
> >> >> > Row   ID Group Died Event_name      var
> >> >> > 1    12510     3  YES          B     -1.05257
> >> >> > 2    12510     3  YES        S45    -1.00000
> >> >> > 3    12510     3  YES        FR2   -1.14630
> >> >> > 4    12510     3  YES        FR8   -1.08831
> >> >> > 5    12510     3  YES       FR20   -1.03339
> >> >> > 6    21510     3   NO          B      -0.87290
> >> >> > 7    21510     3   NO        S45     -1.22185
> >> >> > 8    21510     3   NO        FR2     -1.01592
> >> >> > 9    21510     3   NO        FR8    -1.06550
> >> >> > 10   21510     3   NO       PR48    -0.65326
> >> >> > 11   22210     3  YES          B     -1.37059
> >> >> > 12   30810     3   NO          B     -0.92959
> >> >> > 13   30810     3   NO        S45    -1.26680
> >> >> > 14   30810     3   NO        FR2    -0.99396
> >> >> > 15   30810     3   NO        FR8    -1.04769
> >> >> > 16   30810     3   NO       FR20    -1.04769
> >> >> > 17   31510     4  YES          B     -1.50585
> >> >> > 18   31510     4  YES        S45    -1.35262
> >> >> > 19   31510     4  YES        FR2   -1.26520
> >> >> > 20   31510     4  YES        FR8    -1.11407
> >> >> > 21   31510     4  YES       FR20    -0.97757
> >> >> > 22   40510     2  YES          B      -1.04721
> >> >> > 23   40510     2  YES        S45     -1.13371
> >> >> > 24   51010     3   NO          B        -1.21467
> >> >> > 25   51010     3   NO        S45      -1.18177
> >> >> > 26   51010     3   NO        FR2     -1.23582
> >> >> > 27   51010     3   NO        FR8     -1.35262
> >> >> > 28   51010     3   NO       FR20    -0.69897
> >> >> > 29   51010     3   NO       PR48    -1.14086
> >> >> > 30   51710     4   NO          B      -1.13371
> >> >> > 31   51710     4   NO        S45     -1.24336
> >> >> > 32   51710     4   NO        FR2     -0.85201
> >> >> > 33   51710     4   NO        FR8     -0.72700
> >> >> > 34   51710     4   NO       FR20     -0.71220
> >> >> > 35   51710     4   NO       PR48     -1.10735
> >> >> > 36   51809     1   NO          B         -0.70752
> >> >> > 37   51809     1   NO        FR2     -0.58120
> >> >> > 38   51809     1   NO        FR8     -0.71332
> >> >> > 39   51809     1   NO       FR20     -0.37212
> >> >> > 40   61410     4   NO          B     -1.25493
> >> >> > 41   61410     4   NO        S45     -1.24949
> >> >> > 42   61410     4   NO        FR2     -1.18310
> >> >> > 43   61410     4   NO        FR8     -0.87517
> >> >> > 44   61410     4   NO       FR20     -0.34679
> >> >> > 45   61410     4   NO       PR48     -0.76472
> >> >> > 46   62110     3   NO          B         -1.34199
> >> >> > 47   62110     3   NO        S45     -1.23657
> >> >> > 48   62110     3   NO        FR2     -1.20412
> >> >> > 49   62110     3   NO        FR8     -0.72011
> >> >> > 50   62110     3   NO       FR20     -0.72308
> >> >> > 51   62110     3   NO       PR48     -0.89688
> >> >> > 52   62209     3   NO          B         -0.74041
> >> >> > 53   62209     3   NO        S45     -0.99183
> >> >> > 54   62209     3   NO        FR2     -1.06854
> >> >> > 55   62209     3   NO        FR8     -0.94386
> >> >> > 56   62209     3   NO       FR20     -0.38817
> >> >> > 57   71210     4  YES          B     -1.23657
> >> >> > 58   71210     4  YES        S45     -0.94808
> >> >> > 59   71309     4  YES          B     -1.14630
> >> >> > 60   71309     4  YES        S45     -1.10568
> >> >> > 61   71309     4  YES        FR2     -0.94462
> >> >> > 62   71309     4  YES        FR8     -0.89211
> >> >> > 63   71309     4  YES       FR20     -0.98970
> >> >> > 64   71309     4  YES       PR48     -0.83387
> >> >> > 65   81009     4  YES          B         -1.15989
> >> >> > 66   81009     4  YES        S45     -0.93779
> >> >> > 67   81009     4  YES        FR2     -0.86710
> >> >> > 68   81009     4  YES        FR8     -0.69379
> >> >> > 69   81610     1   NO          B         -1.04769
> >> >> > 70   81610     1   NO        S45     -1.02780
> >> >> > 71   81610     1   NO        FR2     -0.96098
> >> >> > 72   81610     1   NO        FR8     -0.91829
> >> >> > 73   81610     1   NO       FR20     -0.68550
> >> >> > 74   81610     1   NO       PR48     -0.66374
> >> >> > 75   81709     4  YES          B    -0.65521
> >> >> > 76   82410     3   NO          B     -1.06702
> >> >> > 77   82410     3   NO        S45     -1.30103
> >> >> > 78   82410     3   NO        FR2     -0.96617
> >> >> > 79   82410     3   NO        FR8     -0.84497
> >> >> > 80   82410     3   NO       FR20     -0.47716
> >> >> > 81   82410     3   NO       PR48     -0.68131
> >> >> > 82   91310     4   NO          B         -1.30803
> >> >> > 83   91310     4   NO        S45     -1.07212
> >> >> > 84   91310     4   NO        FR2     -0.94615
> >> >> > 85   91310     4   NO        FR8     -1.29414
> >> >> > 86   91310     4   NO       FR20     -0.81304
> >> >> > 87   91310     4   NO       PR48     -0.86519
> >> >> > 88   91409     4   NO          B         -1.12321
> >> >> > 89   91409     4   NO        S45     -1.08831
> >> >> > 90   91409     4   NO        FR2     -1.11862
> >> >> > 91   91409     4   NO        FR8     -0.87976
> >> >> > 92   91409     4   NO       FR20     -0.87517
> >> >> > 93   91409     4   NO       PR48     -0.68867
> >> >> > 94   92109     3   NO          B         -1.15120
> >> >> > 95   92109     3   NO        S45     -0.99525
> >> >> > 96   92109     3   NO        FR2     -0.95429
> >> >> > 97   92109     3   NO        FR8     -0.54914
> >> >> > 98   92109     3   NO       FR20     -0.67264
> >> >> > 99   92109     3   NO       PR48     -0.74256
> >> >> > 100  92110     4  YES          B     -1.05012
> >> >> > 101  92110     4  YES        S45     -1.14086
> >> >> > 102  92110     4  YES        FR2     -0.91901
> >> >> > 103  92110     4  YES        FR8     -0.80521
> >> >> > 104  92110     4  YES       FR20     -0.88807
> >> >> > 105  92710     4   NO          B         -1.20412
> >> >> > 106  92710     4   NO        S45     -1.21325
> >> >> > 107  92710     4   NO        FR2     -1.19518
> >> >> > 108  92710     4   NO        FR8     -0.92959
> >> >> > 109  92710     4   NO       FR20     -0.69315
> >> >> > 110  92710     4   NO       PR48     -0.73779
> >> >> > 111 100410     1   NO          B         -0.92300
> >> >> > 112 100410     1   NO        S45     -1.07314
> >> >> > 113 100410     1   NO        FR2     -0.80162
> >> >> > 114 100410     1   NO        FR8     -0.63283
> >> >> > 115 100410     1   NO       FR20     -0.73119
> >> >> > 116 100410     1   NO       PR48      0.10102
> >> >> > 117 101209     3   NO          B     -1.24718
> >> >> > 118 101209     3   NO        S45     -1.00524
> >> >> > 119 101209     3   NO        FR2     -1.01592
> >> >> > 120 101209     3   NO        FR8     -0.85201
> >> >> > 121 101209     3   NO       FR20     -0.51670
> >> >> > 122 101209     3   NO       PR48     -0.72239
> >> >> > 123 101909     3   NO          B         -1.13549
> >> >> > 124 101909     3   NO        S45     -0.92665
> >> >> > 125 101909     3   NO        FR2     -0.98548
> >> >> > 126 101909     3   NO        FR8     -1.03152
> >> >> > 127 101909     3   NO       FR20     -0.71715
> >> >> > 128 101909     3   NO       PR48     -1.07935
> >> >> > 129 102510     2  YES          B         -1.30103
> >> >> > 130 102510     2  YES        S45     -0.83387
> >> >> > 131 110810     3  YES          B     -1.21968
> >> >> > 132 110810     3  YES        S45     -0.68048
> >> >> > 133 110810     3  YES        FR2     -1.09474
> >> >> > 134 110909     2  YES          B         -1.09259
> >> >> > 135 110909     2  YES        S45     -0.91293
> >> >> > 136 111510     3   NO          B         -1.39794
> >> >> > 137 111510     3   NO        S45     -1.42366
> >> >> > 138 111510     3   NO        FR2     -1.22621
> >> >> > 139 111510     3   NO        FR8     -0.98885
> >> >> > 140 111510     3   NO       FR20     -0.66055
> >> >> > 141 111510     3   NO       PR48     -0.84497
> >> >> > 142 111609     1   NO          B         -0.79942
> >> >> > 143 111609     1   NO        S45     -0.87517
> >> >> > 144 111609     1   NO        FR2     -0.74041
> >> >> > 145 111609     1   NO        FR8     -0.64092
> >> >> > 146 111609     1   NO       FR20     -0.53835
> >> >> > 147 111609     1   NO       PR48     -0.68719
> >> >> > 148 120610     4   NO          B     -1.05110
> >> >> > 149 120610     4   NO        S45     -1.45100
> >> >> > 150 120610     4   NO        FR2     -1.21183
> >> >> > 151 120610     4   NO        FR8     -1.04144
> >> >> > 152 120610     4   NO       FR20     -0.61101
> >> >> > 153 120610     4   NO       PR48     -0.81702
> >> >> > 154 120709     1   NO          B         -0.84497
> >> >> > 155 120709     1   NO        S45     -0.99439
> >> >> > 156 120709     1   NO        FR2     -1.13430
> >> >> > 157 120709     1   NO       FR20     -0.57187
> >> >> > 158 120709     1   NO       PR48     -0.80632
> >> >> > 159 121310     3  YES          B         -1.16115
> >> >> > 160 121310     3  YES        S45     -1.18310
> >> >> >
> >> >> > dat=read.table("C:/.../subset.csv",sep=",",header=TRUE,
> na.strings=".")
> >> >> >
> >> >> > attach(dat)
> >> >> >
> >> >> >
> >> >> >
> >> >> > dat34=dat[Pig_group %in% c("3", "4"),]
> >> >> >
> >> >> > attach(dat34)
> >> >> >
> >> >> > dat34=within(dat34, {
> >> >> >
> >> >> >                    group=factor(group)
> >> >> >
> >> >> >                    Event_name=factor(Event_name)
> >> >> >
> >> >> >                    Died=factor(Died)
> >> >> >
> >> >> >                    ID=factor(ID)
> >> >> >
> >> >> > })
> >> >> >
> >> >> > attach(dat34)
> >> >> >
> >> >> >
> >> >> >
> >> >> > contrasts(dat34$Event_name)=contr.sum(n=6)
> >> >> >
> >> >> > contrasts(dat34$group)=contr.sum(n=2)
> >> >> >
> >> >> > contrasts(dat34$Died)=contr.sum(n=2)
> >> >> >
> >> >> >
> >> >> >  # What the results should be from SAS AR1 var #Type 3 Tests
> >> >> > of Fixed Effects
> >> >> > #Effect          NumDF DenDF F Value Pr > F
> >> >> > #Event_name      5   91    7.43    <.0001
> >> >> > #Died              1   24    0.08    0.7756
> >> >> > #Event_name*Died 5   91    3.09    0.0128
> >> >> >
> >> >> > fit.13=lme(var~Event_name*Died,
> >> >> >    data=liver34,
> >> >> >    random=~1|ID,
> >> >> >    corr=corAR1())
> >> >> > anova(fit.13, type="marginal", adjustSigma=F)
> >> >> > #                    numDF denDF   F-value p-value
> >> >> > #(Intercept)             1    91 1342.7364  <.0001
> >> >> > #Event_name          5    91    8.7143  <.0001
> >> >> > #Died                    1    24    0.0527  0.8204
> >> >> > #Event_name:Died     5    91    3.0909  0.0127
> >> >> >
> >> >> > ######################################################
> >> >> > ###THIS DOES IT but not lme function (need dfs)
> >> >> > fit.16=gls(var~Event_name*Died,
> >> >> >    data=liver34,
> >> >> >    corr=corAR1(, ~1|ID))
> >> >> > anova(fit.16, type="marginal", adjustSigma=F) #Denom. DF: 115
> >> >> > #                    numDF   F-value p-value
> >> >> > #(Intercept)             1 1496.9032  <.0001
> >> >> > #Event_name          5    7.4304  <.0001
> >> >> > #Died                    1    0.0831  0.7736
> >> >> > #Event_name:Died     5    3.0871  0.0119
> >> >> >
> >> >> >  #Give exact replicated answers 1-pf(7.4304, 5, 91)
> >> >> > 1-pf(.0831, 1, 24) 1-pf(3.0871, 5, 91)
> >> >> > #######################################################
> >> >> >
> >> >> >        [[alternative HTML version deleted]]
> >> >> >
> >> >> >
> >> >> > _______________________________________________
> >> >> > R-sig-mixed-models at r-project.org mailing list
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Joshua Wiley
> >> >> Ph.D. Student, Health Psychology Programmer Analyst II,
> >> >> Statistical Consulting Group University of California, Los
> >> >> Angeles https://joshuawiley.com/
> >> >
> >> >
> >>
> >>
> >>
> >> --
> >> Joshua Wiley
> >> Ph.D. Student, Health Psychology
> >> Programmer Analyst II, Statistical Consulting Group University of
> >> California, Los Angeles https://joshuawiley.com/
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

        [[alternative HTML version deleted]]





This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From deter088 at umn.edu  Tue May 22 17:31:57 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 22 May 2012 10:31:57 -0500
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D45690EC960AD@001FSN2MPN1-062.001f.mgd2.msft.net>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
	<CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
	<CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
	<CAOLJphkVfNio+dO3CWEEncsFzh1LukyKfy9xu0aK+jB1KRwh3Q@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D45690EC960AD@001FSN2MPN1-062.001f.mgd2.msft.net>
Message-ID: <CAOLJph=jpEt3rbqExuVgrgiUBR_H+Z1tjhN=H3WqbtyVH3WNSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/d49e6a9d/attachment.pl>

From jwiley.psych at gmail.com  Tue May 22 17:42:46 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 22 May 2012 08:42:46 -0700
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CAOLJphkVfNio+dO3CWEEncsFzh1LukyKfy9xu0aK+jB1KRwh3Q@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
	<CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
	<CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
	<CAOLJphkVfNio+dO3CWEEncsFzh1LukyKfy9xu0aK+jB1KRwh3Q@mail.gmail.com>
Message-ID: <CANz9Z_+c4-n22sQyx=nFeRo1dqBKmWMu7Gpo8S9k3V_Z-g4S8g@mail.gmail.com>

Hi Charles,

Unless you have a maniacal employer who demands that you replicate the
fixed effects from SAS, I do not think that adding DFs to the gls
output will really solve your problem.  You are still talking about
rather different models from PROC MIXED to gls().  You may be able to
get equivalent tests of the fixed effects, but I can promise the
random effects are not identical.  So you want to modify stable R
code, in order to get output from R to match a portion of output from
a different model altogether in SAS?  I appreciate that many people
are only interested in the fixed effects and just consider the
nonindependence in their data a nuissance factor, so you may have no
strong preference for random effects versus gls, but we are not
talking about most people here.  We are talking about R which is used
by all sorts of people.

If you need that in your work, you already showed in your original
email you can do it.  You have the F-values, you just want to
calculate p-values based on the DF from SAS, and you can do so.  If
you want a SAS independent solution, you can get the DF from lme() and
use those with gls().

Doug Bates has removed DF calculations from his more recent package,
lme4 which is sort of the new nlme, so the precedent is actually for
not providing any, leaving to the user to choose sensibly.  Finally
because new development is happening in lme4 not nlme, I rather doubt
any of the authors are going to want to put effort into altering code
in nlme (particularly because it could potentially break other code).

If you are doing this a lot and want a niceish interface, my
suggestion would be to hack the anova.gls() code to include
denominator DF, call it anovadf.gls() or something, and just put that
code in your .Rprofile so that function is always available to you.

Cheers,

Josh

On Tue, May 22, 2012 at 8:01 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Dr. Bates,
>
> After another thought, would it be possible to modify the gls source code to
> incorporate the same denDF calculation used in the lme function from this
> package?? I have been looking through the source code of the nlme package
> and by adding the denDF to the gls function I would solve my initial problem
> of having consistent F values and dfs.? However, I would prefer to work with
> one of the authors regarding any modification.? Perhaps I should contact R
> core mailing list?
>
> Regards,
> Charles
>
> On Mon, May 21, 2012 at 12:22 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> I don't really think there is a way of defining the degrees of freedom
>> for all lme and gls model fits so that they correspond to the
>> "correct" values, which often seems to mean the values returned by
>> SAS. ?If you feel that SAS provides the correct analysis in all cases
>> then you should use SAS. ?We can't reproduce the SAS results in R
>> because SAS is proprietary code and we don't know how those results
>> are calculated.
>>
>> The whole question of degrees of freedom for certain tests is very
>> complicated. ?Often there is no answer because the distribution of the
>> test statistic is not a t or an F distribution.
>>
>> On Mon, May 21, 2012 at 11:16 AM, Charles Determan Jr <deter088 at umn.edu>
>> wrote:
>> > Thank you for giving this some thought Joshua. ?I will be sure to keep
>> > troubleshooting this as well. ?Would it be related to how gls calculates
>> > its values that is somehow reports the 'correct' F value perhaps?
>> >
>> > Regards,
>> > Charles
>> >
>> > On Mon, May 21, 2012 at 11:08 AM, Joshua Wiley
>> > <jwiley.psych at gmail.com>wrote:
>> >
>> >> That suggests they are fitting different models somehow (not just that
>> >> the specifc effect estimates are different). ?No brilliant ideas on in
>> >> what way though...
>> >>
>> >> I checked REML versus ML but that was not it. ?I'll let you know if I
>> >> have any ideas.
>> >>
>> >> Cheers,
>> >>
>> >> Josh
>> >>
>> >> On Mon, May 21, 2012 at 9:02 AM, Charles Determan Jr <deter088 at umn.edu>
>> >> wrote:
>> >> > Hi Joshua,
>> >> >
>> >> > The -2 Log-likelihood from SAS is -58.6
>> >> > The log-likelihood from R fit.13 is 21.9. ?I assume this would be
>> >> multiplied
>> >> > by -2 which would give -43.8.
>> >> >
>> >> > Regards,
>> >> > Charles
>> >> >
>> >> >
>> >> > On Mon, May 21, 2012 at 10:02 AM, Joshua Wiley
>> >> > <jwiley.psych at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> Hi Charles,
>> >> >>
>> >> >> Out of curiosity, what is the log likelihood from SAS? ?Does it
>> >> >> match
>> >> >> that from lme()?
>> >> >>
>> >> >> logLik(fit.13)
>> >> >>
>> >> >> will give it to you.
>> >> >>
>> >> >> Cheers,
>> >> >>
>> >> >> Josh
>> >> >>
>> >> >> On Mon, May 21, 2012 at 5:45 AM, Charles Determan Jr
>> >> >> <deter088 at umn.edu>
>> >> >> wrote:
>> >> >> > Greetings R users,
>> >> >> >
>> >> >> >
>> >> >> > I am trying to match some SAS output of a mixed model. ?After
>> >> >> > running
>> >> >> > PROC
>> >> >> > MIXED with the covariance structure as AR1 the output below is
>> >> >> > given.
>> >> >> > ?Now
>> >> >> > when I try to replicate this with lme, I get the correct degrees
>> >> >> > of
>> >> >> > freedom
>> >> >> > and somewhat close values. ?If I try with gls, I get the exact F
>> >> >> > value
>> >> >> > but
>> >> >> > the incorrect denominator degrees of freedom. ?Is there some
>> >> >> > syntax or
>> >> >> > parameter I can adjust to get lme to have the same F values as
>> >> >> > gls?
>> >> >> > ?That
>> >> >> > way the correct degrees of freedom would be applied and I would
>> >> >> > get
>> >> the
>> >> >> > replicated model. ?The data is also included below. ?Thanks to any
>> >> >> > who
>> >> >> > can
>> >> >> > help with this issue.
>> >> >> >
>> >> >> >
>> >> >> > Regards,
>> >> >> >
>> >> >> > Charles
>> >> >> >
>> >> >> >
>> >> >> > Row ? ID Group Died Event_name ? ? ?var
>> >> >> > 1 ? ?12510 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.05257
>> >> >> > 2 ? ?12510 ? ? 3 ?YES ? ? ? ?S45 ? ?-1.00000
>> >> >> > 3 ? ?12510 ? ? 3 ?YES ? ? ? ?FR2 ? -1.14630
>> >> >> > 4 ? ?12510 ? ? 3 ?YES ? ? ? ?FR8 ? -1.08831
>> >> >> > 5 ? ?12510 ? ? 3 ?YES ? ? ? FR20 ? -1.03339
>> >> >> > 6 ? ?21510 ? ? 3 ? NO ? ? ? ? ?B ? ? ?-0.87290
>> >> >> > 7 ? ?21510 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.22185
>> >> >> > 8 ? ?21510 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.01592
>> >> >> > 9 ? ?21510 ? ? 3 ? NO ? ? ? ?FR8 ? ?-1.06550
>> >> >> > 10 ? 21510 ? ? 3 ? NO ? ? ? PR48 ? ?-0.65326
>> >> >> > 11 ? 22210 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.37059
>> >> >> > 12 ? 30810 ? ? 3 ? NO ? ? ? ? ?B ? ? -0.92959
>> >> >> > 13 ? 30810 ? ? 3 ? NO ? ? ? ?S45 ? ?-1.26680
>> >> >> > 14 ? 30810 ? ? 3 ? NO ? ? ? ?FR2 ? ?-0.99396
>> >> >> > 15 ? 30810 ? ? 3 ? NO ? ? ? ?FR8 ? ?-1.04769
>> >> >> > 16 ? 30810 ? ? 3 ? NO ? ? ? FR20 ? ?-1.04769
>> >> >> > 17 ? 31510 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.50585
>> >> >> > 18 ? 31510 ? ? 4 ?YES ? ? ? ?S45 ? ?-1.35262
>> >> >> > 19 ? 31510 ? ? 4 ?YES ? ? ? ?FR2 ? -1.26520
>> >> >> > 20 ? 31510 ? ? 4 ?YES ? ? ? ?FR8 ? ?-1.11407
>> >> >> > 21 ? 31510 ? ? 4 ?YES ? ? ? FR20 ? ?-0.97757
>> >> >> > 22 ? 40510 ? ? 2 ?YES ? ? ? ? ?B ? ? ?-1.04721
>> >> >> > 23 ? 40510 ? ? 2 ?YES ? ? ? ?S45 ? ? -1.13371
>> >> >> > 24 ? 51010 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ?-1.21467
>> >> >> > 25 ? 51010 ? ? 3 ? NO ? ? ? ?S45 ? ? ?-1.18177
>> >> >> > 26 ? 51010 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.23582
>> >> >> > 27 ? 51010 ? ? 3 ? NO ? ? ? ?FR8 ? ? -1.35262
>> >> >> > 28 ? 51010 ? ? 3 ? NO ? ? ? FR20 ? ?-0.69897
>> >> >> > 29 ? 51010 ? ? 3 ? NO ? ? ? PR48 ? ?-1.14086
>> >> >> > 30 ? 51710 ? ? 4 ? NO ? ? ? ? ?B ? ? ?-1.13371
>> >> >> > 31 ? 51710 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.24336
>> >> >> > 32 ? 51710 ? ? 4 ? NO ? ? ? ?FR2 ? ? -0.85201
>> >> >> > 33 ? 51710 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.72700
>> >> >> > 34 ? 51710 ? ? 4 ? NO ? ? ? FR20 ? ? -0.71220
>> >> >> > 35 ? 51710 ? ? 4 ? NO ? ? ? PR48 ? ? -1.10735
>> >> >> > 36 ? 51809 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.70752
>> >> >> > 37 ? 51809 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.58120
>> >> >> > 38 ? 51809 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.71332
>> >> >> > 39 ? 51809 ? ? 1 ? NO ? ? ? FR20 ? ? -0.37212
>> >> >> > 40 ? 61410 ? ? 4 ? NO ? ? ? ? ?B ? ? -1.25493
>> >> >> > 41 ? 61410 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.24949
>> >> >> > 42 ? 61410 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.18310
>> >> >> > 43 ? 61410 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.87517
>> >> >> > 44 ? 61410 ? ? 4 ? NO ? ? ? FR20 ? ? -0.34679
>> >> >> > 45 ? 61410 ? ? 4 ? NO ? ? ? PR48 ? ? -0.76472
>> >> >> > 46 ? 62110 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.34199
>> >> >> > 47 ? 62110 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.23657
>> >> >> > 48 ? 62110 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.20412
>> >> >> > 49 ? 62110 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.72011
>> >> >> > 50 ? 62110 ? ? 3 ? NO ? ? ? FR20 ? ? -0.72308
>> >> >> > 51 ? 62110 ? ? 3 ? NO ? ? ? PR48 ? ? -0.89688
>> >> >> > 52 ? 62209 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -0.74041
>> >> >> > 53 ? 62209 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.99183
>> >> >> > 54 ? 62209 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.06854
>> >> >> > 55 ? 62209 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.94386
>> >> >> > 56 ? 62209 ? ? 3 ? NO ? ? ? FR20 ? ? -0.38817
>> >> >> > 57 ? 71210 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.23657
>> >> >> > 58 ? 71210 ? ? 4 ?YES ? ? ? ?S45 ? ? -0.94808
>> >> >> > 59 ? 71309 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.14630
>> >> >> > 60 ? 71309 ? ? 4 ?YES ? ? ? ?S45 ? ? -1.10568
>> >> >> > 61 ? 71309 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.94462
>> >> >> > 62 ? 71309 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.89211
>> >> >> > 63 ? 71309 ? ? 4 ?YES ? ? ? FR20 ? ? -0.98970
>> >> >> > 64 ? 71309 ? ? 4 ?YES ? ? ? PR48 ? ? -0.83387
>> >> >> > 65 ? 81009 ? ? 4 ?YES ? ? ? ? ?B ? ? ? ? -1.15989
>> >> >> > 66 ? 81009 ? ? 4 ?YES ? ? ? ?S45 ? ? -0.93779
>> >> >> > 67 ? 81009 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.86710
>> >> >> > 68 ? 81009 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.69379
>> >> >> > 69 ? 81610 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -1.04769
>> >> >> > 70 ? 81610 ? ? 1 ? NO ? ? ? ?S45 ? ? -1.02780
>> >> >> > 71 ? 81610 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.96098
>> >> >> > 72 ? 81610 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.91829
>> >> >> > 73 ? 81610 ? ? 1 ? NO ? ? ? FR20 ? ? -0.68550
>> >> >> > 74 ? 81610 ? ? 1 ? NO ? ? ? PR48 ? ? -0.66374
>> >> >> > 75 ? 81709 ? ? 4 ?YES ? ? ? ? ?B ? ?-0.65521
>> >> >> > 76 ? 82410 ? ? 3 ? NO ? ? ? ? ?B ? ? -1.06702
>> >> >> > 77 ? 82410 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.30103
>> >> >> > 78 ? 82410 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.96617
>> >> >> > 79 ? 82410 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.84497
>> >> >> > 80 ? 82410 ? ? 3 ? NO ? ? ? FR20 ? ? -0.47716
>> >> >> > 81 ? 82410 ? ? 3 ? NO ? ? ? PR48 ? ? -0.68131
>> >> >> > 82 ? 91310 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.30803
>> >> >> > 83 ? 91310 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.07212
>> >> >> > 84 ? 91310 ? ? 4 ? NO ? ? ? ?FR2 ? ? -0.94615
>> >> >> > 85 ? 91310 ? ? 4 ? NO ? ? ? ?FR8 ? ? -1.29414
>> >> >> > 86 ? 91310 ? ? 4 ? NO ? ? ? FR20 ? ? -0.81304
>> >> >> > 87 ? 91310 ? ? 4 ? NO ? ? ? PR48 ? ? -0.86519
>> >> >> > 88 ? 91409 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.12321
>> >> >> > 89 ? 91409 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.08831
>> >> >> > 90 ? 91409 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.11862
>> >> >> > 91 ? 91409 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.87976
>> >> >> > 92 ? 91409 ? ? 4 ? NO ? ? ? FR20 ? ? -0.87517
>> >> >> > 93 ? 91409 ? ? 4 ? NO ? ? ? PR48 ? ? -0.68867
>> >> >> > 94 ? 92109 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.15120
>> >> >> > 95 ? 92109 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.99525
>> >> >> > 96 ? 92109 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.95429
>> >> >> > 97 ? 92109 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.54914
>> >> >> > 98 ? 92109 ? ? 3 ? NO ? ? ? FR20 ? ? -0.67264
>> >> >> > 99 ? 92109 ? ? 3 ? NO ? ? ? PR48 ? ? -0.74256
>> >> >> > 100 ?92110 ? ? 4 ?YES ? ? ? ? ?B ? ? -1.05012
>> >> >> > 101 ?92110 ? ? 4 ?YES ? ? ? ?S45 ? ? -1.14086
>> >> >> > 102 ?92110 ? ? 4 ?YES ? ? ? ?FR2 ? ? -0.91901
>> >> >> > 103 ?92110 ? ? 4 ?YES ? ? ? ?FR8 ? ? -0.80521
>> >> >> > 104 ?92110 ? ? 4 ?YES ? ? ? FR20 ? ? -0.88807
>> >> >> > 105 ?92710 ? ? 4 ? NO ? ? ? ? ?B ? ? ? ? -1.20412
>> >> >> > 106 ?92710 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.21325
>> >> >> > 107 ?92710 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.19518
>> >> >> > 108 ?92710 ? ? 4 ? NO ? ? ? ?FR8 ? ? -0.92959
>> >> >> > 109 ?92710 ? ? 4 ? NO ? ? ? FR20 ? ? -0.69315
>> >> >> > 110 ?92710 ? ? 4 ? NO ? ? ? PR48 ? ? -0.73779
>> >> >> > 111 100410 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.92300
>> >> >> > 112 100410 ? ? 1 ? NO ? ? ? ?S45 ? ? -1.07314
>> >> >> > 113 100410 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.80162
>> >> >> > 114 100410 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.63283
>> >> >> > 115 100410 ? ? 1 ? NO ? ? ? FR20 ? ? -0.73119
>> >> >> > 116 100410 ? ? 1 ? NO ? ? ? PR48 ? ? ?0.10102
>> >> >> > 117 101209 ? ? 3 ? NO ? ? ? ? ?B ? ? -1.24718
>> >> >> > 118 101209 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.00524
>> >> >> > 119 101209 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.01592
>> >> >> > 120 101209 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.85201
>> >> >> > 121 101209 ? ? 3 ? NO ? ? ? FR20 ? ? -0.51670
>> >> >> > 122 101209 ? ? 3 ? NO ? ? ? PR48 ? ? -0.72239
>> >> >> > 123 101909 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.13549
>> >> >> > 124 101909 ? ? 3 ? NO ? ? ? ?S45 ? ? -0.92665
>> >> >> > 125 101909 ? ? 3 ? NO ? ? ? ?FR2 ? ? -0.98548
>> >> >> > 126 101909 ? ? 3 ? NO ? ? ? ?FR8 ? ? -1.03152
>> >> >> > 127 101909 ? ? 3 ? NO ? ? ? FR20 ? ? -0.71715
>> >> >> > 128 101909 ? ? 3 ? NO ? ? ? PR48 ? ? -1.07935
>> >> >> > 129 102510 ? ? 2 ?YES ? ? ? ? ?B ? ? ? ? -1.30103
>> >> >> > 130 102510 ? ? 2 ?YES ? ? ? ?S45 ? ? -0.83387
>> >> >> > 131 110810 ? ? 3 ?YES ? ? ? ? ?B ? ? -1.21968
>> >> >> > 132 110810 ? ? 3 ?YES ? ? ? ?S45 ? ? -0.68048
>> >> >> > 133 110810 ? ? 3 ?YES ? ? ? ?FR2 ? ? -1.09474
>> >> >> > 134 110909 ? ? 2 ?YES ? ? ? ? ?B ? ? ? ? -1.09259
>> >> >> > 135 110909 ? ? 2 ?YES ? ? ? ?S45 ? ? -0.91293
>> >> >> > 136 111510 ? ? 3 ? NO ? ? ? ? ?B ? ? ? ? -1.39794
>> >> >> > 137 111510 ? ? 3 ? NO ? ? ? ?S45 ? ? -1.42366
>> >> >> > 138 111510 ? ? 3 ? NO ? ? ? ?FR2 ? ? -1.22621
>> >> >> > 139 111510 ? ? 3 ? NO ? ? ? ?FR8 ? ? -0.98885
>> >> >> > 140 111510 ? ? 3 ? NO ? ? ? FR20 ? ? -0.66055
>> >> >> > 141 111510 ? ? 3 ? NO ? ? ? PR48 ? ? -0.84497
>> >> >> > 142 111609 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.79942
>> >> >> > 143 111609 ? ? 1 ? NO ? ? ? ?S45 ? ? -0.87517
>> >> >> > 144 111609 ? ? 1 ? NO ? ? ? ?FR2 ? ? -0.74041
>> >> >> > 145 111609 ? ? 1 ? NO ? ? ? ?FR8 ? ? -0.64092
>> >> >> > 146 111609 ? ? 1 ? NO ? ? ? FR20 ? ? -0.53835
>> >> >> > 147 111609 ? ? 1 ? NO ? ? ? PR48 ? ? -0.68719
>> >> >> > 148 120610 ? ? 4 ? NO ? ? ? ? ?B ? ? -1.05110
>> >> >> > 149 120610 ? ? 4 ? NO ? ? ? ?S45 ? ? -1.45100
>> >> >> > 150 120610 ? ? 4 ? NO ? ? ? ?FR2 ? ? -1.21183
>> >> >> > 151 120610 ? ? 4 ? NO ? ? ? ?FR8 ? ? -1.04144
>> >> >> > 152 120610 ? ? 4 ? NO ? ? ? FR20 ? ? -0.61101
>> >> >> > 153 120610 ? ? 4 ? NO ? ? ? PR48 ? ? -0.81702
>> >> >> > 154 120709 ? ? 1 ? NO ? ? ? ? ?B ? ? ? ? -0.84497
>> >> >> > 155 120709 ? ? 1 ? NO ? ? ? ?S45 ? ? -0.99439
>> >> >> > 156 120709 ? ? 1 ? NO ? ? ? ?FR2 ? ? -1.13430
>> >> >> > 157 120709 ? ? 1 ? NO ? ? ? FR20 ? ? -0.57187
>> >> >> > 158 120709 ? ? 1 ? NO ? ? ? PR48 ? ? -0.80632
>> >> >> > 159 121310 ? ? 3 ?YES ? ? ? ? ?B ? ? ? ? -1.16115
>> >> >> > 160 121310 ? ? 3 ?YES ? ? ? ?S45 ? ? -1.18310
>> >> >> >
>> >> >> > dat=read.table("C:/?/subset.csv",sep=",",header=TRUE,
>> >> >> > na.strings=".")
>> >> >> >
>> >> >> > attach(dat)
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> > dat34=dat[Pig_group %in% c("3", "4"),]
>> >> >> >
>> >> >> > attach(dat34)
>> >> >> >
>> >> >> > dat34=within(dat34, {
>> >> >> >
>> >> >> > ? ? ? ? ? ? ? ? ? ?group=factor(group)
>> >> >> >
>> >> >> > ? ? ? ? ? ? ? ? ? ?Event_name=factor(Event_name)
>> >> >> >
>> >> >> > ? ? ? ? ? ? ? ? ? ?Died=factor(Died)
>> >> >> >
>> >> >> > ? ? ? ? ? ? ? ? ? ?ID=factor(ID)
>> >> >> >
>> >> >> > })
>> >> >> >
>> >> >> > attach(dat34)
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> > contrasts(dat34$Event_name)=contr.sum(n=6)
>> >> >> >
>> >> >> > contrasts(dat34$group)=contr.sum(n=2)
>> >> >> >
>> >> >> > contrasts(dat34$Died)=contr.sum(n=2)
>> >> >> >
>> >> >> >
>> >> >> > ?# What the results should be from SAS AR1 var
>> >> >> > #Type 3 Tests of Fixed Effects
>> >> >> > #Effect ? ? ? ? ?NumDF DenDF F Value Pr > F
>> >> >> > #Event_name ? ? ?5 ? 91 ? ?7.43 ? ?<.0001
>> >> >> > #Died ? ? ? ? ? ? ?1 ? 24 ? ?0.08 ? ?0.7756
>> >> >> > #Event_name*Died 5 ? 91 ? ?3.09 ? ?0.0128
>> >> >> >
>> >> >> > fit.13=lme(var~Event_name*Died,
>> >> >> > ? ?data=liver34,
>> >> >> > ? ?random=~1|ID,
>> >> >> > ? ?corr=corAR1())
>> >> >> > anova(fit.13, type="marginal", adjustSigma=F)
>> >> >> > # ? ? ? ? ? ? ? ? ? ?numDF denDF ? F-value p-value
>> >> >> > #(Intercept) ? ? ? ? ? ? 1 ? ?91 1342.7364 ?<.0001
>> >> >> > #Event_name ? ? ? ? ?5 ? ?91 ? ?8.7143 ?<.0001
>> >> >> > #Died ? ? ? ? ? ? ? ? ? ?1 ? ?24 ? ?0.0527 ?0.8204
>> >> >> > #Event_name:Died ? ? 5 ? ?91 ? ?3.0909 ?0.0127
>> >> >> >
>> >> >> > ######################################################
>> >> >> > ###THIS DOES IT but not lme function (need dfs)
>> >> >> > fit.16=gls(var~Event_name*Died,
>> >> >> > ? ?data=liver34,
>> >> >> > ? ?corr=corAR1(, ~1|ID))
>> >> >> > anova(fit.16, type="marginal", adjustSigma=F)
>> >> >> > #Denom. DF: 115
>> >> >> > # ? ? ? ? ? ? ? ? ? ?numDF ? F-value p-value
>> >> >> > #(Intercept) ? ? ? ? ? ? 1 1496.9032 ?<.0001
>> >> >> > #Event_name ? ? ? ? ?5 ? ?7.4304 ?<.0001
>> >> >> > #Died ? ? ? ? ? ? ? ? ? ?1 ? ?0.0831 ?0.7736
>> >> >> > #Event_name:Died ? ? 5 ? ?3.0871 ?0.0119
>> >> >> >
>> >> >> > ?#Give exact replicated answers
>> >> >> > 1-pf(7.4304, 5, 91)
>> >> >> > 1-pf(.0831, 1, 24)
>> >> >> > 1-pf(3.0871, 5, 91)
>> >> >> > #######################################################
>> >> >> >
>> >> >> > ? ? ? ?[[alternative HTML version deleted]]
>> >> >> >
>> >> >> >
>> >> >> > _______________________________________________
>> >> >> > R-sig-mixed-models at r-project.org mailing list
>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >> >
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Joshua Wiley
>> >> >> Ph.D. Student, Health Psychology
>> >> >> Programmer Analyst II, Statistical Consulting Group
>> >> >> University of California, Los Angeles
>> >> >> https://joshuawiley.com/
>> >> >
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >> Joshua Wiley
>> >> Ph.D. Student, Health Psychology
>> >> Programmer Analyst II, Statistical Consulting Group
>> >> University of California, Los Angeles
>> >> https://joshuawiley.com/
>> >>
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From deter088 at umn.edu  Tue May 22 17:50:13 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 22 May 2012 10:50:13 -0500
Subject: [R-sig-ME] 2nd attempt - conflict of dfs or f value in lme
In-Reply-To: <CANz9Z_+c4-n22sQyx=nFeRo1dqBKmWMu7Gpo8S9k3V_Z-g4S8g@mail.gmail.com>
References: <CAOLJphnX04+ORe_qF9F86jYsc=18V_-1quhY8f86E_5CWdLEHw@mail.gmail.com>
	<CANz9Z_JLQisjZH+MLvKfL8S_DmjP95N3DSaXrJOCRwNYrWM0Fg@mail.gmail.com>
	<CAOLJph=d-mPbMfkM2z9HXcOrviNz1Vf1rVXLy-xtmLaeaT1MOQ@mail.gmail.com>
	<CANz9Z_KsXV02LNNFYfvObsAZRZ4tSh4_fDV9gHjsEPwa3UnbeQ@mail.gmail.com>
	<CAOLJph=+AiV7YKXDPRVExbjcEU-qQcg0QPgnvMDQ3u-kevgiaA@mail.gmail.com>
	<CAO7JsnRGYz6UZVvhOuqd8j_UOGSV0E0N3Pbh8qOBB2CJ2TSUEA@mail.gmail.com>
	<CAOLJphkVfNio+dO3CWEEncsFzh1LukyKfy9xu0aK+jB1KRwh3Q@mail.gmail.com>
	<CANz9Z_+c4-n22sQyx=nFeRo1dqBKmWMu7Gpo8S9k3V_Z-g4S8g@mail.gmail.com>
Message-ID: <CAOLJphktjmNZ-cZLub6QyhzQWw_-vmtOgUjYoPOu8g0sGBK8eA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120522/f1e91e2f/attachment.pl>

From gangchen6 at gmail.com  Tue May 22 19:56:16 2012
From: gangchen6 at gmail.com (Gang Chen)
Date: Tue, 22 May 2012 13:56:16 -0400
Subject: [R-sig-ME] How to obtain t-values from mer objects
Message-ID: <CAHmzXO6g_zF14vbOodmYLV+jZ2XHnyi-XTXW4wc3BW0AOg0mnw@mail.gmail.com>

I know how to obtain the fixed effects from a mer object:

> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))

> fixef(fm1)

or,

> getME(fm1, 'beta')

But how can I obtain the t-statistic values for the fixed effects?

Thanks,
Gang


From agalecki at umich.edu  Tue May 22 20:21:02 2012
From: agalecki at umich.edu (Andrzej)
Date: Tue, 22 May 2012 14:21:02 -0400
Subject: [R-sig-ME] How to obtain t-values from mer objects
In-Reply-To: <CAHmzXO6g_zF14vbOodmYLV+jZ2XHnyi-XTXW4wc3BW0AOg0mnw@mail.gmail.com>
References: <CAHmzXO6g_zF14vbOodmYLV+jZ2XHnyi-XTXW4wc3BW0AOg0mnw@mail.gmail.com>
Message-ID: <4FBBD90E.3010302@umich.edu>

Try summary(fm1)

Andrzej

On 5/22/2012 1:56 PM, Gang Chen wrote:

I know how to obtain the fixed effects from a mer object:


> (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))

fixef(fm1)

or,


> getME(fm1, 'beta')
But how can I obtain the t-statistic values for the fixed effects?

Thanks,
Gang


From gangchen at mail.nih.gov  Tue May 22 20:35:04 2012
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 22 May 2012 14:35:04 -0400
Subject: [R-sig-ME] How to obtain t-values from mer objects
In-Reply-To: <4FBBD90E.3010302@umich.edu>
References: <CAHmzXO6g_zF14vbOodmYLV+jZ2XHnyi-XTXW4wc3BW0AOg0mnw@mail.gmail.com>
	<4FBBD90E.3010302@umich.edu>
Message-ID: <CAHmzXO7yk0n5qmyfgCwuAEhhbZdE6LQaEDZdWCKMZwW7+EQC5g@mail.gmail.com>

Sorry I should have stated a little clearer.

I do know how to see or print the t-statistic values at the R prompt.
What I meant to ask is how to extract the t-statistic values from the
mer slots.

Gang

On Tue, May 22, 2012 at 2:21 PM, Andrzej <agalecki at umich.edu> wrote:
> Try summary(fm1)
>
> Andrzej
>
> On 5/22/2012 1:56 PM, Gang Chen wrote:
>
> I know how to obtain the fixed effects from a mer object:
>
>> (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>
> fixef(fm1)
>
> or,
>
>> getME(fm1, 'beta')
> But how can I obtain the t-statistic values for the fixed effects?
>
> Thanks,
> Gang


From roby.joehanes at nih.gov  Tue May 22 20:48:07 2012
From: roby.joehanes at nih.gov (Joehanes, Roby (NIH/NHLBI) [F])
Date: Tue, 22 May 2012 14:48:07 -0400
Subject: [R-sig-ME] How to obtain t-values from mer objects
In-Reply-To: <CAHmzXO7yk0n5qmyfgCwuAEhhbZdE6LQaEDZdWCKMZwW7+EQC5g@mail.gmail.com>
Message-ID: <CBE157A7.2034%joehanesr@mail.nih.gov>

How about

summary(fm1)@coefs[,3]

Or if you are using the next-generation lme4:
summary(fm1)$coef[,3]

Roby


On 5/22/12 2:35 PM, "Chen, Gang (NIH/NIMH) [C]" <gangchen at mail.nih.gov>
wrote:

> Sorry I should have stated a little clearer.
> 
> I do know how to see or print the t-statistic values at the R prompt.
> What I meant to ask is how to extract the t-statistic values from the
> mer slots.
> 
> Gang
> 
> On Tue, May 22, 2012 at 2:21 PM, Andrzej <agalecki at umich.edu> wrote:
>> Try summary(fm1)
>> 
>> Andrzej
>> 
>> On 5/22/2012 1:56 PM, Gang Chen wrote:
>> 
>> I know how to obtain the fixed effects from a mer object:
>> 
>>> (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>> 
>> fixef(fm1)
>> 
>> or,
>> 
>>> getME(fm1, 'beta')
>> But how can I obtain the t-statistic values for the fixed effects?
>> 
>> Thanks,
>> Gang
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From gangchen6 at gmail.com  Tue May 22 21:40:34 2012
From: gangchen6 at gmail.com (Gang Chen)
Date: Tue, 22 May 2012 15:40:34 -0400
Subject: [R-sig-ME] How to obtain t-values from mer objects
In-Reply-To: <CBE157A7.2034%joehanesr@mail.nih.gov>
References: <CAHmzXO7yk0n5qmyfgCwuAEhhbZdE6LQaEDZdWCKMZwW7+EQC5g@mail.gmail.com>
	<CBE157A7.2034%joehanesr@mail.nih.gov>
Message-ID: <CAHmzXO5GX1VG=dC9GMb7o7QwLW=Oxh87Ud8_EieAZzMyR5yjsA@mail.gmail.com>

Yes, that works well. Thanks a lot, Roby!

Gang


On Tue, May 22, 2012 at 2:48 PM, Joehanes, Roby (NIH/NHLBI) [F]
<roby.joehanes at nih.gov> wrote:
> How about
>
> summary(fm1)@coefs[,3]
>
> Or if you are using the next-generation lme4:
> summary(fm1)$coef[,3]
>
> Roby
>
>
> On 5/22/12 2:35 PM, "Chen, Gang (NIH/NIMH) [C]" <gangchen at mail.nih.gov>
> wrote:
>
>> Sorry I should have stated a little clearer.
>>
>> I do know how to see or print the t-statistic values at the R prompt.
>> What I meant to ask is how to extract the t-statistic values from the
>> mer slots.
>>
>> Gang
>>
>> On Tue, May 22, 2012 at 2:21 PM, Andrzej <agalecki at umich.edu> wrote:
>>> Try summary(fm1)
>>>
>>> Andrzej
>>>
>>> On 5/22/2012 1:56 PM, Gang Chen wrote:
>>>
>>> I know how to obtain the fixed effects from a mer object:
>>>
>>>> (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>>>
>>> fixef(fm1)
>>>
>>> or,
>>>
>>>> getME(fm1, 'beta')
>>> But how can I obtain the t-statistic values for the fixed effects?
>>>
>>> Thanks,
>>> Gang
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Tue May 22 22:25:32 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 22 May 2012 15:25:32 -0500
Subject: [R-sig-ME] How to obtain t-values from mer objects
In-Reply-To: <CBE157A7.2034%joehanesr@mail.nih.gov>
References: <CAHmzXO7yk0n5qmyfgCwuAEhhbZdE6LQaEDZdWCKMZwW7+EQC5g@mail.gmail.com>
	<CBE157A7.2034%joehanesr@mail.nih.gov>
Message-ID: <CAO7JsnQ7N+LDS_3zc8xhsqBb-o+nbG=zuhkArzSVg+8U7LPz1A@mail.gmail.com>

The preferred idiom is

coef(summary(fm1))

> library(lme4)
> fm1 <- lmer(Yield ~ 1|Batch, Dyestuff)
> str(coef(summary(fm1)))
 num [1, 1:3] 1527.5 19.4 78.8
 - attr(*, "dimnames")=List of 2
  ..$ : chr "(Intercept)"
  ..$ : chr [1:3] "Estimate" "Std. Error" "t value"

because it works in lme4.0 and the development lme4 (and for many
other types of fitted models too).

On Tue, May 22, 2012 at 1:48 PM, Joehanes, Roby (NIH/NHLBI) [F]
<roby.joehanes at nih.gov> wrote:
> How about
>
> summary(fm1)@coefs[,3]
>
> Or if you are using the next-generation lme4:
> summary(fm1)$coef[,3]
>
> Roby
>
>
> On 5/22/12 2:35 PM, "Chen, Gang (NIH/NIMH) [C]" <gangchen at mail.nih.gov>
> wrote:
>
>> Sorry I should have stated a little clearer.
>>
>> I do know how to see or print the t-statistic values at the R prompt.
>> What I meant to ask is how to extract the t-statistic values from the
>> mer slots.
>>
>> Gang
>>
>> On Tue, May 22, 2012 at 2:21 PM, Andrzej <agalecki at umich.edu> wrote:
>>> Try summary(fm1)
>>>
>>> Andrzej
>>>
>>> On 5/22/2012 1:56 PM, Gang Chen wrote:
>>>
>>> I know how to obtain the fixed effects from a mer object:
>>>
>>>> (fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>>>
>>> fixef(fm1)
>>>
>>> or,
>>>
>>>> getME(fm1, 'beta')
>>> But how can I obtain the t-statistic values for the fixed effects?
>>>
>>> Thanks,
>>> Gang
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue May 22 22:27:39 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 May 2012 20:27:39 +0000 (UTC)
Subject: [R-sig-ME] How to obtain t-values from mer objects
References: <CAHmzXO7yk0n5qmyfgCwuAEhhbZdE6LQaEDZdWCKMZwW7+EQC5g@mail.gmail.com>
	<CBE157A7.2034%joehanesr@mail.nih.gov>
	<CAHmzXO5GX1VG=dC9GMb7o7QwLW=Oxh87Ud8_EieAZzMyR5yjsA@mail.gmail.com>
Message-ID: <loom.20120522T222600-12@post.gmane.org>

Gang Chen <gangchen6 at ...> writes:

> 
> Yes, that works well. Thanks a lot, Roby!
> 
> Gang
> 
> On Tue, May 22, 2012 at 2:48 PM, Joehanes, Roby (NIH/NHLBI) [F]
> <roby.joehanes at ...> wrote:
> > How about
> >
> > summary(fm1)@coefs[,3]
> >
> > Or if you are using the next-generation lme4:
> > summary(fm1)$coef[,3]
> >

  Generally I think

  coef(summary(fm1))[,3]

 should allow you to get the t-statistics in either case,
*without* delving into the internal structure of the fitted model.
If you find that you consistently need to dig into the internals
of the fitted objects, you should ask on the list and/or ask
the maintainers to provide an appropriate accessor method ...

  (I will admit that I haven't tested this)

  Ben Bolker


From elebrija at hotmail.com  Wed May 23 05:35:21 2012
From: elebrija at hotmail.com (Edwin Lebrija Trejos)
Date: Wed, 23 May 2012 03:35:21 +0000
Subject: [R-sig-ME] Group level predictors in mixed models
Message-ID: <DUB108-W28DD0B9A96F552DB81B05D1030@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120523/43bd1e8e/attachment.pl>

From hbiaou at gmail.com  Wed May 23 10:22:32 2012
From: hbiaou at gmail.com (=?ISO-8859-1?Q?Samadori_Honor=E9_Biaou?=)
Date: Wed, 23 May 2012 09:22:32 +0100
Subject: [R-sig-ME] Group level predictors in mixed models
In-Reply-To: <DUB108-W28DD0B9A96F552DB81B05D1030@phx.gbl>
References: <DUB108-W28DD0B9A96F552DB81B05D1030@phx.gbl>
Message-ID: <CAGm8FZ2Xv1vc+qt25Tu6HxGMfFdMmh1jg_JmS2t67C1f6BwO=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120523/448238bf/attachment.pl>

From kheise at uke.uni-hamburg.de  Wed May 23 10:48:45 2012
From: kheise at uke.uni-hamburg.de (Kirstin-Friederike Heise)
Date: Wed, 23 May 2012 10:48:45 +0200
Subject: [R-sig-ME] fitting model for repeated measures cross-over
	design?
In-Reply-To: <07302261-9F9C-4A12-9FA6-9834190332EE@uke.uni-hamburg.de>
References: <07302261-9F9C-4A12-9FA6-9834190332EE@uke.uni-hamburg.de>
Message-ID: <C4AD7DD1-D6A7-49AD-BA4B-6FD9E642A66E@uke.uni-hamburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120523/aa15108d/attachment.pl>

From m.fairbrother at bristol.ac.uk  Thu May 24 16:23:50 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 24 May 2012 15:23:50 +0100
Subject: [R-sig-ME] fitting model for repeated measures cross-over
	design?
In-Reply-To: <mailman.5.1337853602.26197.r-sig-mixed-models@r-project.org>
References: <mailman.5.1337853602.26197.r-sig-mixed-models@r-project.org>
Message-ID: <1AD204CD-CD21-409A-A45B-95765A43D9D3@bristol.ac.uk>

Dear Kirstin,

If I've understood correctly, I'm pretty sure you want "ID/session" not "session/ID", because person-sessions are nested within persons.

And I don't think it makes sense to interact your linear and quadratic time effects (what would such an interaction mean?)? I would think this would make more sense:

factor(agegroup)*time_point*factor(stim.cond) + factor(agegroup)*time_point2*factor(stim.cond)

Even this will generate results that will be hard to interpret, with so many interactions? you'll need lots of plots of the expected outcome for different combinations of agegroup and stim.cond, versus time.

Good luck,
Malcolm



> Date: Wed, 23 May 2012 10:48:45 +0200
> From: Kirstin-Friederike Heise <kheise at uke.uni-hamburg.de>
> To: <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] fitting model for repeated measures cross-over
> 	design?
> Message-ID: <C4AD7DD1-D6A7-49AD-BA4B-6FD9E642A66E at uke.uni-hamburg.de>
> Content-Type: text/plain
> 
> Dear list members, 
> 
> since I am still struggling with building a linear mixed effects model, I will try to rephrase and specify my questions:
> 
> I am analyzing a transient treatment effect (treatment vs. placebo) in a cross-over experiment (2 sessions) in two groups (old, young participants) with repeated measurements (before, during, after treatment in minutes) for both treatment conditions on metric outcome variables. Since I expect a non-linear development of a possible treatment effect over time, I tried to include a quadratic polynomial for time. 
> 
> This is my data frame: 
> 
> data.frame':	5760 obs. of  21 variables:
> $ ID  [=subject level]       : Factor w/ 20 levels "OMI_01","OMI_02",..: 11 11 11 11 11 11 11 11 11 11 ...
> $ agegroup   : Factor w/ 2 levels "OLD     ","YOUNG   ": 2 2 2 2 2 2 2 2 2 2 ...
> $ session    : num  1 1 1 1 1 1 1 1 1 1 ...
> $ stim.cond [=treatment]: Factor w/ 2 levels "sham","tDCS": 1 1 1 1 1 1 1 1 1 1 ...
> $ time_point : num  -15 -15 -15 -15 -15 -15 -15 -15 -15 -15 ...
> $ time_point2: num  225 225 225 225 225 225 225 225 225 225 ...
> $ [log transformed ] outcome : num  NA 2.887 0.963 4.006 2.06 ...
> 
> Using nlme package, my current model looks like
> 
> summary(mR01A<- lme(lnSICIrest~factor(agegroup)*time_point*time_point2*factor(stim.cond),data=tDCSrest, random=~1|session/ID,na.action=na.exclude,method="REML"))
> 
> and 
> summary(mR01_corAR <- update(mR01, correlation = corAR1()))
> respectively.
> 
> 
> My questions are: 
> 1. Does the rather complex random effects structure is in any way reasonable or am I totally on the wrong path here?
> 
> 2. For the model with corAR1 correlation structure, 95% CI cannot be produced - the following error message is returned: "Cannot get confidence intervals on var-cov components: Non-positive definite approximate variance-covariance." 
> Is it necessary and appropriate in addition to specifying the random effects as above to account for the autocorrelation structure of the longitudinal data? Using anova to compare the models, I get a BIC change of -8.621 with a df increase of 2 when corAR1 correlation structure is added to the model. And if I do not need to include corAR1, would it be better to use the lme4 package or is it just a matter of taste?
> 
> 
> I would be very grateful for any thoughts and comments!
> 
> kirstin


From bmeyer at sozpsy.uzh.ch  Thu May 24 17:30:07 2012
From: bmeyer at sozpsy.uzh.ch (Bertolt Meyer)
Date: Thu, 24 May 2012 17:30:07 +0200
Subject: [R-sig-ME] Error in lme4 0.999902344-0: "Object 'multResp' not
	found" ?
Message-ID: <2DA280A7-0340-439B-BC9E-397E9583E9DB@sozpsy.uzh.ch>

Dear list,

The simplest random intercept model that I try to fit with the newest version of lme4 (0.999902344-0) throws an "Object 'multResp' not found" error on my Mac (Mac OSX 10.7.3, German R 2.15.0). Here is a reproducible example:

install.packages(c("minqa", "Rcpp"))
install.packages("lme4", repos="http://lme4.r-forge.r-project.org/repos")
library(lme4)

my_data <- read.csv("http://dl.dropbox.com/u/5384027/my_data.csv")
my_data$group <- as.factor(my_data$group)

# the data set consists of 97 four-person teams
# with two variables x and y observed on the individual
# level in each team

head(my_data)
#   X group        y          x
# 1 1     1 2.914286  -8.170984
# 2 2     1 2.746269 -13.504318
# 3 3     1 3.171429  -1.504318
# 4 4     1 2.978723  -4.837651
# 5 5     2 2.928571  -8.170984
# 6 6     2 2.987013   8.495682

mlmodel1_ri <- lmer(y ~ x + (1 | group), data = my_data)

# Fehler in lmer(y ~ x + (1 | group), data = my_data) : 
#   Objekt 'multResp' nicht gefunden

Does anyone know how to fix this?

Greetings,
Bertolt

-- 
Dr. Bertolt Meyer
Senior research and teaching associate
Social and Economic Psychology
Institute of Psychology, University of Zurich
Binzmuehlestrasse 14/13
CH-8050 Zurich
Switzerland

b.meyer at psychologie.uzh.ch


From elebrija at hotmail.com  Thu May 24 19:16:00 2012
From: elebrija at hotmail.com (Edwin Lebrija Trejos)
Date: Thu, 24 May 2012 17:16:00 +0000
Subject: [R-sig-ME] Group level predictors in mixed models
In-Reply-To: <mailman.5.1337767202.31894.r-sig-mixed-models@r-project.org>
References: <mailman.5.1337767202.31894.r-sig-mixed-models@r-project.org>
Message-ID: <DUB108-W36AA571F07CABA81AFBD24D1000@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120524/f45820b0/attachment.pl>

From bates at stat.wisc.edu  Thu May 24 20:17:16 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 May 2012 13:17:16 -0500
Subject: [R-sig-ME] Error in lme4 0.999902344-0: "Object 'multResp' not
 found" ?
In-Reply-To: <2DA280A7-0340-439B-BC9E-397E9583E9DB@sozpsy.uzh.ch>
References: <2DA280A7-0340-439B-BC9E-397E9583E9DB@sozpsy.uzh.ch>
Message-ID: <CAO7JsnQTkdQczORNOnx4Nb-p-2WVkZ1NixAPWpKsBeFgAFdEAQ@mail.gmail.com>

On Thu, May 24, 2012 at 10:30 AM, Bertolt Meyer <bmeyer at sozpsy.uzh.ch> wrote:
> Dear list,
>
> The simplest random intercept model that I try to fit with the newest version of lme4 (0.999902344-0) throws an "Object 'multResp' not found" error on my Mac (Mac OSX 10.7.3, German R 2.15.0). Here is a reproducible example:
>
> install.packages(c("minqa", "Rcpp"))
> install.packages("lme4", repos="http://lme4.r-forge.r-project.org/repos")
> library(lme4)
>
> my_data <- read.csv("http://dl.dropbox.com/u/5384027/my_data.csv")
> my_data$group <- as.factor(my_data$group)
>
> # the data set consists of 97 four-person teams
> # with two variables x and y observed on the individual
> # level in each team
>
> head(my_data)
> # ? X group ? ? ? ?y ? ? ? ? ?x
> # 1 1 ? ? 1 2.914286 ?-8.170984
> # 2 2 ? ? 1 2.746269 -13.504318
> # 3 3 ? ? 1 3.171429 ?-1.504318
> # 4 4 ? ? 1 2.978723 ?-4.837651
> # 5 5 ? ? 2 2.928571 ?-8.170984
> # 6 6 ? ? 2 2.987013 ? 8.495682
>
> mlmodel1_ri <- lmer(y ~ x + (1 | group), data = my_data)
>
> # Fehler in lmer(y ~ x + (1 | group), data = my_data) :
> # ? Objekt 'multResp' nicht gefunden
>
> Does anyone know how to fix this?

Not a problem on an Ubuntu system.  It may be something to do with the
version of the Mac OS X package on R-forge.  Ben is the person who
creates those and he is very busy right now with teaching obligations.
 Do you have the capability of compiling the source package?

Here are the results on an Ubuntu 12.04 system

> library(lme4)
Loading required package: lattice
Loading required package: Matrix
> str(my_data <- within(read.csv("http://dl.dropbox.com/u/5384027/my_data.csv"),
+                       group <- factor(group)))
'data.frame':	386 obs. of  4 variables:
 $ X    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ group: Factor w/ 97 levels "1","2","3","4",..: 1 1 1 1 2 2 2 2 3 3 ...
 $ y    : num  2.91 2.75 3.17 2.98 2.93 ...
 $ x    : num  -8.17 -13.5 -1.5 -4.84 -8.17 ...
> print(fm1 <- lmer(y ~ x + (1|group), my_data))
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ x + (1 | group)
   Data: my_data

REML criterion at convergence: 142.4097

Random effects:
 Groups   Name        Variance Std.Dev.
 group    (Intercept) 0.02075  0.1440
 Residual             0.06639  0.2577
Number of obs: 386, groups: group, 97

Fixed effects:
            Estimate Std. Error t value
(Intercept) 2.877840   0.019648  146.47
x           0.001337   0.001264    1.06

Correlation of Fixed Effects:
  (Intr)
x 0.002


From bbolker at gmail.com  Thu May 24 22:36:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 24 May 2012 20:36:10 +0000 (UTC)
Subject: [R-sig-ME] Error in lme4 0.999902344-0: "Object 'multResp' not
	found" ?
References: <2DA280A7-0340-439B-BC9E-397E9583E9DB@sozpsy.uzh.ch>
	<CAO7JsnQTkdQczORNOnx4Nb-p-2WVkZ1NixAPWpKsBeFgAFdEAQ@mail.gmail.com>
Message-ID: <loom.20120524T223323-277@post.gmane.org>

Douglas Bates <bates at ...> writes:

> 
> On Thu, May 24, 2012 at 10:30 AM, Bertolt Meyer <bmeyer at ...> wrote:
> > Dear list,
> >
> > The simplest random intercept model that I try to fit with 
> the newest version of lme4 (0.999902344-0)
> throws an "Object 'multResp' not found" error on my Mac
>  (Mac OSX 10.7.3, German R 2.15.0). Here is a
> reproducible example:
> >

  thanks for the notification.  I've just posted 0.999902345-0
to the repository (it may take up to 24 hours to appear), should
address this issue.
   I've also updated the source version on the repository
(i.e. http://lme4.r-forge.r-project.org/repos ) to this
version; the Windows version is a bit older, but current
source and Windows versions (unlike MacOS) should be available
from the standard package directory at http://r-forge.r-project.org
(i.e. install.packages("lme4",repos="http://r-forge.r-project.org"))

  Ben Bolker


From bmeyer at sozpsy.uzh.ch  Fri May 25 09:09:00 2012
From: bmeyer at sozpsy.uzh.ch (Bertolt Meyer)
Date: Fri, 25 May 2012 09:09:00 +0200
Subject: [R-sig-ME] Error in lme4 0.999902344-0: "Object 'multResp'
	not	found" ?
Message-ID: <B91DB419-72ED-4851-B6F5-237C0913A650@sozpsy.uzh.ch>

Ben Bolker <bbolker at ...> writes:

>  thanks for the notification.  I've just posted 0.999902345-0
> to the repository (it may take up to 24 hours to appear), should
> address this issue.

That does indeed solve the problem, thanks for the quick fix! A quick question: A colleague told me that this newest version of lme4 can do CIs for the parameter estimates of the fixed effects. Does that require bootMer() or is there another way?

Thanks again,
Bertolt

From bbolker at gmail.com  Fri May 25 16:40:44 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 25 May 2012 14:40:44 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Error_in_lme4_0=2E999902344-0=3A_=22Object_?=
	=?utf-8?b?J211bHRSZXNwJwlub3QJZm91bmQiID8=?=
References: <B91DB419-72ED-4851-B6F5-237C0913A650@sozpsy.uzh.ch>
Message-ID: <loom.20120525T152731-973@post.gmane.org>

Bertolt Meyer <bmeyer at ...> writes:

> 
> Ben Bolker <bbolker at ...> writes:
> 
> >  thanks for the notification.  I've just posted 0.999902345-0
> > to the repository (it may take up to 24 hours to appear), should
> > address this issue.
> 
> That does indeed solve the problem, thanks for the quick fix! 
> A quick question: A colleague told me that this
> newest version of lme4 can do CIs for the parameter estimates of 
> the fixed effects. Does that require
> bootMer() or is there another way?

  In principle yes; profiling a merMod (new-lme4) object creates
a profile object of class "thpr", which has a confint method.
The confidence intervals produced in this way are more accurate than
the Wald intervals implied by summary() (analogous to the difference
between confint.default() and confint.glm() applied to a glm() fit),
but are still based on Z-score/likelihood ratio test cutoffs, rather
than trying to do any kind of finite-size correction.  If you want
more accurate confidence intervals that incorporate the effects of
the sample size, then you'll need bootMer.

   However ... for GLMMs, we are still wrestling a bit with the
robustness of the fitting, which tends to be more of a problem
when profiling -- so it may not be practical to get profile
confidence intervals on GLMMs quite yet ...

  Ben Bolker


From ramos.grad.student at gmail.com  Sat May 26 01:09:52 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Fri, 25 May 2012 16:09:52 -0700
Subject: [R-sig-ME] error while trying to get predictions from a lme object
Message-ID: <CAHawB9sLhtS+aN1zmxrKuZ+fGbEXWeLDPGBK_sFaX7S0+=EPNg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120525/a6d2cb98/attachment.pl>

From ramos.grad.student at gmail.com  Sat May 26 02:29:35 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Fri, 25 May 2012 17:29:35 -0700
Subject: [R-sig-ME] Fwd: error while trying to get predictions from a lme
	object
In-Reply-To: <CAHawB9ue492WsaowWbGC7v+_wfj0CVfxH4QHYZDAktU=w0931Q@mail.gmail.com>
References: <CAHawB9ue492WsaowWbGC7v+_wfj0CVfxH4QHYZDAktU=w0931Q@mail.gmail.com>
Message-ID: <CAHawB9vwA=gqZqG0dhs-owLvjXCaqKwiT7+0dFva=e181Xk7-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120525/f98aec87/attachment.pl>

From Hugo.Mildenberger at web.de  Sat May 26 18:08:58 2012
From: Hugo.Mildenberger at web.de (Hugo.Mildenberger at web.de)
Date: Sat, 26 May 2012 18:08:58 +0200
Subject: [R-sig-ME] Fwd: error while trying to get predictions from a
 lme object
In-Reply-To: <CAHawB9vwA=gqZqG0dhs-owLvjXCaqKwiT7+0dFva=e181Xk7-Q@mail.gmail.com>
References: <CAHawB9ue492WsaowWbGC7v+_wfj0CVfxH4QHYZDAktU=w0931Q@mail.gmail.com>
	<CAHawB9vwA=gqZqG0dhs-owLvjXCaqKwiT7+0dFva=e181Xk7-Q@mail.gmail.com>
Message-ID: <20120526180858.491c8af4.hm@zotac.lan>

Antonio,

> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>   contrasts can be applied only to factors with 2 or more levels

this is probably a consequence of the variable 'ttd' being  
constantly zero.

Best


On Fri, 25 May 2012 17:29:35 -0700
"Antonio P. Ramos" <ramos.grad.student at gmail.com> wrote:

> ---------- Forwarded message ----------
> From: Antonio P. Ramos <ramos.grad.student at gmail.com>
> Date: Fri, May 25, 2012 at 5:29 PM
> Subject: error while trying to get predictions from a lme object
> To: Antonio Pedro Ramos <ramos.grad.student at gmail.com>
> 
> 
> Another example of the error I am taking about:
> 
> > # the variables from this models dependens
> > model <- lme(log(child_mortality) ~ as.factor(cluster)*time +
> +              my.new.time.one.transition.low.and.middle + ttd +
> +              maternal_educ+ log(IHME_id_gdppc) + hiv_prev-1,
> +              merged0,na.action=na.omit,method="ML",weights=varPower(form
> = ~ time),
> +              random= ~ time| country.x,
> +              correlation=corAR1(form = ~ time),
> +              control=lmeControl(msMaxIter = 200, msVerbose = TRUE))
> >
> 
> 
> > # create a toy data set
> > test.pred0 <-
>  expand.grid(time=20:29,country.x=c("Poland","Brazil","Argentina"))
> > z0 <-
> as.data.frame(cbind(my.new.time.one.transition.low.and.middle=c(0,0,0,0,0,0,1,2,3,4),
> +       ttd=c(0,0,0,0,0,0,1,0,0,0),
> +       maternal_educ=seq(from=10.0, to=12.0, length.out=10),
> +       IHME_id_gdppc=log(seq(from=5000, to=8000, length.out=10)),
> +       hiv_prev=rep(.005,10),cluster=rep("One Transition, Middle
> Income",10)))
> >
> > z <- rbind(z0,z0,z0)
> > test.pred <- cbind(test.pred0,z)
> > # check
> > head(test.pred)
>   time country.x my.new.time.one.transition.low.and.middle ttd
>  maternal_educ    IHME_id_gdppc hiv_prev
> 1   20    Poland                                         0   0
>   10 8.51719319141624    0.005
> 2   21    Poland                                         0   0
> 10.2222222222222 8.58173171255381    0.005
> 3   22    Poland                                         0   0
> 10.4444444444444 8.64235633437024    0.005
> 4   23    Poland                                         0   0
> 10.6666666666667 8.69951474821019    0.005
> 5   24    Poland                                         0   0
> 10.8888888888889 8.75358196948047    0.005
> 6   25    Poland                                         0   0
> 11.1111111111111 8.80487526386802    0.005
>                         cluster
> 1 One Transition, Middle Income
> 2 One Transition, Middle Income
> 3 One Transition, Middle Income
> 4 One Transition, Middle Income
> 5 One Transition, Middle Income
> 6 One Transition, Middle Income
> >
> # run the predictions
> > predict(model,test.pred,level=0)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>   contrasts can be applied only to factors with 2 or more levels
> 
> Thank you!
> 
> Antonio Pedro.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Hugo Mildenberger <hm at zotac.lan>


From john.mueller at louisville.edu  Sat May 26 19:59:28 2012
From: john.mueller at louisville.edu (Mueller,John Martin)
Date: Sat, 26 May 2012 17:59:28 +0000
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle a
 zero-inflated Poisson model for repeated measures?
Message-ID: <109E4F6374337D4C9153497DE5F3EEC51CA2A3E7@EXMBX07.ad.louisville.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120526/a471500e/attachment.pl>

From ramos.grad.student at gmail.com  Sat May 26 22:06:42 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Sat, 26 May 2012 13:06:42 -0700
Subject: [R-sig-ME] Fwd: error while trying to get predictions from a
	lme object
In-Reply-To: <20120526180858.491c8af4.hm@zotac.lan>
References: <CAHawB9ue492WsaowWbGC7v+_wfj0CVfxH4QHYZDAktU=w0931Q@mail.gmail.com>
	<CAHawB9vwA=gqZqG0dhs-owLvjXCaqKwiT7+0dFva=e181Xk7-Q@mail.gmail.com>
	<20120526180858.491c8af4.hm@zotac.lan>
Message-ID: <CAHawB9v9sJ9DFYUan=NP1_dNCuvDFbcquZYJi3m=Vg+AKfg6Aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120526/5af8249c/attachment.pl>

From bbolker at gmail.com  Sun May 27 00:59:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 26 May 2012 22:59:51 +0000 (UTC)
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle a
	zero-inflated Poisson model for repeated measures?
References: <109E4F6374337D4C9153497DE5F3EEC51CA2A3E7@EXMBX07.ad.louisville.edu>
Message-ID: <loom.20120527T005713-591@post.gmane.org>

Mueller,John Martin <john.mueller at ...> writes:

> 
> I am looking into which package to use in R to handle a
> zero-inflated Poisson model for repeated measures
> (growth curve analysis through multiple level modeling).
> 
> >From what I can tell, the lme4 package can handle
> the Poisson model and repeated measures but can't handle
> the zero-inflated Poisson model.  The pscl package can 
> handle the zero-inflate Poisson model but can't
> handle repeated measures.  And that leaves the glmmADMB package 
> as being the only package in R that can
> handle a zero-inflated Poisson model for repeated measure.

  Not quite: MCMCglmm can.  You can also use an expectation-maximization
wrapper to do zero-inflation with lme4 (if you're interested in this,
e-mail me).  It's possible that there are others.  
http://glmm.wikidot.com/pkg-comparison doesn't list any, but that
must be because I don't know about any others at the moment ...

> 
> Is this correct?  Or is there a package in R other than
>  the glmmADMB package that I should be considering?
> 
   I think glmmADMB should be fine.

> And if the glmmADMB package is the only package for this purpose,
> can the glmmADMB handle a 3-level
> multi-level model (hierarchical linear model)?

  Yes.
> 
> The model that I am working on has TIME at level 1, FIRMS at level 2,
>  and LOCATIONS (metropolitan statistical
> areas) at level 3.  The dependent variable at level 1 is a count
>  variable (number of credit sources used by a
> firm) which has an over dispersion of zeros at various points in time.  
> Thus, the reason why I am having to use
> a zero-inflated Poisson model (or I could use a hurdle model).

  I believe that both glmmADMB and MCMCglmm can do either zero-inflated
or hurdle models.


From highstat at highstat.com  Sun May 27 12:36:54 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sun, 27 May 2012 11:36:54 +0100
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle,
 a zero-inflated Poisson model for repeated measures?
In-Reply-To: <mailman.5.1338112802.21884.r-sig-mixed-models@r-project.org>
References: <mailman.5.1338112802.21884.r-sig-mixed-models@r-project.org>
Message-ID: <4FC203C6.6030303@highstat.com>





------------------------------

Message: 2
Date: Sat, 26 May 2012 17:59:28 +0000
From: "Mueller,John Martin"<john.mueller at louisville.edu>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle
	a zero-inflated Poisson model for repeated measures?
Message-ID:
	<109E4F6374337D4C9153497DE5F3EEC51CA2A3E7 at EXMBX07.ad.louisville.edu>
Content-Type: text/plain

I am looking into which package to use in R to handle a zero-inflated Poisson model for repeated measures (growth curve analysis through multiple level modeling).

> From what I can tell, the lme4 package can handle the Poisson model and repeated measures but can't handle the zero-inflated Poisson model.  The pscl package can handle the zero-inflate Poisson model but can't handle repeated measures.  And that leaves the glmmADMB package as being the only package in R that can handle a zero-inflated Poisson model for repeated measure.

Is this correct?  Or is there a package in R other than the glmmADMB package that I should be considering?

And if the glmmADMB package is the only package for this purpose, can the glmmADMB handle a 3-level multi-level model (hierarchical linear model)?

The model that I am working on has TIME at level 1, FIRMS at level 2, and LOCATIONS (metropolitan statistical areas) at level 3.  The dependent variable at level 1 is a count variable (number of credit sources used by a firm) which has an over dispersion of zeros at various points in time.  Thus, the reason why I am having to use a zero-inflated Poisson model (or I could use a hurdle model).

Thanks for your help.

- JM

	[[alternative HTML version deleted]]



------------------------------



John,
You can easily do this with R2WinBUGS and then in WinBUGS. See Chapter 4 of our 2012 book
in which we analyse 2-way nested data; R code is include. Extension to your 3-way nested data would be
an extra loop, plus an extra nesting level of the RE. It is also explained how you can calculate an
intraclass correlation for each level.

The choice between ZIP and hurdle depends on your underlying question.

Alain


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From armstrong.whit at gmail.com  Sun May 27 20:18:21 2012
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Sun, 27 May 2012 14:18:21 -0400
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle,
 a zero-inflated Poisson model for repeated measures?
In-Reply-To: <4FC203C6.6030303@highstat.com>
References: <mailman.5.1338112802.21884.r-sig-mixed-models@r-project.org>
	<4FC203C6.6030303@highstat.com>
Message-ID: <CAMi=pg4rOxqa4=7AVh2Fr9-WMavxdhWLscziD7Etgao1k3ib9g@mail.gmail.com>

If you care to upload an example BUGS model, I'll re-write the example
for rcppbugs and post it back.

Here is one example using the cbpp dataset:
https://github.com/armstrtw/rcppbugs.examples/blob/master/herd.r

-Whit


On Sun, May 27, 2012 at 6:36 AM, Highland Statistics Ltd
<highstat at highstat.com> wrote:
>
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 26 May 2012 17:59:28 +0000
> From: "Mueller,John Martin"<john.mueller at louisville.edu>
> To: "r-sig-mixed-models at r-project.org"
> ? ? ? ?<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle
> ? ? ? ?a zero-inflated Poisson model for repeated measures?
> Message-ID:
> ? ? ? ?<109E4F6374337D4C9153497DE5F3EEC51CA2A3E7 at EXMBX07.ad.louisville.edu>
> Content-Type: text/plain
>
> I am looking into which package to use in R to handle a zero-inflated
> Poisson model for repeated measures (growth curve analysis through multiple
> level modeling).
>
>> From what I can tell, the lme4 package can handle the Poisson model and
>> repeated measures but can't handle the zero-inflated Poisson model. ?The
>> pscl package can handle the zero-inflate Poisson model but can't handle
>> repeated measures. ?And that leaves the glmmADMB package as being the only
>> package in R that can handle a zero-inflated Poisson model for repeated
>> measure.
>
>
> Is this correct? ?Or is there a package in R other than the glmmADMB package
> that I should be considering?
>
> And if the glmmADMB package is the only package for this purpose, can the
> glmmADMB handle a 3-level multi-level model (hierarchical linear model)?
>
> The model that I am working on has TIME at level 1, FIRMS at level 2, and
> LOCATIONS (metropolitan statistical areas) at level 3. ?The dependent
> variable at level 1 is a count variable (number of credit sources used by a
> firm) which has an over dispersion of zeros at various points in time.
> ?Thus, the reason why I am having to use a zero-inflated Poisson model (or I
> could use a hurdle model).
>
> Thanks for your help.
>
> - JM
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
>
>
> John,
> You can easily do this with R2WinBUGS and then in WinBUGS. See Chapter 4 of
> our 2012 book
> in which we analyse 2-way nested data; R code is include. Extension to your
> 3-way nested data would be
> an extra loop, plus an extra nesting level of the RE. It is also explained
> how you can calculate an
> intraclass correlation for each level.
>
> The choice between ZIP and hurdle depends on your underlying question.
>
> Alain
>
>
> --
>
> Dr. Alain F. Zuur
> First author of:
>
> 1. Analysing Ecological Data (2007).
> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
> URL: www.springer.com/0-387-45967-7
>
>
> 2. Mixed effects models and extensions in ecology with R. (2009).
> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
>
>
> 3. A Beginner's Guide to R (2009).
> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
>
>
> 4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012)
> Zuur, Saveliev, Ieno.
> http://www.highstat.com/book4.htm
>
> Other books: http://www.highstat.com/books.htm
>
>
> Statistical consultancy, courses, data analysis and software
> Highland Statistics Ltd.
> 6 Laverock road
> UK - AB41 6FN Newburgh
> Tel: 0044 1358 788177
> Email: highstat at highstat.com
> URL: www.highstat.com
> URL: www.brodgar.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From john.mueller at louisville.edu  Mon May 28 00:45:22 2012
From: john.mueller at louisville.edu (Mueller,John Martin)
Date: Sun, 27 May 2012 22:45:22 +0000
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle a
 zero-inflated Poisson model for repeated measures?
Message-ID: <109E4F6374337D4C9153497DE5F3EEC51CA2B4F5@EXMBX07.ad.louisville.edu>

Ben, thanks for the quick reply.  I will try the glmmADMB package and see if I can get it to work for my analysis.  If the glmmADMB package doesn't work, I will let you know....as then I will either need to try the MCMCglmm package or the lme4 package with the expectation-maximization wrapper you mention. - JM

------------------------------

Message: 4
Date: Sat, 26 May 2012 22:59:51 +0000 (UTC)
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Is glmmADMB the only package in R which can handle a zero-inflated Poisson model for repeated measures?
Message-ID: <loom.20120527T005713-591 at post.gmane.org>
Content-Type: text/plain; charset=us-ascii



From fbarbero at bariloche.inta.gov.ar  Mon May 28 14:00:51 2012
From: fbarbero at bariloche.inta.gov.ar (fernando barbero)
Date: Mon, 28 May 2012 09:00:51 -0300
Subject: [R-sig-ME] Ordinal Package and post hoc test
Message-ID: <000001cd3cc9$87652be0$962f83a0$@inta.gov.ar>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120528/7ed9d3d6/attachment.pl>

From luke.mangaliso.duncan at gmail.com  Mon May 28 09:36:23 2012
From: luke.mangaliso.duncan at gmail.com (Luke Duncan)
Date: Mon, 28 May 2012 09:36:23 +0200
Subject: [R-sig-ME] Assessing interaction effects for GLMM
Message-ID: <CAE9UE+9memsfdabwXAC669-seFa3LNiEHVndGXc0LovGm0XJuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120528/edc88292/attachment.pl>

From gregor.hochschild at gmx.de  Mon May 28 15:29:47 2012
From: gregor.hochschild at gmx.de (gregor.hochschild at gmx.de)
Date: Mon, 28 May 2012 15:29:47 +0200
Subject: [R-sig-ME] problems installing the new lme4 (forthcoming 1.0) on
	Linux server
Message-ID: <20120528132947.128780@gmx.net>

Hi, the new version if lme4 looks great! It works perfectly on my own computer (Mac OSX 10.7) but I am having problems installing it on server without root access (I don't believe that the root access is the issue though). I installed the most recent R version, and followed the instructions here: http://lme4.r-forge.r-project.org/
Nothing worked though. Below are the error messages, the output from sessionInfo ans some more system info from the shell. Any ideas?

Thanks for the great package!
Greg



> install.packages("lme4",repos="http://r-forge.r-project.org")
Warning message:
package ?lme4? is not available (for R version 2.15.0) 

> install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")
long list of errors such as
predModule.h:98: error: expected ?,? or ?...? before ?&? token
...
external.cpp:950: error: ?NULL? was not declared in this scope
make: *** [external.o] Error 1
ERROR: compilation failed for package ?lme4?

> install.packages([LOC OF SOURCE], repos = NULL, type="source")
same as above


>sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.15.0



Linux [server] 2.6.18-238.12.1.el5 #1 SMP Tue May 31 13:22:04 EDT 2011 x86_64 x86_64 x86_64 GNU/Linux

-- 

Jetzt informieren: http://mobile.1und1.de/?ac=OM.PW.PW003K20328T7073a


From drmccloy at uw.edu  Mon May 28 19:07:00 2012
From: drmccloy at uw.edu (Dan McCloy)
Date: Mon, 28 May 2012 10:07:00 -0700
Subject: [R-sig-ME] theoretical question about random effects specifications
Message-ID: <CAOE0pYn9O5FKkdSGmqWAtP2YK3+=OcAL9t06Y9R4NKt6PLO=NQ@mail.gmail.com>

In psycholinguistic research, it seems to be common to have random
effects for both subjects (study participants) and items (stimulus
conditions).  I have a somewhat more complicated experiment, where
each stimulus involves one of 180 different sentences, read by one of
20 different talkers.  It is possible (indeed, likely) that responses
will cluster based on who the talker is, and it is also likely that
certain sentences are harder than others.  So the experimental design
would seem to demand random effects for listener, talker, and
sentence.  However, there is a distinct possibility that some
sentences are easy with some talkers and hard with other talkers
(i.e., due to dialect differences that are particularly strong for
certain words).  Question (1):  is it best to account for this
possibility by including a random effect for "stim" (i.e.,
talker-sentence pairing)?  Question (2):  if so, should I include the
separate random effects for talker and sentence in addition to "stim",
or is that redundant?  Question (3):  I've seen some models referenced
on this list and others that use what seem to be interactions between
random effects terms:  (1|x:y) or (1|x/y).  Is there a reference
somewhere where I could read up on these aspects of model
specification?  I tried running one or two of those, and they didn't
seem to behave like interactions between fixed effects (which I'm more
familiar with).


From bbolker at gmail.com  Mon May 28 22:22:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 28 May 2012 20:22:08 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?problems_installing_the_new_lme4_=28forthcom?=
	=?utf-8?q?ing_1=2E0=29_on=09Linux_server?=
References: <20120528132947.128780@gmx.net>
Message-ID: <loom.20120528T210739-598@post.gmane.org>

 <gregor.hochschild at ...> writes:

>  Hi, the new version if lme4 looks great! It works perfectly on my
> own computer (Mac OSX 10.7) but I am having problems installing it
> on server without root access (I don't believe that the root access
> is the issue though). I installed the most recent R version, and
> followed the instructions here: http://lme4.r-forge.r-project.org/
> Nothing worked though. Below are the error messages, the output from
> sessionInfo ans some more system info from the shell. Any ideas?

  Hmmm.  Do you have the latest versions of Rcpp and RcppEigen
installed?

> > install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")
> long list of errors such as
> predModule.h:98: error: expected ?,? or ?...? before ?&? token
> ...
> external.cpp:950: error: ?NULL? was not declared in this scope
> make: *** [external.o] Error 1
> ERROR: compilation failed for package ?lme4?

  Can you show the *beginning* of the list of errors?
  Can you give the results of gcc --version ?
  (That looks like a pretty old kernel -- I have 2.6.32-41 , and
I'm using a LTS Ubuntu release from 2 years ago ...)

> Linux [server] 2.6.18-238.12.1.el5 #1 SMP Tue May 31 13:22:04 EDT
> 2011 x86_64 x86_64 x86_64 GNU/Linux


From David.Duffy at qimr.edu.au  Tue May 29 01:07:25 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 29 May 2012 09:07:25 +1000 (EST)
Subject: [R-sig-ME] Ordinal Package and post hoc test
In-Reply-To: <000001cd3cc9$87652be0$962f83a0$@inta.gov.ar>
References: <000001cd3cc9$87652be0$962f83a0$@inta.gov.ar>
Message-ID: <Pine.LNX.4.64.1205290852540.32165@orpheus.qimr.edu.au>

On Mon, 28 May 2012, fernando barbero wrote:

>  fm1<-clmm(leaf~population+(1|population:family),data=d,threshold"flexible",
<            link="probit",Hess=TRUE)

> now I want to asses differences within populations, as visual inspection of
> the data suggests that one population has got more seedlings in the A
> category than the other 3 populations. I am thinking in something like the
> glht function of the multcomp package (tukey<-glht(fm1,

How about
pop1 <- d$population == "pop1"
fm2  <- clmm(leaf~ pop1 +(1|pop1:family), data=d,
              threshold"flexible", link="probit",Hess=TRUE)
anova(fm1, fm2), with or without a Bonferroni correction, or use AIC.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From Thierry.ONKELINX at inbo.be  Tue May 29 10:50:52 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 29 May 2012 08:50:52 +0000
Subject: [R-sig-ME] theoretical question about random effects
 specifications
In-Reply-To: <CAOE0pYn9O5FKkdSGmqWAtP2YK3+=OcAL9t06Y9R4NKt6PLO=NQ@mail.gmail.com>
References: <CAOE0pYn9O5FKkdSGmqWAtP2YK3+=OcAL9t06Y9R4NKt6PLO=NQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275D65A2F1@inbomail.inbo.be>

Dear Dan,

(1|x:y) and (1|x/y) are two different things. (1|x:y) is a random effect for every combination of x and y. Whereas (1|x/y) are two random effects: one for each level of x and one for each level of y nested in x. You can write is as (1|x) + (1|x:y). So note that is not equivalent to only (1|x:y)

Something like (1|listener) + (1|talker) + (1|sentence) + (1|talker:sentence) seems to be reasonable for your design. You could try (1|listener) + (1|talker) + (0 + talker|sentence) This allows for different variances per talker for the random effect of sentence. (1|talker:sentence) assumes that all those variances are equal. But using (0 + talker|sentence) comes at a high price: you'll need to estimate n * (1 + 1) / 2 parameters (with n the number of levels of talkers). So you'll need lots of date to support such a complicated model.

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Dan McCloy
Verzonden: maandag 28 mei 2012 19:07
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] theoretical question about random effects specifications

In psycholinguistic research, it seems to be common to have random effects for both subjects (study participants) and items (stimulus conditions).  I have a somewhat more complicated experiment, where each stimulus involves one of 180 different sentences, read by one of
20 different talkers.  It is possible (indeed, likely) that responses will cluster based on who the talker is, and it is also likely that certain sentences are harder than others.  So the experimental design would seem to demand random effects for listener, talker, and sentence.  However, there is a distinct possibility that some sentences are easy with some talkers and hard with other talkers (i.e., due to dialect differences that are particularly strong for certain words).  Question (1):  is it best to account for this possibility by including a random effect for "stim" (i.e., talker-sentence pairing)?  Question (2):  if so, should I include the separate random effects for talker and sentence in addition to "stim", or is that redundant?  Question (3):  I've seen some models referenced on this list and others that use what seem to be interactions between random effects terms:  (1|x:y) or (1|x/y).  Is there a reference somewhere where I could read up on these aspects of model specification?  I tried running one or two of those, and they didn't seem to behave like interactions between fixed effects (which I'm more familiar with).

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Thierry.ONKELINX at inbo.be  Tue May 29 10:58:11 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 29 May 2012 08:58:11 +0000
Subject: [R-sig-ME] Assessing interaction effects for GLMM
In-Reply-To: <CAE9UE+9memsfdabwXAC669-seFa3LNiEHVndGXc0LovGm0XJuQ@mail.gmail.com>
References: <CAE9UE+9memsfdabwXAC669-seFa3LNiEHVndGXc0LovGm0XJuQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275D65B374@inbomail.inbo.be>

Dear Luke,

A workaround is to first create a new variable for the interaction.

TimeTertile <- interaction(Time, Tertile, drop = TRUE)

And then use that variable in the model

m1 <- glmer(y ~ TimeTertile + (1|Individual) + (1|Zone) + Max + Min, family=binomial)

Please not that I use glmer() instead of lmer() which give some more clear code. At the moment, lmer() will call glmer() for you when family is not Gaussian.
Then you can run multicomp

Timetest <- glht(m1, linfct = mcp(TimeTertile = "Tukey"))

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Luke Duncan
Verzonden: maandag 28 mei 2012 9:36
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Assessing interaction effects for GLMM

Dear R gurus

I am running a GLMM that looks at whether chimpanzees spend time in shade more than sun (response variable 'y': used cbind() on counts in the sun and
shade) based on the time of day (Time) and the availability of shade (Tertile). I've included some random factors too which are the chimpanzee in question (Individual) and where they are in a given area (Zone). There are also two continuous predictors (Minimum daily temperature: Min; Maximum daily temperature: Max). I have run my GLMM and I know that Time and Min are significant predictors of the patterns of shade use while Tertile and Max are not. In addition, a Time*Tertile interaction effect is a good predictor as well.

I now need to assess how the specific interaction effect conditions differ to one another. So, for example, how does shade use differ between 10h00 at low shade and 10h00 at high shade? I tried using the package multcomp, but that will only allow me to work out the contrasts for the first-order effects (Time, Tertile) but won't allow me to do so for the interaction effect (Time*Tertile). Any ideas?

My code:

> m1 <- lmer(y ~ Time*Tertile + (1|Individual) + (1|Zone) + Max +
Min,family=binomial,REML=F)
> Anova(m1,type=3,test="Wald")
Analysis of Deviance Table (Type III tests)

Response: y
               Chisq Df Pr(>Chisq)
(Intercept)   0.9511  1     0.3294
Time         60.7807  4  1.988e-12 ***
Tertile       0.3391  1     0.5603
Max           1.3198  1     0.2506
Min          77.7736  1  < 2.2e-16 ***
Time:Tertile 38.9038  4  7.292e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> summary(m1)
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ Time * Tertile + (1 | Individual) + (1 | Zone) + Max + Min
  AIC  BIC logLik deviance
 1168 1224 -569.9     1140
Random effects:
 Groups     Name        Variance Std.Dev.
 Zone       (Intercept) 0.81949  0.90526
 Individual (Intercept) 0.36417  0.60347 Number of obs: 412, groups: Zone, 8; Individual, 7

 Fixed effects:
                     Estimate Std. Error z value Pr(>|z|)
(Intercept)           0.77498    0.79465   0.975 0.329439
Time11h00            -1.54259    0.24351  -6.335 2.38e-10 ***
Time12h00             0.01695    0.77829   0.022 0.982627
Time13h00            -4.26913    0.78217  -5.458 4.81e-08 ***
Time14h00            -1.34503    0.43831  -3.069 0.002150 **
TertileLow            0.32614    0.56003   0.582 0.560323
Max                   0.03751    0.03265   1.149 0.250630
Min                  -0.30912    0.03505  -8.819  < 2e-16 ***
Time11h00:TertileLow  1.03079    0.28579   3.607 0.000310 ***
Time12h00:TertileLow -2.26187    0.79930  -2.830 0.004658 **
Time13h00:TertileLow  2.38129    0.79214   3.006 0.002646 **
Time14h00:TertileLow  1.72263    0.49397   3.487 0.000488 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) Tm1100 Tm1200 Tm1300 Tm1400 TrtlLw Max    Min    T1100:
Time11h00   -0.026
Time12h00   -0.035  0.177
Time13h00   -0.004  0.223  0.068
Time14h00   -0.073  0.259  0.081  0.103
TertileLow  -0.450  0.153  0.043  0.051  0.097
Max         -0.711 -0.169 -0.004 -0.061 -0.023  0.019
Min          0.146  0.186  0.014  0.055  0.099 -0.036 -0.455
Tm11h00:TrL  0.059 -0.851 -0.153 -0.190 -0.222 -0.198  0.096 -0.155 Tm12h00:TrL  0.095 -0.160 -0.974 -0.062 -0.081 -0.067 -0.079  0.012  0.192 Tm13h00:TrL  0.026 -0.208 -0.067 -0.983 -0.099 -0.075  0.024 -0.026  0.229 Tm14h00:TrL  0.126 -0.215 -0.069 -0.088 -0.876 -0.185 -0.047  0.006  0.254
            T1200: T1300:
Time11h00
Time12h00
Time13h00
Time14h00
TertileLow
Max
Min
Tm11h00:TrL
Tm12h00:TrL
Tm13h00:TrL  0.081
Tm14h00:TrL  0.098  0.116

> Timetest <- glht(m1, linfct = mcp(Time = "Tukey"))
Warning message:
In mcp2matrix(model, linfct = linfct) :
  covariate interactions found -- default contrast might be inappropriate
> Timecld<-cld(Timetest)
> Timecld
11h00 12h00 13h00 14h00 10h00
  "a"  "ab"   "c"   "a"   "b"
> summary(Timetest)

         Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: glmer(formula = y ~ Time * Tertile + (1 | Individual) + (1 |
    Zone) + Max + Min, family = binomial, REML = F)

Linear Hypotheses:
                   Estimate Std. Error z value Pr(>|z|)
11h00 - 10h00 == 0 -1.54259    0.24351  -6.335  < 0.001 ***
12h00 - 10h00 == 0  0.01695    0.77829   0.022  1.00000
13h00 - 10h00 == 0 -4.26913    0.78217  -5.458  < 0.001 ***
14h00 - 10h00 == 0 -1.34503    0.43831  -3.069  0.01497 *
12h00 - 11h00 == 0  1.55954    0.77322   2.017  0.22656
13h00 - 11h00 == 0 -2.72654    0.76570  -3.561  0.00285 **
14h00 - 11h00 == 0  0.19756    0.44278   0.446  0.99024
13h00 - 12h00 == 0 -4.28608    1.06546  -4.023  < 0.001 ***
14h00 - 12h00 == 0 -1.36198    0.86161  -1.581  0.47037
14h00 - 13h00 == 0  2.92410    0.85641   3.414  0.00464 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 (Adjusted p values reported -- single-step method)

Luke Duncan

*Post-doctoral** Fellow*
*School of Animal, Plant and Environmental Sciences* *University of the Witwatersrand* *Johannesburg, South Africa*
**
*+27 11 717 6452*

        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From fbarbero at bariloche.inta.gov.ar  Tue May 29 14:56:56 2012
From: fbarbero at bariloche.inta.gov.ar (fernando barbero)
Date: Tue, 29 May 2012 09:56:56 -0300
Subject: [R-sig-ME] Ordinal Package and post hoc test
In-Reply-To: <Pine.LNX.4.64.1205290852540.32165@orpheus.qimr.edu.au>
References: <000001cd3cc9$87652be0$962f83a0$@inta.gov.ar>
	<Pine.LNX.4.64.1205290852540.32165@orpheus.qimr.edu.au>
Message-ID: <001c01cd3d9a$87329730$9597c590$@inta.gov.ar>

Hi David, thank you very much, what you are suggesting is a LRT between a
full model, with the four populations (fm1) and a reduced model (fm2) with
only one population? I understand the LRT approach, but I think that the
reduced model (fm2) should have 3 populations (pop2, pop3 and pop4), so I
can asses if there are differences between pop1 and the other three (then
with another reduced model, with pop1,pop3 and pop4 I could asses
differences between pop2 and the other ones, and like that I would test all
the populations), what do you think about this?
Fernando

-----Mensaje original-----
De: David Duffy [mailto:David.Duffy at qimr.edu.au] 
Enviado el: lunes, 28 de mayo de 2012 08:07 p.m.
Para: fernando barbero
CC: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Ordinal Package and post hoc test

On Mon, 28 May 2012, fernando barbero wrote:

>
fm1<-clmm(leaf~population+(1|population:family),data=d,threshold"flexible",
<            link="probit",Hess=TRUE)

> now I want to asses differences within populations, as visual inspection
of
> the data suggests that one population has got more seedlings in the A
> category than the other 3 populations. I am thinking in something like the
> glht function of the multcomp package (tukey<-glht(fm1,

How about
pop1 <- d$population == "pop1"
fm2  <- clmm(leaf~ pop1 +(1|pop1:family), data=d,
              threshold"flexible", link="probit",Hess=TRUE)
anova(fm1, fm2), with or without a Bonferroni correction, or use AIC.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
-----
Se certific? que el correo no contiene virus.
Comprobada por AVG - www.avg.es
Versi?n: 2012.0.1913 / Base de datos de virus: 2425/5030 - Fecha de la
versi?n: 29/05/2012


From David.Duffy at qimr.edu.au  Tue May 29 15:44:58 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 29 May 2012 23:44:58 +1000 (EST)
Subject: [R-sig-ME] Ordinal Package and post hoc test
In-Reply-To: <001c01cd3d9a$87329730$9597c590$@inta.gov.ar>
References: <000001cd3cc9$87652be0$962f83a0$@inta.gov.ar>
	<Pine.LNX.4.64.1205290852540.32165@orpheus.qimr.edu.au>
	<001c01cd3d9a$87329730$9597c590$@inta.gov.ar>
Message-ID: <Pine.LNX.4.64.1205292306070.30633@orpheus.qimr.edu.au>

On Tue, 29 May 2012, fernando barbero wrote:

>  I understand the LRT approach, but I think that the
> reduced model (fm2) should have 3 populations (pop2, pop3 and pop4), so I
> can asses if there are differences between pop1 and the other three (then
> with another reduced model, with pop1,pop3 and pop4 I could asses
> differences between pop2 and the other ones, and like that I would test all
> the populations), what do you think about this?

Sure, you can construct all possible subsets/contrasts "by hand" if you 
wish, and correct for multiple comparisons.

You might speak to a local statistician, as having thresholds and the 
populations as fixed and random effects complicates things (well I find it 
complicated!).  For example, differences in RE variances with equal means 
(in the middle category, say) for the populations appear as "spreading" of 
the thresholds ie proportions in Cats 1 and 3 are expected to increase or 
decrease in a nice way -- you should check whether the model is 
sensible.


From martin.eklund at ki.se  Mon May 28 18:41:20 2012
From: martin.eklund at ki.se (Martin Eklund)
Date: Mon, 28 May 2012 16:41:20 +0000
Subject: [R-sig-ME] large discrepancy between p-values from mcmc-sampling
	and t-test
Message-ID: <F21E0F8F-8630-4393-81D5-CB65A84A2898@ki.se>

Dear everyone,

My question concerns a large difference between p-values based on mcmc-sampling from a lmer model and those based on t-tests. I am fully aware of the fact that p-values based on t-tests are anti-conservative and that the mcmc-based ones therefore make more sense. However, the following example makes me slightly confused:

Data:

strata,method,y
1,A,1.023
2,A,1.051
3,A,1.025
4,A,1.03
5,A,1.055
6,A,1.116
7,A,1.108
8,A,1.245
9,A,0.983
10,A,1.174
1,B,1.086
2,B,1.074
3,B,1.095
4,B,1.13
5,B,1.089
6,B,1.186
7,B,1.083
8,B,1.293
9,B,1.015
10,B,1.225


Code:

library(lme4)
library(languageR)
test <- read.csv(file="testData.csv")	# Assuming the data above has been saved in a file called testData.csv
t.test(test$y[1:10], test$y[11:20], paired=T)
wilcox.test(test$y[1:10], test$y[11:20], paired=T)
M <- lmer(y ~ method+(1|strata), data=test)
pvalues <- pvals.fnc(M)
pvalues$fixed
barplot(test$y[1:10]-test$y[11:20])
binom.test(9, 10)	# 9 "successes" out of 10 trials, as seen in the barplot from the previous line

Note the significant results in all tests, except for the mcmc-based p-values in the lmer model. Even the sign test in the end result in a significant result, despite have relatively bad power (compared to the t-test and Wilcoxon test). My questions are: What may cause this large discrepancy in p-values based on the mcmc-sampling and the other tests? Can it simply be down to the small sample size? Would you in this case still trust the mcmc-sampling despite the fact that all other tests disagree with the p-value based on the mcmc?

Thank you very much!

Martin.

P.S. I'm not entirely sure if this is the right forum for this question. I would appreciate any pointers about where to ask this question if it is off-topic here. Thanks!



R version 2.15.0 (2012-03-30)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] sv_SE.ISO8859-1/sv_SE.ISO8859-1/sv_SE.ISO8859-1/C/sv_SE.ISO8859-1/sv_SE.ISO8859-1

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] nlme_3.1-104     languageR_1.4    lme4_0.999375-42 Matrix_1.0-6    
[5] lattice_0.20-6  

loaded via a namespace (and not attached):
[1] grid_2.15.0   stats4_2.15.0 tcltk_2.15.0  tools_2.15.0 


From karel.viaene at Ugent.be  Tue May 29 16:05:14 2012
From: karel.viaene at Ugent.be (Karel Viaene)
Date: Tue, 29 May 2012 16:05:14 +0200
Subject: [R-sig-ME] How to test if two gamm-predictions are significantly
	different?
Message-ID: <4FC4D79A.1000106@Ugent.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120529/9edd9603/attachment.pl>

From ewan.carr at gmail.com  Tue May 29 20:01:23 2012
From: ewan.carr at gmail.com (Ewan Carr)
Date: Tue, 29 May 2012 14:01:23 -0400
Subject: [R-sig-ME] Rescaling in MCMCglmm
Message-ID: <CAO8kXhU28_GAANUyFFvjpfsRnF8a3e-nH1fZqdp537Z5FvGDbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120529/3927f8c7/attachment.pl>

From chris at trickysolutions.com.au  Wed May 30 00:59:45 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Wed, 30 May 2012 08:59:45 +1000
Subject: [R-sig-ME] How to test if two gamm-predictions are
	significantly different?
In-Reply-To: <4FC4D79A.1000106@Ugent.be>
References: <4FC4D79A.1000106@Ugent.be>
Message-ID: <-8140022072580173265@unknownmsgid>

Rather than using 95% CI'S for the 2 curves U can try using a 90% CI
for them. If 2 90% CI'S don't overlap it's closer to a 5% t-test than
if 2 95% CI's don't.

But I think your other method for a 95% CI for the difference may be better.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 30/05/2012, at 0:09, Karel Viaene <karel.viaene at ugent.be> wrote:

> Dear R community,
>
> A quick sketch of my situation:
>
> I have two continuous explanatory variables ("concentration" and "time")
> and a continuous response variable, "biomass".
>
> I've fitted a gamm model to these data using the package mgcv and want
> to predict at what concentration the biomass is significantly different
> from the control treatment (i.e. a concentration of 0) for a given point
> in time.
>
> I've done this by predicting the biomass for a series of 1000
> concentrations at a given point in time (using "predict"), constructing
> 95% confidence intervals for these predictions by adding and subtracting
> 1.96*SE and then selecting the lowest concentration where the two CI
> show no overlap.
>
> However I've realized that this technique is not adequate because two
> points can also be significantly different at the 5% significance level
> when the 95% CI do overlap and I want to calculate the lowest possible
> concentration. I've read some literature about this and am considering
> the following method:
>
> * Calculate the difference between the control (C0) and a predicted
> point (e.g. C1), thus C0-C1.
> * Construct a 95% CI for this difference by adding and subtracting
> 1.96*sqrt(SE0^2 + SE1^2).
> * Do this for all predictions.
> * Select the lowest concentration where the 95% CI does not include 0.
>
> Could you give me some feedback about this as I'm unsure if this method
> can be used for gamms. Any comments or suggestions are much appreciated.
>
> Many thanks in advance & kind regards
>
> Karel
>
> --
> Karel Viaene
> Ghent University
> Laboratory of Environmental Toxicology and Aquatic Ecology
> Plateaustraat 22
> 9000 Ghent, Belgium
> tel: +32 (0) 9 264 3779
>
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From kfrost at wisc.edu  Wed May 30 02:54:47 2012
From: kfrost at wisc.edu (Kenneth Frost)
Date: Tue, 29 May 2012 19:54:47 -0500
Subject: [R-sig-ME] How to test if two gamm-predictions are
 significantly different?
In-Reply-To: <7540d55993297.4fc56fc7@wiscmail.wisc.edu>
References: <4FC4D79A.1000106@Ugent.be>
	<7580989191f56.4fc56f10@wiscmail.wisc.edu>
	<76808ed89420b.4fc56f4d@wiscmail.wisc.edu>
	<7690a62d9276f.4fc56f8a@wiscmail.wisc.edu>
	<7540d55993297.4fc56fc7@wiscmail.wisc.edu>
Message-ID: <7710806194ebe.4fc52987@wiscmail.wisc.edu>

Hi, Karel-

Could you provide a longer sketch of your situation? It is not clear to me what your control treatment is and how it relates to concentration or time.

Ken 

On 05/29/12, Karel Viaene  wrote:
> Dear R community,
> 
> A quick sketch of my situation:
> 
> I have two continuous explanatory variables ("concentration" and "time") 
> and a continuous response variable, "biomass".
> 
> I've fitted a gamm model to these data using the package mgcv and want 
> to predict at what concentration the biomass is significantly different 
> from the control treatment (i.e. a concentration of 0) for a given point 
> in time.
> 
> I've done this by predicting the biomass for a series of 1000 
> concentrations at a given point in time (using "predict"), constructing 
> 95% confidence intervals for these predictions by adding and subtracting 
> 1.96*SE and then selecting the lowest concentration where the two CI 
> show no overlap.
> 
> However I've realized that this technique is not adequate because two 
> points can also be significantly different at the 5% significance level 
> when the 95% CI do overlap and I want to calculate the lowest possible 
> concentration. I've read some literature about this and am considering 
> the following method:
> 
> * Calculate the difference between the control (C0) and a predicted 
> point (e.g. C1), thus C0-C1.
> * Construct a 95% CI for this difference by adding and subtracting 
> 1.96*sqrt(SE0^2 + SE1^2).
> * Do this for all predictions.
> * Select the lowest concentration where the 95% CI does not include 0.
> 
> Could you give me some feedback about this as I'm unsure if this method 
> can be used for gamms. Any comments or suggestions are much appreciated.
> 
> Many thanks in advance & kind regards
> 
> Karel
> 
> -- 
> Karel Viaene
> Ghent University
> Laboratory of Environmental Toxicology and Aquatic Ecology
> Plateaustraat 22
> 9000 Ghent, Belgium
> tel: +32 (0) 9 264 3779
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From David.Duffy at qimr.edu.au  Wed May 30 02:58:55 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 30 May 2012 10:58:55 +1000 (EST)
Subject: [R-sig-ME] large discrepancy between p-values from
	mcmc-samplingand t-test
In-Reply-To: <F21E0F8F-8630-4393-81D5-CB65A84A2898@ki.se>
References: <F21E0F8F-8630-4393-81D5-CB65A84A2898@ki.se>
Message-ID: <Pine.LNX.4.64.1205301044530.2036@orpheus.qimr.edu.au>

On Mon, 28 May 2012, Martin Eklund wrote:

> My question concerns a large difference between p-values based on 
> mcmc-sampling from a lmer model and those based on t-tests.

You are relying on mcmcsamp here, which like everything else has been 
affected by various revisions of the lme4 code.  I think some versions 
were giving wrong answers, which I'm pretty sure is the case here (I 
double-checked this running in JAGS, where the 95%HPD looks more 
sensible: est=0.047, 0.016-0.075).

Bugs model:

  model
    {
       for( k in 1 : P ) {
          for( i in 1 : N ) {
             Y[i , k] ~ dnorm(m[i , k], tau1)
             m[i , k] <- mu + T[i , k] * phi / 2 + delta[i]
             T[i , k] <- 2*k - 3
          }
       }
       for( i in 1 : N ) {
          delta[i] ~ dnorm(0.0, tau2)
       }
       tau1 ~ dgamma(0.001, 0.001) sigma1 <- 1 / sqrt(tau1)
       tau2 ~ dgamma(0.001, 0.001) sigma2 <- 1 / sqrt(tau2)
       mu ~ dnorm(0.0, 1.0E-6)
       phi ~ dnorm(0.0, 1.0E-6)
    }


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From karel.viaene at Ugent.be  Wed May 30 10:34:46 2012
From: karel.viaene at Ugent.be (Karel Viaene)
Date: Wed, 30 May 2012 10:34:46 +0200
Subject: [R-sig-ME] How to test if two gamm-predictions are
 significantly different?
In-Reply-To: <7710806194ebe.4fc52987@wiscmail.wisc.edu>
References: <4FC4D79A.1000106@Ugent.be>
	<7580989191f56.4fc56f10@wiscmail.wisc.edu>
	<76808ed89420b.4fc56f4d@wiscmail.wisc.edu>
	<7690a62d9276f.4fc56f8a@wiscmail.wisc.edu>
	<7540d55993297.4fc56fc7@wiscmail.wisc.edu>
	<7710806194ebe.4fc52987@wiscmail.wisc.edu>
Message-ID: <4FC5DBA6.3040109@Ugent.be>

Hi Ken,

the experimental design to which I've fitted the gamm is the following:

Small phytoplankton ecosystems to which a chemical was added (five 
different concentrations + one control treatment).
These ecosystems were followed up through time for 12 weeks. Each week 
the biomass and chemical concentration were calculated/measured.

The gamm I've fitted to this data: biomass = f(time, chemical 
concentration) + error structure

Now I want to determine the lowest chemical concentration where the 
biomass is significantly different from the control treatment, for a 
given point in time (e.g. in week 4, what is the lowest chemical 
concentration for which the biomass is significantly different from the 
control).

I hope this makes it more clear for you.

Karel

Op 30/05/2012 2:54, Kenneth Frost schreef:
> Hi, Karel-
>
> Could you provide a longer sketch of your situation? It is not clear to me what your control treatment is and how it relates to concentration or time.
>
> Ken
>
> On 05/29/12, Karel Viaene  wrote:
>> Dear R community,
>>
>> A quick sketch of my situation:
>>
>> I have two continuous explanatory variables ("concentration" and "time")
>> and a continuous response variable, "biomass".
>>
>> I've fitted a gamm model to these data using the package mgcv and want
>> to predict at what concentration the biomass is significantly different
>> from the control treatment (i.e. a concentration of 0) for a given point
>> in time.
>>
>> I've done this by predicting the biomass for a series of 1000
>> concentrations at a given point in time (using "predict"), constructing
>> 95% confidence intervals for these predictions by adding and subtracting
>> 1.96*SE and then selecting the lowest concentration where the two CI
>> show no overlap.
>>
>> However I've realized that this technique is not adequate because two
>> points can also be significantly different at the 5% significance level
>> when the 95% CI do overlap and I want to calculate the lowest possible
>> concentration. I've read some literature about this and am considering
>> the following method:
>>
>> * Calculate the difference between the control (C0) and a predicted
>> point (e.g. C1), thus C0-C1.
>> * Construct a 95% CI for this difference by adding and subtracting
>> 1.96*sqrt(SE0^2 + SE1^2).
>> * Do this for all predictions.
>> * Select the lowest concentration where the 95% CI does not include 0.
>>
>> Could you give me some feedback about this as I'm unsure if this method
>> can be used for gamms. Any comments or suggestions are much appreciated.
>>
>> Many thanks in advance&  kind regards
>>
>> Karel
>>
>> -- 
>> Karel Viaene
>> Ghent University
>> Laboratory of Environmental Toxicology and Aquatic Ecology
>> Plateaustraat 22
>> 9000 Ghent, Belgium
>> tel: +32 (0) 9 264 3779
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Thierry.ONKELINX at inbo.be  Wed May 30 12:12:41 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 30 May 2012 10:12:41 +0000
Subject: [R-sig-ME] [R] GLMMPQL spatial autocorrelation
In-Reply-To: <1338296751817-4631689.post@n4.nabble.com>
References: <1338296751817-4631689.post@n4.nabble.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275D65DF37@inbomail.inbo.be>

Dear Alex,

I'm cc'ing this to the mixed models list which is more appropriate for the question. Please send all follow up posts only to that list.

First a few more general remarks.
- You are using the data argument of glmmPQL. So there is no need to attach() the data.frame. I recommend avoid to use attach(). You will get into troubles with it, sooner or later...
- The correlation structures of the nlme package (which is used by glmmPQL), work on the residuals WITHIN the groups at the deepest levels of the random effects. So in your case only within individual sites. I guess that you are more interested in spatial correlation among sites than within sites.
- Adding a random intercept per site is equivalent of adding a compound symmetry correlation structure along site.
- which kind of residuals did you look at? You need the normalised one to see the effect of the correlation structure.

Then there is a more theoretical remark. Does a correlation structure on the residuals makes sense when using a binomial or poisson model? Compare is the formula notation of a (gaussian) linear (mixed) model with that of a generalised linear (mixed) model. You'll see that the lmm formula contains an epsilon term where the generalised version does not. This makes sense when you look at the distributions. The Gaussian distribution is defined by two parameters: mu (= combined effect of fixed and random effect) and sigma (the standard deviation of the epsilons). The binomial disitribution is only defined by one parameter: mu (= combined effect of fixed and random effect). It's variance depends on mu.
The correlation structures of nlme work on the epsilons, changing there joint distribution from i.i.d. (thus non correlated)  to the specified correlation structure. So how will that work on a generalised model where you have no epsilons?
Another reasoning is that a correlation struction in a gaussian models affects the variance (sigma) but not the mean (mu). But in binomial case those parameters are linked. So if the correlation structure has an effect on the variance then it must have an effect on the mean. And thus it will be conflicting with the fixed and random effects.

What IMHO would make sense for a generalised model are correlated random effects. E.g. the BLUPs of nearby sites have a stronger correlation than BLUPs of distant sites. Those kind of correlation structure are currently not available in neither nlme nor lme4.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Alexroyan
Verzonden: dinsdag 29 mei 2012 15:06
Aan: r-help at r-project.org
Onderwerp: [R] GLMMPQL spatial autocorrelation

Dear all,

I am experiencing problems using the glmmPQL function in the MASS package (Venables & Ripley 2002) to model binomial data with spatial autocorrelation.

My question  - is the presence of birds affected by various hydrological parameters?

Presence/absence data were collected from 83 sites and coupled against hydrological data from the same site. The bird survey sampling effort varied at each site so I want to include this as a random effect (fAVGNTS). I have also conducted a join count test which suggests that there is some spatial autocorrelation. Consequently I have used the following code:

library(MASS)
attach(Birds)
Birds$x <- Birds$LONGITUDE
Birds$y <- Birds$LATITUDE
M <- glmmPQL(PRESENCE~ HYDROVAR1 + HYDROVAR2, random=  ~ 1|fAVGNTS, correlation =  corExp(form = ~ x + y), family = binomial(link = "logit"), data = Birds)

The model seems to run fine. However, when I compare the results of this model and the residual spread against the same model but without the correlation function, there is absolutely no difference at all.

I am somewhat confused by this as both Dormann et al. 2007 and Bivand et al.
2008 have suggested the use of the glmmPQL function to model binomial data with spatial autocorrelation and random effects.

Therefore I am wondering if anyone knows why this has occurred and secondly I am wondering if the correlation function does indeed work outside of gls?

Many thanks in advance for your help.

Best regards

--
View this message in context: http://r.789695.n4.nabble.com/GLMMPQL-spatial-autocorrelation-tp4631689.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From john.mueller at louisville.edu  Wed May 30 16:58:49 2012
From: john.mueller at louisville.edu (Mueller,John Martin)
Date: Wed, 30 May 2012 14:58:49 +0000
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle,
 a zero-inflated Poisson model for repeated measures? (Whit
 Armstrong)
Message-ID: <109E4F6374337D4C9153497DE5F3EEC51CA2BB40@EXMBX07.ad.louisville.edu>

Whit, thanks for the reply.  I am going to try the glmmADMB package first.  If I can't get that to work, then I will move towards the Markov chain Monte Carlo / BUGS / rcppbugs option.  The BUGS option is something that I am not familiar with, so if I end up going that route (i.e. the glmmADMB package doesn't work), then it will be another learning curve for me to tackle :-)

- JM

------------------------------

Message: 2
Date: Sun, 27 May 2012 14:18:21 -0400
From: Whit Armstrong <armstrong.whit at gmail.com>
To: Highland Statistics Ltd <highstat at highstat.com>
Cc: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Is glmmADMB the only package in R which can
	handle, a zero-inflated Poisson model for repeated measures?
Message-ID:
	<CAMi=pg4rOxqa4=7AVh2Fr9-WMavxdhWLscziD7Etgao1k3ib9g at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

If you care to upload an example BUGS model, I'll re-write the example for rcppbugs and post it back.

Here is one example using the cbpp dataset:
https://github.com/armstrtw/rcppbugs.examples/blob/master/herd.r

-Whit


From john.mueller at louisville.edu  Wed May 30 17:03:51 2012
From: john.mueller at louisville.edu (Mueller,John Martin)
Date: Wed, 30 May 2012 15:03:51 +0000
Subject: [R-sig-ME] Is glmmADMB the only package in R which can handle,
 a zero-inflated Poisson model for repeated measures? (Highland
 Statistics Ltd)
Message-ID: <109E4F6374337D4C9153497DE5F3EEC51CA2BB52@EXMBX07.ad.louisville.edu>

Alain, thanks for the reply and links to your book.  I am going to try the glmmADMB option first.  Then if that doesn't work, I will look at the Markov Chain Monte Carlo / BUGS option. - JM

----------------------------------------------------------------------

Message: 1
Date: Sun, 27 May 2012 11:36:54 +0100
From: Highland Statistics Ltd <highstat at highstat.com>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Is glmmADMB the only package in R which can
	handle, a zero-inflated Poisson model for repeated measures?
Message-ID: <4FC203C6.6030303 at highstat.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed


------------------------------



John,
You can easily do this with R2WinBUGS and then in WinBUGS. See Chapter 4 of our 2012 book in which we analyse 2-way nested data; R code is include. Extension to your 3-way nested data would be an extra loop, plus an extra nesting level of the RE. It is also explained how you can calculate an intraclass correlation for each level.

The choice between ZIP and hurdle depends on your underlying question.

Alain


-- 

Dr. Alain F. Zuur


From nikko at hailmail.net  Wed May 30 18:08:47 2012
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Wed, 30 May 2012 09:08:47 -0700
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 65, Issue 68
In-Reply-To: <mailman.9422.1338339303.4540.r-sig-mixed-models@r-project.org>
References: <mailman.9422.1338339303.4540.r-sig-mixed-models@r-project.org>
Message-ID: <1338394127.17595.140661082772873.30627DD3@webmail.messagingengine.com>

Hi Karel
If you are using mgcv look at the help page for predict.gam. Simon has
examples
of several complex contrasts using the predict function. So to get
a confidence interval on the difference between two predictions you can
use the
predict function with type='lp'
from the predict.gam help page:
#########################################################
## now get variance of sum of predictions using lpmatrix
#########################################################
Xp <- predict(b,newd,type="lpmatrix") 

## Xp %*% coef(b) yields vector of predictions

a <- rep(1,31)
Xs <- t(a) %*% Xp ## Xs %*% coef(b) gives sum of predictions
var.sum <- Xs %*% b$Vp %*% t(Xs)
 
This is not the exact formula but it is close to what you want.

Nicholas
> Date: Tue, 29 May 2012 16:05:14 +0200
> From: Karel Viaene <karel.viaene at Ugent.be>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] How to test if two gamm-predictions are
> 	significantly	different?
> Message-ID: <4FC4D79A.1000106 at Ugent.be>
> Content-Type: text/plain
> 
> Dear R community,
> 
> A quick sketch of my situation:
> 
> I have two continuous explanatory variables ("concentration" and "time") 
> and a continuous response variable, "biomass".
> 
> I've fitted a gamm model to these data using the package mgcv and want 
> to predict at what concentration the biomass is significantly different 
> from the control treatment (i.e. a concentration of 0) for a given point 
> in time.
> 
> I've done this by predicting the biomass for a series of 1000 
> concentrations at a given point in time (using "predict"), constructing 
> 95% confidence intervals for these predictions by adding and subtracting 
> 1.96*SE and then selecting the lowest concentration where the two CI 
> show no overlap.
> 
> However I've realized that this technique is not adequate because two 
> points can also be significantly different at the 5% significance level 
> when the 95% CI do overlap and I want to calculate the lowest possible 
> concentration. I've read some literature about this and am considering 
> the following method:
> 
> * Calculate the difference between the control (C0) and a predicted 
> point (e.g. C1), thus C0-C1.
> * Construct a 95% CI for this difference by adding and subtracting 
> 1.96*sqrt(SE0^2 + SE1^2).
> * Do this for all predictions.
> * Select the lowest concentration where the 95% CI does not include 0.
> 
> Could you give me some feedback about this as I'm unsure if this method 
> can be used for gamms. Any comments or suggestions are much appreciated.
> 
> Many thanks in advance & kind regards
> 
> Karel
> 
> -- 
> Karel Viaene
> Ghent University
> Laboratory of Environmental Toxicology and Aquatic Ecology
> Plateaustraat 22
> 9000 Ghent, Belgium
> tel: +32 (0) 9 264 3779
>


From juliet.hannah at gmail.com  Wed May 30 22:44:01 2012
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Wed, 30 May 2012 16:44:01 -0400
Subject: [R-sig-ME] statistical basis for using mixed model in a situation
Message-ID: <CALzuZRS3MAAMTE_jweerSE+o-pUkqOk=AVr-jmpmryjCenCc-w@mail.gmail.com>

All,

Consider a simple two-group design in which one wants to test if the
means of these two groups are different. Assume a simple
t-test (un-paired) is sufficient. Let's say there are 10 samples in
Group A and 10 in group B.

Now, let's say each sample was measured in triplicate so that Group A
has 30 arising from 10 measured in triplicate.

Here is my question:

We could average the triplicates and proceed with the t-test.

But I have also observed people fitting a mixed model with a random
intercept for the triplicates.

What is the statistical basis for selecting one approach over the other?

Off the top of my head, this seems a little different from examples
such as students nested within classes and so on, but
I am unable to properly characterize it statistically.

Thanks,

Juliet


From john.maindonald at anu.edu.au  Thu May 31 02:31:36 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 31 May 2012 10:31:36 +1000
Subject: [R-sig-ME] statistical basis for using mixed model in a
	situation
In-Reply-To: <CALzuZRS3MAAMTE_jweerSE+o-pUkqOk=AVr-jmpmryjCenCc-w@mail.gmail.com>
References: <CALzuZRS3MAAMTE_jweerSE+o-pUkqOk=AVr-jmpmryjCenCc-w@mail.gmail.com>
Message-ID: <D6E96B5B-6861-41DA-957F-0FA791D4C754@anu.edu.au>

The two approaches (but doing the t-test with var.equal=TRUE) should 
give the same final result, unless the between sample component of
variance happens to be estimated to be zero. If you average the triplicates, 
you get output that is easier to interpret.  The t-test output will give you the 
number of degrees of freedom for the t-test.

Thinking in terms of averaging the triplicates hints at the possibility
that some other form of summary might in one or other circumstance
be preferable, e.g., work with a median.

The mixed model is needed if you want the variance information that, 
if it can be estimated with enough accuracy to be useful, allows 
prediction of the manner in which the SEDs will change when, e.g., 
each sample is measured 5 times. 

It is a "horses for courses" matter!

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 31/05/2012, at 6:44 AM, Juliet Hannah wrote:

> All,
> 
> Consider a simple two-group design in which one wants to test if the
> means of these two groups are different. Assume a simple
> t-test (un-paired) is sufficient. Let's say there are 10 samples in
> Group A and 10 in group B.
> 
> Now, let's say each sample was measured in triplicate so that Group A
> has 30 arising from 10 measured in triplicate.
> 
> Here is my question:
> 
> We could average the triplicates and proceed with the t-test.
> 
> But I have also observed people fitting a mixed model with a random
> intercept for the triplicates.
> 
> What is the statistical basis for selecting one approach over the other?
> 
> Off the top of my head, this seems a little different from examples
> such as students nested within classes and so on, but
> I am unable to properly characterize it statistically.
> 
> Thanks,
> 
> Juliet
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierces1 at msu.edu  Thu May 31 02:52:08 2012
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 30 May 2012 20:52:08 -0400
Subject: [R-sig-ME] statistical basis for using mixed model in
	a	situation
In-Reply-To: <D6E96B5B-6861-41DA-957F-0FA791D4C754@anu.edu.au>
References: <CALzuZRS3MAAMTE_jweerSE+o-pUkqOk=AVr-jmpmryjCenCc-w@mail.gmail.com>
	<D6E96B5B-6861-41DA-957F-0FA791D4C754@anu.edu.au>
Message-ID: <001701cd3ec7$9b5bef80$d213ce80$@msu.edu>

Here's a paper advocating for the simpler approach when the additional
parameters offered by the mixed model are not of intrinsic interest. 

Murtaugh, P. A. (2007). Simplicity and complexity in ecological data
analysis. Ecology, 88(1), 56-62. doi:
10.1890/0012-9658(2007)88[56:SACIED]2.0.CO;2

Anyone have example papers advocating for the other side of this issue?

Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: John Maindonald [mailto:john.maindonald at anu.edu.au] 
Sent: Wednesday, May 30, 2012 8:32 PM
To: Juliet Hannah
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] statistical basis for using mixed model in a
situation

The two approaches (but doing the t-test with var.equal=TRUE) should 
give the same final result, unless the between sample component of
variance happens to be estimated to be zero. If you average the triplicates,

you get output that is easier to interpret.  The t-test output will give you
the 
number of degrees of freedom for the t-test.

Thinking in terms of averaging the triplicates hints at the possibility
that some other form of summary might in one or other circumstance
be preferable, e.g., work with a median.

The mixed model is needed if you want the variance information that, 
if it can be estimated with enough accuracy to be useful, allows 
prediction of the manner in which the SEDs will change when, e.g., 
each sample is measured 5 times. 

It is a "horses for courses" matter!

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 31/05/2012, at 6:44 AM, Juliet Hannah wrote:

> All,
> 
> Consider a simple two-group design in which one wants to test if the
> means of these two groups are different. Assume a simple
> t-test (un-paired) is sufficient. Let's say there are 10 samples in
> Group A and 10 in group B.
> 
> Now, let's say each sample was measured in triplicate so that Group A
> has 30 arising from 10 measured in triplicate.
> 
> Here is my question:
> 
> We could average the triplicates and proceed with the t-test.
> 
> But I have also observed people fitting a mixed model with a random
> intercept for the triplicates.
> 
> What is the statistical basis for selecting one approach over the other?
> 
> Off the top of my head, this seems a little different from examples
> such as students nested within classes and so on, but
> I am unable to properly characterize it statistically.
> 
> Thanks,
> 
> Juliet
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From comtech.usa at gmail.com  Thu May 31 02:52:41 2012
From: comtech.usa at gmail.com (Michael)
Date: Wed, 30 May 2012 19:52:41 -0500
Subject: [R-sig-ME] Using R,
	how to present mixed models vs. regular linear regression models?
Message-ID: <CAPNjSFYVucW=HbXM_=wpn=Aw-vYYOOdaxSsQ4svgmzaSqhyfGw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120530/002b354a/attachment.pl>

From John.Morrongiello at csiro.au  Thu May 31 07:02:57 2012
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Thu, 31 May 2012 15:02:57 +1000
Subject: [R-sig-ME] HPD intervals for fixed parameters in model with crossed
 and correlated random effects
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB17D49998A9@exvic-mbx03.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120531/2cbc3336/attachment.pl>

From comtech.usa at gmail.com  Thu May 31 16:52:52 2012
From: comtech.usa at gmail.com (Michael)
Date: Thu, 31 May 2012 09:52:52 -0500
Subject: [R-sig-ME] Using R,
 how to present mixed models vs. regular linear regression models?
In-Reply-To: <CAPNjSFYVucW=HbXM_=wpn=Aw-vYYOOdaxSsQ4svgmzaSqhyfGw@mail.gmail.com>
References: <CAPNjSFYVucW=HbXM_=wpn=Aw-vYYOOdaxSsQ4svgmzaSqhyfGw@mail.gmail.com>
Message-ID: <CAPNjSFaCQK0aCCnZ1gs4KsdNdjC9t+OnKR7m47UjBCXuW2u=Jg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120531/42616b58/attachment.pl>

From pier.morel at gmail.com  Thu May 31 17:07:48 2012
From: pier.morel at gmail.com (Pierre Morel)
Date: Thu, 31 May 2012 17:07:48 +0200
Subject: [R-sig-ME] Problem in simulate() with GLMMs when a link function is
	specified ?
Message-ID: <014F3178-7D36-4F59-8ED1-C9BE60B68F16@gmail.com>

Dear all,

This is my first message to the list, I hope I won't start on the wrong foot !

I installed the last version of lme4 (0.999902345-0) and I think there is a problem in simulate() when trying to simulate a GLMM in which a link function was specified.
For example, this works (directly from the manual):

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd), data = cbpp, family = binomial)
gg <- simulate(gm1,10)

However, when you specify the link function for the binomial family (even if you keep the default one, logit), there is an error:

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd), data = cbpp, family = binomial(link="logit"))
gg <- simulate(gm1,10)

Error in simulate.merMod(gm1, 10) : 'family' not recognized

Not a problem if you want to use the default link, but I have psychophysics data for which I would like to use the mafc.logit(2) from the psyphy library.

When I look at the source code, even if I am not good enough in R programming to fix it, it seems that it should work with any link function, since the end result seems only used to get the inverse link function: 

	      etasim <- etasim.fix+etasim.reff
	      family <- object at call$family
	      if(is.symbol(family)) family <- as.character(family)
	      if(is.character(family))
		  family <- get(family, mode = "function", envir = parent.frame(2))
	      if(is.function(family)) family <- family()
	      if(is.null(family$family)) stop("'family' not recognized")
	      musim <- family$linkinv(etasim)

Any idea for a quick fix ?

Regards,

Pierre Morel

-- 
Dr. Pierre Morel
German Primate Center (DPZ)
Sensorimotor Research Group

From comtech.usa at gmail.com  Thu May 31 17:24:12 2012
From: comtech.usa at gmail.com (Michael)
Date: Thu, 31 May 2012 10:24:12 -0500
Subject: [R-sig-ME] Using R,
 how to present mixed models vs. regular linear regression models?
In-Reply-To: <CAPNjSFaCQK0aCCnZ1gs4KsdNdjC9t+OnKR7m47UjBCXuW2u=Jg@mail.gmail.com>
References: <CAPNjSFYVucW=HbXM_=wpn=Aw-vYYOOdaxSsQ4svgmzaSqhyfGw@mail.gmail.com>
	<CAPNjSFaCQK0aCCnZ1gs4KsdNdjC9t+OnKR7m47UjBCXuW2u=Jg@mail.gmail.com>
Message-ID: <CAPNjSFZ1p495osOKsbNEr2ATNYX==J2k6kt92SuqOFNVUiYamg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120531/039ce62a/attachment.pl>

From hans at sociologi.cjb.net  Thu May 31 17:35:42 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Thu, 31 May 2012 17:35:42 +0200
Subject: [R-sig-ME] getting between groups variance when using (1|x:y) in
	the formula
Message-ID: <4FC78FCE.7040604@sociologi.cjb.net>

Let's say I have a formula like this

my.fit <- glmer(w ~ 1 + y + (1|x) + (1|x:y) + z)

Then the summary() output gives information about variance and std.dev 
for the random term x:y

and ranef(my.fit, postVar = TRUE) gives estimates and standard 
deviations for x and each value of x:y.

Is there a way to get a single measure of the variance of y within x?

I guess I would have got this information naturally if I had used (1 + y 
| x) instead of (1|x:y), but for computational reasons that was not 
possible or at least not convenient.


From hans at sociologi.cjb.net  Thu May 31 18:11:05 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Thu, 31 May 2012 18:11:05 +0200
Subject: [R-sig-ME] getting between groups variance when using (1|x:y)
 in	the formula
In-Reply-To: <4FC78FCE.7040604@sociologi.cjb.net>
References: <4FC78FCE.7040604@sociologi.cjb.net>
Message-ID: <4FC79819.7000606@sociologi.cjb.net>

On 2012-05-31 17:35, Hans Ekbrand wrote:
> Let's say I have a formula like this
>
> my.fit <- glmer(w ~ 1 + y + (1|x) + (1|x:y) + z)
>
> Then the summary() output gives information about variance and std.dev 
> for the random term x:y
>
> and ranef(my.fit, postVar = TRUE) gives estimates and standard 
> deviations for x and each value of x:y.
>
> Is there a way to get a single measure of the variance of y within x?

I meant to say "a singe measure of the variance of y within x, for each 
level of y".


From praguewatermelon at gmail.com  Fri Jun  1 06:38:59 2012
From: praguewatermelon at gmail.com (Xiao He)
Date: Thu, 31 May 2012 21:38:59 -0700
Subject: [R-sig-ME] specifying priors in MCMCglmm with interactions inside
	random effects, 
Message-ID: <CAGBzz=+fK7=gBN5rz_h__S6WY4DzgRjuJ=9r4mVHYpYU1y2fCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120531/29aa59e0/attachment.pl>

From bbolker at gmail.com  Fri Jun  1 13:32:03 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 1 Jun 2012 11:32:03 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Problem_in_simulate=28=29_with_GLMMs_when_a_?=
	=?utf-8?q?link_function_is=09specified_=3F?=
References: <014F3178-7D36-4F59-8ED1-C9BE60B68F16@gmail.com>
Message-ID: <loom.20120601T132524-16@post.gmane.org>

Pierre Morel <pier.morel at ...> writes:

>  This is my first message to the list, I hope I won't start on the
> wrong foot !

 Welcome.
 
> I installed the last version of lme4 (0.999902345-0)
>  and I think there is a problem in simulate() when
> trying to simulate a GLMM in which a link function was specified.
> For example, this works (directly from the manual):
> 
> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + 
> (1 | herd), data = cbpp, family = binomial)
> gg <- simulate(gm1,10)
> 
> However, when you specify the link function for the binomial family (even if
you keep the default one,
> logit), there is an error:
> 
> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd), 
> data = cbpp, family = binomial(link="logit"))
> gg <- simulate(gm1,10)
> 
> Error in simulate.merMod(gm1, 10) : 'family' not recognized
> 
> Not a problem if you want to use the default link, 
> but I have psychophysics data for which I would like to use
> the mafc.logit(2) from the psyphy library.

  
> When I look at the source code, even if I am not good enough in R
> programming to fix it, it seems that it should work with any link
> function, since the end result seems only used to get the inverse
> link function:
 
> 	      etasim <- etasim.fix+etasim.reff
> 	      family <- object <at> call$family
> 	      if(is.symbol(family)) family <- as.character(family)
> 	      if(is.character(family))
> 		  family <- get(family, mode = "function", 
>                       envir = parent.frame(2))
> 	      if(is.function(family)) family <- family()
> 	      if(is.null(family$family)) stop("'family' not recognized")
> 	      musim <- family$linkinv(etasim)
> 
> Any idea for a quick fix ?
> 

 Thank you for the report.
 This is now fixed on the SVN -- should be rebuilt/installable
on Linux or Windows in 24 hours or less.  If you want to fix it
yourself, I added the line

    if(is.language(family)) family <- eval(family)

 right before the is.null() check.

  If you're in a hurry you could (1) download the SVN code
and build it yourself; (2) copy lme4:::simulate.merMod and
make your own fixed version (I don't know offhand if simulate.merMod
makes use of other internal lme4::: functions)

  I may not get around to updating the built MacOS binary at
lme4.r-forge.r-project.org/repos for a while -- if someone desperately
needs this for the Mac and can't build their own binary they
can let me know.

  Ben Bolker


From bbolker at gmail.com  Fri Jun  1 13:53:41 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 1 Jun 2012 11:53:41 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?getting_between_groups_variance_when_using_?=
	=?utf-8?b?KDF8eDp5KWluCXRoZSBmb3JtdWxh?=
References: <4FC78FCE.7040604@sociologi.cjb.net>
	<4FC79819.7000606@sociologi.cjb.net>
Message-ID: <loom.20120601T135057-542@post.gmane.org>

Hans Ekbrand <hans at ...> writes:

> 
> On 2012-05-31 17:35, Hans Ekbrand wrote:
> > Let's say I have a formula like this
> >
> > my.fit <- glmer(w ~ 1 + y + (1|x) + (1|x:y) + z)
> >
> > Then the summary() output gives information about variance and std.dev 
> > for the random term x:y
> >
> > and ranef(my.fit, postVar = TRUE) gives estimates and standard 
> > deviations for x and each value of x:y.
> >
> > Is there a way to get a single measure of the variance of y within x?
> 
> I meant to say "a singe measure of the variance of y within x, for each 
> level of y".
> 
   I don't think that's something that glmer() estimates -- it
assumes that the variance is equal for every y-within-x combination.
I suppose you could just compute the variance of each group of
conditional modes, i.e. if xyests are your x:y conditional modes
and xests are your x conditional modes then you could
tapply(xyests,list(xests),var) ...  someone may suggest something
better ...


From bbolker at gmail.com  Fri Jun  1 14:18:35 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 01 Jun 2012 08:18:35 -0400
Subject: [R-sig-ME] Testing out glmmADMB
In-Reply-To: <109E4F6374337D4C9153497DE5F3EEC51CA2BC6A@EXMBX07.ad.louisville.edu>
References: <109E4F6374337D4C9153497DE5F3EEC51CA2BC6A@EXMBX07.ad.louisville.edu>
Message-ID: <4FC8B31B.9020900@gmail.com>

  [cc'd to r-sig-mixed-models; I'm taking the liberty of cc'ing this so
that the discussion can be browsed by others]

On 12-05-30 06:45 PM, Mueller,John Martin wrote:
> 
> I am working on building my 3-level model in glmmADMB.  I have been
> able to get some simple 2-level models to run. However, on some of
> the simple 2-level models I get the following error message:
> 
> "The function maximize failed (couldn't find STD file)"
> 
> Does this mean the program hit the maximum iterations?  Or does it
> mean something else (e.g. I setup the model incorrectly)?

   It means there was *some* kind of problem, ranging from hitting
maximum iterations to a non-positive-definite variance-covariance matrix
for the estimated parameters.  You can try setting verbose=TRUE and
looking near the bottom of the voluminous output to see if you can get
something more useful out of it. glmmADMB could use a lot of improvement
in the way it reports problems (as could the underlying AD Model Builder
code).  The thing you have to keep in mind when fitting complex models
is that there are a lot of things that can go wrong (probably you
already know that ...)
> 
> And then on another model I get the following error message:
> 
> "Convergence failed:log-likelihood of gradient=-477.479"
> 
> I am assuming this message means that the model could not converge.
> Any suggestions on what I should look at to get the model to
> converge?

  The first place to look is ?admbControl , but that only you gives a
couple of options for tweaking.  The next thing I would try to do is to
create plots of your data that are as subdivided as possible (I use
ggplot a lot for this) and try to identify whether there are odd data
points, or odd groups, that could be messing things up.  Depending on
how much time and effort you have available, I would also considering
simulating models with similar structure to your data and see whether
you can fit them successfully (and get reasonable answers); if not (i.e.
if it fails when the data is *known* to be structured in exactly the
same way as the model assumes), then your model is probably just too
complicated to handle.

  Another option is trying better starting values, and in particular
getting reasonable starting values by building up from a simpler model.
 The usual tricks of centering and scaling continuous predictors, and
orthogonalizing or otherwise dealing with strongly correlated
predictors, are also useful (although if you're only dealing with a
single continuous predictor ranging from 0 to 5 that may not matter that
much).

> 
> And then I am looking into the format that needs to be used to run
> the 3-level model in glmmADMB.  A simple 3-level growth curve model
> would be the following in my case:
> 
> NTCS ~ 1 + TIME + (TIME | ID | LOCATION)
> 
> where,
> 
> NTCS = number of total credit sources (the variable is count data and
> has an overdispersion of zeros)
> 
> TIME = the time period, 0-5
> 
> ID = the firm ID
> 
> LOCATION = the location of the firm (metro statistical area)
> 
> ID and LOCATION have been converted into a factor, per the error
> message I received when I didn't convert the ID variable to a factor
> (message: all grouping variables in random effects must be factors).
> 
> Is this the correct formatting for the 3-level model?

  I assume you are trying to fit a (log-)linear model to TIME.  I think
that something like ~ TIME + (TIME|LOCATION/ID) would be what you
wanted; this would fit an overall slope (and intercept: the "1+" in the
fixed-effect part of the formula is optional/implicit); variation in the
slope with respect to time across locations; and variation in the slope
with respect to time across firms within location.
> 
> Note: I would normally send you the script and the data, as that
> would help with the explanation.  However, I am having to work on a
> secure server for this analysis as the data is confidential (on a
> NORC.org server).
> 
> Thx.
> 
> - JM
>


From bbolker at gmail.com  Fri Jun  1 18:44:51 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 1 Jun 2012 16:44:51 +0000 (UTC)
Subject: [R-sig-ME] HPD intervals for fixed parameters in model with
	crossed and correlated random effects
References: <D7383CD4D59FEA4DA879EF5096A5A8CB17D49998A9@exvic-mbx03.nexus.csiro.au>
Message-ID: <loom.20120601T183904-68@post.gmane.org>

 <John.Morrongiello at ...> writes:


> I'd very much like to calculate some HPD intervals for the fixed
> parameters in a lmer model containing crossed and correlated random
> effects. However, I have not been able to find a solution for this
> type of model after a pretty thorough search of discussion threats
> or worked examples. Is this possible at the moment with lme4
> (function or work around), or do I have to change packages and try
> something like mcmcglmm?

  I think if you want to compute HPD intervals you are more or less
stuck with MCMCglmm or glmmADMB ....
 
> My data contains 1917 growth measurements (Increment) from 704 fish
> (FishID) and the data is sampled from 29 years (Year). I'm
> interested in the effects of age (2-18 years) and water temperature
> (temp) on growth.  My model is:
 
> M1<-lmer(log(Increment)~log(Age)+temp+(log(Age)|FishID)+(1|Year),
>   data,REML=T)
> 
> HPDinterval requires an mcmc object, but when I try
> mcmcsamp(M1, n=1000)
> 
> I receive the following error:
> Error in .local(object, n, verbose, ...) :
>   Code for non-trivial theta_T not yet written


> I understand this is because MCMCsamp doesn't yet cope with
> correlated random effects? On the glmm wikidot page there is code to
> generate confidence and prediction intervals on predictions- could I
> use some of N this to get a what I'm after (if so, which bits)? I
> haven't used mcmcglmm before, so ideally would like to stay with the
> more familiar lme4 if possible to expedite the analyses! 

   I don't think so, I think you'll need MCMCglmm or glmmADMB.

In principle glmmADMB should work with your model more or less as-is
(although I don't remember whether it can do REML-y stuff or not),
and you can use mcmc=TRUE to get it to run an MCMC chain on the
parameters for you.  However, based on my limited experience, if
you do want to get MCMC working it will be easier using MCMCglmm
(which is intrinsically based on MCMC, and does a bunch of clever
stuff to make the chains mix well).

  good luck,
    Ben Bolker


From bbolker at gmail.com  Fri Jun  1 19:00:54 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 1 Jun 2012 17:00:54 +0000 (UTC)
Subject: [R-sig-ME] Using R,
	how to present mixed models vs. regular linear regression models?
References: <CAPNjSFYVucW=HbXM_=wpn=Aw-vYYOOdaxSsQ4svgmzaSqhyfGw@mail.gmail.com>
	<CAPNjSFaCQK0aCCnZ1gs4KsdNdjC9t+OnKR7m47UjBCXuW2u=Jg@mail.gmail.com>
	<CAPNjSFZ1p495osOKsbNEr2ATNYX==J2k6kt92SuqOFNVUiYamg@mail.gmail.com>
Message-ID: <loom.20120601T185259-199@post.gmane.org>

Michael <comtech.usa at ...> writes:

> 
> And what's the difference between these two models?
> 
> M0 <- lmer (y ~ 1 + (1 | county))
> 
> M1 <- lmer (y ~ -1 + (1 | county))
> 
> On Thu, May 31, 2012 at 9:52 AM, Michael <comtech.usa at ...> wrote:
> 
> > What are the key differences between the following two models?
> >
> >
> >
> > lmefit = lmer(MathAch ~ SES + (1 |School) , MathScores)
> >
> > lmfit = lm(MathAch ~ SES + School -1 , MathScores)
> >
> > To me, they seem to be the same, except that lmefit takes less parameters
> > (because it used Normal distribution to model the levels at the group
> > level...)
> >

  If you don't get a satisfactory answer here you might try on 
http://stats.stackexchange.com ; this seems like a very well-suited
question for that site.

  Your second question is easier because it only involves the fixed
effects; the second model doesn't use an intercept, and so assumes that
the average y across all counties is exactly zero (this is a pretty
weird model; most of the time it doesn't make sense to include a random
effect whose corresponding population-level effect is missing/forced to zero).

  In the second model in your first question I would be careful;
I don't think the -1 does what you think it does/want it to do
(i.e., set the average effect of school to zero).
  
  Ben Bolker


From pauljohn32 at gmail.com  Sat Jun  2 20:49:31 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 2 Jun 2012 13:49:31 -0500
Subject: [R-sig-ME] Using R,
 how to present mixed models vs. regular linear regression models?
In-Reply-To: <CAPNjSFaCQK0aCCnZ1gs4KsdNdjC9t+OnKR7m47UjBCXuW2u=Jg@mail.gmail.com>
References: <CAPNjSFYVucW=HbXM_=wpn=Aw-vYYOOdaxSsQ4svgmzaSqhyfGw@mail.gmail.com>
	<CAPNjSFaCQK0aCCnZ1gs4KsdNdjC9t+OnKR7m47UjBCXuW2u=Jg@mail.gmail.com>
Message-ID: <CAErODj_HuC6pNtzDDAA52HmHf0QV4XHTVO4ZRP1Q-1DKeY0ghg@mail.gmail.com>

On Thu, May 31, 2012 at 9:52 AM, Michael <comtech.usa at gmail.com> wrote:
> What are the key differences between the following two models?
> lmefit = lmer(MathAch ~ SES + (1 |School) , MathScores)
>
> lmfit = lm(MathAch ~ SES + School -1 , MathScores)
>
> To me, they seem to be the same, except that lmefit takes less parameters
> (because it used Normal distribution to model the levels at the group
> level...)
>
Dear Michael

This is a big general philosophical issue, not an R lmer question. You
have quite a bit of homework to do. Your claim is both right and wrong
at the same time, I think.

For background reading, i suggest you study the difference between
fixed effects ('least squares dummy variables") and random effects
models.

For your question about what is being optimized, I suggest you start
with the Pinheiro and Bates book from 2000, and then also study the
papers that Doug Bates has made available and his book chapters.
http://lme4.r-forge.r-project.org/book/.  There is one I can't find at
the moment, but it contrasts the GLS with the Penalized ML views. But
I expect you can Google better than I can. Maybe the best entry point
there is the useR workshop he offered,  Tutorial: Fitting and
evaluating mixed models using lme4
http://user2010.org/tutorials/Bates.html. Or these slides ...
http://lme4.r-forge.r-project.org/slides/2011-01-11-Madison/6NLMM.pdf.

I have a folder of pdf manuscripts I've saved over the years. Here are
things to look for.  John Fox has an online chapter to supplement his
Companion to Applied Regression. I've found the (many, many) articles
and books by Sophia Rabe-Hesketh and Anders Skrondal to be more
understandable than most things about methodology. (google for The
Stata Journal (2002)). They also have a brand new edition of their
mixed models with stata book, which I think is quite good (even though
it does not use R).  There is an essay about this that goes with the R
package glmmML that I think is quite helpful. "Generalized linear
models
with random intercepts" by Goran Boostrom. Also, google for "A First
Look at MultiLevel Models" Georges Monett.

I think you will see there are competing interpretations of mixed
models. The most obvious iterpretation (in my view) is Generalized
Least Squares, that's one I can really understand. However, Prof.
Bates suggests instead you should view it as a penalized maximum
likelihood exercise. I defer to that view and try to understand it,
and I suggest you should too. I recently fell in love with a book by
Simon Wood, Generalized Additive Models (2008).  The GAM part is fine,
but the first 100 pages that lead up to it offer a very superior
explanation of regression modeling, the Generalized Linear Model, and
then mixed effects models.

Good luck, I'm sorry I don't have a comprehensive reading list, but if
you build one, share it back to me :)
pj


-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From skkrause at gmail.com  Sun Jun  3 05:54:23 2012
From: skkrause at gmail.com (Sara Krause)
Date: Sat, 2 Jun 2012 20:54:23 -0700
Subject: [R-sig-ME] multiple variance structure in lmer giving zero variances
Message-ID: <CAJEgrVz6DiRC+KKrNNj4fqHnw=hUqPaO87QJ2Dt==JUpqCb0Gw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120602/9960983a/attachment.pl>

From skkrause at gmail.com  Sun Jun  3 03:21:18 2012
From: skkrause at gmail.com (Sara Krause)
Date: Sat, 2 Jun 2012 18:21:18 -0700
Subject: [R-sig-ME] crossed random
Message-ID: <CAJEgrVxM=KoPYvuXmJ_VRvoJi588BOwP4Jq2an1h3h5qCzeiEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120602/2bc336b4/attachment.pl>

From bbolker at gmail.com  Sun Jun  3 21:15:54 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 3 Jun 2012 19:15:54 +0000 (UTC)
Subject: [R-sig-ME] multiple variance structure in lmer giving zero
	variances
References: <CAJEgrVz6DiRC+KKrNNj4fqHnw=hUqPaO87QJ2Dt==JUpqCb0Gw@mail.gmail.com>
Message-ID: <loom.20120603T111621-469@post.gmane.org>

Sara Krause <skkrause at ...> writes:

> I'm hoping someone can help me out.  Forgive me if I my mistake is
> something simple.  I am new to mixed models, new to R, and new to lme4 and
> am struggling to figure everything out.  I have two questions that I am
> hoping someone can answer.
> 1) Am I using the correct random structure for my model?
> 2) Can someone help me figure out what is wrong with my syntax to code for
> random effect variance by treatment group?

  (I can understand your desperation, but please don't cross-post ...
I almost answered this on r-help with a suggestion that you try
on r-sig-mixed instead.)

> These questions somewhat go together but let me tackle number one first.  I
> was told by our statistician (who unfortunately doesn't know R well) that
> my model should include random effects for ID, ID*state, and ID*season.
> If my understanding of lme4 code is correct, my random structure would
> appear as it does in this model
> M1<-lmer (y~trt*season*state*site+(1|ID)+(1|state)+(1|season))
> 
 [snipped from below]:

> There are two levels in each of these factors.  Treatment is G or S
> (basically treated or control groups) and state is either
> Pre-treatment or Post-treatment.  My other fixed factors are a site
> factor (two locations) and a season factor (breeding or non-breeding
> season).  Is this correct?  (I am starting with the fully crossed
> fixed effects and I will use iterative model selection to find the
> optimal model after I make sure that I have the correct random
> terms)

   In general, categorical predictors should not appear in both
the fixed and random parts of the model -- that constitutes overfitting.

Depending on the structure of your data you should also strongly
consider including interactions between treatment and your random
factors (see Schielzeth, Holger, and Wolfgang
Forstmeier. 2009. ?Conclusions Beyond Support: Overconfident Estimates
in Mixed Models.? Behavioral Ecology 20 (2):416?420.
doi:10.1093/beheco/arn145.
http://www.ncbi.nlm.nih.gov/pubmed/19461866.).  However, you can only
include treatment interactions that make sense. It sounds like each
individual is allocated to a single treatment, so (guessing that your
statistician means that you want the *interactions* of ID with state
and season) I think you should probably use

y~trt*season*state*site+(state|ID)+(0+season|ID)

which includes a random effect of state, a state:ID interaction
(variation of the state effect among individuals), and a season:ID
interaction (variation of seasonal effect among individuals).

  Why are you moving to lmer? is it so that you can handle the
separate effects of state:ID and season:ID ?  

> The second question is a bit more complicated and changes my random
> structure as well.  I had originally built my model in nlme  and used the
> multiple variance (varIdent) function to allow different variance for two
> of my terms (trt and state) in my nlme model because different levels in
> each term had different variances. 
> 
> I found a very helpful post (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000248.html) on
> how to also do this in lmer but it doesn't seem to be working correctly for
> me and I have not been able to figure out why. 

  I'm mostly going to postpone comment on your second question until
your first question is sorted out, although I would also encourage you
to see if your heteroscedasticity problem might be handled by transformation --
most typically, if treatment increases both the mean and variance a lot,
then log transforming the data might take care of the problem with less
hassle ...


> I am also trying to do this
> with 2 factors instead of one.
> The overall structure of my data is
> Structure of my dataset (d)
>   ..@ frame   :'data.frame': 173 obs. of  10 variables:
>   .. ..$ y     : int [1:173] 209 382 448 353 224 112 198 273 495 622 ...
>   .. ..$ trt   : Factor w/ 2 levels "G","S": 1 1 1 1 1 1 1 1 1 1 ...
>   .. ..$ season: Factor w/ 2 levels "Breeding","NonBreeding": 2 2 2 2 2 2 2
> 1 1 1 ...
>   .. ..$ state : Factor w/ 2 levels "Post","Pre": 1 1 1 1 1 1 1 1 1 1 ...
>   .. ..$ site  : Factor w/ 2 levels "Mrak","Orchard": 1 1 1 1 1 2 2 1 1 1
> ...
>   .. ..$ G     : num [1:173] 1 1 1 1 1 1 1 1 1 1 ...
>   .. ..$ ID    : Factor w/ 59 levels "100","103","105",..: 11 19 22 58 6 36
> 50 11 20 24 ...
>   .. ..$ S     : num [1:173] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ Pre   : num [1:173] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..$ Post  : num [1:173] 1 1 1 1 1 1 1 1 1 1 ...
> 

> m1<-lmer(y~trt*season*state*site+(0+G|ID)+(0+S|ID) +(0+Pre|ID) +
> (0+Post|ID)+(1|season), data=d)

  Your basic problem here is that it doesn't make sense to test the interaction
of treatment with ID (as you have effectively done here), because each
individual is only in one treatment category ...


From skkrause at gmail.com  Mon Jun  4 01:49:07 2012
From: skkrause at gmail.com (Sara Krause)
Date: Sun, 3 Jun 2012 16:49:07 -0700
Subject: [R-sig-ME] multiple variance structure in lmer giving zero
	variances
In-Reply-To: <loom.20120603T111621-469@post.gmane.org>
References: <CAJEgrVz6DiRC+KKrNNj4fqHnw=hUqPaO87QJ2Dt==JUpqCb0Gw@mail.gmail.com>
	<loom.20120603T111621-469@post.gmane.org>
Message-ID: <CAJEgrVyJEOJTW57ZNaM725HaT60SXEow0b8aJKAD9h+N3=Ko7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120603/8b5df5ac/attachment.pl>

From John.Morrongiello at csiro.au  Mon Jun  4 09:03:41 2012
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Mon, 4 Jun 2012 17:03:41 +1000
Subject: [R-sig-ME] HPD intervals for fixed parameters in model
In-Reply-To: <mailman.1.1338631201.31638.r-sig-mixed-models@r-project.org>
References: <mailman.1.1338631201.31638.r-sig-mixed-models@r-project.org>
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB17D49998B5@exvic-mbx03.nexus.csiro.au>

Hi Ben

Thanks very much for the response. I've tried both MCMCglmm and glmmADMB and am happy with the parameter estimates and the HPD intervals they produce. The only issue was specifying the random age slope in glmmADMB (as per M1admb below). It seems to only accept random factors- is it possible to specify a random slope? 

M1admb<-glmmadmb(log(Increment)~log(Age)+temp+(log(Age)|FishID)+(1|fYear),data,family='gaussian')

Warning message:
In Ops.factor(log(Age), FishID) : | not meaningful for factors
Error in model.matrix(as.formula(paste("~", lbit)), mdata) : 
  error in evaluating the argument 'object' in selecting a method for function 'model.matrix': Error in parse(text = x) : <text>:2:0: unexpected end of input
1: ~ 
  ^

Cheers

John


Message: 4
Date: Fri, 1 Jun 2012 16:44:51 +0000 (UTC)
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] HPD intervals for fixed parameters in model
	with	crossed and correlated random effects
Message-ID: <loom.20120601T183904-68 at post.gmane.org>
Content-Type: text/plain; charset=us-ascii

 <John.Morrongiello at ...> writes:


> I'd very much like to calculate some HPD intervals for the fixed
> parameters in a lmer model containing crossed and correlated random
> effects. However, I have not been able to find a solution for this
> type of model after a pretty thorough search of discussion threats
> or worked examples. Is this possible at the moment with lme4
> (function or work around), or do I have to change packages and try
> something like mcmcglmm?

  I think if you want to compute HPD intervals you are more or less
stuck with MCMCglmm or glmmADMB ....
 
> My data contains 1917 growth measurements (Increment) from 704 fish
> (FishID) and the data is sampled from 29 years (Year). I'm
> interested in the effects of age (2-18 years) and water temperature
> (temp) on growth.  My model is:
 
> M1<-lmer(log(Increment)~log(Age)+temp+(log(Age)|FishID)+(1|Year),
>   data,REML=T)
> 
> HPDinterval requires an mcmc object, but when I try
> mcmcsamp(M1, n=1000)
> 
> I receive the following error:
> Error in .local(object, n, verbose, ...) :
>   Code for non-trivial theta_T not yet written


> I understand this is because MCMCsamp doesn't yet cope with
> correlated random effects? On the glmm wikidot page there is code to
> generate confidence and prediction intervals on predictions- could I
> use some of N this to get a what I'm after (if so, which bits)? I
> haven't used mcmcglmm before, so ideally would like to stay with the
> more familiar lme4 if possible to expedite the analyses! 

   I don't think so, I think you'll need MCMCglmm or glmmADMB.

In principle glmmADMB should work with your model more or less as-is
(although I don't remember whether it can do REML-y stuff or not),
and you can use mcmc=TRUE to get it to run an MCMC chain on the
parameters for you.  However, based on my limited experience, if
you do want to get MCMC working it will be easier using MCMCglmm
(which is intrinsically based on MCMC, and does a bunch of clever
stuff to make the chains mix well).

  good luck,
    Ben Bolker


From bbolker at gmail.com  Mon Jun  4 09:12:12 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 04 Jun 2012 03:12:12 -0400
Subject: [R-sig-ME] HPD intervals for fixed parameters in model
In-Reply-To: <D7383CD4D59FEA4DA879EF5096A5A8CB17D49998B5@exvic-mbx03.nexus.csiro.au>
References: <mailman.1.1338631201.31638.r-sig-mixed-models@r-project.org>
	<D7383CD4D59FEA4DA879EF5096A5A8CB17D49998B5@exvic-mbx03.nexus.csiro.au>
Message-ID: <4FCC5FCC.7090903@gmail.com>

On 12-06-04 03:03 AM, John.Morrongiello at csiro.au wrote:
> Hi Ben
> 
> Thanks very much for the response. I've tried both MCMCglmm and glmmADMB and am happy with the parameter estimates and the HPD intervals they produce. The only issue was specifying the random age slope in glmmADMB (as per M1admb below). It seems to only accept random factors- is it possible to specify a random slope? 
> 
> M1admb<-glmmadmb(log(Increment)~log(Age)+temp+(log(Age)|FishID)+(1|fYear),data,family='gaussian')
> 
> Warning message:
> In Ops.factor(log(Age), FishID) : | not meaningful for factors
> Error in model.matrix(as.formula(paste("~", lbit)), mdata) : 
>   error in evaluating the argument 'object' in selecting a method for function 'model.matrix': Error in parse(text = x) : <text>:2:0: unexpected end of input
> 1: ~ 
>   ^
> 
> Cheers
> 
> John

  As a quick possible workaround, try defining data$logAge <-
log(data$Age) and using (logAge|FishID) in your model formula; I'm not
sure that glmmADMB can handle defining variable transformations on the
fly in that context.

  Also be aware that the default for lme4 is to use the full correlation
matrix while glmmADMB uses a diagonal matrix, so (e.g.) (logAge|FishID)
would estimate three parameters (variation in intercept across fish,
variation in slope across fish, covariance between intercept and slope)
while glmmADMB would only estimate the first two.  (I think you have to
specify this choice explicitly in MCMCglmm.)

> 
> 
> Message: 4
> Date: Fri, 1 Jun 2012 16:44:51 +0000 (UTC)
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] HPD intervals for fixed parameters in model
> 	with	crossed and correlated random effects
> Message-ID: <loom.20120601T183904-68 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
> 
>  <John.Morrongiello at ...> writes:
> 
> 
>> I'd very much like to calculate some HPD intervals for the fixed
>> parameters in a lmer model containing crossed and correlated random
>> effects. However, I have not been able to find a solution for this
>> type of model after a pretty thorough search of discussion threats
>> or worked examples. Is this possible at the moment with lme4
>> (function or work around), or do I have to change packages and try
>> something like mcmcglmm?
> 
>   I think if you want to compute HPD intervals you are more or less
> stuck with MCMCglmm or glmmADMB ....
>  
>> My data contains 1917 growth measurements (Increment) from 704 fish
>> (FishID) and the data is sampled from 29 years (Year). I'm
>> interested in the effects of age (2-18 years) and water temperature
>> (temp) on growth.  My model is:
>  
>> M1<-lmer(log(Increment)~log(Age)+temp+(log(Age)|FishID)+(1|Year),
>>   data,REML=T)
>>
>> HPDinterval requires an mcmc object, but when I try
>> mcmcsamp(M1, n=1000)
>>
>> I receive the following error:
>> Error in .local(object, n, verbose, ...) :
>>   Code for non-trivial theta_T not yet written
> 
> 
>> I understand this is because MCMCsamp doesn't yet cope with
>> correlated random effects? On the glmm wikidot page there is code to
>> generate confidence and prediction intervals on predictions- could I
>> use some of N this to get a what I'm after (if so, which bits)? I
>> haven't used mcmcglmm before, so ideally would like to stay with the
>> more familiar lme4 if possible to expedite the analyses! 
> 
>    I don't think so, I think you'll need MCMCglmm or glmmADMB.
> 
> In principle glmmADMB should work with your model more or less as-is
> (although I don't remember whether it can do REML-y stuff or not),
> and you can use mcmc=TRUE to get it to run an MCMC chain on the
> parameters for you.  However, based on my limited experience, if
> you do want to get MCMC working it will be easier using MCMCglmm
> (which is intrinsically based on MCMC, and does a bunch of clever
> stuff to make the chains mix well).
> 
>   good luck,
>     Ben Bolker
>


From bbolker at gmail.com  Mon Jun  4 11:02:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 4 Jun 2012 09:02:10 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?multiple_variance_structure_in_lmer_giving_z?=
	=?utf-8?q?ero=09variances?=
References: <CAJEgrVz6DiRC+KKrNNj4fqHnw=hUqPaO87QJ2Dt==JUpqCb0Gw@mail.gmail.com>
	<loom.20120603T111621-469@post.gmane.org>
	<CAJEgrVyJEOJTW57ZNaM725HaT60SXEow0b8aJKAD9h+N3=Ko7Q@mail.gmail.com>
Message-ID: <loom.20120604T102647-865@post.gmane.org>

Sara Krause <skkrause at ...> writes:

> I apologize for the cross-post.  posted to the regular list serve
> first and received a suggestion from someone else that I post here
> instead. ... I should have been clear originally that I had posted
> on the regular listserve first.

  Not a big deal, now you know.

> Your response was very useful in helping me move along in this analysis.  I
> have addressed several of your comments in more detail below but to
> summarize my email, these are my current questions:
> 
> 1.  Is it possible for me to still use the nlme package?  If so, do I use
> the pdBlocked structure to incorporate my random effects? And if I do use
> this structure, could someone point me towards a resource to figure out how
> to create my groupedData?  I'm sure my lack of understanding here is a
> statisitical, rather than R code issue.

  I don't think groupedData is absolutely necessary.  I'll leave the
pdBlocked question for someone else ...

> 2.  It is unclear to me how to deal with the problem of having my
> categorical variables occur in the fixed and random effects.  Any insight
> on this would be helpful.
> 3.  Based on the paper you sent and a look at my data, it does seem like I
> need to incorporate the trt interactions but this exacerbates the problem
> of an overfitted model.

  Yes, but in this case you just can't -- because each individual only
gets a single treatment.  So the interaction might be there, but you
can't estimate it from your data (which gets you off the hook).

> 4.  I tried the model that you kindly provided and received an error.  See
> below for details.

> I was switching to lme4 because I didn't think that I could use the correct
> random terms in nlme.  I would actually prefer to stick with nlme if it is
> possible to do so. I have a few simpler models that I have already run in
> nlme so it would be nice to not have to re-run all of them.  I understand
> the p-values provided are a bit controversial but journals like them anyway
> so they are nice to have.

> My best guess for how to do this based on what I could figure out and your
> suggested lmer model is the following
> 
> m1<-lme(y=trt*state*season*site, data=group,
> random=pdBlocked(list(pdIdent(~state|ID), pdIdent(~season|ID-1))),
> method=("REML"))

> However, I have not been able to find any documentation on how to correctly
> create the groupedData object.  To make my model run, I used

> group=groupedData(y~1|state, data=d, order.groups=FALSE)

> If there is a way to run this model correctly in nlme, I would greatly
> appreciate your insight on this.

  Anyone else want to chime in on this ... ?

> You also raised a couple of other issues in your email that I am not sure
> how to address. You stated

> >   In general, categorical predictors should not appear in both
> > the fixed and random parts of the model -- that constitutes overfitting.
> >
> > My effect of interest in this model is actually the interaction between
> treatment and state because I expect that the treated individuals but not
> the control will decline in (scrotal) size after (contraceptive) treatment.
>  Thus, assuming I am not missing something, state must be in my fixed
> effects.  I expect that there will be seasonal differences in size due to
> breeding season.  This seasonal difference is interesting but ancillary to
> the main question so perhaps I could take season out of the fixed effects.

  I think you're OK: (state|ID) and (season|ID) are putting *interactions*
in the model.  What would definitely break would be (1|state) or (1|season)
(i.e. using fixed effects as *grouping variables* for the random effects).
I think the model is fine as it is.

> The other issue you raised was this one:
> 
> > Depending on the structure of your data you should also strongly
> > consider including interactions between treatment and your random
> > factors (see Schielzeth, Holger, and Wolfgang
> > Forstmeier. 2009. ?Conclusions Beyond Support: Overconfident Estimates
> > in Mixed Models.? Behavioral Ecology 20 (2):416?420.
> > doi:10.1093/beheco/arn145.
> > http://www.ncbi.nlm.nih.gov/pubmed/19461866.).  However, you can only
> > include treatment interactions that make sense.

> I asked about this and he said that the interactions with ID were most
> important but this paper does make a good argument for it. 

  Do you mean "not" above (and "he" is your statistician)?  I can
imagine him saying "not" because they are unidentifiable based on your
design -- so it's not that they're not important, just that you can't
do anything about it.

[snip]

  I claim you're already including these interactions (as
interactions of *fixed* effects).  
   
 [snip]

> It sounds like each
> > individual is allocated to a single treatment, so (guessing that your
> > statistician means that you want the *interactions* of ID with state
> > and season) I think you should probably use
> 
> y~trt*season*state*site+(state|ID)+(0+season|ID)
> >
> 
> Yes, the interactions of ID with state and season is exactly what I am
> looking for.
> Also, your suggestion of a log transformation did take care of the problem
> of the unequal variances so thankfully, I should not have to deal with that
> in a more complicated way.
> Unfortunately, the model as above but on log transformed data resulted in
> the following error
> In mer_finalize(ans) : singular convergence (7)

> It is unclear to me why this is occurring.

  Probably still somewhat overfitted.  Try simplifying the model
a bit and see if you can get somewhere (e.g. take out the four-way
interaction and use (trt+season+state+site)^3 instead?


From tibor at linguistics.rub.de  Mon Jun  4 13:07:48 2012
From: tibor at linguistics.rub.de (Tibor Kiss)
Date: Mon, 4 Jun 2012 13:07:48 +0200
Subject: [R-sig-ME] lme4, cloglog vs. binomial link
Message-ID: <7A4C46CB-970C-4B6C-93AF-297AB57ED8CC@linguistics.rub.de>

Hi everybody,

I am a theoretical and computational linguist and use GLMs and GLMMs (glm and lmer) to identify linguistic features relevant for the presence/absence of other linguistic features. I am somewhat uncertain about the interpretation of my results. In the present application, I want to know which linguistic features determines the presence/absence of a determiner (the, a) in constructions similar to "by bus" vs. "We are taking the bus" (in fact, I am working on German data, but that does not matter now.) The linguistic features I am using come from annotated language corpora, and almost all features are categorical, spanning information pertaining to the words in question(category, morphology, meaning) to the syntactic environment. 

I am not so much interested in developing a model that predicts whether a determiner is realized or omitted, but in a subset of features that seem most pertinent to why the determiner is omitted. In most cases, high prediction and variable selection seem to be two sides of the same coin. If however, the fixed effects are features of the construction (that can be translated into features in a grammar rule) while the lexical items in the construction (the noun in particular, since I develop models where the preposition is kept constant) is taken to be the random effect, then the model can reach high prediction, but is itself not so interesting because it may basically say that whatever the features are, certain lexical items can override everything. (Formally, everything is fine with that result, but grammarians do not like analyses of the form: learn the following nouns by rote, as they can be used in the construction.)

In the following mixed models, *target_noun_lemma* is the representation of the noun in the construction, its categorical value being one of the 712 different nouns in the sample. The sample contains 6.841 different instances of the construction: 810 instances of determiner omission and 6.031 instances of determiner realization. 

The distribution of *target_noun_lemma* is highly skewed (which is standard for language samples): the top five nouns occur 1.225, 466, 443, 414, and 304 times, respectively, and the long tail consists of singular occurrences. 
Using a mixed model, the lexical influence of the nouns can be determined and will be reflected in high standard deviation of the random effect *target_noun_lemma*. While an glmm taking lexical influence into account would show a higher degree of prediction, but it would also indicate that the features employed (i.e. the fixed parameters of the model) only tell a less relevant part of the story. 

In the following models, the fixed effects describe the presence/absence of an adjective in the construction, whether the noun in the construction is extended by further syntactic material (OP), whether the noun is derived from a verb, and which interpretation the preposition will have. 
 
> unter.new.glmm10 <- lmer(determiner ~ adja_in_hit + + I(cor_mp_int_dep_rel_type == "OP") + TN_LEX_nominalisierung + modal + machtverhaeltnis + zuordnung + bezugspunkt + restriktiv + (1 | target_noun_lemma), data = unter.data, family = binomial())

Generalized linear mixed model fit by the Laplace approximation 
Formula: determiner ~ adja_in_hit + +I(cor_mp_int_dep_rel_type == "OP") +  TN_LEX_nominalisierung + modal + machtverhaeltnis + zuordnung + bezugspunkt + restriktiv + (1 | target_noun_lemma) 
   Data: unter.data 
  AIC  BIC logLik deviance
 2302 2370  -1141     2282
Random effects:
 Groups            Name        Variance Std.Dev.
 target_noun_lemma (Intercept) 19.241   4.3865  
Number of obs: 6838, groups: target_noun_lemma, 712

Fixed effects:
                                       				Estimate Std. Error z value Pr(>|z|)    
(Intercept)                              			6.8978     0.4944  13.952  < 2e-16 ***
adja_in_hit1                            			-1.4169     0.1795  -7.893 2.95e-15 ***
I(cor_mp_int_dep_rel_type == "OP")TRUE  	-0.6685     0.5845  -1.144 0.252735    
TN_LEX_nominalisierung                 		-4.7256     0.6551  -7.214 5.43e-13 ***
modal                                  			-1.4955     0.1963  -7.620 2.54e-14 ***
machtverhaeltnis                    		     	1.2352     0.3345   3.693 0.000222 ***
zuordnung                                			1.5816     0.2646   5.977 2.27e-09 ***
bezugspunkt                             			-2.6957     1.6866  -1.598 0.109979    
restriktiv                              			-1.6586     0.2742  -6.049 1.46e-09 ***

The intercept has a value of 6.8978, so a standard deviation of 4.3865 shows that whatever the predictions of the fixed effects are, they can be dwarfed by the random effects. 
 
With regard to the skewed distribution of determiner omission/realization, I understand from Zuur et al. (2009:251) that it would make sense to apply a complementary log log link instead of the binomial link I applied in the above model. Hence, I defined the following model, which differs in the link, but also in the response variable, because I assume (hopefully correct) that the complementary log log link requires the less frequent response to become the success. Hence I have changed determiner into inv_resp (inverted response), where *yes* is coded as yes, and *no* is coded as z-no. 

unter.new.glmm9 <- lmer(inv_resp ~ adja_in_hit + I(cor_mp_int_dep_rel_type == "OP") + TN_LEX_nominalisierung + modal + machtverhaeltnis + zuordnung + bezugspunkt + restriktiv + (1 | target_noun_lemma), data = unter.data, family = binomial(link = "cloglog"))

Data: unter.data 
AIC  BIC logLik deviance
2360 2429  -1170     2340
Random effects:
Groups            Name        Variance Std.Dev.
target_noun_lemma (Intercept) 6.9517   2.6366  
Number of obs: 6838, groups: target_noun_lemma, 712

Fixed effects:
                                           			Estimate Std. Error z value Pr(>|z|)    
(Intercept)                             			-5.4100     0.2935 -18.434  < 2e-16 ***
adja_in_hit1                            			0.9492     0.1424   6.667 2.61e-11 ***
I(cor_mp_int_dep_rel_type == "OP")TRUE   0.3181     0.2545   1.250 0.211386    
TN_LEX_nominalisierung                   		3.5858     0.3913   9.164  < 2e-16 ***
modal                                    			1.2048     0.1505   8.005 1.20e-15 ***
machtverhaeltnis                        		-0.9212     0.2470  -3.729 0.000192 ***
zuordnung                               			-1.2208     0.2096  -5.825 5.71e-09 ***
bezugspunkt                              		2.4556     1.1068   2.219 0.026503 *  
restriktiv                               			1.3635     0.1994   6.838 8.05e-12 ***


The model seems to be worse in terms of AIC (2360 compared to 2302), but the standard deviation of *target_noun_lemma* dropped from 4.38 to 2.636.

Comparing the BLUPs of both models, the BLUPs of the first (binomial) one range from -10.65 to 4.06, while the blups of the second one (cloglog) occupy a smaller range from 6.90 to -3.24. (Given that the response variable is inverted, this means that BLUPs triggering determiner realization remain roughly in the same region (4.06/3.24) while BLUPs triggering determiner omission lost some influence in the extreme (10.65/6.90) ? if I interpret the results correctly. 

My questions are as follows:

1. Is it correct to assume that given a cloglog link, the less frequent response should be considered the success?
2. Is it correct to conclude that the changes in the model have led to less influence of the random factor?
3. How shall I react to the increase in AIC?

A final question, which may not have an answer at all: I am most curious to learn about possible modifications of the model so that an observed random effect can be minimized (while its presence cannot be denied). 

Thanks very much!

With kind regards

Tibor

-----------------------------------------------------------
Prof. Dr. Tibor Kiss
Sprachwissenschaftliches Institut
Ruhr-Universit?t Bochum
http://www.linguistics.rub.de/~kiss


From jwmichel at loyola.edu  Mon Jun  4 21:51:39 2012
From: jwmichel at loyola.edu (John Michel)
Date: Mon, 4 Jun 2012 15:51:39 -0400
Subject: [R-sig-ME] glmmPQL Question
Message-ID: <9B956ACF8A1D85448691396E118A6E5B02766421AA@EXLOYCMS.ad.loyola.edu>

Dear Netters

I am working on some analyses in which I have a two level random effects model and a dichotomous dependent variable. I am using glmmPQL with family=binomial in my model command. I have calculated my models successfully; however, I am now trying to calculate my variance components. I have done a lot using the lme function and have used the following formula to estimate variance components:

VarCorr(Model.1)
GRPpdSymm(1)

What is the syntax to get the variance components in glmmPQL? If this is not simple, I am assuming I could use lmer; however, I also cannot figure out how to get the variance components in lmer. In any even, I would appreciate any suggestions here.

Best
John

--------------------------------------------
John W. Michel, Ph.D.
Assistant Professor of Management
Sellinger School of Business & Management
Loyola University Maryland
4501 N. Charles Street
Baltimore, MD 21201
jwmichel at loyola.edu


From bbolker at gmail.com  Mon Jun  4 23:27:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 4 Jun 2012 21:27:10 +0000 (UTC)
Subject: [R-sig-ME] glmmPQL Question
References: <9B956ACF8A1D85448691396E118A6E5B02766421AA@EXLOYCMS.ad.loyola.edu>
Message-ID: <loom.20120604T232257-354@post.gmane.org>

John Michel <jwmichel at ...> writes:

>  I am working on some analyses in which I have a two level random
> effects model and a dichotomous dependent variable. I am using
> glmmPQL with family=binomial in my model command. I have calculated
> my models successfully; however, I am now trying to calculate my
> variance components. I have done a lot using the lme function and
> have used the following formula to estimate variance components:
 
> VarCorr(Model.1)
> GRPpdSymm(1)

> What is the syntax to get the variance components in glmmPQL? If
> this is not simple, I am assuming I could use lmer; however, I also
> cannot figure out how to get the variance components in lmer. In any
> even, I would appreciate any suggestions here.

  Did you try VarCorr() ??

 From ?glmmPQL:

x <- glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,
  family = binomial, data = bacteria)

 VarCorr(x)
ID = pdLogChol(1) 
            Variance  StdDev   
(Intercept) 1.9898963 1.4106368
Residual    0.6084797 0.7800511

  You probably already know that the object returned by VarCorr()
has a slightly weird format.
 
 I don't know where your second line, GRPpdSymm(1) comes from??

  VarCorr() should work just fine on lmer objects too.

  Perhaps you can give a reproducible example of what you've tried/
what fails for you?
 
  Follow-ups should probably go to r-sig-mixed-models <at> r-project.org


From bbolker at gmail.com  Mon Jun  4 23:28:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 4 Jun 2012 21:28:10 +0000 (UTC)
Subject: [R-sig-ME] glmmPQL Question
References: <9B956ACF8A1D85448691396E118A6E5B02766421AA@EXLOYCMS.ad.loyola.edu>
Message-ID: <loom.20120604T232722-871@post.gmane.org>

John Michel <jwmichel at ...> writes:

>  I am working on some analyses in which I have a two level random
> effects model and a dichotomous dependent variable. I am using
> glmmPQL with family=binomial in my model command. I have calculated
> my models successfully; however, I am now trying to calculate my
> variance components. I have done a lot using the lme function and
> have used the following formula to estimate variance components:

  Oops, sorry about the comment about "follow-ups to r-sig-mixed ..."
I'm half-asleep.


From hans at sociologi.cjb.net  Mon Jun  4 23:30:34 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Mon, 04 Jun 2012 23:30:34 +0200
Subject: [R-sig-ME] getting between groups variance when using (1|x:y)in
 the formula
In-Reply-To: <loom.20120601T135057-542@post.gmane.org>
References: <4FC78FCE.7040604@sociologi.cjb.net>	<4FC79819.7000606@sociologi.cjb.net>
	<loom.20120601T135057-542@post.gmane.org>
Message-ID: <4FCD28FA.3030802@sociologi.cjb.net>

On 2012-06-01 13:53, Ben Bolker wrote:
> Hans Ekbrand<hans at ...>  writes:
>
>    
>> On 2012-05-31 17:35, Hans Ekbrand wrote:
>>      
>>> Let's say I have a formula like this
>>>
>>> my.fit<- glmer(w ~ 1 + y + (1|x) + (1|x:y) + z)
>>>
>>> Then the summary() output gives information about variance and std.dev
>>> for the random term x:y
>>>
>>> and ranef(my.fit, postVar = TRUE) gives estimates and standard
>>> deviations for x and each value of x:y.
>>>
>>> Is there a way to get a single measure of the variance of y within x?
>>>        
>> I meant to say "a singe measure of the variance of y within x, for each
>> level of y".
>>
>>      
>     I don't think that's something that glmer() estimates -- it
> assumes that the variance is equal for every y-within-x combination.
> I suppose you could just compute the variance of each group of
> conditional modes, i.e. if xyests are your x:y conditional modes
> and xests are your x conditional modes then you could
> tapply(xyests,list(xests),var) ...  someone may suggest something
> better ...
>    

Thanks for your suggestion, Ben. I ended up doing like this.:

my.df <- ranef(my.fit, postVar = TRUE, whichel = "x:y")$x
my.var <- as.numeric(attr(my.df, "postVar"))
foo <- strsplit(rownames(my.df), ":")
the.names <- unique(sapply(1:nrow(my.df), function(x) {foo[[x]][2] }))
the.sd <- sapply(the.names, function(x) {
   these <- grep(paste(":", x, "$", sep = ""), rownames(my.df))
   sqrt(sum(my.var[these])/length(these))
})

I am not really sure about the meaningfulness of this measure, but it 
varied over the levels of y in the way I expected.


From bbolker at gmail.com  Mon Jun  4 23:43:17 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 04 Jun 2012 17:43:17 -0400
Subject: [R-sig-ME] glmmPQL Question
In-Reply-To: <9B956ACF8A1D85448691396E118A6E5B02766421AB@EXLOYCMS.ad.loyola.edu>
References: <9B956ACF8A1D85448691396E118A6E5B02766421AB@EXLOYCMS.ad.loyola.edu>
Message-ID: <4FCD2BF5.9060904@gmail.com>

On 12-06-04 05:38 PM, John Michel wrote:
> Ben


> I have always had an issue getting VarCorr to work with any program
> working from lme4. Here is the error message I get when I try to
> calculate the VarCorr

>> VarCorr(Model.A2)
> Error in VarCorr(Model.A2) : error in evaluating the argument 'x' in
> selecting a method for function 'VarCorr'
> 
> Thanks for any additional suggestions you have for me...
> 
> John

  Do you have nlme loaded at the same time?  Does VarCorr() work if you
detach("package:nlme")? What is the result of sessionInfo()? I can't
quite reproduce your error, but if I load nlme after lme4 I can get

Error in UseMethod("VarCorr") :
  no applicable method for 'VarCorr' applied to an object of class "mer"
> 
> 
> From ?glmmPQL:
> 
> x <- glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID, family =
> binomial, data = bacteria)
> 
> VarCorr(x) ID = pdLogChol(1) Variance  StdDev (Intercept) 1.9898963
> 1.4106368 Residual    0.6084797 0.7800511
> 
> You probably already know that the object returned by VarCorr() has a
> slightly weird format.
> 
> I don't know where your second line, GRPpdSymm(1) comes from??
> 
> VarCorr() should work just fine on lmer objects too.
> 
> Perhaps you can give a reproducible example of what you've tried/ 
> what fails for you? 
> ---------------------------------------------------------- John W.
> Michel, Ph.D. Assistant Professor of Management Sellinger School of
> Business & Management Loyola University Maryland 4501 N. Charles
> Street Baltimore, MD 21201 jwmichel at loyola.edu


From dylan.craven at yale.edu  Mon Jun  4 23:48:49 2012
From: dylan.craven at yale.edu (Dylan Craven)
Date: Mon, 4 Jun 2012 17:48:49 -0400
Subject: [R-sig-ME] variance components (and confidence intervals) for both
 fixed and random effects
Message-ID: <CAJiJPrPnCpgf-trqWUvJCpvnL3=_fhQeu6zjnp1hxkUh_ALu7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120604/ac1e8d56/attachment.pl>

From hans at sociologi.cjb.net  Tue Jun  5 00:07:38 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Tue, 05 Jun 2012 00:07:38 +0200
Subject: [R-sig-ME] Caterpillarplots that compares two models
Message-ID: <4FCD31AA.7060906@sociologi.cjb.net>

Dear list,

I have created caterpillarplots that compare the conditional model with 
the full model, see here for an example: 
http://code.cjb.net/country-differences-working.pdf which was based on 
the following two models:

conditional model:
fit.0 <- glmer(poverty.third.year ~ 1 + (1 | country), family = 
binomial("logit"), data = poverty.risks)

full model:
fit.full <- glmer(poverty.third.year ~ 1 + clustering + (1 | country) + 
(1 | country:clustering) + gender + age.in.years + 
age.minus.mean.age.squared + adults.children.ratio + nr.children + 
pl060.others + education.third.year, family = binomial("logit"), data = 
poverty.risks)

In the example above, the random term (1|country) is very much reduced 
in the full model, very few countries differ significantly from the 
mean. These to fits happen to be the result of fitting the models to a 
subsample (those in the population that had been working for at least 6 
months the last year). When the same models are fitted to the complete 
sample, I get a very different view: 
http://code.cjb.net/country-differences-all.pdf

In general, the random effect of county is smaller, but for some 
countries, Estonia, Lithuania and Ireland, the "effect" of country is 
greater in the full model than in the conditional model. That seems 
rather odd to me. What can be the cause of this?

I am a bit worried about the scale of the random effect, perhaps it is 
not the same for the two fits? I guess that would make the whole idea of 
comparing models within one caterpillar plot a rather bad one.


Below I copy the output of (parts of) summary for each fit:

fit.0 (subsample)
Generalized linear mixed model fit by the Laplace approximation
Formula: poverty.third.year ~ 1 + (1 | country)
Data: poverty.risks
AIC BIC logLik deviance
57343 57362 -28670 57339
Random effects:
Groups Name Variance Std.Dev.
country (Intercept) 0.18511 0.43024
Number of obs: 99714, groups: country, 23

Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -2.56422 0.09103 -28.17 <2e-16 ***
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


fit.full (subsample)
Generalized linear mixed model fit by the Laplace approximation
Formula: poverty.third.year ~ 1 + clustering + (1 | country) + (1 | 
country:clustering) + gender + age.in.years + age.squared.transformed + 
adults.children.ratio + nr.children + pl060.others + education.third.year
Data: poverty.risks
AIC BIC logLik deviance
45996 46243 -22972 45944
Random effects:
Groups Name Variance Std.Dev.
country:clustering (Intercept) 0.00901293 0.094936
country (Intercept) 0.00061525 0.024804
Number of obs: 99714, groups: country:clustering, 337; country, 23

Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -2.030e+03 3.758e+02 -5.40 6.61e-08 ***
clusteringEFT-EFT 8.690e-01 6.168e-02 14.09 < 2e-16 ***
clusteringEFT-retired 1.571e+00 5.512e-01 2.85 0.00437 **
clusteringEFT-unemp/inactive 2.363e+00 8.427e-02 28.04 < 2e-16 ***
clusteringEmpl-us 1.342e+00 6.170e-02 21.75 < 2e-16 ***
clusteringEPT 6.855e-01 9.690e-02 7.07 1.50e-12 ***
clusteringInactive-us 2.301e+00 7.672e-02 29.99 < 2e-16 ***
clusteringInto empl 1.227e+00 8.228e-02 14.92 < 2e-16 ***
clusteringRetired 1.528e+00 1.377e-01 11.09 < 2e-16 ***
clusteringSelf 1.862e+00 5.708e-02 32.61 < 2e-16 ***
clusteringSelf-us 1.988e+00 5.864e-02 33.89 < 2e-16 ***
clusteringStud-EFT 1.323e+00 9.211e-02 14.36 < 2e-16 ***
clusteringStud-us 2.473e+00 9.656e-02 25.61 < 2e-16 ***
clusteringUnemp 3.281e+00 7.584e-02 43.27 < 2e-16 ***
clusteringUnemp-us 2.834e+00 5.732e-02 49.43 < 2e-16 ***
gendermale 1.028e-01 2.700e-02 3.81 0.00014 ***
age.in.years 2.922e-02 7.509e-03 3.89 9.96e-05 ***
age.squared.transformed 5.064e+00 9.391e-01 5.39 6.94e-08 ***
adults.children.ratio 1.848e-01 9.994e-03 18.49 < 2e-16 ***
nr.children 3.495e-01 1.675e-02 20.86 < 2e-16 ***
pl060.others -2.118e-02 4.916e-04 -43.08 < 2e-16 ***
education.third.year.L -1.140e+00 3.254e-02 -35.05 < 2e-16 ***
education.third.year.Q -1.496e-01 2.802e-02 -5.34 9.48e-08 ***
education.third.year.C -1.375e-03 2.389e-02 -0.06 0.95410
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

fit.0 (full sample)
Generalized linear mixed model fit by the Laplace approximation
Formula: poverty.third.year ~ 1 + (1 | country)
Data: poverty.risks
AIC BIC logLik deviance
120558 120578 -60277 120554
Random effects:
Groups Name Variance Std.Dev.
country (Intercept) 0.15613 0.39514
Number of obs: 173439, groups: country, 23

Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -2.18302 0.08297 -26.31 <2e-16 ***
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


fit.full (full sample)
Generalized linear mixed model fit by the Laplace approximation
Formula: poverty.third.year ~ 1 + clustering + (1 | country) + (1 | 
country:clustering) + gender + age.in.years + age.minus.mean.age.squared 
+ adults.children.ratio + nr.children + pl060.others + education.third.year
Data: poverty.risks
AIC BIC logLik deviance
101182 101464 -50563 101126
Random effects:
Groups Name Variance Std.Dev.
country:clustering (Intercept) 0.13222 0.36361
country (Intercept) 0.14338 0.37866
Number of obs: 173439, groups: country:clustering, 391; country, 23

Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -3.1631660 0.1268093 -24.94 < 2e-16 ***
clusteringEFT-EFT 0.9268983 0.1253974 7.39 1.45e-13 ***
clusteringEFT-retired 1.0441078 0.1601783 6.52 7.11e-11 ***
clusteringEFT-unemp/inactive 2.2361878 0.1325487 16.87 < 2e-16 ***
clusteringEmpl-us 1.4730953 0.1251873 11.77 < 2e-16 ***
clusteringEPT 0.9096033 0.1553931 5.85 4.81e-09 ***
clusteringInactive 2.2636346 0.1245034 18.18 < 2e-16 ***
clusteringInactive-us 2.1631165 0.1238853 17.46 < 2e-16 ***
clusteringInto empl 1.1975782 0.1413971 8.47 < 2e-16 ***
clusteringRetired 1.5210071 0.1202705 12.65 < 2e-16 ***
clusteringSelf 1.9703456 0.1252232 15.73 < 2e-16 ***
clusteringSelf-us 2.0602333 0.1236974 16.66 < 2e-16 ***
clusteringStud 1.9668401 0.1289621 15.25 < 2e-16 ***
clusteringStud-EFT 1.1877411 0.1450496 8.19 2.64e-16 ***
clusteringStud-us 2.2431522 0.1266391 17.71 < 2e-16 ***
clusteringUnemp 3.4557231 0.1414965 24.42 < 2e-16 ***
clusteringUnemp-us 2.8435813 0.1204452 23.61 < 2e-16 ***
gendermale -0.0333624 0.0177289 -1.88 0.0599 .
age.in.years -0.0100250 0.0009285 -10.80 < 2e-16 ***
age.minus.mean.age.squared 2.7161514 0.3663032 7.42 1.22e-13 ***
adults.children.ratio 0.0845606 0.0074493 11.35 < 2e-16 ***
nr.children 0.3208252 0.0126444 25.37 < 2e-16 ***
pl060.others -0.0228423 0.0003706 -61.63 < 2e-16 ***
education.third.year.L -1.0252936 0.0232188 -44.16 < 2e-16 ***
education.third.year.Q -0.1133282 0.0195783 -5.79 7.10e-09 ***
education.third.year.C 0.0194027 0.0163584 1.19 0.2356
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


From David.Duffy at qimr.edu.au  Tue Jun  5 01:32:07 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 5 Jun 2012 09:32:07 +1000 (EST)
Subject: [R-sig-ME] lme4, cloglog vs. binomial link
In-Reply-To: <7A4C46CB-970C-4B6C-93AF-297AB57ED8CC@linguistics.rub.de>
References: <7A4C46CB-970C-4B6C-93AF-297AB57ED8CC@linguistics.rub.de>
Message-ID: <Pine.LNX.4.64.1206050838010.30029@orpheus.qimr.edu.au>

On Mon, 4 Jun 2012, Tibor Kiss wrote:

> In the following mixed models, *target_noun_lemma* is the representation 
> of the noun in the construction, its categorical value being one of the 
> 712 different nouns in the sample. The sample contains 6.841 different 
> instances of the construction: 810 instances of determiner omission and 
> 6.031 instances of determiner realization.

>
> The distribution of *target_noun_lemma* is highly skewed (which is 
> standard for language samples): the top five nouns occur 1.225, 466, 
> 443, 414, and 304 times
>
> The model seems to be worse in terms of AIC (2360 compared to 2302),
>
> 1. Is it correct to assume that given a cloglog link, the less frequent 
> response should be considered the success?
> 2. Is it correct to conclude 
> that the changes in the model have led to less influence of the random 
> factor?
> 3. How shall I react to the increase in AIC?
>

I found all this quite dizzying.  I would first look for an optimal link 
function in a fixed effect GLM for a dataset of your top 5 nouns. I don't 
think you can read much into the scale of the random effects estimates 
using different link functions.  The other way of doing these things is 
changing the distribution of the random effects - for a single random 
effect like this there are nonparametric/mixture models (you could 
interpret this as clustering your nouns into families).

Interpretation of the AICs depends on the internals of the loglik 
for the different links.  They should be comparable, in which case 
logit good, cloglog bad.

> I am most curious to learn about possible
> modifications of the model so that an observed random effect can be 
> minimized

You can sometimes get rid of a random effect completely by transformation. 
The examples I know of are for continuous Y and crossed factors (additive 
and dominant genetic variances), where one factor can be removed.

Cheers, David Duffy.


From John.Morrongiello at csiro.au  Tue Jun  5 03:36:48 2012
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Tue, 5 Jun 2012 11:36:48 +1000
Subject: [R-sig-ME] HPD intervals for fixed parameters in model
In-Reply-To: <4FCC5FCC.7090903@gmail.com>
References: <mailman.1.1338631201.31638.r-sig-mixed-models@r-project.org>
	<D7383CD4D59FEA4DA879EF5096A5A8CB17D49998B5@exvic-mbx03.nexus.csiro.au>
	<4FCC5FCC.7090903@gmail.com>
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB17D49998B8@exvic-mbx03.nexus.csiro.au>

Log transforming the Age variable prior to putting it in the model solved the problem of a random slope in glmmADMB. 

Thanks also to Ben for the note about the different covariance matrices in use. I did a bit more reading on this, especially for MCMCglmm, and came up with the following model structures. Are the following lmer, MCMCglmm and glmmADMB roughly comparable?

*Variation in fish intercepts, variation in Age slopes, correlation between intercept and slope:

M1lmer<-lmer(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),data,REML=T)
M1mcmc<-MCMCglmm(log(Increment)~logAge+temp,random=~us(1+logAge):FishID + fYear,rcov= ~units, data=data, prior=prior)##us allows for intercept and slope covariance
##not possible with glmmADMB??

* Variation in fish intercepts and age slopes, but no correlation between intercept and slope:

M2lmer<-lmer(log(Increment)~logAge+temp+(1+FishID)+(0+logAge|FishID)+(1|Year),data,REML=F)##REML= FALSE is equivalent to glmmADMB?
M2mcmc<-MCMCglmm(log(Increment)~logAge+temp,random=~idh(1+logAge):FishID + fYear,rcov= ~units, data=data, prior=prior)##idh sets covariance between intercept and slope to zero (also could use idh(logAge):FishID+FishID)
M2glmmADMB<-glmmadmb(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),NSWtiger,family='gaussian')

Cheers

John

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Monday, 4 June 2012 5:12 PM
To: Morrongiello, John (CMAR, Hobart)
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] HPD intervals for fixed parameters in model

On 12-06-04 03:03 AM, John.Morrongiello at csiro.au wrote:
> Hi Ben
> 
> Thanks very much for the response. I've tried both MCMCglmm and glmmADMB and am happy with the parameter estimates and the HPD intervals they produce. The only issue was specifying the random age slope in glmmADMB (as per M1admb below). It seems to only accept random factors- is it possible to specify a random slope? 
> 
> M1admb<-glmmadmb(log(Increment)~log(Age)+temp+(log(Age)|FishID)+(1|fYear),data,family='gaussian')
> 
> Warning message:
> In Ops.factor(log(Age), FishID) : | not meaningful for factors
> Error in model.matrix(as.formula(paste("~", lbit)), mdata) : 
>   error in evaluating the argument 'object' in selecting a method for function 'model.matrix': Error in parse(text = x) : <text>:2:0: unexpected end of input
> 1: ~ 
>   ^
> 
> Cheers
> 
> John

  As a quick possible workaround, try defining data$logAge <-
log(data$Age) and using (logAge|FishID) in your model formula; I'm not
sure that glmmADMB can handle defining variable transformations on the
fly in that context.

  Also be aware that the default for lme4 is to use the full correlation
matrix while glmmADMB uses a diagonal matrix, so (e.g.) (logAge|FishID)
would estimate three parameters (variation in intercept across fish,
variation in slope across fish, covariance between intercept and slope)
while glmmADMB would only estimate the first two.  (I think you have to
specify this choice explicitly in MCMCglmm.)

> 
> 
> Message: 4
> Date: Fri, 1 Jun 2012 16:44:51 +0000 (UTC)
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] HPD intervals for fixed parameters in model
> 	with	crossed and correlated random effects
> Message-ID: <loom.20120601T183904-68 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
> 
>  <John.Morrongiello at ...> writes:
> 
> 
>> I'd very much like to calculate some HPD intervals for the fixed
>> parameters in a lmer model containing crossed and correlated random
>> effects. However, I have not been able to find a solution for this
>> type of model after a pretty thorough search of discussion threats
>> or worked examples. Is this possible at the moment with lme4
>> (function or work around), or do I have to change packages and try
>> something like mcmcglmm?
> 
>   I think if you want to compute HPD intervals you are more or less
> stuck with MCMCglmm or glmmADMB ....
>  
>> My data contains 1917 growth measurements (Increment) from 704 fish
>> (FishID) and the data is sampled from 29 years (Year). I'm
>> interested in the effects of age (2-18 years) and water temperature
>> (temp) on growth.  My model is:
>  
>> M1<-lmer(log(Increment)~log(Age)+temp+(log(Age)|FishID)+(1|Year),
>>   data,REML=T)
>>
>> HPDinterval requires an mcmc object, but when I try
>> mcmcsamp(M1, n=1000)
>>
>> I receive the following error:
>> Error in .local(object, n, verbose, ...) :
>>   Code for non-trivial theta_T not yet written
> 
> 
>> I understand this is because MCMCsamp doesn't yet cope with
>> correlated random effects? On the glmm wikidot page there is code to
>> generate confidence and prediction intervals on predictions- could I
>> use some of N this to get a what I'm after (if so, which bits)? I
>> haven't used mcmcglmm before, so ideally would like to stay with the
>> more familiar lme4 if possible to expedite the analyses! 
> 
>    I don't think so, I think you'll need MCMCglmm or glmmADMB.
> 
> In principle glmmADMB should work with your model more or less as-is
> (although I don't remember whether it can do REML-y stuff or not),
> and you can use mcmc=TRUE to get it to run an MCMC chain on the
> parameters for you.  However, based on my limited experience, if
> you do want to get MCMC working it will be easier using MCMCglmm
> (which is intrinsically based on MCMC, and does a bunch of clever
> stuff to make the chains mix well).
> 
>   good luck,
>     Ben Bolker
> 


From bbolker at gmail.com  Tue Jun  5 09:38:38 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 5 Jun 2012 07:38:38 +0000 (UTC)
Subject: [R-sig-ME] HPD intervals for fixed parameters in model
References: <mailman.1.1338631201.31638.r-sig-mixed-models@r-project.org>
	<D7383CD4D59FEA4DA879EF5096A5A8CB17D49998B5@exvic-mbx03.nexus.csiro.au>
	<4FCC5FCC.7090903@gmail.com>
	<D7383CD4D59FEA4DA879EF5096A5A8CB17D49998B8@exvic-mbx03.nexus.csiro.au>
Message-ID: <loom.20120605T092120-944@post.gmane.org>

 <John.Morrongiello at ...> writes:

>  Log transforming the Age variable prior to putting it in the model
> solved the problem of a random slope in glmmADMB.

[snip]
> Are the following lmer,
> MCMCglmm and glmmADMB roughly comparable?

> *Variation in fish intercepts, variation in Age slopes, correlation between
intercept and slope:
> 
> M1lmer<-lmer(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),
>        data,REML=T)
> M1mcmc<-MCMCglmm(log(Increment)~logAge+temp,
          random=~us(1+logAge):FishID + fYear,rcov= ~units,
          data=data, prior=prior)
> ##us allows for intercept and slope covariance

I believe the glmmadmb syntax here would be

M1glmmadmb <- glmmadmb(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),
        data,corStruct="full",family="gaussian")

A couple of notes:

* glmmadmb() uses _Poisson_ family by default (it was originally
designed for GLMMs, not LMMs)
* I believe that neither MCMCglmm nor glmmadmb is doing REML here
 (although technically MCMCglmm isn't doing likelihood estimation
  in any case, and at the moment I can't think about the correspondence
 between marginal posterior means and REML estimates of variances ...)

 
> * Variation in fish intercepts and age slopes, but no correlation
> between intercept and slope:
 
> M2lmer<-lmer(log(Increment)~logAge+temp+(1+FishID)+(0+logAge|FishID)+
> (1|Year),data,REML=F)

> ##REML= FALSE is equivalent to glmmADMB?

  I think so.

> M2mcmc<-MCMCglmm(log(Increment)~logAge+temp,
      random=~idh(1+logAge):FishID + fYear,rcov=~units, 
     data=data, prior=prior)
 ##idh sets covariance between intercept and slope to zero (also could
##  use idh(logAge):FishID+FishID)

 M2glmmADMB<-glmmadmb(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),
  NSWtiger,family='gaussian')

  I think that's all right.

  You know, the easiest way to check these correspondences is just
to try them (especially on simple simulated data where you know
what the true answer should be).


From ramos.grad.student at gmail.com  Wed Jun  6 00:06:21 2012
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 5 Jun 2012 15:06:21 -0700
Subject: [R-sig-ME] bug in predict.lme ?
Message-ID: <CAHawB9ucGVn+7w-Aw6xRh4_C-Z7zSrms1FBN6YOO+rpVZi4bsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120605/b4435266/attachment.pl>

From John.Morrongiello at csiro.au  Wed Jun  6 02:08:58 2012
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Wed, 6 Jun 2012 10:08:58 +1000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 66, Issue 8
In-Reply-To: <mailman.3.1338890401.23834.r-sig-mixed-models@r-project.org>
References: <mailman.3.1338890401.23834.r-sig-mixed-models@r-project.org>
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB17D49998BD@exvic-mbx03.nexus.csiro.au>

Thanks very much for casting an eye over these Ben. I had a bit of a play around with the different models and they looked similar, but just wanted to be sure that I wasn't missing something glaringly obvious.

John

 
<John.Morrongiello at ...> writes:

>  Log transforming the Age variable prior to putting it in the model
> solved the problem of a random slope in glmmADMB.

[snip]
> Are the following lmer,
> MCMCglmm and glmmADMB roughly comparable?

> *Variation in fish intercepts, variation in Age slopes, correlation between
intercept and slope:
> 
> M1lmer<-lmer(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),
>        data,REML=T)
> M1mcmc<-MCMCglmm(log(Increment)~logAge+temp,
          random=~us(1+logAge):FishID + fYear,rcov= ~units,
          data=data, prior=prior)
> ##us allows for intercept and slope covariance

I believe the glmmadmb syntax here would be

M1glmmadmb <- glmmadmb(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),
        data,corStruct="full",family="gaussian")

A couple of notes:

* glmmadmb() uses _Poisson_ family by default (it was originally
designed for GLMMs, not LMMs)
* I believe that neither MCMCglmm nor glmmadmb is doing REML here
 (although technically MCMCglmm isn't doing likelihood estimation
  in any case, and at the moment I can't think about the correspondence
 between marginal posterior means and REML estimates of variances ...)

 
> * Variation in fish intercepts and age slopes, but no correlation
> between intercept and slope:
 
> M2lmer<-lmer(log(Increment)~logAge+temp+(1+FishID)+(0+logAge|FishID)+
> (1|Year),data,REML=F)

> ##REML= FALSE is equivalent to glmmADMB?

  I think so.

> M2mcmc<-MCMCglmm(log(Increment)~logAge+temp,
      random=~idh(1+logAge):FishID + fYear,rcov=~units, 
     data=data, prior=prior)
 ##idh sets covariance between intercept and slope to zero (also could
##  use idh(logAge):FishID+FishID)

 M2glmmADMB<-glmmadmb(log(Increment)~logAge+temp+(logAge|FishID)+(1|fYear),
  NSWtiger,family='gaussian')

  I think that's all right.

  You know, the easiest way to check these correspondences is just
to try them (especially on simple simulated data where you know
what the true answer should be).


From tmoranlopez at mncn.csic.es  Wed Jun  6 18:57:56 2012
From: tmoranlopez at mncn.csic.es (MORAN LOPEZ, TERESA)
Date: Wed, 06 Jun 2012 18:57:56 +0200
Subject: [R-sig-ME] Running multinomial models with random effects
Message-ID: <20120606185756.15195j04rwudxb84@webmail.csic.es>

Dear all,
I am a phD student working on animal behavior under different  
predation risk. We have conducted an experiment in which acorn  
selection by jays was evaluated in savanna vs forest-type  landscapes.  
  We placed 8 feeders in two different forests and 8 feeders in two  
different savannas.
My response variable is factorial, acorn choice (big, small, both).   
In my design I have spatial pseudorreplication within Areas.  I have  
not found multinom function which allows fitting random effects.  
However, MCMCglmm package allows incorporating them using Bayesian  
Methods. I am new using Bayesian Methods so it has taken me a lot of  
effort to partially understand these models implementation. However,  
once I have run my model I am not sure about output interpretation and  
most importantly how to convert fix effect parameters into  
probabilities.

I have tried three different things: to convert my data in binomial  
(ignoring  infrequent acorn choice ?both?) and run mixed model lmer.   
Pros: I can include random effects , Cons: I lose an infrequent but  
informative level of the response.

  Keep categorical responses and run multinom function without random  
effects.  Pros: I can fit my response variable as categorical and keep  
all levels. Cons: I am ignoring spatial autocorrelation (however, when  
running binomial models acorn choice variation between areas was much  
more lower than between risk levels).
  +
Run MCMCglmm model with random effects. Pros:  I can keep both spatial  
autocorrelation and all levels of the response factor. Cons: Not sure  
about  model implementation and interpretation. Low sample size.


Which option is the most accurate?

Thanks a lot! I am really stucked with my data.

Here I post my MCMCglmm model which is the one I have more doubts

#head(choice)-dataset with choice as factor  (b=big, s=small, bt=both)
    RISK       Area             CHOICE
LOW        Sopie                  b
  LOW       Sopie                  b
  LOW      Sopie                   b
  LOW  Anchurones                  s
  LOW  Anchurones                  bt
  LOW  Anchurones                  b

  I have read package tutorial and Hadfield notes (though I have not  
read all the chapter of Hadfield course notes). Besides I have used  
information posted  Jaeger lab blog:  
http://hlplab.wordpress.com/2009/05/07/multinomial-random-effects-models-in-r/

I am not very sure about random effects priors but I believe the rest  
of them are ok.
k <- length(levels(choice$CHOICE))
I<- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
#Constraints to variance-covariance matrix

prior = list(R = list(fix=1, V =(1/k) * (I + J), n=k), G = list(G1 =  
list(V =diag(2), n=2)))

#R priors, Hadfield manual suggests that structure. Are they right?   
NOT SURE ABOUT RANDOM PRIORS.

M<- MCMCglmm(CHOICE~ -1+ trait + RISK,
               random = ~ us(trait):Area,
               rcov = ~ us(trait):units,
               prior = prior,
               family = "categorical",
               data = choice)

#-1+trait following Hadfield suggestions in order to estimate  
interception if every outcome.
us(trait):-----  since we are not sure of independence assumptions. Is  
model function allright?

My model runs but I find it very difficult to interpret my summary

summary(M)

Iterations = 3001:12991
  Thinning interval  = 10
  Sample size  = 1000

  DIC: 44.21802

  G-structure:  ~us(trait):Area

                          post.mean l-95% CI u-95% CI eff.samp
CHOICE.bt:CHOICE.bt.Area    14.622   0.1881    64.46    7.278
CHOICE.s:CHOICE.bt.Area      3.274 -11.1431    19.29  116.593
CHOICE.bt:CHOICE.s.Area      3.274 -11.1431    19.29  116.593
CHOICE.s:CHOICE.s.Area       5.071   0.1416    15.82  127.395

  R-structure:  ~us(trait):units

                           post.mean l-95% CI u-95% CI eff.samp
CHOICE.bt:CHOICE.bt.units    0.6667   0.6667   0.6667        0
CHOICE.s:CHOICE.bt.units     0.3333   0.3333   0.3333        0
CHOICE.bt:CHOICE.s.units     0.3333   0.3333   0.3333        0
CHOICE.s:CHOICE.s.units      0.6667   0.6667   0.6667        0

  Location effects: CHOICE ~ -1 + trait + RISK

                post.mean l-95% CI u-95% CI eff.samp pMCMC
traitCHOICE.bt   -4.5042 -11.8926   0.3824    15.18 0.052 .
traitCHOICE.s    -2.0187  -6.3370   1.3569    84.55 0.200
RISKRA?A          1.9095  -2.3541   8.2421    56.13 0.336
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

posterior.mode(M$Sol)

traitCHOICE.bt   traitCHOICE.s       RISKRA?A
      -2.594132      -1.836527             1.554387

#Since there is not any intercept I can?t apply plogis() in order to  
get probabilities of choice in different areas.


Sorry that I have that many  questions and thanks a lot!!!


From ronstone1980 at gmail.com  Wed Jun  6 17:39:56 2012
From: ronstone1980 at gmail.com (Ron Stone)
Date: Wed, 6 Jun 2012 17:39:56 +0200
Subject: [R-sig-ME] interpretation of main effect when interaction term
 being significant (ex. lme)
Message-ID: <CAMqQQP0oFh2T+h4bgstqodkbFAFXh2YB4=TOg6Tfyb3BV=yJtg@mail.gmail.com>

Dear all,

I first posted this to the basic R-list, although since the example is
mixed effects model it may be more proper to post it to
r-sig-mixed-models. This question may be too basic quesition for this
list, but if someone has time to answer I will be happy. I have tried
to find out, but haven't found a consice answer.

As an example I use "Pinheiro, J. C. & Bates, D. M. 2000.
Mixed-effects models in S and S-PLUS. Springer, New York." page 225,
where rats are fed by 3 different diets over time, which body mass has
been measured. Response: Body mass, fixed effects Time*Diet, random
effect ~Time|Rat. The main question with this test?was if the
interaction term is significant (i.e. growth rate). However, my
question is could I also look at the p-values of the main effects to
say if body mass increase significant with body mass?

>From Pinheiro, J. C. & Bates, D. M. (2000)

Fixed effects: weight ~Time * Diet

????????????????? Value???? St.error??? DF??? t-value?? p-value
Intercept??? 251.60????? 13.068?? 157?? 19.254??? <.0001
Time????????? 0.36?????????? 0.088????? 13???? 4.084??? 0.0001
Diet2????????? 200.78????? 22.657???? 13???? 8.862?? <.0001
Diet3????????? 252.17????? 22.662??? 157? 11.127?? <.0001
TimeDiet2? 0.60?????????? 0.155???? 157??? 3.871????? 0.0002
TimeDiet3? 0.30?????????? 0.156???? 157??? 1.893????? 0.0602

As stated by Pinheiro, J. C. & Bates, D. M. (2000), the growth rate of
diet 2 (TimeDiet2) differs significantly from diet 1. Although could I
from this also say that body mass increase significantly with time for
diet 1? Like this: f(x) = 251.60 (+/-13.068) + 0.36 x (+/- 0.088), t =
4.084, p = 0.0001? I have seen that people have claimed that it is
wrong to interpret p-values for the main effects when the interaction
is significant. Is it more proper to split the data and run the test
(weight ~Time) for each diet seperately, when looking at the effect of
time on body mass?

Best regards Ron


From esther.frei at env.ethz.ch  Wed Jun  6 20:39:43 2012
From: esther.frei at env.ethz.ch (Frei  Esther)
Date: Wed, 6 Jun 2012 18:39:43 +0000
Subject: [R-sig-ME] contrasts in lmer models
Message-ID: <13BC8E08D754714D9DEF568069DA770503D7DF3B@MBX11.d.ethz.ch>

Dear R experts,

I am fitting a linear mixed model with lmer. Some of the a-priori-contrasts I want to test involve interaction terms. I ran into serious trouble when I tried to test these contrasts:

1. For testing interactions in the fixed factors, I tried using fit.contrast() from the gmodels-package. In principle this works, but the results I get are very suspicious. They vary quite a lot if I execute fit.contrasts several times. I have increased the number of samples from the default  1000 up to 200,000. However, the results don't seem to converge. It seems also strange that sometimes p-values are exactly 0. Does it mean that the contrasts are highly significant (i.e. smaller than the number of decimals displayed in the result)? Or is there something wrong in the way I use the function? Maybe I simply have to run more samples with my complex model?

> require("gmodels")
> ffin <- lmer(y ~ CoV + Alt + Orig + Soil + (1 | Bed) + (1 | Site) + (1 | Pair),  data = TETri,
+             na.action = na.exclude, REML=TRUE)
> cmat <- rbind("First Contrast (600m vs.1200m)"= c(1,0,-1),"Second Contrast (1200m vs.1800m)"=
 +                         c(1,-1,0))

> fit.contrast(ffin,"Alt",cmat,conf.int=0.95,sim.mer=TRUE,n.sim=5000)
                                                                        Estimate Std. Error   p value  Lower.CI    Upper.CI
AltFirst Contrast (600m vs.1200m)   -4.879821   0.979278 0.0000000 -6.317718 -3.86426640
AltSecond Contrast (1200m vs.1800m) -2.867170   1.796602 0.3333333 -4.593912  0.03296012


2. Some of the contrasts that I want to test involve interaction terms. As I understand these cannot directly be approached with fix.contrasts(). Instead I tried to recode the contrast terms into a new combined variable using factorA.factorB = paste(factorA,factorB,sep="."). This only works when I also refit the model with only the new combined factor as fixed effect but results in suspicious p-values of '0'. As I understand, this is not the same model anymore and so it is not very useful.

> TETri$O.A.Soil  <- as.factor(paste(TETri$Orig, TETri$Alt, TETri$Soil, sep= levels(TETri$O.A.Soil) 
> cmat_1 <- rbind("HA Orig12 (O12.T12.SOL vs. O18.T18.GRA)"= c(0,1,0,0,0,0,0,0,-1,0,0,0),"LF Orig12 +                              (O12.T12.SOL vs. O18.T12.SOL)"= c(0,1,0,0,0,0,0,-1,0,0,0,0))
> f1c <- lmer(y ~ CoV + O.A.Soil + (1 | Bed) + (1 | Site) + (1 | Pair),  data = TETri,
+            na.action = na.exclude, REML=TRUE)
> fit.contrast(f1c,"O.A.Soil",cmat_1,conf.int=0.95,sim.mer=TRUE,n.sim=1000)
                                                                                            Estimate Std. Error p value   Lower.CI   Upper.CI
O.A.SoilHA Orig12 (O12.T12.SOL vs. O18.T18.GRA) -3.958218   2.110968       0 -6.6922765 -0.7359227
O.A.SoilLF Orig12 (O12.T12.SOL vs. O18.T12.SOL)  2.714403   1.387434       0  0.5868685  5.3193961


3. Using the function estimable() from gmodels, I have trouble specifying the contrast matrix correctly. The help entry does not really give a good example how to indicate the factor to which I want to refer to. Could anyone give me a hint (example) how to define the contrasts correctly, please?
> f0 <- lmer(y ~ CoV + Alt * Orig * Soil + (1 | Bed) + (1 | Site) + (1 | Pair),  data = TETri,
+             na.action = na.exclude, REML=TRUE)
> cmat <- rbind('Alt600m vs.Alt1200m'= c(1,0,-1),'Alt1200m vs.Alt1800m'= c(1,-1,0))
> estimable(f0,cmat)
Error in FUN(newX[, i], ...) : 'param' has no names and does not match number of coefficients of model. Unable to construct coefficient vector


4. My last question is a general question not specifically related to R: If one of the fixed terms in my mixed model is not significant overall, is it possible that one of the contrasts between levels of that term is still significant?

Thanks a lot for your help!
Esther


From dwinsemius at comcast.net  Wed Jun  6 22:44:33 2012
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Jun 2012 16:44:33 -0400
Subject: [R-sig-ME] interpretation of main effect when interaction term
	being significant (ex. lme)
In-Reply-To: <CAMqQQP0oFh2T+h4bgstqodkbFAFXh2YB4=TOg6Tfyb3BV=yJtg@mail.gmail.com>
References: <CAMqQQP0oFh2T+h4bgstqodkbFAFXh2YB4=TOg6Tfyb3BV=yJtg@mail.gmail.com>
Message-ID: <F72742F6-A7D6-4A11-B01B-CB2D250CDA7E@comcast.net>


On Jun 6, 2012, at 11:39 AM, Ron Stone wrote:

> Dear all,
>
> I first posted this to the basic R-list, although since the example is
> mixed effects model it may be more proper to post it to
> r-sig-mixed-models. This question may be too basic quesition for this
> list, but if someone has time to answer I will be happy. I have tried
> to find out, but haven't found a consice answer.

I'm copying a comment from one of the replies to which I was halfway  
through a response when I saw this appear. (I'm not an expert in this  
so I'm very prepared to accept critique.)

On Jun 6, 2012, at 12:54 PM, arun wrote:

> Hi Ron,
>
> When the interaction is significant, I will not look at the  
> significance of main effects as the main effect significance are  
> irrelevant.  Then the comparisons could be made between the simple  
> effect means.
-----------
A)
The general rule not to interpret main effects estimates in models  
with interaction terms is certainly valid, but what was asked was  
whether the reported Time estimate could applied to baseline case of  
Diet==1. So, no interaction considerations actually adhere to both the  
estimates and the question at hand.

B)
(I have cracked open my copy of P&B and looked at the graphs and think  
that 0.36 is a sensible result for the slope in Diet group 1. I will  
not that that the df in the table below are not correct. Time should  
have df=157 if it were to agree with P&B (2000) text. )

I see that Ron has now cross-posted to R-SIG-ME, so if you address  
this to that group I will see it.

My check with lmer:

(fm1BW.lmer <- lmer(weight~Time*Diet+(Time|Rat), BodyWeight))
(fm1BW.lmer <- lmer(weight~Time*Diet+(Time|Rat)+(Diet|Rat), BodyWeight))

I'm very open to corrections on the model construction. The Time and  
Diet estimates are the same although the std-errors are different for  
Diet.

-- 
David.
>
> As an example I use "Pinheiro, J. C. & Bates, D. M. 2000.
> Mixed-effects models in S and S-PLUS. Springer, New York." page 225,
> where rats are fed by 3 different diets over time, which body mass has
> been measured. Response: Body mass, fixed effects Time*Diet, random
> effect ~Time|Rat. The main question with this test was if the
> interaction term is significant (i.e. growth rate). However, my
> question is could I also look at the p-values of the main effects to
> say if body mass increase significant with body mass?
>
>> From Pinheiro, J. C. & Bates, D. M. (2000)
>
> Fixed effects: weight ~Time * Diet
>
>                   Value     St.error    DF    t-value   p-value
> Intercept    251.60      13.068   157   19.254    <.0001
> Time          0.36           0.088      13     4.084    0.0001
> Diet2          200.78      22.657     13     8.862   <.0001
> Diet3          252.17      22.662    157  11.127   <.0001
> TimeDiet2  0.60           0.155     157    3.871      0.0002
> TimeDiet3  0.30           0.156     157    1.893      0.0602
>
> As stated by Pinheiro, J. C. & Bates, D. M. (2000), the growth rate of
> diet 2 (TimeDiet2) differs significantly from diet 1. Although could I
> from this also say that body mass increase significantly with time for
> diet 1? Like this: f(x) = 251.60 (+/-13.068) + 0.36 x (+/- 0.088), t =
> 4.084, p = 0.0001? I have seen that people have claimed that it is
> wrong to interpret p-values for the main effects when the interaction
> is significant. Is it more proper to split the data and run the test
> (weight ~Time) for each diet seperately, when looking at the effect of
> time on body mass?
>
> Best regards Ron
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius, MD
West Hartford, CT


From pdalgd at gmail.com  Wed Jun  6 22:54:16 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 6 Jun 2012 22:54:16 +0200
Subject: [R-sig-ME] lme4, cloglog vs. binomial link
In-Reply-To: <7A4C46CB-970C-4B6C-93AF-297AB57ED8CC@linguistics.rub.de>
References: <7A4C46CB-970C-4B6C-93AF-297AB57ED8CC@linguistics.rub.de>
Message-ID: <7658F572-AEE2-4127-AB77-321B5B6C3D69@gmail.com>


On Jun 4, 2012, at 13:07 , Tibor Kiss wrote:

> [...snippage...]
> My questions are as follows:
> 
> 1. Is it correct to assume that given a cloglog link, the less frequent response should be considered the success?

No, cloglog is asymmetric, so it will make a difference which outcome is considered success, but there is no mathematical reason to choose between them. In survival data, the cloglog comes out of the proportional hazards model when you have death within a fixed time period as the response (exact date of death not recorded). In that case, death is "success" (!); hopefully, it is the least likely outcome, but it might not be. If cloglog is just used as a generic link function, then no such logic applies.

> 2. Is it correct to conclude that the changes in the model have led to less influence of the random factor?

No. The scales are different. At the very least, you need to somehow compare it to the fixed effects on the same scale. 

> 3. How shall I react to the increase in AIC?

(Or, equivalently, the deviance). The cloglog link model seems to give the worse fit to data. 

> A final question, which may not have an answer at all: I am most curious to learn about possible modifications of the model so that an observed random effect can be minimized (while its presence cannot be denied). 

First, is that desirable, and why? The only logic, that I can think of, is that you want to get the fixed-effect part of the model right, so that the error is not mistakenly taken as part of the random variation.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maj at waikato.ac.nz  Wed Jun  6 23:21:37 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Thu, 7 Jun 2012 09:21:37 +1200
Subject: [R-sig-ME] lme4, cloglog vs. binomial link (peter dalgaard)
Message-ID: <CAE85cPknAqUFxhbEnvHjoz-_UE6Svs6HJMpGgJ0GC3mcGFFTOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120607/eede6ce7/attachment.pl>

From chris at trickysolutions.com.au  Thu Jun  7 04:41:06 2012
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 7 Jun 2012 12:41:06 +1000
Subject: [R-sig-ME] Running multinomial models with random effects
In-Reply-To: <20120606185756.15195j04rwudxb84@webmail.csic.es>
References: <20120606185756.15195j04rwudxb84@webmail.csic.es>
Message-ID: <-3751203455738720197@unknownmsgid>

I'm not neccsarily advocating this. But another way is to use 3
logistic models with random effects.   One for wether they choose big
acorn, one for small, one for both. Then compare the parameters of all
3 to see if there are any differences.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

On 07/06/2012, at 3:00, "MORAN LOPEZ, TERESA" <tmoranlopez at mncn.csic.es> wrote:

> Dear all,
> I am a phD student working on animal behavior under different predation risk. We have conducted an experiment in which acorn selection by jays was evaluated in savanna vs forest-type  landscapes.  We placed 8 feeders in two different forests and 8 feeders in two different savannas.
> My response variable is factorial, acorn choice (big, small, both).  In my design I have spatial pseudorreplication within Areas.  I have not found multinom function which allows fitting random effects. However, MCMCglmm package allows incorporating them using Bayesian Methods. I am new using Bayesian Methods so it has taken me a lot of effort to partially understand these models implementation. However, once I have run my model I am not sure about output interpretation and most importantly how to convert fix effect parameters into probabilities.
>
> I have tried three different things: to convert my data in binomial (ignoring  infrequent acorn choice ?both?) and run mixed model lmer.  Pros: I can include random effects , Cons: I lose an infrequent but informative level of the response.
>
> Keep categorical responses and run multinom function without random effects.  Pros: I can fit my response variable as categorical and keep all levels. Cons: I am ignoring spatial autocorrelation (however, when running binomial models acorn choice variation between areas was much more lower than between risk levels).
> +
> Run MCMCglmm model with random effects. Pros:  I can keep both spatial autocorrelation and all levels of the response factor. Cons: Not sure about  model implementation and interpretation. Low sample size.
>
>
> Which option is the most accurate?
>
> Thanks a lot! I am really stucked with my data.
>
> Here I post my MCMCglmm model which is the one I have more doubts
>
> #head(choice)-dataset with choice as factor  (b=big, s=small, bt=both)
>   RISK       Area             CHOICE
> LOW        Sopie                  b
> LOW       Sopie                  b
> LOW      Sopie                   b
> LOW  Anchurones                  s
> LOW  Anchurones                  bt
> LOW  Anchurones                  b
>
> I have read package tutorial and Hadfield notes (though I have not read all the chapter of Hadfield course notes). Besides I have used information posted  Jaeger lab blog: http://hlplab.wordpress.com/2009/05/07/multinomial-random-effects-models-in-r/
>
> I am not very sure about random effects priors but I believe the rest of them are ok.
> k <- length(levels(choice$CHOICE))
> I<- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> #Constraints to variance-covariance matrix
>
> prior = list(R = list(fix=1, V =(1/k) * (I + J), n=k), G = list(G1 = list(V =diag(2), n=2)))
>
> #R priors, Hadfield manual suggests that structure. Are they right?  NOT SURE ABOUT RANDOM PRIORS.
>
> M<- MCMCglmm(CHOICE~ -1+ trait + RISK,
>              random = ~ us(trait):Area,
>              rcov = ~ us(trait):units,
>              prior = prior,
>              family = "categorical",
>              data = choice)
>
> #-1+trait following Hadfield suggestions in order to estimate interception if every outcome.
> us(trait):-----  since we are not sure of independence assumptions. Is model function allright?
>
> My model runs but I find it very difficult to interpret my summary
>
> summary(M)
>
> Iterations = 3001:12991
> Thinning interval  = 10
> Sample size  = 1000
>
> DIC: 44.21802
>
> G-structure:  ~us(trait):Area
>
>                         post.mean l-95% CI u-95% CI eff.samp
> CHOICE.bt:CHOICE.bt.Area    14.622   0.1881    64.46    7.278
> CHOICE.s:CHOICE.bt.Area      3.274 -11.1431    19.29  116.593
> CHOICE.bt:CHOICE.s.Area      3.274 -11.1431    19.29  116.593
> CHOICE.s:CHOICE.s.Area       5.071   0.1416    15.82  127.395
>
> R-structure:  ~us(trait):units
>
>                          post.mean l-95% CI u-95% CI eff.samp
> CHOICE.bt:CHOICE.bt.units    0.6667   0.6667   0.6667        0
> CHOICE.s:CHOICE.bt.units     0.3333   0.3333   0.3333        0
> CHOICE.bt:CHOICE.s.units     0.3333   0.3333   0.3333        0
> CHOICE.s:CHOICE.s.units      0.6667   0.6667   0.6667        0
>
> Location effects: CHOICE ~ -1 + trait + RISK
>
>               post.mean l-95% CI u-95% CI eff.samp pMCMC
> traitCHOICE.bt   -4.5042 -11.8926   0.3824    15.18 0.052 .
> traitCHOICE.s    -2.0187  -6.3370   1.3569    84.55 0.200
> RISKRA?A          1.9095  -2.3541   8.2421    56.13 0.336
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> posterior.mode(M$Sol)
>
> traitCHOICE.bt   traitCHOICE.s       RISKRA?A
>     -2.594132      -1.836527             1.554387
>
> #Since there is not any intercept I can?t apply plogis() in order to get probabilities of choice in different areas.
>
>
> Sorry that I have that many  questions and thanks a lot!!!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tmoranlopez at mncn.csic.es  Thu Jun  7 10:31:40 2012
From: tmoranlopez at mncn.csic.es (MORAN LOPEZ, TERESA)
Date: Thu, 07 Jun 2012 10:31:40 +0200
Subject: [R-sig-ME] Running multinomial models with random effects
In-Reply-To: <-3751203455738720197@unknownmsgid>
References: <20120606185756.15195j04rwudxb84@webmail.csic.es>
	<-3751203455738720197@unknownmsgid>
Message-ID: <20120607103140.16232bmjomxwcx64@webmail.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120607/4802dc20/attachment.pl>

From m.fairbrother at bristol.ac.uk  Thu Jun  7 13:49:17 2012
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 7 Jun 2012 12:49:17 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 66, Issue 11
In-Reply-To: <mailman.3.1339063201.16753.r-sig-mixed-models@r-project.org>
References: <mailman.3.1339063201.16753.r-sig-mixed-models@r-project.org>
Message-ID: <E0C02624-7173-483C-B25D-95E896702AA9@bristol.ac.uk>

Dear Teresa,

Would the "ordinal" package have what you're looking for?

http://cran.r-project.org/web/packages/ordinal/

Un saludo,
Malcolm



> Date: Thu, 07 Jun 2012 10:31:40 +0200
> From: "MORAN LOPEZ, TERESA" <tmoranlopez at mncn.csic.es>
> To: Chris Howden <chris at trickysolutions.com.au>
> Cc: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Running multinomial models with random effects
> Message-ID: <20120607103140.16232bmjomxwcx64 at webmail.csic.es>
> Content-Type: text/plain
> 
> Thanks a lot Chris,
> I will try that one and see what happens. However, if someone knows how to run multinomials with random effects I will be very greatful!
> 
> Quoting Chris Howden:
> 
>> I'm not neccsarily advocating this. But another way is to use 3
>> logistic models with random effects.   One for wether they choose big
>> acorn, one for small, one for both. Then compare the parameters of all
>> 3 to see if there are any differences.
>> 
>> Chris Howden
>> Founding Partner
>> Tricky Solutions
>> Tricky Solutions 4 Tricky Problems
>> Evidence Based Strategic Development, IP Commercialisation and
>> Innovation, Data Analysis, Modelling and Training
>> 
>> (mobile) 0410 689 945
>> (fax / office)
>> chris at trickysolutions.com.au
>> 
>> Disclaimer: The information in this email and any attachments to it are
>> confidential and may contain legally privileged information. If you are not
>> the named or intended recipient, please delete this communication and
>> contact us immediately. Please note you are not authorised to copy,
>> use or disclose this communication or any attachments without our
>> consent. Although this email has been checked by anti-virus software,
>> there is a risk that email messages may be corrupted or infected by
>> viruses or other
>> interferences. No responsibility is accepted for such interference. Unless
>> expressly stated, the views of the writer are not those of the
>> company. Tricky Solutions always does our best to provide accurate
>> forecasts and analyses based on the data supplied, however it is
>> possible that some important predictors were not included in the data
>> sent to us. Information provided by us should not be solely relied
>> upon when making decisions and clients should use their own judgement.
>> 
>> On 07/06/2012, at 3:00, "MORAN LOPEZ, TERESA" 
>> <tmoranlopez at mncn.csic.es> wrote:
>> 
>>> Dear all,
>>> I am a phD student working on animal behavior under different 
>>> predation risk. We have conducted an experiment in which acorn 
>>> selection by jays was evaluated in savanna vs forest-type  
>>> landscapes.  We placed 8 feeders in two different forests and 8 
>>> feeders in two different savannas.
>>> My response variable is factorial, acorn choice (big, small, both).  
>>> In my design I have spatial pseudorreplication within Areas.  I have 
>>> not found multinom function which allows fitting random effects. 
>>> However, MCMCglmm package allows incorporating them using Bayesian 
>>> Methods. I am new using Bayesian Methods so it has taken me a lot of 
>>> effort to partially understand these models implementation. However, 
>>> once I have run my model I am not sure about output interpretation 
>>> and most importantly how to convert fix effect parameters into 
>>> probabilities.
>>> 
>>> I have tried three different things: to convert my data in binomial 
>>> (ignoring  infrequent acorn choice ?both?) and run mixed model lmer. 
>>> Pros: I can include random effects , Cons: I lose an infrequent but 
>>> informative level of the response.
>>> 
>>> Keep categorical responses and run multinom function without random 
>>> effects.  Pros: I can fit my response variable as categorical and 
>>> keep all levels. Cons: I am ignoring spatial autocorrelation 
>>> (however, when running binomial models acorn choice variation 
>>> between areas was much more lower than between risk levels).
>>> +
>>> Run MCMCglmm model with random effects. Pros:  I can keep both 
>>> spatial autocorrelation and all levels of the response factor. Cons: 
>>> Not sure about  model implementation and interpretation. Low sample 
>>> size.
>>> 
>>> 
>>> Which option is the most accurate?
>>> 
>>> Thanks a lot! I am really stucked with my data.
>>> 
>>> Here I post my MCMCglmm model which is the one I have more doubts
>>> 
>>> #head(choice)-dataset with choice as factor  (b=big, s=small, bt=both)
>>>  RISK       Area             CHOICE
>>> LOW        Sopie                  b
>>> LOW       Sopie                  b
>>> LOW      Sopie                   b
>>> LOW  Anchurones                  s
>>> LOW  Anchurones                  bt
>>> LOW  Anchurones                  b
>>> 
>>> I have read package tutorial and Hadfield notes (though I have not 
>>> read all the chapter of Hadfield course notes). Besides I have used 
>>> information posted  Jaeger lab blog: 
>>> http://hlplab.wordpress.com/2009/05/07/multinomial-random-effects-models-in-r/
>>> 
>>> I am not very sure about random effects priors but I believe the 
>>> rest of them are ok.
>>> k <- length(levels(choice$CHOICE))
>>> I<- diag(k-1)
>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>> #Constraints to variance-covariance matrix
>>> 
>>> prior = list(R = list(fix=1, V =(1/k) * (I + J), n=k), G = list(G1 = 
>>> list(V =diag(2), n=2)))
>>> 
>>> #R priors, Hadfield manual suggests that structure. Are they right?  
>>> NOT SURE ABOUT RANDOM PRIORS.
>>> 
>>> M<- MCMCglmm(CHOICE~ -1+ trait + RISK,
>>>             random = ~ us(trait):Area,
>>>             rcov = ~ us(trait):units,
>>>             prior = prior,
>>>             family = "categorical",
>>>             data = choice)
>>> 
>>> #-1+trait following Hadfield suggestions in order to estimate 
>>> interception if every outcome.
>>> us(trait):-----  since we are not sure of independence assumptions. 
>>> Is model function allright?
>>> 
>>> My model runs but I find it very difficult to interpret my summary
>>> 
>>> summary(M)
>>> 
>>> Iterations = 3001:12991
>>> Thinning interval  = 10
>>> Sample size  = 1000
>>> 
>>> DIC: 44.21802
>>> 
>>> G-structure:  ~us(trait):Area
>>> 
>>>                        post.mean l-95% CI u-95% CI eff.samp
>>> CHOICE.bt:CHOICE.bt.Area    14.622   0.1881    64.46    7.278
>>> CHOICE.s:CHOICE.bt.Area      3.274 -11.1431    19.29  116.593
>>> CHOICE.bt:CHOICE.s.Area      3.274 -11.1431    19.29  116.593
>>> CHOICE.s:CHOICE.s.Area       5.071   0.1416    15.82  127.395
>>> 
>>> R-structure:  ~us(trait):units
>>> 
>>>                         post.mean l-95% CI u-95% CI eff.samp
>>> CHOICE.bt:CHOICE.bt.units    0.6667   0.6667   0.6667        0
>>> CHOICE.s:CHOICE.bt.units     0.3333   0.3333   0.3333        0
>>> CHOICE.bt:CHOICE.s.units     0.3333   0.3333   0.3333        0
>>> CHOICE.s:CHOICE.s.units      0.6667   0.6667   0.6667        0
>>> 
>>> Location effects: CHOICE ~ -1 + trait + RISK
>>> 
>>>              post.mean l-95% CI u-95% CI eff.samp pMCMC
>>> traitCHOICE.bt   -4.5042 -11.8926   0.3824    15.18 0.052 .
>>> traitCHOICE.s    -2.0187  -6.3370   1.3569    84.55 0.200
>>> RISKRA?A          1.9095  -2.3541   8.2421    56.13 0.336
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> posterior.mode(M$Sol)
>>> 
>>> traitCHOICE.bt   traitCHOICE.s       RISKRA?A
>>>    -2.594132      -1.836527             1.554387
>>> 
>>> #Since there is not any intercept I can?t apply plogis() in order to 
>>> get probabilities of choice in different areas.
>>> 
>>> 
>>> Sorry that I have that many  questions and thanks a lot!!!
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From florian.wickelmaier at uni-tuebingen.de  Thu Jun  7 11:23:31 2012
From: florian.wickelmaier at uni-tuebingen.de (florian.wickelmaier at uni-tuebingen.de)
Date: Thu, 7 Jun 2012 11:23:31 +0200 (CEST)
Subject: [R-sig-ME] Running multinomial models with random effects
Message-ID: <alpine.LNX.2.00.1206071116400.11325@linux29.zdv.uni-tuebingen.de>

Alternatively, you could fit a "tree-based" mixed logit model
based on continuation ratio logits. See a recent JSS paper by De
Boeck and Partchev (2012, http://www.jstatsoft.org/v48/c01/).

The idea is to convert the three-level response into a binary one
using a decision tree. In one possible tree, the first node is
indifferent w.r.t. size (response both) vs. picky (response small
or big). The second node is small given picky vs. big given
picky.

You need to extend your data by a two-level node variable. The
new response is then binary. The model can be fit using glmer().

Best, Florian

---
Florian Wickelmaier
Department of Psychology
University of Tuebingen
Schleichstr. 4, 72076 Tuebingen, Germany


From fbarbero at bariloche.inta.gov.ar  Thu Jun  7 15:03:38 2012
From: fbarbero at bariloche.inta.gov.ar (fernando barbero)
Date: Thu, 7 Jun 2012 10:03:38 -0300
Subject: [R-sig-ME] contrasts in lmer models
In-Reply-To: <13BC8E08D754714D9DEF568069DA770503D7DF3B@MBX11.d.ethz.ch>
References: <13BC8E08D754714D9DEF568069DA770503D7DF3B@MBX11.d.ethz.ch>
Message-ID: <002a01cd44ad$f4a557c0$ddf00740$@inta.gov.ar>

Why don t you test those contrasts using the LRT aproach? A full model
against a reduced one with all the effects except the one you are trying to
test. The book "Extending the linear model with R" (by Julian Faraway)
surely will help you
Best regards
Fernando

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Frei Esther
Enviado el: mi?rcoles, 06 de junio de 2012 03:40 p.m.
Para: mailman, r-sig-mixed-models
Asunto: [R-sig-ME] contrasts in lmer models

Dear R experts,

I am fitting a linear mixed model with lmer. Some of the a-priori-contrasts
I want to test involve interaction terms. I ran into serious trouble when I
tried to test these contrasts:

1. For testing interactions in the fixed factors, I tried using
fit.contrast() from the gmodels-package. In principle this works, but the
results I get are very suspicious. They vary quite a lot if I execute
fit.contrasts several times. I have increased the number of samples from the
default  1000 up to 200,000. However, the results don't seem to converge. It
seems also strange that sometimes p-values are exactly 0. Does it mean that
the contrasts are highly significant (i.e. smaller than the number of
decimals displayed in the result)? Or is there something wrong in the way I
use the function? Maybe I simply have to run more samples with my complex
model?

> require("gmodels")
> ffin <- lmer(y ~ CoV + Alt + Orig + Soil + (1 | Bed) + (1 | Site) + (1 |
Pair),  data = TETri,
+             na.action = na.exclude, REML=TRUE)
> cmat <- rbind("First Contrast (600m vs.1200m)"= c(1,0,-1),"Second Contrast
(1200m vs.1800m)"=
 +                         c(1,-1,0))

> fit.contrast(ffin,"Alt",cmat,conf.int=0.95,sim.mer=TRUE,n.sim=5000)
 
Estimate Std. Error   p value  Lower.CI    Upper.CI
AltFirst Contrast (600m vs.1200m)   -4.879821   0.979278 0.0000000 -6.317718
-3.86426640
AltSecond Contrast (1200m vs.1800m) -2.867170   1.796602 0.3333333 -4.593912
0.03296012


2. Some of the contrasts that I want to test involve interaction terms. As I
understand these cannot directly be approached with fix.contrasts(). Instead
I tried to recode the contrast terms into a new combined variable using
factorA.factorB = paste(factorA,factorB,sep="."). This only works when I
also refit the model with only the new combined factor as fixed effect but
results in suspicious p-values of '0'. As I understand, this is not the same
model anymore and so it is not very useful.

> TETri$O.A.Soil  <- as.factor(paste(TETri$Orig, TETri$Alt, TETri$Soil, sep=
levels(TETri$O.A.Soil) 
> cmat_1 <- rbind("HA Orig12 (O12.T12.SOL vs. O18.T18.GRA)"=
c(0,1,0,0,0,0,0,0,-1,0,0,0),"LF Orig12 +
(O12.T12.SOL vs. O18.T12.SOL)"= c(0,1,0,0,0,0,0,-1,0,0,0,0))
> f1c <- lmer(y ~ CoV + O.A.Soil + (1 | Bed) + (1 | Site) + (1 | Pair),
data = TETri,
+            na.action = na.exclude, REML=TRUE)
> fit.contrast(f1c,"O.A.Soil",cmat_1,conf.int=0.95,sim.mer=TRUE,n.sim=1000)
 
Estimate Std. Error p value   Lower.CI   Upper.CI
O.A.SoilHA Orig12 (O12.T12.SOL vs. O18.T18.GRA) -3.958218   2.110968       0
-6.6922765 -0.7359227
O.A.SoilLF Orig12 (O12.T12.SOL vs. O18.T12.SOL)  2.714403   1.387434       0
0.5868685  5.3193961


3. Using the function estimable() from gmodels, I have trouble specifying
the contrast matrix correctly. The help entry does not really give a good
example how to indicate the factor to which I want to refer to. Could anyone
give me a hint (example) how to define the contrasts correctly, please?
> f0 <- lmer(y ~ CoV + Alt * Orig * Soil + (1 | Bed) + (1 | Site) + (1 |
Pair),  data = TETri,
+             na.action = na.exclude, REML=TRUE)
> cmat <- rbind('Alt600m vs.Alt1200m'= c(1,0,-1),'Alt1200m vs.Alt1800m'=
c(1,-1,0))
> estimable(f0,cmat)
Error in FUN(newX[, i], ...) : 'param' has no names and does not match
number of coefficients of model. Unable to construct coefficient vector


4. My last question is a general question not specifically related to R: If
one of the fixed terms in my mixed model is not significant overall, is it
possible that one of the contrasts between levels of that term is still
significant?

Thanks a lot for your help!
Esther

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----
Se certific? que el correo no contiene virus.
Comprobada por AVG - www.avg.es
Versi?n: 2012.0.2177 / Base de datos de virus: 2433/5053 - Fecha de la
versi?n: 06/06/2012


From esther.frei at env.ethz.ch  Fri Jun  8 08:17:58 2012
From: esther.frei at env.ethz.ch (Frei  Esther)
Date: Fri, 8 Jun 2012 06:17:58 +0000
Subject: [R-sig-ME] contrasts in lmer models
In-Reply-To: <002a01cd44ad$f4a557c0$ddf00740$@inta.gov.ar>
References: <13BC8E08D754714D9DEF568069DA770503D7DF3B@MBX11.d.ethz.ch>
	<002a01cd44ad$f4a557c0$ddf00740$@inta.gov.ar>
Message-ID: <13BC8E08D754714D9DEF568069DA770503D7E589@MBX11.d.ethz.ch>

Hello Fernando

Thank you for your answer! I am not sure whether I understand correctly what you suggest. I have read the book of Faraway and have already calculated LRTs in order to test the significance of the fixed and random factors. Following that, now, I would like to test contrasts between the individual levels of the fixed factors (e.g. my factor Alt has three levels 600m, 1200m, and 1800m) and also because there are significant interactions in my model, I would like to estimate and test  various contrasts between different combinations of the factor levels. 

Best regards,
Esther


-----Original Message-----
From: fernando barbero [mailto:fbarbero at bariloche.inta.gov.ar] 
Sent: Donnerstag, 7. Juni 2012 15:04
To: Frei Esther; mailman, r-sig-mixed-models
Subject: RE: [R-sig-ME] contrasts in lmer models

Why don t you test those contrasts using the LRT aproach? A full model against a reduced one with all the effects except the one you are trying to test. The book "Extending the linear model with R" (by Julian Faraway) surely will help you Best regards Fernando

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Frei Esther Enviado el: mi?rcoles, 06 de junio de 2012 03:40 p.m.
Para: mailman, r-sig-mixed-models
Asunto: [R-sig-ME] contrasts in lmer models

Dear R experts,

I am fitting a linear mixed model with lmer. Some of the a-priori-contrasts I want to test involve interaction terms. I ran into serious trouble when I tried to test these contrasts:

1. For testing interactions in the fixed factors, I tried using
fit.contrast() from the gmodels-package. In principle this works, but the results I get are very suspicious. They vary quite a lot if I execute fit.contrasts several times. I have increased the number of samples from the default  1000 up to 200,000. However, the results don't seem to converge. It seems also strange that sometimes p-values are exactly 0. Does it mean that the contrasts are highly significant (i.e. smaller than the number of decimals displayed in the result)? Or is there something wrong in the way I use the function? Maybe I simply have to run more samples with my complex model?

> require("gmodels")
> ffin <- lmer(y ~ CoV + Alt + Orig + Soil + (1 | Bed) + (1 | Site) + (1 
> |
Pair),  data = TETri,
+             na.action = na.exclude, REML=TRUE)
> cmat <- rbind("First Contrast (600m vs.1200m)"= c(1,0,-1),"Second 
> Contrast
(1200m vs.1800m)"=
 +                         c(1,-1,0))

> fit.contrast(ffin,"Alt",cmat,conf.int=0.95,sim.mer=TRUE,n.sim=5000)
 
Estimate Std. Error   p value  Lower.CI    Upper.CI
AltFirst Contrast (600m vs.1200m)   -4.879821   0.979278 0.0000000 -6.317718
-3.86426640
AltSecond Contrast (1200m vs.1800m) -2.867170   1.796602 0.3333333 -4.593912
0.03296012


2. Some of the contrasts that I want to test involve interaction terms. As I understand these cannot directly be approached with fix.contrasts(). Instead I tried to recode the contrast terms into a new combined variable using factorA.factorB = paste(factorA,factorB,sep="."). This only works when I also refit the model with only the new combined factor as fixed effect but results in suspicious p-values of '0'. As I understand, this is not the same model anymore and so it is not very useful.

> TETri$O.A.Soil  <- as.factor(paste(TETri$Orig, TETri$Alt, TETri$Soil, 
> sep=
levels(TETri$O.A.Soil) 
> cmat_1 <- rbind("HA Orig12 (O12.T12.SOL vs. O18.T18.GRA)"=
c(0,1,0,0,0,0,0,0,-1,0,0,0),"LF Orig12 + (O12.T12.SOL vs. O18.T12.SOL)"= c(0,1,0,0,0,0,0,-1,0,0,0,0))
> f1c <- lmer(y ~ CoV + O.A.Soil + (1 | Bed) + (1 | Site) + (1 | Pair),
data = TETri,
+            na.action = na.exclude, REML=TRUE)
> fit.contrast(f1c,"O.A.Soil",cmat_1,conf.int=0.95,sim.mer=TRUE,n.sim=10
> 00)
 
Estimate Std. Error p value   Lower.CI   Upper.CI
O.A.SoilHA Orig12 (O12.T12.SOL vs. O18.T18.GRA) -3.958218   2.110968       0
-6.6922765 -0.7359227
O.A.SoilLF Orig12 (O12.T12.SOL vs. O18.T12.SOL)  2.714403   1.387434       0
0.5868685  5.3193961


3. Using the function estimable() from gmodels, I have trouble specifying the contrast matrix correctly. The help entry does not really give a good example how to indicate the factor to which I want to refer to. Could anyone give me a hint (example) how to define the contrasts correctly, please?
> f0 <- lmer(y ~ CoV + Alt * Orig * Soil + (1 | Bed) + (1 | Site) + (1 |
Pair),  data = TETri,
+             na.action = na.exclude, REML=TRUE)
> cmat <- rbind('Alt600m vs.Alt1200m'= c(1,0,-1),'Alt1200m vs.Alt1800m'=
c(1,-1,0))
> estimable(f0,cmat)
Error in FUN(newX[, i], ...) : 'param' has no names and does not match number of coefficients of model. Unable to construct coefficient vector


4. My last question is a general question not specifically related to R: If one of the fixed terms in my mixed model is not significant overall, is it possible that one of the contrasts between levels of that term is still significant?

Thanks a lot for your help!
Esther

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----
Se certific? que el correo no contiene virus.
Comprobada por AVG - www.avg.es
Versi?n: 2012.0.2177 / Base de datos de virus: 2433/5053 - Fecha de la
versi?n: 06/06/2012


From pdalgd at gmail.com  Fri Jun  8 12:52:08 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Jun 2012 12:52:08 +0200
Subject: [R-sig-ME] lme4, cloglog vs. binomial link (peter dalgaard)
In-Reply-To: <CAE85cPknAqUFxhbEnvHjoz-_UE6Svs6HJMpGgJ0GC3mcGFFTOg@mail.gmail.com>
References: <CAE85cPknAqUFxhbEnvHjoz-_UE6Svs6HJMpGgJ0GC3mcGFFTOg@mail.gmail.com>
Message-ID: <241BF84F-95FF-46A8-9068-67195E86B89F@gmail.com>

Hi Murray,

I think this is pretty strongly related to proportional hazards modelling. If you are looking at it from a Poisson (*) process point of view, the rate of event per unit of time when observing a number of independent processes should be proportional to time and the number  of processes, and the probability of at least one event in a fixed length of time T is then 1 - exp(- n T lambda) (or 1 - exp (-n Lambda(T)) if you have a time-varying intensity, Lambda being the integrated intensity).

-pd

(*) Could be fun if this was actually about fish...

On Jun 6, 2012, at 23:21 , Murray Jorgensen wrote:

> *Hi Peter, Tibor et al.
> 
> I came across an ecological situation recently where a cloglog link seemed
> to be called for. I won't remove the context to the following explanatory
> note that I wrote but I'm sure the same kind of situation could be
> reasonably common:
> 
> 
> We wish to explore the probability of one or more females departing a
> cavity between two site visits as a function of the habitation state of the
> cavity at the first visit. More strictly we study the probability of a
> decrease in the number of females inhabiting the cavity between the two
> visits. Clearly this probability will be zero if no females inhabit the
> cavity at the first visit. More generally the probability will be larger as
> the number of female inhabitants increase as each has the opportunity to
> depart.
> 
> Although this dependance on the initial number of females is part of what
> we want to study we are more interested in questions such as the influence
> of the initial number of males on the probability of female decrease. We
> are indeed also interested in the effect of the initial numbers of females
> on the probability of female decrease, but more in the sense that we would
> like to know whether this is greater than, less than or equal to what would
> be predicted by a simple model.
> 
> One naive model that could be considered is that the decrease probability
> would be proportional to the number of females. This might work if the
> decrease probability was very low but for larger decrease probabilities
> would predict decrease probabilities greater than one. A less naive model
> would assume that each female departs with the same probability,
> independently of the other females.
> Then if the probability of a single female departing is $p$ and there are
> $x$ females in the cavity the probability of 1 or more departing is $p_x =
> 1 - (1-p)^x$.
> 
> The link function for the complementary log-log link is $\eta =
> \log(-\log(1-p))$. To examine the effect of multiple initial females we
> evaluate this at $p_x$.
> 
>                 1-p_x  =  (1-p)^x
>           \log(1-p_x)  =  x\log(1-p)
>    \log(-\log(1-p_x))  =  \log(x)+\log(-\log(1-p))
> 
> Thus the effect of an initial habitation of $x$ females is a shift of
> $\log(x)$ on the linear predictor scale if a complementary log-log link is
> used in a GLM or GLMM for the probability of female decrease. This means
> that the naive model can be accommodated by including $\log(x)$ as an
> offset.  If $x$ were also included as a covariate, a significant
> coefficient would indicate a departure from the naive model.
> 
> Regards, Murray
> 
> *
> 
>> Message: 5
>> Date: Wed, 6 Jun 2012 22:54:16 +0200
>> From: peter dalgaard <pdalgd at gmail.com>
>> To: Tibor Kiss <tibor at linguistics.rub.de>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] lme4, cloglog vs. binomial link
>> Message-ID: <7658F572-AEE2-4127-AB77-321B5B6C3D69 at gmail.com>
>> Content-Type: text/plain; charset=us-ascii
>> 
>> 
>> On Jun 4, 2012, at 13:07 , Tibor Kiss wrote:
>> 
>>> [...snippage...]
>>> My questions are as follows:
>>> 
>>> 1. Is it correct to assume that given a cloglog link, the less frequent
>> response should be considered the success?
>> 
>> No, cloglog is asymmetric, so it will make a difference which outcome is
>> considered success, but there is no mathematical reason to choose between
>> them. In survival data, the cloglog comes out of the proportional hazards
>> model when you have death within a fixed time period as the response (exact
>> date of death not recorded). In that case, death is "success" (!);
>> hopefully, it is the least likely outcome, but it might not be. If cloglog
>> is just used as a generic link function, then no such logic applies.
>> 
>>> 2. Is it correct to conclude that the changes in the model have led to
>> less influence of the random factor?
>> 
>> No. The scales are different. At the very least, you need to somehow
>> compare it to the fixed effects on the same scale.
>> 
>>> 3. How shall I react to the increase in AIC?
>> 
>> (Or, equivalently, the deviance). The cloglog link model seems to give the
>> worse fit to data.
>> 
>>> A final question, which may not have an answer at all: I am most curious
>> to learn about possible modifications of the model so that an observed
>> random effect can be minimized (while its presence cannot be denied).
>> 
>> First, is that desirable, and why? The only logic, that I can think of, is
>> that you want to get the fixed-effect part of the model right, so that the
>> error is not mistakenly taken as part of the random variation.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> ------------------------------
>> 
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> End of R-sig-mixed-models Digest, Vol 66, Issue 10
>> **************************************************
>> 
> 
> 
> 
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From comtech.usa at gmail.com  Fri Jun  8 18:17:45 2012
From: comtech.usa at gmail.com (Michael)
Date: Fri, 8 Jun 2012 11:17:45 -0500
Subject: [R-sig-ME] LME: is the Gaussian distribution sensitive to outliers?
Message-ID: <CAPNjSFY0wMC083097+6mA8sELeUG1V+h1hL4ZHuL7nq0q0M04g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120608/168a677c/attachment.pl>

From maj at waikato.ac.nz  Mon Jun 11 05:26:16 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Mon, 11 Jun 2012 15:26:16 +1200
Subject: [R-sig-ME] lme4, cloglog vs. binomial link (peter dalgaard)
In-Reply-To: <241BF84F-95FF-46A8-9068-67195E86B89F@gmail.com>
References: <CAE85cPknAqUFxhbEnvHjoz-_UE6Svs6HJMpGgJ0GC3mcGFFTOg@mail.gmail.com>
	<241BF84F-95FF-46A8-9068-67195E86B89F@gmail.com>
Message-ID: <4FD56558.7050300@waikato.ac.nz>

Hi Peter and List,

I confess that I have difficulty in seeing the connection with Poisson 
processes. When we are fishing indefinitely we can assume an endless 
supply of fish capture events so a Poisson process seems reasonable. In 
my case of an insect leaving a habitation each 'process' will just be a 
single departure event at some future time which is not exactly observed.

Perhaps I'm thinking about this in the wrong way?

Murray

On 8/06/2012 10:52 p.m., peter dalgaard wrote:
> Hi Murray,
>
> I think this is pretty strongly related to proportional hazards modelling. If you are looking at it from a Poisson (*) process point of view, the rate of event per unit of time when observing a number of independent processes should be proportional to time and the number  of processes, and the probability of at least one event in a fixed length of time T is then 1 - exp(- n T lambda) (or 1 - exp (-n Lambda(T)) if you have a time-varying intensity, Lambda being the integrated intensity).
>
> -pd
>
> (*) Could be fun if this was actually about fish...
>
> On Jun 6, 2012, at 23:21 , Murray Jorgensen wrote:
>
>> *Hi Peter, Tibor et al.
>>
>> I came across an ecological situation recently where a cloglog link seemed
>> to be called for. I won't remove the context to the following explanatory
>> note that I wrote but I'm sure the same kind of situation could be
>> reasonably common:
>>
>>
>> We wish to explore the probability of one or more females departing a
>> cavity between two site visits as a function of the habitation state of the
>> cavity at the first visit. More strictly we study the probability of a
>> decrease in the number of females inhabiting the cavity between the two
>> visits. Clearly this probability will be zero if no females inhabit the
>> cavity at the first visit. More generally the probability will be larger as
>> the number of female inhabitants increase as each has the opportunity to
>> depart.
>>
>> Although this dependance on the initial number of females is part of what
>> we want to study we are more interested in questions such as the influence
>> of the initial number of males on the probability of female decrease. We
>> are indeed also interested in the effect of the initial numbers of females
>> on the probability of female decrease, but more in the sense that we would
>> like to know whether this is greater than, less than or equal to what would
>> be predicted by a simple model.
>>
>> One naive model that could be considered is that the decrease probability
>> would be proportional to the number of females. This might work if the
>> decrease probability was very low but for larger decrease probabilities
>> would predict decrease probabilities greater than one. A less naive model
>> would assume that each female departs with the same probability,
>> independently of the other females.
>> Then if the probability of a single female departing is $p$ and there are
>> $x$ females in the cavity the probability of 1 or more departing is $p_x =
>> 1 - (1-p)^x$.
>>
>> The link function for the complementary log-log link is $\eta =
>> \log(-\log(1-p))$. To examine the effect of multiple initial females we
>> evaluate this at $p_x$.
>>
>>                  1-p_x  =  (1-p)^x
>>            \log(1-p_x)  =  x\log(1-p)
>>     \log(-\log(1-p_x))  =  \log(x)+\log(-\log(1-p))
>>
>> Thus the effect of an initial habitation of $x$ females is a shift of
>> $\log(x)$ on the linear predictor scale if a complementary log-log link is
>> used in a GLM or GLMM for the probability of female decrease. This means
>> that the naive model can be accommodated by including $\log(x)$ as an
>> offset.  If $x$ were also included as a covariate, a significant
>> coefficient would indicate a departure from the naive model.
>>
>> Regards, Murray
>>
>> *
>>
>>> Message: 5
>>> Date: Wed, 6 Jun 2012 22:54:16 +0200
>>> From: peter dalgaard<pdalgd at gmail.com>
>>> To: Tibor Kiss<tibor at linguistics.rub.de>
>>> Cc: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] lme4, cloglog vs. binomial link
>>> Message-ID:<7658F572-AEE2-4127-AB77-321B5B6C3D69 at gmail.com>
>>> Content-Type: text/plain; charset=us-ascii
>>>
>>>
>>> On Jun 4, 2012, at 13:07 , Tibor Kiss wrote:
>>>
>>>> [...snippage...]
>>>> My questions are as follows:
>>>>
>>>> 1. Is it correct to assume that given a cloglog link, the less frequent
>>> response should be considered the success?
>>>
>>> No, cloglog is asymmetric, so it will make a difference which outcome is
>>> considered success, but there is no mathematical reason to choose between
>>> them. In survival data, the cloglog comes out of the proportional hazards
>>> model when you have death within a fixed time period as the response (exact
>>> date of death not recorded). In that case, death is "success" (!);
>>> hopefully, it is the least likely outcome, but it might not be. If cloglog
>>> is just used as a generic link function, then no such logic applies.
>>>
>>>> 2. Is it correct to conclude that the changes in the model have led to
>>> less influence of the random factor?
>>>
>>> No. The scales are different. At the very least, you need to somehow
>>> compare it to the fixed effects on the same scale.
>>>
>>>> 3. How shall I react to the increase in AIC?
>>>
>>> (Or, equivalently, the deviance). The cloglog link model seems to give the
>>> worse fit to data.
>>>
>>>> A final question, which may not have an answer at all: I am most curious
>>> to learn about possible modifications of the model so that an observed
>>> random effect can be minimized (while its presence cannot be denied).
>>>
>>> First, is that desirable, and why? The only logic, that I can think of, is
>>> that you want to get the fixed-effect part of the model right, so that the
>>> error is not mistakenly taken as part of the random variation.
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> _______________________________________________
>>> R-sig-mixed-models mailing list
>>> R-sig-mixed-models at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> End of R-sig-mixed-models Digest, Vol 66, Issue 10
>>> **************************************************
>>>
>>
>>
>>
>> --
>> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>> Department of Statistics, University of Waikato, Hamilton, New Zealand
>> Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
>> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz      majmurr at gmail.com         Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350


From pdalgd at gmail.com  Mon Jun 11 12:59:52 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 11 Jun 2012 12:59:52 +0200
Subject: [R-sig-ME] lme4, cloglog vs. binomial link (peter dalgaard)
In-Reply-To: <4FD56558.7050300@waikato.ac.nz>
References: <CAE85cPknAqUFxhbEnvHjoz-_UE6Svs6HJMpGgJ0GC3mcGFFTOg@mail.gmail.com>
	<241BF84F-95FF-46A8-9068-67195E86B89F@gmail.com>
	<4FD56558.7050300@waikato.ac.nz>
Message-ID: <5AC6F157-E939-4D2D-B4BE-80454B60A5B7@gmail.com>


On Jun 11, 2012, at 05:26 , Murray Jorgensen wrote:

> Hi Peter and List,
> 
> I confess that I have difficulty in seeing the connection with Poisson processes. When we are fishing indefinitely we can assume an endless supply of fish capture events so a Poisson process seems reasonable. In my case of an insect leaving a habitation each 'process' will just be a single departure event at some future time which is not exactly observed.
> 
> Perhaps I'm thinking about this in the wrong way?

(Perhaps a bit long-winded for the list, but now that we've started...)

To my mind, a (time-invariant) Poisson process is just a mechanism which generates events at "completely random" points in time, that is, the (infinitesimal) probability of an event in the next instant is the same, which turns out to equivalent to saying that the time till next event has an exponential distribution. 

A survival process for a single item can be viewed as a Poisson process stopped at the first event. If you have n independent Poisson processes, the intensity of events is just the sum of the intensities. That is really all you need for your case of observing the first "death" out of n. (In classical survival analysis, the process would continue after the first death, but the intensity would be reduced to reflect the new population size.)

Notice that the number of events is not necessarily Poisson distributed if the process is stopped at a time that depends on the process itself (i.e., people usually only die once, not a Poisson-distributed number of times). However, a stopped Poisson process has the same probability for events that only depend on the behavior of the process until it is stopped. E.g., the probability of one or more events in a certain amount of time is the same in a process stopped at the first event as it is in the original process (in terms of electrical fuses, you could "unstop" the process by replacing the fuse).

-pd


> 
> Murray
> 
> On 8/06/2012 10:52 p.m., peter dalgaard wrote:
>> Hi Murray,
>> 
>> I think this is pretty strongly related to proportional hazards modelling. If you are looking at it from a Poisson (*) process point of view, the rate of event per unit of time when observing a number of independent processes should be proportional to time and the number  of processes, and the probability of at least one event in a fixed length of time T is then 1 - exp(- n T lambda) (or 1 - exp (-n Lambda(T)) if you have a time-varying intensity, Lambda being the integrated intensity).
>> 
>> -pd
>> 
>> (*) Could be fun if this was actually about fish...
>> 
>> On Jun 6, 2012, at 23:21 , Murray Jorgensen wrote:
>> 
>>> *Hi Peter, Tibor et al.
>>> 
>>> I came across an ecological situation recently where a cloglog link seemed
>>> to be called for. I won't remove the context to the following explanatory
>>> note that I wrote but I'm sure the same kind of situation could be
>>> reasonably common:
>>> 
>>> 
>>> We wish to explore the probability of one or more females departing a
>>> cavity between two site visits as a function of the habitation state of the
>>> cavity at the first visit. More strictly we study the probability of a
>>> decrease in the number of females inhabiting the cavity between the two
>>> visits. Clearly this probability will be zero if no females inhabit the
>>> cavity at the first visit. More generally the probability will be larger as
>>> the number of female inhabitants increase as each has the opportunity to
>>> depart.
>>> 
>>> Although this dependance on the initial number of females is part of what
>>> we want to study we are more interested in questions such as the influence
>>> of the initial number of males on the probability of female decrease. We
>>> are indeed also interested in the effect of the initial numbers of females
>>> on the probability of female decrease, but more in the sense that we would
>>> like to know whether this is greater than, less than or equal to what would
>>> be predicted by a simple model.
>>> 
>>> One naive model that could be considered is that the decrease probability
>>> would be proportional to the number of females. This might work if the
>>> decrease probability was very low but for larger decrease probabilities
>>> would predict decrease probabilities greater than one. A less naive model
>>> would assume that each female departs with the same probability,
>>> independently of the other females.
>>> Then if the probability of a single female departing is $p$ and there are
>>> $x$ females in the cavity the probability of 1 or more departing is $p_x =
>>> 1 - (1-p)^x$.
>>> 
>>> The link function for the complementary log-log link is $\eta =
>>> \log(-\log(1-p))$. To examine the effect of multiple initial females we
>>> evaluate this at $p_x$.
>>> 
>>>                 1-p_x  =  (1-p)^x
>>>           \log(1-p_x)  =  x\log(1-p)
>>>    \log(-\log(1-p_x))  =  \log(x)+\log(-\log(1-p))
>>> 
>>> Thus the effect of an initial habitation of $x$ females is a shift of
>>> $\log(x)$ on the linear predictor scale if a complementary log-log link is
>>> used in a GLM or GLMM for the probability of female decrease. This means
>>> that the naive model can be accommodated by including $\log(x)$ as an
>>> offset.  If $x$ were also included as a covariate, a significant
>>> coefficient would indicate a departure from the naive model.
>>> 
>>> Regards, Murray
>>> 
>>> *
>>> 
>>>> Message: 5
>>>> Date: Wed, 6 Jun 2012 22:54:16 +0200
>>>> From: peter dalgaard<pdalgd at gmail.com>
>>>> To: Tibor Kiss<tibor at linguistics.rub.de>
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] lme4, cloglog vs. binomial link
>>>> Message-ID:<7658F572-AEE2-4127-AB77-321B5B6C3D69 at gmail.com>
>>>> Content-Type: text/plain; charset=us-ascii
>>>> 
>>>> 
>>>> On Jun 4, 2012, at 13:07 , Tibor Kiss wrote:
>>>> 
>>>>> [...snippage...]
>>>>> My questions are as follows:
>>>>> 
>>>>> 1. Is it correct to assume that given a cloglog link, the less frequent
>>>> response should be considered the success?
>>>> 
>>>> No, cloglog is asymmetric, so it will make a difference which outcome is
>>>> considered success, but there is no mathematical reason to choose between
>>>> them. In survival data, the cloglog comes out of the proportional hazards
>>>> model when you have death within a fixed time period as the response (exact
>>>> date of death not recorded). In that case, death is "success" (!);
>>>> hopefully, it is the least likely outcome, but it might not be. If cloglog
>>>> is just used as a generic link function, then no such logic applies.
>>>> 
>>>>> 2. Is it correct to conclude that the changes in the model have led to
>>>> less influence of the random factor?
>>>> 
>>>> No. The scales are different. At the very least, you need to somehow
>>>> compare it to the fixed effects on the same scale.
>>>> 
>>>>> 3. How shall I react to the increase in AIC?
>>>> 
>>>> (Or, equivalently, the deviance). The cloglog link model seems to give the
>>>> worse fit to data.
>>>> 
>>>>> A final question, which may not have an answer at all: I am most curious
>>>> to learn about possible modifications of the model so that an observed
>>>> random effect can be minimized (while its presence cannot be denied).
>>>> 
>>>> First, is that desirable, and why? The only logic, that I can think of, is
>>>> that you want to get the fixed-effect part of the model right, so that the
>>>> error is not mistakenly taken as part of the random variation.
>>>> 
>>>> --
>>>> Peter Dalgaard, Professor,
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>> 
>>>> 
>>>> 
>>>> ------------------------------
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models mailing list
>>>> R-sig-mixed-models at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>>> 
>>>> End of R-sig-mixed-models Digest, Vol 66, Issue 10
>>>> **************************************************
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>>> Department of Statistics, University of Waikato, Hamilton, New Zealand
>>> Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
>>> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz      majmurr at gmail.com         Fax 7 838 4155
> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maj at waikato.ac.nz  Mon Jun 11 23:15:24 2012
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Tue, 12 Jun 2012 09:15:24 +1200
Subject: [R-sig-ME] lme4, cloglog vs. binomial link (peter dalgaard)
In-Reply-To: <5AC6F157-E939-4D2D-B4BE-80454B60A5B7@gmail.com>
References: <CAE85cPknAqUFxhbEnvHjoz-_UE6Svs6HJMpGgJ0GC3mcGFFTOg@mail.gmail.com>
	<241BF84F-95FF-46A8-9068-67195E86B89F@gmail.com>
	<4FD56558.7050300@waikato.ac.nz>
	<5AC6F157-E939-4D2D-B4BE-80454B60A5B7@gmail.com>
Message-ID: <4FD65FEC.1080307@waikato.ac.nz>

Thanks, Peter that's helpful. Apologies to others if my bend in the 
thread to it too far from the purpose of the group.

Murray

On 11/06/12 10:59 PM, peter dalgaard wrote:
>
> On Jun 11, 2012, at 05:26 , Murray Jorgensen wrote:
>
>> Hi Peter and List,
>>
>> I confess that I have difficulty in seeing the connection with Poisson processes. When we are fishing indefinitely we can assume an endless supply of fish capture events so a Poisson process seems reasonable. In my case of an insect leaving a habitation each 'process' will just be a single departure event at some future time which is not exactly observed.
>>
>> Perhaps I'm thinking about this in the wrong way?
>
> (Perhaps a bit long-winded for the list, but now that we've started...)
>
> To my mind, a (time-invariant) Poisson process is just a mechanism which generates events at "completely random" points in time, that is, the (infinitesimal) probability of an event in the next instant is the same, which turns out to equivalent to saying that the time till next event has an exponential distribution.
>
> A survival process for a single item can be viewed as a Poisson process stopped at the first event. If you have n independent Poisson processes, the intensity of events is just the sum of the intensities. That is really all you need for your case of observing the first "death" out of n. (In classical survival analysis, the process would continue after the first death, but the intensity would be reduced to reflect the new population size.)
>
> Notice that the number of events is not necessarily Poisson distributed if the process is stopped at a time that depends on the process itself (i.e., people usually only die once, not a Poisson-distributed number of times). However, a stopped Poisson process has the same probability for events that only depend on the behavior of the process until it is stopped. E.g., the probability of one or more events in a certain amount of time is the same in a process stopped at the first event as it is in the original process (in terms of electrical fuses, you could "unstop" the process by replacing the fuse).
>
> -pd
>
>
>>
>> Murray
>>
>> On 8/06/2012 10:52 p.m., peter dalgaard wrote:
>>> Hi Murray,
>>>
>>> I think this is pretty strongly related to proportional hazards modelling. If you are looking at it from a Poisson (*) process point of view, the rate of event per unit of time when observing a number of independent processes should be proportional to time and the number  of processes, and the probability of at least one event in a fixed length of time T is then 1 - exp(- n T lambda) (or 1 - exp (-n Lambda(T)) if you have a time-varying intensity, Lambda being the integrated intensity).
>>>
>>> -pd
>>>
>>> (*) Could be fun if this was actually about fish...
>>>
>>> On Jun 6, 2012, at 23:21 , Murray Jorgensen wrote:
>>>
>>>> *Hi Peter, Tibor et al.
>>>>
>>>> I came across an ecological situation recently where a cloglog link seemed
>>>> to be called for. I won't remove the context to the following explanatory
>>>> note that I wrote but I'm sure the same kind of situation could be
>>>> reasonably common:
>>>>
>>>>
>>>> We wish to explore the probability of one or more females departing a
>>>> cavity between two site visits as a function of the habitation state of the
>>>> cavity at the first visit. More strictly we study the probability of a
>>>> decrease in the number of females inhabiting the cavity between the two
>>>> visits. Clearly this probability will be zero if no females inhabit the
>>>> cavity at the first visit. More generally the probability will be larger as
>>>> the number of female inhabitants increase as each has the opportunity to
>>>> depart.
>>>>
>>>> Although this dependance on the initial number of females is part of what
>>>> we want to study we are more interested in questions such as the influence
>>>> of the initial number of males on the probability of female decrease. We
>>>> are indeed also interested in the effect of the initial numbers of females
>>>> on the probability of female decrease, but more in the sense that we would
>>>> like to know whether this is greater than, less than or equal to what would
>>>> be predicted by a simple model.
>>>>
>>>> One naive model that could be considered is that the decrease probability
>>>> would be proportional to the number of females. This might work if the
>>>> decrease probability was very low but for larger decrease probabilities
>>>> would predict decrease probabilities greater than one. A less naive model
>>>> would assume that each female departs with the same probability,
>>>> independently of the other females.
>>>> Then if the probability of a single female departing is $p$ and there are
>>>> $x$ females in the cavity the probability of 1 or more departing is $p_x =
>>>> 1 - (1-p)^x$.
>>>>
>>>> The link function for the complementary log-log link is $\eta =
>>>> \log(-\log(1-p))$. To examine the effect of multiple initial females we
>>>> evaluate this at $p_x$.
>>>>
>>>>                  1-p_x  =  (1-p)^x
>>>>            \log(1-p_x)  =  x\log(1-p)
>>>>     \log(-\log(1-p_x))  =  \log(x)+\log(-\log(1-p))
>>>>
>>>> Thus the effect of an initial habitation of $x$ females is a shift of
>>>> $\log(x)$ on the linear predictor scale if a complementary log-log link is
>>>> used in a GLM or GLMM for the probability of female decrease. This means
>>>> that the naive model can be accommodated by including $\log(x)$ as an
>>>> offset.  If $x$ were also included as a covariate, a significant
>>>> coefficient would indicate a departure from the naive model.
>>>>
>>>> Regards, Murray
>>>>
>>>> *
>>>>
>>>>> Message: 5
>>>>> Date: Wed, 6 Jun 2012 22:54:16 +0200
>>>>> From: peter dalgaard<pdalgd at gmail.com>
>>>>> To: Tibor Kiss<tibor at linguistics.rub.de>
>>>>> Cc: r-sig-mixed-models at r-project.org
>>>>> Subject: Re: [R-sig-ME] lme4, cloglog vs. binomial link
>>>>> Message-ID:<7658F572-AEE2-4127-AB77-321B5B6C3D69 at gmail.com>
>>>>> Content-Type: text/plain; charset=us-ascii
>>>>>
>>>>>
>>>>> On Jun 4, 2012, at 13:07 , Tibor Kiss wrote:
>>>>>
>>>>>> [...snippage...]
>>>>>> My questions are as follows:
>>>>>>
>>>>>> 1. Is it correct to assume that given a cloglog link, the less frequent
>>>>> response should be considered the success?
>>>>>
>>>>> No, cloglog is asymmetric, so it will make a difference which outcome is
>>>>> considered success, but there is no mathematical reason to choose between
>>>>> them. In survival data, the cloglog comes out of the proportional hazards
>>>>> model when you have death within a fixed time period as the response (exact
>>>>> date of death not recorded). In that case, death is "success" (!);
>>>>> hopefully, it is the least likely outcome, but it might not be. If cloglog
>>>>> is just used as a generic link function, then no such logic applies.
>>>>>
>>>>>> 2. Is it correct to conclude that the changes in the model have led to
>>>>> less influence of the random factor?
>>>>>
>>>>> No. The scales are different. At the very least, you need to somehow
>>>>> compare it to the fixed effects on the same scale.
>>>>>
>>>>>> 3. How shall I react to the increase in AIC?
>>>>>
>>>>> (Or, equivalently, the deviance). The cloglog link model seems to give the
>>>>> worse fit to data.
>>>>>
>>>>>> A final question, which may not have an answer at all: I am most curious
>>>>> to learn about possible modifications of the model so that an observed
>>>>> random effect can be minimized (while its presence cannot be denied).
>>>>>
>>>>> First, is that desirable, and why? The only logic, that I can think of, is
>>>>> that you want to get the fixed-effect part of the model right, so that the
>>>>> error is not mistakenly taken as part of the random variation.
>>>>>
>>>>> --
>>>>> Peter Dalgaard, Professor,
>>>>> Center for Statistics, Copenhagen Business School
>>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>>> Phone: (+45)38153501
>>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>>>
>>>>>
>>>>>
>>>>> ------------------------------
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models mailing list
>>>>> R-sig-mixed-models at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>> End of R-sig-mixed-models Digest, Vol 66, Issue 10
>>>>> **************************************************
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>>>> Department of Statistics, University of Waikato, Hamilton, New Zealand
>>>> Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
>>>> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> --
>> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>> Department of Statistics, University of Waikato, Hamilton, New Zealand
>> Email: maj at waikato.ac.nz      majmurr at gmail.com         Fax 7 838 4155
>> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350
>

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz      majmurr at gmail.com         Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350


From tommasojucker at gmail.com  Tue Jun 12 10:46:40 2012
From: tommasojucker at gmail.com (Tommaso Jucker)
Date: Tue, 12 Jun 2012 09:46:40 +0100
Subject: [R-sig-ME] Mixed-effects model with varying slope and intercept
	(multiple regression)
Message-ID: <CAA+TPwt5ZFMvNah477LgFKXASJy91kGLX=o746ODwPE0wOQe4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120612/e4054eab/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Jun 12 12:16:51 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 12 Jun 2012 10:16:51 +0000
Subject: [R-sig-ME] Mixed-effects model with varying slope and
	intercept	(multiple regression)
In-Reply-To: <CAA+TPwt5ZFMvNah477LgFKXASJy91kGLX=o746ODwPE0wOQe4w@mail.gmail.com>
References: <CAA+TPwt5ZFMvNah477LgFKXASJy91kGLX=o746ODwPE0wOQe4w@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275D669FFE@inbomail.inbo.be>

Dear Tommaso,

I would not use random effect for habitat since you have only 3 levels. Either use it as a fixed effect (with or without interactions) or ignore it. It is up to you to decide what option is the most relevant. If you drop the random effects then you have a simple glm() instead of glmer().

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Tommaso Jucker
Verzonden: dinsdag 12 juni 2012 10:47
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Mixed-effects model with varying slope and intercept (multiple regression)

Dear List,

I am testing how the species richness (SR) of a plant community is affected by the presence of an invasive species (Alien). To control for confounding environmental factors my model also contains two covariates
(CV1 and CV2, both continuous). As I have sampled plant communities in 3 different habitats, I would like to fit a mixed-effects model which allows for different effects of the invasive on species richness depending on the habitat in question (in other words separate slopes and intercepts for each of the 3 habitats). Currently my model looks like this:

model <- SR ~ Alien + CV1 + CV2 + (1 + Alien | Habitat)

However, I think this is not correct as the effects of the two covariates are not included in the random effect (slope and intercept vary among habitats, but only account for the effect of the invasive species). How can I formally include the effects of the two covariates in the random effect terms and is this necessary?

Any suggestions are much appreciated.

Best wishes,

Tommaso
__________________________________________________________________________

*Tommaso Jucker*

*    Ph.D. student*
*    Forest Ecology and Conservation Group*
*    Department of Plant Sciences*
*    University of Cambridge*

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From hans at sociologi.cjb.net  Tue Jun 12 16:21:38 2012
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Tue, 12 Jun 2012 16:21:38 +0200
Subject: [R-sig-ME] mcmcglmm and parallel chains
Message-ID: <20120612142138.GA15825@ingegerdsdator>

I am learning mcmcglmm in order to use it on a beowulf cluster.

In https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006558.html

Jarrod Hadfield writes:

"You can merge MCMC chains from multiple runs, although you should make
sure you start them from different initial values"

Is it sufficient to provide differents random seeds for each run,
or does this refer to the start parameter of mcmcglmm()?

   start: optional list having 4 possible elements: ?R? (R-structure)
          ?G? (G-structure) and ?liab? (latent variables or
          liabilities) should contain the starting values where ?G?
          itself is also a list with as many elements as random effect
          components. The fourth element ?QUASI? should be logical: if
          ?TRUE? starting latent variables are obtained heuristically,
          if ?FALSE? then they are sampled from a Z-distribution

-- 
Hans Ekbrand (http://sociologi.cjb.net) <hans at sociologi.cjb.net>


From kharouba at zoology.ubc.ca  Tue Jun 12 17:34:47 2012
From: kharouba at zoology.ubc.ca (Heather Kharouba)
Date: Tue, 12 Jun 2012 08:34:47 -0700
Subject: [R-sig-ME] Error with glmmADMB and beta distribution
Message-ID: <f6dce96b596dd15e0c2eef92db7d461f.squirrel@webmail.zoology.ubc.ca>

Hello,

I am new to glmmADMB and would like to use the beta distribution with
glmmadmb. However, I keep running into the same error. The response
variable is AUC (area under the curve data) from species distribution
models which is continuous and ranges from 0 to 1. The fixed variables are
the number of variables used to build the model (continuous), spatial
extent of the distribution model (continuous), model type (factor) and
taxonomic group (categorical) and the random effect is study.

Here's the model:

model1<-glmmadmb(AUC~variables+log_area+model+taxa+(1|study),
family="beta", verbose=TRUE, data=auc);

A snapshot of the data:

study                  taxa       AUC      model variables log_area
 Araujo et al. 2005 BIRD 0.9156878   GAM         7 16.21771
Araujo et al. 2005 BIRD 0.9288596   GAM         7 16.21771
Araujo et al. 2005 BIRD 0.9254065   GAM         7 16.21771
Araujo et al. 2005 BIRD 0.8825593   GAM         7 16.21771
Araujo et al. 2005 BIRD 0.9388894   GAM         7 16.21771
Araujo et al. 2005 BIRD 0.9061483   GAM         7 16.21771

When I run the model I get this error:
Error in glmmadmb(AUC ~ variables + log_area + model + taxa + (1 | study),
 :
  The function maximizer failed (couldn't find STD file)


This is the printout from verbose=TRUE:
 - final statistics:
24 variables; iteration 0; function evaluation 0
Function value          inf; maximum gradient component mag   0.0000e+00
Exit code = 0;  converg criter   1.0000e-04
Var   Value    Gradient   |Var   Value    Gradient   |Var   Value    Gradient
  1  0.00000          nan |  2  0.00000          nan |  3  0.00000
 nan
  4  0.00000          nan |  5  0.00000          nan |  6  0.00000
 nan
  7  0.00000          nan |  8  0.00000          nan |  9  0.00000
 nan
 10  0.00000          nan | 11  0.00000          nan | 12  0.00000
nan
 13  0.00000          nan | 14  0.00000          nan | 15  0.00000
nan
 16  0.00000          nan | 17  0.00000          nan | 18  0.00000
nan
 19  0.00000          nan | 20  0.00000          nan | 21  0.00000
nan
 22  0.00000          nan | 23  0.00000          nan | 24  0.00000
nan

 - final statistics:
25 variables; iteration 0; function evaluation 0
Function value          inf; maximum gradient component mag   0.0000e+00
Exit code = 0;  converg criter   1.0000e-04
Var   Value    Gradient   |Var   Value    Gradient   |Var   Value    Gradient
  1  0.00000          nan |  2  0.00000          nan |  3  0.00000
 nan
  4  0.00000          nan |  5  0.00000          nan |  6  0.00000
 nan
  7  0.00000          nan |  8  0.00000          nan |  9  0.00000
 nan
 10  0.00000          nan | 11  0.00000          nan | 12  0.00000
nan
 13  0.00000          nan | 14  0.00000          nan | 15  0.00000
nan
 16  0.00000          nan | 17  0.00000          nan | 18  0.00000
nan
 19  0.00000          nan | 20  0.00000          nan | 21  0.00000
nan
 22  0.00000          nan | 23  0.00000          nan | 24  0.00000
nan
 25  0.05795          nan |
Hessian type 4

I'm using glmm ADMB version 0.7.2.2 with R version 2.14.2 on a Mac OS X
Version 10.6.8. I've tried including
admb.opts=admbControl(shess=FALSE,noinit=FALSE) and still get the same
error. I'm guessing there's something wrong with either the response
variable or with the overall data structure?

Thanks,
Heather Kharouba


From torvon at gmail.com  Wed Jun 13 03:31:40 2012
From: torvon at gmail.com (Eiko Fried)
Date: Tue, 12 Jun 2012 21:31:40 -0400
Subject: [R-sig-ME] Random-Intercept Random-Slope Models
Message-ID: <CACm_P7rggGKqEj_k4nSyeRZufgVSA+L5WfSAiwf0jvDgf4rCvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120612/5284068c/attachment.pl>

From jwiley.psych at gmail.com  Wed Jun 13 05:07:11 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 12 Jun 2012 20:07:11 -0700
Subject: [R-sig-ME] Random-Intercept Random-Slope Models
In-Reply-To: <CACm_P7rggGKqEj_k4nSyeRZufgVSA+L5WfSAiwf0jvDgf4rCvA@mail.gmail.com>
References: <CACm_P7rggGKqEj_k4nSyeRZufgVSA+L5WfSAiwf0jvDgf4rCvA@mail.gmail.com>
Message-ID: <668B03A5-1C2D-40A0-853E-E1C0FDE7EC0A@gmail.com>

Hi Eiko,

+ x1 just adds a main effect of x1 on the outcome.  That is how Rs formula interface works regardless of simple linear regression as with lm() or mixed models (including longitudinal of course).  "is really not something you want to do" depends entirely on what you want to do.  It is entirely sensible if you are trying to model baseline differences.  If what you really want to do is try to model differences in the time slope, then of course it is not something you want to do.  If that is what you want, include the interaction with time as:

time * (x1 + x2 + x3)

note that the * is important for that to work.

Cheers,

Josh

On Jun 12, 2012, at 18:31, Eiko Fried <torvon at gmail.com> wrote:

> Dear Mixed Models Mailing List.
> 
> Do I understand correctly that, for longitudinal data, the following syntax
> is really not something you want to do:
> 
> Y ~ time + x1 + x2 +x3 + ( time | subject )
> 
> because significant effects on the covariates would simply refer to the
> intercept of the first measurement point?
> 
> Instead, the model would have to look like this:
> 
> Y ~time (x1 + x2 +x3 ) + ( time | subject)
> 
> to have the covariates also predict differences in slope. Is that correct?
> 
> If this is the case, I don't quite understand most of the R tutorials for
> mixed models out there, because they nearly all use the first notation.
> 
> Thanks for clarifying, I'm a but confused.
> 
> ~~Eiko
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Jun 13 10:06:43 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Jun 2012 08:06:43 +0000 (UTC)
Subject: [R-sig-ME] Error with glmmADMB and beta distribution
References: <f6dce96b596dd15e0c2eef92db7d461f.squirrel@webmail.zoology.ubc.ca>
Message-ID: <loom.20120613T095212-344@post.gmane.org>

Heather Kharouba <kharouba at ...> writes:

> I am new to glmmADMB and would like to use the beta distribution with
> glmmadmb. However, I keep running into the same error. The response
> variable is AUC (area under the curve data) from species distribution
> models which is continuous and ranges from 0 to 1. The fixed variables are
> the number of variables used to build the model (continuous), spatial
> extent of the distribution model (continuous), model type (factor) and
> taxonomic group (categorical) and the random effect is study.
> 
> Here's the model:
> 
> model1<-glmmadmb(AUC~variables+log_area+model+taxa+(1|study),
> family="beta", verbose=TRUE, data=auc);
> 
> A snapshot of the data:
> 
> study                  taxa       AUC      model variables log_area
>  Araujo et al. 2005 BIRD 0.9156878   GAM         7 16.21771
> Araujo et al. 2005 BIRD 0.9288596   GAM         7 16.21771
> Araujo et al. 2005 BIRD 0.9254065   GAM         7 16.21771
> Araujo et al. 2005 BIRD 0.8825593   GAM         7 16.21771
> Araujo et al. 2005 BIRD 0.9388894   GAM         7 16.21771
> Araujo et al. 2005 BIRD 0.9061483   GAM         7 16.21771
> 
> When I run the model I get this error:
> Error in glmmadmb(AUC ~ variables + log_area + model + taxa + (1 | study),
>  :
>   The function maximizer failed (couldn't find STD file)
> 

  [snip]
> 
> I'm using glmm ADMB version 0.7.2.2 with R version 2.14.2 on a Mac OS X
> Version 10.6.8. I've tried including
> admb.opts=admbControl(shess=FALSE,noinit=FALSE) and still get the same
> error. I'm guessing there's something wrong with either the response
> variable or with the overall data structure?

  My first guess would be that you have AUC values that are 
exactly equal to 0 or 1; they will give infinite/NaN log-likelihoods
in the beta model. Beyond that, I'm not sure.  It would be useful
to know a little bit more about your data -- how many total observations?
How many studies?

Does fitting the model without the random effect work, i.e.

model2 <- glmmadmb(AUC~variables+log_area+model+taxa,
  family="beta", verbose=TRUE, data=auc)

?


From bbolker at gmail.com  Wed Jun 13 10:16:28 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Jun 2012 08:16:28 +0000 (UTC)
Subject: [R-sig-ME] mcmcglmm and parallel chains
References: <20120612142138.GA15825@ingegerdsdator>
Message-ID: <loom.20120613T100728-628@post.gmane.org>

Hans Ekbrand <hans at ...> writes:

> 
> I am learning mcmcglmm in order to use it on a beowulf cluster.
> 
> In https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006558.html
> 
> Jarrod Hadfield writes:
> 
> "You can merge MCMC chains from multiple runs, although you should make
> sure you start them from different initial values"
> 
> Is it sufficient to provide differents random seeds for each run,
> or does this refer to the start parameter of mcmcglmm()?
> 
>    start: optional list having 4 possible elements: ?R? (R-structure)
>           ?G? (G-structure) and ?liab? (latent variables or
>           liabilities) should contain the starting values where ?G?
>           itself is also a list with as many elements as random effect
>           components. The fourth element ?QUASI? should be logical: if
>           ?TRUE? starting latent variables are obtained heuristically,
>           if ?FALSE? then they are sampled from a Z-distribution
> 

  It depends a bit on what your computational issues are.  It would
probably be _better_ to use multiple starting points, but if you are
sure you have no problem with burn-in then you can start all the chains
at the same points and rely on the different random-number seeds to allow
the chains to explore parameter space independently.  (Using multiple
starting points would would also allow you to use the Gelman-Rubin
diagnostic to assess convergence.)
   I would do some experiments with MCMCglmm to ensure that you know
how random seeds work with it (i.e. that you get identical answers
if and only if random seeds are set the same).  You may also want/need
to look at some of the comments in the high performance task view about
random number streams for parallel computation.

  
to look into


From pier.morel at gmail.com  Wed Jun 13 10:27:21 2012
From: pier.morel at gmail.com (Pierre Morel)
Date: Wed, 13 Jun 2012 10:27:21 +0200
Subject: [R-sig-ME] Avoid errors in pwrssUpdate ?
Message-ID: <00BA0FA0-9C6A-4366-A60B-7394E1D20A52@gmail.com>

Dear List,

I am getting a lot of pwrssUpdate errors when trying to model my data with gmler (using the most recent version from svn... I don't know if the previous versions were affected).

These errors are "PIRLS step failed" or "pwrssUpdate did not converge in 30 iterations". I understand that these means that the algorithm does not manage to work with my data, but there is a peculiar behavior, and my data doesn't seem too unreasonable to fit with the model I want to use, so I am wondering if the problem is on my side !

Here is a link toward a plot of part of my data as I want to model it (using ggplot2) : https://dl.dropbox.com/u/1205127/Images/glmer_plot.pdf
Each panel is for a subject of a behavioral experiment, and what is represented is the probability of the subject following a rule as a function of the weight given to this rule in the instructions (RuleWeight, between 0 and 1 here). Each point corresponds to a probability computed over 6 trials (points are jittered to see better).

Here is the model I want to fit, which doesn't seem unreasonable given the figure (random slopes and intercepts for subjects) :

model<-glmer(cbind(RuleReach,NTrials-RuleReach)~RuleWeight+(RuleWeight|Subject),data=rewardalldirsub,family=binomial)

However this gives me the "pwrssUpdate did not converge in 30 iterations" error. 
What is surprinsing, is that if I do not use the rightmost points (RuleWeight of 1), the model converges, even though there are less datapoints and the remaining points are the noisiest (subjects follow the rule quite reliably when it has a weight of 1 as you can see).

Removing the correlation in the random effects works sometimes (but not on all my sub data sets), and having a random intercept only (which is obviously not correct) is the only thing that seems to work in all cases.

Centering RuleWeight (ie having it between -1 and 1 instead of 0 and 1) doesn't work.

Any ideas on why this doesn't work / how to make it work ?

Thanks

Pierre Morel

From bbolker at gmail.com  Wed Jun 13 10:54:45 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Jun 2012 08:54:45 +0000 (UTC)
Subject: [R-sig-ME] Avoid errors in pwrssUpdate ?
References: <00BA0FA0-9C6A-4366-A60B-7394E1D20A52@gmail.com>
Message-ID: <loom.20120613T104230-132@post.gmane.org>

Pierre Morel <pier.morel at ...> writes:

> I am getting a lot of pwrssUpdate errors when trying to model my
> data with gmler (using the most recent version from svn... I don't
> know if the previous versions were affected).
 
> These errors are "PIRLS step failed" or "pwrssUpdate did not
> converge in 30 iterations". I understand that these means that the
> algorithm does not manage to work with my data, but there is a
> peculiar behavior, and my data doesn't seem too unreasonable to fit
> with the model I want to use, so I am wondering if the problem is on
> my side !
 
 [snip to make gmane happier]

> Here is the model I want to fit, which doesn't seem unreasonable
> given the figure (random slopes and intercepts for subjects) :
 
>  model<-glmer(cbind(RuleReach,NTrials-RuleReach)~RuleWeight+
>  (RuleWeight|Subject),data=rewardalldirsub,family=binomial)
 
> However this gives me the "pwrssUpdate did not converge in 30
> iterations" error.  What is surprinsing, is that if I do not use the
> rightmost points (RuleWeight of 1), the model converges, even though
> there are less datapoints and the remaining points are the noisiest
> (subjects follow the rule quite reliably when it has a weight of 1
> as you can see).
 
> Removing the correlation in the random effects works sometimes (but
> not on all my sub data sets), and having a random intercept only
> (which is obviously not correct) is the only thing that seems to
> work in all cases.
 
> Centering RuleWeight (ie having it between -1 and 1 instead of 0 and
> 1) doesn't work.  Any ideas on why this doesn't work / how to make
> it work ?

  Thanks for the report: this is an issue the developers are
(painfully) aware of, and working on.  The issue arises mostly when
the predictions for some observations are very close to 0 or 1 (which
explains why using the rightmost points helps ...)  You have tried all
the obvious things I know of.  I would additionally try (1) setting
starting values by hand and/or (2) trying out glmmADMB ...

  Ben Bolker


From n.bunnefeld06 at imperial.ac.uk  Wed Jun 13 11:33:11 2012
From: n.bunnefeld06 at imperial.ac.uk (Bunnefeld, Nils)
Date: Wed, 13 Jun 2012 09:33:11 +0000
Subject: [R-sig-ME] BLUPs in relation to fixed effect interaction
Message-ID: <07DDBF8CB83F184092B7D852182AAB210A05493E@icexch-m2.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120613/53850d33/attachment.pl>

From lborger at cebc.cnrs.fr  Wed Jun 13 12:33:04 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Wed, 13 Jun 2012 12:33:04 +0200
Subject: [R-sig-ME] BLUPs in relation to fixed effect interaction
In-Reply-To: <07DDBF8CB83F184092B7D852182AAB210A05493E@icexch-m2.ic.ac.uk>
References: <07DDBF8CB83F184092B7D852182AAB210A05493E@icexch-m2.ic.ac.uk>
Message-ID: <4FD86C60.8090101@cebc.cnrs.fr>

Hello,

 >We are interested in how much the villages deviate from the estimate 
of the interaction Question*treat

not sure I got your design and question right, but why not including a 
random slope (with the constraint that the covariate cannot be constant 
within each level
of the grouping factor of the random effect)?

More generally, I wonder if psychometric methods and item response 
theory might be of interest to you (apologies if I'm misunderstanding):
http://www.jstatsoft.org/v20/a02/paper



Cheers,
Luca



# Forthcoming book chapter
# Dispersal Ecology and Evolution (ch. 17)
# http://ukcatalogue.oup.com/product/9780199608904.do
---------------------------------------------------------------------
Luca Borger
Postdoctoral Research Fellow
Centre d'Etudes Biologiques de Chiz?
CNRS (UPR1934); INRA (USC1339)
79360 Villiers-en-Bois, France

Tel: +33 (0)549 09 96 13
Fax: +33 (0)549 09 65 26
email: lborger at cebc.cnrs.fr
Web: http://cnrs.academia.edu/LucaBorger
Researcher ID: http://www.researcherid.com/rid/C-6003-2008
Google Scholar: http://scholar.google.com/citations?user=D5CTvNUAAAAJ
---------------------------------------------------------------------
# Newly published! Animal Migration: A synthesis (ch. 8):
# http://ukcatalogue.oup.com/product/9780199568994.do

Le 13/06/2012 11:33, Bunnefeld, Nils a ?crit :
> Dear List,
>
>
> We are using an unmatched count technique to understand the prevalence of illegal hunting. This method is used to make sure people are anonymous and thus hopefully give honest answers about their illegal activity. People are allocated to two treatments and get either a card with four activities (teaching, farming, livestock herding and trading,) or with five activities (teaching, farming, livestock herding, trading and hunting of which one is the sensitive question). The respondents then indicate how many activities they are involved in on their card. We have also asked each person four times the same question but wanted to know whether each of the activities relate to the dry or wet season and whether it was for cash or non-cash. So we have Counts as a dependent variable as the number of activities each person does, Question with four levels (cash dry, cash wet, NonCash dry, NonCash wet), treat with two levels (card with 4 activities, card with 5 activities including the se!
>   nsitive question, Treatment). We have run the model below with Village and id as random effects.
>
> We are now interested why villages are different from each other and extracted the random effects BLUPs using ranef() to be able to use village level explanatory variables in a new model (e.g. distance to protected area). This will give us the estimate how much each village deviates from the overall number of activities, the overall intercept; not really what we are interested in. We are interested in how much the villages deviate from the estimate of the interaction Question*treat because this gives us estimates about the prevalence of illegal hunting in the different seasons rather than the number of activities people are involved in. Any comments or ideas how to implement this in R would be greatly appreciated. An output from our model is below.
>
> Many thanks,
> Nils
>
>
>> library(lme4)
>
>> m1 <- lmer(Counts~Question*treat+(1|Village/id),data=data2,REML=F)
>
>
>
>> summary(m1)
>
> Linear mixed model fit by maximum likelihood
>
> Formula: Counts ~ Question * treat + (1 | Village/id)
>
>     Data: data2
>
>    AIC  BIC logLik deviance REMLdev
>
> 7806 7876  -3892     7784    7825
>
> Random effects:
>
> Groups     Name        Variance Std.Dev.
>
> id:Village (Intercept) 0.21712  0.46596
>
> Village    (Intercept) 0.13535  0.36791
>
> Residual               0.23434  0.48409
>
> Number of obs: 4356, groups: id:Village, 1092; Village, 15
>
>
>
> Fixed effects:
>
>                                   Estimate Std. Error t value
>
> (Intercept)                      1.488733   0.099243  15.001
>
> QuestionCash wet                 0.095400   0.029285   3.258
>
> QuestionNonCash Dry              0.285618   0.029226   9.773
>
> QuestionNonCash Wet              0.514709   0.029226  17.611
>
> treatTreatment                   0.184647   0.040999   4.504
>
> QuestionCash wet:treatTreatment -0.065976   0.041561  -1.587
>
> QuestionNonCash Dry:treatTreatment0.005799   0.041520   0.140
>
> QuestionNonCash Wet:treatTreatment-0.030882   0.041532  -0.744
>
>
>
>
>
>> ranef(m1)
>
> $Village
>
>                 (Intercept)
>
> Guta          0.0822752928
>
> Hunyari      -0.0614857190
>
> Ketembere     0.6976740857
>
> Kitunguruma  -0.3494539970
>
> Koreri       -0.1217766001
>
> Kunzugu      -0.4999783998
>
> Ligamba      -0.4522420174
>
> Makundusi     0.8675942165
>
> Manyamanyama -0.1824419221
>
> Merenga      -0.0006875998
>
> Migungani    -0.1540653530
>
> Morotonga     0.1473949913
>
> Nyamburu     -0.1751358164
>
> Nyamoko       0.0567038683
>
> Robanda       0.1456249700
>
>
>
>
>
> ------------------------------------------------------------------------
> Dr Nils Bunnefeld
> Imperial College London
> Silwood Park
> SL5 7PY, Ascot, UK
> http://www.iccs.org.uk/nils-bunnefeld
> http://fp7hunt.net/
> Tel: +44 20 7594 9086
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From pier.morel at gmail.com  Wed Jun 13 13:09:13 2012
From: pier.morel at gmail.com (Pierre Morel)
Date: Wed, 13 Jun 2012 13:09:13 +0200
Subject: [R-sig-ME] Avoid errors in pwrssUpdate ?
In-Reply-To: <loom.20120613T104230-132@post.gmane.org>
References: <00BA0FA0-9C6A-4366-A60B-7394E1D20A52@gmail.com>
	<loom.20120613T104230-132@post.gmane.org>
Message-ID: <E962DCFF-A1C6-40C9-A1B1-FFD3ED326C58@gmail.com>

OK, thanks for the suggestion of glmmADMB, I will look that up.
I also found out that I could get things working with nAGQ=0.
However the doc says it's less exact, and profile() gives a "pp$setTheta(theta) : theta size mismatch" error in this case.

Pierre Morel


Le 13 juin 2012 ? 10:54, Ben Bolker a ?crit :

> Pierre Morel <pier.morel at ...> writes:
> 
>> I am getting a lot of pwrssUpdate errors when trying to model my
>> data with gmler (using the most recent version from svn... I don't
>> know if the previous versions were affected).
> 
>> These errors are "PIRLS step failed" or "pwrssUpdate did not
>> converge in 30 iterations". I understand that these means that the
>> algorithm does not manage to work with my data, but there is a
>> peculiar behavior, and my data doesn't seem too unreasonable to fit
>> with the model I want to use, so I am wondering if the problem is on
>> my side !
> 
> [snip to make gmane happier]
> 
>> Here is the model I want to fit, which doesn't seem unreasonable
>> given the figure (random slopes and intercepts for subjects) :
> 
>> model<-glmer(cbind(RuleReach,NTrials-RuleReach)~RuleWeight+
>> (RuleWeight|Subject),data=rewardalldirsub,family=binomial)
> 
>> However this gives me the "pwrssUpdate did not converge in 30
>> iterations" error.  What is surprinsing, is that if I do not use the
>> rightmost points (RuleWeight of 1), the model converges, even though
>> there are less datapoints and the remaining points are the noisiest
>> (subjects follow the rule quite reliably when it has a weight of 1
>> as you can see).
> 
>> Removing the correlation in the random effects works sometimes (but
>> not on all my sub data sets), and having a random intercept only
>> (which is obviously not correct) is the only thing that seems to
>> work in all cases.
> 
>> Centering RuleWeight (ie having it between -1 and 1 instead of 0 and
>> 1) doesn't work.  Any ideas on why this doesn't work / how to make
>> it work ?
> 
>  Thanks for the report: this is an issue the developers are
> (painfully) aware of, and working on.  The issue arises mostly when
> the predictions for some observations are very close to 0 or 1 (which
> explains why using the rightmost points helps ...)  You have tried all
> the obvious things I know of.  I would additionally try (1) setting
> starting values by hand and/or (2) trying out glmmADMB ...
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Jun 13 13:40:08 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Jun 2012 07:40:08 -0400
Subject: [R-sig-ME] Fwd: Re: [R-sig-eco] cozigam
In-Reply-To: <CANLCanUdbQFOvqGTtzzaELUY5HUpmOw7n0862mAaMCyQo5aN5w@mail.gmail.com>
References: <CANLCanUdbQFOvqGTtzzaELUY5HUpmOw7n0862mAaMCyQo5aN5w@mail.gmail.com>
Message-ID: <4FD87C18.8000709@gmail.com>

[cc'ing back to r-ecology]


-------- Original Message --------
Subject: 	Re: [R-sig-eco] cozigam
Date: 	Wed, 13 Jun 2012 14:38:49 +0430
From: 	Mahnaz Rabbaniha <rab.mahnaz at gmail.com>
To: 	Ben Bolker <bbolker at gmail.com>

hi

thanks for your answer

for finding the relation  i have try glm,gam and gam with smooth
variable, but in all conditions the results shown unacceptable answer (
for example: R-sq.(adj) =    0.1    ,   Deviance explained = 18.9%)

in base of contacts previous whit r - group and in base of zero in
data,i decided to use cozigam,My awareness is low about it but i try
different code in Liu,2010 .

after the received mis mentioned above, i omitted depth and this code used:

   res <- cozigam(Clupeidae~s(temperature,salinity), constraint =
"proportional", family = gaussian)

 result:

[snip]

> summary(res)
Family: gaussian
Parametric coefficients:
            Estimate       Std. Error   t value Pr(>|t|)
(Intercept)   -20.665505  13.904231    -1.486   0.1401
alpha          -0.486186   0.207679    -2.341   0.0210 *
delta1          0.010161   0.004781     2.125   0.0358 *

Approximate significance of smooth terms:

  Edf       Est.rank    F p-value

s(temperature,salinity)                 20.81       29 8.77      <2e-16 ***
---

Scale est. = 270.56    n = 132

what do you think? is it adequate for analyses ? do you have any suggest


   BMB> This is really too vague a question. You should do the usual
things that are done with the results of any analysis: figure out what
the parameters mean (e.g. by reading the JRSS COZIGAM paper:
http://www.jstatsoft.org/v35/i11/paper ), look at the parameter
estimates, their confidence intervals, predictions and see if they
make sense, residuals and see if there are obvious violations of
the statistical models (systematic patterns, variation in heterogeneity,
etc.)

On Wed, Jun 13, 2012 at 1:03 PM, Ben Bolker <bbolker at gmail.com
<mailto:bbolker at gmail.com>> wrote:

    Mahnaz Rabbaniha <rab.mahnaz at ...> writes:

    > i try to find regression between clupeidae,with
    temperature,salinity and
    > depth. the response variable is inclued many zero ( 86 from 133
    observed)
    >
    > therefore i used this code :
    >
    >  res <- cozigam(Clupeidae~s(temperature,salinity)+s(depth),
    constraint =
    > "proportional", family = gaussian)
    >
    > the result:
    > iteration = 2    norm = 1.001743
    > iteration = 3    norm = 0.3377464
    > iteration = 4    norm = 9.172232e-05
    >
    > ==========================================
    > estimated alpha = -0.5337883 ( 0.1789113 )
    > estimated delta = -0.0009891505 ( NaN )
    > ==========================================
    >
    > Warning message:
    >
    > In sqrt(V.theta[2, 2]) : NaNs produced
    >
    > what is exactly meaning?


     You're probably not getting answers to your repeated posts
    because you're not providing a reproducible example
    ( http://tinyurl.com/reproducible-000 ) and not giving very much
    detail about your problem.
     I strongly suspect that your model is too complex for your data:
    a general rule of thumb is that you need about 10 observations
    per parameter estimated. It's a bit hard to count in this case
    for two reasons -- zeroes are relatively uninformative (so each
    zero counts for less than one 'effective' observation), and it's
    a little hard to count parameters for penalized smooth terms --
    but I think you can't really expect to fit a two-way smooth term
    on temperature and salinity *and* a smooth term on depth ... the
    example in the COZIGAM JRSS paper (referenced in the help)
    fits a model of about the same complexity to 274 data points with
    84 zero catches -- somewhere between 3 and 4 times as much data
    as you have.
     Most narrowly, the program is trying to estimate the standard
    error of the parameter by inverting the matrix of second derivatives,
    and failing because the surface is too flat, or too strongly
    correlated, or some similar problem.

    _______________________________________________
    R-sig-ecology mailing list
    R-sig-ecology at r-project.org <mailto:R-sig-ecology at r-project.org>
    https://stat.ethz.ch/mailman/listinfo/r-sig-ecology


From bbolker at gmail.com  Wed Jun 13 13:41:18 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Jun 2012 07:41:18 -0400
Subject: [R-sig-ME] Fwd: Fwd: Re: [R-sig-eco] cozigam
In-Reply-To: <4FD87C18.8000709@gmail.com>
References: <4FD87C18.8000709@gmail.com>
Message-ID: <4FD87C5E.6070305@gmail.com>



  [oops, cc'd to r-sig-mixed by mistake.  Sorry.  Re-posting to
r-sig-ecology.]

-------- Original Message --------
Subject: Fwd: Re: [R-sig-eco] cozigam
Date: Wed, 13 Jun 2012 07:40:08 -0400
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>,
 Mahnaz Rabbaniha <rab.mahnaz at gmail.com>

[cc'ing back to r-ecology]


-------- Original Message --------
Subject: 	Re: [R-sig-eco] cozigam
Date: 	Wed, 13 Jun 2012 14:38:49 +0430
From: 	Mahnaz Rabbaniha <rab.mahnaz at gmail.com>
To: 	Ben Bolker <bbolker at gmail.com>

hi

thanks for your answer

for finding the relation  i have try glm,gam and gam with smooth
variable, but in all conditions the results shown unacceptable answer (
for example: R-sq.(adj) =    0.1    ,   Deviance explained = 18.9%)

in base of contacts previous whit r - group and in base of zero in
data,i decided to use cozigam,My awareness is low about it but i try
different code in Liu,2010 .

after the received mis mentioned above, i omitted depth and this code used:

   res <- cozigam(Clupeidae~s(temperature,salinity), constraint =
"proportional", family = gaussian)

 result:

[snip]

> summary(res)
Family: gaussian
Parametric coefficients:
            Estimate       Std. Error   t value Pr(>|t|)
(Intercept)   -20.665505  13.904231    -1.486   0.1401
alpha          -0.486186   0.207679    -2.341   0.0210 *
delta1          0.010161   0.004781     2.125   0.0358 *

Approximate significance of smooth terms:

  Edf       Est.rank    F p-value

s(temperature,salinity)                 20.81       29 8.77      <2e-16 ***
---

Scale est. = 270.56    n = 132

what do you think? is it adequate for analyses ? do you have any suggest


   BMB> This is really too vague a question. You should do the usual
things that are done with the results of any analysis: figure out what
the parameters mean (e.g. by reading the JRSS COZIGAM paper:
http://www.jstatsoft.org/v35/i11/paper ), look at the parameter
estimates, their confidence intervals, predictions and see if they
make sense, residuals and see if there are obvious violations of
the statistical models (systematic patterns, variation in heterogeneity,
etc.)

On Wed, Jun 13, 2012 at 1:03 PM, Ben Bolker <bbolker at gmail.com
<mailto:bbolker at gmail.com>> wrote:

    Mahnaz Rabbaniha <rab.mahnaz at ...> writes:

    > i try to find regression between clupeidae,with
    temperature,salinity and
    > depth. the response variable is inclued many zero ( 86 from 133
    observed)
    >
    > therefore i used this code :
    >
    >  res <- cozigam(Clupeidae~s(temperature,salinity)+s(depth),
    constraint =
    > "proportional", family = gaussian)
    >
    > the result:
    > iteration = 2    norm = 1.001743
    > iteration = 3    norm = 0.3377464
    > iteration = 4    norm = 9.172232e-05
    >
    > ==========================================
    > estimated alpha = -0.5337883 ( 0.1789113 )
    > estimated delta = -0.0009891505 ( NaN )
    > ==========================================
    >
    > Warning message:
    >
    > In sqrt(V.theta[2, 2]) : NaNs produced
    >
    > what is exactly meaning?


     You're probably not getting answers to your repeated posts
    because you're not providing a reproducible example
    ( http://tinyurl.com/reproducible-000 ) and not giving very much
    detail about your problem.
     I strongly suspect that your model is too complex for your data:
    a general rule of thumb is that you need about 10 observations
    per parameter estimated. It's a bit hard to count in this case
    for two reasons -- zeroes are relatively uninformative (so each
    zero counts for less than one 'effective' observation), and it's
    a little hard to count parameters for penalized smooth terms --
    but I think you can't really expect to fit a two-way smooth term
    on temperature and salinity *and* a smooth term on depth ... the
    example in the COZIGAM JRSS paper (referenced in the help)
    fits a model of about the same complexity to 274 data points with
    84 zero catches -- somewhere between 3 and 4 times as much data
    as you have.
     Most narrowly, the program is trying to estimate the standard
    error of the parameter by inverting the matrix of second derivatives,
    and failing because the surface is too flat, or too strongly
    correlated, or some similar problem.

    _______________________________________________
    R-sig-ecology mailing list
    R-sig-ecology at r-project.org <mailto:R-sig-ecology at r-project.org>
    https://stat.ethz.ch/mailman/listinfo/r-sig-ecology


From ken.knoblauch at inserm.fr  Wed Jun 13 15:41:53 2012
From: ken.knoblauch at inserm.fr (ken knoblauch)
Date: Wed, 13 Jun 2012 13:41:53 +0000 (UTC)
Subject: [R-sig-ME] Avoid errors in pwrssUpdate ?
References: <00BA0FA0-9C6A-4366-A60B-7394E1D20A52@gmail.com>
	<loom.20120613T104230-132@post.gmane.org>
	<E962DCFF-A1C6-40C9-A1B1-FFD3ED326C58@gmail.com>
Message-ID: <loom.20120613T153129-402@post.gmane.org>

Pierre Morel <pier.morel at ...> writes:
> OK, thanks for the suggestion of glmmADMB, I will look that up.
> I also found out that I could get things working with nAGQ=0.
> However the doc says it's less exact, and profile() gives 
  a "pp$setTheta(theta) : theta size mismatch"
> error in this case.
> Pierre Morel
> Le 13 juin 2012 ? 10:54, Ben Bolker a ?crit :
> > Pierre Morel <pier.morel at ...> writes:
> >> I am getting a lot of pwrssUpdate errors when trying to model my
> >> data with gmler (using the most recent version from svn... I don't
> >> know if the previous versions were affected).
> >> These errors are "PIRLS step failed" or "pwrssUpdate did not
> >> converge in 30 iterations". I understand that these means that the
> >> algorithm does not manage to work with my data, but there is a
> >> peculiar behavior, and my data doesn't seem too unreasonable to fit
> >> with the model I want to use, so I am wondering if the problem is on
> >> my side !
> > 
> > [snip to make gmane happier]
> > 
> >> Here is the model I want to fit, which doesn't seem unreasonable
> >> given the figure (random slopes and intercepts for subjects) :
> >
> >> model<-glmer(cbind(RuleReach,NTrials-RuleReach)~RuleWeight+
> >> (RuleWeight|Subject),data=rewardalldirsub,family=binomial)
> > 
> >> However this gives me the "pwrssUpdate did not converge in 30
> >> iterations" error.  What is surprinsing, is that if I do not use the
> >> rightmost points (RuleWeight of 1), the model converges, even though
> >> there are less datapoints and the remaining points are the noisiest
> >> (subjects follow the rule quite reliably when it has a weight of 1
> >> as you can see).
> > 
> >> Removing the correlation in the random effects works sometimes (but
> >> not on all my sub data sets), and having a random intercept only
> >> (which is obviously not correct) is the only thing that seems to
> >> work in all cases.
> > 
> >> Centering RuleWeight (ie having it between -1 and 1 instead of 0 and
> >> 1) doesn't work.  Any ideas on why this doesn't work / how to make
> >> it work ?
> > 
> >  Thanks for the report: this is an issue the developers are
> > (painfully) aware of, and working on.  The issue arises mostly when
> > the predictions for some observations are very close to 0 or 1 (which
> > explains why using the rightmost points helps ...)  You have tried all
> > the obvious things I know of.  I would additionally try (1) setting
> > starting values by hand and/or (2) trying out glmmADMB ...
> > 
> >  Ben Bolker

I've been trying to monitor this situation from afar so as not to harass
the developers (unduly, at least), in order to be able to use the links
from the psyphy package to fit psychometric functions for binary
and aggregated responses when there are multiple-alternative
forced choices.  I did have some interaction with 
Pr. Bates on the topic a few months back and he did something around
revision 1701 that does permit the link functions to work without
emitting the PIRLS error, and so I keep this version around
in a separate directory while checking the latest to see if the
above discussed problem has been solved.  So, it may be of
value to try this earlier version, unless the developers provide
strong reasons not to.  Hope that is useful.

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From mts002 at uark.edu  Wed Jun 13 17:45:06 2012
From: mts002 at uark.edu (Matthew Smith)
Date: Wed, 13 Jun 2012 10:45:06 -0500
Subject: [R-sig-ME] Repeated Measures MANOVA in R
Message-ID: <20120613104506.Horde.HBqLck9O9e1P2LWCG4G3sGA@uamail.uark.edu>


Greetings,

First off, I apologize if this is too basic of a question, but I am  
relatively new to both R and repeated measures.
I have figured out how to code for repeated measures ANOVA in R using  
the nlme library. I have been able to test different covariance  
structures and obtain the desired parameter estimates. Now I would  
like to run a repeated measures MANOVA on some geometric morphometric  
data that I have. I have consulted online code and my statistical  
adviser, but most of the suggestions I get is for running individual  
ANOVAs on each variable, but I am not comfortable separating shape  
into each Relative Warp score. Can anyone recommend a course of action  
and/or some example data and code?? I tend to be a visual learner, so  
seeing an example would be most beneficial. Thank you in advance.

Matthew Smith
PhD Candidate
Department of Biological Sciences
1 University of Arkansas
Science Engineering Building
Fayetteville, AR 72701-1201
479-575-2963
mts002 at uark.edu


From kharouba at zoology.ubc.ca  Wed Jun 13 18:44:32 2012
From: kharouba at zoology.ubc.ca (Heather Kharouba)
Date: Wed, 13 Jun 2012 09:44:32 -0700
Subject: [R-sig-ME] Error with glmmADMB and beta distribution
In-Reply-To: <loom.20120613T095212-344@post.gmane.org>
References: <f6dce96b596dd15e0c2eef92db7d461f.squirrel@webmail.zoology.ubc.ca>
	<loom.20120613T095212-344@post.gmane.org>
Message-ID: <20bc8fe76447ddea7a1105b60f251f3f.squirrel@webmail.zoology.ubc.ca>

You're right, I have 116 AUC values of 1 (out of 4318 observations). I
tried running the model without these values and I still got the same
error. When I also excluded the random effect (in addition to removing AUC
values of 1) I got this error:

Estimated covariance matrix may not be positive definite
 6.27097e-06 0.201327 0.239814 0.244739 0.260651 0.264242 0.277349
0.314547 0.325412 0.327576 0.33569 0.379634 0.410961 0.425718 0.433164
0.455047 0.466607 0.539125 0.578641 0.6752 0.712861 0.726921 0.970862
1.15373 1.64282

I have 20 studies but the data is very unbalanced ranging from 1 to 1778
observations/study.  Before learning about glmmadmb, the only other
distribution that I found to work with this data is the quasi-binomial
distribution but then I have to rely on marginal tests of parameters which
I understand is not appropriate for unbalanced data and the variable I'm
interested in is categorical with more than 2 levels. I can't calculate
quasi-AIC as you suggest here:
http://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf

because the binomial model won't converge. I realize I won't find a
perfect solution to this problem but I'm not sure which solution is the
least problematic!

Thanks,
Heather


> Heather Kharouba <kharouba at ...> writes:
>
>> I am new to glmmADMB and would like to use the beta distribution with
>> glmmadmb. However, I keep running into the same error. The response
>> variable is AUC (area under the curve data) from species distribution
>> models which is continuous and ranges from 0 to 1. The fixed variables
>> are
>> the number of variables used to build the model (continuous), spatial
>> extent of the distribution model (continuous), model type (factor) and
>> taxonomic group (categorical) and the random effect is study.
>>
>> Here's the model:
>>
>> model1<-glmmadmb(AUC~variables+log_area+model+taxa+(1|study),
>> family="beta", verbose=TRUE, data=auc);
>>
>> A snapshot of the data:
>>
>> study                  taxa       AUC      model variables log_area
>>  Araujo et al. 2005 BIRD 0.9156878   GAM         7 16.21771
>> Araujo et al. 2005 BIRD 0.9288596   GAM         7 16.21771
>> Araujo et al. 2005 BIRD 0.9254065   GAM         7 16.21771
>> Araujo et al. 2005 BIRD 0.8825593   GAM         7 16.21771
>> Araujo et al. 2005 BIRD 0.9388894   GAM         7 16.21771
>> Araujo et al. 2005 BIRD 0.9061483   GAM         7 16.21771
>>
>> When I run the model I get this error:
>> Error in glmmadmb(AUC ~ variables + log_area + model + taxa + (1 |
>> study),
>>  :
>>   The function maximizer failed (couldn't find STD file)
>>
>
>   [snip]
>>
>> I'm using glmm ADMB version 0.7.2.2 with R version 2.14.2 on a Mac OS X
>> Version 10.6.8. I've tried including
>> admb.opts=admbControl(shess=FALSE,noinit=FALSE) and still get the same
>> error. I'm guessing there's something wrong with either the response
>> variable or with the overall data structure?
>
>   My first guess would be that you have AUC values that are
> exactly equal to 0 or 1; they will give infinite/NaN log-likelihoods
> in the beta model. Beyond that, I'm not sure.  It would be useful
> to know a little bit more about your data -- how many total observations?
> How many studies?
>
> Does fitting the model without the random effect work, i.e.
>
> model2 <- glmmadmb(AUC~variables+log_area+model+taxa,
>   family="beta", verbose=TRUE, data=auc)
>
> ?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


------
Heather Kharouba
PhD candidate
Department of Zoology & Beaty Biodiversity Centre
University of British Columbia
4200-6270 University Blvd., Vancouver, B.C. V6T 1Z4
http://www.zoology.ubc.ca/~kharouba


From dadrivr at gmail.com  Wed Jun 13 21:50:10 2012
From: dadrivr at gmail.com (Isaac Petersen)
Date: Wed, 13 Jun 2012 15:50:10 -0400
Subject: [R-sig-ME] Plotting interactions from lme with ggplot
Message-ID: <CAPBn5Xt3_YVQm0yrHfTm0OudKZHosGt0wEVJHBi6bEs__WmDng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120613/f8da5f1a/attachment.pl>

From chenyi at uga.edu  Wed Jun 13 23:40:43 2012
From: chenyi at uga.edu (Yi (Charlie) Chen)
Date: Wed, 13 Jun 2012 21:40:43 +0000
Subject: [R-sig-ME] Bayesian Inference on Variance Components
Message-ID: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120613/c1f6d7fc/attachment.pl>

From kw.stat at gmail.com  Thu Jun 14 00:14:29 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 13 Jun 2012 17:14:29 -0500
Subject: [R-sig-ME] Bayesian Inference on Variance Components
In-Reply-To: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
References: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
Message-ID: <CAKFxdiR7-dNWr0GUkuW7exjtT5GDj-_S76s8YLbSHXvrWrsWAQ@mail.gmail.com>

Have a look at the MCMCglmm package.

Maybe of interest:     Wolfinger, R.D. and Kass, R.E., 2000.
Nonconjugate Bayesian
     analysis of variance component models, _Biometrics_, 56, 768-774.

Kevin Wright


On Wed, Jun 13, 2012 at 4:40 PM, Yi (Charlie) Chen <chenyi at uga.edu> wrote:
> Hi All,
>
> I'm trying to do the Bayesian Inference on variance components of mixed effect models, is there any suggestion about the package I can start with? Especially for the confidence interval, as far as I have tried, I can't get confidence intervals for variance components in NLME and LME4 package, am I right?
>
> Any recommendation or references are very appreciated.
>
> Best,
> Charlie
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Kevin Wright


From David.Duffy at qimr.edu.au  Thu Jun 14 00:53:00 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 14 Jun 2012 08:53:00 +1000 (EST)
Subject: [R-sig-ME] Bayesian Inference on Variance Components
In-Reply-To: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
References: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
Message-ID: <Pine.LNX.4.64.1206140850010.25897@orpheus.qimr.edu.au>

On Wed, 13 Jun 2012, Yi (Charlie) Chen wrote:

> I'm trying to do the Bayesian Inference on variance components of mixed 
> effect models, is there any suggestion about the package I can start 
> with?

Why not look through the WinBUGS examples too.  If all you really want is 
confidence intervals or HPDs, don't forget mcmcsamp() in lme4.


From wkmor1 at gmail.com  Thu Jun 14 07:26:45 2012
From: wkmor1 at gmail.com (William Morris)
Date: Thu, 14 Jun 2012 15:26:45 +1000
Subject: [R-sig-ME] Bayesian Inference on Variance Components
In-Reply-To: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
References: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
Message-ID: <AA60A1ADFD3C47DDAD80CEEC5328B7B0@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120614/02526eab/attachment.pl>

From s.chamaille at yahoo.fr  Thu Jun 14 09:35:04 2012
From: s.chamaille at yahoo.fr (Simon =?ISO-8859-1?Q?Chamaill=E9-Jammes?=)
Date: Thu, 14 Jun 2012 09:35:04 +0200
Subject: [R-sig-ME] Bayesian Inference on Variance Components
Message-ID: <1339659304.2072.12.camel@simon-desktop>

Hi Charlie,

this paper:
Nakagawa, S. and Schielzeth, H. (2010), Repeatability for Gaussian and
non-Gaussian data: a practical guide for biologists. Biological Reviews,
85: 935?956.
http://onlinelibrary.wiley.com/doi/10.1111/j.1469-185X.2010.00141.x/abstract

with the associated website: http://rptr.r-forge.r-project.org/

may be of interest to you. They implemented (in R, using the MCMCglmm
package ) MCMC Bayesian estimation of variance components to compute
intraclass correlations with associated credible intervals (they also
have a glmmPQL + parametric bootstraping approach).

I've been playing it with myself and it may do (with a bit of tweaking
of not, depending of what you want) what you need. I'm however still
uncertain on how to choose reliable un- or weakly informative priors for
variance components in MCMCglmm. My experiments with this so far is that
it is relatively easy to get estimates that are way off the ones
provided by Laplace approximation. 

It seems that BUGS/JAGS would allow you using a wider range of prior
distribution (like half-normal), but I found them harder to use.

best, 

simon


From n.bunnefeld06 at imperial.ac.uk  Thu Jun 14 09:58:01 2012
From: n.bunnefeld06 at imperial.ac.uk (Bunnefeld, Nils)
Date: Thu, 14 Jun 2012 07:58:01 +0000
Subject: [R-sig-ME] BLUPs in relation to fixed effect interaction
In-Reply-To: <4FD86C60.8090101@cebc.cnrs.fr>
References: <07DDBF8CB83F184092B7D852182AAB210A05493E@icexch-m2.ic.ac.uk>
	<4FD86C60.8090101@cebc.cnrs.fr>
Message-ID: <07DDBF8CB83F184092B7D852182AAB210A054C68@icexch-m2.ic.ac.uk>

Thanks Luca, 

That works very well. Thanks for the paper link, very useful.

Cheers,
Nils


*-----Original Message-----
*From: prvs=151105a2de=lborger at cebc.cnrs.fr
*[mailto:prvs=151105a2de=lborger at cebc.cnrs.fr] On Behalf Of Luca Borger
*Sent: 13 June 2012 11:33
*To: Bunnefeld, Nils
*Cc: 'r-sig-mixed-models at r-project.org'
*Subject: Re: [R-sig-ME] BLUPs in relation to fixed effect interaction
*
*Hello,
*
* >We are interested in how much the villages deviate from the estimate
*of the interaction Question*treat
*
*not sure I got your design and question right, but why not including a
*random slope (with the constraint that the covariate cannot be constant
*within each level
*of the grouping factor of the random effect)?
*
*More generally, I wonder if psychometric methods and item response
*theory might be of interest to you (apologies if I'm misunderstanding):
*http://www.jstatsoft.org/v20/a02/paper
*
*
*
*Cheers,
*Luca
*
*
*
*# Forthcoming book chapter
*# Dispersal Ecology and Evolution (ch. 17)
*# http://ukcatalogue.oup.com/product/9780199608904.do
*---------------------------------------------------------------------
*Luca Borger
*Postdoctoral Research Fellow
*Centre d'Etudes Biologiques de Chiz?
*CNRS (UPR1934); INRA (USC1339)
*79360 Villiers-en-Bois, France
*
*Tel: +33 (0)549 09 96 13
*Fax: +33 (0)549 09 65 26
*email: lborger at cebc.cnrs.fr
*Web: http://cnrs.academia.edu/LucaBorger
*Researcher ID: http://www.researcherid.com/rid/C-6003-2008
*Google Scholar: http://scholar.google.com/citations?user=D5CTvNUAAAAJ
*---------------------------------------------------------------------
*# Newly published! Animal Migration: A synthesis (ch. 8):
*# http://ukcatalogue.oup.com/product/9780199568994.do
*
*Le 13/06/2012 11:33, Bunnefeld, Nils a ?crit :
*> Dear List,
*>
*>
*> We are using an unmatched count technique to understand the prevalence
*of illegal hunting. This method is used to make sure people are
*anonymous and thus hopefully give honest answers about their illegal
*activity. People are allocated to two treatments and get either a card
*with four activities (teaching, farming, livestock herding and trading,)
*or with five activities (teaching, farming, livestock herding, trading
*and hunting of which one is the sensitive question). The respondents
*then indicate how many activities they are involved in on their card. We
*have also asked each person four times the same question but wanted to
*know whether each of the activities relate to the dry or wet season and
*whether it was for cash or non-cash. So we have Counts as a dependent
*variable as the number of activities each person does, Question with
*four levels (cash dry, cash wet, NonCash dry, NonCash wet), treat with
*two levels (card with 4 activities, card with 5 activities including the
*se!
*>   nsitive question, Treatment). We have run the model below with
*Village and id as random effects.
*>
*> We are now interested why villages are different from each other and
*extracted the random effects BLUPs using ranef() to be able to use
*village level explanatory variables in a new model (e.g. distance to
*protected area). This will give us the estimate how much each village
*deviates from the overall number of activities, the overall intercept;
*not really what we are interested in. We are interested in how much the
*villages deviate from the estimate of the interaction Question*treat
*because this gives us estimates about the prevalence of illegal hunting
*in the different seasons rather than the number of activities people are
*involved in. Any comments or ideas how to implement this in R would be
*greatly appreciated. An output from our model is below.
*>
*> Many thanks,
*> Nils
*>
*>
*>> library(lme4)
*>
*>> m1 <- lmer(Counts~Question*treat+(1|Village/id),data=data2,REML=F)
*>
*>
*>
*>> summary(m1)
*>
*> Linear mixed model fit by maximum likelihood
*>
*> Formula: Counts ~ Question * treat + (1 | Village/id)
*>
*>     Data: data2
*>
*>    AIC  BIC logLik deviance REMLdev
*>
*> 7806 7876  -3892     7784    7825
*>
*> Random effects:
*>
*> Groups     Name        Variance Std.Dev.
*>
*> id:Village (Intercept) 0.21712  0.46596
*>
*> Village    (Intercept) 0.13535  0.36791
*>
*> Residual               0.23434  0.48409
*>
*> Number of obs: 4356, groups: id:Village, 1092; Village, 15
*>
*>
*>
*> Fixed effects:
*>
*>                                   Estimate Std. Error t value
*>
*> (Intercept)                      1.488733   0.099243  15.001
*>
*> QuestionCash wet                 0.095400   0.029285   3.258
*>
*> QuestionNonCash Dry              0.285618   0.029226   9.773
*>
*> QuestionNonCash Wet              0.514709   0.029226  17.611
*>
*> treatTreatment                   0.184647   0.040999   4.504
*>
*> QuestionCash wet:treatTreatment -0.065976   0.041561  -1.587
*>
*> QuestionNonCash Dry:treatTreatment0.005799   0.041520   0.140
*>
*> QuestionNonCash Wet:treatTreatment-0.030882   0.041532  -0.744
*>
*>
*>
*>
*>
*>> ranef(m1)
*>
*> $Village
*>
*>                 (Intercept)
*>
*> Guta          0.0822752928
*>
*> Hunyari      -0.0614857190
*>
*> Ketembere     0.6976740857
*>
*> Kitunguruma  -0.3494539970
*>
*> Koreri       -0.1217766001
*>
*> Kunzugu      -0.4999783998
*>
*> Ligamba      -0.4522420174
*>
*> Makundusi     0.8675942165
*>
*> Manyamanyama -0.1824419221
*>
*> Merenga      -0.0006875998
*>
*> Migungani    -0.1540653530
*>
*> Morotonga     0.1473949913
*>
*> Nyamburu     -0.1751358164
*>
*> Nyamoko       0.0567038683
*>
*> Robanda       0.1456249700
*>
*>
*>
*>
*>
*> ----------------------------------------------------------------------
*--
*> Dr Nils Bunnefeld
*> Imperial College London
*> Silwood Park
*> SL5 7PY, Ascot, UK
*> http://www.iccs.org.uk/nils-bunnefeld
*> http://fp7hunt.net/
*> Tel: +44 20 7594 9086
*>
*>
*> 	[[alternative HTML version deleted]]
*>
*> _______________________________________________
*> R-sig-mixed-models at r-project.org mailing list
*> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
*>
*>
*
*
*


From Thierry.ONKELINX at inbo.be  Thu Jun 14 10:05:52 2012
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 14 Jun 2012 08:05:52 +0000
Subject: [R-sig-ME] Plotting interactions from lme with ggplot
In-Reply-To: <CAPBn5Xt3_YVQm0yrHfTm0OudKZHosGt0wEVJHBi6bEs__WmDng@mail.gmail.com>
References: <CAPBn5Xt3_YVQm0yrHfTm0OudKZHosGt0wEVJHBi6bEs__WmDng@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA74275D66C4DD@inbomail.inbo.be>

Something like this?

newdata <- expand.grid(
  time = pretty(dataset$time, 20),
  predictor = qnorm(pnorm(c(-1, 0, 1)), mean = mean(dataset$predictor, na.rm = TRUE), sd = sd(dataset$predictor, na.rm = TRUE)),
  moderator = qnorm(pnorm(c(-1, 0, 1)), mean = mean(dataset$moderator, na.rm = TRUE), sd = sd(dataset$moderator, na.rm = TRUE))
)
newdata$outcome <- predict(model, newdata = newdata, level = 0)
newdata$fPredictor <- factor(newdata$predictor, labels = c("LP", "MP", "HP"))
newdata$fModerator <- factor(newdata$moderator, labels = c("LM", "MM", "HM"))
newdata$Combination <- interaction(newdata$fPredict, newdata$fModerator)
library(ggplot2)
ggplot(newdata, aes(x = time, y = outcome, colour = fPredictor, linetype = fModerator)) + geom_line()
ggplot(newdata, aes(x = time, y = outcome, colour = Combination)) + geom_line()



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Isaac Petersen
Verzonden: woensdag 13 juni 2012 21:50
Aan: R-sig-mixed-models
Onderwerp: [R-sig-ME] Plotting interactions from lme with ggplot

I'm fitting a lme growth curve model with two predictors and their interaction as predictors. The multilevel model is nested so that level 1 is time within the individual, and level 2 is the individual.  I would like to plot the mean group-level trajectories at plus and minus 1 SD from the mean of the main effects composing the interaction term using ggplot.
 Thus, the plot should have 4 lines (mean trajectories) representing all combinations of the two predictors (where LO = -1sd from its mean, and HI =
+1sd from its mean):
-LO predictor, LO moderator
-LO predictor, HI moderator
-HI predictor, LO moderator
-HI predictor, HI moderator

They are growth curves, so the plot should have 'time' on the x-axis and 'outcome' on the y-axis.  Here's a sample model:

library(nlme)

set.seed(123)

dataset <- NULL
dataset$id <- rep(1:100, each=10)
dataset$time <- rep(1:10,100)
dataset$outcome <- rnorm(1000, mean=100, sd=15) dataset$predictor <- rnorm(1000, mean=10, sd=3) dataset$moderator <- rnorm(1000, mean=5, sd=2)

dataset <- as.data.frame(dataset)
dataset[sample(1:1000, 400, replace=F),"outcome"] <- NA dataset[sample(1:1000, 400, replace=F),"predictor"] <- NA dataset[sample(1:1000, 400, replace=F),"moderator"] <- NA

model <- lme(outcome~ time + predictor + moderator + predictor*moderator,
random=~1 + time + predictor|id, data=dataset, na.action=na.omit)

How can I plot the interaction on the mean group-level trajectories using ggplot?  I'm new to ggplot, so any help would be greatly appreciated.  Thanks in advance!

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From laurent_step at yahoo.fr  Thu Jun 14 10:21:46 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Thu, 14 Jun 2012 09:21:46 +0100 (BST)
Subject: [R-sig-ME] Re :  Bayesian Inference on Variance Components
In-Reply-To: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
References: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
Message-ID: <1339662106.47736.YahooMailNeo@web29505.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120614/24b06e92/attachment.pl>

From dale.w.steele at gmail.com  Thu Jun 14 23:51:24 2012
From: dale.w.steele at gmail.com (Dale Steele)
Date: Thu, 14 Jun 2012 16:51:24 -0500
Subject: [R-sig-ME] mcmcglmm and parallel chains
In-Reply-To: <loom.20120613T100728-628@post.gmane.org>
References: <20120612142138.GA15825@ingegerdsdator>
	<loom.20120613T100728-628@post.gmane.org>
Message-ID: <CAK-DBaBg0cd2-iJNw9Dwc=aM4MkJcpXbKdF=pJiBh91tWxV+Tg@mail.gmail.com>

Just now hearing from Andrew Redd about his 'harvestr' package which
seems tailor made for this problem...

https://github.com/halpo/harvestr

On Wed, Jun 13, 2012 at 3:16 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Hans Ekbrand <hans at ...> writes:
>
>>
>> I am learning mcmcglmm in order to use it on a beowulf cluster.
>>
>> In https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q3/006558.html
>>
>> Jarrod Hadfield writes:
>>
>> "You can merge MCMC chains from multiple runs, although you should make
>> sure you start them from different initial values"
>>
>> Is it sufficient to provide differents random seeds for each run,
>> or does this refer to the start parameter of mcmcglmm()?
>>
>> ? ?start: optional list having 4 possible elements: ?R? (R-structure)
>> ? ? ? ? ? ?G? (G-structure) and ?liab? (latent variables or
>> ? ? ? ? ? liabilities) should contain the starting values where ?G?
>> ? ? ? ? ? itself is also a list with as many elements as random effect
>> ? ? ? ? ? components. The fourth element ?QUASI? should be logical: if
>> ? ? ? ? ? ?TRUE? starting latent variables are obtained heuristically,
>> ? ? ? ? ? if ?FALSE? then they are sampled from a Z-distribution
>>
>
> ?It depends a bit on what your computational issues are. ?It would
> probably be _better_ to use multiple starting points, but if you are
> sure you have no problem with burn-in then you can start all the chains
> at the same points and rely on the different random-number seeds to allow
> the chains to explore parameter space independently. ?(Using multiple
> starting points would would also allow you to use the Gelman-Rubin
> diagnostic to assess convergence.)
> ? I would do some experiments with MCMCglmm to ensure that you know
> how random seeds work with it (i.e. that you get identical answers
> if and only if random seeds are set the same). ?You may also want/need
> to look at some of the comments in the high performance task view about
> random number streams for parallel computation.
>
>
> to look into
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From katarzyna.kulma at ebc.uu.se  Fri Jun 15 09:42:53 2012
From: katarzyna.kulma at ebc.uu.se (Katarzyna Kulma)
Date: Fri, 15 Jun 2012 09:42:53 +0200
Subject: [R-sig-ME] 0-inflated GLMM in R
Message-ID: <20120615094253.60974byygm8ldmd9@webmail.uu.se>

Hello ADMB-users!

I'm new to glmmADMB and I just can't get it going. I'm trying to run the model

m1<-glmmadmb(rec~INFECTION*bin.age*ld+(1|RINGNO)+(1|year),zeroInflation=TRUE,family="poisson")

where rec is a number of chicks recruited to the population a year
after they fledged (heavily 0-inflated); INFECTION = a malaria
infection status, 1=infected, 0=uninfected; bin.age=binomial age of
parents (yearling, or older); ld-lay date, a covariate. The ring
number and the year are random effects. Yet, when I run this model on  
Mac OX 10.5.8 (R version 2.15) I receive a following message:

Error in parse(text = lab) : object 'lab' not found

In addition: Warning messages:
1: In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
2: In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'

When I run it on Windows XP (R version 2.15), then I get this:

Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
   number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(rec ~ INFECTION * bin.age * ld + (1 | RINGNO) + (1 |  :
   NAs removed in constructing fixed-effect model frame: you should  
probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
   longer object length is not a multiple of shorter object length


I receive these messages when I run the model in both, the most recent
version of glmmADMB or the older one (0.7). Does anyone have any
idea what is going on here? When I posted this question on ADMB-Users  
mailing list, Dave Fourier suggested that it is probably an R issue  
and encouraged me to post this message here. If there's no way I can  
run ADMB, is there any other way I can run 0-inflated mixed models in  
R? I'll appreciate any piece of advice

best wishes,
Kasia


-- 
Katarzyna Kulma

PhD Student
Department of Ecology and Genetics
Institute of Ecology and Evolution/Animal Ecology
Uppsala University
Norbyv?gen 18D
SE-752 36 Uppsala, Sweden

email: katarzyna.kulma at ebc.uu.se
Tel.+46 (0)18 471 2672
Fax.+46 18 471 6484


From joeking1809 at yahoo.com  Fri Jun 15 14:20:28 2012
From: joeking1809 at yahoo.com (Joe King)
Date: Fri, 15 Jun 2012 05:20:28 -0700 (PDT)
Subject: [R-sig-ME] Bootstrapping glmer random effects
Message-ID: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>

Dear all

I am attempting to obtain a bootstrap confidence interval for the random effect in a simple (random intercept) model using glmer.

The problem I have is that the interval I obtain consistently does not contain the value I am trying to get an interval for ! For example I get the following output when I run glmer on the full data:

Generalized linear mixed model fit by the Laplace approximation
Formula: wg~ (1 | city)
? ?Data: dt
? ?AIC ? BIC logLik deviance
?10115 10131 ?-5056 ? ?10111
Random effects:
?Groups ? Name ? ? ? ?Variance Std.Dev.
?city(Intercept) ? ? ? 0.14155 ?0.37623
Number of obs: 19318, groups: city, 218

Fixed effects:
? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|) ??
(Intercept) -2.58566 ? ?0.04045 ?-63.93 ? <2e-16 ***

So I am trying to obtain the confidence interval for random effect variance : 0.14155. ?Yet, the confidence interval I got was ?0.2839343 , 0.3534999. Moreover, the value in every one of the bootstrap replicates is greater than 0.14155. For example, the output from glmer in the last replicate the last bootstrap replicate was

Generalized linear mixed model fit by the Laplace approximation
Formula: wg~ (1 | city)
? ?Data: sam
? ?AIC ? BIC logLik deviance
?10480 10496 ?-5238 ? ?10476
Random effects:
?Groups ? Name ? ? ? ?Variance Std.Dev.
?city(Intercept) ? ? 0.32769 ?0.57245
Number of obs: 19318, groups: city, 217

Fixed effects:
? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|) ??
(Intercept) -2.58779 ? ?0.05142 ?-50.33 ? <2e-16 ***

There are no missing data. This is the code I have used to obtain the interval:

for (i in 1:k) {
? ? sam <- dt[sample(nrow(dt), replace=T, size=nrow(dt)), ]
? ? m1<- glmer(wg~(1|city), data=sam, family=binomial) ??
? ? bs[i] <- VarCorr(m1)$city[1]
}
quantile(bs,c(0.025,0.975))

Could anyone suggest why this is happening, and what I might be able to do about it ?

Thank you
JK


From lbbb at iastate.edu  Fri Jun 15 15:50:10 2012
From: lbbb at iastate.edu (Bin Liu)
Date: Fri, 15 Jun 2012 09:50:10 -0400
Subject: [R-sig-ME] Mean separation test in lmer/glmer models
Message-ID: <CAHgGoCa8qgwYQUHV1ayCtpfH+-ehBt5k56rcasex9cdFDF9KKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120615/94cf15b2/attachment.pl>

From aghaynes at gmail.com  Fri Jun 15 16:50:45 2012
From: aghaynes at gmail.com (Alan Haynes)
Date: Fri, 15 Jun 2012 16:50:45 +0200
Subject: [R-sig-ME] Mean separation test in lmer/glmer models
In-Reply-To: <CAHgGoCa8qgwYQUHV1ayCtpfH+-ehBt5k56rcasex9cdFDF9KKA@mail.gmail.com>
References: <CAHgGoCa8qgwYQUHV1ayCtpfH+-ehBt5k56rcasex9cdFDF9KKA@mail.gmail.com>
Message-ID: <CAPdSD+7eZReZHZTn+sZR+b2fQNH5fd6P1u0aTO6JZE0R-dagaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120615/23a9fa9d/attachment.pl>

From thomas.houslay at stir.ac.uk  Fri Jun 15 17:32:02 2012
From: thomas.houslay at stir.ac.uk (Thomas Houslay)
Date: Fri, 15 Jun 2012 16:32:02 +0100
Subject: [R-sig-ME] MCMCglmm variance query
Message-ID: <1B8AD69721636A40A87E271479473D720165B6346911@EXCH2007.ad.stir.ac.uk>

Dear all,

I am using MCMCglmm to investigate genotype x environment interactions. I have a number of genetic lines, and two environments of interest; several individuals from each line were assigned to a single environment, and various characters were measured.

At the very simplest level, I just want to estimate the genetic correlation of a single character expressed in two different environments. The character I am using to get things going ('PE') fits a normal distribution, but I also have measurements which will require poisson / ZIpoisson once I?m a little more confident. I feel like this should be very straightforward, but I'm still having some problems.

I have used the ?us? variance function for the random effect of Line because I want to measure the covariance between measurements in L and H environments for each Line; ?idh? is used for the rcov term because no individual is measured in both environments. Envt  has two levels, 'L' and 'H'.

Here is my original model, with one of the various priors I tried using:

prior.3 <- list(R=list(V=diag(2),nu=0.002), G=list(G1=list(V=diag(2)*0.02,nu=3)))
model.1 <- MCMCglmm(PE~Envt-1, random=~us(Envt):Line, rcov=~idh(Envt):units, data=mydata, prior=prior.3, nitt=3550000, thin=500, burnin=50000, verbose=FALSE)

> summary(model.1)

 Iterations = 50001:3549501
 Thinning interval  = 500
 Sample size  = 7000 

 DIC: 1294.103 

 G-structure:  ~us(Envt):Line

         post.mean  l-95% CI u-95% CI eff.samp
H:H.Line     1.823  0.004461    8.528     7000
L:H.Line     1.687 -2.169747   11.880     7000
H:L.Line     1.687 -2.169747   11.880     7000
L:L.Line     2.738  0.003271   15.105     7000

 R-structure:  ~idh(Envt):units

        post.mean l-95% CI u-95% CI eff.samp
H.units     320.9    221.2    433.1     7000
L.units     288.4    201.9    383.3     7000

 Location effects: PE ~ Envt - 1 

           post.mean l-95% CI u-95% CI eff.samp  pMCMC    
EnvtH     47.02    42.74    51.36     7000 <1e-04 ***
EnvtL     46.59    42.52    50.50     7000 <1e-04 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

> posterior.mode(model.1$VCV)
     H:H.Line      L:H.Line      H:L.Line      L:L.Line       H.units       L.units 
-2.640172e-04  1.785168e-01  1.785168e-01 -1.828135e-03  3.201142e+02  2.699961e+02 


I think that this indicates that the variances are getting stuck at values close to zero...? I received similar results from all of the different priors which I used. 

Assuming this to be the case, I used the ever-excellent course notes and moved on to try parameter-expanded priors. I have tried various different forms (a couple of which I have given below), all of which give me similar results to that shown below:

## Parameter-expanded priors ##
## inverse-gamma prior for the variances with shape=scale=0.001
prior.parex.4 <- list(R=list(V=diag(2),nu=1.002), G=list(G1=list(V=diag(2),nu=2,alpha.mu=c(0,0),alpha.V=diag(2)*1000)))
## flat for the correlation from -1 to 1
prior.parex.5 <- list(R=list(V=diag(2)*1e-6, nu=3), G=list(G1=list(V=diag(2),nu=2,alpha.mu=c(0,0),alpha.V=diag(2)*1000)))

## Model using prior.parex.5
model.px <- MCMCglmm(PE~Envt-1, random=~us(Envt):Line, rcov=~idh(Envt):units, data=mydata, prior=prior.parex.5, nitt=5050000, thin=500, burnin=5000, verbose=FALSE)

> summary(model.px)

 Iterations = 50001:5049501
 Thinning interval  = 500
 Sample size  = 10000 

 DIC: 1285.159 

 G-structure:  ~us(Envt):Line

         post.mean   l-95% CI u-95% CI eff.samp
H:H.Line     56.43  1.114e-06    182.4    10000
L:H.Line     26.43 -3.325e+01    108.0    10000
H:L.Line     26.43 -3.325e+01    108.0    10000
L:L.Line     88.10  1.459e-04    237.7     9586

 R-structure:  ~idh(Envt):units

        post.mean l-95% CI u-95% CI eff.samp
H.units     286.2    192.0    386.2    10000
L.units     237.3    164.1    316.9    11141

 Location effects: PE ~ Envt - 1 

           post.mean l-95% CI u-95% CI eff.samp  pMCMC    
EnvtH     46.33    39.91    52.92     9222 <1e-04 ***
EnvtL     44.15    36.73    51.31    10000 <1e-04 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

The means of the variance components look more reasonable from the summary than they did in previous models, but the posterior modes seem a bit strange:

> posterior.mode(model.px$VCV)
   H:H.Line    L:H.Line    H:L.Line    L:L.Line     H.units     L.units 
  0.9244938   1.4572214   1.4572214  31.2085852 257.8094014 239.5498357 

This is also having a large effect on calculating heritability of the character in each environment, as L heritability is around 100 times that of H.

I feel as if the parameter-expanded terms are headed more in the right direction, but I don't really know where to go next, and maybe there?s something obvious I?m missing here. If anyone has any ideas, I?d be extremely grateful! 

If there is anything else I should include in order to get some help then please let me know...

Thanks,

Tom


-- 
The University of Stirling is ranked in the top 50 in the world in The Times Higher Education 100 Under 50 table, which ranks the world's best 100 universities under 50 years old.
The University of Stirling is a charity registered in Scotland, 
 number SC 011159.


From datkins at u.washington.edu  Fri Jun 15 17:45:29 2012
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 15 Jun 2012 08:45:29 -0700
Subject: [R-sig-ME] 0-inflated GLMM in R
In-Reply-To: <20120615094253.60974byygm8ldmd9@webmail.uu.se>
References: <20120615094253.60974byygm8ldmd9@webmail.uu.se>
Message-ID: <4FDB5899.1050509@u.washington.edu>


Kasia--

Not sure about the glmmADMB issues (though suspect Ben Bolker may be 
able to help).  It is possible to fit zero-inflated (and related) models 
via MCMCglmm package.  We wrote a tutorial article on mixed models for 
count regression that includes R code (including MCMCglmm for 
zero-inflated models), which you can find:

http://depts.washington.edu/cshrb/newweb/statstutorials.html

[Second to last ms]

Hope that helps.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)


From bbolker at gmail.com  Sat Jun 16 09:53:23 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Jun 2012 07:53:23 +0000 (UTC)
Subject: [R-sig-ME] 0-inflated GLMM in R
References: <20120615094253.60974byygm8ldmd9@webmail.uu.se>
Message-ID: <loom.20120616T093719-587@post.gmane.org>

Katarzyna Kulma <katarzyna.kulma at ...> writes:

> 
> Hello ADMB-users!
 
> I'm new to glmmADMB and I just can't get it going. I'm trying to run
>  the model
 
> m1<-glmmadmb(rec~INFECTION*bin.age*ld+(1|RINGNO)+(1|year),
>  zeroInflation=TRUE,family="poisson")
> 
> where rec is a number of chicks recruited to the population a year
> after they fledged (heavily 0-inflated); INFECTION = a malaria
> infection status, 1=infected, 0=uninfected; bin.age=binomial age of
> parents (yearling, or older); ld-lay date, a covariate. The ring
> number and the year are random effects. Yet, when I run this model on  
> Mac OX 10.5.8 (R version 2.15) I receive a following message:
> 
> Error in parse(text = lab) : object 'lab' not found
> 
> In addition: Warning messages:
> 1: In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
> 2: In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
> 
> When I run it on Windows XP (R version 2.15), then I get this:
> 
> Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
>    number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: In glmmadmb(rec ~ INFECTION * bin.age * ld + (1 | RINGNO) + (1 |  :
>    NAs removed in constructing fixed-effect model frame: you should  
> probably remove them manually, e.g. with na.omit()
> 2: In II[, ii] + REmat$codes[[i]] :
>    longer object length is not a multiple of shorter object length
> 
> I receive these messages when I run the model in both, the most recent
> version of glmmADMB or the older one (0.7). Does anyone have any
> idea what is going on here? When I posted this question on ADMB-Users  
> mailing list, Dave Fourier suggested that it is probably an R issue  
> and encouraged me to post this message here. If there's no way I can  
> run ADMB, is there any other way I can run 0-inflated mixed models in  
> R? I'll appreciate any piece of advice

  I think the problem may be that you are not passing your data
to glmmADMB as a data frame.  This format is not supposed to
be required, but I haven't tested the alternative case (where
the variables are simply located in the global workspace) very
carefully, so there may be problems.

  Also note the error message on Windows, which tells you that
you should probably remove NA values from your data set before
proceeding.

  Can you give the results of sessionInfo() ?  Are you using version
0.7.2.12 from r-forge?


From pdxgary163 at gmail.com  Sat Jun 16 18:56:19 2012
From: pdxgary163 at gmail.com (Gary Dong)
Date: Sat, 16 Jun 2012 09:56:19 -0700
Subject: [R-sig-ME] spatial correlation structure in nlme
Message-ID: <CAEVDvzUs1anspTFF+Y+FxXY0qtkEMb6-V4MQb8mFBLUOHEdk7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120616/939d196c/attachment.pl>

From David.Duffy at qimr.edu.au  Sun Jun 17 01:47:41 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sun, 17 Jun 2012 09:47:41 +1000 (EST)
Subject: [R-sig-ME] Bootstrapping glmer random effects
In-Reply-To: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
References: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
Message-ID: <Pine.LNX.4.64.1206170915370.32392@orpheus.qimr.edu.au>

On Fri, 15 Jun 2012, Joe King wrote:

> Dear all
>
> I am attempting to obtain a bootstrap confidence interval for the random 
> effect in a simple (random intercept) model using glmer.
>
> The problem I have is that the interval I obtain consistently does not 
> contain the value I am trying to get an interval for !
>
> There are no missing data. This is the code I have used to obtain the interval:
>
> for (i in 1:k) {
>   sam <- dt[sample(nrow(dt), replace=T, size=nrow(dt)), ]
>   m1<- glmer(wg~(1|city), data=sam, family=binomial)
>   bs[i] <- VarCorr(m1)$city[1]
> }
> quantile(bs,c(0.025,0.975))
>
> Could anyone suggest why this is happening, and what I might be able to do about it ?

Have a look at how it is done by glmmML's glmmboot (or by merboot).  Your 
resampling has to correctly mimic the mechanism by which your 
data are generated.  I liked Shao J, Tu D (1995): The jackknife and 
bootstrap.


From alinasiriamini at gmail.com  Sun Jun 17 05:27:56 2012
From: alinasiriamini at gmail.com (Ali Nasiri Amini)
Date: Sat, 16 Jun 2012 20:27:56 -0700
Subject: [R-sig-ME] Bootstrapping glmer random effects
In-Reply-To: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
References: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
Message-ID: <CABvqa3Ps+H-ZyrEV39Rci2Jxc6xdmYHT3gRDTVL+L+WXdrZaQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120616/4dafdd7b/attachment.pl>

From joeking1809 at yahoo.com  Sun Jun 17 12:37:31 2012
From: joeking1809 at yahoo.com (Joe King)
Date: Sun, 17 Jun 2012 03:37:31 -0700 (PDT)
Subject: [R-sig-ME] Bootstrapping glmer random effects
In-Reply-To: <CABvqa3Ps+H-ZyrEV39Rci2Jxc6xdmYHT3gRDTVL+L+WXdrZaQA@mail.gmail.com>
References: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
	<CABvqa3Ps+H-ZyrEV39Rci2Jxc6xdmYHT3gRDTVL+L+WXdrZaQA@mail.gmail.com>
Message-ID: <1339929451.51655.YahooMailNeo@web114504.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120617/c5360dd8/attachment.pl>

From cornelia at mcs.st-and.ac.uk  Sun Jun 17 13:12:06 2012
From: cornelia at mcs.st-and.ac.uk (Cornelia Oedekoven)
Date: Sun, 17 Jun 2012 12:12:06 +0100
Subject: [R-sig-ME] Bootstrapping glmer random effects
In-Reply-To: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
References: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
Message-ID: <1339931526.4fddbb866d64f@webmail.st-andrews.ac.uk>

Hi Joe,

I am not sure if I can give you good advice on this but I can try. What I
noticed about your outputs was that you had the same number of observations for
your analysis on the original data and for the last bootstrap output. The number
of cities varied only by 1. This looks like you used your individual
observations as the resampling unit. However, as one other responder has
mentioned already you should use cities as your resampling unit as you have
non-independence between observations within each city. When using city as the
resampling unit you need to include all observations from that city when a city
is picked. You need to also remember to rename your cities after picking them.
For example, if city1 is picked and has, say 4 observations you bring all 4
observations into your bootstrap data and call the city now city1_1 (for
example). Then, when city1 is picked again, bring all 4 observations into your
bootstrap data again and rename city1 to city1_2 for these 4 observations. The
reason you want to do that is that city is your grouping factor for the random
effect and you want to end up with the same number of different cities in your
bootstrap data as in your original data (218 - I believe). I hope this will
work. If you have questions about coding this up I might be able to help you.

Cheers, Cornelia



<>< <>< <>< <>< <>< <>< <><
Cornelia Oedekoven
CREEM
University of St Andrews
cornelia at mcs.st-and.ac.uk
www.creem.st-and.ac.uk
<>< <>< <>< <>< <>< <>< <><

The University of St Andrews is a charity registered in Scotland : No SC013532


Quoting Joe King <joeking1809 at yahoo.com>:

> Dear all
>
> I am attempting to obtain a bootstrap confidence interval for the random
> effect in a simple (random intercept) model using glmer.
>
> The problem I have is that the interval I obtain consistently does not
> contain the value I am trying to get an interval for ! For example I get the
> following output when I run glmer on the full data:
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: wg~ (1 | city)
> ? ?Data: dt
> ? ?AIC ? BIC logLik deviance
> ?10115 10131 ?-5056 ? ?10111
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?city(Intercept) ? ? ? 0.14155 ?0.37623
> Number of obs: 19318, groups: city, 218
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|) ??
> (Intercept) -2.58566 ? ?0.04045 ?-63.93 ? <2e-16 ***
>
> So I am trying to obtain the confidence interval for random effect variance :
> 0.14155. ?Yet, the confidence interval I got was ?0.2839343 , 0.3534999.
> Moreover, the value in every one of the bootstrap replicates is greater than
> 0.14155. For example, the output from glmer in the last replicate the last
> bootstrap replicate was
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: wg~ (1 | city)
> ? ?Data: sam
> ? ?AIC ? BIC logLik deviance
> ?10480 10496 ?-5238 ? ?10476
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?city(Intercept) ? ? 0.32769 ?0.57245
> Number of obs: 19318, groups: city, 217
>
> Fixed effects:
> ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|) ??
> (Intercept) -2.58779 ? ?0.05142 ?-50.33 ? <2e-16 ***
>
> There are no missing data. This is the code I have used to obtain the
> interval:
>
> for (i in 1:k) {
> ? ? sam <- dt[sample(nrow(dt), replace=T, size=nrow(dt)), ]
> ? ? m1<- glmer(wg~(1|city), data=sam, family=binomial) ??
> ? ? bs[i] <- VarCorr(m1)$city[1]
> }
> quantile(bs,c(0.025,0.975))
>
> Could anyone suggest why this is happening, and what I might be able to do
> about it ?
>
> Thank you
> JK
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


------------------------------------------------------------------
University of St Andrews Webmail: https://webmail.st-andrews.ac.uk


From joeking1809 at yahoo.com  Sun Jun 17 23:35:34 2012
From: joeking1809 at yahoo.com (Joe King)
Date: Sun, 17 Jun 2012 14:35:34 -0700 (PDT)
Subject: [R-sig-ME] Bootstrapping glmer random effects
In-Reply-To: <1339931526.4fddbb866d64f@webmail.st-andrews.ac.uk>
References: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
	<1339931526.4fddbb866d64f@webmail.st-andrews.ac.uk>
Message-ID: <1339968934.42081.YahooMailNeo@web114506.mail.gq1.yahoo.com>

Hi Cornelia 


Thanks for your reply. I understand my mistake with sampling from the lower level units.

However I didn't quite understand your point about renaming ? 


From what I understand, I need to
1. Sample, with replacement, from the cities in the data - put these in a new vector.

2. For each item (city) in this new vector, then sample, with replacement, from the data for which all observations are for that item.


Am I missing something ?

Thanks again
JK



----- Original Message -----
From: Cornelia Oedekoven <cornelia at mcs.st-and.ac.uk>
To: Joe King <joeking1809 at yahoo.com>
Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Sent: Sunday, June 17, 2012 12:12 PM
Subject: Re: [R-sig-ME] Bootstrapping glmer random effects

Hi Joe,

I am not sure if I can give you good advice on this but I can try. What I
noticed about your outputs was that you had the same number of observations for
your analysis on the original data and for the last bootstrap output. The number
of cities varied only by 1. This looks like you used your individual
observations as the resampling unit. However, as one other responder has
mentioned already you should use cities as your resampling unit as you have
non-independence between observations within each city. When using city as the
resampling unit you need to include all observations from that city when a city
is picked. You need to also remember to rename your cities after picking them.
For example, if city1 is picked and has, say 4 observations you bring all 4
observations into your bootstrap data and call the city now city1_1 (for
example). Then, when city1 is picked again, bring all 4 observations into your
bootstrap data again and rename city1 to city1_2 for these 4 observations. The
reason you want to do that is that city is your grouping factor for the random
effect and you want to end up with the same number of different cities in your
bootstrap data as in your original data (218 - I believe). I hope this will
work. If you have questions about coding this up I might be able to help you.

Cheers, Cornelia



<>< <>< <>< <>< <>< <>< <><
Cornelia Oedekoven
CREEM
University of St Andrews
cornelia at mcs.st-and.ac.uk
www.creem.st-and.ac.uk
<>< <>< <>< <>< <>< <>< <><

The University of St Andrews is a charity registered in Scotland : No SC013532


Quoting Joe King <joeking1809 at yahoo.com>:

> Dear all
>
> I am attempting to obtain a bootstrap confidence interval for the random
> effect in a simple (random intercept) model using glmer.
>
> The problem I have is that the interval I obtain consistently does not
> contain the value I am trying to get an interval for ! For example I get the
> following output when I run glmer on the full data:
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: wg~ (1 | city)
> ? ?Data: dt
> ? ?AIC ? BIC logLik deviance
> ?10115 10131 ?-5056 ? ?10111
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?city(Intercept) ? ? ? 0.14155 ?0.37623
> Number of obs: 19318, groups: city, 218
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|) ??
> (Intercept) -2.58566 ? ?0.04045 ?-63.93 ? <2e-16 ***
>
> So I am trying to obtain the confidence interval for random effect variance :
> 0.14155. ?Yet, the confidence interval I got was ?0.2839343 , 0.3534999.
> Moreover, the value in every one of the bootstrap replicates is greater than
> 0.14155. For example, the output from glmer in the last replicate the last
> bootstrap replicate was
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: wg~ (1 | city)
> ? ?Data: sam
> ? ?AIC ? BIC logLik deviance
> ?10480 10496 ?-5238 ? ?10476
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?city(Intercept) ? ? 0.32769 ?0.57245
> Number of obs: 19318, groups: city, 217
>
> Fixed effects:
> ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|) ??
> (Intercept) -2.58779 ? ?0.05142 ?-50.33 ? <2e-16 ***
>
> There are no missing data. This is the code I have used to obtain the
> interval:
>
> for (i in 1:k) {
> ? ? sam <- dt[sample(nrow(dt), replace=T, size=nrow(dt)), ]
> ? ? m1<- glmer(wg~(1|city), data=sam, family=binomial) ??
> ? ? bs[i] <- VarCorr(m1)$city[1]
> }
> quantile(bs,c(0.025,0.975))
>
> Could anyone suggest why this is happening, and what I might be able to do
> about it ?
>
> Thank you
> JK
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


------------------------------------------------------------------
University of St Andrews Webmail: https://webmail.st-andrews.ac.uk


From spatrick at cebc.cnrs.fr  Mon Jun 18 10:29:07 2012
From: spatrick at cebc.cnrs.fr (Samantha Patrick)
Date: Mon, 18 Jun 2012 10:29:07 +0200
Subject: [R-sig-ME] Extract a variance estimate per level of random effect
Message-ID: <4FDEE6D3.2070301@cebc.cnrs.fr>

Hi

I am currently trying to estimate how consistent individuals are in a 
trait.  I want to produce an estimate of the variability for each level 
of a random effect (ID).  I can do this simply by calculation the 
variance for each ID separately but I am trying to extract this 
information from a mixed model (either in lmer or mcmcglmm).  I have 
trawled the mailing list but can not find any answers.

As an simplified dummy example I have 2 individuals, each with 5 
observations of a trait.  I can calculate 2 variances, using the 5 
observations for each individual.

head(Data)
ID    trait1
1        10
1        15
1        12
1        19
1        11
2        9
2        10
2        9
2        10
2        10

Variance for 1 = 4.67
Variance for 2 = 0.3

Alternatively I can fit a model of:

model1<-lmer(trait1 ~(1|ID))

 From the variance covariance matrix I can easily extract the between 
and within group variances, but is there a way to extract individual 
variance estimates?

Many Thanks

Sam

-- 

Dr Samantha Patrick
Post Doctoral Fellow
Centre d'Etudes Biologiques de Chiz? - CNRS
79360 Villiers-en-Bois
France
T:+33 549 097 846
M:+33 675 603 451
Skype: sammy_patrick
http://www.cebc.cnrs.fr/Fidentite/patrick/patrick.htm
http://www.researchgate.net/profile/Samantha_Patrick/


From lborger at cebc.cnrs.fr  Mon Jun 18 10:37:59 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Mon, 18 Jun 2012 10:37:59 +0200
Subject: [R-sig-ME] spatial correlation structure in nlme
In-Reply-To: <CAEVDvzUs1anspTFF+Y+FxXY0qtkEMb6-V4MQb8mFBLUOHEdk7Q@mail.gmail.com>
References: <CAEVDvzUs1anspTFF+Y+FxXY0qtkEMb6-V4MQb8mFBLUOHEdk7Q@mail.gmail.com>
Message-ID: <4FDEE8E7.7090809@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120618/4c5aa863/attachment.pl>

From writetoajhere at gmail.com  Mon Jun 18 10:47:02 2012
From: writetoajhere at gmail.com (Alecia Carter)
Date: Mon, 18 Jun 2012 09:47:02 +0100
Subject: [R-sig-ME] Extract a variance estimate per level of random
	effect
In-Reply-To: <4FDEE6D3.2070301@cebc.cnrs.fr>
References: <4FDEE6D3.2070301@cebc.cnrs.fr>
Message-ID: <CAMh=Adyt-E122uJ32RvSq8rirPj20DT7ysy97idxVOUprXSs-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120618/f987bfd3/attachment.pl>

From lborger at cebc.cnrs.fr  Mon Jun 18 11:06:06 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Mon, 18 Jun 2012 11:06:06 +0200
Subject: [R-sig-ME] Extract a variance estimate per level of random
	effect
In-Reply-To: <4FDEE6D3.2070301@cebc.cnrs.fr>
References: <4FDEE6D3.2070301@cebc.cnrs.fr>
Message-ID: <4FDEEF7E.9020609@cebc.cnrs.fr>

Hello,

I think there have been some recent papers on estimating individual 
variability in behaviour, but in any case is this useful?:

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
str(ranef(fm1, postVar = TRUE))
attr((ranef(fm1, postVar = TRUE))[[1]],"postVar")


HTH
Luca









# Forthcoming book chapter
# Dispersal Ecology and Evolution (ch. 17)
# http://ukcatalogue.oup.com/product/9780199608904.do
---------------------------------------------------------------------
Luca Borger
Postdoctoral Research Fellow
Centre d'Etudes Biologiques de Chiz?
CNRS (UPR1934); INRA (USC1339)
79360 Villiers-en-Bois, France

Tel: +33 (0)549 09 96 13
Fax: +33 (0)549 09 65 26
email: lborger at cebc.cnrs.fr
Web: http://cnrs.academia.edu/LucaBorger
Researcher ID: http://www.researcherid.com/rid/C-6003-2008
Google Scholar: http://scholar.google.com/citations?user=D5CTvNUAAAAJ
---------------------------------------------------------------------
# Newly published! Animal Migration: A synthesis (ch. 8):
# http://ukcatalogue.oup.com/product/9780199568994.do

Le 18/06/2012 10:29, Samantha Patrick a ?crit :
> Hi
>
> I am currently trying to estimate how consistent individuals are in a 
> trait.  I want to produce an estimate of the variability for each 
> level of a random effect (ID).  I can do this simply by calculation 
> the variance for each ID separately but I am trying to extract this 
> information from a mixed model (either in lmer or mcmcglmm).  I have 
> trawled the mailing list but can not find any answers.
>
> As an simplified dummy example I have 2 individuals, each with 5 
> observations of a trait.  I can calculate 2 variances, using the 5 
> observations for each individual.
>
> head(Data)
> ID    trait1
> 1        10
> 1        15
> 1        12
> 1        19
> 1        11
> 2        9
> 2        10
> 2        9
> 2        10
> 2        10
>
> Variance for 1 = 4.67
> Variance for 2 = 0.3
>
> Alternatively I can fit a model of:
>
> model1<-lmer(trait1 ~(1|ID))
>
> From the variance covariance matrix I can easily extract the between 
> and within group variances, but is there a way to extract individual 
> variance estimates?
>
> Many Thanks
>
> Sam
>


From aghaynes at gmail.com  Mon Jun 18 11:39:13 2012
From: aghaynes at gmail.com (Alan Haynes)
Date: Mon, 18 Jun 2012 11:39:13 +0200
Subject: [R-sig-ME] Extract a variance estimate per level of random
	effect
In-Reply-To: <4FDEEF7E.9020609@cebc.cnrs.fr>
References: <4FDEE6D3.2070301@cebc.cnrs.fr> <4FDEEF7E.9020609@cebc.cnrs.fr>
Message-ID: <CAPdSD+4G-yWF8Te8_9rdvYePWS+=-EHhJCzhq4d3KJnq_nx0VA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120618/0b72edc8/attachment.pl>

From lborger at cebc.cnrs.fr  Mon Jun 18 12:43:12 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Mon, 18 Jun 2012 12:43:12 +0200
Subject: [R-sig-ME] Extract a variance estimate per level of random
	effect
In-Reply-To: <CAPdSD+4G-yWF8Te8_9rdvYePWS+=-EHhJCzhq4d3KJnq_nx0VA@mail.gmail.com>
References: <4FDEE6D3.2070301@cebc.cnrs.fr> <4FDEEF7E.9020609@cebc.cnrs.fr>
	<CAPdSD+4G-yWF8Te8_9rdvYePWS+=-EHhJCzhq4d3KJnq_nx0VA@mail.gmail.com>
Message-ID: <4FDF0640.7010908@cebc.cnrs.fr>

 >Perhaps theres a way to get at the estimates it produces...

summary(myModel)$modelStruc$varStruc



Le 18/06/2012 11:39, Alan Haynes a ?crit :
> Hi there,
>
> If youre not fixed on either lmer or mcmcglmm particularly, ot might be
> possible using lme...
> Using the weights argument you can allow an individuals variance (in your
> case) to vary. Perhaps theres a way to get at the estimates it produces...
>
>
> HTH
>
> Alan
>
> --------------------------------------------------
> Email: aghaynes at gmail.com
> Mobile: +41794385586
> Skype: aghaynes
>
>
> On 18 June 2012 11:06, Luca Borger <lborger at cebc.cnrs.fr> wrote:
>
>> Hello,
>>
>> I think there have been some recent papers on estimating individual
>> variability in behaviour, but in any case is this useful?:
>>
>> library(lme4)
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> str(ranef(fm1, postVar = TRUE))
>> attr((ranef(fm1, postVar = TRUE))[[1]],"postVar")
>>
>>
>> HTH
>> Luca
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> # Forthcoming book chapter
>> # Dispersal Ecology and Evolution (ch. 17)
>> # http://ukcatalogue.oup.com/**product/9780199608904.do<http://ukcatalogue.oup.com/product/9780199608904.do>
>> ------------------------------**------------------------------**---------
>> Luca Borger
>> Postdoctoral Research Fellow
>>
>> Centre d'Etudes Biologiques de Chiz?
>> CNRS (UPR1934); INRA (USC1339)
>> 79360 Villiers-en-Bois, France
>>
>> Tel: +33 (0)549 09 96 13
>> Fax: +33 (0)549 09 65 26
>> email: lborger at cebc.cnrs.fr
>> Web: http://cnrs.academia.edu/**LucaBorger<http://cnrs.academia.edu/LucaBorger>
>> Researcher ID: http://www.researcherid.com/**rid/C-6003-2008<http://www.researcherid.com/rid/C-6003-2008>
>> Google Scholar: http://scholar.google.com/**citations?user=D5CTvNUAAAAJ<http://scholar.google.com/citations?user=D5CTvNUAAAAJ>
>> ------------------------------**------------------------------**---------
>> # Newly published! Animal Migration: A synthesis (ch. 8):
>> # http://ukcatalogue.oup.com/**product/9780199568994.do<http://ukcatalogue.oup.com/product/9780199568994.do>
>>
>> Le 18/06/2012 10:29, Samantha Patrick a ?crit :
>>
>>   Hi
>>>
>>> I am currently trying to estimate how consistent individuals are in a
>>> trait.  I want to produce an estimate of the variability for each level of
>>> a random effect (ID).  I can do this simply by calculation the variance for
>>> each ID separately but I am trying to extract this information from a mixed
>>> model (either in lmer or mcmcglmm).  I have trawled the mailing list but
>>> can not find any answers.
>>>
>>> As an simplified dummy example I have 2 individuals, each with 5
>>> observations of a trait.  I can calculate 2 variances, using the 5
>>> observations for each individual.
>>>
>>> head(Data)
>>> ID    trait1
>>> 1        10
>>> 1        15
>>> 1        12
>>> 1        19
>>> 1        11
>>> 2        9
>>> 2        10
>>> 2        9
>>> 2        10
>>> 2        10
>>>
>>> Variance for 1 = 4.67
>>> Variance for 2 = 0.3
>>>
>>> Alternatively I can fit a model of:
>>>
>>> model1<-lmer(trait1 ~(1|ID))
>>>
>>>  From the variance covariance matrix I can easily extract the between and
>>> within group variances, but is there a way to extract individual variance
>>> estimates?
>>>
>>> Many Thanks
>>>
>>> Sam
>>>
>>>
>> ______________________________**_________________
>> R-sig-mixed-models at r-project.**org <R-sig-mixed-models at r-project.org>mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>


From fbarbero at bariloche.inta.gov.ar  Mon Jun 18 13:31:16 2012
From: fbarbero at bariloche.inta.gov.ar (fernando barbero)
Date: Mon, 18 Jun 2012 08:31:16 -0300
Subject: [R-sig-ME] Mean separation test in lmer/glmer models
In-Reply-To: <CAHgGoCa8qgwYQUHV1ayCtpfH+-ehBt5k56rcasex9cdFDF9KKA@mail.gmail.com>
References: <CAHgGoCa8qgwYQUHV1ayCtpfH+-ehBt5k56rcasex9cdFDF9KKA@mail.gmail.com>
Message-ID: <003301cd4d45$dfb70c50$9f2524f0$@inta.gov.ar>

Try Multcomp package, 
Ferrnando

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Bin Liu
Enviado el: viernes, 15 de junio de 2012 10:50 a.m.
Para: R-sig-mixed-models at r-project.org
Asunto: [R-sig-ME] Mean separation test in lmer/glmer models

Hi All,

I will be dealing with agricultural experimental design data which has
response (like Yield) and categorical covariates. The covariates can be
water, air, Light and Nitrate (all treatments have multiple levels). The
design is a randomized complete block design with all combinations of
treatments in different blocks. Different combination may have different
sample size. We take the block factor as random and fit a linear mixed
model (or GLMM) using lmer() in R. Our goal is to find the best combination
of treatments which has the most yield, and some combinations which are
significant better than overall mean. My thought about this is using mean
separation test, or multiple comparisons (using adjustments: Bonferroni,
Scheffe, Tukey). I tried searching for a while in R but didn't get enough
information. So can anyone give me some suggestions on useful R functions,
or packages, or research papers which may handle this problem in mixed
effect models? If not available, methods in linear/generalized linear
models without random models may help me too. Thanks a lot in advance!

Regards,

-- 
Bin Liu

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----
Se certific? que el correo no contiene virus.
Comprobada por AVG - www.avg.es
Versi?n: 2012.0.2180 / Base de datos de virus: 2433/5076 - Fecha de la
versi?n: 17/06/2012


From idworkin at msu.edu  Mon Jun 18 15:33:35 2012
From: idworkin at msu.edu (Ian Dworkin)
Date: Mon, 18 Jun 2012 08:33:35 -0500
Subject: [R-sig-ME] Bootstrapping glmer random effects
In-Reply-To: <1339968934.42081.YahooMailNeo@web114506.mail.gq1.yahoo.com>
References: <1339762828.9973.YahooMailNeo@web114501.mail.gq1.yahoo.com>
	<1339931526.4fddbb866d64f@webmail.st-andrews.ac.uk>
	<1339968934.42081.YahooMailNeo@web114506.mail.gq1.yahoo.com>
Message-ID: <CAGudrjmDVM3hX5G9x7iuvc5RnQ-fkR8mWAiF8DS5QLrOZNMfxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120618/1b3e3ece/attachment.pl>

From laurent_step at yahoo.fr  Mon Jun 18 18:04:05 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Mon, 18 Jun 2012 17:04:05 +0100 (BST)
Subject: [R-sig-ME] Re :  Bayesian Inference on Variance Components
In-Reply-To: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
References: <831931A3FBC4454F8488C21952DE377228CA49FB@BL2PRD0210MB385.namprd02.prod.outlook.com>
Message-ID: <1340035445.76947.YahooMailNeo@web29502.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120618/fde87983/attachment.pl>

From laurent_step at yahoo.fr  Tue Jun 19 12:04:40 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Tue, 19 Jun 2012 11:04:40 +0100 (BST)
Subject: [R-sig-ME] how to get posterior simulations of the variance
	components with mcmcsamp() ?
Message-ID: <1340100280.24630.YahooMailNeo@web29504.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120619/f98b93b3/attachment.pl>

From Beatriz.DeFrancisco at sams.ac.uk  Tue Jun 19 13:01:49 2012
From: Beatriz.DeFrancisco at sams.ac.uk (Beatriz De Francisco)
Date: Tue, 19 Jun 2012 11:01:49 +0000
Subject: [R-sig-ME] Extract a variance estimate per level of random
	effect
Message-ID: <6B2C4C7276688144852E9630133C76BA5570B084@Verbiage2.sams.local>

Hi

If you are using lme() you can use the VarCorr() function to get the between and with-in variance for the random part of the model.
For a good explanation you can try http://plantecology.syr.edu/fridley/bio793/mixed1.html

Beatriz de Francisco Mora
PhD Student
The Scottish Association for Marine Science
Scottish Marine Institute
Oban
PA37 1QA
Tel: 06131 559000 (switchboard)
Fax: 01631559001
E. beatriz.defrancisco at sams.ac.uk
http://www.smi.ac.uk/beatriz-de-francisco


Message: 1
Date: Mon, 18 Jun 2012 12:43:12 +0200
From: Luca Borger <lborger at cebc.cnrs.fr>
To: Alan Haynes <aghaynes at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Extract a variance estimate per level of
        random  effect
Message-ID: <4FDF0640.7010908 at cebc.cnrs.fr>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

 >Perhaps theres a way to get at the estimates it produces...

summary(myModel)$modelStruc$varStruc



Le 18/06/2012 11:39, Alan Haynes a ?crit :
> Hi there,
>
> If youre not fixed on either lmer or mcmcglmm particularly, ot might be
> possible using lme...
> Using the weights argument you can allow an individuals variance (in your
> case) to vary. Perhaps theres a way to get at the estimates it produces...
>
>
> HTH
>
> Alan
>
> --------------------------------------------------
> Email: aghaynes at gmail.com
> Mobile: +41794385586
> Skype: aghaynes
>
>
> On 18 June 2012 11:06, Luca Borger <lborger at cebc.cnrs.fr> wrote:
>
>> Hello,
>>
>> I think there have been some recent papers on estimating individual
>> variability in behaviour, but in any case is this useful?:
>>
>> library(lme4)
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> str(ranef(fm1, postVar = TRUE))
>> attr((ranef(fm1, postVar = TRUE))[[1]],"postVar")
>>
>>
>> HTH
>> Luca
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> # Forthcoming book chapter
>> # Dispersal Ecology and Evolution (ch. 17)
>> # http://ukcatalogue.oup.com/**product/9780199608904.do<http://ukcatalogue.oup.com/product/9780199608904.do>
>> ------------------------------**------------------------------**---------
>> Luca Borger
>> Postdoctoral Research Fellow
>>
>> Centre d'Etudes Biologiques de Chiz?
>> CNRS (UPR1934); INRA (USC1339)
>> 79360 Villiers-en-Bois, France
>>
>> Tel: +33 (0)549 09 96 13
>> Fax: +33 (0)549 09 65 26
>> email: lborger at cebc.cnrs.fr
>> Web: http://cnrs.academia.edu/**LucaBorger<http://cnrs.academia.edu/LucaBorger>
>> Researcher ID: http://www.researcherid.com/**rid/C-6003-2008<http://www.researcherid.com/rid/C-6003-2008>
>> Google Scholar: http://scholar.google.com/**citations?user=D5CTvNUAAAAJ<http://scholar.google.com/citations?user=D5CTvNUAAAAJ>
>> ------------------------------**------------------------------**---------
>> # Newly published! Animal Migration: A synthesis (ch. 8):
>> # http://ukcatalogue.oup.com/**product/9780199568994.do<http://ukcatalogue.oup.com/product/9780199568994.do>
>>
>> Le 18/06/2012 10:29, Samantha Patrick a ?crit :
>>
>>   Hi
>>>
>>> I am currently trying to estimate how consistent individuals are in a
>>> trait.  I want to produce an estimate of the variability for each level of
>>> a random effect (ID).  I can do this simply by calculation the variance for
>>> each ID separately but I am trying to extract this information from a mixed
>>> model (either in lmer or mcmcglmm).  I have trawled the mailing list but
>>> can not find any answers.
>>>
>>> As an simplified dummy example I have 2 individuals, each with 5
>>> observations of a trait.  I can calculate 2 variances, using the 5
>>> observations for each individual.
>>>
>>> head(Data)
>>> ID    trait1
>>> 1        10
>>> 1        15
>>> 1        12
>>> 1        19
>>> 1        11
>>> 2        9
>>> 2        10
>>> 2        9
>>> 2        10
>>> 2        10
>>>
>>> Variance for 1 = 4.67
>>> Variance for 2 = 0.3
>>>
>>> Alternatively I can fit a model of:
>>>
>>> model1<-lmer(trait1 ~(1|ID))
>>>
>>>  From the variance covariance matrix I can easily extract the between and
>>> within group variances, but is there a way to extract individual variance
>>> estimates?
>>>
>>> Many Thanks
>>>
>>> Sam
>>>
>>>
>> ______________________________**_________________
>> R-sig-mixed-models at r-project.**org <R-sig-mixed-models at r-project.org>mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>
The Scottish Association for Marine Science (SAMS) is registered in Scotland as a Company Limited by Guarantee (SC009292) and is a registered charity (9206). SAMS has an actively trading wholly owned subsidiary company: SAMS Research Services Ltd a Limited Company (SC224404). All Companies in the group are registered in Scotland and share a registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The content of this message may contain personal views which are not the views of SAMS unless specifically stated. Please note that all email traffic is monitored for purposes of security and spam filtering. As such individual emails may be examined in more detail.


From spatrick at cebc.cnrs.fr  Tue Jun 19 15:33:57 2012
From: spatrick at cebc.cnrs.fr (Samantha Patrick)
Date: Tue, 19 Jun 2012 15:33:57 +0200
Subject: [R-sig-ME] Extract a variance estimate per level of random
	effect
In-Reply-To: <4FDF0640.7010908@cebc.cnrs.fr>
References: <4FDEE6D3.2070301@cebc.cnrs.fr> <4FDEEF7E.9020609@cebc.cnrs.fr>
	<CAPdSD+4G-yWF8Te8_9rdvYePWS+=-EHhJCzhq4d3KJnq_nx0VA@mail.gmail.com>
	<4FDF0640.7010908@cebc.cnrs.fr>
Message-ID: <4FE07FC5.5070105@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120619/b9b24fd9/attachment.pl>

From kegurney at alaska.edu  Wed Jun 20 03:29:09 2012
From: kegurney at alaska.edu (Kirsty E. B. Gurney)
Date: Tue, 19 Jun 2012 17:29:09 -0800
Subject: [R-sig-ME] Random effects in glmmADMB
Message-ID: <5E0E8A3CF6E749E08FE364019E0418D0@Wipflilatitude>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120619/e9722197/attachment.pl>

From jwiley.psych at gmail.com  Wed Jun 20 04:32:57 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 19 Jun 2012 19:32:57 -0700
Subject: [R-sig-ME] Random effects in glmmADMB
In-Reply-To: <5E0E8A3CF6E749E08FE364019E0418D0@Wipflilatitude>
References: <5E0E8A3CF6E749E08FE364019E0418D0@Wipflilatitude>
Message-ID: <CANz9Z_Kd5-=ekmAjworB_tX_nLC+EhTKea_VQADnP9KUr1kgFg@mail.gmail.com>

Hi Kirsty,

I believe you are just missing parentheses.  What happens when you try:

amphs_zinb_bionull<-glmmadmb(VCAmphCountI~Zone + BPeriod +(1|Site),
data=Amphs, zeroInflation=TRUE, family="nbinom")

You may find these two pages I wrote helpful.  They do not deal with
zero inflated negative binomial models specifically, but they do show
various random effect poisson models among others in R in both
glmmadmb and glmer (from lme4):

## mixed effects poisson using packages lme4 and glmmADMB with
corresponding SAS and Stata code
## may be helpful for translating between packages
http://www.ats.ucla.edu/stat/r/pages/mepoisson.htm

## linear mixed models and generalized linear mixed models
## primarily used to simulate a data set so models are not the focus
http://www.ats.ucla.edu/stat/r/pages/mesimulation.htm

It is a bit anathema to say on this list, but you likely could also do
what you want using proc nlmixed.  I have written an example of how to
write out your own model and log likelihood function for a zero
inflated poisson model with random effects in proc nlmixed here:

http://www.ats.ucla.edu/stat/sas/faq/zip_nlmixed.htm

you could extent this to negative binomial without too much work.

Finally, it may be that once you have zero inflation and random
effects, you no longer have over dispersion and a poisson may be
sufficient (i.e., the negative binomial may be overkill once you have
everything else done).  Just a thought you might check out.

Cheers and good luck!

Josh

On Tue, Jun 19, 2012 at 6:29 PM, Kirsty E. B. Gurney
<kegurney at alaska.edu> wrote:
> Good afternoon;
>
> I've previously had success using SAS to create generalized linear mixed models for data with a negative binomial distribution (count data of aquatic invertebrates). However, I've also recently confirmed that this data set is zero-inflated. To deal with the zero-inflation in the negative binomial distribution and maintain nested random effects (both basin and year, nested within site), I have tried to switch my models to R and use the glmmADMB package for a revised set of analyses..
>
> I seem to be having some problems with random effects parts of my models and am hoping that someone on this list may have been through a similar experience and be able to help.
>
> First I imported the data and ran a simplified version of the model with only fixed effects:
>
> amphs_zinb_simple<-glmmadmb(VCAmphCountI~Zone+BPeriod, data=Amphs, zeroInflation=TRUE, family="nbinom")
>
> This model ran with no apparent errors and results seemed feasible. Feeling confident that I knew what was going on, I then added one simple random effect to the model;
>
> amphs_zinb_bionull<-glmmadmb(VCAmphCountI~Zone + BPeriod +1|Site, data=Amphs, zeroInflation=TRUE, family="nbinom")
>
> Hmmm. This did not seem to go so well (see error & warning messages below). I have been through the raw data and can not find the NAs that are referred to, nor can I figure out why I get the warning message about the random factor (Site). Any insights or suggestions would be appreciated. ?I don't want to try and incorporate further random effects until I know what I am doing wrong...
>
> Error: dims [product 1979] do not match the length of object [0]
> In addition: Warning messages:
> 1: In Ops.factor(1 + 1, Site) : | not meaningful for factors
> 2: In glmmadmb(VCAmphCountI ~ 1 + 1 | Site, data = Amphs, zeroInflation = TRUE, ?:
> ?NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
> 3: In cbind(0, II[, -ncol(II)]) :
> ?number of rows of result is not a multiple of vector length (arg 1)
>
> Thanks in advance,
> kbg
>
> -~-~-~-
> Kirsty E. B. Gurney, Ph.D.
> Alaska Cooperative Fish and Wildlife Research Unit
> Institute of Arctic Biology
> 209 Irving 1 Building
> University of Alaska Fairbanks
> Fairbanks, AK 99775
> T: (907) 474 - 7738
> -~-~-~-
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From luciamartinaml at gmail.com  Wed Jun 20 13:52:02 2012
From: luciamartinaml at gmail.com (Lucia)
Date: Wed, 20 Jun 2012 12:52:02 +0100
Subject: [R-sig-ME] How to include autocorrelation in GLMM and what to
 do with false convergence warning message appearing after including an
 interaction term
In-Reply-To: <4FE1B8E6.4000607@gmail.com>
References: <4FE1B8E6.4000607@gmail.com>
Message-ID: <4FE1B962.2020500@gmail.com>


I will try to explain my data as good as possible.
> So we taged 13 different whales with a tag that records time, depth, 
> speed, angle of descent and ascent 25 samples every second.
> The normal diving behaviour of these animals is one deep dive of one 
> hour to 1200 meters followed by a series of 3-7 shallow dives of 20 
> minutes up to 300 m. Because the tag not always stays the same time in 
> each animal, my data is unbalanced and some tag records have one deep 
> dive and 6 shallow dives while other records have 7 deep dives and 26 
> shallow dives.
> I divided each dive in units of 30 seconds. for each unit I have the 
> next data:
> whale number, dive number, total number of fluke strokes in the 30 
> seconds unit of analysis, mean of the sin of the angle during the 30 
> seconds unit, swim speed, dive type(ascent or descent), dive 
> direction( if it is a descent or an ascent) and time since the start 
> of the dive and finally my variable response which is presence or 
> absence of one type of fluke stroke called stroke type B.
>
> I think there has to be some autocorrelation between each 30 seconds 
> unit of analyis and need to include it in my model but do not know how!
>
> I am interested to know what affects the presence or absence of the 
> type B stroke (which is a binomial variable with 0 and 1)
> so I decide to use a  binomial glmm with whale number as a random 
> effect. I included as well dive number within whale as a random effect.
>
> here is the model.
>
>
> glmm114<-lmer (StrokeB~ Time * 
> Depth+SINP+flukes*Depth+speed+(1|whale_number)+(0+dive_number|whale_number),data=Luciadeepas, 
> family = binomial)
>
> this is my final model after taking out the non significative 
> variables, the problem is that due to the interaction a problem 
> appears saying
>
> The false convergence warning message (8)
>
> I looked on internet and it says is a common problem, and some people 
> says that it doesnt make any change in the output while others says 
> that each variable has to be
> divided by 100. but when I do this then the variables that become 
> significant doesnt make any sense.
>
>
> Thanks so much in advanced
> Lucia


From lborger at cebc.cnrs.fr  Wed Jun 20 15:41:33 2012
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Wed, 20 Jun 2012 15:41:33 +0200
Subject: [R-sig-ME] How to include autocorrelation in GLMM and what to
 do with false convergence warning message appearing after including an
 interaction term
In-Reply-To: <4FE1B962.2020500@gmail.com>
References: <4FE1B8E6.4000607@gmail.com> <4FE1B962.2020500@gmail.com>
Message-ID: <4FE1D30D.1050408@cebc.cnrs.fr>

Hello,

 >false convergence warning message

standardising your covariates often helps - and improves the 
interpretability of the model results, too. e.g. see 
http://modelsforinsight.net/wp-content/uploads/2011/01/2010-Schielzeth.pdf

 >I think there has to be some autocorrelation between each 30 seconds 
unit of analyis and need to include it in my model but do not know how!

not straightfoward for GLMMs, see the GLMM wike page 
(http://glmm.wikidot.com/faq) under "Spatial and temporal correlation 
models, heteroscedasticity ("R-side" models)"


HTH

Cheers,
Luca







# Forthcoming book chapter
# Dispersal Ecology and Evolution (ch. 17)
# http://ukcatalogue.oup.com/product/9780199608904.do
---------------------------------------------------------------------
Luca Borger
Postdoctoral Research Fellow
Centre d'Etudes Biologiques de Chiz?
CNRS (UPR1934); INRA (USC1339)
79360 Villiers-en-Bois, France

Tel: +33 (0)549 09 96 13
Fax: +33 (0)549 09 65 26
email: lborger at cebc.cnrs.fr
Web: http://www.cebc.cnrs.fr/Fidentite/borger/borger.htm
      http://cnrs.academia.edu/LucaBorger
Researcher ID: http://www.researcherid.com/rid/C-6003-2008
Google Scholar: http://scholar.google.com/citations?user=D5CTvNUAAAAJ
---------------------------------------------------------------------
# Newly published! Animal Migration: A synthesis (ch. 8):
# http://ukcatalogue.oup.com/product/9780199568994.do

Le 20/06/2012 13:52, Lucia a ?crit :
>
> I will try to explain my data as good as possible.
>> So we taged 13 different whales with a tag that records time, depth, 
>> speed, angle of descent and ascent 25 samples every second.
>> The normal diving behaviour of these animals is one deep dive of one 
>> hour to 1200 meters followed by a series of 3-7 shallow dives of 20 
>> minutes up to 300 m. Because the tag not always stays the same time 
>> in each animal, my data is unbalanced and some tag records have one 
>> deep dive and 6 shallow dives while other records have 7 deep dives 
>> and 26 shallow dives.
>> I divided each dive in units of 30 seconds. for each unit I have the 
>> next data:
>> whale number, dive number, total number of fluke strokes in the 30 
>> seconds unit of analysis, mean of the sin of the angle during the 30 
>> seconds unit, swim speed, dive type(ascent or descent), dive 
>> direction( if it is a descent or an ascent) and time since the start 
>> of the dive and finally my variable response which is presence or 
>> absence of one type of fluke stroke called stroke type B.
>>
>> I think there has to be some autocorrelation between each 30 seconds 
>> unit of analyis and need to include it in my model but do not know how!
>>
>> I am interested to know what affects the presence or absence of the 
>> type B stroke (which is a binomial variable with 0 and 1)
>> so I decide to use a  binomial glmm with whale number as a random 
>> effect. I included as well dive number within whale as a random effect.
>>
>> here is the model.
>>
>>
>> glmm114<-lmer (StrokeB~ Time * 
>> Depth+SINP+flukes*Depth+speed+(1|whale_number)+(0+dive_number|whale_number),data=Luciadeepas, 
>> family = binomial)
>>
>> this is my final model after taking out the non significative 
>> variables, the problem is that due to the interaction a problem 
>> appears saying
>>
>> The false convergence warning message (8)
>>
>> I looked on internet and it says is a common problem, and some people 
>> says that it doesnt make any change in the output while others says 
>> that each variable has to be
>> divided by 100. but when I do this then the variables that become 
>> significant doesnt make any sense.
>>
>>
>> Thanks so much in advanced
>> Lucia
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From luciamartinaml at gmail.com  Wed Jun 20 13:49:58 2012
From: luciamartinaml at gmail.com (Lucia)
Date: Wed, 20 Jun 2012 12:49:58 +0100
Subject: [R-sig-ME] How to include autocorrelation in GLMM and what to do
 with false convergence warning message appearing after including an
 interaction term
Message-ID: <4FE1B8E6.4000607@gmail.com>

I will try to explain my data as good as possible.
So we taged 13 different whales with a tag that records time, depth, 
speed, angle of descent and ascent 25 samples every second.
The normal diving behaviour of these animals is one deep dive of one 
hour to 1200 meters followed by a series of 3-7 shallow dives of 20 
minutes up to 300 m. Because the tag not always stays the same time in 
each animal, my data is unbalanced and some tag records have one deep 
dive and 6 shallow dives while other records have 7 deep dives and 26 
shallow dives.
I divided each dive in units of 30 seconds. for each unit I have the 
next data:
whale number, dive number, total number of fluke strokes in the 30 
seconds unit of analysis, mean of the sin of the angle during the 30 
seconds unit, swim speed, dive type(ascent or descent), dive direction( 
if it is a descent or an ascent) and time since the start of the dive 
and finally my variable response which is presence or absence of one 
type of fluke stroke called stroke type B.

I think there has to be some autocorrelation between each 30 seconds 
unit of analyis and need to include it in my model but do not know how!

I am interested to know what affects the presence or absence of the type 
B stroke (which is a binomial variable with 0 and 1)
so I decide to use a  binomial glmm with whale number as a random 
effect. I included as well dive number within whale as a random effect.

here is the model.


glmm114<-lmer (StrokeB~ Time * 
Depth+SINP+flukes*Depth+speed+(1|whale_number)+(0+dive_number|whale_number),data=Luciadeepas, 
family = binomial)

this is my final model after taking out the non significative variables, 
the problem is that due to the interaction a problem appears saying

The false convergence warning message (8)

I looked on internet and it says is a common problem, and some people 
says that it doesnt make any change in the output while others says that 
each variable has to be
divided by 100. but when I do this then the variables that become 
significant doesnt make any sense.


Thanks so much in advanced
Lucia


From jmwojdak at RADFORD.EDU  Wed Jun 20 16:56:43 2012
From: jmwojdak at RADFORD.EDU (Wojdak, Jeremy)
Date: Wed, 20 Jun 2012 10:56:43 -0400
Subject: [R-sig-ME] binomial GLMM with small upper limit
Message-ID: <71247479631715408F1886722FA393A8A9CF47E834@MLEXCM01.RADFORD.EDU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120620/9eb6c8ee/attachment.pl>

From jenn.s.barrett at gmail.com  Thu Jun 21 00:32:38 2012
From: jenn.s.barrett at gmail.com (Jennifer Barrett)
Date: Wed, 20 Jun 2012 15:32:38 -0700
Subject: [R-sig-ME] Zero-inflated mixed effects model - clarification of
 zeros modeled and R package questions
Message-ID: <CAEbqvwo7a+hOLPcZ1BKUerSir+Xwcczk3AY5CeFbc80woLeM3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120620/3ea1b541/attachment.pl>

From David.Duffy at qimr.edu.au  Thu Jun 21 01:00:03 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 21 Jun 2012 09:00:03 +1000 (EST)
Subject: [R-sig-ME] binomial GLMM with small upper limit
In-Reply-To: <71247479631715408F1886722FA393A8A9CF47E834@MLEXCM01.RADFORD.EDU>
References: <71247479631715408F1886722FA393A8A9CF47E834@MLEXCM01.RADFORD.EDU>
Message-ID: <Pine.LNX.4.64.1206210852080.26207@orpheus.qimr.edu.au>

On Wed, 20 Jun 2012, Wojdak, Jeremy wrote:

> I am working with mortality data - the number of three animals per 
> experimental unit that had died by week 1, week2, ... during an 
> experiment.  So, I am using a binomial GLMM approach to model 
> proportions with a random effect to deal with the repeated measurements 
> from the same exp. unit.  (Specifically, I use the experimental unit or 
> "Tank" as the random effect, since multiple observations from the same 
> unit must be related... and there were temporal/spatial blocks, so each 
> tank is nested within a block.  I include sample "Day" as a fixed effect 
> in the model)
>
> sm7<-glmer(predc.survtbl~predator*Day +(1|Block/Tank), 
> family="binomial", data=predc2)

Does your riskset size change by Day in predc.survtbl?

> All is well, except the model suggests there are no treatment or time 
> effects, while graphical inspection suggests there may be both.

So a naive survival analysis (ignoring Tank etc) is significant?  You
might try the coxme package...


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From highstat at highstat.com  Thu Jun 21 01:32:36 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 21 Jun 2012 00:32:36 +0100
Subject: [R-sig-ME] Zero-inflated mixed effects model - clarification,
 of zeros modeled and R package questions
In-Reply-To: <mailman.1544.1340231571.4567.r-sig-mixed-models@r-project.org>
References: <mailman.1544.1340231571.4567.r-sig-mixed-models@r-project.org>
Message-ID: <4FE25D94.1090808@highstat.com>






------------------------------

Message: 5
Date: Wed, 20 Jun 2012 15:32:38 -0700
From: Jennifer Barrett <jenn.s.barrett at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Zero-inflated mixed effects model - clarification
	of zeros modeled and R package questions
Message-ID:
	<CAEbqvwo7a+hOLPcZ1BKUerSir+Xwcczk3AY5CeFbc80woLeM3A at mail.gmail.com>
Content-Type: text/plain

Hi folks,


I?m looking for some guidance in regards to zero-inflated models with
repeated measures (i.e., random effect for site). My first question is more
of a statistical one, while the second is related to R packages. Apologies
for the long post; however, I want to make sure my concerns/questions are
clear!


Our project and dataset:


- The aim of our project is to 1) examine associations between shoreline
habitat characteristics and the abundance of several shorebird species; and
2) estimate the total abundance of each shorebird species within the entire
study region based on the models from 1) above, with confidence intervals.
Note that we will be using an information theoretic approach for 1) above,
and would like to use MMI for 2).

- Our response dataset consists of counts of shorebirds at >150 coastal
sites, conducted on the second Sunday of each month between the months of



AFZ: No spatial correlation between sites?




Oct-March, over 10 years; however, not every site was surveyed in all
months (we?ve limited our dataset to those with a minimum of 3 counts in a
year).  Our response variable is thus the number of birds counted in a
given month/year at a given site. Note that we plan to model each year
separately.

-  The habitat dataset consists of shoreline units within our entire study
region, with each unit characterized by exposure, substrate type...etc.
Using GIS, we?ve measured the length of shoreline belonging to shoreline
categories (e.g., sand, rock, mud) within each survey site, the average
exposure for the site, and other continuous attributes, as well as one
presence/absence covariate.

- Initial exploratory analysis has shown that the counts are zero-inflated.
While there may be some false zeros in our dataset (i.e., observer error),
the source of the zero-inflation is likely preference of shorebirds for
particular sites with particular features and avoidance of others (i.e.,
true zeros or ?structural zeros?). Some zeros likely also arise because the
species does not saturate its habitat (i.e., habitat suitable, but
unoccupied ? also a ?true? zero), though again, the majority of the zeros
are likely structural.


Onto my questions:


1) I?ve been reading through the literature to decide what type of model
would best be suited for our dataset and questions. While all articles seem
to agree that the choice of a model needs to consider the source of excess
zeros, they seem to contradict one another in regards to what zeros are
being modeled in each component of a zero-inflated mixture model. Note that
I am not considering a two-part (i.e., conditional) model, because I do not
believe that all zeros arise from the occupancy process (as per Joseph et
al. 2009 and as noted above, zero abundance can occur by chance in our
system). Examples:


- Martin et al. (2005) state that when zero inflation is due to true zeros,
two-part or mixture models (ZIP or ZINB) are recommended, and that when
zero inflation is due to false zeros, a ZIB mixture model is recommended;
however, when zero inflation is due to both excess true and false zeros, a
Bayesian framework may be used, though there is no formal discussion in the
literature. NOTE: Since this article was published, Royle?s N-mixture model
has addressed this issue; however, I cannot use this approach as my data do
not meet the assumption of a closed population during the study period.

- In contrast to Martin et al. (2005), Potts and Elith (2006) state that
the zero-inflated mixture model structure implies that zero observations
arising from the zero process are true negative observations, and that
those arising from the Poisson process are false negative observations ?that
is, the habitat is suitable, but unoccupied? (p.155). However, on the
previous page, they defined false negative as ?attributable to experimental
design
 or observer error?, and habitat that is ?suitable, but unoccupied?
as a true negative, so I'm not sure which type of zero observation they are
really referring to here for the Poisson process.

- In contrast to both sources above, Zuur et al. (2009) state that in a ZIP
or ZINB, zeros are modeled as coming from two processes ? the binomial
process, which models only false zeros (observer, design, and survey error)
and the Poisson (or Negbin) process  which models the true zeros and
counts. This is the opposite of what was stated by Potts and Elith.



AFZ: It doesn't read that contrasting..:-). The definition of true and false zeros will
change depending on the data sets and questions. In one setting a true zero could be a
false zero, and vice versa.



- Finally, I?ve read other sources which state that ZIPs simply treat the
population as a mixture, with one set of subjects having a zero response ?
in other words, there is no mention of whether the zero process is modeling
the ?true? or ?false? zeros.


AFZ: True. See the discussion in the Epilogue of our 2012 book:
Zero Inflated Models and Generalized Linear Mixed Models with R. (2012)
Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

It is fully discussed in there. You can indeed view the ZIP as a weighted
average of two distributions...and there is no need for an interpretation
in terms of true and false zeros. True/false zeros make it a nicer story though!





Thinking about my system: there are a bunch of sites where the birds (of a
given species) never go (habitat is unsuitable), and a bunch where they do
go with varying levels of abundance (habitat is suitable, but come sites
are more favored than others, based on habitat features). Following the
last bullet above, a site that is suitable may have a count of zero simply
because the species wasn?t present there on the survey day (i.e., true zero
occurring by chance). Given the contradicting information above, and the
consensus on the importance of considering the source of zeros in model
selection, I would very much appreciate if someone could clear this up for
me - or let me know if I'm completely missing something here? Perhaps this
question should be posed on a stats forum, but given question 2 below, I
thought I'd try here first.



AFZ: Sounds like a ZIP or ZINB to me. But you may also need to add a spatially
correlated error term.




2) Assuming that I?m on the right track with a ZIP, is there a package I
can use to model a ZIP with a random effect for site? I looked at glmmADMB;
however, the zero inflation can only be modeled as a constant. This doesn?t
make sense for my system, as the zero-inflation will be a function of


AFZ: Welcome to WinBUGS or OpenBUGS. Actually...you have to be careful. I've noticed
that random effects and correlation structures may fight with the zero inflation
components in the model, depending where the zeros are. See again the reference above.




  habitat covariates (see above). Likewise, glmmPQL is not an option, as this
method does not yield log-likelihoods (and thus no AIC). I?m also thinking
that the random effect will have to be included in the zero process as well
? is this right?


AFZ: That is an option.....but is also a more complicated the model.


Alain Zuur


Many thanks, and my apologies if anything above is unclear.


Cheers,

JBW

	[[alternative HTML version deleted]]



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 66, Issue 29


From highstat at highstat.com  Thu Jun 21 02:17:43 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 21 Jun 2012 01:17:43 +0100
Subject: [R-sig-ME] How to include autocorrelation in GLMM and what to
 do with, false convergence warning message appearing after including an,
 interaction term (Lucia)
In-Reply-To: <mailman.1544.1340231571.4567.r-sig-mixed-models@r-project.org>
References: <mailman.1544.1340231571.4567.r-sig-mixed-models@r-project.org>
Message-ID: <4FE26827.9000009@highstat.com>



  > I will try to explain my data as good as possible.
>> So we taged 13 different whales with a tag that records time, depth,
>> speed, angle of descent and ascent 25 samples every second.
>> The normal diving behaviour of these animals is one deep dive of one
>> hour to 1200 meters followed by a series of 3-7 shallow dives of 20
>> minutes up to 300 m. Because the tag not always stays the same time
>> in each animal, my data is unbalanced and some tag records have one
>> deep dive and 6 shallow dives while other records have 7 deep dives
>> and 26 shallow dives.
>> I divided each dive in units of 30 seconds. for each unit I have the
>> next data:
>> whale number, dive number, total number of fluke strokes in the 30
>> seconds unit of analysis, mean of the sin of the angle during the 30
>> seconds unit, swim speed, dive type(ascent or descent), dive
>> direction( if it is a descent or an ascent) and time since the start
>> of the dive and finally my variable response which is presence or
>> absence of one type of fluke stroke called stroke type B.
>>
>> I think there has to be some autocorrelation between each 30 seconds
>> unit of analyis and need to include it in my model but do not know how!
>>
>> I am interested to know what affects the presence or absence of the
>> type B stroke (which is a binomial variable with 0 and 1)
>> so I decide to use a  binomial glmm with whale number as a random
>> effect. I included as well dive number within whale as a random effect.
>>
>> here is the model.
>>
>>
>> glmm114<-lmer (StrokeB~ Time *
>> Depth+SINP+flukes*Depth+speed+(1|whale_number)+(0+dive_number|whale_number),data=Luciadeepas,
>> family = binomial)



13 tagged animals may represent a lot of work....but it is not that much for a random intercept (and slope!).
Perhaps dropping the random slope may avoid the warning message. Also...depth and speed sound like "collinearity"??





>>
>> this is my final model after taking out the non significative
>> variables, the problem is that due to the interaction a problem
>> appears saying


Check whether the quality/quantity of your data supports an interaction. There is always a reason if there is trouble.






>>
>> The false convergence warning message (8)
>>
>> I looked on internet and it says is a common problem,


It is a common problem that people use too complicated models..:-)
Or have data that are too limited for the type of models they want to use.




  and some people
>> says that it doesnt make any change in the output while others says
>> that each variable has to be
>> divided by 100.


Better not believe everything people say. Divide by 100...huh????




but when I do this then the variables that become
>> significant doesnt make any sense.


I don;t know what you divided by 100.....but in principle dividing the continuous covariates
by 100 shouldn't change things that much. Unless you have some serious model misspecifications.

Perhaps you want to upload some data.



Alain

  >>
>>
>> Thanks so much in advanced
>> Lucia






-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From jake987722 at hotmail.com  Thu Jun 21 05:04:43 2012
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 20 Jun 2012 21:04:43 -0600
Subject: [R-sig-ME] How to include autocorrelation in GLMM and what to
 do with, false convergence warning message appearing after including an,
 interaction term (Lucia)
In-Reply-To: <4FE26827.9000009@highstat.com>
References: <mailman.1544.1340231571.4567.r-sig-mixed-models@r-project.org>,
	<4FE26827.9000009@highstat.com>
Message-ID: <SNT107-W25F7200281E9E5DB274137CBFD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120620/3f6db31d/attachment.pl>

From highstat at highstat.com  Thu Jun 21 10:57:06 2012
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 21 Jun 2012 09:57:06 +0100
Subject: [R-sig-ME] How to include autocorrelation in GLMM and what to
 do with, false convergence warning message appearing after including an,
 interaction term (Lucia)
Message-ID: <4FE2E1E2.30600@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120621/8a58989b/attachment.pl>

From queirozrafaelmv at yahoo.com.br  Thu Jun 21 18:51:19 2012
From: queirozrafaelmv at yahoo.com.br (Rafael Maia)
Date: Thu, 21 Jun 2012 12:51:19 -0400
Subject: [R-sig-ME] Understanding/plotting fixed effects estimates &
	standard errors
Message-ID: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>

Dear all,

I have ran a mixed effects binomial model and am trying to understand how the estimates of my model relate to its conclusions. It is a fairly simple model with one fixed categorical factor (2 levels) and a nested random effect. I am using lmer and the Wald test result, the likelihood ratio test and running a similar model using MCMCglmm all seem to point in the direction that the fixed effect is significant and important. However, as I am trying to extract the estimates and their standard errors to plot the results (by running a model without the intercept or releveling the factor), it is clear that there is a huge overlap in the estimates of the two levels of the fixed effect.

In the main model (below), the standard error has a very small standard error, but the SE for the intercept is fairly large, and encompasses the estimate of the second level.

So I am trying to understand - am I interpreting something wrong? Converting them from the log-odds scale doesn't seem to help much. If not, how should I reconcile these two pieces of evidence?  Is the releveling/removing intercept approach to understand estimates from a model not valid for mixed models? 

Many thanks for any help!  below you will find the results: 

>m1=lmer(cbind(success,fail) ~ factor+ (1|spp/variable), bb, family='binomial')

> summary(m1)
Generalized linear mixed model fit by the Laplace approximation 
Formula: cbind(success, fail) ~ factor + (1 | spp/variable) 
   Data: bb 
   AIC   BIC logLik deviance
 166.8 173.8 -79.41    158.8
Random effects:
 Groups       Name        Variance Std.Dev.
 variable:spp (Intercept) 0.014916 0.12213 
 spp          (Intercept) 1.907228 1.38102 
Number of obs: 42, groups: variable:spp, 42; spp, 7

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  1.43834    0.52289   2.751  0.00595 ** 
factor1      0.21081    0.04269   4.938 7.88e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

Correlation of Fixed Effects:
       (Intr)
factor1 -0.040

> m0=lmer(cbind(success,fail) ~ 1+ (1|spp/variable), bb, family='binomial')

> anova(m0,m1)
Data: bb
Models:
m0: cbind(success, fail) ~ 1 + (1 | spp/variable)
m1: cbind(success, fail) ~ factor + (1 | spp/variable)
   Df    AIC    BIC  logLik  Chisq Chi Df Pr(>Chisq)    
m0  3 183.16 188.37 -88.579                             
m1  4 166.81 173.76 -79.406 18.346      1  1.842e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

> m3=lmer(cbind(success,fail) ~ factor-1+ (1|spp/variable), bb, family='binomial')

> summary(m3)
Generalized linear mixed model fit by the Laplace approximation 
Formula: cbind(success, fail) ~ factor - 1 + (1 | spp/variable) 
   Data: bb 
   AIC   BIC logLik deviance
 166.8 173.8 -79.41    158.8
Random effects:
 Groups       Name        Variance Std.Dev.
 variable:spp (Intercept) 0.014916 0.12213 
 spp          (Intercept) 1.907221 1.38102 
Number of obs: 42, groups: variable:spp, 42; spp, 7

Fixed effects:
       Estimate Std. Error z value Pr(>|z|)   
factor0    1.4383     0.5229   2.751  0.00595 **
factor1    1.6491     0.5229   3.154  0.00161 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

Correlation of Fixed Effects:
       factor0
factor1 0.997

Abra?os,
Rafael Maia
---
webpage: http://gozips.uakron.edu/~rm72
"A little learning is a dangerous thing; drink deep, or taste not the Pierian spring." (A. Pope)
Graduate Student - Integrated Bioscience
University of Akron
http://gozips.uakron.edu/~shawkey/


From rwdougla at Princeton.EDU  Thu Jun 21 19:05:59 2012
From: rwdougla at Princeton.EDU (Rex W. Douglass)
Date: Thu, 21 Jun 2012 17:05:59 +0000
Subject: [R-sig-ME] lme4, Irtrees,
 and Outcomes Measured at Multiple and Nested Levels of Geography
 and Time
Message-ID: <C78E6A32C62E1448909FD94C19261EC537096591@CSGMBX202W.pu.win.princeton.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120621/9a9ae037/attachment.pl>

From s.chamaille at yahoo.fr  Thu Jun 21 23:07:50 2012
From: s.chamaille at yahoo.fr (Simon =?ISO-8859-1?Q?Chamaill=E9-Jammes?=)
Date: Thu, 21 Jun 2012 23:07:50 +0200
Subject: [R-sig-ME] Do glmer and glmmadmb calculate log likelihood on the
	same scale ?
Message-ID: <1340312870.2169.18.camel@simon-laptop>

Hello all, 
I would like to know if glmer and glmmadmb calculate log likelihood /
deviance on the same scale.

My glmer model end up with the 'false convergence warning'. However a
verbose output suggests that convergence actually goes not so badly. The
exact same model run without warning error using glmmadmb. The estimates
(fixed effects, variance components) are however widely different from
those estimated by glmer, and the logLik of the model is smaller but
negative with glmmadmb (-584.485) than with glmer (-424.4), but I'm
wondering if I can actually compare them. And if so, is this a sign I
could 'reasonably' trust the glmer output more than the glmmadmb ?

thanks

simon


From David.Duffy at qimr.edu.au  Thu Jun 21 23:22:48 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 22 Jun 2012 07:22:48 +1000 (EST)
Subject: [R-sig-ME] Do glmer and glmmadmb calculate log likelihood on
	thesame scale ?
In-Reply-To: <1340312870.2169.18.camel@simon-laptop>
References: <1340312870.2169.18.camel@simon-laptop>
Message-ID: <Pine.LNX.4.64.1206220716520.20618@orpheus.qimr.edu.au>

On Thu, 21 Jun 2012, Simon Chamaill?-Jammes wrote:

> I would like to know if glmer and glmmadmb calculate log likelihood /
> deviance on the same scale.
>
What model family?

data(epil2)
epil2$subject <- factor(epil2$subject)
fm2 <- glmmadmb(y~Base*trt+Age+Visit+(Visit|subject),
                 data=epil2, family="poisson")
gm2 <- glmer(y~Base*trt+Age+Visit+(Visit|subject)
              data=epil2, family=poisson())
logLik(fm2)
'log Lik.' -655.41 (df=8)
logLik(gm2)
'log Lik.' -272.4573 (df=9)


From kegurney at alaska.edu  Thu Jun 21 23:54:05 2012
From: kegurney at alaska.edu (Kirsty E. B. Gurney)
Date: Thu, 21 Jun 2012 13:54:05 -0800
Subject: [R-sig-ME] Zero-inflated mixed effects models: random effects /
	"function maximizer failed"?
Message-ID: <98D0A84D58F649B4BBD7363610BEE021@Wipflilatitude>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120621/b9f7e55f/attachment.pl>

From jwiley.psych at gmail.com  Fri Jun 22 02:24:59 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 21 Jun 2012 17:24:59 -0700
Subject: [R-sig-ME] Do glmer and glmmadmb calculate log likelihood on
 thesame scale ?
In-Reply-To: <Pine.LNX.4.64.1206220716520.20618@orpheus.qimr.edu.au>
References: <1340312870.2169.18.camel@simon-laptop>
	<Pine.LNX.4.64.1206220716520.20618@orpheus.qimr.edu.au>
Message-ID: <CANz9Z_+DieCW7Lz=2gMVLW2Fy17jW8LvoBYhoEmchKfJmG8FnA@mail.gmail.com>

Just a note that those are not the same models.  To match glmer() with
glmmadmb(), try:

gm2 <- glmer(y~Base*trt+Age+Visit+(1 | Visit) + (0 + Visit|subject),
  data=epil2, family=poisson())
logLik(gm2)

which for me gives:

'log Lik.' -421.1128 (df=8)

OR you could change glmmadmb() to

fm2 <- glmmadmb(y~Base*trt+Age+Visit+(Visit|subject),
  data=epil2, family="poisson", corStruct = "full")

however, on my machine, there are warnings about the matrix not being
positive definite, and the model never converges.  If it worked for
you, I would be curious what version of glmmADMB you are using.  Here
is my sessionInfo()

R Under development (unstable) (2012-05-22 r59410)
Platform: x86_64-w64-mingw32/x64 (64-bit)
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-42  Matrix_1.0-7      lattice_0.20-6    glmmADMB_0.7.2.12
[5] R2admb_0.7.5.2    MASS_7.3-18

loaded via a namespace (and not attached):
[1] compiler_2.16.0 grid_2.16.0     nlme_3.1-104    stats4_2.16.0
[5] tools_2.16.0

Cheers,

Josh

On Thu, Jun 21, 2012 at 2:22 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Thu, 21 Jun 2012, Simon Chamaill?-Jammes wrote:
>
>> I would like to know if glmer and glmmadmb calculate log likelihood /
>> deviance on the same scale.
>>
> What model family?
>
> data(epil2)
> epil2$subject <- factor(epil2$subject)
> fm2 <- glmmadmb(y~Base*trt+Age+Visit+(Visit|subject),
> ? ? ? ? ? ? ? ?data=epil2, family="poisson")
> gm2 <- glmer(y~Base*trt+Age+Visit+(Visit|subject)
> ? ? ? ? ? ? data=epil2, family=poisson())
> logLik(fm2)
> 'log Lik.' -655.41 (df=8)
> logLik(gm2)
> 'log Lik.' -272.4573 (df=9)
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From David.Duffy at qimr.edu.au  Fri Jun 22 04:13:35 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 22 Jun 2012 12:13:35 +1000 (EST)
Subject: [R-sig-ME] Do glmer and glmmadmb calculate log likelihood on
	thesame scale ?
In-Reply-To: <CANz9Z_+DieCW7Lz=2gMVLW2Fy17jW8LvoBYhoEmchKfJmG8FnA@mail.gmail.com>
References: <1340312870.2169.18.camel@simon-laptop><Pine.LNX.4.64.1206220716520.20618@orpheus.qimr.edu.au>
	<CANz9Z_+DieCW7Lz=2gMVLW2Fy17jW8LvoBYhoEmchKfJmG8FnA@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1206221125560.30121@orpheus.qimr.edu.au>

On Thu, 21 Jun 2012, Joshua Wiley wrote:

> Just a note that those are not the same models.

Huh.

> OR you could change glmmadmb() to
>
> fm2 <- glmmadmb(y~Base*trt+Age+Visit+(Visit|subject),
>  data=epil2, family="poisson", corStruct = "full")

> however, on my machine, there are warnings about the matrix not being
> positive definite, and the model never converges.

I haven't updated glmmADMB recently (0.6.4 2011-08-30), so it
gives the warning, but continues merrily to give:

             (Intercept)   Visit
(Intercept)     0.24931 0.24931
Visit           0.54572 0.54572

and the same likelihood as before

Log-likelihood: -655.41

glmer was
  Groups  Name        Variance Std.Dev. Corr
  subject (Intercept) 0.24912  0.49912
          Visit       0.53962  0.73459  0.011
  'log Lik.' -262.6586 (df=9)

Your suggestion Visit + (1 | Visit) + (0 + Visit | subject) 
gave me

  Groups  Name        Variance   Std.Dev.
  subject Visit       0.77301    0.87921
  Visit   (Intercept) 5.1845e-16 2.2769e-08
'log Lik.' -421.1128 (df=8)

I have to admit, the direction of the change in loglikelihood here 
confuses me a little ;)

My lme4 is also a little antiquated: 0.999375-42 (2011-10-02).


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From David.Duffy at qimr.edu.au  Fri Jun 22 04:48:01 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 22 Jun 2012 12:48:01 +1000 (EST)
Subject: [R-sig-ME] Understanding/plotting fixed effects estimates
	&standard errors
In-Reply-To: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>
References: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>
Message-ID: <Pine.LNX.4.64.1206221218220.30121@orpheus.qimr.edu.au>


This is nothing to with mixed modelling per se, but how your contrasts for 
the fixed effects are set up.  If this was fixed effects only, you could 
fit -1 + factor (no intercept) to give estimates for each level of factor 
with standard errors that you could correctly interpret as you are trying 
to.  The FAQ (http://glmm.wikidot.com/faq) shows plotting of confidence 
intervals for predictions.


From queirozrafaelmv at yahoo.com.br  Fri Jun 22 05:17:33 2012
From: queirozrafaelmv at yahoo.com.br (Rafael Maia)
Date: Thu, 21 Jun 2012 23:17:33 -0400
Subject: [R-sig-ME] Understanding/plotting fixed effects estimates
	&standard errors
In-Reply-To: <Pine.LNX.4.64.1206221218220.30121@orpheus.qimr.edu.au>
References: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>
	<Pine.LNX.4.64.1206221218220.30121@orpheus.qimr.edu.au>
Message-ID: <7BDCEF9C-741D-41C4-A5D4-5E3A181AAB0A@yahoo.com.br>

hi dr Duffy,

many thanks for the attention and the reply.  I followed the instructions under "Predictions and/or confidence (or prediction) intervals on predictions" of the wiki FAQ; however, unless I missed something, the results were nearly identical (and therefore confidence intervals wide & overlapping) to what I had by removing the intercept from the model:

>m1=lmer(cbind(success,fail) ~ factor + (1|spp/variable), bb, family='binomial')
>summary(m1)
...
Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  1.43834    0.52289   2.751  0.00595 ** 
factor1       0.21081    0.04269   4.938 7.88e-07 ***

>newdat=expand.grid(success=0,fail=0,factor=c('0',"1"))
>mm=model.matrix(terms(m1),newdat)
> estims=mm %*% fixef(m1)
> estims
      [,1]
1 1.438342
2 1.649149
> pvar1=diag(mm %*% tcrossprod(vcov(m1),mm))
> sqrt(pvar1)
[1] 0.5228946 0.5229200

#compare to

>m3=lmer(cbind(success,fail) ~ factor -1 + (1|spp/variable), bb, family='binomial')
>summary(m3)
...
Fixed effects:
      Estimate Std. Error z value Pr(>|z|)   
factor0    1.4383     0.5229   2.751  0.00595 **
factor1    1.6491     0.5229   3.154  0.00161 **

many thanks,

Abra?os,
Rafael Maia
---
webpage: http://gozips.uakron.edu/~rm72
"A little learning is a dangerous thing; drink deep, or taste not the Pierian spring." (A. Pope)
Graduate Student - Integrated Bioscience
University of Akron
http://gozips.uakron.edu/~shawkey/

On Jun 21, 2012, at 10:48 PM, David Duffy wrote:

> 
> This is nothing to with mixed modelling per se, but how your contrasts for the fixed effects are set up.  If this was fixed effects only, you could fit -1 + factor (no intercept) to give estimates for each level of factor with standard errors that you could correctly interpret as you are trying to.  The FAQ (http://glmm.wikidot.com/faq) shows plotting of confidence intervals for predictions.


From pauljohn32 at gmail.com  Fri Jun 22 05:28:06 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 21 Jun 2012 22:28:06 -0500
Subject: [R-sig-ME] need help with predicted values from lmer with newdata
Message-ID: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>

Greetings.

I'm getting some crazy results out of predict on an lmer model.  I've
gone through
this lots of times, and feel certain I'm missing some obvious mistake.
 If you browse
through and get to the bottom, there's some output that shows my predict output
is just wrong, but I can't see why.

I will send the first person with the right answer a new KU t-shirt in
the size of
your choice.  That's better than "thanks in advance". Isn't it?

## Paul Johnson <pauljohn at ku.edu>
## 2012-06-21

## I want to compare the "separate ols regressions on clusters"
## results with the mixed model estimates. I've run into
## trouble because the output of predict with a newdata object
## seems to be completely wrong.  I demonstrate "manual" calculations
## to try to convince you I understand what's going on (but
## peculiarity of predict output may make things appear otherwise).

## I pasted in some output at the bottom in case you just want to
## see where I think there is a problem.

## My system:
## > sessionInfo()
## R version 2.15.0 (2012-03-30)
## Platform: x86_64-pc-linux-gnu (64-bit)

## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
##  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
##  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
##  [7] LC_PAPER=C                 LC_NAME=C
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C
## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base

## other attached packages:
## [1] lme4_0.999902344-0 Matrix_1.0-6       lattice_0.20-6     MASS_7.3-18
## loaded via a namespace (and not attached):
## [1] compiler_2.15.0 grid_2.15.0     minqa_1.2.1     nlme_3.1-104
## [5] splines_2.15.0  tools_2.15.0


## Topic: create multi-level data and use regression and lmer to
## estimate it.  This creates 3 different dependent variables,
## y1: ordinary "homoskedastic" regression (no grouping effect)
## y2: clustered "random intercepts"
## y3: clustered "random intercepts" and "random slope" for 1 predictor (x1)

library(MASS)
set.seed(1234)

## Step 1. Create a Data Frame.

## M respondents, N observations for each one.
## In a repeated measures context, this is called "longitudinal data".
## In cross sectional approach, this is M groups (classrooms) with
## several people in each)

M <- 10
N <- 30

## get M unique gray colors, will use later for plotting
grays <- gray.colors(M)

## Standard deviation of error term at individual level
STDE <- 48

## STDEM: standard deviation of clustered intercepts.
### In a longitudinal "repeated measures" exercise, this is an
## individual-level effect. In a cross section, this is a random
## classroom effect.
STDEM <- 30

## STEx1: standard deviation of slopes across cluster units
STDEx1 <- 5

## The true effects of b0, b1, b2, b3 in
## y = b0 + b1*x1 + b2*x2 + b3*x3
bslopes <- c(0.2, 15.4, -0.2, 3)

## Now generate the data frame with x1, x2 and x3.
## Let's suppose the predictors are Multivariate Normal, with
## means (100,200,150), standard deviations (10, 20, 30), and
## intercorrelations of 0.4.  These can, of course, be adjusted
## for interesting variations.

## Mind, an "indicator" that says with which cluster an observation belongs.
Mind <- 1:M %x% rep(1,N)

means <- c(100, 200, 150)
sds <- c(10, 20, 30)
rho <- 0.4
corr.mat <- matrix(c(1, rho, rho, rho, 1, rho, rho, rho, 1), nrow = 3)
sigma <- diag(sds) %*% corr.mat %*% diag(sds)
x.mat <- mvrnorm(n = N * M, mu = means, Sigma = sigma)
dimnames(x.mat)[[2]] <- c("x1", "x2", "x3")
## Add an intercept on the front of x.mat
x.mat <- cbind("(Intercept)"= 1, x.mat)


## Create a dependent variable that has no clustering effects.  This
## is an "ordinary" regression with slopes and random error designated
## above random noise
y1 <- x.mat %*% bslopes + rnorm(M*N, m=0, s= STDE)
dat <- data.frame(id=1:(N*M), Mind, y1, as.data.frame(x.mat))
rm(Mind, y1, x.mat) ## cleanup workspace

## Layer on additive group level error in y2
## Add a group-level intercept.
## A vector of M disturbances is created, and each is
## added to all N case within its cluster
dat$y2 <- dat$y1 +  rnorm(M, 0, STDEM) %x% rep(1, N)

## In y3, add in random slope effect
## are changing the slope for x1 from b1 to N(b1, STDEx1^2).
## Same as newb1 ~ b1 + N(0, STDEx1) * x1
dat$y3 <- dat$y2 +   (rnorm(M, 0, STDEx1) %x% rep(1, N)) * dat$x1

## In the lme4 package, there is an "easy" tool to run M separate lm regressions
library(lme4)

##100 separate regressions, with 3 predictors
m3list <- lmList(y3 ~ x1 + x2 + x3 | Mind, data=dat, pool = FALSE)


## Now I see a pattern. I'll use the unique range on x1 for each cluster
## I think that makes the lines look more "in" the data.
plot(y3 ~ x1, data=dat, col=grays[Mind], main = "lm on clusters")
for( i in seq_along(m3list)){
    m3mf <- model.frame(m3list[[i]]) #data set for group i
    x1range <- range(m3mf$x1) ## use group-specific ranges this time
    pgroup <- predict( m3list[[i]], newdata = data.frame(x1=x1range,
x2=mean(m3mf$x2), x3=mean(m3mf$x3)))
    lines(x1range, pgroup, col=grays[i])
}

## Hmm. That data looks like it might be handy for comparison later on.
## Build a data frame of it. I've never thought of doing this work
## cluster-by-cluster before.

m3newdat <- lapply(m3list, function(x) {
    m3mf <- model.frame(x)
    ndf = data.frame(x1=range(m3mf$x1), x2=mean(m3mf$x2), x3=mean(m3mf$x3))
    ndf$m3pred <- predict(x, newdata = ndf)
    ndf} )
## Smash the list of data frames together
m3newdat <- do.call("rbind", m3newdat)
## Interesting!
m3newdat[1:20, ]
## Better add a variable Mind. This looks stupid, but works.
m3newdat$Mind <- as.integer( do.call("rbind",
strsplit(row.names(m3newdat), split="\\.", perl=T))[ ,1] )


## Draw new graphs on a new device, so we can compare
dev.new()

## The "right" model allows the random effects to be correlated.
mm4 <- lmer( y3 ~ x1 + x2 + x3 + (x1 | Mind), data=dat)
summary(mm4)



mm4ranef <- ranef(mm4, postVar = TRUE) ## a ranef.mer object, a list
that includes one data frame


### What do the predicted values mean from lmer?
### here they are. But what do they include?
head(mm4pred <- predict(mm4))
tail(mm4pred <- predict(mm4))


## I can't tell what those numbers are. Can't be sure from ?predict.merMod
## So I'm going to go through the step-by-step
## process of calculating predicted values. These should follow a
formula like this
## for model 4. j is the "cluster" index.
##
##  j'th intercept                j'th slope
##  (b0 + raneff(intercept, j)) + (b1 + raneff(x1,j))*x1 + b2 x2 + b3 x3

mm4b <- coef(summary(mm4))[ ,1]
mm4vnames <- names(mm4b)
mm4mm <- model.matrix(mm4) ## predictors

## Doing this bit by bit. First
## b0 + raneff(intercept, j)
mm4inteffect <- mm4b["(Intercept)"] +  mm4ranef[[1]][dat$Mind, 1]
mm4x1effect <- mm4mm[ , c("x1")] * (mm4b["x1"] + mm4ranef[[1]][dat$Mind, 2])
mm4pred2 <- mm4inteffect + mm4x1effect +  mm4mm[ ,c("x2","x3") ] %*%
mm4b[c("x2","x3")]
head(mm4pred2)
tail(mm4pred2)

## Aha! Those exactly match predict for mm4. So I understand what "predict" does




## Now, I want to run predict for some particular values of x1, x2, x3.

## Let's try running m3newdat through the predict function for mm4.
m3newdat$mm4.3 <- predict(mm4, newdata = m3newdat)
m3newdat


## Disaster. Predicted values completely out of whack. Lots of
## lines fall off the bottom of the graph.

plot(y3 ~ x1, data=dat, col=grays[Mind], main="lmer mixed model predictions")
by(m3newdat, m3newdat$Mind, function(x) { lines(x$x1, x$mm4.3,
col=grays[x$Mind])})


## They don't match the manual calculations I perform here
mm4b <- coef(summary(mm4))[ ,1]
mm4vnames <- names(mm4b)
mm4mm <- as.matrix(m3newdat)

##  b0 + raneff(intercept, j)
mm4inteffect <- mm4b["(Intercept)"] + rep(mm4ranef[[1]][, 1], each=2)
mm4x1effect <- mm4mm[ , c("x1")] * rep(mm4b["x1"] + mm4ranef[[1]][, 2], each=2)
mm4manualpred2 <- mm4inteffect + mm4x1effect +  mm4mm[ ,c("x2","x3") ]
%*%  mm4b[c("x2","x3")]

mm4mm <- cbind(as.data.frame(mm4mm), "mm4manualpred" = mm4manualpred2)
mm4mm

## Here's what I see when I do that. m3pred: the lmList predictions.
## mm4manualpred: my "manual" calculations of predicted values for lmer mm4
## mm4.3 output from predict for same "newdat" used with mm4manualpred.

## > mm4mm
##             x1       x2       x3   m3pred Mind      mm4.3 mm4manualpred
## 1.1   88.51074 196.0615 141.3859 1221.477    1  -434.7602      1239.152
## 1.2  110.88258 196.0615 141.3859 1483.957    1  -630.0463      1466.961
## 2.1   80.26167 194.1252 133.7265 1405.672    2  -614.3256      1388.751
## 2.2  117.08533 194.1252 133.7265 1845.499    2 -1051.4105      1866.505
## 3.1   80.84091 202.4517 154.3976 1302.205    3  3527.8154      1284.706
## 3.2  120.33775 202.4517 154.3976 1692.819    3  5037.6392      1717.210
## 4.1   68.96320 204.5145 151.6662 1321.927    4  5097.5261      1379.251
## 4.2  120.17029 204.5145 151.6662 2137.589    4  8559.2362      2108.628
## 5.1   84.85202 200.7799 153.1595 1821.135    5  4736.2240      1813.415
## 5.2  122.58730 200.7799 153.1595 2418.381    5  6641.2026      2426.855
## 6.1   84.60214 202.3324 153.2583 2015.183    6  1521.6831      2001.700
## 6.2  128.13418 202.3324 153.2583 2778.684    6  2086.4726      2799.053
## 7.1   74.73548 198.5761 155.8984 1780.196    7  1497.6761      1802.381
## 7.2  118.97636 198.5761 155.8984 2622.083    7  2127.8282      2603.626
## 8.1   83.40882 200.4991 152.0515 2342.043    8  1954.4592      2323.477
## 8.2  118.73997 200.4991 152.0515 3088.686    8  2601.6007      3105.182
## 9.1   82.48090 205.4736 152.2774 1979.852    9  2253.5650      1950.388
## 9.2  117.48279 205.4736 152.2774 2554.581    9  3027.9842      2587.319
## 10.1  84.77764 205.9689 152.3325 2256.434   10  2236.3346      2268.620
## 10.2 119.66417 205.9689 152.3325 3022.053   10  2980.1202      3012.406


-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From pauljohn32 at gmail.com  Fri Jun 22 05:43:53 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 21 Jun 2012 22:43:53 -0500
Subject: [R-sig-ME] Zero-inflated mixed effects model - clarification of
 zeros modeled and R package questions
In-Reply-To: <CAEbqvwo7a+hOLPcZ1BKUerSir+Xwcczk3AY5CeFbc80woLeM3A@mail.gmail.com>
References: <CAEbqvwo7a+hOLPcZ1BKUerSir+Xwcczk3AY5CeFbc80woLeM3A@mail.gmail.com>
Message-ID: <CAErODj_-9isC0nJ7OE08dGy8gF2P+bSmeBfSf+Sz_=AY384Z=w@mail.gmail.com>

Dear Jennifer:
Response below

On Wed, Jun 20, 2012 at 5:32 PM, Jennifer Barrett
<jenn.s.barrett at gmail.com> wrote:
> Hi folks,
>
>
> I?m looking for some guidance in regards to zero-inflated models with
> repeated measures (i.e., random effect for site). My first question is more
> of a statistical one, while the second is related to R packages. Apologies
> for the long post; however, I want to make sure my concerns/questions are
> clear!
>
>
> Our project and dataset:
>
>
> - The aim of our project is to 1) examine associations between shoreline
> habitat characteristics and the abundance of several shorebird species; and
> 2) estimate the total abundance of each shorebird species within the entire
> study region based on the models from 1) above, with confidence intervals.
> Note that we will be using an information theoretic approach for 1) above,
> and would like to use MMI for 2).
>
> - Our response dataset consists of counts of shorebirds at >150 coastal
> sites, conducted on the second Sunday of each month between the months of
> Oct-March, over 10 years; however, not every site was surveyed in all
> months (we?ve limited our dataset to those with a minimum of 3 counts in a
> year). ?Our response variable is thus the number of birds counted in a
> given month/year at a given site. Note that we plan to model each year
> separately.
>
> - ?The habitat dataset consists of shoreline units within our entire study
> region, with each unit characterized by exposure, substrate type...etc.
> Using GIS, we?ve measured the length of shoreline belonging to shoreline
> categories (e.g., sand, rock, mud) within each survey site, the average
> exposure for the site, and other continuous attributes, as well as one
> presence/absence covariate.
>
> - Initial exploratory analysis has shown that the counts are zero-inflated.
> While there may be some false zeros in our dataset (i.e., observer error),
> the source of the zero-inflation is likely preference of shorebirds for
> particular sites with particular features and avoidance of others (i.e.,
> true zeros or ?structural zeros?). Some zeros likely also arise because the
> species does not saturate its habitat (i.e., habitat suitable, but
> unoccupied ? also a ?true? zero), though again, the majority of the zeros
> are likely structural.
>
>
> Onto my questions:
>
>
> 1) I?ve been reading through the literature to decide what type of model
> would best be suited for our dataset and questions. While all articles seem
> to agree that the choice of a model needs to consider the source of excess
> zeros, they seem to contradict one another in regards to what zeros are
> being modeled in each component of a zero-inflated mixture model. Note that
> I am not considering a two-part (i.e., conditional) model, because I do not
> believe that all zeros arise from the occupancy process (as per Joseph et
> al. 2009 and as noted above, zero abundance can occur by chance in our
> system). Examples:
>
>
> - Martin et al. (2005) state that when zero inflation is due to true zeros,
> two-part or mixture models (ZIP or ZINB) are recommended, and that when
> zero inflation is due to false zeros, a ZIB mixture model is recommended;
> however, when zero inflation is due to both excess true and false zeros, a
> Bayesian framework may be used, though there is no formal discussion in the
> literature. NOTE: Since this article was published, Royle?s N-mixture model
> has addressed this issue; however, I cannot use this approach as my data do
> not meet the assumption of a closed population during the study period.
>
> - In contrast to Martin et al. (2005), Potts and Elith (2006) state that
> the zero-inflated mixture model structure implies that zero observations
> arising from the zero process are true negative observations, and that
> those arising from the Poisson process are false negative observations ?that
> is, the habitat is suitable, but unoccupied? (p.155). However, on the
> previous page, they defined false negative as ?attributable to experimental
> design? or observer error?, and habitat that is ?suitable, but unoccupied?
> as a true negative, so I'm not sure which type of zero observation they are
> really referring to here for the Poisson process.
>
> - In contrast to both sources above, Zuur et al. (2009) state that in a ZIP
> or ZINB, zeros are modeled as coming from two processes ? the binomial
> process, which models only false zeros (observer, design, and survey error)
> and the Poisson (or Negbin) process ?which models the true zeros and
> counts. This is the opposite of what was stated by Potts and Elith.
>
> - Finally, I?ve read other sources which state that ZIPs simply treat the
> population as a mixture, with one set of subjects having a zero response ?
> in other words, there is no mention of whether the zero process is modeling
> the ?true? or ?false? zeros.
>
>
> Thinking about my system: there are a bunch of sites where the birds (of a
> given species) never go (habitat is unsuitable), and a bunch where they do
> go with varying levels of abundance (habitat is suitable, but come sites
> are more favored than others, based on habitat features). Following the
> last bullet above, a site that is suitable may have a count of zero simply
> because the species wasn?t present there on the survey day (i.e., true zero
> occurring by chance). Given the contradicting information above, and the
> consensus on the importance of considering the source of zeros in model
> selection, I would very much appreciate if someone could clear this up for
> me - or let me know if I'm completely missing something here? Perhaps this
> question should be posed on a stats forum, but given question 2 below, I
> thought I'd try here first.
>
>
> 2) Assuming that I?m on the right track with a ZIP, is there a package I
> can use to model a ZIP with a random effect for site? I looked at glmmADMB;
> however, the zero inflation can only be modeled as a constant. This doesn?t
> make sense for my system, as the zero-inflation will be a function of
> habitat covariates (see above). Likewise, glmmPQL is not an option, as this
> method does not yield log-likelihoods (and thus no AIC). I?m also thinking
> that the random effect will have to be included in the zero process as well
> ? is this right?
>
Some of your jargon is unfamiliar to me--"true" and "false" zeros. I
suppose a false zero would be the result of a "hurdle process" (as in
the pscl package).  I've not seen a hurdle model joined in the same
with a zero-inflation model.  Certainly not with "random effects"
apart from the inflated zeros.

Although I do not believe there is an ML solution for your problem
within easy reach. However, there are Bayesian answers. Please see the
package MCMCglmm.  It has a very well done pair of vignettes.

MCMCglmm has a ZIP family option, and you can add random effects.
Jarod Hadfield has been a regular contributor here and I think if you
post your working example code he and others will be glad to help out.

pj



-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From pauljohn32 at gmail.com  Fri Jun 22 06:18:34 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 21 Jun 2012 23:18:34 -0500
Subject: [R-sig-ME] Understanding/plotting fixed effects estimates
 &standard errors
In-Reply-To: <7BDCEF9C-741D-41C4-A5D4-5E3A181AAB0A@yahoo.com.br>
References: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>
	<Pine.LNX.4.64.1206221218220.30121@orpheus.qimr.edu.au>
	<7BDCEF9C-741D-41C4-A5D4-5E3A181AAB0A@yahoo.com.br>
Message-ID: <CAErODj9uRthN3dzzDO+KE7W6eKseJUatGuKywF8U0OJu7OMjtQ@mail.gmail.com>

Can I make a wild guess/accusation below? Please?

On Thu, Jun 21, 2012 at 10:17 PM, Rafael Maia
<queirozrafaelmv at yahoo.com.br> wrote:
> hi dr Duffy,
>
> many thanks for the attention and the reply. ?I followed the instructions under "Predictions and/or confidence (or prediction) intervals on predictions" of the wiki FAQ; however, unless I missed something, the results were nearly identical (and therefore confidence intervals wide & overlapping) to what I had by removing the intercept from the model:
>
>>m1=lmer(cbind(success,fail) ~ factor + (1|spp/variable), bb, family='binomial')
>>summary(m1)
> ...
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ?1.43834 ? ?0.52289 ? 2.751 ?0.00595 **
> factor1 ? ? ? 0.21081 ? ?0.04269 ? 4.938 7.88e-07 ***
>
>>newdat=expand.grid(success=0,fail=0,factor=c('0',"1"))
>>mm=model.matrix(terms(m1),newdat)
>> estims=mm %*% fixef(m1)
>> estims
> ? ? ?[,1]
> 1 1.438342
> 2 1.649149
>> pvar1=diag(mm %*% tcrossprod(vcov(m1),mm))

The predicted value is not very different between the two levels of
"factor" when success=0 and fail=0.  This is a binomial model, the
precision of the predictions is not "linear" or evenly spaced from
left to right.

Can you supply the same calculations for some more meaningful
combinations of success and fail?

When you do, let us see

mm

and

vcov(m1)

please.


>> sqrt(pvar1)
> [1] 0.5228946 0.5229200
>
> #compare to
>
>>m3=lmer(cbind(success,fail) ~ factor -1 + (1|spp/variable), bb, family='binomial')
>>summary(m3)
> ...
> Fixed effects:
> ? ? ?Estimate Std. Error z value Pr(>|z|)
> factor0 ? ?1.4383 ? ? 0.5229 ? 2.751 ?0.00595 **
> factor1 ? ?1.6491 ? ? 0.5229 ? 3.154 0.00161 **
>
> many thanks,
>
> Abra?os,
> Rafael Maia
> ---
> webpage: http://gozips.uakron.edu/~rm72
> "A little learning is a dangerous thing; drink deep, or taste not the Pierian spring." (A. Pope)
> Graduate Student - Integrated Bioscience
> University of Akron
> http://gozips.uakron.edu/~shawkey/
>
> On Jun 21, 2012, at 10:48 PM, David Duffy wrote:
>
>>
>> This is nothing to with mixed modelling per se, but how your contrasts for the fixed effects are set up. ?If this was fixed effects only, you could fit -1 + factor (no intercept) to give estimates for each level of factor with standard errors that you could correctly interpret as you are trying to. ?The FAQ (http://glmm.wikidot.com/faq) shows plotting of confidence intervals for predictions.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From queirozrafaelmv at yahoo.com.br  Fri Jun 22 06:45:34 2012
From: queirozrafaelmv at yahoo.com.br (Rafael Maia)
Date: Fri, 22 Jun 2012 00:45:34 -0400
Subject: [R-sig-ME] Understanding/plotting fixed effects estimates
	&standard errors
In-Reply-To: <CAErODj9uRthN3dzzDO+KE7W6eKseJUatGuKywF8U0OJu7OMjtQ@mail.gmail.com>
References: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>
	<Pine.LNX.4.64.1206221218220.30121@orpheus.qimr.edu.au>
	<7BDCEF9C-741D-41C4-A5D4-5E3A181AAB0A@yahoo.com.br>
	<CAErODj9uRthN3dzzDO+KE7W6eKseJUatGuKywF8U0OJu7OMjtQ@mail.gmail.com>
Message-ID: <B7C5F9F8-25AD-4842-89F7-01EB08526B38@yahoo.com.br>

hi dr Johnson,

many thanks for the help. I tried following your suggestion but changing the values does not change the predictions, so I might be doing something plain wrong (maybe because the predictor is factorial and its just using the model matrix and the estimated fixed effects to calculate the predictions? I'm not entirely sure). The results, as well as mm & vcov follow below:

>newdat=expand.grid(success=c(100,300,500,10000),fail=c(100,300,500,10000),factor=c('0',"1"))
>mm=model.matrix(terms(m1),newdat)
>estims=mm %*% fixef(m1)
> as.vector(estims)
 [1] 1.438342 1.438342 1.438342 1.438342 1.438342 1.438342 1.438342 1.438342
 [9] 1.438342 1.438342 1.438342 1.438342 1.438342 1.438342 1.438342 1.438342
[17] 1.649149 1.649149 1.649149 1.649149 1.649149 1.649149 1.649149 1.649149
[25] 1.649149 1.649149 1.649149 1.649149 1.649149 1.649149 1.649149 1.649149
>pvar1=diag(mm %*% tcrossprod(vcov(m1),mm))
> sqrt(pvar1)
 [1] 0.5228946 0.5228946 0.5228946 0.5228946 0.5228946 0.5228946 0.5228946
 [8] 0.5228946 0.5228946 0.5228946 0.5228946 0.5228946 0.5228946 0.5228946
[15] 0.5228946 0.5228946 0.5229200 0.5229200 0.5229200 0.5229200 0.5229200
[22] 0.5229200 0.5229200 0.5229200 0.5229200 0.5229200 0.5229200 0.5229200
[29] 0.5229200 0.5229200 0.5229200 0.5229200

>#simplifying a bit to print the model matrix

> newdat=expand.grid(success=c(100,500),fail=c(100,500),factor=c('0',"1"))
> newdat
  success fail factor
1 100   100  0
2 500   100  0
3 100   500  0
4 500   500  0
5 100   100 1
6 500   100 1
7 100   500 1
8 500   500 1
> mm=model.matrix(terms(m1),newdat)
> mm
  (Intercept) factor1
1           1      0
2           1      0
3           1      0
4           1      0
5           1      1
6           1      1
7           1      1
8           1      1
attr(,"assign")
[1] 0 1
attr(,"contrasts")
attr(,"contrasts")$factor
[1] "contr.treatment"

> vcov(m1)
2 x 2 Matrix of class "dpoMatrix"
              [,1]          [,2]
[1,]  0.2734187339 -0.0008978599
[2,] -0.0008978599  0.0018223310

I really appreciate the attention. Thanks again,

Abra?os,
Rafael Maia
---
webpage: http://gozips.uakron.edu/~rm72
"A little learning is a dangerous thing; drink deep, or taste not the Pierian spring." (A. Pope)
Graduate Student - Integrated Bioscience
University of Akron
http://gozips.uakron.edu/~shawkey/

On Jun 22, 2012, at 12:18 AM, Paul Johnson wrote:

> Can I make a wild guess/accusation below? Please?
> 
> On Thu, Jun 21, 2012 at 10:17 PM, Rafael Maia
> <queirozrafaelmv at yahoo.com.br> wrote:
>> hi dr Duffy,
>> 
>> many thanks for the attention and the reply.  I followed the instructions under "Predictions and/or confidence (or prediction) intervals on predictions" of the wiki FAQ; however, unless I missed something, the results were nearly identical (and therefore confidence intervals wide & overlapping) to what I had by removing the intercept from the model:
>> 
>>> m1=lmer(cbind(success,fail) ~ factor + (1|spp/variable), bb, family='binomial')
>>> summary(m1)
>> ...
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)  1.43834    0.52289   2.751  0.00595 **
>> factor1       0.21081    0.04269   4.938 7.88e-07 ***
>> 
>>> newdat=expand.grid(success=0,fail=0,factor=c('0',"1"))
>>> mm=model.matrix(terms(m1),newdat)
>>> estims=mm %*% fixef(m1)
>>> estims
>>      [,1]
>> 1 1.438342
>> 2 1.649149
>>> pvar1=diag(mm %*% tcrossprod(vcov(m1),mm))
> 
> The predicted value is not very different between the two levels of
> "factor" when success=0 and fail=0.  This is a binomial model, the
> precision of the predictions is not "linear" or evenly spaced from
> left to right.
> 
> Can you supply the same calculations for some more meaningful
> combinations of success and fail?
> 
> When you do, let us see
> 
> mm
> 
> and
> 
> vcov(m1)
> 
> please.
> 
> 
>>> sqrt(pvar1)
>> [1] 0.5228946 0.5229200
>> 
>> #compare to
>> 
>>> m3=lmer(cbind(success,fail) ~ factor -1 + (1|spp/variable), bb, family='binomial')
>>> summary(m3)
>> ...
>> Fixed effects:
>>      Estimate Std. Error z value Pr(>|z|)
>> factor0    1.4383     0.5229   2.751  0.00595 **
>> factor1    1.6491     0.5229   3.154 0.00161 **
>> 
>> many thanks,
>> 
>> Abra?os,
>> Rafael Maia
>> ---
>> webpage: http://gozips.uakron.edu/~rm72
>> "A little learning is a dangerous thing; drink deep, or taste not the Pierian spring." (A. Pope)
>> Graduate Student - Integrated Bioscience
>> University of Akron
>> http://gozips.uakron.edu/~shawkey/
>> 
>> On Jun 21, 2012, at 10:48 PM, David Duffy wrote:
>> 
>>> 
>>> This is nothing to with mixed modelling per se, but how your contrasts for the fixed effects are set up.  If this was fixed effects only, you could fit -1 + factor (no intercept) to give estimates for each level of factor with standard errors that you could correctly interpret as you are trying to.  The FAQ (http://glmm.wikidot.com/faq) shows plotting of confidence intervals for predictions.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> -- 
> Paul E. Johnson
> Professor, Political Science    Assoc. Director
> 1541 Lilac Lane, Room 504     Center for Research Methods
> University of Kansas               University of Kansas
> http://pj.freefaculty.org            http://quant.ku.edu


From David.Duffy at qimr.edu.au  Fri Jun 22 07:00:53 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 22 Jun 2012 15:00:53 +1000 (EST)
Subject: [R-sig-ME] Understanding/plotting fixed effects estimates
	&standard errors
In-Reply-To: <7BDCEF9C-741D-41C4-A5D4-5E3A181AAB0A@yahoo.com.br>
References: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>
	<Pine.LNX.4.64.1206221218220.30121@orpheus.qimr.edu.au>
	<7BDCEF9C-741D-41C4-A5D4-5E3A181AAB0A@yahoo.com.br>
Message-ID: <Pine.LNX.4.64.1206221453590.4062@orpheus.qimr.edu.au>


Oops, I didn't even see that you presented the no-intercept results in 
your first email.  I would trust the LRTS results, I think. I would really 
need to see the data to get a feel for what is happening (like what is the 
number of trials etc).  Do you even need variable?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From gupta.anshul at live.in  Fri Jun 22 09:09:12 2012
From: gupta.anshul at live.in (Anshul Gupta)
Date: Fri, 22 Jun 2012 12:39:12 +0530
Subject: [R-sig-ME] lme4 Installation on R 2.13.2
Message-ID: <SNT109-W44B8B953A983F732A4D97A91FC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120622/e353a359/attachment.pl>

From s.chamaille at yahoo.fr  Fri Jun 22 09:09:23 2012
From: s.chamaille at yahoo.fr (Simon =?ISO-8859-1?Q?Chamaill=E9-Jammes?=)
Date: Fri, 22 Jun 2012 09:09:23 +0200
Subject: [R-sig-ME] Do glmer and glmmadmb calculate log likelihood on
 thesame scale ?
In-Reply-To: <CANz9Z_+DieCW7Lz=2gMVLW2Fy17jW8LvoBYhoEmchKfJmG8FnA@mail.gmail.com>
References: <1340312870.2169.18.camel@simon-laptop>
	<Pine.LNX.4.64.1206220716520.20618@orpheus.qimr.edu.au>
	<CANz9Z_+DieCW7Lz=2gMVLW2Fy17jW8LvoBYhoEmchKfJmG8FnA@mail.gmail.com>
Message-ID: <1340348963.1934.3.camel@simon-desktop>

Thanks David and Joshua, 
my model was for binomial family. I've just checked on a simpler model
and logLik is exactly similar between glmer and glmmadmb. So if one use
the same model design (accounting for things like those Joshua revealed)
one should be able to compare the logLik and deviance between the two
implementations.

simon

On Thu, 2012-06-21 at 17:24 -0700, Joshua Wiley wrote:
> Just a note that those are not the same models.  To match glmer() with
> glmmadmb(), try:
> 
> gm2 <- glmer(y~Base*trt+Age+Visit+(1 | Visit) + (0 + Visit|subject),
>   data=epil2, family=poisson())
> logLik(gm2)
> 
> which for me gives:
> 
> 'log Lik.' -421.1128 (df=8)
> 
> OR you could change glmmadmb() to
> 
> fm2 <- glmmadmb(y~Base*trt+Age+Visit+(Visit|subject),
>   data=epil2, family="poisson", corStruct = "full")
> 
> however, on my machine, there are warnings about the matrix not being
> positive definite, and the model never converges.  If it worked for
> you, I would be curious what version of glmmADMB you are using.  Here
> is my sessionInfo()
> 
> R Under development (unstable) (2012-05-22 r59410)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_0.999375-42  Matrix_1.0-7      lattice_0.20-6    glmmADMB_0.7.2.12
> [5] R2admb_0.7.5.2    MASS_7.3-18
> 
> loaded via a namespace (and not attached):
> [1] compiler_2.16.0 grid_2.16.0     nlme_3.1-104    stats4_2.16.0
> [5] tools_2.16.0
> 
> Cheers,
> 
> Josh
> 
> On Thu, Jun 21, 2012 at 2:22 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> > On Thu, 21 Jun 2012, Simon Chamaill?-Jammes wrote:
> >
> >> I would like to know if glmer and glmmadmb calculate log likelihood /
> >> deviance on the same scale.
> >>
> > What model family?
> >
> > data(epil2)
> > epil2$subject <- factor(epil2$subject)
> > fm2 <- glmmadmb(y~Base*trt+Age+Visit+(Visit|subject),
> >                data=epil2, family="poisson")
> > gm2 <- glmer(y~Base*trt+Age+Visit+(Visit|subject)
> >             data=epil2, family=poisson())
> > logLik(fm2)
> > 'log Lik.' -655.41 (df=8)
> > logLik(gm2)
> > 'log Lik.' -272.4573 (df=9)
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From romunov at gmail.com  Fri Jun 22 09:17:23 2012
From: romunov at gmail.com (romunov)
Date: Fri, 22 Jun 2012 09:17:23 +0200
Subject: [R-sig-ME] lme4 Installation on R 2.13.2
In-Reply-To: <SNT109-W44B8B953A983F732A4D97A91FC0@phx.gbl>
References: <SNT109-W44B8B953A983F732A4D97A91FC0@phx.gbl>
Message-ID: <CAHT1vphZXYCgyUX9-A-hzA+=c0ZA_v_VA5rw4BmvGOCG1VcMXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120622/7a900df4/attachment.pl>

From jwiley.psych at gmail.com  Fri Jun 22 09:45:23 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 22 Jun 2012 00:45:23 -0700
Subject: [R-sig-ME] Do glmer and glmmadmb calculate log likelihood on
 thesame scale ?
In-Reply-To: <Pine.LNX.4.64.1206221125560.30121@orpheus.qimr.edu.au>
References: <1340312870.2169.18.camel@simon-laptop>
	<Pine.LNX.4.64.1206220716520.20618@orpheus.qimr.edu.au>
	<CANz9Z_+DieCW7Lz=2gMVLW2Fy17jW8LvoBYhoEmchKfJmG8FnA@mail.gmail.com>
	<Pine.LNX.4.64.1206221125560.30121@orpheus.qimr.edu.au>
Message-ID: <CANz9Z_+ZYM91k5BEfqyiFQoLpM3oeztEWmRqyJqzbS_srBKWfA@mail.gmail.com>

Curious.  I so boldly stuck my foot in my mouth about using corStruct
= "full" to equate to glmer(), yet the log likelihood remains
unchanged using it or not in another case I ran where I could get the
model to converge.  Interestingly, a correlation is printed when
corStruct = "full", but somehow the log likelihood and model df do not
change?  I am adding Ben Bolker to this (although he probably would
have seen it soon enough anyway).  A) because it may be relevant that
your original model converges in an older version of glmmadmb, but not
the one I am using. B) because I do not understand why the correlation
among random effects does not seem to affect the log likelihood and
model df in glmmadmb but does in glmer.

glmmadmb(formula = y ~ Visit + (Visit | subject), data = epil2,
    family = "poisson", corStruct = "full")
gives:

Number of observations: total=236, subject=59
Random effect variance(s):
Group=subject
            Variance StdDev Corr
(Intercept) 0.8881   0.9424 (Intr)
Visit       0.5399   0.7348 0.5399

Log-likelihood: -686.899

glmer(y ~ Visit + (Visit|subject), data = epil2, family = "poisson")

gives:

   AIC   BIC logLik deviance
 617.9 635.2 -303.9    607.9
Random effects:
 Groups  Name        Variance Std.Dev. Corr
 subject (Intercept) 0.88772  0.94219
         Visit       0.53592  0.73206  -0.034
Number of obs: 236, groups: subject, 59


On Thu, Jun 21, 2012 at 7:13 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Thu, 21 Jun 2012, Joshua Wiley wrote:
>
>> Just a note that those are not the same models.
>
>
> Huh.
>
>
>> OR you could change glmmadmb() to
>>
>> fm2 <- glmmadmb(y~Base*trt+Age+Visit+(Visit|subject),
>> ?data=epil2, family="poisson", corStruct = "full")
>
>
>> however, on my machine, there are warnings about the matrix not being
>> positive definite, and the model never converges.
>
>
> I haven't updated glmmADMB recently (0.6.4 2011-08-30), so it
> gives the warning, but continues merrily to give:
>
> ? ? ? ? ? ?(Intercept) ? Visit
> (Intercept) ? ? 0.24931 0.24931
> Visit ? ? ? ? ? 0.54572 0.54572
>
> and the same likelihood as before
>
> Log-likelihood: -655.41
>
> glmer was
> ?Groups ?Name ? ? ? ?Variance Std.Dev. Corr
> ?subject (Intercept) 0.24912 ?0.49912
> ? ? ? ? Visit ? ? ? 0.53962 ?0.73459 ?0.011
> ?'log Lik.' -262.6586 (df=9)
>
> Your suggestion Visit + (1 | Visit) + (0 + Visit | subject) gave me
>
> ?Groups ?Name ? ? ? ?Variance ? Std.Dev.
> ?subject Visit ? ? ? 0.77301 ? ?0.87921
> ?Visit ? (Intercept) 5.1845e-16 2.2769e-08
> 'log Lik.' -421.1128 (df=8)
>
> I have to admit, the direction of the change in loglikelihood here confuses
> me a little ;)
>
> My lme4 is also a little antiquated: 0.999375-42 (2011-10-02).
>
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From jwiley.psych at gmail.com  Fri Jun 22 11:19:29 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 22 Jun 2012 02:19:29 -0700
Subject: [R-sig-ME] need help with predicted values from lmer with
	newdata
In-Reply-To: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
Message-ID: <CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>

Hi Paul,

I think this may be a bug in predict.merMod.  It is not terribly
elegant, but I suggest changing line 102 from:

re_new <- unlist(re_List[m])

to

re_new <- as.vector(do.call("rbind", re_List[m]))

I believe the issue with the current is that the random effects are
unlisted which essentially 'stacks' the vector, so you have the random
effects one at a time by effect, not by level (i.e., all intercepts,
then all slopes).  Later this is post multiplied by a matrix that is
sorted by level, the dimensions are correct so the matrices multiply
fine, but the results are not what I believe was intended.

I cannot see a way to add a patch to R-forge or submit a bug report so
I cced Doug on this.

Cheers,

Josh

On Thu, Jun 21, 2012 at 8:28 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Greetings.
>
> I'm getting some crazy results out of predict on an lmer model. ?I've
> gone through
> this lots of times, and feel certain I'm missing some obvious mistake.
> ?If you browse
> through and get to the bottom, there's some output that shows my predict output
> is just wrong, but I can't see why.
>
> I will send the first person with the right answer a new KU t-shirt in
> the size of
> your choice. ?That's better than "thanks in advance". Isn't it?
>
> ## Paul Johnson <pauljohn at ku.edu>
> ## 2012-06-21
>
> ## I want to compare the "separate ols regressions on clusters"
> ## results with the mixed model estimates. I've run into
> ## trouble because the output of predict with a newdata object
> ## seems to be completely wrong. ?I demonstrate "manual" calculations
> ## to try to convince you I understand what's going on (but
> ## peculiarity of predict output may make things appear otherwise).
>
> ## I pasted in some output at the bottom in case you just want to
> ## see where I think there is a problem.
>
> ## My system:
> ## > sessionInfo()
> ## R version 2.15.0 (2012-03-30)
> ## Platform: x86_64-pc-linux-gnu (64-bit)
>
> ## locale:
> ## ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> ## ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ## ?[5] LC_MONETARY=en_US.UTF-8 ? ?LC_MESSAGES=en_US.UTF-8
> ## ?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
> ## ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> ## attached base packages:
> ## [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> ## other attached packages:
> ## [1] lme4_0.999902344-0 Matrix_1.0-6 ? ? ? lattice_0.20-6 ? ? MASS_7.3-18
> ## loaded via a namespace (and not attached):
> ## [1] compiler_2.15.0 grid_2.15.0 ? ? minqa_1.2.1 ? ? nlme_3.1-104
> ## [5] splines_2.15.0 ?tools_2.15.0
>
>
> ## Topic: create multi-level data and use regression and lmer to
> ## estimate it. ?This creates 3 different dependent variables,
> ## y1: ordinary "homoskedastic" regression (no grouping effect)
> ## y2: clustered "random intercepts"
> ## y3: clustered "random intercepts" and "random slope" for 1 predictor (x1)
>
> library(MASS)
> set.seed(1234)
>
> ## Step 1. Create a Data Frame.
>
> ## M respondents, N observations for each one.
> ## In a repeated measures context, this is called "longitudinal data".
> ## In cross sectional approach, this is M groups (classrooms) with
> ## several people in each)
>
> M <- 10
> N <- 30
>
> ## get M unique gray colors, will use later for plotting
> grays <- gray.colors(M)
>
> ## Standard deviation of error term at individual level
> STDE <- 48
>
> ## STDEM: standard deviation of clustered intercepts.
> ### In a longitudinal "repeated measures" exercise, this is an
> ## individual-level effect. In a cross section, this is a random
> ## classroom effect.
> STDEM <- 30
>
> ## STEx1: standard deviation of slopes across cluster units
> STDEx1 <- 5
>
> ## The true effects of b0, b1, b2, b3 in
> ## y = b0 + b1*x1 + b2*x2 + b3*x3
> bslopes <- c(0.2, 15.4, -0.2, 3)
>
> ## Now generate the data frame with x1, x2 and x3.
> ## Let's suppose the predictors are Multivariate Normal, with
> ## means (100,200,150), standard deviations (10, 20, 30), and
> ## intercorrelations of 0.4. ?These can, of course, be adjusted
> ## for interesting variations.
>
> ## Mind, an "indicator" that says with which cluster an observation belongs.
> Mind <- 1:M %x% rep(1,N)
>
> means <- c(100, 200, 150)
> sds <- c(10, 20, 30)
> rho <- 0.4
> corr.mat <- matrix(c(1, rho, rho, rho, 1, rho, rho, rho, 1), nrow = 3)
> sigma <- diag(sds) %*% corr.mat %*% diag(sds)
> x.mat <- mvrnorm(n = N * M, mu = means, Sigma = sigma)
> dimnames(x.mat)[[2]] <- c("x1", "x2", "x3")
> ## Add an intercept on the front of x.mat
> x.mat <- cbind("(Intercept)"= 1, x.mat)
>
>
> ## Create a dependent variable that has no clustering effects. ?This
> ## is an "ordinary" regression with slopes and random error designated
> ## above random noise
> y1 <- x.mat %*% bslopes + rnorm(M*N, m=0, s= STDE)
> dat <- data.frame(id=1:(N*M), Mind, y1, as.data.frame(x.mat))
> rm(Mind, y1, x.mat) ## cleanup workspace
>
> ## Layer on additive group level error in y2
> ## Add a group-level intercept.
> ## A vector of M disturbances is created, and each is
> ## added to all N case within its cluster
> dat$y2 <- dat$y1 + ?rnorm(M, 0, STDEM) %x% rep(1, N)
>
> ## In y3, add in random slope effect
> ## are changing the slope for x1 from b1 to N(b1, STDEx1^2).
> ## Same as newb1 ~ b1 + N(0, STDEx1) * x1
> dat$y3 <- dat$y2 + ? (rnorm(M, 0, STDEx1) %x% rep(1, N)) * dat$x1
>
> ## In the lme4 package, there is an "easy" tool to run M separate lm regressions
> library(lme4)
>
> ##100 separate regressions, with 3 predictors
> m3list <- lmList(y3 ~ x1 + x2 + x3 | Mind, data=dat, pool = FALSE)
>
>
> ## Now I see a pattern. I'll use the unique range on x1 for each cluster
> ## I think that makes the lines look more "in" the data.
> plot(y3 ~ x1, data=dat, col=grays[Mind], main = "lm on clusters")
> for( i in seq_along(m3list)){
> ? ?m3mf <- model.frame(m3list[[i]]) #data set for group i
> ? ?x1range <- range(m3mf$x1) ## use group-specific ranges this time
> ? ?pgroup <- predict( m3list[[i]], newdata = data.frame(x1=x1range,
> x2=mean(m3mf$x2), x3=mean(m3mf$x3)))
> ? ?lines(x1range, pgroup, col=grays[i])
> }
>
> ## Hmm. That data looks like it might be handy for comparison later on.
> ## Build a data frame of it. I've never thought of doing this work
> ## cluster-by-cluster before.
>
> m3newdat <- lapply(m3list, function(x) {
> ? ?m3mf <- model.frame(x)
> ? ?ndf = data.frame(x1=range(m3mf$x1), x2=mean(m3mf$x2), x3=mean(m3mf$x3))
> ? ?ndf$m3pred <- predict(x, newdata = ndf)
> ? ?ndf} )
> ## Smash the list of data frames together
> m3newdat <- do.call("rbind", m3newdat)
> ## Interesting!
> m3newdat[1:20, ]
> ## Better add a variable Mind. This looks stupid, but works.
> m3newdat$Mind <- as.integer( do.call("rbind",
> strsplit(row.names(m3newdat), split="\\.", perl=T))[ ,1] )
>
>
> ## Draw new graphs on a new device, so we can compare
> dev.new()
>
> ## The "right" model allows the random effects to be correlated.
> mm4 <- lmer( y3 ~ x1 + x2 + x3 + (x1 | Mind), data=dat)
> summary(mm4)
>
>
>
> mm4ranef <- ranef(mm4, postVar = TRUE) ## a ranef.mer object, a list
> that includes one data frame
>
>
> ### What do the predicted values mean from lmer?
> ### here they are. But what do they include?
> head(mm4pred <- predict(mm4))
> tail(mm4pred <- predict(mm4))
>
>
> ## I can't tell what those numbers are. Can't be sure from ?predict.merMod
> ## So I'm going to go through the step-by-step
> ## process of calculating predicted values. These should follow a
> formula like this
> ## for model 4. j is the "cluster" index.
> ##
> ## ?j'th intercept ? ? ? ? ? ? ? ?j'th slope
> ## ?(b0 + raneff(intercept, j)) + (b1 + raneff(x1,j))*x1 + b2 x2 + b3 x3
>
> mm4b <- coef(summary(mm4))[ ,1]
> mm4vnames <- names(mm4b)
> mm4mm <- model.matrix(mm4) ## predictors
>
> ## Doing this bit by bit. First
> ## b0 + raneff(intercept, j)
> mm4inteffect <- mm4b["(Intercept)"] + ?mm4ranef[[1]][dat$Mind, 1]
> mm4x1effect <- mm4mm[ , c("x1")] * (mm4b["x1"] + mm4ranef[[1]][dat$Mind, 2])
> mm4pred2 <- mm4inteffect + mm4x1effect + ?mm4mm[ ,c("x2","x3") ] %*%
> mm4b[c("x2","x3")]
> head(mm4pred2)
> tail(mm4pred2)
>
> ## Aha! Those exactly match predict for mm4. So I understand what "predict" does
>
>
>
>
> ## Now, I want to run predict for some particular values of x1, x2, x3.
>
> ## Let's try running m3newdat through the predict function for mm4.
> m3newdat$mm4.3 <- predict(mm4, newdata = m3newdat)
> m3newdat
>
>
> ## Disaster. Predicted values completely out of whack. Lots of
> ## lines fall off the bottom of the graph.
>
> plot(y3 ~ x1, data=dat, col=grays[Mind], main="lmer mixed model predictions")
> by(m3newdat, m3newdat$Mind, function(x) { lines(x$x1, x$mm4.3,
> col=grays[x$Mind])})
>
>
> ## They don't match the manual calculations I perform here
> mm4b <- coef(summary(mm4))[ ,1]
> mm4vnames <- names(mm4b)
> mm4mm <- as.matrix(m3newdat)
>
> ## ?b0 + raneff(intercept, j)
> mm4inteffect <- mm4b["(Intercept)"] + rep(mm4ranef[[1]][, 1], each=2)
> mm4x1effect <- mm4mm[ , c("x1")] * rep(mm4b["x1"] + mm4ranef[[1]][, 2], each=2)
> mm4manualpred2 <- mm4inteffect + mm4x1effect + ?mm4mm[ ,c("x2","x3") ]
> %*% ?mm4b[c("x2","x3")]
>
> mm4mm <- cbind(as.data.frame(mm4mm), "mm4manualpred" = mm4manualpred2)
> mm4mm
>
> ## Here's what I see when I do that. m3pred: the lmList predictions.
> ## mm4manualpred: my "manual" calculations of predicted values for lmer mm4
> ## mm4.3 output from predict for same "newdat" used with mm4manualpred.
>
> ## > mm4mm
> ## ? ? ? ? ? ? x1 ? ? ? x2 ? ? ? x3 ? m3pred Mind ? ? ?mm4.3 mm4manualpred
> ## 1.1 ? 88.51074 196.0615 141.3859 1221.477 ? ?1 ?-434.7602 ? ? ?1239.152
> ## 1.2 ?110.88258 196.0615 141.3859 1483.957 ? ?1 ?-630.0463 ? ? ?1466.961
> ## 2.1 ? 80.26167 194.1252 133.7265 1405.672 ? ?2 ?-614.3256 ? ? ?1388.751
> ## 2.2 ?117.08533 194.1252 133.7265 1845.499 ? ?2 -1051.4105 ? ? ?1866.505
> ## 3.1 ? 80.84091 202.4517 154.3976 1302.205 ? ?3 ?3527.8154 ? ? ?1284.706
> ## 3.2 ?120.33775 202.4517 154.3976 1692.819 ? ?3 ?5037.6392 ? ? ?1717.210
> ## 4.1 ? 68.96320 204.5145 151.6662 1321.927 ? ?4 ?5097.5261 ? ? ?1379.251
> ## 4.2 ?120.17029 204.5145 151.6662 2137.589 ? ?4 ?8559.2362 ? ? ?2108.628
> ## 5.1 ? 84.85202 200.7799 153.1595 1821.135 ? ?5 ?4736.2240 ? ? ?1813.415
> ## 5.2 ?122.58730 200.7799 153.1595 2418.381 ? ?5 ?6641.2026 ? ? ?2426.855
> ## 6.1 ? 84.60214 202.3324 153.2583 2015.183 ? ?6 ?1521.6831 ? ? ?2001.700
> ## 6.2 ?128.13418 202.3324 153.2583 2778.684 ? ?6 ?2086.4726 ? ? ?2799.053
> ## 7.1 ? 74.73548 198.5761 155.8984 1780.196 ? ?7 ?1497.6761 ? ? ?1802.381
> ## 7.2 ?118.97636 198.5761 155.8984 2622.083 ? ?7 ?2127.8282 ? ? ?2603.626
> ## 8.1 ? 83.40882 200.4991 152.0515 2342.043 ? ?8 ?1954.4592 ? ? ?2323.477
> ## 8.2 ?118.73997 200.4991 152.0515 3088.686 ? ?8 ?2601.6007 ? ? ?3105.182
> ## 9.1 ? 82.48090 205.4736 152.2774 1979.852 ? ?9 ?2253.5650 ? ? ?1950.388
> ## 9.2 ?117.48279 205.4736 152.2774 2554.581 ? ?9 ?3027.9842 ? ? ?2587.319
> ## 10.1 ?84.77764 205.9689 152.3325 2256.434 ? 10 ?2236.3346 ? ? ?2268.620
> ## 10.2 119.66417 205.9689 152.3325 3022.053 ? 10 ?2980.1202 ? ? ?3012.406
>
>
> --
> Paul E. Johnson
> Professor, Political Science ? ?Assoc. Director
> 1541 Lilac Lane, Room 504 ? ? Center for Research Methods
> University of Kansas ? ? ? ? ? ? ? University of Kansas
> http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From b.pelzer at maw.ru.nl  Fri Jun 22 13:54:17 2012
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Fri, 22 Jun 2012 13:54:17 +0200
Subject: [R-sig-ME] 2-level null versus 1 level null model
In-Reply-To: <CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
	<CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
Message-ID: <4FE45CE9.5000707@maw.ru.nl>

Hi all,

This is probably a very basic question. I would like to test, using 
lmer, whether a 2-level null model (no covariates, only random 
intercept) has a better fit (lower deviance) than a 'flat' 1-level null 
model. My thought was to estimate both null models with lmer and then 
with anova(M02level, M01level) test for the significance of the 
chisquare difference. However, with lmer one cannot simply estimate a 
1-level model, as far as my knowledge goes... What I did to circumvent 
this was the followin, with Y being the dependent and country the 
level-2 identifier:

one <- rep(1, length(Y))

M01level <-  lmer (Y ~ (1 | one), REML=FALSE)
M02level <-  lmer (Y ~ (1 | one) + (1 | country), REML=FALSE)
anova(M02level, M01level)

This seams to work properly. However, I don't feel really convinced by 
this solution yet. Is it to be trusted, or is there a much simpler way 
to test this using lmer? Thanks for any help!!!

Ben.


From s.chamaille at yahoo.fr  Fri Jun 22 15:08:41 2012
From: s.chamaille at yahoo.fr (Simon =?ISO-8859-1?Q?Chamaill=E9-Jammes?=)
Date: Fri, 22 Jun 2012 15:08:41 +0200
Subject: [R-sig-ME] meaning of the use.u argument in bootMer and
	simulateMerMod
Message-ID: <1340370521.2108.2.camel@simon-desktop>

Hello all, 

recently I've been doing parametric boostrapping of glmer models (using
simulate/refit) to get confidence intervals for both fixed effect and
variance estimates. 

Yesterday I updated to the latest lme4 release on rforge, and discovered
(did I overlook it before?) the use.u argument in the bootMer function
(which is actually used in the simulateMerMod function called by
bootMer).

in bootMer the definition of the use.u argument (default is FALSE) is:
        
logical, indicating, if the spherized random effects should be
simulated / bootstrapped as well. If FALSE, they are not changed, and
all inference is conditional on these.

in simulateMerMod its definition (default is FALSE) is:
        
(logical) generate new random-effects values (FALSE) or generate a
simulation condition on the current random-effects estimates (TRUE)?

Despite these explanations I don't quite get what's actually done and
I'm feeling uneasy about what should be done when bootstrapping to
produce confidence intervals for variance estimates. So far I have
implicitly used the default use.u = FALSE. All examples found on various
discussion/help lists seem to happily avoid this issue, maybe rightly I
don't know.

Any clarification, and answer on am I doing it right or not, would be
welcome.

best,

simon

PS1/ If one use bootMer to perform semi-parametric bootstrapping and
use.u is TRUE (the only option for now with semi-par. bootstrap), then
residuals are randomly permuted and added to the fitted values.

PS2/ I believe what I'm asking here is related and similar to what was
asked here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/005049.html
which wasn't replied to (at least on the list).

PS3/ for my personal knowledge, I would be glad to get a hint on what
"spherized" random effects mean - google was of no help on this (which
somehow makes me feel good at times...)

PS4/ for those interested, usage of use.u = TRUE with observation-level
random effect or nested random effects is problematic, ie. does not run:
you get things like: 
Error in dim(val) <- c(n, nsim) : 
  dims [product 164] do not match the length of object [123]
In addition: Warning message:
In etasim.fix + etasim.reff :
  longer object length is not a multiple of shorter object length


From pauljohn32 at gmail.com  Fri Jun 22 16:44:55 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 22 Jun 2012 09:44:55 -0500
Subject: [R-sig-ME] need help with predicted values from lmer with
	newdata
In-Reply-To: <CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
	<CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
Message-ID: <CAErODj-+eQ3JOXYiDv8uto24MAtb_cDAgFazqLDEjxhGbvNnrQ@mail.gmail.com>

Confirmed. Follow-up below about how you edit predict.merMod

On Fri, Jun 22, 2012 at 4:19 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Paul,
>
> I think this may be a bug in predict.merMod. ?It is not terribly
> elegant, but I suggest changing line 102 from:
>
> re_new <- unlist(re_List[m])
>
> to
>
> re_new <- as.vector(do.call("rbind", re_List[m]))

Changing this resolves the anomaly I experience. If you mail me your
shirt size & mailing address, I will follow through on the shirt.
Official logo and all!

Now a more practical question. This is OT to mixed models, but is on
topic to Emacs and R and how-to revise lme4 objects to test variations
like the one you propose.

I'm using Emacs with ESS.  I learned in this email list that C-c C-d
can open a function and revise it, and then load it.  This is the
Emacs-ESS alternative to R's fix() function.

I have more and more trouble revising objects because more code is
written with non-exported functions and functions.

In order to follow your advice and revise predict.merMod, the only
thing I could think of was the following.

> mypredict <- lme4:::predict.merMod

Then I C-c C-d mypredict, and the re-load that, then change my usage
from predict(m4, ...) to mypredict.

This seemed like a childish way to get at it, I wondered how they are
doing it in the big leagues.

?

PJ


>
> I believe the issue with the current is that the random effects are
> unlisted which essentially 'stacks' the vector, so you have the random
> effects one at a time by effect, not by level (i.e., all intercepts,
> then all slopes). ?Later this is post multiplied by a matrix that is
> sorted by level, the dimensions are correct so the matrices multiply
> fine, but the results are not what I believe was intended.
>
> I cannot see a way to add a patch to R-forge or submit a bug report so
> I cced Doug on this.
>
> Cheers,
>
> Josh
>
> On Thu, Jun 21, 2012 at 8:28 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>> Greetings.
>>
>> I'm getting some crazy results out of predict on an lmer model. ?I've
>> gone through
>> this lots of times, and feel certain I'm missing some obvious mistake.
>> ?If you browse
>> through and get to the bottom, there's some output that shows my predict output
>> is just wrong, but I can't see why.
>>
>> I will send the first person with the right answer a new KU t-shirt in
>> the size of
>> your choice. ?That's better than "thanks in advance". Isn't it?
>>
>> ## Paul Johnson <pauljohn at ku.edu>
>> ## 2012-06-21
>>
>> ## I want to compare the "separate ols regressions on clusters"
>> ## results with the mixed model estimates. I've run into
>> ## trouble because the output of predict with a newdata object
>> ## seems to be completely wrong. ?I demonstrate "manual" calculations
>> ## to try to convince you I understand what's going on (but
>> ## peculiarity of predict output may make things appear otherwise).
>>
>> ## I pasted in some output at the bottom in case you just want to
>> ## see where I think there is a problem.
>>
>> ## My system:
>> ## > sessionInfo()
>> ## R version 2.15.0 (2012-03-30)
>> ## Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> ## locale:
>> ## ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>> ## ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>> ## ?[5] LC_MONETARY=en_US.UTF-8 ? ?LC_MESSAGES=en_US.UTF-8
>> ## ?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
>> ## ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> ## attached base packages:
>> ## [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> ## other attached packages:
>> ## [1] lme4_0.999902344-0 Matrix_1.0-6 ? ? ? lattice_0.20-6 ? ? MASS_7.3-18
>> ## loaded via a namespace (and not attached):
>> ## [1] compiler_2.15.0 grid_2.15.0 ? ? minqa_1.2.1 ? ? nlme_3.1-104
>> ## [5] splines_2.15.0 ?tools_2.15.0
>>
>>
>> ## Topic: create multi-level data and use regression and lmer to
>> ## estimate it. ?This creates 3 different dependent variables,
>> ## y1: ordinary "homoskedastic" regression (no grouping effect)
>> ## y2: clustered "random intercepts"
>> ## y3: clustered "random intercepts" and "random slope" for 1 predictor (x1)
>>
>> library(MASS)
>> set.seed(1234)
>>
>> ## Step 1. Create a Data Frame.
>>
>> ## M respondents, N observations for each one.
>> ## In a repeated measures context, this is called "longitudinal data".
>> ## In cross sectional approach, this is M groups (classrooms) with
>> ## several people in each)
>>
>> M <- 10
>> N <- 30
>>
>> ## get M unique gray colors, will use later for plotting
>> grays <- gray.colors(M)
>>
>> ## Standard deviation of error term at individual level
>> STDE <- 48
>>
>> ## STDEM: standard deviation of clustered intercepts.
>> ### In a longitudinal "repeated measures" exercise, this is an
>> ## individual-level effect. In a cross section, this is a random
>> ## classroom effect.
>> STDEM <- 30
>>
>> ## STEx1: standard deviation of slopes across cluster units
>> STDEx1 <- 5
>>
>> ## The true effects of b0, b1, b2, b3 in
>> ## y = b0 + b1*x1 + b2*x2 + b3*x3
>> bslopes <- c(0.2, 15.4, -0.2, 3)
>>
>> ## Now generate the data frame with x1, x2 and x3.
>> ## Let's suppose the predictors are Multivariate Normal, with
>> ## means (100,200,150), standard deviations (10, 20, 30), and
>> ## intercorrelations of 0.4. ?These can, of course, be adjusted
>> ## for interesting variations.
>>
>> ## Mind, an "indicator" that says with which cluster an observation belongs.
>> Mind <- 1:M %x% rep(1,N)
>>
>> means <- c(100, 200, 150)
>> sds <- c(10, 20, 30)
>> rho <- 0.4
>> corr.mat <- matrix(c(1, rho, rho, rho, 1, rho, rho, rho, 1), nrow = 3)
>> sigma <- diag(sds) %*% corr.mat %*% diag(sds)
>> x.mat <- mvrnorm(n = N * M, mu = means, Sigma = sigma)
>> dimnames(x.mat)[[2]] <- c("x1", "x2", "x3")
>> ## Add an intercept on the front of x.mat
>> x.mat <- cbind("(Intercept)"= 1, x.mat)
>>
>>
>> ## Create a dependent variable that has no clustering effects. ?This
>> ## is an "ordinary" regression with slopes and random error designated
>> ## above random noise
>> y1 <- x.mat %*% bslopes + rnorm(M*N, m=0, s= STDE)
>> dat <- data.frame(id=1:(N*M), Mind, y1, as.data.frame(x.mat))
>> rm(Mind, y1, x.mat) ## cleanup workspace
>>
>> ## Layer on additive group level error in y2
>> ## Add a group-level intercept.
>> ## A vector of M disturbances is created, and each is
>> ## added to all N case within its cluster
>> dat$y2 <- dat$y1 + ?rnorm(M, 0, STDEM) %x% rep(1, N)
>>
>> ## In y3, add in random slope effect
>> ## are changing the slope for x1 from b1 to N(b1, STDEx1^2).
>> ## Same as newb1 ~ b1 + N(0, STDEx1) * x1
>> dat$y3 <- dat$y2 + ? (rnorm(M, 0, STDEx1) %x% rep(1, N)) * dat$x1
>>
>> ## In the lme4 package, there is an "easy" tool to run M separate lm regressions
>> library(lme4)
>>
>> ##100 separate regressions, with 3 predictors
>> m3list <- lmList(y3 ~ x1 + x2 + x3 | Mind, data=dat, pool = FALSE)
>>
>>
>> ## Now I see a pattern. I'll use the unique range on x1 for each cluster
>> ## I think that makes the lines look more "in" the data.
>> plot(y3 ~ x1, data=dat, col=grays[Mind], main = "lm on clusters")
>> for( i in seq_along(m3list)){
>> ? ?m3mf <- model.frame(m3list[[i]]) #data set for group i
>> ? ?x1range <- range(m3mf$x1) ## use group-specific ranges this time
>> ? ?pgroup <- predict( m3list[[i]], newdata = data.frame(x1=x1range,
>> x2=mean(m3mf$x2), x3=mean(m3mf$x3)))
>> ? ?lines(x1range, pgroup, col=grays[i])
>> }
>>
>> ## Hmm. That data looks like it might be handy for comparison later on.
>> ## Build a data frame of it. I've never thought of doing this work
>> ## cluster-by-cluster before.
>>
>> m3newdat <- lapply(m3list, function(x) {
>> ? ?m3mf <- model.frame(x)
>> ? ?ndf = data.frame(x1=range(m3mf$x1), x2=mean(m3mf$x2), x3=mean(m3mf$x3))
>> ? ?ndf$m3pred <- predict(x, newdata = ndf)
>> ? ?ndf} )
>> ## Smash the list of data frames together
>> m3newdat <- do.call("rbind", m3newdat)
>> ## Interesting!
>> m3newdat[1:20, ]
>> ## Better add a variable Mind. This looks stupid, but works.
>> m3newdat$Mind <- as.integer( do.call("rbind",
>> strsplit(row.names(m3newdat), split="\\.", perl=T))[ ,1] )
>>
>>
>> ## Draw new graphs on a new device, so we can compare
>> dev.new()
>>
>> ## The "right" model allows the random effects to be correlated.
>> mm4 <- lmer( y3 ~ x1 + x2 + x3 + (x1 | Mind), data=dat)
>> summary(mm4)
>>
>>
>>
>> mm4ranef <- ranef(mm4, postVar = TRUE) ## a ranef.mer object, a list
>> that includes one data frame
>>
>>
>> ### What do the predicted values mean from lmer?
>> ### here they are. But what do they include?
>> head(mm4pred <- predict(mm4))
>> tail(mm4pred <- predict(mm4))
>>
>>
>> ## I can't tell what those numbers are. Can't be sure from ?predict.merMod
>> ## So I'm going to go through the step-by-step
>> ## process of calculating predicted values. These should follow a
>> formula like this
>> ## for model 4. j is the "cluster" index.
>> ##
>> ## ?j'th intercept ? ? ? ? ? ? ? ?j'th slope
>> ## ?(b0 + raneff(intercept, j)) + (b1 + raneff(x1,j))*x1 + b2 x2 + b3 x3
>>
>> mm4b <- coef(summary(mm4))[ ,1]
>> mm4vnames <- names(mm4b)
>> mm4mm <- model.matrix(mm4) ## predictors
>>
>> ## Doing this bit by bit. First
>> ## b0 + raneff(intercept, j)
>> mm4inteffect <- mm4b["(Intercept)"] + ?mm4ranef[[1]][dat$Mind, 1]
>> mm4x1effect <- mm4mm[ , c("x1")] * (mm4b["x1"] + mm4ranef[[1]][dat$Mind, 2])
>> mm4pred2 <- mm4inteffect + mm4x1effect + ?mm4mm[ ,c("x2","x3") ] %*%
>> mm4b[c("x2","x3")]
>> head(mm4pred2)
>> tail(mm4pred2)
>>
>> ## Aha! Those exactly match predict for mm4. So I understand what "predict" does
>>
>>
>>
>>
>> ## Now, I want to run predict for some particular values of x1, x2, x3.
>>
>> ## Let's try running m3newdat through the predict function for mm4.
>> m3newdat$mm4.3 <- predict(mm4, newdata = m3newdat)
>> m3newdat
>>
>>
>> ## Disaster. Predicted values completely out of whack. Lots of
>> ## lines fall off the bottom of the graph.
>>
>> plot(y3 ~ x1, data=dat, col=grays[Mind], main="lmer mixed model predictions")
>> by(m3newdat, m3newdat$Mind, function(x) { lines(x$x1, x$mm4.3,
>> col=grays[x$Mind])})
>>
>>
>> ## They don't match the manual calculations I perform here
>> mm4b <- coef(summary(mm4))[ ,1]
>> mm4vnames <- names(mm4b)
>> mm4mm <- as.matrix(m3newdat)
>>
>> ## ?b0 + raneff(intercept, j)
>> mm4inteffect <- mm4b["(Intercept)"] + rep(mm4ranef[[1]][, 1], each=2)
>> mm4x1effect <- mm4mm[ , c("x1")] * rep(mm4b["x1"] + mm4ranef[[1]][, 2], each=2)
>> mm4manualpred2 <- mm4inteffect + mm4x1effect + ?mm4mm[ ,c("x2","x3") ]
>> %*% ?mm4b[c("x2","x3")]
>>
>> mm4mm <- cbind(as.data.frame(mm4mm), "mm4manualpred" = mm4manualpred2)
>> mm4mm
>>
>> ## Here's what I see when I do that. m3pred: the lmList predictions.
>> ## mm4manualpred: my "manual" calculations of predicted values for lmer mm4
>> ## mm4.3 output from predict for same "newdat" used with mm4manualpred.
>>
>> ## > mm4mm
>> ## ? ? ? ? ? ? x1 ? ? ? x2 ? ? ? x3 ? m3pred Mind ? ? ?mm4.3 mm4manualpred
>> ## 1.1 ? 88.51074 196.0615 141.3859 1221.477 ? ?1 ?-434.7602 ? ? ?1239.152
>> ## 1.2 ?110.88258 196.0615 141.3859 1483.957 ? ?1 ?-630.0463 ? ? ?1466.961
>> ## 2.1 ? 80.26167 194.1252 133.7265 1405.672 ? ?2 ?-614.3256 ? ? ?1388.751
>> ## 2.2 ?117.08533 194.1252 133.7265 1845.499 ? ?2 -1051.4105 ? ? ?1866.505
>> ## 3.1 ? 80.84091 202.4517 154.3976 1302.205 ? ?3 ?3527.8154 ? ? ?1284.706
>> ## 3.2 ?120.33775 202.4517 154.3976 1692.819 ? ?3 ?5037.6392 ? ? ?1717.210
>> ## 4.1 ? 68.96320 204.5145 151.6662 1321.927 ? ?4 ?5097.5261 ? ? ?1379.251
>> ## 4.2 ?120.17029 204.5145 151.6662 2137.589 ? ?4 ?8559.2362 ? ? ?2108.628
>> ## 5.1 ? 84.85202 200.7799 153.1595 1821.135 ? ?5 ?4736.2240 ? ? ?1813.415
>> ## 5.2 ?122.58730 200.7799 153.1595 2418.381 ? ?5 ?6641.2026 ? ? ?2426.855
>> ## 6.1 ? 84.60214 202.3324 153.2583 2015.183 ? ?6 ?1521.6831 ? ? ?2001.700
>> ## 6.2 ?128.13418 202.3324 153.2583 2778.684 ? ?6 ?2086.4726 ? ? ?2799.053
>> ## 7.1 ? 74.73548 198.5761 155.8984 1780.196 ? ?7 ?1497.6761 ? ? ?1802.381
>> ## 7.2 ?118.97636 198.5761 155.8984 2622.083 ? ?7 ?2127.8282 ? ? ?2603.626
>> ## 8.1 ? 83.40882 200.4991 152.0515 2342.043 ? ?8 ?1954.4592 ? ? ?2323.477
>> ## 8.2 ?118.73997 200.4991 152.0515 3088.686 ? ?8 ?2601.6007 ? ? ?3105.182
>> ## 9.1 ? 82.48090 205.4736 152.2774 1979.852 ? ?9 ?2253.5650 ? ? ?1950.388
>> ## 9.2 ?117.48279 205.4736 152.2774 2554.581 ? ?9 ?3027.9842 ? ? ?2587.319
>> ## 10.1 ?84.77764 205.9689 152.3325 2256.434 ? 10 ?2236.3346 ? ? ?2268.620
>> ## 10.2 119.66417 205.9689 152.3325 3022.053 ? 10 ?2980.1202 ? ? ?3012.406
>>
>>
>> --
>> Paul E. Johnson
>> Professor, Political Science ? ?Assoc. Director
>> 1541 Lilac Lane, Room 504 ? ? Center for Research Methods
>> University of Kansas ? ? ? ? ? ? ? University of Kansas
>> http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/



-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From pauljohn32 at gmail.com  Fri Jun 22 17:21:31 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 22 Jun 2012 10:21:31 -0500
Subject: [R-sig-ME] Understanding/plotting fixed effects estimates
 &standard errors
In-Reply-To: <Pine.LNX.4.64.1206221453590.4062@orpheus.qimr.edu.au>
References: <E4CA60D2-BA47-4CF2-BB78-98A1BFFBDA64@yahoo.com.br>
	<Pine.LNX.4.64.1206221218220.30121@orpheus.qimr.edu.au>
	<7BDCEF9C-741D-41C4-A5D4-5E3A181AAB0A@yahoo.com.br>
	<Pine.LNX.4.64.1206221453590.4062@orpheus.qimr.edu.au>
Message-ID: <CAErODj8KkZYGqRoS8ikCvviq42sK-gsqccSnnYjokjKESNd=Ug@mail.gmail.com>

I woke up this morning and realized I had given you bad advice.
changing the success/fail has no effect on the predictions, as you
found.

you need to put in alternate values of the estimated intercept.
Recall a logistic curve is S shaped. I suspect the intercept you are
using is placing you on the far left or right, where the effect of
change is not substantial. If you adjust the intercept estimate from
low to high, then you will see differences.

Think of this like a linear model, where the confidence interval is an
hour-glass shaped thing.  If you move from left to right, it shrinks
and grows.  Look on slide  37 in this lecture:
http://pj.freefaculty.org/guides/stat/Regression/ElementaryOLS/Regression-2-lecture.pdf
if you don't remember the hourglass

I believe similar is happening in your situation.  The difference is
that the left-and-right movement of the predicted value is driven by
your intercept.  The random effect affects the intercept, so in some
conditions the effect is larger than others, and the standard error
should also change.

On Fri, Jun 22, 2012 at 12:00 AM, David Duffy <David.Duffy at qimr.edu.au> wrote:
>
> Oops, I didn't even see that you presented the no-intercept results in your
> first email. ?I would trust the LRTS results, I think. I would really need
> to see the data to get a feel for what is happening (like what is the number
> of trials etc). ?Do you even need variable?
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From jwiley.psych at gmail.com  Fri Jun 22 17:40:01 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 22 Jun 2012 08:40:01 -0700
Subject: [R-sig-ME] need help with predicted values from lmer with
	newdata
In-Reply-To: <CAErODj-+eQ3JOXYiDv8uto24MAtb_cDAgFazqLDEjxhGbvNnrQ@mail.gmail.com>
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
	<CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
	<CAErODj-+eQ3JOXYiDv8uto24MAtb_cDAgFazqLDEjxhGbvNnrQ@mail.gmail.com>
Message-ID: <CANz9Z_+soBzUAqPUnc-FM3dwjF43ha4zrcpZSw3ocFXcWX8PeA@mail.gmail.com>

Hi Paul,

I am not sure how to use C-c C-d with namespaces and unexported
objects.  I might suggest though that for the assignment, you do
something like:

assignInNamespace("predict.merMod", mypredict, envir =
as.environment("package:lme4"))

It is not an issue in this case, but it can be if mypredict calls
functions that are availabe from lme4 but not to functions in the
global environment.  I am not a big leaguer though so cannot give you
really definitive advice.

Regarding the shirt, give some free help to a local student (or
charity), and I will consider us even :)

Cheers,

Josh

On Fri, Jun 22, 2012 at 7:44 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Confirmed. Follow-up below about how you edit predict.merMod
>
> On Fri, Jun 22, 2012 at 4:19 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>> Hi Paul,
>>
>> I think this may be a bug in predict.merMod. ?It is not terribly
>> elegant, but I suggest changing line 102 from:
>>
>> re_new <- unlist(re_List[m])
>>
>> to
>>
>> re_new <- as.vector(do.call("rbind", re_List[m]))
>
> Changing this resolves the anomaly I experience. If you mail me your
> shirt size & mailing address, I will follow through on the shirt.
> Official logo and all!
>
> Now a more practical question. This is OT to mixed models, but is on
> topic to Emacs and R and how-to revise lme4 objects to test variations
> like the one you propose.
>
> I'm using Emacs with ESS. ?I learned in this email list that C-c C-d
> can open a function and revise it, and then load it. ?This is the
> Emacs-ESS alternative to R's fix() function.
>
> I have more and more trouble revising objects because more code is
> written with non-exported functions and functions.
>
> In order to follow your advice and revise predict.merMod, the only
> thing I could think of was the following.
>
>> mypredict <- lme4:::predict.merMod
>
> Then I C-c C-d mypredict, and the re-load that, then change my usage
> from predict(m4, ...) to mypredict.
>
> This seemed like a childish way to get at it, I wondered how they are
> doing it in the big leagues.
>
> ?
>
> PJ
>
>
>>
>> I believe the issue with the current is that the random effects are
>> unlisted which essentially 'stacks' the vector, so you have the random
>> effects one at a time by effect, not by level (i.e., all intercepts,
>> then all slopes). ?Later this is post multiplied by a matrix that is
>> sorted by level, the dimensions are correct so the matrices multiply
>> fine, but the results are not what I believe was intended.
>>
>> I cannot see a way to add a patch to R-forge or submit a bug report so
>> I cced Doug on this.
>>
>> Cheers,
>>
>> Josh
>>
>> On Thu, Jun 21, 2012 at 8:28 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>> Greetings.
>>>
>>> I'm getting some crazy results out of predict on an lmer model. ?I've
>>> gone through
>>> this lots of times, and feel certain I'm missing some obvious mistake.
>>> ?If you browse
>>> through and get to the bottom, there's some output that shows my predict output
>>> is just wrong, but I can't see why.
>>>
>>> I will send the first person with the right answer a new KU t-shirt in
>>> the size of
>>> your choice. ?That's better than "thanks in advance". Isn't it?
>>>
>>> ## Paul Johnson <pauljohn at ku.edu>
>>> ## 2012-06-21
>>>
>>> ## I want to compare the "separate ols regressions on clusters"
>>> ## results with the mixed model estimates. I've run into
>>> ## trouble because the output of predict with a newdata object
>>> ## seems to be completely wrong. ?I demonstrate "manual" calculations
>>> ## to try to convince you I understand what's going on (but
>>> ## peculiarity of predict output may make things appear otherwise).
>>>
>>> ## I pasted in some output at the bottom in case you just want to
>>> ## see where I think there is a problem.
>>>
>>> ## My system:
>>> ## > sessionInfo()
>>> ## R version 2.15.0 (2012-03-30)
>>> ## Platform: x86_64-pc-linux-gnu (64-bit)
>>>
>>> ## locale:
>>> ## ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>>> ## ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>>> ## ?[5] LC_MONETARY=en_US.UTF-8 ? ?LC_MESSAGES=en_US.UTF-8
>>> ## ?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
>>> ## ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>>> ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> ## attached base packages:
>>> ## [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> ## other attached packages:
>>> ## [1] lme4_0.999902344-0 Matrix_1.0-6 ? ? ? lattice_0.20-6 ? ? MASS_7.3-18
>>> ## loaded via a namespace (and not attached):
>>> ## [1] compiler_2.15.0 grid_2.15.0 ? ? minqa_1.2.1 ? ? nlme_3.1-104
>>> ## [5] splines_2.15.0 ?tools_2.15.0
>>>
>>>
>>> ## Topic: create multi-level data and use regression and lmer to
>>> ## estimate it. ?This creates 3 different dependent variables,
>>> ## y1: ordinary "homoskedastic" regression (no grouping effect)
>>> ## y2: clustered "random intercepts"
>>> ## y3: clustered "random intercepts" and "random slope" for 1 predictor (x1)
>>>
>>> library(MASS)
>>> set.seed(1234)
>>>
>>> ## Step 1. Create a Data Frame.
>>>
>>> ## M respondents, N observations for each one.
>>> ## In a repeated measures context, this is called "longitudinal data".
>>> ## In cross sectional approach, this is M groups (classrooms) with
>>> ## several people in each)
>>>
>>> M <- 10
>>> N <- 30
>>>
>>> ## get M unique gray colors, will use later for plotting
>>> grays <- gray.colors(M)
>>>
>>> ## Standard deviation of error term at individual level
>>> STDE <- 48
>>>
>>> ## STDEM: standard deviation of clustered intercepts.
>>> ### In a longitudinal "repeated measures" exercise, this is an
>>> ## individual-level effect. In a cross section, this is a random
>>> ## classroom effect.
>>> STDEM <- 30
>>>
>>> ## STEx1: standard deviation of slopes across cluster units
>>> STDEx1 <- 5
>>>
>>> ## The true effects of b0, b1, b2, b3 in
>>> ## y = b0 + b1*x1 + b2*x2 + b3*x3
>>> bslopes <- c(0.2, 15.4, -0.2, 3)
>>>
>>> ## Now generate the data frame with x1, x2 and x3.
>>> ## Let's suppose the predictors are Multivariate Normal, with
>>> ## means (100,200,150), standard deviations (10, 20, 30), and
>>> ## intercorrelations of 0.4. ?These can, of course, be adjusted
>>> ## for interesting variations.
>>>
>>> ## Mind, an "indicator" that says with which cluster an observation belongs.
>>> Mind <- 1:M %x% rep(1,N)
>>>
>>> means <- c(100, 200, 150)
>>> sds <- c(10, 20, 30)
>>> rho <- 0.4
>>> corr.mat <- matrix(c(1, rho, rho, rho, 1, rho, rho, rho, 1), nrow = 3)
>>> sigma <- diag(sds) %*% corr.mat %*% diag(sds)
>>> x.mat <- mvrnorm(n = N * M, mu = means, Sigma = sigma)
>>> dimnames(x.mat)[[2]] <- c("x1", "x2", "x3")
>>> ## Add an intercept on the front of x.mat
>>> x.mat <- cbind("(Intercept)"= 1, x.mat)
>>>
>>>
>>> ## Create a dependent variable that has no clustering effects. ?This
>>> ## is an "ordinary" regression with slopes and random error designated
>>> ## above random noise
>>> y1 <- x.mat %*% bslopes + rnorm(M*N, m=0, s= STDE)
>>> dat <- data.frame(id=1:(N*M), Mind, y1, as.data.frame(x.mat))
>>> rm(Mind, y1, x.mat) ## cleanup workspace
>>>
>>> ## Layer on additive group level error in y2
>>> ## Add a group-level intercept.
>>> ## A vector of M disturbances is created, and each is
>>> ## added to all N case within its cluster
>>> dat$y2 <- dat$y1 + ?rnorm(M, 0, STDEM) %x% rep(1, N)
>>>
>>> ## In y3, add in random slope effect
>>> ## are changing the slope for x1 from b1 to N(b1, STDEx1^2).
>>> ## Same as newb1 ~ b1 + N(0, STDEx1) * x1
>>> dat$y3 <- dat$y2 + ? (rnorm(M, 0, STDEx1) %x% rep(1, N)) * dat$x1
>>>
>>> ## In the lme4 package, there is an "easy" tool to run M separate lm regressions
>>> library(lme4)
>>>
>>> ##100 separate regressions, with 3 predictors
>>> m3list <- lmList(y3 ~ x1 + x2 + x3 | Mind, data=dat, pool = FALSE)
>>>
>>>
>>> ## Now I see a pattern. I'll use the unique range on x1 for each cluster
>>> ## I think that makes the lines look more "in" the data.
>>> plot(y3 ~ x1, data=dat, col=grays[Mind], main = "lm on clusters")
>>> for( i in seq_along(m3list)){
>>> ? ?m3mf <- model.frame(m3list[[i]]) #data set for group i
>>> ? ?x1range <- range(m3mf$x1) ## use group-specific ranges this time
>>> ? ?pgroup <- predict( m3list[[i]], newdata = data.frame(x1=x1range,
>>> x2=mean(m3mf$x2), x3=mean(m3mf$x3)))
>>> ? ?lines(x1range, pgroup, col=grays[i])
>>> }
>>>
>>> ## Hmm. That data looks like it might be handy for comparison later on.
>>> ## Build a data frame of it. I've never thought of doing this work
>>> ## cluster-by-cluster before.
>>>
>>> m3newdat <- lapply(m3list, function(x) {
>>> ? ?m3mf <- model.frame(x)
>>> ? ?ndf = data.frame(x1=range(m3mf$x1), x2=mean(m3mf$x2), x3=mean(m3mf$x3))
>>> ? ?ndf$m3pred <- predict(x, newdata = ndf)
>>> ? ?ndf} )
>>> ## Smash the list of data frames together
>>> m3newdat <- do.call("rbind", m3newdat)
>>> ## Interesting!
>>> m3newdat[1:20, ]
>>> ## Better add a variable Mind. This looks stupid, but works.
>>> m3newdat$Mind <- as.integer( do.call("rbind",
>>> strsplit(row.names(m3newdat), split="\\.", perl=T))[ ,1] )
>>>
>>>
>>> ## Draw new graphs on a new device, so we can compare
>>> dev.new()
>>>
>>> ## The "right" model allows the random effects to be correlated.
>>> mm4 <- lmer( y3 ~ x1 + x2 + x3 + (x1 | Mind), data=dat)
>>> summary(mm4)
>>>
>>>
>>>
>>> mm4ranef <- ranef(mm4, postVar = TRUE) ## a ranef.mer object, a list
>>> that includes one data frame
>>>
>>>
>>> ### What do the predicted values mean from lmer?
>>> ### here they are. But what do they include?
>>> head(mm4pred <- predict(mm4))
>>> tail(mm4pred <- predict(mm4))
>>>
>>>
>>> ## I can't tell what those numbers are. Can't be sure from ?predict.merMod
>>> ## So I'm going to go through the step-by-step
>>> ## process of calculating predicted values. These should follow a
>>> formula like this
>>> ## for model 4. j is the "cluster" index.
>>> ##
>>> ## ?j'th intercept ? ? ? ? ? ? ? ?j'th slope
>>> ## ?(b0 + raneff(intercept, j)) + (b1 + raneff(x1,j))*x1 + b2 x2 + b3 x3
>>>
>>> mm4b <- coef(summary(mm4))[ ,1]
>>> mm4vnames <- names(mm4b)
>>> mm4mm <- model.matrix(mm4) ## predictors
>>>
>>> ## Doing this bit by bit. First
>>> ## b0 + raneff(intercept, j)
>>> mm4inteffect <- mm4b["(Intercept)"] + ?mm4ranef[[1]][dat$Mind, 1]
>>> mm4x1effect <- mm4mm[ , c("x1")] * (mm4b["x1"] + mm4ranef[[1]][dat$Mind, 2])
>>> mm4pred2 <- mm4inteffect + mm4x1effect + ?mm4mm[ ,c("x2","x3") ] %*%
>>> mm4b[c("x2","x3")]
>>> head(mm4pred2)
>>> tail(mm4pred2)
>>>
>>> ## Aha! Those exactly match predict for mm4. So I understand what "predict" does
>>>
>>>
>>>
>>>
>>> ## Now, I want to run predict for some particular values of x1, x2, x3.
>>>
>>> ## Let's try running m3newdat through the predict function for mm4.
>>> m3newdat$mm4.3 <- predict(mm4, newdata = m3newdat)
>>> m3newdat
>>>
>>>
>>> ## Disaster. Predicted values completely out of whack. Lots of
>>> ## lines fall off the bottom of the graph.
>>>
>>> plot(y3 ~ x1, data=dat, col=grays[Mind], main="lmer mixed model predictions")
>>> by(m3newdat, m3newdat$Mind, function(x) { lines(x$x1, x$mm4.3,
>>> col=grays[x$Mind])})
>>>
>>>
>>> ## They don't match the manual calculations I perform here
>>> mm4b <- coef(summary(mm4))[ ,1]
>>> mm4vnames <- names(mm4b)
>>> mm4mm <- as.matrix(m3newdat)
>>>
>>> ## ?b0 + raneff(intercept, j)
>>> mm4inteffect <- mm4b["(Intercept)"] + rep(mm4ranef[[1]][, 1], each=2)
>>> mm4x1effect <- mm4mm[ , c("x1")] * rep(mm4b["x1"] + mm4ranef[[1]][, 2], each=2)
>>> mm4manualpred2 <- mm4inteffect + mm4x1effect + ?mm4mm[ ,c("x2","x3") ]
>>> %*% ?mm4b[c("x2","x3")]
>>>
>>> mm4mm <- cbind(as.data.frame(mm4mm), "mm4manualpred" = mm4manualpred2)
>>> mm4mm
>>>
>>> ## Here's what I see when I do that. m3pred: the lmList predictions.
>>> ## mm4manualpred: my "manual" calculations of predicted values for lmer mm4
>>> ## mm4.3 output from predict for same "newdat" used with mm4manualpred.
>>>
>>> ## > mm4mm
>>> ## ? ? ? ? ? ? x1 ? ? ? x2 ? ? ? x3 ? m3pred Mind ? ? ?mm4.3 mm4manualpred
>>> ## 1.1 ? 88.51074 196.0615 141.3859 1221.477 ? ?1 ?-434.7602 ? ? ?1239.152
>>> ## 1.2 ?110.88258 196.0615 141.3859 1483.957 ? ?1 ?-630.0463 ? ? ?1466.961
>>> ## 2.1 ? 80.26167 194.1252 133.7265 1405.672 ? ?2 ?-614.3256 ? ? ?1388.751
>>> ## 2.2 ?117.08533 194.1252 133.7265 1845.499 ? ?2 -1051.4105 ? ? ?1866.505
>>> ## 3.1 ? 80.84091 202.4517 154.3976 1302.205 ? ?3 ?3527.8154 ? ? ?1284.706
>>> ## 3.2 ?120.33775 202.4517 154.3976 1692.819 ? ?3 ?5037.6392 ? ? ?1717.210
>>> ## 4.1 ? 68.96320 204.5145 151.6662 1321.927 ? ?4 ?5097.5261 ? ? ?1379.251
>>> ## 4.2 ?120.17029 204.5145 151.6662 2137.589 ? ?4 ?8559.2362 ? ? ?2108.628
>>> ## 5.1 ? 84.85202 200.7799 153.1595 1821.135 ? ?5 ?4736.2240 ? ? ?1813.415
>>> ## 5.2 ?122.58730 200.7799 153.1595 2418.381 ? ?5 ?6641.2026 ? ? ?2426.855
>>> ## 6.1 ? 84.60214 202.3324 153.2583 2015.183 ? ?6 ?1521.6831 ? ? ?2001.700
>>> ## 6.2 ?128.13418 202.3324 153.2583 2778.684 ? ?6 ?2086.4726 ? ? ?2799.053
>>> ## 7.1 ? 74.73548 198.5761 155.8984 1780.196 ? ?7 ?1497.6761 ? ? ?1802.381
>>> ## 7.2 ?118.97636 198.5761 155.8984 2622.083 ? ?7 ?2127.8282 ? ? ?2603.626
>>> ## 8.1 ? 83.40882 200.4991 152.0515 2342.043 ? ?8 ?1954.4592 ? ? ?2323.477
>>> ## 8.2 ?118.73997 200.4991 152.0515 3088.686 ? ?8 ?2601.6007 ? ? ?3105.182
>>> ## 9.1 ? 82.48090 205.4736 152.2774 1979.852 ? ?9 ?2253.5650 ? ? ?1950.388
>>> ## 9.2 ?117.48279 205.4736 152.2774 2554.581 ? ?9 ?3027.9842 ? ? ?2587.319
>>> ## 10.1 ?84.77764 205.9689 152.3325 2256.434 ? 10 ?2236.3346 ? ? ?2268.620
>>> ## 10.2 119.66417 205.9689 152.3325 3022.053 ? 10 ?2980.1202 ? ? ?3012.406
>>>
>>>
>>> --
>>> Paul E. Johnson
>>> Professor, Political Science ? ?Assoc. Director
>>> 1541 Lilac Lane, Room 504 ? ? Center for Research Methods
>>> University of Kansas ? ? ? ? ? ? ? University of Kansas
>>> http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> Programmer Analyst II, Statistical Consulting Group
>> University of California, Los Angeles
>> https://joshuawiley.com/
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science ? ?Assoc. Director
> 1541 Lilac Lane, Room 504 ? ? Center for Research Methods
> University of Kansas ? ? ? ? ? ? ? University of Kansas
> http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From emptican at gmail.com  Fri Jun 22 22:15:45 2012
From: emptican at gmail.com (Steve Hong)
Date: Fri, 22 Jun 2012 15:15:45 -0500
Subject: [R-sig-ME] two trials of RCBD with subsampling
Message-ID: <CALSKosAZX-QsizrH1cGa-X6KEDBa0xVzbLxhEFRKY0DV5XZS3g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120622/2654e7b9/attachment.pl>

From David.Duffy at qimr.edu.au  Sat Jun 23 00:24:24 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sat, 23 Jun 2012 08:24:24 +1000 (EST)
Subject: [R-sig-ME] 2-level null versus 1 level null model
In-Reply-To: <4FE45CE9.5000707@maw.ru.nl>
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com><CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
	<4FE45CE9.5000707@maw.ru.nl>
Message-ID: <Pine.LNX.4.64.1206230816560.20280@orpheus.qimr.edu.au>

On Fri, 22 Jun 2012, Ben Pelzer wrote:

> one <- rep(1, length(Y))
>
> M01level <-  lmer (Y ~ (1 | one), REML=FALSE)
> M02level <-  lmer (Y ~ (1 | one) + (1 | country), REML=FALSE)
> anova(M02level, M01level)
>
> This seams to work properly. However, I don't feel really convinced by this 
> solution yet. Is it to be trusted, or is there a much simpler way to test 
> this using lmer? Thanks for any help!!!

Yes, this works.  The RLRsim package does an exact test - the 
distribution of the likelihood ratio test isn't straightforward (at the 
very least it's a mixture of chi-squares).

Cheers, David Duffy.


From David.Duffy at qimr.edu.au  Sat Jun 23 00:46:56 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sat, 23 Jun 2012 08:46:56 +1000 (EST)
Subject: [R-sig-ME] lme4, Irtrees,
	and Outcomes Measured at Multiple and Nested Levels of Geography
	and Time
In-Reply-To: <C78E6A32C62E1448909FD94C19261EC537096591@CSGMBX202W.pu.win.princeton.edu>
References: <C78E6A32C62E1448909FD94C19261EC537096591@CSGMBX202W.pu.win.princeton.edu>
Message-ID: <Pine.LNX.4.64.1206230827210.20280@orpheus.qimr.edu.au>

On Thu, 21 Jun 2012, Rex W. Douglass wrote:

> The Long Version: A Vietnam era survey measures territorial control over 
> time in 12,000 hamlets nested in 2,500 villages. There was a 
> hamlet-month survey, a hamlet-quarter survey, a village-month survey, 
> and village-quarter survey. Using Irtrees, lme4, and their 
> documentation, I can put together a model for hamlets and villages 
> separately over time. Two problems, however, stump me.
>
> Responses at different time intervals
>
> Questions asked monthly and quarterly about villages, which hamlets were 
> nested into: Ideally, information about the village would propagate down 
> into the thetas for hamlets, and information about the hamlets would 
> propagate up into the thetas for the villages.
>
> I appreciate any advice you might have.

There's a lot of stuff here - you could almost write a thesis about it ;)

The only comment I could make is that you want a flexible approach that 
allows different measurement errors from your different instruments, so 
structural equation modelling (eg the sem package) or in BUGS.  Those can 
also incorporate your time series, which is harder in lme4.


From comtech.usa at gmail.com  Sat Jun 23 01:47:42 2012
From: comtech.usa at gmail.com (Michael)
Date: Fri, 22 Jun 2012 18:47:42 -0500
Subject: [R-sig-ME] Fitting random intercept model in R?
Message-ID: <CAPNjSFZxp=RLc7DM0NQrjTX0v07XeZrFWOFGWV4q5vuh9JXC+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120622/01206a06/attachment.pl>

From mts002 at uark.edu  Sat Jun 23 03:37:30 2012
From: mts002 at uark.edu (Matthew Smith)
Date: Fri, 22 Jun 2012 20:37:30 -0500
Subject: [R-sig-ME] Matrix of predicted values using lme or lmer
Message-ID: <20120622203730.Horde.NbWYLE9O9e1P5R3axeNAxwA@uamail.uark.edu>

I am currently trying to used a mixed model to perform a Procrustes  
Trajectory analysis on some shape data. I have 17 relative warps  
scores as my dependent matrix accompanied by individual, treatment,  
size, and day. Shape data was collected at 3 separate time points for  
each individual, so this is a repeated measures design. Since I do not  
want to analyze each relative warp separate, I have chosen to use  
individual as a random effect along with my fixed effects.

The procedure calls for a residual randomization, in which residual  
values from a reduced model are added to the predicted values of the  
full model.

The origin code use the lm function, but since I wanted to add random  
effects, I am using lme. My problem lies in when I attempt to get a  
matrix of predicted values rows=# of obs, cols=17 (each RW), it does  
not match up.

I read several discussion forums online and other threads, but I  
cannot seem to come up with a clear answer. Is there a predict command  
for the lme function that will take into account both the fixed and  
random effects? If not, is there one that just takes into account the  
fixed effects?

I appreciate any insight someone can provide me.

Matthew Smith
PhD Candidate
Department of Biological Sciences
1 University of Arkansas
Science Engineering Building
Fayetteville, AR 72701-1201
479-575-2963
mts002 at uark.edu


From elifnurdogruoz at mynet.com  Sat Jun 23 09:33:02 2012
From: elifnurdogruoz at mynet.com (elifnurdogruoz at mynet.com)
Date: Sat, 23 Jun 2012 10:33:02 +0300 (EEST)
Subject: [R-sig-ME] lme random effects in additive models with interaction
Message-ID: <51389.141.196.177.149.1340436782.mynet@webmail212.mynet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120623/cb606520/attachment.pl>

From laurent_step at yahoo.fr  Sat Jun 23 10:18:58 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Sat, 23 Jun 2012 09:18:58 +0100 (BST)
Subject: [R-sig-ME] meaning of the use.u argument in bootMer and
	simulateMerMod
In-Reply-To: <1340370521.2108.2.camel@simon-desktop>
References: <1340370521.2108.2.camel@simon-desktop>
Message-ID: <1340439538.8719.YahooMailNeo@web29504.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120623/d4745854/attachment.pl>

From bbolker at gmail.com  Sat Jun 23 13:27:56 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Jun 2012 11:27:56 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?need_help_with_predicted_values_from_lmer_wi?=
	=?utf-8?q?th=09newdata?=
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
	<CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
Message-ID: <loom.20120623T132717-78@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi Paul,
> 
> I think this may be a bug in predict.merMod.  It is not terribly
> elegant, but I suggest changing line 102 from:
> 
> re_new <- unlist(re_List[m])
> 
> to
> 
> re_new <- as.vector(do.call("rbind", re_List[m]))
> 
> I believe the issue with the current is that the random effects are
> unlisted which essentially 'stacks' the vector, so you have the random
> effects one at a time by effect, not by level (i.e., all intercepts,
> then all slopes).  Later this is post multiplied by a matrix that is
> sorted by level, the dimensions are correct so the matrices multiply
> fine, but the results are not what I believe was intended.
> 
> I cannot see a way to add a patch to R-forge or submit a bug report so
> I cced Doug on this.

  Thanks Josh. This should be fixed now.

 It turned out had to re-vamp things a bit to fix this
in a general and robust way.  I'm not quite sure how this slipped through
the cracks, since I *thought* that I had tested predict() with a multi-response
case (i.e. the sleepstudy data) and gotten sensible answers.  However,
I was testing with graphical output and not with explicit stopifnot() tests,
so it's possible that it was working originally and that I subsequently
broke something ...

  Paul, would you be willing to generate a trimmed-down version of your
example that simply generates multi-trait data?

  For future reference, the lme4 bug tracker lives at:

https://r-forge.r-project.org/tracker/?atid=298&group_id=60&func=browse

  In addition, any advice on how to improve ?predict.merMod ("I can't
tell what those numbers are. Can't be sure from ?predict.merMod") would
be welcome ...

  Ben Bolker


From s.chamaille at yahoo.fr  Sat Jun 23 13:33:15 2012
From: s.chamaille at yahoo.fr (Simon =?ISO-8859-1?Q?Chamaill=E9-Jammes?=)
Date: Sat, 23 Jun 2012 13:33:15 +0200
Subject: [R-sig-ME] meaning of the use.u argument in bootMer and
 simulateMerMod
In-Reply-To: <1340439538.8719.YahooMailNeo@web29504.mail.ird.yahoo.com>
References: <1340370521.2108.2.camel@simon-desktop>
	<1340439538.8719.YahooMailNeo@web29504.mail.ird.yahoo.com>
Message-ID: <1340451195.2061.0.camel@simon-laptop>

install.packages("lme4",repos="http://r-forge.r-project.org")

see here: http://lme4.r-forge.r-project.org/

simon

On Sat, 2012-06-23 at 09:18 +0100, laurent stephane wrote:
> Please, how to get this latest lme4 release ? 
> Thanks in advance,
> SL
> 
> 
> 
> ______________________________________________________________________
> De : Simon Chamaill?-Jammes <s.chamaille at yahoo.fr>
> ? : r-sig-mixed-models at r-project.org 
> Envoy? le : Vendredi 22 juin 2012 15h08
> Objet : [R-sig-ME] meaning of the use.u argument in bootMer and
> simulateMerMod
> 
> 
> Hello all, 
> 
> recently I've been doing parametric boostrapping of glmer models
> (using
> simulate/refit) to get confidence intervals for both fixed effect and
> variance estimates. 
> 
> Yesterday I updated to the latest lme4 release on rforge, and
> discovered
> (did I overlook it before?) the use.u argument in the bootMer function
> (which is actually used in the simulateMerMod function called by
> bootMer).
> 
> in bootMer the definition of the use.u argument (default is FALSE) is:
>         
> logical, indicating, if the spherized random effects should be
> simulated / bootstrapped as well. If FALSE, they are not changed, and
> all inference is conditional on these.
> 
> in simulateMerMod its definition (default is FALSE) is:
>         
> (logical) generate new random-effects values (FALSE) or generate a
> simulation condition on the current random-effects estimates (TRUE)?
> 
> Despite these explanations I don't quite get what's actually done and
> I'm feeling uneasy about what should be done when bootstrapping to
> produce confidence intervals for variance estimates. So far I have
> implicitly used the default use.u = FALSE. All examples found on
> various
> discussion/help lists seem to happily avoid this issue, maybe rightly
> I
> don't know.
> 
> Any clarification, and answer on am I doing it right or not, would be
> welcome.
> 
> best,
> 
> simon
> 
> PS1/ If one use bootMer to perform semi-parametric bootstrapping and
> use.u is TRUE (the only option for now with semi-par. bootstrap), then
> residuals are randomly permuted and added to the fitted values.
> 
> PS2/ I believe what I'm asking here is related and similar to what was
> asked here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/005049.html
> which wasn't replied to (at least on the list).
> 
> PS3/ for my personal knowledge, I would be glad to get a hint on what
> "spherized" random effects mean - google was of no help on this (which
> somehow makes me feel good at times...)
> 
> PS4/ for those interested, usage of use.u = TRUE with
> observation-level
> random effect or nested random effects is problematic, ie. does not
> run:
> you get things like: 
> Error in dim(val) <- c(n, nsim) : 
>   dims [product 164] do not match the length of object [123]
> In addition: Warning message:
> In etasim.fix + etasim.reff :
>   longer object length is not a multiple of shorter object length
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From curis at pharmacie.univ-paris5.fr  Sat Jun 23 08:56:35 2012
From: curis at pharmacie.univ-paris5.fr (Emmanuel Curis)
Date: Sat, 23 Jun 2012 08:56:35 +0200
Subject: [R-sig-ME] Fitting random intercept model in R?
In-Reply-To: <CAPNjSFZxp=RLc7DM0NQrjTX0v07XeZrFWOFGWV4q5vuh9JXC+A@mail.gmail.com>
References: <CAPNjSFZxp=RLc7DM0NQrjTX0v07XeZrFWOFGWV4q5vuh9JXC+A@mail.gmail.com>
Message-ID: <20120623065635.GA7323@info124.pharmacie.univ-paris5.fr>

Hello,

Your model will be a random intercept model if you assume that the
group is a random effect factor; typically, that you have observed
only a few levels of the "infinite" possible levels of the groups (for
instance, if group is a town, a school...). It will be a fixed effect
model if you assume that the group is a fixed effects factor;
typically, that you have observed all possible levels of the groups
(for instance, if group is sex, treatment...)

If I correctly understood both linear mixed models and your problem,
the equation for a single observation (groupe f, individual i) would
be something like

y(f, i) = mu0 + beta_1 F1(f,i) + sum_{k=1 to m} alpha_k 1(F2==m_k)
        + Sum_{k = 1 to f} u_k 1(F0==k)   ] random part
        + epsilon( f, i )                 ]

with 1(f) the indicator variable, that is 1(a) equals 1 if a is true,
0 otherwise; u_f a realisation of a random variable ; mu0 the average
intercept in the whole population ; beta_1 the commun slope ; F1(f,i)
the value of F1 for individual i of group f. This is assuming that F2
as k levels, m_1 to m_k.

Be writing such lines for each observation, you can get the X and Z
matrices.

b is the vector of the u_k above and Z is a matrix of indicators of
the groups, which allows to use the correct b for a given individual,
according to the group he belongs to.

The exact form of X will depend on the way you decide to code the
different levels of F2 ("contrasts"); by default in R, would be
alpha_1=0 and all others alpha_k free, leading to a column of 0 in the
X matrix which is in fact removed together with the alpha_1
coefficient.

For more precise answer, if think you should give more informations,
like the number of levels for F2, the nature of "groups"...

On Fri, Jun 22, 2012 at 06:47:42PM -0500, Michael wrote:
? Hi all,
? 
? Could anybody please shed some light on me?
? 
? N individuals, divided into K groups. N>K.
? 
? Some groups have 1 individuals only, some other groups have more
? individuals.
? 
? Each individual has 4 features (4 variables): F0, F1, F2, and F3, where F0
? is simply the group indicator.
? 
? Therefore the data matrix is of size N x 4.
? 
? There is also a weight vector w, which is of length N, which gives the
? weights for each of the N individuals in the regression.
? 
? May I ask if the following model is a random-intercept model?
? 
? 1. There is a common beta for all N individuals.
? 2. Each group has a different within group regression line (same slope but
? different intercepts).
? 3. The regression line within each group crosses the "cloud" consisting of
? the group members. And the individual residuals scatter around the
? regression line, within each group.
? 
? This sounds like a "random-intercept" model to me.
? 
? However, how do I explicitly write out the equation?
? 
? y = X * beta + Z * b + eps
? 
? More specifically, with the three feature variables F1, F2 and F3 and the
? group indicator variable F0,
? 
? I am having difficulty writing out X and Z explicitly.
? 
? Moreover, my F2 is a factor variable.
? 
? Could anybody please show me how the X and Z matrices look like explicitly?
? And what do the "b"'s represent here?
? 
? And how do I set up the weights in LME in R? If I would like to have
? "group"-weights and "individual"-weights, how shall I do it?
? 
? Thank you!
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at univ-paris5.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker at gmail.com  Sat Jun 23 21:30:43 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Jun 2012 19:30:43 +0000 (UTC)
Subject: [R-sig-ME] Matrix of predicted values using lme or lmer
References: <20120622203730.Horde.NbWYLE9O9e1P5R3axeNAxwA@uamail.uark.edu>
Message-ID: <loom.20120623T210645-151@post.gmane.org>

Matthew Smith <mts002 at ...> writes:

> 
> I am currently trying to used a mixed model to perform a Procrustes  
> Trajectory analysis on some shape data. I have 17 relative warps  
> scores as my dependent matrix accompanied by individual, treatment,  
> size, and day. Shape data was collected at 3 separate time points for  
> each individual, so this is a repeated measures design. Since I do not  
> want to analyze each relative warp separate, I have chosen to use  
> individual as a random effect along with my fixed effects.

> The procedure calls for a residual randomization, in which residual  
> values from a reduced model are added to the predicted values of the  
> full model.
> 
> The origin code use the lm function, but since I wanted to add random  
> effects, I am using lme. My problem lies in when I attempt to get a  
> matrix of predicted values rows=# of obs, cols=17 (each RW), it does  
> not match up.
> 
> I read several discussion forums online and other threads, but I  
> cannot seem to come up with a clear answer. Is there a predict command  
> for the lme function that will take into account both the fixed and  
> random effects? If not, is there one that just takes into account the  
> fixed effects?

  Without a reproducible example, it's a little hard to say.  The
predict method for lme definitely takes the random effects into account
(have you read ?predict.lme ?) -- whether the random effects are taken
into account or not depends on the 'level' argument: level=0 excludes
all random effects; the behavior defaults to including all random effects.

  In order to do a multivariate analysis with lme, I believe you will
need to convert your data to 'long form', i.e. each row will represent
a measurement of a particular warp score on a particular individual
at a particular time.  Someone here may be able to suggest a good reference
for doing this kind of multivariate analysis in lme (as I recall, it
is *not* covered thoroughly in Pinheiro and Bates 2000, which is otherwise
the standard reference text).

  Ben Bolker


From bbolker at gmail.com  Sat Jun 23 22:24:01 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Jun 2012 20:24:01 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?meaning_of_the_use=2Eu_argument_in_bootMer_a?=
	=?utf-8?q?nd=09simulateMerMod?=
References: <1340370521.2108.2.camel@simon-desktop>
Message-ID: <loom.20120623T213124-231@post.gmane.org>

Simon Chamaill?-Jammes <s.chamaille at ...> writes:

> recently I've been doing parametric boostrapping of glmer models (using
> simulate/refit) to get confidence intervals for both fixed effect and
> variance estimates. 
> 
> Yesterday I updated to the latest lme4 release on rforge, and discovered
> (did I overlook it before?) the use.u argument in the bootMer function
> (which is actually used in the simulateMerMod function called by
> bootMer).

  I *think* it's been there for some time, and you just haven't
noticed it?
> 
> in bootMer the definition of the use.u argument (default is FALSE) is:
> 
> logical, indicating, if the spherized random effects should be
> simulated / bootstrapped as well. If FALSE, they are not changed, and
> all inference is conditional on these.
> 
> in simulateMerMod its definition (default is FALSE) is:
> 
> (logical) generate new random-effects values (FALSE) or generate a
> simulation condition on the current random-effects estimates (TRUE)?
> 
> Despite these explanations I don't quite get what's actually done and
> I'm feeling uneasy about what should be done when bootstrapping to
> produce confidence intervals for variance estimates. So far I have
> implicitly used the default use.u = FALSE. All examples found on various
> discussion/help lists seem to happily avoid this issue, maybe rightly I
> don't know.
> 
> Any clarification, and answer on am I doing it right or not, would be
> welcome.

  There's definitely some confusion and inconsistency between the
documentation in both places (?bootMer and ?simulate.merMod); rather
than charging in and fixing everything immediately, I will have to
have some conversation with the primary developers to make sure that
I've got everything right ...

  Bottom line: you're not being dumb, there are some messy/wrong
bits in there.  For now, look carefully at the *code* to see what's
going on.

  I would be inclined to do _unconditional_ simulations (i.e. 
resampling the random effects); I don't, however, know offhand
of any good references on the implications of doing it one way
or the other (obviously the conditional simulations will give
less variability/less conservative estimates of confidence intervals).



> PS1/ If one use bootMer to perform semi-parametric bootstrapping and
> use.u is TRUE (the only option for now with semi-par. bootstrap), then
> residuals are randomly permuted and added to the fitted values.

  Yes.

> PS2/ I believe what I'm asking here is related and similar to what was
> asked here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/005049.html
> which wasn't replied to (at least on the list).
> 
> PS3/ for my personal knowledge, I would be glad to get a hint on what
> "spherized" random effects mean - google was of no help on this (which
> somehow makes me feel good at times...)

  "Spherized" means a form of the random effects that are uncorrelated
and where all observations have equal variance (so that the points
would fall in a (hyper)sphere in multidimensional space. This is discussed
under the rubric "spherical" in the introductory chapter of Doug
Bates's book.


> 
> PS4/ for those interested, usage of use.u = TRUE with observation-level
> random effect or nested random effects is problematic, ie. does not run:
> you get things like: 
> Error in dim(val) <- c(n, nsim) : 
>   dims [product 164] do not match the length of object [123]
> In addition: Warning message:
> In etasim.fix + etasim.reff :
>   longer object length is not a multiple of shorter object length

  Yes indeed (although I'm not 100% sure of the pattern --
I think it may not require nested random effects to break). Will fix!

  thanks for your patience,
    Ben Bolker


From bbolker at gmail.com  Sat Jun 23 23:02:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Jun 2012 21:02:10 +0000 (UTC)
Subject: [R-sig-ME] lme random effects in additive models with
	interaction
References: <51389.141.196.177.149.1340436782.mynet@webmail212.mynet.com>
Message-ID: <loom.20120623T225841-628@post.gmane.org>

 <elifnurdogruoz at ...> writes:

> 
> 
> Hello,I posted this
> message previously on R-help.

  Your data and code came through as almost hopelessly mangled,
at least when viewed in Gmane (a web portal for the mailing list).
Could you please try re-posting in plain text rather than HTML
(as you are requested by the posting guide) to improve the chances
that it gets through?

  Also,

 * some more context may be helpful.
 * As I said on r-help, it is going to be _extremely_ difficult to
generalize to a random population from two replicates.  Have you
read the suggested mailing list thread
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003709.html
?

> The experiment is repeated twice (Replication 1 and 2) ,
> hence I
> thinkthat Replication should be random effect. My
> replications are randomlychosen from a population and I
> should make inference about thepopulation. &nbsp;I don't have a
> chance to take more replications.
>


From laurent_step at yahoo.fr  Sun Jun 24 11:40:07 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Sun, 24 Jun 2012 10:40:07 +0100 (BST)
Subject: [R-sig-ME] crash with the latest update of lme4
Message-ID: <1340530807.8181.YahooMailNeo@web29504.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120624/4f7764b5/attachment.pl>

From nsabin at gmail.com  Sat Jun 23 17:38:37 2012
From: nsabin at gmail.com (Nicholas Sabin)
Date: Sat, 23 Jun 2012 16:38:37 +0100
Subject: [R-sig-ME] Multilevel Ordinal Logistic Regression: clmm warnings
Message-ID: <CAOrjsSR47+LrJ805rR=hdSkmxAm1GdAjDuxJeVxnvCmPgWJ8bA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120623/ec64494b/attachment.pl>

From meluchbrowne at hotmail.com  Sun Jun 24 13:57:08 2012
From: meluchbrowne at hotmail.com (Melanie Browne)
Date: Sun, 24 Jun 2012 11:57:08 +0000
Subject: [R-sig-ME] STD file not found error with glmmADMB
Message-ID: <SNT128-W991BE13F812ABEE9AC034D6E20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120624/ecfadef3/attachment.pl>

From jwiley.psych at gmail.com  Sun Jun 24 18:29:22 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 24 Jun 2012 09:29:22 -0700
Subject: [R-sig-ME] need help with predicted values from lmer with
	newdata
In-Reply-To: <loom.20120623T132717-78@post.gmane.org>
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
	<CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
	<loom.20120623T132717-78@post.gmane.org>
Message-ID: <CANz9Z_+fojMnAVtQC0yCKGppRRjfeBkNZqQefPJqoFRbpV6eOA@mail.gmail.com>

On Sat, Jun 23, 2012 at 4:27 AM, Ben Bolker <bbolker at gmail.com> wrote:
[snip]

> ?In addition, any advice on how to improve ?predict.merMod ("I can't
> tell what those numbers are. Can't be sure from ?predict.merMod") would
> be welcome ...

Far from perfect, but what about something like this?  I do not know
about others, but I often prefer to just see the formulae.  In these
models, the questions I always have are
1) are the random effects being included (nicely shown by Zu)
2) not relevant for the lmer() case, but for glmer, are the predicted
values conditional, unconditional, marginal

when \code{predict} is called on a model object without a new dataset,
it returns the fitted values.  By default, these include the random
effects.  That is, \eqn{\hat{Y} = \mathbf{Xb} + \mathbf{Zu}}{Yhat = Zb
+ Zu}.  Where \eqn{\mathbf{X}}{X} is the fixed-effects design matrix,
\eqn{\mathbf{b}}{b} is the vector of fixed paramter estimates,
\eqn{\mathbf{Z}}{Z} is the random-effects design matrix, and
\eqn{\mathbf{u}}{u} is the vector of random parameter estimates. If
you set \code{REform=NA}, then you will get the unconditional fitted
values.  That is, \eqn{\hat{Y} = \mathbf{Xb}}{Yhat = Xb}.

## FIXME: perhaps add information about link functions

To calculate predicted values from a new dataset (i.e., when
\code{newdata} is not \code{NULL}), the model matrix,
\eqn{\mathbf{X}}{X} is created from \code{newdata}, using the
contrasts from the original model if there are any categorical
(factor) variables.  The fixed portion of the predicted values are
calculated as \eqn{\hat{Y} = \mathbf{Xb}}{Yhat = Xb}.  If \code{REform
= NULL} (the default), then all random effects are used.  If
\code{REform = NA} then no random effects are used, otherwise,
\code{REform} can be a formula specifying which random effects to
include.  These options can be thought of as setting a diagonal
selection matrix, \eqn{\mathbf{D}}{D}.  In the default case, it is the
identity matrix, in the second case, the diagonal is all 0s, and in
the formula case the diagonal contains a combination of 0s and 1s.
Then the final predicted values are \eqn{\hat{Y} = \mathbf{Xb} +
\mathbf{Z}(\mathbf{Du})}{Yhat = Xb + Z(Du)}.



>
> ?Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From jwiley.psych at gmail.com  Sun Jun 24 18:39:09 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 24 Jun 2012 09:39:09 -0700
Subject: [R-sig-ME] STD file not found error with glmmADMB
In-Reply-To: <SNT128-W991BE13F812ABEE9AC034D6E20@phx.gbl>
References: <SNT128-W991BE13F812ABEE9AC034D6E20@phx.gbl>
Message-ID: <CANz9Z_+h-gbxtLunaeRj+urGgrmW-Yx6fY=eOwY1vzWtMkAkBA@mail.gmail.com>

Hi Melanie,

This bit, "function maximizer failed" suggests that it is having
difficulty estimating your model.  What happens if you try a simpler
model, (the simplest being intercept only)?  My memory is vague, but
it seems like Ben Bolker may have said at one point that using
variables from the global environment was not tested much in
glmmadmb(), so you might also try using the data argument.  Which
segues nicely into my last point, which is that it would be helpful to
at least show us the output from

str(yourdataset)

so that we know the size, types of variables, etc.

Cheers,

Josh

On Sun, Jun 24, 2012 at 4:57 AM, Melanie Browne
<meluchbrowne at hotmail.com> wrote:
>
> Hello, I am using the glmmADMB package (I downloaded it using: install.packages("glmmADMB", repos="http://r-forge.r-project.org"), I am not sure which version it is). I'm on R version 2.15.1 GUI 1.52 Leopard build 64-bit, and yes, I'm on a mac.
> I'm trying to run the following function: fit= glmmadmb(fruit ~ surroundings*town+(1|site), family='nbinom1', zeroInflation=TRUE)
> and got the following error: dyld: unknown required load command 0x80000022Error in glmmadmb(fruit ~ surroundings * town + (1 | site), family = "nbinom1", ?: ? The function maximizer failed (couldn't find STD file)
> My variables are fruit counts and there is overdispersion.
> I added the zeroInflation because I read that it worked that way but in my case it still didn't. I also tried to download an older version of the package that I saw you recommended to someone. (I also tried with admb.opts=admbControl(shess=FALSE,noinit=FALSE)). Now I get the following error:Error in parse(text = lab) : object 'lab' not foundIn addition: Warning message:In is.na(rows) : is.na() applied to non-(list or vector) of type 'NULL'
> I hope I have provided enough information and that my problem is clear enough...
> Do you have any ideas that could help me resolve this problem? Or do you know of another package that would let me do a negative binomial with mixed factors? (I don't think the zero-inflated part is a problem).
> Thank you very much,
> Melanie Browne
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From meluchbrowne at hotmail.com  Sun Jun 24 19:38:31 2012
From: meluchbrowne at hotmail.com (Melanie Browne)
Date: Sun, 24 Jun 2012 17:38:31 +0000
Subject: [R-sig-ME] (no subject)
Message-ID: <SNT128-W64DECD053FB5566B0D8007D6E20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120624/75eed25b/attachment.pl>

From elifnurdogruoz at mynet.com  Sun Jun 24 22:35:18 2012
From: elifnurdogruoz at mynet.com (elifnurdogruoz at mynet.com)
Date: Sun, 24 Jun 2012 23:35:18 +0300 (EEST)
Subject: [R-sig-ME] lme random effects in additive models with
	interaction
Message-ID: <61154.139.179.104.89.1340570118.mynet@webmail212.mynet.com>



Thanks for the warning, I hope it seems better now.

My data is like following and there is a response variable y:

Time    Size            Charge          Density   Replication
3       small             +               low      1
.        .                .                .       .
.        .                .                .       .
9       small             +               low      1
3       big               +               low      .
.        .                .                .       .
.        .                .                .       .
9       big               +               low      1
3       small             -               low      1
.        .                .                .       .
.        .                .                .       .
9       small             -               low      1
3       big               -               low      1
.        .                .                .       .
.        .                .                .       .
9       big               -               low      1
3       small             +               high     1
.        .                .                .       .
.        .                .                .       .
9       small             +               high     1
3       big               +               high     1
.        .                .                .       .
.        .                .                .       .
9       big               +               high     1
3       small             -               high     1
.        .                .                .       .
.        .                .                .       .
9       small             -               high     1
3       big               -               high     1
.        .                .                .       .
.        .                .                .       .
9       big               -               high     1
3       small             +               low      2
.        .                .                .       .
.        .                .                .       .
9       small             +               low      2
3       big               +               low      2
.        .                .                .       .
.        .                .                .       .
9       big               +               low      2
3       small             -               low      2
.        .                .                .       .
.        .                .                .       .
9       small             -               low      2
3       big               -               low      2
.        .                .                .       .
.        .                .                .       .
9       big               -               low      2
3       small             +               high     2
.        .                .                .       .
.        .                .                .       .
9       small             +               high     2
3       big               +               high     2
.        .                .                .       .
.        .                .                .       .
9       big               +               high     2
3       small             -               high     2
.        .                .                .       .
.        .                .                .       .
9       small             -               high     2
3       big               -               high     2
.        .                .                .       .
.        .                .                .       .
9       big               -               high     2


My code with comments:

##this function selects the knots
default.knots <- function(x,num.knots)
{
if (missing(num.knots))
num.knots <- max(5,min(floor(length(unique(x))/4),35))
return(quantile(unique(x),seq(0,1,length=
(num.knots+2))[-c(1,(num.knots+2))]))
}

knots <- default.knots(Time)

z <- outer(Time, knots, "-")
z <- z * (z > 0)
z<-z^2

i.size50 <- I(Size==small)
i.chargepos <- I(Charge=="+")
i.densitylow <- I(Density==low)

##Create X and Z matrices,  I put interactions because I want
intercept to be zero at time 0.
X <- cbind( I(Time^2),Time*i.size50,Time*i.chargepos,Time*i.densitylow)
Z <- cbind( z, z*i.size50, z*i.chargepos,z*i.densitylow)


K <- length(knots)

## form blocked diagonal matrix Z to specify which columns of Z are
used for each group

block.ind <- list(1:K, (K+1):(2*K),(2*K+1):(3*K),(3*K+1):(4*K))
Z.block <- list()
for (i in 1:length(block.ind))
Z.block[[i]] <-
as.formula(paste("~Z[,c(",paste(block.ind[[i]],collapse=","),")]-1"))

##create dummy grouping variable since groupedData object is required for lme
group <- rep(1, length(Time))
model.data <- groupedData(y~X|group, data=data.frame(X, y))

fit <- lme(y~-1+X, data=model.data, random=pdBlocked(list(
pdBlocked(Z.block,pdClass="pdIdent"), pdIdent(~-1+ Replication) ) ) )

It gives error : "Error:  getResponseFormula(el) : "Form" must be a
two sided formula"

I read that thread and I know that 2 replication is not enough to be
modelled as random effect.
However, I want to have the correct model even if I get imprecise
estimation of variance.
I know I have a mistake in forming positive definite matrices in random
part, but I couldn't figure out what is wrong.
Thanks in advance,


From s.chamaille at yahoo.fr  Sun Jun 24 22:55:18 2012
From: s.chamaille at yahoo.fr (Simon =?ISO-8859-1?Q?Chamaill=E9-Jammes?=)
Date: Sun, 24 Jun 2012 22:55:18 +0200
Subject: [R-sig-ME] meaning of the use.u argument in bootMer and
 simulateMerMod (Ben Bolker)
In-Reply-To: <mailman.1922.1340483097.4567.r-sig-mixed-models@r-project.org>
References: <mailman.1922.1340483097.4567.r-sig-mixed-models@r-project.org>
Message-ID: <1340571318.3196.8.camel@simon-laptop>

I played around with Poisson-errors model, simulate() and the use.u
argument today, and when use.u is set to TRUE my confidence intervals
(here simply calculated as the interval between the 2.5 and 97.5
percentile of the bootstrapped statistics) sometimes did not include the
point estimate from the original data (this never happens with
use.u=F). 
So I would be reluctant to use this before understanding what's
happening.


> ------------------------------
> 
> Message: 5
> Date: Sat, 23 Jun 2012 20:24:01 +0000 (UTC)
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] meaning of the use.u argument in bootMer and
> 	simulateMerMod
> Message-ID: <loom.20120623T213124-231 at post.gmane.org>
> Content-Type: text/plain; charset=utf-8
> 
> Simon Chamaill?-Jammes <s.chamaille at ...> writes:
> 
> > recently I've been doing parametric boostrapping of glmer models (using
> > simulate/refit) to get confidence intervals for both fixed effect and
> > variance estimates. 
> > 
> > Yesterday I updated to the latest lme4 release on rforge, and discovered
> > (did I overlook it before?) the use.u argument in the bootMer function
> > (which is actually used in the simulateMerMod function called by
> > bootMer).
> 
>   I *think* it's been there for some time, and you just haven't
> noticed it?
> > 
> > in bootMer the definition of the use.u argument (default is FALSE) is:
> > 
> > logical, indicating, if the spherized random effects should be
> > simulated / bootstrapped as well. If FALSE, they are not changed, and
> > all inference is conditional on these.
> > 
> > in simulateMerMod its definition (default is FALSE) is:
> > 
> > (logical) generate new random-effects values (FALSE) or generate a
> > simulation condition on the current random-effects estimates (TRUE)?
> > 
> > Despite these explanations I don't quite get what's actually done and
> > I'm feeling uneasy about what should be done when bootstrapping to
> > produce confidence intervals for variance estimates. So far I have
> > implicitly used the default use.u = FALSE. All examples found on various
> > discussion/help lists seem to happily avoid this issue, maybe rightly I
> > don't know.
> > 
> > Any clarification, and answer on am I doing it right or not, would be
> > welcome.
> 
>   There's definitely some confusion and inconsistency between the
> documentation in both places (?bootMer and ?simulate.merMod); rather
> than charging in and fixing everything immediately, I will have to
> have some conversation with the primary developers to make sure that
> I've got everything right ...
> 
>   Bottom line: you're not being dumb, there are some messy/wrong
> bits in there.  For now, look carefully at the *code* to see what's
> going on.
> 
>   I would be inclined to do _unconditional_ simulations (i.e. 
> resampling the random effects); I don't, however, know offhand
> of any good references on the implications of doing it one way
> or the other (obviously the conditional simulations will give
> less variability/less conservative estimates of confidence intervals).
> 
> 
> 
> > PS1/ If one use bootMer to perform semi-parametric bootstrapping and
> > use.u is TRUE (the only option for now with semi-par. bootstrap), then
> > residuals are randomly permuted and added to the fitted values.
> 
>   Yes.
> 
> > PS2/ I believe what I'm asking here is related and similar to what was
> > asked here:
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/005049.html
> > which wasn't replied to (at least on the list).
> > 
> > PS3/ for my personal knowledge, I would be glad to get a hint on what
> > "spherized" random effects mean - google was of no help on this (which
> > somehow makes me feel good at times...)
> 
>   "Spherized" means a form of the random effects that are uncorrelated
> and where all observations have equal variance (so that the points
> would fall in a (hyper)sphere in multidimensional space. This is discussed
> under the rubric "spherical" in the introductory chapter of Doug
> Bates's book.
> 
> 
> > 
> > PS4/ for those interested, usage of use.u = TRUE with observation-level
> > random effect or nested random effects is problematic, ie. does not run:
> > you get things like: 
> > Error in dim(val) <- c(n, nsim) : 
> >   dims [product 164] do not match the length of object [123]
> > In addition: Warning message:
> > In etasim.fix + etasim.reff :
> >   longer object length is not a multiple of shorter object length
> 
>   Yes indeed (although I'm not 100% sure of the pattern --
> I think it may not require nested random effects to break). Will fix!
> 
>   thanks for your patience,
>     Ben Bolker
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 66, Issue 38
> **************************************************


From David.Duffy at qimr.edu.au  Mon Jun 25 00:49:59 2012
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 25 Jun 2012 08:49:59 +1000 (EST)
Subject: [R-sig-ME] Multilevel Ordinal Logistic Regression: clmm warnings
In-Reply-To: <CAOrjsSR47+LrJ805rR=hdSkmxAm1GdAjDuxJeVxnvCmPgWJ8bA@mail.gmail.com>
References: <CAOrjsSR47+LrJ805rR=hdSkmxAm1GdAjDuxJeVxnvCmPgWJ8bA@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1206250840070.30289@orpheus.qimr.edu.au>

On Sat, 23 Jun 2012, Nicholas Sabin wrote:

> I am working with repeated measures for subjects and the dependent variable
> is ordered categories.  So I am working on building a Multilevel Ordinal
> Logistic Regression model.
>
> Example Data:
>
> ID      Cycle     X          X2    PerfCat
> 100         1     3.5        12    1
> 100         2     7.6        57    4
> 100         3     6.6        43    3
>
> Model.mlol <- clmm(as.ordered(PerfCat) ~
>       X+X2+(1|ID),
>       data=ExampleData)
>
> "In update.uC(rho) : Non finite negative log-likelihood
>  at iteration 165"

I presume Rune Haubo Christensen will give a better answer but this
doesn't sound very good.  What did

clmm(as.ordered(PerfCat) ~ X + (1|ID)..

and

clmm(as.ordered(PerfCat) ~ poly(X,2) + (1|ID)..

give?

Also, the rule of thumb is that ordinal variables with five or more levels 
can usually be treated as continuous without inference problems.  That is, 
you should be getting answers close to your LMM result.

Cheers, David Duffy.


From rune.haubo at gmail.com  Mon Jun 25 08:35:43 2012
From: rune.haubo at gmail.com (Rune Haubo)
Date: Mon, 25 Jun 2012 08:35:43 +0200
Subject: [R-sig-ME] Multilevel Ordinal Logistic Regression: clmm warnings
In-Reply-To: <Pine.LNX.4.64.1206250840070.30289@orpheus.qimr.edu.au>
References: <CAOrjsSR47+LrJ805rR=hdSkmxAm1GdAjDuxJeVxnvCmPgWJ8bA@mail.gmail.com>
	<Pine.LNX.4.64.1206250840070.30289@orpheus.qimr.edu.au>
Message-ID: <CAG_uk93G2E+fZEiVKwrM-E0By+RcOsxwoBf_+3K7N7B85ZbzUg@mail.gmail.com>

Nicholas,

I agree with David: this doesn't sound so good and it seems that the
model might not have converged...  However, to provide more qualified
help, I will need to see the result of

summary(Model.mlol)
sessionInfo()

If you can disclose the result of str(your_data) that might also be
helpful. Lastly, I suggest that you install the latest version of
ordinal from R-Forge due to some recent improvements to the fitting
algorithm:

install.packages("ordinal", repos="http://R-Forge.R-project.org")

Cheers,
Rune


On 25 June 2012 00:49, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Sat, 23 Jun 2012, Nicholas Sabin wrote:
>
>> I am working with repeated measures for subjects and the dependent
>> variable
>> is ordered categories. ?So I am working on building a Multilevel Ordinal
>> Logistic Regression model.
>>
>> Example Data:
>>
>> ID ? ? ?Cycle ? ? X ? ? ? ? ?X2 ? ?PerfCat
>> 100 ? ? ? ? 1 ? ? 3.5 ? ? ? ?12 ? ?1
>> 100 ? ? ? ? 2 ? ? 7.6 ? ? ? ?57 ? ?4
>> 100 ? ? ? ? 3 ? ? 6.6 ? ? ? ?43 ? ?3
>>
>> Model.mlol <- clmm(as.ordered(PerfCat) ~
>> ? ? ?X+X2+(1|ID),
>> ? ? ?data=ExampleData)
>>
>> "In update.uC(rho) : Non finite negative log-likelihood
>> ?at iteration 165"
>
>
> I presume Rune Haubo Christensen will give a better answer but this
> doesn't sound very good. ?What did
>
> clmm(as.ordered(PerfCat) ~ X + (1|ID)..
>
> and
>
> clmm(as.ordered(PerfCat) ~ poly(X,2) + (1|ID)..
>
> give?
>
> Also, the rule of thumb is that ordinal variables with five or more levels
> can usually be treated as continuous without inference problems. ?That is,
> you should be getting answers close to your LMM result.

Well, in my experience that depends strongly on the problem and the
type of data you are dealing with. I have seen many examples where the
response variable had more than 5 levels and linear (mixed) models
were definitely inappropriate.

>
> Cheers, David Duffy.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Rune Haubo Bojesen Christensen

PhD Student, M.Sc. Eng.
Phone: (+45) 45 25 33 63
Mobile: (+45) 30 26 45 54

DTU Informatics, Section for Statistics
Technical University of Denmark, Build. 305, Room 122,
DK-2800 Kgs. Lyngby, Denmark


From bbolker at gmail.com  Mon Jun 25 10:08:05 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Jun 2012 08:08:05 +0000 (UTC)
Subject: [R-sig-ME] STD file not found error with glmmADMB
References: <SNT128-W991BE13F812ABEE9AC034D6E20@phx.gbl>
	<CANz9Z_+h-gbxtLunaeRj+urGgrmW-Yx6fY=eOwY1vzWtMkAkBA@mail.gmail.com>
Message-ID: <loom.20120625T100335-480@post.gmane.org>

Joshua Wiley <jwiley.psych at ...> writes:

> 
> Hi Melanie,
> 
> This bit, "function maximizer failed" suggests that it is having
> difficulty estimating your model.  What happens if you try a simpler
> model, (the simplest being intercept only)?  My memory is vague, but
> it seems like Ben Bolker may have said at one point that using
> variables from the global environment was not tested much in
> glmmadmb(), so you might also try using the data argument.  Which
> segues nicely into my last point, which is that it would be helpful to
> at least show us the output from
> 
> str(yourdataset)
> 
> so that we know the size, types of variables, etc.
> 
> Cheers,
> 
> Josh
> 
> On Sun, Jun 24, 2012 at 4:57 AM, Melanie Browne
> <meluchbrowne <at> hotmail.com> wrote:

> > Hello, I am using the glmmADMB package (I downloaded it using:
> install.packages("glmmADMB", repos="http://r-forge.r-project.org"),
> I am not sure which version it is). I'm on R version 2.15.1 GUI 1.52
> Leopard build 64-bit, and yes, I'm on a mac.  

> I'm trying to run
> the following function: fit= glmmadmb(fruit ~
> surroundings*town+(1|site), family='nbinom1', zeroInflation=TRUE) >
> and got the following error: dyld: unknown required load command
> 0x80000022Error in glmmadmb(fruit ~ surroundings * town + (1 |
> site), family = "nbinom1", ?: ? The function maximizer failed
> (couldn't find STD file) > My variables are fruit counts and there
> is overdispersion.  

  What MacOS version are you running?  I strongly suspect it's
MacOS 10.5 rather than 10.6 ... we've had problems with this in
the past (see the discussion at http://glmmadmb.r-forge.r-project.org/ )

  If you google 'glmmadmb "unknown required load command"' you get

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q4/007155.html

  I added code to glmmADMB that I thought would detect this
situation, but it may not have worked.  Could you please
run the following commands and post the results?

library(glmmADMB)
sessionInfo()
R.version$os
system("uname -v")


From bbolker at gmail.com  Mon Jun 25 10:33:40 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Jun 2012 08:33:40 +0000 (UTC)
Subject: [R-sig-ME] (no subject)
References: <SNT128-W64DECD053FB5566B0D8007D6E20@phx.gbl>
Message-ID: <loom.20120625T103203-345@post.gmane.org>

Melanie Browne <meluchbrowne at ...> writes:


> Hello there! I am not sure I am doing this the right way, I
>  hope you can all read my answer but I was actually able
> to access a computer with windows and the function worked!! 
> so be sure to try that out if you're having the
> same problem as I am and you are using a mac!
> thank you for your answers and thoughts! 		 	   		  

  Thanks for following up.  See my previous answer: I think your
problem is not with MacOS in general but with MacOS 10.5 in particular.
If you can post the answer to the previous question (especially the
answers to R.version and system("uname -v") ) that would be helpful ...

  Ben Bolker


From tmoranlopez at mncn.csic.es  Mon Jun 25 12:08:23 2012
From: tmoranlopez at mncn.csic.es (MORAN LOPEZ, TERESA)
Date: Mon, 25 Jun 2012 12:08:23 +0200
Subject: [R-sig-ME] Running multinomial models with random effects
In-Reply-To: <alpine.LNX.2.00.1206071116400.11325@linux29.zdv.uni-tuebingen.de>
References: <alpine.LNX.2.00.1206071116400.11325@linux29.zdv.uni-tuebingen.de>
Message-ID: <20120625120823.347145clv0s0lthz@webmail.csic.es>

Hi Florian,
thanks a lot for your help. I have been reading De Boeck and Partchev  
paper and I have some questions.
First of all I am having some problems when applying dendrify function.
My dataframe has the following structure:
   RISK       Area CHOICE
1 MONTE      Sopie      2
2 MONTE      Sopie      2
3 MONTE      Sopie      2
4 MONTE Anchurones      3
5 MONTE Anchurones      1
6 MONTE Anchurones      2

being 1 (both acorns choice, 2 chosing the big one and 3 chosing the  
small one)
Following your instructions I mapped my tree as:
mapping <- cbind(c(0, 1, 1), c(NA, 0, 1))
Then I remove the first two columns in order to implement dendrify function
dendrify(jay[,-(1:2)],mapping)
The following error arise:
Error: is.matrix(mat) is not TRUE

I have not been able to find the problem. I have  followed tutorial  
package and paper instructions. mat=(jay[,-(1:2)], has only one column  
since I only have one item and each row corresponds to one choice event.
Any suggestions?




Quoting :

> Alternatively, you could fit a "tree-based" mixed logit model
> based on continuation ratio logits. See a recent JSS paper by De
> Boeck and Partchev (2012, http://www.jstatsoft.org/v48/c01/).
>
> The idea is to convert the three-level response into a binary one
> using a decision tree. In one possible tree, the first node is
> indifferent w.r.t. size (response both) vs. picky (response small
> or big). The second node is small given picky vs. big given
> picky.
>
> You need to extend your data by a two-level node variable. The
> new response is then binary. The model can be fit using glmer().
>
> Best, Florian
>
> ---
> Florian Wickelmaier
> Department of Psychology
> University of Tuebingen
> Schleichstr. 4, 72076 Tuebingen, Germany
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From tmoranlopez at mncn.csic.es  Mon Jun 25 12:21:57 2012
From: tmoranlopez at mncn.csic.es (MORAN LOPEZ, TERESA)
Date: Mon, 25 Jun 2012 12:21:57 +0200
Subject: [R-sig-ME] Running multinomial models with random effects
In-Reply-To: <20120625120823.347145clv0s0lthz@webmail.csic.es>
References: <alpine.LNX.2.00.1206071116400.11325@linux29.zdv.uni-tuebingen.de>
	<20120625120823.347145clv0s0lthz@webmail.csic.es>
Message-ID: <20120625122157.32612pq4zlelwts5@webmail.csic.es>


Dear Florian,
I have just figured out what was going on. I haven?t converted my  
dataframe into matrix. Sorry for such an obvious question!


Quoting "MORAN LOPEZ, TERESA":

> Hi Florian,
> thanks a lot for your help. I have been reading De Boeck and  
> Partchev paper and I have some questions.
> First of all I am having some problems when applying dendrify function.
> My dataframe has the following structure:
>   RISK       Area CHOICE
> 1 MONTE      Sopie      2
> 2 MONTE      Sopie      2
> 3 MONTE      Sopie      2
> 4 MONTE Anchurones      3
> 5 MONTE Anchurones      1
> 6 MONTE Anchurones      2
>
> being 1 (both acorns choice, 2 chosing the big one and 3 chosing the  
> small one)
> Following your instructions I mapped my tree as:
> mapping <- cbind(c(0, 1, 1), c(NA, 0, 1))
> Then I remove the first two columns in order to implement dendrify function
> dendrify(jay[,-(1:2)],mapping)
> The following error arise:
> Error: is.matrix(mat) is not TRUE
>
> I have not been able to find the problem. I have  followed tutorial  
> package and paper instructions. mat=(jay[,-(1:2)], has only one  
> column since I only have one item and each row corresponds to one  
> choice event.
> Any suggestions?
>
>
>
>
> Quoting :
>
>> Alternatively, you could fit a "tree-based" mixed logit model
>> based on continuation ratio logits. See a recent JSS paper by De
>> Boeck and Partchev (2012, http://www.jstatsoft.org/v48/c01/).
>>
>> The idea is to convert the three-level response into a binary one
>> using a decision tree. In one possible tree, the first node is
>> indifferent w.r.t. size (response both) vs. picky (response small
>> or big). The second node is small given picky vs. big given
>> picky.
>>
>> You need to extend your data by a two-level node variable. The
>> new response is then binary. The model can be fit using glmer().
>>
>> Best, Florian
>>
>> ---
>> Florian Wickelmaier
>> Department of Psychology
>> University of Tuebingen
>> Schleichstr. 4, 72076 Tuebingen, Germany
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


From emptican at gmail.com  Mon Jun 25 16:50:54 2012
From: emptican at gmail.com (Steve Hong)
Date: Mon, 25 Jun 2012 09:50:54 -0500
Subject: [R-sig-ME] sas to R
Message-ID: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120625/37a69900/attachment.pl>

From jwiley.psych at gmail.com  Mon Jun 25 17:04:19 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 25 Jun 2012 08:04:19 -0700
Subject: [R-sig-ME] sas to R
In-Reply-To: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
Message-ID: <CANz9Z_KkUA+xwAdK3Q8B2z7584o+1ZCssvm51MXRSJLPK4MkkA@mail.gmail.com>

Hi Steve,

That SAS code looks a little strange to me (I feel like it is missing
a distribution and some options on the random line).  It would
probably help if you could also describe in words what you are doing
or trying to do.

a rough pass at it would be:

glmer(y ~ trt + (trt | block) + (trt | trial), data = df, family = "binomial")

That will fit a logistic model, with a random intercept and trt effect
by block and by trial.  If they are nested, that is fine.  If they are
cross classified, that is fine too.  The random intercept and trt
effect will be correlated by default.

Cheers,

Josh

On Mon, Jun 25, 2012 at 7:50 AM, Steve Hong <emptican at gmail.com> wrote:
> Dear all,
>
> Can anyone help me convert SAS code to R in lme or lmer, especially in
> random statement part?
>
> Here is SAS code:
> proc glimmix data=df;
> class trial block trt;
> model y=trt;
> random trial block(trial) trt(block*trial);
>
> Thanks in advance,
>
> Steve
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From comtech.usa at gmail.com  Mon Jun 25 17:10:45 2012
From: comtech.usa at gmail.com (Michael)
Date: Mon, 25 Jun 2012 10:10:45 -0500
Subject: [R-sig-ME] Fitting random intercept model in R?
In-Reply-To: <20120623065635.GA7323@info124.pharmacie.univ-paris5.fr>
References: <CAPNjSFZxp=RLc7DM0NQrjTX0v07XeZrFWOFGWV4q5vuh9JXC+A@mail.gmail.com>
	<20120623065635.GA7323@info124.pharmacie.univ-paris5.fr>
Message-ID: <CAPNjSFY1OhwbbEJxruMqqff+5WP9cPQACe0LikrDjayg2G3-6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120625/6c94163a/attachment.pl>

From emptican at gmail.com  Mon Jun 25 17:15:12 2012
From: emptican at gmail.com (Steve Hong)
Date: Mon, 25 Jun 2012 10:15:12 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <CANz9Z_KkUA+xwAdK3Q8B2z7584o+1ZCssvm51MXRSJLPK4MkkA@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CANz9Z_KkUA+xwAdK3Q8B2z7584o+1ZCssvm51MXRSJLPK4MkkA@mail.gmail.com>
Message-ID: <CALSKosA7+wEs6dio8-gHHrTy-6Ng1x5DuXH-PXTTJjg-JUOHVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120625/42fc7ba0/attachment.pl>

From kw.stat at gmail.com  Mon Jun 25 17:25:29 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 25 Jun 2012 10:25:29 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
Message-ID: <CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>

This could be similar to a multi-location RCB design were "trial" is
location.  Since no distribution is specified, the distribution is
assumed to be Gaussian.  Make sure that trial, block, trt are factors,
this should be similar to SAS:

lmer(y ~ trt + (1|trial/block/trt), data=df)

> proc glimmix data=df;
> class trial block trt;
> model y=trt;
> random trial block(trial) trt(block*trial);

Kevin Wright


From emptican at gmail.com  Mon Jun 25 18:50:30 2012
From: emptican at gmail.com (Steve Hong)
Date: Mon, 25 Jun 2012 11:50:30 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
Message-ID: <CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>

Thank all of you for replying to me.

I tried lmer, lme, and SAS.  I was able to get outputs when I use
'lme' whereas no results from 'lmer'.  I don't know why.  Does anyone
know what the warning message mean?  Outputs from  'lme' were similar
with those from SAS.  Below is selected outputs from lmer, lme, and
SAS, FYI.

Thanks again,

Steve Hong

> fm.lmer <- lmer(y ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In block:trial :
? numerical expression has 92 elements: only the first used
2: In block:trial :
? numerical expression has 92 elements: only the first used
3: In trt:(block:trial) :
? numerical expression has 92 elements: only the first used
4: In block:trial :
? numerical expression has 92 elements: only the first used
5: In block:trial :
? numerical expression has 92 elements: only the first used
> fm.lme <- lme(y ~ trt, random=(~1|trial/block/trt), data = df, na.action=na.omit)
> summary(fm.lme)
Linear mixed-effects model fit by REML
?Data: df
? ? ? ? AIC ? ? ? BIC ? logLik
? -85.22388 -60.68041 52.61194

Random effects:
?Formula: ~1 | trial
? ? ? ? (Intercept)
StdDev: ? 0.1112442

?Formula: ~1 | block %in% trial
? ? ? ? ?(Intercept)
StdDev: 1.449228e-06

?Formula: ~1 | trt %in% block %in% trial
? ? ? ? (Intercept) ?Residual
StdDev: ?0.07081356 0.1020226

Fixed effects: y ~ trt
? ? ? ? ? ? ? ? ? Value ?Std.Error DF ? ?t-value p-value
(Intercept) ?0.24428523 0.08793775 56 ?2.7779337 ?0.0074
trtau2 ? ? ?-0.00996643 0.05605221 25 -0.1778063 ?0.8603
trtberm ? ? -0.12786905 0.05686903 25 -2.2484830 ?0.0336
trtls44 ? ? ?0.12326637 0.05478364 25 ?2.2500582 ?0.0335
trtsr10y5 ? ?0.02513355 0.05517460 25 ?0.4555275 ?0.6527
trtsr10y6 ? ?0.01932992 0.05478364 25 ?0.3528410 ?0.7272
?Correlation:
? ? ? ? ? (Intr) trtau2 trtbrm trtl44 trt105
trtau2 ? ?-0.314
trtberm ? -0.309 ?0.486
trtls44 ? -0.321 ?0.504 ?0.497
trtsr10y5 -0.319 ?0.500 ?0.493 ?0.511
trtsr10y6 -0.321 ?0.504 ?0.497 ?0.515 ?0.511

Standardized Within-Group Residuals:
? ? ? ? ? Min ? ? ? ? ? ?Q1 ? ? ? ? ? Med ? ? ? ? ? ?Q3 ? ? ? ? ? Max
-2.614096e+00 -5.666986e-01 -9.727356e-05 ?4.692685e-01 ?2.410879e+00

Number of Observations: 92
Number of Groups:
? ? ? ? ? ? ? ? ? ? trial ? ? ? ? ?block %in% trial trt %in% block %in% trial
? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? 6 ? ? ? ? ? ? ? ? ? ? ? ?36
> anova(fm.lme)
? ? ? ? ? ? numDF denDF ?F-value p-value
(Intercept) ? ? 1 ? ?56 9.907983 ?0.0026
trt ? ? ? ? ? ? 5 ? ?25 4.122070 ?0.0072


SAS code and outputs:
proc glimmix data=df;
model y=trt;
random trial block(trial) turf(block*turf);
run;

     Covariance Parameter Estimates

                                 Standard
Cov Parm             Estimate       Error

trial                 0.01237     0.01823
block(trial)                0           .
trt(trial*block)    0.005015    0.002546
Residual              0.01041    0.001963


        Type III Tests of Fixed Effects

              Num      Den
Effect         DF       DF    F Value    Pr > F

trt            5       25       4.12    0.0072



On Mon, Jun 25, 2012 at 10:25 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>
> This could be similar to a multi-location RCB design were "trial" is
> location. ?Since no distribution is specified, the distribution is
> assumed to be Gaussian. ?Make sure that trial, block, trt are factors,
> this should be similar to SAS:
>
> lmer(y ~ trt + (1|trial/block/trt), data=df)
>
> > proc glimmix data=df;
> > class trial block trt;
> > model y=trt;
> > random trial block(trial) trt(block*trial);
>
> Kevin Wright


From bates at stat.wisc.edu  Mon Jun 25 19:28:23 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 25 Jun 2012 12:28:23 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
Message-ID: <CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>

Are you trying to load both the nlme and the lme4 packages at the same
time?  That can cause problems.  You are better off fitting the lmer
model in one R session and the lme model in another.

On Mon, Jun 25, 2012 at 11:50 AM, Steve Hong <emptican at gmail.com> wrote:
> Thank all of you for replying to me.
>
> I tried lmer, lme, and SAS. ?I was able to get outputs when I use
> 'lme' whereas no results from 'lmer'. ?I don't know why. ?Does anyone
> know what the warning message mean? ?Outputs from ?'lme' were similar
> with those from SAS. ?Below is selected outputs from lmer, lme, and
> SAS, FYI.
>
> Thanks again,
>
> Steve Hong
>
>> fm.lmer <- lmer(y ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
> Error: length(f1) == length(f2) is not TRUE
> In addition: Warning messages:
> 1: In block:trial :
> ? numerical expression has 92 elements: only the first used
> 2: In block:trial :
> ? numerical expression has 92 elements: only the first used
> 3: In trt:(block:trial) :
> ? numerical expression has 92 elements: only the first used
> 4: In block:trial :
> ? numerical expression has 92 elements: only the first used
> 5: In block:trial :
> ? numerical expression has 92 elements: only the first used
>> fm.lme <- lme(y ~ trt, random=(~1|trial/block/trt), data = df, na.action=na.omit)
>> summary(fm.lme)
> Linear mixed-effects model fit by REML
> ?Data: df
> ? ? ? ? AIC ? ? ? BIC ? logLik
> ? -85.22388 -60.68041 52.61194
>
> Random effects:
> ?Formula: ~1 | trial
> ? ? ? ? (Intercept)
> StdDev: ? 0.1112442
>
> ?Formula: ~1 | block %in% trial
> ? ? ? ? ?(Intercept)
> StdDev: 1.449228e-06
>
> ?Formula: ~1 | trt %in% block %in% trial
> ? ? ? ? (Intercept) ?Residual
> StdDev: ?0.07081356 0.1020226
>
> Fixed effects: y ~ trt
> ? ? ? ? ? ? ? ? ? Value ?Std.Error DF ? ?t-value p-value
> (Intercept) ?0.24428523 0.08793775 56 ?2.7779337 ?0.0074
> trtau2 ? ? ?-0.00996643 0.05605221 25 -0.1778063 ?0.8603
> trtberm ? ? -0.12786905 0.05686903 25 -2.2484830 ?0.0336
> trtls44 ? ? ?0.12326637 0.05478364 25 ?2.2500582 ?0.0335
> trtsr10y5 ? ?0.02513355 0.05517460 25 ?0.4555275 ?0.6527
> trtsr10y6 ? ?0.01932992 0.05478364 25 ?0.3528410 ?0.7272
> ?Correlation:
> ? ? ? ? ? (Intr) trtau2 trtbrm trtl44 trt105
> trtau2 ? ?-0.314
> trtberm ? -0.309 ?0.486
> trtls44 ? -0.321 ?0.504 ?0.497
> trtsr10y5 -0.319 ?0.500 ?0.493 ?0.511
> trtsr10y6 -0.321 ?0.504 ?0.497 ?0.515 ?0.511
>
> Standardized Within-Group Residuals:
> ? ? ? ? ? Min ? ? ? ? ? ?Q1 ? ? ? ? ? Med ? ? ? ? ? ?Q3 ? ? ? ? ? Max
> -2.614096e+00 -5.666986e-01 -9.727356e-05 ?4.692685e-01 ?2.410879e+00
>
> Number of Observations: 92
> Number of Groups:
> ? ? ? ? ? ? ? ? ? ? trial ? ? ? ? ?block %in% trial trt %in% block %in% trial
> ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? 6 ? ? ? ? ? ? ? ? ? ? ? ?36
>> anova(fm.lme)
> ? ? ? ? ? ? numDF denDF ?F-value p-value
> (Intercept) ? ? 1 ? ?56 9.907983 ?0.0026
> trt ? ? ? ? ? ? 5 ? ?25 4.122070 ?0.0072
>
>
> SAS code and outputs:
> proc glimmix data=df;
> model y=trt;
> random trial block(trial) turf(block*turf);
> run;
>
> ? ? Covariance Parameter Estimates
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Standard
> Cov Parm ? ? ? ? ? ? Estimate ? ? ? Error
>
> trial ? ? ? ? ? ? ? ? 0.01237 ? ? 0.01823
> block(trial) ? ? ? ? ? ? ? ?0 ? ? ? ? ? .
> trt(trial*block) ? ?0.005015 ? ?0.002546
> Residual ? ? ? ? ? ? ?0.01041 ? ?0.001963
>
>
> ? ? ? ?Type III Tests of Fixed Effects
>
> ? ? ? ? ? ? ?Num ? ? ?Den
> Effect ? ? ? ? DF ? ? ? DF ? ?F Value ? ?Pr > F
>
> trt ? ? ? ? ? ?5 ? ? ? 25 ? ? ? 4.12 ? ?0.0072
>
>
>
> On Mon, Jun 25, 2012 at 10:25 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>
>> This could be similar to a multi-location RCB design were "trial" is
>> location. ?Since no distribution is specified, the distribution is
>> assumed to be Gaussian. ?Make sure that trial, block, trt are factors,
>> this should be similar to SAS:
>>
>> lmer(y ~ trt + (1|trial/block/trt), data=df)
>>
>> > proc glimmix data=df;
>> > class trial block trt;
>> > model y=trt;
>> > random trial block(trial) trt(block*trial);
>>
>> Kevin Wright
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emptican at gmail.com  Mon Jun 25 19:41:11 2012
From: emptican at gmail.com (Steve Hong)
Date: Mon, 25 Jun 2012 12:41:11 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
	<CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>
Message-ID: <CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>

Hi Prof. Bates,

Thanks for replying.  Yes, I loaded both packages together and ran
them.  I don't understand different/separate R 'session'?  Obviously,
it seems not different versions (e.g., 2.15.0 vs. 2.14.0).  Could you
rephrase what you meant by R 'session'?

Thanks,

Steve



On Mon, Jun 25, 2012 at 12:28 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> Are you trying to load both the nlme and the lme4 packages at the same
> time? ?That can cause problems. ?You are better off fitting the lmer
> model in one R session and the lme model in another.
>
> On Mon, Jun 25, 2012 at 11:50 AM, Steve Hong <emptican at gmail.com> wrote:
>> Thank all of you for replying to me.
>>
>> I tried lmer, lme, and SAS. ?I was able to get outputs when I use
>> 'lme' whereas no results from 'lmer'. ?I don't know why. ?Does anyone
>> know what the warning message mean? ?Outputs from ?'lme' were similar
>> with those from SAS. ?Below is selected outputs from lmer, lme, and
>> SAS, FYI.
>>
>> Thanks again,
>>
>> Steve Hong
>>
>>> fm.lmer <- lmer(y ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
>> Error: length(f1) == length(f2) is not TRUE
>> In addition: Warning messages:
>> 1: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>> 2: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>> 3: In trt:(block:trial) :
>> ? numerical expression has 92 elements: only the first used
>> 4: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>> 5: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>>> fm.lme <- lme(y ~ trt, random=(~1|trial/block/trt), data = df, na.action=na.omit)
>>> summary(fm.lme)
>> Linear mixed-effects model fit by REML
>> ?Data: df
>> ? ? ? ? AIC ? ? ? BIC ? logLik
>> ? -85.22388 -60.68041 52.61194
>>
>> Random effects:
>> ?Formula: ~1 | trial
>> ? ? ? ? (Intercept)
>> StdDev: ? 0.1112442
>>
>> ?Formula: ~1 | block %in% trial
>> ? ? ? ? ?(Intercept)
>> StdDev: 1.449228e-06
>>
>> ?Formula: ~1 | trt %in% block %in% trial
>> ? ? ? ? (Intercept) ?Residual
>> StdDev: ?0.07081356 0.1020226
>>
>> Fixed effects: y ~ trt
>> ? ? ? ? ? ? ? ? ? Value ?Std.Error DF ? ?t-value p-value
>> (Intercept) ?0.24428523 0.08793775 56 ?2.7779337 ?0.0074
>> trtau2 ? ? ?-0.00996643 0.05605221 25 -0.1778063 ?0.8603
>> trtberm ? ? -0.12786905 0.05686903 25 -2.2484830 ?0.0336
>> trtls44 ? ? ?0.12326637 0.05478364 25 ?2.2500582 ?0.0335
>> trtsr10y5 ? ?0.02513355 0.05517460 25 ?0.4555275 ?0.6527
>> trtsr10y6 ? ?0.01932992 0.05478364 25 ?0.3528410 ?0.7272
>> ?Correlation:
>> ? ? ? ? ? (Intr) trtau2 trtbrm trtl44 trt105
>> trtau2 ? ?-0.314
>> trtberm ? -0.309 ?0.486
>> trtls44 ? -0.321 ?0.504 ?0.497
>> trtsr10y5 -0.319 ?0.500 ?0.493 ?0.511
>> trtsr10y6 -0.321 ?0.504 ?0.497 ?0.515 ?0.511
>>
>> Standardized Within-Group Residuals:
>> ? ? ? ? ? Min ? ? ? ? ? ?Q1 ? ? ? ? ? Med ? ? ? ? ? ?Q3 ? ? ? ? ? Max
>> -2.614096e+00 -5.666986e-01 -9.727356e-05 ?4.692685e-01 ?2.410879e+00
>>
>> Number of Observations: 92
>> Number of Groups:
>> ? ? ? ? ? ? ? ? ? ? trial ? ? ? ? ?block %in% trial trt %in% block %in% trial
>> ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? 6 ? ? ? ? ? ? ? ? ? ? ? ?36
>>> anova(fm.lme)
>> ? ? ? ? ? ? numDF denDF ?F-value p-value
>> (Intercept) ? ? 1 ? ?56 9.907983 ?0.0026
>> trt ? ? ? ? ? ? 5 ? ?25 4.122070 ?0.0072
>>
>>
>> SAS code and outputs:
>> proc glimmix data=df;
>> model y=trt;
>> random trial block(trial) turf(block*turf);
>> run;
>>
>> ? ? Covariance Parameter Estimates
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Standard
>> Cov Parm ? ? ? ? ? ? Estimate ? ? ? Error
>>
>> trial ? ? ? ? ? ? ? ? 0.01237 ? ? 0.01823
>> block(trial) ? ? ? ? ? ? ? ?0 ? ? ? ? ? .
>> trt(trial*block) ? ?0.005015 ? ?0.002546
>> Residual ? ? ? ? ? ? ?0.01041 ? ?0.001963
>>
>>
>> ? ? ? ?Type III Tests of Fixed Effects
>>
>> ? ? ? ? ? ? ?Num ? ? ?Den
>> Effect ? ? ? ? DF ? ? ? DF ? ?F Value ? ?Pr > F
>>
>> trt ? ? ? ? ? ?5 ? ? ? 25 ? ? ? 4.12 ? ?0.0072
>>
>>
>>
>> On Mon, Jun 25, 2012 at 10:25 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>>
>>> This could be similar to a multi-location RCB design were "trial" is
>>> location. ?Since no distribution is specified, the distribution is
>>> assumed to be Gaussian. ?Make sure that trial, block, trt are factors,
>>> this should be similar to SAS:
>>>
>>> lmer(y ~ trt + (1|trial/block/trt), data=df)
>>>
>>> > proc glimmix data=df;
>>> > class trial block trt;
>>> > model y=trt;
>>> > random trial block(trial) trt(block*trial);
>>>
>>> Kevin Wright
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pauljohn32 at gmail.com  Mon Jun 25 19:45:26 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 25 Jun 2012 12:45:26 -0500
Subject: [R-sig-ME] need help with predicted values from lmer with
	newdata
In-Reply-To: <loom.20120623T132717-78@post.gmane.org>
References: <CAErODj9AyM7eVAkMO7NfhXRdbZUGFJ7fX6PhV7BZf1pLSneyCg@mail.gmail.com>
	<CANz9Z_Jmjxp7N55xt8G139XPDBwPyZssXAugGhQvN=3uGZWVEA@mail.gmail.com>
	<loom.20120623T132717-78@post.gmane.org>
Message-ID: <CAErODj8aA1wniHFxEE50VwW02g8EXOX0sJPqbWbk9tx7UhRCwQ@mail.gmail.com>

On Sat, Jun 23, 2012 at 6:27 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Joshua Wiley <jwiley.psych at ...> writes:

>
> ?Paul, would you be willing to generate a trimmed-down version of your
> example that simply generates multi-trait data?
>

I noticed Joshua already working on help page. Great. I don't want to
duplicate his effort, i'm going to keep working on example usages
which Ben may be able to use in the documentation.  I think this
example will be good for lmer, once it is tighter.

I'm attaching most recent longish version to this note. I've already
cut out some crap, but it is not tightened down to minimums yet
because I am stuck on 2 issues. After I understand those, I can cut
out some more crap. The surprise I had last friday with the predicted
values has made me feel cautious/worried.  Also, I will supply a
version that does not depend on my other package "rockchalk".

First, the merMod question.

I want to script up a simulation that fits lots of lmer and calculates
the "bias" and variance of the estimates of the random effects.  If
you run the script I attach, you get a rough idea of how one
particular run would be analyzed. But I'll scale this up, eventually.

What is the recommended way to extract estimated standard deviations
of random effects for a model like this:

mm3 <- lmer( y3 ~ x1 + x2 + x3 + (1|Mind) + (-1 + x1 | Mind),
data=dat, verbose=3)

Don't say "allow correlation between random intercept and random
slope" right now. I allow that later. Here we are wondering, "if we
ignore correlation between random effects, what happens?"

Here's what I tried, after reading lme4 source code. Problem, the
names on the first two list elements are "Mind". So I can't get the
std dev of the slope of x1

## The usual spiel goes
summary(mm3)
mm3VarCorr <- VarCorr(mm3)
mm3VarCorr

## Yank out the standard deviation estimates. idiom stolen from
formatVC in lmer code.
mm3reStdDev <- c(lapply(mm3VarCorr, attr, "stddev"), list(Residual =
attr(mm3VarCorr, "sc")))
mm3reStdDev

## Calculate bias of this run's estimate:
mm3reStdDev[["Mind"]]["(Intercept)"] - STDEb0
##mm3reStdDev[["Mind"]]["x1"] - STDEb1
## Can't figure how to get STD(b1)

I can get it if I access the list members with their numbers

attr(mm3VarCorr[[2]], "stddev")

but in a general setting, this is not good because it pre-supposes I
know that mm3VarCorr has 2 elements in that list.


Second, this is a substantive question.  I've run this script 100s of
times, plugging in various values of the variance of the X's, the
variance of the b's, and the residual standard deviation.

In many cases, the estimates from lmer come out almost exactly right,
but sometimes I fiddle the parameters so that some nonsense appears to
happen.  In the attached script, there is some nonsense, I expect you
will see if you run it.

Here there are 2 nonsensical results:

mm2 <- lmer( y2 ~ x1 + x2 + x3 + (1 | Mind), data=dat)

gives variance estimate for Mind of 0.  So, apparently, there's some
ratio of STDEb0/STDE at which STDEb0 becomes undetectable?  Possible.

And in mm4, where it says the correlation of the random effects is 1.00.

It doesn't always happen, depending on the relative sizes of STDE,
STDEb0, and STDEb1, I can produce things I understand.

I started calculating the correlation of the fitted and the observed
values to make sense out of this,

cor(fitted(mm2), dat$y2)

but don't quite get it. Yet.

Come to think of it, I will just attach the transcript so you don't
have to run this.

But you should run it to see my graphs, which are lovely.

-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu

From bates at stat.wisc.edu  Mon Jun 25 20:01:51 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 25 Jun 2012 13:01:51 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
	<CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>
	<CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>
Message-ID: <CAO7JsnRb=6XKHxa=WJLjbLDgyWno7_TwA-jbdXxF2Q+mx=Ahag@mail.gmail.com>

On Mon, Jun 25, 2012 at 12:41 PM, Steve Hong <emptican at gmail.com> wrote:
> Hi Prof. Bates,
>
> Thanks for replying. ?Yes, I loaded both packages together and ran
> them. ?I don't understand different/separate R 'session'? ?Obviously,
> it seems not different versions (e.g., 2.15.0 vs. 2.14.0). ?Could you
> rephrase what you meant by R 'session'?

I mean to run R, load lme4 and fit the model.  Then quit R and restart
it, load nlme and fit that model.

> On Mon, Jun 25, 2012 at 12:28 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> Are you trying to load both the nlme and the lme4 packages at the same
>> time? ?That can cause problems. ?You are better off fitting the lmer
>> model in one R session and the lme model in another.
>>
>> On Mon, Jun 25, 2012 at 11:50 AM, Steve Hong <emptican at gmail.com> wrote:
>>> Thank all of you for replying to me.
>>>
>>> I tried lmer, lme, and SAS. ?I was able to get outputs when I use
>>> 'lme' whereas no results from 'lmer'. ?I don't know why. ?Does anyone
>>> know what the warning message mean? ?Outputs from ?'lme' were similar
>>> with those from SAS. ?Below is selected outputs from lmer, lme, and
>>> SAS, FYI.
>>>
>>> Thanks again,
>>>
>>> Steve Hong
>>>
>>>> fm.lmer <- lmer(y ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
>>> Error: length(f1) == length(f2) is not TRUE
>>> In addition: Warning messages:
>>> 1: In block:trial :
>>> ? numerical expression has 92 elements: only the first used
>>> 2: In block:trial :
>>> ? numerical expression has 92 elements: only the first used
>>> 3: In trt:(block:trial) :
>>> ? numerical expression has 92 elements: only the first used
>>> 4: In block:trial :
>>> ? numerical expression has 92 elements: only the first used
>>> 5: In block:trial :
>>> ? numerical expression has 92 elements: only the first used
>>>> fm.lme <- lme(y ~ trt, random=(~1|trial/block/trt), data = df, na.action=na.omit)
>>>> summary(fm.lme)
>>> Linear mixed-effects model fit by REML
>>> ?Data: df
>>> ? ? ? ? AIC ? ? ? BIC ? logLik
>>> ? -85.22388 -60.68041 52.61194
>>>
>>> Random effects:
>>> ?Formula: ~1 | trial
>>> ? ? ? ? (Intercept)
>>> StdDev: ? 0.1112442
>>>
>>> ?Formula: ~1 | block %in% trial
>>> ? ? ? ? ?(Intercept)
>>> StdDev: 1.449228e-06
>>>
>>> ?Formula: ~1 | trt %in% block %in% trial
>>> ? ? ? ? (Intercept) ?Residual
>>> StdDev: ?0.07081356 0.1020226
>>>
>>> Fixed effects: y ~ trt
>>> ? ? ? ? ? ? ? ? ? Value ?Std.Error DF ? ?t-value p-value
>>> (Intercept) ?0.24428523 0.08793775 56 ?2.7779337 ?0.0074
>>> trtau2 ? ? ?-0.00996643 0.05605221 25 -0.1778063 ?0.8603
>>> trtberm ? ? -0.12786905 0.05686903 25 -2.2484830 ?0.0336
>>> trtls44 ? ? ?0.12326637 0.05478364 25 ?2.2500582 ?0.0335
>>> trtsr10y5 ? ?0.02513355 0.05517460 25 ?0.4555275 ?0.6527
>>> trtsr10y6 ? ?0.01932992 0.05478364 25 ?0.3528410 ?0.7272
>>> ?Correlation:
>>> ? ? ? ? ? (Intr) trtau2 trtbrm trtl44 trt105
>>> trtau2 ? ?-0.314
>>> trtberm ? -0.309 ?0.486
>>> trtls44 ? -0.321 ?0.504 ?0.497
>>> trtsr10y5 -0.319 ?0.500 ?0.493 ?0.511
>>> trtsr10y6 -0.321 ?0.504 ?0.497 ?0.515 ?0.511
>>>
>>> Standardized Within-Group Residuals:
>>> ? ? ? ? ? Min ? ? ? ? ? ?Q1 ? ? ? ? ? Med ? ? ? ? ? ?Q3 ? ? ? ? ? Max
>>> -2.614096e+00 -5.666986e-01 -9.727356e-05 ?4.692685e-01 ?2.410879e+00
>>>
>>> Number of Observations: 92
>>> Number of Groups:
>>> ? ? ? ? ? ? ? ? ? ? trial ? ? ? ? ?block %in% trial trt %in% block %in% trial
>>> ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? 6 ? ? ? ? ? ? ? ? ? ? ? ?36
>>>> anova(fm.lme)
>>> ? ? ? ? ? ? numDF denDF ?F-value p-value
>>> (Intercept) ? ? 1 ? ?56 9.907983 ?0.0026
>>> trt ? ? ? ? ? ? 5 ? ?25 4.122070 ?0.0072
>>>
>>>
>>> SAS code and outputs:
>>> proc glimmix data=df;
>>> model y=trt;
>>> random trial block(trial) turf(block*turf);
>>> run;
>>>
>>> ? ? Covariance Parameter Estimates
>>>
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Standard
>>> Cov Parm ? ? ? ? ? ? Estimate ? ? ? Error
>>>
>>> trial ? ? ? ? ? ? ? ? 0.01237 ? ? 0.01823
>>> block(trial) ? ? ? ? ? ? ? ?0 ? ? ? ? ? .
>>> trt(trial*block) ? ?0.005015 ? ?0.002546
>>> Residual ? ? ? ? ? ? ?0.01041 ? ?0.001963
>>>
>>>
>>> ? ? ? ?Type III Tests of Fixed Effects
>>>
>>> ? ? ? ? ? ? ?Num ? ? ?Den
>>> Effect ? ? ? ? DF ? ? ? DF ? ?F Value ? ?Pr > F
>>>
>>> trt ? ? ? ? ? ?5 ? ? ? 25 ? ? ? 4.12 ? ?0.0072
>>>
>>>
>>>
>>> On Mon, Jun 25, 2012 at 10:25 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>>>
>>>> This could be similar to a multi-location RCB design were "trial" is
>>>> location. ?Since no distribution is specified, the distribution is
>>>> assumed to be Gaussian. ?Make sure that trial, block, trt are factors,
>>>> this should be similar to SAS:
>>>>
>>>> lmer(y ~ trt + (1|trial/block/trt), data=df)
>>>>
>>>> > proc glimmix data=df;
>>>> > class trial block trt;
>>>> > model y=trt;
>>>> > random trial block(trial) trt(block*trial);
>>>>
>>>> Kevin Wright
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emptican at gmail.com  Mon Jun 25 20:12:52 2012
From: emptican at gmail.com (Steve Hong)
Date: Mon, 25 Jun 2012 13:12:52 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <CAO7JsnRb=6XKHxa=WJLjbLDgyWno7_TwA-jbdXxF2Q+mx=Ahag@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
	<CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>
	<CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>
	<CAO7JsnRb=6XKHxa=WJLjbLDgyWno7_TwA-jbdXxF2Q+mx=Ahag@mail.gmail.com>
Message-ID: <CALSKosBAOCdc-B-LhOqVycsBtbJ5koc9JhwaNOJ_C0AYMM0sKA@mail.gmail.com>

I restarted R and tried to fit the model.  However, I got the same
message...  So, I checked the session information with sessionInfo().
I found there is still nlme package in "loaded via a namespace (and
not attached)".  Is it still causing problem?

Here is what I did:

R version 2.15.0 (2012-03-30)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: i386-pc-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> df <- bcwrear1
> y <- df$day10
> trial <- df$trial
> block <- df$block
> trt <- df$turf
> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: ?lme4?

The following object(s) are masked from ?package:stats?:

    AIC, BIC

> fm.lmer <- lmer(log10(day10) ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In block:trial :
  numerical expression has 92 elements: only the first used
2: In block:trial :
  numerical expression has 92 elements: only the first used
3: In trt:(block:trial) :
  numerical expression has 92 elements: only the first used
4: In block:trial :
  numerical expression has 92 elements: only the first used
5: In block:trial :
  numerical expression has 92 elements: only the first used
>
> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-42 Matrix_1.0-6     lattice_0.20-6

loaded via a namespace (and not attached):
[1] grid_2.15.0   nlme_3.1-103  stats4_2.15.0




Thanks!!!

Steve






On Mon, Jun 25, 2012 at 1:01 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Mon, Jun 25, 2012 at 12:41 PM, Steve Hong <emptican at gmail.com> wrote:
>> Hi Prof. Bates,
>>
>> Thanks for replying. ?Yes, I loaded both packages together and ran
>> them. ?I don't understand different/separate R 'session'? ?Obviously,
>> it seems not different versions (e.g., 2.15.0 vs. 2.14.0). ?Could you
>> rephrase what you meant by R 'session'?
>
> I mean to run R, load lme4 and fit the model. ?Then quit R and restart
> it, load nlme and fit that model.
>
>> On Mon, Jun 25, 2012 at 12:28 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> Are you trying to load both the nlme and the lme4 packages at the same
>>> time? ?That can cause problems. ?You are better off fitting the lmer
>>> model in one R session and the lme model in another.
>>>
>>> On Mon, Jun 25, 2012 at 11:50 AM, Steve Hong <emptican at gmail.com> wrote:
>>>> Thank all of you for replying to me.
>>>>
>>>> I tried lmer, lme, and SAS. ?I was able to get outputs when I use
>>>> 'lme' whereas no results from 'lmer'. ?I don't know why. ?Does anyone
>>>> know what the warning message mean? ?Outputs from ?'lme' were similar
>>>> with those from SAS. ?Below is selected outputs from lmer, lme, and
>>>> SAS, FYI.
>>>>
>>>> Thanks again,
>>>>
>>>> Steve Hong
>>>>
>>>>> fm.lmer <- lmer(y ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
>>>> Error: length(f1) == length(f2) is not TRUE
>>>> In addition: Warning messages:
>>>> 1: In block:trial :
>>>> ? numerical expression has 92 elements: only the first used
>>>> 2: In block:trial :
>>>> ? numerical expression has 92 elements: only the first used
>>>> 3: In trt:(block:trial) :
>>>> ? numerical expression has 92 elements: only the first used
>>>> 4: In block:trial :
>>>> ? numerical expression has 92 elements: only the first used
>>>> 5: In block:trial :
>>>> ? numerical expression has 92 elements: only the first used
>>>>> fm.lme <- lme(y ~ trt, random=(~1|trial/block/trt), data = df, na.action=na.omit)
>>>>> summary(fm.lme)
>>>> Linear mixed-effects model fit by REML
>>>> ?Data: df
>>>> ? ? ? ? AIC ? ? ? BIC ? logLik
>>>> ? -85.22388 -60.68041 52.61194
>>>>
>>>> Random effects:
>>>> ?Formula: ~1 | trial
>>>> ? ? ? ? (Intercept)
>>>> StdDev: ? 0.1112442
>>>>
>>>> ?Formula: ~1 | block %in% trial
>>>> ? ? ? ? ?(Intercept)
>>>> StdDev: 1.449228e-06
>>>>
>>>> ?Formula: ~1 | trt %in% block %in% trial
>>>> ? ? ? ? (Intercept) ?Residual
>>>> StdDev: ?0.07081356 0.1020226
>>>>
>>>> Fixed effects: y ~ trt
>>>> ? ? ? ? ? ? ? ? ? Value ?Std.Error DF ? ?t-value p-value
>>>> (Intercept) ?0.24428523 0.08793775 56 ?2.7779337 ?0.0074
>>>> trtau2 ? ? ?-0.00996643 0.05605221 25 -0.1778063 ?0.8603
>>>> trtberm ? ? -0.12786905 0.05686903 25 -2.2484830 ?0.0336
>>>> trtls44 ? ? ?0.12326637 0.05478364 25 ?2.2500582 ?0.0335
>>>> trtsr10y5 ? ?0.02513355 0.05517460 25 ?0.4555275 ?0.6527
>>>> trtsr10y6 ? ?0.01932992 0.05478364 25 ?0.3528410 ?0.7272
>>>> ?Correlation:
>>>> ? ? ? ? ? (Intr) trtau2 trtbrm trtl44 trt105
>>>> trtau2 ? ?-0.314
>>>> trtberm ? -0.309 ?0.486
>>>> trtls44 ? -0.321 ?0.504 ?0.497
>>>> trtsr10y5 -0.319 ?0.500 ?0.493 ?0.511
>>>> trtsr10y6 -0.321 ?0.504 ?0.497 ?0.515 ?0.511
>>>>
>>>> Standardized Within-Group Residuals:
>>>> ? ? ? ? ? Min ? ? ? ? ? ?Q1 ? ? ? ? ? Med ? ? ? ? ? ?Q3 ? ? ? ? ? Max
>>>> -2.614096e+00 -5.666986e-01 -9.727356e-05 ?4.692685e-01 ?2.410879e+00
>>>>
>>>> Number of Observations: 92
>>>> Number of Groups:
>>>> ? ? ? ? ? ? ? ? ? ? trial ? ? ? ? ?block %in% trial trt %in% block %in% trial
>>>> ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? 6 ? ? ? ? ? ? ? ? ? ? ? ?36
>>>>> anova(fm.lme)
>>>> ? ? ? ? ? ? numDF denDF ?F-value p-value
>>>> (Intercept) ? ? 1 ? ?56 9.907983 ?0.0026
>>>> trt ? ? ? ? ? ? 5 ? ?25 4.122070 ?0.0072
>>>>
>>>>
>>>> SAS code and outputs:
>>>> proc glimmix data=df;
>>>> model y=trt;
>>>> random trial block(trial) turf(block*turf);
>>>> run;
>>>>
>>>> ? ? Covariance Parameter Estimates
>>>>
>>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Standard
>>>> Cov Parm ? ? ? ? ? ? Estimate ? ? ? Error
>>>>
>>>> trial ? ? ? ? ? ? ? ? 0.01237 ? ? 0.01823
>>>> block(trial) ? ? ? ? ? ? ? ?0 ? ? ? ? ? .
>>>> trt(trial*block) ? ?0.005015 ? ?0.002546
>>>> Residual ? ? ? ? ? ? ?0.01041 ? ?0.001963
>>>>
>>>>
>>>> ? ? ? ?Type III Tests of Fixed Effects
>>>>
>>>> ? ? ? ? ? ? ?Num ? ? ?Den
>>>> Effect ? ? ? ? DF ? ? ? DF ? ?F Value ? ?Pr > F
>>>>
>>>> trt ? ? ? ? ? ?5 ? ? ? 25 ? ? ? 4.12 ? ?0.0072
>>>>
>>>>
>>>>
>>>> On Mon, Jun 25, 2012 at 10:25 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>>>>
>>>>> This could be similar to a multi-location RCB design were "trial" is
>>>>> location. ?Since no distribution is specified, the distribution is
>>>>> assumed to be Gaussian. ?Make sure that trial, block, trt are factors,
>>>>> this should be similar to SAS:
>>>>>
>>>>> lmer(y ~ trt + (1|trial/block/trt), data=df)
>>>>>
>>>>> > proc glimmix data=df;
>>>>> > class trial block trt;
>>>>> > model y=trt;
>>>>> > random trial block(trial) trt(block*trial);
>>>>>
>>>>> Kevin Wright
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jake987722 at hotmail.com  Mon Jun 25 20:36:49 2012
From: jake987722 at hotmail.com (Jake Westfall)
Date: Mon, 25 Jun 2012 12:36:49 -0600
Subject: [R-sig-ME] sas to R
In-Reply-To: <CALSKosBAOCdc-B-LhOqVycsBtbJ5koc9JhwaNOJ_C0AYMM0sKA@mail.gmail.com>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>,
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>,
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>,
	<CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>,
	<CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>,
	<CAO7JsnRb=6XKHxa=WJLjbLDgyWno7_TwA-jbdXxF2Q+mx=Ahag@mail.gmail.com>,
	<CALSKosBAOCdc-B-LhOqVycsBtbJ5koc9JhwaNOJ_C0AYMM0sKA@mail.gmail.com>
Message-ID: <SNT107-W282D61055A59623501FAD1CBE10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120625/4a090771/attachment.pl>

From emptican at gmail.com  Mon Jun 25 21:03:02 2012
From: emptican at gmail.com (Steve Hong)
Date: Mon, 25 Jun 2012 14:03:02 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <SNT107-W282D61055A59623501FAD1CBE10@phx.gbl>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
	<CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>
	<CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>
	<CAO7JsnRb=6XKHxa=WJLjbLDgyWno7_TwA-jbdXxF2Q+mx=Ahag@mail.gmail.com>
	<CALSKosBAOCdc-B-LhOqVycsBtbJ5koc9JhwaNOJ_C0AYMM0sKA@mail.gmail.com>
	<SNT107-W282D61055A59623501FAD1CBE10@phx.gbl>
Message-ID: <CALSKosDZwfUwrFb4bCs=gi2dhDZ_CA8KwZeVDqYK_78M0my+RQ@mail.gmail.com>

Thank you, all.

I restarted R and checked package list using 'search()'.  And then,
loaded 'lme4' and ran the model.  However, the results are same...

Below is what I did.

Thank you much again!!!

Steve




R version 2.15.0 (2012-03-30)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: i386-pc-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> search()
[1] ".GlobalEnv"        "package:stats"     "package:graphics"
[4] "package:grDevices" "package:utils"     "package:datasets"
[7] "package:methods"   "Autoloads"         "package:base"
> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: ?lme4?

The following object(s) are masked from ?package:stats?:

    AIC, BIC

> search()
 [1] ".GlobalEnv"        "package:lme4"      "package:Matrix"
 [4] "package:lattice"   "package:stats"     "package:graphics"
 [7] "package:grDevices" "package:utils"     "package:datasets"
[10] "package:methods"   "Autoloads"         "package:base"
> bcwrear1 <- read.table("C:/bcwrear1.txt", header=T)
> df <- bcwrear1
> df=bcwrear1
> df=transform(df, y=day10, trt=turf)
> fm.lmer <- lmer(log10(y) ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In block:trial :
  numerical expression has 92 elements: only the first used
2: In block:trial :
  numerical expression has 92 elements: only the first used
3: In trt:(block:trial) :
  numerical expression has 92 elements: only the first used
4: In block:trial :
  numerical expression has 92 elements: only the first used
5: In block:trial :
  numerical expression has 92 elements: only the first used
>



On Mon, Jun 25, 2012 at 1:36 PM, Jake Westfall <jake987722 at hotmail.com> wrote:
>
> You can unload nlme by using:
> detach("package:nlme")
>
>
> Jake
>
>> Date: Mon, 25 Jun 2012 13:12:52 -0500
>> From: emptican at gmail.com
>> To: bates at stat.wisc.edu
>> CC: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] sas to R
>>
>> I restarted R and tried to fit the model. ?However, I got the same
>> message... ?So, I checked the session information with sessionInfo().
>> I found there is still nlme package in "loaded via a namespace (and
>> not attached)". ?Is it still causing problem?
>>
>> Here is what I did:
>>
>> R version 2.15.0 (2012-03-30)
>> Copyright (C) 2012 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>> ? Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> [Previously saved workspace restored]
>>
>> > df <- bcwrear1
>> > y <- df$day10
>> > trial <- df$trial
>> > block <- df$block
>> > trt <- df$turf
>> > library(lme4)
>> Loading required package: Matrix
>> Loading required package: lattice
>>
>> Attaching package: ?lme4?
>>
>> The following object(s) are masked from ?package:stats?:
>>
>> ? ? AIC, BIC
>>
>> > fm.lmer <- lmer(log10(day10) ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
>> Error: length(f1) == length(f2) is not TRUE
>> In addition: Warning messages:
>> 1: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>> 2: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>> 3: In trt:(block:trial) :
>> ? numerical expression has 92 elements: only the first used
>> 4: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>> 5: In block:trial :
>> ? numerical expression has 92 elements: only the first used
>> >
>> > sessionInfo()
>> R version 2.15.0 (2012-03-30)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] lme4_0.999375-42 Matrix_1.0-6 ? ? lattice_0.20-6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.15.0 ? nlme_3.1-103 ?stats4_2.15.0
>>
>>
>>
>>
>> Thanks!!!
>>
>> Steve
>>
>>
>>
>>
>>
>>
>> On Mon, Jun 25, 2012 at 1:01 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> > On Mon, Jun 25, 2012 at 12:41 PM, Steve Hong <emptican at gmail.com> wrote:
>> >> Hi Prof. Bates,
>> >>
>> >> Thanks for replying. ?Yes, I loaded both packages together and ran
>> >> them. ?I don't understand different/separate R 'session'? ?Obviously,
>> >> it seems not different versions (e.g., 2.15.0 vs. 2.14.0). ?Could you
>> >> rephrase what you meant by R 'session'?
>> >
>> > I mean to run R, load lme4 and fit the model. ?Then quit R and restart
>> > it, load nlme and fit that model.
>> >
>> >> On Mon, Jun 25, 2012 at 12:28 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> >>> Are you trying to load both the nlme and the lme4 packages at the same
>> >>> time? ?That can cause problems. ?You are better off fitting the lmer
>> >>> model in one R session and the lme model in another.
>> >>>
>> >>> On Mon, Jun 25, 2012 at 11:50 AM, Steve Hong <emptican at gmail.com> wrote:
>> >>>> Thank all of you for replying to me.
>> >>>>
>> >>>> I tried lmer, lme, and SAS. ?I was able to get outputs when I use
>> >>>> 'lme' whereas no results from 'lmer'. ?I don't know why. ?Does anyone
>> >>>> know what the warning message mean? ?Outputs from ?'lme' were similar
>> >>>> with those from SAS. ?Below is selected outputs from lmer, lme, and
>> >>>> SAS, FYI.
>> >>>>
>> >>>> Thanks again,
>> >>>>
>> >>>> Steve Hong
>> >>>>
>> >>>>> fm.lmer <- lmer(y ~ trt + (1|trial/block/trt), data=df, na.action=na.omit)
>> >>>> Error: length(f1) == length(f2) is not TRUE
>> >>>> In addition: Warning messages:
>> >>>> 1: In block:trial :
>> >>>> ? numerical expression has 92 elements: only the first used
>> >>>> 2: In block:trial :
>> >>>> ? numerical expression has 92 elements: only the first used
>> >>>> 3: In trt:(block:trial) :
>> >>>> ? numerical expression has 92 elements: only the first used
>> >>>> 4: In block:trial :
>> >>>> ? numerical expression has 92 elements: only the first used
>> >>>> 5: In block:trial :
>> >>>> ? numerical expression has 92 elements: only the first used
>> >>>>> fm.lme <- lme(y ~ trt, random=(~1|trial/block/trt), data = df, na.action=na.omit)
>> >>>>> summary(fm.lme)
>> >>>> Linear mixed-effects model fit by REML
>> >>>> ?Data: df
>> >>>> ? ? ? ? AIC ? ? ? BIC ? logLik
>> >>>> ? -85.22388 -60.68041 52.61194
>> >>>>
>> >>>> Random effects:
>> >>>> ?Formula: ~1 | trial
>> >>>> ? ? ? ? (Intercept)
>> >>>> StdDev: ? 0.1112442
>> >>>>
>> >>>> ?Formula: ~1 | block %in% trial
>> >>>> ? ? ? ? ?(Intercept)
>> >>>> StdDev: 1.449228e-06
>> >>>>
>> >>>> ?Formula: ~1 | trt %in% block %in% trial
>> >>>> ? ? ? ? (Intercept) ?Residual
>> >>>> StdDev: ?0.07081356 0.1020226
>> >>>>
>> >>>> Fixed effects: y ~ trt
>> >>>> ? ? ? ? ? ? ? ? ? Value ?Std.Error DF ? ?t-value p-value
>> >>>> (Intercept) ?0.24428523 0.08793775 56 ?2.7779337 ?0.0074
>> >>>> trtau2 ? ? ?-0.00996643 0.05605221 25 -0.1778063 ?0.8603
>> >>>> trtberm ? ? -0.12786905 0.05686903 25 -2.2484830 ?0.0336
>> >>>> trtls44 ? ? ?0.12326637 0.05478364 25 ?2.2500582 ?0.0335
>> >>>> trtsr10y5 ? ?0.02513355 0.05517460 25 ?0.4555275 ?0.6527
>> >>>> trtsr10y6 ? ?0.01932992 0.05478364 25 ?0.3528410 ?0.7272
>> >>>> ?Correlation:
>> >>>> ? ? ? ? ? (Intr) trtau2 trtbrm trtl44 trt105
>> >>>> trtau2 ? ?-0.314
>> >>>> trtberm ? -0.309 ?0.486
>> >>>> trtls44 ? -0.321 ?0.504 ?0.497
>> >>>> trtsr10y5 -0.319 ?0.500 ?0.493 ?0.511
>> >>>> trtsr10y6 -0.321 ?0.504 ?0.497 ?0.515 ?0.511
>> >>>>
>> >>>> Standardized Within-Group Residuals:
>> >>>> ? ? ? ? ? Min ? ? ? ? ? ?Q1 ? ? ? ? ? Med ? ? ? ? ? ?Q3 ? ? ? ? ? Max
>> >>>> -2.614096e+00 -5.666986e-01 -9.727356e-05 ?4.692685e-01 ?2.410879e+00
>> >>>>
>> >>>> Number of Observations: 92
>> >>>> Number of Groups:
>> >>>> ? ? ? ? ? ? ? ? ? ? trial ? ? ? ? ?block %in% trial trt %in% block %in% trial
>> >>>> ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? 6 ? ? ? ? ? ? ? ? ? ? ? ?36
>> >>>>> anova(fm.lme)
>> >>>> ? ? ? ? ? ? numDF denDF ?F-value p-value
>> >>>> (Intercept) ? ? 1 ? ?56 9.907983 ?0.0026
>> >>>> trt ? ? ? ? ? ? 5 ? ?25 4.122070 ?0.0072
>> >>>>
>> >>>>
>> >>>> SAS code and outputs:
>> >>>> proc glimmix data=df;
>> >>>> model y=trt;
>> >>>> random trial block(trial) turf(block*turf);
>> >>>> run;
>> >>>>
>> >>>> ? ? Covariance Parameter Estimates
>> >>>>
>> >>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Standard
>> >>>> Cov Parm ? ? ? ? ? ? Estimate ? ? ? Error
>> >>>>
>> >>>> trial ? ? ? ? ? ? ? ? 0.01237 ? ? 0.01823
>> >>>> block(trial) ? ? ? ? ? ? ? ?0 ? ? ? ? ? .
>> >>>> trt(trial*block) ? ?0.005015 ? ?0.002546
>> >>>> Residual ? ? ? ? ? ? ?0.01041 ? ?0.001963
>> >>>>
>> >>>>
>> >>>> ? ? ? ?Type III Tests of Fixed Effects
>> >>>>
>> >>>> ? ? ? ? ? ? ?Num ? ? ?Den
>> >>>> Effect ? ? ? ? DF ? ? ? DF ? ?F Value ? ?Pr > F
>> >>>>
>> >>>> trt ? ? ? ? ? ?5 ? ? ? 25 ? ? ? 4.12 ? ?0.0072
>> >>>>
>> >>>>
>> >>>>
>> >>>> On Mon, Jun 25, 2012 at 10:25 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>> >>>>>
>> >>>>> This could be similar to a multi-location RCB design were "trial" is
>> >>>>> location. ?Since no distribution is specified, the distribution is
>> >>>>> assumed to be Gaussian. ?Make sure that trial, block, trt are factors,
>> >>>>> this should be similar to SAS:
>> >>>>>
>> >>>>> lmer(y ~ trt + (1|trial/block/trt), data=df)
>> >>>>>
>> >>>>> > proc glimmix data=df;
>> >>>>> > class trial block trt;
>> >>>>> > model y=trt;
>> >>>>> > random trial block(trial) trt(block*trial);
>> >>>>>
>> >>>>> Kevin Wright
>> >>>>
>> >>>> _______________________________________________
>> >>>> R-sig-mixed-models at r-project.org mailing list
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From chenlei at ibcas.ac.cn  Tue Jun 26 05:30:06 2012
From: chenlei at ibcas.ac.cn (chenlei)
Date: Tue, 26 Jun 2012 11:30:06 +0800 (GMT+08:00)
Subject: [R-sig-ME] Question of ineraction in LMM model
Message-ID: <17f9e7a.9a2a.13826d6c988.Coremail.chenlei@ibcas.ac.cn>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120626/f6da7ea6/attachment.pl>

From bbolker at gmail.com  Tue Jun 26 09:10:21 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Jun 2012 07:10:21 +0000 (UTC)
Subject: [R-sig-ME] sas to R
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
	<CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>
	<CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>
	<CAO7JsnRb=6XKHxa=WJLjbLDgyWno7_TwA-jbdXxF2Q+mx=Ahag@mail.gmail.com>
	<CALSKosBAOCdc-B-LhOqVycsBtbJ5koc9JhwaNOJ_C0AYMM0sKA@mail.gmail.com>
	<SNT107-W282D61055A59623501FAD1CBE10@phx.gbl>
	<CALSKosDZwfUwrFb4bCs=gi2dhDZ_CA8KwZeVDqYK_78M0my+RQ@mail.gmail.com>
Message-ID: <loom.20120626T090817-724@post.gmane.org>

Steve Hong <emptican at ...> writes:

> 
> Thank you, all.
> 
> I restarted R and checked package list using 'search()'.  And then,
> loaded 'lme4' and ran the model.  However, the results are same...
> 
> Below is what I did.
> 
> Thank you much again!!!
> 
> Steve

As Kevin Wright said:

Make sure that trial, block, trt are factors,
  [snip snip snip]


> > bcwrear1 <- read.table("C:/bcwrear1.txt", header=T)
> > df <- bcwrear1
> > df=bcwrear1
> > df=transform(df, y=day10, trt=turf)


df <- transform (trial=factor(trial), block=factor(block), trt=factor(trt))

> > fm.lmer <- lmer(log10(y) ~ trt + (1|trial/block/trt), data=df, 
 na.action=na.omit)


  [snip snip snip]


From sticklenator at gmail.com  Tue Jun 26 13:49:54 2012
From: sticklenator at gmail.com (Kay Lucek)
Date: Tue, 26 Jun 2012 13:49:54 +0200
Subject: [R-sig-ME] How to estimate variance components with lmer for models
 with random effects and compare them with lme results
Message-ID: <CANG6evgkE70EUfkkg=YqdAkeT6qdVaUgEFN70UwPYHb=GZwKNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120626/fb663457/attachment.pl>

From emptican at gmail.com  Tue Jun 26 16:09:15 2012
From: emptican at gmail.com (Steve Hong)
Date: Tue, 26 Jun 2012 09:09:15 -0500
Subject: [R-sig-ME] sas to R
In-Reply-To: <loom.20120626T090817-724@post.gmane.org>
References: <CALSKosBk7_7DifsPb7ZCTqWhvMUnW1LDF5mArs2fwjBRWMC2dQ@mail.gmail.com>
	<CAKFxdiQXk4AMwhUsXbb7CFhUWDVibOp_e49tFeGczvpZjyT+ig@mail.gmail.com>
	<CALSKosAzMbibgn6nUKTc7swddvio_af0BQLpOygD_SPhPJb+MA@mail.gmail.com>
	<CAO7JsnQtmKLXoNHsf26x4i+6G7hJjyozJ+7MPnEF=mCsfNr1EA@mail.gmail.com>
	<CALSKosDhzGE2UXwOWbrNyA3o7UQ1MUzj_pt0=KRaNNbkZ_yjQA@mail.gmail.com>
	<CAO7JsnRb=6XKHxa=WJLjbLDgyWno7_TwA-jbdXxF2Q+mx=Ahag@mail.gmail.com>
	<CALSKosBAOCdc-B-LhOqVycsBtbJ5koc9JhwaNOJ_C0AYMM0sKA@mail.gmail.com>
	<SNT107-W282D61055A59623501FAD1CBE10@phx.gbl>
	<CALSKosDZwfUwrFb4bCs=gi2dhDZ_CA8KwZeVDqYK_78M0my+RQ@mail.gmail.com>
	<loom.20120626T090817-724@post.gmane.org>
Message-ID: <CALSKosDyhni3P+3ukFRw8-VNSMzQEQjGyc5Eae0pE7NsZoy5eA@mail.gmail.com>

Thank all of you.

Ben and Kevin, you were right!  The main reason of my problem that I
experienced was not specifying factors (i.e., trial and block)...
Once I factorized them, I was able to run the models with both lme and
lmer in the SAME R session.  I think it was possible since I did not
use functions in lmer such as lmList.  Also, the results, especially
df and F-stats, were same or very close to results from SAS.  I
greatly appreciate all of your kind/patient suggestions.

Thank you again!!!

Steve

On Tue, Jun 26, 2012 at 2:10 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Steve Hong <emptican at ...> writes:
>
>>
>> Thank you, all.
>>
>> I restarted R and checked package list using 'search()'. ?And then,
>> loaded 'lme4' and ran the model. ?However, the results are same...
>>
>> Below is what I did.
>>
>> Thank you much again!!!
>>
>> Steve
>
> As Kevin Wright said:
>
> Make sure that trial, block, trt are factors,
> ?[snip snip snip]
>
>
>> > bcwrear1 <- read.table("C:/bcwrear1.txt", header=T)
>> > df <- bcwrear1
>> > df=bcwrear1
>> > df=transform(df, y=day10, trt=turf)
>
>
> df <- transform (trial=factor(trial), block=factor(block), trt=factor(trt))
>
>> > fm.lmer <- lmer(log10(y) ~ trt + (1|trial/block/trt), data=df,
> ?na.action=na.omit)
>
>
> ?[snip snip snip]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pauljohn32 at gmail.com  Tue Jun 26 20:37:24 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 26 Jun 2012 13:37:24 -0500
Subject: [R-sig-ME] How to estimate variance components with lmer for
 models with random effects and compare them with lme results
In-Reply-To: <CANG6evgkE70EUfkkg=YqdAkeT6qdVaUgEFN70UwPYHb=GZwKNw@mail.gmail.com>
References: <CANG6evgkE70EUfkkg=YqdAkeT6qdVaUgEFN70UwPYHb=GZwKNw@mail.gmail.com>
Message-ID: <CAErODj8t-j54pBS2JPj2_3WjVYLa9tpy0aoegH0-1xxeTvL0UQ@mail.gmail.com>

On Tue, Jun 26, 2012 at 6:49 AM, Kay Lucek <sticklenator at gmail.com> wrote:
> Hi,
>
> I performed an experiment where I raised different families coming from two
> different source populations, where each family was split up into a
> different treatments. After the experiment I measured several traits on
> each individual.
> To test for an effect of either treatment or source as well as their
> interaction, I used a linear mixed effect model with family as random
> factor, i.e.
> lme(fixed=Trait~Treatment*Source,random=~1|Family,method="ML")
>
> so far so good,
> Now I have to calculate the relative variance components, i.e. the
> percentage of variation that is explained by either treatment or source as
> well as the interaction.
>
> Without a random effect, I could easily use the sums of squares (SS) to
> calculate the variance explained by each factor. But for a mixed model
> (with ML estimation), there are no SS, hence I thought I could use
> Treatment and Source as random effects too to estimate the variance, i.e.
>
> lme(fixed=Trait~1,random=~(Treatment*Source)|Family, method="REML")
>
> However, in some cases, lme does not converge, hence I used lmer from the
> lme4 package:
>
> lmer(Trait~1+(Treatment*Source|Family),data=DATA)

Here is one problem. I do not think it is possible to estimate a
random effect for Source because it has only two values. So for that
you need a fixed effect approach. Or, if Source is not observed, this
becomes a hidden trait model (latent class model).

If there are many different types in Treatment, then this may work with lmer.

I don't understand all of your questions because the "percentage of
variance" terminology confuses me. I mean, I don't believe it is very
useful.

Lets make an example we can understand.  Then perhaps we will
understand your questions. Or you will better understand what you need
to ask.

Suppose I want to generate data according to the story you tell.

Here I generate the family-level characteristics, supposing there are
100 families from population 1 and 90 from population 2. If you fill
this in with parameters you think are realistic, then you have a "test
bench" for your analysis.  I set treatment with 4 levels. I would
guess you need to include fixed effects for Source and Treatment, as
well as the random for treatment.  And you can of course adjust the
layers of influence so that dat2 ends up the way you want.

## Paul Johnson
## 2012-06-26 <pauljohn at ku.edu>
## treatment.R

N <- c(100, 90) ##N families from each source

Source <- c(rep(1, N[1]), rep(2, N[2]))
Family <- seq(1:(sum(N)))

### Randomly assign families to treatment
Treatment  <- as.factor(sample(c("a","b","c","d"), sum(N), replace = TRUE))

### look this over:
famMatrix <- model.matrix( ~ Treatment + Source)

b <- c(1.2, 0.4, 1.1, 0.2, 4)
famMean <- famMatrix %*% b

famSTDE <- 6

famEffect <- famMean + rnorm( sum(N), mean=0, sd= famSTDE)

dat <- cbind(Family, as.data.frame(famMatrix), data.frame(famMean, famEffect))
row.names(dat) <- Family


## How many people per family? Suppose 3.
## Trait that equals "famEffect" + individual random noise.
## Index individual within family
Famind <- rep(Family, each=3)
Iind <- rep(c(1,2,3), sum(N))

## Create individual-level data frame
dat2 <- data.frame(Famind, Iind, famEffect = dat$famEffect[Famind],
Source = dat$Source[Famind], Treatment = Treatment[Famind])

## add individual-level noise
STDE <- 10
dat2$Trait <- dat2$famEffect + rnorm(nrow(dat2),  m =0, sd = STDE)

library(lme4)
mm1 <- lmer(Trait ~ Source + Treatment + (Treatment|Famind), data=dat2)

summary(mm1)

#######################

Here's what I just got

> mm1 <- lmer(Trait ~ Source + Treatment + (Treatment|Famind), data=dat2)
> summary(mm1)
Linear mixed model fit by REML ['summary.mer']
Formula: Trait ~ Source + Treatment + (Treatment | Famind)
   Data: dat2

REML criterion at convergence: 4434.472

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Famind   (Intercept)  19.24    4.386
          Treatmentb   41.53    6.444   -0.357
          Treatmentc   23.31    4.828    0.202  0.753
          Treatmentd  178.54   13.362   -0.191  0.009  0.050
 Residual             104.48   10.221
Number of obs: 570, groups: Famind, 190

Fixed effects:
            Estimate Std. Error t value
(Intercept)   3.1725     2.0969   1.513
Source        2.7868     1.3420   2.077
Treatmentb    1.4507     1.6413   0.884
Treatmentc    3.3708     1.7561   1.919
Treatmentd    0.0402     2.3348   0.017

Correlation of Fixed Effects:
           (Intr) Source Trtmntb Trtmntc
Source     -0.874
Treatmentb -0.237 -0.075
Treatmentc -0.132 -0.172  0.374
Treatmentd -0.145 -0.077  0.277   0.267


If this scenario does not match yours, figure how yours differs, write
it in, and the send working example back to list.


-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From pauljohn32 at gmail.com  Wed Jun 27 20:24:02 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 27 Jun 2012 13:24:02 -0500
Subject: [R-sig-ME] Fitting random intercept model in R?
In-Reply-To: <CAPNjSFZxp=RLc7DM0NQrjTX0v07XeZrFWOFGWV4q5vuh9JXC+A@mail.gmail.com>
References: <CAPNjSFZxp=RLc7DM0NQrjTX0v07XeZrFWOFGWV4q5vuh9JXC+A@mail.gmail.com>
Message-ID: <CAErODj8pBhPRhcp7juE5i1uVLRGhD08t0GYh6CtqK55UZQsojQ@mail.gmail.com>

On Fri, Jun 22, 2012 at 6:47 PM, Michael <comtech.usa at gmail.com> wrote:
> Hi all,
>
> Could anybody please shed some light on me?
>
> N individuals, divided into K groups. N>K.
>
 Here's a new working example of my testing script. I believe it will
clear everything up for you.

This is a situation where  you need to understand ordinary regression
before mixed models.  If you fit (supposing F0 is a "factor")

lm (y ~ F0 + F1 + F2 + F3)

R will notice F0 is a "factor" variable and it creates dummy variables
for all groups but one. Those are "fixed effects", easy to interpret.
Output has lots of parameters,, you get slopes for F1, F2, and F3
(supposing they are numeric) and then one for each level of F0.

You can also fit different slopes for groups with interactions.

lm (y ~ F0 * F1 + F2 + F3)

fits intercept shifts and slope shifts.  If you had 100 groups, this
would generate 202 parameter estimates.  The downside of this approach
is that it will generate a LOT of fixed effects estimates. It uses up
lots of degrees of freedom.

Suppose instead of thinking of the b's of the groups as fixed things,
instead they are drawn from Normal(0, sigma^2).   Then you estimate
only 'sigma^2', not each individual group intercept. Or perhaps MVN,
where you need to estimate correlations too.  That's a lmer model, it
uses fewer degrees of freedom, but in return you have to assume that
the b's follow a probability distribution.

After fitting, you can get the best post-hoc guesses about where the
b's for all the groups might be (output from ranef), but they aren't
estimates in the same sense. They are conditional modal predictions. I
think sometimes called "blups".

If you run this script through, you should see the various
interpretations and nice-ish plots.

## Paul Johnson <pauljohn at ku.edu>
## 2012-06-24

## mlm-2. This is step 2 in the journey

## Topic: create multi-level data and use regression and lmer to
## estimate it.  This creates 3 different dependent variables,
## y1: ordinary "homoskedastic" regression (no grouping effect0
## y2: clustered "random intercepts"
## y3: clustered "random intercepts" and "random slope" for 1 predictor (x1)

## Change 1. I demonstrated mlm-1.R for James Selig, who suggested
## it was important to have clusters made up of various numbers of
## observations (unbalanced groups). Now there are M groups, but
## the variable N becomes a vector that represents the number of
## respondents in each cluster.

## Change 2. Do better book keeping on the random effects.  Now the
## random effects are drawn from a multivariate normal, allowing
## "correlation" between them. The random effects matrix is called
## Mreffects, its columns are (b0, b1), representing the intercept and
## slope effects.  In my opinion, it is easier to specify the
## parameters with standard deviations and correlations.  The Covar
## matrix of the random effects "Msigma" is built up from those
## parameters.

##          | STDEb0  0   | |1  Mrho   | | STDEb0  0   |
## Msigma = |             |X|          |X|             |
##          |  0   STDEb1 | |Mrho    1 | |  0   STDEb1 |

library(MASS) ## for rmvnorm
set.seed(1234) ## for replicability

M <- 100  ## Clusters
## For equal-sized clusters with 10 observations, do this
## N <- rep(10, M)
## There are many ways to get varying cluster sizes.
## This draws cluster sizes from a 4 + Poisson(lambda=20)
N <- 4 + rpois(M, lambda=20)
## I add 4 because a cluster with fewer than 4 observations
## will cause a regression on the separate cluster to fail

## get M unique gray colors, will use later for plotting
## mycolors <- gray.colors(M)

## More colorful mycolors ?
mycolors <- rainbow(M)

## Standard deviation of error term at individual level
STDE <- 50

## The true fixed effects of b0, b1, b2, b3 in
## y = b0 + b1*x1 + b2*x2 + b3*x3
bslopes <- c(0.02, 0.14, -0.2, 0.05)

## Create Mind and Iind indexes for book keeping.
## Mind, "M index" shows with which cluster an observation belongs.
Mind <- unlist(lapply(1:M, function(x) rep(x, each=N[x])))
## Iind, "I index" indexes cluster members.
Iind <- unlist(lapply(1:M, function(x) seq(1, N[x], by=1)))

##Create 3 variables from a multivariate Normal with these
## characteristics
Xmeans <- c(100, 200, 150)
Xsds <- c(10, 20, 30)
Xrho <- 0.4
Xcorr.mat <- matrix(c(1, Xrho, Xrho, Xrho, 1, Xrho, Xrho, Xrho, 1), nrow = 3)
Xsigma <- diag(Xsds) %*% Xcorr.mat %*% diag(Xsds)
X.mat <- mvrnorm(n = sum(N), mu = Xmeans, Sigma = Xsigma)
dimnames(X.mat)[[2]] <- c("x1", "x2", "x3")
## Don't forget to insert an intercept later
X.mat <- cbind(X.mat)

## Create a dependent variable that has no clustering effects.  This
## is an "ordinary" regression.
##     FIXED Part                 +  RANDOM PART
y1 <- cbind(1, X.mat) %*% bslopes + rnorm(sum(N), m = 0, s = STDE)
dat <- cbind(data.frame(Mind, Iind, y1), as.data.frame(X.mat))
rownames(dat) <- paste(dat$Mind, dat$Iind, sep=".") ##may help bookkeeping later
rm(Mind, Iind, y1, X.mat) ## cleanup workspace

## Layer on additive group level error in y2 and y3

## Parameters for random effects:
## STDEb0: standard deviation of clustered intercepts.
STDEb0 <- 5
## STDEb1: standard deviation of slopes across cluster units
STDEb1 <- 0.5
Mrho <- 0.2
## I'm tempted to get fancy here with a matrix for STDEb0, STDEb1, and
## Mrho. It would pay off, I expect. But be harder to teach.
Msigma <- diag(c(STDEb0, STDEb1)) %*% matrix(c(1, Mrho, Mrho, 1), 2,
2) %*% diag(c(STDEb0, STDEb1))
Mreffects <- mvrnorm(M, mu = c(0, 0), Sigma = Msigma)
colnames(Mreffects) <- c("b0","b1")

## In y2, include random intercept
dat$y2 <- dat$y1 + Mreffects[ ,"b0"][dat$Mind]

## In y3, add in random slope effect
dat$y3 <- dat$y2 +  dat$x1 * Mreffects[ ,"b1"][dat$Mind]

## Do some diagnostics on Mreffects
plot(Mreffects[, 1], Mreffects[,2])
##library(rockchalk)
##summarize(Mreffects)
summary(Mreffects)
apply(Mreffects, 2, sd)
cor(Mreffects)

plot(Mreffects[ ,"b0"][dat$Mind], dat$x1 * Mreffects[
,"b1"][dat$Mind], col=dat$Mind, main = "Random Slopes and Intercepts",
xlab="Intercept Random Effect (b0)", ylab="Slope Random Effect
(b1*x)")

## Confirm the reffects are in y2
## cbind(dat$y1, dat$y2, Mreffects[ ,"b0"][dat$Mind])
## cbind(dat$y1, dat$y2, Mreffects[ ,"b0"][dat$Mind], dat$y3, dat$x1 *
Mreffects[ ,"b1"][dat$Mind])


## The "grand" regression?
m1 <- lm(y3 ~ x1 + x2 + x3, data=dat)
summary(m1)

## The "dummy variable" regression?
m2 <- lm(y3 ~ x1 + x2 + x3 + as.factor(Mind), data=dat)
summary(m2)


library(lme4)
## M separate regressions, with 3 predictors
m3list <- lmList(y3 ~ x1 + x2 + x3 | Mind, data=dat, pool = FALSE)

## Predicted values set x2 and x3 at their cluster-specific means.

plot(y3 ~ x1, data=dat, col=mycolors[Mind], lwd = 0.6, main = "lm on clusters")
for( i in seq_along(m3list)){
    m3mf <- model.frame(m3list[[i]]) #data set for group i
    x1range <- range(m3mf$x1) ## use group-specific ranges this time
    pgroup <- predict( m3list[[i]], newdata = data.frame(x1=x1range,
x2=mean(m3mf$x2), x3=mean(m3mf$x3)))
    lines(x1range, pgroup, col=mycolors[i])
}

## If a cluster has 3 or fewer cases, this warning will appear
## Warning message:
## In predict.lm(m3list[[i]], newdata = data.frame(x1 = x1range, x2 =
mean(m3mf$x2),  :
##   prediction from a rank-deficient fit may be misleading


## Keep a record.
m3newdat <- lapply(m3list, function(x) {
    m3mf <- model.frame(x)
    ndf = data.frame(x1=range(m3mf$x1), x2=mean(m3mf$x2), x3=mean(m3mf$x3))
    ndf$m3pred <- predict(x, newdata = ndf)
    ndf} )
m3newdat <- do.call("rbind", m3newdat)
## Better add a variable Mind. This way seems like overkill, but
probably is more
## robust than rep(1:M, each=2). It capitalizes on row names
m3newdat$Mind <-  as.integer(do.call("rbind",
strsplit(row.names(m3newdat), split="\\.", perl=T))[ ,1])

## Draw new graphs on a new device, so we can compare
dev.new()


##
## Estimate this as a mixed-effects model with lme4

## mm2: Just the random intercept, no random slope
mm2 <- lmer( y2 ~ x1 + x2 + x3 + (1 | Mind), data=dat)
summary(mm2)
mm2VarCorr <- VarCorr(mm2)
mm2VarCorr

cor(fitted(mm2), dat$y2)

## Both random intercept and random slope, not correlated with each other
## Depending on Mrho, this may be a 'wrong model'.
mm3 <- lmer( y3 ~ x1 + x2 + x3 + (1|Mind) + (-1 + x1 | Mind),
data=dat, verbose=3)
summary(mm3)
mm3VarCorr <- VarCorr(mm3)
mm3VarCorr

cor(fitted(mm3), dat$y3)



## Yank out the standard deviation estimates. idiom stolen from
formatVC in lmer code.
mm3reStdDev <- c(lapply(mm3VarCorr, attr, "stddev"), list(Residual =
attr(mm3VarCorr, "sc")))
mm3reStdDev


mm3reStdDev[["Mind"]]["(Intercept)"] - STDEb0
##mm3reStdDev[["Mind"]]["x1"] - STDEb1
## Can't figure how to get STD(b1)
mm3reStdDev[["Residual"]] - STDE


## cat("Compare true standard deviation of group level intercept = \n",
##           STDEb0, "with estimate for Std.Dev. of Mind (intercept)
in mm3 \n, which was", attr(mm3VarCorr[[1]], "stddev"), "\n")


## cat("The true standard deviation of the slope of the variable x1 is = \n",
##           STDEb1, "with estimate for Std.Dev. of \n",
attr(mm3VarCorr[[2]], "stddev"), "\n")


## The "right" model allows the random effects to be correlated (Supposing
## Mrho not 0).
mm4 <- lmer( y3 ~ x1 + x2 + x3 + (x1 | Mind), data=dat)
summary(mm4)
mm4VarCorr <- VarCorr(mm4)
mm4VarCorr

cor(fitted(mm4), dat$y3)

plot(fitted(mm4), dat$y3, col=dat$Mind)



## Yank out the standard deviation estimates
mm4reStdDev <- c(lapply(mm4VarCorr, attr, "stddev"), list(Residual =
attr(mm4VarCorr, "sc")))
mm4reStdDev


## Ever do summary stats on the predicted random effects?
mm4ranef <- ranef(mm4, postVar = TRUE) ## a ranef.mer object,  a list
that includes one data frame
apply(mm4ranef[["Mind"]], 2, mean)
apply(mm4ranef[["Mind"]], 2, sd)
summarize(mm4ranef$Mind)
cor(mm4ranef$Mind)

dotplot(mm4ranef)

m3newdat$mm4pred <- predict(mm4, newdata = m3newdat)

plot(y3 ~ x1, data=dat, col=mycolors[Mind], main="lmer mixed model predictions")
by(m3newdat, m3newdat$Mind, function(x) { lines(x$x1, x$mm4pred,
col=mycolors[x$Mind])})


## Double-check prediction values
mm4b <- fixef(mm4) ## coef(summary(mm4))[ ,1]
mm4vnames <- names(mm4b)
##  b0 + raneff(intercept, j)
mm4inteffect <- mm4b["(Intercept)"] +  mm4ranef[[1]][m3newdat$Mind, 1]
mm4x1effect <- m3newdat[ , c("x1")] * (mm4b["x1"] +
mm4ranef[[1]][m3newdat$Mind, 2] )
mm4mmpred2 <- mm4inteffect + mm4x1effect +  as.matrix(m3newdat[
,c("x2","x3") ]) %*%  mm4b[c("x2","x3")]
m3newdat$mm4manualpred <-  mm4inteffect + mm4x1effect +
as.matrix(m3newdat[ ,c("x2","x3") ]) %*%  mm4b[c("x2","x3")]

cbind(m3newdat$mm4manualpred, m3newdat$mm4pred)

## OK, looks good
plot(y3 ~ x1, data=dat, col=mycolors[Mind], main="lmer mixed model predictions")
by(m3newdat, m3newdat$Mind, function(x) { lines(x$x1, x$mm4manualpred,
col=mycolors[x$Mind])})




## Now grab estimates from lm and lmer for closer inspection.
## intercepts on M separate lm fits:
m3b0  <- sapply(m3list, function(m) coef(summary(m))["(Intercept)", "Estimate"])
sd(m3b0)

### The intercept "predictions" (blups) from mm4
mm4b0 <- mm4b["x1"] + mm4ranef[[1]][, "(Intercept)"]
sd(mm4b0)

###The slope estimates from M separate lm fits:
m3x1b  <- sapply(m3list, function(m) coef(summary(m))["x1", "Estimate"])
sd(m3x1b)

### The slope "predictions" (blups) from mm4
mm4x1b <- mm4b["x1"] + mm4ranef[[1]][, "x1"]
sd(mm4x1b)


## Are the mm4 b's better than lm's? Closer to expected values?
Shrunken toward center?
op <- par(no.readonly = TRUE)
par(mar=c(5.1, 5.1, 4.1, 2.1))
plot(m3x1b, mm4x1b, xlab = expression(hat(b)[1] ~~from~~lm), ylab =
expression(hat(b)[1] ~~from~~lmer~~mixed~~model),
main=expression(paste("Shrinkage: Scatter of ",hat(b)[1]," from lm and
lmer" )))
mx1b <- lm( mm4x1b ~ m3x1b)
abline(mx1b)
summary(mx1b)
options(digits=2)
legend("bottomright",
as.expression(c(bquote(widehat(hat(b)[1*j]^{lmer}) == .(coef(mx1b)[1])
+ .(coef(mx1b)[2])*hat(b)[1*j]))), lty=1, lwd=1)
options(digits=6)
par(op)


## Let's compare histograms of the slope estimates
par(mfcol=c(1,2))
par(mar=c(5.1, 4.1, 6.1, 2.1), xpd=T)

## Uses rockchalk: b1breaks <- plotSeq(range(c(m3x1b, mm4x1b)), 20)
b1breaks <- seq(range(c(m3x1b, mm4x1b))[1], range(c(m3x1b,
mm4x1b))[2], length.out = 20)
m3x1bhist <- hist(m3x1b, breaks=b1breaks, plot = FALSE)
m4x1bhist <- hist(mm4x1b, breaks =b1breaks, plot = FALSE)
## Uses rockchalk: ylim <- magRange(c(0, m3x1bhist$density,
m3x1bhist$density),  c(1, 1.2))

ylim <- range(c(0, m3x1bhist$density, m3x1bhist$density))*c(1, 1.2)
hist(m3x1b, breaks=b1breaks, prob = TRUE, ylim=ylim,
xlab=expression(paste("100 lm estimates ", hat(b)[1])),
main=paste("Separate OLS (lm)"))
legend("topright", legend = as.expression(c(
bquote(mean(hat(b)[1])==.(round(mean(m3x1b),2))),
bquote(sd(hat(b)[1])==.(round(sd(m3x1b),2))))))

hist(mm4x1b,  breaks=b1breaks, prob = TRUE, ylim=ylim,
xlab=expression(paste("lmer 'blup' estimates ", hat(b)[1])),
main="Mixed Model (lmer)")
legend("topleft", legend = as.expression(c(
bquote(mean(hat(b)[1])==.(round(mean(mm4x1b),2))),
bquote(sd(hat(b)[1])==.(round(sd(mm4x1b),2))))))
par(op)


## Plot the estimated slopes against the "true" random effects from Mreffects
plot(bslopes[2] + Mreffects[ ,2], m3x1b, xlab="Cluster Slopes (True
Values)", ylab="Estimates of Slopes (across Clusters)", col="gray70",
xlim=c(-15,15))
points(bslopes[2] + Mreffects[ ,2], mm4x1b, , col="black", pch=13)
legend("topleft", c("OLS Slopes", "Mixed Model Slopes"), pch=c(1,13),
col=c("gray70","black"))



## Plot the estimated intercept effects against the "true" random
effects from Mreffects
plot(bslopes[1] + Mreffects[ ,1], m3b0, xlab="Cluster Intercepts (True
Values)", ylab="Estimates of Intercepts", col="gray70")
points(bslopes[1] + Mreffects[ ,1], mm4b0 , col="black", pch=13)
legend("topleft", c("OLS Intercepts", "Mixed Model Intercepts"),
pch=c(1,13), col=c("gray70","black"))





> Some groups have 1 individuals only, some other groups have more
> individuals.
>
> Each individual has 4 features (4 variables): F0, F1, F2, and F3, where F0
> is simply the group indicator.
>
> Therefore the data matrix is of size N x 4.
>
> There is also a weight vector w, which is of length N, which gives the
> weights for each of the N individuals in the regression.
>
> May I ask if the following model is a random-intercept model?
>
> 1. There is a common beta for all N individuals.
> 2. Each group has a different within group regression line (same slope but
> different intercepts).
> 3. The regression line within each group crosses the "cloud" consisting of
> the group members. And the individual residuals scatter around the
> regression line, within each group.
>
> This sounds like a "random-intercept" model to me.
>
> However, how do I explicitly write out the equation?
>
> y = X * beta + Z * b + eps
>
> More specifically, with the three feature variables F1, F2 and F3 and the
> group indicator variable F0,
>
> I am having difficulty writing out X and Z explicitly.
>
> Moreover, my F2 is a factor variable.
>
> Could anybody please show me how the X and Z matrices look like explicitly?
> And what do the "b"'s represent here?
>
> And how do I set up the weights in LME in R? If I would like to have
> "group"-weights and "individual"-weights, how shall I do it?
>
> Thank you!
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From pauljohn32 at gmail.com  Wed Jun 27 20:37:08 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 27 Jun 2012 13:37:08 -0500
Subject: [R-sig-ME] Question of ineraction in LMM model
In-Reply-To: <17f9e7a.9a2a.13826d6c988.Coremail.chenlei@ibcas.ac.cn>
References: <17f9e7a.9a2a.13826d6c988.Coremail.chenlei@ibcas.ac.cn>
Message-ID: <CAErODj-VE5wL0VPpeb1Xn1tFA-whagQEmzy0cJjLH28wHdg9vA@mail.gmail.com>

On Mon, Jun 25, 2012 at 10:30 PM, chenlei <chenlei at ibcas.ac.cn> wrote:
> Dear lists,
>
> Greetings. I read message for a question in R list on May 29 from Dr. ir. Thierry Onkelinx. It is very helpful for me. It is as following:
>
> -------------------------
>
> Dear Luke,
>
> A workaround is to first create a new variable for the interaction.
>
> TimeTertile <- interaction(Time, Tertile, drop = TRUE)
>
> And then use that variable in the model
>
> m1 <- glmer(y ~ TimeTertile + (1|Individual) + (1|Zone) + Max + Min, family=binomial)
>
> Please not that I use glmer() instead of lmer() which give some more clear code. At the moment, lmer() will call glmer() for you when family is not Gaussian.
>
> Then you can run multicomp
>
> Timetest <- glht(m1, linfct = mcp(TimeTertile = "Tukey"))
>
>
>
> -------------------------
>
> But I encounter problem when I use your method to calculate my data. In my data, I tried to analyzed the effect of different successsional age of forest, environmental variable (represented by elevation) on species richness of forest. We sampled 12 forest plots (variable plot), and each successtional age has 3 forest plots (totally 4 successional age). We tried to analyze the effect of successional age and environment on species richness within each plot. We are interested in comparing species richness of forests at different age. So in my case, one of interactive variables is factor variables (successional age) and another is numeric variable (elevation). Following above-described method, I calculated as following:
>
> elev.age=interaction(elevation,age,drop=T);
>
> ? ? ? ? ?model1=lmer(richness~elev.age+(1|plot));
>
> But the error message is:
>
> ? ? ? ? ? ?Error in rep.int(c(1, numeric(n)), n - 1L) :
>
> ? ? ? ? ? ?negative length vectors are not allowed.

When you see errors, we need information about possible causes.

Step one. Please report output from

> sessionInfo()

Step two. Put your data on a server somewhere so we can see it and run
your example code with it.  if the data is huge, make a small subset
we can test to reproduce your trouble.

Now, about your lmer usage:

Better to do it with a data frame, ie, put y, x1, x2 in dat, and run

m1 <- lmer(y ~ x1 + x2 + (1|x2), data = dat)

Generally, I get better results using a data frame.   Depending on the
routine to go find data in your workspace is risky, not just with
lmer, but with any regression function. Using a data frame gives you
security that it is finding what you want.

Although it may not cause an error now in R, it used to be that a
variable named "plot" could be confused with the commonly used
function "plot". When something goes wrong, I always worry about
things like that.  For the same reason, I never name variables "lm",
"rep", "seq", "plot" "glm" and so forth.  Those things used to cause R
to crash, and somewhere deep in my heart I'm still suspicious when
people do that.


>
> I also tried with
>
> ? ? ? ? model2=lmer(richness~elev*age+(1|plot);
>
> ?comp1<-glht(model2,linfct=(mcp(stage="Tukey",interaction_average=T,covariate_average=T)));
>
> But it gives error message:
>
> ? ? ? ?Warning message:
>
> mean(<data.frame>) is deprecated.
>
> ? ? ? ?Use colMeans() or sapply(*, mean) instead.
>
That means the author of glht needs to update code to not run
mean(data) any more. You are not causing that, unless your version of
the package is outdated.

You probably should show us the output of the summary of your lmer
model. Whether or not the hypothesis test is reasonable may depend on
the format of the output.  If you are confident the lmer output is
really what you want, then you need to send the lmer output to the
glht author and ask the usage question.  That's a big IF, though.

pj



> I checked it many times, but cannot find the right way. Could anyone please one give me any suggestions or hint? Your help will be highly appreciated!
>
> Best wishes,
>
> Xiangcheng Mi
>
>
>
> ---------------
>
> Xiangcheng Mi,
>
> Institute of Botany, Chinese Academy of Sciences,
>
> Beijing, 100093
>
> China
>
>
>
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From maurice.francois at ymail.com  Wed Jun 27 21:32:31 2012
From: maurice.francois at ymail.com (Francois Maurice)
Date: Wed, 27 Jun 2012 12:32:31 -0700 (PDT)
Subject: [R-sig-ME] Weights
Message-ID: <1340825551.48884.YahooMailNeo@web122305.mail.ne1.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120627/9d180d89/attachment.pl>

From aghaynes at gmail.com  Thu Jun 28 08:23:09 2012
From: aghaynes at gmail.com (Alan Haynes)
Date: Thu, 28 Jun 2012 08:23:09 +0200
Subject: [R-sig-ME] Weights
In-Reply-To: <1340825551.48884.YahooMailNeo@web122305.mail.ne1.yahoo.com>
References: <1340825551.48884.YahooMailNeo@web122305.mail.ne1.yahoo.com>
Message-ID: <CAPdSD+792C3BGmthj+iAAz3GyCt-ALHOWcGCC=c0CijwpBq8Eg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120628/98223491/attachment.pl>

From bbolker at gmail.com  Thu Jun 28 12:36:10 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Jun 2012 10:36:10 +0000 (UTC)
Subject: [R-sig-ME] Weights
References: <1340825551.48884.YahooMailNeo@web122305.mail.ne1.yahoo.com>
Message-ID: <loom.20120628T123056-283@post.gmane.org>

Francois Maurice <maurice.francois at ...> writes:

> 
> Hi,
> ?
> I have a variable that gives weights to each case. 
> Is there a way with lme() to?specify weights ? I tried the
> "weights" argument but I think it is not the write place. 
> The argument ask me for a varFunc object, which I
> don't know what it is!!
> ?
> I know that the "weights" argument works well with lmer()
> but lmer() doesn't give the p-values for fixed
> effects, or at least I don't know how to get it from lmer().

  Maybe not exactly what you want, but if you know the variances
corresponding to the weights you want to impose (say they are a variable
'estvars' in your data frame) I think you could
use

lme(..., weights=varFixed(~estvars), ...) 
  

in particular, to use wts 'wts' you probably want to use

lme(..., weights=varFixed(~I(1/wts)), ...)

  To make sure that I'm not crazy I would suggest that you try
some simple cases using this approach with lme and lmer, using
explicit weights in the lmer case, and see if you get the same
answers ...

  (If anyone has a better idea or knows this to be wrong,
please speak up !)


From markus.jantti at iki.fi  Thu Jun 28 13:31:59 2012
From: markus.jantti at iki.fi (=?UTF-8?B?TWFya3VzIErDpG50dGk=?=)
Date: Thu, 28 Jun 2012 13:31:59 +0200
Subject: [R-sig-ME] Weights
In-Reply-To: <loom.20120628T123056-283@post.gmane.org>
References: <1340825551.48884.YahooMailNeo@web122305.mail.ne1.yahoo.com>
	<loom.20120628T123056-283@post.gmane.org>
Message-ID: <4FEC40AF.1070701@iki.fi>

On 06/28/2012 12:36 PM, Ben Bolker wrote:
> Francois Maurice <maurice.francois at ...> writes:
>
>>
>> Hi,
>>
>> I have a variable that gives weights to each case.
>> Is there a way with lme() to specify weights ? I tried the
>> "weights" argument but I think it is not the write place.
>> The argument ask me for a varFunc object, which I
>> don't know what it is!!
>>
>> I know that the "weights" argument works well with lmer()
>> but lmer() doesn't give the p-values for fixed
>> effects, or at least I don't know how to get it from lmer().
>
>    Maybe not exactly what you want, but if you know the variances
> corresponding to the weights you want to impose (say they are a variable
> 'estvars' in your data frame) I think you could
> use
>
> lme(..., weights=varFixed(~estvars), ...)
>
>
> in particular, to use wts 'wts' you probably want to use
>
> lme(..., weights=varFixed(~I(1/wts)), ...)
>
>    To make sure that I'm not crazy I would suggest that you try
> some simple cases using this approach with lme and lmer, using
> explicit weights in the lmer case, and see if you get the same
> answers ...
>
>    (If anyone has a better idea or knows this to be wrong,
> please speak up !)

Hi -- this seems to work (since the fixed variance function is the default, it 
can be omitted in the weights= argument to lme). In lmer, the weight that has 
the mean standardized to one produces different results from the one that does 
not, but in lme they both produce the same results. It might be useful to 
explore that a little further.

<code>

## example data
td <- data.frame(y=1:100,
                  g=factor(rep(1:20, 5)),
                  f=factor(rep(1:5, 20)),
                  wgt=100:1)
td$relwgt <- td$wgt/mean(td$wgt)
## replicate the data by the number of weights
ltd <- td[rep(rownames(td), td$wgt),]

library(nlme)
summary(lme(y ~ 1, random= ~1|g, data=td))
summary(lme(y ~ 1, random= ~1|g, data=td, weights=~1/wgt))
summary(lme(y ~ 1, random= ~1|g, data=td, weights=~1/relwgt))
## without weights on the replicated data
summary(lme(y ~ 1, random= ~1|g, data=ltd)
detach(package:nlme)
library(lme4)
summary(lmer(y ~ 1 + (1|g), data=td))
summary(lmer(y ~ 1 + (1|g), data=td, weights=wgt))
summary(lmer(y ~ 1 + (1|g), data=td, weights=relwgt))
## without weights on the replicated data
summary(lmer(y ~ 1 + (1|g), data=ltd))
detach(package:lme4)


</code>

HTH,

Markus



-- 
Markus Jantti
Professor of Economics
Swedish Institute for Social Research
Stockholm University


From laurent_step at yahoo.fr  Fri Jun 29 10:28:48 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Fri, 29 Jun 2012 09:28:48 +0100 (BST)
Subject: [R-sig-ME] profile likelihood confidence interval
Message-ID: <1340958528.93083.YahooMailNeo@web29506.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120629/b6e1f610/attachment.pl>

From laurent_step at yahoo.fr  Fri Jun 29 13:49:45 2012
From: laurent_step at yahoo.fr (laurent stephane)
Date: Fri, 29 Jun 2012 12:49:45 +0100 (BST)
Subject: [R-sig-ME] profile likelihood confidence interval
In-Reply-To: <1340958528.93083.YahooMailNeo@web29506.mail.ird.yahoo.com>
References: <1340958528.93083.YahooMailNeo@web29506.mail.ird.yahoo.com>
Message-ID: <1340970585.87069.YahooMailNeo@web29501.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120629/d481c726/attachment.pl>

From ssimek at CFR.MsState.Edu  Fri Jun 29 17:52:23 2012
From: ssimek at CFR.MsState.Edu (Stephanie L. Simek)
Date: Fri, 29 Jun 2012 10:52:23 -0500
Subject: [R-sig-ME] Post requested
Message-ID: <736BA42933F6C84698DBA828209ED41E01A7F6BE@mail.cfr.msstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120629/2ed8e40e/attachment.pl>

From justiceaheto at yahoo.com  Fri Jun 29 15:26:40 2012
From: justiceaheto at yahoo.com (Justice Moses K. Aheto)
Date: Fri, 29 Jun 2012 06:26:40 -0700 (PDT)
Subject: [R-sig-ME] Fitting multilevel model to a recipe and simulating the
	model.
Message-ID: <1340976400.16374.YahooMailNeo@web113407.mail.gq1.yahoo.com>

Dear All,
I am a new R user but currently working on my dissertation which request that I fit multilevel model to a given situation that can be located in the attachment to this mail and simulate the model 10000 times.
In addition, I will like to compute the standard error, t-value and p-value for the fitted model.
I am available to provide further clarification on the task should you request for.
Could someone help me in this regards.
I do appreciate any assistance given me.
Many thanks in advance.?
?
Kind regards.

Justice Moses K. Aheto
(Chief Executive Officer)
Statistics & Analytics Consultancy Services Ltd.
E-mail: justiceaheto at yahoo.com
Mobile:00447417589148

From f.calboli at imperial.ac.uk  Fri Jun 29 19:15:20 2012
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 29 Jun 2012 18:15:20 +0100
Subject: [R-sig-ME] Fitting multilevel model to a recipe and simulating
	the model.
In-Reply-To: <1340976400.16374.YahooMailNeo@web113407.mail.gq1.yahoo.com>
References: <1340976400.16374.YahooMailNeo@web113407.mail.gq1.yahoo.com>
Message-ID: <914BFDFC-0AEB-40DC-B9AB-78657BC49CC5@imperial.ac.uk>

Just to let you know I don't see any attachment.  In any case, if would be best to keep any explanation in the text of the email.

BW

F



On 29 Jun 2012, at 14:26, Justice Moses K. Aheto wrote:

> Dear All,
> I am a new R user but currently working on my dissertation which request that I fit multilevel model to a given situation that can be located in the attachment to this mail and simulate the model 10000 times.
> In addition, I will like to compute the standard error, t-value and p-value for the fitted model.
> I am available to provide further clarification on the task should you request for.
> Could someone help me in this regards.
> I do appreciate any assistance given me.
> Many thanks in advance. 
>  
> Kind regards.
> 
> Justice Moses K. Aheto
> (Chief Executive Officer)
> Statistics & Analytics Consultancy Services Ltd.
> E-mail: justiceaheto at yahoo.com
> Mobile:00447417589148_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From herptaes at yahoo.es  Fri Jun 29 19:08:37 2012
From: herptaes at yahoo.es (=?iso-8859-1?Q?Andr=E9s_Egea?=)
Date: Fri, 29 Jun 2012 18:08:37 +0100 (BST)
Subject: [R-sig-ME] "mixed" MANOVAs
Message-ID: <1340989717.33487.YahooMailNeo@web29701.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120629/8c95a15c/attachment.pl>

From raquelrguima at gmail.com  Fri Jun 29 23:20:44 2012
From: raquelrguima at gmail.com (Raquel Guimaraes)
Date: Fri, 29 Jun 2012 14:20:44 -0700
Subject: [R-sig-ME] warnings in lmer estimation after mice
Message-ID: <010201cd563d$0c2be710$2483b530$@com>

Hi all,

I need help to understand convergence problems with my estimation.

I am using lmer to estimate a mixed-effects model of an index of teacher
quality on student achievement gains.

The dataset for female students is available in the link above and contains
original and imputed data (m=5 and m=50)

<https://www.dropbox.com/sh/fqpjtkkuz9y9mzr/MhrMXwlrFp>

I want to understand the error messages above and their implications for my
parameter estimates.

1: In mer_finalize(ans) : false convergence (8)
2: In mer_finalize(ans) : singular convergence (7)
3: In mer_finalize(ans) : singular convergence (7)
4: In mer_finalize(ans) : false convergence (8)
5: In mer_finalize(ans) : false convergence (8)

Below you may find the script for my procedures.

Any help will be appreciated!

Thanks,

Raquel

-----------------------------------------------------------------

#Multiple imputation

library("mice")
md.pattern(data.f)
md.pairs(data.f)
# 5 imputations - Predictive mean matching
imp.5.f<-mice(data.f,m=5,seed=23109)
print(imp.5.f)
# 50 imputations - Predictive mean matching
imp.50.f<-mice(data.f,m=50,seed=23109)
print(imp.50.f)

#Running lmer
library(lme4)
    
  #Imputed data
    #Females
      Uncpde.math.f.mi <- with(imp.50.f, lmer(gain ~ index +
        ( index | std_id), verbose=TRUE))
      print(pool(Uncpde.math.f.mi))
      round(summary(pool(Uncpde.math.f.mi)), 2)
	  
>       Uncpde.math.f.mi <- with(imp.50.f, lmer(gain ~ index +
+         ( index | std_id), verbose=TRUE))
  0:     91323.888: 0.666667 0.0912755 0.000000
  1:     90950.102: 0.579295 0.000000 -0.298895
  2:     88854.168: 0.305206 0.000000 -0.0962998
  3:     88814.543: 0.288910 8.27185e-010 -0.126235
  4:     88797.001: 0.261789 0.00137943 -0.146833
  5:     88783.121: 0.229797 0.000000 -0.136191
  6:     88765.032: 0.163649 0.000000 -0.170033
  7:     88764.059: 0.101518 0.00683235 -0.129860
  8:     88757.161: 0.0894730 0.000000 -0.151620
  9:     88756.669: 0.0802386 0.000000 -0.161394
 10:     88756.413: 0.0692536 0.000000 -0.169148
 11:     88756.296: 0.0566213 0.000000 -0.173754
 12:     88756.276: 0.0473775 0.000000 -0.172026
 13:     88756.268: 0.0454115 0.000000 -0.177962
 14:     88756.268: 0.0445268 0.000000 -0.177518
 15:     88756.268: 0.0445255 6.95905e-007 -0.177518
 16:     88756.268: 0.0443349 1.91179e-007 -0.177519
 17:     88756.268: 0.0443349 1.91179e-007 -0.177519
  0:     90892.401: 0.666667 0.0901811 0.000000
  1:     90565.986: 0.582914 0.000000 -0.301351
  2:     88348.591: 0.262114 0.000000 -0.107499
  3:     88300.308: 0.000000 0.000000 -0.259898
  4:     88300.308: 0.000000 0.000000 -0.259898
  0:     92116.635: 0.666667 0.0860717 0.000000
  1:     91920.069: 0.589035 0.000000 -0.302245
  2:     89502.995: 0.208420 0.000000 -0.118175
  3:     89484.310: 0.000000 0.000000 -0.217057
  4:     89484.310: 0.000000 0.000000 -0.217057
  0:     90508.355: 0.666667 0.0907223 0.000000
  1:     90069.269: 0.575010 0.000000 -0.303351
  2:     87914.618: 0.289817 0.000000 -0.0984479
  3:     87811.950: 0.000000 0.000000 -0.262459
  4:     87811.950: 0.000000 0.000000 -0.262459
  0:     90728.496: 0.666667 0.0893763 0.000000
  1:     90385.062: 0.582005 0.000000 -0.301492
  2:     88044.313: 0.230444 0.000000 -0.108661
  3:     88004.837: 0.000000 0.000000 -0.234827
  4:     88004.837: 0.000000 0.000000 -0.234827
  0:     90569.541: 0.666667 0.0904525 0.000000
  1:     90248.550: 0.585924 0.000000 -0.296967
  2:     87912.085: 0.229608 0.000000 -0.106161
  3:     87890.585: 0.000000 0.000000 -0.222132
  4:     87890.585: 0.000000 0.000000 -0.222132
  0:     90567.799: 0.666667 0.0887506 0.000000
  1:     90302.451: 0.587353 0.000000 -0.300203
  2:     88030.944: 0.255280 0.000000 -0.110269
  3:     87995.243: 0.000000 0.000000 -0.246234
  4:     87995.243: 0.000000 0.000000 -0.246234
  0:     90630.186: 0.666667 0.0905161 0.000000
  1:     90245.654: 0.581825 0.000000 -0.299051
  2:     88024.455: 0.278519 0.000000 -0.100122
  3:     87959.404: 0.000000 0.000000 -0.269139
  4:     87959.404: 0.000000 0.000000 -0.269139
  0:     91431.304: 0.666667 0.0910478 0.000000
  1:     91060.176: 0.577973 0.000000 -0.299692
  2:     88879.745: 0.273428 0.000000 -0.0991786
  3:     88804.068: 0.000000 0.000000 -0.272971
  4:     88804.068: 0.000000 0.000000 -0.272971
  0:     90853.326: 0.666667 0.0899358 0.000000
  1:     90519.641: 0.585512 0.000000 -0.298258
  2:     88288.745: 0.275120 0.000000 -0.102956
  3:     88246.430: 0.000000 0.000000 -0.258963
  4:     88246.430: 0.000000 0.000000 -0.258963
  0:     90697.216: 0.666667 0.0856334 0.000000
  1:     90578.775: 0.593759 0.000000 -0.298316
  2:     88081.238: 0.184499 0.000000 -0.119253
  3:     88078.012: 0.000000 0.000000 -0.196102
  4:     88078.012: 0.000000 0.000000 -0.196102
  0:     90639.439: 0.666667 0.0902601 0.000000
  1:     90295.074: 0.583471 0.000000 -0.299601
  2:     88125.514: 0.286629 0.000000 -0.102261
  3:     88067.467: 0.000000 0.000000 -0.268202
  4:     88067.467: 0.000000 0.000000 -0.268202
  0:     90573.744: 0.666667 0.0917234 0.000000
  1:     90156.547: 0.577930 0.000000 -0.300638
  2:     88068.528: 0.306034 0.000000 -0.0965273
  3:     87975.584: 0.000000 0.000000 -0.238077
  4:     87975.584: 0.000000 0.000000 -0.238077
  0:     89721.612: 0.666667 0.0913660 0.000000
  1:     89274.384: 0.577867 0.000000 -0.302115
  2:     87025.514: 0.258058 0.000000 -0.102274
  3:     86960.255: 0.000000 0.000000 -0.264012
  4:     86960.255: 0.000000 0.000000 -0.264012
  0:     89773.327: 0.666667 0.0914180 0.000000
  1:     89431.386: 0.579968 0.000000 -0.297710
  2:     87172.239: 0.245863 0.000000 -0.102001
  3:     87121.156: 0.000000 0.000000 -0.244505
  4:     87121.156: 0.000000 2.95447e-009 -0.244505
  5:     87121.156: 0.000000 1.89955e-009 -0.244505
  0:     91307.998: 0.666667 0.0881736 0.000000
  1:     90963.328: 0.582168 0.000000 -0.305197
  2:     88585.039: 0.218209 0.000000 -0.114601
  3:     88552.517: 0.000000 0.000000 -0.232242
  4:     88552.517: 0.000000 0.000000 -0.232242
  0:     90098.405: 0.666667 0.0912658 0.000000
  1:     89625.050: 0.577676 0.000000 -0.303420
  2:     87381.866: 0.264236 0.000000 -0.102601
  3:     87313.537: 0.000000 0.000000 -0.270530
  4:     87313.537: 0.000000 0.000000 -0.270530
  0:     90946.093: 0.666667 0.0900592 0.000000
  1:     90583.090: 0.581315 0.000000 -0.300756
  2:     88388.898: 0.278531 0.000000 -0.102687
  3:     88324.595: 0.000000 0.000000 -0.273038
  4:     88324.595: 0.000000 0.000000 -0.273038
  0:     91333.939: 0.666667 0.0913058 0.000000
  1:     90904.541: 0.577003 0.000000 -0.299602
  2:     88679.234: 0.272647 0.000000 -0.0969097
  3:     88596.130: 0.000000 0.000000 -0.272223
  4:     88596.130: 0.000000 0.000000 -0.272223
  0:     90152.037: 0.666667 0.0900727 0.000000
  1:     89702.620: 0.575074 0.000000 -0.306728
  2:     87596.979: 0.302713 0.000000 -0.101807
  3:     87484.248: 0.000000 0.000000 -0.248542
  4:     87484.248: 0.000000 0.000000 -0.248542
  0:     91117.801: 0.666667 0.0908513 0.000000
  1:     90757.634: 0.580554 0.000000 -0.299360
  2:     88603.505: 0.283831 0.000000 -0.0999435
  3:     88574.096: 0.267794 0.000000 -0.130461
  4:     88562.206: 0.238612 0.000000 -0.148816
  5:     88553.044: 0.208478 0.000595092 -0.132080
  6:     88546.351: 0.181458 0.000000 -0.153290
  7:     88542.081: 0.150185 0.000000 -0.138783
  8:     88539.627: 0.123847 1.01894e-009 -0.161027
  9:     88538.734: 0.0942445 0.000744265 -0.143374
 10:     88538.275: 0.0808928 0.000000 -0.152300
 11:     88538.188: 0.0721130 0.000000 -0.159438
 12:     88538.184: 0.0695887 0.000000 -0.160606
 13:     88538.183: 0.0680936 0.000000 -0.160978
 14:     88538.183: 0.0677477 0.000000 -0.160916
 15:     88538.183: 0.0676509 0.000000 -0.160808
 16:     88538.183: 0.0676691 0.000000 -0.160770
  0:     90816.807: 0.666667 0.0906318 0.000000
  1:     90424.195: 0.578291 0.000000 -0.302393
  2:     88300.640: 0.297094 0.000000 -0.100293
  3:     88204.488: 0.000000 0.000000 -0.253910
  4:     88204.488: 0.000000 0.000000 -0.253910
  0:     91513.066: 0.666667 0.0905136 0.000000
  1:     91059.392: 0.572808 0.000000 -0.304419
  2:     88963.498: 0.308436 0.000000 -0.0961059
  3:     88828.230: 0.00365434 0.000000 -0.238915
  4:     88828.230: 0.00353298 2.48295e-007 -0.238904
  5:     88828.228: 0.000809467 8.53595e-006 -0.238663
  6:     88828.227: 0.000000 0.000000 -0.238628
  7:     88828.227: 0.000000 0.000000 -0.238628
  0:     91150.802: 0.666667 0.0891040 0.000000
  1:     90889.912: 0.587635 0.000000 -0.295390
  2:     88556.237: 0.240279 0.000000 -0.104882
  3:     88549.670: 0.235780 0.000000 -0.114362
  4:     88542.519: 0.221856 0.000000 -0.136892
  5:     88538.276: 0.196911 0.000536413 -0.128009
  6:     88535.760: 0.176898 0.000000 -0.145077
  7:     88534.303: 0.157582 0.000000 -0.126956
  8:     88533.996: 0.156218 2.29140e-010 -0.129226
  9:     88533.534: 0.153150 3.03087e-005 -0.133544
 10:     88532.859: 0.140751 0.000000 -0.142165
 11:     88532.514: 0.126963 0.000000 -0.135997
 12:     88532.299: 0.114249 0.000000 -0.140115
 13:     88532.276: 0.109185 0.000000 -0.141707
 14:     88532.275: 0.107867 0.000000 -0.142196
 15:     88532.275: 0.107761 0.000000 -0.142270
 16:     88532.275: 0.107763 2.96078e-010 -0.142274
 17:     88532.275: 0.107767 0.000000 -0.142285
 18:     88532.275: 0.107776 0.000000 -0.142284
  0:     90591.670: 0.666667 0.0902163 0.000000
  1:     90253.650: 0.582677 0.000000 -0.296733
  2:     87913.750: 0.234039 0.000000 -0.102682
  3:     87877.999: 0.000000 0.000000 -0.227078
  4:     87877.999: 0.000000 0.000000 -0.227078
  0:     90673.897: 0.666667 0.0896992 0.000000
  1:     90337.823: 0.585673 0.000000 -0.300345
  2:     88000.465: 0.229841 0.000000 -0.109921
  3:     87976.655: 0.000000 0.000000 -0.229344
  4:     87976.655: 0.000000 0.000000 -0.229344
  0:     91695.842: 0.666667 0.0899055 0.000000
  1:     91404.328: 0.584642 0.000000 -0.297876
  2:     89214.414: 0.281201 0.000000 -0.102582
  3:     89188.190: 0.265626 0.000000 -0.133284
  4:     89178.234: 0.236801 0.000000 -0.152108
  5:     89170.640: 0.208346 0.00119384 -0.132766
  6:     89165.050: 0.184852 0.000000 -0.157320
  7:     89161.506: 0.155593 0.000000 -0.139179
  8:     89159.386: 0.133551 4.59756e-009 -0.165624
  9:     89159.213: 0.130015 0.00119127 -0.162734
 10:     89158.808: 0.126412 0.000000 -0.160222
 11:     89158.328: 0.109125 0.000000 -0.154874
 12:     89158.186: 0.0975572 0.000000 -0.168789
 13:     89158.113: 0.0883497 0.000000 -0.164147
 14:     89158.112: 0.0893647 3.36482e-007 -0.164147
 15:     89158.112: 0.0894556 0.000000 -0.164102
 16:     89158.111: 0.0901974 2.92690e-006 -0.163772
 17:     89158.111: 0.0904597 0.000000 -0.163769
 18:     89158.111: 0.0904597 0.000000 -0.163769
  0:     92026.232: 0.666667 0.0894992 0.000000
  1:     91735.788: 0.581037 0.000000 -0.298447
  2:     89530.291: 0.274498 0.000000 -0.101211
  3:     89465.691: 0.000000 0.000000 -0.265849
  4:     89465.691: 0.000000 0.000000 -0.265849
  0:     89155.666: 0.666667 0.0892915 0.000000
  1:     88806.417: 0.582861 0.000000 -0.303162
  2:     86512.523: 0.245630 0.000000 -0.109990
  3:     86472.497: 0.000000 0.000000 -0.248275
  4:     86472.497: 0.000000 0.000000 -0.248275
  0:     91625.651: 0.666667 0.0892096 0.000000
  1:     91305.690: 0.580685 0.000000 -0.300005
  2:     89053.463: 0.263647 0.000000 -0.103131
  3:     88986.561: 0.000000 0.000000 -0.261116
  4:     88986.561: 0.000000 0.000000 -0.261116
  0:     90869.702: 0.666667 0.0892723 0.000000
  1:     90555.120: 0.579552 0.000000 -0.300675
  2:     88410.128: 0.295998 0.000000 -0.100232
  3:     88314.598: 0.000000 0.000000 -0.255183
  4:     88314.598: 0.000000 3.86364e-009 -0.255183
  5:     88314.598: 0.000000 3.86364e-009 -0.255183
  0:     91108.704: 0.666667 0.0906011 0.000000
  1:     90804.467: 0.586207 0.000000 -0.293469
  2:     88408.714: 0.209336 0.000000 -0.104199
  3:     88390.555: 0.000000 0.000000 -0.233786
  4:     88390.555: 0.000000 4.74440e-009 -0.233786
  5:     88390.555: 0.000000 4.74440e-009 -0.233786
  0:     91771.237: 0.666667 0.0903370 0.000000
  1:     91413.484: 0.577979 0.000000 -0.300203
  2:     89218.035: 0.273200 0.000000 -0.100290
  3:     89189.934: 0.254171 1.16058e-009 -0.128658
  4:     89174.483: 0.222469 0.00144656 -0.141297
  5:     89151.646: 0.136126 0.000000 -0.129612
  6:     89144.537: 0.0652530 0.000000 -0.181235
  7:     89143.147: 0.000000 0.000000 -0.132500
  8:     89143.147: 0.000000 0.000000 -0.132500
  0:     92075.541: 0.666667 0.0889713 0.000000
  1:     91754.396: 0.582594 0.000000 -0.299314
  2:     89493.502: 0.269474 0.000000 -0.102596
  3:     89431.022: 0.000000 0.000000 -0.259856
  4:     89431.022: 0.000000 0.000000 -0.259856
  0:     90741.014: 0.666667 0.0910750 0.000000
  1:     90297.019: 0.577011 0.000000 -0.305139
  2:     88152.539: 0.285117 0.000000 -0.103300
  3:     88068.757: 0.000000 0.000000 -0.272904
  4:     88068.757: 0.000000 0.000000 -0.272904
  0:     90254.977: 0.666667 0.0906367 0.000000
  1:     89853.808: 0.580116 0.000000 -0.303049
  2:     87726.880: 0.295568 0.000000 -0.102663
  3:     87649.217: 0.000000 0.000000 -0.257359
  4:     87649.217: 0.000000 0.000000 -0.257359
  0:     90214.862: 0.666667 0.0899011 0.000000
  1:     89935.462: 0.586403 0.000000 -0.298133
  2:     87667.921: 0.252502 0.000000 -0.107255
  3:     87649.405: 0.231383 0.00404239 -0.138625
  4:     87640.356: 0.197140 0.000000 -0.132754
  5:     87636.308: 0.171573 0.000000 -0.160910
  6:     87633.747: 0.143169 0.000414332 -0.135621
  7:     87631.943: 0.109135 0.00175782 -0.152542
  8:     87631.413: 0.100984 0.000000 -0.155398
  9:     87631.389: 0.0970080 0.000000 -0.156461
 10:     87631.383: 0.0953971 0.000000 -0.160248
 11:     87631.379: 0.0917818 4.22655e-005 -0.158282
 12:     87631.379: 0.0936796 0.000000 -0.159862
 13:     87631.378: 0.0935501 0.000000 -0.158634
 14:     87631.377: 0.0923555 0.000000 -0.158946
 15:     87631.377: 0.0929711 0.000000 -0.158993
 16:     87631.377: 0.0929886 1.09932e-006 -0.158978
  0:     90450.512: 0.666667 0.0891198 0.000000
  1:     90145.789: 0.582078 0.000000 -0.299052
  2:     87955.609: 0.286906 0.000000 -0.100895
  3:     87880.498: 0.000000 0.000000 -0.267268
  4:     87880.498: 0.000000 0.000000 -0.267268
  0:     89654.427: 0.666667 0.0897456 0.000000
  1:     89249.342: 0.581870 0.000000 -0.303489
  2:     86983.487: 0.260490 0.000000 -0.107015
  3:     86936.154: 0.000000 0.000000 -0.262106
  4:     86936.154: 0.000000 0.000000 -0.262106
  0:     90672.682: 0.666667 0.0899628 0.000000
  1:     90295.782: 0.579048 0.000000 -0.302737
  2:     88163.587: 0.295266 0.000000 -0.102005
  3:     88073.489: 0.000000 0.000000 -0.257767
  4:     88073.489: 0.000000 0.000000 -0.257767
  0:     90937.235: 0.666667 0.0908255 0.000000
  1:     90560.743: 0.576783 0.000000 -0.302200
  2:     88512.443: 0.313763 0.000000 -0.0979954
  3:     88397.731: 0.0116791 0.000000 -0.238082
  4:     88397.731: 0.0116793 2.13555e-006 -0.238082
  5:     88397.731: 0.0116802 1.58534e-006 -0.238082
  6:     88397.707: 0.0199269 2.58593e-006 -0.240413
  7:     88397.698: 0.0233275 1.25248e-006 -0.240845
  8:     88397.681: 0.0360058 0.000000 -0.238725
  9:     88397.642: 0.0377094 0.000000 -0.233764
 10:     88397.488: 0.0443160 0.000000 -0.213853
 11:     88397.429: 0.0505245 0.000000 -0.206634
 12:     88397.386: 0.0624587 0.000000 -0.191795
 13:     88397.384: 0.0605955 1.43867e-007 -0.197179
 14:     88397.382: 0.0592088 1.94955e-008 -0.196263
 15:     88397.382: 0.0603454 2.87004e-008 -0.195051
 16:     88397.382: 0.0603722 3.24738e-008 -0.195107
  0:     90982.636: 0.666667 0.0900408 0.000000
  1:     90686.775: 0.589304 0.000000 -0.297633
  2:     88417.031: 0.251443 0.000000 -0.107854
  3:     88408.132: 0.000000 0.000000 -0.236649
  4:     88408.132: 0.000000 0.000000 -0.236649
  0:     90869.412: 0.666667 0.0910546 0.000000
  1:     90447.155: 0.576076 0.000000 -0.301419
  2:     88292.494: 0.290024 0.000000 -0.0973598
  3:     88189.600: 0.000000 0.000000 -0.261628
  4:     88189.600: 0.000000 0.000000 -0.261628
  0:     91555.700: 0.666667 0.0894430 0.000000
  1:     91205.211: 0.583675 0.000000 -0.300239
  2:     88819.778: 0.217977 0.000000 -0.109167
  3:     88792.163: 0.000000 0.000000 -0.221989
  4:     88792.163: 0.000000 0.000000 -0.221989
  0:     90699.353: 0.666667 0.0934181 0.000000
  1:     90253.805: 0.585847 0.000000 -0.298291
  2:     88159.371: 0.298780 0.000000 -0.100183
  3:     88136.845: 0.000000 0.000000 -0.249850
  4:     88136.845: 0.000000 0.000000 -0.249850
  0:     91038.775: 0.666667 0.0912136 0.000000
  1:     90656.405: 0.581786 0.000000 -0.298768
  2:     88476.176: 0.280341 0.000000 -0.100177
  3:     88413.623: 0.000000 0.000000 -0.270528
  4:     88413.623: 0.000000 4.32879e-009 -0.270528
  5:     88413.623: 0.000000 4.32879e-009 -0.270528
  0:     90534.064: 0.666667 0.0912434 0.000000
  1:     90158.703: 0.581799 0.000000 -0.299923
  2:     88007.169: 0.285653 0.000000 -0.101348
  3:     87975.548: 0.270763 9.94850e-010 -0.132543
  4:     87963.471: 0.241261 0.00166749 -0.150478
  5:     87955.484: 0.212149 0.000000 -0.133227
  6:     87948.984: 0.188039 0.000000 -0.157996
  7:     87945.106: 0.157972 2.87461e-009 -0.140942
  8:     87942.894: 0.135918 0.000655211 -0.167551
  9:     87942.121: 0.110783 0.000000 -0.144511
 10:     87941.407: 0.0820679 0.000000 -0.163754
 11:     87941.374: 0.0874460 0.000000 -0.164379
 12:     87941.366: 0.0924083 0.000000 -0.165031
 13:     87941.366: 0.0921629 2.75824e-006 -0.164807
 14:     87941.365: 0.0918365 0.000000 -0.164754
 15:     87941.365: 0.0918121 1.05293e-009 -0.164776
 16:     87941.365: 0.0916407 1.25385e-007 -0.164902
 17:     87941.365: 0.0916280 0.000000 -0.164885
 18:     87941.365: 0.0915976 1.78900e-007 -0.164855
 19:     87941.365: 0.0915710 0.000000 -0.164868
 20:     87941.365: 0.0915709 6.77374e-008 -0.164868
 21:     87941.365: 0.0915707 0.000000 -0.164868
 22:     87941.365: 0.0915706 0.000000 -0.164869
 23:     87941.365: 0.0915706 0.000000 -0.164869
  0:     90538.952: 0.666667 0.0906664 0.000000
  1:     90188.780: 0.580152 0.000000 -0.298077
  2:     87995.424: 0.280946 0.000000 -0.0982630
  3:     87965.709: 0.263221 1.10254e-009 -0.127679
  4:     87950.953: 0.232057 0.00156023 -0.142027
  5:     87932.225: 0.160075 0.000000 -0.123961
  6:     87924.828: 0.107481 0.000000 -0.177222
  7:     87923.913: 0.101794 1.32194e-009 -0.172355
  8:     87922.762: 0.0898806 0.000000 -0.163290
  9:     87922.603: 0.0870883 2.97543e-007 -0.162210
 10:     87921.808: 0.0643480 0.000000 -0.154688
 11:     87921.756: 0.0619822 1.91616e-007 -0.155062
 12:     87921.461: 0.0430376 0.000000 -0.157938
 13:     87921.329: 0.0246316 0.000000 -0.160343
 14:     87921.290: 0.0115580 0.000000 -0.161904
 15:     87921.281: 0.00286298 0.000000 -0.162911
 16:     87921.281: 0.00189741 3.55755e-005 -0.162906
 17:     87921.280: 0.000934638 0.000000 -0.162938
 18:     87921.280: 0.000000 0.000000 -0.162968
 19:     87921.280: 0.000000 0.000000 -0.162968
  0:     89913.444: 0.666667 0.0906915 0.000000
  1:     89490.109: 0.578190 0.000000 -0.300666
  2:     87265.611: 0.273646 0.000000 -0.0992267
  3:     87184.839: 0.000000 0.000000 -0.273871
  4:     87184.839: 0.000000 0.000000 -0.273871
  0:     91445.647: 0.666667 0.0887779 0.000000
  1:     91205.368: 0.586436 0.000000 -0.295702
  2:     88923.840: 0.258811 0.000000 -0.103445
  3:     88907.893: 0.242519 0.000000 -0.128815
  4:     88901.918: 0.218662 0.000000 -0.147252
  5:     88895.042: 0.195226 0.000965137 -0.128307
  6:     88890.006: 0.169408 0.000000 -0.143102
  7:     88886.667: 0.140591 0.000000 -0.134234
  8:     88884.703: 0.113739 4.18354e-009 -0.147949
  9:     88883.819: 0.0890199 0.000000 -0.150225
 10:     88883.509: 0.0702513 0.000000 -0.151673
 11:     88883.409: 0.0564583 0.000000 -0.152518
 12:     88883.380: 0.0469538 0.000000 -0.152913
 13:     88883.374: 0.0411088 0.000000 -0.152998
 14:     88883.372: 0.0382539 0.000000 -0.152898
 15:     88883.372: 0.0371689 0.000000 -0.152722
 16:     88883.372: 0.0365899 0.000000 -0.152428
 17:     88883.372: 0.0362285 0.000000 -0.151744
 18:     88883.371: 0.0366140 0.000000 -0.150915
 19:     88883.371: 0.0373644 0.000000 -0.150538
 20:     88883.371: 0.0373648 4.72818e-007 -0.150539
 21:     88883.371: 0.0375860 0.000000 -0.150728
 22:     88883.371: 0.0378454 0.000000 -0.150594
Warning messages:
1: In mer_finalize(ans) : false convergence (8)
2: In mer_finalize(ans) : singular convergence (7)
3: In mer_finalize(ans) : singular convergence (7)
4: In mer_finalize(ans) : false convergence (8)
5: In mer_finalize(ans) : false convergence (8)
>       print(pool(Uncpde.math.f.mi))
Call: pool(object = Uncpde.math.f.mi)

Pooled coefficients:
  (Intercept) index 
   1.90889735    0.02891385 

Fraction of information about the coefficients missing due to nonresponse: 
  (Intercept) index 
    0.9464698     0.9361655 
>       round(summary(pool(Uncpde.math.f.mi)), 2)
               est   se    t    df Pr(>|t|) lo 95 hi 95  nmis  fmi lambda
(Intercept)   1.91 0.27 6.98 49.87      0.0  1.36  2.46    NA 0.95   0.94
index 0.03 0.03 0.85 51.68      0.4 -0.04  0.10 11776 0.94   0.93


From justiceaheto at yahoo.com  Sat Jun 30 14:36:35 2012
From: justiceaheto at yahoo.com (Justice Moses K. Aheto)
Date: Sat, 30 Jun 2012 05:36:35 -0700 (PDT)
Subject: [R-sig-ME] Help needed: Fitting and Simulating multilevel model in
	R.
Message-ID: <1341059795.30406.YahooMailNeo@web113408.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120630/d2c7b539/attachment.pl>

From longrob604 at gmail.com  Sat Jun 30 15:48:38 2012
From: longrob604 at gmail.com (W Robert Long)
Date: Sat, 30 Jun 2012 14:48:38 +0100
Subject: [R-sig-ME] warnings in lmer estimation after mice
In-Reply-To: <010201cd563d$0c2be710$2483b530$@com>
References: <010201cd563d$0c2be710$2483b530$@com>
Message-ID: <4FEF03B6.3050807@gmail.com>

Two things spring to mind:
1. I don't think your imputation respects the data hierarchy -  see p21 
here:
http://www.jstatsoft.org/v45/i03/paper

2. You have 58% missingness in "gain" and 81% missingness in "index", 
which makes me wonder if you should be doing multiple imputation at all.

On 29/06/2012 10:20 PM, Raquel Guimaraes wrote:
> Hi all,
>
> I need help to understand convergence problems with my estimation.
>
> I am using lmer to estimate a mixed-effects model of an index of teacher
> quality on student achievement gains.
>
> The dataset for female students is available in the link above and contains
> original and imputed data (m=5 and m=50)
>
> <https://www.dropbox.com/sh/fqpjtkkuz9y9mzr/MhrMXwlrFp>
>
> I want to understand the error messages above and their implications for my
> parameter estimates.
>
> 1: In mer_finalize(ans) : false convergence (8)
> 2: In mer_finalize(ans) : singular convergence (7)
> 3: In mer_finalize(ans) : singular convergence (7)
> 4: In mer_finalize(ans) : false convergence (8)
> 5: In mer_finalize(ans) : false convergence (8)
>
> Below you may find the script for my procedures.
>
> Any help will be appreciated!
>
> Thanks,
>
> Raquel
>
> -----------------------------------------------------------------
>
> #Multiple imputation
>
> library("mice")
> md.pattern(data.f)
> md.pairs(data.f)
> # 5 imputations - Predictive mean matching
> imp.5.f<-mice(data.f,m=5,seed=23109)
> print(imp.5.f)
> # 50 imputations - Predictive mean matching
> imp.50.f<-mice(data.f,m=50,seed=23109)
> print(imp.50.f)
>
> #Running lmer
> library(lme4)
>
>    #Imputed data
>      #Females
>        Uncpde.math.f.mi <- with(imp.50.f, lmer(gain ~ index +
>          ( index | std_id), verbose=TRUE))
>        print(pool(Uncpde.math.f.mi))
>        round(summary(pool(Uncpde.math.f.mi)), 2)
> 	
>>        Uncpde.math.f.mi <- with(imp.50.f, lmer(gain ~ index +
> +         ( index | std_id), verbose=TRUE))
>    0:     91323.888: 0.666667 0.0912755 0.000000
>    1:     90950.102: 0.579295 0.000000 -0.298895
>    2:     88854.168: 0.305206 0.000000 -0.0962998
>    3:     88814.543: 0.288910 8.27185e-010 -0.126235
>    4:     88797.001: 0.261789 0.00137943 -0.146833
>    5:     88783.121: 0.229797 0.000000 -0.136191
>    6:     88765.032: 0.163649 0.000000 -0.170033
>    7:     88764.059: 0.101518 0.00683235 -0.129860
>    8:     88757.161: 0.0894730 0.000000 -0.151620
>    9:     88756.669: 0.0802386 0.000000 -0.161394
>   10:     88756.413: 0.0692536 0.000000 -0.169148
>   11:     88756.296: 0.0566213 0.000000 -0.173754
>   12:     88756.276: 0.0473775 0.000000 -0.172026
>   13:     88756.268: 0.0454115 0.000000 -0.177962
>   14:     88756.268: 0.0445268 0.000000 -0.177518
>   15:     88756.268: 0.0445255 6.95905e-007 -0.177518
>   16:     88756.268: 0.0443349 1.91179e-007 -0.177519
>   17:     88756.268: 0.0443349 1.91179e-007 -0.177519
>    0:     90892.401: 0.666667 0.0901811 0.000000
>    1:     90565.986: 0.582914 0.000000 -0.301351
>    2:     88348.591: 0.262114 0.000000 -0.107499
>    3:     88300.308: 0.000000 0.000000 -0.259898
>    4:     88300.308: 0.000000 0.000000 -0.259898
>    0:     92116.635: 0.666667 0.0860717 0.000000
>    1:     91920.069: 0.589035 0.000000 -0.302245
>    2:     89502.995: 0.208420 0.000000 -0.118175
>    3:     89484.310: 0.000000 0.000000 -0.217057
>    4:     89484.310: 0.000000 0.000000 -0.217057
>    0:     90508.355: 0.666667 0.0907223 0.000000
>    1:     90069.269: 0.575010 0.000000 -0.303351
>    2:     87914.618: 0.289817 0.000000 -0.0984479
>    3:     87811.950: 0.000000 0.000000 -0.262459
>    4:     87811.950: 0.000000 0.000000 -0.262459
>    0:     90728.496: 0.666667 0.0893763 0.000000
>    1:     90385.062: 0.582005 0.000000 -0.301492
>    2:     88044.313: 0.230444 0.000000 -0.108661
>    3:     88004.837: 0.000000 0.000000 -0.234827
>    4:     88004.837: 0.000000 0.000000 -0.234827
>    0:     90569.541: 0.666667 0.0904525 0.000000
>    1:     90248.550: 0.585924 0.000000 -0.296967
>    2:     87912.085: 0.229608 0.000000 -0.106161
>    3:     87890.585: 0.000000 0.000000 -0.222132
>    4:     87890.585: 0.000000 0.000000 -0.222132
>    0:     90567.799: 0.666667 0.0887506 0.000000
>    1:     90302.451: 0.587353 0.000000 -0.300203
>    2:     88030.944: 0.255280 0.000000 -0.110269
>    3:     87995.243: 0.000000 0.000000 -0.246234
>    4:     87995.243: 0.000000 0.000000 -0.246234
>    0:     90630.186: 0.666667 0.0905161 0.000000
>    1:     90245.654: 0.581825 0.000000 -0.299051
>    2:     88024.455: 0.278519 0.000000 -0.100122
>    3:     87959.404: 0.000000 0.000000 -0.269139
>    4:     87959.404: 0.000000 0.000000 -0.269139
>    0:     91431.304: 0.666667 0.0910478 0.000000
>    1:     91060.176: 0.577973 0.000000 -0.299692
>    2:     88879.745: 0.273428 0.000000 -0.0991786
>    3:     88804.068: 0.000000 0.000000 -0.272971
>    4:     88804.068: 0.000000 0.000000 -0.272971
>    0:     90853.326: 0.666667 0.0899358 0.000000
>    1:     90519.641: 0.585512 0.000000 -0.298258
>    2:     88288.745: 0.275120 0.000000 -0.102956
>    3:     88246.430: 0.000000 0.000000 -0.258963
>    4:     88246.430: 0.000000 0.000000 -0.258963
>    0:     90697.216: 0.666667 0.0856334 0.000000
>    1:     90578.775: 0.593759 0.000000 -0.298316
>    2:     88081.238: 0.184499 0.000000 -0.119253
>    3:     88078.012: 0.000000 0.000000 -0.196102
>    4:     88078.012: 0.000000 0.000000 -0.196102
>    0:     90639.439: 0.666667 0.0902601 0.000000
>    1:     90295.074: 0.583471 0.000000 -0.299601
>    2:     88125.514: 0.286629 0.000000 -0.102261
>    3:     88067.467: 0.000000 0.000000 -0.268202
>    4:     88067.467: 0.000000 0.000000 -0.268202
>    0:     90573.744: 0.666667 0.0917234 0.000000
>    1:     90156.547: 0.577930 0.000000 -0.300638
>    2:     88068.528: 0.306034 0.000000 -0.0965273
>    3:     87975.584: 0.000000 0.000000 -0.238077
>    4:     87975.584: 0.000000 0.000000 -0.238077
>    0:     89721.612: 0.666667 0.0913660 0.000000
>    1:     89274.384: 0.577867 0.000000 -0.302115
>    2:     87025.514: 0.258058 0.000000 -0.102274
>    3:     86960.255: 0.000000 0.000000 -0.264012
>    4:     86960.255: 0.000000 0.000000 -0.264012
>    0:     89773.327: 0.666667 0.0914180 0.000000
>    1:     89431.386: 0.579968 0.000000 -0.297710
>    2:     87172.239: 0.245863 0.000000 -0.102001
>    3:     87121.156: 0.000000 0.000000 -0.244505
>    4:     87121.156: 0.000000 2.95447e-009 -0.244505
>    5:     87121.156: 0.000000 1.89955e-009 -0.244505
>    0:     91307.998: 0.666667 0.0881736 0.000000
>    1:     90963.328: 0.582168 0.000000 -0.305197
>    2:     88585.039: 0.218209 0.000000 -0.114601
>    3:     88552.517: 0.000000 0.000000 -0.232242
>    4:     88552.517: 0.000000 0.000000 -0.232242
>    0:     90098.405: 0.666667 0.0912658 0.000000
>    1:     89625.050: 0.577676 0.000000 -0.303420
>    2:     87381.866: 0.264236 0.000000 -0.102601
>    3:     87313.537: 0.000000 0.000000 -0.270530
>    4:     87313.537: 0.000000 0.000000 -0.270530
>    0:     90946.093: 0.666667 0.0900592 0.000000
>    1:     90583.090: 0.581315 0.000000 -0.300756
>    2:     88388.898: 0.278531 0.000000 -0.102687
>    3:     88324.595: 0.000000 0.000000 -0.273038
>    4:     88324.595: 0.000000 0.000000 -0.273038
>    0:     91333.939: 0.666667 0.0913058 0.000000
>    1:     90904.541: 0.577003 0.000000 -0.299602
>    2:     88679.234: 0.272647 0.000000 -0.0969097
>    3:     88596.130: 0.000000 0.000000 -0.272223
>    4:     88596.130: 0.000000 0.000000 -0.272223
>    0:     90152.037: 0.666667 0.0900727 0.000000
>    1:     89702.620: 0.575074 0.000000 -0.306728
>    2:     87596.979: 0.302713 0.000000 -0.101807
>    3:     87484.248: 0.000000 0.000000 -0.248542
>    4:     87484.248: 0.000000 0.000000 -0.248542
>    0:     91117.801: 0.666667 0.0908513 0.000000
>    1:     90757.634: 0.580554 0.000000 -0.299360
>    2:     88603.505: 0.283831 0.000000 -0.0999435
>    3:     88574.096: 0.267794 0.000000 -0.130461
>    4:     88562.206: 0.238612 0.000000 -0.148816
>    5:     88553.044: 0.208478 0.000595092 -0.132080
>    6:     88546.351: 0.181458 0.000000 -0.153290
>    7:     88542.081: 0.150185 0.000000 -0.138783
>    8:     88539.627: 0.123847 1.01894e-009 -0.161027
>    9:     88538.734: 0.0942445 0.000744265 -0.143374
>   10:     88538.275: 0.0808928 0.000000 -0.152300
>   11:     88538.188: 0.0721130 0.000000 -0.159438
>   12:     88538.184: 0.0695887 0.000000 -0.160606
>   13:     88538.183: 0.0680936 0.000000 -0.160978
>   14:     88538.183: 0.0677477 0.000000 -0.160916
>   15:     88538.183: 0.0676509 0.000000 -0.160808
>   16:     88538.183: 0.0676691 0.000000 -0.160770
>    0:     90816.807: 0.666667 0.0906318 0.000000
>    1:     90424.195: 0.578291 0.000000 -0.302393
>    2:     88300.640: 0.297094 0.000000 -0.100293
>    3:     88204.488: 0.000000 0.000000 -0.253910
>    4:     88204.488: 0.000000 0.000000 -0.253910
>    0:     91513.066: 0.666667 0.0905136 0.000000
>    1:     91059.392: 0.572808 0.000000 -0.304419
>    2:     88963.498: 0.308436 0.000000 -0.0961059
>    3:     88828.230: 0.00365434 0.000000 -0.238915
>    4:     88828.230: 0.00353298 2.48295e-007 -0.238904
>    5:     88828.228: 0.000809467 8.53595e-006 -0.238663
>    6:     88828.227: 0.000000 0.000000 -0.238628
>    7:     88828.227: 0.000000 0.000000 -0.238628
>    0:     91150.802: 0.666667 0.0891040 0.000000
>    1:     90889.912: 0.587635 0.000000 -0.295390
>    2:     88556.237: 0.240279 0.000000 -0.104882
>    3:     88549.670: 0.235780 0.000000 -0.114362
>    4:     88542.519: 0.221856 0.000000 -0.136892
>    5:     88538.276: 0.196911 0.000536413 -0.128009
>    6:     88535.760: 0.176898 0.000000 -0.145077
>    7:     88534.303: 0.157582 0.000000 -0.126956
>    8:     88533.996: 0.156218 2.29140e-010 -0.129226
>    9:     88533.534: 0.153150 3.03087e-005 -0.133544
>   10:     88532.859: 0.140751 0.000000 -0.142165
>   11:     88532.514: 0.126963 0.000000 -0.135997
>   12:     88532.299: 0.114249 0.000000 -0.140115
>   13:     88532.276: 0.109185 0.000000 -0.141707
>   14:     88532.275: 0.107867 0.000000 -0.142196
>   15:     88532.275: 0.107761 0.000000 -0.142270
>   16:     88532.275: 0.107763 2.96078e-010 -0.142274
>   17:     88532.275: 0.107767 0.000000 -0.142285
>   18:     88532.275: 0.107776 0.000000 -0.142284
>    0:     90591.670: 0.666667 0.0902163 0.000000
>    1:     90253.650: 0.582677 0.000000 -0.296733
>    2:     87913.750: 0.234039 0.000000 -0.102682
>    3:     87877.999: 0.000000 0.000000 -0.227078
>    4:     87877.999: 0.000000 0.000000 -0.227078
>    0:     90673.897: 0.666667 0.0896992 0.000000
>    1:     90337.823: 0.585673 0.000000 -0.300345
>    2:     88000.465: 0.229841 0.000000 -0.109921
>    3:     87976.655: 0.000000 0.000000 -0.229344
>    4:     87976.655: 0.000000 0.000000 -0.229344
>    0:     91695.842: 0.666667 0.0899055 0.000000
>    1:     91404.328: 0.584642 0.000000 -0.297876
>    2:     89214.414: 0.281201 0.000000 -0.102582
>    3:     89188.190: 0.265626 0.000000 -0.133284
>    4:     89178.234: 0.236801 0.000000 -0.152108
>    5:     89170.640: 0.208346 0.00119384 -0.132766
>    6:     89165.050: 0.184852 0.000000 -0.157320
>    7:     89161.506: 0.155593 0.000000 -0.139179
>    8:     89159.386: 0.133551 4.59756e-009 -0.165624
>    9:     89159.213: 0.130015 0.00119127 -0.162734
>   10:     89158.808: 0.126412 0.000000 -0.160222
>   11:     89158.328: 0.109125 0.000000 -0.154874
>   12:     89158.186: 0.0975572 0.000000 -0.168789
>   13:     89158.113: 0.0883497 0.000000 -0.164147
>   14:     89158.112: 0.0893647 3.36482e-007 -0.164147
>   15:     89158.112: 0.0894556 0.000000 -0.164102
>   16:     89158.111: 0.0901974 2.92690e-006 -0.163772
>   17:     89158.111: 0.0904597 0.000000 -0.163769
>   18:     89158.111: 0.0904597 0.000000 -0.163769
>    0:     92026.232: 0.666667 0.0894992 0.000000
>    1:     91735.788: 0.581037 0.000000 -0.298447
>    2:     89530.291: 0.274498 0.000000 -0.101211
>    3:     89465.691: 0.000000 0.000000 -0.265849
>    4:     89465.691: 0.000000 0.000000 -0.265849
>    0:     89155.666: 0.666667 0.0892915 0.000000
>    1:     88806.417: 0.582861 0.000000 -0.303162
>    2:     86512.523: 0.245630 0.000000 -0.109990
>    3:     86472.497: 0.000000 0.000000 -0.248275
>    4:     86472.497: 0.000000 0.000000 -0.248275
>    0:     91625.651: 0.666667 0.0892096 0.000000
>    1:     91305.690: 0.580685 0.000000 -0.300005
>    2:     89053.463: 0.263647 0.000000 -0.103131
>    3:     88986.561: 0.000000 0.000000 -0.261116
>    4:     88986.561: 0.000000 0.000000 -0.261116
>    0:     90869.702: 0.666667 0.0892723 0.000000
>    1:     90555.120: 0.579552 0.000000 -0.300675
>    2:     88410.128: 0.295998 0.000000 -0.100232
>    3:     88314.598: 0.000000 0.000000 -0.255183
>    4:     88314.598: 0.000000 3.86364e-009 -0.255183
>    5:     88314.598: 0.000000 3.86364e-009 -0.255183
>    0:     91108.704: 0.666667 0.0906011 0.000000
>    1:     90804.467: 0.586207 0.000000 -0.293469
>    2:     88408.714: 0.209336 0.000000 -0.104199
>    3:     88390.555: 0.000000 0.000000 -0.233786
>    4:     88390.555: 0.000000 4.74440e-009 -0.233786
>    5:     88390.555: 0.000000 4.74440e-009 -0.233786
>    0:     91771.237: 0.666667 0.0903370 0.000000
>    1:     91413.484: 0.577979 0.000000 -0.300203
>    2:     89218.035: 0.273200 0.000000 -0.100290
>    3:     89189.934: 0.254171 1.16058e-009 -0.128658
>    4:     89174.483: 0.222469 0.00144656 -0.141297
>    5:     89151.646: 0.136126 0.000000 -0.129612
>    6:     89144.537: 0.0652530 0.000000 -0.181235
>    7:     89143.147: 0.000000 0.000000 -0.132500
>    8:     89143.147: 0.000000 0.000000 -0.132500
>    0:     92075.541: 0.666667 0.0889713 0.000000
>    1:     91754.396: 0.582594 0.000000 -0.299314
>    2:     89493.502: 0.269474 0.000000 -0.102596
>    3:     89431.022: 0.000000 0.000000 -0.259856
>    4:     89431.022: 0.000000 0.000000 -0.259856
>    0:     90741.014: 0.666667 0.0910750 0.000000
>    1:     90297.019: 0.577011 0.000000 -0.305139
>    2:     88152.539: 0.285117 0.000000 -0.103300
>    3:     88068.757: 0.000000 0.000000 -0.272904
>    4:     88068.757: 0.000000 0.000000 -0.272904
>    0:     90254.977: 0.666667 0.0906367 0.000000
>    1:     89853.808: 0.580116 0.000000 -0.303049
>    2:     87726.880: 0.295568 0.000000 -0.102663
>    3:     87649.217: 0.000000 0.000000 -0.257359
>    4:     87649.217: 0.000000 0.000000 -0.257359
>    0:     90214.862: 0.666667 0.0899011 0.000000
>    1:     89935.462: 0.586403 0.000000 -0.298133
>    2:     87667.921: 0.252502 0.000000 -0.107255
>    3:     87649.405: 0.231383 0.00404239 -0.138625
>    4:     87640.356: 0.197140 0.000000 -0.132754
>    5:     87636.308: 0.171573 0.000000 -0.160910
>    6:     87633.747: 0.143169 0.000414332 -0.135621
>    7:     87631.943: 0.109135 0.00175782 -0.152542
>    8:     87631.413: 0.100984 0.000000 -0.155398
>    9:     87631.389: 0.0970080 0.000000 -0.156461
>   10:     87631.383: 0.0953971 0.000000 -0.160248
>   11:     87631.379: 0.0917818 4.22655e-005 -0.158282
>   12:     87631.379: 0.0936796 0.000000 -0.159862
>   13:     87631.378: 0.0935501 0.000000 -0.158634
>   14:     87631.377: 0.0923555 0.000000 -0.158946
>   15:     87631.377: 0.0929711 0.000000 -0.158993
>   16:     87631.377: 0.0929886 1.09932e-006 -0.158978
>    0:     90450.512: 0.666667 0.0891198 0.000000
>    1:     90145.789: 0.582078 0.000000 -0.299052
>    2:     87955.609: 0.286906 0.000000 -0.100895
>    3:     87880.498: 0.000000 0.000000 -0.267268
>    4:     87880.498: 0.000000 0.000000 -0.267268
>    0:     89654.427: 0.666667 0.0897456 0.000000
>    1:     89249.342: 0.581870 0.000000 -0.303489
>    2:     86983.487: 0.260490 0.000000 -0.107015
>    3:     86936.154: 0.000000 0.000000 -0.262106
>    4:     86936.154: 0.000000 0.000000 -0.262106
>    0:     90672.682: 0.666667 0.0899628 0.000000
>    1:     90295.782: 0.579048 0.000000 -0.302737
>    2:     88163.587: 0.295266 0.000000 -0.102005
>    3:     88073.489: 0.000000 0.000000 -0.257767
>    4:     88073.489: 0.000000 0.000000 -0.257767
>    0:     90937.235: 0.666667 0.0908255 0.000000
>    1:     90560.743: 0.576783 0.000000 -0.302200
>    2:     88512.443: 0.313763 0.000000 -0.0979954
>    3:     88397.731: 0.0116791 0.000000 -0.238082
>    4:     88397.731: 0.0116793 2.13555e-006 -0.238082
>    5:     88397.731: 0.0116802 1.58534e-006 -0.238082
>    6:     88397.707: 0.0199269 2.58593e-006 -0.240413
>    7:     88397.698: 0.0233275 1.25248e-006 -0.240845
>    8:     88397.681: 0.0360058 0.000000 -0.238725
>    9:     88397.642: 0.0377094 0.000000 -0.233764
>   10:     88397.488: 0.0443160 0.000000 -0.213853
>   11:     88397.429: 0.0505245 0.000000 -0.206634
>   12:     88397.386: 0.0624587 0.000000 -0.191795
>   13:     88397.384: 0.0605955 1.43867e-007 -0.197179
>   14:     88397.382: 0.0592088 1.94955e-008 -0.196263
>   15:     88397.382: 0.0603454 2.87004e-008 -0.195051
>   16:     88397.382: 0.0603722 3.24738e-008 -0.195107
>    0:     90982.636: 0.666667 0.0900408 0.000000
>    1:     90686.775: 0.589304 0.000000 -0.297633
>    2:     88417.031: 0.251443 0.000000 -0.107854
>    3:     88408.132: 0.000000 0.000000 -0.236649
>    4:     88408.132: 0.000000 0.000000 -0.236649
>    0:     90869.412: 0.666667 0.0910546 0.000000
>    1:     90447.155: 0.576076 0.000000 -0.301419
>    2:     88292.494: 0.290024 0.000000 -0.0973598
>    3:     88189.600: 0.000000 0.000000 -0.261628
>    4:     88189.600: 0.000000 0.000000 -0.261628
>    0:     91555.700: 0.666667 0.0894430 0.000000
>    1:     91205.211: 0.583675 0.000000 -0.300239
>    2:     88819.778: 0.217977 0.000000 -0.109167
>    3:     88792.163: 0.000000 0.000000 -0.221989
>    4:     88792.163: 0.000000 0.000000 -0.221989
>    0:     90699.353: 0.666667 0.0934181 0.000000
>    1:     90253.805: 0.585847 0.000000 -0.298291
>    2:     88159.371: 0.298780 0.000000 -0.100183
>    3:     88136.845: 0.000000 0.000000 -0.249850
>    4:     88136.845: 0.000000 0.000000 -0.249850
>    0:     91038.775: 0.666667 0.0912136 0.000000
>    1:     90656.405: 0.581786 0.000000 -0.298768
>    2:     88476.176: 0.280341 0.000000 -0.100177
>    3:     88413.623: 0.000000 0.000000 -0.270528
>    4:     88413.623: 0.000000 4.32879e-009 -0.270528
>    5:     88413.623: 0.000000 4.32879e-009 -0.270528
>    0:     90534.064: 0.666667 0.0912434 0.000000
>    1:     90158.703: 0.581799 0.000000 -0.299923
>    2:     88007.169: 0.285653 0.000000 -0.101348
>    3:     87975.548: 0.270763 9.94850e-010 -0.132543
>    4:     87963.471: 0.241261 0.00166749 -0.150478
>    5:     87955.484: 0.212149 0.000000 -0.133227
>    6:     87948.984: 0.188039 0.000000 -0.157996
>    7:     87945.106: 0.157972 2.87461e-009 -0.140942
>    8:     87942.894: 0.135918 0.000655211 -0.167551
>    9:     87942.121: 0.110783 0.000000 -0.144511
>   10:     87941.407: 0.0820679 0.000000 -0.163754
>   11:     87941.374: 0.0874460 0.000000 -0.164379
>   12:     87941.366: 0.0924083 0.000000 -0.165031
>   13:     87941.366: 0.0921629 2.75824e-006 -0.164807
>   14:     87941.365: 0.0918365 0.000000 -0.164754
>   15:     87941.365: 0.0918121 1.05293e-009 -0.164776
>   16:     87941.365: 0.0916407 1.25385e-007 -0.164902
>   17:     87941.365: 0.0916280 0.000000 -0.164885
>   18:     87941.365: 0.0915976 1.78900e-007 -0.164855
>   19:     87941.365: 0.0915710 0.000000 -0.164868
>   20:     87941.365: 0.0915709 6.77374e-008 -0.164868
>   21:     87941.365: 0.0915707 0.000000 -0.164868
>   22:     87941.365: 0.0915706 0.000000 -0.164869
>   23:     87941.365: 0.0915706 0.000000 -0.164869
>    0:     90538.952: 0.666667 0.0906664 0.000000
>    1:     90188.780: 0.580152 0.000000 -0.298077
>    2:     87995.424: 0.280946 0.000000 -0.0982630
>    3:     87965.709: 0.263221 1.10254e-009 -0.127679
>    4:     87950.953: 0.232057 0.00156023 -0.142027
>    5:     87932.225: 0.160075 0.000000 -0.123961
>    6:     87924.828: 0.107481 0.000000 -0.177222
>    7:     87923.913: 0.101794 1.32194e-009 -0.172355
>    8:     87922.762: 0.0898806 0.000000 -0.163290
>    9:     87922.603: 0.0870883 2.97543e-007 -0.162210
>   10:     87921.808: 0.0643480 0.000000 -0.154688
>   11:     87921.756: 0.0619822 1.91616e-007 -0.155062
>   12:     87921.461: 0.0430376 0.000000 -0.157938
>   13:     87921.329: 0.0246316 0.000000 -0.160343
>   14:     87921.290: 0.0115580 0.000000 -0.161904
>   15:     87921.281: 0.00286298 0.000000 -0.162911
>   16:     87921.281: 0.00189741 3.55755e-005 -0.162906
>   17:     87921.280: 0.000934638 0.000000 -0.162938
>   18:     87921.280: 0.000000 0.000000 -0.162968
>   19:     87921.280: 0.000000 0.000000 -0.162968
>    0:     89913.444: 0.666667 0.0906915 0.000000
>    1:     89490.109: 0.578190 0.000000 -0.300666
>    2:     87265.611: 0.273646 0.000000 -0.0992267
>    3:     87184.839: 0.000000 0.000000 -0.273871
>    4:     87184.839: 0.000000 0.000000 -0.273871
>    0:     91445.647: 0.666667 0.0887779 0.000000
>    1:     91205.368: 0.586436 0.000000 -0.295702
>    2:     88923.840: 0.258811 0.000000 -0.103445
>    3:     88907.893: 0.242519 0.000000 -0.128815
>    4:     88901.918: 0.218662 0.000000 -0.147252
>    5:     88895.042: 0.195226 0.000965137 -0.128307
>    6:     88890.006: 0.169408 0.000000 -0.143102
>    7:     88886.667: 0.140591 0.000000 -0.134234
>    8:     88884.703: 0.113739 4.18354e-009 -0.147949
>    9:     88883.819: 0.0890199 0.000000 -0.150225
>   10:     88883.509: 0.0702513 0.000000 -0.151673
>   11:     88883.409: 0.0564583 0.000000 -0.152518
>   12:     88883.380: 0.0469538 0.000000 -0.152913
>   13:     88883.374: 0.0411088 0.000000 -0.152998
>   14:     88883.372: 0.0382539 0.000000 -0.152898
>   15:     88883.372: 0.0371689 0.000000 -0.152722
>   16:     88883.372: 0.0365899 0.000000 -0.152428
>   17:     88883.372: 0.0362285 0.000000 -0.151744
>   18:     88883.371: 0.0366140 0.000000 -0.150915
>   19:     88883.371: 0.0373644 0.000000 -0.150538
>   20:     88883.371: 0.0373648 4.72818e-007 -0.150539
>   21:     88883.371: 0.0375860 0.000000 -0.150728
>   22:     88883.371: 0.0378454 0.000000 -0.150594
> Warning messages:
> 1: In mer_finalize(ans) : false convergence (8)
> 2: In mer_finalize(ans) : singular convergence (7)
> 3: In mer_finalize(ans) : singular convergence (7)
> 4: In mer_finalize(ans) : false convergence (8)
> 5: In mer_finalize(ans) : false convergence (8)
>>        print(pool(Uncpde.math.f.mi))
> Call: pool(object = Uncpde.math.f.mi)
>
> Pooled coefficients:
>    (Intercept) index
>     1.90889735    0.02891385
>
> Fraction of information about the coefficients missing due to nonresponse:
>    (Intercept) index
>      0.9464698     0.9361655
>>        round(summary(pool(Uncpde.math.f.mi)), 2)
>                 est   se    t    df Pr(>|t|) lo 95 hi 95  nmis  fmi lambda
> (Intercept)   1.91 0.27 6.98 49.87      0.0  1.36  2.46    NA 0.95   0.94
> index 0.03 0.03 0.85 51.68      0.4 -0.04  0.10 11776 0.94   0.93
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From raquelrguima at gmail.com  Sat Jun 30 19:59:25 2012
From: raquelrguima at gmail.com (Raquel Guimaraes)
Date: Sat, 30 Jun 2012 10:59:25 -0700
Subject: [R-sig-ME] warnings in lmer estimation after mice
In-Reply-To: <4FEF03B6.3050807@gmail.com>
References: <010201cd563d$0c2be710$2483b530$@com> <4FEF03B6.3050807@gmail.com>
Message-ID: <028a01cd56ea$1849d400$48dd7c00$@com>

Thanks Robert. This is really a great advice. I was worried about the
reduced sample, but I will go ahead and try to explain what's going on.

Best,

Raquel

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of W Robert Long
Sent: Saturday, June 30, 2012 6:49 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] warnings in lmer estimation after mice

Two things spring to mind:
1. I don't think your imputation respects the data hierarchy -  see p21
here:
http://www.jstatsoft.org/v45/i03/paper

2. You have 58% missingness in "gain" and 81% missingness in "index", which
makes me wonder if you should be doing multiple imputation at all.

On 29/06/2012 10:20 PM, Raquel Guimaraes wrote:
> Hi all,
>
> I need help to understand convergence problems with my estimation.
>
> I am using lmer to estimate a mixed-effects model of an index of 
> teacher quality on student achievement gains.
>
> The dataset for female students is available in the link above and 
> contains original and imputed data (m=5 and m=50)
>
> <https://www.dropbox.com/sh/fqpjtkkuz9y9mzr/MhrMXwlrFp>
>
> I want to understand the error messages above and their implications 
> for my parameter estimates.
>
> 1: In mer_finalize(ans) : false convergence (8)
> 2: In mer_finalize(ans) : singular convergence (7)
> 3: In mer_finalize(ans) : singular convergence (7)
> 4: In mer_finalize(ans) : false convergence (8)
> 5: In mer_finalize(ans) : false convergence (8)
>
> Below you may find the script for my procedures.
>
> Any help will be appreciated!
>
> Thanks,
>
> Raquel
>
> -----------------------------------------------------------------
>
> #Multiple imputation
>
> library("mice")
> md.pattern(data.f)
> md.pairs(data.f)
> # 5 imputations - Predictive mean matching
> imp.5.f<-mice(data.f,m=5,seed=23109)
> print(imp.5.f)
> # 50 imputations - Predictive mean matching
> imp.50.f<-mice(data.f,m=50,seed=23109)
> print(imp.50.f)
>
> #Running lmer
> library(lme4)
>
>    #Imputed data
>      #Females
>        Uncpde.math.f.mi <- with(imp.50.f, lmer(gain ~ index +
>          ( index | std_id), verbose=TRUE))
>        print(pool(Uncpde.math.f.mi))
>        round(summary(pool(Uncpde.math.f.mi)), 2)
> 	
>>        Uncpde.math.f.mi <- with(imp.50.f, lmer(gain ~ index +
> +         ( index | std_id), verbose=TRUE))
>    0:     91323.888: 0.666667 0.0912755 0.000000
>    1:     90950.102: 0.579295 0.000000 -0.298895
>    2:     88854.168: 0.305206 0.000000 -0.0962998
>    3:     88814.543: 0.288910 8.27185e-010 -0.126235
>    4:     88797.001: 0.261789 0.00137943 -0.146833
>    5:     88783.121: 0.229797 0.000000 -0.136191
>    6:     88765.032: 0.163649 0.000000 -0.170033
>    7:     88764.059: 0.101518 0.00683235 -0.129860
>    8:     88757.161: 0.0894730 0.000000 -0.151620
>    9:     88756.669: 0.0802386 0.000000 -0.161394
>   10:     88756.413: 0.0692536 0.000000 -0.169148
>   11:     88756.296: 0.0566213 0.000000 -0.173754
>   12:     88756.276: 0.0473775 0.000000 -0.172026
>   13:     88756.268: 0.0454115 0.000000 -0.177962
>   14:     88756.268: 0.0445268 0.000000 -0.177518
>   15:     88756.268: 0.0445255 6.95905e-007 -0.177518
>   16:     88756.268: 0.0443349 1.91179e-007 -0.177519
>   17:     88756.268: 0.0443349 1.91179e-007 -0.177519
>    0:     90892.401: 0.666667 0.0901811 0.000000
>    1:     90565.986: 0.582914 0.000000 -0.301351
>    2:     88348.591: 0.262114 0.000000 -0.107499
>    3:     88300.308: 0.000000 0.000000 -0.259898
>    4:     88300.308: 0.000000 0.000000 -0.259898
>    0:     92116.635: 0.666667 0.0860717 0.000000
>    1:     91920.069: 0.589035 0.000000 -0.302245
>    2:     89502.995: 0.208420 0.000000 -0.118175
>    3:     89484.310: 0.000000 0.000000 -0.217057
>    4:     89484.310: 0.000000 0.000000 -0.217057
>    0:     90508.355: 0.666667 0.0907223 0.000000
>    1:     90069.269: 0.575010 0.000000 -0.303351
>    2:     87914.618: 0.289817 0.000000 -0.0984479
>    3:     87811.950: 0.000000 0.000000 -0.262459
>    4:     87811.950: 0.000000 0.000000 -0.262459
>    0:     90728.496: 0.666667 0.0893763 0.000000
>    1:     90385.062: 0.582005 0.000000 -0.301492
>    2:     88044.313: 0.230444 0.000000 -0.108661
>    3:     88004.837: 0.000000 0.000000 -0.234827
>    4:     88004.837: 0.000000 0.000000 -0.234827
>    0:     90569.541: 0.666667 0.0904525 0.000000
>    1:     90248.550: 0.585924 0.000000 -0.296967
>    2:     87912.085: 0.229608 0.000000 -0.106161
>    3:     87890.585: 0.000000 0.000000 -0.222132
>    4:     87890.585: 0.000000 0.000000 -0.222132
>    0:     90567.799: 0.666667 0.0887506 0.000000
>    1:     90302.451: 0.587353 0.000000 -0.300203
>    2:     88030.944: 0.255280 0.000000 -0.110269
>    3:     87995.243: 0.000000 0.000000 -0.246234
>    4:     87995.243: 0.000000 0.000000 -0.246234
>    0:     90630.186: 0.666667 0.0905161 0.000000
>    1:     90245.654: 0.581825 0.000000 -0.299051
>    2:     88024.455: 0.278519 0.000000 -0.100122
>    3:     87959.404: 0.000000 0.000000 -0.269139
>    4:     87959.404: 0.000000 0.000000 -0.269139
>    0:     91431.304: 0.666667 0.0910478 0.000000
>    1:     91060.176: 0.577973 0.000000 -0.299692
>    2:     88879.745: 0.273428 0.000000 -0.0991786
>    3:     88804.068: 0.000000 0.000000 -0.272971
>    4:     88804.068: 0.000000 0.000000 -0.272971
>    0:     90853.326: 0.666667 0.0899358 0.000000
>    1:     90519.641: 0.585512 0.000000 -0.298258
>    2:     88288.745: 0.275120 0.000000 -0.102956
>    3:     88246.430: 0.000000 0.000000 -0.258963
>    4:     88246.430: 0.000000 0.000000 -0.258963
>    0:     90697.216: 0.666667 0.0856334 0.000000
>    1:     90578.775: 0.593759 0.000000 -0.298316
>    2:     88081.238: 0.184499 0.000000 -0.119253
>    3:     88078.012: 0.000000 0.000000 -0.196102
>    4:     88078.012: 0.000000 0.000000 -0.196102
>    0:     90639.439: 0.666667 0.0902601 0.000000
>    1:     90295.074: 0.583471 0.000000 -0.299601
>    2:     88125.514: 0.286629 0.000000 -0.102261
>    3:     88067.467: 0.000000 0.000000 -0.268202
>    4:     88067.467: 0.000000 0.000000 -0.268202
>    0:     90573.744: 0.666667 0.0917234 0.000000
>    1:     90156.547: 0.577930 0.000000 -0.300638
>    2:     88068.528: 0.306034 0.000000 -0.0965273
>    3:     87975.584: 0.000000 0.000000 -0.238077
>    4:     87975.584: 0.000000 0.000000 -0.238077
>    0:     89721.612: 0.666667 0.0913660 0.000000
>    1:     89274.384: 0.577867 0.000000 -0.302115
>    2:     87025.514: 0.258058 0.000000 -0.102274
>    3:     86960.255: 0.000000 0.000000 -0.264012
>    4:     86960.255: 0.000000 0.000000 -0.264012
>    0:     89773.327: 0.666667 0.0914180 0.000000
>    1:     89431.386: 0.579968 0.000000 -0.297710
>    2:     87172.239: 0.245863 0.000000 -0.102001
>    3:     87121.156: 0.000000 0.000000 -0.244505
>    4:     87121.156: 0.000000 2.95447e-009 -0.244505
>    5:     87121.156: 0.000000 1.89955e-009 -0.244505
>    0:     91307.998: 0.666667 0.0881736 0.000000
>    1:     90963.328: 0.582168 0.000000 -0.305197
>    2:     88585.039: 0.218209 0.000000 -0.114601
>    3:     88552.517: 0.000000 0.000000 -0.232242
>    4:     88552.517: 0.000000 0.000000 -0.232242
>    0:     90098.405: 0.666667 0.0912658 0.000000
>    1:     89625.050: 0.577676 0.000000 -0.303420
>    2:     87381.866: 0.264236 0.000000 -0.102601
>    3:     87313.537: 0.000000 0.000000 -0.270530
>    4:     87313.537: 0.000000 0.000000 -0.270530
>    0:     90946.093: 0.666667 0.0900592 0.000000
>    1:     90583.090: 0.581315 0.000000 -0.300756
>    2:     88388.898: 0.278531 0.000000 -0.102687
>    3:     88324.595: 0.000000 0.000000 -0.273038
>    4:     88324.595: 0.000000 0.000000 -0.273038
>    0:     91333.939: 0.666667 0.0913058 0.000000
>    1:     90904.541: 0.577003 0.000000 -0.299602
>    2:     88679.234: 0.272647 0.000000 -0.0969097
>    3:     88596.130: 0.000000 0.000000 -0.272223
>    4:     88596.130: 0.000000 0.000000 -0.272223
>    0:     90152.037: 0.666667 0.0900727 0.000000
>    1:     89702.620: 0.575074 0.000000 -0.306728
>    2:     87596.979: 0.302713 0.000000 -0.101807
>    3:     87484.248: 0.000000 0.000000 -0.248542
>    4:     87484.248: 0.000000 0.000000 -0.248542
>    0:     91117.801: 0.666667 0.0908513 0.000000
>    1:     90757.634: 0.580554 0.000000 -0.299360
>    2:     88603.505: 0.283831 0.000000 -0.0999435
>    3:     88574.096: 0.267794 0.000000 -0.130461
>    4:     88562.206: 0.238612 0.000000 -0.148816
>    5:     88553.044: 0.208478 0.000595092 -0.132080
>    6:     88546.351: 0.181458 0.000000 -0.153290
>    7:     88542.081: 0.150185 0.000000 -0.138783
>    8:     88539.627: 0.123847 1.01894e-009 -0.161027
>    9:     88538.734: 0.0942445 0.000744265 -0.143374
>   10:     88538.275: 0.0808928 0.000000 -0.152300
>   11:     88538.188: 0.0721130 0.000000 -0.159438
>   12:     88538.184: 0.0695887 0.000000 -0.160606
>   13:     88538.183: 0.0680936 0.000000 -0.160978
>   14:     88538.183: 0.0677477 0.000000 -0.160916
>   15:     88538.183: 0.0676509 0.000000 -0.160808
>   16:     88538.183: 0.0676691 0.000000 -0.160770
>    0:     90816.807: 0.666667 0.0906318 0.000000
>    1:     90424.195: 0.578291 0.000000 -0.302393
>    2:     88300.640: 0.297094 0.000000 -0.100293
>    3:     88204.488: 0.000000 0.000000 -0.253910
>    4:     88204.488: 0.000000 0.000000 -0.253910
>    0:     91513.066: 0.666667 0.0905136 0.000000
>    1:     91059.392: 0.572808 0.000000 -0.304419
>    2:     88963.498: 0.308436 0.000000 -0.0961059
>    3:     88828.230: 0.00365434 0.000000 -0.238915
>    4:     88828.230: 0.00353298 2.48295e-007 -0.238904
>    5:     88828.228: 0.000809467 8.53595e-006 -0.238663
>    6:     88828.227: 0.000000 0.000000 -0.238628
>    7:     88828.227: 0.000000 0.000000 -0.238628
>    0:     91150.802: 0.666667 0.0891040 0.000000
>    1:     90889.912: 0.587635 0.000000 -0.295390
>    2:     88556.237: 0.240279 0.000000 -0.104882
>    3:     88549.670: 0.235780 0.000000 -0.114362
>    4:     88542.519: 0.221856 0.000000 -0.136892
>    5:     88538.276: 0.196911 0.000536413 -0.128009
>    6:     88535.760: 0.176898 0.000000 -0.145077
>    7:     88534.303: 0.157582 0.000000 -0.126956
>    8:     88533.996: 0.156218 2.29140e-010 -0.129226
>    9:     88533.534: 0.153150 3.03087e-005 -0.133544
>   10:     88532.859: 0.140751 0.000000 -0.142165
>   11:     88532.514: 0.126963 0.000000 -0.135997
>   12:     88532.299: 0.114249 0.000000 -0.140115
>   13:     88532.276: 0.109185 0.000000 -0.141707
>   14:     88532.275: 0.107867 0.000000 -0.142196
>   15:     88532.275: 0.107761 0.000000 -0.142270
>   16:     88532.275: 0.107763 2.96078e-010 -0.142274
>   17:     88532.275: 0.107767 0.000000 -0.142285
>   18:     88532.275: 0.107776 0.000000 -0.142284
>    0:     90591.670: 0.666667 0.0902163 0.000000
>    1:     90253.650: 0.582677 0.000000 -0.296733
>    2:     87913.750: 0.234039 0.000000 -0.102682
>    3:     87877.999: 0.000000 0.000000 -0.227078
>    4:     87877.999: 0.000000 0.000000 -0.227078
>    0:     90673.897: 0.666667 0.0896992 0.000000
>    1:     90337.823: 0.585673 0.000000 -0.300345
>    2:     88000.465: 0.229841 0.000000 -0.109921
>    3:     87976.655: 0.000000 0.000000 -0.229344
>    4:     87976.655: 0.000000 0.000000 -0.229344
>    0:     91695.842: 0.666667 0.0899055 0.000000
>    1:     91404.328: 0.584642 0.000000 -0.297876
>    2:     89214.414: 0.281201 0.000000 -0.102582
>    3:     89188.190: 0.265626 0.000000 -0.133284
>    4:     89178.234: 0.236801 0.000000 -0.152108
>    5:     89170.640: 0.208346 0.00119384 -0.132766
>    6:     89165.050: 0.184852 0.000000 -0.157320
>    7:     89161.506: 0.155593 0.000000 -0.139179
>    8:     89159.386: 0.133551 4.59756e-009 -0.165624
>    9:     89159.213: 0.130015 0.00119127 -0.162734
>   10:     89158.808: 0.126412 0.000000 -0.160222
>   11:     89158.328: 0.109125 0.000000 -0.154874
>   12:     89158.186: 0.0975572 0.000000 -0.168789
>   13:     89158.113: 0.0883497 0.000000 -0.164147
>   14:     89158.112: 0.0893647 3.36482e-007 -0.164147
>   15:     89158.112: 0.0894556 0.000000 -0.164102
>   16:     89158.111: 0.0901974 2.92690e-006 -0.163772
>   17:     89158.111: 0.0904597 0.000000 -0.163769
>   18:     89158.111: 0.0904597 0.000000 -0.163769
>    0:     92026.232: 0.666667 0.0894992 0.000000
>    1:     91735.788: 0.581037 0.000000 -0.298447
>    2:     89530.291: 0.274498 0.000000 -0.101211
>    3:     89465.691: 0.000000 0.000000 -0.265849
>    4:     89465.691: 0.000000 0.000000 -0.265849
>    0:     89155.666: 0.666667 0.0892915 0.000000
>    1:     88806.417: 0.582861 0.000000 -0.303162
>    2:     86512.523: 0.245630 0.000000 -0.109990
>    3:     86472.497: 0.000000 0.000000 -0.248275
>    4:     86472.497: 0.000000 0.000000 -0.248275
>    0:     91625.651: 0.666667 0.0892096 0.000000
>    1:     91305.690: 0.580685 0.000000 -0.300005
>    2:     89053.463: 0.263647 0.000000 -0.103131
>    3:     88986.561: 0.000000 0.000000 -0.261116
>    4:     88986.561: 0.000000 0.000000 -0.261116
>    0:     90869.702: 0.666667 0.0892723 0.000000
>    1:     90555.120: 0.579552 0.000000 -0.300675
>    2:     88410.128: 0.295998 0.000000 -0.100232
>    3:     88314.598: 0.000000 0.000000 -0.255183
>    4:     88314.598: 0.000000 3.86364e-009 -0.255183
>    5:     88314.598: 0.000000 3.86364e-009 -0.255183
>    0:     91108.704: 0.666667 0.0906011 0.000000
>    1:     90804.467: 0.586207 0.000000 -0.293469
>    2:     88408.714: 0.209336 0.000000 -0.104199
>    3:     88390.555: 0.000000 0.000000 -0.233786
>    4:     88390.555: 0.000000 4.74440e-009 -0.233786
>    5:     88390.555: 0.000000 4.74440e-009 -0.233786
>    0:     91771.237: 0.666667 0.0903370 0.000000
>    1:     91413.484: 0.577979 0.000000 -0.300203
>    2:     89218.035: 0.273200 0.000000 -0.100290
>    3:     89189.934: 0.254171 1.16058e-009 -0.128658
>    4:     89174.483: 0.222469 0.00144656 -0.141297
>    5:     89151.646: 0.136126 0.000000 -0.129612
>    6:     89144.537: 0.0652530 0.000000 -0.181235
>    7:     89143.147: 0.000000 0.000000 -0.132500
>    8:     89143.147: 0.000000 0.000000 -0.132500
>    0:     92075.541: 0.666667 0.0889713 0.000000
>    1:     91754.396: 0.582594 0.000000 -0.299314
>    2:     89493.502: 0.269474 0.000000 -0.102596
>    3:     89431.022: 0.000000 0.000000 -0.259856
>    4:     89431.022: 0.000000 0.000000 -0.259856
>    0:     90741.014: 0.666667 0.0910750 0.000000
>    1:     90297.019: 0.577011 0.000000 -0.305139
>    2:     88152.539: 0.285117 0.000000 -0.103300
>    3:     88068.757: 0.000000 0.000000 -0.272904
>    4:     88068.757: 0.000000 0.000000 -0.272904
>    0:     90254.977: 0.666667 0.0906367 0.000000
>    1:     89853.808: 0.580116 0.000000 -0.303049
>    2:     87726.880: 0.295568 0.000000 -0.102663
>    3:     87649.217: 0.000000 0.000000 -0.257359
>    4:     87649.217: 0.000000 0.000000 -0.257359
>    0:     90214.862: 0.666667 0.0899011 0.000000
>    1:     89935.462: 0.586403 0.000000 -0.298133
>    2:     87667.921: 0.252502 0.000000 -0.107255
>    3:     87649.405: 0.231383 0.00404239 -0.138625
>    4:     87640.356: 0.197140 0.000000 -0.132754
>    5:     87636.308: 0.171573 0.000000 -0.160910
>    6:     87633.747: 0.143169 0.000414332 -0.135621
>    7:     87631.943: 0.109135 0.00175782 -0.152542
>    8:     87631.413: 0.100984 0.000000 -0.155398
>    9:     87631.389: 0.0970080 0.000000 -0.156461
>   10:     87631.383: 0.0953971 0.000000 -0.160248
>   11:     87631.379: 0.0917818 4.22655e-005 -0.158282
>   12:     87631.379: 0.0936796 0.000000 -0.159862
>   13:     87631.378: 0.0935501 0.000000 -0.158634
>   14:     87631.377: 0.0923555 0.000000 -0.158946
>   15:     87631.377: 0.0929711 0.000000 -0.158993
>   16:     87631.377: 0.0929886 1.09932e-006 -0.158978
>    0:     90450.512: 0.666667 0.0891198 0.000000
>    1:     90145.789: 0.582078 0.000000 -0.299052
>    2:     87955.609: 0.286906 0.000000 -0.100895
>    3:     87880.498: 0.000000 0.000000 -0.267268
>    4:     87880.498: 0.000000 0.000000 -0.267268
>    0:     89654.427: 0.666667 0.0897456 0.000000
>    1:     89249.342: 0.581870 0.000000 -0.303489
>    2:     86983.487: 0.260490 0.000000 -0.107015
>    3:     86936.154: 0.000000 0.000000 -0.262106
>    4:     86936.154: 0.000000 0.000000 -0.262106
>    0:     90672.682: 0.666667 0.0899628 0.000000
>    1:     90295.782: 0.579048 0.000000 -0.302737
>    2:     88163.587: 0.295266 0.000000 -0.102005
>    3:     88073.489: 0.000000 0.000000 -0.257767
>    4:     88073.489: 0.000000 0.000000 -0.257767
>    0:     90937.235: 0.666667 0.0908255 0.000000
>    1:     90560.743: 0.576783 0.000000 -0.302200
>    2:     88512.443: 0.313763 0.000000 -0.0979954
>    3:     88397.731: 0.0116791 0.000000 -0.238082
>    4:     88397.731: 0.0116793 2.13555e-006 -0.238082
>    5:     88397.731: 0.0116802 1.58534e-006 -0.238082
>    6:     88397.707: 0.0199269 2.58593e-006 -0.240413
>    7:     88397.698: 0.0233275 1.25248e-006 -0.240845
>    8:     88397.681: 0.0360058 0.000000 -0.238725
>    9:     88397.642: 0.0377094 0.000000 -0.233764
>   10:     88397.488: 0.0443160 0.000000 -0.213853
>   11:     88397.429: 0.0505245 0.000000 -0.206634
>   12:     88397.386: 0.0624587 0.000000 -0.191795
>   13:     88397.384: 0.0605955 1.43867e-007 -0.197179
>   14:     88397.382: 0.0592088 1.94955e-008 -0.196263
>   15:     88397.382: 0.0603454 2.87004e-008 -0.195051
>   16:     88397.382: 0.0603722 3.24738e-008 -0.195107
>    0:     90982.636: 0.666667 0.0900408 0.000000
>    1:     90686.775: 0.589304 0.000000 -0.297633
>    2:     88417.031: 0.251443 0.000000 -0.107854
>    3:     88408.132: 0.000000 0.000000 -0.236649
>    4:     88408.132: 0.000000 0.000000 -0.236649
>    0:     90869.412: 0.666667 0.0910546 0.000000
>    1:     90447.155: 0.576076 0.000000 -0.301419
>    2:     88292.494: 0.290024 0.000000 -0.0973598
>    3:     88189.600: 0.000000 0.000000 -0.261628
>    4:     88189.600: 0.000000 0.000000 -0.261628
>    0:     91555.700: 0.666667 0.0894430 0.000000
>    1:     91205.211: 0.583675 0.000000 -0.300239
>    2:     88819.778: 0.217977 0.000000 -0.109167
>    3:     88792.163: 0.000000 0.000000 -0.221989
>    4:     88792.163: 0.000000 0.000000 -0.221989
>    0:     90699.353: 0.666667 0.0934181 0.000000
>    1:     90253.805: 0.585847 0.000000 -0.298291
>    2:     88159.371: 0.298780 0.000000 -0.100183
>    3:     88136.845: 0.000000 0.000000 -0.249850
>    4:     88136.845: 0.000000 0.000000 -0.249850
>    0:     91038.775: 0.666667 0.0912136 0.000000
>    1:     90656.405: 0.581786 0.000000 -0.298768
>    2:     88476.176: 0.280341 0.000000 -0.100177
>    3:     88413.623: 0.000000 0.000000 -0.270528
>    4:     88413.623: 0.000000 4.32879e-009 -0.270528
>    5:     88413.623: 0.000000 4.32879e-009 -0.270528
>    0:     90534.064: 0.666667 0.0912434 0.000000
>    1:     90158.703: 0.581799 0.000000 -0.299923
>    2:     88007.169: 0.285653 0.000000 -0.101348
>    3:     87975.548: 0.270763 9.94850e-010 -0.132543
>    4:     87963.471: 0.241261 0.00166749 -0.150478
>    5:     87955.484: 0.212149 0.000000 -0.133227
>    6:     87948.984: 0.188039 0.000000 -0.157996
>    7:     87945.106: 0.157972 2.87461e-009 -0.140942
>    8:     87942.894: 0.135918 0.000655211 -0.167551
>    9:     87942.121: 0.110783 0.000000 -0.144511
>   10:     87941.407: 0.0820679 0.000000 -0.163754
>   11:     87941.374: 0.0874460 0.000000 -0.164379
>   12:     87941.366: 0.0924083 0.000000 -0.165031
>   13:     87941.366: 0.0921629 2.75824e-006 -0.164807
>   14:     87941.365: 0.0918365 0.000000 -0.164754
>   15:     87941.365: 0.0918121 1.05293e-009 -0.164776
>   16:     87941.365: 0.0916407 1.25385e-007 -0.164902
>   17:     87941.365: 0.0916280 0.000000 -0.164885
>   18:     87941.365: 0.0915976 1.78900e-007 -0.164855
>   19:     87941.365: 0.0915710 0.000000 -0.164868
>   20:     87941.365: 0.0915709 6.77374e-008 -0.164868
>   21:     87941.365: 0.0915707 0.000000 -0.164868
>   22:     87941.365: 0.0915706 0.000000 -0.164869
>   23:     87941.365: 0.0915706 0.000000 -0.164869
>    0:     90538.952: 0.666667 0.0906664 0.000000
>    1:     90188.780: 0.580152 0.000000 -0.298077
>    2:     87995.424: 0.280946 0.000000 -0.0982630
>    3:     87965.709: 0.263221 1.10254e-009 -0.127679
>    4:     87950.953: 0.232057 0.00156023 -0.142027
>    5:     87932.225: 0.160075 0.000000 -0.123961
>    6:     87924.828: 0.107481 0.000000 -0.177222
>    7:     87923.913: 0.101794 1.32194e-009 -0.172355
>    8:     87922.762: 0.0898806 0.000000 -0.163290
>    9:     87922.603: 0.0870883 2.97543e-007 -0.162210
>   10:     87921.808: 0.0643480 0.000000 -0.154688
>   11:     87921.756: 0.0619822 1.91616e-007 -0.155062
>   12:     87921.461: 0.0430376 0.000000 -0.157938
>   13:     87921.329: 0.0246316 0.000000 -0.160343
>   14:     87921.290: 0.0115580 0.000000 -0.161904
>   15:     87921.281: 0.00286298 0.000000 -0.162911
>   16:     87921.281: 0.00189741 3.55755e-005 -0.162906
>   17:     87921.280: 0.000934638 0.000000 -0.162938
>   18:     87921.280: 0.000000 0.000000 -0.162968
>   19:     87921.280: 0.000000 0.000000 -0.162968
>    0:     89913.444: 0.666667 0.0906915 0.000000
>    1:     89490.109: 0.578190 0.000000 -0.300666
>    2:     87265.611: 0.273646 0.000000 -0.0992267
>    3:     87184.839: 0.000000 0.000000 -0.273871
>    4:     87184.839: 0.000000 0.000000 -0.273871
>    0:     91445.647: 0.666667 0.0887779 0.000000
>    1:     91205.368: 0.586436 0.000000 -0.295702
>    2:     88923.840: 0.258811 0.000000 -0.103445
>    3:     88907.893: 0.242519 0.000000 -0.128815
>    4:     88901.918: 0.218662 0.000000 -0.147252
>    5:     88895.042: 0.195226 0.000965137 -0.128307
>    6:     88890.006: 0.169408 0.000000 -0.143102
>    7:     88886.667: 0.140591 0.000000 -0.134234
>    8:     88884.703: 0.113739 4.18354e-009 -0.147949
>    9:     88883.819: 0.0890199 0.000000 -0.150225
>   10:     88883.509: 0.0702513 0.000000 -0.151673
>   11:     88883.409: 0.0564583 0.000000 -0.152518
>   12:     88883.380: 0.0469538 0.000000 -0.152913
>   13:     88883.374: 0.0411088 0.000000 -0.152998
>   14:     88883.372: 0.0382539 0.000000 -0.152898
>   15:     88883.372: 0.0371689 0.000000 -0.152722
>   16:     88883.372: 0.0365899 0.000000 -0.152428
>   17:     88883.372: 0.0362285 0.000000 -0.151744
>   18:     88883.371: 0.0366140 0.000000 -0.150915
>   19:     88883.371: 0.0373644 0.000000 -0.150538
>   20:     88883.371: 0.0373648 4.72818e-007 -0.150539
>   21:     88883.371: 0.0375860 0.000000 -0.150728
>   22:     88883.371: 0.0378454 0.000000 -0.150594
> Warning messages:
> 1: In mer_finalize(ans) : false convergence (8)
> 2: In mer_finalize(ans) : singular convergence (7)
> 3: In mer_finalize(ans) : singular convergence (7)
> 4: In mer_finalize(ans) : false convergence (8)
> 5: In mer_finalize(ans) : false convergence (8)
>>        print(pool(Uncpde.math.f.mi))
> Call: pool(object = Uncpde.math.f.mi)
>
> Pooled coefficients:
>    (Intercept) index
>     1.90889735    0.02891385
>
> Fraction of information about the coefficients missing due to nonresponse:
>    (Intercept) index
>      0.9464698     0.9361655
>>        round(summary(pool(Uncpde.math.f.mi)), 2)
>                 est   se    t    df Pr(>|t|) lo 95 hi 95  nmis  fmi lambda
> (Intercept)   1.91 0.27 6.98 49.87      0.0  1.36  2.46    NA 0.95   0.94
> index 0.03 0.03 0.85 51.68      0.4 -0.04  0.10 11776 0.94   0.93
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From 538280 at gmail.com  Sat Jun 30 20:05:11 2012
From: 538280 at gmail.com (Greg Snow)
Date: Sat, 30 Jun 2012 12:05:11 -0600
Subject: [R-sig-ME] Help needed: Fitting and Simulating multilevel model
 in R.
In-Reply-To: <1341059795.30406.YahooMailNeo@web113408.mail.gq1.yahoo.com>
References: <1341059795.30406.YahooMailNeo@web113408.mail.gq1.yahoo.com>
Message-ID: <CAFEqCdy=L_ezVQ4ozjtfoCHn7cDXytOeHuX9avUAm5qx80+OFQ@mail.gmail.com>

The version of the TeachingDemos package that is on R-forge (not the
CRAN version yet) has a function called "simfun" that could be helpful
in setting up the simulation.  You can get the R-forge version with
the command: install.packages("TeachingDemos", repos=
c("http://R-Forge.R-project.org", getOption("repos")))

Look through the help for "simfun" to see how to use it and ideas for
simulating with it.

For doing the analysis you can use the lme4 package (others as well,
but that is one place to start).

On Sat, Jun 30, 2012 at 6:36 AM, Justice Moses K. Aheto
<justiceaheto at yahoo.com> wrote:
> Dear All,
> I am a new R user but currently working on my dissertation which request that I fit multilevel model to a given situation that can be located below and then simulate the fitted model 10000 times.
>
> Set up a simulation model according to the following recipe in R:
> n=number of observation=1000,
> xi~N(0,1), is a predictor.
> Wi~N(0,1), links to birth weight.
> Ni~Poisson(mean=variance=2), number of children per woman.
> Vij~N(0,1), child predictor
> Zij~N(0,1), is an error term.
> Yij(birthweight)=a+bxi+cvij+d(?wi+(?1-?2)zij)
> Where,
> a=3.1, b=0.2, c=0.3, d=0.3, ?=(0,1)
> Note: use the interval for ? on 0, 0.01, 0.02, 0.03, ?0.99, 1)
> 1)      Fit multilevel model for the above.
> 2)      Calculate the standard errors of the estimates, t-values, p-values and store them.
> 3)      Run this recipe 10000 times in a loop.
> 4)      How many times is p-value<0.05
> 5)      How does this vary according to ??
>
> I am available to provide further clarification on the task should you request for.
> Could someone help me in this regards.
> I do appreciate any assistance given me.
> Many thanks in advance.
>
>
> Kind regards.
>
> Justice Moses K. Aheto
> (Chief Executive Officer)
> Statistics & Analytics Consultancy Services Ltd.
> E-mail: justiceaheto at yahoo.com
> Mobile:00447417589148
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From justiceaheto at yahoo.com  Sat Jun 30 21:05:17 2012
From: justiceaheto at yahoo.com (Justice Moses K. Aheto)
Date: Sat, 30 Jun 2012 12:05:17 -0700 (PDT)
Subject: [R-sig-ME] Help needed: Fitting and Simulating multilevel model
	in R.
In-Reply-To: <CAFEqCdy=L_ezVQ4ozjtfoCHn7cDXytOeHuX9avUAm5qx80+OFQ@mail.gmail.com>
References: <1341059795.30406.YahooMailNeo@web113408.mail.gq1.yahoo.com>
	<CAFEqCdy=L_ezVQ4ozjtfoCHn7cDXytOeHuX9avUAm5qx80+OFQ@mail.gmail.com>
Message-ID: <1341083117.71014.YahooMailNeo@web113414.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120630/357c317d/attachment.pl>

From jwiley.psych at gmail.com  Sat Jun 30 21:14:37 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 30 Jun 2012 12:14:37 -0700
Subject: [R-sig-ME] Help needed: Fitting and Simulating multilevel model
 in R.
In-Reply-To: <1341083117.71014.YahooMailNeo@web113414.mail.gq1.yahoo.com>
References: <1341059795.30406.YahooMailNeo@web113408.mail.gq1.yahoo.com>
	<CAFEqCdy=L_ezVQ4ozjtfoCHn7cDXytOeHuX9avUAm5qx80+OFQ@mail.gmail.com>
	<1341083117.71014.YahooMailNeo@web113414.mail.gq1.yahoo.com>
Message-ID: <CANz9Z_KgrFg77WM9G306Hph166H=d7-wzcfWppZTH=U4r09EMg@mail.gmail.com>

Hi Justice,

If this is for your dissertation, why not take the opportunity to
learn how to use R?  If you want someone else to figure out how to do
it on your behalf or just provide the solutions, how much are you
offering to pay as a reward?

If you want to learn how to do it on your own, you may also check out
this page I wrote, which is basically just the code for a multilevel
dataset I simulated.  I was not doing it many times, because my goal
there was just to have a dataset for demonstrative purposes at the
consulting office where I work.  Nevertheless, I created various
(normal, count, binary) outcomes, and fit mixed effects models
accordingly using the lme4 package, so it may help you.

http://www.ats.ucla.edu/stat/r/pages/mesimulation.htm

Again, I think if you just want the solution to be given you, you will
probably need to hire someone.

Cheers,

Josh


On Sat, Jun 30, 2012 at 12:05 PM, Justice Moses K. Aheto
<justiceaheto at yahoo.com> wrote:
> Hi Greg,?Raquel?and All,
> Many thanks for the help so far but I am very new to R and can hardly fit the model with those recipe given in my problem.
> I can fit multilevel models using the raw data in R but not as given me in this case and that really is my major problem.
> Also, I can simulate simple linear regression model from normal distribution in R but not as above.
> I will try to read on what Greg suggested and see if I can understand anything from there.
> I am really in need of someone to provide me with the solutions and I am happy to see?Raquel trying to figure things out on my behalf.
> Thanks to everyone so far trying hard to help me out of this and I do appreciate that effort.
> Best regards.
>
>
> Kind regards.
>
>
>
> Justice Moses K. Aheto
> (Chief Executive Officer)
> Statistics & Analytics Consultancy Services Ltd.
> E-mail: justiceaheto at yahoo.com
> Mobile:00447417589148
>
>
>
>>________________________________
>> From: Greg Snow <538280 at gmail.com>
>>To: Justice Moses K. Aheto <justiceaheto at yahoo.com>
>>Cc: R EXPERTS USA <r-sig-mixed-models at r-project.org>
>>Sent: Saturday, June 30, 2012 7:05 PM
>>Subject: Re: [R-sig-ME] Help needed: Fitting and Simulating multilevel model in R.
>>
>>The version of the TeachingDemos package that is on R-forge (not the
>>CRAN version yet) has a function called "simfun" that could be helpful
>>in setting up the simulation.? You can get the R-forge version with
>>the command: install.packages("TeachingDemos", repos=
>>c("http://R-Forge.R-project.org", getOption("repos")))
>>
>>Look through the help for "simfun" to see how to use it and ideas for
>>simulating with it.
>>
>>For doing the analysis you can use the lme4 package (others as well,
>>but that is one place to start).
>>
>>On Sat, Jun 30, 2012 at 6:36 AM, Justice Moses K. Aheto
>><justiceaheto at yahoo.com> wrote:
>>> Dear All,
>>> I am a new R user but currently working on my dissertation which request that I fit multilevel model to a given situation that can be located below and then simulate the fitted model 10000 times.
>>>
>>> Set up a simulation model according to the following recipe in R:
>>> n=number of observation=1000,
>>> xi~N(0,1), is a predictor.
>>> Wi~N(0,1), links to birth weight.
>>> Ni~Poisson(mean=variance=2), number of children per woman.
>>> Vij~N(0,1), child predictor
>>> Zij~N(0,1), is an error term.
>>> Yij(birthweight)=a+bxi+cvij+d(?wi+(?1-?2)zij)
>>> Where,
>>> a=3.1, b=0.2, c=0.3, d=0.3, ?=(0,1)
>>> Note: use the interval for ? on 0, 0.01, 0.02, 0.03, ?0.99, 1)
>>> 1)? ? ? Fit multilevel model for the above.
>>> 2)? ? ? Calculate the standard errors of the estimates, t-values, p-values and store them.
>>> 3)? ? ? Run this recipe 10000 times in a loop.
>>> 4)? ? ? How many times is p-value<0.05
>>> 5)? ? ? How does this vary according to ??
>>>
>>> I am available to provide further clarification on the task should you request for.
>>> Could someone help me in this regards.
>>> I do appreciate any assistance given me.
>>> Many thanks in advance.
>>>
>>>
>>> Kind regards.
>>>
>>> Justice Moses K. Aheto
>>> (Chief Executive Officer)
>>> Statistics & Analytics Consultancy Services Ltd.
>>> E-mail: justiceaheto at yahoo.com
>>> Mobile:00447417589148
>>>? ? ? ? ?[[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>>--
>>Gregory (Greg) L. Snow Ph.D.
>>538280 at gmail.com
>>
>>
>>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From pdalgd at gmail.com  Sat Jun 30 21:22:48 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 30 Jun 2012 21:22:48 +0200
Subject: [R-sig-ME] "mixed" MANOVAs
In-Reply-To: <1340989717.33487.YahooMailNeo@web29701.mail.ird.yahoo.com>
References: <1340989717.33487.YahooMailNeo@web29701.mail.ird.yahoo.com>
Message-ID: <8BBF49B5-97A2-4A9B-9E96-9463F98226B3@gmail.com>


On Jun 29, 2012, at 19:08 , Andr?s Egea wrote:

> Dear all:
> 
> 
> I need to perform a MANOVA including both fixed and random factors. I know to run a traditional MANOVA (i.e., all factors are fixed) and even a MANCOVA (it seems that manova() function admits covariates), but not how to include random factors. Somewhere I read that MANOVA does not admit random factors, although I have no clue on the reason. Is it that true?

Well, according to ?manova, 

    ?manova? does not support multistratum analysis of variance, so
     the formula should not include an ?Error? term.

There is no specific reason that it cannot work (for balanced error designs, but that's true for aov as well) other than the fact that noone has implemented it. (It's what some sarcastically call a SMOP -- Simple Matter of Programming...)

And true enough, if you try:

> example(aov)
> npk$foo <- rnorm(24)
> m <- manova(cbind(yield,foo) ~  N*P*K + Error(block), npk)
Warning message:
In aov(cbind(yield, foo) ~ N * P * K + Error(block), npk) :
  Error() model is singular

or:

> m <-  aov(cbind(yield,foo) ~  N*P*K + Error(block), npk)
Warning message:
In aov(cbind(yield, foo) ~ N * P * K + Error(block), npk) :
  Error() model is singular

(The two do basically the same thing, manova() does little more than adding an extra class to the result.)

The warning is a bit obscure; it probably just means that something inside aov() didn't expect a matrix response. 


HOWEVER, it turns out that aov has done all the right calculations!!! The result (in m) is composed of a list of objects of class "mlm", for which anova.mlm (which didn't exist at the time manova() was written) knows how do the right thing:

> lapply(m[-1],anova)
$block
Analysis of Variance Table

          Df  Pillai approx F num Df den Df Pr(>F)
N:P:K      1 0.38534  0.94038      2      3 0.4819
Residuals  4                                      

$Within
Analysis of Variance Table

          Df  Pillai approx F num Df den Df   Pr(>F)   
N          1 0.58359   7.7083      2     11 0.008079 **
P          1 0.04395   0.2528      2     11 0.781005   
K          1 0.44757   4.4560      2     11 0.038241 * 
N:P        1 0.21078   1.4689      2     11 0.272010   
N:K        1 0.15182   0.9845      2     11 0.404269   
P:K        1 0.30928   2.4627      2     11 0.130665   
Residuals 12                                           
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

And lo and behold:

> m <- manova(cbind(yield,foo) ~  N*P*K + Error(block), npk)
Warning message:
In aov(cbind(yield, foo) ~ N * P * K + Error(block), npk) :
  Error() model is singular
> summary(m)

Error: block
          Df  Pillai approx F num Df den Df Pr(>F)
N:P:K      1 0.38534  0.94038      2      3 0.4819
Residuals  4                                      

Error: Within
          Df  Pillai approx F num Df den Df   Pr(>F)   
N          1 0.58359   7.7083      2     11 0.008079 **
P          1 0.04395   0.2528      2     11 0.781005   
K          1 0.44757   4.4560      2     11 0.038241 * 
N:P        1 0.21078   1.4689      2     11 0.272010   
N:K        1 0.15182   0.9845      2     11 0.404269   
P:K        1 0.30928   2.4627      2     11 0.130665   
Residuals 12                                           
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 


So it seems that things are pretty darn close to actually just working. 

One caveat: I am pretty sure that the above results are more than superficially sane, but I haven't actually checked. For good measure, if you have a textbook MANOVA example, perhaps you should try that first and see if you can reproduce its test statistics.

-pd


> Anyway, could you tell a way (either the suitable package or even the script) to run MANOVAs with both fixed and random factors, please? My database is balanced. 
> 
> Any assisstance I can get will be greatly appreciated. Thank you very much in advance for your help.
> 
> Looking forward to hearing from you, sincerely,
> Andr?s Egea
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From justiceaheto at yahoo.com  Sat Jun 30 21:31:59 2012
From: justiceaheto at yahoo.com (Justice Moses K. Aheto)
Date: Sat, 30 Jun 2012 12:31:59 -0700 (PDT)
Subject: [R-sig-ME] Help needed: Fitting and Simulating multilevel model
	in R.
In-Reply-To: <CANz9Z_KgrFg77WM9G306Hph166H=d7-wzcfWppZTH=U4r09EMg@mail.gmail.com>
References: <1341059795.30406.YahooMailNeo@web113408.mail.gq1.yahoo.com>
	<CAFEqCdy=L_ezVQ4ozjtfoCHn7cDXytOeHuX9avUAm5qx80+OFQ@mail.gmail.com>
	<1341083117.71014.YahooMailNeo@web113414.mail.gq1.yahoo.com>
	<CANz9Z_KgrFg77WM9G306Hph166H=d7-wzcfWppZTH=U4r09EMg@mail.gmail.com>
Message-ID: <1341084719.32669.YahooMailNeo@web113404.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20120630/9af29ee6/attachment.pl>

