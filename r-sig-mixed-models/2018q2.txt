From jrosen at msu.edu  Sun Apr  1 14:55:34 2018
From: jrosen at msu.edu (Joshua Rosenberg)
Date: Sun, 01 Apr 2018 12:55:34 +0000
Subject: [R-sig-ME] High correlation among random effects for longitudinal
 model
Message-ID: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>

Hi R-sig-mixed-models, I am using the nlme package (and lme() function) to
estimate a longitudinal model for ~ 270 individuals over five time points.
Descriptively, the data seems to take a quadratic form, so I fit a model
like the following:

lme(outcome ~ time + I(time^2),
    random = ~ time + I(time^2),
    correlation = corAR1(form = ~ time | individual_ID),
    data = d_grouped)

I have a question / concerns about the random effects, as they are highly
correlated (intercept and linear term = -.95; intercept and quadratic term
= .96; linear term and quadratic term = -.995):

Random effects:
 Formula: ~time + I(time^2) | individual_ID
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr
(Intercept) 34.836512 (Intr) time
time        39.803783 -0.959
I(time^2)    8.342256  0.969 -0.995
Residual    28.920368

Is this a concern in terms of interpreting the model? Is this a concern
technically in terms of how the model is specified?

Thank you for pointing me in the right direction. Happy to answer any
follow-up questions or to share additional details and information.


Josh

-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From lupp at uchicago.edu  Sun Apr  1 18:20:52 2018
From: lupp at uchicago.edu (Stuart Luppescu)
Date: Sun, 01 Apr 2018 12:20:52 -0400
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
Message-ID: <1522599652.9262.10.camel@uchicago.edu>

On Sun, 2018-04-01 at 12:55 +0000, Joshua Rosenberg wrote:
> lme(outcome ~ time + I(time^2),
>     random = ~ time + I(time^2),
>     correlation = corAR1(form = ~ time | individual_ID),
>     data = d_grouped)
> 
> I have a question / concerns about the random effects, as they are
> highly
> correlated (intercept and linear term = -.95; intercept and quadratic
> term
> = .96; linear term and quadratic term = -.995):

I think this is an ordinary occurrence for the intercept and time trend
to be negatively correlated. The way to avoid this is to center the
time variable at a point in the middle of the series, so, instead of
setting the values of time to {0, 1, 2, 3, 4} use {-2, -1, 0, 1, 2}.

-- 
Stuart Luppescu
Chief Psychometrician (ret.)
UChicago Consortium on School Research
http://consortium.uchicago.edu


From bbolker at gmail.com  Sun Apr  1 18:34:35 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 1 Apr 2018 12:34:35 -0400
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <1522599652.9262.10.camel@uchicago.edu>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
 <1522599652.9262.10.camel@uchicago.edu>
Message-ID: <CABghstTvB+97Hkn2r2g3GbMzqG3NBkj4DkbZGp9T5EhO82qF_w@mail.gmail.com>

On Sun, Apr 1, 2018 at 12:20 PM, Stuart Luppescu <lupp at uchicago.edu> wrote:
> On Sun, 2018-04-01 at 12:55 +0000, Joshua Rosenberg wrote:
>> lme(outcome ~ time + I(time^2),
>>     random = ~ time + I(time^2),
>>     correlation = corAR1(form = ~ time | individual_ID),
>>     data = d_grouped)
>>
>> I have a question / concerns about the random effects, as they are
>> highly
>> correlated (intercept and linear term = -.95; intercept and quadratic
>> term
>> = .96; linear term and quadratic term = -.995):
>
> I think this is an ordinary occurrence for the intercept and time trend
> to be negatively correlated. The way to avoid this is to center the
> time variable at a point in the middle of the series, so, instead of
> setting the values of time to {0, 1, 2, 3, 4} use {-2, -1, 0, 1, 2}.
>

  Agreed.  This is closely related, but not identical to, the
phenomenon where the
*fixed effects* are highly correlated.

> --
> Stuart Luppescu
> Chief Psychometrician (ret.)
> UChicago Consortium on School Research
> http://consortium.uchicago.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From kevin.thorpe at utoronto.ca  Sun Apr  1 19:14:16 2018
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Sun, 1 Apr 2018 13:14:16 -0400
Subject: [R-sig-ME] geometric mean regression
In-Reply-To: <000801d3c940$d532ea10$7f98be30$@tpg.com.au>
References: <001201d3c758$ff12d4b0$fd387e10$@tpg.com.au>
 <7ccf5879-92d1-c01a-5397-f782f0503329@utoronto.ca>
 <000801d3c940$d532ea10$7f98be30$@tpg.com.au>
Message-ID: <bd0017d4-17b5-be6e-f7d0-0a32979a9fa1@utoronto.ca>

Back transformation can be tricky. You should also look at smearing 
estimators. The package Hmisc has a function called smearingEst() that 
you might like to check.

Kevin

On 03/31/2018 06:37 PM, Ahmad wrote:
> Hi Kevin
> 
> Thanks for your email,
> Yes, I almost figured out how get this done. I needed to get the exp() of intercept for the reference group and exp() of coefficient*exp(intercept) for the other group.
> 
> When I was trying this for geometric of 95%CI, the results don't seem quite right. I found an article that if I get the exp() of lsmeans (emmeans) these will produce the correct geometric outputs. Not sure why when I do these manually using the exp() of intercept and coefficient of lm- the outputs are not identical, but close enough.
> 
> Ahmad
>       
> 
> -----Original Message-----
> From: Kevin E. Thorpe <kevin.thorpe at utoronto.ca>
> Sent: Sunday, 1 April 2018 12:22 AM
> To: Ahmad <ahmadr215 at tpg.com.au>
> Subject: Re: [R-sig-ME] geometric mean regression
> 
> Maybe I'm missing something, but doesn't linear regression on log(y) accomplish this?
> 
> Kevin
> 
> On 03/29/2018 08:25 AM, Ahmad wrote:
>> Hi All
>>
>>    
>>
>> I have a dataset and I have been asked to generate geometric means
>> from the linear regression for different groups (2 groups).
>>
>> In fact my data is repeated measures, and I intend to use a
>> mixed-effects regression model with repeated measures. But I thought I
>> can learn how to do this for a simple geometric mean regression, I
>> should be able to translate this into a mixed model.
>>
>>    
>>
>> Any help would be greatly appreciated!
>>
>>    
>>
>> Thanks
>>
>>    
>>
>> Ahmad
>>
>>    


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From tim.cole at ucl.ac.uk  Mon Apr  2 12:45:18 2018
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Mon, 2 Apr 2018 10:45:18 +0000
Subject: [R-sig-ME] geometric mean regression
Message-ID: <2912C755-2201-45BA-80E6-DCFE64C85041@ucl.ac.uk>

Hi Kevin and Ahmad,

Back transformation is not tricky on the natural log scale. Just multiply the coefficients by 100 and view them as differences in percentage units ? see https://doi.org/10.1136/bmj.j3683s .

Best wishes,
Tim
--
?mailto:tim.cole at ucl.ac.uk?Phone 020 7905 2666
Population Policy and Practice Programme
UCL Great Ormond Street Institute of Child Health, 
30 Guilford Street, London WC1N 1EH, UK

Date: Sun, 1 Apr 2018 13:14:16 -0400
From: "Kevin E. Thorpe" <mailto:kevin.thorpe at utoronto.ca>
To: Ahmad <mailto:ahmadr215 at tpg.com.au>
Cc: <mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] geometric mean regression
Message-ID: <mailto:bd0017d4-17b5-be6e-f7d0-0a32979a9fa1 at utoronto.ca>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

Back transformation can be tricky. You should also look at smearing 
estimators. The package Hmisc has a function called smearingEst() that 
you might like to check.

Kevin

On 03/31/2018 06:37 PM, Ahmad wrote:
Hi Kevin
Thanks for your email,
Yes, I almost figured out how get this done. I needed to get the exp() of intercept for the reference group and exp() of coefficient*exp(intercept) for the other group.
When I was trying this for geometric of 95%CI, the results don't seem quite right. I found an article that if I get the exp() of lsmeans (emmeans) these will produce the correct geometric outputs. Not sure why when I do these manually using the exp() of intercept and coefficient of lm- the outputs are not identical, but close enough.
Ahmad
?????? 
-----Original Message-----
From: Kevin E. Thorpe <mailto:kevin.thorpe at utoronto.ca>
Sent: Sunday, 1 April 2018 12:22 AM
To: Ahmad <mailto:ahmadr215 at tpg.com.au>
Subject: Re: [R-sig-ME] geometric mean regression
Maybe I'm missing something, but doesn't linear regression on log(y) accomplish this?
Kevin
On 03/29/2018 08:25 AM, Ahmad wrote:
Hi All

I have a dataset and I have been asked to generate geometric means
from the linear regression for different groups (2 groups).

In fact my data is repeated measures, and I intend to use a
mixed-effects regression model with repeated measures. But I thought I
can learn how to do this for a simple geometric mean regression, I
should be able to translate this into a mixed model.

Any help would be greatly appreciated!

Thanks

Ahmad



From ahmadr215 at tpg.com.au  Mon Apr  2 13:12:51 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Mon, 2 Apr 2018 21:12:51 +1000
Subject: [R-sig-ME] geometric mean regression
In-Reply-To: <2912C755-2201-45BA-80E6-DCFE64C85041@ucl.ac.uk>
References: <2912C755-2201-45BA-80E6-DCFE64C85041@ucl.ac.uk>
Message-ID: <000601d3ca73$8cf0fdd0$a6d2f970$@tpg.com.au>

Hi Kevin and Tim

Thanks for your comments, I will check these out.

Ahmad


-----Original Message-----
From: Cole, Tim <tim.cole at ucl.ac.uk> 
Sent: Monday, 2 April 2018 8:45 PM
To: Ahmad <ahmadr215 at tpg.com.au>; Kevin E. Thorpe <kevin.thorpe at utoronto.ca>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] geometric mean regression

Hi Kevin and Ahmad,

Back transformation is not tricky on the natural log scale. Just multiply the coefficients by 100 and view them as differences in percentage units ? see https://doi.org/10.1136/bmj.j3683s .

Best wishes,
Tim
--
 mailto:tim.cole at ucl.ac.uk Phone 020 7905 2666 Population Policy and Practice Programme UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK

Date: Sun, 1 Apr 2018 13:14:16 -0400
From: "Kevin E. Thorpe" <mailto:kevin.thorpe at utoronto.ca>
To: Ahmad <mailto:ahmadr215 at tpg.com.au>
Cc: <mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] geometric mean regression
Message-ID: <mailto:bd0017d4-17b5-be6e-f7d0-0a32979a9fa1 at utoronto.ca>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

Back transformation can be tricky. You should also look at smearing estimators. The package Hmisc has a function called smearingEst() that you might like to check.

Kevin

On 03/31/2018 06:37 PM, Ahmad wrote:
Hi Kevin
Thanks for your email,
Yes, I almost figured out how get this done. I needed to get the exp() of intercept for the reference group and exp() of coefficient*exp(intercept) for the other group.
When I was trying this for geometric of 95%CI, the results don't seem quite right. I found an article that if I get the exp() of lsmeans (emmeans) these will produce the correct geometric outputs. Not sure why when I do these manually using the exp() of intercept and coefficient of lm- the outputs are not identical, but close enough.
Ahmad
       
-----Original Message-----
From: Kevin E. Thorpe <mailto:kevin.thorpe at utoronto.ca>
Sent: Sunday, 1 April 2018 12:22 AM
To: Ahmad <mailto:ahmadr215 at tpg.com.au>
Subject: Re: [R-sig-ME] geometric mean regression Maybe I'm missing something, but doesn't linear regression on log(y) accomplish this?
Kevin
On 03/29/2018 08:25 AM, Ahmad wrote:
Hi All

I have a dataset and I have been asked to generate geometric means from the linear regression for different groups (2 groups).

In fact my data is repeated measures, and I intend to use a mixed-effects regression model with repeated measures. But I thought I can learn how to do this for a simple geometric mean regression, I should be able to translate this into a mixed model.

Any help would be greatly appreciated!

Thanks

Ahmad


From ahmadr215 at tpg.com.au  Mon Apr  2 13:20:46 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Mon, 2 Apr 2018 21:20:46 +1000
Subject: [R-sig-ME] geometric mean regression
In-Reply-To: <2912C755-2201-45BA-80E6-DCFE64C85041@ucl.ac.uk>
References: <2912C755-2201-45BA-80E6-DCFE64C85041@ucl.ac.uk>
Message-ID: <000701d3ca74$a6a366e0$f3ea34a0$@tpg.com.au>

Kevin

I forgot to say that my data are on natural log scale- and I agree with x100 if we want see the difference in %.
This is a work for a Pharma company, they are interested in geometric means rather than arithmetic means (because data is not normally distributed).  

Ahmad
 

-----Original Message-----
From: Cole, Tim <tim.cole at ucl.ac.uk> 
Sent: Monday, 2 April 2018 8:45 PM
To: Ahmad <ahmadr215 at tpg.com.au>; Kevin E. Thorpe <kevin.thorpe at utoronto.ca>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] geometric mean regression

Hi Kevin and Ahmad,

Back transformation is not tricky on the natural log scale. Just multiply the coefficients by 100 and view them as differences in percentage units ? see https://doi.org/10.1136/bmj.j3683s .

Best wishes,
Tim
--
 mailto:tim.cole at ucl.ac.uk Phone 020 7905 2666 Population Policy and Practice Programme UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK

Date: Sun, 1 Apr 2018 13:14:16 -0400
From: "Kevin E. Thorpe" <mailto:kevin.thorpe at utoronto.ca>
To: Ahmad <mailto:ahmadr215 at tpg.com.au>
Cc: <mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] geometric mean regression
Message-ID: <mailto:bd0017d4-17b5-be6e-f7d0-0a32979a9fa1 at utoronto.ca>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

Back transformation can be tricky. You should also look at smearing estimators. The package Hmisc has a function called smearingEst() that you might like to check.

Kevin

On 03/31/2018 06:37 PM, Ahmad wrote:
Hi Kevin
Thanks for your email,
Yes, I almost figured out how get this done. I needed to get the exp() of intercept for the reference group and exp() of coefficient*exp(intercept) for the other group.
When I was trying this for geometric of 95%CI, the results don't seem quite right. I found an article that if I get the exp() of lsmeans (emmeans) these will produce the correct geometric outputs. Not sure why when I do these manually using the exp() of intercept and coefficient of lm- the outputs are not identical, but close enough.
Ahmad
       
-----Original Message-----
From: Kevin E. Thorpe <mailto:kevin.thorpe at utoronto.ca>
Sent: Sunday, 1 April 2018 12:22 AM
To: Ahmad <mailto:ahmadr215 at tpg.com.au>
Subject: Re: [R-sig-ME] geometric mean regression Maybe I'm missing something, but doesn't linear regression on log(y) accomplish this?
Kevin
On 03/29/2018 08:25 AM, Ahmad wrote:
Hi All

I have a dataset and I have been asked to generate geometric means from the linear regression for different groups (2 groups).

In fact my data is repeated measures, and I intend to use a mixed-effects regression model with repeated measures. But I thought I can learn how to do this for a simple geometric mean regression, I should be able to translate this into a mixed model.

Any help would be greatly appreciated!

Thanks

Ahmad


From bbolker at gmail.com  Mon Apr  2 23:41:00 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Apr 2018 17:41:00 -0400
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <CANYHYTSr3cAMZW3xu4pOCJ99k1xQEvQprFiPNKa+jHdbaDMoDw@mail.gmail.com>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
 <1522599652.9262.10.camel@uchicago.edu>
 <CABghstTvB+97Hkn2r2g3GbMzqG3NBkj4DkbZGp9T5EhO82qF_w@mail.gmail.com>
 <CANYHYTSr3cAMZW3xu4pOCJ99k1xQEvQprFiPNKa+jHdbaDMoDw@mail.gmail.com>
Message-ID: <3303e9df-cee8-d984-0b3a-198adec715c5@gmail.com>


  It's not much of a concern (in my book).

  You could use poly(time,degree=2) (instead of (1 + ) time + I(time^2))
to construct orthogonal polynomials ...

On 18-04-02 05:32 PM, Joshua Rosenberg wrote:
> Dear Stuart and Ben,
> 
> Thank you, this worked to significantly reduce the correlations between
> the intercept and the linear and quadratic terms (though still quite
> high between the linear and quadratic term):
> 
> Random effects:
> ?Formula: ~time + I(time^2) | student_ID
> ?Structure: General positive-definite, Log-Cholesky parametrization
> ? ? ? ? ? ? StdDev? ? Corr? ? ? ? ?
> (Intercept) 18.671959 (Intr) time??
> time? ? ? ? 11.029842 -0.262? ? ? ?
> I(time^2)? ? 8.359834 -0.506? 0.959
> Residual? ? 29.006598? ? ? ? ? ? ??
> 
> Could I ask if that correlation between the linear (time) and
> quadratic?I(time^2)?terms is cause for concern - and if so, how to think
> about (potentially) addressing this?
> Josh
> 
> On Sun, Apr 1, 2018 at 12:34 PM Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>     On Sun, Apr 1, 2018 at 12:20 PM, Stuart Luppescu <lupp at uchicago.edu
>     <mailto:lupp at uchicago.edu>> wrote:
>     > On Sun, 2018-04-01 at 12:55 +0000, Joshua Rosenberg wrote:
>     >> lme(outcome ~ time + I(time^2),
>     >>? ? ?random = ~ time + I(time^2),
>     >>? ? ?correlation = corAR1(form = ~ time | individual_ID),
>     >>? ? ?data = d_grouped)
>     >>
>     >> I have a question / concerns about the random effects, as they are
>     >> highly
>     >> correlated (intercept and linear term = -.95; intercept and quadratic
>     >> term
>     >> = .96; linear term and quadratic term = -.995):
>     >
>     > I think this is an ordinary occurrence for the intercept and time
>     trend
>     > to be negatively correlated. The way to avoid this is to center the
>     > time variable at a point in the middle of the series, so, instead of
>     > setting the values of time to {0, 1, 2, 3, 4} use {-2, -1, 0, 1, 2}.
>     >
> 
>     ? Agreed.? This is closely related, but not identical to, the
>     phenomenon where the
>     *fixed effects* are highly correlated.
> 
>     > --
>     > Stuart Luppescu
>     > Chief Psychometrician (ret.)
>     > UChicago Consortium on School Research
>     > http://consortium.uchicago.edu
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -- 
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology ?&? Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com <http://jmichaelrosenberg.com/>


From russell-lenth at uiowa.edu  Tue Apr  3 00:16:55 2018
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Mon, 2 Apr 2018 22:16:55 +0000
Subject: [R-sig-ME] geometric mean regression
Message-ID: <DM5PR04MB0762ECCF0C392976BA341CBAF1A60@DM5PR04MB0762.namprd04.prod.outlook.com>

The emmeans package handles this quite easily. You can do something like this:

    model <- lm(log(y) ~ treatment + ..., ...)   # where treatment is a factor
    library(emmeans)
    emm <- emmeans(model, "treatment", type = "response")
    emm    # shows the estimated geometric means
    contrast(emm, "pairwise")    # shows ratios of these estimates

A variety of models besides lm() are supported. The response transformation is detected automatically, and `type = "response"` tells it to back-transform. The delta method is used to obtain standard errors.

For more information, see `vignette("transformations", package = "emmeans")`

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017


From ahmadr215 at tpg.com.au  Tue Apr  3 04:38:43 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Tue, 3 Apr 2018 12:38:43 +1000
Subject: [R-sig-ME] geometric mean regression
In-Reply-To: <DM5PR04MB0762ECCF0C392976BA341CBAF1A60@DM5PR04MB0762.namprd04.prod.outlook.com>
References: <DM5PR04MB0762ECCF0C392976BA341CBAF1A60@DM5PR04MB0762.namprd04.prod.outlook.com>
Message-ID: <000301d3caf4$e4395570$acac0050$@tpg.com.au>

Hi Russell

Thanks for this, 
This makes my life much easier! You mentioned that the delta method can
estimate GM of standard errors, is that what you meant?
I need to look into this (SE), it would be great if GM of SE can be done
with emmeans package.

Ahmad
 


-----Original Message-----
From: Lenth, Russell V <russell-lenth at uiowa.edu> 
Sent: Tuesday, 3 April 2018 8:17 AM
To: ahmadr215 at tpg.com.au
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] geometric mean regression

The emmeans package handles this quite easily. You can do something like
this:

    model <- lm(log(y) ~ treatment + ..., ...)   # where treatment is a
factor
    library(emmeans)
    emm <- emmeans(model, "treatment", type = "response")
    emm    # shows the estimated geometric means
    contrast(emm, "pairwise")    # shows ratios of these estimates

A variety of models besides lm() are supported. The response transformation
is detected automatically, and `type = "response"` tells it to
back-transform. The delta method is used to obtain standard errors.

For more information, see `vignette("transformations", package = "emmeans")`

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science The University of Iowa ?-?
Iowa City, IA 52242? USA Voice (319)335-0712 (Dept. office)? -? FAX
(319)335-3017


From thierry.onkelinx at inbo.be  Tue Apr  3 10:10:48 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 3 Apr 2018 10:10:48 +0200
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
Message-ID: <CAJuCY5y7=L0QDGgnZWG02RTp20qW9GbAvxNR=+qKYAMAqw_nVg@mail.gmail.com>

Dear Joshua,

I wrote a blog post on a similar issue a few months ago. You can read
it here: https://www.muscardinus.be/2018/02/highly-correlated-random-effects/

In case you have one observation per time point per individual, then
the random effects structure and correlation structure is probably too
complex for the data.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-04-01 14:55 GMT+02:00 Joshua Rosenberg <jrosen at msu.edu>:
> Hi R-sig-mixed-models, I am using the nlme package (and lme() function) to
> estimate a longitudinal model for ~ 270 individuals over five time points.
> Descriptively, the data seems to take a quadratic form, so I fit a model
> like the following:
>
> lme(outcome ~ time + I(time^2),
>     random = ~ time + I(time^2),
>     correlation = corAR1(form = ~ time | individual_ID),
>     data = d_grouped)
>
> I have a question / concerns about the random effects, as they are highly
> correlated (intercept and linear term = -.95; intercept and quadratic term
> = .96; linear term and quadratic term = -.995):
>
> Random effects:
>  Formula: ~time + I(time^2) | individual_ID
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev    Corr
> (Intercept) 34.836512 (Intr) time
> time        39.803783 -0.959
> I(time^2)    8.342256  0.969 -0.995
> Residual    28.920368
>
> Is this a concern in terms of interpreting the model? Is this a concern
> technically in terms of how the model is specified?
>
> Thank you for pointing me in the right direction. Happy to answer any
> follow-up questions or to share additional details and information.
>
>
> Josh
>
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology & Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ahmadr215 at tpg.com.au  Tue Apr  3 11:42:57 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Tue, 3 Apr 2018 19:42:57 +1000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
Message-ID: <000101d3cb30$27b246a0$7716d3e0$@tpg.com.au>

Hi all

My question here is related to my previous query on Geometric mean of log
data.
I have a continuous dataset with considerable number of zero values, and
not-normally distributed. Because of zero values, I won't be able to take
the log of this variable. It has been suggested by some to add a constant
(e.g. +1) to all data to be able to take the log of data. I can then
transform back the output of lm() or Mixed-model to the original scale using
exp() or emmeans function with "response" method as suggested by Russell
(russell-lenth at uiowa.edu).    

I searched this (adding a constant) and found that views on this approach
are not consistent- I would like to see if anyone has experience on how to
deal with such data. 

Your help is greatly appreciated!

Ahmad


From thierry.onkelinx at inbo.be  Tue Apr  3 12:05:15 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 3 Apr 2018 12:05:15 +0200
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <000101d3cb30$27b246a0$7716d3e0$@tpg.com.au>
References: <000101d3cb30$27b246a0$7716d3e0$@tpg.com.au>
Message-ID: <CAJuCY5xBL+h2N1HEL+9Mp0VgUqgq0Vxms5HvZrHQ0rVRnQx+Dw@mail.gmail.com>

Dear Ahmad,

Don't do log(x+1). If you want to see why, then to the analysis with
log(x+1), log(x+100), log(x+0.001), ... and compare the results.

What is causing the zeros? Are they non-detects? Then you need threat
this as censored data (see the NADA package). If they are not, then a
zero-inflated gamma distribution might be an option.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au>:
> Hi all
>
> My question here is related to my previous query on Geometric mean of log
> data.
> I have a continuous dataset with considerable number of zero values, and
> not-normally distributed. Because of zero values, I won't be able to take
> the log of this variable. It has been suggested by some to add a constant
> (e.g. +1) to all data to be able to take the log of data. I can then
> transform back the output of lm() or Mixed-model to the original scale using
> exp() or emmeans function with "response" method as suggested by Russell
> (russell-lenth at uiowa.edu).
>
> I searched this (adding a constant) and found that views on this approach
> are not consistent- I would like to see if anyone has experience on how to
> deal with such data.
>
> Your help is greatly appreciated!
>
> Ahmad
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From arives at wisc.edu  Tue Apr  3 12:41:10 2018
From: arives at wisc.edu (Anthony R. Ives)
Date: Tue, 3 Apr 2018 10:41:10 +0000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <CAJuCY5xBL+h2N1HEL+9Mp0VgUqgq0Vxms5HvZrHQ0rVRnQx+Dw@mail.gmail.com>
References: <000101d3cb30$27b246a0$7716d3e0$@tpg.com.au>
 <CAJuCY5xBL+h2N1HEL+9Mp0VgUqgq0Vxms5HvZrHQ0rVRnQx+Dw@mail.gmail.com>
Message-ID: <EDE6BCC1-21DF-49ED-AFB4-2F142F974E43@wisc.edu>

Ahmad,

I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).

Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.

I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.

Cheers, Tony


Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.

Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.



On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org on behalf of thierry.onkelinx at inbo.be> wrote:

    Dear Ahmad,
    
    Don't do log(x+1). If you want to see why, then to the analysis with
    log(x+1), log(x+100), log(x+0.001), ... and compare the results.
    
    What is causing the zeros? Are they non-detects? Then you need threat
    this as censored data (see the NADA package). If they are not, then a
    zero-inflated gamma distribution might be an option.
    
    Best regards,
    
    ir. Thierry Onkelinx
    Statisticus / Statistician
    
    Vlaamse Overheid / Government of Flanders
    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
    AND FOREST
    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
    thierry.onkelinx at inbo.be
    Havenlaan 88 bus 73, 1000 Brussel
    www.inbo.be
    
    ///////////////////////////////////////////////////////////////////////////////////////////
    To call in the statistician after the experiment is done may be no
    more than asking him to perform a post-mortem examination: he may be
    able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
    The plural of anecdote is not data. ~ Roger Brinner
    The combination of some data and an aching desire for an answer does
    not ensure that a reasonable answer can be extracted from a given body
    of data. ~ John Tukey
    ///////////////////////////////////////////////////////////////////////////////////////////
    
    
    
    
    2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au>:
    > Hi all
    >
    > My question here is related to my previous query on Geometric mean of log
    > data.
    > I have a continuous dataset with considerable number of zero values, and
    > not-normally distributed. Because of zero values, I won't be able to take
    > the log of this variable. It has been suggested by some to add a constant
    > (e.g. +1) to all data to be able to take the log of data. I can then
    > transform back the output of lm() or Mixed-model to the original scale using
    > exp() or emmeans function with "response" method as suggested by Russell
    > (russell-lenth at uiowa.edu).
    >
    > I searched this (adding a constant) and found that views on this approach
    > are not consistent- I would like to see if anyone has experience on how to
    > deal with such data.
    >
    > Your help is greatly appreciated!
    >
    > Ahmad
    >
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    
    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    


From ahmadr215 at tpg.com.au  Tue Apr  3 14:45:49 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Tue, 3 Apr 2018 22:45:49 +1000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <EDE6BCC1-21DF-49ED-AFB4-2F142F974E43@wisc.edu>
References: <000101d3cb30$27b246a0$7716d3e0$@tpg.com.au>
 <CAJuCY5xBL+h2N1HEL+9Mp0VgUqgq0Vxms5HvZrHQ0rVRnQx+Dw@mail.gmail.com>
 <EDE6BCC1-21DF-49ED-AFB4-2F142F974E43@wisc.edu>
Message-ID: <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>

Hi Tony + Thierry

Thanks for your comments and thoughts,
To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).
So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.

I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.

Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok? 

The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?

Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.

 Thanks
Ahmad
 



-----Original Message-----
From: Anthony R. Ives <arives at wisc.edu> 
Sent: Tuesday, 3 April 2018 8:41 PM
To: Ahmad <ahmadr215 at tpg.com.au>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Thierry Onkelinx <thierry.onkelinx at inbo.be>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Ahmad,

I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).

Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.

I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.

Cheers, Tony


Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.

Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.



On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org on behalf of thierry.onkelinx at inbo.be> wrote:

    Dear Ahmad,
    
    Don't do log(x+1). If you want to see why, then to the analysis with
    log(x+1), log(x+100), log(x+0.001), ... and compare the results.
    
    What is causing the zeros? Are they non-detects? Then you need threat
    this as censored data (see the NADA package). If they are not, then a
    zero-inflated gamma distribution might be an option.
    
    Best regards,
    
    ir. Thierry Onkelinx
    Statisticus / Statistician
    
    Vlaamse Overheid / Government of Flanders
    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
    AND FOREST
    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
    thierry.onkelinx at inbo.be
    Havenlaan 88 bus 73, 1000 Brussel
    www.inbo.be
    
    ///////////////////////////////////////////////////////////////////////////////////////////
    To call in the statistician after the experiment is done may be no
    more than asking him to perform a post-mortem examination: he may be
    able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
    The plural of anecdote is not data. ~ Roger Brinner
    The combination of some data and an aching desire for an answer does
    not ensure that a reasonable answer can be extracted from a given body
    of data. ~ John Tukey
    ///////////////////////////////////////////////////////////////////////////////////////////
    
    
    
    
    2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au>:
    > Hi all
    >
    > My question here is related to my previous query on Geometric mean of log
    > data.
    > I have a continuous dataset with considerable number of zero values, and
    > not-normally distributed. Because of zero values, I won't be able to take
    > the log of this variable. It has been suggested by some to add a constant
    > (e.g. +1) to all data to be able to take the log of data. I can then
    > transform back the output of lm() or Mixed-model to the original scale using
    > exp() or emmeans function with "response" method as suggested by Russell
    > (russell-lenth at uiowa.edu).
    >
    > I searched this (adding a constant) and found that views on this approach
    > are not consistent- I would like to see if anyone has experience on how to
    > deal with such data.
    >
    > Your help is greatly appreciated!
    >
    > Ahmad
    >
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    
    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    


From felipe-francisco.calleja at alumnos.unican.es  Tue Apr  3 09:53:15 2018
From: felipe-francisco.calleja at alumnos.unican.es (CALLEJA APESTEGUI, FELIPE FRANCISCO)
Date: Tue, 3 Apr 2018 07:53:15 +0000
Subject: [R-sig-ME] Help establishing mixed model equation for split plot
 design
Message-ID: <DB6P191MB0088D09AF911107B33C1DE5C87A50@DB6P191MB0088.EURP191.PROD.OUTLOOK.COM>

Hello,


I'm looking for some help establishing a mixed model ANOVA using R, for a split plot design I've made for an experiment of saltmarsh germination. I'll explain as clear as possible the experimental design and afterwards what I've done and my doubts. Hope you can help me. I haven't worked very much with R so many of my doubts are about what I'm "telling" it to do with one or other command.


The experiment consists in meassuring the germination percentage of one species in variable conditions of salinity, immersion time and presence of other species. I sow seeds in soil core's, that are inside plastic boxes that are filled periodically with saline water. There are three factors: salinity (3 levels: 0, 5 and 18), immersion time (3 levels: 0, 20, 40%), species treatment (2 levels: Baccharis, Baccharis + Juncus). Inside each box there are 6 cores that combine in a complete random design the factors of immersion and species treatment. The box is filled with water at one of the levels of salinity. Thus, I'm using a split plot design with salinity as the whole plot factor, and immersion and species treatment as the subplot factors. All factors are considered fixed. Each box is repeated 5 times. Thus, there are 15 boxes and 90 soil cores. The dependent variable is the percentage of germination of the species Baccharis in each core.


I have several doubts about how to analyze the array.


1 - As far as I understand, although I'm treating all my factors as fixed, this is a mixed model because of the interaction between subjects (the boxes I believe), and the "split plot nature" of the array, right? In that sense, which function would be better to analyze this, the aov of the stats package, the lme of the nlme package, the lmer of lme4?



 2 - I've had trouble calculating the degrees of freedom for the residuals. The only reference I have is that the error of the whole plot part should have 12 df's, and the within error should have 60 df's. With that reference I've established two possible R commands:


fit.aov2 <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF + Error(rep:salinityF/immersionF:SpecTF), data=sp.datos)


With rep being the number of repetition. This last one gives the 12 and 60 df's for the error terms.


The other option is:

fit.okay <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= ~1|rep/salinityF, data=sp.datos)

But in this last case, the df's are 8 and 60, which makes me suspect maybe there is something wrong. But as I said, I haven't cleared my head on which should be the correct df's.


Questions: Is the aov line solving a mixed model adequate for my design?,



                     Is the lme line considering salinityF as a random factor? If it is, how can I tell it to consider all factors as fixed, but put salinity at the "higher level" of the whole plot and the other ones in the "lower level" of the subplot?


I hope the questions and the experimental array are clear. If there is any doubt or need more information please let me know. I attach a csv file with the data in case you want to see it.


Finally, if is not too much to ask, I'm fairly new to the splitplot anova's and R, so I would really appreciate if you could answer be with as much detail as possible, to fully understand what's going on and where to continue.


Thanks a lot,


Felipe Calleja Ap?stegui

Predoctoral researcher


Instituto de Hidr?ulica Ambiental "IH Cantabria"

C/ Isabel Torres, N? 15

Parque Cient?fico y Tecnol?gico de Cantabria

39011 Santander (Espa?a)

www.ihcantabria.es<http://www.ihcantabria.es/>

Tel:  +34 942 20 16 16 Ext. 1153

Fax: +34 942 26 63 61

e-mail: felipe-francisco.calleja at alumnos.unican.es


From jrosen at msu.edu  Mon Apr  2 23:32:34 2018
From: jrosen at msu.edu (Joshua Rosenberg)
Date: Mon, 02 Apr 2018 21:32:34 +0000
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <CABghstTvB+97Hkn2r2g3GbMzqG3NBkj4DkbZGp9T5EhO82qF_w@mail.gmail.com>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
 <1522599652.9262.10.camel@uchicago.edu>
 <CABghstTvB+97Hkn2r2g3GbMzqG3NBkj4DkbZGp9T5EhO82qF_w@mail.gmail.com>
Message-ID: <CANYHYTSr3cAMZW3xu4pOCJ99k1xQEvQprFiPNKa+jHdbaDMoDw@mail.gmail.com>

Dear Stuart and Ben,

Thank you, this worked to significantly reduce the correlations between the
intercept and the linear and quadratic terms (though still quite high
between the linear and quadratic term):

Random effects:
 Formula: ~time + I(time^2) | student_ID
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr
(Intercept) 18.671959 (Intr) time
time        11.029842 -0.262
I(time^2)    8.359834 -0.506  0.959
Residual    29.006598

Could I ask if that correlation between the linear (time) and quadratic
I(time^2) terms is cause for concern - and if so, how to think about
(potentially) addressing this?
Josh

On Sun, Apr 1, 2018 at 12:34 PM Ben Bolker <bbolker at gmail.com> wrote:

> On Sun, Apr 1, 2018 at 12:20 PM, Stuart Luppescu <lupp at uchicago.edu>
> wrote:
> > On Sun, 2018-04-01 at 12:55 +0000, Joshua Rosenberg wrote:
> >> lme(outcome ~ time + I(time^2),
> >>     random = ~ time + I(time^2),
> >>     correlation = corAR1(form = ~ time | individual_ID),
> >>     data = d_grouped)
> >>
> >> I have a question / concerns about the random effects, as they are
> >> highly
> >> correlated (intercept and linear term = -.95; intercept and quadratic
> >> term
> >> = .96; linear term and quadratic term = -.995):
> >
> > I think this is an ordinary occurrence for the intercept and time trend
> > to be negatively correlated. The way to avoid this is to center the
> > time variable at a point in the middle of the series, so, instead of
> > setting the values of time to {0, 1, 2, 3, 4} use {-2, -1, 0, 1, 2}.
> >
>
>   Agreed.  This is closely related, but not identical to, the
> phenomenon where the
> *fixed effects* are highly correlated.
>
> > --
> > Stuart Luppescu
> > Chief Psychometrician (ret.)
> > UChicago Consortium on School Research
> > http://consortium.uchicago.edu
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From jrosen at msu.edu  Tue Apr  3 19:08:30 2018
From: jrosen at msu.edu (Joshua Rosenberg)
Date: Tue, 03 Apr 2018 17:08:30 +0000
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <CAJuCY5y7=L0QDGgnZWG02RTp20qW9GbAvxNR=+qKYAMAqw_nVg@mail.gmail.com>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
 <CAJuCY5y7=L0QDGgnZWG02RTp20qW9GbAvxNR=+qKYAMAqw_nVg@mail.gmail.com>
Message-ID: <CANYHYTRU+pP-KD-g7FeBSV3J=CTd9-BJZGn6uwSwyGFaJei-6g@mail.gmail.com>

Thank you Thierry and Ben,
Josh

On Tue, Apr 3, 2018, 4:10 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Joshua,
>
> I wrote a blog post on a similar issue a few months ago. You can read
> it here:
> https://www.muscardinus.be/2018/02/highly-correlated-random-effects/
>
> In case you have one observation per time point per individual, then
> the random effects structure and correlation structure is probably too
> complex for the data.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-04-01 14:55 GMT+02:00 Joshua Rosenberg <jrosen at msu.edu>:
> > Hi R-sig-mixed-models, I am using the nlme package (and lme() function)
> to
> > estimate a longitudinal model for ~ 270 individuals over five time
> points.
> > Descriptively, the data seems to take a quadratic form, so I fit a model
> > like the following:
> >
> > lme(outcome ~ time + I(time^2),
> >     random = ~ time + I(time^2),
> >     correlation = corAR1(form = ~ time | individual_ID),
> >     data = d_grouped)
> >
> > I have a question / concerns about the random effects, as they are highly
> > correlated (intercept and linear term = -.95; intercept and quadratic
> term
> > = .96; linear term and quadratic term = -.995):
> >
> > Random effects:
> >  Formula: ~time + I(time^2) | individual_ID
> >  Structure: General positive-definite, Log-Cholesky parametrization
> >             StdDev    Corr
> > (Intercept) 34.836512 (Intr) time
> > time        39.803783 -0.959
> > I(time^2)    8.342256  0.969 -0.995
> > Residual    28.920368
> >
> > Is this a concern in terms of interpreting the model? Is this a concern
> > technically in terms of how the model is specified?
> >
> > Thank you for pointing me in the right direction. Happy to answer any
> > follow-up questions or to share additional details and information.
> >
> >
> > Josh
> >
> > --
> > Joshua Rosenberg, Ph.D. Candidate
> > Educational Psychology & Educational Technology
> > Michigan State University
> > http://jmichaelrosenberg.com
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From rfriesdo at gmail.com  Tue Apr  3 01:04:26 2018
From: rfriesdo at gmail.com (Rebecca Friesdorf)
Date: Mon, 2 Apr 2018 19:04:26 -0400
Subject: [R-sig-ME] MLM help - longitudinal, (overdispersed) count data
Message-ID: <CAKhH7fBABqD-D2ZzFTpgkwFokeaP0B1RgRXk3LvY=zcw2KdbKQ@mail.gmail.com>

Hi there,

I?m looking for some help analyzing multi-level (longitudinal) data with
the following characteristics: 1) autoregressive structure (daily diary
study), 2) dependent variable is a count (overdispersed Poisson/negative
binomial distribution). I have multiple level 1 and level 2 predictors. I
have done preliminary analyses in HLM 7 and SPSS, but they don?t seem to
have built-in options for data with both of my two characteristics (correct
me if I am wrong here). Based on these analyses I have significant fixed
and random effects for time and my two other level 1 predictors (and not a
whole lot going on with my level 2 predictors).

Which R package would recommend for my analysis (glmmADMB, nlme)? Perhaps
someone has examples/papers/PDFs that outline, in a practical way, how I
would set up my code (or their own code from a past study)? I had ignored
(omitted) missing cases in my initial attempts to do some of these analyses
in the glmmadmb and nlme package, but will also need to figure that out, so
if you have specific recommendations for how to handle those that would be
much appreciated also.

I only know basics with R so the more instructions/explanation the better.

Thank you!

-- 
*Rebecca Friesdorf*
*Ph.D. Candidate *
*Social Psychology*

*WILFRID LAURIER UNIVERSITY*
*Office: *N2068
*Email*: frie3750 at mylaurier.ca

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Apr  3 19:32:55 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 3 Apr 2018 17:32:55 +0000
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <4484_1522775758_w33HFvIo009852_CANYHYTSr3cAMZW3xu4pOCJ99k1xQEvQprFiPNKa+jHdbaDMoDw@mail.gmail.com>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
 <1522599652.9262.10.camel@uchicago.edu>
 <CABghstTvB+97Hkn2r2g3GbMzqG3NBkj4DkbZGp9T5EhO82qF_w@mail.gmail.com>
 <4484_1522775758_w33HFvIo009852_CANYHYTSr3cAMZW3xu4pOCJ99k1xQEvQprFiPNKa+jHdbaDMoDw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8367CF56A@FHSDB2D11-2.csu.mcmaster.ca>

Dear Joshua,

I'm chiming in late, so it's possible that someone already pointed this out and I didn't notice. A better way to specify a polynomial in R is to use poly() in the model formula. By default, this produces orthogonal polynomial regressors (at least in the fixed effects) but the same fit to the data. For example,

> time <- 1:5
> X <- poly(time, 2)

> X
              1          2
[1,] -0.6324555  0.5345225
[2,] -0.3162278 -0.2672612
[3,]  0.0000000 -0.5345225
[4,]  0.3162278 -0.2672612
[5,]  0.6324555  0.5345225
attr(,"coefs")
attr(,"coefs")$alpha
[1] 3 3

attr(,"coefs")$norm2
[1]  1  5 10 14

attr(,"degree")
[1] 1 2
attr(,"class")
[1] "poly"   "matrix"

> colSums(X)
           1            2 
0.000000e+00 1.110223e-16 

> crossprod(X)
              1             2
1  1.000000e+00 -1.110223e-16
2 -1.110223e-16  1.000000e+00

My guess is that this will also reduce the correlations among the random effects. If you really must have raw polynomials, then poly(time, 2, raw=TRUE) offers the advantage that model-structure-aware functions can understand that the linear and quadratic regressors are part of the same term in the model.

Whether high correlations among the random effects are really a problem, my guess is that they aren't, because lme() uses a log-Cholesky factorization of the random-effects covariance matrix anyway. In some contexts, high correlations might produce numerical instability, but, as I said, probably not here. Ben would know.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/





> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Joshua Rosenberg
> Sent: Monday, April 2, 2018 5:33 PM
> To: Ben Bolker <bbolker at gmail.com>
> Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] High correlation among random effects for longitudinal
> model
> 
> Dear Stuart and Ben,
> 
> Thank you, this worked to significantly reduce the correlations between the
> intercept and the linear and quadratic terms (though still quite high between the
> linear and quadratic term):
> 
> Random effects:
>  Formula: ~time + I(time^2) | student_ID
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev    Corr
> (Intercept) 18.671959 (Intr) time
> time        11.029842 -0.262
> I(time^2)    8.359834 -0.506  0.959
> Residual    29.006598
> 
> Could I ask if that correlation between the linear (time) and quadratic
> I(time^2) terms is cause for concern - and if so, how to think about
> (potentially) addressing this?
> Josh
> 
> On Sun, Apr 1, 2018 at 12:34 PM Ben Bolker <bbolker at gmail.com> wrote:
> 
> > On Sun, Apr 1, 2018 at 12:20 PM, Stuart Luppescu <lupp at uchicago.edu>
> > wrote:
> > > On Sun, 2018-04-01 at 12:55 +0000, Joshua Rosenberg wrote:
> > >> lme(outcome ~ time + I(time^2),
> > >>     random = ~ time + I(time^2),
> > >>     correlation = corAR1(form = ~ time | individual_ID),
> > >>     data = d_grouped)
> > >>
> > >> I have a question / concerns about the random effects, as they are
> > >> highly correlated (intercept and linear term = -.95; intercept and
> > >> quadratic term = .96; linear term and quadratic term = -.995):
> > >
> > > I think this is an ordinary occurrence for the intercept and time
> > > trend to be negatively correlated. The way to avoid this is to
> > > center the time variable at a point in the middle of the series, so,
> > > instead of setting the values of time to {0, 1, 2, 3, 4} use {-2, -1, 0, 1, 2}.
> > >
> >
> >   Agreed.  This is closely related, but not identical to, the
> > phenomenon where the *fixed effects* are highly correlated.
> >
> > > --
> > > Stuart Luppescu
> > > Chief Psychometrician (ret.)
> > > UChicago Consortium on School Research
> > > http://consortium.uchicago.edu
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology ?&? Educational Technology Michigan State University
> http://jmichaelrosenberg.com
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From tim.cole at ucl.ac.uk  Tue Apr  3 19:46:53 2018
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Tue, 3 Apr 2018 17:46:53 +0000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
Message-ID: <32B5E67B-2E72-4E12-8391-E30041F8821A@ucl.ac.uk>

Thierry is of course right that using 1 or 100 or 0.001 as the offset gives different answers. But for me that doesn?t rule out using an offset, it just means that it needs treating as an extra model parameter to be estimated. This is easy to do with a grid search to minimise the deviance.

You are right to emphasise the continuous nature of your data, and that zero values are not intrinsically different from non-zero values. The case where I come across this is relating body size with age, where age 0 corresponds to birth. Biologically it makes sense to think of time 0 being at -9 months, i.e. conception rather than birth, in which case the appropriate offset is 0.75 years or 9 months.

Best wishes,
Tim
--
 tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk> Phone 020 7905 2666
Population Policy and Practice Programme
UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK

Date: Tue, 3 Apr 2018 22:45:49 +1000
From: "Ahmad" <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>
To: "'Anthony R. Ives'" <arives at wisc.edu<mailto:arives at wisc.edu>>
Cc: "'r-sig-mixed-models'" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>,
                "'Thierry Onkelinx'" <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with
                zero values- to use the log transformation
Message-ID: <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au<mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>>
Content-Type: text/plain; charset="utf-8"

Hi Tony + Thierry

Thanks for your comments and thoughts,
To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).
So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.

I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.

Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok?

The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?

Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.

Thanks
Ahmad


-----Original Message-----
From: Anthony R. Ives <arives at wisc.edu<mailto:arives at wisc.edu>>
Sent: Tuesday, 3 April 2018 8:41 PM
To: Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>; Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Ahmad,

I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).

Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.

I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.

Cheers, Tony


Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.

Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.


On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

    Dear Ahmad,

    Don't do log(x+1). If you want to see why, then to the analysis with
    log(x+1), log(x+100), log(x+0.001), ... and compare the results.

    What is causing the zeros? Are they non-detects? Then you need threat
    this as censored data (see the NADA package). If they are not, then a
    zero-inflated gamma distribution might be an option.

    Best regards,

    ir. Thierry Onkelinx
    Statisticus / Statistician

    Vlaamse Overheid / Government of Flanders
    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
    AND FOREST
    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
    thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
    Havenlaan 88 bus 73, 1000 Brussel
    www.inbo.be

    ///////////////////////////////////////////////////////////////////////////////////////////
    To call in the statistician after the experiment is done may be no
    more than asking him to perform a post-mortem examination: he may be
    able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
    The plural of anecdote is not data. ~ Roger Brinner
    The combination of some data and an aching desire for an answer does
    not ensure that a reasonable answer can be extracted from a given body
    of data. ~ John Tukey
    ///////////////////////////////////////////////////////////////////////////////////////////




    2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>:
    > Hi all
    >
    > My question here is related to my previous query on Geometric mean of log
    > data.
    > I have a continuous dataset with considerable number of zero values, and
    > not-normally distributed. Because of zero values, I won't be able to take
    > the log of this variable. It has been suggested by some to add a constant
    > (e.g. +1) to all data to be able to take the log of data. I can then
    > transform back the output of lm() or Mixed-model to the original scale using
    > exp() or emmeans function with "response" method as suggested by Russell
    > (russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>).
    >
    > I searched this (adding a constant) and found that views on this approach
    > are not consistent- I would like to see if anyone has experience on how to
    > deal with such data.
    >
    > Your help is greatly appreciated!
    >
    > Ahmad


	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Tue Apr  3 20:24:13 2018
From: Farrar.David at epa.gov (Farrar, David)
Date: Tue, 3 Apr 2018 18:24:13 +0000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <32B5E67B-2E72-4E12-8391-E30041F8821A@ucl.ac.uk>
References: <32B5E67B-2E72-4E12-8391-E30041F8821A@ucl.ac.uk>
Message-ID: <DM5PR0901MB229606E9A283083B3EA840FB9AA50@DM5PR0901MB2296.namprd09.prod.outlook.com>


If you do that with a grid search, how would you get standard errors?  Bootstrap?

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Cole, Tim
Sent: Tuesday, April 03, 2018 1:47 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Thierry is of course right that using 1 or 100 or 0.001 as the offset gives different answers. But for me that doesn?t rule out using an offset, it just means that it needs treating as an extra model parameter to be estimated. This is easy to do with a grid search to minimise the deviance.

You are right to emphasise the continuous nature of your data, and that zero values are not intrinsically different from non-zero values. The case where I come across this is relating body size with age, where age 0 corresponds to birth. Biologically it makes sense to think of time 0 being at -9 months, i.e. conception rather than birth, in which case the appropriate offset is 0.75 years or 9 months.

Best wishes,
Tim
--
 tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk> Phone 020 7905 2666 Population Policy and Practice Programme UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK

Date: Tue, 3 Apr 2018 22:45:49 +1000
From: "Ahmad" <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>
To: "'Anthony R. Ives'" <arives at wisc.edu<mailto:arives at wisc.edu>>
Cc: "'r-sig-mixed-models'" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>,
                "'Thierry Onkelinx'" <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with
                zero values- to use the log transformation
Message-ID: <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au<mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>>
Content-Type: text/plain; charset="utf-8"

Hi Tony + Thierry

Thanks for your comments and thoughts,
To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).
So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.

I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.

Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok?

The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?

Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.

Thanks
Ahmad


-----Original Message-----
From: Anthony R. Ives <arives at wisc.edu<mailto:arives at wisc.edu>>
Sent: Tuesday, 3 April 2018 8:41 PM
To: Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>; Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Ahmad,

I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).

Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.

I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.

Cheers, Tony


Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.

Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.


On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

    Dear Ahmad,

    Don't do log(x+1). If you want to see why, then to the analysis with
    log(x+1), log(x+100), log(x+0.001), ... and compare the results.

    What is causing the zeros? Are they non-detects? Then you need threat
    this as censored data (see the NADA package). If they are not, then a
    zero-inflated gamma distribution might be an option.

    Best regards,

    ir. Thierry Onkelinx
    Statisticus / Statistician

    Vlaamse Overheid / Government of Flanders
    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
    AND FOREST
    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
    thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
    Havenlaan 88 bus 73, 1000 Brussel
    www.inbo.be

    ///////////////////////////////////////////////////////////////////////////////////////////
    To call in the statistician after the experiment is done may be no
    more than asking him to perform a post-mortem examination: he may be
    able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
    The plural of anecdote is not data. ~ Roger Brinner
    The combination of some data and an aching desire for an answer does
    not ensure that a reasonable answer can be extracted from a given body
    of data. ~ John Tukey
    ///////////////////////////////////////////////////////////////////////////////////////////




    2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>:
    > Hi all
    >
    > My question here is related to my previous query on Geometric mean of log
    > data.
    > I have a continuous dataset with considerable number of zero values, and
    > not-normally distributed. Because of zero values, I won't be able to take
    > the log of this variable. It has been suggested by some to add a constant
    > (e.g. +1) to all data to be able to take the log of data. I can then
    > transform back the output of lm() or Mixed-model to the original scale using
    > exp() or emmeans function with "response" method as suggested by Russell
    > (russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>).
    >
    > I searched this (adding a constant) and found that views on this approach
    > are not consistent- I would like to see if anyone has experience on how to
    > deal with such data.
    >
    > Your help is greatly appreciated!
    >
    > Ahmad


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From samuel.knapp at tum.de  Tue Apr  3 21:26:31 2018
From: samuel.knapp at tum.de (Samuel Knapp)
Date: Tue, 3 Apr 2018 21:26:31 +0200
Subject: [R-sig-ME] Help establishing mixed model equation for split,
 plot design
In-Reply-To: <mailman.16330.277.1522775768.1209.r-sig-mixed-models@r-project.org>
References: <mailman.16330.277.1522775768.1209.r-sig-mixed-models@r-project.org>
Message-ID: <7f7486ff-adab-2700-c3dd-b572b7686d7c@tum.de>

Hi Felipe,

if I understand the design correctly, it is a split-plot design with 
salinityF as the whole-plot. Only, if you have arranged the boxes in a 
way that replicate blocks are formed, you should include the rep effect 
in a model. These replicate blocks could be, that you always have three 
boxes with the three different salinity levels grouped together, e.g. on 
one shelf. If you have simply replicated each box 5 times and they are 
set up fully randomly, you should not include a repliate block.

If you have no missing values, and you specify the right model, both 
aov() and lme() should give you the same results. I would suggest the 
following models:


# with replicate blocks

aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF + 
Error(rep/salinityF), data=sp.datos)

lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
~1|rep/salinityF, data=sp.datos)

# or with lmer from lme4 package (library (lme4)

lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF 
+(1|rep/salinityF), data=sp.datos)

# without replicate blocks (I'm not completely sure, if aov will report 
the exact same results here)

aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF + 
Error(rep:salinityF), data=sp.datos)

lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
~1|rep:salinityF, data=sp.datos)

lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF 
+(1|rep:salinityF), data=sp.datos)


As rep/salinityF is simply a short form for rep+rep:salinityF the 
difference will be that you have no rep block effect in the models 
without replicate blocks.


If you have no missing values, the point about using a mixed model here 
is less about variance estimation through a random effect, but 
automatically getting the right F-Test of the main-plot effect in ANOVA 
(which is the main part of doing a proper split-plot analysis!!!).

My experience is that the anova() function from the lmerTest package 
will give you the right denominator df when using the Kenward-Roger 
method. You need to use lmer for this:

library(lmerTest)

anova(lmermodel,ddf="Kenward-Roger")

For proper mean comparisons, I suggest to use the emmeans package, with 
the Tukey test and letter display from the cld() function:

library(emmeans)

cld(emmeans(lmermodel,"salinityF") #replace salinityF by the factor you 
are interested


Finally, if you have one or more missing values, aov() will return 
strange anova tables, thus better use a mixed model!


Best regards,

Samuel

-- 
Samuel Knapp

Lehrstuhl f?r Pflanzenern?hrung
Technische Universit?t M?nchen
(Chair of Plant Nutrition
Technical University of Munich)

Emil-Ramann-Strasse 2
D-85354 Freising

Tel. +49 8161 71-3578	
samuel.knapp at tum.de
www.researchgate.net/profile/Samuel_Knapp



On 03/04/18 19:16, r-sig-mixed-models-request at r-project.org wrote:
> Message: 1
> Date: Tue, 3 Apr 2018 07:53:15 +0000
> From: "CALLEJA APESTEGUI, FELIPE FRANCISCO"
> 	<felipe-francisco.calleja at alumnos.unican.es>
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Help establishing mixed model equation for split
> 	plot design
> Message-ID:
> 	<DB6P191MB0088D09AF911107B33C1DE5C87A50 at DB6P191MB0088.EURP191.PROD.OUTLOOK.COM>
> 	
> Content-Type: text/plain; charset="iso-8859-1"
>
> Hello,
>
>
> I'm looking for some help establishing a mixed model ANOVA using R, for a split plot design I've made for an experiment of saltmarsh germination. I'll explain as clear as possible the experimental design and afterwards what I've done and my doubts. Hope you can help me. I haven't worked very much with R so many of my doubts are about what I'm "telling" it to do with one or other command.
>
>
> The experiment consists in meassuring the germination percentage of one species in variable conditions of salinity, immersion time and presence of other species. I sow seeds in soil core's, that are inside plastic boxes that are filled periodically with saline water. There are three factors: salinity (3 levels: 0, 5 and 18), immersion time (3 levels: 0, 20, 40%), species treatment (2 levels: Baccharis, Baccharis + Juncus). Inside each box there are 6 cores that combine in a complete random design the factors of immersion and species treatment. The box is filled with water at one of the levels of salinity. Thus, I'm using a split plot design with salinity as the whole plot factor, and immersion and species treatment as the subplot factors. All factors are considered fixed. Each box is repeated 5 times. Thus, there are 15 boxes and 90 soil cores. The dependent variable is the percentage of germination of the species Baccharis in each core.
>
>
> I have several doubts about how to analyze the array.
>
>
> 1 - As far as I understand, although I'm treating all my factors as fixed, this is a mixed model because of the interaction between subjects (the boxes I believe), and the "split plot nature" of the array, right? In that sense, which function would be better to analyze this, the aov of the stats package, the lme of the nlme package, the lmer of lme4?
>
>
>
>   2 - I've had trouble calculating the degrees of freedom for the residuals. The only reference I have is that the error of the whole plot part should have 12 df's, and the within error should have 60 df's. With that reference I've established two possible R commands:
>
>
> fit.aov2 <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF + Error(rep:salinityF/immersionF:SpecTF), data=sp.datos)
>
>
> With rep being the number of repetition. This last one gives the 12 and 60 df's for the error terms.
>
>
> The other option is:
>
> fit.okay <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= ~1|rep/salinityF, data=sp.datos)
>
> But in this last case, the df's are 8 and 60, which makes me suspect maybe there is something wrong. But as I said, I haven't cleared my head on which should be the correct df's.
>
>
> Questions: Is the aov line solving a mixed model adequate for my design?,
>
>
>
>                       Is the lme line considering salinityF as a random factor? If it is, how can I tell it to consider all factors as fixed, but put salinity at the "higher level" of the whole plot and the other ones in the "lower level" of the subplot?
>
>
> I hope the questions and the experimental array are clear. If there is any doubt or need more information please let me know. I attach a csv file with the data in case you want to see it.
>
>
> Finally, if is not too much to ask, I'm fairly new to the splitplot anova's and R, so I would really appreciate if you could answer be with as much detail as possible, to fully understand what's going on and where to continue.
>
>
> Thanks a lot,
>
>
> Felipe Calleja Ap?stegui
>
> Predoctoral researcher
>
>
> Instituto de Hidr?ulica Ambiental "IH Cantabria"
>
> C/ Isabel Torres, N? 15
>
> Parque Cient?fico y Tecnol?gico de Cantabria
>
> 39011 Santander (Espa?a)
>
> www.ihcantabria.es<http://www.ihcantabria.es/>
>
> Tel:  +34 942 20 16 16 Ext. 1153
>
> Fax: +34 942 26 63 61
>
> e-mail: felipe-francisco.calleja at alumnos.unican.es
>
>
>


From john.maindonald at anu.edu.au  Tue Apr  3 23:01:21 2018
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 3 Apr 2018 21:01:21 +0000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <DM5PR0901MB229606E9A283083B3EA840FB9AA50@DM5PR0901MB2296.namprd09.prod.outlook.com>
References: <32B5E67B-2E72-4E12-8391-E30041F8821A@ucl.ac.uk>
 <DM5PR0901MB229606E9A283083B3EA840FB9AA50@DM5PR0901MB2296.namprd09.prod.outlook.com>
Message-ID: <57577FE7-DCE4-4B05-8993-D21525B95A3A@anu.edu.au>

If it is just a choice between adding 1, adding 1/6 (as Tukey suggested), and adding 0.001,
that is not in principle different from choosing between: a negative binomial, a poisson,
a quasipoisson, negative binomial types I or II, Delaport, Poisson inverse gaussian. etc
(these are choices in the gamlss package; there are others in glmmTMB and in VGAM),
with choices of link function for the various parameters multiplying the range of possibilities.
The issues that this raises for inference, in cases where the choice is to an extent arbitrary,
are insufficiently acknowledged.

On the point about adding a constant to a continuous dataset with zero values to use the
log transformation, see the discussion at:

https://stats.stackexchange.com/questions/114848/negative-binomial-glm-vs-log-transforming-for-count-data-increased-type-i-erro/215080#215080

For the hurricanes dataset (available as DAAG::hurricNamed) that is the basis for an analysis
and for graphs that I posted, a log(count+1) with gaussian error actually does better, as judged
by comparing the quantiles (use, e.g., gamlss::centiles().  The comparison is least favorable to
the negative binomial at the lower end of the damage category.
[It would be good to have a  predict(?, type=?quantile?), or suchlike, generally available.]

It is curious that there is such a range of alternatives for count data, but that the only widely
canvassed alternative to the binomial has been the  beta binomial, with zero-inflation and
hurdle effects adding to the mix.   I have been looking at data recently where the choice
between using glmer() with its ilimitation to binomial errors, and glmmTMB() with beta binomial
errors, with a scale parameter that is a function of the explanatory variable, makes a huge
difference.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 4/04/2018, at 06:24, Farrar, David <Farrar.David at epa.gov<mailto:Farrar.David at epa.gov>> wrote:


If you do that with a grid search, how would you get standard errors?  Bootstrap?

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Cole, Tim
Sent: Tuesday, April 03, 2018 1:47 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Thierry is of course right that using 1 or 100 or 0.001 as the offset gives different answers. But for me that doesn?t rule out using an offset, it just means that it needs treating as an extra model parameter to be estimated. This is easy to do with a grid search to minimise the deviance.

You are right to emphasise the continuous nature of your data, and that zero values are not intrinsically different from non-zero values. The case where I come across this is relating body size with age, where age 0 corresponds to birth. Biologically it makes sense to think of time 0 being at -9 months, i.e. conception rather than birth, in which case the appropriate offset is 0.75 years or 9 months.

Best wishes,
Tim
--
tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk><mailto:tim.cole at ucl.ac.uk> Phone 020 7905 2666 Population Policy and Practice Programme UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK

Date: Tue, 3 Apr 2018 22:45:49 +1000
From: "Ahmad" <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au>>
To: "'Anthony R. Ives'" <arives at wisc.edu<mailto:arives at wisc.edu><mailto:arives at wisc.edu>>
Cc: "'r-sig-mixed-models'" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>>,
               "'Thierry Onkelinx'" <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with
               zero values- to use the log transformation
Message-ID: <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au<mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au><mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>>
Content-Type: text/plain; charset="utf-8"

Hi Tony + Thierry

Thanks for your comments and thoughts,
To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).
So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.

I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.

Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok?

The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?

Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.

Thanks
Ahmad


-----Original Message-----
From: Anthony R. Ives <arives at wisc.edu<mailto:arives at wisc.edu><mailto:arives at wisc.edu>>
Sent: Tuesday, 3 April 2018 8:41 PM
To: Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au>>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>>; Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Ahmad,

I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).

Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.

I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.

Cheers, Tony


Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.

Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.


On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be>> wrote:

   Dear Ahmad,

   Don't do log(x+1). If you want to see why, then to the analysis with
   log(x+1), log(x+100), log(x+0.001), ... and compare the results.

   What is causing the zeros? Are they non-detects? Then you need threat
   this as censored data (see the NADA package). If they are not, then a
   zero-inflated gamma distribution might be an option.

   Best regards,

   ir. Thierry Onkelinx
   Statisticus / Statistician

   Vlaamse Overheid / Government of Flanders
   INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
   AND FOREST
   Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
   thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be>
   Havenlaan 88 bus 73, 1000 Brussel
   www.inbo.be<http://www.inbo.be>

   ///////////////////////////////////////////////////////////////////////////////////////////
   To call in the statistician after the experiment is done may be no
   more than asking him to perform a post-mortem examination: he may be
   able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
   The plural of anecdote is not data. ~ Roger Brinner
   The combination of some data and an aching desire for an answer does
   not ensure that a reasonable answer can be extracted from a given body
   of data. ~ John Tukey
   ///////////////////////////////////////////////////////////////////////////////////////////




   2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au>>:
Hi all

My question here is related to my previous query on Geometric mean of log
data.
I have a continuous dataset with considerable number of zero values, and
not-normally distributed. Because of zero values, I won't be able to take
the log of this variable. It has been suggested by some to add a constant
(e.g. +1) to all data to be able to take the log of data. I can then
transform back the output of lm() or Mixed-model to the original scale using
exp() or emmeans function with "response" method as suggested by Russell
(russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu><mailto:russell-lenth at uiowa.edu>).

I searched this (adding a constant) and found that views on this approach
are not consistent- I would like to see if anyone has experience on how to
deal with such data.

Your help is greatly appreciated!

Ahmad


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From samuel.knapp at tum.de  Wed Apr  4 10:34:15 2018
From: samuel.knapp at tum.de (Samuel Knapp)
Date: Wed, 4 Apr 2018 10:34:15 +0200
Subject: [R-sig-ME] Help establishing mixed model equation for split,
 plot design
In-Reply-To: <AM4P191MB00822B95F5F0150839DDBC9287A40@AM4P191MB0082.EURP191.PROD.OUTLOOK.COM>
References: <mailman.16330.277.1522775768.1209.r-sig-mixed-models@r-project.org>
 <7f7486ff-adab-2700-c3dd-b572b7686d7c@tum.de>
 <AM4P191MB00822B95F5F0150839DDBC9287A40@AM4P191MB0082.EURP191.PROD.OUTLOOK.COM>
Message-ID: <74c2230b-c5ec-e78c-d35a-9faaba62ef11@tum.de>

Hi Felipe,


please also respond to the mailing list.


Sorry, lme only takes nested random effects (see 
https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified). 
In order to use the rep:salinity effect, you could add a column for the 
main plots in your data set:


sp.datos$rep_salinityF <- paste(sp.datos$rep,sp.datos$salinityF,paste="_")

lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
~1|rep_salinityF, data=sp.datos)


I hope, it works like this.


I'm afraid, I don't fully understand your question regarding equal 
number of samples. Do you mean missing observations? In lme, you need to 
add na.action="na.omit", while lmer is automatically omitting missing 
observations.

You're right, that the ANOVA is doing type III SS. If you're interested 
in other SS type, you could look at the Anova() function from the car 
package. Apparently it can also deal with mixed models. Furthermore, the 
new version of lmerTest can also handle other SS type. See 
https://github.com/runehaubo/lmerTestR/blob/master/pkg_notes/new_lmerTest.pdf


Best,

Samuel



On 04/04/18 10:15, CALLEJA APESTEGUI, FELIPE FRANCISCO wrote:
>
> Hi Samuel,
>
>
> first of all thanks a lot for the quick and clear response.
>
>
> As you state, all models give the same results once they are 
> established following your examples. Now I have a clear view about 
> what is really doing the command and how to continue.
>
>
> Just one quick comment. The line:
>
> *lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
> ~**1|rep:salinityF, data=sp.datos)*
>
>
> Throws the following error:
>
> *Error in getGroups.data.frame(dataMix, groups) : **invalid formula 
> for groups*
>
> I leave it here in case is interesting for you. I've decided to use 
> the lmer package because I have other variables that are not balanced, 
> so I prefer to use the same model in all cases, and that package is 
> working fine.
>
> Just one final question. Is there any consideration I should have when 
> working with variables without equal number of samples? I mean, 
> something specific in the command of the lmer I should be careful with 
> or investigate further on. Or does the function itself has all 
> considerations included. i see from the *anova(fit.okay3, 
> ddf="Kenward-Roger") *that the anova is made using the type III SS so 
> I wouldn't have to change that part. *
> *
>
> Also, fyi,? the aov function in the case of not grouping by rep throws 
> the same result as the lmer.
>
> Again, I really appreciate your help, it has been a lifesaver.
>
> Best regards,
>
> *Felipe Calleja Ap?stegui*
>
> *Predoctoral researcher*
>
> *
> *
>
> *Instituto de Hidr?ulica Ambiental "IH Cantabria"*
>
> C/ Isabel Torres, N? 15
>
> Parque Cient?fico y Tecnol?gico de Cantabria
>
> 39011 Santander (Espa?a)
>
> www.ihcantabria.es <http://www.ihcantabria.es/>
>
> Tel:? +34 942 20 16 16 Ext. 1153
>
> Fax: +34 942 26 63 61
>
> e-mail: f*elipe-francisco.calleja at alumnos.unican.es*
>
>
> ------------------------------------------------------------------------
> *De:* Samuel Knapp <samuel.knapp at tum.de>
> *Enviado:* martes, 3 de abril de 2018 21:26:31
> *Para:* r-sig-mixed-models at r-project.org; CALLEJA APESTEGUI, FELIPE 
> FRANCISCO
> *Asunto:* Re: Help establishing mixed model equation for split, plot 
> design
> Hi Felipe,
>
> if I understand the design correctly, it is a split-plot design with
> salinityF as the whole-plot. Only, if you have arranged the boxes in a
> way that replicate blocks are formed, you should include the rep effect
> in a model. These replicate blocks could be, that you always have three
> boxes with the three different salinity levels grouped together, e.g. on
> one shelf. If you have simply replicated each box 5 times and they are
> set up fully randomly, you should not include a repliate block.
>
> If you have no missing values, and you specify the right model, both
> aov() and lme() should give you the same results. I would suggest the
> following models:
>
>
> # with replicate blocks
>
> aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF +
> Error(rep/salinityF), data=sp.datos)
>
> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
> ~1|rep/salinityF, data=sp.datos)
>
> # or with lmer from lme4 package (library (lme4)
>
> lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF
> +(1|rep/salinityF), data=sp.datos)
>
> # without replicate blocks (I'm not completely sure, if aov will report
> the exact same results here)
>
> aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF +
> Error(rep:salinityF), data=sp.datos)
>
> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
> ~1|rep:salinityF, data=sp.datos)
>
> lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF
> +(1|rep:salinityF), data=sp.datos)
>
>
> As rep/salinityF is simply a short form for rep+rep:salinityF the
> difference will be that you have no rep block effect in the models
> without replicate blocks.
>
>
> If you have no missing values, the point about using a mixed model here
> is less about variance estimation through a random effect, but
> automatically getting the right F-Test of the main-plot effect in ANOVA
> (which is the main part of doing a proper split-plot analysis!!!).
>
> My experience is that the anova() function from the lmerTest package
> will give you the right denominator df when using the Kenward-Roger
> method. You need to use lmer for this:
>
> library(lmerTest)
>
> anova(lmermodel,ddf="Kenward-Roger")
>
> For proper mean comparisons, I suggest to use the emmeans package, with
> the Tukey test and letter display from the cld() function:
>
> library(emmeans)
>
> cld(emmeans(lmermodel,"salinityF") #replace salinityF by the factor you
> are interested
>
>
> Finally, if you have one or more missing values, aov() will return
> strange anova tables, thus better use a mixed model!
>
>
> Best regards,
>
> Samuel
>
> -- 
> Samuel Knapp
>
> Lehrstuhl f?r Pflanzenern?hrung
> Technische Universit?t M?nchen
> (Chair of Plant Nutrition
> Technical University of Munich)
>
> Emil-Ramann-Strasse 2
> D-85354 Freising
>
> Tel. +49 8161 71-3578
> samuel.knapp at tum.de
> www.researchgate.net/profile/Samuel_Knapp 
> <http://www.researchgate.net/profile/Samuel_Knapp>
>
>
>
> On 03/04/18 19:16, r-sig-mixed-models-request at r-project.org wrote:
> > Message: 1
> > Date: Tue, 3 Apr 2018 07:53:15 +0000
> > From: "CALLEJA APESTEGUI, FELIPE FRANCISCO"
> > <felipe-francisco.calleja at alumnos.unican.es>
> > To: "r-sig-mixed-models at r-project.org"
> >??????? <r-sig-mixed-models at r-project.org>
> > Subject: [R-sig-ME] Help establishing mixed model equation for split
> >??????? plot design
> > Message-ID:
> > 
> <DB6P191MB0088D09AF911107B33C1DE5C87A50 at DB6P191MB0088.EURP191.PROD.OUTLOOK.COM>
> >
> > Content-Type: text/plain; charset="iso-8859-1"
> >
> > Hello,
> >
> >
> > I'm looking for some help establishing a mixed model ANOVA using R, 
> for a split plot design I've made for an experiment of saltmarsh 
> germination. I'll explain as clear as possible the experimental design 
> and afterwards what I've done and my doubts. Hope you can help me. I 
> haven't worked very much with R so many of my doubts are about what 
> I'm "telling" it to do with one or other command.
> >
> >
> > The experiment consists in meassuring the germination percentage of 
> one species in variable conditions of salinity, immersion time and 
> presence of other species. I sow seeds in soil core's, that are inside 
> plastic boxes that are filled periodically with saline water. There 
> are three factors: salinity (3 levels: 0, 5 and 18), immersion time (3 
> levels: 0, 20, 40%), species treatment (2 levels: Baccharis, Baccharis 
> + Juncus). Inside each box there are 6 cores that combine in a 
> complete random design the factors of immersion and species treatment. 
> The box is filled with water at one of the levels of salinity. Thus, 
> I'm using a split plot design with salinity as the whole plot factor, 
> and immersion and species treatment as the subplot factors. All 
> factors are considered fixed. Each box is repeated 5 times. Thus, 
> there are 15 boxes and 90 soil cores. The dependent variable is the 
> percentage of germination of the species Baccharis in each core.
> >
> >
> > I have several doubts about how to analyze the array.
> >
> >
> > 1 - As far as I understand, although I'm treating all my factors as 
> fixed, this is a mixed model because of the interaction between 
> subjects (the boxes I believe), and the "split plot nature" of the 
> array, right? In that sense, which function would be better to analyze 
> this, the aov of the stats package, the lme of the nlme package, the 
> lmer of lme4?
> >
> >
> >
> >?? 2 - I've had trouble calculating the degrees of freedom for the 
> residuals. The only reference I have is that the error of the whole 
> plot part should have 12 df's, and the within error should have 60 
> df's. With that reference I've established two possible R commands:
> >
> >
> > fit.aov2 <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF + 
> Error(rep:salinityF/immersionF:SpecTF), data=sp.datos)
> >
> >
> > With rep being the number of repetition. This last one gives the 12 
> and 60 df's for the error terms.
> >
> >
> > The other option is:
> >
> > fit.okay <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
> ~1|rep/salinityF, data=sp.datos)
> >
> > But in this last case, the df's are 8 and 60, which makes me suspect 
> maybe there is something wrong. But as I said, I haven't cleared my 
> head on which should be the correct df's.
> >
> >
> > Questions: Is the aov line solving a mixed model adequate for my 
> design?,
> >
> >
> >
> >?????????????????????? Is the lme line considering salinityF as a 
> random factor? If it is, how can I tell it to consider all factors as 
> fixed, but put salinity at the "higher level" of the whole plot and 
> the other ones in the "lower level" of the subplot?
> >
> >
> > I hope the questions and the experimental array are clear. If there 
> is any doubt or need more information please let me know. I attach a 
> csv file with the data in case you want to see it.
> >
> >
> > Finally, if is not too much to ask, I'm fairly new to the splitplot 
> anova's and R, so I would really appreciate if you could answer be 
> with as much detail as possible, to fully understand what's going on 
> and where to continue.
> >
> >
> > Thanks a lot,
> >
> >
> > Felipe Calleja Ap?stegui
> >
> > Predoctoral researcher
> >
> >
> > Instituto de Hidr?ulica Ambiental "IH Cantabria"
> >
> > C/ Isabel Torres, N? 15
> >
> > Parque Cient?fico y Tecnol?gico de Cantabria
> >
> > 39011 Santander (Espa?a)
> >
> > www.ihcantabria.es<http://www.ihcantabria.es/>
> >
> > Tel:? +34 942 20 16 16 Ext. 1153
> >
> > Fax: +34 942 26 63 61
> >
> > e-mail: felipe-francisco.calleja at alumnos.unican.es
> >
> >
> >
>


	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Wed Apr  4 11:14:34 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 4 Apr 2018 09:14:34 +0000
Subject: [R-sig-ME] Help establishing mixed model equation for split,
 plot design
In-Reply-To: <74c2230b-c5ec-e78c-d35a-9faaba62ef11@tum.de>
References: <mailman.16330.277.1522775768.1209.r-sig-mixed-models@r-project.org>
 <7f7486ff-adab-2700-c3dd-b572b7686d7c@tum.de>
 <AM4P191MB00822B95F5F0150839DDBC9287A40@AM4P191MB0082.EURP191.PROD.OUTLOOK.COM>
 <74c2230b-c5ec-e78c-d35a-9faaba62ef11@tum.de>
Message-ID: <BD437132-1B98-4E0E-BF54-EB2294DEDCB5@glasgow.ac.uk>

Hi, 

> Sorry, lme only takes nested random effects 

Other designs are possible, e.g. fitting crossed random effects in lme is possible but fiddly. Pinheiro & Bates (Mixed Effects Models in S and S-Plus, 2000, p163-167) show how to do this using pdBlocked.

Best wishes,
Paul




> On 4 Apr 2018, at 11:34, Samuel Knapp <samuel.knapp at tum.de> wrote:
> 
> Hi Felipe,
> 
> 
> please also respond to the mailing list.
> 
> 
> Sorry, lme only takes nested random effects (see 
> https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified). 
> In order to use the rep:salinity effect, you could add a column for the 
> main plots in your data set:
> 
> 
> sp.datos$rep_salinityF <- paste(sp.datos$rep,sp.datos$salinityF,paste="_")
> 
> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
> ~1|rep_salinityF, data=sp.datos)
> 
> 
> I hope, it works like this.
> 
> 
> I'm afraid, I don't fully understand your question regarding equal 
> number of samples. Do you mean missing observations? In lme, you need to 
> add na.action="na.omit", while lmer is automatically omitting missing 
> observations.
> 
> You're right, that the ANOVA is doing type III SS. If you're interested 
> in other SS type, you could look at the Anova() function from the car 
> package. Apparently it can also deal with mixed models. Furthermore, the 
> new version of lmerTest can also handle other SS type. See 
> https://github.com/runehaubo/lmerTestR/blob/master/pkg_notes/new_lmerTest.pdf
> 
> 
> Best,
> 
> Samuel
> 
> 
> 
> On 04/04/18 10:15, CALLEJA APESTEGUI, FELIPE FRANCISCO wrote:
>> 
>> Hi Samuel,
>> 
>> 
>> first of all thanks a lot for the quick and clear response.
>> 
>> 
>> As you state, all models give the same results once they are 
>> established following your examples. Now I have a clear view about 
>> what is really doing the command and how to continue.
>> 
>> 
>> Just one quick comment. The line:
>> 
>> *lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
>> ~**1|rep:salinityF, data=sp.datos)*
>> 
>> 
>> Throws the following error:
>> 
>> *Error in getGroups.data.frame(dataMix, groups) : **invalid formula 
>> for groups*
>> 
>> I leave it here in case is interesting for you. I've decided to use 
>> the lmer package because I have other variables that are not balanced, 
>> so I prefer to use the same model in all cases, and that package is 
>> working fine.
>> 
>> Just one final question. Is there any consideration I should have when 
>> working with variables without equal number of samples? I mean, 
>> something specific in the command of the lmer I should be careful with 
>> or investigate further on. Or does the function itself has all 
>> considerations included. i see from the *anova(fit.okay3, 
>> ddf="Kenward-Roger") *that the anova is made using the type III SS so 
>> I wouldn't have to change that part. *
>> *
>> 
>> Also, fyi,? the aov function in the case of not grouping by rep throws 
>> the same result as the lmer.
>> 
>> Again, I really appreciate your help, it has been a lifesaver.
>> 
>> Best regards,
>> 
>> *Felipe Calleja Ap?stegui*
>> 
>> *Predoctoral researcher*
>> 
>> *
>> *
>> 
>> *Instituto de Hidr?ulica Ambiental "IH Cantabria"*
>> 
>> C/ Isabel Torres, N? 15
>> 
>> Parque Cient?fico y Tecnol?gico de Cantabria
>> 
>> 39011 Santander (Espa?a)
>> 
>> www.ihcantabria.es <http://www.ihcantabria.es/>
>> 
>> Tel:? +34 942 20 16 16 Ext. 1153
>> 
>> Fax: +34 942 26 63 61
>> 
>> e-mail: f*elipe-francisco.calleja at alumnos.unican.es*
>> 
>> 
>> ------------------------------------------------------------------------
>> *De:* Samuel Knapp <samuel.knapp at tum.de>
>> *Enviado:* martes, 3 de abril de 2018 21:26:31
>> *Para:* r-sig-mixed-models at r-project.org; CALLEJA APESTEGUI, FELIPE 
>> FRANCISCO
>> *Asunto:* Re: Help establishing mixed model equation for split, plot 
>> design
>> Hi Felipe,
>> 
>> if I understand the design correctly, it is a split-plot design with
>> salinityF as the whole-plot. Only, if you have arranged the boxes in a
>> way that replicate blocks are formed, you should include the rep effect
>> in a model. These replicate blocks could be, that you always have three
>> boxes with the three different salinity levels grouped together, e.g. on
>> one shelf. If you have simply replicated each box 5 times and they are
>> set up fully randomly, you should not include a repliate block.
>> 
>> If you have no missing values, and you specify the right model, both
>> aov() and lme() should give you the same results. I would suggest the
>> following models:
>> 
>> 
>> # with replicate blocks
>> 
>> aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF +
>> Error(rep/salinityF), data=sp.datos)
>> 
>> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
>> ~1|rep/salinityF, data=sp.datos)
>> 
>> # or with lmer from lme4 package (library (lme4)
>> 
>> lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF
>> +(1|rep/salinityF), data=sp.datos)
>> 
>> # without replicate blocks (I'm not completely sure, if aov will report
>> the exact same results here)
>> 
>> aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF +
>> Error(rep:salinityF), data=sp.datos)
>> 
>> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
>> ~1|rep:salinityF, data=sp.datos)
>> 
>> lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF
>> +(1|rep:salinityF), data=sp.datos)
>> 
>> 
>> As rep/salinityF is simply a short form for rep+rep:salinityF the
>> difference will be that you have no rep block effect in the models
>> without replicate blocks.
>> 
>> 
>> If you have no missing values, the point about using a mixed model here
>> is less about variance estimation through a random effect, but
>> automatically getting the right F-Test of the main-plot effect in ANOVA
>> (which is the main part of doing a proper split-plot analysis!!!).
>> 
>> My experience is that the anova() function from the lmerTest package
>> will give you the right denominator df when using the Kenward-Roger
>> method. You need to use lmer for this:
>> 
>> library(lmerTest)
>> 
>> anova(lmermodel,ddf="Kenward-Roger")
>> 
>> For proper mean comparisons, I suggest to use the emmeans package, with
>> the Tukey test and letter display from the cld() function:
>> 
>> library(emmeans)
>> 
>> cld(emmeans(lmermodel,"salinityF") #replace salinityF by the factor you
>> are interested
>> 
>> 
>> Finally, if you have one or more missing values, aov() will return
>> strange anova tables, thus better use a mixed model!
>> 
>> 
>> Best regards,
>> 
>> Samuel
>> 
>> -- 
>> Samuel Knapp
>> 
>> Lehrstuhl f?r Pflanzenern?hrung
>> Technische Universit?t M?nchen
>> (Chair of Plant Nutrition
>> Technical University of Munich)
>> 
>> Emil-Ramann-Strasse 2
>> D-85354 Freising
>> 
>> Tel. +49 8161 71-3578
>> samuel.knapp at tum.de
>> www.researchgate.net/profile/Samuel_Knapp 
>> <http://www.researchgate.net/profile/Samuel_Knapp>
>> 
>> 
>> 
>> On 03/04/18 19:16, r-sig-mixed-models-request at r-project.org wrote:
>>> Message: 1
>>> Date: Tue, 3 Apr 2018 07:53:15 +0000
>>> From: "CALLEJA APESTEGUI, FELIPE FRANCISCO"
>>> <felipe-francisco.calleja at alumnos.unican.es>
>>> To: "r-sig-mixed-models at r-project.org"
>>> ??????? <r-sig-mixed-models at r-project.org>
>>> Subject: [R-sig-ME] Help establishing mixed model equation for split
>>> ??????? plot design
>>> Message-ID:
>>> 
>> <DB6P191MB0088D09AF911107B33C1DE5C87A50 at DB6P191MB0088.EURP191.PROD.OUTLOOK.COM>
>>> 
>>> Content-Type: text/plain; charset="iso-8859-1"
>>> 
>>> Hello,
>>> 
>>> 
>>> I'm looking for some help establishing a mixed model ANOVA using R, 
>> for a split plot design I've made for an experiment of saltmarsh 
>> germination. I'll explain as clear as possible the experimental design 
>> and afterwards what I've done and my doubts. Hope you can help me. I 
>> haven't worked very much with R so many of my doubts are about what 
>> I'm "telling" it to do with one or other command.
>>> 
>>> 
>>> The experiment consists in meassuring the germination percentage of 
>> one species in variable conditions of salinity, immersion time and 
>> presence of other species. I sow seeds in soil core's, that are inside 
>> plastic boxes that are filled periodically with saline water. There 
>> are three factors: salinity (3 levels: 0, 5 and 18), immersion time (3 
>> levels: 0, 20, 40%), species treatment (2 levels: Baccharis, Baccharis 
>> + Juncus). Inside each box there are 6 cores that combine in a 
>> complete random design the factors of immersion and species treatment. 
>> The box is filled with water at one of the levels of salinity. Thus, 
>> I'm using a split plot design with salinity as the whole plot factor, 
>> and immersion and species treatment as the subplot factors. All 
>> factors are considered fixed. Each box is repeated 5 times. Thus, 
>> there are 15 boxes and 90 soil cores. The dependent variable is the 
>> percentage of germination of the species Baccharis in each core.
>>> 
>>> 
>>> I have several doubts about how to analyze the array.
>>> 
>>> 
>>> 1 - As far as I understand, although I'm treating all my factors as 
>> fixed, this is a mixed model because of the interaction between 
>> subjects (the boxes I believe), and the "split plot nature" of the 
>> array, right? In that sense, which function would be better to analyze 
>> this, the aov of the stats package, the lme of the nlme package, the 
>> lmer of lme4?
>>> 
>>> 
>>> 
>>> ?? 2 - I've had trouble calculating the degrees of freedom for the 
>> residuals. The only reference I have is that the error of the whole 
>> plot part should have 12 df's, and the within error should have 60 
>> df's. With that reference I've established two possible R commands:
>>> 
>>> 
>>> fit.aov2 <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF + 
>> Error(rep:salinityF/immersionF:SpecTF), data=sp.datos)
>>> 
>>> 
>>> With rep being the number of repetition. This last one gives the 12 
>> and 60 df's for the error terms.
>>> 
>>> 
>>> The other option is:
>>> 
>>> fit.okay <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= 
>> ~1|rep/salinityF, data=sp.datos)
>>> 
>>> But in this last case, the df's are 8 and 60, which makes me suspect 
>> maybe there is something wrong. But as I said, I haven't cleared my 
>> head on which should be the correct df's.
>>> 
>>> 
>>> Questions: Is the aov line solving a mixed model adequate for my 
>> design?,
>>> 
>>> 
>>> 
>>> ?????????????????????? Is the lme line considering salinityF as a 
>> random factor? If it is, how can I tell it to consider all factors as 
>> fixed, but put salinity at the "higher level" of the whole plot and 
>> the other ones in the "lower level" of the subplot?
>>> 
>>> 
>>> I hope the questions and the experimental array are clear. If there 
>> is any doubt or need more information please let me know. I attach a 
>> csv file with the data in case you want to see it.
>>> 
>>> 
>>> Finally, if is not too much to ask, I'm fairly new to the splitplot 
>> anova's and R, so I would really appreciate if you could answer be 
>> with as much detail as possible, to fully understand what's going on 
>> and where to continue.
>>> 
>>> 
>>> Thanks a lot,
>>> 
>>> 
>>> Felipe Calleja Ap?stegui
>>> 
>>> Predoctoral researcher
>>> 
>>> 
>>> Instituto de Hidr?ulica Ambiental "IH Cantabria"
>>> 
>>> C/ Isabel Torres, N? 15
>>> 
>>> Parque Cient?fico y Tecnol?gico de Cantabria
>>> 
>>> 39011 Santander (Espa?a)
>>> 
>>> www.ihcantabria.es<http://www.ihcantabria.es/>
>>> 
>>> Tel:? +34 942 20 16 16 Ext. 1153
>>> 
>>> Fax: +34 942 26 63 61
>>> 
>>> e-mail: felipe-francisco.calleja at alumnos.unican.es
>>> 
>>> 
>>> 
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From arives at wisc.edu  Wed Apr  4 11:28:02 2018
From: arives at wisc.edu (Anthony R. Ives)
Date: Wed, 4 Apr 2018 09:28:02 +0000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>
References: <000101d3cb30$27b246a0$7716d3e0$@tpg.com.au>
 <CAJuCY5xBL+h2N1HEL+9Mp0VgUqgq0Vxms5HvZrHQ0rVRnQx+Dw@mail.gmail.com>
 <EDE6BCC1-21DF-49ED-AFB4-2F142F974E43@wisc.edu>
 <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>
Message-ID: <41EF5BCE-D4BF-44F8-9FD8-06F1535A29EF@wisc.edu>

Ahmad,

I committed the sin of answering your question before understanding your question. Sorry. My answer now is completely different.

It seems like in your study, you have 75 independent data points (participants). For each participant, the information is the rate of resolution, so the question is how to best characterize this. This depends on the pattern of the data. I?m assuming that you have enough observations per participant, so that you can get a reasonable estimate of the resolution rate for each participant. I?m also assuming that you are interested in log-transforming the data because the injection site volume decays exponentially. If you ignore the zeros for the moment and look at the residuals from fits to each of the 75 participants taken separately, if they look okay (i.e., linear and no obvious heteroscedasticity) on the log scale, then taking the slope is probably fine. I might just ignore the zeros altogether if they don?t add information about the rate of resolution. The goal of the fitting is to get a single number for each participant that best describes the resolution rate. Getting a good description of the resolution rate is a biological question, not a statistical one. You are not going to be using the error structure of these fits to the data from individual participants in your hypothesis test. The hypothesis test would be on the 75 points (resolution rates) for the participants, for which you could use an ANOVA or regression treating each participant as independent.

Of course, this suggestion assumes that you can get reasonable resolution rates for each participant. 

I?ve often had colleagues enthuse about hierarchical models because they ?use all of the data?; there are more data points than would be the case if you aggregate data (such as I?m suggesting ? aggregating the observations for each individual to a single value). However, your data are highly correlated, so if you correctly account for this correlation, then you really have only 75 points. A hierarchical model might help in getting better fits for each participant if you have few observations, but a hierarchical might also cause more statistical problems that are hard to detect. If your treatment effect is strong, aggregating observations to the participant level should detect it. If a test on the aggregated doesn?t detect a pattern while a hierarchical model does, I?d be highly suspicious of the hierarchical model.

Cheers, Tony

On 4/3/18, 7:46 AM, "Ahmad" <ahmadr215 at tpg.com.au> wrote:

    Hi Tony + Thierry
    
    Thanks for your comments and thoughts,
    To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).
    So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.
    
    I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.
    
    Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok? 
    
    The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?
    
    Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.
    
     Thanks
    Ahmad
     
    
    
    
    -----Original Message-----
    From: Anthony R. Ives <arives at wisc.edu> 
    Sent: Tuesday, 3 April 2018 8:41 PM
    To: Ahmad <ahmadr215 at tpg.com.au>
    Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Thierry Onkelinx <thierry.onkelinx at inbo.be>
    Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation
    
    Ahmad,
    
    I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).
    
    Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.
    
    I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.
    
    Cheers, Tony
    
    
    Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.
    
    Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.
    
    
    
    On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org on behalf of thierry.onkelinx at inbo.be> wrote:
    
        Dear Ahmad,
        
        Don't do log(x+1). If you want to see why, then to the analysis with
        log(x+1), log(x+100), log(x+0.001), ... and compare the results.
        
        What is causing the zeros? Are they non-detects? Then you need threat
        this as censored data (see the NADA package). If they are not, then a
        zero-inflated gamma distribution might be an option.
        
        Best regards,
        
        ir. Thierry Onkelinx
        Statisticus / Statistician
        
        Vlaamse Overheid / Government of Flanders
        INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
        AND FOREST
        Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
        thierry.onkelinx at inbo.be
        Havenlaan 88 bus 73, 1000 Brussel
        www.inbo.be
        
        ///////////////////////////////////////////////////////////////////////////////////////////
        To call in the statistician after the experiment is done may be no
        more than asking him to perform a post-mortem examination: he may be
        able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
        The plural of anecdote is not data. ~ Roger Brinner
        The combination of some data and an aching desire for an answer does
        not ensure that a reasonable answer can be extracted from a given body
        of data. ~ John Tukey
        ///////////////////////////////////////////////////////////////////////////////////////////
        
        
        
        
        2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au>:
        > Hi all
        >
        > My question here is related to my previous query on Geometric mean of log
        > data.
        > I have a continuous dataset with considerable number of zero values, and
        > not-normally distributed. Because of zero values, I won't be able to take
        > the log of this variable. It has been suggested by some to add a constant
        > (e.g. +1) to all data to be able to take the log of data. I can then
        > transform back the output of lm() or Mixed-model to the original scale using
        > exp() or emmeans function with "response" method as suggested by Russell
        > (russell-lenth at uiowa.edu).
        >
        > I searched this (adding a constant) and found that views on this approach
        > are not consistent- I would like to see if anyone has experience on how to
        > deal with such data.
        >
        > Your help is greatly appreciated!
        >
        > Ahmad
        >
        > _______________________________________________
        > R-sig-mixed-models at r-project.org mailing list
        > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
        
        _______________________________________________
        R-sig-mixed-models at r-project.org mailing list
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
        
    
    
    


From felipe-francisco.calleja at alumnos.unican.es  Wed Apr  4 12:12:32 2018
From: felipe-francisco.calleja at alumnos.unican.es (CALLEJA APESTEGUI, FELIPE FRANCISCO)
Date: Wed, 4 Apr 2018 10:12:32 +0000
Subject: [R-sig-ME] Help establishing mixed model equation for split,
 plot design
In-Reply-To: <BD437132-1B98-4E0E-BF54-EB2294DEDCB5@glasgow.ac.uk>
References: <mailman.16330.277.1522775768.1209.r-sig-mixed-models@r-project.org>
 <7f7486ff-adab-2700-c3dd-b572b7686d7c@tum.de>
 <AM4P191MB00822B95F5F0150839DDBC9287A40@AM4P191MB0082.EURP191.PROD.OUTLOOK.COM>
 <74c2230b-c5ec-e78c-d35a-9faaba62ef11@tum.de>,
 <BD437132-1B98-4E0E-BF54-EB2294DEDCB5@glasgow.ac.uk>
Message-ID: <AM4P191MB008273D6FA45B7FA33C1D8B087A40@AM4P191MB0082.EURP191.PROD.OUTLOOK.COM>

Thanks everyone.


Samuel, indeed I was refering to missing observations, and due to the lmer considering automatically I won't worry about it.


Thanks Samuel and Paul for the links. I think I'll stay with the lmer model but in case of needing to use the lme I'll check them for help.


Best regards to everyone, you have been of great help.


Felipe Calleja Ap?stegui

Predoctoral researcher


Instituto de Hidr?ulica Ambiental "IH Cantabria"

C/ Isabel Torres, N? 15

Parque Cient?fico y Tecnol?gico de Cantabria

39011 Santander (Espa?a)

www.ihcantabria.es<http://www.ihcantabria.es/>

Tel:  +34 942 20 16 16 Ext. 1153

Fax: +34 942 26 63 61

e-mail: felipe-francisco.calleja at alumnos.unican.es


________________________________
De: Paul Johnson <paul.johnson at glasgow.ac.uk>
Enviado: mi?rcoles, 4 de abril de 2018 11:14:34
Para: Samuel Knapp
Cc: CALLEJA APESTEGUI, FELIPE FRANCISCO; r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Help establishing mixed model equation for split, plot design

Hi,

> Sorry, lme only takes nested random effects

Other designs are possible, e.g. fitting crossed random effects in lme is possible but fiddly. Pinheiro & Bates (Mixed Effects Models in S and S-Plus, 2000, p163-167) show how to do this using pdBlocked.

Best wishes,
Paul




> On 4 Apr 2018, at 11:34, Samuel Knapp <samuel.knapp at tum.de> wrote:
>
> Hi Felipe,
>
>
> please also respond to the mailing list.
>
>
> Sorry, lme only takes nested random effects (see
> https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified).
> In order to use the rep:salinity effect, you could add a column for the
> main plots in your data set:
>
>
> sp.datos$rep_salinityF <- paste(sp.datos$rep,sp.datos$salinityF,paste="_")
>
> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
> ~1|rep_salinityF, data=sp.datos)
>
>
> I hope, it works like this.
>
>
> I'm afraid, I don't fully understand your question regarding equal
> number of samples. Do you mean missing observations? In lme, you need to
> add na.action="na.omit", while lmer is automatically omitting missing
> observations.
>
> You're right, that the ANOVA is doing type III SS. If you're interested
> in other SS type, you could look at the Anova() function from the car
> package. Apparently it can also deal with mixed models. Furthermore, the
> new version of lmerTest can also handle other SS type. See
> https://github.com/runehaubo/lmerTestR/blob/master/pkg_notes/new_lmerTest.pdf
>
>
> Best,
>
> Samuel
>
>
>
> On 04/04/18 10:15, CALLEJA APESTEGUI, FELIPE FRANCISCO wrote:
>>
>> Hi Samuel,
>>
>>
>> first of all thanks a lot for the quick and clear response.
>>
>>
>> As you state, all models give the same results once they are
>> established following your examples. Now I have a clear view about
>> what is really doing the command and how to continue.
>>
>>
>> Just one quick comment. The line:
>>
>> *lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
>> ~**1|rep:salinityF, data=sp.datos)*
>>
>>
>> Throws the following error:
>>
>> *Error in getGroups.data.frame(dataMix, groups) : **invalid formula
>> for groups*
>>
>> I leave it here in case is interesting for you. I've decided to use
>> the lmer package because I have other variables that are not balanced,
>> so I prefer to use the same model in all cases, and that package is
>> working fine.
>>
>> Just one final question. Is there any consideration I should have when
>> working with variables without equal number of samples? I mean,
>> something specific in the command of the lmer I should be careful with
>> or investigate further on. Or does the function itself has all
>> considerations included. i see from the *anova(fit.okay3,
>> ddf="Kenward-Roger") *that the anova is made using the type III SS so
>> I wouldn't have to change that part. *
>> *
>>
>> Also, fyi,? the aov function in the case of not grouping by rep throws
>> the same result as the lmer.
>>
>> Again, I really appreciate your help, it has been a lifesaver.
>>
>> Best regards,
>>
>> *Felipe Calleja Ap?stegui*
>>
>> *Predoctoral researcher*
>>
>> *
>> *
>>
>> *Instituto de Hidr?ulica Ambiental "IH Cantabria"*
>>
>> C/ Isabel Torres, N? 15
>>
>> Parque Cient?fico y Tecnol?gico de Cantabria
>>
>> 39011 Santander (Espa?a)
>>
>> www.ihcantabria.es<http://www.ihcantabria.es> <http://www.ihcantabria.es/>
>>
>> Tel:? +34 942 20 16 16 Ext. 1153
>>
>> Fax: +34 942 26 63 61
>>
>> e-mail: f*elipe-francisco.calleja at alumnos.unican.es*
>>
>>
>> ------------------------------------------------------------------------
>> *De:* Samuel Knapp <samuel.knapp at tum.de>
>> *Enviado:* martes, 3 de abril de 2018 21:26:31
>> *Para:* r-sig-mixed-models at r-project.org; CALLEJA APESTEGUI, FELIPE
>> FRANCISCO
>> *Asunto:* Re: Help establishing mixed model equation for split, plot
>> design
>> Hi Felipe,
>>
>> if I understand the design correctly, it is a split-plot design with
>> salinityF as the whole-plot. Only, if you have arranged the boxes in a
>> way that replicate blocks are formed, you should include the rep effect
>> in a model. These replicate blocks could be, that you always have three
>> boxes with the three different salinity levels grouped together, e.g. on
>> one shelf. If you have simply replicated each box 5 times and they are
>> set up fully randomly, you should not include a repliate block.
>>
>> If you have no missing values, and you specify the right model, both
>> aov() and lme() should give you the same results. I would suggest the
>> following models:
>>
>>
>> # with replicate blocks
>>
>> aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF +
>> Error(rep/salinityF), data=sp.datos)
>>
>> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
>> ~1|rep/salinityF, data=sp.datos)
>>
>> # or with lmer from lme4 package (library (lme4)
>>
>> lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF
>> +(1|rep/salinityF), data=sp.datos)
>>
>> # without replicate blocks (I'm not completely sure, if aov will report
>> the exact same results here)
>>
>> aovmodel <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF +
>> Error(rep:salinityF), data=sp.datos)
>>
>> lmemodel <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
>> ~1|rep:salinityF, data=sp.datos)
>>
>> lmermodel <- lmer(Plantsurvival ~ salinityF*immersionF*SpecTF
>> +(1|rep:salinityF), data=sp.datos)
>>
>>
>> As rep/salinityF is simply a short form for rep+rep:salinityF the
>> difference will be that you have no rep block effect in the models
>> without replicate blocks.
>>
>>
>> If you have no missing values, the point about using a mixed model here
>> is less about variance estimation through a random effect, but
>> automatically getting the right F-Test of the main-plot effect in ANOVA
>> (which is the main part of doing a proper split-plot analysis!!!).
>>
>> My experience is that the anova() function from the lmerTest package
>> will give you the right denominator df when using the Kenward-Roger
>> method. You need to use lmer for this:
>>
>> library(lmerTest)
>>
>> anova(lmermodel,ddf="Kenward-Roger")
>>
>> For proper mean comparisons, I suggest to use the emmeans package, with
>> the Tukey test and letter display from the cld() function:
>>
>> library(emmeans)
>>
>> cld(emmeans(lmermodel,"salinityF") #replace salinityF by the factor you
>> are interested
>>
>>
>> Finally, if you have one or more missing values, aov() will return
>> strange anova tables, thus better use a mixed model!
>>
>>
>> Best regards,
>>
>> Samuel
>>
>> --
>> Samuel Knapp
>>
>> Lehrstuhl f?r Pflanzenern?hrung
>> Technische Universit?t M?nchen
>> (Chair of Plant Nutrition
>> Technical University of Munich)
>>
>> Emil-Ramann-Strasse 2
>> D-85354 Freising
>>
>> Tel. +49 8161 71-3578
>> samuel.knapp at tum.de
>> www.researchgate.net/profile/Samuel_Knapp<http://www.researchgate.net/profile/Samuel_Knapp>
>> <http://www.researchgate.net/profile/Samuel_Knapp>
>>
>>
>>
>> On 03/04/18 19:16, r-sig-mixed-models-request at r-project.org wrote:
>>> Message: 1
>>> Date: Tue, 3 Apr 2018 07:53:15 +0000
>>> From: "CALLEJA APESTEGUI, FELIPE FRANCISCO"
>>> <felipe-francisco.calleja at alumnos.unican.es>
>>> To: "r-sig-mixed-models at r-project.org"
>>> ??????? <r-sig-mixed-models at r-project.org>
>>> Subject: [R-sig-ME] Help establishing mixed model equation for split
>>> ??????? plot design
>>> Message-ID:
>>>
>> <DB6P191MB0088D09AF911107B33C1DE5C87A50 at DB6P191MB0088.EURP191.PROD.OUTLOOK.COM>
>>>
>>> Content-Type: text/plain; charset="iso-8859-1"
>>>
>>> Hello,
>>>
>>>
>>> I'm looking for some help establishing a mixed model ANOVA using R,
>> for a split plot design I've made for an experiment of saltmarsh
>> germination. I'll explain as clear as possible the experimental design
>> and afterwards what I've done and my doubts. Hope you can help me. I
>> haven't worked very much with R so many of my doubts are about what
>> I'm "telling" it to do with one or other command.
>>>
>>>
>>> The experiment consists in meassuring the germination percentage of
>> one species in variable conditions of salinity, immersion time and
>> presence of other species. I sow seeds in soil core's, that are inside
>> plastic boxes that are filled periodically with saline water. There
>> are three factors: salinity (3 levels: 0, 5 and 18), immersion time (3
>> levels: 0, 20, 40%), species treatment (2 levels: Baccharis, Baccharis
>> + Juncus). Inside each box there are 6 cores that combine in a
>> complete random design the factors of immersion and species treatment.
>> The box is filled with water at one of the levels of salinity. Thus,
>> I'm using a split plot design with salinity as the whole plot factor,
>> and immersion and species treatment as the subplot factors. All
>> factors are considered fixed. Each box is repeated 5 times. Thus,
>> there are 15 boxes and 90 soil cores. The dependent variable is the
>> percentage of germination of the species Baccharis in each core.
>>>
>>>
>>> I have several doubts about how to analyze the array.
>>>
>>>
>>> 1 - As far as I understand, although I'm treating all my factors as
>> fixed, this is a mixed model because of the interaction between
>> subjects (the boxes I believe), and the "split plot nature" of the
>> array, right? In that sense, which function would be better to analyze
>> this, the aov of the stats package, the lme of the nlme package, the
>> lmer of lme4?
>>>
>>>
>>>
>>> ?? 2 - I've had trouble calculating the degrees of freedom for the
>> residuals. The only reference I have is that the error of the whole
>> plot part should have 12 df's, and the within error should have 60
>> df's. With that reference I've established two possible R commands:
>>>
>>>
>>> fit.aov2 <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF +
>> Error(rep:salinityF/immersionF:SpecTF), data=sp.datos)
>>>
>>>
>>> With rep being the number of repetition. This last one gives the 12
>> and 60 df's for the error terms.
>>>
>>>
>>> The other option is:
>>>
>>> fit.okay <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random=
>> ~1|rep/salinityF, data=sp.datos)
>>>
>>> But in this last case, the df's are 8 and 60, which makes me suspect
>> maybe there is something wrong. But as I said, I haven't cleared my
>> head on which should be the correct df's.
>>>
>>>
>>> Questions: Is the aov line solving a mixed model adequate for my
>> design?,
>>>
>>>
>>>
>>> ?????????????????????? Is the lme line considering salinityF as a
>> random factor? If it is, how can I tell it to consider all factors as
>> fixed, but put salinity at the "higher level" of the whole plot and
>> the other ones in the "lower level" of the subplot?
>>>
>>>
>>> I hope the questions and the experimental array are clear. If there
>> is any doubt or need more information please let me know. I attach a
>> csv file with the data in case you want to see it.
>>>
>>>
>>> Finally, if is not too much to ask, I'm fairly new to the splitplot
>> anova's and R, so I would really appreciate if you could answer be
>> with as much detail as possible, to fully understand what's going on
>> and where to continue.
>>>
>>>
>>> Thanks a lot,
>>>
>>>
>>> Felipe Calleja Ap?stegui
>>>
>>> Predoctoral researcher
>>>
>>>
>>> Instituto de Hidr?ulica Ambiental "IH Cantabria"
>>>
>>> C/ Isabel Torres, N? 15
>>>
>>> Parque Cient?fico y Tecnol?gico de Cantabria
>>>
>>> 39011 Santander (Espa?a)
>>>
>>> www.ihcantabria.es<http://www.ihcantabria.es/>
>>>
>>> Tel:? +34 942 20 16 16 Ext. 1153
>>>
>>> Fax: +34 942 26 63 61
>>>
>>> e-mail: felipe-francisco.calleja at alumnos.unican.es
>>>
>>>
>>>
>>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jludlam at fitchburgstate.edu  Wed Apr  4 15:55:05 2018
From: jludlam at fitchburgstate.edu (John Ludlam)
Date: Wed, 4 Apr 2018 13:55:05 +0000
Subject: [R-sig-ME] Rules of thumb for model complexity with small sample
 size in lme()
Message-ID: <92897F67-B8D9-4B1B-9D95-78AFF8A0B666@contoso.com>

Hello,

I have an experiment with six streams in two groups (regulated and control).  At each stream there were five sites (Transect).  At each site there were unreplicated nutrient treatments (N, P, N+P, C).  Light was measured at each site.

Stream	Regulated	Transect	Nitrogen	Phosphorus	R	Light
Cranberry	Regulated	30	C	C	-0.102512563	2042.266667
Cranberry	Regulated	30	C	P	-0.08877551	2042.266667
Cranberry	Regulated	50	C	C	-0.107142857	1283.3
Cranberry	Regulated	50	N	C	-0.059375	1283.3
Cranberry	Regulated	70	C	C	-0.067346939	1336.6
Cranberry	Regulated	70	N	C	-0.063636364	1336.6
...

I would like to know if the response differs among groups (regulated vs control) or is related to light or nutrient treatment.  I have two separate analyses, N = 107 and N = 66 with different numbers of missing values (N = 120 before missing values). 

I think the appropriate model structure is:

lme(Response ~ Regulated + Light + Nitrogen + Phosphorus + Nitrogen:Phosphorus), random=~1|Stream/Transect, data=data, method="ML"))

However, I'm concerned that the model is far too complex for my sample size.  Any advice would be appreciated!

Thanks!

John P. Ludlam, Ph.D. - Fitchburg State University




From thierry.onkelinx at inbo.be  Wed Apr  4 17:10:41 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 4 Apr 2018 17:10:41 +0200
Subject: [R-sig-ME] 
 Rules of thumb for model complexity with small sample size in lme()
In-Reply-To: <92897F67-B8D9-4B1B-9D95-78AFF8A0B666@contoso.com>
References: <92897F67-B8D9-4B1B-9D95-78AFF8A0B666@contoso.com>
Message-ID: <CAJuCY5wXf4jmXQ_1A__XN_E-pq0TtwFXGrFMb-2c70m1_T-62A@mail.gmail.com>

Dear John,

Since you don't have replication at the transect level, you should
omit that from the random effects structure.

I tend to strive for at least 10 observations per parameter. More is
better of course. Assuming that Nitrogen and Phosphorus are factors
with two levels, then Regulated + Light + Nitrogen + Phosphorus +
Nitrogen:Phosphorus requires 5 parameters. Add 1 for the random effect
and you have 6 parameters or at least 60 observations. So this model
might work with N = 66. However you will need to carefully check the
model.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-04-04 15:55 GMT+02:00 John Ludlam <jludlam at fitchburgstate.edu>:
> Hello,
>
> I have an experiment with six streams in two groups (regulated and control).  At each stream there were five sites (Transect).  At each site there were unreplicated nutrient treatments (N, P, N+P, C).  Light was measured at each site.
>
> Stream  Regulated       Transect        Nitrogen        Phosphorus      R       Light
> Cranberry       Regulated       30      C       C       -0.102512563    2042.266667
> Cranberry       Regulated       30      C       P       -0.08877551     2042.266667
> Cranberry       Regulated       50      C       C       -0.107142857    1283.3
> Cranberry       Regulated       50      N       C       -0.059375       1283.3
> Cranberry       Regulated       70      C       C       -0.067346939    1336.6
> Cranberry       Regulated       70      N       C       -0.063636364    1336.6
> ...
>
> I would like to know if the response differs among groups (regulated vs control) or is related to light or nutrient treatment.  I have two separate analyses, N = 107 and N = 66 with different numbers of missing values (N = 120 before missing values).
>
> I think the appropriate model structure is:
>
> lme(Response ~ Regulated + Light + Nitrogen + Phosphorus + Nitrogen:Phosphorus), random=~1|Stream/Transect, data=data, method="ML"))
>
> However, I'm concerned that the model is far too complex for my sample size.  Any advice would be appreciated!
>
> Thanks!
>
> John P. Ludlam, Ph.D. - Fitchburg State University
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Apr  4 17:16:21 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Apr 2018 11:16:21 -0400
Subject: [R-sig-ME] 
 Rules of thumb for model complexity with small sample size in lme()
In-Reply-To: <CAJuCY5wXf4jmXQ_1A__XN_E-pq0TtwFXGrFMb-2c70m1_T-62A@mail.gmail.com>
References: <92897F67-B8D9-4B1B-9D95-78AFF8A0B666@contoso.com>
 <CAJuCY5wXf4jmXQ_1A__XN_E-pq0TtwFXGrFMb-2c70m1_T-62A@mail.gmail.com>
Message-ID: <fd535bb4-9ae9-7d4f-2401-19091732340c@gmail.com>


  As I interpret the description, there is actually replication at the
transect level; ~ 2 samples per transect (30 transects, total N=66). In
principle one could even ask if there are variations in the effect of N
and P across transects (this is essentially a very unbalanced
randomized-block design), but I agree that would be unrealistically
optimistic.

  Otherwise I agree with Thierry.

On 18-04-04 11:10 AM, Thierry Onkelinx wrote:
> Dear John,
> 
> Since you don't have replication at the transect level, you should
> omit that from the random effects structure.
> 
> I tend to strive for at least 10 observations per parameter. More is
> better of course. Assuming that Nitrogen and Phosphorus are factors
> with two levels, then Regulated + Light + Nitrogen + Phosphorus +
> Nitrogen:Phosphorus requires 5 parameters. Add 1 for the random effect
> and you have 6 parameters or at least 60 observations. So this model
> might work with N = 66. However you will need to carefully check the
> model.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> 
> 2018-04-04 15:55 GMT+02:00 John Ludlam <jludlam at fitchburgstate.edu>:
>> Hello,
>>
>> I have an experiment with six streams in two groups (regulated and control).  At each stream there were five sites (Transect).  At each site there were unreplicated nutrient treatments (N, P, N+P, C).  Light was measured at each site.
>>
>> Stream  Regulated       Transect        Nitrogen        Phosphorus      R       Light
>> Cranberry       Regulated       30      C       C       -0.102512563    2042.266667
>> Cranberry       Regulated       30      C       P       -0.08877551     2042.266667
>> Cranberry       Regulated       50      C       C       -0.107142857    1283.3
>> Cranberry       Regulated       50      N       C       -0.059375       1283.3
>> Cranberry       Regulated       70      C       C       -0.067346939    1336.6
>> Cranberry       Regulated       70      N       C       -0.063636364    1336.6
>> ...
>>
>> I would like to know if the response differs among groups (regulated vs control) or is related to light or nutrient treatment.  I have two separate analyses, N = 107 and N = 66 with different numbers of missing values (N = 120 before missing values).
>>
>> I think the appropriate model structure is:
>>
>> lme(Response ~ Regulated + Light + Nitrogen + Phosphorus + Nitrogen:Phosphorus), random=~1|Stream/Transect, data=data, method="ML"))
>>
>> However, I'm concerned that the model is far too complex for my sample size.  Any advice would be appreciated!
>>
>> Thanks!
>>
>> John P. Ludlam, Ph.D. - Fitchburg State University
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From tim.cole at ucl.ac.uk  Wed Apr  4 17:35:20 2018
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Wed, 4 Apr 2018 15:35:20 +0000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <DM5PR0901MB229606E9A283083B3EA840FB9AA50@DM5PR0901MB2296.namprd09.prod.outlook.com>
References: <32B5E67B-2E72-4E12-8391-E30041F8821A@ucl.ac.uk>
 <DM5PR0901MB229606E9A283083B3EA840FB9AA50@DM5PR0901MB2296.namprd09.prod.outlook.com>
Message-ID: <B7C860DC-33A8-4B60-BC3A-F79DB5393CC1@ucl.ac.uk>

You can get an approximate standard error by fitting a series of models with different values of the offset d, and then plotting the logs of the model deviances against the corresponding values of d. This plot is a curve which is approximately quadratic in the region of the minimum.

Focussing on the quadratic region, fit a quadratic in d to the log deviances logD:
lm(logD ~ d + I(d^2))
This corresponds to the regression equation:
logD = a + b.d + c.d^2
where a, b and c are the intercept and regression coefficients.

If the sample size is n, then the best estimate of d is -c/(2b) with standard error sqrt(1/nc).

Best wishes,
Tim
--
 tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk> Phone 020 7905 2666
Population Policy and Practice Programme
UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK

From: "Farrar, David" <Farrar.David at epa.gov>
Date: Tuesday, 3 April 2018 at 19:24
To: "Cole, Tim" <tim.cole at ucl.ac.uk>, "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Subject: RE: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation


If you do that with a grid search, how would you get standard errors?  Bootstrap?

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Cole, Tim
Sent: Tuesday, April 03, 2018 1:47 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Thierry is of course right that using 1 or 100 or 0.001 as the offset gives different answers. But for me that doesn?t rule out using an offset, it just means that it needs treating as an extra model parameter to be estimated. This is easy to do with a grid search to minimise the deviance.

You are right to emphasise the continuous nature of your data, and that zero values are not intrinsically different from non-zero values. The case where I come across this is relating body size with age, where age 0 corresponds to birth. Biologically it makes sense to think of time 0 being at -9 months, i.e. conception rather than birth, in which case the appropriate offset is 0.75 years or 9 months.

Best wishes,
Tim
--
tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk><mailto:tim.cole at ucl.ac.uk> Phone 020 7905 2666 Population Policy and Practice Programme UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK

Date: Tue, 3 Apr 2018 22:45:49 +1000
From: "Ahmad" <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au%3e>>
To: "'Anthony R. Ives'" <arives at wisc.edu<mailto:arives at wisc.edu><mailto:arives at wisc.edu><mailto:arives at wisc.edu%3e>>
Cc: "'r-sig-mixed-models'" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org%3e>>,
                "'Thierry Onkelinx'" <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be%3e>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with
                zero values- to use the log transformation
Message-ID: <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au<mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au><mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au><mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au%3e>>
Content-Type: text/plain; charset="utf-8"

Hi Tony + Thierry

Thanks for your comments and thoughts,
To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).
So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.

I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.

Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok?

The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?

Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.

Thanks
Ahmad


-----Original Message-----
From: Anthony R. Ives <arives at wisc.edu<mailto:arives at wisc.edu><mailto:arives at wisc.edu><mailto:arives at wisc.edu%3e>>
Sent: Tuesday, 3 April 2018 8:41 PM
To: Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au%3e>>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org%3e>>; Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be%3e>>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Ahmad,

I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).

Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.

I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.

Cheers, Tony


Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.

Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.


On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be%3e>> wrote:

    Dear Ahmad,

    Don't do log(x+1). If you want to see why, then to the analysis with
    log(x+1), log(x+100), log(x+0.001), ... and compare the results.

    What is causing the zeros? Are they non-detects? Then you need threat
    this as censored data (see the NADA package). If they are not, then a
    zero-inflated gamma distribution might be an option.

    Best regards,

    ir. Thierry Onkelinx
    Statisticus / Statistician

    Vlaamse Overheid / Government of Flanders
    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
    AND FOREST
    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
    thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be>
    Havenlaan 88 bus 73, 1000 Brussel
    www.inbo.be

    ///////////////////////////////////////////////////////////////////////////////////////////
    To call in the statistician after the experiment is done may be no
    more than asking him to perform a post-mortem examination: he may be
    able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
    The plural of anecdote is not data. ~ Roger Brinner
    The combination of some data and an aching desire for an answer does
    not ensure that a reasonable answer can be extracted from a given body
    of data. ~ John Tukey
    ///////////////////////////////////////////////////////////////////////////////////////////




    2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au><mailto:ahmadr215 at tpg.com.au%3e>>:
    > Hi all
    >
    > My question here is related to my previous query on Geometric mean of log
    > data.
    > I have a continuous dataset with considerable number of zero values, and
    > not-normally distributed. Because of zero values, I won't be able to take
    > the log of this variable. It has been suggested by some to add a constant
    > (e.g. +1) to all data to be able to take the log of data. I can then
    > transform back the output of lm() or Mixed-model to the original scale using
    > exp() or emmeans function with "response" method as suggested by Russell
    > (russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu><mailto:russell-lenth at uiowa.edu><mailto:russell-lenth at uiowa.edu%3e>).
    >
    > I searched this (adding a constant) and found that views on this approach
    > are not consistent- I would like to see if anyone has experience on how to
    > deal with such data.
    >
    > Your help is greatly appreciated!
    >
    > Ahmad


                [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From ahmadr215 at tpg.com.au  Thu Apr  5 00:57:56 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Thu, 5 Apr 2018 08:57:56 +1000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <41EF5BCE-D4BF-44F8-9FD8-06F1535A29EF@wisc.edu>
References: <000101d3cb30$27b246a0$7716d3e0$@tpg.com.au>
 <CAJuCY5xBL+h2N1HEL+9Mp0VgUqgq0Vxms5HvZrHQ0rVRnQx+Dw@mail.gmail.com>
 <EDE6BCC1-21DF-49ED-AFB4-2F142F974E43@wisc.edu>
 <000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>
 <41EF5BCE-D4BF-44F8-9FD8-06F1535A29EF@wisc.edu>
Message-ID: <000001d3cc68$60ece7c0$22c6b740$@tpg.com.au>

Hi Tony

Thanks for your comments and thoughts,
You raised interesting concepts here that I didn't think about them before. You are right, I may perhaps haven't explained what the objective of this exercise. I assume this is similar to censoring in survival analysis (but with continuous data), showing in which group the injection site volume resolves sooner- by using the volume data. So, the number of zero in a group means that injection site resolved soon. 

Re aggregation vs. hierarchical approaches, as you pointed out I have 25/group (75 total) with 10-13 observations for each participant.
So, I am not sure to consider this as small or big sample size (or data points) to make a decision about one of these objections. I assume I can run both and see the difference, as you suggested.

Thanks again!
Ahmad



  

-----Original Message-----
From: Anthony R. Ives <arives at wisc.edu> 
Sent: Wednesday, 4 April 2018 7:28 PM
To: Ahmad <ahmadr215 at tpg.com.au>
Cc: 'r-sig-mixed-models' <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

Ahmad,

I committed the sin of answering your question before understanding your question. Sorry. My answer now is completely different.

It seems like in your study, you have 75 independent data points (participants). For each participant, the information is the rate of resolution, so the question is how to best characterize this. This depends on the pattern of the data. I?m assuming that you have enough observations per participant, so that you can get a reasonable estimate of the resolution rate for each participant. I?m also assuming that you are interested in log-transforming the data because the injection site volume decays exponentially. If you ignore the zeros for the moment and look at the residuals from fits to each of the 75 participants taken separately, if they look okay (i.e., linear and no obvious heteroscedasticity) on the log scale, then taking the slope is probably fine. I might just ignore the zeros altogether if they don?t add information about the rate of resolution. The goal of the fitting is to get a single number for each participant that best describes the resolution rate. Getting a good description of the resolution rate is a biological question, not a statistical one. You are not going to be using the error structure of these fits to the data from individual participants in your hypothesis test. The hypothesis test would be on the 75 points (resolution rates) for the participants, for which you could use an ANOVA or regression treating each participant as independent.

Of course, this suggestion assumes that you can get reasonable resolution rates for each participant. 

I?ve often had colleagues enthuse about hierarchical models because they ?use all of the data?; there are more data points than would be the case if you aggregate data (such as I?m suggesting ? aggregating the observations for each individual to a single value). However, your data are highly correlated, so if you correctly account for this correlation, then you really have only 75 points. A hierarchical model might help in getting better fits for each participant if you have few observations, but a hierarchical might also cause more statistical problems that are hard to detect. If your treatment effect is strong, aggregating observations to the participant level should detect it. If a test on the aggregated doesn?t detect a pattern while a hierarchical model does, I?d be highly suspicious of the hierarchical model.

Cheers, Tony

On 4/3/18, 7:46 AM, "Ahmad" <ahmadr215 at tpg.com.au> wrote:

    Hi Tony + Thierry
    
    Thanks for your comments and thoughts,
    To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).
    So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.
    
    I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.
    
    Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok? 
    
    The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?
    
    Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.
    
     Thanks
    Ahmad
     
    
    
    
    -----Original Message-----
    From: Anthony R. Ives <arives at wisc.edu> 
    Sent: Tuesday, 3 April 2018 8:41 PM
    To: Ahmad <ahmadr215 at tpg.com.au>
    Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Thierry Onkelinx <thierry.onkelinx at inbo.be>
    Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation
    
    Ahmad,
    
    I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).
    
    Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.
    
    I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.
    
    Cheers, Tony
    
    
    Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.
    
    Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.
    
    
    
    On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" <r-sig-mixed-models-bounces at r-project.org on behalf of thierry.onkelinx at inbo.be> wrote:
    
        Dear Ahmad,
        
        Don't do log(x+1). If you want to see why, then to the analysis with
        log(x+1), log(x+100), log(x+0.001), ... and compare the results.
        
        What is causing the zeros? Are they non-detects? Then you need threat
        this as censored data (see the NADA package). If they are not, then a
        zero-inflated gamma distribution might be an option.
        
        Best regards,
        
        ir. Thierry Onkelinx
        Statisticus / Statistician
        
        Vlaamse Overheid / Government of Flanders
        INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
        AND FOREST
        Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
        thierry.onkelinx at inbo.be
        Havenlaan 88 bus 73, 1000 Brussel
        www.inbo.be
        
        ///////////////////////////////////////////////////////////////////////////////////////////
        To call in the statistician after the experiment is done may be no
        more than asking him to perform a post-mortem examination: he may be
        able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
        The plural of anecdote is not data. ~ Roger Brinner
        The combination of some data and an aching desire for an answer does
        not ensure that a reasonable answer can be extracted from a given body
        of data. ~ John Tukey
        ///////////////////////////////////////////////////////////////////////////////////////////
        
        
        
        
        2018-04-03 11:42 GMT+02:00 Ahmad <ahmadr215 at tpg.com.au>:
        > Hi all
        >
        > My question here is related to my previous query on Geometric mean of log
        > data.
        > I have a continuous dataset with considerable number of zero values, and
        > not-normally distributed. Because of zero values, I won't be able to take
        > the log of this variable. It has been suggested by some to add a constant
        > (e.g. +1) to all data to be able to take the log of data. I can then
        > transform back the output of lm() or Mixed-model to the original scale using
        > exp() or emmeans function with "response" method as suggested by Russell
        > (russell-lenth at uiowa.edu).
        >
        > I searched this (adding a constant) and found that views on this approach
        > are not consistent- I would like to see if anyone has experience on how to
        > deal with such data.
        >
        > Your help is greatly appreciated!
        >
        > Ahmad
        >
        > _______________________________________________
        > R-sig-mixed-models at r-project.org mailing list
        > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
        
        _______________________________________________
        R-sig-mixed-models at r-project.org mailing list
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
        
    
    
    


From ahmadr215 at tpg.com.au  Thu Apr  5 01:05:05 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Thu, 5 Apr 2018 09:05:05 +1000
Subject: [R-sig-ME] adding a constant to a continuous dataset with zero
 values- to use the log transformation
In-Reply-To: <B7C860DC-33A8-4B60-BC3A-F79DB5393CC1@ucl.ac.uk>
References: <32B5E67B-2E72-4E12-8391-E30041F8821A@ucl.ac.uk>
 <DM5PR0901MB229606E9A283083B3EA840FB9AA50@DM5PR0901MB2296.namprd09.prod.outlook.com>
 <B7C860DC-33A8-4B60-BC3A-F79DB5393CC1@ucl.ac.uk>
Message-ID: <000101d3cc69$600e7930$202b6b90$@tpg.com.au>

Hi Tim

 

Thanks for this, much appreciated!

I will try this to see how it will work.

 

Ahmad

 

 

From: Cole, Tim <tim.cole at ucl.ac.uk> 
Sent: Thursday, 5 April 2018 1:35 AM
To: Farrar, David <Farrar.David at epa.gov>; Ahmad <ahmadr215 at tpg.com.au>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

 

You can get an approximate standard error by fitting a series of models with different values of the offset d, and then plotting the logs of the model deviances against the corresponding values of d. This plot is a curve which is approximately quadratic in the region of the minimum.

 

Focussing on the quadratic region, fit a quadratic in d to the log deviances logD: 

lm(logD ~ d + I(d^2)) 

This corresponds to the regression equation:

logD = a + b.d + c.d^2 

where a, b and c are the intercept and regression coefficients. 

 

If the sample size is n, then the best estimate of d is -c/(2b) with standard error sqrt(1/nc).

 

Best wishes,

Tim

--

  <mailto:tim.cole at ucl.ac.uk> tim.cole at ucl.ac.uk Phone 020 7905 2666

Population Policy and Practice Programme

UCL Great Ormond Street Institute of Child Health, 

30 Guilford Street, London WC1N 1EH, UK

 

From: "Farrar, David" <Farrar.David at epa.gov <mailto:Farrar.David at epa.gov> >
Date: Tuesday, 3 April 2018 at 19:24
To: "Cole, Tim" <tim.cole at ucl.ac.uk <mailto:tim.cole at ucl.ac.uk> >, "r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> " <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> >
Subject: RE: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

 

 

If you do that with a grid search, how would you get standard errors?  Bootstrap?

 

-----Original Message-----

From: R-sig-mixed-models [ <mailto:r-sig-mixed-models-bounces at r-project.org> mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Cole, Tim

Sent: Tuesday, April 03, 2018 1:47 PM

To:  <mailto:r-sig-mixed-models at r-project.org> r-sig-mixed-models at r-project.org

Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

 

Thierry is of course right that using 1 or 100 or 0.001 as the offset gives different answers. But for me that doesn?t rule out using an offset, it just means that it needs treating as an extra model parameter to be estimated. This is easy to do with a grid search to minimise the deviance.

 

You are right to emphasise the continuous nature of your data, and that zero values are not intrinsically different from non-zero values. The case where I come across this is relating body size with age, where age 0 corresponds to birth. Biologically it makes sense to think of time 0 being at -9 months, i.e. conception rather than birth, in which case the appropriate offset is 0.75 years or 9 months.

 

Best wishes,

Tim

--

 <mailto:tim.cole at ucl.ac.uk> tim.cole at ucl.ac.uk< <mailto:tim.cole at ucl.ac.uk> mailto:tim.cole at ucl.ac.uk> Phone 020 7905 2666 Population Policy and Practice Programme UCL Great Ormond Street Institute of Child Health,

30 Guilford Street, London WC1N 1EH, UK

 

Date: Tue, 3 Apr 2018 22:45:49 +1000

From: "Ahmad" < <mailto:ahmadr215 at tpg.com.au> ahmadr215 at tpg.com.au< <mailto:ahmadr215 at tpg.com.au%3e> mailto:ahmadr215 at tpg.com.au>>

To: "'Anthony R. Ives'" < <mailto:arives at wisc.edu> arives at wisc.edu< <mailto:arives at wisc.edu%3e> mailto:arives at wisc.edu>>

Cc: "'r-sig-mixed-models'" < <mailto:r-sig-mixed-models at r-project.org> r-sig-mixed-models at r-project.org< <mailto:r-sig-mixed-models at r-project.org%3e> mailto:r-sig-mixed-models at r-project.org>>,

                "'Thierry Onkelinx'" < <mailto:thierry.onkelinx at inbo.be> thierry.onkelinx at inbo.be< <mailto:thierry.onkelinx at inbo.be%3e> mailto:thierry.onkelinx at inbo.be>>

Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with

                zero values- to use the log transformation

Message-ID: < <mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au> 000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au< <mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au%3e> mailto:000201d3cb49$b3fb7a50$1bf26ef0$@tpg.com.au>>

Content-Type: text/plain; charset="utf-8"

 

Hi Tony + Thierry

 

Thanks for your comments and thoughts,

To answer your first question, these are injection site volume data (cm^3) after injecting a vaccine at X2 and 4X (safety study).

So the injection site volume may resolve sooner in some groups/participants than the others, and then become undetectable (can't be seen with naked eye nor measured) , so these  are considered zero volume. Because this is a repeated measures dataset (continuous data) for a period of 60 days- I assume I need to compare the dataset for the entire 60 days for all treatment groups (and some with zero values). Hope this answers your question.

 

I can see and agree with your point Thierry (not adding a constant log(x+1)) and have seen similar responses from others. Re zero-inflated gamma distribution approach that you are suggesting- I've never done it before. Based on the nature of data (positive continuous with almost log normal distribution), would the results be easily interpretable to non-analytical people? I don't mind to give it a go- if I can understand how to do it.

 

Tony, thanks for your comprehensive comments- Yes I am testing the relationship between a predictor and response variable (volume of injection site reaction to a vaccine)- I intend to use a mixed-model with nlme package. I noticed that the title of your paper is on count data (haven't read it yet- but I will)- but my data is positive continuous data. Are you still suggesting that log(x+1) should be ok?

 

The number of participants are 25/group (3 groups) with 10 observations (repeats) over a 60-day period. I assume it should be considered as a small sample size, but the data points are >100.  So not sure how simulation can sort out the zero values and non-normal distribution of data. Your thoughts?

 

Thanks for your offer, it would be good if I can have a look at a chapter of your book on statistical properties of estimator- back to basic to learn these stuff.

 

Thanks

Ahmad

 

 

-----Original Message-----

From: Anthony R. Ives < <mailto:arives at wisc.edu> arives at wisc.edu< <mailto:arives at wisc.edu%3e> mailto:arives at wisc.edu>>

Sent: Tuesday, 3 April 2018 8:41 PM

To: Ahmad < <mailto:ahmadr215 at tpg.com.au> ahmadr215 at tpg.com.au< <mailto:ahmadr215 at tpg.com.au%3e> mailto:ahmadr215 at tpg.com.au>>

Cc: r-sig-mixed-models < <mailto:r-sig-mixed-models at r-project.org> r-sig-mixed-models at r-project.org< <mailto:r-sig-mixed-models at r-project.org%3e> mailto:r-sig-mixed-models at r-project.org>>; Thierry Onkelinx < <mailto:thierry.onkelinx at inbo.be> thierry.onkelinx at inbo.be< <mailto:thierry.onkelinx at inbo.be%3e> mailto:thierry.onkelinx at inbo.be>>

Subject: Re: [R-sig-ME] adding a constant to a continuous dataset with zero values- to use the log transformation

 

Ahmad,

 

I agree with Thierry that it is important to know where your zeros are coming from. As for whether you can use log(x+1), the answer depends on what you want to know and the characteristics of your data. If you want to know only whether there is a relationship between your predictor and response variables (i.e., significance testing of a slope), then using a log(x+1) transform can have pretty good statistical properties (see Ives 2015 listed below) in terms of type I errors. Generalized Linear Models (GLMs) are the next option, but na?ve application of GLMs can give inflated type I errors. If your dataset is small (<100 points), I?d do simulations to check the type I error rate. Okay, honestly, I?d do simulations regardless of the size of your data. Ways to correct for problems with GLMs are discussed by Warton et al. (2016).

 

Thierry suggests more complicated models depending on the source of your zeros. I don?t know how these methods perform in terms of type I error rates and power, but again, I?d check with simulations.

 

I?ve nearly finished writing a book and software tutorial titled ?A Conceptual Introduction to Correlated Data: Mixed and Phylogenetic Models?. My goal is to discuss basic statistical issues, such as properties of estimators, so that people understand the conceptual ideas underlying the tests they are performing. There is a chapter on the statistical properties of estimators, the problems they can have, and how to identify and fix them using bootstrapping. I?d be happy to send a draft version if you want. Then again, it might be more information than you are interested in.

 

Cheers, Tony

 

 

Ives, A. R. 2015. For testing the significance of regression coefficients, go ahead and log-transform count data. Methods in Ecology and Evolution 6:828?835.

 

Warton, D. I., M. Lyons, J. Stoklosa, and A. R. Ives. 2016. Three points to consider when choosing a LM or GLM test for count data. Methods in Ecology and Evolution 7:882-890.

 

 

On 4/3/18, 5:05 AM, "R-sig-mixed-models on behalf of Thierry Onkelinx" < <mailto:r-sig-mixed-models-bounces at r-project.org> r-sig-mixed-models-bounces at r-project.org< <mailto:r-sig-mixed-models-bounces at r-project.org> mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of  <mailto:thierry.onkelinx at inbo.be> thierry.onkelinx at inbo.be< <mailto:thierry.onkelinx at inbo.be%3e> mailto:thierry.onkelinx at inbo.be>> wrote:

 

    Dear Ahmad,

 

    Don't do log(x+1). If you want to see why, then to the analysis with

    log(x+1), log(x+100), log(x+0.001), ... and compare the results.

 

    What is causing the zeros? Are they non-detects? Then you need threat

    this as censored data (see the NADA package). If they are not, then a

    zero-inflated gamma distribution might be an option.

 

    Best regards,

 

    ir. Thierry Onkelinx

    Statisticus / Statistician

 

    Vlaamse Overheid / Government of Flanders

    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE

    AND FOREST

    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance

     <mailto:thierry.onkelinx at inbo.be> thierry.onkelinx at inbo.be< <mailto:thierry.onkelinx at inbo.be> mailto:thierry.onkelinx at inbo.be>

    Havenlaan 88 bus 73, 1000 Brussel

     <http://www.inbo.be> www.inbo.be

 

    ///////////////////////////////////////////////////////////////////////////////////////////

    To call in the statistician after the experiment is done may be no

    more than asking him to perform a post-mortem examination: he may be

    able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher

    The plural of anecdote is not data. ~ Roger Brinner

    The combination of some data and an aching desire for an answer does

    not ensure that a reasonable answer can be extracted from a given body

    of data. ~ John Tukey

    ///////////////////////////////////////////////////////////////////////////////////////////









    2018-04-03 11:42 GMT+02:00 Ahmad < <mailto:ahmadr215 at tpg.com.au> ahmadr215 at tpg.com.au< <mailto:ahmadr215 at tpg.com.au%3e> mailto:ahmadr215 at tpg.com.au>>:

    > Hi all

    >

    > My question here is related to my previous query on Geometric mean of log

    > data.

    > I have a continuous dataset with considerable number of zero values, and

    > not-normally distributed. Because of zero values, I won't be able to take

    > the log of this variable. It has been suggested by some to add a constant

    > (e.g. +1) to all data to be able to take the log of data. I can then

    > transform back the output of lm() or Mixed-model to the original scale using

    > exp() or emmeans function with "response" method as suggested by Russell

    > ( <mailto:russell-lenth at uiowa.edu> russell-lenth at uiowa.edu< <mailto:russell-lenth at uiowa.edu%3e> mailto:russell-lenth at uiowa.edu>).

    >

    > I searched this (adding a constant) and found that views on this approach

    > are not consistent- I would like to see if anyone has experience on how to

    > deal with such data.

    >

    > Your help is greatly appreciated!

    >

    > Ahmad





                [[alternative HTML version deleted]]



_______________________________________________

 <mailto:R-sig-mixed-models at r-project.org> R-sig-mixed-models at r-project.org mailing list  <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Thu Apr  5 17:45:32 2018
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Thu, 5 Apr 2018 17:45:32 +0200
Subject: [R-sig-ME] Which model types accept the correlation-argument from
 nlme?
Message-ID: <499d1911-3536-435a-6b58-6629d5d0298b@uni-bremen.de>

Dear list,

I am struggling a bit with finding a suitable approach for the following 
problem.

I have 60 samples on a grid, which were sampled six times (bimonthly). 
The 60 samples were not resampled each time, instead the sampling 
location was shifted a few decimeters each time. So, i have six 
individual spatial grids.

The outcome variable are counts of microbial marker genes.

My task is to classically find significant differences in abundance for 
bacterial clades between dates.

My test of choice is glht() from the multcomp packages. This requires a 
model-object from which it calculates Tukey-comparisons of means per 
data. So, classically:

mod <- glm.nb(Abundance ~ Date, data=data)

glht(mod, mcp(Date = "Tukey"),? mcp(Date = "Tukey"), vcov=vcovHC).

Now, since i have likely spatially autocorrelated outcome data, and 
possibly random effects of the time, i set up

amod.null <- lme(fixed=Abundance ~ Date, data = data, random = ~1| Date, 
method="ML") # i think i asked a question about this in this list some 
years ago

and use the update function, applying amod.null to c("corExp", 
"corGaus", "corLin", "corRatio", "corSpher"). I check for the best AIC, 
and subject this model to glht().

So far, so good (i hope).

(Sidequestion: Is the comparison of categorical means of autocorrelated 
measurements affected by the same problems as e.g. performing regression 
analysis between two continous variables, of which at least one is 
autocorrelated?)


It seems that lme() is only for normally distributed data, but my 
outcome variable is seemingly best modelled assuming its negative 
binomially distributed (this was tested with GAMs).

So, i am looking for a model type, which is a) acceptable for glht() or 
other multiple comparison tests, b) allows fixed and random effects, c) 
allows correction of spatial autocorrelated outcome variables, d) 
accepts assumptions of negative-binomial / Poisson

count data.? I was made aware that glmmPQL does a lot of the things i 
want, but it doesnt give p-values afaik, and is not usable with glht().

I am now down to chosing between:

- a glm.nb with correction for heteroscedasticity.

- a lme with random effects and corrections for spatial autocorrelations.

What would an experienced modeller do (i am not)?

Thank you!

-- 
Dr. Tim Richter-Heitmann

University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Thu Apr  5 22:51:58 2018
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 5 Apr 2018 15:51:58 -0500
Subject: [R-sig-ME] "nesting for free" in lme4. Do I have this right?
Message-ID: <CAErODj8Ys+=0VVR1zOa6GW5-akHXgExVMO9nqPwp6MAOJYT-yQ@mail.gmail.com>

I don't (yet) have permission to give you this data, but I've asked
for permission and hope I can show in future if you are interested.

One of the students showed me a model and I said "oh, no, that won't
work" but glmer calculated estimates. He ran a model for US public
opinion with "(1|state) + (1|region)" and I thought it should be "(1 |
region/state)", but it turns out results are the same. This is what I
mean "nesting for free" in lme4.

This author's field of study uses lme4 to calculate shrinkage
estimates for states, gender/ethnic subgroups. Things that I would
treat as individual level fixed effects, like gender, age, and
education, are inserted as random effects. Then they use the
conditional modes for constructing other quantities they want.

After the student ran his model, I suggested instead: "(1 | state)".
This also converges, but the state-by-state effect estimates differ
from the nested model. I thought that was interesting.  The main
purpose here is to retrieve the conditional modes, NOT the variance
estimates.

Which model is better/correct?

Nested

Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: y ~ (1 | regionf/state)
Control: glmerControl(optimizer = "Nelder_Mead")

     AIC      BIC   logLik deviance df.resid
 18888.9  18911.5  -9441.4  18882.9    13875

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.0856 -0.8567 -0.7726  1.1097  1.4309

Random effects:
 Groups        Name        Variance Std.Dev.
 state:regionf (Intercept) 0.05461  0.2337
 regionf       (Intercept) 0.01226  0.1107
Number of obs: 13878, groups:  state:regionf, 50; regionf, 4

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.26732    0.06965  -3.838 0.000124 ***
---


Here are region and first few state conditional modes from the nested model:

$state
                (Intercept)
Alabama        -0.188083365
Alaska         -0.103191227
Arizona         0.049081765
Arkansas       -0.108260203
California      0.436002015
Colorado        0.035086075
Connecticut     0.046271020
Delaware        0.080796357
Florida         0.062439432
...

$regionf
           (Intercept)
Northeast  0.139654257
Midwest   -0.002894665
South     -0.106236023
West      -0.027772517

For reference, the first few random effects from (1 | state) are:

> ranef(individual.modeld)
$state
                (Intercept)
Alabama        -0.260553538
Alaska         -0.116579160
Arizona         0.046677297
Arkansas       -0.172353191
California      0.435397028
Colorado        0.032704790
Connecticut     0.162169289
Delaware        0.057368626
Florida        -0.013638881
....

The "total state effect" for, say, Alabama is the sum of the South
effect and the Alabama effect,
and that's different from the (1 | state) model.

Alabama nested: -0.106236023 -0.188083365 = -0.2943194

Alabama from (1 | state): -0.26

Those are slightly different. Is one better?

Seems to me the difference between the two is simply the shrinkage
effect of the PLS estimator, there's no substantively important
meaning in it.  The shrinkage is applied separately to (1 | region)
and (1 | state). The correlation between region and state effects is
assumed 0.  It is manufacturing 2 random effect layers where there
should be just one.

If state is treated as a fixed effect, of course, the region variable
is unidentifiable. Should the random effect model really be allowed to
manufacture a difference?  That makes me think (1 | state) is the
"right model" and "(1 | region/state)" is different only as an
artifact.

Likelihood ratio test seems to say there is no big difference, which
is a relief.  But what if there were?

individual.modeld: y ~ (1 | state)
individual.modelc: y ~ (1 | regionf/state)
                  Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
individual.modeld  2 18889 18904 -9442.6    18885
individual.modelc  3 18889 18912 -9441.4    18883 2.2477      1     0.1338


More and more, I have the feeling that the random effects model
fabricates an ability to estimate quantities that are not really
indentifiable.  Estimating state-level-random effects on top of
randomly assigned regional scores is only possible because of the
technicalities related to shrinkage. Maybe. I'm not sure, that's why
I'm asking you what you think.

pj
-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From jake.a.westfall at gmail.com  Thu Apr  5 23:07:40 2018
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Thu, 5 Apr 2018 16:07:40 -0500
Subject: [R-sig-ME] "nesting for free" in lme4. Do I have this right?
In-Reply-To: <CAErODj8Ys+=0VVR1zOa6GW5-akHXgExVMO9nqPwp6MAOJYT-yQ@mail.gmail.com>
References: <CAErODj8Ys+=0VVR1zOa6GW5-akHXgExVMO9nqPwp6MAOJYT-yQ@mail.gmail.com>
Message-ID: <CAE9_Wg5Dq26ubb0sGd+EUjSfw2oKNVVhNKtfxDmuVp-_MNGCgA@mail.gmail.com>

Hi Paul,

The "(1|state) + (1|region)" and "(1|region/state)" models are equivalent
if states are explicitly nested (as opposed to implicitly nested) in
regions. Explicitly nested means that the states in each region are labeled
with unique IDs that don't repeat across regions. This equivalence is
because (1|region/state) is just internally expanded to (1|region) +
(1|region:state), but the "region:state" interaction term has the same
number of unique levels as a simple "state" term if all states have unique
IDs.

The model with just "(1|state)" is not equivalent to either of the
aforementioned models. It has fewer parameters and it lumps some of the
region variance in with the state variance.

As for identifiability, because you have many observations within each
state, a model with random effects for both state and region is definitely
identifiable, there shouldn't be any technical or conceptual problem. And
it's probably a better model since it appears there is at least non-trivial
region variance in your data and the model converges fine.

Jake

On Thu, Apr 5, 2018 at 3:51 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:

> I don't (yet) have permission to give you this data, but I've asked
> for permission and hope I can show in future if you are interested.
>
> One of the students showed me a model and I said "oh, no, that won't
> work" but glmer calculated estimates. He ran a model for US public
> opinion with "(1|state) + (1|region)" and I thought it should be "(1 |
> region/state)", but it turns out results are the same. This is what I
> mean "nesting for free" in lme4.
>
> This author's field of study uses lme4 to calculate shrinkage
> estimates for states, gender/ethnic subgroups. Things that I would
> treat as individual level fixed effects, like gender, age, and
> education, are inserted as random effects. Then they use the
> conditional modes for constructing other quantities they want.
>
> After the student ran his model, I suggested instead: "(1 | state)".
> This also converges, but the state-by-state effect estimates differ
> from the nested model. I thought that was interesting.  The main
> purpose here is to retrieve the conditional modes, NOT the variance
> estimates.
>
> Which model is better/correct?
>
> Nested
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
>   Approximation) [glmerMod]
>  Family: binomial  ( logit )
> Formula: y ~ (1 | regionf/state)
> Control: glmerControl(optimizer = "Nelder_Mead")
>
>      AIC      BIC   logLik deviance df.resid
>  18888.9  18911.5  -9441.4  18882.9    13875
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.0856 -0.8567 -0.7726  1.1097  1.4309
>
> Random effects:
>  Groups        Name        Variance Std.Dev.
>  state:regionf (Intercept) 0.05461  0.2337
>  regionf       (Intercept) 0.01226  0.1107
> Number of obs: 13878, groups:  state:regionf, 50; regionf, 4
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -0.26732    0.06965  -3.838 0.000124 ***
> ---
>
>
> Here are region and first few state conditional modes from the nested
> model:
>
> $state
>                 (Intercept)
> Alabama        -0.188083365
> Alaska         -0.103191227
> Arizona         0.049081765
> Arkansas       -0.108260203
> California      0.436002015
> Colorado        0.035086075
> Connecticut     0.046271020
> Delaware        0.080796357
> Florida         0.062439432
> ...
>
> $regionf
>            (Intercept)
> Northeast  0.139654257
> Midwest   -0.002894665
> South     -0.106236023
> West      -0.027772517
>
> For reference, the first few random effects from (1 | state) are:
>
> > ranef(individual.modeld)
> $state
>                 (Intercept)
> Alabama        -0.260553538
> Alaska         -0.116579160
> Arizona         0.046677297
> Arkansas       -0.172353191
> California      0.435397028
> Colorado        0.032704790
> Connecticut     0.162169289
> Delaware        0.057368626
> Florida        -0.013638881
> ....
>
> The "total state effect" for, say, Alabama is the sum of the South
> effect and the Alabama effect,
> and that's different from the (1 | state) model.
>
> Alabama nested: -0.106236023 -0.188083365 = -0.2943194
>
> Alabama from (1 | state): -0.26
>
> Those are slightly different. Is one better?
>
> Seems to me the difference between the two is simply the shrinkage
> effect of the PLS estimator, there's no substantively important
> meaning in it.  The shrinkage is applied separately to (1 | region)
> and (1 | state). The correlation between region and state effects is
> assumed 0.  It is manufacturing 2 random effect layers where there
> should be just one.
>
> If state is treated as a fixed effect, of course, the region variable
> is unidentifiable. Should the random effect model really be allowed to
> manufacture a difference?  That makes me think (1 | state) is the
> "right model" and "(1 | region/state)" is different only as an
> artifact.
>
> Likelihood ratio test seems to say there is no big difference, which
> is a relief.  But what if there were?
>
> individual.modeld: y ~ (1 | state)
> individual.modelc: y ~ (1 | regionf/state)
>                   Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> individual.modeld  2 18889 18904 -9442.6    18885
> individual.modelc  3 18889 18912 -9441.4    18883 2.2477      1     0.1338
>
>
> More and more, I have the feeling that the random effects model
> fabricates an ability to estimate quantities that are not really
> indentifiable.  Estimating state-level-random effects on top of
> randomly assigned regional scores is only possible because of the
> technicalities related to shrinkage. Maybe. I'm not sure, that's why
> I'm asking you what you think.
>
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Apr  6 10:08:34 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 6 Apr 2018 10:08:34 +0200
Subject: [R-sig-ME] "nesting for free" in lme4. Do I have this right?
In-Reply-To: <CAE9_Wg5Dq26ubb0sGd+EUjSfw2oKNVVhNKtfxDmuVp-_MNGCgA@mail.gmail.com>
References: <CAErODj8Ys+=0VVR1zOa6GW5-akHXgExVMO9nqPwp6MAOJYT-yQ@mail.gmail.com>
 <CAE9_Wg5Dq26ubb0sGd+EUjSfw2oKNVVhNKtfxDmuVp-_MNGCgA@mail.gmail.com>
Message-ID: <CAJuCY5yK0A4L4M3=HLNLB1V5q=ZdF6JYnQqoNgy3eTaxgB72bw@mail.gmail.com>

Dear Jake,

IMHO you switched the implicit and explicit nesting. (1|region/state)
is explicit because you tell the model that those should be nested.
Implicit nesting occurs when you add the random effect as crossed
(1|region) + (1|state) but since each state has a unique ID and each
state occurs in only one region, the result is identical to the nested
random effects. Hence the implicit nesting.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-04-05 23:07 GMT+02:00 Jake Westfall <jake.a.westfall at gmail.com>:
> Hi Paul,
>
> The "(1|state) + (1|region)" and "(1|region/state)" models are equivalent
> if states are explicitly nested (as opposed to implicitly nested) in
> regions. Explicitly nested means that the states in each region are labeled
> with unique IDs that don't repeat across regions. This equivalence is
> because (1|region/state) is just internally expanded to (1|region) +
> (1|region:state), but the "region:state" interaction term has the same
> number of unique levels as a simple "state" term if all states have unique
> IDs.
>
> The model with just "(1|state)" is not equivalent to either of the
> aforementioned models. It has fewer parameters and it lumps some of the
> region variance in with the state variance.
>
> As for identifiability, because you have many observations within each
> state, a model with random effects for both state and region is definitely
> identifiable, there shouldn't be any technical or conceptual problem. And
> it's probably a better model since it appears there is at least non-trivial
> region variance in your data and the model converges fine.
>
> Jake
>
> On Thu, Apr 5, 2018 at 3:51 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>
>> I don't (yet) have permission to give you this data, but I've asked
>> for permission and hope I can show in future if you are interested.
>>
>> One of the students showed me a model and I said "oh, no, that won't
>> work" but glmer calculated estimates. He ran a model for US public
>> opinion with "(1|state) + (1|region)" and I thought it should be "(1 |
>> region/state)", but it turns out results are the same. This is what I
>> mean "nesting for free" in lme4.
>>
>> This author's field of study uses lme4 to calculate shrinkage
>> estimates for states, gender/ethnic subgroups. Things that I would
>> treat as individual level fixed effects, like gender, age, and
>> education, are inserted as random effects. Then they use the
>> conditional modes for constructing other quantities they want.
>>
>> After the student ran his model, I suggested instead: "(1 | state)".
>> This also converges, but the state-by-state effect estimates differ
>> from the nested model. I thought that was interesting.  The main
>> purpose here is to retrieve the conditional modes, NOT the variance
>> estimates.
>>
>> Which model is better/correct?
>>
>> Nested
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>   Approximation) [glmerMod]
>>  Family: binomial  ( logit )
>> Formula: y ~ (1 | regionf/state)
>> Control: glmerControl(optimizer = "Nelder_Mead")
>>
>>      AIC      BIC   logLik deviance df.resid
>>  18888.9  18911.5  -9441.4  18882.9    13875
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -1.0856 -0.8567 -0.7726  1.1097  1.4309
>>
>> Random effects:
>>  Groups        Name        Variance Std.Dev.
>>  state:regionf (Intercept) 0.05461  0.2337
>>  regionf       (Intercept) 0.01226  0.1107
>> Number of obs: 13878, groups:  state:regionf, 50; regionf, 4
>>
>> Fixed effects:
>>             Estimate Std. Error z value Pr(>|z|)
>> (Intercept) -0.26732    0.06965  -3.838 0.000124 ***
>> ---
>>
>>
>> Here are region and first few state conditional modes from the nested
>> model:
>>
>> $state
>>                 (Intercept)
>> Alabama        -0.188083365
>> Alaska         -0.103191227
>> Arizona         0.049081765
>> Arkansas       -0.108260203
>> California      0.436002015
>> Colorado        0.035086075
>> Connecticut     0.046271020
>> Delaware        0.080796357
>> Florida         0.062439432
>> ...
>>
>> $regionf
>>            (Intercept)
>> Northeast  0.139654257
>> Midwest   -0.002894665
>> South     -0.106236023
>> West      -0.027772517
>>
>> For reference, the first few random effects from (1 | state) are:
>>
>> > ranef(individual.modeld)
>> $state
>>                 (Intercept)
>> Alabama        -0.260553538
>> Alaska         -0.116579160
>> Arizona         0.046677297
>> Arkansas       -0.172353191
>> California      0.435397028
>> Colorado        0.032704790
>> Connecticut     0.162169289
>> Delaware        0.057368626
>> Florida        -0.013638881
>> ....
>>
>> The "total state effect" for, say, Alabama is the sum of the South
>> effect and the Alabama effect,
>> and that's different from the (1 | state) model.
>>
>> Alabama nested: -0.106236023 -0.188083365 = -0.2943194
>>
>> Alabama from (1 | state): -0.26
>>
>> Those are slightly different. Is one better?
>>
>> Seems to me the difference between the two is simply the shrinkage
>> effect of the PLS estimator, there's no substantively important
>> meaning in it.  The shrinkage is applied separately to (1 | region)
>> and (1 | state). The correlation between region and state effects is
>> assumed 0.  It is manufacturing 2 random effect layers where there
>> should be just one.
>>
>> If state is treated as a fixed effect, of course, the region variable
>> is unidentifiable. Should the random effect model really be allowed to
>> manufacture a difference?  That makes me think (1 | state) is the
>> "right model" and "(1 | region/state)" is different only as an
>> artifact.
>>
>> Likelihood ratio test seems to say there is no big difference, which
>> is a relief.  But what if there were?
>>
>> individual.modeld: y ~ (1 | state)
>> individual.modelc: y ~ (1 | regionf/state)
>>                   Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>> individual.modeld  2 18889 18904 -9442.6    18885
>> individual.modelc  3 18889 18912 -9441.4    18883 2.2477      1     0.1338
>>
>>
>> More and more, I have the feeling that the random effects model
>> fabricates an ability to estimate quantities that are not really
>> indentifiable.  Estimating state-level-random effects on top of
>> randomly assigned regional scores is only possible because of the
>> technicalities related to shrinkage. Maybe. I'm not sure, that's why
>> I'm asking you what you think.
>>
>> pj
>> --
>> Paul E. Johnson   http://pj.freefaculty.org
>> Director, Center for Research Methods and Data Analysis
>> http://crmda.ku.edu
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Fri Apr  6 13:09:49 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 6 Apr 2018 13:09:49 +0200
Subject: [R-sig-ME] 
 Which model types accept the correlation-argument from nlme?
In-Reply-To: <499d1911-3536-435a-6b58-6629d5d0298b@uni-bremen.de>
References: <499d1911-3536-435a-6b58-6629d5d0298b@uni-bremen.de>
Message-ID: <CAJuCY5yB=D3PcM_CTihLK-wD0FjomZsPVH=8z05gPrtxaOS8_Q@mail.gmail.com>

Dear Tim,

I'd go for glmmTMB or INLA because those packages allow for a negative
binomial or Poisson distribution *and* spatially correlated random
effects. Have a look at Zuur et al (2017) Beginner's Guide to
Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-04-05 17:45 GMT+02:00 Tim Richter-Heitmann <trichter at uni-bremen.de>:
> Dear list,
>
> I am struggling a bit with finding a suitable approach for the following
> problem.
>
> I have 60 samples on a grid, which were sampled six times (bimonthly).
> The 60 samples were not resampled each time, instead the sampling
> location was shifted a few decimeters each time. So, i have six
> individual spatial grids.
>
> The outcome variable are counts of microbial marker genes.
>
> My task is to classically find significant differences in abundance for
> bacterial clades between dates.
>
> My test of choice is glht() from the multcomp packages. This requires a
> model-object from which it calculates Tukey-comparisons of means per
> data. So, classically:
>
> mod <- glm.nb(Abundance ~ Date, data=data)
>
> glht(mod, mcp(Date = "Tukey"),  mcp(Date = "Tukey"), vcov=vcovHC).
>
> Now, since i have likely spatially autocorrelated outcome data, and
> possibly random effects of the time, i set up
>
> amod.null <- lme(fixed=Abundance ~ Date, data = data, random = ~1| Date,
> method="ML") # i think i asked a question about this in this list some
> years ago
>
> and use the update function, applying amod.null to c("corExp",
> "corGaus", "corLin", "corRatio", "corSpher"). I check for the best AIC,
> and subject this model to glht().
>
> So far, so good (i hope).
>
> (Sidequestion: Is the comparison of categorical means of autocorrelated
> measurements affected by the same problems as e.g. performing regression
> analysis between two continous variables, of which at least one is
> autocorrelated?)
>
>
> It seems that lme() is only for normally distributed data, but my
> outcome variable is seemingly best modelled assuming its negative
> binomially distributed (this was tested with GAMs).
>
> So, i am looking for a model type, which is a) acceptable for glht() or
> other multiple comparison tests, b) allows fixed and random effects, c)
> allows correction of spatial autocorrelated outcome variables, d)
> accepts assumptions of negative-binomial / Poisson
>
> count data.  I was made aware that glmmPQL does a lot of the things i
> want, but it doesnt give p-values afaik, and is not usable with glht().
>
> I am now down to chosing between:
>
> - a glm.nb with correction for heteroscedasticity.
>
> - a lme with random effects and corrections for spatial autocorrelations.
>
> What would an experienced modeller do (i am not)?
>
> Thank you!
>
> --
> Dr. Tim Richter-Heitmann
>
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jake.a.westfall at gmail.com  Fri Apr  6 16:47:39 2018
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Fri, 6 Apr 2018 09:47:39 -0500
Subject: [R-sig-ME] "nesting for free" in lme4. Do I have this right?
In-Reply-To: <CAJuCY5yK0A4L4M3=HLNLB1V5q=ZdF6JYnQqoNgy3eTaxgB72bw@mail.gmail.com>
References: <CAErODj8Ys+=0VVR1zOa6GW5-akHXgExVMO9nqPwp6MAOJYT-yQ@mail.gmail.com>
 <CAE9_Wg5Dq26ubb0sGd+EUjSfw2oKNVVhNKtfxDmuVp-_MNGCgA@mail.gmail.com>
 <CAJuCY5yK0A4L4M3=HLNLB1V5q=ZdF6JYnQqoNgy3eTaxgB72bw@mail.gmail.com>
Message-ID: <CAE9_Wg4PZo==wgYLss26ShNXK+z3K0bpwSvdVrYm5M332ruyrQ@mail.gmail.com>

Hi Thierry,

I see your point. I usually think of implicit vs. explicit nesting in terms
of how the factor levels are labeled in the dataset: the levels are
explicitly nested if you can see the nesting just from looking at the data
frame, and they're implicitly nested if you can't tell that they're nested
just from looking at the data frame--because they appear to be
crossed--instead you have to have outside, background knowledge about the
dataset. If you instead view the issue from the perspective of the syntax,
then yes, it would make sense to call (1|region/state) explicit and (1|region)
+ (1|state) implicit.

Jake

On Fri, Apr 6, 2018 at 3:08 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Jake,
>
> IMHO you switched the implicit and explicit nesting. (1|region/state)
> is explicit because you tell the model that those should be nested.
> Implicit nesting occurs when you add the random effect as crossed
> (1|region) + (1|state) but since each state has a unique ID and each
> state occurs in only one region, the result is identical to the nested
> random effects. Hence the implicit nesting.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
>
> 2018-04-05 23:07 GMT+02:00 Jake Westfall <jake.a.westfall at gmail.com>:
> > Hi Paul,
> >
> > The "(1|state) + (1|region)" and "(1|region/state)" models are equivalent
> > if states are explicitly nested (as opposed to implicitly nested) in
> > regions. Explicitly nested means that the states in each region are
> labeled
> > with unique IDs that don't repeat across regions. This equivalence is
> > because (1|region/state) is just internally expanded to (1|region) +
> > (1|region:state), but the "region:state" interaction term has the same
> > number of unique levels as a simple "state" term if all states have
> unique
> > IDs.
> >
> > The model with just "(1|state)" is not equivalent to either of the
> > aforementioned models. It has fewer parameters and it lumps some of the
> > region variance in with the state variance.
> >
> > As for identifiability, because you have many observations within each
> > state, a model with random effects for both state and region is
> definitely
> > identifiable, there shouldn't be any technical or conceptual problem. And
> > it's probably a better model since it appears there is at least
> non-trivial
> > region variance in your data and the model converges fine.
> >
> > Jake
> >
> > On Thu, Apr 5, 2018 at 3:51 PM, Paul Johnson <pauljohn32 at gmail.com>
> wrote:
> >
> >> I don't (yet) have permission to give you this data, but I've asked
> >> for permission and hope I can show in future if you are interested.
> >>
> >> One of the students showed me a model and I said "oh, no, that won't
> >> work" but glmer calculated estimates. He ran a model for US public
> >> opinion with "(1|state) + (1|region)" and I thought it should be "(1 |
> >> region/state)", but it turns out results are the same. This is what I
> >> mean "nesting for free" in lme4.
> >>
> >> This author's field of study uses lme4 to calculate shrinkage
> >> estimates for states, gender/ethnic subgroups. Things that I would
> >> treat as individual level fixed effects, like gender, age, and
> >> education, are inserted as random effects. Then they use the
> >> conditional modes for constructing other quantities they want.
> >>
> >> After the student ran his model, I suggested instead: "(1 | state)".
> >> This also converges, but the state-by-state effect estimates differ
> >> from the nested model. I thought that was interesting.  The main
> >> purpose here is to retrieve the conditional modes, NOT the variance
> >> estimates.
> >>
> >> Which model is better/correct?
> >>
> >> Nested
> >>
> >> Generalized linear mixed model fit by maximum likelihood (Laplace
> >>   Approximation) [glmerMod]
> >>  Family: binomial  ( logit )
> >> Formula: y ~ (1 | regionf/state)
> >> Control: glmerControl(optimizer = "Nelder_Mead")
> >>
> >>      AIC      BIC   logLik deviance df.resid
> >>  18888.9  18911.5  -9441.4  18882.9    13875
> >>
> >> Scaled residuals:
> >>     Min      1Q  Median      3Q     Max
> >> -1.0856 -0.8567 -0.7726  1.1097  1.4309
> >>
> >> Random effects:
> >>  Groups        Name        Variance Std.Dev.
> >>  state:regionf (Intercept) 0.05461  0.2337
> >>  regionf       (Intercept) 0.01226  0.1107
> >> Number of obs: 13878, groups:  state:regionf, 50; regionf, 4
> >>
> >> Fixed effects:
> >>             Estimate Std. Error z value Pr(>|z|)
> >> (Intercept) -0.26732    0.06965  -3.838 0.000124 ***
> >> ---
> >>
> >>
> >> Here are region and first few state conditional modes from the nested
> >> model:
> >>
> >> $state
> >>                 (Intercept)
> >> Alabama        -0.188083365
> >> Alaska         -0.103191227
> >> Arizona         0.049081765
> >> Arkansas       -0.108260203
> >> California      0.436002015
> >> Colorado        0.035086075
> >> Connecticut     0.046271020
> >> Delaware        0.080796357
> >> Florida         0.062439432
> >> ...
> >>
> >> $regionf
> >>            (Intercept)
> >> Northeast  0.139654257
> >> Midwest   -0.002894665
> >> South     -0.106236023
> >> West      -0.027772517
> >>
> >> For reference, the first few random effects from (1 | state) are:
> >>
> >> > ranef(individual.modeld)
> >> $state
> >>                 (Intercept)
> >> Alabama        -0.260553538
> >> Alaska         -0.116579160
> >> Arizona         0.046677297
> >> Arkansas       -0.172353191
> >> California      0.435397028
> >> Colorado        0.032704790
> >> Connecticut     0.162169289
> >> Delaware        0.057368626
> >> Florida        -0.013638881
> >> ....
> >>
> >> The "total state effect" for, say, Alabama is the sum of the South
> >> effect and the Alabama effect,
> >> and that's different from the (1 | state) model.
> >>
> >> Alabama nested: -0.106236023 -0.188083365 = -0.2943194
> >>
> >> Alabama from (1 | state): -0.26
> >>
> >> Those are slightly different. Is one better?
> >>
> >> Seems to me the difference between the two is simply the shrinkage
> >> effect of the PLS estimator, there's no substantively important
> >> meaning in it.  The shrinkage is applied separately to (1 | region)
> >> and (1 | state). The correlation between region and state effects is
> >> assumed 0.  It is manufacturing 2 random effect layers where there
> >> should be just one.
> >>
> >> If state is treated as a fixed effect, of course, the region variable
> >> is unidentifiable. Should the random effect model really be allowed to
> >> manufacture a difference?  That makes me think (1 | state) is the
> >> "right model" and "(1 | region/state)" is different only as an
> >> artifact.
> >>
> >> Likelihood ratio test seems to say there is no big difference, which
> >> is a relief.  But what if there were?
> >>
> >> individual.modeld: y ~ (1 | state)
> >> individual.modelc: y ~ (1 | regionf/state)
> >>                   Df   AIC   BIC  logLik deviance  Chisq Chi Df
> Pr(>Chisq)
> >> individual.modeld  2 18889 18904 -9442.6    18885
> >> individual.modelc  3 18889 18912 -9441.4    18883 2.2477      1
>  0.1338
> >>
> >>
> >> More and more, I have the feeling that the random effects model
> >> fabricates an ability to estimate quantities that are not really
> >> indentifiable.  Estimating state-level-random effects on top of
> >> randomly assigned regional scores is only possible because of the
> >> technicalities related to shrinkage. Maybe. I'm not sure, that's why
> >> I'm asking you what you think.
> >>
> >> pj
> >> --
> >> Paul E. Johnson   http://pj.freefaculty.org
> >> Director, Center for Research Methods and Data Analysis
> >> http://crmda.ku.edu
> >>
> >> To write to me directly, please address me at pauljohn at ku.edu.
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Apr  6 17:16:56 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Apr 2018 11:16:56 -0400
Subject: [R-sig-ME] "nesting for free" in lme4. Do I have this right?
In-Reply-To: <CAE9_Wg4PZo==wgYLss26ShNXK+z3K0bpwSvdVrYm5M332ruyrQ@mail.gmail.com>
References: <CAErODj8Ys+=0VVR1zOa6GW5-akHXgExVMO9nqPwp6MAOJYT-yQ@mail.gmail.com>
 <CAE9_Wg5Dq26ubb0sGd+EUjSfw2oKNVVhNKtfxDmuVp-_MNGCgA@mail.gmail.com>
 <CAJuCY5yK0A4L4M3=HLNLB1V5q=ZdF6JYnQqoNgy3eTaxgB72bw@mail.gmail.com>
 <CAE9_Wg4PZo==wgYLss26ShNXK+z3K0bpwSvdVrYm5M332ruyrQ@mail.gmail.com>
Message-ID: <CABghstRHr6KiLi3LwWFsiA7hPO5Q3v7zbNcJpZGJA6CKM7BTHw@mail.gmail.com>

I agree that the terminology could go either way.  FWIW the GLMM FAQ
uses Thierry's convention, i.e. "If the lower-level random effect has
the same labels within each larger group (e.g. blocks 1, 2, 3, 4
within sites A, B, and C) then the explicit nesting (1|a/b) is
required. It seems to be considered best practice to code the nested
level uniquely (e.g. A1, A2, ?, B1, B2, ?) so that confusion between
nested and crossed effects is less likely" (similarly in my chapter 14
of Fox et al's Ecological Statistics book).

On Fri, Apr 6, 2018 at 10:47 AM, Jake Westfall
<jake.a.westfall at gmail.com> wrote:
> Hi Thierry,
>
> I see your point. I usually think of implicit vs. explicit nesting in terms
> of how the factor levels are labeled in the dataset: the levels are
> explicitly nested if you can see the nesting just from looking at the data
> frame, and they're implicitly nested if you can't tell that they're nested
> just from looking at the data frame--because they appear to be
> crossed--instead you have to have outside, background knowledge about the
> dataset. If you instead view the issue from the perspective of the syntax,
> then yes, it would make sense to call (1|region/state) explicit and (1|region)
> + (1|state) implicit.
>
> Jake
>
> On Fri, Apr 6, 2018 at 3:08 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Jake,
>>
>> IMHO you switched the implicit and explicit nesting. (1|region/state)
>> is explicit because you tell the model that those should be nested.
>> Implicit nesting occurs when you add the random effect as crossed
>> (1|region) + (1|state) but since each state has a unique ID and each
>> state occurs in only one region, the result is identical to the nested
>> random effects. Hence the implicit nesting.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>>
>>
>>
>> 2018-04-05 23:07 GMT+02:00 Jake Westfall <jake.a.westfall at gmail.com>:
>> > Hi Paul,
>> >
>> > The "(1|state) + (1|region)" and "(1|region/state)" models are equivalent
>> > if states are explicitly nested (as opposed to implicitly nested) in
>> > regions. Explicitly nested means that the states in each region are
>> labeled
>> > with unique IDs that don't repeat across regions. This equivalence is
>> > because (1|region/state) is just internally expanded to (1|region) +
>> > (1|region:state), but the "region:state" interaction term has the same
>> > number of unique levels as a simple "state" term if all states have
>> unique
>> > IDs.
>> >
>> > The model with just "(1|state)" is not equivalent to either of the
>> > aforementioned models. It has fewer parameters and it lumps some of the
>> > region variance in with the state variance.
>> >
>> > As for identifiability, because you have many observations within each
>> > state, a model with random effects for both state and region is
>> definitely
>> > identifiable, there shouldn't be any technical or conceptual problem. And
>> > it's probably a better model since it appears there is at least
>> non-trivial
>> > region variance in your data and the model converges fine.
>> >
>> > Jake
>> >
>> > On Thu, Apr 5, 2018 at 3:51 PM, Paul Johnson <pauljohn32 at gmail.com>
>> wrote:
>> >
>> >> I don't (yet) have permission to give you this data, but I've asked
>> >> for permission and hope I can show in future if you are interested.
>> >>
>> >> One of the students showed me a model and I said "oh, no, that won't
>> >> work" but glmer calculated estimates. He ran a model for US public
>> >> opinion with "(1|state) + (1|region)" and I thought it should be "(1 |
>> >> region/state)", but it turns out results are the same. This is what I
>> >> mean "nesting for free" in lme4.
>> >>
>> >> This author's field of study uses lme4 to calculate shrinkage
>> >> estimates for states, gender/ethnic subgroups. Things that I would
>> >> treat as individual level fixed effects, like gender, age, and
>> >> education, are inserted as random effects. Then they use the
>> >> conditional modes for constructing other quantities they want.
>> >>
>> >> After the student ran his model, I suggested instead: "(1 | state)".
>> >> This also converges, but the state-by-state effect estimates differ
>> >> from the nested model. I thought that was interesting.  The main
>> >> purpose here is to retrieve the conditional modes, NOT the variance
>> >> estimates.
>> >>
>> >> Which model is better/correct?
>> >>
>> >> Nested
>> >>
>> >> Generalized linear mixed model fit by maximum likelihood (Laplace
>> >>   Approximation) [glmerMod]
>> >>  Family: binomial  ( logit )
>> >> Formula: y ~ (1 | regionf/state)
>> >> Control: glmerControl(optimizer = "Nelder_Mead")
>> >>
>> >>      AIC      BIC   logLik deviance df.resid
>> >>  18888.9  18911.5  -9441.4  18882.9    13875
>> >>
>> >> Scaled residuals:
>> >>     Min      1Q  Median      3Q     Max
>> >> -1.0856 -0.8567 -0.7726  1.1097  1.4309
>> >>
>> >> Random effects:
>> >>  Groups        Name        Variance Std.Dev.
>> >>  state:regionf (Intercept) 0.05461  0.2337
>> >>  regionf       (Intercept) 0.01226  0.1107
>> >> Number of obs: 13878, groups:  state:regionf, 50; regionf, 4
>> >>
>> >> Fixed effects:
>> >>             Estimate Std. Error z value Pr(>|z|)
>> >> (Intercept) -0.26732    0.06965  -3.838 0.000124 ***
>> >> ---
>> >>
>> >>
>> >> Here are region and first few state conditional modes from the nested
>> >> model:
>> >>
>> >> $state
>> >>                 (Intercept)
>> >> Alabama        -0.188083365
>> >> Alaska         -0.103191227
>> >> Arizona         0.049081765
>> >> Arkansas       -0.108260203
>> >> California      0.436002015
>> >> Colorado        0.035086075
>> >> Connecticut     0.046271020
>> >> Delaware        0.080796357
>> >> Florida         0.062439432
>> >> ...
>> >>
>> >> $regionf
>> >>            (Intercept)
>> >> Northeast  0.139654257
>> >> Midwest   -0.002894665
>> >> South     -0.106236023
>> >> West      -0.027772517
>> >>
>> >> For reference, the first few random effects from (1 | state) are:
>> >>
>> >> > ranef(individual.modeld)
>> >> $state
>> >>                 (Intercept)
>> >> Alabama        -0.260553538
>> >> Alaska         -0.116579160
>> >> Arizona         0.046677297
>> >> Arkansas       -0.172353191
>> >> California      0.435397028
>> >> Colorado        0.032704790
>> >> Connecticut     0.162169289
>> >> Delaware        0.057368626
>> >> Florida        -0.013638881
>> >> ....
>> >>
>> >> The "total state effect" for, say, Alabama is the sum of the South
>> >> effect and the Alabama effect,
>> >> and that's different from the (1 | state) model.
>> >>
>> >> Alabama nested: -0.106236023 -0.188083365 = -0.2943194
>> >>
>> >> Alabama from (1 | state): -0.26
>> >>
>> >> Those are slightly different. Is one better?
>> >>
>> >> Seems to me the difference between the two is simply the shrinkage
>> >> effect of the PLS estimator, there's no substantively important
>> >> meaning in it.  The shrinkage is applied separately to (1 | region)
>> >> and (1 | state). The correlation between region and state effects is
>> >> assumed 0.  It is manufacturing 2 random effect layers where there
>> >> should be just one.
>> >>
>> >> If state is treated as a fixed effect, of course, the region variable
>> >> is unidentifiable. Should the random effect model really be allowed to
>> >> manufacture a difference?  That makes me think (1 | state) is the
>> >> "right model" and "(1 | region/state)" is different only as an
>> >> artifact.
>> >>
>> >> Likelihood ratio test seems to say there is no big difference, which
>> >> is a relief.  But what if there were?
>> >>
>> >> individual.modeld: y ~ (1 | state)
>> >> individual.modelc: y ~ (1 | regionf/state)
>> >>                   Df   AIC   BIC  logLik deviance  Chisq Chi Df
>> Pr(>Chisq)
>> >> individual.modeld  2 18889 18904 -9442.6    18885
>> >> individual.modelc  3 18889 18912 -9441.4    18883 2.2477      1
>>  0.1338
>> >>
>> >>
>> >> More and more, I have the feeling that the random effects model
>> >> fabricates an ability to estimate quantities that are not really
>> >> indentifiable.  Estimating state-level-random effects on top of
>> >> randomly assigned regional scores is only possible because of the
>> >> technicalities related to shrinkage. Maybe. I'm not sure, that's why
>> >> I'm asking you what you think.
>> >>
>> >> pj
>> >> --
>> >> Paul E. Johnson   http://pj.freefaculty.org
>> >> Director, Center for Research Methods and Data Analysis
>> >> http://crmda.ku.edu
>> >>
>> >> To write to me directly, please address me at pauljohn at ku.edu.
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From moarmani at outlook.com  Sat Apr  7 08:02:44 2018
From: moarmani at outlook.com (Mohammed Armani)
Date: Sat, 7 Apr 2018 06:02:44 +0000
Subject: [R-sig-ME] Factor level contrasts and associated fixed effect
 priors in MCMCglmm
Message-ID: <HK0PR02MB23538342F9A30173D1097A1BC6B90@HK0PR02MB2353.apcprd02.prod.outlook.com>

Deal all,
I am running a phylogenetic binary model in the package MCMCglmm (The response variable being Resp (0, 1)). One of my predictors is a categorical variable (with 3 levels: T1, T2 and T3) and I would like to set-up the model to explicitly test for differences between the levels of this factor (i.e. T1 vs T2; T1 vs T3 and T2 vs T3). I am following the GLMM worked example of https://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html and proceeded as follows:

contrs<-matrix(c(0,1,0,
                 -1,0,1,
                 0,-1,1),
               byrow=TRUE, ncol=3,
               dimnames=list(c("T1 vs T2",
                               " T1 vs T3 ",
                               " T2 vs T3"),
                             levels(data$T)))

sol_ctr<-solve(contrs)

newmat1<-model.matrix(~T,data=data,
                     contrasts=list(T=sol_ctr1))

datar <- with(data,data.frame(Resp,T,phylo,
                                   newmat1[,-1]))
mod_1<-MCMCglmm(Resp~ T1 vs T2+ T1 vs T3 + T2 vs T3-1,random=~phylo,family="categorical",
                 ginverse=list(phylo=inv.phylo1$Ainv),prior=prior,trunc=TRUE,
                 data=datar,nitt=3e6,burnin=3000,thin=1500)

Question:

1.       First, I would be grateful to receive some feedback if I am doing the right thing with setting the contrasts!

2.       Secondly, one of the factor levels (T2) has only success in the response variable (all=1). I understand from the MCMCglmm course note that in such instances a fixed effect prior such as B=list (mu=c (0, 3), V=diag (3)*(1+pi^2/3) can be applied. However, in the instance where an explicit contrasts is specified as I have done, I am unsure of how to specify the contrast for the fixed effect terms

Thanks.

Armani M


	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Sat Apr  7 15:47:07 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Sat, 7 Apr 2018 15:47:07 +0200
Subject: [R-sig-ME] Why does treatment coding always result in a correlation
 between random slope and intercept?
Message-ID: <CAHr4Dyd9BOpsYAeEUy3wFEY9-9EaCf0r1N7nDYgUapwV9zBWMg@mail.gmail.com>

Dear list,

Consider a within-subject and within-item factorial design where the
experimental treatment variable has two levels (conditions). Let m1 be the
maximal model, m2 the no-within-unit-intercepts model and m3 the
no-random-correlation model:

m1: y ~ condition + (condition|subject) + (condition|item)
m2: y ~ condition + (0 + condition|subject) + (0 + condition|item)
m3: y ~ condition + (1|subject) + (0 + condition|subject) + (1|item) + (0 +
condition|item)

Dale Barr states the following for this situation [1]:
In a deviation-coding representation (condition: -0.5 vs. 0.5) both models,
m1 and m2, allow distributions, where subject's random intercepts are
uncorrelated with subject's random slopes. Only a maximal model allows
distributions, where the two are correlated.

In the treatment-coding representation (condition: 0 vs. 1) these
distributions, where subject's random intercepts are uncorrelated with
subject's random slopes, cannot be fitted using the no-random-correlations
model, *since in each case there is a correlation between random slope and
intercept in the treatment-coding representation.*

Why does treatment coding always result in a correlation between random
slope and intercept?

Please note that I asked the question on Stack Exchange [2] about 10 days
ago.

Regards,
Maarten

[1] http://talklab.psy.gla.ac.uk/simgen/rsonly.html
[2]
https://stats.stackexchange.com/questions/337158/why-does-treatment-coding-always-result-in-a-correlation-between-random-slope-an

	[[alternative HTML version deleted]]


From jrosen at msu.edu  Fri Apr  6 22:53:49 2018
From: jrosen at msu.edu (Joshua Rosenberg)
Date: Fri, 6 Apr 2018 16:53:49 -0400
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8367CF56A@FHSDB2D11-2.csu.mcmaster.ca>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
 <1522599652.9262.10.camel@uchicago.edu>
 <CABghstTvB+97Hkn2r2g3GbMzqG3NBkj4DkbZGp9T5EhO82qF_w@mail.gmail.com>
 <4484_1522775758_w33HFvIo009852_CANYHYTSr3cAMZW3xu4pOCJ99k1xQEvQprFiPNKa+jHdbaDMoDw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367CF56A@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CANYHYTR+PiBe0zUARrd6=mrN0aJOKcENJRduRsup5DJTUBXkTA@mail.gmail.com>

Dear John,

Thank you so much--will use poly in the future (even in cases in which I
might *not* use orthogonal polynomials), as it appears that the summary
function returns helpful output (i.e., correlations fo the fixed effects),
in addition to its other benefits.

When I use the poly function, the random effects correlations are lower:

Random effects:
 Formula: ~+poly(wave, 2) | student_ID
 Structure: General positive-definite, Log-Cholesky parametrization
               StdDev     Corr
(Intercept)      2.178734 (Intr) p(,2)1
poly(wave, 2)1 279.521839 0.834
poly(wave, 2)2 281.979199 0.751  0.987
Residual        16.292629

As are the fixed effects:

Fixed effects: stwm ~ +poly(wave, 2)
                   Value Std.Error   DF   t-value p-value
(Intercept)      5.30155  0.231096 7070 22.940957       0
poly(wave, 2)1 196.33516 23.481935 7070  8.361115       0
poly(wave, 2)2 113.69005 23.591988 7070  4.819011       0
 Correlation:
               (Intr) p(,2)1
poly(wave, 2)1 0.344
poly(wave, 2)2 0.311  0.516

However, when I calculate individual (i.e., group)-specific predicted
values (i.e., BLUPs, using the predict() method, with level = 1), they are
(very) highly correlated:

# A tibble: 3 x 4
  rowname   intercept linear quadratic
  <chr>         <dbl>  <dbl>     <dbl>
1 intercept    NA      0.960     0.960
2 linear        0.960 NA         1.00
3 quadratic     0.960  1.00     NA

When I calculate the same individual-specific predicted values using the
non-orthogonal (raw) polynomials, these correlations are very nearly as
high. At this point, I'm curious how / why these predictions are so highly
correlated.

Thank you again for your help, John, and for yours, Ben, Stuart, Jorg, and
Thierry. Sorry if this is a beginner or otherwise ignorant question as I
learn to work with these longitudinal / polynomial models.
josh

On Tue, Apr 3, 2018 at 1:32 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Joshua,
>
> I'm chiming in late, so it's possible that someone already pointed this
> out and I didn't notice. A better way to specify a polynomial in R is to
> use poly() in the model formula. By default, this produces orthogonal
> polynomial regressors (at least in the fixed effects) but the same fit to
> the data. For example,
>
> > time <- 1:5
> > X <- poly(time, 2)
>
> > X
>               1          2
> [1,] -0.6324555  0.5345225
> [2,] -0.3162278 -0.2672612
> [3,]  0.0000000 -0.5345225
> [4,]  0.3162278 -0.2672612
> [5,]  0.6324555  0.5345225
> attr(,"coefs")
> attr(,"coefs")$alpha
> [1] 3 3
>
> attr(,"coefs")$norm2
> [1]  1  5 10 14
>
> attr(,"degree")
> [1] 1 2
> attr(,"class")
> [1] "poly"   "matrix"
>
> > colSums(X)
>            1            2
> 0.000000e+00 1.110223e-16
>
> > crossprod(X)
>               1             2
> 1  1.000000e+00 -1.110223e-16
> 2 -1.110223e-16  1.000000e+00
>
> My guess is that this will also reduce the correlations among the random
> effects. If you really must have raw polynomials, then poly(time, 2,
> raw=TRUE) offers the advantage that model-structure-aware functions can
> understand that the linear and quadratic regressors are part of the same
> term in the model.
>
> Whether high correlations among the random effects are really a problem,
> my guess is that they aren't, because lme() uses a log-Cholesky
> factorization of the random-effects covariance matrix anyway. In some
> contexts, high correlations might produce numerical instability, but, as I
> said, probably not here. Ben would know.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
>
>
>
>
>
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-
> bounces at r-project.org]
> > On Behalf Of Joshua Rosenberg
> > Sent: Monday, April 2, 2018 5:33 PM
> > To: Ben Bolker <bbolker at gmail.com>
> > Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
> > Subject: Re: [R-sig-ME] High correlation among random effects for
> longitudinal
> > model
> >
> > Dear Stuart and Ben,
> >
> > Thank you, this worked to significantly reduce the correlations between
> the
> > intercept and the linear and quadratic terms (though still quite high
> between the
> > linear and quadratic term):
> >
> > Random effects:
> >  Formula: ~time + I(time^2) | student_ID
> >  Structure: General positive-definite, Log-Cholesky parametrization
> >             StdDev    Corr
> > (Intercept) 18.671959 (Intr) time
> > time        11.029842 -0.262
> > I(time^2)    8.359834 -0.506  0.959
> > Residual    29.006598
> >
> > Could I ask if that correlation between the linear (time) and quadratic
> > I(time^2) terms is cause for concern - and if so, how to think about
> > (potentially) addressing this?
> > Josh
> >
> > On Sun, Apr 1, 2018 at 12:34 PM Ben Bolker <bbolker at gmail.com> wrote:
> >
> > > On Sun, Apr 1, 2018 at 12:20 PM, Stuart Luppescu <lupp at uchicago.edu>
> > > wrote:
> > > > On Sun, 2018-04-01 at 12:55 +0000, Joshua Rosenberg wrote:
> > > >> lme(outcome ~ time + I(time^2),
> > > >>     random = ~ time + I(time^2),
> > > >>     correlation = corAR1(form = ~ time | individual_ID),
> > > >>     data = d_grouped)
> > > >>
> > > >> I have a question / concerns about the random effects, as they are
> > > >> highly correlated (intercept and linear term = -.95; intercept and
> > > >> quadratic term = .96; linear term and quadratic term = -.995):
> > > >
> > > > I think this is an ordinary occurrence for the intercept and time
> > > > trend to be negatively correlated. The way to avoid this is to
> > > > center the time variable at a point in the middle of the series, so,
> > > > instead of setting the values of time to {0, 1, 2, 3, 4} use {-2,
> -1, 0, 1, 2}.
> > > >
> > >
> > >   Agreed.  This is closely related, but not identical to, the
> > > phenomenon where the *fixed effects* are highly correlated.
> > >
> > > > --
> > > > Stuart Luppescu
> > > > Chief Psychometrician (ret.)
> > > > UChicago Consortium on School Research
> > > > http://consortium.uchicago.edu
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > --
> > Joshua Rosenberg, Ph.D. Candidate
> > Educational Psychology ?&? Educational Technology Michigan State
> University
> > http://jmichaelrosenberg.com
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From jrosen at msu.edu  Sat Apr  7 17:31:13 2018
From: jrosen at msu.edu (Joshua Rosenberg)
Date: Sat, 07 Apr 2018 15:31:13 +0000
Subject: [R-sig-ME] 
 High correlation among random effects for longitudinal model
In-Reply-To: <CANYHYTR+PiBe0zUARrd6=mrN0aJOKcENJRduRsup5DJTUBXkTA@mail.gmail.com>
References: <CANYHYTTo-Vvu=P9HfJgdiH7Laf-5bNyHdAGBttkKrht8Fsjc_A@mail.gmail.com>
 <1522599652.9262.10.camel@uchicago.edu>
 <CABghstTvB+97Hkn2r2g3GbMzqG3NBkj4DkbZGp9T5EhO82qF_w@mail.gmail.com>
 <4484_1522775758_w33HFvIo009852_CANYHYTSr3cAMZW3xu4pOCJ99k1xQEvQprFiPNKa+jHdbaDMoDw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367CF56A@FHSDB2D11-2.csu.mcmaster.ca>
 <CANYHYTR+PiBe0zUARrd6=mrN0aJOKcENJRduRsup5DJTUBXkTA@mail.gmail.com>
Message-ID: <CANYHYTQmKBPG=pzoqejBVv3X3kqhKThNVrg2x6EU9YroZ6-DFg@mail.gmail.com>

John et al., please ignore my question, I was a) confusing two things (I
wasn't using the predict() method, but rather ranef()) and b) the
correlations are high but not as high as I thought (closer to .95 than 1) -
due to an error in how I was calculating the individual-specific
predictions using ranef().

Thanks again.
Josh

On Fri, Apr 6, 2018 at 4:53 PM Joshua Rosenberg <jrosen at msu.edu> wrote:

> Dear John,
>
> Thank you so much--will use poly in the future (even in cases in which I
> might *not* use orthogonal polynomials), as it appears that the summary
> function returns helpful output (i.e., correlations fo the fixed effects),
> in addition to its other benefits.
>
> When I use the poly function, the random effects correlations are lower:
>
> Random effects:
>  Formula: ~+poly(wave, 2) | student_ID
>  Structure: General positive-definite, Log-Cholesky parametrization
>                StdDev     Corr
> (Intercept)      2.178734 (Intr) p(,2)1
> poly(wave, 2)1 279.521839 0.834
> poly(wave, 2)2 281.979199 0.751  0.987
> Residual        16.292629
>
> As are the fixed effects:
>
> Fixed effects: stwm ~ +poly(wave, 2)
>                    Value Std.Error   DF   t-value p-value
> (Intercept)      5.30155  0.231096 7070 22.940957       0
> poly(wave, 2)1 196.33516 23.481935 7070  8.361115       0
> poly(wave, 2)2 113.69005 23.591988 7070  4.819011       0
>  Correlation:
>                (Intr) p(,2)1
> poly(wave, 2)1 0.344
> poly(wave, 2)2 0.311  0.516
>
> However, when I calculate individual (i.e., group)-specific predicted
> values (i.e., BLUPs, using the predict() method, with level = 1), they are
> (very) highly correlated:
>
> # A tibble: 3 x 4
>   rowname   intercept linear quadratic
>   <chr>         <dbl>  <dbl>     <dbl>
> 1 intercept    NA      0.960     0.960
> 2 linear        0.960 NA         1.00
> 3 quadratic     0.960  1.00     NA
>
> When I calculate the same individual-specific predicted values using the
> non-orthogonal (raw) polynomials, these correlations are very nearly as
> high. At this point, I'm curious how / why these predictions are so highly
> correlated.
>
> Thank you again for your help, John, and for yours, Ben, Stuart, Jorg, and
> Thierry. Sorry if this is a beginner or otherwise ignorant question as I
> learn to work with these longitudinal / polynomial models.
> josh
>
> On Tue, Apr 3, 2018 at 1:32 PM, Fox, John <jfox at mcmaster.ca> wrote:
>
>> Dear Joshua,
>>
>> I'm chiming in late, so it's possible that someone already pointed this
>> out and I didn't notice. A better way to specify a polynomial in R is to
>> use poly() in the model formula. By default, this produces orthogonal
>> polynomial regressors (at least in the fixed effects) but the same fit to
>> the data. For example,
>>
>> > time <- 1:5
>> > X <- poly(time, 2)
>>
>> > X
>>               1          2
>> [1,] -0.6324555  0.5345225
>> [2,] -0.3162278 -0.2672612
>> [3,]  0.0000000 -0.5345225
>> [4,]  0.3162278 -0.2672612
>> [5,]  0.6324555  0.5345225
>> attr(,"coefs")
>> attr(,"coefs")$alpha
>> [1] 3 3
>>
>> attr(,"coefs")$norm2
>> [1]  1  5 10 14
>>
>> attr(,"degree")
>> [1] 1 2
>> attr(,"class")
>> [1] "poly"   "matrix"
>>
>> > colSums(X)
>>            1            2
>> 0.000000e+00 1.110223e-16
>>
>> > crossprod(X)
>>               1             2
>> 1  1.000000e+00 -1.110223e-16
>> 2 -1.110223e-16  1.000000e+00
>>
>> My guess is that this will also reduce the correlations among the random
>> effects. If you really must have raw polynomials, then poly(time, 2,
>> raw=TRUE) offers the advantage that model-structure-aware functions can
>> understand that the linear and quadratic regressors are part of the same
>> term in the model.
>>
>> Whether high correlations among the random effects are really a problem,
>> my guess is that they aren't, because lme() uses a log-Cholesky
>> factorization of the random-effects covariance matrix anyway. In some
>> contexts, high correlations might produce numerical instability, but, as I
>> said, probably not here. Ben would know.
>>
>> I hope this helps,
>>  John
>>
>> -----------------------------
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: socialsciences.mcmaster.ca/jfox/
>>
>>
>>
>>
>>
>> > -----Original Message-----
>> > From: R-sig-mixed-models [mailto:
>> r-sig-mixed-models-bounces at r-project.org]
>> > On Behalf Of Joshua Rosenberg
>> > Sent: Monday, April 2, 2018 5:33 PM
>> > To: Ben Bolker <bbolker at gmail.com>
>> > Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
>> > Subject: Re: [R-sig-ME] High correlation among random effects for
>> longitudinal
>> > model
>> >
>> > Dear Stuart and Ben,
>> >
>> > Thank you, this worked to significantly reduce the correlations between
>> the
>> > intercept and the linear and quadratic terms (though still quite high
>> between the
>> > linear and quadratic term):
>> >
>> > Random effects:
>> >  Formula: ~time + I(time^2) | student_ID
>> >  Structure: General positive-definite, Log-Cholesky parametrization
>> >             StdDev    Corr
>> > (Intercept) 18.671959 (Intr) time
>> > time        11.029842 -0.262
>> > I(time^2)    8.359834 -0.506  0.959
>> > Residual    29.006598
>> >
>> > Could I ask if that correlation between the linear (time) and quadratic
>> > I(time^2) terms is cause for concern - and if so, how to think about
>> > (potentially) addressing this?
>> > Josh
>> >
>> > On Sun, Apr 1, 2018 at 12:34 PM Ben Bolker <bbolker at gmail.com> wrote:
>> >
>> > > On Sun, Apr 1, 2018 at 12:20 PM, Stuart Luppescu <lupp at uchicago.edu>
>> > > wrote:
>> > > > On Sun, 2018-04-01 at 12:55 +0000, Joshua Rosenberg wrote:
>> > > >> lme(outcome ~ time + I(time^2),
>> > > >>     random = ~ time + I(time^2),
>> > > >>     correlation = corAR1(form = ~ time | individual_ID),
>> > > >>     data = d_grouped)
>> > > >>
>> > > >> I have a question / concerns about the random effects, as they are
>> > > >> highly correlated (intercept and linear term = -.95; intercept and
>> > > >> quadratic term = .96; linear term and quadratic term = -.995):
>> > > >
>> > > > I think this is an ordinary occurrence for the intercept and time
>> > > > trend to be negatively correlated. The way to avoid this is to
>> > > > center the time variable at a point in the middle of the series, so,
>> > > > instead of setting the values of time to {0, 1, 2, 3, 4} use {-2,
>> -1, 0, 1, 2}.
>> > > >
>> > >
>> > >   Agreed.  This is closely related, but not identical to, the
>> > > phenomenon where the *fixed effects* are highly correlated.
>> > >
>> > > > --
>> > > > Stuart Luppescu
>> > > > Chief Psychometrician (ret.)
>> > > > UChicago Consortium on School Research
>> > > > http://consortium.uchicago.edu
>> > > >
>> > > > _______________________________________________
>> > > > R-sig-mixed-models at r-project.org mailing list
>> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> > --
>> > Joshua Rosenberg, Ph.D. Candidate
>> > Educational Psychology ?&? Educational Technology Michigan State
>> University
>> > http://jmichaelrosenberg.com
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology ?&? Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From viraj.torsekar at gmail.com  Sun Apr  8 16:27:53 2018
From: viraj.torsekar at gmail.com (Viraj Torsekar)
Date: Sun, 8 Apr 2018 19:57:53 +0530
Subject: [R-sig-ME] Trouble looping model using glmmTMB
Message-ID: <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q@mail.gmail.com>

Hello all,

I'm trying to find out if distance moved by crickets is a function of
predation risk. My response variable is 'distance moved' and the predictor
is probability of spatial proximity with predator, ranging from 0 to 1. The
response variable is zero-inflated (about 77% values are zeroes) and its
variance is far higher than its mean. Hence, I tried running zero-inflated
negative binomial mixed models using glmmADMB, which failed (mixed because
I have multiple values per individual). Following was the error I kept
encountering: "function maximizer failed" (attaching a text file with
details of this model by keeping debug=TRUE).

Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
it worked! But the problem is, when I try bootstrapping the model using to
obtain confidence intervals, I keep getting the following error after
varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
gradient in optim evaluated to length 1 not 5'. This non-parametric
bootstrapping routine involves for loops in which the model is run using
bootstrapped groups (belonging to the grouping variable; individual.id in
my case) and the model coefficients thus obtained constitute the confidence
intervals. I've tried running 10,000 iterations, but the error pops up
within 10 to 100 runs.

Does anyone have suggestions regarding what can be changed?

Details of the model run singly and not in the loop:

 Family: nbinom2  ( log )
Formula:          movement.whole ~ poc + (1 | female.id)
Zero inflation:                  ~1
Data: incrisk_females_comm

     AIC      BIC   logLik deviance df.resid
  1725.1   1745.9   -857.5   1715.1      474

Random effects:

Conditional model:
 Groups    Name        Variance Std.Dev.
 female.id (Intercept) 0.07924  0.2815
Number of obs: 479, groups:  female.id, 110

Overdispersion parameter for nbinom2 family (): 1.59

Conditional model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  4.66384    0.14161   32.93   <2e-16 ***
poc         -0.08815    0.20978   -0.42    0.674
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   1.2442     0.1098   11.34   <2e-16 ***

Please do mention if you need further details. Thank you in advance.

Viraj Torsekar,
PhD Candidate,
Centre for Ecological Sciences,
Indian Institute of Science

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Apr  8 20:21:33 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 8 Apr 2018 14:21:33 -0400
Subject: [R-sig-ME] Trouble looping model using glmmTMB
In-Reply-To: <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q@mail.gmail.com>
References: <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q@mail.gmail.com>
Message-ID: <CABghstScDLD-30vGmfdpM82pBJFmqWBM8krOBm5EbBqUVWdfng@mail.gmail.com>

Can you post a reproducible example?  This example (which I set up to
match what I thought you were describing) seems to work OK at least
for 20 bootstrap reps, still waiting on the 100-rep run  ... [might be
better to continue this conversation at
https://github.com/glmmTMB/glmmTMB/issues ...]

## simulate primary example data
set.seed(101)
nobs <- 479
ng <- 110
dd <- data.frame(x=rnorm(nobs),f=factor(sample(ng,size=nobs,replace=TRUE)))
library(emdbook)
rf <- rnorm(ng)
dd$y <- emdbook::rzinbinom(nobs,mu=exp(2+dd$x+rf[dd$f]),zprob=0.2,size=1)

## fit primary model
library(glmmTMB)
m0 <- glmmTMB(y~x+(1|f),data=dd,family="nbinom2",zi=~1)

## npar bootstrap by levels
bootsamp <- function(data=dd,grp=dd$f) {
   ss <- split(data,grp)
   bg <- levels(grp)
   bootgrps <- sample(grp,size=length(grp),replace=TRUE)
   do.call(rbind,ss[bootgrps])
}

## test
update(m0,data=bootsamp())

nboot <- 100
## run bootstrap reps
res <- matrix(ncol=4,nrow=nboot)
for (i in seq(nboot)) {
  print(i)
  set.seed(100+i)
  bootfit <- update(m0,data=bootsamp())
  res[i,] <- unlist(fixef(bootfit))
}

On Sun, Apr 8, 2018 at 10:27 AM, Viraj Torsekar
<viraj.torsekar at gmail.com> wrote:
> Hello all,
>
> I'm trying to find out if distance moved by crickets is a function of
> predation risk. My response variable is 'distance moved' and the predictor
> is probability of spatial proximity with predator, ranging from 0 to 1. The
> response variable is zero-inflated (about 77% values are zeroes) and its
> variance is far higher than its mean. Hence, I tried running zero-inflated
> negative binomial mixed models using glmmADMB, which failed (mixed because
> I have multiple values per individual). Following was the error I kept
> encountering: "function maximizer failed" (attaching a text file with
> details of this model by keeping debug=TRUE).
>
> Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
> it worked! But the problem is, when I try bootstrapping the model using to
> obtain confidence intervals, I keep getting the following error after
> varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
> gradient in optim evaluated to length 1 not 5'. This non-parametric
> bootstrapping routine involves for loops in which the model is run using
> bootstrapped groups (belonging to the grouping variable; individual.id in
> my case) and the model coefficients thus obtained constitute the confidence
> intervals. I've tried running 10,000 iterations, but the error pops up
> within 10 to 100 runs.
>
> Does anyone have suggestions regarding what can be changed?
>
> Details of the model run singly and not in the loop:
>
>  Family: nbinom2  ( log )
> Formula:          movement.whole ~ poc + (1 | female.id)
> Zero inflation:                  ~1
> Data: incrisk_females_comm
>
>      AIC      BIC   logLik deviance df.resid
>   1725.1   1745.9   -857.5   1715.1      474
>
> Random effects:
>
> Conditional model:
>  Groups    Name        Variance Std.Dev.
>  female.id (Intercept) 0.07924  0.2815
> Number of obs: 479, groups:  female.id, 110
>
> Overdispersion parameter for nbinom2 family (): 1.59
>
> Conditional model:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  4.66384    0.14161   32.93   <2e-16 ***
> poc         -0.08815    0.20978   -0.42    0.674
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Zero-inflation model:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.2442     0.1098   11.34   <2e-16 ***
>
> Please do mention if you need further details. Thank you in advance.
>
> Viraj Torsekar,
> PhD Candidate,
> Centre for Ecological Sciences,
> Indian Institute of Science
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ligia_oceanica at hotmail.com  Mon Apr  9 08:14:09 2018
From: ligia_oceanica at hotmail.com (Ligia Pizzatto do Prado)
Date: Mon, 9 Apr 2018 06:14:09 +0000
Subject: [R-sig-ME] error: model is nearly unidentifiable
Message-ID: <CO1PR15MB1077BCD8F3D8AE4D75F71153F7BF0@CO1PR15MB1077.namprd15.prod.outlook.com>

Hi there, I'm new to mixed models but have ran a few with success before. Now, while trying to analyse this new experiment I am  having an error that I quite don't understand...


The experiment is a two choice habitat ("choice": poor [0] vs rich [1]) for frogs under two-state treatments, lets say F and C. Then I have as potential variables frog size ("size"), air temperature ("temp"), humidity ("hum") and date of experiment (recorded as continuos variable starting at day 1...). This is a repeated measure design as frogs were tested both in F and C trials (thus id is my random effect). I want to know if the choice is affected by treat, but also considering size, temp, humidity, and date in my model.


First I did:


data$treat<- factor(data$treat)

data$id<- factor(data$id)

data$choice<- factor(data$choice)


summary(data)

treat        id     choice

C:24   1      : 2   0:24

F:24   2      : 2   1:24

           3      : 2

           4      : 2

           5      : 2

           6      : 2

      (Other):36



size                     temp                      hum                   date

 Min.   :35.70      Min.   :24.80       Min.   :53.00       Min.   : 1.00

 1st Qu.:38.25     1st Qu.:26.30     1st Qu.:58.50     1st Qu.: 4.00

 Median :42.40   Median :27.30   Median :63.00   Median : 9.00

 Mean   :42.02    Mean   :26.74     Mean   :63.65    Mean   :10.75

 3rd Qu.:44.27    3rd Qu.:27.40     3rd Qu.:70.50    3rd Qu.:16.75

 Max.   :51.00      Max.   :27.90     Max.   :76.00       Max.   :24.00

m1<- glmer(Fchoice ~ treat + SUL + temp + hum + date + (1|id), data = data, family = binomial)

Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?


I keep getting this message in all models except when I exclude both temp and hum, but I also get the message when tried null model: null<- glmer(choice ~ 1 + (1|id), data = data, family = binomial)


I tried to transform/re-scale all continuous variable (temp, hum, date) and nothing changed, and I quite don't understand why the error also appears in the null model, given id is a factor... If its a scale problem wouldn't this only appear in the continuous variables?


Can anyone provide some guidance here, please?


TIA,


Ligia


	[[alternative HTML version deleted]]


From T.Houslay at exeter.ac.uk  Mon Apr  9 12:20:48 2018
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Mon, 9 Apr 2018 10:20:48 +0000
Subject: [R-sig-ME] Trouble looping model using glmmTMB
In-Reply-To: <mailman.16361.9.1523268001.12154.r-sig-mixed-models@r-project.org>
References: <mailman.16361.9.1523268001.12154.r-sig-mixed-models@r-project.org>
Message-ID: <VI1PR03MB3040688E5726B3AF9F374FC4D2BF0@VI1PR03MB3040.eurprd03.prod.outlook.com>

Hi Viraj,


This isn't a direct answer to your question so you can feel extremely free to ignore it(!), but your question reminded me of an approach I took to modelling calling effort in crickets using zero-altered poisson models in Jarrod's MCMCglmm package. In that case I had a few more predictor variables, but it meant the question could be phrased as two parts: what factors affect whether a male called or not, and - given he did call - what factors affect how much time he spent calling? It seems that that might be another option for you to model the movement with your crickets, although obviously it depends whether you think that would give you anything more valuable than your current approach (eg, is the decision to move something worth modelling separately from how far the cricket travels).


Anyway - my paper including this analysis is at http://doi.wiley.com/10.1111/1365-2435.12766 in case it's of any interest.


Cheers


Tom

----

Message: 1
Date: Sun, 8 Apr 2018 19:57:53 +0530
From: Viraj Torsekar <viraj.torsekar at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Trouble looping model using glmmTMB
Message-ID:
        <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello all,

I'm trying to find out if distance moved by crickets is a function of
predation risk. My response variable is 'distance moved' and the predictor
is probability of spatial proximity with predator, ranging from 0 to 1. The
response variable is zero-inflated (about 77% values are zeroes) and its
variance is far higher than its mean. Hence, I tried running zero-inflated
negative binomial mixed models using glmmADMB, which failed (mixed because
I have multiple values per individual). Following was the error I kept
encountering: "function maximizer failed" (attaching a text file with
details of this model by keeping debug=TRUE).

Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
it worked! But the problem is, when I try bootstrapping the model using to
obtain confidence intervals, I keep getting the following error after
varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
gradient in optim evaluated to length 1 not 5'. This non-parametric
bootstrapping routine involves for loops in which the model is run using
bootstrapped groups (belonging to the grouping variable; individual.id in
my case) and the model coefficients thus obtained constitute the confidence
intervals. I've tried running 10,000 iterations, but the error pops up
within 10 to 100 runs.

Does anyone have suggestions regarding what can be changed?

Details of the model run singly and not in the loop:

 Family: nbinom2  ( log )
Formula:          movement.whole ~ poc + (1 | female.id)
Zero inflation:                  ~1
Data: incrisk_females_comm

     AIC      BIC   logLik deviance df.resid
  1725.1   1745.9   -857.5   1715.1      474

Random effects:

Conditional model:
 Groups    Name        Variance Std.Dev.
 female.id (Intercept) 0.07924  0.2815
Number of obs: 479, groups:  female.id, 110

Overdispersion parameter for nbinom2 family (): 1.59

Conditional model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  4.66384    0.14161   32.93   <2e-16 ***
poc         -0.08815    0.20978   -0.42    0.674
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   1.2442     0.1098   11.34   <2e-16 ***

Please do mention if you need further details. Thank you in advance.

Viraj Torsekar,
PhD Candidate,
Centre for Ecological Sciences,
Indian Institute of Science

        [[alternative HTML version deleted]]



------------------------------

End of R-sig-mixed-models Digest, Vol 136, Issue 19
***************************************************

	[[alternative HTML version deleted]]


From viraj.torsekar at gmail.com  Mon Apr  9 12:38:23 2018
From: viraj.torsekar at gmail.com (Viraj Torsekar)
Date: Mon, 9 Apr 2018 16:08:23 +0530
Subject: [R-sig-ME] Trouble looping model using glmmTMB
In-Reply-To: <CABghstScDLD-30vGmfdpM82pBJFmqWBM8krOBm5EbBqUVWdfng@mail.gmail.com>
References: <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q@mail.gmail.com>
 <CABghstScDLD-30vGmfdpM82pBJFmqWBM8krOBm5EbBqUVWdfng@mail.gmail.com>
Message-ID: <CAOJBL43A6BHe_8HXrfQHmuboFh+AWcHVR_5hPd7jgjtomcpmEg@mail.gmail.com>

Oh, wow. That example was uncannily similar to my dataset (distributions
and absolute numbers too)! But there are two differences. The x (in the
y~x+(1|f)) in my dataset is a probability with a bimodal distribution, best
described by x=rbeta(n, .1, .2). And the y is zero-inflated with around 75%
of the values being zeroes. So I changed the zprob in emdbook::rzinbinom to
0.77 instead of 0.2.

I made these two changes and ran the routine. The model ran for the whole
100 iterations, but with 30 warnings. These warnings involved: 'NA/NaN
function evaluation', 'Model convergence problem; false convergence' and
'Model convergence problem; non-positive-definite Hessian matrix'. Does
that mean it's working all right?

I'm currently trying to use your example on my code and checking if that
works. Will update here soon.

p.s. - I have started a new issue on the glmmTMB discussion forum. For
anyone interested: https://github.com/glmmTMB/glmmTMB/issues/318

Thank you,
Viraj


On 8 April 2018 at 23:51, Ben Bolker <bbolker at gmail.com> wrote:

> Can you post a reproducible example?  This example (which I set up to
> match what I thought you were describing) seems to work OK at least
> for 20 bootstrap reps, still waiting on the 100-rep run  ... [might be
> better to continue this conversation at
> https://github.com/glmmTMB/glmmTMB/issues ...]
>
> ## simulate primary example data
> set.seed(101)
> nobs <- 479
> ng <- 110
> dd <- data.frame(x=rnorm(nobs),f=factor(sample(ng,size=nobs,
> replace=TRUE)))
> library(emdbook)
> rf <- rnorm(ng)
> dd$y <- emdbook::rzinbinom(nobs,mu=exp(2+dd$x+rf[dd$f]),zprob=0.2,size=1)
>
> ## fit primary model
> library(glmmTMB)
> m0 <- glmmTMB(y~x+(1|f),data=dd,family="nbinom2",zi=~1)
>
> ## npar bootstrap by levels
> bootsamp <- function(data=dd,grp=dd$f) {
>    ss <- split(data,grp)
>    bg <- levels(grp)
>    bootgrps <- sample(grp,size=length(grp),replace=TRUE)
>    do.call(rbind,ss[bootgrps])
> }
>
> ## test
> update(m0,data=bootsamp())
>
> nboot <- 100
> ## run bootstrap reps
> res <- matrix(ncol=4,nrow=nboot)
> for (i in seq(nboot)) {
>   print(i)
>   set.seed(100+i)
>   bootfit <- update(m0,data=bootsamp())
>   res[i,] <- unlist(fixef(bootfit))
> }
>
> On Sun, Apr 8, 2018 at 10:27 AM, Viraj Torsekar
> <viraj.torsekar at gmail.com> wrote:
> > Hello all,
> >
> > I'm trying to find out if distance moved by crickets is a function of
> > predation risk. My response variable is 'distance moved' and the
> predictor
> > is probability of spatial proximity with predator, ranging from 0 to 1.
> The
> > response variable is zero-inflated (about 77% values are zeroes) and its
> > variance is far higher than its mean. Hence, I tried running
> zero-inflated
> > negative binomial mixed models using glmmADMB, which failed (mixed
> because
> > I have multiple values per individual). Following was the error I kept
> > encountering: "function maximizer failed" (attaching a text file with
> > details of this model by keeping debug=TRUE).
> >
> > Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
> > it worked! But the problem is, when I try bootstrapping the model using
> to
> > obtain confidence intervals, I keep getting the following error after
> > varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
> > gradient in optim evaluated to length 1 not 5'. This non-parametric
> > bootstrapping routine involves for loops in which the model is run using
> > bootstrapped groups (belonging to the grouping variable; individual.id
> in
> > my case) and the model coefficients thus obtained constitute the
> confidence
> > intervals. I've tried running 10,000 iterations, but the error pops up
> > within 10 to 100 runs.
> >
> > Does anyone have suggestions regarding what can be changed?
> >
> > Details of the model run singly and not in the loop:
> >
> >  Family: nbinom2  ( log )
> > Formula:          movement.whole ~ poc + (1 | female.id)
> > Zero inflation:                  ~1
> > Data: incrisk_females_comm
> >
> >      AIC      BIC   logLik deviance df.resid
> >   1725.1   1745.9   -857.5   1715.1      474
> >
> > Random effects:
> >
> > Conditional model:
> >  Groups    Name        Variance Std.Dev.
> >  female.id (Intercept) 0.07924  0.2815
> > Number of obs: 479, groups:  female.id, 110
> >
> > Overdispersion parameter for nbinom2 family (): 1.59
> >
> > Conditional model:
> >             Estimate Std. Error z value Pr(>|z|)
> > (Intercept)  4.66384    0.14161   32.93   <2e-16 ***
> > poc         -0.08815    0.20978   -0.42    0.674
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Zero-inflation model:
> >             Estimate Std. Error z value Pr(>|z|)
> > (Intercept)   1.2442     0.1098   11.34   <2e-16 ***
> >
> > Please do mention if you need further details. Thank you in advance.
> >
> > Viraj Torsekar,
> > PhD Candidate,
> > Centre for Ecological Sciences,
> > Indian Institute of Science
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From viraj.torsekar at gmail.com  Mon Apr  9 13:39:38 2018
From: viraj.torsekar at gmail.com (Viraj Torsekar)
Date: Mon, 9 Apr 2018 17:09:38 +0530
Subject: [R-sig-ME] Trouble looping model using glmmTMB
In-Reply-To: <VI1PR03MB3040688E5726B3AF9F374FC4D2BF0@VI1PR03MB3040.eurprd03.prod.outlook.com>
References: <mailman.16361.9.1523268001.12154.r-sig-mixed-models@r-project.org>
 <VI1PR03MB3040688E5726B3AF9F374FC4D2BF0@VI1PR03MB3040.eurprd03.prod.outlook.com>
Message-ID: <CAOJBL41fV+M-vVpVwmxyebH1qOa6rPXxgS5j83WJcEH02ZUQ1g@mail.gmail.com>

Thanks so much for the suggestion Tom. Yes I was analysing calling effort
for males, and movement for both males and females in that manner. But I
was running separate models for each. I'll have a look at these conditional
two-part models.

Viraj

On 9 April 2018 at 15:50, Houslay, Tom <T.Houslay at exeter.ac.uk> wrote:

> Hi Viraj,
>
>
> This isn't a direct answer to your question so you can feel extremely free
> to ignore it(!), but your question reminded me of an approach I took to
> modelling calling effort in crickets using zero-altered poisson models in
> Jarrod's MCMCglmm package. In that case I had a few more predictor
> variables, but it meant the question could be phrased as two parts: what
> factors affect whether a male called or not, and - given he did call - what
> factors affect how much time he spent calling? It seems that that might be
> another option for you to model the movement with your crickets, although
> obviously it depends whether you think that would give you anything more
> valuable than your current approach (eg, is the decision to move something
> worth modelling separately from how far the cricket travels).
>
>
> Anyway - my paper including this analysis is at http://doi.wiley.com/10.
> 1111/1365-2435.12766 in case it's of any interest.
>
>
> Cheers
>
>
> Tom
>
> ----
>
> Message: 1
> Date: Sun, 8 Apr 2018 19:57:53 +0530
> From: Viraj Torsekar <viraj.torsekar at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Trouble looping model using glmmTMB
> Message-ID:
>         <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.
> gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
> Hello all,
>
> I'm trying to find out if distance moved by crickets is a function of
> predation risk. My response variable is 'distance moved' and the predictor
> is probability of spatial proximity with predator, ranging from 0 to 1. The
> response variable is zero-inflated (about 77% values are zeroes) and its
> variance is far higher than its mean. Hence, I tried running zero-inflated
> negative binomial mixed models using glmmADMB, which failed (mixed because
> I have multiple values per individual). Following was the error I kept
> encountering: "function maximizer failed" (attaching a text file with
> details of this model by keeping debug=TRUE).
>
> Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
> it worked! But the problem is, when I try bootstrapping the model using to
> obtain confidence intervals, I keep getting the following error after
> varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
> gradient in optim evaluated to length 1 not 5'. This non-parametric
> bootstrapping routine involves for loops in which the model is run using
> bootstrapped groups (belonging to the grouping variable; individual.id in
> my case) and the model coefficients thus obtained constitute the confidence
> intervals. I've tried running 10,000 iterations, but the error pops up
> within 10 to 100 runs.
>
> Does anyone have suggestions regarding what can be changed?
>
> Details of the model run singly and not in the loop:
>
>  Family: nbinom2  ( log )
> Formula:          movement.whole ~ poc + (1 | female.id)
> Zero inflation:                  ~1
> Data: incrisk_females_comm
>
>      AIC      BIC   logLik deviance df.resid
>   1725.1   1745.9   -857.5   1715.1      474
>
> Random effects:
>
> Conditional model:
>  Groups    Name        Variance Std.Dev.
>  female.id (Intercept) 0.07924  0.2815
> Number of obs: 479, groups:  female.id, 110
>
> Overdispersion parameter for nbinom2 family (): 1.59
>
> Conditional model:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  4.66384    0.14161   32.93   <2e-16 ***
> poc         -0.08815    0.20978   -0.42    0.674
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Zero-inflation model:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.2442     0.1098   11.34   <2e-16 ***
>
> Please do mention if you need further details. Thank you in advance.
>
> Viraj Torsekar,
> PhD Candidate,
> Centre for Ecological Sciences,
> Indian Institute of Science
>
>         [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 136, Issue 19
> ***************************************************
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Apr  9 16:14:26 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 9 Apr 2018 14:14:26 +0000
Subject: [R-sig-ME] error: model is nearly unidentifiable
In-Reply-To: <26750_1523254464_w396EN8t018225_CO1PR15MB1077BCD8F3D8AE4D75F71153F7BF0@CO1PR15MB1077.namprd15.prod.outlook.com>
References: <26750_1523254464_w396EN8t018225_CO1PR15MB1077BCD8F3D8AE4D75F71153F7BF0@CO1PR15MB1077.namprd15.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8367DF5AD@FHSDB2D11-2.csu.mcmaster.ca>

Dear Ligia,

Without your data, and therefore without a reproducible example, one can only speculate about the source of the problem. I noticed, however, that your response variable (choice) has equal numbers of 0s and 1s -- 24 of each. Was that simply a coincidence? As well, the response is named "choice" in the earlier part of your message and model "null," but "Fchoice" in model "m1." Why?

More generally, the question mark in "Rescale variables?" indicates that this is a common source of numerical instability but not the only one. For example, highly collinear predictors could also produce a nearly unidentified model. What's curious is that you're observing this problem in a model with only an intercept. Perhaps, e.g., choice is invariant within frogs.

Reading the posting guide at <https://www.r-project.org/posting-guide.html> might help you to formulate your question more effectively.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ligia Pizzatto do Prado
> Sent: Monday, April 9, 2018 2:14 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] error: model is nearly unidentifiable
> 
> Hi there, I'm new to mixed models but have ran a few with success before. Now,
> while trying to analyse this new experiment I am  having an error that I quite
> don't understand...
> 
> 
> The experiment is a two choice habitat ("choice": poor [0] vs rich [1]) for frogs
> under two-state treatments, lets say F and C. Then I have as potential variables
> frog size ("size"), air temperature ("temp"), humidity ("hum") and date of
> experiment (recorded as continuos variable starting at day 1...). This is a
> repeated measure design as frogs were tested both in F and C trials (thus id is my
> random effect). I want to know if the choice is affected by treat, but also
> considering size, temp, humidity, and date in my model.
> 
> 
> First I did:
> 
> 
> data$treat<- factor(data$treat)
> 
> data$id<- factor(data$id)
> 
> data$choice<- factor(data$choice)
> 
> 
> summary(data)
> 
> treat        id     choice
> 
> C:24   1      : 2   0:24
> 
> F:24   2      : 2   1:24
> 
>            3      : 2
> 
>            4      : 2
> 
>            5      : 2
> 
>            6      : 2
> 
>       (Other):36
> 
> 
> 
> size                     temp                      hum                   date
> 
>  Min.   :35.70      Min.   :24.80       Min.   :53.00       Min.   : 1.00
> 
>  1st Qu.:38.25     1st Qu.:26.30     1st Qu.:58.50     1st Qu.: 4.00
> 
>  Median :42.40   Median :27.30   Median :63.00   Median : 9.00
> 
>  Mean   :42.02    Mean   :26.74     Mean   :63.65    Mean   :10.75
> 
>  3rd Qu.:44.27    3rd Qu.:27.40     3rd Qu.:70.50    3rd Qu.:16.75
> 
>  Max.   :51.00      Max.   :27.90     Max.   :76.00       Max.   :24.00
> 
> m1<- glmer(Fchoice ~ treat + SUL + temp + hum + date + (1|id), data = data,
> family = binomial)
> 
> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
> 
> 
> I keep getting this message in all models except when I exclude both temp and
> hum, but I also get the message when tried null model: null<- glmer(choice ~ 1 +
> (1|id), data = data, family = binomial)
> 
> 
> I tried to transform/re-scale all continuous variable (temp, hum, date) and
> nothing changed, and I quite don't understand why the error also appears in the
> null model, given id is a factor... If its a scale problem wouldn't this only appear
> in the continuous variables?
> 
> 
> Can anyone provide some guidance here, please?
> 
> 
> TIA,
> 
> 
> Ligia
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ire.rojo at gmail.com  Mon Apr  9 20:07:58 2018
From: ire.rojo at gmail.com (Irene Rojo)
Date: Mon, 9 Apr 2018 20:07:58 +0200
Subject: [R-sig-ME] Problems with glmmadmb function for zero inflated count
 data
Message-ID: <CAGJ2gra7=Hpjd=+d0OHW2NAT-DDjTbnCaizN7u+s4Gq9cEJAeQ@mail.gmail.com>

Dear all,

I am trying to perform analyses for fish density but I am having several
problems. Also I am not an expert in statistics (at all) so I apologise if
my questions are too basic.

We sampled in 5 zones (ZN; fixed factor with 5 levels) and 3 protection
levels in each zone (PL; three levels). We selected 3, 6 and 9 sites (ST;
random effect) in each of the protection levels, respectively, and carried
out 3 underwater visual censuses in each site.

I am modeling counts of the most abundant species together as the response
variable, and including the area sampled as the offset term of the formula.
And I have so many zeros in my data.

I first tried the "glmer" function but there is so much overdispersion.
Then I thought about the "zeroinfl" function but it doesn't deal with
random effects. It works well if I miss the randon factor, but I don't
think that is right.

So I am trying to fit the models with the "glmmadmb" function as follows:

m0<- glmmadmb(n~  ZN*PL +
          offset(log(area))
          + ( 1 | ST),
          data = den,
          zeroInflation = TRUE,
          family = "nbinom", link = "logit"
         )

I am getting a huge error, either for the poisson or nbinom families:

Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(nTRT10 ~ ZN * PL + offset(log(areaTRT10)) + (1 | ST),  :
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\Windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
5 -noinit -shess' had status

I don't understand the error, so I can't think how to fix it. Can anyone
help with this?

Also, is it right to use this function for the kind of data I have? If not,
could you please suggest a better option?

Thanks in advance,

Irene

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Thu Apr 12 17:33:21 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Apr 2018 15:33:21 +0000
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
Message-ID: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>

Many users experience long execution times and convergence warnings when
trying to fit complex linear mixed-effects models with lmer.  I have, in
the past, shown that such models can be fit using the MixedModels (
https://github.com/dmbates/MixedModels.jl) package for Julia (
https://julialang.org) and that the data can be pulled from an R
representation using either the RCall (
https://github.com/JuliaInterop/RCall.jl) or RData (
https://github.com/JuliaData/RData.jl).

Recently the JuliaCall package for R (
https://github.com/Non-Contradiction/JuliaCall) has become available on
CRAN.  I have a short note at http://rpubs.com/dmbates/377897 on how to use
that package to fit models using MixedModels from R.

	[[alternative HTML version deleted]]


From jnhollandiii at gmail.com  Wed Apr 11 22:26:47 2018
From: jnhollandiii at gmail.com (Nat Holland)
Date: Wed, 11 Apr 2018 15:26:47 -0500
Subject: [R-sig-ME] alternative suggestions to glmmTMB family=beta
Message-ID: <CA+Q3t4GtUJMD+wwHspu86f+0tmqhPBR=PrqmO=aq08p2+97ZfA@mail.gmail.com>

I have tried to use the following model to fit beta distribution response
variable, with high frequency of data at upper end of 0 to 1.0 range of
histogram.

glmmTMB(vas2 ~ bmt + (bmt|studyid), family=list(family="beta",link="logit"))

I get the following warning messages:
Warning messages:
1: In fitTMB(TMBStruc) :
  Model convergence problem; non-positive-definite Hessian matrix. See
vignette('troubleshooting')
2: In fitTMB(TMBStruc) :
  Model convergence problem; false convergence (8). See
vignette('troubleshooting')

Reading about this on the troubleshooting pages suggests "Models with
non-positive definite Hessian matricies should be excluded from further
consideration, in general."

Any suggestions on alternative means of analyses to evaluate the above
model?

Thanks in advance,
Nat

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
J. Nathaniel Holland, Ph.D.
e-mail: jnhollandiii at gmail.com
LinkedIn:  https://www.linkedin.com/in/jnhollandiii/
Google Scholar:
https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Apr 12 18:25:17 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Apr 2018 12:25:17 -0400
Subject: [R-sig-ME] alternative suggestions to glmmTMB family=beta
In-Reply-To: <CA+Q3t4GtUJMD+wwHspu86f+0tmqhPBR=PrqmO=aq08p2+97ZfA@mail.gmail.com>
References: <CA+Q3t4GtUJMD+wwHspu86f+0tmqhPBR=PrqmO=aq08p2+97ZfA@mail.gmail.com>
Message-ID: <CABghstSCwh4oqrnHSP6bC-nhxYu0k8PUtQjq7VJisNL08UiMMA@mail.gmail.com>

What is bmt? numeric or factor? if factor, how many levels does it
have?  If numeric, centering the predictor often helps.

 - the mgcv package can fit beta-distributed responses; I'm not sure
if it does "unstructured" (general positive-definite)
variance-covariance matrices or not. (It doesn't seem straightforward:
https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html)

 - you could take the good old-fashioned approach of
logit-transforming your responses and fitting a linear model

 - you could try simplifying the model: i.e. perhaps a diagonal
(diag(bmt|studyid)) or compound-symmetric (cs(bmt|studyid))
variance-covariance model would be adequate?

 - as a last resort, or if you're really attached to this particular
model, you could try to understand precisely which parameters are
flat/strongly correlated.  If you want to do that, respond here and I
(or Mollie Brooks) can try to talk you through extracting the Hessian
of the fit and figuring out which components/directions are
non-positive ...


On Wed, Apr 11, 2018 at 4:26 PM, Nat Holland <jnhollandiii at gmail.com> wrote:
> I have tried to use the following model to fit beta distribution response
> variable, with high frequency of data at upper end of 0 to 1.0 range of
> histogram.
>
> glmmTMB(vas2 ~ bmt + (bmt|studyid), family=list(family="beta",link="logit"))
>
> I get the following warning messages:
> Warning messages:
> 1: In fitTMB(TMBStruc) :
>   Model convergence problem; non-positive-definite Hessian matrix. See
> vignette('troubleshooting')
> 2: In fitTMB(TMBStruc) :
>   Model convergence problem; false convergence (8). See
> vignette('troubleshooting')
>
> Reading about this on the troubleshooting pages suggests "Models with
> non-positive definite Hessian matricies should be excluded from further
> consideration, in general."
>
> Any suggestions on alternative means of analyses to evaluate the above
> model?
>
> Thanks in advance,
> Nat
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> J. Nathaniel Holland, Ph.D.
> e-mail: jnhollandiii at gmail.com
> LinkedIn:  https://www.linkedin.com/in/jnhollandiii/
> Google Scholar:
> https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Apr 12 19:47:21 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Apr 2018 13:47:21 -0400
Subject: [R-sig-ME] Fwd:  alternative suggestions to glmmTMB family=beta
In-Reply-To: <CABghstSz_X+iQOK8MqUNBugKt=cP8sko_BUknnCDC9wHKzJzbQ@mail.gmail.com>
References: <CA+Q3t4GtUJMD+wwHspu86f+0tmqhPBR=PrqmO=aq08p2+97ZfA@mail.gmail.com>
 <CABghstSCwh4oqrnHSP6bC-nhxYu0k8PUtQjq7VJisNL08UiMMA@mail.gmail.com>
 <CA+Q3t4FhBQqxtoieqFaomv4+XiMFaNtSav3sh2-9+vjhZu9R8Q@mail.gmail.com>
 <CABghstSz_X+iQOK8MqUNBugKt=cP8sko_BUknnCDC9wHKzJzbQ@mail.gmail.com>
Message-ID: <CABghstQFp+PHOq8X+DGykMEHBvem4m1ixruwOzJYjjuCE=mraw@mail.gmail.com>

(resending: pix were embedded, so the message got bounced)

  A couple of things here:

  (1) fitting (bmt | studyid) is very ambitious if bmt is a factor with 10
levels - that means fitting a 10x10 variance-covariance matrix (55
variance-covariance parameters).   OK if you have a giant data set, but
otherwise (a) consider structured (compound symmetric or diagonal) var-cov
matrix; (b) use brms package (which does have beta distribution, and
allows/requires a prior on the variance-covariance matrix which will make
things better).

  (2) the marginal distribution not looking right doesn't necessarily mean
the residual distribution isn't OK for linear models.

 cheers
   Ben Bolker


On Thu, Apr 12, 2018 at 12:54 PM, Nat Holland <jnhollandiii at gmail.com>
wrote:

> Thanks...
> bmt is a factor with 10 levels.
>
> Here is freq distribution untransformed percentages...
>
>
>
> I am ok with good ole fashioned transformation, but when I logit transform
> proportions using (car) logit function, then i still get the spike at upper
> end:
>
>
> This distribution is not sufficient for linear model...
>
> Nat
>
>
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> J. Nathaniel Holland, Ph.D.
> Research and Data Scientist
> e-mail: jnhollandiii at gmail.com
> LinkedIn:  https://www.linkedin.com/in/jnhollandiii/
> Google Scholar:  https://scholar.google.com/cit
> ations?user=VbHqPXEAAAAJ&hl=en
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
> On Thu, Apr 12, 2018 at 11:25 AM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> What is bmt? numeric or factor? if factor, how many levels does it
>> have?  If numeric, centering the predictor often helps.
>>
>>  - the mgcv package can fit beta-distributed responses; I'm not sure
>> if it does "unstructured" (general positive-definite)
>> variance-covariance matrices or not. (It doesn't seem straightforward:
>> https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/rand
>> om.effects.html)
>>
>>  - you could take the good old-fashioned approach of
>> logit-transforming your responses and fitting a linear model
>>
>>  - you could try simplifying the model: i.e. perhaps a diagonal
>> (diag(bmt|studyid)) or compound-symmetric (cs(bmt|studyid))
>> variance-covariance model would be adequate?
>>
>>  - as a last resort, or if you're really attached to this particular
>> model, you could try to understand precisely which parameters are
>> flat/strongly correlated.  If you want to do that, respond here and I
>> (or Mollie Brooks) can try to talk you through extracting the Hessian
>> of the fit and figuring out which components/directions are
>> non-positive ...
>>
>>
>> On Wed, Apr 11, 2018 at 4:26 PM, Nat Holland <jnhollandiii at gmail.com>
>> wrote:
>> > I have tried to use the following model to fit beta distribution
>> response
>> > variable, with high frequency of data at upper end of 0 to 1.0 range of
>> > histogram.
>> >
>> > glmmTMB(vas2 ~ bmt + (bmt|studyid), family=list(family="beta",link
>> ="logit"))
>> >
>> > I get the following warning messages:
>> > Warning messages:
>> > 1: In fitTMB(TMBStruc) :
>> >   Model convergence problem; non-positive-definite Hessian matrix. See
>> > vignette('troubleshooting')
>> > 2: In fitTMB(TMBStruc) :
>> >   Model convergence problem; false convergence (8). See
>> > vignette('troubleshooting')
>> >
>> > Reading about this on the troubleshooting pages suggests "Models with
>> > non-positive definite Hessian matricies should be excluded from further
>> > consideration, in general."
>> >
>> > Any suggestions on alternative means of analyses to evaluate the above
>> > model?
>> >
>> > Thanks in advance,
>> > Nat
>> >
>> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> > J. Nathaniel Holland, Ph.D.
>> > e-mail: jnhollandiii at gmail.com
>> > LinkedIn:  https://www.linkedin.com/in/jnhollandiii/
>> > Google Scholar:
>> > https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en
>> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Apr 13 01:08:16 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Apr 2018 19:08:16 -0400
Subject: [R-sig-ME] alternative suggestions to glmmTMB family=beta
In-Reply-To: <CA+Q3t4G=2L8_woaBhxFUMNX=1NsQtJHo5n1SEZXw7e9bYh2mUQ@mail.gmail.com>
References: <CA+Q3t4GtUJMD+wwHspu86f+0tmqhPBR=PrqmO=aq08p2+97ZfA@mail.gmail.com>
 <CABghstSCwh4oqrnHSP6bC-nhxYu0k8PUtQjq7VJisNL08UiMMA@mail.gmail.com>
 <CA+Q3t4FhBQqxtoieqFaomv4+XiMFaNtSav3sh2-9+vjhZu9R8Q@mail.gmail.com>
 <CABghstSz_X+iQOK8MqUNBugKt=cP8sko_BUknnCDC9wHKzJzbQ@mail.gmail.com>
 <CA+Q3t4G=2L8_woaBhxFUMNX=1NsQtJHo5n1SEZXw7e9bYh2mUQ@mail.gmail.com>
Message-ID: <f5d35b43-cf5d-00df-5182-38f25947f48e@gmail.com>


  The alternative/simpler way to fit a compound symmetry model is as a
nested model, (1|id/bmt). However, this only allows for *positive*
compound symmetry.

  In the example you have, I think this model is actually overspecified,
because the (1|id:bmt) term (the nested specification expands to (1|id)
+ (1|id:bmt)) has one random effect for every observation. An
observation-level random effect underlying a Beta distribution is
equivalent to fitting a logistic-Normal-Beta model, and this will be
unidentifiable (or nearly so) because the Beta distribution has its own
dispersion parameter ...)


On 2018-04-12 01:58 PM, Nat Holland wrote:
> Yes, 10 levels is large... the data set has 277 studyid for total of
> 2770 rows.? So, large, but not so giant. I am working on the cs and dia
> specifications now.... thanks for that suggestion. brms package is also
> another way I would not have seen... I will consider.? I may simply
> randomly select one bmt level randomly from each studyid and then work
> with reduced data set in betareg package that lacks the
> pseudoreplication of (bmt|studyid).? Thanks again...
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> J. Nathaniel Holland, Ph.D.
> Research and Data Scientist
> e-mail: jnhollandiii at gmail.com
> <mailto:jnhollandiii at gmail.com>LinkedIn:?
> https://www.linkedin.com/in/jnhollandiii/
> Google Scholar:?
> https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> 
> On Thu, Apr 12, 2018 at 12:44 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>     ? A couple of things here:
> 
>     ? (1) fitting (bmt | studyid) is very ambitious if bmt is a factor
>     with 10 levels - that means fitting a 10x10 variance-covariance
>     matrix (55 variance-covariance parameters).?? OK if you have a giant
>     data set, but otherwise (a) consider structured (compound symmetric
>     or diagonal) var-cov matrix; (b) use brms package (which does have
>     beta distribution, and allows/requires a prior on the
>     variance-covariance matrix which will make things better).
> 
>     ? (2) the marginal distribution not looking right doesn't
>     necessarily mean the residual distribution isn't OK.
> 
>     ?cheers
>     ?? Ben Bolker
> 
> 
>     On Thu, Apr 12, 2018 at 12:54 PM, Nat Holland
>     <jnhollandiii at gmail.com <mailto:jnhollandiii at gmail.com>> wrote:
> 
>         Thanks...
>         bmt is a factor with 10 levels.
> 
>         Here is freq distribution untransformed percentages...
> 
> 
> 
>         I am ok with good ole fashioned transformation, but when I logit
>         transform proportions using (car) logit function, then i still
>         get the spike at upper end:
> 
> 
>         This distribution is not sufficient for linear model...
> 
>         Nat
> 
> 
> 
>         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>         J. Nathaniel Holland, Ph.D.
>         Research and Data Scientist
>         e-mail: jnhollandiii at gmail.com
>         <mailto:jnhollandiii at gmail.com>LinkedIn:?
>         https://www.linkedin.com/in/jnhollandiii/
>         <https://www.linkedin.com/in/jnhollandiii/>Google Scholar:?
>         https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en
>         <https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> 
>         On Thu, Apr 12, 2018 at 11:25 AM, Ben Bolker <bbolker at gmail.com
>         <mailto:bbolker at gmail.com>> wrote:
> 
>             What is bmt? numeric or factor? if factor, how many levels
>             does it
>             have?? If numeric, centering the predictor often helps.
> 
>             ?- the mgcv package can fit beta-distributed responses; I'm
>             not sure
>             if it does "unstructured" (general positive-definite)
>             variance-covariance matrices or not. (It doesn't seem
>             straightforward:
>             https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html
>             <https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html>)
> 
>             ?- you could take the good old-fashioned approach of
>             logit-transforming your responses and fitting a linear model
> 
>             ?- you could try simplifying the model: i.e. perhaps a diagonal
>             (diag(bmt|studyid)) or compound-symmetric (cs(bmt|studyid))
>             variance-covariance model would be adequate?
> 
>             ?- as a last resort, or if you're really attached to this
>             particular
>             model, you could try to understand precisely which
>             parameters are
>             flat/strongly correlated.? If you want to do that, respond
>             here and I
>             (or Mollie Brooks) can try to talk you through extracting
>             the Hessian
>             of the fit and figuring out which components/directions are
>             non-positive ...
> 
> 
>             On Wed, Apr 11, 2018 at 4:26 PM, Nat Holland
>             <jnhollandiii at gmail.com <mailto:jnhollandiii at gmail.com>> wrote:
>             > I have tried to use the following model to fit beta
>             distribution response
>             > variable, with high frequency of data at upper end of 0 to
>             1.0 range of
>             > histogram.
>             >
>             > glmmTMB(vas2 ~ bmt + (bmt|studyid),
>             family=list(family="beta",link="logit"))
>             >
>             > I get the following warning messages:
>             > Warning messages:
>             > 1: In fitTMB(TMBStruc) :
>             >? ?Model convergence problem; non-positive-definite Hessian
>             matrix. See
>             > vignette('troubleshooting')
>             > 2: In fitTMB(TMBStruc) :
>             >? ?Model convergence problem; false convergence (8). See
>             > vignette('troubleshooting')
>             >
>             > Reading about this on the troubleshooting pages suggests
>             "Models with
>             > non-positive definite Hessian matricies should be excluded
>             from further
>             > consideration, in general."
>             >
>             > Any suggestions on alternative means of analyses to
>             evaluate the above
>             > model?
>             >
>             > Thanks in advance,
>             > Nat
>             >
>             > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>             > J. Nathaniel Holland, Ph.D.
>             > e-mail: jnhollandiii at gmail.com <mailto:jnhollandiii at gmail.com>
>             > LinkedIn:? https://www.linkedin.com/in/jnhollandiii/
>             <https://www.linkedin.com/in/jnhollandiii/>
>             > Google Scholar:
>             >
>             https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en
>             <https://scholar.google.com/citations?user=VbHqPXEAAAAJ&hl=en>
>             > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>             >
>             >? ? ? ? ?[[alternative HTML version deleted]]
>             >
>             > _______________________________________________
>             > R-sig-mixed-models at r-project.org
>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>             > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>             <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
>


From r.turner at auckland.ac.nz  Fri Apr 13 03:11:46 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 13 Apr 2018 13:11:46 +1200
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
In-Reply-To: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
References: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
Message-ID: <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>


On 13/04/18 03:33, Douglas Bates wrote:

> Many users experience long execution times and convergence warnings when
> trying to fit complex linear mixed-effects models with lmer.  I have, in
> the past, shown that such models can be fit using the MixedModels (
> https://github.com/dmbates/MixedModels.jl) package for Julia (
> https://julialang.org) and that the data can be pulled from an R
> representation using either the RCall (
> https://github.com/JuliaInterop/RCall.jl) or RData (
> https://github.com/JuliaData/RData.jl).
> 
> Recently the JuliaCall package for R (
> https://github.com/Non-Contradiction/JuliaCall) has become available on
> CRAN.  I have a short note at http://rpubs.com/dmbates/377897 on how to use
> that package to fit models using MixedModels from R.

This is of considerable interest to me since I am involved in some 
consulting work (about which I have annoyed the r-sig-mixed-models list 
on previous occasions!) which involves mixed models and I have 
experienced the problems referred to in the opening line of your message.

So I had a look at http://rpubs.com/dmbates/377897 just now, and it 
looks promising.

I have however a possibly naive or misguided question:  How do I get a 
printed copy of the vignette?  I tried saving or printing the page that 
showed up in my browser (Firefox; GoogleChrome) in various ways.  The 
result always seems to get truncated at a single page, with the bulk of 
the document omitted.  (The document is also somewhat messed up in other 
ways.)

Is there a simple way of saving a copy of the vignette in such a way 
that I can print off a hard copy?  I suppose I am simply demonstrating 
my ignorance and showing that I am out of the loop when it comes to 
dealing with Rpubs and Rmarkdown documents, but that's the way it is.

Thanks for any tips and advice.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ire.rojo at gmail.com  Fri Apr 13 11:08:34 2018
From: ire.rojo at gmail.com (Irene Rojo)
Date: Fri, 13 Apr 2018 11:08:34 +0200
Subject: [R-sig-ME] Problems fitting and interpreting glmmadmb and glmmTMB
Message-ID: <CAGJ2grZHnVkVPVFmt9dz09073OgscS+_e2gHmX7PySrhTRbF6Q@mail.gmail.com>

 Hi,

I am trying to perform glmm analyses for fish density but I am getting
errors.. Also I am not an expert in statistics (at all) so I apologise if
my questions are too basic.

We sampled in 5 zones (ZN; fixed factor with 5 levels) and 3 protection
levels in each zone (PL; three levels). We selected 3, 6 and 9 sites (ST;
random effect) in each of the protection levels, respectively, and carried
out 3 underwater visual censuses in each site.

I am modeling counts of the most abundant species together as the response
variable, and including the area sampled as the offset term of the formula.
And I have so many zeros in my data.

I first tried the "glmer" function but it didn't work (model failed to
converge). Then I thought about the "zeroinfl" function but it doesn't deal
with random effects. It works well if I miss the random factor, but I don't
think that is right.

So I am trying to fit the models with the "glmmadmb" function as follows:

m0<- glmmadmb(nTRT10~  ZN*PL +
          offset(log(areaTRT10))
          + ( 1 | ST),
          data = den,
          zeroInflation = TRUE,
          family = "nbinom", link = "logit"
         )

I am getting a huge error, either for the poisson or nbinom families, which
I don't understand:

Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(nTRT10 ~ ZN * PL + offset(log(areaTRT10)) + (1 | ST),  :
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\Windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
5 -noinit -shess' had status 1

However, with glmmTMB function it seems to be working well.

m0<- glmmTMB(nTRT10 ~  ZN*PL + ZN + PL +
          offset(log(areaTRT10))
          + ( 1 | ST),
          data = den,
          zi=~ ZN + PL,
          family = nbinom2,
          dispformula = ~ PL
          )

And I get this output:

Family: nbinom2  ( log )
Formula:          nTRT10 ~ ZN * PL + ZN + PL + offset(log(areaTRT10)) + (1
| ST)
Zero inflation:          ~ZN + PL
Dispersion:              ~PL
Data: den

     AIC      BIC   logLik deviance df.resid
  1534.4   1626.1   -741.2   1482.4      226

Random effects:

Conditional model:
 Groups Name        Variance Std.Dev.
 ST     (Intercept) 0.09779  0.3127
Number of obs: 252, groups:  ST, 84

Conditional model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -6.0226     0.4126 -14.598  < 2e-16 ***
ZNCP          1.0949     0.4722   2.319 0.020405 *
ZNEF         -0.1117     0.5170  -0.216 0.828938
ZNMN         -1.8432     0.5088  -3.623 0.000291 ***
ZNTA         -1.0188     0.5224  -1.950 0.051162 .
PLBZ         -0.4027     0.5706  -0.706 0.480357
PLNT          1.1870     0.5262   2.256 0.024100 *
ZNCP:PLBZ     1.6528     0.6926   2.386 0.017015 *
ZNEF:PLBZ     1.8543     0.7333   2.529 0.011455 *
ZNMN:PLBZ     2.1438     0.7569   2.832 0.004624 **
ZNTA:PLBZ     1.4418     0.7361   1.959 0.050143 .
ZNCP:PLNT     0.4205     0.6577   0.639 0.522619
ZNEF:PLNT     1.2943     0.7438   1.740 0.081821 .
ZNMN:PLNT    -0.1311     0.7308  -0.179 0.857588
ZNTA:PLNT     0.6470     0.7057   0.917 0.359197
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)    -0.6591     0.5512  -1.196   0.2318
ZNCP          -19.2792  5421.1935  -0.004   0.9972
ZNEF           -2.0983     0.9260  -2.266   0.0235 *
ZNMN          -17.8418  4982.4109  -0.004   0.9971
ZNTA          -20.4595 13048.1115  -0.002   0.9987
PLBZ            0.1975     0.7920   0.249   0.8031
PLNT           -0.8759     1.0086  -0.868   0.3852
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Dispersion model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.16608    0.21679  -0.766    0.444
PLBZ         0.09037    0.30420   0.297    0.766
PLNT         0.62906    0.32911   1.911    0.056 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



1. I don't understand the error in glmmadmb. Maybe the use of glmmTMB is
fine in this case so I don't need to use glmmadmb but still I am curious. Do
you think the use of glmmTMB is right here? I don't really understand the
differences among the two functions.

2. How can I perform model validation of glmmTMB? Is the same way as with
glmer?

3. How do I interpret the random effects conditional model?

Thank you so much,

Irene

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Apr 13 11:58:04 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 13 Apr 2018 21:58:04 +1200
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
In-Reply-To: <E0860704-F18E-4FBC-9BEC-219A929EFC2B@sms.ed.ac.uk>
References: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
 <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>
 <E0860704-F18E-4FBC-9BEC-219A929EFC2B@sms.ed.ac.uk>
Message-ID: <0ce960bb-a7d3-6e7a-b000-235f0842f2e2@auckland.ac.nz>


On 13/04/18 21:10, HAJDUK Gabriela wrote:

> Hello Rolf,
> 
> You can highlight all text (Ctrl/Cmd + A) and then right click and choose print. It should then give you the entire highlighted content - I?m on Chrome and if I just right click and print I get the first page only, but highlighting beforehand gives all the content. You might need to play with scaling before printing.

Thanks very much Gabriela.  It works like a charm with Chrome, though 
not (at all) with Firefox.

cheers,

Rolf

> 
>> On 13 Apr 2018, at 02:11, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> On 13/04/18 03:33, Douglas Bates wrote:
>>
>>> Many users experience long execution times and convergence warnings when
>>> trying to fit complex linear mixed-effects models with lmer.  I have, in
>>> the past, shown that such models can be fit using the MixedModels (
>>> https://github.com/dmbates/MixedModels.jl) package for Julia (
>>> https://julialang.org) and that the data can be pulled from an R
>>> representation using either the RCall (
>>> https://github.com/JuliaInterop/RCall.jl) or RData (
>>> https://github.com/JuliaData/RData.jl).
>>> Recently the JuliaCall package for R (
>>> https://github.com/Non-Contradiction/JuliaCall) has become available on
>>> CRAN.  I have a short note at http://rpubs.com/dmbates/377897 on how to use
>>> that package to fit models using MixedModels from R.
>>
>> This is of considerable interest to me since I am involved in some consulting work (about which I have annoyed the r-sig-mixed-models list on previous occasions!) which involves mixed models and I have experienced the problems referred to in the opening line of your message.
>>
>> So I had a look at http://rpubs.com/dmbates/377897 just now, and it looks promising.
>>
>> I have however a possibly naive or misguided question:  How do I get a printed copy of the vignette?  I tried saving or printing the page that showed up in my browser (Firefox; GoogleChrome) in various ways.  The result always seems to get truncated at a single page, with the bulk of the document omitted.  (The document is also somewhat messed up in other ways.)
>>
>> Is there a simple way of saving a copy of the vignette in such a way that I can print off a hard copy?  I suppose I am simply demonstrating my ignorance and showing that I am out of the loop when it comes to dealing with Rpubs and Rmarkdown documents, but that's the way it is.
>>
>> Thanks for any tips and advice.


From baron at upenn.edu  Fri Apr 13 12:42:31 2018
From: baron at upenn.edu (Jon Baron)
Date: Fri, 13 Apr 2018 06:42:31 -0400
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
In-Reply-To: <0ce960bb-a7d3-6e7a-b000-235f0842f2e2@auckland.ac.nz>
References: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
 <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>
 <E0860704-F18E-4FBC-9BEC-219A929EFC2B@sms.ed.ac.uk>
 <0ce960bb-a7d3-6e7a-b000-235f0842f2e2@auckland.ac.nz>
Message-ID: <20180413104231.GA13922@upenn.edu>

On 04/13/18 21:58, Rolf Turner wrote:
>
>On 13/04/18 21:10, HAJDUK Gabriela wrote:
>
>> Hello Rolf,
>> 
>> You can highlight all text (Ctrl/Cmd + A) and then right click and choose print. 
>It should then give you the entire highlighted content - I'm on Chrome and if I just 
>right click and print I get the first page only, but highlighting beforehand gives 
>all the content. You might need to play with scaling before printing.
>
>Thanks very much Gabriela.  It works like a charm with Chrome, though 
>not (at all) with Firefox.

In Firefox (at least version 61+, but probably earlier), right click,
then select "This frame", then "Show only this frame", then print.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron


From jessiebarker at gmail.com  Fri Apr 13 13:39:37 2018
From: jessiebarker at gmail.com (Jessie Barker)
Date: Fri, 13 Apr 2018 13:39:37 +0200
Subject: [R-sig-ME] Binomial glmer() with zero-inflated data
Message-ID: <CABtDSpgSXcT=ROEuY9Fok3Gg=gfRfXGci8dU0_JOU96zfOb96Q@mail.gmail.com>

Dear mixed-model enthusiasts,

I have a question about how to model zero-inflated data (I have several 1's
too, but more 0's).

The data are observations of bees visiting flowers to collect nectar. A
visit can either be "pollination" or "nectar robbing" (the bee collects
nectar from a hole through the side of the flower). Each bee made a
sequence of visits, and the response variable that I am interested in is
how many times a bee robbed nectar. (In many cases a bee did not rob nectar
at all - hence the zero-inflation - and in a few cases it only robbed
nectar.) I observed each bee only once.

The predictor variable I am interested in is the proportion of flowers on
the plant that have holes in them (thus enabling nectar robbing). I have
multiple measurements of the response variable on each plant, but only one
measurement of the predictor variable. So I will include plant as a random
effect.

I think I need something like this:

model1 <- glmer ( cbind(rob,pollinate) ~ prop.holes + (1|plant),
data=mydata, family=binomial)

But I don't think that can handle the zero-inflation. Does anyone on this
listserv have any advice?

Thanks in advance - I really appreciate any suggestions!

Best wishes,

Jessie Barker

Junior Fellow
Aarhus Institute of Advanced Studies, Denmark
http://aias.au.dk/aias-fellows/jessica-barker/

	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Fri Apr 13 13:50:37 2018
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Fri, 13 Apr 2018 13:50:37 +0200
Subject: [R-sig-ME] Binomial glmer() with zero-inflated data
In-Reply-To: <CABtDSpgSXcT=ROEuY9Fok3Gg=gfRfXGci8dU0_JOU96zfOb96Q@mail.gmail.com>
References: <CABtDSpgSXcT=ROEuY9Fok3Gg=gfRfXGci8dU0_JOU96zfOb96Q@mail.gmail.com>
Message-ID: <FBEC2421-BE91-41E1-B8CA-85A2BD60B44F@gmail.com>

Dear Jesse,

You probably don?t need to worry about zero-inflation. The binomial distribution should be able to handle the 0s. Your model seems reasonable to me. 

Best regards,
Mollie

???????????
Mollie E. Brooks, Ph.D.
Research Scientist
National Institute of Aquatic Resources
Technical University of Denmark

> On 13Apr 2018, at 13:39, Jessie Barker <jessiebarker at gmail.com> wrote:
> 
> Dear mixed-model enthusiasts,
> 
> I have a question about how to model zero-inflated data (I have several 1's
> too, but more 0's).
> 
> The data are observations of bees visiting flowers to collect nectar. A
> visit can either be "pollination" or "nectar robbing" (the bee collects
> nectar from a hole through the side of the flower). Each bee made a
> sequence of visits, and the response variable that I am interested in is
> how many times a bee robbed nectar. (In many cases a bee did not rob nectar
> at all - hence the zero-inflation - and in a few cases it only robbed
> nectar.) I observed each bee only once.
> 
> The predictor variable I am interested in is the proportion of flowers on
> the plant that have holes in them (thus enabling nectar robbing). I have
> multiple measurements of the response variable on each plant, but only one
> measurement of the predictor variable. So I will include plant as a random
> effect.
> 
> I think I need something like this:
> 
> model1 <- glmer ( cbind(rob,pollinate) ~ prop.holes + (1|plant),
> data=mydata, family=binomial)
> 
> But I don't think that can handle the zero-inflation. Does anyone on this
> listserv have any advice?
> 
> Thanks in advance - I really appreciate any suggestions!
> 
> Best wishes,
> 
> Jessie Barker
> 
> Junior Fellow
> Aarhus Institute of Advanced Studies, Denmark
> http://aias.au.dk/aias-fellows/jessica-barker/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Apr 13 23:48:43 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 14 Apr 2018 09:48:43 +1200
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
In-Reply-To: <20180413104231.GA13922@upenn.edu>
References: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
 <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>
 <E0860704-F18E-4FBC-9BEC-219A929EFC2B@sms.ed.ac.uk>
 <0ce960bb-a7d3-6e7a-b000-235f0842f2e2@auckland.ac.nz>
 <20180413104231.GA13922@upenn.edu>
Message-ID: <1c7ca3a7-3b6a-63c4-255e-ac3fe0ba8a18@auckland.ac.nz>


On 13/04/18 22:42, Jon Baron wrote:

> On 04/13/18 21:58, Rolf Turner wrote:
>>
>> On 13/04/18 21:10, HAJDUK Gabriela wrote:
>>
>>> Hello Rolf,
>>>
>>> You can highlight all text (Ctrl/Cmd + A) and then right click and 
>>> choose print. 
>> It should then give you the entire highlighted content - I'm on Chrome 
>> and if I just right click and print I get the first page only, but 
>> highlighting beforehand gives all the content. You might need to play 
>> with scaling before printing.
>>
>> Thanks very much Gabriela.? It works like a charm with Chrome, though 
>> not (at all) with Firefox.
> 
> In Firefox (at least version 61+, but probably earlier), right click,
> then select "This frame", then "Show only this frame", then print.

Yep, that works.  Thanks.

Not exactly intuitive, but, is it?  (The same must be said for 
Gabriela's solution.)

Software designers often seem to ignore the needs of "ordinary"
users. :-(

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From mmalten at gmail.com  Fri Apr 13 23:59:16 2018
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Fri, 13 Apr 2018 21:59:16 +0000
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
In-Reply-To: <1c7ca3a7-3b6a-63c4-255e-ac3fe0ba8a18@auckland.ac.nz>
References: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
 <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>
 <E0860704-F18E-4FBC-9BEC-219A929EFC2B@sms.ed.ac.uk>
 <0ce960bb-a7d3-6e7a-b000-235f0842f2e2@auckland.ac.nz>
 <20180413104231.GA13922@upenn.edu>
 <1c7ca3a7-3b6a-63c4-255e-ac3fe0ba8a18@auckland.ac.nz>
Message-ID: <CANOgrHYaaLomCSy=2Mdp+J9B=t0t83gUkL_DfkgnvTLyrDphTA@mail.gmail.com>

Works nicely but I?m trying to track down how to move data back and forth.

I need to use glmm for predictions.

On Fri, Apr 13, 2018 at 5:49 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On 13/04/18 22:42, Jon Baron wrote:
>
> > On 04/13/18 21:58, Rolf Turner wrote:
> >>
> >> On 13/04/18 21:10, HAJDUK Gabriela wrote:
> >>
> >>> Hello Rolf,
> >>>
> >>> You can highlight all text (Ctrl/Cmd + A) and then right click and
> >>> choose print.
> >> It should then give you the entire highlighted content - I'm on Chrome
> >> and if I just right click and print I get the first page only, but
> >> highlighting beforehand gives all the content. You might need to play
> >> with scaling before printing.
> >>
> >> Thanks very much Gabriela.  It works like a charm with Chrome, though
> >> not (at all) with Firefox.
> >
> > In Firefox (at least version 61+, but probably earlier), right click,
> > then select "This frame", then "Show only this frame", then print.
>
> Yep, that works.  Thanks.
>
> Not exactly intuitive, but, is it?  (The same must be said for
> Gabriela's solution.)
>
> Software designers often seem to ignore the needs of "ordinary"
> users. :-(
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Apr 14 00:14:00 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 14 Apr 2018 10:14:00 +1200
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
In-Reply-To: <CANOgrHYaaLomCSy=2Mdp+J9B=t0t83gUkL_DfkgnvTLyrDphTA@mail.gmail.com>
References: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
 <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>
 <E0860704-F18E-4FBC-9BEC-219A929EFC2B@sms.ed.ac.uk>
 <0ce960bb-a7d3-6e7a-b000-235f0842f2e2@auckland.ac.nz>
 <20180413104231.GA13922@upenn.edu>
 <1c7ca3a7-3b6a-63c4-255e-ac3fe0ba8a18@auckland.ac.nz>
 <CANOgrHYaaLomCSy=2Mdp+J9B=t0t83gUkL_DfkgnvTLyrDphTA@mail.gmail.com>
Message-ID: <c48703d8-98f0-807c-286f-82afc444cb31@auckland.ac.nz>

On 14/04/18 09:59, Mitchell Maltenfort wrote:
> Works nicely but I?m trying to track down how to move data back and forth.
> 
> I need to use glmm for predictions.

Does not work nicely for me.  I tried (as per Doug's instructions):

 > system.time(j <- julia_setup(JULIA_HOME=jh,verbose=TRUE))

where "jh" had been assigned the character string

     "/home/rolf/Desktop/Julia/julia-d386e40c17/bin/"

which is where I have the Julia binary currently living.

I got the response:

 > Julia version 0.6.2 at location 
/home/rolf/Desktop/Julia/julia-d386e40c17/bin will be used.
 > Julia initiation...
 > Finish Julia initiation.
 > Loading setup script for JuliaCall...
 > Segmentation fault (core dumped)

I have contacted the maintainer of the JuliaCall package, and he has 
responded and is looking into the problem.  (I am running R from the 
command line under Ubuntu 16.04.)

Has anyone else encountered such a seg fault?

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From G.K.Hajduk at ed.ac.uk  Fri Apr 13 11:10:51 2018
From: G.K.Hajduk at ed.ac.uk (HAJDUK Gabriela)
Date: Fri, 13 Apr 2018 09:10:51 +0000
Subject: [R-sig-ME] Vignette on using Julia MixedModels from R
In-Reply-To: <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>
References: <CAO7JsnQXzNHM=4JEy+F_=Qjkf5c+coCpi_GXkmstVKuqXagLOw@mail.gmail.com>
 <0d1e6f29-2490-7a9d-093c-d7a8e5ee451d@auckland.ac.nz>
Message-ID: <E0860704-F18E-4FBC-9BEC-219A929EFC2B@sms.ed.ac.uk>

Hello Rolf,

You can highlight all text (Ctrl/Cmd + A) and then right click and choose print. It should then give you the entire highlighted content - I?m on Chrome and if I just right click and print I get the first page only, but highlighting beforehand gives all the content. You might need to play with scaling before printing.

Best,
Gabriela


> On 13 Apr 2018, at 02:11, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 13/04/18 03:33, Douglas Bates wrote:
> 
>> Many users experience long execution times and convergence warnings when
>> trying to fit complex linear mixed-effects models with lmer.  I have, in
>> the past, shown that such models can be fit using the MixedModels (
>> https://github.com/dmbates/MixedModels.jl) package for Julia (
>> https://julialang.org) and that the data can be pulled from an R
>> representation using either the RCall (
>> https://github.com/JuliaInterop/RCall.jl) or RData (
>> https://github.com/JuliaData/RData.jl).
>> Recently the JuliaCall package for R (
>> https://github.com/Non-Contradiction/JuliaCall) has become available on
>> CRAN.  I have a short note at http://rpubs.com/dmbates/377897 on how to use
>> that package to fit models using MixedModels from R.
> 
> This is of considerable interest to me since I am involved in some consulting work (about which I have annoyed the r-sig-mixed-models list on previous occasions!) which involves mixed models and I have experienced the problems referred to in the opening line of your message.
> 
> So I had a look at http://rpubs.com/dmbates/377897 just now, and it looks promising.
> 
> I have however a possibly naive or misguided question:  How do I get a printed copy of the vignette?  I tried saving or printing the page that showed up in my browser (Firefox; GoogleChrome) in various ways.  The result always seems to get truncated at a single page, with the bulk of the document omitted.  (The document is also somewhat messed up in other ways.)
> 
> Is there a simple way of saving a copy of the vignette in such a way that I can print off a hard copy?  I suppose I am simply demonstrating my ignorance and showing that I am out of the loop when it comes to dealing with Rpubs and Rmarkdown documents, but that's the way it is.
> 
> Thanks for any tips and advice.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From pharrison at uwaterloo.ca  Fri Apr 13 21:04:06 2018
From: pharrison at uwaterloo.ca (Philip Harrison)
Date: Fri, 13 Apr 2018 19:04:06 +0000
Subject: [R-sig-ME] zero mean fixed effects priors in a cloglog link model
Message-ID: <71f5bb48f0ba4361a8bc2fbde4e0d625@uwaterloo.ca>

Hi List,


I have a presence-absence fish telemetry dataset that has a very high number of zero's (12,732 absences and 1120 presences). So I want fit a cloglog link GLMM, which seems to work better than a logit link.

However, I also have some quasi-complete seperation- that is I have all zeros
 in one of my factor level predictions.

So ideally I would like to try and fit zero mean normal priors for my fixed
effects levels using Ben Bolker's logit link
example https://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html
using bglmer.

so the logit model looks like this:
cmod_blme_L2 <- bglmer(predation~ttt+(1|block),data=newdat,
                       family=binomial,
                       fixef.prior = normal(cov = diag(9,4)))

where ttt is a categorical variable four levels
the priors provide 4 ? 4 diagonal matrix with diagonal
elements equal to 9, for variances of 9 or
standard deviations of 3.

So with the logit link above
-2sd will be -6 and +2SD would be +6 ...so pretty weak.

 inv.logit(-6)<- 0.002472623
 inv.logit(6)<- 0.9975274

Can I use the same priors for cloglog link?
invcloglog(-6) <- 0.002475683
  invcloglog(6)<- 1

My gut says yes it should work they are both weak and the issues are with the lower end.  The model runs nicely and gives sensible estimates.
However I figured it would be more correct to have 2xsd be -6 and +2 but I dont know how to code such a prior. I would consider using MCMCglmm too if it allowed me to fit those priors.

Any help would be much appreciated


Philip Harrison PhD
Post-Doc in Cooke and Power Labs
Department of Biology
University of Waterloo
200 University Avenue West
Waterloo, Ontario, Canada
N2L 3G1

Researchgate: http://tinyurl.com/RG-PMH
Google Scholar: http://tinyurl.com/ScholarPMH
Lab Website: http://www.fecpl.ca/people/philip-harrison/
Personal Website: https://pharriso4.wixsite.com/philipmharrison


	[[alternative HTML version deleted]]


From random at yorku.ca  Fri Apr 13 13:55:52 2018
From: random at yorku.ca (Georges Monette)
Date: Fri, 13 Apr 2018 07:55:52 -0400
Subject: [R-sig-ME] Longitudinal and Multilevel Data in R and Stan: 5-day
 workshop May 28 to June 1, 2018
Message-ID: <880932da-bbae-8f3b-8eb6-8a8eb63c2619@yorku.ca>

Longitudinal and Multilevel Data in R and Stan
ICPSR short course: May 28 to June 1, 2018

May 28: Introduction to R by John Fox
May 29 to June 1: Longitudinal and Multilevel Data in R and Stan by Georges Monette

Sponsored and organized by ICPSR, University of Michigan and
held at York University in Toronto, Ontario

Course description:https://www.icpsr.umich.edu/icpsrweb/sumprog/courses/0226

Applications:https://www.icpsr.umich.edu/icpsrweb/content/sumprog/registration.html

For further information, contact Bryn Greer-Wootten at ISR, York University:bryngw at yorku.ca


	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Sun Apr 15 13:00:08 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Sun, 15 Apr 2018 13:00:08 +0200
Subject: [R-sig-ME] ML vs. REML to find a parsimonious mixed model
Message-ID: <CAHr4Dycsa1wmOXKKmDuGzrQi8pxgXq55iQxjEoEzFvyYNmvUvA@mail.gmail.com>

I want to use LRTs via anova() on fitted linear mixed models (merMod
objects) to find a parsimonious mixed model containing only variance
components supported by the data (e.g. Matuschek et al. 2017 [1], Bates et
al. 2015 [2]).
In this situation my focus is *only on the reduction of the random effects
part* of the models.
The aforementioned papers use ML instead of REML estimation within this
process. Douglas Bates seems to prefer ML model comparison due to the
skewed nature of the distribution of variance estimators [3] and the user
Wolfgang states that "the ML estimator usually has lower mean-squared error
(MSE) than the REML estimator" [4]. However, literally every textbook I
know suggests using REML estimation when comparing mixed models that differ
only in their random effect parts.

What would you suggest in this particular situation? ML or REML?

Best regards,
Maarten

[1] https://arxiv.org/abs/1511.01864
[2] https://arxiv.org/abs/1506.04967
[3] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q3/023750.html
[4] https://stats.stackexchange.com/a/48770

	[[alternative HTML version deleted]]


From ligia_oceanica at hotmail.com  Tue Apr 17 03:14:35 2018
From: ligia_oceanica at hotmail.com (Ligia Pizzatto do Prado)
Date: Tue, 17 Apr 2018 01:14:35 +0000
Subject: [R-sig-ME] Enc: error: model is nearly unidentifiable
In-Reply-To: <CO1PR15MB1077F471DE0E7C2F59065320F7B10@CO1PR15MB1077.namprd15.prod.outlook.com>
References: <26750_1523254464_w396EN8t018225_CO1PR15MB1077BCD8F3D8AE4D75F71153F7BF0@CO1PR15MB1077.namprd15.prod.outlook.com>,
 <ACD1644AA6C67E4FBD0C350625508EC8367DF5AD@FHSDB2D11-2.csu.mcmaster.ca>,
 <CO1PR15MB1077F471DE0E7C2F59065320F7B10@CO1PR15MB1077.namprd15.prod.outlook.com>
Message-ID: <CO1PR15MB10771814192614F5AA33BB19F7B70@CO1PR15MB1077.namprd15.prod.outlook.com>



Dear John, thanks for your reply.


I tried to simplify my variables names when posted (originally named Fchoice and changed to choice), so Fchoice was just a typo in the formula when posting, it was all the same in the model thou...


I doubled checked the data and it is correct, 24 0s and 42 1s for my response variable. it is a coincidence. 6 frogs chose 1 in both trials, 6 chose 0 and 12 chose had 0 and 1 in each trial. So, no choice don't seem invariant within frogs, but I now pasted the dataset bellow.


Lets try again...


The experiment is a two choice habitat ("Fchoice": poor [0] vs rich [1]) for frogs under two-state treatments, lets say F and C. Then I have as potential variables frog size ("SUL"), air temperature ("temp"), humidity ("hum") and date of experiment ("dateCont" recorded as continuos variable starting at day 1...). This is a repeated measure design as frogs were tested both in F and C trials (thus id is my random effect). I want to know if the choice is affected by treat, but also considering SUL, temp, humidity, and date in my model.

##Dataset:

newdata
   treat id Fchoice  SUL temp hum dateCont
1      F  1       1 42.5 27.0  53        1
2      F  2       0 36.5 27.0  53        1
3      F  3       0 38.1 27.0  53        1
4      F  4       0 46.4 27.0  53        1
5      C  5       1 35.7 27.3  63        2
6      C  6       1 41.6 27.3  63        2
7      C  7       0 45.4 27.3  63        2
8      C  8       1 43.6 27.3  63        2
9      C  1       1 42.5 27.5  64        3
10     C  3       0 38.1 27.5  64        3
11     C  4       1 46.4 27.5  64        3
12     F  5       1 35.7 27.4  59        4
13     F  6       1 41.6 27.4  59        4
14     F  7       1 45.4 27.4  59        4
15     F  8       0 43.6 27.4  59        4
16     C  2       0 36.5 27.9  60        5
17     C  9       1 46.0 27.9  60        5
18     C 10       1 38.0 27.9  60        5
19     C 11       0 46.9 27.9  60        5
20     F 10       1 38.0 27.4  63        8
21     F 11       0 46.9 27.4  63        8
22     F 12       1 37.6 27.4  63        8
23     F  9       0 46.0 26.3  76        9
24     C 13       1 38.3 25.1  75        9
25     C 14       0 47.3 25.1  75        9
26     C 15       1 37.6 25.1  75        9
27     C 12       0 37.6 25.1  75       11
28     F 13       0 38.3 26.3  76       11
29     F 14       0 47.3 26.3  76       11
30     F 15       0 37.6 26.3  76       11
31     C 16       1 38.9 26.3  55       15
32     C 17       0 38.9 26.3  55       15
33     C 18       0 42.3 26.3  55       15
34     F 20       0 51.0 26.3  59       16
35     F 21       0 43.5 26.3  59       16
36     F 22       1 43.5 26.3  59       16
37     F 16       0 38.9 27.6  57       19
38     F 17       1 38.9 27.6  57       19
39     F 18       0 42.3 27.6  57       19
40     C 20       0 51.0 27.3  75       22
41     C 21       1 43.5 27.3  75       22
42     C 22       1 43.5 27.3  75       22
43     C 23       1 41.6 27.3  75       22
44     F 23       0 41.6 25.1  69       23
45     F 24       1 43.9 25.1  69       23
46     F 25       0 43.5 25.1  69       23
47     C 24       1 43.9 24.8  55       24
48     C 25       1 43.5 24.8  55       24

summary(newdata)
 treat        id     Fchoice      SUL             temp            hum
 C:24   1      : 2   0:24    Min.   :35.70   Min.   :24.80   Min.   :53.00
 F:24   2      : 2   1:24    1st Qu.:38.25   1st Qu.:26.30   1st Qu.:58.50
        3      : 2           Median :42.40   Median :27.30   Median :63.00
        4      : 2           Mean   :42.02   Mean   :26.74   Mean   :63.65
        5      : 2           3rd Qu.:44.27   3rd Qu.:27.40   3rd Qu.:70.50
        6      : 2           Max.   :51.00   Max.   :27.90   Max.   :76.00
        (Other):36
    dateCont
 Min.   : 1.00
 1st Qu.: 4.00
 Median : 9.00
 Mean   :10.75
 3rd Qu.:16.75
 Max.   :24.00

## The models:

>m1<- glmer(Fchoice ~ treat + SUL + temp + hum + dateCont + (1|id), data = newdata, family = binomial)
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

> null<- glmer(Fchoice ~ 1 + (1|id), data = newdata, family = binomial)
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

m2<- glmer(Fchoice ~ treat + SUL + temp + dateCont + (1|id), data = data, family = binomial)
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

> m3<- glmer(Fchoice ~ treat + SUL + dateCont + (1|id), data = data, family = binomial)

> m4<- glmer(Fchoice ~ treat + SUL + temp + (1|id), data = data, family = binomial)
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

> m5<- glmer(Fchoice ~ treat + SUL + (1|id), data = data, family = binomial)

> m6<- glmer(Fchoice ~ treat  + (1|id), data = data, family = binomial)

> m7<- glmer(Fchoice ~ treat + SUL + hum + (1|id), data = data, family = binomial)
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

I can see that dateCont and temp are significantly correlated, but dateCont and hum are not.

I'm using R 3.3.3 GUI 1.69 Mavericks build (7328). Is this enough info to reproduce, John?

Cheers,

Ligia
________________________________
De: Fox, John <jfox at mcmaster.ca>
Enviado: segunda-feira, 9 de abril de 2018 14:14
Para: Ligia Pizzatto do Prado
Cc: r-sig-mixed-models at r-project.org
Assunto: RE: error: model is nearly unidentifiable

Dear Ligia,

Without your data, and therefore without a reproducible example, one can only speculate about the source of the problem. I noticed, however, that your response variable (choice) has equal numbers of 0s and 1s -- 24 of each. Was that simply a coincidence? As well, the response is named "choice" in the earlier part of your message and model "null," but "Fchoice" in model "m1." Why?

More generally, the question mark in "Rescale variables?" indicates that this is a common source of numerical instability but not the only one. For example, highly collinear predictors could also produce a nearly unidentified model. What's curious is that you're observing this problem in a model with only an intercept. Perhaps, e.g., choice is invariant within frogs.

Reading the posting guide at <https://www.r-project.org/posting-guide.html> might help you to formulate your question more effectively.
R: Posting Guide: How to ask good questions that prompt ...<https://www.r-project.org/posting-guide.html>
www.r-project.org
Posting Guide: How to ask good questions that prompt useful answers. This guide is intended to help you get the most out of the R mailing lists, and to avoid embarrassment.




I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ligia Pizzatto do Prado
> Sent: Monday, April 9, 2018 2:14 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] error: model is nearly unidentifiable
>
> Hi there, I'm new to mixed models but have ran a few with success before. Now,
> while trying to analyse this new experiment I am  having an error that I quite
> don't understand...
>
>
> The experiment is a two choice habitat ("choice": poor [0] vs rich [1]) for frogs
> under two-state treatments, lets say F and C. Then I have as potential variables
> frog size ("size"), air temperature ("temp"), humidity ("hum") and date of
> experiment (recorded as continuos variable starting at day 1...). This is a
> repeated measure design as frogs were tested both in F and C trials (thus id is my
> random effect). I want to know if the choice is affected by treat, but also
> considering size, temp, humidity, and date in my model.
>
>
> First I did:
>
>
> data$treat<- factor(data$treat)
>
> data$id<- factor(data$id)
>
> data$choice<- factor(data$choice)
>
>
> summary(data)
>
> treat        id     choice
>
> C:24   1      : 2   0:24
>
> F:24   2      : 2   1:24
>
>            3      : 2
>
>            4      : 2
>
>            5      : 2
>
>            6      : 2
>
>       (Other):36
>
>
>
> size                     temp                      hum                   date
>
>  Min.   :35.70      Min.   :24.80       Min.   :53.00       Min.   : 1.00
>
>  1st Qu.:38.25     1st Qu.:26.30     1st Qu.:58.50     1st Qu.: 4.00
>
>  Median :42.40   Median :27.30   Median :63.00   Median : 9.00
>
>  Mean   :42.02    Mean   :26.74     Mean   :63.65    Mean   :10.75
>
>  3rd Qu.:44.27    3rd Qu.:27.40     3rd Qu.:70.50    3rd Qu.:16.75
>
>  Max.   :51.00      Max.   :27.90     Max.   :76.00       Max.   :24.00
>
> m1<- glmer(Fchoice ~ treat + SUL + temp + hum + date + (1|id), data = data,
> family = binomial)
>
> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
>
>
> I keep getting this message in all models except when I exclude both temp and
> hum, but I also get the message when tried null model: null<- glmer(choice ~ 1 +
> (1|id), data = data, family = binomial)
>
>
> I tried to transform/re-scale all continuous variable (temp, hum, date) and
> nothing changed, and I quite don't understand why the error also appears in the
> null model, given id is a factor... If its a scale problem wouldn't this only appear
> in the continuous variables?
>
>
> Can anyone provide some guidance here, please?
>
>
> TIA,
>
>
> Ligia
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Tue Apr 17 06:25:52 2018
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Tue, 17 Apr 2018 04:25:52 +0000
Subject: [R-sig-ME] error: model is nearly unidentifiable
In-Reply-To: <CO1PR15MB10771814192614F5AA33BB19F7B70@CO1PR15MB1077.namprd15.prod.outlook.com>
References: <26750_1523254464_w396EN8t018225_CO1PR15MB1077BCD8F3D8AE4D75F71153F7BF0@CO1PR15MB1077.namprd15.prod.outlook.com>,
 <ACD1644AA6C67E4FBD0C350625508EC8367DF5AD@FHSDB2D11-2.csu.mcmaster.ca>,
 <CO1PR15MB1077F471DE0E7C2F59065320F7B10@CO1PR15MB1077.namprd15.prod.outlook.com>,
 <CO1PR15MB10771814192614F5AA33BB19F7B70@CO1PR15MB1077.namprd15.prod.outlook.com>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D4A849C1C4@EXCH06S.adqimr.ad.lan>

> The experiment is a two choice habitat ("Fchoice": poor [0] vs rich
> [1]) for frogs under two-state treatments, lets say F > and C. Then
> I have as potential variables frog size ("SUL"), air temperature
> ("temp"), humidity ("hum") and date of experiment ("dateCont" recorded
> as continuous variable starting at day 1...). This is a repeated
> measure design as frogs were tested both in F and C trials (thus id is
> my random effect). I want to know if the choice is affected by treat,
> but also considering SUL, temp, humidity, and date in my model.

Should date rather be a factor? That would make the model even harder to fit, as you would
have too few data for the number of coefficients to be estimated.

Since you have exactly 2 obs per ID, then a generalized estimating equation should be pretty close,
and tends to be a bit more stable.  We can also check comparing the
glmmML fit - it is set up only for a simple RE model like yours, but the fitter often does a better job for those.

library(gee)
summary(gee(Fchoice ~ treat + SUL + temp + hum + dateCont, id=id, data=x,
                         corstr="exchangeable", family="binomial"))
library(glmmML)
summary(glmmML(Fchoice ~ treat + SUL + temp + hum + dateCont, cluster=id, data=x, family="binomial"))

               GEE (exchangeable r=0.08)         glmmML                   glmer
               Estimate Robust S.E.    Robust z     coef se(coef)       z Estimate Std. Error z value 
(Intercept) -0.88719918 10.40645085 -0.08525473 -1.13855 11.88440 -0.0958 -1.14557   11.89332  -0.096 
treatF      -1.15044245  0.64272611 -1.78994198 -1.21411  0.70458 -1.7232 -1.21572    0.70451  -1.726 
SUL         -0.10705958  0.07911966 -1.35313499 -0.11373  0.09252 -1.2293 -0.11384    0.09255  -1.230 
temp         0.25765994  0.35199301  0.73200300  0.28526  0.41123  0.6937  0.28591    0.41136   0.695 
hum         -0.01921368  0.03913854 -0.49091468 -0.02243  0.04662 -0.4812 -0.02252    0.04665  -0.483 
dateCont     0.02696366  0.04181628  0.64481255  0.02962  0.05015  0.5905  0.02965    0.05020   0.591 

Looks like glmer has found a solution close to that accepted by the other approaches. To me, suggests that glmer has worked OK.


From jcm6t at virginia.edu  Tue Apr 17 19:43:30 2018
From: jcm6t at virginia.edu (Mychaleckyj, Josyf C. (Joe) (jcm6t))
Date: Tue, 17 Apr 2018 17:43:30 +0000
Subject: [R-sig-ME] Custom nlme::CorStruct Class based on CorCompSymm
References: <D86CC96B-9C0E-416C-B165-D65BA475D9FB@virginia.edu>
Message-ID: <4D1F3DEE-8804-4CE1-BC4B-D89F1D1D8F44@virginia.edu>



I am working on a custom CorStruct class based on CorCompSymm. There will be a single parameter passed into the class for optimization, like rho.The grouping will be ~ 1 | Subject. Initially i plan to use this with gls but ultimately would like to extend to lme also.

The complication in this case is that the calculation of the correlation matrices requires another fixed parameter that varies between pairs of repeated observations within each subject - this will be passed into the functions as a numerical lower.tri() vector.  Within corMatrix I need to be sure that I am applying the correct parameter value from the vector to the correct pair of observations for the within-Subject correlation matrix.

For example: in a Subject with 3 observations, fixparam[1,2] = fixparam[2,1] = 0.25; fixparam[1,3] = param[3,1] = 0.125, etc.
(this is a genetics application but I?m keeping genetics out of the discussion).

From P&B discussion of groupedData I expected the Subjects to be default ordered as max within-group response. This is true in getGroups but my simple tests using the Orthodont data suggest that the subject list and observations are simply ordered by first occurrence in the data.frame of observations as exposed within CorMatrix. I can?t determine the ordering within Subject from my test case below but assuming as per df order.

I?ve posted a scrambled unbalanced test case below to show my reasoning. My specific questions:

1. Am i correct in my inference as to how Subjects and observations are accessed in the CorCompSymm class on which I am basing my custom class ? Hopefully the  print method is not reordering under the covers.

2. Can i rely on this default ordering to be preserved ?

3. I would feel better if there were some way to specify the rowname or a unique identifier for each observation to index the fixed parameter vector, but not alter the RE structure with a covariate. Any hidden tricks ?


Thanks for your help,

Joe.


# Test case:
# 1.  Create a simple unbalanced scrambled subset of Orthodont to test for precedence

> Orthodont.sub
Grouped Data: distance ~ age | Subject
    distance age Subject    Sex
11      24.0  12     M03   Male
106     25.0  10     F11 Female
105     24.5   8     F11 Female
107     28.0  12     F11 Female
80      26.5  14     F04 Female
78      24.5  10     F04 Female
77      23.5   8     F04 Female
25      22.0   8     M07   Male
10      22.5  10     M03   Male
108     28.0  14     F11 Female

> table(Orthodont.sub$Subject)
M07 M03 F04 F11
  1   2   3   4

# as expected based on P & B
> getGroups(Orthodont.sub)
 [1] M03 F11 F11 F11 F04 F04 F04 M07 M03 F11
Levels: M07 < M03 < F04 < F11

> cs4<- corCompSymm(value = 0.3,form = ~ 1 | Subject)
> cs4<- Initialize(cs4, data = Orthodont.sub)

# Subject order in list M03, F11, F04, M07
> corMatrix(cs4)
$M03
     [,1] [,2]
[1,]  1.0  0.3
[2,]  0.3  1.0

$F11
     [,1] [,2] [,3] [,4]
[1,]  1.0  0.3  0.3  0.3
[2,]  0.3  1.0  0.3  0.3
[3,]  0.3  0.3  1.0  0.3
[4,]  0.3  0.3  0.3  1.0

$F04
     [,1] [,2] [,3]
[1,]  1.0  0.3  0.3
[2,]  0.3  1.0  0.3
[3,]  0.3  0.3  1.0

$M07
     [,1]
[1,]    1

# Now check that the same thing happens with Orthodont coerced to simple data frame
> Orthodont.sub<-as.data.frame(Orthodont.sub)
> Orthodont.sub
    distance age Subject    Sex
11      24.0  12     M03   Male
106     25.0  10     F11 Female
105     24.5   8     F11 Female
107     28.0  12     F11 Female
80      26.5  14     F04 Female
78      24.5  10     F04 Female
77      23.5   8     F04 Female
25      22.0   8     M07   Male
10      22.5  10     M03   Male
108     28.0  14     F11 Female

# double check
> table(Orthodont.sub$Subject)
M07 M03 F04 F11
  1   2   3   4

# all appears to be the same as cs4 - does not depend on groupedData object
> cs5<- corCompSymm(value = 0.3,form = ~ 1 | Subject)
> cs5<- Initialize(cs5, data = Orthodont.sub)
> corMatrix(cs5)
$M03
     [,1] [,2]
[1,]  1.0  0.3
[2,]  0.3  1.0

$F11
     [,1] [,2] [,3] [,4]
[1,]  1.0  0.3  0.3  0.3
[2,]  0.3  1.0  0.3  0.3
[3,]  0.3  0.3  1.0  0.3
[4,]  0.3  0.3  0.3  1.0

$F04
     [,1] [,2] [,3]
[1,]  1.0  0.3  0.3
[2,]  0.3  1.0  0.3
[3,]  0.3  0.3  1.0

$M07
     [,1]
[1,]    1






	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Apr 18 02:16:34 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 18 Apr 2018 12:16:34 +1200
Subject: [R-sig-ME] Binomial generalised linear mixed model using JuliaCall.
Message-ID: <9fe5ca27-4dc7-bdd0-8b87-4e37a73544b7@auckland.ac.nz>


Hi all.

I seem to have managed (not quite sure how! :-) ) with considerable 
assistance from the maintainer of the JuliaCall package, to get that 
package running.

I am however having a struggle to figure out how to fit the sort of 
model that I am interested in.  The vignette that Doug Bates provided a 
while back gives an example of fitting a linear mixed model, and I have 
managed to reproduce that example.  (My results differed from those that 
Doug's vignette showed, ever so slightly in the values of some of the 
variance components, but I'm not going to worry my pretty little head 
about that.)

Now I want to proceed to my "real problem" which is to fit a 
*generalised* linear mixed model, of the binomial persuasion, and I 
cannot find my way to documentation on how to do this.

The syntax for the sort of fit that I want would be, in the glmer() 
context, of the form:

fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/prd + (prd | Rep),data=Dat,
              family=binomial(link=logit))

where "Trt" is a factor (fixed effect), "prd" is a numeric predictor,
and "Rep" is a factor (random effect).

Can anyone instruct me (in very simple terms please, I'm slow!) as to 
what the analogous syntax would be using the MixedModels package in 
Julia?  Or point me at an elementary tutorial on doing this?

I have the impression, from one item that I saw on StackExchange, that 
MixedModels doesn't really handle general binomial models, only 
Bernoulli models.  Consequently one has to expand out one's data set
creating one row for each success ("Dead" in my case) and one row for 
each failure ("Alive").  Is this correct, or is there an easier way to 
go about it?

Thanks for any words of wisdom.

cheers,

Rolf Turner

Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bbolker at gmail.com  Wed Apr 18 05:58:11 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Apr 2018 23:58:11 -0400
Subject: [R-sig-ME] 
 Binomial generalised linear mixed model using JuliaCall.
In-Reply-To: <9fe5ca27-4dc7-bdd0-8b87-4e37a73544b7@auckland.ac.nz>
References: <9fe5ca27-4dc7-bdd0-8b87-4e37a73544b7@auckland.ac.nz>
Message-ID: <CABghstQ+4D4wU1QqD5VKPOXyBHUuWBr0Yd6tUMDu58m_=Dw+Vw@mail.gmail.com>

Don't have time to dig into this right now (I'm not an expert), but the docs at

https://github.com/dmbates/MixedModels.jl/blob/master/docs/jmd/constructors.jmd#L104


say:

> Note that, in keeping with convention in the [`GLM` package](https://github.com/JuliaStats/GLM.jl), the distribution family for a binary (i.e. 0/1) response is the `Bernoulli` distribution.
The `Binomial` distribution is only used when the response is the
fraction of trials returning a positive, in which case the number of
trials must be specified as the case weights.

   ... which implies that you can do what you want.

https://github.com/dmbates/MixedModels.jl/blob/fd22daf226938a4f98ce3d4b228e5a99437e3218/src/pls.jl#L61

seem to give 'weights' as the third argument to the LinearMixedModel
function ... ?

On Tue, Apr 17, 2018 at 8:16 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> Hi all.
>
> I seem to have managed (not quite sure how! :-) ) with considerable
> assistance from the maintainer of the JuliaCall package, to get that package
> running.
>
> I am however having a struggle to figure out how to fit the sort of model
> that I am interested in.  The vignette that Doug Bates provided a while back
> gives an example of fitting a linear mixed model, and I have managed to
> reproduce that example.  (My results differed from those that Doug's
> vignette showed, ever so slightly in the values of some of the variance
> components, but I'm not going to worry my pretty little head about that.)
>
> Now I want to proceed to my "real problem" which is to fit a *generalised*
> linear mixed model, of the binomial persuasion, and I cannot find my way to
> documentation on how to do this.
>
> The syntax for the sort of fit that I want would be, in the glmer() context,
> of the form:
>
> fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/prd + (prd | Rep),data=Dat,
>              family=binomial(link=logit))
>
> where "Trt" is a factor (fixed effect), "prd" is a numeric predictor,
> and "Rep" is a factor (random effect).
>
> Can anyone instruct me (in very simple terms please, I'm slow!) as to what
> the analogous syntax would be using the MixedModels package in Julia?  Or
> point me at an elementary tutorial on doing this?
>
> I have the impression, from one item that I saw on StackExchange, that
> MixedModels doesn't really handle general binomial models, only Bernoulli
> models.  Consequently one has to expand out one's data set
> creating one row for each success ("Dead" in my case) and one row for each
> failure ("Alive").  Is this correct, or is there an easier way to go about
> it?
>
> Thanks for any words of wisdom.
>
> cheers,
>
> Rolf Turner
>
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r.turner at auckland.ac.nz  Wed Apr 18 07:28:24 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 18 Apr 2018 17:28:24 +1200
Subject: [R-sig-ME] 
 Binomial generalised linear mixed model using JuliaCall.
In-Reply-To: <CABghstQ+4D4wU1QqD5VKPOXyBHUuWBr0Yd6tUMDu58m_=Dw+Vw@mail.gmail.com>
References: <9fe5ca27-4dc7-bdd0-8b87-4e37a73544b7@auckland.ac.nz>
 <CABghstQ+4D4wU1QqD5VKPOXyBHUuWBr0Yd6tUMDu58m_=Dw+Vw@mail.gmail.com>
Message-ID: <a67cc4e8-c489-6417-b452-5bd776b22dae@auckland.ac.nz>


On 18/04/18 15:58, Ben Bolker wrote:

> Don't have time to dig into this right now (I'm not an expert), but the docs at
> 
> https://github.com/dmbates/MixedModels.jl/blob/master/docs/jmd/constructors.jmd#L104
> 
> 
> say:
> 
>> Note that, in keeping with convention in the [`GLM` package](https://github.com/JuliaStats/GLM.jl), the distribution family for a binary (i.e. 0/1) response is the `Bernoulli` distribution.
> The `Binomial` distribution is only used when the response is the
> fraction of trials returning a positive, in which case the number of
> trials must be specified as the case weights.
> 
>     ... which implies that you can do what you want.
> 
> https://github.com/dmbates/MixedModels.jl/blob/fd22daf226938a4f98ce3d4b228e5a99437e3218/src/pls.jl#L61
> 
> seem to give 'weights' as the third argument to the LinearMixedModel
> function ... ?

Thanks Ben.  That looks like it holds out some hope.  I'll try to pursue 
it.  I still cannot discern aspects of the syntax however.  The docs say 
that the "canonical link, which is `GLM.LogitLink` for the `Bernoulli` 
distribution, is used if no explicit link is specified."  But I can't 
find how to specify other links (e.g. cloglog).

I shall keep searching.

Thanks again.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From karistaeh at gmail.com  Wed Apr 18 21:04:25 2018
From: karistaeh at gmail.com (Karista Hudelson)
Date: Wed, 18 Apr 2018 15:04:25 -0400
Subject: [R-sig-ME] random slopes model specification
Message-ID: <CAKeD0uiowfYs1QJkTX7un2u96YqR3SO-se_YwduVvCGc4HmCuw@mail.gmail.com>

Hello Mixed Modelers,

I was hoping to get a bit of feedback on the random effects structure of
the model below.  I wanted to allow two of the fixed effects (my effects of
interest) to have random slopes and also random intercepts for each
watershed (there are 5 watersheds, 27 observations of Spring_MST &
Summer_Rain, and 790 fish (so there are 790 measurements of Hg and
FishLength).

 model6<-lmer(Hg~FishLength+Spring_MST+Summer_Rain+(1+Spring_MST+Summer_Rain|watershed),data=FSV,REML=FALSE)

this model converges, and the output looks "like I want it to look"; ie,
slopes are different for the two effects which logically should have
different slopes:

>   coef(model6)
$watershed
       (Intercept)    FishLength Spring_MST Summer_Rain
877911    -1.7734565 0.02147013 0.03245297 -0.04841394
3319324   -1.2429440 0.02147013 0.03037712 -0.04472220
11597701  -1.6688121 0.02147013 0.03204351 -0.04768574
31121323  -0.9214729 0.02147013 0.02911923 -0.04248513
97032352  -1.4819562 0.02147013 0.03131236 -0.04638544


Here is a bit of the summary() for model6:
Fixed effects:
              Estimate Std. Error         df t value Pr(>|t|)
(Intercept)  -1.417728   0.144246   6.000000  -9.829 6.18e-05 ***
Length        0.021470   0.001085 783.800000  19.794  < 2e-16 ***
Spring_MST    0.031061   0.007518 312.000000   4.132 4.63e-05 ***
Summer_Rain  -0.045938   0.007276 132.100000  -6.314 3.82e-09 ***

It seems to be doing what I intended, but the random effects structure
looks like a bit of a run-on sentence compared to most of the other models
I've seen.  Does this appear correct?

Also....if I'm allowing for the slopes of  the effects of interest to be
different for each watershed and allowing intercepts to be different, in
your opinion(s) would it be easier to understand if I just run separate
models for each lake?  Here how that looks for the Lake with watershed  877911
(corresponding to top line of coef() table above):

> clim<-Hg~FishLength+Spring_MST+Summer_Rain
> climS<-lm(clim,data=Smid)
> summary(climS)

              Estimate Std. Error t value Pr(>|t|)
(Intercept) -1.3531180  0.2152754  -6.286 2.19e-09 ***
Length       0.0276015  0.0027818   9.922  < 2e-16 ***
Spring_MST   0.0247300  0.0081347   3.040 0.002699 **
Summer_Rain -0.0025433  0.0007216  -3.525 0.000531 ***

Any thoughts are appreciated.  Thanks in advance for your time and brain
power.

Much Obliged,
Karista Hudelson

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Apr 18 21:54:09 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Apr 2018 15:54:09 -0400
Subject: [R-sig-ME] random slopes model specification
In-Reply-To: <CAKeD0uiowfYs1QJkTX7un2u96YqR3SO-se_YwduVvCGc4HmCuw@mail.gmail.com>
References: <CAKeD0uiowfYs1QJkTX7un2u96YqR3SO-se_YwduVvCGc4HmCuw@mail.gmail.com>
Message-ID: <CABghstTc9yqY7jeKCr_Yj7dSC8jOTk1kPyWLw+5xV1Zsdv0ytQ@mail.gmail.com>

On Wed, Apr 18, 2018 at 3:04 PM, Karista Hudelson <karistaeh at gmail.com> wrote:
> Hello Mixed Modelers,
>
> I was hoping to get a bit of feedback on the random effects structure of
> the model below.  I wanted to allow two of the fixed effects (my effects of
> interest) to have random slopes and also random intercepts for each
> watershed (there are 5 watersheds, 27 observations of Spring_MST &
> Summer_Rain, and 790 fish (so there are 790 measurements of Hg and
> FishLength).
>
>  model6<-lmer(Hg~FishLength+Spring_MST+Summer_Rain+(1+Spring_MST+Summer_Rain|watershed),data=FSV,REML=FALSE)
>
> this model converges, and the output looks "like I want it to look"; ie,
> slopes are different for the two effects which logically should have
> different slopes:
>
>>   coef(model6)
> $watershed
>        (Intercept)    FishLength Spring_MST Summer_Rain
> 877911    -1.7734565 0.02147013 0.03245297 -0.04841394
> 3319324   -1.2429440 0.02147013 0.03037712 -0.04472220
> 11597701  -1.6688121 0.02147013 0.03204351 -0.04768574
> 31121323  -0.9214729 0.02147013 0.02911923 -0.04248513
> 97032352  -1.4819562 0.02147013 0.03131236 -0.04638544

    Notice that there is not much variability  in your coefficients
across watersheds
(zero variability in FishLength effects because you left it out of your random
effects on purpose, about 10% variability in Spring_MST and Summer_Rain).
Normally it's not recommended to fit a model with three correlated RE terms
(intercept, spring_MST, summer_rain) to only a grouping factor with
only 5 levels -- this is
equivalent to trying to estimate a 3x3 variance-covariance matrix with
5 observations
(I'm a little surprised this worked at all).  Are all the values in
getME(fitted_model,"theta") 'reasonable',
i.e. larger than (say) 1e-4?

   There is a huge, ongoing debate about what to do in this case,
where the RE model
you want is theoretically identifiable (you do have multiple
measurements of spring_MST
and summer_RAIN in each watershed), but practically very poorly
constrained, suggestions ranging from

  "keep it maximal" (Barr et al): fit the full model, reduce when the
model is singular
  try to constrain complexity _a priori_, reduce by model selection
(AIC or p-value based)
  use Bayesian methods to add priors/regularize the problem
  substitute fixed effects instead.

>
>
> Here is a bit of the summary() for model6:
> Fixed effects:
>               Estimate Std. Error         df t value Pr(>|t|)
> (Intercept)  -1.417728   0.144246   6.000000  -9.829 6.18e-05 ***
> Length        0.021470   0.001085 783.800000  19.794  < 2e-16 ***
> Spring_MST    0.031061   0.007518 312.000000   4.132 4.63e-05 ***
> Summer_Rain  -0.045938   0.007276 132.100000  -6.314 3.82e-09 ***
>
> It seems to be doing what I intended, but the random effects structure
> looks like a bit of a run-on sentence compared to most of the other models
> I've seen.  Does this appear correct?
>
> Also....if I'm allowing for the slopes of  the effects of interest to be
> different for each watershed and allowing intercepts to be different, in
> your opinion(s) would it be easier to understand if I just run separate
> models for each lake?  Here how that looks for the Lake with watershed  877911
> (corresponding to top line of coef() table above):
>
>> clim<-Hg~FishLength+Spring_MST+Summer_Rain
>> climS<-lm(clim,data=Smid)
>> summary(climS)
>
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept) -1.3531180  0.2152754  -6.286 2.19e-09 ***
> Length       0.0276015  0.0027818   9.922  < 2e-16 ***
> Spring_MST   0.0247300  0.0081347   3.040 0.002699 **
> Summer_Rain -0.0025433  0.0007216  -3.525 0.000531 ***
>
> Any thoughts are appreciated.  Thanks in advance for your time and brain
> power.

  Fitting separate models will be almost equivalent to fitting a single

Hg~(FishLength+Spring_MST+Summer_Rain):watershed

model -- the only difference will be whether the residual variance is
pooled/assumed to be
the same across watersheds.

>
> Much Obliged,
> Karista Hudelson
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Apr 18 23:11:41 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Apr 2018 17:11:41 -0400
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
Message-ID: <4df58563-e902-809e-f849-e6ddbd8ea987@gmail.com>


  Is anyone else getting spam responses to r-sig-mixed-models posts?

  cheers
   Ben Bolker


From Phillip.Alday at mpi.nl  Thu Apr 19 00:24:37 2018
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Wed, 18 Apr 2018 22:24:37 +0000
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
Message-ID: <82871249-91ec-4674-b4bb-f814cf9c77a4@mpi.nl>

Not yet, but a similar problem was just reported on r-help (under the slightly more panicky subject "hacked")

Phillip

Sent from my mobile, please excuse the brevity.
________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Wednesday, April 18, 2018 11:11 PM
To: r-sig-mixed-models at r-project.org; r-sig-mixed-models-owner at r-project.org
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?


  Is anyone else getting spam responses to r-sig-mixed-models posts?

  cheers
   Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Thu Apr 19 02:05:32 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 19 Apr 2018 00:05:32 +0000
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
In-Reply-To: <4df58563-e902-809e-f849-e6ddbd8ea987@gmail.com>
References: <4df58563-e902-809e-f849-e6ddbd8ea987@gmail.com>
Message-ID: <CAHr4Dyen6iZ=bMV88SRsO8FW3kg2EZJX=FL6K453PgY-x0SShQ@mail.gmail.com>

I am getting spam responses, too!

Regards,
Maarten Jung

On Wed, Apr 18, 2018, 23:11 Ben Bolker <bbolker at gmail.com> wrote:

>
>   Is anyone else getting spam responses to r-sig-mixed-models posts?
>
>   cheers
>    Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From T.Houslay at exeter.ac.uk  Thu Apr 19 10:25:17 2018
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Thu, 19 Apr 2018 08:25:17 +0000
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
In-Reply-To: <mailman.16394.1320.1524096350.1209.r-sig-mixed-models@r-project.org>
References: <mailman.16394.1320.1524096350.1209.r-sig-mixed-models@r-project.org>
Message-ID: <VI1PR03MB30407F1C034639BD1D05E7CAD2B50@VI1PR03MB3040.eurprd03.prod.outlook.com>

Yep - I got a load of ~interesting~ emails in response to a post a few days ago


________________________________
Date: Wed, 18 Apr 2018 17:11:41 -0400
From: Ben Bolker <bbolker at gmail.com>
To: "r-sig-mixed-models at r-project.org"
        <r-sig-mixed-models at r-project.org>,
        r-sig-mixed-models-owner at r-project.org
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
Message-ID: <4df58563-e902-809e-f849-e6ddbd8ea987 at gmail.com>
Content-Type: text/plain; charset="utf-8"


  Is anyone else getting spam responses to r-sig-mixed-models posts?

  cheers
   Ben Bolker




	[[alternative HTML version deleted]]


From karistaeh at gmail.com  Thu Apr 19 17:13:25 2018
From: karistaeh at gmail.com (Karista Hudelson)
Date: Thu, 19 Apr 2018 11:13:25 -0400
Subject: [R-sig-ME] random slopes model specification
In-Reply-To: <CABghstTc9yqY7jeKCr_Yj7dSC8jOTk1kPyWLw+5xV1Zsdv0ytQ@mail.gmail.com>
References: <CAKeD0uiowfYs1QJkTX7un2u96YqR3SO-se_YwduVvCGc4HmCuw@mail.gmail.com>
 <CABghstTc9yqY7jeKCr_Yj7dSC8jOTk1kPyWLw+5xV1Zsdv0ytQ@mail.gmail.com>
Message-ID: <CAKeD0uiSAG-QXEE2gG88W5+ReDx0iuof=s+swwkZP+9=fZwj4A@mail.gmail.com>

Greetings again Modelers,

Thanks for the reply Dr. Bolker.  You brought up some excellent points: the
theta values were ~ 0; I was trying to "keep it maximal" (Schielzeth &
Forstmeier 2008); I was also surprised this converged/ "worked".  Your
point about the residual pooled variance vs allowing the variance to be
different speaks directly about my hypothesis that "one model should rule
them all", if climate is truly driving variance, it should influence all
the lakes, but in fact the models I've made thus far do not support this
very well.  Also noted from your reply: I have too many fixed effects and
not enough variance to explain with them...yes.

Nonetheless, I have one follow up question, I would very much appreciate an
experienced point of view:
If I'm mostly interested in the effect of the two climate effects (and only
including watershed and FishLength because they're influential), then
should I try to allow the slopes to vary, but the intercept, which is set
mainly due to watershed and FishLength, not to vary (because the intercept
is not informative for my hypothesis, it's more about the slopes, I
think)?

For example:

model7<-lmer(Hg~FishLength+Spring_MST+Summer_Rain+(Spring_MST+Summer_Rain-1|watershed),data=FSV,REML=FALSE)

> coef( model7 )
$watershed
         (Intercept)  FishLength    Spring_MST Summer_Rain
877911     -2.111044 0.03653274 -0.0001905891 -0.04581202
3319324    -2.111044 0.03653274  0.0446875053 -0.03808708
11597701   -2.111044 0.03653274  0.0337457453 -0.03997050
31121323   -2.111044 0.03653274 -0.2581203000 -0.09020993
97032352   -2.111044 0.03653274  0.0492101881 -0.03730858


> getME(model7,"theta")
            WA.Spring_MST WA.Summer_Rain.Spring_MST
*WA.Summer_Rain *
               0.37626815                0.06476772               *
0.00000000  #:[*

from summary(model7):

Random effects:
 Groups   Name        Variance  Std.Dev. Corr
 wat...   Spring_MST  0.0144248 0.12010
          Summer_Rain 0.0004274 0.02067  1.00
 Residual             0.1018861 0.31920
Number of obs: 790, groups:  WA, 5

Fixed effects:
              Estimate Std. Error         df t value Pr(>|t|)
(Intercept)  -2.111044   0.070860 786.000000 -29.792   <2e-16 ***
FishLength    0.036533   0.001764 785.500000  20.711   <2e-16 ***
Spring_MST   -0.026133   0.055546   5.100000  -0.470   0.6575
Summer_Rain  -0.050278   0.015880   8.600000  -3.166   0.0121 *
---

Thanks modelers for any advice...except it the advice is along the lines of
square peg, round hole, don't force it.  I see that too.

Karista


On Wed, Apr 18, 2018 at 3:54 PM, Ben Bolker <bbolker at gmail.com> wrote:

> On Wed, Apr 18, 2018 at 3:04 PM, Karista Hudelson <karistaeh at gmail.com>
> wrote:
> > Hello Mixed Modelers,
> >
> > I was hoping to get a bit of feedback on the random effects structure of
> > the model below.  I wanted to allow two of the fixed effects (my effects
> of
> > interest) to have random slopes and also random intercepts for each
> > watershed (there are 5 watersheds, 27 observations of Spring_MST &
> > Summer_Rain, and 790 fish (so there are 790 measurements of Hg and
> > FishLength).
> >
> >  model6<-lmer(Hg~FishLength+Spring_MST+Summer_Rain+(1+Spring_
> MST+Summer_Rain|watershed),data=FSV,REML=FALSE)
> >
> > this model converges, and the output looks "like I want it to look"; ie,
> > slopes are different for the two effects which logically should have
> > different slopes:
> >
> >>   coef(model6)
> > $watershed
> >        (Intercept)    FishLength Spring_MST Summer_Rain
> > 877911    -1.7734565 0.02147013 0.03245297 -0.04841394
> > 3319324   -1.2429440 0.02147013 0.03037712 -0.04472220
> > 11597701  -1.6688121 0.02147013 0.03204351 -0.04768574
> > 31121323  -0.9214729 0.02147013 0.02911923 -0.04248513
> > 97032352  -1.4819562 0.02147013 0.03131236 -0.04638544
>
>     Notice that there is not much variability  in your coefficients
> across watersheds
> (zero variability in FishLength effects because you left it out of your
> random
> effects on purpose, about 10% variability in Spring_MST and Summer_Rain).
> Normally it's not recommended to fit a model with three correlated RE terms
> (intercept, spring_MST, summer_rain) to only a grouping factor with
> only 5 levels -- this is
> equivalent to trying to estimate a 3x3 variance-covariance matrix with
> 5 observations
> (I'm a little surprised this worked at all).  Are all the values in
> getME(fitted_model,"theta") 'reasonable',
> i.e. larger than (say) 1e-4?
>
>    There is a huge, ongoing debate about what to do in this case,
> where the RE model
> you want is theoretically identifiable (you do have multiple
> measurements of spring_MST
> and summer_RAIN in each watershed), but practically very poorly
> constrained, suggestions ranging from
>
>   "keep it maximal" (Barr et al): fit the full model, reduce when the
> model is singular
>   try to constrain complexity _a priori_, reduce by model selection
> (AIC or p-value based)
>   use Bayesian methods to add priors/regularize the problem
>   substitute fixed effects instead.
>
> >
> >
> > Here is a bit of the summary() for model6:
> > Fixed effects:
> >               Estimate Std. Error         df t value Pr(>|t|)
> > (Intercept)  -1.417728   0.144246   6.000000  -9.829 6.18e-05 ***
> > Length        0.021470   0.001085 783.800000  19.794  < 2e-16 ***
> > Spring_MST    0.031061   0.007518 312.000000   4.132 4.63e-05 ***
> > Summer_Rain  -0.045938   0.007276 132.100000  -6.314 3.82e-09 ***
> >
> > It seems to be doing what I intended, but the random effects structure
> > looks like a bit of a run-on sentence compared to most of the other
> models
> > I've seen.  Does this appear correct?
> >
> > Also....if I'm allowing for the slopes of  the effects of interest to be
> > different for each watershed and allowing intercepts to be different, in
> > your opinion(s) would it be easier to understand if I just run separate
> > models for each lake?  Here how that looks for the Lake with watershed
> 877911
> > (corresponding to top line of coef() table above):
> >
> >> clim<-Hg~FishLength+Spring_MST+Summer_Rain
> >> climS<-lm(clim,data=Smid)
> >> summary(climS)
> >
> >               Estimate Std. Error t value Pr(>|t|)
> > (Intercept) -1.3531180  0.2152754  -6.286 2.19e-09 ***
> > Length       0.0276015  0.0027818   9.922  < 2e-16 ***
> > Spring_MST   0.0247300  0.0081347   3.040 0.002699 **
> > Summer_Rain -0.0025433  0.0007216  -3.525 0.000531 ***
> >
> > Any thoughts are appreciated.  Thanks in advance for your time and brain
> > power.
>
>   Fitting separate models will be almost equivalent to fitting a single
>
> Hg~(FishLength+Spring_MST+Summer_Rain):watershed
>
> model -- the only difference will be whether the residual variance is
> pooled/assumed to be
> the same across watersheds.
>
> >
> > Much Obliged,
> > Karista Hudelson
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Karista

	[[alternative HTML version deleted]]


From karistaeh at gmail.com  Thu Apr 19 18:28:29 2018
From: karistaeh at gmail.com (Karista Hudelson)
Date: Thu, 19 Apr 2018 12:28:29 -0400
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
In-Reply-To: <VI1PR03MB30407F1C034639BD1D05E7CAD2B50@VI1PR03MB3040.eurprd03.prod.outlook.com>
References: <mailman.16394.1320.1524096350.1209.r-sig-mixed-models@r-project.org>
 <VI1PR03MB30407F1C034639BD1D05E7CAD2B50@VI1PR03MB3040.eurprd03.prod.outlook.com>
Message-ID: <CAKeD0ugODCqT=ctgX4a=g2dZG7Zc_M6EU3F9=AHQC2_yQWJ2Fw@mail.gmail.com>

Yes there are weird spam replies now that you mention it- my spam folder
has several of them.

On Thu, Apr 19, 2018 at 4:25 AM, Houslay, Tom <T.Houslay at exeter.ac.uk>
wrote:

> Yep - I got a load of ~interesting~ emails in response to a post a few
> days ago
>
>
> ________________________________
> Date: Wed, 18 Apr 2018 17:11:41 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>,
>         r-sig-mixed-models-owner at r-project.org
> Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
> Message-ID: <4df58563-e902-809e-f849-e6ddbd8ea987 at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
>   Is anyone else getting spam responses to r-sig-mixed-models posts?
>
>   cheers
>    Ben Bolker
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Karista

	[[alternative HTML version deleted]]


From smckinney at bccrc.ca  Thu Apr 19 21:05:08 2018
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 19 Apr 2018 19:05:08 +0000
Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
In-Reply-To: <CAKeD0ugODCqT=ctgX4a=g2dZG7Zc_M6EU3F9=AHQC2_yQWJ2Fw@mail.gmail.com>
References: <mailman.16394.1320.1524096350.1209.r-sig-mixed-models@r-project.org>
 <VI1PR03MB30407F1C034639BD1D05E7CAD2B50@VI1PR03MB3040.eurprd03.prod.outlook.com>,
 <CAKeD0ugODCqT=ctgX4a=g2dZG7Zc_M6EU3F9=AHQC2_yQWJ2Fw@mail.gmail.com>
Message-ID: <1524164708180.56326@bccrc.ca>

Yes, someone seems to be scraping email addresses from all R mailing lists.  I replied to an R-devel post yesterday, and now Julia Cabrera is not messing around . . .


"Re: Re Rd R Bug write table for matrix of more than 2 147 483 648 elements

Julia Cabrera <JuliaCabrera at lk.mobilemessage.info>

Steven Baby, I am not playing with you at all ok. And for your information, I don?t have much time to waste sending emails. You should think about my privacy because of the fact that I am a woman. We can have a video chat with my other profile. The other profile doesn?t demand you to link a credit card. Let?s us Video Chat Here "



I'm not sure how one plugs up an open email list against such bot attacks.  It no doubt entails a more complex system that masks all email addresses and would bust the CRAN budget.

Funny that a bot is so busy as not to have time to waste sending emails . . .  
Do bots have privacy rights?

Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Karista Hudelson <karistaeh at gmail.com>
Sent: Thursday, April 19, 2018 9:28 AM
To: r-sig-mixed-models at r-project.org; bbolker at gmail.com
Subject: Re: [R-sig-ME] spam backscatter from r-sig-mixed-models?

Yes there are weird spam replies now that you mention it- my spam folder
has several of them.

On Thu, Apr 19, 2018 at 4:25 AM, Houslay, Tom <T.Houslay at exeter.ac.uk>
wrote:

> Yep - I got a load of ~interesting~ emails in response to a post a few
> days ago
>
>
> ________________________________
> Date: Wed, 18 Apr 2018 17:11:41 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>,
>         r-sig-mixed-models-owner at r-project.org
> Subject: [R-sig-ME] spam backscatter from r-sig-mixed-models?
> Message-ID: <4df58563-e902-809e-f849-e6ddbd8ea987 at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
>   Is anyone else getting spam responses to r-sig-mixed-models posts?
>
>   cheers
>    Ben Bolker
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



--
Karista

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From altessedac2 at gmail.com  Fri Apr 20 12:32:40 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Fri, 20 Apr 2018 12:32:40 +0200
Subject: [R-sig-ME] When-Introduce-Randoms-Effects
Message-ID: <CANrzCv0GCV40DcJhWddMQAApzhV6ST-tHi=uEFz7fJDTOk6TYw@mail.gmail.com>

Hi, dear all.
When modelling, in which cases is it necessary to introduce random
intercepts and / or slopes in a model?
In advance thanks for your responses.
Kind regards,

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Garanti
sans virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From ieshan at gmail.com  Fri Apr 20 15:48:43 2018
From: ieshan at gmail.com (Dan)
Date: Fri, 20 Apr 2018 09:48:43 -0400
Subject: [R-sig-ME] Random Effects in NLME
Message-ID: <CAET4i1fJADhxQizvtPi_kAnmF6cUdapo-74EeVrh0PRR00L0FA@mail.gmail.com>

Hi all:

I am struggling with the proper way to code random effects for an
experiment in which temperature (cooling) was measured across time. I
cannot share the data. However, I will describe the experiment: The cooling
of an object is measured six times over the course of a minute from a fixed
temperature on down. Then, each object (there are 30 objects) is coated
with one (and only one) of three materials.

Multiple replicates are completed for both the before-coating and
after-coating conditions.

So, each object (say, A) has multiple runs in the 'Control' condition
(e.g., A1C,A2C,A3C) and with Coating X (e.g., A1X, A2X, A3X). A second
object (say, B) has multiple runs in the 'Control' condition (B1C, B2C,
B3C) and with Coating Y (B1Y, B2Y, B3Y), etc. As I mentioned, there are
multiple measurements within each run; these measurements fit a cooling
function (exponential decay).

I am able to create a nonlinear model, e.g :
nlme(Temperature~(a-c)*exp(b*Time)+c,
           fixed=list(a~Coating,b~Coating,c~Coating),
           random=a+b+c~1|Object,
           start=startVec)

Which fits. And returns lots of "significant" differences in parameter
estimates.

However, I am somewhat distrustful of these results, as if this was a
linear mixed model, I would have expected a random effects structure more
like (lmer) (Coating| Object ) OR (1| Object ) + (1|Tooth:Coating).

However, when I change:
           random=a+b+c~1|Object
to
           random=a+b+c~Coating| Object

R simply locks up. I assume this is because I'm now estimating way too many
Random Effects.

But, I can't figure out how to specify something like
            random=a~Object, b~Coating|Object, c~Object,
or something similar.

I've done quite a lot of Googling about this, but have struggled to find
nlme examples. Ben in particular has a page was helpful (
http://rpubs.com/bbolker/3423), but as best I can tell, that example uses
something similar to first equation above and doesn't allow varying
parameters by group.

Also note that the models above don't use the individual 'Run' information,
and I suppose that they could (Tooth/Run?).

Any thoughts on the correct model specification here?

Best-
Dan

	[[alternative HTML version deleted]]


From dsidhu at ucalgary.ca  Fri Apr 20 19:14:11 2018
From: dsidhu at ucalgary.ca (David Sidhu)
Date: Fri, 20 Apr 2018 17:14:11 +0000
Subject: [R-sig-ME] Multivariate Regression with Crossed Random Effects
Message-ID: <F6740B4D-5D90-4B13-A5A8-D48E87069139@ucalgary.ca>

Hi All!

Am I correct that it isn?t currently possible to run a mixed effects linear regression with multiple outcome variables (i.e., multivariate regression) in R? I am talking on the order of 25 outcome variables.

It seems that there may be some ways to ?cheat? lme4 into this, but the examples I?ve come across have all been with a pair of outcomes. Is there any way to do this with 25?

Thanks!
Dave

---
David M. Sidhu, MSc<http://davidmsidhu.com/>
PhD Candidate
Department of Psychology
University of Calgary







	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sat Apr 21 20:14:09 2018
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer, Wolfgang (SP))
Date: Sat, 21 Apr 2018 18:14:09 +0000
Subject: [R-sig-ME] Multivariate Regression with Crossed Random Effects
In-Reply-To: <F6740B4D-5D90-4B13-A5A8-D48E87069139@ucalgary.ca>
References: <F6740B4D-5D90-4B13-A5A8-D48E87069139@ucalgary.ca>
Message-ID: <2df2c5569f494924ad0e8b25a6700f02@UM-MAIL3214.unimaas.nl>

Hi David,

This is possible. Structure your dataset so it has all outcomes in a single column and have a second variable indicate the outcome. Let's say 3 outcomes have been measured 4 times in a bunch of subjects. Then:

subject  time  outcome   y
1        1     1         .
1        1     2         .
1        1     3         .
1        2     1         .
1        2     2         .
1        2     3         .
1        3     1         .
1        3     2         .
1        3     3         .
1        4     1         .
1        4     2         .
1        4     3         .
2        1     1         .
...

Then one could use for example this model:

lmer(y ~ factor(time)*factor(outcome) + (factor(outcome) - 1 | subject), data=dat)

This is a model with a saturated mean structure and random effects for all outcome levels with an 'unstructured' var-cov matrix.

One could go even one step further and allow an unstructured var-cov matrix for the errors among the outcomes at each time point. That's possible with lme() from the nlme package with:

lme(y ~ factor(time)*factor(outcome), random = ~ factor(outcome) - 1 | subject, correlation = corSymm(form = ~ 1 | subject/time), weights = varIdent(form = ~ 1 | outcome), data=dat)

If you do this with 25 outcomes, then the var-cov matrix for the outcome random effects will have 325 parameters. And the same number of parameters for the var-cov matrix for the errors. Fitting such a model would require (a) tons of data and (b) a lot of patience. 

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of David Sidhu
Sent: Friday, 20 April, 2018 19:14
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Multivariate Regression with Crossed Random Effects

Hi All!

Am I correct that it isn?t currently possible to run a mixed effects linear regression with multiple outcome variables (i.e., multivariate regression) in R? I am talking on the order of 25 outcome variables.

It seems that there may be some ways to ?cheat? lme4 into this, but the examples I?ve come across have all been with a pair of outcomes. Is there any way to do this with 25?

Thanks!
Dave

---
David M. Sidhu, MSc<http://davidmsidhu.com/>
PhD Candidate
Department of Psychology
University of Calgary

From bbolker at gmail.com  Sat Apr 21 20:56:49 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Apr 2018 14:56:49 -0400
Subject: [R-sig-ME] Multivariate Regression with Crossed Random Effects
In-Reply-To: <F6740B4D-5D90-4B13-A5A8-D48E87069139@ucalgary.ca>
References: <F6740B4D-5D90-4B13-A5A8-D48E87069139@ucalgary.ca>
Message-ID: <CABghstQjp8jWEVt8t24Sm4g2E6TaicEgy4vdP8j4smGru7VkfQ@mail.gmail.com>

The ways to "cheat" with 2 variables (i.e., convert the data set to
long/melted format; use the index of the original observation as a
grouping variable) should in principle extend to an arbitrary number
of responses. The problem will be that estimating the 25x25
variance-covariance matrix will be difficult. (Classical MANOVA
approaches make the assumption of sphericity:
https://en.wikipedia.org/wiki/Mauchly%27s_sphericity_test )  You could
use a method (MCMCglmm, glmmTMB, lme) that allows you to constrain the
variance-covariance matrix (e.g. compound symmetric), or a Bayesian
method with a prior on the variance-covariance matrix ...

On Fri, Apr 20, 2018 at 1:14 PM, David Sidhu <dsidhu at ucalgary.ca> wrote:
> Hi All!
>
> Am I correct that it isn?t currently possible to run a mixed effects linear regression with multiple outcome variables (i.e., multivariate regression) in R? I am talking on the order of 25 outcome variables.
>
> It seems that there may be some ways to ?cheat? lme4 into this, but the examples I?ve come across have all been with a pair of outcomes. Is there any way to do this with 25?
>
> Thanks!
> Dave
>
> ---
> David M. Sidhu, MSc<http://davidmsidhu.com/>
> PhD Candidate
> Department of Psychology
> University of Calgary
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mrguilfoyle at gmail.com  Mon Apr 23 17:46:25 2018
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Mon, 23 Apr 2018 16:46:25 +0100
Subject: [R-sig-ME] mgcv gamm problem with factor-smooth interaction and AR1
 errors
References: <1234C0D5-38F9-4A91-93AA-39D48CFA4C56@gmail.com>
Message-ID: <3E184326-8E78-45C2-A2F3-048DF4D0F770@gmail.com>


I've posted this question to the main R help list without any joy - I wonder if someone here might be able to help...

I'm trying to fit a mgcv::gamm model including random smooths and an autocorrelation term but am getting a consistent error.  I get the same issue with my real data and the toy data in the example below.  As far as I can see the model is specified correctly and the mgcv man/help pages imply this sort of model should be possible.

Any ideas?

Many thanks
Mathew

library('mgcv')
set.seed(1)
#generate some data
df = data.frame(index=rep(1:10,5), x=runif(50,0,1), subject = as.factor(sort(rep(1:5,10))))

##models M1-M4 all fit without issue, but M5 fails

# random intercept
m1 = gamm(x~s(index), random=list(subject=~1), data=df, method = 'REML')

#factor interaction, random intercept, AR errors
m2 = gamm(x~s(index, by=subject), random=list(subject=~1), correlation=corAR1(form=~index|subject), data=df, method = 'REML')

#factor interaction, random intercept and slope, AR errors
m3 = gamm(x~s(index, by=subject), random=list(subject=~index), correlation=corAR1(form=~index|subject), data=df, method = 'REML')

# the 'fs' smooth on its own works ok
m4 = gamm(x~s(index, subject, bs='fs'), data=df, method = 'REML')

#combination of 'fs' smooth and AR errors generates the error: "Error in matrix(0, size.cg[i], size.cg[i]) : object 'size.cg' not found"
m5 = gamm(x~s(index, subject, bs='fs'), correlation=corAR1(form=~index|subject), data=df, method = 'REML')


From phillip.alday at mpi.nl  Mon Apr 23 18:19:17 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Mon, 23 Apr 2018 18:19:17 +0200
Subject: [R-sig-ME] 
 mgcv gamm problem with factor-smooth interaction and AR1 errors
In-Reply-To: <3E184326-8E78-45C2-A2F3-048DF4D0F770@gmail.com>
References: <1234C0D5-38F9-4A91-93AA-39D48CFA4C56@gmail.com>
 <3E184326-8E78-45C2-A2F3-048DF4D0F770@gmail.com>
Message-ID: <93fd8258-1f14-81f0-0e27-847a0dceb1fd@mpi.nl>

Without really trying to understand your models and whether my
suggestion does the same thing, I found that this works:

m6 = gamm(x~s(index, by=subject, bs='fs'),
correlation=corAR1(form=~index|subject), data=df, method = 'REML')

I just looked at the differences between lines and saw that "subject"
was specified as a named argument in some lines, but not others.

Phillip

On 04/23/2018 05:46 PM, Mathew Guilfoyle wrote:
> 
> I've posted this question to the main R help list without any joy - I wonder if someone here might be able to help...
> 
> I'm trying to fit a mgcv::gamm model including random smooths and an autocorrelation term but am getting a consistent error.  I get the same issue with my real data and the toy data in the example below.  As far as I can see the model is specified correctly and the mgcv man/help pages imply this sort of model should be possible.
> 
> Any ideas?
> 
> Many thanks
> Mathew
> 
> library('mgcv')
> set.seed(1)
> #generate some data
> df = data.frame(index=rep(1:10,5), x=runif(50,0,1), subject = as.factor(sort(rep(1:5,10))))
> 
> ##models M1-M4 all fit without issue, but M5 fails
> 
> # random intercept
> m1 = gamm(x~s(index), random=list(subject=~1), data=df, method = 'REML')
> 
> #factor interaction, random intercept, AR errors
> m2 = gamm(x~s(index, by=subject), random=list(subject=~1), correlation=corAR1(form=~index|subject), data=df, method = 'REML')
> 
> #factor interaction, random intercept and slope, AR errors
> m3 = gamm(x~s(index, by=subject), random=list(subject=~index), correlation=corAR1(form=~index|subject), data=df, method = 'REML')
> 
> # the 'fs' smooth on its own works ok
> m4 = gamm(x~s(index, subject, bs='fs'), data=df, method = 'REML')
> 
> #combination of 'fs' smooth and AR errors generates the error: "Error in matrix(0, size.cg[i], size.cg[i]) : object 'size.cg' not found"
> m5 = gamm(x~s(index, subject, bs='fs'), correlation=corAR1(form=~index|subject), data=df, method = 'REML')
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Maarten.Jung at mailbox.tu-dresden.de  Mon Apr 23 23:38:00 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Mon, 23 Apr 2018 23:38:00 +0200
Subject: [R-sig-ME] ML vs. REML to find a parsimonious mixed model
Message-ID: <CAHr4DycELfCsuYBN7HP=V=hTJDX3h6+55+HZUSNpFO+vRsYsDA@mail.gmail.com>

 Hi Christoph,

No, I didn't.
And I'm still very interested in what other mixed model experts/experienced
mixed model users think about it.
At the moment I tend to use REML for this purpose.

Best,
Maarten

On Mon, Apr 23, 2018 at 4:20 PM, Christoph Huber <
christoph.huber-huber at univie.ac.at> wrote:

> Hi Maarten,
>
> Did you get any responses yet? I was facing the same problem and went for
> REML eventually. But it still seems to me that this question does not (yet)
> have a definite answer.
>
> Best,
> Christoph
>
>
>
> Am 16.04.2018 um 12:00 schrieb r-sig-mixed-models-request at r-project.org:
>
> Send R-sig-mixed-models mailing list submissions to
> r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>   1. ML vs. REML to find a parsimonious mixed model (Maarten Jung)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 15 Apr 2018 13:00:08 +0200
> From: Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de>
> To: Help Mixed Models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] ML vs. REML to find a parsimonious mixed model
> Message-ID:
> <CAHr4Dycsa1wmOXKKmDuGzrQi8pxgXq55iQxjEoEzFvyYNmvUvA at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> I want to use LRTs via anova() on fitted linear mixed models (merMod
> objects) to find a parsimonious mixed model containing only variance
> components supported by the data (e.g. Matuschek et al. 2017 [1], Bates et
> al. 2015 [2]).
> In this situation my focus is *only on the reduction of the random effects
> part* of the models.
> The aforementioned papers use ML instead of REML estimation within this
> process. Douglas Bates seems to prefer ML model comparison due to the
> skewed nature of the distribution of variance estimators [3] and the user
> Wolfgang states that "the ML estimator usually has lower mean-squared error
> (MSE) than the REML estimator" [4]. However, literally every textbook I
> know suggests using REML estimation when comparing mixed models that differ
> only in their random effect parts.
>
> What would you suggest in this particular situation? ML or REML?
>
> Best regards,
> Maarten
>
> [1] https://arxiv.org/abs/1511.01864
> [2] https://arxiv.org/abs/1506.04967
> [3] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q3/023750.html
> [4] https://stats.stackexchange.com/a/48770
>
> [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 136, Issue 26
> ***************************************************
>
>
> ?
> Dr. Christoph Huber-Huber
> Center for Mind/Brain Sciences (CIMeC)
> University of Trento
> Corso Bettini 31
> <https://maps.google.com/?q=Corso+Bettini+31+38068+Rovereto&entry=gmail&source=g>
> 38068 Rovereto
> <https://maps.google.com/?q=Corso+Bettini+31+38068+Rovereto&entry=gmail&source=g>
> (TN), Italy
>
> e-mail: christoph.huberhuber at unitn.it
>
>
>
>

	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Tue Apr 24 00:08:25 2018
From: jdpo223 at g.uky.edu (Poe, John)
Date: Mon, 23 Apr 2018 18:08:25 -0400
Subject: [R-sig-ME] ML vs. REML to find a parsimonious mixed model
In-Reply-To: <CAHr4DycELfCsuYBN7HP=V=hTJDX3h6+55+HZUSNpFO+vRsYsDA@mail.gmail.com>
References: <CAHr4DycELfCsuYBN7HP=V=hTJDX3h6+55+HZUSNpFO+vRsYsDA@mail.gmail.com>
Message-ID: <CAFW8Byosw9h=juxmU0U1fUyf59QhUUYnhDtyDY7GupDHJj1jSw@mail.gmail.com>

My take is that it usually doesn't matter and you can tell when it's likely
to before you've started running models based on sample size.

In practice, I almost always use ML unless I've got some specific reason to
try REML (either I have sample size issues or it is for pedagogical
purposes). REML will return less downwardly biased random effects so long
as your sample size is small so you might as well do it if it matters. I've
only seen them return materially different results in a couple of instances
when it wasn't a toy data set designed to produce differences. If you are
getting different p values for the deviance tests on random effects between
REML and ML then you should probably take that as a sign to be extra
paranoid. Most of my models are nonlinear so REML isn't strictly an option
in a lot of software anyway (it is possible but often not on offer). I say
do what you want as long as the deviance tests are still viable.




On Mon, Apr 23, 2018 at 5:38 PM, Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

>  Hi Christoph,
>
> No, I didn't.
> And I'm still very interested in what other mixed model experts/experienced
> mixed model users think about it.
> At the moment I tend to use REML for this purpose.
>
> Best,
> Maarten
>
> On Mon, Apr 23, 2018 at 4:20 PM, Christoph Huber <
> christoph.huber-huber at univie.ac.at> wrote:
>
> > Hi Maarten,
> >
> > Did you get any responses yet? I was facing the same problem and went for
> > REML eventually. But it still seems to me that this question does not
> (yet)
> > have a definite answer.
> >
> > Best,
> > Christoph
> >
> >
> >
> > Am 16.04.2018 um 12:00 schrieb r-sig-mixed-models-request at r-project.org:
> >
> > Send R-sig-mixed-models mailing list submissions to
> > r-sig-mixed-models at r-project.org
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > or, via email, send a message with subject or body 'help' to
> > r-sig-mixed-models-request at r-project.org
> >
> > You can reach the person managing the list at
> > r-sig-mixed-models-owner at r-project.org
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of R-sig-mixed-models digest..."
> >
> >
> > Today's Topics:
> >
> >   1. ML vs. REML to find a parsimonious mixed model (Maarten Jung)
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Sun, 15 Apr 2018 13:00:08 +0200
> > From: Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de>
> > To: Help Mixed Models <r-sig-mixed-models at r-project.org>
> > Subject: [R-sig-ME] ML vs. REML to find a parsimonious mixed model
> > Message-ID:
> > <CAHr4Dycsa1wmOXKKmDuGzrQi8pxgXq55iQxjEoEzFvyYNmvUvA at mail.gmail.com>
> > Content-Type: text/plain; charset="utf-8"
> >
> > I want to use LRTs via anova() on fitted linear mixed models (merMod
> > objects) to find a parsimonious mixed model containing only variance
> > components supported by the data (e.g. Matuschek et al. 2017 [1], Bates
> et
> > al. 2015 [2]).
> > In this situation my focus is *only on the reduction of the random
> effects
> > part* of the models.
> > The aforementioned papers use ML instead of REML estimation within this
> > process. Douglas Bates seems to prefer ML model comparison due to the
> > skewed nature of the distribution of variance estimators [3] and the user
> > Wolfgang states that "the ML estimator usually has lower mean-squared
> error
> > (MSE) than the REML estimator" [4]. However, literally every textbook I
> > know suggests using REML estimation when comparing mixed models that
> differ
> > only in their random effect parts.
> >
> > What would you suggest in this particular situation? ML or REML?
> >
> > Best regards,
> > Maarten
> >
> > [1] https://arxiv.org/abs/1511.01864
> > [2] https://arxiv.org/abs/1506.04967
> > [3] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q3/023750.html
> > [4] https://stats.stackexchange.com/a/48770
> >
> > [[alternative HTML version deleted]]
> >
> >
> >
> >
> > ------------------------------
> >
> > Subject: Digest Footer
> >
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > ------------------------------
> >
> > End of R-sig-mixed-models Digest, Vol 136, Issue 26
> > ***************************************************
> >
> >
> > ?
> > Dr. Christoph Huber-Huber
> > Center for Mind/Brain Sciences (CIMeC)
> > University of Trento
> > Corso Bettini 31
> > <https://maps.google.com/?q=Corso+Bettini+31+38068+
> Rovereto&entry=gmail&source=g>
> > 38068 Rovereto
> > <https://maps.google.com/?q=Corso+Bettini+31+38068+
> Rovereto&entry=gmail&source=g>
> > (TN), Italy
> >
> > e-mail: christoph.huberhuber at unitn.it
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 




Thanks,
John


John Poe, Ph.D.
Postdoctoral Scholar / Research Methodologist
Center for Public Health Services & Systems Research
University of Kentucky
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From babayussifk at gmail.com  Tue Apr 24 16:35:37 2018
From: babayussifk at gmail.com (Kassim Baba Yussif)
Date: Tue, 24 Apr 2018 14:35:37 +0000
Subject: [R-sig-ME] CANNOT PARTITION ERROR VARIANCE AMONG EXPERIMENTS
Message-ID: <CAH3UFiXEvrDnE4SmV9YmbO07Msfsne6hT2Z33vGL106fXfxJWA@mail.gmail.com>

 I am analyzing data from multiple experiments using linear mixed effect
model. However, I cannot partition the error variance based on each
experiment. I will therefore be grateful if I can be guided on how to go
about it.

Below is the model I used:

lmer(yield~Experiment+(1|Genotype), data = MET)

	[[alternative HTML version deleted]]


From pgreenw1 at gmu.edu  Wed Apr 25 03:17:32 2018
From: pgreenw1 at gmu.edu (P Greenwood)
Date: Tue, 24 Apr 2018 21:17:32 -0400
Subject: [R-sig-ME] comparing 2 models
Message-ID: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>

Hello

Although alpha-band EEG is something of a gold standard in predicting processing of stimuli (pre-stimulus alpha), it is not easy to measure EEG outside the lab (e.g. in a vehicle).  In contrast, heart-rate and eye gaze are more reliably obtained in the field using low-cost wearable sensors. 

We sought to compare the ability of 3 sensors to model human reaction time (RT) to a signal from automation.  We compared these measures: alpha-band (PzAlpha), heart-rate variability (HRV), and eye gaze (lnX).  Each person has 10 trials in each of 5 drives. Pnum is subject number.

We sought to model RT from  alpha-band,  heart-rate variability (HRV), and eye gaze (lnX) and Drive.

sumModelInteraction4 <- lmer(RT ~ 1 + (PzAlpha+ HRV+lnX+Drive)^3 +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)

The output, pasted below, reveals interactions: PzAlpha x HRV, PzAlpha x Drive, and HRV x Drive. Also pasted below is some of the raw data.

An LRT comparing this model with an additive model (PzAlpha+RMSSD+lnX+Drive+Trial) yields a significant difference.  This suggests that the interactions  PzAlpha x Drive and HRV x Drive are meaningful predictors. 

We would like to determine whether PzAlpha x Drive or  HRV x Drive is the better predictor of RT.  What is the best way to compare those 2 models?  The measures are scaled and centered.

Thank you very much.

Pam Greenwood

Fixed effects:
                      Estimate Std. Error         df t value Pr(>|t|)   
(Intercept)         -1.908e-01  1.368e-01  3.310e+01  -1.395  0.17235   
PzAlpha             -1.098e-01  6.042e-02  2.339e+02  -1.818  0.07041 . 
HRV               -1.127e-01  6.402e-02  1.112e+03  -1.760  0.07868 . 
lnX                  7.921e-02  7.547e-02  1.102e+03   1.050  0.29416   
Drive                5.382e-02  1.661e-02  1.080e+03   3.241  0.00123 **
PzAlpha: HRV       -1.586e-01  6.424e-02  7.035e+02  -2.468  0.01382 * 
PzAlpha:lnX          1.116e-01  7.400e-02  8.456e+02   1.508  0.13199   
PzAlpha:Drive        4.405e-02  1.730e-02  1.049e+03   2.546  0.01103 * 
HRV:lnX           -4.723e-02  6.905e-02  1.100e+03  -0.684  0.49407   
HRV:Drive          3.652e-02  1.747e-02  1.098e+03   2.091  0.03677 * 
lnX:Drive           -1.275e-02  1.992e-02  1.100e+03  -0.640  0.52217   
PzAlpha: HRV:lnX    1.473e-02  2.567e-02  8.244e+02   0.574  0.56621   
PzAlpha: HRV:Drive  3.308e-02  1.878e-02  1.084e+03   1.761  0.07845 . 
PzAlpha:lnX:Drive   -2.325e-02  2.005e-02  9.166e+02  -1.160  0.24640   
HRV:lnX:Drive      9.729e-03  1.769e-02  1.097e+03   0.550  0.58247   


	
	Pnum
	Drive		Trial	RT	ACC	FzAlpha	CzAlpha	PzAlpha	FzTheta	CzTheta	PzTheta	MeanPupil	lnX	lnY	MeanRR	
HRV
20	1	1	1480.8931	1	7.9928	10.216	7.6254	3.4916	4.8657	6.4977	4.280969072	-3.208115816	-2.423813328	0.7336  		0.074666667
20	1	2	1983.254	1	-8.2609	0.62018	0.32812	4.2257	6.0181	6.5564	4.360414101	-1.926558582	-2.364252526	0.7336		0.074666667
20	1	3	1588.0317	1	1.2572	5.5394	9.0619	4.322	6.7421	7.2778	4.429370379	-2.510514134	-2.890876402	0.734		0.073333333
20	1	4	2600	0	-2.0822	-3.5216	2.597	7.6632	9.4505	9.2404	3.994177574	-2.121340179	-3.875411777	0.7408		0.050666667
20	1	5	1268.9969	1	2.463	4.5837	4.0916	3.4363	4.2989	-2.1573	3.927884406	-1.754642861	-2.737213207	0.7516		0.014666667




















































0





























Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1


	[[alternative HTML version deleted]]


From c.c.voeten at hum.leidenuniv.nl  Wed Apr 25 09:19:57 2018
From: c.c.voeten at hum.leidenuniv.nl (Voeten, C.C.)
Date: Wed, 25 Apr 2018 07:19:57 +0000
Subject: [R-sig-ME] comparing 2 models
In-Reply-To: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>
References: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F877CC3@SPMXM08.VUW.leidenuniv.nl>

Hi Pam,

I don't know if it is the 'best' way, but 'a' way could be to simply compare the AICs of these two models?

lmer(RT ~ 1 + PzAlpha+ HRV+lnX+Drive + PzAlpha:Drive +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)
lmer(RT ~ 1 + PzAlpha+ HRV+lnX+Drive + HRV:Drive +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)

Best,
Cesko

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Namens P Greenwood
Verzonden: woensdag 25 april 2018 03:18
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] comparing 2 models

Hello

Although alpha-band EEG is something of a gold standard in predicting processing of stimuli (pre-stimulus alpha), it is not easy to measure EEG outside the lab (e.g. in a vehicle).  In contrast, heart-rate and eye gaze are more reliably obtained in the field using low-cost wearable sensors. 

We sought to compare the ability of 3 sensors to model human reaction time (RT) to a signal from automation.  We compared these measures: alpha-band (PzAlpha), heart-rate variability (HRV), and eye gaze (lnX).  Each person has 10 trials in each of 5 drives. Pnum is subject number.

We sought to model RT from  alpha-band,  heart-rate variability (HRV), and eye gaze (lnX) and Drive.

sumModelInteraction4 <- lmer(RT ~ 1 + (PzAlpha+ HRV+lnX+Drive)^3 +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)

The output, pasted below, reveals interactions: PzAlpha x HRV, PzAlpha x Drive, and HRV x Drive. Also pasted below is some of the raw data.

An LRT comparing this model with an additive model (PzAlpha+RMSSD+lnX+Drive+Trial) yields a significant difference.  This suggests that the interactions  PzAlpha x Drive and HRV x Drive are meaningful predictors. 

We would like to determine whether PzAlpha x Drive or  HRV x Drive is the better predictor of RT.  What is the best way to compare those 2 models?  The measures are scaled and centered.

Thank you very much.

Pam Greenwood

Fixed effects:
                      Estimate Std. Error         df t value Pr(>|t|)   
(Intercept)         -1.908e-01  1.368e-01  3.310e+01  -1.395  0.17235   
PzAlpha             -1.098e-01  6.042e-02  2.339e+02  -1.818  0.07041 . 
HRV               -1.127e-01  6.402e-02  1.112e+03  -1.760  0.07868 . 
lnX                  7.921e-02  7.547e-02  1.102e+03   1.050  0.29416   
Drive                5.382e-02  1.661e-02  1.080e+03   3.241  0.00123 **
PzAlpha: HRV       -1.586e-01  6.424e-02  7.035e+02  -2.468  0.01382 * 
PzAlpha:lnX          1.116e-01  7.400e-02  8.456e+02   1.508  0.13199   
PzAlpha:Drive        4.405e-02  1.730e-02  1.049e+03   2.546  0.01103 * 
HRV:lnX           -4.723e-02  6.905e-02  1.100e+03  -0.684  0.49407   
HRV:Drive          3.652e-02  1.747e-02  1.098e+03   2.091  0.03677 * 
lnX:Drive           -1.275e-02  1.992e-02  1.100e+03  -0.640  0.52217   
PzAlpha: HRV:lnX    1.473e-02  2.567e-02  8.244e+02   0.574  0.56621   
PzAlpha: HRV:Drive  3.308e-02  1.878e-02  1.084e+03   1.761  0.07845 . 
PzAlpha:lnX:Drive   -2.325e-02  2.005e-02  9.166e+02  -1.160  0.24640   
HRV:lnX:Drive      9.729e-03  1.769e-02  1.097e+03   0.550  0.58247   


	
	Pnum
	Drive		Trial	RT	ACC	FzAlpha	CzAlpha	PzAlpha	FzTheta	CzTheta	PzTheta	MeanPupil	lnX	lnY	MeanRR	
HRV
20	1	1	1480.8931	1	7.9928	10.216	7.6254	3.4916	4.8657	6.4977	4.280969072	-3.208115816	-2.423813328	0.7336  		0.074666667
20	1	2	1983.254	1	-8.2609	0.62018	0.32812	4.2257	6.0181	6.5564	4.360414101	-1.926558582	-2.364252526	0.7336		0.074666667
20	1	3	1588.0317	1	1.2572	5.5394	9.0619	4.322	6.7421	7.2778	4.429370379	-2.510514134	-2.890876402	0.734		0.073333333
20	1	4	2600	0	-2.0822	-3.5216	2.597	7.6632	9.4505	9.2404	3.994177574	-2.121340179	-3.875411777	0.7408		0.050666667
20	1	5	1268.9969	1	2.463	4.5837	4.0916	3.4363	4.2989	-2.1573	3.927884406	-1.754642861	-2.737213207	0.7516		0.014666667




















































0





























Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From emmanuel.curis at parisdescartes.fr  Wed Apr 25 09:45:46 2018
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 25 Apr 2018 09:45:46 +0200
Subject: [R-sig-ME] comparing 2 models
In-Reply-To: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>
References: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>
Message-ID: <20180425074546.GA18480@info124.pharmacie.univ-paris5.fr>

Hello,

I think if your interest is more in predictive power of your model
than in its ability to reproduce the dataset, your best choice would
be using cross-validation.  And to summarize the closeness of your
predicted results to the real ones, you may use all the concordance
tools, either descriptive like Bland-Altman plots, or more
quantititive like concordance correlation coefficients (but beware
that their interpretation beyond ? the closest to one, the better ? is
not easy) or similar agreement measures. Obviously, the second part
can be done without the cross-validation step, on your single, whole
dataset.

The ? best ? model will be the one witht the highest concordance
correlation coefficient; to test that it is significantly better is
more tricky, but should be done with carefully crafted simulations,
fitting one model to simulated data generated by either one model or
the other and vice-versa...

Note also that if all your predictors are continuous, as seems to be
in your description, the syntax (x+y+...)^n is misleading, because it
forgets some important terms.

Indeed, let consider the two-variables case, x and y. The first order
model is z = ?0 + alpha * x + beta * y, a plane. The second order
model would then be a paraboloid,

z = ?0 + alpha * x + beta * y + gamma * x? + delta * y? + a * x * y

However, the syntax (x+y)^2 expends to x + y + x:y, that is it forgets
the I(x^2) and I(y^2) terms. So, unless you have strong belief that
both gamma and delta are 0, you're model is incomplete.

Hope all of this will help,
Best regards,
Emmanuel

On Tue, Apr 24, 2018 at 09:17:32PM -0400, P Greenwood wrote:
? Hello
? 
? Although alpha-band EEG is something of a gold standard in predicting processing of stimuli (pre-stimulus alpha), it is not easy to measure EEG outside the lab (e.g. in a vehicle).  In contrast, heart-rate and eye gaze are more reliably obtained in the field using low-cost wearable sensors. 
? 
? We sought to compare the ability of 3 sensors to model human reaction time (RT) to a signal from automation.  We compared these measures: alpha-band (PzAlpha), heart-rate variability (HRV), and eye gaze (lnX).  Each person has 10 trials in each of 5 drives. Pnum is subject number.
? 
? We sought to model RT from  alpha-band,  heart-rate variability (HRV), and eye gaze (lnX) and Drive.
? 
? sumModelInteraction4 <- lmer(RT ~ 1 + (PzAlpha+ HRV+lnX+Drive)^3 +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)
? 
? The output, pasted below, reveals interactions: PzAlpha x HRV, PzAlpha x Drive, and HRV x Drive. Also pasted below is some of the raw data.
? 
? An LRT comparing this model with an additive model (PzAlpha+RMSSD+lnX+Drive+Trial) yields a significant difference.  This suggests that the interactions  PzAlpha x Drive and HRV x Drive are meaningful predictors. 
? 
? We would like to determine whether PzAlpha x Drive or  HRV x Drive is the better predictor of RT.  What is the best way to compare those 2 models?  The measures are scaled and centered.
? 
? Thank you very much.
? 
? Pam Greenwood
? 
? Fixed effects:
?                       Estimate Std. Error         df t value Pr(>|t|)   
? (Intercept)         -1.908e-01  1.368e-01  3.310e+01  -1.395  0.17235   
? PzAlpha             -1.098e-01  6.042e-02  2.339e+02  -1.818  0.07041 . 
? HRV               -1.127e-01  6.402e-02  1.112e+03  -1.760  0.07868 . 
? lnX                  7.921e-02  7.547e-02  1.102e+03   1.050  0.29416   
? Drive                5.382e-02  1.661e-02  1.080e+03   3.241  0.00123 **
? PzAlpha: HRV       -1.586e-01  6.424e-02  7.035e+02  -2.468  0.01382 * 
? PzAlpha:lnX          1.116e-01  7.400e-02  8.456e+02   1.508  0.13199   
? PzAlpha:Drive        4.405e-02  1.730e-02  1.049e+03   2.546  0.01103 * 
? HRV:lnX           -4.723e-02  6.905e-02  1.100e+03  -0.684  0.49407   
? HRV:Drive          3.652e-02  1.747e-02  1.098e+03   2.091  0.03677 * 
? lnX:Drive           -1.275e-02  1.992e-02  1.100e+03  -0.640  0.52217   
? PzAlpha: HRV:lnX    1.473e-02  2.567e-02  8.244e+02   0.574  0.56621   
? PzAlpha: HRV:Drive  3.308e-02  1.878e-02  1.084e+03   1.761  0.07845 . 
? PzAlpha:lnX:Drive   -2.325e-02  2.005e-02  9.166e+02  -1.160  0.24640   
? HRV:lnX:Drive      9.729e-03  1.769e-02  1.097e+03   0.550  0.58247   
? 
? 
? 	
? 	Pnum
? 	Drive		Trial	RT	ACC	FzAlpha	CzAlpha	PzAlpha	FzTheta	CzTheta	PzTheta	MeanPupil	lnX	lnY	MeanRR	
? HRV
? 20	1	1	1480.8931	1	7.9928	10.216	7.6254	3.4916	4.8657	6.4977	4.280969072	-3.208115816	-2.423813328	0.7336  		0.074666667
? 20	1	2	1983.254	1	-8.2609	0.62018	0.32812	4.2257	6.0181	6.5564	4.360414101	-1.926558582	-2.364252526	0.7336		0.074666667
? 20	1	3	1588.0317	1	1.2572	5.5394	9.0619	4.322	6.7421	7.2778	4.429370379	-2.510514134	-2.890876402	0.734		0.073333333
? 20	1	4	2600	0	-2.0822	-3.5216	2.597	7.6632	9.4505	9.2404	3.994177574	-2.121340179	-3.875411777	0.7408		0.050666667
? 20	1	5	1268.9969	1	2.463	4.5837	4.0916	3.4363	4.2989	-2.1573	3.927884406	-1.754642861	-2.737213207	0.7516		0.014666667
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 0
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? 
? Editorial Board, NeuroImage
? David King Hall 2052
? George Mason University
? MSN 3F5, 4400 University Drive
? Fairfax, VA 22030-4444
? 
? Ph: 703 993-4268
? fax: 703 993-1359
? email: Pgreenw1 at gmu.edu
? http://psychology.gmu.edu/people/pgreenw1
? 
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bachlaw01 at outlook.com  Wed Apr 25 13:47:33 2018
From: bachlaw01 at outlook.com (Jonathan Judge)
Date: Wed, 25 Apr 2018 11:47:33 +0000
Subject: [R-sig-ME] comparing 2 models
In-Reply-To: <20180425074546.GA18480@info124.pharmacie.univ-paris5.fr>
References: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>,
 <20180425074546.GA18480@info124.pharmacie.univ-paris5.fr>
Message-ID: <BN3PR16MB08200BE4E8BECEF4EA4B076AAF8F0@BN3PR16MB0820.namprd16.prod.outlook.com>

I think the best option would be to refit these models in Stan (a front end like rstanarm or brms makes it easy with similar lme4 syntax) and use the LOO function to compare their out of sample predictive power. 

Otherwise, if you wish to stick with lme4, you need some way to properly count the number of effective parameters. AIC doesn?t do that because it doesn?t understand / account for the shrinkage of random effects. You might consider WAIC, which does a better job of this. There is an implementation for lme4 models in the blmeco package. 

Jonathan

Sent from my iPhone

> On Apr 25, 2018, at 2:45 AM, Emmanuel Curis <emmanuel.curis at parisdescartes.fr> wrote:
> 
> Hello,
> 
> I think if your interest is more in predictive power of your model
> than in its ability to reproduce the dataset, your best choice would
> be using cross-validation.  And to summarize the closeness of your
> predicted results to the real ones, you may use all the concordance
> tools, either descriptive like Bland-Altman plots, or more
> quantititive like concordance correlation coefficients (but beware
> that their interpretation beyond ? the closest to one, the better ? is
> not easy) or similar agreement measures. Obviously, the second part
> can be done without the cross-validation step, on your single, whole
> dataset.
> 
> The ? best ? model will be the one witht the highest concordance
> correlation coefficient; to test that it is significantly better is
> more tricky, but should be done with carefully crafted simulations,
> fitting one model to simulated data generated by either one model or
> the other and vice-versa...
> 
> Note also that if all your predictors are continuous, as seems to be
> in your description, the syntax (x+y+...)^n is misleading, because it
> forgets some important terms.
> 
> Indeed, let consider the two-variables case, x and y. The first order
> model is z = ?0 + alpha * x + beta * y, a plane. The second order
> model would then be a paraboloid,
> 
> z = ?0 + alpha * x + beta * y + gamma * x? + delta * y? + a * x * y
> 
> However, the syntax (x+y)^2 expends to x + y + x:y, that is it forgets
> the I(x^2) and I(y^2) terms. So, unless you have strong belief that
> both gamma and delta are 0, you're model is incomplete.
> 
> Hope all of this will help,
> Best regards,
> Emmanuel
> 
> On Tue, Apr 24, 2018 at 09:17:32PM -0400, P Greenwood wrote:
> ? Hello
> ? 
> ? Although alpha-band EEG is something of a gold standard in predicting processing of stimuli (pre-stimulus alpha), it is not easy to measure EEG outside the lab (e.g. in a vehicle).  In contrast, heart-rate and eye gaze are more reliably obtained in the field using low-cost wearable sensors. 
> ? 
> ? We sought to compare the ability of 3 sensors to model human reaction time (RT) to a signal from automation.  We compared these measures: alpha-band (PzAlpha), heart-rate variability (HRV), and eye gaze (lnX).  Each person has 10 trials in each of 5 drives. Pnum is subject number.
> ? 
> ? We sought to model RT from  alpha-band,  heart-rate variability (HRV), and eye gaze (lnX) and Drive.
> ? 
> ? sumModelInteraction4 <- lmer(RT ~ 1 + (PzAlpha+ HRV+lnX+Drive)^3 +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)
> ? 
> ? The output, pasted below, reveals interactions: PzAlpha x HRV, PzAlpha x Drive, and HRV x Drive. Also pasted below is some of the raw data.
> ? 
> ? An LRT comparing this model with an additive model (PzAlpha+RMSSD+lnX+Drive+Trial) yields a significant difference.  This suggests that the interactions  PzAlpha x Drive and HRV x Drive are meaningful predictors. 
> ? 
> ? We would like to determine whether PzAlpha x Drive or  HRV x Drive is the better predictor of RT.  What is the best way to compare those 2 models?  The measures are scaled and centered.
> ? 
> ? Thank you very much.
> ? 
> ? Pam Greenwood
> ? 
> ? Fixed effects:
> ?                       Estimate Std. Error         df t value Pr(>|t|)   
> ? (Intercept)         -1.908e-01  1.368e-01  3.310e+01  -1.395  0.17235   
> ? PzAlpha             -1.098e-01  6.042e-02  2.339e+02  -1.818  0.07041 . 
> ? HRV               -1.127e-01  6.402e-02  1.112e+03  -1.760  0.07868 . 
> ? lnX                  7.921e-02  7.547e-02  1.102e+03   1.050  0.29416   
> ? Drive                5.382e-02  1.661e-02  1.080e+03   3.241  0.00123 **
> ? PzAlpha: HRV       -1.586e-01  6.424e-02  7.035e+02  -2.468  0.01382 * 
> ? PzAlpha:lnX          1.116e-01  7.400e-02  8.456e+02   1.508  0.13199   
> ? PzAlpha:Drive        4.405e-02  1.730e-02  1.049e+03   2.546  0.01103 * 
> ? HRV:lnX           -4.723e-02  6.905e-02  1.100e+03  -0.684  0.49407   
> ? HRV:Drive          3.652e-02  1.747e-02  1.098e+03   2.091  0.03677 * 
> ? lnX:Drive           -1.275e-02  1.992e-02  1.100e+03  -0.640  0.52217   
> ? PzAlpha: HRV:lnX    1.473e-02  2.567e-02  8.244e+02   0.574  0.56621   
> ? PzAlpha: HRV:Drive  3.308e-02  1.878e-02  1.084e+03   1.761  0.07845 . 
> ? PzAlpha:lnX:Drive   -2.325e-02  2.005e-02  9.166e+02  -1.160  0.24640   
> ? HRV:lnX:Drive      9.729e-03  1.769e-02  1.097e+03   0.550  0.58247   
> ? 
> ? 
> ?    
> ?    Pnum
> ?    Drive        Trial    RT    ACC    FzAlpha    CzAlpha    PzAlpha    FzTheta    CzTheta    PzTheta    MeanPupil    lnX    lnY    MeanRR    
> ? HRV
> ? 20    1    1    1480.8931    1    7.9928    10.216    7.6254    3.4916    4.8657    6.4977    4.280969072    -3.208115816    -2.423813328    0.7336          0.074666667
> ? 20    1    2    1983.254    1    -8.2609    0.62018    0.32812    4.2257    6.0181    6.5564    4.360414101    -1.926558582    -2.364252526    0.7336        0.074666667
> ? 20    1    3    1588.0317    1    1.2572    5.5394    9.0619    4.322    6.7421    7.2778    4.429370379    -2.510514134    -2.890876402    0.734        0.073333333
> ? 20    1    4    2600    0    -2.0822    -3.5216    2.597    7.6632    9.4505    9.2404    3.994177574    -2.121340179    -3.875411777    0.7408        0.050666667
> ? 20    1    5    1268.9969    1    2.463    4.5837    4.0916    3.4363    4.2989    -2.1573    3.927884406    -1.754642861    -2.737213207    0.7516        0.014666667
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 0
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? Editorial Board, NeuroImage
> ? David King Hall 2052
> ? George Mason University
> ? MSN 3F5, 4400 University Drive
> ? Fairfax, VA 22030-4444
> ? 
> ? Ph: 703 993-4268
> ? fax: 703 993-1359
> ? email: Pgreenw1 at gmu.edu
> ? http://psychology.gmu.edu/people/pgreenw1
> ? 
> ? 
> ?    [[alternative HTML version deleted]]
> ? 
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -- 
>                                Emmanuel CURIS
>                                emmanuel.curis at parisdescartes.fr
> 
> Page WWW: http://emmanuel.curis.online.fr/index.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From paul.johnson at glasgow.ac.uk  Wed Apr 25 16:34:14 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 25 Apr 2018 14:34:14 +0000
Subject: [R-sig-ME] CANNOT PARTITION ERROR VARIANCE AMONG EXPERIMENTS
In-Reply-To: <CAH3UFiXEvrDnE4SmV9YmbO07Msfsne6hT2Z33vGL106fXfxJWA@mail.gmail.com>
References: <CAH3UFiXEvrDnE4SmV9YmbO07Msfsne6hT2Z33vGL106fXfxJWA@mail.gmail.com>
Message-ID: <0756934B2C0D624DB20E135A92ACC524136EFF05@CMS12-01.campus.gla.ac.uk>

Hi Kassim,

fit <- lmer(yield~Experiment+(1|Genotype), data = MET)

# variance "explained" by fixed effects, i.e. between experiments
fitval <- model.matrix(fit) %*% fixef(fit)
n <- length(fitval)
Vf <- sum((fitval - mean(fitval))^2)/n
#  var(fitval) would be simpler but uses n-1 as the denominator whereas I think (?!) n is correct
# (in practice it'll only make a substantial difference if n is very small)

# genotype random effect variance (unexplained variation among genotypes)
Vr <- VarCorr(fit)$Genotype[, ]
# (note that this doesn't work when there are random slopes)

# residual/error variance (unexplained variation between observations)
Ve <- attr(VarCorr(fit), "sc")^2

var(MET$yield)
# ...should be not too far from
Vf + Vr + Ve

Best wishes,
Paul


________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Kassim Baba Yussif [babayussifk at gmail.com]
Sent: 24 April 2018 15:35
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] CANNOT PARTITION ERROR VARIANCE AMONG EXPERIMENTS

 I am analyzing data from multiple experiments using linear mixed effect
model. However, I cannot partition the error variance based on each
experiment. I will therefore be grateful if I can be guided on how to go
about it.

Below is the model I used:

lmer(yield~Experiment+(1|Genotype), data = MET)

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pauljohn32 at gmail.com  Wed Apr 25 16:56:51 2018
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 25 Apr 2018 09:56:51 -0500
Subject: [R-sig-ME] Convergence problem example
Message-ID: <CAErODj-Lx9c7V3Gpg1iN-w6moPcr9h4sH+BvntdgWe4pk+QFOQ@mail.gmail.com>

In the book Multilevel and Longitudinal Modeling using Stata,
Rabe-Hesketh and Skrondal have a lot of exercises and over the years
I've been trying to write Stata and R code to demonstrate
similarities/differences.

I've run into an example where Stata (either with builtin methods or
the addon gllamm) seems to think it gets estimates but lme4
diagnostics say there is a convergence failure.  I want to impose on
you, get your advice about it. We see convergence warnings quite often
with lme4, but they are usually the "rescale your variables" errors,
not as blunt as this.

The first part retrieves "dairy.dta" from the book website

library(foreign)
library(lme4)

fn <- "dairy"
if (!file.exists(paste0(fn, ".dta12"))) {
    download.file(paste0("http://www.stata-press.com/data/mlmus3/", fn, ".dta"),
                  destfile = paste0(fn, ".dta12"))
}

dairy <- read.dta(paste0(fn, ".dta12"))

#1
m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
            family = binomial(link = "logit"), nAGQ = 30,
            data = dairy)
summary(m1)

>From that, I see:
> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
+             family = binomial(link = "logit"), nAGQ = 30,
+             data = dairy)
Warning messages:
1: 'rBind' is deprecated.
 Since R version 3.2.0, base's rbind() should work fine with S4 objects
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00396932 (tol = 0.001,
component 1)
> summary(m1)
Generalized linear mixed model fit by maximum likelihood (Adaptive
  Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
 Family: binomial  ( logit )
Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
   Data: dairy

     AIC      BIC   logLik deviance df.resid
  4017.8   4047.9  -2003.9   4007.8     3022

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8136 -0.7652 -0.6479  1.0420  1.6213

Random effects:
 Groups Name        Variance Std.Dev.
 cow    (Intercept) 0.3419   0.5847
Number of obs: 3027, groups:  cow, 1575

Fixed effects:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)       -1.55693    0.43481  -3.581 0.000343 ***
lncfs              0.52221    0.10007   5.218 1.81e-07 ***
aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
heiferprimiparous -0.08259    0.09718  -0.850 0.395410
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) lncfs  aiai
lncfs       -0.965
aiai        -0.193 -0.046
heifrprmprs -0.054  0.016 -0.051
convergence code: 0
Model failed to converge with max|grad| = 0.00396932 (tol = 0.001, component 1)


Stata output for comparison purposes, using gllamm:

. gllamm fscr lncfs ai heifer, i(cow) link(logit) fam(binom) adapt

Running adaptive quadrature
Iteration 0:    log likelihood = -2004.6011
Iteration 1:    log likelihood = -2003.9085
Iteration 2:    log likelihood = -2003.9069


Adaptive quadrature has converged, running Newton-Raphson
Iteration 0:   log likelihood = -2003.9069
Iteration 1:   log likelihood = -2003.9069
Iteration 2:   log likelihood = -2003.9064
Iteration 3:   log likelihood = -2003.9064

number of level 1 units = 3027
number of level 2 units = 1575

Condition Number = 47.123877

gllamm model

log likelihood = -2003.9064

------------------------------------------------------------------------------
        fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       lncfs |   .5222157   .1000693     5.22   0.000     .3260834     .718348
          ai |  -1.095598   .1234099    -8.88   0.000    -1.337477   -.8537193
      heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078837
       _cons |  -1.556961   .4348008    -3.58   0.000    -2.409155   -.7047673
------------------------------------------------------------------------------


Variances and covariances of random effects
------------------------------------------------------------------------------


***level 2 (cow)

    var(1): .34188062 (.1263136)
------------------------------------------------------------------------------


Using the newer meglm that is provided with Stata

. meglm fscr lncfs ai heifer || cow: , family(binom) link(logit)

Fitting fixed-effects model:

Iteration 0:   log likelihood = -2011.8253
Iteration 1:   log likelihood = -2009.1421
Iteration 2:   log likelihood = -2009.1412
Iteration 3:   log likelihood = -2009.1412

Refining starting values:

Grid node 0:   log likelihood = -2015.6021

Fitting full model:

Iteration 0:   log likelihood = -2015.6021
Iteration 1:   log likelihood =  -2006.709
Iteration 2:   log likelihood = -2003.9174
Iteration 3:   log likelihood = -2003.9065
Iteration 4:   log likelihood = -2003.9065

Mixed-effects GLM                               Number of obs     =      3,027
Family:                binomial
Link:                     logit
Group variable:             cow                 Number of groups  =      1,575

                                                Obs per group:
                                                              min =          1
                                                              avg =        1.9
                                                              max =          5

Integration method: mvaghermite                 Integration pts.  =          7

                                                Wald chi2(3)      =     103.86
Log likelihood = -2003.9065                     Prob > chi2       =     0.0000
------------------------------------------------------------------------------
        fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       lncfs |   .5222154   .1000694     5.22   0.000      .326083    .7183479
          ai |  -1.095597   .1234095    -8.88   0.000    -1.337476   -.8537191
      heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078836
       _cons |  -1.556961   .4348012    -3.58   0.000    -2.409155   -.7047659
-------------+----------------------------------------------------------------
cow          |
   var(_cons)|   .3418776   .1263105                      .1657237    .7052721
------------------------------------------------------------------------------
LR test vs. logistic model: chibar2(01) = 10.47       Prob >= chibar2 = 0.0006


As far as I can see, parameter estimates are the same. I did not
compare conditional modes.

If lme4's converge warning is valid, then we have a concrete case
where Stata is reporting the wrong thing.  I can see some upside there
:)

R details

> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 17.10

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-15    Matrix_1.2-14  foreign_0.8-69

loaded via a namespace (and not attached):
 [1] minqa_1.2.4     MASS_7.3-49     compiler_3.4.4  tools_3.4.4
 [5] Rcpp_0.12.15    splines_3.4.4   nlme_3.1-137    grid_3.4.4
 [9] nloptr_1.0.4    lattice_0.20-35


-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From phillip.alday at mpi.nl  Wed Apr 25 17:12:21 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 25 Apr 2018 17:12:21 +0200
Subject: [R-sig-ME] Convergence problem example
In-Reply-To: <CAErODj-Lx9c7V3Gpg1iN-w6moPcr9h4sH+BvntdgWe4pk+QFOQ@mail.gmail.com>
References: <CAErODj-Lx9c7V3Gpg1iN-w6moPcr9h4sH+BvntdgWe4pk+QFOQ@mail.gmail.com>
Message-ID: <34357487-1e4c-208b-4868-1398483583f7@mpi.nl>

Changing the optimizer seems to address the convergence warnings and has
no impact on the other aspects of the fit:

> m1 <- update(m1, control=glmerControl(optimizer="bobyqa"))
> summary(m1)
Generalized linear mixed model fit by maximum likelihood (Adaptive
  Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
 Family: binomial  ( logit )
Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
   Data: dairy
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  4017.8   4047.9  -2003.9   4007.8     3022

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8136 -0.7652 -0.6479  1.0420  1.6213

Random effects:
 Groups Name        Variance Std.Dev.
 cow    (Intercept) 0.3419   0.5847
Number of obs: 3027, groups:  cow, 1575

Fixed effects:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)       -1.55696    0.43481  -3.581 0.000343 ***
lncfs              0.52222    0.10007   5.218  1.8e-07 ***
aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
heiferprimiparous -0.08259    0.09718  -0.850 0.395418
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) lncfs  aiai
lncfs       -0.965
aiai        -0.193 -0.046
heifrprmprs -0.054  0.016 -0.051

Phillip



On 04/25/2018 04:56 PM, Paul Johnson wrote:
> In the book Multilevel and Longitudinal Modeling using Stata,
> Rabe-Hesketh and Skrondal have a lot of exercises and over the years
> I've been trying to write Stata and R code to demonstrate
> similarities/differences.
> 
> I've run into an example where Stata (either with builtin methods or
> the addon gllamm) seems to think it gets estimates but lme4
> diagnostics say there is a convergence failure.  I want to impose on
> you, get your advice about it. We see convergence warnings quite often
> with lme4, but they are usually the "rescale your variables" errors,
> not as blunt as this.
> 
> The first part retrieves "dairy.dta" from the book website
> 
> library(foreign)
> library(lme4)
> 
> fn <- "dairy"
> if (!file.exists(paste0(fn, ".dta12"))) {
>     download.file(paste0("http://www.stata-press.com/data/mlmus3/", fn, ".dta"),
>                   destfile = paste0(fn, ".dta12"))
> }
> 
> dairy <- read.dta(paste0(fn, ".dta12"))
> 
> #1
> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
>             family = binomial(link = "logit"), nAGQ = 30,
>             data = dairy)
> summary(m1)
> 
> From that, I see:
>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
> +             family = binomial(link = "logit"), nAGQ = 30,
> +             data = dairy)
> Warning messages:
> 1: 'rBind' is deprecated.
>  Since R version 3.2.0, base's rbind() should work fine with S4 objects
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.00396932 (tol = 0.001,
> component 1)
>> summary(m1)
> Generalized linear mixed model fit by maximum likelihood (Adaptive
>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
>  Family: binomial  ( logit )
> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
>    Data: dairy
> 
>      AIC      BIC   logLik deviance df.resid
>   4017.8   4047.9  -2003.9   4007.8     3022
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.8136 -0.7652 -0.6479  1.0420  1.6213
> 
> Random effects:
>  Groups Name        Variance Std.Dev.
>  cow    (Intercept) 0.3419   0.5847
> Number of obs: 3027, groups:  cow, 1575
> 
> Fixed effects:
>                   Estimate Std. Error z value Pr(>|z|)
> (Intercept)       -1.55693    0.43481  -3.581 0.000343 ***
> lncfs              0.52221    0.10007   5.218 1.81e-07 ***
> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
> heiferprimiparous -0.08259    0.09718  -0.850 0.395410
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>             (Intr) lncfs  aiai
> lncfs       -0.965
> aiai        -0.193 -0.046
> heifrprmprs -0.054  0.016 -0.051
> convergence code: 0
> Model failed to converge with max|grad| = 0.00396932 (tol = 0.001, component 1)
> 
> 
> Stata output for comparison purposes, using gllamm:
> 
> . gllamm fscr lncfs ai heifer, i(cow) link(logit) fam(binom) adapt
> 
> Running adaptive quadrature
> Iteration 0:    log likelihood = -2004.6011
> Iteration 1:    log likelihood = -2003.9085
> Iteration 2:    log likelihood = -2003.9069
> 
> 
> Adaptive quadrature has converged, running Newton-Raphson
> Iteration 0:   log likelihood = -2003.9069
> Iteration 1:   log likelihood = -2003.9069
> Iteration 2:   log likelihood = -2003.9064
> Iteration 3:   log likelihood = -2003.9064
> 
> number of level 1 units = 3027
> number of level 2 units = 1575
> 
> Condition Number = 47.123877
> 
> gllamm model
> 
> log likelihood = -2003.9064
> 
> ------------------------------------------------------------------------------
>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
> -------------+----------------------------------------------------------------
>        lncfs |   .5222157   .1000693     5.22   0.000     .3260834     .718348
>           ai |  -1.095598   .1234099    -8.88   0.000    -1.337477   -.8537193
>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078837
>        _cons |  -1.556961   .4348008    -3.58   0.000    -2.409155   -.7047673
> ------------------------------------------------------------------------------
> 
> 
> Variances and covariances of random effects
> ------------------------------------------------------------------------------
> 
> 
> ***level 2 (cow)
> 
>     var(1): .34188062 (.1263136)
> ------------------------------------------------------------------------------
> 
> 
> Using the newer meglm that is provided with Stata
> 
> . meglm fscr lncfs ai heifer || cow: , family(binom) link(logit)
> 
> Fitting fixed-effects model:
> 
> Iteration 0:   log likelihood = -2011.8253
> Iteration 1:   log likelihood = -2009.1421
> Iteration 2:   log likelihood = -2009.1412
> Iteration 3:   log likelihood = -2009.1412
> 
> Refining starting values:
> 
> Grid node 0:   log likelihood = -2015.6021
> 
> Fitting full model:
> 
> Iteration 0:   log likelihood = -2015.6021
> Iteration 1:   log likelihood =  -2006.709
> Iteration 2:   log likelihood = -2003.9174
> Iteration 3:   log likelihood = -2003.9065
> Iteration 4:   log likelihood = -2003.9065
> 
> Mixed-effects GLM                               Number of obs     =      3,027
> Family:                binomial
> Link:                     logit
> Group variable:             cow                 Number of groups  =      1,575
> 
>                                                 Obs per group:
>                                                               min =          1
>                                                               avg =        1.9
>                                                               max =          5
> 
> Integration method: mvaghermite                 Integration pts.  =          7
> 
>                                                 Wald chi2(3)      =     103.86
> Log likelihood = -2003.9065                     Prob > chi2       =     0.0000
> ------------------------------------------------------------------------------
>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
> -------------+----------------------------------------------------------------
>        lncfs |   .5222154   .1000694     5.22   0.000      .326083    .7183479
>           ai |  -1.095597   .1234095    -8.88   0.000    -1.337476   -.8537191
>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078836
>        _cons |  -1.556961   .4348012    -3.58   0.000    -2.409155   -.7047659
> -------------+----------------------------------------------------------------
> cow          |
>    var(_cons)|   .3418776   .1263105                      .1657237    .7052721
> ------------------------------------------------------------------------------
> LR test vs. logistic model: chibar2(01) = 10.47       Prob >= chibar2 = 0.0006
> 
> 
> As far as I can see, parameter estimates are the same. I did not
> compare conditional modes.
> 
> If lme4's converge warning is valid, then we have a concrete case
> where Stata is reporting the wrong thing.  I can see some upside there
> :)
> 
> R details
> 
>> sessionInfo()
> R version 3.4.4 (2018-03-15)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 17.10
> 
> Matrix products: default
> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_1.1-15    Matrix_1.2-14  foreign_0.8-69
> 
> loaded via a namespace (and not attached):
>  [1] minqa_1.2.4     MASS_7.3-49     compiler_3.4.4  tools_3.4.4
>  [5] Rcpp_0.12.15    splines_3.4.4   nlme_3.1-137    grid_3.4.4
>  [9] nloptr_1.0.4    lattice_0.20-35
> 
>


From phillip.alday at mpi.nl  Wed Apr 25 17:52:16 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 25 Apr 2018 17:52:16 +0200
Subject: [R-sig-ME] comparing 2 models
In-Reply-To: <BN3PR16MB08200BE4E8BECEF4EA4B076AAF8F0@BN3PR16MB0820.namprd16.prod.outlook.com>
References: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>
 <20180425074546.GA18480@info124.pharmacie.univ-paris5.fr>
 <BN3PR16MB08200BE4E8BECEF4EA4B076AAF8F0@BN3PR16MB0820.namprd16.prod.outlook.com>
Message-ID: <be5a0e48-f0cb-70aa-f8b4-4a1331fe2ba5@mpi.nl>

In addition to the previous suggestions (CV/LOO and AIC comparison),
there is also Vuong's closeness test for non nested models. I haven't
used it myself, but a quick search suggests that a fair amount of
information about its use and misuse (in e.g. checking for
zero-inflation in Poisson models) is available.

One small note here: PzAlpha and HRV are both continuous predictors, so
they both contribute the same number of degrees of freedom to a model,
so you can compare (log) likelihoods directly instead of using AIC or
BIC because the number of parameters will be the same. (You still can't
do the LRT because amongst other things the chisq df will be 0.) This
also suggests the parameter counting concern  is largely moot, as the
parameters and data are the same. (I'll let someone else more qualified
address the broader issue of parameter counting for AIC/BIC in mixed
models.)

There are also a number of parameter selection methods that work within
one model. In frequentist land, there's elastic net and LASSO, which are
implemented for mixed models in packages such as lmmen and glmmLasso.
There's two ways to use those methods here:

(1) cross validation on the penalty for number of parameters so that the
model selects the 'ideal' number of predictors
(2) setting a particularly penalty to achieve a desired number of
parameters and letting the model choose which ones those are

Both should be typically well supported in good elastic net and LASSO
implementations.

In Bayesian terms, you can achieve the same thing by appropriate choice
of priors. brms has LASSO and horseshoe priors and uses early the same
syntax as lme4:

sumModelInteraction4 <- brm(RT ~ 1 + (PzAlpha+ HRV+lnX+Drive)^3 +  (1 |
Pnum) + (1 | Trial), data = INFAST_Behavioralnew,
prior=set_prior('horseshoe',class='b'))

(The author of brms, Paul B?rkner, also contributes to this list and
might be able to say more about ways of addressing this issue.)

Finally, I see that you're using untransformed RTs in a linear/gaussian
model. There's a lot of debate on whether you should transform or use a
non linear/gaussian model (e.g. log transform, use the gamma transform
with identity or inverse link, etc.). I would check to see how well the
current model actually describes the data and see if non-gaussian models
or a suitable transformation improves fit before doing variable selection.

Best,
Phillip




On 04/25/2018 01:47 PM, Jonathan Judge wrote:
> I think the best option would be to refit these models in Stan (a front end like rstanarm or brms makes it easy with similar lme4 syntax) and use the LOO function to compare their out of sample predictive power. 
> 
> Otherwise, if you wish to stick with lme4, you need some way to properly count the number of effective parameters. AIC doesn?t do that because it doesn?t understand / account for the shrinkage of random effects. You might consider WAIC, which does a better job of this. There is an implementation for lme4 models in the blmeco package. 
> 
> Jonathan
> 
> Sent from my iPhone
> 
>> On Apr 25, 2018, at 2:45 AM, Emmanuel Curis <emmanuel.curis at parisdescartes.fr> wrote:
>>
>> Hello,
>>
>> I think if your interest is more in predictive power of your model
>> than in its ability to reproduce the dataset, your best choice would
>> be using cross-validation.  And to summarize the closeness of your
>> predicted results to the real ones, you may use all the concordance
>> tools, either descriptive like Bland-Altman plots, or more
>> quantititive like concordance correlation coefficients (but beware
>> that their interpretation beyond ? the closest to one, the better ? is
>> not easy) or similar agreement measures. Obviously, the second part
>> can be done without the cross-validation step, on your single, whole
>> dataset.
>>
>> The ? best ? model will be the one witht the highest concordance
>> correlation coefficient; to test that it is significantly better is
>> more tricky, but should be done with carefully crafted simulations,
>> fitting one model to simulated data generated by either one model or
>> the other and vice-versa...
>>
>> Note also that if all your predictors are continuous, as seems to be
>> in your description, the syntax (x+y+...)^n is misleading, because it
>> forgets some important terms.
>>
>> Indeed, let consider the two-variables case, x and y. The first order
>> model is z = ?0 + alpha * x + beta * y, a plane. The second order
>> model would then be a paraboloid,
>>
>> z = ?0 + alpha * x + beta * y + gamma * x? + delta * y? + a * x * y
>>
>> However, the syntax (x+y)^2 expends to x + y + x:y, that is it forgets
>> the I(x^2) and I(y^2) terms. So, unless you have strong belief that
>> both gamma and delta are 0, you're model is incomplete.
>>
>> Hope all of this will help,
>> Best regards,
>> Emmanuel
>>
>> On Tue, Apr 24, 2018 at 09:17:32PM -0400, P Greenwood wrote:
>> ? Hello
>> ? 
>> ? Although alpha-band EEG is something of a gold standard in predicting processing of stimuli (pre-stimulus alpha), it is not easy to measure EEG outside the lab (e.g. in a vehicle).  In contrast, heart-rate and eye gaze are more reliably obtained in the field using low-cost wearable sensors. 
>> ? 
>> ? We sought to compare the ability of 3 sensors to model human reaction time (RT) to a signal from automation.  We compared these measures: alpha-band (PzAlpha), heart-rate variability (HRV), and eye gaze (lnX).  Each person has 10 trials in each of 5 drives. Pnum is subject number.
>> ? 
>> ? We sought to model RT from  alpha-band,  heart-rate variability (HRV), and eye gaze (lnX) and Drive.
>> ? 
>> ? sumModelInteraction4 <- lmer(RT ~ 1 + (PzAlpha+ HRV+lnX+Drive)^3 +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)
>> ? 
>> ? The output, pasted below, reveals interactions: PzAlpha x HRV, PzAlpha x Drive, and HRV x Drive. Also pasted below is some of the raw data.
>> ? 
>> ? An LRT comparing this model with an additive model (PzAlpha+RMSSD+lnX+Drive+Trial) yields a significant difference.  This suggests that the interactions  PzAlpha x Drive and HRV x Drive are meaningful predictors. 
>> ? 
>> ? We would like to determine whether PzAlpha x Drive or  HRV x Drive is the better predictor of RT.  What is the best way to compare those 2 models?  The measures are scaled and centered.
>> ? 
>> ? Thank you very much.
>> ? 
>> ? Pam Greenwood
>> ? 
>> ? Fixed effects:
>> ?                       Estimate Std. Error         df t value Pr(>|t|)   
>> ? (Intercept)         -1.908e-01  1.368e-01  3.310e+01  -1.395  0.17235   
>> ? PzAlpha             -1.098e-01  6.042e-02  2.339e+02  -1.818  0.07041 . 
>> ? HRV               -1.127e-01  6.402e-02  1.112e+03  -1.760  0.07868 . 
>> ? lnX                  7.921e-02  7.547e-02  1.102e+03   1.050  0.29416   
>> ? Drive                5.382e-02  1.661e-02  1.080e+03   3.241  0.00123 **
>> ? PzAlpha: HRV       -1.586e-01  6.424e-02  7.035e+02  -2.468  0.01382 * 
>> ? PzAlpha:lnX          1.116e-01  7.400e-02  8.456e+02   1.508  0.13199   
>> ? PzAlpha:Drive        4.405e-02  1.730e-02  1.049e+03   2.546  0.01103 * 
>> ? HRV:lnX           -4.723e-02  6.905e-02  1.100e+03  -0.684  0.49407   
>> ? HRV:Drive          3.652e-02  1.747e-02  1.098e+03   2.091  0.03677 * 
>> ? lnX:Drive           -1.275e-02  1.992e-02  1.100e+03  -0.640  0.52217   
>> ? PzAlpha: HRV:lnX    1.473e-02  2.567e-02  8.244e+02   0.574  0.56621   
>> ? PzAlpha: HRV:Drive  3.308e-02  1.878e-02  1.084e+03   1.761  0.07845 . 
>> ? PzAlpha:lnX:Drive   -2.325e-02  2.005e-02  9.166e+02  -1.160  0.24640   
>> ? HRV:lnX:Drive      9.729e-03  1.769e-02  1.097e+03   0.550  0.58247   
>> ? 
>> ? 
>> ?    
>> ?    Pnum
>> ?    Drive        Trial    RT    ACC    FzAlpha    CzAlpha    PzAlpha    FzTheta    CzTheta    PzTheta    MeanPupil    lnX    lnY    MeanRR    
>> ? HRV
>> ? 20    1    1    1480.8931    1    7.9928    10.216    7.6254    3.4916    4.8657    6.4977    4.280969072    -3.208115816    -2.423813328    0.7336          0.074666667
>> ? 20    1    2    1983.254    1    -8.2609    0.62018    0.32812    4.2257    6.0181    6.5564    4.360414101    -1.926558582    -2.364252526    0.7336        0.074666667
>> ? 20    1    3    1588.0317    1    1.2572    5.5394    9.0619    4.322    6.7421    7.2778    4.429370379    -2.510514134    -2.890876402    0.734        0.073333333
>> ? 20    1    4    2600    0    -2.0822    -3.5216    2.597    7.6632    9.4505    9.2404    3.994177574    -2.121340179    -3.875411777    0.7408        0.050666667
>> ? 20    1    5    1268.9969    1    2.463    4.5837    4.0916    3.4363    4.2989    -2.1573    3.927884406    -1.754642861    -2.737213207    0.7516        0.014666667
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 0
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? Editorial Board, NeuroImage
>> ? David King Hall 2052
>> ? George Mason University
>> ? MSN 3F5, 4400 University Drive
>> ? Fairfax, VA 22030-4444
>> ? 
>> ? Ph: 703 993-4268
>> ? fax: 703 993-1359
>> ? email: Pgreenw1 at gmu.edu
>> ? http://psychology.gmu.edu/people/pgreenw1
>> ? 
>> ? 
>> ?    [[alternative HTML version deleted]]
>> ? 
>> ? _______________________________________________
>> ? R-sig-mixed-models at r-project.org mailing list
>> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> -- 
>>                                Emmanuel CURIS
>>                                emmanuel.curis at parisdescartes.fr
>>
>> Page WWW: http://emmanuel.curis.online.fr/index.html
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cri.alessandro at gmail.com  Wed Apr 25 19:07:07 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Wed, 25 Apr 2018 12:07:07 -0500
Subject: [R-sig-ME] z-scores using glht
Message-ID: <CAHhX7Wj4MWrWMrfCZ2x2MZG_8MLfqxA1OMkqQa_4pBjwPeVU-Q@mail.gmail.com>

Hi all,

after fitting a model with lme, I run post-hoc tests with glht. The results
are repored in the following:

> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> summary(lev.ph, test=adjusted("bonferroni"))

Simultaneous Tests for General Linear Hypotheses

Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
~des_days |
    ratID, method = "ML", na.action = na.omit, control = lCtr)

Linear Hypotheses:
                                 Estimate   Std. Error  z value
Pr(>|z|)
des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
des_days48 == 0   2688.4     1078.5        2.493        0.038025 *

I am trying to understand the output values. How are the z-scores computed?
If the function uses standard errors, should these be t-statistics (and not
z-scores)?

Sorry for the perhaps trivial question.

Best
Cristiano

	[[alternative HTML version deleted]]


From cri.alessandro at gmail.com  Wed Apr 25 19:07:54 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Wed, 25 Apr 2018 12:07:54 -0500
Subject: [R-sig-ME] z-scores using glht
Message-ID: <CAHhX7Wjojn7rWmwwFB7Xu5cOJRoeF3FgUgF1PnKWiUcnd_CHAw@mail.gmail.com>

Hi all,

after fitting a model with lme, I run post-hoc tests with glht. The results
are repored in the following:

> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> summary(lev.ph, test=adjusted("bonferroni"))

Simultaneous Tests for General Linear Hypotheses

Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
~des_days |
    ratID, method = "ML", na.action = na.omit, control = lCtr)

Linear Hypotheses:
                                 Estimate   Std. Error  z value
Pr(>|z|)
des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
des_days48 == 0   2688.4     1078.5        2.493        0.038025 *

I am trying to understand the output values. How are the z-scores computed?
If the function uses standard errors, should these be t-statistics (and not
z-scores)?

Sorry for the perhaps trivial question.

Best

	[[alternative HTML version deleted]]


From cri.alessandro at gmail.com  Wed Apr 25 19:26:38 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Wed, 25 Apr 2018 12:26:38 -0500
Subject: [R-sig-ME] z-scores and glht
Message-ID: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>

Hi all,

something is wrong with my email, so I am sorry for possible multiple
postings.

After fitting a model with lme, I run post-hoc tests with glht. The results
are repored in the following:

> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> summary(lev.ph, test=adjusted("bonferroni"))

Simultaneous Tests for General Linear Hypotheses

Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
~des_days |
    ratID, method = "ML", na.action = na.omit, control = lCtr)

Linear Hypotheses:
                                 Estimate   Std. Error  z value
Pr(>|z|)
des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
des_days48 == 0   2688.4     1078.5        2.493        0.038025 *

I am trying to understand the output values. How are the z-scores computed?
If the function uses standard errors, should these be t-statistics (and not
z-scores)?

Thanks for your help, and sorry for the naive question.

Best
Cristiano

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Wed Apr 25 20:18:16 2018
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 25 Apr 2018 13:18:16 -0500
Subject: [R-sig-ME] Convergence problem example
In-Reply-To: <34357487-1e4c-208b-4868-1398483583f7@mpi.nl>
References: <CAErODj-Lx9c7V3Gpg1iN-w6moPcr9h4sH+BvntdgWe4pk+QFOQ@mail.gmail.com>
 <34357487-1e4c-208b-4868-1398483583f7@mpi.nl>
Message-ID: <CAErODj--rO9eMWzmj2Ar7z8Z_82ohEvn2c1rnDUgrzq5BgpKXg@mail.gmail.com>

Thanks. I confirm your suggestion.

There are still some moving pieces I don't understand. Mostly, I
wonder if the convergence warning that I saw is a meaningful thing,
whether users should be notified about it at all.  I'm not a
specialist on this.

The estimates differ at the 6th decimal point. In the fixed estimates
(m1 is default, m1a is bobyqa):

> fixef(m1) - fixef(m1a)
      (Intercept)             lncfs              aiai heiferprimiparous
     2.489050e-05     -5.759644e-06      2.962373e-06     -1.161505e-06

Maybe the convergence warning does find a real issue.

The anova() comparison thinks the models are identical:

> anova(m1a, m1)
Data: dairy
Models:
m1a: fscr ~ lncfs + ai + heifer + (1 | cow)
m1: fscr ~ lncfs + ai + heifer + (1 | cow)
    Df    AIC    BIC  logLik deviance Chisq Chi Df Pr(>Chisq)
m1a  5 4017.8 4047.9 -2003.9   4007.8
m1   5 4017.8 4047.9 -2003.9   4007.8     0      0          1

You have to turn up the digits to find a difference:

> print(anova(m1a, m1), digits = 20)
Data: dairy
Models:
m1a: fscr ~ lncfs + ai + heifer + (1 | cow)
m1: fscr ~ lncfs + ai + heifer + (1 | cow)
        Df                   AIC                     BIC
                  logLik
m1a  5 4017.8128979117764175 4047.8895344568850305 -2003.9064489558882087
m1   5 4017.8128979273369623 4047.8895344724455754 -2003.9064489636684812
                 deviance Chisq Chi Df Pr(>Chisq)
m1a 4007.8128979117764175
m1   4007.8128979273369623     0      0          1
>



pj


On Wed, Apr 25, 2018 at 10:12 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:
> Changing the optimizer seems to address the convergence warnings and has
> no impact on the other aspects of the fit:
>
>> m1 <- update(m1, control=glmerControl(optimizer="bobyqa"))
>> summary(m1)
> Generalized linear mixed model fit by maximum likelihood (Adaptive
>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
>  Family: binomial  ( logit )
> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
>    Data: dairy
> Control: glmerControl(optimizer = "bobyqa")
>
>      AIC      BIC   logLik deviance df.resid
>   4017.8   4047.9  -2003.9   4007.8     3022
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.8136 -0.7652 -0.6479  1.0420  1.6213
>
> Random effects:
>  Groups Name        Variance Std.Dev.
>  cow    (Intercept) 0.3419   0.5847
> Number of obs: 3027, groups:  cow, 1575
>
> Fixed effects:
>                   Estimate Std. Error z value Pr(>|z|)
> (Intercept)       -1.55696    0.43481  -3.581 0.000343 ***
> lncfs              0.52222    0.10007   5.218  1.8e-07 ***
> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
> heiferprimiparous -0.08259    0.09718  -0.850 0.395418
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) lncfs  aiai
> lncfs       -0.965
> aiai        -0.193 -0.046
> heifrprmprs -0.054  0.016 -0.051
>
> Phillip
>
>
>
> On 04/25/2018 04:56 PM, Paul Johnson wrote:
>> In the book Multilevel and Longitudinal Modeling using Stata,
>> Rabe-Hesketh and Skrondal have a lot of exercises and over the years
>> I've been trying to write Stata and R code to demonstrate
>> similarities/differences.
>>
>> I've run into an example where Stata (either with builtin methods or
>> the addon gllamm) seems to think it gets estimates but lme4
>> diagnostics say there is a convergence failure.  I want to impose on
>> you, get your advice about it. We see convergence warnings quite often
>> with lme4, but they are usually the "rescale your variables" errors,
>> not as blunt as this.
>>
>> The first part retrieves "dairy.dta" from the book website
>>
>> library(foreign)
>> library(lme4)
>>
>> fn <- "dairy"
>> if (!file.exists(paste0(fn, ".dta12"))) {
>>     download.file(paste0("http://www.stata-press.com/data/mlmus3/", fn, ".dta"),
>>                   destfile = paste0(fn, ".dta12"))
>> }
>>
>> dairy <- read.dta(paste0(fn, ".dta12"))
>>
>> #1
>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
>>             family = binomial(link = "logit"), nAGQ = 30,
>>             data = dairy)
>> summary(m1)
>>
>> From that, I see:
>>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
>> +             family = binomial(link = "logit"), nAGQ = 30,
>> +             data = dairy)
>> Warning messages:
>> 1: 'rBind' is deprecated.
>>  Since R version 3.2.0, base's rbind() should work fine with S4 objects
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 0.00396932 (tol = 0.001,
>> component 1)
>>> summary(m1)
>> Generalized linear mixed model fit by maximum likelihood (Adaptive
>>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
>>  Family: binomial  ( logit )
>> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
>>    Data: dairy
>>
>>      AIC      BIC   logLik deviance df.resid
>>   4017.8   4047.9  -2003.9   4007.8     3022
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -1.8136 -0.7652 -0.6479  1.0420  1.6213
>>
>> Random effects:
>>  Groups Name        Variance Std.Dev.
>>  cow    (Intercept) 0.3419   0.5847
>> Number of obs: 3027, groups:  cow, 1575
>>
>> Fixed effects:
>>                   Estimate Std. Error z value Pr(>|z|)
>> (Intercept)       -1.55693    0.43481  -3.581 0.000343 ***
>> lncfs              0.52221    0.10007   5.218 1.81e-07 ***
>> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
>> heiferprimiparous -0.08259    0.09718  -0.850 0.395410
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>             (Intr) lncfs  aiai
>> lncfs       -0.965
>> aiai        -0.193 -0.046
>> heifrprmprs -0.054  0.016 -0.051
>> convergence code: 0
>> Model failed to converge with max|grad| = 0.00396932 (tol = 0.001, component 1)
>>
>>
>> Stata output for comparison purposes, using gllamm:
>>
>> . gllamm fscr lncfs ai heifer, i(cow) link(logit) fam(binom) adapt
>>
>> Running adaptive quadrature
>> Iteration 0:    log likelihood = -2004.6011
>> Iteration 1:    log likelihood = -2003.9085
>> Iteration 2:    log likelihood = -2003.9069
>>
>>
>> Adaptive quadrature has converged, running Newton-Raphson
>> Iteration 0:   log likelihood = -2003.9069
>> Iteration 1:   log likelihood = -2003.9069
>> Iteration 2:   log likelihood = -2003.9064
>> Iteration 3:   log likelihood = -2003.9064
>>
>> number of level 1 units = 3027
>> number of level 2 units = 1575
>>
>> Condition Number = 47.123877
>>
>> gllamm model
>>
>> log likelihood = -2003.9064
>>
>> ------------------------------------------------------------------------------
>>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
>> -------------+----------------------------------------------------------------
>>        lncfs |   .5222157   .1000693     5.22   0.000     .3260834     .718348
>>           ai |  -1.095598   .1234099    -8.88   0.000    -1.337477   -.8537193
>>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078837
>>        _cons |  -1.556961   .4348008    -3.58   0.000    -2.409155   -.7047673
>> ------------------------------------------------------------------------------
>>
>>
>> Variances and covariances of random effects
>> ------------------------------------------------------------------------------
>>
>>
>> ***level 2 (cow)
>>
>>     var(1): .34188062 (.1263136)
>> ------------------------------------------------------------------------------
>>
>>
>> Using the newer meglm that is provided with Stata
>>
>> . meglm fscr lncfs ai heifer || cow: , family(binom) link(logit)
>>
>> Fitting fixed-effects model:
>>
>> Iteration 0:   log likelihood = -2011.8253
>> Iteration 1:   log likelihood = -2009.1421
>> Iteration 2:   log likelihood = -2009.1412
>> Iteration 3:   log likelihood = -2009.1412
>>
>> Refining starting values:
>>
>> Grid node 0:   log likelihood = -2015.6021
>>
>> Fitting full model:
>>
>> Iteration 0:   log likelihood = -2015.6021
>> Iteration 1:   log likelihood =  -2006.709
>> Iteration 2:   log likelihood = -2003.9174
>> Iteration 3:   log likelihood = -2003.9065
>> Iteration 4:   log likelihood = -2003.9065
>>
>> Mixed-effects GLM                               Number of obs     =      3,027
>> Family:                binomial
>> Link:                     logit
>> Group variable:             cow                 Number of groups  =      1,575
>>
>>                                                 Obs per group:
>>                                                               min =          1
>>                                                               avg =        1.9
>>                                                               max =          5
>>
>> Integration method: mvaghermite                 Integration pts.  =          7
>>
>>                                                 Wald chi2(3)      =     103.86
>> Log likelihood = -2003.9065                     Prob > chi2       =     0.0000
>> ------------------------------------------------------------------------------
>>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
>> -------------+----------------------------------------------------------------
>>        lncfs |   .5222154   .1000694     5.22   0.000      .326083    .7183479
>>           ai |  -1.095597   .1234095    -8.88   0.000    -1.337476   -.8537191
>>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078836
>>        _cons |  -1.556961   .4348012    -3.58   0.000    -2.409155   -.7047659
>> -------------+----------------------------------------------------------------
>> cow          |
>>    var(_cons)|   .3418776   .1263105                      .1657237    .7052721
>> ------------------------------------------------------------------------------
>> LR test vs. logistic model: chibar2(01) = 10.47       Prob >= chibar2 = 0.0006
>>
>>
>> As far as I can see, parameter estimates are the same. I did not
>> compare conditional modes.
>>
>> If lme4's converge warning is valid, then we have a concrete case
>> where Stata is reporting the wrong thing.  I can see some upside there
>> :)
>>
>> R details
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 17.10
>>
>> Matrix products: default
>> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
>> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_1.1-15    Matrix_1.2-14  foreign_0.8-69
>>
>> loaded via a namespace (and not attached):
>>  [1] minqa_1.2.4     MASS_7.3-49     compiler_3.4.4  tools_3.4.4
>>  [5] Rcpp_0.12.15    splines_3.4.4   nlme_3.1-137    grid_3.4.4
>>  [9] nloptr_1.0.4    lattice_0.20-35
>>
>>



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From dan at danmirman.org  Wed Apr 25 20:25:53 2018
From: dan at danmirman.org (Dan Mirman)
Date: Wed, 25 Apr 2018 13:25:53 -0500
Subject: [R-sig-ME] z-scores and glht
In-Reply-To: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
References: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
Message-ID: <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>

The z-scores are computed by dividing the Estimate by the SE. As for why
these are not t-statistics, the short answer is that the degrees of freedom
are not trivial to compute. I believe Doug Bates' response is often cited
by way of explanation:
http://stat.ethz.ch/pipermail/r-help/2006-May/094765.html and it is covered
in the FAQ:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have
(for more discussion of alternatives see Luke, 2017,
http://link.springer.com/article/10.3758%2Fs13428-016-0809-y).

glht() is side-stepping all of that and just using a normal approximation.
For what it's worth, my own experience is that this approximation is only
slightly anti-conservative, so I usually feel comfortable using it.

Hope that helps,
Dan

On Wed, Apr 25, 2018 at 12:26 PM, Cristiano Alessandro <
cri.alessandro at gmail.com> wrote:

> Hi all,
>
> something is wrong with my email, so I am sorry for possible multiple
> postings.
>
> After fitting a model with lme, I run post-hoc tests with glht. The results
> are repored in the following:
>
> > lev.ph <- glht(lev.lm, linfct = ph_conditional);
> > summary(lev.ph, test=adjusted("bonferroni"))
>
> Simultaneous Tests for General Linear Hypotheses
>
> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
> ~des_days |
>     ratID, method = "ML", na.action = na.omit, control = lCtr)
>
> Linear Hypotheses:
>                                  Estimate   Std. Error  z value
> Pr(>|z|)
> des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
> des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
> des_days48 == 0   2688.4     1078.5        2.493        0.038025 *
>
> I am trying to understand the output values. How are the z-scores computed?
> If the function uses standard errors, should these be t-statistics (and not
> z-scores)?
>
> Thanks for your help, and sorry for the naive question.
>
> Best
> Cristiano
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
-----------------------------------------------------
Dan Mirman
Associate Professor
Department of Psychology
University of Alabama at Birmingham
http://www.danmirman.org
-----------------------------------------------------

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Apr 25 20:34:34 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Apr 2018 14:34:34 -0400
Subject: [R-sig-ME] z-scores and glht
In-Reply-To: <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
References: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
 <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
Message-ID: <55d1ace8-8400-3689-b0dc-b4979b2a9102@gmail.com>


  If someone wanted to work hard enough they could probably work out a
Satterthwaite approximation for the degrees of freedom of these
contrasts ... ?


On 2018-04-25 02:25 PM, Dan Mirman wrote:
> The z-scores are computed by dividing the Estimate by the SE. As for why
> these are not t-statistics, the short answer is that the degrees of freedom
> are not trivial to compute. I believe Doug Bates' response is often cited
> by way of explanation:
> http://stat.ethz.ch/pipermail/r-help/2006-May/094765.html and it is covered
> in the FAQ:
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have
> (for more discussion of alternatives see Luke, 2017,
> http://link.springer.com/article/10.3758%2Fs13428-016-0809-y).
> 
> glht() is side-stepping all of that and just using a normal approximation.
> For what it's worth, my own experience is that this approximation is only
> slightly anti-conservative, so I usually feel comfortable using it.
> 
> Hope that helps,
> Dan
> 
> On Wed, Apr 25, 2018 at 12:26 PM, Cristiano Alessandro <
> cri.alessandro at gmail.com> wrote:
> 
>> Hi all,
>>
>> something is wrong with my email, so I am sorry for possible multiple
>> postings.
>>
>> After fitting a model with lme, I run post-hoc tests with glht. The results
>> are repored in the following:
>>
>>> lev.ph <- glht(lev.lm, linfct = ph_conditional);
>>> summary(lev.ph, test=adjusted("bonferroni"))
>>
>> Simultaneous Tests for General Linear Hypotheses
>>
>> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
>> ~des_days |
>>     ratID, method = "ML", na.action = na.omit, control = lCtr)
>>
>> Linear Hypotheses:
>>                                  Estimate   Std. Error  z value
>> Pr(>|z|)
>> des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
>> des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
>> des_days48 == 0   2688.4     1078.5        2.493        0.038025 *
>>
>> I am trying to understand the output values. How are the z-scores computed?
>> If the function uses standard errors, should these be t-statistics (and not
>> z-scores)?
>>
>> Thanks for your help, and sorry for the naive question.
>>
>> Best
>> Cristiano
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
>


From bbolker at gmail.com  Wed Apr 25 20:47:05 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Apr 2018 14:47:05 -0400
Subject: [R-sig-ME] Convergence problem example
In-Reply-To: <34357487-1e4c-208b-4868-1398483583f7@mpi.nl>
References: <CAErODj-Lx9c7V3Gpg1iN-w6moPcr9h4sH+BvntdgWe4pk+QFOQ@mail.gmail.com>
 <34357487-1e4c-208b-4868-1398483583f7@mpi.nl>
Message-ID: <ee8c7336-ddb9-04ed-a166-eff5e809dc1e@gmail.com>


  Just a quick comment.

  As long-time readers of this forum may know (I think I've said it here
before), the convergence warnings provided by lme4 are often
over-sensitive.  They're based on *post hoc* attempts (after the
nonlinear optimizer thinks it has converged) to evaluate the KKT
criteria (in this case reducing to zero gradient, negative
positive-definite Hessian) by computing the finite-difference
approximations of the gradient and Hessian of the negative
log-likelihood.  The problem is that this computation is just as subject
to numeric error as the nonlinear optimization itself, so it doesn't
work very well. (Some of this is stated in ?lme4::convergence)

  Doug Bates feels that attempts to fix the problem are
"toast-scraping", i.e. attempts to fix something that was a bad idea in
the first place (i.e., I/we should throw away the metaphorical burned
toast and scrap the post-hoc convergence tests, relying on the optimizer
to tell us if it thinks it has converged successfully). The Catch-22 is
that (1) I'm afraid to throw a system that might catch a reasonable
fraction of truly bad convergence cases; (2) I don't want to flip-flop
(take the tests out, then decide that they were a good idea after all
and reintroduce them); (3) making an *informed* decision what to do
(e.g. throwing out the tests or setting a more appropriate threshold)
would require a lot of work generating test cases -- an in order to get
a really good handle on the problem, we'd have to generate not just
"nice" test cases but all kinds of pathological examples where there
really are convergence problems.

  Besides being hard and tedious, this is time I don't really have.
Volunteers ... ?

  cheers
   Ben Bolker

On 2018-04-25 11:12 AM, Phillip Alday wrote:
> Changing the optimizer seems to address the convergence warnings and has
> no impact on the other aspects of the fit:
> 
>> m1 <- update(m1, control=glmerControl(optimizer="bobyqa"))
>> summary(m1)
> Generalized linear mixed model fit by maximum likelihood (Adaptive
>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
>  Family: binomial  ( logit )
> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
>    Data: dairy
> Control: glmerControl(optimizer = "bobyqa")
> 
>      AIC      BIC   logLik deviance df.resid
>   4017.8   4047.9  -2003.9   4007.8     3022
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.8136 -0.7652 -0.6479  1.0420  1.6213
> 
> Random effects:
>  Groups Name        Variance Std.Dev.
>  cow    (Intercept) 0.3419   0.5847
> Number of obs: 3027, groups:  cow, 1575
> 
> Fixed effects:
>                   Estimate Std. Error z value Pr(>|z|)
> (Intercept)       -1.55696    0.43481  -3.581 0.000343 ***
> lncfs              0.52222    0.10007   5.218  1.8e-07 ***
> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
> heiferprimiparous -0.08259    0.09718  -0.850 0.395418
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>             (Intr) lncfs  aiai
> lncfs       -0.965
> aiai        -0.193 -0.046
> heifrprmprs -0.054  0.016 -0.051
> 
> Phillip
> 
> 
> 
> On 04/25/2018 04:56 PM, Paul Johnson wrote:
>> In the book Multilevel and Longitudinal Modeling using Stata,
>> Rabe-Hesketh and Skrondal have a lot of exercises and over the years
>> I've been trying to write Stata and R code to demonstrate
>> similarities/differences.
>>
>> I've run into an example where Stata (either with builtin methods or
>> the addon gllamm) seems to think it gets estimates but lme4
>> diagnostics say there is a convergence failure.  I want to impose on
>> you, get your advice about it. We see convergence warnings quite often
>> with lme4, but they are usually the "rescale your variables" errors,
>> not as blunt as this.
>>
>> The first part retrieves "dairy.dta" from the book website
>>
>> library(foreign)
>> library(lme4)
>>
>> fn <- "dairy"
>> if (!file.exists(paste0(fn, ".dta12"))) {
>>     download.file(paste0("http://www.stata-press.com/data/mlmus3/", fn, ".dta"),
>>                   destfile = paste0(fn, ".dta12"))
>> }
>>
>> dairy <- read.dta(paste0(fn, ".dta12"))
>>
>> #1
>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
>>             family = binomial(link = "logit"), nAGQ = 30,
>>             data = dairy)
>> summary(m1)
>>
>> From that, I see:
>>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
>> +             family = binomial(link = "logit"), nAGQ = 30,
>> +             data = dairy)
>> Warning messages:
>> 1: 'rBind' is deprecated.
>>  Since R version 3.2.0, base's rbind() should work fine with S4 objects
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 0.00396932 (tol = 0.001,
>> component 1)
>>> summary(m1)
>> Generalized linear mixed model fit by maximum likelihood (Adaptive
>>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
>>  Family: binomial  ( logit )
>> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
>>    Data: dairy
>>
>>      AIC      BIC   logLik deviance df.resid
>>   4017.8   4047.9  -2003.9   4007.8     3022
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -1.8136 -0.7652 -0.6479  1.0420  1.6213
>>
>> Random effects:
>>  Groups Name        Variance Std.Dev.
>>  cow    (Intercept) 0.3419   0.5847
>> Number of obs: 3027, groups:  cow, 1575
>>
>> Fixed effects:
>>                   Estimate Std. Error z value Pr(>|z|)
>> (Intercept)       -1.55693    0.43481  -3.581 0.000343 ***
>> lncfs              0.52221    0.10007   5.218 1.81e-07 ***
>> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
>> heiferprimiparous -0.08259    0.09718  -0.850 0.395410
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>             (Intr) lncfs  aiai
>> lncfs       -0.965
>> aiai        -0.193 -0.046
>> heifrprmprs -0.054  0.016 -0.051
>> convergence code: 0
>> Model failed to converge with max|grad| = 0.00396932 (tol = 0.001, component 1)
>>
>>
>> Stata output for comparison purposes, using gllamm:
>>
>> . gllamm fscr lncfs ai heifer, i(cow) link(logit) fam(binom) adapt
>>
>> Running adaptive quadrature
>> Iteration 0:    log likelihood = -2004.6011
>> Iteration 1:    log likelihood = -2003.9085
>> Iteration 2:    log likelihood = -2003.9069
>>
>>
>> Adaptive quadrature has converged, running Newton-Raphson
>> Iteration 0:   log likelihood = -2003.9069
>> Iteration 1:   log likelihood = -2003.9069
>> Iteration 2:   log likelihood = -2003.9064
>> Iteration 3:   log likelihood = -2003.9064
>>
>> number of level 1 units = 3027
>> number of level 2 units = 1575
>>
>> Condition Number = 47.123877
>>
>> gllamm model
>>
>> log likelihood = -2003.9064
>>
>> ------------------------------------------------------------------------------
>>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
>> -------------+----------------------------------------------------------------
>>        lncfs |   .5222157   .1000693     5.22   0.000     .3260834     .718348
>>           ai |  -1.095598   .1234099    -8.88   0.000    -1.337477   -.8537193
>>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078837
>>        _cons |  -1.556961   .4348008    -3.58   0.000    -2.409155   -.7047673
>> ------------------------------------------------------------------------------
>>
>>
>> Variances and covariances of random effects
>> ------------------------------------------------------------------------------
>>
>>
>> ***level 2 (cow)
>>
>>     var(1): .34188062 (.1263136)
>> ------------------------------------------------------------------------------
>>
>>
>> Using the newer meglm that is provided with Stata
>>
>> . meglm fscr lncfs ai heifer || cow: , family(binom) link(logit)
>>
>> Fitting fixed-effects model:
>>
>> Iteration 0:   log likelihood = -2011.8253
>> Iteration 1:   log likelihood = -2009.1421
>> Iteration 2:   log likelihood = -2009.1412
>> Iteration 3:   log likelihood = -2009.1412
>>
>> Refining starting values:
>>
>> Grid node 0:   log likelihood = -2015.6021
>>
>> Fitting full model:
>>
>> Iteration 0:   log likelihood = -2015.6021
>> Iteration 1:   log likelihood =  -2006.709
>> Iteration 2:   log likelihood = -2003.9174
>> Iteration 3:   log likelihood = -2003.9065
>> Iteration 4:   log likelihood = -2003.9065
>>
>> Mixed-effects GLM                               Number of obs     =      3,027
>> Family:                binomial
>> Link:                     logit
>> Group variable:             cow                 Number of groups  =      1,575
>>
>>                                                 Obs per group:
>>                                                               min =          1
>>                                                               avg =        1.9
>>                                                               max =          5
>>
>> Integration method: mvaghermite                 Integration pts.  =          7
>>
>>                                                 Wald chi2(3)      =     103.86
>> Log likelihood = -2003.9065                     Prob > chi2       =     0.0000
>> ------------------------------------------------------------------------------
>>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
>> -------------+----------------------------------------------------------------
>>        lncfs |   .5222154   .1000694     5.22   0.000      .326083    .7183479
>>           ai |  -1.095597   .1234095    -8.88   0.000    -1.337476   -.8537191
>>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078836
>>        _cons |  -1.556961   .4348012    -3.58   0.000    -2.409155   -.7047659
>> -------------+----------------------------------------------------------------
>> cow          |
>>    var(_cons)|   .3418776   .1263105                      .1657237    .7052721
>> ------------------------------------------------------------------------------
>> LR test vs. logistic model: chibar2(01) = 10.47       Prob >= chibar2 = 0.0006
>>
>>
>> As far as I can see, parameter estimates are the same. I did not
>> compare conditional modes.
>>
>> If lme4's converge warning is valid, then we have a concrete case
>> where Stata is reporting the wrong thing.  I can see some upside there
>> :)
>>
>> R details
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 17.10
>>
>> Matrix products: default
>> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
>> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_1.1-15    Matrix_1.2-14  foreign_0.8-69
>>
>> loaded via a namespace (and not attached):
>>  [1] minqa_1.2.4     MASS_7.3-49     compiler_3.4.4  tools_3.4.4
>>  [5] Rcpp_0.12.15    splines_3.4.4   nlme_3.1-137    grid_3.4.4
>>  [9] nloptr_1.0.4    lattice_0.20-35
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cri.alessandro at gmail.com  Wed Apr 25 20:49:39 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Wed, 25 Apr 2018 13:49:39 -0500
Subject: [R-sig-ME] z-scores and glht
In-Reply-To: <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
References: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
 <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
Message-ID: <CAHhX7Whk5=y=4DtSVOBBvj+3h4sfvG5nVK-hvQXmB=wQ145LZA@mail.gmail.com>

Hi Dan,

thanks for your answer. Sorry about my naive question, from a
non-statistician. I still have trouble understanding; you say that z-scores
are the estimates divided by the SE. Isn't this the definition of a
t-statistic under the null hypothesis that the mean is equal to zero?

Also, when you say that glht() is side-stepping all of that and just using
a normal approximation. What does it mean/imply exactly, as far as
computing the z-scores (the ones I see in the output of the summary) goes?

Best
Cristiano

On Wed, Apr 25, 2018 at 1:25 PM, Dan Mirman <dan at danmirman.org> wrote:

> The z-scores are computed by dividing the Estimate by the SE. As for why
> these are not t-statistics, the short answer is that the degrees of freedom
> are not trivial to compute. I believe Doug Bates' response is often cited
> by way of explanation:
> http://stat.ethz.ch/pipermail/r-help/2006-May/094765.html and it is
> covered
> in the FAQ:
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#
> why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-
> options-do-i-have
> (for more discussion of alternatives see Luke, 2017,
> http://link.springer.com/article/10.3758%2Fs13428-016-0809-y).
>
> glht() is side-stepping all of that and just using a normal approximation.
> For what it's worth, my own experience is that this approximation is only
> slightly anti-conservative, so I usually feel comfortable using it.
>
> Hope that helps,
> Dan
>
> On Wed, Apr 25, 2018 at 12:26 PM, Cristiano Alessandro <
> cri.alessandro at gmail.com> wrote:
>
> > Hi all,
> >
> > something is wrong with my email, so I am sorry for possible multiple
> > postings.
> >
> > After fitting a model with lme, I run post-hoc tests with glht. The
> results
> > are repored in the following:
> >
> > > lev.ph <- glht(lev.lm, linfct = ph_conditional);
> > > summary(lev.ph, test=adjusted("bonferroni"))
> >
> > Simultaneous Tests for General Linear Hypotheses
> >
> > Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
> > ~des_days |
> >     ratID, method = "ML", na.action = na.omit, control = lCtr)
> >
> > Linear Hypotheses:
> >                                  Estimate   Std. Error  z value
> > Pr(>|z|)
> > des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
> > des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
> > des_days48 == 0   2688.4     1078.5        2.493        0.038025 *
> >
> > I am trying to understand the output values. How are the z-scores
> computed?
> > If the function uses standard errors, should these be t-statistics (and
> not
> > z-scores)?
> >
> > Thanks for your help, and sorry for the naive question.
> >
> > Best
> > Cristiano
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
> -----------------------------------------------------
> Dan Mirman
> Associate Professor
> Department of Psychology
> University of Alabama at Birmingham
> http://www.danmirman.org
> -----------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Apr 25 20:53:52 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Apr 2018 14:53:52 -0400
Subject: [R-sig-ME] z-scores and glht
In-Reply-To: <CAHhX7Whk5=y=4DtSVOBBvj+3h4sfvG5nVK-hvQXmB=wQ145LZA@mail.gmail.com>
References: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
 <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
 <CAHhX7Whk5=y=4DtSVOBBvj+3h4sfvG5nVK-hvQXmB=wQ145LZA@mail.gmail.com>
Message-ID: <365edcfb-ea6c-4a9a-e04d-6f4182a9c5bd@gmail.com>


   A little more detail:

 if we take the ratio  R=(estimated coefficient)/(standard error), that
is not yet either a "Z score" or a "t score".  If we assume the standard
error is itself estimated without error (i.e. we have an arbitrarily
large amount of data), then we expect R to be normally distributed and
we call it a "Z-score".  If we take into account the expected
uncertainty in the standard error, which in simple cases we can quantify
by knowing the number of residual degrees of freedom, we expect R to be
t-distributed with df=(residual degrees of freedom); then we call R a
"t-score".

  If we are not in a simple case, figuring out the appropriate df can be
difficult.

  cheers
   Ben Bolker


On 2018-04-25 02:49 PM, Cristiano Alessandro wrote:
> Hi Dan,
> 
> thanks for your answer. Sorry about my naive question, from a
> non-statistician. I still have trouble understanding; you say that z-scores
> are the estimates divided by the SE. Isn't this the definition of a
> t-statistic under the null hypothesis that the mean is equal to zero?
> 
> Also, when you say that glht() is side-stepping all of that and just using
> a normal approximation. What does it mean/imply exactly, as far as
> computing the z-scores (the ones I see in the output of the summary) goes?
> 
> Best
> Cristiano
> 
> On Wed, Apr 25, 2018 at 1:25 PM, Dan Mirman <dan at danmirman.org> wrote:
> 
>> The z-scores are computed by dividing the Estimate by the SE. As for why
>> these are not t-statistics, the short answer is that the degrees of freedom
>> are not trivial to compute. I believe Doug Bates' response is often cited
>> by way of explanation:
>> http://stat.ethz.ch/pipermail/r-help/2006-May/094765.html and it is
>> covered
>> in the FAQ:
>> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#
>> why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-
>> options-do-i-have
>> (for more discussion of alternatives see Luke, 2017,
>> http://link.springer.com/article/10.3758%2Fs13428-016-0809-y).
>>
>> glht() is side-stepping all of that and just using a normal approximation.
>> For what it's worth, my own experience is that this approximation is only
>> slightly anti-conservative, so I usually feel comfortable using it.
>>
>> Hope that helps,
>> Dan
>>
>> On Wed, Apr 25, 2018 at 12:26 PM, Cristiano Alessandro <
>> cri.alessandro at gmail.com> wrote:
>>
>>> Hi all,
>>>
>>> something is wrong with my email, so I am sorry for possible multiple
>>> postings.
>>>
>>> After fitting a model with lme, I run post-hoc tests with glht. The
>> results
>>> are repored in the following:
>>>
>>>> lev.ph <- glht(lev.lm, linfct = ph_conditional);
>>>> summary(lev.ph, test=adjusted("bonferroni"))
>>>
>>> Simultaneous Tests for General Linear Hypotheses
>>>
>>> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
>>> ~des_days |
>>>     ratID, method = "ML", na.action = na.omit, control = lCtr)
>>>
>>> Linear Hypotheses:
>>>                                  Estimate   Std. Error  z value
>>> Pr(>|z|)
>>> des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
>>> des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
>>> des_days48 == 0   2688.4     1078.5        2.493        0.038025 *
>>>
>>> I am trying to understand the output values. How are the z-scores
>> computed?
>>> If the function uses standard errors, should these be t-statistics (and
>> not
>>> z-scores)?
>>>
>>> Thanks for your help, and sorry for the naive question.
>>>
>>> Best
>>> Cristiano
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> -----------------------------------------------------
>> Dan Mirman
>> Associate Professor
>> Department of Psychology
>> University of Alabama at Birmingham
>> http://www.danmirman.org
>> -----------------------------------------------------
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Wed Apr 25 20:55:59 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Apr 2018 14:55:59 -0400
Subject: [R-sig-ME] comparing 2 models
In-Reply-To: <BN3PR16MB08200BE4E8BECEF4EA4B076AAF8F0@BN3PR16MB0820.namprd16.prod.outlook.com>
References: <19AAD5A9-B6BD-47BB-8B64-E091577B21EA@gmu.edu>
 <20180425074546.GA18480@info124.pharmacie.univ-paris5.fr>
 <BN3PR16MB08200BE4E8BECEF4EA4B076AAF8F0@BN3PR16MB0820.namprd16.prod.outlook.com>
Message-ID: <60a3cd5b-3013-391b-2c8a-b5944f65d879@gmail.com>


WAIC may be better than cAIC (conditional AIC: Greven and Kneib), for
all I know, but just pointing out for completeness that there's a cAIC4
package that works with lme4.


On 2018-04-25 07:47 AM, Jonathan Judge wrote:
> I think the best option would be to refit these models in Stan (a front end like rstanarm or brms makes it easy with similar lme4 syntax) and use the LOO function to compare their out of sample predictive power. 
> 
> Otherwise, if you wish to stick with lme4, you need some way to properly count the number of effective parameters. AIC doesn?t do that because it doesn?t understand / account for the shrinkage of random effects. You might consider WAIC, which does a better job of this. There is an implementation for lme4 models in the blmeco package. 
> 
> Jonathan
> 
> Sent from my iPhone
> 
>> On Apr 25, 2018, at 2:45 AM, Emmanuel Curis <emmanuel.curis at parisdescartes.fr> wrote:
>>
>> Hello,
>>
>> I think if your interest is more in predictive power of your model
>> than in its ability to reproduce the dataset, your best choice would
>> be using cross-validation.  And to summarize the closeness of your
>> predicted results to the real ones, you may use all the concordance
>> tools, either descriptive like Bland-Altman plots, or more
>> quantititive like concordance correlation coefficients (but beware
>> that their interpretation beyond ? the closest to one, the better ? is
>> not easy) or similar agreement measures. Obviously, the second part
>> can be done without the cross-validation step, on your single, whole
>> dataset.
>>
>> The ? best ? model will be the one witht the highest concordance
>> correlation coefficient; to test that it is significantly better is
>> more tricky, but should be done with carefully crafted simulations,
>> fitting one model to simulated data generated by either one model or
>> the other and vice-versa...
>>
>> Note also that if all your predictors are continuous, as seems to be
>> in your description, the syntax (x+y+...)^n is misleading, because it
>> forgets some important terms.
>>
>> Indeed, let consider the two-variables case, x and y. The first order
>> model is z = ?0 + alpha * x + beta * y, a plane. The second order
>> model would then be a paraboloid,
>>
>> z = ?0 + alpha * x + beta * y + gamma * x? + delta * y? + a * x * y
>>
>> However, the syntax (x+y)^2 expends to x + y + x:y, that is it forgets
>> the I(x^2) and I(y^2) terms. So, unless you have strong belief that
>> both gamma and delta are 0, you're model is incomplete.
>>
>> Hope all of this will help,
>> Best regards,
>> Emmanuel
>>
>> On Tue, Apr 24, 2018 at 09:17:32PM -0400, P Greenwood wrote:
>> ? Hello
>> ? 
>> ? Although alpha-band EEG is something of a gold standard in predicting processing of stimuli (pre-stimulus alpha), it is not easy to measure EEG outside the lab (e.g. in a vehicle).  In contrast, heart-rate and eye gaze are more reliably obtained in the field using low-cost wearable sensors. 
>> ? 
>> ? We sought to compare the ability of 3 sensors to model human reaction time (RT) to a signal from automation.  We compared these measures: alpha-band (PzAlpha), heart-rate variability (HRV), and eye gaze (lnX).  Each person has 10 trials in each of 5 drives. Pnum is subject number.
>> ? 
>> ? We sought to model RT from  alpha-band,  heart-rate variability (HRV), and eye gaze (lnX) and Drive.
>> ? 
>> ? sumModelInteraction4 <- lmer(RT ~ 1 + (PzAlpha+ HRV+lnX+Drive)^3 +  (1 | Pnum) + (1 | Trial), data = INFAST_Behavioralnew, REML = FALSE)
>> ? 
>> ? The output, pasted below, reveals interactions: PzAlpha x HRV, PzAlpha x Drive, and HRV x Drive. Also pasted below is some of the raw data.
>> ? 
>> ? An LRT comparing this model with an additive model (PzAlpha+RMSSD+lnX+Drive+Trial) yields a significant difference.  This suggests that the interactions  PzAlpha x Drive and HRV x Drive are meaningful predictors. 
>> ? 
>> ? We would like to determine whether PzAlpha x Drive or  HRV x Drive is the better predictor of RT.  What is the best way to compare those 2 models?  The measures are scaled and centered.
>> ? 
>> ? Thank you very much.
>> ? 
>> ? Pam Greenwood
>> ? 
>> ? Fixed effects:
>> ?                       Estimate Std. Error         df t value Pr(>|t|)   
>> ? (Intercept)         -1.908e-01  1.368e-01  3.310e+01  -1.395  0.17235   
>> ? PzAlpha             -1.098e-01  6.042e-02  2.339e+02  -1.818  0.07041 . 
>> ? HRV               -1.127e-01  6.402e-02  1.112e+03  -1.760  0.07868 . 
>> ? lnX                  7.921e-02  7.547e-02  1.102e+03   1.050  0.29416   
>> ? Drive                5.382e-02  1.661e-02  1.080e+03   3.241  0.00123 **
>> ? PzAlpha: HRV       -1.586e-01  6.424e-02  7.035e+02  -2.468  0.01382 * 
>> ? PzAlpha:lnX          1.116e-01  7.400e-02  8.456e+02   1.508  0.13199   
>> ? PzAlpha:Drive        4.405e-02  1.730e-02  1.049e+03   2.546  0.01103 * 
>> ? HRV:lnX           -4.723e-02  6.905e-02  1.100e+03  -0.684  0.49407   
>> ? HRV:Drive          3.652e-02  1.747e-02  1.098e+03   2.091  0.03677 * 
>> ? lnX:Drive           -1.275e-02  1.992e-02  1.100e+03  -0.640  0.52217   
>> ? PzAlpha: HRV:lnX    1.473e-02  2.567e-02  8.244e+02   0.574  0.56621   
>> ? PzAlpha: HRV:Drive  3.308e-02  1.878e-02  1.084e+03   1.761  0.07845 . 
>> ? PzAlpha:lnX:Drive   -2.325e-02  2.005e-02  9.166e+02  -1.160  0.24640   
>> ? HRV:lnX:Drive      9.729e-03  1.769e-02  1.097e+03   0.550  0.58247   
>> ? 
>> ? 
>> ?    
>> ?    Pnum
>> ?    Drive        Trial    RT    ACC    FzAlpha    CzAlpha    PzAlpha    FzTheta    CzTheta    PzTheta    MeanPupil    lnX    lnY    MeanRR    
>> ? HRV
>> ? 20    1    1    1480.8931    1    7.9928    10.216    7.6254    3.4916    4.8657    6.4977    4.280969072    -3.208115816    -2.423813328    0.7336          0.074666667
>> ? 20    1    2    1983.254    1    -8.2609    0.62018    0.32812    4.2257    6.0181    6.5564    4.360414101    -1.926558582    -2.364252526    0.7336        0.074666667
>> ? 20    1    3    1588.0317    1    1.2572    5.5394    9.0619    4.322    6.7421    7.2778    4.429370379    -2.510514134    -2.890876402    0.734        0.073333333
>> ? 20    1    4    2600    0    -2.0822    -3.5216    2.597    7.6632    9.4505    9.2404    3.994177574    -2.121340179    -3.875411777    0.7408        0.050666667
>> ? 20    1    5    1268.9969    1    2.463    4.5837    4.0916    3.4363    4.2989    -2.1573    3.927884406    -1.754642861    -2.737213207    0.7516        0.014666667
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 0
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? 
>> ? Editorial Board, NeuroImage
>> ? David King Hall 2052
>> ? George Mason University
>> ? MSN 3F5, 4400 University Drive
>> ? Fairfax, VA 22030-4444
>> ? 
>> ? Ph: 703 993-4268
>> ? fax: 703 993-1359
>> ? email: Pgreenw1 at gmu.edu
>> ? http://psychology.gmu.edu/people/pgreenw1
>> ? 
>> ? 
>> ?    [[alternative HTML version deleted]]
>> ? 
>> ? _______________________________________________
>> ? R-sig-mixed-models at r-project.org mailing list
>> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> -- 
>>                                Emmanuel CURIS
>>                                emmanuel.curis at parisdescartes.fr
>>
>> Page WWW: http://emmanuel.curis.online.fr/index.html
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From dan at danmirman.org  Wed Apr 25 21:08:45 2018
From: dan at danmirman.org (Dan Mirman)
Date: Wed, 25 Apr 2018 14:08:45 -0500
Subject: [R-sig-ME] z-scores and glht
In-Reply-To: <365edcfb-ea6c-4a9a-e04d-6f4182a9c5bd@gmail.com>
References: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
 <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
 <CAHhX7Whk5=y=4DtSVOBBvj+3h4sfvG5nVK-hvQXmB=wQ145LZA@mail.gmail.com>
 <365edcfb-ea6c-4a9a-e04d-6f4182a9c5bd@gmail.com>
Message-ID: <CAGfVdyrbG0AMjCZG5JawzULo0dCR=18GQBrNZpnqPZaqeb=ZhA@mail.gmail.com>

Ben's answer already covered the statistical points, so I'll just clarify
my (perhaps odd) description of the glht() output: it is treating that
ratio as a z-score, which allows easy calculation of a p-value. And my
experience is that this p-value is only slightly different from what you'd
get by treating that ratio as a t-statistic and figuring out the
appropriate df (based on K-R or Satterthwaite approximations), but that's
just my experience based on the kinds of data that I work with.

On Wed, Apr 25, 2018 at 1:53 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>    A little more detail:
>
>  if we take the ratio  R=(estimated coefficient)/(standard error), that
> is not yet either a "Z score" or a "t score".  If we assume the standard
> error is itself estimated without error (i.e. we have an arbitrarily
> large amount of data), then we expect R to be normally distributed and
> we call it a "Z-score".  If we take into account the expected
> uncertainty in the standard error, which in simple cases we can quantify
> by knowing the number of residual degrees of freedom, we expect R to be
> t-distributed with df=(residual degrees of freedom); then we call R a
> "t-score".
>
>   If we are not in a simple case, figuring out the appropriate df can be
> difficult.
>
>   cheers
>    Ben Bolker
>
>
> On 2018-04-25 02:49 PM, Cristiano Alessandro wrote:
> > Hi Dan,
> >
> > thanks for your answer. Sorry about my naive question, from a
> > non-statistician. I still have trouble understanding; you say that
> z-scores
> > are the estimates divided by the SE. Isn't this the definition of a
> > t-statistic under the null hypothesis that the mean is equal to zero?
> >
> > Also, when you say that glht() is side-stepping all of that and just
> using
> > a normal approximation. What does it mean/imply exactly, as far as
> > computing the z-scores (the ones I see in the output of the summary)
> goes?
> >
> > Best
> > Cristiano
> >
> > On Wed, Apr 25, 2018 at 1:25 PM, Dan Mirman <dan at danmirman.org> wrote:
> >
> >> The z-scores are computed by dividing the Estimate by the SE. As for why
> >> these are not t-statistics, the short answer is that the degrees of
> freedom
> >> are not trivial to compute. I believe Doug Bates' response is often
> cited
> >> by way of explanation:
> >> http://stat.ethz.ch/pipermail/r-help/2006-May/094765.html and it is
> >> covered
> >> in the FAQ:
> >> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#
> >> why-doesnt-lme4-display-denominator-degrees-of-
> freedomp-values-what-other-
> >> options-do-i-have
> >> (for more discussion of alternatives see Luke, 2017,
> >> http://link.springer.com/article/10.3758%2Fs13428-016-0809-y).
> >>
> >> glht() is side-stepping all of that and just using a normal
> approximation.
> >> For what it's worth, my own experience is that this approximation is
> only
> >> slightly anti-conservative, so I usually feel comfortable using it.
> >>
> >> Hope that helps,
> >> Dan
> >>
> >> On Wed, Apr 25, 2018 at 12:26 PM, Cristiano Alessandro <
> >> cri.alessandro at gmail.com> wrote:
> >>
> >>> Hi all,
> >>>
> >>> something is wrong with my email, so I am sorry for possible multiple
> >>> postings.
> >>>
> >>> After fitting a model with lme, I run post-hoc tests with glht. The
> >> results
> >>> are repored in the following:
> >>>
> >>>> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> >>>> summary(lev.ph, test=adjusted("bonferroni"))
> >>>
> >>> Simultaneous Tests for General Linear Hypotheses
> >>>
> >>> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
> >>> ~des_days |
> >>>     ratID, method = "ML", na.action = na.omit, control = lCtr)
> >>>
> >>> Linear Hypotheses:
> >>>                                  Estimate   Std. Error  z value
> >>> Pr(>|z|)
> >>> des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
> >>> des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
> >>> des_days48 == 0   2688.4     1078.5        2.493        0.038025 *
> >>>
> >>> I am trying to understand the output values. How are the z-scores
> >> computed?
> >>> If the function uses standard errors, should these be t-statistics (and
> >> not
> >>> z-scores)?
> >>>
> >>> Thanks for your help, and sorry for the naive question.
> >>>
> >>> Best
> >>> Cristiano
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >>
> >> --
> >> -----------------------------------------------------
> >> Dan Mirman
> >> Associate Professor
> >> Department of Psychology
> >> University of Alabama at Birmingham
> >> http://www.danmirman.org
> >> -----------------------------------------------------
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
-----------------------------------------------------
Dan Mirman
Associate Professor
Department of Psychology
University of Alabama at Birmingham
http://www.danmirman.org
-----------------------------------------------------

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Apr 25 21:11:55 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 25 Apr 2018 19:11:55 +0000
Subject: [R-sig-ME] z-scores and glht
In-Reply-To: <32055_1524681290_w3PIYnmH014347_55d1ace8-8400-3689-b0dc-b4979b2a9102@gmail.com>
References: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
 <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
 <32055_1524681290_w3PIYnmH014347_55d1ace8-8400-3689-b0dc-b4979b2a9102@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8367F1840@FHSDB2D11-2.csu.mcmaster.ca>

Hi Ben,

Specifying test="F" in car::linearHypothesis() should allow you to get a Wald F-test of a linear hypothesis (but without the Bonferroni correction, which I suppose could be done manually).

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Wednesday, April 25, 2018 2:35 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] z-scores and glht
> 
> 
>   If someone wanted to work hard enough they could probably work out a
> Satterthwaite approximation for the degrees of freedom of these
> contrasts ... ?
> 
> 
> On 2018-04-25 02:25 PM, Dan Mirman wrote:
> > The z-scores are computed by dividing the Estimate by the SE. As for
> > why these are not t-statistics, the short answer is that the degrees
> > of freedom are not trivial to compute. I believe Doug Bates' response
> > is often cited by way of explanation:
> > http://stat.ethz.ch/pipermail/r-help/2006-May/094765.html and it is
> > covered in the FAQ:
> > http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4
> > -display-denominator-degrees-of-freedomp-values-what-other-options-do-
> > i-have (for more discussion of alternatives see Luke, 2017,
> > http://link.springer.com/article/10.3758%2Fs13428-016-0809-y).
> >
> > glht() is side-stepping all of that and just using a normal
> approximation.
> > For what it's worth, my own experience is that this approximation is
> > only slightly anti-conservative, so I usually feel comfortable using
> it.
> >
> > Hope that helps,
> > Dan
> >
> > On Wed, Apr 25, 2018 at 12:26 PM, Cristiano Alessandro <
> > cri.alessandro at gmail.com> wrote:
> >
> >> Hi all,
> >>
> >> something is wrong with my email, so I am sorry for possible multiple
> >> postings.
> >>
> >> After fitting a model with lme, I run post-hoc tests with glht. The
> >> results are repored in the following:
> >>
> >>> lev.ph <- glht(lev.lm, linfct = ph_conditional); summary(lev.ph,
> >>> test=adjusted("bonferroni"))
> >>
> >> Simultaneous Tests for General Linear Hypotheses
> >>
> >> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
> >> = ~des_days |
> >>     ratID, method = "ML", na.action = na.omit, control = lCtr)
> >>
> >> Linear Hypotheses:
> >>                                  Estimate   Std. Error  z value
> >> Pr(>|z|)
> >> des_days1 == 0     3232.2      443.2         7.294        9.05e-13
> ***
> >> des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
> >> des_days48 == 0   2688.4     1078.5        2.493        0.038025 *
> >>
> >> I am trying to understand the output values. How are the z-scores
> computed?
> >> If the function uses standard errors, should these be t-statistics
> >> (and not z-scores)?
> >>
> >> Thanks for your help, and sorry for the naive question.
> >>
> >> Best
> >> Cristiano
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ieshan at gmail.com  Wed Apr 25 22:11:38 2018
From: ieshan at gmail.com (Dan)
Date: Wed, 25 Apr 2018 16:11:38 -0400
Subject: [R-sig-ME] Specifying Multiple Random Effects in NLME
Message-ID: <CAET4i1f-SH5zA6xcCxNXc091HCk+snMv+rFm0tf995yYukiCOw@mail.gmail.com>

Hi all:

I am curating an off-list thread about specifying multiple random effects
in NLME.

1.  If it's (1|Object) + (1|Object:Coating) that you want then
you should be able to use a nested specification (which nlme *can*
handle relatively easily), i.e. something like

random=a+b+c~1|Object/Coating


Although (Coating|Object) and (1|Object:Coating) both in some sense
represent "interactions" the latter is *much* simpler/more parsimonious.

If you're OK with 1|Object:Coating rather than Coating|Object it
should be *much* faster.  If you don't understand the distinction (which
would be absolutely fine and understandable) can we resume the
discussion on r-sig-mixed-models ... ?
-----------

So:
random=a+b+c~Coating|Object
does not fit.

But:
random=a+b+c~Object/Coating
fits.

Can you better explain the distinction here? I have sometimes used the
1|Object:Coating + 1|Object syntax and sometimes the Coating|Object syntax
in other models. My experience/understanding is that the former syntax with
multiple "within subject" variables produces exactly matching output to the
standard "repeated measures ANOVA" with the lmer assumption of compound
symmetry.

Are there cases where one vs. the other formulation should absolutely be
used? My understanding that for continuous variables, e.g., multiple
measurements across multiple days, Days|Object would be the correct syntax.
But here we're talking about a factor variable.


2.   I'm trying to read the "random" section for nlme right now but it's
kind of making my head explode (and I think there's a typo: " the same
as the order of the order of the elements in the list").  It *sounds*
like (1) explicitly creating an interaction
ObjCoating=interaction(Object,Coating) and (2) using something like

  list(ObjCoating=a~1,Object=b~1,Object=c~1)

should work (grouping factors as names, then [right-hand-side variable
name]~[random effects model], but I'm worried about the phrase "The
order of nesting will be assumed the same as the order of the elements
in the list": what nesting?
-----------

I think that formulation is explicitly in order. I replaced your first
ObjCoating with simply Object, just to test what would happen:

Random effects:
 Formula: a ~ 1 | Object
        a.(Intercept)
StdDev:      1.305816

 Formula: b ~ 1 | Object %in% Object
        b.(Intercept)
StdDev:    0.01576521

 Formula: c ~ 1 | Object %in% Object %in% Object
        c.(Intercept) Residual
StdDev:      2.677883 2.219676

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Wed Apr 25 23:43:08 2018
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 25 Apr 2018 21:43:08 +0000
Subject: [R-sig-ME] z-scores and glht
In-Reply-To: <365edcfb-ea6c-4a9a-e04d-6f4182a9c5bd@gmail.com>
References: <CAHhX7WgRgDAduQbZwZcd1bUR9ErrRUBJKBMRLF9i2v2iZEJ-tA@mail.gmail.com>
 <CAGfVdyrG9dmwkAiq1YMYJGSpX02xfCeFLZQ+Vd6WUDGY5nWPjg@mail.gmail.com>
 <CAHhX7Whk5=y=4DtSVOBBvj+3h4sfvG5nVK-hvQXmB=wQ145LZA@mail.gmail.com>
 <365edcfb-ea6c-4a9a-e04d-6f4182a9c5bd@gmail.com>
Message-ID: <C7E2FB10-339A-491C-901A-F3B48EB51ADE@anu.edu.au>

Working out the appropriate degrees of freedom is worse than difficult, surely.
As the variance estimate is, under the model?s normality assumptions, a linear
combination of chi-squared statistics, the distribution is not a t-distribution.
Approximations are available that provide degrees of freedom for a t-distribution
approximation that, for calculating percentage points that are commonly of
interest, will commonly do the job acceptably well.  The Kenward-Roger
approximation, implemented in the `afex` package, seemed for long time to be
the best of the bunch ? has more recent work may come up with anything better?

An updated Chapter 10 for the third edition of the Maindonald & Braun text
'Data Analysis and Graphics Using R - An Example-Based Approach? has been
posted at:
http://maths-people.anu.edu.au/%7Ejohnm/daagur4/ch10-4ednDraft.pdf<http://maths-people.anu.edu.au/~johnm/daagur4/ch10-4ednDraft.pdf>
(this 4th edition ?draft? may or may not make it into print ? progress on a 4th
has now for some months been stalled at the publisher end of the chain.)

There is an example on page 9 of the pdf (labeled p. 340) that demonstrates
the use of afex::mixed() called with "method=?KR??, to invoke the use of the
Kenward-Roger approximation.

Note also the possibility of using the function lme4::botMer() to obtain simulated
estimates or (with `use.u = TRUE` and type=="semiparametric") a
simulated/bootstrapped mix.


John Maindonald


On 26/04/2018, at 06:53, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:


  A little more detail:

if we take the ratio  R=(estimated coefficient)/(standard error), that
is not yet either a "Z score" or a "t score".  If we assume the standard
error is itself estimated without error (i.e. we have an arbitrarily
large amount of data), then we expect R to be normally distributed and
we call it a "Z-score".  If we take into account the expected
uncertainty in the standard error, which in simple cases we can quantify
by knowing the number of residual degrees of freedom, we expect R to be
t-distributed with df=(residual degrees of freedom); then we call R a
"t-score".

 If we are not in a simple case, figuring out the appropriate df can be
difficult.

 cheers
  Ben Bolker


On 2018-04-25 02:49 PM, Cristiano Alessandro wrote:
Hi Dan,

thanks for your answer. Sorry about my naive question, from a
non-statistician. I still have trouble understanding; you say that z-scores
are the estimates divided by the SE. Isn't this the definition of a
t-statistic under the null hypothesis that the mean is equal to zero?

Also, when you say that glht() is side-stepping all of that and just using
a normal approximation. What does it mean/imply exactly, as far as
computing the z-scores (the ones I see in the output of the summary) goes?

Best
Cristiano

On Wed, Apr 25, 2018 at 1:25 PM, Dan Mirman <dan at danmirman.org<mailto:dan at danmirman.org>> wrote:

The z-scores are computed by dividing the Estimate by the SE. As for why
these are not t-statistics, the short answer is that the degrees of freedom
are not trivial to compute. I believe Doug Bates' response is often cited
by way of explanation:
http://stat.ethz.ch/pipermail/r-help/2006-May/094765.html and it is
covered
in the FAQ:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#
why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-
options-do-i-have
(for more discussion of alternatives see Luke, 2017,
http://link.springer.com/article/10.3758%2Fs13428-016-0809-y).

glht() is side-stepping all of that and just using a normal approximation.
For what it's worth, my own experience is that this approximation is only
slightly anti-conservative, so I usually feel comfortable using it.

Hope that helps,
Dan

On Wed, Apr 25, 2018 at 12:26 PM, Cristiano Alessandro <
cri.alessandro at gmail.com> wrote:

Hi all,

something is wrong with my email, so I am sorry for possible multiple
postings.

After fitting a model with lme, I run post-hoc tests with glht. The
results
are repored in the following:

lev.ph <- glht(lev.lm, linfct = ph_conditional);
summary(lev.ph, test=adjusted("bonferroni"))

Simultaneous Tests for General Linear Hypotheses

Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random =
~des_days |
   ratID, method = "ML", na.action = na.omit, control = lCtr)

Linear Hypotheses:
                                Estimate   Std. Error  z value
Pr(>|z|)
des_days1 == 0     3232.2      443.2         7.294        9.05e-13 ***
des_days14 == 0   3356.1      912.2         3.679        0.000702 ***
des_days48 == 0   2688.4     1078.5        2.493        0.038025 *

I am trying to understand the output values. How are the z-scores
computed?
If the function uses standard errors, should these be t-statistics (and
not
z-scores)?

Thanks for your help, and sorry for the naive question.

Best
Cristiano

       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




--
-----------------------------------------------------
Dan Mirman
Associate Professor
Department of Psychology
University of Alabama at Birmingham
http://www.danmirman.org
-----------------------------------------------------

       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Thu Apr 26 02:17:41 2018
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 25 Apr 2018 19:17:41 -0500
Subject: [R-sig-ME] Convergence problem example
In-Reply-To: <ee8c7336-ddb9-04ed-a166-eff5e809dc1e@gmail.com>
References: <CAErODj-Lx9c7V3Gpg1iN-w6moPcr9h4sH+BvntdgWe4pk+QFOQ@mail.gmail.com>
 <34357487-1e4c-208b-4868-1398483583f7@mpi.nl>
 <ee8c7336-ddb9-04ed-a166-eff5e809dc1e@gmail.com>
Message-ID: <CAErODj8XrpTgC2oAPdHht0TPaP1rYOU8tgVWnhPUHyDurSQ8+w@mail.gmail.com>

Dear Ben

I understand. Help us think of ways we can help you.

I wonder why you don't take the easy route.  Have glmer do the
convergence test. If failed, then change the optimizer to bobyqa, and
IF that silences the convergence warning, report that result? That's
what I'd do, if I knew how :)


Dear everybody else

Lets see if we can help!

Questions/Ideas

1. How often does this come up?

Casual googling indicates the problem was widespread 2 years ago,
maybe not so many posts about it now.

Do you think so?

2.  What do you think about making a survey for lme4 users to find out
how often convergence warnings happen?  We could make a place to
attach files that have code and R objects.

If that survey existed, could we insert its address into the lme4
convergence warning along with instructions on what to do.  I'm
thinking something simple like "Help with diagnostics.  Run this:

saveRDS(the_data_frame, file = "your-last-name-20180425.rds")

and then paste in the trouble-causing function call into the following box...

Some cases have private data, I understand, but I doubt that all of them do.

3. Should we archive & categorize the reproducible examples?

What do you say if we (I) make a GitHub project for convergence
failure examples?  Self contained examples. Maybe the one I had today
is example 1. I suppose we need maybe  20 or 30 more, with a variety
of different warning messages.

I wish I had an example where the convergence diagnostic is correct
and the problem is not solved in a superficial way.  I'd be especially
enthusiastic if Stata or SAS don't notice and report non-converged
results on same model.

I found a post that hits the high points for me:
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
(I wish the author would put his/her name in it!)

pj

On Wed, Apr 25, 2018 at 1:47 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>   Just a quick comment.
>
>   As long-time readers of this forum may know (I think I've said it here
> before), the convergence warnings provided by lme4 are often
> over-sensitive.  They're based on *post hoc* attempts (after the
> nonlinear optimizer thinks it has converged) to evaluate the KKT
> criteria (in this case reducing to zero gradient, negative
> positive-definite Hessian) by computing the finite-difference
> approximations of the gradient and Hessian of the negative
> log-likelihood.  The problem is that this computation is just as subject
> to numeric error as the nonlinear optimization itself, so it doesn't
> work very well. (Some of this is stated in ?lme4::convergence)
>
>   Doug Bates feels that attempts to fix the problem are
> "toast-scraping", i.e. attempts to fix something that was a bad idea in
> the first place (i.e., I/we should throw away the metaphorical burned
> toast and scrap the post-hoc convergence tests, relying on the optimizer
> to tell us if it thinks it has converged successfully). The Catch-22 is
> that (1) I'm afraid to throw a system that might catch a reasonable
> fraction of truly bad convergence cases; (2) I don't want to flip-flop
> (take the tests out, then decide that they were a good idea after all
> and reintroduce them); (3) making an *informed* decision what to do
> (e.g. throwing out the tests or setting a more appropriate threshold)
> would require a lot of work generating test cases -- an in order to get
> a really good handle on the problem, we'd have to generate not just
> "nice" test cases but all kinds of pathological examples where there
> really are convergence problems.
>
>   Besides being hard and tedious, this is time I don't really have.
> Volunteers ... ?
>
>   cheers
>    Ben Bolker
>
> On 2018-04-25 11:12 AM, Phillip Alday wrote:
>> Changing the optimizer seems to address the convergence warnings and has
>> no impact on the other aspects of the fit:
>>
>>> m1 <- update(m1, control=glmerControl(optimizer="bobyqa"))
>>> summary(m1)
>> Generalized linear mixed model fit by maximum likelihood (Adaptive
>>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
>>  Family: binomial  ( logit )
>> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
>>    Data: dairy
>> Control: glmerControl(optimizer = "bobyqa")
>>
>>      AIC      BIC   logLik deviance df.resid
>>   4017.8   4047.9  -2003.9   4007.8     3022
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -1.8136 -0.7652 -0.6479  1.0420  1.6213
>>
>> Random effects:
>>  Groups Name        Variance Std.Dev.
>>  cow    (Intercept) 0.3419   0.5847
>> Number of obs: 3027, groups:  cow, 1575
>>
>> Fixed effects:
>>                   Estimate Std. Error z value Pr(>|z|)
>> (Intercept)       -1.55696    0.43481  -3.581 0.000343 ***
>> lncfs              0.52222    0.10007   5.218  1.8e-07 ***
>> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
>> heiferprimiparous -0.08259    0.09718  -0.850 0.395418
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>             (Intr) lncfs  aiai
>> lncfs       -0.965
>> aiai        -0.193 -0.046
>> heifrprmprs -0.054  0.016 -0.051
>>
>> Phillip
>>
>>
>>
>> On 04/25/2018 04:56 PM, Paul Johnson wrote:
>>> In the book Multilevel and Longitudinal Modeling using Stata,
>>> Rabe-Hesketh and Skrondal have a lot of exercises and over the years
>>> I've been trying to write Stata and R code to demonstrate
>>> similarities/differences.
>>>
>>> I've run into an example where Stata (either with builtin methods or
>>> the addon gllamm) seems to think it gets estimates but lme4
>>> diagnostics say there is a convergence failure.  I want to impose on
>>> you, get your advice about it. We see convergence warnings quite often
>>> with lme4, but they are usually the "rescale your variables" errors,
>>> not as blunt as this.
>>>
>>> The first part retrieves "dairy.dta" from the book website
>>>
>>> library(foreign)
>>> library(lme4)
>>>
>>> fn <- "dairy"
>>> if (!file.exists(paste0(fn, ".dta12"))) {
>>>     download.file(paste0("http://www.stata-press.com/data/mlmus3/", fn, ".dta"),
>>>                   destfile = paste0(fn, ".dta12"))
>>> }
>>>
>>> dairy <- read.dta(paste0(fn, ".dta12"))
>>>
>>> #1
>>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
>>>             family = binomial(link = "logit"), nAGQ = 30,
>>>             data = dairy)
>>> summary(m1)
>>>
>>> From that, I see:
>>>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
>>> +             family = binomial(link = "logit"), nAGQ = 30,
>>> +             data = dairy)
>>> Warning messages:
>>> 1: 'rBind' is deprecated.
>>>  Since R version 3.2.0, base's rbind() should work fine with S4 objects
>>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>   Model failed to converge with max|grad| = 0.00396932 (tol = 0.001,
>>> component 1)
>>>> summary(m1)
>>> Generalized linear mixed model fit by maximum likelihood (Adaptive
>>>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
>>>  Family: binomial  ( logit )
>>> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
>>>    Data: dairy
>>>
>>>      AIC      BIC   logLik deviance df.resid
>>>   4017.8   4047.9  -2003.9   4007.8     3022
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -1.8136 -0.7652 -0.6479  1.0420  1.6213
>>>
>>> Random effects:
>>>  Groups Name        Variance Std.Dev.
>>>  cow    (Intercept) 0.3419   0.5847
>>> Number of obs: 3027, groups:  cow, 1575
>>>
>>> Fixed effects:
>>>                   Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)       -1.55693    0.43481  -3.581 0.000343 ***
>>> lncfs              0.52221    0.10007   5.218 1.81e-07 ***
>>> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
>>> heiferprimiparous -0.08259    0.09718  -0.850 0.395410
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>             (Intr) lncfs  aiai
>>> lncfs       -0.965
>>> aiai        -0.193 -0.046
>>> heifrprmprs -0.054  0.016 -0.051
>>> convergence code: 0
>>> Model failed to converge with max|grad| = 0.00396932 (tol = 0.001, component 1)
>>>
>>>
>>> Stata output for comparison purposes, using gllamm:
>>>
>>> . gllamm fscr lncfs ai heifer, i(cow) link(logit) fam(binom) adapt
>>>
>>> Running adaptive quadrature
>>> Iteration 0:    log likelihood = -2004.6011
>>> Iteration 1:    log likelihood = -2003.9085
>>> Iteration 2:    log likelihood = -2003.9069
>>>
>>>
>>> Adaptive quadrature has converged, running Newton-Raphson
>>> Iteration 0:   log likelihood = -2003.9069
>>> Iteration 1:   log likelihood = -2003.9069
>>> Iteration 2:   log likelihood = -2003.9064
>>> Iteration 3:   log likelihood = -2003.9064
>>>
>>> number of level 1 units = 3027
>>> number of level 2 units = 1575
>>>
>>> Condition Number = 47.123877
>>>
>>> gllamm model
>>>
>>> log likelihood = -2003.9064
>>>
>>> ------------------------------------------------------------------------------
>>>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
>>> -------------+----------------------------------------------------------------
>>>        lncfs |   .5222157   .1000693     5.22   0.000     .3260834     .718348
>>>           ai |  -1.095598   .1234099    -8.88   0.000    -1.337477   -.8537193
>>>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078837
>>>        _cons |  -1.556961   .4348008    -3.58   0.000    -2.409155   -.7047673
>>> ------------------------------------------------------------------------------
>>>
>>>
>>> Variances and covariances of random effects
>>> ------------------------------------------------------------------------------
>>>
>>>
>>> ***level 2 (cow)
>>>
>>>     var(1): .34188062 (.1263136)
>>> ------------------------------------------------------------------------------
>>>
>>>
>>> Using the newer meglm that is provided with Stata
>>>
>>> . meglm fscr lncfs ai heifer || cow: , family(binom) link(logit)
>>>
>>> Fitting fixed-effects model:
>>>
>>> Iteration 0:   log likelihood = -2011.8253
>>> Iteration 1:   log likelihood = -2009.1421
>>> Iteration 2:   log likelihood = -2009.1412
>>> Iteration 3:   log likelihood = -2009.1412
>>>
>>> Refining starting values:
>>>
>>> Grid node 0:   log likelihood = -2015.6021
>>>
>>> Fitting full model:
>>>
>>> Iteration 0:   log likelihood = -2015.6021
>>> Iteration 1:   log likelihood =  -2006.709
>>> Iteration 2:   log likelihood = -2003.9174
>>> Iteration 3:   log likelihood = -2003.9065
>>> Iteration 4:   log likelihood = -2003.9065
>>>
>>> Mixed-effects GLM                               Number of obs     =      3,027
>>> Family:                binomial
>>> Link:                     logit
>>> Group variable:             cow                 Number of groups  =      1,575
>>>
>>>                                                 Obs per group:
>>>                                                               min =          1
>>>                                                               avg =        1.9
>>>                                                               max =          5
>>>
>>> Integration method: mvaghermite                 Integration pts.  =          7
>>>
>>>                                                 Wald chi2(3)      =     103.86
>>> Log likelihood = -2003.9065                     Prob > chi2       =     0.0000
>>> ------------------------------------------------------------------------------
>>>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
>>> -------------+----------------------------------------------------------------
>>>        lncfs |   .5222154   .1000694     5.22   0.000      .326083    .7183479
>>>           ai |  -1.095597   .1234095    -8.88   0.000    -1.337476   -.8537191
>>>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593    .1078836
>>>        _cons |  -1.556961   .4348012    -3.58   0.000    -2.409155   -.7047659
>>> -------------+----------------------------------------------------------------
>>> cow          |
>>>    var(_cons)|   .3418776   .1263105                      .1657237    .7052721
>>> ------------------------------------------------------------------------------
>>> LR test vs. logistic model: chibar2(01) = 10.47       Prob >= chibar2 = 0.0006
>>>
>>>
>>> As far as I can see, parameter estimates are the same. I did not
>>> compare conditional modes.
>>>
>>> If lme4's converge warning is valid, then we have a concrete case
>>> where Stata is reporting the wrong thing.  I can see some upside there
>>> :)
>>>
>>> R details
>>>
>>>> sessionInfo()
>>> R version 3.4.4 (2018-03-15)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 17.10
>>>
>>> Matrix products: default
>>> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
>>> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] lme4_1.1-15    Matrix_1.2-14  foreign_0.8-69
>>>
>>> loaded via a namespace (and not attached):
>>>  [1] minqa_1.2.4     MASS_7.3-49     compiler_3.4.4  tools_3.4.4
>>>  [5] Rcpp_0.12.15    splines_3.4.4   nlme_3.1-137    grid_3.4.4
>>>  [9] nloptr_1.0.4    lattice_0.20-35
>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From mollieebrooks at gmail.com  Thu Apr 26 16:55:05 2018
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Thu, 26 Apr 2018 16:55:05 +0200
Subject: [R-sig-ME] TMB course announcement
Message-ID: <41C33CFD-A84D-4EDF-B8D4-48E9B6EF126B@gmail.com>

Dear mixed modelers,

I just wanted to let you know that there is space available in a course on Template Model Builder (TMB). This could be useful for mixed modelers who need more flexibility. 

The workshop will be held 29-Jun-2018, 09:00 - 17:00 in St. Andrews, Scotland. It is part of the International Statistical Ecology Conference, but you can register for the course even if you aren?t attending the conference. Details can be found on the conference website (http://www.isec2018.org <http://www.isec2018.org/>) under "Workshops" then "Template Model Builder".

The instructors will be: 
Anders Nielsen, Senior Researcher, National Institute of Aquatic Resources, Technical University of Denmark
Andrea Havron, Doctoral Candidate, Statistics, University of Aukland, New Zealand
Mollie Brooks, Research Scientist, National Institute of Aquatic Resources, Technical University of Denmark 

Best,
Mollie
???????????
Mollie E. Brooks, Ph.D.
Research Scientist
National Institute of Aquatic Resources
Technical University of Denmark


	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Thu Apr 26 20:29:35 2018
From: jdpo223 at g.uky.edu (Poe, John)
Date: Thu, 26 Apr 2018 14:29:35 -0400
Subject: [R-sig-ME] Multilevel Modeling Courses in Ann Arbor, Switzerland,
 and Slovenia
Message-ID: <CAFW8BypRaTqA1Vn79HgwJxCzx7j10a51Virp4NqwbY9UHR6_MA@mail.gmail.com>

Hello mixed modelers,

I've noticed people announce their courses on the listserv so I
thought I'd jump in as well.

I'm teaching three courses on multilevel modeling over the summer.
I'll be teaching a week long course on multilevel modeling using R and
Stan in Switzerland -- June 11-15 -- and again in Slovenia -- August
27-31st. You can see the material I'll be covering at the GSERM
website ( http://www.gserm.ch/stgallen/course/basic-and-advanced-multilevel-modeling-with-r-and-stan/
). I draw pretty heavily on statistics, econometrics, and
psychometrics so the material covered is a somewhat unique mix for a
multilevel class. It covers both likelihood and Bayesian approaches.

Additionally, I'm teaching a month long class on advanced multilevel
models -- July 23-August 17-- in Ann Arbor, MI as part of the ICPSR
summer program. You can see my current syllabus at
https://www.icpsr.umich.edu/icpsrweb/sumprog/syllabi/166807

Comments on the material that I plan to cover are STRONGLY encouraged!

-- 




Thanks,
John


John Poe, Ph.D.
Postdoctoral Scholar / Research Methodologist
Center for Public Health Services & Systems Research
University of Kentucky
www.johndavidpoe.com


From jorgeavec at gmail.com  Thu Apr 26 22:48:19 2018
From: jorgeavec at gmail.com (=?UTF-8?Q?Jorge_Enrique_Avenda=C3=B1o?=)
Date: Thu, 26 Apr 2018 15:48:19 -0500
Subject: [R-sig-ME] Question on fitting linear mixed model
Message-ID: <CA+-BVrCh1K5yUaOwLB=Wffs2ug381-9n4hh6gX6F-=2YWviwqg@mail.gmail.com>

 Hi all,

I am new with mixed models and would like to ask your advice respect to a
model I am trying to implement in lme4.

Brifely, I want to test the effect of 5 plumage treatments in the
aggression response of 13 birds (territorial males of the same species
selected randomly from a population).

All 13 males were tested against my five plumage treatments. So, I have
only one observation (response) of every individual per treatment. So, I
tried to run the following model:
model = lmer(Aggresion ~ Treatment + (1|Individual_ID), data=data)

Then, I obtained this message: Error: number of levels of each grouping
factor must be < number of observations

One colleague told me that this model does not work because I only have one
observation/response of every individual per treatment, whereas the number
of treatments are five. Moreover, my model should not be nested because
individuals were tested across all five treatments, instead of being
distributed or restricted to particular treatments.

I would like to include in my model the Individual ID because some
individuals were more aggresive than others, and more importantly I want to
know if one plumage treatment elicited more aggression than others. I
understand that Individual ID is a random factor. However, I don't know
what kind of mixed model I am facing.

I would be very glad if you could help me with this issue.
My best,
Jorge


-- 
Jorge Enrique Avenda?o., M.Sc.
Estudiante de Doctorado
Laboratorio de Biolog?a Evolutiva de Vertebrados
Departamento de Ciencias Biol?gicas
Universidad de los Andes, Bogot?, Colombia.
Tel: +571 3394949 ext. 3755

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Thu Apr 26 23:13:32 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 26 Apr 2018 21:13:32 +0000
Subject: [R-sig-ME] Convergence problem example
In-Reply-To: <23743_1524682044_0P7R001TY86ZDE20_ee8c7336-ddb9-04ed-a166-eff5e809dc1e@gmail.com>
References: <CAErODj-Lx9c7V3Gpg1iN-w6moPcr9h4sH+BvntdgWe4pk+QFOQ@mail.gmail.com>
 <34357487-1e4c-208b-4868-1398483583f7@mpi.nl>
 <23743_1524682044_0P7R001TY86ZDE20_ee8c7336-ddb9-04ed-a166-eff5e809dc1e@gmail.com>
Message-ID: <CAO7JsnSTnUxHjb83pXM7LZ_8xoOW2vd8d=miJ=_Yd7=bCis_bg@mail.gmail.com>

Let me expand a bit on what Ben says here.

On Wed, Apr 25, 2018 at 1:47 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>   Just a quick comment.
>
>   As long-time readers of this forum may know (I think I've said it here
> before), the convergence warnings provided by lme4 are often
> over-sensitive.  They're based on *post hoc* attempts (after the
> nonlinear optimizer thinks it has converged) to evaluate the KKT
> criteria (in this case reducing to zero gradient, negative
> positive-definite Hessian) by computing the finite-difference
> approximations of the gradient and Hessian of the negative
> log-likelihood.  The problem is that this computation is just as subject
> to numeric error as the nonlinear optimization itself, so it doesn't
> work very well. (Some of this is stated in ?lme4::convergence)
>
>   Doug Bates feels that attempts to fix the problem are
> "toast-scraping", i.e. attempts to fix something that was a bad idea in
> the first place (i.e., I/we should throw away the metaphorical burned
> toast and scrap the post-hoc convergence tests, relying on the optimizer
> to tell us if it thinks it has converged successfully). The Catch-22 is
> that (1) I'm afraid to throw a system that might catch a reasonable
> fraction of truly bad convergence cases; (2) I don't want to flip-flop
> (take the tests out, then decide that they were a good idea after all
> and reintroduce them); (3) making an *informed* decision what to do
> (e.g. throwing out the tests or setting a more appropriate threshold)
> would require a lot of work generating test cases -- an in order to get
> a really good handle on the problem, we'd have to generate not just
> "nice" test cases but all kinds of pathological examples where there
> really are convergence problems.
>

The "toast-scaping" is a reference Ed Deming's comments about trying to do
quality control by inspection after the fact.  He said this was a case of
"burning the toast and then scraping it" when the better course was not to
burn the toast in the first place.

Determining  ML or REML estimates for linear mixed-effects models can be a
difficult optimization problem.  The way we formulate it in lme4 is as a
constrained optimization problem but with rather simple constraints.  Some
of the components of the parameter vector must be non-negative. Sometimes
the problem can be very simple - optimize with respect to a single
parameter - and sometimes it can be relatively difficult.  Some algorithms
may work well on one type of problem and others work well on a different
problem.  My recent experience is that the NLopt (
https://nlopt.readthedocs.io/) implementation of the BOBYQA (Bounded
Optimization BY Quadratic Approximation) algorithm is both reliable and
fast.  It is available through the nloptr package for R.  In the Julia code
I use the NLopt.jl package (https://github.com/JuliaOpt/NLopt.jl).  I
haven't run into a case where another algorithm or implementation has
converged to a (substantially) better optimum than does this one.  (That
is, there may be a slightly better optimum from another algorithm but the
differences are negligible.)

My recommendation is to change the default algorithm to the nloptr
implementation of BOBYQA and drop the attempts to check convergence.  Some
of the problems with the convergence checks are:

- The conditions like the gradient being zero don't apply when convergence
is on the boundary

- The calculations are based on finite-difference derivatives and (I think)
finite differences of finite differences.  These are notoriously inaccurate.

- In any floating point calculation you can't expect an exact answer so
then you need to decide when you are close enough to, say, a gradient of
zero. This can be very difficult to determine.

The optimization for GLMMs can be even more difficult because, in the
second stage at least, the fixed-effects parameters are part of the general
optimization and the objective (deviance) function doesn't have a closed
form expression.  For some cases we can use adaptive Gauss-Hermite
quadrature, in other cases we use the Laplace approximation.   I was
responsible for the two-stage approach of doing an initial, fast,
optimization where the fixed-effects parameters were optimized in the PIRLS
(penalized iteratively reweighted least squares) evaluation followed by the
second, slower optimization with the fixed-effects parameters in the
general optimization.  The first stage may not even be necessary.  However,
I think that this again is a case where the optimization code - for both
stages - should default to the NLopt implementation of BOBYQA.

I would be quite happy to participate in studying different approaches to
the optimization using data sets from the literature and contributed data
and models.  I have started something like this in the benchmark section of
the MixedModels package for Julia.  At present it is just checking the
execution time for about 50 different linear mixed model fits but the code
could reasonably be modified to try different optimization methods and to
test GLMMs as well.  I realize that most readers of this list would want to
work in R but there are definite advantages in a Julia implementation.  For
one thing MixedModels is written completely in Julia whereas lme4 is an
exotic mixture of languages with all the delightful interfaces between
languages and packages.


  Besides being hard and tedious, this is time I don't really have.
> Volunteers ... ?
>
>   cheers
>    Ben Bolker
>
> On 2018-04-25 11:12 AM, Phillip Alday wrote:
> > Changing the optimizer seems to address the convergence warnings and has
> > no impact on the other aspects of the fit:
> >
> >> m1 <- update(m1, control=glmerControl(optimizer="bobyqa"))
> >> summary(m1)
> > Generalized linear mixed model fit by maximum likelihood (Adaptive
> >   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
> >  Family: binomial  ( logit )
> > Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
> >    Data: dairy
> > Control: glmerControl(optimizer = "bobyqa")
> >
> >      AIC      BIC   logLik deviance df.resid
> >   4017.8   4047.9  -2003.9   4007.8     3022
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -1.8136 -0.7652 -0.6479  1.0420  1.6213
> >
> > Random effects:
> >  Groups Name        Variance Std.Dev.
> >  cow    (Intercept) 0.3419   0.5847
> > Number of obs: 3027, groups:  cow, 1575
> >
> > Fixed effects:
> >                   Estimate Std. Error z value Pr(>|z|)
> > (Intercept)       -1.55696    0.43481  -3.581 0.000343 ***
> > lncfs              0.52222    0.10007   5.218  1.8e-07 ***
> > aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
> > heiferprimiparous -0.08259    0.09718  -0.850 0.395418
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >             (Intr) lncfs  aiai
> > lncfs       -0.965
> > aiai        -0.193 -0.046
> > heifrprmprs -0.054  0.016 -0.051
> >
> > Phillip
> >
> >
> >
> > On 04/25/2018 04:56 PM, Paul Johnson wrote:
> >> In the book Multilevel and Longitudinal Modeling using Stata,
> >> Rabe-Hesketh and Skrondal have a lot of exercises and over the years
> >> I've been trying to write Stata and R code to demonstrate
> >> similarities/differences.
> >>
> >> I've run into an example where Stata (either with builtin methods or
> >> the addon gllamm) seems to think it gets estimates but lme4
> >> diagnostics say there is a convergence failure.  I want to impose on
> >> you, get your advice about it. We see convergence warnings quite often
> >> with lme4, but they are usually the "rescale your variables" errors,
> >> not as blunt as this.
> >>
> >> The first part retrieves "dairy.dta" from the book website
> >>
> >> library(foreign)
> >> library(lme4)
> >>
> >> fn <- "dairy"
> >> if (!file.exists(paste0(fn, ".dta12"))) {
> >>     download.file(paste0("http://www.stata-press.com/data/mlmus3/",
> fn, ".dta"),
> >>                   destfile = paste0(fn, ".dta12"))
> >> }
> >>
> >> dairy <- read.dta(paste0(fn, ".dta12"))
> >>
> >> #1
> >> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
> >>             family = binomial(link = "logit"), nAGQ = 30,
> >>             data = dairy)
> >> summary(m1)
> >>
> >> From that, I see:
> >>> m1 <- glmer(fscr ~ lncfs + ai + heifer + (1 | cow),
> >> +             family = binomial(link = "logit"), nAGQ = 30,
> >> +             data = dairy)
> >> Warning messages:
> >> 1: 'rBind' is deprecated.
> >>  Since R version 3.2.0, base's rbind() should work fine with S4 objects
> >> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  :
> >>   Model failed to converge with max|grad| = 0.00396932 (tol = 0.001,
> >> component 1)
> >>> summary(m1)
> >> Generalized linear mixed model fit by maximum likelihood (Adaptive
> >>   Gauss-Hermite Quadrature, nAGQ = 30) [glmerMod]
> >>  Family: binomial  ( logit )
> >> Formula: fscr ~ lncfs + ai + heifer + (1 | cow)
> >>    Data: dairy
> >>
> >>      AIC      BIC   logLik deviance df.resid
> >>   4017.8   4047.9  -2003.9   4007.8     3022
> >>
> >> Scaled residuals:
> >>     Min      1Q  Median      3Q     Max
> >> -1.8136 -0.7652 -0.6479  1.0420  1.6213
> >>
> >> Random effects:
> >>  Groups Name        Variance Std.Dev.
> >>  cow    (Intercept) 0.3419   0.5847
> >> Number of obs: 3027, groups:  cow, 1575
> >>
> >> Fixed effects:
> >>                   Estimate Std. Error z value Pr(>|z|)
> >> (Intercept)       -1.55693    0.43481  -3.581 0.000343 ***
> >> lncfs              0.52221    0.10007   5.218 1.81e-07 ***
> >> aiai              -1.09560    0.12341  -8.878  < 2e-16 ***
> >> heiferprimiparous -0.08259    0.09718  -0.850 0.395410
> >> ---
> >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >> Correlation of Fixed Effects:
> >>             (Intr) lncfs  aiai
> >> lncfs       -0.965
> >> aiai        -0.193 -0.046
> >> heifrprmprs -0.054  0.016 -0.051
> >> convergence code: 0
> >> Model failed to converge with max|grad| = 0.00396932 (tol = 0.001,
> component 1)
> >>
> >>
> >> Stata output for comparison purposes, using gllamm:
> >>
> >> . gllamm fscr lncfs ai heifer, i(cow) link(logit) fam(binom) adapt
> >>
> >> Running adaptive quadrature
> >> Iteration 0:    log likelihood = -2004.6011
> >> Iteration 1:    log likelihood = -2003.9085
> >> Iteration 2:    log likelihood = -2003.9069
> >>
> >>
> >> Adaptive quadrature has converged, running Newton-Raphson
> >> Iteration 0:   log likelihood = -2003.9069
> >> Iteration 1:   log likelihood = -2003.9069
> >> Iteration 2:   log likelihood = -2003.9064
> >> Iteration 3:   log likelihood = -2003.9064
> >>
> >> number of level 1 units = 3027
> >> number of level 2 units = 1575
> >>
> >> Condition Number = 47.123877
> >>
> >> gllamm model
> >>
> >> log likelihood = -2003.9064
> >>
> >>
> ------------------------------------------------------------------------------
> >>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf.
> Interval]
> >>
> -------------+----------------------------------------------------------------
> >>        lncfs |   .5222157   .1000693     5.22   0.000     .3260834
>  .718348
> >>           ai |  -1.095598   .1234099    -8.88   0.000    -1.337477
>  -.8537193
> >>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593
> .1078837
> >>        _cons |  -1.556961   .4348008    -3.58   0.000    -2.409155
>  -.7047673
> >>
> ------------------------------------------------------------------------------
> >>
> >>
> >> Variances and covariances of random effects
> >>
> ------------------------------------------------------------------------------
> >>
> >>
> >> ***level 2 (cow)
> >>
> >>     var(1): .34188062 (.1263136)
> >>
> ------------------------------------------------------------------------------
> >>
> >>
> >> Using the newer meglm that is provided with Stata
> >>
> >> . meglm fscr lncfs ai heifer || cow: , family(binom) link(logit)
> >>
> >> Fitting fixed-effects model:
> >>
> >> Iteration 0:   log likelihood = -2011.8253
> >> Iteration 1:   log likelihood = -2009.1421
> >> Iteration 2:   log likelihood = -2009.1412
> >> Iteration 3:   log likelihood = -2009.1412
> >>
> >> Refining starting values:
> >>
> >> Grid node 0:   log likelihood = -2015.6021
> >>
> >> Fitting full model:
> >>
> >> Iteration 0:   log likelihood = -2015.6021
> >> Iteration 1:   log likelihood =  -2006.709
> >> Iteration 2:   log likelihood = -2003.9174
> >> Iteration 3:   log likelihood = -2003.9065
> >> Iteration 4:   log likelihood = -2003.9065
> >>
> >> Mixed-effects GLM                               Number of obs     =
>   3,027
> >> Family:                binomial
> >> Link:                     logit
> >> Group variable:             cow                 Number of groups  =
>   1,575
> >>
> >>                                                 Obs per group:
> >>                                                               min =
>       1
> >>                                                               avg =
>     1.9
> >>                                                               max =
>       5
> >>
> >> Integration method: mvaghermite                 Integration pts.  =
>       7
> >>
> >>                                                 Wald chi2(3)      =
>  103.86
> >> Log likelihood = -2003.9065                     Prob > chi2       =
>  0.0000
> >>
> ------------------------------------------------------------------------------
> >>         fscr |      Coef.   Std. Err.      z    P>|z|     [95% Conf.
> Interval]
> >>
> -------------+----------------------------------------------------------------
> >>        lncfs |   .5222154   .1000694     5.22   0.000      .326083
> .7183479
> >>           ai |  -1.095597   .1234095    -8.88   0.000    -1.337476
>  -.8537191
> >>       heifer |  -.0825878   .0971811    -0.85   0.395    -.2730593
> .1078836
> >>        _cons |  -1.556961   .4348012    -3.58   0.000    -2.409155
>  -.7047659
> >>
> -------------+----------------------------------------------------------------
> >> cow          |
> >>    var(_cons)|   .3418776   .1263105                      .1657237
> .7052721
> >>
> ------------------------------------------------------------------------------
> >> LR test vs. logistic model: chibar2(01) = 10.47       Prob >= chibar2 =
> 0.0006
> >>
> >>
> >> As far as I can see, parameter estimates are the same. I did not
> >> compare conditional modes.
> >>
> >> If lme4's converge warning is valid, then we have a concrete case
> >> where Stata is reporting the wrong thing.  I can see some upside there
> >> :)
> >>
> >> R details
> >>
> >>> sessionInfo()
> >> R version 3.4.4 (2018-03-15)
> >> Platform: x86_64-pc-linux-gnu (64-bit)
> >> Running under: Ubuntu 17.10
> >>
> >> Matrix products: default
> >> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
> >> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
> >>
> >> locale:
> >>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >> other attached packages:
> >> [1] lme4_1.1-15    Matrix_1.2-14  foreign_0.8-69
> >>
> >> loaded via a namespace (and not attached):
> >>  [1] minqa_1.2.4     MASS_7.3-49     compiler_3.4.4  tools_3.4.4
> >>  [5] Rcpp_0.12.15    splines_3.4.4   nlme_3.1-137    grid_3.4.4
> >>  [9] nloptr_1.0.4    lattice_0.20-35
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From dalal.e.hanna at gmail.com  Fri Apr 27 00:45:29 2018
From: dalal.e.hanna at gmail.com (Dalal Hanna)
Date: Thu, 26 Apr 2018 18:45:29 -0400
Subject: [R-sig-ME] Concern/question regarding discrepancy between glmmADBM
 summary output and glht comparisons output
Message-ID: <CAA3K1KyvOmj4uQzqMYCG7p-XR1dpvtLar+tkUg60ztYRhz9niw@mail.gmail.com>

Hello,

I am new to this mailing list and also to glmms.
I am writing concerning a discrepancy I observed between glmmADMB summary
output and and glht comparisons which made me want to enquire about the
"best" way to proceed for an analysis.

As in this thread
<https://stats.stackexchange.com/questions/230734/post-hoc-output-and-glmm-output-dont-add-up>
 I'm observing different results between a negative binomial glmm summary
model output and glht  post-hoc comparisons.  I have pasted reproducible
code below.
I did a little digging online, and found this
<https://www.researchgate.net/post/Multiple_comparisons_in_GLMMs>post
<https://www.researchgate.net/post/Multiple_comparisons_in_GLMMs> which
lead me to believe this has to do with multiplicity. (When I use an
unadjusted test, as the answer in the post suggests, I find the same results
as in the model summary).
Still, I find myself wondering if in general its better to use the glht
function that corrects for multiple comparisons (and doesn't match up with
the model outputs), or if I should use the glht function that doesn't correct
for multiple comparisons.
Based on some posts (example
<https://stats.stackexchange.com/questions/204741/which-multiple-comparison-method-to-use-for-a-lmer-model-lsmeans-or-glht>)
I've read I suspect that its 'better' to correct for multiple comparisons
to avoid Type 1 error, but I am not sure about this given the mismatch with
the model output and wanted to ask before moving forward.
I have not encountered this problem before as I have only previously used a
model selection approach with linear mixed models, and did not have to
think about p-values and post-hoc analyses for mixed models.

Thank you for your time, I really appreciate any help/clarifications on
this topic.
Dalal Hanna


###Reproducible example####
#Generate dataframe
RecreationalTrails<-c(5, 0, 0, 4, 7, 0, 0, 0, 6, 5, 0, 6, 6, 0, 0, 0, 0, 0,
0, 0, 0, 0,4, 6, 8, 0, 0, 7)
LandUse<-c("Protected", "Agricultural", "Forestry", "Unprotected Forest",
"Protected", "Agricultural", "Forestry", "Unprotected Forest",
           "Protected", "Agricultural", "Forestry", "Unprotected
Forest","Protected", "Agricultural", "Forestry", "Unprotected Forest",
           "Protected", "Agricultural", "Forestry", "Unprotected
Forest","Protected", "Agricultural", "Forestry", "Unprotected Forest",
           "Protected", "Agricultural", "Forestry", "Unprotected Forest")
Parc<-c("Monts Valin", "Monts Valin", "Monts Valin", "Monts Valin", "Fjords
du Saguenay", "Fjords du Saguenay","Fjords du Saguenay",
        "Fjords du Saguenay", "Hautes Gorges",  "Hautes Gorges","Hautes
Gorges","Hautes Gorges",  "Grands Jardins",    "Grands Jardins",
        "Grands Jardins", "Grands Jardins", "Mont Tremblant",  "Mont
Tremblant", "Mont Tremblant", "Mont Tremblant",  "Mauricie",
        "Mauricie",  "Mauricie",  "Mauricie", "Jacques Cartier",
"Jacques Cartier", "Jacques Cartier", "Jacques Cartier")

ESCombinedDataRE<-data.frame(c("LandUse", "Parc", "RecreationalTrails"))
ESCombinedDataRE <- data.frame(LandUse, Parc, RecreationalTrails)
names(ESCombinedDataRE) <- c("LandUse", "Parc", "RecreationalTrails")
ESCombinedDataRE$LandUse <- factor(ESCombinedDataRE$LandUse,
levels=c("Protected", "Unprotected Forest", "Forestry", "Agricultural"))

ESCombinedDataRE
str(ESCombinedDataRE)

#Run model
library(glmmADMB)
R_glmer <- glmmadmb(RecreationalTrails ~ LandUse+ (1|Parc),
data=ESCombinedDataRE, family= "nbinom")

#Validate model
#homogeneity
ResidR<-resid(R_glmer)
qqnorm(ResidR)
qqline(ResidR, col=2)
#Note that I am not certain that this model actually meets its assumptions.
I see here that there is
#likely a problem of homogeneity, but am not sure what alternative model I
could run for this dataset, suggestions most welcome.

#Model results
summary(R_glmer)
#Post-hoc comparisons
summary(glht(R_glmer, linfct=mcp(LandUse="Tukey")))

#Alternative post-hoc comparison without adjusted test
mc_RT <- glht(R_glmer, linfct=mcp(LandUse="Tukey"))
summary(mc_RT, test=adjusted("none"))

	[[alternative HTML version deleted]]


From vicrotas at gmail.com  Fri Apr 27 01:45:28 2018
From: vicrotas at gmail.com (Victoria Ortiz)
Date: Thu, 26 Apr 2018 20:45:28 -0300
Subject: [R-sig-ME] Question about continuous distributions in GLMM
In-Reply-To: <CAEpo04=QK+9yWW4_n669rYtCLiOxGBxk=V6mnTa9PNgfvK3D6Q@mail.gmail.com>
References: <CAEpo04=QK+9yWW4_n669rYtCLiOxGBxk=V6mnTa9PNgfvK3D6Q@mail.gmail.com>
Message-ID: <CAEpo04k1UdkK2TWPByX7OnkRmXWbdECMjkKeFysz6gKYPACCKg@mail.gmail.com>

I write to ask a simple question about quantitative continuous variables
distributions. We have data for morphological traits in insects but they do
not fit any distribution in GLMM. The design has two fixed variables and a
random one. We are interested in the variance components of the random
variable and its interactions. We tried normal (lm4), gamma (glmer),
lognormal (GLMMPQL), tweedie (GLMMTMB) and compound poison (CPLM). There is
no good fit for any case. In fact, the better model using AIC is normal. The
residuals vs. predicted graphic and the Q-Q plot have the following
form: *https://github.com/vicrotas/Repositorio-de-Vicka/issues/1
<https://github.com/vicrotas/Repositorio-de-Vicka/issues/1>*



Given that the fit to normal distribution is not good, we want to know if
there is any other distribution we could try. What else we can do in this
scenario?



On the other hand, to estimate the variance components we used the
following in lmer:



m1 <- lmer ( variable ~ fixed factor  1 * fixed factor 2 + (fixed factor 1
* fixed factor 2 | | random factor))



The specific question is if the double bar ('| |') is a good way to
estimate the variance components or if there is another way to do it?



Thanks in advance!

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Apr 27 22:08:00 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 27 Apr 2018 16:08:00 -0400
Subject: [R-sig-ME] Question about continuous distributions in GLMM
In-Reply-To: <CAEpo04k1UdkK2TWPByX7OnkRmXWbdECMjkKeFysz6gKYPACCKg@mail.gmail.com>
References: <CAEpo04=QK+9yWW4_n669rYtCLiOxGBxk=V6mnTa9PNgfvK3D6Q@mail.gmail.com>
 <CAEpo04k1UdkK2TWPByX7OnkRmXWbdECMjkKeFysz6gKYPACCKg@mail.gmail.com>
Message-ID: <44db0ee5-ef31-0a7c-0389-a21c7ba44881@gmail.com>



On 2018-04-26 07:45 PM, Victoria Ortiz wrote:
> I write to ask a simple question about quantitative continuous variables
> distributions. We have data for morphological traits in insects but they do
> not fit any distribution in GLMM. The design has two fixed variables and a
> random one. We are interested in the variance components of the random
> variable and its interactions. We tried normal (lm4), gamma (glmer),
> lognormal (GLMMPQL), tweedie (GLMMTMB) and compound poison (CPLM). There is
> no good fit for any case. In fact, the better model using AIC is normal. The
> residuals vs. predicted graphic and the Q-Q plot have the following
> form: *https://github.com/vicrotas/Repositorio-de-Vicka/issues/1
> <https://github.com/vicrotas/Repositorio-de-Vicka/issues/1>*
> 


  I'm not quite sure what to suggest about the distribution.  Since this
looks left-skewed, you might try a power transformation with g > 1 (e.g.
x^1.5) to shift it.  (That would be applied to the data rather than the
residuals, so might not work perfectly ...) For a rough idea, you could
run a Box-Cox analysis on the residuals.

  Alternatively, if you can figure out a permutation approach that works
(e.g. permutation within and between groups) that could give you a
distribution-robust way to get a p-value.

> 
> 
> Given that the fit to normal distribution is not good, we want to know if
> there is any other distribution we could try. What else we can do in this
> scenario?
> 
> 
> 
> On the other hand, to estimate the variance components we used the
> following in lmer:
> 
> 
> 
> m1 <- lmer ( variable ~ fixed factor  1 * fixed factor 2 + (fixed factor 1
> * fixed factor 2 || random factor))
> 
> 
> 
> The specific question is if the double bar ('| |') is a good way to
> estimate the variance components or if there is another way to do it?

  Can you clarify what you mean by "variance components"? Are you
explicitly trying to partition variance, or are you just trying to make
sure that you control for among-group variation?

  If your data will support it, I think it would be better to fit the
unstructured variance-covariance matrix; if not, you could try one of
the Bayesian methods (blme, MCMCglmm, brms, rstanarm ...) that would
allow you to regularize/put a prior on the variance-covariance matrix.


> 
> 
> 
> Thanks in advance!
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From n.flaiba at hotmail.com  Fri Apr 27 22:33:28 2018
From: n.flaiba at hotmail.com (Nicolas Flaibani)
Date: Fri, 27 Apr 2018 20:33:28 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
Message-ID: <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>


 Hi everyone!


I would like to join the discussion of the second topic (Specifying Multiple Random Effects in NLME by Dan) but in my case I?m going to talk about the lme4 package, instead of the nmle. I think that the question is still relevant.

I?ve had a doubt for a long time about how to investigate the interactions between random and fixed effects. I?ve read a lot of forums, papers and help?s packages and I?ve always concluded that the correct form of testing the interaction between a random and a fixed variable was:


Model1 <- lmer (Y ~ X1 + X2 + (X1 | Random Variable)


However, I found in some forums and personal communications from several researchers that there is another way to investigate the interaction between random and fixed variables and has the following syntax:


Model2 <- lmer (Y ~ X1 + X2 + (1 | Random Variable: X1)


I understand that this syntax


(1|Random Variable/X1) = (1|Random Variable)+(1|Random Variable:X1)


specify a nested structure between the variables and this is not the case of interest.

My particular question is whether the syntax of the Model 2 is correct to test interactions between random and fixed variables. If this model is correct, which are the differences with the syntax of Model 1, since the resulting models are clearly different? Besides, in coincidence with the question of Dan (?Are there cases where one vs. the other formulation should absolutely be used? My understanding that for continuous variables, e.g., multiple measurements across multiple days, Days|Object would be the correct syntax. But here we're talking about a factor variable?), I ask if one type of syntax should be used if the fixed variables are continuous or there are factors.

If I compare the summary from a model with the latter syntax (model 2), with the summary of the same analysis made with a statistic program (like Statistica), the results are very similar. That?s not the case with the model 1.

For example, if I analyze a morphological trait with the syntax


M2 <- lmer (Wing ~ Temperature * Sex + Temperature + Sex + (1 | Line) +   (1 | Line:Sex:Temperature) + (1 | Line:Sex) + (1 | Line:Temperature))


the summary is the following:


Random effects:

 Groups                               Name        Variance Std.Dev.

 Line:Sex:Temperature  (Intercept)  14.6231  3.8240

 Line:Temperature          (Intercept) 154.7685 12.4406

 Line:Sex                         (Intercept)   0.6947  0.8335

 Line                                 (Intercept)  72.5945  8.5202

 Residual                                             180.0664 13.4189


Fixed effects:

                    Estimate Std. Error      df t value                         Pr(>|t|)

(Intercept)                  501.141      2.268  96.940 221.009       < 2e-16 ***

Temperature25        -57.960      2.699  54.800 -21.473         < 2e-16 ***

SexM                         -53.639      1.001  96.260 -53.584         < 2e-16 ***

Temperature25:SexM   -6.488      1.391  48.300          -4.663 2.49e-05 ***


I found that the function rand() from the lmerTest package gives me the p values of the random effects if I write the model like this:

> rand(M2)

Analysis of Random effects Table:


                         Chi.sq Chi.DF p.value

Line                    4.6152      1    0.03 *

Line:Sex:Temperature  30.8130      1   3e-08 ***

Line:Sex                             0.0391      1    0.84

Line:Temperature          112.1539      1  <2e-16 ***


I don?t know if this function is reliable because it is not mentioned for testing the significance of the random effects in the page https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html

The summary of the same analysis made with the Statistica is:




Effect

SS

Degr. of

MS

Den.Syn.

Den.Syn.

F

p

Intercept

Fixed

764579151

1

764579151

48,001

12655,91

60412,83

0,000000

Line

Random

608181

48

12670

47,800

6489,64

1,95

0,011254

Sex

Fixed

3138661

1

3138661

48,038

495,62

6332,81

0,000000

Temperature

Fixed

3686660

1

3686660

48,003

6459,62

570,72

0,000000

Line*Sex

Random

23808

48

496

48,000

473,30

1,05

0,435866

Line*Temperature

Random

310413

48

6467

48,000

473,30

13,66

0,000000

Sex*Temperature

Fixed

10075

1

10075

48,040

472,94

21,30

0,000029

Line*Sex*Temperature

Random

22718

48

473

3696,000

167,33

2,83

0,000000

Error

618467

3696

167




But if I write the model with the other syntax:

M1 <- lmer(Wing ~ Temperature * Sex + (Temperature * Sex | Line))



the summary is the following:



REML criterion at convergence: 31440.9



Random effects:

 Groups   Name                Variance Std.Dev. Corr

 Line    (Intercept)           266.78   16.333

  Temperature25             398.27   19.957   -0.60

   SexM                                41.54    6.446   -0.56  0.46

  Temperature25:SexM  61.34    7.832    0.56 -0.61 -0.80

 Residual                             167.33   12.936



Fixed effects:

                                             Estimate Std. Error         df t value             Pr(>|t|)

(Intercept)                          501.603      2.371            48.046 211.586  < 2e-16 ***

Temperature25               -58.423      2.911               48.027 -20.070  < 2e-16 ***

SexM                                 -53.659      1.095              47.964 -49.023  < 2e-16 ***

Temperature                    25:SexM   -6.470               1.393  48.278  -4.644 2.66e-05 ***

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



In addition, if I apply the ?rand function? for this syntax (M1), it doesn?t retourn the whole p-values of the random effects (Do not give me p value for line and line*Temperature*Sex)

Analysis of Random effects Table:

                                             Chi.sq Chi.DF p.value

Temperatura:L?nea 0.00e+00      0       1

Sexo:L?nea             1.46e-10      0  <2e-16 ***


I really appreciate your time and dedication for answering this questions. Thank you for trying to help us understand a little more about the syntax of these complex models and thus better understand their correct approach.

Thank you very much for your time everyone.



Greetings,

Nicolas


----------------------------------------------------------------------------------------
Message: 2
Date: Wed, 25 Apr 2018 16:11:38 -0400
From: Dan <ieshan at gmail.com>
To: "R-SIG-Mixed-Models at R-project.org"
        <R-sig-mixed-models at r-project.org>, Ben Bolker <bbolker at gmail.com>
Subject: [R-sig-ME] Specifying Multiple Random Effects in NLME
Message-ID:
        <CAET4i1f-SH5zA6xcCxNXc091HCk+snMv+rFm0tf995yYukiCOw at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi all:

I am curating an off-list thread about specifying multiple random effects
in NLME.

1.  If it's (1|Object) + (1|Object:Coating) that you want then
you should be able to use a nested specification (which nlme *can*
handle relatively easily), i.e. something like

random=a+b+c~1|Object/Coating


Although (Coating|Object) and (1|Object:Coating) both in some sense
represent "interactions" the latter is *much* simpler/more parsimonious.

If you're OK with 1|Object:Coating rather than Coating|Object it
should be *much* faster.  If you don't understand the distinction (which
would be absolutely fine and understandable) can we resume the
discussion on r-sig-mixed-models ... ?
-----------

So:
random=a+b+c~Coating|Object
does not fit.

But:
random=a+b+c~Object/Coating
fits.

Can you better explain the distinction here? I have sometimes used the
1|Object:Coating + 1|Object syntax and sometimes the Coating|Object syntax
in other models. My experience/understanding is that the former syntax with
multiple "within subject" variables produces exactly matching output to the
standard "repeated measures ANOVA" with the lmer assumption of compound
symmetry.

Are there cases where one vs. the other formulation should absolutely be
used? My understanding that for continuous variables, e.g., multiple
measurements across multiple days, Days|Object would be the correct syntax.
But here we're talking about a factor variable.


2.   I'm trying to read the "random" section for nlme right now but it's
kind of making my head explode (and I think there's a typo: " the same
as the order of the order of the elements in the list").  It *sounds*
like (1) explicitly creating an interaction
ObjCoating=interaction(Object,Coating) and (2) using something like

  list(ObjCoating=a~1,Object=b~1,Object=c~1)

should work (grouping factors as names, then [right-hand-side variable
name]~[random effects model], but I'm worried about the phrase "The
order of nesting will be assumed the same as the order of the elements
in the list": what nesting?
-----------

I think that formulation is explicitly in order. I replaced your first
ObjCoating with simply Object, just to test what would happen:

Random effects:
 Formula: a ~ 1 | Object
        a.(Intercept)
StdDev:      1.305816

 Formula: b ~ 1 | Object %in% Object
        b.(Intercept)
StdDev:    0.01576521

 Formula: c ~ 1 | Object %in% Object %in% Object
        c.(Intercept) Residual
StdDev:      2.677883 2.219676

        [[alternative HTML version deleted]]




*****

	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Sat Apr 28 11:32:58 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Sat, 28 Apr 2018 11:32:58 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
Message-ID: <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>

On 27 April 2018 at 22:33, Nicolas Flaibani <n.flaiba at hotmail.com> wrote:
>
>  Hi everyone!
>
>
> I would like to join the discussion of the second topic (Specifying Multiple Random Effects in NLME by Dan) but in my case I?m going to talk about the lme4 package, instead of the nmle. I think that the question is still relevant.
>
> I?ve had a doubt for a long time about how to investigate the interactions between random and fixed effects. I?ve read a lot of forums, papers and help?s packages and I?ve always concluded that the correct form of testing the interaction between a random and a fixed variable was:
>
>
> Model1 <- lmer (Y ~ X1 + X2 + (X1 | Random Variable)
>
>
> However, I found in some forums and personal communications from several researchers that there is another way to investigate the interaction between random and fixed variables and has the following syntax:
>
>
> Model2 <- lmer (Y ~ X1 + X2 + (1 | Random Variable: X1)
>
The 'classical' (think DOE and 'variance-components') interaction is
Model2 if X1 is categorical/factor and Model1 if X1 is continuous
(then Model1 is sometimes called the 'random coefficient model').

If X1 is continuous Model2 doesn't make sense - on the other hand
Model1 can be fitted if X1 is a factor. In that case Model1 is rather
complex and the number of parameters grows rapidly with the number of
levels of X1 - in comparison the random term in Model2 uses just one
(variance) parameter. While some people often favour 'Model1 with
factor X1'- construction, I often think it is difficult to explain
what this model actually means; it is also very often overfitting
since it requires a lot of data and special data-generating mechanism
to support models of that form.

>
> I understand that this syntax
>
>
> (1|Random Variable/X1) = (1|Random Variable)+(1|Random Variable:X1)
>
>
> specify a nested structure between the variables and this is not the case of interest.

This construction serves two purposes: one is when the random-effect
variables have a 'truly' nested structure such as pupils in classes
(in schools, in districts, etc). The other purpose often applies to
designed experiments where you might have machines (fixed) and
operators (random). The main effects model is then

Model3 <- lmer(Y ~ machines + (1 | operators))

and a model that includes the interaction reads

Model3b <- lmer(Y ~ machines + (1 | operators) + (1 | machines:operators))

Technically the 'machines:operators' combinations are nested in
'operators' but we usually don't think of it that way.

The point here is that we need to also consider Model3b as an
alternative to Model1 and Model2. Of these models, Model3 _and_ Model2
are the simplest while Model1 is the most complex with Model3b in the
middle often serving as an appropriate compromise.

>
> My particular question is whether the syntax of the Model 2 is correct to test interactions between random and fixed variables. If this model is correct, which are the differences with the syntax of Model 1, since the resulting models are clearly different? Besides, in coincidence with the question of Dan (?Are there cases where one vs. the other formulation should absolutely be used? My understanding that for continuous variables, e.g., multiple measurements across multiple days, Days|Object would be the correct syntax. But here we're talking about a factor variable?), I ask if one type of syntax should be used if the fixed variables are continuous or there are factors.
>
> If I compare the summary from a model with the latter syntax (model 2), with the summary of the same analysis made with a statistic program (like Statistica), the results are very similar. That?s not the case with the model 1.
>
> For example, if I analyze a morphological trait with the syntax
>
>
> M2 <- lmer (Wing ~ Temperature * Sex + Temperature + Sex + (1 | Line) +   (1 | Line:Sex:Temperature) + (1 | Line:Sex) + (1 | Line:Temperature))
>
>
> the summary is the following:
>
>
> Random effects:
>
>  Groups                               Name        Variance Std.Dev.
>
>  Line:Sex:Temperature  (Intercept)  14.6231  3.8240
>
>  Line:Temperature          (Intercept) 154.7685 12.4406
>
>  Line:Sex                         (Intercept)   0.6947  0.8335
>
>  Line                                 (Intercept)  72.5945  8.5202
>
>  Residual                                             180.0664 13.4189
>
>
> Fixed effects:
>
>                     Estimate Std. Error      df t value                         Pr(>|t|)
>
> (Intercept)                  501.141      2.268  96.940 221.009       < 2e-16 ***
>
> Temperature25        -57.960      2.699  54.800 -21.473         < 2e-16 ***
>
> SexM                         -53.639      1.001  96.260 -53.584         < 2e-16 ***
>
> Temperature25:SexM   -6.488      1.391  48.300          -4.663 2.49e-05 ***
>
>
> I found that the function rand() from the lmerTest package gives me the p values of the random effects if I write the model like this:
>
>> rand(M2)
>
> Analysis of Random effects Table:
>
>
>                          Chi.sq Chi.DF p.value
>
> Line                    4.6152      1    0.03 *
>
> Line:Sex:Temperature  30.8130      1   3e-08 ***
>
> Line:Sex                             0.0391      1    0.84
>
> Line:Temperature          112.1539      1  <2e-16 ***
>
>
> I don?t know if this function is reliable because it is not mentioned for testing the significance of the random effects in the page https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html

Having written rand (=ranova) my views may be biased but I should say
that it _is_ reliable. That is, I haven't seen cases where it's not
doing what was intended ;-) rand() and ranova() simply compares two
models using anova(m1, m2, refit=FALSE) where m2 differs from m1 by
having one of its random-effect terms reduced or removed.

>
> The summary of the same analysis made with the Statistica is:
>
>
>
>
> Effect
>
> SS
>
> Degr. of
>
> MS
>
> Den.Syn.
>
> Den.Syn.
>
> F
>
> p
>
> Intercept
>
> Fixed
>
> 764579151
>
> 1
>
> 764579151
>
> 48,001
>
> 12655,91
>
> 60412,83
>
> 0,000000
>
> Line
>
> Random
>
> 608181
>
> 48
>
> 12670
>
> 47,800
>
> 6489,64
>
> 1,95
>
> 0,011254
>
> Sex
>
> Fixed
>
> 3138661
>
> 1
>
> 3138661
>
> 48,038
>
> 495,62
>
> 6332,81
>
> 0,000000
>
> Temperature
>
> Fixed
>
> 3686660
>
> 1
>
> 3686660
>
> 48,003
>
> 6459,62
>
> 570,72
>
> 0,000000
>
> Line*Sex
>
> Random
>
> 23808
>
> 48
>
> 496
>
> 48,000
>
> 473,30
>
> 1,05
>
> 0,435866
>
> Line*Temperature
>
> Random
>
> 310413
>
> 48
>
> 6467
>
> 48,000
>
> 473,30
>
> 13,66
>
> 0,000000
>
> Sex*Temperature
>
> Fixed
>
> 10075
>
> 1
>
> 10075
>
> 48,040
>
> 472,94
>
> 21,30
>
> 0,000029
>
> Line*Sex*Temperature
>
> Random
>
> 22718
>
> 48
>
> 473
>
> 3696,000
>
> 167,33
>
> 2,83
>
> 0,000000
>
> Error
>
> 618467
>
> 3696
>
> 167
>
>
>
>
> But if I write the model with the other syntax:
>
> M1 <- lmer(Wing ~ Temperature * Sex + (Temperature * Sex | Line))
>
Writing the model as
M1 <- lmer(Wing ~ Temperature * Sex + (0 + Temperature:Sex | Line))
is often preferable as it makes the random-effect variance-covariance
matrix easier to interpret.

>
>
> the summary is the following:
>
>
>
> REML criterion at convergence: 31440.9
>
>
>
> Random effects:
>
>  Groups   Name                Variance Std.Dev. Corr
>
>  Line    (Intercept)           266.78   16.333
>
>   Temperature25             398.27   19.957   -0.60
>
>    SexM                                41.54    6.446   -0.56  0.46
>
>   Temperature25:SexM  61.34    7.832    0.56 -0.61 -0.80
>
>  Residual                             167.33   12.936
>
>
>
> Fixed effects:
>
>                                              Estimate Std. Error         df t value             Pr(>|t|)
>
> (Intercept)                          501.603      2.371            48.046 211.586  < 2e-16 ***
>
> Temperature25               -58.423      2.911               48.027 -20.070  < 2e-16 ***
>
> SexM                                 -53.659      1.095              47.964 -49.023  < 2e-16 ***
>
> Temperature                    25:SexM   -6.470               1.393  48.278  -4.644 2.66e-05 ***
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>
> In addition, if I apply the ?rand function? for this syntax (M1), it doesn?t retourn the whole p-values of the random effects (Do not give me p value for line and line*Temperature*Sex)

Use lmerTest::ranova(M1, reduce.terms=FALSE) to achieve a test for the
entire random-effect term (and make sure you have lmerTest version >=
3.0-0 installed).

>
> Analysis of Random effects Table:
>
>                                              Chi.sq Chi.DF p.value
>
> Temperatura:L?nea 0.00e+00      0       1
>
> Sexo:L?nea             1.46e-10      0  <2e-16 ***
>
>
> I really appreciate your time and dedication for answering this questions. Thank you for trying to help us understand a little more about the syntax of these complex models and thus better understand their correct approach.

You are not alone if you think this is complicated. My students are
for the most part challenged in simply writing up the mathematical
formula that correctly represents models such as Model1 -
transitioning from scalar random-effect terms (e.g. Model3b) to
vector-valued random-effect terms (e.g. Model1) often takes time and
dedication.

Cheers
Rune

>
> Thank you very much for your time everyone.
>
>
>
> Greetings,
>
> Nicolas
>
>
> ----------------------------------------------------------------------------------------
> Message: 2
> Date: Wed, 25 Apr 2018 16:11:38 -0400
> From: Dan <ieshan at gmail.com>
> To: "R-SIG-Mixed-Models at R-project.org"
>         <R-sig-mixed-models at r-project.org>, Ben Bolker <bbolker at gmail.com>
> Subject: [R-sig-ME] Specifying Multiple Random Effects in NLME
> Message-ID:
>         <CAET4i1f-SH5zA6xcCxNXc091HCk+snMv+rFm0tf995yYukiCOw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi all:
>
> I am curating an off-list thread about specifying multiple random effects
> in NLME.
>
> 1.  If it's (1|Object) + (1|Object:Coating) that you want then
> you should be able to use a nested specification (which nlme *can*
> handle relatively easily), i.e. something like
>
> random=a+b+c~1|Object/Coating
>
>
> Although (Coating|Object) and (1|Object:Coating) both in some sense
> represent "interactions" the latter is *much* simpler/more parsimonious.
>
> If you're OK with 1|Object:Coating rather than Coating|Object it
> should be *much* faster.  If you don't understand the distinction (which
> would be absolutely fine and understandable) can we resume the
> discussion on r-sig-mixed-models ... ?
> -----------
>
> So:
> random=a+b+c~Coating|Object
> does not fit.
>
> But:
> random=a+b+c~Object/Coating
> fits.
>
> Can you better explain the distinction here? I have sometimes used the
> 1|Object:Coating + 1|Object syntax and sometimes the Coating|Object syntax
> in other models. My experience/understanding is that the former syntax with
> multiple "within subject" variables produces exactly matching output to the
> standard "repeated measures ANOVA" with the lmer assumption of compound
> symmetry.
>
> Are there cases where one vs. the other formulation should absolutely be
> used? My understanding that for continuous variables, e.g., multiple
> measurements across multiple days, Days|Object would be the correct syntax.
> But here we're talking about a factor variable.
>
>
> 2.   I'm trying to read the "random" section for nlme right now but it's
> kind of making my head explode (and I think there's a typo: " the same
> as the order of the order of the elements in the list").  It *sounds*
> like (1) explicitly creating an interaction
> ObjCoating=interaction(Object,Coating) and (2) using something like
>
>   list(ObjCoating=a~1,Object=b~1,Object=c~1)
>
> should work (grouping factors as names, then [right-hand-side variable
> name]~[random effects model], but I'm worried about the phrase "The
> order of nesting will be assumed the same as the order of the elements
> in the list": what nesting?
> -----------
>
> I think that formulation is explicitly in order. I replaced your first
> ObjCoating with simply Object, just to test what would happen:
>
> Random effects:
>  Formula: a ~ 1 | Object
>         a.(Intercept)
> StdDev:      1.305816
>
>  Formula: b ~ 1 | Object %in% Object
>         b.(Intercept)
> StdDev:    0.01576521
>
>  Formula: c ~ 1 | Object %in% Object %in% Object
>         c.(Intercept) Residual
> StdDev:      2.677883 2.219676
>
>         [[alternative HTML version deleted]]
>
>
>
>
> *****
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From felipe-francisco.calleja at alumnos.unican.es  Sat Apr 28 13:00:11 2018
From: felipe-francisco.calleja at alumnos.unican.es (CALLEJA APESTEGUI, FELIPE FRANCISCO)
Date: Sat, 28 Apr 2018 11:00:11 +0000
Subject: [R-sig-ME] Help establishing mixed model equation for split,
 plot design
In-Reply-To: <7f7486ff-adab-2700-c3dd-b572b7686d7c@tum.de>
References: <mailman.16330.277.1522775768.1209.r-sig-mixed-models@r-project.org>,
 <7f7486ff-adab-2700-c3dd-b572b7686d7c@tum.de>
Message-ID: <AM4P191MB008284E01C4274B1DF25E8DA878C0@AM4P191MB0082.EURP191.PROD.OUTLOOK.COM>

Hello again everyone.


Some weeks ago I wrote asking for help for establishing the adequate mixed effects model in a split plot design I'm working on. After many weeks of reading and surfing the web, this list gave me the direction I desperately needed.


I'm facing now another challenge and I hope you will be able to help me (or point me in the right direction).


The original mail is at the end of this one, I'll just copy in here the experiments description before asking you my questions.


"The experiment consists in meassuring the germination percentage of one species in variable conditions of salinity, immersion time and presence of other species. I sow seeds in soil core's, that are inside plastic boxes that are filled periodically with saline water. There are three factors: salinity (3 levels: 0, 5 and 18), immersion time (3 levels: 0, 20, 40%), species treatment (2 levels: Baccharis, Baccharis + Juncus). Inside each box there are 6 cores that combine in a complete random design the factors of immersion and species treatment. The box is filled with water at one of the levels of salinity. Thus, I'm using a split plot design with salinity as the whole plot factor, and immersion and species treatment as the subplot factors. All factors are considered fixed. Each box is repeated 5 times. Thus, there are 15 boxes and 90 soil cores. The dependent variable is the percentage of germination of the species Baccharis in each core."



For another dependent variable I measured, the conditions of normality and homoestacity are not fulfilled, so I'm thinking about using a non-parametric test to analyze the data. The thing I don't know which one is the best suited for my design and what R packages could be useful. I've seen options in the nparLD (https://cran.r-project.org/web/packages/nparLD/nparLD.pdf), the WRS2 package (https://cran.r-project.org/web/packages/WRS2/vignettes/WRS2.pdf), and the rlme package (https://www.rdocumentation.org/packages/rlme/versions/0.5/topics/rlme), but with none of this I can clear my head on how to make them work, and specially if they are what I need.


This time, for simplifying the array, I'm interest in making bivariate tests using only the whole plot factor Salinity, and the sub-plot factor Immersion, using only the cores that had one species sown (removing the competition element).


Could you give some guidance on what type of non-parametric tests I should use (if there's any!), and which package you consider to be the best suited for an array like this?


Thanks a lot in advance, any tip is very well appreciated.


Best regards,

Felipe Calleja Ap?stegui

Predoctoral researcher


Instituto de Hidr?ulica Ambiental "IH Cantabria"

C/ Isabel Torres, N? 15

Parque Cient?fico y Tecnol?gico de Cantabria

39011 Santander (Espa?a)

www.ihcantabria.es<http://www.ihcantabria.es/>

Tel:  +34 942 20 16 16 Ext. 1153

Fax: +34 942 26 63 61

e-mail: felipe-francisco.calleja at alumnos.unican.es


------------------------------------------------------------------------------------------------------
On 03/04/18 19:16, r-sig-mixed-models-request at r-project.org wrote:
> Message: 1
> Date: Tue, 3 Apr 2018 07:53:15 +0000
> From: "CALLEJA APESTEGUI, FELIPE FRANCISCO"
>        <felipe-francisco.calleja at alumnos.unican.es>
> To: "r-sig-mixed-models at r-project.org"
>        <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Help establishing mixed model equation for split
>        plot design
> Message-ID:
>        <DB6P191MB0088D09AF911107B33C1DE5C87A50 at DB6P191MB0088.EURP191.PROD.OUTLOOK.COM>
>
> Content-Type: text/plain; charset="iso-8859-1"
>
> Hello,
>
>
> I'm looking for some help establishing a mixed model ANOVA using R, for a split plot design I've made for an experiment of saltmarsh germination. I'll explain as clear as possible the experimental design and afterwards what I've done and my doubts. Hope you can help me. I haven't worked very much with R so many of my doubts are about what I'm "telling" it to do with one or other command.
>
>
> The experiment consists in meassuring the germination percentage of one species in variable conditions of salinity, immersion time and presence of other species. I sow seeds in soil core's, that are inside plastic boxes that are filled periodically with saline water. There are three factors: salinity (3 levels: 0, 5 and 18), immersion time (3 levels: 0, 20, 40%), species treatment (2 levels: Baccharis, Baccharis + Juncus). Inside each box there are 6 cores that combine in a complete random design the factors of immersion and species treatment. The box is filled with water at one of the levels of salinity. Thus, I'm using a split plot design with salinity as the whole plot factor, and immersion and species treatment as the subplot factors. All factors are considered fixed. Each box is repeated 5 times. Thus, there are 15 boxes and 90 soil cores. The dependent variable is the percentage of germination of the species Baccharis in each core.
>
>
> I have several doubts about how to analyze the array.
>
>
> 1 - As far as I understand, although I'm treating all my factors as fixed, this is a mixed model because of the interaction between subjects (the boxes I believe), and the "split plot nature" of the array, right? In that sense, which function would be better to analyze this, the aov of the stats package, the lme of the nlme package, the lmer of lme4?
>
>
>
>   2 - I've had trouble calculating the degrees of freedom for the residuals. The only reference I have is that the error of the whole plot part should have 12 df's, and the within error should have 60 df's. With that reference I've established two possible R commands:
>
>
> fit.aov2 <- aov(Plantsurvival ~ salinityF*immersionF*SpecTF + Error(rep:salinityF/immersionF:SpecTF), data=sp.datos)
>
>
> With rep being the number of repetition. This last one gives the 12 and 60 df's for the error terms.
>
>
> The other option is:
>
> fit.okay <- lme(Plantsurvival ~ salinityF*immersionF*SpecTF, random= ~1|rep/salinityF, data=sp.datos)
>
> But in this last case, the df's are 8 and 60, which makes me suspect maybe there is something wrong. But as I said, I haven't cleared my head on which should be the correct df's.
>
>
> Questions: Is the aov line solving a mixed model adequate for my design?,
>
>
>
>                       Is the lme line considering salinityF as a random factor? If it is, how can I tell it to consider all factors as fixed, but put salinity at the "higher level" of the whole plot and the other ones in the "lower level" of the subplot?
>
>
> I hope the questions and the experimental array are clear. If there is any doubt or need more information please let me know. I attach a csv file with the data in case you want to see it.
>
>
> Finally, if is not too much to ask, I'm fairly new to the splitplot anova's and R, so I would really appreciate if you could answer be with as much detail as possible, to fully understand what's going on and where to continue.
>
>
> Thanks a lot,
>
>
> Felipe Calleja Ap?stegui
>
> Predoctoral researcher
>
>
> Instituto de Hidr?ulica Ambiental "IH Cantabria"
>
> C/ Isabel Torres, N? 15
>
> Parque Cient?fico y Tecnol?gico de Cantabria
>
> 39011 Santander (Espa?a)
>
> www.ihcantabria.es<http://www.ihcantabria.es/>
>
> Tel:  +34 942 20 16 16 Ext. 1153
>
> Fax: +34 942 26 63 61
>
> e-mail: felipe-francisco.calleja at alumnos.unican.es
>
>
>


	[[alternative HTML version deleted]]


From Bill.Poling at zelis.com  Mon Apr 30 19:13:53 2018
From: Bill.Poling at zelis.com (Bill Poling)
Date: Mon, 30 Apr 2018 17:13:53 +0000
Subject: [R-sig-ME] FW:  Trouble looping model using glmmTMB
In-Reply-To: <CAOJBL41fV+M-vVpVwmxyebH1qOa6rPXxgS5j83WJcEH02ZUQ1g@mail.gmail.com>
References: <mailman.16361.9.1523268001.12154.r-sig-mixed-models@r-project.org>
 <VI1PR03MB3040688E5726B3AF9F374FC4D2BF0@VI1PR03MB3040.eurprd03.prod.outlook.com>
 <CAOJBL41fV+M-vVpVwmxyebH1qOa6rPXxgS5j83WJcEH02ZUQ1g@mail.gmail.com>
Message-ID: <SN1PR0201MB18402A9220A3EB819944D995EA820@SN1PR0201MB1840.namprd02.prod.outlook.com>

Message-ID:CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.<mailto:CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.%0b>gmail.com<http://gmail.com>

Hi, I have been following this string as I try to learn how to bootstrap using R.

I am an R novice and this is my first post.

I believe I am complying with the rules as I understand them.

My question pertains to deriving confidence interval(s) from the bootstrap  output.

I ran the bbolker script From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker, Sent: Sunday, April 08, 2018 2:22 PM on this topic

Therefore I have the 100:

           [,1]     [,2]      [,3]       [,4]
  [1,] 1.674036 1.103844 -1.558970 0.20640989
  [2,] 1.626733 1.116971 -1.683252 0.09869567
  [3,] 1.623758 1.173316 -1.669386 0.21515432
  [4,] 1.690359 1.141988 -1.729407 0.17972799
  [5,] 1.679417 1.146139 -1.425824 0.19958387

etc?..

AND the bootfit model:

bootfit

# Formula:          y ~ x + (1 | f)
# Zero inflation:     ~1
# Data: bootsamp()
# AIC         BIC       logLik    df.resid
# 13101.717 13130.980 -6545.859      2567
# Random-effects (co)variances:
#
#   Conditional model:
#   Groups Name        Std.Dev.
#       f      (Intercept) 1.499
#
# Number of obs: 2572 / Conditional model: f, 102
#
# Overdispersion parameter for nbinom2 family (): 1.17
#
# Fixed Effects:
#
#   Conditional model:
#   (Intercept)            x
#       1.578            1.103
#
# Zero-inflation model:
#   (Intercept)
#     -1.657


I have reviewed the confint help and performed the examples: (mtcars and the glm counts).



However, I am not sure how to apply the confint() function on this bootstrap output.



Please advise.



Thank you.



WHP
William H. Poling, Ph.D., MPH


From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Viraj Torsekar
Sent: Monday, April 09, 2018 7:40 AM
To: Houslay, Tom <T.Houslay at exeter.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble looping model using glmmTMB

Thanks so much for the suggestion Tom. Yes I was analysing calling effort
for males, and movement for both males and females in that manner. But I
was running separate models for each. I'll have a look at these conditional
two-part models.

Viraj

On 9 April 2018 at 15:50, Houslay, Tom <T.Houslay at exeter.ac.uk<mailto:T.Houslay at exeter.ac.uk>> wrote:

> Hi Viraj,
>
>
> This isn't a direct answer to your question so you can feel extremely free
> to ignore it(!), but your question reminded me of an approach I took to
> modelling calling effort in crickets using zero-altered poisson models in
> Jarrod's MCMCglmm package. In that case I had a few more predictor
> variables, but it meant the question could be phrased as two parts: what
> factors affect whether a male called or not, and - given he did call - what
> factors affect how much time he spent calling? It seems that that might be
> another option for you to model the movement with your crickets, although
> obviously it depends whether you think that would give you anything more
> valuable than your current approach (eg, is the decision to move something
> worth modelling separately from how far the cricket travels).
>
>
> Anyway - my paper including this analysis is at http://doi.wiley.com/10<http://doi.wiley.com/10>.
> 1111/1365-2435.12766 in case it's of any interest.
>
>
> Cheers
>
>
> Tom
>
> ----
>
> Message: 1
> Date: Sun, 8 Apr 2018 19:57:53 +0530
> From: Viraj Torsekar <viraj.torsekar at gmail.com<mailto:viraj.torsekar at gmail.com>>
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Trouble looping model using glmmTMB
> Message-ID:
> <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.
<mailto:CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.%0b>> gmail.com<http://gmail.com>>
> Content-Type: text/plain; charset="utf-8"
>
>
> Hello all,
>
> I'm trying to find out if distance moved by crickets is a function of
> predation risk. My response variable is 'distance moved' and the predictor
> is probability of spatial proximity with predator, ranging from 0 to 1. The
> response variable is zero-inflated (about 77% values are zeroes) and its
> variance is far higher than its mean. Hence, I tried running zero-inflated
> negative binomial mixed models using glmmADMB, which failed (mixed because
> I have multiple values per individual). Following was the error I kept
> encountering: "function maximizer failed" (attaching a text file with
> details of this model by keeping debug=TRUE).
>
> Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
> it worked! But the problem is, when I try bootstrapping the model using to
> obtain confidence intervals, I keep getting the following error after
> varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
> gradient in optim evaluated to length 1 not 5'. This non-parametric
> bootstrapping routine involves for loops in which the model is run using
> bootstrapped groups (belonging to the grouping variable; individual.id<http://individual.id> in
> my case) and the model coefficients thus obtained constitute the confidence
> intervals. I've tried running 10,000 iterations, but the error pops up
> within 10 to 100 runs.
>
> Does anyone have suggestions regarding what can be changed?
>
> Details of the model run singly and not in the loop:
>
> Family: nbinom2 ( log )
> Formula: movement.whole ~ poc + (1 | female.id<http://female.id>)
> Zero inflation: ~1
> Data: incrisk_females_comm
>
> AIC BIC logLik deviance df.resid
> 1725.1 1745.9 -857.5 1715.1 474
>
> Random effects:
>
> Conditional model:
> Groups Name Variance Std.Dev<http://Std.Dev>.
> female.id<http://female.id> (Intercept) 0.07924 0.2815
> Number of obs: 479, groups: female.id<http://female.id>, 110
>
> Overdispersion parameter for nbinom2 family (): 1.59
>
> Conditional model:
> Estimate Std. Error z value Pr(>|z|)
> (Intercept) 4.66384 0.14161 32.93 <2e-16 ***
> poc -0.08815 0.20978 -0.42 0.674
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Zero-inflation model:
> Estimate Std. Error z value Pr(>|z|)
> (Intercept) 1.2442 0.1098 11.34 <2e-16 ***
>
> Please do mention if you need further details. Thank you in advance.
>
> Viraj Torsekar,
> PhD Candidate,
> Centre for Ecological Sciences,
> Indian Institute of Science
>
> [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 136, Issue 19
> ***************************************************
>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From Bill.Poling at zelis.com  Tue May  1 14:11:09 2018
From: Bill.Poling at zelis.com (Bill Poling)
Date: Tue, 1 May 2018 12:11:09 +0000
Subject: [R-sig-ME] Trouble looping model using glmmTMB
In-Reply-To: <CAOJBL41fV+M-vVpVwmxyebH1qOa6rPXxgS5j83WJcEH02ZUQ1g@mail.gmail.com>
References: <mailman.16361.9.1523268001.12154.r-sig-mixed-models@r-project.org>
 <VI1PR03MB3040688E5726B3AF9F374FC4D2BF0@VI1PR03MB3040.eurprd03.prod.outlook.com>
 <CAOJBL41fV+M-vVpVwmxyebH1qOa6rPXxgS5j83WJcEH02ZUQ1g@mail.gmail.com>
Message-ID: <SN1PR0201MB18403BC66D9CBA4370905039EA810@SN1PR0201MB1840.namprd02.prod.outlook.com>

Hi, I have been following this string as I try to learn how to bootstrap using R.

I am an R novice and this is actually my first post.

Therefore, I hope I am complying with the posting rules, as I understand them, properly.

I ran the bbolker script From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker, Sent: Sunday, April 08, 2018 2:22 PM on this topic

Therefore I have the 100:

           [,1]     [,2]      [,3]       [,4]
  [1,] 1.674036 1.103844 -1.558970 0.20640989
  [2,] 1.626733 1.116971 -1.683252 0.09869567
  [3,] 1.623758 1.173316 -1.669386 0.21515432
  [4,] 1.690359 1.141988 -1.729407 0.17972799
  [5,] 1.679417 1.146139 -1.425824 0.19958387

etc?..

AND the bootfit model:

bootfit

# Formula:          y ~ x + (1 | f)
# Zero inflation:     ~1
# Data: bootsamp()
# AIC         BIC       logLik    df.resid
# 13101.717 13130.980 -6545.859      2567
# Random-effects (co)variances:
#
#   Conditional model:
#   Groups Name        Std.Dev.
#       f      (Intercept) 1.499
#
# Number of obs: 2572 / Conditional model: f, 102
#
# Overdispersion parameter for nbinom2 family (): 1.17
#
# Fixed Effects:
#
#   Conditional model:
#   (Intercept)            x
#       1.578            1.103
#
# Zero-inflation model:
#   (Intercept)
#     -1.657


I have reviewed the confint() help and performed the examples: (mtcars and the glm counts).



However, I am not sure how to apply the confint() function on this bootstrap output.


My questions pertain to:


  1.  Deriving confidence interval(s) from the bootstrap  output.
  2.  Proper interpretation of the resulting output statistics.



Please advise at your convenience and thank you in advance for any assistance.



WHP
William H. Poling, Ph.D., MPH


From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Viraj Torsekar
Sent: Monday, April 09, 2018 7:40 AM
To: Houslay, Tom <T.Houslay at exeter.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Trouble looping model using glmmTMB

Thanks so much for the suggestion Tom. Yes I was analysing calling effort
for males, and movement for both males and females in that manner. But I
was running separate models for each. I'll have a look at these conditional
two-part models.

Viraj

On 9 April 2018 at 15:50, Houslay, Tom <T.Houslay at exeter.ac.uk<mailto:T.Houslay at exeter.ac.uk>> wrote:

> Hi Viraj,
>
>
> This isn't a direct answer to your question so you can feel extremely free
> to ignore it(!), but your question reminded me of an approach I took to
> modelling calling effort in crickets using zero-altered poisson models in
> Jarrod's MCMCglmm package. In that case I had a few more predictor
> variables, but it meant the question could be phrased as two parts: what
> factors affect whether a male called or not, and - given he did call - what
> factors affect how much time he spent calling? It seems that that might be
> another option for you to model the movement with your crickets, although
> obviously it depends whether you think that would give you anything more
> valuable than your current approach (eg, is the decision to move something
> worth modelling separately from how far the cricket travels).
>
>
> Anyway - my paper including this analysis is at http://doi.wiley.com/10<http://doi.wiley.com/10>.
> 1111/1365-2435.12766 in case it's of any interest.
>
>
> Cheers
>
>
> Tom
>
> ----
>
> Message: 1
> Date: Sun, 8 Apr 2018 19:57:53 +0530
> From: Viraj Torsekar <viraj.torsekar at gmail.com<mailto:viraj.torsekar at gmail.com>>
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Trouble looping model using glmmTMB
> Message-ID:
> <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.
<mailto:CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.%0b>> gmail.com<http://gmail.com>>
> Content-Type: text/plain; charset="utf-8"
>
>
> Hello all,
>
> I'm trying to find out if distance moved by crickets is a function of
> predation risk. My response variable is 'distance moved' and the predictor
> is probability of spatial proximity with predator, ranging from 0 to 1. The
> response variable is zero-inflated (about 77% values are zeroes) and its
> variance is far higher than its mean. Hence, I tried running zero-inflated
> negative binomial mixed models using glmmADMB, which failed (mixed because
> I have multiple values per individual). Following was the error I kept
> encountering: "function maximizer failed" (attaching a text file with
> details of this model by keeping debug=TRUE).
>
> Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
> it worked! But the problem is, when I try bootstrapping the model using to
> obtain confidence intervals, I keep getting the following error after
> varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
> gradient in optim evaluated to length 1 not 5'. This non-parametric
> bootstrapping routine involves for loops in which the model is run using
> bootstrapped groups (belonging to the grouping variable; individual.id<http://individual.id> in
> my case) and the model coefficients thus obtained constitute the confidence
> intervals. I've tried running 10,000 iterations, but the error pops up
> within 10 to 100 runs.
>
> Does anyone have suggestions regarding what can be changed?
>
> Details of the model run singly and not in the loop:
>
> Family: nbinom2 ( log )
> Formula: movement.whole ~ poc + (1 | female.id<http://female.id>)
> Zero inflation: ~1
> Data: incrisk_females_comm
>
> AIC BIC logLik deviance df.resid
> 1725.1 1745.9 -857.5 1715.1 474
>
> Random effects:
>
> Conditional model:
> Groups Name Variance Std.Dev<http://Std.Dev>.
> female.id<http://female.id> (Intercept) 0.07924 0.2815
> Number of obs: 479, groups: female.id<http://female.id>, 110
>
> Overdispersion parameter for nbinom2 family (): 1.59
>
> Conditional model:
> Estimate Std. Error z value Pr(>|z|)
> (Intercept) 4.66384 0.14161 32.93 <2e-16 ***
> poc -0.08815 0.20978 -0.42 0.674
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Zero-inflation model:
> Estimate Std. Error z value Pr(>|z|)
> (Intercept) 1.2442 0.1098 11.34 <2e-16 ***
>
> Please do mention if you need further details. Thank you in advance.
>
> Viraj Torsekar,
> PhD Candidate,
> Centre for Ecological Sciences,
> Indian Institute of Science
>
> [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 136, Issue 19
> ***************************************************
>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Tue May  1 15:45:20 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Tue, 1 May 2018 15:45:20 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
Message-ID: <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>

Dear Rune,

am I right in thinking of Model3b as a zero-correlation-parameter
model (m_zcp) but with the variances of the operators-related effects
constrained to equality?
Specifically, is the difference between Model3b and m_zcp that m_zcp
estimates variance components for each level of the factor 'machines'
and Model3b assumes equal variances across the levels of machines and
estimates only one variance for all levels?

Model3b <- lmer(Y ~ machines + (1 | operators) + (1 | machines:operators))
m_zcp  <- lmer(Y ~ machines + (machines || operators))

Cheers,
Maarten


From rune.haubo at gmail.com  Tue May  1 21:53:31 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Tue, 1 May 2018 21:53:31 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
 <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
Message-ID: <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>

On 1 May 2018 at 15:45, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> Dear Rune,
>
> am I right in thinking of Model3b as a zero-correlation-parameter
> model (m_zcp) but with the variances of the operators-related effects
> constrained to equality?
> Specifically, is the difference between Model3b and m_zcp that m_zcp
> estimates variance components for each level of the factor 'machines'
> and Model3b assumes equal variances across the levels of machines and
> estimates only one variance for all levels?
>
> Model3b <- lmer(Y ~ machines + (1 | operators) + (1 | machines:operators))
> m_zcp  <- lmer(Y ~ machines + (machines || operators))
>
> Cheers,
> Maarten

Hmm, well, that only makes partial sense to me. You probably want to compare

Model2 <- lmer(Y ~ machines + (1 | machines:operators))

with m_zcp. These two models have the same number of random effects
the difference
being that Model2 assumes a single variance for all of them, while m_zcp
assumes that the vectors of random effects for each operator come from a
multivariate normal distribution the dimension of which match the number of
machines.

This is probably easier to think about if we look at a concrete example, say
using the cake data from lme4. Here recipe=machines and replicate=operators;
there are 3 levels for recipe and 15 replicates.

First, '(recipe || replicate)' is the same as/expands to '(1 |
replicate) + (0 + recipe | replicate)'
which is just an over-parameterized version of '(0 + recipe | replicate)', which
again is a re-parameterized version of '(recipe | replicate)'. These are all
representing the same model (all on 10 df though lmer() is mislead and thinks
that m_zcp has 11 df):

> library(lmerTest)
> m_zcp <- lmer(angle ~ recipe  + (recipe || replicate), cake)
> VarCorr(m_zcp)
 Groups      Name        Std.Dev. Corr
 replicate   (Intercept) 0.0000
 replicate.1 recipeA     5.0692
             recipeB     6.7300   0.951
             recipeC     7.2107   0.902 0.991
 Residual                5.3622
> m_zcp2 <- lmer(angle ~ recipe + (0 + recipe | replicate), cake)
> VarCorr(m_zcp2)
 Groups    Name    Std.Dev. Corr
 replicate recipeA 5.0692
           recipeB 6.7300   0.951
           recipeC 7.2107   0.902 0.991
 Residual          5.3622
> m_zcp3 <- lmer(angle ~ recipe + (recipe | replicate), cake)
> anova(m_zcp, m_zcp2, m_zcp3, refit=FALSE)
Data: cake
Models:
m_zcp2: angle ~ recipe + (0 + recipe | replicate)
m_zcp3: angle ~ recipe + (recipe | replicate)
m_zcp: angle ~ recipe + (recipe || replicate)
       Df  AIC    BIC logLik deviance Chisq Chi Df Pr(>Chisq)
m_zcp2 10 1741 1777.0 -860.5     1721
m_zcp3 10 1741 1777.0 -860.5     1721     0      0          1
m_zcp  11 1743 1782.6 -860.5     1721     0      1          1

If we want to enforce a diagonal covariance matrix for the random effects,
we can use the dummy function:
m_zcp4 <- lmer(angle ~ recipe +
                 (0 + dummy(recipe, "A") | replicate) +
                 (0 + dummy(recipe, "B") | replicate) +
                 (0 + dummy(recipe, "C") | replicate), data=cake)
VarCorr(m_zcp4)
 Groups      Name               Std.Dev.
 replicate   dummy(recipe, "A") 5.0429
 replicate.1 dummy(recipe, "B") 6.6476
 replicate.2 dummy(recipe, "C") 7.1727
 Residual                       5.4181

Now we have something closer to what I think you were thinking of. Here,

Model2 <- lmer(angle ~ recipe + (1 | recipe:replicate), data=cake)

and m_zcp estimate the same random effects, but Model2 assumes they have
the same variance while m_zcp says that the variance depends on the
recipe and none of the models include correlation parameters.

In this case the difference in variance between recipes is small and
the random-effect estimates are very similar (as is the test for the
fixed-effects of recipe):

head(matrix(unlist(ranef(Model2)[[1]]), ncol=3))
          [,1]      [,2]        [,3]
[1,] 10.444800 13.695174 15.22126404
[2,]  9.106993 13.397883 13.43752216
[3,]  5.242219  4.181884  3.47829667
[4,] -2.487329  1.357626  4.22152245
[5,]  2.269316  1.654916 -3.21073538
[6,] -6.054813 -2.953084 -0.08918709

head(ranef(m_zcp4)$replicate)
  dummy(recipe, "A") dummy(recipe, "B") dummy(recipe, "C")
1           9.821502          13.824869        15.58456445
2           8.563530          13.524764        13.75824831
3           4.929388           4.221487         3.56131649
4          -2.338897           1.370483         4.32228155
5           2.133894           1.670588        -3.28736906
6          -5.693489          -2.981050        -0.09131581

Cheers
Rune


From Maarten.Jung at mailbox.tu-dresden.de  Wed May  2 00:27:06 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Wed, 2 May 2018 00:27:06 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
 <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
 <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>
Message-ID: <CAHr4Dyc9R2i0xyx2J7SRrjPbrHs0o60Nyr7B9gJVsu=dBq2ftw@mail.gmail.com>

Sorry, I forgot that lmer() (unlike lmer_alt() from the afex package)
does not convert factors to numeric covariates when using the the
double-bar notation!
The model I was talking about would be:

m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
VarCorr(m_zcp5)
 Groups      Name        Std.Dev.
 replicate   (Intercept) 6.2359
 replicate.1 re1.recipe1 1.7034
 replicate.2 re1.recipe2 0.0000
 Residual                5.3775

This model seems to differ (and I don't really understand why) from
m_zcp6 which I think is equivalent to your m_zcp4:
m_zcp6 <- lmer_alt(angle ~ recipe  + (0 + recipe || replicate), cake)
VarCorr(m_zcp6)
 Groups      Name        Std.Dev.
 replicate   re1.recipeA 5.0429
 replicate.1 re1.recipeB 6.6476
 replicate.2 re1.recipeC 7.1727
 Residual                5.4181

anova(m_zcp6, m_zcp5, refit = FALSE)
Data: data
Models:
m_zcp6: angle ~ recipe + ((0 + re1.recipeA | replicate) + (0 + re1.recipeB |
m_zcp6:     replicate) + (0 + re1.recipeC | replicate))
m_zcp5: angle ~ recipe + ((1 | replicate) + (0 + re1.recipe1 | replicate) +
m_zcp5:     (0 + re1.recipe2 | replicate))
       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
m_zcp6  7 1781.8 1807.0 -883.88   1767.8
m_zcp5  7 1742.0 1767.2 -863.98   1728.0 39.807      0  < 2.2e-16 ***

Do m_zcp5 and Model3b estimate the same random effects in this case?
If not, what is the difference between m_zcp5 and Model3b (except for
the fact that the variance depends on the
recipe in m_zcp5) and which one is the more complex model?
I would be glad if you could elaborate on this and help me and the
others understand these models.

Cheers,
Maarten

On Tue, May 1, 2018 at 9:53 PM, Rune Haubo <rune.haubo at gmail.com> wrote:
> On 1 May 2018 at 15:45, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>> Dear Rune,
>>
>> am I right in thinking of Model3b as a zero-correlation-parameter
>> model (m_zcp) but with the variances of the operators-related effects
>> constrained to equality?
>> Specifically, is the difference between Model3b and m_zcp that m_zcp
>> estimates variance components for each level of the factor 'machines'
>> and Model3b assumes equal variances across the levels of machines and
>> estimates only one variance for all levels?
>>
>> Model3b <- lmer(Y ~ machines + (1 | operators) + (1 | machines:operators))
>> m_zcp  <- lmer(Y ~ machines + (machines || operators))
>>
>> Cheers,
>> Maarten
>
> Hmm, well, that only makes partial sense to me. You probably want to compare
>
> Model2 <- lmer(Y ~ machines + (1 | machines:operators))
>
> with m_zcp. These two models have the same number of random effects
> the difference
> being that Model2 assumes a single variance for all of them, while m_zcp
> assumes that the vectors of random effects for each operator come from a
> multivariate normal distribution the dimension of which match the number of
> machines.
>
> This is probably easier to think about if we look at a concrete example, say
> using the cake data from lme4. Here recipe=machines and replicate=operators;
> there are 3 levels for recipe and 15 replicates.
>
> First, '(recipe || replicate)' is the same as/expands to '(1 |
> replicate) + (0 + recipe | replicate)'
> which is just an over-parameterized version of '(0 + recipe | replicate)', which
> again is a re-parameterized version of '(recipe | replicate)'. These are all
> representing the same model (all on 10 df though lmer() is mislead and thinks
> that m_zcp has 11 df):
>
>> library(lmerTest)
>> m_zcp <- lmer(angle ~ recipe  + (recipe || replicate), cake)
>> VarCorr(m_zcp)
>  Groups      Name        Std.Dev. Corr
>  replicate   (Intercept) 0.0000
>  replicate.1 recipeA     5.0692
>              recipeB     6.7300   0.951
>              recipeC     7.2107   0.902 0.991
>  Residual                5.3622
>> m_zcp2 <- lmer(angle ~ recipe + (0 + recipe | replicate), cake)
>> VarCorr(m_zcp2)
>  Groups    Name    Std.Dev. Corr
>  replicate recipeA 5.0692
>            recipeB 6.7300   0.951
>            recipeC 7.2107   0.902 0.991
>  Residual          5.3622
>> m_zcp3 <- lmer(angle ~ recipe + (recipe | replicate), cake)
>> anova(m_zcp, m_zcp2, m_zcp3, refit=FALSE)
> Data: cake
> Models:
> m_zcp2: angle ~ recipe + (0 + recipe | replicate)
> m_zcp3: angle ~ recipe + (recipe | replicate)
> m_zcp: angle ~ recipe + (recipe || replicate)
>        Df  AIC    BIC logLik deviance Chisq Chi Df Pr(>Chisq)
> m_zcp2 10 1741 1777.0 -860.5     1721
> m_zcp3 10 1741 1777.0 -860.5     1721     0      0          1
> m_zcp  11 1743 1782.6 -860.5     1721     0      1          1
>
> If we want to enforce a diagonal covariance matrix for the random effects,
> we can use the dummy function:
> m_zcp4 <- lmer(angle ~ recipe +
>                  (0 + dummy(recipe, "A") | replicate) +
>                  (0 + dummy(recipe, "B") | replicate) +
>                  (0 + dummy(recipe, "C") | replicate), data=cake)
> VarCorr(m_zcp4)
>  Groups      Name               Std.Dev.
>  replicate   dummy(recipe, "A") 5.0429
>  replicate.1 dummy(recipe, "B") 6.6476
>  replicate.2 dummy(recipe, "C") 7.1727
>  Residual                       5.4181
>
> Now we have something closer to what I think you were thinking of. Here,
>
> Model2 <- lmer(angle ~ recipe + (1 | recipe:replicate), data=cake)
>
> and m_zcp estimate the same random effects, but Model2 assumes they have
> the same variance while m_zcp says that the variance depends on the
> recipe and none of the models include correlation parameters.
>
> In this case the difference in variance between recipes is small and
> the random-effect estimates are very similar (as is the test for the
> fixed-effects of recipe):
>
> head(matrix(unlist(ranef(Model2)[[1]]), ncol=3))
>           [,1]      [,2]        [,3]
> [1,] 10.444800 13.695174 15.22126404
> [2,]  9.106993 13.397883 13.43752216
> [3,]  5.242219  4.181884  3.47829667
> [4,] -2.487329  1.357626  4.22152245
> [5,]  2.269316  1.654916 -3.21073538
> [6,] -6.054813 -2.953084 -0.08918709
>
> head(ranef(m_zcp4)$replicate)
>   dummy(recipe, "A") dummy(recipe, "B") dummy(recipe, "C")
> 1           9.821502          13.824869        15.58456445
> 2           8.563530          13.524764        13.75824831
> 3           4.929388           4.221487         3.56131649
> 4          -2.338897           1.370483         4.32228155
> 5           2.133894           1.670588        -3.28736906
> 6          -5.693489          -2.981050        -0.09131581
>
> Cheers
> Rune


From viraj.torsekar at gmail.com  Wed May  2 09:03:24 2018
From: viraj.torsekar at gmail.com (Viraj Torsekar)
Date: Wed, 2 May 2018 12:33:24 +0530
Subject: [R-sig-ME] Trouble looping model using glmmTMB
In-Reply-To: <SN1PR0201MB18403BC66D9CBA4370905039EA810@SN1PR0201MB1840.namprd02.prod.outlook.com>
References: <mailman.16361.9.1523268001.12154.r-sig-mixed-models@r-project.org>
 <VI1PR03MB3040688E5726B3AF9F374FC4D2BF0@VI1PR03MB3040.eurprd03.prod.outlook.com>
 <CAOJBL41fV+M-vVpVwmxyebH1qOa6rPXxgS5j83WJcEH02ZUQ1g@mail.gmail.com>
 <SN1PR0201MB18403BC66D9CBA4370905039EA810@SN1PR0201MB1840.namprd02.prod.outlook.com>
Message-ID: <CAOJBL43EZQC3OhDwxq689e_oJDOZAgNoZTVWVZQFCYo2gKRQqQ@mail.gmail.com>

Hi Bill,

To answer your first question (Deriving confidence interval(s) from the
bootstrap), the following code might help. That should give you a data
frame of the lower CI range of 2.5% and higher range of 97.5%.

CI_values <- data.frame(sapply(1:ncol(X), function(x)
quantile(X[,x],c(0.025,0.975))))

where, X is the data frame containing the bootstrapped values.

As for the second question (Proper interpretation of the resulting output
statistics.) you might want to refer to Nakagawa and Cuthill (2007) and
Cumming and Finch (2005).

Viraj


On 1 May 2018 at 17:41, Bill Poling <Bill.Poling at zelis.com> wrote:

> Hi, I have been following this string as I try to learn how to bootstrap
> using R.
>
>
>
> I am an R novice and this is actually my first post.
>
>
>
> Therefore, I hope I am complying with the posting rules, as I understand
> them, properly.
>
>
>
> I ran the bbolker script From: R-sig-mixed-models [
> mailto:r-sig-mixed-models-bounces at r-project.org
> <r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Ben Bolker,
> Sent: Sunday, April 08, 2018 2:22 PM on this topic
>
>
>
> Therefore I have the 100:
>
>
>
>            [,1]     [,2]      [,3]       [,4]
>
>   [1,] 1.674036 1.103844 -1.558970 0.20640989
>
>   [2,] 1.626733 1.116971 -1.683252 0.09869567
>
>   [3,] 1.623758 1.173316 -1.669386 0.21515432
>
>   [4,] 1.690359 1.141988 -1.729407 0.17972799
>
>   [5,] 1.679417 1.146139 -1.425824 0.19958387
>
>
> etc?..
>
>
>
> AND the bootfit model:
>
>
>
> bootfit
>
>
>
> # Formula:          y ~ x + (1 | f)
>
> # Zero inflation:     ~1
>
> # Data: bootsamp()
>
> # AIC         BIC       logLik    df.resid
>
> # 13101.717 13130.980 -6545.859      2567
>
> # Random-effects (co)variances:
>
> #
>
> #   Conditional model:
>
> #   Groups Name        Std.Dev.
>
> #       f      (Intercept) 1.499
>
> #
>
> # Number of obs: 2572 / Conditional model: f, 102
>
> #
>
> # Overdispersion parameter for nbinom2 family (): 1.17
>
> #
>
> # Fixed Effects:
>
> #
>
> #   Conditional model:
>
> #   (Intercept)            x
>
> #       1.578            1.103
>
> #
>
> # Zero-inflation model:
>
> #   (Intercept)
>
> #     -1.657
>
>
>
> I have reviewed the confint() help and performed the examples: (mtcars and the glm counts).
>
>
>
> However, I am not sure how to apply the confint() function on this bootstrap output.
>
>
>
> My questions pertain to:
>
>
>
>    1. Deriving confidence interval(s) from the bootstrap  output.
>    2. Proper interpretation of the resulting output statistics.
>
>
>
> Please advise at your convenience and thank you in advance for any assistance.
>
>
>
> WHP
>
> William H. Poling, Ph.D., MPH
>
>
>
>
>
> *From:* R-sig-mixed-models [mailto:r-sig-mixed-models-
> bounces at r-project.org] *On Behalf Of *Viraj Torsekar
> *Sent:* Monday, April 09, 2018 7:40 AM
> *To:* Houslay, Tom <T.Houslay at exeter.ac.uk>
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Trouble looping model using glmmTMB
>
>
>
> Thanks so much for the suggestion Tom. Yes I was analysing calling effort
> for males, and movement for both males and females in that manner. But I
> was running separate models for each. I'll have a look at these conditional
> two-part models.
>
> Viraj
>
> On 9 April 2018 at 15:50, Houslay, Tom <T.Houslay at exeter.ac.uk> wrote:
>
> > Hi Viraj,
> >
> >
> > This isn't a direct answer to your question so you can feel extremely
> free
> > to ignore it(!), but your question reminded me of an approach I took to
> > modelling calling effort in crickets using zero-altered poisson models in
> > Jarrod's MCMCglmm package. In that case I had a few more predictor
> > variables, but it meant the question could be phrased as two parts: what
> > factors affect whether a male called or not, and - given he did call -
> what
> > factors affect how much time he spent calling? It seems that that might
> be
> > another option for you to model the movement with your crickets, although
> > obviously it depends whether you think that would give you anything more
> > valuable than your current approach (eg, is the decision to move
> something
> > worth modelling separately from how far the cricket travels).
> >
> >
> > Anyway - my paper including this analysis is at http://doi.wiley.com/10.
> > 1111/1365-2435.12766 in case it's of any interest.
>
> >
> >
> > Cheers
> >
> >
> > Tom
> >
> > ----
> >
> > Message: 1
> > Date: Sun, 8 Apr 2018 19:57:53 +0530
> > From: Viraj Torsekar <viraj.torsekar at gmail.com>
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Trouble looping model using glmmTMB
> > Message-ID:
> > <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.
> <CAOJBL42qdVortWMi2xVdqv=4MHUT8zbiOPbU3Y+UxBSjkiAY0Q at mail.%0b>> gmail.com>
> > Content-Type: text/plain; charset="utf-8"
> >
> >
> > Hello all,
> >
> > I'm trying to find out if distance moved by crickets is a function of
> > predation risk. My response variable is 'distance moved' and the
> predictor
> > is probability of spatial proximity with predator, ranging from 0 to 1.
> The
> > response variable is zero-inflated (about 77% values are zeroes) and its
> > variance is far higher than its mean. Hence, I tried running
> zero-inflated
> > negative binomial mixed models using glmmADMB, which failed (mixed
> because
> > I have multiple values per individual). Following was the error I kept
> > encountering: "function maximizer failed" (attaching a text file with
> > details of this model by keeping debug=TRUE).
> >
> > Hence, I shifted to glmmTMB (version: 0.2.0), on Dr. Bolker's advice, and
> > it worked! But the problem is, when I try bootstrapping the model using
> to
> > obtain confidence intervals, I keep getting the following error after
> > varying number of runs: 'Error in optimHess(par.fixed, obj$fn, obj$gr):
> > gradient in optim evaluated to length 1 not 5'. This non-parametric
> > bootstrapping routine involves for loops in which the model is run using
> > bootstrapped groups (belonging to the grouping variable; individual.id
> in
> > my case) and the model coefficients thus obtained constitute the
> confidence
> > intervals. I've tried running 10,000 iterations, but the error pops up
> > within 10 to 100 runs.
> >
> > Does anyone have suggestions regarding what can be changed?
> >
> > Details of the model run singly and not in the loop:
> >
> > Family: nbinom2 ( log )
> > Formula: movement.whole ~ poc + (1 | female.id)
> > Zero inflation: ~1
> > Data: incrisk_females_comm
> >
> > AIC BIC logLik deviance df.resid
> > 1725.1 1745.9 -857.5 1715.1 474
> >
> > Random effects:
> >
> > Conditional model:
> > Groups Name Variance Std.Dev.
> > female.id (Intercept) 0.07924 0.2815
> > Number of obs: 479, groups: female.id, 110
> >
> > Overdispersion parameter for nbinom2 family (): 1.59
> >
> > Conditional model:
> > Estimate Std. Error z value Pr(>|z|)
> > (Intercept) 4.66384 0.14161 32.93 <2e-16 ***
> > poc -0.08815 0.20978 -0.42 0.674
> > ---
> > Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Zero-inflation model:
> > Estimate Std. Error z value Pr(>|z|)
> > (Intercept) 1.2442 0.1098 11.34 <2e-16 ***
> >
> > Please do mention if you need further details. Thank you in advance.
> >
> > Viraj Torsekar,
> > PhD Candidate,
> > Centre for Ecological Sciences,
> > Indian Institute of Science
> >
> > [[alternative HTML version deleted]]
> >
> >
> >
> > ------------------------------
> >
> > End of R-sig-mixed-models Digest, Vol 136, Issue 19
> > ***************************************************
> >
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> Confidentiality Notice This message is sent from Zelis. This transmission
> may contain information which is privileged and confidential and is
> intended for the personal and confidential use of the named recipient only.
> Such information may be protected by applicable State and Federal laws from
> this disclosure or unauthorized use. If the reader of this message is not
> the intended recipient, or the employee or agent responsible for delivering
> the message to the intended recipient, you are hereby notified that any
> disclosure, review, discussion, copying, or taking any action in reliance
> on the contents of this transmission is strictly prohibited. If you have
> received this transmission in error, please contact the sender immediately.
> Zelis, 2018.
>

	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Wed May  2 11:56:45 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 2 May 2018 11:56:45 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAHr4Dyc9R2i0xyx2J7SRrjPbrHs0o60Nyr7B9gJVsu=dBq2ftw@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
 <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
 <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>
 <CAHr4Dyc9R2i0xyx2J7SRrjPbrHs0o60Nyr7B9gJVsu=dBq2ftw@mail.gmail.com>
Message-ID: <CAG_uk91AD66Ncxztkq+Z539BBeqkn1yF1m9uV=a4Hw3cJis+EQ@mail.gmail.com>

On 2 May 2018 at 00:27, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> Sorry, I forgot that lmer() (unlike lmer_alt() from the afex package)
> does not convert factors to numeric covariates when using the the
> double-bar notation!
> The model I was talking about would be:
>
> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
> VarCorr(m_zcp5)
>  Groups      Name        Std.Dev.
>  replicate   (Intercept) 6.2359
>  replicate.1 re1.recipe1 1.7034
>  replicate.2 re1.recipe2 0.0000
>  Residual                5.3775
>
> This model seems to differ (and I don't really understand why) from
> m_zcp6 which I think is equivalent to your m_zcp4:
> m_zcp6 <- lmer_alt(angle ~ recipe  + (0 + recipe || replicate), cake)
> VarCorr(m_zcp6)
>  Groups      Name        Std.Dev.
>  replicate   re1.recipeA 5.0429
>  replicate.1 re1.recipeB 6.6476
>  replicate.2 re1.recipeC 7.1727
>  Residual                5.4181
>
> anova(m_zcp6, m_zcp5, refit = FALSE)
> Data: data
> Models:
> m_zcp6: angle ~ recipe + ((0 + re1.recipeA | replicate) + (0 + re1.recipeB |
> m_zcp6:     replicate) + (0 + re1.recipeC | replicate))
> m_zcp5: angle ~ recipe + ((1 | replicate) + (0 + re1.recipe1 | replicate) +
> m_zcp5:     (0 + re1.recipe2 | replicate))
>        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> m_zcp6  7 1781.8 1807.0 -883.88   1767.8
> m_zcp5  7 1742.0 1767.2 -863.98   1728.0 39.807      0  < 2.2e-16 ***
>

Yes, m_zcp4 and m_zcp6 are identical.

For m_zcp5 I get:
m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
VarCorr(m_zcp5)
 Groups      Name        Std.Dev.
 replicate   (Intercept) 6.0528e+00
 replicate.1 re1.recipeB 5.8203e-07
 replicate.2 re1.recipeC 2.1303e+00
 Residual                5.4693e+00

and if we change the reference level for recipe we get yet another result:
cake2 <- cake
cake2$recipe <- relevel(cake2$recipe, "C")
m_zcp5b <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake2)
VarCorr(m_zcp5b)
 Groups      Name        Std.Dev.
 replicate   (Intercept) 6.5495e+00
 replicate.1 re1.recipeA 2.5561e+00
 replicate.2 re1.recipeB 1.0259e-07
 Residual                5.4061e+00
This instability indicates that something fishy is going on...

The correlation parameters are needed in the "default" representation:
(recipe | replicate) and (0 + recipe | replicate) are equivalent
because the correlation parameters make the "appropriate adjustments",
but (recipe || replicate) is _not_ the same as (0 + recipe ||
replicate) with afex::lmer_alt. I might take it as far as to say that
(recipe | replicate) is meaningful because it is a re-parameterization
of (0 + recipe | replicate). On the other hand, while the diagonal
variance-covariance matrix parameterized by (0 + recipe || replicate)
is meaningful, a model with (recipe || replicate) using afex::lmer_alt
does _not_ make sense to me (and does not represent a diagonal
variance-covariance matrix).

> Do m_zcp5 and Model3b estimate the same random effects in this case?

Well, Model3b makes sense while m_zcp5 does not, but Model3b estimates
more random effects than the others:
Model3b <- lmerTest::lmer(angle ~ recipe + (1 | replicate) + (1 |
recipe:replicate),
                          data=cake)
length(unlist(ranef(Model3b))) # 60
length(unlist(ranef(m_zcp4))) # 45 - same for m_zcp, m_zcp2 and m_zcp6
and Model2

> If not, what is the difference between m_zcp5 and Model3b (except for
> the fact that the variance depends on the
> recipe in m_zcp5) and which one is the more complex model?

There is no unique 'complexity' ordering, for example, Model3b use 2
random-effect variance-covariance parameters to represent 60 random
effects, while m_zcp4 (m_zcp2) use 3 (6) random-effect
variance-covariance parameters to represent 45 random effects. But
usually the relevant 'complexity' scale is the number of parameters,
cf. likelihood ratio tests, AIC, BIC etc. There are corner-cases,
however; if x1 and x2 are continuous then (1 + x1 + x2 | group) and
'(1 + x1 | group) + (1 + x2 | group)' both use 6 random-effect
variance-covariance parameters, but the models represent different
structures and you can argue that the latter formulation is less
complex than the former since it avoids the correlation between x1 and
x2.

Cheers,
Rune

> I would be glad if you could elaborate on this and help me and the
> others understand these models.
>
> Cheers,
> Maarten
>


From maechler at stat.math.ethz.ch  Wed May  2 12:09:20 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 2 May 2018 12:09:20 +0200
Subject: [R-sig-ME] nlmer error "pwrss failed to converge"
In-Reply-To: <74cfb51987e1475d844393dd1a52b71b@UUSALE0A.utcmail.com>
References: <74cfb51987e1475d844393dd1a52b71b@UUSALE0A.utcmail.com>
Message-ID: <23273.36432.130545.20531@stat.math.ethz.ch>

>>>>> Louisell, Paul T PW  ........ on Wed, 2 May 2018 writes

(to the lme4-Authors)

    > Hi,
    > I'm using 64-bit R-3.5.0 on a Windows 7 platform. I'm also using the most recent version of lme4 (2018-04-03 21:41:32 UTC). Here's the error I get:

    > Error in devfun(rho$pp$theta) : prss failed to converge in 300 iterations

    > I can't find anywhere where the user has control over this parameter (prss). Is there any way to increase the number of iterations?

I assume you have looked at ?lmer which on the topic of
"control" points to ?lmerControl.
Both help pages, unfortunately, do not mention "prss" so this is
very reasonable question

However, ?lmer documents it argument `verbose` as

 verbose: integer scalar.  If '> 0' verbose output is generated during
          the optimization of the parameter estimates.  If '> 1'
          verbose output is generated during the individual PIRLS steps.

and you can take PIRLS (Penalized Iteratively Reweighted Least-Squares)
as "synonymous" here to PRSS (Penalized Residual Sum of Squares).

- In this case, you can actually not change the 300 iteration max
  (it is currently hard coded in the C++ code)

- I strongly recommend using  'verbose = 1' or even '= 2'.

- Please give us much more details, notably about your model
  formula, your data, e.g. the result of  str(.) and maybe
  summary(.)


    > Thanks in advance for any help you can give,

    > Paul Louisell
    > Statistical Specialist
    > .....

I hope the above does help further.

Also, I've taken the liberty to answer in this public
R-SIG-Mixed-Models mailing list, so others can help too and also
that others will find this answer in the future..

Best regards,

Martin Maechler
ETH Zurich


From Maarten.Jung at mailbox.tu-dresden.de  Wed May  2 17:42:36 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Wed, 2 May 2018 17:42:36 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAG_uk91AD66Ncxztkq+Z539BBeqkn1yF1m9uV=a4Hw3cJis+EQ@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
 <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
 <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>
 <CAHr4Dyc9R2i0xyx2J7SRrjPbrHs0o60Nyr7B9gJVsu=dBq2ftw@mail.gmail.com>
 <CAG_uk91AD66Ncxztkq+Z539BBeqkn1yF1m9uV=a4Hw3cJis+EQ@mail.gmail.com>
Message-ID: <CAHr4DydppA6YWNajuxYy-og_gmHVHAEQ5P5ZojABMwVr9RODCQ@mail.gmail.com>

Thank you for explaining this. This is *very* interesting.
As far as I understand, m_zcp5 is the model Reinhold Kliegl uses in
this RPub article[1] (actually m_zcp7 which should be identical). Also
Barr et al. (2013)[2], Bates et al. (2015)[3] and Matuschek et al.
(2017)[4] suggest similar models as the first step for model
reduction. However, their categorical independent variables have only
two levels and they work with crossed random effects.

cake3 <- cake
cake3 <- subset(cake3, recipe != "C")
cake3recipe<?factor(cake3recipe<?factor(cake3recipe)
contrasts(cake3recipe) <- c(0.5, -0.5)  # Barr and Matuschek use
effect coding  m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe ||
replicate), cake3) VarCorr(m_zcp5)  Groups      Name        Std.Dev.
replicate   (Intercept) 5.8077    replicate.1 re1.recipe1 1.8601
Residual                5.5366   cake3recipe) <- c(0.5, -0.5)  # Barr
and Matuschek use effect coding  m_zcp5 <- lmer_alt(angle ~ recipe  +
(recipe || replicate), cake3) VarCorr(m_zcp5)  Groups      Name
Std.Dev.  replicate   (Intercept) 5.8077    replicate.1 re1.recipe1
1.8601    Residual                5.5366   cake3recipe_numeric <-
ifelse(cake3$recipe == "A", 0.5, -0.5)
m_zcp7 <- lmer(angle ~ recipe_numeric + (1|replicate) + (0 +
recipe_numeric|replicate), cake3)
VarCorr(m_zcp7)
 Groups      Name           Std.Dev.
 replicate   (Intercept)    5.8077
 replicate.1 recipe_numeric 1.8601
 Residual                   5.5366

Besides that, Reinhold Kliegl reduces m_zcp5 to Model3b - i.e. (recipe
|| replicate) to (1 | replicate) + (1 | recipe:replicate).
Whereas you, If I understand correctly, suggest reducing/comparing (0
+ recipe || replicate) to (1 | recipe:replicate).
Why is that? Am I missing something?

Cheers,
Maarten

[1] https://rpubs.com/Reinhold/22193
[2] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/
[3] https://arxiv.org/abs/1506.04967 vignettes here:
https://github.com/dmbates/RePsychLing/tree/master/vignettes
[4] https://arxiv.org/abs/1511.01864

On Wed, May 2, 2018 at 11:56 AM, Rune Haubo <rune.haubo at gmail.com> wrote:
> On 2 May 2018 at 00:27, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>> Sorry, I forgot that lmer() (unlike lmer_alt() from the afex package)
>> does not convert factors to numeric covariates when using the the
>> double-bar notation!
>> The model I was talking about would be:
>>
>> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
>> VarCorr(m_zcp5)
>>  Groups      Name        Std.Dev.
>>  replicate   (Intercept) 6.2359
>>  replicate.1 re1.recipe1 1.7034
>>  replicate.2 re1.recipe2 0.0000
>>  Residual                5.3775
>>
>> This model seems to differ (and I don't really understand why) from
>> m_zcp6 which I think is equivalent to your m_zcp4:
>> m_zcp6 <- lmer_alt(angle ~ recipe  + (0 + recipe || replicate), cake)
>> VarCorr(m_zcp6)
>>  Groups      Name        Std.Dev.
>>  replicate   re1.recipeA 5.0429
>>  replicate.1 re1.recipeB 6.6476
>>  replicate.2 re1.recipeC 7.1727
>>  Residual                5.4181
>>
>> anova(m_zcp6, m_zcp5, refit = FALSE)
>> Data: data
>> Models:
>> m_zcp6: angle ~ recipe + ((0 + re1.recipeA | replicate) + (0 + re1.recipeB |
>> m_zcp6:     replicate) + (0 + re1.recipeC | replicate))
>> m_zcp5: angle ~ recipe + ((1 | replicate) + (0 + re1.recipe1 | replicate) +
>> m_zcp5:     (0 + re1.recipe2 | replicate))
>>        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>> m_zcp6  7 1781.8 1807.0 -883.88   1767.8
>> m_zcp5  7 1742.0 1767.2 -863.98   1728.0 39.807      0  < 2.2e-16 ***
>>
>
> Yes, m_zcp4 and m_zcp6 are identical.
>
> For m_zcp5 I get:
> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
> VarCorr(m_zcp5)
>  Groups      Name        Std.Dev.
>  replicate   (Intercept) 6.0528e+00
>  replicate.1 re1.recipeB 5.8203e-07
>  replicate.2 re1.recipeC 2.1303e+00
>  Residual                5.4693e+00
>
> and if we change the reference level for recipe we get yet another result:
> cake2 <- cake
> cake2$recipe <- relevel(cake2$recipe, "C")
> m_zcp5b <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake2)
> VarCorr(m_zcp5b)
>  Groups      Name        Std.Dev.
>  replicate   (Intercept) 6.5495e+00
>  replicate.1 re1.recipeA 2.5561e+00
>  replicate.2 re1.recipeB 1.0259e-07
>  Residual                5.4061e+00
> This instability indicates that something fishy is going on...
>
> The correlation parameters are needed in the "default" representation:
> (recipe | replicate) and (0 + recipe | replicate) are equivalent
> because the correlation parameters make the "appropriate adjustments",
> but (recipe || replicate) is _not_ the same as (0 + recipe ||
> replicate) with afex::lmer_alt. I might take it as far as to say that
> (recipe | replicate) is meaningful because it is a re-parameterization
> of (0 + recipe | replicate). On the other hand, while the diagonal
> variance-covariance matrix parameterized by (0 + recipe || replicate)
> is meaningful, a model with (recipe || replicate) using afex::lmer_alt
> does _not_ make sense to me (and does not represent a diagonal
> variance-covariance matrix).
>
>> Do m_zcp5 and Model3b estimate the same random effects in this case?
>
> Well, Model3b makes sense while m_zcp5 does not, but Model3b estimates
> more random effects than the others:
> Model3b <- lmerTest::lmer(angle ~ recipe + (1 | replicate) + (1 |
> recipe:replicate),
>                           data=cake)
> length(unlist(ranef(Model3b))) # 60
> length(unlist(ranef(m_zcp4))) # 45 - same for m_zcp, m_zcp2 and m_zcp6
> and Model2
>
>> If not, what is the difference between m_zcp5 and Model3b (except for
>> the fact that the variance depends on the
>> recipe in m_zcp5) and which one is the more complex model?
>
> There is no unique 'complexity' ordering, for example, Model3b use 2
> random-effect variance-covariance parameters to represent 60 random
> effects, while m_zcp4 (m_zcp2) use 3 (6) random-effect
> variance-covariance parameters to represent 45 random effects. But
> usually the relevant 'complexity' scale is the number of parameters,
> cf. likelihood ratio tests, AIC, BIC etc. There are corner-cases,
> however; if x1 and x2 are continuous then (1 + x1 + x2 | group) and
> '(1 + x1 | group) + (1 + x2 | group)' both use 6 random-effect
> variance-covariance parameters, but the models represent different
> structures and you can argue that the latter formulation is less
> complex than the former since it avoids the correlation between x1 and
> x2.
>
> Cheers,
> Rune
>
>> I would be glad if you could elaborate on this and help me and the
>> others understand these models.
>>
>> Cheers,
>> Maarten
>>


From Maarten.Jung at mailbox.tu-dresden.de  Wed May  2 17:50:41 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Wed, 2 May 2018 17:50:41 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAG_uk91AD66Ncxztkq+Z539BBeqkn1yF1m9uV=a4Hw3cJis+EQ@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
 <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
 <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>
 <CAHr4Dyc9R2i0xyx2J7SRrjPbrHs0o60Nyr7B9gJVsu=dBq2ftw@mail.gmail.com>
 <CAG_uk91AD66Ncxztkq+Z539BBeqkn1yF1m9uV=a4Hw3cJis+EQ@mail.gmail.com>
Message-ID: <CAHr4DydRmQgqkWrLQGs-3oKJAahP5AHzLw0Vfb5jh7qoAJc5EQ@mail.gmail.com>

Thank you for explaining this. This is *very* interesting.
As far as I understand, m_zcp5 is the model Reinhold Kliegl uses in
this RPub article[1] (actually m_zcp7 which should be identical). Also
Barr et al. (2013)[2], Bates et al. (2015)[3] and Matuschek et al.
(2017)[4] suggest similar models as the first step for model
reduction. However, their categorical independent variables have only
two levels and they work with crossed random effects.

cake3 <- cake
cake3 <- subset(cake3, recipe != "C")
cake3$recipe <- factor(cake3$recipe)
contrasts(cake3$recipe) <- c(0.5, -0.5)  # Barr and Matuschek use effect coding
m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake3)
VarCorr(m_zcp5)
 Groups      Name        Std.Dev.
 replicate   (Intercept) 5.8077
 replicate.1 re1.recipe1 1.8601
 Residual                5.5366

cake3$recipe_numeric <- ifelse(cake3$recipe == "A", 0.5, -0.5)
m_zcp7 <- lmer(angle ~ recipe_numeric + (1|replicate) + (0 +
recipe_numeric|replicate), cake3)
VarCorr(m_zcp7)
 Groups      Name           Std.Dev.
 replicate   (Intercept)    5.8077
 replicate.1 recipe_numeric 1.8601
 Residual                   5.5366

Besides that, Reinhold Kliegl reduces m_zcp5 to Model3b - i.e. (recipe
|| replicate) to (1 | replicate) + (1 | recipe:replicate).
Whereas you, If I understand correctly, suggest reducing/comparing (0
+ recipe || replicate) to (1 | recipe:replicate).
Why is that? Am I missing something?

Cheers,
Maarten

[1] https://rpubs.com/Reinhold/22193
[2] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/
[3] https://arxiv.org/abs/1506.04967 vignettes here:
https://github.com/dmbates/RePsychLing/tree/master/vignettes
[4] https://arxiv.org/abs/1511.01864

On Wed, May 2, 2018 at 11:56 AM, Rune Haubo <rune.haubo at gmail.com> wrote:
> On 2 May 2018 at 00:27, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>> Sorry, I forgot that lmer() (unlike lmer_alt() from the afex package)
>> does not convert factors to numeric covariates when using the the
>> double-bar notation!
>> The model I was talking about would be:
>>
>> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
>> VarCorr(m_zcp5)
>>  Groups      Name        Std.Dev.
>>  replicate   (Intercept) 6.2359
>>  replicate.1 re1.recipe1 1.7034
>>  replicate.2 re1.recipe2 0.0000
>>  Residual                5.3775
>>
>> This model seems to differ (and I don't really understand why) from
>> m_zcp6 which I think is equivalent to your m_zcp4:
>> m_zcp6 <- lmer_alt(angle ~ recipe  + (0 + recipe || replicate), cake)
>> VarCorr(m_zcp6)
>>  Groups      Name        Std.Dev.
>>  replicate   re1.recipeA 5.0429
>>  replicate.1 re1.recipeB 6.6476
>>  replicate.2 re1.recipeC 7.1727
>>  Residual                5.4181
>>
>> anova(m_zcp6, m_zcp5, refit = FALSE)
>> Data: data
>> Models:
>> m_zcp6: angle ~ recipe + ((0 + re1.recipeA | replicate) + (0 + re1.recipeB |
>> m_zcp6:     replicate) + (0 + re1.recipeC | replicate))
>> m_zcp5: angle ~ recipe + ((1 | replicate) + (0 + re1.recipe1 | replicate) +
>> m_zcp5:     (0 + re1.recipe2 | replicate))
>>        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>> m_zcp6  7 1781.8 1807.0 -883.88   1767.8
>> m_zcp5  7 1742.0 1767.2 -863.98   1728.0 39.807      0  < 2.2e-16 ***
>>
>
> Yes, m_zcp4 and m_zcp6 are identical.
>
> For m_zcp5 I get:
> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
> VarCorr(m_zcp5)
>  Groups      Name        Std.Dev.
>  replicate   (Intercept) 6.0528e+00
>  replicate.1 re1.recipeB 5.8203e-07
>  replicate.2 re1.recipeC 2.1303e+00
>  Residual                5.4693e+00
>
> and if we change the reference level for recipe we get yet another result:
> cake2 <- cake
> cake2$recipe <- relevel(cake2$recipe, "C")
> m_zcp5b <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake2)
> VarCorr(m_zcp5b)
>  Groups      Name        Std.Dev.
>  replicate   (Intercept) 6.5495e+00
>  replicate.1 re1.recipeA 2.5561e+00
>  replicate.2 re1.recipeB 1.0259e-07
>  Residual                5.4061e+00
> This instability indicates that something fishy is going on...
>
> The correlation parameters are needed in the "default" representation:
> (recipe | replicate) and (0 + recipe | replicate) are equivalent
> because the correlation parameters make the "appropriate adjustments",
> but (recipe || replicate) is _not_ the same as (0 + recipe ||
> replicate) with afex::lmer_alt. I might take it as far as to say that
> (recipe | replicate) is meaningful because it is a re-parameterization
> of (0 + recipe | replicate). On the other hand, while the diagonal
> variance-covariance matrix parameterized by (0 + recipe || replicate)
> is meaningful, a model with (recipe || replicate) using afex::lmer_alt
> does _not_ make sense to me (and does not represent a diagonal
> variance-covariance matrix).
>
>> Do m_zcp5 and Model3b estimate the same random effects in this case?
>
> Well, Model3b makes sense while m_zcp5 does not, but Model3b estimates
> more random effects than the others:
> Model3b <- lmerTest::lmer(angle ~ recipe + (1 | replicate) + (1 |
> recipe:replicate),
>                           data=cake)
> length(unlist(ranef(Model3b))) # 60
> length(unlist(ranef(m_zcp4))) # 45 - same for m_zcp, m_zcp2 and m_zcp6
> and Model2
>
>> If not, what is the difference between m_zcp5 and Model3b (except for
>> the fact that the variance depends on the
>> recipe in m_zcp5) and which one is the more complex model?
>
> There is no unique 'complexity' ordering, for example, Model3b use 2
> random-effect variance-covariance parameters to represent 60 random
> effects, while m_zcp4 (m_zcp2) use 3 (6) random-effect
> variance-covariance parameters to represent 45 random effects. But
> usually the relevant 'complexity' scale is the number of parameters,
> cf. likelihood ratio tests, AIC, BIC etc. There are corner-cases,
> however; if x1 and x2 are continuous then (1 + x1 + x2 | group) and
> '(1 + x1 | group) + (1 + x2 | group)' both use 6 random-effect
> variance-covariance parameters, but the models represent different
> structures and you can argue that the latter formulation is less
> complex than the former since it avoids the correlation between x1 and
> x2.
>
> Cheers,
> Rune
>
>> I would be glad if you could elaborate on this and help me and the
>> others understand these models.
>>
>> Cheers,
>> Maarten
>>


From adam.sloth at yahoo.com  Thu May  3 21:34:47 2018
From: adam.sloth at yahoo.com (Adam Sloth)
Date: Thu, 3 May 2018 21:34:47 +0200
Subject: [R-sig-ME] what units are MCMCglmm posterior means in?
Message-ID: <CAC395P5_jBDc0RjgeLXMX87sy_6shHMYJ_4s4KKb2345qUG8uQ@mail.gmail.com>

my question is probably amateurish but I can't seem to find the answer
anywhere.

In what metric are the MCMCglmm package's posterior means for family =
"categorical"?

I suppose that they can't be odds ratios and probabilites as my numbers are
outside their bounds. So I'm thinking ? are they just basic regression
coefficients conceptually equal to those obtained by lme4::glmer?

Thank you!

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri May  4 06:50:48 2018
From: j.hadfield at ed.ac.uk (HADFIELD Jarrod)
Date: Fri, 4 May 2018 04:50:48 +0000
Subject: [R-sig-ME] what units are MCMCglmm posterior means in?
In-Reply-To: <CAC395P5_jBDc0RjgeLXMX87sy_6shHMYJ_4s4KKb2345qUG8uQ@mail.gmail.com>
References: <CAC395P5_jBDc0RjgeLXMX87sy_6shHMYJ_4s4KKb2345qUG8uQ@mail.gmail.com>
Message-ID: <5CA0DDF9-C923-4A31-AD2F-6FA47626AED5@ed.ac.uk>

Hi, 

They are the log of the odds ratio as in standard logistic regression.

Cheers,

Jarrod
 

> On 3 May 2018, at 20:34, Adam Sloth via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> 
> my question is probably amateurish but I can't seem to find the answer
> anywhere.
> 
> In what metric are the MCMCglmm package's posterior means for family =
> "categorical"?
> 
> I suppose that they can't be odds ratios and probabilites as my numbers are
> outside their bounds. So I'm thinking ? are they just basic regression
> coefficients conceptually equal to those obtained by lme4::glmer?
> 
> Thank you!
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rune.haubo at gmail.com  Fri May  4 09:56:55 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Fri, 4 May 2018 09:56:55 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAHr4DydRmQgqkWrLQGs-3oKJAahP5AHzLw0Vfb5jh7qoAJc5EQ@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
 <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
 <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>
 <CAHr4Dyc9R2i0xyx2J7SRrjPbrHs0o60Nyr7B9gJVsu=dBq2ftw@mail.gmail.com>
 <CAG_uk91AD66Ncxztkq+Z539BBeqkn1yF1m9uV=a4Hw3cJis+EQ@mail.gmail.com>
 <CAHr4DydRmQgqkWrLQGs-3oKJAahP5AHzLw0Vfb5jh7qoAJc5EQ@mail.gmail.com>
Message-ID: <CAG_uk91Y1G5ZiNR=zN8n0qAXarjsCoGb1VH=uKm_yPR2wVRkTg@mail.gmail.com>

On 2 May 2018 at 17:50, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> Thank you for explaining this. This is *very* interesting.
> As far as I understand, m_zcp5 is the model Reinhold Kliegl uses in
> this RPub article[1] (actually m_zcp7 which should be identical). Also
> Barr et al. (2013)[2], Bates et al. (2015)[3] and Matuschek et al.
> (2017)[4] suggest similar models as the first step for model
> reduction. However, their categorical independent variables have only
> two levels and they work with crossed random effects.

I haven't read those articles recently in enough detail that I can comment.

>
> cake3 <- cake
> cake3 <- subset(cake3, recipe != "C")
> cake3$recipe <- factor(cake3$recipe)
> contrasts(cake3$recipe) <- c(0.5, -0.5)  # Barr and Matuschek use effect coding
> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake3)
> VarCorr(m_zcp5)
>  Groups      Name        Std.Dev.
>  replicate   (Intercept) 5.8077
>  replicate.1 re1.recipe1 1.8601
>  Residual                5.5366
>
> cake3$recipe_numeric <- ifelse(cake3$recipe == "A", 0.5, -0.5)
> m_zcp7 <- lmer(angle ~ recipe_numeric + (1|replicate) + (0 +
> recipe_numeric|replicate), cake3)
> VarCorr(m_zcp7)
>  Groups      Name           Std.Dev.
>  replicate   (Intercept)    5.8077
>  replicate.1 recipe_numeric 1.8601
>  Residual                   5.5366

So m_zcp5 and m_zcp7 are identical but I don't see how they are
meaningful in this context. Looking at the random-effect design matrix

image(getME(m_zcp5, "Z")) # identical to image(getME(m_zcp7, "Z"))

you can see that this model estimates a random main effect for
replicate (i.e. (1 | replicate)) and then a random _slope_ for recipe
at each replicate (i.e. recipe in '(recipe || replicate)' is treated
as numeric rather than factor). As far as I can tell this random slope
model is _unrelated_ to models where recipe is treated as a factor
that we have discussed previously: It is a completely different model
and I don't see how it is relevant for this design. (Notice that
'recipe' is equivalent to 'recipe_numeric' in the fixed-effects, but
not so in the random-effects!)

>
> Besides that, Reinhold Kliegl reduces m_zcp5 to Model3b - i.e. (recipe
> || replicate) to (1 | replicate) + (1 | recipe:replicate).
> Whereas you, If I understand correctly, suggest reducing/comparing (0
> + recipe || replicate) to (1 | recipe:replicate).
> Why is that? Am I missing something?

If anything I would say that you should look at all relevant models
and choose the one that represents the best compromise between fit to
data and complexity :-) Likelihood ratio tests can be a helpful guide,
but take care not to formally compare/test models that are not nested.

Here is an example of a set of models and sequences in which they can
be compared with LR tests:

# Random main effect of replicate, no interaction:
fm1 <- lmer(angle ~ recipe + (1 | replicate), data=cake)
# Random interaction recipe:replicate; same variance across recipes;
no main effect:
fm2 <- lmer(angle ~ recipe + (1 | recipe:replicate), data=cake)
# Random interaction with different variances across recipes; no main effect:
fm3 <- lmer(angle ~ recipe +
              (0 + dummy(recipe, "A") | replicate) +
              (0 + dummy(recipe, "B") | replicate) +
              (0 + dummy(recipe, "C") | replicate), data=cake)
# Random main effect and interaction with same variance across recipes:
fm4 <- lmer(angle ~ recipe + (1 | replicate) + (1 | recipe:replicate),
data=cake)
# Random main effect and interaction with different variances across recipes:
fm5 <- lmer(angle ~ recipe + (1 | replicate) +
              (0 + dummy(recipe, "A") | replicate) +
              (0 + dummy(recipe, "B") | replicate) +
               (0 + dummy(recipe, "C") | replicate), data=cake)
# Multivariate structure that contains both main and interaction effects with
# different variances and correlations:
fm6 <- lmer(angle ~ recipe + (0 + recipe | replicate), data=cake)
# Same model, just re-parameterized:
# fm6b <- lmer(angle ~ recipe + (recipe | replicate), data=cake)
# fm6c <- lmer(angle ~ recipe + (1 | replicate) + (0 + recipe |
replicate), data=cake)
# fm6d <- lmer(angle ~ recipe + (1 | replicate) + (recipe |
replicate), data=cake)
# fm6e <- lmer(angle ~ recipe + (1 | recipe:replicate) + (recipe |
replicate), data=cake)
# anova(fm6, fm6b, fm6c, fm6d, fm6e, refit=FALSE) # fm6 = fm6b = fm6c
= fm6d = fm6e

Note that in fm4 and fm5 the random main and interaction effects are
independent, but in fm6 they are not.

No. parameters and log-likelihood/deviance of these models:
as.data.frame(anova(fm1, fm2, fm3, fm4, fm5, fm6,
refit=FALSE))[paste0("fm", 1:6), 1:5]
    Df      AIC      BIC    logLik deviance
fm1  5 1741.019 1759.011 -865.5097 1731.019
fm2  5 1776.967 1794.959 -883.4835 1766.967
fm3  7 1779.571 1804.760 -882.7857 1765.571
fm4  6 1741.067 1762.658 -864.5337 1729.067
fm5  8 1743.437 1772.224 -863.7185 1727.437
fm6 10 1741.003 1776.987 -860.5016 1721.003

The following nesting structure indicate sequences in which models can be
compares with LR tests (arrows indicate model simplification):
fm6 -> fm5 -> fm4 -> fm2
fm6 -> fm5 -> fm4 -> fm1
fm6 -> fm5 -> fm3 -> fm2

Note that fm3 and fm4 are not nested and simply represent different structures
and so no formal LR test is available. The same is true for fm1 and
fm2 as well as
fm1 and fm3.

In addition to these models there are others which are just not as
easily fitted with lmer (to the best of my knowledge) for example a
version of fm5 where the interaction random effect is specified with a
common covariance parameter on top of the 3 variances. Theoretically
there are many options here but obtaining the fits is often not
straight forward and usually no single fit is uniquely better than the
rest.

Cheers
Rune

>
> Cheers,
> Maarten
>
> [1] https://rpubs.com/Reinhold/22193
> [2] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/
> [3] https://arxiv.org/abs/1506.04967 vignettes here:
> https://github.com/dmbates/RePsychLing/tree/master/vignettes
> [4] https://arxiv.org/abs/1511.01864
>
> On Wed, May 2, 2018 at 11:56 AM, Rune Haubo <rune.haubo at gmail.com> wrote:
>> On 2 May 2018 at 00:27, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>> Sorry, I forgot that lmer() (unlike lmer_alt() from the afex package)
>>> does not convert factors to numeric covariates when using the the
>>> double-bar notation!
>>> The model I was talking about would be:
>>>
>>> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
>>> VarCorr(m_zcp5)
>>>  Groups      Name        Std.Dev.
>>>  replicate   (Intercept) 6.2359
>>>  replicate.1 re1.recipe1 1.7034
>>>  replicate.2 re1.recipe2 0.0000
>>>  Residual                5.3775
>>>
>>> This model seems to differ (and I don't really understand why) from
>>> m_zcp6 which I think is equivalent to your m_zcp4:
>>> m_zcp6 <- lmer_alt(angle ~ recipe  + (0 + recipe || replicate), cake)
>>> VarCorr(m_zcp6)
>>>  Groups      Name        Std.Dev.
>>>  replicate   re1.recipeA 5.0429
>>>  replicate.1 re1.recipeB 6.6476
>>>  replicate.2 re1.recipeC 7.1727
>>>  Residual                5.4181
>>>
>>> anova(m_zcp6, m_zcp5, refit = FALSE)
>>> Data: data
>>> Models:
>>> m_zcp6: angle ~ recipe + ((0 + re1.recipeA | replicate) + (0 + re1.recipeB |
>>> m_zcp6:     replicate) + (0 + re1.recipeC | replicate))
>>> m_zcp5: angle ~ recipe + ((1 | replicate) + (0 + re1.recipe1 | replicate) +
>>> m_zcp5:     (0 + re1.recipe2 | replicate))
>>>        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>>> m_zcp6  7 1781.8 1807.0 -883.88   1767.8
>>> m_zcp5  7 1742.0 1767.2 -863.98   1728.0 39.807      0  < 2.2e-16 ***
>>>
>>
>> Yes, m_zcp4 and m_zcp6 are identical.
>>
>> For m_zcp5 I get:
>> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
>> VarCorr(m_zcp5)
>>  Groups      Name        Std.Dev.
>>  replicate   (Intercept) 6.0528e+00
>>  replicate.1 re1.recipeB 5.8203e-07
>>  replicate.2 re1.recipeC 2.1303e+00
>>  Residual                5.4693e+00
>>
>> and if we change the reference level for recipe we get yet another result:
>> cake2 <- cake
>> cake2$recipe <- relevel(cake2$recipe, "C")
>> m_zcp5b <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake2)
>> VarCorr(m_zcp5b)
>>  Groups      Name        Std.Dev.
>>  replicate   (Intercept) 6.5495e+00
>>  replicate.1 re1.recipeA 2.5561e+00
>>  replicate.2 re1.recipeB 1.0259e-07
>>  Residual                5.4061e+00
>> This instability indicates that something fishy is going on...
>>
>> The correlation parameters are needed in the "default" representation:
>> (recipe | replicate) and (0 + recipe | replicate) are equivalent
>> because the correlation parameters make the "appropriate adjustments",
>> but (recipe || replicate) is _not_ the same as (0 + recipe ||
>> replicate) with afex::lmer_alt. I might take it as far as to say that
>> (recipe | replicate) is meaningful because it is a re-parameterization
>> of (0 + recipe | replicate). On the other hand, while the diagonal
>> variance-covariance matrix parameterized by (0 + recipe || replicate)
>> is meaningful, a model with (recipe || replicate) using afex::lmer_alt
>> does _not_ make sense to me (and does not represent a diagonal
>> variance-covariance matrix).
>>
>>> Do m_zcp5 and Model3b estimate the same random effects in this case?
>>
>> Well, Model3b makes sense while m_zcp5 does not, but Model3b estimates
>> more random effects than the others:
>> Model3b <- lmerTest::lmer(angle ~ recipe + (1 | replicate) + (1 |
>> recipe:replicate),
>>                           data=cake)
>> length(unlist(ranef(Model3b))) # 60
>> length(unlist(ranef(m_zcp4))) # 45 - same for m_zcp, m_zcp2 and m_zcp6
>> and Model2
>>
>>> If not, what is the difference between m_zcp5 and Model3b (except for
>>> the fact that the variance depends on the
>>> recipe in m_zcp5) and which one is the more complex model?
>>
>> There is no unique 'complexity' ordering, for example, Model3b use 2
>> random-effect variance-covariance parameters to represent 60 random
>> effects, while m_zcp4 (m_zcp2) use 3 (6) random-effect
>> variance-covariance parameters to represent 45 random effects. But
>> usually the relevant 'complexity' scale is the number of parameters,
>> cf. likelihood ratio tests, AIC, BIC etc. There are corner-cases,
>> however; if x1 and x2 are continuous then (1 + x1 + x2 | group) and
>> '(1 + x1 | group) + (1 + x2 | group)' both use 6 random-effect
>> variance-covariance parameters, but the models represent different
>> structures and you can argue that the latter formulation is less
>> complex than the former since it avoids the correlation between x1 and
>> x2.
>>
>> Cheers,
>> Rune
>>
>>> I would be glad if you could elaborate on this and help me and the
>>> others understand these models.
>>>
>>> Cheers,
>>> Maarten
>>>


From babayussifk at gmail.com  Fri May  4 18:38:46 2018
From: babayussifk at gmail.com (Kassim Baba Yussif)
Date: Fri, 4 May 2018 16:38:46 +0000
Subject: [R-sig-ME] MODELLING NON-CONSTANT VARIANCE OF FIXED EFFECTS IN
 LINEAR MIXED EFFECT MODEL
Message-ID: <CAH3UFiV3ghd2-=+fdgvwaDQKM2_Pm-RCh2ROrYuzNC4P9w+03g@mail.gmail.com>

Hello good day,
Please I am analyzing my data using mix model with the equation:

lmer(yield ~ environment + (1|genotype), data = MET).

How can I model non-constant error variance.

	[[alternative HTML version deleted]]


From henganl2 at illinois.edu  Fri May  4 20:30:50 2018
From: henganl2 at illinois.edu (Lin, Heng-An)
Date: Fri, 4 May 2018 18:30:50 +0000
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
Message-ID: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>

Hi all,

I am analyzing my data with following model,

model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)

in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).

But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.

So, I think i might make some mistake in the model in R...

Can anyone give me some suggestion?

Thanks in advance!

Heng-An

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri May  4 20:39:43 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 4 May 2018 14:39:43 -0400
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>
Message-ID: <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>

  This seems like a reasonable model specification.  Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different?  (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From henganl2 at illinois.edu  Fri May  4 21:36:57 2018
From: henganl2 at illinois.edu (Lin, Heng-An)
Date: Fri, 4 May 2018 19:36:57 +0000
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>,
 <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>
Message-ID: <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>

Thanks!!


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source

DF

Sum of Squares

Mean Square

Error DF

F Value

Pr > F

Treatment

4

46.196951

11.549238

8.0509

0.41

0.7954

Location

2

4670.979652

2335.489826

9.2885

44.74

<.0001

Location*Treatment

8

224.443332

28.055417

34

1.66

0.1442

Block(Location)

9

369.782487

41.086943

34

2.43

0.0295

Residual

34

574.051330

16.883863

.

.

.













And here is R output:


> anova(model_MW)
Analysis of Variance Table
               Df   Sum Sq  Mean Sq   F value
Treatment 4   34.847   8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?q: Ben Bolker [bbolker at gmail.com]
?H????: 2018?~5??4?? ?U?? 01:39
??: Lin, Heng-An
???: r-sig-mixed-models at r-project.org
?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

This seems like a reasonable model specification. Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different? (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From henganl2 at illinois.edu  Fri May  4 22:15:30 2018
From: henganl2 at illinois.edu (Lin, Heng-An)
Date: Fri, 4 May 2018 20:15:30 +0000
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>, 
 <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>,
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>
Message-ID: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C@CHIMBX6.ad.uillinois.edu>

**  Sorry I didn't notice that the format of the previous email was off, so I just send the same email again

 
Here is my SAS syntax and output : 

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

 Source                      Df   Sum_of_squares   F_value   
 Treatment                 4     46.196951           0.41
 Location                    2     4670.0979652     44.74
 Location*Treatment   8     224.44332           1.66
 Block (Location)         9     369.782487         2.43
 Residual                    34    574.051330


And here is R output: 

 
> anova(model_MW)
Analysis of Variance Table
               Df   Sum Sq  Mean Sq   F value
Treatment 4   34.847   8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.  
Maybe is because I use type III in SAS and in lmer is using REML? 

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer? 
I am really new to this, Thanks for your time! 

Heng-An 
________________________________________
?: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] ?? Lin, Heng-An [henganl2 at illinois.edu]
????: 2018?5?4? ?? 02:36
?: Ben Bolker
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

Thanks!!


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source

DF

Sum of Squares

Mean Square

Error DF

F Value

Pr > F

Treatment

4

46.196951

11.549238

8.0509

0.41

0.7954

Location

2

4670.979652

2335.489826

9.2885

44.74

<.0001

Location*Treatment

8

224.443332

28.055417

34

1.66

0.1442

Block(Location)

9

369.782487

41.086943

34

2.43

0.0295

Residual

34

574.051330

16.883863

.

.

.













And here is R output:


> anova(model_MW)
Analysis of Variance Table
               Df   Sum Sq  Mean Sq   F value
Treatment 4   34.847   8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?q: Ben Bolker [bbolker at gmail.com]
?H????: 2018?~5??4?? ?U?? 01:39
??: Lin, Heng-An
???: r-sig-mixed-models at r-project.org
?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

This seems like a reasonable model specification. Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different? (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]


From j.zavrakidis at nki.nl  Fri May  4 23:01:48 2018
From: j.zavrakidis at nki.nl (j.zavrakidis at nki.nl)
Date: Fri, 4 May 2018 21:01:48 +0000
Subject: [R-sig-ME] AR(1) structure with Satterthwaite correction
In-Reply-To: <1525467462548.33561@nki.nl>
References: <b1001397b00c447bbfe6fb5c08cef5e6@EXCH-D02.nki.nl>,
 <1525467462548.33561@nki.nl>
Message-ID: <1525467674613.60345@nki.nl>



Dear all,

I have a question which is half theoretical and half practical. 
I am working on longitudinal datasets with small sample sizes, which i analyze with mixed models. Now, i am aware of the possible corrections in such cases, Satterthwaite and Kenward-Rodger. I am also aware of the different covariance structures that you  can impose in the level-1 variance. 
And here comes my question: Can we combine these 2 ??
That is, when we are talking about longitudinal data it is very possible that measurements closer in time are more correlated than those who are further apart, and the AR(1) is a potential covariance structure. Hence, can i have a model where the residuals  are autocorellated for instance and at the same time I apply the Satterthwaite correction for the df's and consequently for the inferences of the fixed effects ? 
If the answer to that question is yes (as I assume it is), how can I do that in R ? I know that for the AR(1) structure i have to use the nlme package, and for the Satterthwaite correction the lmerTest package which actually uses the lmer package. Do i miss a package or an update to the previous that make the combination possible?
P.S. I found the following paper where they combines these 2 'techniques' in SAS...
https://www.jstor.org/stable/1400374?seq=1#page_scan_tab_contents? 
?
?
Kind regards,
?
John Zavrakidis
?
Junior Researcher - Statistician
Department of Epidemiology and Biostatistics
?
e-mail:? j.zavrakidis at nki.nl
?
?
?

?
The Netherlands Cancer Institute | Plesmanlaan 121 | 1066 CX AMSTERDAM | www.nki.nl
?

?
 
?
This e-mail is intended for the addressee(s) eyes only. If you are not the intended recipient, you are hereby kindly requested to inform the sender of this. In view of the electronic  nature of this communication, The Netherlands Cancer Institute (NKI) is neither liable for the proper and complete transmission of the information contained therein nor for any delay in its receipt. For information about the Netherlands Cancer Institute, go  to www.nki.nl.
?
 
?
Dit e-mailbericht is uitsluitend bestemd voor de geadresseerde(n). Als dit bericht niet voor u bestemd is, wordt u vriendelijk verzocht dit aan de afzender te melden. Het  Antoni van Leeuwenhoek? (AVL) staat door de elektronische verzending van dit bericht niet in voor de juiste en volledige overbrenging van de inhoud, noch voor tijdige ontvangst daarvan. Voor informatie over het AVL raadpleegt u www.avl.nl
?
 ?
       

From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Sat May  5 18:11:29 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Sat, 05 May 2018 16:11:29 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAG_uk91Y1G5ZiNR=zN8n0qAXarjsCoGb1VH=uKm_yPR2wVRkTg@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
 <CAHr4Dyc6yh6=ErpUgt-Qqbh6bRvtSW_UhHcPtKjbokzaszGyVQ@mail.gmail.com>
 <CAG_uk904KgS07xXyagaXKuJfG6G5jnDqMQBurOC4h-GCo=Qp5w@mail.gmail.com>
 <CAHr4Dyc9R2i0xyx2J7SRrjPbrHs0o60Nyr7B9gJVsu=dBq2ftw@mail.gmail.com>
 <CAG_uk91AD66Ncxztkq+Z539BBeqkn1yF1m9uV=a4Hw3cJis+EQ@mail.gmail.com>
 <CAHr4DydRmQgqkWrLQGs-3oKJAahP5AHzLw0Vfb5jh7qoAJc5EQ@mail.gmail.com>
 <CAG_uk91Y1G5ZiNR=zN8n0qAXarjsCoGb1VH=uKm_yPR2wVRkTg@mail.gmail.com>
Message-ID: <CAHr4DyfEwap=3cmSGLtQ4_DVY-v_44O=6Zj9iEFP-ih0_at=gQ@mail.gmail.com>

What you suggest makes perfect sense to me.
Many thanks for your efforts and for taking time to explain the issues that
come with these models!

That said, I wonder what other mixed model experts think about m_zcp5 when
there are only categorical independent variables (i.e. factors) and
therefore I cc'd some of the aforementioned  authors. Comments on this are
highly welcome.

Cheers,
Maarten

On Fri, May 4, 2018, 09:56 Rune Haubo <rune.haubo at gmail.com> wrote:

> On 2 May 2018 at 17:50, Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de>
> wrote:
> > Thank you for explaining this. This is *very* interesting.
> > As far as I understand, m_zcp5 is the model Reinhold Kliegl uses in
> > this RPub article[1] (actually m_zcp7 which should be identical). Also
> > Barr et al. (2013)[2], Bates et al. (2015)[3] and Matuschek et al.
> > (2017)[4] suggest similar models as the first step for model
> > reduction. However, their categorical independent variables have only
> > two levels and they work with crossed random effects.
>
> I haven't read those articles recently in enough detail that I can comment.
>
> >
> > cake3 <- cake
> > cake3 <- subset(cake3, recipe != "C")
> > cake3$recipe <- factor(cake3$recipe)
> > contrasts(cake3$recipe) <- c(0.5, -0.5)  # Barr and Matuschek use effect
> coding
> > m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake3)
> > VarCorr(m_zcp5)
> >  Groups      Name        Std.Dev.
> >  replicate   (Intercept) 5.8077
> >  replicate.1 re1.recipe1 1.8601
> >  Residual                5.5366
> >
> > cake3$recipe_numeric <- ifelse(cake3$recipe == "A", 0.5, -0.5)
> > m_zcp7 <- lmer(angle ~ recipe_numeric + (1|replicate) + (0 +
> > recipe_numeric|replicate), cake3)
> > VarCorr(m_zcp7)
> >  Groups      Name           Std.Dev.
> >  replicate   (Intercept)    5.8077
> >  replicate.1 recipe_numeric 1.8601
> >  Residual                   5.5366
>
> So m_zcp5 and m_zcp7 are identical but I don't see how they are
> meaningful in this context. Looking at the random-effect design matrix
>
> image(getME(m_zcp5, "Z")) # identical to image(getME(m_zcp7, "Z"))
>
> you can see that this model estimates a random main effect for
> replicate (i.e. (1 | replicate)) and then a random _slope_ for recipe
> at each replicate (i.e. recipe in '(recipe || replicate)' is treated
> as numeric rather than factor). As far as I can tell this random slope
> model is _unrelated_ to models where recipe is treated as a factor
> that we have discussed previously: It is a completely different model
> and I don't see how it is relevant for this design. (Notice that
> 'recipe' is equivalent to 'recipe_numeric' in the fixed-effects, but
> not so in the random-effects!)
>
> >
> > Besides that, Reinhold Kliegl reduces m_zcp5 to Model3b - i.e. (recipe
> > || replicate) to (1 | replicate) + (1 | recipe:replicate).
> > Whereas you, If I understand correctly, suggest reducing/comparing (0
> > + recipe || replicate) to (1 | recipe:replicate).
> > Why is that? Am I missing something?
>
> If anything I would say that you should look at all relevant models
> and choose the one that represents the best compromise between fit to
> data and complexity :-) Likelihood ratio tests can be a helpful guide,
> but take care not to formally compare/test models that are not nested.
>
> Here is an example of a set of models and sequences in which they can
> be compared with LR tests:
>
> # Random main effect of replicate, no interaction:
> fm1 <- lmer(angle ~ recipe + (1 | replicate), data=cake)
> # Random interaction recipe:replicate; same variance across recipes;
> no main effect:
> fm2 <- lmer(angle ~ recipe + (1 | recipe:replicate), data=cake)
> # Random interaction with different variances across recipes; no main
> effect:
> fm3 <- lmer(angle ~ recipe +
>               (0 + dummy(recipe, "A") | replicate) +
>               (0 + dummy(recipe, "B") | replicate) +
>               (0 + dummy(recipe, "C") | replicate), data=cake)
> # Random main effect and interaction with same variance across recipes:
> fm4 <- lmer(angle ~ recipe + (1 | replicate) + (1 | recipe:replicate),
> data=cake)
> # Random main effect and interaction with different variances across
> recipes:
> fm5 <- lmer(angle ~ recipe + (1 | replicate) +
>               (0 + dummy(recipe, "A") | replicate) +
>               (0 + dummy(recipe, "B") | replicate) +
>                (0 + dummy(recipe, "C") | replicate), data=cake)
> # Multivariate structure that contains both main and interaction effects
> with
> # different variances and correlations:
> fm6 <- lmer(angle ~ recipe + (0 + recipe | replicate), data=cake)
> # Same model, just re-parameterized:
> # fm6b <- lmer(angle ~ recipe + (recipe | replicate), data=cake)
> # fm6c <- lmer(angle ~ recipe + (1 | replicate) + (0 + recipe |
> replicate), data=cake)
> # fm6d <- lmer(angle ~ recipe + (1 | replicate) + (recipe |
> replicate), data=cake)
> # fm6e <- lmer(angle ~ recipe + (1 | recipe:replicate) + (recipe |
> replicate), data=cake)
> # anova(fm6, fm6b, fm6c, fm6d, fm6e, refit=FALSE) # fm6 = fm6b = fm6c
> = fm6d = fm6e
>
> Note that in fm4 and fm5 the random main and interaction effects are
> independent, but in fm6 they are not.
>
> No. parameters and log-likelihood/deviance of these models:
> as.data.frame(anova(fm1, fm2, fm3, fm4, fm5, fm6,
> refit=FALSE))[paste0("fm", 1:6), 1:5]
>     Df      AIC      BIC    logLik deviance
> fm1  5 1741.019 1759.011 -865.5097 1731.019
> fm2  5 1776.967 1794.959 -883.4835 1766.967
> fm3  7 1779.571 1804.760 -882.7857 1765.571
> fm4  6 1741.067 1762.658 -864.5337 1729.067
> fm5  8 1743.437 1772.224 -863.7185 1727.437
> fm6 10 1741.003 1776.987 -860.5016 1721.003
>
> The following nesting structure indicate sequences in which models can be
> compares with LR tests (arrows indicate model simplification):
> fm6 -> fm5 -> fm4 -> fm2
> fm6 -> fm5 -> fm4 -> fm1
> fm6 -> fm5 -> fm3 -> fm2
>
> Note that fm3 and fm4 are not nested and simply represent different
> structures
> and so no formal LR test is available. The same is true for fm1 and
> fm2 as well as
> fm1 and fm3.
>
> In addition to these models there are others which are just not as
> easily fitted with lmer (to the best of my knowledge) for example a
> version of fm5 where the interaction random effect is specified with a
> common covariance parameter on top of the 3 variances. Theoretically
> there are many options here but obtaining the fits is often not
> straight forward and usually no single fit is uniquely better than the
> rest.
>
> Cheers
> Rune
>
> >
> > Cheers,
> > Maarten
> >
> > [1] https://rpubs.com/Reinhold/22193
> > [2] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/
> > [3] https://arxiv.org/abs/1506.04967 vignettes here:
> > https://github.com/dmbates/RePsychLing/tree/master/vignettes
> > [4] https://arxiv.org/abs/1511.01864
> >
> > On Wed, May 2, 2018 at 11:56 AM, Rune Haubo <rune.haubo at gmail.com>
> wrote:
> >> On 2 May 2018 at 00:27, Maarten Jung <
> Maarten.Jung at mailbox.tu-dresden.de> wrote:
> >>> Sorry, I forgot that lmer() (unlike lmer_alt() from the afex package)
> >>> does not convert factors to numeric covariates when using the the
> >>> double-bar notation!
> >>> The model I was talking about would be:
> >>>
> >>> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
> >>> VarCorr(m_zcp5)
> >>>  Groups      Name        Std.Dev.
> >>>  replicate   (Intercept) 6.2359
> >>>  replicate.1 re1.recipe1 1.7034
> >>>  replicate.2 re1.recipe2 0.0000
> >>>  Residual                5.3775
> >>>
> >>> This model seems to differ (and I don't really understand why) from
> >>> m_zcp6 which I think is equivalent to your m_zcp4:
> >>> m_zcp6 <- lmer_alt(angle ~ recipe  + (0 + recipe || replicate), cake)
> >>> VarCorr(m_zcp6)
> >>>  Groups      Name        Std.Dev.
> >>>  replicate   re1.recipeA 5.0429
> >>>  replicate.1 re1.recipeB 6.6476
> >>>  replicate.2 re1.recipeC 7.1727
> >>>  Residual                5.4181
> >>>
> >>> anova(m_zcp6, m_zcp5, refit = FALSE)
> >>> Data: data
> >>> Models:
> >>> m_zcp6: angle ~ recipe + ((0 + re1.recipeA | replicate) + (0 +
> re1.recipeB |
> >>> m_zcp6:     replicate) + (0 + re1.recipeC | replicate))
> >>> m_zcp5: angle ~ recipe + ((1 | replicate) + (0 + re1.recipe1 |
> replicate) +
> >>> m_zcp5:     (0 + re1.recipe2 | replicate))
> >>>        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> >>> m_zcp6  7 1781.8 1807.0 -883.88   1767.8
> >>> m_zcp5  7 1742.0 1767.2 -863.98   1728.0 39.807      0  < 2.2e-16 ***
> >>>
> >>
> >> Yes, m_zcp4 and m_zcp6 are identical.
> >>
> >> For m_zcp5 I get:
> >> m_zcp5 <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake)
> >> VarCorr(m_zcp5)
> >>  Groups      Name        Std.Dev.
> >>  replicate   (Intercept) 6.0528e+00
> >>  replicate.1 re1.recipeB 5.8203e-07
> >>  replicate.2 re1.recipeC 2.1303e+00
> >>  Residual                5.4693e+00
> >>
> >> and if we change the reference level for recipe we get yet another
> result:
> >> cake2 <- cake
> >> cake2$recipe <- relevel(cake2$recipe, "C")
> >> m_zcp5b <- lmer_alt(angle ~ recipe  + (recipe || replicate), cake2)
> >> VarCorr(m_zcp5b)
> >>  Groups      Name        Std.Dev.
> >>  replicate   (Intercept) 6.5495e+00
> >>  replicate.1 re1.recipeA 2.5561e+00
> >>  replicate.2 re1.recipeB 1.0259e-07
> >>  Residual                5.4061e+00
> >> This instability indicates that something fishy is going on...
> >>
> >> The correlation parameters are needed in the "default" representation:
> >> (recipe | replicate) and (0 + recipe | replicate) are equivalent
> >> because the correlation parameters make the "appropriate adjustments",
> >> but (recipe || replicate) is _not_ the same as (0 + recipe ||
> >> replicate) with afex::lmer_alt. I might take it as far as to say that
> >> (recipe | replicate) is meaningful because it is a re-parameterization
> >> of (0 + recipe | replicate). On the other hand, while the diagonal
> >> variance-covariance matrix parameterized by (0 + recipe || replicate)
> >> is meaningful, a model with (recipe || replicate) using afex::lmer_alt
> >> does _not_ make sense to me (and does not represent a diagonal
> >> variance-covariance matrix).
> >>
> >>> Do m_zcp5 and Model3b estimate the same random effects in this case?
> >>
> >> Well, Model3b makes sense while m_zcp5 does not, but Model3b estimates
> >> more random effects than the others:
> >> Model3b <- lmerTest::lmer(angle ~ recipe + (1 | replicate) + (1 |
> >> recipe:replicate),
> >>                           data=cake)
> >> length(unlist(ranef(Model3b))) # 60
> >> length(unlist(ranef(m_zcp4))) # 45 - same for m_zcp, m_zcp2 and m_zcp6
> >> and Model2
> >>
> >>> If not, what is the difference between m_zcp5 and Model3b (except for
> >>> the fact that the variance depends on the
> >>> recipe in m_zcp5) and which one is the more complex model?
> >>
> >> There is no unique 'complexity' ordering, for example, Model3b use 2
> >> random-effect variance-covariance parameters to represent 60 random
> >> effects, while m_zcp4 (m_zcp2) use 3 (6) random-effect
> >> variance-covariance parameters to represent 45 random effects. But
> >> usually the relevant 'complexity' scale is the number of parameters,
> >> cf. likelihood ratio tests, AIC, BIC etc. There are corner-cases,
> >> however; if x1 and x2 are continuous then (1 + x1 + x2 | group) and
> >> '(1 + x1 | group) + (1 + x2 | group)' both use 6 random-effect
> >> variance-covariance parameters, but the models represent different
> >> structures and you can argue that the latter formulation is less
> >> complex than the former since it avoids the correlation between x1 and
> >> x2.
> >>
> >> Cheers,
> >> Rune
> >>
> >>> I would be glad if you could elaborate on this and help me and the
> >>> others understand these models.
> >>>
> >>> Cheers,
> >>> Maarten
> >>>
>

	[[alternative HTML version deleted]]


From @tevedrd @ending from y@hoo@com  Mon May  7 13:14:53 2018
From: @tevedrd @ending from y@hoo@com (Steve Denham)
Date: Mon, 7 May 2018 11:14:53 +0000 (UTC)
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C@CHIMBX6.ad.uillinois.edu>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>
 <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C@CHIMBX6.ad.uillinois.edu>
Message-ID: <309243853.613635.1525691693783@mail.yahoo.com>

Hi Heng-An,
What do you get when you let SAS use the default REML method (i.e. remove the method=type3 statement)?? I suspect that it is much closer to the R results, and would be what most SAS modelers would consider more appropriate for this design.
Steve Denham Senior Director, Bioinformatics Sciences ?MPI Research, Inc. 

    On Friday, May 4, 2018, 4:16:04 PM EDT, Lin, Heng-An <henganl2 at illinois.edu> wrote:  
 
 **? Sorry I didn't notice that the format of the previous email was off, so I just send the same email again

 
Here is my SAS syntax and output : 

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

 Source? ? ? ? ? ? ? ? ? ? ? Df? Sum_of_squares? F_value? 
 Treatment? ? ? ? ? ? ? ? 4? ? 46.196951? ? ? ? ? 0.41
 Location? ? ? ? ? ? ? ? ? ? 2? ? 4670.0979652? ? 44.74
 Location*Treatment? 8? ? 224.44332? ? ? ? ? 1.66
 Block (Location)? ? ? ? 9? ? 369.782487? ? ? ? 2.43
 Residual? ? ? ? ? ? ? ? ? ? 34? ? 574.051330


And here is R output: 

 
> anova(model_MW)
Analysis of Variance Table
? ? ? ? ? ? ? Df? Sum Sq? Mean Sq? F value
Treatment 4? 34.847? 8.7118? ? ? 0.5085


I am not sure why the sum of square, and the F- value are different.? 
Maybe is because I use type III in SAS and in lmer is using REML? 

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer? 
I am really new to this, Thanks for your time! 

Heng-An 
________________________________________
?: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] ?? Lin, Heng-An [henganl2 at illinois.edu]
????: 2018?5?4? ?? 02:36
?: Ben Bolker
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

Thanks!!


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source

DF

Sum of Squares

Mean Square

Error DF

F Value

Pr > F

Treatment

4

46.196951

11.549238

8.0509

0.41

0.7954

Location

2

4670.979652

2335.489826

9.2885

44.74

<.0001

Location*Treatment

8

224.443332

28.055417

34

1.66

0.1442

Block(Location)

9

369.782487

41.086943

34

2.43

0.0295

Residual

34

574.051330

16.883863

.

.

.













And here is R output:


> anova(model_MW)
Analysis of Variance Table
? ? ? ? ? ? ? Df? Sum Sq? Mean Sq? F value
Treatment 4? 34.847? 8.7118? ? ? 0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
[[elided Yahoo spam]]

Heng-An
________________________________________
?q: Ben Bolker [bbolker at gmail.com]
?H????: 2018?~5??4?? ?U?? 01:39
??: Lin, Heng-An
???: r-sig-mixed-models at r-project.org
?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

This seems like a reasonable model specification. Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different? (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

? ? ? ? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  
	[[alternative HTML version deleted]]


From @d@m@@loth @ending from y@hoo@com  Mon May  7 20:00:04 2018
From: @d@m@@loth @ending from y@hoo@com (Adam Sloth)
Date: Mon, 7 May 2018 20:00:04 +0200
Subject: [R-sig-ME] MCMCglmm with flat prior vs. glmer
Message-ID: <CAC395P6fNoMtKFVJGYNKWGAPhepwz_RVY9go_eEb_EiGdOTKcQ@mail.gmail.com>

Hi,
is MCMC-based GLMM with flat prior basically just a robust variant of a
classical GLMM? I mean ? frequentist analyses work with a flat prior anyway
so the only difference should be in the more reliable method.

Am I right?

Thanks.

	[[alternative HTML version deleted]]


From heng@nl2 @ending from illinoi@@edu  Mon May  7 21:17:28 2018
From: heng@nl2 @ending from illinoi@@edu (Lin, Heng-An)
Date: Mon, 7 May 2018 19:17:28 +0000
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <309243853.613635.1525691693783@mail.yahoo.com>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>
 <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C@CHIMBX6.ad.uillinois.edu>,
 <309243853.613635.1525691693783@mail.yahoo.com>
Message-ID: <14FC5E11B32FB84FB0D08FE2F4127AFE2B5382A5@CHIMBX6.ad.uillinois.edu>

Hi Ben,

When I using SAS with default REML, it won't display the sum of square.
It only shows covariance parameter estimates for random effect,
for the fixed effect, it still using Type 3.

I am trying using the code below in r to see the difference
anova(model_MW, ddf="Kenward-Roger")
anova(model_MW, type=3)
anova(model_MW, type=3, ddf="Kenward-Roger")

________________________________
?: Steve Denham [stevedrd at yahoo.com]
????: 2018?5?7? ?? 06:14
?: Ben Bolker; Lin, Heng-An
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

Hi Heng-An,

What do you get when you let SAS use the default REML method (i.e. remove the method=type3 statement)?  I suspect that it is much closer to the R results, and would be what most SAS modelers would consider more appropriate for this design.

Steve Denham Senior Director, Bioinformatics Sciences  MPI Research, Inc.


On Friday, May 4, 2018, 4:16:04 PM EDT, Lin, Heng-An <henganl2 at illinois.edu> wrote:


**  Sorry I didn't notice that the format of the previous email was off, so I just send the same email again


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source                      Df  Sum_of_squares  F_value
Treatment                4    46.196951          0.41
Location                    2    4670.0979652    44.74
Location*Treatment  8    224.44332          1.66
Block (Location)        9    369.782487        2.43
Residual                    34    574.051330


And here is R output:


> anova(model_MW)
Analysis of Variance Table
              Df  Sum Sq  Mean Sq  F value
Treatment 4  34.847  8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>] ?? Lin, Heng-An [henganl2 at illinois.edu<mailto:henganl2 at illinois.edu>]
????: 2018?5?4? ?? 02:36
?: Ben Bolker
??: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term


Thanks!!


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source

DF

Sum of Squares

Mean Square

Error DF

F Value

Pr > F

Treatment

4

46.196951

11.549238

8.0509

0.41

0.7954

Location

2

4670.979652

2335.489826

9.2885

44.74

<.0001

Location*Treatment

8

224.443332

28.055417

34

1.66

0.1442

Block(Location)

9

369.782487

41.086943

34

2.43

0.0295

Residual

34

574.051330

16.883863

.

.

.













And here is R output:


> anova(model_MW)
Analysis of Variance Table
              Df  Sum Sq  Mean Sq  F value
Treatment 4  34.847  8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?q: Ben Bolker [bbolker at gmail.com<mailto:bbolker at gmail.com>]
?H????: 2018?~5??4?? ?U?? 01:39
??: Lin, Heng-An
???: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

This seems like a reasonable model specification. Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different? (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu<mailto:henganl2 at illinois.edu>> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From heng@nl2 @ending from illinoi@@edu  Mon May  7 21:19:17 2018
From: heng@nl2 @ending from illinoi@@edu (Lin, Heng-An)
Date: Mon, 7 May 2018 19:19:17 +0000
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <309243853.613635.1525691693783@mail.yahoo.com>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>
 <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C@CHIMBX6.ad.uillinois.edu>,
 <309243853.613635.1525691693783@mail.yahoo.com>
Message-ID: <14FC5E11B32FB84FB0D08FE2F4127AFE2B5382DC@CHIMBX6.ad.uillinois.edu>

Hi,

When I using SAS with default REML, it won't display the sum of square.
It only shows covariance parameter estimates for random effect,
for the fixed effect, it still using Type 3.

I am trying using the code below in r to see the difference
anova(model_MW, ddf="Kenward-Roger")
anova(model_MW, type=3)
anova(model_MW, type=3, ddf="Kenward-Roger")
________________________________
?: Steve Denham [stevedrd at yahoo.com]
????: 2018?5?7? ?? 06:14
?: Ben Bolker; Lin, Heng-An
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

Hi Heng-An,

What do you get when you let SAS use the default REML method (i.e. remove the method=type3 statement)?  I suspect that it is much closer to the R results, and would be what most SAS modelers would consider more appropriate for this design.

Steve Denham Senior Director, Bioinformatics Sciences  MPI Research, Inc.


On Friday, May 4, 2018, 4:16:04 PM EDT, Lin, Heng-An <henganl2 at illinois.edu> wrote:


**  Sorry I didn't notice that the format of the previous email was off, so I just send the same email again


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source                      Df  Sum_of_squares  F_value
Treatment                4    46.196951          0.41
Location                    2    4670.0979652    44.74
Location*Treatment  8    224.44332          1.66
Block (Location)        9    369.782487        2.43
Residual                    34    574.051330


And here is R output:


> anova(model_MW)
Analysis of Variance Table
              Df  Sum Sq  Mean Sq  F value
Treatment 4  34.847  8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>] ?? Lin, Heng-An [henganl2 at illinois.edu<mailto:henganl2 at illinois.edu>]
????: 2018?5?4? ?? 02:36
?: Ben Bolker
??: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term


Thanks!!


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source

DF

Sum of Squares

Mean Square

Error DF

F Value

Pr > F

Treatment

4

46.196951

11.549238

8.0509

0.41

0.7954

Location

2

4670.979652

2335.489826

9.2885

44.74

<.0001

Location*Treatment

8

224.443332

28.055417

34

1.66

0.1442

Block(Location)

9

369.782487

41.086943

34

2.43

0.0295

Residual

34

574.051330

16.883863

.

.

.













And here is R output:


> anova(model_MW)
Analysis of Variance Table
              Df  Sum Sq  Mean Sq  F value
Treatment 4  34.847  8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?q: Ben Bolker [bbolker at gmail.com<mailto:bbolker at gmail.com>]
?H????: 2018?~5??4?? ?U?? 01:39
??: Lin, Heng-An
???: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

This seems like a reasonable model specification. Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different? (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu<mailto:henganl2 at illinois.edu>> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From heng@nl2 @ending from illinoi@@edu  Mon May  7 21:39:33 2018
From: heng@nl2 @ending from illinoi@@edu (Lin, Heng-An)
Date: Mon, 7 May 2018 19:39:33 +0000
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <309243853.613635.1525691693783@mail.yahoo.com>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>
 <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C@CHIMBX6.ad.uillinois.edu>,
 <309243853.613635.1525691693783@mail.yahoo.com>
Message-ID: <14FC5E11B32FB84FB0D08FE2F4127AFE2B538320@CHIMBX6.ad.uillinois.edu>

Hi,

When I using SAS with default REML, it won't display the sum of square.
It only shows covariance parameter estimates for random effect,
for the fixed effect, it still using Type 3.

I am trying using the code below in r to see the difference with smaller and balanced data set
anova(model_MW, ddf="Kenward-Roger")
anova(model_MW, type=3)
anova(model_MW, type=3, ddf="Kenward-Roger")


here is what I got in R

> anova(model_Test, type="3", ddf="Kenward-Roger")
Type III Analysis of Variance Table with Kenward-Roger's method
                   Sum Sq   Mean Sq   NumDF    DenDF    F value     Pr(>F)
Treatment    60.219    15.055     4             4            0.8347     0.5674



and in SAS  (with type3 and KR method)
                 df     Sum Sq     F value  p-value
Treatment   4     78.9246    0.81      0.5801

They seems more similar for F and P value, but the Sum sq still different...not sure why
Sorry for sending repeating email.

Thanks for your time again.
________________________________
?: Steve Denham [stevedrd at yahoo.com]
????: 2018?5?7? ?? 06:14
?: Ben Bolker; Lin, Heng-An
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

Hi Heng-An,

What do you get when you let SAS use the default REML method (i.e. remove the method=type3 statement)?  I suspect that it is much closer to the R results, and would be what most SAS modelers would consider more appropriate for this design.

Steve Denham Senior Director, Bioinformatics Sciences  MPI Research, Inc.


On Friday, May 4, 2018, 4:16:04 PM EDT, Lin, Heng-An <henganl2 at illinois.edu> wrote:


**  Sorry I didn't notice that the format of the previous email was off, so I just send the same email again


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source                      Df  Sum_of_squares  F_value
Treatment                4    46.196951          0.41
Location                    2    4670.0979652    44.74
Location*Treatment  8    224.44332          1.66
Block (Location)        9    369.782487        2.43
Residual                    34    574.051330


And here is R output:


> anova(model_MW)
Analysis of Variance Table
              Df  Sum Sq  Mean Sq  F value
Treatment 4  34.847  8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>] ?? Lin, Heng-An [henganl2 at illinois.edu<mailto:henganl2 at illinois.edu>]
????: 2018?5?4? ?? 02:36
?: Ben Bolker
??: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term


Thanks!!


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source

DF

Sum of Squares

Mean Square

Error DF

F Value

Pr > F

Treatment

4

46.196951

11.549238

8.0509

0.41

0.7954

Location

2

4670.979652

2335.489826

9.2885

44.74

<.0001

Location*Treatment

8

224.443332

28.055417

34

1.66

0.1442

Block(Location)

9

369.782487

41.086943

34

2.43

0.0295

Residual

34

574.051330

16.883863

.

.

.













And here is R output:


> anova(model_MW)
Analysis of Variance Table
              Df  Sum Sq  Mean Sq  F value
Treatment 4  34.847  8.7118      0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time!

Heng-An
________________________________________
?q: Ben Bolker [bbolker at gmail.com<mailto:bbolker at gmail.com>]
?H????: 2018?~5??4?? ?U?? 01:39
??: Lin, Heng-An
???: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

This seems like a reasonable model specification. Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different? (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu<mailto:henganl2 at illinois.edu>> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @@muel@kn@pp @ending from tum@de  Mon May  7 22:53:39 2018
From: @@muel@kn@pp @ending from tum@de (Samuel Knapp)
Date: Mon, 7 May 2018 22:53:39 +0200
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53833D@CHIMBX6.ad.uillinois.edu>
References: <mailman.16459.2372.1525464947.1209.r-sig-mixed-models@r-project.org>
 <81cdfac5-91a2-f09c-9ca7-b39b28b2b26e@tum.de>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B53833D@CHIMBX6.ad.uillinois.edu>
Message-ID: <34ce818d-a565-8419-153a-943114c5646f@tum.de>

Hi Heng-An,

it is good practice to reply also to the mailing list in Cc.

Is this dataset fully balanced now? What is the number of levels of each 
of the factors and what is the number of total observations now?

Why is the SAS ANOVA now only containing the fixed effect, while before 
it also contained the random effects? Did you change any other model 
statements?

It is really strange, that the estimates differ.

Could you please report also the estimated variances? See summary(model) 
in R and the beginning of the SAS output. It should be 4 variances (one 
for each random effecct and the residual variance).

One more thing, will you get same results for Satterthwaite ddf?

Best regards,
Samuel



On 07/05/18 21:42, Lin, Heng-An wrote:
> Hi Samuel,
>
> Thanks for the suggestion, that's really helpful.
>
> so I tried to use the code below in r to see the difference with smaller and balanced data set
> here is what I got in R
>
>> anova(model_Test, type="3", ddf="Kenward-Roger")
> Type III Analysis of Variance Table with Kenward-Roger's method
>                     Sum Sq   Mean Sq   NumDF    DenDF    F value     Pr(>F)
> Treatment    60.219    15.055     4             4            0.8347     0.5674
>
>
> and in SAS  (with type3 and KR method)
>                   df     Sum Sq     F value  p-value
> Treatment   4     78.9246    0.81      0.5801
>
> They seems more similar for F and P value, but the Sum sq still different...not sure why
> Sorry for sending repeating email.
>
> Thanks for your time again.
> ________________________________________
> ?: Samuel Knapp [samuel.knapp at tum.de]
> ????: 2018?5?7? ?? 03:39
> ?: Lin, Heng-An
> ??: r-sig-mixed-models-request at r-project.org
> ??: Re: [R-sig-ME] Mixed linear model with nested and interaction term
>
> Hi Heng-An,
>
> The SAS model specification seems to be in accordance with the lmer
> model. However, I'm slightly surprised, that the SAS ANOVA also contains
> the random effects.
>
> Looking at the degrees of freedom, I get the impression that your data
> is not fully orthogonal, e.g. that you don't have the same number of
> reps at each location or some missing values. If you dont't have fully
> orthogonal and balanced data (i.e. n obs = n treatments * n locations *
> n replications), there could be differences between different SS methods
> (Type 1, 2 or 3) or df methods (Kenward-Roger, Satterthwaite).
>
> In order to test that, you could
> 1) create an orthogonal and balanced subset of your data and compare
> results.
> 2) Test other df methods in R with the lmerTest package
>       library(lmerTest)
>       anova(model_MW, ddf="Satterthwaite")
>       # or
>       anova(model_MW, ddf="Kenward-Roger")
> 3) Test other SS methods in R, also implemented now in the lmerTest package
>       anova(model_MW, type =1) # or type=2 or type=3
> 4) Test the same settings in SAS using the method statement in the proc
> mixed call, and the ddfm statement in the model line.
>
> Additionally, to just simply playing around, also get familiar with the
> different concepts (The SAS documentation on proc mixed has quite a good
> overview). This shall rather be an overview on how to specify different
> options.
>
> I'd be interested, if you get similar results....
>
> Best regards,
> Samuel
>
>
>
> On 04/05/18 22:15, r-sig-mixed-models-request at r-project.org wrote:
>> Date: Fri, 4 May 2018 20:15:30 +0000
>> From: "Lin, Heng-An" <henganl2 at illinois.edu>
>> To: Ben Bolker <bbolker at gmail.com>
>> Cc: "r-sig-mixed-models at r-project.org"
>>        <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Mixed linear model with nested and interaction
>>        term
>> Message-ID:
>>        <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C at CHIMBX6.ad.uillinois.edu>
>> Content-Type: text/plain; charset="utf-8"
>>
>> **  Sorry I didn't notice that the format of the previous email was off, so I just send the same email again
>>
>>
>> Here is my SAS syntax and output :
>>
>> proc mixed data=A method=type3; class Location Block Treatment;
>> model Yield= Treatment/ddfm=kr;
>> random Location Location*Treatment Block(Location);
>> run;quit;
>>
>>    Source                      Df   Sum_of_squares   F_value
>>    Treatment                 4     46.196951           0.41
>>    Location                    2     4670.0979652     44.74
>>    Location*Treatment   8     224.44332           1.66
>>    Block (Location)         9     369.782487         2.43
>>    Residual                    34    574.051330
>>
>>
>> And here is R output:
>>
>>
>>> anova(model_MW)
>> Analysis of Variance Table
>>                  Df   Sum Sq  Mean Sq   F value
>> Treatment 4   34.847   8.7118      0.5085
>>
>>
>> I am not sure why the sum of square, and the F- value are different.
>> Maybe is because I use type III in SAS and in lmer is using REML?
>>
>> I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
>> I am really new to this, Thanks for your time!
>>
>> Heng-An
>>
>> ________________________________________
>> ?q: Ben Bolker [bbolker at gmail.com]
>> ?H????: 2018?~5??4?? ?U?? 01:39
>> ??: Lin, Heng-An
>> ???: r-sig-mixed-models at r-project.org
>> ?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term
>>
>> This seems like a reasonable model specification. Can you show us
>> the results you're getting from R and SAS, and your SAS syntax (some
>> people here understand that language), so that we can see what looks
>> different? (It would help if you also wrote a few sentences about
>> what you see as the important differences between the results.)
>>
>> On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu> wrote:
>>> Hi all,
>>>
>>> I am analyzing my data with following model,
>>>
>>> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>>>
>>> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>>>
>>> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>>>
>>> So, I think i might make some mistake in the model in R...
>>>
>>> Can anyone give me some suggestion?
>>>
>>> Thanks in advance!
>>>
>>> Heng-An
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>           [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Subject: Digest Footer
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> ------------------------------
>>
>> End of R-sig-mixed-models Digest, Vol 137, Issue 6
>> **************************************************


From @tevedrd @ending from y@hoo@com  Tue May  8 11:42:27 2018
From: @tevedrd @ending from y@hoo@com (Steve Denham)
Date: Tue, 8 May 2018 09:42:27 +0000 (UTC)
Subject: [R-sig-ME] Mixed linear model with nested and interaction term
In-Reply-To: <14FC5E11B32FB84FB0D08FE2F4127AFE2B538320@CHIMBX6.ad.uillinois.edu>
References: <14FC5E11B32FB84FB0D08FE2F4127AFE2B53742A@CHIMBX6.ad.uillinois.edu>
 <CABghstROfDNP3j3mOE_JGa5ipx3QYT2rpXUrJeUJ4_f1PfXhHg@mail.gmail.com>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B5374DC@CHIMBX6.ad.uillinois.edu>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B53751C@CHIMBX6.ad.uillinois.edu>
 <309243853.613635.1525691693783@mail.yahoo.com>
 <14FC5E11B32FB84FB0D08FE2F4127AFE2B538320@CHIMBX6.ad.uillinois.edu>
Message-ID: <1121034517.1030315.1525772547129@mail.yahoo.com>

The point of the REML method is that there are no sums of squares for the covariance effects.? In fact, there are no sums of squares for any of the effects.? Type III calculates covariance parameters using method of moments, while REML uses restricted maximum likelihood.
Steve Denham Senior Director, Bioinformatics Sciences ?MPI Research, Inc. 

    On Monday, May 7, 2018, 3:41:37 PM EDT, Lin, Heng-An <henganl2 at illinois.edu> wrote:  
 
 Hi,?

When I using SAS with default REML, it won't display the sum of square.?
It only shows covariance parameter estimates for random effect,?for the fixed effect, it still using Type 3.?

I am trying using the code below in r to see the difference with smaller and balanced data set?anova(model_MW, ddf="Kenward-Roger")anova(model_MW, type=3)anova(model_MW, type=3, ddf="Kenward-Roger")

here is what I got in R?
> anova(model_Test, type="3", ddf="Kenward-Roger")Type III Analysis of Variance Table with Kenward-Roger's method? ? ? ? ? ? ? ? ? ?Sum Sq? ?Mean Sq? ?NumDF? ? DenDF? ? F value? ? ?Pr(>F)Treatment? ? 60.219? ? 15.055? ? ?4? ? ? ? ? ? ?4? ? ? ? ? ? 0.8347? ? ?0.5674


and in SAS? (with type3 and KR method)? ? ? ? ? ? ? ? ?df? ? ?Sum Sq? ? ?F value? p-value?Treatment? ?4? ? ?78.9246? ? 0.81? ? ? 0.5801
They seems more similar for F and P value, but the Sum sq still different...not sure why?Sorry for sending repeating email.
Thanks for your time again.??: Steve Denham [stevedrd at yahoo.com]
????: 2018?5?7? ?? 06:14
?: Ben Bolker; Lin, Heng-An
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

Hi Heng-An,
What do you get when you let SAS use the default REML method (i.e. remove the method=type3 statement)?? I suspect that it is much closer to the R results, and would be what most SAS modelers would consider more appropriate for this design.
Steve Denham Senior Director, Bioinformatics Sciences ?MPI Research, Inc.

On Friday, May 4, 2018, 4:16:04 PM EDT, Lin, Heng-An <henganl2 at illinois.edu> wrote:

**? Sorry I didn't notice that the format of the previous email was off, so I just send the same email again


Here is my SAS syntax and output : 

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source? ? ? ? ? ? ? ? ? ? ? Df? Sum_of_squares? F_value? 
Treatment? ? ? ? ? ? ? ? 4? ? 46.196951? ? ? ? ? 0.41
Location? ? ? ? ? ? ? ? ? ? 2? ? 4670.0979652? ? 44.74
Location*Treatment? 8? ? 224.44332? ? ? ? ? 1.66
Block (Location)? ? ? ? 9? ? 369.782487? ? ? ? 2.43
Residual? ? ? ? ? ? ? ? ? ? 34? ? 574.051330


And here is R output: 


> anova(model_MW)
Analysis of Variance Table
? ? ? ? ? ? ? Df? Sum Sq? Mean Sq? F value
Treatment 4? 34.847? 8.7118? ? ? 0.5085


I am not sure why the sum of square, and the F- value are different.? 
Maybe is because I use type III in SAS and in lmer is using REML? 

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
I am really new to this, Thanks for your time! 

Heng-An 
________________________________________
?: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] ?? Lin, Heng-An [henganl2 at illinois.edu]
????: 2018?5?4? ?? 02:36
?: Ben Bolker
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

Thanks!!


Here is my SAS syntax and output :

proc mixed data=A method=type3; class Location Block Treatment;
model Yield= Treatment/ddfm=kr;
random Location Location*Treatment Block(Location);
run;quit;

Source

DF

Sum of Squares

Mean Square

Error DF

F Value

Pr > F

Treatment

4

46.196951

11.549238

8.0509

0.41

0.7954

Location

2

4670.979652

2335.489826

9.2885

44.74

<.0001

Location*Treatment

8

224.443332

28.055417

34

1.66

0.1442

Block(Location)

9

369.782487

41.086943

34

2.43

0.0295

Residual

34

574.051330

16.883863

.

.

.













And here is R output:


> anova(model_MW)
Analysis of Variance Table
? ? ? ? ? ? ? Df? Sum Sq? Mean Sq? F value
Treatment 4? 34.847? 8.7118? ? ? 0.5085


I am not sure why the sum of square, and the F- value are different.
Maybe is because I use type III in SAS and in lmer is using REML?

I would also like to check the sum of square of other factors as SAS did, is there any way could do this in lmer?
[[elided Yahoo spam]]

Heng-An
________________________________________
?q: Ben Bolker [bbolker at gmail.com]
?H????: 2018?~5??4?? ?U?? 01:39
??: Lin, Heng-An
???: r-sig-mixed-models at r-project.org
?D??: Re: [R-sig-ME] Mixed linear model with nested and interaction term

This seems like a reasonable model specification. Can you show us
the results you're getting from R and SAS, and your SAS syntax (some
people here understand that language), so that we can see what looks
different? (It would help if you also wrote a few sentences about
what you see as the important differences between the results.)

On Fri, May 4, 2018 at 2:30 PM, Lin, Heng-An <henganl2 at illinois.edu> wrote:
> Hi all,
>
> I am analyzing my data with following model,
>
> model1 <- lmer(Yield~Treatment+(1|Location)+(1|Location:Treatment)+(1|Location:Block), data=A)
>
> in here, I want to set an random interaction term (Location*treatment) and an random nested term (block nested within location).
>
> But I couldn't get similar ANOVA results when I compare the output with SAS porc mixed output.
>
> So, I think i might make some mistake in the model in R...
>
> Can anyone give me some suggestion?
>
> Thanks in advance!
>
> Heng-An
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

? ? ? ? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  
	[[alternative HTML version deleted]]


From n@fl@ib@ @ending from hotm@il@com  Tue May  8 23:06:02 2018
From: n@fl@ib@ @ending from hotm@il@com (Nicolas Flaibani)
Date: Tue, 8 May 2018 21:06:02 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41
In-Reply-To: <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
References: <mailman.16430.1866.1524692601.1209.r-sig-mixed-models@r-project.org>
 <BN6PR1701MB1732BBD5F5560D683C57FA1A8E8D0@BN6PR1701MB1732.namprd17.prod.outlook.com>,
 <CAG_uk934grrjf-oD8dW1hgSFFgakooULVaSrOWUm7z9WYd2W1g@mail.gmail.com>
Message-ID: <BN6PR1701MB173204741094A070E933AEBB8E9A0@BN6PR1701MB1732.namprd17.prod.outlook.com>


Hi, Rune,
Thank you, a lot, for answering so fast to my question (R-sig-mixed-models Digest, Vol 136, Issue 41). These days I?ve been reading the mails that you have been sending about how to investigate the interaction between random and fixed effects and how to estimate the variance components in these models.
To put the question and examples in context, I want to briefly comment the research subject of my laboratory. The working line that is developed here study different characters (morphological, physiological and behavioral) in several species of Drosophila. Because of its easy way of maintenance, Drosophila is perfect to generate isolines and have an accurate estimate of genetics components. For example, one of the working lines involucrates the study of the thorax or wing length (like estimators of body size) in fly raised at different temperatures for diverse genetic lines. One of the principal interests is the study of the interaction between the fixed effects variables (i. e. Temperature) and the random effect variable (Line) to study the genotype-phenotype interaction. In this sense, to further compare different populations we are interested in estimate the variance components (by percentages of variance explained by Line and the interaction Line*Temperature, qualitatively).

As you said ??Model1 can be fitted if X1 is a factor. In that case Model1 is rather complex and the number of parameters grows rapidly with the number of levels of X1 - in comparison the random term in Model2 uses just one (variance) parameter?, in the first place I am going to simplify the model to try to better understand.
So, as the first option, I decided to try a model like the Model 1:
mt <-lmer(Torax ~Temperature+Sex+ (Temperature|Line), data)
Random effects:
 Groups   Name          Variance Std.Dev. Corr
 Line     (Intercept)      49.27    7.019
          Temperature25 52.80    7.266    -0.55
 Residual                       19.21    4.383
Number of obs: 780, groups:  Linea, 49

In addition, trying to resume my interest in knowing which is the variance explained by the interaction Line*Temperature and by Line, I?ve arrived to these models:
mtb <- lmer(Torax ~Temperature +Sex+ (0+Temperature|Line), data) AIC=4814,43
Random effects:
 Groups   Name          Variance Std.Dev. Corr
 Line       Temperature17  49.27    7.019
               Temperature25  46.38    6.811    0.45
 Residual                   19.21    4.383
Number of obs: 780, groups:  Linea, 49

mtb2 <- lmer(Torax ~Temperature +Sex+ (Temperature||Line), data) AIC=4816,43
Random effects:
 Groups   Name          Variance Std.Dev. Corr
 Line     (Intercept)      22.41    4.734
 Line1   Temperature17  26.86    5.182
          Temperature25  23.97    4.896    -0.04
 Residual                 19.21    4.383
Number of obs: 780, groups:  Linea, 49
> AIC(mt,mtb,mtb2)
         df      AIC
mt    7 4814.428
mtb   7 4814.428
mtb2  8 4816.428

They have the same fixed effects, but the difference resides in how they expressed the variance components. So, if I?m interested in obtain the whole variance components (Line and Line*Temperature), do I need to run the mtb2 model? The other models aren?t useful? The difference between the three models is how we interpret and how they show us the variance?
On one hand, the difference between mtb and mtb2 is the existence of one parameter of variance related to Line? (If I want to estimate the variance for each component it will be Line=22.41 and Line:Temperature(26.86+23.97) or this last sum doesn?t make sense?)
It's very difficult for me to understand how to interpret the variance components in the models mt and mtb. In addition, in your first answer to Jung, you said ?First, '(recipe || replicate)' is the same as/expands to '(1 |replicate) + (0 + recipe | replicate)' which is just an over-parameterized version of '(0 + recipe | replicate)', which again is a re-parameterized version of '(recipe | replicate)'. These are all representing the same model (all on 10 df though lmer() is mislead and thinks that m_zcp has 11 df)??  I don?t understand why you said that the model (recipe || replicate) is over-parameterized, if it has the same parameters that (0 + recipe | replicate). Even if I notice that in the variance components I have different amounts of estimated variances, however I would not be seeing that this has an impact on the model worsening due to excess of estimated parameters. I do not know if I explain myself?
On the other hand, going back to your initial advice ?The point here is that we need to also consider Model3b as an alternative to Model1 and Model2. Of these models, Model3 _and_ Model2 are the simplest while Model1 is the most complex with Model3b in the middle often serving as an appropriate compromise..?  I run a model as
mt3 <- lmer(Torax ~ Sex +Temperature +(1|Line:Temperature),
AIC=4820.112
Random effects:
 Groups            Name        Variance Std.Dev.
 Line:Temperature (Intercept)  47.81    6.915
 Residual                       19.21    4.383
Number of obs: 780, groups:  Line:Temperature, 98

However, this syntax doesn?t let me see all variance components (doesn?t show Line). So, I decided to run another syntax.
mt3b <- lmer(Torax ~Sex +Temperature+ (1 | Line) +(1 | Temperature:Line),data)
Random effects:
Groups                       Name       Variance Std.Dev.
Temperature:Line  (Intercept) 26.40    5.138
Line                           (Intercept)  21.42    4.628
Residual                                         19.21    4.383
Number of obs: 780, groups:  Temperature:Line, 98; Linea, 49

If I compare all models:
           df      AIC
mt      7 4814.428
mtb    7 4814.428
mtb2  8 4816.428
mt3     5 4820.112
mt3b  6 4812.476

and only I focus in those that show me all variance components (Line and Line*Temperature, mtb2 and mt3b), can I choose the best model in function of AIC?
Going back to the general objective of estimate the variance components and evaluate the interaction between the random variables, my question is: the difference between the last models is that mtb2 is estimating 2 parameters more which correspond, on one hand, to the discrimination of the interaction?s variance of Line*Temperature in two components (Line*Temperature17 and Line*Temperature25) and on the other hand, to the correlation between those components. If this is correct, according to my objective, is more parsimonious mt3b? In adittion, the sum of the variance explained for the interaction Line*Temperature17 and Line*Temperature25 (if this make any sense) shouldn?t be similar or identical to the variance explained for Temperature:Line? Because if I compare those values I don?t see that happen.

Finally, in your last mail you enumerate different models that can be compared. I don?t understand the difference between the model fm5 and the model fm6c, I don?t know if you can clarify me a bit.

Thank you so much again for your patience and dedication.
Cheers,
Nicol?s.


________________________________
De: Rune Haubo <rune.haubo at gmail.com>
Enviado: s?bado, 28 de abril de 2018 06:32
Para: Nicolas Flaibani
Cc: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 136, Issue 41

On 27 April 2018 at 22:33, Nicolas Flaibani <n.flaiba at hotmail.com> wrote:
>
>  Hi everyone!
>
>
> I would like to join the discussion of the second topic (Specifying Multiple Random Effects in NLME by Dan) but in my case I?m going to talk about the lme4 package, instead of the nmle. I think that the question is still relevant.
>
> I?ve had a doubt for a long time about how to investigate the interactions between random and fixed effects. I?ve read a lot of forums, papers and help?s packages and I?ve always concluded that the correct form of testing the interaction between a random and a fixed variable was:
>
>
> Model1 <- lmer (Y ~ X1 + X2 + (X1 | Random Variable)
>
>
> However, I found in some forums and personal communications from several researchers that there is another way to investigate the interaction between random and fixed variables and has the following syntax:
>
>
> Model2 <- lmer (Y ~ X1 + X2 + (1 | Random Variable: X1)
>
The 'classical' (think DOE and 'variance-components') interaction is
Model2 if X1 is categorical/factor and Model1 if X1 is continuous
(then Model1 is sometimes called the 'random coefficient model').

If X1 is continuous Model2 doesn't make sense - on the other hand
Model1 can be fitted if X1 is a factor. In that case Model1 is rather
complex and the number of parameters grows rapidly with the number of
levels of X1 - in comparison the random term in Model2 uses just one
(variance) parameter. While some people often favour 'Model1 with
factor X1'- construction, I often think it is difficult to explain
what this model actually means; it is also very often overfitting
since it requires a lot of data and special data-generating mechanism
to support models of that form.

>
> I understand that this syntax
>
>
> (1|Random Variable/X1) = (1|Random Variable)+(1|Random Variable:X1)
>
>
> specify a nested structure between the variables and this is not the case of interest.

This construction serves two purposes: one is when the random-effect
variables have a 'truly' nested structure such as pupils in classes
(in schools, in districts, etc). The other purpose often applies to
designed experiments where you might have machines (fixed) and
operators (random). The main effects model is then

Model3 <- lmer(Y ~ machines + (1 | operators))

and a model that includes the interaction reads

Model3b <- lmer(Y ~ machines + (1 | operators) + (1 | machines:operators))

Technically the 'machines:operators' combinations are nested in
'operators' but we usually don't think of it that way.

The point here is that we need to also consider Model3b as an
alternative to Model1 and Model2. Of these models, Model3 _and_ Model2
are the simplest while Model1 is the most complex with Model3b in the
middle often serving as an appropriate compromise.

>
> My particular question is whether the syntax of the Model 2 is correct to test interactions between random and fixed variables. If this model is correct, which are the differences with the syntax of Model 1, since the resulting models are clearly different? Besides, in coincidence with the question of Dan (?Are there cases where one vs. the other formulation should absolutely be used? My understanding that for continuous variables, e.g., multiple measurements across multiple days, Days|Object would be the correct syntax. But here we're talking about a factor variable?), I ask if one type of syntax should be used if the fixed variables are continuous or there are factors.
>
> If I compare the summary from a model with the latter syntax (model 2), with the summary of the same analysis made with a statistic program (like Statistica), the results are very similar. That?s not the case with the model 1.
>
> For example, if I analyze a morphological trait with the syntax
>
>
> M2 <- lmer (Wing ~ Temperature * Sex + Temperature + Sex + (1 | Line) +   (1 | Line:Sex:Temperature) + (1 | Line:Sex) + (1 | Line:Temperature))
>
>
> the summary is the following:
>
>
> Random effects:
>
>  Groups                               Name        Variance Std.Dev.
>
>  Line:Sex:Temperature  (Intercept)  14.6231  3.8240
>
>  Line:Temperature          (Intercept) 154.7685 12.4406
>
>  Line:Sex                         (Intercept)   0.6947  0.8335
>
>  Line                                 (Intercept)  72.5945  8.5202
>
>  Residual                                             180.0664 13.4189
>
>
> Fixed effects:
>
>                     Estimate Std. Error      df t value                         Pr(>|t|)
>
> (Intercept)                  501.141      2.268  96.940 221.009       < 2e-16 ***
>
> Temperature25        -57.960      2.699  54.800 -21.473         < 2e-16 ***
>
> SexM                         -53.639      1.001  96.260 -53.584         < 2e-16 ***
>
> Temperature25:SexM   -6.488      1.391  48.300          -4.663 2.49e-05 ***
>
>
> I found that the function rand() from the lmerTest package gives me the p values of the random effects if I write the model like this:
>
>> rand(M2)
>
> Analysis of Random effects Table:
>
>
>                          Chi.sq Chi.DF p.value
>
> Line                    4.6152      1    0.03 *
>
> Line:Sex:Temperature  30.8130      1   3e-08 ***
>
> Line:Sex                             0.0391      1    0.84
>
> Line:Temperature          112.1539      1  <2e-16 ***
>
>
> I don?t know if this function is reliable because it is not mentioned for testing the significance of the random effects in the page https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html
GLMM FAQ - GitHub Pages<https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html>
bbolker.github.io
Introduction. This is an informal FAQ list for the r-sig-mixed-models mailing list.. The most commonly used functions for mixed modeling in R are. linear mixed models: aov(), nlme::lme 1, lme4::lmer;




Having written rand (=ranova) my views may be biased but I should say
that it _is_ reliable. That is, I haven't seen cases where it's not
doing what was intended ;-) rand() and ranova() simply compares two
models using anova(m1, m2, refit=FALSE) where m2 differs from m1 by
having one of its random-effect terms reduced or removed.

>
> The summary of the same analysis made with the Statistica is:
>
>
>
>
> Effect
>
> SS
>
> Degr. of
>
> MS
>
> Den.Syn.
>
> Den.Syn.
>
> F
>
> p
>
> Intercept
>
> Fixed
>
> 764579151
>
> 1
>
> 764579151
>
> 48,001
>
> 12655,91
>
> 60412,83
>
> 0,000000
>
> Line
>
> Random
>
> 608181
>
> 48
>
> 12670
>
> 47,800
>
> 6489,64
>
> 1,95
>
> 0,011254
>
> Sex
>
> Fixed
>
> 3138661
>
> 1
>
> 3138661
>
> 48,038
>
> 495,62
>
> 6332,81
>
> 0,000000
>
> Temperature
>
> Fixed
>
> 3686660
>
> 1
>
> 3686660
>
> 48,003
>
> 6459,62
>
> 570,72
>
> 0,000000
>
> Line*Sex
>
> Random
>
> 23808
>
> 48
>
> 496
>
> 48,000
>
> 473,30
>
> 1,05
>
> 0,435866
>
> Line*Temperature
>
> Random
>
> 310413
>
> 48
>
> 6467
>
> 48,000
>
> 473,30
>
> 13,66
>
> 0,000000
>
> Sex*Temperature
>
> Fixed
>
> 10075
>
> 1
>
> 10075
>
> 48,040
>
> 472,94
>
> 21,30
>
> 0,000029
>
> Line*Sex*Temperature
>
> Random
>
> 22718
>
> 48
>
> 473
>
> 3696,000
>
> 167,33
>
> 2,83
>
> 0,000000
>
> Error
>
> 618467
>
> 3696
>
> 167
>
>
>
>
> But if I write the model with the other syntax:
>
> M1 <- lmer(Wing ~ Temperature * Sex + (Temperature * Sex | Line))
>
Writing the model as
M1 <- lmer(Wing ~ Temperature * Sex + (0 + Temperature:Sex | Line))
is often preferable as it makes the random-effect variance-covariance
matrix easier to interpret.

>
>
> the summary is the following:
>
>
>
> REML criterion at convergence: 31440.9
>
>
>
> Random effects:
>
>  Groups   Name                Variance Std.Dev. Corr
>
>  Line    (Intercept)           266.78   16.333
>
>   Temperature25             398.27   19.957   -0.60
>
>    SexM                                41.54    6.446   -0.56  0.46
>
>   Temperature25:SexM  61.34    7.832    0.56 -0.61 -0.80
>
>  Residual                             167.33   12.936
>
>
>
> Fixed effects:
>
>                                              Estimate Std. Error         df t value             Pr(>|t|)
>
> (Intercept)                          501.603      2.371            48.046 211.586  < 2e-16 ***
>
> Temperature25               -58.423      2.911               48.027 -20.070  < 2e-16 ***
>
> SexM                                 -53.659      1.095              47.964 -49.023  < 2e-16 ***
>
> Temperature                    25:SexM   -6.470               1.393  48.278  -4.644 2.66e-05 ***
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>
> In addition, if I apply the ?rand function? for this syntax (M1), it doesn?t retourn the whole p-values of the random effects (Do not give me p value for line and line*Temperature*Sex)

Use lmerTest::ranova(M1, reduce.terms=FALSE) to achieve a test for the
entire random-effect term (and make sure you have lmerTest version >=
3.0-0 installed).

>
> Analysis of Random effects Table:
>
>                                              Chi.sq Chi.DF p.value
>
> Temperatura:L?nea 0.00e+00      0       1
>
> Sexo:L?nea             1.46e-10      0  <2e-16 ***
>
>
> I really appreciate your time and dedication for answering this questions. Thank you for trying to help us understand a little more about the syntax of these complex models and thus better understand their correct approach.

You are not alone if you think this is complicated. My students are
for the most part challenged in simply writing up the mathematical
formula that correctly represents models such as Model1 -
transitioning from scalar random-effect terms (e.g. Model3b) to
vector-valued random-effect terms (e.g. Model1) often takes time and
dedication.

Cheers
Rune

>
> Thank you very much for your time everyone.
>
>
>
> Greetings,
>
> Nicolas
>
>
> ----------------------------------------------------------------------------------------
> Message: 2
> Date: Wed, 25 Apr 2018 16:11:38 -0400
> From: Dan <ieshan at gmail.com>
> To: "R-SIG-Mixed-Models at R-project.org"
>         <R-sig-mixed-models at r-project.org>, Ben Bolker <bbolker at gmail.com>
> Subject: [R-sig-ME] Specifying Multiple Random Effects in NLME
> Message-ID:
>         <CAET4i1f-SH5zA6xcCxNXc091HCk+snMv+rFm0tf995yYukiCOw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi all:
>
> I am curating an off-list thread about specifying multiple random effects
> in NLME.
>
> 1.  If it's (1|Object) + (1|Object:Coating) that you want then
> you should be able to use a nested specification (which nlme *can*
> handle relatively easily), i.e. something like
>
> random=a+b+c~1|Object/Coating
>
>
> Although (Coating|Object) and (1|Object:Coating) both in some sense
> represent "interactions" the latter is *much* simpler/more parsimonious.
>
> If you're OK with 1|Object:Coating rather than Coating|Object it
> should be *much* faster.  If you don't understand the distinction (which
> would be absolutely fine and understandable) can we resume the
> discussion on r-sig-mixed-models ... ?
> -----------
>
> So:
> random=a+b+c~Coating|Object
> does not fit.
>
> But:
> random=a+b+c~Object/Coating
> fits.
>
> Can you better explain the distinction here? I have sometimes used the
> 1|Object:Coating + 1|Object syntax and sometimes the Coating|Object syntax
> in other models. My experience/understanding is that the former syntax with
> multiple "within subject" variables produces exactly matching output to the
> standard "repeated measures ANOVA" with the lmer assumption of compound
> symmetry.
>
> Are there cases where one vs. the other formulation should absolutely be
> used? My understanding that for continuous variables, e.g., multiple
> measurements across multiple days, Days|Object would be the correct syntax.
> But here we're talking about a factor variable.
>
>
> 2.   I'm trying to read the "random" section for nlme right now but it's
> kind of making my head explode (and I think there's a typo: " the same
> as the order of the order of the elements in the list").  It *sounds*
> like (1) explicitly creating an interaction
> ObjCoating=interaction(Object,Coating) and (2) using something like
>
>   list(ObjCoating=a~1,Object=b~1,Object=c~1)
>
> should work (grouping factors as names, then [right-hand-side variable
> name]~[random effects model], but I'm worried about the phrase "The
> order of nesting will be assumed the same as the order of the elements
> in the list": what nesting?
> -----------
>
> I think that formulation is explicitly in order. I replaced your first
> ObjCoating with simply Object, just to test what would happen:
>
> Random effects:
>  Formula: a ~ 1 | Object
>         a.(Intercept)
> StdDev:      1.305816
>
>  Formula: b ~ 1 | Object %in% Object
>         b.(Intercept)
> StdDev:    0.01576521
>
>  Formula: c ~ 1 | Object %in% Object %in% Object
>         c.(Intercept) Residual
> StdDev:      2.677883 2.219676
>
>         [[alternative HTML version deleted]]
>
>
>
>
> *****
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From p@uljohn32 @ending from gm@il@com  Wed May  9 19:22:48 2018
From: p@uljohn32 @ending from gm@il@com (Paul Johnson)
Date: Wed, 9 May 2018 12:22:48 -0500
Subject: [R-sig-ME] rBind in lme4
Message-ID: <CAErODj--nGnc1NEVkJU8An8bduG_jYjU6MgVC0mdnmcKPmHzfw@mail.gmail.com>

Dear maintainers:

I got a note from CRAN today saying one of my packages will be removed
because it accesses rBind via lme4.

Did you get the same message?

Dear maintainer,

Please see the problems shown on
<https://cran.r-project.org/web/checks/check_results_rockchalk.html>.

Please correct before 2018-05-23 to safely retain your package on CRAN.

Best,
-k




-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From vicrot@@ @ending from gm@il@com  Wed May  9 20:16:48 2018
From: vicrot@@ @ending from gm@il@com (Victoria Ortiz)
Date: Wed, 9 May 2018 15:16:48 -0300
Subject: [R-sig-ME] Question about continuous distributions in GLMM
In-Reply-To: <44db0ee5-ef31-0a7c-0389-a21c7ba44881@gmail.com>
References: <CAEpo04=QK+9yWW4_n669rYtCLiOxGBxk=V6mnTa9PNgfvK3D6Q@mail.gmail.com>
 <CAEpo04k1UdkK2TWPByX7OnkRmXWbdECMjkKeFysz6gKYPACCKg@mail.gmail.com>
 <44db0ee5-ef31-0a7c-0389-a21c7ba44881@gmail.com>
Message-ID: <CAEpo04np5hjea=j1Yz8D1u8mxyu2Sf8GHxSeiYQJzWBqALiOWA@mail.gmail.com>

 Hi,
I'm so sorry for the delay in the response, I was with a lot of work.

With "variance components" I mean the partition of the total variance into
the different factors that explain it. Our interest is to have a
quantification of the portion of the variance explained by the different
factors, both random and fixed. Translated to the biology of our data, this
means to estimate genetic, genotype x environment variation, and
environment variation of the total phenotypic variation for a given trait
in a population. In particular, the objective is to compare this estimators
between diferent populations analyzed separately.

Additionaly, reading another topics of this mail list, I found that the
classical model for testing the interaction and obtain the variance
components would be a model like the following:

m2 <- lmer ( variable ~ fixed factor  1 * fixed factor 2 + (1 | random
factor) + (1 | fixed factor 1:random factor2) + (1 | fixed factor 2:random
factor) + (1| fixed factor 1:fixed factor 2:random factor))

So, with this model, in the summary I can see the partition of the total
variance of the random effects. Is this right?

Finally, if I want the p-values of the random effects, I should analize the
full and reduce models sequentially. Also, I found that another way to do
it is with the 'ranova' function from the lmerTest package, but the results
are very dissimilar. I don't know in wich analysis should I trust, I think
that in this case the sequentially one is correct.

Thank you for your time!
Victoria.

2018-04-27 17:08 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

>
>
> On 2018-04-26 07:45 PM, Victoria Ortiz wrote:
> > I write to ask a simple question about quantitative continuous variables
> > distributions. We have data for morphological traits in insects but they
> do
> > not fit any distribution in GLMM. The design has two fixed variables and
> a
> > random one. We are interested in the variance components of the random
> > variable and its interactions. We tried normal (lm4), gamma (glmer),
> > lognormal (GLMMPQL), tweedie (GLMMTMB) and compound poison (CPLM). There
> is
> > no good fit for any case. In fact, the better model using AIC is normal.
> The
> > residuals vs. predicted graphic and the Q-Q plot have the following
> > form: *https://github.com/vicrotas/Repositorio-de-Vicka/issues/1
> > <https://github.com/vicrotas/Repositorio-de-Vicka/issues/1>*
> >
>
>
>   I'm not quite sure what to suggest about the distribution.  Since this
> looks left-skewed, you might try a power transformation with g > 1 (e.g.
> x^1.5) to shift it.  (That would be applied to the data rather than the
> residuals, so might not work perfectly ...) For a rough idea, you could
> run a Box-Cox analysis on the residuals.
>
>   Alternatively, if you can figure out a permutation approach that works
> (e.g. permutation within and between groups) that could give you a
> distribution-robust way to get a p-value.
>
> >
> >
> > Given that the fit to normal distribution is not good, we want to know if
> > there is any other distribution we could try. What else we can do in this
> > scenario?
> >
> >
> >
> > On the other hand, to estimate the variance components we used the
> > following in lmer:
> >
> >
> >
> > m1 <- lmer ( variable ~ fixed factor  1 * fixed factor 2 + (fixed factor
> 1
> > * fixed factor 2 || random factor))
> >
> >
> >
> > The specific question is if the double bar ('| |') is a good way to
> > estimate the variance components or if there is another way to do it?
>
>   Can you clarify what you mean by "variance components"? Are you
> explicitly trying to partition variance, or are you just trying to make
> sure that you control for among-group variation?
>
>   If your data will support it, I think it would be better to fit the
> unstructured variance-covariance matrix; if not, you could try one of
> the Bayesian methods (blme, MCMCglmm, brms, rstanarm ...) that would
> allow you to regularize/put a prior on the variance-covariance matrix.
>
>
> >
> >
> >
> > Thanks in advance!
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From rune@h@ubo @ending from gm@il@com  Wed May  9 20:41:20 2018
From: rune@h@ubo @ending from gm@il@com (Rune Haubo)
Date: Wed, 9 May 2018 20:41:20 +0200
Subject: [R-sig-ME] Question about continuous distributions in GLMM
In-Reply-To: <CAEpo04np5hjea=j1Yz8D1u8mxyu2Sf8GHxSeiYQJzWBqALiOWA@mail.gmail.com>
References: <CAEpo04=QK+9yWW4_n669rYtCLiOxGBxk=V6mnTa9PNgfvK3D6Q@mail.gmail.com>
 <CAEpo04k1UdkK2TWPByX7OnkRmXWbdECMjkKeFysz6gKYPACCKg@mail.gmail.com>
 <44db0ee5-ef31-0a7c-0389-a21c7ba44881@gmail.com>
 <CAEpo04np5hjea=j1Yz8D1u8mxyu2Sf8GHxSeiYQJzWBqALiOWA@mail.gmail.com>
Message-ID: <CAG_uk90=avAvtiZdUm3JMAVRf_Nc+RMKkhK+_FjGa-UCxee3Vg@mail.gmail.com>

On 9 May 2018 at 20:16, Victoria Ortiz <vicrotas at gmail.com> wrote:
>  Hi,
> I'm so sorry for the delay in the response, I was with a lot of work.
>
> With "variance components" I mean the partition of the total variance into
> the different factors that explain it. Our interest is to have a
> quantification of the portion of the variance explained by the different
> factors, both random and fixed. Translated to the biology of our data, this
> means to estimate genetic, genotype x environment variation, and
> environment variation of the total phenotypic variation for a given trait
> in a population. In particular, the objective is to compare this estimators
> between diferent populations analyzed separately.
>
> Additionaly, reading another topics of this mail list, I found that the
> classical model for testing the interaction and obtain the variance
> components would be a model like the following:
>
> m2 <- lmer ( variable ~ fixed factor  1 * fixed factor 2 + (1 | random
> factor) + (1 | fixed factor 1:random factor2) + (1 | fixed factor 2:random
> factor) + (1| fixed factor 1:fixed factor 2:random factor))
>
> So, with this model, in the summary I can see the partition of the total
> variance of the random effects. Is this right?

Yes, this model will decompose the variance of the response into
variance components for the random effects and the residual variance.
>
> Finally, if I want the p-values of the random effects, I should analize the
> full and reduce models sequentially. Also, I found that another way to do
> it is with the 'ranova' function from the lmerTest package, but the results
> are very dissimilar. I don't know in wich analysis should I trust, I think
> that in this case the sequentially one is correct.

Can you quantify how these approaches are different? If you run
lmerTest::ranova(m2) it should provide (REML) likelihood ratio tests
of the random terms by deleting these from the full model one-by-one.
Note that if the model is fitted with REML (default) the tests are
REML-likelihood ratio tests - otherwise ML likelihood ratio tests.

Perhaps you use anova(m2, reduce_m2) or equivalently anova(m2,
reduce_m2, refit=TRUE) which produce ML likelihood ratio tests while
fitting your model with REML and that is the source of the difference?
[For tests of random effect terms I recommend the REML likelihood
ratio tests produced by lmerTest::ranova over the ML LR tests produced
by anova(m2, reduce_m2, refit=TRUE) but other tools, e.g. package
RLRsim may produce even more accurate tests].

Cheers
Rune


From @@id_lect06 @ending from y@hoo@com  Thu May 10 09:08:26 2018
From: @@id_lect06 @ending from y@hoo@com (Said Ali Shah)
Date: Thu, 10 May 2018 07:08:26 +0000 (UTC)
Subject: [R-sig-ME] Hi listers
References: <834745482.1927741.1525936106611.ref@mail.yahoo.com>
Message-ID: <834745482.1927741.1525936106611@mail.yahoo.com>

I am using linear mixed model for my analysis, my model is?m1<-lme(yij~X1i+Tti+X1i*Tti+(1+Tti),data1)? with random slope and random intercept. if i run this model it works fine but when i run it in loop or i specify correlation structure i.e.m<-lme(yij~X1i+Tti+X1i*Tti+(1+Tti),correlation=corAR1(), data1) then it give me error?Error in lme.formula(yij ~ X1i + Tti + X1i * Tti + (1 + Tti), correlation = corAR1(),? :?? nlminb problem, convergence error code = 1? message = iteration limit reached without convergence (10)so whether there is problem in model specification or in the correlation specification??
	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Fri May 11 14:50:51 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Fri, 11 May 2018 13:50:51 +0100
Subject: [R-sig-ME] Syntax for adding group-level predictors
Message-ID: <CAOE=hqKtHUZWxY-qR=BC_EgUzfZF6WFBVhgJVTU65WvGg0XW-w@mail.gmail.com>

Hi,
I am working with a random intercept model. I have the usual "X" vector of
covariates and one id variable which will make up the random intercept. Now
I wish to add group-level predictors (which are NOT in the X vector) such
that the random intercept depends on these predictors.
For example,
Response variable: Production of maize
Covariate: Size of plot
Group-level predictor: Age of farmer
ID variable: Household_ID

I wish to confirm the syntax for including the group-level "Age of farmer"
variable.
fit<-lmer(Production~ Size+ Age+ (1|Household_ID), data=data)

Is this correct or is there another way of declaring the group-level
predictor in the formula?

Thank you

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Fri May 11 15:27:57 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Fri, 11 May 2018 15:27:57 +0200
Subject: [R-sig-ME] Syntax for adding group-level predictors
In-Reply-To: <CAOE=hqKtHUZWxY-qR=BC_EgUzfZF6WFBVhgJVTU65WvGg0XW-w@mail.gmail.com>
References: <CAOE=hqKtHUZWxY-qR=BC_EgUzfZF6WFBVhgJVTU65WvGg0XW-w@mail.gmail.com>
Message-ID: <CAJuCY5yb4dDX3jAu7DVc-w_5HXA-QGZVeY0cwjonL-ONL2cLKw@mail.gmail.com>

Dear Yashree,

You added "Age" to the fixed effects. This assumes that the slope of
Age is shared among all household. Which makes sense to me.

For "Size" you have two options: Size + Age + (1|ID) or Age + (1 +
Size|ID). The former assumes that the slope of Size is the same for
each household (hence a 'fixed' slope). The latter assumes that each
household has a different slope for Size (hence a 'random' slope).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-05-11 14:50 GMT+02:00 Yashree Mehta <yashree19 at gmail.com>:
> Hi,
> I am working with a random intercept model. I have the usual "X" vector of
> covariates and one id variable which will make up the random intercept. Now
> I wish to add group-level predictors (which are NOT in the X vector) such
> that the random intercept depends on these predictors.
> For example,
> Response variable: Production of maize
> Covariate: Size of plot
> Group-level predictor: Age of farmer
> ID variable: Household_ID
>
> I wish to confirm the syntax for including the group-level "Age of farmer"
> variable.
> fit<-lmer(Production~ Size+ Age+ (1|Household_ID), data=data)
>
> Is this correct or is there another way of declaring the group-level
> predictor in the formula?
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m@echler @ending from @t@t@m@th@ethz@ch  Sat May 12 22:53:03 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 12 May 2018 22:53:03 +0200
Subject: [R-sig-ME] rBind in lme4
In-Reply-To: <CAErODj--nGnc1NEVkJU8An8bduG_jYjU6MgVC0mdnmcKPmHzfw@mail.gmail.com>
References: <CAErODj--nGnc1NEVkJU8An8bduG_jYjU6MgVC0mdnmcKPmHzfw@mail.gmail.com>
Message-ID: <23287.21551.987865.717352@stat.math.ethz.ch>

>>>>> Paul Johnson <pauljohn32 at gmail.com>
>>>>>     on Wed, 9 May 2018 12:22:48 -0500 writes:

    > Dear maintainers: I got a note from CRAN today saying one
    > of my packages will be removed because it accesses rBind
    > via lme4.

    > Did you get the same message?

who would "you" be?

Indeed, you *should* have imported it from Matrix rather than
lme4, and in Matrix it has been documented to be deprecated --
and you should just use  rbind() instead -- since R version
3.2.0 the rBind() "detour" had no longer been necessary.

  > rBind(1,2)
  [,1]
  [1,]    1
  [2,]    2
  Warning message:
  'rBind' is deprecated.
  Since R version 3.2.0, base's rbind() should work fine with S4 objects 
  > 

Best,
Martin

    > Dear maintainer,

    > Please see the problems shown on
    > <https://cran.r-project.org/web/checks/check_results_rockchalk.html>.

    > Please correct before 2018-05-23 to safely retain your
    > package on CRAN.

    > Best, -k




    > -- 
    > Paul E. Johnson http://pj.freefaculty.org Director, Center
    > for Research Methods and Data Analysis http://crmda.ku.edu

    > To write to me directly, please address me at pauljohn at
    > ku.edu.

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From p@uljohn32 @ending from gm@il@com  Mon May 14 08:36:53 2018
From: p@uljohn32 @ending from gm@il@com (Paul Johnson)
Date: Mon, 14 May 2018 01:36:53 -0500
Subject: [R-sig-ME] rBind in lme4
In-Reply-To: <23287.21551.987865.717352@stat.math.ethz.ch>
References: <CAErODj--nGnc1NEVkJU8An8bduG_jYjU6MgVC0mdnmcKPmHzfw@mail.gmail.com>
 <23287.21551.987865.717352@stat.math.ethz.ch>
Message-ID: <CAErODj-LNfDjEaMmqu7KEnbRjKj57ubQLj5W4wRCaVWKtfufBQ@mail.gmail.com>

Sorry, I see my mistake now.  I was warning you about a problem that
you were aware of already.

In the lme4 Git repo, Martin committed a patch that removed the usage
of rBind from formatVC on Mar 22, 2018. I thought you had it still
when I asked.

pj


On Sat, May 12, 2018 at 3:53 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Paul Johnson <pauljohn32 at gmail.com>
>>>>>>     on Wed, 9 May 2018 12:22:48 -0500 writes:
>
>     > Dear maintainers: I got a note from CRAN today saying one
>     > of my packages will be removed because it accesses rBind
>     > via lme4.
>
>     > Did you get the same message?
>
> who would "you" be?
>
> Indeed, you *should* have imported it from Matrix rather than
> lme4, and in Matrix it has been documented to be deprecated --
> and you should just use  rbind() instead -- since R version
> 3.2.0 the rBind() "detour" had no longer been necessary.
>
>   > rBind(1,2)
>   [,1]
>   [1,]    1
>   [2,]    2
>   Warning message:
>   'rBind' is deprecated.
>   Since R version 3.2.0, base's rbind() should work fine with S4 objects
>   >
>
> Best,
> Martin
>
>     > Dear maintainer,
>
>     > Please see the problems shown on
>     > <https://cran.r-project.org/web/checks/check_results_rockchalk.html>.
>
>     > Please correct before 2018-05-23 to safely retain your
>     > package on CRAN.
>
>     > Best, -k
>
>
>
>
>     > --
>     > Paul E. Johnson http://pj.freefaculty.org Director, Center
>     > for Research Methods and Data Analysis http://crmda.ku.edu
>
>     > To write to me directly, please address me at pauljohn at
>     > ku.edu.
>
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From mr@luced@n @ending from hotm@il@it  Mon May 14 21:48:22 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Mon, 14 May 2018 19:48:22 +0000
Subject: [R-sig-ME] Free statistical analysis material?
Message-ID: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>

Hello everybody,

I am trying the difficult task to conclude an interdisciplinary PhD.
Statistics looks nice, and I have learned a lot about the basic principles and methodologies, and how they work.

But I miss a lot. In particular all the little variations and methods due to interpretations and methodologies (for example now I am looking at the function of contrasts in mixed-effects models), and generally, from theory to applied statistics there is an incredible gap.

Is anybody in this list (as I don't really have a mentor on statistics nor I know statisticians) be able to point me to some free materials (books, tutorials) to study the topic in detail, but not too much in detail?

For example, in this moment, I am trying to figure the following script out. I understand it on its general lines, but there are really obscure points in my head on understanding the "why".
In the following example, what I don't understand is just the contrasts, but the person who is following me (who is a very nice person) has given me the task to figure out the best way to make a contrast "2 conditions > 6 conditions". She has suggested some guessing, but she is not a specialist.

I was thinking that maybe you that are specialists know some free not-too-long source that I could read to move around.

----

library(lmerTest)

str(datasheet.complete)
# set Score as numeric
datasheet.complete$Score = as.numeric(datasheet.complete$Score)

levels(datasheet.complete$Closure)

# closure contrasts
cl_c1 = c(-1/3,-1/3,-1/3,1)
cl_c2 = c(-1/2,-1/2,1,0)
cl_c3 = c(-1,1,0,0)
closuremat.temp = rbind(constant = 1/4,cl_c1,cl_c2,cl_c3)
closuremat = solve(closuremat.temp)
closuremat = closuremat[, -1]
closuremat

# expertise contrasts

exp_c1 = c(-1/2,-1/2,1)
exp_c2 = c(-1,1,0)
expmat.temp = rbind(constant = 1/3,exp_c1,exp_c2)
expmat = solve(expmat.temp)
expmat = expmat[, -1]
expmat

# set contrast
contrasts(datasheet.complete$Closure) = closuremat
contrasts(datasheet.complete$ExpertiseType) = expmat


modela = lmer(Score~1+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
modelb = update(modela,.~.+ExpertiseType)
modelc = update(modelb,.~.+Closure)
modeld = update(modelc,.~.+ExpertiseType*Closure)

anova(modela,modelb,modelc,modeld)

model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
summary(model)


	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon May 14 21:56:02 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 14 May 2018 15:56:02 -0400
Subject: [R-sig-ME] Free statistical analysis material?
In-Reply-To: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <83a9f0e3-ab3e-757b-0a68-d00c78ac11d0@gmail.com>


  Contrasts are confusing, and not specific to LMMs.  You might see if

http://bbolker.github.io/mixedmodels-misc/notes/contrasts.pdf

helps at all.  (From a quick glance at your question & code below, I'm
not sure what you mean by "2 conditions > 6 conditions" ???)

On 2018-05-14 03:48 PM, Luca Danieli wrote:
> Hello everybody,
> 
> I am trying the difficult task to conclude an interdisciplinary PhD.
> Statistics looks nice, and I have learned a lot about the basic principles and methodologies, and how they work.
> 
> But I miss a lot. In particular all the little variations and methods due to interpretations and methodologies (for example now I am looking at the function of contrasts in mixed-effects models), and generally, from theory to applied statistics there is an incredible gap.
> 
> Is anybody in this list (as I don't really have a mentor on statistics nor I know statisticians) be able to point me to some free materials (books, tutorials) to study the topic in detail, but not too much in detail?
> 
> For example, in this moment, I am trying to figure the following script out. I understand it on its general lines, but there are really obscure points in my head on understanding the "why".
> In the following example, what I don't understand is just the contrasts, but the person who is following me (who is a very nice person) has given me the task to figure out the best way to make a contrast "2 conditions > 6 conditions". She has suggested some guessing, but she is not a specialist.
> 
> I was thinking that maybe you that are specialists know some free not-too-long source that I could read to move around.
> 
> ----
> 
> library(lmerTest)
> 
> str(datasheet.complete)
> # set Score as numeric
> datasheet.complete$Score = as.numeric(datasheet.complete$Score)
> 
> levels(datasheet.complete$Closure)
> 
> # closure contrasts
> cl_c1 = c(-1/3,-1/3,-1/3,1)
> cl_c2 = c(-1/2,-1/2,1,0)
> cl_c3 = c(-1,1,0,0)
> closuremat.temp = rbind(constant = 1/4,cl_c1,cl_c2,cl_c3)
> closuremat = solve(closuremat.temp)
> closuremat = closuremat[, -1]
> closuremat
> 
> # expertise contrasts
> 
> exp_c1 = c(-1/2,-1/2,1)
> exp_c2 = c(-1,1,0)
> expmat.temp = rbind(constant = 1/3,exp_c1,exp_c2)
> expmat = solve(expmat.temp)
> expmat = expmat[, -1]
> expmat
> 
> # set contrast
> contrasts(datasheet.complete$Closure) = closuremat
> contrasts(datasheet.complete$ExpertiseType) = expmat
> 
> 
> modela = lmer(Score~1+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
> modelb = update(modela,.~.+ExpertiseType)
> modelc = update(modelb,.~.+Closure)
> modeld = update(modelc,.~.+ExpertiseType*Closure)
> 
> anova(modela,modelb,modelc,modeld)
> 
> model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
> summary(model)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mr@luced@n @ending from hotm@il@it  Mon May 14 22:38:35 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Mon, 14 May 2018 20:38:35 +0000
Subject: [R-sig-ME] Free statistical analysis material?
In-Reply-To: <83a9f0e3-ab3e-757b-0a68-d00c78ac11d0@gmail.com>
References: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>,
 <83a9f0e3-ab3e-757b-0a68-d00c78ac11d0@gmail.com>
Message-ID: <CWXP265MB0470B6F8A269D3161B65E847F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>

Thank you for confirming the confusion.

In general, in the example the first contrast is about the first effect/variable (in this case a "musical closure") and has 4 conditions, so I create a contrast like:

condition 4 > conditions 1, 2, 3

-> cl_c1 = c(-1/3,-1/3,-1/3,1)

Now I want to look at another effect/variable (named "position"). This has 8 conditions and I have to make a contrast like

conditions 1, 2 > conditions 3, 4, 5, 6, 7, 8
Hipotetically should be (?):

-> ps_c1 = c(0.5, 0.5, -1/6, -1/6, -1/6, -1/6, -1/6, -1/6)

? Guess I am wrong?

Btw, I received the following reply from the mailing list by a certain Elisa Rose. Maybe you want to dig into the issue?

Hey  {fullname}   ///I guess that given the mailing list it couldn't detect my name
Thanks for your response. Can I have a pic or two to start talking? Please respond with pics/infos, Hope to hear back from you asap.

Thanks,

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: 14 May 2018 20:56
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Free statistical analysis material?


  Contrasts are confusing, and not specific to LMMs.  You might see if

http://bbolker.github.io/mixedmodels-misc/notes/contrasts.pdf

helps at all.  (From a quick glance at your question & code below, I'm
not sure what you mean by "2 conditions > 6 conditions" ???)

On 2018-05-14 03:48 PM, Luca Danieli wrote:
> Hello everybody,
>
> I am trying the difficult task to conclude an interdisciplinary PhD.
> Statistics looks nice, and I have learned a lot about the basic principles and methodologies, and how they work.
>
> But I miss a lot. In particular all the little variations and methods due to interpretations and methodologies (for example now I am looking at the function of contrasts in mixed-effects models), and generally, from theory to applied statistics there is an incredible gap.
>
> Is anybody in this list (as I don't really have a mentor on statistics nor I know statisticians) be able to point me to some free materials (books, tutorials) to study the topic in detail, but not too much in detail?
>
> For example, in this moment, I am trying to figure the following script out. I understand it on its general lines, but there are really obscure points in my head on understanding the "why".
> In the following example, what I don't understand is just the contrasts, but the person who is following me (who is a very nice person) has given me the task to figure out the best way to make a contrast "2 conditions > 6 conditions". She has suggested some guessing, but she is not a specialist.
>
> I was thinking that maybe you that are specialists know some free not-too-long source that I could read to move around.
>
> ----
>
> library(lmerTest)
>
> str(datasheet.complete)
> # set Score as numeric
> datasheet.complete$Score = as.numeric(datasheet.complete$Score)
>
> levels(datasheet.complete$Closure)
>
> # closure contrasts
> cl_c1 = c(-1/3,-1/3,-1/3,1)
> cl_c2 = c(-1/2,-1/2,1,0)
> cl_c3 = c(-1,1,0,0)
> closuremat.temp = rbind(constant = 1/4,cl_c1,cl_c2,cl_c3)
> closuremat = solve(closuremat.temp)
> closuremat = closuremat[, -1]
> closuremat
>
> # expertise contrasts
>
> exp_c1 = c(-1/2,-1/2,1)
> exp_c2 = c(-1,1,0)
> expmat.temp = rbind(constant = 1/3,exp_c1,exp_c2)
> expmat = solve(expmat.temp)
> expmat = expmat[, -1]
> expmat
>
> # set contrast
> contrasts(datasheet.complete$Closure) = closuremat
> contrasts(datasheet.complete$ExpertiseType) = expmat
>
>
> modela = lmer(Score~1+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
> modelb = update(modela,.~.+ExpertiseType)
> modelc = update(modelb,.~.+Closure)
> modeld = update(modelc,.~.+ExpertiseType*Closure)
>
> anova(modela,modelb,modelc,modeld)
>
> model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
> summary(model)
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon May 14 22:45:36 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 14 May 2018 16:45:36 -0400
Subject: [R-sig-ME] Free statistical analysis material?
In-Reply-To: <CWXP265MB0470B6F8A269D3161B65E847F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
 <83a9f0e3-ab3e-757b-0a68-d00c78ac11d0@gmail.com>
 <CWXP265MB0470B6F8A269D3161B65E847F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <3c5c7bc2-8659-e418-2449-fc0aa275229d@gmail.com>


  The ugly spam e-mail is a known problem.  I get it too. I think the R
mailing list administrators (I am not one of them!) are aware of the
issue, in the meantime I think the advice given was "ignore it or update
your spam filters".

  Your 'contrast' vector for 8  conditions seems reasonable.  It really
represents a single row of the *inverse* contrast matrix (since it
describes the linear combination of group means that determines the
parameter value not the linear combination of values that determines a
group mean).  It would have to be embedded in the same kind of
conversion code as in the examples you showed for closure and expertise
in your example.

  Did you read the PDF I linked to?

  cheers
   Ben Bolker

On 2018-05-14 04:38 PM, Luca Danieli wrote:
> Thank you for confirming the confusion.
> 
> In general, in the example the first contrast is about the first
> effect/variable (in this case a "musical closure") and has 4 conditions,
> so I create a contrast like:
> 
> condition 4 > conditions 1, 2, 3
> 
> -> cl_c1 = c(-1/3,-1/3,-1/3,1)
> 
> Now I want to look at another effect/variable (named "position"). This
> has 8 conditions and I have to make a contrast like
> 
> conditions 1, 2 > conditions 3, 4, 5, 6, 7, 8
> Hipotetically should be (?):
> 
> -> ps_c1 = c(0.5, 0.5, -1/6, -1/6, -1/6, -1/6, -1/6, -1/6)
> 
> ? Guess I am wrong?
> 
> Btw, I received the following?reply from the mailing list by a certain
> Elisa Rose. Maybe you want to dig into the issue?
> 
> Hey??{fullname}? ?///I guess that given the mailing list it couldn't
> detect my?name
> Thanks for your response. Can I have a pic or two to start talking?
> Please respond with pics/infos, Hope to hear back from you asap.
> 
> Thanks,
> 
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* 14 May 2018 20:56
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Free statistical analysis material?
> ?
> 
> ? Contrasts are confusing, and not specific to LMMs.? You might see if
> 
> http://bbolker.github.io/mixedmodels-misc/notes/contrasts.pdf
> 
> helps at all.? (From a quick glance at your question & code below, I'm
> not sure what you mean by "2 conditions > 6 conditions" ???)
> 
> On 2018-05-14 03:48 PM, Luca Danieli wrote:
>> Hello everybody,
>> 
>> I am trying the difficult task to conclude an interdisciplinary PhD.
>> Statistics looks nice, and I have learned a lot about the basic principles and methodologies, and how they work.
>> 
>> But I miss a lot. In particular all the little variations and methods due to interpretations and methodologies (for example now I am looking at the function of contrasts in mixed-effects models), and generally, from theory to applied statistics there is an incredible gap.
>> 
>> Is anybody in this list (as I don't really have a mentor on statistics nor I know statisticians) be able to point me to some free materials (books, tutorials) to study the topic in detail, but not too much in detail?
>> 
>> For example, in this moment, I am trying to figure the following script out. I understand it on its general lines, but there are really obscure points in my head on understanding the "why".
>> In the following example, what I don't understand is just the contrasts, but the person who is following me (who is a very nice person) has given me the task to figure out the best way to make a contrast "2 conditions > 6 conditions". She has suggested some guessing, but she is not a specialist.
>> 
>> I was thinking that maybe you that are specialists know some free not-too-long source that I could read to move around.
>> 
>> ----
>> 
>> library(lmerTest)
>> 
>> str(datasheet.complete)
>> # set Score as numeric
>> datasheet.complete$Score = as.numeric(datasheet.complete$Score)
>> 
>> levels(datasheet.complete$Closure)
>> 
>> # closure contrasts
>> cl_c1 = c(-1/3,-1/3,-1/3,1)
>> cl_c2 = c(-1/2,-1/2,1,0)
>> cl_c3 = c(-1,1,0,0)
>> closuremat.temp = rbind(constant = 1/4,cl_c1,cl_c2,cl_c3)
>> closuremat = solve(closuremat.temp)
>> closuremat = closuremat[, -1]
>> closuremat
>> 
>> # expertise contrasts
>> 
>> exp_c1 = c(-1/2,-1/2,1)
>> exp_c2 = c(-1,1,0)
>> expmat.temp = rbind(constant = 1/3,exp_c1,exp_c2)
>> expmat = solve(expmat.temp)
>> expmat = expmat[, -1]
>> expmat
>> 
>> # set contrast
>> contrasts(datasheet.complete$Closure) = closuremat
>> contrasts(datasheet.complete$ExpertiseType) = expmat
>> 
>> 
>> modela = lmer(Score~1+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
>> modelb = update(modela,.~.+ExpertiseType)
>> modelc = update(modelb,.~.+Closure)
>> modeld = update(modelc,.~.+ExpertiseType*Closure)
>> 
>> anova(modela,modelb,modelc,modeld)
>> 
>> model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
>> summary(model)
>> 
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mr@luced@n @ending from hotm@il@it  Mon May 14 22:55:58 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Mon, 14 May 2018 20:55:58 +0000
Subject: [R-sig-ME] Free statistical analysis material?
In-Reply-To: <3c5c7bc2-8659-e418-2449-fc0aa275229d@gmail.com>
References: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
 <83a9f0e3-ab3e-757b-0a68-d00c78ac11d0@gmail.com>
 <CWXP265MB0470B6F8A269D3161B65E847F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>,
 <3c5c7bc2-8659-e418-2449-fc0aa275229d@gmail.com>
Message-ID: <CWXP265MB04706097243F2220623C6C2EF69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>

Yes thank you! I am reading it right now!
It's great for the fact that it mentions examples from actual real studies, which gives an idea of how things get applied in real world analysis and in case I can check the relative paper!

I have looked also at the material suggested by Rune Haubo - I didn't find mention of mixed-effects models, but I guess I'll have to look into the mixed-model theory part.

Super thanks to everybody!
Best
________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: 14 May 2018 21:45
To: Luca Danieli; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Free statistical analysis material?


  The ugly spam e-mail is a known problem.  I get it too. I think the R
mailing list administrators (I am not one of them!) are aware of the
issue, in the meantime I think the advice given was "ignore it or update
your spam filters".

  Your 'contrast' vector for 8  conditions seems reasonable.  It really
represents a single row of the *inverse* contrast matrix (since it
describes the linear combination of group means that determines the
parameter value not the linear combination of values that determines a
group mean).  It would have to be embedded in the same kind of
conversion code as in the examples you showed for closure and expertise
in your example.

  Did you read the PDF I linked to?

  cheers
   Ben Bolker

On 2018-05-14 04:38 PM, Luca Danieli wrote:
> Thank you for confirming the confusion.
>
> In general, in the example the first contrast is about the first
> effect/variable (in this case a "musical closure") and has 4 conditions,
> so I create a contrast like:
>
> condition 4 > conditions 1, 2, 3
>
> -> cl_c1 = c(-1/3,-1/3,-1/3,1)
>
> Now I want to look at another effect/variable (named "position"). This
> has 8 conditions and I have to make a contrast like
>
> conditions 1, 2 > conditions 3, 4, 5, 6, 7, 8
> Hipotetically should be (?):
>
> -> ps_c1 = c(0.5, 0.5, -1/6, -1/6, -1/6, -1/6, -1/6, -1/6)
>
> ? Guess I am wrong?
>
> Btw, I received the following reply from the mailing list by a certain
> Elisa Rose. Maybe you want to dig into the issue?
>
> Hey  {fullname}   ///I guess that given the mailing list it couldn't
> detect my name
> Thanks for your response. Can I have a pic or two to start talking?
> Please respond with pics/infos, Hope to hear back from you asap.
>
> Thanks,
>
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* 14 May 2018 20:56
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Free statistical analysis material?
>
>
>   Contrasts are confusing, and not specific to LMMs.  You might see if
>
> http://bbolker.github.io/mixedmodels-misc/notes/contrasts.pdf
>
> helps at all.  (From a quick glance at your question & code below, I'm
> not sure what you mean by "2 conditions > 6 conditions" ???)
>
> On 2018-05-14 03:48 PM, Luca Danieli wrote:
>> Hello everybody,
>>
>> I am trying the difficult task to conclude an interdisciplinary PhD.
>> Statistics looks nice, and I have learned a lot about the basic principles and methodologies, and how they work.
>>
>> But I miss a lot. In particular all the little variations and methods due to interpretations and methodologies (for example now I am looking at the function of contrasts in mixed-effects models), and generally, from theory to applied statistics there is an incredible gap.
>>
>> Is anybody in this list (as I don't really have a mentor on statistics nor I know statisticians) be able to point me to some free materials (books, tutorials) to study the topic in detail, but not too much in detail?
>>
>> For example, in this moment, I am trying to figure the following script out. I understand it on its general lines, but there are really obscure points in my head on understanding the "why".
>> In the following example, what I don't understand is just the contrasts, but the person who is following me (who is a very nice person) has given me the task to figure out the best way to make a contrast "2 conditions > 6 conditions". She has suggested some guessing, but she is not a specialist.
>>
>> I was thinking that maybe you that are specialists know some free not-too-long source that I could read to move around.
>>
>> ----
>>
>> library(lmerTest)
>>
>> str(datasheet.complete)
>> # set Score as numeric
>> datasheet.complete$Score = as.numeric(datasheet.complete$Score)
>>
>> levels(datasheet.complete$Closure)
>>
>> # closure contrasts
>> cl_c1 = c(-1/3,-1/3,-1/3,1)
>> cl_c2 = c(-1/2,-1/2,1,0)
>> cl_c3 = c(-1,1,0,0)
>> closuremat.temp = rbind(constant = 1/4,cl_c1,cl_c2,cl_c3)
>> closuremat = solve(closuremat.temp)
>> closuremat = closuremat[, -1]
>> closuremat
>>
>> # expertise contrasts
>>
>> exp_c1 = c(-1/2,-1/2,1)
>> exp_c2 = c(-1,1,0)
>> expmat.temp = rbind(constant = 1/3,exp_c1,exp_c2)
>> expmat = solve(expmat.temp)
>> expmat = expmat[, -1]
>> expmat
>>
>> # set contrast
>> contrasts(datasheet.complete$Closure) = closuremat
>> contrasts(datasheet.complete$ExpertiseType) = expmat
>>
>>
>> modela = lmer(Score~1+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
>> modelb = update(modela,.~.+ExpertiseType)
>> modelc = update(modelb,.~.+Closure)
>> modeld = update(modelc,.~.+ExpertiseType*Closure)
>>
>> anova(modela,modelb,modelc,modeld)
>>
>> model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
>> summary(model)
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Thu May 17 12:43:29 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Thu, 17 May 2018 12:43:29 +0200
Subject: [R-sig-ME] What is the appropriate zero-correlation parameter model
 for factors in lmer?
Message-ID: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>

Dear list,

When one wants to specify a lmer model including variance components but no
correlation parameters for categorical predictors (factors) afaik one has
to convert the factors to numeric covariates or use lme4::dummy(). Until
recently I thought m2a (or equivalently m2b using the double-bar syntax)
would be the correct way to specify such a zero-correlation parameter model.

But in this thread [1] Rune Haubo Bojesen Christensen pointed out that this
model does not make sense to him. Instead he suggests m3 as an appropriate
model.
I think this is a *highly relevant difference* for everyone who uses
factors in lmer and therefore I'm bringing up this issue again. But maybe
I'm mistaken and just don't get what is quite obvious for more experienced
mixed modelers.
Please note that the question is on CrossValidated [2] but some consider it
as off-topic and I don't think there will be an answer any time soon.

So here are my questions:
How should one specify a lmm without correlation parameters for factors and
what are the differences between m2a and m3?
Is there a preferred model for model comparison with m4 (this model is also
discussed here [3])?

library("lme4")
data("Machines", package = "MEMSS")

d <- Machines
contrasts(d$Machine)  # default coding: contr.sum

m1 <- lmer(score ~ Machine + (Machine | Worker), d)

c1 <- model.matrix(m1)[, 2]
c2 <- model.matrix(m1)[, 3]
m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 + c2 |
Worker), d)
m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
VarCorr(m2a)
 Groups   Name        Std.Dev.
 Worker   (Intercept) 5.24354
 Worker.1 c1          2.58446
 Worker.2 c2          3.71504
 Residual             0.96256

m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A") |
Worker) +
                                            (0 + dummy(Machine, "B") |
Worker) +
                                            (0 + dummy(Machine, "C") |
Worker), d)
VarCorr(m3)
 Groups   Name                Std.Dev.
 Worker   (Intercept)         3.78595
 Worker.1 dummy(Machine, "A") 1.94032
 Worker.2 dummy(Machine, "B") 5.87402
 Worker.3 dummy(Machine, "C") 2.84547
 Residual                     0.96158

m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)


[1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
[2] https://stats.stackexchange.com/q/345842/136579
[3] https://stats.stackexchange.com/q/304374/136579

Best regards,
Maarten

	[[alternative HTML version deleted]]


From h@l@bikeren @ending from gm@il@com  Thu May 17 13:07:10 2018
From: h@l@bikeren @ending from gm@il@com (Keren Halabi)
Date: Thu, 17 May 2018 14:07:10 +0300
Subject: [R-sig-ME] Optimize multiple confounded parameters using optim()
Message-ID: <CACtqGW7dgKAD63Zymwks2-XH6n3FG6UZARK-pMNERGrg47kJiA@mail.gmail.com>

Dear list,

My apologies in advance if this is not the relevant forum for the below
question.

I wish to define a codon site model, which is mixture model over multiple
dN/dS ratios.
Thus, I want to constrain each  dN/dS ratio by its preceding ratio in the
mixture and its following ratio in the mixture. I was thinking of using the
bounds parameter of the optim() function to achieve this.

However, I am experiencing an issue while attempting to optimize a function
with regards to multiple parameters. Specifically, due to setting the
bounds to be dependent on one another.

Here is a basic example: say that I want to optimize the below function
named "test', with regards to vector v, with the following constraint:
0<=v[1]<=v[2]<=1:
test <-function(v=c(0,1)) {return(v[2]-v[1])}

Now, calling optim() with the following settings:
a=0
b=1
res = optim(c(a,b), test, lower=c(0,a), upper=c(b,1),method="L-BFGS-B")

Yields optimized values:
a=1
b=0
test(c(a,b))=-1

It appears that the constraint was not satisfied, but the bounds still had
some  affect on the result. This makes me suspect that I didn't set the
lower and upper bounds correctly when calling optim().
Could you please let me know what I did wrong?

Many thanks!
Keren

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu May 17 18:12:15 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 May 2018 09:12:15 -0700
Subject: [R-sig-ME] 
 Optimize multiple confounded parameters using optim()
In-Reply-To: <CACtqGW7dgKAD63Zymwks2-XH6n3FG6UZARK-pMNERGrg47kJiA@mail.gmail.com>
References: <CACtqGW7dgKAD63Zymwks2-XH6n3FG6UZARK-pMNERGrg47kJiA@mail.gmail.com>
Message-ID: <173CE1E1-7215-41FB-8EBE-40B672129A60@dcn.davis.ca.us>

I am not sure I follow your explanation of the problem domain, but the equations look like the kind of thing that linear programming was designed to solve. There are a few options for that among the contributed packages (look in the Optimization Task View on CRAN).

On May 17, 2018 4:07:10 AM PDT, Keren Halabi <halabikeren at gmail.com> wrote:
>Dear list,
>
>My apologies in advance if this is not the relevant forum for the below
>question.
>
>I wish to define a codon site model, which is mixture model over
>multiple
>dN/dS ratios.
>Thus, I want to constrain each  dN/dS ratio by its preceding ratio in
>the
>mixture and its following ratio in the mixture. I was thinking of using
>the
>bounds parameter of the optim() function to achieve this.
>
>However, I am experiencing an issue while attempting to optimize a
>function
>with regards to multiple parameters. Specifically, due to setting the
>bounds to be dependent on one another.
>
>Here is a basic example: say that I want to optimize the below function
>named "test', with regards to vector v, with the following constraint:
>0<=v[1]<=v[2]<=1:
>test <-function(v=c(0,1)) {return(v[2]-v[1])}
>
>Now, calling optim() with the following settings:
>a=0
>b=1
>res = optim(c(a,b), test, lower=c(0,a), upper=c(b,1),method="L-BFGS-B")
>
>Yields optimized values:
>a=1
>b=0
>test(c(a,b))=-1
>
>It appears that the constraint was not satisfied, but the bounds still
>had
>some  affect on the result. This makes me suspect that I didn't set the
>lower and upper bounds correctly when calling optim().
>Could you please let me know what I did wrong?
>
>Many thanks!
>Keren
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Sent from my phone. Please excuse my brevity.


From m@echler @ending from @t@t@m@th@ethz@ch  Thu May 17 19:45:46 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 17 May 2018 19:45:46 +0200
Subject: [R-sig-ME] rBind in lme4
In-Reply-To: <CAErODj-LNfDjEaMmqu7KEnbRjKj57ubQLj5W4wRCaVWKtfufBQ@mail.gmail.com>
References: <CAErODj--nGnc1NEVkJU8An8bduG_jYjU6MgVC0mdnmcKPmHzfw@mail.gmail.com>
 <23287.21551.987865.717352@stat.math.ethz.ch>
 <CAErODj-LNfDjEaMmqu7KEnbRjKj57ubQLj5W4wRCaVWKtfufBQ@mail.gmail.com>
Message-ID: <23293.49098.449478.506534@stat.math.ethz.ch>

>>>>> Paul Johnson 
>>>>>     on Mon, 14 May 2018 01:36:53 -0500 writes:

    > Sorry, I see my mistake now.  I was warning you about a
    > problem that you were aware of already.

    > In the lme4 Git repo, Martin committed a patch that
    > removed the usage of rBind from formatVC on Mar 22,
    > 2018. I thought you had it still when I asked.

    > pj

aah.. I now understand ... and I apologize for my "not very tender"
answer.

Best, Martin

    > On Sat, May 12, 2018 at 3:53 PM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Paul Johnson <pauljohn32 at gmail.com> on Wed, 9 May
    >>>>>>> 2018 12:22:48 -0500 writes:
    >> 
    >> > Dear maintainers: I got a note from CRAN today saying
    >> one > of my packages will be removed because it accesses
    >> rBind > via lme4.
    >> 
    >> > Did you get the same message?
    >> 
    >> who would "you" be?
    >> 
    >> Indeed, you *should* have imported it from Matrix rather
    >> than lme4, and in Matrix it has been documented to be
    >> deprecated -- and you should just use rbind() instead --
    >> since R version 3.2.0 the rBind() "detour" had no longer
    >> been necessary.
    >> 
    >> > rBind(1,2) [,1] [1,] 1 [2,] 2 Warning message: 'rBind'
    >> is deprecated.  Since R version 3.2.0, base's rbind()
    >> should work fine with S4 objects
    >> >
    >> 
    >> Best, Martin
    >> 
    >> > Dear maintainer,
    >> 
    >> > Please see the problems shown on >
    >> <https://cran.r-project.org/web/checks/check_results_rockchalk.html>.
    >> 
    >> > Please correct before 2018-05-23 to safely retain your
    >> > package on CRAN.
    >> 
    >> > Best, -k
    >> 
    >> 
    >> 
    >> 
    >> > --
    >> > Paul E. Johnson http://pj.freefaculty.org Director,
    >> Center > for Research Methods and Data Analysis
    >> http://crmda.ku.edu
    >> 
    >> > To write to me directly, please address me at pauljohn
    >> at > ku.edu.
    >> 
    >> > _______________________________________________ >
    >> R-sig-mixed-models at r-project.org mailing list >
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



    > -- 
    > Paul E. Johnson http://pj.freefaculty.org Director, Center
    > for Research Methods and Data Analysis http://crmda.ku.edu

    > To write to me directly, please address me at pauljohn at
    > ku.edu.

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From edw@rd@molin@ @ending from gm@il@com  Thu May 17 20:24:07 2018
From: edw@rd@molin@ @ending from gm@il@com (Juan Pablo Edwards Molina)
Date: Thu, 17 May 2018 15:24:07 -0300
Subject: [R-sig-ME] syntax equation of random intercepts and slopes model
Message-ID: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>

Dear list,

I fitted a linear mixed effects models to a set of 41 field trials
with plot-level assessments of x,y, for estimating the linear
regression coefficients ?_0 and ?_1

res1 <- lmer(y ~ x, random = ~ x | trial , data=mydata)

I wish to write the model equation for its publication, so this is my first try:

W_ij= (?_0 + u_0i)+ (?_1+ u_1i) x_ij + e_ij

where j subscript represents the j-plot within i-trial, both for y or
x. ?0 and ?1 are the population average intercept and slope; u0i and
u1i are the effect of the i-trial on the intercept and the slope,
respectively, considered as random variables (with mean 0 and
variances  ?_u0 and  ?_u1 a )

I?m not sure if I?m in the right path... I would really appreciate any guidance.

Juan Edwards
National Institute of Agriculture Technology - Argentina


From edw@rd@molin@ @ending from gm@il@com  Thu May 17 20:27:37 2018
From: edw@rd@molin@ @ending from gm@il@com (Juan Pablo Edwards Molina)
Date: Thu, 17 May 2018 15:27:37 -0300
Subject: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes
 model
In-Reply-To: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>
References: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>
Message-ID: <CAF5W3aQdX=EuPSAu4NOcQpY8Z2iAYLw8ZKvy2L+S0DmqpbA63Q@mail.gmail.com>

Sorry, I edited the lmer function...

============================================
Dear list,

I fitted a linear mixed effects models to a set of 41 field trials
with plot-level assessments of x,y, for estimating the linear
regression coefficients ?_0 and ?_1

res1 <- lmer(y ~ x+ (x|trial), data=mydata, REML=F)

I wish to write the model equation for its publication, so this is my first try:

W_ij= (?_0 + u_0i)+ (?_1+ u_1i) x_ij + e_ij

where j subscript represents the j-plot within i-trial, both for y or
x. ?0 and ?1 are the population average intercept and slope; u0i and
u1i are the effect of the i-trial on the intercept and the slope,
respectively, considered as random variables (with mean 0 and
variances  ?_u0 and  ?_u1 a )

I?m not sure if I?m in the right path... I would really appreciate any guidance.

Juan Edwards
National Institute of Agriculture Technology - Argentina


From bbolker @ending from gm@il@com  Thu May 17 21:57:06 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 17 May 2018 15:57:06 -0400
Subject: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes
 model
In-Reply-To: <CAF5W3aQdX=EuPSAu4NOcQpY8Z2iAYLw8ZKvy2L+S0DmqpbA63Q@mail.gmail.com>
References: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>
 <CAF5W3aQdX=EuPSAu4NOcQpY8Z2iAYLw8ZKvy2L+S0DmqpbA63Q@mail.gmail.com>
Message-ID: <CABghstQpyRDRxN3cy6bipCWVWA15s2WkVs2uvuRTDBOiEeWpAw@mail.gmail.com>

That looks about right.  You didn't specify the variance of e_ij in
your description, and you didn't say explicitly that the u_ and e_
values are Normally distributed ...

On Thu, May 17, 2018 at 2:27 PM, Juan Pablo Edwards Molina
<edwardsmolina at gmail.com> wrote:
> Sorry, I edited the lmer function...
>
> ============================================
> Dear list,
>
> I fitted a linear mixed effects models to a set of 41 field trials
> with plot-level assessments of x,y, for estimating the linear
> regression coefficients ?_0 and ?_1
>
> res1 <- lmer(y ~ x+ (x|trial), data=mydata, REML=F)
>
> I wish to write the model equation for its publication, so this is my first try:
>
> W_ij= (?_0 + u_0i)+ (?_1+ u_1i) x_ij + e_ij
>
> where j subscript represents the j-plot within i-trial, both for y or
> x. ?0 and ?1 are the population average intercept and slope; u0i and
> u1i are the effect of the i-trial on the intercept and the slope,
> respectively, considered as random variables (with mean 0 and
> variances  ?_u0 and  ?_u1 a )
>
> I?m not sure if I?m in the right path... I would really appreciate any guidance.
>
> Juan Edwards
> National Institute of Agriculture Technology - Argentina
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From edw@rd@molin@ @ending from gm@il@com  Fri May 18 01:33:49 2018
From: edw@rd@molin@ @ending from gm@il@com (Juan Pablo Edwards Molina)
Date: Thu, 17 May 2018 20:33:49 -0300
Subject: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes
 model
In-Reply-To: <CABghstQpyRDRxN3cy6bipCWVWA15s2WkVs2uvuRTDBOiEeWpAw@mail.gmail.com>
References: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>
 <CAF5W3aQdX=EuPSAu4NOcQpY8Z2iAYLw8ZKvy2L+S0DmqpbA63Q@mail.gmail.com>
 <CABghstQpyRDRxN3cy6bipCWVWA15s2WkVs2uvuRTDBOiEeWpAw@mail.gmail.com>
Message-ID: <CAF5W3aRag-ODUtiyRzmpAAr-MpUT-88BOF6Yi0KZHjG2ubO1dg@mail.gmail.com>

Thanks prof. Bolker,
Do you mean this?

u_i?N(0,?^2)      e_ij?N(0,v_i)

Juan
Juan


2018-05-17 16:57 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
> That looks about right.  You didn't specify the variance of e_ij in
> your description, and you didn't say explicitly that the u_ and e_
> values are Normally distributed ...
>
> On Thu, May 17, 2018 at 2:27 PM, Juan Pablo Edwards Molina
> <edwardsmolina at gmail.com> wrote:
>> Sorry, I edited the lmer function...
>>
>> ============================================
>> Dear list,
>>
>> I fitted a linear mixed effects models to a set of 41 field trials
>> with plot-level assessments of x,y, for estimating the linear
>> regression coefficients ?_0 and ?_1
>>
>> res1 <- lmer(y ~ x+ (x|trial), data=mydata, REML=F)
>>
>> I wish to write the model equation for its publication, so this is my first try:
>>
>> W_ij= (?_0 + u_0i)+ (?_1+ u_1i) x_ij + e_ij
>>
>> where j subscript represents the j-plot within i-trial, both for y or
>> x. ?0 and ?1 are the population average intercept and slope; u0i and
>> u1i are the effect of the i-trial on the intercept and the slope,
>> respectively, considered as random variables (with mean 0 and
>> variances  ?_u0 and  ?_u1 a )
>>
>> I?m not sure if I?m in the right path... I would really appreciate any guidance.
>>
>> Juan Edwards
>> National Institute of Agriculture Technology - Argentina
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From c@c@voeten @ending from hum@leidenuniv@nl  Fri May 18 09:23:00 2018
From: c@c@voeten @ending from hum@leidenuniv@nl (Voeten, C.C.)
Date: Fri, 18 May 2018 07:23:00 +0000
Subject: [R-sig-ME] 
 Optimize multiple confounded parameters using optim()
In-Reply-To: <CACtqGW7dgKAD63Zymwks2-XH6n3FG6UZARK-pMNERGrg47kJiA@mail.gmail.com>
References: <CACtqGW7dgKAD63Zymwks2-XH6n3FG6UZARK-pMNERGrg47kJiA@mail.gmail.com>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F88C844@SPMXM08.VUW.leidenuniv.nl>

Hi Keren,

This is not a question about mixed-effects regression, so it is probably better suited at a more general R help list, or on StackOverflow. But since I once had a similar problem, I can perhaps briefly answer your question anyway:

You appear to be after dynamic bounds for each of the parameters, depending on the value of the other parameter. Unfortunately, your code:

	res = optim(c(a,b), test, lower=c(0,a), upper=c(b,1),method="L-BFGS-B")

will be expanded to:

	res = optim(c(0,1), test, lower=c(0,0), upper=c(1,1),method="L-BFGS-B")

before optim() is called, since a=0 and b=1. What you want, however, is for this expansion to happen within the function to be evaluated itself. The way to do this is to set the bounds in your optim() call at the most extreme values for both parameters (i.e. c(0,0) and c(1,1), as you have inadvertently already done), and to have your function return infinity when it is presented with an infeasible solution. In other words:

	test <- function (v) if (v[1] > v[2]) Inf else v[2]-v[1]

In the future, this kind of general question not specific to mixed-effects models is probably better posted on StackOverflow, but I hope this helps anyway.

Cesko

> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] Namens Keren Halabi
> Verzonden: donderdag 17 mei 2018 13:07
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Optimize multiple confounded parameters using
> optim()
> 
> Dear list,
> 
> My apologies in advance if this is not the relevant forum for the below
> question.
> 
> I wish to define a codon site model, which is mixture model over multiple
> dN/dS ratios.
> Thus, I want to constrain each  dN/dS ratio by its preceding ratio in the
> mixture and its following ratio in the mixture. I was thinking of using the
> bounds parameter of the optim() function to achieve this.
> 
> However, I am experiencing an issue while attempting to optimize a function
> with regards to multiple parameters. Specifically, due to setting the bounds
> to be dependent on one another.
> 
> Here is a basic example: say that I want to optimize the below function
> named "test', with regards to vector v, with the following constraint:
> 0<=v[1]<=v[2]<=1:
> test <-function(v=c(0,1)) {return(v[2]-v[1])}
> 
> Now, calling optim() with the following settings:
> a=0
> b=1
> res = optim(c(a,b), test, lower=c(0,a), upper=c(b,1),method="L-BFGS-B")
> 
> Yields optimized values:
> a=1
> b=0
> test(c(a,b))=-1
> 
> It appears that the constraint was not satisfied, but the bounds still had some
> affect on the result. This makes me suspect that I didn't set the lower and
> upper bounds correctly when calling optim().
> Could you please let me know what I did wrong?
> 
> Many thanks!
> Keren
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mr@luced@n @ending from hotm@il@it  Fri May 18 11:45:24 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Fri, 18 May 2018 09:45:24 +0000
Subject: [R-sig-ME] Free statistical analysis material?
In-Reply-To: <3c5c7bc2-8659-e418-2449-fc0aa275229d@gmail.com>
References: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
 <83a9f0e3-ab3e-757b-0a68-d00c78ac11d0@gmail.com>
 <CWXP265MB0470B6F8A269D3161B65E847F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>,
 <3c5c7bc2-8659-e418-2449-fc0aa275229d@gmail.com>
Message-ID: <CWXP265MB047068233A30222DA46608E7F6900@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>

Hello again Ben and all R users,

I am having the problem that I cannot make a contrast hypothesis for a rectangular matrix, because I cannot invert it. Somehow, I had read somewhere to use the method "pseudoinverse()" instead of "solve()".

But in the analysis, I cannot get the p_value of my contrast hypothesis.
Does somebody have a suggestion on how to either:

  *   create a square matrix when I have few hypothesis with a lot of conditions (e.g., ps_c1 = c(0.5, 0.5, -1/6, -1/6, -1/6, -1/6, -1/6, -1/6)). Matrix 2x8.
  *   get the p_value of a rectangular matrix contrast hypothesis?

A more detailed explanation is on stackexchange: https://stats.stackexchange.com/questions/346523/get-p-value-about-contrast-hypothesis-for-rectangular-matrix#346523

Best
Luca


________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: 14 May 2018 21:45
To: Luca Danieli; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Free statistical analysis material?


  The ugly spam e-mail is a known problem.  I get it too. I think the R
mailing list administrators (I am not one of them!) are aware of the
issue, in the meantime I think the advice given was "ignore it or update
your spam filters".

  Your 'contrast' vector for 8  conditions seems reasonable.  It really
represents a single row of the *inverse* contrast matrix (since it
describes the linear combination of group means that determines the
parameter value not the linear combination of values that determines a
group mean).  It would have to be embedded in the same kind of
conversion code as in the examples you showed for closure and expertise
in your example.

  Did you read the PDF I linked to?

  cheers
   Ben Bolker

On 2018-05-14 04:38 PM, Luca Danieli wrote:
> Thank you for confirming the confusion.
>
> In general, in the example the first contrast is about the first
> effect/variable (in this case a "musical closure") and has 4 conditions,
> so I create a contrast like:
>
> condition 4 > conditions 1, 2, 3
>
> -> cl_c1 = c(-1/3,-1/3,-1/3,1)
>
> Now I want to look at another effect/variable (named "position"). This
> has 8 conditions and I have to make a contrast like
>
> conditions 1, 2 > conditions 3, 4, 5, 6, 7, 8
> Hipotetically should be (?):
>
> -> ps_c1 = c(0.5, 0.5, -1/6, -1/6, -1/6, -1/6, -1/6, -1/6)
>
> ? Guess I am wrong?
>
> Btw, I received the following reply from the mailing list by a certain
> Elisa Rose. Maybe you want to dig into the issue?
>
> Hey  {fullname}   ///I guess that given the mailing list it couldn't
> detect my name
> Thanks for your response. Can I have a pic or two to start talking?
> Please respond with pics/infos, Hope to hear back from you asap.
>
> Thanks,
>
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* 14 May 2018 20:56
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Free statistical analysis material?
>
>
>   Contrasts are confusing, and not specific to LMMs.  You might see if
>
> http://bbolker.github.io/mixedmodels-misc/notes/contrasts.pdf
>
> helps at all.  (From a quick glance at your question & code below, I'm
> not sure what you mean by "2 conditions > 6 conditions" ???)
>
> On 2018-05-14 03:48 PM, Luca Danieli wrote:
>> Hello everybody,
>>
>> I am trying the difficult task to conclude an interdisciplinary PhD.
>> Statistics looks nice, and I have learned a lot about the basic principles and methodologies, and how they work.
>>
>> But I miss a lot. In particular all the little variations and methods due to interpretations and methodologies (for example now I am looking at the function of contrasts in mixed-effects models), and generally, from theory to applied statistics there is an incredible gap.
>>
>> Is anybody in this list (as I don't really have a mentor on statistics nor I know statisticians) be able to point me to some free materials (books, tutorials) to study the topic in detail, but not too much in detail?
>>
>> For example, in this moment, I am trying to figure the following script out. I understand it on its general lines, but there are really obscure points in my head on understanding the "why".
>> In the following example, what I don't understand is just the contrasts, but the person who is following me (who is a very nice person) has given me the task to figure out the best way to make a contrast "2 conditions > 6 conditions". She has suggested some guessing, but she is not a specialist.
>>
>> I was thinking that maybe you that are specialists know some free not-too-long source that I could read to move around.
>>
>> ----
>>
>> library(lmerTest)
>>
>> str(datasheet.complete)
>> # set Score as numeric
>> datasheet.complete$Score = as.numeric(datasheet.complete$Score)
>>
>> levels(datasheet.complete$Closure)
>>
>> # closure contrasts
>> cl_c1 = c(-1/3,-1/3,-1/3,1)
>> cl_c2 = c(-1/2,-1/2,1,0)
>> cl_c3 = c(-1,1,0,0)
>> closuremat.temp = rbind(constant = 1/4,cl_c1,cl_c2,cl_c3)
>> closuremat = solve(closuremat.temp)
>> closuremat = closuremat[, -1]
>> closuremat
>>
>> # expertise contrasts
>>
>> exp_c1 = c(-1/2,-1/2,1)
>> exp_c2 = c(-1,1,0)
>> expmat.temp = rbind(constant = 1/3,exp_c1,exp_c2)
>> expmat = solve(expmat.temp)
>> expmat = expmat[, -1]
>> expmat
>>
>> # set contrast
>> contrasts(datasheet.complete$Closure) = closuremat
>> contrasts(datasheet.complete$ExpertiseType) = expmat
>>
>>
>> modela = lmer(Score~1+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
>> modelb = update(modela,.~.+ExpertiseType)
>> modelc = update(modelb,.~.+Closure)
>> modeld = update(modelc,.~.+ExpertiseType*Closure)
>>
>> anova(modela,modelb,modelc,modeld)
>>
>> model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), data = datasheet.complete, REML = TRUE)
>> summary(model)
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Fri May 18 13:52:20 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Fri, 18 May 2018 13:52:20 +0200
Subject: [R-sig-ME] Free statistical analysis material?
In-Reply-To: <CWXP265MB047068233A30222DA46608E7F6900@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB04709A11A90CC7C38FA182C0F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
 <83a9f0e3-ab3e-757b-0a68-d00c78ac11d0@gmail.com>
 <CWXP265MB0470B6F8A269D3161B65E847F69C0@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
 <3c5c7bc2-8659-e418-2449-fc0aa275229d@gmail.com>
 <CWXP265MB047068233A30222DA46608E7F6900@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CAHr4DyfPei1gfVEwOUL_fvsO_AbFC95kh=eJYYhEGyRJ5NDAxQ@mail.gmail.com>

Hi Luca,

I think this is not an issue specific to lmer() or mixed models. Maybe this
post [1] and especially the section "Running Fewer than J-1 Contrasts for J
Groups" are also informative.
Anyways, see my comments on CrossValidated.
Also, you can *always*, i.e. independent of whether the matrix is square or
not, use the generalized inverse/pseudoinverse matrix returned by
MASS::ginv(rbind(contrast1, contrast2, ...)). However, you then have to set
column names to name the contrasts.

[1]
https://rstudio-pubs-static.s3.amazonaws.com/65059_586f394d8eb84f84b1baaf56ffb6b47f.html

Cheers,
Maarten

On Fri, May 18, 2018 at 11:45 AM, Luca Danieli <mr.lucedan at hotmail.it>
wrote:

> Hello again Ben and all R users,
>
> I am having the problem that I cannot make a contrast hypothesis for a
> rectangular matrix, because I cannot invert it. Somehow, I had read
> somewhere to use the method "pseudoinverse()" instead of "solve()".
>
> But in the analysis, I cannot get the p_value of my contrast hypothesis.
> Does somebody have a suggestion on how to either:
>
>   *   create a square matrix when I have few hypothesis with a lot of
> conditions (e.g., ps_c1 = c(0.5, 0.5, -1/6, -1/6, -1/6, -1/6, -1/6, -1/6)).
> Matrix 2x8.
>   *   get the p_value of a rectangular matrix contrast hypothesis?
>
> A more detailed explanation is on stackexchange:
> https://stats.stackexchange.com/questions/346523/get-p-value
> -about-contrast-hypothesis-for-rectangular-matrix#346523
>
> Best
> Luca
>
>
> ________________________________
> From: Ben Bolker <bbolker at gmail.com>
> Sent: 14 May 2018 21:45
> To: Luca Danieli; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Free statistical analysis material?
>
>
>   The ugly spam e-mail is a known problem.  I get it too. I think the R
> mailing list administrators (I am not one of them!) are aware of the
> issue, in the meantime I think the advice given was "ignore it or update
> your spam filters".
>
>   Your 'contrast' vector for 8  conditions seems reasonable.  It really
> represents a single row of the *inverse* contrast matrix (since it
> describes the linear combination of group means that determines the
> parameter value not the linear combination of values that determines a
> group mean).  It would have to be embedded in the same kind of
> conversion code as in the examples you showed for closure and expertise
> in your example.
>
>   Did you read the PDF I linked to?
>
>   cheers
>    Ben Bolker
>
> On 2018-05-14 04:38 PM, Luca Danieli wrote:
> > Thank you for confirming the confusion.
> >
> > In general, in the example the first contrast is about the first
> > effect/variable (in this case a "musical closure") and has 4 conditions,
> > so I create a contrast like:
> >
> > condition 4 > conditions 1, 2, 3
> >
> > -> cl_c1 = c(-1/3,-1/3,-1/3,1)
> >
> > Now I want to look at another effect/variable (named "position"). This
> > has 8 conditions and I have to make a contrast like
> >
> > conditions 1, 2 > conditions 3, 4, 5, 6, 7, 8
> > Hipotetically should be (?):
> >
> > -> ps_c1 = c(0.5, 0.5, -1/6, -1/6, -1/6, -1/6, -1/6, -1/6)
> >
> > ? Guess I am wrong?
> >
> > Btw, I received the following reply from the mailing list by a certain
> > Elisa Rose. Maybe you want to dig into the issue?
> >
> > Hey  {fullname}   ///I guess that given the mailing list it couldn't
> > detect my name
> > Thanks for your response. Can I have a pic or two to start talking?
> > Please respond with pics/infos, Hope to hear back from you asap.
> >
> > Thanks,
> >
> > ------------------------------------------------------------------------
> > *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> > behalf of Ben Bolker <bbolker at gmail.com>
> > *Sent:* 14 May 2018 20:56
> > *To:* r-sig-mixed-models at r-project.org
> > *Subject:* Re: [R-sig-ME] Free statistical analysis material?
> >
> >
> >   Contrasts are confusing, and not specific to LMMs.  You might see if
> >
> > http://bbolker.github.io/mixedmodels-misc/notes/contrasts.pdf
> >
> > helps at all.  (From a quick glance at your question & code below, I'm
> > not sure what you mean by "2 conditions > 6 conditions" ???)
> >
> > On 2018-05-14 03:48 PM, Luca Danieli wrote:
> >> Hello everybody,
> >>
> >> I am trying the difficult task to conclude an interdisciplinary PhD.
> >> Statistics looks nice, and I have learned a lot about the basic
> principles and methodologies, and how they work.
> >>
> >> But I miss a lot. In particular all the little variations and methods
> due to interpretations and methodologies (for example now I am looking at
> the function of contrasts in mixed-effects models), and generally, from
> theory to applied statistics there is an incredible gap.
> >>
> >> Is anybody in this list (as I don't really have a mentor on statistics
> nor I know statisticians) be able to point me to some free materials
> (books, tutorials) to study the topic in detail, but not too much in detail?
> >>
> >> For example, in this moment, I am trying to figure the following script
> out. I understand it on its general lines, but there are really obscure
> points in my head on understanding the "why".
> >> In the following example, what I don't understand is just the
> contrasts, but the person who is following me (who is a very nice person)
> has given me the task to figure out the best way to make a contrast "2
> conditions > 6 conditions". She has suggested some guessing, but she is not
> a specialist.
> >>
> >> I was thinking that maybe you that are specialists know some free
> not-too-long source that I could read to move around.
> >>
> >> ----
> >>
> >> library(lmerTest)
> >>
> >> str(datasheet.complete)
> >> # set Score as numeric
> >> datasheet.complete$Score = as.numeric(datasheet.complete$Score)
> >>
> >> levels(datasheet.complete$Closure)
> >>
> >> # closure contrasts
> >> cl_c1 = c(-1/3,-1/3,-1/3,1)
> >> cl_c2 = c(-1/2,-1/2,1,0)
> >> cl_c3 = c(-1,1,0,0)
> >> closuremat.temp = rbind(constant = 1/4,cl_c1,cl_c2,cl_c3)
> >> closuremat = solve(closuremat.temp)
> >> closuremat = closuremat[, -1]
> >> closuremat
> >>
> >> # expertise contrasts
> >>
> >> exp_c1 = c(-1/2,-1/2,1)
> >> exp_c2 = c(-1,1,0)
> >> expmat.temp = rbind(constant = 1/3,exp_c1,exp_c2)
> >> expmat = solve(expmat.temp)
> >> expmat = expmat[, -1]
> >> expmat
> >>
> >> # set contrast
> >> contrasts(datasheet.complete$Closure) = closuremat
> >> contrasts(datasheet.complete$ExpertiseType) = expmat
> >>
> >>
> >> modela = lmer(Score~1+(1|Participant)+(1|Item), data =
> datasheet.complete, REML = TRUE)
> >> modelb = update(modela,.~.+ExpertiseType)
> >> modelc = update(modelb,.~.+Closure)
> >> modeld = update(modelc,.~.+ExpertiseType*Closure)
> >>
> >> anova(modela,modelb,modelc,modeld)
> >>
> >> model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item),
> data = datasheet.complete, REML = TRUE)
> >> summary(model)
> >>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl  Fri May 18 15:27:07 2018
From: wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl (Viechtbauer, Wolfgang (SP))
Date: Fri, 18 May 2018 13:27:07 +0000
Subject: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes
 model
In-Reply-To: <CAF5W3aRag-ODUtiyRzmpAAr-MpUT-88BOF6Yi0KZHjG2ubO1dg@mail.gmail.com>
References: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>
 <CAF5W3aQdX=EuPSAu4NOcQpY8Z2iAYLw8ZKvy2L+S0DmqpbA63Q@mail.gmail.com>
 <CABghstQpyRDRxN3cy6bipCWVWA15s2WkVs2uvuRTDBOiEeWpAw@mail.gmail.com>
 <CAF5W3aRag-ODUtiyRzmpAAr-MpUT-88BOF6Yi0KZHjG2ubO1dg@mail.gmail.com>
Message-ID: <7960b295a252497d82991c9f43280580@UM-MAIL3214.unimaas.nl>

It should be:

u_0i ~ N(0, ?^2_0)
u_1i ~ N(0, ?^2_1)
e_ij ~ N(0, sigma^2)

and it is also worth mentioning that the model allows for correlation between u_0i and u_1i. So, technically, the assumption is:

[u_0i] ~ MVN([0], [?^2_0  rho*?_0*?_1])
[u_1i]      ([0]  [       ?^2_1      ])

And if one wants to be really explicit, we assume that u_0i and e_ij are independent and u_1i and e_ij are independent.

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Juan Pablo Edwards Molina
Sent: Friday, 18 May, 2018 1:34
To: Ben Bolker
Cc: R SIG Mixed Models
Subject: Re: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes model

Thanks prof. Bolker,
Do you mean this?

u_i?N(0,?^2)      e_ij?N(0,v_i)

Juan
Juan

2018-05-17 16:57 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
> That looks about right.  You didn't specify the variance of e_ij in
> your description, and you didn't say explicitly that the u_ and e_
> values are Normally distributed ...
>
> On Thu, May 17, 2018 at 2:27 PM, Juan Pablo Edwards Molina
> <edwardsmolina at gmail.com> wrote:
>> Sorry, I edited the lmer function...
>>
>> ============================================
>> Dear list,
>>
>> I fitted a linear mixed effects models to a set of 41 field trials
>> with plot-level assessments of x,y, for estimating the linear
>> regression coefficients ?_0 and ?_1
>>
>> res1 <- lmer(y ~ x+ (x|trial), data=mydata, REML=F)
>>
>> I wish to write the model equation for its publication, so this is my first try:
>>
>> W_ij= (?_0 + u_0i)+ (?_1+ u_1i) x_ij + e_ij
>>
>> where j subscript represents the j-plot within i-trial, both for y or
>> x. ?0 and ?1 are the population average intercept and slope; u0i and
>> u1i are the effect of the i-trial on the intercept and the slope,
>> respectively, considered as random variables (with mean 0 and
>> variances  ?_u0 and  ?_u1 a )
>>
>> I?m not sure if I?m in the right path... I would really appreciate any guidance.
>>
>> Juan Edwards
>> National Institute of Agriculture Technology - Argentina

From edw@rd@molin@ @ending from gm@il@com  Fri May 18 15:42:06 2018
From: edw@rd@molin@ @ending from gm@il@com (Juan Pablo Edwards Molina)
Date: Fri, 18 May 2018 10:42:06 -0300
Subject: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes
 model
In-Reply-To: <7960b295a252497d82991c9f43280580@UM-MAIL3214.unimaas.nl>
References: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>
 <CAF5W3aQdX=EuPSAu4NOcQpY8Z2iAYLw8ZKvy2L+S0DmqpbA63Q@mail.gmail.com>
 <CABghstQpyRDRxN3cy6bipCWVWA15s2WkVs2uvuRTDBOiEeWpAw@mail.gmail.com>
 <CAF5W3aRag-ODUtiyRzmpAAr-MpUT-88BOF6Yi0KZHjG2ubO1dg@mail.gmail.com>
 <7960b295a252497d82991c9f43280580@UM-MAIL3214.unimaas.nl>
Message-ID: <CAF5W3aS+OS=jAsWtxOvyG4dw-_9c=k9bix6J399ju21AvMr3uQ@mail.gmail.com>

Excellent!

Is it the case of your example tutorial in
http://www.metafor-project.org/doku.php/tips:two_stage_analysis#mixed-effects_model_approach
?

Thanks Wolfgang!

Juan Edwards

Juan


2018-05-18 10:27 GMT-03:00 Viechtbauer, Wolfgang (SP)
<wolfgang.viechtbauer at maastrichtuniversity.nl>:
> It should be:
>
> u_0i ~ N(0, ?^2_0)
> u_1i ~ N(0, ?^2_1)
> e_ij ~ N(0, sigma^2)
>
> and it is also worth mentioning that the model allows for correlation between u_0i and u_1i. So, technically, the assumption is:
>
> [u_0i] ~ MVN([0], [?^2_0  rho*?_0*?_1])
> [u_1i]      ([0]  [       ?^2_1      ])
>
> And if one wants to be really explicit, we assume that u_0i and e_ij are independent and u_1i and e_ij are independent.
>
> Best,
> Wolfgang
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Juan Pablo Edwards Molina
> Sent: Friday, 18 May, 2018 1:34
> To: Ben Bolker
> Cc: R SIG Mixed Models
> Subject: Re: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes model
>
> Thanks prof. Bolker,
> Do you mean this?
>
> u_i?N(0,?^2)      e_ij?N(0,v_i)
>
> Juan
> Juan
>
> 2018-05-17 16:57 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>> That looks about right.  You didn't specify the variance of e_ij in
>> your description, and you didn't say explicitly that the u_ and e_
>> values are Normally distributed ...
>>
>> On Thu, May 17, 2018 at 2:27 PM, Juan Pablo Edwards Molina
>> <edwardsmolina at gmail.com> wrote:
>>> Sorry, I edited the lmer function...
>>>
>>> ============================================
>>> Dear list,
>>>
>>> I fitted a linear mixed effects models to a set of 41 field trials
>>> with plot-level assessments of x,y, for estimating the linear
>>> regression coefficients ?_0 and ?_1
>>>
>>> res1 <- lmer(y ~ x+ (x|trial), data=mydata, REML=F)
>>>
>>> I wish to write the model equation for its publication, so this is my first try:
>>>
>>> W_ij= (?_0 + u_0i)+ (?_1+ u_1i) x_ij + e_ij
>>>
>>> where j subscript represents the j-plot within i-trial, both for y or
>>> x. ?0 and ?1 are the population average intercept and slope; u0i and
>>> u1i are the effect of the i-trial on the intercept and the slope,
>>> respectively, considered as random variables (with mean 0 and
>>> variances  ?_u0 and  ?_u1 a )
>>>
>>> I?m not sure if I?m in the right path... I would really appreciate any guidance.
>>>
>>> Juan Edwards
>>> National Institute of Agriculture Technology - Argentina


From wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl  Fri May 18 15:48:35 2018
From: wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl (Viechtbauer, Wolfgang (SP))
Date: Fri, 18 May 2018 13:48:35 +0000
Subject: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes
 model
In-Reply-To: <CAF5W3aS+OS=jAsWtxOvyG4dw-_9c=k9bix6J399ju21AvMr3uQ@mail.gmail.com>
References: <CAF5W3aTMi4CdVQQTY8Q8fG_5VWixU-s_5Ya029giS4=L6P3pDw@mail.gmail.com>
 <CAF5W3aQdX=EuPSAu4NOcQpY8Z2iAYLw8ZKvy2L+S0DmqpbA63Q@mail.gmail.com>
 <CABghstQpyRDRxN3cy6bipCWVWA15s2WkVs2uvuRTDBOiEeWpAw@mail.gmail.com>
 <CAF5W3aRag-ODUtiyRzmpAAr-MpUT-88BOF6Yi0KZHjG2ubO1dg@mail.gmail.com>
 <7960b295a252497d82991c9f43280580@UM-MAIL3214.unimaas.nl>
 <CAF5W3aS+OS=jAsWtxOvyG4dw-_9c=k9bix6J399ju21AvMr3uQ@mail.gmail.com>
Message-ID: <d89bff8f1a814ef5b66b896b074d51f6@UM-MAIL3214.unimaas.nl>

Yes, that's the same model.

Best,
Wolfgang

-----Original Message-----
From: Juan Pablo Edwards Molina [mailto:edwardsmolina at gmail.com] 
Sent: Friday, 18 May, 2018 15:42
To: Viechtbauer, Wolfgang (SP)
Cc: R SIG Mixed Models
Subject: Re: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes model

Excellent!

Is it the case of your example tutorial in
http://www.metafor-project.org/doku.php/tips:two_stage_analysis#mixed-effects_model_approach
?

Thanks Wolfgang!

Juan Edwards

Juan

2018-05-18 10:27 GMT-03:00 Viechtbauer, Wolfgang (SP)
<wolfgang.viechtbauer at maastrichtuniversity.nl>:
> It should be:
>
> u_0i ~ N(0, ?^2_0)
> u_1i ~ N(0, ?^2_1)
> e_ij ~ N(0, sigma^2)
>
> and it is also worth mentioning that the model allows for correlation between u_0i and u_1i. So, technically, the assumption is:
>
> [u_0i] ~ MVN([0], [?^2_0  rho*?_0*?_1])
> [u_1i]      ([0]  [       ?^2_1      ])
>
> And if one wants to be really explicit, we assume that u_0i and e_ij are independent and u_1i and e_ij are independent.
>
> Best,
> Wolfgang
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Juan Pablo Edwards Molina
> Sent: Friday, 18 May, 2018 1:34
> To: Ben Bolker
> Cc: R SIG Mixed Models
> Subject: Re: [R-sig-ME] Fwd: syntax equation of random intercepts and slopes model
>
> Thanks prof. Bolker,
> Do you mean this?
>
> u_i?N(0,?^2)      e_ij?N(0,v_i)
>
> Juan
> Juan
>
> 2018-05-17 16:57 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>> That looks about right.  You didn't specify the variance of e_ij in
>> your description, and you didn't say explicitly that the u_ and e_
>> values are Normally distributed ...
>>
>> On Thu, May 17, 2018 at 2:27 PM, Juan Pablo Edwards Molina
>> <edwardsmolina at gmail.com> wrote:
>>> Sorry, I edited the lmer function...
>>>
>>> ============================================
>>> Dear list,
>>>
>>> I fitted a linear mixed effects models to a set of 41 field trials
>>> with plot-level assessments of x,y, for estimating the linear
>>> regression coefficients ?_0 and ?_1
>>>
>>> res1 <- lmer(y ~ x+ (x|trial), data=mydata, REML=F)
>>>
>>> I wish to write the model equation for its publication, so this is my first try:
>>>
>>> W_ij= (?_0 + u_0i)+ (?_1+ u_1i) x_ij + e_ij
>>>
>>> where j subscript represents the j-plot within i-trial, both for y or
>>> x. ?0 and ?1 are the population average intercept and slope; u0i and
>>> u1i are the effect of the i-trial on the intercept and the slope,
>>> respectively, considered as random variables (with mean 0 and
>>> variances  ?_u0 and  ?_u1 a )
>>>
>>> I?m not sure if I?m in the right path... I would really appreciate any guidance.
>>>
>>> Juan Edwards
>>> National Institute of Agriculture Technology - Argentina

From ire@rojo @ending from gm@il@com  Mon May 21 10:51:34 2018
From: ire@rojo @ending from gm@il@com (Irene Rojo)
Date: Mon, 21 May 2018 10:51:34 +0200
Subject: [R-sig-ME] Cheking for outliers after fitting a glmmTMB
Message-ID: <CAGJ2grb1s7jrei7ztSdhH75LCOxKEiFD+aoisWdc1jwj4aUmuQ@mail.gmail.com>

Dear all,

I am trying to check the assumptions after fitting a glmm with the glmmTMB
package.

However, I don't know how to get the Residuals vs Leverage plot and Cook's
distance. Neither the "leveragePlot(model)" nor "leverage.plot(model)"
functions do work with an object of class glmmTMB. Can anyone give some
advice of how can I get it?

Thank you so much,

Irene

	[[alternative HTML version deleted]]


From mr@luced@n @ending from hotm@il@it  Mon May 21 14:03:44 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Mon, 21 May 2018 12:03:44 +0000
Subject: [R-sig-ME] It's hours I am trying to install emmeans
Message-ID: <CWXP265MB0470E67A690E86E499087100F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>

Hi there,

As said above, I am trying to install emmeans since a few hours. I am in Ubuntu 18.04.

I have attempted different approaches, but it's always the same: the package starts downloading and it gets slower and slower, until my machine becomes unusable, and the installation keeps running - probably it get stuck in a loop; maybe I just have to wait, I don't understand.

Sure is that right now I have tried to install a dependency alone, to break down the installation process into more achievable steps, and I am installing the "shinystan" package, which, great news, has just finished after 10 minutes by saying that had non-zero exit status.

Now I will continue installing some dependencies, but if you were aware why it takes so long, it would be nice to know if there is any problem.

Best
Luca

Get Outlook for Android<https://aka.ms/ghei36>


	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Mon May 21 14:43:53 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Mon, 21 May 2018 12:43:53 +0000
Subject: [R-sig-ME] Cheking for outliers after fitting a glmmTMB
In-Reply-To: <6121_1526892703_w4L8pgFV009126_CAGJ2grb1s7jrei7ztSdhH75LCOxKEiFD+aoisWdc1jwj4aUmuQ@mail.gmail.com>
References: <6121_1526892703_w4L8pgFV009126_CAGJ2grb1s7jrei7ztSdhH75LCOxKEiFD+aoisWdc1jwj4aUmuQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836808407@FHSDB2D11-2.csu.mcmaster.ca>

Dear Irene,

You're apparently trying to use the leveragePlot() function in the car package. That doesn't plot residuals vs. hat-values (leverages) but is rather a variation on added-variable plots. 

The car package does have some influence diagnostics for mixed models, but unfortunately only for models fit with functions in the lme4 and nlme packages. See ?influence.mixed.models . Perhaps you can adapt our code to the glmmTMB package.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/

 

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Irene Rojo
> Sent: Monday, May 21, 2018 4:52 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Cheking for outliers after fitting a glmmTMB
> 
> Dear all,
> 
> I am trying to check the assumptions after fitting a glmm with the glmmTMB
> package.
> 
> However, I don't know how to get the Residuals vs Leverage plot and Cook's
> distance. Neither the "leveragePlot(model)" nor "leverage.plot(model)"
> functions do work with an object of class glmmTMB. Can anyone give some
> advice of how can I get it?
> 
> Thank you so much,
> 
> Irene
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mr@luced@n @ending from hotm@il@it  Mon May 21 15:17:16 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Mon, 21 May 2018 13:17:16 +0000
Subject: [R-sig-ME] It's hours I am trying to install emmeans
In-Reply-To: <CWXP265MB0470E67A690E86E499087100F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB0470E67A690E86E499087100F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CWXP265MB0470B63CB082D03198272D17F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>

New information.

When installing "brms", I get the error

-> ERROR: dependency ?shinystan? is not available for package ?brms?

Do you know whether shinystan is available?

Best
Luca
________________________________
From: Luca Danieli <mr.lucedan at hotmail.it>
Sent: 21 May 2018 13:03
To: r-sig-mixed-models at r-project.org
Subject: It's hours I am trying to install emmeans

Hi there,

As said above, I am trying to install emmeans since a few hours. I am in Ubuntu 18.04.

I have attempted different approaches, but it's always the same: the package starts downloading and it gets slower and slower, until my machine becomes unusable, and the installation keeps running - probably it get stuck in a loop; maybe I just have to wait, I don't understand.

Sure is that right now I have tried to install a dependency alone, to break down the installation process into more achievable steps, and I am installing the "shinystan" package, which, great news, has just finished after 10 minutes by saying that had non-zero exit status.

Now I will continue installing some dependencies, but if you were aware why it takes so long, it would be nice to know if there is any problem.

Best
Luca

Get Outlook for Android<https://aka.ms/ghei36>


	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Mon May 21 16:08:04 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Mon, 21 May 2018 16:08:04 +0200
Subject: [R-sig-ME] Cheking for outliers after fitting a glmmTMB
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836808407@FHSDB2D11-2.csu.mcmaster.ca>
References: <6121_1526892703_w4L8pgFV009126_CAGJ2grb1s7jrei7ztSdhH75LCOxKEiFD+aoisWdc1jwj4aUmuQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836808407@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <79C27E2F-5BB8-410A-B563-B195D0213BBA@gmail.com>

Hi Irene,

Some residual diagnostics can be done with the DHARMa package, but maybe not Cook?s distance and leverage. 

Here?s the main documentation
https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html <https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html>

and here?s a discussion about using it with glmmTMB
https://github.com/florianhartig/DHARMa/issues/16 <https://github.com/florianhartig/DHARMa/issues/16>

cheers,
Mollie

???????????
Mollie E. Brooks, Ph.D.
Research Scientist
National Institute of Aquatic Resources
Technical University of Denmark

> On 21May 2018, at 14:43, Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Irene,
> 
> You're apparently trying to use the leveragePlot() function in the car package. That doesn't plot residuals vs. hat-values (leverages) but is rather a variation on added-variable plots. 
> 
> The car package does have some influence diagnostics for mixed models, but unfortunately only for models fit with functions in the lme4 and nlme packages. See ?influence.mixed.models . Perhaps you can adapt our code to the glmmTMB package.
> 
> I hope this helps,
> John
> 
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
> 
> 
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Irene Rojo
>> Sent: Monday, May 21, 2018 4:52 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Cheking for outliers after fitting a glmmTMB
>> 
>> Dear all,
>> 
>> I am trying to check the assumptions after fitting a glmm with the glmmTMB
>> package.
>> 
>> However, I don't know how to get the Residuals vs Leverage plot and Cook's
>> distance. Neither the "leveragePlot(model)" nor "leverage.plot(model)"
>> functions do work with an object of class glmmTMB. Can anyone give some
>> advice of how can I get it?
>> 
>> Thank you so much,
>> 
>> Irene
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From drmccloy @ending from uw@edu  Mon May 21 17:22:53 2018
From: drmccloy @ending from uw@edu (Dan McCloy)
Date: Mon, 21 May 2018 08:22:53 -0700
Subject: [R-sig-ME] It's hours I am trying to install emmeans
In-Reply-To: <CWXP265MB0470B63CB082D03198272D17F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB0470E67A690E86E499087100F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
 <CWXP265MB0470B63CB082D03198272D17F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CAOE0pYmECBk9eWDTAYMQ29EmvuA-FjyjSusQXOLen5LV2o65AA@mail.gmail.com>

Whenever you get a message saying something "finished with non-zero exit
status", that means something went wrong, and almost certainly the software
is not properly installed.  Without more information about the specific
error messages, there is little we can do to help.  I suggest you try a
site like https://askubuntu.com/ for general help with installing software
for Ubuntu...  this email list is more focused on how to perform mixed
effects analysis, not how to install the packages.

As far as general advice when faced with problems like this, the first step
is to read the messages in the terminal.  Buried in there will often be a
clue to what is going wrong, like "no space left on disk", "permission
denied", or "prerequisite not available".


On Mon, May 21, 2018 at 6:17 AM, Luca Danieli <mr.lucedan at hotmail.it> wrote:

> New information.
>
> When installing "brms", I get the error
>
> -> ERROR: dependency ?shinystan? is not available for package ?brms?
>
> Do you know whether shinystan is available?
>
> Best
> Luca
> ________________________________
> From: Luca Danieli <mr.lucedan at hotmail.it>
> Sent: 21 May 2018 13:03
> To: r-sig-mixed-models at r-project.org
> Subject: It's hours I am trying to install emmeans
>
> Hi there,
>
> As said above, I am trying to install emmeans since a few hours. I am in
> Ubuntu 18.04.
>
> I have attempted different approaches, but it's always the same: the
> package starts downloading and it gets slower and slower, until my machine
> becomes unusable, and the installation keeps running - probably it get
> stuck in a loop; maybe I just have to wait, I don't understand.
>
> Sure is that right now I have tried to install a dependency alone, to
> break down the installation process into more achievable steps, and I am
> installing the "shinystan" package, which, great news, has just finished
> after 10 minutes by saying that had non-zero exit status.
>
> Now I will continue installing some dependencies, but if you were aware
> why it takes so long, it would be nice to know if there is any problem.
>
> Best
> Luca
>
> Get Outlook for Android<https://aka.ms/ghei36>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From ru@@ell-lenth @ending from uiow@@edu  Mon May 21 17:47:48 2018
From: ru@@ell-lenth @ending from uiow@@edu (Lenth, Russell V)
Date: Mon, 21 May 2018 15:47:48 +0000
Subject: [R-sig-ME] It's hours I am trying to install emmeans
In-Reply-To: <mailman.16502.994.1526916252.32595.r-sig-mixed-models@r-project.org>
References: <mailman.16502.994.1526916252.32595.r-sig-mixed-models@r-project.org>
Message-ID: <2B269630-6EDF-4516-BD09-1966DC0521C3@uiowa.edu>

I made an unwise choice in version 1.2 of emmeans, by putting brms in Imports. That has the effect of expanding the dependencies in emmeans to over 100 other packages. I have rectified that in the latest github version, which depends on many fewer other packages and won?t create such an installation nightmare (I hope). 

A new version 1.2.1 has been submitted to CRAN but so far it has not been accepted. It?s not clear if it will or won?t because if the short time since the previous version. 

Russ Lenth 


From mr@luced@n @ending from hotm@il@it  Mon May 21 17:50:26 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Mon, 21 May 2018 15:50:26 +0000
Subject: [R-sig-ME] It's hours I am trying to install emmeans
In-Reply-To: <2B269630-6EDF-4516-BD09-1966DC0521C3@uiowa.edu>
References: <mailman.16502.994.1526916252.32595.r-sig-mixed-models@r-project.org>,
 <2B269630-6EDF-4516-BD09-1966DC0521C3@uiowa.edu>
Message-ID: <CWXP265MB0470EB87A6A9639015B9ACA5F6950@CWXP265MB0470.GBRP265.PROD.OUTLOOK.COM>

Great! :) Good to know. Thanks for working for us!

Best
Luca
________________________________
From: Lenth, Russell V <russell-lenth at uiowa.edu>
Sent: 21 May 2018 16:47
To: r-sig-mixed-models at r-project.org
Cc: Luca Danieli
Subject: Re: It's hours I am trying to install emmeans

I made an unwise choice in version 1.2 of emmeans, by putting brms in Imports. That has the effect of expanding the dependencies in emmeans to over 100 other packages. I have rectified that in the latest github version, which depends on many fewer other packages and won?t create such an installation nightmare (I hope).

A new version 1.2.1 has been submitted to CRAN but so far it has not been accepted. It?s not clear if it will or won?t because if the short time since the previous version.

Russ Lenth


	[[alternative HTML version deleted]]


From ru@@ell-lenth @ending from uiow@@edu  Mon May 21 20:52:18 2018
From: ru@@ell-lenth @ending from uiow@@edu (Lenth, Russell V)
Date: Mon, 21 May 2018 18:52:18 +0000
Subject: [R-sig-ME] It's hours I am trying to install emmeans
In-Reply-To: <2B269630-6EDF-4516-BD09-1966DC0521C3@uiowa.edu>
References: <mailman.16502.994.1526916252.32595.r-sig-mixed-models@r-project.org>,
 <2B269630-6EDF-4516-BD09-1966DC0521C3@uiowa.edu>
Message-ID: <ADE0B7ED-9A9D-4910-93A7-E067379027D7@uiowa.edu>

Emmeans 1.2.1 is now on its way to CRAN and it?s mirrors. It should be a lot easier to install. 

Russ

> On May 21, 2018, at 8:47 AM, Lenth, Russell V <russell-lenth at uiowa.edu> wrote:
> 
> I made an unwise choice in version 1.2 of emmeans, by putting brms in Imports. That has the effect of expanding the dependencies in emmeans to over 100 other packages. I have rectified that in the latest github version, which depends on many fewer other packages and won?t create such an installation nightmare (I hope). 
> 
> A new version 1.2.1 has been submitted to CRAN but so far it has not been accepted. It?s not clear if it will or won?t because if the short time since the previous version. 
> 
> Russ Lenth 
> 

From reinhold@kliegl @ending from gm@il@com  Tue May 22 00:21:55 2018
From: reinhold@kliegl @ending from gm@il@com (Reinhold Kliegl)
Date: Tue, 22 May 2018 00:21:55 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
Message-ID: <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>

Sorry, I am somewhat late to this conversation. I am responding to this
thread, because it fits my comment very well, but it was initially
triggered by a previous thread, especially Rune Haubo's post here [1]. So I
hope it is ok to continue here.

I have a few comments and questions. For details I refer to an RPub I put
up along with this post [2]. I start with a translation between Rune
Haubo's fm's and the terminology I use in the RPub:

 fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
 fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in RE
(zcpLMM_RE0)
 fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
interaction (intLMM),
 fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
 fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in RE
(zcpLMM_RE1)

Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6 are in
Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and fm5 so
far (see below).

(I) The post was triggered by the question whether intLMM is nested under
zcpLMM. I had included this LRT in my older RPub cited in the thread, but I
stand corrected and agree with Rune Haubo that intLMM is not nested under
zcpLMM. For example, in the new RPub, I show that slightly modified
Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
additional model parameter in the latter. Thanks for the critical reading.


(II) Here are Runo Haubo's sequences (left, resorted) augmented with my
translation (right)

(1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     -> minLMM
(2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
(3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2

and here are sequences I came up with (left) augmented with translation
into RH's fm's.

(1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
(3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
(4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new sequence)


(III) I have questions about fm2 and fm5.
   fm2: fm2 redefines the levels of the group factor (e.g., in the cake
data there are 45 groups in fm2 compared to 15 in the other models). Why is
fm2 nested under fm3 and fm6? Somehow it looks to me that you include an
f:g interaction without the g main effect (relative to fm4). This looks
like an interesting model; I would appreciate a bit more conceptual support
for its interpretation in the model hierarchy.
   fm5: fm5 specifies 4 variance components (VCs), but the factor has only
3 levels. So to me this looks like there is redundancy built into the
model. In support of this intuition, for the cake data, one of the VCs is
estimated with 0. However, in the Machine data the model was not
degenerate. So I am not sure. In other words, if the factor levels are A,
B, C, and the two contrasts are c1 and c2, I thought I can specify either
(1 + c1 + c2) or (0 + A + B + C). fm5 specifies (1 + A + B + C) which is
rank deficient in the fixed effect part, but not necessarily in the
random-effect term. What am I missing here?

[1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
[2] http://rpubs.com/Reinhold/391027

Best,
Reinhold Kliegl


On Thu, May 17, 2018 at 12:43 PM, Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
> Dear list,
>
> When one wants to specify a lmer model including variance components but
no
> correlation parameters for categorical predictors (factors) afaik one has
> to convert the factors to numeric covariates or use lme4::dummy(). Until
> recently I thought m2a (or equivalently m2b using the double-bar syntax)
> would be the correct way to specify such a zero-correlation parameter
model.
>
> But in this thread [1] Rune Haubo Bojesen Christensen pointed out that
this
> model does not make sense to him. Instead he suggests m3 as an appropriate
> model.
> I think this is a *highly relevant difference* for everyone who uses
> factors in lmer and therefore I'm bringing up this issue again. But maybe
> I'm mistaken and just don't get what is quite obvious for more experienced
> mixed modelers.
> Please note that the question is on CrossValidated [2] but some consider
it
> as off-topic and I don't think there will be an answer any time soon.
>
> So here are my questions:
> How should one specify a lmm without correlation parameters for factors
and
> what are the differences between m2a and m3?
> Is there a preferred model for model comparison with m4 (this model is
also
> discussed here [3])?
>
> library("lme4")
> data("Machines", package = "MEMSS")
>
> d <- Machines
> contrasts(d$Machine)  # default coding: contr.sum
>
> m1 <- lmer(score ~ Machine + (Machine | Worker), d)
>
> c1 <- model.matrix(m1)[, 2]
> c2 <- model.matrix(m1)[, 3]
> m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 + c2 |
> Worker), d)
> m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
> VarCorr(m2a)
>  Groups   Name        Std.Dev.
>  Worker   (Intercept) 5.24354
>  Worker.1 c1          2.58446
>  Worker.2 c2          3.71504
>  Residual             0.96256
>
> m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A") |
> Worker) +
>                                             (0 + dummy(Machine, "B") |
> Worker) +
>                                             (0 + dummy(Machine, "C") |
> Worker), d)
> VarCorr(m3)
>  Groups   Name                Std.Dev.
>  Worker   (Intercept)         3.78595
>  Worker.1 dummy(Machine, "A") 1.94032
>  Worker.2 dummy(Machine, "B") 5.87402
>  Worker.3 dummy(Machine, "C") 2.84547
>  Residual                     0.96158
>
> m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
>
>
> [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
> [2] https://stats.stackexchange.com/q/345842/136579
> [3] https://stats.stackexchange.com/q/304374/136579
>
> Best regards,
> Maarten
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From orchidn @ending from live@com  Tue May 22 01:36:53 2018
From: orchidn @ending from live@com (dani)
Date: Mon, 21 May 2018 23:36:53 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
Message-ID: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,


I am working with a glmmTMB model with two random effects. Some of my covariates have non-parametric associations with my dependent variable so I would like to fit splines for them. I am not sure how my code should look like.


Could someone point me towards an example using glmmTMB with splines? I am not really sure how to interpret such a model.


Thanks!

Best regards,

Dani



<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Tue May 22 02:09:09 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 21 May 2018 20:09:09 -0400
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <511ed65a-1715-a11c-9c5a-8ef1d48c3643@gmail.com>


  I don't know of an example offhand, but

https://stats.stackexchange.com/questions/301666/using-splines-in-r-lme4glmer-scale-issues

  gives an example of using splines::ns().  Basically, you can use ns()
as a drop-in term within a formula; unlike the magical s() function in
mgcv, you have to specify the number of knots/degrees of freedom
yourself (splines::ns fits regression splines, mgcv::s fits *penalized*
regression splines).

  Perhaps not known to everyone, mgcv can handle some forms of
zero-inflation (although I think it does ZIP but not ZINB), so
https://www.fromthebottomoftheheap.net/2017/05/04/compare-mgcv-with-glmmTMB/

might also be useful.

Here's an example. It is in principle possible to use
(ns(Days,5)|Subject) as the random effect (i.e. let curves vary among
individuals), but it didn't work in this case -- too complex for this
medium-size data set.

library(glmmTMB)
data(sleepstudy,package="lme4")

library(splines)
m1 <- glmmTMB(Reaction~ns(Days,5)+(1|Subject), data=sleepstudy)
sleepstudy$pred <- predict(m1)

library(ggplot2)
ggplot(sleepstudy,aes(x=Days))+geom_point(aes(y=Reaction))+geom_line(aes(y=pred,group=Subject))





On 2018-05-21 07:36 PM, dani wrote:
> Hello everyone,
> 
> 
> I am working with a glmmTMB model with two random effects. Some of my
> covariates have non-parametric associations with my dependent
> variable so I would like to fit splines for them. I am not sure how
> my code should look like.
> 
> 
> Could someone point me towards an example using glmmTMB with splines?
> I am not really sure how to interpret such a model.
> 
> 
> Thanks!
> 
> Best regards,
> 
> Dani
> 
> 
> 
> <http://aka.ms/weboutlook>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From orchidn @ending from live@com  Tue May 22 02:13:12 2018
From: orchidn @ending from live@com (dani)
Date: Tue, 22 May 2018 00:13:12 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <511ed65a-1715-a11c-9c5a-8ef1d48c3643@gmail.com>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <511ed65a-1715-a11c-9c5a-8ef1d48c3643@gmail.com>
Message-ID: <MWHPR1201MB00292A5FA62D9044EC36BF25D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Dr Bolker,


Thank you so much for your prompt and helpful answer! This is great!

Best regards,

Dani


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Monday, May 21, 2018 5:09 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB- fitting splines


  I don't know of an example offhand, but

https://stats.stackexchange.com/questions/301666/using-splines-in-r-lme4glmer-scale-issues

  gives an example of using splines::ns().  Basically, you can use ns()
as a drop-in term within a formula; unlike the magical s() function in
mgcv, you have to specify the number of knots/degrees of freedom
yourself (splines::ns fits regression splines, mgcv::s fits *penalized*
regression splines).

  Perhaps not known to everyone, mgcv can handle some forms of
zero-inflation (although I think it does ZIP but not ZINB), so
https://www.fromthebottomoftheheap.net/2017/05/04/compare-mgcv-with-glmmTMB/

might also be useful.

Here's an example. It is in principle possible to use
(ns(Days,5)|Subject) as the random effect (i.e. let curves vary among
individuals), but it didn't work in this case -- too complex for this
medium-size data set.

library(glmmTMB)
data(sleepstudy,package="lme4")

library(splines)
m1 <- glmmTMB(Reaction~ns(Days,5)+(1|Subject), data=sleepstudy)
sleepstudy$pred <- predict(m1)

library(ggplot2)
ggplot(sleepstudy,aes(x=Days))+geom_point(aes(y=Reaction))+geom_line(aes(y=pred,group=Subject))





On 2018-05-21 07:36 PM, dani wrote:
> Hello everyone,
>
>
> I am working with a glmmTMB model with two random effects. Some of my
> covariates have non-parametric associations with my dependent
> variable so I would like to fit splines for them. I am not sure how
> my code should look like.
>
>
> Could someone point me towards an example using glmmTMB with splines?
> I am not really sure how to interpret such a model.
>
>
> Thanks!
>
> Best regards,
>
> Dani
>
>
>
> <http://aka.ms/weboutlook>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From john@m@indon@ld @ending from @nu@edu@@u  Tue May 22 04:10:35 2018
From: john@m@indon@ld @ending from @nu@edu@@u (John Maindonald)
Date: Tue, 22 May 2018 02:10:35 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <FF6A434C-32BB-430E-A3E3-E2FB739A2E97@anu.edu.au>

There is an example at http://www.rpubs.com/johnhm/Overdispersed
See Section 2.2 .


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 22/05/2018, at 11:36, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:




	[[alternative HTML version deleted]]


From orchidn @ending from live@com  Tue May 22 04:41:27 2018
From: orchidn @ending from live@com (dani)
Date: Tue, 22 May 2018 02:41:27 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <FF6A434C-32BB-430E-A3E3-E2FB739A2E97@anu.edu.au>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <FF6A434C-32BB-430E-A3E3-E2FB739A2E97@anu.edu.au>
Message-ID: <MWHPR1201MB0029D25E050284B7882582C5D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi John,

Thank you so much! This is very helpful! I managed to run it  but I am not sure how to interpret the results as I get this:


# Conditional model:
#                                                    Estimate Std. Error z value Pr(>|z|)
# (Intercept)                             -8.40461    1.58077  -5.317 1.06e-07 ***
# splines::ns(newage, 2)1     -1.89262    0.57246  -3.306 0.000946 ***
# splines::ns(newage, 2)2      0.10296    0.47268   0.218 0.827575


I am not sure what to make of the two different spline results.

Best regards,

D

________________________________
From: John Maindonald <john.maindonald at anu.edu.au>
Sent: Monday, May 21, 2018 7:10 PM
To: dani
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

There is an example at http://www.rpubs.com/johnhm/Overdispersed
See Section 2.2 .


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 22/05/2018, at 11:36, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:




	[[alternative HTML version deleted]]


From john@m@indon@ld @ending from @nu@edu@@u  Tue May 22 07:00:21 2018
From: john@m@indon@ld @ending from @nu@edu@@u (John Maindonald)
Date: Tue, 22 May 2018 05:00:21 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <MWHPR1201MB0029D25E050284B7882582C5D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <FF6A434C-32BB-430E-A3E3-E2FB739A2E97@anu.edu.au>
 <MWHPR1201MB0029D25E050284B7882582C5D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <6CEF79D5-097C-4341-B7D7-6349E2312884@anu.edu.au>

The spline coefficients multiply the two basis terms.  Most times, one wants to
work with predicted values and standard errors.  The predict method seems
not yet to have been implemented for glmmTMB models with a betabinomial
error family.  One can use fitted() to get just the fitted probabilities, and do a
complementary log-log transform (in this instance) to get predictions on the
scale of the linear predictor (NB, linear in the sense that it is a linear combination
of the basis functions, plus intercept).

The output suggests that the first basis term might be enough on its own.
Observe, however, to choose a simple case:

> x <- 1:5; splines::ns(x, 2)[, 1]
[1] 0.0000000 0.3570466 0.5662628 0.5290951 0.3440969

This is a very nonlinear function of x, quite different from the linear function
of x that one gets by typing splines::ns(x, 1)

Regression thin plate splines, as implemented in mgcv. have the advantage
that the initial basis terms change only very slightly as one moves to a higher
degree of freedom basis.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 22/05/2018, at 14:41, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:

Hi John,
Thank you so much! This is very helpful! I managed to run it  but I am not sure how to interpret the results as I get this:


# Conditional model:
#                                                    Estimate Std. Error z value Pr(>|z|)
# (Intercept)                             -8.40461    1.58077  -5.317 1.06e-07 ***
# splines::ns(newage, 2)1     -1.89262    0.57246  -3.306 0.000946 ***
# splines::ns(newage, 2)2      0.10296    0.47268   0.218 0.827575


I am not sure what to make of the two different spline results.
Best regards,
D
________________________________
From: John Maindonald <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>>
Sent: Monday, May 21, 2018 7:10 PM
To: dani
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

There is an example at http://www.rpubs.com/johnhm/Overdispersed
See Section 2.2 .

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 22/05/2018, at 11:36, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:


	[[alternative HTML version deleted]]


From reinhold@kliegl @ending from gm@il@com  Tue May 22 09:45:36 2018
From: reinhold@kliegl @ending from gm@il@com (Reinhold Kliegl)
Date: Tue, 22 May 2018 09:45:36 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
Message-ID: <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>

Ok, I figured out the answer to the question about fm2.

fm2 is indeed a very nice baseline for fm3 and fm4. So I distinguish
between min1LMM and min2LMM.

 fm1 = y ~ 1 + f + (1 | g)               # minimal LMM version 1  (min1LMM)
 fm2 = y ~ 1 + f + (1 | f:g)             # minimal LMM version 2  (min2LMM)
 fm3 = y ~ 1 + f + (0 + f || g)          # zcpLMM with 0 in RE (zcpLMM_RE0)
 fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)   # LMM w/ f x g interaction (intLMM)
 fm5 = y ~ 1 + f + (1 | g) + (0 + f | g) # N/A
 fm6 = y ~ 1 + f + (1 + f |  g)          # maximal LMM (maxLMM)
 fm7 = y ~ 1 + f + (1 + f || g)          # zcpLMM with 1 in RE (zcpLMM_RE1)


(1) maxLMM_RE1 -> intLMM     -> min1LMM  # fm6 -> fm4 -> fm1
(2) maxLMM_RE1 -> intLMM     -> min2LMM  # fm6 -> fm4 -> fm2
(3) maxLMM_RE0 -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm3 -> fm2
(4) maxLMM_RE1 -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm7 -> fm1  (new sequence)


On Tue, May 22, 2018 at 12:21 AM, Reinhold Kliegl <reinhold.kliegl at gmail.com
> wrote:

> Sorry, I am somewhat late to this conversation. I am responding to this
> thread, because it fits my comment very well, but it was initially
> triggered by a previous thread, especially Rune Haubo's post here [1]. So I
> hope it is ok to continue here.
>
> I have a few comments and questions. For details I refer to an RPub I put
> up along with this post [2]. I start with a translation between Rune
> Haubo's fm's and the terminology I use in the RPub:
>
>  fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
>  fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in RE
> (zcpLMM_RE0)
>  fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
> interaction (intLMM),
>  fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
>  fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in RE
> (zcpLMM_RE1)
>
> Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6 are
> in Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and fm5
> so far (see below).
>
> (I) The post was triggered by the question whether intLMM is nested under
> zcpLMM. I had included this LRT in my older RPub cited in the thread, but I
> stand corrected and agree with Rune Haubo that intLMM is not nested under
> zcpLMM. For example, in the new RPub, I show that slightly modified
> Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
> additional model parameter in the latter. Thanks for the critical reading.
>
>
> (II) Here are Runo Haubo's sequences (left, resorted) augmented with my
> translation (right)
>
> (1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     -> minLMM
> (2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
> (3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2
>
> and here are sequences I came up with (left) augmented with translation
> into RH's fm's.
>
> (1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
> (3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
> (4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new sequence)
>
>
> (III) I have questions about fm2 and fm5.
>    fm2: fm2 redefines the levels of the group factor (e.g., in the cake
> data there are 45 groups in fm2 compared to 15 in the other models). Why is
> fm2 nested under fm3 and fm6? Somehow it looks to me that you include an
> f:g interaction without the g main effect (relative to fm4). This looks
> like an interesting model; I would appreciate a bit more conceptual support
> for its interpretation in the model hierarchy.
>    fm5: fm5 specifies 4 variance components (VCs), but the factor has only
> 3 levels. So to me this looks like there is redundancy built into the
> model. In support of this intuition, for the cake data, one of the VCs is
> estimated with 0. However, in the Machine data the model was not
> degenerate. So I am not sure. In other words, if the factor levels are A,
> B, C, and the two contrasts are c1 and c2, I thought I can specify either
> (1 + c1 + c2) or (0 + A + B + C). fm5 specifies (1 + A + B + C) which is
> rank deficient in the fixed effect part, but not necessarily in the
> random-effect term. What am I missing here?
>
> [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
> [2] http://rpubs.com/Reinhold/391027
>
> Best,
> Reinhold Kliegl
>
>
> On Thu, May 17, 2018 at 12:43 PM, Maarten Jung <Maarten.Jung at mailbox.tu-
> dresden.de> wrote:
> >
> > Dear list,
> >
> > When one wants to specify a lmer model including variance components but
> no
> > correlation parameters for categorical predictors (factors) afaik one has
> > to convert the factors to numeric covariates or use lme4::dummy(). Until
> > recently I thought m2a (or equivalently m2b using the double-bar syntax)
> > would be the correct way to specify such a zero-correlation parameter
> model.
> >
> > But in this thread [1] Rune Haubo Bojesen Christensen pointed out that
> this
> > model does not make sense to him. Instead he suggests m3 as an
> appropriate
> > model.
> > I think this is a *highly relevant difference* for everyone who uses
> > factors in lmer and therefore I'm bringing up this issue again. But maybe
> > I'm mistaken and just don't get what is quite obvious for more
> experienced
> > mixed modelers.
> > Please note that the question is on CrossValidated [2] but some consider
> it
> > as off-topic and I don't think there will be an answer any time soon.
> >
> > So here are my questions:
> > How should one specify a lmm without correlation parameters for factors
> and
> > what are the differences between m2a and m3?
> > Is there a preferred model for model comparison with m4 (this model is
> also
> > discussed here [3])?
> >
> > library("lme4")
> > data("Machines", package = "MEMSS")
> >
> > d <- Machines
> > contrasts(d$Machine)  # default coding: contr.sum
> >
> > m1 <- lmer(score ~ Machine + (Machine | Worker), d)
> >
> > c1 <- model.matrix(m1)[, 2]
> > c2 <- model.matrix(m1)[, 3]
> > m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 + c2
> |
> > Worker), d)
> > m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
> > VarCorr(m2a)
> >  Groups   Name        Std.Dev.
> >  Worker   (Intercept) 5.24354
> >  Worker.1 c1          2.58446
> >  Worker.2 c2          3.71504
> >  Residual             0.96256
> >
> > m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A") |
> > Worker) +
> >                                             (0 + dummy(Machine, "B") |
> > Worker) +
> >                                             (0 + dummy(Machine, "C") |
> > Worker), d)
> > VarCorr(m3)
> >  Groups   Name                Std.Dev.
> >  Worker   (Intercept)         3.78595
> >  Worker.1 dummy(Machine, "A") 1.94032
> >  Worker.2 dummy(Machine, "B") 5.87402
> >  Worker.3 dummy(Machine, "C") 2.84547
> >  Residual                     0.96158
> >
> > m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
> >
> >
> > [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
> > [2] https://stats.stackexchange.com/q/345842/136579
> > [3] https://stats.stackexchange.com/q/304374/136579
> >
> > Best regards,
> > Maarten
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Tue May 22 11:00:37 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Tue, 22 May 2018 11:00:37 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
 <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
Message-ID: <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>

I see that fm2 is nested within fm3 and fm4.
But I have a hard time understanding fm3 and fm2 because, as Reinhold Kiegl
said, they specify the f:g interaction but without the g main effect. Can
someone provide an intuition for these models?

Also, it is not entirely clear to me what fm5 represents. It looks to me,
and again I am with Reinhold Kiegl , as if there were over-parameterization
going on.

Cheers,
Maarten

On Tue, May 22, 2018 at 9:45 AM, Reinhold Kliegl <reinhold.kliegl at gmail.com>
wrote:

> Ok, I figured out the answer to the question about fm2.
>
> fm2 is indeed a very nice baseline for fm3 and fm4. So I distinguish
> between min1LMM and min2LMM.
>
>  fm1 = y ~ 1 + f + (1 | g)               # minimal LMM version 1  (min1LMM)
>  fm2 = y ~ 1 + f + (1 | f:g)             # minimal LMM version 2  (min2LMM)
>  fm3 = y ~ 1 + f + (0 + f || g)          # zcpLMM with 0 in RE (zcpLMM_RE0)
>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)   # LMM w/ f x g interaction
> (intLMM)
>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g) # N/A
>  fm6 = y ~ 1 + f + (1 + f |  g)          # maximal LMM (maxLMM)
>  fm7 = y ~ 1 + f + (1 + f || g)          # zcpLMM with 1 in RE (zcpLMM_RE1)
>
>
> (1) maxLMM_RE1 -> intLMM     -> min1LMM  # fm6 -> fm4 -> fm1
> (2) maxLMM_RE1 -> intLMM     -> min2LMM  # fm6 -> fm4 -> fm2
> (3) maxLMM_RE0 -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm3 -> fm2
> (4) maxLMM_RE1 -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm7 -> fm1  (new
> sequence)
>
>
> On Tue, May 22, 2018 at 12:21 AM, Reinhold Kliegl <
> reinhold.kliegl at gmail.com> wrote:
>
>> Sorry, I am somewhat late to this conversation. I am responding to this
>> thread, because it fits my comment very well, but it was initially
>> triggered by a previous thread, especially Rune Haubo's post here [1]. So I
>> hope it is ok to continue here.
>>
>> I have a few comments and questions. For details I refer to an RPub I put
>> up along with this post [2]. I start with a translation between Rune
>> Haubo's fm's and the terminology I use in the RPub:
>>
>>  fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
>>  fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in RE
>> (zcpLMM_RE0)
>>  fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
>> interaction (intLMM),
>>  fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
>>  fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in RE
>> (zcpLMM_RE1)
>>
>> Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6 are
>> in Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and fm5
>> so far (see below).
>>
>> (I) The post was triggered by the question whether intLMM is nested under
>> zcpLMM. I had included this LRT in my older RPub cited in the thread, but I
>> stand corrected and agree with Rune Haubo that intLMM is not nested under
>> zcpLMM. For example, in the new RPub, I show that slightly modified
>> Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
>> additional model parameter in the latter. Thanks for the critical reading.
>>
>>
>> (II) Here are Runo Haubo's sequences (left, resorted) augmented with my
>> translation (right)
>>
>> (1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     -> minLMM
>> (2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
>> (3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2
>>
>> and here are sequences I came up with (left) augmented with translation
>> into RH's fm's.
>>
>> (1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
>> (3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new
>> sequence)
>>
>>
>> (III) I have questions about fm2 and fm5.
>>    fm2: fm2 redefines the levels of the group factor (e.g., in the cake
>> data there are 45 groups in fm2 compared to 15 in the other models). Why is
>> fm2 nested under fm3 and fm6? Somehow it looks to me that you include an
>> f:g interaction without the g main effect (relative to fm4). This looks
>> like an interesting model; I would appreciate a bit more conceptual support
>> for its interpretation in the model hierarchy.
>>    fm5: fm5 specifies 4 variance components (VCs), but the factor has
>> only 3 levels. So to me this looks like there is redundancy built into the
>> model. In support of this intuition, for the cake data, one of the VCs is
>> estimated with 0. However, in the Machine data the model was not
>> degenerate. So I am not sure. In other words, if the factor levels are A,
>> B, C, and the two contrasts are c1 and c2, I thought I can specify either
>> (1 + c1 + c2) or (0 + A + B + C). fm5 specifies (1 + A + B + C) which is
>> rank deficient in the fixed effect part, but not necessarily in the
>> random-effect term. What am I missing here?
>>
>> [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>> [2] http://rpubs.com/Reinhold/391027
>>
>> Best,
>> Reinhold Kliegl
>>
>>
>> On Thu, May 17, 2018 at 12:43 PM, Maarten Jung <
>> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>> >
>> > Dear list,
>> >
>> > When one wants to specify a lmer model including variance components
>> but no
>> > correlation parameters for categorical predictors (factors) afaik one
>> has
>> > to convert the factors to numeric covariates or use lme4::dummy(). Until
>> > recently I thought m2a (or equivalently m2b using the double-bar syntax)
>> > would be the correct way to specify such a zero-correlation parameter
>> model.
>> >
>> > But in this thread [1] Rune Haubo Bojesen Christensen pointed out that
>> this
>> > model does not make sense to him. Instead he suggests m3 as an
>> appropriate
>> > model.
>> > I think this is a *highly relevant difference* for everyone who uses
>> > factors in lmer and therefore I'm bringing up this issue again. But
>> maybe
>> > I'm mistaken and just don't get what is quite obvious for more
>> experienced
>> > mixed modelers.
>> > Please note that the question is on CrossValidated [2] but some
>> consider it
>> > as off-topic and I don't think there will be an answer any time soon.
>> >
>> > So here are my questions:
>> > How should one specify a lmm without correlation parameters for factors
>> and
>> > what are the differences between m2a and m3?
>> > Is there a preferred model for model comparison with m4 (this model is
>> also
>> > discussed here [3])?
>> >
>> > library("lme4")
>> > data("Machines", package = "MEMSS")
>> >
>> > d <- Machines
>> > contrasts(d$Machine)  # default coding: contr.sum
>> >
>> > m1 <- lmer(score ~ Machine + (Machine | Worker), d)
>> >
>> > c1 <- model.matrix(m1)[, 2]
>> > c2 <- model.matrix(m1)[, 3]
>> > m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 +
>> c2 |
>> > Worker), d)
>> > m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
>> > VarCorr(m2a)
>> >  Groups   Name        Std.Dev.
>> >  Worker   (Intercept) 5.24354
>> >  Worker.1 c1          2.58446
>> >  Worker.2 c2          3.71504
>> >  Residual             0.96256
>> >
>> > m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A") |
>> > Worker) +
>> >                                             (0 + dummy(Machine, "B") |
>> > Worker) +
>> >                                             (0 + dummy(Machine, "C") |
>> > Worker), d)
>> > VarCorr(m3)
>> >  Groups   Name                Std.Dev.
>> >  Worker   (Intercept)         3.78595
>> >  Worker.1 dummy(Machine, "A") 1.94032
>> >  Worker.2 dummy(Machine, "B") 5.87402
>> >  Worker.3 dummy(Machine, "C") 2.84547
>> >  Residual                     0.96158
>> >
>> > m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
>> >
>> >
>> > [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/
>> 026775.html
>> > [2] https://stats.stackexchange.com/q/345842/136579
>> > [3] https://stats.stackexchange.com/q/304374/136579
>> >
>> > Best regards,
>> > Maarten
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>

	[[alternative HTML version deleted]]


From reinhold@kliegl @ending from gm@il@com  Tue May 22 13:17:03 2018
From: reinhold@kliegl @ending from gm@il@com (Reinhold Kliegl)
Date: Tue, 22 May 2018 13:17:03 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
 <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
 <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>
Message-ID: <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>

There is an interpretable alternative to fm5 (actually there are many ...),
called fm8 below, that avoids the redundancy between variance components.
The change is to switch from (1 |g) + (0 + f | g) = (1 | g) + (0 + A + B +
C | g) to 1 | g) + (0 + c1 + c2 |g ), where c1 and c2 are the contrasts
defined for f. (I have actually used such LMMs quite often.) With this
specification the difference to the maxLMM (fm6) is that the correlation
between intercept and contrasts is suppressed to zero. The correlation
parameters now refer to the correlations between effects of c1 and c2, not
to the correlations between A, B, and C.  Actually, this is but one example
of many LMMs one could slot into this position of the hierarchical model
sequences. At this level of model complexity one can suppress various
subsets of correlation parameters (as illustrated in Bates et al. (2015)[1]
and various vignettes of the RePsychLing package).


 fm1 = y ~ 1 + f + (1 | g)                     # minimal LMM version 1
 (min1LMM)
 fm2 = y ~ 1 + f + (1 | f:g)                   # minimal LMM version 2
 (min2LMM)
 fm3 = y ~ 1 + f + (0 + f || g)                # zcpLMM with 0 in RE
(zcpLMM_RE0)
 fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)         # LMM w/ f x g interaction
(intLMM)
 fm5 = y ~ 1 + f + (1 | g) + (0 + f | g)       # N/A
 fm6 = y ~ 1 + f + (1 + f |  g)                # maximal LMM (maxLMM)
 fm7 = y ~ 1 + f + (1 + f || g)                # zcpLMM with 1 in RE
(zcpLMM_RE1)
 fm8 = y ~ 1 + f + (1 | g) + (0 + c1 + c2 | g) # parsimonious LMM (prsmLMM)

Hierarchical model sequences

(1) maxLMM_RE1 -> prsmLMM -> intLMM     -> min1LMM  # fm6 -> fm8 -> fm4 ->
fm1
(2) maxLMM_RE1 -> prsmLMM -> intLMM     -> min2LMM  # fm6 -> fm8 -> fm4 ->
fm2
(3) maxLMM_RE0 -> prsmLMM -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm8 -> fm3 ->
fm2
(4) maxLMM_RE1 -> prsmLMM -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm8 -> fm7 ->
fm1  (new sequence)
```

I will update the RPub in the next days.

[1] https://arxiv.org/pdf/1506.04967.pdf


Best regards,
Reinhold Kliegl

On Tue, May 22, 2018 at 11:00 AM, Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> I see that fm2 is nested within fm3 and fm4.
> But I have a hard time understanding fm3 and fm2 because, as Reinhold
> Kiegl said, they specify the f:g interaction but without the g main effect.
> Can someone provide an intuition for these models?
>
> Also, it is not entirely clear to me what fm5 represents. It looks to me,
> and again I am with Reinhold Kiegl , as if there were
> over-parameterization going on.
>
> Cheers,
> Maarten
>
> On Tue, May 22, 2018 at 9:45 AM, Reinhold Kliegl <
> reinhold.kliegl at gmail.com> wrote:
>
>> Ok, I figured out the answer to the question about fm2.
>>
>> fm2 is indeed a very nice baseline for fm3 and fm4. So I distinguish
>> between min1LMM and min2LMM.
>>
>>  fm1 = y ~ 1 + f + (1 | g)               # minimal LMM version 1
>>  (min1LMM)
>>  fm2 = y ~ 1 + f + (1 | f:g)             # minimal LMM version 2
>>  (min2LMM)
>>  fm3 = y ~ 1 + f + (0 + f || g)          # zcpLMM with 0 in RE
>> (zcpLMM_RE0)
>>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)   # LMM w/ f x g interaction
>> (intLMM)
>>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g) # N/A
>>  fm6 = y ~ 1 + f + (1 + f |  g)          # maximal LMM (maxLMM)
>>  fm7 = y ~ 1 + f + (1 + f || g)          # zcpLMM with 1 in RE
>> (zcpLMM_RE1)
>>
>>
>> (1) maxLMM_RE1 -> intLMM     -> min1LMM  # fm6 -> fm4 -> fm1
>> (2) maxLMM_RE1 -> intLMM     -> min2LMM  # fm6 -> fm4 -> fm2
>> (3) maxLMM_RE0 -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm3 -> fm2
>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm7 -> fm1  (new
>> sequence)
>>
>>
>> On Tue, May 22, 2018 at 12:21 AM, Reinhold Kliegl <
>> reinhold.kliegl at gmail.com> wrote:
>>
>>> Sorry, I am somewhat late to this conversation. I am responding to this
>>> thread, because it fits my comment very well, but it was initially
>>> triggered by a previous thread, especially Rune Haubo's post here [1]. So I
>>> hope it is ok to continue here.
>>>
>>> I have a few comments and questions. For details I refer to an RPub I
>>> put up along with this post [2]. I start with a translation between Rune
>>> Haubo's fm's and the terminology I use in the RPub:
>>>
>>>  fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
>>>  fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in RE
>>> (zcpLMM_RE0)
>>>  fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
>>> interaction (intLMM),
>>>  fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
>>>  fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in RE
>>> (zcpLMM_RE1)
>>>
>>> Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6 are
>>> in Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and fm5
>>> so far (see below).
>>>
>>> (I) The post was triggered by the question whether intLMM is nested
>>> under zcpLMM. I had included this LRT in my older RPub cited in the thread,
>>> but I stand corrected and agree with Rune Haubo that intLMM is not nested
>>> under zcpLMM. For example, in the new RPub, I show that slightly modified
>>> Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
>>> additional model parameter in the latter. Thanks for the critical reading.
>>>
>>>
>>> (II) Here are Runo Haubo's sequences (left, resorted) augmented with my
>>> translation (right)
>>>
>>> (1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     -> minLMM
>>> (2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
>>> (3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2
>>>
>>> and here are sequences I came up with (left) augmented with translation
>>> into RH's fm's.
>>>
>>> (1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
>>> (3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new
>>> sequence)
>>>
>>>
>>> (III) I have questions about fm2 and fm5.
>>>    fm2: fm2 redefines the levels of the group factor (e.g., in the cake
>>> data there are 45 groups in fm2 compared to 15 in the other models). Why is
>>> fm2 nested under fm3 and fm6? Somehow it looks to me that you include an
>>> f:g interaction without the g main effect (relative to fm4). This looks
>>> like an interesting model; I would appreciate a bit more conceptual support
>>> for its interpretation in the model hierarchy.
>>>    fm5: fm5 specifies 4 variance components (VCs), but the factor has
>>> only 3 levels. So to me this looks like there is redundancy built into the
>>> model. In support of this intuition, for the cake data, one of the VCs is
>>> estimated with 0. However, in the Machine data the model was not
>>> degenerate. So I am not sure. In other words, if the factor levels are A,
>>> B, C, and the two contrasts are c1 and c2, I thought I can specify either
>>> (1 + c1 + c2) or (0 + A + B + C). fm5 specifies (1 + A + B + C) which is
>>> rank deficient in the fixed effect part, but not necessarily in the
>>> random-effect term. What am I missing here?
>>>
>>> [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>>> [2] http://rpubs.com/Reinhold/391027
>>>
>>> Best,
>>> Reinhold Kliegl
>>>
>>>
>>> On Thu, May 17, 2018 at 12:43 PM, Maarten Jung <
>>> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>> >
>>> > Dear list,
>>> >
>>> > When one wants to specify a lmer model including variance components
>>> but no
>>> > correlation parameters for categorical predictors (factors) afaik one
>>> has
>>> > to convert the factors to numeric covariates or use lme4::dummy().
>>> Until
>>> > recently I thought m2a (or equivalently m2b using the double-bar
>>> syntax)
>>> > would be the correct way to specify such a zero-correlation parameter
>>> model.
>>> >
>>> > But in this thread [1] Rune Haubo Bojesen Christensen pointed out that
>>> this
>>> > model does not make sense to him. Instead he suggests m3 as an
>>> appropriate
>>> > model.
>>> > I think this is a *highly relevant difference* for everyone who uses
>>> > factors in lmer and therefore I'm bringing up this issue again. But
>>> maybe
>>> > I'm mistaken and just don't get what is quite obvious for more
>>> experienced
>>> > mixed modelers.
>>> > Please note that the question is on CrossValidated [2] but some
>>> consider it
>>> > as off-topic and I don't think there will be an answer any time soon.
>>> >
>>> > So here are my questions:
>>> > How should one specify a lmm without correlation parameters for
>>> factors and
>>> > what are the differences between m2a and m3?
>>> > Is there a preferred model for model comparison with m4 (this model is
>>> also
>>> > discussed here [3])?
>>> >
>>> > library("lme4")
>>> > data("Machines", package = "MEMSS")
>>> >
>>> > d <- Machines
>>> > contrasts(d$Machine)  # default coding: contr.sum
>>> >
>>> > m1 <- lmer(score ~ Machine + (Machine | Worker), d)
>>> >
>>> > c1 <- model.matrix(m1)[, 2]
>>> > c2 <- model.matrix(m1)[, 3]
>>> > m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 +
>>> c2 |
>>> > Worker), d)
>>> > m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
>>> > VarCorr(m2a)
>>> >  Groups   Name        Std.Dev.
>>> >  Worker   (Intercept) 5.24354
>>> >  Worker.1 c1          2.58446
>>> >  Worker.2 c2          3.71504
>>> >  Residual             0.96256
>>> >
>>> > m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A") |
>>> > Worker) +
>>> >                                             (0 + dummy(Machine, "B") |
>>> > Worker) +
>>> >                                             (0 + dummy(Machine, "C") |
>>> > Worker), d)
>>> > VarCorr(m3)
>>> >  Groups   Name                Std.Dev.
>>> >  Worker   (Intercept)         3.78595
>>> >  Worker.1 dummy(Machine, "A") 1.94032
>>> >  Worker.2 dummy(Machine, "B") 5.87402
>>> >  Worker.3 dummy(Machine, "C") 2.84547
>>> >  Residual                     0.96158
>>> >
>>> > m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
>>> >
>>> >
>>> > [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026
>>> 775.html
>>> > [2] https://stats.stackexchange.com/q/345842/136579
>>> > [3] https://stats.stackexchange.com/q/304374/136579
>>> >
>>> > Best regards,
>>> > Maarten
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From F@rr@r@D@vid @ending from ep@@gov  Tue May 22 14:59:38 2018
From: F@rr@r@D@vid @ending from ep@@gov (Farrar, David)
Date: Tue, 22 May 2018 12:59:38 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <MWHPR1201MB0029D25E050284B7882582C5D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <FF6A434C-32BB-430E-A3E3-E2FB739A2E97@anu.edu.au>
 <MWHPR1201MB0029D25E050284B7882582C5D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <DM5PR09MB13247470DB0CAFAC17270E779A940@DM5PR09MB1324.namprd09.prod.outlook.com>

I think I used functions from Hmisc, the last time I did regression splines.  
(I did not use penalized splines - I specified enough knots to give an appropriate range of shapes, and used the default knot placements.)
David 

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of dani
Sent: Monday, May 21, 2018 10:41 PM
To: John Maindonald <john.maindonald at anu.edu.au>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

Hi John,

Thank you so much! This is very helpful! I managed to run it  but I am not sure how to interpret the results as I get this:


# Conditional model:
#                                                    Estimate Std. Error z value Pr(>|z|)
# (Intercept)                             -8.40461    1.58077  -5.317 1.06e-07 ***
# splines::ns(newage, 2)1     -1.89262    0.57246  -3.306 0.000946 ***
# splines::ns(newage, 2)2      0.10296    0.47268   0.218 0.827575


I am not sure what to make of the two different spline results.

Best regards,

D

________________________________
From: John Maindonald <john.maindonald at anu.edu.au>
Sent: Monday, May 21, 2018 7:10 PM
To: dani
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

There is an example at http://www.rpubs.com/johnhm/Overdispersed
See Section 2.2 .


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 22/05/2018, at 11:36, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:




	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From orchidn @ending from live@com  Tue May 22 18:27:40 2018
From: orchidn @ending from live@com (dani)
Date: Tue, 22 May 2018 16:27:40 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <6CEF79D5-097C-4341-B7D7-6349E2312884@anu.edu.au>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <FF6A434C-32BB-430E-A3E3-E2FB739A2E97@anu.edu.au>
 <MWHPR1201MB0029D25E050284B7882582C5D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <6CEF79D5-097C-4341-B7D7-6349E2312884@anu.edu.au>
Message-ID: <MWHPR1201MB002908A427008677617F00EED6940@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


Thank you so much for your detailed explanation!


Best,

D


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: John Maindonald <john.maindonald at anu.edu.au>
Sent: Monday, May 21, 2018 10:00 PM
To: dani
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

The spline coefficients multiply the two basis terms.  Most times, one wants to
work with predicted values and standard errors.  The predict method seems
not yet to have been implemented for glmmTMB models with a betabinomial
error family.  One can use fitted() to get just the fitted probabilities, and do a
complementary log-log transform (in this instance) to get predictions on the
scale of the linear predictor (NB, linear in the sense that it is a linear combination
of the basis functions, plus intercept).

The output suggests that the first basis term might be enough on its own.
Observe, however, to choose a simple case:

> x <- 1:5; splines::ns(x, 2)[, 1]
[1] 0.0000000 0.3570466 0.5662628 0.5290951 0.3440969

This is a very nonlinear function of x, quite different from the linear function
of x that one gets by typing splines::ns(x, 1)

Regression thin plate splines, as implemented in mgcv. have the advantage
that the initial basis terms change only very slightly as one moves to a higher
degree of freedom basis.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 22/05/2018, at 14:41, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:

Hi John,
Thank you so much! This is very helpful! I managed to run it  but I am not sure how to interpret the results as I get this:


# Conditional model:
#                                                    Estimate Std. Error z value Pr(>|z|)
# (Intercept)                             -8.40461    1.58077  -5.317 1.06e-07 ***
# splines::ns(newage, 2)1     -1.89262    0.57246  -3.306 0.000946 ***
# splines::ns(newage, 2)2      0.10296    0.47268   0.218 0.827575


I am not sure what to make of the two different spline results.
Best regards,
D
________________________________
From: John Maindonald <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>>
Sent: Monday, May 21, 2018 7:10 PM
To: dani
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

There is an example at http://www.rpubs.com/johnhm/Overdispersed
See Section 2.2 .

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 22/05/2018, at 11:36, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:


	[[alternative HTML version deleted]]


From orchidn @ending from live@com  Tue May 22 18:29:07 2018
From: orchidn @ending from live@com (dani)
Date: Tue, 22 May 2018 16:29:07 +0000
Subject: [R-sig-ME] glmmTMB- fitting splines
In-Reply-To: <DM5PR09MB13247470DB0CAFAC17270E779A940@DM5PR09MB1324.namprd09.prod.outlook.com>
References: <MWHPR1201MB0029CC3894DC359CE1F078ABD6950@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <FF6A434C-32BB-430E-A3E3-E2FB739A2E97@anu.edu.au>
 <MWHPR1201MB0029D25E050284B7882582C5D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <DM5PR09MB13247470DB0CAFAC17270E779A940@DM5PR09MB1324.namprd09.prod.outlook.com>
Message-ID: <MWHPR1201MB00292A329EFBDF9C49ADD494D6940@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi David,


Thanks. I am not sure Hmisc works with random effects - I will check it out, though.


Best,

D


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Farrar, David <Farrar.David at epa.gov>
Sent: Tuesday, May 22, 2018 5:59 AM
To: dani; John Maindonald
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] glmmTMB- fitting splines

I think I used functions from Hmisc, the last time I did regression splines.
(I did not use penalized splines - I specified enough knots to give an appropriate range of shapes, and used the default knot placements.)
David

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of dani
Sent: Monday, May 21, 2018 10:41 PM
To: John Maindonald <john.maindonald at anu.edu.au>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

Hi John,

Thank you so much! This is very helpful! I managed to run it  but I am not sure how to interpret the results as I get this:


# Conditional model:
#                                                    Estimate Std. Error z value Pr(>|z|)
# (Intercept)                             -8.40461    1.58077  -5.317 1.06e-07 ***
# splines::ns(newage, 2)1     -1.89262    0.57246  -3.306 0.000946 ***
# splines::ns(newage, 2)2      0.10296    0.47268   0.218 0.827575


I am not sure what to make of the two different spline results.

Best regards,

D

________________________________
From: John Maindonald <john.maindonald at anu.edu.au>
Sent: Monday, May 21, 2018 7:10 PM
To: dani
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB- fitting splines

There is an example at http://www.rpubs.com/johnhm/Overdispersed
See Section 2.2 .


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 22/05/2018, at 11:36, dani <orchidn at live.com<mailto:orchidn at live.com>> wrote:




        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Tue May 22 22:51:56 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Tue, 22 May 2018 22:51:56 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
 <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
 <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>
 <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>
Message-ID: <CAHr4Dydqg6sTtBhdYMFp1uPoK0uYHdQ+xE71Ckd1OsgOK2myug@mail.gmail.com>

I have to clarify that I was talking about fm5 in the way Rune Haubo
specified it:
fm5.2 = y ~ 1 + f + (1 | g) + (0 + f || g) which is, when using a
treatment coded factor with 3 levels, equivalent to
fm5.2 = y ~ 1 + f + (1 | g ) +
            (0 + dummy(f, "1st level") | g) +
            (0 + dummy(f, "2nd level") | g) +
            (0 + dummy(f, "3rd level") | g)
In the way Reinhold Kliegl specified fm5, i.e. with  (0 + f | g)
instead of (0 + f || g), it seems to me that fm5 is just an
over/re-parameterized version of fm6 with one additional parameter and
they both yield the same fit.

However, I think both fm5.2 and fm5 are difficult to understand
because they use (1 | g) and, at the same time, the 0 + f notation
within one formula. So my question remains the same: as Reinhold
Kliegl put it "if the factor levels are A, B, C, and the two contrasts
are c1 and c2, I thought I can specify either (1 + c1 + c2) or (0 + A
+ B + C)". But this doesn't seem to be the case for random effects -
or is it?
Maybe answering this question can also explain the difference between
fm3 and fm7.

Best regards,
Maarten

On Tue, May 22, 2018 at 1:17 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> There is an interpretable alternative to fm5 (actually there are many ...),
> called fm8 below, that avoids the redundancy between variance components.
> The change is to switch from (1 |g) + (0 + f | g) = (1 | g) + (0 + A + B + C
> | g) to 1 | g) + (0 + c1 + c2 |g ), where c1 and c2 are the contrasts
> defined for f. (I have actually used such LMMs quite often.) With this
> specification the difference to the maxLMM (fm6) is that the correlation
> between intercept and contrasts is suppressed to zero. The correlation
> parameters now refer to the correlations between effects of c1 and c2, not
> to the correlations between A, B, and C.  Actually, this is but one example
> of many LMMs one could slot into this position of the hierarchical model
> sequences. At this level of model complexity one can suppress various
> subsets of correlation parameters (as illustrated in Bates et al. (2015)[1]
> and various vignettes of the RePsychLing package).
>
>
>  fm1 = y ~ 1 + f + (1 | g)                     # minimal LMM version 1
> (min1LMM)
>  fm2 = y ~ 1 + f + (1 | f:g)                   # minimal LMM version 2
> (min2LMM)
>  fm3 = y ~ 1 + f + (0 + f || g)                # zcpLMM with 0 in RE
> (zcpLMM_RE0)
>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)         # LMM w/ f x g interaction
> (intLMM)
>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g)       # N/A
>  fm6 = y ~ 1 + f + (1 + f |  g)                # maximal LMM (maxLMM)
>  fm7 = y ~ 1 + f + (1 + f || g)                # zcpLMM with 1 in RE
> (zcpLMM_RE1)
>  fm8 = y ~ 1 + f + (1 | g) + (0 + c1 + c2 | g) # parsimonious LMM (prsmLMM)
>
> Hierarchical model sequences
>
> (1) maxLMM_RE1 -> prsmLMM -> intLMM     -> min1LMM  # fm6 -> fm8 -> fm4 ->
> fm1
> (2) maxLMM_RE1 -> prsmLMM -> intLMM     -> min2LMM  # fm6 -> fm8 -> fm4 ->
> fm2
> (3) maxLMM_RE0 -> prsmLMM -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm8 -> fm3 ->
> fm2
> (4) maxLMM_RE1 -> prsmLMM -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm8 -> fm7 ->
> fm1  (new sequence)
> ```
>
> I will update the RPub in the next days.
>
> [1] https://arxiv.org/pdf/1506.04967.pdf
>
>
> Best regards,
> Reinhold Kliegl
>
> On Tue, May 22, 2018 at 11:00 AM, Maarten Jung
> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>
>> I see that fm2 is nested within fm3 and fm4.
>> But I have a hard time understanding fm3 and fm2 because, as Reinhold
>> Kiegl said, they specify the f:g interaction but without the g main effect.
>> Can someone provide an intuition for these models?
>>
>> Also, it is not entirely clear to me what fm5 represents. It looks to me,
>> and again I am with Reinhold Kiegl , as if there were over-parameterization
>> going on.
>>
>> Cheers,
>> Maarten
>>
>> On Tue, May 22, 2018 at 9:45 AM, Reinhold Kliegl
>> <reinhold.kliegl at gmail.com> wrote:
>>>
>>> Ok, I figured out the answer to the question about fm2.
>>>
>>> fm2 is indeed a very nice baseline for fm3 and fm4. So I distinguish
>>> between min1LMM and min2LMM.
>>>
>>>  fm1 = y ~ 1 + f + (1 | g)               # minimal LMM version 1
>>> (min1LMM)
>>>  fm2 = y ~ 1 + f + (1 | f:g)             # minimal LMM version 2
>>> (min2LMM)
>>>  fm3 = y ~ 1 + f + (0 + f || g)          # zcpLMM with 0 in RE
>>> (zcpLMM_RE0)
>>>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)   # LMM w/ f x g interaction
>>> (intLMM)
>>>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g) # N/A
>>>  fm6 = y ~ 1 + f + (1 + f |  g)          # maximal LMM (maxLMM)
>>>  fm7 = y ~ 1 + f + (1 + f || g)          # zcpLMM with 1 in RE
>>> (zcpLMM_RE1)
>>>
>>>
>>> (1) maxLMM_RE1 -> intLMM     -> min1LMM  # fm6 -> fm4 -> fm1
>>> (2) maxLMM_RE1 -> intLMM     -> min2LMM  # fm6 -> fm4 -> fm2
>>> (3) maxLMM_RE0 -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm3 -> fm2
>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm7 -> fm1  (new
>>> sequence)
>>>
>>>
>>> On Tue, May 22, 2018 at 12:21 AM, Reinhold Kliegl
>>> <reinhold.kliegl at gmail.com> wrote:
>>>>
>>>> Sorry, I am somewhat late to this conversation. I am responding to this
>>>> thread, because it fits my comment very well, but it was initially triggered
>>>> by a previous thread, especially Rune Haubo's post here [1]. So I hope it is
>>>> ok to continue here.
>>>>
>>>> I have a few comments and questions. For details I refer to an RPub I
>>>> put up along with this post [2]. I start with a translation between Rune
>>>> Haubo's fm's and the terminology I use in the RPub:
>>>>
>>>>  fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
>>>>  fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in RE
>>>> (zcpLMM_RE0)
>>>>  fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
>>>> interaction (intLMM),
>>>>  fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
>>>>  fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in RE
>>>> (zcpLMM_RE1)
>>>>
>>>> Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6 are
>>>> in Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and fm5
>>>> so far (see below).
>>>>
>>>> (I) The post was triggered by the question whether intLMM is nested
>>>> under zcpLMM. I had included this LRT in my older RPub cited in the thread,
>>>> but I stand corrected and agree with Rune Haubo that intLMM is not nested
>>>> under zcpLMM. For example, in the new RPub, I show that slightly modified
>>>> Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
>>>> additional model parameter in the latter. Thanks for the critical reading.
>>>>
>>>>
>>>> (II) Here are Runo Haubo's sequences (left, resorted) augmented with my
>>>> translation (right)
>>>>
>>>> (1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     ->
>>>> minLMM
>>>> (2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
>>>> (3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2
>>>>
>>>> and here are sequences I came up with (left) augmented with translation
>>>> into RH's fm's.
>>>>
>>>> (1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
>>>> (3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
>>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new
>>>> sequence)
>>>>
>>>>
>>>> (III) I have questions about fm2 and fm5.
>>>>    fm2: fm2 redefines the levels of the group factor (e.g., in the cake
>>>> data there are 45 groups in fm2 compared to 15 in the other models). Why is
>>>> fm2 nested under fm3 and fm6? Somehow it looks to me that you include an f:g
>>>> interaction without the g main effect (relative to fm4). This looks like an
>>>> interesting model; I would appreciate a bit more conceptual support for its
>>>> interpretation in the model hierarchy.
>>>>    fm5: fm5 specifies 4 variance components (VCs), but the factor has
>>>> only 3 levels. So to me this looks like there is redundancy built into the
>>>> model. In support of this intuition, for the cake data, one of the VCs is
>>>> estimated with 0. However, in the Machine data the model was not degenerate.
>>>> So I am not sure. In other words, if the factor levels are A, B, C, and the
>>>> two contrasts are c1 and c2, I thought I can specify either (1 + c1 + c2) or
>>>> (0 + A + B + C). fm5 specifies (1 + A + B + C) which is rank deficient in
>>>> the fixed effect part, but not necessarily in the random-effect term. What
>>>> am I missing here?
>>>>
>>>> [1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>>>> [2] http://rpubs.com/Reinhold/391027
>>>>
>>>> Best,
>>>> Reinhold Kliegl
>>>>
>>>>
>>>> On Thu, May 17, 2018 at 12:43 PM, Maarten Jung
>>>> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>>> >
>>>> > Dear list,
>>>> >
>>>> > When one wants to specify a lmer model including variance components
>>>> > but no
>>>> > correlation parameters for categorical predictors (factors) afaik one
>>>> > has
>>>> > to convert the factors to numeric covariates or use lme4::dummy().
>>>> > Until
>>>> > recently I thought m2a (or equivalently m2b using the double-bar
>>>> > syntax)
>>>> > would be the correct way to specify such a zero-correlation parameter
>>>> > model.
>>>> >
>>>> > But in this thread [1] Rune Haubo Bojesen Christensen pointed out that
>>>> > this
>>>> > model does not make sense to him. Instead he suggests m3 as an
>>>> > appropriate
>>>> > model.
>>>> > I think this is a *highly relevant difference* for everyone who uses
>>>> > factors in lmer and therefore I'm bringing up this issue again. But
>>>> > maybe
>>>> > I'm mistaken and just don't get what is quite obvious for more
>>>> > experienced
>>>> > mixed modelers.
>>>> > Please note that the question is on CrossValidated [2] but some
>>>> > consider it
>>>> > as off-topic and I don't think there will be an answer any time soon.
>>>> >
>>>> > So here are my questions:
>>>> > How should one specify a lmm without correlation parameters for
>>>> > factors and
>>>> > what are the differences between m2a and m3?
>>>> > Is there a preferred model for model comparison with m4 (this model is
>>>> > also
>>>> > discussed here [3])?
>>>> >
>>>> > library("lme4")
>>>> > data("Machines", package = "MEMSS")
>>>> >
>>>> > d <- Machines
>>>> > contrasts(d$Machine)  # default coding: contr.sum
>>>> >
>>>> > m1 <- lmer(score ~ Machine + (Machine | Worker), d)
>>>> >
>>>> > c1 <- model.matrix(m1)[, 2]
>>>> > c2 <- model.matrix(m1)[, 3]
>>>> > m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 +
>>>> > c2 |
>>>> > Worker), d)
>>>> > m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
>>>> > VarCorr(m2a)
>>>> >  Groups   Name        Std.Dev.
>>>> >  Worker   (Intercept) 5.24354
>>>> >  Worker.1 c1          2.58446
>>>> >  Worker.2 c2          3.71504
>>>> >  Residual             0.96256
>>>> >
>>>> > m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A") |
>>>> > Worker) +
>>>> >                                             (0 + dummy(Machine, "B") |
>>>> > Worker) +
>>>> >                                             (0 + dummy(Machine, "C") |
>>>> > Worker), d)
>>>> > VarCorr(m3)
>>>> >  Groups   Name                Std.Dev.
>>>> >  Worker   (Intercept)         3.78595
>>>> >  Worker.1 dummy(Machine, "A") 1.94032
>>>> >  Worker.2 dummy(Machine, "B") 5.87402
>>>> >  Worker.3 dummy(Machine, "C") 2.84547
>>>> >  Residual                     0.96158
>>>> >
>>>> > m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
>>>> >
>>>> >
>>>> > [1]
>>>> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>>>> > [2] https://stats.stackexchange.com/q/345842/136579
>>>> > [3] https://stats.stackexchange.com/q/304374/136579
>>>> >
>>>> > Best regards,
>>>> > Maarten
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > _______________________________________________
>>>> > R-sig-mixed-models at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>


From orchidn @ending from live@com  Wed May 23 08:28:20 2018
From: orchidn @ending from live@com (dani)
Date: Wed, 23 May 2018 06:28:20 +0000
Subject: [R-sig-ME] GAMM versus glmmTMB
Message-ID: <MWHPR1201MB00291E9A396593C81627FFAED66B0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,


I am working with a GAMM model with two random groups and two splines. Please see below. The results indicate that var9 has a linear association with the DV, therefore I decided to run another model without splines: a glmmTMB model - so I could also run a zero inflated model (not shown here); I replaced variable v1 (age, which displayed a quadratic association with the DV) with a categorical variable based on 3 age groups I was interested in.


I was surprised to see that the results differed - for instance var8 is approaching significance in the glmmTMB model.


My question is: should I stick with the GAMM model and remove the spline for var9 and run the GAMM again and present those results or should I proceed with the glmmTMB model.  I would like to use the glmmTMB model to be able to compare the fit for the zero inflated and simple Poisson models.


Thank you very much!

Best,

Dani

br5f<- gamm(Num_admiss ~ s(var1)+var2 + var3 + var4 + var5+
             var6+ var7+var8+s(VAR9)+offset(lexpfn), random=list(GROUPA=~1, groupB=~1), niterPQL=100,family=quasipoisson, data=may21Omi)

summary(br5f)

plot(br5f$gam,pages=1)
summary(br5f$gam)

# Family: quasipoisson
# Link function: log
#
# Formula:
#   Num_admiss ~ s(var1) + var2 + var3 + VAR4 +
#   var5 + var6 + var7 + var8 + s(VAR9) + offset(lexpfn)
#
# Parametric coefficients:
#   Estimate Std. Error t value Pr(>|t|)
# (Intercept)   -7.82201    1.47685  -5.296 1.32e-07 ***
# var2M  0.06554    0.16972   0.386   0.6994
# var31         0.10356    0.18420   0.562   0.5741
# VAR41  -0.05777    0.20573  -0.281   0.7789
# var5           0.11638    0.04644   2.506   0.0123 *
# var6             0.02036    0.03520   0.578   0.5630
# var7       -0.09351    0.06160  -1.518   0.1292
# var8            -0.03119    0.04293  -0.726   0.4676
# ---
#   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
#
# Approximate significance of smooth terms:
#               edf Ref.df     F p-value
# s(var1)     2.146  2.146 6.087 0.00312 **
# s(VAR9) 1.000  1.000 0.218 0.64083
# ---
#   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
#
# R-sq.(adj) =  0.0317
# Scale est. = 4.0528    n = 1892

summary(br5f$lme)

# Linear mixed-effects model fit by maximum likelihood
# Data: data
# AIC      BIC    logLik
# 11065.24 11148.43 -5517.622
#
# Random effects:
#   Formula: ~Xr - 1 | g
# Structure: pdIdnot
# Xr1       Xr2       Xr3       Xr4       Xr5       Xr6       Xr7       Xr8
# StdDev: 0.8294889 0.8294889 0.8294889 0.8294889 0.8294889 0.8294889 0.8294889 0.8294889
#
# Formula: ~Xr.0 - 1 | g.0 %in% g
# Structure: pdIdnot
# Xr.01        Xr.02        Xr.03        Xr.04        Xr.05        Xr.06        Xr.07        Xr.08
# StdDev: 7.618265e-05 7.618265e-05 7.618265e-05 7.618265e-05 7.618265e-05 7.618265e-05 7.618265e-05 7.618265e-05
#
# Formula: ~1 | GROUPA %in% g.0 %in% g
# (Intercept)
# StdDev: 0.0002181793
#
# Formula: ~1 | groupB %in% GROUPA %in% g.0 %in% g
# (Intercept) Residual
# StdDev: 0.0001290529 2.013153
#
# Variance function:
#   Structure: fixed weights
# Formula: ~invwt
# Fixed effects: list(fixed)
# Value Std.Error   DF   t-value p-value
# X(Intercept)      -7.822006 1.4776376 1470 -5.293589  0.0000
# Xvar2M     0.065538 0.1698107 1470  0.385945  0.6996
# Xvar31            0.103558 0.1843021  239  0.561892  0.5747
# XVAR41     -0.057767 0.2058345  173 -0.280647  0.7793
# Xvar5              0.116383 0.0464641  173  2.504787  0.0132
# Xvar6                0.020364 0.0352209  173  0.578183  0.5639
# Xvar7          -0.093506 0.0616327  173 -1.517156  0.1311
# Xvar8               -0.031187 0.0429514  173 -0.726106  0.4688
# Xs(var1)Fx1     -0.384263 0.2817892  173 -1.363652  0.1744
# Xs(VAR9)Fx1 -0.041480 0.0889423  173 -0.466372  0.6415
# Correlation:
#   X(Int) Xgnd_M Xthn21 XNEW_S Xvar5  Xvar6    Xst_p1 Xvar8    Xs()F1
# Xvar2M    -0.062
# Xvar31           -0.022  0.020
# XVAR41     -0.038 -0.029  0.189
# Xvar5             -0.008  0.057 -0.061 -0.206
# Xvar6               -0.868 -0.027  0.052  0.023  0.006
# Xvar7          -0.654  0.003 -0.089  0.043 -0.368  0.254
# Xvar8                0.011 -0.060 -0.001  0.034 -0.189  0.218 -0.228
# Xs(var1)Fx1     -0.019  0.023  0.000 -0.062  0.014  0.034 -0.006  0.029
# Xs(VAR9)Fx1  0.051 -0.095 -0.074 -0.052 -0.008 -0.078  0.037 -0.020 -0.021
#
# Standardized Within-Group Residuals:
#   Min         Q1        Med         Q3        Max
# -0.8708042 -0.3019933 -0.2090718 -0.0899512 14.9421321
#
# Number of Observations: 1892
# Number of Groups:
#   g                               g.0 %in% g
# 1                                        1
# GROUPA %in% g.0 %in% g groupB %in% GROUPA %in% g.0 %in% g
# 1472                                     1652





fit <-glmmTMB(Num_admiss ~ newagecat+var2 + var3 + VAR4 +
                              var9+var5+var6+ var7+var8+offset(lexpfn)+(1| GROUPA)+(1|groupB), family=poisson,data=may21Omi)

# Family: poisson  ( log )
# Formula:          Num_admiss ~ newagecat + var2 + var3 + VAR4 +
#   var5 + var6 + var7+ var8 + var9 + offset(lexpfn) +      (1 | GROUPA) + (1 | groupB)
# Data: may21Omi
#
# AIC      BIC   logLik deviance df.resid
# 2407.5   2479.6  -1190.8   2381.5     1879
#
# Random effects:
#
#   Conditional model:
#   Groups      Name        Variance Std.Dev.
# groupB (Intercept) 1.173    1.083
# GROUPA    (Intercept) 4.125    2.031
# Number of obs: 1892, groups:  groupB, 1636; GROUPA, 1472
#
# Conditional model:
#                  Estimate Std. Error z value Pr(>|z|)
# (Intercept)   -9.5950170  1.6721112  -5.738 9.57e-09 ***
# newagecat2    -0.6298056  0.1970976  -3.195   0.0014 **
# newagecat3    -0.4693142  0.2934038  -1.600   0.1097
# var2M  0.1048778  0.1886372   0.556   0.5782
# var31        -0.0120491  0.2067959  -0.058   0.9535
# VAR41  -0.0189449  0.2255866  -0.084   0.9331
# var5          0.1032991  0.0498155   2.074   0.0381 *
# var6             0.0081499  0.0385051   0.212   0.8324
# var7       -0.0273567  0.0729078  -0.375   0.7075
# var8            -0.0617969  0.0455357  -1.357   0.1747
# var9    -0.0005731  0.0040367  -0.142   0.8871
---
#   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From g@i@rrido @ending from gm@il@com  Wed May 23 13:14:59 2018
From: g@i@rrido @ending from gm@il@com (Mario Garrido)
Date: Wed, 23 May 2018 14:14:59 +0300
Subject: [R-sig-ME] P-value associated to explanatory from glmer binomial
 family
Message-ID: <CABi7Y8b0+p1knXtoOra5oH5X352oT4GH6LLMnzr=Oq6226GOLg@mail.gmail.com>

Dear lme4-users,
I am trying to get the P-value associated with a glmer model from the
binomial family.
My model is the following:
glmer(Infection.status~origin+ (1|donationID), family=binomial)->q7H

where Infection status is a dummy variable with two levels, infected and
uninfected
I tried to get the P-value associated to the the explanatory variable origin
but I get only the F-value and the degrees of freedom

(aov <- anova(q7H))
Analysis of Variance Table
         Df Sum Sq Mean Sq F value
origin   2 5.3061  2.6531  2.6531

I have 2 different questions
1. Am I doing correctly or am I using an incorrect command?

2. with the F-value I get and the df, should I go to test the significance
to a F or Chi-squared table? I guess I should go to the latest since I am
running a binomial test, right?
In case I have to go to an F table, how can I know the numerator and
denominator degrees of freedom?

Thanks in advance

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Thu May 24 10:55:32 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Thu, 24 May 2018 10:55:32 +0200
Subject: [R-sig-ME] 
 P-value associated to explanatory from glmer binomial family
In-Reply-To: <CABi7Y8b0+p1knXtoOra5oH5X352oT4GH6LLMnzr=Oq6226GOLg@mail.gmail.com>
References: <CABi7Y8b0+p1knXtoOra5oH5X352oT4GH6LLMnzr=Oq6226GOLg@mail.gmail.com>
Message-ID: <CAJuCY5w0MkdWAtAaj1_8VMJDvqFZYNXBnCT5OtmXsL0Lwaf+Yg@mail.gmail.com>

Dear Mario,

Calculating the degrees of freedom of a mixed model is not straightforward.

A workaround would be to use a likelihoodratio test between two nested
models: one with and one without the variable. See the example below.

library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              data = cbpp, family = binomial)
anova(gm1)
gm0 <- glmer(cbind(incidence, size - incidence) ~ (1 | herd),
              data = cbpp, family = binomial)
anova(gm1, gm0)


Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-05-23 13:14 GMT+02:00 Mario Garrido <gaiarrido at gmail.com>:

> Dear lme4-users,
> I am trying to get the P-value associated with a glmer model from the
> binomial family.
> My model is the following:
> glmer(Infection.status~origin+ (1|donationID), family=binomial)->q7H
>
> where Infection status is a dummy variable with two levels, infected and
> uninfected
> I tried to get the P-value associated to the the explanatory variable
> origin
> but I get only the F-value and the degrees of freedom
>
> (aov <- anova(q7H))
> Analysis of Variance Table
>          Df Sum Sq Mean Sq F value
> origin   2 5.3061  2.6531  2.6531
>
> I have 2 different questions
> 1. Am I doing correctly or am I using an incorrect command?
>
> 2. with the F-value I get and the df, should I go to test the significance
> to a F or Chi-squared table? I guess I should go to the latest since I am
> running a binomial test, right?
> In case I have to go to an F table, how can I know the numerator and
> denominator degrees of freedom?
>
> Thanks in advance
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j@@min@herden @ending from gm@il@com  Thu May 24 14:16:54 2018
From: j@@min@herden @ending from gm@il@com (Jasmin Herden)
Date: Thu, 24 May 2018 14:16:54 +0200
Subject: [R-sig-ME] MCMCglmm models and (quasi-)complete separation
In-Reply-To: <CAD+CoDMaqnOwCaENchc60HoW_M+xC3k4vk=axaB2c7zrGTFuFw@mail.gmail.com>
References: <CAD+CoDMaqnOwCaENchc60HoW_M+xC3k4vk=axaB2c7zrGTFuFw@mail.gmail.com>
Message-ID: <CAD+CoDMgKNRDBnj0kLjG2MiOKYKmQC1+ZpJNKTRCtOpb155EGg@mail.gmail.com>

Dear fellow R users,

I have recently started using the MCMCglmm R package to analyse some of my
problematic
data which severely suffers from (quasi)complete separation.

I have followed Ben Bolker's suggestions of zero-mean Normal priors on the
fixed effects to analyse such kinds of data.
(https://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html)

My model is:

k<-8 #number of the fixed effects
     #Intercept+single effects+interactions

prior.c <- list(B=list(V=diag(9,k), mu=rep(0,k)),
                R=list(V=1,fix=1),
                G=list(G1=list(V=1, nu=1,alpha.mu=0, alpha.V=1000),
                       G2=list(V=1,nu=1,alpha.mu=0, alpha.V=1000),
                       G3=list(V=1,nu=1,alpha.mu=0, alpha.V=1000)))

nsamp <- 10000
THIN <- 900
BURNIN <- 10000
NITT <- BURNIN + THIN*nsamp
model3 = MCMCglmm(survival~
                    Site*b*c,
                  random=~x+Field+Field_block,
                  data=dset,
                    slice=TRUE,
                    pl=T,
                    prior=prior.c,
                    family="categorical",verbose=FALSE,
                    nitt=NITT,burnin=BURNIN,thin=THIN)

Survival is a binary value of 0 or 1 and is observed only once per
experimental plant.
Therefore the observation-level variance R is fixed to 1. (As in the linked
example.)

Site, b, and c are two-level categorical variables. x is crossed with Field
and Field_block, but Field_block is nested within Field.

Models are run for each species separately.

My questions are:

a) Many worked examples which I based my own analysis on use the
Gelman-Rubin
criterion where you check the convergence of your model by running it a
number of times and then compare models.

However, I think the MCMCglmm vignette said to start the model running with
overdispersed priors which is definitely not an option for me with the kind
of data I have.

I have tried using the testing for the Gelman-Rubin criterion nonetheless,
but the Gelman diagnostic plots do not show a oscillating line that finally
converges on a value but
rather clines and straigt lines.

b) I am also not quite sure, if the value R is fixed at is appropiate for
all models I run. For some
models, I still get latent variable values bigger than 20, even at very
high numbers of iterations.

c) How do you decide to use family="categorical" (=logit link) or "ordinal"
(=probit link)?
Based on the DIC of the models?

d) For many of my models, the explained variance for the random effects
Field and Field_block are very high; sometimes reaching an upper estimate
of 99%.
I think the problem is that Field_block is not only nested in Field but
that Field is also
nested in the categorical fixed effect Site.
Is my model overparametrized with regard to Field, since I have nearly
complete survival in one of the two levels of Site?

Kind regards,
Jasmin

	[[alternative HTML version deleted]]


From reinhold@kliegl @ending from gm@il@com  Thu May 24 21:22:12 2018
From: reinhold@kliegl @ending from gm@il@com (Reinhold Kliegl)
Date: Thu, 24 May 2018 21:22:12 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
 <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
 <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>
 <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>
Message-ID: <CAG+WrEwpGxDbN6Gif2TiP80XZZZPqeNgwoFZEuuvVSGp808YxA@mail.gmail.com>

Here is an update (final for now) with 10 models and 4 hierarchical
sequences. Comments, details, and a demonstration with the Machines data
are available in a new RPub[1]. I switched to a notation with numeric
covariates to reduce potential confusion about terms containing `1+f` and
`0+f`; `c1` and `c2` are contrasts defined for a factor with levels `A`,
`B`, and `C`.

## LMMs

### Prototype LMMs

max_LMM:   m1 = y ~ 1 + c1 + c2 + (1 + c1 + c2 | subj)
prsm1_LMM: m2 = y ~ 1 + c1 + c2 + (1 | subj) + (0 + c1 + c2 | subj)
zcp_LMM:   m3 = y ~ 1 + c1 + c2 + (1 + c1 + c2 || subj)
prsm2_LMM: m4 = y ~ 1 + c1 + c2 + (1 + c2 || subj)
min_LMM:   m5 = y ~ 1 + c1 + c2 + (1 | subj)

Protoype refers to prsm1 and prsm2; there are also variations of them.
Prsm1 are models pruning correlation parameters; prsm2 are models pruning
variance components in the absence of correlation parameters. The order
reflects hierarchical decreasing model complexity.

### LMMs with interaction term

int_LMM:   m6 = y ~ 1 + c1 + c2 + (1 | subj) + (1 | factor:subj)
min2_Lmm:  m7 = y ~ 1 + c1 + c2 + (1 | factor:subj)

### LMMs with (0 + f | g) RE structures

maxL_MM_RE0:   m8 = y ~ 1 + c1 + c2 + (0 + A + B + C | subj)
prsm1_LMM_RE0: m9 = y ~ 1 + c1 + c2 + (0 + A | subj) + (0 + B + C | subj)
zcp_LMM_RE0:  m10 = y ~ 1 + c1 + c2 + (0 + A + B + C || subj)

## Hierarchical model sequences

Here are the sequences I am confident about.

(1) max_LMM -> prsm1_LMM -> zcp_LMM -> prsm2_LMM -> min1_LMM
(2) max_LMM -> int_LMM -> min1_LMM
(3) max_LMM -> int_LMM -> min2_LMM
(4) max_LMM_RE0 -> prsm1_LMM_RE0 -> zcp_LMM_RE0

So far, in my research, I have worked almost exclusively with Sequence (1)
and do not recall ever experiencing technical problems or inconsistencies
as long as there was no overparameterization. It has served me well in the
determination of parsimonious LMMs[2, 3].

For complex fixed-effect structures (i.e., for models with many factors or
with factors with many levels), the number of correlation parameters grows
very rapidly. If this goes together with a modest number of observations or
levels of the random factor, Sequences (2) and (3) might be a good place to
start to avoid convergence problems. Of course, if your hypotheses are
about correlation parameters, these LMMs will not get you very far.

Finally, Sequence (4) could be a default strategy if one is interested in
the fixed effects and if one does not want to spend much time in wondering
about the meaning of CPs. However, as correlations between levels of fixed
factors are can be very large (at least larger than correlations between
effects), LMMs in this sequence may be prone to convergence problems.

A few open questions -
(1) Rune Haubo proposed that min2_LMM (his fm2) is nested under zcp_LMM_RE0
(his fm3) and could serve as a baseline model, but I don't understand why
it is nested.
(2) Marteen Jung wonders about Rune Haubo's fm5 (with four VCs; there was
typo in my last post). The ten models above have at most 3 VCs (i.e., the
number of levels of the factor). I also don't see a good place for it in
the sequences. Am I missing something?
(3) Any suggestions for models between maxLMM and intLMM and for models
between intLMM and minLMM?

Best
Reinhold Kliegl

[1] http://rpubs.com/Reinhold/391828
[2] https://arxiv.org/abs/1506.04967
[3] https://www.sciencedirect.com/science/article/pii/S0749596X17300013



On Tue, May 22, 2018 at 1:17 PM, Reinhold Kliegl <reinhold.kliegl at gmail.com>
wrote:
>
> There is an interpretable alternative to fm5 (actually there are many
...), called fm8 below, that avoids the redundancy between variance
components.  The change is to switch from (1 |g) + (0 + f | g) = (1 | g) +
(0 + A + B + C | g) to 1 | g) + (0 + c1 + c2 |g ), where c1 and c2 are the
contrasts defined for f. (I have actually used such LMMs quite often.) With
this specification the difference to the maxLMM (fm6) is that the
correlation between intercept and contrasts is suppressed to zero. The
correlation parameters now refer to the correlations between effects of c1
and c2, not to the correlations between A, B, and C.  Actually, this is but
one example of many LMMs one could slot into this position of the
hierarchical model sequences. At this level of model complexity one can
suppress various subsets of correlation parameters (as illustrated in Bates
et al. (2015)[1] and various vignettes of the RePsychLing package).
>
>
>  fm1 = y ~ 1 + f + (1 | g)                     # minimal LMM version 1
 (min1LMM)
>  fm2 = y ~ 1 + f + (1 | f:g)                   # minimal LMM version 2
 (min2LMM)
>  fm3 = y ~ 1 + f + (0 + f || g)                # zcpLMM with 0 in RE
(zcpLMM_RE0)
>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)         # LMM w/ f x g interaction
(intLMM)
>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g)       # N/A
>  fm6 = y ~ 1 + f + (1 + f |  g)                # maximal LMM (maxLMM)
>  fm7 = y ~ 1 + f + (1 + f || g)                # zcpLMM with 1 in RE
(zcpLMM_RE1)
>  fm8 = y ~ 1 + f + (1 | g) + (0 + c1 + c2 | g) # parsimonious LMM
(prsmLMM)
>
> Hierarchical model sequences
>
> (1) maxLMM_RE1 -> prsmLMM -> intLMM     -> min1LMM  # fm6 -> fm8 -> fm4
-> fm1
> (2) maxLMM_RE1 -> prsmLMM -> intLMM     -> min2LMM  # fm6 -> fm8 -> fm4
-> fm2
> (3) maxLMM_RE0 -> prsmLMM -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm8 -> fm3
-> fm2
> (4) maxLMM_RE1 -> prsmLMM -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm8 -> fm7
-> fm1  (new sequence)
> ```
>
> I will update the RPub in the next days.
>
> [1] https://arxiv.org/pdf/1506.04967.pdf
>
>
> Best regards,
> Reinhold Kliegl
>
> On Tue, May 22, 2018 at 11:00 AM, Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>
>> I see that fm2 is nested within fm3 and fm4.
>> But I have a hard time understanding fm3 and fm2 because, as Reinhold
Kiegl said, they specify the f:g interaction but without the g main effect.
Can someone provide an intuition for these models?
>>
>> Also, it is not entirely clear to me what fm5 represents. It looks to
me, and again I am with Reinhold Kiegl , as if there were
over-parameterization going on.
>>
>> Cheers,
>> Maarten
>>
>> On Tue, May 22, 2018 at 9:45 AM, Reinhold Kliegl <
reinhold.kliegl at gmail.com> wrote:
>>>
>>> Ok, I figured out the answer to the question about fm2.
>>>
>>> fm2 is indeed a very nice baseline for fm3 and fm4. So I distinguish
between min1LMM and min2LMM.
>>>
>>>  fm1 = y ~ 1 + f + (1 | g)               # minimal LMM version 1
 (min1LMM)
>>>  fm2 = y ~ 1 + f + (1 | f:g)             # minimal LMM version 2
 (min2LMM)
>>>  fm3 = y ~ 1 + f + (0 + f || g)          # zcpLMM with 0 in RE
(zcpLMM_RE0)
>>>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)   # LMM w/ f x g interaction
(intLMM)
>>>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g) # N/A
>>>  fm6 = y ~ 1 + f + (1 + f |  g)          # maximal LMM (maxLMM)
>>>  fm7 = y ~ 1 + f + (1 + f || g)          # zcpLMM with 1 in RE
(zcpLMM_RE1)
>>>
>>>
>>> (1) maxLMM_RE1 -> intLMM     -> min1LMM  # fm6 -> fm4 -> fm1
>>> (2) maxLMM_RE1 -> intLMM     -> min2LMM  # fm6 -> fm4 -> fm2
>>> (3) maxLMM_RE0 -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm3 -> fm2
>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm7 -> fm1  (new
sequence)
>>>
>>>
>>> On Tue, May 22, 2018 at 12:21 AM, Reinhold Kliegl <
reinhold.kliegl at gmail.com> wrote:
>>>>
>>>> Sorry, I am somewhat late to this conversation. I am responding to
this thread, because it fits my comment very well, but it was initially
triggered by a previous thread, especially Rune Haubo's post here [1]. So I
hope it is ok to continue here.
>>>>
>>>> I have a few comments and questions. For details I refer to an RPub I
put up along with this post [2]. I start with a translation between Rune
Haubo's fm's and the terminology I use in the RPub:
>>>>
>>>>  fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
>>>>  fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in
RE (zcpLMM_RE0)
>>>>  fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
interaction (intLMM),
>>>>  fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
>>>>  fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in
RE (zcpLMM_RE1)
>>>>
>>>> Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6
are in Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and
fm5 so far (see below).
>>>>
>>>> (I) The post was triggered by the question whether intLMM is nested
under zcpLMM. I had included this LRT in my older RPub cited in the thread,
but I stand corrected and agree with Rune Haubo that intLMM is not nested
under zcpLMM. For example, in the new RPub, I show that slightly modified
Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
additional model parameter in the latter. Thanks for the critical reading.
>>>>
>>>>
>>>> (II) Here are Runo Haubo's sequences (left, resorted) augmented with
my translation (right)
>>>>
>>>> (1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     ->
minLMM
>>>> (2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
>>>> (3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2
>>>>
>>>> and here are sequences I came up with (left) augmented with
translation into RH's fm's.
>>>>
>>>> (1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
>>>> (3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
>>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new
sequence)
>>>>
>>>>
>>>> (III) I have questions about fm2 and fm5.
>>>>    fm2: fm2 redefines the levels of the group factor (e.g., in the
cake data there are 45 groups in fm2 compared to 15 in the other models).
Why is fm2 nested under fm3 and fm6? Somehow it looks to me that you
include an f:g interaction without the g main effect (relative to fm4).
This looks like an interesting model; I would appreciate a bit more
conceptual support for its interpretation in the model hierarchy.
>>>>    fm5: fm5 specifies 4 variance components (VCs), but the factor has
only 3 levels. So to me this looks like there is redundancy built into the
model. In support of this intuition, for the cake data, one of the VCs is
estimated with 0. However, in the Machine data the model was not
degenerate. So I am not sure. In other words, if the factor levels are A,
B, C, and the two contrasts are c1 and c2, I thought I can specify either
(1 + c1 + c2) or (0 + A + B + C). fm5 specifies (1 + A + B + C) which is
rank deficient in the fixed effect part, but not necessarily in the
random-effect term. What am I missing here?
>>>>
>>>> [1]
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>>>> [2] http://rpubs.com/Reinhold/391027
>>>>
>>>> Best,
>>>> Reinhold Kliegl
>>>>
>>>>
>>>> On Thu, May 17, 2018 at 12:43 PM, Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>>> >
>>>> > Dear list,
>>>> >
>>>> > When one wants to specify a lmer model including variance components
but no
>>>> > correlation parameters for categorical predictors (factors) afaik
one has
>>>> > to convert the factors to numeric covariates or use lme4::dummy().
Until
>>>> > recently I thought m2a (or equivalently m2b using the double-bar
syntax)
>>>> > would be the correct way to specify such a zero-correlation
parameter model.
>>>> >
>>>> > But in this thread [1] Rune Haubo Bojesen Christensen pointed out
that this
>>>> > model does not make sense to him. Instead he suggests m3 as an
appropriate
>>>> > model.
>>>> > I think this is a *highly relevant difference* for everyone who uses
>>>> > factors in lmer and therefore I'm bringing up this issue again. But
maybe
>>>> > I'm mistaken and just don't get what is quite obvious for more
experienced
>>>> > mixed modelers.
>>>> > Please note that the question is on CrossValidated [2] but some
consider it
>>>> > as off-topic and I don't think there will be an answer any time soon.
>>>> >
>>>> > So here are my questions:
>>>> > How should one specify a lmm without correlation parameters for
factors and
>>>> > what are the differences between m2a and m3?
>>>> > Is there a preferred model for model comparison with m4 (this model
is also
>>>> > discussed here [3])?
>>>> >
>>>> > library("lme4")
>>>> > data("Machines", package = "MEMSS")
>>>> >
>>>> > d <- Machines
>>>> > contrasts(d$Machine)  # default coding: contr.sum
>>>> >
>>>> > m1 <- lmer(score ~ Machine + (Machine | Worker), d)
>>>> >
>>>> > c1 <- model.matrix(m1)[, 2]
>>>> > c2 <- model.matrix(m1)[, 3]
>>>> > m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0
+ c2 |
>>>> > Worker), d)
>>>> > m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
>>>> > VarCorr(m2a)
>>>> >  Groups   Name        Std.Dev.
>>>> >  Worker   (Intercept) 5.24354
>>>> >  Worker.1 c1          2.58446
>>>> >  Worker.2 c2          3.71504
>>>> >  Residual             0.96256
>>>> >
>>>> > m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A")
|
>>>> > Worker) +
>>>> >                                             (0 + dummy(Machine, "B")
|
>>>> > Worker) +
>>>> >                                             (0 + dummy(Machine, "C")
|
>>>> > Worker), d)
>>>> > VarCorr(m3)
>>>> >  Groups   Name                Std.Dev.
>>>> >  Worker   (Intercept)         3.78595
>>>> >  Worker.1 dummy(Machine, "A") 1.94032
>>>> >  Worker.2 dummy(Machine, "B") 5.87402
>>>> >  Worker.3 dummy(Machine, "C") 2.84547
>>>> >  Residual                     0.96158
>>>> >
>>>> > m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
>>>> >
>>>> >
>>>> > [1]
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>>>> > [2] https://stats.stackexchange.com/q/345842/136579
>>>> > [3] https://stats.stackexchange.com/q/304374/136579
>>>> >
>>>> > Best regards,
>>>> > Maarten
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > _______________________________________________
>>>> > R-sig-mixed-models at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From D@vid@Duffy @ending from qimrberghofer@edu@@u  Fri May 25 08:58:40 2018
From: D@vid@Duffy @ending from qimrberghofer@edu@@u (David Duffy)
Date: Fri, 25 May 2018 06:58:40 +0000
Subject: [R-sig-ME] MCMCglmm models and (quasi-)complete separation
In-Reply-To: <CAD+CoDMgKNRDBnj0kLjG2MiOKYKmQC1+ZpJNKTRCtOpb155EGg@mail.gmail.com>
References: <CAD+CoDMaqnOwCaENchc60HoW_M+xC3k4vk=axaB2c7zrGTFuFw@mail.gmail.com>,
 <CAD+CoDMgKNRDBnj0kLjG2MiOKYKmQC1+ZpJNKTRCtOpb155EGg@mail.gmail.com>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D4A84A9A39@EXCH06S.adqimr.ad.lan>

Dear Jasmin. I, at least, would need to see some kind of data to understand your comments re separation etc. Does a simpler model run eg dropping field_block and simplifying the fixed effects? And does such a model run in lmer or other programs? Diagnosing a nonidentified model (ie some parameters in your model may not be estimable given your pattern of observations) in MCMC is hard.
________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jasmin Herden [jasmin.herden at gmail.com]
Sent: Thursday, 24 May 2018 10:16 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm models and (quasi-)complete separation

Dear fellow R users,

I have recently started using the MCMCglmm R package to analyse some of my
problematic
data which severely suffers from (quasi)complete separation.

I have followed Ben Bolker's suggestions of zero-mean Normal priors on the
fixed effects to analyse such kinds of data.
(https://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html)

My model is:

k<-8 #number of the fixed effects
     #Intercept+single effects+interactions

prior.c <- list(B=list(V=diag(9,k), mu=rep(0,k)),
                R=list(V=1,fix=1),
                G=list(G1=list(V=1, nu=1,alpha.mu=0, alpha.V=1000),
                       G2=list(V=1,nu=1,alpha.mu=0, alpha.V=1000),
                       G3=list(V=1,nu=1,alpha.mu=0, alpha.V=1000)))

nsamp <- 10000
THIN <- 900
BURNIN <- 10000
NITT <- BURNIN + THIN*nsamp
model3 = MCMCglmm(survival~
                    Site*b*c,
                  random=~x+Field+Field_block,
                  data=dset,
                    slice=TRUE,
                    pl=T,
                    prior=prior.c,
                    family="categorical",verbose=FALSE,
                    nitt=NITT,burnin=BURNIN,thin=THIN)

Survival is a binary value of 0 or 1 and is observed only once per
experimental plant.
Therefore the observation-level variance R is fixed to 1. (As in the linked
example.)

Site, b, and c are two-level categorical variables. x is crossed with Field
and Field_block, but Field_block is nested within Field.

Models are run for each species separately.

My questions are:

a) Many worked examples which I based my own analysis on use the
Gelman-Rubin
criterion where you check the convergence of your model by running it a
number of times and then compare models.

However, I think the MCMCglmm vignette said to start the model running with
overdispersed priors which is definitely not an option for me with the kind
of data I have.

I have tried using the testing for the Gelman-Rubin criterion nonetheless,
but the Gelman diagnostic plots do not show a oscillating line that finally
converges on a value but
rather clines and straigt lines.

b) I am also not quite sure, if the value R is fixed at is appropiate for
all models I run. For some
models, I still get latent variable values bigger than 20, even at very
high numbers of iterations.

c) How do you decide to use family="categorical" (=logit link) or "ordinal"
(=probit link)?
Based on the DIC of the models?

d) For many of my models, the explained variance for the random effects
Field and Field_block are very high; sometimes reaching an upper estimate
of 99%.
I think the problem is that Field_block is not only nested in Field but
that Field is also
nested in the categorical fixed effect Site.
Is my model overparametrized with regard to Field, since I have nearly
complete survival in one of the two levels of Site?

Kind regards,
Jasmin

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From rune@h@ubo @ending from gm@il@com  Fri May 25 10:27:26 2018
From: rune@h@ubo @ending from gm@il@com (Rune Haubo)
Date: Fri, 25 May 2018 10:27:26 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAG+WrEwpGxDbN6Gif2TiP80XZZZPqeNgwoFZEuuvVSGp808YxA@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
 <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
 <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>
 <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>
 <CAG+WrEwpGxDbN6Gif2TiP80XZZZPqeNgwoFZEuuvVSGp808YxA@mail.gmail.com>
Message-ID: <CAG_uk925yU88bmdfheifETi8X-yBuV=TUQeL_SgWpidp7NBcew@mail.gmail.com>

On 24 May 2018 at 21:22, Reinhold Kliegl <reinhold.kliegl at gmail.com> wrote:
> Here is an update (final for now) with 10 models and 4 hierarchical
> sequences. Comments, details, and a demonstration with the Machines data are
> available in a new RPub[1]. I switched to a notation with numeric covariates
> to reduce potential confusion about terms containing `1+f` and `0+f`; `c1`
> and `c2` are contrasts defined for a factor with levels `A`, `B`, and `C`.
>
> ## LMMs
>
> ### Prototype LMMs
>
> max_LMM:   m1 = y ~ 1 + c1 + c2 + (1 + c1 + c2 | subj)
> prsm1_LMM: m2 = y ~ 1 + c1 + c2 + (1 | subj) + (0 + c1 + c2 | subj)
> zcp_LMM:   m3 = y ~ 1 + c1 + c2 + (1 + c1 + c2 || subj)
> prsm2_LMM: m4 = y ~ 1 + c1 + c2 + (1 + c2 || subj)
> min_LMM:   m5 = y ~ 1 + c1 + c2 + (1 | subj)
>
> Protoype refers to prsm1 and prsm2; there are also variations of them. Prsm1
> are models pruning correlation parameters; prsm2 are models pruning variance
> components in the absence of correlation parameters. The order reflects
> hierarchical decreasing model complexity.
>
> ### LMMs with interaction term
>
> int_LMM:   m6 = y ~ 1 + c1 + c2 + (1 | subj) + (1 | factor:subj)
> min2_Lmm:  m7 = y ~ 1 + c1 + c2 + (1 | factor:subj)
>
> ### LMMs with (0 + f | g) RE structures
>
> maxL_MM_RE0:   m8 = y ~ 1 + c1 + c2 + (0 + A + B + C | subj)
> prsm1_LMM_RE0: m9 = y ~ 1 + c1 + c2 + (0 + A | subj) + (0 + B + C | subj)
> zcp_LMM_RE0:  m10 = y ~ 1 + c1 + c2 + (0 + A + B + C || subj)
>
> ## Hierarchical model sequences
>
> Here are the sequences I am confident about.
>
> (1) max_LMM -> prsm1_LMM -> zcp_LMM -> prsm2_LMM -> min1_LMM
> (2) max_LMM -> int_LMM -> min1_LMM
> (3) max_LMM -> int_LMM -> min2_LMM
> (4) max_LMM_RE0 -> prsm1_LMM_RE0 -> zcp_LMM_RE0
>
> So far, in my research, I have worked almost exclusively with Sequence (1)
> and do not recall ever experiencing technical problems or inconsistencies as
> long as there was no overparameterization. It has served me well in the
> determination of parsimonious LMMs[2, 3].
>
> For complex fixed-effect structures (i.e., for models with many factors or
> with factors with many levels), the number of correlation parameters grows
> very rapidly. If this goes together with a modest number of observations or
> levels of the random factor, Sequences (2) and (3) might be a good place to
> start to avoid convergence problems. Of course, if your hypotheses are about
> correlation parameters, these LMMs will not get you very far.
>
> Finally, Sequence (4) could be a default strategy if one is interested in
> the fixed effects and if one does not want to spend much time in wondering
> about the meaning of CPs. However, as correlations between levels of fixed
> factors are can be very large (at least larger than correlations between
> effects), LMMs in this sequence may be prone to convergence problems.
>
> A few open questions -
> (1) Rune Haubo proposed that min2_LMM (his fm2) is nested under zcp_LMM_RE0
> (his fm3) and could serve as a baseline model, but I don't understand why it
> is nested.
> (2) Marteen Jung wonders about Rune Haubo's fm5 (with four VCs; there was
> typo in my last post). The ten models above have at most 3 VCs (i.e., the
> number of levels of the factor). I also don't see a good place for it in the
> sequences. Am I missing something?
> (3) Any suggestions for models between maxLMM and intLMM and for models
> between intLMM and minLMM?

I must admit that I haven't read all of the above in detail but I can
address the
specific questions.

First a note on terminology: My understanding is that a variance component (VC)
is an random-effects term that is independent of other terms and
classically a term of the form
(1 | g) or (1 | g:f). If we also allow the VC-terminology for random terms with
vector-valued random-effects, e.g. (g | f), then arguably none of the models
have more than two VCs (excluding residuals).

For the Machines data fm5 reads
fm5 <- lmer(score ~  Machine + (1 | Worker) +
              (0 + dummy(Machine, "A") | Worker) +
              (0 + dummy(Machine, "B") | Worker) +
              (0 + dummy(Machine, "C") | Worker), Machines)

which may also be specified as (thanks Reinhold Kliegl)

mm0 <- model.matrix(~ 0 + Machine, Machines)
A <- mm0[, 1]
B <- mm0[, 2]
C <- mm0[, 3]
fm5b <- lmer(score ~  Machine + (1 | Worker) + (0 + A + B + C ||
Worker), Machines)
anova(fm5, fm5b, refit=FALSE) # Chisq = 0
and there other variants as well.

Other relevant models to be discussed are:
fm3 <- lmer(score ~  Machine + (0 + A + B + C || Worker), Machines)
fm2 <- lmer(score ~  Machine + (1| Worker:Machine), Machines)
fm6 <- lmer(score ~  Machine + (0 + Machine | Worker), Machines)

Since observations on different Workers are independent we can understand these
models by considering how they parameterize the variance-covariance
matrix of the
9 observations that belong to each Worker in the marginal distribution
of the observations.

fm5, uses 5 variance-parameters to parameterize the by-Worker
(9x9) variance-covariance matrix, Cov(Y_j): 1 for (1 | Worker), 3 for
(0 + A + B + C || Worker) and 1 for the residual variance.

The covariance structure for within-Worker observations is:
- The variance of each observation is sigma_w^2 + sigma_i^2 + sigma^2 where
the terms refer to Worker, the i'th Machine and residuals.
- The covariance between two different obervations from the same Machine and
Worker is sigma_w^2 + sigma_i^2, i.e. it depends on which Machine was used.
- The covariance between two different observations on the same Worker but
different Machines is just sigma_w^2.

Thus, if (1 | Worker) is removed from fm5 it reduces to fm3 and it amounts to
setting sigma_w^2 to zero. In effect the covariance betwen two different
observations on the same Worker but different Machines is 0.

If instead we consider model fm6 which corresponds to exchanging all random
terms in fm5 with (0 + Machine | Worker) it changes the covariance of two
observations from the same Worker and different Machines from a constant
sigma_w^2 to sigma_{i,i'}^2, i.e., it depends on which pair of Machines the
two observations come from. Since there are 6 possible pairs of Machines fm6
uses 6+1 variance parameters to parameterize the Worker-level covariance matrix,
i.e. 2 more than fm5.

For the Machines data fm2 reads
fm2 <- lmer(score ~  Machine + (1 | Worker:Machine), Machines)

This model says that the covariance between two different observations
on the same
Worker and same Machine is sigma_{mw}^2 thus it is different from fm3 by setting
sigma_i^2 to the constant (wrt. Machine) sigma_{mw}^2. With 3 Machines fm2
saves 2 variance-parameters relative to fm3 and ends up using only 2 variance
parameters. For completeness, the variance of an observation is
sigma_{mw}^2 + sigma^2
and the covariance of any two observations which are not from the same
Worker and the
same Machine is 0.

Now, I skipped a number of details but an email is not exactly suited for a
mathematical exposition so I hope the above makes sense, and I hope it
helps explain the nesting structure.

Cheers
Rune

>
> Best
> Reinhold Kliegl
>
> [1] http://rpubs.com/Reinhold/391828
> [2] https://arxiv.org/abs/1506.04967
> [3] https://www.sciencedirect.com/science/article/pii/S0749596X17300013
>
>
>
> On Tue, May 22, 2018 at 1:17 PM, Reinhold Kliegl <reinhold.kliegl at gmail.com>
> wrote:
>>
>> There is an interpretable alternative to fm5 (actually there are many
>> ...), called fm8 below, that avoids the redundancy between variance
>> components.  The change is to switch from (1 |g) + (0 + f | g) = (1 | g) +
>> (0 + A + B + C | g) to 1 | g) + (0 + c1 + c2 |g ), where c1 and c2 are the
>> contrasts defined for f. (I have actually used such LMMs quite often.) With
>> this specification the difference to the maxLMM (fm6) is that the
>> correlation between intercept and contrasts is suppressed to zero. The
>> correlation parameters now refer to the correlations between effects of c1
>> and c2, not to the correlations between A, B, and C.  Actually, this is but
>> one example of many LMMs one could slot into this position of the
>> hierarchical model sequences. At this level of model complexity one can
>> suppress various subsets of correlation parameters (as illustrated in Bates
>> et al. (2015)[1] and various vignettes of the RePsychLing package).
>>
>>
>>  fm1 = y ~ 1 + f + (1 | g)                     # minimal LMM version 1
>> (min1LMM)
>>  fm2 = y ~ 1 + f + (1 | f:g)                   # minimal LMM version 2
>> (min2LMM)
>>  fm3 = y ~ 1 + f + (0 + f || g)                # zcpLMM with 0 in RE
>> (zcpLMM_RE0)
>>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)         # LMM w/ f x g interaction
>> (intLMM)
>>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g)       # N/A
>>  fm6 = y ~ 1 + f + (1 + f |  g)                # maximal LMM (maxLMM)
>>  fm7 = y ~ 1 + f + (1 + f || g)                # zcpLMM with 1 in RE
>> (zcpLMM_RE1)
>>  fm8 = y ~ 1 + f + (1 | g) + (0 + c1 + c2 | g) # parsimonious LMM
>> (prsmLMM)
>>
>> Hierarchical model sequences
>>
>> (1) maxLMM_RE1 -> prsmLMM -> intLMM     -> min1LMM  # fm6 -> fm8 -> fm4 ->
>> fm1
>> (2) maxLMM_RE1 -> prsmLMM -> intLMM     -> min2LMM  # fm6 -> fm8 -> fm4 ->
>> fm2
>> (3) maxLMM_RE0 -> prsmLMM -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm8 -> fm3 ->
>> fm2
>> (4) maxLMM_RE1 -> prsmLMM -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm8 -> fm7 ->
>> fm1  (new sequence)
>> ```
>>
>> I will update the RPub in the next days.
>>
>> [1] https://arxiv.org/pdf/1506.04967.pdf
>>
>>
>> Best regards,
>> Reinhold Kliegl
>>
>> On Tue, May 22, 2018 at 11:00 AM, Maarten Jung
>> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>>
>>> I see that fm2 is nested within fm3 and fm4.
>>> But I have a hard time understanding fm3 and fm2 because, as Reinhold
>>> Kiegl said, they specify the f:g interaction but without the g main effect.
>>> Can someone provide an intuition for these models?
>>>
>>> Also, it is not entirely clear to me what fm5 represents. It looks to me,
>>> and again I am with Reinhold Kiegl , as if there were over-parameterization
>>> going on.
>>>
>>> Cheers,
>>> Maarten
>>>
>>> On Tue, May 22, 2018 at 9:45 AM, Reinhold Kliegl
>>> <reinhold.kliegl at gmail.com> wrote:
>>>>
>>>> Ok, I figured out the answer to the question about fm2.
>>>>
>>>> fm2 is indeed a very nice baseline for fm3 and fm4. So I distinguish
>>>> between min1LMM and min2LMM.
>>>>
>>>>  fm1 = y ~ 1 + f + (1 | g)               # minimal LMM version 1
>>>> (min1LMM)
>>>>  fm2 = y ~ 1 + f + (1 | f:g)             # minimal LMM version 2
>>>> (min2LMM)
>>>>  fm3 = y ~ 1 + f + (0 + f || g)          # zcpLMM with 0 in RE
>>>> (zcpLMM_RE0)
>>>>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)   # LMM w/ f x g interaction
>>>> (intLMM)
>>>>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g) # N/A
>>>>  fm6 = y ~ 1 + f + (1 + f |  g)          # maximal LMM (maxLMM)
>>>>  fm7 = y ~ 1 + f + (1 + f || g)          # zcpLMM with 1 in RE
>>>> (zcpLMM_RE1)
>>>>
>>>>
>>>> (1) maxLMM_RE1 -> intLMM     -> min1LMM  # fm6 -> fm4 -> fm1
>>>> (2) maxLMM_RE1 -> intLMM     -> min2LMM  # fm6 -> fm4 -> fm2
>>>> (3) maxLMM_RE0 -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm3 -> fm2
>>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm7 -> fm1  (new
>>>> sequence)
>>>>
>>>>
>>>> On Tue, May 22, 2018 at 12:21 AM, Reinhold Kliegl
>>>> <reinhold.kliegl at gmail.com> wrote:
>>>>>
>>>>> Sorry, I am somewhat late to this conversation. I am responding to this
>>>>> thread, because it fits my comment very well, but it was initially triggered
>>>>> by a previous thread, especially Rune Haubo's post here [1]. So I hope it is
>>>>> ok to continue here.
>>>>>
>>>>> I have a few comments and questions. For details I refer to an RPub I
>>>>> put up along with this post [2]. I start with a translation between Rune
>>>>> Haubo's fm's and the terminology I use in the RPub:
>>>>>
>>>>>  fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
>>>>>  fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in
>>>>> RE (zcpLMM_RE0)
>>>>>  fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
>>>>> interaction (intLMM),
>>>>>  fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
>>>>>  fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in
>>>>> RE (zcpLMM_RE1)
>>>>>
>>>>> Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6
>>>>> are in Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and
>>>>> fm5 so far (see below).
>>>>>
>>>>> (I) The post was triggered by the question whether intLMM is nested
>>>>> under zcpLMM. I had included this LRT in my older RPub cited in the thread,
>>>>> but I stand corrected and agree with Rune Haubo that intLMM is not nested
>>>>> under zcpLMM. For example, in the new RPub, I show that slightly modified
>>>>> Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
>>>>> additional model parameter in the latter. Thanks for the critical reading.
>>>>>
>>>>>
>>>>> (II) Here are Runo Haubo's sequences (left, resorted) augmented with my
>>>>> translation (right)
>>>>>
>>>>> (1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     ->
>>>>> minLMM
>>>>> (2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
>>>>> (3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2
>>>>>
>>>>> and here are sequences I came up with (left) augmented with translation
>>>>> into RH's fm's.
>>>>>
>>>>> (1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
>>>>> (3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
>>>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new
>>>>> sequence)
>>>>>
>>>>>
>>>>> (III) I have questions about fm2 and fm5.
>>>>>    fm2: fm2 redefines the levels of the group factor (e.g., in the cake
>>>>> data there are 45 groups in fm2 compared to 15 in the other models). Why is
>>>>> fm2 nested under fm3 and fm6? Somehow it looks to me that you include an f:g
>>>>> interaction without the g main effect (relative to fm4). This looks like an
>>>>> interesting model; I would appreciate a bit more conceptual support for its
>>>>> interpretation in the model hierarchy.
>>>>>    fm5: fm5 specifies 4 variance components (VCs), but the factor has
>>>>> only 3 levels. So to me this looks like there is redundancy built into the
>>>>> model. In support of this intuition, for the cake data, one of the VCs is
>>>>> estimated with 0. However, in the Machine data the model was not degenerate.
>>>>> So I am not sure. In other words, if the factor levels are A, B, C, and the
>>>>> two contrasts are c1 and c2, I thought I can specify either (1 + c1 + c2) or
>>>>> (0 + A + B + C). fm5 specifies (1 + A + B + C) which is rank deficient in
>>>>> the fixed effect part, but not necessarily in the random-effect term. What
>>>>> am I missing here?
>>>>>
>>>>> [1]
>>>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>>>>> [2] http://rpubs.com/Reinhold/391027
>>>>>
>>>>> Best,
>>>>> Reinhold Kliegl
>>>>>
>>>>>
>>>>> On Thu, May 17, 2018 at 12:43 PM, Maarten Jung
>>>>> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>>>> >
>>>>> > Dear list,
>>>>> >
>>>>> > When one wants to specify a lmer model including variance components
>>>>> > but no
>>>>> > correlation parameters for categorical predictors (factors) afaik one
>>>>> > has
>>>>> > to convert the factors to numeric covariates or use lme4::dummy().
>>>>> > Until
>>>>> > recently I thought m2a (or equivalently m2b using the double-bar
>>>>> > syntax)
>>>>> > would be the correct way to specify such a zero-correlation parameter
>>>>> > model.
>>>>> >
>>>>> > But in this thread [1] Rune Haubo Bojesen Christensen pointed out
>>>>> > that this
>>>>> > model does not make sense to him. Instead he suggests m3 as an
>>>>> > appropriate
>>>>> > model.
>>>>> > I think this is a *highly relevant difference* for everyone who uses
>>>>> > factors in lmer and therefore I'm bringing up this issue again. But
>>>>> > maybe
>>>>> > I'm mistaken and just don't get what is quite obvious for more
>>>>> > experienced
>>>>> > mixed modelers.
>>>>> > Please note that the question is on CrossValidated [2] but some
>>>>> > consider it
>>>>> > as off-topic and I don't think there will be an answer any time soon.
>>>>> >
>>>>> > So here are my questions:
>>>>> > How should one specify a lmm without correlation parameters for
>>>>> > factors and
>>>>> > what are the differences between m2a and m3?
>>>>> > Is there a preferred model for model comparison with m4 (this model
>>>>> > is also
>>>>> > discussed here [3])?
>>>>> >
>>>>> > library("lme4")
>>>>> > data("Machines", package = "MEMSS")
>>>>> >
>>>>> > d <- Machines
>>>>> > contrasts(d$Machine)  # default coding: contr.sum
>>>>> >
>>>>> > m1 <- lmer(score ~ Machine + (Machine | Worker), d)
>>>>> >
>>>>> > c1 <- model.matrix(m1)[, 2]
>>>>> > c2 <- model.matrix(m1)[, 3]
>>>>> > m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 +
>>>>> > c2 |
>>>>> > Worker), d)
>>>>> > m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
>>>>> > VarCorr(m2a)
>>>>> >  Groups   Name        Std.Dev.
>>>>> >  Worker   (Intercept) 5.24354
>>>>> >  Worker.1 c1          2.58446
>>>>> >  Worker.2 c2          3.71504
>>>>> >  Residual             0.96256
>>>>> >
>>>>> > m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A")
>>>>> > |
>>>>> > Worker) +
>>>>> >                                             (0 + dummy(Machine, "B")
>>>>> > |
>>>>> > Worker) +
>>>>> >                                             (0 + dummy(Machine, "C")
>>>>> > |
>>>>> > Worker), d)
>>>>> > VarCorr(m3)
>>>>> >  Groups   Name                Std.Dev.
>>>>> >  Worker   (Intercept)         3.78595
>>>>> >  Worker.1 dummy(Machine, "A") 1.94032
>>>>> >  Worker.2 dummy(Machine, "B") 5.87402
>>>>> >  Worker.3 dummy(Machine, "C") 2.84547
>>>>> >  Residual                     0.96158
>>>>> >
>>>>> > m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
>>>>> >
>>>>> >
>>>>> > [1]
>>>>> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
>>>>> > [2] https://stats.stackexchange.com/q/345842/136579
>>>>> > [3] https://stats.stackexchange.com/q/304374/136579
>>>>> >
>>>>> > Best regards,
>>>>> > Maarten
>>>>> >
>>>>> >         [[alternative HTML version deleted]]
>>>>> >
>>>>> > _______________________________________________
>>>>> > R-sig-mixed-models at r-project.org mailing list
>>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>
>>
>


From @h@r@d@@r@m@d@@@ @ending from gm@il@com  Fri May 25 13:28:17 2018
From: @h@r@d@@r@m@d@@@ @ending from gm@il@com (Sharada Ramadass)
Date: Fri, 25 May 2018 16:58:17 +0530
Subject: [R-sig-ME] modeling fixed effects with different spatial scales in
 glmm using nlme
Message-ID: <CAG=Fgt_vB+Wke3CFEpM_xzJCJRqRw8Pq3PY9JaXMcZaGvAV16g@mail.gmail.com>

Hello,
  This is my first time working with glmm and the associated software in R
and I am using nlme to model my research data. I have multiple queries
relating to the model design and results interpretation and will post them
as separate questions for the sake of clarity.

Here is my first query:

I am looking at predictors of growth (response), and have fixed effects at
different spatial scales - individual level measurement (for an organism)
called I, and measurements at two different spatial scales for abiotic (A)
and biotic (B) factors.

Do I need to do anything different to incorporate the different scales of
the fixed effects or could I use them in a normal glmm model, e.g.
(this is just a notation and not the exact syntax)
lme(growth ~ I + A + B +<random effects>)

In some ways it mimics a split plot design which has explanatory variables
at different spatial scales, though this is not an experimental setup but
field data.

Any inputs will be appreciated.
Thanks and Regards,
Sharada

	[[alternative HTML version deleted]]


From @h@r@d@@r@m@d@@@ @ending from gm@il@com  Fri May 25 13:41:56 2018
From: @h@r@d@@r@m@d@@@ @ending from gm@il@com (Sharada Ramadass)
Date: Fri, 25 May 2018 17:11:56 +0530
Subject: [R-sig-ME] modeling nested random effects with glmm using nlme
Message-ID: <CAG=Fgt8MSTyiBmS4wyrr701-Yj_f8GwSRVViHGc3toSZpDUuvQ@mail.gmail.com>

Hello,
  I am new to glmm and am using nlme to model a mixed effects model for my
data.
I have 13 species and 15 individuals per species. I am looking at including
both species and individuals as random effect factors. While I have
multiple measurements at the species level (multiple individuals measured
for the same data), I only have 1 measurement at the individual level
within any species.

This FAQ (https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html)
tells me

1|species/individual = intercept varying among species and among
individuals within species.

In that case, since I have 15 individuals per species, does it make sense
to include the individual as a nested factor within species in the random
effects? Somewhere else I read that if you do not have repeat measures, it
does not make sense to include that factor as a random effect.

Any inputs would be appreciated.
Thanks and Regards,
Sharada

	[[alternative HTML version deleted]]


From @h@r@d@@r@m@d@@@ @ending from gm@il@com  Fri May 25 13:48:22 2018
From: @h@r@d@@r@m@d@@@ @ending from gm@il@com (Sharada Ramadass)
Date: Fri, 25 May 2018 17:18:22 +0530
Subject: [R-sig-ME] Interpreting and making sense of the variance in random
 effects with glmm in nlme
Message-ID: <CAG=Fgt9DwyuLEJGEu-8xhuC9WQ3LKHWB1Ufy7ew76KMk_DxDnA@mail.gmail.com>

Hello,
  I am new to glmm and I am trying to use a mixed model for my data. I have
explanatory variables that are fixed effects, such as individual organism
measurement data, biotic and abiotic factors (both at different spatial
scales).
I also have 13 species and 15 individuals per species and have incorporated
them as random effects (with individuals nested within species in an
intercept model).

However, I am not clear as to how to interpret the random effects variance
components and how they relate to the total variance explained by the
random factors in the model.

Here's an example output snippet.

Random effects:

 Formula: ~1 | species

        (Intercept)

StdDev:   0.2443396



 Formula: ~1 | indv %in% species

         (Intercept)  Residual

StdDev: 4.502529e-05 0.5041833

How do I interpret this output? Any inputs would be appreciated.

Thanks and Regards,
Sharada

	[[alternative HTML version deleted]]


From j@@min@herden @ending from gm@il@com  Fri May 25 14:05:33 2018
From: j@@min@herden @ending from gm@il@com (Jasmin Herden)
Date: Fri, 25 May 2018 14:05:33 +0200
Subject: [R-sig-ME] MCMCglmm models and (quasi-)complete separation
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D4A84A9A39@EXCH06S.adqimr.ad.lan>
References: <CAD+CoDMaqnOwCaENchc60HoW_M+xC3k4vk=axaB2c7zrGTFuFw@mail.gmail.com>
 <CAD+CoDMgKNRDBnj0kLjG2MiOKYKmQC1+ZpJNKTRCtOpb155EGg@mail.gmail.com>
 <4737E17E7C8C3C4A8B5C1CE5346371D4A84A9A39@EXCH06S.adqimr.ad.lan>
Message-ID: <CAD+CoDNBaLEC=F5Z5gMpWPBzkgiEwCM7Fxn7W9nhPrTQnHtj5g@mail.gmail.com>

Dear David,

a)


*Dear Jasmin. I, at least, would need to see some kind of data to
understand your comments re separation etc.*
Here are the first few lines of the data set.


> head(dsetMailingList)       Site Field Species PlantID native.neophyte Treatment Seed_family Origin survival_to_harvest   Sp_Sf Field_Subplot
355 Potsdam    DB     Dat Dat10CK        neophyte       CON
E10      K                   1 Dat.E10        DB _ C
356 Potsdam    MQ     Dat Dat10CK        neophyte       CON
E10      K                   0 Dat.E10        MQ _ B
357 Potsdam    GR     Dat Dat10CK        neophyte       CON
E10      K                   1 Dat.E10        GR _ B
358 Potsdam    GR     Dat Dat10CP        neophyte       CON
10      P                   0  Dat.10        GR _ B
359 Potsdam    DB     Dat Dat10CP        neophyte       CON
10      P                   1  Dat.10        DB _ A
360 Potsdam    MQ     Dat Dat10CP        neophyte       CON
10      P                   1  Dat.10        MQ _ B


>

b) *Does a simpler model run eg dropping field_block and simplifying the
fixed effects? And does such a model run in lmer or other programs?*

I had originally started with a binomial glmer model, but in most species
this lead to ridiculously large standard errors. These large SE values are
indicative of quasi-complete separation (i.e. nearly complete 0 or 1 for
one factor level). (See also the following link:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004172.html).

I have tried using blglmer as suggested by Ben Bolker in the example
referenced in my first post to the mailing list. In principle, all models
with complete separation looked good with bglmer.
However, my intended approach in glmer was to take the full model and get
likelihood ratio tests and corresponding p-values for the fixed effects by
step-wise model
reduction. Theoretically, this is also possible with bglmer, but Ben Bolker
advised against using bglmer for more than just an overall model check in
several posts. Furthermore, I am not quite sure if or how I need to adjust
the priors in bglmer during step-wise model reduction or if step-wise model
reduction is appropiate for bglmer at all. Ben Bolker recommended using the
MCMCglmm package instead of bglmer for a proper analysis.

Due to my approach of testing all fixed effects (Site, Origin, and
Treatment, and interactions) in my local adaptation study, reducing the
fixed effects is not really an option.

Kind regards,
Jasmin Herden




On Fri, May 25, 2018 at 8:58 AM, David Duffy <David.Duffy at qimrberghofer.
edu.au> wrote:

>  Does a simpler model run eg dropping field_block and simplifying the
> fixed effects? And does such a model run in lmer or other programs?
> Diagnosing a nonidentified model (ie some parameters in your model may not
> be estimable given your pattern of observations) in MCMC is hard.
> ________________________________________
> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> behalf of Jasmin Herden [jasmin.herden at gmail.com]
> Sent: Thursday, 24 May 2018 10:16 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm models and (quasi-)complete separation
>
> Dear fellow R users,
>
> I have recently started using the MCMCglmm R package to analyse some of my
> problematic
> data which severely suffers from (quasi)complete separation.
>
> I have followed Ben Bolker's suggestions of zero-mean Normal priors on the
> fixed effects to analyse such kinds of data.
> (https://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html)
>
> My model is:
>
> k<-8 #number of the fixed effects
>      #Intercept+single effects+interactions
>
> prior.c <- list(B=list(V=diag(9,k), mu=rep(0,k)),
>                 R=list(V=1,fix=1),
>                 G=list(G1=list(V=1, nu=1,alpha.mu=0, alpha.V=1000),
>                        G2=list(V=1,nu=1,alpha.mu=0, alpha.V=1000),
>                        G3=list(V=1,nu=1,alpha.mu=0, alpha.V=1000)))
>
> nsamp <- 10000
> THIN <- 900
> BURNIN <- 10000
> NITT <- BURNIN + THIN*nsamp
> model3 = MCMCglmm(survival~
>                     Site*b*c,
>                   random=~x+Field+Field_block,
>                   data=dset,
>                     slice=TRUE,
>                     pl=T,
>                     prior=prior.c,
>                     family="categorical",verbose=FALSE,
>                     nitt=NITT,burnin=BURNIN,thin=THIN)
>
> Survival is a binary value of 0 or 1 and is observed only once per
> experimental plant.
> Therefore the observation-level variance R is fixed to 1. (As in the linked
> example.)
>
> Site, b, and c are two-level categorical variables. x is crossed with Field
> and Field_block, but Field_block is nested within Field.
>
> Models are run for each species separately.
>
> My questions are:
>
> a) Many worked examples which I based my own analysis on use the
> Gelman-Rubin
> criterion where you check the convergence of your model by running it a
> number of times and then compare models.
>
> However, I think the MCMCglmm vignette said to start the model running with
> overdispersed priors which is definitely not an option for me with the kind
> of data I have.
>
> I have tried using the testing for the Gelman-Rubin criterion nonetheless,
> but the Gelman diagnostic plots do not show a oscillating line that finally
> converges on a value but
> rather clines and straigt lines.
>
> b) I am also not quite sure, if the value R is fixed at is appropiate for
> all models I run. For some
> models, I still get latent variable values bigger than 20, even at very
> high numbers of iterations.
>
> c) How do you decide to use family="categorical" (=logit link) or "ordinal"
> (=probit link)?
> Based on the DIC of the models?
>
> d) For many of my models, the explained variance for the random effects
> Field and Field_block are very high; sometimes reaching an upper estimate
> of 99%.
> I think the problem is that Field_block is not only nested in Field but
> that Field is also
> nested in the categorical fixed effect Site.
> Is my model overparametrized with regard to Field, since I have nearly
> complete survival in one of the two levels of Site?
>
> Kind regards,
> Jasmin
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From g@i@rrido @ending from gm@il@com  Fri May 25 10:13:34 2018
From: g@i@rrido @ending from gm@il@com (Mario Garrido)
Date: Fri, 25 May 2018 11:13:34 +0300
Subject: [R-sig-ME] 
 P-value associated to explanatory from glmer binomial family
In-Reply-To: <CAJuCY5w0MkdWAtAaj1_8VMJDvqFZYNXBnCT5OtmXsL0Lwaf+Yg@mail.gmail.com>
References: <CABi7Y8b0+p1knXtoOra5oH5X352oT4GH6LLMnzr=Oq6226GOLg@mail.gmail.com>
 <CAJuCY5w0MkdWAtAaj1_8VMJDvqFZYNXBnCT5OtmXsL0Lwaf+Yg@mail.gmail.com>
Message-ID: <CABi7Y8ZEYuik7GoHkOgvde90Hrt9X1Gpzd68wHBDpHdz=jgnaw@mail.gmail.com>

 Dear Thierry,
thanks so much for the clarification. After I run the LRT I get those
results

gm1 <- glmer(Mycoplasma~ type+ (1|donor.number), family=binomial)

anova(gm1)

Analysis of Variance Table

     Df Sum Sq Mean Sq F value

type  1 3.2124  3.2124  3.2124

gm0<-  glmer(Mycoplasma~ 1+ (1|donor.number), family=binomial)

anova(gm1, gm0)

Data: NULL

Models:

gm0: Mycoplasma ~ 1 + (1 | donor.number)

gm1: Mycoplasma ~ type + (1 | donor.number)

         Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)

gm0  2 46.492 49.869 -21.246   42.492
gm1  3 44.901 49.968 -19.451   38.901 3.5905      1    0.05811 .


The F-value associated to  type, my only explanatory variable, is 3.124, as
anova(gm1) shows above

1. So which values should I take to calculate the P-value associated to the
variable type? 2 and 3 as shows  anova(gm1, gm0)
Is like that then?

1-pf(3.2124,2,3)

[1] 0.1795865

or

1-pf(3.2124,3,2)

[1] 0.246378


2.   anova(gm1, gm0) give a P-value associated of 0.058, since I have only
one explanatory variable, is not this value the defining the significance
of this variable (the ine that makes the difference between the 2 models)


3. What is in this case the F-value and df provided by anova(gm1)?



Srry, I am a little confused with the results. Thanks!


2018-05-24 11:55 GMT+03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Mario,
>
> Calculating the degrees of freedom of a mixed model is not straightforward.
>
> A workaround would be to use a likelihoodratio test between two nested
> models: one with and one without the variable. See the example below.
>
> library(lme4)
> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>               data = cbpp, family = binomial)
> anova(gm1)
> gm0 <- glmer(cbind(incidence, size - incidence) ~ (1 | herd),
>               data = cbpp, family = binomial)
> anova(gm1, gm0)
>
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-05-23 13:14 GMT+02:00 Mario Garrido <gaiarrido at gmail.com>:
>
>> Dear lme4-users,
>> I am trying to get the P-value associated with a glmer model from the
>> binomial family.
>> My model is the following:
>> glmer(Infection.status~origin+ (1|donationID), family=binomial)->q7H
>>
>> where Infection status is a dummy variable with two levels, infected and
>> uninfected
>> I tried to get the P-value associated to the the explanatory variable
>> origin
>> but I get only the F-value and the degrees of freedom
>>
>> (aov <- anova(q7H))
>> Analysis of Variance Table
>>          Df Sum Sq Mean Sq F value
>> origin   2 5.3061  2.6531  2.6531
>>
>> I have 2 different questions
>> 1. Am I doing correctly or am I using an incorrect command?
>>
>> 2. with the F-value I get and the df, should I go to test the significance
>> to a F or Chi-squared table? I guess I should go to the latest since I am
>> running a binomial test, right?
>> In case I have to go to an F table, how can I know the numerator and
>> denominator degrees of freedom?
>>
>> Thanks in advance
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From mew0099 @ending from @uburn@edu  Fri May 25 16:48:59 2018
From: mew0099 @ending from @uburn@edu (Matthew Wolak)
Date: Fri, 25 May 2018 14:48:59 +0000
Subject: [R-sig-ME] MCMCglmm models and (quasi-)complete separation
In-Reply-To: <CAD+CoDNBaLEC=F5Z5gMpWPBzkgiEwCM7Fxn7W9nhPrTQnHtj5g@mail.gmail.com>
References: <CAD+CoDMaqnOwCaENchc60HoW_M+xC3k4vk=axaB2c7zrGTFuFw@mail.gmail.com>
 <CAD+CoDMgKNRDBnj0kLjG2MiOKYKmQC1+ZpJNKTRCtOpb155EGg@mail.gmail.com>
 <4737E17E7C8C3C4A8B5C1CE5346371D4A84A9A39@EXCH06S.adqimr.ad.lan>,
 <CAD+CoDNBaLEC=F5Z5gMpWPBzkgiEwCM7Fxn7W9nhPrTQnHtj5g@mail.gmail.com>
Message-ID: <1527259739766.26392@auburn.edu>

Dear Jasmin,

Have you had a look at the MCMCglmm Course Notes (apologies if you have)? Specifically in Ch. 2 (specifically pp.52-57, of my Nov. 14, 2016 version, if you want to jump right into some of the relevant chunks). That at least gives an example and works through some of the issues you are dealing with. In particular, when Jarrod explains setting a better prior on the fixed effects, he drops the models global intercept, which might be pretty helpful in your case.

Just a couple (~5) additional thoughts inserted to your original email below. Hope this helps!

Sincerely,
Matthew
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jasmin Herden <jasmin.herden at gmail.com>
Sent: Friday, May 25, 2018 7:05 AM
To: r-sig-mixed-models at r-project.org; David.Duffy at qimrberghofer.edu.au
Subject: Re: [R-sig-ME] MCMCglmm models and (quasi-)complete separation

Dear David,

a)


*Dear Jasmin. I, at least, would need to see some kind of data to
understand your comments re separation etc.*
Here are the first few lines of the data set.


> head(dsetMailingList)       Site Field Species PlantID native.neophyte Treatment Seed_family Origin survival_to_harvest   Sp_Sf Field_Subplot
355 Potsdam    DB     Dat Dat10CK        neophyte       CON
E10      K                   1 Dat.E10        DB _ C
356 Potsdam    MQ     Dat Dat10CK        neophyte       CON
E10      K                   0 Dat.E10        MQ _ B
357 Potsdam    GR     Dat Dat10CK        neophyte       CON
E10      K                   1 Dat.E10        GR _ B
358 Potsdam    GR     Dat Dat10CP        neophyte       CON
10      P                   0  Dat.10        GR _ B
359 Potsdam    DB     Dat Dat10CP        neophyte       CON
10      P                   1  Dat.10        DB _ A
360 Potsdam    MQ     Dat Dat10CP        neophyte       CON
10      P                   1  Dat.10        MQ _ B


>

b) *Does a simpler model run eg dropping field_block and simplifying the
fixed effects? And does such a model run in lmer or other programs?*

I had originally started with a binomial glmer model, but in most species
this lead to ridiculously large standard errors. These large SE values are
indicative of quasi-complete separation (i.e. nearly complete 0 or 1 for
one factor level). (See also the following link:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004172.html).

I have tried using blglmer as suggested by Ben Bolker in the example
referenced in my first post to the mailing list. In principle, all models
with complete separation looked good with bglmer.
However, my intended approach in glmer was to take the full model and get
likelihood ratio tests and corresponding p-values for the fixed effects by
step-wise model
reduction. Theoretically, this is also possible with bglmer, but Ben Bolker
advised against using bglmer for more than just an overall model check in
several posts. Furthermore, I am not quite sure if or how I need to adjust
the priors in bglmer during step-wise model reduction or if step-wise model
reduction is appropiate for bglmer at all. Ben Bolker recommended using the
MCMCglmm package instead of bglmer for a proper analysis.

Due to my approach of testing all fixed effects (Site, Origin, and
Treatment, and interactions) in my local adaptation study, reducing the
fixed effects is not really an option.

Kind regards,
Jasmin Herden




On Fri, May 25, 2018 at 8:58 AM, David Duffy <David.Duffy at qimrberghofer.
edu.au> wrote:

>  Does a simpler model run eg dropping field_block and simplifying the
> fixed effects? And does such a model run in lmer or other programs?
> Diagnosing a nonidentified model (ie some parameters in your model may not
> be estimable given your pattern of observations) in MCMC is hard.
> ________________________________________
> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> behalf of Jasmin Herden [jasmin.herden at gmail.com]
> Sent: Thursday, 24 May 2018 10:16 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm models and (quasi-)complete separation
>
> Dear fellow R users,
>
> I have recently started using the MCMCglmm R package to analyse some of my
> problematic
> data which severely suffers from (quasi)complete separation.
>
> I have followed Ben Bolker's suggestions of zero-mean Normal priors on the
> fixed effects to analyse such kinds of data.
> (https://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html)
>
> My model is:
>
> k<-8 #number of the fixed effects
>      #Intercept+single effects+interactions
>

####  <<INSERT>>  ####
# So if you removed the global intercept, k<-7

> prior.c <- list(B=list(V=diag(9,k), mu=rep(0,k)),
>                 R=list(V=1,fix=1),
>                 G=list(G1=list(V=1, nu=1,alpha.mu=0, alpha.V=1000),
>                        G2=list(V=1,nu=1,alpha.mu=0, alpha.V=1000),
>                        G3=list(V=1,nu=1,alpha.mu=0, alpha.V=1000)))
>
> nsamp <- 10000
> THIN <- 900
> BURNIN <- 10000
> NITT <- BURNIN + THIN*nsamp


####  <<INSERT>>  ####
# You may want to consider a larger thinning interval (and for trial runs of the model, nsamp~1000 will suffice)
## I can't tell you an exact number, but it could be THIN <- 5000 or 10000
# These specifications also partly depend on the size of your dataset and the number of levels of fixed
## and random effects and the distribution of 0s/1s across these; which we cannot get from `head()`




> model3 = MCMCglmm(survival~
>                     Site*b*c,
>                   random=~x+Field+Field_block,
>                   data=dset,
>                     slice=TRUE,
>                     pl=T,
>                     prior=prior.c,
>                     family="categorical",verbose=FALSE,
>                     nitt=NITT,burnin=BURNIN,thin=THIN)
>
> Survival is a binary value of 0 or 1 and is observed only once per
> experimental plant.
> Therefore the observation-level variance R is fixed to 1. (As in the linked
> example.)
>
> Site, b, and c are two-level categorical variables. x is crossed with Field
> and Field_block, but Field_block is nested within Field.
>
> Models are run for each species separately.
>
> My questions are:
>
> a) Many worked examples which I based my own analysis on use the
> Gelman-Rubin
> criterion where you check the convergence of your model by running it a
> number of times and then compare models.
>
> However, I think the MCMCglmm vignette said to start the model running with
> overdispersed priors which is definitely not an option for me with the kind
> of data I have.
>
> I have tried using the testing for the Gelman-Rubin criterion nonetheless,
> but the Gelman diagnostic plots do not show a oscillating line that finally
> converges on a value but
> rather clines and straigt lines.


####  <<INSERT>>  ####
# I'm not sure to what part of the MCMCglmm vignette you are referring, but to use this
## Approach with multiple models, you will need to specify starting values.
## Otherwise, each model might proceed along the same chain (if I'm not mistaken) and you just get
## n of the same model/posterior
# To specify starting values:

# I can't remember if it is necessary, but it would be good to set the random seed for each model
m <- 1  #<-- model=1
set.seed(101+m)
#XXX Make sure matches prior in structure
# nfx <- number of liabilities
startN <- list(liab = rnorm(nfx, 0, 12),   # Need to specify the liabilities  
        B = list(V=diag(20,k), mu=rep(0,k)),
	R = list(R1 = rIW(diag(1), 15, fix = 1)), # where I have 15, tailor to the values you are getting
	G = list(G1 = rIW(diag(1), 15),
		G2 = rIW(diag(1), 15),
		G3 = rIW(diag(1), 15)))
# Then in MCMCglmm()
## MCMCglmm(...., start = startN)




>
> b) I am also not quite sure, if the value R is fixed at is appropiate for
> all models I run. For some
> models, I still get latent variable values bigger than 20, even at very
> high numbers of iterations.
>


####  <<INSERT>>  ####
# fixing R=1 is fairly standard for family="categorical".



> c) How do you decide to use family="categorical" (=logit link) or "ordinal"
> (=probit link)?
> Based on the DIC of the models?
>
> d) For many of my models, the explained variance for the random effects
> Field and Field_block are very high; sometimes reaching an upper estimate
> of 99%.
> I think the problem is that Field_block is not only nested in Field but
> that Field is also
> nested in the categorical fixed effect Site.
> Is my model overparametrized with regard to Field, since I have nearly
> complete survival in one of the two levels of Site?

####  <<INSERT>>  ####
# You might need to make sure the model you specify is converging OK, before
## deciding about your model specification based on the parameters it has estimated



>
> Kind regards,
> Jasmin
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Fri May 25 20:45:58 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 25 May 2018 14:45:58 -0400
Subject: [R-sig-ME] 
 P-value associated to explanatory from glmer binomial family
In-Reply-To: <CABi7Y8ZEYuik7GoHkOgvde90Hrt9X1Gpzd68wHBDpHdz=jgnaw@mail.gmail.com>
References: <CABi7Y8b0+p1knXtoOra5oH5X352oT4GH6LLMnzr=Oq6226GOLg@mail.gmail.com>
 <CAJuCY5w0MkdWAtAaj1_8VMJDvqFZYNXBnCT5OtmXsL0Lwaf+Yg@mail.gmail.com>
 <CABi7Y8ZEYuik7GoHkOgvde90Hrt9X1Gpzd68wHBDpHdz=jgnaw@mail.gmail.com>
Message-ID: <CABghstSUyHXPgDKWS1v2PVNBQp=gbRU=pOeZn+yBz1WN38GBGw@mail.gmail.com>

 What Thierry is explaining is that F tests don't really work for
GLM(M)s. (F tests are based on the uncertainty of the estimate of the
residual variance; typical (binomial & Poisson) GLMs don't estimate a
residual variance at all. There is a theory of "Bartlett corrections",
which are finite-size corrections for GLMs, but they're not widely
used.)

1. pf(Fstat,df,lower.tail=FALSE)  (equivalent to your 1-pf(...)
calculation, but more accurate for small p-values) would be reasonable
*if* the "F statistic" presented by anova() were actually
F-distributed with a known df, but as Thierry said, it's not. The "2"
and "3" given by anova() are the *model* ("numerator") degrees of
freedom, not the *residual* (denominator) df, which are unknown/hard
to compute.

2. 0.058 is indeed the p-value associated with the 'type' variable,
since that's the only difference between the models

3. The df doesn't really exist here.  I *think* you can get to the
equivalent F statistic reported in the anova() from the information
given here, but I'd have to think about it for 5 minutes ... but since
you're not going to run an F test anyway, it doesn't matter too much
...

On Fri, May 25, 2018 at 4:13 AM, Mario Garrido <gaiarrido at gmail.com> wrote:
>  Dear Thierry,
> thanks so much for the clarification. After I run the LRT I get those
> results
>
> gm1 <- glmer(Mycoplasma~ type+ (1|donor.number), family=binomial)
>
> anova(gm1)
>
> Analysis of Variance Table
>
>      Df Sum Sq Mean Sq F value
>
> type  1 3.2124  3.2124  3.2124
>
> gm0<-  glmer(Mycoplasma~ 1+ (1|donor.number), family=binomial)
>
> anova(gm1, gm0)
>
> Data: NULL
>
> Models:
>
> gm0: Mycoplasma ~ 1 + (1 | donor.number)
>
> gm1: Mycoplasma ~ type + (1 | donor.number)
>
>          Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>
> gm0  2 46.492 49.869 -21.246   42.492
> gm1  3 44.901 49.968 -19.451   38.901 3.5905      1    0.05811 .
>
>
> The F-value associated to  type, my only explanatory variable, is 3.124, as
> anova(gm1) shows above
>
> 1. So which values should I take to calculate the P-value associated to the
> variable type? 2 and 3 as shows  anova(gm1, gm0)
> Is like that then?
>
> 1-pf(3.2124,2,3)
>
> [1] 0.1795865
>
> or
>
> 1-pf(3.2124,3,2)
>
> [1] 0.246378
>
>
> 2.   anova(gm1, gm0) give a P-value associated of 0.058, since I have only
> one explanatory variable, is not this value the defining the significance
> of this variable (the ine that makes the difference between the 2 models)
>
>
> 3. What is in this case the F-value and df provided by anova(gm1)?
>
>
>
> Srry, I am a little confused with the results. Thanks!
>
>
> 2018-05-24 11:55 GMT+03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Mario,
>>
>> Calculating the degrees of freedom of a mixed model is not straightforward.
>>
>> A workaround would be to use a likelihoodratio test between two nested
>> models: one with and one without the variable. See the example below.
>>
>> library(lme4)
>> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>               data = cbpp, family = binomial)
>> anova(gm1)
>> gm0 <- glmer(cbind(incidence, size - incidence) ~ (1 | herd),
>>               data = cbpp, family = binomial)
>> anova(gm1, gm0)
>>
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-05-23 13:14 GMT+02:00 Mario Garrido <gaiarrido at gmail.com>:
>>
>>> Dear lme4-users,
>>> I am trying to get the P-value associated with a glmer model from the
>>> binomial family.
>>> My model is the following:
>>> glmer(Infection.status~origin+ (1|donationID), family=binomial)->q7H
>>>
>>> where Infection status is a dummy variable with two levels, infected and
>>> uninfected
>>> I tried to get the P-value associated to the the explanatory variable
>>> origin
>>> but I get only the F-value and the degrees of freedom
>>>
>>> (aov <- anova(q7H))
>>> Analysis of Variance Table
>>>          Df Sum Sq Mean Sq F value
>>> origin   2 5.3061  2.6531  2.6531
>>>
>>> I have 2 different questions
>>> 1. Am I doing correctly or am I using an incorrect command?
>>>
>>> 2. with the F-value I get and the df, should I go to test the significance
>>> to a F or Chi-squared table? I guess I should go to the latest since I am
>>> running a binomial test, right?
>>> In case I have to go to an F table, how can I know the numerator and
>>> denominator degrees of freedom?
>>>
>>> Thanks in advance
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cri@@le@@@ndro @ending from gm@il@com  Fri May 25 22:49:41 2018
From: cri@@le@@@ndro @ending from gm@il@com (Cristiano Alessandro)
Date: Fri, 25 May 2018 15:49:41 -0500
Subject: [R-sig-ME] partially crossed design, longitudinal
Message-ID: <CAHhX7WhUfruv2moMcFYHiMjdUXRKmkNbx8tDHsz5uPEZ2-HeOA@mail.gmail.com>

Hi all,

I have a longitudinal study in which I measure the outcome variables at
baseline condition (bas), then I apply a perturbation (pert) and I measure
the outcome variable twice (early and late after perturbation is applied),
and then I remove the perturbation (noPert) and I measure twice (early and
late after perturbation is applied).

I would like to use mixed models for this design, but I am a bit confused
on how to do it. I could just have a single fixed effects 'time' with
levels 1 to 5, where level 1 would be baseline, level 2 would be pert/early
and so on. I think this is not the best design though. Alternatively, I
could use a fixed effects 'condition' with levels bas, pert, noPert,
crossed with another fixed effect 'time' with levels early/late. However,
this last design has the problem that I do not have early/late for baseline
actually.

Do you have suggestion of what to do in a case like this?

Thanks a lot
Cristiano

	[[alternative HTML version deleted]]


From jchrpi @ending from gm@il@com  Sat May 26 13:42:54 2018
From: jchrpi @ending from gm@il@com (Julien Piquet)
Date: Sat, 26 May 2018 12:42:54 +0100
Subject: [R-sig-ME] Multivariate MCMCglmm with binary and gaussian dependent
 variables
Message-ID: <CAL2vFCsUSUE4BfnXcQnD7GvMG3SzxGLcCGYQ0GRU9aNPE=nBSQ@mail.gmail.com>

Dear MCMglmm,

I just saw a post from 2015 in which a user tried to fit a bivariate
MCMCglmm with one dependent variable from Gaussian family and another one
that wwas binary, so perhaps my question has already been treated but I
couldn't find what I was looking for. Right now, I am trying to run a
multivariate MCMCglmm in which some dependent variables are gaussian and
others are binary, which is exactly the same to the previous so far.
However, in my case I have five variables instead of two (4 Gaussian and
one binary). The thing is that I am not quite an expert in Bayesian
statistics so, right now I've been struggling to find a way to code a
prior for such model. Recently I found an inverse-gamma prior
(prior2=list(R=list(V=diag(5),nu=4.002),G=list(G1=list(V=diag(5),nu=4.002)))
could work (the model ran), but I am not sure whether it is correct to use
it or not. Therefore, I would be really grateful if anyone could help to
know which prior/s I should use for this model. I say priors because
perhaps there are several options and thus model robustness to prior
selection can be assessed. Thank you in advance.

Julien C. Piquet
PhD student - GEEI
Instituto de Productos Naturales y Agrobiolog?a (IPNA-CSIC)
38206 San Crist?bal de La Laguna - SPAIN

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Sat May 26 15:59:22 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Sat, 26 May 2018 15:59:22 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAG_uk925yU88bmdfheifETi8X-yBuV=TUQeL_SgWpidp7NBcew@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
 <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
 <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>
 <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>
 <CAG+WrEwpGxDbN6Gif2TiP80XZZZPqeNgwoFZEuuvVSGp808YxA@mail.gmail.com>
 <CAG_uk925yU88bmdfheifETi8X-yBuV=TUQeL_SgWpidp7NBcew@mail.gmail.com>
Message-ID: <CAHr4DycKsPqy4c+w6S4pHkhkyt8U4jt1OMZngB13waZPBg9t8w@mail.gmail.com>

Rune,

Your explanations make sense to me but I don't know how to connect
them to the things I know, or thought I knew, about mixed models (see
(1) and (2)).
Let me just double-check if I get it right:

fm5 <- lmer(score ~  Machine + (1|Worker) + (1|Worker:Machine), Machines)

would imply that covariance between two different observations from
the same Machine and same Worker is sigma_w^2 + sigma_wm^2 and the
covariance between two different observations from different Machines
but the same Worker is sigma_w^2. Do I have this right?

(1) In the mixed model books I read random effects (RE) are introduces
as zero-centered offsets (following a normal distribution) around the
fixed effects. However, this doesn't seem to be the case for the
models you suggest, i.e. the factor Machine is coded with
contr.treatment by default but you use 0 + Machine or 0 + A + B + C in
the random effects part. What am I missing here?

(2) From the "RE as zero-centered offsets around the fixed
effects"-perspective the models suggest by Reinhold Kliegl do makes
sense to me. But from the "variance-covariance matrix in the marginal
distribution"-perspective I have a hard time understanding what they
represent.
E.g. consider zcp_LMM:
mm1 <- model.matrix(~ 1 + Machine, Machines)
dBA <- mm1[, 2]
dCA <- mm1[, 3]
zcp_LMM <- lmer(score ~  Machine + (1 + dBA + dCA || Worker), Machines)

If I get it right the covariance between two different observations
from different Machines but the same Worker is sigma_w^2 here. But
what about the covariance between two different observations from the
same Machine and same Worker? Is it sigma_w^2 + sigma_j^2 where
sigma_j^2 refers to the j'th contrasts, i.e. it would be different for
dBA (the difference between Machine B and A) and dCA (the difference
between Machine C and A? If this is true is there a useful way to
interpret these models?

Cheers,
Maarten

On Fri, May 25, 2018 at 10:27 AM, Rune Haubo <rune.haubo at gmail.com> wrote:
>
> On 24 May 2018 at 21:22, Reinhold Kliegl <reinhold.kliegl at gmail.com> wrote:
> > Here is an update (final for now) with 10 models and 4 hierarchical
> > sequences. Comments, details, and a demonstration with the Machines data are
> > available in a new RPub[1]. I switched to a notation with numeric covariates
> > to reduce potential confusion about terms containing `1+f` and `0+f`; `c1`
> > and `c2` are contrasts defined for a factor with levels `A`, `B`, and `C`.
> >
> > ## LMMs
> >
> > ### Prototype LMMs
> >
> > max_LMM:   m1 = y ~ 1 + c1 + c2 + (1 + c1 + c2 | subj)
> > prsm1_LMM: m2 = y ~ 1 + c1 + c2 + (1 | subj) + (0 + c1 + c2 | subj)
> > zcp_LMM:   m3 = y ~ 1 + c1 + c2 + (1 + c1 + c2 || subj)
> > prsm2_LMM: m4 = y ~ 1 + c1 + c2 + (1 + c2 || subj)
> > min_LMM:   m5 = y ~ 1 + c1 + c2 + (1 | subj)
> >
> > Protoype refers to prsm1 and prsm2; there are also variations of them. Prsm1
> > are models pruning correlation parameters; prsm2 are models pruning variance
> > components in the absence of correlation parameters. The order reflects
> > hierarchical decreasing model complexity.
> >
> > ### LMMs with interaction term
> >
> > int_LMM:   m6 = y ~ 1 + c1 + c2 + (1 | subj) + (1 | factor:subj)
> > min2_Lmm:  m7 = y ~ 1 + c1 + c2 + (1 | factor:subj)
> >
> > ### LMMs with (0 + f | g) RE structures
> >
> > maxL_MM_RE0:   m8 = y ~ 1 + c1 + c2 + (0 + A + B + C | subj)
> > prsm1_LMM_RE0: m9 = y ~ 1 + c1 + c2 + (0 + A | subj) + (0 + B + C | subj)
> > zcp_LMM_RE0:  m10 = y ~ 1 + c1 + c2 + (0 + A + B + C || subj)
> >
> > ## Hierarchical model sequences
> >
> > Here are the sequences I am confident about.
> >
> > (1) max_LMM -> prsm1_LMM -> zcp_LMM -> prsm2_LMM -> min1_LMM
> > (2) max_LMM -> int_LMM -> min1_LMM
> > (3) max_LMM -> int_LMM -> min2_LMM
> > (4) max_LMM_RE0 -> prsm1_LMM_RE0 -> zcp_LMM_RE0
> >
> > So far, in my research, I have worked almost exclusively with Sequence (1)
> > and do not recall ever experiencing technical problems or inconsistencies as
> > long as there was no overparameterization. It has served me well in the
> > determination of parsimonious LMMs[2, 3].
> >
> > For complex fixed-effect structures (i.e., for models with many factors or
> > with factors with many levels), the number of correlation parameters grows
> > very rapidly. If this goes together with a modest number of observations or
> > levels of the random factor, Sequences (2) and (3) might be a good place to
> > start to avoid convergence problems. Of course, if your hypotheses are about
> > correlation parameters, these LMMs will not get you very far.
> >
> > Finally, Sequence (4) could be a default strategy if one is interested in
> > the fixed effects and if one does not want to spend much time in wondering
> > about the meaning of CPs. However, as correlations between levels of fixed
> > factors are can be very large (at least larger than correlations between
> > effects), LMMs in this sequence may be prone to convergence problems.
> >
> > A few open questions -
> > (1) Rune Haubo proposed that min2_LMM (his fm2) is nested under zcp_LMM_RE0
> > (his fm3) and could serve as a baseline model, but I don't understand why it
> > is nested.
> > (2) Marteen Jung wonders about Rune Haubo's fm5 (with four VCs; there was
> > typo in my last post). The ten models above have at most 3 VCs (i.e., the
> > number of levels of the factor). I also don't see a good place for it in the
> > sequences. Am I missing something?
> > (3) Any suggestions for models between maxLMM and intLMM and for models
> > between intLMM and minLMM?
>
> I must admit that I haven't read all of the above in detail but I can
> address the
> specific questions.
>
> First a note on terminology: My understanding is that a variance component (VC)
> is an random-effects term that is independent of other terms and
> classically a term of the form
> (1 | g) or (1 | g:f). If we also allow the VC-terminology for random terms with
> vector-valued random-effects, e.g. (g | f), then arguably none of the models
> have more than two VCs (excluding residuals).
>
> For the Machines data fm5 reads
> fm5 <- lmer(score ~  Machine + (1 | Worker) +
>               (0 + dummy(Machine, "A") | Worker) +
>               (0 + dummy(Machine, "B") | Worker) +
>               (0 + dummy(Machine, "C") | Worker), Machines)
>
> which may also be specified as (thanks Reinhold Kliegl)
>
> mm0 <- model.matrix(~ 0 + Machine, Machines)
> A <- mm0[, 1]
> B <- mm0[, 2]
> C <- mm0[, 3]
> fm5b <- lmer(score ~  Machine + (1 | Worker) + (0 + A + B + C ||
> Worker), Machines)
> anova(fm5, fm5b, refit=FALSE) # Chisq = 0
> and there other variants as well.
>
> Other relevant models to be discussed are:
> fm3 <- lmer(score ~  Machine + (0 + A + B + C || Worker), Machines)
> fm2 <- lmer(score ~  Machine + (1| Worker:Machine), Machines)
> fm6 <- lmer(score ~  Machine + (0 + Machine | Worker), Machines)
>
> Since observations on different Workers are independent we can understand these
> models by considering how they parameterize the variance-covariance
> matrix of the
> 9 observations that belong to each Worker in the marginal distribution
> of the observations.
>
> fm5, uses 5 variance-parameters to parameterize the by-Worker
> (9x9) variance-covariance matrix, Cov(Y_j): 1 for (1 | Worker), 3 for
> (0 + A + B + C || Worker) and 1 for the residual variance.
>
> The covariance structure for within-Worker observations is:
> - The variance of each observation is sigma_w^2 + sigma_i^2 + sigma^2 where
> the terms refer to Worker, the i'th Machine and residuals.
> - The covariance between two different obervations from the same Machine and
> Worker is sigma_w^2 + sigma_i^2, i.e. it depends on which Machine was used.
> - The covariance between two different observations on the same Worker but
> different Machines is just sigma_w^2.
>
> Thus, if (1 | Worker) is removed from fm5 it reduces to fm3 and it amounts to
> setting sigma_w^2 to zero. In effect the covariance betwen two different
> observations on the same Worker but different Machines is 0.
>
> If instead we consider model fm6 which corresponds to exchanging all random
> terms in fm5 with (0 + Machine | Worker) it changes the covariance of two
> observations from the same Worker and different Machines from a constant
> sigma_w^2 to sigma_{i,i'}^2, i.e., it depends on which pair of Machines the
> two observations come from. Since there are 6 possible pairs of Machines fm6
> uses 6+1 variance parameters to parameterize the Worker-level covariance matrix,
> i.e. 2 more than fm5.
>
> For the Machines data fm2 reads
> fm2 <- lmer(score ~  Machine + (1 | Worker:Machine), Machines)
>
> This model says that the covariance between two different observations
> on the same
> Worker and same Machine is sigma_{mw}^2 thus it is different from fm3 by setting
> sigma_i^2 to the constant (wrt. Machine) sigma_{mw}^2. With 3 Machines fm2
> saves 2 variance-parameters relative to fm3 and ends up using only 2 variance
> parameters. For completeness, the variance of an observation is
> sigma_{mw}^2 + sigma^2
> and the covariance of any two observations which are not from the same
> Worker and the
> same Machine is 0.
>
> Now, I skipped a number of details but an email is not exactly suited for a
> mathematical exposition so I hope the above makes sense, and I hope it
> helps explain the nesting structure.
>
> Cheers
> Rune
>
> >
> > Best
> > Reinhold Kliegl
> >
> > [1] http://rpubs.com/Reinhold/391828
> > [2] https://arxiv.org/abs/1506.04967
> > [3] https://www.sciencedirect.com/science/article/pii/S0749596X17300013
> >
> >
> >
> > On Tue, May 22, 2018 at 1:17 PM, Reinhold Kliegl <reinhold.kliegl at gmail.com>
> > wrote:
> >>
> >> There is an interpretable alternative to fm5 (actually there are many
> >> ...), called fm8 below, that avoids the redundancy between variance
> >> components.  The change is to switch from (1 |g) + (0 + f | g) = (1 | g) +
> >> (0 + A + B + C | g) to 1 | g) + (0 + c1 + c2 |g ), where c1 and c2 are the
> >> contrasts defined for f. (I have actually used such LMMs quite often.) With
> >> this specification the difference to the maxLMM (fm6) is that the
> >> correlation between intercept and contrasts is suppressed to zero. The
> >> correlation parameters now refer to the correlations between effects of c1
> >> and c2, not to the correlations between A, B, and C.  Actually, this is but
> >> one example of many LMMs one could slot into this position of the
> >> hierarchical model sequences. At this level of model complexity one can
> >> suppress various subsets of correlation parameters (as illustrated in Bates
> >> et al. (2015)[1] and various vignettes of the RePsychLing package).
> >>
> >>
> >>  fm1 = y ~ 1 + f + (1 | g)                     # minimal LMM version 1
> >> (min1LMM)
> >>  fm2 = y ~ 1 + f + (1 | f:g)                   # minimal LMM version 2
> >> (min2LMM)
> >>  fm3 = y ~ 1 + f + (0 + f || g)                # zcpLMM with 0 in RE
> >> (zcpLMM_RE0)
> >>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)         # LMM w/ f x g interaction
> >> (intLMM)
> >>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g)       # N/A
> >>  fm6 = y ~ 1 + f + (1 + f |  g)                # maximal LMM (maxLMM)
> >>  fm7 = y ~ 1 + f + (1 + f || g)                # zcpLMM with 1 in RE
> >> (zcpLMM_RE1)
> >>  fm8 = y ~ 1 + f + (1 | g) + (0 + c1 + c2 | g) # parsimonious LMM
> >> (prsmLMM)
> >>
> >> Hierarchical model sequences
> >>
> >> (1) maxLMM_RE1 -> prsmLMM -> intLMM     -> min1LMM  # fm6 -> fm8 -> fm4 ->
> >> fm1
> >> (2) maxLMM_RE1 -> prsmLMM -> intLMM     -> min2LMM  # fm6 -> fm8 -> fm4 ->
> >> fm2
> >> (3) maxLMM_RE0 -> prsmLMM -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm8 -> fm3 ->
> >> fm2
> >> (4) maxLMM_RE1 -> prsmLMM -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm8 -> fm7 ->
> >> fm1  (new sequence)
> >> ```
> >>
> >> I will update the RPub in the next days.
> >>
> >> [1] https://arxiv.org/pdf/1506.04967.pdf
> >>
> >>
> >> Best regards,
> >> Reinhold Kliegl
> >>
> >> On Tue, May 22, 2018 at 11:00 AM, Maarten Jung
> >> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> >>>
> >>> I see that fm2 is nested within fm3 and fm4.
> >>> But I have a hard time understanding fm3 and fm2 because, as Reinhold
> >>> Kiegl said, they specify the f:g interaction but without the g main effect.
> >>> Can someone provide an intuition for these models?
> >>>
> >>> Also, it is not entirely clear to me what fm5 represents. It looks to me,
> >>> and again I am with Reinhold Kiegl , as if there were over-parameterization
> >>> going on.
> >>>
> >>> Cheers,
> >>> Maarten
> >>>
> >>> On Tue, May 22, 2018 at 9:45 AM, Reinhold Kliegl
> >>> <reinhold.kliegl at gmail.com> wrote:
> >>>>
> >>>> Ok, I figured out the answer to the question about fm2.
> >>>>
> >>>> fm2 is indeed a very nice baseline for fm3 and fm4. So I distinguish
> >>>> between min1LMM and min2LMM.
> >>>>
> >>>>  fm1 = y ~ 1 + f + (1 | g)               # minimal LMM version 1
> >>>> (min1LMM)
> >>>>  fm2 = y ~ 1 + f + (1 | f:g)             # minimal LMM version 2
> >>>> (min2LMM)
> >>>>  fm3 = y ~ 1 + f + (0 + f || g)          # zcpLMM with 0 in RE
> >>>> (zcpLMM_RE0)
> >>>>  fm4 = y ~ 1 + f + (1 | g) + (1 | f:g)   # LMM w/ f x g interaction
> >>>> (intLMM)
> >>>>  fm5 = y ~ 1 + f + (1 | g) + (0 + f | g) # N/A
> >>>>  fm6 = y ~ 1 + f + (1 + f |  g)          # maximal LMM (maxLMM)
> >>>>  fm7 = y ~ 1 + f + (1 + f || g)          # zcpLMM with 1 in RE
> >>>> (zcpLMM_RE1)
> >>>>
> >>>>
> >>>> (1) maxLMM_RE1 -> intLMM     -> min1LMM  # fm6 -> fm4 -> fm1
> >>>> (2) maxLMM_RE1 -> intLMM     -> min2LMM  # fm6 -> fm4 -> fm2
> >>>> (3) maxLMM_RE0 -> zcpLMM_RE0 -> min2LMM  # fm6 -> fm3 -> fm2
> >>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> min1LMM  # fm6 -> fm7 -> fm1  (new
> >>>> sequence)
> >>>>
> >>>>
> >>>> On Tue, May 22, 2018 at 12:21 AM, Reinhold Kliegl
> >>>> <reinhold.kliegl at gmail.com> wrote:
> >>>>>
> >>>>> Sorry, I am somewhat late to this conversation. I am responding to this
> >>>>> thread, because it fits my comment very well, but it was initially triggered
> >>>>> by a previous thread, especially Rune Haubo's post here [1]. So I hope it is
> >>>>> ok to continue here.
> >>>>>
> >>>>> I have a few comments and questions. For details I refer to an RPub I
> >>>>> put up along with this post [2]. I start with a translation between Rune
> >>>>> Haubo's fm's and the terminology I use in the RPub:
> >>>>>
> >>>>>  fm1 = y ~ 1 + f + (1 | g)            # minimal LMM (minLMM)
> >>>>>  fm3 = y ~ 1 + f + (0 + f || g)       # zero-corr param LMM with 0 in
> >>>>> RE (zcpLMM_RE0)
> >>>>>  fm4 = y ~ 1 + f + (1 | g) + (1|f:g)  # LMM w/ fixed x random factor
> >>>>> interaction (intLMM),
> >>>>>  fm6 = y ~ 1 + f + (1 + f |  g)       # maximal LMM (maxLMM)
> >>>>>  fm7 = y ~ 1 + f + (1 + f || g)       # zero-corr param LMM with 1 in
> >>>>> RE (zcpLMM_RE1)
> >>>>>
> >>>>> Notes: f is a fixed factor, g is a group (random) factor; fm1 to fm6
> >>>>> are in Rune Haubo's post; fm7 is new (added by me). I have not used fm2 and
> >>>>> fm5 so far (see below).
> >>>>>
> >>>>> (I) The post was triggered by the question whether intLMM is nested
> >>>>> under zcpLMM. I had included this LRT in my older RPub cited in the thread,
> >>>>> but I stand corrected and agree with Rune Haubo that intLMM is not nested
> >>>>> under zcpLMM. For example, in the new RPub, I show that slightly modified
> >>>>> Machines data exhibit smaller deviance for intLMM than zcpLMM despite an
> >>>>> additional model parameter in the latter. Thanks for the critical reading.
> >>>>>
> >>>>>
> >>>>> (II) Here are Runo Haubo's sequences (left, resorted) augmented with my
> >>>>> translation (right)
> >>>>>
> >>>>> (1) fm6 -> fm5 -> fm4 -> fm1  # maxLMM_RE1 -> fm5 -> intLMM     ->
> >>>>> minLMM
> >>>>> (2) fm6 -> fm5 -> fm4 -> fm2  # maxLMM_RE1 -> fm5 -> intLMM     -> fm2
> >>>>> (3) fm6 -> fm5 -> fm3 -> fm2  # maxLMM_RE1 -> fm5 -> zcpLMM_RE0 -> fm2
> >>>>>
> >>>>> and here are sequences I came up with (left) augmented with translation
> >>>>> into RH's fm's.
> >>>>>
> >>>>> (1) maxLMM_RE1 -> intLMM     -> minLMM  # fm6 -> fm4 -> fm1
> >>>>> (3) maxLMM_RE0 -> zcpLMM_RE0            # fm6 -> fm3
> >>>>> (4) maxLMM_RE1 -> zcpLMM_RE1 -> minLMM  # fm6 -> fm7 -> fm1  (new
> >>>>> sequence)
> >>>>>
> >>>>>
> >>>>> (III) I have questions about fm2 and fm5.
> >>>>>    fm2: fm2 redefines the levels of the group factor (e.g., in the cake
> >>>>> data there are 45 groups in fm2 compared to 15 in the other models). Why is
> >>>>> fm2 nested under fm3 and fm6? Somehow it looks to me that you include an f:g
> >>>>> interaction without the g main effect (relative to fm4). This looks like an
> >>>>> interesting model; I would appreciate a bit more conceptual support for its
> >>>>> interpretation in the model hierarchy.
> >>>>>    fm5: fm5 specifies 4 variance components (VCs), but the factor has
> >>>>> only 3 levels. So to me this looks like there is redundancy built into the
> >>>>> model. In support of this intuition, for the cake data, one of the VCs is
> >>>>> estimated with 0. However, in the Machine data the model was not degenerate.
> >>>>> So I am not sure. In other words, if the factor levels are A, B, C, and the
> >>>>> two contrasts are c1 and c2, I thought I can specify either (1 + c1 + c2) or
> >>>>> (0 + A + B + C). fm5 specifies (1 + A + B + C) which is rank deficient in
> >>>>> the fixed effect part, but not necessarily in the random-effect term. What
> >>>>> am I missing here?
> >>>>>
> >>>>> [1]
> >>>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
> >>>>> [2] http://rpubs.com/Reinhold/391027
> >>>>>
> >>>>> Best,
> >>>>> Reinhold Kliegl
> >>>>>
> >>>>>
> >>>>> On Thu, May 17, 2018 at 12:43 PM, Maarten Jung
> >>>>> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> >>>>> >
> >>>>> > Dear list,
> >>>>> >
> >>>>> > When one wants to specify a lmer model including variance components
> >>>>> > but no
> >>>>> > correlation parameters for categorical predictors (factors) afaik one
> >>>>> > has
> >>>>> > to convert the factors to numeric covariates or use lme4::dummy().
> >>>>> > Until
> >>>>> > recently I thought m2a (or equivalently m2b using the double-bar
> >>>>> > syntax)
> >>>>> > would be the correct way to specify such a zero-correlation parameter
> >>>>> > model.
> >>>>> >
> >>>>> > But in this thread [1] Rune Haubo Bojesen Christensen pointed out
> >>>>> > that this
> >>>>> > model does not make sense to him. Instead he suggests m3 as an
> >>>>> > appropriate
> >>>>> > model.
> >>>>> > I think this is a *highly relevant difference* for everyone who uses
> >>>>> > factors in lmer and therefore I'm bringing up this issue again. But
> >>>>> > maybe
> >>>>> > I'm mistaken and just don't get what is quite obvious for more
> >>>>> > experienced
> >>>>> > mixed modelers.
> >>>>> > Please note that the question is on CrossValidated [2] but some
> >>>>> > consider it
> >>>>> > as off-topic and I don't think there will be an answer any time soon.
> >>>>> >
> >>>>> > So here are my questions:
> >>>>> > How should one specify a lmm without correlation parameters for
> >>>>> > factors and
> >>>>> > what are the differences between m2a and m3?
> >>>>> > Is there a preferred model for model comparison with m4 (this model
> >>>>> > is also
> >>>>> > discussed here [3])?
> >>>>> >
> >>>>> > library("lme4")
> >>>>> > data("Machines", package = "MEMSS")
> >>>>> >
> >>>>> > d <- Machines
> >>>>> > contrasts(d$Machine)  # default coding: contr.sum
> >>>>> >
> >>>>> > m1 <- lmer(score ~ Machine + (Machine | Worker), d)
> >>>>> >
> >>>>> > c1 <- model.matrix(m1)[, 2]
> >>>>> > c2 <- model.matrix(m1)[, 3]
> >>>>> > m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + c1 | Worker) + (0 +
> >>>>> > c2 |
> >>>>> > Worker), d)
> >>>>> > m2b <- lmer(score ~ Machine + (c1 + c2 || Worker), d)
> >>>>> > VarCorr(m2a)
> >>>>> >  Groups   Name        Std.Dev.
> >>>>> >  Worker   (Intercept) 5.24354
> >>>>> >  Worker.1 c1          2.58446
> >>>>> >  Worker.2 c2          3.71504
> >>>>> >  Residual             0.96256
> >>>>> >
> >>>>> > m3 <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A")
> >>>>> > |
> >>>>> > Worker) +
> >>>>> >                                             (0 + dummy(Machine, "B")
> >>>>> > |
> >>>>> > Worker) +
> >>>>> >                                             (0 + dummy(Machine, "C")
> >>>>> > |
> >>>>> > Worker), d)
> >>>>> > VarCorr(m3)
> >>>>> >  Groups   Name                Std.Dev.
> >>>>> >  Worker   (Intercept)         3.78595
> >>>>> >  Worker.1 dummy(Machine, "A") 1.94032
> >>>>> >  Worker.2 dummy(Machine, "B") 5.87402
> >>>>> >  Worker.3 dummy(Machine, "C") 2.84547
> >>>>> >  Residual                     0.96158
> >>>>> >
> >>>>> > m4 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)
> >>>>> >
> >>>>> >
> >>>>> > [1]
> >>>>> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
> >>>>> > [2] https://stats.stackexchange.com/q/345842/136579
> >>>>> > [3] https://stats.stackexchange.com/q/304374/136579
> >>>>> >
> >>>>> > Best regards,
> >>>>> > Maarten
> >>>>> >
> >>>>> >         [[alternative HTML version deleted]]
> >>>>> >
> >>>>> > _______________________________________________
> >>>>> > R-sig-mixed-models at r-project.org mailing list
> >>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>
> >>>
> >>
> >


From thierry@onkelinx @ending from inbo@be  Tue May 29 12:18:27 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 29 May 2018 12:18:27 +0200
Subject: [R-sig-ME] partially crossed design, longitudinal
In-Reply-To: <CAHhX7WhUfruv2moMcFYHiMjdUXRKmkNbx8tDHsz5uPEZ2-HeOA@mail.gmail.com>
References: <CAHhX7WhUfruv2moMcFYHiMjdUXRKmkNbx8tDHsz5uPEZ2-HeOA@mail.gmail.com>
Message-ID: <CAJuCY5yXcqLi4WyR7b8Rv1r7pxbNet9rYi1DQ+Lngn6fqdDwoQ@mail.gmail.com>

Dear Christiano,

IMHO, the easiest solution would be to fit the model with the 5 level time
variable and then calculate the relevant post-hoc contrasts. e.g pert =
(pert early + pert late) / 2

Thinking about the analysis at the design stage of an experiment is
valuable.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-05-25 22:49 GMT+02:00 Cristiano Alessandro <cri.alessandro at gmail.com>:

> Hi all,
>
> I have a longitudinal study in which I measure the outcome variables at
> baseline condition (bas), then I apply a perturbation (pert) and I measure
> the outcome variable twice (early and late after perturbation is applied),
> and then I remove the perturbation (noPert) and I measure twice (early and
> late after perturbation is applied).
>
> I would like to use mixed models for this design, but I am a bit confused
> on how to do it. I could just have a single fixed effects 'time' with
> levels 1 to 5, where level 1 would be baseline, level 2 would be pert/early
> and so on. I think this is not the best design though. Alternatively, I
> could use a fixed effects 'condition' with levels bas, pert, noPert,
> crossed with another fixed effect 'time' with levels early/late. However,
> this last design has the problem that I do not have early/late for baseline
> actually.
>
> Do you have suggestion of what to do in a case like this?
>
> Thanks a lot
> Cristiano
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From dmichl @ending from uni-pot@d@m@de  Tue May 29 20:30:47 2018
From: dmichl @ending from uni-pot@d@m@de (Diana Michl)
Date: Tue, 29 May 2018 20:30:47 +0200
Subject: [R-sig-ME] ordinal mixed model - which one to use?
Message-ID: <2815fc18-15f6-baba-682e-23cc9b84bbd7@uni-potsdam.de>

Dear List,

I'm fitting ordinal mixed models with package {ordinal}. I have a clmm 
with 1 predictor (fixed effect, factor with 2 levels "woe" and "meta"), 
2 random effects, and an ordinal outcome, ratings from 1-4. Items=82, 
n=26. My question: Do I use

link="logit" or link="cloglog"? Or something else all together?

For all I know, cloglog is rather used when higher outcomes are more 
likely, but it also depends on the model fit. I thought cloglog made 
sense here b/c I have 53 cases of "woe" and 29 cases of "meta". "woe" 
are conceptually more likely to be rated as 4 or 3 (higher events).
If this is incorrect, please correct me.

In my logit model, I get a ridiculously huge odds ratio - but much 
better fit.
In my cloglog model, the odds ratio is still worryingly large, but less 
a tenth, while the fit is much worse. I post the outputs below.

A few remarks: Overall, I don't understand the huge OR. I have an 
extremely similar dataset (items=80, n=28) where the OR with the logit 
model are just 4.7 and the cloglog OR are only 2.73. So that seems fine. 
The difference between dataset 2 and the problematic one is the means: 
Their difference is much bigger in the problematic dataset:

#mean of typ meta = 1.27

#mean of typ woe = 3.42

as opposed to dataset 2:

#mean of typ meta = 2.35

#mean of typ woe = 3.02


Output logit model with link="logit":


> summary(m) Cumulative Link Mixed Model fitted with the Laplace 
approximation formula: rat ~ typ + (1 | itemid) + (1 | Vp) data: nwmeta 
link threshold nobs logLik AIC niter max.grad cond.H logit equidistant 
2132 -1682.63 3375.25 215(1094) 2.68e-04 3.6e+01 Random effects: Groups 
Name Variance Std.Dev. itemid (Intercept) 0.8829 0.9396 Vp (Intercept) 
0.7831 0.8849 Number of groups: itemid 82, Vp 26 Coefficients: Estimate 
Std. Error z value Pr(>|z|) typwoe 6.0994 0.2846 21.43 <2e-16 *** --- 
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Threshold 
coefficients: Estimate Std. Error z value threshold.1 1.73903 0.26937 
6.456 spacing 1.96709 0.07206 27.299 OR(typwoe) = 429.57

cloglog model:

> summary(mcloglog) Cumulative Link Mixed Model fitted with the Laplace 
approximation formula: rat ~ typ + (1 | itemid) + (1 | Vp) data: nwmeta 
link threshold nobs logLik AIC niter max.grad cond.H cloglog flexible 
2132 -1735.62 3483.24 352(2061) 1.48e-05 7.1e+01 Random effects: Groups 
Name Variance Std.Dev. itemid (Intercept) 0.3774 0.6143 Vp (Intercept) 
0.3413 0.5842 Number of groups: itemid 82, Vp 26 Coefficients: Estimate 
Std. Error z value Pr(>|z|) typwoe 3.7495 0.1763 21.27 <2e-16 *** --- 
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Threshold 
coefficients: Estimate Std. Error z value 1|2 0.4984 0.1704 2.926 2|3 
1.6293 0.1780 9.153 3|4 3.0036 0.1864 16.113



OR(typwoe) = 40.69





comparison:

> anova(mcloglog, m) Likelihood ratio tests of cumulative link models: 
formula: link: threshold: mcloglog rat ~ typ + (1 | itemid) + (1 | Vp) 
cloglog flexible m rat ~ typ + (1 | itemid) + (1 | Vp) logit flexible 
no.par AIC logLik LR.stat df Pr(>Chisq) mcloglog 6 3483.2 -1735.6 m 6 
3376.6 -1682.3 106.67 0


My sd seems fine at 1.26. Checking for outliers and several model 
assumptions isn't possible for a clmm.

Thanks very much in advance for any input

-- 
Diana Michl


	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Wed May 30 16:52:33 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 30 May 2018 16:52:33 +0200
Subject: [R-sig-ME] ordinal mixed model - which one to use?
In-Reply-To: <2815fc18-15f6-baba-682e-23cc9b84bbd7@uni-potsdam.de>
References: <2815fc18-15f6-baba-682e-23cc9b84bbd7@uni-potsdam.de>
Message-ID: <CAJuCY5w=E-+L=tKnp-AxyOAFogD_GY=wF+7XO4RHuNYTg3TLTA@mail.gmail.com>

Dear Diana,

Posting in HTML makes the R output very hard to read.

The first thing that I do when I'm confronted with such large
coefficients is checking for quasi-complete separation.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-05-29 20:30 GMT+02:00 Diana Michl <dmichl at uni-potsdam.de>:
> Dear List,
>
> I'm fitting ordinal mixed models with package {ordinal}. I have a clmm
> with 1 predictor (fixed effect, factor with 2 levels "woe" and "meta"),
> 2 random effects, and an ordinal outcome, ratings from 1-4. Items=82,
> n=26. My question: Do I use
>
> link="logit" or link="cloglog"? Or something else all together?
>
> For all I know, cloglog is rather used when higher outcomes are more
> likely, but it also depends on the model fit. I thought cloglog made
> sense here b/c I have 53 cases of "woe" and 29 cases of "meta". "woe"
> are conceptually more likely to be rated as 4 or 3 (higher events).
> If this is incorrect, please correct me.
>
> In my logit model, I get a ridiculously huge odds ratio - but much
> better fit.
> In my cloglog model, the odds ratio is still worryingly large, but less
> a tenth, while the fit is much worse. I post the outputs below.
>
> A few remarks: Overall, I don't understand the huge OR. I have an
> extremely similar dataset (items=80, n=28) where the OR with the logit
> model are just 4.7 and the cloglog OR are only 2.73. So that seems fine.
> The difference between dataset 2 and the problematic one is the means:
> Their difference is much bigger in the problematic dataset:
>
> #mean of typ meta = 1.27
>
> #mean of typ woe = 3.42
>
> as opposed to dataset 2:
>
> #mean of typ meta = 2.35
>
> #mean of typ woe = 3.02
>
>
> Output logit model with link="logit":
>
>
>> summary(m) Cumulative Link Mixed Model fitted with the Laplace
> approximation formula: rat ~ typ + (1 | itemid) + (1 | Vp) data: nwmeta
> link threshold nobs logLik AIC niter max.grad cond.H logit equidistant
> 2132 -1682.63 3375.25 215(1094) 2.68e-04 3.6e+01 Random effects: Groups
> Name Variance Std.Dev. itemid (Intercept) 0.8829 0.9396 Vp (Intercept)
> 0.7831 0.8849 Number of groups: itemid 82, Vp 26 Coefficients: Estimate
> Std. Error z value Pr(>|z|) typwoe 6.0994 0.2846 21.43 <2e-16 *** ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Threshold
> coefficients: Estimate Std. Error z value threshold.1 1.73903 0.26937
> 6.456 spacing 1.96709 0.07206 27.299 OR(typwoe) = 429.57
>
> cloglog model:
>
>> summary(mcloglog) Cumulative Link Mixed Model fitted with the Laplace
> approximation formula: rat ~ typ + (1 | itemid) + (1 | Vp) data: nwmeta
> link threshold nobs logLik AIC niter max.grad cond.H cloglog flexible
> 2132 -1735.62 3483.24 352(2061) 1.48e-05 7.1e+01 Random effects: Groups
> Name Variance Std.Dev. itemid (Intercept) 0.3774 0.6143 Vp (Intercept)
> 0.3413 0.5842 Number of groups: itemid 82, Vp 26 Coefficients: Estimate
> Std. Error z value Pr(>|z|) typwoe 3.7495 0.1763 21.27 <2e-16 *** ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Threshold
> coefficients: Estimate Std. Error z value 1|2 0.4984 0.1704 2.926 2|3
> 1.6293 0.1780 9.153 3|4 3.0036 0.1864 16.113
>
>
>
> OR(typwoe) = 40.69
>
>
>
>
>
> comparison:
>
>> anova(mcloglog, m) Likelihood ratio tests of cumulative link models:
> formula: link: threshold: mcloglog rat ~ typ + (1 | itemid) + (1 | Vp)
> cloglog flexible m rat ~ typ + (1 | itemid) + (1 | Vp) logit flexible
> no.par AIC logLik LR.stat df Pr(>Chisq) mcloglog 6 3483.2 -1735.6 m 6
> 3376.6 -1682.3 106.67 0
>
>
> My sd seems fine at 1.26. Checking for outliers and several model
> assumptions isn't possible for a clmm.
>
> Thanks very much in advance for any input
>
> --
> Diana Michl
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dmichl @ending from uni-pot@d@m@de  Wed May 30 17:29:50 2018
From: dmichl @ending from uni-pot@d@m@de (Diana Michl)
Date: Wed, 30 May 2018 17:29:50 +0200
Subject: [R-sig-ME] ordinal mixed model - which one to use?
In-Reply-To: <37d97252-1b59-3d37-343c-fe26cd021c1a@uni-potsdam.de>
References: <37d97252-1b59-3d37-343c-fe26cd021c1a@uni-potsdam.de>
Message-ID: <627cf671-4a03-08fb-0b1d-4ca6747dd052@uni-potsdam.de>

Dear List, dear Thierry,

thank you for pointing out my formatting got screwed up and still 
fighting your way through! I'm resending my email below. Complete 
separation: Well, not quite, but I do have few cases with few cells:



Conceptually, this is wanted and makes perfect sense. If this is the 
reason, I'm not sure what to do. It still seems strange to me that 
because one's cases are pretty straight forward and results are, too, 
this should make modelling so difficult or impossible... Thank you and 
kind regards
> Dear Diana,
>
> Posting in HTML makes the R output very hard to read.
>
> The first thing that I do when I'm confronted with such large
> coefficients is checking for quasi-complete separation.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////


-------- Weitergeleitete Nachricht --------
Betreff: 	ordinal mixed model - which one to use?
Datum: 	Tue, 29 May 2018 20:30:47 +0200
Von: 	Diana Michl <dmichl at uni-potsdam.de>
An: 	r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>



Dear List,

I'm fitting ordinal mixed models with package {ordinal}. I have a clmm 
with 1 predictor (fixed effect, factor with 2 levels "woe" and "meta"), 
2 random effects, and an ordinal outcome, ratings from 1-4. Items=82, 
n=26. My question: Do I use

link="logit" or link="cloglog"? Or something else all together?

For all I know, cloglog is rather used when higher outcomes are more 
likely, but it also depends on the model fit. I thought cloglog made 
sense here b/c I have 53 cases of "woe" and 29 cases of "meta". "woe" 
are conceptually more likely to be rated as 4 or 3 (higher events).
If this is incorrect, please correct me.

In my logit model, I get a ridiculously huge odds ratio - but much 
better fit.
In my cloglog model, the odds ratio is still worryingly large, but less 
a tenth, while the fit is much worse. I post the outputs below.

A few remarks: Overall, I don't understand the huge OR. I have an 
extremely similar dataset (items=80, n=28) where the OR with the logit 
model are just 4.7 and the cloglog OR are only 2.73. So that seems fine. 
The difference between dataset 2 and the problematic one is the means: 
Their difference is much bigger in the problematic dataset:

#mean of typ meta = 1.27

#mean of typ woe = 3.42

as opposed to dataset 2:

#mean of typ meta = 2.35

#mean of typ woe = 3.02

cloglog model:


comparison:


My sd seems fine at 1.26. Checking for outliers and several model 
assumptions isn't possible for a clmm.

Thanks very much in advance for any input

-- 
Diana Michl


From dmichl @ending from uni-pot@d@m@de  Wed May 30 17:41:34 2018
From: dmichl @ending from uni-pot@d@m@de (Diana Michl)
Date: Wed, 30 May 2018 17:41:34 +0200
Subject: [R-sig-ME] OT: How make emails readable?
Message-ID: <ximss-66386079@be2.mail.uni-potsdam.de>

I'm very sorry another email of mine got out where the formatting got 
screwed up.
I tried several ways and sent test emails to myself first. Plain text 
instead of HTML looks terrible, so I made screenshots. This worked fine for 
my own inbox, but apparently the images get swiped when sent to the list.
Now I don't know how to add input from R to an email without it being lost 
or unreadable.
Any advice?
Thanks


Diana Michl, M.A.
dmichl at uni-potsdam.de


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed May 30 22:55:47 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 30 May 2018 13:55:47 -0700
Subject: [R-sig-ME] OT: How make emails readable?
In-Reply-To: <ximss-66386079@be2.mail.uni-potsdam.de>
References: <ximss-66386079@be2.mail.uni-potsdam.de>
Message-ID: <23B0341B-EBFA-41BE-85EA-A0924ACA90E4@dcn.davis.ca.us>

Change your aesthetic sensibility. This is not a flippant answer... R code is plain text, and the setup of these mailing lists is such that plain text is strongly preferred as a medium for communication. This creates an incentive to use R as much as possible in expressing yourself.

Some people find this transition unacceptable and they use web forums like Stackexchange instead... but you may find a different subset of experts there so this might or might not suit you.

On May 30, 2018 8:41:34 AM PDT, Diana Michl <dmichl at uni-potsdam.de> wrote:
>I'm very sorry another email of mine got out where the formatting got 
>screwed up.
>I tried several ways and sent test emails to myself first. Plain text 
>instead of HTML looks terrible, so I made screenshots. This worked fine
>for 
>my own inbox, but apparently the images get swiped when sent to the
>list.
>Now I don't know how to add input from R to an email without it being
>lost 
>or unreadable.
>Any advice?
>Thanks
>
>
>Diana Michl, M.A.
>dmichl at uni-potsdam.de
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Sent from my phone. Please excuse my brevity.


From bl@zej@mrozin@ki @ending from gm@il@com  Thu May 31 13:37:28 2018
From: bl@zej@mrozin@ki @ending from gm@il@com (Blazej Mrozinski)
Date: Thu, 31 May 2018 13:37:28 +0200
Subject: [R-sig-ME] Looking for help in moving from a full factorial
 repeated measure anova to a LME model
Message-ID: <CANAWZx8_kgAm1O1=8GDKagm+A7veX0tnK8MeamTsJG5J16Vf2w@mail.gmail.com>

Greetings to all group members,

I'm having troubles in setting up a linear mixed model for analyzing a
balanced factorial within-subject design

I would normally use GLM Repeated Measures in SPSS on aggregated data-
which is what I already did with current and previous data, but want to
avoid losing participants due to missing data listwise deletion associated
with GLM module.

Otherwise, I'd like everything as in GLM Repeated Measures - that is: all
main effects and all interactions.

I understand that to use LME I need to have a raw datafile with separate
line for each observation (multiple lines per participant). [Preparing such
data file is not a problem].
I am, however, unsure about proper syntax to get an equivalent of GLM
Repeated Measures while using LME4.

This is some exemplary R code that mimics my real data structure (in raw /
long format):

library(AlgDesign) #for generating a factorial design)
df <-gen.factorial(c(8,2,2,2,2,10), factors = "all",
                  varNames = c("rep", "A", "B", "C", "D", "Subject"))

df$rep <- as.numeric(df$rep)
df$Subject <- as.numeric(df$Subject)

response <- sample(0:1, 1280, replace=TRUE, prob = c(0.3, 0.7))
logRT <- rnorm(n=1280, m=7, sd=1)

df <- cbind(df, response, logRT)
df$logRT[df$logRT<5 | df$logRT >9] <- NA

In my usual workflow I'd aggregate logRT over each factor and transpose to
a wide format resulting in one row per subject to accomodate SPSS needs in
GLM repeated measure procedure.

Clearly running

m <- lmer(logRT ~ A*B*C*D*response + (1|Subject), df)
anova(m)

gives very different results from what I can get via SPSS anova and I'm
guessing problem lies in how I specified the model in lmer call.

Any help would be greatly appreciated.

Blazej Mrozinski

	[[alternative HTML version deleted]]


From kenneth@keuk @ending from gm@il@com  Wed May 30 09:57:33 2018
From: kenneth@keuk @ending from gm@il@com (Kenneth KEUK)
Date: Wed, 30 May 2018 16:57:33 +0900
Subject: [R-sig-ME] Strange results using MuMIn's model.avg() and MCMCglmm
 model
Message-ID: <CAL3ndbKrBQ5bLR6BiKQJQHAU+o3V00MsBydCDtBBpgFje0QtJw@mail.gmail.com>

Hello everyone,

I am modelling parasite loads (counts, Poisson distributed) according
to multiple quantitative behavioural variables in primates. Thus, I am
using the MCMCglmm package to fit Bayesian mixed-models, especially
for later implementation of a pedigree.

I need to average models using the model.avg() function of the MuMIn
package, which is described as supporting MCMCglmm
(https://cran.r-project.org/web/packages/MuMIn/MuMIn.pdf). As
specified, I also had to wrap the MCMCglmm() function with
updateable() for the averaging to "work" without error.

The issue though is, while the function provided averaged estimates
for the variables, the standard errors seem suspicious (Z values and
Pr values also).

Either none were provided (NAs), or they were _exactly_ equal to their estimate.

In other words, I came to the exact same issue as this unanswered
question in StackOverflow, which provide a reproducible example:
https://stackoverflow.com/questions/37996824/why-does-mumin-give-weird-results-with-mcmcglmm

Is this behaviour normal or am I missing something in how the average
is done? Have others manage to obtain credible intervals after
averaging MCMCglmm models with MuMIn?

Many thanks for your help!
---
Kenneth Keuk


From jonn@tion@ @ending from gm@il@com  Thu May 31 16:42:01 2018
From: jonn@tion@ @ending from gm@il@com (jonnations)
Date: Thu, 31 May 2018 09:42:01 -0500
Subject: [R-sig-ME] Phylogenetic Logistic Regression for non-binary data:
 best practices and programs?
Message-ID: <CAHta4sP9O49fqXaSx-zeW+OWuoZcWow+KZ-FjpTiqXJrF+XPQQ@mail.gmail.com>

Hi Listserv,

I am new to this type of work and have tried to make this as clear as
possible.

I am working on a project that models habitat use (y = ground(0) vs.
tree(1)) and body size (x = body size, continuous). My y variables are from
the formula:

 y=((tree captures / tree effort)) / (tree captures / tree effort) +
(ground captures / ground effort)

which should provide a ratio of captures in a given habitat while
accounting for effort. My y values are mostly binary, but some species'
values are between 0 and 1. The data look like this example:

y = c(0, 0, 0, 0, 0, 0, 0.25, 0.4, 0.6, 0.9, 0.9, 1, 1, 1, 1)

My goal for the model is to use the species with known habitat "scores" to
predict the habitat value (y) of species from their body size value (x).

There are 2 "random" effects in the model, the relatedness of the species
(the phylogeny, Rp) and the intraspecific variation of the x measurement
(Rs). These are both very important as my 150 data points are distributed
between 22 species.

Using logistic regression, the model takes the form: logit (Pr ( Y = 1 ))
=  a +  Bx + Rp + Rs +  e

I have two questions for the group. First, is it appropriate to use
logistic regression (or a logit link) on these kinds of non-binary y
values? I have found several examples online of logistic regression with
non-binary variables (links below) but I have not found a publication with
a study design like mine.

Second, any suggestions of programs for setting up the model? I am
interested in using a bayesian glmm method (MCMCglmm, jags, etc.), however
I am worried that the programs will view these data as non-binary and
either insist on an ordinal regression (not what I am doing) or otherwise
provide categorical groupings on the response variable and produce strange
results. Can any glmm program handle my Rp, Rs, and the non-binary nature
of the y variables?

I hope this is clear. Any suggestions will be greatly appreciated! Thanks
for your help and patience.

Best,
Jon

Links mentioned above:
https://stats.stackexchange.com/questions/33562/choose-best-model-between-logit-probit-and-nls?rq=1
https://stats.stackexchange.com/questions/69886/using-logistic-regression-for-a-continuous-dependent-variable?rq=1
-- 
Jonathan A. Nations
PhD Candidate
Esselstyn Lab
Museum of Natural Sciences
Louisiana State University

	[[alternative HTML version deleted]]


From p@ul@buerkner @ending from gm@il@com  Thu May 31 17:19:33 2018
From: p@ul@buerkner @ending from gm@il@com (Paul Buerkner)
Date: Thu, 31 May 2018 17:19:33 +0200
Subject: [R-sig-ME] 
 Phylogenetic Logistic Regression for non-binary data:
 best practices and programs?
In-Reply-To: <CAHta4sP9O49fqXaSx-zeW+OWuoZcWow+KZ-FjpTiqXJrF+XPQQ@mail.gmail.com>
References: <CAHta4sP9O49fqXaSx-zeW+OWuoZcWow+KZ-FjpTiqXJrF+XPQQ@mail.gmail.com>
Message-ID: <CAGoSky_q=V1Zckr+wPCKkyFt4+uOp=93pe+to8o2SLOyDwg0Zw@mail.gmail.com>

Hi Jon,

a few thoughts about your response variable first.

When dealing with proportions (values between 0 and 1) the beta
distribution is what is usually being used. However, the beta distribution
cannot handle observations at the boundary (i.e. y = 0 or 1).

That's obviously a problem for your data. We have multiple options to deal
with that:

We can use a zero-one-inflated-beta distribution which models the data as
three separate processes (0, 1, and everything in between).

Alternatively, and probably something I would prefer for your data, one
could model the data using an ordinal distribution. This will require the
values between 0 and 1 to be brokenup into (not too many) discrete
categories,
which will lead to some information loss but at least is more informative
than a simple 0 1 treatement as in logistic regression.

You can fit all of these models above in combination with phylogenetic
structures using the brms R package (some are available in MCMCglmm as
well). Type vignette("brms_phylogenetics") in R for more details.

Best,
Paul

2018-05-31 16:42 GMT+02:00 jonnations <jonnations at gmail.com>:

> Hi Listserv,
>
> I am new to this type of work and have tried to make this as clear as
> possible.
>
> I am working on a project that models habitat use (y = ground(0) vs.
> tree(1)) and body size (x = body size, continuous). My y variables are from
> the formula:
>
>  y=((tree captures / tree effort)) / (tree captures / tree effort) +
> (ground captures / ground effort)
>
> which should provide a ratio of captures in a given habitat while
> accounting for effort. My y values are mostly binary, but some species'
> values are between 0 and 1. The data look like this example:
>
> y = c(0, 0, 0, 0, 0, 0, 0.25, 0.4, 0.6, 0.9, 0.9, 1, 1, 1, 1)
>
> My goal for the model is to use the species with known habitat "scores" to
> predict the habitat value (y) of species from their body size value (x).
>
> There are 2 "random" effects in the model, the relatedness of the species
> (the phylogeny, Rp) and the intraspecific variation of the x measurement
> (Rs). These are both very important as my 150 data points are distributed
> between 22 species.
>
> Using logistic regression, the model takes the form: logit (Pr ( Y = 1 ))
> =  a +  Bx + Rp + Rs +  e
>
> I have two questions for the group. First, is it appropriate to use
> logistic regression (or a logit link) on these kinds of non-binary y
> values? I have found several examples online of logistic regression with
> non-binary variables (links below) but I have not found a publication with
> a study design like mine.
>
> Second, any suggestions of programs for setting up the model? I am
> interested in using a bayesian glmm method (MCMCglmm, jags, etc.), however
> I am worried that the programs will view these data as non-binary and
> either insist on an ordinal regression (not what I am doing) or otherwise
> provide categorical groupings on the response variable and produce strange
> results. Can any glmm program handle my Rp, Rs, and the non-binary nature
> of the y variables?
>
> I hope this is clear. Any suggestions will be greatly appreciated! Thanks
> for your help and patience.
>
> Best,
> Jon
>
> Links mentioned above:
> https://stats.stackexchange.com/questions/33562/choose-
> best-model-between-logit-probit-and-nls?rq=1
> https://stats.stackexchange.com/questions/69886/using-
> logistic-regression-for-a-continuous-dependent-variable?rq=1
> --
> Jonathan A. Nations
> PhD Candidate
> Esselstyn Lab
> Museum of Natural Sciences
> Louisiana State University
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jonn@tion@ @ending from gm@il@com  Thu May 31 22:14:06 2018
From: jonn@tion@ @ending from gm@il@com (jonnations)
Date: Thu, 31 May 2018 15:14:06 -0500
Subject: [R-sig-ME] 
 Phylogenetic Logistic Regression for non-binary data:
 best practices and programs?
In-Reply-To: <CAGoSky_q=V1Zckr+wPCKkyFt4+uOp=93pe+to8o2SLOyDwg0Zw@mail.gmail.com>
References: <CAHta4sP9O49fqXaSx-zeW+OWuoZcWow+KZ-FjpTiqXJrF+XPQQ@mail.gmail.com>
 <CAGoSky_q=V1Zckr+wPCKkyFt4+uOp=93pe+to8o2SLOyDwg0Zw@mail.gmail.com>
Message-ID: <CAHta4sO7C09mVKnfZM8r8-NpXMizAcJbZ70RxPO2u4SiH1DrLw@mail.gmail.com>

Hi Paul,

Thank you for the quick response! This is the exact kind of information I
was hoping for. I had just heard of brms in passing, but after looking
through the vignettes it seems like a good choice. I have been interested
in STAN's algorithms but correctly scripting a phylogenetic glmm from
scratch seemed daunting.

Quick question concerning ordinal regression: I though - perhaps naively -
that ordinal models always "categorize" data and fit separate "slopes" for
each category. My ultimate goal is to use the model to predict a response
value from an explanatory variable for species lacking habitat (response)
data. I had anticipated a posterior distribution of a continuous response
variable for each "newdata" value in predict().

I see that there are several additional ordinal families in brms that I am
unfamiliar with. Perhaps one of these would be best for predicting a
(continuous?) response value, or maybe it is just "better" to predict
membership in an apriori discrete category.

Your thoughts would be greatly appreciated. Thanks again for the help!

Jon


On Thu, May 31, 2018 at 10:19 AM, Paul Buerkner <paul.buerkner at gmail.com>
wrote:

> Hi Jon,
>
> a few thoughts about your response variable first.
>
> When dealing with proportions (values between 0 and 1) the beta
> distribution is what is usually being used. However, the beta distribution
> cannot handle observations at the boundary (i.e. y = 0 or 1).
>
> That's obviously a problem for your data. We have multiple options to deal
> with that:
>
> We can use a zero-one-inflated-beta distribution which models the data as
> three separate processes (0, 1, and everything in between).
>
> Alternatively, and probably something I would prefer for your data, one
> could model the data using an ordinal distribution. This will require the
> values between 0 and 1 to be brokenup into (not too many) discrete
> categories,
> which will lead to some information loss but at least is more informative
> than a simple 0 1 treatement as in logistic regression.
>
> You can fit all of these models above in combination with phylogenetic
> structures using the brms R package (some are available in MCMCglmm as
> well). Type vignette("brms_phylogenetics") in R for more details.
>
> Best,
> Paul
>
> 2018-05-31 16:42 GMT+02:00 jonnations <jonnations at gmail.com>:
>
>> Hi Listserv,
>>
>> I am new to this type of work and have tried to make this as clear as
>> possible.
>>
>> I am working on a project that models habitat use (y = ground(0) vs.
>> tree(1)) and body size (x = body size, continuous). My y variables are
>> from
>> the formula:
>>
>>  y=((tree captures / tree effort)) / (tree captures / tree effort) +
>> (ground captures / ground effort)
>>
>> which should provide a ratio of captures in a given habitat while
>> accounting for effort. My y values are mostly binary, but some species'
>> values are between 0 and 1. The data look like this example:
>>
>> y = c(0, 0, 0, 0, 0, 0, 0.25, 0.4, 0.6, 0.9, 0.9, 1, 1, 1, 1)
>>
>> My goal for the model is to use the species with known habitat "scores" to
>> predict the habitat value (y) of species from their body size value (x).
>>
>> There are 2 "random" effects in the model, the relatedness of the species
>> (the phylogeny, Rp) and the intraspecific variation of the x measurement
>> (Rs). These are both very important as my 150 data points are distributed
>> between 22 species.
>>
>> Using logistic regression, the model takes the form: logit (Pr ( Y = 1 ))
>> =  a +  Bx + Rp + Rs +  e
>>
>> I have two questions for the group. First, is it appropriate to use
>> logistic regression (or a logit link) on these kinds of non-binary y
>> values? I have found several examples online of logistic regression with
>> non-binary variables (links below) but I have not found a publication with
>> a study design like mine.
>>
>> Second, any suggestions of programs for setting up the model? I am
>> interested in using a bayesian glmm method (MCMCglmm, jags, etc.), however
>> I am worried that the programs will view these data as non-binary and
>> either insist on an ordinal regression (not what I am doing) or otherwise
>> provide categorical groupings on the response variable and produce strange
>> results. Can any glmm program handle my Rp, Rs, and the non-binary nature
>> of the y variables?
>>
>> I hope this is clear. Any suggestions will be greatly appreciated! Thanks
>> for your help and patience.
>>
>> Best,
>> Jon
>>
>> Links mentioned above:
>> https://stats.stackexchange.com/questions/33562/choose-best-
>> model-between-logit-probit-and-nls?rq=1
>> https://stats.stackexchange.com/questions/69886/using-logist
>> ic-regression-for-a-continuous-dependent-variable?rq=1
>> --
>> Jonathan A. Nations
>> PhD Candidate
>> Esselstyn Lab
>> Museum of Natural Sciences
>> Louisiana State University
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
Jonathan A. Nations
PhD Candidate
Esselstyn Lab <http://www.museum.lsu.edu/esselstyn>
Museum of Natural Sciences <http://sites01.lsu.edu/wp/mns>
Louisiana State University

	[[alternative HTML version deleted]]


From p@ul@buerkner @ending from gm@il@com  Thu May 31 22:31:24 2018
From: p@ul@buerkner @ending from gm@il@com (Paul Buerkner)
Date: Thu, 31 May 2018 22:31:24 +0200
Subject: [R-sig-ME] 
 Phylogenetic Logistic Regression for non-binary data:
 best practices and programs?
In-Reply-To: <CAHta4sO7C09mVKnfZM8r8-NpXMizAcJbZ70RxPO2u4SiH1DrLw@mail.gmail.com>
References: <CAHta4sP9O49fqXaSx-zeW+OWuoZcWow+KZ-FjpTiqXJrF+XPQQ@mail.gmail.com>
 <CAGoSky_q=V1Zckr+wPCKkyFt4+uOp=93pe+to8o2SLOyDwg0Zw@mail.gmail.com>
 <CAHta4sO7C09mVKnfZM8r8-NpXMizAcJbZ70RxPO2u4SiH1DrLw@mail.gmail.com>
Message-ID: <CAGoSky_o-z0UhScOdfr4dw7dypEJet_BTzbtN9W2xQL6M+WTfA@mail.gmail.com>

Hi John,

See https://psyarxiv.com/x8swp/ for a detailed introduction to ordinal
models. For your data I think the cumulative() family probably makes the
most sense among the ordinal families.

Please keep in mind that ordinal models do not "automatically" categorized
the response. You have to categorize it yourself.

Paul

2018-05-31 22:14 GMT+02:00 jonnations <jonnations at gmail.com>:

> Hi Paul,
>
> Thank you for the quick response! This is the exact kind of information I
> was hoping for. I had just heard of brms in passing, but after looking
> through the vignettes it seems like a good choice. I have been interested
> in STAN's algorithms but correctly scripting a phylogenetic glmm from
> scratch seemed daunting.
>
> Quick question concerning ordinal regression: I though - perhaps naively -
> that ordinal models always "categorize" data and fit separate "slopes" for
> each category. My ultimate goal is to use the model to predict a response
> value from an explanatory variable for species lacking habitat (response)
> data. I had anticipated a posterior distribution of a continuous response
> variable for each "newdata" value in predict().
>
> I see that there are several additional ordinal families in brms that I am
> unfamiliar with. Perhaps one of these would be best for predicting a
> (continuous?) response value, or maybe it is just "better" to predict
> membership in an apriori discrete category.
>
> Your thoughts would be greatly appreciated. Thanks again for the help!
>
> Jon
>
>
> On Thu, May 31, 2018 at 10:19 AM, Paul Buerkner <paul.buerkner at gmail.com>
> wrote:
>
>> Hi Jon,
>>
>> a few thoughts about your response variable first.
>>
>> When dealing with proportions (values between 0 and 1) the beta
>> distribution is what is usually being used. However, the beta distribution
>> cannot handle observations at the boundary (i.e. y = 0 or 1).
>>
>> That's obviously a problem for your data. We have multiple options to
>> deal with that:
>>
>> We can use a zero-one-inflated-beta distribution which models the data as
>> three separate processes (0, 1, and everything in between).
>>
>> Alternatively, and probably something I would prefer for your data, one
>> could model the data using an ordinal distribution. This will require the
>> values between 0 and 1 to be brokenup into (not too many) discrete
>> categories,
>> which will lead to some information loss but at least is more informative
>> than a simple 0 1 treatement as in logistic regression.
>>
>> You can fit all of these models above in combination with phylogenetic
>> structures using the brms R package (some are available in MCMCglmm as
>> well). Type vignette("brms_phylogenetics") in R for more details.
>>
>> Best,
>> Paul
>>
>> 2018-05-31 16:42 GMT+02:00 jonnations <jonnations at gmail.com>:
>>
>>> Hi Listserv,
>>>
>>> I am new to this type of work and have tried to make this as clear as
>>> possible.
>>>
>>> I am working on a project that models habitat use (y = ground(0) vs.
>>> tree(1)) and body size (x = body size, continuous). My y variables are
>>> from
>>> the formula:
>>>
>>>  y=((tree captures / tree effort)) / (tree captures / tree effort) +
>>> (ground captures / ground effort)
>>>
>>> which should provide a ratio of captures in a given habitat while
>>> accounting for effort. My y values are mostly binary, but some species'
>>> values are between 0 and 1. The data look like this example:
>>>
>>> y = c(0, 0, 0, 0, 0, 0, 0.25, 0.4, 0.6, 0.9, 0.9, 1, 1, 1, 1)
>>>
>>> My goal for the model is to use the species with known habitat "scores"
>>> to
>>> predict the habitat value (y) of species from their body size value (x).
>>>
>>> There are 2 "random" effects in the model, the relatedness of the species
>>> (the phylogeny, Rp) and the intraspecific variation of the x measurement
>>> (Rs). These are both very important as my 150 data points are distributed
>>> between 22 species.
>>>
>>> Using logistic regression, the model takes the form: logit (Pr ( Y = 1 ))
>>> =  a +  Bx + Rp + Rs +  e
>>>
>>> I have two questions for the group. First, is it appropriate to use
>>> logistic regression (or a logit link) on these kinds of non-binary y
>>> values? I have found several examples online of logistic regression with
>>> non-binary variables (links below) but I have not found a publication
>>> with
>>> a study design like mine.
>>>
>>> Second, any suggestions of programs for setting up the model? I am
>>> interested in using a bayesian glmm method (MCMCglmm, jags, etc.),
>>> however
>>> I am worried that the programs will view these data as non-binary and
>>> either insist on an ordinal regression (not what I am doing) or otherwise
>>> provide categorical groupings on the response variable and produce
>>> strange
>>> results. Can any glmm program handle my Rp, Rs, and the non-binary nature
>>> of the y variables?
>>>
>>> I hope this is clear. Any suggestions will be greatly appreciated! Thanks
>>> for your help and patience.
>>>
>>> Best,
>>> Jon
>>>
>>> Links mentioned above:
>>> https://stats.stackexchange.com/questions/33562/choose-best-
>>> model-between-logit-probit-and-nls?rq=1
>>> https://stats.stackexchange.com/questions/69886/using-logist
>>> ic-regression-for-a-continuous-dependent-variable?rq=1
>>> --
>>> Jonathan A. Nations
>>> PhD Candidate
>>> Esselstyn Lab
>>> Museum of Natural Sciences
>>> Louisiana State University
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Jonathan A. Nations
> PhD Candidate
> Esselstyn Lab <http://www.museum.lsu.edu/esselstyn>
> Museum of Natural Sciences <http://sites01.lsu.edu/wp/mns>
> Louisiana State University
>
>

	[[alternative HTML version deleted]]


From kevin@thorpe @ending from utoronto@c@  Fri Jun  1 14:53:14 2018
From: kevin@thorpe @ending from utoronto@c@ (Kevin E. Thorpe)
Date: Fri, 1 Jun 2018 08:53:14 -0400
Subject: [R-sig-ME] Simulating Cluster RCTs
Message-ID: <f532e5a8-a70a-6dba-6d23-0b55652d06f5@utoronto.ca>

Hi All.

Apologies if this is the wrong list but after searching I have not found 
what I am looking for.

I would like (mainly for teaching) to be able to simulate cluster RCTs 
with continuous and binary outcomes. It appears to me that 
simulate.merMod in lme4 may be one way to do this. Unfortunately, I am a 
bit lost in the help file. For one thing, in the newparams argument, I 
have no idea what theta is.

Also, in the simulations I would like to be able to specify an ICC to 
control the clustering effect as well as the usual things (e.g. mean 
response in the control group, treatment effect, number of clusters and 
cluster sizes).

I would be most appreciative for any guidance or examples of this type 
of simulation, either with simulate.merMod or other approaches.

Thank you in advance for your time.

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From mr@luced@n @ending from hotm@il@it  Fri Jun  1 19:54:47 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Fri, 1 Jun 2018 17:54:47 +0000
Subject: [R-sig-ME] Error in `row.names<-.data.frame`
Message-ID: <DB3PR0402MB38514F1DB016D947ADEE545FF6620@DB3PR0402MB3851.eurprd04.prod.outlook.com>

Hello everybody,

I am still working on my R analysis, and using the contrasts. Specifically, I was needing a rectangular contrasts and I was actually taught how to create it. But when I give a column name to my contrasts, this creates an error in the summary() function of my lmer() analysis.

The code for naming the column of my contrast is:


colnames(posmat) <- "pos_c1"

While the error I get in the summary() is


Error in `row.names<-.data.frame`(`*tmp*`, value = value) :
  duplicate 'row.names' are not allowed
In addition: Warning message:
non-unique value when setting 'row.names': ?Pos?

I have written a CrossValidated topic with a MWE: https://stats.stackexchange.com/questions/349399/r-error-in-row-names-data-frame

Is anybody here aware of how that happens and how to solve it?

Best
Luca

	[[alternative HTML version deleted]]


From ukoether @ending from uke@de  Fri Jun  1 22:54:57 2018
From: ukoether @ending from uke@de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Fri, 1 Jun 2018 22:54:57 +0200
Subject: [R-sig-ME] Simulating Cluster RCTs
In-Reply-To: <f532e5a8-a70a-6dba-6d23-0b55652d06f5@utoronto.ca>
References: <f532e5a8-a70a-6dba-6d23-0b55652d06f5@utoronto.ca>
Message-ID: <ab2c0cd1-5290-ece9-fb28-9f25143c4b2f@uke.de>

Hi Kevin,

I think that a more appropriate way to achieve your goal is to have a
look at a library that explicitly deals with the simulation of data.
Especially, you should look into the "simstudy" package, which is
developed by Keith Goldfield, which is, as I recall it, clearly able to
do what you want:

The package:

https://cran.r-project.org/web/packages/simstudy/index.html

Goldfield's blog about generating data using simstudy:

https://www.rdatagen.net/

His posts about clustered data:

https://www.rdatagen.net/page/clustered/

Good luck,

Ulf


Am 01.06.2018 um 14:53 schrieb Kevin E. Thorpe:
> Hi All.
> 
> Apologies if this is the wrong list but after searching I have not found
> what I am looking for.
> 
> I would like (mainly for teaching) to be able to simulate cluster RCTs
> with continuous and binary outcomes. It appears to me that
> simulate.merMod in lme4 may be one way to do this. Unfortunately, I am a
> bit lost in the help file. For one thing, in the newparams argument, I
> have no idea what theta is.
> 
> Also, in the simulations I would like to be able to specify an ICC to
> control the clustering effect as well as the usual things (e.g. mean
> response in the control group, treatment effect, number of clusters and
> cluster sizes).
> 
> I would be most appreciative for any guidance or examples of this type
> of simulation, either with simulate.merMod or other approaches.
> 
> Thank you in advance for your time.
> 
> Kevin
> 
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From bbolker @ending from gm@il@com  Sat Jun  2 08:48:41 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sat, 2 Jun 2018 02:48:41 -0400
Subject: [R-sig-ME] Simulating Cluster RCTs
In-Reply-To: <ab2c0cd1-5290-ece9-fb28-9f25143c4b2f@uke.de>
References: <f532e5a8-a70a-6dba-6d23-0b55652d06f5@utoronto.ca>
 <ab2c0cd1-5290-ece9-fb28-9f25143c4b2f@uke.de>
Message-ID: <CABghstRBAPyk2UJosCrHHUi8Z1iKpdUCfkEU7s8nd-Y0wCgbkQ@mail.gmail.com>

If you can find an existing package that does the kind of model you
want, that would certainly be recommended. You could also look at the
power analysis section of the GLMM FAQ
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#power-analysis

For scalar/intercept-only random effects, the theta parameters are the
among-group standard deviations (scaled by the residual standard
deviation, for linear mixed models). For random-slopes models it's
(alas) more complicated -- the theta parameters are the elements of
the (scaled) Cholesky factor of the variance-covariance matrix -- but
you could use the functions in ?vcconv to convert from
variance-covariance matrices to Cholesky factors ..

On Fri, Jun 1, 2018 at 4:54 PM, Ulf K?ther <ukoether at uke.de> wrote:
> Hi Kevin,
>
> I think that a more appropriate way to achieve your goal is to have a
> look at a library that explicitly deals with the simulation of data.
> Especially, you should look into the "simstudy" package, which is
> developed by Keith Goldfield, which is, as I recall it, clearly able to
> do what you want:
>
> The package:
>
> https://cran.r-project.org/web/packages/simstudy/index.html
>
> Goldfield's blog about generating data using simstudy:
>
> https://www.rdatagen.net/
>
> His posts about clustered data:
>
> https://www.rdatagen.net/page/clustered/
>
> Good luck,
>
> Ulf
>
>
> Am 01.06.2018 um 14:53 schrieb Kevin E. Thorpe:
>> Hi All.
>>
>> Apologies if this is the wrong list but after searching I have not found
>> what I am looking for.
>>
>> I would like (mainly for teaching) to be able to simulate cluster RCTs
>> with continuous and binary outcomes. It appears to me that
>> simulate.merMod in lme4 may be one way to do this. Unfortunately, I am a
>> bit lost in the help file. For one thing, in the newparams argument, I
>> have no idea what theta is.
>>
>> Also, in the simulations I would like to be able to specify an ICC to
>> control the clustering effect as well as the usual things (e.g. mean
>> response in the control group, treatment effect, number of clusters and
>> cluster sizes).
>>
>> I would be most appreciative for any guidance or examples of this type
>> of simulation, either with simulate.merMod or other approaches.
>>
>> Thank you in advance for your time.
>>
>> Kevin
>>
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From kevin@thorpe @ending from utoronto@c@  Sat Jun  2 16:38:24 2018
From: kevin@thorpe @ending from utoronto@c@ (Kevin E. Thorpe)
Date: Sat, 2 Jun 2018 10:38:24 -0400
Subject: [R-sig-ME] Simulating Cluster RCTs
In-Reply-To: <CABghstRBAPyk2UJosCrHHUi8Z1iKpdUCfkEU7s8nd-Y0wCgbkQ@mail.gmail.com>
References: <f532e5a8-a70a-6dba-6d23-0b55652d06f5@utoronto.ca>
 <ab2c0cd1-5290-ece9-fb28-9f25143c4b2f@uke.de>
 <CABghstRBAPyk2UJosCrHHUi8Z1iKpdUCfkEU7s8nd-Y0wCgbkQ@mail.gmail.com>
Message-ID: <0a9127ad-b4e5-5053-c1b0-e58c73e456ce@utoronto.ca>

Thank you both for the advice.

Kevin

On 06/02/2018 02:48 AM, Ben Bolker wrote:
> If you can find an existing package that does the kind of model you
> want, that would certainly be recommended. You could also look at the
> power analysis section of the GLMM FAQ
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#power-analysis
> 
> For scalar/intercept-only random effects, the theta parameters are the
> among-group standard deviations (scaled by the residual standard
> deviation, for linear mixed models). For random-slopes models it's
> (alas) more complicated -- the theta parameters are the elements of
> the (scaled) Cholesky factor of the variance-covariance matrix -- but
> you could use the functions in ?vcconv to convert from
> variance-covariance matrices to Cholesky factors ..
> 
> On Fri, Jun 1, 2018 at 4:54 PM, Ulf K?ther <ukoether at uke.de> wrote:
>> Hi Kevin,
>>
>> I think that a more appropriate way to achieve your goal is to have a
>> look at a library that explicitly deals with the simulation of data.
>> Especially, you should look into the "simstudy" package, which is
>> developed by Keith Goldfield, which is, as I recall it, clearly able to
>> do what you want:
>>
>> The package:
>>
>> https://cran.r-project.org/web/packages/simstudy/index.html
>>
>> Goldfield's blog about generating data using simstudy:
>>
>> https://www.rdatagen.net/
>>
>> His posts about clustered data:
>>
>> https://www.rdatagen.net/page/clustered/
>>
>> Good luck,
>>
>> Ulf
>>
>>
>> Am 01.06.2018 um 14:53 schrieb Kevin E. Thorpe:
>>> Hi All.
>>>
>>> Apologies if this is the wrong list but after searching I have not found
>>> what I am looking for.
>>>
>>> I would like (mainly for teaching) to be able to simulate cluster RCTs
>>> with continuous and binary outcomes. It appears to me that
>>> simulate.merMod in lme4 may be one way to do this. Unfortunately, I am a
>>> bit lost in the help file. For one thing, in the newparams argument, I
>>> have no idea what theta is.
>>>
>>> Also, in the simulations I would like to be able to specify an ICC to
>>> control the clustering effect as well as the usual things (e.g. mean
>>> response in the control group, treatment effect, number of clusters and
>>> cluster sizes).
>>>
>>> I would be most appreciative for any guidance or examples of this type
>>> of simulation, either with simulate.merMod or other approaches.
>>>
>>> Thank you in advance for your time.
>>>
>>> Kevin
>>>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From creemt@ @ending from TNC@ORG  Mon Jun  4 13:38:47 2018
From: creemt@ @ending from TNC@ORG (Charlotte Reemts)
Date: Mon, 4 Jun 2018 11:38:47 +0000
Subject: [R-sig-ME] nested random effects with temporal correlation
Message-ID: <1528112327344.92886@TNC.ORG>

Mixed modelers,
I am analyzing data from a fire experiment. We counted the number of point intercepts of a grass along 3 pairs of transects (so n=6). One transect in each pair was burned. We collected data in 2006 (before burning) and for three years after burning. We calculated frequency of the grass by dividing the intercepts by the total number of contacts of all species, so I am using the binomial family for analysis. We want to know whether the frequency of the grass decreased in the burned transects compared to the unburned transects and how that frequency changes with time since burning (I am using glht contrasts, not shown, to do this).

A reviewer would like me to include nested random effects and account for temporal correlation, since we repeatedly sampled the same transects. I created the glmmPQL model below, which converges, but I am concerned that it is a very complex model for a small dataset. Do you have any suggestions for 1) the best way to simplify the model and 2) the best way to justify that simplification to the reviewer?

Thanks,
Charlotte

krdata2<-read.table(header=T, text= "
Pair

Treatment

Year

Transect

totalcontacts

freq

1

burned

2006

T1

190

0.778947

1

burned

2007

T1

231

0.337662

1

burned

2008

T1

250

0.508

1

burned

2009

T1

148

0.52027

1

unburned

2006

C1

188

0.946809

1

unburned

2007

C1

210

0.92381

1

unburned

2008

C1

214

0.878505

1

unburned

2009

C1

162

0.962963

2

burned

2006

T2

196

0.80102

2

burned

2007

T2

270

0.414815

2

burned

2008

T2

266

0.56015

2

burned

2009

T2

210

0.847619

2

unburned

2006

C2

193

0.782383

2

unburned

2007

C2

211

0.85782

2

unburned

2008

C2

194

0.938144

2

unburned

2009

C2

198

0.959596

3

burned

2006

T3

193

0.632124

3

burned

2007

T3

275

0.192727

3

burned

2008

T3

222

0.405405

3

burned

2009

T3

176

0.642045

3

unburned

2006

C3

198

0.747475

3

unburned

2007

C3

207

0.758454

3

unburned

2008

C3

207

0.772947

3

unburned

2009

C3

143

0.944056

")

krdata2$Year<-as.factor(krdata2$Year)
aus.kr.pql2<-glmmPQL(freq ~ Treatment*Year, random = ~1|Pair/Treatment,
                    correlation=corCAR1(form = ~Year|Pair/Treatment),
                    family=binomial(link="logit"), weights=totalcontacts, data=krdata2)?



___________________________________________
Charlotte Reemts, M.S.
Research and Monitoring Ecologist
creemts at tnc.org

	[[alternative HTML version deleted]]


From H@Tiw@ri @ending from murdoch@edu@@u  Tue Jun  5 02:42:44 2018
From: H@Tiw@ri @ending from murdoch@edu@@u (Harish Tiwari)
Date: Tue, 5 Jun 2018 00:42:44 +0000
Subject: [R-sig-ME] Help with glmmTMB mixed models
Message-ID: <SYCPR01MB3776286B8B8D2ED6F31FCE3FA6660@SYCPR01MB3776.ausprd01.prod.outlook.com>

 Hi

I am working on control of dog-bite related rabies in India. In this regard, I want to construct a mixed model that could predict the grouping behaviour of free-roaming dogs as solitary ( found singly), in pairs, in triads or in the groups of four or more dogs. As basically it is a count data, and chances of sighting no dog are not accounted, this response variable follows a zero-truncated Poisson distribution. The predictors are a mix of numerical ( resight probability, temperature, humidity and wind velocity of the day of the survey) and categorical ( gender, age, body condition score and if sighted in the proximity of garbage dumps) variables.

The data was collected by the survey of free-roaming dogs over 7 survey occasions in the manner of capture-recapture data ( only here it was sight-resight). As many individuals were sighted more than once during the survey, and their measures are repeated, mixed models with random effect were thought to be the way to account for the clustering.  I modelled the data on the glmmTMB package (the intercepts, however, did not differ much when the model was constructed using   VGAM -vglm function). I seek to resolve some queries I have in this regard:


  1.  Is the glmmTMB package appropriate to model this kind of data?
  2.  How to test goodness of fit of the model?


Help is greatly appreciated


thanks

Harish


	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Tue Jun  5 15:56:41 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 5 Jun 2018 09:56:41 -0400
Subject: [R-sig-ME] Help with glmmTMB mixed models
In-Reply-To: <SYCPR01MB3776286B8B8D2ED6F31FCE3FA6660@SYCPR01MB3776.ausprd01.prod.outlook.com>
References: <SYCPR01MB3776286B8B8D2ED6F31FCE3FA6660@SYCPR01MB3776.ausprd01.prod.outlook.com>
Message-ID: <df393efb-e794-a5ed-7506-98c7974ee507@gmail.com>


I think I'd recommend an ordinal response (e.g. using the clmm function
from the ordinal package).  Other than being a positive integer-valued
values, I don't think group size really matches the mechanism of a
truncated Poisson very well.

  I'm not sure how to test goodness-of-fit for CLMM.  If you use clmm2
instead of clmm, you'll be able to get predicted values from the model,
which you examine to get an intuitive idea of how well the model is fitting.



On 2018-06-04 08:42 PM, Harish Tiwari wrote:
> Hi
> 
> I am working on control of dog-bite related rabies in India. In this
> regard, I want to construct a mixed model that could predict the
> grouping behaviour of free-roaming dogs as solitary ( found singly),
> in pairs, in triads or in the groups of four or more dogs. As
> basically it is a count data, and chances of sighting no dog are not
> accounted, this response variable follows a zero-truncated Poisson
> distribution. The predictors are a mix of numerical ( resight
> probability, temperature, humidity and wind velocity of the day of
> the survey) and categorical ( gender, age, body condition score and
> if sighted in the proximity of garbage dumps) variables.
> 
> The data was collected by the survey of free-roaming dogs over 7
> survey occasions in the manner of capture-recapture data ( only here
> it was sight-resight). As many individuals were sighted more than
> once during the survey, and their measures are repeated, mixed models
> with random effect were thought to be the way to account for the
> clustering.  I modelled the data on the glmmTMB package (the
> intercepts, however, did not differ much when the model was
> constructed using   VGAM -vglm function). I seek to resolve some
> queries I have in this regard:
> 
> 
> 1.  Is the glmmTMB package appropriate to model this kind of data? 2.
> How to test goodness of fit of the model?
> 
> 
> Help is greatly appreciated
> 
> 
> thanks
> 
> Harish
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cri@@le@@@ndro @ending from gm@il@com  Tue Jun  5 23:32:35 2018
From: cri@@le@@@ndro @ending from gm@il@com (Cristiano Alessandro)
Date: Tue, 5 Jun 2018 16:32:35 -0500
Subject: [R-sig-ME] partially crossed design, longitudinal
In-Reply-To: <CAJuCY5yXcqLi4WyR7b8Rv1r7pxbNet9rYi1DQ+Lngn6fqdDwoQ@mail.gmail.com>
References: <CAHhX7WhUfruv2moMcFYHiMjdUXRKmkNbx8tDHsz5uPEZ2-HeOA@mail.gmail.com>
 <CAJuCY5yXcqLi4WyR7b8Rv1r7pxbNet9rYi1DQ+Lngn6fqdDwoQ@mail.gmail.com>
Message-ID: <CAHhX7WgE_eq-AbsJwEF+QgzXoZo9V8Sx35qEdFfD=AOHFKZgaA@mail.gmail.com>

Hi Thierry,

thanks for your help. While I understand the need of considering the
analysis at the design stage of an experiment, I thought this was a pretty
standard design. Like when testing for a drug, I have a baseline (before
treatment), then I measure at different time point during administration of
the drug (to see the time course of the treatment), and then at different
time point after interruption of the drug administration (to see
retaining). I would be interested to see if the drug is effective, and if
there is a 'time' effect during drug administration and interruption.

Do you have suggestions on how to design this kind of study better for the
future? Thanks!

Best
Cristiano


Do you have suggestions on how to design this study better for the future?

On Tue, May 29, 2018 at 5:18 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Christiano,
>
> IMHO, the easiest solution would be to fit the model with the 5 level time
> variable and then calculate the relevant post-hoc contrasts. e.g pert =
> (pert early + pert late) / 2
>
> Thinking about the analysis at the design stage of an experiment is
> valuable.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-05-25 22:49 GMT+02:00 Cristiano Alessandro <cri.alessandro at gmail.com>
> :
>
>> Hi all,
>>
>> I have a longitudinal study in which I measure the outcome variables at
>> baseline condition (bas), then I apply a perturbation (pert) and I measure
>> the outcome variable twice (early and late after perturbation is applied),
>> and then I remove the perturbation (noPert) and I measure twice (early and
>> late after perturbation is applied).
>>
>> I would like to use mixed models for this design, but I am a bit confused
>> on how to do it. I could just have a single fixed effects 'time' with
>> levels 1 to 5, where level 1 would be baseline, level 2 would be
>> pert/early
>> and so on. I think this is not the best design though. Alternatively, I
>> could use a fixed effects 'condition' with levels bas, pert, noPert,
>> crossed with another fixed effect 'time' with levels early/late. However,
>> this last design has the problem that I do not have early/late for
>> baseline
>> actually.
>>
>> Do you have suggestion of what to do in a case like this?
>>
>> Thanks a lot
>> Cristiano
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From mdevoto @ending from @gro@ub@@@r  Wed Jun  6 14:52:26 2018
From: mdevoto @ending from @gro@ub@@@r (Mariano Devoto)
Date: Wed, 6 Jun 2018 09:52:26 -0300
Subject: [R-sig-ME] help with network analysis
Message-ID: <CAJRWjBZo8NzGebX0CvQHR4=rr6BNnjRx+No07xx0jThFAiNH0Q@mail.gmail.com>

 Dear List,

I am analyzing the structure of pollination networks in conventional vs
organic avocado farms.
I have four different response variables: interaction richness (a count),
interaction evenness, interaction selectivity and nestedness (all three
take values in the [0, 1] interval).
The explanatory variables are: farm type (fixed factor, 2 levels), sampling
season (fixed factor, 2 levels), and farm identity (random factor).
Additionally, the number of species in the network (a count) might affect
some of the response variables (interaction richness and nestedness
probably, although I am not sure about the other two), so I decided to
"correct" for that effect in some of the models.
I am generally familiar with models dealing with count data, but I am not
too confident modelling 0-1 bounded continuous data.
For each variable I've searched the literature and online resources to try
and find the best R function, model and error structure.

I have pasted below a workable code that deals sequentially with each
response variable.
Would you say the models correctly are defined in each case? I am
particularly concerned with (1) the suitability of the "simulateResidual"
function in the Dharma package (which I recently learned about) as a way to
check the fit of the model,
and (2) the validity of the offset term in model 4.

Your comments and suggestions will be greatly appreciated.

Best regards,

Mariano

###############################
require(RCurl); require(visreg); require(lme4); require(DHARMa);
library(lmerTest); require(glmmTMB); require(effects)
my.file <- getURL("https://docs.google.com/spreadsheets/d/e/2PACX-
1vRn3_aM-OlKldXlEB45qKjL9jMoY_-CP2saOI8HteTTx4_AZv-
card1sce4MDbqwYJ8kllJUaysfcBR/pub?output=csv")
avocado_data <- read.csv(textConnection(my.file), head=T)
str(avocado_data)

##Model for Interaction richness
model1 <- glmer(irich ~ offset(log(species)) + type + season + (1|farm),
family=poisson, data=avocado_data)
summary(model1)
#diagnostic plots
plot(model1)
simulationOutput <- simulateResiduals(fittedModel = model2, n = 1000)
testOverdispersion(simulationOutput = simulationOutput, alternative
="greater") #the data are not overdispersed relative to the Poisson
distribution
plotSimulatedResiduals(simulationOutput = simulationOutput)
visreg(model1, pch=16, cex=1.5, rug=FALSE, ylab="Interaction richness",
line.par=list(col="darkgreen"), points.par=list(col="red", cex=1.5),
overlay=TRUE)

##Model for Interaction evenness
model2 <- lmer(ieven~ type + season + (1|farm), data=avocado_data)
summary(model2)
#diagnostic plots
plot(model2)
simulationOutput <- simulateResiduals(fittedModel = model2, n = 1000)
plotSimulatedResiduals(simulationOutput = simulationOutput)
visreg(model2, pch=16, cex=1.5, rug=FALSE, ylab="Interaction evenness",
line.par=list(col="darkgreen"), points.par=list(col="red", cex=1.5),
overlay=TRUE)

##Model for Interaction selectivity
model3 <- lmer(h2 ~ type + season + (1|farm), data=avocado_data)
summary(model3)
#diagnostic plots
plot(model3)
simulationOutput <- simulateResiduals(fittedModel = model3, n = 1000)
plotSimulatedResiduals(simulationOutput = simulationOutput)
visreg(model3, pch=16, cex=2, rug=FALSE, ylab="Interaction selectivity",
line.par=list(col="darkgreen"), points.par=list(col="red", cex=1.5),
overlay=TRUE)

#model for Nestedness
model4 <- glmmTMB(nestedness/100 ~ offset(log(species)) + type + season +
(1|farm), data=avocado_data, family=list(family="beta", link="logit"))
summary(model4)
#diagnostic plots
simulationOutput <- simulateResiduals(fittedModel = model4, n = 1000)
plotSimulatedResiduals(simulationOutput = simulationOutput)
visreg(model4, pch=16, cex=2, rug=FALSE, ylab="Nestedness",
line.par=list(col="darkgreen"), points.par=list(col="red", cex=1.5),
overlay=TRUE) #does not work with glmmTMB :-(
plot(allEffects(model4)) #doesn't work either . Any alternatives?

###############################



*Dr. Mariano Devoto*

Profesor Adjunto - C?tedra de Bot?nica General, Facultad de Agronom?a de la
UBA
Investigador Adjunto del CONICET

Av. San Mart?n 4453 - C1417DSE - C. A. de Buenos Aires - Argentina
+5411 4524-8069
*https://www.researchgate.net/profile/Mariano_Devoto
<https://www.researchgate.net/profile/Mariano_Devoto>*

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Wed Jun  6 15:16:44 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 6 Jun 2018 15:16:44 +0200
Subject: [R-sig-ME] nested random effects with temporal correlation
In-Reply-To: <1528112327344.92886@TNC.ORG>
References: <1528112327344.92886@TNC.ORG>
Message-ID: <CAJuCY5z30km=yODLULXcdiuk+w-0vG2=8yfLLcS3H0fDAEnpAg@mail.gmail.com>

Dear Charlotte,

The reviewer is correct, at least from a conceptual point of view.
Pair and transect are both random effects and transect is nested in
pair. Temporal auto correlation is plausible.

However from a practical point of view, you don't have enough pairs to
use it as a random effects (see
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random).
The number of transects is a tiny bit larger. Therefore I would use
only the transects as random intercepts. Any effect at the pairs
levels will be absorbed by the transects.

Your glmmPQL model estimates the **residual** auto correlation
**within** the most detailed random effect level. The residuals from
year t are correlated to the residuals from year t-1 **within** the
same transect. Residuals **between** different transects are assumed
to be independent. Given that your model contains the treatment - year
interaction and year is used as a factor, then much of the temporal
pattern will be already explained by the fixed effects. Hence the
residual auto correlation might be overkill.

Another option is to model Year as a random effect with temporal auto
correlation between the years. You can do that with the INLA package.

Best regards,

Thierry



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-04 13:38 GMT+02:00 Charlotte Reemts <creemts at tnc.org>:
> Mixed modelers,
> I am analyzing data from a fire experiment. We counted the number of point intercepts of a grass along 3 pairs of transects (so n=6). One transect in each pair was burned. We collected data in 2006 (before burning) and for three years after burning. We calculated frequency of the grass by dividing the intercepts by the total number of contacts of all species, so I am using the binomial family for analysis. We want to know whether the frequency of the grass decreased in the burned transects compared to the unburned transects and how that frequency changes with time since burning (I am using glht contrasts, not shown, to do this).
>
> A reviewer would like me to include nested random effects and account for temporal correlation, since we repeatedly sampled the same transects. I created the glmmPQL model below, which converges, but I am concerned that it is a very complex model for a small dataset. Do you have any suggestions for 1) the best way to simplify the model and 2) the best way to justify that simplification to the reviewer?
>
> Thanks,
> Charlotte
>
> krdata2<-read.table(header=T, text= "
> Pair
>
> Treatment
>
> Year
>
> Transect
>
> totalcontacts
>
> freq
>
> 1
>
> burned
>
> 2006
>
> T1
>
> 190
>
> 0.778947
>
> 1
>
> burned
>
> 2007
>
> T1
>
> 231
>
> 0.337662
>
> 1
>
> burned
>
> 2008
>
> T1
>
> 250
>
> 0.508
>
> 1
>
> burned
>
> 2009
>
> T1
>
> 148
>
> 0.52027
>
> 1
>
> unburned
>
> 2006
>
> C1
>
> 188
>
> 0.946809
>
> 1
>
> unburned
>
> 2007
>
> C1
>
> 210
>
> 0.92381
>
> 1
>
> unburned
>
> 2008
>
> C1
>
> 214
>
> 0.878505
>
> 1
>
> unburned
>
> 2009
>
> C1
>
> 162
>
> 0.962963
>
> 2
>
> burned
>
> 2006
>
> T2
>
> 196
>
> 0.80102
>
> 2
>
> burned
>
> 2007
>
> T2
>
> 270
>
> 0.414815
>
> 2
>
> burned
>
> 2008
>
> T2
>
> 266
>
> 0.56015
>
> 2
>
> burned
>
> 2009
>
> T2
>
> 210
>
> 0.847619
>
> 2
>
> unburned
>
> 2006
>
> C2
>
> 193
>
> 0.782383
>
> 2
>
> unburned
>
> 2007
>
> C2
>
> 211
>
> 0.85782
>
> 2
>
> unburned
>
> 2008
>
> C2
>
> 194
>
> 0.938144
>
> 2
>
> unburned
>
> 2009
>
> C2
>
> 198
>
> 0.959596
>
> 3
>
> burned
>
> 2006
>
> T3
>
> 193
>
> 0.632124
>
> 3
>
> burned
>
> 2007
>
> T3
>
> 275
>
> 0.192727
>
> 3
>
> burned
>
> 2008
>
> T3
>
> 222
>
> 0.405405
>
> 3
>
> burned
>
> 2009
>
> T3
>
> 176
>
> 0.642045
>
> 3
>
> unburned
>
> 2006
>
> C3
>
> 198
>
> 0.747475
>
> 3
>
> unburned
>
> 2007
>
> C3
>
> 207
>
> 0.758454
>
> 3
>
> unburned
>
> 2008
>
> C3
>
> 207
>
> 0.772947
>
> 3
>
> unburned
>
> 2009
>
> C3
>
> 143
>
> 0.944056
>
> ")
>
> krdata2$Year<-as.factor(krdata2$Year)
> aus.kr.pql2<-glmmPQL(freq ~ Treatment*Year, random = ~1|Pair/Treatment,
>                     correlation=corCAR1(form = ~Year|Pair/Treatment),
>                     family=binomial(link="logit"), weights=totalcontacts, data=krdata2)?
>
>
>
> ___________________________________________
> Charlotte Reemts, M.S.
> Research and Monitoring Ecologist
> creemts at tnc.org
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From poulin @ending from m@th@uni@tr@@fr  Wed Jun  6 16:13:05 2018
From: poulin @ending from m@th@uni@tr@@fr (poulin)
Date: Wed, 6 Jun 2018 16:13:05 +0200
Subject: [R-sig-ME] GLMM for proportions
Message-ID: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>

Dear list,

I have a question regarding GLMM's for proportion fitted with lme4.

Such models are fitted using the binomial family. When I fit such 
models, I use, on the left side of the formula : cbind(success,failure).

Problem is when, for example, data are durations (duration of success 
and duration of failure) that are not integer numbers if speaking in 
seconds.
When fitting a GLM, one can use directly in the left part of the formula 
a variable that is the proportion of success. When trying to do this for 
a GLMM one will have the warning message : ??In eval (family$initalize, 
rho): non-integer # successes in a binomial glm!??
To avoid this, biologists I work sometimes with, used ms instead of s 
for their duration times of success and failure but then the associated 
tests are too powerfull...
I am not able to tell if the displayed warning message is of concern or 
not.
So my question is : do you think it is better to use ms instead of s or 
directly the proportion?
Thanks in advance for any help that can be provided
Best regards

-- 
Nicolas Poulin
Ing?nieur de Recherche
Centre de Statistique de Strasbourg (CeStatS)
http://www.math.unistra.fr/CeStatS/

T?l : 03 68 85 0189

IRMA, UMR 7501
Universit? de Strasbourg et CNRS
7 rue Ren?-Descartes
67084 Strasbourg Cedex


From thierry@onkelinx @ending from inbo@be  Wed Jun  6 16:24:15 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 6 Jun 2018 16:24:15 +0200
Subject: [R-sig-ME] GLMM for proportions
In-Reply-To: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
References: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
Message-ID: <CAJuCY5xEuCVi74gpY-Hz7YGc+dr3r0ZPdRjTmUzTGoCL3b3skA@mail.gmail.com>

Dear Nicolas,

The cbind(success, failure) notation is used when we aggregate (sum)
the number of successes and failures. The data generating process
behind it, are a series of trials which result in either success or
failure. Hence their sum will be integer.

We need to know more about your data generating process in order to
give you sensible advice. Scaling the data by using different units is
wrong. Compare binom.test(c(1, 9)) and binom.test(c(1000, 9000)). Both
yield exactly the same proportion, but their confidence interval are
very different. Why? c(1000, 9000) is much more informative than c(1,
9).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-06 16:13 GMT+02:00 poulin <poulin at math.unistra.fr>:
> Dear list,
>
> I have a question regarding GLMM's for proportion fitted with lme4.
>
> Such models are fitted using the binomial family. When I fit such models, I
> use, on the left side of the formula : cbind(success,failure).
>
> Problem is when, for example, data are durations (duration of success and
> duration of failure) that are not integer numbers if speaking in seconds.
> When fitting a GLM, one can use directly in the left part of the formula a
> variable that is the proportion of success. When trying to do this for a
> GLMM one will have the warning message : ? In eval (family$initalize, rho):
> non-integer # successes in a binomial glm! ?
> To avoid this, biologists I work sometimes with, used ms instead of s for
> their duration times of success and failure but then the associated tests
> are too powerfull...
> I am not able to tell if the displayed warning message is of concern or not.
> So my question is : do you think it is better to use ms instead of s or
> directly the proportion?
> Thanks in advance for any help that can be provided
> Best regards
>
> --
> Nicolas Poulin
> Ing?nieur de Recherche
> Centre de Statistique de Strasbourg (CeStatS)
> http://www.math.unistra.fr/CeStatS/
>
> T?l : 03 68 85 0189
>
> IRMA, UMR 7501
> Universit? de Strasbourg et CNRS
> 7 rue Ren?-Descartes
> 67084 Strasbourg Cedex
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Wed Jun  6 16:27:48 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 6 Jun 2018 10:27:48 -0400
Subject: [R-sig-ME] GLMM for proportions
In-Reply-To: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
References: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
Message-ID: <a0c2faed-10d3-23ab-423a-3f9504ae00d4@gmail.com>


  Complementing Thierry Onkelinx's answer:

  This is more generally a GLM (rather than GLMM) question.

  Can you clarify a little bit more?  When you say "ms instead of s" do
you mean milliseconds rather than seconds?

  If you actually have durations, a Gamma(link="log") or plain
log-Normal analysis (i.e. log-transform and then linear model) might
work. In either case, values of exactly zero will be technically
problematic, and will require you to think a bit more about the
data-generating process.

  If you have fractions of a time interval then Beta regression might
work (in glmmTMB or brms or mgcv), or you can logit transform or
(old-fashionedly) arcsin-sqrt transform ...

On 2018-06-06 10:13 AM, poulin wrote:
> Dear list,
> 
> I have a question regarding GLMM's for proportion fitted with lme4.
> 
> Such models are fitted using the binomial family. When I fit such
> models, I use, on the left side of the formula : cbind(success,failure).
> 
> Problem is when, for example, data are durations (duration of success
> and duration of failure) that are not integer numbers if speaking in
> seconds.
> When fitting a GLM, one can use directly in the left part of the formula
> a variable that is the proportion of success. When trying to do this for
> a GLMM one will have the warning message : ??In eval (family$initalize,
> rho): non-integer # successes in a binomial glm!??
> To avoid this, biologists I work sometimes with, used ms instead of s
> for their duration times of success and failure but then the associated
> tests are too powerfull...
> I am not able to tell if the displayed warning message is of concern or
> not.
> So my question is : do you think it is better to use ms instead of s or
> directly the proportion?
> Thanks in advance for any help that can be provided
> Best regards
>


From poulin @ending from m@th@uni@tr@@fr  Wed Jun  6 16:33:36 2018
From: poulin @ending from m@th@uni@tr@@fr (poulin)
Date: Wed, 6 Jun 2018 16:33:36 +0200
Subject: [R-sig-ME] GLMM for proportions
In-Reply-To: <CAJuCY5xEuCVi74gpY-Hz7YGc+dr3r0ZPdRjTmUzTGoCL3b3skA@mail.gmail.com>
References: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
 <CAJuCY5xEuCVi74gpY-Hz7YGc+dr3r0ZPdRjTmUzTGoCL3b3skA@mail.gmail.com>
Message-ID: <eab27949-55b0-1d8a-c1e6-2fbb60922ea8@math.unistra.fr>

Thanks Thierry for this advice. Yes I was aware of this. Actually, the 
data were obtained by analysing videos frame by frame. The video's 
resolution was such that each frame "duration" is considered to be 
0.04s. My first advice to the biologists was to use the numbers of 
frames for both number of success and failure. They did not want this 
because they want to speak (and analyse) in term of real duration. 
Hence, using ms instead of frames is multiplying the number of attemps 
by 4.

They have publish the results last year 
(https://peerj.com/articles/3227/) but someone wrote to the editor to 
tell the statistical approach was wrong and to use directly the 
proportions in the GLMM. This person did not mention that, doing this, a 
warning message was displayed.

Best regards

Nicolas Poulin
Ing?nieur de Recherche
Centre de Statistique de Strasbourg (CeStatS)
http://www.math.unistra.fr/CeStatS/

T?l : 03 68 85 0189

IRMA, UMR 7501
Universit? de Strasbourg et CNRS
7 rue Ren?-Descartes
67084 Strasbourg Cedex
Le 06/06/2018 ? 16:24, Thierry Onkelinx a ?crit?:
> Dear Nicolas,
>
> The cbind(success, failure) notation is used when we aggregate (sum)
> the number of successes and failures. The data generating process
> behind it, are a series of trials which result in either success or
> failure. Hence their sum will be integer.
>
> We need to know more about your data generating process in order to
> give you sensible advice. Scaling the data by using different units is
> wrong. Compare binom.test(c(1, 9)) and binom.test(c(1000, 9000)). Both
> yield exactly the same proportion, but their confidence interval are
> very different. Why? c(1000, 9000) is much more informative than c(1,
> 9).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-06-06 16:13 GMT+02:00 poulin <poulin at math.unistra.fr>:
>> Dear list,
>>
>> I have a question regarding GLMM's for proportion fitted with lme4.
>>
>> Such models are fitted using the binomial family. When I fit such models, I
>> use, on the left side of the formula : cbind(success,failure).
>>
>> Problem is when, for example, data are durations (duration of success and
>> duration of failure) that are not integer numbers if speaking in seconds.
>> When fitting a GLM, one can use directly in the left part of the formula a
>> variable that is the proportion of success. When trying to do this for a
>> GLMM one will have the warning message : ? In eval (family$initalize, rho):
>> non-integer # successes in a binomial glm! ?
>> To avoid this, biologists I work sometimes with, used ms instead of s for
>> their duration times of success and failure but then the associated tests
>> are too powerfull...
>> I am not able to tell if the displayed warning message is of concern or not.
>> So my question is : do you think it is better to use ms instead of s or
>> directly the proportion?
>> Thanks in advance for any help that can be provided
>> Best regards
>>
>> --
>> Nicolas Poulin
>> Ing?nieur de Recherche
>> Centre de Statistique de Strasbourg (CeStatS)
>> http://www.math.unistra.fr/CeStatS/
>>
>> T?l : 03 68 85 0189
>>
>> IRMA, UMR 7501
>> Universit? de Strasbourg et CNRS
>> 7 rue Ren?-Descartes
>> 67084 Strasbourg Cedex
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From poulin @ending from m@th@uni@tr@@fr  Wed Jun  6 16:42:16 2018
From: poulin @ending from m@th@uni@tr@@fr (poulin)
Date: Wed, 6 Jun 2018 16:42:16 +0200
Subject: [R-sig-ME] GLMM for proportions
In-Reply-To: <a0c2faed-10d3-23ab-423a-3f9504ae00d4@gmail.com>
References: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
 <a0c2faed-10d3-23ab-423a-3f9504ae00d4@gmail.com>
Message-ID: <8efe586f-ccfe-62a8-7e4b-f1c38e25e3a7@math.unistra.fr>

Yes I mean milliseconds instead of seconds but I made a mistake. Its not 
milliseconds but 0.01s. My bad.

But as I explained in my second mail it's more going from fames (lasting 
0.04s) to 0.01 s.

Actually the main problem was that each video was not lasting the same 
time. Hence it is not possible to analyse time without reference to the 
total lasting of the video

Nicolas Poulin
Ing?nieur de Recherche
Centre de Statistique de Strasbourg (CeStatS)
http://www.math.unistra.fr/CeStatS/

T?l : 03 68 85 0189

IRMA, UMR 7501
Universit? de Strasbourg et CNRS
7 rue Ren?-Descartes
67084 Strasbourg Cedex
Le 06/06/2018 ? 16:27, Ben Bolker a ?crit?:
>    Complementing Thierry Onkelinx's answer:
>
>    This is more generally a GLM (rather than GLMM) question.
>
>    Can you clarify a little bit more?  When you say "ms instead of s" do
> you mean milliseconds rather than seconds?
>
>    If you actually have durations, a Gamma(link="log") or plain
> log-Normal analysis (i.e. log-transform and then linear model) might
> work. In either case, values of exactly zero will be technically
> problematic, and will require you to think a bit more about the
> data-generating process.
>
>    If you have fractions of a time interval then Beta regression might
> work (in glmmTMB or brms or mgcv), or you can logit transform or
> (old-fashionedly) arcsin-sqrt transform ...
>
> On 2018-06-06 10:13 AM, poulin wrote:
>> Dear list,
>>
>> I have a question regarding GLMM's for proportion fitted with lme4.
>>
>> Such models are fitted using the binomial family. When I fit such
>> models, I use, on the left side of the formula : cbind(success,failure).
>>
>> Problem is when, for example, data are durations (duration of success
>> and duration of failure) that are not integer numbers if speaking in
>> seconds.
>> When fitting a GLM, one can use directly in the left part of the formula
>> a variable that is the proportion of success. When trying to do this for
>> a GLMM one will have the warning message : ??In eval (family$initalize,
>> rho): non-integer # successes in a binomial glm!??
>> To avoid this, biologists I work sometimes with, used ms instead of s
>> for their duration times of success and failure but then the associated
>> tests are too powerfull...
>> I am not able to tell if the displayed warning message is of concern or
>> not.
>> So my question is : do you think it is better to use ms instead of s or
>> directly the proportion?
>> Thanks in advance for any help that can be provided
>> Best regards
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From chri@@@ @ending from med@umich@edu  Wed Jun  6 16:42:49 2018
From: chri@@@ @ending from med@umich@edu (Andrews, Chris)
Date: Wed, 6 Jun 2018 14:42:49 +0000
Subject: [R-sig-ME] GLMM for proportions
In-Reply-To: <CAJuCY5xEuCVi74gpY-Hz7YGc+dr3r0ZPdRjTmUzTGoCL3b3skA@mail.gmail.com>
References: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
 <CAJuCY5xEuCVi74gpY-Hz7YGc+dr3r0ZPdRjTmUzTGoCL3b3skA@mail.gmail.com>
Message-ID: <57fa3a1fc277415481e6206f871d8958@med.umich.edu>


And when Thierry says sum the number of success and failures, he is referring to outcomes of _independent_ trials.  It is unlikely that your counts of microseconds are from independent trials.

Chris

-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Sent: Wednesday, June 06, 2018 10:24 AM
To: poulin
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] GLMM for proportions

Dear Nicolas,

The cbind(success, failure) notation is used when we aggregate (sum)
the number of successes and failures. The data generating process
behind it, are a series of trials which result in either success or
failure. Hence their sum will be integer.

We need to know more about your data generating process in order to
give you sensible advice. Scaling the data by using different units is
wrong. Compare binom.test(c(1, 9)) and binom.test(c(1000, 9000)). Both
yield exactly the same proportion, but their confidence interval are
very different. Why? c(1000, 9000) is much more informative than c(1,
9).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-06 16:13 GMT+02:00 poulin <poulin at math.unistra.fr>:
> Dear list,
>
> I have a question regarding GLMM's for proportion fitted with lme4.
>
> Such models are fitted using the binomial family. When I fit such models, I
> use, on the left side of the formula : cbind(success,failure).
>
> Problem is when, for example, data are durations (duration of success and
> duration of failure) that are not integer numbers if speaking in seconds.
> When fitting a GLM, one can use directly in the left part of the formula a
> variable that is the proportion of success. When trying to do this for a
> GLMM one will have the warning message : ? In eval (family$initalize, rho):
> non-integer # successes in a binomial glm! ?
> To avoid this, biologists I work sometimes with, used ms instead of s for
> their duration times of success and failure but then the associated tests
> are too powerfull...
> I am not able to tell if the displayed warning message is of concern or not.
> So my question is : do you think it is better to use ms instead of s or
> directly the proportion?
> Thanks in advance for any help that can be provided
> Best regards
>
> --
> Nicolas Poulin
> Ing?nieur de Recherche
> Centre de Statistique de Strasbourg (CeStatS)
> http://www.math.unistra.fr/CeStatS/
>
> T?l : 03 68 85 0189
>
> IRMA, UMR 7501
> Universit? de Strasbourg et CNRS
> 7 rue Ren?-Descartes
> 67084 Strasbourg Cedex
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

From bbolker @ending from gm@il@com  Wed Jun  6 16:47:50 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 6 Jun 2018 10:47:50 -0400
Subject: [R-sig-ME] GLMM for proportions
In-Reply-To: <eab27949-55b0-1d8a-c1e6-2fbb60922ea8@math.unistra.fr>
References: <51055323-4b97-cc51-3cd0-9397841d6b57@math.unistra.fr>
 <CAJuCY5xEuCVi74gpY-Hz7YGc+dr3r0ZPdRjTmUzTGoCL3b3skA@mail.gmail.com>
 <eab27949-55b0-1d8a-c1e6-2fbb60922ea8@math.unistra.fr>
Message-ID: <3064bf4c-a5f6-201d-cac6-e2b2e95316e2@gmail.com>


  The problem even with using frames is that it's hard to believe that
the behaviour in one frame is independent of the behaviour in the next
(an assumption of the binomial response).  So I agree that a binomial
approach is probably wrong.

  Possibilities:

 - using a quasibinomial model would take care of at least some of the
non-independence problem
 - a Beta model
 - transformed ratios

On 2018-06-06 10:33 AM, poulin wrote:
> Thanks Thierry for this advice. Yes I was aware of this. Actually, the
> data were obtained by analysing videos frame by frame. The video's
> resolution was such that each frame "duration" is considered to be
> 0.04s. My first advice to the biologists was to use the numbers of
> frames for both number of success and failure. They did not want this
> because they want to speak (and analyse) in term of real duration.
> Hence, using ms instead of frames is multiplying the number of attemps
> by 4.
> 
> They have publish the results last year
> (https://peerj.com/articles/3227/) but someone wrote to the editor to
> tell the statistical approach was wrong and to use directly the
> proportions in the GLMM. This person did not mention that, doing this, a
> warning message was displayed.
> 
> Best regards
> 
> Nicolas Poulin
> Ing?nieur de Recherche
> Centre de Statistique de Strasbourg (CeStatS)
> http://www.math.unistra.fr/CeStatS/
> 
> T?l : 03 68 85 0189
> 
> IRMA, UMR 7501
> Universit? de Strasbourg et CNRS
> 7 rue Ren?-Descartes
> 67084 Strasbourg Cedex
> Le 06/06/2018 ? 16:24, Thierry Onkelinx a ?crit?:
>> Dear Nicolas,
>>
>> The cbind(success, failure) notation is used when we aggregate (sum)
>> the number of successes and failures. The data generating process
>> behind it, are a series of trials which result in either success or
>> failure. Hence their sum will be integer.
>>
>> We need to know more about your data generating process in order to
>> give you sensible advice. Scaling the data by using different units is
>> wrong. Compare binom.test(c(1, 9)) and binom.test(c(1000, 9000)). Both
>> yield exactly the same proportion, but their confidence interval are
>> very different. Why? c(1000, 9000) is much more informative than c(1,
>> 9).
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>>
>> 2018-06-06 16:13 GMT+02:00 poulin <poulin at math.unistra.fr>:
>>> Dear list,
>>>
>>> I have a question regarding GLMM's for proportion fitted with lme4.
>>>
>>> Such models are fitted using the binomial family. When I fit such
>>> models, I
>>> use, on the left side of the formula : cbind(success,failure).
>>>
>>> Problem is when, for example, data are durations (duration of success
>>> and
>>> duration of failure) that are not integer numbers if speaking in
>>> seconds.
>>> When fitting a GLM, one can use directly in the left part of the
>>> formula a
>>> variable that is the proportion of success. When trying to do this for a
>>> GLMM one will have the warning message : ? In eval (family$initalize,
>>> rho):
>>> non-integer # successes in a binomial glm! ?
>>> To avoid this, biologists I work sometimes with, used ms instead of s
>>> for
>>> their duration times of success and failure but then the associated
>>> tests
>>> are too powerfull...
>>> I am not able to tell if the displayed warning message is of concern
>>> or not.
>>> So my question is : do you think it is better to use ms instead of s or
>>> directly the proportion?
>>> Thanks in advance for any help that can be provided
>>> Best regards
>>>
>>> -- 
>>> Nicolas Poulin
>>> Ing?nieur de Recherche
>>> Centre de Statistique de Strasbourg (CeStatS)
>>> http://www.math.unistra.fr/CeStatS/
>>>
>>> T?l : 03 68 85 0189
>>>
>>> IRMA, UMR 7501
>>> Universit? de Strasbourg et CNRS
>>> 7 rue Ren?-Descartes
>>> 67084 Strasbourg Cedex
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From n@th@n@el@w@lker@h@le @ending from gm@il@com  Wed Jun  6 17:29:24 2018
From: n@th@n@el@w@lker@h@le @ending from gm@il@com (Nathanael Walker-Hale)
Date: Wed, 6 Jun 2018 11:29:24 -0400
Subject: [R-sig-ME] MCMCglmm: tissue type as a random effect when not all
 species have been measured for all tissuess
Message-ID: <CAO5TJMRXw3DjLd12pWEcVNNtAZy8QMgxurVRtjh7wsGYpDqpGA@mail.gmail.com>

Hi all,

I am planning to use MCMCglmm to do a phylogenetic comparative analysis. I
have multiple metabolite measurements on multiple tissue types per species
(e.g. leaf, three measurements, root, three measurements, per species). I
am interested in analyzing how levels of metabolite are predicted by the
presence or absence of a gene. Ideally, I would like to model both
between-species relationships (from a phylogeny) and tissue type as random
effects. However, not all species have measurements on all tissue types.

Will this be a problem for the analysis? Is it possible to run the model in
the presence of missing data like this? There is not a particularly heavy
bias to the pattern of missing tissue across the phylogeny, but some tissue
types have been measured much less than others (e.g. far fewer species have
floral measurements).

Best wishes,

Nathanael

	[[alternative HTML version deleted]]


From R@E@Crump @ending from w@rwick@@c@uk  Wed Jun  6 17:44:44 2018
From: R@E@Crump @ending from w@rwick@@c@uk (Crump, Ron)
Date: Wed, 6 Jun 2018 15:44:44 +0000
Subject: [R-sig-ME] GLMM for proportions
Message-ID: <DB6PR01MB37498FBE2EE909CCE19F8FB9FA650@DB6PR01MB3749.eurprd01.prod.exchangelabs.com>

> Thanks Thierry for this advice. Yes I was aware of this. Actually, the
> data were obtained by analysing videos frame by frame. The video's
> resolution was such that each frame "duration" is considered to be
> 0.04s. My first advice to the biologists was to use the numbers of
> frames for both number of success and failure. They did not want this
> because they want to speak (and analyse) in term of real duration.
> Hence, using ms instead of frames is multiplying the number of attemps
> by 4.

It seems more like a set of different time-series (one for each video) with
(0,1) data at each point (frame within video) rather than one observation
per video. So some random effects to model video and time? Auto-correlation
(does that work in a logistic GLMM?)? Random (video) intercepts? Plus some
other stuff.

Ron.

From bbolker @ending from gm@il@com  Wed Jun  6 17:46:42 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 6 Jun 2018 11:46:42 -0400
Subject: [R-sig-ME] 
 MCMCglmm: tissue type as a random effect when not all
 species have been measured for all tissuess
In-Reply-To: <CAO5TJMRXw3DjLd12pWEcVNNtAZy8QMgxurVRtjh7wsGYpDqpGA@mail.gmail.com>
References: <CAO5TJMRXw3DjLd12pWEcVNNtAZy8QMgxurVRtjh7wsGYpDqpGA@mail.gmail.com>
Message-ID: <ccd469e1-15cf-577c-d77a-52e819c1fb0e@gmail.com>


  In principle this kind of missing data is no problem, but it seems odd
to treat tissue type as random if (as I understand it) you only have two
types of tissue (root, leaf) ... Perhaps you have more? Even so (say you
had a few more), this would present both technical issues [you'd
probably need a moderately strongly informative prior on the
among-tissue variance], and it seems odd to me to treat tissues as
exchangeable.

On 2018-06-06 11:29 AM, Nathanael Walker-Hale wrote:
> Hi all,
> 
> I am planning to use MCMCglmm to do a phylogenetic comparative analysis. I
> have multiple metabolite measurements on multiple tissue types per species
> (e.g. leaf, three measurements, root, three measurements, per species). I
> am interested in analyzing how levels of metabolite are predicted by the
> presence or absence of a gene. Ideally, I would like to model both
> between-species relationships (from a phylogeny) and tissue type as random
> effects. However, not all species have measurements on all tissue types.
> 
> Will this be a problem for the analysis? Is it possible to run the model in
> the presence of missing data like this? There is not a particularly heavy
> bias to the pattern of missing tissue across the phylogeny, but some tissue
> types have been measured much less than others (e.g. far fewer species have
> floral measurements).
> 
> Best wishes,
> 
> Nathanael
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cri@@le@@@ndro @ending from gm@il@com  Wed Jun  6 18:45:01 2018
From: cri@@le@@@ndro @ending from gm@il@com (Cristiano Alessandro)
Date: Wed, 6 Jun 2018 11:45:01 -0500
Subject: [R-sig-ME] dropping interaction terms
Message-ID: <CAHhX7WgWE2SYSUWUtCmhDo+d64NuQWfEmNKkzh8qeTKFXUHVjw@mail.gmail.com>

Dear all,

I have a simple design with two factors (each with two levels) and their
interaction term. I am analyzing it with mixed models.

The interaction term is not significant. Do I need to fit another model
without the interaction term before performing post-hoc tests, or is it
more appropriate to perform post-hoc tests on the full model with the
non-significant interaction term?

Thanks for your help

Best
Cristiano

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Jun  6 18:34:34 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 6 Jun 2018 12:34:34 -0400
Subject: [R-sig-ME] dropping interaction terms
In-Reply-To: <CAHhX7WgWE2SYSUWUtCmhDo+d64NuQWfEmNKkzh8qeTKFXUHVjw@mail.gmail.com>
References: <CAHhX7WgWE2SYSUWUtCmhDo+d64NuQWfEmNKkzh8qeTKFXUHVjw@mail.gmail.com>
Message-ID: <b264604e-7f6b-1bc0-0d9a-3050833f09bd@gmail.com>


  This is really a broad linear modeling question rather than one that
applies specifically to mixed models.  Can I suggest that you try
CrossValidated [https://stats.stackexchange.com] ? (Be prepared for a
variety of opinions ...)

  cheers
    Ben Bolker

On 2018-06-06 12:45 PM, Cristiano Alessandro wrote:
> Dear all,
> 
> I have a simple design with two factors (each with two levels) and their
> interaction term. I am analyzing it with mixed models.
> 
> The interaction term is not significant. Do I need to fit another model
> without the interaction term before performing post-hoc tests, or is it
> more appropriate to perform post-hoc tests on the full model with the
> non-significant interaction term?
> 
> Thanks for your help
> 
> Best
> Cristiano
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cri@@le@@@ndro @ending from gm@il@com  Wed Jun  6 19:05:31 2018
From: cri@@le@@@ndro @ending from gm@il@com (Cristiano Alessandro)
Date: Wed, 6 Jun 2018 12:05:31 -0500
Subject: [R-sig-ME] dropping interaction terms
In-Reply-To: <b264604e-7f6b-1bc0-0d9a-3050833f09bd@gmail.com>
References: <CAHhX7WgWE2SYSUWUtCmhDo+d64NuQWfEmNKkzh8qeTKFXUHVjw@mail.gmail.com>
 <b264604e-7f6b-1bc0-0d9a-3050833f09bd@gmail.com>
Message-ID: <CAHhX7WgMxOeWoLz71o5hmS7TL90ebw278-fjbmC8nra9D1WJwg@mail.gmail.com>

It sounds like the question is controversial. Yes, I'll post it on cross
validated. Thanks!

On Wed, Jun 6, 2018 at 11:34 AM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   This is really a broad linear modeling question rather than one that
> applies specifically to mixed models.  Can I suggest that you try
> CrossValidated [https://stats.stackexchange.com] ? (Be prepared for a
> variety of opinions ...)
>
>   cheers
>     Ben Bolker
>
> On 2018-06-06 12:45 PM, Cristiano Alessandro wrote:
> > Dear all,
> >
> > I have a simple design with two factors (each with two levels) and their
> > interaction term. I am analyzing it with mixed models.
> >
> > The interaction term is not significant. Do I need to fit another model
> > without the interaction term before performing post-hoc tests, or is it
> > more appropriate to perform post-hoc tests on the full model with the
> > non-significant interaction term?
> >
> > Thanks for your help
> >
> > Best
> > Cristiano
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From n@th@n@el@w@lker@h@le @ending from gm@il@com  Wed Jun  6 19:07:19 2018
From: n@th@n@el@w@lker@h@le @ending from gm@il@com (Nathanael Walker-Hale)
Date: Wed, 6 Jun 2018 13:07:19 -0400
Subject: [R-sig-ME] 
 MCMCglmm: tissue type as a random effect when not all
 species have been measured for all tissuess
In-Reply-To: <ccd469e1-15cf-577c-d77a-52e819c1fb0e@gmail.com>
References: <CAO5TJMRXw3DjLd12pWEcVNNtAZy8QMgxurVRtjh7wsGYpDqpGA@mail.gmail.com>
 <ccd469e1-15cf-577c-d77a-52e819c1fb0e@gmail.com>
Message-ID: <CAO5TJMQGmUXdRN2vxFZVo18vz9ntXupTeY0xsR0rG=OErc5UOw@mail.gmail.com>

Hi Ben,

Thanks very much for your response. There are more tissues (six in all), I
just chose those as an example of the data format. I was under the
impression that the missing data would be a problem if attempting to treat
tissue type as fixed, but is this not the case? I have seen in other
threads the ways in which missing responses are imputed in MCMCglmm, and I
could perhaps merge tissue types into two or three classes (say root, shoot
and flower) and model them as fixed, if the missing data does not create
problems for the analysis.

Thanks again for your help,

Nathanael

On Wed, Jun 6, 2018 at 11:46 AM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   In principle this kind of missing data is no problem, but it seems odd
> to treat tissue type as random if (as I understand it) you only have two
> types of tissue (root, leaf) ... Perhaps you have more? Even so (say you
> had a few more), this would present both technical issues [you'd
> probably need a moderately strongly informative prior on the
> among-tissue variance], and it seems odd to me to treat tissues as
> exchangeable.
>
> On 2018-06-06 11:29 AM, Nathanael Walker-Hale wrote:
> > Hi all,
> >
> > I am planning to use MCMCglmm to do a phylogenetic comparative analysis.
> I
> > have multiple metabolite measurements on multiple tissue types per
> species
> > (e.g. leaf, three measurements, root, three measurements, per species). I
> > am interested in analyzing how levels of metabolite are predicted by the
> > presence or absence of a gene. Ideally, I would like to model both
> > between-species relationships (from a phylogeny) and tissue type as
> random
> > effects. However, not all species have measurements on all tissue types.
> >
> > Will this be a problem for the analysis? Is it possible to run the model
> in
> > the presence of missing data like this? There is not a particularly heavy
> > bias to the pattern of missing tissue across the phylogeny, but some
> tissue
> > types have been measured much less than others (e.g. far fewer species
> have
> > floral measurements).
> >
> > Best wishes,
> >
> > Nathanael
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Jun  6 19:09:06 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 6 Jun 2018 13:09:06 -0400
Subject: [R-sig-ME] 
 MCMCglmm: tissue type as a random effect when not all
 species have been measured for all tissuess
In-Reply-To: <CAO5TJMQGmUXdRN2vxFZVo18vz9ntXupTeY0xsR0rG=OErc5UOw@mail.gmail.com>
References: <CAO5TJMRXw3DjLd12pWEcVNNtAZy8QMgxurVRtjh7wsGYpDqpGA@mail.gmail.com>
 <ccd469e1-15cf-577c-d77a-52e819c1fb0e@gmail.com>
 <CAO5TJMQGmUXdRN2vxFZVo18vz9ntXupTeY0xsR0rG=OErc5UOw@mail.gmail.com>
Message-ID: <6302855b-f595-3cbe-fffc-faee304dbc6c@gmail.com>


  My guess is that it would be no problem to treat tissue as fixed and
species as random (and phylogenetically correlated) (and the
species:tissue interaction as random, so that you can model variation
within species -- **or** simply pool the multiple measurements from each
species/tissue combination, see Murtaugh "Simplicity and complexity in
ecological data analysis").
  Why not try it (maybe with a subset of your data) and see what happens?

On 2018-06-06 01:07 PM, Nathanael Walker-Hale wrote:
> Hi Ben,
> 
> Thanks very much for your response. There are more tissues (six in all),
> I just chose those as an example of the data format. I was under the
> impression that the missing data would be a problem if attempting to
> treat tissue type as fixed, but is this not the case? I have seen in
> other threads the ways in which missing responses are imputed in
> MCMCglmm, and I could perhaps merge tissue types into two or three
> classes (say root, shoot and flower) and model them as fixed, if the
> missing data does not create problems for the analysis.
> 
> Thanks again for your help,
> 
> Nathanael
> 
> On Wed, Jun 6, 2018 at 11:46 AM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>     ? In principle this kind of missing data is no problem, but it seems odd
>     to treat tissue type as random if (as I understand it) you only have two
>     types of tissue (root, leaf) ... Perhaps you have more? Even so (say you
>     had a few more), this would present both technical issues [you'd
>     probably need a moderately strongly informative prior on the
>     among-tissue variance], and it seems odd to me to treat tissues as
>     exchangeable.
> 
>     On 2018-06-06 11:29 AM, Nathanael Walker-Hale wrote:
>     > Hi all,
>     >
>     > I am planning to use MCMCglmm to do a phylogenetic comparative
>     analysis. I
>     > have multiple metabolite measurements on multiple tissue types per
>     species
>     > (e.g. leaf, three measurements, root, three measurements, per
>     species). I
>     > am interested in analyzing how levels of metabolite are predicted
>     by the
>     > presence or absence of a gene. Ideally, I would like to model both
>     > between-species relationships (from a phylogeny) and tissue type
>     as random
>     > effects. However, not all species have measurements on all tissue
>     types.
>     >
>     > Will this be a problem for the analysis? Is it possible to run the
>     model in
>     > the presence of missing data like this? There is not a
>     particularly heavy
>     > bias to the pattern of missing tissue across the phylogeny, but
>     some tissue
>     > types have been measured much less than others (e.g. far fewer
>     species have
>     > floral measurements).
>     >
>     > Best wishes,
>     >
>     > Nathanael
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
>


From n@th@n@el@w@lker@h@le @ending from gm@il@com  Wed Jun  6 19:29:56 2018
From: n@th@n@el@w@lker@h@le @ending from gm@il@com (Nathanael Walker-Hale)
Date: Wed, 6 Jun 2018 13:29:56 -0400
Subject: [R-sig-ME] 
 MCMCglmm: tissue type as a random effect when not all
 species have been measured for all tissuess
In-Reply-To: <6302855b-f595-3cbe-fffc-faee304dbc6c@gmail.com>
References: <CAO5TJMRXw3DjLd12pWEcVNNtAZy8QMgxurVRtjh7wsGYpDqpGA@mail.gmail.com>
 <ccd469e1-15cf-577c-d77a-52e819c1fb0e@gmail.com>
 <CAO5TJMQGmUXdRN2vxFZVo18vz9ntXupTeY0xsR0rG=OErc5UOw@mail.gmail.com>
 <6302855b-f595-3cbe-fffc-faee304dbc6c@gmail.com>
Message-ID: <CAO5TJMQ4H2GoNmZtxBmeYOjVmtg1nWpk2b6EG_N4tM=8daNtTg@mail.gmail.com>

Thank you! I will.

On Wed, Jun 6, 2018 at 1:09 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   My guess is that it would be no problem to treat tissue as fixed and
> species as random (and phylogenetically correlated) (and the
> species:tissue interaction as random, so that you can model variation
> within species -- **or** simply pool the multiple measurements from each
> species/tissue combination, see Murtaugh "Simplicity and complexity in
> ecological data analysis").
>   Why not try it (maybe with a subset of your data) and see what happens?
>
> On 2018-06-06 01:07 PM, Nathanael Walker-Hale wrote:
> > Hi Ben,
> >
> > Thanks very much for your response. There are more tissues (six in all),
> > I just chose those as an example of the data format. I was under the
> > impression that the missing data would be a problem if attempting to
> > treat tissue type as fixed, but is this not the case? I have seen in
> > other threads the ways in which missing responses are imputed in
> > MCMCglmm, and I could perhaps merge tissue types into two or three
> > classes (say root, shoot and flower) and model them as fixed, if the
> > missing data does not create problems for the analysis.
> >
> > Thanks again for your help,
> >
> > Nathanael
> >
> > On Wed, Jun 6, 2018 at 11:46 AM, Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >
> >       In principle this kind of missing data is no problem, but it seems
> odd
> >     to treat tissue type as random if (as I understand it) you only have
> two
> >     types of tissue (root, leaf) ... Perhaps you have more? Even so (say
> you
> >     had a few more), this would present both technical issues [you'd
> >     probably need a moderately strongly informative prior on the
> >     among-tissue variance], and it seems odd to me to treat tissues as
> >     exchangeable.
> >
> >     On 2018-06-06 11:29 AM, Nathanael Walker-Hale wrote:
> >     > Hi all,
> >     >
> >     > I am planning to use MCMCglmm to do a phylogenetic comparative
> >     analysis. I
> >     > have multiple metabolite measurements on multiple tissue types per
> >     species
> >     > (e.g. leaf, three measurements, root, three measurements, per
> >     species). I
> >     > am interested in analyzing how levels of metabolite are predicted
> >     by the
> >     > presence or absence of a gene. Ideally, I would like to model both
> >     > between-species relationships (from a phylogeny) and tissue type
> >     as random
> >     > effects. However, not all species have measurements on all tissue
> >     types.
> >     >
> >     > Will this be a problem for the analysis? Is it possible to run the
> >     model in
> >     > the presence of missing data like this? There is not a
> >     particularly heavy
> >     > bias to the pattern of missing tissue across the phylogeny, but
> >     some tissue
> >     > types have been measured much less than others (e.g. far fewer
> >     species have
> >     > floral measurements).
> >     >
> >     > Best wishes,
> >     >
> >     > Nathanael
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
>

	[[alternative HTML version deleted]]


From j@orkin @ending from @om@um@ryl@nd@edu  Wed Jun  6 20:45:13 2018
From: j@orkin @ending from @om@um@ryl@nd@edu (Sorkin, John)
Date: Wed, 6 Jun 2018 18:45:13 +0000
Subject: [R-sig-ME] dropping interaction terms
In-Reply-To: <CAHhX7WgMxOeWoLz71o5hmS7TL90ebw278-fjbmC8nra9D1WJwg@mail.gmail.com>
References: <CAHhX7WgWE2SYSUWUtCmhDo+d64NuQWfEmNKkzh8qeTKFXUHVjw@mail.gmail.com>
 <b264604e-7f6b-1bc0-0d9a-3050833f09bd@gmail.com>,
 <CAHhX7WgMxOeWoLz71o5hmS7TL90ebw278-fjbmC8nra9D1WJwg@mail.gmail.com>
Message-ID: <CO2PR03MB22328DA0624F3F861A18ABF6E2650@CO2PR03MB2232.namprd03.prod.outlook.com>

Cristiano,


Your question has no absolutely correct answer.


If you have reason to believe that there is an interaction, even though your model does not demonstrate a significant interaction, you could justify leaving the interaction in the model and doing your post hoc tests. If you believe that the result you obtained regarding the interaction, that the interaction is not significant, then it would be most appropriate to drop the interaction, re-run the model and do your post-hoc tests.


Why would you want to do post hoc tests in a model that contains an interaction, an interaction that the model indicates is not significant, unless you have other data that lead you to believe that the interaction represents physical truth? If you have other data suggesting that the interaction does in fact represent reality (even though your data do not support this) you might want to include the interaction in you post hoc tests to as to most accurately model reality.


The above represents on old statistician's opinion. Like much in statistics the answer to your question reflects that fact that much of statistics is art rather than science.


John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Cristiano Alessandro <cri.alessandro at gmail.com>
Sent: Wednesday, June 6, 2018 1:05 PM
To: Ben Bolker
Cc: R Mixed Models
Subject: Re: [R-sig-ME] dropping interaction terms

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



It sounds like the question is controversial. Yes, I'll post it on cross
validated. Thanks!

On Wed, Jun 6, 2018 at 11:34 AM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   This is really a broad linear modeling question rather than one that
> applies specifically to mixed models.  Can I suggest that you try
> CrossValidated [https://stats.stackexchange.com] ? (Be prepared for a
> variety of opinions ...)
>
>   cheers
>     Ben Bolker
>
> On 2018-06-06 12:45 PM, Cristiano Alessandro wrote:
> > Dear all,
> >
> > I have a simple design with two factors (each with two levels) and their
> > interaction term. I am analyzing it with mixed models.
> >
> > The interaction term is not significant. Do I need to fit another model
> > without the interaction term before performing post-hoc tests, or is it
> > more appropriate to perform post-hoc tests on the full model with the
> > non-significant interaction term?
> >
> > Thanks for your help
> >
> > Best
> > Cristiano
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From cri@@le@@@ndro @ending from gm@il@com  Wed Jun  6 23:30:13 2018
From: cri@@le@@@ndro @ending from gm@il@com (Cristiano Alessandro)
Date: Wed, 6 Jun 2018 16:30:13 -0500
Subject: [R-sig-ME] p-values from model fitting or glht?
Message-ID: <CAHhX7Wj5XZPuzFnTWjBD0L+WYsbnrRaAwwv2vLiL+QyTXtvsEg@mail.gmail.com>

Hi all,

I am running a mixed model to compare two groups. This is repeated measure
design. The model is very simple:

linM11 <- lme(values ~ grf, random = ~1|id, data=dat_trf,
na.action=na.omit, method = "ML", control=lCtr )

where grf is a factor with two levels. I am asking if the two levels are
significantly different. When I call summary() I obtain (among the other
things):

> summary(linM11)

Fixed effects: values ~ grf
                 Value         Std.Error    DF  t-value      p-value
(Intercept) -8.513064 0.9908567 16   -8.59162   0.0000
grf1            3.027705 1.4158346 15     2.13846   0.0493

which makes me think that the two groups are barely significantly
different. But If I run this post-hoc test I get this other (quite
different) result:

> ph_conditional <- c("grf1 = 0");
> linM.ph <- glht(linM, linfct = ph_conditional);
> summary(linM.ph)

Linear Hypotheses:
                  Estimate   Std. Error   z value    Pr(>|z|)
grf1 == 0    3.028        1.372         2.206      0.0274 *

Which one should I trust? I am always confused on whether I should use the
p-values of the model fit or those of the post-hoc tests. If I had multiple
tests, I would certainly run the post-hoc and adjust for multiple
comparisons (with glht). But here there is only one test, and I am not sure
why I get so different results, and which one I should trust.

Thanks
Cristiano

	[[alternative HTML version deleted]]


From j@orkin @ending from @om@um@ryl@nd@edu  Thu Jun  7 02:14:50 2018
From: j@orkin @ending from @om@um@ryl@nd@edu (Sorkin, John)
Date: Thu, 7 Jun 2018 00:14:50 +0000
Subject: [R-sig-ME] p-values from model fitting or glht?
In-Reply-To: <CAHhX7Wj5XZPuzFnTWjBD0L+WYsbnrRaAwwv2vLiL+QyTXtvsEg@mail.gmail.com>
References: <CAHhX7Wj5XZPuzFnTWjBD0L+WYsbnrRaAwwv2vLiL+QyTXtvsEg@mail.gmail.com>
Message-ID: <CO2PR03MB2232210DDE644D1B1E30E7A0E2640@CO2PR03MB2232.namprd03.prod.outlook.com>

Cristiano,


Is the difference in the p value simply due to the difference in the tests that are being done? The summary statistic is using a Student's t-test which for 15 degrees of freedom for a two-tailed p value of 0.05 has a critical value of 2.131 while the post-hoc test is performed using a z-test which for a two-tailed p value of 0.05 has a critical value of 1.96. One should also note the the SE for the summary statistic is 1.42 while the SE for the post-hoc test is 1.37. I don't know why these values are different; I suspect they are calculated differently.


For small sample sizes Wald's statistic (the difference of two means divided by the SE of the difference, which when applied to the post-hoc test is equivalent to a z test) can be too liberal. For these cases, a likelihood ratio test has been recommended to me.


I hope this helps, or at least does not confuse.

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Cristiano Alessandro <cri.alessandro at gmail.com>
Sent: Wednesday, June 6, 2018 5:30 PM
To: R Mixed Models
Subject: [R-sig-ME] p-values from model fitting or glht?

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



Hi all,

I am running a mixed model to compare two groups. This is repeated measure
design. The model is very simple:

linM11 <- lme(values ~ grf, random = ~1|id, data=dat_trf,
na.action=na.omit, method = "ML", control=lCtr )

where grf is a factor with two levels. I am asking if the two levels are
significantly different. When I call summary() I obtain (among the other
things):

> summary(linM11)

Fixed effects: values ~ grf
                 Value         Std.Error    DF  t-value      p-value
(Intercept) -8.513064 0.9908567 16   -8.59162   0.0000
grf1            3.027705 1.4158346 15     2.13846   0.0493

which makes me think that the two groups are barely significantly
different. But If I run this post-hoc test I get this other (quite
different) result:

> ph_conditional <- c("grf1 = 0");
> linM.ph <- glht(linM, linfct = ph_conditional);
> summary(linM.ph)

Linear Hypotheses:
                  Estimate   Std. Error   z value    Pr(>|z|)
grf1 == 0    3.028        1.372         2.206      0.0274 *

Which one should I trust? I am always confused on whether I should use the
p-values of the model fit or those of the post-hoc tests. If I had multiple
tests, I would certainly run the post-hoc and adjust for multiple
comparisons (with glht). But here there is only one test, and I am not sure
why I get so different results, and which one I should trust.

Thanks
Cristiano

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Thu Jun  7 16:00:48 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Thu, 7 Jun 2018 16:00:48 +0200
Subject: [R-sig-ME] Group level predictors
Message-ID: <CAOE=hq+ApNJVAsRfWmeyjo0ZWzsLQEJrfxafnE=n88H7Hk6WmQ@mail.gmail.com>

Hello,

I had recently posted the following for understanding the syntax for adding
group-level predictors in a random intercept model:

"""""

Hi,
I am working with a random intercept model. I have the usual "X" vector of
covariates and one id variable which will make up the random intercept. Now
I wish to add group-level predictors (which are NOT in the X vector) such
that the random intercept depends on these predictors.
For example,
Response variable: Production of maize
Covariate: Size of plot
Group-level predictor: Age of farmer
ID variable: Household_ID

I wish to confirm the syntax for including the group-level "Age of farmer"
variable.
fit<-lmer(Production~ Size+ Age+ (1|Household_ID), data=data)

Is this correct or is there another way of declaring the group-level
predictor in the formula?

"""""

This syntax had been confirmed as correct. Now I am wondering how does lmer
really distinguish between the usual X covariates and group-level
predictors? We have not really differentiated them in the formula. How does
lmer construe Age to only impact the random intercept?

Thank you very much,

Regards,

Yashree

	[[alternative HTML version deleted]]


From mr@luced@n @ending from hotm@il@it  Fri Jun  8 15:17:48 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Fri, 8 Jun 2018 13:17:48 +0000
Subject: [R-sig-ME] Different p_values from between groups to within groups
Message-ID: <DB3PR0402MB38517D78B212FDA7B55A4947F67B0@DB3PR0402MB3851.eurprd04.prod.outlook.com>

Hello everybody,

may I ask you a suggestion on how to interpret a weird result I have?

I have 3 groups (ExpertiseType), and through the use of contrast hypotheses, the first model gives me this output:

model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), database, REML=TRUE)
                                                                  Pr(>|t|)
Closurecl_c1:ExpertiseTypeexp_c1    0.42203
Closurecl_c2:ExpertiseTypeexp_c1    0.00601 **
Closurecl_c3:ExpertiseTypeexp_c1   9.32e-08 ***

Another, more detailed model, gives me the following:

model = lmer(Score~Closure*ExpertiseType+ExpertiseType*LastPosition+Closure*LastPosition+(1|Participant)+(1|Item), database, REML=TRUE)

                                                                  Pr(>|t|)
Closurecl_c1:ExpertiseTypeexp_c1    0.50738
Closurecl_c2:ExpertiseTypeexp_c1    0.01059 *
Closurecl_c3:ExpertiseTypeexp_c1   4.05e-08 ***

As you can notice, I have an interaction in both analyses, but if I look for the same contrast hypotheses within the group for which I have the interaction, the Closurecl_c2 effect disappeares.

model = lmer(Score~Closure*LastPosition+(1|Participant)+(1|Item), subset(database, ExpertiseType==3), REML=TRUE)

                           Pr(>|t|)
Closurecl_c1      0.4411
Closurecl_c2      0.1419
Closurecl_c3   5.00e-07 ***

Which one should I consider the most reliable output?
Or, alternatively, what does this difference mean? I really don't know how to interpret this outcome. I was expecting that within groups, the analysis would get more defined.

Best
Luca



	[[alternative HTML version deleted]]


From liumeng @ending from u@c@edu  Sat Jun  9 21:06:32 2018
From: liumeng @ending from u@c@edu (Meng Liu)
Date: Sat, 9 Jun 2018 15:06:32 -0400
Subject: [R-sig-ME] fitting beta and zero mixture model containing both
 nested and crossed random effects
Message-ID: <CAMdkWR9Ns-3W7dgDXJnBp5kcGP_u7q+d9scXD5xCgeeHUmnh7w@mail.gmail.com>

To whom it may concern,

I am trying to fit a model for a data among which the response value is
within [0,1). I am thinking about fitting the zeros as a complete separate
category from the non-zero data, i.e. a binomial (Bernoulli) model to "==0
vs >0" and a Beta model to the >0 responses. Also, my data contains both
nested factors and crossed factors, which means I need to add nested random
effects and crossed random effects to both logistic model part and beta
model model. However, I didn't find any R packages can do exactly what I
want (By far I found gamlss, glmmTMB, zoib but they either can only assume
random zero or they can only fit repeated measures/clustered data but not
nested and crossed design). Therefore, I am wondering if any one know if
there is any available package or function can do this.

Thank you very much for your help!

Best regards

Meng

	[[alternative HTML version deleted]]


From guill@umech@umet @ending from gm@il@com  Sun Jun 10 17:04:22 2018
From: guill@umech@umet @ending from gm@il@com (Guillaume Chaumet)
Date: Sun, 10 Jun 2018 17:04:22 +0200
Subject: [R-sig-ME] Fwd: fitting beta and zero mixture model containing both
 nested and crossed random effects
In-Reply-To: <CAGg8SkL4VETeKEsmsz1z=Av6zfTU0mhv_UasUyDk0xhaJ0HxwQ@mail.gmail.com>
References: <CAMdkWR9Ns-3W7dgDXJnBp5kcGP_u7q+d9scXD5xCgeeHUmnh7w@mail.gmail.com>
 <CAGg8SkL4VETeKEsmsz1z=Av6zfTU0mhv_UasUyDk0xhaJ0HxwQ@mail.gmail.com>
Message-ID: <CAGg8SkJ8T4OJuB46bkr1GE0d=CE+YYoFFRxBha+NeFdJseQZRQ@mail.gmail.com>

---------- Forwarded message ----------
From: Guillaume Chaumet <guillaumechaumet at gmail.com>
Date: 2018-06-10 17:03 GMT+02:00
Subject: Re: [R-sig-ME] fitting beta and zero mixture model containing
both nested and crossed random effects
To: Meng Liu <liumeng at usc.edu>


brms: https://cran.r-project.org/web/packages/brms/index.html

2018-06-09 21:06 GMT+02:00 Meng Liu <liumeng at usc.edu>:
> To whom it may concern,
>
> I am trying to fit a model for a data among which the response value is
> within [0,1). I am thinking about fitting the zeros as a complete separate
> category from the non-zero data, i.e. a binomial (Bernoulli) model to "==0
> vs >0" and a Beta model to the >0 responses. Also, my data contains both
> nested factors and crossed factors, which means I need to add nested random
> effects and crossed random effects to both logistic model part and beta
> model model. However, I didn't find any R packages can do exactly what I
> want (By far I found gamlss, glmmTMB, zoib but they either can only assume
> random zero or they can only fit repeated measures/clustered data but not
> nested and crossed design). Therefore, I am wondering if any one know if
> there is any available package or function can do this.
>
> Thank you very much for your help!
>
> Best regards
>
> Meng
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From y@@hree19 @ending from gm@il@com  Sun Jun 10 19:00:21 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Sun, 10 Jun 2018 19:00:21 +0200
Subject: [R-sig-ME] Group-level predictors which impact the random intercept
Message-ID: <CAOE=hqLZEgS505eExANNtr-pFOiFt7AzuWpdHov+i5snHJei=Q@mail.gmail.com>

Hello,

I had recently posted the following for understanding the syntax for adding
group-level predictors in a random intercept model:

"""""

Hi,
I am working with a random intercept model. I have the usual "X" vector of
covariates and one id variable which will make up the random intercept. Now
I wish to add group-level predictors (which are NOT in the X vector) such
that the random intercept depends on these predictors.
For example,
Response variable: Production of maize
Covariate: Size of plot
Group-level predictor: Age of farmer
ID variable: Household_ID

I wish to confirm the syntax for including the group-level "Age of farmer"
variable.
fit<-lmer(Production~ Size+ Age+ (1|Household_ID), data=data)

Is this correct or is there another way of declaring the group-level
predictor in the formula?

"""""

This syntax had been confirmed as correct. Now I am wondering how does lmer
really distinguish between the usual X covariates and group-level
predictors? We have not really differentiated them in the formula. How does
lmer construe Age to only impact the random intercept?

Thank you very much,

Regards,

Yashree

	[[alternative HTML version deleted]]


From d@vid@tn@jone@ @ending from gm@il@com  Mon Jun 11 15:59:24 2018
From: d@vid@tn@jone@ @ending from gm@il@com (David Jones)
Date: Mon, 11 Jun 2018 08:59:24 -0500
Subject: [R-sig-ME] Non-Normal and Heteroskedastic Residuals in Longitudinal
 Model Due to Non-Normal DV - Percentile Bootstrap Sufficient,
 or Wild Bootstrap Needed?
Message-ID: <CAJgUswJEqP2zq060uTjjh8iiStaU9xX7GJ+cN-b5mwT74xsSfw@mail.gmail.com>

I am looking to model quality of life (QOL) as a DV over time. The DV
shows strong negative skew. I am wondering about the best way to
handle this (more detail below). Frequency distribution of QOL and
example code are also at the end of this message.

Many participants just say that their quality of life is great, and
thus there is a ceiling effect with many values clustered at the
highest value. While the distribution resembles y=e^x, I have not been
able to fit a distribution via GLMM that results in normally
distributed and homoskedastic residuals (including gamma and inverse
gaussian). A number of DV transformations have not worked either
(e.g., log, exponential, Box-Cox), in large part because of the large
proportion of values at the maximum level of QOL, which creates a
spike at the end of the distribution. I could try zero-inflated models
by transforming the dv (multiply by -1 and put the starting value at
0), but even then there will still be a disproportionate number of
values clustered at one end.

My question: I am particularly interested in fixed effects parameters
from a longitudinal model, and was thinking of testing these
parameters by using percentile bootstrap CIs via confint(). However,
the residuals from a lmer model are both non-normal and
heteroskedastic - will percentile bootstrap of beta coefficients
address this, or can only the wild bootstrap address these issues (as
it is targeted to residuals)? I have a basic understanding of the
bootstrap but am not an expert regarding its use in linear models.

Many thanks!




# Example lmer code
model <- lmer(QOL ~ poly(time, 2) + (time | ID), data=dataset, REML =
FALSE )


# Frequency distribution

QOL    valid_percent
25    0.000308261
30    0.000308261
32    0.000308261
34    0.000616523
38    0.000308261
41    0.000308261
45    0.000308261
46    0.000308261
47    0.000308261
48    0.000616523
49    0.000616523
50    0.000616523
51    0.000308261
52    0.000308261
53    0.001541307
54    0.000616523
55    0.001233046
56    0.000616523
57    0.000924784
58    0.000308261
59    0.000924784
60    0.000924784
61    0.001849568
62    0.001541307
63    0.003082614
64    0.001849568
65    0.00215783
66    0.002466091
67    0.004007398
68    0.002466091
69    0.004007398
70    0.002466091
71    0.003699137
72    0.006781751
73    0.004932183
74    0.006781751
75    0.006165228
76    0.007090012
77    0.007706535
78    0.008631319
79    0.010789149
80    0.015104809
81    0.014488286
82    0.01541307
83    0.020345253
84    0.025893958
85    0.03298397
86    0.036066585
87    0.053020962
88    0.064426634
89    0.080147966
90    0.088779285
91    0.452219482


From b@te@ @ending from @t@t@wi@c@edu  Mon Jun 11 18:11:04 2018
From: b@te@ @ending from @t@t@wi@c@edu (Douglas Bates)
Date: Mon, 11 Jun 2018 11:11:04 -0500
Subject: [R-sig-ME] 
 Group-level predictors which impact the random intercept
In-Reply-To: <20210_1528650038_0PA40023A9X0XZ10_CAOE=hqLZEgS505eExANNtr-pFOiFt7AzuWpdHov+i5snHJei=Q@mail.gmail.com>
References: <20210_1528650038_0PA40023A9X0XZ10_CAOE=hqLZEgS505eExANNtr-pFOiFt7AzuWpdHov+i5snHJei=Q@mail.gmail.com>
Message-ID: <CAO7JsnT0Ug8vR0N3Z3BK5saXKM34y2Z1BLL1ovR6yah0ty9wxg@mail.gmail.com>

Thank you for transferring the discussion over to the R-SIG-Mixed-Models
group.

As I mentioned in the email discussion, the issue of covariates in the
fixed-effects terms and whether or not they vary within the levels of a
grouping factor for random-effects terms is a consequence of the way the
model is described in the multilevel modeling literature.  In other words,
there is no inherent problem with defining a mixed-effects model involving
a fixed-effect for Age even though Age does not change within
Household_ID.  When multilevel models were being formulated many years ago
an approach to how one would estimate the parameters leaked over into the
model definition.  It became important to formulate models within models
within ... but that approach is unnecessary and led to many
misconceptions.  Furthermore, the approach is too restrictive.   A
multilevel model cannot accommodate crossed random effects, such as subject
and item, or partially crossed random effects such as child, teacher and
school in longitudinal data.

To me one of the most important innovations in the lme4 package was to
reformulate the evaluation of the deviance for a linear mixed-effects model
as a penalized least squares problem and to employ a sparse Cholesky
factorization to solve a modified version of Henderson's mixed-model
equations.  This is described in our 2015 J. of Statistical Software
paper.  It is not important for every user of the lme4 package to
understand the mathematics of the derivation but it helps to know that the
model can be formulated and the parameters can be estimated as described
there.  The fact that other and, I think it is fair to say, inferior
formulations and estimation methods exist is not relevant.

On Sun, Jun 10, 2018 at 12:00 PM Yashree Mehta <yashree19 at gmail.com> wrote:

> Hello,
>
> I had recently posted the following for understanding the syntax for adding
> group-level predictors in a random intercept model:
>
> """""
>
> Hi,
> I am working with a random intercept model. I have the usual "X" vector of
> covariates and one id variable which will make up the random intercept. Now
> I wish to add group-level predictors (which are NOT in the X vector) such
> that the random intercept depends on these predictors.
> For example,
> Response variable: Production of maize
> Covariate: Size of plot
> Group-level predictor: Age of farmer
> ID variable: Household_ID
>
> I wish to confirm the syntax for including the group-level "Age of farmer"
> variable.
> fit<-lmer(Production~ Size+ Age+ (1|Household_ID), data=data)
>
> Is this correct or is there another way of declaring the group-level
> predictor in the formula?
>
> """""
>
> This syntax had been confirmed as correct. Now I am wondering how does lmer
> really distinguish between the usual X covariates and group-level
> predictors? We have not really differentiated them in the formula. How does
> lmer construe Age to only impact the random intercept?
>
> Thank you very much,
>
> Regards,
>
> Yashree
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Tue Jun 12 03:55:48 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 11 Jun 2018 21:55:48 -0400
Subject: [R-sig-ME] 
 Fwd: fitting beta and zero mixture model containing both
 nested and crossed random effects
In-Reply-To: <CAGg8SkJ8T4OJuB46bkr1GE0d=CE+YYoFFRxBha+NeFdJseQZRQ@mail.gmail.com>
References: <CAMdkWR9Ns-3W7dgDXJnBp5kcGP_u7q+d9scXD5xCgeeHUmnh7w@mail.gmail.com>
 <CAGg8SkL4VETeKEsmsz1z=Av6zfTU0mhv_UasUyDk0xhaJ0HxwQ@mail.gmail.com>
 <CAGg8SkJ8T4OJuB46bkr1GE0d=CE+YYoFFRxBha+NeFdJseQZRQ@mail.gmail.com>
Message-ID: <CABghstSyQMXV83BVV+22adJY_=X=4S-CTzDcGzANjzPjF3Tm6w@mail.gmail.com>

I think Guillaume is right that brms can do this, but  I don't see why
glmmTMB *can't* do all of this (fixed and (nested and/or crossed
random effects)) in both the binomial (logistic) and beta components)

On Sun, Jun 10, 2018 at 11:04 AM, Guillaume Chaumet
<guillaumechaumet at gmail.com> wrote:
> ---------- Forwarded message ----------
> From: Guillaume Chaumet <guillaumechaumet at gmail.com>
> Date: 2018-06-10 17:03 GMT+02:00
> Subject: Re: [R-sig-ME] fitting beta and zero mixture model containing
> both nested and crossed random effects
> To: Meng Liu <liumeng at usc.edu>
>
>
> brms: https://cran.r-project.org/web/packages/brms/index.html
>
> 2018-06-09 21:06 GMT+02:00 Meng Liu <liumeng at usc.edu>:
>> To whom it may concern,
>>
>> I am trying to fit a model for a data among which the response value is
>> within [0,1). I am thinking about fitting the zeros as a complete separate
>> category from the non-zero data, i.e. a binomial (Bernoulli) model to "==0
>> vs >0" and a Beta model to the >0 responses. Also, my data contains both
>> nested factors and crossed factors, which means I need to add nested random
>> effects and crossed random effects to both logistic model part and beta
>> model model. However, I didn't find any R packages can do exactly what I
>> want (By far I found gamlss, glmmTMB, zoib but they either can only assume
>> random zero or they can only fit repeated measures/clustered data but not
>> nested and crossed design). Therefore, I am wondering if any one know if
>> there is any available package or function can do this.
>>
>> Thank you very much for your help!
>>
>> Best regards
>>
>> Meng
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From y@@hree19 @ending from gm@il@com  Tue Jun 12 12:25:51 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Tue, 12 Jun 2018 12:25:51 +0200
Subject: [R-sig-ME] 
 Group-level predictors which impact the random intercept
In-Reply-To: <CAO7JsnT0Ug8vR0N3Z3BK5saXKM34y2Z1BLL1ovR6yah0ty9wxg@mail.gmail.com>
References: <20210_1528650038_0PA40023A9X0XZ10_CAOE=hqLZEgS505eExANNtr-pFOiFt7AzuWpdHov+i5snHJei=Q@mail.gmail.com>
 <CAO7JsnT0Ug8vR0N3Z3BK5saXKM34y2Z1BLL1ovR6yah0ty9wxg@mail.gmail.com>
Message-ID: <CAOE=hqKYZknrSi+yKStJoUMgxBDEDVV8m=DHVSe8N+bos+2VdA@mail.gmail.com>

Thank you very much for your response and explanation.

Regards,
Yashree

On Mon, Jun 11, 2018 at 6:11 PM, Douglas Bates <bates at stat.wisc.edu> wrote:

> Thank you for transferring the discussion over to the R-SIG-Mixed-Models
> group.
>
> As I mentioned in the email discussion, the issue of covariates in the
> fixed-effects terms and whether or not they vary within the levels of a
> grouping factor for random-effects terms is a consequence of the way the
> model is described in the multilevel modeling literature.  In other words,
> there is no inherent problem with defining a mixed-effects model involving
> a fixed-effect for Age even though Age does not change within
> Household_ID.  When multilevel models were being formulated many years ago
> an approach to how one would estimate the parameters leaked over into the
> model definition.  It became important to formulate models within models
> within ... but that approach is unnecessary and led to many
> misconceptions.  Furthermore, the approach is too restrictive.   A
> multilevel model cannot accommodate crossed random effects, such as subject
> and item, or partially crossed random effects such as child, teacher and
> school in longitudinal data.
>
> To me one of the most important innovations in the lme4 package was to
> reformulate the evaluation of the deviance for a linear mixed-effects model
> as a penalized least squares problem and to employ a sparse Cholesky
> factorization to solve a modified version of Henderson's mixed-model
> equations.  This is described in our 2015 J. of Statistical Software
> paper.  It is not important for every user of the lme4 package to
> understand the mathematics of the derivation but it helps to know that the
> model can be formulated and the parameters can be estimated as described
> there.  The fact that other and, I think it is fair to say, inferior
> formulations and estimation methods exist is not relevant.
>
> On Sun, Jun 10, 2018 at 12:00 PM Yashree Mehta <yashree19 at gmail.com>
> wrote:
>
>> Hello,
>>
>> I had recently posted the following for understanding the syntax for
>> adding
>> group-level predictors in a random intercept model:
>>
>> """""
>>
>> Hi,
>> I am working with a random intercept model. I have the usual "X" vector of
>> covariates and one id variable which will make up the random intercept.
>> Now
>> I wish to add group-level predictors (which are NOT in the X vector) such
>> that the random intercept depends on these predictors.
>> For example,
>> Response variable: Production of maize
>> Covariate: Size of plot
>> Group-level predictor: Age of farmer
>> ID variable: Household_ID
>>
>> I wish to confirm the syntax for including the group-level "Age of farmer"
>> variable.
>> fit<-lmer(Production~ Size+ Age+ (1|Household_ID), data=data)
>>
>> Is this correct or is there another way of declaring the group-level
>> predictor in the formula?
>>
>> """""
>>
>> This syntax had been confirmed as correct. Now I am wondering how does
>> lmer
>> really distinguish between the usual X covariates and group-level
>> predictors? We have not really differentiated them in the formula. How
>> does
>> lmer construe Age to only impact the random intercept?
>>
>> Thank you very much,
>>
>> Regards,
>>
>> Yashree
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Tue Jun 12 14:10:23 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 12 Jun 2018 14:10:23 +0200
Subject: [R-sig-ME] 
 Different p_values from between groups to within groups
In-Reply-To: <DB3PR0402MB38517D78B212FDA7B55A4947F67B0@DB3PR0402MB3851.eurprd04.prod.outlook.com>
References: <DB3PR0402MB38517D78B212FDA7B55A4947F67B0@DB3PR0402MB3851.eurprd04.prod.outlook.com>
Message-ID: <CAJuCY5wsnhnUMBy903__7gH5cZEC-8Zf+qnaJZwA-bRr2ym-JA@mail.gmail.com>

Dear Luca,

Those p-values are conditional on the model and not to be used for
model comparison. First find out which model is the most appropriate,
then to the post hoc tests.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-08 15:17 GMT+02:00 Luca Danieli <mr.lucedan at hotmail.it>:
> Hello everybody,
>
> may I ask you a suggestion on how to interpret a weird result I have?
>
> I have 3 groups (ExpertiseType), and through the use of contrast hypotheses, the first model gives me this output:
>
> model = lmer(Score~Closure*ExpertiseType+(1|Participant)+(1|Item), database, REML=TRUE)
>                                                                   Pr(>|t|)
> Closurecl_c1:ExpertiseTypeexp_c1    0.42203
> Closurecl_c2:ExpertiseTypeexp_c1    0.00601 **
> Closurecl_c3:ExpertiseTypeexp_c1   9.32e-08 ***
>
> Another, more detailed model, gives me the following:
>
> model = lmer(Score~Closure*ExpertiseType+ExpertiseType*LastPosition+Closure*LastPosition+(1|Participant)+(1|Item), database, REML=TRUE)
>
>                                                                   Pr(>|t|)
> Closurecl_c1:ExpertiseTypeexp_c1    0.50738
> Closurecl_c2:ExpertiseTypeexp_c1    0.01059 *
> Closurecl_c3:ExpertiseTypeexp_c1   4.05e-08 ***
>
> As you can notice, I have an interaction in both analyses, but if I look for the same contrast hypotheses within the group for which I have the interaction, the Closurecl_c2 effect disappeares.
>
> model = lmer(Score~Closure*LastPosition+(1|Participant)+(1|Item), subset(database, ExpertiseType==3), REML=TRUE)
>
>                            Pr(>|t|)
> Closurecl_c1      0.4411
> Closurecl_c2      0.1419
> Closurecl_c3   5.00e-07 ***
>
> Which one should I consider the most reliable output?
> Or, alternatively, what does this difference mean? I really don't know how to interpret this outcome. I was expecting that within groups, the analysis would get more defined.
>
> Best
> Luca
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bd@r@t @ending from wi@c@edu  Tue Jun 12 20:34:59 2018
From: bd@r@t @ending from wi@c@edu (Burcu Darst)
Date: Tue, 12 Jun 2018 18:34:59 +0000
Subject: [R-sig-ME] types of residuals in lme4
Message-ID: <5534C6A7-D374-43D9-B015-5AEA226CCAD3@wisc.edu>

I am using lme4 to get residuals from a model that has two random intercepts, as shown below:

test = lmer(continuousOutcome ~ age + sex + (1|DBID) + (1|familyID), data, na.action = na.exclude)


I?ve tried extracting all of the following types of residuals, but the only differences I observe between these approaches are due to scaling (i.e., residuals do not differ by residual type).

resids = as.data.table(residuals(test,type = "pearson", scaled = TRUE))
resids = as.data.table(residuals(test,type = "working", scaled = TRUE))
resids = as.data.table(residuals(test,type = "response", scaled = TRUE))
resids = as.data.table(residuals(test,type = "deviance", scaled = TRUE))
resids = as.data.table(residuals(test,type = "pearson"))
resids = as.data.table(residuals(test,type = "working"))
resids = as.data.table(residuals(test,type = "response"))
resids = as.data.table(residuals(test,type = "deviance"))


Is this an expected result when using lme4 to obtain residuals from mixed models? I want to ensure that the residuals I am obtaining are individual level (which they appear to be) and that they account for the two random intercepts (which I believe they do, since they differ if I exclude one of the random intercepts).


	[[alternative HTML version deleted]]


From guill@umech@umet @ending from gm@il@com  Wed Jun 13 10:26:07 2018
From: guill@umech@umet @ending from gm@il@com (Guillaume Chaumet)
Date: Wed, 13 Jun 2018 10:26:07 +0200
Subject: [R-sig-ME] fitting beta and zero mixture model containing both
 nested and crossed random effects
In-Reply-To: <CAMdkWR9=2K-bj=mqdShvb6TggWCgX0g3JN3S6zROQFMB5s27sw@mail.gmail.com>
References: <CAMdkWR9Ns-3W7dgDXJnBp5kcGP_u7q+d9scXD5xCgeeHUmnh7w@mail.gmail.com>
 <CAGg8SkL4VETeKEsmsz1z=Av6zfTU0mhv_UasUyDk0xhaJ0HxwQ@mail.gmail.com>
 <CAMdkWR9=2K-bj=mqdShvb6TggWCgX0g3JN3S6zROQFMB5s27sw@mail.gmail.com>
Message-ID: <CAGg8Sk+_hYRMRD45xqsYZT89=tu-hER1EKpewgVCiEymmvxMDQ@mail.gmail.com>

My bad, I replied to you the first time without including the list.
Regarding your last question, perhaps the list and/or Ben could
provide a more accurate answer than me.
I'm also curious to know how glmmTMB could do that

2018-06-13 0:09 GMT+02:00 Meng Liu <liumeng at usc.edu>:
> Hi Guillaume,
>
> Thank you so much for this! I just have another question: for example if I
> have random factor A and B in both logistic model part and beta model part,
> then after I fit the whole model and got variance component estimation of
> random effect for factor A and B for both logistic model part and beta model
> model part, will there be any way to combine variance together? I.e. I can
> estimate a total variance from factor A, and a total variance from factor B
> (i.e. only differ by factor, not model)? Something like variance
> decomposition but I believe here is more complex as this is a mixture model.
>
> Thank you again for all your help
>
> Best regards,
>
> Meng
>
> On Sun, Jun 10, 2018 at 11:03 AM, Guillaume Chaumet
> <guillaumechaumet at gmail.com> wrote:
>>
>> brms:
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_web_packages_brms_index.html&d=DwIBaQ&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=Gfi89kd1PSimpIhWBglYPuJRn3_FF_uNBGvzVDvWe4A&e=
>>
>> 2018-06-09 21:06 GMT+02:00 Meng Liu <liumeng at usc.edu>:
>> > To whom it may concern,
>> >
>> > I am trying to fit a model for a data among which the response value is
>> > within [0,1). I am thinking about fitting the zeros as a complete
>> > separate
>> > category from the non-zero data, i.e. a binomial (Bernoulli) model to
>> > "==0
>> > vs >0" and a Beta model to the >0 responses. Also, my data contains both
>> > nested factors and crossed factors, which means I need to add nested
>> > random
>> > effects and crossed random effects to both logistic model part and beta
>> > model model. However, I didn't find any R packages can do exactly what I
>> > want (By far I found gamlss, glmmTMB, zoib but they either can only
>> > assume
>> > random zero or they can only fit repeated measures/clustered data but
>> > not
>> > nested and crossed design). Therefore, I am wondering if any one know if
>> > there is any available package or function can do this.
>> >
>> > Thank you very much for your help!
>> >
>> > Best regards
>> >
>> > Meng
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> >
>> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIBaQ&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=FMNtOORgf7OlXhD5m8VHoGCnuWlt5NLqtXxalxQOhQw&e=
>
>


From bbolker @ending from gm@il@com  Wed Jun 13 15:38:59 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 13 Jun 2018 09:38:59 -0400
Subject: [R-sig-ME] fitting beta and zero mixture model containing both
 nested and crossed random effects
In-Reply-To: <CAGg8Sk+_hYRMRD45xqsYZT89=tu-hER1EKpewgVCiEymmvxMDQ@mail.gmail.com>
References: <CAMdkWR9Ns-3W7dgDXJnBp5kcGP_u7q+d9scXD5xCgeeHUmnh7w@mail.gmail.com>
 <CAGg8SkL4VETeKEsmsz1z=Av6zfTU0mhv_UasUyDk0xhaJ0HxwQ@mail.gmail.com>
 <CAMdkWR9=2K-bj=mqdShvb6TggWCgX0g3JN3S6zROQFMB5s27sw@mail.gmail.com>
 <CAGg8Sk+_hYRMRD45xqsYZT89=tu-hER1EKpewgVCiEymmvxMDQ@mail.gmail.com>
Message-ID: <CABghstQCNwJgj2VoYePa3krAfdrBD3E6TiJTDjgVEtHLg5CaOQ@mail.gmail.com>

  I'm not sure how this (variance decomposition based on a
zero-inflated model) would work.
What is your subject-area/scientific question?

On Wed, Jun 13, 2018 at 4:26 AM, Guillaume Chaumet
<guillaumechaumet at gmail.com> wrote:
> My bad, I replied to you the first time without including the list.
> Regarding your last question, perhaps the list and/or Ben could
> provide a more accurate answer than me.
> I'm also curious to know how glmmTMB could do that
>
> 2018-06-13 0:09 GMT+02:00 Meng Liu <liumeng at usc.edu>:
>> Hi Guillaume,
>>
>> Thank you so much for this! I just have another question: for example if I
>> have random factor A and B in both logistic model part and beta model part,
>> then after I fit the whole model and got variance component estimation of
>> random effect for factor A and B for both logistic model part and beta model
>> model part, will there be any way to combine variance together? I.e. I can
>> estimate a total variance from factor A, and a total variance from factor B
>> (i.e. only differ by factor, not model)? Something like variance
>> decomposition but I believe here is more complex as this is a mixture model.
>>
>> Thank you again for all your help
>>
>> Best regards,
>>
>> Meng
>>
>> On Sun, Jun 10, 2018 at 11:03 AM, Guillaume Chaumet
>> <guillaumechaumet at gmail.com> wrote:
>>>
>>> brms:
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_web_packages_brms_index.html&d=DwIBaQ&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=Gfi89kd1PSimpIhWBglYPuJRn3_FF_uNBGvzVDvWe4A&e=
>>>
>>> 2018-06-09 21:06 GMT+02:00 Meng Liu <liumeng at usc.edu>:
>>> > To whom it may concern,
>>> >
>>> > I am trying to fit a model for a data among which the response value is
>>> > within [0,1). I am thinking about fitting the zeros as a complete
>>> > separate
>>> > category from the non-zero data, i.e. a binomial (Bernoulli) model to
>>> > "==0
>>> > vs >0" and a Beta model to the >0 responses. Also, my data contains both
>>> > nested factors and crossed factors, which means I need to add nested
>>> > random
>>> > effects and crossed random effects to both logistic model part and beta
>>> > model model. However, I didn't find any R packages can do exactly what I
>>> > want (By far I found gamlss, glmmTMB, zoib but they either can only
>>> > assume
>>> > random zero or they can only fit repeated measures/clustered data but
>>> > not
>>> > nested and crossed design). Therefore, I am wondering if any one know if
>>> > there is any available package or function can do this.
>>> >
>>> > Thank you very much for your help!
>>> >
>>> > Best regards
>>> >
>>> > Meng
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> >
>>> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIBaQ&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=FMNtOORgf7OlXhD5m8VHoGCnuWlt5NLqtXxalxQOhQw&e=
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From w@lidm@w@@@10 @ending from gm@il@com  Wed Jun 13 16:28:51 2018
From: w@lidm@w@@@10 @ending from gm@il@com (Walid Mawass)
Date: Wed, 13 Jun 2018 10:28:51 -0400
Subject: [R-sig-ME] MCMCglmm bivariate with offset
Message-ID: <91fa7964-2dbe-0dcc-b356-c27501a0ac20@gmail.com>

Hello everyone,

I am working on a bivariate MCMCglmm model and I want to include an 
offset term for my second response variable. I already know that for the 
offset, i have to fix the coefficient to 1 through the prior but it is 
not working in my case. I have 4 fixed effects fitted for both response 
variables and the offset is fitted for the second one using 
/at.level(trait,2)/.

prior1 <- list(B=list(V=diag(5)*1e8, mu=rep(0,5)), R=list(V=diag(2), 
nu=3), G=list(G1=list(V=diag(2), nu=3),G2=list(V=diag(2), nu=3)))
prior1$B$mu[5]<- 1
prior1$B$V[5,5]<- 1e-8

is this the proper way to set the prior? or should the fixed effects 
matrix have different dimensions since my model is bivariate:

model_multi <- MCMCglmm(cbind(AFR, OffMortality)~trait-1 + trait:COEFPAR 
+ trait:I(COEFPAR*COEFPAR) + trait:TWIN + trait:YEARM+ 
at.level(trait,2):log(FERTILITY), random = 
~us(trait):animal+us(trait):MOTHERW, rcov = ~us(trait):units, data = 
IAC, pedigree = prunedPed, family = c("gaussian", "poisson"), nitt = 
3500000, burnin = 500000, thin = 3000, prior = prior1, verbose = FALSE, 
pr=TRUE)

Thank you in advance for any advice.

-- 
Walid Mawass

Ph.D. candidate in Cellular and Molecular Biology

Population Genetics Laboratory

University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


	[[alternative HTML version deleted]]


From liumeng @ending from u@c@edu  Wed Jun 13 16:47:18 2018
From: liumeng @ending from u@c@edu (Meng Liu)
Date: Wed, 13 Jun 2018 10:47:18 -0400
Subject: [R-sig-ME] fitting beta and zero mixture model containing both
 nested and crossed random effects
In-Reply-To: <CABghstQCNwJgj2VoYePa3krAfdrBD3E6TiJTDjgVEtHLg5CaOQ@mail.gmail.com>
References: <CAMdkWR9Ns-3W7dgDXJnBp5kcGP_u7q+d9scXD5xCgeeHUmnh7w@mail.gmail.com>
 <CAGg8SkL4VETeKEsmsz1z=Av6zfTU0mhv_UasUyDk0xhaJ0HxwQ@mail.gmail.com>
 <CAMdkWR9=2K-bj=mqdShvb6TggWCgX0g3JN3S6zROQFMB5s27sw@mail.gmail.com>
 <CAGg8Sk+_hYRMRD45xqsYZT89=tu-hER1EKpewgVCiEymmvxMDQ@mail.gmail.com>
 <CABghstQCNwJgj2VoYePa3krAfdrBD3E6TiJTDjgVEtHLg5CaOQ@mail.gmail.com>
Message-ID: <CAMdkWR_x9N6oNUf+F9eY8c=HebU2sUWGfWu0JFTXfNQcQ8TkAw@mail.gmail.com>

Hi Ben and Guilaume,

Thank you for reply. I am working on a precision experiment design, in
which a sample will be tested using different assay, by different operator
at different site. The measurement is allele frequency of DNA, which is a
continuous proportion outcome. I originally plan to run a beta distribution
random effects model, among which assay, operator and site are all random
factors. However, because I found there are some zeros in the response
data, that's why I am trying to run a zero-inflated beta random effects
model, with random factors in both zero part and non zero part. I.e., we
assume there will be variance from each factor in terms of predicting zero,
and variance from each factor in terms of continuous data. However, the
final research question would be evaluating the total variance contributed
from each factor.I can see here it is more complex for just generalized
linear model because of random effects from two different models. I am
wondering if you have any idea on this or do you know anybody who might
have thoughts on this?

Thank you again for all help!

Best regards,

Meng

On Wed, Jun 13, 2018 at 9:38 AM, Ben Bolker <bbolker at gmail.com> wrote:

>   I'm not sure how this (variance decomposition based on a
> zero-inflated model) would work.
> What is your subject-area/scientific question?
>
> On Wed, Jun 13, 2018 at 4:26 AM, Guillaume Chaumet
> <guillaumechaumet at gmail.com> wrote:
> > My bad, I replied to you the first time without including the list.
> > Regarding your last question, perhaps the list and/or Ben could
> > provide a more accurate answer than me.
> > I'm also curious to know how glmmTMB could do that
> >
> > 2018-06-13 0:09 GMT+02:00 Meng Liu <liumeng at usc.edu>:
> >> Hi Guillaume,
> >>
> >> Thank you so much for this! I just have another question: for example
> if I
> >> have random factor A and B in both logistic model part and beta model
> part,
> >> then after I fit the whole model and got variance component estimation
> of
> >> random effect for factor A and B for both logistic model part and beta
> model
> >> model part, will there be any way to combine variance together? I.e. I
> can
> >> estimate a total variance from factor A, and a total variance from
> factor B
> >> (i.e. only differ by factor, not model)? Something like variance
> >> decomposition but I believe here is more complex as this is a mixture
> model.
> >>
> >> Thank you again for all your help
> >>
> >> Best regards,
> >>
> >> Meng
> >>
> >> On Sun, Jun 10, 2018 at 11:03 AM, Guillaume Chaumet
> >> <guillaumechaumet at gmail.com> wrote:
> >>>
> >>> brms:
> >>> https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-
> 2Dproject.org_web_packages_brms_index.html&d=DwIBaQ&c=
> clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=
> Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=
> Gfi89kd1PSimpIhWBglYPuJRn3_FF_uNBGvzVDvWe4A&e=
> >>>
> >>> 2018-06-09 21:06 GMT+02:00 Meng Liu <liumeng at usc.edu>:
> >>> > To whom it may concern,
> >>> >
> >>> > I am trying to fit a model for a data among which the response value
> is
> >>> > within [0,1). I am thinking about fitting the zeros as a complete
> >>> > separate
> >>> > category from the non-zero data, i.e. a binomial (Bernoulli) model to
> >>> > "==0
> >>> > vs >0" and a Beta model to the >0 responses. Also, my data contains
> both
> >>> > nested factors and crossed factors, which means I need to add nested
> >>> > random
> >>> > effects and crossed random effects to both logistic model part and
> beta
> >>> > model model. However, I didn't find any R packages can do exactly
> what I
> >>> > want (By far I found gamlss, glmmTMB, zoib but they either can only
> >>> > assume
> >>> > random zero or they can only fit repeated measures/clustered data but
> >>> > not
> >>> > nested and crossed design). Therefore, I am wondering if any one
> know if
> >>> > there is any available package or function can do this.
> >>> >
> >>> > Thank you very much for your help!
> >>> >
> >>> > Best regards
> >>> >
> >>> > Meng
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > _______________________________________________
> >>> > R-sig-mixed-models at r-project.org mailing list
> >>> >
> >>> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.
> ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIBaQ&c=
> clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=
> Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=
> FMNtOORgf7OlXhD5m8VHoGCnuWlt5NLqtXxalxQOhQw&e=
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.
> ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIFaQ&c=
> clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=Ij73g98b5MaGitndhxmoIw&m=
> 2BcoGwnjTH2lMtoXsQy3PazIJQlKthmPnzhLeUAe8Iw&s=
> ni4tfiCBB6TzaOnxJfYkjSxo5Ztgo3sx1FyYE-Qc2AY&e=
>

	[[alternative HTML version deleted]]


From jorge@cuev@ @ending from tum@de  Wed Jun 13 17:35:21 2018
From: jorge@cuev@ @ending from tum@de (Cueva, Jorge)
Date: Wed, 13 Jun 2018 15:35:21 +0000
Subject: [R-sig-ME] Different number of observations in variables of glmer
Message-ID: <831d663cb2094d7d9e354fe1fe4b8276@tum.de>

Hello, I am trying fit a glmer where the fixed variables has a different number of observations (72 and 60). With the models where the variables has the full observations I don?t have problems but yes in the models where some of its variables has 60 observations. In the second case,  all work well until I compute the R2m and R2c and I get the error "fitting model with the observation-level random effect term failed. Add the term manually", so, when I ingress the observation level the AIC increase 2 points, and miss 1 df. Please how I might work in these cases??

First case...
glmer(Spp~1+Mth.Prec+Soil.depth+Drainage+(1|Cluster),data = VariabRL,family=poisson,glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)))

Second case...
glmer(Spp~1+Mth.Prec+Soil.depth+Drainage+(1|Cluster)+(1|X),data = VariabRL,family=poisson,glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)))

Mth.Prec = 72 observations
Soil.depth and Drainage = 60 observations
X = observation level

Thanks a lot

Jorge Cueva Ortiz
Ing. Forestal
ECU: 0993085161
GER: 0049 1631327886


	[[alternative HTML version deleted]]


From pcdjohn@on @ending from gm@il@com  Wed Jun 13 18:35:05 2018
From: pcdjohn@on @ending from gm@il@com (Paul Johnson)
Date: Wed, 13 Jun 2018 17:35:05 +0100
Subject: [R-sig-ME] fitting beta and zero mixture model containing both
 nested and crossed random effects
In-Reply-To: <CAMdkWR_x9N6oNUf+F9eY8c=HebU2sUWGfWu0JFTXfNQcQ8TkAw@mail.gmail.com>
References: <CAMdkWR9Ns-3W7dgDXJnBp5kcGP_u7q+d9scXD5xCgeeHUmnh7w@mail.gmail.com>
 <CAGg8SkL4VETeKEsmsz1z=Av6zfTU0mhv_UasUyDk0xhaJ0HxwQ@mail.gmail.com>
 <CAMdkWR9=2K-bj=mqdShvb6TggWCgX0g3JN3S6zROQFMB5s27sw@mail.gmail.com>
 <CAGg8Sk+_hYRMRD45xqsYZT89=tu-hER1EKpewgVCiEymmvxMDQ@mail.gmail.com>
 <CABghstQCNwJgj2VoYePa3krAfdrBD3E6TiJTDjgVEtHLg5CaOQ@mail.gmail.com>
 <CAMdkWR_x9N6oNUf+F9eY8c=HebU2sUWGfWu0JFTXfNQcQ8TkAw@mail.gmail.com>
Message-ID: <128981A4-56E2-41FB-A582-F173FEEA3665@glasgow.ac.uk>

Hi Meng,

Is it possible for you to model the raw data (the counts of alleles within each individual site/assay/etc) rather than the calculated allele frequency (= proportion*)? If you have access to this data it would simplify your model greatly. I guess the reason for having zeroes is that there were no copies of an allele in a subpopulation (site, etc), giving an estimated proportion of zero? If so, you need a model with a binomial distribution for the responses (e.g. cbind(n.minor.allele, n.major.allele)**, assuming two alleles), and you could have a beta distribution for the allele frequencies. Then the model will see zeroes as being drawn from a binomial distribution with a non-zero allele frequency. This is the Balding-Nichols model, which gives a natural way of gauging the strength of random effects via f, which is an analogue of Wright?s Fst (which measures correlation between alleles in a subpopulation relative to the total population):

p.sub ~ Beta(shape1 = (1 - f) / f * p, shape2 = (1 - f) / f * (1 - p))

?for 0 < f < 1. p is the mean allele frequency, p.sub are the subpopulation (site, assay, etc) allele frequencies.

And the distribution of the number of alleles in subpopulation i is: 

n.minor.allele[i] ~ Binom(2n[i], p.sub[i])

...n[i] is the number of diploid individuals in subpopulation i.

Alternatively, I guess there?s nothing to stop you having normally distributed allele frequencies on the logit scale, in which case you could fit the model with glmer.

Best wishes,
Paul

*It?s a stats/population genetics language difference ? for statisticians frequency means count, while for population geneticists an allele frequency is a proportion (I have a foot in each camp).
**Pooling alleles in this way, i.e. ignoring the individual level, assumes HWE. If you don?t want to do that you can treat a diploid individual as a level nested within site/assay/etc, and estimate an individual level f, which is analogous to Fis, the inbreeding coefficient.


> On 13 Jun 2018, at 15:47, Meng Liu <liumeng at usc.edu> wrote:
> 
> Hi Ben and Guilaume,
> 
> Thank you for reply. I am working on a precision experiment design, in
> which a sample will be tested using different assay, by different operator
> at different site. The measurement is allele frequency of DNA, which is a
> continuous proportion outcome. I originally plan to run a beta distribution
> random effects model, among which assay, operator and site are all random
> factors. However, because I found there are some zeros in the response
> data, that's why I am trying to run a zero-inflated beta random effects
> model, with random factors in both zero part and non zero part. I.e., we
> assume there will be variance from each factor in terms of predicting zero,
> and variance from each factor in terms of continuous data. However, the
> final research question would be evaluating the total variance contributed
> from each factor.I can see here it is more complex for just generalized
> linear model because of random effects from two different models. I am
> wondering if you have any idea on this or do you know anybody who might
> have thoughts on this?
> 
> Thank you again for all help!
> 
> Best regards,
> 
> Meng
> 
> On Wed, Jun 13, 2018 at 9:38 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> I'm not sure how this (variance decomposition based on a
>> zero-inflated model) would work.
>> What is your subject-area/scientific question?
>> 
>> On Wed, Jun 13, 2018 at 4:26 AM, Guillaume Chaumet
>> <guillaumechaumet at gmail.com> wrote:
>>> My bad, I replied to you the first time without including the list.
>>> Regarding your last question, perhaps the list and/or Ben could
>>> provide a more accurate answer than me.
>>> I'm also curious to know how glmmTMB could do that
>>> 
>>> 2018-06-13 0:09 GMT+02:00 Meng Liu <liumeng at usc.edu>:
>>>> Hi Guillaume,
>>>> 
>>>> Thank you so much for this! I just have another question: for example
>> if I
>>>> have random factor A and B in both logistic model part and beta model
>> part,
>>>> then after I fit the whole model and got variance component estimation
>> of
>>>> random effect for factor A and B for both logistic model part and beta
>> model
>>>> model part, will there be any way to combine variance together? I.e. I
>> can
>>>> estimate a total variance from factor A, and a total variance from
>> factor B
>>>> (i.e. only differ by factor, not model)? Something like variance
>>>> decomposition but I believe here is more complex as this is a mixture
>> model.
>>>> 
>>>> Thank you again for all your help
>>>> 
>>>> Best regards,
>>>> 
>>>> Meng
>>>> 
>>>> On Sun, Jun 10, 2018 at 11:03 AM, Guillaume Chaumet
>>>> <guillaumechaumet at gmail.com> wrote:
>>>>> 
>>>>> brms:
>>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-
>> 2Dproject.org_web_packages_brms_index.html&d=DwIBaQ&c=
>> clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=
>> Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=
>> Gfi89kd1PSimpIhWBglYPuJRn3_FF_uNBGvzVDvWe4A&e=
>>>>> 
>>>>> 2018-06-09 21:06 GMT+02:00 Meng Liu <liumeng at usc.edu>:
>>>>>> To whom it may concern,
>>>>>> 
>>>>>> I am trying to fit a model for a data among which the response value
>> is
>>>>>> within [0,1). I am thinking about fitting the zeros as a complete
>>>>>> separate
>>>>>> category from the non-zero data, i.e. a binomial (Bernoulli) model to
>>>>>> "==0
>>>>>> vs >0" and a Beta model to the >0 responses. Also, my data contains
>> both
>>>>>> nested factors and crossed factors, which means I need to add nested
>>>>>> random
>>>>>> effects and crossed random effects to both logistic model part and
>> beta
>>>>>> model model. However, I didn't find any R packages can do exactly
>> what I
>>>>>> want (By far I found gamlss, glmmTMB, zoib but they either can only
>>>>>> assume
>>>>>> random zero or they can only fit repeated measures/clustered data but
>>>>>> not
>>>>>> nested and crossed design). Therefore, I am wondering if any one
>> know if
>>>>>> there is any available package or function can do this.
>>>>>> 
>>>>>> Thank you very much for your help!
>>>>>> 
>>>>>> Best regards
>>>>>> 
>>>>>> Meng
>>>>>> 
>>>>>>      [[alternative HTML version deleted]]
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> 
>>>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.
>> ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIBaQ&c=
>> clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=
>> Ij73g98b5MaGitndhxmoIw&m=Uy-z_keMG1SfZG-g8FxVqzfz-Ghl2OHun7TY7tfexwo&s=
>> FMNtOORgf7OlXhD5m8VHoGCnuWlt5NLqtXxalxQOhQw&e=
>>>> 
>>>> 
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.
>> ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIFaQ&c=
>> clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=Ij73g98b5MaGitndhxmoIw&m=
>> 2BcoGwnjTH2lMtoXsQy3PazIJQlKthmPnzhLeUAe8Iw&s=
>> ni4tfiCBB6TzaOnxJfYkjSxo5Ztgo3sx1FyYE-Qc2AY&e=
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j@h@dfield @ending from ed@@c@uk  Wed Jun 13 20:08:09 2018
From: j@h@dfield @ending from ed@@c@uk (HADFIELD Jarrod)
Date: Wed, 13 Jun 2018 18:08:09 +0000
Subject: [R-sig-ME] MCMCglmm bivariate with offset
In-Reply-To: <91fa7964-2dbe-0dcc-b356-c27501a0ac20@gmail.com>
References: <91fa7964-2dbe-0dcc-b356-c27501a0ac20@gmail.com>
Message-ID: <5F267D06-4E39-40DE-AA37-ABA3C8859F81@ed.ac.uk>

Hi, 

I think you have 11 fixed effects, not 5. Replace 5 with 11 and then it should work. Also, you should expect the posterior to be sensitive to the prior if you have nu=3 unless there is a lot of information in the data.

Cheers,

Jarrod


> On 13 Jun 2018, at 15:28, Walid Mawass <walidmawass10 at gmail.com> wrote:
> 
> Hello everyone,
> 
> I am working on a bivariate MCMCglmm model and I want to include an 
> offset term for my second response variable. I already know that for the 
> offset, i have to fix the coefficient to 1 through the prior but it is 
> not working in my case. I have 4 fixed effects fitted for both response 
> variables and the offset is fitted for the second one using 
> /at.level(trait,2)/.
> 
> prior1 <- list(B=list(V=diag(5)*1e8, mu=rep(0,5)), R=list(V=diag(2), 
> nu=3), G=list(G1=list(V=diag(2), nu=3),G2=list(V=diag(2), nu=3)))
> prior1$B$mu[5]<- 1
> prior1$B$V[5,5]<- 1e-8
> 
> is this the proper way to set the prior? or should the fixed effects 
> matrix have different dimensions since my model is bivariate:
> 
> model_multi <- MCMCglmm(cbind(AFR, OffMortality)~trait-1 + trait:COEFPAR 
> + trait:I(COEFPAR*COEFPAR) + trait:TWIN + trait:YEARM+ 
> at.level(trait,2):log(FERTILITY), random = 
> ~us(trait):animal+us(trait):MOTHERW, rcov = ~us(trait):units, data = 
> IAC, pedigree = prunedPed, family = c("gaussian", "poisson"), nitt = 
> 3500000, burnin = 500000, thin = 3000, prior = prior1, verbose = FALSE, 
> pr=TRUE)
> 
> Thank you in advance for any advice.
> 
> -- 
> Walid Mawass
> 
> Ph.D. candidate in Cellular and Molecular Biology
> 
> Population Genetics Laboratory
> 
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From w@lidm@w@@@10 @ending from gm@il@com  Wed Jun 13 20:51:37 2018
From: w@lidm@w@@@10 @ending from gm@il@com (Walid Mawass)
Date: Wed, 13 Jun 2018 14:51:37 -0400
Subject: [R-sig-ME] MCMCglmm bivariate with offset
In-Reply-To: <5F267D06-4E39-40DE-AA37-ABA3C8859F81@ed.ac.uk>
References: <91fa7964-2dbe-0dcc-b356-c27501a0ac20@gmail.com>
 <5F267D06-4E39-40DE-AA37-ABA3C8859F81@ed.ac.uk>
Message-ID: <09117a52-3f10-712c-0be5-f2f1afb98303@gmail.com>

Thank you Jarrod, the model finally ran with your advice. I am aware of 
the sensitivity of the posterior distribution, this is just my first 
prior. I am going to use another one with nu = 1.002.

Cheers

Walid


On 6/13/2018 2:08 PM, HADFIELD Jarrod wrote:
> Hi,
>
> I think you have 11 fixed effects, not 5. Replace 5 with 11 and then it should work. Also, you should expect the posterior to be sensitive to the prior if you have nu=3 unless there is a lot of information in the data.
>
> Cheers,
>
> Jarrod
>
>
>> On 13 Jun 2018, at 15:28, Walid Mawass <walidmawass10 at gmail.com> wrote:
>>
>> Hello everyone,
>>
>> I am working on a bivariate MCMCglmm model and I want to include an
>> offset term for my second response variable. I already know that for the
>> offset, i have to fix the coefficient to 1 through the prior but it is
>> not working in my case. I have 4 fixed effects fitted for both response
>> variables and the offset is fitted for the second one using
>> /at.level(trait,2)/.
>>
>> prior1 <- list(B=list(V=diag(5)*1e8, mu=rep(0,5)), R=list(V=diag(2),
>> nu=3), G=list(G1=list(V=diag(2), nu=3),G2=list(V=diag(2), nu=3)))
>> prior1$B$mu[5]<- 1
>> prior1$B$V[5,5]<- 1e-8
>>
>> is this the proper way to set the prior? or should the fixed effects
>> matrix have different dimensions since my model is bivariate:
>>
>> model_multi <- MCMCglmm(cbind(AFR, OffMortality)~trait-1 + trait:COEFPAR
>> + trait:I(COEFPAR*COEFPAR) + trait:TWIN + trait:YEARM+
>> at.level(trait,2):log(FERTILITY), random =
>> ~us(trait):animal+us(trait):MOTHERW, rcov = ~us(trait):units, data =
>> IAC, pedigree = prunedPed, family = c("gaussian", "poisson"), nitt =
>> 3500000, burnin = 500000, thin = 3000, prior = prior1, verbose = FALSE,
>> pr=TRUE)
>>
>> Thank you in advance for any advice.
>>
>> -- 
>> Walid Mawass
>>
>> Ph.D. candidate in Cellular and Molecular Biology
>>
>> Population Genetics Laboratory
>>
>> University of Qu?bec at Trois-Rivi?res
>> 3351, boul. des Forges, C.P. 500
>> Trois-Rivi?res (Qu?bec) G9A 5H7
>> Telephone: 819-376-5011 poste 3384
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Walid Mawass

Ph.D. candidate in Cellular and Molecular Biology

Population Genetics Laboratory

University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


From B@Liew @ending from bh@m@@c@uk  Thu Jun 14 17:16:07 2018
From: B@Liew @ending from bh@m@@c@uk (Bernard Liew)
Date: Thu, 14 Jun 2018 15:16:07 +0000
Subject: [R-sig-ME] Using variance components of lmer for ICC computation in
 reliability study
Message-ID: <A901AC7187F75B41BF677B0A610C0976E8D3D4@EX11.adf.bham.ac.uk>

Dear Community,


I am doing a reliability study, using the methods of https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on the lmer formulation and the use of the variance components.

Background: I have 20 subjects, 2 fixed raters, 2 testing sessions, and 10 trials per sessions. my dependent variable is a continuous variable (scale 1-10). Sessions are nested within each subject-assessor combination. I desire a ICC (3) formulation of inter-rater and inter-session reliability from the variance components.

My lmer model is:

lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)

Question:

  1.  is the model formulation right? and is my interpretation of the variance components for ICC below right?
  2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) # I read that the variation of raters will be lumped with the residual
  3.  inter-session ICC =( var (subj) + var (residual)) /( var (subj) + var (subj:session) + var (residual))
some simulated data:
df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2), trial = c(1:10))
df$vas = rnorm (nrow (df_sim), mean = 3, sd = 1.5)

I appreciate the kind response.

Kind regards,
Bernard



	[[alternative HTML version deleted]]


From HDor@n @ending from @ir@org  Thu Jun 14 19:35:11 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Thu, 14 Jun 2018 17:35:11 +0000
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
Message-ID: <D7481F39.515BB%hdoran@air.org>

Well no, you?re specification is not right because your variable is not
continuous as you note. Continuous means it is a real number between
-Inf/Inf and you have boundaries between 1 and 10. So, you should not be
using a linear model assuming the outcome is continuous.



On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:

>Dear Community,
>
>
>I am doing a reliability study, using the methods of
>https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on the
>lmer formulation and the use of the variance components.
>
>Background: I have 20 subjects, 2 fixed raters, 2 testing sessions, and
>10 trials per sessions. my dependent variable is a continuous variable
>(scale 1-10). Sessions are nested within each subject-assessor
>combination. I desire a ICC (3) formulation of inter-rater and
>inter-session reliability from the variance components.
>
>My lmer model is:
>
>lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
>
>Question:
>
>  1.  is the model formulation right? and is my interpretation of the
>variance components for ICC below right?
>  2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) # I
>read that the variation of raters will be lumped with the residual
>  3.  inter-session ICC =( var (subj) + var (residual)) /( var (subj) +
>var (subj:session) + var (residual))
>some simulated data:
>df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2), trial
>= c(1:10))
>df$vas = rnorm (nrow (df_sim), mean = 3, sd = 1.5)
>
>I appreciate the kind response.
>
>Kind regards,
>Bernard
>
>
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From tom_philippi @ending from np@@gov  Thu Jun 14 19:54:05 2018
From: tom_philippi @ending from np@@gov (Philippi, Tom)
Date: Thu, 14 Jun 2018 10:54:05 -0700
Subject: [R-sig-ME] 
 [EXTERNAL] Non-Normal and Heteroskedastic Residuals in
 Longitudinal Model Due to Non-Normal DV - Percentile Bootstrap Sufficient,
 or Wild Bootstrap Needed?
In-Reply-To: <CAJgUswJEqP2zq060uTjjh8iiStaU9xX7GJ+cN-b5mwT74xsSfw@mail.gmail.com>
References: <CAJgUswJEqP2zq060uTjjh8iiStaU9xX7GJ+cN-b5mwT74xsSfw@mail.gmail.com>
Message-ID: <CAM9kYqgAm_sNV2en7Sdmm2dXG177xJ2yGPLHne4ajMUMmspC2Q@mail.gmail.com>

David--

I apologize in advance for not answering your precise question, but no one
else has responded, and this response might be more helpful than nothing.

If I understand your frequency data, nearly half of your observations are
tied at the extreme value of 91.  No transform is going to make that
distribution approximately normal.  Without rather large sample sizes, most
forms of bootstrapping will not produce confidence intervals with nominal
and symmetric coverage.  Further, modeling changes in the _mean_ of such
values can muddle or mislead on changes over time.

If you are primarily interested in the fixed effects, would quantile
regression perhaps address your questions of interest?  I don't know
"quality of life", but in my field, when I have oddly-distributed response
variables, I'm almost always interested in more than the mean, as the
temporal changes are more than a simple shift of the entire distribution.
For your example data, if 45% of the responses were 91, then longitudinal
trends in a mean are driven by a mixture of changes in that fraction plus
shifts in the length or width of the tail of lower values.  Quantile
regression on the lower quantiles (the median in the above data is 90)
might be more informative, as well as more applicable to such data.  If
subjects either converge on high scores over time, or start out with high
scores but then diverge as some fraction of subjects accumulate health
problems and have their scores decline over time, quantile regression might
better characterize such changes.

I have used lqmm with longitudinal data on limpet sizes with fixed plots as
random effects, and am exploring it for temporal trends in water quality
 The vignette for lqmm uses the Orthodont data from nlme, and includes the
equivalent of (1 + time | subject) as a random effect.  lqmm includes a
bootstrap function for objects of class lqm or lqmm.  I have yet to
simulate highly skewed or mixture model WQ data to see if (when)
bootstrapped confidence intervals have reasonable coverage, but that is in
the queue for this fall.

Also, perhaps the real experts on this list can chime in on the form of
your model.  While I understand mixed models with linear terms for time as
a fixed effect and within-subject random effect, I'm not clear on what
linear and quadratic fixed effect terms but only linear within-subject
terms means, especially if subjects differ in starting or drop-out times.

My apologies for not directly answering your question.  And certainly your
mileage will vary.

Tom

"To do science is to search for repeated patterns, not simply to accumulate
facts..."   --Robert MacArthur 1972, Geographical Ecology

"Statistical methods of analysis are intended to aid the interpretation of
data that are subject to appreciable haphazard variability"    --Cox &
Hinkley 1974; Theoretical Statistics

On Mon, Jun 11, 2018 at 6:59 AM, David Jones <david.tn.jones at gmail.com>
wrote:

> I am looking to model quality of life (QOL) as a DV over time. The DV
> shows strong negative skew. I am wondering about the best way to
> handle this (more detail below). Frequency distribution of QOL and
> example code are also at the end of this message.
>
> Many participants just say that their quality of life is great, and
> thus there is a ceiling effect with many values clustered at the
> highest value. While the distribution resembles y=e^x, I have not been
> able to fit a distribution via GLMM that results in normally
> distributed and homoskedastic residuals (including gamma and inverse
> gaussian). A number of DV transformations have not worked either
> (e.g., log, exponential, Box-Cox), in large part because of the large
> proportion of values at the maximum level of QOL, which creates a
> spike at the end of the distribution. I could try zero-inflated models
> by transforming the dv (multiply by -1 and put the starting value at
> 0), but even then there will still be a disproportionate number of
> values clustered at one end.
>
> My question: I am particularly interested in fixed effects parameters
> from a longitudinal model, and was thinking of testing these
> parameters by using percentile bootstrap CIs via confint(). However,
> the residuals from a lmer model are both non-normal and
> heteroskedastic - will percentile bootstrap of beta coefficients
> address this, or can only the wild bootstrap address these issues (as
> it is targeted to residuals)? I have a basic understanding of the
> bootstrap but am not an expert regarding its use in linear models.
>
> Many thanks!
>
>
>
>
> # Example lmer code
> model <- lmer(QOL ~ poly(time, 2) + (time | ID), data=dataset, REML =
> FALSE )
>
>
> # Frequency distribution
>
> QOL    valid_percent
> 25    0.000308261
> 30    0.000308261
> 32    0.000308261
> 34    0.000616523
> 38    0.000308261
> 41    0.000308261
> 45    0.000308261
> 46    0.000308261
> 47    0.000308261
> 48    0.000616523
> 49    0.000616523
> 50    0.000616523
> 51    0.000308261
> 52    0.000308261
> 53    0.001541307
> 54    0.000616523
> 55    0.001233046
> 56    0.000616523
> 57    0.000924784
> 58    0.000308261
> 59    0.000924784
> 60    0.000924784
> 61    0.001849568
> 62    0.001541307
> 63    0.003082614
> 64    0.001849568
> 65    0.00215783
> 66    0.002466091
> 67    0.004007398
> 68    0.002466091
> 69    0.004007398
> 70    0.002466091
> 71    0.003699137
> 72    0.006781751
> 73    0.004932183
> 74    0.006781751
> 75    0.006165228
> 76    0.007090012
> 77    0.007706535
> 78    0.008631319
> 79    0.010789149
> 80    0.015104809
> 81    0.014488286
> 82    0.01541307
> 83    0.020345253
> 84    0.025893958
> 85    0.03298397
> 86    0.036066585
> 87    0.053020962
> 88    0.064426634
> 89    0.080147966
> 90    0.088779285
> 91    0.452219482
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From p@ul@john@on @ending from gl@@gow@@c@uk  Thu Jun 14 20:44:14 2018
From: p@ul@john@on @ending from gl@@gow@@c@uk (Paul Johnson)
Date: Thu, 14 Jun 2018 18:44:14 +0000
Subject: [R-sig-ME] 
 Different number of observations in variables of glmer
In-Reply-To: <831d663cb2094d7d9e354fe1fe4b8276@tum.de>
References: <831d663cb2094d7d9e354fe1fe4b8276@tum.de>
Message-ID: <17B3708E-ADDA-4E08-8D3F-3DF9AFD03472@glasgow.ac.uk>

The r.squaredGLMM function in MuMIn tries to add an observation-level random effect term if it doesn?t find one ? I suspect this is where your error is coming from. It?s debatable whether this is a good idea (on the one hand it?s often a good idea to add an OLRE, but I think it would be better to give the user the choice). 

I suggest using the rsquared function in piecewiseSEM. A major update has just been uploaded to CRAN, which includes extensions of R-squared to models not previously covered:
https://cran.r-project.org/web/packages/piecewiseSEM/index.html

> On 13 Jun 2018, at 16:35, Cueva, Jorge <jorge.cueva at tum.de> wrote:
> 
> Hello, I am trying fit a glmer where the fixed variables has a different number of observations (72 and 60). With the models where the variables has the full observations I don?t have problems but yes in the models where some of its variables has 60 observations. In the second case,  all work well until I compute the R2m and R2c and I get the error "fitting model with the observation-level random effect term failed. Add the term manually", so, when I ingress the observation level the AIC increase 2 points, and miss 1 df. Please how I might work in these cases??
> 
> First case...
> glmer(Spp~1+Mth.Prec+Soil.depth+Drainage+(1|Cluster),data = VariabRL,family=poisson,glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)))
> 
> Second case...
> glmer(Spp~1+Mth.Prec+Soil.depth+Drainage+(1|Cluster)+(1|X),data = VariabRL,family=poisson,glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)))
> 
> Mth.Prec = 72 observations
> Soil.depth and Drainage = 60 observations
> X = observation level
> 
> Thanks a lot
> 
> Jorge Cueva Ortiz
> Ing. Forestal
> ECU: 0993085161
> GER: 0049 1631327886
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r@turner @ending from @uckl@nd@@c@nz  Fri Jun 15 00:33:44 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 15 Jun 2018 10:33:44 +1200
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <D7481F39.515BB%hdoran@air.org>
References: <D7481F39.515BB%hdoran@air.org>
Message-ID: <4af67f99-18f6-1d17-e873-6612152b753d@auckland.ac.nz>


On 15/06/18 05:35, Doran, Harold wrote:

> Well no, you?re specification is not right because your variable is not
> continuous as you note. Continuous means it is a real number between
> -Inf/Inf and you have boundaries between 1 and 10. So, you should not be
> using a linear model assuming the outcome is continuous.

I think that the foregoing is a bit misleading.  For a variable to be 
continuous it is not necessary for it to have a range from -infinity to 
infinity.

The OP says that dv  "is a continuous variable (scale 1-10)".  It is not 
clear to me what this means.  The "obvious"/usual meaning or 
interpretation would be that dv can take (only) the (positive integer) 
values 1, 2, ..., 10.  If this is so, then a continuous model is not 
appropriate.  (It should be noted however that people in the social 
sciences do this sort of thing --- i.e. treat discrete variables as 
continuous --- all the time.)

It is *possible* that dv can take values in the real interval [1,10], in
which case it *is* continuous, and a "continuous model" is indeed 
appropriate.

The OP should clarify what the situation actually is.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
> 
>> Dear Community,
>>
>>
>> I am doing a reliability study, using the methods of
>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on the
>> lmer formulation and the use of the variance components.
>>
>> Background: I have 20 subjects, 2 fixed raters, 2 testing sessions, and
>> 10 trials per sessions. my dependent variable is a continuous variable
>> (scale 1-10). Sessions are nested within each subject-assessor
>> combination. I desire a ICC (3) formulation of inter-rater and
>> inter-session reliability from the variance components.
>>
>> My lmer model is:
>>
>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
>>
>> Question:
>>
>>   1.  is the model formulation right? and is my interpretation of the
>> variance components for ICC below right?
>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) # I
>> read that the variation of raters will be lumped with the residual
>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var (subj) +
>> var (subj:session) + var (residual))
>> some simulated data:
>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2), trial
>> = c(1:10))
>> df$vas = rnorm (nrow (df_sim), mean = 3, sd = 1.5)
>>
>> I appreciate the kind response.


From HDor@n @ending from @ir@org  Fri Jun 15 00:58:59 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Thu, 14 Jun 2018 22:58:59 +0000
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <4af67f99-18f6-1d17-e873-6612152b753d@auckland.ac.nz>
References: <D7481F39.515BB%hdoran@air.org>
 <4af67f99-18f6-1d17-e873-6612152b753d@auckland.ac.nz>
Message-ID: <D7486A52.515E4%hdoran@air.org>

That?s a helpful clarification, Rolf. However, with gaussian normal errors
in the linear model, we can?t *really* assume they would asymptote at 1 or
10. My suspicion is that these are likert-style ordered counts of some
form, although the OP should clarify. In which case, the 1 or 10 are
limits with censoring, as true values for some measured trait could exist
outside those boundaries (and I suspect the model is forming predicted
values outside of 1 or 10).

 

On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:

>
>On 15/06/18 05:35, Doran, Harold wrote:
>
>> Well no, you?re specification is not right because your variable is not
>> continuous as you note. Continuous means it is a real number between
>> -Inf/Inf and you have boundaries between 1 and 10. So, you should not be
>> using a linear model assuming the outcome is continuous.
>
>I think that the foregoing is a bit misleading.  For a variable to be
>continuous it is not necessary for it to have a range from -infinity to
>infinity.
>
>The OP says that dv  "is a continuous variable (scale 1-10)".  It is not
>clear to me what this means.  The "obvious"/usual meaning or
>interpretation would be that dv can take (only) the (positive integer)
>values 1, 2, ..., 10.  If this is so, then a continuous model is not
>appropriate.  (It should be noted however that people in the social
>sciences do this sort of thing --- i.e. treat discrete variables as
>continuous --- all the time.)
>
>It is *possible* that dv can take values in the real interval [1,10], in
>which case it *is* continuous, and a "continuous model" is indeed
>appropriate.
>
>The OP should clarify what the situation actually is.
>
>cheers,
>
>Rolf Turner
>
>-- 
>Technical Editor ANZJS
>Department of Statistics
>University of Auckland
>Phone: +64-9-373-7599 ext. 88276
>
>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
>> 
>>> Dear Community,
>>>
>>>
>>> I am doing a reliability study, using the methods of
>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on the
>>> lmer formulation and the use of the variance components.
>>>
>>> Background: I have 20 subjects, 2 fixed raters, 2 testing sessions, and
>>> 10 trials per sessions. my dependent variable is a continuous variable
>>> (scale 1-10). Sessions are nested within each subject-assessor
>>> combination. I desire a ICC (3) formulation of inter-rater and
>>> inter-session reliability from the variance components.
>>>
>>> My lmer model is:
>>>
>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
>>>
>>> Question:
>>>
>>>   1.  is the model formulation right? and is my interpretation of the
>>> variance components for ICC below right?
>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) # I
>>> read that the variation of raters will be lumped with the residual
>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var (subj) +
>>> var (subj:session) + var (residual))
>>> some simulated data:
>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2),
>>>trial
>>> = c(1:10))
>>> df$vas = rnorm (nrow (df_sim), mean = 3, sd = 1.5)
>>>
>>> I appreciate the kind response.
>
>


From d@vid@tn@jone@ @ending from gm@il@com  Fri Jun 15 01:47:05 2018
From: d@vid@tn@jone@ @ending from gm@il@com (David Jones)
Date: Thu, 14 Jun 2018 18:47:05 -0500
Subject: [R-sig-ME] 
 [EXTERNAL] Non-Normal and Heteroskedastic Residuals in
 Longitudinal Model Due to Non-Normal DV - Percentile Bootstrap Sufficient,
 or Wild Bootstrap Needed?
In-Reply-To: <CAM9kYqgAm_sNV2en7Sdmm2dXG177xJ2yGPLHne4ajMUMmspC2Q@mail.gmail.com>
References: <CAJgUswJEqP2zq060uTjjh8iiStaU9xX7GJ+cN-b5mwT74xsSfw@mail.gmail.com>
 <CAM9kYqgAm_sNV2en7Sdmm2dXG177xJ2yGPLHne4ajMUMmspC2Q@mail.gmail.com>
Message-ID: <CAJgUswJ13CAqXi7OE8XJfVSyFumvcxt2WhCE=JFBDWLKMJOM4g@mail.gmail.com>

Hi Tom,

Thank you for your detailed follow up. You are correct that many of
the observations are at the extreme value. I am fortunate to have a
fairly large sample (~700 participants with roughly 8 timepoints
each), and I would be hopeful that bootstrapping could come to the
rescue. That being said, it's a tricky situation as you suggest.

I had not considered quantile regression, and a mixed quantile
approach might be a great way to get at this. I am very grateful for
this overall suggestion as well as the specifics to look for in the
lqmm vignette (and how it corresponds to nlme). It is a difficult
analytic situation and your input has been very helpful.

David

On Thu, Jun 14, 2018 at 12:54 PM, Philippi, Tom <tom_philippi at nps.gov> wrote:
> David--
>
> I apologize in advance for not answering your precise question, but no one
> else has responded, and this response might be more helpful than nothing.
>
> If I understand your frequency data, nearly half of your observations are
> tied at the extreme value of 91.  No transform is going to make that
> distribution approximately normal.  Without rather large sample sizes, most
> forms of bootstrapping will not produce confidence intervals with nominal
> and symmetric coverage.  Further, modeling changes in the _mean_ of such
> values can muddle or mislead on changes over time.
>
> If you are primarily interested in the fixed effects, would quantile
> regression perhaps address your questions of interest?  I don't know
> "quality of life", but in my field, when I have oddly-distributed response
> variables, I'm almost always interested in more than the mean, as the
> temporal changes are more than a simple shift of the entire distribution.
> For your example data, if 45% of the responses were 91, then longitudinal
> trends in a mean are driven by a mixture of changes in that fraction plus
> shifts in the length or width of the tail of lower values.  Quantile
> regression on the lower quantiles (the median in the above data is 90) might
> be more informative, as well as more applicable to such data.  If subjects
> either converge on high scores over time, or start out with high scores but
> then diverge as some fraction of subjects accumulate health problems and
> have their scores decline over time, quantile regression might better
> characterize such changes.
>
> I have used lqmm with longitudinal data on limpet sizes with fixed plots as
> random effects, and am exploring it for temporal trends in water quality
> The vignette for lqmm uses the Orthodont data from nlme, and includes the
> equivalent of (1 + time | subject) as a random effect.  lqmm includes a
> bootstrap function for objects of class lqm or lqmm.  I have yet to simulate
> highly skewed or mixture model WQ data to see if (when) bootstrapped
> confidence intervals have reasonable coverage, but that is in the queue for
> this fall.
>
> Also, perhaps the real experts on this list can chime in on the form of your
> model.  While I understand mixed models with linear terms for time as a
> fixed effect and within-subject random effect, I'm not clear on what linear
> and quadratic fixed effect terms but only linear within-subject terms means,
> especially if subjects differ in starting or drop-out times.
>
> My apologies for not directly answering your question.  And certainly your
> mileage will vary.
>
> Tom
>
> "To do science is to search for repeated patterns, not simply to accumulate
> facts..."   --Robert MacArthur 1972, Geographical Ecology
>
> "Statistical methods of analysis are intended to aid the interpretation of
> data that are subject to appreciable haphazard variability"    --Cox &
> Hinkley 1974; Theoretical Statistics
>
> On Mon, Jun 11, 2018 at 6:59 AM, David Jones <david.tn.jones at gmail.com>
> wrote:
>>
>> I am looking to model quality of life (QOL) as a DV over time. The DV
>> shows strong negative skew. I am wondering about the best way to
>> handle this (more detail below). Frequency distribution of QOL and
>> example code are also at the end of this message.
>>
>> Many participants just say that their quality of life is great, and
>> thus there is a ceiling effect with many values clustered at the
>> highest value. While the distribution resembles y=e^x, I have not been
>> able to fit a distribution via GLMM that results in normally
>> distributed and homoskedastic residuals (including gamma and inverse
>> gaussian). A number of DV transformations have not worked either
>> (e.g., log, exponential, Box-Cox), in large part because of the large
>> proportion of values at the maximum level of QOL, which creates a
>> spike at the end of the distribution. I could try zero-inflated models
>> by transforming the dv (multiply by -1 and put the starting value at
>> 0), but even then there will still be a disproportionate number of
>> values clustered at one end.
>>
>> My question: I am particularly interested in fixed effects parameters
>> from a longitudinal model, and was thinking of testing these
>> parameters by using percentile bootstrap CIs via confint(). However,
>> the residuals from a lmer model are both non-normal and
>> heteroskedastic - will percentile bootstrap of beta coefficients
>> address this, or can only the wild bootstrap address these issues (as
>> it is targeted to residuals)? I have a basic understanding of the
>> bootstrap but am not an expert regarding its use in linear models.
>>
>> Many thanks!
>>
>>
>>
>>
>> # Example lmer code
>> model <- lmer(QOL ~ poly(time, 2) + (time | ID), data=dataset, REML =
>> FALSE )
>>
>>
>> # Frequency distribution
>>
>> QOL    valid_percent
>> 25    0.000308261
>> 30    0.000308261
>> 32    0.000308261
>> 34    0.000616523
>> 38    0.000308261
>> 41    0.000308261
>> 45    0.000308261
>> 46    0.000308261
>> 47    0.000308261
>> 48    0.000616523
>> 49    0.000616523
>> 50    0.000616523
>> 51    0.000308261
>> 52    0.000308261
>> 53    0.001541307
>> 54    0.000616523
>> 55    0.001233046
>> 56    0.000616523
>> 57    0.000924784
>> 58    0.000308261
>> 59    0.000924784
>> 60    0.000924784
>> 61    0.001849568
>> 62    0.001541307
>> 63    0.003082614
>> 64    0.001849568
>> 65    0.00215783
>> 66    0.002466091
>> 67    0.004007398
>> 68    0.002466091
>> 69    0.004007398
>> 70    0.002466091
>> 71    0.003699137
>> 72    0.006781751
>> 73    0.004932183
>> 74    0.006781751
>> 75    0.006165228
>> 76    0.007090012
>> 77    0.007706535
>> 78    0.008631319
>> 79    0.010789149
>> 80    0.015104809
>> 81    0.014488286
>> 82    0.01541307
>> 83    0.020345253
>> 84    0.025893958
>> 85    0.03298397
>> 86    0.036066585
>> 87    0.053020962
>> 88    0.064426634
>> 89    0.080147966
>> 90    0.088779285
>> 91    0.452219482
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From bbolker @ending from gm@il@com  Fri Jun 15 03:27:54 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 14 Jun 2018 21:27:54 -0400
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <D7486A52.515E4%hdoran@air.org>
References: <D7481F39.515BB%hdoran@air.org>
 <4af67f99-18f6-1d17-e873-6612152b753d@auckland.ac.nz>
 <D7486A52.515E4%hdoran@air.org>
Message-ID: <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>

More generally, the best way to fit this kind of model is to use an
*ordinal* model, which assumes the responses are in increasing
sequence but does not assume the distance between levels (e.g. 1 vs 2,
2 vs 3 ...) is uniform.  However, I'm not sure how one would go about
computing an ICC from ordinal data ... (the 'ordinal' package is the
place to look for the model-fitting procedures). Googling it finds
some stuff, but it seems that it doesn't necessarily apply to complex
designs ...

https://stats.stackexchange.com/questions/3539/inter-rater-reliability-for-ordinal-or-interval-data
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/


On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
> That?s a helpful clarification, Rolf. However, with gaussian normal errors
> in the linear model, we can?t *really* assume they would asymptote at 1 or
> 10. My suspicion is that these are likert-style ordered counts of some
> form, although the OP should clarify. In which case, the 1 or 10 are
> limits with censoring, as true values for some measured trait could exist
> outside those boundaries (and I suspect the model is forming predicted
> values outside of 1 or 10).
>
>
>
> On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>
>>
>>On 15/06/18 05:35, Doran, Harold wrote:
>>
>>> Well no, you?re specification is not right because your variable is not
>>> continuous as you note. Continuous means it is a real number between
>>> -Inf/Inf and you have boundaries between 1 and 10. So, you should not be
>>> using a linear model assuming the outcome is continuous.
>>
>>I think that the foregoing is a bit misleading.  For a variable to be
>>continuous it is not necessary for it to have a range from -infinity to
>>infinity.
>>
>>The OP says that dv  "is a continuous variable (scale 1-10)".  It is not
>>clear to me what this means.  The "obvious"/usual meaning or
>>interpretation would be that dv can take (only) the (positive integer)
>>values 1, 2, ..., 10.  If this is so, then a continuous model is not
>>appropriate.  (It should be noted however that people in the social
>>sciences do this sort of thing --- i.e. treat discrete variables as
>>continuous --- all the time.)
>>
>>It is *possible* that dv can take values in the real interval [1,10], in
>>which case it *is* continuous, and a "continuous model" is indeed
>>appropriate.
>>
>>The OP should clarify what the situation actually is.
>>
>>cheers,
>>
>>Rolf Turner
>>
>>--
>>Technical Editor ANZJS
>>Department of Statistics
>>University of Auckland
>>Phone: +64-9-373-7599 ext. 88276
>>
>>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
>>>
>>>> Dear Community,
>>>>
>>>>
>>>> I am doing a reliability study, using the methods of
>>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on the
>>>> lmer formulation and the use of the variance components.
>>>>
>>>> Background: I have 20 subjects, 2 fixed raters, 2 testing sessions, and
>>>> 10 trials per sessions. my dependent variable is a continuous variable
>>>> (scale 1-10). Sessions are nested within each subject-assessor
>>>> combination. I desire a ICC (3) formulation of inter-rater and
>>>> inter-session reliability from the variance components.
>>>>
>>>> My lmer model is:
>>>>
>>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
>>>>
>>>> Question:
>>>>
>>>>   1.  is the model formulation right? and is my interpretation of the
>>>> variance components for ICC below right?
>>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) # I
>>>> read that the variation of raters will be lumped with the residual
>>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var (subj) +
>>>> var (subj:session) + var (residual))
>>>> some simulated data:
>>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2),
>>>>trial
>>>> = c(1:10))
>>>> df$vas = rnorm (nrow (df_sim), mean = 3, sd = 1.5)
>>>>
>>>> I appreciate the kind response.
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From rdi@z02 @ending from gm@il@com  Fri Jun 15 09:42:20 2018
From: rdi@z02 @ending from gm@il@com (Ramon Diaz-Uriarte)
Date: Fri, 15 Jun 2018 09:42:20 +0200
Subject: [R-sig-ME] fractional response models with random effects (or
 another question about [0, 1] response)
Message-ID: <8736xozear.fsf@gmail.com>



Dear all,

(Yet another question about response variables in [0, 1]).

I'd like to fit models, that include random effects, to response variables
in [0, 1] (i.e., they can take any value betwee 0 and 1, including 0 and
1). The response variables are averages of values that, themselves, are
not proportions nor binary variables[1].


I'd like to avoid *zero-one-inflated (beta) models* (available, e.g., in
brms), because I do not think that the 0s and 1s are governed by a
different process than the values in (0, 1).


Using a *beta model* (e.g., as available in glmmTMB) after transforming
the response via the sometimes recommended (e.g.,
https://cran.r-project.org/web/packages/betareg/vignettes/betareg.pdf) (y
* (n?1) + 0.5) / n does not seem ideal, since it is not clear what "n"
should be, and I have about 5% of the values exactly 0 or 1.


An alternative would be a *fractional response model*, with a binomial
model and accounting for overdispersion. In
https://stats.stackexchange.com/a/233664, using glmer, it is suggested that
accounting for overdispersion can be done adding a random effect to each
observation (or row of the data); we would also pass a weights vector to
avoid the warning about non-integer values. But an update from January 2018
indicates that might not be a valid approach (and my own experiments with
my data make me uneasy).


Instead of glmer, I could fit a binomial model using MCMCglmm or INLA,
both of which accomodate observation-level random effects (I guess I could
try this with brms, too). I am not sure this is sensible, though, for this
type of response variable.



Any suggestions?


Thanks,


[1] One of the variables, for example, is the Jensen-Shannon divergence
between two distributions, rescaled from [0, log(2)] to [0, 1]


--
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From HDor@n @ending from @ir@org  Fri Jun 15 10:57:01 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Fri, 15 Jun 2018 08:57:01 +0000
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <A901AC7187F75B41BF677B0A610C0976E8D453@EX11.adf.bham.ac.uk>
References: <D7481F39.515BB%hdoran@air.org>
 <4af67f99-18f6-1d17-e873-6612152b753d@auckland.ac.nz>
 <D7486A52.515E4%hdoran@air.org>
 <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
 <A901AC7187F75B41BF677B0A610C0976E8D453@EX11.adf.bham.ac.uk>
Message-ID: <D748F67D.515F9%hdoran@air.org>

It seems to me you actually have censored data of three types, left, right and within the intervals. You might find it helpful to review this paper and see how models like yours can be estimated.

https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf

From: Bernard Liew <B.Liew at bham.ac.uk<mailto:B.Liew at bham.ac.uk>>
Date: Friday, June 15, 2018 at 1:20 AM
To: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>, AIR <hdoran at air.org<mailto:hdoran at air.org>>
Cc: Rolf Turner <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>, "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: RE: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study


Thanks all,



My original question appears to be now two (1) the distribution of my DV (hence what models to use; (2) specification of my lmer model to parse out variance components.



Topic (1): DV distribution

Yes, my measure is a sliding rule between 1-10 of subjective pain, so any number up to a single decimal is plausible. Is a linear model automatically excluded, or can (a) do a fitted/residual plot for checking; (b) log transform the dv if (a) shows evidence of  non-normality.



Going back to Rolf's point of social science, you are right. But realistically, many measures in biomechanics (which I am in), are analyzed using linear models, even though they are bounded. Example, a simple scalar height is bounded to a lower limit of zero, and an upper limit of what ever instrument is created. Joint angles are bounded physiologically too. So when are measures really -inf/inf?



Topic (2): lmer



Assuming my DV is appropriate for lmer, base on the experimental design used, I hope to receive some feedback on my fixed and random effects specification still ?



Thanks again all, for the kind response



Bernard



-----Original Message-----
From: bbolker at gmail.com<mailto:bbolker at gmail.com> <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Sent: Friday, June 15, 2018 2:28 AM
To: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
Cc: Rolf Turner <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>; Bernard Liew <B.Liew at bham.ac.uk<mailto:B.Liew at bham.ac.uk>>
Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study



More generally, the best way to fit this kind of model is to use an

*ordinal* model, which assumes the responses are in increasing sequence but does not assume the distance between levels (e.g. 1 vs 2,

2 vs 3 ...) is uniform.  However, I'm not sure how one would go about computing an ICC from ordinal data ... (the 'ordinal' package is the place to look for the model-fitting procedures). Googling it finds some stuff, but it seems that it doesn't necessarily apply to complex designs ...



https://stats.stackexchange.com/questions/3539/inter-rater-reliability-for-ordinal-or-interval-data

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/





On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:

> That?s a helpful clarification, Rolf. However, with gaussian normal

> errors in the linear model, we can?t *really* assume they would

> asymptote at 1 or 10. My suspicion is that these are likert-style

> ordered counts of some form, although the OP should clarify. In which

> case, the 1 or 10 are limits with censoring, as true values for some

> measured trait could exist outside those boundaries (and I suspect the

> model is forming predicted values outside of 1 or 10).

>

>

>

> On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:

>

>>

>>On 15/06/18 05:35, Doran, Harold wrote:

>>

>>> Well no, you?re specification is not right because your variable is

>>> not continuous as you note. Continuous means it is a real number

>>> between -Inf/Inf and you have boundaries between 1 and 10. So, you

>>> should not be using a linear model assuming the outcome is continuous.

>>

>>I think that the foregoing is a bit misleading.  For a variable to be

>>continuous it is not necessary for it to have a range from -infinity

>>to infinity.

>>

>>The OP says that dv  "is a continuous variable (scale 1-10)".  It is

>>not clear to me what this means.  The "obvious"/usual meaning or

>>interpretation would be that dv can take (only) the (positive integer)

>>values 1, 2, ..., 10.  If this is so, then a continuous model is not

>>appropriate.  (It should be noted however that people in the social

>>sciences do this sort of thing --- i.e. treat discrete variables as

>>continuous --- all the time.)

>>

>>It is *possible* that dv can take values in the real interval [1,10],

>>in which case it *is* continuous, and a "continuous model" is indeed

>>appropriate.

>>

>>The OP should clarify what the situation actually is.

>>

>>cheers,

>>

>>Rolf Turner

>>

>>--

>>Technical Editor ANZJS

>>Department of Statistics

>>University of Auckland

>>Phone: +64-9-373-7599 ext. 88276

>>

>>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk<mailto:B.Liew at bham.ac.uk>> wrote:

>>>

>>>> Dear Community,

>>>>

>>>>

>>>> I am doing a reliability study, using the methods of

>>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on

>>>> the lmer formulation and the use of the variance components.

>>>>

>>>> Background: I have 20 subjects, 2 fixed raters, 2 testing sessions,

>>>> and

>>>> 10 trials per sessions. my dependent variable is a continuous

>>>> variable (scale 1-10). Sessions are nested within each

>>>> subject-assessor combination. I desire a ICC (3) formulation of

>>>> inter-rater and inter-session reliability from the variance components.

>>>>

>>>> My lmer model is:

>>>>

>>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)

>>>>

>>>> Question:

>>>>

>>>>   1.  is the model formulation right? and is my interpretation of

>>>>the  variance components for ICC below right?

>>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) #

>>>>I  read that the variation of raters will be lumped with the residual

>>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var

>>>>(subj) +  var (subj:session) + var (residual))  some simulated data:

>>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2),

>>>>trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 3, sd =

>>>>1.5)

>>>>

>>>> I appreciate the kind response.

>>

>>

>

> _______________________________________________

> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list

> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Jun 15 16:26:36 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 15 Jun 2018 14:26:36 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>

Dear R mixed-model users,

I?d like to announce the release of my new package GLMMadaptive for fitting generalized linear mixed models using adaptive Gaussian quadrature. You may read more about it here: https://goo.gl/7pi8Sh

Any comments or suggestions are more than welcome.

Best,
Dimitris


Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

	[[alternative HTML version deleted]]


From pierre@de@villemereuil @ending from m@iloo@org  Fri Jun 15 17:05:04 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Fri, 15 Jun 2018 17:05:04 +0200
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
References: <D7481F39.515BB%hdoran@air.org> <D7486A52.515E4%hdoran@air.org>
 <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
Message-ID: <1749290.qfJmdIGWE2@ev8sa6>

Hi,

> However, I'm not sure how one would go about computing an ICC from ordinal data

I've never used the package "ordinal", but if it's anything like the "ordinal" family of MCMCglmm, then computing an ICC on the liability scale would be fairly easy, as one would just proceed as always and simply add the so-called "link variance" corresponding to the chosen link function (1 for probit, (pi^2)/3 for logit). E.g. for a given variance component Vcomp and a probit link:
ICC = Vcomp / (sum(variance components of the model) + 1)

However, computing an ICC on the data scale would be much more difficult as it is actually multivariate...

I think in the case when such scores were used, having the estimate on the liability scale make sense though, as the binning is more due to our inability of finely measuring this scale rather than an actual property of the system.

Cheers,
Pierre.

Le vendredi 15 juin 2018, 03:27:54 CEST Ben Bolker a ?crit :
> More generally, the best way to fit this kind of model is to use an
> *ordinal* model, which assumes the responses are in increasing
> sequence but does not assume the distance between levels (e.g. 1 vs 2,
> 2 vs 3 ...) is uniform.  However, I'm not sure how one would go about
> computing an ICC from ordinal data ... (the 'ordinal' package is the
> place to look for the model-fitting procedures). Googling it finds
> some stuff, but it seems that it doesn't necessarily apply to complex
> designs ...
> 
> https://stats.stackexchange.com/questions/3539/inter-rater-reliability-for-ordinal-or-interval-data
> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/
> 
> 
> On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
> > That?s a helpful clarification, Rolf. However, with gaussian normal errors
> > in the linear model, we can?t *really* assume they would asymptote at 1 or
> > 10. My suspicion is that these are likert-style ordered counts of some
> > form, although the OP should clarify. In which case, the 1 or 10 are
> > limits with censoring, as true values for some measured trait could exist
> > outside those boundaries (and I suspect the model is forming predicted
> > values outside of 1 or 10).
> >
> >
> >
> > On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
> >
> >>
> >>On 15/06/18 05:35, Doran, Harold wrote:
> >>
> >>> Well no, you?re specification is not right because your variable is not
> >>> continuous as you note. Continuous means it is a real number between
> >>> -Inf/Inf and you have boundaries between 1 and 10. So, you should not be
> >>> using a linear model assuming the outcome is continuous.
> >>
> >>I think that the foregoing is a bit misleading.  For a variable to be
> >>continuous it is not necessary for it to have a range from -infinity to
> >>infinity.
> >>
> >>The OP says that dv  "is a continuous variable (scale 1-10)".  It is not
> >>clear to me what this means.  The "obvious"/usual meaning or
> >>interpretation would be that dv can take (only) the (positive integer)
> >>values 1, 2, ..., 10.  If this is so, then a continuous model is not
> >>appropriate.  (It should be noted however that people in the social
> >>sciences do this sort of thing --- i.e. treat discrete variables as
> >>continuous --- all the time.)
> >>
> >>It is *possible* that dv can take values in the real interval [1,10], in
> >>which case it *is* continuous, and a "continuous model" is indeed
> >>appropriate.
> >>
> >>The OP should clarify what the situation actually is.
> >>
> >>cheers,
> >>
> >>Rolf Turner
> >>
> >>--
> >>Technical Editor ANZJS
> >>Department of Statistics
> >>University of Auckland
> >>Phone: +64-9-373-7599 ext. 88276
> >>
> >>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
> >>>
> >>>> Dear Community,
> >>>>
> >>>>
> >>>> I am doing a reliability study, using the methods of
> >>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on the
> >>>> lmer formulation and the use of the variance components.
> >>>>
> >>>> Background: I have 20 subjects, 2 fixed raters, 2 testing sessions, and
> >>>> 10 trials per sessions. my dependent variable is a continuous variable
> >>>> (scale 1-10). Sessions are nested within each subject-assessor
> >>>> combination. I desire a ICC (3) formulation of inter-rater and
> >>>> inter-session reliability from the variance components.
> >>>>
> >>>> My lmer model is:
> >>>>
> >>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
> >>>>
> >>>> Question:
> >>>>
> >>>>   1.  is the model formulation right? and is my interpretation of the
> >>>> variance components for ICC below right?
> >>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) # I
> >>>> read that the variation of raters will be lumped with the residual
> >>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var (subj) +
> >>>> var (subj:session) + var (residual))
> >>>> some simulated data:
> >>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2),
> >>>>trial
> >>>> = c(1:10))
> >>>> df$vas = rnorm (nrow (df_sim), mean = 3, sd = 1.5)
> >>>>
> >>>> I appreciate the kind response.
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Fri Jun 15 17:06:56 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 15 Jun 2018 11:06:56 -0400
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
References: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
Message-ID: <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>

It looks interesting (at an admittedly *very* quick initial glance).
Can you clarify how it differs from using lme4::glmer with nAGQ>1 ?

On Fri, Jun 15, 2018 at 10:26 AM, D. Rizopoulos
<d.rizopoulos at erasmusmc.nl> wrote:
> Dear R mixed-model users,
>
> I?d like to announce the release of my new package GLMMadaptive for fitting generalized linear mixed models using adaptive Gaussian quadrature. You may read more about it here: https://goo.gl/7pi8Sh
>
> Any comments or suggestions are more than welcome.
>
> Best,
> Dimitris
>
>
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From HDor@n @ending from @ir@org  Fri Jun 15 17:31:55 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Fri, 15 Jun 2018 15:31:55 +0000
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <1749290.qfJmdIGWE2@ev8sa6>
References: <D7481F39.515BB%hdoran@air.org> <D7486A52.515E4%hdoran@air.org>
 <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
 <1749290.qfJmdIGWE2@ev8sa6>
Message-ID: <BY2PR0501MB2008FBCAF0DA15FF2F8AE325CA7C0@BY2PR0501MB2008.namprd05.prod.outlook.com>

This seems to me like the tail is wagging the dog. I don't think the question should be framed around, "what can I do to get an ICC?" The question should be around what distributional family is appropriate given the observed data?

If an ICC cannot be made available after the appropriate link function is chosen, then I'm not sure that's really of any consequence. The point of a random effects model is *not* to yield an ICC. But, to yield appropriate estimates for the fixed effects and marginal variances.

If these data are treated as ordinal, that's a LOT of threshold parameters to estimate and might be quite expensive to compute. 


-----Original Message-----
From: Pierre de Villemereuil [mailto:pierre.de.villemereuil at mailoo.org] 
Sent: Friday, June 15, 2018 11:05 AM
To: r-sig-mixed-models at r-project.org
Cc: Ben Bolker <bbolker at gmail.com>; Doran, Harold <HDoran at air.org>; Bernard Liew <B.Liew at bham.ac.uk>
Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study

Hi,

> However, I'm not sure how one would go about computing an ICC from 
> ordinal data

I've never used the package "ordinal", but if it's anything like the "ordinal" family of MCMCglmm, then computing an ICC on the liability scale would be fairly easy, as one would just proceed as always and simply add the so-called "link variance" corresponding to the chosen link function (1 for probit, (pi^2)/3 for logit). E.g. for a given variance component Vcomp and a probit link:
ICC = Vcomp / (sum(variance components of the model) + 1)

However, computing an ICC on the data scale would be much more difficult as it is actually multivariate...

I think in the case when such scores were used, having the estimate on the liability scale make sense though, as the binning is more due to our inability of finely measuring this scale rather than an actual property of the system.

Cheers,
Pierre.

Le vendredi 15 juin 2018, 03:27:54 CEST Ben Bolker a ?crit :
> More generally, the best way to fit this kind of model is to use an
> *ordinal* model, which assumes the responses are in increasing 
> sequence but does not assume the distance between levels (e.g. 1 vs 2,
> 2 vs 3 ...) is uniform.  However, I'm not sure how one would go about 
> computing an ICC from ordinal data ... (the 'ordinal' package is the 
> place to look for the model-fitting procedures). Googling it finds 
> some stuff, but it seems that it doesn't necessarily apply to complex 
> designs ...
> 
> https://stats.stackexchange.com/questions/3539/inter-rater-reliability
> -for-ordinal-or-interval-data 
> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/
> 
> 
> On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
> > That?s a helpful clarification, Rolf. However, with gaussian normal 
> > errors in the linear model, we can?t *really* assume they would 
> > asymptote at 1 or 10. My suspicion is that these are likert-style 
> > ordered counts of some form, although the OP should clarify. In 
> > which case, the 1 or 10 are limits with censoring, as true values 
> > for some measured trait could exist outside those boundaries (and I 
> > suspect the model is forming predicted values outside of 1 or 10).
> >
> >
> >
> > On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
> >
> >>
> >>On 15/06/18 05:35, Doran, Harold wrote:
> >>
> >>> Well no, you?re specification is not right because your variable 
> >>> is not continuous as you note. Continuous means it is a real 
> >>> number between -Inf/Inf and you have boundaries between 1 and 10. 
> >>> So, you should not be using a linear model assuming the outcome is continuous.
> >>
> >>I think that the foregoing is a bit misleading.  For a variable to 
> >>be continuous it is not necessary for it to have a range from 
> >>-infinity to infinity.
> >>
> >>The OP says that dv  "is a continuous variable (scale 1-10)".  It is 
> >>not clear to me what this means.  The "obvious"/usual meaning or 
> >>interpretation would be that dv can take (only) the (positive 
> >>integer) values 1, 2, ..., 10.  If this is so, then a continuous 
> >>model is not appropriate.  (It should be noted however that people 
> >>in the social sciences do this sort of thing --- i.e. treat discrete 
> >>variables as continuous --- all the time.)
> >>
> >>It is *possible* that dv can take values in the real interval 
> >>[1,10], in which case it *is* continuous, and a "continuous model" 
> >>is indeed appropriate.
> >>
> >>The OP should clarify what the situation actually is.
> >>
> >>cheers,
> >>
> >>Rolf Turner
> >>
> >>--
> >>Technical Editor ANZJS
> >>Department of Statistics
> >>University of Auckland
> >>Phone: +64-9-373-7599 ext. 88276
> >>
> >>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
> >>>
> >>>> Dear Community,
> >>>>
> >>>>
> >>>> I am doing a reliability study, using the methods of 
> >>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question 
> >>>> on the lmer formulation and the use of the variance components.
> >>>>
> >>>> Background: I have 20 subjects, 2 fixed raters, 2 testing 
> >>>> sessions, and
> >>>> 10 trials per sessions. my dependent variable is a continuous 
> >>>> variable (scale 1-10). Sessions are nested within each 
> >>>> subject-assessor combination. I desire a ICC (3) formulation of 
> >>>> inter-rater and inter-session reliability from the variance components.
> >>>>
> >>>> My lmer model is:
> >>>>
> >>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
> >>>>
> >>>> Question:
> >>>>
> >>>>   1.  is the model formulation right? and is my interpretation of 
> >>>>the  variance components for ICC below right?
> >>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) 
> >>>># I  read that the variation of raters will be lumped with the residual
> >>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var 
> >>>>(subj) +  var (subj:session) + var (residual))  some simulated 
> >>>>data:
> >>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = 
> >>>>c(1:2), trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 
> >>>>3, sd = 1.5)
> >>>>
> >>>> I appreciate the kind response.
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From @bedim@il @ending from gm@il@com  Fri Jun 15 17:41:30 2018
From: @bedim@il @ending from gm@il@com (Mehdi Abedi)
Date: Fri, 15 Jun 2018 20:11:30 +0430
Subject: [R-sig-ME] (no subject)
Message-ID: <CADGhagiPVmsSXRHON4scrQcMvy4SPOMrwZLHp5b_ojoDpNB=bQ@mail.gmail.com>



	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Jun 15 18:34:32 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 15 Jun 2018 16:34:32 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
In-Reply-To: <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>
References: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
 <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEAF59C8@EXCH-RX03.erasmusmc.nl>

AFAIK, lme4::glmer with nAGQ>1 *only* works for scalar random effects. At least, when I try setting nAGQ > 1 for a random intercepts and random slopes model in lme4::glmer (lme4_1.1-17)  I get the error message:

Error in updateGlmerDevfun(devfun, glmod$reTrms, nAGQ = nAGQ) : 
  nAGQ > 1 is only available for models with a single, scalar random-effects term

GLMMadaptive::mixed_model implements the AGQ in such settings.

My main motivation to create this package is the longitudinal data analysis setting in which including something more than random intercepts is very typical. At least the students in my Repeated Measurements course (https://github.com/drizopoulos/Repeated_Measurements) have had some difficult times getting lme4::glmer() with a Laplace approximation to work in such cases.


-----Original Message-----
From: Ben Bolker <bbolker at gmail.com> 
Sent: Friday, June 15, 2018 5:07 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature

It looks interesting (at an admittedly *very* quick initial glance).
Can you clarify how it differs from using lme4::glmer with nAGQ>1 ?

On Fri, Jun 15, 2018 at 10:26 AM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:
> Dear R mixed-model users,
>
> I?d like to announce the release of my new package GLMMadaptive for 
> fitting generalized linear mixed models using adaptive Gaussian 
> quadrature. You may read more about it here: https://goo.gl/7pi8Sh
>
> Any comments or suggestions are more than welcome.
>
> Best,
> Dimitris
>
>
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker @ending from gm@il@com  Fri Jun 15 19:56:44 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 15 Jun 2018 13:56:44 -0400
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEAF59C8@EXCH-RX03.erasmusmc.nl>
References: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
 <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF59C8@EXCH-RX03.erasmusmc.nl>
Message-ID: <CABghstQM0QbpbaqyZ1-gH8c2g7j_1PN9TKje5t41OzwzqhsEVA@mail.gmail.com>

Good point.  Extending AGQ to more complex models in lme4 is something
that's been on my list for a long time, but it's great to see someone
meeting the need.  Even if I or someone does eventually get it working
in lme4, two implementations are always better than one ...

  For those interested in this topic, there are a few other approaches
to improved frequentist estimates (i.e. without going full-Bayesian)
that are implemented in R:  Helen Ogden's glmmsr package implements
sequential reduction and importance sampling methods, The glmm and
bernor packages use other flavors of importance sampling/MC likelihood
approximations. glmmADMB has importance sampling; TMB (the engine
underlying glmmTMB) has an importance-sampling method, but it hasn't
(yet) been integrated in glmmTMB ...

  cheers
    Ben Bolker


On Fri, Jun 15, 2018 at 12:34 PM, D. Rizopoulos
<d.rizopoulos at erasmusmc.nl> wrote:
> AFAIK, lme4::glmer with nAGQ>1 *only* works for scalar random effects. At least, when I try setting nAGQ > 1 for a random intercepts and random slopes model in lme4::glmer (lme4_1.1-17)  I get the error message:
>
> Error in updateGlmerDevfun(devfun, glmod$reTrms, nAGQ = nAGQ) :
>   nAGQ > 1 is only available for models with a single, scalar random-effects term
>
> GLMMadaptive::mixed_model implements the AGQ in such settings.
>
> My main motivation to create this package is the longitudinal data analysis setting in which including something more than random intercepts is very typical. At least the students in my Repeated Measurements course (https://github.com/drizopoulos/Repeated_Measurements) have had some difficult times getting lme4::glmer() with a Laplace approximation to work in such cases.
>
>
> -----Original Message-----
> From: Ben Bolker <bbolker at gmail.com>
> Sent: Friday, June 15, 2018 5:07 PM
> To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
>
> It looks interesting (at an admittedly *very* quick initial glance).
> Can you clarify how it differs from using lme4::glmer with nAGQ>1 ?
>
> On Fri, Jun 15, 2018 at 10:26 AM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:
>> Dear R mixed-model users,
>>
>> I?d like to announce the release of my new package GLMMadaptive for
>> fitting generalized linear mixed models using adaptive Gaussian
>> quadrature. You may read more about it here: https://goo.gl/7pi8Sh
>>
>> Any comments or suggestions are more than welcome.
>>
>> Best,
>> Dimitris
>>
>>
>> Professor of Biostatistics
>> Erasmus University Medical Center
>> The Netherlands
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From B@Liew @ending from bh@m@@c@uk  Fri Jun 15 07:20:58 2018
From: B@Liew @ending from bh@m@@c@uk (Bernard Liew)
Date: Fri, 15 Jun 2018 05:20:58 +0000
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
References: <D7481F39.515BB%hdoran@air.org>
 <4af67f99-18f6-1d17-e873-6612152b753d@auckland.ac.nz>
 <D7486A52.515E4%hdoran@air.org>
 <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
Message-ID: <A901AC7187F75B41BF677B0A610C0976E8D453@EX11.adf.bham.ac.uk>

Thanks all,



My original question appears to be now two (1) the distribution of my DV (hence what models to use; (2) specification of my lmer model to parse out variance components.



Topic (1): DV distribution

Yes, my measure is a sliding rule between 1-10 of subjective pain, so any number up to a single decimal is plausible. Is a linear model automatically excluded, or can (a) do a fitted/residual plot for checking; (b) log transform the dv if (a) shows evidence of  non-normality.



Going back to Rolf's point of social science, you are right. But realistically, many measures in biomechanics (which I am in), are analyzed using linear models, even though they are bounded. Example, a simple scalar height is bounded to a lower limit of zero, and an upper limit of what ever instrument is created. Joint angles are bounded physiologically too. So when are measures really -inf/inf?



Topic (2): lmer



Assuming my DV is appropriate for lmer, base on the experimental design used, I hope to receive some feedback on my fixed and random effects specification still ?



Thanks again all, for the kind response



Bernard



-----Original Message-----
From: bbolker at gmail.com <bbolker at gmail.com>
Sent: Friday, June 15, 2018 2:28 AM
To: Doran, Harold <HDoran at air.org>
Cc: Rolf Turner <r.turner at auckland.ac.nz>; r-sig-mixed-models at r-project.org; Bernard Liew <B.Liew at bham.ac.uk>
Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study



More generally, the best way to fit this kind of model is to use an

*ordinal* model, which assumes the responses are in increasing sequence but does not assume the distance between levels (e.g. 1 vs 2,

2 vs 3 ...) is uniform.  However, I'm not sure how one would go about computing an ICC from ordinal data ... (the 'ordinal' package is the place to look for the model-fitting procedures). Googling it finds some stuff, but it seems that it doesn't necessarily apply to complex designs ...



https://stats.stackexchange.com/questions/3539/inter-rater-reliability-for-ordinal-or-interval-data

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/





On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:

> That?s a helpful clarification, Rolf. However, with gaussian normal

> errors in the linear model, we can?t *really* assume they would

> asymptote at 1 or 10. My suspicion is that these are likert-style

> ordered counts of some form, although the OP should clarify. In which

> case, the 1 or 10 are limits with censoring, as true values for some

> measured trait could exist outside those boundaries (and I suspect the

> model is forming predicted values outside of 1 or 10).

>

>

>

> On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:

>

>>

>>On 15/06/18 05:35, Doran, Harold wrote:

>>

>>> Well no, you?re specification is not right because your variable is

>>> not continuous as you note. Continuous means it is a real number

>>> between -Inf/Inf and you have boundaries between 1 and 10. So, you

>>> should not be using a linear model assuming the outcome is continuous.

>>

>>I think that the foregoing is a bit misleading.  For a variable to be

>>continuous it is not necessary for it to have a range from -infinity

>>to infinity.

>>

>>The OP says that dv  "is a continuous variable (scale 1-10)".  It is

>>not clear to me what this means.  The "obvious"/usual meaning or

>>interpretation would be that dv can take (only) the (positive integer)

>>values 1, 2, ..., 10.  If this is so, then a continuous model is not

>>appropriate.  (It should be noted however that people in the social

>>sciences do this sort of thing --- i.e. treat discrete variables as

>>continuous --- all the time.)

>>

>>It is *possible* that dv can take values in the real interval [1,10],

>>in which case it *is* continuous, and a "continuous model" is indeed

>>appropriate.

>>

>>The OP should clarify what the situation actually is.

>>

>>cheers,

>>

>>Rolf Turner

>>

>>--

>>Technical Editor ANZJS

>>Department of Statistics

>>University of Auckland

>>Phone: +64-9-373-7599 ext. 88276

>>

>>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk<mailto:B.Liew at bham.ac.uk>> wrote:

>>>

>>>> Dear Community,

>>>>

>>>>

>>>> I am doing a reliability study, using the methods of

>>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question on

>>>> the lmer formulation and the use of the variance components.

>>>>

>>>> Background: I have 20 subjects, 2 fixed raters, 2 testing sessions,

>>>> and

>>>> 10 trials per sessions. my dependent variable is a continuous

>>>> variable (scale 1-10). Sessions are nested within each

>>>> subject-assessor combination. I desire a ICC (3) formulation of

>>>> inter-rater and inter-session reliability from the variance components.

>>>>

>>>> My lmer model is:

>>>>

>>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)

>>>>

>>>> Question:

>>>>

>>>>   1.  is the model formulation right? and is my interpretation of

>>>>the  variance components for ICC below right?

>>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) #

>>>>I  read that the variation of raters will be lumped with the residual

>>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var

>>>>(subj) +  var (subj:session) + var (residual))  some simulated data:

>>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = c(1:2),

>>>>trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 3, sd =

>>>>1.5)

>>>>

>>>> I appreciate the kind response.

>>

>>

>

> _______________________________________________

> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list

> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From li@_mori@ @ending from hotm@il@cl  Fri Jun 15 18:49:41 2018
From: li@_mori@ @ending from hotm@il@cl (lia moris)
Date: Fri, 15 Jun 2018 16:49:41 +0000
Subject: [R-sig-ME] Please help on glmer in lme4
Message-ID: <CY4PR16MB0039A6636EBC0001A84E48C5F07C0@CY4PR16MB0039.namprd16.prod.outlook.com>

Dear R,


The stage 1 (nAGQ=0) use the initial values for theta by default and initial values for beta is obtained from a generalized linear model fit. The stage 2 initial values are  theta estimated from stage 1 and initial values for beta  the same ones from stage 1, right?



Thank's!


Lia


	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Jun 15 20:31:58 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 15 Jun 2018 18:31:58 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
In-Reply-To: <CABghstQM0QbpbaqyZ1-gH8c2g7j_1PN9TKje5t41OzwzqhsEVA@mail.gmail.com>
References: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
 <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF59C8@EXCH-RX03.erasmusmc.nl>
 <CABghstQM0QbpbaqyZ1-gH8c2g7j_1PN9TKje5t41OzwzqhsEVA@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEAF5BCE@EXCH-RX03.erasmusmc.nl>

Indeed! GLMMadaptive::mixed_model is also more flexible in allowing users to define their own mixed models by specifying the log-density of the repeated measurements outcome, i.e., something similar to what Proc NLMIXED in doing in SAS. More info in the vignette: https://cran.r-project.org/web/packages/GLMMadaptive/vignettes/Custom_Models.html 

Best,
Dimitris


-----Original Message-----
From: Ben Bolker <bbolker at gmail.com> 
Sent: Friday, June 15, 2018 7:57 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature

Good point.  Extending AGQ to more complex models in lme4 is something that's been on my list for a long time, but it's great to see someone meeting the need.  Even if I or someone does eventually get it working in lme4, two implementations are always better than one ...

  For those interested in this topic, there are a few other approaches to improved frequentist estimates (i.e. without going full-Bayesian) that are implemented in R:  Helen Ogden's glmmsr package implements sequential reduction and importance sampling methods, The glmm and bernor packages use other flavors of importance sampling/MC likelihood approximations. glmmADMB has importance sampling; TMB (the engine underlying glmmTMB) has an importance-sampling method, but it hasn't
(yet) been integrated in glmmTMB ...

  cheers
    Ben Bolker


On Fri, Jun 15, 2018 at 12:34 PM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:
> AFAIK, lme4::glmer with nAGQ>1 *only* works for scalar random effects. At least, when I try setting nAGQ > 1 for a random intercepts and random slopes model in lme4::glmer (lme4_1.1-17)  I get the error message:
>
> Error in updateGlmerDevfun(devfun, glmod$reTrms, nAGQ = nAGQ) :
>   nAGQ > 1 is only available for models with a single, scalar 
> random-effects term
>
> GLMMadaptive::mixed_model implements the AGQ in such settings.
>
> My main motivation to create this package is the longitudinal data analysis setting in which including something more than random intercepts is very typical. At least the students in my Repeated Measurements course (https://github.com/drizopoulos/Repeated_Measurements) have had some difficult times getting lme4::glmer() with a Laplace approximation to work in such cases.
>
>
> -----Original Message-----
> From: Ben Bolker <bbolker at gmail.com>
> Sent: Friday, June 15, 2018 5:07 PM
> To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
>
> It looks interesting (at an admittedly *very* quick initial glance).
> Can you clarify how it differs from using lme4::glmer with nAGQ>1 ?
>
> On Fri, Jun 15, 2018 at 10:26 AM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:
>> Dear R mixed-model users,
>>
>> I?d like to announce the release of my new package GLMMadaptive for 
>> fitting generalized linear mixed models using adaptive Gaussian 
>> quadrature. You may read more about it here: https://goo.gl/7pi8Sh
>>
>> Any comments or suggestions are more than welcome.
>>
>> Best,
>> Dimitris
>>
>>
>> Professor of Biostatistics
>> Erasmus University Medical Center
>> The Netherlands
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker @ending from gm@il@com  Fri Jun 15 21:05:10 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 15 Jun 2018 15:05:10 -0400
Subject: [R-sig-ME] Please help on glmer in lme4
In-Reply-To: <CY4PR16MB0039A6636EBC0001A84E48C5F07C0@CY4PR16MB0039.namprd16.prod.outlook.com>
References: <CY4PR16MB0039A6636EBC0001A84E48C5F07C0@CY4PR16MB0039.namprd16.prod.outlook.com>
Message-ID: <b9c384fc-8d36-d09a-fec1-1ffaa06587cf@gmail.com>


  Not quite, I think.  It's *much* more obscure than it should be, but I
believe that the initial GLM fixed-effects parameters in both stages are
set to a vector of zeros, not to the results of an initial GLM fit.  (In
the nAGQ=0 phase, the fixed effects parameters are profiled out, not
used as part of the high-level optimization.) The following two lines
are the proof (not at all obvious!)

https://github.com/lme4/lme4/blob/5071612b79bbc86ef7ae185249baf18c62afca56/R/modular.R#L430

https://github.com/lme4/lme4/blob/5071612b79bbc86ef7ae185249baf18c62afca56/R/AllClass.R#L80

On 2018-06-15 12:49 PM, lia moris wrote:
> Dear R,
> 
> 
> The stage 1 (nAGQ=0) use the initial values for theta by default and
> initial values for beta is obtained from a generalized linear model
> fit. The stage 2 initial values are  theta estimated from stage 1 and
> initial values for beta  the same ones from stage 1, right?
> 
> 
> 
> Thank's!
> 
> 
> Lia
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @e@n@m@ce@ch @ending from gm@il@com  Fri Jun 15 21:37:18 2018
From: @e@n@m@ce@ch @ending from gm@il@com (Sean MacEachern)
Date: Fri, 15 Jun 2018 12:37:18 -0700
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEAF5BCE@EXCH-RX03.erasmusmc.nl>
References: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
 <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF59C8@EXCH-RX03.erasmusmc.nl>
 <CABghstQM0QbpbaqyZ1-gH8c2g7j_1PN9TKje5t41OzwzqhsEVA@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF5BCE@EXCH-RX03.erasmusmc.nl>
Message-ID: <CAApsJR7NcvV4_UcdrHXa7NS4A2JFF3fBHf0fxWZwCF2iix9pWw@mail.gmail.com>

Looks interesting. Would it be possible to fit a Numerator relationship
matrix as a random effect similarly to MCMCglmm or Asreml for binary or
categorical datasets?

Regards,

Sean MacEachern

On Fri, Jun 15, 2018 at 12:09 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
wrote:

> Indeed! GLMMadaptive::mixed_model is also more flexible in allowing users
> to define their own mixed models by specifying the log-density of the
> repeated measurements outcome, i.e., something similar to what Proc NLMIXED
> in doing in SAS. More info in the vignette:
> https://cran.r-project.org/web/packages/GLMMadaptive/vignettes/Custom_Models.html
>
> Best,
> Dimitris
>
>
> -----Original Message-----
> From: Ben Bolker <bbolker at gmail.com>
> Sent: Friday, June 15, 2018 7:57 PM
> To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
>
> Good point.  Extending AGQ to more complex models in lme4 is something
> that's been on my list for a long time, but it's great to see someone
> meeting the need.  Even if I or someone does eventually get it working in
> lme4, two implementations are always better than one ...
>
>   For those interested in this topic, there are a few other approaches to
> improved frequentist estimates (i.e. without going full-Bayesian) that are
> implemented in R:  Helen Ogden's glmmsr package implements sequential
> reduction and importance sampling methods, The glmm and bernor packages use
> other flavors of importance sampling/MC likelihood approximations. glmmADMB
> has importance sampling; TMB (the engine underlying glmmTMB) has an
> importance-sampling method, but it hasn't
> (yet) been integrated in glmmTMB ...
>
>   cheers
>     Ben Bolker
>
>
> On Fri, Jun 15, 2018 at 12:34 PM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> wrote:
> > AFAIK, lme4::glmer with nAGQ>1 *only* works for scalar random effects.
> At least, when I try setting nAGQ > 1 for a random intercepts and random
> slopes model in lme4::glmer (lme4_1.1-17)  I get the error message:
> >
> > Error in updateGlmerDevfun(devfun, glmod$reTrms, nAGQ = nAGQ) :
> >   nAGQ > 1 is only available for models with a single, scalar
> > random-effects term
> >
> > GLMMadaptive::mixed_model implements the AGQ in such settings.
> >
> > My main motivation to create this package is the longitudinal data
> analysis setting in which including something more than random intercepts
> is very typical. At least the students in my Repeated Measurements course (
> https://github.com/drizopoulos/Repeated_Measurements) have had some
> difficult times getting lme4::glmer() with a Laplace approximation to work
> in such cases.
> >
> >
> > -----Original Message-----
> > From: Ben Bolker <bbolker at gmail.com>
> > Sent: Friday, June 15, 2018 5:07 PM
> > To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
> >
> > It looks interesting (at an admittedly *very* quick initial glance).
> > Can you clarify how it differs from using lme4::glmer with nAGQ>1 ?
> >
> > On Fri, Jun 15, 2018 at 10:26 AM, D. Rizopoulos <
> d.rizopoulos at erasmusmc.nl> wrote:
> >> Dear R mixed-model users,
> >>
> >> I?d like to announce the release of my new package GLMMadaptive for
> >> fitting generalized linear mixed models using adaptive Gaussian
> >> quadrature. You may read more about it here: https://goo.gl/7pi8Sh
> >>
> >> Any comments or suggestions are more than welcome.
> >>
> >> Best,
> >> Dimitris
> >>
> >>
> >> Professor of Biostatistics
> >> Erasmus University Medical Center
> >> The Netherlands
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Jun 15 21:57:21 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 15 Jun 2018 19:57:21 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
In-Reply-To: <CAApsJR7NcvV4_UcdrHXa7NS4A2JFF3fBHf0fxWZwCF2iix9pWw@mail.gmail.com>
References: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
 <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF59C8@EXCH-RX03.erasmusmc.nl>
 <CABghstQM0QbpbaqyZ1-gH8c2g7j_1PN9TKje5t41OzwzqhsEVA@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF5BCE@EXCH-RX03.erasmusmc.nl>
 <CAApsJR7NcvV4_UcdrHXa7NS4A2JFF3fBHf0fxWZwCF2iix9pWw@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEAF5CE2@EXCH-RX03.erasmusmc.nl>

No, this is not currently possible. I will need to think if it can be ?easily? incorporated in the package?

Best,
Dimitris


From: Sean MacEachern <sean.maceach at gmail.com>
Sent: Friday, June 15, 2018 9:37 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: bbolker at gmail.com; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature

Looks interesting. Would it be possible to fit a Numerator relationship matrix as a random effect similarly to MCMCglmm or Asreml for binary or categorical datasets?

Regards,

Sean MacEachern

On Fri, Jun 15, 2018 at 12:09 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>> wrote:
Indeed! GLMMadaptive::mixed_model is also more flexible in allowing users to define their own mixed models by specifying the log-density of the repeated measurements outcome, i.e., something similar to what Proc NLMIXED in doing in SAS. More info in the vignette: https://cran.r-project.org/web/packages/GLMMadaptive/vignettes/Custom_Models.html

Best,
Dimitris


-----Original Message-----
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Sent: Friday, June 15, 2018 7:57 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature

Good point.  Extending AGQ to more complex models in lme4 is something that's been on my list for a long time, but it's great to see someone meeting the need.  Even if I or someone does eventually get it working in lme4, two implementations are always better than one ...

  For those interested in this topic, there are a few other approaches to improved frequentist estimates (i.e. without going full-Bayesian) that are implemented in R:  Helen Ogden's glmmsr package implements sequential reduction and importance sampling methods, The glmm and bernor packages use other flavors of importance sampling/MC likelihood approximations. glmmADMB has importance sampling; TMB (the engine underlying glmmTMB) has an importance-sampling method, but it hasn't
(yet) been integrated in glmmTMB ...

  cheers
    Ben Bolker


On Fri, Jun 15, 2018 at 12:34 PM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>> wrote:
> AFAIK, lme4::glmer with nAGQ>1 *only* works for scalar random effects. At least, when I try setting nAGQ > 1 for a random intercepts and random slopes model in lme4::glmer (lme4_1.1-17)  I get the error message:
>
> Error in updateGlmerDevfun(devfun, glmod$reTrms, nAGQ = nAGQ) :
>   nAGQ > 1 is only available for models with a single, scalar
> random-effects term
>
> GLMMadaptive::mixed_model implements the AGQ in such settings.
>
> My main motivation to create this package is the longitudinal data analysis setting in which including something more than random intercepts is very typical. At least the students in my Repeated Measurements course (https://github.com/drizopoulos/Repeated_Measurements) have had some difficult times getting lme4::glmer() with a Laplace approximation to work in such cases.
>
>
> -----Original Message-----
> From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
> Sent: Friday, June 15, 2018 5:07 PM
> To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
>
> It looks interesting (at an admittedly *very* quick initial glance).
> Can you clarify how it differs from using lme4::glmer with nAGQ>1 ?
>
> On Fri, Jun 15, 2018 at 10:26 AM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>> wrote:
>> Dear R mixed-model users,
>>
>> I?d like to announce the release of my new package GLMMadaptive for
>> fitting generalized linear mixed models using adaptive Gaussian
>> quadrature. You may read more about it here: https://goo.gl/7pi8Sh
>>
>> Any comments or suggestions are more than welcome.
>>
>> Best,
>> Dimitris
>>
>>
>> Professor of Biostatistics
>> Erasmus University Medical Center
>> The Netherlands
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From c@b@@tride @ending from @heffield@@c@uk  Sat Jun 16 13:01:49 2018
From: c@b@@tride @ending from @heffield@@c@uk (Chris Stride)
Date: Sat, 16 Jun 2018 12:01:49 +0100
Subject: [R-sig-ME] random effects covariance matrix specification in nlme
In-Reply-To: <3602e304-c27f-0b79-35fd-65268807a931@highstat.com>
References: <mailman.16151.1234.1519633022.1673.r-sig-mixed-models@r-project.org>
 <3602e304-c27f-0b79-35fd-65268807a931@highstat.com>
Message-ID: <ef0374eb-d395-4a8d-994e-25ca78c649e9@sheffield.ac.uk>

Hi

I'm trying to fit a mixed effects exponential decay model, in which I 
have random effects for the initial value (init), the asymptote (asymp), 
and the rate (rate).

The catch is that I'd also like to estimate the correlation between init 
and asymp, but not between init and rate, or asymp and rate.

Now using? random = pdDiag(init + asymp + rate ~ 1) has none of the 
random effects correlated

And using? random = pdSymm(init + asymp + rate ~ 1) has all three of the 
random effects correlated

How do I specify just the correlation I want?

cheers

Chris


From li@_mori@ @ending from hotm@il@cl  Sat Jun 16 00:10:04 2018
From: li@_mori@ @ending from hotm@il@cl (lia moris)
Date: Fri, 15 Jun 2018 22:10:04 +0000
Subject: [R-sig-ME] start in glmer
Message-ID: <CY4PR16MB0039DB924078C863E69827D3F07C0@CY4PR16MB0039.namprd16.prod.outlook.com>

Hello,


The start[["fixef"]] (glmer function lme4 package) use a vector of zeros always? Than is, with nAGQ=1 (Laplace) or nAGQ>1 (Gauss-Hermite)?


Thank's


Lia

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Sat Jun 16 14:54:05 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Sat, 16 Jun 2018 12:54:05 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
In-Reply-To: <239123094.506633.1529136540477@mail.yahoo.com>
References: <7191AFC7255B4F49A30707E39BEAD05FDEAF54E0@EXCH-RX03.erasmusmc.nl>
 <CABghstSyhUQKZnHAisG-uzvAOde2Ej=zcQUbqp9Z6FYRaWMuig@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF59C8@EXCH-RX03.erasmusmc.nl>
 <CABghstQM0QbpbaqyZ1-gH8c2g7j_1PN9TKje5t41OzwzqhsEVA@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF5BCE@EXCH-RX03.erasmusmc.nl>
 <CAApsJR7NcvV4_UcdrHXa7NS4A2JFF3fBHf0fxWZwCF2iix9pWw@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEAF5CE2@EXCH-RX03.erasmusmc.nl>
 <239123094.506633.1529136540477@mail.yahoo.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEAF65E7@EXCH-RX03.erasmusmc.nl>

Yes, this is in my plans to include in future versions of the package ? For now I?m focusing on finalizing/extending the methods for the standard generics. Most notably, including subject-specific (dynamic) predictions with standard errors in the predict() method. The development version of the package is on my dedicated GitHub repo.

Best,
Dimitris


From: Christopher Stanley <stanleychristopher1 at yahoo.com>
Sent: Saturday, June 16, 2018 10:09 AM
To: Sean MacEachern <sean.maceach at gmail.com>; D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature

Dimitris, the flexibility sounds great. Will this package allow users to specify zero-inflated (poisson/negative binomial) count data as well?

Best
Christopher

On Friday, June 15, 2018, 9:57:41 PM GMT+2, D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>> wrote:


No, this is not currently possible. I will need to think if it can be ?easily? incorporated in the package?

Best,
Dimitris


From: Sean MacEachern <sean.maceach at gmail.com<mailto:sean.maceach at gmail.com>>
Sent: Friday, June 15, 2018 9:37 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>
Cc: bbolker at gmail.com<mailto:bbolker at gmail.com>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature

Looks interesting. Would it be possible to fit a Numerator relationship matrix as a random effect similarly to MCMCglmm or Asreml for binary or categorical datasets?

Regards,

Sean MacEachern

On Fri, Jun 15, 2018 at 12:09 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl><mailto:d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>> wrote:
Indeed! GLMMadaptive::mixed_model is also more flexible in allowing users to define their own mixed models by specifying the log-density of the repeated measurements outcome, i.e., something similar to what Proc NLMIXED in doing in SAS. More info in the vignette: https://cran.r-project.org/web/packages/GLMMadaptive/vignettes/Custom_Models.html

Best,
Dimitris


-----Original Message-----
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com><mailto:bbolker at gmail.com<mailto:bbolker at gmail.com>>>
Sent: Friday, June 15, 2018 7:57 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl><mailto:d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature

Good point.  Extending AGQ to more complex models in lme4 is something that's been on my list for a long time, but it's great to see someone meeting the need.  Even if I or someone does eventually get it working in lme4, two implementations are always better than one ...

  For those interested in this topic, there are a few other approaches to improved frequentist estimates (i.e. without going full-Bayesian) that are implemented in R:  Helen Ogden's glmmsr package implements sequential reduction and importance sampling methods, The glmm and bernor packages use other flavors of importance sampling/MC likelihood approximations. glmmADMB has importance sampling; TMB (the engine underlying glmmTMB) has an importance-sampling method, but it hasn't
(yet) been integrated in glmmTMB ...

  cheers
    Ben Bolker


On Fri, Jun 15, 2018 at 12:34 PM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl><mailto:d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>> wrote:
> AFAIK, lme4::glmer with nAGQ>1 *only* works for scalar random effects. At least, when I try setting nAGQ > 1 for a random intercepts and random slopes model in lme4::glmer (lme4_1.1-17)  I get the error message:
>
> Error in updateGlmerDevfun(devfun, glmod$reTrms, nAGQ = nAGQ) :
>  nAGQ > 1 is only available for models with a single, scalar
> random-effects term
>
> GLMMadaptive::mixed_model implements the AGQ in such settings.
>
> My main motivation to create this package is the longitudinal data analysis setting in which including something more than random intercepts is very typical. At least the students in my Repeated Measurements course (https://github.com/drizopoulos/Repeated_Measurements) have had some difficult times getting lme4::glmer() with a Laplace approximation to work in such cases.
>
>
> -----Original Message-----
> From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com><mailto:bbolker at gmail.com<mailto:bbolker at gmail.com>>>
> Sent: Friday, June 15, 2018 5:07 PM
> To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl><mailto:d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
> Subject: Re: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature
>
> It looks interesting (at an admittedly *very* quick initial glance).
> Can you clarify how it differs from using lme4::glmer with nAGQ>1 ?
>
> On Fri, Jun 15, 2018 at 10:26 AM, D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl><mailto:d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>> wrote:
>> Dear R mixed-model users,
>>
>> I?d like to announce the release of my new package GLMMadaptive for
>> fitting generalized linear mixed models using adaptive Gaussian
>> quadrature. You may read more about it here: https://goo.gl/7pi8Sh
>>
>> Any comments or suggestions are more than welcome.
>>
>> Best,
>> Dimitris
>>
>>
>> Professor of Biostatistics
>> Erasmus University Medical Center
>> The Netherlands
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

    [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Sat Jun 16 19:08:57 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sat, 16 Jun 2018 13:08:57 -0400
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <A901AC7187F75B41BF677B0A610C0976E8D5A1@EX11.adf.bham.ac.uk>
References: <D7481F39.515BB%hdoran@air.org> <D7486A52.515E4%hdoran@air.org>
 <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
 <1749290.qfJmdIGWE2@ev8sa6>
 <A901AC7187F75B41BF677B0A610C0976E8D5A1@EX11.adf.bham.ac.uk>
Message-ID: <214a0b79-f054-4c3d-44d1-1db849bd34f1@gmail.com>


  These extra terms are (I think) the 'residual' variances corresponding
to different GLM families, which are fixed rather than estimated.  You
might find Nakagawa and Schielzeth "Repeatability for Gaussian and
non-Gaussian data" (Biological Reviews 2010) useful ...

On 2018-06-16 01:02 PM, Bernard Liew wrote:
> Thanks Pierre for the suggestion to use MCMCglmm. Very useful.
> 
> 1) Can I ask why when taking the ratio of the variance components, the denominator is ICC = Vcomp / (sum(variance components of the model) + 1)? Why is the one added?
> 
> 2) I have tried mixed ordinal modelling using "ordinal" or MCMCglmm, and noticed the variance of the residuals of the model is not produced. I have also read that the residual is assumed to be as you mentioned (pi^2)/3. Is there a reason (maybe a not so technical one?)
> 
> Kind regards,
> Bernard
> 
> -----Original Message-----
> From: pierre.de.villemereuil at mailoo.org <pierre.de.villemereuil at mailoo.org> 
> Sent: Friday, June 15, 2018 4:05 PM
> To: r-sig-mixed-models at r-project.org
> Cc: Ben Bolker <bbolker at gmail.com>; Doran, Harold <HDoran at air.org>; Bernard Liew <B.Liew at bham.ac.uk>
> Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study
> 
> Hi,
> 
>> However, I'm not sure how one would go about computing an ICC from 
>> ordinal data
> 
> I've never used the package "ordinal", but if it's anything like the "ordinal" family of MCMCglmm, then computing an ICC on the liability scale would be fairly easy, as one would just proceed as always and simply add the so-called "link variance" corresponding to the chosen link function (1 for probit, (pi^2)/3 for logit). E.g. for a given variance component Vcomp and a probit link:
> ICC = Vcomp / (sum(variance components of the model) + 1)
> 
> However, computing an ICC on the data scale would be much more difficult as it is actually multivariate...
> 
> I think in the case when such scores were used, having the estimate on the liability scale make sense though, as the binning is more due to our inability of finely measuring this scale rather than an actual property of the system.
> 
> Cheers,
> Pierre.
> 
> Le vendredi 15 juin 2018, 03:27:54 CEST Ben Bolker a ?crit :
>> More generally, the best way to fit this kind of model is to use an
>> *ordinal* model, which assumes the responses are in increasing 
>> sequence but does not assume the distance between levels (e.g. 1 vs 2,
>> 2 vs 3 ...) is uniform.  However, I'm not sure how one would go about 
>> computing an ICC from ordinal data ... (the 'ordinal' package is the 
>> place to look for the model-fitting procedures). Googling it finds 
>> some stuff, but it seems that it doesn't necessarily apply to complex 
>> designs ...
>>
>> https://stats.stackexchange.com/questions/3539/inter-rater-reliability
>> -for-ordinal-or-interval-data 
>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/
>>
>>
>> On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
>>> That?s a helpful clarification, Rolf. However, with gaussian normal 
>>> errors in the linear model, we can?t *really* assume they would 
>>> asymptote at 1 or 10. My suspicion is that these are likert-style 
>>> ordered counts of some form, although the OP should clarify. In 
>>> which case, the 1 or 10 are limits with censoring, as true values 
>>> for some measured trait could exist outside those boundaries (and I 
>>> suspect the model is forming predicted values outside of 1 or 10).
>>>
>>>
>>>
>>> On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>>
>>>>
>>>> On 15/06/18 05:35, Doran, Harold wrote:
>>>>
>>>>> Well no, you?re specification is not right because your variable 
>>>>> is not continuous as you note. Continuous means it is a real 
>>>>> number between -Inf/Inf and you have boundaries between 1 and 10. 
>>>>> So, you should not be using a linear model assuming the outcome is continuous.
>>>>
>>>> I think that the foregoing is a bit misleading.  For a variable to 
>>>> be continuous it is not necessary for it to have a range from 
>>>> -infinity to infinity.
>>>>
>>>> The OP says that dv  "is a continuous variable (scale 1-10)".  It is 
>>>> not clear to me what this means.  The "obvious"/usual meaning or 
>>>> interpretation would be that dv can take (only) the (positive 
>>>> integer) values 1, 2, ..., 10.  If this is so, then a continuous 
>>>> model is not appropriate.  (It should be noted however that people 
>>>> in the social sciences do this sort of thing --- i.e. treat discrete 
>>>> variables as continuous --- all the time.)
>>>>
>>>> It is *possible* that dv can take values in the real interval 
>>>> [1,10], in which case it *is* continuous, and a "continuous model" 
>>>> is indeed appropriate.
>>>>
>>>> The OP should clarify what the situation actually is.
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> --
>>>> Technical Editor ANZJS
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>>
>>>>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
>>>>>
>>>>>> Dear Community,
>>>>>>
>>>>>>
>>>>>> I am doing a reliability study, using the methods of 
>>>>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question 
>>>>>> on the lmer formulation and the use of the variance components.
>>>>>>
>>>>>> Background: I have 20 subjects, 2 fixed raters, 2 testing 
>>>>>> sessions, and
>>>>>> 10 trials per sessions. my dependent variable is a continuous 
>>>>>> variable (scale 1-10). Sessions are nested within each 
>>>>>> subject-assessor combination. I desire a ICC (3) formulation of 
>>>>>> inter-rater and inter-session reliability from the variance components.
>>>>>>
>>>>>> My lmer model is:
>>>>>>
>>>>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
>>>>>>
>>>>>> Question:
>>>>>>
>>>>>>   1.  is the model formulation right? and is my interpretation of 
>>>>>> the  variance components for ICC below right?
>>>>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) 
>>>>>> # I  read that the variation of raters will be lumped with the residual
>>>>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var 
>>>>>> (subj) +  var (subj:session) + var (residual))  some simulated 
>>>>>> data:
>>>>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = 
>>>>>> c(1:2), trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 
>>>>>> 3, sd = 1.5)
>>>>>>
>>>>>> I appreciate the kind response.
>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>


From pierre@de@villemereuil @ending from m@iloo@org  Sat Jun 16 20:28:17 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Sat, 16 Jun 2018 20:28:17 +0200
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <A901AC7187F75B41BF677B0A610C0976E8D5A1@EX11.adf.bham.ac.uk>
References: <D7481F39.515BB%hdoran@air.org> <1749290.qfJmdIGWE2@ev8sa6>
 <A901AC7187F75B41BF677B0A610C0976E8D5A1@EX11.adf.bham.ac.uk>
Message-ID: <11328875.omvUFyD7TN@flyosfixe>

Dear Bernard,

> Thanks Pierre for the suggestion to use MCMCglmm. Very useful.

Glad this was helpful.

> 1) Can I ask why when taking the ratio of the variance components, the denominator is ICC = Vcomp / (sum(variance components of the model) + 1)? Why is the one added?

You can find an explanation for this in the Supplementary File on our article on quantitative genetics interpretation of GLMMs:
http://www.genetics.org/content/204/3/1281.supplemental

It is fairly technical. Trying to put it simply: there is an equivalence between a binomial/probit model and the threshold model. This is because a probit link is actually the CDF of a normal distribution (same goes for a logit and a logistic distribution): using a probit link and a binomial is equivalent to using a threshold model after adding a random noise normally distributed (this is Fig. S1 in our Suppl. File above). 

And the variance of this random noise is thus the variance of a standard normal distribution which is 1 (or the variance of a standard logistic distribution, which is (pi^2)/3, for a logit link).

Computing the ICC on the liability scale "as if" a threshold model was used thus only requires to add that extra-variance on the denominator.

> 2) I have tried mixed ordinal modelling using "ordinal" or MCMCglmm, and noticed the variance of the residuals of the model is not produced. I have also read that the residual is assumed to be as you mentioned (pi^2)/3. Is there a reason (maybe a not so technical one?)

It all depends what you call "residual". In MCMCglmm, there is for example a "residual" variance called "units" which value should be fixed to e.g. 1 when running families such as ordinal. This variance is required to be added in the denominator of the ICC. If you have only a random effect, you would have:
Vrand / (Vrand + Vunits + 1)

Note that there is also the "threshold" family in MCMCglmm, which is special in the sense that (to say it quickly) the "units" variance is the variance of the probit link and should be fixed to 1. In that case, you would have:
Vrand / (Vrand + Vunits)

Sometimes this "extra-variance" (1 or (pi^2)/3) is indeed called "residual variance". This is because, as per my explanation above, probit and logit links can be seen as "adding a random noise then taking a threshold", this random noise is sometimes seen as a "residual error" in the model.

I hope this will clarify things for you. I'm afraid it's difficult to explain clearly the whys without going too much into the technicality of the models.

Cheers,
Pierre.

> 
> Kind regards,
> Bernard
> 
> -----Original Message-----
> From: pierre.de.villemereuil at mailoo.org <pierre.de.villemereuil at mailoo.org> 
> Sent: Friday, June 15, 2018 4:05 PM
> To: r-sig-mixed-models at r-project.org
> Cc: Ben Bolker <bbolker at gmail.com>; Doran, Harold <HDoran at air.org>; Bernard Liew <B.Liew at bham.ac.uk>
> Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study
> 
> Hi,
> 
> > However, I'm not sure how one would go about computing an ICC from 
> > ordinal data
> 
> I've never used the package "ordinal", but if it's anything like the "ordinal" family of MCMCglmm, then computing an ICC on the liability scale would be fairly easy, as one would just proceed as always and simply add the so-called "link variance" corresponding to the chosen link function (1 for probit, (pi^2)/3 for logit). E.g. for a given variance component Vcomp and a probit link:
> ICC = Vcomp / (sum(variance components of the model) + 1)
> 
> However, computing an ICC on the data scale would be much more difficult as it is actually multivariate...
> 
> I think in the case when such scores were used, having the estimate on the liability scale make sense though, as the binning is more due to our inability of finely measuring this scale rather than an actual property of the system.
> 
> Cheers,
> Pierre.
> 
> Le vendredi 15 juin 2018, 03:27:54 CEST Ben Bolker a ?crit :
> > More generally, the best way to fit this kind of model is to use an
> > *ordinal* model, which assumes the responses are in increasing 
> > sequence but does not assume the distance between levels (e.g. 1 vs 2,
> > 2 vs 3 ...) is uniform.  However, I'm not sure how one would go about 
> > computing an ICC from ordinal data ... (the 'ordinal' package is the 
> > place to look for the model-fitting procedures). Googling it finds 
> > some stuff, but it seems that it doesn't necessarily apply to complex 
> > designs ...
> > 
> > https://stats.stackexchange.com/questions/3539/inter-rater-reliability
> > -for-ordinal-or-interval-data 
> > https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/
> > 
> > 
> > On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
> > > That?s a helpful clarification, Rolf. However, with gaussian normal 
> > > errors in the linear model, we can?t *really* assume they would 
> > > asymptote at 1 or 10. My suspicion is that these are likert-style 
> > > ordered counts of some form, although the OP should clarify. In 
> > > which case, the 1 or 10 are limits with censoring, as true values 
> > > for some measured trait could exist outside those boundaries (and I 
> > > suspect the model is forming predicted values outside of 1 or 10).
> > >
> > >
> > >
> > > On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
> > >
> > >>
> > >>On 15/06/18 05:35, Doran, Harold wrote:
> > >>
> > >>> Well no, you?re specification is not right because your variable 
> > >>> is not continuous as you note. Continuous means it is a real 
> > >>> number between -Inf/Inf and you have boundaries between 1 and 10. 
> > >>> So, you should not be using a linear model assuming the outcome is continuous.
> > >>
> > >>I think that the foregoing is a bit misleading.  For a variable to 
> > >>be continuous it is not necessary for it to have a range from 
> > >>-infinity to infinity.
> > >>
> > >>The OP says that dv  "is a continuous variable (scale 1-10)".  It is 
> > >>not clear to me what this means.  The "obvious"/usual meaning or 
> > >>interpretation would be that dv can take (only) the (positive 
> > >>integer) values 1, 2, ..., 10.  If this is so, then a continuous 
> > >>model is not appropriate.  (It should be noted however that people 
> > >>in the social sciences do this sort of thing --- i.e. treat discrete 
> > >>variables as continuous --- all the time.)
> > >>
> > >>It is *possible* that dv can take values in the real interval 
> > >>[1,10], in which case it *is* continuous, and a "continuous model" 
> > >>is indeed appropriate.
> > >>
> > >>The OP should clarify what the situation actually is.
> > >>
> > >>cheers,
> > >>
> > >>Rolf Turner
> > >>
> > >>--
> > >>Technical Editor ANZJS
> > >>Department of Statistics
> > >>University of Auckland
> > >>Phone: +64-9-373-7599 ext. 88276
> > >>
> > >>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
> > >>>
> > >>>> Dear Community,
> > >>>>
> > >>>>
> > >>>> I am doing a reliability study, using the methods of 
> > >>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question 
> > >>>> on the lmer formulation and the use of the variance components.
> > >>>>
> > >>>> Background: I have 20 subjects, 2 fixed raters, 2 testing 
> > >>>> sessions, and
> > >>>> 10 trials per sessions. my dependent variable is a continuous 
> > >>>> variable (scale 1-10). Sessions are nested within each 
> > >>>> subject-assessor combination. I desire a ICC (3) formulation of 
> > >>>> inter-rater and inter-session reliability from the variance components.
> > >>>>
> > >>>> My lmer model is:
> > >>>>
> > >>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
> > >>>>
> > >>>> Question:
> > >>>>
> > >>>>   1.  is the model formulation right? and is my interpretation of 
> > >>>>the  variance components for ICC below right?
> > >>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) 
> > >>>># I  read that the variation of raters will be lumped with the residual
> > >>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var 
> > >>>>(subj) +  var (subj:session) + var (residual))  some simulated 
> > >>>>data:
> > >>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = 
> > >>>>c(1:2), trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 
> > >>>>3, sd = 1.5)
> > >>>>
> > >>>> I appreciate the kind response.
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 


From B@Liew @ending from bh@m@@c@uk  Sat Jun 16 19:02:18 2018
From: B@Liew @ending from bh@m@@c@uk (Bernard Liew)
Date: Sat, 16 Jun 2018 17:02:18 +0000
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <1749290.qfJmdIGWE2@ev8sa6>
References: <D7481F39.515BB%hdoran@air.org> <D7486A52.515E4%hdoran@air.org>
 <CABghstT8zoYYmic0LusU7YK_h00tqAQpCcEBp4P6rt7hw+bCNQ@mail.gmail.com>
 <1749290.qfJmdIGWE2@ev8sa6>
Message-ID: <A901AC7187F75B41BF677B0A610C0976E8D5A1@EX11.adf.bham.ac.uk>

Thanks Pierre for the suggestion to use MCMCglmm. Very useful.

1) Can I ask why when taking the ratio of the variance components, the denominator is ICC = Vcomp / (sum(variance components of the model) + 1)? Why is the one added?

2) I have tried mixed ordinal modelling using "ordinal" or MCMCglmm, and noticed the variance of the residuals of the model is not produced. I have also read that the residual is assumed to be as you mentioned (pi^2)/3. Is there a reason (maybe a not so technical one?)

Kind regards,
Bernard

-----Original Message-----
From: pierre.de.villemereuil at mailoo.org <pierre.de.villemereuil at mailoo.org> 
Sent: Friday, June 15, 2018 4:05 PM
To: r-sig-mixed-models at r-project.org
Cc: Ben Bolker <bbolker at gmail.com>; Doran, Harold <HDoran at air.org>; Bernard Liew <B.Liew at bham.ac.uk>
Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study

Hi,

> However, I'm not sure how one would go about computing an ICC from 
> ordinal data

I've never used the package "ordinal", but if it's anything like the "ordinal" family of MCMCglmm, then computing an ICC on the liability scale would be fairly easy, as one would just proceed as always and simply add the so-called "link variance" corresponding to the chosen link function (1 for probit, (pi^2)/3 for logit). E.g. for a given variance component Vcomp and a probit link:
ICC = Vcomp / (sum(variance components of the model) + 1)

However, computing an ICC on the data scale would be much more difficult as it is actually multivariate...

I think in the case when such scores were used, having the estimate on the liability scale make sense though, as the binning is more due to our inability of finely measuring this scale rather than an actual property of the system.

Cheers,
Pierre.

Le vendredi 15 juin 2018, 03:27:54 CEST Ben Bolker a ?crit :
> More generally, the best way to fit this kind of model is to use an
> *ordinal* model, which assumes the responses are in increasing 
> sequence but does not assume the distance between levels (e.g. 1 vs 2,
> 2 vs 3 ...) is uniform.  However, I'm not sure how one would go about 
> computing an ICC from ordinal data ... (the 'ordinal' package is the 
> place to look for the model-fitting procedures). Googling it finds 
> some stuff, but it seems that it doesn't necessarily apply to complex 
> designs ...
> 
> https://stats.stackexchange.com/questions/3539/inter-rater-reliability
> -for-ordinal-or-interval-data 
> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/
> 
> 
> On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
> > That?s a helpful clarification, Rolf. However, with gaussian normal 
> > errors in the linear model, we can?t *really* assume they would 
> > asymptote at 1 or 10. My suspicion is that these are likert-style 
> > ordered counts of some form, although the OP should clarify. In 
> > which case, the 1 or 10 are limits with censoring, as true values 
> > for some measured trait could exist outside those boundaries (and I 
> > suspect the model is forming predicted values outside of 1 or 10).
> >
> >
> >
> > On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
> >
> >>
> >>On 15/06/18 05:35, Doran, Harold wrote:
> >>
> >>> Well no, you?re specification is not right because your variable 
> >>> is not continuous as you note. Continuous means it is a real 
> >>> number between -Inf/Inf and you have boundaries between 1 and 10. 
> >>> So, you should not be using a linear model assuming the outcome is continuous.
> >>
> >>I think that the foregoing is a bit misleading.  For a variable to 
> >>be continuous it is not necessary for it to have a range from 
> >>-infinity to infinity.
> >>
> >>The OP says that dv  "is a continuous variable (scale 1-10)".  It is 
> >>not clear to me what this means.  The "obvious"/usual meaning or 
> >>interpretation would be that dv can take (only) the (positive 
> >>integer) values 1, 2, ..., 10.  If this is so, then a continuous 
> >>model is not appropriate.  (It should be noted however that people 
> >>in the social sciences do this sort of thing --- i.e. treat discrete 
> >>variables as continuous --- all the time.)
> >>
> >>It is *possible* that dv can take values in the real interval 
> >>[1,10], in which case it *is* continuous, and a "continuous model" 
> >>is indeed appropriate.
> >>
> >>The OP should clarify what the situation actually is.
> >>
> >>cheers,
> >>
> >>Rolf Turner
> >>
> >>--
> >>Technical Editor ANZJS
> >>Department of Statistics
> >>University of Auckland
> >>Phone: +64-9-373-7599 ext. 88276
> >>
> >>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
> >>>
> >>>> Dear Community,
> >>>>
> >>>>
> >>>> I am doing a reliability study, using the methods of 
> >>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question 
> >>>> on the lmer formulation and the use of the variance components.
> >>>>
> >>>> Background: I have 20 subjects, 2 fixed raters, 2 testing 
> >>>> sessions, and
> >>>> 10 trials per sessions. my dependent variable is a continuous 
> >>>> variable (scale 1-10). Sessions are nested within each 
> >>>> subject-assessor combination. I desire a ICC (3) formulation of 
> >>>> inter-rater and inter-session reliability from the variance components.
> >>>>
> >>>> My lmer model is:
> >>>>
> >>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
> >>>>
> >>>> Question:
> >>>>
> >>>>   1.  is the model formulation right? and is my interpretation of 
> >>>>the  variance components for ICC below right?
> >>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var (residual)) 
> >>>># I  read that the variation of raters will be lumped with the residual
> >>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var 
> >>>>(subj) +  var (subj:session) + var (residual))  some simulated 
> >>>>data:
> >>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = 
> >>>>c(1:2), trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 
> >>>>3, sd = 1.5)
> >>>>
> >>>> I appreciate the kind response.
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From pierre@de@villemereuil @ending from m@iloo@org  Mon Jun 18 09:45:57 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Mon, 18 Jun 2018 09:45:57 +0200
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <A901AC7187F75B41BF677B0A610C0976E8D608@EX11.adf.bham.ac.uk>
References: <D7481F39.515BB%hdoran@air.org> <11328875.omvUFyD7TN@flyosfixe>
 <A901AC7187F75B41BF677B0A610C0976E8D608@EX11.adf.bham.ac.uk>
Message-ID: <2780159.yGQmEfl06x@ev8sa6>

Hi,

> When I refer to residuals, as I understand from lmer modelling, it is the level 1 variance. Back to my design, I have many subjects, two fixed raters, sessions nested within a subject, and trials nested within sessions. Hence, level 1 variance would typically reflect inter-trial variance.

Thing is: there is nothing like this for GLMMs. The lowest level of "residual variance" is basically the distribution variance.

You could think there would be such a thing with a threshold model, but it turns out that the total variance of the liability scale is non identifiable, so nothing there either.

> If I were to use lmer modelling, I do not have to specify the level 1 random effects (i.e. ~1| SUBJ:SESSION:TRIAL), as it is in the residuals. 

Indeed.

> However, using mcmcglmm, there appears to be an even lower level of random effects which is fixed (as you mentioned). So my question is, should I specify also the level 1 random effects?

No, you shouldn't. There is already the "residual" variance in MCMCglmm (the R part of the variance) which should account for that, but that you need to fix to 1 (because of the non identifiability issue I'm mentioning above). If you had such kind of random effects, it means you re-model such a non identifiable variance.

> Sample formula using your suggestion of probit (I just like to know if the priors and model are appropriate):
> mcglmm_mod = MCMCglmm(vas ~ RATER, 
>                       random =  ~ SUBJ +
>                         SUBJ:SESSION +
>                         SUBJ:SESSION:TRIAL,
>                       data = as.data.frame (df %>% filter (SIDE == "R")),
>                       family = "ordinal",
>                       prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0),
>                                                             G2=list(V=1, nu=0),
>                                                             G3=list(V=1, nu=0))))
> Many thanks again for your (and everyone's) help thus far.

As I'm saying above, I suggest you remove the SUBJ:SESSION:TRIAL effect, if it corresponds, as you state to a "level-1 variance". 

Another thing is that I don't think it is wise to use nu = 0 for such a model prior. I'd recommend using the parameter expansion of MCMCglmm's prior and especially a chi-square like prior that has been shown to perform quite well for such models:
G1 = list(V = 1, nu = 1000, alpha.mu = 0, alpha.V = 1)

And a last thing is that the "threshold" family is supposed to have better mixing and be faster than the "ordinal" family according to Jarrod Hadfield. You might want to give it a try (and beware that the + 1 should be removed from the ICC denominator when using "threshold", as per my previous email).

Best,
Pierre.

> 
> Kind regards,
> Bernard
> -----Original Message-----
> From: pierre.de.villemereuil at mailoo.org <pierre.de.villemereuil at mailoo.org> 
> Sent: Saturday, June 16, 2018 7:28 PM
> To: Bernard Liew <B.Liew at bham.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study
> 
> Dear Bernard,
> 
> > Thanks Pierre for the suggestion to use MCMCglmm. Very useful.
> 
> Glad this was helpful.
> 
> > 1) Can I ask why when taking the ratio of the variance components, the denominator is ICC = Vcomp / (sum(variance components of the model) + 1)? Why is the one added?
> 
> You can find an explanation for this in the Supplementary File on our article on quantitative genetics interpretation of GLMMs:
> http://www.genetics.org/content/204/3/1281.supplemental
> 
> It is fairly technical. Trying to put it simply: there is an equivalence between a binomial/probit model and the threshold model. This is because a probit link is actually the CDF of a normal distribution (same goes for a logit and a logistic distribution): using a probit link and a binomial is equivalent to using a threshold model after adding a random noise normally distributed (this is Fig. S1 in our Suppl. File above). 
> 
> And the variance of this random noise is thus the variance of a standard normal distribution which is 1 (or the variance of a standard logistic distribution, which is (pi^2)/3, for a logit link).
> 
> Computing the ICC on the liability scale "as if" a threshold model was used thus only requires to add that extra-variance on the denominator.
> 
> > 2) I have tried mixed ordinal modelling using "ordinal" or MCMCglmm, 
> > and noticed the variance of the residuals of the model is not 
> > produced. I have also read that the residual is assumed to be as you 
> > mentioned (pi^2)/3. Is there a reason (maybe a not so technical one?)
> 
> It all depends what you call "residual". In MCMCglmm, there is for example a "residual" variance called "units" which value should be fixed to e.g. 1 when running families such as ordinal. This variance is required to be added in the denominator of the ICC. If you have only a random effect, you would have:
> Vrand / (Vrand + Vunits + 1)
> 
> Note that there is also the "threshold" family in MCMCglmm, which is special in the sense that (to say it quickly) the "units" variance is the variance of the probit link and should be fixed to 1. In that case, you would have:
> Vrand / (Vrand + Vunits)
> 
> Sometimes this "extra-variance" (1 or (pi^2)/3) is indeed called "residual variance". This is because, as per my explanation above, probit and logit links can be seen as "adding a random noise then taking a threshold", this random noise is sometimes seen as a "residual error" in the model.
> 
> I hope this will clarify things for you. I'm afraid it's difficult to explain clearly the whys without going too much into the technicality of the models.
> 
> Cheers,
> Pierre.
> 
> > 
> > Kind regards,
> > Bernard
> > 
> > -----Original Message-----
> > From: pierre.de.villemereuil at mailoo.org 
> > <pierre.de.villemereuil at mailoo.org>
> > Sent: Friday, June 15, 2018 4:05 PM
> > To: r-sig-mixed-models at r-project.org
> > Cc: Ben Bolker <bbolker at gmail.com>; Doran, Harold <HDoran at air.org>; 
> > Bernard Liew <B.Liew at bham.ac.uk>
> > Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer 
> > for ICC computation in reliability study
> > 
> > Hi,
> > 
> > > However, I'm not sure how one would go about computing an ICC from 
> > > ordinal data
> > 
> > I've never used the package "ordinal", but if it's anything like the "ordinal" family of MCMCglmm, then computing an ICC on the liability scale would be fairly easy, as one would just proceed as always and simply add the so-called "link variance" corresponding to the chosen link function (1 for probit, (pi^2)/3 for logit). E.g. for a given variance component Vcomp and a probit link:
> > ICC = Vcomp / (sum(variance components of the model) + 1)
> > 
> > However, computing an ICC on the data scale would be much more difficult as it is actually multivariate...
> > 
> > I think in the case when such scores were used, having the estimate on the liability scale make sense though, as the binning is more due to our inability of finely measuring this scale rather than an actual property of the system.
> > 
> > Cheers,
> > Pierre.
> > 
> > Le vendredi 15 juin 2018, 03:27:54 CEST Ben Bolker a ?crit :
> > > More generally, the best way to fit this kind of model is to use an
> > > *ordinal* model, which assumes the responses are in increasing 
> > > sequence but does not assume the distance between levels (e.g. 1 vs 
> > > 2,
> > > 2 vs 3 ...) is uniform.  However, I'm not sure how one would go 
> > > about computing an ICC from ordinal data ... (the 'ordinal' package 
> > > is the place to look for the model-fitting procedures). Googling it 
> > > finds some stuff, but it seems that it doesn't necessarily apply to 
> > > complex designs ...
> > > 
> > > https://stats.stackexchange.com/questions/3539/inter-rater-reliabili
> > > ty
> > > -for-ordinal-or-interval-data
> > > https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/
> > > 
> > > 
> > > On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
> > > > That?s a helpful clarification, Rolf. However, with gaussian 
> > > > normal errors in the linear model, we can?t *really* assume they 
> > > > would asymptote at 1 or 10. My suspicion is that these are 
> > > > likert-style ordered counts of some form, although the OP should 
> > > > clarify. In which case, the 1 or 10 are limits with censoring, as 
> > > > true values for some measured trait could exist outside those 
> > > > boundaries (and I suspect the model is forming predicted values outside of 1 or 10).
> > > >
> > > >
> > > >
> > > > On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
> > > >
> > > >>
> > > >>On 15/06/18 05:35, Doran, Harold wrote:
> > > >>
> > > >>> Well no, you?re specification is not right because your variable 
> > > >>> is not continuous as you note. Continuous means it is a real 
> > > >>> number between -Inf/Inf and you have boundaries between 1 and 10.
> > > >>> So, you should not be using a linear model assuming the outcome is continuous.
> > > >>
> > > >>I think that the foregoing is a bit misleading.  For a variable to 
> > > >>be continuous it is not necessary for it to have a range from 
> > > >>-infinity to infinity.
> > > >>
> > > >>The OP says that dv  "is a continuous variable (scale 1-10)".  It 
> > > >>is not clear to me what this means.  The "obvious"/usual meaning 
> > > >>or interpretation would be that dv can take (only) the (positive
> > > >>integer) values 1, 2, ..., 10.  If this is so, then a continuous 
> > > >>model is not appropriate.  (It should be noted however that people 
> > > >>in the social sciences do this sort of thing --- i.e. treat 
> > > >>discrete variables as continuous --- all the time.)
> > > >>
> > > >>It is *possible* that dv can take values in the real interval 
> > > >>[1,10], in which case it *is* continuous, and a "continuous model"
> > > >>is indeed appropriate.
> > > >>
> > > >>The OP should clarify what the situation actually is.
> > > >>
> > > >>cheers,
> > > >>
> > > >>Rolf Turner
> > > >>
> > > >>--
> > > >>Technical Editor ANZJS
> > > >>Department of Statistics
> > > >>University of Auckland
> > > >>Phone: +64-9-373-7599 ext. 88276
> > > >>
> > > >>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
> > > >>>
> > > >>>> Dear Community,
> > > >>>>
> > > >>>>
> > > >>>> I am doing a reliability study, using the methods of 
> > > >>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question 
> > > >>>> on the lmer formulation and the use of the variance components.
> > > >>>>
> > > >>>> Background: I have 20 subjects, 2 fixed raters, 2 testing 
> > > >>>> sessions, and
> > > >>>> 10 trials per sessions. my dependent variable is a continuous 
> > > >>>> variable (scale 1-10). Sessions are nested within each 
> > > >>>> subject-assessor combination. I desire a ICC (3) formulation of 
> > > >>>> inter-rater and inter-session reliability from the variance components.
> > > >>>>
> > > >>>> My lmer model is:
> > > >>>>
> > > >>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
> > > >>>>
> > > >>>> Question:
> > > >>>>
> > > >>>>   1.  is the model formulation right? and is my interpretation 
> > > >>>>of the  variance components for ICC below right?
> > > >>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var 
> > > >>>>(residual)) # I  read that the variation of raters will be lumped with the residual
> > > >>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var
> > > >>>>(subj) +  var (subj:session) + var (residual))  some simulated
> > > >>>>data:
> > > >>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = 
> > > >>>>c(1:2), trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 
> > > >>>>3, sd = 1.5)
> > > >>>>
> > > >>>> I appreciate the kind response.
> > > >>
> > > >>
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list 
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > 
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > 
> > 
> 
> 
> 
> 


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Mon Jun 18 10:09:42 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Mon, 18 Jun 2018 10:09:42 +0200
Subject: [R-sig-ME] Best practice for co/variance component testing in LMM
Message-ID: <CAHr4DyeVNOA=sx9=LnH3Dbq2r1-_ib1CFdKjjtOoSKe9L3M=-Q@mail.gmail.com>

What is the best way to test if multiple co/variance components in a
linear mixed model improve the model fit?
When testing the null hypothesis that variance components are zero the
alternative hypothesis is one-sided, the sampling distribution of the
anova()-LR-statistic is not welI approximated by a chi-square
distribution and the LRT is conservative in this "boundary case". I
know there is RLRsim but I couldn't figure out how to test for
multiple variance components with exactRLRT/exactLRT. Besides that
RLRsim cannot be used to test the null hypothesis that a covariance is
equal to zero.
I came up with the idea to use LRT based on chi-bar-square
distributions, which have known weights following a binomial
distribution [1], for testing the (uncorrelated) variance components.
When testing the covariance the parameter value in the null hypothesis
is no longer on the edge of the parameter space and I think the LRT
via anova() should be, at least asymptotically, correct.
Are there better ways and/or other R packages for this purpose,
especially for merMod objects?

Cheers,
Maarten

[1] http://www.jstor.org/stable/27643833


From D@vid@Duffy @ending from qimrberghofer@edu@@u  Mon Jun 18 11:36:21 2018
From: D@vid@Duffy @ending from qimrberghofer@edu@@u (David Duffy)
Date: Mon, 18 Jun 2018 09:36:21 +0000
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>

> Thing is: there is nothing like this for GLMMs. The lowest level of "residual variance" is basically the 
> distribution variance.
> You could think there would be such a thing with a threshold model, but it turns out that the total variance of 
> the liability scale is non identifiable, so nothing there either.

There is some information when there are multiple thresholds.

From pierre@de@villemereuil @ending from m@iloo@org  Mon Jun 18 12:11:06 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Mon, 18 Jun 2018 12:11:06 +0200
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>
References: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>
Message-ID: <2566315.fojsGdY2Yc@ev8sa6>

Hi David,

> > Thing is: there is nothing like this for GLMMs. The lowest level of "residual variance" is basically the 
> > distribution variance.
> > You could think there would be such a thing with a threshold model, but it turns out that the total variance of 
> > the liability scale is non identifiable, so nothing there either.
> 
> There is some information when there are multiple thresholds.

You mean information to measure e.g. additive over-dispersion? 

I agree but wouldn't you need quite a lot of thresholds (categories) for this to be measurable and not poses numerical issues? I have no practical experience in trying to account for that, so I'm curious if you have any experience in this.

Best,
Pierre.


From j@h@dfield @ending from ed@@c@uk  Mon Jun 18 12:22:38 2018
From: j@h@dfield @ending from ed@@c@uk (Jarrod Hadfield)
Date: Mon, 18 Jun 2018 11:22:38 +0100
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
In-Reply-To: <2566315.fojsGdY2Yc@ev8sa6>
References: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>
 <2566315.fojsGdY2Yc@ev8sa6>
Message-ID: <ed7356e3-9646-47b8-5e4e-975a8d87b959@ed.ac.uk>

Hi,

I think the residual variance is still non-identifiable with multiple 
thresholds. In fact,? this paper:

https://gsejournal.biomedcentral.com/track/pdf/10.1186/1297-9686-27-3-229

uses the non-identifiability in a 3 category problem to fix the 
thresholds but estimate the residual variance because this is the same 
as fixing the residual variance and estimating the free threshold.

Cheers,

Jarrod




On 18/06/2018 11:11, Pierre de Villemereuil wrote:
> Hi David,
>
>>> Thing is: there is nothing like this for GLMMs. The lowest level of "residual variance" is basically the
>>> distribution variance.
>>> You could think there would be such a thing with a threshold model, but it turns out that the total variance of
>>> the liability scale is non identifiable, so nothing there either.
>> There is some information when there are multiple thresholds.
> You mean information to measure e.g. additive over-dispersion?
>
> I agree but wouldn't you need quite a lot of thresholds (categories) for this to be measurable and not poses numerical issues? I have no practical experience in trying to account for that, so I'm curious if you have any experience in this.
>
> Best,
> Pierre.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From B@Liew @ending from bh@m@@c@uk  Sun Jun 17 17:42:19 2018
From: B@Liew @ending from bh@m@@c@uk (Bernard Liew)
Date: Sun, 17 Jun 2018 15:42:19 +0000
Subject: [R-sig-ME] 
 [FORGED] Re: Using variance components of lmer for ICC
 computation in reliability study
In-Reply-To: <11328875.omvUFyD7TN@flyosfixe>
References: <D7481F39.515BB%hdoran@air.org> <1749290.qfJmdIGWE2@ev8sa6>
 <A901AC7187F75B41BF677B0A610C0976E8D5A1@EX11.adf.bham.ac.uk>
 <11328875.omvUFyD7TN@flyosfixe>
Message-ID: <A901AC7187F75B41BF677B0A610C0976E8D608@EX11.adf.bham.ac.uk>

Dear Pierre,

Again, thanks for referring me to the paper (and thanks to Ben for the review article). It's becoming clearer now.

When I refer to residuals, as I understand from lmer modelling, it is the level 1 variance. Back to my design, I have many subjects, two fixed raters, sessions nested within a subject, and trials nested within sessions. Hence, level 1 variance would typically reflect inter-trial variance.

If I were to use lmer modelling, I do not have to specify the level 1 random effects (i.e. ~1| SUBJ:SESSION:TRIAL), as it is in the residuals. 

However, using mcmcglmm, there appears to be an even lower level of random effects which is fixed (as you mentioned). So my question is, should I specify also the level 1 random effects?

Sample formula using your suggestion of probit (I just like to know if the priors and model are appropriate):
mcglmm_mod = MCMCglmm(vas ~ RATER, 
                      random =  ~ SUBJ +
                        SUBJ:SESSION +
                        SUBJ:SESSION:TRIAL,
                      data = as.data.frame (df %>% filter (SIDE == "R")),
                      family = "ordinal",
                      prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0),
                                                            G2=list(V=1, nu=0),
                                                            G3=list(V=1, nu=0))))
Many thanks again for your (and everyone's) help thus far.

Kind regards,
Bernard
-----Original Message-----
From: pierre.de.villemereuil at mailoo.org <pierre.de.villemereuil at mailoo.org> 
Sent: Saturday, June 16, 2018 7:28 PM
To: Bernard Liew <B.Liew at bham.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer for ICC computation in reliability study

Dear Bernard,

> Thanks Pierre for the suggestion to use MCMCglmm. Very useful.

Glad this was helpful.

> 1) Can I ask why when taking the ratio of the variance components, the denominator is ICC = Vcomp / (sum(variance components of the model) + 1)? Why is the one added?

You can find an explanation for this in the Supplementary File on our article on quantitative genetics interpretation of GLMMs:
http://www.genetics.org/content/204/3/1281.supplemental

It is fairly technical. Trying to put it simply: there is an equivalence between a binomial/probit model and the threshold model. This is because a probit link is actually the CDF of a normal distribution (same goes for a logit and a logistic distribution): using a probit link and a binomial is equivalent to using a threshold model after adding a random noise normally distributed (this is Fig. S1 in our Suppl. File above). 

And the variance of this random noise is thus the variance of a standard normal distribution which is 1 (or the variance of a standard logistic distribution, which is (pi^2)/3, for a logit link).

Computing the ICC on the liability scale "as if" a threshold model was used thus only requires to add that extra-variance on the denominator.

> 2) I have tried mixed ordinal modelling using "ordinal" or MCMCglmm, 
> and noticed the variance of the residuals of the model is not 
> produced. I have also read that the residual is assumed to be as you 
> mentioned (pi^2)/3. Is there a reason (maybe a not so technical one?)

It all depends what you call "residual". In MCMCglmm, there is for example a "residual" variance called "units" which value should be fixed to e.g. 1 when running families such as ordinal. This variance is required to be added in the denominator of the ICC. If you have only a random effect, you would have:
Vrand / (Vrand + Vunits + 1)

Note that there is also the "threshold" family in MCMCglmm, which is special in the sense that (to say it quickly) the "units" variance is the variance of the probit link and should be fixed to 1. In that case, you would have:
Vrand / (Vrand + Vunits)

Sometimes this "extra-variance" (1 or (pi^2)/3) is indeed called "residual variance". This is because, as per my explanation above, probit and logit links can be seen as "adding a random noise then taking a threshold", this random noise is sometimes seen as a "residual error" in the model.

I hope this will clarify things for you. I'm afraid it's difficult to explain clearly the whys without going too much into the technicality of the models.

Cheers,
Pierre.

> 
> Kind regards,
> Bernard
> 
> -----Original Message-----
> From: pierre.de.villemereuil at mailoo.org 
> <pierre.de.villemereuil at mailoo.org>
> Sent: Friday, June 15, 2018 4:05 PM
> To: r-sig-mixed-models at r-project.org
> Cc: Ben Bolker <bbolker at gmail.com>; Doran, Harold <HDoran at air.org>; 
> Bernard Liew <B.Liew at bham.ac.uk>
> Subject: Re: [R-sig-ME] [FORGED] Re: Using variance components of lmer 
> for ICC computation in reliability study
> 
> Hi,
> 
> > However, I'm not sure how one would go about computing an ICC from 
> > ordinal data
> 
> I've never used the package "ordinal", but if it's anything like the "ordinal" family of MCMCglmm, then computing an ICC on the liability scale would be fairly easy, as one would just proceed as always and simply add the so-called "link variance" corresponding to the chosen link function (1 for probit, (pi^2)/3 for logit). E.g. for a given variance component Vcomp and a probit link:
> ICC = Vcomp / (sum(variance components of the model) + 1)
> 
> However, computing an ICC on the data scale would be much more difficult as it is actually multivariate...
> 
> I think in the case when such scores were used, having the estimate on the liability scale make sense though, as the binning is more due to our inability of finely measuring this scale rather than an actual property of the system.
> 
> Cheers,
> Pierre.
> 
> Le vendredi 15 juin 2018, 03:27:54 CEST Ben Bolker a ?crit :
> > More generally, the best way to fit this kind of model is to use an
> > *ordinal* model, which assumes the responses are in increasing 
> > sequence but does not assume the distance between levels (e.g. 1 vs 
> > 2,
> > 2 vs 3 ...) is uniform.  However, I'm not sure how one would go 
> > about computing an ICC from ordinal data ... (the 'ordinal' package 
> > is the place to look for the model-fitting procedures). Googling it 
> > finds some stuff, but it seems that it doesn't necessarily apply to 
> > complex designs ...
> > 
> > https://stats.stackexchange.com/questions/3539/inter-rater-reliabili
> > ty
> > -for-ordinal-or-interval-data
> > https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3402032/
> > 
> > 
> > On Thu, Jun 14, 2018 at 6:58 PM, Doran, Harold <HDoran at air.org> wrote:
> > > That?s a helpful clarification, Rolf. However, with gaussian 
> > > normal errors in the linear model, we can?t *really* assume they 
> > > would asymptote at 1 or 10. My suspicion is that these are 
> > > likert-style ordered counts of some form, although the OP should 
> > > clarify. In which case, the 1 or 10 are limits with censoring, as 
> > > true values for some measured trait could exist outside those 
> > > boundaries (and I suspect the model is forming predicted values outside of 1 or 10).
> > >
> > >
> > >
> > > On 6/14/18, 6:33 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
> > >
> > >>
> > >>On 15/06/18 05:35, Doran, Harold wrote:
> > >>
> > >>> Well no, you?re specification is not right because your variable 
> > >>> is not continuous as you note. Continuous means it is a real 
> > >>> number between -Inf/Inf and you have boundaries between 1 and 10.
> > >>> So, you should not be using a linear model assuming the outcome is continuous.
> > >>
> > >>I think that the foregoing is a bit misleading.  For a variable to 
> > >>be continuous it is not necessary for it to have a range from 
> > >>-infinity to infinity.
> > >>
> > >>The OP says that dv  "is a continuous variable (scale 1-10)".  It 
> > >>is not clear to me what this means.  The "obvious"/usual meaning 
> > >>or interpretation would be that dv can take (only) the (positive
> > >>integer) values 1, 2, ..., 10.  If this is so, then a continuous 
> > >>model is not appropriate.  (It should be noted however that people 
> > >>in the social sciences do this sort of thing --- i.e. treat 
> > >>discrete variables as continuous --- all the time.)
> > >>
> > >>It is *possible* that dv can take values in the real interval 
> > >>[1,10], in which case it *is* continuous, and a "continuous model"
> > >>is indeed appropriate.
> > >>
> > >>The OP should clarify what the situation actually is.
> > >>
> > >>cheers,
> > >>
> > >>Rolf Turner
> > >>
> > >>--
> > >>Technical Editor ANZJS
> > >>Department of Statistics
> > >>University of Auckland
> > >>Phone: +64-9-373-7599 ext. 88276
> > >>
> > >>> On 6/14/18, 11:16 AM, "Bernard Liew" <B.Liew at bham.ac.uk> wrote:
> > >>>
> > >>>> Dear Community,
> > >>>>
> > >>>>
> > >>>> I am doing a reliability study, using the methods of 
> > >>>> https://www.ncbi.nlm.nih.gov/pubmed/28505546. I have a question 
> > >>>> on the lmer formulation and the use of the variance components.
> > >>>>
> > >>>> Background: I have 20 subjects, 2 fixed raters, 2 testing 
> > >>>> sessions, and
> > >>>> 10 trials per sessions. my dependent variable is a continuous 
> > >>>> variable (scale 1-10). Sessions are nested within each 
> > >>>> subject-assessor combination. I desire a ICC (3) formulation of 
> > >>>> inter-rater and inter-session reliability from the variance components.
> > >>>>
> > >>>> My lmer model is:
> > >>>>
> > >>>> lmer (dv ~ rater + (1|subj) + (1|subj:session), data = df)
> > >>>>
> > >>>> Question:
> > >>>>
> > >>>>   1.  is the model formulation right? and is my interpretation 
> > >>>>of the  variance components for ICC below right?
> > >>>>   2.  inter-rater ICC = var (subj) / (var(subj) + var 
> > >>>>(residual)) # I  read that the variation of raters will be lumped with the residual
> > >>>>   3.  inter-session ICC =( var (subj) + var (residual)) /( var
> > >>>>(subj) +  var (subj:session) + var (residual))  some simulated
> > >>>>data:
> > >>>> df = expand.grid(subj = c(1:20), rater = c(1:2), session = 
> > >>>>c(1:2), trial  = c(1:10))  df$vas = rnorm (nrow (df_sim), mean = 
> > >>>>3, sd = 1.5)
> > >>>>
> > >>>> I appreciate the kind response.
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 




From b@pelzer @ending from m@w@ru@nl  Mon Jun 18 19:54:28 2018
From: b@pelzer @ending from m@w@ru@nl (Ben Pelzer)
Date: Mon, 18 Jun 2018 19:54:28 +0200
Subject: [R-sig-ME] 
 Best practice for co/variance component testing in LMM
In-Reply-To: <CAHr4DyeVNOA=sx9=LnH3Dbq2r1-_ib1CFdKjjtOoSKe9L3M=-Q@mail.gmail.com>
References: <CAHr4DyeVNOA=sx9=LnH3Dbq2r1-_ib1CFdKjjtOoSKe9L3M=-Q@mail.gmail.com>
Message-ID: <3c129775-4748-9498-60fb-ad5df067ce00@maw.ru.nl>

Hi Maarten,

It sounds as if paragraph 6.2.1 in Snijders & Bosker 2nd edition of 
"Multilevel Analysis" gives an answer to your question. Regards,

Ben.

On 18-6-2018 10:09, Maarten Jung wrote:
> What is the best way to test if multiple co/variance components in a
> linear mixed model improve the model fit?
> When testing the null hypothesis that variance components are zero the
> alternative hypothesis is one-sided, the sampling distribution of the
> anova()-LR-statistic is not welI approximated by a chi-square
> distribution and the LRT is conservative in this "boundary case". I
> know there is RLRsim but I couldn't figure out how to test for
> multiple variance components with exactRLRT/exactLRT. Besides that
> RLRsim cannot be used to test the null hypothesis that a covariance is
> equal to zero.
> I came up with the idea to use LRT based on chi-bar-square
> distributions, which have known weights following a binomial
> distribution [1], for testing the (uncorrelated) variance components.
> When testing the covariance the parameter value in the null hypothesis
> is no longer on the edge of the parameter space and I think the LRT
> via anova() should be, at least asymptotically, correct.
> Are there better ways and/or other R packages for this purpose,
> especially for merMod objects?
>
> Cheers,
> Maarten
>
> [1] http://www.jstor.org/stable/27643833
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Mon Jun 18 20:44:47 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Mon, 18 Jun 2018 20:44:47 +0200
Subject: [R-sig-ME] 
 Best practice for co/variance component testing in LMM
In-Reply-To: <3c129775-4748-9498-60fb-ad5df067ce00@maw.ru.nl>
References: <CAHr4DyeVNOA=sx9=LnH3Dbq2r1-_ib1CFdKjjtOoSKe9L3M=-Q@mail.gmail.com>
 <3c129775-4748-9498-60fb-ad5df067ce00@maw.ru.nl>
Message-ID: <CAHr4Dye=a50peS_9H2nHn-2yRBycSv0sE5MMeP-ay1oZHFOKOQ@mail.gmail.com>

Hi Ben,

unfortunately it doesn't.
S & B only describe (1) the appropriate chi-bar-square distribution
for the test of a single variance component and (2) the appropriate
chi-bar-square distributions for testing a single random slope which
(in their approach) includes testing if the corresponding covariances
are zero. This seems to me as if their tests for (2) build on the idea
that the covariance paramters are not on the boundary but the
variances component of interest (the one of the random slope) is?

However, they do not describe how one should test if multiple
uncorrelated variance components are equal to zero and the LRT they
describe are only asymptotically correct.

It may well be that there are better options/ "exact" tests (similar
to RLRsim) for testing if multiple co/variance components improve the
model fit and that's what I'm looking for.

Cheers,
Maarten

On Mon, Jun 18, 2018 at 7:54 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> Hi Maarten,
>
> It sounds as if paragraph 6.2.1 in Snijders & Bosker 2nd edition of
> "Multilevel Analysis" gives an answer to your question. Regards,
>
> Ben.
>
> On 18-6-2018 10:09, Maarten Jung wrote:
>>
>> What is the best way to test if multiple co/variance components in a
>> linear mixed model improve the model fit?
>> When testing the null hypothesis that variance components are zero the
>> alternative hypothesis is one-sided, the sampling distribution of the
>> anova()-LR-statistic is not welI approximated by a chi-square
>> distribution and the LRT is conservative in this "boundary case". I
>> know there is RLRsim but I couldn't figure out how to test for
>> multiple variance components with exactRLRT/exactLRT. Besides that
>> RLRsim cannot be used to test the null hypothesis that a covariance is
>> equal to zero.
>> I came up with the idea to use LRT based on chi-bar-square
>> distributions, which have known weights following a binomial
>> distribution [1], for testing the (uncorrelated) variance components.
>> When testing the covariance the parameter value in the null hypothesis
>> is no longer on the edge of the parameter space and I think the LRT
>> via anova() should be, at least asymptotically, correct.
>> Are there better ways and/or other R packages for this purpose,
>> especially for merMod objects?
>>
>> Cheers,
>> Maarten
>>
>> [1] http://www.jstor.org/stable/27643833
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From D@vid@Duffy @ending from qimrberghofer@edu@@u  Tue Jun 19 01:15:36 2018
From: D@vid@Duffy @ending from qimrberghofer@edu@@u (David Duffy)
Date: Mon, 18 Jun 2018 23:15:36 +0000
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
In-Reply-To: <ed7356e3-9646-47b8-5e4e-975a8d87b959@ed.ac.uk>
References: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>
 <2566315.fojsGdY2Yc@ev8sa6>,<ed7356e3-9646-47b8-5e4e-975a8d87b959@ed.ac.uk>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B50EF@EXCH06S.adqimr.ad.lan>

The situations I have most experience with is where there are fixed effects/multiple groups and the thresholds vary across groups -  eg  "spreading" of the thresholds in one group compared to the others may be interpretable as variance difference etc. In multidimensional setups, one tests the goodness of fit of the single threshold model by
fitting one-factor models to triads of variables at a time eg

Muthen B, Hofacker C (1988): Testing the assumptions underlying tetrachoric correlations. Psychometrika 53:563-578.

Maybe there is information about the residual variances in the 2-threshold model in such a setup?

Cheers, David.
________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jarrod Hadfield [j.hadfield at ed.ac.uk]
Sent: Monday, 18 June 2018 8:22 PM
To: Pierre de Villemereuil; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME]  Using variance components of lmer for ICC computation in reliability study

Hi,

I think the residual variance is still non-identifiable with multiple
thresholds. In fact,  this paper:

https://gsejournal.biomedcentral.com/track/pdf/10.1186/1297-9686-27-3-229

uses the non-identifiability in a 3 category problem to fix the
thresholds but estimate the residual variance because this is the same
as fixing the residual variance and estimating the free threshold.

Cheers,

Jarrod




On 18/06/2018 11:11, Pierre de Villemereuil wrote:
> Hi David,
>
>>> Thing is: there is nothing like this for GLMMs. The lowest level of "residual variance" is basically the
>>> distribution variance.
>>> You could think there would be such a thing with a threshold model, but it turns out that the total variance of
>>> the liability scale is non identifiable, so nothing there either.
>> There is some information when there are multiple thresholds.
> You mean information to measure e.g. additive over-dispersion?
>
> I agree but wouldn't you need quite a lot of thresholds (categories) for this to be measurable and not poses numerical issues? I have no practical experience in trying to account for that, so I'm curious if you have any experience in this.
>
> Best,
> Pierre.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierre@de@villemereuil @ending from m@iloo@org  Tue Jun 19 09:38:04 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Tue, 19 Jun 2018 09:38:04 +0200
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B50EF@EXCH06S.adqimr.ad.lan>
References: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>
 <ed7356e3-9646-47b8-5e4e-975a8d87b959@ed.ac.uk>
 <4737E17E7C8C3C4A8B5C1CE5346371D4A84B50EF@EXCH06S.adqimr.ad.lan>
Message-ID: <6774750.Z77ZOZtpCQ@ev8sa6>

Hi,

> Maybe there is information about the residual variances in the 2-threshold model in such a setup?

Maybe, but it would be quite hard (if possible at all) to distinguish from changes in the mean, wouldn't it? Unless the changes in the "spreading" are quite dramatic and located in the extreme categories with a strong "depletion" from the central one. 

It's interesting to think about it though.

Cheers,
Pierre.


From j@h@dfield @ending from ed@@c@uk  Tue Jun 19 10:04:22 2018
From: j@h@dfield @ending from ed@@c@uk (Jarrod Hadfield)
Date: Tue, 19 Jun 2018 09:04:22 +0100
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
In-Reply-To: <6774750.Z77ZOZtpCQ@ev8sa6>
References: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>
 <ed7356e3-9646-47b8-5e4e-975a8d87b959@ed.ac.uk>
 <4737E17E7C8C3C4A8B5C1CE5346371D4A84B50EF@EXCH06S.adqimr.ad.lan>
 <6774750.Z77ZOZtpCQ@ev8sa6>
Message-ID: <3a433f9c-14e9-31e3-abea-36077616d368@ed.ac.uk>

Hi,

No - the residual variance is non-identifiable in a threshold model 
irrespective of the number of thresholds unless the thresholds are 
constrained in some way (e.g. fully constrained as in the paper I 
previously referenced). Strong depletion from the central category would 
simply mean the two thresholds are close together.

Cheers,

Jarrod


On 19/06/2018 08:38, Pierre de Villemereuil wrote:
> Hi,
>
>> Maybe there is information about the residual variances in the 2-threshold model in such a setup?
> Maybe, but it would be quite hard (if possible at all) to distinguish from changes in the mean, wouldn't it? Unless the changes in the "spreading" are quite dramatic and located in the extreme categories with a strong "depletion" from the central one.
>
> It's interesting to think about it though.
>
> Cheers,
> Pierre.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From pierre@de@villemereuil @ending from m@iloo@org  Tue Jun 19 10:11:02 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Tue, 19 Jun 2018 10:11:02 +0200
Subject: [R-sig-ME] 
 Using variance components of lmer for ICC computation in
 reliability study
In-Reply-To: <3a433f9c-14e9-31e3-abea-36077616d368@ed.ac.uk>
References: <4737E17E7C8C3C4A8B5C1CE5346371D4A84B5063@EXCH06S.adqimr.ad.lan>
 <6774750.Z77ZOZtpCQ@ev8sa6> <3a433f9c-14e9-31e3-abea-36077616d368@ed.ac.uk>
Message-ID: <4340087.AsHfISvNLB@ev8sa6>

Yes, but would an assumptions that thresholds are conserved between the groups you compare reasonable (depends on the "groups" of course)? In that case (with "fixed" thresholds assumptions), you might be able to start talking about the variance, no?

Of course, it's still non identifiable, in the sense that you need to assume fixed thresholds to talk about this. I figured it was the assumption David was making.

Cheers,
Pierre.

Le mardi 19 juin 2018, 10:04:22 CEST Jarrod Hadfield a ?crit :
> Hi,
> 
> No - the residual variance is non-identifiable in a threshold model 
> irrespective of the number of thresholds unless the thresholds are 
> constrained in some way (e.g. fully constrained as in the paper I 
> previously referenced). Strong depletion from the central category would 
> simply mean the two thresholds are close together.
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 19/06/2018 08:38, Pierre de Villemereuil wrote:
> > Hi,
> >
> >> Maybe there is information about the residual variances in the 2-threshold model in such a setup?
> > Maybe, but it would be quite hard (if possible at all) to distinguish from changes in the mean, wouldn't it? Unless the changes in the "spreading" are quite dramatic and located in the extreme categories with a strong "depletion" from the central one.
> >
> > It's interesting to think about it though.
> >
> > Cheers,
> > Pierre.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


From mr@luced@n @ending from hotm@il@it  Wed Jun 20 22:51:53 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Wed, 20 Jun 2018 20:51:53 +0000
Subject: [R-sig-ME] Plot a result without a main effect
Message-ID: <DB3PR0402MB38513FDC0C54A3031D513915F6770@DB3PR0402MB3851.eurprd04.prod.outlook.com>

Hello everybody.

In an experiment I have 8 tests that are run consecutively. Each of these tests has a different intercept due to the stimulus used, and not related to the object of my study. How can I remove these intercepts? Meaning: in R I am using lmer(), and I provide these intercepts as a fixed effect. Now I would like to plot the scores taking that fixed-effect out of my plot to have a better view of the behaviour of the scores without this effect.

Is that possible? How can I do that?

Best
Luca

	[[alternative HTML version deleted]]


From julleey@w @ending from y@hoo@c@  Fri Jun 22 02:12:55 2018
From: julleey@w @ending from y@hoo@c@ (Julie Lee-Yaw)
Date: Fri, 22 Jun 2018 00:12:55 +0000 (UTC)
Subject: [R-sig-ME] Using corSpher to correct for spatial autocorrelation
References: <1326727721.756117.1529626375583.ref@mail.yahoo.com>
Message-ID: <1326727721.756117.1529626375583@mail.yahoo.com>

Hi?
I want to use the the correlation setting with corSpher in nlme to account for potential spatial autocorrelation in my data. My data include observations from across the globe with locations in latitude and longitude (decimal degrees). From the R help for corSpher, the example syntax would be something like:
fm1Wheat2 <- gls(yield ~ variety - 1, corr =corSpher(c(28, 0.2), form = ~ latitude + longitude, nugget = TRUE))

My question is whether the latitude and longitude provided should be projected into a spatial projection that preserves distances or areas or whether providing decimal degrees is appropriate?
Many thanks!


	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Fri Jun 22 09:12:14 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Fri, 22 Jun 2018 09:12:14 +0200
Subject: [R-sig-ME] 
 Using corSpher to correct for spatial autocorrelation
In-Reply-To: <1326727721.756117.1529626375583@mail.yahoo.com>
References: <1326727721.756117.1529626375583.ref@mail.yahoo.com>
 <1326727721.756117.1529626375583@mail.yahoo.com>
Message-ID: <CAJuCY5xZ5ECiJP_PxRpMECFgNw7KUaz8X9z60eD=y6Wzwn7uxg@mail.gmail.com>

Dear Julie,

corSpher() is a spherical variogram / correlogram model. It defines a
specific shape of the variogram, not the kind of data. All variogram
models in nlme assume Euclidean distances, so you will need projected
data. But that opens another can of worm when your data spans a
considerable part of the globe.

This paper might be relevant for you:
https://www.math.ntnu.no/inla/r-inla.org/papers/jss/lindgren.pdf

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-22 2:12 GMT+02:00 Julie Lee-Yaw via R-sig-mixed-models
<r-sig-mixed-models at r-project.org>:
> Hi
> I want to use the the correlation setting with corSpher in nlme to account for potential spatial autocorrelation in my data. My data include observations from across the globe with locations in latitude and longitude (decimal degrees). From the R help for corSpher, the example syntax would be something like:
> fm1Wheat2 <- gls(yield ~ variety - 1, corr =corSpher(c(28, 0.2), form = ~ latitude + longitude, nugget = TRUE))
>
> My question is whether the latitude and longitude provided should be projected into a spatial projection that preserves distances or areas or whether providing decimal degrees is appropriate?
> Many thanks!
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @hm@dr215 m@ili@g off tpg@com@@u  Sat Jun 23 15:04:44 2018
From: @hm@dr215 m@ili@g off tpg@com@@u (@hm@dr215 m@ili@g off tpg@com@@u)
Date: Sat, 23 Jun 2018 23:04:44 +1000
Subject: [R-sig-ME] mixed-effects ordinal logistic regression model
Message-ID: <002501d40af2$c282c360$47884a20$@tpg.com.au>

Hi list

 

I have a dataset with n=60 animals with two groups (30/group; control and
treatment) on 3 different research sites. Animals are monitored on days 0,
14 and 28 (repeated measures), and lesions are scored from 1-4.

 

I want to use a mixed-effects ordinal logistic regression model and consider
animals and research sites as random-effects in the model.

I haven't done ordinal logistic regression before, and I would like to use
this data and learn how to do the analysis and also interpret the outputs. I
appreciate any help on;

 

1- A book, paper or link on ordinal logistic regression (easy to read and
understand for an average reader) 

2- What is the preferred package in R to analyse such data? I noticed some
have used "Ordinal" package.

3- Is it appropriate to use farm (n=3) as a random-effects in the model? I
assume 3 is small to be considered as a random-effects in the model, your
thoughts? 

4- Because observations are repeated on 3 occasions (repeated measures), I
intend to use animals as a random-effects. 

5- If I use both research sites and animals as random-effects, I assume it
would be a nested random-effects model?

6- I appreciate if someone can help with some R codes on ordinal logistic
regression 

 

Your help is greatly appreciated!

 

Ahmad

 

 

 

 


	[[alternative HTML version deleted]]


From p@ul@buerkner @ending from gm@il@com  Sat Jun 23 15:30:41 2018
From: p@ul@buerkner @ending from gm@il@com (Paul Buerkner)
Date: Sat, 23 Jun 2018 15:30:41 +0200
Subject: [R-sig-ME] mixed-effects ordinal logistic regression model
In-Reply-To: <002501d40af2$c282c360$47884a20$@tpg.com.au>
References: <002501d40af2$c282c360$47884a20$@tpg.com.au>
Message-ID: <CAGoSky___sd0xhDeEakt+J0SORs2gUnO_0v_qK_OQY8y-tg=Pw@mail.gmail.com>

Hi Ahmad,

if you want to fit this model in a frequentist framework, I recommend the
"ordinal" package. If you rather want to use a Bayesian framework, I
recommend "brms". For a tutorial paper about ordinal models also containing
R code for brms, see https://psyarxiv.com/x8swp/

Paul

2018-06-23 15:04 GMT+02:00 <ahmadr215 at tpg.com.au>:

> Hi list
>
>
>
> I have a dataset with n=60 animals with two groups (30/group; control and
> treatment) on 3 different research sites. Animals are monitored on days 0,
> 14 and 28 (repeated measures), and lesions are scored from 1-4.
>
>
>
> I want to use a mixed-effects ordinal logistic regression model and
> consider
> animals and research sites as random-effects in the model.
>
> I haven't done ordinal logistic regression before, and I would like to use
> this data and learn how to do the analysis and also interpret the outputs.
> I
> appreciate any help on;
>
>
>
> 1- A book, paper or link on ordinal logistic regression (easy to read and
> understand for an average reader)
>
> 2- What is the preferred package in R to analyse such data? I noticed some
> have used "Ordinal" package.
>
> 3- Is it appropriate to use farm (n=3) as a random-effects in the model? I
> assume 3 is small to be considered as a random-effects in the model, your
> thoughts?
>
> 4- Because observations are repeated on 3 occasions (repeated measures), I
> intend to use animals as a random-effects.
>
> 5- If I use both research sites and animals as random-effects, I assume it
> would be a nested random-effects model?
>
> 6- I appreciate if someone can help with some R codes on ordinal logistic
> regression
>
>
>
> Your help is greatly appreciated!
>
>
>
> Ahmad
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From michiel@kiggen @ending from gm@il@com  Sun Jun 24 23:41:58 2018
From: michiel@kiggen @ending from gm@il@com (Michiel Kiggen)
Date: Sun, 24 Jun 2018 23:41:58 +0200
Subject: [R-sig-ME] Errors in GLMER
Message-ID: <CADqHjY-dzKe+T6TdUDgNVOLkc35XbLPDBrPDOs0DHkF9c8HnOA@mail.gmail.com>

Dear Reader,

I'm trying to run a GLMER model for the following data:
*2x scaled continous predictor* (sum score of 2 questionairres)
*1x predictor being 10 trials* on a ultimatum game of which each trial is 1
out of 10 possible options. (offer of a split of $20: e.g. you 1 and 19
me). Inserted this a non ordered factor (10-levels) with sum-to-zero coding
(contrast.sum).
*1x dependent binary variable *being the response to the 10 trials valued
at accepted (1) or reject (2). Entered as a factor.

After the following model without correlations terms (I ran this model
after failing to converge on a model without optimizers and the all_fit of
that) I get the following errors:

glmer(AoR ~ Trials * (sPredictor1*sPredictor2) + (1 | ID )+  (0 + Trials
|ID),family = binomial, data = data, control = glmerControl(optCtrl =
list(maxfun = 1e+9, optimizer = "bobyqa")))


*fixed-effect model matrix is rank deficient so dropping 10 columns /
coefficients*
*Warning messages:*
*1: In (function (npt = min(n + 2L, 2L * n), rhobeg = NA, rhoend = NA,  :*
*  unused control arguments ignored*
*2: In (function (iprint = 0L, maxfun = 10000L, FtolAbs = 0.00001, FtolRel
= 1e-15,  :*
*  unused control arguments ignored*
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  unable to evaluate scaled gradient
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 11 negative eigenvalues

I'm afraid I might be doing something wrong in handeling the DV or
10-factor level IV, which in turn, is causing the 3 errors in bold. Does
anyone have suggestions. Or can some one tell me what the source of these
errors are?

Much obliged in advance,

Kindest regards,

Michiel Kiggen

	[[alternative HTML version deleted]]


From trevord@vi@w@lker @ending from gm@il@com  Mon Jun 25 03:53:12 2018
From: trevord@vi@w@lker @ending from gm@il@com (Trevor Walker)
Date: Sun, 24 Jun 2018 21:53:12 -0400
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 138, Issue 34
Message-ID: <CAMDVrE1NcTmnZPFnpspc2N1ZfYCA=QiSr4TYPrRfYG=YaxOPTg@mail.gmail.com>

 Try googling "Cumulative link mixed model".

I have had success with the clm and clmm functions in the ordinal package.

-Trevor

On Sun, Jun 24, 2018 at 6:00 AM, <r-sig-mixed-models-request at r-project.org>
wrote:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. mixed-effects ordinal logistic regression model
>       (ahmadr215 at tpg.com.au)
>    2. Re: mixed-effects ordinal logistic regression model
>       (Paul Buerkner)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 23 Jun 2018 23:04:44 +1000
> From: <ahmadr215 at tpg.com.au>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] mixed-effects ordinal logistic regression model
> Message-ID: <002501d40af2$c282c360$47884a20$@tpg.com.au>
> Content-Type: text/plain; charset="utf-8"
>
> Hi list
>
>
>
> I have a dataset with n=60 animals with two groups (30/group; control and
> treatment) on 3 different research sites. Animals are monitored on days 0,
> 14 and 28 (repeated measures), and lesions are scored from 1-4.
>
>
>
> I want to use a mixed-effects ordinal logistic regression model and
> consider
> animals and research sites as random-effects in the model.
>
> I haven't done ordinal logistic regression before, and I would like to use
> this data and learn how to do the analysis and also interpret the outputs.
> I
> appreciate any help on;
>
>
>
> 1- A book, paper or link on ordinal logistic regression (easy to read and
> understand for an average reader)
>
> 2- What is the preferred package in R to analyse such data? I noticed some
> have used "Ordinal" package.
>
> 3- Is it appropriate to use farm (n=3) as a random-effects in the model? I
> assume 3 is small to be considered as a random-effects in the model, your
> thoughts?
>
> 4- Because observations are repeated on 3 occasions (repeated measures), I
> intend to use animals as a random-effects.
>
> 5- If I use both research sites and animals as random-effects, I assume it
> would be a nested random-effects model?
>
> 6- I appreciate if someone can help with some R codes on ordinal logistic
> regression
>
>
>
> Your help is greatly appreciated!
>
>
>
> Ahmad
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 23 Jun 2018 15:30:41 +0200
> From: Paul Buerkner <paul.buerkner at gmail.com>
> To: ahmadr215 at tpg.com.au
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] mixed-effects ordinal logistic regression
>         model
> Message-ID:
>         <CAGoSky___sd0xhDeEakt+J0SORs2gUnO_0v_qK_OQY8y-tg=Pw@
> mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi Ahmad,
>
> if you want to fit this model in a frequentist framework, I recommend the
> "ordinal" package. If you rather want to use a Bayesian framework, I
> recommend "brms". For a tutorial paper about ordinal models also containing
> R code for brms, see https://psyarxiv.com/x8swp/
>
> Paul
>
> 2018-06-23 15:04 GMT+02:00 <ahmadr215 at tpg.com.au>:
>
> > Hi list
> >
> >
> >
> > I have a dataset with n=60 animals with two groups (30/group; control and
> > treatment) on 3 different research sites. Animals are monitored on days
> 0,
> > 14 and 28 (repeated measures), and lesions are scored from 1-4.
> >
> >
> >
> > I want to use a mixed-effects ordinal logistic regression model and
> > consider
> > animals and research sites as random-effects in the model.
> >
> > I haven't done ordinal logistic regression before, and I would like to
> use
> > this data and learn how to do the analysis and also interpret the
> outputs.
> > I
> > appreciate any help on;
> >
> >
> >
> > 1- A book, paper or link on ordinal logistic regression (easy to read and
> > understand for an average reader)
> >
> > 2- What is the preferred package in R to analyse such data? I noticed
> some
> > have used "Ordinal" package.
> >
> > 3- Is it appropriate to use farm (n=3) as a random-effects in the model?
> I
> > assume 3 is small to be considered as a random-effects in the model, your
> > thoughts?
> >
> > 4- Because observations are repeated on 3 occasions (repeated measures),
> I
> > intend to use animals as a random-effects.
> >
> > 5- If I use both research sites and animals as random-effects, I assume
> it
> > would be a nested random-effects model?
> >
> > 6- I appreciate if someone can help with some R codes on ordinal logistic
> > regression
> >
> >
> >
> > Your help is greatly appreciated!
> >
> >
> >
> > Ahmad
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 138, Issue 34
> ***************************************************
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Mon Jun 25 09:08:52 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 25 Jun 2018 09:08:52 +0200
Subject: [R-sig-ME] Errors in GLMER
In-Reply-To: <CADqHjY-dzKe+T6TdUDgNVOLkc35XbLPDBrPDOs0DHkF9c8HnOA@mail.gmail.com>
References: <CADqHjY-dzKe+T6TdUDgNVOLkc35XbLPDBrPDOs0DHkF9c8HnOA@mail.gmail.com>
Message-ID: <CAJuCY5ybFhzAB5s80=rfSNwEyEJ15rTEu6Kqf917MAbyufBnZw@mail.gmail.com>

Dear Michiel,

Does it run with the random slope for trial. If I understand the
design correctly, you have only one observation per trial and per ID.
In that case a random slope for trial as an (ordered) factor won't
work.

Consider using trial as a continuous variable and use some polynomials
to model it.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-24 23:41 GMT+02:00 Michiel Kiggen <michiel.kiggen at gmail.com>:
> Dear Reader,
>
> I'm trying to run a GLMER model for the following data:
> *2x scaled continous predictor* (sum score of 2 questionairres)
> *1x predictor being 10 trials* on a ultimatum game of which each trial is 1
> out of 10 possible options. (offer of a split of $20: e.g. you 1 and 19
> me). Inserted this a non ordered factor (10-levels) with sum-to-zero coding
> (contrast.sum).
> *1x dependent binary variable *being the response to the 10 trials valued
> at accepted (1) or reject (2). Entered as a factor.
>
> After the following model without correlations terms (I ran this model
> after failing to converge on a model without optimizers and the all_fit of
> that) I get the following errors:
>
> glmer(AoR ~ Trials * (sPredictor1*sPredictor2) + (1 | ID )+  (0 + Trials
> |ID),family = binomial, data = data, control = glmerControl(optCtrl =
> list(maxfun = 1e+9, optimizer = "bobyqa")))
>
>
> *fixed-effect model matrix is rank deficient so dropping 10 columns /
> coefficients*
> *Warning messages:*
> *1: In (function (npt = min(n + 2L, 2L * n), rhobeg = NA, rhoend = NA,  :*
> *  unused control arguments ignored*
> *2: In (function (iprint = 0L, maxfun = 10000L, FtolAbs = 0.00001, FtolRel
> = 1e-15,  :*
> *  unused control arguments ignored*
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   unable to evaluate scaled gradient
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 11 negative eigenvalues
>
> I'm afraid I might be doing something wrong in handeling the DV or
> 10-factor level IV, which in turn, is causing the 3 errors in bold. Does
> anyone have suggestions. Or can some one tell me what the source of these
> errors are?
>
> Much obliged in advance,
>
> Kindest regards,
>
> Michiel Kiggen
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @hm@dr215 m@ili@g off tpg@com@@u  Mon Jun 25 11:11:03 2018
From: @hm@dr215 m@ili@g off tpg@com@@u (@hm@dr215 m@ili@g off tpg@com@@u)
Date: Mon, 25 Jun 2018 19:11:03 +1000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 138, Issue 34
In-Reply-To: <CAMDVrE1NcTmnZPFnpspc2N1ZfYCA=QiSr4TYPrRfYG=YaxOPTg@mail.gmail.com>
References: <CAMDVrE1NcTmnZPFnpspc2N1ZfYCA=QiSr4TYPrRfYG=YaxOPTg@mail.gmail.com>
Message-ID: <007601d40c64$73711240$5a5336c0$@tpg.com.au>

Hi Paul/Trever

Thanks for these, much appreciated!
I will try these to see which one works, and how the outputs can be
interpreted. 


Ahmad



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
Behalf Of Trevor Walker
Sent: Monday, 25 June 2018 11:53 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 138, Issue 34

 Try googling "Cumulative link mixed model".

I have had success with the clm and clmm functions in the ordinal package.

-Trevor

On Sun, Jun 24, 2018 at 6:00 AM, <r-sig-mixed-models-request at r-project.org>
wrote:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific 
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. mixed-effects ordinal logistic regression model
>       (ahmadr215 at tpg.com.au)
>    2. Re: mixed-effects ordinal logistic regression model
>       (Paul Buerkner)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 23 Jun 2018 23:04:44 +1000
> From: <ahmadr215 at tpg.com.au>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] mixed-effects ordinal logistic regression model
> Message-ID: <002501d40af2$c282c360$47884a20$@tpg.com.au>
> Content-Type: text/plain; charset="utf-8"
>
> Hi list
>
>
>
> I have a dataset with n=60 animals with two groups (30/group; control 
> and
> treatment) on 3 different research sites. Animals are monitored on 
> days 0,
> 14 and 28 (repeated measures), and lesions are scored from 1-4.
>
>
>
> I want to use a mixed-effects ordinal logistic regression model and 
> consider animals and research sites as random-effects in the model.
>
> I haven't done ordinal logistic regression before, and I would like to 
> use this data and learn how to do the analysis and also interpret the
outputs.
> I
> appreciate any help on;
>
>
>
> 1- A book, paper or link on ordinal logistic regression (easy to read 
> and understand for an average reader)
>
> 2- What is the preferred package in R to analyse such data? I noticed 
> some have used "Ordinal" package.
>
> 3- Is it appropriate to use farm (n=3) as a random-effects in the 
> model? I assume 3 is small to be considered as a random-effects in the 
> model, your thoughts?
>
> 4- Because observations are repeated on 3 occasions (repeated 
> measures), I intend to use animals as a random-effects.
>
> 5- If I use both research sites and animals as random-effects, I 
> assume it would be a nested random-effects model?
>
> 6- I appreciate if someone can help with some R codes on ordinal 
> logistic regression
>
>
>
> Your help is greatly appreciated!
>
>
>
> Ahmad
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 23 Jun 2018 15:30:41 +0200
> From: Paul Buerkner <paul.buerkner at gmail.com>
> To: ahmadr215 at tpg.com.au
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] mixed-effects ordinal logistic regression
>         model
> Message-ID:
>         <CAGoSky___sd0xhDeEakt+J0SORs2gUnO_0v_qK_OQY8y-tg=Pw@
> mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi Ahmad,
>
> if you want to fit this model in a frequentist framework, I recommend 
> the "ordinal" package. If you rather want to use a Bayesian framework, 
> I recommend "brms". For a tutorial paper about ordinal models also 
> containing R code for brms, see https://psyarxiv.com/x8swp/
>
> Paul
>
> 2018-06-23 15:04 GMT+02:00 <ahmadr215 at tpg.com.au>:
>
> > Hi list
> >
> >
> >
> > I have a dataset with n=60 animals with two groups (30/group; 
> > control and
> > treatment) on 3 different research sites. Animals are monitored on 
> > days
> 0,
> > 14 and 28 (repeated measures), and lesions are scored from 1-4.
> >
> >
> >
> > I want to use a mixed-effects ordinal logistic regression model and 
> > consider animals and research sites as random-effects in the model.
> >
> > I haven't done ordinal logistic regression before, and I would like 
> > to
> use
> > this data and learn how to do the analysis and also interpret the
> outputs.
> > I
> > appreciate any help on;
> >
> >
> >
> > 1- A book, paper or link on ordinal logistic regression (easy to 
> > read and understand for an average reader)
> >
> > 2- What is the preferred package in R to analyse such data? I 
> > noticed
> some
> > have used "Ordinal" package.
> >
> > 3- Is it appropriate to use farm (n=3) as a random-effects in the model?
> I
> > assume 3 is small to be considered as a random-effects in the model, 
> > your thoughts?
> >
> > 4- Because observations are repeated on 3 occasions (repeated 
> > measures),
> I
> > intend to use animals as a random-effects.
> >
> > 5- If I use both research sites and animals as random-effects, I 
> > assume
> it
> > would be a nested random-effects model?
> >
> > 6- I appreciate if someone can help with some R codes on ordinal 
> > logistic regression
> >
> >
> >
> > Your help is greatly appreciated!
> >
> >
> >
> > Ahmad
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 138, Issue 34
> ***************************************************
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m@lcolm@f@irbrother @ending from umu@@e  Mon Jun 25 12:39:03 2018
From: m@lcolm@f@irbrother @ending from umu@@e (Malcolm Fairbrother)
Date: Mon, 25 Jun 2018 10:39:03 +0000
Subject: [R-sig-ME] mixed-effects ordinal logistic regression model
In-Reply-To: <007d01d40c6b$438487e0$ca8d97a0$@tpg.com.au>
References: <mailman.16647.369.1529917878.37760.r-sig-mixed-models@r-project.org>
 <9019FB96-22ED-49E7-A26D-361A692CFDA9@umu.se>
 <007d01d40c6b$438487e0$ca8d97a0$@tpg.com.au>
Message-ID: <88B88973-6899-4114-BB1D-3642803BA1C2@umu.se>

Hi Ahmad,
Well I assume you?ll want random intercepts for animal, which is the "random = ~animal? part of the code.
In either a Bayesian or frequentist framework, I don?t think you should try to estimate a variance for a random classification with only three unique values. This sort of question comes up frequently on this list, and pretty much everybody agrees that you need an N of about 10 at the very least, and probably more in most situations. If you search the list archives, you?ll find a variety of discussions about this issue.
Best wishes,
Malcolm



On 25 Jun 2018, at 11:59, ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au> wrote:

Hi Malcom

Thanks for this,
So, if I use the Bayesian method- I don?t need to be concerned about the random-effects.
What about in a frequentist framework, do you believe site (n=3) should be included as a random-effects?

Ahmad


From: Malcolm Fairbrother <malcolm.fairbrother at umu.se<mailto:malcolm.fairbrother at umu.se>>
Sent: Monday, 25 June 2018 7:41 PM
To: ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] mixed-effects ordinal logistic regression model

Hi Ahmad,

If you're willing to work in a Bayesian framework, and use a probit rather than logit model, you may have some luck with something like:

library(MCMCglmm)

prior1 <- list(R=list(V=1, fix=1), G = list(G1 = list(V=1, nu=0.02)))

mod <- MCMCglmm(lesions ~ treatment + site + day, random = ~animal, data=yourdata, family="threshold", prior=prior1)

summary(mod)

The package course notes may help:
https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf

To me, it would make sense to make site and day (like treatment) categorical variables. So you treat site as a fixed effect.

Hope that helps,
Malcolm


Date: Mon, 25 Jun 2018 19:11:03 +1000
From: <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>
To: "'Trevor Walker'" <trevordaviswalker at gmail.com<mailto:trevordaviswalker at gmail.com>>,
<r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 138, Issue 34

Hi Paul/Trever

Thanks for these, much appreciated!
I will try these to see which one works, and how the outputs can be
interpreted.


Ahmad



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On
Behalf Of Trevor Walker
Sent: Monday, 25 June 2018 11:53 AM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 138, Issue 34

Try googling "Cumulative link mixed model".

I have had success with the clm and clmm functions in the ordinal package.

-Trevor

On Sun, Jun 24, 2018 at 6:00 AM, <r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org>>
wrote:


Send R-sig-mixed-models mailing list submissions to
       r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
       https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
       r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org>

You can reach the person managing the list at
       r-sig-mixed-models-owner at r-project.org<mailto:r-sig-mixed-models-owner at r-project.org>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. mixed-effects ordinal logistic regression model
     (ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>)
  2. Re: mixed-effects ordinal logistic regression model
     (Paul Buerkner)

----------------------------------------------------------------------

Message: 1
Date: Sat, 23 Jun 2018 23:04:44 +1000
From: <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>
To: <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] mixed-effects ordinal logistic regression model
Message-ID: <002501d40af2$c282c360$47884a20$@tpg.com.au<mailto:002501d40af2$c282c360$47884a20$@tpg.com.au>>
Content-Type: text/plain; charset="utf-8"

Hi list



I have a dataset with n=60 animals with two groups (30/group; control
and
treatment) on 3 different research sites. Animals are monitored on
days 0,
14 and 28 (repeated measures), and lesions are scored from 1-4.



I want to use a mixed-effects ordinal logistic regression model and
consider animals and research sites as random-effects in the model.

I haven't done ordinal logistic regression before, and I would like to
use this data and learn how to do the analysis and also interpret the
outputs.

I
appreciate any help on;



1- A book, paper or link on ordinal logistic regression (easy to read
and understand for an average reader)

2- What is the preferred package in R to analyse such data? I noticed
some have used "Ordinal" package.

3- Is it appropriate to use farm (n=3) as a random-effects in the
model? I assume 3 is small to be considered as a random-effects in the
model, your thoughts?

4- Because observations are repeated on 3 occasions (repeated
measures), I intend to use animals as a random-effects.

5- If I use both research sites and animals as random-effects, I
assume it would be a nested random-effects model?

6- I appreciate if someone can help with some R codes on ordinal
logistic regression



Your help is greatly appreciated!



Ahmad










       [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Sat, 23 Jun 2018 15:30:41 +0200
From: Paul Buerkner <paul.buerkner at gmail.com<mailto:paul.buerkner at gmail.com>>
To: ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] mixed-effects ordinal logistic regression
       model
Message-ID:
       <CAGoSky___sd0xhDeEakt+J0SORs2gUnO_0v_qK_OQY8y-tg=Pw@
mail.gmail.com<http://mail.gmail.com/>>
Content-Type: text/plain; charset="utf-8"

Hi Ahmad,

if you want to fit this model in a frequentist framework, I recommend
the "ordinal" package. If you rather want to use a Bayesian framework,
I recommend "brms". For a tutorial paper about ordinal models also
containing R code for brms, see https://psyarxiv.com/x8swp/

Paul

2018-06-23 15:04 GMT+02:00 <ahmadr215 at tpg.com.au<mailto:ahmadr215 at tpg.com.au>>:


Hi list



I have a dataset with n=60 animals with two groups (30/group;
control and
treatment) on 3 different research sites. Animals are monitored on
days
0,

14 and 28 (repeated measures), and lesions are scored from 1-4.



I want to use a mixed-effects ordinal logistic regression model and
consider animals and research sites as random-effects in the model.

I haven't done ordinal logistic regression before, and I would like
to
use

this data and learn how to do the analysis and also interpret the
outputs.

I
appreciate any help on;



1- A book, paper or link on ordinal logistic regression (easy to
read and understand for an average reader)

2- What is the preferred package in R to analyse such data? I
noticed
some

have used "Ordinal" package.

3- Is it appropriate to use farm (n=3) as a random-effects in the model?
I

assume 3 is small to be considered as a random-effects in the model,
your thoughts?

4- Because observations are repeated on 3 occasions (repeated
measures),
I

intend to use animals as a random-effects.

5- If I use both research sites and animals as random-effects, I
assume
it

would be a nested random-effects model?

6- I appreciate if someone can help with some R codes on ordinal
logistic regression



Your help is greatly appreciated!



Ahmad


	[[alternative HTML version deleted]]


From michiel@kiggen @ending from gm@il@com  Mon Jun 25 18:33:02 2018
From: michiel@kiggen @ending from gm@il@com (Michiel Kiggen)
Date: Mon, 25 Jun 2018 18:33:02 +0200
Subject: [R-sig-ME] Errors in GLMER
In-Reply-To: <CAJuCY5ybFhzAB5s80=rfSNwEyEJ15rTEu6Kqf917MAbyufBnZw@mail.gmail.com>
References: <CADqHjY-dzKe+T6TdUDgNVOLkc35XbLPDBrPDOs0DHkF9c8HnOA@mail.gmail.com>
 <CAJuCY5ybFhzAB5s80=rfSNwEyEJ15rTEu6Kqf917MAbyufBnZw@mail.gmail.com>
Message-ID: <CADqHjY_UXv32KcAqs1Obihp_WDtyPzmF2-eShK119hXueb--wA@mail.gmail.com>

Dear Thierry

Thanks so much for comments, I really appreciate it.

Based on your feedback, I'm running the following model now:

model_poly_nc <- glmer(AoR ~ Offers_lin*(sFW*sMF)+ Offers_quad *(sFW*sMF) +
(1 |ID)+ (0 + Offers_lin| ID)+(0 + Offers_quad| ID),family = binomial, data
= data, control = glmerControl(optCtrl = list(maxfun = 1e+9)))

*Offers_lin* & *Offers_quad* are the trial variables (polynomials for
linear and quadratic patterns). Both of them are centered. Metric is from 1
till 10. (1 being trial in which people get lowest offer and 10 being the
highest offer in an ultimatum game)
*sFW* & *sMF *are the continous questionairre sumscores, standardized &
centered.
*DV* (2 level factor accept or reject)
*n = 103*

I ran the model with covariance terms for the random effects. It didn't
converge, neither with optimizers bobyqa & Nelder_Mead.
However, the function *allFit,* strangely returned *[OK] for bobyqa,
Nelder_Mead, nloptwrap.NLOPT_LN_NELDERMEAD & nloptwrap.NLOPT_LN_BOBYQA*.
The model above is without covariance terms for the random effects. After
running this I get the same convergence issue and the same output on
allFit:  [OK] for bobyqa, Nelder_Mead, nloptwrap.NLOPT_LN_NELDERMEAD
& nloptwrap.NLOPT_LN_BOBYQA.

Using the *getME *function to look at the different *Fixed Effects*
generated by *allFit* (no covariance term model, as described above), it
reveals that the numbers are similar for bobyqa,  loptwrap.NLOPT_LN_NELDERMEAD
& nloptwrap.NLOPT_LN_BOBYQA. While for the Nelder_mead numbers are just
slightly different. Like a 0.02 difference.

For the seperate Models with optimizers Bobyqa & Nelder_Mead (both with
convergence issues), the fixed effects were exactly the same.

I'm not sure how to interpret these allFit function results. For what
patterns should I look incase I want to conclude these warnings are
false-positives?
Else, what options do I have? I've already stripped the model of it random
covariances (Removing the random slope will make the purpose of using Mixed
Models dispensable).

My apologies if I'm asking any obvious questions. First time i'm running
this kind of analysis.

Any help is much appreciated!

Kind regards,

Michiel





Op ma 25 jun. 2018 om 09:08 schreef Thierry Onkelinx <
thierry.onkelinx at inbo.be>:

> Dear Michiel,
>
> Does it run with the random slope for trial. If I understand the
> design correctly, you have only one observation per trial and per ID.
> In that case a random slope for trial as an (ordered) factor won't
> work.
>
> Consider using trial as a continuous variable and use some polynomials
> to model it.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-06-24 23:41 GMT+02:00 Michiel Kiggen <michiel.kiggen at gmail.com>:
> > Dear Reader,
> >
> > I'm trying to run a GLMER model for the following data:
> > *2x scaled continous predictor* (sum score of 2 questionairres)
> > *1x predictor being 10 trials* on a ultimatum game of which each trial
> is 1
> > out of 10 possible options. (offer of a split of $20: e.g. you 1 and 19
> > me). Inserted this a non ordered factor (10-levels) with sum-to-zero
> coding
> > (contrast.sum).
> > *1x dependent binary variable *being the response to the 10 trials valued
> > at accepted (1) or reject (2). Entered as a factor.
> >
> > After the following model without correlations terms (I ran this model
> > after failing to converge on a model without optimizers and the all_fit
> of
> > that) I get the following errors:
> >
> > glmer(AoR ~ Trials * (sPredictor1*sPredictor2) + (1 | ID )+  (0 + Trials
> > |ID),family = binomial, data = data, control = glmerControl(optCtrl =
> > list(maxfun = 1e+9, optimizer = "bobyqa")))
> >
> >
> > *fixed-effect model matrix is rank deficient so dropping 10 columns /
> > coefficients*
> > *Warning messages:*
> > *1: In (function (npt = min(n + 2L, 2L * n), rhobeg = NA, rhoend = NA,
> :*
> > *  unused control arguments ignored*
> > *2: In (function (iprint = 0L, maxfun = 10000L, FtolAbs = 0.00001,
> FtolRel
> > = 1e-15,  :*
> > *  unused control arguments ignored*
> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> >   unable to evaluate scaled gradient
> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> >   Model failed to converge: degenerate  Hessian with 11 negative
> eigenvalues
> >
> > I'm afraid I might be doing something wrong in handeling the DV or
> > 10-factor level IV, which in turn, is causing the 3 errors in bold. Does
> > anyone have suggestions. Or can some one tell me what the source of these
> > errors are?
> >
> > Much obliged in advance,
> >
> > Kindest regards,
> >
> > Michiel Kiggen
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From B@Liew @ending from bh@m@@c@uk  Mon Jun 25 17:09:58 2018
From: B@Liew @ending from bh@m@@c@uk (Bernard Liew)
Date: Mon, 25 Jun 2018 15:09:58 +0000
Subject: [R-sig-ME] Question on hierarchical nature and data format using
 lmer
Message-ID: <A901AC7187F75B41BF677B0A610C0976E8E5F9@EX11.adf.bham.ac.uk>

Dear Community,

Thank you first for the help. My question pertains to a research design as follow:

200 students in total from 4 schools, undergoing different clinical placements in a semester. There are 5 different plausible clinical placements. This means some students have zero placements, others can have a maximum of three, with any placement combinations. Two out of three clinical placements are restricted to some schools. So some clinical placements are nested within schools, others are crossed across schools.

The response variable is an ordinal measure Likert scale of "sharing". The predictors are school and placement.

Qn to be answered: Does different school and clinical placement alter a student's degree of sharing?

Problem 1: data format

The traditional way to format the data is the long "tidy" method. However, because placements are not unique to an individual, how best should one format the data?

Solution 1 ( I think): make the placement variable into a wide format, so instead of one placement predictor, I now have five different placement predictors. This then appears to change the research question? Is there another solution?

Kind regards,
Bernard


	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Tue Jun 26 10:31:16 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 26 Jun 2018 10:31:16 +0200
Subject: [R-sig-ME] Errors in GLMER
In-Reply-To: <CADqHjY_UXv32KcAqs1Obihp_WDtyPzmF2-eShK119hXueb--wA@mail.gmail.com>
References: <CADqHjY-dzKe+T6TdUDgNVOLkc35XbLPDBrPDOs0DHkF9c8HnOA@mail.gmail.com>
 <CAJuCY5ybFhzAB5s80=rfSNwEyEJ15rTEu6Kqf917MAbyufBnZw@mail.gmail.com>
 <CADqHjY_UXv32KcAqs1Obihp_WDtyPzmF2-eShK119hXueb--wA@mail.gmail.com>
Message-ID: <CAJuCY5zuEXpOCdn-DsTphmgeJfukQbzG_=myq-VXfQZSOuqSwg@mail.gmail.com>

Dear Michiel,

I think you need to take a step back. Your model is most likely too
complex for your data. You have about 16 parameters in your model and
only 103 observations... I tend to use as a rule of thumb: at least 10
effective observations per parameter. In case of a binomial
distribution I count the number of success and the number of failures
and use the lowest of the two as number of effective observations. In
ideal circumstances, a near 50%-50% split, you have 50 effective
observations so you can use only 5 parameters... Fisher's quote in my
signature might be applicable.

A side note: although you can code a binomial response as a factor, it
is IMHO more clear to code it as a logical value. If you do want to
code it as a factor, make sure that you read the details of ?family.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-25 18:33 GMT+02:00 Michiel Kiggen <michiel.kiggen at gmail.com>:
> Dear Thierry
>
> Thanks so much for comments, I really appreciate it.
>
> Based on your feedback, I'm running the following model now:
>
> model_poly_nc <- glmer(AoR ~ Offers_lin*(sFW*sMF)+ Offers_quad *(sFW*sMF) +
> (1 |ID)+ (0 + Offers_lin| ID)+(0 + Offers_quad| ID),family = binomial, data
> = data, control = glmerControl(optCtrl = list(maxfun = 1e+9)))
>
> Offers_lin & Offers_quad are the trial variables (polynomials for linear and
> quadratic patterns). Both of them are centered. Metric is from 1 till 10. (1
> being trial in which people get lowest offer and 10 being the highest offer
> in an ultimatum game)
> sFW & sMF are the continous questionairre sumscores, standardized &
> centered.
> DV (2 level factor accept or reject)
> n = 103
>
> I ran the model with covariance terms for the random effects. It didn't
> converge, neither with optimizers bobyqa & Nelder_Mead.
> However, the function allFit, strangely returned [OK] for bobyqa,
> Nelder_Mead, nloptwrap.NLOPT_LN_NELDERMEAD & nloptwrap.NLOPT_LN_BOBYQA.
> The model above is without covariance terms for the random effects. After
> running this I get the same convergence issue and the same output on allFit:
> [OK] for bobyqa, Nelder_Mead, nloptwrap.NLOPT_LN_NELDERMEAD &
> nloptwrap.NLOPT_LN_BOBYQA.
>
> Using the getME function to look at the different Fixed Effects generated by
> allFit (no covariance term model, as described above), it reveals that the
> numbers are similar for bobyqa,  loptwrap.NLOPT_LN_NELDERMEAD &
> nloptwrap.NLOPT_LN_BOBYQA. While for the Nelder_mead numbers are just
> slightly different. Like a 0.02 difference.
>
> For the seperate Models with optimizers Bobyqa & Nelder_Mead (both with
> convergence issues), the fixed effects were exactly the same.
>
> I'm not sure how to interpret these allFit function results. For what
> patterns should I look incase I want to conclude these warnings are
> false-positives?
> Else, what options do I have? I've already stripped the model of it random
> covariances (Removing the random slope will make the purpose of using Mixed
> Models dispensable).
>
> My apologies if I'm asking any obvious questions. First time i'm running
> this kind of analysis.
>
> Any help is much appreciated!
>
> Kind regards,
>
> Michiel
>
>
>
>
>
> Op ma 25 jun. 2018 om 09:08 schreef Thierry Onkelinx
> <thierry.onkelinx at inbo.be>:
>>
>> Dear Michiel,
>>
>> Does it run with the random slope for trial. If I understand the
>> design correctly, you have only one observation per trial and per ID.
>> In that case a random slope for trial as an (ordered) factor won't
>> work.
>>
>> Consider using trial as a continuous variable and use some polynomials
>> to model it.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> 2018-06-24 23:41 GMT+02:00 Michiel Kiggen <michiel.kiggen at gmail.com>:
>> > Dear Reader,
>> >
>> > I'm trying to run a GLMER model for the following data:
>> > *2x scaled continous predictor* (sum score of 2 questionairres)
>> > *1x predictor being 10 trials* on a ultimatum game of which each trial
>> > is 1
>> > out of 10 possible options. (offer of a split of $20: e.g. you 1 and 19
>> > me). Inserted this a non ordered factor (10-levels) with sum-to-zero
>> > coding
>> > (contrast.sum).
>> > *1x dependent binary variable *being the response to the 10 trials
>> > valued
>> > at accepted (1) or reject (2). Entered as a factor.
>> >
>> > After the following model without correlations terms (I ran this model
>> > after failing to converge on a model without optimizers and the all_fit
>> > of
>> > that) I get the following errors:
>> >
>> > glmer(AoR ~ Trials * (sPredictor1*sPredictor2) + (1 | ID )+  (0 + Trials
>> > |ID),family = binomial, data = data, control = glmerControl(optCtrl =
>> > list(maxfun = 1e+9, optimizer = "bobyqa")))
>> >
>> >
>> > *fixed-effect model matrix is rank deficient so dropping 10 columns /
>> > coefficients*
>> > *Warning messages:*
>> > *1: In (function (npt = min(n + 2L, 2L * n), rhobeg = NA, rhoend = NA,
>> > :*
>> > *  unused control arguments ignored*
>> > *2: In (function (iprint = 0L, maxfun = 10000L, FtolAbs = 0.00001,
>> > FtolRel
>> > = 1e-15,  :*
>> > *  unused control arguments ignored*
>> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> > :
>> >   unable to evaluate scaled gradient
>> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> > :
>> >   Model failed to converge: degenerate  Hessian with 11 negative
>> > eigenvalues
>> >
>> > I'm afraid I might be doing something wrong in handeling the DV or
>> > 10-factor level IV, which in turn, is causing the 3 errors in bold. Does
>> > anyone have suggestions. Or can some one tell me what the source of
>> > these
>> > errors are?
>> >
>> > Much obliged in advance,
>> >
>> > Kindest regards,
>> >
>> > Michiel Kiggen
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry@onkelinx @ending from inbo@be  Tue Jun 26 10:37:55 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 26 Jun 2018 10:37:55 +0200
Subject: [R-sig-ME] 
 Question on hierarchical nature and data format using lmer
In-Reply-To: <A901AC7187F75B41BF677B0A610C0976E8E5F9@EX11.adf.bham.ac.uk>
References: <A901AC7187F75B41BF677B0A610C0976E8E5F9@EX11.adf.bham.ac.uk>
Message-ID: <CAJuCY5xLVrB82OLxMtce_yT9mxy5LZjArF03KaEUYo0EWvL36g@mail.gmail.com>

Dear Bernard,

The typical format is one row of data per observation. If you have one
measurement per student, then you need to have a column per clinical
placement (with a TRUE or FALSE value).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-25 17:09 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
> Dear Community,
>
> Thank you first for the help. My question pertains to a research design as follow:
>
> 200 students in total from 4 schools, undergoing different clinical placements in a semester. There are 5 different plausible clinical placements. This means some students have zero placements, others can have a maximum of three, with any placement combinations. Two out of three clinical placements are restricted to some schools. So some clinical placements are nested within schools, others are crossed across schools.
>
> The response variable is an ordinal measure Likert scale of "sharing". The predictors are school and placement.
>
> Qn to be answered: Does different school and clinical placement alter a student's degree of sharing?
>
> Problem 1: data format
>
> The traditional way to format the data is the long "tidy" method. However, because placements are not unique to an individual, how best should one format the data?
>
> Solution 1 ( I think): make the placement variable into a wide format, so instead of one placement predictor, I now have five different placement predictors. This then appears to change the research question? Is there another solution?
>
> Kind regards,
> Bernard
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @lte@@ed@c2 @ending from gm@il@com  Wed Jun 27 14:42:13 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Wed, 27 Jun 2018 14:42:13 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
Message-ID: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>

Hi, dear all.
neither
install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
   nor
install.packages("R2admb")
install.packages("glmmADMB",
repos=c("http://glmmadmb.r-forge.r-project.org/repos",
                         getOption("repos")),
                 type="source")
,
helps me to intall this package.
In advance, many thanks for any help.
Kind regards,
Amal

	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Wed Jun 27 14:45:13 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Wed, 27 Jun 2018 14:45:13 +0200
Subject: [R-sig-ME] problem-installing-glmmADMB-package
Message-ID: <CANrzCv0QLQ0CZ6an1bi2-Q=eUcL9-4wYkrsO8LWwKA_YXNcU1A@mail.gmail.com>

 Hi, dear all.
neither
install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
   nor
install.packages("R2admb")
install.packages("glmmADMB",
repos=c("http://glmmadmb.r-forge.r-project.org/repos",
                         getOption("repos")),
                 type="source")
,
helps me to intall this package;
my laptop is 64 bits, running under windows 8.1.
In advance, many thanks for any help.
Kind regards,
Amal

	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Wed Jun 27 14:45:21 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Wed, 27 Jun 2018 14:45:21 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
Message-ID: <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>

Hi Amal,

Maybe installing from GitHub could work. See instructions here https://github.com/bbolker/glmmadmb

If that doesn?t work, please give us more information, like error messages.

Mollie

> On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> 
> Hi, dear all.
> neither
> install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
>   nor
> install.packages("R2admb")
> install.packages("glmmADMB",
> repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>                         getOption("repos")),
>                 type="source")
> ,
> helps me to intall this package.
> In advance, many thanks for any help.
> Kind regards,
> Amal
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @lte@@ed@c2 @ending from gm@il@com  Wed Jun 27 15:11:15 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Wed, 27 Jun 2018 15:11:15 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
 <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
Message-ID: <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>

Mollie,
many thanks for your reply.
These instructions do not work and I get the message below:

Downloading GitHub repo bbolker/glmmadmb at master
from URL https://api.github.com/repos/bbolker/glmmadmb/zipball/masterInstalling
glmmADMB"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" --no-site-file --no-environ
--no-save --no-restore  \
  --quiet CMD INSTALL  \
  "C:/Users/Coliasso/AppData/Local/Temp/Rtmpopho7h/devtools20ec3a7135b9/bbolker-glmmadmb-ac75f73"
 \
  --library="C:/Users/Coliasso/Documents/R/win-library/3.4"
--install-tests Installation failed: cannot change working directory

>


2018-06-27 14:45 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:

> Hi Amal,
>
> Maybe installing from GitHub could work. See instructions here
> https://github.com/bbolker/glmmadmb
>
> If that doesn?t work, please give us more information, like error messages.
>
> Mollie
>
> > On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> >
> > Hi, dear all.
> > neither
> > install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
> >   nor
> > install.packages("R2admb")
> > install.packages("glmmADMB",
> > repos=c("http://glmmadmb.r-forge.r-project.org/repos",
> >                         getOption("repos")),
> >                 type="source")
> > ,
> > helps me to intall this package.
> > In advance, many thanks for any help.
> > Kind regards,
> > Amal
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From romunov @ending from gm@il@com  Wed Jun 27 15:24:53 2018
From: romunov @ending from gm@il@com (romunov)
Date: Wed, 27 Jun 2018 15:24:53 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
 <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
 <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>
Message-ID: <CAHT1vpiXXFqJNYut=E37Lnaw63a8BcXv9U4gLTcVd9j-AYahqQ@mail.gmail.com>

Please include a bit more information in your problem report. At which step
the problem occurs?

Cheers,
Roman

On Wed, Jun 27, 2018 at 3:11 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
wrote:

> Mollie,
> many thanks for your reply.
> These instructions do not work and I get the message below:
>
> Downloading GitHub repo bbolker/glmmadmb at master
> from URL
> https://api.github.com/repos/bbolker/glmmadmb/zipball/masterInstalling
> glmmADMB"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" --no-site-file --no-environ
> --no-save --no-restore  \
>   --quiet CMD INSTALL  \
>
> "C:/Users/Coliasso/AppData/Local/Temp/Rtmpopho7h/devtools20ec3a7135b9/bbolker-glmmadmb-ac75f73"
>  \
>   --library="C:/Users/Coliasso/Documents/R/win-library/3.4"
> --install-tests Installation failed: cannot change working directory
>
> >
>
>
> 2018-06-27 14:45 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:
>
> > Hi Amal,
> >
> > Maybe installing from GitHub could work. See instructions here
> > https://github.com/bbolker/glmmadmb
> >
> > If that doesn?t work, please give us more information, like error
> messages.
> >
> > Mollie
> >
> > > On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> > >
> > > Hi, dear all.
> > > neither
> > > install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
> > >   nor
> > > install.packages("R2admb")
> > > install.packages("glmmADMB",
> > > repos=c("http://glmmadmb.r-forge.r-project.org/repos",
> > >                         getOption("repos")),
> > >                 type="source")
> > > ,
> > > helps me to intall this package.
> > > In advance, many thanks for any help.
> > > Kind regards,
> > > Amal
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Wed Jun 27 15:41:58 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Wed, 27 Jun 2018 15:41:58 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <CAHT1vpiXXFqJNYut=E37Lnaw63a8BcXv9U4gLTcVd9j-AYahqQ@mail.gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
 <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
 <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>
 <CAHT1vpiXXFqJNYut=E37Lnaw63a8BcXv9U4gLTcVd9j-AYahqQ@mail.gmail.com>
Message-ID: <CANrzCv1hKx7VYOTnHxhX+HX2qKi3_C9vfp2Z4CKSrASR39_Fag@mail.gmail.com>

Hi, Roman.
The problem occurs at the third of the installation steps here:
https://github.com/bbolker/glmmadmb
My 64 bits pc is running under windows 8.1.
Kind regards,
Amal

2018-06-27 15:24 GMT+02:00 romunov <romunov at gmail.com>:

> Please include a bit more information in your problem report. At which
> step the problem occurs?
>
> Cheers,
> Roman
>
> On Wed, Jun 27, 2018 at 3:11 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
>
>> Mollie,
>> many thanks for your reply.
>> These instructions do not work and I get the message below:
>>
>> Downloading GitHub repo bbolker/glmmadmb at master
>> from URL https://api.github.com/repos/bbolker/glmmadmb/zipball/
>> masterInstalling
>> glmmADMB"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" --no-site-file --no-environ
>> --no-save --no-restore  \
>>   --quiet CMD INSTALL  \
>>   "C:/Users/Coliasso/AppData/Local/Temp/Rtmpopho7h/
>> devtools20ec3a7135b9/bbolker-glmmadmb-ac75f73"
>>  \
>>   --library="C:/Users/Coliasso/Documents/R/win-library/3.4"
>> --install-tests Installation failed: cannot change working directory
>>
>> >
>>
>>
>> 2018-06-27 14:45 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:
>>
>> > Hi Amal,
>> >
>> > Maybe installing from GitHub could work. See instructions here
>> > https://github.com/bbolker/glmmadmb
>> >
>> > If that doesn?t work, please give us more information, like error
>> messages.
>> >
>> > Mollie
>> >
>> > > On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com>
>> wrote:
>> > >
>> > > Hi, dear all.
>> > > neither
>> > > install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
>> > >   nor
>> > > install.packages("R2admb")
>> > > install.packages("glmmADMB",
>> > > repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>> > >                         getOption("repos")),
>> > >                 type="source")
>> > > ,
>> > > helps me to intall this package.
>> > > In advance, many thanks for any help.
>> > > Kind regards,
>> > > Amal
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> In God we trust, all others bring data.
>

	[[alternative HTML version deleted]]


From romunov @ending from gm@il@com  Wed Jun 27 15:55:15 2018
From: romunov @ending from gm@il@com (romunov)
Date: Wed, 27 Jun 2018 15:55:15 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <CANrzCv1hKx7VYOTnHxhX+HX2qKi3_C9vfp2Z4CKSrASR39_Fag@mail.gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
 <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
 <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>
 <CAHT1vpiXXFqJNYut=E37Lnaw63a8BcXv9U4gLTcVd9j-AYahqQ@mail.gmail.com>
 <CANrzCv1hKx7VYOTnHxhX+HX2qKi3_C9vfp2Z4CKSrASR39_Fag@mail.gmail.com>
Message-ID: <CAHT1vpgJkeC_jOAvKWaUkQ4LLVBa+OVuzpa7A-j_WP4d9Zo=5g@mail.gmail.com>

A shotgun approach to solving this would be to have all R instances closed
and make sure you have permission to write. Forgive me if I have not
followed this thread from the beginning, but do you have appropriate
Windows toolchain installed?

Cheers,
Roman

On Wed, Jun 27, 2018 at 3:41 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
wrote:

> Hi, Roman.
> The problem occurs at the third of the installation steps here:
> https://github.com/bbolker/glmmadmb
> My 64 bits pc is running under windows 8.1.
> Kind regards,
> Amal
>
> 2018-06-27 15:24 GMT+02:00 romunov <romunov at gmail.com>:
>
>> Please include a bit more information in your problem report. At which
>> step the problem occurs?
>>
>> Cheers,
>> Roman
>>
>> On Wed, Jun 27, 2018 at 3:11 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
>> wrote:
>>
>>> Mollie,
>>> many thanks for your reply.
>>> These instructions do not work and I get the message below:
>>>
>>> Downloading GitHub repo bbolker/glmmadmb at master
>>> from URL
>>> https://api.github.com/repos/bbolker/glmmadmb/zipball/masterInstalling
>>> glmmADMB"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" --no-site-file --no-environ
>>> --no-save --no-restore  \
>>>   --quiet CMD INSTALL  \
>>>
>>> "C:/Users/Coliasso/AppData/Local/Temp/Rtmpopho7h/devtools20ec3a7135b9/bbolker-glmmadmb-ac75f73"
>>>  \
>>>   --library="C:/Users/Coliasso/Documents/R/win-library/3.4"
>>> --install-tests Installation failed: cannot change working directory
>>>
>>> >
>>>
>>>
>>> 2018-06-27 14:45 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:
>>>
>>> > Hi Amal,
>>> >
>>> > Maybe installing from GitHub could work. See instructions here
>>> > https://github.com/bbolker/glmmadmb
>>> >
>>> > If that doesn?t work, please give us more information, like error
>>> messages.
>>> >
>>> > Mollie
>>> >
>>> > > On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com>
>>> wrote:
>>> > >
>>> > > Hi, dear all.
>>> > > neither
>>> > > install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
>>> > >   nor
>>> > > install.packages("R2admb")
>>> > > install.packages("glmmADMB",
>>> > > repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>>> > >                         getOption("repos")),
>>> > >                 type="source")
>>> > > ,
>>> > > helps me to intall this package.
>>> > > In advance, many thanks for any help.
>>> > > Kind regards,
>>> > > Amal
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-mixed-models at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> In God we trust, all others bring data.
>>
>
>

-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Wed Jun 27 15:59:24 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Wed, 27 Jun 2018 15:59:24 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <CAHT1vpgJkeC_jOAvKWaUkQ4LLVBa+OVuzpa7A-j_WP4d9Zo=5g@mail.gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
 <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
 <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>
 <CAHT1vpiXXFqJNYut=E37Lnaw63a8BcXv9U4gLTcVd9j-AYahqQ@mail.gmail.com>
 <CANrzCv1hKx7VYOTnHxhX+HX2qKi3_C9vfp2Z4CKSrASR39_Fag@mail.gmail.com>
 <CAHT1vpgJkeC_jOAvKWaUkQ4LLVBa+OVuzpa7A-j_WP4d9Zo=5g@mail.gmail.com>
Message-ID: <CANrzCv0u6_9NaqwC3FTQD7OHQUpZF9SnuSXCt+s_aENcXg+0Mw@mail.gmail.com>

Please, Roman,
which Windows toolchain  do you mean?

2018-06-27 15:55 GMT+02:00 romunov <romunov at gmail.com>:

> A shotgun approach to solving this would be to have all R instances closed
> and make sure you have permission to write. Forgive me if I have not
> followed this thread from the beginning, but do you have appropriate
> Windows toolchain installed?
>
> Cheers,
> Roman
>
> On Wed, Jun 27, 2018 at 3:41 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
>
>> Hi, Roman.
>> The problem occurs at the third of the installation steps here:
>> https://github.com/bbolker/glmmadmb
>> My 64 bits pc is running under windows 8.1.
>> Kind regards,
>> Amal
>>
>> 2018-06-27 15:24 GMT+02:00 romunov <romunov at gmail.com>:
>>
>>> Please include a bit more information in your problem report. At which
>>> step the problem occurs?
>>>
>>> Cheers,
>>> Roman
>>>
>>> On Wed, Jun 27, 2018 at 3:11 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
>>> wrote:
>>>
>>>> Mollie,
>>>> many thanks for your reply.
>>>> These instructions do not work and I get the message below:
>>>>
>>>> Downloading GitHub repo bbolker/glmmadmb at master
>>>> from URL https://api.github.com/repos/bbolker/glmmadmb/zipball/
>>>> masterInstalling
>>>> glmmADMB"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" --no-site-file --no-environ
>>>> --no-save --no-restore  \
>>>>   --quiet CMD INSTALL  \
>>>>   "C:/Users/Coliasso/AppData/Local/Temp/Rtmpopho7h/
>>>> devtools20ec3a7135b9/bbolker-glmmadmb-ac75f73"
>>>>  \
>>>>   --library="C:/Users/Coliasso/Documents/R/win-library/3.4"
>>>> --install-tests Installation failed: cannot change working directory
>>>>
>>>> >
>>>>
>>>>
>>>> 2018-06-27 14:45 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:
>>>>
>>>> > Hi Amal,
>>>> >
>>>> > Maybe installing from GitHub could work. See instructions here
>>>> > https://github.com/bbolker/glmmadmb
>>>> >
>>>> > If that doesn?t work, please give us more information, like error
>>>> messages.
>>>> >
>>>> > Mollie
>>>> >
>>>> > > On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com>
>>>> wrote:
>>>> > >
>>>> > > Hi, dear all.
>>>> > > neither
>>>> > > install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
>>>> > >   nor
>>>> > > install.packages("R2admb")
>>>> > > install.packages("glmmADMB",
>>>> > > repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>>>> > >                         getOption("repos")),
>>>> > >                 type="source")
>>>> > > ,
>>>> > > helps me to intall this package.
>>>> > > In advance, many thanks for any help.
>>>> > > Kind regards,
>>>> > > Amal
>>>> > >
>>>> > >       [[alternative HTML version deleted]]
>>>> > >
>>>> > > _______________________________________________
>>>> > > R-sig-mixed-models at r-project.org mailing list
>>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> In God we trust, all others bring data.
>>>
>>
>>
>
> --
> In God we trust, all others bring data.
>

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Wed Jun 27 16:01:13 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Wed, 27 Jun 2018 16:01:13 +0200
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <CAHT1vpgJkeC_jOAvKWaUkQ4LLVBa+OVuzpa7A-j_WP4d9Zo=5g@mail.gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
 <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
 <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>
 <CAHT1vpiXXFqJNYut=E37Lnaw63a8BcXv9U4gLTcVd9j-AYahqQ@mail.gmail.com>
 <CANrzCv1hKx7VYOTnHxhX+HX2qKi3_C9vfp2Z4CKSrASR39_Fag@mail.gmail.com>
 <CAHT1vpgJkeC_jOAvKWaUkQ4LLVBa+OVuzpa7A-j_WP4d9Zo=5g@mail.gmail.com>
Message-ID: <b54b0860-12fc-112a-d53d-c1f680e553b9@mpi.nl>

I've run into this issue with rstan when using RStudio (from a conda
installation, but I think RStudio is the relevant bit). As part of its
support of project-based workflows, RStudio does some managing of the
working directory and I think that's what blocks changing the working
directory. In my case, I was unable to install the rstan examples from
RStudio, but was able to do so from the standalone R.

Best,
Phillip

On 06/27/2018 03:55 PM, romunov wrote:
> A shotgun approach to solving this would be to have all R instances closed
> and make sure you have permission to write. Forgive me if I have not
> followed this thread from the beginning, but do you have appropriate
> Windows toolchain installed?
> 
> Cheers,
> Roman
> 
> On Wed, Jun 27, 2018 at 3:41 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> 
>> Hi, Roman.
>> The problem occurs at the third of the installation steps here:
>> https://github.com/bbolker/glmmadmb
>> My 64 bits pc is running under windows 8.1.
>> Kind regards,
>> Amal
>>
>> 2018-06-27 15:24 GMT+02:00 romunov <romunov at gmail.com>:
>>
>>> Please include a bit more information in your problem report. At which
>>> step the problem occurs?
>>>
>>> Cheers,
>>> Roman
>>>
>>> On Wed, Jun 27, 2018 at 3:11 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
>>> wrote:
>>>
>>>> Mollie,
>>>> many thanks for your reply.
>>>> These instructions do not work and I get the message below:
>>>>
>>>> Downloading GitHub repo bbolker/glmmadmb at master
>>>> from URL
>>>> https://api.github.com/repos/bbolker/glmmadmb/zipball/masterInstalling
>>>> glmmADMB"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" --no-site-file --no-environ
>>>> --no-save --no-restore  \
>>>>   --quiet CMD INSTALL  \
>>>>
>>>> "C:/Users/Coliasso/AppData/Local/Temp/Rtmpopho7h/devtools20ec3a7135b9/bbolker-glmmadmb-ac75f73"
>>>>  \
>>>>   --library="C:/Users/Coliasso/Documents/R/win-library/3.4"
>>>> --install-tests Installation failed: cannot change working directory
>>>>
>>>>>
>>>>
>>>>
>>>> 2018-06-27 14:45 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:
>>>>
>>>>> Hi Amal,
>>>>>
>>>>> Maybe installing from GitHub could work. See instructions here
>>>>> https://github.com/bbolker/glmmadmb
>>>>>
>>>>> If that doesn?t work, please give us more information, like error
>>>> messages.
>>>>>
>>>>> Mollie
>>>>>
>>>>>> On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com>
>>>> wrote:
>>>>>>
>>>>>> Hi, dear all.
>>>>>> neither
>>>>>> install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
>>>>>>   nor
>>>>>> install.packages("R2admb")
>>>>>> install.packages("glmmADMB",
>>>>>> repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>>>>>>                         getOption("repos")),
>>>>>>                 type="source")
>>>>>> ,
>>>>>> helps me to intall this package.
>>>>>> In advance, many thanks for any help.
>>>>>> Kind regards,
>>>>>> Amal
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> In God we trust, all others bring data.
>>>
>>
>>
>


From bbolker @ending from gm@il@com  Wed Jun 27 16:05:02 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 27 Jun 2018 10:05:02 -0400
Subject: [R-sig-ME] Problem-installing-package-GlmmADMB
In-Reply-To: <CANrzCv0u6_9NaqwC3FTQD7OHQUpZF9SnuSXCt+s_aENcXg+0Mw@mail.gmail.com>
References: <CANrzCv0vyTgQiR8_NmsfW=mJ0AJ5YqHgUHkyKikDr1Gu0UHgBA@mail.gmail.com>
 <0EE03D78-35EA-49C0-8034-F7EDC0461918@gmail.com>
 <CANrzCv1CNX2cx9c1-qg=x1to-H3=GPn6ESpHtQgk=gV0Eakx7Q@mail.gmail.com>
 <CAHT1vpiXXFqJNYut=E37Lnaw63a8BcXv9U4gLTcVd9j-AYahqQ@mail.gmail.com>
 <CANrzCv1hKx7VYOTnHxhX+HX2qKi3_C9vfp2Z4CKSrASR39_Fag@mail.gmail.com>
 <CAHT1vpgJkeC_jOAvKWaUkQ4LLVBa+OVuzpa7A-j_WP4d9Zo=5g@mail.gmail.com>
 <CANrzCv0u6_9NaqwC3FTQD7OHQUpZF9SnuSXCt+s_aENcXg+0Mw@mail.gmail.com>
Message-ID: <CABghstQ6itS930M0ekjRXoSZCJspyP-VN1yoS58dXJAs2=tbGQ@mail.gmail.com>

A few quick points:

(1) I don't think you should need the windows toolchain to install
glmmADMB; it doesn't have any compiled components (it has a
pre-compiled binary "blob" that prevents it from being posted to
CRAN). But try devtools::dr_devtools()
(2) The fact that your error report ends with " --install-tests
Installation failed: cannot change working directory" strongly
suggests that you may have other problems with file permissions, as
romunov suggests
(3) It might be worth trying glmmTMB instead. glmmADMB is still
supported (sort of), but glmmTMB is newer, nearly drop-in compatible
with glmmADMB, faster, and better supported/under more rapid
development.

On Wed, Jun 27, 2018 at 9:59 AM, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> Please, Roman,
> which Windows toolchain  do you mean?
>
> 2018-06-27 15:55 GMT+02:00 romunov <romunov at gmail.com>:
>
>> A shotgun approach to solving this would be to have all R instances closed
>> and make sure you have permission to write. Forgive me if I have not
>> followed this thread from the beginning, but do you have appropriate
>> Windows toolchain installed?
>>
>> Cheers,
>> Roman
>>
>> On Wed, Jun 27, 2018 at 3:41 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
>> wrote:
>>
>>> Hi, Roman.
>>> The problem occurs at the third of the installation steps here:
>>> https://github.com/bbolker/glmmadmb
>>> My 64 bits pc is running under windows 8.1.
>>> Kind regards,
>>> Amal
>>>
>>> 2018-06-27 15:24 GMT+02:00 romunov <romunov at gmail.com>:
>>>
>>>> Please include a bit more information in your problem report. At which
>>>> step the problem occurs?
>>>>
>>>> Cheers,
>>>> Roman
>>>>
>>>> On Wed, Jun 27, 2018 at 3:11 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
>>>> wrote:
>>>>
>>>>> Mollie,
>>>>> many thanks for your reply.
>>>>> These instructions do not work and I get the message below:
>>>>>
>>>>> Downloading GitHub repo bbolker/glmmadmb at master
>>>>> from URL https://api.github.com/repos/bbolker/glmmadmb/zipball/
>>>>> masterInstalling
>>>>> glmmADMB"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" --no-site-file --no-environ
>>>>> --no-save --no-restore  \
>>>>>   --quiet CMD INSTALL  \
>>>>>   "C:/Users/Coliasso/AppData/Local/Temp/Rtmpopho7h/
>>>>> devtools20ec3a7135b9/bbolker-glmmadmb-ac75f73"
>>>>>  \
>>>>>   --library="C:/Users/Coliasso/Documents/R/win-library/3.4"
>>>>> --install-tests Installation failed: cannot change working directory
>>>>>
>>>>> >
>>>>>
>>>>>
>>>>> 2018-06-27 14:45 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:
>>>>>
>>>>> > Hi Amal,
>>>>> >
>>>>> > Maybe installing from GitHub could work. See instructions here
>>>>> > https://github.com/bbolker/glmmadmb
>>>>> >
>>>>> > If that doesn?t work, please give us more information, like error
>>>>> messages.
>>>>> >
>>>>> > Mollie
>>>>> >
>>>>> > > On 27Jun 2018, at 14:42, C. AMAL D. GLELE <altessedac2 at gmail.com>
>>>>> wrote:
>>>>> > >
>>>>> > > Hi, dear all.
>>>>> > > neither
>>>>> > > install.packages("glmmADMB", repos="http://R-Forge.R-project.org")
>>>>> > >   nor
>>>>> > > install.packages("R2admb")
>>>>> > > install.packages("glmmADMB",
>>>>> > > repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>>>>> > >                         getOption("repos")),
>>>>> > >                 type="source")
>>>>> > > ,
>>>>> > > helps me to intall this package.
>>>>> > > In advance, many thanks for any help.
>>>>> > > Kind regards,
>>>>> > > Amal
>>>>> > >
>>>>> > >       [[alternative HTML version deleted]]
>>>>> > >
>>>>> > > _______________________________________________
>>>>> > > R-sig-mixed-models at r-project.org mailing list
>>>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >
>>>>> >
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>
>>>> --
>>>> In God we trust, all others bring data.
>>>>
>>>
>>>
>>
>> --
>> In God we trust, all others bring data.
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry@onkelinx @ending from inbo@be  Wed Jun 27 17:13:48 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 27 Jun 2018 17:13:48 +0200
Subject: [R-sig-ME] 
 Question on hierarchical nature and data format using lmer
In-Reply-To: <A901AC7187F75B41BF677B0A610C0976E8E9C8@EX11.adf.bham.ac.uk>
References: <A901AC7187F75B41BF677B0A610C0976E8E5F9@EX11.adf.bham.ac.uk>
 <CAJuCY5xLVrB82OLxMtce_yT9mxy5LZjArF03KaEUYo0EWvL36g@mail.gmail.com>
 <A901AC7187F75B41BF677B0A610C0976E8E9C8@EX11.adf.bham.ac.uk>
Message-ID: <CAJuCY5wv6To4nSiZ6jB+uQMQFPbQgPxbrXGo3zA3-kFwHeWtJg@mail.gmail.com>

Dear Bernard,

Using a factor both in the fixed effects and the random effects is
nonsense. I wrote a blog post on that topic:
https://www.muscardinus.be/2017/08/fixed-and-random/

Do all programs have multiple clinics? If programme "physio" has only
clinic "A" and clinic "A" is only used in programme "physio" then it
is impossible to distinguish between the effect of the programme and
the effect of the clinic. Can you illustrate your design as a simple
table (e.g. programme as column and clinic as row)? Note that any HTML
formatting will be removed, so you plain text formatting only.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-27 16:56 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
> Thanks Thierry,
>
> I thought so. So this leads on to the next question of how to then specify the random effects structure. Given predictors of study programme (4 levels: physio, med, nurse, speed), clinicA (yes/no), clinicB(yes/no), clinicC(yes/no), clinicD(yes/no), clinicE(yes/no), and s clinic A,B,C are nested in study programme [ie. Some clinics are only offered in some programme), and D,E are crossed across programme (common to all programmes)
>
> Is the following logical? I am using the ordinal package, but the formula follows that of lmer.
>
> clmm (as.factor (Sharing) ~ Programme + clinicA + clinicB + clinicC+ clinicD+ clinicE +
>                   (1| Programme) + (1| Programme:clinicA) + (1| Programme:clinicB) + (1| Programme:clinicC) +
>             (1| clinicD)  + (1| clinicE) + (1| Programme:clinicD) + (1| Programme:clinicE) ,
>                   data = dat,
>                   link = "logit",
>                   threshold = "equidistant")
>
> Many thanks,
> Bernard
>
> -----Original Message-----
> From: thierry.onkelinx at inbo.be <thierry.onkelinx at inbo.be>
> Sent: 26 June 2018 09:38
> To: Bernard Liew (School of Sport Exercise and Rehabilitation Sciences) <B.Liew at bham.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Question on hierarchical nature and data format using lmer
>
> Dear Bernard,
>
> The typical format is one row of data per observation. If you have one measurement per student, then you need to have a column per clinical placement (with a TRUE or FALSE value).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-06-25 17:09 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
>> Dear Community,
>>
>> Thank you first for the help. My question pertains to a research design as follow:
>>
>> 200 students in total from 4 schools, undergoing different clinical placements in a semester. There are 5 different plausible clinical placements. This means some students have zero placements, others can have a maximum of three, with any placement combinations. Two out of three clinical placements are restricted to some schools. So some clinical placements are nested within schools, others are crossed across schools.
>>
>> The response variable is an ordinal measure Likert scale of "sharing". The predictors are school and placement.
>>
>> Qn to be answered: Does different school and clinical placement alter a student's degree of sharing?
>>
>> Problem 1: data format
>>
>> The traditional way to format the data is the long "tidy" method. However, because placements are not unique to an individual, how best should one format the data?
>>
>> Solution 1 ( I think): make the placement variable into a wide format, so instead of one placement predictor, I now have five different placement predictors. This then appears to change the research question? Is there another solution?
>>
>> Kind regards,
>> Bernard
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From B@Liew @ending from bh@m@@c@uk  Wed Jun 27 16:56:27 2018
From: B@Liew @ending from bh@m@@c@uk (Bernard Liew)
Date: Wed, 27 Jun 2018 14:56:27 +0000
Subject: [R-sig-ME] 
 Question on hierarchical nature and data format using lmer
In-Reply-To: <CAJuCY5xLVrB82OLxMtce_yT9mxy5LZjArF03KaEUYo0EWvL36g@mail.gmail.com>
References: <A901AC7187F75B41BF677B0A610C0976E8E5F9@EX11.adf.bham.ac.uk>
 <CAJuCY5xLVrB82OLxMtce_yT9mxy5LZjArF03KaEUYo0EWvL36g@mail.gmail.com>
Message-ID: <A901AC7187F75B41BF677B0A610C0976E8E9C8@EX11.adf.bham.ac.uk>

Thanks Thierry,

I thought so. So this leads on to the next question of how to then specify the random effects structure. Given predictors of study programme (4 levels: physio, med, nurse, speed), clinicA (yes/no), clinicB(yes/no), clinicC(yes/no), clinicD(yes/no), clinicE(yes/no), and s clinic A,B,C are nested in study programme [ie. Some clinics are only offered in some programme), and D,E are crossed across programme (common to all programmes)

Is the following logical? I am using the ordinal package, but the formula follows that of lmer.

clmm (as.factor (Sharing) ~ Programme + clinicA + clinicB + clinicC+ clinicD+ clinicE + 
                  (1| Programme) + (1| Programme:clinicA) + (1| Programme:clinicB) + (1| Programme:clinicC) + 
	    (1| clinicD)  + (1| clinicE) + (1| Programme:clinicD) + (1| Programme:clinicE) , 
                  data = dat,
                  link = "logit",
                  threshold = "equidistant") 

Many thanks,
Bernard

-----Original Message-----
From: thierry.onkelinx at inbo.be <thierry.onkelinx at inbo.be> 
Sent: 26 June 2018 09:38
To: Bernard Liew (School of Sport Exercise and Rehabilitation Sciences) <B.Liew at bham.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question on hierarchical nature and data format using lmer

Dear Bernard,

The typical format is one row of data per observation. If you have one measurement per student, then you need to have a column per clinical placement (with a TRUE or FALSE value).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-06-25 17:09 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
> Dear Community,
>
> Thank you first for the help. My question pertains to a research design as follow:
>
> 200 students in total from 4 schools, undergoing different clinical placements in a semester. There are 5 different plausible clinical placements. This means some students have zero placements, others can have a maximum of three, with any placement combinations. Two out of three clinical placements are restricted to some schools. So some clinical placements are nested within schools, others are crossed across schools.
>
> The response variable is an ordinal measure Likert scale of "sharing". The predictors are school and placement.
>
> Qn to be answered: Does different school and clinical placement alter a student's degree of sharing?
>
> Problem 1: data format
>
> The traditional way to format the data is the long "tidy" method. However, because placements are not unique to an individual, how best should one format the data?
>
> Solution 1 ( I think): make the placement variable into a wide format, so instead of one placement predictor, I now have five different placement predictors. This then appears to change the research question? Is there another solution?
>
> Kind regards,
> Bernard
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From B@Liew @ending from bh@m@@c@uk  Wed Jun 27 17:45:57 2018
From: B@Liew @ending from bh@m@@c@uk (Bernard Liew)
Date: Wed, 27 Jun 2018 15:45:57 +0000
Subject: [R-sig-ME] 
 Question on hierarchical nature and data format using lmer
In-Reply-To: <CAJuCY5wv6To4nSiZ6jB+uQMQFPbQgPxbrXGo3zA3-kFwHeWtJg@mail.gmail.com>
References: <A901AC7187F75B41BF677B0A610C0976E8E5F9@EX11.adf.bham.ac.uk>
 <CAJuCY5xLVrB82OLxMtce_yT9mxy5LZjArF03KaEUYo0EWvL36g@mail.gmail.com>
 <A901AC7187F75B41BF677B0A610C0976E8E9C8@EX11.adf.bham.ac.uk>
 <CAJuCY5wv6To4nSiZ6jB+uQMQFPbQgPxbrXGo3zA3-kFwHeWtJg@mail.gmail.com>
Message-ID: <A901AC7187F75B41BF677B0A610C0976E8EA1C@EX11.adf.bham.ac.uk>

Great Thierry!

I am really exposing my ignorance, but I am also learning a lot. I design matrix shows up well. The research question is simple: Does study programme and different clinical placements predict a student's degree of sharing (ordinal).

Programme	A	B	C	D	E
Medicine	N	N	N	Y	Y
Medicine	N	N	N	Y	Y
Medicine	N	N	N	Y	Y
Nurse		Y	Y	N	Y	Y
Nurse		Y	Y	N	Y	Y
Nurse		Y	Y	N	Y	Y
Physio		Y	Y	Y	Y	Y
Physio		Y	Y	Y	Y	Y
Physio		Y	Y	Y	Y	Y
Speech		Y	Y	Y	Y	Y
Speech		Y	Y	Y	Y	Y
Speech		Y	Y	Y	Y	Y


Kind regards,
Bernard
-----Original Message-----
From: thierry.onkelinx at inbo.be <thierry.onkelinx at inbo.be> 
Sent: 27 June 2018 16:14
To: Bernard Liew (School of Sport Exercise and Rehabilitation Sciences) <B.Liew at bham.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question on hierarchical nature and data format using lmer

Dear Bernard,

Using a factor both in the fixed effects and the random effects is nonsense. I wrote a blog post on that topic:
https://www.muscardinus.be/2017/08/fixed-and-random/

Do all programs have multiple clinics? If programme "physio" has only clinic "A" and clinic "A" is only used in programme "physio" then it is impossible to distinguish between the effect of the programme and the effect of the clinic. Can you illustrate your design as a simple table (e.g. programme as column and clinic as row)? Note that any HTML formatting will be removed, so you plain text formatting only.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-06-27 16:56 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
> Thanks Thierry,
>
> I thought so. So this leads on to the next question of how to then 
> specify the random effects structure. Given predictors of study 
> programme (4 levels: physio, med, nurse, speed), clinicA (yes/no), 
> clinicB(yes/no), clinicC(yes/no), clinicD(yes/no), clinicE(yes/no), 
> and s clinic A,B,C are nested in study programme [ie. Some clinics are 
> only offered in some programme), and D,E are crossed across programme 
> (common to all programmes)
>
> Is the following logical? I am using the ordinal package, but the formula follows that of lmer.
>
> clmm (as.factor (Sharing) ~ Programme + clinicA + clinicB + clinicC+ clinicD+ clinicE +
>                   (1| Programme) + (1| Programme:clinicA) + (1| Programme:clinicB) + (1| Programme:clinicC) +
>             (1| clinicD)  + (1| clinicE) + (1| Programme:clinicD) + (1| Programme:clinicE) ,
>                   data = dat,
>                   link = "logit",
>                   threshold = "equidistant")
>
> Many thanks,
> Bernard
>
> -----Original Message-----
> From: thierry.onkelinx at inbo.be <thierry.onkelinx at inbo.be>
> Sent: 26 June 2018 09:38
> To: Bernard Liew (School of Sport Exercise and Rehabilitation 
> Sciences) <B.Liew at bham.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Question on hierarchical nature and data 
> format using lmer
>
> Dear Bernard,
>
> The typical format is one row of data per observation. If you have one measurement per student, then you need to have a column per clinical placement (with a TRUE or FALSE value).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN 
> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie 
> & Kwaliteitszorg / Team Biometrics & Quality Assurance 
> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> //////////////////////////////////////////////////////////////////////
> ///////////////////// To call in the statistician after the experiment 
> is done may be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of. ~ Sir 
> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger 
> Brinner The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be extracted from 
> a given body of data. ~ John Tukey 
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
>
>
> 2018-06-25 17:09 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
>> Dear Community,
>>
>> Thank you first for the help. My question pertains to a research design as follow:
>>
>> 200 students in total from 4 schools, undergoing different clinical placements in a semester. There are 5 different plausible clinical placements. This means some students have zero placements, others can have a maximum of three, with any placement combinations. Two out of three clinical placements are restricted to some schools. So some clinical placements are nested within schools, others are crossed across schools.
>>
>> The response variable is an ordinal measure Likert scale of "sharing". The predictors are school and placement.
>>
>> Qn to be answered: Does different school and clinical placement alter a student's degree of sharing?
>>
>> Problem 1: data format
>>
>> The traditional way to format the data is the long "tidy" method. However, because placements are not unique to an individual, how best should one format the data?
>>
>> Solution 1 ( I think): make the placement variable into a wide format, so instead of one placement predictor, I now have five different placement predictors. This then appears to change the research question? Is there another solution?
>>
>> Kind regards,
>> Bernard
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From thierry@onkelinx @ending from inbo@be  Thu Jun 28 11:04:28 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Thu, 28 Jun 2018 11:04:28 +0200
Subject: [R-sig-ME] 
 Question on hierarchical nature and data format using lmer
In-Reply-To: <A901AC7187F75B41BF677B0A610C0976E8EA1C@EX11.adf.bham.ac.uk>
References: <A901AC7187F75B41BF677B0A610C0976E8E5F9@EX11.adf.bham.ac.uk>
 <CAJuCY5xLVrB82OLxMtce_yT9mxy5LZjArF03KaEUYo0EWvL36g@mail.gmail.com>
 <A901AC7187F75B41BF677B0A610C0976E8E9C8@EX11.adf.bham.ac.uk>
 <CAJuCY5wv6To4nSiZ6jB+uQMQFPbQgPxbrXGo3zA3-kFwHeWtJg@mail.gmail.com>
 <A901AC7187F75B41BF677B0A610C0976E8EA1C@EX11.adf.bham.ac.uk>
Message-ID: <CAJuCY5wEEOEVwUGdtoiAv=Lr_EFDs3m1QQQSmLraXTDNtYj2og@mail.gmail.com>

Dear Bernard,

It seems like you need no random effects at all. Something like
clm(Sharing ~ Programma/Clinic) could do.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-06-27 17:45 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
> Great Thierry!
>
> I am really exposing my ignorance, but I am also learning a lot. I design matrix shows up well. The research question is simple: Does study programme and different clinical placements predict a student's degree of sharing (ordinal).
>
> Programme       A       B       C       D       E
> Medicine        N       N       N       Y       Y
> Medicine        N       N       N       Y       Y
> Medicine        N       N       N       Y       Y
> Nurse           Y       Y       N       Y       Y
> Nurse           Y       Y       N       Y       Y
> Nurse           Y       Y       N       Y       Y
> Physio          Y       Y       Y       Y       Y
> Physio          Y       Y       Y       Y       Y
> Physio          Y       Y       Y       Y       Y
> Speech          Y       Y       Y       Y       Y
> Speech          Y       Y       Y       Y       Y
> Speech          Y       Y       Y       Y       Y
>
>
> Kind regards,
> Bernard
> -----Original Message-----
> From: thierry.onkelinx at inbo.be <thierry.onkelinx at inbo.be>
> Sent: 27 June 2018 16:14
> To: Bernard Liew (School of Sport Exercise and Rehabilitation Sciences) <B.Liew at bham.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Question on hierarchical nature and data format using lmer
>
> Dear Bernard,
>
> Using a factor both in the fixed effects and the random effects is nonsense. I wrote a blog post on that topic:
> https://www.muscardinus.be/2017/08/fixed-and-random/
>
> Do all programs have multiple clinics? If programme "physio" has only clinic "A" and clinic "A" is only used in programme "physio" then it is impossible to distinguish between the effect of the programme and the effect of the clinic. Can you illustrate your design as a simple table (e.g. programme as column and clinic as row)? Note that any HTML formatting will be removed, so you plain text formatting only.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-06-27 16:56 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
>> Thanks Thierry,
>>
>> I thought so. So this leads on to the next question of how to then
>> specify the random effects structure. Given predictors of study
>> programme (4 levels: physio, med, nurse, speed), clinicA (yes/no),
>> clinicB(yes/no), clinicC(yes/no), clinicD(yes/no), clinicE(yes/no),
>> and s clinic A,B,C are nested in study programme [ie. Some clinics are
>> only offered in some programme), and D,E are crossed across programme
>> (common to all programmes)
>>
>> Is the following logical? I am using the ordinal package, but the formula follows that of lmer.
>>
>> clmm (as.factor (Sharing) ~ Programme + clinicA + clinicB + clinicC+ clinicD+ clinicE +
>>                   (1| Programme) + (1| Programme:clinicA) + (1| Programme:clinicB) + (1| Programme:clinicC) +
>>             (1| clinicD)  + (1| clinicE) + (1| Programme:clinicD) + (1| Programme:clinicE) ,
>>                   data = dat,
>>                   link = "logit",
>>                   threshold = "equidistant")
>>
>> Many thanks,
>> Bernard
>>
>> -----Original Message-----
>> From: thierry.onkelinx at inbo.be <thierry.onkelinx at inbo.be>
>> Sent: 26 June 2018 09:38
>> To: Bernard Liew (School of Sport Exercise and Rehabilitation
>> Sciences) <B.Liew at bham.ac.uk>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Question on hierarchical nature and data
>> format using lmer
>>
>> Dear Bernard,
>>
>> The typical format is one row of data per observation. If you have one measurement per student, then you need to have a column per clinical placement (with a TRUE or FALSE value).
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
>> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
>> & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>>
>> //////////////////////////////////////////////////////////////////////
>> ///////////////////// To call in the statistician after the experiment
>> is done may be no more than asking him to perform a post-mortem
>> examination: he may be able to say what the experiment died of. ~ Sir
>> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
>> Brinner The combination of some data and an aching desire for an
>> answer does not ensure that a reasonable answer can be extracted from
>> a given body of data. ~ John Tukey
>> //////////////////////////////////////////////////////////////////////
>> /////////////////////
>>
>>
>>
>>
>> 2018-06-25 17:09 GMT+02:00 Bernard Liew <B.Liew at bham.ac.uk>:
>>> Dear Community,
>>>
>>> Thank you first for the help. My question pertains to a research design as follow:
>>>
>>> 200 students in total from 4 schools, undergoing different clinical placements in a semester. There are 5 different plausible clinical placements. This means some students have zero placements, others can have a maximum of three, with any placement combinations. Two out of three clinical placements are restricted to some schools. So some clinical placements are nested within schools, others are crossed across schools.
>>>
>>> The response variable is an ordinal measure Likert scale of "sharing". The predictors are school and placement.
>>>
>>> Qn to be answered: Does different school and clinical placement alter a student's degree of sharing?
>>>
>>> Problem 1: data format
>>>
>>> The traditional way to format the data is the long "tidy" method. However, because placements are not unique to an individual, how best should one format the data?
>>>
>>> Solution 1 ( I think): make the placement variable into a wide format, so instead of one placement predictor, I now have five different placement predictors. This then appears to change the research question? Is there another solution?
>>>
>>> Kind regards,
>>> Bernard
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From je@n@@udu@@e@u @ending from y@hoo@fr  Thu Jun 28 09:13:25 2018
From: je@n@@udu@@e@u @ending from y@hoo@fr (audusseau jean)
Date: Thu, 28 Jun 2018 07:13:25 +0000 (UTC)
Subject: [R-sig-ME] r crossed nested random effects lme4
References: <1783378010.5284494.1530170005475.ref@mail.yahoo.com>
Message-ID: <1783378010.5284494.1530170005475@mail.yahoo.com>

Dear all,I try to find the appropriate model for the following data set with lme4:
Each individual subject goes through 3 conditions ("Group", within-subject factor). These 3 conditions include 9 items (3 items in each condition, but the items differ in each condition). Score (4th column not represented above) is a continuous dependant variable (reaction time).I am interested in the fixed effect of the "Cond" variable and also would like to take into account the dependencies between my factors, but I have difficulties to know if my factors should be considered as nested or crossed.Does the following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any help would be much appreciated.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1530169904311blob.jpg
Type: image/png
Size: 13883 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180628/f4eb6e27/attachment.png>

From @rued@ @ending from ced@u@b@e@  Thu Jun 28 15:45:10 2018
From: @rued@ @ending from ced@u@b@e@ (=?UTF-8?Q?Sarah=C3=AD_Rueda_Salazar?=)
Date: Thu, 28 Jun 2018 15:45:10 +0200
Subject: [R-sig-ME] Fixed Effect and survival analysis (coxme package)
Message-ID: <CAHRw6-98eS0O3rX5TbEy8Ocg3xM+fy2zfjJEKCN6EGs_B=Q2Aw@mail.gmail.com>

Dear R users,


My question is related to the recently updated version of coxme package (
mixed effect in survival analysis).  Currently, I work with multistate
models with changes in health status on elder population.  I use coxPH by
stratifying the hazard by different transition type ( deterioration, health
improvements, death from healthy status and death from not healthy status).

So, I wondered if I can apply mixed effect on my multistate model to see
the differences by countries (shared frailty).  I?ve read the coxme?s
document post on May 11, 2018 and others several materials in this subject
:Steele et al:2004, Austin : 2017,Putter: 2014, Willekens: 2014,
Brost?n:2011, Mills, 2011 and finally Allison (which provide me a quite
understandable approach in the line of my humble knowledge in mathematical
demography) .

I thought it is not possible to use to multilevel in
multistate with coxme package so, I?ve done a model for each transition
type by separate . It means one model by transition type. If I stratify the
hazard  (reference risk by interested covariates )  by my four transitions
type, I make hazard be free(no proportional by transition type) and it
means that the model estimates separately baseline hazard for the different
values of transition type ( following this material by Putter( 2018:7
<https://cran.r-project.org/web/packages/mstate/vignettes/Tutorial.pdf>)

e.g: It is a simple model using sex , reference category "male" with my
data:

> modelSex.0 <- coxph(Surv(Tstarta,Tstopa,status) ~
+                        SexF.1+ SexF.2+SexF.3+SexF.4+
+                       strata(trans),
+                     data=d0)

SexF.1= related to covariate sex  in transition 1(healthy to not healthy)
SexF.2 = transition healthy to death
SexF.3= transition  Not healthy to Healthy
SexF.4= transition  Not healthy to Death

But, I came across  this post
<https://stat.ethz.ch/pipermail/r-help/2014-September/421690.html>  where
Therneau replied a request ( I copy a chunk that I?m interested in):

2. The model above is the correct covariance structure for a set of
> families. There is a
> single intercept per subject, with a complex correlation matrix. The
> simpler "per family"
> frailty model would be



> model4 <- coxme(Surv(Survival, Event) ~ Sex + strata(cohort) + SNP1 + SNP2
> + SNP3 +
> (1|famid), death.dat)



> This model lets each family have a separate risk, with everyone in the
> same family sharing
> the exact same risk. It is less general than model3 above which lets a
> family have higher
> risk plus has variation between family members. A model with both
> per-subject and per family terms is identical to one with a covariance
> matrix of s1 K + s2 B, where K is the kinship matrix, B is a block
> diagonal matrix which
> has a solid block of "1" for each family, and s1 s2 are the fitted
> variance coefficients.


 taking the example to my data,  strata would be my transition type (trans)
instead "cohort"  and my groups (instead famid) would be country, as follows


> modelSex.1 <- coxme(Surv(Tstarta,Tstopa,status) ~
+                        SexF.1+ SexF.2+SexF.3+SexF.4+
+                       (1|Country),
+                     data=d0)

> anova(modelSex.0,modelSex.1)

Analysis of Deviance Table
 Cox model: response is  Surv(Tstarta, Tstopa, status)
 Model 1: ~ SexF.1+ SexF.2+SexF.3+SexF.4+ strata(trans)
 Model 2: ~ SexF.1+ SexF.2+SexF.3+SexF.4+ strata(trans) + (1 | Country)
    loglik  Chisq Df P(>|Chi|)
1 -1342082
2 -1339605 4953.8  1 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> stem(exp(ranef(modelSex.1)[[1]]))

  The decimal point is 1 digit(s) to the left of the |

   6 | 589
   8 | 1448477
  10 | 115669
  12 | 0846

> exp(ranef(modelSex.1)[[1]])
       AT        BE        BG        CY        CZ        EE
1.1981346 0.9712875 0.8092424 1.3614033 0.8382588 1.0117071
       EL        ES        HU        IE        IT        LT
0.7514988 1.2761863 1.0085404 0.8760514 1.1615717 0.9708070
       LU        LV        MT        PL        PT        RO
1.1893096 1.3381012 1.0522161 0.7843473 1.1642434 0.7911292
       SK        UK
0.9440166 0.8428222

> fixed.effects(modelSex.1)
     SexF.1      SexF.2      SexF.3      SexF.4
 0.16349517 -0.63184370 -0.08578787 -0.61023260


The thing is that I?m not sure on how to interpret the frailty values by
countries (random effect described by the variance within groups)  because
I have four different effects (each related with my transition types). I
know that by using strata for my transition type is the same as I applied 4
different cox model (related for each type of transition). If I
apply separated model  I would obtain frailty random effect by groups
(countries) regarding specific transition but, doing this model with the
strata  ( modelSex.1 ) with my 4 transition type at once, I do not know
what those frailty values are telling me about the four different type of
hazard.

For other side, I have other question related to the recent article of
Mixed Effect (May, 2018) . Might be, it is a very very silly question but I
need to understand it .
In pag 9, second parraph , Therneau describes the simple cox model and it
is described the standard deviation (excess of risk for each group)  . So,
there is an argument  that states"... 15% of the families to be 1 std dev
or more above the mean..."  Im working with that data and code but I
couldnt find where you got the value of 15%.


I hope somebody can help me,
Many thanks in advance,
Best wishes

 Sarah?














*Centre d'Estudis Demogr?ficsCarrer de Ca n'Altay?, Edifici E2Universitat
Aut?noma de Barcelona,08193
Bellaterra, Barcelona/SPAINPhone: 34/93.581.30.60
<34%2F93.581.30.60>Fax: 34/93.581.30.61
<34%2F93.581.30.61>e-mail: srueda at ced.uab.es
<ssancho at ced.uab.es>http://www.ced.uab.es <http://www.ced.uab.es/>*



-- 
*Sarah? Rueda Salazar*
*Investigadora en Formaci?n (FPI/CED)*












*Centre d'Estudis Demogr?ficsCarrer de Ca n'Altay?, Edifici E2Universitat
Aut?noma de Barcelona,08193
Bellaterra, Barcelona/SPAINPhone: 34/93.581.30.60
<34%2F93.581.30.60>Fax: 34/93.581.30.61
<34%2F93.581.30.61>e-mail: srueda at ced.uab.es
<ssancho at ced.uab.es>http://www.ced.uab.es <http://www.ced.uab.es/>*

From Phillip@Ald@y @ending from mpi@nl  Thu Jun 28 21:59:54 2018
From: Phillip@Ald@y @ending from mpi@nl (Alday, Phillip)
Date: Thu, 28 Jun 2018 19:59:54 +0000
Subject: [R-sig-ME] r crossed nested random effects lme4
In-Reply-To: <1783378010.5284494.1530170005475@mail.yahoo.com>
References: <1783378010.5284494.1530170005475.ref@mail.yahoo.com>
 <1783378010.5284494.1530170005475@mail.yahoo.com>
Message-ID: <a2cc54bb-9920-87bc-10ff-e5249ca03af0@mpi.nl>

lme4 doesn't force a hard nested-crossed distinction and can handle implicit nesting/crossing easily (assuming unique identifiers, which you have), so you don't have to worry about that.

The only "problem" I see with your model is that it is an "intercept-only" model. Given that there are only three items per condition, this makes sense for the by-item random effect. But you should consider whether the by-subject random effect should have a slope for condition. This is all assuming that you only sent us a screenshot of the top of the dataset and that you have more than three subjects ...

There are some more general issues about whether you should transform reaction time, but a quick search will yield lots of papers discussing the pros and cons of that.

Finally, please be kind to the list and be consistent in your names -- you swap back and forth between Group and Cond in your description.

Phillip

On 28/06/18 09:13, audusseau jean via R-sig-mixed-models wrote:

Dear all,I try to find the appropriate model for the following data set with lme4:
Each individual subject goes through 3 conditions ("Group", within-subject factor). These 3 conditions include 9 items (3 items in each condition, but the items differ in each condition). Score (4th column not represented above) is a continuous dependant variable (reaction time).I am interested in the fixed effect of the "Cond" variable and also would like to take into account the dependencies between my factors, but I have difficulties to know if my factors should be considered as nested or crossed.Does the following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any help would be much appreciated.





_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Fri Jun 29 15:27:37 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Fri, 29 Jun 2018 15:27:37 +0200
Subject: [R-sig-ME] r crossed nested random effects lme4
In-Reply-To: <283160916.171893.1530260707068@mail.yahoo.com>
References: <1783378010.5284494.1530170005475.ref@mail.yahoo.com>
 <1783378010.5284494.1530170005475@mail.yahoo.com>
 <a2cc54bb-9920-87bc-10ff-e5249ca03af0@mpi.nl>
 <283160916.171893.1530260707068@mail.yahoo.com>
Message-ID: <db556ef6-f7fc-2e39-0d0c-a78531c9650f@mpi.nl>

Yes, use that model. Since Items are nested within conditions, it
doesn't make sense to have an by-item slope for condition.

Phillip

On 06/29/2018 10:25 AM, audusseau jean wrote:
> Phillip,
> 
> Many thanks for your answer. I apologize for such an unclear description
> of my experiment. I wanted to make it simpler but it seems I produced
> the opposite.
> 
> In fact, my experiment consists of :
> 
> - _71_ subjects
> 
> - going through 3 conditions (so "condition" and "subject" are crossed)
> 
> - each condition comprises _30_ items (so items are nested in conditions)
> 
> Concerning the dependant variable, I use 1/RT.
> 
> As I understand your comments, I should acknowledge that the condition
> effect may vary for different subjects. So I thought a better model may be:
> 
> 1/RT~1+condition+(condition|subject) +(1| item)
> 
> Given that I have 30 items in each condition, would you advice to modify
> the last term of this syntax ?
> 
> Thank you for your time.
> 
> 
> 
> Le jeudi 28 juin 2018 ? 21:59:56 UTC+2, Alday, Phillip
> <Phillip.Alday at mpi.nl> a ?crit :
> 
> 
> lme4 doesn't force a hard nested-crossed distinction and can handle
> implicit nesting/crossing easily (assuming unique identifiers, which you
> have), so you don't have to worry about that.
> 
> The only "problem" I see with your model is that it is an
> "intercept-only" model. Given that there are only three items per
> condition, this makes sense for the by-item random effect. But you
> should consider whether the by-subject random effect should have a slope
> for condition. This is all assuming that you only sent us a screenshot
> of the top of the dataset and that you have more than three subjects ...
> 
> There are some more general issues about whether you should transform
> reaction time, but a quick search will yield lots of papers discussing
> the pros and cons of that.
> 
> Finally, please be kind to the list and be consistent in your names --
> you swap back and forth between Group and Cond in your description.
> 
> Phillip
> 
> 
> On 28/06/18 09:13, audusseau jean via R-sig-mixed-models wrote:
>> Dear all,I try to find the appropriate model for the following data set with lme4:
>> Each individual subject goes through 3 conditions ("Group", within-subject factor). These 3 conditions include 9 items (3 items in each condition, but the items differ in each condition). Score (4th column not represented above) is a continuous dependant variable (reaction time).I am interested in the fixed effect of the "Cond" variable and also would like to take into account the dependencies between my factors, but I have difficulties to know if my factors should be considered as nested or crossed.Does the following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any help would be much appreciated.
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From je@n@@udu@@e@u @ending from y@hoo@fr  Fri Jun 29 10:25:07 2018
From: je@n@@udu@@e@u @ending from y@hoo@fr (audusseau jean)
Date: Fri, 29 Jun 2018 08:25:07 +0000 (UTC)
Subject: [R-sig-ME] r crossed nested random effects lme4
In-Reply-To: <a2cc54bb-9920-87bc-10ff-e5249ca03af0@mpi.nl>
References: <1783378010.5284494.1530170005475.ref@mail.yahoo.com>
 <1783378010.5284494.1530170005475@mail.yahoo.com>
 <a2cc54bb-9920-87bc-10ff-e5249ca03af0@mpi.nl>
Message-ID: <283160916.171893.1530260707068@mail.yahoo.com>

 
Phillip,

Many thanks for your answer. I apologize for such an unclear description ofmy experiment. I wanted to make it simpler but it seems I produced theopposite.

In fact, my experiment consists of :

- 71 subjects

- going through 3 conditions (so "condition" and"subject" are crossed)

- each condition comprises 30 items (so items are nested inconditions)

Concerning the dependant variable, I use 1/RT.

As I understand your comments, I should acknowledge that the condition effectmay vary for different subjects. So I thought a better model may be:

1/RT~1+condition+(condition|subject)+(1| item)

Given that I have 30 items in each condition, would you advice to modifythe last term of this syntax??

Thank you for your time.


    Le jeudi 28 juin 2018 ? 21:59:56 UTC+2, Alday, Phillip <Phillip.Alday at mpi.nl> a ?crit :  
 
 
lme4 doesn't force a hard nested-crossed distinction and can handle implicit nesting/crossing easily (assuming unique identifiers, which you have), so you don't have to worry about that.


The only "problem" I see with your model is that it is an "intercept-only" model. Given that there are only three items per condition, this makes sense for the by-item random effect. But you should consider whether the by-subject random effect should have a slope for condition. This is all assuming that you only sent us a screenshot of the top of the dataset and that you have more than three subjects ...

There are some more general issues about whether you should transform reaction time, but a quick search will yield lots of papers discussing the pros and cons of that.

Finally, please be kind to the list and be consistent in your names -- you swap back and forth between Group and Cond in your description.


Phillip


On 28/06/18 09:13, audusseau jean via R-sig-mixed-models wrote:

Dear all,I try to find the appropriate model for the following data set with lme4:
Each individual subject goes through 3 conditions ("Group", within-subject factor). These 3 conditions include 9 items (3 items in each condition, but the items differ in each condition). Score (4th column not represented above) is a continuous dependant variable (reaction time).I am interested in the fixed effect of the "Cond" variable and also would like to take into account the dependencies between my factors, but I have difficulties to know if my factors should be considered as nested or crossed.Does the following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any help would be much appreciated.


 
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

  
	[[alternative HTML version deleted]]


