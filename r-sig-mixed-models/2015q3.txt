From chirleu at gmail.com  Wed Jul  1 11:27:01 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Wed, 1 Jul 2015 11:27:01 +0200
Subject: [R-sig-ME] getting matrix-covariance matrices from a multivariate
	lme
Message-ID: <CALC46t9zRkXNMypzOXKuPpSeoxAGg-1bWfM=Ca8qATkWFC6N6w@mail.gmail.com>

Dear list,
I'm running a multivariate mixed model in lme. So far, I'm modeling only
two response variables (dataset in long format), but the questions below
applies as well to models with more response variables. I have been reading
some documents produced by Ben Bolker available online (e.g. this
<http://rstudio-pubs-static.s3.amazonaws.com/3336_03636030d93d47de9131e625b72f58c6.html>)
but still I have some doubts.

This is my model. I hope it is correctly specified: there is a single fixed
effect ("month", continuous variable), different variances between traits
and a correlation term to account for the temporal correlation of the
replicates. "tim" is a timer variable, "id" is individual identity and
"trait" is a factor variable with two levels in this simple case (the two
response traits).

lme21=lme(value~trait*poly(month,3)-1,data=long21,random=~trait-1|id,weights=varIdent(form=~1|trait),correlation=corAR1(form=~tim|id/trait))

The summary:
Linear mixed-effects model fit by REML
 Data: long21
       AIC      BIC   logLik
  12364.22 12453.96 -6168.11

Random effects:
 Formula: ~trait - 1 | id
 Structure: General positive-definite, Log-Cholesky parametrization
         StdDev    Corr
traitdvm 1.6190039 trtdvm
traitsdl 0.1730272 0.702
Residual 3.2393785

Correlation Structure: ARMA(1,0)
 Formula: ~tim | id/trait
 Parameter estimate(s):
     Phi1
0.5775275
Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | trait
 Parameter estimates:
      dvm       sdl
1.0000000 0.1166486
Fixed effects: value ~ trait * poly(month, 3) - 1
                             Value Std.Error   DF   t-value p-value
traitdvm                   2.85966  0.154334 4217 18.529065  0.0000
traitsdl                   0.03629  0.017347 4217  2.092108  0.0365
poly(month, 3)1           41.34481  5.323865 4217  7.765939  0.0000
poly(month, 3)2          -14.49704  6.118856 4217 -2.369241  0.0179
poly(month, 3)3          -30.73276  4.157736 4217 -7.391707  0.0000
traitsdl:poly(month, 3)1 -44.68770  5.355425 4217 -8.344380  0.0000
traitsdl:poly(month, 3)2  13.13565  6.149759 4217  2.135962  0.0327
traitsdl:poly(month, 3)3  33.08326  4.183701 4217  7.907655  0.0000
 Correlation:
                         trtdvm trtsdl p(,3)1 p(,3)2 p(,3)3 t:(,3)1 t:(,3)2
traitsdl                  0.297
poly(month, 3)1           0.025 -0.001
poly(month, 3)2           0.063  0.017 -0.006
poly(month, 3)3          -0.037  0.001 -0.462  0.051
traitsdl:poly(month, 3)1 -0.025  0.004 -0.993  0.006  0.459
traitsdl:poly(month, 3)2 -0.060 -0.010  0.006 -0.993 -0.050 -0.006
traitsdl:poly(month, 3)3  0.037 -0.006  0.459 -0.050 -0.993 -0.462   0.051

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-7.48299422 -0.52498105 -0.03120914  0.53723986  5.96432196

Number of Observations: 4498
Number of Groups: 274

And these are my questions:
1- How can I get the random and residual variance-covariance matrices? Can
they be extracted using VarCorr somehow? This is part of the output in
MCMCglmm but in lme I haven't found the way to do it in lme so far...
2- How can I test the significance of the random covariances, i.e, if it is
statistically different from zero? I guess a solution would be to fit a
model with a constrained covariance (fixed to zero) and then compare
models, but how would this be specified in the model?

Thanks!!

David

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Fri Jul  3 09:54:04 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Fri, 3 Jul 2015 09:54:04 +0200
Subject: [R-sig-ME] interpretation of lme after convergence warning
Message-ID: <CALC46t9gFqtZFaWKO7f9eaHmc5bNq1TPqEAfSK9NdRPaH4o8SA@mail.gmail.com>

Dear list,

I?m running some lme models, and some of them do not converge:



Error in lme.formula(value ~ trait * poly(month, 3) - 1, data = long41,  :

  nlminb problem, convergence error code = 1

  message = iteration limit reached without convergence (10)



By using the ?control? argument (control=lmeCtlList) where?

lmeCtlList=lmeControl(maxIter=2,msMaxIter=3, tolerance=1e-4,
niter=4,msTol=1e-5, nlmStepMax=5,msVerbose=TRUE ,returnObject=TRUE)



?I?m able to tun the model until a warning is obtained.:



> lme41=lme(value~trait*poly(month,3)-1,data=long41,random=~trait-1|id,weights=varIdent(form=~1|trait),correlation=corAR1(form=~tim|id/trait),control=lmeCtlList)

  0:     32018.004: 0.372405 0.0422295 0.899729  1.28724 0.0267174
0.0599544  2.46838 -0.256311  2.12184 -2.41635  0.00000  0.00000
0.00000  0.00000

  1:     29219.716: 0.373150 0.0430342 0.903878  1.29395 0.0266993
0.0599082  2.47015 -0.256428  2.12293 -2.41762 0.303089 0.793629
-0.323934 -0.416277

  2:     28671.324: 0.293462 0.0160438 0.841610  1.27912 0.0256651
0.0605562  2.47777 -0.257765  2.12967 -2.43187 0.914815 0.813828
-0.436943 -1.19160

  3:     28482.303: 0.298865 0.0294951 0.850191  1.29426 0.0236547
0.0611059  2.47682 -0.257961  2.13046 -2.43399 0.898115 0.650545
-0.538846 -0.935158

  3:     28482.303: 0.298865 0.0294951 0.850191  1.29426 0.0236547
0.0611059  2.47682 -0.257961  2.13046 -2.43399 0.898115 0.650545
-0.538846 -0.935158

Warning message:

In lme.formula(value ~ trait * poly(month, 3) - 1, data = long41,  :

  nlminb problem, convergence error code = 1

  message = iteration limit reached without convergence (10)



But even so, I can get some output of the model with summary(lme41)



My question is: is the output of the summary still valid or should I avoid
interpreting it?



Thank you very much.


David

	[[alternative HTML version deleted]]


From tcarpenter at spu.edu  Thu Jul  2 02:56:05 2015
From: tcarpenter at spu.edu (Carpenter, Tom)
Date: Thu, 2 Jul 2015 00:56:05 +0000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
Message-ID: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>

All,

I have a paper in which we are using a within-person model using multi-level modeling. I ran the models in lmer in R, although we had a substantial portion of people for whom at least one observation is still missing. My understanding is that the default is to drop that person entirely (e.g., na.action=na.omit) ?.is that correct? My understanding was that the HLM software (e.g., by SSI) and most other multi-level modeling programs can still run the models based on the remaining observations (e.g., you may have 4 out of 5 observations per person and still be able to run the model).

I would love to know if it is possible to do that in lmer or if some solution is present. For example, is it possible to use FIML in lmer? Advice for handling this situation would be appreciated, as I?m new to lmer!

Best,


Tom Carpenter, Ph.D.
Assistant Professor, Psychology
Seattle Pacific University
3307 3rd Ave W. Suite 107,
Seattle, WA, 98119
tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
Office: (206) 281-2916
Fax: (206) 281-2695













	[[alternative HTML version deleted]]


From catarinasilvcastro at gmail.com  Thu Jul  2 10:55:33 2015
From: catarinasilvcastro at gmail.com (Catarina Silva Castro)
Date: Thu, 2 Jul 2015 09:55:33 +0100
Subject: [R-sig-ME] counseling for multilevel models
Message-ID: <CALOrwjGP2LoJYARXaGKzALQz-ECgT9=m6YsfrW0bm1fGk_K_KQ@mail.gmail.com>

Hello!
My name is Catarina and study in the Faculty of Sciences of the
University of Oporto, Portugal.
Within the framework of my master's thesis, I am using a set of data
on work accidents in a chain of stores.
The chain store is divided into different directions of operations and
each is associated monthly records of the number of registered work
accidents.
After several reviews, I think the multilevel models are the most
suitable but when implementing in R the models, I don't know how to
assign variables to different levels. When i use the function lme of
the nlme library or lmer of the lme4 library, all covariables that
include in the model are assigned to level 1 and do not know how to
assign them to higher levels.
I needed help to advise me on which the most appropriate functions
and libraries, if them are not, and I would to know how to assign
variables to different levels and get the best results for my study.
Waiting for reply. Thanks, Catarina


From bates at stat.wisc.edu  Sat Jul  4 18:09:05 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 04 Jul 2015 16:09:05 +0000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
Message-ID: <CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>

I think we would need to know more about the structure of the data and the
models that you wish to fit to it before we could be of any assistance.

To be honest, your question doesn't make sense in the context of lmer.  The
data for lmer must be in the "long form".  That is, each observation
corresponds to a row in the data frame.  If one subject has 5 observations
there will be 5 rows for that subject.  If another has only two
observations there will be two rows.  To me you are describing unbalanced
data, not missing data.  In most cases it is more confusing than
illuminating to think of data in the "wide form", with one row for each
subject and multiple columns for the observations, when working with R.

There is no difficulty with working with unbalanced data in lmer.

On Sat, Jul 4, 2015 at 10:42 AM Carpenter, Tom <tcarpenter at spu.edu> wrote:

> All,
>
> I have a paper in which we are using a within-person model using
> multi-level modeling. I ran the models in lmer in R, although we had a
> substantial portion of people for whom at least one observation is still
> missing. My understanding is that the default is to drop that person
> entirely (e.g., na.action=na.omit) ?.is that correct? My understanding was
> that the HLM software (e.g., by SSI) and most other multi-level modeling
> programs can still run the models based on the remaining observations
> (e.g., you may have 4 out of 5 observations per person and still be able to
> run the model).
>
> I would love to know if it is possible to do that in lmer or if some
> solution is present. For example, is it possible to use FIML in lmer?
> Advice for handling this situation would be appreciated, as I?m new to lmer!
>
> Best,
>
>
> Tom Carpenter, Ph.D.
> Assistant Professor, Psychology
> Seattle Pacific University
> 3307 3rd Ave W. Suite 107,
> Seattle, WA, 98119
> tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
> Office: (206) 281-2916
> Fax: (206) 281-2695
>
>
>
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Sat Jul  4 18:18:01 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 04 Jul 2015 16:18:01 +0000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
Message-ID: <CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>

By the way, most of us don't know the acronym FIML.  I have a suspicion
that it is one of the many "maximum likelihood" estimators defined in the
multilevel modeling literature.  To a statistician these expressions are
nonsensical.  Once you define the probability model there is only one
possible definition of likelihood and hence only one criterion for the
maximum likelihood estimators to optimize.  Creating a different criterion
and saying that the optimizers of this criterion are the "<whatever>
maximum likelihood" estimators is false advertising.

Having said all this I will admit that the original sin, the "REML"
criterion, was committed by statisticians.  In retrospect I wish that we
had not incorporated that criterion into the nlme and lme4 packages but, at
the time we wrote them, our work would have been dismissed as wrong if our
answers did not agree with SAS PROC MIXED, etc.  So we opted for
bug-for-bug compatibility with existing software.

On Sat, Jul 4, 2015 at 11:09 AM Douglas Bates <bates at stat.wisc.edu> wrote:

> I think we would need to know more about the structure of the data and the
> models that you wish to fit to it before we could be of any assistance.
>
> To be honest, your question doesn't make sense in the context of lmer.
> The data for lmer must be in the "long form".  That is, each observation
> corresponds to a row in the data frame.  If one subject has 5 observations
> there will be 5 rows for that subject.  If another has only two
> observations there will be two rows.  To me you are describing unbalanced
> data, not missing data.  In most cases it is more confusing than
> illuminating to think of data in the "wide form", with one row for each
> subject and multiple columns for the observations, when working with R.
>
> There is no difficulty with working with unbalanced data in lmer.
>
> On Sat, Jul 4, 2015 at 10:42 AM Carpenter, Tom <tcarpenter at spu.edu> wrote:
>
>> All,
>>
>> I have a paper in which we are using a within-person model using
>> multi-level modeling. I ran the models in lmer in R, although we had a
>> substantial portion of people for whom at least one observation is still
>> missing. My understanding is that the default is to drop that person
>> entirely (e.g., na.action=na.omit) ?.is that correct? My understanding was
>> that the HLM software (e.g., by SSI) and most other multi-level modeling
>> programs can still run the models based on the remaining observations
>> (e.g., you may have 4 out of 5 observations per person and still be able to
>> run the model).
>>
>> I would love to know if it is possible to do that in lmer or if some
>> solution is present. For example, is it possible to use FIML in lmer?
>> Advice for handling this situation would be appreciated, as I?m new to lmer!
>>
>> Best,
>>
>>
>> Tom Carpenter, Ph.D.
>> Assistant Professor, Psychology
>> Seattle Pacific University
>> 3307 3rd Ave W. Suite 107,
>> Seattle, WA, 98119
>> tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
>> Office: (206) 281-2916
>> Fax: (206) 281-2695
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From Tom.Wenseleers at bio.kuleuven.be  Sat Jul  4 20:15:23 2015
From: Tom.Wenseleers at bio.kuleuven.be (Tom Wenseleers)
Date: Sat, 4 Jul 2015 18:15:23 +0000
Subject: [R-sig-ME] Specification of binomial mixed model with custom
 intercept
In-Reply-To: <558ADB54.3020304@glasgow.ac.uk>
References: <37EFC97028F3E44082ACC5CBEC00563011541B46@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W198183686B973039916732CBA00@phx.gbl>,
	<37EFC97028F3E44082ACC5CBEC00563011541BDC@ICTS-S-MBX13.luna.kuleuven.be>,
	<COL129-W53524BB832038F295D27FFCBA00@phx.gbl>
	<37EFC97028F3E44082ACC5CBEC00563011541C22@ICTS-S-MBX13.luna.kuleuven.be>
	<558ADA6E.1080909@glasgow.ac.uk>,<558ADB54.3020304@glasgow.ac.uk>
Message-ID: <37EFC97028F3E44082ACC5CBEC00563011545155@ICTS-S-MBX13.luna.kuleuven.be>

Hi Dale,
Many thanks for the pointer - yes, it turned out that this was indeed the right syntax, e.g. for a binomial GLM (analogous syntax for a binomial mixed model) :

data=data.frame(treatment=c("INF","CONTR","INF","CONTR","INF","CONTR","INF","CONTR"),day=c(4,4,8,8,12,12,16,16),infected=c(20,11,18,15,19,16,19,19),not_infected=c(0,9,2,5,1,4,1,1))
data$propinfected=data$infected/(data$infected+data$not_infected)
data$baseline=qlogis(c(0.01,0.99))[data$treatment] # to have starting vals near 0 or 1 for the two groups (CONTROL and experimentally INFected)
fit=glm(cbind(infected,not_infected)~ -1+treatment:log(day),offset=baseline,family=binomial,data=data)

(used log(day) here because that gave a better fit)

Basically, it's a binomial GLM to describe the evolution of the proportion of infected individuals as a function of time (day) in two groups, a CONTROL group, where the initial prop of infecteds is known to be near 0 at day=0, and an experimentally infected group INF, where the initial prop of infecteds is known to be near 1 at day=0.

Turned out the problem had more to do with getting the effects package to plot the model correctly.
Apparently the effects package only supports specifying one fixed intercept/offset - in my case I got around this by plotting the predictions for the two groups separately and each time suppressing the other group's output, and specifying the correct offset for each group : 

library(effects)

a=plot(effect(fit,term="treatment:log(day)",xlevels=list(day=seq(0.01, 17, 1)),offset=qlogis(0.01) ),ylim=c(-0.05,1.05),xlim=c(-1,17),multiline=T,xlab="Day",ylab="Proportion infected",ci.style="bands",rescale.axis=F,rug=F,lines=c(1,1),lwd=c(2,2),colors=c("black",rgb(1,1,1,0)))

b=plot(effect(fit,term="treatment:log(day)",xlevels=list(day=seq(0.01, 17, 1)),offset=qlogis(0.99) ),ylim=c(-0.05,1.05),xlim=c(-1,17),multiline=T,xlab="Day",ylab="Proportion infected",ci.style="bands",rescale.axis=F,rug=F,lines=c(1,1),lwd=c(2,2),colors=c(rgb(1,1,1,0),"red"))

library(latticeExtra)
c=xyplot(propinfected~day,data=data,pch=15,cex=2,col=data$treatment,ylim=c(0,1),xlim=c(-1,17))
a+as.layer(b)+as.layer(c)

Of course I could also use predict() directly, or work with the Effect() dataframes to plot the model, rather than apply this hack...

cheers,
Tom

________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Dale Barr [dale.barr at glasgow.ac.uk]
Sent: 24 June 2015 18:31
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Specification of binomial mixed model with custom intercept

[ ...and of course also including the offset(baseline) term in the
formula... ]

On 24/06/15 17:27, Dale Barr wrote:
> Hi Tom,
>
> You might want to try the original syntax again, but without estimation
> of the (known) intercept term, using the "-1" syntax:
>
> fit=glmer(cbind(infected,not_infected) ~ -1 + (1|colony) + treatment *
> time, family=binomial, data=data)
>
> -Dale
>
> On 23/06/15 22:23, Tom Wenseleers wrote:
>> Hi Jake,
>> Many thanks for your advice! And yes realised the model would never quite get to 0% or 100% - that's why I had been trying putting in an intercept, as in
>> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
>>
>> But just tried adding points for t=0 and that does indeed seem to give sensible results - so I'll go with that then - thanks for the advice!
>>
>> If anyone else on this list would know how to formally put in constraints like the ones I mentioned, please let me know though!
>>
>> cheers,
>> Tom
>>
>> ________________________________
>> From: Jake Westfall [jake987722 at hotmail.com]
>> Sent: 23 June 2015 23:01
>> To: Tom Wenseleers
>> Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>
>> I see. This does seem more sensible. One complication I should point out is that you will never get your model to predict exactly 100% or 0%, as these correspond to logits of infinity or -infinity, respectively. You could set them to something high like logit = +/- 10 (corresonding to p = .99995 or .00005), but the exact values you fix them to are arbitrary and will affect the other model estimates. So it's tricky. One sort of klugey solution could be to put the time=0 measurements in the dataset "as if" you had recorded them -- with the justification being that you are virtually certain what the measurements would have been had you technically taken them at time=0 -- and then run the unconstrained model. This would basically just be a not-completely-arbitrary way of deciding what non-infinite values to fix the time=0 predictions to.
>>
>>
>> Jake
>>
>>> From: Tom.Wenseleers at bio.kuleuven.be
>>> To: jake987722 at hotmail.com; r-sig-mixed-models at r-project.org
>>> Subject: RE: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>> Date: Tue, 23 Jun 2015 19:35:20 +0000
>>>
>>> Hi Jake,
>>> Well to clarify a bit - I have actual datapoints for time=4, 8, 12 and 16, but not for t=0 days.
>>> For t=0, however, I know that based on my treatments (injecting individuals with virus lysate or with buffer) the proportion of infected individuals was ca 0% for the CONTROL treatment and 100% for the INJECTED group.
>>> Problem is that if this a priori constraint is not taken into account and I fit my model and make an effect plot, the prediction is not exactly 0% for the CONTROL group or 100% for the INJECTED group, even though I know that it should. So my question is whether constraints such as these can be taken into account into either binomial GLMs or binomial mixed models, e.g. by specifying custom offsets/intercepts? (I also have other similar models where I would like to be able to specify that at time=0 the initial proportion is known a priori to be 0.5)
>>>
>>> In general my aim of specifying constraints such as these would be to obtain better fits that better/more parsimoniously reflect known facts about the actual experiments.
>>>
>>> cheers,
>>> Tom
>>>
>>> ________________________________________
>>> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Jake Westfall [jake987722 at hotmail.com]
>>> Sent: 23 June 2015 17:30
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>>
>>> Hi Tom,
>>>
>>> I'm not sure if this is a sensible thing to do. If your presumption about the proportion of infected insects in each group at time=0 is correct, then surely your data must already reflect this fact? In which case I don't see why you can't just estimate the unconstrained model that you wrote and let the model figure out for itself what p(infected) is at time=0. In short, I don't see the added value of the constraints you mention.
>>>
>>> With that said, it occurs to me that if you really do want to implement the two constraints that you mentioned, then really you are not estimating any fixed-effect parameters at time=0. So it seems you could just as well exclude the time=0 data and just model the treatment factor at time=1. >From those parameter estimates it would be easier to figure out what the time slopes are for each group, since they will just be the difference between the time=1 parameter estimates and whatever values you fixed the proportions at time=0 to. Hope this makes sense.
>>>
>>> Jake
>>>
>>>> From: Tom.Wenseleers at bio.kuleuven.be
>>>> To: r-sig-mixed-models at r-project.org
>>>> Date: Tue, 23 Jun 2015 15:02:47 +0000
>>>> Subject: [R-sig-ME] Specification of binomial mixed model with custom intercept
>>>>
>>>> Dear all,
>>>> I have a binomial mixed model
>>>> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time,family=binomial,data=data)
>>>> in which I am modelling the evolution of an infection in different social insect colonies across two treatment groups (INJECTED and CONTROL) as a function of time.
>>>> However, as my INJECTED group individuals should all be infected at time=0, whereas none of my CONTROL individuals should be infected at time=0, I would like to force the model to go approx through 1 at time t=0 for the INJECTED group and to go approx through 0 at time t=1 for the CONTROL group. What would be the correct way to specify such a model?
>>>> I tried with
>>>> data$baseline=qlogis(c(0.001,0.999))[data$treatment]
>>>> fit=glmer(cbind(infected,not_infected)~(1|colony)+treatment*time+offset(baseline),family=binomial,data=data)
>>>> but this doesn't seem to give sensible predictions.
>>>> Any thoughts on the correct syntax?
>>>>
>>>> cheers,
>>>> Tom Wenseleers
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>      [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Dale Barr
Institute of Neuroscience and Psychology
University of Glasgow
58 Hillhead Street
Glasgow G12 8QB

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From karl at huftis.org  Sat Jul  4 21:21:26 2015
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Sat, 04 Jul 2015 21:21:26 +0200
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
	<CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
Message-ID: <55983236.2050902@huftis.org>

Den 04. juli 2015 18:18, Douglas Bates skreiv:
> Having said all this I will admit that the original sin, the "REML"
> criterion, was committed by statisticians.  In retrospect I wish that we
> had not incorporated that criterion into the nlme and lme4 packages but, at
> the time we wrote them, our work would have been dismissed as wrong if our
> answers did not agree with SAS PROC MIXED, etc.  So we opted for
> bug-for-bug compatibility with existing software.

Hm. I find this statement surprising. I was under the impression REML is 
*preferred* to ML in many situations (e.g. in simple random intercept 
models with few observations for each random intercept), and that *ML 
estimation* may result in severe bias. Do you consider maximising the 
REML criterion as a bug?

-- 
Karl Ove Hufthammer


From Phillip.Alday at unisa.edu.au  Sun Jul  5 06:14:07 2015
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Sun, 5 Jul 2015 04:14:07 +0000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <55983236.2050902@huftis.org>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
	<CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
	<55983236.2050902@huftis.org>
Message-ID: <1436069647.23972.13.camel@loki>

On Sat, 2015-07-04 at 21:21 +0200, Karl Ove Hufthammer wrote:
> Den 04. juli 2015 18:18, Douglas Bates skreiv:
> > Having said all this I will admit that the original sin, the "REML"
> > criterion, was committed by statisticians.  In retrospect I wish that we
> > had not incorporated that criterion into the nlme and lme4 packages but, at
> > the time we wrote them, our work would have been dismissed as wrong if our
> > answers did not agree with SAS PROC MIXED, etc.  So we opted for
> > bug-for-bug compatibility with existing software.
> 
> Hm. I find this statement surprising. I was under the impression REML is 
> *preferred* to ML in many situations (e.g. in simple random intercept 
> models with few observations for each random intercept), and that *ML 
> estimation* may result in severe bias. Do you consider maximising the 
> REML criterion as a bug?
> 

This was my question as well. My understanding was that REML, like
Bessel's correction for the sample variance, was motivated by bias in
the maximum-likelihood estimator for small numbers of observations. The
corrected estimator is in both cases no longer the MLE, so that the ML
part is bit of a misnomer, but if you take "residualized" expansion of
RE instead of "restricted", then REML seems more like a function of ML
and not a "type" of ML.

IIRC, the default in MixedModels.jl is now ML -- have you changed your
opinion about the utility of REML? Is there some type of weird
paradoxical situation with REML like with Bessel's correction -- the
variance estimates are no longer biased, but the s.d. estimates are? 

Or is the original sin the use of the name REML when REML is no longer
*the* maximum likelihood?

Best,
Phillip Alday

From ljrhurley at gmail.com  Sun Jul  5 06:35:24 2015
From: ljrhurley at gmail.com (landon hurley)
Date: Sun, 5 Jul 2015 00:35:24 -0400
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <1436069647.23972.13.camel@loki>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
	<CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
	<55983236.2050902@huftis.org> <1436069647.23972.13.camel@loki>
Message-ID: <5598B40C.5090001@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 07/05/2015 12:14 AM, Phillip Alday wrote:
> On Sat, 2015-07-04 at 21:21 +0200, Karl Ove Hufthammer wrote:
>> Den 04. juli 2015 18:18, Douglas Bates skreiv:
>>> Having said all this I will admit that the original sin, the 
>>> "REML" criterion, was committed by statisticians.  In retrospect 
>>> I wish that we had not incorporated that criterion into the nlme 
>>> and lme4 packages but, at the time we wrote them, our work would 
>>> have been dismissed as wrong if our answers did not agree with 
>>> SAS PROC MIXED, etc.  So we opted for bug-for-bug compatibility 
>>> with existing software.
>> 
>> Hm. I find this statement surprising. I was under the impression 
>> REML is *preferred* to ML in many situations (e.g. in simple
>> random intercept models with few observations for each random
>> intercept), and that *ML estimation* may result in severe bias. Do
>> you consider maximising the REML criterion as a bug?
>> 
> 
> This was my question as well. My understanding was that REML, like 
> Bessel's correction for the sample variance, was motivated by bias in
> the maximum-likelihood estimator for small numbers of observations.
> The corrected estimator is in both cases no longer the MLE, so that
> the ML part is bit of a misnomer, but if you take "residualized"
> expansion of RE instead of "restricted", then REML seems more like a
> function of ML and not a "type" of ML.
> 
> IIRC, the default in MixedModels.jl is now ML -- have you changed 
> your opinion about the utility of REML? Is there some type of weird 
> paradoxical situation with REML like with Bessel's correction -- the
>  variance estimates are no longer biased, but the s.d. estimates
> are?
> 
> 
> Or is the original sin the use of the name REML when REML is no 
> longer *the* maximum likelihood?
> 

I had assumed that he would have responded by now, but it is a holiday
in the US. The position Bates is taking is explained (I think) in his
2010 report
lme4: Mixed effects modelling with R in Section 5.5 `The REML
Criterion', roughly page 123-124 in the pdf [0]. It's a short read, but
the most relevant bit I think is:

> The argument for preferring ?_R to ?_L as an estimate of ?**2 is
> that the numerator in both estimates is the sum of squared
> residuals at ? and, although the residual vector, yobs ? X? , is an
> n-dimensional vector, the residual at ? satisfies p linearly
> independent constraints, X**{T} (yobs ? X? ) = 0. That is, the residual
> at ? is the projection of the observed response vector, yobs , into
> an (n ? p)-dimensional linear subspace of the n-dimensional response
> space. The estimate ?R takes into account the fact that ?**2 is
> estimated from residuals that have only n ? p degrees of freedom.
> 
> Another argument often put forward for REML estimation is that ?_R is 
> an unbiased estimate of ?**2 , in the sense that the expected value of
> the estimator is equal to the value of the parameter. However, 
> determining the expected value of an estimator involves integrating 
> with respect to the density of the estimator and we have seen that 
> densities of estimators of variances will be skewed, often highly 
> skewed. It is not clear why we should be interested in the expected 
> value of a highly skewed estimator. If we were to transform to a
> more symmetric scale, such as the estimator of the standard deviation
> or the estimator of the logarithm of the standard deviation, the
> REML estimator would no longer be unbiased. Furthermore, this
> property of unbiasedness of variance estimators does not generalize
> from the linear regression model to linear mixed models. This is all
> to say that the distinction between REML and ML estimates of
> variances and variance components is probably less important that
> many people believe.


best,

landon
[0]:
www.researchgate.net/publictopics.PublicPostFileLoader.html?id=53326f19d5a3f206348b45af&key=6a85e53326f199010f

> Best, Phillip Alday _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


- -- 
Violence is the last refuge of the incompetent.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.17 (GNU/Linux)

iQIcBAEBCgAGBQJVmLQMAAoJEDeph/0fVJWs21AP/RPMNrQDdkd67eQWfb9jhbTZ
VIfZDNAt088n8XednUzk6BQlVUirb8akqdVq8YqtdaCotdP5dxXjRr30hO72FeRj
rvLWcZXtDVuNwOFZA44Aw2YplwD1sU+G+vMLOsPD4BrBRfByY5FkkX2lTliQjbVK
eYNi57977w/AE7y48OTprwBdkNkWjTQTrnKAsglBtOlnC+x8TdD8J0WfaZCfI1CP
iUN6298pdSNWm+vAWaFCeq6Wig8o2kYGONd1RBDzGidbcy5CiQebuJYZ8cU5zl4V
X34alL6cX+9qDLWbi4jYz1/3lG1U4NsCKhs6fM7imxOFV9XXtsZTr16xmHbkc6B+
daNAbln/SHKoCpuvGiO+IL/H8y8W1DLyJk7sRlb7tOuDHViBCOPLwPZj71aJFFab
qY40JvxdV0rputOeg5OtTyqROxCwtgqKWDaGcli1Dpcrca2aE7qNpPdMjxmnJN+j
RDaCkHflJuwHifkupg7qSfLa2zbBf4KirfGnOsoeicZPF4s7BmDLU28fMlhAqEly
Dbg3niPaW4/X3X69yrkw5XG46uftRGlSUdl/eMWWBUVy3o5oAkAgxpQl/49Md0CX
SyYyv+Iaa9NPtgI828NYfw59xsW98hTnNNtG+D0V4nN/1d29M/KM6LspxV9Nu64b
XNno0S7U16mSu1KhvIwY
=7uyi
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Sun Jul  5 07:41:54 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 05 Jul 2015 01:41:54 -0400
Subject: [R-sig-ME] counseling for multilevel models
In-Reply-To: <CALOrwjGP2LoJYARXaGKzALQz-ECgT9=m6YsfrW0bm1fGk_K_KQ@mail.gmail.com>
References: <CALOrwjGP2LoJYARXaGKzALQz-ECgT9=m6YsfrW0bm1fGk_K_KQ@mail.gmail.com>
Message-ID: <5598C3A2.9060101@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-07-02 04:55 AM, Catarina Silva Castro wrote:
> Hello! My name is Catarina and study in the Faculty of Sciences of
> the University of Oporto, Portugal. Within the framework of my
> master's thesis, I am using a set of data on work accidents in a
> chain of stores. The chain store is divided into different
> directions of operations and each is associated monthly records of
> the number of registered work accidents. After several reviews, I
> think the multilevel models are the most suitable but when
> implementing in R the models, I don't know how to assign variables
> to different levels. When i use the function lme of the nlme
> library or lmer of the lme4 library, all covariables that include
> in the model are assigned to level 1 and do not know how to assign
> them to higher levels. I needed help to advise me on which the most
> appropriate functions and libraries, if them are not, and I would
> to know how to assign variables to different levels and get the
> best results for my study. Waiting for reply. Thanks, Catarina
> 

   You might need to be a little bit more specific/concrete.

   lme4 and nlme do not need to be told at what levels the fixed effects
(which I will take to be the same as your "covariables") vary.  It is
important to take this into account when deciding which terms to allow
to vary across which random-effects grouping levels, but this is not
an explicit model-specification issue.

  For example, suppose we have a response y, a grouping variable g,
and two covariates/fixed effects: x1 varies across individuals and x2
varies only across groups (that is, all individuals within any level
of g have identical values of x2).  Then the maximal model that makes
sense to fit (as an LMM) is

   y ~ x1 + x2 + (x1|g)   ;

if you try to fit

   y ~ x1 + x2 + (x1+x2|g)

(or some other model that incorporates variation of the effect of x2
across groups), you will get (hopefully) a warning or (possibly) a
wonky answer, as the observation/experimental design doesn't contain
any information about variation in this effect.

   I'm a little bit confused by your statement "all covariables that
include in the model are assigned to level 1"; how do you know?  The
only place I can think of that these packages make any kind of
assertion about levels is in anova(), where (n)lme (not lme4/lmer)
takes a guess about the appropriate denominator-df for an F test.  It
is true that lme's algorithm gets it wrong sometimes for random-slopes
models; if that is the case, please confirm / give more details ... in
any case, a bit of clarification about what's wrong and how you know
would be useful.

  cheers
    Ben Bolker


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVmMOhAAoJEOCV5YRblxUHEiIH/0kk/PkzTotmKDi8eT0jGMyQ
9LGWFDXcZ9wHqN8L16VSm8yTDHz7geHkSRrrvVori0UQv8QojPvXn2CTxou/PiEV
oKG9ly5bPGK2ujEH0BK/W4Wp9x/i2iwGZdwSgJ45NwM2pKcOT6GDh0ZtARJTIHmz
B9s3LTK6OLP55a/hB/u5EO/HiydfnWhFnh7qxwrEIwOEOdzaN61R8jLah53b04gb
zXukK4YthvOYhFGsjW6dFkUqIEZ3Z/w4GOygayoiezLJo+b7MOIWLiZuNUI+aCBp
D3nZLUXtCaOfCQ/wkM2yscbBzdWldg1W1AYZlCnurUQrx9o7z2NwqAi+xnZKchQ=
=N9Vp
-----END PGP SIGNATURE-----


From tcarpenter at spu.edu  Sat Jul  4 18:43:59 2015
From: tcarpenter at spu.edu (Carpenter, Tom)
Date: Sat, 4 Jul 2015 16:43:59 +0000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>,
	<CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
Message-ID: <24A2D639-60AD-4FDE-A2CD-6662C026F1D1@spu.edu>

Very, very helpful! Thanks.

As a side note, are there good resources you might direct an applied user toward for understanding issues with REML? I had a reviewer recently complain that I had NOT used it in lmer...

Tom Carpenter, Ph.D.
Assistant Professor, Psychology
Seattle Pacific University
3307 3rd Ave W. Suite 107,
Seattle, WA, 98119
tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>
Office: (206) 281-2916
Mobile: (206) 276-1541
Fax: (206) 281-2695


On Jul 4, 2015, at 9:18 AM, Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>> wrote:

By the way, most of us don't know the acronym FIML.  I have a suspicion that it is one of the many "maximum likelihood" estimators defined in the multilevel modeling literature.  To a statistician these expressions are nonsensical.  Once you define the probability model there is only one possible definition of likelihood and hence only one criterion for the maximum likelihood estimators to optimize.  Creating a different criterion and saying that the optimizers of this criterion are the "<whatever> maximum likelihood" estimators is false advertising.

Having said all this I will admit that the original sin, the "REML" criterion, was committed by statisticians.  In retrospect I wish that we had not incorporated that criterion into the nlme and lme4 packages but, at the time we wrote them, our work would have been dismissed as wrong if our answers did not agree with SAS PROC MIXED, etc.  So we opted for bug-for-bug compatibility with existing software.

On Sat, Jul 4, 2015 at 11:09 AM Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>> wrote:
I think we would need to know more about the structure of the data and the models that you wish to fit to it before we could be of any assistance.

To be honest, your question doesn't make sense in the context of lmer.  The data for lmer must be in the "long form".  That is, each observation corresponds to a row in the data frame.  If one subject has 5 observations there will be 5 rows for that subject.  If another has only two observations there will be two rows.  To me you are describing unbalanced data, not missing data.  In most cases it is more confusing than illuminating to think of data in the "wide form", with one row for each subject and multiple columns for the observations, when working with R.

There is no difficulty with working with unbalanced data in lmer.

On Sat, Jul 4, 2015 at 10:42 AM Carpenter, Tom <tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>> wrote:
All,

I have a paper in which we are using a within-person model using multi-level modeling. I ran the models in lmer in R, although we had a substantial portion of people for whom at least one observation is still missing. My understanding is that the default is to drop that person entirely (e.g., na.action=na.omit) ....is that correct? My understanding was that the HLM software (e.g., by SSI) and most other multi-level modeling programs can still run the models based on the remaining observations (e.g., you may have 4 out of 5 observations per person and still be able to run the model).

I would love to know if it is possible to do that in lmer or if some solution is present. For example, is it possible to use FIML in lmer? Advice for handling this situation would be appreciated, as I'm new to lmer!

Best,


Tom Carpenter, Ph.D.
Assistant Professor, Psychology
Seattle Pacific University
3307 3rd Ave W. Suite 107,
Seattle, WA, 98119
tcarpenter at spu.edu<mailto:tcarpenter at spu.edu><mailto:tcarpenter at spu.edu<mailto:tcarpenter at spu.edu>>
Office: (206) 281-2916
Fax: (206) 281-2695













        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Sun Jul  5 17:21:56 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 05 Jul 2015 15:21:56 +0000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <5598B40C.5090001@gmail.com>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
	<CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
	<55983236.2050902@huftis.org> <1436069647.23972.13.camel@loki>
	<5598B40C.5090001@gmail.com>
Message-ID: <CAO7JsnRa70gCd7iwr0wiRQFY-bLtiGcCZyHrGKDDCvL7gdW4QQ@mail.gmail.com>

My apologies for making such a statement then not following up.  As has
been mentioned, this is a holiday weekend in the U.S.

The section that Landon quoted does get at the point of my comment.

The usual justification for REML is that REML estimators of variance
components are less biased than are the maximum likelihood estimators
(mle).  On the surface this seems to be a convincing argument, for who
would want to use a "biased" estimator?

But why should we be concerned with the estimator of the variance?  Why not
the estimator of the standard deviation, or the logarithm of the standard
deviation?  The distribution of variance estimators are highly skewed in
most cases.  Consider the simplest case of estimating the variance from an
i.i.d. sample from a Gaussian distribution.  The distribution of the
estimator is a Chi-squared distribution, which is highly skewed.  The
distribution of the estimator of ? is less skewed.  The distribution of the
estimator of log(?) is more-or-less symmetric.

The important point here is that "bias" relates to the expected value of
the estimator.  The argument for REML is based on the expected value of a
quantity with a highly skewed distribution, but we know that this is a poor
measure of location for such a distribution.  That's why it is more
informative to consider median salaries instead of average salaries.  The
fact that the average wealth of members of LeBron James's high school
basketball team is very high doesn't make them all rich.

Mle's have an invariance property in that the mle of ? is the square root
of the mle of ??; the mle of log(??) is the logarithm of the mle of ??,
etc.  Unbiased estimators aren't invariant under transformation.  The
square root of an unbiased estimator of ?? is not an unbiased estimator of
?.

If an unbiased estimator were so important then we should probably consider
the estimate of log(??), not ?? itself.  The reason for our being fixated
on ?? is more computational than practical.  When using hand calculations
it is easiest to estimate ?? then derive an estimate of ? from that.  These
considerations are less convincing when using computers.

In summary, the case for REML is less convincing than it seems at first
glance.  It is a consequence of a certain type of mathematical exposition,
where your assumptions are never questioned.  You only care about going
from "if" to "then".  In mathematical statistics you say, "assuming that
the model is correct, these are the consequences" and that is all there is
to it.  The way that the game is actually played is that, when you get to
the end of the proof and discover that you need some conditions to make it
work, you go back to the beginning and add those conditions.  It helps if
you call this case the "regular" case or the "normal" case or some other
word with favorable connotations.

So if you want to characterize the "best" estimator you do it by peeling
off properties related to the first moment, the second moment, etc. For the
first moment you say that the expected value of the estimator must be equal
to the parameter being estimated and you call that the "unbiased" case.
Technically this is just a mathematical property but the connotation of the
word gives it much more heft than the mathematical property.  In
mathematical statistics it is irrelevant to question why it is this
particular estimator or this particular scale that is of interest - the
only objective is to prove the theorem and publish the result.

(The folklore in our department is that George Box's famous statement about
"all models are wrong" originated in a thesis defense where the candidate
began by stating that "Assuming that the model is correct" and George
interrupted to say "But all models are wrong".  It wasn't a good day for
the candidate.  I'm sorry to say that I don't know if this story is
accurate as I never took the opportunity to ask him.)

On Sat, Jul 4, 2015 at 11:36 PM landon hurley <ljrhurley at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> On 07/05/2015 12:14 AM, Phillip Alday wrote:
> > On Sat, 2015-07-04 at 21:21 +0200, Karl Ove Hufthammer wrote:
> >> Den 04. juli 2015 18:18, Douglas Bates skreiv:
> >>> Having said all this I will admit that the original sin, the
> >>> "REML" criterion, was committed by statisticians.  In retrospect
> >>> I wish that we had not incorporated that criterion into the nlme
> >>> and lme4 packages but, at the time we wrote them, our work would
> >>> have been dismissed as wrong if our answers did not agree with
> >>> SAS PROC MIXED, etc.  So we opted for bug-for-bug compatibility
> >>> with existing software.
> >>
> >> Hm. I find this statement surprising. I was under the impression
> >> REML is *preferred* to ML in many situations (e.g. in simple
> >> random intercept models with few observations for each random
> >> intercept), and that *ML estimation* may result in severe bias. Do
> >> you consider maximising the REML criterion as a bug?
> >>
> >
> > This was my question as well. My understanding was that REML, like
> > Bessel's correction for the sample variance, was motivated by bias in
> > the maximum-likelihood estimator for small numbers of observations.
> > The corrected estimator is in both cases no longer the MLE, so that
> > the ML part is bit of a misnomer, but if you take "residualized"
> > expansion of RE instead of "restricted", then REML seems more like a
> > function of ML and not a "type" of ML.
> >
> > IIRC, the default in MixedModels.jl is now ML -- have you changed
> > your opinion about the utility of REML? Is there some type of weird
> > paradoxical situation with REML like with Bessel's correction -- the
> >  variance estimates are no longer biased, but the s.d. estimates
> > are?
> >
> >
> > Or is the original sin the use of the name REML when REML is no
> > longer *the* maximum likelihood?
> >
>
> I had assumed that he would have responded by now, but it is a holiday
> in the US. The position Bates is taking is explained (I think) in his
> 2010 report
> lme4: Mixed effects modelling with R in Section 5.5 `The REML
> Criterion', roughly page 123-124 in the pdf [0]. It's a short read, but
> the most relevant bit I think is:
>
> > The argument for preferring ?_R to ?_L as an estimate of ?**2 is
> > that the numerator in both estimates is the sum of squared
> > residuals at ? and, although the residual vector, yobs ? X? , is an
> > n-dimensional vector, the residual at ? satisfies p linearly
> > independent constraints, X**{T} (yobs ? X? ) = 0. That is, the residual
> > at ? is the projection of the observed response vector, yobs , into
> > an (n ? p)-dimensional linear subspace of the n-dimensional response
> > space. The estimate ?R takes into account the fact that ?**2 is
> > estimated from residuals that have only n ? p degrees of freedom.
> >
> > Another argument often put forward for REML estimation is that ?_R is
> > an unbiased estimate of ?**2 , in the sense that the expected value of
> > the estimator is equal to the value of the parameter. However,
> > determining the expected value of an estimator involves integrating
> > with respect to the density of the estimator and we have seen that
> > densities of estimators of variances will be skewed, often highly
> > skewed. It is not clear why we should be interested in the expected
> > value of a highly skewed estimator. If we were to transform to a
> > more symmetric scale, such as the estimator of the standard deviation
> > or the estimator of the logarithm of the standard deviation, the
> > REML estimator would no longer be unbiased. Furthermore, this
> > property of unbiasedness of variance estimators does not generalize
> > from the linear regression model to linear mixed models. This is all
> > to say that the distinction between REML and ML estimates of
> > variances and variance components is probably less important that
> > many people believe.
>
>
> best,
>
> landon
> [0]:
>
> www.researchgate.net/publictopics.PublicPostFileLoader.html?id=53326f19d5a3f206348b45af&key=6a85e53326f199010f
>
> > Best, Phillip Alday _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
> - --
> Violence is the last refuge of the incompetent.
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.17 (GNU/Linux)
>
> iQIcBAEBCgAGBQJVmLQMAAoJEDeph/0fVJWs21AP/RPMNrQDdkd67eQWfb9jhbTZ
> VIfZDNAt088n8XednUzk6BQlVUirb8akqdVq8YqtdaCotdP5dxXjRr30hO72FeRj
> rvLWcZXtDVuNwOFZA44Aw2YplwD1sU+G+vMLOsPD4BrBRfByY5FkkX2lTliQjbVK
> eYNi57977w/AE7y48OTprwBdkNkWjTQTrnKAsglBtOlnC+x8TdD8J0WfaZCfI1CP
> iUN6298pdSNWm+vAWaFCeq6Wig8o2kYGONd1RBDzGidbcy5CiQebuJYZ8cU5zl4V
> X34alL6cX+9qDLWbi4jYz1/3lG1U4NsCKhs6fM7imxOFV9XXtsZTr16xmHbkc6B+
> daNAbln/SHKoCpuvGiO+IL/H8y8W1DLyJk7sRlb7tOuDHViBCOPLwPZj71aJFFab
> qY40JvxdV0rputOeg5OtTyqROxCwtgqKWDaGcli1Dpcrca2aE7qNpPdMjxmnJN+j
> RDaCkHflJuwHifkupg7qSfLa2zbBf4KirfGnOsoeicZPF4s7BmDLU28fMlhAqEly
> Dbg3niPaW4/X3X69yrkw5XG46uftRGlSUdl/eMWWBUVy3o5oAkAgxpQl/49Md0CX
> SyYyv+Iaa9NPtgI828NYfw59xsW98hTnNNtG+D0V4nN/1d29M/KM6LspxV9Nu64b
> XNno0S7U16mSu1KhvIwY
> =7uyi
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Mon Jul  6 02:31:01 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 6 Jul 2015 00:31:01 +0000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <CAO7JsnRa70gCd7iwr0wiRQFY-bLtiGcCZyHrGKDDCvL7gdW4QQ@mail.gmail.com>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
	<CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
	<55983236.2050902@huftis.org> <1436069647.23972.13.camel@loki>
	<5598B40C.5090001@gmail.com>
	<CAO7JsnRa70gCd7iwr0wiRQFY-bLtiGcCZyHrGKDDCvL7gdW4QQ@mail.gmail.com>
Message-ID: <411CBD92-0DD2-4397-A200-D274D49040DD@anu.edu.au>

Quoting Douglas:
> . . .  In mathematical statistics you say, "assuming that
> the model is correct, these are the consequences" and that is all there is
> to it.  The way that the game is actually played is that, when you get to
> the end of the proof and discover that you need some conditions to make it
> work, you go back to the beginning and add those conditions.

So mathematical statistics is a ?game?.  That is surely a rather damning comment!
It does however raise important points.  My perception is that the situation has 
improved greatly from the ?that is all there is to it? typical stance in the published 
literature of the 1960s and 1970s.  There?s greater pressure to back up theoretical 
development with computations with (often, somewhat) real data.  

The situation is though uneven.   In some parts of the literature though (the literature 
on smoothing seems to me particularly rife with this problem) serious issues with the 
unreality of iid or at least id (independence) assumptions, for time series and/or 
spatial data, are just ignored!  That is just one example.  [For interpolation, maybe
the iid assumption often makes reasonable sense for spatial data.]

More important than whether the estimator has likelihood in its name, or whether it
is misleading to call it some kind of likelihood estimator, is whether it serves the 
intended purpose.  Use the median for sure where it makes sense, which incidentally
is neither unbiased nor ML.  I do not think that one would get away with quoting
maximum likelihood estimators (eg, for wages and wage differentials in various 
sectors) in a set of national account figures.  Here, one might be tempted to make
politically fraught comments about the malign effects of highly skew distributions!
Nuf sed.

In many contexts, it is thought important to have numbers that add up.  That, after
all is what analysis of variance breakdowns of the mean are all about.  Medians do
not work well in that context; they do not give a table that adds up.  But of course,
just because one is presenting a table where effects add up to give a grand mean,
distributions that are close to symmetric are important, for conceptual as well as for
theoretical (normality of sampling distribution) reasons.  This all becomes a whole 
lot more fraught for GLM models.

The main benefit of REML may be that it matches what comes out computationally
to the theory.  Does this do serious damage to the numbers that come out, relative
to the way that they will be used?  Doug, do your strictures apply also to the t-statistic,
which is a REML type statistic?  (One uses an unbiased estimate of the variance in
the denominator.)  Or is the issue that it is just a means to an end?

On moment estimators, comments made by Tukey seem to me relevant: 
"Do not assume ?that we always know what in fact we never know ? the exact probability structure . . . 
No data set is large enough to tell us how it should be analysed.?
[Tukey: More honest foundations for data analysis. Journal of Statistical Planning and Inference, 
vol. 57, no. 1, pp. 21-28, 1997]

Nor, I want to add, do we commonly have all the needed background information.

Moment estimators can be a way to get an estimator that applies to a wide class of distributions.
I and many others think this more than sufficient justification for the dispersion estimate that is 
widely used in quasi-likelihood computations, notable to GLM models with quasi-Poisson or 
quasi-binomial distributions.  A key question is of course whether the dispersion might vary 
with the mean.  And yes, this does make a whole lot more sense if one is working on a scale
where the sampling distribution(s) is(are) symmetric.  So perhaps what is wrong with standard
quasi models is that they inflate the variance on a scale where distributions are nothing like
symmetric! What is totally wrong is any failure to adjust for an inflated variance in cases (in 
most areas, e.g., ecology, the great majority) where the variance clearly is inflated relative to
the Poisson or binomial.  Note that this applies also to glmer models, notably where Poisson 
or binomial errors are specified.  One can specify an observation level random effect. I suspect 
that results are often compromised because of failure to attend to this issue.

In summary, there are some very important issues here, but I do not see that substituting one
 mathematical simplification for another is an answer.  In the end, we want our models to be 
useful, useful I would hope for more than purposes of getting promotion!

John Maindonald             email: john.maindonald at anu.edu.au

> On 6/07/2015, at 01:21, Douglas Bates <bates at stat.wisc.edu> wrote:
> 
> My apologies for making such a statement then not following up.  As has
> been mentioned, this is a holiday weekend in the U.S.
> 
> The section that Landon quoted does get at the point of my comment.
> 
> The usual justification for REML is that REML estimators of variance
> components are less biased than are the maximum likelihood estimators
> (mle).  On the surface this seems to be a convincing argument, for who
> would want to use a "biased" estimator?
> 
> But why should we be concerned with the estimator of the variance?  Why not
> the estimator of the standard deviation, or the logarithm of the standard
> deviation?  The distribution of variance estimators are highly skewed in
> most cases.  Consider the simplest case of estimating the variance from an
> i.i.d. sample from a Gaussian distribution.  The distribution of the
> estimator is a Chi-squared distribution, which is highly skewed.  The
> distribution of the estimator of ? is less skewed.  The distribution of the
> estimator of log(?) is more-or-less symmetric.
> 
> The important point here is that "bias" relates to the expected value of
> the estimator.  The argument for REML is based on the expected value of a
> quantity with a highly skewed distribution, but we know that this is a poor
> measure of location for such a distribution.  That's why it is more
> informative to consider median salaries instead of average salaries.  The
> fact that the average wealth of members of LeBron James's high school
> basketball team is very high doesn't make them all rich.
> 
> Mle's have an invariance property in that the mle of ? is the square root
> of the mle of ??; the mle of log(??) is the logarithm of the mle of ??,
> etc.  Unbiased estimators aren't invariant under transformation.  The
> square root of an unbiased estimator of ?? is not an unbiased estimator of
> ?.
> 
> If an unbiased estimator were so important then we should probably consider
> the estimate of log(??), not ?? itself.  The reason for our being fixated
> on ?? is more computational than practical.  When using hand calculations
> it is easiest to estimate ?? then derive an estimate of ? from that.  These
> considerations are less convincing when using computers.





> In summary, the case for REML is less convincing than it seems at first
> glance.  It is a consequence of a certain type of mathematical exposition,
> where your assumptions are never questioned.  You only care about going
> from "if" to "then".  In mathematical statistics you say, "assuming that
> the model is correct, these are the consequences" and that is all there is
> to it.  The way that the game is actually played is that, when you get to
> the end of the proof and discover that you need some conditions to make it
> work, you go back to the beginning and add those conditions.  It helps if
> you call this case the "regular" case or the "normal" case or some other
> word with favorable connotations.
> 
> So if you want to characterize the "best" estimator you do it by peeling
> off properties related to the first moment, the second moment, etc. For the
> first moment you say that the expected value of the estimator must be equal
> to the parameter being estimated and you call that the "unbiased" case.
> Technically this is just a mathematical property but the connotation of the
> word gives it much more heft than the mathematical property.  In
> mathematical statistics it is irrelevant to question why it is this
> particular estimator or this particular scale that is of interest - the
> only objective is to prove the theorem and publish the result.
> 
> (The folklore in our department is that George Box's famous statement about
> "all models are wrong" originated in a thesis defense where the candidate
> began by stating that "Assuming that the model is correct" and George
> interrupted to say "But all models are wrong".  It wasn't a good day for
> the candidate.  I'm sorry to say that I don't know if this story is
> accurate as I never took the opportunity to ask him.)
> 
> On Sat, Jul 4, 2015 at 11:36 PM landon hurley <ljrhurley at gmail.com> wrote:
> 
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA512
>> 
>> On 07/05/2015 12:14 AM, Phillip Alday wrote:
>>> On Sat, 2015-07-04 at 21:21 +0200, Karl Ove Hufthammer wrote:
>>>> Den 04. juli 2015 18:18, Douglas Bates skreiv:
>>>>> Having said all this I will admit that the original sin, the
>>>>> "REML" criterion, was committed by statisticians.  In retrospect
>>>>> I wish that we had not incorporated that criterion into the nlme
>>>>> and lme4 packages but, at the time we wrote them, our work would
>>>>> have been dismissed as wrong if our answers did not agree with
>>>>> SAS PROC MIXED, etc.  So we opted for bug-for-bug compatibility
>>>>> with existing software.
>>>> 
>>>> Hm. I find this statement surprising. I was under the impression
>>>> REML is *preferred* to ML in many situations (e.g. in simple
>>>> random intercept models with few observations for each random
>>>> intercept), and that *ML estimation* may result in severe bias. Do
>>>> you consider maximising the REML criterion as a bug?
>>>> 
>>> 
>>> This was my question as well. My understanding was that REML, like
>>> Bessel's correction for the sample variance, was motivated by bias in
>>> the maximum-likelihood estimator for small numbers of observations.
>>> The corrected estimator is in both cases no longer the MLE, so that
>>> the ML part is bit of a misnomer, but if you take "residualized"
>>> expansion of RE instead of "restricted", then REML seems more like a
>>> function of ML and not a "type" of ML.
>>> 
>>> IIRC, the default in MixedModels.jl is now ML -- have you changed
>>> your opinion about the utility of REML? Is there some type of weird
>>> paradoxical situation with REML like with Bessel's correction -- the
>>> variance estimates are no longer biased, but the s.d. estimates
>>> are?
>>> 
>>> 
>>> Or is the original sin the use of the name REML when REML is no
>>> longer *the* maximum likelihood?
>>> 
>> 
>> I had assumed that he would have responded by now, but it is a holiday
>> in the US. The position Bates is taking is explained (I think) in his
>> 2010 report
>> lme4: Mixed effects modelling with R in Section 5.5 `The REML
>> Criterion', roughly page 123-124 in the pdf [0]. It's a short read, but
>> the most relevant bit I think is:
>> 
>>> The argument for preferring ?_R to ?_L as an estimate of ?**2 is
>>> that the numerator in both estimates is the sum of squared
>>> residuals at ? and, although the residual vector, yobs ? X? , is an
>>> n-dimensional vector, the residual at ? satisfies p linearly
>>> independent constraints, X**{T} (yobs ? X? ) = 0. That is, the residual
>>> at ? is the projection of the observed response vector, yobs , into
>>> an (n ? p)-dimensional linear subspace of the n-dimensional response
>>> space. The estimate ?R takes into account the fact that ?**2 is
>>> estimated from residuals that have only n ? p degrees of freedom.
>>> 
>>> Another argument often put forward for REML estimation is that ?_R is
>>> an unbiased estimate of ?**2 , in the sense that the expected value of
>>> the estimator is equal to the value of the parameter. However,
>>> determining the expected value of an estimator involves integrating
>>> with respect to the density of the estimator and we have seen that
>>> densities of estimators of variances will be skewed, often highly
>>> skewed. It is not clear why we should be interested in the expected
>>> value of a highly skewed estimator. If we were to transform to a
>>> more symmetric scale, such as the estimator of the standard deviation
>>> or the estimator of the logarithm of the standard deviation, the
>>> REML estimator would no longer be unbiased. Furthermore, this
>>> property of unbiasedness of variance estimators does not generalize
>>> from the linear regression model to linear mixed models. This is all
>>> to say that the distinction between REML and ML estimates of
>>> variances and variance components is probably less important that
>>> many people believe.
>> 
>> 
>> best,
>> 
>> landon
>> [0]:
>> 
>> www.researchgate.net/publictopics.PublicPostFileLoader.html?id=53326f19d5a3f206348b45af&key=6a85e53326f199010f
>> 
>>> Best, Phillip Alday _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> 
>> - --
>> Violence is the last refuge of the incompetent.
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2.0.17 (GNU/Linux)
>> 
>> iQIcBAEBCgAGBQJVmLQMAAoJEDeph/0fVJWs21AP/RPMNrQDdkd67eQWfb9jhbTZ
>> VIfZDNAt088n8XednUzk6BQlVUirb8akqdVq8YqtdaCotdP5dxXjRr30hO72FeRj
>> rvLWcZXtDVuNwOFZA44Aw2YplwD1sU+G+vMLOsPD4BrBRfByY5FkkX2lTliQjbVK
>> eYNi57977w/AE7y48OTprwBdkNkWjTQTrnKAsglBtOlnC+x8TdD8J0WfaZCfI1CP
>> iUN6298pdSNWm+vAWaFCeq6Wig8o2kYGONd1RBDzGidbcy5CiQebuJYZ8cU5zl4V
>> X34alL6cX+9qDLWbi4jYz1/3lG1U4NsCKhs6fM7imxOFV9XXtsZTr16xmHbkc6B+
>> daNAbln/SHKoCpuvGiO+IL/H8y8W1DLyJk7sRlb7tOuDHViBCOPLwPZj71aJFFab
>> qY40JvxdV0rputOeg5OtTyqROxCwtgqKWDaGcli1Dpcrca2aE7qNpPdMjxmnJN+j
>> RDaCkHflJuwHifkupg7qSfLa2zbBf4KirfGnOsoeicZPF4s7BmDLU28fMlhAqEly
>> Dbg3niPaW4/X3X69yrkw5XG46uftRGlSUdl/eMWWBUVy3o5oAkAgxpQl/49Md0CX
>> SyYyv+Iaa9NPtgI828NYfw59xsW98hTnNNtG+D0V4nN/1d29M/KM6LspxV9Nu64b
>> XNno0S7U16mSu1KhvIwY
>> =7uyi
>> -----END PGP SIGNATURE-----
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 	


From ken.beath at mq.edu.au  Mon Jul  6 03:24:09 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Mon, 6 Jul 2015 11:24:09 +1000
Subject: [R-sig-ME] Missing values in lmer vs. HLM
In-Reply-To: <411CBD92-0DD2-4397-A200-D274D49040DD@anu.edu.au>
References: <23B4DBA5-BC84-4880-9098-3FE582727CBA@spu.edu>
	<CAO7JsnRFeEuJkhnWWcJyt3s9dQrcNnAWf55ZhAbSe7uuDar54Q@mail.gmail.com>
	<CAO7JsnS4tVg-r2hXKMZmUHtVF0DTMh+8BKdcsH=3P6K4HqF8hw@mail.gmail.com>
	<55983236.2050902@huftis.org> <1436069647.23972.13.camel@loki>
	<5598B40C.5090001@gmail.com>
	<CAO7JsnRa70gCd7iwr0wiRQFY-bLtiGcCZyHrGKDDCvL7gdW4QQ@mail.gmail.com>
	<411CBD92-0DD2-4397-A200-D274D49040DD@anu.edu.au>
Message-ID: <CAF5_5cxCJ-b_TP_ZtLHCU_-7xap8suKF9zeyevMVN7h6_xf9+g@mail.gmail.com>

There has been a reasonable amount of work on comparing different methods
for random-effects meta-analysis. Using REML does produce better estimates
of the effect size, in terms of coverage than maximum likelihood. Using the
profile likelihood produces better results again, so maybe that is what
should be used. On the other hand it is likely that the distribution of the
random effects isn't normal, so it probably isn't important.

If it is important there are now more general ways of fixing the bias and
coverage, parametric bootstrap should work nicely, so it doesn't seem
useful to use a technique that only has limited application. Maximum
likelihood is applied to mixed effects logistic where it has much the same
problems, and everyone just seems to ignore them.



On 6 July 2015 at 10:31, John Maindonald <john.maindonald at anu.edu.au> wrote:

> Quoting Douglas:
> > . . .  In mathematical statistics you say, "assuming that
> > the model is correct, these are the consequences" and that is all there
> is
> > to it.  The way that the game is actually played is that, when you get to
> > the end of the proof and discover that you need some conditions to make
> it
> > work, you go back to the beginning and add those conditions.
>
> So mathematical statistics is a ?game?.  That is surely a rather damning
> comment!
> It does however raise important points.  My perception is that the
> situation has
> improved greatly from the ?that is all there is to it? typical stance in
> the published
> literature of the 1960s and 1970s.  There?s greater pressure to back up
> theoretical
> development with computations with (often, somewhat) real data.
>
> The situation is though uneven.   In some parts of the literature though
> (the literature
> on smoothing seems to me particularly rife with this problem) serious
> issues with the
> unreality of iid or at least id (independence) assumptions, for time
> series and/or
> spatial data, are just ignored!  That is just one example.  [For
> interpolation, maybe
> the iid assumption often makes reasonable sense for spatial data.]
>
> More important than whether the estimator has likelihood in its name, or
> whether it
> is misleading to call it some kind of likelihood estimator, is whether it
> serves the
> intended purpose.  Use the median for sure where it makes sense, which
> incidentally
> is neither unbiased nor ML.  I do not think that one would get away with
> quoting
> maximum likelihood estimators (eg, for wages and wage differentials in
> various
> sectors) in a set of national account figures.  Here, one might be tempted
> to make
> politically fraught comments about the malign effects of highly skew
> distributions!
> Nuf sed.
>
> In many contexts, it is thought important to have numbers that add up.
> That, after
> all is what analysis of variance breakdowns of the mean are all about.
> Medians do
> not work well in that context; they do not give a table that adds up.  But
> of course,
> just because one is presenting a table where effects add up to give a
> grand mean,
> distributions that are close to symmetric are important, for conceptual as
> well as for
> theoretical (normality of sampling distribution) reasons.  This all
> becomes a whole
> lot more fraught for GLM models.
>
> The main benefit of REML may be that it matches what comes out
> computationally
> to the theory.  Does this do serious damage to the numbers that come out,
> relative
> to the way that they will be used?  Doug, do your strictures apply also to
> the t-statistic,
> which is a REML type statistic?  (One uses an unbiased estimate of the
> variance in
> the denominator.)  Or is the issue that it is just a means to an end?
>
> On moment estimators, comments made by Tukey seem to me relevant:
> "Do not assume ?that we always know what in fact we never know ? the exact
> probability structure . . .
> No data set is large enough to tell us how it should be analysed.?
> [Tukey: More honest foundations for data analysis. Journal of Statistical
> Planning and Inference,
> vol. 57, no. 1, pp. 21-28, 1997]
>
> Nor, I want to add, do we commonly have all the needed background
> information.
>
> Moment estimators can be a way to get an estimator that applies to a wide
> class of distributions.
> I and many others think this more than sufficient justification for the
> dispersion estimate that is
> widely used in quasi-likelihood computations, notable to GLM models with
> quasi-Poisson or
> quasi-binomial distributions.  A key question is of course whether the
> dispersion might vary
> with the mean.  And yes, this does make a whole lot more sense if one is
> working on a scale
> where the sampling distribution(s) is(are) symmetric.  So perhaps what is
> wrong with standard
> quasi models is that they inflate the variance on a scale where
> distributions are nothing like
> symmetric! What is totally wrong is any failure to adjust for an inflated
> variance in cases (in
> most areas, e.g., ecology, the great majority) where the variance clearly
> is inflated relative to
> the Poisson or binomial.  Note that this applies also to glmer models,
> notably where Poisson
> or binomial errors are specified.  One can specify an observation level
> random effect. I suspect
> that results are often compromised because of failure to attend to this
> issue.
>
> In summary, there are some very important issues here, but I do not see
> that substituting one
>  mathematical simplification for another is an answer.  In the end, we
> want our models to be
> useful, useful I would hope for more than purposes of getting promotion!
>
> John Maindonald             email: john.maindonald at anu.edu.au
>
> > On 6/07/2015, at 01:21, Douglas Bates <bates at stat.wisc.edu> wrote:
> >
> > My apologies for making such a statement then not following up.  As has
> > been mentioned, this is a holiday weekend in the U.S.
> >
> > The section that Landon quoted does get at the point of my comment.
> >
> > The usual justification for REML is that REML estimators of variance
> > components are less biased than are the maximum likelihood estimators
> > (mle).  On the surface this seems to be a convincing argument, for who
> > would want to use a "biased" estimator?
> >
> > But why should we be concerned with the estimator of the variance?  Why
> not
> > the estimator of the standard deviation, or the logarithm of the standard
> > deviation?  The distribution of variance estimators are highly skewed in
> > most cases.  Consider the simplest case of estimating the variance from
> an
> > i.i.d. sample from a Gaussian distribution.  The distribution of the
> > estimator is a Chi-squared distribution, which is highly skewed.  The
> > distribution of the estimator of ? is less skewed.  The distribution of
> the
> > estimator of log(?) is more-or-less symmetric.
> >
> > The important point here is that "bias" relates to the expected value of
> > the estimator.  The argument for REML is based on the expected value of a
> > quantity with a highly skewed distribution, but we know that this is a
> poor
> > measure of location for such a distribution.  That's why it is more
> > informative to consider median salaries instead of average salaries.  The
> > fact that the average wealth of members of LeBron James's high school
> > basketball team is very high doesn't make them all rich.
> >
> > Mle's have an invariance property in that the mle of ? is the square root
> > of the mle of ??; the mle of log(??) is the logarithm of the mle of ??,
> > etc.  Unbiased estimators aren't invariant under transformation.  The
> > square root of an unbiased estimator of ?? is not an unbiased estimator
> of
> > ?.
> >
> > If an unbiased estimator were so important then we should probably
> consider
> > the estimate of log(??), not ?? itself.  The reason for our being fixated
> > on ?? is more computational than practical.  When using hand calculations
> > it is easiest to estimate ?? then derive an estimate of ? from that.
> These
> > considerations are less convincing when using computers.
>
>
>
>
>
> > In summary, the case for REML is less convincing than it seems at first
> > glance.  It is a consequence of a certain type of mathematical
> exposition,
> > where your assumptions are never questioned.  You only care about going
> > from "if" to "then".  In mathematical statistics you say, "assuming that
> > the model is correct, these are the consequences" and that is all there
> is
> > to it.  The way that the game is actually played is that, when you get to
> > the end of the proof and discover that you need some conditions to make
> it
> > work, you go back to the beginning and add those conditions.  It helps if
> > you call this case the "regular" case or the "normal" case or some other
> > word with favorable connotations.
> >
> > So if you want to characterize the "best" estimator you do it by peeling
> > off properties related to the first moment, the second moment, etc. For
> the
> > first moment you say that the expected value of the estimator must be
> equal
> > to the parameter being estimated and you call that the "unbiased" case.
> > Technically this is just a mathematical property but the connotation of
> the
> > word gives it much more heft than the mathematical property.  In
> > mathematical statistics it is irrelevant to question why it is this
> > particular estimator or this particular scale that is of interest - the
> > only objective is to prove the theorem and publish the result.
> >
> > (The folklore in our department is that George Box's famous statement
> about
> > "all models are wrong" originated in a thesis defense where the candidate
> > began by stating that "Assuming that the model is correct" and George
> > interrupted to say "But all models are wrong".  It wasn't a good day for
> > the candidate.  I'm sorry to say that I don't know if this story is
> > accurate as I never took the opportunity to ask him.)
> >
> > On Sat, Jul 4, 2015 at 11:36 PM landon hurley <ljrhurley at gmail.com>
> wrote:
> >
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA512
> >>
> >> On 07/05/2015 12:14 AM, Phillip Alday wrote:
> >>> On Sat, 2015-07-04 at 21:21 +0200, Karl Ove Hufthammer wrote:
> >>>> Den 04. juli 2015 18:18, Douglas Bates skreiv:
> >>>>> Having said all this I will admit that the original sin, the
> >>>>> "REML" criterion, was committed by statisticians.  In retrospect
> >>>>> I wish that we had not incorporated that criterion into the nlme
> >>>>> and lme4 packages but, at the time we wrote them, our work would
> >>>>> have been dismissed as wrong if our answers did not agree with
> >>>>> SAS PROC MIXED, etc.  So we opted for bug-for-bug compatibility
> >>>>> with existing software.
> >>>>
> >>>> Hm. I find this statement surprising. I was under the impression
> >>>> REML is *preferred* to ML in many situations (e.g. in simple
> >>>> random intercept models with few observations for each random
> >>>> intercept), and that *ML estimation* may result in severe bias. Do
> >>>> you consider maximising the REML criterion as a bug?
> >>>>
> >>>
> >>> This was my question as well. My understanding was that REML, like
> >>> Bessel's correction for the sample variance, was motivated by bias in
> >>> the maximum-likelihood estimator for small numbers of observations.
> >>> The corrected estimator is in both cases no longer the MLE, so that
> >>> the ML part is bit of a misnomer, but if you take "residualized"
> >>> expansion of RE instead of "restricted", then REML seems more like a
> >>> function of ML and not a "type" of ML.
> >>>
> >>> IIRC, the default in MixedModels.jl is now ML -- have you changed
> >>> your opinion about the utility of REML? Is there some type of weird
> >>> paradoxical situation with REML like with Bessel's correction -- the
> >>> variance estimates are no longer biased, but the s.d. estimates
> >>> are?
> >>>
> >>>
> >>> Or is the original sin the use of the name REML when REML is no
> >>> longer *the* maximum likelihood?
> >>>
> >>
> >> I had assumed that he would have responded by now, but it is a holiday
> >> in the US. The position Bates is taking is explained (I think) in his
> >> 2010 report
> >> lme4: Mixed effects modelling with R in Section 5.5 `The REML
> >> Criterion', roughly page 123-124 in the pdf [0]. It's a short read, but
> >> the most relevant bit I think is:
> >>
> >>> The argument for preferring ?_R to ?_L as an estimate of ?**2 is
> >>> that the numerator in both estimates is the sum of squared
> >>> residuals at ? and, although the residual vector, yobs ? X? , is an
> >>> n-dimensional vector, the residual at ? satisfies p linearly
> >>> independent constraints, X**{T} (yobs ? X? ) = 0. That is, the residual
> >>> at ? is the projection of the observed response vector, yobs , into
> >>> an (n ? p)-dimensional linear subspace of the n-dimensional response
> >>> space. The estimate ?R takes into account the fact that ?**2 is
> >>> estimated from residuals that have only n ? p degrees of freedom.
> >>>
> >>> Another argument often put forward for REML estimation is that ?_R is
> >>> an unbiased estimate of ?**2 , in the sense that the expected value of
> >>> the estimator is equal to the value of the parameter. However,
> >>> determining the expected value of an estimator involves integrating
> >>> with respect to the density of the estimator and we have seen that
> >>> densities of estimators of variances will be skewed, often highly
> >>> skewed. It is not clear why we should be interested in the expected
> >>> value of a highly skewed estimator. If we were to transform to a
> >>> more symmetric scale, such as the estimator of the standard deviation
> >>> or the estimator of the logarithm of the standard deviation, the
> >>> REML estimator would no longer be unbiased. Furthermore, this
> >>> property of unbiasedness of variance estimators does not generalize
> >>> from the linear regression model to linear mixed models. This is all
> >>> to say that the distinction between REML and ML estimates of
> >>> variances and variance components is probably less important that
> >>> many people believe.
> >>
> >>
> >> best,
> >>
> >> landon
> >> [0]:
> >>
> >>
> www.researchgate.net/publictopics.PublicPostFileLoader.html?id=53326f19d5a3f206348b45af&key=6a85e53326f199010f
> >>
> >>> Best, Phillip Alday _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >> - --
> >> Violence is the last refuge of the incompetent.
> >> -----BEGIN PGP SIGNATURE-----
> >> Version: GnuPG v2.0.17 (GNU/Linux)
> >>
> >> iQIcBAEBCgAGBQJVmLQMAAoJEDeph/0fVJWs21AP/RPMNrQDdkd67eQWfb9jhbTZ
> >> VIfZDNAt088n8XednUzk6BQlVUirb8akqdVq8YqtdaCotdP5dxXjRr30hO72FeRj
> >> rvLWcZXtDVuNwOFZA44Aw2YplwD1sU+G+vMLOsPD4BrBRfByY5FkkX2lTliQjbVK
> >> eYNi57977w/AE7y48OTprwBdkNkWjTQTrnKAsglBtOlnC+x8TdD8J0WfaZCfI1CP
> >> iUN6298pdSNWm+vAWaFCeq6Wig8o2kYGONd1RBDzGidbcy5CiQebuJYZ8cU5zl4V
> >> X34alL6cX+9qDLWbi4jYz1/3lG1U4NsCKhs6fM7imxOFV9XXtsZTr16xmHbkc6B+
> >> daNAbln/SHKoCpuvGiO+IL/H8y8W1DLyJk7sRlb7tOuDHViBCOPLwPZj71aJFFab
> >> qY40JvxdV0rputOeg5OtTyqROxCwtgqKWDaGcli1Dpcrca2aE7qNpPdMjxmnJN+j
> >> RDaCkHflJuwHifkupg7qSfLa2zbBf4KirfGnOsoeicZPF4s7BmDLU28fMlhAqEly
> >> Dbg3niPaW4/X3X69yrkw5XG46uftRGlSUdl/eMWWBUVy3o5oAkAgxpQl/49Md0CX
> >> SyYyv+Iaa9NPtgI828NYfw59xsW98hTnNNtG+D0V4nN/1d29M/KM6LspxV9Nu64b
> >> XNno0S7U16mSu1KhvIwY
> >> =7uyi
> >> -----END PGP SIGNATURE-----
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From liberationecology at gmail.com  Mon Jul  6 23:54:52 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Mon, 6 Jul 2015 16:54:52 -0500
Subject: [R-sig-ME] MCMCglmm predictions with new data for multi-response
	model
Message-ID: <CAPNXFM69fMCUL9n_RYuVsf4khOmcCArb+sO+bE-TvcrzLtt53w@mail.gmail.com>

Dear list,

I am hoping to generate predictions (with CIs) based on new data for a
model with
3 Gaussian response variables and 1 blocking variable.

A very similar and recent question hasn't received a substantive reply yet,
here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023616.html .
Jarrod mentioned on this list some months ago that a version of MCMCglmm
that can predict with new data is imminent, but I haven't seen any signs of
it -
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023329.html .

I believe I understand the process as discussed here -
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q1/020065.html
http://stackoverflow.com/questions/21057548/how-can-one-simulate-quantities-of-interest-from-the-posterior-density-in-mcmcgl
,
http://glmm.wikidot.com/faq

Here is my working understanding of the process:
(1) Generate new data / prediction frame -> pred_frame
(2) Generate fixed effects design matrix -> fix_dm
(3) Extract chains of coefficients from Sol -> beta
(4) Matrix-multiply  fix_dm * beta -> temp
(5) Extract variance-covariance matrix as rowsums of mod$VCV -> V
(6) Divide temp by sqrt(V) to get a matrix of predictions [i, j] with i =
MCMC sample and j= new data point -> pred_mat
(7) Generate CIs for predictions as HPDs of columns of pred_mat

Here are my questions:
a. Most broadly - am I on the right track, or have I totally misunderstood
something critical?

b. For (4) above - the structure of model$Sol in the multi-response model
is complex and doesn't conform to the design matrix. I figure I need to melt
the design matrix but I'm unsure how to ensure I'm doing that in just the
same way as MCMCglmm.

c. Some of the same unanswered questions discussed here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023616.html  ,
- I suspect based on some of the discussions linked to above that the
procedure I outlined produces results that are marginalized over random
effects, but I'm not at all sure.
- What's the most appropriate way to generate CIs for predictions? If I'm
not wrong about (7), what's the best way to calculate those HPDs?

Here is the model I'm working with:

prior2 <- list(R=list(V=diag(3),nu=3), G=list(G1=list(V=diag(3),
nu=3.02, alpha.mu=rep(0,3),
alpha.V=1000*diag(3)), G2=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3),
alpha.V=1000*diag(3) ) ) )

m2b <- MCMCglmm(cbind(professional, relational, practice) ~
                 -1 + trait +
                 trait:income + trait:age + trait:ethnicity +
trait:gender + trait:residence + trait:education + trait:HDI +
trait:Ineq + trait:Enviro + trait:Enviro:gender + trait:Ineq:gender +
trait:Ineq:ethnicity + trait:Ineq:income,
               random= ~us(trait):block + us(trait):ID, rcov= ~us(trait):units,
               family=rep("gaussian",3),
               prior=prior2,
               nitt <- 80000, thin <- 25, burnin <- 50000,
               data=df_sel,
               verbose=TRUE)

Thank you immensely much for any help!

Warmly,

Rafter




















Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Tue Jul  7 14:07:17 2015
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 7 Jul 2015 14:07:17 +0200
Subject: [R-sig-ME] MCMCglmm predictions with new data for
	multi-response model
Message-ID: <CAAH-yP_T+Oaj-UqJsyJZnHDZ28T6DqDg4ghOPfb7uzh82Nb62A@mail.gmail.com>

Hi Rafter,

(a) You're on the right track.

(b) The design matrix is available at m2b$X. If you take a look, you'll see
how it's formatted. Something like temp <- as.matrix(m2b$X) %*% t(m2b$Sol)
should be what you want, just replacing "as.matrix(m2b$X)" with your new
data, in the same format.

(c.1) Because your outcomes are Gaussian, you don't need to do anything
with the random effects to generate predictions that are marginalized over
the random effects. That's only an issue for other sorts of outcomes
(binary, categorical, etc.). So your steps 5 and 6 are unnecessary. Your
"temp" is already your "pred_mat".

(c.2) I believe you're looking for apply(temp, 1, function(x)
HPDinterval(as.mcmc(x))).

Cheers,
Malcolm



Date: Mon, 6 Jul 2015 16:54:52 -0500
> From: rafter sass ferguson <liberationecology at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] MCMCglmm predictions with new data for
>         multi-response  model
>
> Dear list,
>
> I am hoping to generate predictions (with CIs) based on new data for a
> model with
> 3 Gaussian response variables and 1 blocking variable.
>
> A very similar and recent question hasn't received a substantive reply yet,
> here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023616.html
> .
> Jarrod mentioned on this list some months ago that a version of MCMCglmm
> that can predict with new data is imminent, but I haven't seen any signs of
> it -
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023329.html .
>
> I believe I understand the process as discussed here -
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q1/020065.html
>
> http://stackoverflow.com/questions/21057548/how-can-one-simulate-quantities-of-interest-from-the-posterior-density-in-mcmcgl
> ,
> http://glmm.wikidot.com/faq
>
> Here is my working understanding of the process:
> (1) Generate new data / prediction frame -> pred_frame
> (2) Generate fixed effects design matrix -> fix_dm
> (3) Extract chains of coefficients from Sol -> beta
> (4) Matrix-multiply  fix_dm * beta -> temp
> (5) Extract variance-covariance matrix as rowsums of mod$VCV -> V
> (6) Divide temp by sqrt(V) to get a matrix of predictions [i, j] with i =
> MCMC sample and j= new data point -> pred_mat
> (7) Generate CIs for predictions as HPDs of columns of pred_mat
>
> Here are my questions:
> a. Most broadly - am I on the right track, or have I totally misunderstood
> something critical?
>
> b. For (4) above - the structure of model$Sol in the multi-response model
> is complex and doesn't conform to the design matrix. I figure I need to
> melt
> the design matrix but I'm unsure how to ensure I'm doing that in just the
> same way as MCMCglmm.
>
> c. Some of the same unanswered questions discussed here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023616.html  ,
> - I suspect based on some of the discussions linked to above that the
> procedure I outlined produces results that are marginalized over random
> effects, but I'm not at all sure.
> - What's the most appropriate way to generate CIs for predictions? If I'm
> not wrong about (7), what's the best way to calculate those HPDs?
>
> Here is the model I'm working with:
>
> prior2 <- list(R=list(V=diag(3),nu=3), G=list(G1=list(V=diag(3),
> nu=3.02, alpha.mu=rep(0,3),
> alpha.V=1000*diag(3)), G2=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3),
> alpha.V=1000*diag(3) ) ) )
>
> m2b <- MCMCglmm(cbind(professional, relational, practice) ~
>                  -1 + trait +
>                  trait:income + trait:age + trait:ethnicity +
> trait:gender + trait:residence + trait:education + trait:HDI +
> trait:Ineq + trait:Enviro + trait:Enviro:gender + trait:Ineq:gender +
> trait:Ineq:ethnicity + trait:Ineq:income,
>                random= ~us(trait):block + us(trait):ID, rcov=
> ~us(trait):units,
>                family=rep("gaussian",3),
>                prior=prior2,
>                nitt <- 80000, thin <- 25, burnin <- 50000,
>                data=df_sel,
>                verbose=TRUE)
>
> Thank you immensely much for any help!
>
> Warmly,
>
> Rafter
>

	[[alternative HTML version deleted]]


From JSorkin at grecc.umaryland.edu  Tue Jul  7 18:08:13 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 07 Jul 2015 12:08:13 -0400
Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values)
 from don't agree . . . Why?????????
Message-ID: <559BC12D020000CB001320FA@smtp.medicine.umaryland.edu>

I am posting this message to this list (after posting to R help) at the
suggestion of Bert Gunter.
 
I am trying to fit data from 23 subjects using random effects
regression, and am comparing the results of lme and lmer. The point
estimates and the SEs are the same in both models, however the degrees
of freedom are widely different. lme reports 88 DF, lmer approximately
22. Can someone help me understand why the DFs are not the same? I have
23 subjects, each of whom is studied in up to five different
experimental conditions (i.e. Amp). For each condition multiple
measurements are made for each subject (i.e. X).
Thank you,
John
 
 

# lme: Random intercept, random slope.
cat("********This analysis has 88 degrees of freedom\n")
fit0X.new <- groupedData(X~Amp|SS,data=data,order.groups=FALSE)
xx <- lme(fit0X.new,random=~1+Amp)
summary(xx)
cat("\n\n")
 
 
# lmer: Random intercept, random slope.
cat("*********This analysis has ~22 degrees of freedom\n")
fit0X <- lmer(X~Amp+(1+Amp|SS),data=data)
print(summary(fit0X))
fit0XSum<-summary(fit0X)$coefficients
 
 
 
********This analysis has 88 degrees of freedom
Linear mixed-effects model fit by REML
 Data: fit0X.new 
       AIC      BIC    logLik
  331.7688 347.9717 -159.8844
Random effects:
 Formula: ~1 + Amp | SS
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr  
(Intercept) 1.3515911 (Intr)
Amp         2.5619953 -0.366
Residual    0.6139429       
Fixed effects: X ~ Amp 
               Value Std.Error DF   t-value p-value
(Intercept) 1.718376 0.3609133 88  4.761188       0
Amp         6.890429 0.5978236 88 11.525856       0
 Correlation: 
    (Intr)
Amp -0.526
Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max 
-2.2177007 -0.5770388 -0.1249565  0.5247444  4.1150164 
Number of Observations: 112
Number of Groups: 23 

*********This analysis has ~22 degrees of freedom
Linear mixed model fit by REML t-tests use Satterthwaite approximations
to degrees of freedom [merModLmerTest]
Formula: X ~ Amp + (1 + Amp | SS)
   Data: data
REML criterion at convergence: 319.8
Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.2177 -0.5770 -0.1250  0.5247  4.1150 
Random effects:
 Groups   Name        Variance Std.Dev. Corr 
 SS       (Intercept) 1.8268   1.3516        
          Amp         6.5638   2.5620   -0.37
 Residual             0.3769   0.6139        
Number of obs: 112, groups:  SS, 23
Fixed effects:
            Estimate Std. Error      df t value Pr(>|t|)    
(Intercept)   1.7184     0.3609 21.1150   4.761 0.000104 ***
Amp           6.8904     0.5978 22.0460  11.526 8.37e-11 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Correlation of Fixed Effects:
    (Intr)
Amp -0.526






John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From jake987722 at hotmail.com  Tue Jul  7 18:34:12 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Tue, 7 Jul 2015 10:34:12 -0600
Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values)
 from don't agree . . . Why?????????
In-Reply-To: <559BC12D020000CB001320FA@smtp.medicine.umaryland.edu>
References: <559BC12D020000CB001320FA@smtp.medicine.umaryland.edu>
Message-ID: <COL129-W10FEFCF69CE2CA3FDE6E22CB920@phx.gbl>

Hi John,

lmer does not use or report degrees of freedom on its own. It appears that you are getting degrees of freedom from the lmerTest package. Just for future reference.

The degrees of freedom from lme are based on an inner-outer rule that is described here: https://books.google.com/books?id=3TVDAAAAQBAJ&lpg=PR1&dq=pinheiro%20bates&pg=PA91#v=onepage&q&f=false

The degrees of freedom from lmerTest are based on Satterthwaite's approximation, described here: https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation

It looks like the "Amp" predictor is being treated by the models as a numeric, but you said it represents 5 experimental conditions? Should it not be a factor then?

Jake

> Date: Tue, 7 Jul 2015 12:08:13 -0400
> From: JSorkin at grecc.umaryland.edu
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values) from don't agree . . . Why?????????
> 
> I am posting this message to this list (after posting to R help) at the
> suggestion of Bert Gunter.
>  
> I am trying to fit data from 23 subjects using random effects
> regression, and am comparing the results of lme and lmer. The point
> estimates and the SEs are the same in both models, however the degrees
> of freedom are widely different. lme reports 88 DF, lmer approximately
> 22. Can someone help me understand why the DFs are not the same? I have
> 23 subjects, each of whom is studied in up to five different
> experimental conditions (i.e. Amp). For each condition multiple
> measurements are made for each subject (i.e. X).
> Thank you,
> John
>  
>  
> 
> # lme: Random intercept, random slope.
> cat("********This analysis has 88 degrees of freedom\n")
> fit0X.new <- groupedData(X~Amp|SS,data=data,order.groups=FALSE)
> xx <- lme(fit0X.new,random=~1+Amp)
> summary(xx)
> cat("\n\n")
>  
>  
> # lmer: Random intercept, random slope.
> cat("*********This analysis has ~22 degrees of freedom\n")
> fit0X <- lmer(X~Amp+(1+Amp|SS),data=data)
> print(summary(fit0X))
> fit0XSum<-summary(fit0X)$coefficients
>  
>  
>  
> ********This analysis has 88 degrees of freedom
> Linear mixed-effects model fit by REML
>  Data: fit0X.new 
>        AIC      BIC    logLik
>   331.7688 347.9717 -159.8844
> Random effects:
>  Formula: ~1 + Amp | SS
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev    Corr  
> (Intercept) 1.3515911 (Intr)
> Amp         2.5619953 -0.366
> Residual    0.6139429       
> Fixed effects: X ~ Amp 
>                Value Std.Error DF   t-value p-value
> (Intercept) 1.718376 0.3609133 88  4.761188       0
> Amp         6.890429 0.5978236 88 11.525856       0
>  Correlation: 
>     (Intr)
> Amp -0.526
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max 
> -2.2177007 -0.5770388 -0.1249565  0.5247444  4.1150164 
> Number of Observations: 112
> Number of Groups: 23 
> 
> *********This analysis has ~22 degrees of freedom
> Linear mixed model fit by REML t-tests use Satterthwaite approximations
> to degrees of freedom [merModLmerTest]
> Formula: X ~ Amp + (1 + Amp | SS)
>    Data: data
> REML criterion at convergence: 319.8
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -2.2177 -0.5770 -0.1250  0.5247  4.1150 
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr 
>  SS       (Intercept) 1.8268   1.3516        
>           Amp         6.5638   2.5620   -0.37
>  Residual             0.3769   0.6139        
> Number of obs: 112, groups:  SS, 23
> Fixed effects:
>             Estimate Std. Error      df t value Pr(>|t|)    
> (Intercept)   1.7184     0.3609 21.1150   4.761 0.000104 ***
> Amp           6.8904     0.5978 22.0460  11.526 8.37e-11 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Correlation of Fixed Effects:
>     (Intr)
> Amp -0.526
> 
> 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From bbolker at gmail.com  Tue Jul  7 18:53:26 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Jul 2015 12:53:26 -0400
Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values)
 from don't agree . . . Why?????????
In-Reply-To: <COL129-W10FEFCF69CE2CA3FDE6E22CB920@phx.gbl>
References: <559BC12D020000CB001320FA@smtp.medicine.umaryland.edu>
	<COL129-W10FEFCF69CE2CA3FDE6E22CB920@phx.gbl>
Message-ID: <CABghstSPM-5kuv6Y--Pqt8AzBQH-3hbpbxFqEpZG1zKjrP2Cyg@mail.gmail.com>

Following up/amplifying: the heuristic inner-outer algorithm that lme
uses to guess the degrees of freedom can definitely fail for
random-slopes models (I should probably add this to the GLMM FAQ if I
haven't already). Logically, because slope varies across
random-effects groups, we have effectively 22 df (number of groups-1)
for estimating the significance of the slope fixed effect. The
Satterthwaite approximation that lmerTest uses gets it right here (as
would ddf="Kenward-Roger" in lmerTest anova()).

  Good to have this stated for the record.


  cheers
     Ben Bolker

On Tue, Jul 7, 2015 at 12:34 PM, Jake Westfall <jake987722 at hotmail.com> wrote:
> Hi John,
>
> lmer does not use or report degrees of freedom on its own. It appears that you are getting degrees of freedom from the lmerTest package. Just for future reference.
>
> The degrees of freedom from lme are based on an inner-outer rule that is described here: https://books.google.com/books?id=3TVDAAAAQBAJ&lpg=PR1&dq=pinheiro%20bates&pg=PA91#v=onepage&q&f=false
>
> The degrees of freedom from lmerTest are based on Satterthwaite's approximation, described here: https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation
>
> It looks like the "Amp" predictor is being treated by the models as a numeric, but you said it represents 5 experimental conditions? Should it not be a factor then?
>
> Jake
>
>> Date: Tue, 7 Jul 2015 12:08:13 -0400
>> From: JSorkin at grecc.umaryland.edu
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values) from don't agree . . . Why?????????
>>
>> I am posting this message to this list (after posting to R help) at the
>> suggestion of Bert Gunter.
>>
>> I am trying to fit data from 23 subjects using random effects
>> regression, and am comparing the results of lme and lmer. The point
>> estimates and the SEs are the same in both models, however the degrees
>> of freedom are widely different. lme reports 88 DF, lmer approximately
>> 22. Can someone help me understand why the DFs are not the same? I have
>> 23 subjects, each of whom is studied in up to five different
>> experimental conditions (i.e. Amp). For each condition multiple
>> measurements are made for each subject (i.e. X).
>> Thank you,
>> John
>>
>>
>>
>> # lme: Random intercept, random slope.
>> cat("********This analysis has 88 degrees of freedom\n")
>> fit0X.new <- groupedData(X~Amp|SS,data=data,order.groups=FALSE)
>> xx <- lme(fit0X.new,random=~1+Amp)
>> summary(xx)
>> cat("\n\n")
>>
>>
>> # lmer: Random intercept, random slope.
>> cat("*********This analysis has ~22 degrees of freedom\n")
>> fit0X <- lmer(X~Amp+(1+Amp|SS),data=data)
>> print(summary(fit0X))
>> fit0XSum<-summary(fit0X)$coefficients
>>
>>
>>
>> ********This analysis has 88 degrees of freedom
>> Linear mixed-effects model fit by REML
>>  Data: fit0X.new
>>        AIC      BIC    logLik
>>   331.7688 347.9717 -159.8844
>> Random effects:
>>  Formula: ~1 + Amp | SS
>>  Structure: General positive-definite, Log-Cholesky parametrization
>>             StdDev    Corr
>> (Intercept) 1.3515911 (Intr)
>> Amp         2.5619953 -0.366
>> Residual    0.6139429
>> Fixed effects: X ~ Amp
>>                Value Std.Error DF   t-value p-value
>> (Intercept) 1.718376 0.3609133 88  4.761188       0
>> Amp         6.890429 0.5978236 88 11.525856       0
>>  Correlation:
>>     (Intr)
>> Amp -0.526
>> Standardized Within-Group Residuals:
>>        Min         Q1        Med         Q3        Max
>> -2.2177007 -0.5770388 -0.1249565  0.5247444  4.1150164
>> Number of Observations: 112
>> Number of Groups: 23
>>
>> *********This analysis has ~22 degrees of freedom
>> Linear mixed model fit by REML t-tests use Satterthwaite approximations
>> to degrees of freedom [merModLmerTest]
>> Formula: X ~ Amp + (1 + Amp | SS)
>>    Data: data
>> REML criterion at convergence: 319.8
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -2.2177 -0.5770 -0.1250  0.5247  4.1150
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  SS       (Intercept) 1.8268   1.3516
>>           Amp         6.5638   2.5620   -0.37
>>  Residual             0.3769   0.6139
>> Number of obs: 112, groups:  SS, 23
>> Fixed effects:
>>             Estimate Std. Error      df t value Pr(>|t|)
>> (Intercept)   1.7184     0.3609 21.1150   4.761 0.000104 ***
>> Amp           6.8904     0.5978 22.0460  11.526 8.37e-11 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> Correlation of Fixed Effects:
>>     (Intr)
>> Amp -0.526
>>
>>
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:12}}
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From thierry.onkelinx at inbo.be  Wed Jul  8 09:03:35 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 8 Jul 2015 09:03:35 +0200
Subject: [R-sig-ME] getting matrix-covariance matrices from a
	multivariate lme
In-Reply-To: <CALC46t9zRkXNMypzOXKuPpSeoxAGg-1bWfM=Ca8qATkWFC6N6w@mail.gmail.com>
References: <CALC46t9zRkXNMypzOXKuPpSeoxAGg-1bWfM=Ca8qATkWFC6N6w@mail.gmail.com>
Message-ID: <CAJuCY5y1GMoDEnfE3+3WST_Bqhkeh77N2UsN6LozGmSXpM0fcw@mail.gmail.com>

Dear David,

VarCorr() is indeed the tool you need to extract the variance-covariance of
the random effect.

You can set all covariances of the random effect to zero with pdDiag().

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-07-01 11:27 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:

> Dear list,
> I'm running a multivariate mixed model in lme. So far, I'm modeling only
> two response variables (dataset in long format), but the questions below
> applies as well to models with more response variables. I have been reading
> some documents produced by Ben Bolker available online (e.g. this
> <
> http://rstudio-pubs-static.s3.amazonaws.com/3336_03636030d93d47de9131e625b72f58c6.html
> >)
> but still I have some doubts.
>
> This is my model. I hope it is correctly specified: there is a single fixed
> effect ("month", continuous variable), different variances between traits
> and a correlation term to account for the temporal correlation of the
> replicates. "tim" is a timer variable, "id" is individual identity and
> "trait" is a factor variable with two levels in this simple case (the two
> response traits).
>
>
> lme21=lme(value~trait*poly(month,3)-1,data=long21,random=~trait-1|id,weights=varIdent(form=~1|trait),correlation=corAR1(form=~tim|id/trait))
>
> The summary:
> Linear mixed-effects model fit by REML
>  Data: long21
>        AIC      BIC   logLik
>   12364.22 12453.96 -6168.11
>
> Random effects:
>  Formula: ~trait - 1 | id
>  Structure: General positive-definite, Log-Cholesky parametrization
>          StdDev    Corr
> traitdvm 1.6190039 trtdvm
> traitsdl 0.1730272 0.702
> Residual 3.2393785
>
> Correlation Structure: ARMA(1,0)
>  Formula: ~tim | id/trait
>  Parameter estimate(s):
>      Phi1
> 0.5775275
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | trait
>  Parameter estimates:
>       dvm       sdl
> 1.0000000 0.1166486
> Fixed effects: value ~ trait * poly(month, 3) - 1
>                              Value Std.Error   DF   t-value p-value
> traitdvm                   2.85966  0.154334 4217 18.529065  0.0000
> traitsdl                   0.03629  0.017347 4217  2.092108  0.0365
> poly(month, 3)1           41.34481  5.323865 4217  7.765939  0.0000
> poly(month, 3)2          -14.49704  6.118856 4217 -2.369241  0.0179
> poly(month, 3)3          -30.73276  4.157736 4217 -7.391707  0.0000
> traitsdl:poly(month, 3)1 -44.68770  5.355425 4217 -8.344380  0.0000
> traitsdl:poly(month, 3)2  13.13565  6.149759 4217  2.135962  0.0327
> traitsdl:poly(month, 3)3  33.08326  4.183701 4217  7.907655  0.0000
>  Correlation:
>                          trtdvm trtsdl p(,3)1 p(,3)2 p(,3)3 t:(,3)1 t:(,3)2
> traitsdl                  0.297
> poly(month, 3)1           0.025 -0.001
> poly(month, 3)2           0.063  0.017 -0.006
> poly(month, 3)3          -0.037  0.001 -0.462  0.051
> traitsdl:poly(month, 3)1 -0.025  0.004 -0.993  0.006  0.459
> traitsdl:poly(month, 3)2 -0.060 -0.010  0.006 -0.993 -0.050 -0.006
> traitsdl:poly(month, 3)3  0.037 -0.006  0.459 -0.050 -0.993 -0.462   0.051
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -7.48299422 -0.52498105 -0.03120914  0.53723986  5.96432196
>
> Number of Observations: 4498
> Number of Groups: 274
>
> And these are my questions:
> 1- How can I get the random and residual variance-covariance matrices? Can
> they be extracted using VarCorr somehow? This is part of the output in
> MCMCglmm but in lme I haven't found the way to do it in lme so far...
> 2- How can I test the significance of the random covariances, i.e, if it is
> statistically different from zero? I guess a solution would be to fit a
> model with a constrained covariance (fixed to zero) and then compare
> models, but how would this be specified in the model?
>
> Thanks!!
>
> David
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From liberationecology at gmail.com  Thu Jul  9 01:03:10 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Wed, 8 Jul 2015 18:03:10 -0500
Subject: [R-sig-ME] MCMCglmm predictions with new data for
	multi-response model
In-Reply-To: <CAAH-yP_T+Oaj-UqJsyJZnHDZ28T6DqDg4ghOPfb7uzh82Nb62A@mail.gmail.com>
References: <CAAH-yP_T+Oaj-UqJsyJZnHDZ28T6DqDg4ghOPfb7uzh82Nb62A@mail.gmail.com>
Message-ID: <CAPNXFM46LgGb-rQvNNzv6p0muTbJ6oh2hdA+B667XH003UyQ9w@mail.gmail.com>

Thanks so much for your response. That is encouraging, and very helpful.
It's nice every once in a while to find out things are simpler than you
imagined.

Two quick notes for anyone who finds this discussion while googling about:
? I let MCMCglmm do the melting and formatting of my (new data) design
matrix (which could have been tricky, being multivariate). I generated my
prediction frame in standard 'wide' format, and then used it as an input
for a dummy model identical to my original model, and then pulled out X
from the dummy model.

? I was getting the non-conformable arguments error for a while, when I
tried to multiple t(Sol) by the design matrix. It took me a while to figure
out that I had to re-run my original model making sure pr=FALSE, as
retaining the random effects changes the structure of Sol.

Thanks again, Malcom!

~rafter


Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

On Tue, Jul 7, 2015 at 7:07 AM, Malcolm Fairbrother <
M.Fairbrother at bristol.ac.uk> wrote:

> Hi Rafter,
>
> (a) You're on the right track.
>
> (b) The design matrix is available at m2b$X. If you take a look, you'll
> see how it's formatted. Something like temp <- as.matrix(m2b$X) %*%
> t(m2b$Sol) should be what you want, just replacing "as.matrix(m2b$X)" with
> your new data, in the same format.
>
> (c.1) Because your outcomes are Gaussian, you don't need to do anything
> with the random effects to generate predictions that are marginalized over
> the random effects. That's only an issue for other sorts of outcomes
> (binary, categorical, etc.). So your steps 5 and 6 are unnecessary. Your
> "temp" is already your "pred_mat".
>
> (c.2) I believe you're looking for apply(temp, 1, function(x)
> HPDinterval(as.mcmc(x))).
>
> Cheers,
> Malcolm
>
>
>
> Date: Mon, 6 Jul 2015 16:54:52 -0500
>> From: rafter sass ferguson <liberationecology at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] MCMCglmm predictions with new data for
>>         multi-response  model
>>
>>
>> Dear list,
>>
>> I am hoping to generate predictions (with CIs) based on new data for a
>> model with
>> 3 Gaussian response variables and 1 blocking variable.
>>
>> A very similar and recent question hasn't received a substantive reply
>> yet,
>> here:
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023616.html .
>> Jarrod mentioned on this list some months ago that a version of MCMCglmm
>> that can predict with new data is imminent, but I haven't seen any signs
>> of
>> it -
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023329.html .
>>
>> I believe I understand the process as discussed here -
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q1/020065.html
>>
>> http://stackoverflow.com/questions/21057548/how-can-one-simulate-quantities-of-interest-from-the-posterior-density-in-mcmcgl
>> ,
>> http://glmm.wikidot.com/faq
>>
>> Here is my working understanding of the process:
>> (1) Generate new data / prediction frame -> pred_frame
>> (2) Generate fixed effects design matrix -> fix_dm
>> (3) Extract chains of coefficients from Sol -> beta
>> (4) Matrix-multiply  fix_dm * beta -> temp
>> (5) Extract variance-covariance matrix as rowsums of mod$VCV -> V
>> (6) Divide temp by sqrt(V) to get a matrix of predictions [i, j] with i =
>> MCMC sample and j= new data point -> pred_mat
>> (7) Generate CIs for predictions as HPDs of columns of pred_mat
>>
>> Here are my questions:
>> a. Most broadly - am I on the right track, or have I totally misunderstood
>> something critical?
>>
>> b. For (4) above - the structure of model$Sol in the multi-response model
>> is complex and doesn't conform to the design matrix. I figure I need to
>> melt
>> the design matrix but I'm unsure how to ensure I'm doing that in just the
>> same way as MCMCglmm.
>>
>> c. Some of the same unanswered questions discussed here:
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q2/023616.html  ,
>> - I suspect based on some of the discussions linked to above that the
>> procedure I outlined produces results that are marginalized over random
>> effects, but I'm not at all sure.
>> - What's the most appropriate way to generate CIs for predictions? If I'm
>> not wrong about (7), what's the best way to calculate those HPDs?
>>
>> Here is the model I'm working with:
>>
>> prior2 <- list(R=list(V=diag(3),nu=3), G=list(G1=list(V=diag(3),
>> nu=3.02, alpha.mu=rep(0,3),
>> alpha.V=1000*diag(3)), G2=list(V=diag(3), nu=3.02, alpha.mu=rep(0,3),
>> alpha.V=1000*diag(3) ) ) )
>>
>> m2b <- MCMCglmm(cbind(professional, relational, practice) ~
>>                  -1 + trait +
>>                  trait:income + trait:age + trait:ethnicity +
>> trait:gender + trait:residence + trait:education + trait:HDI +
>> trait:Ineq + trait:Enviro + trait:Enviro:gender + trait:Ineq:gender +
>> trait:Ineq:ethnicity + trait:Ineq:income,
>>                random= ~us(trait):block + us(trait):ID, rcov=
>> ~us(trait):units,
>>                family=rep("gaussian",3),
>>                prior=prior2,
>>                nitt <- 80000, thin <- 25, burnin <- 50000,
>>                data=df_sel,
>>                verbose=TRUE)
>>
>> Thank you immensely much for any help!
>>
>> Warmly,
>>
>> Rafter
>>
>

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Fri Jul 10 21:21:57 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 10 Jul 2015 15:21:57 -0400
Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values)
 from don't agree . . . Why?????????
References: 559BBA9C.medlxdom.medlxpo.200.20000CB.1.1320D6.1
Message-ID: <559FE315020000CB001327B2@smtp.medicine.umaryland.edu>

Forgive me for posting this again, I initially posted several days ago
and have yet to hear from anyone. Any help that can be offered would be
appreciated!
John
 
 
I am posting this message to this list (after posting to R help) at the
suggestion of Bert Gunter.
 
I am trying to fit data from 23 subjects using random effects
regression, and am comparing the results of lme and lmer. The point
estimates and the SEs are the same in both models, however the degrees
of freedom are widely different. lme reports 88 DF, lmer approximately
22. Can someone help me understand why the DFs are not the same? I have
23 subjects, each of whom is studied in up to five different
experimental conditions (i.e. Amp). For each condition multiple
measurements are made for each subject (i.e. X).
Thank you,
John
 
 

# lme: Random intercept, random slope.
cat("********This analysis has 88 degrees of freedom\n")
fit0X.new <- groupedData(X~Amp|SS,data=data,order.groups=FALSE)
xx <- lme(fit0X.new,random=~1+Amp)
summary(xx)
cat("\n\n")
 
 
# lmer: Random intercept, random slope.
cat("*********This analysis has ~22 degrees of freedom\n")
fit0X <- lmer(X~Amp+(1+Amp|SS),data=data)
print(summary(fit0X))
fit0XSum<-summary(fit0X)$coefficients
 
 
 
********This analysis has 88 degrees of freedom
Linear mixed-effects model fit by REML
 Data: fit0X.new 
       AIC      BIC    logLik
  331.7688 347.9717 -159.8844
Random effects:
 Formula: ~1 + Amp | SS
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr  
(Intercept) 1.3515911 (Intr)
Amp         2.5619953 -0.366
Residual    0.6139429       
Fixed effects: X ~ Amp 
               Value Std.Error DF   t-value p-value
(Intercept) 1.718376 0.3609133 88  4.761188       0
Amp         6.890429 0.5978236 88 11.525856       0
 Correlation: 
    (Intr)
Amp -0.526
Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max 
-2.2177007 -0.5770388 -0.1249565  0.5247444  4.1150164 
Number of Observations: 112
Number of Groups: 23 

*********This analysis has ~22 degrees of freedom
Linear mixed model fit by REML t-tests use Satterthwaite approximations
to degrees of freedom [merModLmerTest]
Formula: X ~ Amp + (1 + Amp | SS)
   Data: data
REML criterion at convergence: 319.8
Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.2177 -0.5770 -0.1250  0.5247  4.1150 
Random effects:
 Groups   Name        Variance Std.Dev. Corr 
 SS       (Intercept) 1.8268   1.3516        
          Amp         6.5638   2.5620   -0.37
 Residual             0.3769   0.6139        
Number of obs: 112, groups:  SS, 23
Fixed effects:
            Estimate Std. Error      df t value Pr(>|t|)    
(Intercept)   1.7184     0.3609 21.1150   4.761 0.000104 ***
Amp           6.8904     0.5978 22.0460  11.526 8.37e-11 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Correlation of Fixed Effects:
    (Intr)
Amp -0.526






John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(PThis email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From lizestats at gmail.com  Fri Jul 10 21:34:38 2015
From: lizestats at gmail.com (Lize van der Merwe)
Date: Fri, 10 Jul 2015 21:34:38 +0200
Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values)
	from don't agree . . . Why?????????
In-Reply-To: <559FE315020000CB001327B2@smtp.medicine.umaryland.edu>
References: 559BBA9C.medlxdom.medlxpo.200.20000CB.1.1320D6.1
	<559FE315020000CB001327B2@smtp.medicine.umaryland.edu>
Message-ID: <008001d0bb47$78fa3500$6aee9f00$@gmail.com>

John
I received a very detailed and clear explanation from Ben Bolker and John Westfall through this list on Tuesday.
Lize


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Sorkin
Sent: 10 July 2015 21:22
To: r-sig-mixed-models at r-project.org
Cc: lme4-authors at r-forge.wu-wien.ac.at
Subject: [R-sig-ME] lme and lmer degrees of freedom (and hence p values) from don't agree . . . Why?????????

Forgive me for posting this again, I initially posted several days ago and have yet to hear from anyone. Any help that can be offered would be appreciated!
John
 
 
I am posting this message to this list (after posting to R help) at the suggestion of Bert Gunter.
 
I am trying to fit data from 23 subjects using random effects regression, and am comparing the results of lme and lmer. The point estimates and the SEs are the same in both models, however the degrees of freedom are widely different. lme reports 88 DF, lmer approximately 22. Can someone help me understand why the DFs are not the same? I have
23 subjects, each of whom is studied in up to five different experimental conditions (i.e. Amp). For each condition multiple measurements are made for each subject (i.e. X).
Thank you,
John
 
 

# lme: Random intercept, random slope.
cat("********This analysis has 88 degrees of freedom\n") fit0X.new <- groupedData(X~Amp|SS,data=data,order.groups=FALSE)
xx <- lme(fit0X.new,random=~1+Amp)
summary(xx)
cat("\n\n")
 
 
# lmer: Random intercept, random slope.
cat("*********This analysis has ~22 degrees of freedom\n") fit0X <- lmer(X~Amp+(1+Amp|SS),data=data)
print(summary(fit0X))
fit0XSum<-summary(fit0X)$coefficients
 
 
 
********This analysis has 88 degrees of freedom Linear mixed-effects model fit by REML
 Data: fit0X.new 
       AIC      BIC    logLik
  331.7688 347.9717 -159.8844
Random effects:
 Formula: ~1 + Amp | SS
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr  
(Intercept) 1.3515911 (Intr)
Amp         2.5619953 -0.366
Residual    0.6139429       
Fixed effects: X ~ Amp 
               Value Std.Error DF   t-value p-value
(Intercept) 1.718376 0.3609133 88  4.761188       0
Amp         6.890429 0.5978236 88 11.525856       0
 Correlation: 
    (Intr)
Amp -0.526
Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max 
-2.2177007 -0.5770388 -0.1249565  0.5247444  4.1150164 Number of Observations: 112 Number of Groups: 23 

*********This analysis has ~22 degrees of freedom Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of freedom [merModLmerTest]
Formula: X ~ Amp + (1 + Amp | SS)
   Data: data
REML criterion at convergence: 319.8
Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.2177 -0.5770 -0.1250  0.5247  4.1150 Random effects:
 Groups   Name        Variance Std.Dev. Corr 
 SS       (Intercept) 1.8268   1.3516        
          Amp         6.5638   2.5620   -0.37
 Residual             0.3769   0.6139        
Number of obs: 112, groups:  SS, 23
Fixed effects:
            Estimate Std. Error      df t value Pr(>|t|)    
(Intercept)   1.7184     0.3609 21.1150   4.761 0.000104 ***
Amp           6.8904     0.5978 22.0460  11.526 8.37e-11 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Correlation of Fixed Effects:
    (Intr)
Amp -0.526






John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(PThis email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From JSorkin at grecc.umaryland.edu  Sat Jul 11 19:53:05 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 11 Jul 2015 13:53:05 -0400
Subject: [R-sig-ME] TEST: Please ignore this message,
 I am trying to determine why messages I send to the list are not
 forwarded to me Thank you, John
Message-ID: <55A11FC1020000CB00132897@smtp.medicine.umaryland.edu>

TEST: Please ignore this message, I am trying to determine why messages I send to the list are not forwarded to me      Thank you, John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From alexander.burren at bfh.ch  Wed Jul  8 01:09:28 2015
From: alexander.burren at bfh.ch (Alexander Burren)
Date: Wed, 8 Jul 2015 01:09:28 +0200
Subject: [R-sig-ME] glmer
Message-ID: <CADLNpBz5685w3ahKo5B7RPxWKPej2=M2S6rcDMu9Vj2Fkt3b=w@mail.gmail.com>

Dear all

I have a question about the package lme4. What ist the problem by
the following error?

convergence code: 0
unable to evaluate scaled gradient
Model failed to converge: degenerate  Hessian with 5 negative eigenvalues

Best regards

Alexander

-- 
Berne University of Applied Sciences
School of Agricultural, Forest and Food Sciences
Animal genetics group
Alexander Burren
Scientific collaborator
L?nggasse 85
CH-3052 Zollikofen
Switzerland
alexander.burren at bfh.ch

From elhamhaem at gmail.com  Wed Jul  8 10:18:58 2015
From: elhamhaem at gmail.com (elham haem)
Date: Wed, 8 Jul 2015 12:48:58 +0430
Subject: [R-sig-ME] nlmer function
Message-ID: <CAAoih8VcYJC4ESd-9oMabK9EU-ip-jb+7=tcSMKCWriaADZMbQ@mail.gmail.com>

Dear lme4 authors,


I have studied ?Mixed models in R using the lme4 package Part 6: Nonlinear
mixed models? by Douglas Bates. In this tutorial, there are some codes to
fit nonlinear mixed models for Theoph data. The codes are as fallows:



>Th. start <- c(lKe = -2.5, lKa = 0.5 , lCl = -3)

> nm1 <- nlmer ( conc ~ SSfol (Dose , Time ,lKe , lKa , lCl) ~

+    0+ lKe+lKa+lCl +(0+ lKe| Subject )+(0+ lKa| Subject )

+    +(0+ lCl| Subject ), nAGQ =0, Theoph ,

+     start = Th.start , verbose = TRUE )


I have 2 problems:

1. when I run these codes, I see this error:

Error: unexpected '=' in:

"+ +(0+ lCl| Subject ), nAGQ =0, Theoph ,

+ start ="

 2. I want to add a covariate (like age) to CL parameter. How should I
modify above codes?


Thanks in advance

Elham Haem

	[[alternative HTML version deleted]]


From sa.filahi at gmail.com  Fri Jul 10 11:00:42 2015
From: sa.filahi at gmail.com (Said Filahi)
Date: Fri, 10 Jul 2015 09:00:42 +0000
Subject: [R-sig-ME] portrait diagram
Message-ID: <CABNiEmmLV-8UTW81pn_QMfGgi4qDAhFc4=OesAEEuzb2ONbgpQ@mail.gmail.com>

Hello,
my name is Said and study in the university of science and technic
Casablanca, Morocco.

Now i work in the the trend in indice of extreme weather, and i want to
compare modele and observation to see whose modele is better

i have 27 indice (42 years serie) with 20 station (site) and 4 modele (each
modele 2 simulation eval and hist) and i want to use PORTRAIT DIAGRAM to
compare this modele.


I need help to make a script to do this portrait diagram


waiting for replay

thanks

Said

	[[alternative HTML version deleted]]


From federico.calboli at helsinki.fi  Sun Jul 12 16:48:43 2015
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Sun, 12 Jul 2015 17:48:43 +0300
Subject: [R-sig-ME] nlmer function
In-Reply-To: <CAAoih8VcYJC4ESd-9oMabK9EU-ip-jb+7=tcSMKCWriaADZMbQ@mail.gmail.com>
References: <CAAoih8VcYJC4ESd-9oMabK9EU-ip-jb+7=tcSMKCWriaADZMbQ@mail.gmail.com>
Message-ID: <FDD37C32-EEC8-41B3-B8F1-F39564849AC3@helsinki.fi>


> On 8 Jul 2015, at 11:18, elham haem <elhamhaem at gmail.com> wrote:
> 
> Dear lme4 authors,
> 
> 
> I have studied ?Mixed models in R using the lme4 package Part 6: Nonlinear
> mixed models? by Douglas Bates. In this tutorial, there are some codes to
> fit nonlinear mixed models for Theoph data. The codes are as fallows:
> 
> 
> 
>> Th. start <- c(lKe = -2.5, lKa = 0.5 , lCl = -3)
> 
>> nm1 <- nlmer ( conc ~ SSfol (Dose , Time ,lKe , lKa , lCl) ~
> 
> +    0+ lKe+lKa+lCl +(0+ lKe| Subject )+(0+ lKa| Subject )
> 
> +    +(0+ lCl| Subject ), nAGQ =0, Theoph ,
> 
> +     start = Th.start , verbose = TRUE )
> 
> 
> I have 2 problems:
> 
> 1. when I run these codes, I see this error:
> 
> Error: unexpected '=' in:
> 
> "+ +(0+ lCl| Subject ), nAGQ =0, Theoph ,
> 
> + start ="
> 
> 2. I want to add a covariate (like age) to CL parameter. How should I
> modify above codes?
> 

When you copy code verbatim from a pdf you copy the formatting, hence the code is unlikely to work.  This, which is lifted verbatim and fixed in a text editor by removing extra spaces in the formatting, and the line breaks, works.

library(lme4)
data(Theph)
Th.start <- c( lKe = -2.5 , lKa = 0.5 , lCl = -3)
nm1 <- nlmer ( conc ~ SSfol ( Dose , Time , lKe , lKa , lCl ) ~ 0+ lKe + lKa + lCl +(0+ lKe | Subject )+(0+ lKa | Subject ) +(0+ lCl | Subject ), nAGQ =0 , Theoph , start = Th.start , verbose = TRUE )




> 
> Thanks in advance
> 
> Elham Haem
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From federico.calboli at helsinki.fi  Sun Jul 12 16:52:42 2015
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Sun, 12 Jul 2015 17:52:42 +0300
Subject: [R-sig-ME] nlmer function
In-Reply-To: <FDD37C32-EEC8-41B3-B8F1-F39564849AC3@helsinki.fi>
References: <CAAoih8VcYJC4ESd-9oMabK9EU-ip-jb+7=tcSMKCWriaADZMbQ@mail.gmail.com>
	<FDD37C32-EEC8-41B3-B8F1-F39564849AC3@helsinki.fi>
Message-ID: <2D78FC44-83BE-4853-9CCF-844BF019CA79@helsinki.fi>


> On 12 Jul 2015, at 17:48, Federico Calboli <federico.calboli at helsinki.fi> wrote:
> 
> 
>> On 8 Jul 2015, at 11:18, elham haem <elhamhaem at gmail.com> wrote:
>> 
>> Dear lme4 authors,
>> 
>> 
>> I have studied ?Mixed models in R using the lme4 package Part 6: Nonlinear
>> mixed models? by Douglas Bates. In this tutorial, there are some codes to
>> fit nonlinear mixed models for Theoph data. The codes are as fallows:
>> 
>> 
>> 
>>> Th. start <- c(lKe = -2.5, lKa = 0.5 , lCl = -3)
>> 
>>> nm1 <- nlmer ( conc ~ SSfol (Dose , Time ,lKe , lKa , lCl) ~
>> 
>> +    0+ lKe+lKa+lCl +(0+ lKe| Subject )+(0+ lKa| Subject )
>> 
>> +    +(0+ lCl| Subject ), nAGQ =0, Theoph ,
>> 
>> +     start = Th.start , verbose = TRUE )
>> 
>> 
>> I have 2 problems:
>> 
>> 1. when I run these codes, I see this error:
>> 
>> Error: unexpected '=' in:
>> 
>> "+ +(0+ lCl| Subject ), nAGQ =0, Theoph ,
>> 
>> + start ="
>> 
>> 2. I want to add a covariate (like age) to CL parameter. How should I
>> modify above codes?
>> 
> 
> When you copy code verbatim from a pdf you copy the formatting, hence the code is unlikely to work.  This, which is lifted verbatim and fixed in a text editor by removing extra spaces in the formatting, and the line breaks, works.
> 
> library(lme4)
> data(Theph)

the most astute will notice the data is called ?Theoph' not ?Theph? 


> Th.start <- c( lKe = -2.5 , lKa = 0.5 , lCl = -3)
> nm1 <- nlmer ( conc ~ SSfol ( Dose , Time , lKe , lKa , lCl ) ~ 0+ lKe + lKa + lCl +(0+ lKe | Subject )+(0+ lKa | Subject ) +(0+ lCl | Subject ), nAGQ =0 , Theoph , start = Th.start , verbose = TRUE )
> 
> 
> 
> 
>> 
>> Thanks in advance
>> 
>> Elham Haem
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
> 
> federico.calboli at helsinki.fi
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From r.turner at auckland.ac.nz  Sun Jul 12 23:20:32 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 13 Jul 2015 09:20:32 +1200
Subject: [R-sig-ME] [FORGED]  portrait diagram
In-Reply-To: <CABNiEmmLV-8UTW81pn_QMfGgi4qDAhFc4=OesAEEuzb2ONbgpQ@mail.gmail.com>
References: <CABNiEmmLV-8UTW81pn_QMfGgi4qDAhFc4=OesAEEuzb2ONbgpQ@mail.gmail.com>
Message-ID: <55A2DA20.3070005@auckland.ac.nz>


On 10/07/15 21:00, Said Filahi wrote:

> Hello,
> my name is Said and study in the university of science and technic
> Casablanca, Morocco.
>
> Now i work in the the trend in indice of extreme weather, and i want to
> compare modele and observation to see whose modele is better
>
> i have 27 indice (42 years serie) with 20 station (site) and 4 modele (each
> modele 2 simulation eval and hist) and i want to use PORTRAIT DIAGRAM to
> compare this modele.
>
>
> I need help to make a script to do this portrait diagram
>
>
> waiting for replay

You'll have a long wait unless you ask a more perspicuous question.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bbolker at gmail.com  Sun Jul 12 23:53:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 12 Jul 2015 17:53:00 -0400
Subject: [R-sig-ME] [FORGED]  portrait diagram
In-Reply-To: <55A2DA20.3070005@auckland.ac.nz>
References: <CABNiEmmLV-8UTW81pn_QMfGgi4qDAhFc4=OesAEEuzb2ONbgpQ@mail.gmail.com>
	<55A2DA20.3070005@auckland.ac.nz>
Message-ID: <55A2E1BC.5020703@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-07-12 05:20 PM, Rolf Turner wrote:
> 
> On 10/07/15 21:00, Said Filahi wrote:
> 
>> Hello, my name is Said and study in the university of science and
>> technic Casablanca, Morocco.
>> 
>> Now i work in the the trend in indice of extreme weather, and i
>> want to compare modele and observation to see whose modele is
>> better
>> 
>> i have 27 indice (42 years serie) with 20 station (site) and 4
>> modele (each modele 2 simulation eval and hist) and i want to use
>> PORTRAIT DIAGRAM to compare this modele.
>> 
>> 
>> I need help to make a script to do this portrait diagram
>> 
>> 
>> waiting for replay
> 
> You'll have a long wait unless you ask a more perspicuous
> question.
> 
> cheers,
> 
> Rolf Turner


  A bit of googling (which should not be necessary -- users should try
to provide some context for their question, keeping in mind that list
readers are from a wide variety of backgrounds) points to this
http://www-pcmdi.llnl.gov/publications/pdf/rpt69.pdf for the probable
definition of a "portrait diagram".

  But you really, really need to give us more to go on.  Reproducible
example, please?  What have you tried/found so far?  Are there other
implementations you can point to? Also, it's not at all clear that
this is really a mixed model question.

  Ben Bolker



-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVouG8AAoJEOCV5YRblxUHKJsH/ipqT95GZglc292puCOtnigV
sr8WDa0bojcR54E6ugXdRjtZOxOx63fdngYTdl5QzlZY/Izop/0A2y5Mz3nOm8/e
b3+WFeVAAUKogB/tUbU5nv/r/EdZXZ/JS4uQu2H0nlB6ZzaQ4krHbBiOzMBYUUQl
wSVLcrM6u8xXd8+Qzm0bI8ioL0oxCGSzpP8CWrfdKuADA921WjDzz5cTkCd69Rh0
tocI5w8Zyc8vDUllLwtDqGhDjo49dahEfnAPvpChLi7ID2yMFN/kH7nrijdDC1vD
+5/j9Nv32Q3YWUUO3X+CY8xKLeRRYh+gUadprxb5zgDUuWnEuQSG24FOpQcSy3M=
=Qyek
-----END PGP SIGNATURE-----


From bates at stat.wisc.edu  Mon Jul 13 23:01:07 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Jul 2015 21:01:07 +0000
Subject: [R-sig-ME] Comparing optimizers for lmer
Message-ID: <CAO7JsnSo9WVqOSbYWxOd0OM1FTWLaYyvt_6L1SfBbwHHfS=R5Q@mail.gmail.com>

Colin Longhurst and I have been comparing optimizers with lmer on several
examples of linear mixed-effects models.  We included gradient-based and
derivative-free optimizers using lmm from the MixedModels package for Julia
in our comparisons.

The results are available as a github repository in the form or an R
package. It is installed by first installing the devtools package then
running

devtools::install_github("Stat990-033/Timings")

A summary of the results in the form of an IPython (or IJulia, in this
case) notebook can be accessed as

https://github.com/Stat990-033/Timings/blob/master/inst/doc/Summaries.ipynb

This should display as a notebook in your browser.  If you clone the
repository and have Julia installed along with the packages required, you
can rerun the results on your computer to see what timings it gives.

The bottom line is that the most reliable of the optimizers we tried in R
are NLOPT_LN_BOBYQA from the nloptr package and L-BFGS-B and nlminb from
the optimx package.  Of these NLOPT_LN_BOBYQA is generally the fastest and
I have recommended to my co-authors of the lme4 package that it become the
default.

	[[alternative HTML version deleted]]


From steven.v.miller at gmail.com  Wed Jul 15 02:53:01 2015
From: steven.v.miller at gmail.com (svm)
Date: Tue, 14 Jul 2015 20:53:01 -0400
Subject: [R-sig-ME] Perfectly correlated random effects (when they shouldn't
	be)
Message-ID: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>

Hi all,

I'm a long-time reader and wanted to raise a question I've seen asked here
before about correlated random effects. Past answers I have encountered on
this listserv explain that perfectly correlated random effects suggest
model overfitting and variances of random effects that are effectively zero
and can be omitted for a simpler model. In my case, I don't think that's
what is happening here, though I could well be fitting a poor model in
glmer.

I'll describe the nature of the data first. I'm modeling individual-level
survey data for countries across multiple waves and am estimating the
region of the globe as a random effect as well. I have three random effects
(country, country-wave, and region). In the region random effect, I am
allowing country-wave-level predictors to have varying slopes. My inquiry
is whether some country-wave-level contextual indicator can have an overall
effect (as a fixed effect), the effect of which can vary by region. In
other words: is the effect of some country-level indicator (e.g.
unemployment) in a given year different for countries in Western Europe
than for countries in Africa even if, on average, there is a positive or
negative association at the individual-level? These country-wave-level
predictors that I allow to vary by region are the ones reporting perfect
correlation and I'm unsure how to interpret that (or if I'm estimating the
model correctly).

I should also add that I have individual-level predictors as well as
country-wave-level predictors, though it's the latter that concerns me.
Further, every non-binary indicator in the model is standardized by two
standard deviations.

For those interested, I have a reproducible (if rather large) example
below. Dropbox link to the data is here:
https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0

In this reproducible example, y is the outcome variable and x1 and x2 are
two country-wave-level predictors I allow to vary by region. Both x1 and x2
are interval-level predictors that I standardized to have a mean of zero
and a standard deviation of .5 (per Gelman's (2008) recommendation).

I estimate the following model.

summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 +
x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))

The results are theoretically intuitive. I think they make sense. However,
I get a report of perfect correlation for the varying slopes of the region
random effect.

Random effects:
 Groups       Name        Variance Std.Dev. Corr
 country:wave (Intercept) 0.15915  0.3989
 country      (Intercept) 0.32945  0.5740
 region       (Intercept) 0.01646  0.1283
              x1          0.02366  0.1538    1.00
              x2          0.13994  0.3741   -1.00 -1.00
Number of obs: 212570, groups:  country:wave, 143; country, 82; region, 6

What should I make of this and am I estimating this model wrong? For what
it's worth, the dotplot of the region random effect (with conditional
variance) makes sense and is theoretically intuitive, given my data. (
http://i.imgur.com/mrnaJ77.png)

Any help would be greatly appreciated.

Best regards,
Steve

	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Wed Jul 15 03:07:37 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Tue, 14 Jul 2015 19:07:37 -0600
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
Message-ID: <COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>

Hi Steve,

I think the issue is that estimating 3 variances and 3 covariances for regions is quite ambitious given that there are only 6 regions. I think it's not surprising that the model has a hard time getting good estimates of those parameters.

Jake

> Date: Tue, 14 Jul 2015 20:53:01 -0400
> From: steven.v.miller at gmail.com
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Perfectly correlated random effects (when they shouldn't	be)
> 
> Hi all,
> 
> I'm a long-time reader and wanted to raise a question I've seen asked here
> before about correlated random effects. Past answers I have encountered on
> this listserv explain that perfectly correlated random effects suggest
> model overfitting and variances of random effects that are effectively zero
> and can be omitted for a simpler model. In my case, I don't think that's
> what is happening here, though I could well be fitting a poor model in
> glmer.
> 
> I'll describe the nature of the data first. I'm modeling individual-level
> survey data for countries across multiple waves and am estimating the
> region of the globe as a random effect as well. I have three random effects
> (country, country-wave, and region). In the region random effect, I am
> allowing country-wave-level predictors to have varying slopes. My inquiry
> is whether some country-wave-level contextual indicator can have an overall
> effect (as a fixed effect), the effect of which can vary by region. In
> other words: is the effect of some country-level indicator (e.g.
> unemployment) in a given year different for countries in Western Europe
> than for countries in Africa even if, on average, there is a positive or
> negative association at the individual-level? These country-wave-level
> predictors that I allow to vary by region are the ones reporting perfect
> correlation and I'm unsure how to interpret that (or if I'm estimating the
> model correctly).
> 
> I should also add that I have individual-level predictors as well as
> country-wave-level predictors, though it's the latter that concerns me.
> Further, every non-binary indicator in the model is standardized by two
> standard deviations.
> 
> For those interested, I have a reproducible (if rather large) example
> below. Dropbox link to the data is here:
> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
> 
> In this reproducible example, y is the outcome variable and x1 and x2 are
> two country-wave-level predictors I allow to vary by region. Both x1 and x2
> are interval-level predictors that I standardized to have a mean of zero
> and a standard deviation of .5 (per Gelman's (2008) recommendation).
> 
> I estimate the following model.
> 
> summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 +
> x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))
> 
> The results are theoretically intuitive. I think they make sense. However,
> I get a report of perfect correlation for the varying slopes of the region
> random effect.
> 
> Random effects:
>  Groups       Name        Variance Std.Dev. Corr
>  country:wave (Intercept) 0.15915  0.3989
>  country      (Intercept) 0.32945  0.5740
>  region       (Intercept) 0.01646  0.1283
>               x1          0.02366  0.1538    1.00
>               x2          0.13994  0.3741   -1.00 -1.00
> Number of obs: 212570, groups:  country:wave, 143; country, 82; region, 6
> 
> What should I make of this and am I estimating this model wrong? For what
> it's worth, the dotplot of the region random effect (with conditional
> variance) makes sense and is theoretically intuitive, given my data. (
> http://i.imgur.com/mrnaJ77.png)
> 
> Any help would be greatly appreciated.
> 
> Best regards,
> Steve
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From steven.v.miller at gmail.com  Wed Jul 15 03:45:12 2015
From: steven.v.miller at gmail.com (svm)
Date: Tue, 14 Jul 2015 21:45:12 -0400
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
Message-ID: <CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>

I considered that. I disaggregated the region random effect from 6 to 18
(the latter of which approximates the World Bank's region classification).
I'm still encountering the same curious issue.

Random effects:
 Groups       Name        Variance  Std.Dev. Corr
 country:wave (Intercept) 0.1530052 0.39116
 country      (Intercept) 0.3735876 0.61122
 wbregion     (Intercept) 0.0137822 0.11740
              x1        0.0009384 0.03063  -1.00
              x2         0.0767387 0.27702  -1.00  1.00
Number of obs: 212570, groups:  country:wave, 143; country, 82; wbregion, 18

 For what it's worth: the model estimates fine. The results are intuitive
and theoretically consistent. They also don't change if I were to remove
that region random effect. I'd like to keep the region random effect (with
varying slopes) in the model. I'm struggling with what I should think about
the perfect correlations.

On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall <jake987722 at hotmail.com>
wrote:

> Hi Steve,
>
>
> I think the issue is that estimating 3 variances and 3 covariances for
> regions is quite ambitious given that there are only 6 regions. I think
> it's not surprising that the model has a hard time getting good estimates
> of those parameters.
>
>
> Jake
>
> > Date: Tue, 14 Jul 2015 20:53:01 -0400
> > From: steven.v.miller at gmail.com
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Perfectly correlated random effects (when they
> shouldn't be)
>
> >
> > Hi all,
> >
> > I'm a long-time reader and wanted to raise a question I've seen asked
> here
> > before about correlated random effects. Past answers I have encountered
> on
> > this listserv explain that perfectly correlated random effects suggest
> > model overfitting and variances of random effects that are effectively
> zero
> > and can be omitted for a simpler model. In my case, I don't think that's
> > what is happening here, though I could well be fitting a poor model in
> > glmer.
> >
> > I'll describe the nature of the data first. I'm modeling individual-level
> > survey data for countries across multiple waves and am estimating the
> > region of the globe as a random effect as well. I have three random
> effects
> > (country, country-wave, and region). In the region random effect, I am
> > allowing country-wave-level predictors to have varying slopes. My inquiry
> > is whether some country-wave-level contextual indicator can have an
> overall
> > effect (as a fixed effect), the effect of which can vary by region. In
> > other words: is the effect of some country-level indicator (e.g.
> > unemployment) in a given year different for countries in Western Europe
> > than for countries in Africa even if, on average, there is a positive or
> > negative association at the individual-level? These country-wave-level
> > predictors that I allow to vary by region are the ones reporting perfect
> > correlation and I'm unsure how to interpret that (or if I'm estimating
> the
> > model correctly).
> >
> > I should also add that I have individual-level predictors as well as
> > country-wave-level predictors, though it's the latter that concerns me.
> > Further, every non-binary indicator in the model is standardized by two
> > standard deviations.
> >
> > For those interested, I have a reproducible (if rather large) example
> > below. Dropbox link to the data is here:
> >
> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
> >
> > In this reproducible example, y is the outcome variable and x1 and x2 are
> > two country-wave-level predictors I allow to vary by region. Both x1 and
> x2
> > are interval-level predictors that I standardized to have a mean of zero
> > and a standard deviation of .5 (per Gelman's (2008) recommendation).
> >
> > I estimate the following model.
> >
> > summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) +
> (1 +
> > x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))
> >
> > The results are theoretically intuitive. I think they make sense.
> However,
> > I get a report of perfect correlation for the varying slopes of the
> region
> > random effect.
> >
> > Random effects:
> > Groups Name Variance Std.Dev. Corr
> > country:wave (Intercept) 0.15915 0.3989
> > country (Intercept) 0.32945 0.5740
> > region (Intercept) 0.01646 0.1283
> > x1 0.02366 0.1538 1.00
> > x2 0.13994 0.3741 -1.00 -1.00
> > Number of obs: 212570, groups: country:wave, 143; country, 82; region, 6
> >
> > What should I make of this and am I estimating this model wrong? For what
> > it's worth, the dotplot of the region random effect (with conditional
> > variance) makes sense and is theoretically intuitive, given my data. (
> > http://i.imgur.com/mrnaJ77.png)
> >
> > Any help would be greatly appreciated.
> >
> > Best regards,
> > Steve
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Steven V. Miller
Assistant Professor
Department of Political Science
Clemson University
http://svmiller.com

	[[alternative HTML version deleted]]


From reinhold.kliegl at gmail.com  Wed Jul 15 10:57:29 2015
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 15 Jul 2015 10:57:29 +0200
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
Message-ID: <CAG+WrEyULQWVoTOYOM7Gf-ANcYz3ARj2fPgRW2ArLcV01sE0Tg@mail.gmail.com>

It looks like your model is overparameterized. Specifically, although you
have a very large number of observations (N=212570),  the data do not
support the six model parameters you try to estimate for the random-effects
term of region. You can see this quickly with the rePCA() function. There
was also a convergence warning for me, but perhaps this was due to the fact
that I worked with the full set (as provided in the dropbox file), whereas
you used a subset.

As a first step, I forced the correlation parameters to zero with the
||-syntax (zcpM1 GLMM below). A LRT suggests that dropping the three
correlation parameters does not decrease the goodness of fit; Chi-sq(3) =
1.9, p=.5959.  This could very well be a consequence of the small number of
regions, as Jake pointed out; and even 18 regions may not be enough for a
reliable estimation of three correlation parameters.

Moreover, the rePCA() suggests that even the three remaining model
parameters for the random-effects term of region are quite marginally
supported by the data. In the zero-correlation parameter GLMM, the variance
component for x1 was estimated to be suspiciously small.  Therefore, in a
second step, I removed the region-related x1 variance component . Again,
according to a LRT there was no significant loss in goodness of fit;
Chi-sq(1) = 0.

The R script is inserted below. Please note that taking a correlation
parameter or a variance component out of a model does not mean that it is
zero, but that the data do not support a model that assumes that it is
different from zero.  zcpM2 (below) looks like an adequate parsimonious
GLMM for these data.


###

# Note: The original post used a subset of the data, but it is not clear
how they were selected. I used all the data.

library(lme4)
library(RePsychLing)
data <- read.csv("correlated-random-effects.csv", header=TRUE)
str(data)
data$country <- factor(data$country)
data$region <- factor(data$region)

# no convergence problem
print(summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) +
                          (1 +  x1 + x2 | region), data=data,
family=binomial(link="logit"))))

summary(rePCA(M1))

# convergence problem
print(summary(zcpM1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
country:wave) +
                             (1 +  x1 + x2 || region), data=data,
family=binomial(link="logit"))))
summary(rePCA(zcpM1))

# ok
print(summary(zcpM2 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
country:wave) +
                                   (1 + x2 || region), data=data,
family=binomial(link="logit"))))
summary(rePCA(zcpM2))

anova(zcpM2, zcpM1, M1)

####




On Wed, Jul 15, 2015 at 3:45 AM, svm <steven.v.miller at gmail.com> wrote:

> I considered that. I disaggregated the region random effect from 6 to 18
> (the latter of which approximates the World Bank's region classification).
> I'm still encountering the same curious issue.
>
> Random effects:
>  Groups       Name        Variance  Std.Dev. Corr
>  country:wave (Intercept) 0.1530052 0.39116
>  country      (Intercept) 0.3735876 0.61122
>  wbregion     (Intercept) 0.0137822 0.11740
>               x1        0.0009384 0.03063  -1.00
>               x2         0.0767387 0.27702  -1.00  1.00
> Number of obs: 212570, groups:  country:wave, 143; country, 82; wbregion,
> 18
>
>  For what it's worth: the model estimates fine. The results are intuitive
> and theoretically consistent. They also don't change if I were to remove
> that region random effect. I'd like to keep the region random effect (with
> varying slopes) in the model. I'm struggling with what I should think about
> the perfect correlations.
>
> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall <jake987722 at hotmail.com>
> wrote:
>
> > Hi Steve,
> >
> >
> > I think the issue is that estimating 3 variances and 3 covariances for
> > regions is quite ambitious given that there are only 6 regions. I think
> > it's not surprising that the model has a hard time getting good estimates
> > of those parameters.
> >
> >
> > Jake
> >
> > > Date: Tue, 14 Jul 2015 20:53:01 -0400
> > > From: steven.v.miller at gmail.com
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Perfectly correlated random effects (when they
> > shouldn't be)
> >
> > >
> > > Hi all,
> > >
> > > I'm a long-time reader and wanted to raise a question I've seen asked
> > here
> > > before about correlated random effects. Past answers I have encountered
> > on
> > > this listserv explain that perfectly correlated random effects suggest
> > > model overfitting and variances of random effects that are effectively
> > zero
> > > and can be omitted for a simpler model. In my case, I don't think
> that's
> > > what is happening here, though I could well be fitting a poor model in
> > > glmer.
> > >
> > > I'll describe the nature of the data first. I'm modeling
> individual-level
> > > survey data for countries across multiple waves and am estimating the
> > > region of the globe as a random effect as well. I have three random
> > effects
> > > (country, country-wave, and region). In the region random effect, I am
> > > allowing country-wave-level predictors to have varying slopes. My
> inquiry
> > > is whether some country-wave-level contextual indicator can have an
> > overall
> > > effect (as a fixed effect), the effect of which can vary by region. In
> > > other words: is the effect of some country-level indicator (e.g.
> > > unemployment) in a given year different for countries in Western Europe
> > > than for countries in Africa even if, on average, there is a positive
> or
> > > negative association at the individual-level? These country-wave-level
> > > predictors that I allow to vary by region are the ones reporting
> perfect
> > > correlation and I'm unsure how to interpret that (or if I'm estimating
> > the
> > > model correctly).
> > >
> > > I should also add that I have individual-level predictors as well as
> > > country-wave-level predictors, though it's the latter that concerns me.
> > > Further, every non-binary indicator in the model is standardized by two
> > > standard deviations.
> > >
> > > For those interested, I have a reproducible (if rather large) example
> > > below. Dropbox link to the data is here:
> > >
> >
> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
> > >
> > > In this reproducible example, y is the outcome variable and x1 and x2
> are
> > > two country-wave-level predictors I allow to vary by region. Both x1
> and
> > x2
> > > are interval-level predictors that I standardized to have a mean of
> zero
> > > and a standard deviation of .5 (per Gelman's (2008) recommendation).
> > >
> > > I estimate the following model.
> > >
> > > summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) +
> > (1 +
> > > x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))
> > >
> > > The results are theoretically intuitive. I think they make sense.
> > However,
> > > I get a report of perfect correlation for the varying slopes of the
> > region
> > > random effect.
> > >
> > > Random effects:
> > > Groups Name Variance Std.Dev. Corr
> > > country:wave (Intercept) 0.15915 0.3989
> > > country (Intercept) 0.32945 0.5740
> > > region (Intercept) 0.01646 0.1283
> > > x1 0.02366 0.1538 1.00
> > > x2 0.13994 0.3741 -1.00 -1.00
> > > Number of obs: 212570, groups: country:wave, 143; country, 82; region,
> 6
> > >
> > > What should I make of this and am I estimating this model wrong? For
> what
> > > it's worth, the dotplot of the region random effect (with conditional
> > > variance) makes sense and is theoretically intuitive, given my data. (
> > > http://i.imgur.com/mrnaJ77.png)
> > >
> > > Any help would be greatly appreciated.
> > >
> > > Best regards,
> > > Steve
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
> Steven V. Miller
> Assistant Professor
> Department of Political Science
> Clemson University
> http://svmiller.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From reinhold.kliegl at gmail.com  Wed Jul 15 13:25:44 2015
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 15 Jul 2015 13:25:44 +0200
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CAG+WrEyULQWVoTOYOM7Gf-ANcYz3ARj2fPgRW2ArLcV01sE0Tg@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAG+WrEyULQWVoTOYOM7Gf-ANcYz3ARj2fPgRW2ArLcV01sE0Tg@mail.gmail.com>
Message-ID: <CAG+WrEwuXu9y0u-UL4UjtuO5z3NgNMOekmzG4Q+QGNVeiHamjg@mail.gmail.com>

Actually, I overlooked that the region-related variance component of x2 can
also be removed from the GLMM without loss of goodness of fit. Thus, I end
up with an intercept-only GLMM as the most parsimonious model for this data
set. Here is the anova() output:

> anova(zcpM3, zcpM2, zcpM1, M1)
Data: data
Models:
zcpM3: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 | region)
zcpM2: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x2 || region)
zcpM1: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 + x2 ||
region)
M1: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 + x2 |
region)
      Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
zcpM3  6 258193 258255 -129091   258181                          (only
intercept, parsimonious GLMM)
zcpM2  7 258195 258267 -129091   258181 0.1882      1     0.6644
zcpM1  8 258197 258279 -129091   258181 0.0000      1     1.0000
M1    11 258201 258314 -129090   258179 1.8885      3     0.5959
(overparameterized max GLMM)

There is another interesting aspect to this reduction of model complexity.
The parsimonious GLMM yields the SMALLEST z-value for the significant fixed
effect of x1. Thus, this is a counterexample to the claim that maximal
models are always anti-conservative. Whether this is the case or not may
depend on whether the maximal model is overparameterized or not. Here are
the corresponding fixed-effect estimates for x1 and x2:

Fixed effects for x1 across GLMMs:
                    Estimate Std. Error z value Pr(>|z|)
zcpM3: x1           0.51004    0.23859    2.138  0.0325 *  (only intercept,
parsimonious GLMM)
zcpM2: x1           0.515822   0.167005   3.089  0.00201 **
zcpM1: x1           0.516168   0.149704   3.448  0.000565 ***
M1:    x1           0.48913    0.19972    2.449  0.0143 *
 (overparameterized max GLMM)

Fixed effects for x2 across GLMMs:
zcpM3: x2          -0.02743    0.15881   -0.173  0.8629    (only intercept,
parsimonious GLMM)
zcpM2: x2          -0.008715   0.151586  -0.057  0.95416
zcpM1: x2          -0.008701   0.155332  -0.056  0.955331
M1:    x2           0.04422    0.17376    0.254  0.7991
 (overparameterized max GLMM)

On Wed, Jul 15, 2015 at 10:57 AM, Reinhold Kliegl <reinhold.kliegl at gmail.com
> wrote:

> It looks like your model is overparameterized. Specifically, although you
> have a very large number of observations (N=212570),  the data do not
> support the six model parameters you try to estimate for the random-effects
> term of region. You can see this quickly with the rePCA() function. There
> was also a convergence warning for me, but perhaps this was due to the fact
> that I worked with the full set (as provided in the dropbox file), whereas
> you used a subset.
>
> As a first step, I forced the correlation parameters to zero with the
> ||-syntax (zcpM1 GLMM below). A LRT suggests that dropping the three
> correlation parameters does not decrease the goodness of fit; Chi-sq(3) =
> 1.9, p=.5959.  This could very well be a consequence of the small number of
> regions, as Jake pointed out; and even 18 regions may not be enough for a
> reliable estimation of three correlation parameters.
>
> Moreover, the rePCA() suggests that even the three remaining model
> parameters for the random-effects term of region are quite marginally
> supported by the data. In the zero-correlation parameter GLMM, the variance
> component for x1 was estimated to be suspiciously small.  Therefore, in a
> second step, I removed the region-related x1 variance component . Again,
> according to a LRT there was no significant loss in goodness of fit;
> Chi-sq(1) = 0.
>
> The R script is inserted below. Please note that taking a correlation
> parameter or a variance component out of a model does not mean that it is
> zero, but that the data do not support a model that assumes that it is
> different from zero.  zcpM2 (below) looks like an adequate parsimonious
> GLMM for these data.
>
>
> ###
>
> # Note: The original post used a subset of the data, but it is not clear
> how they were selected. I used all the data.
>
> library(lme4)
> library(RePsychLing)
> data <- read.csv("correlated-random-effects.csv", header=TRUE)
> str(data)
> data$country <- factor(data$country)
> data$region <- factor(data$region)
>
> # no convergence problem
> print(summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave)
> +
>                           (1 +  x1 + x2 | region), data=data,
> family=binomial(link="logit"))))
>
> summary(rePCA(M1))
>
> # convergence problem
> print(summary(zcpM1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
> country:wave) +
>                              (1 +  x1 + x2 || region), data=data,
> family=binomial(link="logit"))))
> summary(rePCA(zcpM1))
>
> # ok
> print(summary(zcpM2 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
> country:wave) +
>                                    (1 + x2 || region), data=data,
> family=binomial(link="logit"))))
> summary(rePCA(zcpM2))
>
> anova(zcpM2, zcpM1, M1)
>
> ####
>
>
>
>
> On Wed, Jul 15, 2015 at 3:45 AM, svm <steven.v.miller at gmail.com> wrote:
>
>> I considered that. I disaggregated the region random effect from 6 to 18
>> (the latter of which approximates the World Bank's region classification).
>> I'm still encountering the same curious issue.
>>
>> Random effects:
>>  Groups       Name        Variance  Std.Dev. Corr
>>  country:wave (Intercept) 0.1530052 0.39116
>>  country      (Intercept) 0.3735876 0.61122
>>  wbregion     (Intercept) 0.0137822 0.11740
>>               x1        0.0009384 0.03063  -1.00
>>               x2         0.0767387 0.27702  -1.00  1.00
>> Number of obs: 212570, groups:  country:wave, 143; country, 82; wbregion,
>> 18
>>
>>  For what it's worth: the model estimates fine. The results are intuitive
>> and theoretically consistent. They also don't change if I were to remove
>> that region random effect. I'd like to keep the region random effect (with
>> varying slopes) in the model. I'm struggling with what I should think
>> about
>> the perfect correlations.
>>
>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall <jake987722 at hotmail.com>
>> wrote:
>>
>> > Hi Steve,
>> >
>> >
>> > I think the issue is that estimating 3 variances and 3 covariances for
>> > regions is quite ambitious given that there are only 6 regions. I think
>> > it's not surprising that the model has a hard time getting good
>> estimates
>> > of those parameters.
>> >
>> >
>> > Jake
>> >
>> > > Date: Tue, 14 Jul 2015 20:53:01 -0400
>> > > From: steven.v.miller at gmail.com
>> > > To: r-sig-mixed-models at r-project.org
>> > > Subject: [R-sig-ME] Perfectly correlated random effects (when they
>> > shouldn't be)
>> >
>> > >
>> > > Hi all,
>> > >
>> > > I'm a long-time reader and wanted to raise a question I've seen asked
>> > here
>> > > before about correlated random effects. Past answers I have
>> encountered
>> > on
>> > > this listserv explain that perfectly correlated random effects suggest
>> > > model overfitting and variances of random effects that are effectively
>> > zero
>> > > and can be omitted for a simpler model. In my case, I don't think
>> that's
>> > > what is happening here, though I could well be fitting a poor model in
>> > > glmer.
>> > >
>> > > I'll describe the nature of the data first. I'm modeling
>> individual-level
>> > > survey data for countries across multiple waves and am estimating the
>> > > region of the globe as a random effect as well. I have three random
>> > effects
>> > > (country, country-wave, and region). In the region random effect, I am
>> > > allowing country-wave-level predictors to have varying slopes. My
>> inquiry
>> > > is whether some country-wave-level contextual indicator can have an
>> > overall
>> > > effect (as a fixed effect), the effect of which can vary by region. In
>> > > other words: is the effect of some country-level indicator (e.g.
>> > > unemployment) in a given year different for countries in Western
>> Europe
>> > > than for countries in Africa even if, on average, there is a positive
>> or
>> > > negative association at the individual-level? These country-wave-level
>> > > predictors that I allow to vary by region are the ones reporting
>> perfect
>> > > correlation and I'm unsure how to interpret that (or if I'm estimating
>> > the
>> > > model correctly).
>> > >
>> > > I should also add that I have individual-level predictors as well as
>> > > country-wave-level predictors, though it's the latter that concerns
>> me.
>> > > Further, every non-binary indicator in the model is standardized by
>> two
>> > > standard deviations.
>> > >
>> > > For those interested, I have a reproducible (if rather large) example
>> > > below. Dropbox link to the data is here:
>> > >
>> >
>> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
>> > >
>> > > In this reproducible example, y is the outcome variable and x1 and x2
>> are
>> > > two country-wave-level predictors I allow to vary by region. Both x1
>> and
>> > x2
>> > > are interval-level predictors that I standardized to have a mean of
>> zero
>> > > and a standard deviation of .5 (per Gelman's (2008) recommendation).
>> > >
>> > > I estimate the following model.
>> > >
>> > > summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) +
>> > (1 +
>> > > x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))
>> > >
>> > > The results are theoretically intuitive. I think they make sense.
>> > However,
>> > > I get a report of perfect correlation for the varying slopes of the
>> > region
>> > > random effect.
>> > >
>> > > Random effects:
>> > > Groups Name Variance Std.Dev. Corr
>> > > country:wave (Intercept) 0.15915 0.3989
>> > > country (Intercept) 0.32945 0.5740
>> > > region (Intercept) 0.01646 0.1283
>> > > x1 0.02366 0.1538 1.00
>> > > x2 0.13994 0.3741 -1.00 -1.00
>> > > Number of obs: 212570, groups: country:wave, 143; country, 82;
>> region, 6
>> > >
>> > > What should I make of this and am I estimating this model wrong? For
>> what
>> > > it's worth, the dotplot of the region random effect (with conditional
>> > > variance) makes sense and is theoretically intuitive, given my data. (
>> > > http://i.imgur.com/mrnaJ77.png)
>> > >
>> > > Any help would be greatly appreciated.
>> > >
>> > > Best regards,
>> > > Steve
>> > >
>> > > [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>
>>
>> --
>> Steven V. Miller
>> Assistant Professor
>> Department of Political Science
>> Clemson University
>> http://svmiller.com
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From reinhold.kliegl at gmail.com  Wed Jul 15 13:32:14 2015
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 15 Jul 2015 13:32:14 +0200
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CAG+WrEwuXu9y0u-UL4UjtuO5z3NgNMOekmzG4Q+QGNVeiHamjg@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAG+WrEyULQWVoTOYOM7Gf-ANcYz3ARj2fPgRW2ArLcV01sE0Tg@mail.gmail.com>
	<CAG+WrEwuXu9y0u-UL4UjtuO5z3NgNMOekmzG4Q+QGNVeiHamjg@mail.gmail.com>
Message-ID: <CAG+WrExybg64DoXEJz4cn1MyA0bg7V6mxxQU9=wy5tnAyTPt4w@mail.gmail.com>

Correction: ... a counterexample to the claim that maximal models are
always conservative (not: anti-conservative).


On Wed, Jul 15, 2015 at 1:25 PM, Reinhold Kliegl <reinhold.kliegl at gmail.com>
wrote:

> Actually, I overlooked that the region-related variance component of x2
> can also be removed from the GLMM without loss of goodness of fit. Thus, I
> end up with an intercept-only GLMM as the most parsimonious model for this
> data set. Here is the anova() output:
>
> > anova(zcpM3, zcpM2, zcpM1, M1)
> Data: data
> Models:
> zcpM3: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 | region)
> zcpM2: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x2 ||
> region)
> zcpM1: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 + x2 ||
> region)
> M1: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 + x2 |
> region)
>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> zcpM3  6 258193 258255 -129091   258181                          (only
> intercept, parsimonious GLMM)
> zcpM2  7 258195 258267 -129091   258181 0.1882      1     0.6644
> zcpM1  8 258197 258279 -129091   258181 0.0000      1     1.0000
> M1    11 258201 258314 -129090   258179 1.8885      3     0.5959
> (overparameterized max GLMM)
>
> There is another interesting aspect to this reduction of model complexity.
> The parsimonious GLMM yields the SMALLEST z-value for the significant fixed
> effect of x1. Thus, this is a counterexample to the claim that maximal
> models are always anti-conservative. Whether this is the case or not may
> depend on whether the maximal model is overparameterized or not. Here are
> the corresponding fixed-effect estimates for x1 and x2:
>
> Fixed effects for x1 across GLMMs:
>                     Estimate Std. Error z value Pr(>|z|)
> zcpM3: x1           0.51004    0.23859    2.138  0.0325 *  (only
> intercept, parsimonious GLMM)
> zcpM2: x1           0.515822   0.167005   3.089  0.00201 **
> zcpM1: x1           0.516168   0.149704   3.448  0.000565 ***
> M1:    x1           0.48913    0.19972    2.449  0.0143 *
>  (overparameterized max GLMM)
>
> Fixed effects for x2 across GLMMs:
> zcpM3: x2          -0.02743    0.15881   -0.173  0.8629    (only
> intercept, parsimonious GLMM)
> zcpM2: x2          -0.008715   0.151586  -0.057  0.95416
> zcpM1: x2          -0.008701   0.155332  -0.056  0.955331
> M1:    x2           0.04422    0.17376    0.254  0.7991
>  (overparameterized max GLMM)
>
> On Wed, Jul 15, 2015 at 10:57 AM, Reinhold Kliegl <
> reinhold.kliegl at gmail.com> wrote:
>
>> It looks like your model is overparameterized. Specifically, although you
>> have a very large number of observations (N=212570),  the data do not
>> support the six model parameters you try to estimate for the random-effects
>> term of region. You can see this quickly with the rePCA() function. There
>> was also a convergence warning for me, but perhaps this was due to the fact
>> that I worked with the full set (as provided in the dropbox file), whereas
>> you used a subset.
>>
>> As a first step, I forced the correlation parameters to zero with the
>> ||-syntax (zcpM1 GLMM below). A LRT suggests that dropping the three
>> correlation parameters does not decrease the goodness of fit; Chi-sq(3) =
>> 1.9, p=.5959.  This could very well be a consequence of the small number of
>> regions, as Jake pointed out; and even 18 regions may not be enough for a
>> reliable estimation of three correlation parameters.
>>
>> Moreover, the rePCA() suggests that even the three remaining model
>> parameters for the random-effects term of region are quite marginally
>> supported by the data. In the zero-correlation parameter GLMM, the variance
>> component for x1 was estimated to be suspiciously small.  Therefore, in a
>> second step, I removed the region-related x1 variance component . Again,
>> according to a LRT there was no significant loss in goodness of fit;
>> Chi-sq(1) = 0.
>>
>> The R script is inserted below. Please note that taking a correlation
>> parameter or a variance component out of a model does not mean that it is
>> zero, but that the data do not support a model that assumes that it is
>> different from zero.  zcpM2 (below) looks like an adequate parsimonious
>> GLMM for these data.
>>
>>
>> ###
>>
>> # Note: The original post used a subset of the data, but it is not clear
>> how they were selected. I used all the data.
>>
>> library(lme4)
>> library(RePsychLing)
>> data <- read.csv("correlated-random-effects.csv", header=TRUE)
>> str(data)
>> data$country <- factor(data$country)
>> data$region <- factor(data$region)
>>
>> # no convergence problem
>> print(summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>> country:wave) +
>>                           (1 +  x1 + x2 | region), data=data,
>> family=binomial(link="logit"))))
>>
>> summary(rePCA(M1))
>>
>> # convergence problem
>> print(summary(zcpM1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>> country:wave) +
>>                              (1 +  x1 + x2 || region), data=data,
>> family=binomial(link="logit"))))
>> summary(rePCA(zcpM1))
>>
>> # ok
>> print(summary(zcpM2 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>> country:wave) +
>>                                    (1 + x2 || region), data=data,
>> family=binomial(link="logit"))))
>> summary(rePCA(zcpM2))
>>
>> anova(zcpM2, zcpM1, M1)
>>
>> ####
>>
>>
>>
>>
>> On Wed, Jul 15, 2015 at 3:45 AM, svm <steven.v.miller at gmail.com> wrote:
>>
>>> I considered that. I disaggregated the region random effect from 6 to 18
>>> (the latter of which approximates the World Bank's region
>>> classification).
>>> I'm still encountering the same curious issue.
>>>
>>> Random effects:
>>>  Groups       Name        Variance  Std.Dev. Corr
>>>  country:wave (Intercept) 0.1530052 0.39116
>>>  country      (Intercept) 0.3735876 0.61122
>>>  wbregion     (Intercept) 0.0137822 0.11740
>>>               x1        0.0009384 0.03063  -1.00
>>>               x2         0.0767387 0.27702  -1.00  1.00
>>> Number of obs: 212570, groups:  country:wave, 143; country, 82;
>>> wbregion, 18
>>>
>>>  For what it's worth: the model estimates fine. The results are intuitive
>>> and theoretically consistent. They also don't change if I were to remove
>>> that region random effect. I'd like to keep the region random effect
>>> (with
>>> varying slopes) in the model. I'm struggling with what I should think
>>> about
>>> the perfect correlations.
>>>
>>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall <jake987722 at hotmail.com>
>>> wrote:
>>>
>>> > Hi Steve,
>>> >
>>> >
>>> > I think the issue is that estimating 3 variances and 3 covariances for
>>> > regions is quite ambitious given that there are only 6 regions. I think
>>> > it's not surprising that the model has a hard time getting good
>>> estimates
>>> > of those parameters.
>>> >
>>> >
>>> > Jake
>>> >
>>> > > Date: Tue, 14 Jul 2015 20:53:01 -0400
>>> > > From: steven.v.miller at gmail.com
>>> > > To: r-sig-mixed-models at r-project.org
>>> > > Subject: [R-sig-ME] Perfectly correlated random effects (when they
>>> > shouldn't be)
>>> >
>>> > >
>>> > > Hi all,
>>> > >
>>> > > I'm a long-time reader and wanted to raise a question I've seen asked
>>> > here
>>> > > before about correlated random effects. Past answers I have
>>> encountered
>>> > on
>>> > > this listserv explain that perfectly correlated random effects
>>> suggest
>>> > > model overfitting and variances of random effects that are
>>> effectively
>>> > zero
>>> > > and can be omitted for a simpler model. In my case, I don't think
>>> that's
>>> > > what is happening here, though I could well be fitting a poor model
>>> in
>>> > > glmer.
>>> > >
>>> > > I'll describe the nature of the data first. I'm modeling
>>> individual-level
>>> > > survey data for countries across multiple waves and am estimating the
>>> > > region of the globe as a random effect as well. I have three random
>>> > effects
>>> > > (country, country-wave, and region). In the region random effect, I
>>> am
>>> > > allowing country-wave-level predictors to have varying slopes. My
>>> inquiry
>>> > > is whether some country-wave-level contextual indicator can have an
>>> > overall
>>> > > effect (as a fixed effect), the effect of which can vary by region.
>>> In
>>> > > other words: is the effect of some country-level indicator (e.g.
>>> > > unemployment) in a given year different for countries in Western
>>> Europe
>>> > > than for countries in Africa even if, on average, there is a
>>> positive or
>>> > > negative association at the individual-level? These
>>> country-wave-level
>>> > > predictors that I allow to vary by region are the ones reporting
>>> perfect
>>> > > correlation and I'm unsure how to interpret that (or if I'm
>>> estimating
>>> > the
>>> > > model correctly).
>>> > >
>>> > > I should also add that I have individual-level predictors as well as
>>> > > country-wave-level predictors, though it's the latter that concerns
>>> me.
>>> > > Further, every non-binary indicator in the model is standardized by
>>> two
>>> > > standard deviations.
>>> > >
>>> > > For those interested, I have a reproducible (if rather large) example
>>> > > below. Dropbox link to the data is here:
>>> > >
>>> >
>>> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
>>> > >
>>> > > In this reproducible example, y is the outcome variable and x1 and
>>> x2 are
>>> > > two country-wave-level predictors I allow to vary by region. Both x1
>>> and
>>> > x2
>>> > > are interval-level predictors that I standardized to have a mean of
>>> zero
>>> > > and a standard deviation of .5 (per Gelman's (2008) recommendation).
>>> > >
>>> > > I estimate the following model.
>>> > >
>>> > > summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave)
>>> +
>>> > (1 +
>>> > > x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))
>>> > >
>>> > > The results are theoretically intuitive. I think they make sense.
>>> > However,
>>> > > I get a report of perfect correlation for the varying slopes of the
>>> > region
>>> > > random effect.
>>> > >
>>> > > Random effects:
>>> > > Groups Name Variance Std.Dev. Corr
>>> > > country:wave (Intercept) 0.15915 0.3989
>>> > > country (Intercept) 0.32945 0.5740
>>> > > region (Intercept) 0.01646 0.1283
>>> > > x1 0.02366 0.1538 1.00
>>> > > x2 0.13994 0.3741 -1.00 -1.00
>>> > > Number of obs: 212570, groups: country:wave, 143; country, 82;
>>> region, 6
>>> > >
>>> > > What should I make of this and am I estimating this model wrong? For
>>> what
>>> > > it's worth, the dotplot of the region random effect (with conditional
>>> > > variance) makes sense and is theoretically intuitive, given my data.
>>> (
>>> > > http://i.imgur.com/mrnaJ77.png)
>>> > >
>>> > > Any help would be greatly appreciated.
>>> > >
>>> > > Best regards,
>>> > > Steve
>>> > >
>>> > > [[alternative HTML version deleted]]
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-mixed-models at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>>
>>>
>>>
>>> --
>>> Steven V. Miller
>>> Assistant Professor
>>> Department of Political Science
>>> Clemson University
>>> http://svmiller.com
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From steven.v.miller at gmail.com  Wed Jul 15 17:42:40 2015
From: steven.v.miller at gmail.com (svm)
Date: Wed, 15 Jul 2015 11:42:40 -0400
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CAG+WrExybg64DoXEJz4cn1MyA0bg7V6mxxQU9=wy5tnAyTPt4w@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAG+WrEyULQWVoTOYOM7Gf-ANcYz3ARj2fPgRW2ArLcV01sE0Tg@mail.gmail.com>
	<CAG+WrEwuXu9y0u-UL4UjtuO5z3NgNMOekmzG4Q+QGNVeiHamjg@mail.gmail.com>
	<CAG+WrExybg64DoXEJz4cn1MyA0bg7V6mxxQU9=wy5tnAyTPt4w@mail.gmail.com>
Message-ID: <CABafbio-Cqy0mWVnFMG=e2U1vzMS0qCSjqtzRPy+yzC1kXe9rg@mail.gmail.com>

Appreciate all the input. My preference would be for the minimal models for
concern of computation and overparameterization, but my field is one where
the reviewer is always right and junk models are encouraged. I do
appreciate the insight about the small number of regions. I think I had
been mistaken in my belief that the number of countries per region would
compensate even if the number of regions themselves were small.

On Wed, Jul 15, 2015 at 7:32 AM, Reinhold Kliegl <reinhold.kliegl at gmail.com>
wrote:

> Correction: ... a counterexample to the claim that maximal models are
> always conservative (not: anti-conservative).
>
>
> On Wed, Jul 15, 2015 at 1:25 PM, Reinhold Kliegl <
> reinhold.kliegl at gmail.com> wrote:
>
>> Actually, I overlooked that the region-related variance component of x2
>> can also be removed from the GLMM without loss of goodness of fit. Thus, I
>> end up with an intercept-only GLMM as the most parsimonious model for this
>> data set. Here is the anova() output:
>>
>> > anova(zcpM3, zcpM2, zcpM1, M1)
>> Data: data
>> Models:
>> zcpM3: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 | region)
>> zcpM2: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x2 ||
>> region)
>> zcpM1: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 + x2 ||
>> region)
>> M1: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 + x2 |
>> region)
>>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>> zcpM3  6 258193 258255 -129091   258181                          (only
>> intercept, parsimonious GLMM)
>> zcpM2  7 258195 258267 -129091   258181 0.1882      1     0.6644
>> zcpM1  8 258197 258279 -129091   258181 0.0000      1     1.0000
>> M1    11 258201 258314 -129090   258179 1.8885      3     0.5959
>> (overparameterized max GLMM)
>>
>> There is another interesting aspect to this reduction of model
>> complexity. The parsimonious GLMM yields the SMALLEST z-value for the
>> significant fixed effect of x1. Thus, this is a counterexample to the claim
>> that maximal models are always anti-conservative. Whether this is the case
>> or not may depend on whether the maximal model is overparameterized or not.
>> Here are the corresponding fixed-effect estimates for x1 and x2:
>>
>> Fixed effects for x1 across GLMMs:
>>                     Estimate Std. Error z value Pr(>|z|)
>> zcpM3: x1           0.51004    0.23859    2.138  0.0325 *  (only
>> intercept, parsimonious GLMM)
>> zcpM2: x1           0.515822   0.167005   3.089  0.00201 **
>> zcpM1: x1           0.516168   0.149704   3.448  0.000565 ***
>> M1:    x1           0.48913    0.19972    2.449  0.0143 *
>>  (overparameterized max GLMM)
>>
>> Fixed effects for x2 across GLMMs:
>> zcpM3: x2          -0.02743    0.15881   -0.173  0.8629    (only
>> intercept, parsimonious GLMM)
>> zcpM2: x2          -0.008715   0.151586  -0.057  0.95416
>> zcpM1: x2          -0.008701   0.155332  -0.056  0.955331
>> M1:    x2           0.04422    0.17376    0.254  0.7991
>>  (overparameterized max GLMM)
>>
>> On Wed, Jul 15, 2015 at 10:57 AM, Reinhold Kliegl <
>> reinhold.kliegl at gmail.com> wrote:
>>
>>> It looks like your model is overparameterized. Specifically, although
>>> you have a very large number of observations (N=212570),  the data do not
>>> support the six model parameters you try to estimate for the random-effects
>>> term of region. You can see this quickly with the rePCA() function. There
>>> was also a convergence warning for me, but perhaps this was due to the fact
>>> that I worked with the full set (as provided in the dropbox file), whereas
>>> you used a subset.
>>>
>>> As a first step, I forced the correlation parameters to zero with the
>>> ||-syntax (zcpM1 GLMM below). A LRT suggests that dropping the three
>>> correlation parameters does not decrease the goodness of fit; Chi-sq(3) =
>>> 1.9, p=.5959.  This could very well be a consequence of the small number of
>>> regions, as Jake pointed out; and even 18 regions may not be enough for a
>>> reliable estimation of three correlation parameters.
>>>
>>> Moreover, the rePCA() suggests that even the three remaining model
>>> parameters for the random-effects term of region are quite marginally
>>> supported by the data. In the zero-correlation parameter GLMM, the variance
>>> component for x1 was estimated to be suspiciously small.  Therefore, in a
>>> second step, I removed the region-related x1 variance component . Again,
>>> according to a LRT there was no significant loss in goodness of fit;
>>> Chi-sq(1) = 0.
>>>
>>> The R script is inserted below. Please note that taking a correlation
>>> parameter or a variance component out of a model does not mean that it is
>>> zero, but that the data do not support a model that assumes that it is
>>> different from zero.  zcpM2 (below) looks like an adequate parsimonious
>>> GLMM for these data.
>>>
>>>
>>> ###
>>>
>>> # Note: The original post used a subset of the data, but it is not clear
>>> how they were selected. I used all the data.
>>>
>>> library(lme4)
>>> library(RePsychLing)
>>> data <- read.csv("correlated-random-effects.csv", header=TRUE)
>>> str(data)
>>> data$country <- factor(data$country)
>>> data$region <- factor(data$region)
>>>
>>> # no convergence problem
>>> print(summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>>> country:wave) +
>>>                           (1 +  x1 + x2 | region), data=data,
>>> family=binomial(link="logit"))))
>>>
>>> summary(rePCA(M1))
>>>
>>> # convergence problem
>>> print(summary(zcpM1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>>> country:wave) +
>>>                              (1 +  x1 + x2 || region), data=data,
>>> family=binomial(link="logit"))))
>>> summary(rePCA(zcpM1))
>>>
>>> # ok
>>> print(summary(zcpM2 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>>> country:wave) +
>>>                                    (1 + x2 || region), data=data,
>>> family=binomial(link="logit"))))
>>> summary(rePCA(zcpM2))
>>>
>>> anova(zcpM2, zcpM1, M1)
>>>
>>> ####
>>>
>>>
>>>
>>>
>>> On Wed, Jul 15, 2015 at 3:45 AM, svm <steven.v.miller at gmail.com> wrote:
>>>
>>>> I considered that. I disaggregated the region random effect from 6 to 18
>>>> (the latter of which approximates the World Bank's region
>>>> classification).
>>>> I'm still encountering the same curious issue.
>>>>
>>>> Random effects:
>>>>  Groups       Name        Variance  Std.Dev. Corr
>>>>  country:wave (Intercept) 0.1530052 0.39116
>>>>  country      (Intercept) 0.3735876 0.61122
>>>>  wbregion     (Intercept) 0.0137822 0.11740
>>>>               x1        0.0009384 0.03063  -1.00
>>>>               x2         0.0767387 0.27702  -1.00  1.00
>>>> Number of obs: 212570, groups:  country:wave, 143; country, 82;
>>>> wbregion, 18
>>>>
>>>>  For what it's worth: the model estimates fine. The results are
>>>> intuitive
>>>> and theoretically consistent. They also don't change if I were to remove
>>>> that region random effect. I'd like to keep the region random effect
>>>> (with
>>>> varying slopes) in the model. I'm struggling with what I should think
>>>> about
>>>> the perfect correlations.
>>>>
>>>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall <jake987722 at hotmail.com>
>>>> wrote:
>>>>
>>>> > Hi Steve,
>>>> >
>>>> >
>>>> > I think the issue is that estimating 3 variances and 3 covariances for
>>>> > regions is quite ambitious given that there are only 6 regions. I
>>>> think
>>>> > it's not surprising that the model has a hard time getting good
>>>> estimates
>>>> > of those parameters.
>>>> >
>>>> >
>>>> > Jake
>>>> >
>>>> > > Date: Tue, 14 Jul 2015 20:53:01 -0400
>>>> > > From: steven.v.miller at gmail.com
>>>> > > To: r-sig-mixed-models at r-project.org
>>>> > > Subject: [R-sig-ME] Perfectly correlated random effects (when they
>>>> > shouldn't be)
>>>> >
>>>> > >
>>>> > > Hi all,
>>>> > >
>>>> > > I'm a long-time reader and wanted to raise a question I've seen
>>>> asked
>>>> > here
>>>> > > before about correlated random effects. Past answers I have
>>>> encountered
>>>> > on
>>>> > > this listserv explain that perfectly correlated random effects
>>>> suggest
>>>> > > model overfitting and variances of random effects that are
>>>> effectively
>>>> > zero
>>>> > > and can be omitted for a simpler model. In my case, I don't think
>>>> that's
>>>> > > what is happening here, though I could well be fitting a poor model
>>>> in
>>>> > > glmer.
>>>> > >
>>>> > > I'll describe the nature of the data first. I'm modeling
>>>> individual-level
>>>> > > survey data for countries across multiple waves and am estimating
>>>> the
>>>> > > region of the globe as a random effect as well. I have three random
>>>> > effects
>>>> > > (country, country-wave, and region). In the region random effect, I
>>>> am
>>>> > > allowing country-wave-level predictors to have varying slopes. My
>>>> inquiry
>>>> > > is whether some country-wave-level contextual indicator can have an
>>>> > overall
>>>> > > effect (as a fixed effect), the effect of which can vary by region.
>>>> In
>>>> > > other words: is the effect of some country-level indicator (e.g.
>>>> > > unemployment) in a given year different for countries in Western
>>>> Europe
>>>> > > than for countries in Africa even if, on average, there is a
>>>> positive or
>>>> > > negative association at the individual-level? These
>>>> country-wave-level
>>>> > > predictors that I allow to vary by region are the ones reporting
>>>> perfect
>>>> > > correlation and I'm unsure how to interpret that (or if I'm
>>>> estimating
>>>> > the
>>>> > > model correctly).
>>>> > >
>>>> > > I should also add that I have individual-level predictors as well as
>>>> > > country-wave-level predictors, though it's the latter that concerns
>>>> me.
>>>> > > Further, every non-binary indicator in the model is standardized by
>>>> two
>>>> > > standard deviations.
>>>> > >
>>>> > > For those interested, I have a reproducible (if rather large)
>>>> example
>>>> > > below. Dropbox link to the data is here:
>>>> > >
>>>> >
>>>> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
>>>> > >
>>>> > > In this reproducible example, y is the outcome variable and x1 and
>>>> x2 are
>>>> > > two country-wave-level predictors I allow to vary by region. Both
>>>> x1 and
>>>> > x2
>>>> > > are interval-level predictors that I standardized to have a mean of
>>>> zero
>>>> > > and a standard deviation of .5 (per Gelman's (2008) recommendation).
>>>> > >
>>>> > > I estimate the following model.
>>>> > >
>>>> > > summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>>>> country:wave) +
>>>> > (1 +
>>>> > > x1 + x2 | region), data=subset(Data),
>>>> family=binomial(link="logit")))
>>>> > >
>>>> > > The results are theoretically intuitive. I think they make sense.
>>>> > However,
>>>> > > I get a report of perfect correlation for the varying slopes of the
>>>> > region
>>>> > > random effect.
>>>> > >
>>>> > > Random effects:
>>>> > > Groups Name Variance Std.Dev. Corr
>>>> > > country:wave (Intercept) 0.15915 0.3989
>>>> > > country (Intercept) 0.32945 0.5740
>>>> > > region (Intercept) 0.01646 0.1283
>>>> > > x1 0.02366 0.1538 1.00
>>>> > > x2 0.13994 0.3741 -1.00 -1.00
>>>> > > Number of obs: 212570, groups: country:wave, 143; country, 82;
>>>> region, 6
>>>> > >
>>>> > > What should I make of this and am I estimating this model wrong?
>>>> For what
>>>> > > it's worth, the dotplot of the region random effect (with
>>>> conditional
>>>> > > variance) makes sense and is theoretically intuitive, given my
>>>> data. (
>>>> > > http://i.imgur.com/mrnaJ77.png)
>>>> > >
>>>> > > Any help would be greatly appreciated.
>>>> > >
>>>> > > Best regards,
>>>> > > Steve
>>>> > >
>>>> > > [[alternative HTML version deleted]]
>>>> > >
>>>> > > _______________________________________________
>>>> > > R-sig-mixed-models at r-project.org mailing list
>>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >
>>>>
>>>>
>>>>
>>>> --
>>>> Steven V. Miller
>>>> Assistant Professor
>>>> Department of Political Science
>>>> Clemson University
>>>> http://svmiller.com
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Wed Jul 15 18:52:03 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Wed, 15 Jul 2015 18:52:03 +0200
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
Message-ID: <CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>

if you look at the results from a baysian perspective, it seems to be a
typcial "problem" of ML-procedures estimating the mode.

The mode is nothing special, just the point where the density is maximal.
When you have skewed distribution (as usual for correlations) the mode will
often be close to the borders of the region of definition (-1 or 1 in this
case). The posterior distribution of the correlation, however, can still be
very wide ranging from strong negative correlation to strong positive
correlation, especially when the number of levels of a grouping factor is
not that large. In those cases, zero (i.e. insignificant) correlation is a
very likely value even if the mode itself is extreme.

I tried fitting your models with bayesian R packages (brms and MCMCglmm).
Unfortunately, because you have so many observations and quite a few random
effects, they run relatively slow so i am still waiting for the results.

2015-07-15 3:45 GMT+02:00 svm <steven.v.miller at gmail.com>:

> I considered that. I disaggregated the region random effect from 6 to 18
> (the latter of which approximates the World Bank's region classification).
> I'm still encountering the same curious issue.
>
> Random effects:
>  Groups       Name        Variance  Std.Dev. Corr
>  country:wave (Intercept) 0.1530052 0.39116
>  country      (Intercept) 0.3735876 0.61122
>  wbregion     (Intercept) 0.0137822 0.11740
>               x1        0.0009384 0.03063  -1.00
>               x2         0.0767387 0.27702  -1.00  1.00
> Number of obs: 212570, groups:  country:wave, 143; country, 82; wbregion,
> 18
>
>  For what it's worth: the model estimates fine. The results are intuitive
> and theoretically consistent. They also don't change if I were to remove
> that region random effect. I'd like to keep the region random effect (with
> varying slopes) in the model. I'm struggling with what I should think about
> the perfect correlations.
>
> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall <jake987722 at hotmail.com>
> wrote:
>
> > Hi Steve,
> >
> >
> > I think the issue is that estimating 3 variances and 3 covariances for
> > regions is quite ambitious given that there are only 6 regions. I think
> > it's not surprising that the model has a hard time getting good estimates
> > of those parameters.
> >
> >
> > Jake
> >
> > > Date: Tue, 14 Jul 2015 20:53:01 -0400
> > > From: steven.v.miller at gmail.com
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Perfectly correlated random effects (when they
> > shouldn't be)
> >
> > >
> > > Hi all,
> > >
> > > I'm a long-time reader and wanted to raise a question I've seen asked
> > here
> > > before about correlated random effects. Past answers I have encountered
> > on
> > > this listserv explain that perfectly correlated random effects suggest
> > > model overfitting and variances of random effects that are effectively
> > zero
> > > and can be omitted for a simpler model. In my case, I don't think
> that's
> > > what is happening here, though I could well be fitting a poor model in
> > > glmer.
> > >
> > > I'll describe the nature of the data first. I'm modeling
> individual-level
> > > survey data for countries across multiple waves and am estimating the
> > > region of the globe as a random effect as well. I have three random
> > effects
> > > (country, country-wave, and region). In the region random effect, I am
> > > allowing country-wave-level predictors to have varying slopes. My
> inquiry
> > > is whether some country-wave-level contextual indicator can have an
> > overall
> > > effect (as a fixed effect), the effect of which can vary by region. In
> > > other words: is the effect of some country-level indicator (e.g.
> > > unemployment) in a given year different for countries in Western Europe
> > > than for countries in Africa even if, on average, there is a positive
> or
> > > negative association at the individual-level? These country-wave-level
> > > predictors that I allow to vary by region are the ones reporting
> perfect
> > > correlation and I'm unsure how to interpret that (or if I'm estimating
> > the
> > > model correctly).
> > >
> > > I should also add that I have individual-level predictors as well as
> > > country-wave-level predictors, though it's the latter that concerns me.
> > > Further, every non-binary indicator in the model is standardized by two
> > > standard deviations.
> > >
> > > For those interested, I have a reproducible (if rather large) example
> > > below. Dropbox link to the data is here:
> > >
> >
> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
> > >
> > > In this reproducible example, y is the outcome variable and x1 and x2
> are
> > > two country-wave-level predictors I allow to vary by region. Both x1
> and
> > x2
> > > are interval-level predictors that I standardized to have a mean of
> zero
> > > and a standard deviation of .5 (per Gelman's (2008) recommendation).
> > >
> > > I estimate the following model.
> > >
> > > summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) +
> > (1 +
> > > x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))
> > >
> > > The results are theoretically intuitive. I think they make sense.
> > However,
> > > I get a report of perfect correlation for the varying slopes of the
> > region
> > > random effect.
> > >
> > > Random effects:
> > > Groups Name Variance Std.Dev. Corr
> > > country:wave (Intercept) 0.15915 0.3989
> > > country (Intercept) 0.32945 0.5740
> > > region (Intercept) 0.01646 0.1283
> > > x1 0.02366 0.1538 1.00
> > > x2 0.13994 0.3741 -1.00 -1.00
> > > Number of obs: 212570, groups: country:wave, 143; country, 82; region,
> 6
> > >
> > > What should I make of this and am I estimating this model wrong? For
> what
> > > it's worth, the dotplot of the region random effect (with conditional
> > > variance) makes sense and is theoretically intuitive, given my data. (
> > > http://i.imgur.com/mrnaJ77.png)
> > >
> > > Any help would be greatly appreciated.
> > >
> > > Best regards,
> > > Steve
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
> Steven V. Miller
> Assistant Professor
> Department of Political Science
> Clemson University
> http://svmiller.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From steven.v.miller at gmail.com  Wed Jul 15 19:44:25 2015
From: steven.v.miller at gmail.com (svm)
Date: Wed, 15 Jul 2015 13:44:25 -0400
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>
Message-ID: <CABafbipX0ppZh5RuCBhww-wyyDfcYx3W-ew4fcCdng4GCgmMUw@mail.gmail.com>

I appreciate you running the models in Bayesian packages. I've thought
about going that route, though I have no experience fitting these models in
Stan or JAGS or some other package.

As for the slow compile: I took some advice from the vignette on Cran about
performance optimization (even at the expense of suboptimal estimates). I
wish I knew how to parallelize the model, though that's a different topic.

On Wed, Jul 15, 2015 at 12:52 PM, Paul Buerkner <paul.buerkner at gmail.com>
wrote:

> if you look at the results from a baysian perspective, it seems to be a
> typcial "problem" of ML-procedures estimating the mode.
>
> The mode is nothing special, just the point where the density is maximal.
> When you have skewed distribution (as usual for correlations) the mode will
> often be close to the borders of the region of definition (-1 or 1 in this
> case). The posterior distribution of the correlation, however, can still be
> very wide ranging from strong negative correlation to strong positive
> correlation, especially when the number of levels of a grouping factor is
> not that large. In those cases, zero (i.e. insignificant) correlation is a
> very likely value even if the mode itself is extreme.
>
> I tried fitting your models with bayesian R packages (brms and MCMCglmm).
> Unfortunately, because you have so many observations and quite a few random
> effects, they run relatively slow so i am still waiting for the results.
>
> 2015-07-15 3:45 GMT+02:00 svm <steven.v.miller at gmail.com>:
>
>> I considered that. I disaggregated the region random effect from 6 to 18
>> (the latter of which approximates the World Bank's region classification).
>> I'm still encountering the same curious issue.
>>
>> Random effects:
>>  Groups       Name        Variance  Std.Dev. Corr
>>  country:wave (Intercept) 0.1530052 0.39116
>>  country      (Intercept) 0.3735876 0.61122
>>  wbregion     (Intercept) 0.0137822 0.11740
>>               x1        0.0009384 0.03063  -1.00
>>               x2         0.0767387 0.27702  -1.00  1.00
>> Number of obs: 212570, groups:  country:wave, 143; country, 82; wbregion,
>> 18
>>
>>  For what it's worth: the model estimates fine. The results are intuitive
>> and theoretically consistent. They also don't change if I were to remove
>> that region random effect. I'd like to keep the region random effect (with
>> varying slopes) in the model. I'm struggling with what I should think
>> about
>> the perfect correlations.
>>
>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall <jake987722 at hotmail.com>
>> wrote:
>>
>> > Hi Steve,
>> >
>> >
>> > I think the issue is that estimating 3 variances and 3 covariances for
>> > regions is quite ambitious given that there are only 6 regions. I think
>> > it's not surprising that the model has a hard time getting good
>> estimates
>> > of those parameters.
>> >
>> >
>> > Jake
>> >
>> > > Date: Tue, 14 Jul 2015 20:53:01 -0400
>> > > From: steven.v.miller at gmail.com
>> > > To: r-sig-mixed-models at r-project.org
>> > > Subject: [R-sig-ME] Perfectly correlated random effects (when they
>> > shouldn't be)
>> >
>> > >
>> > > Hi all,
>> > >
>> > > I'm a long-time reader and wanted to raise a question I've seen asked
>> > here
>> > > before about correlated random effects. Past answers I have
>> encountered
>> > on
>> > > this listserv explain that perfectly correlated random effects suggest
>> > > model overfitting and variances of random effects that are effectively
>> > zero
>> > > and can be omitted for a simpler model. In my case, I don't think
>> that's
>> > > what is happening here, though I could well be fitting a poor model in
>> > > glmer.
>> > >
>> > > I'll describe the nature of the data first. I'm modeling
>> individual-level
>> > > survey data for countries across multiple waves and am estimating the
>> > > region of the globe as a random effect as well. I have three random
>> > effects
>> > > (country, country-wave, and region). In the region random effect, I am
>> > > allowing country-wave-level predictors to have varying slopes. My
>> inquiry
>> > > is whether some country-wave-level contextual indicator can have an
>> > overall
>> > > effect (as a fixed effect), the effect of which can vary by region. In
>> > > other words: is the effect of some country-level indicator (e.g.
>> > > unemployment) in a given year different for countries in Western
>> Europe
>> > > than for countries in Africa even if, on average, there is a positive
>> or
>> > > negative association at the individual-level? These country-wave-level
>> > > predictors that I allow to vary by region are the ones reporting
>> perfect
>> > > correlation and I'm unsure how to interpret that (or if I'm estimating
>> > the
>> > > model correctly).
>> > >
>> > > I should also add that I have individual-level predictors as well as
>> > > country-wave-level predictors, though it's the latter that concerns
>> me.
>> > > Further, every non-binary indicator in the model is standardized by
>> two
>> > > standard deviations.
>> > >
>> > > For those interested, I have a reproducible (if rather large) example
>> > > below. Dropbox link to the data is here:
>> > >
>> >
>> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
>> > >
>> > > In this reproducible example, y is the outcome variable and x1 and x2
>> are
>> > > two country-wave-level predictors I allow to vary by region. Both x1
>> and
>> > x2
>> > > are interval-level predictors that I standardized to have a mean of
>> zero
>> > > and a standard deviation of .5 (per Gelman's (2008) recommendation).
>> > >
>> > > I estimate the following model.
>> > >
>> > > summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 | country:wave) +
>> > (1 +
>> > > x1 + x2 | region), data=subset(Data), family=binomial(link="logit")))
>> > >
>> > > The results are theoretically intuitive. I think they make sense.
>> > However,
>> > > I get a report of perfect correlation for the varying slopes of the
>> > region
>> > > random effect.
>> > >
>> > > Random effects:
>> > > Groups Name Variance Std.Dev. Corr
>> > > country:wave (Intercept) 0.15915 0.3989
>> > > country (Intercept) 0.32945 0.5740
>> > > region (Intercept) 0.01646 0.1283
>> > > x1 0.02366 0.1538 1.00
>> > > x2 0.13994 0.3741 -1.00 -1.00
>> > > Number of obs: 212570, groups: country:wave, 143; country, 82;
>> region, 6
>> > >
>> > > What should I make of this and am I estimating this model wrong? For
>> what
>> > > it's worth, the dotplot of the region random effect (with conditional
>> > > variance) makes sense and is theoretically intuitive, given my data. (
>> > > http://i.imgur.com/mrnaJ77.png)
>> > >
>> > > Any help would be greatly appreciated.
>> > >
>> > > Best regards,
>> > > Steve
>> > >
>> > > [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>
>>
>> --
>> Steven V. Miller
>> Assistant Professor
>> Department of Political Science
>> Clemson University
>> http://svmiller.com
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Wed Jul 15 22:28:03 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 15 Jul 2015 16:28:03 -0400
Subject: [R-sig-ME] TEST2: Please ignore this message,
 I am trying to determine why messages I send to the list are not
 forwarded to me Thank you, John
Message-ID: <55A68A13020000CB00132F6D@smtp.medicine.umaryland.edu>

TEST2
 
TEST: Please ignore this message, I am trying to determine why messages I send to the list are not forwarded to me      Thank you, John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From bbolker at gmail.com  Wed Jul 15 23:18:23 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 15 Jul 2015 17:18:23 -0400
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <55A6C4E2.10305@gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>
	<55A6C4E2.10305@gmail.com>
Message-ID: <55A6CE1F.5070404@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-07-15 04:38 PM, Ben Bolker wrote:
> On 15-07-15 12:52 PM, Paul Buerkner wrote:
>> if you look at the results from a baysian perspective, it seems
>> to be a typcial "problem" of ML-procedures estimating the mode.
>> 
>> The mode is nothing special, just the point where the density is
>> maximal. When you have skewed distribution (as usual for
>> correlations) the mode will often be close to the borders of the
>> region of definition (-1 or 1 in this case). The posterior
>> distribution of the correlation, however, can still be very wide
>> ranging from strong negative correlation to strong positive 
>> correlation, especially when the number of levels of a grouping
>> factor is not that large. In those cases, zero (i.e.
>> insignificant) correlation is a very likely value even if the
>> mode itself is extreme.
>> 
>> I tried fitting your models with bayesian R packages (brms and
>> MCMCglmm). Unfortunately, because you have so many observations
>> and quite a few random effects, they run relatively slow so i am
>> still waiting for the results.
> 

 You can also use blme, which implements a very thin Bayesian wrapper
around [g]lmer and does maximum _a posteriori_ (i.e. Bayesian mode)
estimates with
weak (but principled) priors on the random effects -- it's based on

Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and
Jingchen Liu. ?A Nondegenerate Penalized Likelihood Estimator for
Variance Parameters in Multilevel Models.? Psychometrika 78, no. 4
(March 12, 2013): 685?709. doi:10.1007/s11336-013-9328-2.

  Profile 'likelihood' confidence intervals based on blme will get you
a reasonable approximation of the width of the credible interval,
although it's a little bit of a cheesy/awkward combination between
marginal (proper Bayesian) and conditional (MAP/cheesy-Bayesian)
measures of uncertainty.





>> 2015-07-15 3:45 GMT+02:00 svm <steven.v.miller at gmail.com>:
>> 
>>> I considered that. I disaggregated the region random effect
>>> from 6 to 18 (the latter of which approximates the World Bank's
>>> region classification). I'm still encountering the same curious
>>> issue.
>>> 
>>> Random effects: Groups       Name        Variance  Std.Dev.
>>> Corr country:wave (Intercept) 0.1530052 0.39116 country
>>> (Intercept) 0.3735876 0.61122 wbregion     (Intercept)
>>> 0.0137822 0.11740 x1        0.0009384 0.03063  -1.00 x2
>>> 0.0767387 0.27702  -1.00  1.00 Number of obs: 212570, groups:
>>> country:wave, 143; country, 82; wbregion, 18
>>> 
>>> For what it's worth: the model estimates fine. The results are
>>> intuitive and theoretically consistent. They also don't change
>>> if I were to remove that region random effect. I'd like to keep
>>> the region random effect (with varying slopes) in the model.
>>> I'm struggling with what I should think about the perfect
>>> correlations.
>>> 
>>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall
>>> <jake987722 at hotmail.com> wrote:
>>> 
>>>> Hi Steve,
>>>> 
>>>> 
>>>> I think the issue is that estimating 3 variances and 3
>>>> covariances for regions is quite ambitious given that there
>>>> are only 6 regions. I think it's not surprising that the
>>>> model has a hard time getting good estimates of those
>>>> parameters.
>>>> 
>>>> 
>>>> Jake
>>>> 
>>>>> Date: Tue, 14 Jul 2015 20:53:01 -0400 From:
>>>>> steven.v.miller at gmail.com To:
>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME]
>>>>> Perfectly correlated random effects (when they
>>>> shouldn't be)
>>>> 
>>>>> 
>>>>> Hi all,
>>>>> 
>>>>> I'm a long-time reader and wanted to raise a question I've
>>>>> seen asked
>>>> here
>>>>> before about correlated random effects. Past answers I have
>>>>> encountered
>>>> on
>>>>> this listserv explain that perfectly correlated random
>>>>> effects suggest model overfitting and variances of random
>>>>> effects that are effectively
>>>> zero
>>>>> and can be omitted for a simpler model. In my case, I don't
>>>>> think
>>> that's
>>>>> what is happening here, though I could well be fitting a
>>>>> poor model in glmer.
>>>>> 
>>>>> I'll describe the nature of the data first. I'm modeling
>>> individual-level
>>>>> survey data for countries across multiple waves and am
>>>>> estimating the region of the globe as a random effect as
>>>>> well. I have three random
>>>> effects
>>>>> (country, country-wave, and region). In the region random
>>>>> effect, I am allowing country-wave-level predictors to have
>>>>> varying slopes. My
>>> inquiry
>>>>> is whether some country-wave-level contextual indicator can
>>>>> have an
>>>> overall
>>>>> effect (as a fixed effect), the effect of which can vary by
>>>>> region. In other words: is the effect of some country-level
>>>>> indicator (e.g. unemployment) in a given year different for
>>>>> countries in Western Europe than for countries in Africa
>>>>> even if, on average, there is a positive
>>> or
>>>>> negative association at the individual-level? These
>>>>> country-wave-level predictors that I allow to vary by
>>>>> region are the ones reporting
>>> perfect
>>>>> correlation and I'm unsure how to interpret that (or if I'm
>>>>> estimating
>>>> the
>>>>> model correctly).
>>>>> 
>>>>> I should also add that I have individual-level predictors
>>>>> as well as country-wave-level predictors, though it's the
>>>>> latter that concerns me. Further, every non-binary
>>>>> indicator in the model is standardized by two standard
>>>>> deviations.
>>>>> 
>>>>> For those interested, I have a reproducible (if rather
>>>>> large) example below. Dropbox link to the data is here:
>>>>> 
>>>> 
>>> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
>>>>>
>>>>>
>>> 
In this reproducible example, y is the outcome variable and x1 and x2
>>> are
>>>>> two country-wave-level predictors I allow to vary by
>>>>> region. Both x1
>>> and
>>>> x2
>>>>> are interval-level predictors that I standardized to have a
>>>>> mean of
>>> zero
>>>>> and a standard deviation of .5 (per Gelman's (2008)
>>>>> recommendation).
>>>>> 
>>>>> I estimate the following model.
>>>>> 
>>>>> summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>>>>> country:wave) +
>>>> (1 +
>>>>> x1 + x2 | region), data=subset(Data),
>>>>> family=binomial(link="logit")))
>>>>> 
>>>>> The results are theoretically intuitive. I think they make
>>>>> sense.
>>>> However,
>>>>> I get a report of perfect correlation for the varying
>>>>> slopes of the
>>>> region
>>>>> random effect.
>>>>> 
>>>>> Random effects: Groups Name Variance Std.Dev. Corr 
>>>>> country:wave (Intercept) 0.15915 0.3989 country (Intercept)
>>>>> 0.32945 0.5740 region (Intercept) 0.01646 0.1283 x1 0.02366
>>>>> 0.1538 1.00 x2 0.13994 0.3741 -1.00 -1.00 Number of obs:
>>>>> 212570, groups: country:wave, 143; country, 82; region,
>>> 6
>>>>> 
>>>>> What should I make of this and am I estimating this model
>>>>> wrong? For
>>> what
>>>>> it's worth, the dotplot of the region random effect (with
>>>>> conditional variance) makes sense and is theoretically
>>>>> intuitive, given my data. ( 
>>>>> http://i.imgur.com/mrnaJ77.png)
>>>>> 
>>>>> Any help would be greatly appreciated.
>>>>> 
>>>>> Best regards, Steve
>>>>> 
>>>>> [[alternative HTML version deleted]]
>>>>> 
>>>>> _______________________________________________ 
>>>>> R-sig-mixed-models at r-project.org mailing list 
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> 
>>> 
>>> -- Steven V. Miller Assistant Professor Department of Political
>>> Science Clemson University http://svmiller.com
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVps4fAAoJEOCV5YRblxUH0wQIANBg6CaKoHuM6RQY5VltpEbk
5+RYc0tIYXmvNzGesG0QTQaLz0A5cx5mo0EGxsKQq8vUz2ycRlSlcYo9uI0K/xft
D8MMhdVr8QhIW2RtoWPNPzn6HIe276CFnHg4Co+3vbMcccbvTvWvxsDYaT/LOlRn
JoVjN/HcOscMOQkAxZV6elYBZe+kbVVhOS0SNo3Bt5P528EuWIxaRlC2lO5aoHSL
1cgLn5uyWLsxb3Cuu3FctwYfYOk9hsEXNM/EGMleshDq6umGtSm9lqiM8vqgSnMl
Iyp2A+r3fkRzfEZyWv0Ygi4OA0iZ5/BSH44+sR60hj/qSpqGYwUQ+fIrfKXAYTw=
=cHT0
-----END PGP SIGNATURE-----


From liberationecology at gmail.com  Thu Jul 16 01:05:18 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Wed, 15 Jul 2015 18:05:18 -0500
Subject: [R-sig-ME] variance explained by fixed effects in MCMCglmm
Message-ID: <CAPNXFM5Wuxj+GdF4SfMN8=T=KRbGUA7+9fAuMskzqo8i9govAg@mail.gmail.com>

I've been searching for ways to calculate some R^2-like statistics for a
multi-level multi-response model fit with MCMCglmm (with 3 Gaussian
responses).

I can see from the Course Notes and elsewhere that it's very
straightforward to calculate the variance explained by the random effects,
but after much searching I haven't found a discussion for fixed effects. It
looks like one option would be refitting with all my fixed effects as
random - but I'm concerned that might be bonkers, or that there might be an
easier way.

For previous multilevel modeling with lmer, I've used the approach
following Nakagawa et al. 2013 (A general and simple method for obtaining
R2 from generalized linear mixed-effects models. Methods in Ecology and
Evolution, 4(2), 133?142. http://doi.org/10.1111/j.2041-210x.2012.00261.x)
to calculate conditional and marginal R^2...
but I'm not sure how to adapt it for the (for me) brave new world of
MCMCglmm.

I would be grateful for any advice!

Thanks so much for your time.

Warmly,
Rafter


Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

	[[alternative HTML version deleted]]


From dan.newman86 at gmail.com  Thu Jul 16 07:41:49 2015
From: dan.newman86 at gmail.com (Daniel Newman)
Date: Thu, 16 Jul 2015 15:41:49 +1000
Subject: [R-sig-ME] Method to transform fixed effect parameter estimates
 back on to the response scale [after glmer() with family=Gamma(link =
 "log")] ??
Message-ID: <CAGmnqXgNR+jFM-gZYaadsyO9CmRx7voMFFmQpoaOrwFfzJHrYg@mail.gmail.com>

Subject: Method to transform fixed effect parameter estimates back on to
the response scale [after glmer() with family=Gamma(link = "log")] ??

Dear lme4 experts,

I am using lme4 to model human reaction-time (RT; in milliseconds)
responses. My model includes both nested and fully crossed random
intercepts, and fixed effect ?predictor? factors.

lmer() seems to work quite well for this, and is nice since I can use the
fixed effect parameter estimates (beta and Std.Errors) for interpretation
to say that for every unit of the ?predictor? that changes, we expect a
change of ~beta units in RT on the response scale (milliseconds). Pretty
happy with the results?.BUT?

glmer() may be the better option since the response distribution has a
positive skew with no zero values (typical RT distribution), and glmer()
allows the same model specification as my lmer() model, except using
family=Gamma(link = "log") to account for the skewed response distribution.

This seems to work well and gives very similar results to the equivalent
lmer() model, but with somewhat improved residual plots, so I guess the
glmer() with family=Gamma(link = "log") is a more valid approach since it
explicitly accounts for the shape of response distribution.

PROBLEM: Is there a way to transform the fixed effect parameter estimates
and Std.Errors from the glmer() with family=Gamma(link = "log"), back to
the response scale (i.e. back to RT in milliseconds). It would be nice/aid
interpretation to say that for every unit of the ?predictor? that changes,
we expect a change of ~beta units on the response scale.

Thank you so much for your time!!

Cheers
Dan


--

	[[alternative HTML version deleted]]


From robert.krause at student.ru.nl  Thu Jul 16 11:00:42 2015
From: robert.krause at student.ru.nl (Krause, R.W. (Robert))
Date: Thu, 16 Jul 2015 09:00:42 +0000
Subject: [R-sig-ME] variance explained by fixed effects in MCMCglmm
In-Reply-To: <CAPNXFM5Wuxj+GdF4SfMN8=T=KRbGUA7+9fAuMskzqo8i9govAg@mail.gmail.com>
References: <CAPNXFM5Wuxj+GdF4SfMN8=T=KRbGUA7+9fAuMskzqo8i9govAg@mail.gmail.com>
Message-ID: <550127DC72DC184594C27704B95941E512F091CA@exprd02.hosting.ru.nl>

Hey Rafter,

I had a similar question some time back and came across this webside.

http://jonlefcheck.net/2013/03/13/r2-for-linear-mixed-effects-models/

Here functions for calculating marginal and conditional R? are provided.
My knowledge about these mathematics and philosophy is limited so it might be that someone on this list has good arguments not to use these functions or calculate these R?s at all.
If so, please step forward.

Best regards,
Robert

Robert Krause, MS
Behavioural Science Institute
Radboud University Nijmegen


________________________________________
Von: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org]&quot; im Auftrag von &quot;rafter sass ferguson [liberationecology at gmail.com]
Gesendet: Donnerstag, 16. Juli 2015 01:05
An: r-sig-mixed-models
Betreff: [R-sig-ME] variance explained by fixed effects in MCMCglmm

I've been searching for ways to calculate some R^2-like statistics for a
multi-level multi-response model fit with MCMCglmm (with 3 Gaussian
responses).

I can see from the Course Notes and elsewhere that it's very
straightforward to calculate the variance explained by the random effects,
but after much searching I haven't found a discussion for fixed effects. It
looks like one option would be refitting with all my fixed effects as
random - but I'm concerned that might be bonkers, or that there might be an
easier way.

For previous multilevel modeling with lmer, I've used the approach
following Nakagawa et al. 2013 (A general and simple method for obtaining
R2 from generalized linear mixed-effects models. Methods in Ecology and
Evolution, 4(2), 133?142. http://doi.org/10.1111/j.2041-210x.2012.00261.x)
to calculate conditional and marginal R^2...
but I'm not sure how to adapt it for the (for me) brave new world of
MCMCglmm.

I would be grateful for any advice!

Thanks so much for your time.

Warmly,
Rafter


Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From stevedrd at yahoo.com  Thu Jul 16 11:15:04 2015
From: stevedrd at yahoo.com (Steve Denham)
Date: Thu, 16 Jul 2015 09:15:04 +0000 (UTC)
Subject: [R-sig-ME] Method to transform fixed effect parameter estimates
 back on to the response scale [after glmer() with family=Gamma(link =
 "log")] ??
In-Reply-To: <CAGmnqXgNR+jFM-gZYaadsyO9CmRx7voMFFmQpoaOrwFfzJHrYg@mail.gmail.com>
References: <CAGmnqXgNR+jFM-gZYaadsyO9CmRx7voMFFmQpoaOrwFfzJHrYg@mail.gmail.com>
Message-ID: <1412028052.1639391.1437038104291.JavaMail.yahoo@mail.yahoo.com>

Hi Dan,
While that would be nice, it just isn't the case that for a gamma distributed variable that there is an increase of some fixed amount for a given change in the predictor. ?What actually happens is that for a given change in the predictor, there is a fixed MULTIPLICATIVE change. ?Say that coefficient for the fixed effect is 2. ?Then for a unit increase in the fixed effect, I believe the response would be exp(2*(unit change)) larger (It is early and caffeine hasn't kicked in yet, so that may be incorrect). ?Unit changes at larger values will have a greater effect on the response than at smaller values.?Steve Denham
Director, Biostatistics
MPI Research, Inc.
 
      From: Daniel Newman <dan.newman86 at gmail.com>
 To: r-sig-mixed-models at r-project.org 
 Sent: Thursday, July 16, 2015 1:41 AM
 Subject: [R-sig-ME] Method to transform fixed effect parameter estimates back on to the response scale [after glmer() with family=Gamma(link = "log")] ??
   
Subject: Method to transform fixed effect parameter estimates back on to
the response scale [after glmer() with family=Gamma(link = "log")] ??

Dear lme4 experts,

I am using lme4 to model human reaction-time (RT; in milliseconds)
responses. My model includes both nested and fully crossed random
intercepts, and fixed effect ?predictor? factors.

lmer() seems to work quite well for this, and is nice since I can use the
fixed effect parameter estimates (beta and Std.Errors) for interpretation
to say that for every unit of the ?predictor? that changes, we expect a
change of ~beta units in RT on the response scale (milliseconds). Pretty
happy with the results?.BUT?

glmer() may be the better option since the response distribution has a
positive skew with no zero values (typical RT distribution), and glmer()
allows the same model specification as my lmer() model, except using
family=Gamma(link = "log") to account for the skewed response distribution.

This seems to work well and gives very similar results to the equivalent
lmer() model, but with somewhat improved residual plots, so I guess the
glmer() with family=Gamma(link = "log") is a more valid approach since it
explicitly accounts for the shape of response distribution.

PROBLEM: Is there a way to transform the fixed effect parameter estimates
and Std.Errors from the glmer() with family=Gamma(link = "log"), back to
the response scale (i.e. back to RT in milliseconds). It would be nice/aid
interpretation to say that for every unit of the ?predictor? that changes,
we expect a change of ~beta units on the response scale.

Thank you so much for your time!!

Cheers
Dan


--

??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Thu Jul 16 21:33:17 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 16 Jul 2015 15:33:17 -0400
Subject: [R-sig-ME] TEST3: Please ignore this message,
 I am trying to determine why messages I send to the list are not
 forwarded to me Thank you, John
References: 55A11FC1.medlxdom.medlxpo.200.20000CB.1.132897.1
Message-ID: <55A7CEBD020000CB001331AB@smtp.medicine.umaryland.edu>

TEST3


My apologies to one and all for posting this message for the third time. I believe I have solved the problem I have had (not receiving any messages from the list) and this email message will let me know if I have. The problem appears to have been a setting in my user profile which was not set to ON to inform the listserver to send messages from the listserver to me. I will know I changing the setting solves my problem in a few minutes . . . . Again my apologies!


P.S. I waited half a day hoping to get a message from the list before I sent this message to the listserver. I have not received any messages. I do not know if that is because I still have a problem, or if the list is not vary active, hence my sending this message.




TEST2
 
TEST: Please ignore this message, I am trying to determine why messages I send to the list are not forwarded to me      Thank you, John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 



Call
Send SMS
Call from mobile
Add to Skype
You'll need Skype CreditFree via Skype


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From paul.buerkner at gmail.com  Sat Jul 18 20:40:23 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Sat, 18 Jul 2015 20:40:23 +0200
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <55A6CE1F.5070404@ufl.edu>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>
	<55A6C4E2.10305@gmail.com> <55A6CE1F.5070404@ufl.edu>
Message-ID: <CAGoSky-tugtuMODo-h1YcG8+Z5NQ9aZmaSv_Kh8drqfmOepG+A@mail.gmail.com>

I managed to fit the models with bayesian techniques using the package brms.

Because your data is so huge, I decided to run only 500 iterations, of
which 100 are warmup (i.e. burnin). As brms uses Stan on the backend, the
quality of the samples is relatively high so that 400 markov samples should
be enough for our purposes.

Below I present the results of the maximal model as well as the model
withour any random effects for x1 and x2. The related plots are attached.

First, the maximal model (fit1_brm):

Family: bernoulli (logit)
Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 +
x2 | region)
   Data: data (Number of observations: 212570)
Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
         total post-warmup samples = 400

Random Effects:
~country (Number of levels: 82)
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.59      0.08     0.44     0.75        140    1

~country:wave (Number of levels: 143)
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.42      0.04     0.34     0.51        148    1

~region (Number of levels: 6)
                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)         0.24      0.20     0.01     0.77        300    1
sd(x1)                0.41      0.38     0.02     1.44        398    1
sd(x2)                0.57      0.45     0.03     1.75        289    1
cor(Intercept,x1)     0.04      0.47    -0.84     0.86        400    1
cor(Intercept,x2)    -0.20      0.46    -0.90     0.70        400    1
cor(x1,x2)           -0.14      0.50    -0.92     0.87        400    1

Fixed Effects:
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
Intercept    -0.61      0.15    -0.91    -0.36        400    1
x1            0.43      0.39    -0.31     1.20        400    1
x2            0.02      0.40    -0.69     0.81        344    1

Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample is a
crude measure of effective sample size, and Rhat is the potential scale
reduction factor on split chains (at convergence, Rhat = 1).




>From what I see, the results differ from lme4 in four aspects.

1. Indeed, there seems to be not enough evidence in the data to estimate
the random effects correlations reasonably, as implied by the huge CIs. The
Estimates (means in this case) are close to 0 instead of -1 or 1, which
seems more intuitive from my perspective.
2. While the random effects standard deviations of country and country:wave
are similar to lme4 (their posterior distributions are nearly symmetric;
see plot_fit1_brm in the attachment), the sds of region are considerably
larger than the ones estimated by lme4. This is because the mode is always
smaller than the mean when the distributions a right skewed. Especially,
from my perspective, they do not seem to be so small that removing them
from the model would be justified (I am currently running the same model
without correlations but the results shouldnt be too different).
3. The estimate of x1 is a bit smaller than in lme4 (0.43 against 0.49).
Unfortunately, I do not have any immediate explanation for this...
4. The standard error of x1 has nearly doubled as compared to lme4 (0.39
against 0.2).  As a result, the CI is almost twice a large.  Most likely,
this is because the random effects sd of x1 is much larger than in lme4,
which also affects the standard error of the fixed effect.

To test, whether 4. is solely because of the random effects of x1, I
completely removed them in the second model (fit2_brm):

Family: bernoulli (logit)
Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 | region)
   Data: data (Number of observations: 212570)
Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
         total post-warmup samples = 400

Random Effects:
~country (Number of levels: 82)
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.61      0.08     0.49     0.77         96 1.03

~country:wave (Number of levels: 143)
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)      0.4      0.04     0.34     0.49        197 1.01

~region (Number of levels: 6)
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.27      0.19     0.03     0.72        278    1

Fixed Effects:
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
Intercept    -0.61      0.15    -0.95    -0.31        400 1.01
x1            0.42      0.25    -0.05     0.89        400 1.00
x2           -0.04      0.22    -0.46     0.37        400 1.00

Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample is a
crude measure of effective sample size, and Rhat is the potential scale
reduction factor on split chains (at convergence, Rhat = 1).


The standard error of x1 indeed went down being close to what lme4
estimated (0.25 against 0.24). What I find suspicius is that the maximal
model in lme4 (i.e. the one including random effects for x1) estimates lower
standard error for the fixed effect of x1 than the model without those
random effects (see the results of Reinhold Klingl). From my perspective,
this is unlikely to be correct. Whats your opinon on this?


2015-07-15 23:18 GMT+02:00 Ben Bolker <bbolker at gmail.com>:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 15-07-15 04:38 PM, Ben Bolker wrote:
> > On 15-07-15 12:52 PM, Paul Buerkner wrote:
> >> if you look at the results from a baysian perspective, it seems
> >> to be a typcial "problem" of ML-procedures estimating the mode.
> >>
> >> The mode is nothing special, just the point where the density is
> >> maximal. When you have skewed distribution (as usual for
> >> correlations) the mode will often be close to the borders of the
> >> region of definition (-1 or 1 in this case). The posterior
> >> distribution of the correlation, however, can still be very wide
> >> ranging from strong negative correlation to strong positive
> >> correlation, especially when the number of levels of a grouping
> >> factor is not that large. In those cases, zero (i.e.
> >> insignificant) correlation is a very likely value even if the
> >> mode itself is extreme.
> >>
> >> I tried fitting your models with bayesian R packages (brms and
> >> MCMCglmm). Unfortunately, because you have so many observations
> >> and quite a few random effects, they run relatively slow so i am
> >> still waiting for the results.
> >
>
>  You can also use blme, which implements a very thin Bayesian wrapper
> around [g]lmer and does maximum _a posteriori_ (i.e. Bayesian mode)
> estimates with
> weak (but principled) priors on the random effects -- it's based on
>
> Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and
> Jingchen Liu. ?A Nondegenerate Penalized Likelihood Estimator for
> Variance Parameters in Multilevel Models.? Psychometrika 78, no. 4
> (March 12, 2013): 685?709. doi:10.1007/s11336-013-9328-2.
>
>   Profile 'likelihood' confidence intervals based on blme will get you
> a reasonable approximation of the width of the credible interval,
> although it's a little bit of a cheesy/awkward combination between
> marginal (proper Bayesian) and conditional (MAP/cheesy-Bayesian)
> measures of uncertainty.
>
>
>
>
>
> >> 2015-07-15 3:45 GMT+02:00 svm <steven.v.miller at gmail.com>:
> >>
> >>> I considered that. I disaggregated the region random effect
> >>> from 6 to 18 (the latter of which approximates the World Bank's
> >>> region classification). I'm still encountering the same curious
> >>> issue.
> >>>
> >>> Random effects: Groups       Name        Variance  Std.Dev.
> >>> Corr country:wave (Intercept) 0.1530052 0.39116 country
> >>> (Intercept) 0.3735876 0.61122 wbregion     (Intercept)
> >>> 0.0137822 0.11740 x1        0.0009384 0.03063  -1.00 x2
> >>> 0.0767387 0.27702  -1.00  1.00 Number of obs: 212570, groups:
> >>> country:wave, 143; country, 82; wbregion, 18
> >>>
> >>> For what it's worth: the model estimates fine. The results are
> >>> intuitive and theoretically consistent. They also don't change
> >>> if I were to remove that region random effect. I'd like to keep
> >>> the region random effect (with varying slopes) in the model.
> >>> I'm struggling with what I should think about the perfect
> >>> correlations.
> >>>
> >>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall
> >>> <jake987722 at hotmail.com> wrote:
> >>>
> >>>> Hi Steve,
> >>>>
> >>>>
> >>>> I think the issue is that estimating 3 variances and 3
> >>>> covariances for regions is quite ambitious given that there
> >>>> are only 6 regions. I think it's not surprising that the
> >>>> model has a hard time getting good estimates of those
> >>>> parameters.
> >>>>
> >>>>
> >>>> Jake
> >>>>
> >>>>> Date: Tue, 14 Jul 2015 20:53:01 -0400 From:
> >>>>> steven.v.miller at gmail.com To:
> >>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME]
> >>>>> Perfectly correlated random effects (when they
> >>>> shouldn't be)
> >>>>
> >>>>>
> >>>>> Hi all,
> >>>>>
> >>>>> I'm a long-time reader and wanted to raise a question I've
> >>>>> seen asked
> >>>> here
> >>>>> before about correlated random effects. Past answers I have
> >>>>> encountered
> >>>> on
> >>>>> this listserv explain that perfectly correlated random
> >>>>> effects suggest model overfitting and variances of random
> >>>>> effects that are effectively
> >>>> zero
> >>>>> and can be omitted for a simpler model. In my case, I don't
> >>>>> think
> >>> that's
> >>>>> what is happening here, though I could well be fitting a
> >>>>> poor model in glmer.
> >>>>>
> >>>>> I'll describe the nature of the data first. I'm modeling
> >>> individual-level
> >>>>> survey data for countries across multiple waves and am
> >>>>> estimating the region of the globe as a random effect as
> >>>>> well. I have three random
> >>>> effects
> >>>>> (country, country-wave, and region). In the region random
> >>>>> effect, I am allowing country-wave-level predictors to have
> >>>>> varying slopes. My
> >>> inquiry
> >>>>> is whether some country-wave-level contextual indicator can
> >>>>> have an
> >>>> overall
> >>>>> effect (as a fixed effect), the effect of which can vary by
> >>>>> region. In other words: is the effect of some country-level
> >>>>> indicator (e.g. unemployment) in a given year different for
> >>>>> countries in Western Europe than for countries in Africa
> >>>>> even if, on average, there is a positive
> >>> or
> >>>>> negative association at the individual-level? These
> >>>>> country-wave-level predictors that I allow to vary by
> >>>>> region are the ones reporting
> >>> perfect
> >>>>> correlation and I'm unsure how to interpret that (or if I'm
> >>>>> estimating
> >>>> the
> >>>>> model correctly).
> >>>>>
> >>>>> I should also add that I have individual-level predictors
> >>>>> as well as country-wave-level predictors, though it's the
> >>>>> latter that concerns me. Further, every non-binary
> >>>>> indicator in the model is standardized by two standard
> >>>>> deviations.
> >>>>>
> >>>>> For those interested, I have a reproducible (if rather
> >>>>> large) example below. Dropbox link to the data is here:
> >>>>>
> >>>>
> >>>
> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
> >>>>>
> >>>>>
> >>>
> In this reproducible example, y is the outcome variable and x1 and x2
> >>> are
> >>>>> two country-wave-level predictors I allow to vary by
> >>>>> region. Both x1
> >>> and
> >>>> x2
> >>>>> are interval-level predictors that I standardized to have a
> >>>>> mean of
> >>> zero
> >>>>> and a standard deviation of .5 (per Gelman's (2008)
> >>>>> recommendation).
> >>>>>
> >>>>> I estimate the following model.
> >>>>>
> >>>>> summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
> >>>>> country:wave) +
> >>>> (1 +
> >>>>> x1 + x2 | region), data=subset(Data),
> >>>>> family=binomial(link="logit")))
> >>>>>
> >>>>> The results are theoretically intuitive. I think they make
> >>>>> sense.
> >>>> However,
> >>>>> I get a report of perfect correlation for the varying
> >>>>> slopes of the
> >>>> region
> >>>>> random effect.
> >>>>>
> >>>>> Random effects: Groups Name Variance Std.Dev. Corr
> >>>>> country:wave (Intercept) 0.15915 0.3989 country (Intercept)
> >>>>> 0.32945 0.5740 region (Intercept) 0.01646 0.1283 x1 0.02366
> >>>>> 0.1538 1.00 x2 0.13994 0.3741 -1.00 -1.00 Number of obs:
> >>>>> 212570, groups: country:wave, 143; country, 82; region,
> >>> 6
> >>>>>
> >>>>> What should I make of this and am I estimating this model
> >>>>> wrong? For
> >>> what
> >>>>> it's worth, the dotplot of the region random effect (with
> >>>>> conditional variance) makes sense and is theoretically
> >>>>> intuitive, given my data. (
> >>>>> http://i.imgur.com/mrnaJ77.png)
> >>>>>
> >>>>> Any help would be greatly appreciated.
> >>>>>
> >>>>> Best regards, Steve
> >>>>>
> >>>>> [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>
> >>>
> >>> -- Steven V. Miller Assistant Professor Department of Political
> >>> Science Clemson University http://svmiller.com
> >>>
> >>> [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVps4fAAoJEOCV5YRblxUH0wQIANBg6CaKoHuM6RQY5VltpEbk
> 5+RYc0tIYXmvNzGesG0QTQaLz0A5cx5mo0EGxsKQq8vUz2ycRlSlcYo9uI0K/xft
> D8MMhdVr8QhIW2RtoWPNPzn6HIe276CFnHg4Co+3vbMcccbvTvWvxsDYaT/LOlRn
> JoVjN/HcOscMOQkAxZV6elYBZe+kbVVhOS0SNo3Bt5P528EuWIxaRlC2lO5aoHSL
> 1cgLn5uyWLsxb3Cuu3FctwYfYOk9hsEXNM/EGMleshDq6umGtSm9lqiM8vqgSnMl
> Iyp2A+r3fkRzfEZyWv0Ygi4OA0iZ5/BSH44+sR60hj/qSpqGYwUQ+fIrfKXAYTw=
> =cHT0
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot_fit1_brm.pdf
Type: application/pdf
Size: 78421 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150718/61a496b2/attachment-0002.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot_fit2_brm.pdf
Type: application/pdf
Size: 45943 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20150718/61a496b2/attachment-0003.pdf>

From steven.v.miller at gmail.com  Sat Jul 18 22:29:53 2015
From: steven.v.miller at gmail.com (svm)
Date: Sat, 18 Jul 2015 16:29:53 -0400
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CAGoSky-tugtuMODo-h1YcG8+Z5NQ9aZmaSv_Kh8drqfmOepG+A@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>
	<55A6C4E2.10305@gmail.com> <55A6CE1F.5070404@ufl.edu>
	<CAGoSky-tugtuMODo-h1YcG8+Z5NQ9aZmaSv_Kh8drqfmOepG+A@mail.gmail.com>
Message-ID: <CABafbio6TQ71daEu+UOF22U7m_=j5=eXP+rPUsRL2Gy3+yHh8A@mail.gmail.com>

Genuinely had no idea about that brms package in R. Is it new? It looks
very intriguing, though the syntax I'm seeing in the reference manual
doesn't appear to be working. Do you mind if I see the code? Maybe I'm
doing it wrong.

I followed Ben's advice and pursued a blmer strategy with a disaggregated
version of the random effects variable. I ran the full models (so: not the
simple reproducible example) and got something that makes more sense. I
also corrected for various weird data points (i.e. countries whose surveys
were likely botched in execution). Here is the summary of the random
effects.

Random effects:
 Groups       Name        Variance Std.Dev. Corr
 country:wave (Intercept) 0.16091  0.4011
 country      (Intercept) 0.34949  0.5912
 region       (Intercept) 0.04604  0.2146
              eti         0.24501  0.4950    0.20
              sti         0.18997  0.4359   -0.45 -0.04
Number of obs: 208551, groups:  country:wave, 143; country, 82; region, 13

I think this makes sense. The regions ultimately don't vary that much from
each other, which I think is intuitive, given the data. The correlations
among the random slopes are importantly not 0, -1, or 1.

In a full model (with controls), the significance of the z-value associated
with x1 is 1.741 (coeff: .516, sd: .296), which is below the conventional
cutoff of z = 1.96. My field is kind of a "cult of p < .05" crowd, but I'm
not terribly bothered by this. I do believe what I'm doing here is a very
conservative test of where x1 is discernible from zero across the range of
the data.

As for the comparison between x1 in fit2_brm versus the maximal model in
lme4: I honestly don't know. I learn something new each time I do a mixed
effects analysis, but I can offer no immediate answer for that.

I definitely do appreciate the input of this listserv. I'm more than
grateful for your time and patience with me.

Best regards,
Steve

On Sat, Jul 18, 2015 at 2:40 PM, Paul Buerkner <paul.buerkner at gmail.com>
wrote:

> I managed to fit the models with bayesian techniques using the package
> brms.
>
> Because your data is so huge, I decided to run only 500 iterations, of
> which 100 are warmup (i.e. burnin). As brms uses Stan on the backend, the
> quality of the samples is relatively high so that 400 markov samples should
> be enough for our purposes.
>
> Below I present the results of the maximal model as well as the model
> withour any random effects for x1 and x2. The related plots are attached.
>
> First, the maximal model (fit1_brm):
>
> Family: bernoulli (logit)
> Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 +
> x2 | region)
>    Data: data (Number of observations: 212570)
> Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
>          total post-warmup samples = 400
>
> Random Effects:
> ~country (Number of levels: 82)
>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sd(Intercept)     0.59      0.08     0.44     0.75        140    1
>
> ~country:wave (Number of levels: 143)
>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sd(Intercept)     0.42      0.04     0.34     0.51        148    1
>
> ~region (Number of levels: 6)
>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sd(Intercept)         0.24      0.20     0.01     0.77        300    1
> sd(x1)                0.41      0.38     0.02     1.44        398    1
> sd(x2)                0.57      0.45     0.03     1.75        289    1
> cor(Intercept,x1)     0.04      0.47    -0.84     0.86        400    1
> cor(Intercept,x2)    -0.20      0.46    -0.90     0.70        400    1
> cor(x1,x2)           -0.14      0.50    -0.92     0.87        400    1
>
> Fixed Effects:
>           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> Intercept    -0.61      0.15    -0.91    -0.36        400    1
> x1            0.43      0.39    -0.31     1.20        400    1
> x2            0.02      0.40    -0.69     0.81        344    1
>
> Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample is a
> crude measure of effective sample size, and Rhat is the potential scale
> reduction factor on split chains (at convergence, Rhat = 1).
>
>
>
>
> >From what I see, the results differ from lme4 in four aspects.
>
> 1. Indeed, there seems to be not enough evidence in the data to estimate
> the random effects correlations reasonably, as implied by the huge CIs. The
> Estimates (means in this case) are close to 0 instead of -1 or 1, which
> seems more intuitive from my perspective.
> 2. While the random effects standard deviations of country and country:wave
> are similar to lme4 (their posterior distributions are nearly symmetric;
> see plot_fit1_brm in the attachment), the sds of region are considerably
> larger than the ones estimated by lme4. This is because the mode is always
> smaller than the mean when the distributions a right skewed. Especially,
> from my perspective, they do not seem to be so small that removing them
> from the model would be justified (I am currently running the same model
> without correlations but the results shouldnt be too different).
> 3. The estimate of x1 is a bit smaller than in lme4 (0.43 against 0.49).
> Unfortunately, I do not have any immediate explanation for this...
> 4. The standard error of x1 has nearly doubled as compared to lme4 (0.39
> against 0.2).  As a result, the CI is almost twice a large.  Most likely,
> this is because the random effects sd of x1 is much larger than in lme4,
> which also affects the standard error of the fixed effect.
>
> To test, whether 4. is solely because of the random effects of x1, I
> completely removed them in the second model (fit2_brm):
>
> Family: bernoulli (logit)
> Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 | region)
>    Data: data (Number of observations: 212570)
> Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
>          total post-warmup samples = 400
>
> Random Effects:
> ~country (Number of levels: 82)
>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sd(Intercept)     0.61      0.08     0.49     0.77         96 1.03
>
> ~country:wave (Number of levels: 143)
>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sd(Intercept)      0.4      0.04     0.34     0.49        197 1.01
>
> ~region (Number of levels: 6)
>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> sd(Intercept)     0.27      0.19     0.03     0.72        278    1
>
> Fixed Effects:
>           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> Intercept    -0.61      0.15    -0.95    -0.31        400 1.01
> x1            0.42      0.25    -0.05     0.89        400 1.00
> x2           -0.04      0.22    -0.46     0.37        400 1.00
>
> Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample is a
> crude measure of effective sample size, and Rhat is the potential scale
> reduction factor on split chains (at convergence, Rhat = 1).
>
>
> The standard error of x1 indeed went down being close to what lme4
> estimated (0.25 against 0.24). What I find suspicius is that the maximal
> model in lme4 (i.e. the one including random effects for x1) estimates
> lower
> standard error for the fixed effect of x1 than the model without those
> random effects (see the results of Reinhold Klingl). From my perspective,
> this is unlikely to be correct. Whats your opinon on this?
>
>
> 2015-07-15 23:18 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
>
> > -----BEGIN PGP SIGNED MESSAGE-----
> > Hash: SHA1
> >
> > On 15-07-15 04:38 PM, Ben Bolker wrote:
> > > On 15-07-15 12:52 PM, Paul Buerkner wrote:
> > >> if you look at the results from a baysian perspective, it seems
> > >> to be a typcial "problem" of ML-procedures estimating the mode.
> > >>
> > >> The mode is nothing special, just the point where the density is
> > >> maximal. When you have skewed distribution (as usual for
> > >> correlations) the mode will often be close to the borders of the
> > >> region of definition (-1 or 1 in this case). The posterior
> > >> distribution of the correlation, however, can still be very wide
> > >> ranging from strong negative correlation to strong positive
> > >> correlation, especially when the number of levels of a grouping
> > >> factor is not that large. In those cases, zero (i.e.
> > >> insignificant) correlation is a very likely value even if the
> > >> mode itself is extreme.
> > >>
> > >> I tried fitting your models with bayesian R packages (brms and
> > >> MCMCglmm). Unfortunately, because you have so many observations
> > >> and quite a few random effects, they run relatively slow so i am
> > >> still waiting for the results.
> > >
> >
> >  You can also use blme, which implements a very thin Bayesian wrapper
> > around [g]lmer and does maximum _a posteriori_ (i.e. Bayesian mode)
> > estimates with
> > weak (but principled) priors on the random effects -- it's based on
> >
> > Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and
> > Jingchen Liu. ?A Nondegenerate Penalized Likelihood Estimator for
> > Variance Parameters in Multilevel Models.? Psychometrika 78, no. 4
> > (March 12, 2013): 685?709. doi:10.1007/s11336-013-9328-2.
> >
> >   Profile 'likelihood' confidence intervals based on blme will get you
> > a reasonable approximation of the width of the credible interval,
> > although it's a little bit of a cheesy/awkward combination between
> > marginal (proper Bayesian) and conditional (MAP/cheesy-Bayesian)
> > measures of uncertainty.
> >
> >
> >
> >
> >
> > >> 2015-07-15 3:45 GMT+02:00 svm <steven.v.miller at gmail.com>:
> > >>
> > >>> I considered that. I disaggregated the region random effect
> > >>> from 6 to 18 (the latter of which approximates the World Bank's
> > >>> region classification). I'm still encountering the same curious
> > >>> issue.
> > >>>
> > >>> Random effects: Groups       Name        Variance  Std.Dev.
> > >>> Corr country:wave (Intercept) 0.1530052 0.39116 country
> > >>> (Intercept) 0.3735876 0.61122 wbregion     (Intercept)
> > >>> 0.0137822 0.11740 x1        0.0009384 0.03063  -1.00 x2
> > >>> 0.0767387 0.27702  -1.00  1.00 Number of obs: 212570, groups:
> > >>> country:wave, 143; country, 82; wbregion, 18
> > >>>
> > >>> For what it's worth: the model estimates fine. The results are
> > >>> intuitive and theoretically consistent. They also don't change
> > >>> if I were to remove that region random effect. I'd like to keep
> > >>> the region random effect (with varying slopes) in the model.
> > >>> I'm struggling with what I should think about the perfect
> > >>> correlations.
> > >>>
> > >>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall
> > >>> <jake987722 at hotmail.com> wrote:
> > >>>
> > >>>> Hi Steve,
> > >>>>
> > >>>>
> > >>>> I think the issue is that estimating 3 variances and 3
> > >>>> covariances for regions is quite ambitious given that there
> > >>>> are only 6 regions. I think it's not surprising that the
> > >>>> model has a hard time getting good estimates of those
> > >>>> parameters.
> > >>>>
> > >>>>
> > >>>> Jake
> > >>>>
> > >>>>> Date: Tue, 14 Jul 2015 20:53:01 -0400 From:
> > >>>>> steven.v.miller at gmail.com To:
> > >>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME]
> > >>>>> Perfectly correlated random effects (when they
> > >>>> shouldn't be)
> > >>>>
> > >>>>>
> > >>>>> Hi all,
> > >>>>>
> > >>>>> I'm a long-time reader and wanted to raise a question I've
> > >>>>> seen asked
> > >>>> here
> > >>>>> before about correlated random effects. Past answers I have
> > >>>>> encountered
> > >>>> on
> > >>>>> this listserv explain that perfectly correlated random
> > >>>>> effects suggest model overfitting and variances of random
> > >>>>> effects that are effectively
> > >>>> zero
> > >>>>> and can be omitted for a simpler model. In my case, I don't
> > >>>>> think
> > >>> that's
> > >>>>> what is happening here, though I could well be fitting a
> > >>>>> poor model in glmer.
> > >>>>>
> > >>>>> I'll describe the nature of the data first. I'm modeling
> > >>> individual-level
> > >>>>> survey data for countries across multiple waves and am
> > >>>>> estimating the region of the globe as a random effect as
> > >>>>> well. I have three random
> > >>>> effects
> > >>>>> (country, country-wave, and region). In the region random
> > >>>>> effect, I am allowing country-wave-level predictors to have
> > >>>>> varying slopes. My
> > >>> inquiry
> > >>>>> is whether some country-wave-level contextual indicator can
> > >>>>> have an
> > >>>> overall
> > >>>>> effect (as a fixed effect), the effect of which can vary by
> > >>>>> region. In other words: is the effect of some country-level
> > >>>>> indicator (e.g. unemployment) in a given year different for
> > >>>>> countries in Western Europe than for countries in Africa
> > >>>>> even if, on average, there is a positive
> > >>> or
> > >>>>> negative association at the individual-level? These
> > >>>>> country-wave-level predictors that I allow to vary by
> > >>>>> region are the ones reporting
> > >>> perfect
> > >>>>> correlation and I'm unsure how to interpret that (or if I'm
> > >>>>> estimating
> > >>>> the
> > >>>>> model correctly).
> > >>>>>
> > >>>>> I should also add that I have individual-level predictors
> > >>>>> as well as country-wave-level predictors, though it's the
> > >>>>> latter that concerns me. Further, every non-binary
> > >>>>> indicator in the model is standardized by two standard
> > >>>>> deviations.
> > >>>>>
> > >>>>> For those interested, I have a reproducible (if rather
> > >>>>> large) example below. Dropbox link to the data is here:
> > >>>>>
> > >>>>
> > >>>
> >
> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
> > >>>>>
> > >>>>>
> > >>>
> > In this reproducible example, y is the outcome variable and x1 and x2
> > >>> are
> > >>>>> two country-wave-level predictors I allow to vary by
> > >>>>> region. Both x1
> > >>> and
> > >>>> x2
> > >>>>> are interval-level predictors that I standardized to have a
> > >>>>> mean of
> > >>> zero
> > >>>>> and a standard deviation of .5 (per Gelman's (2008)
> > >>>>> recommendation).
> > >>>>>
> > >>>>> I estimate the following model.
> > >>>>>
> > >>>>> summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
> > >>>>> country:wave) +
> > >>>> (1 +
> > >>>>> x1 + x2 | region), data=subset(Data),
> > >>>>> family=binomial(link="logit")))
> > >>>>>
> > >>>>> The results are theoretically intuitive. I think they make
> > >>>>> sense.
> > >>>> However,
> > >>>>> I get a report of perfect correlation for the varying
> > >>>>> slopes of the
> > >>>> region
> > >>>>> random effect.
> > >>>>>
> > >>>>> Random effects: Groups Name Variance Std.Dev. Corr
> > >>>>> country:wave (Intercept) 0.15915 0.3989 country (Intercept)
> > >>>>> 0.32945 0.5740 region (Intercept) 0.01646 0.1283 x1 0.02366
> > >>>>> 0.1538 1.00 x2 0.13994 0.3741 -1.00 -1.00 Number of obs:
> > >>>>> 212570, groups: country:wave, 143; country, 82; region,
> > >>> 6
> > >>>>>
> > >>>>> What should I make of this and am I estimating this model
> > >>>>> wrong? For
> > >>> what
> > >>>>> it's worth, the dotplot of the region random effect (with
> > >>>>> conditional variance) makes sense and is theoretically
> > >>>>> intuitive, given my data. (
> > >>>>> http://i.imgur.com/mrnaJ77.png)
> > >>>>>
> > >>>>> Any help would be greatly appreciated.
> > >>>>>
> > >>>>> Best regards, Steve
> > >>>>>
> > >>>>> [[alternative HTML version deleted]]
> > >>>>>
> > >>>>> _______________________________________________
> > >>>>> R-sig-mixed-models at r-project.org mailing list
> > >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>>>
> > >>>
> > >>>
> > >>>
> > >>> -- Steven V. Miller Assistant Professor Department of Political
> > >>> Science Clemson University http://svmiller.com
> > >>>
> > >>> [[alternative HTML version deleted]]
> > >>>
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>>
> > >>
> > >> [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> >
> > -----BEGIN PGP SIGNATURE-----
> > Version: GnuPG v1.4.11 (GNU/Linux)
> >
> > iQEcBAEBAgAGBQJVps4fAAoJEOCV5YRblxUH0wQIANBg6CaKoHuM6RQY5VltpEbk
> > 5+RYc0tIYXmvNzGesG0QTQaLz0A5cx5mo0EGxsKQq8vUz2ycRlSlcYo9uI0K/xft
> > D8MMhdVr8QhIW2RtoWPNPzn6HIe276CFnHg4Co+3vbMcccbvTvWvxsDYaT/LOlRn
> > JoVjN/HcOscMOQkAxZV6elYBZe+kbVVhOS0SNo3Bt5P528EuWIxaRlC2lO5aoHSL
> > 1cgLn5uyWLsxb3Cuu3FctwYfYOk9hsEXNM/EGMleshDq6umGtSm9lqiM8vqgSnMl
> > Iyp2A+r3fkRzfEZyWv0Ygi4OA0iZ5/BSH44+sR60hj/qSpqGYwUQ+fIrfKXAYTw=
> > =cHT0
> > -----END PGP SIGNATURE-----
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Sat Jul 18 23:38:41 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Sat, 18 Jul 2015 23:38:41 +0200
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CABafbio6TQ71daEu+UOF22U7m_=j5=eXP+rPUsRL2Gy3+yHh8A@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>
	<55A6C4E2.10305@gmail.com> <55A6CE1F.5070404@ufl.edu>
	<CAGoSky-tugtuMODo-h1YcG8+Z5NQ9aZmaSv_Kh8drqfmOepG+A@mail.gmail.com>
	<CABafbio6TQ71daEu+UOF22U7m_=j5=eXP+rPUsRL2Gy3+yHh8A@mail.gmail.com>
Message-ID: <CAGoSky8=okEO_MrTiueSohUh7a9Y3uWjVSafWqW3GvgpJ3Xc_Q@mail.gmail.com>

That looks better.

I used the developmental version of brms from github available through

library(devtools)
install_github("paul-buerkner/brms")

because the release version on CRAN does not yet support all relevant
features (the country:wave syntax is not accepted by brms 0.3.0).

The syntax i used was

library(brms)
fit1_brm <- brm(y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 +  x1
+ x2 | region),
                            data = data, family = "bernoulli", n.warmup =
100, n.iter = 500, n.chains = 1)
summary(fit1_brm)
plot(fit1_brm)

fit2_brm <- brm(y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 |
region),
                            data = data, family = "bernoulli", n.warmup =
100, n.iter = 500, n.chains = 1)
summary(fit2_brm)
plot(fit2_brm)

Remember that you have to install Stan to make brms work. It will take
several hours to fit those models, so be patient. :-)

2015-07-18 22:29 GMT+02:00 svm <steven.v.miller at gmail.com>:

> Genuinely had no idea about that brms package in R. Is it new? It looks
> very intriguing, though the syntax I'm seeing in the reference manual
> doesn't appear to be working. Do you mind if I see the code? Maybe I'm
> doing it wrong.
>
> I followed Ben's advice and pursued a blmer strategy with a disaggregated
> version of the random effects variable. I ran the full models (so: not the
> simple reproducible example) and got something that makes more sense. I
> also corrected for various weird data points (i.e. countries whose surveys
> were likely botched in execution). Here is the summary of the random
> effects.
>
> Random effects:
>  Groups       Name        Variance Std.Dev. Corr
>  country:wave (Intercept) 0.16091  0.4011
>  country      (Intercept) 0.34949  0.5912
>  region       (Intercept) 0.04604  0.2146
>               eti         0.24501  0.4950    0.20
>               sti         0.18997  0.4359   -0.45 -0.04
> Number of obs: 208551, groups:  country:wave, 143; country, 82; region, 13
>
> I think this makes sense. The regions ultimately don't vary that much from
> each other, which I think is intuitive, given the data. The correlations
> among the random slopes are importantly not 0, -1, or 1.
>
> In a full model (with controls), the significance of the z-value
> associated with x1 is 1.741 (coeff: .516, sd: .296), which is below the
> conventional cutoff of z = 1.96. My field is kind of a "cult of p < .05"
> crowd, but I'm not terribly bothered by this. I do believe what I'm doing
> here is a very conservative test of where x1 is discernible from zero
> across the range of the data.
>
> As for the comparison between x1 in fit2_brm versus the maximal model in
> lme4: I honestly don't know. I learn something new each time I do a mixed
> effects analysis, but I can offer no immediate answer for that.
>
> I definitely do appreciate the input of this listserv. I'm more than
> grateful for your time and patience with me.
>
> Best regards,
> Steve
>
> On Sat, Jul 18, 2015 at 2:40 PM, Paul Buerkner <paul.buerkner at gmail.com>
> wrote:
>
>> I managed to fit the models with bayesian techniques using the package
>> brms.
>>
>> Because your data is so huge, I decided to run only 500 iterations, of
>> which 100 are warmup (i.e. burnin). As brms uses Stan on the backend, the
>> quality of the samples is relatively high so that 400 markov samples
>> should
>> be enough for our purposes.
>>
>> Below I present the results of the maximal model as well as the model
>> withour any random effects for x1 and x2. The related plots are attached.
>>
>> First, the maximal model (fit1_brm):
>>
>> Family: bernoulli (logit)
>> Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 +
>> x2 | region)
>>    Data: data (Number of observations: 212570)
>> Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
>>          total post-warmup samples = 400
>>
>> Random Effects:
>> ~country (Number of levels: 82)
>>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sd(Intercept)     0.59      0.08     0.44     0.75        140    1
>>
>> ~country:wave (Number of levels: 143)
>>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sd(Intercept)     0.42      0.04     0.34     0.51        148    1
>>
>> ~region (Number of levels: 6)
>>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sd(Intercept)         0.24      0.20     0.01     0.77        300    1
>> sd(x1)                0.41      0.38     0.02     1.44        398    1
>> sd(x2)                0.57      0.45     0.03     1.75        289    1
>> cor(Intercept,x1)     0.04      0.47    -0.84     0.86        400    1
>> cor(Intercept,x2)    -0.20      0.46    -0.90     0.70        400    1
>> cor(x1,x2)           -0.14      0.50    -0.92     0.87        400    1
>>
>> Fixed Effects:
>>           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> Intercept    -0.61      0.15    -0.91    -0.36        400    1
>> x1            0.43      0.39    -0.31     1.20        400    1
>> x2            0.02      0.40    -0.69     0.81        344    1
>>
>> Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample is a
>> crude measure of effective sample size, and Rhat is the potential scale
>> reduction factor on split chains (at convergence, Rhat = 1).
>>
>>
>>
>>
>> >From what I see, the results differ from lme4 in four aspects.
>>
>> 1. Indeed, there seems to be not enough evidence in the data to estimate
>> the random effects correlations reasonably, as implied by the huge CIs.
>> The
>> Estimates (means in this case) are close to 0 instead of -1 or 1, which
>> seems more intuitive from my perspective.
>> 2. While the random effects standard deviations of country and
>> country:wave
>> are similar to lme4 (their posterior distributions are nearly symmetric;
>> see plot_fit1_brm in the attachment), the sds of region are considerably
>> larger than the ones estimated by lme4. This is because the mode is always
>> smaller than the mean when the distributions a right skewed. Especially,
>> from my perspective, they do not seem to be so small that removing them
>> from the model would be justified (I am currently running the same model
>> without correlations but the results shouldnt be too different).
>> 3. The estimate of x1 is a bit smaller than in lme4 (0.43 against 0.49).
>> Unfortunately, I do not have any immediate explanation for this...
>> 4. The standard error of x1 has nearly doubled as compared to lme4 (0.39
>> against 0.2).  As a result, the CI is almost twice a large.  Most likely,
>> this is because the random effects sd of x1 is much larger than in lme4,
>> which also affects the standard error of the fixed effect.
>>
>> To test, whether 4. is solely because of the random effects of x1, I
>> completely removed them in the second model (fit2_brm):
>>
>> Family: bernoulli (logit)
>> Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 | region)
>>    Data: data (Number of observations: 212570)
>> Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
>>          total post-warmup samples = 400
>>
>> Random Effects:
>> ~country (Number of levels: 82)
>>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sd(Intercept)     0.61      0.08     0.49     0.77         96 1.03
>>
>> ~country:wave (Number of levels: 143)
>>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sd(Intercept)      0.4      0.04     0.34     0.49        197 1.01
>>
>> ~region (Number of levels: 6)
>>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> sd(Intercept)     0.27      0.19     0.03     0.72        278    1
>>
>> Fixed Effects:
>>           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
>> Intercept    -0.61      0.15    -0.95    -0.31        400 1.01
>> x1            0.42      0.25    -0.05     0.89        400 1.00
>> x2           -0.04      0.22    -0.46     0.37        400 1.00
>>
>> Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample is a
>> crude measure of effective sample size, and Rhat is the potential scale
>> reduction factor on split chains (at convergence, Rhat = 1).
>>
>>
>> The standard error of x1 indeed went down being close to what lme4
>> estimated (0.25 against 0.24). What I find suspicius is that the maximal
>> model in lme4 (i.e. the one including random effects for x1) estimates
>> lower
>> standard error for the fixed effect of x1 than the model without those
>> random effects (see the results of Reinhold Klingl). From my perspective,
>> this is unlikely to be correct. Whats your opinon on this?
>>
>>
>> 2015-07-15 23:18 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
>>
>> > -----BEGIN PGP SIGNED MESSAGE-----
>> > Hash: SHA1
>> >
>> > On 15-07-15 04:38 PM, Ben Bolker wrote:
>> > > On 15-07-15 12:52 PM, Paul Buerkner wrote:
>> > >> if you look at the results from a baysian perspective, it seems
>> > >> to be a typcial "problem" of ML-procedures estimating the mode.
>> > >>
>> > >> The mode is nothing special, just the point where the density is
>> > >> maximal. When you have skewed distribution (as usual for
>> > >> correlations) the mode will often be close to the borders of the
>> > >> region of definition (-1 or 1 in this case). The posterior
>> > >> distribution of the correlation, however, can still be very wide
>> > >> ranging from strong negative correlation to strong positive
>> > >> correlation, especially when the number of levels of a grouping
>> > >> factor is not that large. In those cases, zero (i.e.
>> > >> insignificant) correlation is a very likely value even if the
>> > >> mode itself is extreme.
>> > >>
>> > >> I tried fitting your models with bayesian R packages (brms and
>> > >> MCMCglmm). Unfortunately, because you have so many observations
>> > >> and quite a few random effects, they run relatively slow so i am
>> > >> still waiting for the results.
>> > >
>> >
>> >  You can also use blme, which implements a very thin Bayesian wrapper
>> > around [g]lmer and does maximum _a posteriori_ (i.e. Bayesian mode)
>> > estimates with
>> > weak (but principled) priors on the random effects -- it's based on
>> >
>> > Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and
>> > Jingchen Liu. ?A Nondegenerate Penalized Likelihood Estimator for
>> > Variance Parameters in Multilevel Models.? Psychometrika 78, no. 4
>> > (March 12, 2013): 685?709. doi:10.1007/s11336-013-9328-2.
>> >
>> >   Profile 'likelihood' confidence intervals based on blme will get you
>> > a reasonable approximation of the width of the credible interval,
>> > although it's a little bit of a cheesy/awkward combination between
>> > marginal (proper Bayesian) and conditional (MAP/cheesy-Bayesian)
>> > measures of uncertainty.
>> >
>> >
>> >
>> >
>> >
>> > >> 2015-07-15 3:45 GMT+02:00 svm <steven.v.miller at gmail.com>:
>> > >>
>> > >>> I considered that. I disaggregated the region random effect
>> > >>> from 6 to 18 (the latter of which approximates the World Bank's
>> > >>> region classification). I'm still encountering the same curious
>> > >>> issue.
>> > >>>
>> > >>> Random effects: Groups       Name        Variance  Std.Dev.
>> > >>> Corr country:wave (Intercept) 0.1530052 0.39116 country
>> > >>> (Intercept) 0.3735876 0.61122 wbregion     (Intercept)
>> > >>> 0.0137822 0.11740 x1        0.0009384 0.03063  -1.00 x2
>> > >>> 0.0767387 0.27702  -1.00  1.00 Number of obs: 212570, groups:
>> > >>> country:wave, 143; country, 82; wbregion, 18
>> > >>>
>> > >>> For what it's worth: the model estimates fine. The results are
>> > >>> intuitive and theoretically consistent. They also don't change
>> > >>> if I were to remove that region random effect. I'd like to keep
>> > >>> the region random effect (with varying slopes) in the model.
>> > >>> I'm struggling with what I should think about the perfect
>> > >>> correlations.
>> > >>>
>> > >>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall
>> > >>> <jake987722 at hotmail.com> wrote:
>> > >>>
>> > >>>> Hi Steve,
>> > >>>>
>> > >>>>
>> > >>>> I think the issue is that estimating 3 variances and 3
>> > >>>> covariances for regions is quite ambitious given that there
>> > >>>> are only 6 regions. I think it's not surprising that the
>> > >>>> model has a hard time getting good estimates of those
>> > >>>> parameters.
>> > >>>>
>> > >>>>
>> > >>>> Jake
>> > >>>>
>> > >>>>> Date: Tue, 14 Jul 2015 20:53:01 -0400 From:
>> > >>>>> steven.v.miller at gmail.com To:
>> > >>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME]
>> > >>>>> Perfectly correlated random effects (when they
>> > >>>> shouldn't be)
>> > >>>>
>> > >>>>>
>> > >>>>> Hi all,
>> > >>>>>
>> > >>>>> I'm a long-time reader and wanted to raise a question I've
>> > >>>>> seen asked
>> > >>>> here
>> > >>>>> before about correlated random effects. Past answers I have
>> > >>>>> encountered
>> > >>>> on
>> > >>>>> this listserv explain that perfectly correlated random
>> > >>>>> effects suggest model overfitting and variances of random
>> > >>>>> effects that are effectively
>> > >>>> zero
>> > >>>>> and can be omitted for a simpler model. In my case, I don't
>> > >>>>> think
>> > >>> that's
>> > >>>>> what is happening here, though I could well be fitting a
>> > >>>>> poor model in glmer.
>> > >>>>>
>> > >>>>> I'll describe the nature of the data first. I'm modeling
>> > >>> individual-level
>> > >>>>> survey data for countries across multiple waves and am
>> > >>>>> estimating the region of the globe as a random effect as
>> > >>>>> well. I have three random
>> > >>>> effects
>> > >>>>> (country, country-wave, and region). In the region random
>> > >>>>> effect, I am allowing country-wave-level predictors to have
>> > >>>>> varying slopes. My
>> > >>> inquiry
>> > >>>>> is whether some country-wave-level contextual indicator can
>> > >>>>> have an
>> > >>>> overall
>> > >>>>> effect (as a fixed effect), the effect of which can vary by
>> > >>>>> region. In other words: is the effect of some country-level
>> > >>>>> indicator (e.g. unemployment) in a given year different for
>> > >>>>> countries in Western Europe than for countries in Africa
>> > >>>>> even if, on average, there is a positive
>> > >>> or
>> > >>>>> negative association at the individual-level? These
>> > >>>>> country-wave-level predictors that I allow to vary by
>> > >>>>> region are the ones reporting
>> > >>> perfect
>> > >>>>> correlation and I'm unsure how to interpret that (or if I'm
>> > >>>>> estimating
>> > >>>> the
>> > >>>>> model correctly).
>> > >>>>>
>> > >>>>> I should also add that I have individual-level predictors
>> > >>>>> as well as country-wave-level predictors, though it's the
>> > >>>>> latter that concerns me. Further, every non-binary
>> > >>>>> indicator in the model is standardized by two standard
>> > >>>>> deviations.
>> > >>>>>
>> > >>>>> For those interested, I have a reproducible (if rather
>> > >>>>> large) example below. Dropbox link to the data is here:
>> > >>>>>
>> > >>>>
>> > >>>
>> >
>> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
>> > >>>>>
>> > >>>>>
>> > >>>
>> > In this reproducible example, y is the outcome variable and x1 and x2
>> > >>> are
>> > >>>>> two country-wave-level predictors I allow to vary by
>> > >>>>> region. Both x1
>> > >>> and
>> > >>>> x2
>> > >>>>> are interval-level predictors that I standardized to have a
>> > >>>>> mean of
>> > >>> zero
>> > >>>>> and a standard deviation of .5 (per Gelman's (2008)
>> > >>>>> recommendation).
>> > >>>>>
>> > >>>>> I estimate the following model.
>> > >>>>>
>> > >>>>> summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
>> > >>>>> country:wave) +
>> > >>>> (1 +
>> > >>>>> x1 + x2 | region), data=subset(Data),
>> > >>>>> family=binomial(link="logit")))
>> > >>>>>
>> > >>>>> The results are theoretically intuitive. I think they make
>> > >>>>> sense.
>> > >>>> However,
>> > >>>>> I get a report of perfect correlation for the varying
>> > >>>>> slopes of the
>> > >>>> region
>> > >>>>> random effect.
>> > >>>>>
>> > >>>>> Random effects: Groups Name Variance Std.Dev. Corr
>> > >>>>> country:wave (Intercept) 0.15915 0.3989 country (Intercept)
>> > >>>>> 0.32945 0.5740 region (Intercept) 0.01646 0.1283 x1 0.02366
>> > >>>>> 0.1538 1.00 x2 0.13994 0.3741 -1.00 -1.00 Number of obs:
>> > >>>>> 212570, groups: country:wave, 143; country, 82; region,
>> > >>> 6
>> > >>>>>
>> > >>>>> What should I make of this and am I estimating this model
>> > >>>>> wrong? For
>> > >>> what
>> > >>>>> it's worth, the dotplot of the region random effect (with
>> > >>>>> conditional variance) makes sense and is theoretically
>> > >>>>> intuitive, given my data. (
>> > >>>>> http://i.imgur.com/mrnaJ77.png)
>> > >>>>>
>> > >>>>> Any help would be greatly appreciated.
>> > >>>>>
>> > >>>>> Best regards, Steve
>> > >>>>>
>> > >>>>> [[alternative HTML version deleted]]
>> > >>>>>
>> > >>>>> _______________________________________________
>> > >>>>> R-sig-mixed-models at r-project.org mailing list
>> > >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>>>
>> > >>>
>> > >>>
>> > >>>
>> > >>> -- Steven V. Miller Assistant Professor Department of Political
>> > >>> Science Clemson University http://svmiller.com
>> > >>>
>> > >>> [[alternative HTML version deleted]]
>> > >>>
>> > >>> _______________________________________________
>> > >>> R-sig-mixed-models at r-project.org mailing list
>> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>>
>> > >>
>> > >> [[alternative HTML version deleted]]
>> > >>
>> > >> _______________________________________________
>> > >> R-sig-mixed-models at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>
>> > >
>> >
>> > -----BEGIN PGP SIGNATURE-----
>> > Version: GnuPG v1.4.11 (GNU/Linux)
>> >
>> > iQEcBAEBAgAGBQJVps4fAAoJEOCV5YRblxUH0wQIANBg6CaKoHuM6RQY5VltpEbk
>> > 5+RYc0tIYXmvNzGesG0QTQaLz0A5cx5mo0EGxsKQq8vUz2ycRlSlcYo9uI0K/xft
>> > D8MMhdVr8QhIW2RtoWPNPzn6HIe276CFnHg4Co+3vbMcccbvTvWvxsDYaT/LOlRn
>> > JoVjN/HcOscMOQkAxZV6elYBZe+kbVVhOS0SNo3Bt5P528EuWIxaRlC2lO5aoHSL
>> > 1cgLn5uyWLsxb3Cuu3FctwYfYOk9hsEXNM/EGMleshDq6umGtSm9lqiM8vqgSnMl
>> > Iyp2A+r3fkRzfEZyWv0Ygi4OA0iZ5/BSH44+sR60hj/qSpqGYwUQ+fIrfKXAYTw=
>> > =cHT0
>> > -----END PGP SIGNATURE-----
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sun Jul 19 14:52:01 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 19 Jul 2015 14:52:01 +0200
Subject: [R-sig-ME] Perfectly correlated random effects (when they
 shouldn't be)
In-Reply-To: <CAGoSky8=okEO_MrTiueSohUh7a9Y3uWjVSafWqW3GvgpJ3Xc_Q@mail.gmail.com>
References: <CABafbiqtGNzNRAdtbzRpOXHiZyYfT5z_-CHh9YPkbCOQ-0K0Tw@mail.gmail.com>
	<COL129-W936081F80619412D7AABC7CB9A0@phx.gbl>
	<CABafbip4pD5j83s3vkj-t_ryUNrc79EzRv-av3TRPHZNz3vqYQ@mail.gmail.com>
	<CAGoSky9UiJjmN4D9CORqsQ-EiXY_5xPeRz6m411LuKW4pre64Q@mail.gmail.com>
	<55A6C4E2.10305@gmail.com> <55A6CE1F.5070404@ufl.edu>
	<CAGoSky-tugtuMODo-h1YcG8+Z5NQ9aZmaSv_Kh8drqfmOepG+A@mail.gmail.com>
	<CABafbio6TQ71daEu+UOF22U7m_=j5=eXP+rPUsRL2Gy3+yHh8A@mail.gmail.com>
	<CAGoSky8=okEO_MrTiueSohUh7a9Y3uWjVSafWqW3GvgpJ3Xc_Q@mail.gmail.com>
Message-ID: <CAJuCY5xpkH83XsoJ_Ooc1K4bcgCtACokqT4aRtdOFDU5+f9B3Q@mail.gmail.com>

Dear all,

I tried to tackle this with the INLA package. See
http://rpubs.com/INBOstats/perfect_correlation for the results.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-07-18 23:38 GMT+02:00 Paul Buerkner <paul.buerkner at gmail.com>:

> That looks better.
>
> I used the developmental version of brms from github available through
>
> library(devtools)
> install_github("paul-buerkner/brms")
>
> because the release version on CRAN does not yet support all relevant
> features (the country:wave syntax is not accepted by brms 0.3.0).
>
> The syntax i used was
>
> library(brms)
> fit1_brm <- brm(y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 +  x1
> + x2 | region),
>                             data = data, family = "bernoulli", n.warmup =
> 100, n.iter = 500, n.chains = 1)
> summary(fit1_brm)
> plot(fit1_brm)
>
> fit2_brm <- brm(y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 |
> region),
>                             data = data, family = "bernoulli", n.warmup =
> 100, n.iter = 500, n.chains = 1)
> summary(fit2_brm)
> plot(fit2_brm)
>
> Remember that you have to install Stan to make brms work. It will take
> several hours to fit those models, so be patient. :-)
>
> 2015-07-18 22:29 GMT+02:00 svm <steven.v.miller at gmail.com>:
>
> > Genuinely had no idea about that brms package in R. Is it new? It looks
> > very intriguing, though the syntax I'm seeing in the reference manual
> > doesn't appear to be working. Do you mind if I see the code? Maybe I'm
> > doing it wrong.
> >
> > I followed Ben's advice and pursued a blmer strategy with a disaggregated
> > version of the random effects variable. I ran the full models (so: not
> the
> > simple reproducible example) and got something that makes more sense. I
> > also corrected for various weird data points (i.e. countries whose
> surveys
> > were likely botched in execution). Here is the summary of the random
> > effects.
> >
> > Random effects:
> >  Groups       Name        Variance Std.Dev. Corr
> >  country:wave (Intercept) 0.16091  0.4011
> >  country      (Intercept) 0.34949  0.5912
> >  region       (Intercept) 0.04604  0.2146
> >               eti         0.24501  0.4950    0.20
> >               sti         0.18997  0.4359   -0.45 -0.04
> > Number of obs: 208551, groups:  country:wave, 143; country, 82; region,
> 13
> >
> > I think this makes sense. The regions ultimately don't vary that much
> from
> > each other, which I think is intuitive, given the data. The correlations
> > among the random slopes are importantly not 0, -1, or 1.
> >
> > In a full model (with controls), the significance of the z-value
> > associated with x1 is 1.741 (coeff: .516, sd: .296), which is below the
> > conventional cutoff of z = 1.96. My field is kind of a "cult of p < .05"
> > crowd, but I'm not terribly bothered by this. I do believe what I'm doing
> > here is a very conservative test of where x1 is discernible from zero
> > across the range of the data.
> >
> > As for the comparison between x1 in fit2_brm versus the maximal model in
> > lme4: I honestly don't know. I learn something new each time I do a mixed
> > effects analysis, but I can offer no immediate answer for that.
> >
> > I definitely do appreciate the input of this listserv. I'm more than
> > grateful for your time and patience with me.
> >
> > Best regards,
> > Steve
> >
> > On Sat, Jul 18, 2015 at 2:40 PM, Paul Buerkner <paul.buerkner at gmail.com>
> > wrote:
> >
> >> I managed to fit the models with bayesian techniques using the package
> >> brms.
> >>
> >> Because your data is so huge, I decided to run only 500 iterations, of
> >> which 100 are warmup (i.e. burnin). As brms uses Stan on the backend,
> the
> >> quality of the samples is relatively high so that 400 markov samples
> >> should
> >> be enough for our purposes.
> >>
> >> Below I present the results of the maximal model as well as the model
> >> withour any random effects for x1 and x2. The related plots are
> attached.
> >>
> >> First, the maximal model (fit1_brm):
> >>
> >> Family: bernoulli (logit)
> >> Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 + x1 +
> >> x2 | region)
> >>    Data: data (Number of observations: 212570)
> >> Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
> >>          total post-warmup samples = 400
> >>
> >> Random Effects:
> >> ~country (Number of levels: 82)
> >>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> sd(Intercept)     0.59      0.08     0.44     0.75        140    1
> >>
> >> ~country:wave (Number of levels: 143)
> >>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> sd(Intercept)     0.42      0.04     0.34     0.51        148    1
> >>
> >> ~region (Number of levels: 6)
> >>                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> sd(Intercept)         0.24      0.20     0.01     0.77        300    1
> >> sd(x1)                0.41      0.38     0.02     1.44        398    1
> >> sd(x2)                0.57      0.45     0.03     1.75        289    1
> >> cor(Intercept,x1)     0.04      0.47    -0.84     0.86        400    1
> >> cor(Intercept,x2)    -0.20      0.46    -0.90     0.70        400    1
> >> cor(x1,x2)           -0.14      0.50    -0.92     0.87        400    1
> >>
> >> Fixed Effects:
> >>           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> Intercept    -0.61      0.15    -0.91    -0.36        400    1
> >> x1            0.43      0.39    -0.31     1.20        400    1
> >> x2            0.02      0.40    -0.69     0.81        344    1
> >>
> >> Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample
> is a
> >> crude measure of effective sample size, and Rhat is the potential scale
> >> reduction factor on split chains (at convergence, Rhat = 1).
> >>
> >>
> >>
> >>
> >> >From what I see, the results differ from lme4 in four aspects.
> >>
> >> 1. Indeed, there seems to be not enough evidence in the data to estimate
> >> the random effects correlations reasonably, as implied by the huge CIs.
> >> The
> >> Estimates (means in this case) are close to 0 instead of -1 or 1, which
> >> seems more intuitive from my perspective.
> >> 2. While the random effects standard deviations of country and
> >> country:wave
> >> are similar to lme4 (their posterior distributions are nearly symmetric;
> >> see plot_fit1_brm in the attachment), the sds of region are considerably
> >> larger than the ones estimated by lme4. This is because the mode is
> always
> >> smaller than the mean when the distributions a right skewed. Especially,
> >> from my perspective, they do not seem to be so small that removing them
> >> from the model would be justified (I am currently running the same model
> >> without correlations but the results shouldnt be too different).
> >> 3. The estimate of x1 is a bit smaller than in lme4 (0.43 against 0.49).
> >> Unfortunately, I do not have any immediate explanation for this...
> >> 4. The standard error of x1 has nearly doubled as compared to lme4 (0.39
> >> against 0.2).  As a result, the CI is almost twice a large.  Most
> likely,
> >> this is because the random effects sd of x1 is much larger than in lme4,
> >> which also affects the standard error of the fixed effect.
> >>
> >> To test, whether 4. is solely because of the random effects of x1, I
> >> completely removed them in the second model (fit2_brm):
> >>
> >> Family: bernoulli (logit)
> >> Formula: y ~ x1 + x2 + (1 | country) + (1 | country:wave) + (1 | region)
> >>    Data: data (Number of observations: 212570)
> >> Samples: 1 chains, each with n.iter = 500; n.warmup = 100; n.thin = 1;
> >>          total post-warmup samples = 400
> >>
> >> Random Effects:
> >> ~country (Number of levels: 82)
> >>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> sd(Intercept)     0.61      0.08     0.49     0.77         96 1.03
> >>
> >> ~country:wave (Number of levels: 143)
> >>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> sd(Intercept)      0.4      0.04     0.34     0.49        197 1.01
> >>
> >> ~region (Number of levels: 6)
> >>               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> sd(Intercept)     0.27      0.19     0.03     0.72        278    1
> >>
> >> Fixed Effects:
> >>           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
> >> Intercept    -0.61      0.15    -0.95    -0.31        400 1.01
> >> x1            0.42      0.25    -0.05     0.89        400 1.00
> >> x2           -0.04      0.22    -0.46     0.37        400 1.00
> >>
> >> Samples were drawn using NUTS(diag_e). For each parameter, Eff.Sample
> is a
> >> crude measure of effective sample size, and Rhat is the potential scale
> >> reduction factor on split chains (at convergence, Rhat = 1).
> >>
> >>
> >> The standard error of x1 indeed went down being close to what lme4
> >> estimated (0.25 against 0.24). What I find suspicius is that the maximal
> >> model in lme4 (i.e. the one including random effects for x1) estimates
> >> lower
> >> standard error for the fixed effect of x1 than the model without those
> >> random effects (see the results of Reinhold Klingl). From my
> perspective,
> >> this is unlikely to be correct. Whats your opinon on this?
> >>
> >>
> >> 2015-07-15 23:18 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
> >>
> >> > -----BEGIN PGP SIGNED MESSAGE-----
> >> > Hash: SHA1
> >> >
> >> > On 15-07-15 04:38 PM, Ben Bolker wrote:
> >> > > On 15-07-15 12:52 PM, Paul Buerkner wrote:
> >> > >> if you look at the results from a baysian perspective, it seems
> >> > >> to be a typcial "problem" of ML-procedures estimating the mode.
> >> > >>
> >> > >> The mode is nothing special, just the point where the density is
> >> > >> maximal. When you have skewed distribution (as usual for
> >> > >> correlations) the mode will often be close to the borders of the
> >> > >> region of definition (-1 or 1 in this case). The posterior
> >> > >> distribution of the correlation, however, can still be very wide
> >> > >> ranging from strong negative correlation to strong positive
> >> > >> correlation, especially when the number of levels of a grouping
> >> > >> factor is not that large. In those cases, zero (i.e.
> >> > >> insignificant) correlation is a very likely value even if the
> >> > >> mode itself is extreme.
> >> > >>
> >> > >> I tried fitting your models with bayesian R packages (brms and
> >> > >> MCMCglmm). Unfortunately, because you have so many observations
> >> > >> and quite a few random effects, they run relatively slow so i am
> >> > >> still waiting for the results.
> >> > >
> >> >
> >> >  You can also use blme, which implements a very thin Bayesian wrapper
> >> > around [g]lmer and does maximum _a posteriori_ (i.e. Bayesian mode)
> >> > estimates with
> >> > weak (but principled) priors on the random effects -- it's based on
> >> >
> >> > Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and
> >> > Jingchen Liu. ?A Nondegenerate Penalized Likelihood Estimator for
> >> > Variance Parameters in Multilevel Models.? Psychometrika 78, no. 4
> >> > (March 12, 2013): 685?709. doi:10.1007/s11336-013-9328-2.
> >> >
> >> >   Profile 'likelihood' confidence intervals based on blme will get you
> >> > a reasonable approximation of the width of the credible interval,
> >> > although it's a little bit of a cheesy/awkward combination between
> >> > marginal (proper Bayesian) and conditional (MAP/cheesy-Bayesian)
> >> > measures of uncertainty.
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > >> 2015-07-15 3:45 GMT+02:00 svm <steven.v.miller at gmail.com>:
> >> > >>
> >> > >>> I considered that. I disaggregated the region random effect
> >> > >>> from 6 to 18 (the latter of which approximates the World Bank's
> >> > >>> region classification). I'm still encountering the same curious
> >> > >>> issue.
> >> > >>>
> >> > >>> Random effects: Groups       Name        Variance  Std.Dev.
> >> > >>> Corr country:wave (Intercept) 0.1530052 0.39116 country
> >> > >>> (Intercept) 0.3735876 0.61122 wbregion     (Intercept)
> >> > >>> 0.0137822 0.11740 x1        0.0009384 0.03063  -1.00 x2
> >> > >>> 0.0767387 0.27702  -1.00  1.00 Number of obs: 212570, groups:
> >> > >>> country:wave, 143; country, 82; wbregion, 18
> >> > >>>
> >> > >>> For what it's worth: the model estimates fine. The results are
> >> > >>> intuitive and theoretically consistent. They also don't change
> >> > >>> if I were to remove that region random effect. I'd like to keep
> >> > >>> the region random effect (with varying slopes) in the model.
> >> > >>> I'm struggling with what I should think about the perfect
> >> > >>> correlations.
> >> > >>>
> >> > >>> On Tue, Jul 14, 2015 at 9:07 PM, Jake Westfall
> >> > >>> <jake987722 at hotmail.com> wrote:
> >> > >>>
> >> > >>>> Hi Steve,
> >> > >>>>
> >> > >>>>
> >> > >>>> I think the issue is that estimating 3 variances and 3
> >> > >>>> covariances for regions is quite ambitious given that there
> >> > >>>> are only 6 regions. I think it's not surprising that the
> >> > >>>> model has a hard time getting good estimates of those
> >> > >>>> parameters.
> >> > >>>>
> >> > >>>>
> >> > >>>> Jake
> >> > >>>>
> >> > >>>>> Date: Tue, 14 Jul 2015 20:53:01 -0400 From:
> >> > >>>>> steven.v.miller at gmail.com To:
> >> > >>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME]
> >> > >>>>> Perfectly correlated random effects (when they
> >> > >>>> shouldn't be)
> >> > >>>>
> >> > >>>>>
> >> > >>>>> Hi all,
> >> > >>>>>
> >> > >>>>> I'm a long-time reader and wanted to raise a question I've
> >> > >>>>> seen asked
> >> > >>>> here
> >> > >>>>> before about correlated random effects. Past answers I have
> >> > >>>>> encountered
> >> > >>>> on
> >> > >>>>> this listserv explain that perfectly correlated random
> >> > >>>>> effects suggest model overfitting and variances of random
> >> > >>>>> effects that are effectively
> >> > >>>> zero
> >> > >>>>> and can be omitted for a simpler model. In my case, I don't
> >> > >>>>> think
> >> > >>> that's
> >> > >>>>> what is happening here, though I could well be fitting a
> >> > >>>>> poor model in glmer.
> >> > >>>>>
> >> > >>>>> I'll describe the nature of the data first. I'm modeling
> >> > >>> individual-level
> >> > >>>>> survey data for countries across multiple waves and am
> >> > >>>>> estimating the region of the globe as a random effect as
> >> > >>>>> well. I have three random
> >> > >>>> effects
> >> > >>>>> (country, country-wave, and region). In the region random
> >> > >>>>> effect, I am allowing country-wave-level predictors to have
> >> > >>>>> varying slopes. My
> >> > >>> inquiry
> >> > >>>>> is whether some country-wave-level contextual indicator can
> >> > >>>>> have an
> >> > >>>> overall
> >> > >>>>> effect (as a fixed effect), the effect of which can vary by
> >> > >>>>> region. In other words: is the effect of some country-level
> >> > >>>>> indicator (e.g. unemployment) in a given year different for
> >> > >>>>> countries in Western Europe than for countries in Africa
> >> > >>>>> even if, on average, there is a positive
> >> > >>> or
> >> > >>>>> negative association at the individual-level? These
> >> > >>>>> country-wave-level predictors that I allow to vary by
> >> > >>>>> region are the ones reporting
> >> > >>> perfect
> >> > >>>>> correlation and I'm unsure how to interpret that (or if I'm
> >> > >>>>> estimating
> >> > >>>> the
> >> > >>>>> model correctly).
> >> > >>>>>
> >> > >>>>> I should also add that I have individual-level predictors
> >> > >>>>> as well as country-wave-level predictors, though it's the
> >> > >>>>> latter that concerns me. Further, every non-binary
> >> > >>>>> indicator in the model is standardized by two standard
> >> > >>>>> deviations.
> >> > >>>>>
> >> > >>>>> For those interested, I have a reproducible (if rather
> >> > >>>>> large) example below. Dropbox link to the data is here:
> >> > >>>>>
> >> > >>>>
> >> > >>>
> >> >
> >>
> https://www.dropbox.com/s/t29jfwm98tsdr71/correlated-random-effects.csv?dl=0
> >> > >>>>>
> >> > >>>>>
> >> > >>>
> >> > In this reproducible example, y is the outcome variable and x1 and x2
> >> > >>> are
> >> > >>>>> two country-wave-level predictors I allow to vary by
> >> > >>>>> region. Both x1
> >> > >>> and
> >> > >>>> x2
> >> > >>>>> are interval-level predictors that I standardized to have a
> >> > >>>>> mean of
> >> > >>> zero
> >> > >>>>> and a standard deviation of .5 (per Gelman's (2008)
> >> > >>>>> recommendation).
> >> > >>>>>
> >> > >>>>> I estimate the following model.
> >> > >>>>>
> >> > >>>>> summary(M1 <- glmer(y ~ x1 + x2 + (1 | country) + (1 |
> >> > >>>>> country:wave) +
> >> > >>>> (1 +
> >> > >>>>> x1 + x2 | region), data=subset(Data),
> >> > >>>>> family=binomial(link="logit")))
> >> > >>>>>
> >> > >>>>> The results are theoretically intuitive. I think they make
> >> > >>>>> sense.
> >> > >>>> However,
> >> > >>>>> I get a report of perfect correlation for the varying
> >> > >>>>> slopes of the
> >> > >>>> region
> >> > >>>>> random effect.
> >> > >>>>>
> >> > >>>>> Random effects: Groups Name Variance Std.Dev. Corr
> >> > >>>>> country:wave (Intercept) 0.15915 0.3989 country (Intercept)
> >> > >>>>> 0.32945 0.5740 region (Intercept) 0.01646 0.1283 x1 0.02366
> >> > >>>>> 0.1538 1.00 x2 0.13994 0.3741 -1.00 -1.00 Number of obs:
> >> > >>>>> 212570, groups: country:wave, 143; country, 82; region,
> >> > >>> 6
> >> > >>>>>
> >> > >>>>> What should I make of this and am I estimating this model
> >> > >>>>> wrong? For
> >> > >>> what
> >> > >>>>> it's worth, the dotplot of the region random effect (with
> >> > >>>>> conditional variance) makes sense and is theoretically
> >> > >>>>> intuitive, given my data. (
> >> > >>>>> http://i.imgur.com/mrnaJ77.png)
> >> > >>>>>
> >> > >>>>> Any help would be greatly appreciated.
> >> > >>>>>
> >> > >>>>> Best regards, Steve
> >> > >>>>>
> >> > >>>>> [[alternative HTML version deleted]]
> >> > >>>>>
> >> > >>>>> _______________________________________________
> >> > >>>>> R-sig-mixed-models at r-project.org mailing list
> >> > >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> > >>>>
> >> > >>>
> >> > >>>
> >> > >>>
> >> > >>> -- Steven V. Miller Assistant Professor Department of Political
> >> > >>> Science Clemson University http://svmiller.com
> >> > >>>
> >> > >>> [[alternative HTML version deleted]]
> >> > >>>
> >> > >>> _______________________________________________
> >> > >>> R-sig-mixed-models at r-project.org mailing list
> >> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> > >>>
> >> > >>
> >> > >> [[alternative HTML version deleted]]
> >> > >>
> >> > >> _______________________________________________
> >> > >> R-sig-mixed-models at r-project.org mailing list
> >> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> > >>
> >> > >
> >> >
> >> > -----BEGIN PGP SIGNATURE-----
> >> > Version: GnuPG v1.4.11 (GNU/Linux)
> >> >
> >> > iQEcBAEBAgAGBQJVps4fAAoJEOCV5YRblxUH0wQIANBg6CaKoHuM6RQY5VltpEbk
> >> > 5+RYc0tIYXmvNzGesG0QTQaLz0A5cx5mo0EGxsKQq8vUz2ycRlSlcYo9uI0K/xft
> >> > D8MMhdVr8QhIW2RtoWPNPzn6HIe276CFnHg4Co+3vbMcccbvTvWvxsDYaT/LOlRn
> >> > JoVjN/HcOscMOQkAxZV6elYBZe+kbVVhOS0SNo3Bt5P528EuWIxaRlC2lO5aoHSL
> >> > 1cgLn5uyWLsxb3Cuu3FctwYfYOk9hsEXNM/EGMleshDq6umGtSm9lqiM8vqgSnMl
> >> > Iyp2A+r3fkRzfEZyWv0Ygi4OA0iZ5/BSH44+sR60hj/qSpqGYwUQ+fIrfKXAYTw=
> >> > =cHT0
> >> > -----END PGP SIGNATURE-----
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From daniel_rubi at ymail.com  Sat Jul 18 20:55:54 2015
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Sat, 18 Jul 2015 11:55:54 -0700
Subject: [R-sig-ME] Scaling the response of a linear model to different
	factor groups
Message-ID: <1437245754.65541.YahooMailBasic@web163805.mail.gq1.yahoo.com>

I hope this question is general enough to be of broad interest.

Here's the abstract explanation of my problem:
I have two groups for which I measured a certain feature. Specifically, this feature can be divided into sub-categories, where I am aware that in each group there are inherent differences among the sub-categories. I'm interested to test if the two groups differ WRT to this feature, and if so what is the contribution of each sub-category to this feature.


Now, here's the actual data I'm working with:

My groups are two species of rodents. The feature is their whisker lengths. The whiskers are organized in four rows on the faces of each of the species (they are compatible betwen the two species).In both species the whiskers at different rows have different lengths (e.g., row 1 has the longest among all other rows whiskers in both species). 

What would be the correct linear model to test this? 

The simple mixed-effects model I can think of would be: whisker_length ~ species + whisker_row + (1|animal)

where animal is a random effect, since I measure whiske lengths for several animals of each species.


Is this model sufficient?
My concerns are:
1. Interpretation - if the result of the model is that both species and whisker_row (one or more of the four rows) are significant, does this model inform me whether the significant whisker rows are different between the two species? My impression is that the only interpreation is that whisker_row significantly determines whisker length, regardless of the species. Hence, should I add an interaction term between species and whisker_row to capture that?
2. Should I standardize all whisker lengths relative to their rows, so that they are on a common scale according to their row?


Thanks a lot,
rubi


From thierry.onkelinx at inbo.be  Tue Jul 21 10:07:20 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 21 Jul 2015 10:07:20 +0200
Subject: [R-sig-ME] Scaling the response of a linear model to different
 factor groups
In-Reply-To: <1437245754.65541.YahooMailBasic@web163805.mail.gq1.yahoo.com>
References: <1437245754.65541.YahooMailBasic@web163805.mail.gq1.yahoo.com>
Message-ID: <CAJuCY5znXccyYWK7xg=GC76ugqJ6-68otiffv7WXRo5e=EX0xA@mail.gmail.com>

Dear Daniel,

You answered your first question yourself: if you don't add the interaction
then effect of whisker_row is forced to be identical between the species.
The interaction seems to be required from an ecological point of view.

I would not standardise the whisker lengths. I find that is makes the model
harder to interpret. Instead, rather think about the whether the effects of
species and whisker_row is additive of multiplicative. E.g. do you want to
express the difference between the first and second rows to be x mm
(additive) or rather as the second row is x% of the first row
(multiplicative). The additive model is plain lmm. You get the
multiplicative model by log transforming the length or by using a gamma
distribution with log link.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-07-18 20:55 GMT+02:00 Daniel Rubi <daniel_rubi at ymail.com>:

> I hope this question is general enough to be of broad interest.
>
> Here's the abstract explanation of my problem:
> I have two groups for which I measured a certain feature. Specifically,
> this feature can be divided into sub-categories, where I am aware that in
> each group there are inherent differences among the sub-categories. I'm
> interested to test if the two groups differ WRT to this feature, and if so
> what is the contribution of each sub-category to this feature.
>
>
> Now, here's the actual data I'm working with:
>
> My groups are two species of rodents. The feature is their whisker
> lengths. The whiskers are organized in four rows on the faces of each of
> the species (they are compatible betwen the two species).In both species
> the whiskers at different rows have different lengths (e.g., row 1 has the
> longest among all other rows whiskers in both species).
>
> What would be the correct linear model to test this?
>
> The simple mixed-effects model I can think of would be: whisker_length ~
> species + whisker_row + (1|animal)
>
> where animal is a random effect, since I measure whiske lengths for
> several animals of each species.
>
>
> Is this model sufficient?
> My concerns are:
> 1. Interpretation - if the result of the model is that both species and
> whisker_row (one or more of the four rows) are significant, does this model
> inform me whether the significant whisker rows are different between the
> two species? My impression is that the only interpreation is that
> whisker_row significantly determines whisker length, regardless of the
> species. Hence, should I add an interaction term between species and
> whisker_row to capture that?
> 2. Should I standardize all whisker lengths relative to their rows, so
> that they are on a common scale according to their row?
>
>
> Thanks a lot,
> rubi
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Thomas.Parmentier at bio.kuleuven.be  Tue Jul 21 18:59:09 2015
From: Thomas.Parmentier at bio.kuleuven.be (Thomas Parmentier)
Date: Tue, 21 Jul 2015 16:59:09 +0000
Subject: [R-sig-ME] zero values generalized mixed model
Message-ID: <BFD0D1413E83714B8EB0386A5467D8A33D779680@ICTS-S-MBX11.luna.kuleuven.be>

Hi all,
I?ve got a question concerning a generalized mixed model where some levels only have zero values.
I will try to explain my setup: I am testing location preference of ant-associated beetles (15 species) in ant nests. Therefore I made six-chamber nests with 6 identical connected pots. Ant workers stored all their brood (standardized volumes) in one chamber. This brood chamber also contained most workers. My aim is to test whether some species are attracted or repulsed from those dense brood chambers. Later, I want to link this location preference with other traits of the myrmecophiles (e.g. degree of parasitism).
I used a generalized (binomial) mixed model with presence (score 1) / absence (score 0) in the brood chamber as dependent variable. A model without intercept and an offset of (logit(1/6) was used to directly test the deviation of the observed proportions from the expected proportion by random distribution (1/6). Species = 15 species of myrmecophiles, replicate = experiment was run 15 times.
Model:
modelbrood<-glmer(BROOD_CHAMBER~offset(datasetlocation$baseline) -1+SOORT+(1|REPLICATE)+(1|ID), binomial(link=logit), data=datasetlocation)
So far, everything runs fine. However two species were never observed in the brood chambers, even with more than 50 individuals tested in total. So  they show a clear aversion of the brood chambers. However, when tested, SE are extremely large for those species, and consequently P values of 0.8 are given. So apparently the model struggles with levels of a factor with only zero values. When I change one zero to one in both species, the SE are much more reliable.

So my question is there a way to handle zero values in generalized mixed models?

Thanks a lot,

Thomas
________________________________
Laboratory of Socioecology and Socioevolution
K.U.Leuven
Naamsestraat 59
B-3000 Leuven
Belgium

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Jul 21 21:04:09 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 21 Jul 2015 21:04:09 +0200
Subject: [R-sig-ME] Article on using observation-level random effects vs
 beta-binomial models for overdispersed binomial data
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F1A0B351F@UM-MAIL4112.unimaas.nl>

Dear All,

An article was just published in PeerJ that may be of interest to some readers of this mailing list:

Harrison, X. A. (2015). A comparison of observation-level random effect and beta-binomial models for modelling overdispersion in binomial data in ecology & evolution. PeerJ 3:e1114 https://dx.doi.org/10.7717/peerj.1114 

lme4 was used for fitting the model with observation-level random effects.

One thing that I would have liked to see is a discussion of how the choice of estimation method (i.e., PQL, Laplace, (A)GQ) may impact the accuracy of the methods. Lots of previous research on that (Austin, 2010; Kim et al., 2013; Li et al., 2011; Zhang et al., 2011), indicating that this can make quite a bit of a difference, especially when the number of clusters is low (which was in fact the focus of this article).

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com     

From bbolker at gmail.com  Tue Jul 21 21:17:57 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Jul 2015 15:17:57 -0400
Subject: [R-sig-ME] zero values generalized mixed model
In-Reply-To: <BFD0D1413E83714B8EB0386A5467D8A33D779680@ICTS-S-MBX11.luna.kuleuven.be>
References: <BFD0D1413E83714B8EB0386A5467D8A33D779680@ICTS-S-MBX11.luna.kuleuven.be>
Message-ID: <55AE9AE5.7080209@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-07-21 12:59 PM, Thomas Parmentier wrote:
> Hi all, I?ve got a question concerning a generalized mixed model
> where some levels only have zero values. I will try to explain my
> setup: I am testing location preference of ant-associated beetles
> (15 species) in ant nests. Therefore I made six-chamber nests with
> 6 identical connected pots. Ant workers stored all their brood
> (standardized volumes) in one chamber. This brood chamber also
> contained most workers. My aim is to test whether some species are
> attracted or repulsed from those dense brood chambers. Later, I
> want to link this location preference with other traits of the
> myrmecophiles (e.g. degree of parasitism). I used a generalized
> (binomial) mixed model with presence (score 1) / absence (score 0)
> in the brood chamber as dependent variable. A model without
> intercept and an offset of (logit(1/6) was used to directly test
> the deviation of the observed proportions from the expected
> proportion by random distribution (1/6). Species = 15 species of
> myrmecophiles, replicate = experiment was run 15 times. Model: 
> modelbrood<-glmer(BROOD_CHAMBER~offset(datasetlocation$baseline)
> -1+SOORT+(1|REPLICATE)+(1|ID), binomial(link=logit),
> data=datasetlocation) So far, everything runs fine. However two
> species were never observed in the brood chambers, even with more
> than 50 individuals tested in total. So  they show a clear aversion
> of the brood chambers. However, when tested, SE are extremely large
> for those species, and consequently P values of 0.8 are given. So
> apparently the model struggles with levels of a factor with only
> zero values. When I change one zero to one in both species, the SE
> are much more reliable.
> 
> So my question is there a way to handle zero values in generalized
> mixed models?
> 
> Thanks a lot,

  This is called "complete separation"; at this point, the
simplest/most practical way to handle this is to move to a Bayesian
framework using either blmer or MCMCglmm; see e.g.
http://stats.stackexchange.com/questions/128742/mixed-logistic-model-with-complete-separation
and links therein ...

  cheers
   Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVrprlAAoJEOCV5YRblxUHNH4IALQDB7sUvDfn67SldGDbcMpz
/fDEvuYqmhh9+Bms3GC60Mmb+34tY8BlcFUuXd+UQUQDQsEkX1SlJVICrOySmrVi
fTnA7GwbhbOYjYJLBdJDcoNsai4IWRKHxmtE8qgPoq7a/DvljxEEOY2XH2DKi6yZ
1V1UUZhGSJvw8eOnRX7pttNke6lbOybH6yaIssQWpGzcVV8e2bGdUsnFJGnpo+0x
zy9Vgzc20k1/NX3Vn0Stj04X0EctFTDZ7XILKQx2refwCLMxgVroAXPvz5TAcJVh
gw0Ay0Xtuz+6wi3OTaz3bjevBuy4iTZQN9eGmkNsReq3WvOvxNRdDn2M4n/TVmY=
=w2Jk
-----END PGP SIGNATURE-----


From highstat at highstat.com  Thu Jul 23 11:41:50 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 23 Jul 2015 17:41:50 +0800
Subject: [R-sig-ME] Stats courses in Queensland, Australia
Message-ID: <55B0B6DE.4080007@highstat.com>

Apologies for cross-posting


There are various remaining seats on the following two statistics courses:

Course 1:
Introduction to Generalized Linear Models with R. -Bayesian and 
frequentist approaches -
Dates: 11 - 14 August, 2015
Location: Hotel Grand Chancellor, Coral Coast Drive, Palm Cove. Australia


Course 2:
Introduction to Zero Inflated Models with R. - Frequentist and Bayesian 
approaches -
Dates: 17 - 21 August, 2015
Location: Hotel Grand Chancellor, Coral Coast Drive, Palm Cove. Australia


Course website:
http://highstat.com/statscourse.htm

Course flyers:
http://highstat.com/Courses/Flyers/Flyer2015_08PalmCoveI.pdf
http://highstat.com/Courses/Flyers/Flyer2015_08PalmCoveII.pdf

Both courses are pre-required knowledge for our 'Introduction to GLMs 
with spatial and temporal correlation'.


Kind regards,

Alain Zuur



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From pfabuel at gmail.com  Tue Jul 21 13:48:29 2015
From: pfabuel at gmail.com (Francisco Fabuel)
Date: Tue, 21 Jul 2015 13:48:29 +0200
Subject: [R-sig-ME] Fwd: Model failed to converge in bootMer
In-Reply-To: <CA+DOucFdU_kxguTB5MQoxJoC8gjB_E8TeE6er9bpfNfTXi7GgQ@mail.gmail.com>
References: <CA+DOucFdU_kxguTB5MQoxJoC8gjB_E8TeE6er9bpfNfTXi7GgQ@mail.gmail.com>
Message-ID: <CA+DOucHFc_HOmbW9zC+t955Mt1M3-ue8W8wracN2j_huAVPatg@mail.gmail.com>

I'm trying to estimate some quantities derived from a lmer object using
bootstrap. When I use the function bootMer, a large proportion of
replications seems to fail to converge, but if I program the bootstrap
using package boot, everything seems go well.

Please, find attached a simple example (R script and data) of the problem:
with bootMer in 10 simulations, I've got 7 warnings:

Warning messages:1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
control$checkConv,  :
  Model failed to converge with max|grad| = 0.00132463 (tol = 0.001,
component 1)


Thank you in advance.
Francisco Fabuel

From F.Ingleby at sussex.ac.uk  Thu Jul 23 09:39:06 2015
From: F.Ingleby at sussex.ac.uk (Fiona Ingleby)
Date: Thu, 23 Jul 2015 07:39:06 +0000
Subject: [R-sig-ME] Bayesian, MCMCglmm and multiple testing
Message-ID: <856A554D-CD5A-41AA-A185-1907E7ADC1FA@sussex.ac.uk>

Hi everyone,

I?m working with gene expression data and am planning on running a mixed model with MCMCglmm for each gene in the dataset individually (>15000 models). 

With previous non-Bayesian approaches to this data, I have corrected results for multiple testing with the false discovery rate, and I?m wondering if there is a generally accepted way of correcting Bayesian results for multiple tests. I?ve had a look through some publications but I?m drawing a blank so would anyone be able to point me in the direction of some useful information? Either methods, or discussion about the consequences of multiple testing for Bayesian model results, would be really helpful.

It has been suggested to me to simply use the pseudo-p-values in the MCMCglmm output to adjust p-values, but to be honest I?ve always ignored the pMCMC values as I?ve found the intervals much more useful, so I?m not sure how good a solution this would be.

Thanks in advance for any help,

Fiona

From daniel_rubi at ymail.com  Wed Jul 22 04:17:36 2015
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Tue, 21 Jul 2015 19:17:36 -0700
Subject: [R-sig-ME] Scaling the response of a linear model to different
	factor groups
In-Reply-To: <CAJuCY5znXccyYWK7xg=GC76ugqJ6-68otiffv7WXRo5e=EX0xA@mail.gmail.com>
Message-ID: <1437531456.60509.YahooMailBasic@web163805.mail.gq1.yahoo.com>

Thanks a lot.
--------------------------------------------
On Tue, 7/21/15, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

 Subject: Re: [R-sig-ME] Scaling the response of a linear model to different factor groups
 To: "Daniel Rubi" <daniel_rubi at ymail.com>
 Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
 Date: Tuesday, July 21, 2015, 4:07 AM
 
 Dear
 Daniel,
 You answered your
 first question yourself: if you don't add the
 interaction then effect of whisker_row is forced to be
 identical between the species. The interaction seems to be
 required from an ecological point of view.
 I would not standardise the whisker
 lengths. I find that is makes the model harder to interpret.
 Instead, rather think about the whether the effects of
 species and whisker_row is additive of multiplicative. E.g.
 do you want to express the difference between the first and
 second rows to be x mm (additive) or rather as the second
 row is x% of the first row (multiplicative). The additive
 model is plain lmm. You get the multiplicative model by log
 transforming the length or by using a gamma distribution
 with log link.
 Best
 regards,
 ir. Thierry Onkelinx
 Instituut voor natuur- en bosonderzoek /
 Research Institute for Nature and Forest 
 team Biometrie & Kwaliteitszorg / team
 Biometrics & Quality Assurance 
 Kliniekstraat 25
 1070
 Anderlecht
 Belgium
 
 To call in the statistician after the
 experiment is done may be no more than asking him to perform
 a post-mortem examination: he may be able to say what the
 experiment died of. ~ Sir Ronald Aylmer Fisher
 The plural of anecdote is not data. ~ Roger
 Brinner 
 The combination of some data and an
 aching desire for an answer does not ensure that a
 reasonable answer can be extracted from a given body of
 data. ~ John Tukey
 
 2015-07-18 20:55 GMT+02:00
 Daniel Rubi <daniel_rubi at ymail.com>:
 I hope this question is general
 enough to be of broad interest.
 
 
 
 Here's the abstract explanation of my problem:
 
 I have two groups for which I measured a certain feature.
 Specifically, this feature can be divided into
 sub-categories, where I am aware that in each group there
 are inherent differences among the sub-categories. I'm
 interested to test if the two groups differ WRT to this
 feature, and if so what is the contribution of each
 sub-category to this feature.
 
 
 
 
 
 Now, here's the actual data I'm working with:
 
 
 
 My groups are two species of rodents. The feature is their
 whisker lengths. The whiskers are organized in four rows on
 the faces of each of the species (they are compatible betwen
 the two species).In both species the whiskers at different
 rows have different lengths (e.g., row 1 has the longest
 among all other rows whiskers in both species).
 
 
 
 What would be the correct linear model to test this?
 
 
 
 The simple mixed-effects model I can think of would be:
 whisker_length ~ species + whisker_row + (1|animal)
 
 
 
 where animal is a random effect, since I measure whiske
 lengths for several animals of each species.
 
 
 
 
 
 Is this model sufficient?
 
 My concerns are:
 
 1. Interpretation - if the result of the model is that both
 species and whisker_row (one or more of the four rows) are
 significant, does this model inform me whether the
 significant whisker rows are different between the two
 species? My impression is that the only interpreation is
 that whisker_row significantly determines whisker length,
 regardless of the species. Hence, should I add an
 interaction term between species and whisker_row to capture
 that?
 
 2. Should I standardize all whisker lengths relative to
 their rows, so that they are on a common scale according to
 their row?
 
 
 
 
 
 Thanks a lot,
 
 rubi
 
 
 
 _______________________________________________
 
 R-sig-mixed-models at r-project.org
 mailing list
 
 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierre.de.villemereuil at mailoo.org  Thu Jul 23 18:06:35 2015
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Thu, 23 Jul 2015 18:06:35 +0200
Subject: [R-sig-ME] Bayesian, MCMCglmm and multiple testing
In-Reply-To: <856A554D-CD5A-41AA-A185-1907E7ADC1FA@sussex.ac.uk>
References: <856A554D-CD5A-41AA-A185-1907E7ADC1FA@sussex.ac.uk>
Message-ID: <3765855.64d7PuA6mM@flyosfixe>

Hi Fiona!

Most of the FDR corrections using p-values are based on the assumptions that 
p-values are uniform between 0 and 1 under the null hypothesis, which would 
probably not be the case for the "pMCMC" output of MCMCglmm.

Bayesian controls of the FDR do exist, but they are based either on posterior 
probabilities or Bayes Factors, no of which are yielded by MCMCglmm (to my 
knowledge).

If you could achieve to derive a Bayes Factor from the output, then you could 
compute a q-value with (Bayesian) FDR control. Some information about that can 
be found on section 5 of the following document:
http://onlinelibrary.wiley.com/store/10.1111/mec.12705/asset/supinfo/mec12705-sup-0001-Suppinfo.pdf?v=1&s=87375f6d520a98dc1a69594771db07065946b41f

Hope this helps.

Best Regards,
Pierre.

Le jeudi 23 juillet 2015, 07:39:06 Fiona Ingleby a ?crit :
> Hi everyone,
> 
> I?m working with gene expression data and am planning on running a mixed
> model with MCMCglmm for each gene in the dataset individually (>15000
> models).
> 
> With previous non-Bayesian approaches to this data, I have corrected results
> for multiple testing with the false discovery rate, and I?m wondering if
> there is a generally accepted way of correcting Bayesian results for
> multiple tests. I?ve had a look through some publications but I?m drawing a
> blank so would anyone be able to point me in the direction of some useful
> information? Either methods, or discussion about the consequences of
> multiple testing for Bayesian model results, would be really helpful.
> 
> It has been suggested to me to simply use the pseudo-p-values in the
> MCMCglmm output to adjust p-values, but to be honest I?ve always ignored
> the pMCMC values as I?ve found the intervals much more useful, so I?m not
> sure how good a solution this would be.
> 
> Thanks in advance for any help,
> 
> Fiona
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Jul 23 19:34:47 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Jul 2015 13:34:47 -0400
Subject: [R-sig-ME] Fwd: Model failed to converge in bootMer
In-Reply-To: <CA+DOucHFc_HOmbW9zC+t955Mt1M3-ue8W8wracN2j_huAVPatg@mail.gmail.com>
References: <CA+DOucFdU_kxguTB5MQoxJoC8gjB_E8TeE6er9bpfNfTXi7GgQ@mail.gmail.com>
	<CA+DOucHFc_HOmbW9zC+t955Mt1M3-ue8W8wracN2j_huAVPatg@mail.gmail.com>
Message-ID: <55B125B7.4040903@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-07-21 07:48 AM, Francisco Fabuel wrote:
> I'm trying to estimate some quantities derived from a lmer object
> using bootstrap. When I use the function bootMer, a large
> proportion of replications seems to fail to converge, but if I
> program the bootstrap using package boot, everything seems go
> well.
> 
> Please, find attached a simple example (R script and data) of the
> problem: with bootMer in 10 simulations, I've got 7 warnings:
> 
> Warning messages:1: In checkConv(attr(opt, "derivs"), opt$par, ctrl
> = control$checkConv,  : Model failed to converge with max|grad| =
> 0.00132463 (tol = 0.001, component 1)
> 
> 
> Thank you in advance. Francisco Fabuel

  Scripts and data generally get stripped from messages sent to the
mailing list; you may need to post them somewhere else and send along
a URL.

  This is a little surprising since bootMer internally calls boot, so
the devil must be in the details somewhere -- which goes back to the
fact that we do probably need to see the code (and preferably data)...

  Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVsSW3AAoJEOCV5YRblxUHOnUIAJAiMOVPVdzo7j8ZBwSZ7fvf
rcNOrUQQyEk2gN6ym4i8uplSaM4nh5GHlxlWdsD4IGdJQ3HHBkGVEgpSQl8Q5Jrk
7sbx10WhEYKvuJfnbNyBYFzJvw+Gsm6hQqJsKUZGZrlUTgP/cuH0xLeZX/ljV+Qf
8Cm5KvK5oRUClr8GD3MVd0zC+ZryOpZyZaRM02i+IwfM6B1FGIe4vBrCp8XTK7ht
gixDTyx9UFjXHRKsU33XHbg9zA9D+eW7sX45XeyqyHYiwK0Yeb85ujx4Tdkv7PCB
yDhUXEyVDC8Z/5HFwh57EalJI6yizZ31KaX5z3QVapH+pVH7hjYlhtq9u3EVG+M=
=VEhi
-----END PGP SIGNATURE-----


From dsolrueda at gmail.com  Sat Jul 25 11:31:22 2015
From: dsolrueda at gmail.com (Daniel Sol)
Date: Sat, 25 Jul 2015 11:31:22 +0200
Subject: [R-sig-ME]  Log-normal MCMCglmm
Message-ID: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>

Hi everybody,

I have trouble finding how to implement a MCMCglmm with log-normal error. I
know some people just log-transform the response variable, but this is not
the same.

Many thanks in advance,

Dani

-- 
Daniel Sol
CREAF (Centre for Ecological Research and Forestry Applications)
CSIC (Spanish National Research Council)
Bellaterra, Catalonia E-08193, Spain
TEL: +34 93-5814678
FAX: +34 93-5814151
E-MAIL: d.sol at creaf.uab.es
Webpage: http://dsolrueda.wix.com/sol-group

	[[alternative HTML version deleted]]


From albrechj at staff.uni-marburg.de  Tue Jul 28 10:40:00 2015
From: albrechj at staff.uni-marburg.de (=?utf-8?Q?J=C3=B6rg_Albrecht?=)
Date: Tue, 28 Jul 2015 10:40:00 +0200
Subject: [R-sig-ME] Log-normal MCMCglmm
In-Reply-To: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
References: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
Message-ID: <ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>

Hi Dani,

you could try specifying 

family = "poisson".

Best,

J?rg

?
J?rg Albrecht, PhD
Postdoctoral researcher
Institute of Nature Conservation
Polish Academy of Sciences
Mickiewicza 33
31-120 Krakow, Poland
www.carpathianbear.pl <http://www.carpathianbear.pl/>
www.globeproject.pl <http://www.globeproject.pl/>
www.iop.krakow.pl <http://www.iop.krakow.pl/>
> Am 25.07.2015 um 11:31 schrieb Daniel Sol <dsolrueda at gmail.com>:
> 
> Hi everybody,
> 
> I have trouble finding how to implement a MCMCglmm with log-normal error. I
> know some people just log-transform the response variable, but this is not
> the same.
> 
> Many thanks in advance,
> 
> Dani
> 
> -- 
> Daniel Sol
> CREAF (Centre for Ecological Research and Forestry Applications)
> CSIC (Spanish National Research Council)
> Bellaterra, Catalonia E-08193, Spain
> TEL: +34 93-5814678
> FAX: +34 93-5814151
> E-MAIL: d.sol at creaf.uab.es
> Webpage: http://dsolrueda.wix.com/sol-group
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


	[[alternative HTML version deleted]]


From dsolrueda at gmail.com  Tue Jul 28 10:47:29 2015
From: dsolrueda at gmail.com (Daniel Sol)
Date: Tue, 28 Jul 2015 10:47:29 +0200
Subject: [R-sig-ME] Log-normal MCMCglmm
In-Reply-To: <ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>
References: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
	<ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>
Message-ID: <CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>

Hi J?rg,

Thanks a lot for the suggestion. I actually have tried to use a Poisson
error, but it looks like my data best fit a log-normal distribution.

Best,

Dani

2015-07-28 10:40 GMT+02:00 J?rg Albrecht <albrechj at staff.uni-marburg.de>:

> Hi Dani,
>
> you could try specifying
>
> family = "poisson".
>
> Best,
>
> J?rg
>
> ?
> J?rg Albrecht, PhD
> Postdoctoral researcher
> Institute of Nature Conservation
> Polish Academy of Sciences
> Mickiewicza 33
> 31-120 Krakow, Poland
> www.carpathianbear.pl
> www.globeproject.pl
> www.iop.krakow.pl
>
> Am 25.07.2015 um 11:31 schrieb Daniel Sol <dsolrueda at gmail.com>:
>
> Hi everybody,
>
> I have trouble finding how to implement a MCMCglmm with log-normal error. I
> know some people just log-transform the response variable, but this is not
> the same.
>
> Many thanks in advance,
>
> Dani
>
> --
> Daniel Sol
> CREAF (Centre for Ecological Research and Forestry Applications)
> CSIC (Spanish National Research Council)
> Bellaterra, Catalonia E-08193, Spain
> TEL: +34 93-5814678
> FAX: +34 93-5814151
> E-MAIL: d.sol at creaf.uab.es
> Webpage: http://dsolrueda.wix.com/sol-group
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
Daniel Sol
CREAF (Centre for Ecological Research and Forestry Applications)
CSIC (Spanish National Research Council)
Bellaterra, Catalonia E-08193, Spain
TEL: +34 93-5814678
FAX: +34 93-5814151
E-MAIL: d.sol at creaf.uab.es
Webpage: http://dsolrueda.wix.com/sol-group

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Tue Jul 28 12:33:04 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 28 Jul 2015 10:33:04 +0000
Subject: [R-sig-ME] Log-normal MCMCglmm
In-Reply-To: <CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>
References: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
	<ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>
	<CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>
Message-ID: <353CAFC4-8F52-4AF8-AC2B-420DFF512BF9@glasgow.ac.uk>

Hi Dani,

Can you explain with a formula what you mean by the difference between a model with log-normal errors and a model with normal errors where the response is log-transformed? As the errors are log-normal, i.e. strictly positive, they presumably can?t be additive. Are they multiplicative? If they are then logging the predictor will result in an additive model with normal errors.

E.g. a multiplicative model with lognormal errors:
Y = Yhat * exp(epsilon), where epsilon ~ exp(N(0, sigma^2))

Log it:
log(Y) = log(Yhat) + log(epsilon)
which is an additive model with normal errors with the response log-transformed.

Best wishes,
Paul

On 28 Jul 2015, at 09:47, Daniel Sol <dsolrueda at gmail.com> wrote:

> Hi J?rg,
> 
> Thanks a lot for the suggestion. I actually have tried to use a Poisson
> error, but it looks like my data best fit a log-normal distribution.
> 
> Best,
> 
> Dani
> 
> 2015-07-28 10:40 GMT+02:00 J?rg Albrecht <albrechj at staff.uni-marburg.de>:
> 
>> Hi Dani,
>> 
>> you could try specifying
>> 
>> family = "poisson".
>> 
>> Best,
>> 
>> J?rg
>> 
>> ?
>> J?rg Albrecht, PhD
>> Postdoctoral researcher
>> Institute of Nature Conservation
>> Polish Academy of Sciences
>> Mickiewicza 33
>> 31-120 Krakow, Poland
>> www.carpathianbear.pl
>> www.globeproject.pl
>> www.iop.krakow.pl
>> 
>> Am 25.07.2015 um 11:31 schrieb Daniel Sol <dsolrueda at gmail.com>:
>> 
>> Hi everybody,
>> 
>> I have trouble finding how to implement a MCMCglmm with log-normal error. I
>> know some people just log-transform the response variable, but this is not
>> the same.
>> 
>> Many thanks in advance,
>> 
>> Dani
>> 
>> --
>> Daniel Sol
>> CREAF (Centre for Ecological Research and Forestry Applications)
>> CSIC (Spanish National Research Council)
>> Bellaterra, Catalonia E-08193, Spain
>> TEL: +34 93-5814678
>> FAX: +34 93-5814151
>> E-MAIL: d.sol at creaf.uab.es
>> Webpage: http://dsolrueda.wix.com/sol-group
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
> 
> 
> -- 
> Daniel Sol
> CREAF (Centre for Ecological Research and Forestry Applications)
> CSIC (Spanish National Research Council)
> Bellaterra, Catalonia E-08193, Spain
> TEL: +34 93-5814678
> FAX: +34 93-5814151
> E-MAIL: d.sol at creaf.uab.es
> Webpage: http://dsolrueda.wix.com/sol-group
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dsolrueda at gmail.com  Tue Jul 28 13:03:15 2015
From: dsolrueda at gmail.com (Daniel Sol)
Date: Tue, 28 Jul 2015 13:03:15 +0200
Subject: [R-sig-ME] Log-normal MCMCglmm
In-Reply-To: <20150728114148.127147uigrhupilo@www.staffmail.ed.ac.uk>
References: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
	<ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>
	<CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>
	<20150728114148.127147uigrhupilo@www.staffmail.ed.ac.uk>
Message-ID: <CAN3C_1CsgVQy+UUk1d9FY6w8FBR+qLtTVja+xDbQAiMQUBRmiw@mail.gmail.com>

Dear Paul and Jarrod,

Thanks a lot for your responses. I read somewhere that in GLM
log-transforming the response variable and using a log-link is not exactly
the same, but I did not really know the implications. Based on your
clarifications, I'm gonna log-transform the response variable. Many thanks
for your help, I really appreciate it.

Best wishes,

Dani








2015-07-28 12:41 GMT+02:00 Jarrod Hadfield <j.hadfield at ed.ac.uk>:

> Hi Dani,
>
> I'm not sure why logging the response is not equivalent? Is it because you
> wish the residuals to be log normal, but the distribution of other random
> effects to be normal? If so, then MCMCglmm is not able to handle this: all
> random effects, including residuals, must be (multivariate) normal on some
> link scale.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> Quoting Daniel Sol <dsolrueda at gmail.com> on Tue, 28 Jul 2015 10:47:29
> +0200:
>
>  Hi J?rg,
>>
>> Thanks a lot for the suggestion. I actually have tried to use a Poisson
>> error, but it looks like my data best fit a log-normal distribution.
>>
>> Best,
>>
>> Dani
>>
>> 2015-07-28 10:40 GMT+02:00 J?rg Albrecht <albrechj at staff.uni-marburg.de>:
>>
>>  Hi Dani,
>>>
>>> you could try specifying
>>>
>>> family = "poisson".
>>>
>>> Best,
>>>
>>> J?rg
>>>
>>> ?
>>> J?rg Albrecht, PhD
>>> Postdoctoral researcher
>>> Institute of Nature Conservation
>>> Polish Academy of Sciences
>>> Mickiewicza 33
>>> 31-120 Krakow, Poland
>>> www.carpathianbear.pl
>>> www.globeproject.pl
>>> www.iop.krakow.pl
>>>
>>> Am 25.07.2015 um 11:31 schrieb Daniel Sol <dsolrueda at gmail.com>:
>>>
>>> Hi everybody,
>>>
>>> I have trouble finding how to implement a MCMCglmm with log-normal
>>> error. I
>>> know some people just log-transform the response variable, but this is
>>> not
>>> the same.
>>>
>>> Many thanks in advance,
>>>
>>> Dani
>>>
>>> --
>>> Daniel Sol
>>> CREAF (Centre for Ecological Research and Forestry Applications)
>>> CSIC (Spanish National Research Council)
>>> Bellaterra, Catalonia E-08193, Spain
>>> TEL: +34 93-5814678
>>> FAX: +34 93-5814151
>>> E-MAIL: d.sol at creaf.uab.es
>>> Webpage: http://dsolrueda.wix.com/sol-group
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>>
>>
>> --
>> Daniel Sol
>> CREAF (Centre for Ecological Research and Forestry Applications)
>> CSIC (Spanish National Research Council)
>> Bellaterra, Catalonia E-08193, Spain
>> TEL: +34 93-5814678
>> FAX: +34 93-5814151
>> E-MAIL: d.sol at creaf.uab.es
>> Webpage: http://dsolrueda.wix.com/sol-group
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
Daniel Sol
CREAF (Centre for Ecological Research and Forestry Applications)
CSIC (Spanish National Research Council)
Bellaterra, Catalonia E-08193, Spain
TEL: +34 93-5814678
FAX: +34 93-5814151
E-MAIL: d.sol at creaf.uab.es
Webpage: http://dsolrueda.wix.com/sol-group

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Jul 28 12:41:48 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 28 Jul 2015 11:41:48 +0100
Subject: [R-sig-ME] Log-normal MCMCglmm
In-Reply-To: <CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>
References: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
	<ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>
	<CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>
Message-ID: <20150728114148.127147uigrhupilo@www.staffmail.ed.ac.uk>

Hi Dani,

I'm not sure why logging the response is not equivalent? Is it because  
you wish the residuals to be log normal, but the distribution of other  
random effects to be normal? If so, then MCMCglmm is not able to  
handle this: all random effects, including residuals, must be  
(multivariate) normal on some link scale.

Cheers,

Jarrod




Quoting Daniel Sol <dsolrueda at gmail.com> on Tue, 28 Jul 2015 10:47:29 +0200:

> Hi J?rg,
>
> Thanks a lot for the suggestion. I actually have tried to use a Poisson
> error, but it looks like my data best fit a log-normal distribution.
>
> Best,
>
> Dani
>
> 2015-07-28 10:40 GMT+02:00 J?rg Albrecht <albrechj at staff.uni-marburg.de>:
>
>> Hi Dani,
>>
>> you could try specifying
>>
>> family = "poisson".
>>
>> Best,
>>
>> J?rg
>>
>> ?
>> J?rg Albrecht, PhD
>> Postdoctoral researcher
>> Institute of Nature Conservation
>> Polish Academy of Sciences
>> Mickiewicza 33
>> 31-120 Krakow, Poland
>> www.carpathianbear.pl
>> www.globeproject.pl
>> www.iop.krakow.pl
>>
>> Am 25.07.2015 um 11:31 schrieb Daniel Sol <dsolrueda at gmail.com>:
>>
>> Hi everybody,
>>
>> I have trouble finding how to implement a MCMCglmm with log-normal error. I
>> know some people just log-transform the response variable, but this is not
>> the same.
>>
>> Many thanks in advance,
>>
>> Dani
>>
>> --
>> Daniel Sol
>> CREAF (Centre for Ecological Research and Forestry Applications)
>> CSIC (Spanish National Research Council)
>> Bellaterra, Catalonia E-08193, Spain
>> TEL: +34 93-5814678
>> FAX: +34 93-5814151
>> E-MAIL: d.sol at creaf.uab.es
>> Webpage: http://dsolrueda.wix.com/sol-group
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> Daniel Sol
> CREAF (Centre for Ecological Research and Forestry Applications)
> CSIC (Spanish National Research Council)
> Bellaterra, Catalonia E-08193, Spain
> TEL: +34 93-5814678
> FAX: +34 93-5814151
> E-MAIL: d.sol at creaf.uab.es
> Webpage: http://dsolrueda.wix.com/sol-group
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Tue Jul 28 13:58:06 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 28 Jul 2015 12:58:06 +0100
Subject: [R-sig-ME] Log-normal MCMCglmm
In-Reply-To: <CAN3C_1CsgVQy+UUk1d9FY6w8FBR+qLtTVja+xDbQAiMQUBRmiw@mail.gmail.com>
References: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
	<ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>
	<CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>
	<20150728114148.127147uigrhupilo@www.staffmail.ed.ac.uk>
	<CAN3C_1CsgVQy+UUk1d9FY6w8FBR+qLtTVja+xDbQAiMQUBRmiw@mail.gmail.com>
Message-ID: <20150728125806.61306hs2mibmnrwg@www.staffmail.ed.ac.uk>

Hi Dani,

You are right. In a glm the link function is concerning the mean:

log(E[y]) = a linear model

this is not generally the same as:

E[log(y)] = a linear model

If y is log-normal

log(E[y]) = E[log(y)]+VAR[log(y)]/2

Implying that you would need to modify you're location effects by the  
variance to recover the location effects under a Gaussian glm with  
log-link.

Cheers,

Jarrod




Quoting Daniel Sol <dsolrueda at gmail.com> on Tue, 28 Jul 2015 13:03:15 +0200:

> Dear Paul and Jarrod,
>
> Thanks a lot for your responses. I read somewhere that in GLM
> log-transforming the response variable and using a log-link is not exactly
> the same, but I did not really know the implications. Based on your
> clarifications, I'm gonna log-transform the response variable. Many thanks
> for your help, I really appreciate it.
>
> Best wishes,
>
> Dani
>
>
>
>
>
>
>
>
> 2015-07-28 12:41 GMT+02:00 Jarrod Hadfield <j.hadfield at ed.ac.uk>:
>
>> Hi Dani,
>>
>> I'm not sure why logging the response is not equivalent? Is it because you
>> wish the residuals to be log normal, but the distribution of other random
>> effects to be normal? If so, then MCMCglmm is not able to handle this: all
>> random effects, including residuals, must be (multivariate) normal on some
>> link scale.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>> Quoting Daniel Sol <dsolrueda at gmail.com> on Tue, 28 Jul 2015 10:47:29
>> +0200:
>>
>>  Hi J?rg,
>>>
>>> Thanks a lot for the suggestion. I actually have tried to use a Poisson
>>> error, but it looks like my data best fit a log-normal distribution.
>>>
>>> Best,
>>>
>>> Dani
>>>
>>> 2015-07-28 10:40 GMT+02:00 J?rg Albrecht <albrechj at staff.uni-marburg.de>:
>>>
>>>  Hi Dani,
>>>>
>>>> you could try specifying
>>>>
>>>> family = "poisson".
>>>>
>>>> Best,
>>>>
>>>> J?rg
>>>>
>>>> ?
>>>> J?rg Albrecht, PhD
>>>> Postdoctoral researcher
>>>> Institute of Nature Conservation
>>>> Polish Academy of Sciences
>>>> Mickiewicza 33
>>>> 31-120 Krakow, Poland
>>>> www.carpathianbear.pl
>>>> www.globeproject.pl
>>>> www.iop.krakow.pl
>>>>
>>>> Am 25.07.2015 um 11:31 schrieb Daniel Sol <dsolrueda at gmail.com>:
>>>>
>>>> Hi everybody,
>>>>
>>>> I have trouble finding how to implement a MCMCglmm with log-normal
>>>> error. I
>>>> know some people just log-transform the response variable, but this is
>>>> not
>>>> the same.
>>>>
>>>> Many thanks in advance,
>>>>
>>>> Dani
>>>>
>>>> --
>>>> Daniel Sol
>>>> CREAF (Centre for Ecological Research and Forestry Applications)
>>>> CSIC (Spanish National Research Council)
>>>> Bellaterra, Catalonia E-08193, Spain
>>>> TEL: +34 93-5814678
>>>> FAX: +34 93-5814151
>>>> E-MAIL: d.sol at creaf.uab.es
>>>> Webpage: http://dsolrueda.wix.com/sol-group
>>>>
>>>> [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Daniel Sol
>>> CREAF (Centre for Ecological Research and Forestry Applications)
>>> CSIC (Spanish National Research Council)
>>> Bellaterra, Catalonia E-08193, Spain
>>> TEL: +34 93-5814678
>>> FAX: +34 93-5814151
>>> E-MAIL: d.sol at creaf.uab.es
>>> Webpage: http://dsolrueda.wix.com/sol-group
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Daniel Sol
> CREAF (Centre for Ecological Research and Forestry Applications)
> CSIC (Spanish National Research Council)
> Bellaterra, Catalonia E-08193, Spain
> TEL: +34 93-5814678
> FAX: +34 93-5814151
> E-MAIL: d.sol at creaf.uab.es
> Webpage: http://dsolrueda.wix.com/sol-group
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From daniel.gregory3 at gmail.com  Tue Jul 28 20:01:54 2015
From: daniel.gregory3 at gmail.com (=?UTF-8?Q?Gr=c3=a9gory_DANIEL?=)
Date: Tue, 28 Jul 2015 20:01:54 +0200
Subject: [R-sig-ME] MCMCglmm : Bivariate model and prior
In-Reply-To: <55B7C2F2.2000004@gmail.com>
References: <55B7C134.7060701@gmail.com> <55B7C2F2.2000004@gmail.com>
Message-ID: <55B7C392.4090401@gmail.com>

Dear MCMCglmm users,

Few weeks ago, I asked a question concerning some issues that I have to 
parametrize a bivariate model in MCMCglmm. So I'm sorry to ask again. 
But I want to be sure that I had no response because no one says or 
because it's impossible, and not because of an simple oversight, a field 
work or a vacation. ^^

I wish to run a bivariate model with MCMCglmm package. But one response 
variable is a continuous one (family = gaussian) and the other is a 
binary one (family = ordinal). I have sought a way to parameterize 
properly the priors (in the archives of this list too), I tried some 
solutions that I thought, but in vain. I think I have to fix to 1 the 
residual variance for the binary variable and leave it free for the 
continuous variable.
Is it possible in MCMCglmm ? And if yes : how do I parameterize the 
priors for the residual variance ?

I'll very grateful if someone could answer me.

Gr?gory DANIEL
PhD Student - LBBE
University of Lyon 1
69100 Villeurbanne - FRANCE


From j.hadfield at ed.ac.uk  Tue Jul 28 20:40:27 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 28 Jul 2015 19:40:27 +0100
Subject: [R-sig-ME] MCMCglmm : Bivariate model and prior
In-Reply-To: <55B7C392.4090401@gmail.com>
References: <55B7C134.7060701@gmail.com> <55B7C2F2.2000004@gmail.com>
	<55B7C392.4090401@gmail.com>
Message-ID: <20150728194027.14384p13fc39f88w@www.staffmail.ed.ac.uk>

Hi,

The answer to your first question is field work.

The prior for the residual term is list(V=V, nu=nu, fix=2) where V is  
some covariance matrix with V[2,2]=1, and nu is the degree of belief  
parameter. You could try a flat prior initially i.e V=diag(2) and nu=0.

I would advise using family="threshold" rather than family="ordinal"  
for this analysis. If the estimated residual covariance matrix is VR  
then then the residual correlation on the latent scale is:

VR[1,2]/sqrt(VR[1,1])

with family="ordinal" it is:

VR[1,2]/sqrt(VR[1,1]*2)

and so this constrains the correlation to be less in magnitude than  
the theoretical limits of -1 and 1 because VR is constrained to be  
positive definite.

Cheers,

Jarrod





Quoting Gr?gory DANIEL <daniel.gregory3 at gmail.com> on Tue, 28 Jul 2015  
20:01:54 +0200:

> Dear MCMCglmm users,
>
> Few weeks ago, I asked a question concerning some issues that I have  
> to parametrize a bivariate model in MCMCglmm. So I'm sorry to ask  
> again. But I want to be sure that I had no response because no one  
> says or because it's impossible, and not because of an simple  
> oversight, a field work or a vacation. ^^
>
> I wish to run a bivariate model with MCMCglmm package. But one  
> response variable is a continuous one (family = gaussian) and the  
> other is a binary one (family = ordinal). I have sought a way to  
> parameterize properly the priors (in the archives of this list too),  
> I tried some solutions that I thought, but in vain. I think I have  
> to fix to 1 the residual variance for the binary variable and leave  
> it free for the continuous variable.
> Is it possible in MCMCglmm ? And if yes : how do I parameterize the  
> priors for the residual variance ?
>
> I'll very grateful if someone could answer me.
>
> Gr?gory DANIEL
> PhD Student - LBBE
> University of Lyon 1
> 69100 Villeurbanne - FRANCE
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From paul.johnson at glasgow.ac.uk  Tue Jul 28 18:14:07 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 28 Jul 2015 16:14:07 +0000
Subject: [R-sig-ME] Log-normal MCMCglmm
In-Reply-To: <353CAFC4-8F52-4AF8-AC2B-420DFF512BF9@glasgow.ac.uk>
References: <CAN3C_1D5g1ftUxnFvGOfOGZ7OG=RwwX1KvDGEHh4xuHXLjcfzQ@mail.gmail.com>
	<ED9E5D93-D344-4735-A271-AF00BE9B5E8E@staff.uni-marburg.de>
	<CAN3C_1C_Lgb+CsJN=PpkKQa33_9TS4H7apQqKsSa_YPb3rhToA@mail.gmail.com>
	<353CAFC4-8F52-4AF8-AC2B-420DFF512BF9@glasgow.ac.uk>
Message-ID: <0033BBE2-F706-443D-97C8-C5CFC9657D36@glasgow.ac.uk>

PS I should have written:

> Y = Yhat * epsilon, where epsilon ~ exp(N(0, sigma^2))


not

> Y = Yhat * exp(epsilon), where epsilon ~ exp(N(0, sigma^2))

Paul


On 28 Jul 2015, at 11:33, Paul Johnson <Paul.Johnson at glasgow.ac.uk> wrote:

> Hi Dani,
> 
> Can you explain with a formula what you mean by the difference between a model with log-normal errors and a model with normal errors where the response is log-transformed? As the errors are log-normal, i.e. strictly positive, they presumably can?t be additive. Are they multiplicative? If they are then logging the predictor will result in an additive model with normal errors.
> 
> E.g. a multiplicative model with lognormal errors:
> Y = Yhat * exp(epsilon), where epsilon ~ exp(N(0, sigma^2))
> 
> Log it:
> log(Y) = log(Yhat) + log(epsilon)
> which is an additive model with normal errors with the response log-transformed.
> 
> Best wishes,
> Paul
> 
> On 28 Jul 2015, at 09:47, Daniel Sol <dsolrueda at gmail.com> wrote:
> 
>> Hi J?rg,
>> 
>> Thanks a lot for the suggestion. I actually have tried to use a Poisson
>> error, but it looks like my data best fit a log-normal distribution.
>> 
>> Best,
>> 
>> Dani
>> 
>> 2015-07-28 10:40 GMT+02:00 J?rg Albrecht <albrechj at staff.uni-marburg.de>:
>> 
>>> Hi Dani,
>>> 
>>> you could try specifying
>>> 
>>> family = "poisson".
>>> 
>>> Best,
>>> 
>>> J?rg
>>> 
>>> ?
>>> J?rg Albrecht, PhD
>>> Postdoctoral researcher
>>> Institute of Nature Conservation
>>> Polish Academy of Sciences
>>> Mickiewicza 33
>>> 31-120 Krakow, Poland
>>> www.carpathianbear.pl
>>> www.globeproject.pl
>>> www.iop.krakow.pl
>>> 
>>> Am 25.07.2015 um 11:31 schrieb Daniel Sol <dsolrueda at gmail.com>:
>>> 
>>> Hi everybody,
>>> 
>>> I have trouble finding how to implement a MCMCglmm with log-normal error. I
>>> know some people just log-transform the response variable, but this is not
>>> the same.
>>> 
>>> Many thanks in advance,
>>> 
>>> Dani
>>> 
>>> --
>>> Daniel Sol
>>> CREAF (Centre for Ecological Research and Forestry Applications)
>>> CSIC (Spanish National Research Council)
>>> Bellaterra, Catalonia E-08193, Spain
>>> TEL: +34 93-5814678
>>> FAX: +34 93-5814151
>>> E-MAIL: d.sol at creaf.uab.es
>>> Webpage: http://dsolrueda.wix.com/sol-group
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>> 
>> 
>> -- 
>> Daniel Sol
>> CREAF (Centre for Ecological Research and Forestry Applications)
>> CSIC (Spanish National Research Council)
>> Bellaterra, Catalonia E-08193, Spain
>> TEL: +34 93-5814678
>> FAX: +34 93-5814151
>> E-MAIL: d.sol at creaf.uab.es
>> Webpage: http://dsolrueda.wix.com/sol-group
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From beckyannegilbert at gmail.com  Wed Jul 29 19:05:42 2015
From: beckyannegilbert at gmail.com (Becky Gilbert)
Date: Wed, 29 Jul 2015 18:05:42 +0100
Subject: [R-sig-ME] glmer formula with partially-crossed fixed effects
Message-ID: <CALWifgBU6RWzsScj2=tAwKBsF2W--sXZjsghjv6Hg7FZ+CuYVg@mail.gmail.com>

Dear List,

I'm trying to create a logistic linear mixed effect model with 3 fixed
factors, 2 of which are partially crossed (I think this is the right
term?).  Factor A has 2 levels, factor B has 2 levels that only occur
within one level of A, and factor C has 2 levels.  There are also 2 crossed
random factors, subject and item.  I've provided an example data set with
the same structure at the end of this email.

My question is, how do I code the partially crossed fixed effects (A and B)
in order to get all the fixed effects of interest?

Here's what I'd like to get from the model:
1. main effect of A
2. effect of B (which occurs within one level of A)
3. main effect of C
4. A:C interaction
5. B:C interaction (which occurs within one level of A)

So far I have tried the following:

1. Code factor B as two levels, which are only valid within level 1 of A.
Within level 2 of A, factor B = NA. This gives me the following
combinations:
A   B
1   1
1   2
2   NA

I get an error using this formula (random intercepts only, for convenience):
glmer(dv ~ 1 + A + B + C + A:C + B:C +
    (1|subject) +
    (1|item),
    data = mydata,
    family = binomial)

Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels

2. Use dummy coding for factor B, where A1B1 is coded as 1 and everything
else is 2, and then look at the effect of B within A1.  Recoding the B
factor in this way gives me:
A  BnoNA
1   1
1   2
2   2

glmer(dv ~ 1 + A + BnoNA + C + A:C + BnoNA:C +
                (1|subject) +
                (1|item),
              data = mydata,
              family = binomial)

This model converges without errors/warnings, but I don't know how to get
the effect of B within A1.  Also, it seems like I don't want to model the
main effects and interactions of 'BnoNA' (i.e. the effect of A1B1), but I
don't know how else to write the formula...

3. Remove factor A from the model, recode B with 3 levels (i.e. 1 = A1B1, 2
= A1B2, 3 = A2), then use contrasts of B levels to get the main effect of A
(i.e. (B = 1 and B = 2) vs B = 3).
A  B   B3levels
1  1    1
1  2    2
2  NA 3

glmer(dv ~ 1 + B3levels + C + B3levels:C +
                (1|subject) +
                (1|item),
              data = mydata,
              family = binomial)

This model converges without errors/warnings, but I don't know how to add
the contrasts for (B1 and B2) vs B3, or the interaction between this
contrast coding (i.e. main effect of A) and C.

4. Run 2 separate models. The first model uses the full data set to get the
effects of A, C and the interaction.  The second model uses a subset of the
data (only level 1 of A) to get the effect of B within A1, and the B:C
interaction.  My concern with this solution is that the random effects
structure would differ between the two models, because the random effects
for subjects and items would be based on data from both levels of A in the
first model and only A1 in the second model.

Apologies for the novice question, messy data simulation code and possible
confusion of terms!  I searched the list archives and I googled extensively
but couldn't find an answer.

Thanks in advance.
Becky


### Here is code to produce some example data of the same structure.

A <- c(rep(rep(c(1,1,1,1,0,0), each = 13), 13),
       rep(rep(c(0,1,1,1,1,0), each = 13), 13),
       rep(rep(c(0,0,1,1,1,1), each = 13), 13),
       rep(rep(c(1,0,0,1,1,1), each = 13), 13),
       rep(rep(c(1,1,0,0,1,1), each = 13), 13),
       rep(rep(c(1,1,1,0,0,1), each = 13), 13))
B <- c(rep(rep(c(1,1,0,0,NA,NA), each = 13), 13),
       rep(rep(c(NA,1,1,0,0,NA), each = 13), 13),
       rep(rep(c(NA,NA,1,1,0,0), each = 13), 13),
       rep(rep(c(0,NA,NA,1,1,0), each = 13), 13),
       rep(rep(c(0,0,NA,NA,1,1), each = 13), 13),
       rep(rep(c(1,0,0,NA,NA,1), each = 13), 13))
C <- c(rep(rep(c(1,0,1,0,1,0), each = 13), 13),
       rep(rep(c(0,1,0,1,0,1), each = 13), 13),
       rep(rep(c(1,0,1,0,1,0), each = 13), 13),
       rep(rep(c(0,1,0,1,0,1), each = 13), 13),
       rep(rep(c(1,0,1,0,1,0), each = 13), 13),
       rep(rep(c(0,1,0,1,0,1), each = 13), 13))
mydata <- data.frame(A = factor(A),
                     B = factor(B),
                     C = factor(C),
                     subject = factor(rep(1:78, each = 78)),
                     item = factor(rep(1:78, 78)),
                     dv = factor(sample(0:1, 78*78, replace = TRUE)))

# recode B factor - change NAs into 0s
mydata$BnoNA <- mydata$B
mydata$BnoNA[which(is.na(mydata$BnoNA))] <- 0

# recode B factor - change NAs into a 3rd level
mydata$B3levels <- as.numeric(mydata$B)
mydata$B3levels[which(is.na(mydata$B3levels))] <- 3
mydata$B3levels <- as.factor(mydata$B3levels)

> str(mydata)
'data.frame': 6084 obs. of  8 variables:
 $ A       : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ B       : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ C       : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ subject : Factor w/ 78 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ item    : Factor w/ 78 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10
...
 $ dv      : Factor w/ 2 levels "0","1": 2 2 1 1 1 2 1 2 2 1 ...
 $ BnoNA   : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ B3levels: Factor w/ 3 levels "1","2","3": 2 2 2 2 2 2 2 2 2 2 ...

#Because B is only partially crossed with A, there should be no valid
entries of B in one of the levels of A, as confirmed by:
> table(mydata$A, mydata$B)
       0    1
  0    0    0
  1 2028 2028
> table(mydata$A,mydata$BnoNA)
       0    1
  0 2028    0
  1 2028 2028
> table(mydata$A,mydata$B3levels)

       1    2    3
  0    0    0 2028
  1 2028 2028    0

### My R environment
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)
lme4_1.1-7

	[[alternative HTML version deleted]]


From drmccloy at uw.edu  Wed Jul 29 21:38:11 2015
From: drmccloy at uw.edu (Dan McCloy)
Date: Wed, 29 Jul 2015 12:38:11 -0700
Subject: [R-sig-ME] glmer formula with partially-crossed fixed effects
In-Reply-To: <CALWifgBU6RWzsScj2=tAwKBsF2W--sXZjsghjv6Hg7FZ+CuYVg@mail.gmail.com>
References: <CALWifgBU6RWzsScj2=tAwKBsF2W--sXZjsghjv6Hg7FZ+CuYVg@mail.gmail.com>
Message-ID: <CAOE0pYm+yNeMQQZhxvOJXb6QE8S_1e6jfrDiM3XVXfScV9eGDA@mail.gmail.com>

You may want to consider Helmert coding applied to a single new factor made
from A and B, with 3 levels: A1, A2B1, A2B2. Make sure that A1 ends up as
the highest value in the factor.

foo <- factor(1:3, labels=c("A2B1", "A2B2", "A1"))
contrasts(foo) <- contr.helmert
contrasts(foo) <- contrasts(foo) / rep(2:3, each=3)

The last line is to get "sum to one" factor weights.  See ?contr.helmert
for more info.
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington





On Wed, Jul 29, 2015 at 10:05 AM, Becky Gilbert <beckyannegilbert at gmail.com>
wrote:

> Dear List,
>
> I'm trying to create a logistic linear mixed effect model with 3 fixed
> factors, 2 of which are partially crossed (I think this is the right
> term?).  Factor A has 2 levels, factor B has 2 levels that only occur
> within one level of A, and factor C has 2 levels.  There are also 2 crossed
> random factors, subject and item.  I've provided an example data set with
> the same structure at the end of this email.
>
> My question is, how do I code the partially crossed fixed effects (A and B)
> in order to get all the fixed effects of interest?
>
> Here's what I'd like to get from the model:
> 1. main effect of A
> 2. effect of B (which occurs within one level of A)
> 3. main effect of C
> 4. A:C interaction
> 5. B:C interaction (which occurs within one level of A)
>
> So far I have tried the following:
>
> 1. Code factor B as two levels, which are only valid within level 1 of A.
> Within level 2 of A, factor B = NA. This gives me the following
> combinations:
> A   B
> 1   1
> 1   2
> 2   NA
>
> I get an error using this formula (random intercepts only, for
> convenience):
> glmer(dv ~ 1 + A + B + C + A:C + B:C +
>     (1|subject) +
>     (1|item),
>     data = mydata,
>     family = binomial)
>
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>   contrasts can be applied only to factors with 2 or more levels
>
> 2. Use dummy coding for factor B, where A1B1 is coded as 1 and everything
> else is 2, and then look at the effect of B within A1.  Recoding the B
> factor in this way gives me:
> A  BnoNA
> 1   1
> 1   2
> 2   2
>
> glmer(dv ~ 1 + A + BnoNA + C + A:C + BnoNA:C +
>                 (1|subject) +
>                 (1|item),
>               data = mydata,
>               family = binomial)
>
> This model converges without errors/warnings, but I don't know how to get
> the effect of B within A1.  Also, it seems like I don't want to model the
> main effects and interactions of 'BnoNA' (i.e. the effect of A1B1), but I
> don't know how else to write the formula...
>
> 3. Remove factor A from the model, recode B with 3 levels (i.e. 1 = A1B1, 2
> = A1B2, 3 = A2), then use contrasts of B levels to get the main effect of A
> (i.e. (B = 1 and B = 2) vs B = 3).
> A  B   B3levels
> 1  1    1
> 1  2    2
> 2  NA 3
>
> glmer(dv ~ 1 + B3levels + C + B3levels:C +
>                 (1|subject) +
>                 (1|item),
>               data = mydata,
>               family = binomial)
>
> This model converges without errors/warnings, but I don't know how to add
> the contrasts for (B1 and B2) vs B3, or the interaction between this
> contrast coding (i.e. main effect of A) and C.
>
> 4. Run 2 separate models. The first model uses the full data set to get the
> effects of A, C and the interaction.  The second model uses a subset of the
> data (only level 1 of A) to get the effect of B within A1, and the B:C
> interaction.  My concern with this solution is that the random effects
> structure would differ between the two models, because the random effects
> for subjects and items would be based on data from both levels of A in the
> first model and only A1 in the second model.
>
> Apologies for the novice question, messy data simulation code and possible
> confusion of terms!  I searched the list archives and I googled extensively
> but couldn't find an answer.
>
> Thanks in advance.
> Becky
>
>
> ### Here is code to produce some example data of the same structure.
>
> A <- c(rep(rep(c(1,1,1,1,0,0), each = 13), 13),
>        rep(rep(c(0,1,1,1,1,0), each = 13), 13),
>        rep(rep(c(0,0,1,1,1,1), each = 13), 13),
>        rep(rep(c(1,0,0,1,1,1), each = 13), 13),
>        rep(rep(c(1,1,0,0,1,1), each = 13), 13),
>        rep(rep(c(1,1,1,0,0,1), each = 13), 13))
> B <- c(rep(rep(c(1,1,0,0,NA,NA), each = 13), 13),
>        rep(rep(c(NA,1,1,0,0,NA), each = 13), 13),
>        rep(rep(c(NA,NA,1,1,0,0), each = 13), 13),
>        rep(rep(c(0,NA,NA,1,1,0), each = 13), 13),
>        rep(rep(c(0,0,NA,NA,1,1), each = 13), 13),
>        rep(rep(c(1,0,0,NA,NA,1), each = 13), 13))
> C <- c(rep(rep(c(1,0,1,0,1,0), each = 13), 13),
>        rep(rep(c(0,1,0,1,0,1), each = 13), 13),
>        rep(rep(c(1,0,1,0,1,0), each = 13), 13),
>        rep(rep(c(0,1,0,1,0,1), each = 13), 13),
>        rep(rep(c(1,0,1,0,1,0), each = 13), 13),
>        rep(rep(c(0,1,0,1,0,1), each = 13), 13))
> mydata <- data.frame(A = factor(A),
>                      B = factor(B),
>                      C = factor(C),
>                      subject = factor(rep(1:78, each = 78)),
>                      item = factor(rep(1:78, 78)),
>                      dv = factor(sample(0:1, 78*78, replace = TRUE)))
>
> # recode B factor - change NAs into 0s
> mydata$BnoNA <- mydata$B
> mydata$BnoNA[which(is.na(mydata$BnoNA))] <- 0
>
> # recode B factor - change NAs into a 3rd level
> mydata$B3levels <- as.numeric(mydata$B)
> mydata$B3levels[which(is.na(mydata$B3levels))] <- 3
> mydata$B3levels <- as.factor(mydata$B3levels)
>
> > str(mydata)
> 'data.frame': 6084 obs. of  8 variables:
>  $ A       : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
>  $ B       : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
>  $ C       : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
>  $ subject : Factor w/ 78 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1
> ...
>  $ item    : Factor w/ 78 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10
> ...
>  $ dv      : Factor w/ 2 levels "0","1": 2 2 1 1 1 2 1 2 2 1 ...
>  $ BnoNA   : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
>  $ B3levels: Factor w/ 3 levels "1","2","3": 2 2 2 2 2 2 2 2 2 2 ...
>
> #Because B is only partially crossed with A, there should be no valid
> entries of B in one of the levels of A, as confirmed by:
> > table(mydata$A, mydata$B)
>        0    1
>   0    0    0
>   1 2028 2028
> > table(mydata$A,mydata$BnoNA)
>        0    1
>   0 2028    0
>   1 2028 2028
> > table(mydata$A,mydata$B3levels)
>
>        1    2    3
>   0    0    0 2028
>   1 2028 2028    0
>
> ### My R environment
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> lme4_1.1-7
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From M.E.Sudell at liverpool.ac.uk  Tue Jul 28 16:01:49 2015
From: M.E.Sudell at liverpool.ac.uk (Sudell, Maria [mesudell])
Date: Tue, 28 Jul 2015 14:01:49 +0000
Subject: [R-sig-ME] Calculation of random effects for factors in R
Message-ID: <A0BEC8B4FD089747956D1ACE2E85D0F403DACEAF@BHEXMBX2.livad.liv.ac.uk>

Hello,
I have a question concerning exactly how random effects for a factor are calculated in R.  I have tried to find an answer on various R related websites and text books but cannot find a definitive explanation.

As an example, if you had a longitudinal dataset, and you wanted to include an individual specific random effect for a smoking factor (say 3 levels, current, ex, never), how would the random effects be calculated using R?  (I understand how to code this in R, I am aiming to understand the mechanics of how the function gets to the random effects).

My understanding so far would be that indicator variables for each of the levels of the factor would be included (in this case 3 indicator variables of 0,1, one for each of current, ex, never).  Then coefficients for the indicator variables would be found (so for each individual in the dataset, we would end up with a coefficient for one of the indicator variables, assuming that individuals can't be in more than one group).  These random coefficients (one for each individual as each individual would only fall into one smoking status) would then have their mean and variation calculated, in order to report the distribution of the random effect.  Is this correct?

Apologies for such a simple question.  Any help or explanation (or point to relevant paper or textbook) of how random effects are calculated for factors in R would be greatly appreciated.
Many thanks
Maria


	[[alternative HTML version deleted]]


From daniel.kaschek at physik.uni-freiburg.de  Thu Jul 30 15:34:07 2015
From: daniel.kaschek at physik.uni-freiburg.de (Daniel Kaschek)
Date: Thu, 30 Jul 2015 15:34:07 +0200
Subject: [R-sig-ME] Model with variable number of arguments
Message-ID: <1438263247.13557.91.camel@physik.uni-freiburg.de>

Dear all,

I have the following model:

y_ij = x_i/s_j + (eps_ij)/s_j

where y_ij are the responses, x_i and s_j are the fixed effects and the
random effects follow a normal distribution

eps_ij ~ N(0, sigma0^2 + x_i^2 * sigmaR^2)

with error parameters sigma0 and sigmaR. In the end, I am interested in
the parameters x_i, s_j, sigma0 and sigmaR.

First of all, is lme4 the right package to solve this problem? When
looking at nlmer(), I had problems to figure out what would be the
correct structure of the function in the middle of the 3-part-formula.

Any help is appreciated.

Thanks a lot in advance,
Daniel


From yvonne.hiller at hotmail.de  Fri Jul 31 15:42:21 2015
From: yvonne.hiller at hotmail.de (Yvonne Hiller)
Date: Fri, 31 Jul 2015 15:42:21 +0200
Subject: [R-sig-ME] Interpretation of GLMM output in R
Message-ID: <DUB119-W22109F11D44DFB8D916C5928A0@phx.gbl>





















Dear Ben Bolker and list members,

 

I?am a PhD-student working on tropical plant-pollinator
interactions (the fig-fig wasp mutualism).

I have some difficulties with my analyses of my data
using lmer (family = Poisson). I have read a lot of threads and searched for
solutions in Zuur 2009, though it was not completely satisfying. I looked at
other papers using GLMM (espeacially for the fig-fig wasp mutualism), but there
were so many different ways in reporting and interpreting p-values, AICs etc.
Therefore, I would be very grateful, if you could go through my output and
answer my questions to hopefully fully understand GLMM. Thank you so much in
advance.

 

One of my questions is:

Have parasitoids (offspring) and the volume size an
effect on the number of pollinator offspring?

 

As pollinators are parasitized by parasitoids, I would
expect a negative impact on pollinator offspring. As the size of the fig fruits
might be an additionally factor (due to limited oviposition sites inside the fruit
or due to the ovipositor length of a parasitoid is to short to reach inner most
ovules galled by pollinators), I included it in the model.

 

I have poisson data (counts):

 

Pollinator
= pollinator offspring

Parasitoids = parasitoid offspring

volume = fig fruit size measurement

tree = Tree ID

 

I have data from trees in the forest and in the
farmland, as well as data of the rainy and dry season. I have chosen to perform
lmer for each season and habitat separately. For each tree, I have collected 10
fig fruits to count offspring of wasps at the trophic level (pollinator,
parasitoid) and to measure the size of the fruit (volume). As I have 10 fig
fruits per tree, I would use tree as a random effect, to account for unmeasured
variance between trees. I have found different approaches to that in
literature. For instance: We did not include? tree ? and ?
syconium ? as random factors, because wasps were free to move between syconia
on the same tree, and between trees. 

Therefore,
I am not sure if I have to use GLMM with trees as a random effect or if it?s
also possible to use GLM without the random effect. 

 

The inclusion of
fig volume in this manner removed the need to use ?fig? as an additional nested
factor within ?tree?. Is that right?

 

Here, I
present the model with the random effect.

So, lets start with the model of the farmland during
the dry season:

 

fad <- lmer(Pollinator~Parasitoids+volume+(1|tree),family="poisson",verbose=TRUE)

 

summary (fad)

Generalized linear mixed model fit by the Laplace
approximation 

Formula: Pollinator ~ Parasitoids + volume + (1 |
tree) 

   Data:
fad.data 

  AIC  BIC logLik deviance

 1166 1175
-578.9     1158

Random effects:

 Groups
Name        Variance Std.Dev.

 tree   (Intercept) 0.10634  0.3261 


Number of obs: 80, groups: tree, 8

 

Fixed effects:

             
Estimate Std. Error z value Pr(>|z|)    

(Intercept) 
2.3167867  0.1632747  14.190  
<2e-16 ***

Parasitoids -0.0046908 
0.0021686  -2.163   0.0305 * 


volume      
0.0069525  0.0006108  11.383  
<2e-16 ***

---

Signif.
codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
?.? 0.1 ? ? 1

 

Correlation of Fixed Effects:

           
(Intr) Prstds

Parasitoids -0.160       

volume     
-0.657 -0.107

 

1. Random effects: What does the Random
Effect table - the Variance, Std. Dev. and Intercept tells me?

 

So it says that the
between?tree variability is fairly large. But I don?t understand to what it
relates. Does it mean that pollinator offspring variance is high between
trees and might be overestimating the explanatory variables?

 

2. What can I
conclude from the model regarding the fixed effects and how to report about it
(with or without p-values, z-values, estimates)?

 

So of what I know is that
the p-value is only a guide and that it is rather a comparison of two models.
What are the two models and can I compare them. 

 

4. What does the
correlation of fixed effects tells me?

 

5. Is it right
that the estimates tells me whether the relation of the fixed effects to
pollinator offspring is positive or negative?

 

6. Can I
calculate an effect size on each explanatory variable?

 

I would highly appreciate your feedback on this.
Thanks so much in advance.

 

Best wishes,

Yvonne Hiller





 		 	   		  
	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Sat Aug  1 15:41:23 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 1 Aug 2015 08:41:23 -0500
Subject: [R-sig-ME] Interpretation of GLMM output in R
In-Reply-To: <DUB119-W22109F11D44DFB8D916C5928A0@phx.gbl>
References: <DUB119-W22109F11D44DFB8D916C5928A0@phx.gbl>
Message-ID: <CAErODj_XdLLOqJM_SuhinCYjUOqx667whKS3g5_uzGDrxeCm5w@mail.gmail.com>

Hi

Your message comes through with weird line breaks, you should turn off
the HTML compose option in your mail program, just write text.

On Fri, Jul 31, 2015 at 8:42 AM, Yvonne Hiller <yvonne.hiller at hotmail.de> wrote:
>
>
>
>
> Dear Ben Bolker and list members,
>
>
>
> I?am a PhD-student working on tropical plant-pollinator
> interactions (the fig-fig wasp mutualism).
>
> I have some difficulties with my analyses of my data
> using lmer (family = Poisson). I have read a lot of threads and searched for
> solutions in Zuur 2009, though it was not completely satisfying. I looked at
> other papers using GLMM (espeacially for the fig-fig wasp mutualism), but there
> were so many different ways in reporting and interpreting p-values, AICs etc.
> Therefore, I would be very grateful, if you could go through my output and
> answer my questions to hopefully fully understand GLMM. Thank you so much in
> advance.
>
>
>
> One of my questions is:
>
> Have parasitoids (offspring) and the volume size an
> effect on the number of pollinator offspring?
>
>
>
> As pollinators are parasitized by parasitoids, I would
> expect a negative impact on pollinator offspring. As the size of the fig fruits
> might be an additionally factor (due to limited oviposition sites inside the fruit
> or due to the ovipositor length of a parasitoid is to short to reach inner most
> ovules galled by pollinators), I included it in the model.
>
>
>
> I have poisson data (counts):
>
>
>
> Pollinator
> = pollinator offspring
>
> Parasitoids = parasitoid offspring
>
> volume = fig fruit size measurement
>
> tree = Tree ID
>
>
>
> I have data from trees in the forest and in the
> farmland, as well as data of the rainy and dry season. I have chosen to perform
> lmer for each season and habitat separately. For each tree, I have collected 10
> fig fruits to count offspring of wasps at the trophic level (pollinator,
> parasitoid) and to measure the size of the fruit (volume). As I have 10 fig
> fruits per tree, I would use tree as a random effect, to account for unmeasured
> variance between trees. I have found different approaches to that in
> literature. For instance: We did not include? tree ? and ?
> syconium ? as random factors, because wasps were free to move between syconia
> on the same tree, and between trees.
>
> Therefore,
> I am not sure if I have to use GLMM with trees as a random effect or if it?s
> also possible to use GLM without the random effect.
>
>
>
> The inclusion of
> fig volume in this manner removed the need to use ?fig? as an additional nested
> factor within ?tree?. Is that right?
>
>
>
> Here, I
> present the model with the random effect.
>
> So, lets start with the model of the farmland during
> the dry season:
>
>
>
> fad <- lmer(Pollinator~Parasitoids+volume+(1|tree),family="poisson",verbose=TRUE)
>
>
>
> summary (fad)
>
> Generalized linear mixed model fit by the Laplace
> approximation
>
> Formula: Pollinator ~ Parasitoids + volume + (1 |
> tree)
>
>    Data:
> fad.data
>
>   AIC  BIC logLik deviance
>
>  1166 1175
> -578.9     1158
>
> Random effects:
>
>  Groups
> Name        Variance Std.Dev.
>
>  tree   (Intercept) 0.10634  0.3261
>
>
> Number of obs: 80, groups: tree, 8
>
>
>
> Fixed effects:
>
>
> Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)
> 2.3167867  0.1632747  14.190
> <2e-16 ***
>
> Parasitoids -0.0046908
> 0.0021686  -2.163   0.0305 *
>
>
> volume
> 0.0069525  0.0006108  11.383
> <2e-16 ***
>
> ---
>
> Signif.
> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
> ?.? 0.1 ? ? 1
>
>
>
> Correlation of Fixed Effects:
>
>
> (Intr) Prstds
>
> Parasitoids -0.160
>
> volume
> -0.657 -0.107
>
>
>
> 1. Random effects: What does the Random
> Effect table - the Variance, Std. Dev. and Intercept tells me?
>
>
Your model assumes that the outcome is Poisson with expected value
exp(beta0 + beta1*parasitoids + btree)

btree is a unique added amount for each tree.  The estimate of the
number btree's variance across trees is 0.1.

What that 0.1 means in terms of the predicted outcome?  Well, that
mostly depends on how big beta0 + beta1*parasitoids is.  If that
number is huge, say 1000, then adding a thing with variance 0.1 won't
matter much.

On the other hand, if it is 0.01, then the random effect at the tree
level is very large, compared to the systematic components in your
model.  When the link function gets applied, the distribution of
outcomes changes in an interesting way.

If you run ranef(), it will spit out the estimates of the random
differences among trees (btree "BLUPS").  If you run the predict
method, you can see how those map out to predicted values (exp(beta0 +
beta1 parasitoids + btree)

>
> So it says that the
> between?tree variability is fairly large. But I don?t understand to what it
> relates. Does it mean that pollinator offspring variance is high between
> trees and might be overestimating the explanatory variables?
>
>
>
> 2. What can I
> conclude from the model regarding the fixed effects and how to report about it
> (with or without p-values, z-values, estimates)?
>
>
>
> So of what I know is that
> the p-value is only a guide and that it is rather a comparison of two models.
> What are the two models and can I compare them.
>
>
I am puzzled why you see p values at all. In the version of lme4 I'm
running now, I don't see p values.

Lets compare versions, since I'm pretty sure p values were removed
quite a while ago.

> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-8   Matrix_1.2-2

loaded via a namespace (and not attached):
[1] grid_3.1.2      lattice_0.20-33 MASS_7.3-43     minqa_1.2.4
[5] nlme_3.1-121    nloptr_1.0.4    Rcpp_0.12.0     splines_3.1.2
[9] tools_3.1.2

Anyway...

If you had a huge sample, those p values would be accurate.

You have a small sample, there are other, more computationally
intensive ways, to get p values.  Read the Jrnl Stat Software paper b
y the lmer team, they describe profiling and bootstrapping. You have
small enough sample, could do either one.

>
> 4. What does the
> correlation of fixed effects tells me?
>
It is a hint about multicollinearity & numerical instability, so far as I know.

>
>
> 5. Is it right
> that the estimates tells me whether the relation of the fixed effects to
> pollinator offspring is positive or negative?
>
>
Best way to get answer is to plot the predicted values from the model.
Use the predict function to plot for various values of the predictor.

>
> 6. Can I
> calculate an effect size on each explanatory variable?
>
Only if you think the term "effect size" is meaningful.  And if you
have a formula for one.  In my experience with consulting here, it
means anything the researcher wants to call a summary number.

I've come to loathe the term because somebody in the US Dept. of
Education mandated all studies report standardized effect sizes,
forcing everybody to make Herculean assumptions about all kinds of
model parameters to get Cohen's D or whatnot.

>
>
> I would highly appreciate your feedback on this.
> Thanks so much in advance.
>
Good luck.  Next time, use a text only email composer and try to ask 1
specific question. You are more likely to get attention if people can
easily read the message and see what you want.  This one was difficult
to read (for me at least) and also somewhat vague.

>
>
> Best wishes,
>
> Yvonne Hiller
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From pauljohn32 at gmail.com  Sat Aug  1 16:16:15 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 1 Aug 2015 09:16:15 -0500
Subject: [R-sig-ME] Calculation of random effects for factors in R
In-Reply-To: <A0BEC8B4FD089747956D1ACE2E85D0F403DACEAF@BHEXMBX2.livad.liv.ac.uk>
References: <A0BEC8B4FD089747956D1ACE2E85D0F403DACEAF@BHEXMBX2.livad.liv.ac.uk>
Message-ID: <CAErODj_ca7H8nZ2JWT8h8MTCZMBHKe2WAoy10_xzuvz350zHEg@mail.gmail.com>

On Tue, Jul 28, 2015 at 9:01 AM, Sudell, Maria [mesudell]
<M.E.Sudell at liverpool.ac.uk> wrote:
> Hello,
> I have a question concerning exactly how random effects for a factor are calculated in R.  I have tried to find an answer on various R related websites and text books but cannot find a definitive explanation.
>
> As an example, if you had a longitudinal dataset, and you wanted to include an individual specific random effect for a smoking factor (say 3 levels, current, ex, never), how would the random effects be calculated using R?  (I understand how to code this in R, I am aiming to understand the mechanics of how the function gets to the random effects).
>
I'm putting together class notes on this, but they are not quite
ready, or else I would give them to you.

The Pinheiro & Bates book (2000) is the classic statement on this.
There is a newer article that the lme4 team prepared for JSS will
answer this for you.  Those are technically demanding.  I have found
there are easier-to read interpretations of this in the Gelman & Hill
2007 book and in Ben Bolker's book Ecological Models and Data in R.

The approach is penalized maximum likelihood, in which the random
effects are conceptualized as coefficients on a random effects design
matrix.   I did not realize how difficult this was to explain until I
tried with some students. If you bang your head on a few of these
books for a while, get the 2006 book by Simon Wood on generalized
additive models. On the way to GAMs, he's got about the most beautiful
explanation of how these models are estimated that you will ever find.
  That's technically challenging, but I've never seen the structure
laid out so beautifully.

> My understanding so far would be that indicator variables for each of the levels of the factor would be included (in this case 3 indicator variables of 0,1, one for each of current, ex, never).  Then coefficients for the indicator variables would be found (so for each individual in the dataset, we would end up with a coefficient for one of the indicator variables, assuming that individuals can't be in more than one group).  These random coefficients (one for each individual as each individual would only fall into one smoking status) would then have their mean and variation calculated, in order to report the distribution of the random effect.  Is this correct?
>
Not exactly.  The estimate of the variance of the random effect is a
parameter estimate, and so far as I can tell, it is not ever linked or
even compared against the estimates of the individual case random
effects. That's an interesting question, though.  Until you asked, I
had not thought much about it.  I've never run ranef() to get the
individual random effect estimates and calculated their variance.

Theoretically, we know the estimated random effects are a blend of the
estimates you would get if you treated each subgroup in isolation and
the estimate you get if you pool all of the data.  And the sample size
within each group determines how much weight is placed on the
subgroup-specific estimate.

Since those estimates of the b's are shrunken in that way, their
variance won't necessarily coincide with the variance number at the
top of the lmer output.

Anyway, I've been reading the papers by Doug Bates and now the larger
lme4 team and they explain all this thoroughly.

> Apologies for such a simple question.  Any help or explanation (or point to relevant paper or textbook) of how random effects are calculated for factors in R would be greatly appreciated.
> Many thanks
> Maria
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From pauljohn32 at gmail.com  Sat Aug  1 16:26:57 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 1 Aug 2015 09:26:57 -0500
Subject: [R-sig-ME] Model with variable number of arguments
In-Reply-To: <1438263247.13557.91.camel@physik.uni-freiburg.de>
References: <1438263247.13557.91.camel@physik.uni-freiburg.de>
Message-ID: <CAErODj9piXRPxzaufD--xnfcjzf5ysQAk+arOo=SDrq089nc1A@mail.gmail.com>

On Thu, Jul 30, 2015 at 8:34 AM, Daniel Kaschek
<daniel.kaschek at physik.uni-freiburg.de> wrote:
> Dear all,
>
> I have the following model:
>
> y_ij = x_i/s_j + (eps_ij)/s_j
>
> where y_ij are the responses, x_i and s_j are the fixed effects and the
> random effects follow a normal distribution
>
1.  x_i and s_j are observed variables or parameters you need to
estimate?  Why you have no betas?

2. the formulation using division is unfamiliar to me, but when you
get to this part

> eps_ij ~ N(0, sigma0^2 + x_i^2 * sigmaR^2)
>

Can't answer because I can't tell if x_i is observed or not.  If it is
not, I don't know that lme4 will help.

How did eps get this way in the first place.  It appears it might be
the sum of 2 separate random effects. If that's right, you are getting
closer to the sort of model I would understand

It makes me wonder why you don't have s_j inside the variance term
there,, or why you don't have both x_ and s_ outside.

Its pretty tough to read email with lots of x_i and such.  That part
is bad about plain text mailing lists

> with error parameters sigma0 and sigmaR. In the end, I am interested in
> the parameters x_i, s_j, sigma0 and sigmaR.
>
> First of all, is lme4 the right package to solve this problem? When
> looking at nlmer(), I had problems to figure out what would be the
> correct structure of the function in the middle of the 3-part-formula.
>
> Any help is appreciated.
>
> Thanks a lot in advance,
> Daniel
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science        Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org              http://crmda.ku.edu


From bates at stat.wisc.edu  Sat Aug  1 18:27:01 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 01 Aug 2015 16:27:01 +0000
Subject: [R-sig-ME] Calculation of random effects for factors in R
In-Reply-To: <CAErODj_ca7H8nZ2JWT8h8MTCZMBHKe2WAoy10_xzuvz350zHEg@mail.gmail.com>
References: <A0BEC8B4FD089747956D1ACE2E85D0F403DACEAF@BHEXMBX2.livad.liv.ac.uk>
	<CAErODj_ca7H8nZ2JWT8h8MTCZMBHKe2WAoy10_xzuvz350zHEg@mail.gmail.com>
Message-ID: <CAO7JsnRFdCQ0gtSqUCKHVPaVN7HKHx=UndsPO-AEzE=vcR8QAw@mail.gmail.com>

On Sat, Aug 1, 2015 at 9:17 AM Paul Johnson <pauljohn32 at gmail.com> wrote:

> On Tue, Jul 28, 2015 at 9:01 AM, Sudell, Maria [mesudell]
> <M.E.Sudell at liverpool.ac.uk> wrote:
> > Hello,
> > I have a question concerning exactly how random effects for a factor are
> calculated in R.  I have tried to find an answer on various R related
> websites and text books but cannot find a definitive explanation.
> >
> > As an example, if you had a longitudinal dataset, and you wanted to
> include an individual specific random effect for a smoking factor (say 3
> levels, current, ex, never), how would the random effects be calculated
> using R?  (I understand how to code this in R, I am aiming to understand
> the mechanics of how the function gets to the random effects).
> >
> I'm putting together class notes on this, but they are not quite
> ready, or else I would give them to you.
>
> The Pinheiro & Bates book (2000) is the classic statement on this.
> There is a newer article that the lme4 team prepared for JSS will
> answer this for you.  Those are technically demanding.  I have found
> there are easier-to read interpretations of this in the Gelman & Hill
> 2007 book and in Ben Bolker's book Ecological Models and Data in R.
>
> The approach is penalized maximum likelihood, in which the random
> effects are conceptualized as coefficients on a random effects design
> matrix.   I did not realize how difficult this was to explain until I
> tried with some students. If you bang your head on a few of these
> books for a while, get the 2006 book by Simon Wood on generalized
> additive models. On the way to GAMs, he's got about the most beautiful
>  explanation of how these models are estimated that you will ever find.
> That's technically challenging, but I've never seen the structure laid out
> so beautifully.


I would not use the phrase "penalized maximum likelihood".  The evaluation
of the likelihood is done by solving a penalized least squares problem.  It
is this that makes it possible to fit models with a large number of
fixed-effects coefficients reasonably quickly because the fixed-effects
coefficients, and one of the variance parameters, can be "profiled out" of
the optimization problem.  This doesn't change the definition of the
maximum likelihood estimates, it simply makes them easier to evaluate.

In general I find that definitions of "<whatever> maximum likelihood"
estimators shouldn't be given those names.  The beauty of maximum
likelihood estimation is that the definition of the likelihood criterion is
so simple.  One you describe the probability model for the responses as a
function of the parameter values you use the same expression as the
probability density or probability mass function but regarded as a function
of the parameters with the responses fixed at the observed values.  There
are no optional flavors or "mix-ins" as at an ice-cream store.  Once you
have defined the probability model there is only one way to define the
likelihood.  The values of the parameters that maximize the likelihood are
the maximum likelihood estimates.

I do not try to hide the fact that I am a recovering mathematician (it's
been over thirty years since I have been tempted to prove a theorem but we
must remain vigilant) and I am very literal about the definitions of terms
in mathematics or mathematical statistics.  Given a probability model there
is only one likelihood function.  We can manipulate and re-express it to
make computation easier; for example, we typically optimize the
log-likelihood because it is more amenable to most optimization algorithms,
but we can do so because the values of the parameters that optimize the
log-likelihood are the same as those that optimize the likelihood.

 My understanding so far would be that indicator variables for each of the
> levels of the factor would be included (in this case 3 indicator variables
> of 0,1, one for each of current, ex, never).  Then coefficients for the
> indicator variables would be found (so for each individual in the dataset,
> we would end up with a coefficient for one of the indicator variables,
> assuming that individuals can't be in more than one group).  These random
> coefficients (one for each individual as each individual would only fall
> into one smoking status) would then have their mean and variation
> calculated, in order to report the distribution of the random effect.  Is
> this correct?
> >
> Not exactly.  The estimate of the variance of the random effect is a
> parameter estimate, and so far as I can tell, it is not ever linked or
> even compared against the estimates of the individual case random
> effects. That's an interesting question, though.  Until you asked, I
> had not thought much about it.  I've never run ranef() to get the
> individual random effect estimates and calculated their variance.
>

On the surface it is entirely reasonable to expect the observed
variance-covariance of the BLUP's to be similar to the estimate of the
parameters. But when you look deeper you discover that those two quantities
are from different distributions and there is no good reason to expect that
they should be similar.

I prefer the term "conditional means", in the case of linear mixed models
(LMMs), or "conditional modes", for GLMMs or NLMMs, because, well, that's
what they are.  Other than having a cute acronym the phrase "best linear
unbiased predictor" does not, to me at least, describe what these things
are.  If I say I want the values that maximize the conditional density of
the random effects, given the observed data and with the parameters set to
their maximum likelihood estimates, I have defined these values in a
meaningful way and it is natural to call them the "conditional modes".  It
happens that in a Gaussian linear mixed model all the distributions being
considered are themselves multivariate Gaussian and hence the conditional
modes are also the conditional means.

The covariance parameters being estimated are from the variance-covariance
matrix of the unconditional distribution of the random effects. There is no
reason to expect them to correspond to the variance-covariance of the
conditional modes or means.

If you want to make an analogy to Bayesian inference, the parameters being
estimated define the prior distribution and the conditional means are from
the posterior distribution.

Sorry for going on at such length.  I hope this is, to some at least, more
illuminating than confusing.

Theoretically, we know the estimated random effects are a blend of the
> estimates you would get if you treated each subgroup in isolation and
> the estimate you get if you pool all of the data.  And the sample size
> within each group determines how much weight is placed on the
> subgroup-specific estimate.
>
> Since those estimates of the b's are shrunken in that way, their
> variance won't necessarily coincide with the variance number at the
> top of the lmer output.
>
> Anyway, I've been reading the papers by Doug Bates and now the larger
> lme4 team and they explain all this thoroughly.
>
> > Apologies for such a simple question.  Any help or explanation (or point
> to relevant paper or textbook) of how random effects are calculated for
> factors in R would be greatly appreciated.
> > Many thanks
> > Maria
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science        Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org              http://crmda.ku.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sun Aug  2 00:08:35 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 2 Aug 2015 00:08:35 +0200
Subject: [R-sig-ME] Interpretation of GLMM output in R
In-Reply-To: <CAErODj_XdLLOqJM_SuhinCYjUOqx667whKS3g5_uzGDrxeCm5w@mail.gmail.com>
References: <DUB119-W22109F11D44DFB8D916C5928A0@phx.gbl>
	<CAErODj_XdLLOqJM_SuhinCYjUOqx667whKS3g5_uzGDrxeCm5w@mail.gmail.com>
Message-ID: <CAJuCY5zCXd+tvdFTy_EQSq=jxTyQKG_T+rbeLsPjmWjQuDNOQg@mail.gmail.com>

Paul,

Note that exp(beta0 + beta1*parasitoids + btree) is equivalent to exp(beta0
+ beta1*parasitoids)*exp(btree). So the relative effect of tree doesn't
depend on the other effects.

I tend to look at the ratio of the 97.5% and 2.5% quantiles of the random
effect. exp(q*sigma)/exp(-q*sigma) or simplified exp(2*q*sigma) with q
=1.96 (97.5% quantile of a normal distribution) and sigma= the standard
deviation of the random effect. exp(2*1.96*0.3261) ~ 3.5 So the 97.5%
quantile tree has about 3.5 times the number of pollinators of the 2.5%
quantile tree.

Best regards,

Thierry
Op 1-aug.-2015 15:43 schreef "Paul Johnson" <pauljohn32 at gmail.com>:

> Hi
>
> Your message comes through with weird line breaks, you should turn off
> the HTML compose option in your mail program, just write text.
>
> On Fri, Jul 31, 2015 at 8:42 AM, Yvonne Hiller <yvonne.hiller at hotmail.de>
> wrote:
> >
> >
> >
> >
> > Dear Ben Bolker and list members,
> >
> >
> >
> > I?am a PhD-student working on tropical plant-pollinator
> > interactions (the fig-fig wasp mutualism).
> >
> > I have some difficulties with my analyses of my data
> > using lmer (family = Poisson). I have read a lot of threads and searched
> for
> > solutions in Zuur 2009, though it was not completely satisfying. I
> looked at
> > other papers using GLMM (espeacially for the fig-fig wasp mutualism),
> but there
> > were so many different ways in reporting and interpreting p-values, AICs
> etc.
> > Therefore, I would be very grateful, if you could go through my output
> and
> > answer my questions to hopefully fully understand GLMM. Thank you so
> much in
> > advance.
> >
> >
> >
> > One of my questions is:
> >
> > Have parasitoids (offspring) and the volume size an
> > effect on the number of pollinator offspring?
> >
> >
> >
> > As pollinators are parasitized by parasitoids, I would
> > expect a negative impact on pollinator offspring. As the size of the fig
> fruits
> > might be an additionally factor (due to limited oviposition sites inside
> the fruit
> > or due to the ovipositor length of a parasitoid is to short to reach
> inner most
> > ovules galled by pollinators), I included it in the model.
> >
> >
> >
> > I have poisson data (counts):
> >
> >
> >
> > Pollinator
> > = pollinator offspring
> >
> > Parasitoids = parasitoid offspring
> >
> > volume = fig fruit size measurement
> >
> > tree = Tree ID
> >
> >
> >
> > I have data from trees in the forest and in the
> > farmland, as well as data of the rainy and dry season. I have chosen to
> perform
> > lmer for each season and habitat separately. For each tree, I have
> collected 10
> > fig fruits to count offspring of wasps at the trophic level (pollinator,
> > parasitoid) and to measure the size of the fruit (volume). As I have 10
> fig
> > fruits per tree, I would use tree as a random effect, to account for
> unmeasured
> > variance between trees. I have found different approaches to that in
> > literature. For instance: We did not include? tree ? and ?
> > syconium ? as random factors, because wasps were free to move between
> syconia
> > on the same tree, and between trees.
> >
> > Therefore,
> > I am not sure if I have to use GLMM with trees as a random effect or if
> it?s
> > also possible to use GLM without the random effect.
> >
> >
> >
> > The inclusion of
> > fig volume in this manner removed the need to use ?fig? as an additional
> nested
> > factor within ?tree?. Is that right?
> >
> >
> >
> > Here, I
> > present the model with the random effect.
> >
> > So, lets start with the model of the farmland during
> > the dry season:
> >
> >
> >
> > fad <-
> lmer(Pollinator~Parasitoids+volume+(1|tree),family="poisson",verbose=TRUE)
> >
> >
> >
> > summary (fad)
> >
> > Generalized linear mixed model fit by the Laplace
> > approximation
> >
> > Formula: Pollinator ~ Parasitoids + volume + (1 |
> > tree)
> >
> >    Data:
> > fad.data
> >
> >   AIC  BIC logLik deviance
> >
> >  1166 1175
> > -578.9     1158
> >
> > Random effects:
> >
> >  Groups
> > Name        Variance Std.Dev.
> >
> >  tree   (Intercept) 0.10634  0.3261
> >
> >
> > Number of obs: 80, groups: tree, 8
> >
> >
> >
> > Fixed effects:
> >
> >
> > Estimate Std. Error z value Pr(>|z|)
> >
> > (Intercept)
> > 2.3167867  0.1632747  14.190
> > <2e-16 ***
> >
> > Parasitoids -0.0046908
> > 0.0021686  -2.163   0.0305 *
> >
> >
> > volume
> > 0.0069525  0.0006108  11.383
> > <2e-16 ***
> >
> > ---
> >
> > Signif.
> > codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
> > ?.? 0.1 ? ? 1
> >
> >
> >
> > Correlation of Fixed Effects:
> >
> >
> > (Intr) Prstds
> >
> > Parasitoids -0.160
> >
> > volume
> > -0.657 -0.107
> >
> >
> >
> > 1. Random effects: What does the Random
> > Effect table - the Variance, Std. Dev. and Intercept tells me?
> >
> >
> Your model assumes that the outcome is Poisson with expected value
> exp(beta0 + beta1*parasitoids + btree)
>
> btree is a unique added amount for each tree.  The estimate of the
> number btree's variance across trees is 0.1.
>
> What that 0.1 means in terms of the predicted outcome?  Well, that
> mostly depends on how big beta0 + beta1*parasitoids is.  If that
> number is huge, say 1000, then adding a thing with variance 0.1 won't
> matter much.
>
> On the other hand, if it is 0.01, then the random effect at the tree
> level is very large, compared to the systematic components in your
> model.  When the link function gets applied, the distribution of
> outcomes changes in an interesting way.
>
> If you run ranef(), it will spit out the estimates of the random
> differences among trees (btree "BLUPS").  If you run the predict
> method, you can see how those map out to predicted values (exp(beta0 +
> beta1 parasitoids + btree)
>
> >
> > So it says that the
> > between?tree variability is fairly large. But I don?t understand to what
> it
> > relates. Does it mean that pollinator offspring variance is high between
> > trees and might be overestimating the explanatory variables?
> >
> >
> >
> > 2. What can I
> > conclude from the model regarding the fixed effects and how to report
> about it
> > (with or without p-values, z-values, estimates)?
> >
> >
> >
> > So of what I know is that
> > the p-value is only a guide and that it is rather a comparison of two
> models.
> > What are the two models and can I compare them.
> >
> >
> I am puzzled why you see p values at all. In the version of lme4 I'm
> running now, I don't see p values.
>
> Lets compare versions, since I'm pretty sure p values were removed
> quite a while ago.
>
> > sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_1.1-8   Matrix_1.2-2
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.2      lattice_0.20-33 MASS_7.3-43     minqa_1.2.4
> [5] nlme_3.1-121    nloptr_1.0.4    Rcpp_0.12.0     splines_3.1.2
> [9] tools_3.1.2
>
> Anyway...
>
> If you had a huge sample, those p values would be accurate.
>
> You have a small sample, there are other, more computationally
> intensive ways, to get p values.  Read the Jrnl Stat Software paper b
> y the lmer team, they describe profiling and bootstrapping. You have
> small enough sample, could do either one.
>
> >
> > 4. What does the
> > correlation of fixed effects tells me?
> >
> It is a hint about multicollinearity & numerical instability, so far as I
> know.
>
> >
> >
> > 5. Is it right
> > that the estimates tells me whether the relation of the fixed effects to
> > pollinator offspring is positive or negative?
> >
> >
> Best way to get answer is to plot the predicted values from the model.
> Use the predict function to plot for various values of the predictor.
>
> >
> > 6. Can I
> > calculate an effect size on each explanatory variable?
> >
> Only if you think the term "effect size" is meaningful.  And if you
> have a formula for one.  In my experience with consulting here, it
> means anything the researcher wants to call a summary number.
>
> I've come to loathe the term because somebody in the US Dept. of
> Education mandated all studies report standardized effect sizes,
> forcing everybody to make Herculean assumptions about all kinds of
> model parameters to get Cohen's D or whatnot.
>
> >
> >
> > I would highly appreciate your feedback on this.
> > Thanks so much in advance.
> >
> Good luck.  Next time, use a text only email composer and try to ask 1
> specific question. You are more likely to get attention if people can
> easily read the message and see what you want.  This one was difficult
> to read (for me at least) and also somewhat vague.
>
> >
> >
> > Best wishes,
> >
> > Yvonne Hiller
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science        Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org              http://crmda.ku.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From yvonne.hiller at hotmail.de  Sun Aug  2 11:31:15 2015
From: yvonne.hiller at hotmail.de (Yvonne Hiller)
Date: Sun, 2 Aug 2015 11:31:15 +0200
Subject: [R-sig-ME] Interpretation of GLMM output in R
In-Reply-To: <CAJuCY5zCXd+tvdFTy_EQSq=jxTyQKG_T+rbeLsPjmWjQuDNOQg@mail.gmail.com>
References: <DUB119-W22109F11D44DFB8D916C5928A0@phx.gbl>,
	<CAErODj_XdLLOqJM_SuhinCYjUOqx667whKS3g5_uzGDrxeCm5w@mail.gmail.com>,
	<CAJuCY5zCXd+tvdFTy_EQSq=jxTyQKG_T+rbeLsPjmWjQuDNOQg@mail.gmail.com>
Message-ID: <DUB119-W5194A05C2CB27F904EBA4692880@phx.gbl>

Dear Paul, Thierry and list members,
first of all: 
Thanks so much for going through my questions, although it came in an
inappropriate look with wired brackets and? unspecified questions. Apologies for that. So I
try again to specify things.

The model includes following variables:
Pollinator = pollinator offspring
Parasitoids = parasitoid offspring
Volume = measured fig size 
tree? = tree ID

This is the output of the model:

?fad <-glmer(Pollinator~Parasitoids+volume+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
?Family: poisson? ( log )
Formula: Pollinator ~ Parasitoids + volume + (1 | tree)
?? Data: fad.data

???? AIC????? BIC?? logLik deviance df.resid 
? 1550.6?? 1560.2?? -771.3?? 1542.6?????? 76 

Scaled residuals: 
??? Min????? 1Q? Median????? 3Q???? Max 
-7.4825 -2.4111 -0.4725? 2.4321? 9.3409 

Random effects:
?Groups Name??????? Variance Std.Dev.
?tree?? (Intercept) 0.1063?? 0.3261? 
Number of obs: 80, groups:? tree, 8

Fixed effects:
????????????? Estimate Std. Error z value Pr(>|z|)??? 
(Intercept)? 2.3167832? 0.1634876? 14.171?? <2e-16 ***
Parasitoids -0.0046908? 0.0022169? -2.116?? 0.0344 *? 
volume?????? 0.0069527? 0.0006197? 11.220?? <2e-16 ***
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
??????????? (Intr) Prstds
Parasitoids -0.144?????? 
volume????? -0.656 -0.139

1. I want to know if the predictor variables have an effect on pollinator
offspring. Therefore, I tested if? ?Parasitoids? and? ?volume? are important factors in the model by the LRT.

fad1 <- glmer(Pollinator~1+volume+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
fad2 <- glmer(Pollinator~Parasitoids+1+(1|tree),data=fad.data,family="poisson",verbose=TRUE)

anova(fad,fad1)
Models:
fad1: Pollinator ~ 1 + volume + (1 | tree)
fad: Pollinator ~ Parasitoids + volume + (1 | tree)
???? Df??? AIC??? BIC? logLik deviance? Chisq Chi Df Pr(>Chisq)? 
fad1? 3 1553.1 1560.3 -773.57?? 1547.1?????????????????????????? 
fad?? 4 1550.6 1560.2 -771.32?? 1542.6 4.5105????? 1??? 0.03369 *
anova(fad,fad2)
Models:
fad2: Pollinator ~ Parasitoids + 1 + (1 | tree)
fad: Pollinator ~ Parasitoids + volume + (1 | tree)
???? Df??? AIC??? BIC? logLik deviance? Chisq Chi Df Pr(>Chisq)??? 
fad2? 3 1669.2 1676.4 -831.61?? 1663.2???????????????????????????? 
fad?? 4 1550.6 1560.2 -771.32?? 1542.6 120.59????? 1? < 2.2e-16 ***
>From the output, I conclude that both predictor variables have an effect on pollinator offspring. Is it reasonable to do the LRT for testing the predictor variables? Is there any chance to get an effect size of how much the predictor variables explain variance in the response variable? Since I know they have an effect, interpreation would be different when the effect of one variable is small or large. 

2. From suggestions of Thierry and Paul and from the the caterpillar plot:
dotplot(ranef(fad, condVar=TRUE))$tree
I do understand that there is indeed a fairly large remaining variability in the number of pollinator offspring? among trees, but
the relative effect of ?tree? does not depend on ?Parasitoids? and ?volume?. 
Again, I would highly appreciate your suggestions and feedback on this. Thank you very much in advance.
Best wishes,Yvonne

________________________________
> Date: Sun, 2 Aug 2015 00:08:35 +0200 
> Subject: Re: [R-sig-ME] Interpretation of GLMM output in R 
> From: thierry.onkelinx at inbo.be 
> To: pauljohn32 at gmail.com 
> CC: yvonne.hiller at hotmail.de; r-sig-mixed-models at r-project.org 
>  
>  
> Paul, 
>  
> Note that exp(beta0 + beta1*parasitoids + btree) is equivalent to  
> exp(beta0 + beta1*parasitoids)*exp(btree). So the relative effect of  
> tree doesn't depend on the other effects. 
>  
> I tend to look at the ratio of the 97.5% and 2.5% quantiles of the  
> random effect. exp(q*sigma)/exp(-q*sigma) or simplified exp(2*q*sigma)  
> with q =1.96 (97.5% quantile of a normal distribution) and sigma= the  
> standard deviation of the random effect. exp(2*1.96*0.3261) ~ 3.5 So  
> the 97.5% quantile tree has about 3.5 times the number of pollinators  
> of the 2.5% quantile tree. 
>  
> Best regards, 
>  
> Thierry 
>  
> Op 1-aug.-2015 15:43 schreef "Paul Johnson"  
> <pauljohn32 at gmail.com<mailto:pauljohn32 at gmail.com>>: 
> Hi 
>  
> Your message comes through with weird line breaks, you should turn off 
> the HTML compose option in your mail program, just write text. 
>  
> On Fri, Jul 31, 2015 at 8:42 AM, Yvonne Hiller  
> <yvonne.hiller at hotmail.de<mailto:yvonne.hiller at hotmail.de>> wrote: 
> > 
> > 
> > 
> > 
> > Dear Ben Bolker and list members, 
> > 
> > 
> > 
> > I?am a PhD-student working on tropical plant-pollinator 
> > interactions (the fig-fig wasp mutualism). 
> > 
> > I have some difficulties with my analyses of my data 
> > using lmer (family = Poisson). I have read a lot of threads and  
> searched for 
> > solutions in Zuur 2009, though it was not completely satisfying. I  
> looked at 
> > other papers using GLMM (espeacially for the fig-fig wasp mutualism),  
> but there 
> > were so many different ways in reporting and interpreting p-values,  
> AICs etc. 
> > Therefore, I would be very grateful, if you could go through my output and 
> > answer my questions to hopefully fully understand GLMM. Thank you so  
> much in 
> > advance. 
> > 
> > 
> > 
> > One of my questions is: 
> > 
> > Have parasitoids (offspring) and the volume size an 
> > effect on the number of pollinator offspring? 
> > 
> > 
> > 
> > As pollinators are parasitized by parasitoids, I would 
> > expect a negative impact on pollinator offspring. As the size of the  
> fig fruits 
> > might be an additionally factor (due to limited oviposition sites  
> inside the fruit 
> > or due to the ovipositor length of a parasitoid is to short to reach  
> inner most 
> > ovules galled by pollinators), I included it in the model. 
> > 
> > 
> > 
> > I have poisson data (counts): 
> > 
> > 
> > 
> > Pollinator 
> > = pollinator offspring 
> > 
> > Parasitoids = parasitoid offspring 
> > 
> > volume = fig fruit size measurement 
> > 
> > tree = Tree ID 
> > 
> > 
> > 
> > I have data from trees in the forest and in the 
> > farmland, as well as data of the rainy and dry season. I have chosen  
> to perform 
> > lmer for each season and habitat separately. For each tree, I have  
> collected 10 
> > fig fruits to count offspring of wasps at the trophic level (pollinator, 
> > parasitoid) and to measure the size of the fruit (volume). As I have 10 fig 
> > fruits per tree, I would use tree as a random effect, to account for  
> unmeasured 
> > variance between trees. I have found different approaches to that in 
> > literature. For instance: We did not include? tree ? and ? 
> > syconium ? as random factors, because wasps were free to move between  
> syconia 
> > on the same tree, and between trees. 
> > 
> > Therefore, 
> > I am not sure if I have to use GLMM with trees as a random effect or  
> if it?s 
> > also possible to use GLM without the random effect. 
> > 
> > 
> > 
> > The inclusion of 
> > fig volume in this manner removed the need to use ?fig? as an  
> additional nested 
> > factor within ?tree?. Is that right? 
> > 
> > 
> > 
> > Here, I 
> > present the model with the random effect. 
> > 
> > So, lets start with the model of the farmland during 
> > the dry season: 
> > 
> > 
> > 
> > fad <-  
> lmer(Pollinator~Parasitoids+volume+(1|tree),family="poisson",verbose=TRUE) 
> > 
> > 
> > 
> > summary (fad) 
> > 
> > Generalized linear mixed model fit by the Laplace 
> > approximation 
> > 
> > Formula: Pollinator ~ Parasitoids + volume + (1 | 
> > tree) 
> > 
> >    Data: 
> > fad.data 
> > 
> >   AIC  BIC logLik deviance 
> > 
> >  1166 1175 
> > -578.9     1158 
> > 
> > Random effects: 
> > 
> >  Groups 
> > Name        Variance Std.Dev. 
> > 
> >  tree   (Intercept) 0.10634  0.3261 
> > 
> > 
> > Number of obs: 80, groups: tree, 8 
> > 
> > 
> > 
> > Fixed effects: 
> > 
> > 
> > Estimate Std. Error z value Pr(>|z|) 
> > 
> > (Intercept) 
> > 2.3167867  0.1632747  14.190 
> > <2e-16 *** 
> > 
> > Parasitoids -0.0046908 
> > 0.0021686  -2.163   0.0305 * 
> > 
> > 
> > volume 
> > 0.0069525  0.0006108  11.383 
> > <2e-16 *** 
> > 
> > --- 
> > 
> > Signif. 
> > codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 
> > ?.? 0.1 ? ? 1 
> > 
> > 
> > 
> > Correlation of Fixed Effects: 
> > 
> > 
> > (Intr) Prstds 
> > 
> > Parasitoids -0.160 
> > 
> > volume 
> > -0.657 -0.107 
> > 
> > 
> > 
> > 1. Random effects: What does the Random 
> > Effect table - the Variance, Std. Dev. and Intercept tells me? 
> > 
> > 
> Your model assumes that the outcome is Poisson with expected value 
> exp(beta0 + beta1*parasitoids + btree) 
>  
> btree is a unique added amount for each tree.  The estimate of the 
> number btree's variance across trees is 0.1. 
>  
> What that 0.1 means in terms of the predicted outcome?  Well, that 
> mostly depends on how big beta0 + beta1*parasitoids is.  If that 
> number is huge, say 1000, then adding a thing with variance 0.1 won't 
> matter much. 
>  
> On the other hand, if it is 0.01, then the random effect at the tree 
> level is very large, compared to the systematic components in your 
> model.  When the link function gets applied, the distribution of 
> outcomes changes in an interesting way. 
>  
> If you run ranef(), it will spit out the estimates of the random 
> differences among trees (btree "BLUPS").  If you run the predict 
> method, you can see how those map out to predicted values (exp(beta0 + 
> beta1 parasitoids + btree) 
>  
> > 
> > So it says that the 
> > between?tree variability is fairly large. But I don?t understand to what it 
> > relates. Does it mean that pollinator offspring variance is high between 
> > trees and might be overestimating the explanatory variables? 
> > 
> > 
> > 
> > 2. What can I 
> > conclude from the model regarding the fixed effects and how to report  
> about it 
> > (with or without p-values, z-values, estimates)? 
> > 
> > 
> > 
> > So of what I know is that 
> > the p-value is only a guide and that it is rather a comparison of two  
> models. 
> > What are the two models and can I compare them. 
> > 
> > 
> I am puzzled why you see p values at all. In the version of lme4 I'm 
> running now, I don't see p values. 
>  
> Lets compare versions, since I'm pretty sure p values were removed 
> quite a while ago. 
>  
> > sessionInfo() 
> R version 3.1.2 (2014-10-31) 
> Platform: x86_64-pc-linux-gnu (64-bit) 
>  
> locale: 
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C 
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8 
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C 
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C 
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C 
>  
> attached base packages: 
> [1] stats     graphics  grDevices utils     datasets  methods   base 
>  
> other attached packages: 
> [1] lme4_1.1-8   Matrix_1.2-2 
>  
> loaded via a namespace (and not attached): 
> [1] grid_3.1.2      lattice_0.20-33 MASS_7.3-43     minqa_1.2.4 
> [5] nlme_3.1-121    nloptr_1.0.4    Rcpp_0.12.0     splines_3.1.2 
> [9] tools_3.1.2 
>  
> Anyway... 
>  
> If you had a huge sample, those p values would be accurate. 
>  
> You have a small sample, there are other, more computationally 
> intensive ways, to get p values.  Read the Jrnl Stat Software paper b 
> y the lmer team, they describe profiling and bootstrapping. You have 
> small enough sample, could do either one. 
>  
> > 
> > 4. What does the 
> > correlation of fixed effects tells me? 
> > 
> It is a hint about multicollinearity & numerical instability, so far as  
> I know. 
>  
> > 
> > 
> > 5. Is it right 
> > that the estimates tells me whether the relation of the fixed effects to 
> > pollinator offspring is positive or negative? 
> > 
> > 
> Best way to get answer is to plot the predicted values from the model. 
> Use the predict function to plot for various values of the predictor. 
>  
> > 
> > 6. Can I 
> > calculate an effect size on each explanatory variable? 
> > 
> Only if you think the term "effect size" is meaningful.  And if you 
> have a formula for one.  In my experience with consulting here, it 
> means anything the researcher wants to call a summary number. 
>  
> I've come to loathe the term because somebody in the US Dept. of 
> Education mandated all studies report standardized effect sizes, 
> forcing everybody to make Herculean assumptions about all kinds of 
> model parameters to get Cohen's D or whatnot. 
>  
> > 
> > 
> > I would highly appreciate your feedback on this. 
> > Thanks so much in advance. 
> > 
> Good luck.  Next time, use a text only email composer and try to ask 1 
> specific question. You are more likely to get attention if people can 
> easily read the message and see what you want.  This one was difficult 
> to read (for me at least) and also somewhat vague. 
>  
> > 
> > 
> > Best wishes, 
> > 
> > Yvonne Hiller 
> > 
> > 
> > 
> > 
> > 
> > 
> >         [[alternative HTML version deleted]] 
> > 
> > 
> > _______________________________________________ 
> >  
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>  
> mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
> > 
>  
>  
>  
> -- 
> Paul E. Johnson 
> Professor, Political Science        Director 
> 1541 Lilac Lane, Room 504      Center for Research Methods 
> University of Kansas                 University of Kansas 
> http://pj.freefaculty.org              http://crmda.ku.edu 
>  
> _______________________________________________ 
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>  
> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
 		 	   		  

From hughes.dupond at gmx.de  Sun Aug  2 13:34:47 2015
From: hughes.dupond at gmx.de (Lionel)
Date: Sun, 02 Aug 2015 13:34:47 +0200
Subject: [R-sig-ME] Interpretation of GLMM output in R
In-Reply-To: <DUB119-W5194A05C2CB27F904EBA4692880@phx.gbl>
References: <DUB119-W22109F11D44DFB8D916C5928A0@phx.gbl>,
	<CAErODj_XdLLOqJM_SuhinCYjUOqx667whKS3g5_uzGDrxeCm5w@mail.gmail.com>,
	<CAJuCY5zCXd+tvdFTy_EQSq=jxTyQKG_T+rbeLsPjmWjQuDNOQg@mail.gmail.com>
	<DUB119-W5194A05C2CB27F904EBA4692880@phx.gbl>
Message-ID: <55BE0057.8040401@gmx.de>

Dear Yvonne,

To answer Question 1, I would scale both predictors to unit standard 
deviation (ie fad.data$Volume_std<-scale(fad.data$Volume,scale=TRUE)) 
and then compare the back-transformed coefficients, as you have a 
Poisson model this would be then exp(fixef(fad)). Say that you get a 
value of 1.5 for the variable Volume, you would then interpret this as: 
an increase in one standard deviation of Volume leads to an increase of 
1.5*Pollinator, put differently every increase of one standard deviation 
in Volume increase Pollinator by 50%. Having scaled the predictor would 
also allow you to compare the strength of their effects. Also note that 
effect sizes do not give informations about how much variance in the 
response variable is explained by individuals terms.

Concerning the LRT to test the effect of predictors, it is not the best 
available option (see http://glmm.wikidot.com/faq#summary) the function 
"mixed" in the "afex" package allow you to do parametric bootstrap to 
test fixed effects (using type 2 or 3 tests). For effects with very 
small p-values (like volume) using LRT or parametric bootstrap will most 
certainly lead to the same interpretation (ie volume has a significant 
effect), for p-values close to 0.05 (like parasitoids) you might get 
different interpretations.

Sincerely yours,
Lionel

On 02/08/2015 11:31, Yvonne Hiller wrote:
> Dear Paul, Thierry and list members,
> first of all:
> Thanks so much for going through my questions, although it came in an
> inappropriate look with wired brackets and  unspecified questions. Apologies for that. So I
> try again to specify things.
>
> The model includes following variables:
> Pollinator = pollinator offspring
> Parasitoids = parasitoid offspring
> Volume = measured fig size
> tree  = tree ID
>
> This is the output of the model:
>
>   fad <-glmer(Pollinator~Parasitoids+volume+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>   Family: poisson  ( log )
> Formula: Pollinator ~ Parasitoids + volume + (1 | tree)
>     Data: fad.data
>
>       AIC      BIC   logLik deviance df.resid
>    1550.6   1560.2   -771.3   1542.6       76
>
> Scaled residuals:
>      Min      1Q  Median      3Q     Max
> -7.4825 -2.4111 -0.4725  2.4321  9.3409
>
> Random effects:
>   Groups Name        Variance Std.Dev.
>   tree   (Intercept) 0.1063   0.3261
> Number of obs: 80, groups:  tree, 8
>
> Fixed effects:
>                Estimate Std. Error z value Pr(>|z|)
> (Intercept)  2.3167832  0.1634876  14.171   <2e-16 ***
> Parasitoids -0.0046908  0.0022169  -2.116   0.0344 *
> volume       0.0069527  0.0006197  11.220   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>              (Intr) Prstds
> Parasitoids -0.144
> volume      -0.656 -0.139
>
> 1. I want to know if the predictor variables have an effect on pollinator
> offspring. Therefore, I tested if  ?Parasitoids? and  ?volume? are important factors in the model by the LRT.
>
> fad1 <- glmer(Pollinator~1+volume+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
> fad2 <- glmer(Pollinator~Parasitoids+1+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
>
> anova(fad,fad1)
> Models:
> fad1: Pollinator ~ 1 + volume + (1 | tree)
> fad: Pollinator ~ Parasitoids + volume + (1 | tree)
>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> fad1  3 1553.1 1560.3 -773.57   1547.1
> fad   4 1550.6 1560.2 -771.32   1542.6 4.5105      1    0.03369 *
> anova(fad,fad2)
> Models:
> fad2: Pollinator ~ Parasitoids + 1 + (1 | tree)
> fad: Pollinator ~ Parasitoids + volume + (1 | tree)
>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> fad2  3 1669.2 1676.4 -831.61   1663.2
> fad   4 1550.6 1560.2 -771.32   1542.6 120.59      1  < 2.2e-16 ***
> >From the output, I conclude that both predictor variables have an effect on pollinator offspring. Is it reasonable to do the LRT for testing the predictor variables? Is there any chance to get an effect size of how much the predictor variables explain variance in the response variable? Since I know they have an effect, interpreation would be different when the effect of one variable is small or large.
>
> 2. From suggestions of Thierry and Paul and from the the caterpillar plot:
> dotplot(ranef(fad, condVar=TRUE))$tree
> I do understand that there is indeed a fairly large remaining variability in the number of pollinator offspring  among trees, but
> the relative effect of ?tree? does not depend on ?Parasitoids? and ?volume?.
> Again, I would highly appreciate your suggestions and feedback on this. Thank you very much in advance.
> Best wishes,Yvonne
>
> ________________________________
>> Date: Sun, 2 Aug 2015 00:08:35 +0200
>> Subject: Re: [R-sig-ME] Interpretation of GLMM output in R
>> From: thierry.onkelinx at inbo.be
>> To: pauljohn32 at gmail.com
>> CC: yvonne.hiller at hotmail.de; r-sig-mixed-models at r-project.org
>>   
>>   
>> Paul,
>>   
>> Note that exp(beta0 + beta1*parasitoids + btree) is equivalent to
>> exp(beta0 + beta1*parasitoids)*exp(btree). So the relative effect of
>> tree doesn't depend on the other effects.
>>   
>> I tend to look at the ratio of the 97.5% and 2.5% quantiles of the
>> random effect. exp(q*sigma)/exp(-q*sigma) or simplified exp(2*q*sigma)
>> with q =1.96 (97.5% quantile of a normal distribution) and sigma= the
>> standard deviation of the random effect. exp(2*1.96*0.3261) ~ 3.5 So
>> the 97.5% quantile tree has about 3.5 times the number of pollinators
>> of the 2.5% quantile tree.
>>   
>> Best regards,
>>   
>> Thierry
>>   
>> Op 1-aug.-2015 15:43 schreef "Paul Johnson"
>> <pauljohn32 at gmail.com<mailto:pauljohn32 at gmail.com>>:
>> Hi
>>   
>> Your message comes through with weird line breaks, you should turn off
>> the HTML compose option in your mail program, just write text.
>>   
>> On Fri, Jul 31, 2015 at 8:42 AM, Yvonne Hiller
>> <yvonne.hiller at hotmail.de<mailto:yvonne.hiller at hotmail.de>> wrote:
>>>
>>>
>>>
>>> Dear Ben Bolker and list members,
>>>
>>>
>>>
>>> I?am a PhD-student working on tropical plant-pollinator
>>> interactions (the fig-fig wasp mutualism).
>>>
>>> I have some difficulties with my analyses of my data
>>> using lmer (family = Poisson). I have read a lot of threads and
>> searched for
>>> solutions in Zuur 2009, though it was not completely satisfying. I
>> looked at
>>> other papers using GLMM (espeacially for the fig-fig wasp mutualism),
>> but there
>>> were so many different ways in reporting and interpreting p-values,
>> AICs etc.
>>> Therefore, I would be very grateful, if you could go through my output and
>>> answer my questions to hopefully fully understand GLMM. Thank you so
>> much in
>>> advance.
>>>
>>>
>>>
>>> One of my questions is:
>>>
>>> Have parasitoids (offspring) and the volume size an
>>> effect on the number of pollinator offspring?
>>>
>>>
>>>
>>> As pollinators are parasitized by parasitoids, I would
>>> expect a negative impact on pollinator offspring. As the size of the
>> fig fruits
>>> might be an additionally factor (due to limited oviposition sites
>> inside the fruit
>>> or due to the ovipositor length of a parasitoid is to short to reach
>> inner most
>>> ovules galled by pollinators), I included it in the model.
>>>
>>>
>>>
>>> I have poisson data (counts):
>>>
>>>
>>>
>>> Pollinator
>>> = pollinator offspring
>>>
>>> Parasitoids = parasitoid offspring
>>>
>>> volume = fig fruit size measurement
>>>
>>> tree = Tree ID
>>>
>>>
>>>
>>> I have data from trees in the forest and in the
>>> farmland, as well as data of the rainy and dry season. I have chosen
>> to perform
>>> lmer for each season and habitat separately. For each tree, I have
>> collected 10
>>> fig fruits to count offspring of wasps at the trophic level (pollinator,
>>> parasitoid) and to measure the size of the fruit (volume). As I have 10 fig
>>> fruits per tree, I would use tree as a random effect, to account for
>> unmeasured
>>> variance between trees. I have found different approaches to that in
>>> literature. For instance: We did not include? tree ? and ?
>>> syconium ? as random factors, because wasps were free to move between
>> syconia
>>> on the same tree, and between trees.
>>>
>>> Therefore,
>>> I am not sure if I have to use GLMM with trees as a random effect or
>> if it?s
>>> also possible to use GLM without the random effect.
>>>
>>>
>>>
>>> The inclusion of
>>> fig volume in this manner removed the need to use ?fig? as an
>> additional nested
>>> factor within ?tree?. Is that right?
>>>
>>>
>>>
>>> Here, I
>>> present the model with the random effect.
>>>
>>> So, lets start with the model of the farmland during
>>> the dry season:
>>>
>>>
>>>
>>> fad <-
>> lmer(Pollinator~Parasitoids+volume+(1|tree),family="poisson",verbose=TRUE)
>>>
>>>
>>> summary (fad)
>>>
>>> Generalized linear mixed model fit by the Laplace
>>> approximation
>>>
>>> Formula: Pollinator ~ Parasitoids + volume + (1 |
>>> tree)
>>>
>>>     Data:
>>> fad.data
>>>
>>>    AIC  BIC logLik deviance
>>>
>>>   1166 1175
>>> -578.9     1158
>>>
>>> Random effects:
>>>
>>>   Groups
>>> Name        Variance Std.Dev.
>>>
>>>   tree   (Intercept) 0.10634  0.3261
>>>
>>>
>>> Number of obs: 80, groups: tree, 8
>>>
>>>
>>>
>>> Fixed effects:
>>>
>>>
>>> Estimate Std. Error z value Pr(>|z|)
>>>
>>> (Intercept)
>>> 2.3167867  0.1632747  14.190
>>> <2e-16 ***
>>>
>>> Parasitoids -0.0046908
>>> 0.0021686  -2.163   0.0305 *
>>>
>>>
>>> volume
>>> 0.0069525  0.0006108  11.383
>>> <2e-16 ***
>>>
>>> ---
>>>
>>> Signif.
>>> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>>> ?.? 0.1 ? ? 1
>>>
>>>
>>>
>>> Correlation of Fixed Effects:
>>>
>>>
>>> (Intr) Prstds
>>>
>>> Parasitoids -0.160
>>>
>>> volume
>>> -0.657 -0.107
>>>
>>>
>>>
>>> 1. Random effects: What does the Random
>>> Effect table - the Variance, Std. Dev. and Intercept tells me?
>>>
>>>
>> Your model assumes that the outcome is Poisson with expected value
>> exp(beta0 + beta1*parasitoids + btree)
>>   
>> btree is a unique added amount for each tree.  The estimate of the
>> number btree's variance across trees is 0.1.
>>   
>> What that 0.1 means in terms of the predicted outcome?  Well, that
>> mostly depends on how big beta0 + beta1*parasitoids is.  If that
>> number is huge, say 1000, then adding a thing with variance 0.1 won't
>> matter much.
>>   
>> On the other hand, if it is 0.01, then the random effect at the tree
>> level is very large, compared to the systematic components in your
>> model.  When the link function gets applied, the distribution of
>> outcomes changes in an interesting way.
>>   
>> If you run ranef(), it will spit out the estimates of the random
>> differences among trees (btree "BLUPS").  If you run the predict
>> method, you can see how those map out to predicted values (exp(beta0 +
>> beta1 parasitoids + btree)
>>   
>>> So it says that the
>>> between?tree variability is fairly large. But I don?t understand to what it
>>> relates. Does it mean that pollinator offspring variance is high between
>>> trees and might be overestimating the explanatory variables?
>>>
>>>
>>>
>>> 2. What can I
>>> conclude from the model regarding the fixed effects and how to report
>> about it
>>> (with or without p-values, z-values, estimates)?
>>>
>>>
>>>
>>> So of what I know is that
>>> the p-value is only a guide and that it is rather a comparison of two
>> models.
>>> What are the two models and can I compare them.
>>>
>>>
>> I am puzzled why you see p values at all. In the version of lme4 I'm
>> running now, I don't see p values.
>>   
>> Lets compare versions, since I'm pretty sure p values were removed
>> quite a while ago.
>>   
>>> sessionInfo()
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>   
>> locale:
>>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>   
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>   
>> other attached packages:
>> [1] lme4_1.1-8   Matrix_1.2-2
>>   
>> loaded via a namespace (and not attached):
>> [1] grid_3.1.2      lattice_0.20-33 MASS_7.3-43     minqa_1.2.4
>> [5] nlme_3.1-121    nloptr_1.0.4    Rcpp_0.12.0     splines_3.1.2
>> [9] tools_3.1.2
>>   
>> Anyway...
>>   
>> If you had a huge sample, those p values would be accurate.
>>   
>> You have a small sample, there are other, more computationally
>> intensive ways, to get p values.  Read the Jrnl Stat Software paper b
>> y the lmer team, they describe profiling and bootstrapping. You have
>> small enough sample, could do either one.
>>   
>>> 4. What does the
>>> correlation of fixed effects tells me?
>>>
>> It is a hint about multicollinearity & numerical instability, so far as
>> I know.
>>   
>>>
>>> 5. Is it right
>>> that the estimates tells me whether the relation of the fixed effects to
>>> pollinator offspring is positive or negative?
>>>
>>>
>> Best way to get answer is to plot the predicted values from the model.
>> Use the predict function to plot for various values of the predictor.
>>   
>>> 6. Can I
>>> calculate an effect size on each explanatory variable?
>>>
>> Only if you think the term "effect size" is meaningful.  And if you
>> have a formula for one.  In my experience with consulting here, it
>> means anything the researcher wants to call a summary number.
>>   
>> I've come to loathe the term because somebody in the US Dept. of
>> Education mandated all studies report standardized effect sizes,
>> forcing everybody to make Herculean assumptions about all kinds of
>> model parameters to get Cohen's D or whatnot.
>>   
>>>
>>> I would highly appreciate your feedback on this.
>>> Thanks so much in advance.
>>>
>> Good luck.  Next time, use a text only email composer and try to ask 1
>> specific question. You are more likely to get attention if people can
>> easily read the message and see what you want.  This one was difficult
>> to read (for me at least) and also somewhat vague.
>>   
>>>
>>> Best wishes,
>>>
>>> Yvonne Hiller
>>>
>>>
>>>
>>>
>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>>   
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>   
>>   
>>   
>> -- 
>> Paul E. Johnson
>> Professor, Political Science        Director
>> 1541 Lilac Lane, Room 504      Center for Research Methods
>> University of Kansas                 University of Kansas
>> http://pj.freefaculty.org              http://crmda.ku.edu
>>   
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   		 	   		
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From yvonne.hiller at hotmail.de  Sun Aug  2 14:14:05 2015
From: yvonne.hiller at hotmail.de (Yvonne Hiller)
Date: Sun, 2 Aug 2015 14:14:05 +0200
Subject: [R-sig-ME] Interpretation of GLMM output in R
In-Reply-To: <55BE0057.8040401@gmx.de>
References: <DUB119-W22109F11D44DFB8D916C5928A0@phx.gbl>, ,
	<CAErODj_XdLLOqJM_SuhinCYjUOqx667whKS3g5_uzGDrxeCm5w@mail.gmail.com>,
	,
	<CAJuCY5zCXd+tvdFTy_EQSq=jxTyQKG_T+rbeLsPjmWjQuDNOQg@mail.gmail.com>,
	<DUB119-W5194A05C2CB27F904EBA4692880@phx.gbl>,
	<55BE0057.8040401@gmx.de>
Message-ID: <DUB119-W1210BBFC6FFB3442BE38B592880@phx.gbl>

Dear Lionel, thanks a lot. That is very much helpful. ;)
Sincerely,
Ycvonne
----------------------------------------
> Date: Sun, 2 Aug 2015 13:34:47 +0200
> From: hughes.dupond at gmx.de
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Interpretation of GLMM output in R
>
> Dear Yvonne,
>
> To answer Question 1, I would scale both predictors to unit standard
> deviation (ie fad.data$Volume_std<-scale(fad.data$Volume,scale=TRUE))
> and then compare the back-transformed coefficients, as you have a
> Poisson model this would be then exp(fixef(fad)). Say that you get a
> value of 1.5 for the variable Volume, you would then interpret this as:
> an increase in one standard deviation of Volume leads to an increase of
> 1.5*Pollinator, put differently every increase of one standard deviation
> in Volume increase Pollinator by 50%. Having scaled the predictor would
> also allow you to compare the strength of their effects. Also note that
> effect sizes do not give informations about how much variance in the
> response variable is explained by individuals terms.
>
> Concerning the LRT to test the effect of predictors, it is not the best
> available option (see http://glmm.wikidot.com/faq#summary) the function
> "mixed" in the "afex" package allow you to do parametric bootstrap to
> test fixed effects (using type 2 or 3 tests). For effects with very
> small p-values (like volume) using LRT or parametric bootstrap will most
> certainly lead to the same interpretation (ie volume has a significant
> effect), for p-values close to 0.05 (like parasitoids) you might get
> different interpretations.
>
> Sincerely yours,
> Lionel
>
> On 02/08/2015 11:31, Yvonne Hiller wrote:
>> Dear Paul, Thierry and list members,
>> first of all:
>> Thanks so much for going through my questions, although it came in an
>> inappropriate look with wired brackets and unspecified questions. Apologies for that. So I
>> try again to specify things.
>>
>> The model includes following variables:
>> Pollinator = pollinator offspring
>> Parasitoids = parasitoid offspring
>> Volume = measured fig size
>> tree = tree ID
>>
>> This is the output of the model:
>>
>> fad <-glmer(Pollinator~Parasitoids+volume+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
>> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>> Family: poisson ( log )
>> Formula: Pollinator ~ Parasitoids + volume + (1 | tree)
>> Data: fad.data
>>
>> AIC BIC logLik deviance df.resid
>> 1550.6 1560.2 -771.3 1542.6 76
>>
>> Scaled residuals:
>> Min 1Q Median 3Q Max
>> -7.4825 -2.4111 -0.4725 2.4321 9.3409
>>
>> Random effects:
>> Groups Name Variance Std.Dev.
>> tree (Intercept) 0.1063 0.3261
>> Number of obs: 80, groups: tree, 8
>>
>> Fixed effects:
>> Estimate Std. Error z value Pr(>|z|)
>> (Intercept) 2.3167832 0.1634876 14.171 <2e-16 ***
>> Parasitoids -0.0046908 0.0022169 -2.116 0.0344 *
>> volume 0.0069527 0.0006197 11.220 <2e-16 ***
>> ---
>> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>> (Intr) Prstds
>> Parasitoids -0.144
>> volume -0.656 -0.139
>>
>> 1. I want to know if the predictor variables have an effect on pollinator
>> offspring. Therefore, I tested if ?Parasitoids? and ?volume? are important factors in the model by the LRT.
>>
>> fad1 <- glmer(Pollinator~1+volume+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
>> fad2 <- glmer(Pollinator~Parasitoids+1+(1|tree),data=fad.data,family="poisson",verbose=TRUE)
>>
>> anova(fad,fad1)
>> Models:
>> fad1: Pollinator ~ 1 + volume + (1 | tree)
>> fad: Pollinator ~ Parasitoids + volume + (1 | tree)
>> Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq)
>> fad1 3 1553.1 1560.3 -773.57 1547.1
>> fad 4 1550.6 1560.2 -771.32 1542.6 4.5105 1 0.03369 *
>> anova(fad,fad2)
>> Models:
>> fad2: Pollinator ~ Parasitoids + 1 + (1 | tree)
>> fad: Pollinator ~ Parasitoids + volume + (1 | tree)
>> Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq)
>> fad2 3 1669.2 1676.4 -831.61 1663.2
>> fad 4 1550.6 1560.2 -771.32 1542.6 120.59 1 < 2.2e-16 ***
>>>From the output, I conclude that both predictor variables have an effect on pollinator offspring. Is it reasonable to do the LRT for testing the predictor variables? Is there any chance to get an effect size of how much the predictor variables explain variance in the response variable? Since I know they have an effect, interpreation would be different when the effect of one variable is small or large.
>>
>> 2. From suggestions of Thierry and Paul and from the the caterpillar plot:
>> dotplot(ranef(fad, condVar=TRUE))$tree
>> I do understand that there is indeed a fairly large remaining variability in the number of pollinator offspring among trees, but
>> the relative effect of ?tree? does not depend on ?Parasitoids? and ?volume?.
>> Again, I would highly appreciate your suggestions and feedback on this. Thank you very much in advance.
>> Best wishes,Yvonne
>>
>> ________________________________
>>> Date: Sun, 2 Aug 2015 00:08:35 +0200
>>> Subject: Re: [R-sig-ME] Interpretation of GLMM output in R
>>> From: thierry.onkelinx at inbo.be
>>> To: pauljohn32 at gmail.com
>>> CC: yvonne.hiller at hotmail.de; r-sig-mixed-models at r-project.org
>>>
>>>
>>> Paul,
>>>
>>> Note that exp(beta0 + beta1*parasitoids + btree) is equivalent to
>>> exp(beta0 + beta1*parasitoids)*exp(btree). So the relative effect of
>>> tree doesn't depend on the other effects.
>>>
>>> I tend to look at the ratio of the 97.5% and 2.5% quantiles of the
>>> random effect. exp(q*sigma)/exp(-q*sigma) or simplified exp(2*q*sigma)
>>> with q =1.96 (97.5% quantile of a normal distribution) and sigma= the
>>> standard deviation of the random effect. exp(2*1.96*0.3261) ~ 3.5 So
>>> the 97.5% quantile tree has about 3.5 times the number of pollinators
>>> of the 2.5% quantile tree.
>>>
>>> Best regards,
>>>
>>> Thierry
>>>
>>> Op 1-aug.-2015 15:43 schreef "Paul Johnson"
>>> <pauljohn32 at gmail.com<mailto:pauljohn32 at gmail.com>>:
>>> Hi
>>>
>>> Your message comes through with weird line breaks, you should turn off
>>> the HTML compose option in your mail program, just write text.
>>>
>>> On Fri, Jul 31, 2015 at 8:42 AM, Yvonne Hiller
>>> <yvonne.hiller at hotmail.de<mailto:yvonne.hiller at hotmail.de>> wrote:
>>>>
>>>>
>>>>
>>>> Dear Ben Bolker and list members,
>>>>
>>>>
>>>>
>>>> I?am a PhD-student working on tropical plant-pollinator
>>>> interactions (the fig-fig wasp mutualism).
>>>>
>>>> I have some difficulties with my analyses of my data
>>>> using lmer (family = Poisson). I have read a lot of threads and
>>> searched for
>>>> solutions in Zuur 2009, though it was not completely satisfying. I
>>> looked at
>>>> other papers using GLMM (espeacially for the fig-fig wasp mutualism),
>>> but there
>>>> were so many different ways in reporting and interpreting p-values,
>>> AICs etc.
>>>> Therefore, I would be very grateful, if you could go through my output and
>>>> answer my questions to hopefully fully understand GLMM. Thank you so
>>> much in
>>>> advance.
>>>>
>>>>
>>>>
>>>> One of my questions is:
>>>>
>>>> Have parasitoids (offspring) and the volume size an
>>>> effect on the number of pollinator offspring?
>>>>
>>>>
>>>>
>>>> As pollinators are parasitized by parasitoids, I would
>>>> expect a negative impact on pollinator offspring. As the size of the
>>> fig fruits
>>>> might be an additionally factor (due to limited oviposition sites
>>> inside the fruit
>>>> or due to the ovipositor length of a parasitoid is to short to reach
>>> inner most
>>>> ovules galled by pollinators), I included it in the model.
>>>>
>>>>
>>>>
>>>> I have poisson data (counts):
>>>>
>>>>
>>>>
>>>> Pollinator
>>>> = pollinator offspring
>>>>
>>>> Parasitoids = parasitoid offspring
>>>>
>>>> volume = fig fruit size measurement
>>>>
>>>> tree = Tree ID
>>>>
>>>>
>>>>
>>>> I have data from trees in the forest and in the
>>>> farmland, as well as data of the rainy and dry season. I have chosen
>>> to perform
>>>> lmer for each season and habitat separately. For each tree, I have
>>> collected 10
>>>> fig fruits to count offspring of wasps at the trophic level (pollinator,
>>>> parasitoid) and to measure the size of the fruit (volume). As I have 10 fig
>>>> fruits per tree, I would use tree as a random effect, to account for
>>> unmeasured
>>>> variance between trees. I have found different approaches to that in
>>>> literature. For instance: We did not include? tree ? and ?
>>>> syconium ? as random factors, because wasps were free to move between
>>> syconia
>>>> on the same tree, and between trees.
>>>>
>>>> Therefore,
>>>> I am not sure if I have to use GLMM with trees as a random effect or
>>> if it?s
>>>> also possible to use GLM without the random effect.
>>>>
>>>>
>>>>
>>>> The inclusion of
>>>> fig volume in this manner removed the need to use ?fig? as an
>>> additional nested
>>>> factor within ?tree?. Is that right?
>>>>
>>>>
>>>>
>>>> Here, I
>>>> present the model with the random effect.
>>>>
>>>> So, lets start with the model of the farmland during
>>>> the dry season:
>>>>
>>>>
>>>>
>>>> fad <-
>>> lmer(Pollinator~Parasitoids+volume+(1|tree),family="poisson",verbose=TRUE)
>>>>
>>>>
>>>> summary (fad)
>>>>
>>>> Generalized linear mixed model fit by the Laplace
>>>> approximation
>>>>
>>>> Formula: Pollinator ~ Parasitoids + volume + (1 |
>>>> tree)
>>>>
>>>> Data:
>>>> fad.data
>>>>
>>>> AIC BIC logLik deviance
>>>>
>>>> 1166 1175
>>>> -578.9 1158
>>>>
>>>> Random effects:
>>>>
>>>> Groups
>>>> Name Variance Std.Dev.
>>>>
>>>> tree (Intercept) 0.10634 0.3261
>>>>
>>>>
>>>> Number of obs: 80, groups: tree, 8
>>>>
>>>>
>>>>
>>>> Fixed effects:
>>>>
>>>>
>>>> Estimate Std. Error z value Pr(>|z|)
>>>>
>>>> (Intercept)
>>>> 2.3167867 0.1632747 14.190
>>>> <2e-16 ***
>>>>
>>>> Parasitoids -0.0046908
>>>> 0.0021686 -2.163 0.0305 *
>>>>
>>>>
>>>> volume
>>>> 0.0069525 0.0006108 11.383
>>>> <2e-16 ***
>>>>
>>>> ---
>>>>
>>>> Signif.
>>>> codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05
>>>> ?.? 0.1 ? ? 1
>>>>
>>>>
>>>>
>>>> Correlation of Fixed Effects:
>>>>
>>>>
>>>> (Intr) Prstds
>>>>
>>>> Parasitoids -0.160
>>>>
>>>> volume
>>>> -0.657 -0.107
>>>>
>>>>
>>>>
>>>> 1. Random effects: What does the Random
>>>> Effect table - the Variance, Std. Dev. and Intercept tells me?
>>>>
>>>>
>>> Your model assumes that the outcome is Poisson with expected value
>>> exp(beta0 + beta1*parasitoids + btree)
>>>
>>> btree is a unique added amount for each tree. The estimate of the
>>> number btree's variance across trees is 0.1.
>>>
>>> What that 0.1 means in terms of the predicted outcome? Well, that
>>> mostly depends on how big beta0 + beta1*parasitoids is. If that
>>> number is huge, say 1000, then adding a thing with variance 0.1 won't
>>> matter much.
>>>
>>> On the other hand, if it is 0.01, then the random effect at the tree
>>> level is very large, compared to the systematic components in your
>>> model. When the link function gets applied, the distribution of
>>> outcomes changes in an interesting way.
>>>
>>> If you run ranef(), it will spit out the estimates of the random
>>> differences among trees (btree "BLUPS"). If you run the predict
>>> method, you can see how those map out to predicted values (exp(beta0 +
>>> beta1 parasitoids + btree)
>>>
>>>> So it says that the
>>>> between?tree variability is fairly large. But I don?t understand to what it
>>>> relates. Does it mean that pollinator offspring variance is high between
>>>> trees and might be overestimating the explanatory variables?
>>>>
>>>>
>>>>
>>>> 2. What can I
>>>> conclude from the model regarding the fixed effects and how to report
>>> about it
>>>> (with or without p-values, z-values, estimates)?
>>>>
>>>>
>>>>
>>>> So of what I know is that
>>>> the p-value is only a guide and that it is rather a comparison of two
>>> models.
>>>> What are the two models and can I compare them.
>>>>
>>>>
>>> I am puzzled why you see p values at all. In the version of lme4 I'm
>>> running now, I don't see p values.
>>>
>>> Lets compare versions, since I'm pretty sure p values were removed
>>> quite a while ago.
>>>
>>>> sessionInfo()
>>> R version 3.1.2 (2014-10-31)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>
>>> locale:
>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>> [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> other attached packages:
>>> [1] lme4_1.1-8 Matrix_1.2-2
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_3.1.2 lattice_0.20-33 MASS_7.3-43 minqa_1.2.4
>>> [5] nlme_3.1-121 nloptr_1.0.4 Rcpp_0.12.0 splines_3.1.2
>>> [9] tools_3.1.2
>>>
>>> Anyway...
>>>
>>> If you had a huge sample, those p values would be accurate.
>>>
>>> You have a small sample, there are other, more computationally
>>> intensive ways, to get p values. Read the Jrnl Stat Software paper b
>>> y the lmer team, they describe profiling and bootstrapping. You have
>>> small enough sample, could do either one.
>>>
>>>> 4. What does the
>>>> correlation of fixed effects tells me?
>>>>
>>> It is a hint about multicollinearity & numerical instability, so far as
>>> I know.
>>>
>>>>
>>>> 5. Is it right
>>>> that the estimates tells me whether the relation of the fixed effects to
>>>> pollinator offspring is positive or negative?
>>>>
>>>>
>>> Best way to get answer is to plot the predicted values from the model.
>>> Use the predict function to plot for various values of the predictor.
>>>
>>>> 6. Can I
>>>> calculate an effect size on each explanatory variable?
>>>>
>>> Only if you think the term "effect size" is meaningful. And if you
>>> have a formula for one. In my experience with consulting here, it
>>> means anything the researcher wants to call a summary number.
>>>
>>> I've come to loathe the term because somebody in the US Dept. of
>>> Education mandated all studies report standardized effect sizes,
>>> forcing everybody to make Herculean assumptions about all kinds of
>>> model parameters to get Cohen's D or whatnot.
>>>
>>>>
>>>> I would highly appreciate your feedback on this.
>>>> Thanks so much in advance.
>>>>
>>> Good luck. Next time, use a text only email composer and try to ask 1
>>> specific question. You are more likely to get attention if people can
>>> easily read the message and see what you want. This one was difficult
>>> to read (for me at least) and also somewhat vague.
>>>
>>>>
>>>> Best wishes,
>>>>
>>>> Yvonne Hiller
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> [[alternative HTML version deleted]]
>>>>
>>>>
>>>> _______________________________________________
>>>>
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>>
>>> --
>>> Paul E. Johnson
>>> Professor, Political Science Director
>>> 1541 Lilac Lane, Room 504 Center for Research Methods
>>> University of Kansas University of Kansas
>>> http://pj.freefaculty.org http://crmda.ku.edu
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  

From jspmccain at gmail.com  Sun Aug  2 21:24:13 2015
From: jspmccain at gmail.com (Scott McCain)
Date: Sun, 02 Aug 2015 19:24:13 +0000
Subject: [R-sig-ME] Binomial glmmadmb error message
Message-ID: <CA+9vPVaxF3wWk4cWh3SvmN4J-hkpUtUr+_pUP5pymnkQZhWKjw@mail.gmail.com>

Hello,

I'm trying to fit a hurdle mixed effects model, looking at cod abundance
(cod0, cod1, and cod2). Because of the overdispersion and zero-inflation,
I'm trying to use a hurdle model with the first stage as a binomial GLMM
and the second stage a negative binomial GLMM. We have chosen site to be a
random effect. Here is a summary of the data I'm working with:

str(div.3a)
'data.frame': 325 obs. of  21 variables:
 $ beach           : Factor w/ 56 levels "1","2","3","4",..: 1 1 1 1 1 1 1
1 1 7 ...
 $ shannons        : num  1.017 1.014 1.302 0.853 1.325 ...
 $ year            : Factor w/ 12 levels "59","60","61",..: 3 5 4 7 11 6 9
10 8 7 ...
 $ region          : Factor w/ 6 levels "Bonavista Bay",..: 5 5 5 5 5 5 5 5
5 5 ...
 $ species.rich    : int  6 7 6 7 6 5 6 4 6 3 ...
 $ year.range      : Factor w/ 2 levels "1960-1964","1992-1996": 1 1 1 2 2
1 2 2 2 2 ...
 $ sum.tfish       : num  137 120 157 84 73 56 20 5 320 96 ...
 $ evenness        : num  0.568 0.521 0.726 0.439 0.74 ...
 $ cod0            : int  24 43 0 0 0 3 0 0 0 9 ...
 $ cod1            : int  47 10 48 0 0 8 0 0 1 0 ...
 $ cod2            : int  0 0 5 0 0 0 0 0 0 0 ...
 $ beach.name      : Factor w/ 56 levels "Admirals Beach",..: 26 26 26 26
26 26 26 26 26 52 ...
 $ site.no         : Factor w/ 42 levels "1","2","5","6",..: 1 1 1 1 1 1 1
1 1 5 ...
 $ depth           : num  4 4 4 4 4 4 4 4 4 3 ...
 $ vegetation      : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
 $ eelgrass        : int  1 1 1 1 1 1 1 1 1 0 ...
 $ kelp            : int  0 0 0 0 0 0 0 0 0 1 ...
 $ cod0nz          : num  1 1 0 0 0 1 0 0 0 1 ...
 $ cod1nz          : num  1 1 1 0 0 1 0 0 1 0 ...
 $ cod2nz          : num  0 0 1 0 0 0 0 0 0 0 ...

(I'm using likelihood ratio tests using anova() by adding one term at a
time). First fitting the binomial glmmadmb:

cod1b.1 <- glmmadmb(data=div.3a, cod1nz ~ (1|site.no), family="binomial")

#works fine

cod1b.2 <- glmmadmb(data=div.3a, cod1nz ~ year.range + (1|site.no),
family="binomial")

## the above returns the following error message:

Parameters were estimated, but not standard errors were not: the most
likely problem is that the curvature at MLE was zero or negative

Error in glmmadmb(data = div.3a, cod1nz ~ year.range + (1 | site.no),  :
  The function maximizer failed (couldn't find STD file) Troubleshooting
steps include (1) run with 'save.dir' set and inspect output files; (2)
change run parameters: see '?admbControl'

In addition: Warning message:
running command 'C:\Windows\system32\cmd.exe /c
"C:/Users/Scott/Documents/R/win-library/3.2/glmmADMB/bin/windows64/glmmadmb.exe"
-maxfn 500 -maxph 5' had status 1

################

So looking at this error message, I first attempted to inspect the output
files but was quickly lost. I then looked into admbControl() and tried the
following:

cod1b.2 <- glmmadmb(data=div.3a, cod1nz ~ year.range + (1|site.no),
family="binomial", admb.opts=admbControl(noinit=FALSE, shess=FALSE))

#This unfortunately returns the exact same error message.

What's quite strange is when I add in the next term I want to do null
hypothesis testing on ("region"), I don't get an error.

cod1b.3 <- glmmadmb(data=div.3a, cod1nz ~ year.range + region + (1|site.no),
family="binomial")

However when I add the next term, "vegetation", I get this error:

cod1b.4 <- glmmadmb(data=div.3a, cod1nz ~ year.range + region + vegetation
+ (1|site.no), family="binomial")

Warning message:
In glmmadmb(data = div.3a, cod1nz ~ year.range + region + vegetation +  :
  Convergence failed:log-likelihood of gradient= -0.0434684

If anybody has any insight about these error messages, please let me know!

Here is my sessionInfo():

R version 3.2.1 (2015-06-18)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8 x64 (build 9200)

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
[5] LC_TIME=English_Canada.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods
base

other attached packages:
 [1] glmmADMB_0.8.0     matrixStats_0.14.2 beepr_1.2          lmtest_0.9-34
     zoo_1.7-12         gridExtra_2.0.0    pscl_1.4.9
 [8] MASS_7.3-40        mgcv_1.8-7         nlme_3.1-120
statmod_1.4.21     tweedie_2.2.1      lme4_1.1-8         Matrix_1.2-1
[15] xtable_1.7-4       mvabund_3.10.4     ggplot2_1.0.1      stringr_1.0.0
     vegan_2.3-0        lattice_0.20-31    permute_0.8-4
[22] reshape2_1.4.1     dplyr_0.4.2

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.0      R2admb_0.7.5.3   nloptr_1.0.4     plyr_1.8.3
tools_3.2.1      digest_0.6.8     gtable_0.1.2     DBI_0.3.1
 [9] parallel_3.2.1   proto_0.3-10     cluster_2.0.1    R6_2.1.0
minqa_1.2.4      magrittr_1.5     scales_0.2.5     splines_3.2.1
[17] assertthat_0.1   colorspace_1.2-6 stringi_0.5-5    lazyeval_0.1.10
 munsell_0.4.2    audio_0.1-5

Thanks!

Scott

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue Aug  4 14:04:38 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 04 Aug 2015 21:34:38 +0930
Subject: [R-sig-ME] Course: Introduction to zero inflated models
Message-ID: <55C0AA56.8030204@highstat.com>

Apologies for cross-posting

We would like to announce the following statistics course:

Course: Introduction to zero inflated models
Where:  Elche (close to Alicante), Spain
When:   2-6 November 2015

Course website: http://www.highstat.com/statscourse.htm
Flyer: http://www.highstat.com/Courses/Flyers/Flyer2015_11Elche.pdf


Kind regards,

Alain Zuur







-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From daniel.kaschek at physik.uni-freiburg.de  Mon Aug  3 10:05:37 2015
From: daniel.kaschek at physik.uni-freiburg.de (Daniel Kaschek)
Date: Mon, 03 Aug 2015 10:05:37 +0200
Subject: [R-sig-ME] Model with variable number of arguments
In-Reply-To: <CAErODj9piXRPxzaufD--xnfcjzf5ysQAk+arOo=SDrq089nc1A@mail.gmail.com>
References: <1438263247.13557.91.camel@physik.uni-freiburg.de>
	<CAErODj9piXRPxzaufD--xnfcjzf5ysQAk+arOo=SDrq089nc1A@mail.gmail.com>
Message-ID: <1438589137.13557.104.camel@physik.uni-freiburg.de>

On Sa, 2015-08-01 at 09:26 -0500, Paul Johnson wrote:
> On Thu, Jul 30, 2015 at 8:34 AM, Daniel Kaschek
> <daniel.kaschek at physik.uni-freiburg.de> wrote:
> > Dear all,
> >
> > I have the following model:
> >
> > y_ij = x_i/s_j + (eps_ij)/s_j
> >
> > where y_ij are the responses, x_i and s_j are the fixed effects and the
> > random effects follow a normal distribution
> >
> 1.  x_i and s_j are observed variables or parameters you need to
> estimate?  Why you have no betas?

Both, the x_i and s_j are parameters whereas the y_ij are the
observations. The background is that a time course of concentrations,
x_i (i corresponds to different time points) is measured several times,
but on a different scale, given by s_j. If you plot all y_ij together in
one plot, put i on the x-axis and group with respect to j, you would see
the same time course on different scales.


> 
> 2. the formulation using division is unfamiliar to me, but when you
> get to this part
> 
> > eps_ij ~ N(0, sigma0^2 + x_i^2 * sigmaR^2)
> >
> 
> Can't answer because I can't tell if x_i is observed or not.  If it is
> not, I don't know that lme4 will help.

The parameters x_i correspond to the "true" time course. The expected
variance at time point i has two contributions: 1. a constant
contribution, sigma0^2, and 2. a contribution relative to the
concentrations, (x_i * sigmaR)^2. Since each measured time course lives
on a different scale, the variance eps_ij needs to be divided by the
corresponding scaling factor s_j. 

> 
> How did eps get this way in the first place.  It appears it might be
> the sum of 2 separate random effects. If that's right, you are getting
> closer to the sort of model I would understand
> 
> It makes me wonder why you don't have s_j inside the variance term
> there,, or why you don't have both x_ and s_ outside.
> 
> Its pretty tough to read email with lots of x_i and such.  That part
> is bad about plain text mailing lists

Yes, I known :-(


Though, I hope, I could make things clearer. 

Best regards,
Daniel

> 
> > with error parameters sigma0 and sigmaR. In the end, I am interested in
> > the parameters x_i, s_j, sigma0 and sigmaR.
> >
> > First of all, is lme4 the right package to solve this problem? When
> > looking at nlmer(), I had problems to figure out what would be the
> > correct structure of the function in the middle of the 3-part-formula.
> >
> > Any help is appreciated.
> >
> > Thanks a lot in advance,
> > Daniel
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From nunezcmv at gmail.com  Wed Aug  5 17:57:59 2015
From: nunezcmv at gmail.com (Cassandra Nunez)
Date: Wed, 05 Aug 2015 10:57:59 -0500
Subject: [R-sig-ME] comparison of GLMM pQL models?
Message-ID: <55C23287.2080500@gmail.com>

Can anyone tell me how I can compare GLMM PQL models to determine which 
is the best fit for my data?

Thanks so much!


From cddesjardins at gmail.com  Wed Aug  5 18:38:29 2015
From: cddesjardins at gmail.com (Christopher David Desjardins)
Date: Wed, 5 Aug 2015 16:38:29 +0000
Subject: [R-sig-ME] comparison of GLMM pQL models?
In-Reply-To: <55C23287.2080500@gmail.com>
References: <55C23287.2080500@gmail.com>
Message-ID: <CALrjt783O=m5GiV9UdUR5kfZK8foPcp-z2MeXqTEchB3QeX2BQ@mail.gmail.com>

Hi,

I think these could be helpful.

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015407.html
https://stat.ethz.ch/pipermail/r-help/2006-February/088629.html
https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf



On Wed, Aug 5, 2015 at 3:57 PM, Cassandra Nunez <nunezcmv at gmail.com> wrote:

> Can anyone tell me how I can compare GLMM PQL models to determine which is
> the best fit for my data?
>
> Thanks so much!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
https://cddesja.github.io/

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Fri Aug  7 21:27:03 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Fri, 7 Aug 2015 16:27:03 -0300
Subject: [R-sig-ME] interaction terms interpretation
Message-ID: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>

Hi all, I?m running a mixed model with poisson error distribution as I have
count data of a shorebird species. My predictors are AMGP (another
shorebird that is usually associated to "my" species and probably has
ecological influence on it), grass height and field distance to the lagoon.

I?m having a hard time trying to interpret second order interactions. I
appreciate your comments of references recommendations. Here is the output
of my model. All the best, Joaqu?n.

Call:glmmadmb(formula = BBSA ~ AMGP * Grass_height *
Distance_to_lagoon +     (1 | Field_name) + offset(log(Field_area.o)),
data = my4S,     family = "nbinom1", zeroInflation = TRUE)
AIC: 226
Coefficients:                                     Estimate Std. Error
z value Pr(>|z|)    (Intercept)                           -5.8797
1.2250   -4.80  1.6e-06 ***AMGP
3.3086     1.0246    3.23   0.0012 ** Grass_height
     -4.1592     1.9961   -2.08   0.0372 *  Distance_to_lagoon
           -0.5029     1.3929   -0.36   0.7180    AMGP:Grass_height
                  2.9442     1.5142    1.94   0.0518 .
AMGP:Distance_to_lagoon               -2.4695     0.9632   -2.56
0.0104 *  Grass_height:Distance_to_lagoon        0.0339     2.0065
0.02   0.9865    AMGP:Grass_height:Distance_to_lagoon  -4.0363
1.3264   -3.04   0.0023 ** ---Signif. codes:  0 ?***? 0.001 ?**? 0.01
?*? 0.05 ?.? 0.1 ? ? 1
Number of observations: total=64, Field_name=16 Random effect
variance(s):Group=Field_name            Variance StdDev(Intercept)
0.03721 0.1929
Negative binomial dispersion parameter: 20.633 (std. err.:
7.4042)Zero-inflation: 1e-06  (std. err.:  6.8336e-09 )
Log-likelihood: -102


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From abedimail at gmail.com  Mon Aug 10 07:54:32 2015
From: abedimail at gmail.com (Mehdi Abedi)
Date: Mon, 10 Aug 2015 10:24:32 +0430
Subject: [R-sig-ME] Mixed model for count data with overdispersion
Message-ID: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>

Dear all,

I had quick search but it looks there is no simple way in lme4 or  nlme In
the case of overdispersion for count data,. How we can run mixed model for
count data with family of quasipoisson or maybe NB?

I my working on seeding emergence with 2 fixed factor (n=10) and i would
like to have my plot as replicate(n=5) as a random.

Warm regards,
Mehdi

-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Aug 10 09:02:16 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 10 Aug 2015 09:02:16 +0200
Subject: [R-sig-ME] interaction terms interpretation
In-Reply-To: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>
References: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>
Message-ID: <CAJuCY5wB_tNFuDmym_LFtk-T4eVt_YbJf9=z=YtRVmvGeZuHqA@mail.gmail.com>

Dear Joaquin,

Your mail is mangled because you send it in HTML. This makes the model
output very hard to read.

It's impossible to interpret model output without thorough knowledge of the
dataset. I suggest that you try to make some graphs of the model.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-08-07 21:27 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Hi all, I?m running a mixed model with poisson error distribution as I have
> count data of a shorebird species. My predictors are AMGP (another
> shorebird that is usually associated to "my" species and probably has
> ecological influence on it), grass height and field distance to the lagoon.
>
> I?m having a hard time trying to interpret second order interactions. I
> appreciate your comments of references recommendations. Here is the output
> of my model. All the best, Joaqu?n.
>
> Call:glmmadmb(formula = BBSA ~ AMGP * Grass_height *
> Distance_to_lagoon +     (1 | Field_name) + offset(log(Field_area.o)),
> data = my4S,     family = "nbinom1", zeroInflation = TRUE)
> AIC: 226
> Coefficients:                                     Estimate Std. Error
> z value Pr(>|z|)    (Intercept)                           -5.8797
> 1.2250   -4.80  1.6e-06 ***AMGP
> 3.3086     1.0246    3.23   0.0012 ** Grass_height
>      -4.1592     1.9961   -2.08   0.0372 *  Distance_to_lagoon
>            -0.5029     1.3929   -0.36   0.7180    AMGP:Grass_height
>                   2.9442     1.5142    1.94   0.0518 .
> AMGP:Distance_to_lagoon               -2.4695     0.9632   -2.56
> 0.0104 *  Grass_height:Distance_to_lagoon        0.0339     2.0065
> 0.02   0.9865    AMGP:Grass_height:Distance_to_lagoon  -4.0363
> 1.3264   -3.04   0.0023 ** ---Signif. codes:  0 ?***? 0.001 ?**? 0.01
> ?*? 0.05 ?.? 0.1 ? ? 1
> Number of observations: total=64, Field_name=16 Random effect
> variance(s):Group=Field_name            Variance StdDev(Intercept)
> 0.03721 0.1929
> Negative binomial dispersion parameter: 20.633 (std. err.:
> 7.4042)Zero-inflation: 1e-06  (std. err.:  6.8336e-09 )
> Log-likelihood: -102
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From manabu.sakamoto at gmail.com  Mon Aug 10 10:18:07 2015
From: manabu.sakamoto at gmail.com (Manabu Sakamoto)
Date: Mon, 10 Aug 2015 09:18:07 +0100
Subject: [R-sig-ME] Mixed model for count data with overdispersion
In-Reply-To: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>
References: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>
Message-ID: <CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>

Dear Mehdi,

You can use the function MCMCglmm in the package of the same name,
specifying family="poisson". MCMCglmm automatically accounts for over
dispersion in count data.

best regards,
Manabu

On 10 August 2015 at 06:54, Mehdi Abedi <abedimail at gmail.com> wrote:

> Dear all,
>
> I had quick search but it looks there is no simple way in lme4 or  nlme In
> the case of overdispersion for count data,. How we can run mixed model for
> count data with family of quasipoisson or maybe NB?
>
> I my working on seeding emergence with 2 fixed factor (n=10) and i would
> like to have my plot as replicate(n=5) as a random.
>
> Warm regards,
> Mehdi
>
> --
>
>
> *Mehdi Abedi Department of Range Management*
>
> *Faculty of Natural Resources & Marine Sciences *
>
> *Tarbiat Modares University (TMU) *
>
> *46417-76489, Noor*
>
> *Mazandaran, IRAN *
>
> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>
> *Homepage
> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>
> *Tel: +98-122-6253101 *
>
> *Fax: +98-122-6253499*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Manabu Sakamoto, PhD
manabu.sakamoto at gmail.com

	[[alternative HTML version deleted]]


From abedimail at gmail.com  Mon Aug 10 10:56:56 2015
From: abedimail at gmail.com (Mehdi Abedi)
Date: Mon, 10 Aug 2015 13:26:56 +0430
Subject: [R-sig-ME] Mixed model for count data with overdispersion
In-Reply-To: <CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>
References: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>
	<CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>
Message-ID: <CADGhagh2E7JaEHGoLG1jdUTE8VHOhhbO6cftpB06SpiwyEu4Lw@mail.gmail.com>

Thanks Manabu,
It is a bit complicated for me but If i have this data:
Parameter: Totalseedling
fixed effect: Heatsmoke, cold
random effect: plot

I should do something like this?!


Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random =
~Plots,family="poisson", data = growthdata)
 summary( Model1)
It looks i can not get anova() here for output as well?


I am not familiar with other details in the MCMCglmm:

library( MCMCglmm)
Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random = ~Plot,
+ family = "poisson", data = growthdata, prior = prior,
+ verbose = FALSE, pr = TRUE)

Warm regards,
Mehdi

On Mon, Aug 10, 2015 at 12:48 PM, Manabu Sakamoto <manabu.sakamoto at gmail.com
> wrote:

> Dear Mehdi,
>
> You can use the function MCMCglmm in the package of the same name,
> specifying family="poisson". MCMCglmm automatically accounts for over
> dispersion in count data.
>
> best regards,
> Manabu
>
> On 10 August 2015 at 06:54, Mehdi Abedi <abedimail at gmail.com> wrote:
>
>> Dear all,
>>
>> I had quick search but it looks there is no simple way in lme4 or  nlme In
>> the case of overdispersion for count data,. How we can run mixed model for
>> count data with family of quasipoisson or maybe NB?
>>
>> I my working on seeding emergence with 2 fixed factor (n=10) and i would
>> like to have my plot as replicate(n=5) as a random.
>>
>> Warm regards,
>> Mehdi
>>
>> --
>>
>>
>> *Mehdi Abedi Department of Range Management*
>>
>> *Faculty of Natural Resources & Marine Sciences *
>>
>> *Tarbiat Modares University (TMU) *
>>
>> *46417-76489, Noor*
>>
>> *Mazandaran, IRAN *
>>
>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>>
>> *Homepage
>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>
>> *Tel: +98-122-6253101 *
>>
>> *Fax: +98-122-6253499*
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Manabu Sakamoto, PhD
> manabu.sakamoto at gmail.com
>



-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From cddesjardins at gmail.com  Mon Aug 10 11:16:24 2015
From: cddesjardins at gmail.com (Christopher David Desjardins)
Date: Mon, 10 Aug 2015 09:16:24 +0000
Subject: [R-sig-ME] Mixed model for count data with overdispersion
In-Reply-To: <CADGhagh2E7JaEHGoLG1jdUTE8VHOhhbO6cftpB06SpiwyEu4Lw@mail.gmail.com>
References: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>
	<CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>
	<CADGhagh2E7JaEHGoLG1jdUTE8VHOhhbO6cftpB06SpiwyEu4Lw@mail.gmail.com>
Message-ID: <F6AF9039-92EF-4CFD-A722-55824AD2D908@gmail.com>

Hi,

You really should read about the MCMCglmm package before just using it. There are a couple of vignettes which I strongly suggest that you read prior to actually using MCMCglmm as they explain a lot.

https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf <https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf>
https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf <https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf>

Do note that you need to specify prior distributions or at least understand the default ones.

Chris

> On Aug 10, 2015, at 8:56 AM, Mehdi Abedi <abedimail at gmail.com> wrote:
> 
> Thanks Manabu,
> It is a bit complicated for me but If i have this data:
> Parameter: Totalseedling
> fixed effect: Heatsmoke, cold
> random effect: plot
> 
> I should do something like this?!
> 
> 
> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random =
> ~Plots,family="poisson", data = growthdata)
> summary( Model1)
> It looks i can not get anova() here for output as well?
> 
> 
> I am not familiar with other details in the MCMCglmm:
> 
> library( MCMCglmm)
> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random = ~Plot,
> + family = "poisson", data = growthdata, prior = prior,
> + verbose = FALSE, pr = TRUE)
> 
> Warm regards,
> Mehdi
> 
> On Mon, Aug 10, 2015 at 12:48 PM, Manabu Sakamoto <manabu.sakamoto at gmail.com <mailto:manabu.sakamoto at gmail.com>
>> wrote:
> 
>> Dear Mehdi,
>> 
>> You can use the function MCMCglmm in the package of the same name,
>> specifying family="poisson". MCMCglmm automatically accounts for over
>> dispersion in count data.
>> 
>> best regards,
>> Manabu
>> 
>> On 10 August 2015 at 06:54, Mehdi Abedi <abedimail at gmail.com> wrote:
>> 
>>> Dear all,
>>> 
>>> I had quick search but it looks there is no simple way in lme4 or  nlme In
>>> the case of overdispersion for count data,. How we can run mixed model for
>>> count data with family of quasipoisson or maybe NB?
>>> 
>>> I my working on seeding emergence with 2 fixed factor (n=10) and i would
>>> like to have my plot as replicate(n=5) as a random.
>>> 
>>> Warm regards,
>>> Mehdi
>>> 
>>> --
>>> 
>>> 
>>> *Mehdi Abedi Department of Range Management*
>>> 
>>> *Faculty of Natural Resources & Marine Sciences *
>>> 
>>> *Tarbiat Modares University (TMU) *
>>> 
>>> *46417-76489, Noor*
>>> 
>>> *Mazandaran, IRAN *
>>> 
>>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>>> 
>>> *Homepage
>>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>> 
>>> *Tel: +98-122-6253101 *
>>> 
>>> *Fax: +98-122-6253499*
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> 
>> 
>> --
>> Manabu Sakamoto, PhD
>> manabu.sakamoto at gmail.com
>> 
> 
> 
> 
> -- 
> 
> 
> *Mehdi Abedi Department of Range Management*
> 
> *Faculty of Natural Resources & Marine Sciences *
> 
> *Tarbiat Modares University (TMU) *
> 
> *46417-76489, Noor*
> 
> *Mazandaran, IRAN *
> 
> *mehdi.abedi at modares.ac.ir <mailto:mehdi.abedi at modares.ac.ir> <Mehdi.abedi at modares.ac.ir <mailto:Mehdi.abedi at modares.ac.ir>>*
> 
> *Homepage
> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>>*
> 
> *Tel: +98-122-6253101 *
> 
> *Fax: +98-122-6253499*
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From abedimail at gmail.com  Mon Aug 10 11:27:33 2015
From: abedimail at gmail.com (Mehdi Abedi)
Date: Mon, 10 Aug 2015 13:57:33 +0430
Subject: [R-sig-ME] Mixed model for count data with overdispersion
In-Reply-To: <F6AF9039-92EF-4CFD-A722-55824AD2D908@gmail.com>
References: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>
	<CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>
	<CADGhagh2E7JaEHGoLG1jdUTE8VHOhhbO6cftpB06SpiwyEu4Lw@mail.gmail.com>
	<F6AF9039-92EF-4CFD-A722-55824AD2D908@gmail.com>
Message-ID: <CADGhagisridue8NPeMo46cULjKwx6GUVSo3FtmO-Ehy03=XmRA@mail.gmail.com>

Thanks Chris for lectures,
Working with MCMCglmm is like jumping from high school physics to Albert
Einstein lectures:). Hopefully i can digest this as a ecologist this
modeling part!
All the best

On Mon, Aug 10, 2015 at 1:46 PM, Christopher David Desjardins <
cddesjardins at gmail.com> wrote:

> Hi,
>
> You really should read about the MCMCglmm package before just using it.
> There are a couple of vignettes which I strongly suggest that you read
> prior to actually using MCMCglmm as they explain a lot.
>
> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf
> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf
>
> Do note that you need to specify prior distributions or at least
> understand the default ones.
>
> Chris
>
> On Aug 10, 2015, at 8:56 AM, Mehdi Abedi <abedimail at gmail.com> wrote:
>
> Thanks Manabu,
> It is a bit complicated for me but If i have this data:
> Parameter: Totalseedling
> fixed effect: Heatsmoke, cold
> random effect: plot
>
> I should do something like this?!
>
>
> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random =
> ~Plots,family="poisson", data = growthdata)
> summary( Model1)
> It looks i can not get anova() here for output as well?
>
>
> I am not familiar with other details in the MCMCglmm:
>
> library( MCMCglmm)
> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random = ~Plot,
> + family = "poisson", data = growthdata, prior = prior,
> + verbose = FALSE, pr = TRUE)
>
> Warm regards,
> Mehdi
>
> On Mon, Aug 10, 2015 at 12:48 PM, Manabu Sakamoto <
> manabu.sakamoto at gmail.com
>
> wrote:
>
>
> Dear Mehdi,
>
> You can use the function MCMCglmm in the package of the same name,
> specifying family="poisson". MCMCglmm automatically accounts for over
> dispersion in count data.
>
> best regards,
> Manabu
>
> On 10 August 2015 at 06:54, Mehdi Abedi <abedimail at gmail.com> wrote:
>
> Dear all,
>
> I had quick search but it looks there is no simple way in lme4 or  nlme In
> the case of overdispersion for count data,. How we can run mixed model for
> count data with family of quasipoisson or maybe NB?
>
> I my working on seeding emergence with 2 fixed factor (n=10) and i would
> like to have my plot as replicate(n=5) as a random.
>
> Warm regards,
> Mehdi
>
> --
>
>
> *Mehdi Abedi Department of Range Management*
>
> *Faculty of Natural Resources & Marine Sciences *
>
> *Tarbiat Modares University (TMU) *
>
> *46417-76489, Noor*
>
> *Mazandaran, IRAN *
>
> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>
> *Homepage
> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>
> *Tel: +98-122-6253101 *
>
> *Fax: +98-122-6253499*
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> Manabu Sakamoto, PhD
> manabu.sakamoto at gmail.com
>
>
>
>
> --
>
>
> *Mehdi Abedi Department of Range Management*
>
> *Faculty of Natural Resources & Marine Sciences *
>
> *Tarbiat Modares University (TMU) *
>
> *46417-76489, Noor*
>
> *Mazandaran, IRAN *
>
> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>
> *Homepage
> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>
> *Tel: +98-122-6253101 *
>
> *Fax: +98-122-6253499*
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Mon Aug 10 12:36:18 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Mon, 10 Aug 2015 20:36:18 +1000
Subject: [R-sig-ME] interaction terms interpretation
In-Reply-To: <CAJuCY5wB_tNFuDmym_LFtk-T4eVt_YbJf9=z=YtRVmvGeZuHqA@mail.gmail.com>
References: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>
	<CAJuCY5wB_tNFuDmym_LFtk-T4eVt_YbJf9=z=YtRVmvGeZuHqA@mail.gmail.com>
Message-ID: <CAF5_5cwrHj0hCjWWJKsEYy6_=h1hi9Kqf=DN4OvpDVMuxmZmMA@mail.gmail.com>

There is actually a continuous third order interaction, which are just
about impossible to interpret.

As well as the graphs, which you always should start with, think about what
is sensible for the model. Should any of the predictors be log-scaled? As AMGP
is a count it wouldn't be surprising it it is, or use log(1+x) if there are
zeroes.

Look at diagnostic plots and make sure that everything is fine, especially
that there are no outliers which might be causing the interaction.

Ken

On 10 August 2015 at 17:02, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Joaquin,
>
> Your mail is mangled because you send it in HTML. This makes the model
> output very hard to read.
>
> It's impossible to interpret model output without thorough knowledge of the
> dataset. I suggest that you try to make some graphs of the model.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-08-07 21:27 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>
> > Hi all, I?m running a mixed model with poisson error distribution as I
> have
> > count data of a shorebird species. My predictors are AMGP (another
> > shorebird that is usually associated to "my" species and probably has
> > ecological influence on it), grass height and field distance to the
> lagoon.
> >
> > I?m having a hard time trying to interpret second order interactions. I
> > appreciate your comments of references recommendations. Here is the
> output
> > of my model. All the best, Joaqu?n.
> >
> > Call:glmmadmb(formula = BBSA ~ AMGP * Grass_height *
> > Distance_to_lagoon +     (1 | Field_name) + offset(log(Field_area.o)),
> > data = my4S,     family = "nbinom1", zeroInflation = TRUE)
> > AIC: 226
> > Coefficients:                                     Estimate Std. Error
> > z value Pr(>|z|)    (Intercept)                           -5.8797
> > 1.2250   -4.80  1.6e-06 ***AMGP
> > 3.3086     1.0246    3.23   0.0012 ** Grass_height
> >      -4.1592     1.9961   -2.08   0.0372 *  Distance_to_lagoon
> >            -0.5029     1.3929   -0.36   0.7180    AMGP:Grass_height
> >                   2.9442     1.5142    1.94   0.0518 .
> > AMGP:Distance_to_lagoon               -2.4695     0.9632   -2.56
> > 0.0104 *  Grass_height:Distance_to_lagoon        0.0339     2.0065
> > 0.02   0.9865    AMGP:Grass_height:Distance_to_lagoon  -4.0363
> > 1.3264   -3.04   0.0023 ** ---Signif. codes:  0 ?***? 0.001 ?**? 0.01
> > ?*? 0.05 ?.? 0.1 ? ? 1
> > Number of observations: total=64, Field_name=16 Random effect
> > variance(s):Group=Field_name            Variance StdDev(Intercept)
> > 0.03721 0.1929
> > Negative binomial dispersion parameter: 20.633 (std. err.:
> > 7.4042)Zero-inflation: 1e-06  (std. err.:  6.8336e-09 )
> > Log-likelihood: -102
> >
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From steve.walker at utoronto.ca  Mon Aug 10 14:35:29 2015
From: steve.walker at utoronto.ca (Steve Walker)
Date: Mon, 10 Aug 2015 08:35:29 -0400
Subject: [R-sig-ME] Mixed model for count data with overdispersion
In-Reply-To: <CADGhagisridue8NPeMo46cULjKwx6GUVSo3FtmO-Ehy03=XmRA@mail.gmail.com>
References: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>	<CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>	<CADGhagh2E7JaEHGoLG1jdUTE8VHOhhbO6cftpB06SpiwyEu4Lw@mail.gmail.com>	<F6AF9039-92EF-4CFD-A722-55824AD2D908@gmail.com>
	<CADGhagisridue8NPeMo46cULjKwx6GUVSo3FtmO-Ehy03=XmRA@mail.gmail.com>
Message-ID: <55C89A91.7030205@utoronto.ca>

An alternative is to use glmer with `family=Poisson` and an 
observation-level random effect.  I only skimmed this paper, but it will 
hopefully put you on to the main idea:

https://peerj.com/articles/616/

Cheers,
Steve

On 2015-08-10 5:27 AM, Mehdi Abedi wrote:
> Thanks Chris for lectures,
> Working with MCMCglmm is like jumping from high school physics to Albert
> Einstein lectures:). Hopefully i can digest this as a ecologist this
> modeling part!
> All the best
>
> On Mon, Aug 10, 2015 at 1:46 PM, Christopher David Desjardins <
> cddesjardins at gmail.com> wrote:
>
>> Hi,
>>
>> You really should read about the MCMCglmm package before just using it.
>> There are a couple of vignettes which I strongly suggest that you read
>> prior to actually using MCMCglmm as they explain a lot.
>>
>> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf
>> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf
>>
>> Do note that you need to specify prior distributions or at least
>> understand the default ones.
>>
>> Chris
>>
>> On Aug 10, 2015, at 8:56 AM, Mehdi Abedi <abedimail at gmail.com> wrote:
>>
>> Thanks Manabu,
>> It is a bit complicated for me but If i have this data:
>> Parameter: Totalseedling
>> fixed effect: Heatsmoke, cold
>> random effect: plot
>>
>> I should do something like this?!
>>
>>
>> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random =
>> ~Plots,family="poisson", data = growthdata)
>> summary( Model1)
>> It looks i can not get anova() here for output as well?
>>
>>
>> I am not familiar with other details in the MCMCglmm:
>>
>> library( MCMCglmm)
>> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random = ~Plot,
>> + family = "poisson", data = growthdata, prior = prior,
>> + verbose = FALSE, pr = TRUE)
>>
>> Warm regards,
>> Mehdi
>>
>> On Mon, Aug 10, 2015 at 12:48 PM, Manabu Sakamoto <
>> manabu.sakamoto at gmail.com
>>
>> wrote:
>>
>>
>> Dear Mehdi,
>>
>> You can use the function MCMCglmm in the package of the same name,
>> specifying family="poisson". MCMCglmm automatically accounts for over
>> dispersion in count data.
>>
>> best regards,
>> Manabu
>>
>> On 10 August 2015 at 06:54, Mehdi Abedi <abedimail at gmail.com> wrote:
>>
>> Dear all,
>>
>> I had quick search but it looks there is no simple way in lme4 or  nlme In
>> the case of overdispersion for count data,. How we can run mixed model for
>> count data with family of quasipoisson or maybe NB?
>>
>> I my working on seeding emergence with 2 fixed factor (n=10) and i would
>> like to have my plot as replicate(n=5) as a random.
>>
>> Warm regards,
>> Mehdi
>>
>> --
>>
>>
>> *Mehdi Abedi Department of Range Management*
>>
>> *Faculty of Natural Resources & Marine Sciences *
>>
>> *Tarbiat Modares University (TMU) *
>>
>> *46417-76489, Noor*
>>
>> *Mazandaran, IRAN *
>>
>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>>
>> *Homepage
>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>
>> *Tel: +98-122-6253101 *
>>
>> *Fax: +98-122-6253499*
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>> --
>> Manabu Sakamoto, PhD
>> manabu.sakamoto at gmail.com
>>
>>
>>
>>
>> --
>>
>>
>> *Mehdi Abedi Department of Range Management*
>>
>> *Faculty of Natural Resources & Marine Sciences *
>>
>> *Tarbiat Modares University (TMU) *
>>
>> *46417-76489, Noor*
>>
>> *Mazandaran, IRAN *
>>
>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>>
>> *Homepage
>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>
>> *Tel: +98-122-6253101 *
>>
>> *Fax: +98-122-6253499*
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>


From paul.johnson at glasgow.ac.uk  Mon Aug 10 14:45:38 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Mon, 10 Aug 2015 12:45:38 +0000
Subject: [R-sig-ME] Mixed model for count data with overdispersion
In-Reply-To: <55C89A91.7030205@utoronto.ca>
References: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>
	<CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>
	<CADGhagh2E7JaEHGoLG1jdUTE8VHOhhbO6cftpB06SpiwyEu4Lw@mail.gmail.com>
	<F6AF9039-92EF-4CFD-A722-55824AD2D908@gmail.com>
	<CADGhagisridue8NPeMo46cULjKwx6GUVSo3FtmO-Ehy03=XmRA@mail.gmail.com>,
	<55C89A91.7030205@utoronto.ca>
Message-ID: <0756934B2C0D624DB20E135A92ACC52403F0B361@CMS12-01.campus.gla.ac.uk>

I'll second Steve's suggestion (which I think is the easiest, although assessing fit is tricky) and add another suggestion of fitting a negative binomial GLMM in glmmADMB.

Paul


Sent using CloudMagic<https://cloudmagic.com/k/d/mailapp?ct=pa&cv=7.0.42&pv=4.2.2>
On Mon, Aug 10, 2015 at 1:37 PM, Steve Walker <steve.walker at utoronto.ca<mailto:steve.walker at utoronto.ca>> wrote:


An alternative is to use glmer with `family=Poisson` and an
observation-level random effect.  I only skimmed this paper, but it will
hopefully put you on to the main idea:

https://peerj.com/articles/616/

Cheers,
Steve

On 2015-08-10 5:27 AM, Mehdi Abedi wrote:
> Thanks Chris for lectures,
> Working with MCMCglmm is like jumping from high school physics to Albert
> Einstein lectures:). Hopefully i can digest this as a ecologist this
> modeling part!
> All the best
>
> On Mon, Aug 10, 2015 at 1:46 PM, Christopher David Desjardins <
> cddesjardins at gmail.com> wrote:
>
>> Hi,
>>
>> You really should read about the MCMCglmm package before just using it.
>> There are a couple of vignettes which I strongly suggest that you read
>> prior to actually using MCMCglmm as they explain a lot.
>>
>> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf
>> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf
>>
>> Do note that you need to specify prior distributions or at least
>> understand the default ones.
>>
>> Chris
>>
>> On Aug 10, 2015, at 8:56 AM, Mehdi Abedi <abedimail at gmail.com> wrote:
>>
>> Thanks Manabu,
>> It is a bit complicated for me but If i have this data:
>> Parameter: Totalseedling
>> fixed effect: Heatsmoke, cold
>> random effect: plot
>>
>> I should do something like this?!
>>
>>
>> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random =
>> ~Plots,family="poisson", data = growthdata)
>> summary( Model1)
>> It looks i can not get anova() here for output as well?
>>
>>
>> I am not familiar with other details in the MCMCglmm:
>>
>> library( MCMCglmm)
>> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random = ~Plot,
>> + family = "poisson", data = growthdata, prior = prior,
>> + verbose = FALSE, pr = TRUE)
>>
>> Warm regards,
>> Mehdi
>>
>> On Mon, Aug 10, 2015 at 12:48 PM, Manabu Sakamoto <
>> manabu.sakamoto at gmail.com
>>
>> wrote:
>>
>>
>> Dear Mehdi,
>>
>> You can use the function MCMCglmm in the package of the same name,
>> specifying family="poisson". MCMCglmm automatically accounts for over
>> dispersion in count data.
>>
>> best regards,
>> Manabu
>>
>> On 10 August 2015 at 06:54, Mehdi Abedi <abedimail at gmail.com> wrote:
>>
>> Dear all,
>>
>> I had quick search but it looks there is no simple way in lme4 or  nlme In
>> the case of overdispersion for count data,. How we can run mixed model for
>> count data with family of quasipoisson or maybe NB?
>>
>> I my working on seeding emergence with 2 fixed factor (n=10) and i would
>> like to have my plot as replicate(n=5) as a random.
>>
>> Warm regards,
>> Mehdi
>>
>> --
>>
>>
>> *Mehdi Abedi Department of Range Management*
>>
>> *Faculty of Natural Resources & Marine Sciences *
>>
>> *Tarbiat Modares University (TMU) *
>>
>> *46417-76489, Noor*
>>
>> *Mazandaran, IRAN *
>>
>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>>
>> *Homepage
>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>
>> *Tel: +98-122-6253101 *
>>
>> *Fax: +98-122-6253499*
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>> --
>> Manabu Sakamoto, PhD
>> manabu.sakamoto at gmail.com
>>
>>
>>
>>
>> --
>>
>>
>> *Mehdi Abedi Department of Range Management*
>>
>> *Faculty of Natural Resources & Marine Sciences *
>>
>> *Tarbiat Modares University (TMU) *
>>
>> *46417-76489, Noor*
>>
>> *Mazandaran, IRAN *
>>
>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
>>
>> *Homepage
>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>
>> *Tel: +98-122-6253101 *
>>
>> *Fax: +98-122-6253499*
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From abedimail at gmail.com  Mon Aug 10 15:29:15 2015
From: abedimail at gmail.com (Mehdi Abedi)
Date: Mon, 10 Aug 2015 17:59:15 +0430
Subject: [R-sig-ME] Mixed model for count data with overdispersion
In-Reply-To: <0756934B2C0D624DB20E135A92ACC52403F0B361@CMS12-01.campus.gla.ac.uk>
References: <CADGhagiwZKFHnRKpMp-e9o_wVAMKhiibi6MkRFKFgtCWj64jrA@mail.gmail.com>
	<CAErHMT1ALrHKa4q2zj4GT1So1rD5u2d=11z+48ek-79KO_AACA@mail.gmail.com>
	<CADGhagh2E7JaEHGoLG1jdUTE8VHOhhbO6cftpB06SpiwyEu4Lw@mail.gmail.com>
	<F6AF9039-92EF-4CFD-A722-55824AD2D908@gmail.com>
	<CADGhagisridue8NPeMo46cULjKwx6GUVSo3FtmO-Ehy03=XmRA@mail.gmail.com>
	<55C89A91.7030205@utoronto.ca>
	<0756934B2C0D624DB20E135A92ACC52403F0B361@CMS12-01.campus.gla.ac.uk>
Message-ID: <CADGhagjmceoiL3esVVjoR4=Z07hcaFwui6DcVFR3bj5Y5Hv2Gg@mail.gmail.com>

Thanks Paul and Steve,
If i understood well you mean somethings like this!?:


library( glmmADMB)
Model2<- glmmadmb(Totalseedling~Heatsmoke *Cold+(1|Plots),data=growthdata,
family="nbinom1")
 summary(Model2)

Is it possible to get only main effect results with some function like
anova or similar in glmmADMB. I am mainly interested to only main effect(
Heatsmoke and Cold) than theirs levels results. I think anova function
doesn't play role in these advanced package :)
All the best,
Mehdi

On Mon, Aug 10, 2015 at 5:15 PM, Paul Johnson <paul.johnson at glasgow.ac.uk>
wrote:

> I'll second Steve's suggestion (which I think is the easiest, although
> assessing fit is tricky) and add another suggestion of fitting a negative
> binomial GLMM in glmmADMB.
>
> Paul
>
>
> Sent using CloudMagic
> <https://cloudmagic.com/k/d/mailapp?ct=pa&cv=7.0.42&pv=4.2.2>
> On Mon, Aug 10, 2015 at 1:37 PM, Steve Walker <steve.walker at utoronto.ca>
> wrote:
>
> An alternative is to use glmer with `family=Poisson` and an
> observation-level random effect.  I only skimmed this paper, but it will
> hopefully put you on to the main idea:
>
> https://peerj.com/articles/616/
>
> Cheers,
> Steve
>
> On 2015-08-10 5:27 AM, Mehdi Abedi wrote:
> > Thanks Chris for lectures,
> > Working with MCMCglmm is like jumping from high school physics to Albert
> > Einstein lectures:). Hopefully i can digest this as a ecologist this
> > modeling part!
> > All the best
> >
> > On Mon, Aug 10, 2015 at 1:46 PM, Christopher David Desjardins <
> > cddesjardins at gmail.com> wrote:
> >
> >> Hi,
> >>
> >> You really should read about the MCMCglmm package before just using it.
> >> There are a couple of vignettes which I strongly suggest that you read
> >> prior to actually using MCMCglmm as they explain a lot.
> >>
> >> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf
> >>
> https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf
> >>
> >> Do note that you need to specify prior distributions or at least
> >> understand the default ones.
> >>
> >> Chris
> >>
> >> On Aug 10, 2015, at 8:56 AM, Mehdi Abedi <abedimail at gmail.com> wrote:
> >>
> >> Thanks Manabu,
> >> It is a bit complicated for me but If i have this data:
> >> Parameter: Totalseedling
> >> fixed effect: Heatsmoke, cold
> >> random effect: plot
> >>
> >> I should do something like this?!
> >>
> >>
> >> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random =
> >> ~Plots,family="poisson", data = growthdata)
> >> summary( Model1)
> >> It looks i can not get anova() here for output as well?
> >>
> >>
> >> I am not familiar with other details in the MCMCglmm:
> >>
> >> library( MCMCglmm)
> >> Model1<- MCMCglmm(Totalseedling ~ Heatsmoke *Cold, random = ~Plot,
> >> + family = "poisson", data = growthdata, prior = prior,
> >> + verbose = FALSE, pr = TRUE)
> >>
> >> Warm regards,
> >> Mehdi
> >>
> >> On Mon, Aug 10, 2015 at 12:48 PM, Manabu Sakamoto <
> >> manabu.sakamoto at gmail.com
> >>
> >> wrote:
> >>
> >>
> >> Dear Mehdi,
> >>
> >> You can use the function MCMCglmm in the package of the same name,
> >> specifying family="poisson". MCMCglmm automatically accounts for over
> >> dispersion in count data.
> >>
> >> best regards,
> >> Manabu
> >>
> >> On 10 August 2015 at 06:54, Mehdi Abedi <abedimail at gmail.com> wrote:
> >>
> >> Dear all,
> >>
> >> I had quick search but it looks there is no simple way in lme4 or  nlme
> In
> >> the case of overdispersion for count data,. How we can run mixed model
> for
> >> count data with family of quasipoisson or maybe NB?
> >>
> >> I my working on seeding emergence with 2 fixed factor (n=10) and i
> would
> >> like to have my plot as replicate(n=5) as a random.
> >>
> >> Warm regards,
> >> Mehdi
> >>
> >> --
> >>
> >>
> >> *Mehdi Abedi Department of Range Management*
> >>
> >> *Faculty of Natural Resources & Marine Sciences *
> >>
> >> *Tarbiat Modares University (TMU) *
> >>
> >> *46417-76489, Noor*
> >>
> >> *Mazandaran, IRAN *
> >>
> >> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
> >>
> >> *Homepage
> >> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
> >>
> >> *Tel: +98-122-6253101 *
> >>
> >> *Fax: +98-122-6253499*
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >>
> >> --
> >> Manabu Sakamoto, PhD
> >> manabu.sakamoto at gmail.com
> >>
> >>
> >>
> >>
> >> --
> >>
> >>
> >> *Mehdi Abedi Department of Range Management*
> >>
> >> *Faculty of Natural Resources & Marine Sciences *
> >>
> >> *Tarbiat Modares University (TMU) *
> >>
> >> *46417-76489, Noor*
> >>
> >> *Mazandaran, IRAN *
> >>
> >> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*
> >>
> >> *Homepage
> >> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
> >>
> >> *Tel: +98-122-6253101 *
> >>
> >> *Fax: +98-122-6253499*
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at modares.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Mon Aug 10 16:30:18 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 10 Aug 2015 11:30:18 -0300
Subject: [R-sig-ME] interaction terms interpretation
In-Reply-To: <CAF5_5cwrHj0hCjWWJKsEYy6_=h1hi9Kqf=DN4OvpDVMuxmZmMA@mail.gmail.com>
References: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>
	<CAJuCY5wB_tNFuDmym_LFtk-T4eVt_YbJf9=z=YtRVmvGeZuHqA@mail.gmail.com>
	<CAF5_5cwrHj0hCjWWJKsEYy6_=h1hi9Kqf=DN4OvpDVMuxmZmMA@mail.gmail.com>
Message-ID: <CAMM93=J=wdqv+s=iiEAxP6GwA2XjNxx4kH53w1NCh_owDgU8Ow@mail.gmail.com>

Thankyoy very much Ken and Thierry. I'll try that. Is there any specific
function for making graphs of the model? I appreciate recommendations or
citations to explore how to graph model results. Thanks again. Joaquin
El 10/08/2015 07:36, "Ken Beath" <ken.beath at mq.edu.au> escribi?:

> There is actually a continuous third order interaction, which are just
> about impossible to interpret.
>
> As well as the graphs, which you always should start with, think about
> what is sensible for the model. Should any of the predictors be log-scaled?
> As AMGP is a count it wouldn't be surprising it it is, or use log(1+x) if
> there are zeroes.
>
> Look at diagnostic plots and make sure that everything is fine, especially
> that there are no outliers which might be causing the interaction.
>
> Ken
>
> On 10 August 2015 at 17:02, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Joaquin,
>>
>> Your mail is mangled because you send it in HTML. This makes the model
>> output very hard to read.
>>
>> It's impossible to interpret model output without thorough knowledge of
>> the
>> dataset. I suggest that you try to make some graphs of the model.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2015-08-07 21:27 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>
>> > Hi all, I?m running a mixed model with poisson error distribution as I
>> have
>> > count data of a shorebird species. My predictors are AMGP (another
>> > shorebird that is usually associated to "my" species and probably has
>> > ecological influence on it), grass height and field distance to the
>> lagoon.
>> >
>> > I?m having a hard time trying to interpret second order interactions. I
>> > appreciate your comments of references recommendations. Here is the
>> output
>> > of my model. All the best, Joaqu?n.
>> >
>> > Call:glmmadmb(formula = BBSA ~ AMGP * Grass_height *
>> > Distance_to_lagoon +     (1 | Field_name) + offset(log(Field_area.o)),
>> > data = my4S,     family = "nbinom1", zeroInflation = TRUE)
>> > AIC: 226
>> > Coefficients:                                     Estimate Std. Error
>> > z value Pr(>|z|)    (Intercept)                           -5.8797
>> > 1.2250   -4.80  1.6e-06 ***AMGP
>> > 3.3086     1.0246    3.23   0.0012 ** Grass_height
>> >      -4.1592     1.9961   -2.08   0.0372 *  Distance_to_lagoon
>> >            -0.5029     1.3929   -0.36   0.7180    AMGP:Grass_height
>> >                   2.9442     1.5142    1.94   0.0518 .
>> > AMGP:Distance_to_lagoon               -2.4695     0.9632   -2.56
>> > 0.0104 *  Grass_height:Distance_to_lagoon        0.0339     2.0065
>> > 0.02   0.9865    AMGP:Grass_height:Distance_to_lagoon  -4.0363
>> > 1.3264   -3.04   0.0023 ** ---Signif. codes:  0 ?***? 0.001 ?**? 0.01
>> > ?*? 0.05 ?.? 0.1 ? ? 1
>> > Number of observations: total=64, Field_name=16 Random effect
>> > variance(s):Group=Field_name            Variance StdDev(Intercept)
>> > 0.03721 0.1929
>> > Negative binomial dispersion parameter: 20.633 (std. err.:
>> > 7.4042)Zero-inflation: 1e-06  (std. err.:  6.8336e-09 )
>> > Log-likelihood: -102
>> >
>> >
>> > --
>> > *Joaqu?n Aldabe*
>> >
>> > *Grupo Biodiversidad, Ambiente y Sociedad*
>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >
>> > *Departamento de Conservaci?n*
>> > Aves Uruguay
>> > BirdLife International
>> > Canelones 1164, Montevideo
>> >
>> > https://sites.google.com/site/joaquin.aldabe
>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Level 2, AHH
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:12}}


From bbolker at gmail.com  Mon Aug 10 16:54:36 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 10 Aug 2015 10:54:36 -0400
Subject: [R-sig-ME] interaction terms interpretation
In-Reply-To: <CAMM93=J=wdqv+s=iiEAxP6GwA2XjNxx4kH53w1NCh_owDgU8Ow@mail.gmail.com>
References: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>
	<CAJuCY5wB_tNFuDmym_LFtk-T4eVt_YbJf9=z=YtRVmvGeZuHqA@mail.gmail.com>
	<CAF5_5cwrHj0hCjWWJKsEYy6_=h1hi9Kqf=DN4OvpDVMuxmZmMA@mail.gmail.com>
	<CAMM93=J=wdqv+s=iiEAxP6GwA2XjNxx4kH53w1NCh_owDgU8Ow@mail.gmail.com>
Message-ID: <CABghstR2+fJGTc_CNZCG40EuUnkh1AnjOLA=w79OreqBWj8NgA@mail.gmail.com>

Consider taking a look at
http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html .

On Mon, Aug 10, 2015 at 10:30 AM, Joaqu?n Aldabe
<joaquin.aldabe at gmail.com> wrote:
> Thankyoy very much Ken and Thierry. I'll try that. Is there any specific
> function for making graphs of the model? I appreciate recommendations or
> citations to explore how to graph model results. Thanks again. Joaquin
> El 10/08/2015 07:36, "Ken Beath" <ken.beath at mq.edu.au> escribi?:
>
>> There is actually a continuous third order interaction, which are just
>> about impossible to interpret.
>>
>> As well as the graphs, which you always should start with, think about
>> what is sensible for the model. Should any of the predictors be log-scaled?
>> As AMGP is a count it wouldn't be surprising it it is, or use log(1+x) if
>> there are zeroes.
>>
>> Look at diagnostic plots and make sure that everything is fine, especially
>> that there are no outliers which might be causing the interaction.
>>
>> Ken
>>
>> On 10 August 2015 at 17:02, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Joaquin,
>>>
>>> Your mail is mangled because you send it in HTML. This makes the model
>>> output very hard to read.
>>>
>>> It's impossible to interpret model output without thorough knowledge of
>>> the
>>> dataset. I suggest that you try to make some graphs of the model.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> 2015-08-07 21:27 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>>
>>> > Hi all, I?m running a mixed model with poisson error distribution as I
>>> have
>>> > count data of a shorebird species. My predictors are AMGP (another
>>> > shorebird that is usually associated to "my" species and probably has
>>> > ecological influence on it), grass height and field distance to the
>>> lagoon.
>>> >
>>> > I?m having a hard time trying to interpret second order interactions. I
>>> > appreciate your comments of references recommendations. Here is the
>>> output
>>> > of my model. All the best, Joaqu?n.
>>> >
>>> > Call:glmmadmb(formula = BBSA ~ AMGP * Grass_height *
>>> > Distance_to_lagoon +     (1 | Field_name) + offset(log(Field_area.o)),
>>> > data = my4S,     family = "nbinom1", zeroInflation = TRUE)
>>> > AIC: 226
>>> > Coefficients:                                     Estimate Std. Error
>>> > z value Pr(>|z|)    (Intercept)                           -5.8797
>>> > 1.2250   -4.80  1.6e-06 ***AMGP
>>> > 3.3086     1.0246    3.23   0.0012 ** Grass_height
>>> >      -4.1592     1.9961   -2.08   0.0372 *  Distance_to_lagoon
>>> >            -0.5029     1.3929   -0.36   0.7180    AMGP:Grass_height
>>> >                   2.9442     1.5142    1.94   0.0518 .
>>> > AMGP:Distance_to_lagoon               -2.4695     0.9632   -2.56
>>> > 0.0104 *  Grass_height:Distance_to_lagoon        0.0339     2.0065
>>> > 0.02   0.9865    AMGP:Grass_height:Distance_to_lagoon  -4.0363
>>> > 1.3264   -3.04   0.0023 ** ---Signif. codes:  0 ?***? 0.001 ?**? 0.01
>>> > ?*? 0.05 ?.? 0.1 ? ? 1
>>> > Number of observations: total=64, Field_name=16 Random effect
>>> > variance(s):Group=Field_name            Variance StdDev(Intercept)
>>> > 0.03721 0.1929
>>> > Negative binomial dispersion parameter: 20.633 (std. err.:
>>> > 7.4042)Zero-inflation: 1e-06  (std. err.:  6.8336e-09 )
>>> > Log-likelihood: -102
>>> >
>>> >
>>> > --
>>> > *Joaqu?n Aldabe*
>>> >
>>> > *Grupo Biodiversidad, Ambiente y Sociedad*
>>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>> >
>>> > *Departamento de Conservaci?n*
>>> > Aves Uruguay
>>> > BirdLife International
>>> > Canelones 1164, Montevideo
>>> >
>>> > https://sites.google.com/site/joaquin.aldabe
>>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>>
>> *Ken Beath*
>> Lecturer
>> Statistics Department
>> MACQUARIE UNIVERSITY NSW 2109, Australia
>>
>> Phone: +61 (0)2 9850 8516
>>
>> Level 2, AHH
>> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>>
>> CRICOS Provider No 00002J
>> This message is intended for the addressee named and m...{{dropped:12}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From joaquin.aldabe at gmail.com  Mon Aug 10 16:58:58 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 10 Aug 2015 11:58:58 -0300
Subject: [R-sig-ME] interaction terms interpretation
In-Reply-To: <CABghstR2+fJGTc_CNZCG40EuUnkh1AnjOLA=w79OreqBWj8NgA@mail.gmail.com>
References: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>
	<CAJuCY5wB_tNFuDmym_LFtk-T4eVt_YbJf9=z=YtRVmvGeZuHqA@mail.gmail.com>
	<CAF5_5cwrHj0hCjWWJKsEYy6_=h1hi9Kqf=DN4OvpDVMuxmZmMA@mail.gmail.com>
	<CAMM93=J=wdqv+s=iiEAxP6GwA2XjNxx4kH53w1NCh_owDgU8Ow@mail.gmail.com>
	<CABghstR2+fJGTc_CNZCG40EuUnkh1AnjOLA=w79OreqBWj8NgA@mail.gmail.com>
Message-ID: <CAMM93=JEJW=RdYWmFXvU+Z9UxtA5iTJ85FcGtDDXE_z4pNHkBg@mail.gmail.com>

Thankyou Ben! It looks great. Cheers
El 10/08/2015 11:54, "Ben Bolker" <bbolker at gmail.com> escribi?:

> Consider taking a look at
> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html .
>
> On Mon, Aug 10, 2015 at 10:30 AM, Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com> wrote:
> > Thankyoy very much Ken and Thierry. I'll try that. Is there any specific
> > function for making graphs of the model? I appreciate recommendations or
> > citations to explore how to graph model results. Thanks again. Joaquin
> > El 10/08/2015 07:36, "Ken Beath" <ken.beath at mq.edu.au> escribi?:
> >
> >> There is actually a continuous third order interaction, which are just
> >> about impossible to interpret.
> >>
> >> As well as the graphs, which you always should start with, think about
> >> what is sensible for the model. Should any of the predictors be
> log-scaled?
> >> As AMGP is a count it wouldn't be surprising it it is, or use log(1+x)
> if
> >> there are zeroes.
> >>
> >> Look at diagnostic plots and make sure that everything is fine,
> especially
> >> that there are no outliers which might be causing the interaction.
> >>
> >> Ken
> >>
> >> On 10 August 2015 at 17:02, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> >> wrote:
> >>
> >>> Dear Joaquin,
> >>>
> >>> Your mail is mangled because you send it in HTML. This makes the model
> >>> output very hard to read.
> >>>
> >>> It's impossible to interpret model output without thorough knowledge of
> >>> the
> >>> dataset. I suggest that you try to make some graphs of the model.
> >>>
> >>> Best regards,
> >>>
> >>> ir. Thierry Onkelinx
> >>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> >>> Forest
> >>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >>> Kliniekstraat 25
> >>> 1070 Anderlecht
> >>> Belgium
> >>>
> >>> To call in the statistician after the experiment is done may be no more
> >>> than asking him to perform a post-mortem examination: he may be able to
> >>> say
> >>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>> The plural of anecdote is not data. ~ Roger Brinner
> >>> The combination of some data and an aching desire for an answer does
> not
> >>> ensure that a reasonable answer can be extracted from a given body of
> >>> data.
> >>> ~ John Tukey
> >>>
> >>> 2015-08-07 21:27 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
> >>>
> >>> > Hi all, I?m running a mixed model with poisson error distribution as
> I
> >>> have
> >>> > count data of a shorebird species. My predictors are AMGP (another
> >>> > shorebird that is usually associated to "my" species and probably has
> >>> > ecological influence on it), grass height and field distance to the
> >>> lagoon.
> >>> >
> >>> > I?m having a hard time trying to interpret second order
> interactions. I
> >>> > appreciate your comments of references recommendations. Here is the
> >>> output
> >>> > of my model. All the best, Joaqu?n.
> >>> >
> >>> > Call:glmmadmb(formula = BBSA ~ AMGP * Grass_height *
> >>> > Distance_to_lagoon +     (1 | Field_name) +
> offset(log(Field_area.o)),
> >>> > data = my4S,     family = "nbinom1", zeroInflation = TRUE)
> >>> > AIC: 226
> >>> > Coefficients:                                     Estimate Std. Error
> >>> > z value Pr(>|z|)    (Intercept)                           -5.8797
> >>> > 1.2250   -4.80  1.6e-06 ***AMGP
> >>> > 3.3086     1.0246    3.23   0.0012 ** Grass_height
> >>> >      -4.1592     1.9961   -2.08   0.0372 *  Distance_to_lagoon
> >>> >            -0.5029     1.3929   -0.36   0.7180    AMGP:Grass_height
> >>> >                   2.9442     1.5142    1.94   0.0518 .
> >>> > AMGP:Distance_to_lagoon               -2.4695     0.9632   -2.56
> >>> > 0.0104 *  Grass_height:Distance_to_lagoon        0.0339     2.0065
> >>> > 0.02   0.9865    AMGP:Grass_height:Distance_to_lagoon  -4.0363
> >>> > 1.3264   -3.04   0.0023 ** ---Signif. codes:  0 ?***? 0.001 ?**? 0.01
> >>> > ?*? 0.05 ?.? 0.1 ? ? 1
> >>> > Number of observations: total=64, Field_name=16 Random effect
> >>> > variance(s):Group=Field_name            Variance StdDev(Intercept)
> >>> > 0.03721 0.1929
> >>> > Negative binomial dispersion parameter: 20.633 (std. err.:
> >>> > 7.4042)Zero-inflation: 1e-06  (std. err.:  6.8336e-09 )
> >>> > Log-likelihood: -102
> >>> >
> >>> >
> >>> > --
> >>> > *Joaqu?n Aldabe*
> >>> >
> >>> > *Grupo Biodiversidad, Ambiente y Sociedad*
> >>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> >>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >>> >
> >>> > *Departamento de Conservaci?n*
> >>> > Aves Uruguay
> >>> > BirdLife International
> >>> > Canelones 1164, Montevideo
> >>> >
> >>> > https://sites.google.com/site/joaquin.aldabe
> >>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > _______________________________________________
> >>> > R-sig-mixed-models at r-project.org mailing list
> >>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>> >
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >>
> >> --
> >>
> >> *Ken Beath*
> >> Lecturer
> >> Statistics Department
> >> MACQUARIE UNIVERSITY NSW 2109, Australia
> >>
> >> Phone: +61 (0)2 9850 8516
> >>
> >> Level 2, AHH
> >> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
> >>
> >> CRICOS Provider No 00002J
> >> This message is intended for the addressee named and m...{{dropped:12}}
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From alexandre.m.martin at gmail.com  Mon Aug 10 19:15:34 2015
From: alexandre.m.martin at gmail.com (Alexandre Martin)
Date: Mon, 10 Aug 2015 13:15:34 -0400
Subject: [R-sig-ME] covariance problems in MCMCglmm. genetic effects and
	multiple membership
Message-ID: <01ad01d0d390$2ba2df30$82e89d90$@gmail.com>

Dear Szymek, 

Thank you again for your contribution with your last answer. 

I am wondering now how to write the model to estimate the covariance between
the ?mm(?)? and the ?animal? random parts. 

Jarrod wrote in this thread
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q4/017034.html) about
maternal genetic effects : ?it is not yet possible to fit the covariance
between maternal genetic and direct genetic effects?

Since my model is similar to that described in the thread, is it still
impossible to fit a model to assess the covariance between direct and
indirect genetic effects in a way similar to that in ASReml as follow?

 

For y =Xb + Z1animal + Z2maternal + e 

Analysis of some kind

anim !P                       # The variable ?anim? is related to a pedigree
fil

dam !P                        # The variable ?dam? is related to a pedigree
file

dage 10 !A

rt 6 

wwt

grp 322 !A

example.ped

example.dat

wwt ~ mu rt dage !r anim dam !f grp 

0 0 1 

anim 2 

2 0 US !GP

.2 0 .15 

anim o AINV

 

 

Best 

 

Alexandre

 

 

De : Szymek Drobniak [mailto:szymek.drobniak at uj.edu.pl] 
Envoy? : 14 mai 2015 17:39
? : r-sig-mixed-models at r-project.org
Cc : alexandre.m.martin at gmail.com
Objet : Re: genetic effects and multiple membership in MCMCglmm (Alexandre
Martin)

 

Hello Alexandre,

 

using ped assigns a given correlation structure only to the "animal" random
effect. You have to create an inverse of A matrix:

 

my_inverse <- inverseA(ped)$Ainv

 

and assign it in MCMCglmm to specific random effects:

 

MCMCglmm(Y~1,
random=~animal+mm(m1+m2+m3),

ginverse=list(animal=my_inverse, m1=my_inverse,
m2=my_inverse,m3=my_inverse), data=dat, pr=T).

 

Cheers

Szymek


	[[alternative HTML version deleted]]


From pfabuel at gmail.com  Sat Aug  8 12:07:55 2015
From: pfabuel at gmail.com (Francisco Fabuel)
Date: Sat, 8 Aug 2015 12:07:55 +0200
Subject: [R-sig-ME] Fwd: Model failed to converge in bootMer
In-Reply-To: <CA+DOucG_tuHz6qrofe20yhDzepwGr=wkdZXPkObOk0tAC-3i=g@mail.gmail.com>
References: <CA+DOucFdU_kxguTB5MQoxJoC8gjB_E8TeE6er9bpfNfTXi7GgQ@mail.gmail.com>
	<CABghstTL2_KcNhJsJEBBq79G4FBCGinD7ZxH-15zk31ORkyN2g@mail.gmail.com>
	<CA+DOucG_tuHz6qrofe20yhDzepwGr=wkdZXPkObOk0tAC-3i=g@mail.gmail.com>
Message-ID: <CA+DOucGS9S=eQ=RC1cSuqUVy4sxqt963c5iG53UhSyRuzBA58w@mail.gmail.com>

Hi all:

In the following link of Dropbox you can find two archives (script and
data) that cause the problem.


https://www.dropbox.com/sh/pnnqg41wf6mwvum/AAB1uCdKLcsS87v4vxra8tOla?dl=0

Francisco Fabuel






2015-07-21 13:37 GMT+02:00 Ben Bolker <bbolker at gmail.com>:

> Please forward this question to r-sig-mixed-models at r-project.org.  Are
> you using the latest CRAN version (1.1-8) of lme4?
>
>   Ben Bolker
>
>
> On Tue, Jul 21, 2015 at 3:33 AM, Francisco Fabuel <pfabuel at gmail.com>
> wrote:
> > Mr. Bolker:
> >
> > I'm trying to estimate some quantities derived from a lmer object using
> > bootstrap. When I use the function bootMer, a large proportion of
> > replications seems to fail to converge, but if I program the bootstrap
> > using package boot, everything seems go well.
> >
> > Please, find attached a simple example (R script and data) of the
> problem:
> > with bootMer in 10 simulations, I've got 7 warnings:
> >
> > Warning messages:
> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> >   Model failed to converge with max|grad| = 0.00132463 (tol = 0.001,
> > component 1)
> >
> >
> > Thank you in advance.
> > Francisco Fabuel
>

	[[alternative HTML version deleted]]


From szymek.drobniak at uj.edu.pl  Mon Aug 10 19:27:32 2015
From: szymek.drobniak at uj.edu.pl (Szymek Drobniak)
Date: Mon, 10 Aug 2015 17:27:32 +0000
Subject: [R-sig-ME] covariance problems in MCMCglmm. genetic effects and
 multiple membership
In-Reply-To: <01ad01d0d390$2ba2df30$82e89d90$@gmail.com>
References: <01ad01d0d390$2ba2df30$82e89d90$@gmail.com>
Message-ID: <CANXb-o4DtkTVEHRN89HL6FQDDpzxoc1kfzCfi+2PNuOLRyXiew@mail.gmail.com>

Hi Unfortunately this is not possible as far as Know but please someone
correct me if I'm wrong - MCMCglmm cannot use design matrices of necessary
form for random effects. you'll have to use asreml - or asreml-r which has
syntax similar to MCMCGLMM.

Cheers
Szymek
W dniu pon., 10 sie 2015 o 19:15 Alexandre Martin <
alexandre.m.martin at gmail.com> napisa?(a):

> Dear Szymek,
>
> Thank you again for your contribution with your last answer.
>
> I am wondering now how to write the model to estimate the covariance
> between the ?mm(?)? and the ?animal? random parts.
>
> Jarrod wrote in this thread (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q4/017034.html) about maternal genetic effects : ?*it is not yet possible to fit the covariance between maternal genetic and direct genetic effects*?
>
> Since my model is similar to that described in the thread, is it still
> impossible to fit a model to assess the covariance between direct and
> indirect genetic effects in a way similar to that in ASReml as follow?
>
>
>
> For y =Xb + Z1animal + Z2maternal + e
>
> Analysis of some kind
>
> anim !P                       # The variable ?anim? is related to a
> pedigree fil
>
> dam !P                        # The variable ?dam? is related to a
> pedigree file
>
> dage 10 !A
>
> rt 6
>
> wwt
>
> grp 322 !A
>
> example.ped
>
> example.dat
>
> wwt ~ mu rt dage !r anim dam !f grp
>
> 0 0 1
>
> anim 2
>
> 2 0 US !GP
>
> .2 0 .15
>
> anim o AINV
>
>
>
>
>
> Best
>
>
>
> Alexandre
>
>
>
>
>
> *De :* Szymek Drobniak [mailto:szymek.drobniak at uj.edu.pl]
> *Envoy? :* 14 mai 2015 17:39
> *? :* r-sig-mixed-models at r-project.org
> *Cc :* alexandre.m.martin at gmail.com
> *Objet :* Re: genetic effects and multiple membership in MCMCglmm
> (Alexandre Martin)
>
>
>
> Hello Alexandre,
>
>
>
> using ped assigns a given correlation structure only to the "animal"
> random effect. You have to create an inverse of A matrix:
>
>
>
> my_inverse <- inverseA(ped)$Ainv
>
>
>
> and assign it in MCMCglmm to specific random effects:
>
>
>
> MCMCglmm(Y~1,
> random=~animal+mm(m1+m2+m3),
>
> ginverse=list(animal=my_inverse, m1=my_inverse,
> m2=my_inverse,m3=my_inverse), data=dat, pr=T).
>
>
>
> Cheers
>
> Szymek
>

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Mon Aug 10 21:44:59 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 10 Aug 2015 16:44:59 -0300
Subject: [R-sig-ME] interaction terms interpretation
In-Reply-To: <CAMM93=JEJW=RdYWmFXvU+Z9UxtA5iTJ85FcGtDDXE_z4pNHkBg@mail.gmail.com>
References: <CAMM93=LwSqy6zPf=Y2Vz4BrNdORPgQAben69sjzkanJkZzURZQ@mail.gmail.com>
	<CAJuCY5wB_tNFuDmym_LFtk-T4eVt_YbJf9=z=YtRVmvGeZuHqA@mail.gmail.com>
	<CAF5_5cwrHj0hCjWWJKsEYy6_=h1hi9Kqf=DN4OvpDVMuxmZmMA@mail.gmail.com>
	<CAMM93=J=wdqv+s=iiEAxP6GwA2XjNxx4kH53w1NCh_owDgU8Ow@mail.gmail.com>
	<CABghstR2+fJGTc_CNZCG40EuUnkh1AnjOLA=w79OreqBWj8NgA@mail.gmail.com>
	<CAMM93=JEJW=RdYWmFXvU+Z9UxtA5iTJ85FcGtDDXE_z4pNHkBg@mail.gmail.com>
Message-ID: <CAMM93=KdpMSwOeictRK2gm7R=HnwQ70ZN6WrvaRfA-hr9ArsDw@mail.gmail.com>

Thierry, Ken and Ben, I'm following your useful recommendations. Just in
case, I'm attaching the model output in a correct format so that you can
see it.

Best,
Joaqu?n

2015-08-10 11:58 GMT-03:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Thankyou Ben! It looks great. Cheers
> El 10/08/2015 11:54, "Ben Bolker" <bbolker at gmail.com> escribi?:
>
>> Consider taking a look at
>> http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html .
>>
>> On Mon, Aug 10, 2015 at 10:30 AM, Joaqu?n Aldabe
>> <joaquin.aldabe at gmail.com> wrote:
>> > Thankyoy very much Ken and Thierry. I'll try that. Is there any specific
>> > function for making graphs of the model? I appreciate recommendations or
>> > citations to explore how to graph model results. Thanks again. Joaquin
>> > El 10/08/2015 07:36, "Ken Beath" <ken.beath at mq.edu.au> escribi?:
>> >
>> >> There is actually a continuous third order interaction, which are just
>> >> about impossible to interpret.
>> >>
>> >> As well as the graphs, which you always should start with, think about
>> >> what is sensible for the model. Should any of the predictors be
>> log-scaled?
>> >> As AMGP is a count it wouldn't be surprising it it is, or use log(1+x)
>> if
>> >> there are zeroes.
>> >>
>> >> Look at diagnostic plots and make sure that everything is fine,
>> especially
>> >> that there are no outliers which might be causing the interaction.
>> >>
>> >> Ken
>> >>
>> >> On 10 August 2015 at 17:02, Thierry Onkelinx <thierry.onkelinx at inbo.be
>> >
>> >> wrote:
>> >>
>> >>> Dear Joaquin,
>> >>>
>> >>> Your mail is mangled because you send it in HTML. This makes the model
>> >>> output very hard to read.
>> >>>
>> >>> It's impossible to interpret model output without thorough knowledge
>> of
>> >>> the
>> >>> dataset. I suggest that you try to make some graphs of the model.
>> >>>
>> >>> Best regards,
>> >>>
>> >>> ir. Thierry Onkelinx
>> >>> Instituut voor natuur- en bosonderzoek / Research Institute for
>> Nature and
>> >>> Forest
>> >>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> >>> Kliniekstraat 25
>> >>> 1070 Anderlecht
>> >>> Belgium
>> >>>
>> >>> To call in the statistician after the experiment is done may be no
>> more
>> >>> than asking him to perform a post-mortem examination: he may be able
>> to
>> >>> say
>> >>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >>> The plural of anecdote is not data. ~ Roger Brinner
>> >>> The combination of some data and an aching desire for an answer does
>> not
>> >>> ensure that a reasonable answer can be extracted from a given body of
>> >>> data.
>> >>> ~ John Tukey
>> >>>
>> >>> 2015-08-07 21:27 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>> >>>
>> >>> > Hi all, I?m running a mixed model with poisson error distribution
>> as I
>> >>> have
>> >>> > count data of a shorebird species. My predictors are AMGP (another
>> >>> > shorebird that is usually associated to "my" species and probably
>> has
>> >>> > ecological influence on it), grass height and field distance to the
>> >>> lagoon.
>> >>> >
>> >>> > I?m having a hard time trying to interpret second order
>> interactions. I
>> >>> > appreciate your comments of references recommendations. Here is the
>> >>> output
>> >>> > of my model. All the best, Joaqu?n.
>> >>> >
>> >>> > Call:glmmadmb(formula = BBSA ~ AMGP * Grass_height *
>> >>> > Distance_to_lagoon +     (1 | Field_name) +
>> offset(log(Field_area.o)),
>> >>> > data = my4S,     family = "nbinom1", zeroInflation = TRUE)
>> >>> > AIC: 226
>> >>> > Coefficients:                                     Estimate Std.
>> Error
>> >>> > z value Pr(>|z|)    (Intercept)                           -5.8797
>> >>> > 1.2250   -4.80  1.6e-06 ***AMGP
>> >>> > 3.3086     1.0246    3.23   0.0012 ** Grass_height
>> >>> >      -4.1592     1.9961   -2.08   0.0372 *  Distance_to_lagoon
>> >>> >            -0.5029     1.3929   -0.36   0.7180    AMGP:Grass_height
>> >>> >                   2.9442     1.5142    1.94   0.0518 .
>> >>> > AMGP:Distance_to_lagoon               -2.4695     0.9632   -2.56
>> >>> > 0.0104 *  Grass_height:Distance_to_lagoon        0.0339     2.0065
>> >>> > 0.02   0.9865    AMGP:Grass_height:Distance_to_lagoon  -4.0363
>> >>> > 1.3264   -3.04   0.0023 ** ---Signif. codes:  0 ?***? 0.001 ?**?
>> 0.01
>> >>> > ?*? 0.05 ?.? 0.1 ? ? 1
>> >>> > Number of observations: total=64, Field_name=16 Random effect
>> >>> > variance(s):Group=Field_name            Variance StdDev(Intercept)
>> >>> > 0.03721 0.1929
>> >>> > Negative binomial dispersion parameter: 20.633 (std. err.:
>> >>> > 7.4042)Zero-inflation: 1e-06  (std. err.:  6.8336e-09 )
>> >>> > Log-likelihood: -102
>> >>> >
>> >>> >
>> >>> > --
>> >>> > *Joaqu?n Aldabe*
>> >>> >
>> >>> > *Grupo Biodiversidad, Ambiente y Sociedad*
>> >>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> >>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >>> >
>> >>> > *Departamento de Conservaci?n*
>> >>> > Aves Uruguay
>> >>> > BirdLife International
>> >>> > Canelones 1164, Montevideo
>> >>> >
>> >>> > https://sites.google.com/site/joaquin.aldabe
>> >>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> >>> >
>> >>> >         [[alternative HTML version deleted]]
>> >>> >
>> >>> > _______________________________________________
>> >>> > R-sig-mixed-models at r-project.org mailing list
>> >>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>> >
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >>
>> >>
>> >> --
>> >>
>> >> *Ken Beath*
>> >> Lecturer
>> >> Statistics Department
>> >> MACQUARIE UNIVERSITY NSW 2109, Australia
>> >>
>> >> Phone: +61 (0)2 9850 8516
>> >>
>> >> Level 2, AHH
>> >> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>> >>
>> >> CRICOS Provider No 00002J
>> >> This message is intended for the addressee named and m...{{dropped:12}}
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

From Subhash.Chandra at ecodev.vic.gov.au  Tue Aug 11 00:42:20 2015
From: Subhash.Chandra at ecodev.vic.gov.au (Subhash.Chandra at ecodev.vic.gov.au)
Date: Tue, 11 Aug 2015 08:42:20 +1000
Subject: [R-sig-ME] A question about LME4
Message-ID: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>

Appreciate your help and advice on (hopefully a simple) question. This 
relates to the mathematical expressions that LME4 uses to estimate log 
likelihood under maximum likelihood (ML) and under residual maximum 
likelihood (ReML) for fitting linear mixed models (LMM). What I am 
'exactly' looking for is mathematical expressions for log likelihood in 
the form of expressions (2), (4) and (5) in the attached paper by Gurka 
(2006).
 


I have gone through the LME4 documentation
https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf

I must admit I am unable to figure out the answer to my question. 

Regards,
Subhash

Dr Subhash Chandra | Chief Biometrician
Agriculture Research & Development Division
Department of Economic Development, Jobs, Transport & Resources
255 Ferguson Road, Tatura 3616, Victoria, Australia
T:  03 5833 5397 | M: 0427 277 560 | E: Subhash.Chandra at ecodev.vic.gov.au


********************************************************************************
Department of Economic Development, Jobs, Transport and Resources, Government of
Victoria, Victoria, Australia.

This email, and any attachments, may contain privileged and confidential
information.  If you are not the intended recipient, you may not distribute or
reproduce this e-mail or the attachments.  If you have received this message in
error, please notify us by return email.
********************************************************************************

From hughes.dupond at gmx.de  Tue Aug 11 17:37:12 2015
From: hughes.dupond at gmx.de (Lionel)
Date: Tue, 11 Aug 2015 17:37:12 +0200
Subject: [R-sig-ME] A question about LME4
In-Reply-To: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>
References: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>
Message-ID: <55CA16A8.7080403@gmx.de>

Dear Subash,

Can't see the attached paper that you mention but this paper: 
http://arxiv.org/abs/1406.5823 should give you what you are looking for.

Yours,
Lionel

On 11/08/2015 00:42, Subhash.Chandra at ecodev.vic.gov.au wrote:
> Appreciate your help and advice on (hopefully a simple) question. This
> relates to the mathematical expressions that LME4 uses to estimate log
> likelihood under maximum likelihood (ML) and under residual maximum
> likelihood (ReML) for fitting linear mixed models (LMM). What I am
> 'exactly' looking for is mathematical expressions for log likelihood in
> the form of expressions (2), (4) and (5) in the attached paper by Gurka
> (2006).
>   
>
>
> I have gone through the LME4 documentation
> https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
> https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf
>
> I must admit I am unable to figure out the answer to my question.
>
> Regards,
> Subhash
>
> Dr Subhash Chandra | Chief Biometrician
> Agriculture Research & Development Division
> Department of Economic Development, Jobs, Transport & Resources
> 255 Ferguson Road, Tatura 3616, Victoria, Australia
> T:  03 5833 5397 | M: 0427 277 560 | E: Subhash.Chandra at ecodev.vic.gov.au
>
>
> ********************************************************************************
> Department of Economic Development, Jobs, Transport and Resources, Government of
> Victoria, Victoria, Australia.
>
> This email, and any attachments, may contain privileged and confidential
> information.  If you are not the intended recipient, you may not distribute or
> reproduce this e-mail or the attachments.  If you have received this message in
> error, please notify us by return email.
> ********************************************************************************
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Tue Aug 11 17:37:08 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 11 Aug 2015 15:37:08 +0000
Subject: [R-sig-ME] A question about LME4
In-Reply-To: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>
References: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>
Message-ID: <CAO7JsnTT1_oJ2zsJZiPhS0gnj8ARgXuTDJGRQq-5WAVQA12OFg@mail.gmail.com>

As Ben mentioned in his off-list reply to you, the paper
http://arxiv.org/abs/1406.5823 describes in some detail the computational
methods that are used in lme4.  The fact that they don't correspond to
those in the 2006 paper by Gurka in The American Statistician is not an
oversight.  They are quite superior to any methods based on the equations
in that paper, as they should be.  We have spent the last 20 years or so
developing them.

On Tue, Aug 11, 2015 at 10:31 AM <Subhash.Chandra at ecodev.vic.gov.au> wrote:

> Appreciate your help and advice on (hopefully a simple) question. This
> relates to the mathematical expressions that LME4 uses to estimate log
> likelihood under maximum likelihood (ML) and under residual maximum
> likelihood (ReML) for fitting linear mixed models (LMM). What I am
> 'exactly' looking for is mathematical expressions for log likelihood in
> the form of expressions (2), (4) and (5) in the attached paper by Gurka
> (2006).
>
>
>
> I have gone through the LME4 documentation
> https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
> https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf
>
> I must admit I am unable to figure out the answer to my question.
>
> Regards,
> Subhash
>
> Dr Subhash Chandra | Chief Biometrician
> Agriculture Research & Development Division
> Department of Economic Development, Jobs, Transport & Resources
> 255 Ferguson Road, Tatura 3616, Victoria, Australia
> T:  03 5833 5397 | M: 0427 277 560 | E: Subhash.Chandra at ecodev.vic.gov.au
>
>
>
> ********************************************************************************
> Department of Economic Development, Jobs, Transport and Resources,
> Government of
> Victoria, Victoria, Australia.
>
> This email, and any attachments, may contain privileged and confidential
> information.  If you are not the intended recipient, you may not
> distribute or
> reproduce this e-mail or the attachments.  If you have received this
> message in
> error, please notify us by return email.
>
> ********************************************************************************
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From steve.walker at utoronto.ca  Tue Aug 11 19:05:45 2015
From: steve.walker at utoronto.ca (Steve Walker)
Date: Tue, 11 Aug 2015 13:05:45 -0400
Subject: [R-sig-ME] A question about LME4
In-Reply-To: <CAO7JsnTT1_oJ2zsJZiPhS0gnj8ARgXuTDJGRQq-5WAVQA12OFg@mail.gmail.com>
References: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>
	<CAO7JsnTT1_oJ2zsJZiPhS0gnj8ARgXuTDJGRQq-5WAVQA12OFg@mail.gmail.com>
Message-ID: <55CA2B69.4060701@utoronto.ca>

On 2015-08-11 11:37 AM, Douglas Bates wrote:
> As Ben mentioned in his off-list reply to you, the paper
> http://arxiv.org/abs/1406.5823 describes in some detail the computational
> methods that are used in lme4.

This arxiv paper (in press at JSS) is pretty long, although hopefully 
comprehensive.  To help pinpoint things a bit check out equations 34 and 
41.  These give the ML and REML criteria (on the deviance scale) that 
are used within lmer.

> The fact that they don't correspond to
> those in the 2006 paper by Gurka in The American Statistician is not an
> oversight.  They are quite superior to any methods based on the equations
> in that paper, as they should be.  We have spent the last 20 years or so
> developing them.

To expand on these remarks a bit, both the fixed effects coefficient 
vector and residual variance parameter are profiled out, which makes 
computations more efficient.  Also, correlations among random effects 
are partly accounted for in these equations using the log determinant of 
a sparse Cholesky factor, which is very efficiently updated over 
iterations of the nonlinear optimizer.

Cheers,
Steve

>
> On Tue, Aug 11, 2015 at 10:31 AM <Subhash.Chandra at ecodev.vic.gov.au> wrote:
>
>> Appreciate your help and advice on (hopefully a simple) question. This
>> relates to the mathematical expressions that LME4 uses to estimate log
>> likelihood under maximum likelihood (ML) and under residual maximum
>> likelihood (ReML) for fitting linear mixed models (LMM). What I am
>> 'exactly' looking for is mathematical expressions for log likelihood in
>> the form of expressions (2), (4) and (5) in the attached paper by Gurka
>> (2006).
>>
>>
>>
>> I have gone through the LME4 documentation
>> https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
>> https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf
>>
>> I must admit I am unable to figure out the answer to my question.
>>
>> Regards,
>> Subhash
>>
>> Dr Subhash Chandra | Chief Biometrician
>> Agriculture Research & Development Division
>> Department of Economic Development, Jobs, Transport & Resources
>> 255 Ferguson Road, Tatura 3616, Victoria, Australia
>> T:  03 5833 5397 | M: 0427 277 560 | E: Subhash.Chandra at ecodev.vic.gov.au
>>
>>
>>
>> ********************************************************************************
>> Department of Economic Development, Jobs, Transport and Resources,
>> Government of
>> Victoria, Victoria, Australia.
>>
>> This email, and any attachments, may contain privileged and confidential
>> information.  If you are not the intended recipient, you may not
>> distribute or
>> reproduce this e-mail or the attachments.  If you have received this
>> message in
>> error, please notify us by return email.
>>
>> ********************************************************************************
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From Subhash.Chandra at ecodev.vic.gov.au  Wed Aug 12 01:56:53 2015
From: Subhash.Chandra at ecodev.vic.gov.au (Subhash.Chandra at ecodev.vic.gov.au)
Date: Wed, 12 Aug 2015 09:56:53 +1000
Subject: [R-sig-ME] A question about LME4
In-Reply-To: <55CA2B69.4060701@utoronto.ca>
References: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>
	<CAO7JsnTT1_oJ2zsJZiPhS0gnj8ARgXuTDJGRQq-5WAVQA12OFg@mail.gmail.com>
	<55CA2B69.4060701@utoronto.ca>
Message-ID: <OFF3655694.9DE48FB4-ONCA257E9E.0081BCA5-CA257E9E.00838D58@cenitex.vic.gov.au>

Thanks everyone for their advice. Looks like I did not phrase my question 
correctly. My apologies to waste your time. First, to clarify what Douglas 
wrote, I was not questioning the correctness of your approach. The 
question that I intended to really ask is: 

Does LME4 use the complete log residual likelihood in Gurka's equation 
(4)? If not, what does it omit from equation (4), for example, equation 
(5) in Gurka's paper that SAS uses by omitting a constant? As regards the 
log likelihood, I assume (hopefully correctly) that LME4 uses the exact 
equivalent of what appears in equation (2) of Gurka's paper. 

Hope someone could help clarify these points. Sorry if this looks like a 
silly question to ask.



From:   Steve Walker <steve.walker at utoronto.ca>
To:     Douglas Bates <bates at stat.wisc.edu>, 
Subhash.Chandra at ecodev.vic.gov.au, r-sig-mixed-models at r-project.org, 
Date:   12/08/2015 03:05 AM
Subject:        Re: [R-sig-ME] A question about LME4



On 2015-08-11 11:37 AM, Douglas Bates wrote:
> As Ben mentioned in his off-list reply to you, the paper
> http://arxiv.org/abs/1406.5823 describes in some detail the 
computational
> methods that are used in lme4.

This arxiv paper (in press at JSS) is pretty long, although hopefully 
comprehensive.  To help pinpoint things a bit check out equations 34 and 
41.  These give the ML and REML criteria (on the deviance scale) that 
are used within lmer.

> The fact that they don't correspond to
> those in the 2006 paper by Gurka in The American Statistician is not an
> oversight.  They are quite superior to any methods based on the 
equations
> in that paper, as they should be.  We have spent the last 20 years or so
> developing them.

To expand on these remarks a bit, both the fixed effects coefficient 
vector and residual variance parameter are profiled out, which makes 
computations more efficient.  Also, correlations among random effects 
are partly accounted for in these equations using the log determinant of 
a sparse Cholesky factor, which is very efficiently updated over 
iterations of the nonlinear optimizer.

Cheers,
Steve

>
> On Tue, Aug 11, 2015 at 10:31 AM <Subhash.Chandra at ecodev.vic.gov.au> 
wrote:
>
>> Appreciate your help and advice on (hopefully a simple) question. This
>> relates to the mathematical expressions that LME4 uses to estimate log
>> likelihood under maximum likelihood (ML) and under residual maximum
>> likelihood (ReML) for fitting linear mixed models (LMM). What I am
>> 'exactly' looking for is mathematical expressions for log likelihood in
>> the form of expressions (2), (4) and (5) in the attached paper by Gurka
>> (2006).
>>
>>
>>
>> I have gone through the LME4 documentation
>> https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
>> https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf
>>
>> I must admit I am unable to figure out the answer to my question.
>>
>> Regards,
>> Subhash
>>
>> Dr Subhash Chandra | Chief Biometrician
>> Agriculture Research & Development Division
>> Department of Economic Development, Jobs, Transport & Resources
>> 255 Ferguson Road, Tatura 3616, Victoria, Australia
>> T:  03 5833 5397 | M: 0427 277 560 | E: 
Subhash.Chandra at ecodev.vic.gov.au
>>
>>
>>
>> 
********************************************************************************
>> Department of Economic Development, Jobs, Transport and Resources,
>> Government of
>> Victoria, Victoria, Australia.
>>
>> This email, and any attachments, may contain privileged and 
confidential
>> information.  If you are not the intended recipient, you may not
>> distribute or
>> reproduce this e-mail or the attachments.  If you have received this
>> message in
>> error, please notify us by return email.
>>
>> 
********************************************************************************
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>                [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>





********************************************************************************
Department of Economic Development, Jobs, Transport and Resources, Government of
Victoria, Victoria, Australia.

This email, and any attachments, may contain privileged and confidential
information.  If you are not the intended recipient, you may not distribute or
reproduce this e-mail or the attachments.  If you have received this message in
error, please notify us by return email.
********************************************************************************
	[[alternative HTML version deleted]]


From mmalten at gmail.com  Wed Aug 12 02:05:34 2015
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Tue, 11 Aug 2015 20:05:34 -0400
Subject: [R-sig-ME] Making sure something is kosher
Message-ID: <CANOgrHaOcf0hFOLVMe---XRmzNV354fgVsdQ1+CMseqy5kCkwA@mail.gmail.com>

I realize combining multiple imputation with random effect estimation is
dodgy.

Supposing I use mice with glmer to do the model fits, and then bootstrap to
get confidence intervals on the random effect estimates.

Is that a clean way to do it?  If not, what's recommended?

Thanks!



-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From JSorkin at grecc.umaryland.edu  Wed Aug 12 02:55:56 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 11 Aug 2015 20:55:56 -0400
Subject: [R-sig-ME] Making sure something is kosher
In-Reply-To: <CANOgrHaOcf0hFOLVMe---XRmzNV354fgVsdQ1+CMseqy5kCkwA@mail.gmail.com>
References: <CANOgrHaOcf0hFOLVMe---XRmzNV354fgVsdQ1+CMseqy5kCkwA@mail.gmail.com>
Message-ID: <55CA615C020000CB00135B93@smtp.medicine.umaryland.edu>

Why is it dodgy?


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

>>> Mitchell Maltenfort <mmalten at gmail.com> 08/11/15 8:06 PM >>>
I realize combining multiple imputation with random effect estimation is
dodgy.

Supposing I use mice with glmer to do the model fits, and then bootstrap to
get confidence intervals on the random effect estimates.

Is that a clean way to do it?  If not, what's recommended?

Thanks!



-- 
Sent from Gmail Mobile

    [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From pauljohn32 at gmail.com  Wed Aug 12 09:48:25 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 12 Aug 2015 02:48:25 -0500
Subject: [R-sig-ME] Making sure something is kosher
In-Reply-To: <CANOgrHaOcf0hFOLVMe---XRmzNV354fgVsdQ1+CMseqy5kCkwA@mail.gmail.com>
References: <CANOgrHaOcf0hFOLVMe---XRmzNV354fgVsdQ1+CMseqy5kCkwA@mail.gmail.com>
Message-ID: <CAErODj_bHEq_n9LKoRpHUOVSN88Mz-C+BhgMcs3ZB-26Lpj0zA@mail.gmail.com>

I think you mean to ask, how does one pool bootstrapped confidence
intervals constructed from 20 imputations? Same question about variance
estimates, or ICC. Appears now, each of those is a separate battle.
Similarly, any anova() test done separately. Rubin's rules great for MLEs.
Not so much for all that other stuff that we do.

VanBuren worked out the R^2 and some papers exist on model chisquare.
if you find one on CI, let me know. I'm wondering if you could simply
aggregate runs and build a CI. if not, appears you need better math stat
training than I have.

One project here explored that. If you are in the "I need 100 imputations"
crew and you want 5000 bootstraps, well... get a cluster. I'll ask that
team what they know.

pj
Paul Johnson
http://pj.freefaculty.org
On Aug 11, 2015 7:06 PM, "Mitchell Maltenfort" <mmalten at gmail.com> wrote:

> I realize combining multiple imputation with random effect estimation is
> dodgy.
>
> Supposing I use mice with glmer to do the model fits, and then bootstrap to
> get confidence intervals on the random effect estimates.
>
> Is that a clean way to do it?  If not, what's recommended?
>
> Thanks!
>
>
>
> --
> Sent from Gmail Mobile
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Wed Aug 12 10:03:44 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 12 Aug 2015 03:03:44 -0500
Subject: [R-sig-ME] Binomial glmmadmb error message
In-Reply-To: <CA+9vPVaxF3wWk4cWh3SvmN4J-hkpUtUr+_pUP5pymnkQZhWKjw@mail.gmail.com>
References: <CA+9vPVaxF3wWk4cWh3SvmN4J-hkpUtUr+_pUP5pymnkQZhWKjw@mail.gmail.com>
Message-ID: <CAErODj9por2skOh1AfDogT7JquON=0kDReGHgr5fTtwBBLEMeQ@mail.gmail.com>

Hi

pj
Paul Johnson
http://pj.freefaculty.org
On Aug 2, 2015 2:25 PM, "Scott McCain" <jspmccain at gmail.com> wrote:
>
> Hello,
>
> I'm trying to fit a hurdle mixed effects model, looking at cod abundance
> (cod0, cod1, and cod2). Because of the overdispersion and zero-inflation,
> I'm trying to use a hurdle model with the first stage as a binomial GLMM
> and the second stage a negative binomial GLMM. We have chosen site to be a
> random effect. Here is a summary of the data I'm working with:
>
> str(div.3a)
> 'data.frame': 325 obs. of  21 variables:
>  $ beach           : Factor w/ 56 levels "1","2","3","4",..: 1 1 1 1 1 1 1
> 1 1 7 ...
>  $ shannons        : num  1.017 1.014 1.302 0.853 1.325 ...
>  $ year            : Factor w/ 12 levels "59","60","61",..: 3 5 4 7 11 6 9
> 10 8 7 ...
>  $ region          : Factor w/ 6 levels "Bonavista Bay",..: 5 5 5 5 5 5 5
5
> 5 5 ...
>  $ species.rich    : int  6 7 6 7 6 5 6 4 6 3 ...
>  $ year.range      : Factor w/ 2 levels "1960-1964","1992-1996": 1 1 1 2 2
> 1 2 2 2 2 ...
>  $ sum.tfish       : num  137 120 157 84 73 56 20 5 320 96 ...
>  $ evenness        : num  0.568 0.521 0.726 0.439 0.74 ...
>  $ cod0            : int  24 43 0 0 0 3 0 0 0 9 ...
>  $ cod1            : int  47 10 48 0 0 8 0 0 1 0 ...
>  $ cod2            : int  0 0 5 0 0 0 0 0 0 0 ...
>  $ beach.name      : Factor w/ 56 levels "Admirals Beach",..: 26 26 26 26
> 26 26 26 26 26 52 ...
>  $ site.no         : Factor w/ 42 levels "1","2","5","6",..: 1 1 1 1 1 1 1
> 1 1 5 ...
>  $ depth           : num  4 4 4 4 4 4 4 4 4 3 ...
>  $ vegetation      : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
>  $ eelgrass        : int  1 1 1 1 1 1 1 1 1 0 ...
>  $ kelp            : int  0 0 0 0 0 0 0 0 0 1 ...
>  $ cod0nz          : num  1 1 0 0 0 1 0 0 0 1 ...
>  $ cod1nz          : num  1 1 1 0 0 1 0 0 1 0 ...
>  $ cod2nz          : num  0 0 1 0 0 0 0 0 0 0 ...
>
> (I'm using likelihood ratio tests using anova() by adding one term at a
> time). First fitting the binomial glmmadmb:
>
> cod1b.1 <- glmmadmb(data=div.3a, cod1nz ~ (1|site.no), family="binomial")
>
> #works fine
>
> cod1b.2 <- glmmadmb(data=div.3a, cod1nz ~ year.range + (1|site.no),
> family="binomial")
>
> ## the above returns the following error message:
>
> Parameters were estimated, but not standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative
>
> Error in glmmadmb(data = div.3a, cod1nz ~ year.range + (1 | site.no),  :
>   The function maximizer failed (couldn't find STD file) Troubleshooting
> steps include (1) run with 'save.dir' set and inspect output files; (2)
> change run parameters: see '?admbControl'
>
> In addition: Warning message:
> running command 'C:\Windows\system32\cmd.exe /c
>
"C:/Users/Scott/Documents/R/win-library/3.2/glmmADMB/bin/windows64/glmmadmb.exe"
> -maxfn 500 -maxph 5' had status 1
>
> ################
>
> So looking at this error message, I first attempted to inspect the output
> files but was quickly lost. I then looked into admbControl() and tried the
> following:

I suspect quasi-complete separation here. For one year.range value, there
is no diversity. That generally gives back this kind of error.

If I were you, i'd get table(div.3a, year.range, site.no) to see.
>
> cod1b.2 <- glmmadmb(data=div.3a, cod1nz ~ year.range + (1|site.no),
> family="binomial", admb.opts=admbControl(noinit=FALSE, shess=FALSE))
>
> #This unfortunately returns the exact same error message.
>
> What's quite strange is when I add in the next term I want to do null
> hypothesis testing on ("region"), I don't get an error.
>
> cod1b.3 <- glmmadmb(data=div.3a, cod1nz ~ year.range + region + (1|site.no
),
> family="binomial")
>
> However when I add the next term, "vegetation", I get this error:
>
> cod1b.4 <- glmmadmb(data=div.3a, cod1nz ~ year.range + region + vegetation
> + (1|site.no), family="binomial")
>
> Warning message:
> In glmmadmb(data = div.3a, cod1nz ~ year.range + region + vegetation +  :
>   Convergence failed:log-likelihood of gradient= -0.0434684
>
> If anybody has any insight about these error messages, please let me know!
>
> Here is my sessionInfo():
>
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 8 x64 (build 9200)
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>  LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> base
>
> other attached packages:
>  [1] glmmADMB_0.8.0     matrixStats_0.14.2 beepr_1.2
lmtest_0.9-34
>      zoo_1.7-12         gridExtra_2.0.0    pscl_1.4.9
>  [8] MASS_7.3-40        mgcv_1.8-7         nlme_3.1-120
> statmod_1.4.21     tweedie_2.2.1      lme4_1.1-8         Matrix_1.2-1
> [15] xtable_1.7-4       mvabund_3.10.4     ggplot2_1.0.1
stringr_1.0.0
>      vegan_2.3-0        lattice_0.20-31    permute_0.8-4
> [22] reshape2_1.4.1     dplyr_0.4.2
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.0      R2admb_0.7.5.3   nloptr_1.0.4     plyr_1.8.3
> tools_3.2.1      digest_0.6.8     gtable_0.1.2     DBI_0.3.1
>  [9] parallel_3.2.1   proto_0.3-10     cluster_2.0.1    R6_2.1.0
> minqa_1.2.4      magrittr_1.5     scales_0.2.5     splines_3.2.1
> [17] assertthat_0.1   colorspace_1.2-6 stringi_0.5-5    lazyeval_0.1.10
>  munsell_0.4.2    audio_0.1-5
>
> Thanks!
>
> Scott
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Wed Aug 12 10:18:39 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 12 Aug 2015 03:18:39 -0500
Subject: [R-sig-ME] Method to transform fixed effect parameter estimates
 back on to the response scale [after glmer() with family=Gamma(link =
 "log")] ??
In-Reply-To: <CAGmnqXgNR+jFM-gZYaadsyO9CmRx7voMFFmQpoaOrwFfzJHrYg@mail.gmail.com>
References: <CAGmnqXgNR+jFM-gZYaadsyO9CmRx7voMFFmQpoaOrwFfzJHrYg@mail.gmail.com>
Message-ID: <CAErODj_dMTLuDEnK3AHjSFBbNoQreCmNXB+i3nZdgZxEtPajSA@mail.gmail.com>

pj
Paul Johnson
http://pj.freefaculty.org
On Jul 16, 2015 12:43 AM, "Daniel Newman" <dan.newman86 at gmail.com> wrote:
>
> Subject: Method to transform fixed effect parameter estimates back on to
> the response scale [after glmer() with family=Gamma(link = "log")] ??
>
> Dear lme4 experts,
>
> I am using lme4 to model human reaction-time (RT; in milliseconds)
> responses. My model includes both nested and fully crossed random
> intercepts, and fixed effect ?predictor? factors.
>
> lmer() seems to work quite well for this, and is nice since I can use the
> fixed effect parameter estimates (beta and Std.Errors) for interpretation
> to say that for every unit of the ?predictor? that changes, we expect a
> change of ~beta units in RT on the response scale (milliseconds). Pretty
> happy with the results?.BUT?
>
> glmer() may be the better option since the response distribution has a
> positive skew with no zero values (typical RT distribution), and glmer()
> allows the same model specification as my lmer() model, except using
> family=Gamma(link = "log") to account for the skewed response
distribution.
>
> This seems to work well and gives very similar results to the equivalent
> lmer() model, but with somewhat improved residual plots, so I guess the
> glmer() with family=Gamma(link = "log") is a more valid approach since it
> explicitly accounts for the shape of response distribution.

Similar predicted values for inputs? That only sense in which you should
compare.
>
> PROBLEM: Is there a way to transform the fixed effect parameter estimates
> and Std.Errors from the glmer() with family=Gamma(link = "log"), back to
> the response scale (i.e. back to RT in milliseconds). It would be nice/aid
> interpretation to say that for every unit of the ?predictor? that changes,
> we expect a change of ~beta units on the response scale.

No, don't back transform params. Yes do run predict() and use that to
explore input _> output mapping. Specify newdata carefully to see what you
want. Run plotSlopes in my package "rockchalk" to see what I mean. That
works on lm and glm, did not consider extend to glmer, but ought to. All we
need is draw one line per group.

>
> Thank you so much for your time!!
>
> Cheers
> Dan
>
>
> --
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From emeline.mourocq at uzh.ch  Wed Aug 12 13:00:54 2015
From: emeline.mourocq at uzh.ch (emeline mourocq)
Date: Wed, 12 Aug 2015 13:00:54 +0200
Subject: [R-sig-ME] MCMC model selection reference
Message-ID: <04bb01d0d4ee$297dce40$7c796ac0$@uzh.ch>

Dear Jarrod,

 

In your previous comment about DIC you said : "For non-Gaussian data I never
use DIC, and have seriously considered removing it from MCMCglmm." What is
then the alternative(s) you suggest to use to do model selection using
MCMCglmm for non-Gaussian data?

 

I am asking because I am investigating the effect of several predictors on a
binary one-inflated response variable using MCMCglmm and was planning to do
model selection based on delta DIC of model with and without the predictor
of interest.

 

Would you have a recommendation for "a best method" to use to do model
selection in my case?

 

Best regards

Emeline

 

 

 



---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Aug 12 13:55:10 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 12 Aug 2015 13:55:10 +0200
Subject: [R-sig-ME] A question about LME4
In-Reply-To: <OFF3655694.9DE48FB4-ONCA257E9E.0081BCA5-CA257E9E.00838D58@cenitex.vic.gov.au>
References: <OFE0D4E863.69803899-ONCA257E9D.007C50AF-CA257E9D.007CBA28@cenitex.vic.gov.au>
	<CAO7JsnTT1_oJ2zsJZiPhS0gnj8ARgXuTDJGRQq-5WAVQA12OFg@mail.gmail.com>
	<55CA2B69.4060701@utoronto.ca>,
	<OFF3655694.9DE48FB4-ONCA257E9E.0081BCA5-CA257E9E.00838D58@cenitex.vic.gov.au>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F1A0B3520@UM-MAIL4112.unimaas.nl>

For ML estimation, lme4 (and nlme) uses what is equation (2) in Gurka (2006). For REML estimation, they both use what is equation (5), so the +1/2 ln|X'X| part is omitted.

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Subhash.Chandra at ecodev.vic.gov.au [Subhash.Chandra at ecodev.vic.gov.au]
Sent: Wednesday, August 12, 2015 1:56 AM
To: Steve Walker
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] A question about LME4

Thanks everyone for their advice. Looks like I did not phrase my question
correctly. My apologies to waste your time. First, to clarify what Douglas
wrote, I was not questioning the correctness of your approach. The
question that I intended to really ask is:

Does LME4 use the complete log residual likelihood in Gurka's equation
(4)? If not, what does it omit from equation (4), for example, equation
(5) in Gurka's paper that SAS uses by omitting a constant? As regards the
log likelihood, I assume (hopefully correctly) that LME4 uses the exact
equivalent of what appears in equation (2) of Gurka's paper.

Hope someone could help clarify these points. Sorry if this looks like a
silly question to ask.

From:   Steve Walker <steve.walker at utoronto.ca>
To:     Douglas Bates <bates at stat.wisc.edu>,
Subhash.Chandra at ecodev.vic.gov.au, r-sig-mixed-models at r-project.org,
Date:   12/08/2015 03:05 AM
Subject:        Re: [R-sig-ME] A question about LME4

On 2015-08-11 11:37 AM, Douglas Bates wrote:
> As Ben mentioned in his off-list reply to you, the paper
> http://arxiv.org/abs/1406.5823 describes in some detail the
computational
> methods that are used in lme4.

This arxiv paper (in press at JSS) is pretty long, although hopefully
comprehensive.  To help pinpoint things a bit check out equations 34 and
41.  These give the ML and REML criteria (on the deviance scale) that
are used within lmer.

> The fact that they don't correspond to
> those in the 2006 paper by Gurka in The American Statistician is not an
> oversight.  They are quite superior to any methods based on the
equations
> in that paper, as they should be.  We have spent the last 20 years or so
> developing them.

To expand on these remarks a bit, both the fixed effects coefficient
vector and residual variance parameter are profiled out, which makes
computations more efficient.  Also, correlations among random effects
are partly accounted for in these equations using the log determinant of
a sparse Cholesky factor, which is very efficiently updated over
iterations of the nonlinear optimizer.

Cheers,
Steve

> On Tue, Aug 11, 2015 at 10:31 AM <Subhash.Chandra at ecodev.vic.gov.au>
wrote:
>
>> Appreciate your help and advice on (hopefully a simple) question. This
>> relates to the mathematical expressions that LME4 uses to estimate log
>> likelihood under maximum likelihood (ML) and under residual maximum
>> likelihood (ReML) for fitting linear mixed models (LMM). What I am
>> 'exactly' looking for is mathematical expressions for log likelihood in
>> the form of expressions (2), (4) and (5) in the attached paper by Gurka
>> (2006).
>>
>> I have gone through the LME4 documentation
>> https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
>> https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf
>>
>> I must admit I am unable to figure out the answer to my question.
>>
>> Regards,
>> Subhash
>>
>> Dr Subhash Chandra | Chief Biometrician
>> Agriculture Research & Development Division
>> Department of Economic Development, Jobs, Transport & Resources
>> 255 Ferguson Road, Tatura 3616, Victoria, Australia
>> T:  03 5833 5397 | M: 0427 277 560 | E: Subhash.Chandra at ecodev.vic.gov.au

From mmalten at gmail.com  Wed Aug 12 14:11:55 2015
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Wed, 12 Aug 2015 08:11:55 -0400
Subject: [R-sig-ME] Making sure something is kosher
In-Reply-To: <CAErODj_bHEq_n9LKoRpHUOVSN88Mz-C+BhgMcs3ZB-26Lpj0zA@mail.gmail.com>
References: <CANOgrHaOcf0hFOLVMe---XRmzNV354fgVsdQ1+CMseqy5kCkwA@mail.gmail.com>
	<CAErODj_bHEq_n9LKoRpHUOVSN88Mz-C+BhgMcs3ZB-26Lpj0zA@mail.gmail.com>
Message-ID: <CANOgrHYsRO4XPLREpmiyC9wfRwGyBB3j==C8qXcVRh8AgKEEjA@mail.gmail.com>

This is looking at patient outcomes with doctor as random effect

Some patient demographics are missing

I figured this wasn't going to be as easy as pool glmer imputations from
mice, then use se.ranef from arm to get standard errors on random effects

I was hoping to get away with 1000 bootstrapped samples, 5-10 imputations
each bootstrap

Too optimistic?

On Wednesday, August 12, 2015, Paul Johnson <pauljohn32 at gmail.com> wrote:

> I think you mean to ask, how does one pool bootstrapped confidence
> intervals constructed from 20 imputations? Same question about variance
> estimates, or ICC. Appears now, each of those is a separate battle.
> Similarly, any anova() test done separately. Rubin's rules great for MLEs.
> Not so much for all that other stuff that we do.
>
> VanBuren worked out the R^2 and some papers exist on model chisquare.
> if you find one on CI, let me know. I'm wondering if you could simply
> aggregate runs and build a CI. if not, appears you need better math stat
> training than I have.
>
> One project here explored that. If you are in the "I need 100 imputations"
> crew and you want 5000 bootstraps, well... get a cluster. I'll ask that
> team what they know.
>
> pj
> Paul Johnson
> http://pj.freefaculty.org
> On Aug 11, 2015 7:06 PM, "Mitchell Maltenfort" <mmalten at gmail.com
> <javascript:_e(%7B%7D,'cvml','mmalten at gmail.com');>> wrote:
>
>> I realize combining multiple imputation with random effect estimation is
>> dodgy.
>>
>> Supposing I use mice with glmer to do the model fits, and then bootstrap
>> to
>> get confidence intervals on the random effect estimates.
>>
>> Is that a clean way to do it?  If not, what's recommended?
>>
>> Thanks!
>>
>>
>>
>> --
>> Sent from Gmail Mobile
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org
>> <javascript:_e(%7B%7D,'cvml','R-sig-mixed-models at r-project.org');>
>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From liberationecology at gmail.com  Wed Aug 12 14:16:59 2015
From: liberationecology at gmail.com (rafter sass ferguson)
Date: Wed, 12 Aug 2015 14:16:59 +0200
Subject: [R-sig-ME] variance explained by fixed effects in MCMCglmm
Message-ID: <CAPNXFM73PSTXOnKRbtupOrq-yZSgpJMSwk0O42on1N_kmFpNbw@mail.gmail.com>

For any who comes looking:

I asked this same question on researchgate here:
https://www.researchgate.net/post/How_can_I_calculate_R2_for_an_Bayesian_MCMC_multilevel_model

Happily, it was answered by Shinichi Nakagawa himself (author of the
original article), who provided updated
code based on the same example models but using MCMCglmm.
I'm pasting in his response below:

Hi, Rafter
>
> I have added MCMCglmm to our supplementary R code. Note that I have only
> done it for the Gaussian model (see below) - it comes with credible
> intervals for R2 as well. The next week or so I will do this for binary and
> Poisson models (binary model one is a bit complicated). Once finished, I
> will upload it to my website (http://www.i-deel.org/
> <https://www.researchgate.net/go.Deref.html?url=http%3A%2F%2Fwww.i-deel.org%2F>)
> linking it with the paper.
>
> Thanks
>
> Shinichi
>
> ####################################################
>
> # A. Preparation
>
> ####################################################
>
> # Note that data generation appears below the analysis section.
>
> # You can use the simulated data table from the supplementary files to
> reproduce exactly the same results as presented in the paper.
> # Set the work directy that is used for rading/saving data tables
>
> # setwd("/Users/R2")
>
>
> # load R required packages
>
> # If this is done for the first time, it might need to first download and
> install the package
>
> # install.packages("arm")
>
> library(arm)
>
> # install.packages("lme4")
>
> # the verson 1.0-5
>
> library(lme4)
>
> # install.packages("MCMCglmm")
>
> library(MCMCglmm)
> ####################################################
>
> # B. Analysis
>
> ####################################################
> # 1. Analysis of body size (Gaussian mixed models)
>
> #---------------------------------------------------
> # Clear memory
>
> rm(list = ls())
> # Read body length data (Gaussian, available for both sexes)
>
> Data <- read.csv("BeetlesBody.csv")
> # Fit null model without fixed effects (but including all random effects)
>
> m0 <- lmer(BodyL ~ 1 + (1 | Population) + (1 | Container), data = Data)
> # MCMCglmm model
> mm0<-MCMCglmm(BodyL ~ 1 , random = ~ Population + Container, data=Data)
> # Fit alternative model including fixed and all random effects
>
> mF <- lmer(BodyL ~ Sex + Treatment + Habitat + (1 | Population) + (1 |
> Container), data = Data)
> # MCMCglmm model
> mmF<-MCMCglmm(BodyL ~ Sex + Treatment + Habitat , random = ~ Population +
> Container, data=Data)
> # View model fits for both models
>
> summary(m0)
>
> summary(mm0)
> summary(mF)
>
> summary(mmF)
> # Extraction of fitted value for the alternative model
>
> # fixef() extracts coefficents for fixed effects
>
> # mF at pp$X returns fixed effect design matrix
>
> Fixed <- fixef(mF)[2] * mF at pp$X[, 2] + fixef(mF)[3] * mF at pp$X[, 3] +
> fixef(mF)[4] * mF at pp$X[, 4]
>
>
> # MCMCglmm (it is probably better to get a posterior distribuiton of R2
> rather than getting each varaince component - we do this below as an
> alternative)
>
> mFixed <- mean(mmF$Sol[,2]) * mmF$X[, 2] + mean(mmF$Sol[, 3]) * mmF$X[, 3]
> + mean(mmF$Sol[ ,4]) * mmF$X[, 4]
>
>
> # Calculation of the variance in fitted values
>
> VarF <- var(Fixed)
>
> mVarF<- var(mFixed)
>
>
> # An alternative way for getting the same result
>
> VarF <- var(as.vector(fixef(mF) %*% t(mF at pp$X)))
>
> mVarF <- var(as.vector(apply(mmF$Sol,2,mean) %*% t(mmF$X)))
> # R2GLMM(m) - marginal R2GLMM
>
> # Equ. 26, 29 and 30
>
> # VarCorr() extracts variance components
>
> # attr(VarCorr(lmer.model),'sc')^2 extracts the residual variance
>
> VarF/(VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1] +
> attr(VarCorr(mF), "sc")^2)
>
>
> # MCMCglmm - marginal
> mVarF/(mVarF+sum(apply(mmF$VCV,2,mean)))
>
>
> # alternative with crebile intervals
> vmVarF<-numeric(1000)
>
> for(i in 1:1000){
>
> Var<-var(as.vector(mmF$Sol[i,] %*% t(mmF$X)))
>
> vmVarF[i]<-Var}
>
>
> R2m<-vmVarF/(vmVarF+mmF$VCV[,1]+mmF$VCV[,2]+mmF$VCV[,3])
>
> mean(R2m)
>
> posterior.mode(R2m)
>
> HPDinterval(R2m)
> # R2GLMM(c) - conditional R2GLMM for full model
>
> # Equ. 30
>
> (VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1])/(VarF +
> VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1] + (attr(VarCorr(mF),
> "sc")^2))
>
>
> # MCMCglmm - conditional
>
> (mVarF+sum(apply(mmF$VCV,2,mean)[-3]))/(mVarF+sum(apply(mmF$VCV,2,mean)))
> # alternative with crebile intervals
>
>
> R2c<-(vmVarF+mmF$VCV[,1]+mmF$VCV[,2])/(vmVarF+mmF$VCV[,1]+mmF$VCV[,2]+mmF$VCV[,3])
>
> mean(R2c)
>
> posterior.mode(R2c)
>
> HPDinterval(R2c)
>




Rafter Sass Ferguson, MS
PhD Candidate | Crop Sciences Department
University of Illinois in Urbana-Champaign
liberationecology.org
518 567 7407

On Thu, Jul 16, 2015 at 1:05 AM, rafter sass ferguson <
liberationecology at gmail.com> wrote:

> I've been searching for ways to calculate some R^2-like statistics for a
> multi-level multi-response model fit with MCMCglmm (with 3 Gaussian
> responses).
>
> I can see from the Course Notes and elsewhere that it's very
> straightforward to calculate the variance explained by the random effects,
> but after much searching I haven't found a discussion for fixed effects. It
> looks like one option would be refitting with all my fixed effects as
> random - but I'm concerned that might be bonkers, or that there might be an
> easier way.
>
> For previous multilevel modeling with lmer, I've used the approach
> following Nakagawa et al. 2013 (A general and simple method for obtaining
> R2 from generalized linear mixed-effects models. Methods in Ecology and
> Evolution, 4(2), 133?142. http://doi.org/10.1111/j.2041-210x.2012.00261.x)
> to calculate conditional and marginal R^2...
> but I'm not sure how to adapt it for the (for me) brave new world of
> MCMCglmm.
>
> I would be grateful for any advice!
>
> Thanks so much for your time.
>
> Warmly,
> Rafter
>
>
> Rafter Sass Ferguson, MS
> PhD Candidate | Crop Sciences Department
> University of Illinois in Urbana-Champaign
> liberationecology.org
> 518 567 7407
>

	[[alternative HTML version deleted]]


From alexandre.m.martin at gmail.com  Wed Aug 12 15:03:46 2015
From: alexandre.m.martin at gmail.com (Alexandre Martin)
Date: Wed, 12 Aug 2015 09:03:46 -0400
Subject: [R-sig-ME] covariance problems in MCMCglmm. genetic effects and
	multiple membership
In-Reply-To: <CANXb-o4DtkTVEHRN89HL6FQDDpzxoc1kfzCfi+2PNuOLRyXiew@mail.gmail.com>
References: <01ad01d0d390$2ba2df30$82e89d90$@gmail.com>
	<CANXb-o4DtkTVEHRN89HL6FQDDpzxoc1kfzCfi+2PNuOLRyXiew@mail.gmail.com>
Message-ID: <003901d0d4ff$53fe0610$fbfa1230$@gmail.com>

Dear all, dear Szymek, 

Thank you for your answer.

I am looking at ASReml to manage that. 

 

All the best.

 

Alexandre

 

 

De : Szymek Drobniak [mailto:szymek.drobniak at uj.edu.pl] 
Envoy? : 10 ao?t 2015 13:28
? : Alexandre Martin; r-sig-mixed-models at r-project.org
Objet : Re: covariance problems in MCMCglmm. genetic effects and multiple membership

 

Hi Unfortunately this is not possible as far as Know but please someone correct me if I'm wrong - MCMCglmm cannot use design matrices of necessary form for random effects. you'll have to use asreml - or asreml-r which has syntax similar to MCMCGLMM.

Cheers
Szymek

W dniu pon., 10 sie 2015 o 19:15 Alexandre Martin <alexandre.m.martin at gmail.com> napisa?(a):

Dear Szymek, 

Thank you again for your contribution with your last answer. 

I am wondering now how to write the model to estimate the covariance between the ?mm(?)? and the ?animal? random parts. 

Jarrod wrote in this thread (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q4/017034.html) about maternal genetic effects : ?it is not yet possible to fit the covariance between maternal genetic and direct genetic effects?

Since my model is similar to that described in the thread, is it still impossible to fit a model to assess the covariance between direct and indirect genetic effects in a way similar to that in ASReml as follow?

 

For y =Xb + Z1animal + Z2maternal + e 

Analysis of some kind

anim !P                       # The variable ?anim? is related to a pedigree fil

dam !P                        # The variable ?dam? is related to a pedigree file

dage 10 !A

rt 6 

wwt

grp 322 !A

example.ped

example.dat

wwt ~ mu rt dage !r anim dam !f grp 

0 0 1 

anim 2 

2 0 US !GP

.2 0 .15 

anim o AINV

 

 

Best 

 

Alexandre

 

 

De : Szymek Drobniak [mailto:szymek.drobniak at uj.edu.pl] 
Envoy? : 14 mai 2015 17:39
? : r-sig-mixed-models at r-project.org
Cc : alexandre.m.martin at gmail.com
Objet : Re: genetic effects and multiple membership in MCMCglmm (Alexandre Martin)

 

Hello Alexandre,

 

using ped assigns a given correlation structure only to the "animal" random effect. You have to create an inverse of A matrix:

 

my_inverse <- inverseA(ped)$Ainv

 

and assign it in MCMCglmm to specific random effects:

 

MCMCglmm(Y~1,
random=~animal+mm(m1+m2+m3),

ginverse=list(animal=my_inverse, m1=my_inverse, m2=my_inverse,m3=my_inverse), data=dat, pr=T).

 

Cheers

Szymek


	[[alternative HTML version deleted]]


From carbrae at gmail.com  Mon Aug 17 18:01:09 2015
From: carbrae at gmail.com (Bradley Carlson)
Date: Mon, 17 Aug 2015 12:01:09 -0400
Subject: [R-sig-ME] Residual variance for mixed effects survival analysis
Message-ID: <CAF37_NcwcyZ5ZZbMvHbmQ-7KWzVM85Hd2kE6iOmMcfUq9f=EGQ@mail.gmail.com>

I'm working on an analysis of the amount of time it takes an animal to
perform a behavior. This data is right-censored, as we stopped waiting
after 10 minutes and simply had to record "10+ minutes" for any animals
that didn't perform the behavior. The data is well suited for a Cox
proportional hazards 'survival' analysis in this regard. However, I have
multiple measurements of each individual animal (random effect) and would
like to quantify the individual repeatability of the behavior in addition
to the effect of covariates. In a typical LMM, this would be the (variance
among random intercepts) / (variance among random intercepts + residual
variance).

I can fit a mixed effects survival analysis in the package 'coxme'. It
provides a random effect variance, but no residual variance. Is it
possible, given the mechanics of fitting an ME survival analysis, to get a
residual variance?

Thank you in advance!

-- 

Bradley Evan Carlson
Assistant Professor of Biology
Wabash College, Crawfordsville IN

Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
Website: https://sites.google.com/site/bradleyecarlson/home

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Tue Aug 18 01:26:11 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Tue, 18 Aug 2015 09:26:11 +1000
Subject: [R-sig-ME] Residual variance for mixed effects survival analysis
In-Reply-To: <CAF37_NcwcyZ5ZZbMvHbmQ-7KWzVM85Hd2kE6iOmMcfUq9f=EGQ@mail.gmail.com>
References: <CAF37_NcwcyZ5ZZbMvHbmQ-7KWzVM85Hd2kE6iOmMcfUq9f=EGQ@mail.gmail.com>
Message-ID: <CAF5_5cyaX_i=+WXEHe+_ccgVJmvHcdY6HRFOk32zDh_hvaoHaw@mail.gmail.com>

For Cox survival analysis there is no residual as part of the model, hence
no residual variance.

Ken

On 18 August 2015 at 02:01, Bradley Carlson <carbrae at gmail.com> wrote:

> I'm working on an analysis of the amount of time it takes an animal to
> perform a behavior. This data is right-censored, as we stopped waiting
> after 10 minutes and simply had to record "10+ minutes" for any animals
> that didn't perform the behavior. The data is well suited for a Cox
> proportional hazards 'survival' analysis in this regard. However, I have
> multiple measurements of each individual animal (random effect) and would
> like to quantify the individual repeatability of the behavior in addition
> to the effect of covariates. In a typical LMM, this would be the (variance
> among random intercepts) / (variance among random intercepts + residual
> variance).
>
> I can fit a mixed effects survival analysis in the package 'coxme'. It
> provides a random effect variance, but no residual variance. Is it
> possible, given the mechanics of fitting an ME survival analysis, to get a
> residual variance?
>
> Thank you in advance!
>
> --
>
> Bradley Evan Carlson
> Assistant Professor of Biology
> Wabash College, Crawfordsville IN
>
> Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
> Website: https://sites.google.com/site/bradleyecarlson/home
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From andrea.cantieni at phsz.ch  Tue Aug 18 11:36:36 2015
From: andrea.cantieni at phsz.ch (Andrea Cantieni)
Date: Tue, 18 Aug 2015 09:36:36 +0000
Subject: [R-sig-ME] design weights
Message-ID: <EE119CAC-974C-4F76-A09A-63FF9CA6080D@phsz.ch>

Hi,

Is there a way to use design weights - i.e. each unit is weighted inversely proportional to its probability of selection - as in HLM?

http://www.ssicentral.com/hlm/example6-2.pdf

Or does anybody know how to do this in R otherwise?

Best regards,
Andrea Cantieni

........................................

Andrea Cantieni
Research Assistant

University of Teacher Education Schwyz
Institute for Media and Schools
Zaystrasse 42
6410 Goldau
Switzerland

andrea.cantieni at phsz.ch<mailto:andrea.cantieni at phsz.ch>
www.phsz.ch<http://www.phsz.ch>

..........................................
 _____               _   _               _           _
|  __ \             | | | |             (_)         | |
| |__) |   ___ _ __ | |_| |__  _   _ ___ _  __ _ ___| |_
|  _  /   / _ \ '_ \| __| '_ \| | | / __| |/ _` / __| __|
| | \ \  |  __/ | | | |_| | | | |_| \__ \ | (_| \__ \ |_
|_|  \_\  \___|_| |_|\__|_| |_|\__,_|___/_|\__,_|___/\__|






	[[alternative HTML version deleted]]


From gustaf.granath at gmail.com  Tue Aug 18 11:44:07 2015
From: gustaf.granath at gmail.com (Gustaf Granath)
Date: Tue, 18 Aug 2015 11:44:07 +0200
Subject: [R-sig-ME] Phylogenetic component using lme4ord
Message-ID: <55D2FE67.3040708@gmail.com>

Hi all,
Im testing different ways to quantify/incorporate the phylogenetic 
component in the analyzes of trait data (e.g. phylo signal/lambda). I 
noticed that lme4ord has progressed and started to play around with it. 
Im particularly interested in using data with with-species samples 
(PGLMM). Im not sure I understand the fitting/output from lme4ord though.

# First load packages and data
require(phytools)
require(geiger)
require(MCMCglmm)
data(bird.families)

# this data has high phylogentic signal so we lower it a bit
library(geiger)
set.seed(350)
bird.families.rs <- rescale(bird.families, 'lambda', lambda=0.5)
phylo.effect <- fastBM(bird.families.rs)
phylosig(bird.families.rs, phylo.effect, method='lambda', test = TRUE)
# lambda ~0.7

# Lets add within-species variation
phylo.effect.rep <- data.frame(y = c(phylo.effect,
                                     rnorm(length(phylo.effect), 0, 1) + 
phylo.effect,
                                     rnorm(length(phylo.effect), 0, 1) + 
phylo.effect),
                                 species = rep(names(phylo.effect), 3))

# Anlyze data using lme4ord (install from github)
# I think phyloEdge() was earlier pagelLamda()
library(lme4ord)
formula <- y ~ 1 + (1| species) + phyloEdge(1 | species, phylo = 
bird.families.rs)
mod <- strucGlmer(formula, family = gaussian(), data = phylo.effect.rep, 
optMaxit = 1000000)
summary(mod)
# sumary() does not give random effects
getReTrm(mod)
# species.phyloEdge component VERY small.
# It seems like only 2 components are estimated.
# I thought there would be 3: phylo, species (between species variation 
not captured by the BM model), within-species (residual).

# And now compare with MCMCglmm
# WARNING slow!!
library(MCMCglmm)
Ainv <- inverseA(bird.families.rs, scale = TRUE)$Ainv
prior = list(R = list(V = 1, nu = 0.02),
              G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 
1000),
                       G2 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 
1000)))
phylo.effect.rep$species.ide <- phylo.effect.rep$species

m1.phy <- MCMCglmm(y ~ 1, random =~ species + species.ide,
                     data = phylo.effect.rep, ginverse = list(species = 
Ainv),
                     nitt = 700000, thin=100, prior = prior, burnin = 
50000, pr=TRUE)

# without species.ide
prior = list(R = list(V = 1, nu = 0.02),
              G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 
1000)))
m2.phy <- MCMCglmm(y ~ 1, random =~ species,
                     data = phylo.effect.rep, ginverse = list(species = 
Ainv),
                     nitt = 500000, thin=100, prior = prior, burnin = 
50000, pr=TRUE)

summary(m1.phy)
# 3 components estimated
summary(m2.phy)
# in m2.phy species and species.ide are merged into one component.
# Thus Lambda cannot be estimated for m2.phy.

# Lambda
# Here we assume within-species variance is measurement error so not 
included in the denominator
lambda.1 <- 
m1.phy$VCV[,"species"]/(m1.phy$VCV[,"species"]+m1.phy$VCV[,"species.ide"])
mean(lambda.1)
# ~0.78. Not too bad and longer chains (more samples) may improve this
# however the posterior of species.ide does not look good! But it seems 
to give an OK result.

Question: can the MCMCglmm results be replicated using lme4ord? What 
model is actually fitted by lme4ord?

Hope someone can help.

Cheers,

Gustaf


-- 
Gustaf Granath (PhD)
Post doc
Swedish University of Agricultural Sciences
Department of Ecology


From drmasoodmohd at gmail.com  Tue Aug 18 11:53:47 2015
From: drmasoodmohd at gmail.com (Mohd Masood)
Date: Tue, 18 Aug 2015 17:53:47 +0800
Subject: [R-sig-ME] design weights
In-Reply-To: <EE119CAC-974C-4F76-A09A-63FF9CA6080D@phsz.ch>
References: <EE119CAC-974C-4F76-A09A-63FF9CA6080D@phsz.ch>
Message-ID: <CAA50DA3-1EFF-476A-99FF-6DCCD4B9FF24@gmail.com>

Hi Andrea 
Use "survey" package in R. It deals with survey design including weights. 

BW
Masood

Sent from my iPhone

> On Aug 18, 2015, at 5:36 PM, Andrea Cantieni <andrea.cantieni at phsz.ch> wrote:
> 
> Hi,
> 
> Is there a way to use design weights - i.e. each unit is weighted inversely proportional to its probability of selection - as in HLM?
> 
> http://www.ssicentral.com/hlm/example6-2.pdf
> 
> Or does anybody know how to do this in R otherwise?
> 
> Best regards,
> Andrea Cantieni
> 
> ........................................
> 
> Andrea Cantieni
> Research Assistant
> 
> University of Teacher Education Schwyz
> Institute for Media and Schools
> Zaystrasse 42
> 6410 Goldau
> Switzerland
> 
> andrea.cantieni at phsz.ch<mailto:andrea.cantieni at phsz.ch>
> www.phsz.ch<http://www.phsz.ch>
> 
> ..........................................
> _____               _   _               _           _
> |  __ \             | | | |             (_)         | |
> | |__) |   ___ _ __ | |_| |__  _   _ ___ _  __ _ ___| |_
> |  _  /   / _ \ '_ \| __| '_ \| | | / __| |/ _` / __| __|
> | | \ \  |  __/ | | | |_| | | | |_| \__ \ | (_| \__ \ |_
> |_|  \_\  \___|_| |_|\__|_| |_|\__,_|___/_|\__,_|___/\__|
> 
> 
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.debes at utu.fi  Tue Aug 18 13:50:46 2015
From: paul.debes at utu.fi (paul debes)
Date: Tue, 18 Aug 2015 14:50:46 +0300
Subject: [R-sig-ME] starting values in glmmadmb and / or covariance
	specification in glmer
Message-ID: <op.x3ka6whqa3mgvf@armadillo.utu.fi>

Dear list members,

Does anybody know either how to use starting values for the variance  
components using glmmadmb (glmmADMB package) or how I can specify a common  
covariance across different variances for the random statement with glmer  
(NOT with lmer that seems to work differently)?

Sorry for asking two different questions, but an answer to only one would  
already help me.

Presently, I keep running out of memory (8GB) when trying to fit a set of  
binary GLMMs with binomial error distribution using glmmadmb that I cannot  
specify in glmer (which doesn't have any memory problems). Maybe  
specifying starting values in glmmadmb would help?

I can fit all of a set of models with PQL (asreml-r package), but only  
some with Laplace approximation (what I want) using glmer (lme4 package).  
Hence, it is possible to fit the models generally. But I have no clue how  
to specify a certain covariance structure in glmer (common covariance +  
diagonal, equal variance).

I tried the following models with both glmer and glmmadmb; both work fine:

a) ~ 1 + Fixed.Effects + (1|Group) + (1|Fixed.Effect:Group) # simplest  
model; common covariance (fitted by the Group term that is crossed with  
Fixed.Effect) & common variance between / for all levels of Fixed.Effect  
by Group

b) ~ 1 + Fixed.Effects + (0+Fixed.Effect|Group) # maximal model; different  
covariance & different variance between / for all levels of Fixed.Effect  
by Group levels

However, an intermediate model specification results in different  
covariance structures in glmmadmb (where I run out of memory; I tested its  
correct behaviour with a subset of data) vs. glmer:

c) ~ 1 + Fixed.Effects + (1|Group) + (0+Fixed.Effect|Group) # I try to  
fit: a common covariance among levels of Fixed.Effect by Group, different  
Group variances for each level of Fixed.Effect

The asreml-r syntax for the model I try to specify in c) is:

fixed = ~ 1 + Fixed.Effects,
random = ~ Group + idh(Fixed.Effects):Group

or alternatively (I'm not particularly interested in the amount of  
variance for the crossed Group term, just in inferences about fixed  
effects):

random = ~ corh(Fixed.Effects):Group


For c), glmmadmb and I understand each other - no covariances are fit  
among Fixed.Effect by Group levels in addition to that implied by the  
Group random term - whereas proper glmer syntax must be different as it  
fits BOTH individual-pair covariances (printed as correlations with  
'summary') AND the random term variance (I'm far away from wanting to fit  
this).

How do I specify model c) appropriately in glmer or how do I specify  
starting values in glmmadmb (to get rid of my memory-limitation problem  
instead of learning new glmer syntax)?


Many thanks in advance,
Paul

-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From andrea.cantieni at phsz.ch  Tue Aug 18 16:45:08 2015
From: andrea.cantieni at phsz.ch (Andrea Cantieni)
Date: Tue, 18 Aug 2015 14:45:08 +0000
Subject: [R-sig-ME] design weights
In-Reply-To: <CAA50DA3-1EFF-476A-99FF-6DCCD4B9FF24@gmail.com>
References: <EE119CAC-974C-4F76-A09A-63FF9CA6080D@phsz.ch>
	<CAA50DA3-1EFF-476A-99FF-6DCCD4B9FF24@gmail.com>
Message-ID: <1A90C0C3-A913-434C-8356-37CF29EAB736@phsz.ch>

Hi Masood,

Thank you!

But I have to fit a weighted _multilevel_ model!

Best regards,
Andrea


Am 18.08.2015 um 11:53 schrieb Mohd Masood <drmasoodmohd at gmail.com<mailto:drmasoodmohd at gmail.com>>:

Hi Andrea
Use "survey" package in R. It deals with survey design including weights.

BW
Masood

Sent from my iPhone

On Aug 18, 2015, at 5:36 PM, Andrea Cantieni <andrea.cantieni at phsz.ch<mailto:andrea.cantieni at phsz.ch>> wrote:

Hi,

Is there a way to use design weights - i.e. each unit is weighted inversely proportional to its probability of selection - as in HLM?

http://www.ssicentral.com/hlm/example6-2.pdf

Or does anybody know how to do this in R otherwise?

Best regards,
Andrea Cantieni

........................................

Andrea Cantieni
Research Assistant

University of Teacher Education Schwyz
Institute for Media and Schools
Zaystrasse 42
6410 Goldau
Switzerland

andrea.cantieni at phsz.ch<mailto:andrea.cantieni at phsz.ch><mailto:andrea.cantieni at phsz.ch>
www.phsz.ch<http://www.phsz.ch/><http://www.phsz.ch<http://www.phsz.ch/>>

..........................................
_____               _   _               _           _
|  __ \             | | | |             (_)         | |
| |__) |   ___ _ __ | |_| |__  _   _ ___ _  __ _ ___| |_
|  _  /   / _ \ '_ \| __| '_ \| | | / __| |/ _` / __| __|
| | \ \  |  __/ | | | |_| | | | |_| \__ \ | (_| \__ \ |_
|_|  \_\  \___|_| |_|\__|_| |_|\__,_|___/_|\__,_|___/\__|






  [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From carbrae at gmail.com  Tue Aug 18 18:38:50 2015
From: carbrae at gmail.com (Bradley Carlson)
Date: Tue, 18 Aug 2015 12:38:50 -0400
Subject: [R-sig-ME] Residual variance for mixed effects survival analysis
In-Reply-To: <CAF5_5cyaX_i=+WXEHe+_ccgVJmvHcdY6HRFOk32zDh_hvaoHaw@mail.gmail.com>
References: <CAF37_NcwcyZ5ZZbMvHbmQ-7KWzVM85Hd2kE6iOmMcfUq9f=EGQ@mail.gmail.com>
	<CAF5_5cyaX_i=+WXEHe+_ccgVJmvHcdY6HRFOk32zDh_hvaoHaw@mail.gmail.com>
Message-ID: <CAF37_Nd8t=CYNCAQYW7MnDJJs3=XwZ-THxKUK2SLuwxFNjgwiw@mail.gmail.com>

I feared that might be the situation - thanks for confirming. I'll be
toying with some creative options then. Thanks again,

Brad

On Mon, Aug 17, 2015 at 7:26 PM, Ken Beath <ken.beath at mq.edu.au> wrote:

> For Cox survival analysis there is no residual as part of the model, hence
> no residual variance.
>
> Ken
>
> On 18 August 2015 at 02:01, Bradley Carlson <carbrae at gmail.com> wrote:
>
>> I'm working on an analysis of the amount of time it takes an animal to
>> perform a behavior. This data is right-censored, as we stopped waiting
>> after 10 minutes and simply had to record "10+ minutes" for any animals
>> that didn't perform the behavior. The data is well suited for a Cox
>> proportional hazards 'survival' analysis in this regard. However, I have
>> multiple measurements of each individual animal (random effect) and would
>> like to quantify the individual repeatability of the behavior in addition
>> to the effect of covariates. In a typical LMM, this would be the (variance
>> among random intercepts) / (variance among random intercepts + residual
>> variance).
>>
>> I can fit a mixed effects survival analysis in the package 'coxme'. It
>> provides a random effect variance, but no residual variance. Is it
>> possible, given the mechanics of fitting an ME survival analysis, to get a
>> residual variance?
>>
>> Thank you in advance!
>>
>> --
>>
>> Bradley Evan Carlson
>> Assistant Professor of Biology
>> Wabash College, Crawfordsville IN
>>
>> Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
>> Website: https://sites.google.com/site/bradleyecarlson/home
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Level 2, AHH
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and m...{{dropped:21}}


From Farrar.David at epa.gov  Tue Aug 18 21:30:52 2015
From: Farrar.David at epa.gov (Farrar, David)
Date: Tue, 18 Aug 2015 19:30:52 +0000
Subject: [R-sig-ME] Residual variance for mixed effects survival analysis
In-Reply-To: <CAF37_Nd8t=CYNCAQYW7MnDJJs3=XwZ-THxKUK2SLuwxFNjgwiw@mail.gmail.com>
References: <CAF37_NcwcyZ5ZZbMvHbmQ-7KWzVM85Hd2kE6iOmMcfUq9f=EGQ@mail.gmail.com>
	<CAF5_5cyaX_i=+WXEHe+_ccgVJmvHcdY6HRFOk32zDh_hvaoHaw@mail.gmail.com>
	<CAF37_Nd8t=CYNCAQYW7MnDJJs3=XwZ-THxKUK2SLuwxFNjgwiw@mail.gmail.com>
Message-ID: <CY1PR09MB0758364994DE1AF74607788D9A780@CY1PR09MB0758.namprd09.prod.outlook.com>


It would seem odd to me if there have been no models for this situation with analogues of extra-binomial variation and some sort of time series structure, although such a model might not be termed "Cox" modeling.

regards,
David

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bradley Carlson
Sent: Tuesday, August 18, 2015 12:39 PM
To: Ken Beath
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Residual variance for mixed effects survival analysis

I feared that might be the situation - thanks for confirming. I'll be toying with some creative options then. Thanks again,

Brad

On Mon, Aug 17, 2015 at 7:26 PM, Ken Beath <ken.beath at mq.edu.au> wrote:

> For Cox survival analysis there is no residual as part of the model, 
> hence no residual variance.
>
> Ken
>
> On 18 August 2015 at 02:01, Bradley Carlson <carbrae at gmail.com> wrote:
>
>> I'm working on an analysis of the amount of time it takes an animal 
>> to perform a behavior. This data is right-censored, as we stopped 
>> waiting after 10 minutes and simply had to record "10+ minutes" for 
>> any animals that didn't perform the behavior. The data is well suited 
>> for a Cox proportional hazards 'survival' analysis in this regard. 
>> However, I have multiple measurements of each individual animal 
>> (random effect) and would like to quantify the individual 
>> repeatability of the behavior in addition to the effect of 
>> covariates. In a typical LMM, this would be the (variance among 
>> random intercepts) / (variance among random intercepts + residual variance).
>>
>> I can fit a mixed effects survival analysis in the package 'coxme'. 
>> It provides a random effect variance, but no residual variance. Is it 
>> possible, given the mechanics of fitting an ME survival analysis, to 
>> get a residual variance?
>>
>> Thank you in advance!
>>
>> --
>>
>> Bradley Evan Carlson
>> Assistant Professor of Biology
>> Wabash College, Crawfordsville IN
>>
>> Email: *carlsonb at wabash.edu* <+carlsonb at wabash.edu>
>> Website: https://sites.google.com/site/bradleyecarlson/home
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
>
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
>
> Phone: +61 (0)2 9850 8516
>
> Level 2, AHH
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
>
> CRICOS Provider No 00002J
> This message is intended for the addressee named and=2...{{dropped:7}}


From singmann at psychologie.uzh.ch  Wed Aug 19 11:20:36 2015
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Wed, 19 Aug 2015 11:20:36 +0200
Subject: [R-sig-ME] New afex version (0.14-2): || notation works with factors
Message-ID: <mr1hor$567$1@ger.gmane.org>

Dear list,

I have released a new version of afex (0.14-2) to CRAN with several new 
features which may be of interest. It should appear on your CRAN mirror 
soon if it is not already there.

The most important feature for this audience is perhaps that afex can 
now correctly suppress the estimation of correlations among factor 
random slopes using the "||" notation. This is achieved by first 
creating the model matrix for the random factors and then passing the so 
created numerical variables instead of the original factors. For 
convenience, I have created a wrapper function, lmer_alt(), which 
expands the random effects in such a way but otherwise behaves like lmer 
(or glmer if a family argument is passed). That also means it does not 
enforce a specific factor coding (in contrast to the other afex 
functions that per default use sum-to-zero contrasts).
The following example (from Reinhold Kliegl, 
https://rpubs.com/Reinhold/22193) shows this:

require(afex)
data("Machines", package = "MEMSS")
contrasts(Machines$Machine) <- contr.treatment(3)
m1a <- lmer(score ~ Machine + (Machine|Worker), Machines, REML=FALSE)
summary(m1a)$varcor
## Groups   Name        Std.Dev. Corr
## Worker   (Intercept) 3.71695
##          Machine2    5.35595   0.488
##          Machine3    3.35308  -0.363  0.296
## Residual             0.96158
m1b <- lmer(score ~ Machine + (Machine||Worker), Machines, REML=FALSE)
summary(m1b)$varcor
## Groups   Name        Std.Dev. Corr
## Worker   (Intercept) 0.49674
## Worker.1 MachineA    3.68361
##          MachineB    7.85482  0.805
##          MachineC    3.96965  0.618 0.772
## Residual             0.96158
m1c <- lmer_alt(score~Machine+(Machine||Worker), Machines, REML=FALSE)
summary(m1c)$varcor
## Groups   Name         Std.Dev.
## Worker   (Intercept)  3.71176
## Worker.1 re1.Machine2 5.36912
## Worker.2 re1.Machine3 3.30637
## Residual              0.96257

As can be seen, lmer_alt behaves like one would be expect and not like 
lmer. This behavior can also be activated for the afex mixed() function 
by setting expand_re = TRUE.

Furthermore, afex is now fully integrated with lsmeans for all types of 
follow-up tests and contrasts. This is particularly noteworthy for the 
ANOVA functions (which have been renamed to aov_ez, aov_car, and aov_4) 
which now return per default an object of class "afex_aov". This object 
contains the ANOVA estimated with both car::Anova (for correct Type 
II/II tests) and stats::aov (for follow-up tests) and can be directly 
passed to lsmeans. This means one can directly run any type of post-hoc 
tests/contrasts on ANOVA independent of whether or not these tests 
relate to between- or within-factors or a mix thereof. The new vignette 
shows this in detail:
https://cran.rstudio.com/web/packages/afex/vignettes/anova_posthoc.html

The full list of changes is available here:
https://cran.rstudio.com/web/packages/afex/NEWS

afex has also moved to github now (where all the cool kids are) so I am 
happy for any comments there (https://github.com/singmann/afex), here, 
or per mail.

Cheers,
Henrik

PS: Due to a bug in the current CRAN version of stringi the following 
warning message appears regularly in afex, but can be safely ignored:
In stri_c(..., sep = sep, collapse = collapse, ignore_null = TRUE) :
   longer object length is not a multiple of shorter object length

Updating stringi from github (https://github.com/Rexamine/stringi/) 
removes this warning.


From joaquin.aldabe at gmail.com  Wed Aug 19 16:39:01 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 19 Aug 2015 11:39:01 -0300
Subject: [R-sig-ME] glm question
Message-ID: <CAMM93=+SAFWSCw0Bs5HL7w3O1ppA5vkjWXys4EYrynxWkEC_4Q@mail.gmail.com>

Dear All, I?m running a glm with poisson errors and have a doubt when
ploting the predicted values. One of my variables has a positive slope in
the summary output, but when I plot the predicted values on the original
plot it draws a line with negative slope. I appreciate your comments on
this and any other aspect of the analysis.

Attached is the script and data.

Thanks in advanced,

Joaqu?n.

pd. If this is not the correct forum to ask about glm, please let me know.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

From thierry.onkelinx at inbo.be  Wed Aug 19 16:54:16 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 19 Aug 2015 16:54:16 +0200
Subject: [R-sig-ME] glm question
In-Reply-To: <CAMM93=+SAFWSCw0Bs5HL7w3O1ppA5vkjWXys4EYrynxWkEC_4Q@mail.gmail.com>
References: <CAMM93=+SAFWSCw0Bs5HL7w3O1ppA5vkjWXys4EYrynxWkEC_4Q@mail.gmail.com>
Message-ID: <CAJuCY5wowwNMRYQXwh3yQ6H-a=z7Q8zSq_VJPpZptD-QOegXAQ@mail.gmail.com>

Dear Joaquin,

Your attachments got stripped. It's better to put them somewhere on
line an add a link in your message.

If your problem concerns a glm() then r-help would be a better mailing
list. If it is about glmer() then this mailing list is fine.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-08-19 16:39 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
> Dear All, I?m running a glm with poisson errors and have a doubt when
> ploting the predicted values. One of my variables has a positive slope in
> the summary output, but when I plot the predicted values on the original
> plot it draws a line with negative slope. I appreciate your comments on
> this and any other aspect of the analysis.
>
> Attached is the script and data.
>
> Thanks in advanced,
>
> Joaqu?n.
>
> pd. If this is not the correct forum to ask about glm, please let me know.
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From joaquin.aldabe at gmail.com  Wed Aug 19 17:47:02 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 19 Aug 2015 12:47:02 -0300
Subject: [R-sig-ME] glm question
In-Reply-To: <CAJuCY5wowwNMRYQXwh3yQ6H-a=z7Q8zSq_VJPpZptD-QOegXAQ@mail.gmail.com>
References: <CAMM93=+SAFWSCw0Bs5HL7w3O1ppA5vkjWXys4EYrynxWkEC_4Q@mail.gmail.com>
	<CAJuCY5wowwNMRYQXwh3yQ6H-a=z7Q8zSq_VJPpZptD-QOegXAQ@mail.gmail.com>
Message-ID: <CAMM93=KW+Lr3WYuAZ+JJKQK2+xVO8Y2Bsys2-TCy1RKgZNXeyg@mail.gmail.com>

Thanks Thierry, I?ve attached the data in excel format and the script in
txt. I?ll also write to r-help.
Best wishes,
Joaqu?n.

2015-08-19 11:54 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Joaquin,
>
> Your attachments got stripped. It's better to put them somewhere on
> line an add a link in your message.
>
> If your problem concerns a glm() then r-help would be a better mailing
> list. If it is about glmer() then this mailing list is fine.
>
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2015-08-19 16:39 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
> > Dear All, I?m running a glm with poisson errors and have a doubt when
> > ploting the predicted values. One of my variables has a positive slope in
> > the summary output, but when I plot the predicted values on the original
> > plot it draws a line with negative slope. I appreciate your comments on
> > this and any other aspect of the analysis.
> >
> > Attached is the script and data.
> >
> > Thanks in advanced,
> >
> > Joaqu?n.
> >
> > pd. If this is not the correct forum to ask about glm, please let me
> know.
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
-------------- next part --------------
my4<-read.table(file.choose(), header=T, dec=",")
my4s<-as.data.frame(scale(my4[,c(6,10,12,13,16)], center=T, scale=T))
my4S<-cbind(BBSA=my4$BBSA, Field_name=my4$Field_name,Grassland_type=my4$Grassland_type, Flood=my4$Flood, Year=my4$Year,my4s)

m2.glm=glm(BBSA~AMGP+Distance_to_lagoon+Grass_height, family="quasipoisson", data=my4S
summary(m2.glm)
#residuales
par(mfrow=c(2,2))
plot(m2.glm)#pretty good

#predict
amgp=seq(-0.51, 5.44, length.out=100)
grass=seq(-0.85,2.83, length.out=100)
dist=seq(-1.59,1.53, length.out=100)
newdata=data.frame(AMGP=amgp, Distance_to_lagoon=dist,Grass_height=grass)
pred.m2.glm=exp(predict(m2.glm,newdata))
plot(BBSA~Grass_height, data=my4S)
lines(newdata$Grass_height,pred.m2.glm)
plot(BBSA~AMGP, data=my4S)
lines(newdata$AMGP,pred.m2.glm)#why negative slope if summary output is positive
plot(BBSA~Distance_to_lagoon, data=my4S)
lines(newdata$Distance_to_lagoon, pred.m2.glm)

From ken.beath at mq.edu.au  Thu Aug 20 01:32:22 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Thu, 20 Aug 2015 09:32:22 +1000
Subject: [R-sig-ME] glm question
In-Reply-To: <CAMM93=KW+Lr3WYuAZ+JJKQK2+xVO8Y2Bsys2-TCy1RKgZNXeyg@mail.gmail.com>
References: <CAMM93=+SAFWSCw0Bs5HL7w3O1ppA5vkjWXys4EYrynxWkEC_4Q@mail.gmail.com>
	<CAJuCY5wowwNMRYQXwh3yQ6H-a=z7Q8zSq_VJPpZptD-QOegXAQ@mail.gmail.com>
	<CAMM93=KW+Lr3WYuAZ+JJKQK2+xVO8Y2Bsys2-TCy1RKgZNXeyg@mail.gmail.com>
Message-ID: <CAF5_5cwuSVTMwR=qDTdYece4C2O57K8Rucoe=Rbr5wHfXhE_3w@mail.gmail.com>

The way your data is setup for prediction as grass height varies so do the
other two predictors so the prediction reflects ht is happening in all the
covariates.

Hold the other two constant as you change grass height. What is usually
done is to do this for a series of values of the other predictors and plot
the multiple curves.


Ken

On 20 August 2015 at 01:47, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:

> Thanks Thierry, I?ve attached the data in excel format and the script in
> txt. I?ll also write to r-help.
> Best wishes,
> Joaqu?n.
>
> 2015-08-19 11:54 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
> > Dear Joaquin,
> >
> > Your attachments got stripped. It's better to put them somewhere on
> > line an add a link in your message.
> >
> > If your problem concerns a glm() then r-help would be a better mailing
> > list. If it is about glmer() then this mailing list is fine.
> >
> > Best regards,
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> >
> > 2015-08-19 16:39 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
> > > Dear All, I?m running a glm with poisson errors and have a doubt when
> > > ploting the predicted values. One of my variables has a positive slope
> in
> > > the summary output, but when I plot the predicted values on the
> original
> > > plot it draws a line with negative slope. I appreciate your comments on
> > > this and any other aspect of the analysis.
> > >
> > > Attached is the script and data.
> > >
> > > Thanks in advanced,
> > >
> > > Joaqu?n.
> > >
> > > pd. If this is not the correct forum to ask about glm, please let me
> > know.
> > >
> > > --
> > > *Joaqu?n Aldabe*
> > >
> > > *Grupo Biodiversidad, Ambiente y Sociedad*
> > > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> > >
> > > *Departamento de Conservaci?n*
> > > Aves Uruguay
> > > BirdLife International
> > > Canelones 1164, Montevideo
> > >
> > > https://sites.google.com/site/joaquin.aldabe
> > > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From mariadelc.romero at gmail.com  Fri Aug 21 01:33:52 2015
From: mariadelc.romero at gmail.com (=?UTF-8?Q?Mar=C3=ADa_del_Carmen_Romero?=)
Date: Thu, 20 Aug 2015 20:33:52 -0300
Subject: [R-sig-ME] Parallel version of lmer or glmer?
Message-ID: <CAFA8r3H=3CAb7+kGDR4eNqSMPTOXSfkohPjhofPoqfMxp0NF6g@mail.gmail.com>

Hello,
I want to know if there is a parallel version of lmer or glmer (both of
package lme4).
Thanks
Mar?a

	[[alternative HTML version deleted]]


From kalakouentin at gmail.com  Fri Aug 21 03:23:31 2015
From: kalakouentin at gmail.com (Pantelis Z. Hadjipantelis)
Date: Thu, 20 Aug 2015 18:23:31 -0700
Subject: [R-sig-ME] Parallel version of lmer or glmer?
In-Reply-To: <CAFA8r3H=3CAb7+kGDR4eNqSMPTOXSfkohPjhofPoqfMxp0NF6g@mail.gmail.com>
References: <CAFA8r3H=3CAb7+kGDR4eNqSMPTOXSfkohPjhofPoqfMxp0NF6g@mail.gmail.com>
Message-ID: <55D67D93.6000109@gmail.com>

There is no natively parallel versions of 'lmer' or 'glmer' to my knowledge.

That being said, if the BLAS implementation used (in this case 'Eigen' 
via 'RcppEigen') has multi-core capabilities one can use multiple cores.
Assuming one has OpenMP installed he would need to recompile 'lme4' 
changing the 'Makevars' arguments manually to activate OpenMP. I would 
not do this because I do not know if 'lme4' has been tested against 
multi-core installations; in theory this should make 'lme4' multi-core 
out-of-the-box though.
A starting point for more information on multi-threaded Eigen is here: 
http://eigen.tuxfamily.org/dox/TopicMultiThreading.html; prof. Bates can 
provide a more authoritative opinion on this matter.

One might want to try something safer/easier by changing the BLAS 
implementation R uses.
The BLAS implementation 'OpenBLAS' is relatively easy to install and 
provides a significant speed-up against the BLAS R is distributed with. 
I have used this configuration (and seen it in other people's systems) 
for years without any problems. This will not affect only 'lme4' but all 
the installed packages. In this way one accelerates (and makes 
multi-core) all the BLAS related functionality of R.
For more details on this just google: "openblas R"; they are a few 
guides online describing how to make this change.

Finally, if one is mostly interested in parallelism for the sake of 
bootstrapping, the function 'bootMer' allows bootstrapping a model in 
parallel directly (check the documentation of it  - '?lme4::bootMer').

All best,
Pantelis


On 08/20/2015 04:33 PM, Mar?a del Carmen Romero wrote:
> Hello,
> I want to know if there is a parallel version of lmer or glmer (both of
> package lme4).
> Thanks
> Mar?a
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From aruna.sudarshan at gmail.com  Fri Aug 21 07:59:44 2015
From: aruna.sudarshan at gmail.com (aruna sudarshan)
Date: Fri, 21 Aug 2015 11:29:44 +0530
Subject: [R-sig-ME] repeated measures using lmer
Message-ID: <CAGA5bS-bqgCFUBLHQbe2KBgvq=V=FCBUhGoER9XXPAaWeR_85g@mail.gmail.com>

I am trying to run a linear mixed effects model with the following groups.
My DV is reaction time and fixed factors are time (pre vs.
post:within-subject), condition (congruent vs. incongruent: within
subject), SOA (early vs. late: between subject) and stimulation (vertex vs.
DLPFC: between subject).
My concerns are:
a) I have very few participants in each SOA condition: the early SOA
condition has only 3 participants in the vertex and 4 in the DLPFC condition
while the late SOA condition has 2 participants in the vertex and 4 in the
DLPFC condition

b)2 out of the 4 participants  in the late SOA condition participated in
both vertex and DLPFC condition.

is it possible to compute a lmer with such few participants and how do i
account for random intercepts and slopes with few number of participants?
Thanks for all the help

	[[alternative HTML version deleted]]


From beckyannegilbert at gmail.com  Fri Aug 21 13:04:07 2015
From: beckyannegilbert at gmail.com (Becky Gilbert)
Date: Fri, 21 Aug 2015 12:04:07 +0100
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert contrasts
Message-ID: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>

Dear list,

I'm wondering if someone could help me interpret an interaction between two
factors, when one of the factors uses Helmert contrasts?

I ran a linear mixed effects model (lmer) with reaction times as the DV, 2
fixed factors: Time (2 levels) and Word Type (3 levels), and 2 random
factors: Subjects and Items.  I used Helmert contrasts for the Word Type
factor:
- Contrast 1 = level 1 (Untrained) vs levels 2 & 3 (Trained-related and
Trained-unrelated)
- Contrast 2 = level 2 vs. level 3 (Trained-related vs Trained-unrelated)
The data, contrasts, model, summary and model comparisons are listed at the
end of the message.

Model comparisons with anova() showed a significant interaction between
Time and Word Type.  However, I don't know how to get the statistics for
the interactions between Time and each Word Type contrast.

Based on the t-values for coefficients in the model summary, it looks like
the significant Word Type x Time interaction is driven by the interaction
with the 1st contrast for Word Type (t = 2.61).  However I don't think that
the statistics for the fixed effects coefficients are exactly what I'm
looking forward (they are sequential tests, right?).  And if these are the
appropriate statistics, I'm aware of the problems with trying to get
p-values from these  estimates.  So is there a way to do likelihood ratio
tests for each Word Type contrast, or some other way of interpreting the
Word Type x Time interaction?

Data structure:
> str(rtData)
'data.frame': 1244 obs. of  11 variables:
 $ Subject      : Factor w/ 16 levels "AB","AS","AW",..: 1 1 1 1 1 1 1 1 1
1 ...
 $ Item       : Factor w/ 48 levels "ANT","BANDAGE",..: 3 4 6 12 13 14 22
29 30 34 ...
 $ Response     : int  960 1255 651 1043 671 643 743 695 965 589 ...
 $ Time     : Factor w/ 2 levels "-1","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ WordType     : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ logRT        : num  2.98 3.1 2.81 3.02 2.83 ...

> contrasts(rtData$Time)
   [,1]
-1  0.5
1  -0.5

> contrasts(rtData$WordType)
        [,1] [,2]
0  0.6666667  0.0
1 -0.3333333 -0.5
2 -0.3333333  0.5

Model:
lmer(logRT ~ 1 + WordType + Time + WordType:Time +
                      (1 + Time|Subject) +
                      (1|Item),
                    data = rtData)

REML criterion at convergence: -2061.2
Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.7228 -0.6588 -0.0872  0.5712  3.7790
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Item   (Intercept)     0.000933  0.03054
 Subject  (Intercept)  0.004590  0.06775
          Time1            0.005591  0.07478  0.05
 Residual                 0.009575  0.09785
Number of obs: 1244, groups:  Target, 46; Subject, 16
Fixed effects:
                            Estimate     Std. Error   t value
(Intercept)              2.8765116  0.0177527  162.03
WordType1            0.0111628  0.0110852    1.01
WordType2            0.0007306  0.0071519    0.10
Time1                  -0.0268310  0.0195248   -1.37
WordType1:Time1  0.0301627  0.0115349    2.61
WordType2:Time1 -0.0089123  0.0141624   -0.63

Model comparisons with anova() for main effects and interaction:

-full model vs no Word Type x Time interaction
                               Df     AIC     BIC logLik deviance  Chisq
Chi Df Pr(>Chisq)
rtModelNoInteraction  9 -2077.5 -2031.3 1047.7  -2095.5

rtModelFull               11 -2080.5 -2024.1 1051.2  -2102.5 7.0388      2
   0.02962 *

-full model vs model without Time and interaction
                       Df     AIC     BIC logLik deviance  Chisq Chi Df
Pr(>Chisq)
rtModelNoTime  8 -2077.8 -2036.7 1046.9  -2093.8
rtModelFull      11 -2080.5 -2024.1 1051.2  -2102.5 8.7424      3
 0.03292 *

-full model vs model without Word Type and interaction
                      Df     AIC     BIC logLik deviance  Chisq Chi Df
Pr(>Chisq)
rtModelNoWT  7 -2080.4 -2044.5 1047.2  -2094.4
rtModelFull     11 -2080.5 -2024.1 1051.2  -2102.5 8.0875      4    0.08842
.

Thanks in advance for any advice!
Becky
____________________________________________

Dr Becky Gilbert

	[[alternative HTML version deleted]]


From beckyannegilbert at gmail.com  Fri Aug 21 14:46:49 2015
From: beckyannegilbert at gmail.com (Becky Gilbert)
Date: Fri, 21 Aug 2015 13:46:49 +0100
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert
	contrasts
In-Reply-To: <op.x3ptqoyza3mgvf@armadillo>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
Message-ID: <CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>

Hi Paul,

Thanks very much for the suggestion!  I tried using lsmeans() to get the
pairwise comparisons as you suggested, and the results are below.

I'm a little confused by the results because the pairwise comparison tests
all show p > .05, but the WordType x Time interaction was significant when
tested via model comparisons...?  I think this might be due to the Tukey
adjustment for multiple comparisons, but I'm not sure.  Specifically the
contrast for the two levels of Time at WordType = 2 looks like it might
have been significant before the multiple comparisons correction, thus
accounting for the significance of the interaction term in model
comparisons.  Any thoughts?

Thanks again!
Becky

$lsmeans
WordType = 0:
 Time   lsmean         SE    df lower.CL upper.CL
 -1       2.880592 0.02209390 21.58 2.834721 2.926464
 1        2.887315 0.02144245 22.13 2.842860 2.931769

WordType = 1:
 Time   lsmean         SE    df lower.CL upper.CL
 -1       2.856211 0.02156603 19.78 2.811193 2.901229
 1        2.888640 0.02089339 20.17 2.845080 2.932200

WordType = 2:
 Time   lsmean         SE    df lower.CL upper.CL
 -1       2.852485 0.02181905 20.72 2.807072 2.897898
 1        2.893827 0.02113775 21.12 2.849883 2.937770

Confidence level used: 0.95

$contrasts
WordType = 0:
 contrast    estimate         SE    df t.ratio p.value
 -1 - 1   -0.00672255 0.02078469 19.31  -0.323  0.7498

WordType = 1:
 contrast    estimate         SE    df t.ratio p.value
 -1 - 1   -0.03242907 0.02097452 20.02  -1.546  0.1377

WordType = 2:
 contrast    estimate         SE    df t.ratio p.value
 -1 - 1   -0.04134141 0.02146707 21.93  -1.926  0.0672


____________________________________________

Dr Becky Gilbert

On 21 August 2015 at 12:19, paul debes <paul.debes at utu.fi> wrote:

> Hi Becky,
>
> Maybe you are interested in pairwise comparisons? The "lsmeans" package
> comes in handy.
>
> Try something like this:
>
> library("pbkrtest") # gives you KW-adjusted denDF for tests, but must be
> installed
> library("lsmeans")
>
> Model.lmer.means = lsmeans(Model, spec = pairwise ~ WordType|Time)
> Model.lmer.means = summary(Model.lmer.means)
> Model.lmer.means
>
> Maybe you want the contrast conditional on WordType, not Time? Swap it to:
> "spec = pairwise ~ Time|WordType"
>
> Best,
> Paul
>
>
> On Fri, 21 Aug 2015 14:04:07 +0300, Becky Gilbert <
> beckyannegilbert at gmail.com> wrote:
>
> Dear list,
>>
>> I'm wondering if someone could help me interpret an interaction between
>> two
>> factors, when one of the factors uses Helmert contrasts?
>>
>> I ran a linear mixed effects model (lmer) with reaction times as the DV, 2
>> fixed factors: Time (2 levels) and Word Type (3 levels), and 2 random
>> factors: Subjects and Items.  I used Helmert contrasts for the Word Type
>> factor:
>> - Contrast 1 = level 1 (Untrained) vs levels 2 & 3 (Trained-related and
>> Trained-unrelated)
>> - Contrast 2 = level 2 vs. level 3 (Trained-related vs Trained-unrelated)
>> The data, contrasts, model, summary and model comparisons are listed at
>> the
>> end of the message.
>>
>> Model comparisons with anova() showed a significant interaction between
>> Time and Word Type.  However, I don't know how to get the statistics for
>> the interactions between Time and each Word Type contrast.
>>
>> Based on the t-values for coefficients in the model summary, it looks like
>> the significant Word Type x Time interaction is driven by the interaction
>> with the 1st contrast for Word Type (t = 2.61).  However I don't think
>> that
>> the statistics for the fixed effects coefficients are exactly what I'm
>> looking forward (they are sequential tests, right?).  And if these are the
>> appropriate statistics, I'm aware of the problems with trying to get
>> p-values from these  estimates.  So is there a way to do likelihood ratio
>> tests for each Word Type contrast, or some other way of interpreting the
>> Word Type x Time interaction?
>>
>> Data structure:
>>
>>> str(rtData)
>>>
>> 'data.frame': 1244 obs. of  11 variables:
>>  $ Subject      : Factor w/ 16 levels "AB","AS","AW",..: 1 1 1 1 1 1 1 1 1
>> 1 ...
>>  $ Item       : Factor w/ 48 levels "ANT","BANDAGE",..: 3 4 6 12 13 14 22
>> 29 30 34 ...
>>  $ Response     : int  960 1255 651 1043 671 643 743 695 965 589 ...
>>  $ Time     : Factor w/ 2 levels "-1","1": 1 1 1 1 1 1 1 1 1 1 ...
>>  $ WordType     : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...
>>  $ logRT        : num  2.98 3.1 2.81 3.02 2.83 ...
>>
>> contrasts(rtData$Time)
>>>
>>    [,1]
>> -1  0.5
>> 1  -0.5
>>
>> contrasts(rtData$WordType)
>>>
>>         [,1] [,2]
>> 0  0.6666667  0.0
>> 1 -0.3333333 -0.5
>> 2 -0.3333333  0.5
>>
>> Model:
>> lmer(logRT ~ 1 + WordType + Time + WordType:Time +
>>                       (1 + Time|Subject) +
>>                       (1|Item),
>>                     data = rtData)
>>
>> REML criterion at convergence: -2061.2
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -2.7228 -0.6588 -0.0872  0.5712  3.7790
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  Item   (Intercept)     0.000933  0.03054
>>  Subject  (Intercept)  0.004590  0.06775
>>           Time1            0.005591  0.07478  0.05
>>  Residual                 0.009575  0.09785
>> Number of obs: 1244, groups:  Target, 46; Subject, 16
>> Fixed effects:
>>                             Estimate     Std. Error   t value
>> (Intercept)              2.8765116  0.0177527  162.03
>> WordType1            0.0111628  0.0110852    1.01
>> WordType2            0.0007306  0.0071519    0.10
>> Time1                  -0.0268310  0.0195248   -1.37
>> WordType1:Time1  0.0301627  0.0115349    2.61
>> WordType2:Time1 -0.0089123  0.0141624   -0.63
>>
>> Model comparisons with anova() for main effects and interaction:
>>
>> -full model vs no Word Type x Time interaction
>>                                Df     AIC     BIC logLik deviance  Chisq
>> Chi Df Pr(>Chisq)
>> rtModelNoInteraction  9 -2077.5 -2031.3 1047.7  -2095.5
>>
>> rtModelFull               11 -2080.5 -2024.1 1051.2  -2102.5 7.0388      2
>>    0.02962 *
>>
>> -full model vs model without Time and interaction
>>                        Df     AIC     BIC logLik deviance  Chisq Chi Df
>> Pr(>Chisq)
>> rtModelNoTime  8 -2077.8 -2036.7 1046.9  -2093.8
>> rtModelFull      11 -2080.5 -2024.1 1051.2  -2102.5 8.7424      3
>>  0.03292 *
>>
>> -full model vs model without Word Type and interaction
>>                       Df     AIC     BIC logLik deviance  Chisq Chi Df
>> Pr(>Chisq)
>> rtModelNoWT  7 -2080.4 -2044.5 1047.2  -2094.4
>> rtModelFull     11 -2080.5 -2024.1 1051.2  -2102.5 8.0875      4
>> 0.08842
>> .
>>
>> Thanks in advance for any advice!
>> Becky
>> ____________________________________________
>>
>> Dr Becky Gilbert
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Paul Debes
> DFG Research Fellow
> University of Turku
> Department of Biology
> It?inen Pitk?katu 4
> 20520 Turku
> Finland
>

	[[alternative HTML version deleted]]


From beckyannegilbert at gmail.com  Fri Aug 21 15:23:46 2015
From: beckyannegilbert at gmail.com (Becky Gilbert)
Date: Fri, 21 Aug 2015 14:23:46 +0100
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert
	contrasts
In-Reply-To: <CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
	<CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
Message-ID: <CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>

Hi Paul/List,

After thinking about this a bit more, I don't think planned comparisons
gives me what I'm looking for.  I want to know whether the effect of Time
is different for WordType = 0 (level 1) vs the other two levels combined -
this is WordType contrast 1.  I also want to know whether the effect of
Time is different for WordType = 1 vs WordType = 2 (i.e. level 2 vs level
3) - this is WordType contrast 2.

I think the use of planned comparisons here would defeat the purpose of my
contrasts, but maybe I'm missing something?

Thanks!
Becky

____________________________________________

Dr Becky Gilbert

On 21 August 2015 at 13:46, Becky Gilbert <beckyannegilbert at gmail.com>
wrote:

> Hi Paul,
>
> Thanks very much for the suggestion!  I tried using lsmeans() to get the
> pairwise comparisons as you suggested, and the results are below.
>
> I'm a little confused by the results because the pairwise comparison tests
> all show p > .05, but the WordType x Time interaction was significant when
> tested via model comparisons...?  I think this might be due to the Tukey
> adjustment for multiple comparisons, but I'm not sure.  Specifically the
> contrast for the two levels of Time at WordType = 2 looks like it might
> have been significant before the multiple comparisons correction, thus
> accounting for the significance of the interaction term in model
> comparisons.  Any thoughts?
>
> Thanks again!
> Becky
>
> $lsmeans
> WordType = 0:
>  Time   lsmean         SE    df lower.CL upper.CL
>  -1       2.880592 0.02209390 21.58 2.834721 2.926464
>  1        2.887315 0.02144245 22.13 2.842860 2.931769
>
> WordType = 1:
>  Time   lsmean         SE    df lower.CL upper.CL
>  -1       2.856211 0.02156603 19.78 2.811193 2.901229
>  1        2.888640 0.02089339 20.17 2.845080 2.932200
>
> WordType = 2:
>  Time   lsmean         SE    df lower.CL upper.CL
>  -1       2.852485 0.02181905 20.72 2.807072 2.897898
>  1        2.893827 0.02113775 21.12 2.849883 2.937770
>
> Confidence level used: 0.95
>
> $contrasts
> WordType = 0:
>  contrast    estimate         SE    df t.ratio p.value
>  -1 - 1   -0.00672255 0.02078469 19.31  -0.323  0.7498
>
> WordType = 1:
>  contrast    estimate         SE    df t.ratio p.value
>  -1 - 1   -0.03242907 0.02097452 20.02  -1.546  0.1377
>
> WordType = 2:
>  contrast    estimate         SE    df t.ratio p.value
>  -1 - 1   -0.04134141 0.02146707 21.93  -1.926  0.0672
>
>
> ____________________________________________
>
> Dr Becky Gilbert
>
> On 21 August 2015 at 12:19, paul debes <paul.debes at utu.fi> wrote:
>
>> Hi Becky,
>>
>> Maybe you are interested in pairwise comparisons? The "lsmeans" package
>> comes in handy.
>>
>> Try something like this:
>>
>> library("pbkrtest") # gives you KW-adjusted denDF for tests, but must be
>> installed
>> library("lsmeans")
>>
>> Model.lmer.means = lsmeans(Model, spec = pairwise ~ WordType|Time)
>> Model.lmer.means = summary(Model.lmer.means)
>> Model.lmer.means
>>
>> Maybe you want the contrast conditional on WordType, not Time? Swap it to:
>> "spec = pairwise ~ Time|WordType"
>>
>> Best,
>> Paul
>>
>>
>> On Fri, 21 Aug 2015 14:04:07 +0300, Becky Gilbert <
>> beckyannegilbert at gmail.com> wrote:
>>
>> Dear list,
>>>
>>> I'm wondering if someone could help me interpret an interaction between
>>> two
>>> factors, when one of the factors uses Helmert contrasts?
>>>
>>> I ran a linear mixed effects model (lmer) with reaction times as the DV,
>>> 2
>>> fixed factors: Time (2 levels) and Word Type (3 levels), and 2 random
>>> factors: Subjects and Items.  I used Helmert contrasts for the Word Type
>>> factor:
>>> - Contrast 1 = level 1 (Untrained) vs levels 2 & 3 (Trained-related and
>>> Trained-unrelated)
>>> - Contrast 2 = level 2 vs. level 3 (Trained-related vs Trained-unrelated)
>>> The data, contrasts, model, summary and model comparisons are listed at
>>> the
>>> end of the message.
>>>
>>> Model comparisons with anova() showed a significant interaction between
>>> Time and Word Type.  However, I don't know how to get the statistics for
>>> the interactions between Time and each Word Type contrast.
>>>
>>> Based on the t-values for coefficients in the model summary, it looks
>>> like
>>> the significant Word Type x Time interaction is driven by the interaction
>>> with the 1st contrast for Word Type (t = 2.61).  However I don't think
>>> that
>>> the statistics for the fixed effects coefficients are exactly what I'm
>>> looking forward (they are sequential tests, right?).  And if these are
>>> the
>>> appropriate statistics, I'm aware of the problems with trying to get
>>> p-values from these  estimates.  So is there a way to do likelihood ratio
>>> tests for each Word Type contrast, or some other way of interpreting the
>>> Word Type x Time interaction?
>>>
>>> Data structure:
>>>
>>>> str(rtData)
>>>>
>>> 'data.frame': 1244 obs. of  11 variables:
>>>  $ Subject      : Factor w/ 16 levels "AB","AS","AW",..: 1 1 1 1 1 1 1 1
>>> 1
>>> 1 ...
>>>  $ Item       : Factor w/ 48 levels "ANT","BANDAGE",..: 3 4 6 12 13 14 22
>>> 29 30 34 ...
>>>  $ Response     : int  960 1255 651 1043 671 643 743 695 965 589 ...
>>>  $ Time     : Factor w/ 2 levels "-1","1": 1 1 1 1 1 1 1 1 1 1 ...
>>>  $ WordType     : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...
>>>  $ logRT        : num  2.98 3.1 2.81 3.02 2.83 ...
>>>
>>> contrasts(rtData$Time)
>>>>
>>>    [,1]
>>> -1  0.5
>>> 1  -0.5
>>>
>>> contrasts(rtData$WordType)
>>>>
>>>         [,1] [,2]
>>> 0  0.6666667  0.0
>>> 1 -0.3333333 -0.5
>>> 2 -0.3333333  0.5
>>>
>>> Model:
>>> lmer(logRT ~ 1 + WordType + Time + WordType:Time +
>>>                       (1 + Time|Subject) +
>>>                       (1|Item),
>>>                     data = rtData)
>>>
>>> REML criterion at convergence: -2061.2
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -2.7228 -0.6588 -0.0872  0.5712  3.7790
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev. Corr
>>>  Item   (Intercept)     0.000933  0.03054
>>>  Subject  (Intercept)  0.004590  0.06775
>>>           Time1            0.005591  0.07478  0.05
>>>  Residual                 0.009575  0.09785
>>> Number of obs: 1244, groups:  Target, 46; Subject, 16
>>> Fixed effects:
>>>                             Estimate     Std. Error   t value
>>> (Intercept)              2.8765116  0.0177527  162.03
>>> WordType1            0.0111628  0.0110852    1.01
>>> WordType2            0.0007306  0.0071519    0.10
>>> Time1                  -0.0268310  0.0195248   -1.37
>>> WordType1:Time1  0.0301627  0.0115349    2.61
>>> WordType2:Time1 -0.0089123  0.0141624   -0.63
>>>
>>> Model comparisons with anova() for main effects and interaction:
>>>
>>> -full model vs no Word Type x Time interaction
>>>                                Df     AIC     BIC logLik deviance  Chisq
>>> Chi Df Pr(>Chisq)
>>> rtModelNoInteraction  9 -2077.5 -2031.3 1047.7  -2095.5
>>>
>>> rtModelFull               11 -2080.5 -2024.1 1051.2  -2102.5 7.0388
>>> 2
>>>    0.02962 *
>>>
>>> -full model vs model without Time and interaction
>>>                        Df     AIC     BIC logLik deviance  Chisq Chi Df
>>> Pr(>Chisq)
>>> rtModelNoTime  8 -2077.8 -2036.7 1046.9  -2093.8
>>> rtModelFull      11 -2080.5 -2024.1 1051.2  -2102.5 8.7424      3
>>>  0.03292 *
>>>
>>> -full model vs model without Word Type and interaction
>>>                       Df     AIC     BIC logLik deviance  Chisq Chi Df
>>> Pr(>Chisq)
>>> rtModelNoWT  7 -2080.4 -2044.5 1047.2  -2094.4
>>> rtModelFull     11 -2080.5 -2024.1 1051.2  -2102.5 8.0875      4
>>> 0.08842
>>> .
>>>
>>> Thanks in advance for any advice!
>>> Becky
>>> ____________________________________________
>>>
>>> Dr Becky Gilbert
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Paul Debes
>> DFG Research Fellow
>> University of Turku
>> Department of Biology
>> It?inen Pitk?katu 4
>> 20520 Turku
>> Finland
>>
>
>

	[[alternative HTML version deleted]]


From aduahgya at mtu.edu  Fri Aug 21 16:21:09 2015
From: aduahgya at mtu.edu (Akwasi Duah-Gyamfi)
Date: Fri, 21 Aug 2015 10:21:09 -0400
Subject: [R-sig-ME] mixed effects - unequal time interval
Message-ID: <CAE9oN5zJ08w3YmJa4HwVvOvccYpWcqa9kk_dkNRzmLW2BHjS+g@mail.gmail.com>

Dear Colleagues,
I would be appreciate any advice with regard to the handling of unequal
time interval in repeated measures regression with mixed models.

My objective is to examine effects of logging treatments (high, moderate,
low intensities) on tree species abundance over time (6, 10, 20, 36 months
after logging). I sampled plots in blocks imposed with the treatments .
Thus equal number of plots were randomly located in each of the blocks.

As an example, i modeled abundance in a repeated measures framework with
explanatory variables (treatment and time - of particular interest here)
with block/plot as the random effects

mymodel<-lme(abundance~treatment+treatment*month, random=~1 | block/plot,
data=sppghana, correlation=corAR(1))

Please, is this an appropriate usage of the AR(1) structure? Is there an
alternative way of handling the unequal time interval?

Akwasi

	[[alternative HTML version deleted]]


From aruna.sudarshan at gmail.com  Fri Aug 21 04:06:18 2015
From: aruna.sudarshan at gmail.com (aruna sudarshan)
Date: Fri, 21 Aug 2015 04:06:18 +0200
Subject: [R-sig-ME] repeated measures using lmer
Message-ID: <CAGA5bS9QpN5nOv=fLd1eQOasmnfSm-v+QPi6jGMCPKjfZ8AtFw@mail.gmail.com>

I am trying to run a linear mixed effects model with the following groups.
My DV is reaction time and fixed factors are time (pre vs.
post:within-subject), condition (congruent vs. incongruent: within
subject), SOA (early vs. late: between subject) and stimulation (vertex vs.
DLPFC: between subject).
My concerns are:
a) I have very few participants in each SOA condition: the early SOA
condition has only 3 participants in the vertex and 4 in the DLPFC condition
while the late SOA condition has 2 participants in the vertex and 4 in the
DLPFC condition

b)2 out of the 4 participants  in the late SOA condition participated in
both vertex and DLPFC condition.

is it possible to compute a lmer with such few participants and how do i
account for random intercepts and slopes with few number of participants?
Thanks for all the help

	[[alternative HTML version deleted]]


From g.southon at sheffield.ac.uk  Fri Aug 21 18:36:47 2015
From: g.southon at sheffield.ac.uk (Georgina Southon)
Date: Fri, 21 Aug 2015 17:36:47 +0100
Subject: [R-sig-ME] Mixed cumulative link modelling - error message
Message-ID: <4A5D204F-13D6-40E8-8834-5039859BFCE8@sheffield.ac.uk>

Hi,

I hope someone can help. I have problems fitting a cumulative link mixed model to my data.
Looking at the str output, rating shows as an integer, despite the fact that it shows as an ordered factor when asked is.factor. Is this the problem or is there something else I have overlooked?

str(bob)
'data.frame':	283 obs. of  4 variables:
 $ site     : Factor w/ 10 levels "ADD","BH","BR",..: 4 4 4 4 4 4 4 4 4 4 ...
 $ person   : Factor w/ 283 levels "ADD10","ADD11",..: 80 91 102 104 105 106 107 108 109 81 ...
 $ treatment: Factor w/ 2 levels "CONTROL","MEADOW": 2 2 2 2 2 2 2 2 2 2 ...
 $ rating   : int  4 3 4 2 3 4 5 5 5 3 ...
> 
> m1<-clmm2(rating~treatment,random=person,data=bob)

Error in clm2(location = rating ~ treatment, data = bob, subset = c("1",  : 
  response needs to be a factor

Thanks for any feedback / advice!



	[[alternative HTML version deleted]]


From drmccloy at uw.edu  Fri Aug 21 19:39:23 2015
From: drmccloy at uw.edu (Dan McCloy)
Date: Fri, 21 Aug 2015 10:39:23 -0700
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert
	contrasts
In-Reply-To: <CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
	<CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
	<CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>
Message-ID: <CAOE0pY=NTCZwOYz9N0tsqpCcR5rrzjjW_bGSA+J3tsjWZqiuuA@mail.gmail.com>

As a word of caution, you seem to have set up your factor coding to make
interpretation especially tricky. The coding of your "Time1" variable is
set up so that your factor level of "-1" has a positive coefficient, and
your factor level of "1" has a negative coefficient.  Before doing anything
else, I recommend you re-run the model after re-setting the contrasts for
"Time" so that your textual levels have the same sign as their coefficients
in the model (personally I would go further and re-code the factor as "Pos"
and "Neg" or some other textual shorthand that cannot be confused with row
or column numbers of the contrast matrix).  I also usually set the row
names of contrast matrices to be actual names, so that the lmer output
names the coefficients in a way that is harder for me to mis-interpret
(e.g., as "TimePos" or "TimeNeg" instead of "Time1").  While you're at it,
if you're interested in "treatment" vs "no treatment" you might consider
re-setting the contrasts for the WordType factor as well.  You have this:

        [,1] [,2]
0  0.6666667  0.0  # untrained
1 -0.3333333 -0.5  # trained-related
2 -0.3333333  0.5  # trained-unrelated

which means that *positive* coefficient estimates for factor 1 mean that
"untrained" increases RT.  Similar comment for related vs. unrelated.  I
would recommend swapping the signs on both factors so that anything that is
"un-" is negative, like this:

        [,1] [,2]
0 -0.6666667  0.0  # untrained
1  0.3333333  0.5  # trained-related
2  0.3333333 -0.5  # trained-unrelated

As far as interpreting the model coefficients for the interactions:

WordType1:Time1  0.0301627  0.0115349    2.61
WordType2:Time1 -0.0089123  0.0141624   -0.63

This says that comparing  cases of "WordType1" (which curently means
"untrained minus trained" in your experiment) combined with "Time1" (which
I think means Time=1 or what I'm calling "Pos") has a positive coefficient
(the combination increases log reaction time, or slows people down)
relative to what you would expect if "WordType" and "Time" contributed
independently to reaction time.  In other words, I think this means that
lack of training slows people down more when Time=1 than when Time=-1
(though the mismatch between signs of the factor levels and contrast
coefficients for the Time variable make me hesitate as to whether I said
that last bit backwards).

Hope it helps, and good luck.
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington


On Fri, Aug 21, 2015 at 6:23 AM, Becky Gilbert <beckyannegilbert at gmail.com>
wrote:

> Hi Paul/List,
>
> After thinking about this a bit more, I don't think planned comparisons
> gives me what I'm looking for.  I want to know whether the effect of Time
> is different for WordType = 0 (level 1) vs the other two levels combined -
> this is WordType contrast 1.  I also want to know whether the effect of
> Time is different for WordType = 1 vs WordType = 2 (i.e. level 2 vs level
> 3) - this is WordType contrast 2.
>
> I think the use of planned comparisons here would defeat the purpose of my
> contrasts, but maybe I'm missing something?
>
> Thanks!
> Becky
>
> ____________________________________________
>
> Dr Becky Gilbert
>
> On 21 August 2015 at 13:46, Becky Gilbert <beckyannegilbert at gmail.com>
> wrote:
>
> > Hi Paul,
> >
> > Thanks very much for the suggestion!  I tried using lsmeans() to get the
> > pairwise comparisons as you suggested, and the results are below.
> >
> > I'm a little confused by the results because the pairwise comparison
> tests
> > all show p > .05, but the WordType x Time interaction was significant
> when
> > tested via model comparisons...?  I think this might be due to the Tukey
> > adjustment for multiple comparisons, but I'm not sure.  Specifically the
> > contrast for the two levels of Time at WordType = 2 looks like it might
> > have been significant before the multiple comparisons correction, thus
> > accounting for the significance of the interaction term in model
> > comparisons.  Any thoughts?
> >
> > Thanks again!
> > Becky
> >
> > $lsmeans
> > WordType = 0:
> >  Time   lsmean         SE    df lower.CL upper.CL
> >  -1       2.880592 0.02209390 21.58 2.834721 2.926464
> >  1        2.887315 0.02144245 22.13 2.842860 2.931769
> >
> > WordType = 1:
> >  Time   lsmean         SE    df lower.CL upper.CL
> >  -1       2.856211 0.02156603 19.78 2.811193 2.901229
> >  1        2.888640 0.02089339 20.17 2.845080 2.932200
> >
> > WordType = 2:
> >  Time   lsmean         SE    df lower.CL upper.CL
> >  -1       2.852485 0.02181905 20.72 2.807072 2.897898
> >  1        2.893827 0.02113775 21.12 2.849883 2.937770
> >
> > Confidence level used: 0.95
> >
> > $contrasts
> > WordType = 0:
> >  contrast    estimate         SE    df t.ratio p.value
> >  -1 - 1   -0.00672255 0.02078469 19.31  -0.323  0.7498
> >
> > WordType = 1:
> >  contrast    estimate         SE    df t.ratio p.value
> >  -1 - 1   -0.03242907 0.02097452 20.02  -1.546  0.1377
> >
> > WordType = 2:
> >  contrast    estimate         SE    df t.ratio p.value
> >  -1 - 1   -0.04134141 0.02146707 21.93  -1.926  0.0672
> >
> >
> > ____________________________________________
> >
> > Dr Becky Gilbert
> >
> > On 21 August 2015 at 12:19, paul debes <paul.debes at utu.fi> wrote:
> >
> >> Hi Becky,
> >>
> >> Maybe you are interested in pairwise comparisons? The "lsmeans" package
> >> comes in handy.
> >>
> >> Try something like this:
> >>
> >> library("pbkrtest") # gives you KW-adjusted denDF for tests, but must be
> >> installed
> >> library("lsmeans")
> >>
> >> Model.lmer.means = lsmeans(Model, spec = pairwise ~ WordType|Time)
> >> Model.lmer.means = summary(Model.lmer.means)
> >> Model.lmer.means
> >>
> >> Maybe you want the contrast conditional on WordType, not Time? Swap it
> to:
> >> "spec = pairwise ~ Time|WordType"
> >>
> >> Best,
> >> Paul
> >>
> >>
> >> On Fri, 21 Aug 2015 14:04:07 +0300, Becky Gilbert <
> >> beckyannegilbert at gmail.com> wrote:
> >>
> >> Dear list,
> >>>
> >>> I'm wondering if someone could help me interpret an interaction between
> >>> two
> >>> factors, when one of the factors uses Helmert contrasts?
> >>>
> >>> I ran a linear mixed effects model (lmer) with reaction times as the
> DV,
> >>> 2
> >>> fixed factors: Time (2 levels) and Word Type (3 levels), and 2 random
> >>> factors: Subjects and Items.  I used Helmert contrasts for the Word
> Type
> >>> factor:
> >>> - Contrast 1 = level 1 (Untrained) vs levels 2 & 3 (Trained-related and
> >>> Trained-unrelated)
> >>> - Contrast 2 = level 2 vs. level 3 (Trained-related vs
> Trained-unrelated)
> >>> The data, contrasts, model, summary and model comparisons are listed at
> >>> the
> >>> end of the message.
> >>>
> >>> Model comparisons with anova() showed a significant interaction between
> >>> Time and Word Type.  However, I don't know how to get the statistics
> for
> >>> the interactions between Time and each Word Type contrast.
> >>>
> >>> Based on the t-values for coefficients in the model summary, it looks
> >>> like
> >>> the significant Word Type x Time interaction is driven by the
> interaction
> >>> with the 1st contrast for Word Type (t = 2.61).  However I don't think
> >>> that
> >>> the statistics for the fixed effects coefficients are exactly what I'm
> >>> looking forward (they are sequential tests, right?).  And if these are
> >>> the
> >>> appropriate statistics, I'm aware of the problems with trying to get
> >>> p-values from these  estimates.  So is there a way to do likelihood
> ratio
> >>> tests for each Word Type contrast, or some other way of interpreting
> the
> >>> Word Type x Time interaction?
> >>>
> >>> Data structure:
> >>>
> >>>> str(rtData)
> >>>>
> >>> 'data.frame': 1244 obs. of  11 variables:
> >>>  $ Subject      : Factor w/ 16 levels "AB","AS","AW",..: 1 1 1 1 1 1 1
> 1
> >>> 1
> >>> 1 ...
> >>>  $ Item       : Factor w/ 48 levels "ANT","BANDAGE",..: 3 4 6 12 13 14
> 22
> >>> 29 30 34 ...
> >>>  $ Response     : int  960 1255 651 1043 671 643 743 695 965 589 ...
> >>>  $ Time     : Factor w/ 2 levels "-1","1": 1 1 1 1 1 1 1 1 1 1 ...
> >>>  $ WordType     : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1
> ...
> >>>  $ logRT        : num  2.98 3.1 2.81 3.02 2.83 ...
> >>>
> >>> contrasts(rtData$Time)
> >>>>
> >>>    [,1]
> >>> -1  0.5
> >>> 1  -0.5
> >>>
> >>> contrasts(rtData$WordType)
> >>>>
> >>>         [,1] [,2]
> >>> 0  0.6666667  0.0
> >>> 1 -0.3333333 -0.5
> >>> 2 -0.3333333  0.5
> >>>
> >>> Model:
> >>> lmer(logRT ~ 1 + WordType + Time + WordType:Time +
> >>>                       (1 + Time|Subject) +
> >>>                       (1|Item),
> >>>                     data = rtData)
> >>>
> >>> REML criterion at convergence: -2061.2
> >>> Scaled residuals:
> >>>     Min      1Q  Median      3Q     Max
> >>> -2.7228 -0.6588 -0.0872  0.5712  3.7790
> >>> Random effects:
> >>>  Groups   Name        Variance Std.Dev. Corr
> >>>  Item   (Intercept)     0.000933  0.03054
> >>>  Subject  (Intercept)  0.004590  0.06775
> >>>           Time1            0.005591  0.07478  0.05
> >>>  Residual                 0.009575  0.09785
> >>> Number of obs: 1244, groups:  Target, 46; Subject, 16
> >>> Fixed effects:
> >>>                             Estimate     Std. Error   t value
> >>> (Intercept)              2.8765116  0.0177527  162.03
> >>> WordType1            0.0111628  0.0110852    1.01
> >>> WordType2            0.0007306  0.0071519    0.10
> >>> Time1                  -0.0268310  0.0195248   -1.37
> >>> WordType1:Time1  0.0301627  0.0115349    2.61
> >>> WordType2:Time1 -0.0089123  0.0141624   -0.63
> >>>
> >>> Model comparisons with anova() for main effects and interaction:
> >>>
> >>> -full model vs no Word Type x Time interaction
> >>>                                Df     AIC     BIC logLik deviance
> Chisq
> >>> Chi Df Pr(>Chisq)
> >>> rtModelNoInteraction  9 -2077.5 -2031.3 1047.7  -2095.5
> >>>
> >>> rtModelFull               11 -2080.5 -2024.1 1051.2  -2102.5 7.0388
> >>> 2
> >>>    0.02962 *
> >>>
> >>> -full model vs model without Time and interaction
> >>>                        Df     AIC     BIC logLik deviance  Chisq Chi Df
> >>> Pr(>Chisq)
> >>> rtModelNoTime  8 -2077.8 -2036.7 1046.9  -2093.8
> >>> rtModelFull      11 -2080.5 -2024.1 1051.2  -2102.5 8.7424      3
> >>>  0.03292 *
> >>>
> >>> -full model vs model without Word Type and interaction
> >>>                       Df     AIC     BIC logLik deviance  Chisq Chi Df
> >>> Pr(>Chisq)
> >>> rtModelNoWT  7 -2080.4 -2044.5 1047.2  -2094.4
> >>> rtModelFull     11 -2080.5 -2024.1 1051.2  -2102.5 8.0875      4
> >>> 0.08842
> >>> .
> >>>
> >>> Thanks in advance for any advice!
> >>> Becky
> >>> ____________________________________________
> >>>
> >>> Dr Becky Gilbert
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >> --
> >> Paul Debes
> >> DFG Research Fellow
> >> University of Turku
> >> Department of Biology
> >> It?inen Pitk?katu 4
> >> 20520 Turku
> >> Finland
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From petri.lankoski at gmail.com  Fri Aug 21 19:47:08 2015
From: petri.lankoski at gmail.com (Petri Lankoski)
Date: Fri, 21 Aug 2015 19:47:08 +0200
Subject: [R-sig-ME] Mixed cumulative link modelling - error message
In-Reply-To: <4A5D204F-13D6-40E8-8834-5039859BFCE8@sheffield.ac.uk>
References: <4A5D204F-13D6-40E8-8834-5039859BFCE8@sheffield.ac.uk>
Message-ID: <55D7641C.8080708@gmail.com>


Hi,

You need to force rating from int to factor. Try:

bob$rating = factor(bob$rating)



On 21/08/15 18:36, Georgina Southon wrote:
> Hi,
>
> I hope someone can help. I have problems fitting a cumulative link mixed model to my data.
> Looking at the str output, rating shows as an integer, despite the fact that it shows as an ordered factor when asked is.factor. Is this the problem or is there something else I have overlooked?
>
> str(bob)
> 'data.frame':	283 obs. of  4 variables:
>   $ site     : Factor w/ 10 levels "ADD","BH","BR",..: 4 4 4 4 4 4 4 4 4 4 ...
>   $ person   : Factor w/ 283 levels "ADD10","ADD11",..: 80 91 102 104 105 106 107 108 109 81 ...
>   $ treatment: Factor w/ 2 levels "CONTROL","MEADOW": 2 2 2 2 2 2 2 2 2 2 ...
>   $ rating   : int  4 3 4 2 3 4 5 5 5 3 ...
>>
>> m1<-clmm2(rating~treatment,random=person,data=bob)
>
> Error in clm2(location = rating ~ treatment, data = bob, subset = c("1",  :
>    response needs to be a factor
>
> Thanks for any feedback / advice!
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Petri Lankoski ................... Associate Professor
Media Technology ................ S?dert?rn University
email: petri.lankoski at sh.se  .........................
Web: http://www.iki.fi/petri.lankoski/ ...............


From drmccloy at uw.edu  Fri Aug 21 19:51:39 2015
From: drmccloy at uw.edu (Dan McCloy)
Date: Fri, 21 Aug 2015 10:51:39 -0700
Subject: [R-sig-ME] Mixed cumulative link modelling - error message
In-Reply-To: <4A5D204F-13D6-40E8-8834-5039859BFCE8@sheffield.ac.uk>
References: <4A5D204F-13D6-40E8-8834-5039859BFCE8@sheffield.ac.uk>
Message-ID: <CAOE0pYk+=5E5ivDFYAoS03bx1b_vVfv3VAXhUrfoAinrzwh1Hw@mail.gmail.com>

If str() says that bob$rating is of type int, then it is of type int.
Observe:

foo <- data.frame(bar=seq(1,3,1), baz=factor(seq(4,6,1)),
qux=factor(seq(7,9,1), ordered=TRUE))
str(foo)
'data.frame':    3 obs. of  3 variables:
 $ bar: num  1 2 3
 $ baz: Factor w/ 3 levels "4","5","6": 1 2 3
 $ qux: Ord.factor w/ 3 levels "7"<"8"<"9": 1 2 3

you need to do bob$rating <- factor(bob$rating, ordered=TRUE) before
running your model.
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington



On Fri, Aug 21, 2015 at 9:36 AM, Georgina Southon <g.southon at sheffield.ac.uk
> wrote:

> Hi,
>
> I hope someone can help. I have problems fitting a cumulative link mixed
> model to my data.
> Looking at the str output, rating shows as an integer, despite the fact
> that it shows as an ordered factor when asked is.factor. Is this the
> problem or is there something else I have overlooked?
>
> str(bob)
> 'data.frame':   283 obs. of  4 variables:
>  $ site     : Factor w/ 10 levels "ADD","BH","BR",..: 4 4 4 4 4 4 4 4 4 4
> ...
>  $ person   : Factor w/ 283 levels "ADD10","ADD11",..: 80 91 102 104 105
> 106 107 108 109 81 ...
>  $ treatment: Factor w/ 2 levels "CONTROL","MEADOW": 2 2 2 2 2 2 2 2 2 2
> ...
>  $ rating   : int  4 3 4 2 3 4 5 5 5 3 ...
> >
> > m1<-clmm2(rating~treatment,random=person,data=bob)
>
> Error in clm2(location = rating ~ treatment, data = bob, subset = c("1",  :
>   response needs to be a factor
>
> Thanks for any feedback / advice!
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Fri Aug 21 19:59:51 2015
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 21 Aug 2015 17:59:51 +0000
Subject: [R-sig-ME] Parallel version of lmer or glmer?
In-Reply-To: <CAFA8r3H=3CAb7+kGDR4eNqSMPTOXSfkohPjhofPoqfMxp0NF6g@mail.gmail.com>
References: <CAFA8r3H=3CAb7+kGDR4eNqSMPTOXSfkohPjhofPoqfMxp0NF6g@mail.gmail.com>
Message-ID: <CAO7JsnQ+HiWKXCeVAtuPcyjZLw=JGS0B2NRjf48E0tSVcxe4Qw@mail.gmail.com>

On Thu, Aug 20, 2015 at 6:35 PM Mar?a del Carmen Romero <
mariadelc.romero at gmail.com> wrote:

> Hello,
> I want to know if there is a parallel version of lmer or glmer (both of
> package lme4).
>

It depends what you mean by "parallel".  Do you mean "faster"? (If instead
you mean "I want to tie up lots of processors for a long time"  just use
MCMC methods. :-)

If you do mean "faster" you can fit LMM or GLMM models faster but exactly
how to go about it depends very much on the type of problem you have.

- are you fitting LMMs or GLMMs?
- are you using a muilt-core processor or a cluster?
- how many observations, fixed-effects parameters, distinct grouping
factors and covariance parameters?  (If you are fitting a "maximal model"
in the sense of Barr et al. (2012) and it is taking a very long time the
simplest advice is "don't do that".)

Pantelis has mentioned using multi-threaded BLAS such as OpenBLAS or Intel
MKL but without first profiling the execution on your problem it would be
difficult to assess whether this would help.  Most of the numerical linear
algebra in lme4 is performed using Eigen.

For LMMs the simplest approach to making things faster is to change the
optimizer from the default to the version of bobyqa from the nloptr
package. Over the summer Colin Longhurst performed an in-depth comparison
of optimizers on LMM problems.  Preliminary results are at
https://github.com/Stat990-033/Timings/blob/master/inst/doc/Summaries.ipynb

	[[alternative HTML version deleted]]


From ken.beath at mq.edu.au  Sat Aug 22 02:18:36 2015
From: ken.beath at mq.edu.au (Ken Beath)
Date: Sat, 22 Aug 2015 10:18:36 +1000
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert
	contrasts
In-Reply-To: <CAOE0pY=NTCZwOYz9N0tsqpCcR5rrzjjW_bGSA+J3tsjWZqiuuA@mail.gmail.com>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
	<CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
	<CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>
	<CAOE0pY=NTCZwOYz9N0tsqpCcR5rrzjjW_bGSA+J3tsjWZqiuuA@mail.gmail.com>
Message-ID: <CAF5_5cy6WuNAsw+3qjL9+56=ZnAvnWMJ2jgLDik+-iHGdCwhJA@mail.gmail.com>

The first thing to do is to decide if an interaction is really needed.
Applying anova() to the model with interaction should give this. Note that
if there is an interaction it is not possible to conclude anything about
the main effects. The tests that you have performed use Chi-sq statistics
which is not correct for a linear model, it should be F. Playing around
with lme4 I found that wasn't possible except when using a single model.
Testing for removal of combined interaction and main effect is not correct.

If there is an interaction I would suggest using the standard contrasts.
Then you will need to summarise this and there are a few ways in R to do
this. One is svycontrast in the survey package. The result should be a
different effect of time for each word type or vice-versa. This is
something that should be talked over with a statistician.

On 22 August 2015 at 03:39, Dan McCloy <drmccloy at uw.edu> wrote:

> As a word of caution, you seem to have set up your factor coding to make
> interpretation especially tricky. The coding of your "Time1" variable is
> set up so that your factor level of "-1" has a positive coefficient, and
> your factor level of "1" has a negative coefficient.  Before doing anything
> else, I recommend you re-run the model after re-setting the contrasts for
> "Time" so that your textual levels have the same sign as their coefficients
> in the model (personally I would go further and re-code the factor as "Pos"
> and "Neg" or some other textual shorthand that cannot be confused with row
> or column numbers of the contrast matrix).  I also usually set the row
> names of contrast matrices to be actual names, so that the lmer output
> names the coefficients in a way that is harder for me to mis-interpret
> (e.g., as "TimePos" or "TimeNeg" instead of "Time1").  While you're at it,
> if you're interested in "treatment" vs "no treatment" you might consider
> re-setting the contrasts for the WordType factor as well.  You have this:
>
>         [,1] [,2]
> 0  0.6666667  0.0  # untrained
> 1 -0.3333333 -0.5  # trained-related
> 2 -0.3333333  0.5  # trained-unrelated
>
> which means that *positive* coefficient estimates for factor 1 mean that
> "untrained" increases RT.  Similar comment for related vs. unrelated.  I
> would recommend swapping the signs on both factors so that anything that is
> "un-" is negative, like this:
>
>         [,1] [,2]
> 0 -0.6666667  0.0  # untrained
> 1  0.3333333  0.5  # trained-related
> 2  0.3333333 -0.5  # trained-unrelated
>
> As far as interpreting the model coefficients for the interactions:
>
> WordType1:Time1  0.0301627  0.0115349    2.61
> WordType2:Time1 -0.0089123  0.0141624   -0.63
>
> This says that comparing  cases of "WordType1" (which curently means
> "untrained minus trained" in your experiment) combined with "Time1" (which
> I think means Time=1 or what I'm calling "Pos") has a positive coefficient
> (the combination increases log reaction time, or slows people down)
> relative to what you would expect if "WordType" and "Time" contributed
> independently to reaction time.  In other words, I think this means that
> lack of training slows people down more when Time=1 than when Time=-1
> (though the mismatch between signs of the factor levels and contrast
> coefficients for the Time variable make me hesitate as to whether I said
> that last bit backwards).
>
> Hope it helps, and good luck.
> -- dan
>
> Daniel McCloy
> http://dan.mccloy.info/
> Postdoctoral Research Fellow
> Institute for Learning and Brain Sciences
> University of Washington
>
>
> On Fri, Aug 21, 2015 at 6:23 AM, Becky Gilbert <beckyannegilbert at gmail.com
> >
> wrote:
>
> > Hi Paul/List,
> >
> > After thinking about this a bit more, I don't think planned comparisons
> > gives me what I'm looking for.  I want to know whether the effect of Time
> > is different for WordType = 0 (level 1) vs the other two levels combined
> -
> > this is WordType contrast 1.  I also want to know whether the effect of
> > Time is different for WordType = 1 vs WordType = 2 (i.e. level 2 vs level
> > 3) - this is WordType contrast 2.
> >
> > I think the use of planned comparisons here would defeat the purpose of
> my
> > contrasts, but maybe I'm missing something?
> >
> > Thanks!
> > Becky
> >
> > ____________________________________________
> >
> > Dr Becky Gilbert
> >
> > On 21 August 2015 at 13:46, Becky Gilbert <beckyannegilbert at gmail.com>
> > wrote:
> >
> > > Hi Paul,
> > >
> > > Thanks very much for the suggestion!  I tried using lsmeans() to get
> the
> > > pairwise comparisons as you suggested, and the results are below.
> > >
> > > I'm a little confused by the results because the pairwise comparison
> > tests
> > > all show p > .05, but the WordType x Time interaction was significant
> > when
> > > tested via model comparisons...?  I think this might be due to the
> Tukey
> > > adjustment for multiple comparisons, but I'm not sure.  Specifically
> the
> > > contrast for the two levels of Time at WordType = 2 looks like it might
> > > have been significant before the multiple comparisons correction, thus
> > > accounting for the significance of the interaction term in model
> > > comparisons.  Any thoughts?
> > >
> > > Thanks again!
> > > Becky
> > >
> > > $lsmeans
> > > WordType = 0:
> > >  Time   lsmean         SE    df lower.CL upper.CL
> > >  -1       2.880592 0.02209390 21.58 2.834721 2.926464
> > >  1        2.887315 0.02144245 22.13 2.842860 2.931769
> > >
> > > WordType = 1:
> > >  Time   lsmean         SE    df lower.CL upper.CL
> > >  -1       2.856211 0.02156603 19.78 2.811193 2.901229
> > >  1        2.888640 0.02089339 20.17 2.845080 2.932200
> > >
> > > WordType = 2:
> > >  Time   lsmean         SE    df lower.CL upper.CL
> > >  -1       2.852485 0.02181905 20.72 2.807072 2.897898
> > >  1        2.893827 0.02113775 21.12 2.849883 2.937770
> > >
> > > Confidence level used: 0.95
> > >
> > > $contrasts
> > > WordType = 0:
> > >  contrast    estimate         SE    df t.ratio p.value
> > >  -1 - 1   -0.00672255 0.02078469 19.31  -0.323  0.7498
> > >
> > > WordType = 1:
> > >  contrast    estimate         SE    df t.ratio p.value
> > >  -1 - 1   -0.03242907 0.02097452 20.02  -1.546  0.1377
> > >
> > > WordType = 2:
> > >  contrast    estimate         SE    df t.ratio p.value
> > >  -1 - 1   -0.04134141 0.02146707 21.93  -1.926  0.0672
> > >
> > >
> > > ____________________________________________
> > >
> > > Dr Becky Gilbert
> > >
> > > On 21 August 2015 at 12:19, paul debes <paul.debes at utu.fi> wrote:
> > >
> > >> Hi Becky,
> > >>
> > >> Maybe you are interested in pairwise comparisons? The "lsmeans"
> package
> > >> comes in handy.
> > >>
> > >> Try something like this:
> > >>
> > >> library("pbkrtest") # gives you KW-adjusted denDF for tests, but must
> be
> > >> installed
> > >> library("lsmeans")
> > >>
> > >> Model.lmer.means = lsmeans(Model, spec = pairwise ~ WordType|Time)
> > >> Model.lmer.means = summary(Model.lmer.means)
> > >> Model.lmer.means
> > >>
> > >> Maybe you want the contrast conditional on WordType, not Time? Swap it
> > to:
> > >> "spec = pairwise ~ Time|WordType"
> > >>
> > >> Best,
> > >> Paul
> > >>
> > >>
> > >> On Fri, 21 Aug 2015 14:04:07 +0300, Becky Gilbert <
> > >> beckyannegilbert at gmail.com> wrote:
> > >>
> > >> Dear list,
> > >>>
> > >>> I'm wondering if someone could help me interpret an interaction
> between
> > >>> two
> > >>> factors, when one of the factors uses Helmert contrasts?
> > >>>
> > >>> I ran a linear mixed effects model (lmer) with reaction times as the
> > DV,
> > >>> 2
> > >>> fixed factors: Time (2 levels) and Word Type (3 levels), and 2 random
> > >>> factors: Subjects and Items.  I used Helmert contrasts for the Word
> > Type
> > >>> factor:
> > >>> - Contrast 1 = level 1 (Untrained) vs levels 2 & 3 (Trained-related
> and
> > >>> Trained-unrelated)
> > >>> - Contrast 2 = level 2 vs. level 3 (Trained-related vs
> > Trained-unrelated)
> > >>> The data, contrasts, model, summary and model comparisons are listed
> at
> > >>> the
> > >>> end of the message.
> > >>>
> > >>> Model comparisons with anova() showed a significant interaction
> between
> > >>> Time and Word Type.  However, I don't know how to get the statistics
> > for
> > >>> the interactions between Time and each Word Type contrast.
> > >>>
> > >>> Based on the t-values for coefficients in the model summary, it looks
> > >>> like
> > >>> the significant Word Type x Time interaction is driven by the
> > interaction
> > >>> with the 1st contrast for Word Type (t = 2.61).  However I don't
> think
> > >>> that
> > >>> the statistics for the fixed effects coefficients are exactly what
> I'm
> > >>> looking forward (they are sequential tests, right?).  And if these
> are
> > >>> the
> > >>> appropriate statistics, I'm aware of the problems with trying to get
> > >>> p-values from these  estimates.  So is there a way to do likelihood
> > ratio
> > >>> tests for each Word Type contrast, or some other way of interpreting
> > the
> > >>> Word Type x Time interaction?
> > >>>
> > >>> Data structure:
> > >>>
> > >>>> str(rtData)
> > >>>>
> > >>> 'data.frame': 1244 obs. of  11 variables:
> > >>>  $ Subject      : Factor w/ 16 levels "AB","AS","AW",..: 1 1 1 1 1 1
> 1
> > 1
> > >>> 1
> > >>> 1 ...
> > >>>  $ Item       : Factor w/ 48 levels "ANT","BANDAGE",..: 3 4 6 12 13
> 14
> > 22
> > >>> 29 30 34 ...
> > >>>  $ Response     : int  960 1255 651 1043 671 643 743 695 965 589 ...
> > >>>  $ Time     : Factor w/ 2 levels "-1","1": 1 1 1 1 1 1 1 1 1 1 ...
> > >>>  $ WordType     : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1
> > ...
> > >>>  $ logRT        : num  2.98 3.1 2.81 3.02 2.83 ...
> > >>>
> > >>> contrasts(rtData$Time)
> > >>>>
> > >>>    [,1]
> > >>> -1  0.5
> > >>> 1  -0.5
> > >>>
> > >>> contrasts(rtData$WordType)
> > >>>>
> > >>>         [,1] [,2]
> > >>> 0  0.6666667  0.0
> > >>> 1 -0.3333333 -0.5
> > >>> 2 -0.3333333  0.5
> > >>>
> > >>> Model:
> > >>> lmer(logRT ~ 1 + WordType + Time + WordType:Time +
> > >>>                       (1 + Time|Subject) +
> > >>>                       (1|Item),
> > >>>                     data = rtData)
> > >>>
> > >>> REML criterion at convergence: -2061.2
> > >>> Scaled residuals:
> > >>>     Min      1Q  Median      3Q     Max
> > >>> -2.7228 -0.6588 -0.0872  0.5712  3.7790
> > >>> Random effects:
> > >>>  Groups   Name        Variance Std.Dev. Corr
> > >>>  Item   (Intercept)     0.000933  0.03054
> > >>>  Subject  (Intercept)  0.004590  0.06775
> > >>>           Time1            0.005591  0.07478  0.05
> > >>>  Residual                 0.009575  0.09785
> > >>> Number of obs: 1244, groups:  Target, 46; Subject, 16
> > >>> Fixed effects:
> > >>>                             Estimate     Std. Error   t value
> > >>> (Intercept)              2.8765116  0.0177527  162.03
> > >>> WordType1            0.0111628  0.0110852    1.01
> > >>> WordType2            0.0007306  0.0071519    0.10
> > >>> Time1                  -0.0268310  0.0195248   -1.37
> > >>> WordType1:Time1  0.0301627  0.0115349    2.61
> > >>> WordType2:Time1 -0.0089123  0.0141624   -0.63
> > >>>
> > >>> Model comparisons with anova() for main effects and interaction:
> > >>>
> > >>> -full model vs no Word Type x Time interaction
> > >>>                                Df     AIC     BIC logLik deviance
> > Chisq
> > >>> Chi Df Pr(>Chisq)
> > >>> rtModelNoInteraction  9 -2077.5 -2031.3 1047.7  -2095.5
> > >>>
> > >>> rtModelFull               11 -2080.5 -2024.1 1051.2  -2102.5 7.0388
> > >>> 2
> > >>>    0.02962 *
> > >>>
> > >>> -full model vs model without Time and interaction
> > >>>                        Df     AIC     BIC logLik deviance  Chisq Chi
> Df
> > >>> Pr(>Chisq)
> > >>> rtModelNoTime  8 -2077.8 -2036.7 1046.9  -2093.8
> > >>> rtModelFull      11 -2080.5 -2024.1 1051.2  -2102.5 8.7424      3
> > >>>  0.03292 *
> > >>>
> > >>> -full model vs model without Word Type and interaction
> > >>>                       Df     AIC     BIC logLik deviance  Chisq Chi
> Df
> > >>> Pr(>Chisq)
> > >>> rtModelNoWT  7 -2080.4 -2044.5 1047.2  -2094.4
> > >>> rtModelFull     11 -2080.5 -2024.1 1051.2  -2102.5 8.0875      4
> > >>> 0.08842
> > >>> .
> > >>>
> > >>> Thanks in advance for any advice!
> > >>> Becky
> > >>> ____________________________________________
> > >>>
> > >>> Dr Becky Gilbert
> > >>>
> > >>>         [[alternative HTML version deleted]]
> > >>>
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>>
> > >>
> > >>
> > >> --
> > >> Paul Debes
> > >> DFG Research Fellow
> > >> University of Turku
> > >> Department of Biology
> > >> It?inen Pitk?katu 4
> > >> 20520 Turku
> > >> Finland
> > >>
> > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Level 2, AHH
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From smckinney at bccrc.ca  Sat Aug 22 03:53:45 2015
From: smckinney at bccrc.ca (Steven McKinney)
Date: Sat, 22 Aug 2015 01:53:45 +0000
Subject: [R-sig-ME] Interpreting lmer() interactions with
	Helmert	contrasts
In-Reply-To: <CAF5_5cy6WuNAsw+3qjL9+56=ZnAvnWMJ2jgLDik+-iHGdCwhJA@mail.gmail.com>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
	<CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
	<CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>
	<CAOE0pY=NTCZwOYz9N0tsqpCcR5rrzjjW_bGSA+J3tsjWZqiuuA@mail.gmail.com>
	<CAF5_5cy6WuNAsw+3qjL9+56=ZnAvnWMJ2jgLDik+-iHGdCwhJA@mail.gmail.com>
Message-ID: <94ecd3aa45ba4b679338755155ab5458@CRCMAIL6.BCCRC.CA>



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ken Beath
> Sent: August-21-15 5:19 PM
> To: Dan McCloy
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Interpreting lmer() interactions with Helmert
> contrasts
> 
> The first thing to do is to decide if an interaction is really needed.
> Applying anova() to the model with interaction should give this. Note that
> if there is an interaction it is not possible to conclude anything about
> the main effects. 

In the case of a significant interaction, the conclusion is that the change in one of the main effects depends on the level of the other main effect.  Both main effects are statistically significant, but a single value for each main effect will not adequately summarize the degree of response.  One can make conclusions about the main effects, but the conclusions are more complex than a single estimate for each main effect.



> The tests that you have performed use Chi-sq statistics
> which is not correct for a linear model, it should be F. 

For linear mixed effects models, F tests are not possible.  The Chi-square tests presented are likelihood ratio chi-square tests comparing the likelihoods of the full model (under the alternative hypothesis) and the reduced model (under the null hypothesis).  The anova() method for lmer objects automagically refits the two models using maximum likelihood (as opposed to restricted maximum likelihood) and performs the likelihood ratio chi-square test.  The degrees of freedom of that test equal the number of parameters posited to be zero under the reduced (null hypothesis) model as compared to the full (alternative hypothesis) model.


> Playing around
> with lme4 I found that wasn't possible except when using a single model.
> Testing for removal of combined interaction and main effect is not correct.

An omnibus test for the statistical significance of a variable of interest (say variable A), when that variable is in a model involving an interaction with another variable (say variable B) will test the interaction term A:B and the main effect A.  The full model has A + B + A:B and the reduced model has only B.  Thus a proper omnibus test for the usefulness of A in the model will involve the interaction A:B and the main effect A.  This test really should be done before testing A:B for proper multiple comparisons control.



Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre






> 
> If there is an interaction I would suggest using the standard contrasts.
> Then you will need to summarise this and there are a few ways in R to do
> this. One is svycontrast in the survey package. The result should be a
> different effect of time for each word type or vice-versa. This is
> something that should be talked over with a statistician.
> 
> On 22 August 2015 at 03:39, Dan McCloy <drmccloy at uw.edu> wrote:
> 
> > As a word of caution, you seem to have set up your factor coding to make
> > interpretation especially tricky. The coding of your "Time1" variable is
> > set up so that your factor level of "-1" has a positive coefficient, and
> > your factor level of "1" has a negative coefficient.  Before doing
> anything
> > else, I recommend you re-run the model after re-setting the contrasts for
> > "Time" so that your textual levels have the same sign as their
> coefficients
> > in the model (personally I would go further and re-code the factor as
> "Pos"
> > and "Neg" or some other textual shorthand that cannot be confused with
> row
> > or column numbers of the contrast matrix).  I also usually set the row
> > names of contrast matrices to be actual names, so that the lmer output
> > names the coefficients in a way that is harder for me to mis-interpret
> > (e.g., as "TimePos" or "TimeNeg" instead of "Time1").  While you're at
> it,
> > if you're interested in "treatment" vs "no treatment" you might consider
> > re-setting the contrasts for the WordType factor as well.  You have this:
> >
> >         [,1] [,2]
> > 0  0.6666667  0.0  # untrained
> > 1 -0.3333333 -0.5  # trained-related
> > 2 -0.3333333  0.5  # trained-unrelated
> >
> > which means that *positive* coefficient estimates for factor 1 mean that
> > "untrained" increases RT.  Similar comment for related vs. unrelated.  I
> > would recommend swapping the signs on both factors so that anything that
> is
> > "un-" is negative, like this:
> >
> >         [,1] [,2]
> > 0 -0.6666667  0.0  # untrained
> > 1  0.3333333  0.5  # trained-related
> > 2  0.3333333 -0.5  # trained-unrelated
> >
> > As far as interpreting the model coefficients for the interactions:
> >
> > WordType1:Time1  0.0301627  0.0115349    2.61
> > WordType2:Time1 -0.0089123  0.0141624   -0.63
> >
> > This says that comparing  cases of "WordType1" (which curently means
> > "untrained minus trained" in your experiment) combined with "Time1"
> (which
> > I think means Time=1 or what I'm calling "Pos") has a positive
> coefficient
> > (the combination increases log reaction time, or slows people down)
> > relative to what you would expect if "WordType" and "Time" contributed
> > independently to reaction time.  In other words, I think this means that
> > lack of training slows people down more when Time=1 than when Time=-1
> > (though the mismatch between signs of the factor levels and contrast
> > coefficients for the Time variable make me hesitate as to whether I said
> > that last bit backwards).
> >
> > Hope it helps, and good luck.
> > -- dan
> >
> > Daniel McCloy
> > http://dan.mccloy.info/
> > Postdoctoral Research Fellow
> > Institute for Learning and Brain Sciences
> > University of Washington
> >
> >
> > On Fri, Aug 21, 2015 at 6:23 AM, Becky Gilbert
> <beckyannegilbert at gmail.com
> > >
> > wrote:
> >
> > > Hi Paul/List,
> > >
> > > After thinking about this a bit more, I don't think planned comparisons
> > > gives me what I'm looking for.  I want to know whether the effect of
> Time
> > > is different for WordType = 0 (level 1) vs the other two levels
> combined
> > -
> > > this is WordType contrast 1.  I also want to know whether the effect of
> > > Time is different for WordType = 1 vs WordType = 2 (i.e. level 2 vs
> level
> > > 3) - this is WordType contrast 2.
> > >
> > > I think the use of planned comparisons here would defeat the purpose of
> > my
> > > contrasts, but maybe I'm missing something?
> > >
> > > Thanks!
> > > Becky
> > >
> > > ____________________________________________
> > >
> > > Dr Becky Gilbert
> > >
> > > On 21 August 2015 at 13:46, Becky Gilbert <beckyannegilbert at gmail.com>
> > > wrote:
> > >
> > > > Hi Paul,
> > > >
> > > > Thanks very much for the suggestion!  I tried using lsmeans() to get
> > the
> > > > pairwise comparisons as you suggested, and the results are below.
> > > >
> > > > I'm a little confused by the results because the pairwise comparison
> > > tests
> > > > all show p > .05, but the WordType x Time interaction was significant
> > > when
> > > > tested via model comparisons...?  I think this might be due to the
> > Tukey
> > > > adjustment for multiple comparisons, but I'm not sure.  Specifically
> > the
> > > > contrast for the two levels of Time at WordType = 2 looks like it
> might
> > > > have been significant before the multiple comparisons correction,
> thus
> > > > accounting for the significance of the interaction term in model
> > > > comparisons.  Any thoughts?
> > > >
> > > > Thanks again!
> > > > Becky
> > > >
> > > > $lsmeans
> > > > WordType = 0:
> > > >  Time   lsmean         SE    df lower.CL upper.CL
> > > >  -1       2.880592 0.02209390 21.58 2.834721 2.926464
> > > >  1        2.887315 0.02144245 22.13 2.842860 2.931769
> > > >
> > > > WordType = 1:
> > > >  Time   lsmean         SE    df lower.CL upper.CL
> > > >  -1       2.856211 0.02156603 19.78 2.811193 2.901229
> > > >  1        2.888640 0.02089339 20.17 2.845080 2.932200
> > > >
> > > > WordType = 2:
> > > >  Time   lsmean         SE    df lower.CL upper.CL
> > > >  -1       2.852485 0.02181905 20.72 2.807072 2.897898
> > > >  1        2.893827 0.02113775 21.12 2.849883 2.937770
> > > >
> > > > Confidence level used: 0.95
> > > >
> > > > $contrasts
> > > > WordType = 0:
> > > >  contrast    estimate         SE    df t.ratio p.value
> > > >  -1 - 1   -0.00672255 0.02078469 19.31  -0.323  0.7498
> > > >
> > > > WordType = 1:
> > > >  contrast    estimate         SE    df t.ratio p.value
> > > >  -1 - 1   -0.03242907 0.02097452 20.02  -1.546  0.1377
> > > >
> > > > WordType = 2:
> > > >  contrast    estimate         SE    df t.ratio p.value
> > > >  -1 - 1   -0.04134141 0.02146707 21.93  -1.926  0.0672
> > > >
> > > >
> > > > ____________________________________________
> > > >
> > > > Dr Becky Gilbert
> > > >
> > > > On 21 August 2015 at 12:19, paul debes <paul.debes at utu.fi> wrote:
> > > >
> > > >> Hi Becky,
> > > >>
> > > >> Maybe you are interested in pairwise comparisons? The "lsmeans"
> > package
> > > >> comes in handy.
> > > >>
> > > >> Try something like this:
> > > >>
> > > >> library("pbkrtest") # gives you KW-adjusted denDF for tests, but
> must
> > be
> > > >> installed
> > > >> library("lsmeans")
> > > >>
> > > >> Model.lmer.means = lsmeans(Model, spec = pairwise ~ WordType|Time)
> > > >> Model.lmer.means = summary(Model.lmer.means)
> > > >> Model.lmer.means
> > > >>
> > > >> Maybe you want the contrast conditional on WordType, not Time? Swap
> it
> > > to:
> > > >> "spec = pairwise ~ Time|WordType"
> > > >>
> > > >> Best,
> > > >> Paul
> > > >>
> > > >>
> > > >> On Fri, 21 Aug 2015 14:04:07 +0300, Becky Gilbert <
> > > >> beckyannegilbert at gmail.com> wrote:
> > > >>
> > > >> Dear list,
> > > >>>
> > > >>> I'm wondering if someone could help me interpret an interaction
> > between
> > > >>> two
> > > >>> factors, when one of the factors uses Helmert contrasts?
> > > >>>
> > > >>> I ran a linear mixed effects model (lmer) with reaction times as
> the
> > > DV,
> > > >>> 2
> > > >>> fixed factors: Time (2 levels) and Word Type (3 levels), and 2
> random
> > > >>> factors: Subjects and Items.  I used Helmert contrasts for the Word
> > > Type
> > > >>> factor:
> > > >>> - Contrast 1 = level 1 (Untrained) vs levels 2 & 3 (Trained-related
> > and
> > > >>> Trained-unrelated)
> > > >>> - Contrast 2 = level 2 vs. level 3 (Trained-related vs
> > > Trained-unrelated)
> > > >>> The data, contrasts, model, summary and model comparisons are
> listed
> > at
> > > >>> the
> > > >>> end of the message.
> > > >>>
> > > >>> Model comparisons with anova() showed a significant interaction
> > between
> > > >>> Time and Word Type.  However, I don't know how to get the
> statistics
> > > for
> > > >>> the interactions between Time and each Word Type contrast.
> > > >>>
> > > >>> Based on the t-values for coefficients in the model summary, it
> looks
> > > >>> like
> > > >>> the significant Word Type x Time interaction is driven by the
> > > interaction
> > > >>> with the 1st contrast for Word Type (t = 2.61).  However I don't
> > think
> > > >>> that
> > > >>> the statistics for the fixed effects coefficients are exactly what
> > I'm
> > > >>> looking forward (they are sequential tests, right?).  And if these
> > are
> > > >>> the
> > > >>> appropriate statistics, I'm aware of the problems with trying to
> get
> > > >>> p-values from these  estimates.  So is there a way to do likelihood
> > > ratio
> > > >>> tests for each Word Type contrast, or some other way of
> interpreting
> > > the
> > > >>> Word Type x Time interaction?
> > > >>>
> > > >>> Data structure:
> > > >>>
> > > >>>> str(rtData)
> > > >>>>
> > > >>> 'data.frame': 1244 obs. of  11 variables:
> > > >>>  $ Subject      : Factor w/ 16 levels "AB","AS","AW",..: 1 1 1 1 1
> 1
> > 1
> > > 1
> > > >>> 1
> > > >>> 1 ...
> > > >>>  $ Item       : Factor w/ 48 levels "ANT","BANDAGE",..: 3 4 6 12 13
> > 14
> > > 22
> > > >>> 29 30 34 ...
> > > >>>  $ Response     : int  960 1255 651 1043 671 643 743 695 965 589
> ...
> > > >>>  $ Time     : Factor w/ 2 levels "-1","1": 1 1 1 1 1 1 1 1 1 1 ...
> > > >>>  $ WordType     : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1
> 1
> > > ...
> > > >>>  $ logRT        : num  2.98 3.1 2.81 3.02 2.83 ...
> > > >>>
> > > >>> contrasts(rtData$Time)
> > > >>>>
> > > >>>    [,1]
> > > >>> -1  0.5
> > > >>> 1  -0.5
> > > >>>
> > > >>> contrasts(rtData$WordType)
> > > >>>>
> > > >>>         [,1] [,2]
> > > >>> 0  0.6666667  0.0
> > > >>> 1 -0.3333333 -0.5
> > > >>> 2 -0.3333333  0.5
> > > >>>
> > > >>> Model:
> > > >>> lmer(logRT ~ 1 + WordType + Time + WordType:Time +
> > > >>>                       (1 + Time|Subject) +
> > > >>>                       (1|Item),
> > > >>>                     data = rtData)
> > > >>>
> > > >>> REML criterion at convergence: -2061.2
> > > >>> Scaled residuals:
> > > >>>     Min      1Q  Median      3Q     Max
> > > >>> -2.7228 -0.6588 -0.0872  0.5712  3.7790
> > > >>> Random effects:
> > > >>>  Groups   Name        Variance Std.Dev. Corr
> > > >>>  Item   (Intercept)     0.000933  0.03054
> > > >>>  Subject  (Intercept)  0.004590  0.06775
> > > >>>           Time1            0.005591  0.07478  0.05
> > > >>>  Residual                 0.009575  0.09785
> > > >>> Number of obs: 1244, groups:  Target, 46; Subject, 16
> > > >>> Fixed effects:
> > > >>>                             Estimate     Std. Error   t value
> > > >>> (Intercept)              2.8765116  0.0177527  162.03
> > > >>> WordType1            0.0111628  0.0110852    1.01
> > > >>> WordType2            0.0007306  0.0071519    0.10
> > > >>> Time1                  -0.0268310  0.0195248   -1.37
> > > >>> WordType1:Time1  0.0301627  0.0115349    2.61
> > > >>> WordType2:Time1 -0.0089123  0.0141624   -0.63
> > > >>>
> > > >>> Model comparisons with anova() for main effects and interaction:
> > > >>>
> > > >>> -full model vs no Word Type x Time interaction
> > > >>>                                Df     AIC     BIC logLik deviance
> > > Chisq
> > > >>> Chi Df Pr(>Chisq)
> > > >>> rtModelNoInteraction  9 -2077.5 -2031.3 1047.7  -2095.5
> > > >>>
> > > >>> rtModelFull               11 -2080.5 -2024.1 1051.2  -2102.5 7.0388
> > > >>> 2
> > > >>>    0.02962 *
> > > >>>
> > > >>> -full model vs model without Time and interaction
> > > >>>                        Df     AIC     BIC logLik deviance  Chisq
> Chi
> > Df
> > > >>> Pr(>Chisq)
> > > >>> rtModelNoTime  8 -2077.8 -2036.7 1046.9  -2093.8
> > > >>> rtModelFull      11 -2080.5 -2024.1 1051.2  -2102.5 8.7424      3
> > > >>>  0.03292 *
> > > >>>
> > > >>> -full model vs model without Word Type and interaction
> > > >>>                       Df     AIC     BIC logLik deviance  Chisq Chi
> > Df
> > > >>> Pr(>Chisq)
> > > >>> rtModelNoWT  7 -2080.4 -2044.5 1047.2  -2094.4
> > > >>> rtModelFull     11 -2080.5 -2024.1 1051.2  -2102.5 8.0875      4
> > > >>> 0.08842
> > > >>> .
> > > >>>
> > > >>> Thanks in advance for any advice!
> > > >>> Becky
> > > >>> ____________________________________________
> > > >>>
> > > >>> Dr Becky Gilbert
> > > >>>
> > > >>>         [[alternative HTML version deleted]]
> > > >>>
> > > >>> _______________________________________________
> > > >>> R-sig-mixed-models at r-project.org mailing list
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >>>
> > > >>
> > > >>
> > > >> --
> > > >> Paul Debes
> > > >> DFG Research Fellow
> > > >> University of Turku
> > > >> Department of Biology
> > > >> It?inen Pitk?katu 4
> > > >> 20520 Turku
> > > >> Finland
> > > >>
> > > >
> > > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> --
> 
> *Ken Beath*
> Lecturer
> Statistics Department
> MACQUARIE UNIVERSITY NSW 2109, Australia
> 
> Phone: +61 (0)2 9850 8516
> 
> Level 2, AHH
> http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
> 
> CRICOS Provider No 00002J
> This message is intended for the addressee named and may...{{dropped:9}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From g.southon at sheffield.ac.uk  Sat Aug 22 10:02:25 2015
From: g.southon at sheffield.ac.uk (Georgina Southon)
Date: Sat, 22 Aug 2015 09:02:25 +0100
Subject: [R-sig-ME] Mixed cumulative link modelling - error message
In-Reply-To: <CAOE0pYk+=5E5ivDFYAoS03bx1b_vVfv3VAXhUrfoAinrzwh1Hw@mail.gmail.com>
References: <4A5D204F-13D6-40E8-8834-5039859BFCE8@sheffield.ac.uk>
	<CAOE0pYk+=5E5ivDFYAoS03bx1b_vVfv3VAXhUrfoAinrzwh1Hw@mail.gmail.com>
Message-ID: <E03E220A-0324-4DF6-A447-93869570CD66@sheffield.ac.uk>


Hi Dan,
Thanks - that worked a treat!
Georgina




On 21 Aug 2015, at 18:51, Dan McCloy <drmccloy at uw.edu> wrote:

If str() says that bob$rating is of type int, then it is of type int.  Observe:

foo <- data.frame(bar=seq(1,3,1), baz=factor(seq(4,6,1)), qux=factor(seq(7,9,1), ordered=TRUE))
str(foo)
'data.frame':    3 obs. of  3 variables:
 $ bar: num  1 2 3
 $ baz: Factor w/ 3 levels "4","5","6": 1 2 3
 $ qux: Ord.factor w/ 3 levels "7"<"8"<"9": 1 2 3

you need to do bob$rating <- factor(bob$rating, ordered=TRUE) before running your model.
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington



On Fri, Aug 21, 2015 at 9:36 AM, Georgina Southon <g.southon at sheffield.ac.uk> wrote:
Hi,

I hope someone can help. I have problems fitting a cumulative link mixed model to my data.
Looking at the str output, rating shows as an integer, despite the fact that it shows as an ordered factor when asked is.factor. Is this the problem or is there something else I have overlooked?

str(bob)
'data.frame':   283 obs. of  4 variables:
 $ site     : Factor w/ 10 levels "ADD","BH","BR",..: 4 4 4 4 4 4 4 4 4 4 ...
 $ person   : Factor w/ 283 levels "ADD10","ADD11",..: 80 91 102 104 105 106 107 108 109 81 ...
 $ treatment: Factor w/ 2 levels "CONTROL","MEADOW": 2 2 2 2 2 2 2 2 2 2 ...
 $ rating   : int  4 3 4 2 3 4 5 5 5 3 ...
>
> m1<-clmm2(rating~treatment,random=person,data=bob)

Error in clm2(location = rating ~ treatment, data = bob, subset = c("1",  :
  response needs to be a factor

Thanks for any feedback / advice!



        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From beckyannegilbert at gmail.com  Mon Aug 24 13:54:01 2015
From: beckyannegilbert at gmail.com (Becky Gilbert)
Date: Mon, 24 Aug 2015 12:54:01 +0100
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert
	contrasts
In-Reply-To: <94ecd3aa45ba4b679338755155ab5458@CRCMAIL6.BCCRC.CA>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
	<CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
	<CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>
	<CAOE0pY=NTCZwOYz9N0tsqpCcR5rrzjjW_bGSA+J3tsjWZqiuuA@mail.gmail.com>
	<CAF5_5cy6WuNAsw+3qjL9+56=ZnAvnWMJ2jgLDik+-iHGdCwhJA@mail.gmail.com>
	<94ecd3aa45ba4b679338755155ab5458@CRCMAIL6.BCCRC.CA>
Message-ID: <CALWifgBmuehuB1u7vP5OeFV=mrCHbfXHw0CW5K=zQSeZdKBnXg@mail.gmail.com>

Thanks very much everyone for the responses.

@Dan: Thank you for the recommendation about my factor contrast
coefficients.  I hadn't given much thought to the sign/level association,
but now that you point it out, it seems obvious that I should do it the way
you describe.  Here are the model coefficients with recoded contrasts:

> contrasts(rtData$Time)
    [,1]
-1 -0.5  # pre-test
1   0.5  # post-test

> contrasts(rtData$WordType)
        [,1]        [,2]
0 -0.6666667  0.0  # untrained
1  0.3333333  0.5  # trained-related
2  0.3333333 -0.5  # trained-unrelated

                              Estimate     Std. Error    t value
(Intercept)               2.8765116  0.0177527  162.03
WordType1            -0.0111628  0.0110852   -1.01
WordType2            -0.0007306  0.0071519   -0.10
Time1                    0.0268310  0.0195248    1.37
WordType1:Time1   0.0301627  0.0115349    2.61
WordType2:Time1  -0.0089123  0.0141624   -0.63

My interpretations of the interaction coefficients are:
1) log RT increases (i.e. RTs slow down) for the two trained (vs untrained)
Word Types at post-test (Time = 1)
2) log RT decreases (i.e. RTs speed up) for the trained-related (vs
trained-unrelated) Word Type at post-test (Time = 1)..

However, this doesn't really answer my original question about how to
assess (and report) the contribution of these two interactions to the model
fit.  Obviously the t statistic is larger for the Time1:WordType1 compared
to the Time1:WordType2 interaction coefficients, but that only tells me
their relative contributions - I would need to know degrees of freedom to
get p-values, which I understand is not straightforward.  Also, I've read
that the t statistics for coefficients that are output by summary() for an
lmer model are sequential tests and thus not the appropriate/desired
statistics for assessing the contribution of factors (someone please
correct me if I'm wrong!).  Hence the reason for using LRT to assess this.
This still leaves me with the problem of not being able to test the
interactions between Time and the two contrasts for WordType - I can test
the whole WordType factor and Time:WordType interaction via LRTs, but not
each contrast within WordType.

@Steven: thanks for your explanation re interpreting main effects in the
presence of an interaction, and of the Chi-square LRTs for assessing the
contribution of factors/terms.

However I'm confused by this:

An omnibus test for the statistical significance of a variable of interest
> (say variable A), when that variable is in a model involving an interaction
> with another variable (say variable B) will test the interaction term A:B
> and the main effect A.  The full model has A + B + A:B and the reduced
> model has only B.  Thus a proper omnibus test for the usefulness of A in
> the model will involve the interaction A:B and the main effect A.  This
> test really should be done before testing A:B for proper multiple
> comparisons control.


Is this what you're saying?

1. test A: (A + B + A:B) vs (B)
2. test B: (A + B + A:B) vs (A)
then, if either of the above are significant:
3. test A:B: (A + B + A:B) vs (A + B)

Which I think is the procedure described here:
https://mailman.ucsd.edu/pipermail/ling-r-lang-l/2011-October/000305.html
Assuming this is what you meant, will this procedure always get you to step
3 (assessing the interaction) in the case of a significant interaction
without main effects (as in a cross-over interaction).  Sorry if I've
completely misunderstood!

Becky


____________________________________________

Dr Becky Gilbert (nee Prince)

http://www.york.ac.uk/psychology/staff/postgrads/becky.gilbert/
http://www.researchgate.net/profile/Becky_Gilbert2
http://twitter.com/BeckyAGilbert

On 22 August 2015 at 02:53, Steven McKinney <smckinney at bccrc.ca> wrote:

>
>
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:
> r-sig-mixed-models-bounces at r-project.org]
> > On Behalf Of Ken Beath
> > Sent: August-21-15 5:19 PM
> > To: Dan McCloy
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Interpreting lmer() interactions with Helmert
> > contrasts
> >
> > The first thing to do is to decide if an interaction is really needed.
> > Applying anova() to the model with interaction should give this. Note
> that
> > if there is an interaction it is not possible to conclude anything about
> > the main effects.
>
> In the case of a significant interaction, the conclusion is that the
> change in one of the main effects depends on the level of the other main
> effect.  Both main effects are statistically significant, but a single
> value for each main effect will not adequately summarize the degree of
> response.  One can make conclusions about the main effects, but the
> conclusions are more complex than a single estimate for each main effect.
>
>
>
> > The tests that you have performed use Chi-sq statistics
> > which is not correct for a linear model, it should be F.
>
> For linear mixed effects models, F tests are not possible.  The Chi-square
> tests presented are likelihood ratio chi-square tests comparing the
> likelihoods of the full model (under the alternative hypothesis) and the
> reduced model (under the null hypothesis).  The anova() method for lmer
> objects automagically refits the two models using maximum likelihood (as
> opposed to restricted maximum likelihood) and performs the likelihood ratio
> chi-square test.  The degrees of freedom of that test equal the number of
> parameters posited to be zero under the reduced (null hypothesis) model as
> compared to the full (alternative hypothesis) model.
>
>
> > Playing around
> > with lme4 I found that wasn't possible except when using a single model.
> > Testing for removal of combined interaction and main effect is not
> correct.
>
> An omnibus test for the statistical significance of a variable of interest
> (say variable A), when that variable is in a model involving an interaction
> with another variable (say variable B) will test the interaction term A:B
> and the main effect A.  The full model has A + B + A:B and the reduced
> model has only B.  Thus a proper omnibus test for the usefulness of A in
> the model will involve the interaction A:B and the main effect A.  This
> test really should be done before testing A:B for proper multiple
> comparisons control.
>
>
>
> Steven McKinney, Ph.D.
>
> Statistician
> Molecular Oncology and Breast Cancer Program
> British Columbia Cancer Research Centre
>
>
>
>
>
>
> >
> > If there is an interaction I would suggest using the standard contrasts.
> > Then you will need to summarise this and there are a few ways in R to do
> > this. One is svycontrast in the survey package. The result should be a
> > different effect of time for each word type or vice-versa. This is
> > something that should be talked over with a statistician.
> >
> > On 22 August 2015 at 03:39, Dan McCloy <drmccloy at uw.edu> wrote:
> >
> > > As a word of caution, you seem to have set up your factor coding to
> make
> > > interpretation especially tricky. The coding of your "Time1" variable
> is
> > > set up so that your factor level of "-1" has a positive coefficient,
> and
> > > your factor level of "1" has a negative coefficient.  Before doing
> > anything
> > > else, I recommend you re-run the model after re-setting the contrasts
> for
> > > "Time" so that your textual levels have the same sign as their
> > coefficients
> > > in the model (personally I would go further and re-code the factor as
> > "Pos"
> > > and "Neg" or some other textual shorthand that cannot be confused with
> > row
> > > or column numbers of the contrast matrix).  I also usually set the row
> > > names of contrast matrices to be actual names, so that the lmer output
> > > names the coefficients in a way that is harder for me to mis-interpret
> > > (e.g., as "TimePos" or "TimeNeg" instead of "Time1").  While you're at
> > it,
> > > if you're interested in "treatment" vs "no treatment" you might
> consider
> > > re-setting the contrasts for the WordType factor as well.  You have
> this:
> > >
> > >         [,1] [,2]
> > > 0  0.6666667  0.0  # untrained
> > > 1 -0.3333333 -0.5  # trained-related
> > > 2 -0.3333333  0.5  # trained-unrelated
> > >
> > > which means that *positive* coefficient estimates for factor 1 mean
> that
> > > "untrained" increases RT.  Similar comment for related vs. unrelated.
> I
> > > would recommend swapping the signs on both factors so that anything
> that
> > is
> > > "un-" is negative, like this:
> > >
> > >         [,1] [,2]
> > > 0 -0.6666667  0.0  # untrained
> > > 1  0.3333333  0.5  # trained-related
> > > 2  0.3333333 -0.5  # trained-unrelated
> > >
> > > As far as interpreting the model coefficients for the interactions:
> > >
> > > WordType1:Time1  0.0301627  0.0115349    2.61
> > > WordType2:Time1 -0.0089123  0.0141624   -0.63
> > >
> > > This says that comparing  cases of "WordType1" (which curently means
> > > "untrained minus trained" in your experiment) combined with "Time1"
> > (which
> > > I think means Time=1 or what I'm calling "Pos") has a positive
> > coefficient
> > > (the combination increases log reaction time, or slows people down)
> > > relative to what you would expect if "WordType" and "Time" contributed
> > > independently to reaction time.  In other words, I think this means
> that
> > > lack of training slows people down more when Time=1 than when Time=-1
> > > (though the mismatch between signs of the factor levels and contrast
> > > coefficients for the Time variable make me hesitate as to whether I
> said
> > > that last bit backwards).
> > >
> > > Hope it helps, and good luck.
> > > -- dan
> > >
> > > Daniel McCloy
> > > http://dan.mccloy.info/
> > > Postdoctoral Research Fellow
> > > Institute for Learning and Brain Sciences
> > > University of Washington
> > >
> > >
> > > On Fri, Aug 21, 2015 at 6:23 AM, Becky Gilbert
> > <beckyannegilbert at gmail.com
> > > >
> > > wrote:
> > >
> > > > Hi Paul/List,
> > > >
> > > > After thinking about this a bit more, I don't think planned
> comparisons
> > > > gives me what I'm looking for.  I want to know whether the effect of
> > Time
> > > > is different for WordType = 0 (level 1) vs the other two levels
> > combined
> > > -
> > > > this is WordType contrast 1.  I also want to know whether the effect
> of
> > > > Time is different for WordType = 1 vs WordType = 2 (i.e. level 2 vs
> > level
> > > > 3) - this is WordType contrast 2.
> > > >
> > > > I think the use of planned comparisons here would defeat the purpose
> of
> > > my
> > > > contrasts, but maybe I'm missing something?
> > > >
> > > > Thanks!
> > > > Becky
> > > >
> > > > ____________________________________________
> > > >
> > > > Dr Becky Gilbert
> > > >
> > > > On 21 August 2015 at 13:46, Becky Gilbert <
> beckyannegilbert at gmail.com>
> > > > wrote:
> > > >
> > > > > Hi Paul,
> > > > >
> > > > > Thanks very much for the suggestion!  I tried using lsmeans() to
> get
> > > the
> > > > > pairwise comparisons as you suggested, and the results are below.
> > > > >
> > > > > I'm a little confused by the results because the pairwise
> comparison
> > > > tests
> > > > > all show p > .05, but the WordType x Time interaction was
> significant
> > > > when
> > > > > tested via model comparisons...?  I think this might be due to the
> > > Tukey
> > > > > adjustment for multiple comparisons, but I'm not sure.
> Specifically
> > > the
> > > > > contrast for the two levels of Time at WordType = 2 looks like it
> > might
> > > > > have been significant before the multiple comparisons correction,
> > thus
> > > > > accounting for the significance of the interaction term in model
> > > > > comparisons.  Any thoughts?
> > > > >
> > > > > Thanks again!
> > > > > Becky
> > > > >
> > > > > $lsmeans
> > > > > WordType = 0:
> > > > >  Time   lsmean         SE    df lower.CL upper.CL
> > > > >  -1       2.880592 0.02209390 21.58 2.834721 2.926464
> > > > >  1        2.887315 0.02144245 22.13 2.842860 2.931769
> > > > >
> > > > > WordType = 1:
> > > > >  Time   lsmean         SE    df lower.CL upper.CL
> > > > >  -1       2.856211 0.02156603 19.78 2.811193 2.901229
> > > > >  1        2.888640 0.02089339 20.17 2.845080 2.932200
> > > > >
> > > > > WordType = 2:
> > > > >  Time   lsmean         SE    df lower.CL upper.CL
> > > > >  -1       2.852485 0.02181905 20.72 2.807072 2.897898
> > > > >  1        2.893827 0.02113775 21.12 2.849883 2.937770
> > > > >
> > > > > Confidence level used: 0.95
> > > > >
> > > > > $contrasts
> > > > > WordType = 0:
> > > > >  contrast    estimate         SE    df t.ratio p.value
> > > > >  -1 - 1   -0.00672255 0.02078469 19.31  -0.323  0.7498
> > > > >
> > > > > WordType = 1:
> > > > >  contrast    estimate         SE    df t.ratio p.value
> > > > >  -1 - 1   -0.03242907 0.02097452 20.02  -1.546  0.1377
> > > > >
> > > > > WordType = 2:
> > > > >  contrast    estimate         SE    df t.ratio p.value
> > > > >  -1 - 1   -0.04134141 0.02146707 21.93  -1.926  0.0672
> > > > >
> > > > >
> > > > > ____________________________________________
> > > > >
> > > > > Dr Becky Gilbert
> > > > >
> > > > > On 21 August 2015 at 12:19, paul debes <paul.debes at utu.fi> wrote:
> > > > >
> > > > >> Hi Becky,
> > > > >>
> > > > >> Maybe you are interested in pairwise comparisons? The "lsmeans"
> > > package
> > > > >> comes in handy.
> > > > >>
> > > > >> Try something like this:
> > > > >>
> > > > >> library("pbkrtest") # gives you KW-adjusted denDF for tests, but
> > must
> > > be
> > > > >> installed
> > > > >> library("lsmeans")
> > > > >>
> > > > >> Model.lmer.means = lsmeans(Model, spec = pairwise ~ WordType|Time)
> > > > >> Model.lmer.means = summary(Model.lmer.means)
> > > > >> Model.lmer.means
> > > > >>
> > > > >> Maybe you want the contrast conditional on WordType, not Time?
> Swap
> > it
> > > > to:
> > > > >> "spec = pairwise ~ Time|WordType"
> > > > >>
> > > > >> Best,
> > > > >> Paul
> > > > >>
> > > > >>
> > > > >> On Fri, 21 Aug 2015 14:04:07 +0300, Becky Gilbert <
> > > > >> beckyannegilbert at gmail.com> wrote:
> > > > >>
> > > > >> Dear list,
> > > > >>>
> > > > >>> I'm wondering if someone could help me interpret an interaction
> > > between
> > > > >>> two
> > > > >>> factors, when one of the factors uses Helmert contrasts?
> > > > >>>
> > > > >>> I ran a linear mixed effects model (lmer) with reaction times as
> > the
> > > > DV,
> > > > >>> 2
> > > > >>> fixed factors: Time (2 levels) and Word Type (3 levels), and 2
> > random
> > > > >>> factors: Subjects and Items.  I used Helmert contrasts for the
> Word
> > > > Type
> > > > >>> factor:
> > > > >>> - Contrast 1 = level 1 (Untrained) vs levels 2 & 3
> (Trained-related
> > > and
> > > > >>> Trained-unrelated)
> > > > >>> - Contrast 2 = level 2 vs. level 3 (Trained-related vs
> > > > Trained-unrelated)
> > > > >>> The data, contrasts, model, summary and model comparisons are
> > listed
> > > at
> > > > >>> the
> > > > >>> end of the message.
> > > > >>>
> > > > >>> Model comparisons with anova() showed a significant interaction
> > > between
> > > > >>> Time and Word Type.  However, I don't know how to get the
> > statistics
> > > > for
> > > > >>> the interactions between Time and each Word Type contrast.
> > > > >>>
> > > > >>> Based on the t-values for coefficients in the model summary, it
> > looks
> > > > >>> like
> > > > >>> the significant Word Type x Time interaction is driven by the
> > > > interaction
> > > > >>> with the 1st contrast for Word Type (t = 2.61).  However I don't
> > > think
> > > > >>> that
> > > > >>> the statistics for the fixed effects coefficients are exactly
> what
> > > I'm
> > > > >>> looking forward (they are sequential tests, right?).  And if
> these
> > > are
> > > > >>> the
> > > > >>> appropriate statistics, I'm aware of the problems with trying to
> > get
> > > > >>> p-values from these  estimates.  So is there a way to do
> likelihood
> > > > ratio
> > > > >>> tests for each Word Type contrast, or some other way of
> > interpreting
> > > > the
> > > > >>> Word Type x Time interaction?
> > > > >>>
> > > > >>> Data structure:
> > > > >>>
> > > > >>>> str(rtData)
> > > > >>>>
> > > > >>> 'data.frame': 1244 obs. of  11 variables:
> > > > >>>  $ Subject      : Factor w/ 16 levels "AB","AS","AW",..: 1 1 1 1
> 1
> > 1
> > > 1
> > > > 1
> > > > >>> 1
> > > > >>> 1 ...
> > > > >>>  $ Item       : Factor w/ 48 levels "ANT","BANDAGE",..: 3 4 6 12
> 13
> > > 14
> > > > 22
> > > > >>> 29 30 34 ...
> > > > >>>  $ Response     : int  960 1255 651 1043 671 643 743 695 965 589
> > ...
> > > > >>>  $ Time     : Factor w/ 2 levels "-1","1": 1 1 1 1 1 1 1 1 1 1
> ...
> > > > >>>  $ WordType     : Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1
> 1 1
> > 1
> > > > ...
> > > > >>>  $ logRT        : num  2.98 3.1 2.81 3.02 2.83 ...
> > > > >>>
> > > > >>> contrasts(rtData$Time)
> > > > >>>>
> > > > >>>    [,1]
> > > > >>> -1  0.5
> > > > >>> 1  -0.5
> > > > >>>
> > > > >>> contrasts(rtData$WordType)
> > > > >>>>
> > > > >>>         [,1] [,2]
> > > > >>> 0  0.6666667  0.0
> > > > >>> 1 -0.3333333 -0.5
> > > > >>> 2 -0.3333333  0.5
> > > > >>>
> > > > >>> Model:
> > > > >>> lmer(logRT ~ 1 + WordType + Time + WordType:Time +
> > > > >>>                       (1 + Time|Subject) +
> > > > >>>                       (1|Item),
> > > > >>>                     data = rtData)
> > > > >>>
> > > > >>> REML criterion at convergence: -2061.2
> > > > >>> Scaled residuals:
> > > > >>>     Min      1Q  Median      3Q     Max
> > > > >>> -2.7228 -0.6588 -0.0872  0.5712  3.7790
> > > > >>> Random effects:
> > > > >>>  Groups   Name        Variance Std.Dev. Corr
> > > > >>>  Item   (Intercept)     0.000933  0.03054
> > > > >>>  Subject  (Intercept)  0.004590  0.06775
> > > > >>>           Time1            0.005591  0.07478  0.05
> > > > >>>  Residual                 0.009575  0.09785
> > > > >>> Number of obs: 1244, groups:  Target, 46; Subject, 16
> > > > >>> Fixed effects:
> > > > >>>                             Estimate     Std. Error   t value
> > > > >>> (Intercept)              2.8765116  0.0177527  162.03
> > > > >>> WordType1            0.0111628  0.0110852    1.01
> > > > >>> WordType2            0.0007306  0.0071519    0.10
> > > > >>> Time1                  -0.0268310  0.0195248   -1.37
> > > > >>> WordType1:Time1  0.0301627  0.0115349    2.61
> > > > >>> WordType2:Time1 -0.0089123  0.0141624   -0.63
> > > > >>>
> > > > >>> Model comparisons with anova() for main effects and interaction:
> > > > >>>
> > > > >>> -full model vs no Word Type x Time interaction
> > > > >>>                                Df     AIC     BIC logLik deviance
> > > > Chisq
> > > > >>> Chi Df Pr(>Chisq)
> > > > >>> rtModelNoInteraction  9 -2077.5 -2031.3 1047.7  -2095.5
> > > > >>>
> > > > >>> rtModelFull               11 -2080.5 -2024.1 1051.2  -2102.5
> 7.0388
> > > > >>> 2
> > > > >>>    0.02962 *
> > > > >>>
> > > > >>> -full model vs model without Time and interaction
> > > > >>>                        Df     AIC     BIC logLik deviance  Chisq
> > Chi
> > > Df
> > > > >>> Pr(>Chisq)
> > > > >>> rtModelNoTime  8 -2077.8 -2036.7 1046.9  -2093.8
> > > > >>> rtModelFull      11 -2080.5 -2024.1 1051.2  -2102.5 8.7424      3
> > > > >>>  0.03292 *
> > > > >>>
> > > > >>> -full model vs model without Word Type and interaction
> > > > >>>                       Df     AIC     BIC logLik deviance  Chisq
> Chi
> > > Df
> > > > >>> Pr(>Chisq)
> > > > >>> rtModelNoWT  7 -2080.4 -2044.5 1047.2  -2094.4
> > > > >>> rtModelFull     11 -2080.5 -2024.1 1051.2  -2102.5 8.0875      4
> > > > >>> 0.08842
> > > > >>> .
> > > > >>>
> > > > >>> Thanks in advance for any advice!
> > > > >>> Becky
> > > > >>> ____________________________________________
> > > > >>>
> > > > >>> Dr Becky Gilbert
> > > > >>>
> > > > >>>         [[alternative HTML version deleted]]
> > > > >>>
> > > > >>> _______________________________________________
> > > > >>> R-sig-mixed-models at r-project.org mailing list
> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > > >>>
> > > > >>
> > > > >>
> > > > >> --
> > > > >> Paul Debes
> > > > >> DFG Research Fellow
> > > > >> University of Turku
> > > > >> Department of Biology
> > > > >> It?inen Pitk?katu 4
> > > > >> 20520 Turku
> > > > >> Finland
> > > > >>
> > > > >
> > > > >
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> >
> >
> > --
> >
> > *Ken Beath*
> > Lecturer
> > Statistics Department
> > MACQUARIE UNIVERSITY NSW 2109, Australia
> >
> > Phone: +61 (0)2 9850 8516
> >
> > Level 2, AHH
> > http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
> >
> > CRICOS Provider No 00002J
> > This message is intended for the addressee named and may...{{dropped:9}}
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From smckinney at bccrc.ca  Mon Aug 24 20:22:01 2015
From: smckinney at bccrc.ca (Steven McKinney)
Date: Mon, 24 Aug 2015 18:22:01 +0000
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert
 contrasts
In-Reply-To: <CALWifgBmuehuB1u7vP5OeFV=mrCHbfXHw0CW5K=zQSeZdKBnXg@mail.gmail.com>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
	<CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
	<CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>
	<CAOE0pY=NTCZwOYz9N0tsqpCcR5rrzjjW_bGSA+J3tsjWZqiuuA@mail.gmail.com>
	<CAF5_5cy6WuNAsw+3qjL9+56=ZnAvnWMJ2jgLDik+-iHGdCwhJA@mail.gmail.com>
	<94ecd3aa45ba4b679338755155ab5458@CRCMAIL6.BCCRC.CA>,
	<CALWifgBmuehuB1u7vP5OeFV=mrCHbfXHw0CW5K=zQSeZdKBnXg@mail.gmail.com>
Message-ID: <1440440521464.41234@bccrc.ca>

Hi Becky,

For a model containing A + B + A:B we have two situations


Case 1)  Interest in A, but the need to have B in the model (B's parameter is a nuisance parameter in the model - B needs to be in the model do adjust for an important factor so that the model behaves properly, but B is not the factor we are interested in testing).  This is what I saw as the relevant situation in your case (you seemed to want to test Time, while adjusting for WordType).

Case 2)  Interest in the relevance of both A and B  (discussed in the dialog to which you linked below)


The discussion you link to below provides this hierarchy of models

l.full = lmer(response ~ A + B + A:B + (1 + A | sub) + (1 | item), data, family="binomial")
l.AB = lmer(response ~ A + B + (1 + A | sub) + (1 | item), data, family="binomial")
l.A = lmer(response ~ A + (1 + A | sub) + (1 | item), data, family="binomial")
l.B = lmer(response ~ B + (1 | sub) + (1 | item), data, family="binomial")

but omits

l.reduced = lmer(response ~ (1 | sub) + (1 | item), data, family="binomial")

i.e  the model with neither A nor B.


Case 1)  If we are interested in A, the omnibus test is

anova (l.B, l.full)

If this test is significant, and the contribution of A to the model is of a size of scientific relevance, then you can declare A as a significant model component and begin to investigate the functional form of that contribution.

The next step would be to test the interaction.  If that is significant and of relevant scientific size, then A is important, but its contribution differs for different levels of B.  If the interaction is not significant, and the sample size was large enough to detect differences of importance, then the interaction term can be dropped and the main effects model best summarizes the association.


Case 2) If we are interested in both A and B, the omnibus test for their joint relevance is

anova( l.reduced, l.full ).  This test was not discussed in the link you provided.

If this test yields a non-significant p-value, then A and B are not contributing to improving the model fit and their usefulness is questionable if the data set size was large enough to detect effect sizes of scientific relevance.

If the p-value is small, then of course we need to assess whether the improved model fit is telling us anything of scientific value.  (All p-values get small when data set sizes get large - so then the question is the relevance of the degree of association.)

The problem with the discussion you link to is that two test results were posited to assess the relevance of both A and B

"if anova(l.full, l.A) is significant, B has an effect (main effect or interaction).
if anova(l.full, l.B) is significant, A has an effect (main effect or interaction)."

so there's two tests and no discussion of adjustment for multiple comparisons.  The omnibus test anova( l.reduced, l.full ) tests both A and B simultaneously in one test at the stated type I error rate.  If that test is significant, and the effect sizes of A and B in the model are more than just trivially small differences of no scientific or biological or medical relevance, then you can start assessing the nature of their joint contribution to the model.  The first thing to look at would then be the interaction term.  If that is significant, and of a relevant size, you are done.  Both A and B are important, but the contribution of A depends on the level of B.  If the interaction is not significant, then you can look at A and B individually and see which is contributing to the model fit at a level of scientific or biological or medical relevance.







Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney +at+ bccrc +dot+ ca

tel: 604-675-8000 x7561

Molecular Oncology
675 West 10th Ave, Floor 4, Room 4.122
Vancouver B.C.
V5Z 1L3
Canada
________________________________
From: Becky Gilbert <beckyannegilbert at gmail.com>
Sent: August 24, 2015 4:54 AM
To: Steven McKinney
Cc: Ken Beath; Dan McCloy; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Interpreting lmer() interactions with Helmert contrasts

Thanks very much everyone for the responses.

@Dan: Thank you for the recommendation about my factor contrast coefficients.  I hadn't given much thought to the sign/level association, but now that you point it out, it seems obvious that I should do it the way you describe.  Here are the model coefficients with recoded contrasts:

> contrasts(rtData$Time)
    [,1]
-1 -0.5  # pre-test
1   0.5  # post-test

> contrasts(rtData$WordType)
        [,1]        [,2]
0 -0.6666667  0.0  # untrained
1  0.3333333  0.5  # trained-related
2  0.3333333 -0.5  # trained-unrelated

                              Estimate     Std. Error    t value
(Intercept)               2.8765116  0.0177527  162.03
WordType1            -0.0111628  0.0110852   -1.01
WordType2            -0.0007306  0.0071519   -0.10
Time1                    0.0268310  0.0195248    1.37
WordType1:Time1   0.0301627  0.0115349    2.61
WordType2:Time1  -0.0089123  0.0141624   -0.63

My interpretations of the interaction coefficients are:
1) log RT increases (i.e. RTs slow down) for the two trained (vs untrained) Word Types at post-test (Time = 1)
2) log RT decreases (i.e. RTs speed up) for the trained-related (vs trained-unrelated) Word Type at post-test (Time = 1)..

However, this doesn't really answer my original question about how to assess (and report) the contribution of these two interactions to the model fit.  Obviously the t statistic is larger for the Time1:WordType1 compared to the Time1:WordType2 interaction coefficients, but that only tells me their relative contributions - I would need to know degrees of freedom to get p-values, which I understand is not straightforward.  Also, I've read that the t statistics for coefficients that are output by summary() for an lmer model are sequential tests and thus not the appropriate/desired statistics for assessing the contribution of factors (someone please correct me if I'm wrong!).  Hence the reason for using LRT to assess this.  This still leaves me with the problem of not being able to test the interactions between Time and the two contrasts for WordType - I can test the whole WordType factor and Time:WordType interaction via LRTs, but not each contrast within WordType.

@Steven: thanks for your explanation re interpreting main effects in the presence of an interaction, and of the Chi-square LRTs for assessing the contribution of factors/terms.

However I'm confused by this:

An omnibus test for the statistical significance of a variable of interest (say variable A), when that variable is in a model involving an interaction with another variable (say variable B) will test the interaction term A:B and the main effect A.  The full model has A + B + A:B and the reduced model has only B.  Thus a proper omnibus test for the usefulness of A in the model will involve the interaction A:B and the main effect A.  This test really should be done before testing A:B for proper multiple comparisons control.

Is this what you're saying?

1. test A: (A + B + A:B) vs (B)
2. test B: (A + B + A:B) vs (A)
then, if either of the above are significant:
3. test A:B: (A + B + A:B) vs (A + B)

Which I think is the procedure described here: https://mailman.ucsd.edu/pipermail/ling-r-lang-l/2011-October/000305.html
Assuming this is what you meant, will this procedure always get you to step 3 (assessing the interaction) in the case of a significant interaction without main effects (as in a cross-over interaction).  Sorry if I've completely misunderstood!

Becky


____________________________________________

Dr Becky Gilbert (nee Prince)

http://www.york.ac.uk/psychology/staff/postgrads/becky.gilbert/
http://www.researchgate.net/profile/Becky_Gilbert2
http://twitter.com/BeckyAGilbert

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jrmorrongiello at gmail.com  Wed Aug 26 15:23:18 2015
From: jrmorrongiello at gmail.com (John Morrongiello)
Date: Wed, 26 Aug 2015 23:23:18 +1000
Subject: [R-sig-ME] profile and/or bootstrapped CIs for GAMM random effects
Message-ID: <CAPTgL1Y6Z-bwZz4BVnouJ=Gw1JfGfYiKCNGihf-Xk8P=aOhsUw@mail.gmail.com>

Hi
I'm having trouble estimating CIs for random effects (i.e. CODE) from a
gamm4 model fit with a gamma distribution,
My model is:

c1<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=Gamma(link=log))

confint(c1$mer,method="profile")
##this returns
Error in mkMerMod(rho = environment(devfun), opt = opt, reTrms = b$reTrms,
:
  unused argument (devFunOnly = TRUE)

confint(c1$mer,method="boot")
##this returns
Error in mkNewReTrms(object, newdata, compReForm, na.action = na.action,  :
  random effects specified in re.form that were not present in original
model

Are these errors arising because I'm using a gamma distribution? Is there
another way to get the random effect CIs?

I can get random effect CIs for the following model:
c2<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=gaussian)

confint(c2$mer,method="profile")##works
confint(c2$mer,method="boot")##same error message as above

Thanks for your time
John

	[[alternative HTML version deleted]]


From beckyannegilbert at gmail.com  Wed Aug 26 16:51:07 2015
From: beckyannegilbert at gmail.com (Becky Gilbert)
Date: Wed, 26 Aug 2015 15:51:07 +0100
Subject: [R-sig-ME] Interpreting lmer() interactions with Helmert
	contrasts
In-Reply-To: <1440440521464.41234@bccrc.ca>
References: <CALWifgBRx0Zuno7FHNQ=jZ0Ko-5vuTGkLAyS_wRP-qeGeCBm5A@mail.gmail.com>
	<op.x3ptqoyza3mgvf@armadillo>
	<CALWifgC=+-s=uxA25uTXE8_eK0BcrGTV4+YEPx8xkJJuD8YXiA@mail.gmail.com>
	<CALWifgDK1k1p_AUaqOCE+TysXRY4Zr6E-N+Jkx6NFDrwFwCW-w@mail.gmail.com>
	<CAOE0pY=NTCZwOYz9N0tsqpCcR5rrzjjW_bGSA+J3tsjWZqiuuA@mail.gmail.com>
	<CAF5_5cy6WuNAsw+3qjL9+56=ZnAvnWMJ2jgLDik+-iHGdCwhJA@mail.gmail.com>
	<94ecd3aa45ba4b679338755155ab5458@CRCMAIL6.BCCRC.CA>
	<CALWifgBmuehuB1u7vP5OeFV=mrCHbfXHw0CW5K=zQSeZdKBnXg@mail.gmail.com>
	<1440440521464.41234@bccrc.ca>
Message-ID: <CALWifgB=RLKHpZ4n0ym5KQdmsviGhb+me0h2cC0ivQcgZw+Ahg@mail.gmail.com>

Hi Steven,

Thanks very much for the clear and helpful explanation.  Thanks also for
highlighting the difference between the two cases.

In case you (or anyone else) is interested, neither factor is a nuisance
variable.  I'm interested in the effects of both Time and Word Type, and
especially their interaction.  We were predicting:

1. RTs for the two trained Word Types (related and unrelated) would
increase at Time 1 (post-training) vs Time -1 (pre-training), but RTs for
the untrained Word Type would be the same for both levels of Time
2. RTs for the unrelated Word Type might show a larger effect of time (i.e.
increase at Time 1) compared to the related Word Type (this is the main
research question)

This goes back to the original question I posted to the list - I tried to
use Helmert contrasts for Word Type to get separate interaction terms
relating to each prediction above, but couldn't work out how to get LRTs
for the two interactions terms (because removing the WordType:Time term
removes the interactions for both WordType contrasts at the same time).
I've since tried explicitly coding the two WordType contrasts as separate
variables (rather than using contrasts() on a single variable) so that I
can remove the interactions with each contrast separately and then assess
their contributions to the model.  However I'm not sure whether this
solution is correct/ideal.

Becky


On 24 August 2015 at 19:22, Steven McKinney <smckinney at bccrc.ca> wrote:

> Hi Becky,
>
> For a model containing A + B + A:B we have two situations
>
>
> Case 1)  Interest in A, but the need to have B in the model (B's parameter
> is a nuisance parameter in the model - B needs to be in the model do adjust
> for an important factor so that the model behaves properly, but B is not
> the factor we are interested in testing).  This is what I saw as the
> relevant situation in your case (you seemed to want to test Time, while
> adjusting for WordType).
>
> Case 2)  Interest in the relevance of both A and B  (discussed in the
> dialog to which you linked below)
>
>
> The discussion you link to below provides this hierarchy of models
>
> l.full = lmer(response ~ A + B + A:B + (1 + A | sub) + (1 | item), data,
> family="binomial")
> l.AB = lmer(response ~ A + B + (1 + A | sub) + (1 | item), data,
> family="binomial")
> l.A = lmer(response ~ A + (1 + A | sub) + (1 | item), data,
> family="binomial")
> l.B = lmer(response ~ B + (1 | sub) + (1 | item), data, family="binomial")
>
> but omits
>
> l.reduced = lmer(response ~ (1 | sub) + (1 | item), data,
> family="binomial")
>
> i.e  the model with neither A nor B.
>
>
> Case 1)  If we are interested in A, the omnibus test is
>
> anova (l.B, l.full)
>
> If this test is significant, and the contribution of A to the model is of
> a size of scientific relevance, then you can declare A as a significant
> model component and begin to investigate the functional form of that
> contribution.
>
> The next step would be to test the interaction.  If that is significant
> and of relevant scientific size, then A is important, but its contribution
> differs for different levels of B.  If the interaction is not significant,
> and the sample size was large enough to detect differences of importance,
> then the interaction term can be dropped and the main effects model best
> summarizes the association.
>
>
> Case 2) If we are interested in both A and B, the omnibus test for their
> joint relevance is
>
> anova( l.reduced, l.full ).  This test was not discussed in the link you
> provided.
>
> If this test yields a non-significant p-value, then A and B are not
> contributing to improving the model fit and their usefulness is
> questionable if the data set size was large enough to detect effect sizes
> of scientific relevance.
>
> If the p-value is small, then of course we need to assess whether the
> improved model fit is telling us anything of scientific value.  (All
> p-values get small when data set sizes get large - so then the question is
> the relevance of the degree of association.)
>
> The problem with the discussion you link to is that two test results were
> posited to assess the relevance of both A and B
>
> "if anova(l.full, l.A) is significant, B has an effect (main effect or
> interaction).
> if anova(l.full, l.B) is significant, A has an effect (main effect or
> interaction)."
>
> so there's two tests and no discussion of adjustment for multiple
> comparisons.  The omnibus test anova( l.reduced, l.full ) tests both A and
> B simultaneously in one test at the stated type I error rate.  If that test
> is significant, and the effect sizes of A and B in the model are more than
> just trivially small differences of no scientific or biological or medical
> relevance, then you can start assessing the nature of their joint
> contribution to the model.  The first thing to look at would then be the
> interaction term.  If that is significant, and of a relevant size, you are
> done.  Both A and B are important, but the contribution of A depends on the
> level of B.  If the interaction is not significant, then you can look at A
> and B individually and see which is contributing to the model fit at a
> level of scientific or biological or medical relevance.
>
>
>
>
>
>
>
> Steven McKinney, Ph.D.
>
> Statistician
> Molecular Oncology and Breast Cancer Program
> British Columbia Cancer Research Centre
>
> email: smckinney +at+ bccrc +dot+ ca
>
> tel: 604-675-8000 x7561
>
> Molecular Oncology
> 675 West 10th Ave, Floor 4, Room 4.122
> Vancouver B.C.
> V5Z 1L3
> Canada
> ________________________________
> From: Becky Gilbert <beckyannegilbert at gmail.com>
> Sent: August 24, 2015 4:54 AM
> To: Steven McKinney
> Cc: Ken Beath; Dan McCloy; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Interpreting lmer() interactions with Helmert
> contrasts
>
> Thanks very much everyone for the responses.
>
> @Dan: Thank you for the recommendation about my factor contrast
> coefficients.  I hadn't given much thought to the sign/level association,
> but now that you point it out, it seems obvious that I should do it the way
> you describe.  Here are the model coefficients with recoded contrasts:
>
> > contrasts(rtData$Time)
>     [,1]
> -1 -0.5  # pre-test
> 1   0.5  # post-test
>
> > contrasts(rtData$WordType)
>         [,1]        [,2]
> 0 -0.6666667  0.0  # untrained
> 1  0.3333333  0.5  # trained-related
> 2  0.3333333 -0.5  # trained-unrelated
>
>                               Estimate     Std. Error    t value
> (Intercept)               2.8765116  0.0177527  162.03
> WordType1            -0.0111628  0.0110852   -1.01
> WordType2            -0.0007306  0.0071519   -0.10
> Time1                    0.0268310  0.0195248    1.37
> WordType1:Time1   0.0301627  0.0115349    2.61
> WordType2:Time1  -0.0089123  0.0141624   -0.63
>
> My interpretations of the interaction coefficients are:
> 1) log RT increases (i.e. RTs slow down) for the two trained (vs
> untrained) Word Types at post-test (Time = 1)
> 2) log RT decreases (i.e. RTs speed up) for the trained-related (vs
> trained-unrelated) Word Type at post-test (Time = 1)..
>
> However, this doesn't really answer my original question about how to
> assess (and report) the contribution of these two interactions to the model
> fit.  Obviously the t statistic is larger for the Time1:WordType1 compared
> to the Time1:WordType2 interaction coefficients, but that only tells me
> their relative contributions - I would need to know degrees of freedom to
> get p-values, which I understand is not straightforward.  Also, I've read
> that the t statistics for coefficients that are output by summary() for an
> lmer model are sequential tests and thus not the appropriate/desired
> statistics for assessing the contribution of factors (someone please
> correct me if I'm wrong!).  Hence the reason for using LRT to assess this.
> This still leaves me with the problem of not being able to test the
> interactions between Time and the two contrasts for WordType - I can test
> the whole WordType factor and Time:WordType interaction via LRTs, but not
> each contrast within WordType.
>
> @Steven: thanks for your explanation re interpreting main effects in the
> presence of an interaction, and of the Chi-square LRTs for assessing the
> contribution of factors/terms.
>
> However I'm confused by this:
>
> An omnibus test for the statistical significance of a variable of interest
> (say variable A), when that variable is in a model involving an interaction
> with another variable (say variable B) will test the interaction term A:B
> and the main effect A.  The full model has A + B + A:B and the reduced
> model has only B.  Thus a proper omnibus test for the usefulness of A in
> the model will involve the interaction A:B and the main effect A.  This
> test really should be done before testing A:B for proper multiple
> comparisons control.
>
> Is this what you're saying?
>
> 1. test A: (A + B + A:B) vs (B)
> 2. test B: (A + B + A:B) vs (A)
> then, if either of the above are significant:
> 3. test A:B: (A + B + A:B) vs (A + B)
>
> Which I think is the procedure described here:
> https://mailman.ucsd.edu/pipermail/ling-r-lang-l/2011-October/000305.html
> Assuming this is what you meant, will this procedure always get you to
> step 3 (assessing the interaction) in the case of a significant interaction
> without main effects (as in a cross-over interaction).  Sorry if I've
> completely misunderstood!
>
> Becky
>
>
> ____________________________________________
>
> Dr Becky Gilbert (nee Prince)
>
> http://www.york.ac.uk/psychology/staff/postgrads/becky.gilbert/
> http://www.researchgate.net/profile/Becky_Gilbert2
> http://twitter.com/BeckyAGilbert
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From kanixwang at uchicago.edu  Wed Aug 26 22:11:17 2015
From: kanixwang at uchicago.edu (Kanix Wang)
Date: Wed, 26 Aug 2015 15:11:17 -0500
Subject: [R-sig-ME] Inflated heritability estimate for animal model with
 binary response using MCMCglmm
Message-ID: <CACTuc-fKCfDcV6VAJ8wwLb6Oqtwrx1_3_Oxv85CStLKd=BfT8w@mail.gmail.com>

Dear list,

I'm using MCMglmm to estimate heritability for binary traits with the model
below. I have seen a inflated heritbility estimate when I use sex and age
as fixed effects vs only using intercept. Both estimates passed the
convergence test and half-width test.
Can anyone help me identify the likely causes of this inflation? Is the
model mis-specified? Also, I'm wondering if using age as a random effect
make any sense.

priorA <- list(R = list(V = 1, fix = 1), G = list(G1 =list(V = 1, nu =
1000, alpha.mu = 0, alpha.V = 1), G2 =list(V = 1, n = 1)))

modelbin <- MCMCglmm(pheno ~ sex + age, random = ~animal +fam , family =
"ordinal", pedigree = pedigree, prior = priorA, data = databin, nitt =
nitt, burnin = burnin, thin = 500, slice=TRUE, pl=TRUE)

Sex and age are factor variables. The fam variable is for the common
environment effects in the descendants. All parents have NA for fam.

Any help would be greatly appreciated.

Best,
Kanix Wang

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sun Aug 30 11:57:14 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 30 Aug 2015 10:57:14 +0100
Subject: [R-sig-ME] Inflated heritability estimate for animal model with
 binary response using MCMCglmm
In-Reply-To: <CACTuc-fKCfDcV6VAJ8wwLb6Oqtwrx1_3_Oxv85CStLKd=BfT8w@mail.gmail.com>
References: <CACTuc-fKCfDcV6VAJ8wwLb6Oqtwrx1_3_Oxv85CStLKd=BfT8w@mail.gmail.com>
Message-ID: <20150830105714.6876684gegmemdgk@www.staffmail.ed.ac.uk>

Hi,

Is this the h2 on the latent or data scale? If the latent scale do  
families/relatives have correlated sexes/ages? If they do, this may  
explain a drop in the latent scale h2.

Also, if you have phenotypes for parents it is very important that you  
give them dummy fam variables not NA. They did belong to a family,  
even if you did not record it.

I would also use family="threshold" rather than family="ordinal". They  
are equivalent but you do not need to add 1 to the denominator  
variance of the h2 with family="threshold". If you set V_units=1,  
family="threshold" is the standard probit model.

Also, V=1 and nu=1 is a pretty strong prior, and so you may want to  
change this.

Cheers,

Jarrod


<kanixwang at uchicago.edu> on Wed, 26 Aug 2015 15:11:17 -0500:

> Dear list,
>
> I'm using MCMglmm to estimate heritability for binary traits with the model
> below. I have seen a inflated heritbility estimate when I use sex and age
> as fixed effects vs only using intercept. Both estimates passed the
> convergence test and half-width test.
> Can anyone help me identify the likely causes of this inflation? Is the
> model mis-specified? Also, I'm wondering if using age as a random effect
> make any sense.
>
> priorA <- list(R = list(V = 1, fix = 1), G = list(G1 =list(V = 1, nu =
> 1000, alpha.mu = 0, alpha.V = 1), G2 =list(V = 1, n = 1)))
>
> modelbin <- MCMCglmm(pheno ~ sex + age, random = ~animal +fam , family =
> "ordinal", pedigree = pedigree, prior = priorA, data = databin, nitt =
> nitt, burnin = burnin, thin = 500, slice=TRUE, pl=TRUE)
>
> Sex and age are factor variables. The fam variable is for the common
> environment effects in the descendants. All parents have NA for fam.
>
> Any help would be greatly appreciated.
>
> Best,
> Kanix Wang
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From chirleu at gmail.com  Mon Aug 31 09:06:40 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Mon, 31 Aug 2015 09:06:40 +0200
Subject: [R-sig-ME] acf() and lme
Message-ID: <CALC46t9fYu15+EQjuJO4Pq_bu13-mr5Epvyqj7bw3-5i-1tcAw@mail.gmail.com>

Dear list,

I'm running a model like this using lme (nlme):

model=lme(res~t1+t2+poly(month,3)+location,random=~1|ID,data=dataset,method="REML")

where "res" is the response variable, "t1", "t2" and "month" are
explanatory variables and "ID" is individual identity.

If I extract the normalized residuals and run acf(residuals), there is
evidence for strong autocorrelation (in this case, temporal
autocorrelation, since data were collected in a monthly basis over 3 years).

So I can run the same model incorporating the autocorrelation structure.

model=lme(res~t1+t2+poly(t3,3)+location,random=~1|ID,correlation=corAR1(form=~tim),data=dataset,method="REML")

where "tim" is a time dummy variable.

This model is much better according to AIC and anova, and if I run
acf(residuals) now, the plot seems ok.

However, my questions are:

1. How does acf know which observations are potentionally correlated
(because they share the same ID in this case) and which are not if I only
pass the residuals?

2. How does acf know which is the correct time order of the observations?

Thanks in advance,

David

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Aug 31 09:31:59 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 31 Aug 2015 09:31:59 +0200
Subject: [R-sig-ME] acf() and lme
In-Reply-To: <CALC46t9fYu15+EQjuJO4Pq_bu13-mr5Epvyqj7bw3-5i-1tcAw@mail.gmail.com>
References: <CALC46t9fYu15+EQjuJO4Pq_bu13-mr5Epvyqj7bw3-5i-1tcAw@mail.gmail.com>
Message-ID: <CAJuCY5wZgGE_g2CNP9MFpVKg-csg7GBCQhq3+rimz8=7S==MnQ@mail.gmail.com>

Dear David,

1) It is safer to use ACF(model) because ACF() was created to handle
nlme objects. And thus can take the correct design structure into
account. acf() probably worked because the data was sorted first along
ID and then along time.
2) acf() doesn't. It uses the current order in the data.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-08-31 9:06 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:
> Dear list,
>
> I'm running a model like this using lme (nlme):
>
> model=lme(res~t1+t2+poly(month,3)+location,random=~1|ID,data=dataset,method="REML")
>
> where "res" is the response variable, "t1", "t2" and "month" are
> explanatory variables and "ID" is individual identity.
>
> If I extract the normalized residuals and run acf(residuals), there is
> evidence for strong autocorrelation (in this case, temporal
> autocorrelation, since data were collected in a monthly basis over 3 years).
>
> So I can run the same model incorporating the autocorrelation structure.
>
> model=lme(res~t1+t2+poly(t3,3)+location,random=~1|ID,correlation=corAR1(form=~tim),data=dataset,method="REML")
>
> where "tim" is a time dummy variable.
>
> This model is much better according to AIC and anova, and if I run
> acf(residuals) now, the plot seems ok.
>
> However, my questions are:
>
> 1. How does acf know which observations are potentionally correlated
> (because they share the same ID in this case) and which are not if I only
> pass the residuals?
>
> 2. How does acf know which is the correct time order of the observations?
>
> Thanks in advance,
>
> David
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From chirleu at gmail.com  Mon Aug 31 10:49:02 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Mon, 31 Aug 2015 10:49:02 +0200
Subject: [R-sig-ME] acf() and lme
In-Reply-To: <CAJuCY5wZgGE_g2CNP9MFpVKg-csg7GBCQhq3+rimz8=7S==MnQ@mail.gmail.com>
References: <CALC46t9fYu15+EQjuJO4Pq_bu13-mr5Epvyqj7bw3-5i-1tcAw@mail.gmail.com>
	<CAJuCY5wZgGE_g2CNP9MFpVKg-csg7GBCQhq3+rimz8=7S==MnQ@mail.gmail.com>
Message-ID: <CALC46t-T-pFUTJ19Fay5q9aTQNAECZOFotj+uSmyH=g-emjtTA@mail.gmail.com>

Thanks Thierry, very helpful.

David

2015-08-31 9:31 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear David,
>
> 1) It is safer to use ACF(model) because ACF() was created to handle
> nlme objects. And thus can take the correct design structure into
> account. acf() probably worked because the data was sorted first along
> ID and then along time.
> 2) acf() doesn't. It uses the current order in the data.
>
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2015-08-31 9:06 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:
> > Dear list,
> >
> > I'm running a model like this using lme (nlme):
> >
> >
> model=lme(res~t1+t2+poly(month,3)+location,random=~1|ID,data=dataset,method="REML")
> >
> > where "res" is the response variable, "t1", "t2" and "month" are
> > explanatory variables and "ID" is individual identity.
> >
> > If I extract the normalized residuals and run acf(residuals), there is
> > evidence for strong autocorrelation (in this case, temporal
> > autocorrelation, since data were collected in a monthly basis over 3
> years).
> >
> > So I can run the same model incorporating the autocorrelation structure.
> >
> >
> model=lme(res~t1+t2+poly(t3,3)+location,random=~1|ID,correlation=corAR1(form=~tim),data=dataset,method="REML")
> >
> > where "tim" is a time dummy variable.
> >
> > This model is much better according to AIC and anova, and if I run
> > acf(residuals) now, the plot seems ok.
> >
> > However, my questions are:
> >
> > 1. How does acf know which observations are potentionally correlated
> > (because they share the same ID in this case) and which are not if I only
> > pass the residuals?
> >
> > 2. How does acf know which is the correct time order of the observations?
> >
> > Thanks in advance,
> >
> > David
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Mon Aug 31 17:53:41 2015
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Mon, 31 Aug 2015 11:53:41 -0400
Subject: [R-sig-ME] Using lmer to determine inter-rater reliability
Message-ID: <55E47885.30001@utoronto.ca>

Hello.

I have a data frame with following structure.

 > str(vision)
'data.frame':	268 obs. of  9 variables:
  $ Child          : Factor w/ 67 levels "C01-05","C01-10",..: 43 43 43 
43 44 44 44 44 42 42 ...
  $ Test           : Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 4 
1 2 ...
  $ Rater          : Factor w/ 4 levels "F","L","P","S": 4 1 4 1 1 4 1 4 
4 1 ...
  $ Binoc          : int  100 100 100 100 0 0 0 0 40 0 ...
  $ Yield          : int  100 100 100 80 100 20 50 30 100 100 ...
  $ Tries          : int  5 5 5 6 5 10 10 10 5 5 ...
  $ Result         : Factor w/ 5 levels "Pass","ReferBI",..: 1 1 1 1 3 2 
3 2 3 3 ...
  $ ResultCollapsed: Factor w/ 3 levels "Pass","Refer",..: 1 1 1 1 2 2 2 
2 2 2 ...
  $ Test1          : Factor w/ 16 levels "F:1","F:2","F:3",..: 13 2 15 4 
1 14 3 16 13 2 ...

In these data, each subject is rated by 2 (of 4) raters twice. The Test1 
variable was created from Test and Rater with
(Rater:Test)[drop=TRUE] to explicitly create the nesting.

I then fit the following model.

 > binoc.lmer1 <- lmer(Binoc~1+(1|Child) + (1|Rater) + 
(1|Test1),data=vision)
 > binoc.lmer1
Linear mixed model fit by REML ['lmerMod']
Formula: Binoc ~ 1 + (1 | Child) + (1 | Rater) + (1 | Test1)
    Data: vision
REML criterion at convergence: 2592.62
Random effects:
  Groups   Name        Std.Dev.
  Child    (Intercept) 29.226
  Test1    (Intercept)  2.292
  Rater    (Intercept)  5.823
  Residual             26.330
Number of obs: 264, groups:  Child, 66; Test1, 16; Rater, 4
Fixed Effects:
(Intercept)
       51.68


Now my questions.

1. Have I fit the right model?

2. If so, would the right estimate for the rater ICC be
	Rater/(Rater + Residual)
    or
	(Rater + Test1)/(Rater + Test1 + Residual)

3. Would Test1/(Test1 + Residual) give an estimate of intra-rater 
reliability?

Thanks for you time.

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From lindeh at uw.edu  Sun Aug 30 22:41:33 2015
From: lindeh at uw.edu (Hannah L. Linder)
Date: Sun, 30 Aug 2015 13:41:33 -0700
Subject: [R-sig-ME] GLMMpql and GEE question
Message-ID: <CAF0=RbYvSFwGbAjGrsXqL72PpXpgsmHBZ3zuEPk5bsDy6ZcFSw@mail.gmail.com>

Hi,

I am an M.S. student at the University of Washington School of Aquatic and
Fishery Sciences.My thesis involves the comparison of many models that you
could use to analyze monitoring data. A big part of this comparison is
looking at models with and without autocorrelation (my data is a univariate
time series). I was hoping to compare a GLS, GLM, and GLM with
autocorrelation for a non-normal data set using their RMSE values. I was
originally intending to use a GLM-GEE, because I have seen them used in the
literature within my field, but I noticed the glmmPQL function allows for
different corARMA correlation structure and the gee only allow for an ar-1
correlation structure. So now, I believe that I would rather use the
glmmPQL for the purpose of comparing a model that allows for
autocorrelation but is normally distributed (GLS), one that is non-normal
with no autocorrelation (GLM), and one that is non-normal with
autocorrelation. I am wondering if there is a big difference between the
glmmPQL model and a glm-gee? I know the gee is a marginal model, and a glmm
models random effects, but in the case of a univariate time series (which
is essentially a single group) I am not sure how this would make a big
difference.


If anyone has any time to provide suggestions on better understanding the
difference between these two models, or if it is appropriate to use a glmm
rather than a gee in this case, I would greatly appreciate it.

Thank-you very much,
Hannah Linder

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Sep  1 10:24:07 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 1 Sep 2015 10:24:07 +0200
Subject: [R-sig-ME] GLMMpql and GEE question
In-Reply-To: <CAF0=RbYvSFwGbAjGrsXqL72PpXpgsmHBZ3zuEPk5bsDy6ZcFSw@mail.gmail.com>
References: <CAF0=RbYvSFwGbAjGrsXqL72PpXpgsmHBZ3zuEPk5bsDy6ZcFSw@mail.gmail.com>
Message-ID: <CAJuCY5wS10CXtUxdHFih5F6pwfdG3xpfOwmHCuE+MbqJ3=5CeQ@mail.gmail.com>

Dear Hanna,

GLMM doesn't make sense if you have only one level. It requires
theoretically at least two, in practice even more to get reliable
fits.

I would have a look at the INLA package (www.r-inla.org). It allows
both several non-gaussian distributions and correlated random effects.
In case of a univariate timeseries, then time itself is the random
effect.

library(INLA)
inla(Count ~ f(Time, model = "ar1"), family = "poisson") # AR1
inla(Count ~ f(Time, model = "rw1"), family = "poisson") # random walk order 1
inla(Count ~ f(Time, model = "rw2"), family = "poisson") # random walk order 2

see http://www.r-inla.org/models/latent-models

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-08-30 22:41 GMT+02:00 Hannah L. Linder <lindeh at uw.edu>:
> Hi,
>
> I am an M.S. student at the University of Washington School of Aquatic and
> Fishery Sciences.My thesis involves the comparison of many models that you
> could use to analyze monitoring data. A big part of this comparison is
> looking at models with and without autocorrelation (my data is a univariate
> time series). I was hoping to compare a GLS, GLM, and GLM with
> autocorrelation for a non-normal data set using their RMSE values. I was
> originally intending to use a GLM-GEE, because I have seen them used in the
> literature within my field, but I noticed the glmmPQL function allows for
> different corARMA correlation structure and the gee only allow for an ar-1
> correlation structure. So now, I believe that I would rather use the
> glmmPQL for the purpose of comparing a model that allows for
> autocorrelation but is normally distributed (GLS), one that is non-normal
> with no autocorrelation (GLM), and one that is non-normal with
> autocorrelation. I am wondering if there is a big difference between the
> glmmPQL model and a glm-gee? I know the gee is a marginal model, and a glmm
> models random effects, but in the case of a univariate time series (which
> is essentially a single group) I am not sure how this would make a big
> difference.
>
>
> If anyone has any time to provide suggestions on better understanding the
> difference between these two models, or if it is appropriate to use a glmm
> rather than a gee in this case, I would greatly appreciate it.
>
> Thank-you very much,
> Hannah Linder
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From joaquin.aldabe at gmail.com  Tue Sep  1 22:58:44 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 1 Sep 2015 17:58:44 -0300
Subject: [R-sig-ME] glmm question
Message-ID: <CAMM93=L_c8c2EVz6f_Cp+O_KxBd7ycEvQh6W3vK+yVKQNehSqQ@mail.gmail.com>

Hello, I?m trying to model de abundance of a grassland shorebird
(Buff-breasted Sandpiper, BBSA) as a function of the abundance of American
Golden Plover (AMGP) abundance, grass height and distance to the lagoon.
I?m using area as an offset.

I?ve tried a glmm with poisson errors and wanted you to see if residuals
are fine (they don?t look great, but wanted to know if they area minimally
acceptable). Also, I?m trying to understand two way interactions but I?m no
sure how to proceed, and also would like to plot the interactions and
unique variables effects (can you please provide suggestions?).

I also have problems with the predict function. In the script are the
notes. I?m attaching the data as well as the script with commentaries.

Let me know if there?s some format problem with the files.

Thank you very much in advanced.

Joaqu?n.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
-------------- next part --------------
Field_name	Year	Month	Grassland_type	Prop_numero_potr_pastalto	Grass_height	Has_pastalt	Prop_sup_pastoalt	Field_area	Distance_to_lagoon	Flood	Field_enclosure_700m	Field_enclosure_350	Grazing_regime	BBSA	AMGP
Casas	2006	December	Natural	0,375	13,0	264,0	0,1	47	4699	No	61,0	42,8	Rotational	0	0
Pradera_B	2006	December	Improved	0,375	37,0	264,0	0,1	50	4426	No	66,8	46,4	Rotational	0	0
Pradera_A	2006	December	Improved	0,375	4,5	264,0	0,1	32	4073	No	76,9	68,9	Rotational	0	0
Ba?o	2006	December	Natural	0,375	7,0	264,0	0,1	142	2611	Yes	9,2	2,7	Continuous	65	100
Puesto	2006	December	Natural	0,375	6,5	264,0	0,1	261	1864	Yes	3,1	0,0	Continuous	1	39
Tres_Porteras	2006	December	Natural	0,375	6,0	264,0	0,1	92	2480	No	43,9	24,3	Continuous	0	0
Del_Medio	2006	December	Natural	0,375	4,5	264,0	0,1	82	2962	No	39,6	18,5	Continuous	0	0
Sancho	2006	December	Natural	0,375	3,0	264,0	0,1	244	874	Yes	26,8	6,8	Continuous	57	30
Laguna	2006	December	Natural	0,375	4,5	264,0	0,1	345	459	Yes	6,5	0,0	Continuous	94	201
Bolsa_Chica	2006	December	Natural	0,375	8,0	264,0	0,1	122	562	Yes	18,3	4,3	Continuous	0	1
Estero	2006	December	Improved	0,375	8,0	264,0	0,1	179	2600	No	25,8	10,6	Rotational	0	1
Coronillas	2006	December	Natural	0,375	3,5	264,0	0,1	150	342	Yes	7,5	0,5	Continuous	14	2
Pradera_Balneario	2006	December	Improved	0,375	35,0	264,0	0,1	36	4037	No	63,9	48,1	Rotational	0	0
Primer_Potrero	2006	December	Improved	0,375	35,0	264,0	0,1	43	3584	No	62,6	35,9	Rotational	0	0
Pileta	2006	December	Improved	0,375	40,0	264,0	0,1	46	3046	No	43,2	28,8	Rotational	0	0
Aljibe	2006	December	Improved	0,375	40,0	264,0	0,1	42	2361	No	47,4	38,3	Rotational	0	0
Casas	2007	December	Natural	0,1875	4,0	347,0	18,0	47	4699	No	61,0	42,9	Rotational	0	0
Pradera_B	2007	December	Improved	0,1875	30,0	347,0	18,0	50	4426	No	66,8	46,4	Rotational	0	0
Pradera_Balneario	2007	December	Improved	0,1875	6,0	347,0	18,0	36	4037	No	63,9	48,1	Rotational	0	0
Primer_Potrero	2007	December	Improved	0,1875	7,0	347,0	18,0	43	3584	No	62,6	35,9	Rotational	0	30
Pradera_A	2007	December	Improved	0,1875	6,0	347,0	18,0	32	4073	No	76,9	68,9	Rotational	0	0
Ba?o	2007	December	Natural	0,1875	3,5	347,0	18,0	142	2611	Yes	9,2	2,7	Continuous	7	64
Laguna	2007	December	Natural	0,1875	4,0	347,0	18,0	345	459	Yes	6,5	0,0	Continuous	4	91
Puesto	2007	December	Natural	0,1875	12,0	347,0	18,0	261	1864	Yes	3,1	0,0	Continuous	54	131
Sancho	2007	December	Natural	0,1875	4,5	347,0	18,0	244	874	Yes	26,8	6,8	Continuous	66	65
Bolsa_Chica	2007	December	Natural	0,1875	4,0	347,0	18,0	122	562	Yes	18,3	4,3	Continuous	52	92
Tres_Porteras	2007	December	Natural	0,1875	4,0	347,0	18,0	92	2480	No	43,9	24,3	Continuous	0	0
Del_Medio	2007	December	Natural	0,1875	6,5	347,0	18,0	82	2962	No	39,6	18,5	Continuous	0	0
Pileta	2007	December	Improved	0,1875	14,0	347,0	18,0	46	3046	No	43,2	28,8	Rotational	0	0
Aljibe	2007	December	Improved	0,1875	6,0	347,0	18,0	42	2361	No	47,4	38,3	Rotational	2	54
Coronillas	2007	December	Natural	0,1875	5,0	347,0	18,0	150	342	Yes	7,5	0,5	Continuous	55	157
Estero	2007	December	Improved	0,1875	7,0	347,0	18,0	179	2600	No	25,8	10,6	Rotational	0	0
Estero	2008	December	Improved	0,125	5,5	82,0	4,3	179	2600	No	25,8	10,6	Rotational	22	155
Del_Medio	2008	December	Natural	0,125	6,5	82,0	4,3	82	2962	No	39,6	18,5	Continuous	0	29
Tres_Porteras	2008	December	Natural	0,125	5,0	82,0	4,3	92	2480	No	43,9	24,3	Continuous	3	25
Primer_Potrero	2008	December	Improved	0,125	8,5	82,0	4,3	43	3584	No	62,6	35,9	Rotational	0	0
Pradera_Balneario	2008	December	Improved	0,125	8,0	82,0	4,3	36	4037	No	63,9	48,1	Rotational	0	0
Casas	2008	December	Natural	0,125	6,5	82,0	4,3	47	4699	No	61,0	42,9	Rotational	0	0
Laguna	2008	December	Natural	0,125	5,0	82,0	4,3	345	459	Yes	6,5	0,0	Continuous	14	27
Aljibe	2008	December	Improved	0,125	7,5	82,0	4,3	42	2361	No	47,4	38,3	Rotational	0	0
Bolsa_Chica	2008	December	Natural	0,125	4,5	82,0	4,3	122	562	Yes	18,3	4,3	Continuous	7	22
Pileta	2008	December	Improved	0,125	8,0	82,0	4,3	46	3046	No	43,2	28,8	Rotational	0	0
Coronillas	2008	December	Natural	0,125	3,0	82,0	4,3	150	342	Yes	7,5	0,5	Continuous	60	118
Sancho	2008	December	Natural	0,125	4,5	82,0	4,3	244	874	Yes	26,8	6,8	Continuous	59	198
Pradera_A	2008	December	Improved	0,125	12,0	82,0	4,3	32	4073	No	76,9	68,9	Rotational	0	0
Pradera_B	2008	December	Improved	0,125	20,0	82,0	4,3	50	4426	No	66,8	46,4	Rotational	0	0
Ba?o	2008	December	Natural	0,125	5,5	82,0	4,3	142	2611	Yes	9,2	2,7	Continuous	18	152
Puesto	2008	December	Natural	0,125	9,0	82,0	4,3	261	1864	Yes	3,1	0,0	Continuous	0	46
Puesto	2012	December	Natural	0,75	24,6	1512,0	79,0	261	1864	Yes	3,1	0,0	Continuous	0	0
Coronillas	2012	December	Natural	0,75	13,9	1512,0	79,0	150	342	Yes	7,5	0,5	Continuous	0	0
Sancho	2012	December	Natural	0,75	15,4	1512,0	79,0	244	874	Yes	26,8	6,8	Continuous	0	0
Primer_Potrero	2012	December	Improved	0,75	25,4	1512,0	79,0	43	3584	No	62,6	35,9	Rotational	0	0
Pradera_A	2012	December	Improved	0,75	16,0	1512,0	79,0	32	4073	No	76,9	68,9	Rotational	0	0
Pradera_B	2012	December	Improved	0,75	12,8	1512,0	79,0	50	4426	No	66,8	46,4	Rotational	0	0
Estero	2012	December	Improved	0,75	8,5	1512,0	79,0	179	2600	No	25,8	10,6	Rotational	7	143
Tres_Porteras	2012	December	Natural	0,75	9,7	1512,0	79,0	92	2480	No	43,9	24,3	Continuous	0	0
Del_Medio	2012	December	Natural	0,75	3,4	1512,0	79,0	82	2962	No	39,6	18,5	Continuous	57	273
Ba?o	2012	December	Natural	0,75	11,4	1512,0	79,0	142	2611	Yes	9,2	2,7	Continuous	0	0
Laguna	2012	December	Natural	0,75	14,8	1512,0	79,0	345	459	Yes	6,5	0,0	Continuous	0	0
Casas	2012	December	Natural	0,75	14,8	1512,0	79,0	47	4699	No	61,0	42,9	Rotational	0	0
Pradera_Balneario	2012	December	Improved	0,75	13,3	1512,0	79,0	30	4037	No	63,9	48,1	Rotational	0	557
Pileta	2012	December	Improved	0,75	19,0	1512,0	79,0	46	3046	No	43,2	28,8	Rotational	0	0
Aljibe	2012	December	Improved	0,75	3,4	1512,0	79,0	42	2361	No	47,4	38,3	Rotational	66	253
Bolsa_Chica	2012	December	Natural	0,75	35,0	1512,0	79,0	122	562	Yes	18,3	4,3	Continuous	0	0
															
															
-------------- next part --------------
my4<-read.table(file.choose(), header=T, dec=",")

#scale variables
my4s<-as.data.frame(scale(my4[,c(6,10,12,13,16)], center=T, scale=T))
my4S<-cbind(BBSA=my4$BBSA, Field_name=my4$Field_name,Grassland_type=my4$Grassland_type, Flood=my4$Flood, Year=my4$Year,my4s)
my4S$log.AMGP=scale(log(my4$AMGP+1), scale=T, center=T)

# Add Field_area to use as offset
my4S<-cbind(my4S, Field_area.o=my4$Field_area)

require(lme4)
m3.1=glmer(BBSA~log.AMGP*Distance_to_lagoon+Grass_height*Distance_to_lagoon+log.AMGP*Grass_height+Grassland_type+(1|Field_name),family="poisson", offset=log(Field_area.o),data=my4S[-61,])
summary(m3.1)

plot(fitted(m3.1),residuals(m3.1))
qqnorm(residuals(m3.1)); qqline(residuals(m3.1))

m3.1.1=update(m3.1,~.-Grassland_type)
summary(m3.1.1)

#Prediction with m3.1.1. I?m leaving as fix the variables amgp, distance to lagoon (dist), to see the effect of grass height (grass) when distance to lagoon is lowest. But I could not make prediction function work.  

#Distance to lagoon 

amgp=rep(-0.79,500)#0.47
dist=rep(-1.59,500)#0.52
grass=seq(-0.85,2.83, length.out=500)
area1=seq(30,345,500)#52.5
newdata=data.frame(log.AMGP=amgp, Distance_to_lagoon=dist,Grass_height=grass, Field_area.o=area1)
predglmm=predict(m3.1.1,newdata, Reform=~(1|Field_name))

From john.morrongiello at unimelb.edu.au  Wed Sep  2 00:51:54 2015
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Tue, 1 Sep 2015 22:51:54 +0000
Subject: [R-sig-ME] profile and/or bootstrapped CIs for GAMM random effects
Message-ID: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F85@000s-ex-mbx-qs1.unimelb.edu.au>

Hi all
I thought I'd re-post this message from last week as it may have got lost in the weekend traffic:

I'm having trouble estimating CIs for random effects (i.e. CODE) from a gamm4 model fit with a gamma distribution,
My model is:

c1<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=Gamma(link=log))
confint(c1$mer,method="profile")
##this returns
Error in mkMerMod(rho = environment(devfun), opt = opt, reTrms = b$reTrms,  :
  unused argument (devFunOnly = TRUE)

confint(c1$mer,method="boot")
##this returns
Error in mkNewReTrms(object, newdata, compReForm, na.action = na.action,  :
  random effects specified in re.form that were not present in original model
Are these errors arising because I'm using a gamma distribution? Is there another way to get the random effect CIs?

I can get random effect CIs for the following model:
c2<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=gaussian)

confint(c2$mer,method="profile")##works
confint(c2$mer,method="boot")##same error message as above

Thanks for your time
John

--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
W: morrongiellolab.com<http://morrongiellolab.com/>

	[[alternative HTML version deleted]]


From john.morrongiello at unimelb.edu.au  Wed Sep  2 01:10:08 2015
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Tue, 1 Sep 2015 23:10:08 +0000
Subject: [R-sig-ME] random slopes in gamm4
Message-ID: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F9B@000s-ex-mbx-qs1.unimelb.edu.au>

Hi all

Most GAMM examples involve the fitting of a model with just a random intercept (e.g. M1 below). However, I'd like to explore the possibility of each individual (ID) having a different X1 smoother 'slope', akin to a random slope in lmer (M2)

M1<-gamm4(response ~ s(X1,k=4), random =~(1|ID),data)
M2<-gamm4(response ~ s(X1,k=4), random =~(X1|ID),data)
However, I'm unsure how to interpret the random slope X1 in M2. If positive, is it an overall increase in smoother 'wriggliness' i.e. increase in edf (opposite for negative)? Or is it something else? Would someone know how to visualise these 'random smoothers' so I can get a feel for what is going on?

I found an example using the amer package (http://www.statistik.lmu.de/~poessnecker/Lehre/SoSe2011/SchaetzentestenII/material/hohenriedAmer.pdf) that does what I'd like to do (and plots up random smoothers), but I have no familiarity with this package and it appears to have been removed from cran.

d2 <- amer(y ~ -1 + group + bsp(time, k = 6, by = group) + bsp(time, k = 6, by = dog, allPen = T), data = dog), corr = F

The amer notes also say that gamm4 can't do subject-wise smooth trends, so I guess it is not possible? Which brings me back to my first question- what is the (X1|ID) in M2 doing?

Cheers

John




--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
W: morrongiellolab.com<http://morrongiellolab.com/>


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Sep  2 02:44:39 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 1 Sep 2015 20:44:39 -0400
Subject: [R-sig-ME] profile and/or bootstrapped CIs for GAMM random
 effects
In-Reply-To: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F85@000s-ex-mbx-qs1.unimelb.edu.au>
References: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F85@000s-ex-mbx-qs1.unimelb.edu.au>
Message-ID: <55E64677.5030905@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Is there any chance you could post a reproducible example ... ?

  (Out of curiosity, do you have strong reasons to use a Gamma/log-link
rather than a log-Normal model?)

  Ben Bolker

On 15-09-01 06:51 PM, John Morrongiello wrote:
> Hi all I thought I'd re-post this message from last week as it may
> have got lost in the weekend traffic:
> 
> I'm having trouble estimating CIs for random effects (i.e. CODE)
> from a gamm4 model fit with a gamma distribution, My model is:
> 
> c1<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=Gamma(link=log))
>
> 
confint(c1$mer,method="profile")
> ##this returns Error in mkMerMod(rho = environment(devfun), opt =
> opt, reTrms = b$reTrms,  : unused argument (devFunOnly = TRUE)
> 
> confint(c1$mer,method="boot") ##this returns Error in
> mkNewReTrms(object, newdata, compReForm, na.action = na.action,  : 
> random effects specified in re.form that were not present in
> original model Are these errors arising because I'm using a gamma
> distribution? Is there another way to get the random effect CIs?
> 
> I can get random effect CIs for the following model: 
> c2<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=gaussian)
>
>  confint(c2$mer,method="profile")##works 
> confint(c2$mer,method="boot")##same error message as above
> 
> Thanks for your time John
> 
> -- Dr. John R. Morrongiello School of BioSciences University of
> Melbourne Victoria 3010, Australia T: +61 3 8344 8929 M: +61 403
> 338 554 E:
> john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
>
> 
W: morrongiellolab.com<http://morrongiellolab.com/>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJV5kZ3AAoJEOCV5YRblxUHSRIH/jSfi8qVSxuFx9a+r6jy6zhQ
gq2pLAdbR3/gImwlXWyuJAzJRpPgd/oEYOP7l88iyLMOZNCo5hT5rUpsxzE0yxCH
3fsW1Pdy5+uL3As+jS3WYaECZp8wQt/Rh1tmV0ON/rVY7f+6Oa7ZGhc4Hjbg8+a8
MOgDMObnhVj+W2fd0WMgCSNczXUSKbFkgSEHCLoc2gt3MkvVDgL+mV5BI8XrYLob
u83k39Lu/Wp+BmkJoaVSSME3aQM1bpt+oL6wAQS/L0PFkMPIcLQDJ3F7drUrFxNo
UdCuHZ0OxeS2UEvpMIB8qSMb8FjJmKT64Zh0V3rrHXq4Hn1lh6CsHvBt9cmhcuY=
=fo9G
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Wed Sep  2 02:44:39 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 1 Sep 2015 20:44:39 -0400
Subject: [R-sig-ME] profile and/or bootstrapped CIs for GAMM random
 effects
In-Reply-To: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F85@000s-ex-mbx-qs1.unimelb.edu.au>
References: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F85@000s-ex-mbx-qs1.unimelb.edu.au>
Message-ID: <55E64677.4040809@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Is there any chance you could post a reproducible example ... ?

  (Out of curiosity, do you have strong reasons to use a Gamma/log-link
rather than a log-Normal model?)

  Ben Bolker

On 15-09-01 06:51 PM, John Morrongiello wrote:
> Hi all I thought I'd re-post this message from last week as it may
> have got lost in the weekend traffic:
> 
> I'm having trouble estimating CIs for random effects (i.e. CODE)
> from a gamm4 model fit with a gamma distribution, My model is:
> 
> c1<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=Gamma(link=log))
>
> 
confint(c1$mer,method="profile")
> ##this returns Error in mkMerMod(rho = environment(devfun), opt =
> opt, reTrms = b$reTrms,  : unused argument (devFunOnly = TRUE)
> 
> confint(c1$mer,method="boot") ##this returns Error in
> mkNewReTrms(object, newdata, compReForm, na.action = na.action,  : 
> random effects specified in re.form that were not present in
> original model Are these errors arising because I'm using a gamma
> distribution? Is there another way to get the random effect CIs?
> 
> I can get random effect CIs for the following model: 
> c2<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=gaussian)
>
>  confint(c2$mer,method="profile")##works 
> confint(c2$mer,method="boot")##same error message as above
> 
> Thanks for your time John
> 
> -- Dr. John R. Morrongiello School of BioSciences University of
> Melbourne Victoria 3010, Australia T: +61 3 8344 8929 M: +61 403
> 338 554 E:
> john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
>
> 
W: morrongiellolab.com<http://morrongiellolab.com/>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJV5kZ3AAoJEOCV5YRblxUHSRIH/jSfi8qVSxuFx9a+r6jy6zhQ
gq2pLAdbR3/gImwlXWyuJAzJRpPgd/oEYOP7l88iyLMOZNCo5hT5rUpsxzE0yxCH
3fsW1Pdy5+uL3As+jS3WYaECZp8wQt/Rh1tmV0ON/rVY7f+6Oa7ZGhc4Hjbg8+a8
MOgDMObnhVj+W2fd0WMgCSNczXUSKbFkgSEHCLoc2gt3MkvVDgL+mV5BI8XrYLob
u83k39Lu/Wp+BmkJoaVSSME3aQM1bpt+oL6wAQS/L0PFkMPIcLQDJ3F7drUrFxNo
UdCuHZ0OxeS2UEvpMIB8qSMb8FjJmKT64Zh0V3rrHXq4Hn1lh6CsHvBt9cmhcuY=
=fo9G
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Wed Sep  2 04:18:39 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 1 Sep 2015 22:18:39 -0400
Subject: [R-sig-ME] profile and/or bootstrapped CIs for GAMM random
 effects
In-Reply-To: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F85@000s-ex-mbx-qs1.unimelb.edu.au>
References: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F2F85@000s-ex-mbx-qs1.unimelb.edu.au>
Message-ID: <55E65C7F.6090103@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  This looks like it could get ugly, we might have to call on Simon
Wood.  I've posted it as https://github.com/lme4/lme4/issues/333 , but
I think it's really a gamm4 problem or at least a gamm4/lme4
communication problem.  The part of the problem I've been able to
identify so far is that the @call slot of the $mer part of the gamm4
object does *not* look like a normal lme4 call, which causes problems
(much farther down) where we use update() to try to reconstruct a
version of the model that is just a deviance function.  Getting a
deviance function back from a glmerMod object in a more
straightforward way is something that's been on our list ...

  Ben Bolker


On 15-09-01 06:51 PM, John Morrongiello wrote:
> Hi all I thought I'd re-post this message from last week as it may
> have got lost in the weekend traffic:
> 
> I'm having trouble estimating CIs for random effects (i.e. CODE)
> from a gamm4 model fit with a gamma distribution, My model is:
> 
> c1<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=Gamma(link=log))
>
> 
confint(c1$mer,method="profile")
> ##this returns Error in mkMerMod(rho = environment(devfun), opt =
> opt, reTrms = b$reTrms,  : unused argument (devFunOnly = TRUE)
> 
> confint(c1$mer,method="boot") ##this returns Error in
> mkNewReTrms(object, newdata, compReForm, na.action = na.action,  : 
> random effects specified in re.form that were not present in
> original model Are these errors arising because I'm using a gamma
> distribution? Is there another way to get the random effect CIs?
> 
> I can get random effect CIs for the following model: 
> c2<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family=gaussian)
>
>  confint(c2$mer,method="profile")##works 
> confint(c2$mer,method="boot")##same error message as above
> 
> Thanks for your time John
> 
> -- Dr. John R. Morrongiello School of BioSciences University of
> Melbourne Victoria 3010, Australia T: +61 3 8344 8929 M: +61 403
> 338 554 E:
> john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
>
> 
W: morrongiellolab.com<http://morrongiellolab.com/>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJV5lx/AAoJEOCV5YRblxUHmr4IANzYM/N+AKeC87E2D/CsqQ6y
6vRVkTq5hkugdh3/zhMip/WNO9cpdGiW0B8Rs9l4Auyb4LvflboVcUciaHiA5vpc
WSWc0AX4Y/aSyGfDa/F1Y0JyL1tawq/ivFU0W6F8DgTj4qi5CcA3v7ZmKoKBaGGv
gqDqY/XpjhKIWt91NtF4IIdSQDZxmFqrRu1Kfi5w7XXsBWS94PtbaWy6K6aIaMwc
J3bi+FotIlZTb0dNCgenhLT7ZnFLO928KDI5xSM4F7NVouRn3rCa0MRJnys3XPrM
M01gc72OSg47JGA87wtF2wWlTC49UYqGypQfByzNnLheIqf0ka2jCZrOHOBptiY=
=kq9H
-----END PGP SIGNATURE-----


From john.morrongiello at unimelb.edu.au  Wed Sep  2 15:48:01 2015
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Wed, 2 Sep 2015 13:48:01 +0000
Subject: [R-sig-ME] profile and/or bootstrapped CIs for GAMM random
	effects
Message-ID: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F32D0@000s-ex-mbx-qs1.unimelb.edu.au>

Hi Ben
Thanks for looking into this for me. It looks like you've been able to develop a reproducible example, but below is a subset of my data for reference. The full data are radio telemetry-based distances (longdist) for 28 fish on a flood plain, located approximately every 2 weeks. We're interested in exploring the temporal movement patterns of fish, and then identify potential environmental drivers of this. Fish leave their home pool in the wet season, move onto the floodplain for a period, then return pretty much back to their home pool

In regards to the Gamma/log-link model: I decided to go down this path as my response variable is distance from 'home' (longdist) which is strictly positive and continuous. I realise I could log-transform the data, but thought it good to just use an appropriate distribution. I'm happy to be convinced to go down the transformation path as it would help with other response variables that are continuous but include zeros (here I've had to split the analysis into two steps: 1) a binomial GLMM for zero or >0 distance; 2) a gamma GLMM for all distances >0)

Cheers
John

mydata <- structure(list(CODE = structure(c(4L, 3L, 8L, 3L, 8L, 4L, 8L,3L, 4L, 8L, 4L, 3L, 8L, 3L, 4L, 8L, 4L, 8L,
          4L, 8L, 1L, 3L, 7L,2L, 5L, 6L, 4L, 8L, 1L, 2L, 3L, 7L, 8L, 3L, 5L, 6L, 8L, 3L, 1L,7L, 2L, 5L, 6L, 1L, 3L, 8L, 5L,
          2L, 7L, 6L, 8L, 3L, 1L, 2L, 5L,6L, 7L, 8L, 3L, 1L, 5L, 2L, 6L, 7L, 3L, 1L, 5L, 2L, 7L, 8L, 1L,8L, 7L), 
         .Label = c("113.08", "113.09", "113.18", "113.2", "142","142.02", "142.11", "142.16"), class = "factor"),
          longdist = c(915.3204902,293.3651772, 121.817523, 926.8937579, 1657.624408, 634.3312583,192.829031, 258.3748562,
          612.3309929, 1369.839623, 515.8210633,243.1597688, 3955.710259, 9535.900065, 6882.407512, 1643.480296,9098.188882,
          1151.279039, 6526.611439, 2590.840377, 2872.818688,4482.909503, 277.6635567, 4188.271695, 8267.951169,
          3319.834396,11015.65632, 26744.47918, 1540.673734, 3623.761144, 5309.040932,452.5968432, 3043.91542, 4473.26457,
          7251.069327, 10195.13599,1455.050153, 4270.682608, 2341.194885, 1413.999748, 4296.287262,1870.788559, 5058.781157,
          1796.509776, 3564.458943, 321.5355384,2613.835935, 3616.955753, 167.6945737, 3768.178122, 1323.04003,3626.427229,
          342.0831861, 4025.501297, 1759.654454, 3575.230119,222.7191619, 1936.035776, 2087.192677, 66.80421153,
          3317.121218,3718.282656, 6090.502215, 328.044963, 3603.478304, 339.1607537,3139.444897, 4376.683207, 136.4894718, 1421.734876, 
         477.0550425,174.7315492, 1347.494408),
          time = c(6L, 6L, 6L, 16L, 16L, 16L,27L, 27L, 27L, 41L, 41L, 41L, 55L, 55L, 55L, 70L, 70L, 92L, 92L,105L, 105L, 105L,
          105L, 105L, 105L, 105L, 105L, 119L, 119L, 119L,119L, 119L, 133L, 133L, 133L, 133L, 147L, 147L, 147L, 147L, 147L,147L,
          147L, 164L, 164L, 164L, 164L, 164L, 164L, 164L, 176L, 176L,176L, 176L, 176L, 176L, 176L, 189L, 189L, 189L, 189L,
          189L, 189L,189L, 204L, 204L, 204L, 204L, 204L, 204L, 216L, 216L, 216L)), .Names = c("CODE","longdist", "time"),
          class = "data.frame", row.names = c(43L,48L, 53L, 80L, 82L, 84L, 101L, 109L, 111L, 129L, 132L, 134L,153L, 158L,
          159L, 174L, 189L, 205L, 208L, 241L, 247L, 252L, 253L,258L, 260L, 262L, 265L, 272L, 281L, 283L, 287L, 291L, 296L,
          301L,306L, 311L, 323L, 329L, 331L, 337L, 338L, 346L, 349L, 354L, 359L,365L, 367L, 369L, 373L, 377L, 380L, 381L,
          388L, 393L, 398L, 399L,401L, 407L, 409L, 415L, 421L, 424L, 432L, 433L, 436L, 437L, 449L,451L, 455L, 458L, 464L, 471L, 486L))

f2<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=mydata,family=Gamma(link=log))
confint(f2$mer,method="profile")
confint(f2$mer,method="boot")
	
----------------------------------------------------------------------

Message: 1
Date: Tue, 1 Sep 2015 20:44:39 -0400
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] profile and/or bootstrapped CIs for GAMM
	random effects
Message-ID: <55E64677.5030905 at gmail.com>
Content-Type: text/plain; charset=windows-1252

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Is there any chance you could post a reproducible example ... ?

  (Out of curiosity, do you have strong reasons to use a Gamma/log-link rather than a log-Normal model?)

  Ben Bolker

On 15-09-01 06:51 PM, John Morrongiello wrote:
> Hi all I thought I'd re-post this message from last week as it may 
> have got lost in the weekend traffic:
> 
> I'm having trouble estimating CIs for random effects (i.e. CODE) from 
> a gamm4 model fit with a gamma distribution, My model is:
> 
> c1<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family
> =Gamma(link=log))
>
> 
confint(c1$mer,method="profile")
> ##this returns Error in mkMerMod(rho = environment(devfun), opt = opt, 
> reTrms = b$reTrms,  : unused argument (devFunOnly = TRUE)
> 
> confint(c1$mer,method="boot") ##this returns Error in 
> mkNewReTrms(object, newdata, compReForm, na.action = na.action,  :
> random effects specified in re.form that were not present in original 
> model Are these errors arising because I'm using a gamma distribution? 
> Is there another way to get the random effect CIs?
> 
> I can get random effect CIs for the following model: 
> c2<-gamm4((longdist)~s(time,k=4),random=~(1|CODE),data=catfish1,family
> =gaussian)
>
>  confint(c2$mer,method="profile")##works
> confint(c2$mer,method="boot")##same error message as above


--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au
W: morrongiellolab.com


From joaquin.aldabe at gmail.com  Wed Sep  2 20:45:39 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 2 Sep 2015 15:45:39 -0300
Subject: [R-sig-ME] glmm question
In-Reply-To: <CAMM93=L_c8c2EVz6f_Cp+O_KxBd7ycEvQh6W3vK+yVKQNehSqQ@mail.gmail.com>
References: <CAMM93=L_c8c2EVz6f_Cp+O_KxBd7ycEvQh6W3vK+yVKQNehSqQ@mail.gmail.com>
Message-ID: <CAMM93=L+zdi6kzgy5yKyKJmRLbzFBCKA7AfAiJCr5wpxhnreMg@mail.gmail.com>

Hello, I sent this message but not sure if you received. I really
appreciate any comment. Thanks a lot, Joaqu?n.

2015-09-01 17:58 GMT-03:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Hello, I?m trying to model de abundance of a grassland shorebird
> (Buff-breasted Sandpiper, BBSA) as a function of the abundance of American
> Golden Plover (AMGP) abundance, grass height and distance to the lagoon.
> I?m using area as an offset.
>
> I?ve tried a glmm with poisson errors and wanted you to see if residuals
> are fine (they don?t look great, but wanted to know if they area minimally
> acceptable). Also, I?m trying to understand two way interactions but I?m no
> sure how to proceed, and also would like to plot the interactions and
> unique variables effects (can you please provide suggestions?).
>
> I also have problems with the predict function. In the script are the
> notes. I?m attaching the data as well as the script with commentaries.
>
> Let me know if there?s some format problem with the files.
>
> Thank you very much in advanced.
>
> Joaqu?n.
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Sep  2 22:13:57 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 Sep 2015 16:13:57 -0400
Subject: [R-sig-ME] glmm question
In-Reply-To: <CAMM93=L+zdi6kzgy5yKyKJmRLbzFBCKA7AfAiJCr5wpxhnreMg@mail.gmail.com>
References: <CAMM93=L_c8c2EVz6f_Cp+O_KxBd7ycEvQh6W3vK+yVKQNehSqQ@mail.gmail.com>
	<CAMM93=L+zdi6kzgy5yKyKJmRLbzFBCKA7AfAiJCr5wpxhnreMg@mail.gmail.com>
Message-ID: <55E75885.4040500@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-09-02 02:45 PM, Joaqu?n Aldabe wrote:
> Hello, I sent this message but not sure if you received. I really 
> appreciate any comment. Thanks a lot, Joaqu?n.

  You should generally be subscribed to the list if you're going to
post there, but you might have your options set so that you don't
receive copies of mail you sent.  You can also check the archives at

https://stat.ethz.ch/pipermail/r-sig-mixed-models/

or the Gmane interface to the mailing list at

http://news.gmane.org/gmane.comp.lang.r.lme4.devel

(I prefer the latter, but there is sometimes a slight delay).  There's
also a Nabble interface, but it tends to send things to the list in a
slightly obnoxious way, so I would avoid it.

   If you know that your message got through (by looking in one of the
places above) but no-one seems to answering, you can (1) send a
follow-up after a few days politely asking for more attention; (2) try
to figure out why your question didn't get answered.  It might (a)
have slipped through the cracks (in which case go to #1), or it might
be too general, or too vague, or too hard, for people to answer.  It
never hurts to try to make your question narrower, or more precise, or
explain the context better, or provide a reproducible example
<http://tinyurl.com/reproducible-000> (I see that you did include data
and scripts, but these sometimes get stripped by the mailing list.
Also, people are more likely to respond to a *minimal* example, e.g. a
message that says "there's something wrong in these 5 lines of code"
rather than "my script is attached, please see my questions therein".)
 (Asking good questions is hard; so is finding the time to answer them.)

  Ben Bolker



> 2015-09-01 17:58 GMT-03:00 Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com>:
> 
>> Hello, I?m trying to model de abundance of a grassland shorebird 
>> (Buff-breasted Sandpiper, BBSA) as a function of the abundance of
>> American Golden Plover (AMGP) abundance, grass height and
>> distance to the lagoon. I?m using area as an offset.
>> 
>> I?ve tried a glmm with poisson errors and wanted you to see if
>> residuals are fine (they don?t look great, but wanted to know if
>> they area minimally acceptable). Also, I?m trying to understand
>> two way interactions but I?m no sure how to proceed, and also
>> would like to plot the interactions and unique variables effects
>> (can you please provide suggestions?).
>> 
>> I also have problems with the predict function. In the script are
>> the notes. I?m attaching the data as well as the script with
>> commentaries.
>> 
>> Let me know if there?s some format problem with the files.
>> 
>> Thank you very much in advanced.
>> 
>> Joaqu?n.
>> 
>> -- *Joaqu?n Aldabe*
>> 
>> *Grupo Biodiversidad, Ambiente y Sociedad* Centro Universitario
>> de la Regi?n Este, Universidad de la Rep?blica Ruta 15 (y Ruta
>> 9), Km 28.500, Departamento de Rocha
>> 
>> *Departamento de Conservaci?n* Aves Uruguay BirdLife
>> International Canelones 1164, Montevideo
>> 
>> https://sites.google.com/site/joaquin.aldabe 
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> 
>> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJV51iFAAoJEOCV5YRblxUH8+kH/2Fk8defPqEgHK2KOHphsULV
/+RGaND/fXsS+gw3zWFQez1iQ/RWWIyI7EzfMjUNO51x0Av9J5uINTadA1zkoC16
gwmANKBaZ6vsPuh1yJPD/43uwVWAH+Scb0tpLuIoUp4ERzH8BhFKLfrTLSXC0hqi
BDdPF0FyklEHXMh7ZNS83N168S811aIe7V8ZUsUG9v2T/Na7To4Pwx/z7NsKkVKb
bKIiPGTUI1XSqTeLClcoaxWDXdlwCKQ7b1zNd4EGma4ntPvYU+FQFhzw2Y9NH3m9
pyPLySHAu3huloIaj/7477mYzrLOgJ32VZkDAL95skT4GYPullEK2H50f9mgSWU=
=dCFa
-----END PGP SIGNATURE-----


From hughes.dupond at gmx.de  Wed Sep  2 23:08:36 2015
From: hughes.dupond at gmx.de (Lionel)
Date: Wed, 02 Sep 2015 23:08:36 +0200
Subject: [R-sig-ME] glmm question
In-Reply-To: <CAMM93=L+zdi6kzgy5yKyKJmRLbzFBCKA7AfAiJCr5wpxhnreMg@mail.gmail.com>
References: <CAMM93=L_c8c2EVz6f_Cp+O_KxBd7ycEvQh6W3vK+yVKQNehSqQ@mail.gmail.com>
	<CAMM93=L+zdi6kzgy5yKyKJmRLbzFBCKA7AfAiJCr5wpxhnreMg@mail.gmail.com>
Message-ID: <55E76554.3050200@gmx.de>

Dear Joaquin,

I did not look in your script but here are my thoughts on your question:
- concerning residuals, the choice of accepting a model as fitting to 
the data or not based on residuals plot (ie residuals vs fitted value) 
is at the discretion of the analyst/scientist. Sometime when I am unsure 
I simulate data from the model (ie simulate for merMod object), fit 
these simulated data to the model (ie function refit for merMod) and see 
if the resulting residual plot differ from the one I got from my 
empirical data. If yes my model is wrong, otherwise the model is not so bad.

- Two-way interaction between categorical variables or between a 
categorical and continuous variable are rather easy to understand, it 
gets trickier for interaction between two continuous variables, I wrote 
an article on this a while back: http://rpubs.com/hughes/15353, this was 
for lm but for glmm the interpretation would be the same (except that we 
have a link function, log in the case of poisson, between the observed 
data and the modeled response). There are certainly many more resource 
out there, I found the UCLA pages nicely written: 
http://www.ats.ucla.edu/stat/r/

Yours,
Lionel

On 02/09/2015 20:45, Joaqu?n Aldabe wrote:
> Hello, I sent this message but not sure if you received. I really
> appreciate any comment. Thanks a lot, Joaqu?n.
>
> 2015-09-01 17:58 GMT-03:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>
>> Hello, I?m trying to model de abundance of a grassland shorebird
>> (Buff-breasted Sandpiper, BBSA) as a function of the abundance of American
>> Golden Plover (AMGP) abundance, grass height and distance to the lagoon.
>> I?m using area as an offset.
>>
>> I?ve tried a glmm with poisson errors and wanted you to see if residuals
>> are fine (they don?t look great, but wanted to know if they area minimally
>> acceptable). Also, I?m trying to understand two way interactions but I?m no
>> sure how to proceed, and also would like to plot the interactions and
>> unique variables effects (can you please provide suggestions?).
>>
>> I also have problems with the predict function. In the script are the
>> notes. I?m attaching the data as well as the script with commentaries.
>>
>> Let me know if there?s some format problem with the files.
>>
>> Thank you very much in advanced.
>>
>> Joaqu?n.
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>
>>
>


From bbolker at gmail.com  Thu Sep  3 22:14:44 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 Sep 2015 20:14:44 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?profile_and/or_bootstrapped_CIs_for_GAMM_ran?=
	=?utf-8?q?dom=09effects?=
References: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F32D0@000s-ex-mbx-qs1.unimelb.edu.au>
Message-ID: <loom.20150903T220537-342@post.gmane.org>

John Morrongiello <john.morrongiello at ...> writes:

[snip snip snip]

> In regards to the Gamma/log-link model: I decided to go down this
> path as my response variable is distance from 'home' (longdist)
> which is strictly positive and continuous. I realise I could
> log-transform the data, but thought it good to just use an
> appropriate distribution. I'm happy to be convinced to go down the
> transformation path as it would help with other response variables
> that are continuous but include zeros (here I've had to split the
> analysis into two steps: 1) a binomial GLMM for zero or >0 distance;
> 2) a gamma GLMM for all distances >0)

  I think assuming log-normality (which is essentially what you're
doing when you log-transform and fit a LMM -- the only thing you have
to be careful about is comparing (log)likelihoods with models on
non-transformed data, since you have changed the scale of the data) is
not on average any better or worse (more or less correct) than
assuming a Gamma distribution.  There is some work on comparisons/
reciprocal robustness (referenced in McCullagh and Nelder, I don't
remember the ref. right now).

  Unfortunately transformation won't help you with the zeros in
the response, as they will be 'illegal' for the log-transformation
as for the Gamma likelihood.  You'll still have to do the two-stage
model or something else a little bit fancier than a plain mixed model.


From daniel at earthoceanspace.com  Tue Sep  8 09:19:21 2015
From: daniel at earthoceanspace.com (Daniel Harrison)
Date: Tue, 08 Sep 2015 17:19:21 +1000
Subject: [R-sig-ME] problems with glmmadmb
In-Reply-To: <<53E50A02.9070508@gmail.com>>
Message-ID: <D214C919.1CF31%daniel@earthoceanspace.com>

Hey there,

I am having some problems with glmmadmb.

I am predicting  a series of glmm with gamma distribution.

Glmmadmb converges on all models, however the pearson residuals from every
model come back as all ?NA?.

In glmmer several of the models fail to converge.

Is this expected behaviour with a gamma distribution?

Regards,

Daniel Harrison
PhD Candidate
University of Sydney



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Sep  9 01:29:46 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 Sep 2015 19:29:46 -0400
Subject: [R-sig-ME] problems with glmmadmb
In-Reply-To: <D214C919.1CF31%daniel@earthoceanspace.com>
References: <D214C919.1CF31%daniel@earthoceanspace.com>
Message-ID: <CABghstSkv2oOanm75JPsOBDHJpGA6rZuw_zVTDR2FmjbLfQn=Q@mail.gmail.com>

No, not really.

* Gamma models are generally less well-tested.  There might be
something wrong with the residuals calculation; I can take a look
(more likely to look if you send a reproducible example).
* As detailed in ?convergence in the lme4 documentation, the
convergence tests give a lot of false positives.  If the estimated
coefficients & log-likelihoods match between glmmadmb and glmer I
think it's OK to trust them.


On Tue, Sep 8, 2015 at 3:19 AM, Daniel Harrison
<daniel at earthoceanspace.com> wrote:
> Hey there,
>
> I am having some problems with glmmadmb.
>
> I am predicting  a series of glmm with gamma distribution.
>
> Glmmadmb converges on all models, however the pearson residuals from every
> model come back as all ?NA?.
>
> In glmmer several of the models fail to converge.
>
> Is this expected behaviour with a gamma distribution?
>
> Regards,
>
> Daniel Harrison
> PhD Candidate
> University of Sydney
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From chirleu at gmail.com  Thu Sep 10 10:47:28 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 10 Sep 2015 10:47:28 +0200
Subject: [R-sig-ME] non-linear slope in random regression model
Message-ID: <CALC46t9=CRmx1RU_dOzkYpwcXuX+wypwPB9xvcDX+GAYmJ-=LA@mail.gmail.com>

Hello,
I'm fitting some random regression models to investigate variation over
time of a response trait.
The time variable is "month", and by fitting a random regression model I
want to investigate variation in plasticity across individuals, i.e.,
differences in the "slope" between trait and time across individuals.

The relationship between the response trait and month is non-linear.
Basically, it describes a seasonal cycle.

I have considered two model candidates:

*Model 1*: fitting a polynomial of month in the fixed effects part to
describe the non-linearity and get the population mean effect of month, and
then a random slope using again the polynomial for month, to ge the
individual differences.

trait~poly(month,3),random=~poly(month,3)|ID


*Model 2*: fitting a polynomial of month in the fixed effect part to
describe the non-linearity, and then the individual-specific deviation from
the fixed-effect means is modelled as a funtion of month (linear), assuming
that the non-linearity is already accounted for with the fixed effect.

trait~poly(month,3),random=~month|ID

*My question is*:
Is it neccesary to include the non-linearity in the random part if it was
already included in the fixed-effects part?

The idea of fitting model 2 comes from the following reference (page 488):

Dingemanse, N. J., Barber, I., Wright, J., & Brommer, J. E. (2012).
Quantitative genetics of behavioural reaction norms: genetic correlations
between personality and behavioural plasticity vary across stickleback
populations.*Journal of evolutionary biology*, *25*(3), 485-496.


Thank you.

David

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Sep 10 11:08:39 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 10 Sep 2015 11:08:39 +0200
Subject: [R-sig-ME] non-linear slope in random regression model
In-Reply-To: <CALC46t9=CRmx1RU_dOzkYpwcXuX+wypwPB9xvcDX+GAYmJ-=LA@mail.gmail.com>
References: <CALC46t9=CRmx1RU_dOzkYpwcXuX+wypwPB9xvcDX+GAYmJ-=LA@mail.gmail.com>
Message-ID: <CAJuCY5xSmm5i5sW2mXPGsx2Qi9Z8=-_yTLK7uvqcVjX59iaRBg@mail.gmail.com>

Dear David,

Polynomials are technically still a linear model since they result is in
linear combination of variable.

The only straightforward answer to you question is: it depends on the data.
If you have plenty data, then I'd go for model 1. If the data doesn't
require a second and 3th order polynomial, then their random effect
variance will be very small. And the model will be reduced to model 2.

Note than plenty data means a lot of different id AND a lot of months per
id. If you have only one year of data then random=~poly(month, 1)|ID is
about as complex as you can go.

A 3th order polynomial seems a bit odd to me to model seasonality. I'd
rather expect an even order. You might want to consider fitting month as a
factor in the fixed effects. Then you model the seasonality without
assumptions on the pattern.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-09-10 10:47 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:

> Hello,
> I'm fitting some random regression models to investigate variation over
> time of a response trait.
> The time variable is "month", and by fitting a random regression model I
> want to investigate variation in plasticity across individuals, i.e.,
> differences in the "slope" between trait and time across individuals.
>
> The relationship between the response trait and month is non-linear.
> Basically, it describes a seasonal cycle.
>
> I have considered two model candidates:
>
> *Model 1*: fitting a polynomial of month in the fixed effects part to
> describe the non-linearity and get the population mean effect of month, and
> then a random slope using again the polynomial for month, to ge the
> individual differences.
>
> trait~poly(month,3),random=~poly(month,3)|ID
>
>
> *Model 2*: fitting a polynomial of month in the fixed effect part to
> describe the non-linearity, and then the individual-specific deviation from
> the fixed-effect means is modelled as a funtion of month (linear), assuming
> that the non-linearity is already accounted for with the fixed effect.
>
> trait~poly(month,3),random=~month|ID
>
> *My question is*:
> Is it neccesary to include the non-linearity in the random part if it was
> already included in the fixed-effects part?
>
> The idea of fitting model 2 comes from the following reference (page 488):
>
> Dingemanse, N. J., Barber, I., Wright, J., & Brommer, J. E. (2012).
> Quantitative genetics of behavioural reaction norms: genetic correlations
> between personality and behavioural plasticity vary across stickleback
> populations.*Journal of evolutionary biology*, *25*(3), 485-496.
>
>
> Thank you.
>
> David
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Thu Sep 10 11:33:24 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 10 Sep 2015 11:33:24 +0200
Subject: [R-sig-ME] non-linear slope in random regression model
In-Reply-To: <CAJuCY5xSmm5i5sW2mXPGsx2Qi9Z8=-_yTLK7uvqcVjX59iaRBg@mail.gmail.com>
References: <CALC46t9=CRmx1RU_dOzkYpwcXuX+wypwPB9xvcDX+GAYmJ-=LA@mail.gmail.com>
	<CAJuCY5xSmm5i5sW2mXPGsx2Qi9Z8=-_yTLK7uvqcVjX59iaRBg@mail.gmail.com>
Message-ID: <CALC46t9Sjs7Vi=_ozvhLyFZdkB82jHuncXmF9EWS5UCrhk5-Ow@mail.gmail.com>

Thanks Thierry and Alastair.

I do have a lot of IDs (~290) but not so many month per ID (a mean of 10).

So from your comments I conclude that if I run model 2, or as suggested by
Thierry this equivalent model, in which month is a factor in the fixed
part...

trait~as.factor(month),random=~month|ID

...and I get significant between individual differences in the slope of the
random effect, the conclusion is that individuals differ in their
non-linear (as described by factor(month) or poly(month,3) in the fixed
part) relationship between trait and month. Right?

If this is correct then I would not upgrade to a higher order random slope
to keep things simple!

Best,

David




2015-09-10 11:08 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear David,
>
> Polynomials are technically still a linear model since they result is in
> linear combination of variable.
>
> The only straightforward answer to you question is: it depends on the
> data. If you have plenty data, then I'd go for model 1. If the data doesn't
> require a second and 3th order polynomial, then their random effect
> variance will be very small. And the model will be reduced to model 2.
>
> Note than plenty data means a lot of different id AND a lot of months per
> id. If you have only one year of data then random=~poly(month, 1)|ID is
> about as complex as you can go.
>
> A 3th order polynomial seems a bit odd to me to model seasonality. I'd
> rather expect an even order. You might want to consider fitting month as a
> factor in the fixed effects. Then you model the seasonality without
> assumptions on the pattern.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-09-10 10:47 GMT+02:00 David Villegas R?os <chirleu at gmail.com>:
>
>> Hello,
>> I'm fitting some random regression models to investigate variation over
>> time of a response trait.
>> The time variable is "month", and by fitting a random regression model I
>> want to investigate variation in plasticity across individuals, i.e.,
>> differences in the "slope" between trait and time across individuals.
>>
>> The relationship between the response trait and month is non-linear.
>> Basically, it describes a seasonal cycle.
>>
>> I have considered two model candidates:
>>
>> *Model 1*: fitting a polynomial of month in the fixed effects part to
>> describe the non-linearity and get the population mean effect of month,
>> and
>> then a random slope using again the polynomial for month, to ge the
>> individual differences.
>>
>> trait~poly(month,3),random=~poly(month,3)|ID
>>
>>
>> *Model 2*: fitting a polynomial of month in the fixed effect part to
>> describe the non-linearity, and then the individual-specific deviation
>> from
>> the fixed-effect means is modelled as a funtion of month (linear),
>> assuming
>> that the non-linearity is already accounted for with the fixed effect.
>>
>> trait~poly(month,3),random=~month|ID
>>
>> *My question is*:
>> Is it neccesary to include the non-linearity in the random part if it was
>> already included in the fixed-effects part?
>>
>> The idea of fitting model 2 comes from the following reference (page 488):
>>
>> Dingemanse, N. J., Barber, I., Wright, J., & Brommer, J. E. (2012).
>> Quantitative genetics of behavioural reaction norms: genetic correlations
>> between personality and behavioural plasticity vary across stickleback
>> populations.*Journal of evolutionary biology*, *25*(3), 485-496.
>>
>>
>> Thank you.
>>
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From A.Wilson at exeter.ac.uk  Thu Sep 10 11:51:37 2015
From: A.Wilson at exeter.ac.uk (Wilson, Alastair)
Date: Thu, 10 Sep 2015 09:51:37 +0000
Subject: [R-sig-ME] non-linear slope in random regression model
In-Reply-To: <CALC46t9Sjs7Vi=_ozvhLyFZdkB82jHuncXmF9EWS5UCrhk5-Ow@mail.gmail.com>
References: <CALC46t9=CRmx1RU_dOzkYpwcXuX+wypwPB9xvcDX+GAYmJ-=LA@mail.gmail.com>
	<CAJuCY5xSmm5i5sW2mXPGsx2Qi9Z8=-_yTLK7uvqcVjX59iaRBg@mail.gmail.com>
	<CALC46t9Sjs7Vi=_ozvhLyFZdkB82jHuncXmF9EWS5UCrhk5-Ow@mail.gmail.com>
Message-ID: <AMSPR03MB3926F7C1117A865B3258B38B2510@AMSPR03MB392.eurprd03.prod.outlook.com>

Hi David,

Replying off list as last message has been held for moderation  (I suspect uni has changed e-mail aliases or something) and this is not really an e-mail about R anyway!0. Fitting month as a factor makes a lot of sense to me for reasons Thierry gave. To reiterate though your random effect model is something you need to decide. Simplistically, imagine you fixed effects has ?taken out? all monthly variation in the mean. The question now is, do you want to model individual reaction norms as constant, a straight line, or something curvy (in which case polynomials are not a bad place to start).

Dingemanse et al have suggested using higher order polynomials to look at behavioural reaction norms ? something that has long been done in quant gen for longitudinal data (e.g. growth, milk yields with age etc). In evo ecol there is a long tradition of stickling with straight line reaction norms, but I think this is largely for semantic convenience, not necessarily because they fit people?s data brilliantly. If you centre the X axis then you can interpret the elevation of an individuals reaction norm as its phenotype in an average environment, while the slope can be used as its ?plasticity?. If you add a quadratic term people don?t know what to call it! Of course what it really means is that the ?plasticity? slope of the reaction norm, itself changes according to where you are on the X axis.

Not sure if that helps. Whatever you decide you should make sure you include covariance between slopes and elevations in your model (and with high order terms if you include them), to do otherwise forces very strong (and unrealistic) assumptions on the reaction norms that can distort things a lot. You should also consider whether it is appropriate to assume a homogeneous residual variance across all your months as violations of this can generate spurious support for IxE (i.e. among-individual variance in reaction norm slopes).

Best

A

From: David Villegas R?os [mailto:chirleu at gmail.com]
Sent: 10 September 2015 10:33
To: Thierry Onkelinx; Wilson, Alastair
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] non-linear slope in random regression model

Thanks Thierry and Alastair.

I do have a lot of IDs (~290) but not so many month per ID (a mean of 10).

So from your comments I conclude that if I run model 2, or as suggested by Thierry this equivalent model, in which month is a factor in the fixed part...

trait~as.factor(month),random=~month|ID

...and I get significant between individual differences in the slope of the random effect, the conclusion is that individuals differ in their non-linear (as described by factor(month) or poly(month,3) in the fixed part) relationship between trait and month. Right?

If this is correct then I would not upgrade to a higher order random slope to keep things simple!

Best,

David




2015-09-10 11:08 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>:
Dear David,

Polynomials are technically still a linear model since they result is in linear combination of variable.

The only straightforward answer to you question is: it depends on the data. If you have plenty data, then I'd go for model 1. If the data doesn't require a second and 3th order polynomial, then their random effect variance will be very small. And the model will be reduced to model 2.

Note than plenty data means a lot of different id AND a lot of months per id. If you have only one year of data then random=~poly(month, 1)|ID is about as complex as you can go.

A 3th order polynomial seems a bit odd to me to model seasonality. I'd rather expect an even order. You might want to consider fitting month as a factor in the fixed effects. Then you model the seasonality without assumptions on the pattern.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-09-10 10:47 GMT+02:00 David Villegas R?os <chirleu at gmail.com<mailto:chirleu at gmail.com>>:
Hello,
I'm fitting some random regression models to investigate variation over
time of a response trait.
The time variable is "month", and by fitting a random regression model I
want to investigate variation in plasticity across individuals, i.e.,
differences in the "slope" between trait and time across individuals.

The relationship between the response trait and month is non-linear.
Basically, it describes a seasonal cycle.

I have considered two model candidates:

*Model 1*: fitting a polynomial of month in the fixed effects part to
describe the non-linearity and get the population mean effect of month, and
then a random slope using again the polynomial for month, to ge the
individual differences.

trait~poly(month,3),random=~poly(month,3)|ID


*Model 2*: fitting a polynomial of month in the fixed effect part to
describe the non-linearity, and then the individual-specific deviation from
the fixed-effect means is modelled as a funtion of month (linear), assuming
that the non-linearity is already accounted for with the fixed effect.

trait~poly(month,3),random=~month|ID

*My question is*:
Is it neccesary to include the non-linearity in the random part if it was
already included in the fixed-effects part?

The idea of fitting model 2 comes from the following reference (page 488):

Dingemanse, N. J., Barber, I., Wright, J., & Brommer, J. E. (2012).
Quantitative genetics of behavioural reaction norms: genetic correlations
between personality and behavioural plasticity vary across stickleback
populations.*Journal of evolutionary biology*, *25*(3), 485-496.


Thank you.

David

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From A.Wilson at exeter.ac.uk  Thu Sep 10 11:05:03 2015
From: A.Wilson at exeter.ac.uk (Wilson, Alastair)
Date: Thu, 10 Sep 2015 09:05:03 +0000
Subject: [R-sig-ME] non-linear slope in random regression model
In-Reply-To: <CALC46t9=CRmx1RU_dOzkYpwcXuX+wypwPB9xvcDX+GAYmJ-=LA@mail.gmail.com>
References: <CALC46t9=CRmx1RU_dOzkYpwcXuX+wypwPB9xvcDX+GAYmJ-=LA@mail.gmail.com>
Message-ID: <AMSPR03MB392F0A3C8B41CD9623630DBB2510@AMSPR03MB392.eurprd03.prod.outlook.com>

Hi David, 

It is not necessary - it may or may not be useful/interesting depending on your questions and structure of your data. In this sort of random regression model you are using your fixed effect structure to account for the relationship between your X variable (here time) and the response mean. If a 3rd order polynomial does a good job then great! In the random effect structure you are modelling the individual level effects (i.e. deviations from the fixed effect mean attributable to individual identity). These could be constant (0 order), a linear (1st order) function of X or something else (e.g. a quadratic, or indeed some other type of function of X). 

There is no necessary connection between the functional form you use in the fixed effects and that in the random effects. For plasticity studies a linear regression is common in the random effect but higher orders could be used (and may prove better fits).

For more on these sorts of models (they have some issues as well as some strength!) I would suggest looking in the animal breeding/quant gen literature, for instance work by Karin Meyer and Mark Kirkpatrick here

http://rstb.royalsocietypublishing.org/content/360/1459/1443

Alastair Wilson

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of David Villegas R?os
Sent: 10 September 2015 09:47
To: r-sig-mixed-models
Subject: [R-sig-ME] non-linear slope in random regression model

Hello,
I'm fitting some random regression models to investigate variation over time of a response trait.
The time variable is "month", and by fitting a random regression model I want to investigate variation in plasticity across individuals, i.e., differences in the "slope" between trait and time across individuals.

The relationship between the response trait and month is non-linear.
Basically, it describes a seasonal cycle.

I have considered two model candidates:

*Model 1*: fitting a polynomial of month in the fixed effects part to describe the non-linearity and get the population mean effect of month, and then a random slope using again the polynomial for month, to ge the individual differences.

trait~poly(month,3),random=~poly(month,3)|ID


*Model 2*: fitting a polynomial of month in the fixed effect part to describe the non-linearity, and then the individual-specific deviation from the fixed-effect means is modelled as a funtion of month (linear), assuming that the non-linearity is already accounted for with the fixed effect.

trait~poly(month,3),random=~month|ID

*My question is*:
Is it neccesary to include the non-linearity in the random part if it was already included in the fixed-effects part?

The idea of fitting model 2 comes from the following reference (page 488):

Dingemanse, N. J., Barber, I., Wright, J., & Brommer, J. E. (2012).
Quantitative genetics of behavioural reaction norms: genetic correlations between personality and behavioural plasticity vary across stickleback populations.*Journal of evolutionary biology*, *25*(3), 485-496.


Thank you.

David

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From antonellocanu1982 at gmail.com  Thu Sep 10 17:33:19 2015
From: antonellocanu1982 at gmail.com (Antonello Canu)
Date: Thu, 10 Sep 2015 17:33:19 +0200
Subject: [R-sig-ME] possible collinearity between random and fixed effects
	in a linear mixed model
Message-ID: <002b01d0ebde$05d07900$11716b00$@com>

Dear all,

Recently I have submitted a manuscript in which I used a linear mixed model
to describe the variation in the date of reproduction of female wild boars.
For each female (n=350, culled by hunters in 27 relatively small [nearly 200
ha] hunting areas in 8 hunting seasons), we had analyzed the uterus and we
had an estimate of the age of fetuses, therefore we obtained the estimate of
the conception date.

Since I was especially interested in the study of the synchrony of
reproduction among females belonging to the same social group (a phenomenon
observed in the past for wild boar female groups and many other mammals), I
fitted a model with date of reproduction as dependent variable, and groups
of females culled in both the same "hunting area" + the same hunting season
as random factor (i.e., females with a not negligible prob. to belong to the
same social group...therefore my random term is a rough proxy of social
group).

As independent variables, I included in my models many environmental and
individual variables.

I tested for the inclusion of the random term (full model with the random
term vs. full model without it), that was extremely significant. Then I
performed model selection, selecting some of the environmental factors.

The problem: Most of my environmental data are "poor". For example, for the
rainfall and seed production I have a unique value for each hunting season.
For other variables such as tree coverage I have a unique data for all the
observations belonging to the same "hunting area", etc. Therefore, I have
n=350 sows but only 8 different values for rainfall, only 27 values for tree
coverage etc.

I had included the "poor" environmental variables (and some of them were
selected) because a first version of the ms was rejected by a journal
because of the lack of environmental data, known to be able to influence the
reproduction.

Anyway: in this new submission the referee told me that I cannot use both
the random term and the fixed effect because:

<<some of the fixed factors are equivalent to the random term year (e.g
rainfall, temperatures, seed crop) or hunting ground (habitat, tree species
abundance). This is not correct because environmental and inter-annual
heterogeneity (which I guess the authors are interested in) is accounted for
by random factors. So one can either use hunting ground- and year-base
predictors as fixed terms to study their effects or as a random terms, to
eliminate their effects. I assume that the authors prefer the former.>>

 

The referee in few words suggested me to drop to the random term. However,
the random term explains a huge amount of variance and is in perfect
agreement with the biological knowledge about wild boar reproduction (i.e.,
synchrony of reproduction among females near to each other). I think it is a
shame to drop to it, and I want to be sure that I can't use both the
environmental data and the random term for the abovementioned reasons (due
to the fact that a certain amount of groups have the same values for the
environmental variables). Furthermore, it is not only a matter of
"dropping". I actually think that results without the random term would be
extremely misleading. Since it seems that there IS a "social group effect":
if I ignored it, systematic variation would end up in the residuals leading
to potentially biased inference.

If the referee's suggestion is questionable, I want to try to discuss this
aspect, and possibly to keep my model. My lack of statistical knowledge,
anyway, make me unsure. Someone can suggest anything?

Thanks in advance,

Antonio

 


	[[alternative HTML version deleted]]


From orzack at freshpond.org  Thu Sep 10 17:02:59 2015
From: orzack at freshpond.org (Steven Orzack)
Date: Thu, 10 Sep 2015 11:02:59 -0400
Subject: [R-sig-ME] Testing a trend across possibly non-independent estimates
Message-ID: <55F19BA3.4060009@freshpond.org>

A colleague and I have a longitudinal dataset in which records are 
organized as follows

individual_ID_1        age        cohort    health_at_age
individual_ID_1        age+1    cohort    health_at_age+1
individual_ID_2        age        cohort    health_at_age
individual_ID_2        age+1    cohort    health_at_age+1

etc.

call this longitudinal.df

There are a few thousand individuals, twenty or so cohorts, and up to 15 
or so health scores
(each at a different age) for a given individual.

Health is scored as present/absent (1/0).

We wish to assess a hypothesis about the trend across ages of how health 
at a given age changes
over cohorts.

In particular, one hypothesis is that, say, the slope parameter for a 
regression (cohort is
predictor variable, health is the response variable) is negative for 
younger ages and is positive
for older ages.

Note that there are two ways one could derive a slope estimate for a 
given age.

First way: for a given age defined by a logical variable sel, one can 
use a GLM

glm(health ~ 1 + cohort, family = binomial, data = longitudinal.df, 
subset = sel)

Repeat this for each age to derive the age-specific estimate to be added 
to the ensemble of slope
estimates.

a GLM works because an individual contributes only one health record for 
a given age-specific GLM.

Second way: one could use a GLMM

glmer(health ~ 1 + Cohort * as.factor(Age) + (cohort|individual_ID), 
data = longitudinal.df,
family = binomial)

The GLMM model generates age-specific intercepts and slopes.

As it happens, this GLMM model does have substantially more support 
(AIC) than does the GLMM model
without age as a factor (even though it has many more parameters). 
Hence, it appears that trends
over cohorts differs across ages. Of course, this only means that there 
are differences among ages.
By itself, it says nothing about how the trends changes over ages.

I welcome opinions as to the merits of the GLM approach and the GLMM 
approach. I regard the latter
as more appropriate and statistically proper.

The main question is:

Given an ensemble of slope estimates (derived by GLM or by GLMM) and 
that the data underlying any
one slope estimate cannot be assumed to be independent of the data 
underlying the other slope
estimates (because most individuals contribute a health record for 
multiple ages),

How does one statistically assess whether there is an increasing trend 
across ages of how
health changes over cohorts (as measured by the sign and magnitude of 
the slope for a given age)?.

If the data underlying any one slope estimate were known to be 
independent of the data underlying
any other estimate, the assessment would be straight forward (using a 
correlation or regression).

A related question stems from my discomfort about only using the slope 
estimate to assess the trend
across cohorts for a given age. Is there a more "synthetic" way to do 
this, one that is based upon
the trend determined by all of the regression coefficients (intercept, 
slope, etc.)?

note that in this analysis, random effects are nuisance parameters. 
Accounting
for them is good practice and important but I doubt that any association 
between measures for a
given individual influences the biological bottom line of the analysis. 
Nonetheless, I do not want
to whistle past the graveyard.....

Many thanks in advance for suggestions!

-- 
Steven Orzack


From john.morrongiello at unimelb.edu.au  Fri Sep 11 01:28:20 2015
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Thu, 10 Sep 2015 23:28:20 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 105, Issue 8
In-Reply-To: <mailman.3561.1441899757.3797.r-sig-mixed-models@r-project.org>
References: <mailman.3561.1441899757.3797.r-sig-mixed-models@r-project.org>
Message-ID: <DE0D2370A8DD1A44ABCC0AF0597EC2C9137F42E9@000s-ex-mbx-qs1.unimelb.edu.au>

Hi David
Just thinking, given you say month could have a seasonally cyclical effect (i.e. December should be very similar to January) another, option to model the mean month effect with a cyclic cubic regression spline smoother in gamm4. A smoother in this sense deals a bit with Thierry's point of not assuming a symmetrical pattern for month, you are estimating a lot less parameters in the model, and importantly you a not left with potential hard to explain large 'steps' in predicted monthly values at the end of the year.

In your case, this might look like:
library(gamm4)
gamm4(trait ~s(month, bs='cc',k=4),random=~1|ID,data)## play around with k yourself to set the desired level of smoother 'wriggliness'

Where this leaves the random regression part of your question, I'm not sure. You can fit a random month slope for month in the above model, but I'm yet to find a good interpretation of its meaning. 

##example data (sorry just had poisson code at hand, concept similar with normal)
x <- runif(100)#imagine these are your months
fac <- sample(1:20,100,replace=TRUE)
eta <- x^2*3 + fac/20; fac <- as.factor(fac)
y <- rpois(100,exp(eta))

## fit model with just cyclic smoother for x
M1 <- gamm4(y~s(x,bs='cc'),random=~(1|fac))
plot(M1$gam)## ensures max(x) cycles to min(x) (i.e. December into January)

## fit model with cyclic smoother for x and potentially random slope for x?
M2 <- gamm4(y~s(x,bs='cc'),random=~(x|fac))
plot(M2$gam)

In this fictious case, the random x slopes result in a better model fit
AIC(M1$mer,M2$mer)

I guess my question would be: how do you interpret the x's (potential random slopes) below? 
ranef(M2$mer)$fac

Can they be interpreted as reaction norms, and ultimately are they performing a similar role to a polynomial random slope in David's original example? Perhaps naievely, if x is positive, is it an overall increase in smoother 'wriggliness' i.e. increase in edf (opposite for negative)? Or is it something else? Would someone know how to visualise these random slopes dependant on the mean smoother so I can get a feel for what is going on?

Cheers
John

--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au
W: morrongiellolab.com


----------------------------------------------------------------------

Message: 1
Date: Thu, 10 Sep 2015 09:51:37 +0000
From: "Wilson, Alastair" <A.Wilson at exeter.ac.uk>
To: David Villegas R?os <chirleu at gmail.com>, "Thierry	Onkelinx"
	<thierry.onkelinx at inbo.be>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] non-linear slope in random regression model
Message-ID:
	<AMSPR03MB3926F7C1117A865B3258B38B2510 at AMSPR03MB392.eurprd03.prod.outlook.com>
	
Content-Type: text/plain; charset="UTF-8"

Hi David,

Replying off list as last message has been held for moderation  (I suspect uni has changed e-mail aliases or something) and this is not really an e-mail about R anyway!0. Fitting month as a factor makes a lot of sense to me for reasons Thierry gave. To reiterate though your random effect model is something you need to decide. Simplistically, imagine you fixed effects has ?taken out? all monthly variation in the mean. The question now is, do you want to model individual reaction norms as constant, a straight line, or something curvy (in which case polynomials are not a bad place to start).

Dingemanse et al have suggested using higher order polynomials to look at behavioural reaction norms ? something that has long been done in quant gen for longitudinal data (e.g. growth, milk yields with age etc). In evo ecol there is a long tradition of stickling with straight line reaction norms, but I think this is largely for semantic convenience, not necessarily because they fit people?s data brilliantly. If you centre the X axis then you can interpret the elevation of an individuals reaction norm as its phenotype in an average environment, while the slope can be used as its ?plasticity?. If you add a quadratic term people don?t know what to call it! Of course what it really means is that the ?plasticity? slope of the reaction norm, itself changes according to where you are on the X axis.

Not sure if that helps. Whatever you decide you should make sure you include covariance between slopes and elevations in your model (and with high order terms if you include them), to do otherwise forces very strong (and unrealistic) assumptions on the reaction norms that can distort things a lot. You should also consider whether it is appropriate to assume a homogeneous residual variance across all your months as violations of this can generate spurious support for IxE (i.e. among-individual variance in reaction norm slopes).

Best

A

From: David Villegas R?os [mailto:chirleu at gmail.com]
Sent: 10 September 2015 10:33
To: Thierry Onkelinx; Wilson, Alastair
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] non-linear slope in random regression model

Thanks Thierry and Alastair.

I do have a lot of IDs (~290) but not so many month per ID (a mean of 10).

So from your comments I conclude that if I run model 2, or as suggested by Thierry this equivalent model, in which month is a factor in the fixed part...

trait~as.factor(month),random=~month|ID

...and I get significant between individual differences in the slope of the random effect, the conclusion is that individuals differ in their non-linear (as described by factor(month) or poly(month,3) in the fixed part) relationship between trait and month. Right?

If this is correct then I would not upgrade to a higher order random slope to keep things simple!

Best,

David




2015-09-10 11:08 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>:
Dear David,

Polynomials are technically still a linear model since they result is in linear combination of variable.

The only straightforward answer to you question is: it depends on the data. If you have plenty data, then I'd go for model 1. If the data doesn't require a second and 3th order polynomial, then their random effect variance will be very small. And the model will be reduced to model 2.

Note than plenty data means a lot of different id AND a lot of months per id. If you have only one year of data then random=~poly(month, 1)|ID is about as complex as you can go.

A 3th order polynomial seems a bit odd to me to model seasonality. I'd rather expect an even order. You might want to consider fitting month as a factor in the fixed effects. Then you model the seasonality without assumptions on the pattern.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-09-10 10:47 GMT+02:00 David Villegas R?os <chirleu at gmail.com<mailto:chirleu at gmail.com>>:
Hello,
I'm fitting some random regression models to investigate variation over time of a response trait.
The time variable is "month", and by fitting a random regression model I want to investigate variation in plasticity across individuals, i.e., differences in the "slope" between trait and time across individuals.

The relationship between the response trait and month is non-linear.
Basically, it describes a seasonal cycle.

I have considered two model candidates:

*Model 1*: fitting a polynomial of month in the fixed effects part to describe the non-linearity and get the population mean effect of month, and then a random slope using again the polynomial for month, to ge the individual differences.

trait~poly(month,3),random=~poly(month,3)|ID


*Model 2*: fitting a polynomial of month in the fixed effect part to describe the non-linearity, and then the individual-specific deviation from the fixed-effect means is modelled as a funtion of month (linear), assuming that the non-linearity is already accounted for with the fixed effect.

trait~poly(month,3),random=~month|ID

*My question is*:
Is it neccesary to include the non-linearity in the random part if it was already included in the fixed-effects part?

The idea of fitting model 2 comes from the following reference (page 488):

Dingemanse, N. J., Barber, I., Wright, J., & Brommer, J. E. (2012).
Quantitative genetics of behavioural reaction norms: genetic correlations between personality and behavioural plasticity vary across stickleback populations.*Journal of evolutionary biology*, *25*(3), 485-496.


Thank you.

David

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


------------------------------

Message: 2
Date: Thu, 10 Sep 2015 09:05:03 +0000
From: "Wilson, Alastair" <A.Wilson at exeter.ac.uk>
To: David Villegas R?os <chirleu at gmail.com>,	r-sig-mixed-models
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] non-linear slope in random regression model
Message-ID:
	<AMSPR03MB392F0A3C8B41CD9623630DBB2510 at AMSPR03MB392.eurprd03.prod.outlook.com>
	
Content-Type: text/plain; charset="iso-8859-1"

Hi David, 

It is not necessary - it may or may not be useful/interesting depending on your questions and structure of your data. In this sort of random regression model you are using your fixed effect structure to account for the relationship between your X variable (here time) and the response mean. If a 3rd order polynomial does a good job then great! In the random effect structure you are modelling the individual level effects (i.e. deviations from the fixed effect mean attributable to individual identity). These could be constant (0 order), a linear (1st order) function of X or something else (e.g. a quadratic, or indeed some other type of function of X). 

There is no necessary connection between the functional form you use in the fixed effects and that in the random effects. For plasticity studies a linear regression is common in the random effect but higher orders could be used (and may prove better fits).

For more on these sorts of models (they have some issues as well as some strength!) I would suggest looking in the animal breeding/quant gen literature, for instance work by Karin Meyer and Mark Kirkpatrick here

http://rstb.royalsocietypublishing.org/content/360/1459/1443

Alastair Wilson

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of David Villegas R?os
Sent: 10 September 2015 09:47
To: r-sig-mixed-models
Subject: [R-sig-ME] non-linear slope in random regression model

Hello,
I'm fitting some random regression models to investigate variation over time of a response trait.
The time variable is "month", and by fitting a random regression model I want to investigate variation in plasticity across individuals, i.e., differences in the "slope" between trait and time across individuals.

The relationship between the response trait and month is non-linear.
Basically, it describes a seasonal cycle.

I have considered two model candidates:

*Model 1*: fitting a polynomial of month in the fixed effects part to describe the non-linearity and get the population mean effect of month, and then a random slope using again the polynomial for month, to ge the individual differences.

trait~poly(month,3),random=~poly(month,3)|ID


*Model 2*: fitting a polynomial of month in the fixed effect part to describe the non-linearity, and then the individual-specific deviation from the fixed-effect means is modelled as a funtion of month (linear), assuming that the non-linearity is already accounted for with the fixed effect.

trait~poly(month,3),random=~month|ID

*My question is*:
Is it neccesary to include the non-linearity in the random part if it was already included in the fixed-effects part?

The idea of fitting model 2 comes from the following reference (page 488):

Dingemanse, N. J., Barber, I., Wright, J., & Brommer, J. E. (2012).
Quantitative genetics of behavioural reaction norms: genetic correlations between personality and behavioural plasticity vary across stickleback populations.*Journal of evolutionary biology*, *25*(3), 485-496.


Thank you.

David

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From edtorres82 at yahoo.com.mx  Fri Sep 11 04:06:51 2015
From: edtorres82 at yahoo.com.mx (Edgar Torres)
Date: Fri, 11 Sep 2015 02:06:51 +0000 (UTC)
Subject: [R-sig-ME] Intervention analysis with mixed models?
Message-ID: <2119860804.788036.1441937211803.JavaMail.yahoo@mail.yahoo.com>

Dear all,


I wouldlike to know if it is possible to perform an intervention analysis with linearmixed models. I have three response variable (two are counts, and one is continuous).Each dependent variable was measure for fishing vessels (23 vessels) over time(I can estimate them either monthly or annually). The time series is from 1992to 2008, in 2002 there was a fishing restriction so I would like to know ifthis restriction impacted my dependent variables. Because I do not have acontrol group of vessels I cannot carry out a BACI design, so I just canevaluate the Before-After effect. Moreover, I would like to know if there is aneffect from sea surface temperatures (sst) anomalies in my dependent variables.An example of my data is as follows:


????????? Year??? Boat???BA?? LMAMb ?? ???MAMb??ANOM1_2?? ???ANOM3??ANOM4??? Time

1??????? 1992? ? ??AP?????B??? ? ? ? ? ? ?25?? ??????579.8?????????????0.59?????????? 0.44????????? 0.49??????????? 1

2??????? 1992????? AW????B? ? ? ? ? ? ???27?? ??????638.0? ? ? ? ? ? ?0.59?????????? 0.44????????? 0.49??????????? 1

3??????? 1992? ? ??AY?????B?? ? ????????? 25????????229.7??????????? ?0.59?????????? 0.44?????????0.49????????? ??1

325??? 2008?? ? ?QQ???? A? ? ? ? ? ? ? ?24??? ? ? ?496.0? ? ? ? ? ? ?0.35????????? -0.26??????? -0.89?????????? 17
326??? 2008?????WB???? A? ? ? ? ? ? ??11? ? ? ? ?135.6? ? ? ? ? ? ?0.35????????? -0.26??????? -0.89? ? ? ? ? ?17

327??? 2008??????XY? ? ?A? ? ? ? ? ? ??33? ? ? ? ?501.3? ? ? ? ? ? ?0.35? ?? ? ? ?-0.26??????? -0.89? ? ? ? ? ?17

?I found a similarpost trying to answer this type of analysis (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004399.html).In the post the suggestion is:


mod <-lmer(Attack ~ Group*Year + Group*BA + (1|Subject), data=dat, family=poisson)


"This testswhether the difference in Attack before and after differs by Group, and whetherthe trajectory of Attack over time (Year) differs by Group. Note that year isnumeric and re-centered at 1994 (the year the intervention started)."



Followingthe example I formulated my model as follows (without a ?Group? effect):


mam.glmm1 <- glmer(LMAMb ~ BA +Time + ANOM3 + (1 | Vessel), data=o, family=poisson(), na.action=na.omit,verbose=T)


I performthree additional models, modifying ANOM3, which refers to sst anomalies, then Icarry out an anova() to selecta model, and I get the following ANOVA table:


?????????? ???????????????Df ?????????AIC??????????BIC? ?????logLik????deviance? ??????Chisq???Chi Df ????Pr(>Chisq)??? 

lmam.glmm1???5 ???2598.9 ???2617.9 ???-1294.5????????2588.9???????????????????????????? 

lmam.glmm2? ??5 ???2601.1 ???2620.0 ???-1295.5????????2591.1 ????0.0000??? ?????????0???? ????????????????1???

lmam.glmm3? ??5 ???2595.7 ???2614.6 ???-1292.8????????2585.7 ????5.4112????????????0???? ??????<2e-16 ***

lmam.glmm4? ??5 ???2601.2 ???2620.2 ???-1295.6????????2591.2 ????0.0000????????????0???????? ????????????1 



>From these resultsI select mam.glmm3 model and I perform an Anova() in this model to test forfixed effects, looking for the effect of BA:

? ? ? ? ? ? ? ? ? ? ? ? ? ??Chisq ???Df ?????????Pr(>Chisq) ?
BA?????????????????10.3832? ????1?? ? ? ? ? ? ?0.001272 **

Time????? ? ? ? ? ??4.9562? ????1?? ? ? ? ? ? ?0.025997 * 

ANOM3_4? ? ? ?9.1747? ????1?? ? ? ? ? ? ?0.002454 **



>From these resultsI was wondering:

1)????? If it is enough to estimate theBefore-After effect on response variables? 

2)????? Is there a correlation between Time (continuous)and BA (factor) effects? Is it necessary to make an interaction between theseeffects?

3)????? Am I missing something, is it normalto have p-values of 1 results and Chi Df of 0 from model comparison withanova()? 

4)????? Can I conclude that effectivelythere was an effect Before-After on my dependent variable?

Thanks inadvance, I am beginning in the use of mixed models.
EDGAR
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Sep 11 10:50:20 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 11 Sep 2015 10:50:20 +0200
Subject: [R-sig-ME] possible collinearity between random and fixed
 effects in a linear mixed model
In-Reply-To: <002b01d0ebde$05d07900$11716b00$@com>
References: <002b01d0ebde$05d07900$11716b00$@com>
Message-ID: <CAJuCY5zgd8S7eCzxheum4QyE2y+hd=3OOpxBrjnfkUNR0adWLA@mail.gmail.com>

Dear Antonello,

IMHO the referee is wrong. I've illustrated this issue with a simple
example at http://rpubs.com/INBOstats/both_fixed_random

To put is simple: the random effects only model things that the fixed
effects can't model. In your case the random effect will tell something
about the social group effect after correcting for the fixed effects.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-09-10 17:33 GMT+02:00 Antonello Canu <antonellocanu1982 at gmail.com>:

> Dear all,
>
> Recently I have submitted a manuscript in which I used a linear mixed model
> to describe the variation in the date of reproduction of female wild boars.
> For each female (n=350, culled by hunters in 27 relatively small [nearly
> 200
> ha] hunting areas in 8 hunting seasons), we had analyzed the uterus and we
> had an estimate of the age of fetuses, therefore we obtained the estimate
> of
> the conception date.
>
> Since I was especially interested in the study of the synchrony of
> reproduction among females belonging to the same social group (a phenomenon
> observed in the past for wild boar female groups and many other mammals), I
> fitted a model with date of reproduction as dependent variable, and groups
> of females culled in both the same "hunting area" + the same hunting season
> as random factor (i.e., females with a not negligible prob. to belong to
> the
> same social group...therefore my random term is a rough proxy of social
> group).
>
> As independent variables, I included in my models many environmental and
> individual variables.
>
> I tested for the inclusion of the random term (full model with the random
> term vs. full model without it), that was extremely significant. Then I
> performed model selection, selecting some of the environmental factors.
>
> The problem: Most of my environmental data are "poor". For example, for the
> rainfall and seed production I have a unique value for each hunting season.
> For other variables such as tree coverage I have a unique data for all the
> observations belonging to the same "hunting area", etc. Therefore, I have
> n=350 sows but only 8 different values for rainfall, only 27 values for
> tree
> coverage etc.
>
> I had included the "poor" environmental variables (and some of them were
> selected) because a first version of the ms was rejected by a journal
> because of the lack of environmental data, known to be able to influence
> the
> reproduction.
>
> Anyway: in this new submission the referee told me that I cannot use both
> the random term and the fixed effect because:
>
> <<some of the fixed factors are equivalent to the random term year (e.g
> rainfall, temperatures, seed crop) or hunting ground (habitat, tree species
> abundance). This is not correct because environmental and inter-annual
> heterogeneity (which I guess the authors are interested in) is accounted
> for
> by random factors. So one can either use hunting ground- and year-base
> predictors as fixed terms to study their effects or as a random terms, to
> eliminate their effects. I assume that the authors prefer the former.>>
>
>
>
> The referee in few words suggested me to drop to the random term. However,
> the random term explains a huge amount of variance and is in perfect
> agreement with the biological knowledge about wild boar reproduction (i.e.,
> synchrony of reproduction among females near to each other). I think it is
> a
> shame to drop to it, and I want to be sure that I can't use both the
> environmental data and the random term for the abovementioned reasons (due
> to the fact that a certain amount of groups have the same values for the
> environmental variables). Furthermore, it is not only a matter of
> "dropping". I actually think that results without the random term would be
> extremely misleading. Since it seems that there IS a "social group effect":
> if I ignored it, systematic variation would end up in the residuals leading
> to potentially biased inference.
>
> If the referee's suggestion is questionable, I want to try to discuss this
> aspect, and possibly to keep my model. My lack of statistical knowledge,
> anyway, make me unsure. Someone can suggest anything?
>
> Thanks in advance,
>
> Antonio
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Sep 11 11:02:43 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 11 Sep 2015 11:02:43 +0200
Subject: [R-sig-ME] Testing a trend across possibly non-independent
	estimates
In-Reply-To: <55F19BA3.4060009@freshpond.org>
References: <55F19BA3.4060009@freshpond.org>
Message-ID: <CAJuCY5w0jBtrh_BiWk+Rs03MSGmnt44S_peXSoKKs7R14cACcA@mail.gmail.com>

Dear Steven,

I assume that each individual remains in the same cohort. Then a random
slope of cohort is pointless.

Are cohort age groups?

I'd first try to write down the equation of the model you have in mind. I
have the feeling that you're stuck at that point. Consulting a local
statistician might be a good idea.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-09-10 17:02 GMT+02:00 Steven Orzack <orzack at freshpond.org>:

> A colleague and I have a longitudinal dataset in which records are
> organized as follows
>
> individual_ID_1        age        cohort    health_at_age
> individual_ID_1        age+1    cohort    health_at_age+1
> individual_ID_2        age        cohort    health_at_age
> individual_ID_2        age+1    cohort    health_at_age+1
>
> etc.
>
> call this longitudinal.df
>
> There are a few thousand individuals, twenty or so cohorts, and up to 15
> or so health scores
> (each at a different age) for a given individual.
>
> Health is scored as present/absent (1/0).
>
> We wish to assess a hypothesis about the trend across ages of how health
> at a given age changes
> over cohorts.
>
> In particular, one hypothesis is that, say, the slope parameter for a
> regression (cohort is
> predictor variable, health is the response variable) is negative for
> younger ages and is positive
> for older ages.
>
> Note that there are two ways one could derive a slope estimate for a given
> age.
>
> First way: for a given age defined by a logical variable sel, one can use
> a GLM
>
> glm(health ~ 1 + cohort, family = binomial, data = longitudinal.df, subset
> = sel)
>
> Repeat this for each age to derive the age-specific estimate to be added
> to the ensemble of slope
> estimates.
>
> a GLM works because an individual contributes only one health record for a
> given age-specific GLM.
>
> Second way: one could use a GLMM
>
> glmer(health ~ 1 + Cohort * as.factor(Age) + (cohort|individual_ID), data
> = longitudinal.df,
> family = binomial)
>
> The GLMM model generates age-specific intercepts and slopes.
>
> As it happens, this GLMM model does have substantially more support (AIC)
> than does the GLMM model
> without age as a factor (even though it has many more parameters). Hence,
> it appears that trends
> over cohorts differs across ages. Of course, this only means that there
> are differences among ages.
> By itself, it says nothing about how the trends changes over ages.
>
> I welcome opinions as to the merits of the GLM approach and the GLMM
> approach. I regard the latter
> as more appropriate and statistically proper.
>
> The main question is:
>
> Given an ensemble of slope estimates (derived by GLM or by GLMM) and that
> the data underlying any
> one slope estimate cannot be assumed to be independent of the data
> underlying the other slope
> estimates (because most individuals contribute a health record for
> multiple ages),
>
> How does one statistically assess whether there is an increasing trend
> across ages of how
> health changes over cohorts (as measured by the sign and magnitude of the
> slope for a given age)?.
>
> If the data underlying any one slope estimate were known to be independent
> of the data underlying
> any other estimate, the assessment would be straight forward (using a
> correlation or regression).
>
> A related question stems from my discomfort about only using the slope
> estimate to assess the trend
> across cohorts for a given age. Is there a more "synthetic" way to do
> this, one that is based upon
> the trend determined by all of the regression coefficients (intercept,
> slope, etc.)?
>
> note that in this analysis, random effects are nuisance parameters.
> Accounting
> for them is good practice and important but I doubt that any association
> between measures for a
> given individual influences the biological bottom line of the analysis.
> Nonetheless, I do not want
> to whistle past the graveyard.....
>
> Many thanks in advance for suggestions!
>
> --
> Steven Orzack
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From martin.hecht at hu-berlin.de  Fri Sep 11 22:41:35 2015
From: martin.hecht at hu-berlin.de (Martin Hecht)
Date: Fri, 11 Sep 2015 22:41:35 +0200
Subject: [R-sig-ME] residuals in logistic regression model
Message-ID: <55F33C7F.1070700@hu-berlin.de>


Hi,

I have some questions concerning the residuals in a logistic regression 
model ( family = binomial(link = "logit") ).
Basically I am trying to reproduce the fixed error variance of 3.29 from 
simulated data (see code below).
My questions are:

[1] What is the difference between the residuals obtained with resid() 
vs. m$residuals in glm() ?
[2] Why doesn't any of these two residual variances equal the original 
value of 3.29?
[3] How can the residuals be transformed to be on the "original" scale 
(with their variance being 3.29)?
[4] The fitted() values seem to be probabilities, is that right?
[5] Why are the fitted() values and the residuals not on the same 
scale/metric?

thank you very much,
Martin


# install.packages("gtools")
library(gtools) # for inv.logit
# install.packages("lme4")
library(lme4)

set.seed(1234)

### data generation

# standard logistic errors
eps <- rlogis ( n <- 100000 , 0 , 1 )

# variance of errors is 3.29
var ( eps )
# [1] 3.293174

# regression without predictors
# latent y equals errors
ylat <- 0 + eps

# probabilities using inverse logit function
probs <- inv.logit ( ylat )

# generation of responses from bernoulli distribution
resp <- sapply ( probs , function ( prob ) rbinom ( 1, 1, prob ) )


### glm model

# logistic regression
m <- glm ( resp ~ 1 , family = binomial(link = "logit") )

# variance of resid()
var ( resid ( m ) )
# [1] 1.386302

# variance of residuals in the results object
var ( m$residuals )
# [1] 4.000061


### glmer model

# random groups to specify a "level 2" random effect
# (just for the purpose to be able to run glmer)
gr <- sample ( 1:10 , n , replace = TRUE )
d <- data.frame ( resp , gr )

# model
m2 <- glmer ( resp ~ 1 + (1|gr) , d , family = binomial(link = "logit") )

# variance of resid()
var ( resid ( m2 ) )
# [1] 1.386302


From jkamienk at gmail.com  Sat Sep 12 23:04:27 2015
From: jkamienk at gmail.com (Juan Kamienkowski)
Date: Sat, 12 Sep 2015 18:04:27 -0300
Subject: [R-sig-ME] how to compare between models with replacements of a
	given predictor
Message-ID: <CAARjoQTf5=L1X82VerohtOMuBz8qtCjmEx9n8M==DQrz862a-g@mail.gmail.com>

Dear all,

I have the following problem, and I would appreciate very much if someone
on this list could give me some insight or reference to orient my search.

For example, I have this simple model for lmer():

Y ~ A + B + (1|D)

But B is very difficult and expensive to measure, so I want to replace it
with another predictors that I can compute automatically (B1, B2, ...).
Then, I ran these models,

Y ~ A + B1 + (1|D)
Y ~ A + B2 + (1|D)
...

But when I compared them with the original model, all these models were
worse. Thus, I tried these models,

Y ~ A + B + B1 + (1|D)
Y ~ A + B + B2 + (1|D)
...

And in some cases the absolute value of the estimate of B (and the t-value)
decreased more than others... But I'm not convinced this could be really
conclusive that some replacements are better than others.


My intuition is that this should be a common problem in many fields, but I
couldn't find the answer in the bibliography (probably I didn't try the
good keywords). Thus, I will be very grateful if someone could guide me a
little bit.

Many thanks in advance,

Best,

Juan



-- 
Juan E Kamienkowski
@ Departamento de Fisica, FCEN-UBA http://df.uba.ar/
@ Laboratorio de Neurociencia Integrativa http://neuro.org.ar/
@ Laboratorio de Inteligencia Artificial Aplicada http://liaa.dc.uba.ar/

	[[alternative HTML version deleted]]


From ev.heys at gmail.com  Mon Sep 14 09:58:57 2015
From: ev.heys at gmail.com (Evelien Heyselaar)
Date: Mon, 14 Sep 2015 09:58:57 +0200
Subject: [R-sig-ME] Logit mixed model power analysis
Message-ID: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com>

Hi,

Firstly, I'm sorry if this question has been asked (and answered) before
(although I couldn't find it). I'm doing my analysis using logit mixed
models (family = binomial(link = "logit"), glmer model) and I was wondering
if there was a way to calculate power for my final model. I have looked
over the web and all I can find are programs and simulations for linear
mixed models with a continuous outcome, but not if the outcome is only 0's
and 1's. Is there a way for me to calculate power for this model?

Thank you very much,

Evelien

	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Mon Sep 14 10:04:57 2015
From: paul.debes at utu.fi (paul debes)
Date: Mon, 14 Sep 2015 11:04:57 +0300
Subject: [R-sig-ME] Logit mixed model power analysis
In-Reply-To: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com>
References: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com>
Message-ID: <op.x4x0qjfwa3mgvf@armadillo.utu.fi>

Hi Evelien & List,

A very recent publication might answer your question:

http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12306/pdf

Best,
Paul


On Mon, 14 Sep 2015 10:58:57 +0300, Evelien Heyselaar <ev.heys at gmail.com>  
wrote:

> Hi,
>
> Firstly, I'm sorry if this question has been asked (and answered) before
> (although I couldn't find it). I'm doing my analysis using logit mixed
> models (family = binomial(link = "logit"), glmer model) and I was  
> wondering
> if there was a way to calculate power for my final model. I have looked
> over the web and all I can find are programs and simulations for linear
> mixed models with a continuous outcome, but not if the outcome is only  
> 0's
> and 1's. Is there a way for me to calculate power for this model?
>
> Thank you very much,
>
> Evelien
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland


From jasonschoeneberger at gmail.com  Mon Sep 14 12:55:33 2015
From: jasonschoeneberger at gmail.com (Jason Schoeneberger)
Date: Mon, 14 Sep 2015 06:55:33 -0400
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 105, Issue 12
In-Reply-To: <mailman.1.1442224801.30625.r-sig-mixed-models@r-project.org>
References: <mailman.1.1442224801.30625.r-sig-mixed-models@r-project.org>
Message-ID: <038f01d0eedb$e1ecdeb0$a5c69c10$@gmail.com>

You could also check here for some general guidance:
http://www.tandfonline.com/doi/full/10.1080/00220973.2015.1027805#.VfanYhFVh
Bc


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: Monday, September 14, 2015 6:00 AM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 105, Issue 12

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific than
"Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Logit mixed model power analysis (Evelien Heyselaar)
   2. Re: Logit mixed model power analysis (paul debes)


----------------------------------------------------------------------

Message: 1
Date: Mon, 14 Sep 2015 09:58:57 +0200
From: Evelien Heyselaar <ev.heys at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Logit mixed model power analysis
Message-ID:
	<CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hi,

Firstly, I'm sorry if this question has been asked (and answered) before
(although I couldn't find it). I'm doing my analysis using logit mixed
models (family = binomial(link = "logit"), glmer model) and I was wondering
if there was a way to calculate power for my final model. I have looked over
the web and all I can find are programs and simulations for linear mixed
models with a continuous outcome, but not if the outcome is only 0's and
1's. Is there a way for me to calculate power for this model?

Thank you very much,

Evelien

	[[alternative HTML version deleted]]



------------------------------

Message: 2
Date: Mon, 14 Sep 2015 11:04:57 +0300
From: paul debes <paul.debes at utu.fi>
To: r-sig-mixed-models at r-project.org, Evelien Heyselaar
	<ev.heys at gmail.com>
Subject: Re: [R-sig-ME] Logit mixed model power analysis
Message-ID: <op.x4x0qjfwa3mgvf at armadillo.utu.fi>
Content-Type: text/plain; charset=iso-8859-15; format=flowed;
	delsp=yes

Hi Evelien & List,

A very recent publication might answer your question:

http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12306/pdf

Best,
Paul


On Mon, 14 Sep 2015 10:58:57 +0300, Evelien Heyselaar <ev.heys at gmail.com>
wrote:

> Hi,
>
> Firstly, I'm sorry if this question has been asked (and answered) 
> before (although I couldn't find it). I'm doing my analysis using 
> logit mixed models (family = binomial(link = "logit"), glmer model) 
> and I was wondering if there was a way to calculate power for my final 
> model. I have looked over the web and all I can find are programs and 
> simulations for linear mixed models with a continuous outcome, but not 
> if the outcome is only 0's and 1's. Is there a way for me to calculate 
> power for this model?
>
> Thank you very much,
>
> Evelien
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Paul Debes
DFG Research Fellow
University of Turku
Department of Biology
It?inen Pitk?katu 4
20520 Turku
Finland



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 105, Issue 12


From etnbot1 at gmail.com  Mon Sep 14 13:58:58 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Mon, 14 Sep 2015 12:58:58 +0100
Subject: [R-sig-ME] Mixed model nesting query
Message-ID: <CAF79uv=jkoMUV+V7wWQJYwoonyPTstA1JGynXM5ArvJ=oOOe-g@mail.gmail.com>

Hi all,

I have a quick question relating to the specification of a linear mixed
model (I'm relatively new to R and I would be very grateful for any
advice). I have fit a linear mixed model but it does not answer my desired
question.,

My study looks at allergy levels of skin patches from patients and readings
(repeated 5 times) are measured over 4 time points

I need to determine if the allergy level for skin patch changes over time
(e.g. if allergy level from skin patch 1 for patient 1 at time 0 is
different from allergy level for skin patch 1 for patient 1 at time 1 etc.)
I do not want to see the difference between skin patch 1 and skin patch
2....

I'm really unsure how to set up this type of nesting... as

model<-lmer(allergy_level ~ time+skin +(time|reading/patient))

does not give me the desired result.


There are 7 skin patches per patient. (10 patients in total)
5 readings are taken at each of the 4 time points

my data is in the format

Patient ID        Skin patch ID     Reading       TimePoint     Allergy
Level
1                               1
1                        0                1.2
1                               1                   2
                       0                 1.4
1                               1                   3
                       0                 1.1
:                                                     :



Many thanks for reading my post

Kind regards

Etn

	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Mon Sep 14 16:55:03 2015
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Mon, 14 Sep 2015 10:55:03 -0400
Subject: [R-sig-ME] Using lmer to determine inter-rater reliability
In-Reply-To: <55E47885.30001@utoronto.ca>
References: <55E47885.30001@utoronto.ca>
Message-ID: <55F6DFC7.1030308@utoronto.ca>

Hello again.

I posted this question a couple of weeks ago and since I have received 
no suggestions, I assume it's because I have not given enough information.

If more information is needed, please let me know what you need and I'll 
do my best to provide it.

Thanks,

Kevin

On 08/31/2015 11:53 AM, Kevin E. Thorpe wrote:
> Hello.
>
> I have a data frame with following structure.
>
>  > str(vision)
> 'data.frame':    268 obs. of  9 variables:
>   $ Child          : Factor w/ 67 levels "C01-05","C01-10",..: 43 43 43
> 43 44 44 44 44 42 42 ...
>   $ Test           : Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 4
> 1 2 ...
>   $ Rater          : Factor w/ 4 levels "F","L","P","S": 4 1 4 1 1 4 1 4
> 4 1 ...
>   $ Binoc          : int  100 100 100 100 0 0 0 0 40 0 ...
>   $ Yield          : int  100 100 100 80 100 20 50 30 100 100 ...
>   $ Tries          : int  5 5 5 6 5 10 10 10 5 5 ...
>   $ Result         : Factor w/ 5 levels "Pass","ReferBI",..: 1 1 1 1 3 2
> 3 2 3 3 ...
>   $ ResultCollapsed: Factor w/ 3 levels "Pass","Refer",..: 1 1 1 1 2 2 2
> 2 2 2 ...
>   $ Test1          : Factor w/ 16 levels "F:1","F:2","F:3",..: 13 2 15 4
> 1 14 3 16 13 2 ...
>
> In these data, each subject is rated by 2 (of 4) raters twice. The Test1
> variable was created from Test and Rater with
> (Rater:Test)[drop=TRUE] to explicitly create the nesting.
>
> I then fit the following model.
>
>  > binoc.lmer1 <- lmer(Binoc~1+(1|Child) + (1|Rater) +
> (1|Test1),data=vision)
>  > binoc.lmer1
> Linear mixed model fit by REML ['lmerMod']
> Formula: Binoc ~ 1 + (1 | Child) + (1 | Rater) + (1 | Test1)
>     Data: vision
> REML criterion at convergence: 2592.62
> Random effects:
>   Groups   Name        Std.Dev.
>   Child    (Intercept) 29.226
>   Test1    (Intercept)  2.292
>   Rater    (Intercept)  5.823
>   Residual             26.330
> Number of obs: 264, groups:  Child, 66; Test1, 16; Rater, 4
> Fixed Effects:
> (Intercept)
>        51.68
>
>
> Now my questions.
>
> 1. Have I fit the right model?
>
> 2. If so, would the right estimate for the rater ICC be
>      Rater/(Rater + Residual)
>     or
>      (Rater + Test1)/(Rater + Test1 + Residual)
>
> 3. Would Test1/(Test1 + Residual) give an estimate of intra-rater
> reliability?
>
> Thanks for you time.
>
> Kevin
>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From quentin.schorpp at ti.bund.de  Tue Sep 15 14:45:16 2015
From: quentin.schorpp at ti.bund.de (Quentin Schorpp)
Date: Tue, 15 Sep 2015 14:45:16 +0200
Subject: [R-sig-ME] partly nested repeated measurements
Message-ID: <55F812DC.90808@ti.bund.de>

Hello,

I made a field study, where i took samples for soil fauna.

The Design is complicated and i want to make sure that i choose the 
right model formulation.

The study comprises 18 sites (SiteID) at 7 locations (loc),
     The number of sites per location varies between 1 and 5

On each site i took 4 samples (SiteID, too).

I sampled 12 of the 18 sites in two consecutive years (Sampling 
Campaigns = SC). Hence I've got repeated measurements.
     These fields are assigned to one of 4 Age Classes (AC) of a 
perennial energy crop. Age Class is derived from the year of establishment.
     Each Age Class has 3 Replicates.

Another Class consisting of an annual energy crop was sampled in 3 
Replicates in year one and 3 different replicates in year two.
     However I want to treat this Class as Age Class Zero.

The SiteID is nested in the Age Class and partly nested in SC (only for 
SiteID 13-18)

The Aim of the investigation was to substitute time for space. So i want 
to know if there is an development throughout the Age Classes (i.e. 
increase in abundance, different community structures, Gain in 
individual weights, increase in functional groups, etc).
And if there is an development, I want to know if it is resembled in the 
two consecutive years of sampling.

My Model formula is:

model <- glmer(Y ~ AC*SC + (1|SiteID), family="poisson", data)
     or in a more general coding:
     model <- glmer(Abundance ~ Trt*time + (1|subject), 
family="poisson", data)

Is this the right way?
     The random effect accounts for repeated measurements.
     I did not consider location, since it was not fully factorial.

The Analysis increases in complexity regarding the response variable:

Indiviudal weights have a right skewed distribution, but contain zeroes 
(gamma distribution is not possible here)
Abundance of nematode families were identified in subsamples of 100 
Individuals in total per sample, hence family abundances represent 
rather proportions.
Abundances of families are community data and should be analysed with 
multivariate methods.

I read a lot of posts and book chapters for the Analysis of longitudinal 
data, however there is a vast amount of methods and method fine tuning 
and again and again i face difficulties, error messages, many different 
results from different approaches. Now, I just want to know the truth, 
but i've got severe problems to take a decision on which Analysis to 
choose.

Kind regards,
Quentin


From arndtch at uni-landau.de  Tue Sep 15 14:47:43 2015
From: arndtch at uni-landau.de (Charlotte Arndt)
Date: Tue, 15 Sep 2015 14:47:43 +0200
Subject: [R-sig-ME] testing random slopes in three-level models & error
	message
Message-ID: <55F8136F.3090900@uni-landau.de>

Hi all,

I have two questions, one regarding the testing of random slopes in 
three-level models and one regarding an error message:

My data have a three-level structure: Items (level 1, n=6111) are nested 
within measurement occasions (level 2, n=2111), and measurement 
occasions are nested within persons (level 3, n=84). I assume a 
curvilinear relationship between one predictor and one outcome (both at 
level 1), so I included a linear and a squared term as predictors in my 
model. I am mainly interested in the fixed effects but to find out the 
"best" model to report, I want to test whether random slopes are needed 
at level 2 and/or level 3.
I wonder whether there is any "best practice" in which order the random 
slopes should be tested in three-level models?

I tried to compute a full model (random slopes for all terms at both 
levels) to compare this with models in which only one of the four random 
terms was fixed (this was done for all four possible random slopes).

Using lme4, I got an error message with regard to the full model :

>mod.full <- lmer(OUTCOME ~ 1 + PRED.linear + PRED.squared + (1 + 
PRED.linear + PRED.squared| ID.L2) + (1 +

PRED.linear + PRED.squared  | ID.L3), data)
Error: number of observations (=6111) <= number of random effects 
(=6333) for term (1 + PRED.linear + PRED.squared | ID.L2); the 
random-effects parameters and the residual variance (or scale parameter) 
are probably unidentifiable


If more information is needed, please let me know.
Thanks,

Charlotte

-- 
******************************
Charlotte Arndt
Department of Psychology
University of Koblenz-Landau
Fortstr. 7
76829 Landau, Germany
E-Mail: arndtch at uni-landau.de


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Sep 15 17:21:57 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 15 Sep 2015 17:21:57 +0200
Subject: [R-sig-ME] residuals in logistic regression model
In-Reply-To: <55F33C7F.1070700@hu-berlin.de>
References: <55F33C7F.1070700@hu-berlin.de>
Message-ID: <CAJuCY5z8JzSRTpWgOxZ8G3tXJHwB8Jxee2ufg5sjda+L-XH7_w@mail.gmail.com>

Dear Martin,

You need to do some reading on residuals in the context of a
generalised linear model. There are not the same as those of a linear
model. Have a look at the formula of a glm. There is no residual terms
like there is one with a linear model.

Note that there are different ways to calculate residuals on a glm.
See ?residuals.glm

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-11 22:41 GMT+02:00 Martin Hecht <martin.hecht at hu-berlin.de>:
>
> Hi,
>
> I have some questions concerning the residuals in a logistic regression
> model ( family = binomial(link = "logit") ).
> Basically I am trying to reproduce the fixed error variance of 3.29 from
> simulated data (see code below).
> My questions are:
>
> [1] What is the difference between the residuals obtained with resid() vs.
> m$residuals in glm() ?
> [2] Why doesn't any of these two residual variances equal the original value
> of 3.29?
> [3] How can the residuals be transformed to be on the "original" scale (with
> their variance being 3.29)?
> [4] The fitted() values seem to be probabilities, is that right?
> [5] Why are the fitted() values and the residuals not on the same
> scale/metric?
>
> thank you very much,
> Martin
>
>
> # install.packages("gtools")
> library(gtools) # for inv.logit
> # install.packages("lme4")
> library(lme4)
>
> set.seed(1234)
>
> ### data generation
>
> # standard logistic errors
> eps <- rlogis ( n <- 100000 , 0 , 1 )
>
> # variance of errors is 3.29
> var ( eps )
> # [1] 3.293174
>
> # regression without predictors
> # latent y equals errors
> ylat <- 0 + eps
>
> # probabilities using inverse logit function
> probs <- inv.logit ( ylat )
>
> # generation of responses from bernoulli distribution
> resp <- sapply ( probs , function ( prob ) rbinom ( 1, 1, prob ) )
>
>
> ### glm model
>
> # logistic regression
> m <- glm ( resp ~ 1 , family = binomial(link = "logit") )
>
> # variance of resid()
> var ( resid ( m ) )
> # [1] 1.386302
>
> # variance of residuals in the results object
> var ( m$residuals )
> # [1] 4.000061
>
>
> ### glmer model
>
> # random groups to specify a "level 2" random effect
> # (just for the purpose to be able to run glmer)
> gr <- sample ( 1:10 , n , replace = TRUE )
> d <- data.frame ( resp , gr )
>
> # model
> m2 <- glmer ( resp ~ 1 + (1|gr) , d , family = binomial(link = "logit") )
>
> # variance of resid()
> var ( resid ( m2 ) )
> # [1] 1.386302
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Tue Sep 15 17:32:40 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 15 Sep 2015 17:32:40 +0200
Subject: [R-sig-ME] Logit mixed model power analysis
In-Reply-To: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com>
References: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com>
Message-ID: <CAJuCY5zvCXyHjXSX41dC1dSQ8WO2qPKUQdU1dobPTQiJZ7hQ2Q@mail.gmail.com>

Dear Evenlien,

Post-hoc power tests are not very informative. You will get a high
power when the signal is significant and low power when not
significant.

You can always use a brute force approach to estimate the power.
Simulate a dataset with know effect size. Analyse that dataset with
your model and store the relevant p-values. Repeat this so you get N
simulated datasets for that specific effect size. Then power = mean(p
< alpha).

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-14 9:58 GMT+02:00 Evelien Heyselaar <ev.heys at gmail.com>:
> Hi,
>
> Firstly, I'm sorry if this question has been asked (and answered) before
> (although I couldn't find it). I'm doing my analysis using logit mixed
> models (family = binomial(link = "logit"), glmer model) and I was wondering
> if there was a way to calculate power for my final model. I have looked
> over the web and all I can find are programs and simulations for linear
> mixed models with a continuous outcome, but not if the outcome is only 0's
> and 1's. Is there a way for me to calculate power for this model?
>
> Thank you very much,
>
> Evelien
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Tue Sep 15 17:37:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 15 Sep 2015 17:37:28 +0200
Subject: [R-sig-ME] testing random slopes in three-level models & error
	message
In-Reply-To: <55F8136F.3090900@uni-landau.de>
References: <55F8136F.3090900@uni-landau.de>
Message-ID: <CAJuCY5xBAKfwWdsEtcXhPu9cuVL+an-smubCKE_CotguMN=sYQ@mail.gmail.com>

Dear Charlotte,

The error message seems to be quite clear: you're model is too complex
for your dataset. So either simplify to model or get more data.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-15 14:47 GMT+02:00 Charlotte Arndt <arndtch at uni-landau.de>:
> Hi all,
>
> I have two questions, one regarding the testing of random slopes in
> three-level models and one regarding an error message:
>
> My data have a three-level structure: Items (level 1, n=6111) are nested
> within measurement occasions (level 2, n=2111), and measurement
> occasions are nested within persons (level 3, n=84). I assume a
> curvilinear relationship between one predictor and one outcome (both at
> level 1), so I included a linear and a squared term as predictors in my
> model. I am mainly interested in the fixed effects but to find out the
> "best" model to report, I want to test whether random slopes are needed
> at level 2 and/or level 3.
> I wonder whether there is any "best practice" in which order the random
> slopes should be tested in three-level models?
>
> I tried to compute a full model (random slopes for all terms at both
> levels) to compare this with models in which only one of the four random
> terms was fixed (this was done for all four possible random slopes).
>
> Using lme4, I got an error message with regard to the full model :
>
>>mod.full <- lmer(OUTCOME ~ 1 + PRED.linear + PRED.squared + (1 +
> PRED.linear + PRED.squared| ID.L2) + (1 +
>
> PRED.linear + PRED.squared  | ID.L3), data)
> Error: number of observations (=6111) <= number of random effects
> (=6333) for term (1 + PRED.linear + PRED.squared | ID.L2); the
> random-effects parameters and the residual variance (or scale parameter)
> are probably unidentifiable
>
>
> If more information is needed, please let me know.
> Thanks,
>
> Charlotte
>
> --
> ******************************
> Charlotte Arndt
> Department of Psychology
> University of Koblenz-Landau
> Fortstr. 7
> 76829 Landau, Germany
> E-Mail: arndtch at uni-landau.de
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.johnson at glasgow.ac.uk  Tue Sep 15 18:21:00 2015
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 15 Sep 2015 16:21:00 +0000
Subject: [R-sig-ME] Logit mixed model power analysis
In-Reply-To: <CAJuCY5zvCXyHjXSX41dC1dSQ8WO2qPKUQdU1dobPTQiJZ7hQ2Q@mail.gmail.com>
References: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com>
	<CAJuCY5zvCXyHjXSX41dC1dSQ8WO2qPKUQdU1dobPTQiJZ7hQ2Q@mail.gmail.com>
Message-ID: <5A718A87-705B-4879-AD6F-16D5163C43EB@glasgow.ac.uk>

Hi Evenlien,

I second what Thierry said about the pointlessness of post-hoc power analysis when using the observed effect size.

This tutorial by Ben Bolker shows how to do power analysis for a binomial GLMM:
http://rpubs.com/bbolker/11703
NB you don?t need the first 3 lines any more (assuming you have a reasonably up-to-date version of lme4).

I also recommend Chapter 5 of Ben?s book Ecological Models and Data in R as an introduction to simulation, including power analysis.

Our paper on simulation-based power analysis for GLMMs 
http://dx.doi.org/10.1111/2041-210X.12306
which Paul Debes mentioned, has a supplementary online R tutorial, including a binomial example. 

Best wishes,
Paul



> On 15 Sep 2015, at 16:32, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Evenlien,
> 
> Post-hoc power tests are not very informative. You will get a high
> power when the signal is significant and low power when not
> significant.
> 
> You can always use a brute force approach to estimate the power.
> Simulate a dataset with know effect size. Analyse that dataset with
> your model and store the relevant p-values. Repeat this so you get N
> simulated datasets for that specific effect size. Then power = mean(p
> < alpha).
> 
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> 
> 
> 2015-09-14 9:58 GMT+02:00 Evelien Heyselaar <ev.heys at gmail.com>:
>> Hi,
>> 
>> Firstly, I'm sorry if this question has been asked (and answered) before
>> (although I couldn't find it). I'm doing my analysis using logit mixed
>> models (family = binomial(link = "logit"), glmer model) and I was wondering
>> if there was a way to calculate power for my final model. I have looked
>> over the web and all I can find are programs and simulations for linear
>> mixed models with a continuous outcome, but not if the outcome is only 0's
>> and 1's. Is there a way for me to calculate power for this model?
>> 
>> Thank you very much,
>> 
>> Evelien
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From David.Duffy at qimrberghofer.edu.au  Wed Sep 16 03:29:03 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Wed, 16 Sep 2015 11:29:03 +1000
Subject: [R-sig-ME] Logit mixed model power analysis
In-Reply-To: <5A718A87-705B-4879-AD6F-16D5163C43EB@glasgow.ac.uk>
References: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com><CAJuCY5zvCXyHjXSX41dC1dSQ8WO2qPKUQdU1dobPTQiJZ7hQ2Q@mail.gmail.com>
	<5A718A87-705B-4879-AD6F-16D5163C43EB@glasgow.ac.uk>
Message-ID: <alpine.LMD.2.00.1509161120170.20194@orpheus.qimr.edu.au>

On Wed, 16 Sep 2015, Paul Johnson wrote:

> I second what Thierry said about the pointlessness of post-hoc power 
> analysis when using the observed effect size.
>>
>> Post-hoc power tests are not very informative. You will get a high
>> power when the signal is significant and low power when not
>> significant.

A few people defend it as an estimate of the reproducibility 
probability. Gelman and Carlin suggest plugging in a "sensible" 
(Bayesian) estimate of the true effect based on your prior knowledge, so 
you can estimate the probability of a "Type S" (sign of true effect 
could actually be opposite to your study point estimate) or "Type M" 
error.

Cheers, David.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From A.Robinson at ms.unimelb.edu.au  Wed Sep 16 03:44:01 2015
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 16 Sep 2015 11:44:01 +1000
Subject: [R-sig-ME] Logit mixed model power analysis
In-Reply-To: <alpine.LMD.2.00.1509161120170.20194@orpheus.qimr.edu.au>
References: <CAJfT-N6QQ9upA1cHnRJw2-Fp8786ig2b0Hw-zYoW+wCYUW3FyA@mail.gmail.com>
	<CAJuCY5zvCXyHjXSX41dC1dSQ8WO2qPKUQdU1dobPTQiJZ7hQ2Q@mail.gmail.com>
	<5A718A87-705B-4879-AD6F-16D5163C43EB@glasgow.ac.uk>
	<alpine.LMD.2.00.1509161120170.20194@orpheus.qimr.edu.au>
Message-ID: <CAHyGmd5YOuAd94RerdooPr01qGqt1AKnrGe0m8ycL7JuQCyMHA@mail.gmail.com>

I understand post-hoc power as being a function of the p-value, and
therefore redundant.  When asked for the kind of information that post-hoc
power is used to represent, I prefer to provide confidence intervals on the
parameters of interest - if possible.

Best wishes,

Andrew


On Wed, Sep 16, 2015 at 11:29 AM, David Duffy <
David.Duffy at qimrberghofer.edu.au> wrote:

> On Wed, 16 Sep 2015, Paul Johnson wrote:
>
> I second what Thierry said about the pointlessness of post-hoc power
>> analysis when using the observed effect size.
>>
>>>
>>> Post-hoc power tests are not very informative. You will get a high
>>> power when the signal is significant and low power when not
>>> significant.
>>>
>>
> A few people defend it as an estimate of the reproducibility probability.
> Gelman and Carlin suggest plugging in a "sensible" (Bayesian) estimate of
> the true effect based on your prior knowledge, so you can estimate the
> probability of a "Type S" (sign of true effect could actually be opposite
> to your study point estimate) or "Type M" error.
>
> Cheers, David.
>
> | David Duffy (MBBS PhD)
> | email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax:
> -0101
> | Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
> | 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Andrew Robinson
Deputy Director, CEBRA, School of Biosciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: +61-3-8344
4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

MSME: http://www.crcpress.com/product/isbn/9781439858028
FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Wed Sep 16 10:19:23 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Wed, 16 Sep 2015 10:19:23 +0200
Subject: [R-sig-ME] Question about autocorrelation in nlme
Message-ID: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>

Dear list,

I have a question concerning autocorrelation models as estimated by nlme.

When I try to recover an autocorrelative (AR1) effect from simulated data,
I do not get the expected results, that is nlme gives different estimations
than I would expect based on the parameters used to simulate the data
(reproducible example below).

### autocor with random effects
set.seed(12345)
phi <- 0.5  # autocorrelation
b <- 0.3  # effect of predictor x
x <- sample(1:20, 1000, TRUE)  # predictor x
ID <- rep(1:100, each = 10)  # person IDs
r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
e <- rnorm(1000, sd = 2)  # residuals with sd = 2
y <- rep(0,1000)  # initialize y
y[1] <- b*x[1] + r[ID[1]] + e[1]
for (i in 2:1000) {
  if (ID[i] == ID[i-1])
    y[i] <- phi * y[i-1] + b*x[i] + r[ID[i]] + e[i]  # not the first
observation for this ID
  else y[i] <- b*x[i] + r[ID[i]] + e[i]  # first observation for this ID
}

data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
head(data)
p <- ggplot(data, aes(x=time, y=y, group=ID))
p + geom_line()

### fit with AR1 effect
library(nlme)
fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form =
~1|ID))
summary(fit_lmeA)


Accordingly, the model I think of as AR1 does not seem to be the one nlme
fits to the data. Does someone know what type of model nlme actually
assumes in this situation?

Thanks for your help!

Best
 Paul

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Sep 16 11:08:30 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 16 Sep 2015 11:08:30 +0200
Subject: [R-sig-ME] Question about autocorrelation in nlme
In-Reply-To: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>
References: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>
Message-ID: <CAJuCY5zgm7Mh7gnHOaP90DsR95kYthffp3b=-CG5xwQwJygFHg@mail.gmail.com>

Dear Paul,

The correlation functions in nlme work on the residuals, not on the response.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-16 10:19 GMT+02:00 Paul Buerkner <paul.buerkner at gmail.com>:
> Dear list,
>
> I have a question concerning autocorrelation models as estimated by nlme.
>
> When I try to recover an autocorrelative (AR1) effect from simulated data,
> I do not get the expected results, that is nlme gives different estimations
> than I would expect based on the parameters used to simulate the data
> (reproducible example below).
>
> ### autocor with random effects
> set.seed(12345)
> phi <- 0.5  # autocorrelation
> b <- 0.3  # effect of predictor x
> x <- sample(1:20, 1000, TRUE)  # predictor x
> ID <- rep(1:100, each = 10)  # person IDs
> r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
> e <- rnorm(1000, sd = 2)  # residuals with sd = 2
> y <- rep(0,1000)  # initialize y
> y[1] <- b*x[1] + r[ID[1]] + e[1]
> for (i in 2:1000) {
>   if (ID[i] == ID[i-1])
>     y[i] <- phi * y[i-1] + b*x[i] + r[ID[i]] + e[i]  # not the first
> observation for this ID
>   else y[i] <- b*x[i] + r[ID[i]] + e[i]  # first observation for this ID
> }
>
> data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
> head(data)
> p <- ggplot(data, aes(x=time, y=y, group=ID))
> p + geom_line()
>
> ### fit with AR1 effect
> library(nlme)
> fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form =
> ~1|ID))
> summary(fit_lmeA)
>
>
> Accordingly, the model I think of as AR1 does not seem to be the one nlme
> fits to the data. Does someone know what type of model nlme actually
> assumes in this situation?
>
> Thanks for your help!
>
> Best
>  Paul
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Wed Sep 16 12:40:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 16 Sep 2015 12:40:28 +0200
Subject: [R-sig-ME] Question about autocorrelation in nlme
In-Reply-To: <CAGoSky_5EF5Amo4Z4=F0PNv5Z0XT=AvSoais6GO5j=3ZM0c2OA@mail.gmail.com>
References: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>
	<CAJuCY5zgm7Mh7gnHOaP90DsR95kYthffp3b=-CG5xwQwJygFHg@mail.gmail.com>
	<CAGoSky_5EF5Amo4Z4=F0PNv5Z0XT=AvSoais6GO5j=3ZM0c2OA@mail.gmail.com>
Message-ID: <CAJuCY5zhmhgtin=b9TgPdnWvGV2bLxcZrqqmo1wS4qJcPF==vA@mail.gmail.com>

Dear Paul,

Please keep the mailing list in cc.

I'd recommend the book of Pinheiro and Bates on nlme.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-16 12:23 GMT+02:00 Paul Buerkner <paul.buerkner at gmail.com>:
> Thanks for the quick answer! That makes sense.
>
> Do you know where I can find the complete model formulation used by nlme so
> that I can simulate data from it?
>
> Thanks again!
>  Paul
>
>
>
> 2015-09-16 11:08 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>> Dear Paul,
>>
>> The correlation functions in nlme work on the residuals, not on the
>> response.
>>
>> Best regards,
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2015-09-16 10:19 GMT+02:00 Paul Buerkner <paul.buerkner at gmail.com>:
>> > Dear list,
>> >
>> > I have a question concerning autocorrelation models as estimated by
>> > nlme.
>> >
>> > When I try to recover an autocorrelative (AR1) effect from simulated
>> > data,
>> > I do not get the expected results, that is nlme gives different
>> > estimations
>> > than I would expect based on the parameters used to simulate the data
>> > (reproducible example below).
>> >
>> > ### autocor with random effects
>> > set.seed(12345)
>> > phi <- 0.5  # autocorrelation
>> > b <- 0.3  # effect of predictor x
>> > x <- sample(1:20, 1000, TRUE)  # predictor x
>> > ID <- rep(1:100, each = 10)  # person IDs
>> > r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
>> > e <- rnorm(1000, sd = 2)  # residuals with sd = 2
>> > y <- rep(0,1000)  # initialize y
>> > y[1] <- b*x[1] + r[ID[1]] + e[1]
>> > for (i in 2:1000) {
>> >   if (ID[i] == ID[i-1])
>> >     y[i] <- phi * y[i-1] + b*x[i] + r[ID[i]] + e[i]  # not the first
>> > observation for this ID
>> >   else y[i] <- b*x[i] + r[ID[i]] + e[i]  # first observation for this ID
>> > }
>> >
>> > data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
>> > head(data)
>> > p <- ggplot(data, aes(x=time, y=y, group=ID))
>> > p + geom_line()
>> >
>> > ### fit with AR1 effect
>> > library(nlme)
>> > fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form
>> > =
>> > ~1|ID))
>> > summary(fit_lmeA)
>> >
>> >
>> > Accordingly, the model I think of as AR1 does not seem to be the one
>> > nlme
>> > fits to the data. Does someone know what type of model nlme actually
>> > assumes in this situation?
>> >
>> > Thanks for your help!
>> >
>> > Best
>> >  Paul
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From kw.stat at gmail.com  Wed Sep 16 15:46:21 2015
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 16 Sep 2015 08:46:21 -0500
Subject: [R-sig-ME] Question about autocorrelation in nlme
In-Reply-To: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>
References: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>
Message-ID: <CAKFxdiRKR2r_aOaG9aTi06XoEtdkFoe00XW=nCTPwZmTHOKkKA@mail.gmail.com>

This might help:
http://stats.stackexchange.com/questions/6469/simple-linear-model-with-autocorrelated-errors-in-r

Adapting that to your example:

### autocor with random effects
set.seed(12345)
b <- 0.3  # effect of predictor x
x <- sample(1:20, 1000, TRUE)  # predictor x (time)
ID <- rep(1:100, each = 10)  # person IDs
r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
e <- arima.sim(model=list(ar=0.5), n=1000, sd=2) # .5 = autocor
plot(e)
y <- b*x + r[ID] + e

data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
head(data)

library(lattice)
xyplot(y~x|ID, data)

### fit with AR1 effect
library(nlme)
fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form =
~1|ID))
summary(fit_lmeA)

The model recovers phi and b nicely:

Correlation Structure: AR(1)
 Formula: ~1 | ID
 Parameter estimate(s):
      Phi
0.5522512
Fixed effects: y ~ x
                 Value  Std.Error  DF   t-value p-value
(Intercept) -0.1189931 0.18745596 899 -0.634779  0.5257
x            0.3076964 0.01017406 899 30.243235  0.0000


Kevin Wright


On Wed, Sep 16, 2015 at 3:19 AM, Paul Buerkner <paul.buerkner at gmail.com> wrote:
> Dear list,
>
> I have a question concerning autocorrelation models as estimated by nlme.
>
> When I try to recover an autocorrelative (AR1) effect from simulated data,
> I do not get the expected results, that is nlme gives different estimations
> than I would expect based on the parameters used to simulate the data
> (reproducible example below).
>
> ### autocor with random effects
> set.seed(12345)
> phi <- 0.5  # autocorrelation
> b <- 0.3  # effect of predictor x
> x <- sample(1:20, 1000, TRUE)  # predictor x
> ID <- rep(1:100, each = 10)  # person IDs
> r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
> e <- rnorm(1000, sd = 2)  # residuals with sd = 2
> y <- rep(0,1000)  # initialize y
> y[1] <- b*x[1] + r[ID[1]] + e[1]
> for (i in 2:1000) {
>   if (ID[i] == ID[i-1])
>     y[i] <- phi * y[i-1] + b*x[i] + r[ID[i]] + e[i]  # not the first
> observation for this ID
>   else y[i] <- b*x[i] + r[ID[i]] + e[i]  # first observation for this ID
> }
>
> data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
> head(data)
> p <- ggplot(data, aes(x=time, y=y, group=ID))
> p + geom_line()
>
> ### fit with AR1 effect
> library(nlme)
> fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form =
> ~1|ID))
> summary(fit_lmeA)
>
>
> Accordingly, the model I think of as AR1 does not seem to be the one nlme
> fits to the data. Does someone know what type of model nlme actually
> assumes in this situation?
>
> Thanks for your help!
>
> Best
>  Paul
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Kevin Wright


From etnbot1 at gmail.com  Wed Sep 16 15:50:07 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Wed, 16 Sep 2015 14:50:07 +0100
Subject: [R-sig-ME] Mixed model nesting query
Message-ID: <CAF79uvm5fMeB347kdejZKaZNMJsfcgBku3fAg4L62GndsS1STg@mail.gmail.com>

Hi all,

I have a quick question relating to the specification of a linear mixed
model (I'm relatively new to R and I would be very grateful for any
advice). I have fit a linear mixed model but it does not answer my desired
question, thus I think I have set-up my model incorrectly....

My study looks at allergy levels of skin patches from patients and readings
(repeated 5 times) are measured over 4 time points

I need to determine if the allergy level for skin patch changes over time
(e.g. if allergy level from skin patch 1 for patient 1 at time 0 is
different from allergy level for skin patch 1 for patient 1 at time 1 etc.)
I do not want to see the difference between skin patch 1 and skin patch
2....

I'm really unsure how to set up this type of nesting... as

model<-lmer(allergy_level ~ time+skin +(time|reading/patient))

does not give me the desired result.


There are 7 skin patches per patient. (10 patients in total)
5 readings are taken at each of the 4 time points

my data is in the format

Patient ID        Skin patch ID     Reading       TimePoint     Allergy
Level
1                               1
1                        0                1.2
1                               1
2                        0                 1.4
1                               1
3                        0                 1.1
:                                                     :



Many thanks for reading my post. Any advice is greatly appreciated.

Kind regards

Etn

	[[alternative HTML version deleted]]


From dbrookswr at gmail.com  Wed Sep 16 16:04:45 2015
From: dbrookswr at gmail.com (Dan Wright)
Date: Wed, 16 Sep 2015 09:04:45 -0500
Subject: [R-sig-ME] Question about autocorrelation in nlme
In-Reply-To: <6db7699588db4a29be2f454c29f999d2@BY2PR04MB807.namprd04.prod.outlook.com>
References: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>
	<6db7699588db4a29be2f454c29f999d2@BY2PR04MB807.namprd04.prod.outlook.com>
Message-ID: <CAFAZ+MKk=u3tvLLr+wTpukPa9F_yyfWwT+cu8xHNB9LOE0sojA@mail.gmail.com>

There are also examples on
http://www.ats.ucla.edu/stat/r/examples/alda/ch7.htm (and examples from
their other chapters may also be useful ... Singer and Willet's book is
highly recommended). We go through a similar example using gls in
https://www.researchgate.net/publication/23134911_Multilevel_modeling_Beyond_the_basic_applications

On Wed, Sep 16, 2015 at 8:46 AM, Kevin Wright <kw.stat at gmail.com> wrote:

> This might help:
>
> http://stats.stackexchange.com/questions/6469/simple-linear-model-with-autocorrelated-errors-in-r
>
> Adapting that to your example:
>
> ### autocor with random effects
> set.seed(12345)
> b <- 0.3  # effect of predictor x
> x <- sample(1:20, 1000, TRUE)  # predictor x (time)
> ID <- rep(1:100, each = 10)  # person IDs
> r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
> e <- arima.sim(model=list(ar=0.5), n=1000, sd=2) # .5 = autocor
> plot(e)
> y <- b*x + r[ID] + e
>
> data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
> head(data)
>
> library(lattice)
> xyplot(y~x|ID, data)
>
> ### fit with AR1 effect
> library(nlme)
> fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form =
> ~1|ID))
> summary(fit_lmeA)
>
> The model recovers phi and b nicely:
>
> Correlation Structure: AR(1)
>  Formula: ~1 | ID
>  Parameter estimate(s):
>       Phi
> 0.5522512
> Fixed effects: y ~ x
>                  Value  Std.Error  DF   t-value p-value
> (Intercept) -0.1189931 0.18745596 899 -0.634779  0.5257
> x            0.3076964 0.01017406 899 30.243235  0.0000
>
>
> Kevin Wright
>
>
> On Wed, Sep 16, 2015 at 3:19 AM, Paul Buerkner <paul.buerkner at gmail.com>
> wrote:
> > Dear list,
> >
> > I have a question concerning autocorrelation models as estimated by nlme.
> >
> > When I try to recover an autocorrelative (AR1) effect from simulated
> data,
> > I do not get the expected results, that is nlme gives different
> estimations
> > than I would expect based on the parameters used to simulate the data
> > (reproducible example below).
> >
> > ### autocor with random effects
> > set.seed(12345)
> > phi <- 0.5  # autocorrelation
> > b <- 0.3  # effect of predictor x
> > x <- sample(1:20, 1000, TRUE)  # predictor x
> > ID <- rep(1:100, each = 10)  # person IDs
> > r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
> > e <- rnorm(1000, sd = 2)  # residuals with sd = 2
> > y <- rep(0,1000)  # initialize y
> > y[1] <- b*x[1] + r[ID[1]] + e[1]
> > for (i in 2:1000) {
> >   if (ID[i] == ID[i-1])
> >     y[i] <- phi * y[i-1] + b*x[i] + r[ID[i]] + e[i]  # not the first
> > observation for this ID
> >   else y[i] <- b*x[i] + r[ID[i]] + e[i]  # first observation for this ID
> > }
> >
> > data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
> > head(data)
> > p <- ggplot(data, aes(x=time, y=y, group=ID))
> > p + geom_line()
> >
> > ### fit with AR1 effect
> > library(nlme)
> > fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form
> =
> > ~1|ID))
> > summary(fit_lmeA)
> >
> >
> > Accordingly, the model I think of as AR1 does not seem to be the one nlme
> > fits to the data. Does someone know what type of model nlme actually
> > assumes in this situation?
> >
> > Thanks for your help!
> >
> > Best
> >  Paul
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Kevin Wright
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From karraspito at yahoo.es  Thu Sep 17 16:16:45 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Thu, 17 Sep 2015 14:16:45 +0000 (UTC)
Subject: [R-sig-ME] Factor response and explanatory variables
Message-ID: <1733583610.1416712.1442499405295.JavaMail.yahoo@mail.yahoo.com>

?? Hello everyone,
??First of all, this is the same message I have sent to the general list before, I think it's more appropriate here.
?? I am going to ask this certainly tricky question here not (yet) with the intention of getting a definitive answer, as I need to deepen my questions much more, but just to have an approximate idea of which direction taking next. 
?? I have a dataset where the potential response variables are categorical multinomial (ordered, I think): several people were asked to give a value from 1 to 5 to several attributes in a potential partner, both for a short term commitment or for a longer relationship. The age, religion, sexual orientation, sexual identity (gender), self-perceived sexual attractivess and minimum attractiveness demanded in a potential partner (this ones also with values 1 to 5) were recorded for each participant.?? The idea is using the values given to attributes in potential partners as the response variable, and see to what extent these are influenced by the person's age, gender, religion and so on. 
?? The problem is that all my variables are factors, I have no numeric ones. Also, as the values given to the same attributes for a short term commitment of for a longer relationship are expected to be correlated, I was considering using multiple response variables, which adds even more difficulty to the model.
?? I have been reading about MCMCglmm, the course notes, which are not easy to understand. In any case, at some point I have read that if I don't want to fit random effects (as I think it's my case), I'd better use the pscl package instead.

?? Can you give me any advice at this point? Should I try and use pscl, or is it better to try with MCMCglmm given the difficulty of the model? Any little help will be highly appreciated. 

?? Thank you very much
?? Iker.__________________________________________________________________

?? Dr. Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? School of Life Sciences
?? Joseph Banks Laboratories
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Thu Sep 17 16:29:01 2015
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Thu, 17 Sep 2015 16:29:01 +0200
Subject: [R-sig-ME] Question about autocorrelation in nlme
In-Reply-To: <CAFAZ+MKk=u3tvLLr+wTpukPa9F_yyfWwT+cu8xHNB9LOE0sojA@mail.gmail.com>
References: <CAGoSky-B5zz+8RgRgh6eXGrJ78NS=Rmy9h5uaDHBW7vWznE94A@mail.gmail.com>
	<6db7699588db4a29be2f454c29f999d2@BY2PR04MB807.namprd04.prod.outlook.com>
	<CAFAZ+MKk=u3tvLLr+wTpukPa9F_yyfWwT+cu8xHNB9LOE0sojA@mail.gmail.com>
Message-ID: <CAGoSky-ep9aTjhw4empkgHWq=ecZsL7SeyXgp0z+BqBA-G0Yew@mail.gmail.com>

Thank you both for your helpful comments and suggestions!

This indeed answers may question thoroughly! :-)

best
 paul

2015-09-16 16:04 GMT+02:00 Dan Wright <dbrookswr at gmail.com>:

> There are also examples on
> http://www.ats.ucla.edu/stat/r/examples/alda/ch7.htm (and examples from
> their other chapters may also be useful ... Singer and Willet's book is
> highly recommended). We go through a similar example using gls in
> https://www.researchgate.net/publication/23134911_Multilevel_modeling_Beyond_the_basic_applications
>
> On Wed, Sep 16, 2015 at 8:46 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>
>> This might help:
>>
>> http://stats.stackexchange.com/questions/6469/simple-linear-model-with-autocorrelated-errors-in-r
>>
>> Adapting that to your example:
>>
>> ### autocor with random effects
>> set.seed(12345)
>> b <- 0.3  # effect of predictor x
>> x <- sample(1:20, 1000, TRUE)  # predictor x (time)
>> ID <- rep(1:100, each = 10)  # person IDs
>> r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
>> e <- arima.sim(model=list(ar=0.5), n=1000, sd=2) # .5 = autocor
>> plot(e)
>> y <- b*x + r[ID] + e
>>
>> data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
>> head(data)
>>
>> library(lattice)
>> xyplot(y~x|ID, data)
>>
>> ### fit with AR1 effect
>> library(nlme)
>> fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor = corAR1(form =
>> ~1|ID))
>> summary(fit_lmeA)
>>
>> The model recovers phi and b nicely:
>>
>> Correlation Structure: AR(1)
>>  Formula: ~1 | ID
>>  Parameter estimate(s):
>>       Phi
>> 0.5522512
>> Fixed effects: y ~ x
>>                  Value  Std.Error  DF   t-value p-value
>> (Intercept) -0.1189931 0.18745596 899 -0.634779  0.5257
>> x            0.3076964 0.01017406 899 30.243235  0.0000
>>
>>
>> Kevin Wright
>>
>>
>> On Wed, Sep 16, 2015 at 3:19 AM, Paul Buerkner <paul.buerkner at gmail.com>
>> wrote:
>> > Dear list,
>> >
>> > I have a question concerning autocorrelation models as estimated by
>> nlme.
>> >
>> > When I try to recover an autocorrelative (AR1) effect from simulated
>> data,
>> > I do not get the expected results, that is nlme gives different
>> estimations
>> > than I would expect based on the parameters used to simulate the data
>> > (reproducible example below).
>> >
>> > ### autocor with random effects
>> > set.seed(12345)
>> > phi <- 0.5  # autocorrelation
>> > b <- 0.3  # effect of predictor x
>> > x <- sample(1:20, 1000, TRUE)  # predictor x
>> > ID <- rep(1:100, each = 10)  # person IDs
>> > r <- rnorm(100, sd = 1)  # random Intercepts with sd = 1
>> > e <- rnorm(1000, sd = 2)  # residuals with sd = 2
>> > y <- rep(0,1000)  # initialize y
>> > y[1] <- b*x[1] + r[ID[1]] + e[1]
>> > for (i in 2:1000) {
>> >   if (ID[i] == ID[i-1])
>> >     y[i] <- phi * y[i-1] + b*x[i] + r[ID[i]] + e[i]  # not the first
>> > observation for this ID
>> >   else y[i] <- b*x[i] + r[ID[i]] + e[i]  # first observation for this ID
>> > }
>> >
>> > data <- data.frame(y = y, x = x, ID = ID, time = rep(1:10, 100))
>> > head(data)
>> > p <- ggplot(data, aes(x=time, y=y, group=ID))
>> > p + geom_line()
>> >
>> > ### fit with AR1 effect
>> > library(nlme)
>> > fit_lmeA <- lme(y ~ x, data = data, random = ~ 1 | ID, cor =
>> corAR1(form =
>> > ~1|ID))
>> > summary(fit_lmeA)
>> >
>> >
>> > Accordingly, the model I think of as AR1 does not seem to be the one
>> nlme
>> > fits to the data. Does someone know what type of model nlme actually
>> > assumes in this situation?
>> >
>> > Thanks for your help!
>> >
>> > Best
>> >  Paul
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Kevin Wright
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From taka.6765 at gmail.com  Thu Sep 17 23:52:56 2015
From: taka.6765 at gmail.com (Takahiro Fushimi)
Date: Thu, 17 Sep 2015 17:52:56 -0400
Subject: [R-sig-ME] Unidentifiable model in lmer
Message-ID: <55FB3638.8070708@gmail.com>

Hi everyone,

I have been working on a linear mixed effect model by using lmer() 
function, but I got an error saying that the fitted model is not 
identifiable.

The data set includes the following variables:
y = a numeric variable
factorA = a 3-level categorical variable
factorB = a 2-level categorical variable
subjectID = subject id number. 2 measurements of y for each subject

R code and output are as follows:
 > (result <- lmer(y ~ factorA + factorB + factorA*factorB + 
(1|subjectID)))
Linear mixed model fit by REML ['merModLmerTest']
Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
REML criterion at convergence: 1928.966
Random effects:
  Groups    Name        Std.Dev.
  subjectID (Intercept) 4711
  Residual              7688
Number of obs: 97, groups:  subjectID, 51
Fixed Effects:
       (Intercept)           factorA1           factorA2 factorB1 
factorA1:factorB1  factorA2:factorB1
             62411              -2700              -1124 
-1037               1279               2482
 > summary(result)
Model is not identifiable...
summary from lme4 is returned
some computational error has occurred in lmerTest
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)

REML criterion at convergence: 1929

Scaled residuals:
      Min       1Q   Median       3Q      Max
-1.93423 -0.62611  0.01837  0.48887  2.73380

Random effects:
  Groups    Name        Variance Std.Dev.
  subjectID (Intercept) 22194074 4711
  Residual              59108495 7688
Number of obs: 97, groups:  subjectID, 51

Fixed effects:
                   Estimate Std. Error t value
(Intercept)          62411       2065  30.227
factorA1             -2700       3238  -0.834
factorA2             -1124       3008  -0.374
factorB1             -1037       2512  -0.413
factorA1:factorB1     1279       4013   0.319
factorA2:factorB1     2482       3642   0.681

Correlation of Fixed Effects:
             (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
factorA1    -0.638
factorA2    -0.687  0.438
factorB1    -0.608  0.388  0.418
fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
 >

Could anyone give me some idea of why this unidentifiability problem 
happens and how to fix it?
Any help would be appreciated.

Best regards,
Takahiro


From jake987722 at hotmail.com  Fri Sep 18 00:53:14 2015
From: jake987722 at hotmail.com (Jake Westfall)
Date: Thu, 17 Sep 2015 17:53:14 -0500
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <55FB3638.8070708@gmail.com>
References: <55FB3638.8070708@gmail.com>
Message-ID: <COL129-W2314994D2ED10B37FAE7A4CB5A0@phx.gbl>

I believe this is a problem in lmerTest, not in lme4. I seem to recall running into a problem like this myself in the past, where lmerTest claimed that a model was not identifiable when I called summary() on it, even though I was pretty confident the model was fine and lmer() did not complain at all when fitting the model. (I don't think I ever figured out what was making it happen.)

Jake 

> To: r-sig-mixed-models at r-project.org
> From: taka.6765 at gmail.com
> Date: Thu, 17 Sep 2015 17:52:56 -0400
> Subject: [R-sig-ME] Unidentifiable model in lmer
> 
> Hi everyone,
> 
> I have been working on a linear mixed effect model by using lmer() 
> function, but I got an error saying that the fitted model is not 
> identifiable.
> 
> The data set includes the following variables:
> y = a numeric variable
> factorA = a 3-level categorical variable
> factorB = a 2-level categorical variable
> subjectID = subject id number. 2 measurements of y for each subject
> 
> R code and output are as follows:
>  > (result <- lmer(y ~ factorA + factorB + factorA*factorB + 
> (1|subjectID)))
> Linear mixed model fit by REML ['merModLmerTest']
> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
> REML criterion at convergence: 1928.966
> Random effects:
>   Groups    Name        Std.Dev.
>   subjectID (Intercept) 4711
>   Residual              7688
> Number of obs: 97, groups:  subjectID, 51
> Fixed Effects:
>        (Intercept)           factorA1           factorA2 factorB1 
> factorA1:factorB1  factorA2:factorB1
>              62411              -2700              -1124 
> -1037               1279               2482
>  > summary(result)
> Model is not identifiable...
> summary from lme4 is returned
> some computational error has occurred in lmerTest
> Linear mixed model fit by REML ['lmerMod']
> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
> 
> REML criterion at convergence: 1929
> 
> Scaled residuals:
>       Min       1Q   Median       3Q      Max
> -1.93423 -0.62611  0.01837  0.48887  2.73380
> 
> Random effects:
>   Groups    Name        Variance Std.Dev.
>   subjectID (Intercept) 22194074 4711
>   Residual              59108495 7688
> Number of obs: 97, groups:  subjectID, 51
> 
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)          62411       2065  30.227
> factorA1             -2700       3238  -0.834
> factorA2             -1124       3008  -0.374
> factorB1             -1037       2512  -0.413
> factorA1:factorB1     1279       4013   0.319
> factorA2:factorB1     2482       3642   0.681
> 
> Correlation of Fixed Effects:
>              (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
> factorA1    -0.638
> factorA2    -0.687  0.438
> factorB1    -0.608  0.388  0.418
> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>  >
> 
> Could anyone give me some idea of why this unidentifiability problem 
> happens and how to fix it?
> Any help would be appreciated.
> 
> Best regards,
> Takahiro
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From chelucero at uchicago.edu  Fri Sep 18 07:23:11 2015
From: chelucero at uchicago.edu (=?UTF-8?Q?Ch=C3=A9_Lucero?=)
Date: Fri, 18 Sep 2015 05:23:11 +0000
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <55FB3638.8070708@gmail.com>
References: <55FB3638.8070708@gmail.com>
Message-ID: <CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>

I don't know if this is causing the problem you're seeing, but A*B expands
to A + B + A:B, so your model right now is R ~ A + B + A + B + A:B + (1|S).

On Thu, Sep 17, 2015 at 5:53 PM Takahiro Fushimi <taka.6765 at gmail.com>
wrote:

> Hi everyone,
>
> I have been working on a linear mixed effect model by using lmer()
> function, but I got an error saying that the fitted model is not
> identifiable.
>
> The data set includes the following variables:
> y = a numeric variable
> factorA = a 3-level categorical variable
> factorB = a 2-level categorical variable
> subjectID = subject id number. 2 measurements of y for each subject
>
> R code and output are as follows:
>  > (result <- lmer(y ~ factorA + factorB + factorA*factorB +
> (1|subjectID)))
> Linear mixed model fit by REML ['merModLmerTest']
> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
> REML criterion at convergence: 1928.966
> Random effects:
>   Groups    Name        Std.Dev.
>   subjectID (Intercept) 4711
>   Residual              7688
> Number of obs: 97, groups:  subjectID, 51
> Fixed Effects:
>        (Intercept)           factorA1           factorA2 factorB1
> factorA1:factorB1  factorA2:factorB1
>              62411              -2700              -1124
> -1037               1279               2482
>  > summary(result)
> Model is not identifiable...
> summary from lme4 is returned
> some computational error has occurred in lmerTest
> Linear mixed model fit by REML ['lmerMod']
> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>
> REML criterion at convergence: 1929
>
> Scaled residuals:
>       Min       1Q   Median       3Q      Max
> -1.93423 -0.62611  0.01837  0.48887  2.73380
>
> Random effects:
>   Groups    Name        Variance Std.Dev.
>   subjectID (Intercept) 22194074 4711
>   Residual              59108495 7688
> Number of obs: 97, groups:  subjectID, 51
>
> Fixed effects:
>                    Estimate Std. Error t value
> (Intercept)          62411       2065  30.227
> factorA1             -2700       3238  -0.834
> factorA2             -1124       3008  -0.374
> factorB1             -1037       2512  -0.413
> factorA1:factorB1     1279       4013   0.319
> factorA2:factorB1     2482       3642   0.681
>
> Correlation of Fixed Effects:
>              (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
> factorA1    -0.638
> factorA2    -0.687  0.438
> factorB1    -0.608  0.388  0.418
> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>  >
>
> Could anyone give me some idea of why this unidentifiability problem
> happens and how to fix it?
> Any help would be appreciated.
>
> Best regards,
> Takahiro
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Fri Sep 18 07:43:27 2015
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Fri, 18 Sep 2015 05:43:27 +0000
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
References: <55FB3638.8070708@gmail.com>
	<CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
Message-ID: <7FFB5277-B19D-4379-AA9F-6189218117F0@unisa.edu.au>

I suspect that is a large part of the problem - the extra parameters are collinear by definition and that will cause issues with model fit.

Phillip


> On 18 Sep 2015, at 14:53, Ch? Lucero <chelucero at uchicago.edu> wrote:
> 
> I don't know if this is causing the problem you're seeing, but A*B expands
> to A + B + A:B, so your model right now is R ~ A + B + A + B + A:B + (1|S).
> 
> On Thu, Sep 17, 2015 at 5:53 PM Takahiro Fushimi <taka.6765 at gmail.com>
> wrote:
> 
>> Hi everyone,
>> 
>> I have been working on a linear mixed effect model by using lmer()
>> function, but I got an error saying that the fitted model is not
>> identifiable.
>> 
>> The data set includes the following variables:
>> y = a numeric variable
>> factorA = a 3-level categorical variable
>> factorB = a 2-level categorical variable
>> subjectID = subject id number. 2 measurements of y for each subject
>> 
>> R code and output are as follows:
>>> (result <- lmer(y ~ factorA + factorB + factorA*factorB +
>> (1|subjectID)))
>> Linear mixed model fit by REML ['merModLmerTest']
>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>> REML criterion at convergence: 1928.966
>> Random effects:
>>  Groups    Name        Std.Dev.
>>  subjectID (Intercept) 4711
>>  Residual              7688
>> Number of obs: 97, groups:  subjectID, 51
>> Fixed Effects:
>>       (Intercept)           factorA1           factorA2 factorB1
>> factorA1:factorB1  factorA2:factorB1
>>             62411              -2700              -1124
>> -1037               1279               2482
>>> summary(result)
>> Model is not identifiable...
>> summary from lme4 is returned
>> some computational error has occurred in lmerTest
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>> 
>> REML criterion at convergence: 1929
>> 
>> Scaled residuals:
>>      Min       1Q   Median       3Q      Max
>> -1.93423 -0.62611  0.01837  0.48887  2.73380
>> 
>> Random effects:
>>  Groups    Name        Variance Std.Dev.
>>  subjectID (Intercept) 22194074 4711
>>  Residual              59108495 7688
>> Number of obs: 97, groups:  subjectID, 51
>> 
>> Fixed effects:
>>                   Estimate Std. Error t value
>> (Intercept)          62411       2065  30.227
>> factorA1             -2700       3238  -0.834
>> factorA2             -1124       3008  -0.374
>> factorB1             -1037       2512  -0.413
>> factorA1:factorB1     1279       4013   0.319
>> factorA2:factorB1     2482       3642   0.681
>> 
>> Correlation of Fixed Effects:
>>             (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
>> factorA1    -0.638
>> factorA2    -0.687  0.438
>> factorB1    -0.608  0.388  0.418
>> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
>> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>>> 
>> 
>> Could anyone give me some idea of why this unidentifiability problem
>> happens and how to fix it?
>> Any help would be appreciated.
>> 
>> Best regards,
>> Takahiro
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Fri Sep 18 09:23:37 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 18 Sep 2015 09:23:37 +0200
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
References: <55FB3638.8070708@gmail.com>
	<CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
Message-ID: <CAJuCY5xk8758TtTJZ58m_woGg75DnqJR-Jpet4yPcXc64q7hiw@mail.gmail.com>

The formula shouldn't be the problem. model.matrix() is clever enough
to handle this. Have a look at the examples below.

model.matrix(~ A + B + A * B, data= data.frame(A = 1, B = 1))
model.matrix(~ A + B + A * B + B + A:B + B:A, data= data.frame(A = 1, B = 1))

I suggest to give use a reproducible example of the problem so that we
can invesigate what when wrong.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-18 7:23 GMT+02:00 Ch? Lucero <chelucero at uchicago.edu>:
> I don't know if this is causing the problem you're seeing, but A*B expands
> to A + B + A:B, so your model right now is R ~ A + B + A + B + A:B + (1|S).
>
> On Thu, Sep 17, 2015 at 5:53 PM Takahiro Fushimi <taka.6765 at gmail.com>
> wrote:
>
>> Hi everyone,
>>
>> I have been working on a linear mixed effect model by using lmer()
>> function, but I got an error saying that the fitted model is not
>> identifiable.
>>
>> The data set includes the following variables:
>> y = a numeric variable
>> factorA = a 3-level categorical variable
>> factorB = a 2-level categorical variable
>> subjectID = subject id number. 2 measurements of y for each subject
>>
>> R code and output are as follows:
>>  > (result <- lmer(y ~ factorA + factorB + factorA*factorB +
>> (1|subjectID)))
>> Linear mixed model fit by REML ['merModLmerTest']
>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>> REML criterion at convergence: 1928.966
>> Random effects:
>>   Groups    Name        Std.Dev.
>>   subjectID (Intercept) 4711
>>   Residual              7688
>> Number of obs: 97, groups:  subjectID, 51
>> Fixed Effects:
>>        (Intercept)           factorA1           factorA2 factorB1
>> factorA1:factorB1  factorA2:factorB1
>>              62411              -2700              -1124
>> -1037               1279               2482
>>  > summary(result)
>> Model is not identifiable...
>> summary from lme4 is returned
>> some computational error has occurred in lmerTest
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>
>> REML criterion at convergence: 1929
>>
>> Scaled residuals:
>>       Min       1Q   Median       3Q      Max
>> -1.93423 -0.62611  0.01837  0.48887  2.73380
>>
>> Random effects:
>>   Groups    Name        Variance Std.Dev.
>>   subjectID (Intercept) 22194074 4711
>>   Residual              59108495 7688
>> Number of obs: 97, groups:  subjectID, 51
>>
>> Fixed effects:
>>                    Estimate Std. Error t value
>> (Intercept)          62411       2065  30.227
>> factorA1             -2700       3238  -0.834
>> factorA2             -1124       3008  -0.374
>> factorB1             -1037       2512  -0.413
>> factorA1:factorB1     1279       4013   0.319
>> factorA2:factorB1     2482       3642   0.681
>>
>> Correlation of Fixed Effects:
>>              (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
>> factorA1    -0.638
>> factorA2    -0.687  0.438
>> factorB1    -0.608  0.388  0.418
>> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
>> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>>  >
>>
>> Could anyone give me some idea of why this unidentifiability problem
>> happens and how to fix it?
>> Any help would be appreciated.
>>
>> Best regards,
>> Takahiro
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From karraspito at yahoo.es  Fri Sep 18 13:14:43 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Fri, 18 Sep 2015 11:14:43 +0000 (UTC)
Subject: [R-sig-ME] Factor response and explanatory variables
In-Reply-To: <alpine.LMD.2.00.1509181549360.26815@orpheus.qimr.edu.au>
References: <alpine.LMD.2.00.1509181549360.26815@orpheus.qimr.edu.au>
Message-ID: <1327255289.2051815.1442574883609.JavaMail.yahoo@mail.yahoo.com>


?? Thank you very much. I have actually made quite a lot of progress with MCMCglmm, I just need to find some proper priors, "only" that...
?? I'll post here again when I have much more accurate and focused questions.? 

?? Thank you very much again!?? Iker
?__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


      De: David Duffy <David.Duffy at qimrberghofer.edu.au>
 Para: Iker Vaquero Alba <karraspito at yahoo.es> 
CC: r-sig-mixed-models at r-project.org 
 Enviado: Viernes 18 de septiembre de 2015 7:04
 Asunto: Re: [R-sig-ME] Factor response and explanatory variables
   
On Fri, 18 Sep 2015, Iker Vaquero Alba wrote:


> The problem is that all my variables are factors

You might consider path analysis/SEM using polychoric correlations, 
especially if you have multiple ordinal outcomes of interest. In R, 
lavaan, OpenMx, (sem plus polycor).

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au? ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia? GPG 4D0B994A


  
	[[alternative HTML version deleted]]


From lei.he at uzh.ch  Fri Sep 18 14:17:12 2015
From: lei.he at uzh.ch (lei.he at uzh.ch)
Date: Fri, 18 Sep 2015 14:17:12 +0200
Subject: [R-sig-ME] Model comparison between a full model and a random
	effect reduced model
Message-ID: <OF031747A9.EB27EE31-ONC1257EC4.00437237-C1257EC4.00437DFC@lotus.uzh.ch>

Dear all,



I?m studying speaker idiosyncratic intensity variability in the speech signal. My dataset looks like this:



-nPVIm: numeric variable, quantifying intensity variability

-tempo: factor with 5 levels, indicating five levels of speech rates (normal, slow, even slower, fast, fastest possible)

-sentence: factor with 7 levels, i.e. seven different sentences

-speaker: factor 12 levels, i.e. twelve speakers



I first I fitted speaker as a random effect with the rationale that we cannot exhaust all the possible speakers:

Full1 = lmer(nPVIm ~ tempo + (1|speaker) + (1|sentence), data=dat, REML=F)



Then I fitted speaker as a fixed effect. The rationale is that if we apply ?nPVIm? in a close-set speaker identification or verification system, the speakers are fixed:

Full2 = lmer(nPVIm~tempo + speaker + (1|sentence), data=dat, REML=F)



Next, I fitted a reduced model without speaker effect:

Reduced = lmer(nPVIm~tempo + (1|sentence), data=dat, REML=F)



Finally, I used the anova () function to test whether Full1 and Full2 are significantly different from Reduced.?



Results showed that speaker as both random and fixed effects are significant, and the AICs of both Full1 and Full2 are lower than that of Reduced.



Now we have received the reviewer?s comments. The reviewer wasn?t certain if it allows the models to be compared like this, especially anova(Full1, Reduced). So I would like to ask if our way of model fitting and comparisons is free from problems.



Thank you very much in advance!



Kindest regards,


Lei

---------------------------
Lei He

Phonetics Laboratory
Department of Comparative Linguistics
University of Zurich

Plattenstrasse 54
CH8032
Zurich
Switzerland

	[[alternative HTML version deleted]]


From taka.6765 at gmail.com  Fri Sep 18 16:40:10 2015
From: taka.6765 at gmail.com (Takahiro Fushimi)
Date: Fri, 18 Sep 2015 10:40:10 -0400
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <CAJuCY5xk8758TtTJZ58m_woGg75DnqJR-Jpet4yPcXc64q7hiw@mail.gmail.com>
References: <55FB3638.8070708@gmail.com>
	<CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
	<CAJuCY5xk8758TtTJZ58m_woGg75DnqJR-Jpet4yPcXc64q7hiw@mail.gmail.com>
Message-ID: <55FC224A.4070405@gmail.com>

The data set is as follows:
 > dataset
            y A B  ID
1   60625.19 0 1  72
2   51088.38 0 1  73
3   67283.03 0 1  74
4   56550.54 0 1  75
5         NA 0 1  76
6         NA 0 1  78
7   58720.44 0 1  79
8   63939.01 0 1  86
9   66298.32 0 1  88
10  62662.15 0 1  89
11  53604.41 0 1  90
12  88338.55 0 1  91
13  62818.78 0 1  92
14  68696.71 0 1  93
15  57433.98 0 1  94
16  59105.99 0 1  95
17  44801.97 0 1  96
18  68655.48 0 1 121
19  62645.16 0 1 122
20  69409.15 0 1 123
21  43568.70 0 1 124
22  55693.21 1 1  77
23  57322.63 1 1  80
24  51095.55 1 1  81
25  57660.41 1 1  82
26  64128.63 1 1  83
27  55216.42 1 1  84
28  59945.17 1 1  98
29  67284.31 1 1 116
30  55401.13 1 1 117
31  60471.59 1 1 118
32        NA 1 1 119
33  63633.07 1 1 120
34  65939.14 1 1 125
35        NA 1 1 128
36  69488.38 2 1 100
37  43950.50 2 1 101
38  52782.99 2 1 102
39  55674.94 2 1 103
40  70130.25 2 1 104
41  72560.25 2 1 105
42  69297.95 2 1 106
43  53188.98 2 1 107
44  75687.53 2 1 108
45  68242.23 2 1 109
46  60696.15 2 1 110
47  65087.04 2 1 112
48  59377.71 2 1 113
49  55055.45 2 1 114
50  66673.40 2 1 115
51  65933.37 2 1 126
52  62636.56 2 1 127
53  49606.80 0 0  72
54  58668.13 0 0  73
55  56694.13 0 0  74
56        NA 0 0  75
57        NA 0 0  76
58  61928.95 0 0  78
59  63208.84 0 0  79
60  83786.71 0 0  86
61  72727.53 0 0  88
62  78873.45 0 0  89
63  47482.32 0 0  90
64  65967.84 0 0  91
65  53228.25 0 0  92
66  65699.59 0 0  93
67  61792.81 0 0  94
68  44816.72 0 0  95
69  71048.06 0 0  96
70  59671.84 0 0 121
71  89513.43 0 0 122
72  56972.30 0 0 123
73  45439.25 0 0 124
74  51357.83 1 0  77
75        NA 1 0  80
76  60146.86 1 0  81
77  56845.88 1 0  82
78  63181.13 1 0  83
79  63704.80 1 0  84
80  49140.22 1 0  98
81  54538.14 1 0 116
82  49411.32 1 0 117
83  66059.73 1 0 118
84  73147.55 1 0 119
85  55665.96 1 0 120
86  66821.27 1 0 125
87  66935.12 1 0 128
88  54350.63 2 0 100
89  48116.25 2 0 101
90  67664.66 2 0 102
91  64278.54 2 0 103
92  64555.03 2 0 104
93  62463.60 2 0 105
94  55831.53 2 0 106
95  57392.61 2 0 107
96  75727.00 2 0 108
97  64839.50 2 0 109
98  51009.78 2 0 110
99  65274.59 2 0 112
100 63339.91 2 0 113
101 62276.49 2 0 114
102 66159.42 2 0 115
103 58333.76 2 0 126
104 60275.09 2 0 127

Best regards,
Takahiro

On 9/18/15 3:23 AM, Thierry Onkelinx wrote:
> The formula shouldn't be the problem. model.matrix() is clever enough
> to handle this. Have a look at the examples below.
>
> model.matrix(~ A + B + A * B, data= data.frame(A = 1, B = 1))
> model.matrix(~ A + B + A * B + B + A:B + B:A, data= data.frame(A = 1, B = 1))
>
> I suggest to give use a reproducible example of the problem so that we
> can invesigate what when wrong.
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2015-09-18 7:23 GMT+02:00 Ch? Lucero <chelucero at uchicago.edu>:
>> I don't know if this is causing the problem you're seeing, but A*B expands
>> to A + B + A:B, so your model right now is R ~ A + B + A + B + A:B + (1|S).
>>
>> On Thu, Sep 17, 2015 at 5:53 PM Takahiro Fushimi <taka.6765 at gmail.com>
>> wrote:
>>
>>> Hi everyone,
>>>
>>> I have been working on a linear mixed effect model by using lmer()
>>> function, but I got an error saying that the fitted model is not
>>> identifiable.
>>>
>>> The data set includes the following variables:
>>> y = a numeric variable
>>> factorA = a 3-level categorical variable
>>> factorB = a 2-level categorical variable
>>> subjectID = subject id number. 2 measurements of y for each subject
>>>
>>> R code and output are as follows:
>>>   > (result <- lmer(y ~ factorA + factorB + factorA*factorB +
>>> (1|subjectID)))
>>> Linear mixed model fit by REML ['merModLmerTest']
>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>> REML criterion at convergence: 1928.966
>>> Random effects:
>>>    Groups    Name        Std.Dev.
>>>    subjectID (Intercept) 4711
>>>    Residual              7688
>>> Number of obs: 97, groups:  subjectID, 51
>>> Fixed Effects:
>>>         (Intercept)           factorA1           factorA2 factorB1
>>> factorA1:factorB1  factorA2:factorB1
>>>               62411              -2700              -1124
>>> -1037               1279               2482
>>>   > summary(result)
>>> Model is not identifiable...
>>> summary from lme4 is returned
>>> some computational error has occurred in lmerTest
>>> Linear mixed model fit by REML ['lmerMod']
>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>>
>>> REML criterion at convergence: 1929
>>>
>>> Scaled residuals:
>>>        Min       1Q   Median       3Q      Max
>>> -1.93423 -0.62611  0.01837  0.48887  2.73380
>>>
>>> Random effects:
>>>    Groups    Name        Variance Std.Dev.
>>>    subjectID (Intercept) 22194074 4711
>>>    Residual              59108495 7688
>>> Number of obs: 97, groups:  subjectID, 51
>>>
>>> Fixed effects:
>>>                     Estimate Std. Error t value
>>> (Intercept)          62411       2065  30.227
>>> factorA1             -2700       3238  -0.834
>>> factorA2             -1124       3008  -0.374
>>> factorB1             -1037       2512  -0.413
>>> factorA1:factorB1     1279       4013   0.319
>>> factorA2:factorB1     2482       3642   0.681
>>>
>>> Correlation of Fixed Effects:
>>>               (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
>>> factorA1    -0.638
>>> factorA2    -0.687  0.438
>>> factorB1    -0.608  0.388  0.418
>>> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
>>> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>>>   >
>>>
>>> Could anyone give me some idea of why this unidentifiability problem
>>> happens and how to fix it?
>>> Any help would be appreciated.
>>>
>>> Best regards,
>>> Takahiro
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Takahiro Fushimi
Columbia University in the City of New York
Master of Arts in Statistics


From thierry.onkelinx at inbo.be  Fri Sep 18 16:41:49 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 18 Sep 2015 16:41:49 +0200
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <55FC224A.4070405@gmail.com>
References: <55FB3638.8070708@gmail.com>
	<CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
	<CAJuCY5xk8758TtTJZ58m_woGg75DnqJR-Jpet4yPcXc64q7hiw@mail.gmail.com>
	<55FC224A.4070405@gmail.com>
Message-ID: <CAJuCY5z2T1VXYBkGQCWRu0hmeE=D4Cy74conQ6F8EeBk80X+EQ@mail.gmail.com>

Dear Takahiro,

Please send the output of dput(dataset). That's a lot easier to
copy-paste into an R session.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-18 16:40 GMT+02:00 Takahiro Fushimi <taka.6765 at gmail.com>:
> The data set is as follows:
>> dataset
>            y A B  ID
> 1   60625.19 0 1  72
> 2   51088.38 0 1  73
> 3   67283.03 0 1  74
> 4   56550.54 0 1  75
> 5         NA 0 1  76
> 6         NA 0 1  78
> 7   58720.44 0 1  79
> 8   63939.01 0 1  86
> 9   66298.32 0 1  88
> 10  62662.15 0 1  89
> 11  53604.41 0 1  90
> 12  88338.55 0 1  91
> 13  62818.78 0 1  92
> 14  68696.71 0 1  93
> 15  57433.98 0 1  94
> 16  59105.99 0 1  95
> 17  44801.97 0 1  96
> 18  68655.48 0 1 121
> 19  62645.16 0 1 122
> 20  69409.15 0 1 123
> 21  43568.70 0 1 124
> 22  55693.21 1 1  77
> 23  57322.63 1 1  80
> 24  51095.55 1 1  81
> 25  57660.41 1 1  82
> 26  64128.63 1 1  83
> 27  55216.42 1 1  84
> 28  59945.17 1 1  98
> 29  67284.31 1 1 116
> 30  55401.13 1 1 117
> 31  60471.59 1 1 118
> 32        NA 1 1 119
> 33  63633.07 1 1 120
> 34  65939.14 1 1 125
> 35        NA 1 1 128
> 36  69488.38 2 1 100
> 37  43950.50 2 1 101
> 38  52782.99 2 1 102
> 39  55674.94 2 1 103
> 40  70130.25 2 1 104
> 41  72560.25 2 1 105
> 42  69297.95 2 1 106
> 43  53188.98 2 1 107
> 44  75687.53 2 1 108
> 45  68242.23 2 1 109
> 46  60696.15 2 1 110
> 47  65087.04 2 1 112
> 48  59377.71 2 1 113
> 49  55055.45 2 1 114
> 50  66673.40 2 1 115
> 51  65933.37 2 1 126
> 52  62636.56 2 1 127
> 53  49606.80 0 0  72
> 54  58668.13 0 0  73
> 55  56694.13 0 0  74
> 56        NA 0 0  75
> 57        NA 0 0  76
> 58  61928.95 0 0  78
> 59  63208.84 0 0  79
> 60  83786.71 0 0  86
> 61  72727.53 0 0  88
> 62  78873.45 0 0  89
> 63  47482.32 0 0  90
> 64  65967.84 0 0  91
> 65  53228.25 0 0  92
> 66  65699.59 0 0  93
> 67  61792.81 0 0  94
> 68  44816.72 0 0  95
> 69  71048.06 0 0  96
> 70  59671.84 0 0 121
> 71  89513.43 0 0 122
> 72  56972.30 0 0 123
> 73  45439.25 0 0 124
> 74  51357.83 1 0  77
> 75        NA 1 0  80
> 76  60146.86 1 0  81
> 77  56845.88 1 0  82
> 78  63181.13 1 0  83
> 79  63704.80 1 0  84
> 80  49140.22 1 0  98
> 81  54538.14 1 0 116
> 82  49411.32 1 0 117
> 83  66059.73 1 0 118
> 84  73147.55 1 0 119
> 85  55665.96 1 0 120
> 86  66821.27 1 0 125
> 87  66935.12 1 0 128
> 88  54350.63 2 0 100
> 89  48116.25 2 0 101
> 90  67664.66 2 0 102
> 91  64278.54 2 0 103
> 92  64555.03 2 0 104
> 93  62463.60 2 0 105
> 94  55831.53 2 0 106
> 95  57392.61 2 0 107
> 96  75727.00 2 0 108
> 97  64839.50 2 0 109
> 98  51009.78 2 0 110
> 99  65274.59 2 0 112
> 100 63339.91 2 0 113
> 101 62276.49 2 0 114
> 102 66159.42 2 0 115
> 103 58333.76 2 0 126
> 104 60275.09 2 0 127
>
> Best regards,
> Takahiro
>
>
> On 9/18/15 3:23 AM, Thierry Onkelinx wrote:
>>
>> The formula shouldn't be the problem. model.matrix() is clever enough
>> to handle this. Have a look at the examples below.
>>
>> model.matrix(~ A + B + A * B, data= data.frame(A = 1, B = 1))
>> model.matrix(~ A + B + A * B + B + A:B + B:A, data= data.frame(A = 1, B =
>> 1))
>>
>> I suggest to give use a reproducible example of the problem so that we
>> can invesigate what when wrong.
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2015-09-18 7:23 GMT+02:00 Ch? Lucero <chelucero at uchicago.edu>:
>>>
>>> I don't know if this is causing the problem you're seeing, but A*B
>>> expands
>>> to A + B + A:B, so your model right now is R ~ A + B + A + B + A:B +
>>> (1|S).
>>>
>>> On Thu, Sep 17, 2015 at 5:53 PM Takahiro Fushimi <taka.6765 at gmail.com>
>>> wrote:
>>>
>>>> Hi everyone,
>>>>
>>>> I have been working on a linear mixed effect model by using lmer()
>>>> function, but I got an error saying that the fitted model is not
>>>> identifiable.
>>>>
>>>> The data set includes the following variables:
>>>> y = a numeric variable
>>>> factorA = a 3-level categorical variable
>>>> factorB = a 2-level categorical variable
>>>> subjectID = subject id number. 2 measurements of y for each subject
>>>>
>>>> R code and output are as follows:
>>>>   > (result <- lmer(y ~ factorA + factorB + factorA*factorB +
>>>> (1|subjectID)))
>>>> Linear mixed model fit by REML ['merModLmerTest']
>>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>>> REML criterion at convergence: 1928.966
>>>> Random effects:
>>>>    Groups    Name        Std.Dev.
>>>>    subjectID (Intercept) 4711
>>>>    Residual              7688
>>>> Number of obs: 97, groups:  subjectID, 51
>>>> Fixed Effects:
>>>>         (Intercept)           factorA1           factorA2 factorB1
>>>> factorA1:factorB1  factorA2:factorB1
>>>>               62411              -2700              -1124
>>>> -1037               1279               2482
>>>>   > summary(result)
>>>> Model is not identifiable...
>>>> summary from lme4 is returned
>>>> some computational error has occurred in lmerTest
>>>> Linear mixed model fit by REML ['lmerMod']
>>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>>>
>>>> REML criterion at convergence: 1929
>>>>
>>>> Scaled residuals:
>>>>        Min       1Q   Median       3Q      Max
>>>> -1.93423 -0.62611  0.01837  0.48887  2.73380
>>>>
>>>> Random effects:
>>>>    Groups    Name        Variance Std.Dev.
>>>>    subjectID (Intercept) 22194074 4711
>>>>    Residual              59108495 7688
>>>> Number of obs: 97, groups:  subjectID, 51
>>>>
>>>> Fixed effects:
>>>>                     Estimate Std. Error t value
>>>> (Intercept)          62411       2065  30.227
>>>> factorA1             -2700       3238  -0.834
>>>> factorA2             -1124       3008  -0.374
>>>> factorB1             -1037       2512  -0.413
>>>> factorA1:factorB1     1279       4013   0.319
>>>> factorA2:factorB1     2482       3642   0.681
>>>>
>>>> Correlation of Fixed Effects:
>>>>               (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
>>>> factorA1    -0.638
>>>> factorA2    -0.687  0.438
>>>> factorB1    -0.608  0.388  0.418
>>>> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
>>>> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>>>>   >
>>>>
>>>> Could anyone give me some idea of why this unidentifiability problem
>>>> happens and how to fix it?
>>>> Any help would be appreciated.
>>>>
>>>> Best regards,
>>>> Takahiro
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Takahiro Fushimi
> Columbia University in the City of New York
> Master of Arts in Statistics
>


From taka.6765 at gmail.com  Fri Sep 18 17:08:28 2015
From: taka.6765 at gmail.com (Takahiro Fushimi)
Date: Fri, 18 Sep 2015 11:08:28 -0400
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <CAJuCY5z2T1VXYBkGQCWRu0hmeE=D4Cy74conQ6F8EeBk80X+EQ@mail.gmail.com>
References: <55FB3638.8070708@gmail.com>
	<CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
	<CAJuCY5xk8758TtTJZ58m_woGg75DnqJR-Jpet4yPcXc64q7hiw@mail.gmail.com>
	<55FC224A.4070405@gmail.com>
	<CAJuCY5z2T1VXYBkGQCWRu0hmeE=D4Cy74conQ6F8EeBk80X+EQ@mail.gmail.com>
Message-ID: <55FC28EC.5090705@gmail.com>

Sorry about it. Does this work?

dataset <- data.frame(y = c(60625.19, 51088.38, 67283.03, 56550.54, 
NA,   NA, 58720.44,63939.01, 66298.32, 62662.15, 53604.41, 88338.55, 
62818.78, 68696.71,57433.98, 59105.99, 44801.97, 68655.48, 62645.16, 
69409.15, 43568.70,55693.21, 57322.63, 51095.55, 57660.41, 64128.63, 
55216.42, 59945.17,67284.31, 55401.13, 60471.59, NA, 63633.07, 
65939.14,NA, 69488.38, 43950.50, 52782.99, 55674.94, 70130.25, 72560.25, 
69297.95, 53188.98, 75687.53, 68242.23, 60696.15, 65087.04, 59377.71, 
55055.45, 66673.40, 65933.37, 62636.56, 49606.80, 58668.13, 56694.13, 
NA, NA, 61928.95,63208.84, 83786.71, 72727.53, 78873.45, 47482.32, 
65967.84, 53228.25, 65699.59, 61792.81, 44816.72, 71048.06, 59671.84, 
89513.43, 56972.30, 45439.25, 51357.83, NA, 60146.86, 56845.88, 
63181.13, 63704.80, 49140.22, 54538.14, 49411.32, 66059.73, 73147.55, 
55665.96, 66821.27, 66935.12, 54350.63, 48116.25, 67664.66, 64278.54, 
64555.03, 62463.60, 55831.53, 57392.61, 75727.00, 64839.50, 51009.78, 
65274.59, 63339.91, 62276.49, 66159.42, 58333.76, 60275.09) , A = 
as.factor(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)) , B = as.factor(c(1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0)), ID = as.factor(c(72,  73,  74,  75,  76, 78,  79,  86,  88,  
89,  90, 91,  92,  93,  94,  95,  96,  121, 122, 123, 124, 77,  80,  81, 
82,  83,  84,  98,  116, 117, 118, 119, 120, 125, 128, 100, 101, 102, 
103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 126, 127, 
72, 73, 74, 75, 76, 78, 79, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 121, 
122, 123, 124, 77, 80, 81, 82, 83, 84, 98, 116, 117, 118, 119, 120, 125, 
128, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 
114, 115, 126, 127)))

Best regards,
Takahiro

On 9/18/15 10:41 AM, Thierry Onkelinx wrote:
> Dear Takahiro,
>
> Please send the output of dput(dataset). That's a lot easier to
> copy-paste into an R session.
>
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2015-09-18 16:40 GMT+02:00 Takahiro Fushimi <taka.6765 at gmail.com>:
>> The data set is as follows:
>>> dataset
>>             y A B  ID
>> 1   60625.19 0 1  72
>> 2   51088.38 0 1  73
>> 3   67283.03 0 1  74
>> 4   56550.54 0 1  75
>> 5         NA 0 1  76
>> 6         NA 0 1  78
>> 7   58720.44 0 1  79
>> 8   63939.01 0 1  86
>> 9   66298.32 0 1  88
>> 10  62662.15 0 1  89
>> 11  53604.41 0 1  90
>> 12  88338.55 0 1  91
>> 13  62818.78 0 1  92
>> 14  68696.71 0 1  93
>> 15  57433.98 0 1  94
>> 16  59105.99 0 1  95
>> 17  44801.97 0 1  96
>> 18  68655.48 0 1 121
>> 19  62645.16 0 1 122
>> 20  69409.15 0 1 123
>> 21  43568.70 0 1 124
>> 22  55693.21 1 1  77
>> 23  57322.63 1 1  80
>> 24  51095.55 1 1  81
>> 25  57660.41 1 1  82
>> 26  64128.63 1 1  83
>> 27  55216.42 1 1  84
>> 28  59945.17 1 1  98
>> 29  67284.31 1 1 116
>> 30  55401.13 1 1 117
>> 31  60471.59 1 1 118
>> 32        NA 1 1 119
>> 33  63633.07 1 1 120
>> 34  65939.14 1 1 125
>> 35        NA 1 1 128
>> 36  69488.38 2 1 100
>> 37  43950.50 2 1 101
>> 38  52782.99 2 1 102
>> 39  55674.94 2 1 103
>> 40  70130.25 2 1 104
>> 41  72560.25 2 1 105
>> 42  69297.95 2 1 106
>> 43  53188.98 2 1 107
>> 44  75687.53 2 1 108
>> 45  68242.23 2 1 109
>> 46  60696.15 2 1 110
>> 47  65087.04 2 1 112
>> 48  59377.71 2 1 113
>> 49  55055.45 2 1 114
>> 50  66673.40 2 1 115
>> 51  65933.37 2 1 126
>> 52  62636.56 2 1 127
>> 53  49606.80 0 0  72
>> 54  58668.13 0 0  73
>> 55  56694.13 0 0  74
>> 56        NA 0 0  75
>> 57        NA 0 0  76
>> 58  61928.95 0 0  78
>> 59  63208.84 0 0  79
>> 60  83786.71 0 0  86
>> 61  72727.53 0 0  88
>> 62  78873.45 0 0  89
>> 63  47482.32 0 0  90
>> 64  65967.84 0 0  91
>> 65  53228.25 0 0  92
>> 66  65699.59 0 0  93
>> 67  61792.81 0 0  94
>> 68  44816.72 0 0  95
>> 69  71048.06 0 0  96
>> 70  59671.84 0 0 121
>> 71  89513.43 0 0 122
>> 72  56972.30 0 0 123
>> 73  45439.25 0 0 124
>> 74  51357.83 1 0  77
>> 75        NA 1 0  80
>> 76  60146.86 1 0  81
>> 77  56845.88 1 0  82
>> 78  63181.13 1 0  83
>> 79  63704.80 1 0  84
>> 80  49140.22 1 0  98
>> 81  54538.14 1 0 116
>> 82  49411.32 1 0 117
>> 83  66059.73 1 0 118
>> 84  73147.55 1 0 119
>> 85  55665.96 1 0 120
>> 86  66821.27 1 0 125
>> 87  66935.12 1 0 128
>> 88  54350.63 2 0 100
>> 89  48116.25 2 0 101
>> 90  67664.66 2 0 102
>> 91  64278.54 2 0 103
>> 92  64555.03 2 0 104
>> 93  62463.60 2 0 105
>> 94  55831.53 2 0 106
>> 95  57392.61 2 0 107
>> 96  75727.00 2 0 108
>> 97  64839.50 2 0 109
>> 98  51009.78 2 0 110
>> 99  65274.59 2 0 112
>> 100 63339.91 2 0 113
>> 101 62276.49 2 0 114
>> 102 66159.42 2 0 115
>> 103 58333.76 2 0 126
>> 104 60275.09 2 0 127
>>
>> Best regards,
>> Takahiro
>>
>>
>> On 9/18/15 3:23 AM, Thierry Onkelinx wrote:
>>> The formula shouldn't be the problem. model.matrix() is clever enough
>>> to handle this. Have a look at the examples below.
>>>
>>> model.matrix(~ A + B + A * B, data= data.frame(A = 1, B = 1))
>>> model.matrix(~ A + B + A * B + B + A:B + B:A, data= data.frame(A = 1, B =
>>> 1))
>>>
>>> I suggest to give use a reproducible example of the problem so that we
>>> can invesigate what when wrong.
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given body
>>> of data. ~ John Tukey
>>>
>>>
>>> 2015-09-18 7:23 GMT+02:00 Ch? Lucero <chelucero at uchicago.edu>:
>>>> I don't know if this is causing the problem you're seeing, but A*B
>>>> expands
>>>> to A + B + A:B, so your model right now is R ~ A + B + A + B + A:B +
>>>> (1|S).
>>>>
>>>> On Thu, Sep 17, 2015 at 5:53 PM Takahiro Fushimi <taka.6765 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi everyone,
>>>>>
>>>>> I have been working on a linear mixed effect model by using lmer()
>>>>> function, but I got an error saying that the fitted model is not
>>>>> identifiable.
>>>>>
>>>>> The data set includes the following variables:
>>>>> y = a numeric variable
>>>>> factorA = a 3-level categorical variable
>>>>> factorB = a 2-level categorical variable
>>>>> subjectID = subject id number. 2 measurements of y for each subject
>>>>>
>>>>> R code and output are as follows:
>>>>>    > (result <- lmer(y ~ factorA + factorB + factorA*factorB +
>>>>> (1|subjectID)))
>>>>> Linear mixed model fit by REML ['merModLmerTest']
>>>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>>>> REML criterion at convergence: 1928.966
>>>>> Random effects:
>>>>>     Groups    Name        Std.Dev.
>>>>>     subjectID (Intercept) 4711
>>>>>     Residual              7688
>>>>> Number of obs: 97, groups:  subjectID, 51
>>>>> Fixed Effects:
>>>>>          (Intercept)           factorA1           factorA2 factorB1
>>>>> factorA1:factorB1  factorA2:factorB1
>>>>>                62411              -2700              -1124
>>>>> -1037               1279               2482
>>>>>    > summary(result)
>>>>> Model is not identifiable...
>>>>> summary from lme4 is returned
>>>>> some computational error has occurred in lmerTest
>>>>> Linear mixed model fit by REML ['lmerMod']
>>>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>>>>
>>>>> REML criterion at convergence: 1929
>>>>>
>>>>> Scaled residuals:
>>>>>         Min       1Q   Median       3Q      Max
>>>>> -1.93423 -0.62611  0.01837  0.48887  2.73380
>>>>>
>>>>> Random effects:
>>>>>     Groups    Name        Variance Std.Dev.
>>>>>     subjectID (Intercept) 22194074 4711
>>>>>     Residual              59108495 7688
>>>>> Number of obs: 97, groups:  subjectID, 51
>>>>>
>>>>> Fixed effects:
>>>>>                      Estimate Std. Error t value
>>>>> (Intercept)          62411       2065  30.227
>>>>> factorA1             -2700       3238  -0.834
>>>>> factorA2             -1124       3008  -0.374
>>>>> factorB1             -1037       2512  -0.413
>>>>> factorA1:factorB1     1279       4013   0.319
>>>>> factorA2:factorB1     2482       3642   0.681
>>>>>
>>>>> Correlation of Fixed Effects:
>>>>>                (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
>>>>> factorA1    -0.638
>>>>> factorA2    -0.687  0.438
>>>>> factorB1    -0.608  0.388  0.418
>>>>> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
>>>>> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>>>>>    >
>>>>>
>>>>> Could anyone give me some idea of why this unidentifiability problem
>>>>> happens and how to fix it?
>>>>> Any help would be appreciated.
>>>>>
>>>>> Best regards,
>>>>> Takahiro
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Takahiro Fushimi
>> Columbia University in the City of New York
>> Master of Arts in Statistics
>>

-- 
Takahiro Fushimi
Columbia University in the City of New York
Master of Arts in Statistics


From thierry.onkelinx at inbo.be  Fri Sep 18 17:15:56 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 18 Sep 2015 17:15:56 +0200
Subject: [R-sig-ME] Unidentifiable model in lmer
In-Reply-To: <55FC28EC.5090705@gmail.com>
References: <55FB3638.8070708@gmail.com>
	<CAJOWFj_mYja2rBsgCGd=8Lj6rLy9=tuBFNF1pqMdT49kC3oSWQ@mail.gmail.com>
	<CAJuCY5xk8758TtTJZ58m_woGg75DnqJR-Jpet4yPcXc64q7hiw@mail.gmail.com>
	<55FC224A.4070405@gmail.com>
	<CAJuCY5z2T1VXYBkGQCWRu0hmeE=D4Cy74conQ6F8EeBk80X+EQ@mail.gmail.com>
	<55FC28EC.5090705@gmail.com>
Message-ID: <CAJuCY5x_1tM0reoTLyyDOGANELRRr++NKCiTUgj4fNGBmyXy6w@mail.gmail.com>

Yes, this works.

library(lme4)
result <- lmer(y ~ A * B + (1|ID), data = dataset)
summary(result) # works fine
library(lmerTest)
summary(result) # works fine
result <- lmer(y ~ A * B + (1|ID), data = dataset)
summary(result) # yields "Model is not identifiable..."

This might be due to the fact that ID is nested in A. I recommend that
you contact the authors of lmerTest about this problem.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-18 17:08 GMT+02:00 Takahiro Fushimi <taka.6765 at gmail.com>:
> Sorry about it. Does this work?
>
> dataset <- data.frame(y = c(60625.19, 51088.38, 67283.03, 56550.54, NA,
> NA, 58720.44,63939.01, 66298.32, 62662.15, 53604.41, 88338.55, 62818.78,
> 68696.71,57433.98, 59105.99, 44801.97, 68655.48, 62645.16, 69409.15,
> 43568.70,55693.21, 57322.63, 51095.55, 57660.41, 64128.63, 55216.42,
> 59945.17,67284.31, 55401.13, 60471.59, NA, 63633.07, 65939.14,NA, 69488.38,
> 43950.50, 52782.99, 55674.94, 70130.25, 72560.25, 69297.95, 53188.98,
> 75687.53, 68242.23, 60696.15, 65087.04, 59377.71, 55055.45, 66673.40,
> 65933.37, 62636.56, 49606.80, 58668.13, 56694.13, NA, NA, 61928.95,63208.84,
> 83786.71, 72727.53, 78873.45, 47482.32, 65967.84, 53228.25, 65699.59,
> 61792.81, 44816.72, 71048.06, 59671.84, 89513.43, 56972.30, 45439.25,
> 51357.83, NA, 60146.86, 56845.88, 63181.13, 63704.80, 49140.22, 54538.14,
> 49411.32, 66059.73, 73147.55, 55665.96, 66821.27, 66935.12, 54350.63,
> 48116.25, 67664.66, 64278.54, 64555.03, 62463.60, 55831.53, 57392.61,
> 75727.00, 64839.50, 51009.78, 65274.59, 63339.91, 62276.49, 66159.42,
> 58333.76, 60275.09) , A = as.factor(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)) , B = as.factor(c(1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0)), ID = as.factor(c(72,  73,  74,  75,  76, 78,  79,  86,  88,  89,  90,
> 91,  92,  93,  94,  95,  96,  121, 122, 123, 124, 77,  80,  81, 82,  83,
> 84,  98,  116, 117, 118, 119, 120, 125, 128, 100, 101, 102, 103, 104, 105,
> 106, 107, 108, 109, 110, 112, 113, 114, 115, 126, 127, 72, 73, 74, 75, 76,
> 78, 79, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 121, 122, 123, 124, 77, 80,
> 81, 82, 83, 84, 98, 116, 117, 118, 119, 120, 125, 128, 100, 101, 102, 103,
> 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 126, 127)))
>
> Best regards,
> Takahiro
>
>
> On 9/18/15 10:41 AM, Thierry Onkelinx wrote:
>>
>> Dear Takahiro,
>>
>> Please send the output of dput(dataset). That's a lot easier to
>> copy-paste into an R session.
>>
>> Best regards,
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2015-09-18 16:40 GMT+02:00 Takahiro Fushimi <taka.6765 at gmail.com>:
>>>
>>> The data set is as follows:
>>>>
>>>> dataset
>>>
>>>             y A B  ID
>>> 1   60625.19 0 1  72
>>> 2   51088.38 0 1  73
>>> 3   67283.03 0 1  74
>>> 4   56550.54 0 1  75
>>> 5         NA 0 1  76
>>> 6         NA 0 1  78
>>> 7   58720.44 0 1  79
>>> 8   63939.01 0 1  86
>>> 9   66298.32 0 1  88
>>> 10  62662.15 0 1  89
>>> 11  53604.41 0 1  90
>>> 12  88338.55 0 1  91
>>> 13  62818.78 0 1  92
>>> 14  68696.71 0 1  93
>>> 15  57433.98 0 1  94
>>> 16  59105.99 0 1  95
>>> 17  44801.97 0 1  96
>>> 18  68655.48 0 1 121
>>> 19  62645.16 0 1 122
>>> 20  69409.15 0 1 123
>>> 21  43568.70 0 1 124
>>> 22  55693.21 1 1  77
>>> 23  57322.63 1 1  80
>>> 24  51095.55 1 1  81
>>> 25  57660.41 1 1  82
>>> 26  64128.63 1 1  83
>>> 27  55216.42 1 1  84
>>> 28  59945.17 1 1  98
>>> 29  67284.31 1 1 116
>>> 30  55401.13 1 1 117
>>> 31  60471.59 1 1 118
>>> 32        NA 1 1 119
>>> 33  63633.07 1 1 120
>>> 34  65939.14 1 1 125
>>> 35        NA 1 1 128
>>> 36  69488.38 2 1 100
>>> 37  43950.50 2 1 101
>>> 38  52782.99 2 1 102
>>> 39  55674.94 2 1 103
>>> 40  70130.25 2 1 104
>>> 41  72560.25 2 1 105
>>> 42  69297.95 2 1 106
>>> 43  53188.98 2 1 107
>>> 44  75687.53 2 1 108
>>> 45  68242.23 2 1 109
>>> 46  60696.15 2 1 110
>>> 47  65087.04 2 1 112
>>> 48  59377.71 2 1 113
>>> 49  55055.45 2 1 114
>>> 50  66673.40 2 1 115
>>> 51  65933.37 2 1 126
>>> 52  62636.56 2 1 127
>>> 53  49606.80 0 0  72
>>> 54  58668.13 0 0  73
>>> 55  56694.13 0 0  74
>>> 56        NA 0 0  75
>>> 57        NA 0 0  76
>>> 58  61928.95 0 0  78
>>> 59  63208.84 0 0  79
>>> 60  83786.71 0 0  86
>>> 61  72727.53 0 0  88
>>> 62  78873.45 0 0  89
>>> 63  47482.32 0 0  90
>>> 64  65967.84 0 0  91
>>> 65  53228.25 0 0  92
>>> 66  65699.59 0 0  93
>>> 67  61792.81 0 0  94
>>> 68  44816.72 0 0  95
>>> 69  71048.06 0 0  96
>>> 70  59671.84 0 0 121
>>> 71  89513.43 0 0 122
>>> 72  56972.30 0 0 123
>>> 73  45439.25 0 0 124
>>> 74  51357.83 1 0  77
>>> 75        NA 1 0  80
>>> 76  60146.86 1 0  81
>>> 77  56845.88 1 0  82
>>> 78  63181.13 1 0  83
>>> 79  63704.80 1 0  84
>>> 80  49140.22 1 0  98
>>> 81  54538.14 1 0 116
>>> 82  49411.32 1 0 117
>>> 83  66059.73 1 0 118
>>> 84  73147.55 1 0 119
>>> 85  55665.96 1 0 120
>>> 86  66821.27 1 0 125
>>> 87  66935.12 1 0 128
>>> 88  54350.63 2 0 100
>>> 89  48116.25 2 0 101
>>> 90  67664.66 2 0 102
>>> 91  64278.54 2 0 103
>>> 92  64555.03 2 0 104
>>> 93  62463.60 2 0 105
>>> 94  55831.53 2 0 106
>>> 95  57392.61 2 0 107
>>> 96  75727.00 2 0 108
>>> 97  64839.50 2 0 109
>>> 98  51009.78 2 0 110
>>> 99  65274.59 2 0 112
>>> 100 63339.91 2 0 113
>>> 101 62276.49 2 0 114
>>> 102 66159.42 2 0 115
>>> 103 58333.76 2 0 126
>>> 104 60275.09 2 0 127
>>>
>>> Best regards,
>>> Takahiro
>>>
>>>
>>> On 9/18/15 3:23 AM, Thierry Onkelinx wrote:
>>>>
>>>> The formula shouldn't be the problem. model.matrix() is clever enough
>>>> to handle this. Have a look at the examples below.
>>>>
>>>> model.matrix(~ A + B + A * B, data= data.frame(A = 1, B = 1))
>>>> model.matrix(~ A + B + A * B + B + A:B + B:A, data= data.frame(A = 1, B
>>>> =
>>>> 1))
>>>>
>>>> I suggest to give use a reproducible example of the problem so that we
>>>> can invesigate what when wrong.
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no
>>>> more than asking him to perform a post-mortem examination: he may be
>>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body
>>>> of data. ~ John Tukey
>>>>
>>>>
>>>> 2015-09-18 7:23 GMT+02:00 Ch? Lucero <chelucero at uchicago.edu>:
>>>>>
>>>>> I don't know if this is causing the problem you're seeing, but A*B
>>>>> expands
>>>>> to A + B + A:B, so your model right now is R ~ A + B + A + B + A:B +
>>>>> (1|S).
>>>>>
>>>>> On Thu, Sep 17, 2015 at 5:53 PM Takahiro Fushimi <taka.6765 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi everyone,
>>>>>>
>>>>>> I have been working on a linear mixed effect model by using lmer()
>>>>>> function, but I got an error saying that the fitted model is not
>>>>>> identifiable.
>>>>>>
>>>>>> The data set includes the following variables:
>>>>>> y = a numeric variable
>>>>>> factorA = a 3-level categorical variable
>>>>>> factorB = a 2-level categorical variable
>>>>>> subjectID = subject id number. 2 measurements of y for each subject
>>>>>>
>>>>>> R code and output are as follows:
>>>>>>    > (result <- lmer(y ~ factorA + factorB + factorA*factorB +
>>>>>> (1|subjectID)))
>>>>>> Linear mixed model fit by REML ['merModLmerTest']
>>>>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>>>>> REML criterion at convergence: 1928.966
>>>>>> Random effects:
>>>>>>     Groups    Name        Std.Dev.
>>>>>>     subjectID (Intercept) 4711
>>>>>>     Residual              7688
>>>>>> Number of obs: 97, groups:  subjectID, 51
>>>>>> Fixed Effects:
>>>>>>          (Intercept)           factorA1           factorA2 factorB1
>>>>>> factorA1:factorB1  factorA2:factorB1
>>>>>>                62411              -2700              -1124
>>>>>> -1037               1279               2482
>>>>>>    > summary(result)
>>>>>> Model is not identifiable...
>>>>>> summary from lme4 is returned
>>>>>> some computational error has occurred in lmerTest
>>>>>> Linear mixed model fit by REML ['lmerMod']
>>>>>> Formula: y ~ factorA + factorB + factorA * factorB + (1 | subjectID)
>>>>>>
>>>>>> REML criterion at convergence: 1929
>>>>>>
>>>>>> Scaled residuals:
>>>>>>         Min       1Q   Median       3Q      Max
>>>>>> -1.93423 -0.62611  0.01837  0.48887  2.73380
>>>>>>
>>>>>> Random effects:
>>>>>>     Groups    Name        Variance Std.Dev.
>>>>>>     subjectID (Intercept) 22194074 4711
>>>>>>     Residual              59108495 7688
>>>>>> Number of obs: 97, groups:  subjectID, 51
>>>>>>
>>>>>> Fixed effects:
>>>>>>                      Estimate Std. Error t value
>>>>>> (Intercept)          62411       2065  30.227
>>>>>> factorA1             -2700       3238  -0.834
>>>>>> factorA2             -1124       3008  -0.374
>>>>>> factorB1             -1037       2512  -0.413
>>>>>> factorA1:factorB1     1279       4013   0.319
>>>>>> factorA2:factorB1     2482       3642   0.681
>>>>>>
>>>>>> Correlation of Fixed Effects:
>>>>>>                (Intr) fctrA1 fctrA2 fctrB1 fA1:B1
>>>>>> factorA1    -0.638
>>>>>> factorA2    -0.687  0.438
>>>>>> factorB1    -0.608  0.388  0.418
>>>>>> fctrA1:fcB1  0.381 -0.601 -0.262 -0.626
>>>>>> fctrA2:fcB1  0.420 -0.268 -0.606 -0.690  0.432
>>>>>>    >
>>>>>>
>>>>>> Could anyone give me some idea of why this unidentifiability problem
>>>>>> happens and how to fix it?
>>>>>> Any help would be appreciated.
>>>>>>
>>>>>> Best regards,
>>>>>> Takahiro
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> --
>>> Takahiro Fushimi
>>> Columbia University in the City of New York
>>> Master of Arts in Statistics
>>>
>
> --
> Takahiro Fushimi
> Columbia University in the City of New York
> Master of Arts in Statistics
>


From karraspito at yahoo.es  Sat Sep 19 00:26:20 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Fri, 18 Sep 2015 22:26:20 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm: Fixing the priors in multivariate response
 models without random effects
Message-ID: <970929744.6502.1442615180938.JavaMail.yahoo@mail.yahoo.com>


?? Hello all,
?? I have managed to pretty much understand the MCMCglmm function, at least to the point of being able to write a model with just a single response categorical variable and run it. It can be done without any need to specify any priors. However, when I try to run a more complicated model with a bivariate response, the problems start. 
?? This is the model I am trying to run and the error message I get:
testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,singular.ok=TRUE)

????????????????????? MCMC iteration = 0

? Acceptance ratio for latent scores = 0.000154

????????????????????? MCMC iteration = 1000

? Acceptance ratio for latent scores = 0.211168
Error in MCMCglmm(cbind(natapshort, nataplong) ~ gender + age + religion +? : 
? Mixed model equations singular: use a (stronger) prior


So I need to define my own priors. As I am still in the testing stage, I tried some simple ones found in the CourseNotes. Also from the CourseNotes and other sources, I understand that the term G refers to random effects, so I should not include it. Then I should include B and R, am I right? I haven't been able to find very clear information about what G, B and R refer to.
?? I have tried this:? 
?? prior<- list(B= list(B1 = list(V = diag(2), n = 1.002)),R = list(V = diag(2), n = 1.002))
??? And this is what I get:
?? testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age????? +gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr????? +religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,????? rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,prior=prior,singular.ok=TRUE)
Error in priorformat(if (NOpriorG) { : 
? V is the wrong dimension for some prior$G/prior$R elements

After getting this error, I have tried adding another five B terms (as I have 6 explanatory variables), but the result is tha same. 


If I try just with G and B:
prior<- list(G = list(G1 = list(V = diag(2), n = 1.002)),B = list(V = diag(2), n = 1.002))
>testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age?? +gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr?? +religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,?? rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,prior=prior)

Error in MCMCglmm(cbind(natapshort, nataplong) ~ gender + age + religion +? : 
? either both or neither R and G structures need a prior

?? I am getting crazy. Could anybody shed some light on the priors' issue and help me find some simple ones that can make my model work? I don't even know where to look any more, I have read plenty of sources and documents, but I haven't got any clear conclusion yet.
?? Thank you very much.?? Best wishes,?? Iker
 ?__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Fri Sep 18 08:04:56 2015
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Fri, 18 Sep 2015 16:04:56 +1000
Subject: [R-sig-ME] Factor response and explanatory variables
In-Reply-To: <1733583610.1416712.1442499405295.JavaMail.yahoo@mail.yahoo.com>
References: <1733583610.1416712.1442499405295.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.LMD.2.00.1509181549360.26815@orpheus.qimr.edu.au>

On Fri, 18 Sep 2015, Iker Vaquero Alba wrote:
> The problem is that all my variables are factors

You might consider path analysis/SEM using polychoric correlations, 
especially if you have multiple ordinal outcomes of interest. In R, 
lavaan, OpenMx, (sem plus polycor).

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From orzack at freshpond.org  Fri Sep 18 17:33:45 2015
From: orzack at freshpond.org (Steven Orzack)
Date: Fri, 18 Sep 2015 11:33:45 -0400
Subject: [R-sig-ME] Testing a trend across possibly non-independent
	estimates, take 2
Message-ID: <55FC2ED9.9090705@freshpond.org>

I have longitudinal data on Health (0/1) for a set of individuals, each 
of which has a cohort ID (defined by birth year). Each individual is 
assessed for health for a range of ages. Call the data frame 
longitudinal.df, which looks like

ID Age Cohort Health

individual_ID_1 age cohort health_at_age
individual_ID_1 age+1 cohort health_at_age+1
individual_ID_2 age cohort health_at_age
individual_ID_2 age+1 cohort health_at_age+1
etc.

if we fit, say,

glmer(Health ~ Cohort:as.factor(Age) + (Cohort|ID), data = 
longitudinal.df, family = binomial)

we get a set of age-specific slopes:

Cohort:as.factor(Age)64
Cohort:as.factor(Age)66
.
.
.
Cohort:as.factor(Age)92
Cohort:as.factor(Age)94

each estimates the slope on the logit scale of the regression between 
health (y) and cohort (x) for a given age.

This model has a much lower AIC than the model without age-specific 
slopes. This means that there is support for the claim that there is 
heterogeneity across ages with respect to slope.

I have an external hypothesis that the trend of these age-specific 
slopes over age is increasing (with younger ages having negative slopes 
and older ages having positive slopes).


How do I correctly test for an increasing trend over ages of the 
age-specific regression slope estimates derived from the glmer model fit?

many thanks!
-- 
Steven Orzack


From j.hadfield at ed.ac.uk  Mon Sep 21 12:48:49 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 21 Sep 2015 11:48:49 +0100
Subject: [R-sig-ME] MCMCglmm: Fixing the priors in multivariate response
 models without random effects
In-Reply-To: <970929744.6502.1442615180938.JavaMail.yahoo@mail.yahoo.com>
References: <970929744.6502.1442615180938.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20150921114849.51511t92m0dvusuo@www.staffmail.ed.ac.uk>

Hi,

The issue is that both outcomes are binary and you are trying to  
estimate an unstructured residual covariance matrix. The diagonal  
elements (the variances) are not identifiable and so need to be  
constrained. The simplest method is to constrain the matrix to a  
correlation matrix using corg(trait):units.

Its hard to say without knowing what the data are, but I would think  
you need to fit trait in the fixed effect part of the model together  
with an interaction between trait and other predictors.

Also, I would recommend using family="threshold" rather than  
family="categorical" for bivariate problems. I've given the reasons  
for this in older posts. For example, the probit section of:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html

Regarding the correct dimension of the prior for the fixed effects, B  
should be equal to the number of fixed effects fitted. I can't see how  
many you have, but definitely more than 2: it looks closer to 20.

Cheers,

Jarrod





Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Fri, 18 Sep 2015  
22:26:20 +0000 (UTC):

>
> ?? Hello all,
> ?? I have managed to pretty much understand the MCMCglmm function,  
> at least to the point of being able to write a model with just a  
> single response categorical variable and run it. It can be done  
> without any need to specify any priors. However, when I try to run a  
> more complicated model with a bivariate response, the problems start.
> ?? This is the model I am trying to run and the error message I get:
> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,singular.ok=TRUE)
>
> ????????????????????? MCMC iteration = 0
>
> ? Acceptance ratio for latent scores = 0.000154
>
> ????????????????????? MCMC iteration = 1000
>
> ? Acceptance ratio for latent scores = 0.211168
> Error in MCMCglmm(cbind(natapshort, nataplong) ~ gender + age + religion +? :
> ? Mixed model equations singular: use a (stronger) prior
>
>
> So I need to define my own priors. As I am still in the testing  
> stage, I tried some simple ones found in the CourseNotes. Also from  
> the CourseNotes and other sources, I understand that the term G  
> refers to random effects, so I should not include it. Then I should  
> include B and R, am I right? I haven't been able to find very clear  
> information about what G, B and R refer to.
> ?? I have tried this:?
> ?? prior<- list(B= list(B1 = list(V = diag(2), n = 1.002)),R =  
> list(V = diag(2), n = 1.002))
> ??? And this is what I get:
> ??  
> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age????? +gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr????? +religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,?????  
> rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,prior=prior,singular.ok=TRUE)
> Error in priorformat(if (NOpriorG) { :
> ? V is the wrong dimension for some prior$G/prior$R elements
>
> After getting this error, I have tried adding another five B terms  
> (as I have 6 explanatory variables), but the result is tha same.
>
>
> If I try just with G and B:
> prior<- list(G = list(G1 = list(V = diag(2), n = 1.002)),B = list(V  
> = diag(2), n = 1.002))
>> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age?? +gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr?? +religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,??  
>> rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,prior=prior)
>
> Error in MCMCglmm(cbind(natapshort, nataplong) ~ gender + age + religion +? :
> ? either both or neither R and G structures need a prior
>
> ?? I am getting crazy. Could anybody shed some light on the priors'  
> issue and help me find some simple ones that can make my model work?  
> I don't even know where to look any more, I have read plenty of  
> sources and documents, but I haven't got any clear conclusion yet.
> ?? Thank you very much.?? Best wishes,?? Iker
>  ?__________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From karraspito at yahoo.es  Mon Sep 21 13:23:52 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Mon, 21 Sep 2015 11:23:52 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm: Fixing the priors in multivariate response
 models without random effects
In-Reply-To: <20150921114849.51511t92m0dvusuo@www.staffmail.ed.ac.uk>
References: <20150921114849.51511t92m0dvusuo@www.staffmail.ed.ac.uk>
Message-ID: <1140751033.1172280.1442834632426.JavaMail.yahoo@mail.yahoo.com>

?

     De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
 Para: Iker Vaquero Alba <karraspito at yahoo.es> 
CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Enviado: Lunes 21 de septiembre de 2015 11:48
 Asunto: Re: [R-sig-ME] MCMCglmm: Fixing the priors in multivariate response models without random effects
   
Hi,

The issue is that both outcomes are binary and you are trying to? 
estimate an unstructured residual covariance matrix. The diagonal? 
elements (the variances) are not identifiable and so need to be? 
constrained. The simplest method is to constrain the matrix to a? 
correlation matrix using corg(trait):units.
Dear Jarrod, 

?? Thank you so much for your invaluable help. I'm not sure I understand why "both outcomes are binary". My two dependent variables, as well as some of the explanatory ones, are multinomial, at least as far as I can understand: they are valuations from 1 to 5 given to different attributes by a group of volunteers. 


Its hard to say without knowing what the data are, but I would think? 
you need to fit trait in the fixed effect part of the model together? 
with an interaction between trait and other predictors.
The data are as follows: 
Response variables: 
natapshort and nataplong: both are categorical and multinomial variables, consisting on values from 1 to 5, depending on the importance several volunteers give to natural appearance on their potential partners, either for a short term relationship or for a longer commitment.Explanatory variables:
gender: factor with 3 levels (male, female, other). Gender of the participants.age: factor with 6 levels. Age of the participants, classified by age ranges.religion: factor with 2 levels (yes or no).sexor: factor with 3 levels. Sexual orientation of the participants.selfattr: factor with 5 levels. Value (from 1 to 5) that each participants gives to their own attractiveness.partnerattr: factor with 5 levels. Value (from 1 to 5) that each participant considers as the minimum attractiveness for a person to be considered as a potential partner.

When you say I need to "fit trait in the fixed effect part of the model together with an interaction between trait and other predictors.", you mean physically include the term "trait" in the model, as I have seen in many places, or you mean just including 2-way interactions between explanatory variables (that has been done already)??
Also, I would recommend using family="threshold" rather than? 
family="categorical" for bivariate problems. I've given the reasons? 
for this in older posts. For example, the probit section of:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021875.html
Ok, thank you very much for that, I'll have a look to understand the reasons.

 Regarding the correct dimension of the prior for the fixed effects, B? should be equal to the number of fixed effects fitted. I can't see how? 
many you have, but definitely more than 2: it looks closer to 20.
Cheers,

Jarrod
Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Fri, 18 Sep 2015? 
22:26:20 +0000 (UTC):

Just another question: should it be equal to the number of single fixed effects fitted (six in this case), or each two-way interaction (for example, gender:selfattr) qualifies as a new fixed effect (in which case I would have 21)?
Also, I have just read in a very useful document I've found from Tufts University, that when writing the priors, you need to fit an R structure for each fixed effect and a G structure for each random effect. According to that, I would have to fit 21 (6?) R structures and no G structures at all. But you say I have to fit 21 B structures as well. So, if R is the structure of fixed effects and G the structure of random effects, what is B?
Thank you very much again for your patience and huge help, and sorry for the endless questions.
Best wishes,Iker

__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? Animal sexual signals: Do they maximise or optimise information content?





>
> ?? Hello all,
> ?? I have managed to pretty much understand the MCMCglmm function,? 
> at least to the point of being able to write a model with just a? 
> single response categorical variable and run it. It can be done? 
> without any need to specify any priors. However, when I try to run a? 
> more complicated model with a bivariate response, the problems start.
> ?? This is the model I am trying to run and the error message I get:
> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,singular.ok=TRUE)
>
> ????????????????????? MCMC iteration = 0
>
> ? Acceptance ratio for latent scores = 0.000154
>
> ????????????????????? MCMC iteration = 1000
>
> ? Acceptance ratio for latent scores = 0.211168
> Error in MCMCglmm(cbind(natapshort, nataplong) ~ gender + age + religion +? :
> ? Mixed model equations singular: use a (stronger) prior
>
>
> So I need to define my own priors. As I am still in the testing? 
> stage, I tried some simple ones found in the CourseNotes. Also from?
> the CourseNotes and other sources, I understand that the term G? 
> refers to random effects, so I should not include it. Then I should?
> include B and R, am I right? I haven't been able to find very clear?
> information about what G, B and R refer to.
> ?? I have tried this:?
> ?? prior<- list(B= list(B1 = list(V = diag(2), n = 1.002)),R =? 
> list(V = diag(2), n = 1.002))
> ??? And this is what I get:
> ??? 
> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age????? +gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr????? +religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,?????? 
> rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,prior=prior,singular.ok=TRUE)
> Error in priorformat(if (NOpriorG) { :
> ? V is the wrong dimension for some prior$G/prior$R elements
>
> After getting this error, I have tried adding another five B terms?
> (as I have 6 explanatory variables), but the result is tha same.
>
>
> If I try just with G and B:
> prior<- list(G = list(G1 = list(V = diag(2), n = 1.002)),B = list(V? 
> = diag(2), n = 1.002))
>> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age?? +gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr?? +religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,??? 
>> rcov=~us(trait):units,family=c("categorical","categorical"),data=extphen,nitt=10000,prior=prior)
>
> Error in MCMCglmm(cbind(natapshort, nataplong) ~ gender + age + religion +? :
> ? either both or neither R and G structures need a prior
>
> ?? I am getting crazy. Could anybody shed some light on the priors'? 
> issue and help me find some simple ones that can make my model work?? 
> I don't even know where to look any more, I have read plenty of? 
> sources and documents, but I haven't got any clear conclusion yet.
> ?? Thank you very much.?? Best wishes,?? Iker
>? ?__________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.





| ? |
| ? | ? | ? | ? | ? |
| Animal sexual signals: Do they maximise or optimise information content?Resumen  |
|  |
| Ver en eric.exeter.ac.uk | Vista previa por Yahoo |
|  |
| ? |


  
	[[alternative HTML version deleted]]


From francesco.sigona at unisalento.it  Mon Sep 21 13:55:50 2015
From: francesco.sigona at unisalento.it (Francesco Sigona)
Date: Mon, 21 Sep 2015 13:55:50 +0200
Subject: [R-sig-ME] using a continuous-valued variable as fixed effect
Message-ID: <55FFF046.4080907@unisalento.it>

Hi all,

I'm a newbie with linear mixed model.

I just would like to know if it is possible to use one or more variables 
assuming values in a continuous range (e.g. a frequency values in Hz) as 
fixed effects, in a linear mixed model, possibly together with (or 
without) categorical (binary) effects, using lmer4 package.

In case: how to do it and how to read the results, in terms of 
statistical significance?

Can anyone explain if in this case mixed models are actually different 
from a simple (multiple) linear regression?
Why should mixed models be preferred to linear regression in this case?

Thank you in advance.

Francesco

-- 
*Francesco SIGONA*
Electronics engineer 	
Piazza Filippo Muratore
73100 - Lecce - Italy 	<https://maps.google.com/maps?q=40.331002,18.156462>
tel.: +39 0832 335006
fax.: +39 0832 335007

============================================================
*Center for Interdisciplinary Research on Language (CRIL) 
<http://www.cril.unisalento.it> &
Cognitive Neuroscience of Language and Speech Sciences Lab (CNLSS) * 	
*Dipartimento di Studi umanistici
Universit? del Salento * 	

============================================================
*Laboratorio Diffuso di Ricerca Interdisciplinare Applicata alla Medicina
(DReAM) * 	


From heffner at umd.edu  Mon Sep 21 18:37:58 2015
From: heffner at umd.edu (Chris Heffner)
Date: Mon, 21 Sep 2015 16:37:58 +0000
Subject: [R-sig-ME] Convergence Error: 0 Fixed Correlations and More
Message-ID: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>

Hi,

I'm running a psychology experiment with a few fixed effects and random
factors, but for some of the models that I'm comparing I get an output that
looks something like this:

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: FW ~ FactorA + FactorB + FactorC + FactorA:FactorC +
FactorB:FactorC +      (1 | participant) + (1 + FactorC || item)
   Data: east.acc1.subset
Control: glmerControl(optCtrl = list(maxfun = 30000))

     AIC      BIC   logLik deviance df.resid
  1001.5   1066.9   -487.7    975.5     1120

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.8335 -0.3041  0.1416  0.3566  2.8851

Random effects:
 Groups      Name        Variance  Std.Dev.  Corr
 item     FactorCB       5.454e+00 2.3352985
             FactorCS       3.097e+00 1.7597629 -0.81
 item.1   (Intercept) 5.437e+00 2.3316731
 participant (Intercept) 2.595e-08 0.0001611
Number of obs: 1133, groups:  item, 55; participant, 23

(Intercept)            0.1928833  0.0006222   310.0   <2e-16 ***
FactorAInitial        1.8077886  0.0006222  2905.5   <2e-16 ***
FactorB150        -0.4506653  0.0006220  -724.5   <2e-16 ***
FactorB200        -0.5485114  0.0006220  -881.9   <2e-16 ***
FactorCS                 -0.3923921  0.0006221  -630.8   <2e-16 ***
FactorAInitial:FactorCS -0.0889474  0.0006221  -143.0   <2e-16 ***
FactorB150:FactorCS   0.1347207  0.0006221   216.6   <2e-16 ***
FactorB200:FactorCS   0.0682518  0.0006221   109.7   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) FAIn FB150 FB200 FCS FAI:FCS FB150:FCS
FAIntl 0.000
FB150 0.000  0.000
FB200 0.000  0.000  0.000
FCS       0.000  0.000  0.000  0.000
FaInt:FCS 0.000  0.000  0.000  0.000  0.000
FB150:FCS 0.000  0.000  0.000  0.000  0.000 0.000
FB200:FCS 0.000  0.000  0.000  0.000  0.000 0.000  0.000

convergence code: 0
Model failed to converge with max|grad| = 0.113738 (tol = 0.001, component
1)
Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?

I've tried look through my data, as my first thought was that data was
somehow miscoded, but I can't see anything that would be the matter.  A
more complicated version of the model had the same problem until I got rid
of a single participant (who seemed otherwise entirely unexceptional).  The
more complicated model now converges fine, but this simpler one now has
these issues.  I have an almost identical dataset that I've been doing
almost exactly the same models with that hasn't been giving me similar
problems.

Any thoughts?

Thank you,

Chris

	[[alternative HTML version deleted]]


From abfine at gmail.com  Mon Sep 21 20:58:55 2015
From: abfine at gmail.com (Alex Fine)
Date: Mon, 21 Sep 2015 14:58:55 -0400
Subject: [R-sig-ME] using a continuous-valued variable as fixed effect
In-Reply-To: <55FFF046.4080907@unisalento.it>
References: <55FFF046.4080907@unisalento.it>
Message-ID: <CAJ6ui+PBsL1m3Ay4ZCkkvczx64y6UTLToMKUbVe8bS1Ga8ox1Q@mail.gmail.com>

Hi Francesco,

Yes, MEMs can accommodate continuous-valued predictors, just like in
classical regression (GLMs).  It's also possible and very common to model
interactions between continuous and categorical predictors.  Their
interpretation is also essentially the same as in GLMs.  I'd recommend
Gelman and Hill (2007), Chapters 11-13 for a nice introduction.

hth,
Alex

On Mon, Sep 21, 2015 at 7:55 AM, Francesco Sigona <
francesco.sigona at unisalento.it> wrote:

> Hi all,
>
> I'm a newbie with linear mixed model.
>
> I just would like to know if it is possible to use one or more variables
> assuming values in a continuous range (e.g. a frequency values in Hz) as
> fixed effects, in a linear mixed model, possibly together with (or without)
> categorical (binary) effects, using lmer4 package.
>
> In case: how to do it and how to read the results, in terms of statistical
> significance?
>
> Can anyone explain if in this case mixed models are actually different
> from a simple (multiple) linear regression?
> Why should mixed models be preferred to linear regression in this case?
>
> Thank you in advance.
>
> Francesco
>
> --
> *Francesco SIGONA*
> Electronics engineer
> Piazza Filippo Muratore
> 73100 - Lecce - Italy   <
> https://maps.google.com/maps?q=40.331002,18.156462>
> tel.: +39 0832 335006
> fax.: +39 0832 335007
>
> ============================================================
> *Center for Interdisciplinary Research on Language (CRIL) <
> http://www.cril.unisalento.it> &
> Cognitive Neuroscience of Language and Speech Sciences Lab (CNLSS) *
> *Dipartimento di Studi umanistici
> Universit? del Salento *
>
> ============================================================
> *Laboratorio Diffuso di Ricerca Interdisciplinare Applicata alla Medicina
> (DReAM) *
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/
<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Sep 22 09:33:56 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 22 Sep 2015 09:33:56 +0200
Subject: [R-sig-ME] Convergence Error: 0 Fixed Correlations and More
In-Reply-To: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>
References: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>
Message-ID: <CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>

Dear Chris,

The correct syntax is (1 + FactorC | item) not (1 + FactorC || item).
Use a single |. I find the item.1 strange in the output. This might be
due to the syntax error.

The item random effect variances are quit high. You might have a
problem of quasi-complete separation. (1 + FactorC | item) might be
too complex for your data. Does (1 | item) converge?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-21 18:37 GMT+02:00 Chris Heffner <heffner at umd.edu>:
> Hi,
>
> I'm running a psychology experiment with a few fixed effects and random
> factors, but for some of the models that I'm comparing I get an output that
> looks something like this:
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: FW ~ FactorA + FactorB + FactorC + FactorA:FactorC +
> FactorB:FactorC +      (1 | participant) + (1 + FactorC || item)
>    Data: east.acc1.subset
> Control: glmerControl(optCtrl = list(maxfun = 30000))
>
>      AIC      BIC   logLik deviance df.resid
>   1001.5   1066.9   -487.7    975.5     1120
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.8335 -0.3041  0.1416  0.3566  2.8851
>
> Random effects:
>  Groups      Name        Variance  Std.Dev.  Corr
>  item     FactorCB       5.454e+00 2.3352985
>              FactorCS       3.097e+00 1.7597629 -0.81
>  item.1   (Intercept) 5.437e+00 2.3316731
>  participant (Intercept) 2.595e-08 0.0001611
> Number of obs: 1133, groups:  item, 55; participant, 23
>
> (Intercept)            0.1928833  0.0006222   310.0   <2e-16 ***
> FactorAInitial        1.8077886  0.0006222  2905.5   <2e-16 ***
> FactorB150        -0.4506653  0.0006220  -724.5   <2e-16 ***
> FactorB200        -0.5485114  0.0006220  -881.9   <2e-16 ***
> FactorCS                 -0.3923921  0.0006221  -630.8   <2e-16 ***
> FactorAInitial:FactorCS -0.0889474  0.0006221  -143.0   <2e-16 ***
> FactorB150:FactorCS   0.1347207  0.0006221   216.6   <2e-16 ***
> FactorB200:FactorCS   0.0682518  0.0006221   109.7   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) FAIn FB150 FB200 FCS FAI:FCS FB150:FCS
> FAIntl 0.000
> FB150 0.000  0.000
> FB200 0.000  0.000  0.000
> FCS       0.000  0.000  0.000  0.000
> FaInt:FCS 0.000  0.000  0.000  0.000  0.000
> FB150:FCS 0.000  0.000  0.000  0.000  0.000 0.000
> FB200:FCS 0.000  0.000  0.000  0.000  0.000 0.000  0.000
>
> convergence code: 0
> Model failed to converge with max|grad| = 0.113738 (tol = 0.001, component
> 1)
> Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
>
> I've tried look through my data, as my first thought was that data was
> somehow miscoded, but I can't see anything that would be the matter.  A
> more complicated version of the model had the same problem until I got rid
> of a single participant (who seemed otherwise entirely unexceptional).  The
> more complicated model now converges fine, but this simpler one now has
> these issues.  I have an almost identical dataset that I've been doing
> almost exactly the same models with that hasn't been giving me similar
> problems.
>
> Any thoughts?
>
> Thank you,
>
> Chris
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From heffner at umd.edu  Tue Sep 22 15:21:13 2015
From: heffner at umd.edu (Chris Heffner)
Date: Tue, 22 Sep 2015 13:21:13 +0000
Subject: [R-sig-ME] Convergence Error: 0 Fixed Correlations and More
In-Reply-To: <CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>
References: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>
	<CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>
Message-ID: <CA+6pzmf5UTY7WCJEveaJP11A1G838h4Lt-ZTf_tKTp_LN1mN5Q@mail.gmail.com>

Hello Thierry,

Thanks for the input!  The || syntax is intentional; it gets rid of the
correlation parameters between the random effects in the model.  This was
done based on my reading of the Bates, Kliegl, Vasishth, and Baayen
manuscript ("Parsimonious mixed models") from earlier this year as a way to
tamp down on overcomplexity.  However, changing it to a single pipe, (1 +
FactorC | item), does not affect convergence, although the warnings I get
change:

1: In vcov.merMod(object, use.hessian = use.hessian) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite or contains NA values: falling back to var-cov
estimated from RX
2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite or contains NA values: falling back to var-cov
estimated from RX1: In vcov.merMod(object, use.hessian = use.hessian) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite or contains NA values: falling back to var-cov
estimated from RX
2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite or contains NA values: falling back to var-cov
estimated from RX

(1 | item) converges... but so does (1 + FactorB + FactorC | item), which
to me seems to argue against model complexity being the cause.

Thank you,

Chris

On Tue, Sep 22, 2015 at 3:34 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Chris,
>
> The correct syntax is (1 + FactorC | item) not (1 + FactorC || item).
> Use a single |. I find the item.1 strange in the output. This might be
> due to the syntax error.
>
> The item random effect variances are quit high. You might have a
> problem of quasi-complete separation. (1 + FactorC | item) might be
> too complex for your data. Does (1 | item) converge?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2015-09-21 18:37 GMT+02:00 Chris Heffner <heffner at umd.edu>:
> > Hi,
> >
> > I'm running a psychology experiment with a few fixed effects and random
> > factors, but for some of the models that I'm comparing I get an output
> that
> > looks something like this:
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['glmerMod']
> >  Family: binomial  ( logit )
> > Formula: FW ~ FactorA + FactorB + FactorC + FactorA:FactorC +
> > FactorB:FactorC +      (1 | participant) + (1 + FactorC || item)
> >    Data: east.acc1.subset
> > Control: glmerControl(optCtrl = list(maxfun = 30000))
> >
> >      AIC      BIC   logLik deviance df.resid
> >   1001.5   1066.9   -487.7    975.5     1120
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -3.8335 -0.3041  0.1416  0.3566  2.8851
> >
> > Random effects:
> >  Groups      Name        Variance  Std.Dev.  Corr
> >  item     FactorCB       5.454e+00 2.3352985
> >              FactorCS       3.097e+00 1.7597629 -0.81
> >  item.1   (Intercept) 5.437e+00 2.3316731
> >  participant (Intercept) 2.595e-08 0.0001611
> > Number of obs: 1133, groups:  item, 55; participant, 23
> >
> > (Intercept)            0.1928833  0.0006222   310.0   <2e-16 ***
> > FactorAInitial        1.8077886  0.0006222  2905.5   <2e-16 ***
> > FactorB150        -0.4506653  0.0006220  -724.5   <2e-16 ***
> > FactorB200        -0.5485114  0.0006220  -881.9   <2e-16 ***
> > FactorCS                 -0.3923921  0.0006221  -630.8   <2e-16 ***
> > FactorAInitial:FactorCS -0.0889474  0.0006221  -143.0   <2e-16 ***
> > FactorB150:FactorCS   0.1347207  0.0006221   216.6   <2e-16 ***
> > FactorB200:FactorCS   0.0682518  0.0006221   109.7   <2e-16 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >             (Intr) FAIn FB150 FB200 FCS FAI:FCS FB150:FCS
> > FAIntl 0.000
> > FB150 0.000  0.000
> > FB200 0.000  0.000  0.000
> > FCS       0.000  0.000  0.000  0.000
> > FaInt:FCS 0.000  0.000  0.000  0.000  0.000
> > FB150:FCS 0.000  0.000  0.000  0.000  0.000 0.000
> > FB200:FCS 0.000  0.000  0.000  0.000  0.000 0.000  0.000
> >
> > convergence code: 0
> > Model failed to converge with max|grad| = 0.113738 (tol = 0.001,
> component
> > 1)
> > Model is nearly unidentifiable: very large eigenvalue
> >  - Rescale variables?
> >
> > I've tried look through my data, as my first thought was that data was
> > somehow miscoded, but I can't see anything that would be the matter.  A
> > more complicated version of the model had the same problem until I got
> rid
> > of a single participant (who seemed otherwise entirely unexceptional).
> The
> > more complicated model now converges fine, but this simpler one now has
> > these issues.  I have an almost identical dataset that I've been doing
> > almost exactly the same models with that hasn't been giving me similar
> > problems.
> >
> > Any thoughts?
> >
> > Thank you,
> >
> > Chris
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Sep 22 15:40:26 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 Sep 2015 09:40:26 -0400
Subject: [R-sig-ME] Convergence Error: 0 Fixed Correlations and More
In-Reply-To: <CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>
References: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>
	<CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>
Message-ID: <CABghstQ6Qx1XxdMDLYZEJTUPMQRwna1BwTt7LE_RYx7XyA8bzw@mail.gmail.com>

On Tue, Sep 22, 2015 at 3:33 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear Chris,
>
> The correct syntax is (1 + FactorC | item) not (1 + FactorC || item).
> Use a single |. I find the item.1 strange in the output. This might be
> due to the syntax error.

   Chris might be trying to suppress the correlations between
random-effect component:
the double-bar notation expands to (1|item) + (0 + FactorC | item),
but there's a problem here: there's not *really* a way to do this with the
double-bar syntax.  If FactorC has two levels (B and S), then the
right (tedious)
way to do this is

( 1|item)+(0+dummy(FactorC,"C")|item)

or maybe (?)

(0+dummy(FactorC,"C")|item)(0+dummy(FactorC,"C")|item)



(I think the current model is overparameterized)

>
> The item random effect variances are quit high. You might have a
> problem of quasi-complete separation. (1 + FactorC | item) might be
> too complex for your data. Does (1 | item) converge?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium


  [snip]

>
>
> 2015-09-21 18:37 GMT+02:00 Chris Heffner <heffner at umd.edu>:
>> Hi,
>>
>> I'm running a psychology experiment with a few fixed effects and random
>> factors, but for some of the models that I'm comparing I get an output that
>> looks something like this:
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>>  Family: binomial  ( logit )
>> Formula: FW ~ FactorA + FactorB + FactorC + FactorA:FactorC +
>> FactorB:FactorC +      (1 | participant) + (1 + FactorC || item)
>>    Data: east.acc1.subset
>> Control: glmerControl(optCtrl = list(maxfun = 30000))
>>
>>      AIC      BIC   logLik deviance df.resid
>>   1001.5   1066.9   -487.7    975.5     1120
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -3.8335 -0.3041  0.1416  0.3566  2.8851
>>
>> Random effects:
>>  Groups      Name        Variance  Std.Dev.  Corr
>>  item     FactorCB       5.454e+00 2.3352985
>>              FactorCS       3.097e+00 1.7597629 -0.81
>>  item.1   (Intercept) 5.437e+00 2.3316731
>>  participant (Intercept) 2.595e-08 0.0001611
>> Number of obs: 1133, groups:  item, 55; participant, 23
>>
>> (Intercept)            0.1928833  0.0006222   310.0   <2e-16 ***
>> FactorAInitial        1.8077886  0.0006222  2905.5   <2e-16 ***
>> FactorB150        -0.4506653  0.0006220  -724.5   <2e-16 ***
>> FactorB200        -0.5485114  0.0006220  -881.9   <2e-16 ***
>> FactorCS                 -0.3923921  0.0006221  -630.8   <2e-16 ***
>> FactorAInitial:FactorCS -0.0889474  0.0006221  -143.0   <2e-16 ***
>> FactorB150:FactorCS   0.1347207  0.0006221   216.6   <2e-16 ***
>> FactorB200:FactorCS   0.0682518  0.0006221   109.7   <2e-16 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>             (Intr) FAIn FB150 FB200 FCS FAI:FCS FB150:FCS
>> FAIntl 0.000
>> FB150 0.000  0.000
>> FB200 0.000  0.000  0.000
>> FCS       0.000  0.000  0.000  0.000
>> FaInt:FCS 0.000  0.000  0.000  0.000  0.000
>> FB150:FCS 0.000  0.000  0.000  0.000  0.000 0.000
>> FB200:FCS 0.000  0.000  0.000  0.000  0.000 0.000  0.000
>>
>> convergence code: 0
>> Model failed to converge with max|grad| = 0.113738 (tol = 0.001, component
>> 1)
>> Model is nearly unidentifiable: very large eigenvalue
>>  - Rescale variables?
>>
>> I've tried look through my data, as my first thought was that data was
>> somehow miscoded, but I can't see anything that would be the matter.  A
>> more complicated version of the model had the same problem until I got rid
>> of a single participant (who seemed otherwise entirely unexceptional).  The
>> more complicated model now converges fine, but this simpler one now has
>> these issues.  I have an almost identical dataset that I've been doing
>> almost exactly the same models with that hasn't been giving me similar
>> problems.
>>
>> Any thoughts?
>>
>> Thank you,
>>
>> Chris
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emmanuel.curis at parisdescartes.fr  Tue Sep 22 16:15:29 2015
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 22 Sep 2015 16:15:29 +0200
Subject: [R-sig-ME] Convergence Error: 0 Fixed Correlations and More
In-Reply-To: <CABghstQ6Qx1XxdMDLYZEJTUPMQRwna1BwTt7LE_RYx7XyA8bzw@mail.gmail.com>
References: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>
	<CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>
	<CABghstQ6Qx1XxdMDLYZEJTUPMQRwna1BwTt7LE_RYx7XyA8bzw@mail.gmail.com>
Message-ID: <20150922141529.GB25089@info124.pharmacie.univ-paris5.fr>

Speaking about this factor variables coding to have uncorrelated
random effects... Following Thierry Onkelinx's advice [thanks a lot
for this advice, by the way, I think I didn't answered yet, sorry], I
wrote down the models for a similar case, and it turned out that when
having uncorrelated random effects for all levels of a covariate, then
the Y variables were also uncorrelated, but it allowed different
variances for each level.

I thought one advantage of random effects was to introduce
correlations between observations taken for the same patient, so I
wonder if this trick really does what one expects (assuming I didn't
made mistakes, and I am not the only one to have this idea about
consequences of random effects), and that specifying special random
effects covariance matrix structures is less error-prone with nlme?

Best regards,

On Tue, Sep 22, 2015 at 09:40:26AM -0400, Ben Bolker wrote:
? On Tue, Sep 22, 2015 at 3:33 AM, Thierry Onkelinx
? <thierry.onkelinx at inbo.be> wrote:
? > Dear Chris,
? >
? > The correct syntax is (1 + FactorC | item) not (1 + FactorC || item).
? > Use a single |. I find the item.1 strange in the output. This might be
? > due to the syntax error.
? 
?    Chris might be trying to suppress the correlations between
? random-effect component:
? the double-bar notation expands to (1|item) + (0 + FactorC | item),
? but there's a problem here: there's not *really* a way to do this with the
? double-bar syntax.  If FactorC has two levels (B and S), then the
? right (tedious)
? way to do this is
? 
? ( 1|item)+(0+dummy(FactorC,"C")|item)
? 
? or maybe (?)
? 
? (0+dummy(FactorC,"C")|item)(0+dummy(FactorC,"C")|item)
? 
? 
? 
? (I think the current model is overparameterized)
? 
? >
? > The item random effect variances are quit high. You might have a
? > problem of quasi-complete separation. (1 + FactorC | item) might be
? > too complex for your data. Does (1 | item) converge?
? >
? > Best regards,
? >
? > ir. Thierry Onkelinx
? > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
? > and Forest
? > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
? > Kliniekstraat 25
? > 1070 Anderlecht
? > Belgium
? 
? 
?   [snip]
? 
? >
? >
? > 2015-09-21 18:37 GMT+02:00 Chris Heffner <heffner at umd.edu>:
? >> Hi,
? >>
? >> I'm running a psychology experiment with a few fixed effects and random
? >> factors, but for some of the models that I'm comparing I get an output that
? >> looks something like this:
? >>
? >> Generalized linear mixed model fit by maximum likelihood (Laplace
? >> Approximation) ['glmerMod']
? >>  Family: binomial  ( logit )
? >> Formula: FW ~ FactorA + FactorB + FactorC + FactorA:FactorC +
? >> FactorB:FactorC +      (1 | participant) + (1 + FactorC || item)
? >>    Data: east.acc1.subset
? >> Control: glmerControl(optCtrl = list(maxfun = 30000))
? >>
? >>      AIC      BIC   logLik deviance df.resid
? >>   1001.5   1066.9   -487.7    975.5     1120
? >>
? >> Scaled residuals:
? >>     Min      1Q  Median      3Q     Max
? >> -3.8335 -0.3041  0.1416  0.3566  2.8851
? >>
? >> Random effects:
? >>  Groups      Name        Variance  Std.Dev.  Corr
? >>  item     FactorCB       5.454e+00 2.3352985
? >>              FactorCS       3.097e+00 1.7597629 -0.81
? >>  item.1   (Intercept) 5.437e+00 2.3316731
? >>  participant (Intercept) 2.595e-08 0.0001611
? >> Number of obs: 1133, groups:  item, 55; participant, 23
? >>
? >> (Intercept)            0.1928833  0.0006222   310.0   <2e-16 ***
? >> FactorAInitial        1.8077886  0.0006222  2905.5   <2e-16 ***
? >> FactorB150        -0.4506653  0.0006220  -724.5   <2e-16 ***
? >> FactorB200        -0.5485114  0.0006220  -881.9   <2e-16 ***
? >> FactorCS                 -0.3923921  0.0006221  -630.8   <2e-16 ***
? >> FactorAInitial:FactorCS -0.0889474  0.0006221  -143.0   <2e-16 ***
? >> FactorB150:FactorCS   0.1347207  0.0006221   216.6   <2e-16 ***
? >> FactorB200:FactorCS   0.0682518  0.0006221   109.7   <2e-16 ***
? >> ---
? >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
? >>
? >> Correlation of Fixed Effects:
? >>             (Intr) FAIn FB150 FB200 FCS FAI:FCS FB150:FCS
? >> FAIntl 0.000
? >> FB150 0.000  0.000
? >> FB200 0.000  0.000  0.000
? >> FCS       0.000  0.000  0.000  0.000
? >> FaInt:FCS 0.000  0.000  0.000  0.000  0.000
? >> FB150:FCS 0.000  0.000  0.000  0.000  0.000 0.000
? >> FB200:FCS 0.000  0.000  0.000  0.000  0.000 0.000  0.000
? >>
? >> convergence code: 0
? >> Model failed to converge with max|grad| = 0.113738 (tol = 0.001, component
? >> 1)
? >> Model is nearly unidentifiable: very large eigenvalue
? >>  - Rescale variables?
? >>
? >> I've tried look through my data, as my first thought was that data was
? >> somehow miscoded, but I can't see anything that would be the matter.  A
? >> more complicated version of the model had the same problem until I got rid
? >> of a single participant (who seemed otherwise entirely unexceptional).  The
? >> more complicated model now converges fine, but this simpler one now has
? >> these issues.  I have an almost identical dataset that I've been doing
? >> almost exactly the same models with that hasn't been giving me similar
? >> problems.
? >>
? >> Any thoughts?
? >>
? >> Thank you,
? >>
? >> Chris
? >>
? >>         [[alternative HTML version deleted]]
? >>
? >> _______________________________________________
? >> R-sig-mixed-models at r-project.org mailing list
? >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >
? > _______________________________________________
? > R-sig-mixed-models at r-project.org mailing list
? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker at gmail.com  Tue Sep 22 16:49:42 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 Sep 2015 14:49:42 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Testing_a_trend_across_possibly_non-independ?=
	=?utf-8?q?ent=09estimates=2C_take_2?=
References: <55FC2ED9.9090705@freshpond.org>
Message-ID: <loom.20150922T164123-108@post.gmane.org>

Steven Orzack <orzack at ...> writes:

> 
> I have longitudinal data on Health (0/1) for a set of individuals, each 
> of which has a cohort ID (defined by birth year). Each individual is 
> assessed for health for a range of ages. Call the data frame 
> longitudinal.df, which looks like
> 
> ID Age Cohort Health
> 
> individual_ID_1 age cohort health_at_age
> individual_ID_1 age+1 cohort health_at_age+1
> individual_ID_2 age cohort health_at_age
> individual_ID_2 age+1 cohort health_at_age+1
> etc.
> 
> if we fit, say,
> 
> glmer(Health ~ Cohort:as.factor(Age) + (Cohort|ID), data = 
> longitudinal.df, family = binomial)
> 
> we get a set of age-specific slopes:
> 
> Cohort:as.factor(Age)64
> Cohort:as.factor(Age)66
> .
> .
> .
> Cohort:as.factor(Age)92
> Cohort:as.factor(Age)94
> 
> each estimates the slope on the logit scale of the regression between 
> health (y) and cohort (x) for a given age.
> 
> This model has a much lower AIC than the model without age-specific 
> slopes. This means that there is support for the claim that there is 
> heterogeneity across ages with respect to slope.
> 
> I have an external hypothesis that the trend of these age-specific 
> slopes over age is increasing (with younger ages having negative slopes 
> and older ages having positive slopes).
> 
> How do I correctly test for an increasing trend over ages of the 
> age-specific regression slope estimates derived from the glmer model fit?

   Hmm.  I'm not sure, but isn't this just a test of accelerating
slope, i.e. a quadratic model in age?  Constructing tests on sets
of parameters seems like the long way around.  I would suggest
making Age an *ordered* factor; then you will get the same number
of parameters, but the contrasts will be parameterized in terms
of orthogonal polynomials, so that the first few parameters will be
labeled L (linear), Q (quadratic), C (cubic) ... the significance
of the 'Q' term will be a reasonable test of change in slope with
age, and you can try to simplify the model by keeping only the first
few polynomial terms (e.g. equivalent to Cohort:poly(Age,3))


From bbolker at gmail.com  Tue Sep 22 17:10:02 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 Sep 2015 15:10:02 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Model_comparison_between_a_full_model_and_a_?=
	=?utf-8?q?random=09effect_reduced_model?=
References: <OF031747A9.EB27EE31-ONC1257EC4.00437237-C1257EC4.00437DFC@lotus.uzh.ch>
Message-ID: <loom.20150922T165005-276@post.gmane.org>

 <lei.he at ...> writes:

> 
> Dear all,
 
> I?m studying speaker idiosyncratic intensity variability in the
>  speech signal. My dataset looks like this:
 
> -nPVIm: numeric variable, quantifying intensity variability
 
> -tempo: factor with 5 levels, indicating five levels of speech rates
> (normal, slow, even slower, fast, fastest possible)
 
> -sentence: factor with 7 levels, i.e. seven different sentences
> 
> -speaker: factor 12 levels, i.e. twelve speakers
 
> I first I fitted speaker as a random effect with the rationale that
>  we cannot exhaust all the possible speakers:
 
> Full1 = lmer(nPVIm ~ tempo + (1|speaker) + (1|sentence), data=dat, REML=F)
 
> Then I fitted speaker as a fixed effect. The rationale is that if we
> apply ?nPVIm? in a close-set speaker identification or verification
> system, the speakers are fixed:
 
> Full2 = lmer(nPVIm~tempo + speaker + (1|sentence), data=dat, REML=F)
> 
> Next, I fitted a reduced model without speaker effect:
> 
> Reduced = lmer(nPVIm~tempo + (1|sentence), data=dat, REML=F)
 
> Finally, I used the anova () function to test whether Full1 and
>  Full2 are significantly different from Reduced.?
 
> Results showed that speaker as both random and fixed effects are
> significant, and the AICs of both Full1 and Full2 are lower than
> that of Reduced.
 
> Now we have received the reviewer?s comments. The reviewer wasn?t
> certain if it allows the models to be compared like this, especially
> anova(Full1, Reduced). So I would like to ask if our way of model
> fitting and comparisons is free from problems.
 
 [snip]

 A few things:

* the test of the model with and without a random effect of speaker
is testing whether there is any variation among speakers in their
baseline (normal-tempo) value of nPVIm.  Assuming that's what you want,
the test is *almost* OK but is actually conservative.

from Fox et al <http://ukcatalogue.oup.com/product/9780199672554.do>
chapter 13:

Boundary effects: statistical tests for linear models, including
GLMMs, typically assume that estimated parameters could be either
above or below their null value (e.g., slopes and intercepts can be
either positive or negative). This is not true for the random effect
variances in a (G)LMM?they must be positive?which causes problems with
standard hypothesis tests and confidence interval calculations
(Pinheiro and Bates 2000). In the simplest case of testing whether a
single random-effect variance is zero, the p-value derived from
standard theory is twice as large as it should be, leading to a
conservative test (you?re more likely to conclude that you can?t
reject the null hypothesis). To test the null hypothesis that the sole
random-effect variance in a model is equal to zero you can just divide
the p-value by 2. If you want to test hypotheses about random effects
in a model with more than one random effect you will need to simulate
the null hypothesis (section 13.6.2).

This is also discussed in Bolker 2008 (chapter 7, I think) and in
http://glmm.wikidot.com/faq

As far as testing between fixed and random effects specifications;
I don't normally do this (I don't think it's a question that often
makes sense), but econometricians have considered it: see
"Hausman tests"
https://en.wikipedia.org/wiki/Durbin%E2%80%93Wu%E2%80%93Hausman_test
   
I don't know if anyone has coded it for lme4 models.

From mashitahj at gmail.com  Tue Sep 22 00:24:25 2015
From: mashitahj at gmail.com (Mashitah Jusoh)
Date: Mon, 21 Sep 2015 17:24:25 -0500
Subject: [R-sig-ME] interaction and nested notation in lmer
Message-ID: <CAAUQNiJ5WtjDpOkkCx=ENMbG1T05XXRtLnddFB3zUrMMneropw@mail.gmail.com>

Hi,

I would like to ask about the notation to indicated nested and interaction
when using lmer function.

Here is my experiment look like:

I have 95 genotypes with 2 replications that were conducted in two years.
Some of the observation were missing, making the dataset unbalance. So, I
decided to use lmer function to fit the data to get the variance component
and will treat all components as random. The model that I am going to fit
is:

Y=mean + year + genotype + rep (nested in year)  + genotype*year + error

I am wondering how to write the command for nested and interaction term in
R using lmer function for this model? As far as I search in the internet,
the command for nested and interaction seems like using similar notation,
for example (1|year:rep) to show rep is nested within year (for random
effect) the same notation is used to indicate the interaction (for other
variables, such as genotype:year). Correct me if i am wrong. And, can you
give some clarification about this and also how lmer/ R works with
interaction and nested data?

Thank you

-- 
Mashitah Jusoh
Graduate Student
Department of Horticulture
UW-Madison

	[[alternative HTML version deleted]]


From karraspito at yahoo.es  Wed Sep 23 15:28:09 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Wed, 23 Sep 2015 13:28:09 +0000 (UTC)
Subject: [R-sig-ME] Interpreting a MCMCglmm model with a bivariate response
	variable
Message-ID: <948774124.422503.1443014889833.JavaMail.yahoo@mail.yahoo.com>


?? Hello all,
?? I am implementing a model with a multiple (bivariate) response variable using MCMCglmm. Both response variables and all the explanatory variables are categorical variables, with between 2 and 6 levels. The model is as follows:
?? 
testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~us(trait):units,family=c("threshold","threshold"),data=extphen,nitt=100000,singular.ok=TRUE)
?? And this is the summary of the model after all the iterations:
?? 
summary(testmodel1)??Iterations =3001:99991?Thinninginterval? = 10?Sample size? = 9700 ??DIC: ??R-structure:? ~us(trait):units????????????????????????????post.mean l-95% CI u-95% CI eff.sampnatapshort:natapshort.units??? 114108???992.1?? 213000??? 7.105nataplong:natapshort.units????? 33245???310.8??? 66300??? 4.656natapshort:nataplong.units ?????33245???310.8??? 66300??? 4.656nataplong:nataplong.units?????? 82964???671.5?? 155869??? 2.218??Location effects:cbind(natapshort, nataplong) ~ gender + age + religion + sexor + selfattr +partnerattr + gender:age + gender:religion + gender:sexor + gender:selfattr +gender:partnerattr + age:religion + age:sexor + age:selfattr + age:partnerattr+ religion:sexor + religion:selfattr + religion:partnerattr + sexor:selfattr +sexor:partnerattr + selfattr:partnerattr ???????????????????????post.mean? ?l-95% CI??u-95% CI eff.samp?? pMCMC?? (Intercept)???????????8.934e+02 -6.995e+02?2.596e+03?? 275.73 0.22660?? genderM??????????????-8.936e+01 -7.437e+02?5.066e+02? 4236.67 0.75794?? genderO??????????????-1.292e+03 -1.934e+05?1.765e+05? 9700.00 0.99052?? age??????????????????-3.493e+02 -1.170e+03?3.615e+02?? 505.92 0.31918?? religionY????????????-7.361e+02 -1.598e+03?1.481e+01??? 33.71 0.03402 * sexorHOM?????????????-1.235e+03 -1.808e+05?1.679e+05? 9700.00 0.99814?? sexorOT????????????? ??2.193e+03 -1.589e+05? 1.687e+05 10583.09 0.97814?? selfattr?????????????-2.367e+02 -7.424e+02?1.706e+02?? 314.82 0.24948?? partnerattr???????????1.391e+02 -2.667e+02?6.147e+02?? 966.40 0.49546?? genderM:age???????????2.696e+01 -1.313e+02? 1.748e+02? 3786.10 0.69670?? genderO:age??????????-1.055e+04 -8.325e+04?7.163e+04? 1722.63 0.78474?? genderM:religionY????-1.295e+02 -3.725e+02?8.194e+01?? 200.08 0.20495?? genderO:religionY????-1.016e+04 -1.589e+05?1.505e+05? 8731.86 0.89052?? genderM:sexorHOM?????-2.245e+02 -5.713e+02?4.443e+01?? 105.67 0.10495?? genderO:sexorHOM?????-8.104e+03 -1.620e+05?1.385e+05? 5318.22 0.90474?? genderM:sexorOT??????-1.520e+02 -5.124e+02?1.856e+02?? 423.76 0.33402?? genderO:sexorOT???????2.628e+03 -1.654e+05?1.658e+05? 9700.00 0.97670?? genderM:selfattr??????9.029e+01 -3.152e+01?2.334e+02?? 119.78 0.12907?? genderO:selfattr??????6.281e+03 -6.511e+04?8.524e+04? 3504.67 0.88412?? genderM:partnerattr??-7.284e+01 -2.160e+02?6.729e+01?? 263.29 0.25052?? genderO:partnerattr???2.536e+02 -5.113e+02?1.121e+03? 1291.76 0.49113?? age:religionY?????????8.732e+01 -1.283e+02?3.457e+02?? 727.46 0.42289?? age:sexorHOM??????????2.809e+02 -8.592e+04?8.847e+04? 9700.00 0.99711?? age:sexorOT??????????-1.246e+03 -8.447e+04?7.941e+04? 9370.57 0.97526?? age:selfattr??????????1.195e+02 -6.636e+01?3.452e+02?? 212.35 0.19567?? age:partnerattr??????-8.598e+00 -1.963e+02?1.714e+02? 9700.00 0.92227?? religionY:sexorHOM????8.506e+01 -2.392e+02?4.612e+02? 2059.92 0.59959?? religionY:sexorOT?????1.420e+01 -5.170e+02?5.464e+02? 9700.00 0.96268?? religionY:selfattr????2.782e+01 -1.198e+02?1.833e+02? 3520.80 0.68701?? religionY:partnerattr?1.407e+02? 1.423e+01? 2.886e+02???22.99 0.00928 **sexorHOM:selfattr?????1.160e+02 -1.141e+02?3.707e+02?? 394.74 0.28495?? sexorOT:selfattr??????1.006e+02 -8.528e+01?3.050e+02?? 305.50 0.24577?? sexorHOM:partnerattr??1.231e+02 -1.246e+02?3.990e+02?? 415.43 0.31072?? sexorOT:partnerattr??-1.401e+00 -2.007e+02 ?1.956e+02?9700.00 0.99237?? selfattr:partnerattr??5.483e+00 -6.017e+01?7.207e+01? 3007.45 0.85464?? ---Signif. codes:? 0?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1??Cutpoints: ??????????????????????????post.mean l-95% CI u-95% CI eff.sampcutpoint.traitnatapshort.1???? 235.2???62.34??? 376.2??? 8.822cutpoint.traitnatapshort.2???? 633.4??202.16??? 944.0??? 3.578cutpoint.traitnatapshort.3???1139.5?? 364.35?? 1683.7???5.832cutpoint.traitnataplong.1????? 293.4???54.85??? 433.7??? 5.203cutpoint.traitnataplong.2????? 651.8??223.70??? 961.6??? 2.604cutpoint.traitnataplong.3????1023.1?? 344.82?? 1483.0???2.353
?? 
So, my question is: in that summary, where are the effect sizes, are they the "post. mean" column? And have they been transformed in some way? Because obviously, for response variables that can only take values 1,2,3,4 or 5, I would expect to see those as the effect size. 
Also, is there any way of knowing to what extent are those results due to each specific response variable, and the degree of covariance between both? Is it possible to get all that information from that summary output I have copied above?
?? Thank you very much.?? Iker

__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Sep 23 15:57:38 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Sep 2015 09:57:38 -0400
Subject: [R-sig-ME] interaction and nested notation in lmer
In-Reply-To: <CAAUQNiJ5WtjDpOkkCx=ENMbG1T05XXRtLnddFB3zUrMMneropw@mail.gmail.com>
References: <CAAUQNiJ5WtjDpOkkCx=ENMbG1T05XXRtLnddFB3zUrMMneropw@mail.gmail.com>
Message-ID: <CABghstQvBuvdMW9xyOgMmg8gtcZ1GwiM7+BwJvAbnk-AjkBwoA@mail.gmail.com>

On Mon, Sep 21, 2015 at 6:24 PM, Mashitah Jusoh <mashitahj at gmail.com> wrote:
> Hi,
>
> I would like to ask about the notation to indicated nested and interaction
> when using lmer function.
>
> Here is my experiment look like:
>
> I have 95 genotypes with 2 replications that were conducted in two years.
> Some of the observation were missing, making the dataset unbalance. So, I
> decided to use lmer function to fit the data to get the variance component
> and will treat all components as random. The model that I am going to fit
> is:
>
> Y=mean + year + genotype + rep (nested in year)  + genotype*year + error
>
> I am wondering how to write the command for nested and interaction term in
> R using lmer function for this model? As far as I search in the internet,
> the command for nested and interaction seems like using similar notation,
> for example (1|year:rep) to show rep is nested within year (for random
> effect) the same notation is used to indicate the interaction (for other
> variables, such as genotype:year). Correct me if i am wrong. And, can you
> give some clarification about this and also how lmer/ R works with
> interaction and nested data?

  If you have samples from only 2 years, it's not going to be
particularly practical to fit
a model with year as random effect.  Setting that aside for the moment,
the distinction between (1|year/rep) and (1|year:rep) is that the
former expands to
(1|year) + (1|year:rep)  (i.e., effect of year and effect of rep
within year), while the latter
is just rep within year -- i.e. no main effect of year.

  However, nesting syntax doesn't really doesn't work well for fixed
effects (partly
due to the way R handles the formulae, and partly for conceptual reasons) -- in
your model, year:rep would give 4 fixed-effect parameters, as would
year+rep+year:rep
or year*rep (two ways of specifying crossed effects)

  I think I would recommend

Y  ~ 1 + year*rep + (1|genotype) + (1|genotype:year)

With unbalanced data, it may be hard to get a unique decomposition of
variance ...

 Ben Bolker


From j.hadfield at ed.ac.uk  Wed Sep 23 16:25:02 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 23 Sep 2015 15:25:02 +0100
Subject: [R-sig-ME] Interpreting a MCMCglmm model with a bivariate
 response variable
In-Reply-To: <948774124.422503.1443014889833.JavaMail.yahoo@mail.yahoo.com>
References: <948774124.422503.1443014889833.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20150923152502.16369inb31h7c9j4@www.staffmail.ed.ac.uk>

Hi Iker,

You need to follow the advice given to your previous post. With  
unconstrained residual variance the model is largely generating  
nonsense. Use `corg' instead of `us'. Also, depending on what the  
outcomes are you almost certainly need to have `trait' in the fixed  
effect specification.

Jarrod




   Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Wed, 23 Sep 2015  
13:28:09 +0000 (UTC):

>
> ?? Hello all,
> ?? I am implementing a model with a multiple (bivariate) response  
> variable using MCMCglmm. Both response variables and all the  
> explanatory variables are categorical variables, with between 2 and  
> 6 levels. The model is as follows:
> ??
> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~us(trait):units,family=c("threshold","threshold"),data=extphen,nitt=100000,singular.ok=TRUE)
> ?? And this is the summary of the model after all the iterations:
> ??
> summary(testmodel1)??Iterations =3001:99991?Thinninginterval? =  
> 10?Sample size? = 9700 ??DIC: ??R-structure:?  
> ~us(trait):units????????????????????????????post.mean l-95% CI u-95%  
> CI eff.sampnatapshort:natapshort.units??? 114108???992.1?? 213000???  
> 7.105nataplong:natapshort.units????? 33245???310.8??? 66300???  
> 4.656natapshort:nataplong.units ?????33245???310.8??? 66300???  
> 4.656nataplong:nataplong.units?????? 82964???671.5?? 155869???  
> 2.218??Location effects:cbind(natapshort, nataplong) ~ gender + age  
> + religion + sexor + selfattr +partnerattr + gender:age +  
> gender:religion + gender:sexor + gender:selfattr +gender:partnerattr  
> + age:religion + age:sexor + age:selfattr + age:partnerattr+  
> religion:sexor + religion:selfattr + religion:partnerattr +  
> sexor:selfattr +sexor:partnerattr + selfattr:partnerattr  
> ???????????????????????post.mean? ?l-95% CI??u-95% CI eff.samp??  
> pMCMC?? (Intercept)???????????8.934e+02 -6.995e+02?2.596e+03??  
> 275.73 0.22660?? genderM??????????????-8.936e+01 -7.437e+0
> 2?5.066e+02? 4236.67 0.75794?? genderO??????????????-1.292e+03  
> -1.934e+05?1.765e+05? 9700.00 0.99052??  
> age??????????????????-3.493e+02 -1.170e+03?3.615e+02?? 505.92  
> 0.31918?? religionY????????????-7.361e+02 -1.598e+03?1.481e+01???  
> 33.71 0.03402 * sexorHOM?????????????-1.235e+03  
> -1.808e+05?1.679e+05? 9700.00 0.99814?? sexorOT?????????????  
> ??2.193e+03 -1.589e+05? 1.687e+05 10583.09 0.97814??  
> selfattr?????????????-2.367e+02 -7.424e+02?1.706e+02?? 314.82  
> 0.24948?? partnerattr???????????1.391e+02 -2.667e+02?6.147e+02??  
> 966.40 0.49546?? genderM:age???????????2.696e+01 -1.313e+02?  
> 1.748e+02? 3786.10 0.69670?? genderO:age??????????-1.055e+04  
> -8.325e+04?7.163e+04? 1722.63 0.78474??  
> genderM:religionY????-1.295e+02 -3.725e+02?8.194e+01?? 200.08  
> 0.20495?? genderO:religionY????-1.016e+04 -1.589e+05?1.505e+05?  
> 8731.86 0.89052?? genderM:sexorHOM?????-2.245e+02  
> -5.713e+02?4.443e+01?? 105.67 0.10495??  
> genderO:sexorHOM?????-8.104e+03 -1.620e+05?1.385e+05? 5318.22  
> 0.90474?? genderM:sexorOT??????-1.52
> 0e+02 -5.124e+02?1.856e+02?? 423.76 0.33402??  
> genderO:sexorOT???????2.628e+03 -1.654e+05?1.658e+05? 9700.00  
> 0.97670?? genderM:selfattr??????9.029e+01 -3.152e+01?2.334e+02??  
> 119.78 0.12907?? genderO:selfattr??????6.281e+03  
> -6.511e+04?8.524e+04? 3504.67 0.88412??  
> genderM:partnerattr??-7.284e+01 -2.160e+02?6.729e+01?? 263.29  
> 0.25052?? genderO:partnerattr???2.536e+02 -5.113e+02?1.121e+03?  
> 1291.76 0.49113?? age:religionY?????????8.732e+01  
> -1.283e+02?3.457e+02?? 727.46 0.42289??  
> age:sexorHOM??????????2.809e+02 -8.592e+04?8.847e+04? 9700.00  
> 0.99711?? age:sexorOT??????????-1.246e+03 -8.447e+04?7.941e+04?  
> 9370.57 0.97526?? age:selfattr??????????1.195e+02  
> -6.636e+01?3.452e+02?? 212.35 0.19567??  
> age:partnerattr??????-8.598e+00 -1.963e+02?1.714e+02? 9700.00  
> 0.92227?? religionY:sexorHOM????8.506e+01 -2.392e+02?4.612e+02?  
> 2059.92 0.59959?? religionY:sexorOT?????1.420e+01  
> -5.170e+02?5.464e+02? 9700.00 0.96268??  
> religionY:selfattr????2.782e+01 -1.198e+02?1.833e+02? 3520.80  
> 0.68701?? religionY:part
> nerattr?1.407e+02? 1.423e+01? 2.886e+02???22.99 0.00928  
> **sexorHOM:selfattr?????1.160e+02 -1.141e+02?3.707e+02?? 394.74  
> 0.28495?? sexorOT:selfattr??????1.006e+02 -8.528e+01?3.050e+02??  
> 305.50 0.24577?? sexorHOM:partnerattr??1.231e+02  
> -1.246e+02?3.990e+02?? 415.43 0.31072??  
> sexorOT:partnerattr??-1.401e+00 -2.007e+02 ?1.956e+02?9700.00  
> 0.99237?? selfattr:partnerattr??5.483e+00 -6.017e+01?7.207e+01?  
> 3007.45 0.85464?? ---Signif. codes:? 0?***? 0.001 ?**? 0.01 ?*? 0.05  
> ?.? 0.1 ? ? 1??Cutpoints: ??????????????????????????post.mean l-95%  
> CI u-95% CI eff.sampcutpoint.traitnatapshort.1???? 235.2???62.34???  
> 376.2??? 8.822cutpoint.traitnatapshort.2???? 633.4??202.16???  
> 944.0??? 3.578cutpoint.traitnatapshort.3???1139.5?? 364.35??  
> 1683.7???5.832cutpoint.traitnataplong.1????? 293.4???54.85???  
> 433.7??? 5.203cutpoint.traitnataplong.2????? 651.8??223.70???  
> 961.6??? 2.604cutpoint.traitnataplong.3????1023.1?? 344.82??  
> 1483.0???2.353
> ??
> So, my question is: in that summary, where are the effect sizes, are  
> they the "post. mean" column? And have they been transformed in some  
> way? Because obviously, for response variables that can only take  
> values 1,2,3,4 or 5, I would expect to see those as the effect size.
> Also, is there any way of knowing to what extent are those results  
> due to each specific response variable, and the degree of covariance  
> between both? Is it possible to get all that information from that  
> summary output I have copied above?
> ?? Thank you very much.?? Iker
>
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From karraspito at yahoo.es  Wed Sep 23 16:32:00 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Wed, 23 Sep 2015 14:32:00 +0000 (UTC)
Subject: [R-sig-ME] Interpreting a MCMCglmm model with a bivariate
 response variable
In-Reply-To: <20150923152502.16369inb31h7c9j4@www.staffmail.ed.ac.uk>
References: <20150923152502.16369inb31h7c9j4@www.staffmail.ed.ac.uk>
Message-ID: <771064182.482785.1443018720695.JavaMail.yahoo@mail.yahoo.com>


?? Hi, Jarrod and everyone else.
?? Thank you very much for your advise. Actually, I just realized after sending the email, I was going to send the correct one. The model:
testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~corg(trait):units,family=c("threshold","threshold"),data=extphen,nitt=100000,singular.ok=TRUE)
?And the summary outcome:
?summary(testmodel1)

?Iterations = 3001:99991
?Thinning interval? = 10
?Sample size? = 9700 

?DIC: 

?R-structure:? ~corg(trait):units

??????????????????????????? post.mean l-95% CI u-95% CI eff.samp
natapshort:natapshort.units??? 1.0000?? 1.0000?? 1.0000??????? 0
nataplong:natapshort.units???? 0.3469?? 0.2243?? 0.4744???? 7885
natapshort:nataplong.units???? 0.3469?? 0.2243?? 0.4744???? 7885
nataplong:nataplong.units????? 1.0000?? 1.0000?? 1.0000??????? 0

?Location effects: cbind(natapshort, nataplong) ~ gender + age + religion + sexor + selfattr + partnerattr + gender:age + gender:religion + gender:sexor + gender:selfattr + gender:partnerattr + age:religion + age:sexor + age:selfattr + age:partnerattr + religion:sexor + religion:selfattr + religion:partnerattr + sexor:selfattr + sexor:partnerattr + selfattr:partnerattr 

?????????????????????? post.mean?? l-95% CI?? u-95% CI eff.samp?? pMCMC?? 
(Intercept)??????????? 3.170e+00 -1.940e+00? 8.301e+00???? 8794 0.21897?? 
genderM?????????????? -1.048e-01 -2.006e+00? 1.915e+00???? 9408 0.90948?? 
genderO?????????????? -5.316e+02 -1.827e+05? 1.854e+05???? 9864 0.99052?? 
age?????????????????? -1.006e+00 -3.414e+00? 1.266e+00???? 8847 0.39959?? 
religionY???????????? -2.823e+00 -5.121e+00 -5.111e-01???? 8322 0.01691 * 
sexorHOM?????????????? 1.338e+03 -1.663e+05? 1.738e+05???? 9700 0.99608?? 
sexorOT??????????????? 8.310e+02 -1.580e+05? 1.586e+05???? 9700 0.99732?? 
selfattr????????????? -8.544e-01 -2.236e+00? 5.512e-01???? 9092 0.22454?? 
partnerattr??????????? 4.296e-01 -9.066e-01? 1.784e+00???? 8818 0.52598?? 
genderM:age??????????? 3.254e-02 -4.556e-01? 5.027e-01???? 9700 0.88557?? 
genderO:age??????????? 2.113e+02 -7.761e+04? 7.336e+04???? 9700 0.99918?? 
genderM:religionY???? -4.660e-01 -1.141e+00? 2.360e-01???? 9503 0.17258?? 
genderO:religionY????? 3.408e+02 -1.551e+05? 1.567e+05???? 9700 0.99485?? 
genderM:sexorHOM????? -7.522e-01 -1.687e+00? 1.528e-01???? 9700 0.11155?? 
genderO:sexorHOM?????? 8.643e+01 -1.468e+05? 1.512e+05???? 9700 0.99258?? 
genderM:sexorOT?????? -5.950e-01 -1.661e+00? 4.325e-01???? 9326 0.26742?? 
genderO:sexorOT??????? 6.955e+02 -1.589e+05? 1.664e+05???? 9700 0.99340?? 
genderM:selfattr?????? 3.038e-01 -1.054e-01? 6.976e-01???? 9334 0.13526?? 
genderO:selfattr????? -1.968e+02 -7.999e+04? 7.118e+04???? 9341 0.99340?? 
genderM:partnerattr?? -2.686e-01 -6.974e-01? 1.595e-01???? 9345 0.20866?? 
genderO:partnerattr??? 1.064e+00 -1.365e+00? 3.685e+00???? 8894 0.41155?? 
age:religionY????????? 3.473e-01 -3.822e-01? 1.100e+00???? 9215 0.34763?? 
age:sexorHOM????????? -6.704e+02 -8.690e+04? 8.316e+04???? 9700 0.99608?? 
age:sexorOT?????????? -4.160e+02 -7.930e+04? 7.899e+04???? 9700 0.99732?? 
age:selfattr?????????? 3.904e-01 -2.322e-01? 9.908e-01???? 9257 0.20351?? 
age:partnerattr?????? -5.805e-02 -6.213e-01? 5.200e-01???? 8974 0.85155?? 
religionY:sexorHOM???? 3.131e-01 -8.014e-01? 1.381e+00???? 9700 0.57505?? 
religionY:sexorOT???? -3.484e-03 -1.612e+00? 1.651e+00???? 7850 0.99278?? 
religionY:selfattr???? 1.074e-01 -3.688e-01? 5.790e-01???? 8506 0.65649?? 
religionY:partnerattr? 5.330e-01? 1.455e-01? 8.974e-01???? 8817 0.00495 **
sexorHOM:selfattr????? 3.787e-01 -3.850e-01? 1.134e+00???? 9101 0.31588?? 
sexorOT:selfattr?????? 3.805e-01 -2.086e-01? 9.754e-01???? 9163 0.20866?? 
sexorHOM:partnerattr?? 4.977e-01 -2.861e-01? 1.323e+00???? 8472 0.22639?? 
sexorOT:partnerattr?? -7.482e-02 -6.965e-01? 5.284e-01???? 9023 0.80000?? 
selfattr:partnerattr?? 5.051e-02 -1.438e-01? 2.540e-01???? 8700 0.62041?? 
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

?Cutpoints: 
?????????????????????????? post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitnatapshort.1???? 1.024?? 0.7313??? 1.335??? 872.3
cutpoint.traitnatapshort.2???? 2.362?? 2.0725??? 2.698??? 756.2
cutpoint.traitnatapshort.3???? 4.002?? 3.6299??? 4.396??? 884.4
cutpoint.traitnataplong.1????? 1.187?? 0.9010??? 1.489??? 828.4
cutpoint.traitnataplong.2????? 2.496?? 2.1718??? 2.812??? 727.6
cutpoint.traitnataplong.3????? 3.959?? 3.5890??? 4.350??? 872.9
Some additional questions, if that's fine:
1. Do I have to actually include the word 'trait' in the model, something like 'cbind(natapshort, nataplong) ~ trait + gender + age..."? What is the reason for that? Also, do I have to include interactions between 'trait' and other variables? 
2. Why the summary of my model does not give me the DIC value? It appears empty.

Thank you very much. 
Iker


__________________________________________________________________

?? Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations 
?? Joseph Banks Laboratories
?? School of Life Sciences
?? University of Lincoln?? Brayford Campus, Lincoln
?? LN6 7DL
?? United Kingdom

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


      De: Jarrod Hadfield <j.hadfield at ed.ac.uk>

CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Enviado: Mi?rcoles 23 de septiembre de 2015 15:25
 Asunto: Re: [R-sig-ME] Interpreting a MCMCglmm model with a bivariate response variable
   
Hi Iker,

You need to follow the advice given to your previous post. With? 
unconstrained residual variance the model is largely generating? 
nonsense. Use `corg' instead of `us'. Also, depending on what the? 
outcomes are you almost certainly need to have `trait' in the fixed? 
effect specification.

Jarrod





? 
13:28:09 +0000 (UTC):



>
> ?? Hello all,
> ?? I am implementing a model with a multiple (bivariate) response? 
> variable using MCMCglmm. Both response variables and all the? 
> explanatory variables are categorical variables, with between 2 and?
> 6 levels. The model is as follows:
> ??
> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~us(trait):units,family=c("threshold","threshold"),data=extphen,nitt=100000,singular.ok=TRUE)
> ?? And this is the summary of the model after all the iterations:
> ??
> summary(testmodel1)??Iterations =3001:99991?Thinninginterval? =? 
> 10?Sample size? = 9700 ??DIC: ??R-structure:?? 
> ~us(trait):units????????????????????????????post.mean l-95% CI u-95%? 
> CI eff.sampnatapshort:natapshort.units??? 114108???992.1?? 213000???? 
> 7.105nataplong:natapshort.units????? 33245???310.8??? 66300???? 
> 4.656natapshort:nataplong.units ?????33245???310.8??? 66300???? 
> 4.656nataplong:nataplong.units?????? 82964???671.5?? 155869???? 
> 2.218??Location effects:cbind(natapshort, nataplong) ~ gender + age? 
> + religion + sexor + selfattr +partnerattr + gender:age +? 
> gender:religion + gender:sexor + gender:selfattr +gender:partnerattr? 
> + age:religion + age:sexor + age:selfattr + age:partnerattr+? 
> religion:sexor + religion:selfattr + religion:partnerattr +? 
> sexor:selfattr +sexor:partnerattr + selfattr:partnerattr? 
> ???????????????????????post.mean? ?l-95% CI??u-95% CI eff.samp??? 
> pMCMC?? (Intercept)???????????8.934e+02 -6.995e+02?2.596e+03??? 
> 275.73 0.22660?? genderM??????????????-8.936e+01 -7.437e+0
> 2?5.066e+02? 4236.67 0.75794?? genderO??????????????-1.292e+03? 
> -1.934e+05?1.765e+05? 9700.00 0.99052??? 
> age??????????????????-3.493e+02 -1.170e+03?3.615e+02?? 505.92? 
> 0.31918?? religionY????????????-7.361e+02 -1.598e+03?1.481e+01???? 
> 33.71 0.03402 * sexorHOM?????????????-1.235e+03? 
> -1.808e+05?1.679e+05? 9700.00 0.99814?? sexorOT?????????????? 
> ??2.193e+03 -1.589e+05? 1.687e+05 10583.09 0.97814??? 
> selfattr?????????????-2.367e+02 -7.424e+02?1.706e+02?? 314.82? 
> 0.24948?? partnerattr???????????1.391e+02 -2.667e+02?6.147e+02??? 
> 966.40 0.49546?? genderM:age???????????2.696e+01 -1.313e+02?? 
> 1.748e+02? 3786.10 0.69670?? genderO:age??????????-1.055e+04? 
> -8.325e+04?7.163e+04? 1722.63 0.78474??? 
> genderM:religionY????-1.295e+02 -3.725e+02?8.194e+01?? 200.08? 
> 0.20495?? genderO:religionY????-1.016e+04 -1.589e+05?1.505e+05?? 
> 8731.86 0.89052?? genderM:sexorHOM?????-2.245e+02? 
> -5.713e+02?4.443e+01?? 105.67 0.10495??? 
> genderO:sexorHOM?????-8.104e+03 -1.620e+05?1.385e+05? 5318.22? 
> 0.90474?? genderM:sexorOT??????-1.52
> 0e+02 -5.124e+02?1.856e+02?? 423.76 0.33402??? 
> genderO:sexorOT???????2.628e+03 -1.654e+05?1.658e+05? 9700.00? 
> 0.97670?? genderM:selfattr??????9.029e+01 -3.152e+01?2.334e+02??? 
> 119.78 0.12907?? genderO:selfattr??????6.281e+03? 
> -6.511e+04?8.524e+04? 3504.67 0.88412??? 
> genderM:partnerattr??-7.284e+01 -2.160e+02?6.729e+01?? 263.29? 
> 0.25052?? genderO:partnerattr???2.536e+02 -5.113e+02?1.121e+03?? 
> 1291.76 0.49113?? age:religionY?????????8.732e+01? 
> -1.283e+02?3.457e+02?? 727.46 0.42289??? 
> age:sexorHOM??????????2.809e+02 -8.592e+04?8.847e+04? 9700.00? 
> 0.99711?? age:sexorOT??????????-1.246e+03 -8.447e+04?7.941e+04?? 
> 9370.57 0.97526?? age:selfattr??????????1.195e+02? 
> -6.636e+01?3.452e+02?? 212.35 0.19567??? 
> age:partnerattr??????-8.598e+00 -1.963e+02?1.714e+02? 9700.00? 
> 0.92227?? religionY:sexorHOM????8.506e+01 -2.392e+02?4.612e+02?? 
> 2059.92 0.59959?? religionY:sexorOT?????1.420e+01? 
> -5.170e+02?5.464e+02? 9700.00 0.96268??? 
> religionY:selfattr????2.782e+01 -1.198e+02?1.833e+02? 3520.80? 
> 0.68701?? religionY:part
> nerattr?1.407e+02? 1.423e+01? 2.886e+02???22.99 0.00928? 
> **sexorHOM:selfattr?????1.160e+02 -1.141e+02?3.707e+02?? 394.74? 
> 0.28495?? sexorOT:selfattr??????1.006e+02 -8.528e+01?3.050e+02??? 
> 305.50 0.24577?? sexorHOM:partnerattr??1.231e+02? 
> -1.246e+02?3.990e+02?? 415.43 0.31072??? 
> sexorOT:partnerattr??-1.401e+00 -2.007e+02 ?1.956e+02?9700.00? 
> 0.99237?? selfattr:partnerattr??5.483e+00 -6.017e+01?7.207e+01?? 
> 3007.45 0.85464?? ---Signif. codes:? 0?***? 0.001 ?**? 0.01 ?*? 0.05? 
> ?.? 0.1 ? ? 1??Cutpoints: ??????????????????????????post.mean l-95%? 
> CI u-95% CI eff.sampcutpoint.traitnatapshort.1???? 235.2???62.34???? 
> 376.2??? 8.822cutpoint.traitnatapshort.2???? 633.4??202.16???? 
> 944.0??? 3.578cutpoint.traitnatapshort.3???1139.5?? 364.35??? 
> 1683.7???5.832cutpoint.traitnataplong.1????? 293.4???54.85???? 
> 433.7??? 5.203cutpoint.traitnataplong.2????? 651.8??223.70???? 
> 961.6??? 2.604cutpoint.traitnataplong.3????1023.1?? 344.82??? 
> 1483.0???2.353
> ??
> So, my question is: in that summary, where are the effect sizes, are? 
> they the "post. mean" column? And have they been transformed in some? 
> way? Because obviously, for response variables that can only take? 
> values 1,2,3,4 or 5, I would expect to see those as the effect size.
> Also, is there any way of knowing to what extent are those results?
> due to each specific response variable, and the degree of covariance? 
> between both? Is it possible to get all that information from that?
> summary output I have copied above?
> ?? Thank you very much.?? Iker
>
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.




  
	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Sep 23 16:38:47 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 23 Sep 2015 15:38:47 +0100
Subject: [R-sig-ME] Interpreting a MCMCglmm model with a bivariate
 response variable
In-Reply-To: <771064182.482785.1443018720695.JavaMail.yahoo@mail.yahoo.com>
References: <20150923152502.16369inb31h7c9j4@www.staffmail.ed.ac.uk>
	<771064182.482785.1443018720695.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20150923153847.24672t7mcy8ajr0g@www.staffmail.ed.ac.uk>

Hi,

a) Section 8 of the course notes details the use of 'triat'.

b) DIC is not implemented for multivariate threshold models. DIC, as  
its currently `focussed' is not useful anyway, I think.

Cheers,

Jarrod




The muklQuoting Iker Vaquero Alba <karraspito at yahoo.es> on Wed, 23 Sep  
2015 14:32:00 +0000 (UTC):

>
> ?? Hi, Jarrod and everyone else.
> ?? Thank you very much for your advise. Actually, I just realized  
> after sending the email, I was going to send the correct one. The  
> model:
> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~corg(trait):units,family=c("threshold","threshold"),data=extphen,nitt=100000,singular.ok=TRUE)
> ?And the summary outcome:
> ?summary(testmodel1)
>
> ?Iterations = 3001:99991
> ?Thinning interval? = 10
> ?Sample size? = 9700
>
> ?DIC:
>
> ?R-structure:? ~corg(trait):units
>
> ??????????????????????????? post.mean l-95% CI u-95% CI eff.samp
> natapshort:natapshort.units??? 1.0000?? 1.0000?? 1.0000??????? 0
> nataplong:natapshort.units???? 0.3469?? 0.2243?? 0.4744???? 7885
> natapshort:nataplong.units???? 0.3469?? 0.2243?? 0.4744???? 7885
> nataplong:nataplong.units????? 1.0000?? 1.0000?? 1.0000??????? 0
>
> ?Location effects: cbind(natapshort, nataplong) ~ gender + age +  
> religion + sexor + selfattr + partnerattr + gender:age +  
> gender:religion + gender:sexor + gender:selfattr +  
> gender:partnerattr + age:religion + age:sexor + age:selfattr +  
> age:partnerattr + religion:sexor + religion:selfattr +  
> religion:partnerattr + sexor:selfattr + sexor:partnerattr +  
> selfattr:partnerattr
>
> ?????????????????????? post.mean?? l-95% CI?? u-95% CI eff.samp?? pMCMC??
> (Intercept)??????????? 3.170e+00 -1.940e+00? 8.301e+00???? 8794 0.21897??
> genderM?????????????? -1.048e-01 -2.006e+00? 1.915e+00???? 9408 0.90948??
> genderO?????????????? -5.316e+02 -1.827e+05? 1.854e+05???? 9864 0.99052??
> age?????????????????? -1.006e+00 -3.414e+00? 1.266e+00???? 8847 0.39959??
> religionY???????????? -2.823e+00 -5.121e+00 -5.111e-01???? 8322 0.01691 *
> sexorHOM?????????????? 1.338e+03 -1.663e+05? 1.738e+05???? 9700 0.99608??
> sexorOT??????????????? 8.310e+02 -1.580e+05? 1.586e+05???? 9700 0.99732??
> selfattr????????????? -8.544e-01 -2.236e+00? 5.512e-01???? 9092 0.22454??
> partnerattr??????????? 4.296e-01 -9.066e-01? 1.784e+00???? 8818 0.52598??
> genderM:age??????????? 3.254e-02 -4.556e-01? 5.027e-01???? 9700 0.88557??
> genderO:age??????????? 2.113e+02 -7.761e+04? 7.336e+04???? 9700 0.99918??
> genderM:religionY???? -4.660e-01 -1.141e+00? 2.360e-01???? 9503 0.17258??
> genderO:religionY????? 3.408e+02 -1.551e+05? 1.567e+05???? 9700 0.99485??
> genderM:sexorHOM????? -7.522e-01 -1.687e+00? 1.528e-01???? 9700 0.11155??
> genderO:sexorHOM?????? 8.643e+01 -1.468e+05? 1.512e+05???? 9700 0.99258??
> genderM:sexorOT?????? -5.950e-01 -1.661e+00? 4.325e-01???? 9326 0.26742??
> genderO:sexorOT??????? 6.955e+02 -1.589e+05? 1.664e+05???? 9700 0.99340??
> genderM:selfattr?????? 3.038e-01 -1.054e-01? 6.976e-01???? 9334 0.13526??
> genderO:selfattr????? -1.968e+02 -7.999e+04? 7.118e+04???? 9341 0.99340??
> genderM:partnerattr?? -2.686e-01 -6.974e-01? 1.595e-01???? 9345 0.20866??
> genderO:partnerattr??? 1.064e+00 -1.365e+00? 3.685e+00???? 8894 0.41155??
> age:religionY????????? 3.473e-01 -3.822e-01? 1.100e+00???? 9215 0.34763??
> age:sexorHOM????????? -6.704e+02 -8.690e+04? 8.316e+04???? 9700 0.99608??
> age:sexorOT?????????? -4.160e+02 -7.930e+04? 7.899e+04???? 9700 0.99732??
> age:selfattr?????????? 3.904e-01 -2.322e-01? 9.908e-01???? 9257 0.20351??
> age:partnerattr?????? -5.805e-02 -6.213e-01? 5.200e-01???? 8974 0.85155??
> religionY:sexorHOM???? 3.131e-01 -8.014e-01? 1.381e+00???? 9700 0.57505??
> religionY:sexorOT???? -3.484e-03 -1.612e+00? 1.651e+00???? 7850 0.99278??
> religionY:selfattr???? 1.074e-01 -3.688e-01? 5.790e-01???? 8506 0.65649??
> religionY:partnerattr? 5.330e-01? 1.455e-01? 8.974e-01???? 8817 0.00495 **
> sexorHOM:selfattr????? 3.787e-01 -3.850e-01? 1.134e+00???? 9101 0.31588??
> sexorOT:selfattr?????? 3.805e-01 -2.086e-01? 9.754e-01???? 9163 0.20866??
> sexorHOM:partnerattr?? 4.977e-01 -2.861e-01? 1.323e+00???? 8472 0.22639??
> sexorOT:partnerattr?? -7.482e-02 -6.965e-01? 5.284e-01???? 9023 0.80000??
> selfattr:partnerattr?? 5.051e-02 -1.438e-01? 2.540e-01???? 8700 0.62041??
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> ?Cutpoints:
> ?????????????????????????? post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitnatapshort.1???? 1.024?? 0.7313??? 1.335??? 872.3
> cutpoint.traitnatapshort.2???? 2.362?? 2.0725??? 2.698??? 756.2
> cutpoint.traitnatapshort.3???? 4.002?? 3.6299??? 4.396??? 884.4
> cutpoint.traitnataplong.1????? 1.187?? 0.9010??? 1.489??? 828.4
> cutpoint.traitnataplong.2????? 2.496?? 2.1718??? 2.812??? 727.6
> cutpoint.traitnataplong.3????? 3.959?? 3.5890??? 4.350??? 872.9
> Some additional questions, if that's fine:
> 1. Do I have to actually include the word 'trait' in the model,  
> something like 'cbind(natapshort, nataplong) ~ trait + gender +  
> age..."? What is the reason for that? Also, do I have to include  
> interactions between 'trait' and other variables?
> 2. Why the summary of my model does not give me the DIC value? It  
> appears empty.
>
> Thank you very much.
> Iker
>
>
> __________________________________________________________________
>
> ?? Iker Vaquero-Alba
> ?? Visiting Postdoctoral Research Associate
> ?? Laboratory of Evolutionary Ecology of Adaptations
> ?? Joseph Banks Laboratories
> ?? School of Life Sciences
> ?? University of Lincoln?? Brayford Campus, Lincoln
> ?? LN6 7DL
> ?? United Kingdom
>
> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
>       De: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>  Para: Iker Vaquero Alba <karraspito at yahoo.es>
> CC: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
>  Enviado: Mi?rcoles 23 de septiembre de 2015 15:25
>  Asunto: Re: [R-sig-ME] Interpreting a MCMCglmm model with a  
> bivariate response variable
>
> Hi Iker,
>
> You need to follow the advice given to your previous post. With?
> unconstrained residual variance the model is largely generating?
> nonsense. Use `corg' instead of `us'. Also, depending on what the?
> outcomes are you almost certainly need to have `trait' in the fixed?
> effect specification.
>
> Jarrod
>
>
>
>
> ? Quoting Iker Vaquero Alba <karraspito at yahoo.es> on Wed, 23 Sep 2015?
> 13:28:09 +0000 (UTC):
>
>
>
>>
>> ?? Hello all,
>> ?? I am implementing a model with a multiple (bivariate) response?
>> variable using MCMCglmm. Both response variables and all the?
>> explanatory variables are categorical variables, with between 2 and?
>> 6 levels. The model is as follows:
>> ??
>> testmodel1<-MCMCglmm(cbind(natapshort,nataplong)~gender+age+religion+sexor+selfattr+partnerattr+gender:age+gender:religion+gender:sexor+gender:selfattr+gender:partnerattr+age:religion+age:sexor+age:selfattr+age:partnerattr+religion:sexor+religion:selfattr+religion:partnerattr+sexor:selfattr+sexor:partnerattr+selfattr:partnerattr,random=NULL,rcov=~us(trait):units,family=c("threshold","threshold"),data=extphen,nitt=100000,singular.ok=TRUE)
>> ?? And this is the summary of the model after all the iterations:
>> ??
>> summary(testmodel1)??Iterations =3001:99991?Thinninginterval? =?
>> 10?Sample size? = 9700 ??DIC: ??R-structure:??
>> ~us(trait):units????????????????????????????post.mean l-95% CI u-95%?
>> CI eff.sampnatapshort:natapshort.units??? 114108???992.1?? 213000????
>> 7.105nataplong:natapshort.units????? 33245???310.8??? 66300????
>> 4.656natapshort:nataplong.units ?????33245???310.8??? 66300????
>> 4.656nataplong:nataplong.units?????? 82964???671.5?? 155869????
>> 2.218??Location effects:cbind(natapshort, nataplong) ~ gender + age?
>> + religion + sexor + selfattr +partnerattr + gender:age +?
>> gender:religion + gender:sexor + gender:selfattr +gender:partnerattr?
>> + age:religion + age:sexor + age:selfattr + age:partnerattr+?
>> religion:sexor + religion:selfattr + religion:partnerattr +?
>> sexor:selfattr +sexor:partnerattr + selfattr:partnerattr?
>> ???????????????????????post.mean? ?l-95% CI??u-95% CI eff.samp???
>> pMCMC?? (Intercept)???????????8.934e+02 -6.995e+02?2.596e+03???
>> 275.73 0.22660?? genderM??????????????-8.936e+01 -7.437e+0
>> 2?5.066e+02? 4236.67 0.75794?? genderO??????????????-1.292e+03?
>> -1.934e+05?1.765e+05? 9700.00 0.99052???
>> age??????????????????-3.493e+02 -1.170e+03?3.615e+02?? 505.92?
>> 0.31918?? religionY????????????-7.361e+02 -1.598e+03?1.481e+01????
>> 33.71 0.03402 * sexorHOM?????????????-1.235e+03?
>> -1.808e+05?1.679e+05? 9700.00 0.99814?? sexorOT??????????????
>> ??2.193e+03 -1.589e+05? 1.687e+05 10583.09 0.97814???
>> selfattr?????????????-2.367e+02 -7.424e+02?1.706e+02?? 314.82?
>> 0.24948?? partnerattr???????????1.391e+02 -2.667e+02?6.147e+02???
>> 966.40 0.49546?? genderM:age???????????2.696e+01 -1.313e+02??
>> 1.748e+02? 3786.10 0.69670?? genderO:age??????????-1.055e+04?
>> -8.325e+04?7.163e+04? 1722.63 0.78474???
>> genderM:religionY????-1.295e+02 -3.725e+02?8.194e+01?? 200.08?
>> 0.20495?? genderO:religionY????-1.016e+04 -1.589e+05?1.505e+05??
>> 8731.86 0.89052?? genderM:sexorHOM?????-2.245e+02?
>> -5.713e+02?4.443e+01?? 105.67 0.10495???
>> genderO:sexorHOM?????-8.104e+03 -1.620e+05?1.385e+05? 5318.22?
>> 0.90474?? genderM:sexorOT??????-1.52
>> 0e+02 -5.124e+02?1.856e+02?? 423.76 0.33402???
>> genderO:sexorOT???????2.628e+03 -1.654e+05?1.658e+05? 9700.00?
>> 0.97670?? genderM:selfattr??????9.029e+01 -3.152e+01?2.334e+02???
>> 119.78 0.12907?? genderO:selfattr??????6.281e+03?
>> -6.511e+04?8.524e+04? 3504.67 0.88412???
>> genderM:partnerattr??-7.284e+01 -2.160e+02?6.729e+01?? 263.29?
>> 0.25052?? genderO:partnerattr???2.536e+02 -5.113e+02?1.121e+03??
>> 1291.76 0.49113?? age:religionY?????????8.732e+01?
>> -1.283e+02?3.457e+02?? 727.46 0.42289???
>> age:sexorHOM??????????2.809e+02 -8.592e+04?8.847e+04? 9700.00?
>> 0.99711?? age:sexorOT??????????-1.246e+03 -8.447e+04?7.941e+04??
>> 9370.57 0.97526?? age:selfattr??????????1.195e+02?
>> -6.636e+01?3.452e+02?? 212.35 0.19567???
>> age:partnerattr??????-8.598e+00 -1.963e+02?1.714e+02? 9700.00?
>> 0.92227?? religionY:sexorHOM????8.506e+01 -2.392e+02?4.612e+02??
>> 2059.92 0.59959?? religionY:sexorOT?????1.420e+01?
>> -5.170e+02?5.464e+02? 9700.00 0.96268???
>> religionY:selfattr????2.782e+01 -1.198e+02?1.833e+02? 3520.80?
>> 0.68701?? religionY:part
>> nerattr?1.407e+02? 1.423e+01? 2.886e+02???22.99 0.00928?
>> **sexorHOM:selfattr?????1.160e+02 -1.141e+02?3.707e+02?? 394.74?
>> 0.28495?? sexorOT:selfattr??????1.006e+02 -8.528e+01?3.050e+02???
>> 305.50 0.24577?? sexorHOM:partnerattr??1.231e+02?
>> -1.246e+02?3.990e+02?? 415.43 0.31072???
>> sexorOT:partnerattr??-1.401e+00 -2.007e+02 ?1.956e+02?9700.00?
>> 0.99237?? selfattr:partnerattr??5.483e+00 -6.017e+01?7.207e+01??
>> 3007.45 0.85464?? ---Signif. codes:? 0?***? 0.001 ?**? 0.01 ?*? 0.05?
>> ?.? 0.1 ? ? 1??Cutpoints: ??????????????????????????post.mean l-95%?
>> CI u-95% CI eff.sampcutpoint.traitnatapshort.1???? 235.2???62.34????
>> 376.2??? 8.822cutpoint.traitnatapshort.2???? 633.4??202.16????
>> 944.0??? 3.578cutpoint.traitnatapshort.3???1139.5?? 364.35???
>> 1683.7???5.832cutpoint.traitnataplong.1????? 293.4???54.85????
>> 433.7??? 5.203cutpoint.traitnataplong.2????? 651.8??223.70????
>> 961.6??? 2.604cutpoint.traitnataplong.3????1023.1?? 344.82???
>> 1483.0???2.353
>> ??
>> So, my question is: in that summary, where are the effect sizes, are?
>> they the "post. mean" column? And have they been transformed in some?
>> way? Because obviously, for response variables that can only take?
>> values 1,2,3,4 or 5, I would expect to see those as the effect size.
>> Also, is there any way of knowing to what extent are those results?
>> due to each specific response variable, and the degree of covariance?
>> between both? Is it possible to get all that information from that?
>> summary output I have copied above?
>> ?? Thank you very much.?? Iker
>>
>> __________________________________________________________________
>>
>> ?? Iker Vaquero-Alba
>> ?? Visiting Postdoctoral Research Associate
>> ?? Laboratory of Evolutionary Ecology of Adaptations
>> ?? Joseph Banks Laboratories
>> ?? School of Life Sciences
>> ?? University of Lincoln?? Brayford Campus, Lincoln
>> ?? LN6 7DL
>> ?? United Kingdom
>>
>> ?? https://eric.exeter.ac.uk/repository/handle/10036/3381
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From westm490 at gmail.com  Wed Sep 23 20:36:05 2015
From: westm490 at gmail.com (M West)
Date: Wed, 23 Sep 2015 14:36:05 -0400
Subject: [R-sig-ME] mixed effects model glmer
Message-ID: <CAFJT+3JfeAYXU-iOsYB8Fb1i21qRvfo++PZqLSBg1zSNPP7rEw@mail.gmail.com>

I am trying to fit a mixed effects model with repeated measures data.

Data are:

y variable = percentage (# females/total)
x variable = percentage

measured across multiple sites for 4 years.

here's the model:

y <- cbind(total females, (Total - total females)))

mod1 <- with(data, glmer(y ~ disease prevalence +  (1|Site) + (1|Year),
family = binomial,  data = data1))

1) This model runs, but the summary(mod1) just generates a series of the
following....which doesn't make any sense so something must be wrong with
the model specification...I'm just not sure what.

2) Also, what is the default AR correlation on these models (i.e., do I
need to specify it or is the temporal psuedoreplication taken care of)?

3) Finally, do you suggest another form of the model that's better etc.?

Fixed effects:
                                Estimate             Std. Error    z value
   Pr(>|z|)
(Intercept)                  -1.60267            0.11618    -13.794    <
2e-16 ***
disease prevalence    -0.40212           0.15557     -2.585     0.009745 **
disease prevalence    0.035088231    -1.46452    0.22860  -6.406 1.49e-10
***
disease prevalence    0.064935065     -0.36344   0.30810  -1.180 0.238157

disease prevalence    0.078507945    -2.57479    0.46537  -5.533 3.15e-08
***
disease prevalence    0.120039255    -3.30998    0.71915  -4.603 4.17e-06
***
disease prevalence    0.182623706     -0.14362   0.19899  -0.722 0.470438


Many thanks in advance,
M.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Sep 23 22:41:27 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Sep 2015 16:41:27 -0400
Subject: [R-sig-ME] mixed effects model glmer
In-Reply-To: <CAFJT+3JfeAYXU-iOsYB8Fb1i21qRvfo++PZqLSBg1zSNPP7rEw@mail.gmail.com>
References: <CAFJT+3JfeAYXU-iOsYB8Fb1i21qRvfo++PZqLSBg1zSNPP7rEw@mail.gmail.com>
Message-ID: <CABghstR_VA4EHeL+0pur3khdZ=+ozapaRQJ6UAAPM4hj1FV2zg@mail.gmail.com>

On Wed, Sep 23, 2015 at 2:36 PM, M West <westm490 at gmail.com> wrote:
> I am trying to fit a mixed effects model with repeated measures data.
>
> Data are:
>
> y variable = percentage (# females/total)
> x variable = percentage
>
> measured across multiple sites for 4 years.
>
> here's the model:
>
> y <- cbind(total females, (Total - total females)))
>
> mod1 <- with(data, glmer(y ~ disease prevalence +  (1|Site) + (1|Year),
> family = binomial,  data = data1))

  Just to be clear, disease prevalence is a number in [0,1]?
>
> 1) This model runs, but the summary(mod1) just generates a series of the
> following....which doesn't make any sense so something must be wrong with
> the model specification...I'm just not sure what.
>
> 2) Also, what is the default AR correlation on these models (i.e., do I
> need to specify it or is the temporal psuedoreplication taken care of)?

  AR models are not currently easy in lme4.  My suggestion (=hack) would
be to get the residuals and use nlme::gls(resid~1,correlation=corAR1()) (or
something like that) to see if you should worry about autoregressive structure.

  Four years is not very many, so you might need to treat Year as a
fixed effect (e.g. I would consider that option if the random effects variance
is estimated as zero)

  How many sites?  How many total observations?

  I have to admit that I'm stumped by your apparent model output (i.e.
that there are multiple parameters for disease prevalence when there
should only be one)

  Perhaps you could send the results of summary(data1) and/or
str(data1) and summary() of your whole model?

>
> 3) Finally, do you suggest another form of the model that's better etc.?
>
> Fixed effects:
>                                 Estimate             Std. Error    z value
>    Pr(>|z|)
> (Intercept)                  -1.60267            0.11618    -13.794    <
> 2e-16 ***
> disease prevalence    -0.40212           0.15557     -2.585     0.009745 **
> disease prevalence    0.035088231    -1.46452    0.22860  -6.406 1.49e-10
> ***
> disease prevalence    0.064935065     -0.36344   0.30810  -1.180 0.238157
>
> disease prevalence    0.078507945    -2.57479    0.46537  -5.533 3.15e-08
> ***
> disease prevalence    0.120039255    -3.30998    0.71915  -4.603 4.17e-06
> ***
> disease prevalence    0.182623706     -0.14362   0.19899  -0.722 0.470438
>
>


From bbolker at gmail.com  Thu Sep 24 05:07:26 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Sep 2015 23:07:26 -0400
Subject: [R-sig-ME] mixed effects model glmer
In-Reply-To: <CAFJT+3Lk-jK+oNgEAudQQXU9J6wkfK+JiSBWpp+3vBV+LZ8q5A@mail.gmail.com>
References: <CAFJT+3JfeAYXU-iOsYB8Fb1i21qRvfo++PZqLSBg1zSNPP7rEw@mail.gmail.com>
	<CABghstR_VA4EHeL+0pur3khdZ=+ozapaRQJ6UAAPM4hj1FV2zg@mail.gmail.com>
	<CAFJT+3Lk-jK+oNgEAudQQXU9J6wkfK+JiSBWpp+3vBV+LZ8q5A@mail.gmail.com>
Message-ID: <CABghstRya9gdNtdt_sRsKU8nJ5yvb3MELoR_zzQhPgMCEUPWMQ@mail.gmail.com>

[I'm taking the liberty of cc'ing r-sig-mixed-models on this; please keep the
mailing list in the cc: list when responding]

 the main problem, which should be very easy to fix, is simply that
your predictor variable accidentally got turned into a factor!

  Try

data1 <- transform(data1,
   disease.prevalence=as.numeric(as.character(disease.prevalence)))

  Additionally:

  there's nothing necessarily wrong with means/year.  Take a second look
at things after you have un-mangled your data ...

On Wed, Sep 23, 2015 at 6:26 PM, M West <westm490 at gmail.com> wrote:
> Hi Dr. Bolker,
>
> Thanks for getting back to me.
>
>  Just to be clear, disease prevalence is a number in [0,1]?
>
> Not currently, it's just percentage infected out of total (e.g., 20/400).
> I can change it if I need to....
>
>
> Four years is not very many, so you might need to treat Year as a
> fixed effect (e.g. I would consider that option if the random effects
> variance
> is estimated as zero).
>
>
>
>  How many sites?  How many total observations?
> 15 sites total each year.
>
> Can do. We sample every two weeks for ~3-4 months per year. So, I collapsed
> the data down to
> means/year....maybe that's no good either.
>
>
> I have to admit that I'm stumped by your apparent model output (i.e.
> that there are multiple parameters for disease prevalence when there
> should only be one)
>
>   Perhaps you could send the results of summary(data1) and/or
> str(data1) and summary() of your whole model?
>
> Sure, thy are all down below...I can also send you the data and code if
> that's easier.
>
> summary(data1)
>
>     Site        Site.1            Year           Max_P         variable_X
> disease prevalence   Average.of...male Average.of.Total.Female
> Average.of.total.all
>            :57   Min.   : 1              :56              :57
> :57              :57                  :74      Min.   : 2.00         Min.
> :106.0
>  Asite   : 6   1st Qu.: 4   2009       :15   0          : 2   1.260095428: 2
> 0          : 3       0.633898824: 1      1st Qu.: 8.75         1st Qu.:295.8
>  Bsite: 6   Median : 8   2010       :15   0.912379678: 2   10.90217665: 2
> 14.50737238: 2       0.770941362: 1      Median :21.50         Median :414.5
>  BCsite  : 6   Mean   : 8   2011       :15   1.841225901: 2   14.44718559: 2
> 2.089865262: 2       0.853637644: 1      Mean   :24.10         Mean   :400.8
>  Csite: 6   3rd Qu.:12   2014       :15   1.956818222: 2   18.02232207: 2
> 2.208160622: 2       1.008902322: 1      3rd Qu.:30.25         3rd Qu.:513.8
>  Dsite  : 6   Max.   :15   11.20859993: 2   10.69047265: 2   18.5213911 : 2
> 2.643993383: 2       1.00895193 : 1      Max.   :89.00         Max.   :648.0
>  (Other)   :62   NA's   :89   (Other)    :31   (Other)    :82
>
>
>
> summary(moda)
>
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: y ~ disease.prevalence + (1 | Lake) + (1 | Year)
>    Data: males1
>
>      AIC      BIC   logLik deviance df.resid
>    419.3    545.0   -149.7    299.3        0
>
> Scaled residuals:
>    Min     1Q Median     3Q    Max
> -3.470  0.000  0.000  0.000  1.989
>
> Random effects:
>  Groups Name        Variance Std.Dev.
>  Site   (Intercept) 0        0
>  Year   (Intercept) 0        0
> Number of obs: 60, groups:  Lake, 15; Year, 4
>
> Fixed effects:
>                               Estimate Std. Error z value Pr(>|z|)
> (Intercept)                   -1.60267    0.11618 -13.794  < 2e-16 ***
> disease.prevalence0           -0.40212    0.15557  -2.585 0.009745 **
> disease.prevalence0.035088231 -1.46452    0.22860  -6.406 1.49e-10 ***
> disease.prevalence0.064935065 -0.36344    0.30810  -1.180 0.238157
> disease.prevalence0.078507945 -2.57479    0.46537  -5.533 3.15e-08 ***
> disease.prevalence0.120039255 -3.30998    0.71915  -4.603 4.17e-06 ***
>
> this goes on forever and then there's this:
>
> Correlation matrix not shown by default, as p = 58 > 20.
> Use print(...., correlation=TRUE)  or
> vcov(....) if you need it
>
>
>
>
> str(data1)
> 'data.frame': 149 obs. of  12 variables:
>  $ Site                     : Factor w/ 18 levels "","Alake","BDlake",..: 2
> 3 4 5 6 7 8 9 10 12 ...
>  $ Site1                    : int  1 2 3 4 5 6 7 8 9 10 ...
>  $ Year                      : Factor w/ 22 levels "","11.20859993",..: 7 7
> 7 7 7 7 7 7 7 7 ...
>  $ disease.prevalence        : Factor w/ 75 levels "","0","0.035088231",..:
> 8 35 5 69 6 56 11 51 50 26 ...
>  $ Average.of...male         : Factor w/ 76 levels "","0.633898824",..: 14
> 32 31 61 5 45 11 62 68 60 ...
>  $ Average.of.Total.Female     : int  7 14 5 31 2 22 6 21 14 24 ...
>  $ Average.of.total.all     : int  405 553 331 512 274 648 338 388 230 454
> ....
>  $ Change.in.percent.females   : num  1.581 2.466 2.535 5.183 0.843 ...
>
>
>
>
> On Wed, Sep 23, 2015 at 4:41 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> On Wed, Sep 23, 2015 at 2:36 PM, M West <westm490 at gmail.com> wrote:
>> > I am trying to fit a mixed effects model with repeated measures data.
>> >
>> > Data are:
>> >
>> > y variable = percentage (# females/total)
>> > x variable = percentage
>> >
>> > measured across multiple sites for 4 years.
>> >
>> > here's the model:
>> >
>> > y <- cbind(total females, (Total - total females)))
>> >
>> > mod1 <- with(data, glmer(y ~ disease prevalence +  (1|Site) + (1|Year),
>> > family = binomial,  data = data1))
>>
>>   Just to be clear, disease prevalence is a number in [0,1]?
>> >
>> > 1) This model runs, but the summary(mod1) just generates a series of the
>> > following....which doesn't make any sense so something must be wrong
>> > with
>> > the model specification...I'm just not sure what.
>> >
>> > 2) Also, what is the default AR correlation on these models (i.e., do I
>> > need to specify it or is the temporal psuedoreplication taken care of)?
>>
>>   AR models are not currently easy in lme4.  My suggestion (=hack) would
>> be to get the residuals and use nlme::gls(resid~1,correlation=corAR1())
>> (or
>> something like that) to see if you should worry about autoregressive
>> structure.
>>
>>   Four years is not very many, so you might need to treat Year as a
>> fixed effect (e.g. I would consider that option if the random effects
>> variance
>> is estimated as zero)
>>
>>   How many sites?  How many total observations?
>>
>>   I have to admit that I'm stumped by your apparent model output (i.e.
>> that there are multiple parameters for disease prevalence when there
>> should only be one)
>>
>>   Perhaps you could send the results of summary(data1) and/or
>> str(data1) and summary() of your whole model?
>>
>> >
>> > 3) Finally, do you suggest another form of the model that's better etc.?
>> >
>> > Fixed effects:
>> >                                 Estimate             Std. Error    z
>> > value
>> >    Pr(>|z|)
>> > (Intercept)                  -1.60267            0.11618    -13.794    <
>> > 2e-16 ***
>> > disease prevalence    -0.40212           0.15557     -2.585     0.009745
>> > **
>> > disease prevalence    0.035088231    -1.46452    0.22860  -6.406
>> > 1.49e-10
>> > ***
>> > disease prevalence    0.064935065     -0.36344   0.30810  -1.180
>> > 0.238157
>> >
>> > disease prevalence    0.078507945    -2.57479    0.46537  -5.533
>> > 3.15e-08
>> > ***
>> > disease prevalence    0.120039255    -3.30998    0.71915  -4.603
>> > 4.17e-06
>> > ***
>> > disease prevalence    0.182623706     -0.14362   0.19899  -0.722
>> > 0.470438
>> >
>> >
>
>


From thierry.onkelinx at inbo.be  Thu Sep 24 09:44:00 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 24 Sep 2015 09:44:00 +0200
Subject: [R-sig-ME] mixed effects model glmer
In-Reply-To: <CABghstR_VA4EHeL+0pur3khdZ=+ozapaRQJ6UAAPM4hj1FV2zg@mail.gmail.com>
References: <CAFJT+3JfeAYXU-iOsYB8Fb1i21qRvfo++PZqLSBg1zSNPP7rEw@mail.gmail.com>
	<CABghstR_VA4EHeL+0pur3khdZ=+ozapaRQJ6UAAPM4hj1FV2zg@mail.gmail.com>
Message-ID: <CAJuCY5wTNBAf+wzZafxW5VUMREeqMFegob6sOba1KFTbWEbsDw@mail.gmail.com>

Adding a random effect is equivalent to a compound symmetry
correlation structure. Since you have only 4 years, it would be too
bad compared to an AR1 correlation structure.

If you really need correlated random effects, then you can have a look
at the INLA package. Not on CRAN but on www.r-inla.org.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-09-23 22:41 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
> On Wed, Sep 23, 2015 at 2:36 PM, M West <westm490 at gmail.com> wrote:
>> I am trying to fit a mixed effects model with repeated measures data.
>>
>> Data are:
>>
>> y variable = percentage (# females/total)
>> x variable = percentage
>>
>> measured across multiple sites for 4 years.
>>
>> here's the model:
>>
>> y <- cbind(total females, (Total - total females)))
>>
>> mod1 <- with(data, glmer(y ~ disease prevalence +  (1|Site) + (1|Year),
>> family = binomial,  data = data1))
>
>   Just to be clear, disease prevalence is a number in [0,1]?
>>
>> 1) This model runs, but the summary(mod1) just generates a series of the
>> following....which doesn't make any sense so something must be wrong with
>> the model specification...I'm just not sure what.
>>
>> 2) Also, what is the default AR correlation on these models (i.e., do I
>> need to specify it or is the temporal psuedoreplication taken care of)?
>
>   AR models are not currently easy in lme4.  My suggestion (=hack) would
> be to get the residuals and use nlme::gls(resid~1,correlation=corAR1()) (or
> something like that) to see if you should worry about autoregressive structure.
>
>   Four years is not very many, so you might need to treat Year as a
> fixed effect (e.g. I would consider that option if the random effects variance
> is estimated as zero)
>
>   How many sites?  How many total observations?
>
>   I have to admit that I'm stumped by your apparent model output (i.e.
> that there are multiple parameters for disease prevalence when there
> should only be one)
>
>   Perhaps you could send the results of summary(data1) and/or
> str(data1) and summary() of your whole model?
>
>>
>> 3) Finally, do you suggest another form of the model that's better etc.?
>>
>> Fixed effects:
>>                                 Estimate             Std. Error    z value
>>    Pr(>|z|)
>> (Intercept)                  -1.60267            0.11618    -13.794    <
>> 2e-16 ***
>> disease prevalence    -0.40212           0.15557     -2.585     0.009745 **
>> disease prevalence    0.035088231    -1.46452    0.22860  -6.406 1.49e-10
>> ***
>> disease prevalence    0.064935065     -0.36344   0.30810  -1.180 0.238157
>>
>> disease prevalence    0.078507945    -2.57479    0.46537  -5.533 3.15e-08
>> ***
>> disease prevalence    0.120039255    -3.30998    0.71915  -4.603 4.17e-06
>> ***
>> disease prevalence    0.182623706     -0.14362   0.19899  -0.722 0.470438
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r.sardell at med.miami.edu  Thu Sep 24 17:47:36 2015
From: r.sardell at med.miami.edu (Sardell, Rebecca Joanne)
Date: Thu, 24 Sep 2015 15:47:36 +0000
Subject: [R-sig-ME] MCMCglmm bivariate model
Message-ID: <SN1PR0701MB1966624D1E46F951D50D8D5CBE430@SN1PR0701MB1966.namprd07.prod.outlook.com>

Hi all,
I'm using MCMCglmm to estimate the heritability of 2 traits and their genetic correlation in a repeated measures animal model. My data consists of 500 individuals each measured twice for each trait with a few missing values. y1 is Gaussian, y2 is ordered discrete categories 0-5. Separate models for each trait run ok but I have 2 issues with a bivariate model.


1)      the bivariate model gives a bimodal posterior distribution for the trait y2:ID term with one peak at ~4 (similar to the univariate model) and a second peak at zero. I'm using parameter expanded priors and both mixing and convergence look ok according to trace plots, Geweke plots and Heidelberg tests. Autocorrelation is <0.13. The ID term does have some support at zero in a univariate model of y2 but has a clear mode at 4, whereas in the bivariate model there is equal support for 0 and 4.



2)      The fixed effect, location (a 3 level factor), is only relevant for trait y1. In the univariate model for y1 the 3 levels are estimated ok with no error but in the bivariate model using trait-1 + at.level(trait, 1):location gives the error "In MCMCglmm(cbind(y1, y2) ~ trait - 1 + at.level(trait,  :  some fixed effects are not estimable and have been removed. Use singular.ok=TRUE to sample these effects, but use an informative prior!" and gives estimates in the summary table for locations 1 and 2, suggesting location 3 could not be estimated? Using trait-1+trait:location does not give an error and gives estimates for locations 2 and 3 in the summary table for both traits, which presumably are contrasts from the "trait y1" that corresponds to location 1.


Can anyone advise on these 2 issues? Am I using at.level(trait, 1) correctly? I've copied my code and output below:
Thanks in advance,
Rebecca
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
univariate models:
P1<- list(G = list(G1 = list(V = 1, n = 0.002), G2 = list(V = 1,n = 0.002)), R = list(V = 1, n = 0.002))
M1<-MCMCglmm(y1~age+location+size,
random=~animal+ID,
pedigree=ped,
data=pheno2,prior=P1,nitt=1010000,thin=1000,burnin=10000,verbose=FALSE)

> summary(M1)
Iterations = 10001:1009001
Thinning interval  = 1000
Sample size  = 1000

DIC: 10909.28

G-structure:  ~animal

       post.mean l-95% CI u-95% CI eff.samp
animal      1144    444.3     1885     1162

               ~ID

   post.mean l-95% CI u-95% CI eff.samp
ID      1750     1184     2462     1000

R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units     793.1    700.6    896.2     1000

Location effects: y1 ~ age + location + size

            post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)   469.474  434.740  502.941     1000 <0.001 ***
age            -3.409   -3.950   -2.958     1000 <0.001 ***
location2    23.355   10.235   37.260     1000  0.002 **
location3   -14.113  -29.935    3.468     1000  0.114
size      4.782    2.300    7.316     1000 <0.001 ***
---

> posterior.heritability<-M1$VCV[,"animal"]/(M1$VCV[,"animal"]+M1$VCV[,"ID"]+M1$VCV[,"units"])
> mean(posterior.heritability)
[1] 0.31

~~~~~~~~~~~~~~~~~~~~~~~~~~
P2 <- list(R=list(V = 1 , fix=1), G = list(G1=list(V=1, nu=1,alpha.mu=0, alpha.V=1000),G2=list(V=1, nu=1, alpha.mu=0, alpha.V=1000)))
M2<-MCMCglmm(y2~age,random=~animal+ID,pedigree=ped,family="threshold",data=pheno2,prior=P2,verbose=FALSE, nitt=10500000,thin=2000,burnin=500000)
> summary(M2)

Iterations = 500001:10498001
Thinning interval  = 2000
Sample size  = 5000

DIC: 1270.806

G-structure:  ~animal

       post.mean l-95% CI u-95% CI eff.samp
animal     10.38    4.473    16.46     4162

               ~ID

   post.mean l-95% CI u-95% CI eff.samp
ID     4.291 2.09e-05     8.01     3910

R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

Location effects: y2 ~ age

            post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)  -11.6004 -14.5259  -8.9838     5000 <2e-04 ***
age            0.1794   0.1404   0.2218     5000 <2e-04 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Cutpoints:
                      post.mean l-95% CI u-95% CI eff.samp
cutpoint.traity2.1     2.895    2.461    3.314     5351
cutpoint.trait y2.2     4.610    4.069    5.268     4793
cutpoint.trait y2.3     7.398    6.527    8.348     5000
cutpoint.trait y2.4    11.917   10.013   13.981     5141

> posterior.heritability<-M2$VCV[,"animal"]/(M2$VCV[,"animal"]+M2$VCV[,"ID"]+M2$VCV[,"units"])
> mean(posterior.heritability)
[1] 0.66


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Bivariate model:
P3 = list(R = list(V = diag(2), nu = 1.002, fix = 2), G = list(G1 = list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),G2 = list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
M3<-MCMCglmm(cbind(y1, y2) ~ trait - 1 + at.level(trait, 1):location + trait:age + at.level(trait, 1):size,
pedigree=ped, data=pheno2,
random = ~us(trait):animal+us(trait):ID,
rcov = ~us(trait):units,  family = c("gaussian", "threshold"),
prior = P3, verbose = FALSE, nitt=10500000,thin=2000,burnin=500000)

> summary(M3)

Iterations = 500001:10498001
Thinning interval  = 2000
Sample size  = 5000

DIC: 12151.2

G-structure:  ~us(trait):animal

                           post.mean l-95% CI u-95% CI eff.samp
y1:y1.animal   1156.88  435.518 1870.316     5000
y2:y1.animal        -39.70  -83.129    5.598     4666
y1:y2.animal        -39.70  -83.129    5.598     4666
y2:y2.animal             11.04    4.659   17.753     3657

               ~us(trait):ID

                       post.mean   l-95% CI u-95% CI eff.samp
y1:y1.ID  1743.758  1.124e+03 2351.973     5000
y2:y1.ID       -12.174 -4.464e+01   20.891     5000
y1:y2.ID       -12.174 -4.464e+01   20.891     5000
y2:y2.ID             3.876  3.188e-06    7.734     3514

R-structure:  ~us(trait):units

                          post.mean l-95% CI u-95% CI eff.samp
y1:y1.units   791.876  696.035    882.1     4568
y2:y1.units         2.582   -1.169      6.1     5000
y1:y2.units         2.582   -1.169      6.1     5000
y2:y2.units             1.000    1.000      1.0        0

Location effects: cbind(y1, y2) ~ trait - 1 + at.level(trait, 1):loca

                               post.mean l-95% CI u-95% CI eff.samp  pMCMC
traity1                  456.6321 419.7208 494.7115     5239 <2e-04 ***
traity2                      -11.5170 -14.4037  -8.8785     4137 <2e-04 ***
at.level(trait, 1):location1   11.6986  -4.0319  28.8620     5000 0.1676
at.level(trait, 1):location2   37.8950  22.5601  53.8510     5000 <2e-04 ***
traity1:age               -3.4116  -3.9302  -2.9405     5209 <2e-04 ***
traity2:age                    0.1779   0.1383   0.2184     4670 <2e-04 ***
at.level(trait, 1):size     4.4378   1.9564   6.9510     5421 0.0004 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Cutpoints:
                      post.mean l-95% CI u-95% CI eff.samp
cutpoint.traity2.1     2.890    2.473    3.308     4696
cutpoint.trait y2.2     4.600    4.074    5.186     4474
cutpoint.trait y2.3     7.451    6.565    8.327     4071
cutpoint.trait y2.4    12.053   10.131   14.039     4045


herit_y1<- M3$VCV[,'y1:y1.animal']/( M3$VCV[,'y1:y1.animal']+ M3$VCV[,'y1:y1.ID']+ M3$VCV[,'y1:y1.units'])
mean(herit_y1)
=0.31 (0.13-0.48)

herit_y2<- M3$VCV[,'y2:y2.animal']/( M3$VCV[,'y2:y2.animal']+ M3$VCV[,'y2:y2.ID']+ M3$VCV[,'y2:y2.units'])
mean(herit_y2)
=0.68 (0.42-0.95)

corr.gen<- M3$VCV[,'y1:y2.animal']/sqrt(M3$VCV[,'y1:y1.animal']* M3$VCV[,y2:y2.animal'])
mean(corr.gen)
=-0.36 (-0.70-0.004)


~~~~~~~~~~~~~~~~~~~~~~~~~~~~
summary table for bivariate model with trait:location instead of at.level(trait, 1):location

Location effects: cbind(y1, y2) ~ trait - 1 + trait:location + trait:age + at.level(trait, 1):size

                              post.mean l-95% CI u-95% CI eff.samp  pMCMC
traity1                 468.8456 433.1704 499.3057   761.34 <0.001 ***
traity2                     -11.6934 -14.6120  -9.0283    88.10 <0.001 ***
traity1:location2      23.5282  10.8358  36.8648  1000.00 <0.001 ***
traity2:location2           0.9043  -0.2198   2.1732   341.51  0.128
traity1:location3     -14.6928 -30.8528   1.0206   887.36  0.074 .
traity2:location3           0.8966  -0.4732   2.3384   453.18  0.218
traity1:age              -3.3947  -3.9142  -2.9634   839.89 <0.001 ***
traity2:age                   0.1718   0.1356   0.2125    92.35 <0.001 ***
at.level(trait, 1):size    4.4933   2.2326   7.3976  1000.00  0.002 **



	[[alternative HTML version deleted]]


From westm490 at gmail.com  Thu Sep 24 18:31:34 2015
From: westm490 at gmail.com (M West)
Date: Thu, 24 Sep 2015 12:31:34 -0400
Subject: [R-sig-ME] mixed effects model glmer
In-Reply-To: <CAJuCY5wTNBAf+wzZafxW5VUMREeqMFegob6sOba1KFTbWEbsDw@mail.gmail.com>
References: <CAFJT+3JfeAYXU-iOsYB8Fb1i21qRvfo++PZqLSBg1zSNPP7rEw@mail.gmail.com>
	<CABghstR_VA4EHeL+0pur3khdZ=+ozapaRQJ6UAAPM4hj1FV2zg@mail.gmail.com>
	<CAJuCY5wTNBAf+wzZafxW5VUMREeqMFegob6sOba1KFTbWEbsDw@mail.gmail.com>
Message-ID: <CAFJT+3Lf8FHn_tg8U_EBxtctw_QADrzZXvSCB6NkZTfvpZAKqA@mail.gmail.com>

Ah. that worked - no idea why that happened.
Thanks so much! - I'll know what it looks like if that ever happens again.

M.

On Thu, Sep 24, 2015 at 3:44 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Adding a random effect is equivalent to a compound symmetry
> correlation structure. Since you have only 4 years, it would be too
> bad compared to an AR1 correlation structure.
>
> If you really need correlated random effects, then you can have a look
> at the INLA package. Not on CRAN but on www.r-inla.org.
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2015-09-23 22:41 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
> > On Wed, Sep 23, 2015 at 2:36 PM, M West <westm490 at gmail.com> wrote:
> >> I am trying to fit a mixed effects model with repeated measures data.
> >>
> >> Data are:
> >>
> >> y variable = percentage (# females/total)
> >> x variable = percentage
> >>
> >> measured across multiple sites for 4 years.
> >>
> >> here's the model:
> >>
> >> y <- cbind(total females, (Total - total females)))
> >>
> >> mod1 <- with(data, glmer(y ~ disease prevalence +  (1|Site) + (1|Year),
> >> family = binomial,  data = data1))
> >
> >   Just to be clear, disease prevalence is a number in [0,1]?
> >>
> >> 1) This model runs, but the summary(mod1) just generates a series of the
> >> following....which doesn't make any sense so something must be wrong
> with
> >> the model specification...I'm just not sure what.
> >>
> >> 2) Also, what is the default AR correlation on these models (i.e., do I
> >> need to specify it or is the temporal psuedoreplication taken care of)?
> >
> >   AR models are not currently easy in lme4.  My suggestion (=hack) would
> > be to get the residuals and use nlme::gls(resid~1,correlation=corAR1())
> (or
> > something like that) to see if you should worry about autoregressive
> structure.
> >
> >   Four years is not very many, so you might need to treat Year as a
> > fixed effect (e.g. I would consider that option if the random effects
> variance
> > is estimated as zero)
> >
> >   How many sites?  How many total observations?
> >
> >   I have to admit that I'm stumped by your apparent model output (i.e.
> > that there are multiple parameters for disease prevalence when there
> > should only be one)
> >
> >   Perhaps you could send the results of summary(data1) and/or
> > str(data1) and summary() of your whole model?
> >
> >>
> >> 3) Finally, do you suggest another form of the model that's better etc.?
> >>
> >> Fixed effects:
> >>                                 Estimate             Std. Error    z
> value
> >>    Pr(>|z|)
> >> (Intercept)                  -1.60267            0.11618    -13.794    <
> >> 2e-16 ***
> >> disease prevalence    -0.40212           0.15557     -2.585
>  0.009745 **
> >> disease prevalence    0.035088231    -1.46452    0.22860  -6.406
> 1.49e-10
> >> ***
> >> disease prevalence    0.064935065     -0.36344   0.30810  -1.180
> 0.238157
> >>
> >> disease prevalence    0.078507945    -2.57479    0.46537  -5.533
> 3.15e-08
> >> ***
> >> disease prevalence    0.120039255    -3.30998    0.71915  -4.603
> 4.17e-06
> >> ***
> >> disease prevalence    0.182623706     -0.14362   0.19899  -0.722
> 0.470438
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep 25 03:09:33 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 25 Sep 2015 01:09:33 +0000 (UTC)
Subject: [R-sig-ME] Convergence Error: 0 Fixed Correlations and More
References: <CA+6pzmdcRW7Yx_RgvuSSR3kTFUPz2AeSep2x50_r-LpCXH0tfA@mail.gmail.com>
	<CAJuCY5zh0VwzUPU+3HVPy_oKeKUNaYf+yziLWzdqyQPGS9egEA@mail.gmail.com>
	<CABghstQ6Qx1XxdMDLYZEJTUPMQRwna1BwTt7LE_RYx7XyA8bzw@mail.gmail.com>
	<20150922141529.GB25089@info124.pharmacie.univ-paris5.fr>
Message-ID: <loom.20150925T030200-459@post.gmane.org>

Emmanuel Curis <emmanuel.curis at ...> writes:

> 
> Speaking about this factor variables coding to have uncorrelated
> random effects... Following Thierry Onkelinx's advice [thanks a lot
> for this advice, by the way, I think I didn't answered yet, sorry], I
> wrote down the models for a similar case, and it turned out that when
> having uncorrelated random effects for all levels of a covariate, then
> the Y variables were also uncorrelated, but it allowed different
> variances for each level.

> 
> I thought one advantage of random effects was to introduce
> correlations between observations taken for the same patient, so I
> wonder if this trick really does what one expects (assuming I didn't
> made mistakes, and I am not the only one to have this idea about
> consequences of random effects), and that specifying special random
> effects covariance matrix structures is less error-prone with nlme?

  I think at least one of us is confused.  Specifying uncorrelated
random effects terms doesn't (I think) mean the predictor variables are 
uncorrelated.  It means the variation of the effects of predictor
variables across groups is uncorrelated.  

  In particular, if the model specifies that the intercept term varies
across groups, then this *does* induce correlations within groups,
because the observations within the group share a random effect
(which means there is less variation within a group than across
the overall population).  Admittedly, this is the only kind of
correlation the stable branch of lme4 allows (not AR1, or
other interesting correlation structures -- only (positive)
compound symmetry.  If nlme works for your problem, by all means
use it ... but lme4 does 'real' GLMMs (not just via PQL), and
is faster than nlme for LMMs ...


 [snipped context to make Gmane happy]


From etnbot1 at gmail.com  Thu Sep 24 16:06:51 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Thu, 24 Sep 2015 15:06:51 +0100
Subject: [R-sig-ME] Linear mixed model query
Message-ID: <CAF79uvk-ThiNNg36=RtRspitwVgYsu2ogPoQypdxS+Y4=1aNUQ@mail.gmail.com>

Hi all,

My study looks at allergy levels of skin patches from patients and readings
(repeated 5 times) are measured over 4 time points

I need to determine if the allergy level for skin patch changes over time
(e.g. if allergy level from skin patch 1 for patient 1 at time 0 is
different from allergy level for skin patch 1 for patient 1 at time 1 etc.)
I do not want to see the difference between skin patch 1 and skin patch
2....

using package lmer:
model<-lmer(allergy_level ~ time +(time|patient/patch))

Results from this model indicate that time is not significant - the average
patient allergy level for individual skin patches does not change over
time:

Random effects:

 Groups   Name        Variance Std.Dev. Corr

 ID:patch (Intercept) 17.4109  4.1726

          time1        2.7109  1.6465   -0.30

          time2        3.0082  1.7344   -0.26  0.60

          time3        5.7643  2.4009   -0.35  0.15  0.54

 patch    (Intercept) 19.1576  4.3769

          time1        0.2103  0.4586   -0.56

          time2        0.4372  0.6612   -0.94  0.48

          time3        0.5895  0.7678   -0.48  0.96  0.49

 Residual              4.9467  2.2241

Number of obs: 2956, groups:  ID:patch, 149; patch, 16



Fixed effects:

            Estimate Std. Error t value

(Intercept)  6.44763    1.15028   5.605

time1       -0.01907    0.21237  -0.090

time2       -0.03172    0.24759  -0.128

time3       -0.01124    0.29940  -0.038





model1: Force ~ 1 + (1 + time | patch/ID)

model2: Force ~ time + (1 + time | patch/ID)

         Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)

model11 22 14281 14413 -7118.5    14237

model12 25 14287 14437 -7118.4    14237 0.0208      3     0.9992

I have extracted the random coefficients from model 1:

ranef(model1)

$`ID:patch`

      (Intercept)       time1        time2        time3

1:11    5.9845070  0.34088535  0.431998708  1.590906238

1:12    5.1236456 -0.03178611 -0.149784278 -0.116150278

1:13    6.3746877 -0.76853294 -0.550037715  0.842518786
   :
   :
However, I need to be able to tell if there is a significant difference for
individual patches for individual patients over time

e.g.
If I run individual linear regression on patient 1 for skin patch 1,
results show that that time is significant:

Coefficients:

            Estimate Std. Error t value Pr(>|t|)

(Intercept)  18.0800     0.6523  27.717 5.95e-15 ***

time1         0.3600     0.9225   0.390 0.701502

time2         1.2400     0.9225   1.344 0.197641

time3        -4.3400     0.9225  -4.705 0.000239 ***

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



Residual standard error: 1.459 on 16 degrees of freedom

Multiple R-squared:  0.7323,    Adjusted R-squared:  0.6821

F-statistic: 14.59 on 3 and 16 DF,  p-value: 7.679e-05


If I run individual regression models for each skin patch for each patient,
this will result in a large number of models as I have There are 16 skin
patches per patient. (10 patients in total) 5 readings are taken at each of
the 4 time points.

I thought linear mixed models would be an appropriate method to answer my
question (I need to be able to tell if there is a significant difference
for individual patches for individual patients over time).

Any advice is greatly appreciated,

Many thanks

Etn

	[[alternative HTML version deleted]]


From m51988mnew at juno.com  Thu Sep 24 15:19:29 2015
From: m51988mnew at juno.com (m51988mnew at juno.com)
Date: Thu, 24 Sep 2015 13:19:29 GMT
Subject: [R-sig-ME] question about degrees of freedom in lmer , library(lme4)
Message-ID: <20150924.091929.24540.0@webmail13.dca.untd.com>

Mr. Bolker,
 Perhaps you can help me with a question about lmer  in library(lme4). 
 In SAs proc mixed there are various options for calculating degrees of
 freedom for fixed effects.
 This matters when the standard error of an estimate is a linear combination
 of mean squares, for which proc mixed provides sat and kr options.
 Does lmer have such options?
 Thank you.
 Stanley Shulman
____________________________________________________________
Buffett?s New Enemy
Buffett just confirmed his worst fear. Click here for his warning.
http://thirdpartyoffers.juno.com/TGL3141/5603f88ec344f788e63c8st03duc
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep 25 21:36:07 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 25 Sep 2015 15:36:07 -0400
Subject: [R-sig-ME] question about degrees of freedom in lmer ,
	library(lme4)
In-Reply-To: <20150924.091929.24540.0@webmail13.dca.untd.com>
References: <20150924.091929.24540.0@webmail13.dca.untd.com>
Message-ID: <CABghstT_O1riNn1H99ez9xUjY9G37_=m59jS+SBJ3aUtpW4pLg@mail.gmail.com>

  check out the pbkrtest, lmerTest, and afex packages (and the ?pvalues
help page in the lme4 package, which points you in those directions)

On Thu, Sep 24, 2015 at 9:19 AM, m51988mnew at juno.com
<m51988mnew at juno.com> wrote:
> Mr. Bolker,
>  Perhaps you can help me with a question about lmer  in library(lme4).
>  In SAs proc mixed there are various options for calculating degrees of
>  freedom for fixed effects.
>  This matters when the standard error of an estimate is a linear combination
>  of mean squares, for which proc mixed provides sat and kr options.
>  Does lmer have such options?
>  Thank you.
>  Stanley Shulman
> ____________________________________________________________
> Buffett?s New Enemy
> Buffett just confirmed his worst fear. Click here for his warning.
> http://thirdpartyoffers.juno.com/TGL3141/5603f88ec344f788e63c8st03duc
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Sep 25 21:47:30 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 25 Sep 2015 15:47:30 -0400
Subject: [R-sig-ME] Linear mixed model query
In-Reply-To: <CAF79uvk-ThiNNg36=RtRspitwVgYsu2ogPoQypdxS+Y4=1aNUQ@mail.gmail.com>
References: <CAF79uvk-ThiNNg36=RtRspitwVgYsu2ogPoQypdxS+Y4=1aNUQ@mail.gmail.com>
Message-ID: <CABghstS9jOAxjRZNQLbk-A5k_6p72_p7=j1YPmqccKuL65yY9w@mail.gmail.com>

On Thu, Sep 24, 2015 at 10:06 AM, Etn bot <etnbot1 at gmail.com> wrote:
> Hi all,
>
> My study looks at allergy levels of skin patches from patients and readings
> (repeated 5 times) are measured over 4 time points
>
> I need to determine if the allergy level for skin patch changes over time
> (e.g. if allergy level from skin patch 1 for patient 1 at time 0 is
> different from allergy level for skin patch 1 for patient 1 at time 1 etc.)
> I do not want to see the difference between skin patch 1 and skin patch
> 2....
>
> using package lmer:
> model<-lmer(allergy_level ~ time +(time|patient/patch))
>
> Results from this model indicate that time is not significant - the average
> patient allergy level for individual skin patches does not change over
> time:
>
> Random effects:
>
>  Groups   Name        Variance Std.Dev. Corr
>
>  ID:patch (Intercept) 17.4109  4.1726
>
>           time1        2.7109  1.6465   -0.30
>
>           time2        3.0082  1.7344   -0.26  0.60
>
>           time3        5.7643  2.4009   -0.35  0.15  0.54
>
>  patch    (Intercept) 19.1576  4.3769
>
>           time1        0.2103  0.4586   -0.56
>
>           time2        0.4372  0.6612   -0.94  0.48
>
>           time3        0.5895  0.7678   -0.48  0.96  0.49
>
>  Residual              4.9467  2.2241
>
> Number of obs: 2956, groups:  ID:patch, 149; patch, 16
>
>
>
> Fixed effects:
>
>             Estimate Std. Error t value
>
> (Intercept)  6.44763    1.15028   5.605
>
> time1       -0.01907    0.21237  -0.090
>
> time2       -0.03172    0.24759  -0.128
>
> time3       -0.01124    0.29940  -0.038
>
>
   I was going to ask if you wanted to treat time as linear, but there's
not much evidence that it will help you here.
>
>
>
> model1: Force ~ 1 + (1 + time | patch/ID)
>
> model2: Force ~ time + (1 + time | patch/ID)
>
>          Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>
> model11 22 14281 14413 -7118.5    14237
>
> model12 25 14287 14437 -7118.4    14237 0.0208      3     0.9992
>
> I have extracted the random coefficients from model 1:
>
> ranef(model1)
>
> $`ID:patch`
>
>       (Intercept)       time1        time2        time3
>
> 1:11    5.9845070  0.34088535  0.431998708  1.590906238
>
> 1:12    5.1236456 -0.03178611 -0.149784278 -0.116150278
>
> 1:13    6.3746877 -0.76853294 -0.550037715  0.842518786
>    :
>    :
> However, I need to be able to tell if there is a significant difference for
> individual patches for individual patients over time
>
> e.g.
> If I run individual linear regression on patient 1 for skin patch 1,
> results show that that time is significant:
>
> Coefficients:
>
>             Estimate Std. Error t value Pr(>|t|)
>
> (Intercept)  18.0800     0.6523  27.717 5.95e-15 ***
>
> time1         0.3600     0.9225   0.390 0.701502
>
> time2         1.2400     0.9225   1.344 0.197641
>
> time3        -4.3400     0.9225  -4.705 0.000239 ***
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>
> Residual standard error: 1.459 on 16 degrees of freedom
>
> Multiple R-squared:  0.7323,    Adjusted R-squared:  0.6821
>
> F-statistic: 14.59 on 3 and 16 DF,  p-value: 7.679e-05
>
>
> If I run individual regression models for each skin patch for each patient,
> this will result in a large number of models as I have There are 16 skin
> patches per patient. (10 patients in total) 5 readings are taken at each of
> the 4 time points.
>
> I thought linear mixed models would be an appropriate method to answer my
> question (I need to be able to tell if there is a significant difference
> for individual patches for individual patients over time).
>

  When you adopt a random-effects formulation, you forego the ability
to perform significance tests on individual levels -- that's the price you
pay for the benefits of doing shrinkage estimation.  If you need significance
tests on individual patch/patient combinations, you're going to be
stuck with 160 significance tests (you should probably consider some
kind of multiple-comparisons correction ...)

 Ben Bolker


From j.hadfield at ed.ac.uk  Sun Sep 27 11:28:14 2015
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 27 Sep 2015 10:28:14 +0100
Subject: [R-sig-ME] MCMCglmm bivariate model
In-Reply-To: <SN1PR0701MB1966624D1E46F951D50D8D5CBE430@SN1PR0701MB1966.namprd07.prod.outlook.com>
References: <SN1PR0701MB1966624D1E46F951D50D8D5CBE430@SN1PR0701MB1966.namprd07.prod.outlook.com>
Message-ID: <20150927102814.20904hyd9y5s5aww@www.staffmail.ed.ac.uk>

Hi,

1) It is hard to offer advice on this. It seems from the widths of the  
credible intervals that the genetic term and the ID term are hard to  
separate. What is the structure of the pedigree like? The scaled  
F-distribution with large scale has a long tail. My guess is that this  
results in a long tail for the animal term which then forces the ID  
term to zero, resulting in a bimodal posterior distribution. Although  
a scale of 1000 makes sense for trait 1, it is less reasonable for the  
threshold trait. Pierre de Villemereuil makes this point in his  
Methods in Ecology and Evolution paper (4 3 260?275 2013). He suggests  
a prior that approaches the chi-square distribution (V=1, nu=1000,  
alpha.mu=0, alpha.V=1) but you can't use this in a bivariate setting  
because both traits have to have a common nu. You could try reducing  
the scale of the threshold trait to something more reasonable. For  
example,

P3 = list(R = list(V = diag(2), nu = 1.002, fix = 2), G = list(G1 =
  list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(c(1000,100))),G2 =
  list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(c(1000,100)))))

or perhaps even less (e.g. 10). Why bimodality increases under the  
bivariate specification I'm not sure. I have not seen any papers  
exploring the bivariate scaled-F prior theoretically. It would be nice  
if some one did! The new version of MCMCglmm (now on-line) can fit  
antedependence structures. Here, priors can be placed directly on  
regression coefficients (e.g. the breeding value for y2 on y1) which  
may turn out to have nicer properties - not sure.


2) There is nothing to worry about, M3 is the correct model and it is  
just a reparameterisation of M1. From the bivariate model location 3  
trait 1 is the intercept (457), location 1 trait 1 is (457+11 = 468)  
and location 2 trait 1 is (457+38 = 495). From the univariate model  
location 1 is the intercept (469) location 2 is  (469+23 = 491) and  
location 3 is (469-14 = 455). They differ slightly of course, but  
there is Monte Carlo error, and the model is slightly different (e.g.  
there are correlations between traits).

Cheers,

Jarrod



2015 15:47:36 +0000:

> Hi all,
> I'm using MCMCglmm to estimate the heritability of 2 traits and  
> their genetic correlation in a repeated measures animal model. My  
> data consists of 500 individuals each measured twice for each trait  
> with a few missing values. y1 is Gaussian, y2 is ordered discrete  
> categories 0-5. Separate models for each trait run ok but I have 2  
> issues with a bivariate model.
>
>
> 1)      the bivariate model gives a bimodal posterior distribution  
> for the trait y2:ID term with one peak at ~4 (similar to the  
> univariate model) and a second peak at zero. I'm using parameter  
> expanded priors and both mixing and convergence look ok according to  
> trace plots, Geweke plots and Heidelberg tests. Autocorrelation is  
> <0.13. The ID term does have some support at zero in a univariate  
> model of y2 but has a clear mode at 4, whereas in the bivariate  
> model there is equal support for 0 and 4.
>
>
>
> 2)      The fixed effect, location (a 3 level factor), is only  
> relevant for trait y1. In the univariate model for y1 the 3 levels  
> are estimated ok with no error but in the bivariate model using  
> trait-1 + at.level(trait, 1):location gives the error "In  
> MCMCglmm(cbind(y1, y2) ~ trait - 1 + at.level(trait,  :  some fixed  
> effects are not estimable and have been removed. Use  
> singular.ok=TRUE to sample these effects, but use an informative  
> prior!" and gives estimates in the summary table for locations 1 and  
> 2, suggesting location 3 could not be estimated? Using  
> trait-1+trait:location does not give an error and gives estimates  
> for locations 2 and 3 in the summary table for both traits, which  
> presumably are contrasts from the "trait y1" that corresponds to  
> location 1.
>
>
> Can anyone advise on these 2 issues? Am I using at.level(trait, 1)  
> correctly? I've copied my code and output below:
> Thanks in advance,
> Rebecca
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> univariate models:
> P1<- list(G = list(G1 = list(V = 1, n = 0.002), G2 = list(V = 1,n =  
> 0.002)), R = list(V = 1, n = 0.002))
> M1<-MCMCglmm(y1~age+location+size,
> random=~animal+ID,
> pedigree=ped,
> data=pheno2,prior=P1,nitt=1010000,thin=1000,burnin=10000,verbose=FALSE)
>
>> summary(M1)
> Iterations = 10001:1009001
> Thinning interval  = 1000
> Sample size  = 1000
>
> DIC: 10909.28
>
> G-structure:  ~animal
>
>        post.mean l-95% CI u-95% CI eff.samp
> animal      1144    444.3     1885     1162
>
>                ~ID
>
>    post.mean l-95% CI u-95% CI eff.samp
> ID      1750     1184     2462     1000
>
> R-structure:  ~units
>
>       post.mean l-95% CI u-95% CI eff.samp
> units     793.1    700.6    896.2     1000
>
> Location effects: y1 ~ age + location + size
>
>             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)   469.474  434.740  502.941     1000 <0.001 ***
> age            -3.409   -3.950   -2.958     1000 <0.001 ***
> location2    23.355   10.235   37.260     1000  0.002 **
> location3   -14.113  -29.935    3.468     1000  0.114
> size      4.782    2.300    7.316     1000 <0.001 ***
> ---
>
>> posterior.heritability<-M1$VCV[,"animal"]/(M1$VCV[,"animal"]+M1$VCV[,"ID"]+M1$VCV[,"units"])
>> mean(posterior.heritability)
> [1] 0.31
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~
> P2 <- list(R=list(V = 1 , fix=1), G = list(G1=list(V=1,  
> nu=1,alpha.mu=0, alpha.V=1000),G2=list(V=1, nu=1, alpha.mu=0,  
> alpha.V=1000)))
> M2<-MCMCglmm(y2~age,random=~animal+ID,pedigree=ped,family="threshold",data=pheno2,prior=P2,verbose=FALSE,  
> nitt=10500000,thin=2000,burnin=500000)
>> summary(M2)
>
> Iterations = 500001:10498001
> Thinning interval  = 2000
> Sample size  = 5000
>
> DIC: 1270.806
>
> G-structure:  ~animal
>
>        post.mean l-95% CI u-95% CI eff.samp
> animal     10.38    4.473    16.46     4162
>
>                ~ID
>
>    post.mean l-95% CI u-95% CI eff.samp
> ID     4.291 2.09e-05     8.01     3910
>
> R-structure:  ~units
>
>       post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
> Location effects: y2 ~ age
>
>             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)  -11.6004 -14.5259  -8.9838     5000 <2e-04 ***
> age            0.1794   0.1404   0.2218     5000 <2e-04 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Cutpoints:
>                       post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traity2.1     2.895    2.461    3.314     5351
> cutpoint.trait y2.2     4.610    4.069    5.268     4793
> cutpoint.trait y2.3     7.398    6.527    8.348     5000
> cutpoint.trait y2.4    11.917   10.013   13.981     5141
>
>> posterior.heritability<-M2$VCV[,"animal"]/(M2$VCV[,"animal"]+M2$VCV[,"ID"]+M2$VCV[,"units"])
>> mean(posterior.heritability)
> [1] 0.66
>
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Bivariate model:
> P3 = list(R = list(V = diag(2), nu = 1.002, fix = 2), G = list(G1 =  
> list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000),G2 =  
> list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
> M3<-MCMCglmm(cbind(y1, y2) ~ trait - 1 + at.level(trait, 1):location  
> + trait:age + at.level(trait, 1):size,
> pedigree=ped, data=pheno2,
> random = ~us(trait):animal+us(trait):ID,
> rcov = ~us(trait):units,  family = c("gaussian", "threshold"),
> prior = P3, verbose = FALSE, nitt=10500000,thin=2000,burnin=500000)
>
>> summary(M3)
>
> Iterations = 500001:10498001
> Thinning interval  = 2000
> Sample size  = 5000
>
> DIC: 12151.2
>
> G-structure:  ~us(trait):animal
>
>                            post.mean l-95% CI u-95% CI eff.samp
> y1:y1.animal   1156.88  435.518 1870.316     5000
> y2:y1.animal        -39.70  -83.129    5.598     4666
> y1:y2.animal        -39.70  -83.129    5.598     4666
> y2:y2.animal             11.04    4.659   17.753     3657
>
>                ~us(trait):ID
>
>                        post.mean   l-95% CI u-95% CI eff.samp
> y1:y1.ID  1743.758  1.124e+03 2351.973     5000
> y2:y1.ID       -12.174 -4.464e+01   20.891     5000
> y1:y2.ID       -12.174 -4.464e+01   20.891     5000
> y2:y2.ID             3.876  3.188e-06    7.734     3514
>
> R-structure:  ~us(trait):units
>
>                           post.mean l-95% CI u-95% CI eff.samp
> y1:y1.units   791.876  696.035    882.1     4568
> y2:y1.units         2.582   -1.169      6.1     5000
> y1:y2.units         2.582   -1.169      6.1     5000
> y2:y2.units             1.000    1.000      1.0        0
>
> Location effects: cbind(y1, y2) ~ trait - 1 + at.level(trait, 1):loca
>
>                                post.mean l-95% CI u-95% CI eff.samp  pMCMC
> traity1                  456.6321 419.7208 494.7115     5239 <2e-04 ***
> traity2                      -11.5170 -14.4037  -8.8785     4137 <2e-04 ***
> at.level(trait, 1):location1   11.6986  -4.0319  28.8620     5000 0.1676
> at.level(trait, 1):location2   37.8950  22.5601  53.8510     5000 <2e-04 ***
> traity1:age               -3.4116  -3.9302  -2.9405     5209 <2e-04 ***
> traity2:age                    0.1779   0.1383   0.2184     4670 <2e-04 ***
> at.level(trait, 1):size     4.4378   1.9564   6.9510     5421 0.0004 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Cutpoints:
>                       post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traity2.1     2.890    2.473    3.308     4696
> cutpoint.trait y2.2     4.600    4.074    5.186     4474
> cutpoint.trait y2.3     7.451    6.565    8.327     4071
> cutpoint.trait y2.4    12.053   10.131   14.039     4045
>
>
> herit_y1<- M3$VCV[,'y1:y1.animal']/( M3$VCV[,'y1:y1.animal']+  
> M3$VCV[,'y1:y1.ID']+ M3$VCV[,'y1:y1.units'])
> mean(herit_y1)
> =0.31 (0.13-0.48)
>
> herit_y2<- M3$VCV[,'y2:y2.animal']/( M3$VCV[,'y2:y2.animal']+  
> M3$VCV[,'y2:y2.ID']+ M3$VCV[,'y2:y2.units'])
> mean(herit_y2)
> =0.68 (0.42-0.95)
>
> corr.gen<- M3$VCV[,'y1:y2.animal']/sqrt(M3$VCV[,'y1:y1.animal']*  
> M3$VCV[,y2:y2.animal'])
> mean(corr.gen)
> =-0.36 (-0.70-0.004)
>
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> summary table for bivariate model with trait:location instead of  
> at.level(trait, 1):location
>
> Location effects: cbind(y1, y2) ~ trait - 1 + trait:location +  
> trait:age + at.level(trait, 1):size
>
>                               post.mean l-95% CI u-95% CI eff.samp  pMCMC
> traity1                 468.8456 433.1704 499.3057   761.34 <0.001 ***
> traity2                     -11.6934 -14.6120  -9.0283    88.10 <0.001 ***
> traity1:location2      23.5282  10.8358  36.8648  1000.00 <0.001 ***
> traity2:location2           0.9043  -0.2198   2.1732   341.51  0.128
> traity1:location3     -14.6928 -30.8528   1.0206   887.36  0.074 .
> traity2:location3           0.8966  -0.4732   2.3384   453.18  0.218
> traity1:age              -3.3947  -3.9142  -2.9634   839.89 <0.001 ***
> traity2:age                   0.1718   0.1356   0.2125    92.35 <0.001 ***
> at.level(trait, 1):size    4.4933   2.2326   7.3976  1000.00  0.002 **
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From qelmore1 at yahoo.com  Tue Sep 29 01:49:52 2015
From: qelmore1 at yahoo.com (Quincy Elamore)
Date: Mon, 28 Sep 2015 23:49:52 +0000 (UTC)
Subject: [R-sig-ME] Remove from list
Message-ID: <186970582.1772457.1443484192271.JavaMail.yahoo@mail.yahoo.com>

To whom it may concern:
Please remove me from the list.
Thanks
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Sep 29 05:05:16 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 28 Sep 2015 23:05:16 -0400
Subject: [R-sig-ME] Remove from list
In-Reply-To: <186970582.1772457.1443484192271.JavaMail.yahoo@mail.yahoo.com>
References: <186970582.1772457.1443484192271.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CABghstTFnmYWFFcWdFSTn6-YDDJuPt3TAisS-SedeL6W5a=8jw@mail.gmail.com>

You'll have to go to the link posted at the bottom of every message on
the list in order to unsubscribe yourself:

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

On Mon, Sep 28, 2015 at 7:49 PM, Quincy Elamore via R-sig-mixed-models
<r-sig-mixed-models at r-project.org> wrote:
> To whom it may concern:
> Please remove me from the list.
> Thanks
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Tue Sep 29 11:12:30 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 29 Sep 2015 10:12:30 +0100
Subject: [R-sig-ME] Stats course: Lisbon, Portugal
Message-ID: <560A55FE.1020102@highstat.com>

Apologies for cross-posting

We would like to announce the following statistics course:

Course: Data exploration, regression, GLM & GAM with introduction to R
Where:  Lisbon, Portugal
When:   8-12 February 2016

Course website: http://www.highstat.com/statscourse.htm
Flyer: http://highstat.com/Courses/Flyers/Flyer2016_02Lisbon_RGG.pdf



Kind regards,

Alain Zuur




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From etnbot1 at gmail.com  Wed Sep 30 16:18:19 2015
From: etnbot1 at gmail.com (Etn bot)
Date: Wed, 30 Sep 2015 15:18:19 +0100
Subject: [R-sig-ME] Linear mixed model query
In-Reply-To: <CABghstS9jOAxjRZNQLbk-A5k_6p72_p7=j1YPmqccKuL65yY9w@mail.gmail.com>
References: <CAF79uvk-ThiNNg36=RtRspitwVgYsu2ogPoQypdxS+Y4=1aNUQ@mail.gmail.com>
	<CABghstS9jOAxjRZNQLbk-A5k_6p72_p7=j1YPmqccKuL65yY9w@mail.gmail.com>
Message-ID: <CAF79uvnEjxwjW3z_TXZSU33fiuNc5hFAPdnwjDRBhLYFJCtavQ@mail.gmail.com>

Many thanks for your response Ben, it is greatly appreciated


Kind regards

Etn

On 25 September 2015 at 20:47, Ben Bolker <bbolker at gmail.com> wrote:

> On Thu, Sep 24, 2015 at 10:06 AM, Etn bot <etnbot1 at gmail.com> wrote:
> > Hi all,
> >
> > My study looks at allergy levels of skin patches from patients and
> readings
> > (repeated 5 times) are measured over 4 time points
> >
> > I need to determine if the allergy level for skin patch changes over time
> > (e.g. if allergy level from skin patch 1 for patient 1 at time 0 is
> > different from allergy level for skin patch 1 for patient 1 at time 1
> etc.)
> > I do not want to see the difference between skin patch 1 and skin patch
> > 2....
> >
> > using package lmer:
> > model<-lmer(allergy_level ~ time +(time|patient/patch))
> >
> > Results from this model indicate that time is not significant - the
> average
> > patient allergy level for individual skin patches does not change over
> > time:
> >
> > Random effects:
> >
> >  Groups   Name        Variance Std.Dev. Corr
> >
> >  ID:patch (Intercept) 17.4109  4.1726
> >
> >           time1        2.7109  1.6465   -0.30
> >
> >           time2        3.0082  1.7344   -0.26  0.60
> >
> >           time3        5.7643  2.4009   -0.35  0.15  0.54
> >
> >  patch    (Intercept) 19.1576  4.3769
> >
> >           time1        0.2103  0.4586   -0.56
> >
> >           time2        0.4372  0.6612   -0.94  0.48
> >
> >           time3        0.5895  0.7678   -0.48  0.96  0.49
> >
> >  Residual              4.9467  2.2241
> >
> > Number of obs: 2956, groups:  ID:patch, 149; patch, 16
> >
> >
> >
> > Fixed effects:
> >
> >             Estimate Std. Error t value
> >
> > (Intercept)  6.44763    1.15028   5.605
> >
> > time1       -0.01907    0.21237  -0.090
> >
> > time2       -0.03172    0.24759  -0.128
> >
> > time3       -0.01124    0.29940  -0.038
> >
> >
>    I was going to ask if you wanted to treat time as linear, but there's
> not much evidence that it will help you here.
> >
> >
> >
> > model1: Force ~ 1 + (1 + time | patch/ID)
> >
> > model2: Force ~ time + (1 + time | patch/ID)
> >
> >          Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> >
> > model11 22 14281 14413 -7118.5    14237
> >
> > model12 25 14287 14437 -7118.4    14237 0.0208      3     0.9992
> >
> > I have extracted the random coefficients from model 1:
> >
> > ranef(model1)
> >
> > $`ID:patch`
> >
> >       (Intercept)       time1        time2        time3
> >
> > 1:11    5.9845070  0.34088535  0.431998708  1.590906238
> >
> > 1:12    5.1236456 -0.03178611 -0.149784278 -0.116150278
> >
> > 1:13    6.3746877 -0.76853294 -0.550037715  0.842518786
> >    :
> >    :
> > However, I need to be able to tell if there is a significant difference
> for
> > individual patches for individual patients over time
> >
> > e.g.
> > If I run individual linear regression on patient 1 for skin patch 1,
> > results show that that time is significant:
> >
> > Coefficients:
> >
> >             Estimate Std. Error t value Pr(>|t|)
> >
> > (Intercept)  18.0800     0.6523  27.717 5.95e-15 ***
> >
> > time1         0.3600     0.9225   0.390 0.701502
> >
> > time2         1.2400     0.9225   1.344 0.197641
> >
> > time3        -4.3400     0.9225  -4.705 0.000239 ***
> >
> > ---
> >
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >
> >
> > Residual standard error: 1.459 on 16 degrees of freedom
> >
> > Multiple R-squared:  0.7323,    Adjusted R-squared:  0.6821
> >
> > F-statistic: 14.59 on 3 and 16 DF,  p-value: 7.679e-05
> >
> >
> > If I run individual regression models for each skin patch for each
> patient,
> > this will result in a large number of models as I have There are 16 skin
> > patches per patient. (10 patients in total) 5 readings are taken at each
> of
> > the 4 time points.
> >
> > I thought linear mixed models would be an appropriate method to answer my
> > question (I need to be able to tell if there is a significant difference
> > for individual patches for individual patients over time).
> >
>
>   When you adopt a random-effects formulation, you forego the ability
> to perform significance tests on individual levels -- that's the price you
> pay for the benefits of doing shrinkage estimation.  If you need
> significance
> tests on individual patch/patient combinations, you're going to be
> stuck with 160 significance tests (you should probably consider some
> kind of multiple-comparisons correction ...)
>
>  Ben Bolker
>

	[[alternative HTML version deleted]]


